{
  "Token": {
    "__init__": [
      "self",
      "name"
    ],
    "append": [
      "self",
      "key",
      "value"
    ],
    "string": [
      "self",
      "orders"
    ]
  },
  "TokenParser": {
    "__init__": [
      "self",
      "lang",
      "operator"
    ],
    "load": [
      "self",
      "input"
    ],
    "read": [
      "self"
    ],
    "parse_ws": [
      "self"
    ],
    "parse_char": [
      "self",
      "exp"
    ],
    "parse_chars": [
      "self",
      "exp"
    ],
    "parse_key": [
      "self"
    ],
    "parse_value": [
      "self"
    ],
    "parse": [
      "self",
      "input"
    ],
    "reorder": [
      "self",
      "input"
    ]
  },
  "get_lang": [
    "text"
  ],
  "preprocess": [
    "text",
    "traditional_to_simple"
  ],
  "postprocess": [
    "text",
    "full_to_half",
    "remove_interjections",
    "remove_puncts",
    "tag_oov"
  ],
  "should_normalize": [
    "text",
    "operator",
    "remove_erhua"
  ],
  "reorder": [
    "text",
    "lang",
    "operator"
  ],
  "tag": [
    "text",
    "lang",
    "operator",
    "enable_0_to_9"
  ],
  "verbalize": [
    "text",
    "lang",
    "operator",
    "remove_erhua"
  ],
  "normalize": [
    "text",
    "config"
  ],
  "__all__": [],
  "main": [],
  "NormalizerConfig": {},
  "Normalizer": {
    "__init__": [
      "self"
    ],
    "normalize": [
      "self",
      "text"
    ]
  },
  "load_fst": [
    "fst_path"
  ],
  "EOS": [],
  "TN_ORDERS": [],
  "EN_TN_ORDERS": [],
  "ITN_ORDERS": [],
  "FSTS": []
}