{
  "__version__": [],
  "short_version": [],
  "parse_version_info": [
    "version_str"
  ],
  "version_info": [],
  "logger": [],
  "LogitsProcessor": [],
  "GenerationConfig": {
    "convert_stop_bad_words_to_ids": [
      "self",
      "tokenizer"
    ],
    "update_from_hf_gen_cfg": [
      "self",
      "generation_config",
      "tokenizer_eos_token_id"
    ],
    "__post_init__": [
      "self"
    ]
  },
  "TurbomindEngineConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "PytorchEngineConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "ResponseType": {
    "SUCCESS": [],
    "FINISH": [],
    "ENGINE_STOP_ERROR": [],
    "SESSION_REPEAT": [],
    "SESSION_NOT_EXIST": [],
    "HANDLER_NOT_EXIST": [],
    "INPUT_LENGTH_ERROR": [],
    "INTERNAL_ENGINE_ERROR": [],
    "CANCEL": [],
    "PREFIX_CACHE_CONFLICT_INTERACTIVE_MODE": [],
    "NO_QUEUE": []
  },
  "Response": {
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_format_none_text_fields": [
      "self"
    ],
    "extend": [
      "self",
      "other"
    ]
  },
  "EventType": {
    "QUEUED": [],
    "SCHEDULED": [],
    "PREEMPTED": []
  },
  "EngineEvent": {
    "new_event": [
      "cls",
      "event_type",
      "timestamp"
    ]
  },
  "ScheduleMetrics": {},
  "RequestMetrics": {},
  "EngineOutput": {},
  "VisionConfig": {},
  "SpeculativeConfig": {},
  "autoget_backend": [
    "model_path"
  ],
  "autoget_backend_config": [
    "model_path",
    "backend_config"
  ],
  "check_vl_llm": [
    "config"
  ],
  "get_task": [
    "model_path"
  ],
  "get_model_arch": [
    "model_path"
  ],
  "search_nested_config": [
    "config",
    "key"
  ],
  "RequestLogger": {
    "__init__": [
      "self",
      "max_log_len"
    ],
    "log_prompt": [
      "self",
      "session_id",
      "prompt"
    ],
    "log_inputs": [
      "self",
      "session_id",
      "prompt",
      "prompt_token_ids",
      "gen_config",
      "adapter_name"
    ]
  },
  "logger_initialized": [],
  "_ASNI_COLOR": {
    "BRIGHT_RED": [],
    "RED": [],
    "YELLOW": [],
    "WHITE": [],
    "GREEN": []
  },
  "can_colorize": [],
  "ColorFormatter": {
    "_LEVELNAME_COLOR_MAP": [],
    "_RESET_COLOR": [],
    "format": [
      "self",
      "record"
    ]
  },
  "FilterDuplicateWarning": {
    "__init__": [
      "self",
      "name"
    ],
    "filter": [
      "self",
      "record"
    ]
  },
  "_FORMAT": [],
  "get_logger": [
    "name",
    "log_file",
    "log_level",
    "file_mode",
    "log_formatter"
  ],
  "filter_suffix": [
    "response",
    "suffixes"
  ],
  "_stop_words": [
    "stop_words",
    "tokenizer"
  ],
  "get_hf_gen_cfg": [
    "path"
  ],
  "get_model": [
    "pretrained_model_name_or_path",
    "download_dir",
    "revision",
    "token"
  ],
  "logging_timer": [
    "op_name",
    "logger",
    "level"
  ],
  "_get_and_verify_max_len": [
    "hf_config",
    "max_model_len"
  ],
  "get_max_batch_size": [
    "device_type"
  ],
  "is_bf16_supported": [
    "device_type"
  ],
  "try_import_deeplink": [
    "device_type"
  ],
  "serialize_state_dict": [
    "state_dict"
  ],
  "is_dlblas_installed": [],
  "FlattenedTensorMetadata": {},
  "FlattenedTensorBucket": {
    "__init__": [
      "self",
      "named_tensors",
      "flattened_tensor",
      "metadata"
    ],
    "get_flattened_tensor": [
      "self"
    ],
    "get_metadata": [
      "self"
    ],
    "reconstruct_tensors": [
      "self"
    ]
  },
  "DetokenizeState": {
    "as_tuple": [
      "self"
    ]
  },
  "HuggingFaceTokenizer": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_check_transformers_version": [
      "self",
      "model_dir"
    ],
    "get_vocab": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "vocab_size_with_added": [
      "self"
    ],
    "bos_token_id": [
      "self"
    ],
    "eos_token_id": [
      "self"
    ],
    "prefix_space_tokens": [
      "self"
    ],
    "_maybe_add_prefix_space": [
      "self",
      "tokens",
      "decoded"
    ],
    "maybe_decode_bytes": [
      "self"
    ],
    "indexes_containing_token": [
      "self",
      "token"
    ],
    "encode": [
      "self",
      "s",
      "add_bos",
      "add_special_tokens"
    ],
    "decode": [
      "self",
      "t",
      "offset",
      "skip_special_tokens"
    ],
    "_convert_tokens_to_string_with_added_encoders": [
      "tokenizer",
      "output_tokens",
      "skip_special_tokens",
      "spaces_between_special_tokens"
    ],
    "detokenize_incrementally": [
      "self",
      "all_input_ids",
      "state",
      "skip_special_tokens",
      "spaces_between_special_tokens"
    ],
    "__call__": [
      "self",
      "s"
    ]
  },
  "ChatGLM4Tokenizer": {
    "__init__": [
      "self",
      "model_path"
    ],
    "encode": [
      "self",
      "s",
      "add_bos",
      "add_special_tokens"
    ]
  },
  "ChatGLMTokenizer": {
    "__init__": [
      "self",
      "model_path"
    ]
  },
  "GptOssTokenizer": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "detokenize_incrementally": [
      "self",
      "all_input_ids",
      "state",
      "skip_special_tokens",
      "spaces_between_special_tokens"
    ]
  },
  "Tokenizer": {
    "__init__": [
      "self",
      "model_path"
    ],
    "vocab_size": [
      "self"
    ],
    "bos_token_id": [
      "self"
    ],
    "eos_token_id": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "encode": [
      "self",
      "s",
      "add_bos",
      "add_special_tokens"
    ],
    "decode": [
      "self",
      "t",
      "offset",
      "skip_special_tokens"
    ],
    "detokenize_incrementally": [
      "self",
      "all_input_ids",
      "state",
      "skip_special_tokens",
      "spaces_between_special_tokens"
    ],
    "__call__": [
      "self",
      "s"
    ],
    "indexes_containing_token": [
      "self",
      "token"
    ]
  },
  "pipeline": [
    "model_path",
    "backend_config",
    "chat_template_config",
    "log_level",
    "max_log_len",
    "speculative_config"
  ],
  "serve": [
    "model_path",
    "model_name",
    "backend",
    "backend_config",
    "chat_template_config",
    "server_name",
    "server_port",
    "log_level",
    "api_keys",
    "ssl"
  ],
  "client": [
    "api_server_url",
    "api_key"
  ],
  "__all__": [],
  "Pipeline": {
    "__init__": [
      "self",
      "model_path",
      "backend_config",
      "chat_template_config",
      "log_level",
      "max_log_len",
      "speculative_config"
    ],
    "infer": [
      "self",
      "prompts",
      "gen_config",
      "do_preprocess",
      "adapter_name",
      "use_tqdm"
    ],
    "batch_infer": [
      "self"
    ],
    "stream_infer": [
      "self",
      "prompts",
      "sessions",
      "gen_config",
      "do_preprocess",
      "adapter_name",
      "stream_response"
    ],
    "close": [
      "self"
    ],
    "chat": [
      "self",
      "prompt",
      "session",
      "gen_config",
      "stream_response",
      "adapter_name"
    ],
    "session": [
      "self"
    ],
    "get_reward_score": [
      "self",
      "input_ids"
    ],
    "get_ppl": [
      "self",
      "input_ids"
    ],
    "__call__": [
      "self",
      "prompts",
      "gen_config"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "generate": [
      "self"
    ],
    "_is_single": [
      "prompts"
    ],
    "_request_generator": [
      "self",
      "prompts",
      "sessions",
      "gen_config"
    ],
    "_get_limiter": [
      "self"
    ],
    "_infer": [
      "self",
      "requests",
      "multiplex",
      "pbar",
      "loop"
    ],
    "_run": [
      "self",
      "fn",
      "coro"
    ],
    "_batch_iterator": [
      "self",
      "sizes",
      "max_value"
    ],
    "_get_long_text_ppl": [
      "self",
      "session",
      "input_ids",
      "max_input_len"
    ],
    "_get_ppl": [
      "self",
      "sessions",
      "input_ids",
      "max_input_len",
      "target_ids",
      "sequence_start",
      "sequence_end"
    ]
  },
  "_EventLoopThread": {
    "__init__": [
      "self",
      "daemon"
    ],
    "_thread_entry": [
      "self",
      "fut"
    ],
    "_cancel_all_tasks": [
      "self"
    ],
    "close": [
      "self"
    ]
  },
  "MODELS": [],
  "random_uuid": [],
  "get_text": [
    "content"
  ],
  "ChatTemplateConfig": {
    "chat_template": [
      "self"
    ],
    "to_json": [
      "self",
      "file_path"
    ],
    "from_json": [
      "cls",
      "file_or_string"
    ]
  },
  "BaseChatTemplate": {
    "__init__": [
      "self",
      "system",
      "meta_instruction",
      "eosys",
      "user",
      "eoh",
      "assistant",
      "eoa",
      "separator",
      "tool",
      "eotool",
      "capability",
      "stop_words"
    ],
    "get_prompt": [
      "self",
      "prompt",
      "sequence_start"
    ],
    "messages2prompt": [
      "self",
      "messages",
      "sequence_start"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "CogVLM": {
    "__init__": [
      "self",
      "meta_instruction",
      "eosys",
      "user",
      "separator",
      "eoh",
      "assistant",
      "eoa",
      "stop_words"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "Vicuna": {
    "__init__": [
      "self",
      "meta_instruction",
      "eosys",
      "user",
      "eoh",
      "assistant",
      "eoa",
      "stop_words"
    ],
    "get_prompt": [
      "self",
      "prompt",
      "sequence_start"
    ],
    "messages2prompt": [
      "self",
      "messages",
      "sequence_start"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "Llavav1": {
    "__init__": [
      "self",
      "meta_instruction"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "InternLMChat7B": {
    "__init__": [
      "self",
      "system",
      "meta_instruction",
      "eosys",
      "user",
      "eoh",
      "assistant",
      "eoa",
      "separator",
      "stop_words"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "Baichuan2": {
    "__init__": [
      "self",
      "user",
      "assistant"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "Llama2": {
    "__init__": [
      "self",
      "system",
      "meta_instruction",
      "eosys",
      "assistant",
      "eoa",
      "separator",
      "session_len"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "CodeLlama": {
    "__init__": [
      "self",
      "meta_instruction",
      "suffix_first",
      "stop_words"
    ],
    "get_prompt": [
      "self",
      "prompt",
      "sequence_start"
    ],
    "_infill_prompt": [
      "self",
      "prompt"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "ChatGLM2": {
    "__init__": [
      "self",
      "user",
      "eoh",
      "assistant",
      "eoa"
    ],
    "get_prompt": [
      "self",
      "prompt",
      "sequence_start"
    ],
    "messages2prompt": [
      "self",
      "messages",
      "sequence_start"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "MistralChat": {
    "__init__": [
      "self",
      "user",
      "eoh",
      "eoa"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "InternVLZH": {
    "__init__": [
      "self",
      "user",
      "eoh",
      "assistant",
      "eoa"
    ],
    "get_prompt": [
      "self",
      "prompt",
      "sequence_start"
    ],
    "messages2prompt": [
      "self",
      "messages",
      "sequence_start"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "DeepseekVL": {
    "__init__": [
      "self",
      "meta_instruction",
      "eosys",
      "user",
      "eoh",
      "assistant",
      "eoa"
    ],
    "get_prompt": [
      "self",
      "prompt",
      "sequence_start"
    ],
    "messages2prompt": [
      "self",
      "messages",
      "sequence_start"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "DeepseekVL2": {
    "__init__": [
      "self",
      "meta_instruction",
      "eosys",
      "user",
      "eoh",
      "assistant",
      "eoa"
    ],
    "get_prompt": [
      "self",
      "prompt",
      "sequence_start"
    ],
    "messages2prompt": [
      "self",
      "messages",
      "sequence_start"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "ChatmlDirect": {
    "__init__": [
      "self",
      "system",
      "meta_instruction",
      "eosys",
      "user",
      "eoh",
      "assistant",
      "eoa",
      "separator"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "HFChatTemplate": {
    "__init__": [
      "self",
      "model_path"
    ],
    "get_prompt": [
      "self",
      "prompt",
      "sequence_start"
    ],
    "messages2prompt": [
      "self",
      "messages",
      "sequence_start"
    ],
    "_role_instruction": [
      "self",
      "role"
    ],
    "match": [
      "cls",
      "model_path"
    ]
  },
  "get_chat_template": [
    "model_path",
    "config"
  ],
  "Session": {
    "UNKNOWN": [],
    "SUCCESS": [],
    "FAIL": [],
    "__init__": [
      "self",
      "input_len",
      "req_output_len"
    ],
    "tick": [
      "self",
      "n_token"
    ],
    "finish": [
      "self",
      "status"
    ]
  },
  "Profiler": {
    "__init__": [
      "self",
      "stream_output",
      "percentages"
    ],
    "new_session": [
      "self"
    ],
    "start": [
      "self"
    ],
    "finish": [
      "self"
    ],
    "compute_metrics": [
      "self"
    ],
    "summarize": [
      "self",
      "title",
      "hyperparams",
      "header",
      "digits"
    ],
    "save_csv": [
      "self",
      "csv_file",
      "hyperparams"
    ]
  },
  "DefaultsAndTypesHelpFormatter": {
    "_get_help_string": [
      "self",
      "action"
    ]
  },
  "convert_args": [
    "args"
  ],
  "get_lora_adapters": [
    "adapters"
  ],
  "get_speculative_config": [
    "args"
  ],
  "ArgumentHelper": {
    "model_name": [
      "parser"
    ],
    "dtype": [
      "parser",
      "default"
    ],
    "quant_dtype": [
      "parser",
      "default"
    ],
    "model_format": [
      "parser",
      "default"
    ],
    "revision": [
      "parser",
      "default"
    ],
    "download_dir": [
      "parser",
      "default"
    ],
    "tp": [
      "parser"
    ],
    "dp": [
      "parser"
    ],
    "ep": [
      "parser"
    ],
    "cp": [
      "parser"
    ],
    "dp_rank": [
      "parser"
    ],
    "node_rank": [
      "parser"
    ],
    "num_nodes": [
      "parser"
    ],
    "dist_init_addr": [
      "parser"
    ],
    "session_id": [
      "parser"
    ],
    "session_len": [
      "parser",
      "default"
    ],
    "max_batch_size": [
      "parser"
    ],
    "quant_policy": [
      "parser",
      "default"
    ],
    "rope_scaling_factor": [
      "parser"
    ],
    "hf_overrides": [
      "parser"
    ],
    "use_logn_attn": [
      "parser"
    ],
    "block_size": [
      "parser"
    ],
    "top_p": [
      "parser"
    ],
    "top_k": [
      "parser"
    ],
    "temperature": [
      "parser",
      "default"
    ],
    "repetition_penalty": [
      "parser"
    ],
    "log_level": [
      "parser"
    ],
    "api_keys": [
      "parser"
    ],
    "ssl": [
      "parser"
    ],
    "backend": [
      "parser"
    ],
    "stream_output": [
      "parser"
    ],
    "calib_dataset": [
      "parser"
    ],
    "calib_samples": [
      "parser"
    ],
    "calib_seqlen": [
      "parser"
    ],
    "calib_batchsize": [
      "parser"
    ],
    "calib_search_scale": [
      "parser"
    ],
    "device": [
      "parser",
      "default",
      "choices"
    ],
    "chat_template": [
      "parser"
    ],
    "reasoning_parser": [
      "parser"
    ],
    "tool_call_parser": [
      "parser"
    ],
    "allow_terminate_by_client": [
      "parser"
    ],
    "enable_abort_handling": [
      "parser"
    ],
    "cache_max_entry_count": [
      "parser"
    ],
    "adapters": [
      "parser"
    ],
    "work_dir": [
      "parser"
    ],
    "cache_block_seq_len": [
      "parser"
    ],
    "enable_prefix_caching": [
      "parser"
    ],
    "num_tokens_per_iter": [
      "parser"
    ],
    "max_prefill_iters": [
      "parser"
    ],
    "async_": [
      "parser"
    ],
    "max_prefill_token_num": [
      "parser"
    ],
    "vision_max_batch_size": [
      "parser"
    ],
    "max_log_len": [
      "parser"
    ],
    "disable_fastapi_docs": [
      "parser"
    ],
    "eager_mode": [
      "parser"
    ],
    "communicator": [
      "parser"
    ],
    "enable_microbatch": [
      "parser"
    ],
    "enable_eplb": [
      "parser"
    ],
    "disable_metrics": [
      "parser"
    ],
    "role": [
      "parser"
    ],
    "migration_backend": [
      "parser"
    ],
    "disable_vision_encoder": [
      "parser"
    ],
    "logprobs_mode": [
      "parser"
    ],
    "dllm_block_length": [
      "parser"
    ],
    "dllm_unmasking_strategy": [
      "parser"
    ],
    "dllm_denoising_steps": [
      "parser"
    ],
    "dllm_confidence_threshold": [
      "parser"
    ],
    "enable_return_routed_experts": [
      "parser"
    ],
    "add_spec_group": [
      "parser"
    ],
    "distributed_executor_backend": [
      "parser"
    ]
  },
  "FlexibleArgumentParser": {
    "parse_args": [
      "self",
      "args",
      "namespace"
    ]
  },
  "run": [],
  "CLI": {
    "_desc": [],
    "parser": [],
    "subparsers": [],
    "add_parser_chat": [],
    "add_parser_checkenv": [],
    "check_env": [
      "args"
    ],
    "chat": [
      "args"
    ],
    "add_parsers": []
  },
  "SubCliServe": {
    "_help": [],
    "_desc": [],
    "parser": [],
    "subparsers": [],
    "add_parser_api_server": [],
    "add_parser_proxy": [],
    "api_server": [
      "args"
    ],
    "proxy": [
      "args"
    ],
    "add_parsers": []
  },
  "SubCliLite": {
    "_help": [],
    "_desc": [],
    "parser": [],
    "subparsers": [],
    "add_parser_auto_awq": [],
    "add_parser_auto_gptq": [],
    "add_parser_calibrate": [],
    "add_parser_smooth_quant": [],
    "auto_awq": [
      "args"
    ],
    "auto_gptq": [
      "args"
    ],
    "calibrate": [
      "args"
    ],
    "smooth_quant": [
      "args"
    ],
    "add_parsers": []
  },
  "input_prompt": [],
  "build_pipe": [
    "model_path",
    "backend"
  ],
  "build_gen_config": [],
  "get_adapter_name": [
    "adapters"
  ],
  "main": [
    "model_path",
    "backend"
  ],
  "SchedulerStats": {
    "__repr__": [
      "self"
    ],
    "update_from_schedule_metrics": [
      "self",
      "scheduled_metrics"
    ]
  },
  "RequestStats": {
    "__init__": [
      "self",
      "arrival_time",
      "prompt_tokens"
    ],
    "__repr__": [
      "self"
    ],
    "update_from_events": [
      "self",
      "engine_events"
    ],
    "e2e_latency": [
      "self"
    ],
    "queued_time_interval": [
      "self"
    ],
    "prefill_time_interval": [
      "self"
    ],
    "decode_time_interval": [
      "self"
    ],
    "inference_time_interval": [
      "self"
    ]
  },
  "IterationStats": {
    "__init__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_time_since": [
      "self",
      "start"
    ],
    "update_from_output": [
      "self",
      "outputs",
      "req_stats"
    ]
  },
  "SpeculativeDecodingStats": {
    "__post_init__": [
      "self"
    ],
    "update_from_output": [
      "self",
      "outputs"
    ],
    "update_per_draft": [
      "self",
      "num_draft_tokens",
      "num_accepted_tokens"
    ],
    "__repr__": [
      "self"
    ]
  },
  "StatLoggerBase": {
    "record_schedule": [
      "self",
      "stats"
    ],
    "record_iteration": [
      "self",
      "stats"
    ],
    "record_specdecode": [
      "self",
      "stats"
    ],
    "log": [
      "self"
    ]
  },
  "LoggingStatLogger": {
    "__init__": [
      "self",
      "dp_rank"
    ],
    "_reset": [
      "self",
      "now"
    ],
    "record_schedule": [
      "self",
      "stats"
    ],
    "record_iteration": [
      "self",
      "stats"
    ],
    "record_specdecode": [
      "self",
      "stats"
    ],
    "record_finish": [
      "self",
      "stats"
    ],
    "get_spec_msg": [
      "self"
    ],
    "log": [
      "self"
    ]
  },
  "PrometheusStatLogger": {
    "__init__": [
      "self",
      "model_name",
      "max_model_len",
      "dp_rank"
    ],
    "record_schedule": [
      "self",
      "stats"
    ],
    "record_iteration": [
      "self",
      "stats"
    ],
    "record_finish": [
      "self",
      "stats"
    ],
    "record_specdecode": [
      "self",
      "stats"
    ]
  },
  "build_buckets": [
    "mantissa_lst",
    "max_value"
  ],
  "build_1_2_5_buckets": [
    "max_value"
  ],
  "MetricsProcessor": {
    "__init__": [
      "self"
    ],
    "start_metrics_handler": [
      "self",
      "enable_metrics"
    ],
    "stop_metrics_handler": [
      "self"
    ],
    "_run_metrics_handler": [
      "self"
    ],
    "update_schedule_stats": [
      "self",
      "schedule_metrics"
    ],
    "queue_update": [
      "self",
      "update_data"
    ],
    "increase_total_requests": [
      "self"
    ],
    "increase_completed_requests": [
      "self"
    ],
    "increase_api_routed_requests": [
      "self"
    ],
    "decrease_api_routed_requests": [
      "self"
    ]
  },
  "metrics_processor": [],
  "InputEmbeddingType": [],
  "InputEmbeddingRangeType": [],
  "InputEmbeddings": {
    "move_position": [
      "self",
      "offset"
    ]
  },
  "SamplingParam": {
    "from_gen_config": [
      "cls",
      "gen_config"
    ]
  },
  "MessageStatus": {
    "WAITING": [],
    "READY": [],
    "STOPPED": [],
    "RUNNING": [],
    "TO_BE_MIGRATED": [],
    "MIGRATION_WAITING": [],
    "MIGRATION_READY": [],
    "MIGRATION_RUNNING": [],
    "MIGRATION_DONE": []
  },
  "SeqMap": [],
  "SequenceMeta": {},
  "SequenceManager": {
    "__init__": [
      "self",
      "seq_meta"
    ],
    "_new_seq_id": [
      "self"
    ],
    "get_all_sequences": [
      "self"
    ],
    "get_sequences": [
      "self",
      "states"
    ],
    "num_sequences": [
      "self",
      "status"
    ],
    "add_sequence": [
      "self",
      "seq"
    ],
    "remove_sequence": [
      "self",
      "seq"
    ],
    "update_sequence_status": [
      "self",
      "seq",
      "new_status"
    ]
  },
  "_to_ndarray": [
    "token_ids"
  ],
  "SchedulerSession": {
    "__init__": [
      "self",
      "session_id",
      "seq_manager",
      "scheduler"
    ],
    "add_sequence": [
      "self",
      "token_ids",
      "sampling_param",
      "adapter_name",
      "multimodals",
      "input_embeddings",
      "migration_request",
      "resp_cache",
      "preserve_cache"
    ],
    "remove_sequence": [
      "self",
      "seq"
    ]
  },
  "_div_up": [
    "x",
    "n"
  ],
  "_round_up": [
    "x",
    "n"
  ],
  "HistoryEmbeddings": {
    "__init__": [
      "self",
      "embeddings"
    ],
    "append": [
      "self",
      "embeddings"
    ],
    "clone": [
      "self"
    ],
    "copy": [
      "self"
    ],
    "get_step": [
      "self",
      "step"
    ],
    "embeddings": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self"
    ]
  },
  "_HistoryDataBase": {
    "ALLOC_SIZE": [],
    "COPY_ON_RESIZE": [],
    "__init__": [
      "self",
      "data",
      "dtype"
    ],
    "_create_empty_array": [
      "self",
      "dtype"
    ],
    "_get_pad_width": [
      "self",
      "reserve_size"
    ],
    "reserve": [
      "self",
      "size"
    ],
    "get_real": [
      "self"
    ],
    "resize": [
      "self",
      "size"
    ],
    "append": [
      "self",
      "new_data"
    ],
    "__setitem__": [
      "self"
    ],
    "__getitem__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "clone": [
      "self"
    ],
    "copy": [
      "self"
    ]
  },
  "HistoryTokenIds": {
    "ALLOC_SIZE": [],
    "__init__": [
      "self",
      "token_ids",
      "dtype"
    ],
    "_token_ids": [
      "self",
      "value"
    ]
  },
  "HistoryRouterExperts": {
    "ALLOC_SIZE": [],
    "COPY_ON_RESIZE": [],
    "__init__": [
      "self",
      "expert_ids",
      "dtype"
    ],
    "_create_empty_array": [
      "self",
      "dtype"
    ],
    "_get_pad_width": [
      "self",
      "reserve_size"
    ]
  },
  "HistoryLogits": {
    "ALLOC_SIZE": [],
    "COPY_ON_RESIZE": [],
    "__init__": [
      "self",
      "logits",
      "dtype"
    ],
    "_create_empty_array": [
      "self",
      "dtype"
    ],
    "_get_pad_width": [
      "self",
      "reserve_size"
    ],
    "set_torch_dtype": [
      "self",
      "torch_dtype"
    ],
    "get_logits": [
      "self"
    ],
    "clone": [
      "self"
    ]
  },
  "HistoryMultiModals": {
    "__init__": [
      "self",
      "multimodals"
    ],
    "get_datas": [
      "self",
      "start",
      "end"
    ],
    "add_inputs": [
      "self",
      "input_mms"
    ],
    "empty": [
      "self"
    ],
    "update_multimodals": [
      "input_mms",
      "prev_len"
    ]
  },
  "UpdateTokenMode": {
    "INPUTS": [],
    "PREFILL": [],
    "DECODE": []
  },
  "SchedulerSequence": {
    "__post_init__": [
      "self"
    ],
    "block_size": [
      "self"
    ],
    "history_image_num": [
      "self"
    ],
    "history_image_token_len": [
      "self"
    ],
    "session_id": [
      "self"
    ],
    "token_ids": [
      "self"
    ],
    "input_embeddings": [
      "self"
    ],
    "history_ids": [
      "self"
    ],
    "all_ids": [
      "self"
    ],
    "valid_ids": [
      "self"
    ],
    "generated_ids": [
      "self"
    ],
    "return_routed_experts": [
      "self"
    ],
    "routed_experts": [
      "self"
    ],
    "append_routed_experts": [
      "self",
      "routed_experts"
    ],
    "num_history_ids": [
      "self"
    ],
    "num_token_ids": [
      "self"
    ],
    "num_valid_ids": [
      "self"
    ],
    "num_images": [
      "self"
    ],
    "num_all_ids": [
      "self"
    ],
    "num_blocks": [
      "self"
    ],
    "state": [
      "self"
    ],
    "set_state": [
      "self",
      "state"
    ],
    "status": [
      "self"
    ],
    "return_logits": [
      "self"
    ],
    "logits": [
      "self"
    ],
    "append_logits": [
      "self",
      "logits"
    ],
    "get_input_multimodals": [
      "self"
    ],
    "record_event": [
      "self",
      "event_type",
      "timestamp"
    ],
    "_update_embeddings": [
      "self",
      "embeddings"
    ],
    "_update_multimodals": [
      "self",
      "multimodals"
    ],
    "update_token_ids": [
      "self",
      "token_ids",
      "multimodals",
      "embeddings",
      "model_meta",
      "mode"
    ],
    "set_step": [
      "self",
      "step"
    ]
  },
  "PG_WAIT_TIMEOUT": [],
  "get_device_str": [
    "device_type"
  ],
  "get_resource_kwargs": [
    "device_str",
    "resource_used"
  ],
  "_wait_until_pg_ready": [
    "current_placement_group"
  ],
  "_get_obj_store_memory": [
    "dp"
  ],
  "init_ray_cluster": [
    "world_size",
    "ray_address",
    "dp",
    "device_type"
  ],
  "RayContext": {
    "__init__": [
      "self",
      "world_size",
      "ray_address",
      "dp",
      "device_type"
    ],
    "get_placement_group": [
      "self"
    ],
    "shutdown": [
      "self"
    ]
  },
  "DistGroup": {
    "close": [
      "self"
    ]
  },
  "_build_tp_group_impl": [
    "tp",
    "rank",
    "world_size",
    "timeout",
    "cpu_backend",
    "ccl_backend",
    "attn_tp",
    "tp_mode"
  ],
  "_build_attn_tp_group": [
    "context",
    "timeout",
    "cpu_backend",
    "ccl_backend"
  ],
  "_build_mlp_tp_group": [
    "context",
    "timeout",
    "cpu_backend",
    "ccl_backend"
  ],
  "_build_moe_tp_group": [
    "context",
    "timeout",
    "cpu_backend",
    "ccl_backend"
  ],
  "_build_tp_group": [
    "context",
    "timeout",
    "cpu_backend",
    "ccl_backend"
  ],
  "DistContext": {
    "_build_ep_group": [
      "cls",
      "context",
      "timeout",
      "ccl_backend"
    ],
    "build": [
      "cls",
      "rank",
      "dist_config",
      "ccl_backend"
    ],
    "close": [
      "self"
    ]
  },
  "DefaultContext": [],
  "DistManager": {
    "__init__": [
      "self"
    ],
    "current_config": [
      "self"
    ]
  },
  "get_dist_manager": [],
  "get_world_rank": [],
  "get_tp_world_rank": [
    "layer_type"
  ],
  "get_dp_world_rank": [],
  "get_ep_world_rank": [],
  "_check_group_device": [
    "device"
  ],
  "get_process_group": [
    "device"
  ],
  "get_dist_group": [
    "layer_type"
  ],
  "get_tp_group": [
    "device",
    "layer_type"
  ],
  "get_group": [
    "group_type",
    "device"
  ],
  "all_reduce": [
    "tensor",
    "op",
    "group",
    "async_op"
  ],
  "broadcast": [
    "tensor",
    "src",
    "group",
    "async_op"
  ],
  "all_gather_object": [
    "object_list",
    "obj",
    "group"
  ],
  "all_gather": [
    "tensor_list",
    "tensor",
    "group",
    "async_op"
  ],
  "all_gather_into_tensor": [
    "output_tensor",
    "input_tensor",
    "group",
    "async_op"
  ],
  "reduce_scatter": [
    "output",
    "input_list",
    "op",
    "group",
    "async_op"
  ],
  "gather_by_tp_sizes": [
    "x",
    "tp_sizes",
    "group",
    "async_op"
  ],
  "reduce_scatter_by_tp_sizes": [
    "out",
    "rank",
    "tp_sizes",
    "group"
  ],
  "env_to_bool": [
    "env_var",
    "default"
  ],
  "env_to_int": [
    "env_var",
    "default"
  ],
  "env_to_list_int": [
    "env_var",
    "default"
  ],
  "env_to_float": [
    "env_var",
    "default"
  ],
  "_ENVS": [],
  "set_envs": [],
  "get_all_envs": [],
  "DLLM_MASKED": [],
  "DLLM_UNMASKED": [],
  "DLLM_CACHED": [],
  "get_gpu_memory": [
    "device_id"
  ],
  "get_cpu_memory": [],
  "bind_sigature": [
    "input_names",
    "args",
    "kwargs"
  ],
  "singleton": [
    "cls"
  ],
  "T": [],
  "CtxMgrBase": {
    "__init__": [
      "self",
      "default"
    ],
    "current_context": [
      "self"
    ],
    "set_context": [
      "self",
      "context"
    ],
    "context": [
      "self",
      "context"
    ]
  },
  "maybe_register_config_serialize_by_value": [
    "trust_remote_code"
  ],
  "monkey_patch_hf_modules_cache": [],
  "wait_for_async_tasks": [
    "tasks",
    "cancel_pending",
    "ignore_cancellederror"
  ],
  "cancel_async_tasks": [
    "tasks"
  ],
  "_update_torch_dtype": [
    "config",
    "dtype"
  ],
  "BackendConfig": {},
  "SchedulerConfig": {},
  "CacheConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "TPMode": {
    "DEFAULT": [],
    "DP_TP": []
  },
  "DistConfig": {
    "__post_init__": [
      "self"
    ],
    "get_tp_by_layer": [
      "self",
      "layer_type"
    ],
    "from_engine_config": [
      "cls",
      "engine_config"
    ]
  },
  "_override_hf_config_dict": [
    "hf_config",
    "key",
    "hf_overrides"
  ],
  "_overide_hf_config_cfg": [
    "hf_config",
    "key",
    "hf_overrides"
  ],
  "_override_hf_config": [
    "hf_config",
    "key",
    "hf_overrides"
  ],
  "override_hf_config": [
    "hf_config",
    "hf_overrides"
  ],
  "_default_check_env": [
    "device"
  ],
  "_patch_quantization_config": [
    "hf_config",
    "model_format"
  ],
  "ModelConfig": {
    "get_head_size": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path",
      "trust_remote_code",
      "dtype",
      "dist_config",
      "hf_overrides",
      "is_draft_model",
      "spec_method",
      "model_format"
    ],
    "from_hf_config": [
      "cls",
      "hf_config",
      "model_path",
      "dtype",
      "dist_config",
      "is_draft_model",
      "spec_method"
    ]
  },
  "UnmaskingStrategy": {
    "SEQUENTIAL": [],
    "LOW_CONFIDENCE_DYNAMIC": [],
    "LOW_CONFIDENCE_STATIC": [],
    "from_str": [
      "cls",
      "strategy"
    ]
  },
  "DLLMConfig": {},
  "MiscConfig": {
    "from_engine_config": [
      "cls",
      "engine_config"
    ]
  },
  "SpecDecodeConfig": {
    "from_config": [
      "cls",
      "method",
      "num_speculative_tokens",
      "model",
      "target_cache_cfg",
      "target_model",
      "dtype"
    ]
  },
  "QuantizationConfig": {
    "from_config": [
      "cls",
      "hf_config"
    ],
    "get_quant_method": [
      "self",
      "prefix"
    ],
    "get": [
      "self",
      "key",
      "default"
    ]
  },
  "LogicalTokenBlocks": {
    "ALLOC_SIZE": [],
    "__init__": [
      "self",
      "blocks"
    ],
    "reserve": [
      "self",
      "size"
    ],
    "__setitem__": [
      "self"
    ],
    "__getitem__": [
      "self"
    ],
    "get_real_blocks": [
      "self"
    ],
    "append": [
      "self",
      "blocks"
    ],
    "__len__": [
      "self"
    ],
    "resize": [
      "self",
      "num_blocks"
    ],
    "reset": [
      "self"
    ],
    "clone": [
      "self"
    ]
  },
  "DPMeta": {
    "_gather_tp_sizes": [
      "tp",
      "seqlen",
      "num_tokens",
      "dist_ctx",
      "layer_type"
    ],
    "build": [
      "cls",
      "seqlen",
      "num_tokens"
    ],
    "sync_tp_size": [
      "self",
      "tp_size"
    ]
  },
  "VisionModelInputs": {
    "to_device": [
      "self",
      "device",
      "non_blocking"
    ],
    "get_inputs": [
      "self",
      "history_lengths",
      "seq_lengths"
    ]
  },
  "ModelInputsDelta": {
    "seq_length": [
      "self"
    ],
    "fill_tensors": [
      "self"
    ],
    "to_device": [
      "self",
      "device",
      "non_blocking"
    ],
    "log_info": [
      "self"
    ]
  },
  "ModelInputs": {
    "step": [
      "self",
      "input_ids",
      "step_seqlens"
    ],
    "to_device": [
      "self",
      "device",
      "non_blocking"
    ],
    "build_dp_meta": [
      "self",
      "num_tokens"
    ],
    "log_info": [
      "self"
    ]
  },
  "StepContext": {
    "new": [
      "cls",
      "inputs",
      "model_config",
      "cache_config",
      "kv_caches",
      "state_caches",
      "kv_quant_policy"
    ],
    "get_mask_and_position_ids": [
      "cls",
      "inputs"
    ]
  },
  "BuildModelContext": {},
  "StepContextManager": {
    "__init__": [
      "self",
      "build_ctx"
    ],
    "build_context": [
      "self",
      "inputs",
      "model_config",
      "cache_config",
      "kv_caches",
      "state_caches",
      "kv_quant_policy"
    ]
  },
  "StepCtxMgrApi": {
    "__init__": [
      "self"
    ]
  },
  "set_step_ctx_manager": [],
  "get_step_ctx_manager": [],
  "step_ctx_manager": [],
  "build_strategy_factory": [
    "model_config",
    "misc_config",
    "specdecode_config"
  ],
  "SeqList": [],
  "DLLMSamplingStrategy": {
    "__init__": [
      "self",
      "pad_token_id",
      "dllm_block_length"
    ],
    "make_sampling_inputs": [
      "self",
      "seqs"
    ],
    "merge_sampling_delta": [
      "self",
      "sampling_delta",
      "other"
    ],
    "update_sampling_delta": [
      "self",
      "sampling_delta",
      "delta"
    ],
    "step_sampling_delta": [
      "self",
      "sampling_delta",
      "next_token_ids",
      "extra_inputs"
    ]
  },
  "DLLMCudagraphStrategy": {
    "__init__": [
      "self",
      "block_size"
    ],
    "get_max_tokens": [
      "self",
      "batch_size",
      "origin_batch_size",
      "num_tokens"
    ]
  },
  "DLLMStrategyFactory": {
    "__init__": [
      "self",
      "model_config",
      "dllm_config"
    ],
    "_update_dllm_block_length": [
      "self"
    ],
    "build_cudagraph_strategy": [
      "self"
    ],
    "build_sampling_strategy": [
      "self"
    ],
    "build_model_inputs_strategy": [
      "self"
    ],
    "build_model_agent_strategy": [
      "self"
    ],
    "build_engine_strategy": [
      "self",
      "cache_config",
      "scheduler_config"
    ],
    "build_sequence_strategy": [
      "self"
    ]
  },
  "DLLMEngineStrategy": {
    "__init__": [
      "self",
      "scheduler_config",
      "cache_config",
      "dllm_block_length"
    ],
    "_check": [
      "self"
    ],
    "get_prealloc_size": [
      "self",
      "is_decoding"
    ],
    "get_num_loops": [
      "self",
      "is_decoding"
    ],
    "get_num_decode_tokens": [
      "self"
    ]
  },
  "get_model_inputs_next_decoding": [
    "inputs",
    "input_ids",
    "max_q_seqlen",
    "step_seqlens",
    "model_metas"
  ],
  "DLLMExtraInputs": {
    "broadcast": [
      "self",
      "src",
      "group",
      "async_op"
    ],
    "merge": [
      "self",
      "other"
    ]
  },
  "DLLMExtraOutputs": {},
  "_check_stopwords_dllm": [
    "token_ids",
    "stop_words",
    "is_unmasked",
    "stopped",
    "stop_pos",
    "num_appendable_ids",
    "output_start_pos",
    "inputs"
  ],
  "DLLMStoppingCriteria": {
    "clone": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "update": [
      "self",
      "delta"
    ],
    "step": [
      "self",
      "token_ids",
      "stop_words",
      "inputs",
      "extra_inputs"
    ]
  },
  "DLLMModelAgentStrategy": {
    "__init__": [
      "self",
      "dllm_config",
      "dllm_mask_token"
    ],
    "_update_dllm": [
      "self",
      "next_token_ids",
      "dllm_mask",
      "seqlens"
    ],
    "slice_outputs": [
      "self",
      "inputs",
      "seq_length"
    ],
    "slice_extra_inputs": [
      "self",
      "extra_inputs",
      "model_inputs",
      "model_outputs"
    ],
    "step_sampling_inputs": [
      "self",
      "sampling_inputs",
      "next_token_ids",
      "extra_inputs"
    ],
    "make_stopping_criteria": [
      "self",
      "seqs"
    ],
    "make_extra_inputs": [
      "self",
      "seqs",
      "model_inputs"
    ],
    "update_extra_inputs": [
      "self",
      "extra_inputs",
      "delta"
    ],
    "make_extra_outputs": [
      "self",
      "extra_inputs"
    ],
    "update_prefill_for_next_step": [
      "self",
      "model_inputs",
      "extra_inputs",
      "next_token_ids",
      "model_metas",
      "extra_outputs"
    ],
    "update_decoding_for_next_step": [
      "self",
      "model_inputs",
      "next_token_ids",
      "model_metas",
      "extra_inputs"
    ],
    "post_sampling": [
      "self",
      "inputs",
      "logits",
      "next_token_ids",
      "extra_inputs"
    ],
    "make_dummy_next_token": [
      "self",
      "inputs",
      "logits",
      "extra_inputs"
    ],
    "broadcast_next_token": [
      "self",
      "next_token_ids",
      "extra_inputs",
      "dist_ctx"
    ]
  },
  "DLLM_MASK_DTYPE": [],
  "HistoryDLLMMask": {
    "__init__": [
      "self",
      "token_ids",
      "dtype"
    ]
  },
  "SchedulerSequenceDLLM": {
    "__post_init__": [
      "self"
    ],
    "dllm_mask": [
      "self"
    ],
    "num_valid_ids": [
      "self"
    ],
    "generated_ids": [
      "self"
    ],
    "all_dllm_mask": [
      "self"
    ],
    "dllm_block_length": [
      "self"
    ],
    "dllm_mask_token": [
      "self"
    ],
    "set_stop_pos": [
      "self",
      "pos"
    ],
    "_update_token_ids_inputs": [
      "self",
      "token_ids",
      "dllm_mask"
    ],
    "_update_token_ids_decode": [
      "self",
      "token_ids",
      "dllm_mask"
    ],
    "_update_token_ids_prefill": [
      "self",
      "token_ids",
      "dllm_mask"
    ],
    "update_token_ids": [
      "self",
      "token_ids",
      "multimodals",
      "embeddings",
      "model_meta",
      "dllm_mask",
      "mode"
    ],
    "set_step": [
      "self",
      "step"
    ]
  },
  "DLLMSequenceStrategy": {
    "__init__": [
      "self",
      "block_size",
      "dllm_mask_token"
    ],
    "make_sequence": [
      "self",
      "seq_id",
      "session",
      "sampling_param",
      "adapter_name",
      "migration_request",
      "resp_cache",
      "preserve_cache"
    ],
    "update_running": [
      "self",
      "running",
      "batched_outputs",
      "model_inputs",
      "delta"
    ]
  },
  "UnmaskingProcessor": {
    "__init__": [
      "self",
      "dllm_config"
    ],
    "_get_scores": [
      "self",
      "logits",
      "token_ids"
    ],
    "_get_denoise_num": [
      "self"
    ],
    "low_confidence_static": [
      "self",
      "logits",
      "token_ids",
      "dllm_mask"
    ],
    "low_confidence_dynamic": [
      "self",
      "logits",
      "token_ids",
      "dllm_mask"
    ],
    "sequential": [
      "self",
      "dllm_mask"
    ],
    "__call__": [
      "self",
      "logits",
      "input_ids",
      "token_ids",
      "dllm_mask"
    ]
  },
  "DLLMModelInputsStrategy": {
    "__init__": [
      "self",
      "block_size"
    ],
    "make_dummy": [
      "self",
      "batch_size",
      "is_decoding",
      "device",
      "dummy_block_id",
      "vocab_size"
    ],
    "merge": [
      "self",
      "inputs",
      "other"
    ],
    "update_inputs": [
      "self",
      "inputs",
      "delta"
    ]
  },
  "ARSpecSamplingStrategy": {},
  "ARSpecCudagraphStrategy": {
    "__init__": [
      "self",
      "num_spec_tokens"
    ],
    "get_max_tokens": [
      "self",
      "batch_size",
      "origin_batch_size",
      "num_tokens"
    ]
  },
  "ARSpecStrategyFactory": {
    "__init__": [
      "self",
      "model_config",
      "specdecode_config"
    ],
    "build_cudagraph_strategy": [
      "self"
    ],
    "build_sampling_strategy": [
      "self"
    ],
    "build_model_inputs_strategy": [
      "self"
    ],
    "build_model_agent_strategy": [
      "self"
    ],
    "build_engine_strategy": [
      "self",
      "cache_config",
      "scheduler_config"
    ],
    "build_sequence_strategy": [
      "self"
    ]
  },
  "ARSpecEngineStrategy": {
    "__init__": [
      "self",
      "scheduler_config",
      "cache_config",
      "num_spec_tokens"
    ],
    "get_prealloc_size": [
      "self",
      "is_decoding"
    ],
    "get_num_loops": [
      "self",
      "is_decoding"
    ],
    "get_num_decode_tokens": [
      "self"
    ]
  },
  "ARSpecExtraInputs": {
    "__repr__": [
      "self"
    ],
    "broadcast": [
      "self",
      "src",
      "group",
      "async_op"
    ],
    "merge": [
      "self",
      "other"
    ]
  },
  "ARSpecExtraOutputs": {
    "__repr__": [
      "self"
    ]
  },
  "ARSpecStoppingCriteria": {
    "clone": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "update": [
      "self",
      "delta"
    ],
    "step": [
      "self",
      "next_token_ids",
      "stop_words",
      "inputs",
      "extra_inputs"
    ]
  },
  "ARSpecModelAgentStrategy": {
    "__init__": [
      "self",
      "num_spec_tokens"
    ],
    "slice_outputs": [
      "self",
      "inputs",
      "seq_length"
    ],
    "slice_extra_inputs": [
      "self",
      "extra_inputs",
      "model_inputs",
      "model_outputs"
    ],
    "step_sampling_inputs": [
      "self",
      "sampling_inputs",
      "next_token_ids"
    ],
    "make_stopping_criteria": [
      "self",
      "seqs"
    ],
    "make_extra_inputs": [
      "self",
      "seqs",
      "model_inputs"
    ],
    "update_extra_inputs": [
      "self",
      "extra_inputs",
      "delta"
    ],
    "make_extra_outputs": [
      "self",
      "extra_inputs"
    ],
    "update_prefill_for_next_step": [
      "self",
      "model_inputs",
      "extra_inputs",
      "next_token_ids",
      "model_metas",
      "extra_outputs"
    ],
    "update_decoding_for_next_step": [
      "self",
      "model_inputs",
      "next_token_ids",
      "model_metas",
      "extra_inputs",
      "extra_outputs"
    ],
    "post_sampling": [
      "self",
      "inputs",
      "logits",
      "next_token_ids",
      "extra_inputs"
    ],
    "make_dummy_next_token": [
      "self",
      "inputs",
      "logits",
      "extra_inputs"
    ],
    "broadcast_next_token": [
      "self",
      "next_token_ids",
      "extra_inputs",
      "dist_ctx"
    ]
  },
  "SchedulerSequenceARSpec": {
    "__post_init__": [
      "self"
    ],
    "num_valid_ids": [
      "self"
    ],
    "num_spec_ids": [
      "self"
    ],
    "generated_ids": [
      "self"
    ],
    "set_stop_pos": [
      "self",
      "pos"
    ],
    "_update_token_ids_inputs": [
      "self",
      "token_ids"
    ],
    "_update_token_ids_prefill": [
      "self",
      "token_ids",
      "draft_token_ids"
    ],
    "_update_token_ids_decode": [
      "self",
      "token_ids",
      "draft_token_ids"
    ],
    "update_token_ids": [
      "self",
      "token_ids",
      "multimodals",
      "embeddings",
      "model_meta",
      "draft_token_ids",
      "mode"
    ]
  },
  "ARSpecSequenceStrategy": {
    "make_sequence": [
      "self",
      "seq_id",
      "session",
      "sampling_param",
      "adapter_name",
      "migration_request",
      "resp_cache",
      "preserve_cache"
    ],
    "update_running": [
      "self",
      "running",
      "batched_outputs",
      "model_inputs",
      "delta"
    ]
  },
  "ARSpecModelInputsStrategy": {
    "__init__": [
      "self",
      "num_spec_tokens"
    ],
    "make_dummy": [
      "self",
      "batch_size",
      "is_decoding",
      "device",
      "dummy_block_id",
      "vocab_size",
      "max_q_seqlen",
      "target_hidden_size",
      "target_dtype"
    ],
    "merge": [
      "self",
      "inputs",
      "other"
    ],
    "update_inputs": [
      "self",
      "inputs",
      "delta"
    ]
  },
  "_gather_all_ids": [
    "pad_id",
    "seqs",
    "sampling_inputs"
  ],
  "_get_num_ignore_eos": [
    "seqs"
  ],
  "ARSamplingStrategy": {
    "__init__": [
      "self",
      "pad_token_id"
    ],
    "make_sampling_inputs": [
      "self",
      "seqs"
    ],
    "on_session_end": [
      "self",
      "session_id"
    ],
    "merge_sampling_delta": [
      "self",
      "sampling_delta",
      "other"
    ],
    "step_sampling_delta": [
      "self",
      "sampling_delta",
      "next_token_ids"
    ],
    "update_sampling_delta": [
      "self",
      "sampling_delta",
      "delta"
    ]
  },
  "ARCudagraphStrategy": {
    "get_max_tokens": [
      "self",
      "batch_size",
      "origin_batch_size",
      "num_tokens"
    ]
  },
  "ARStrategyFactory": {
    "__init__": [
      "self",
      "model_config"
    ],
    "build_cudagraph_strategy": [
      "self"
    ],
    "build_sampling_strategy": [
      "self"
    ],
    "build_model_inputs_strategy": [
      "self"
    ],
    "build_model_agent_strategy": [
      "self"
    ],
    "build_engine_strategy": [
      "self",
      "cache_config",
      "scheduler_config"
    ],
    "build_sequence_strategy": [
      "self"
    ]
  },
  "AREngineStrategy": {
    "__init__": [
      "self",
      "scheduler_config",
      "cache_config"
    ],
    "get_prealloc_size": [
      "self",
      "is_decoding"
    ],
    "get_num_loops": [
      "self",
      "is_decoding"
    ],
    "get_num_decode_tokens": [
      "self"
    ]
  },
  "ARExtraInputs": {},
  "ARExtraOutputs": {},
  "ARStoppingCriteria": {
    "clone": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "update": [
      "self",
      "delta"
    ],
    "step": [
      "self",
      "token_ids",
      "stop_words",
      "inputs",
      "extra_inputs"
    ]
  },
  "ARModelAgentStrategy": {
    "slice_outputs": [
      "self",
      "inputs",
      "seq_length"
    ],
    "slice_extra_inputs": [
      "self",
      "extra_inputs",
      "model_inputs",
      "model_outputs"
    ],
    "step_sampling_inputs": [
      "self",
      "sampling_inputs",
      "next_token_ids"
    ],
    "make_stopping_criteria": [
      "self",
      "seqs"
    ],
    "make_extra_inputs": [
      "self",
      "seqs",
      "model_inputs"
    ],
    "make_extra_outputs": [
      "self",
      "extra_inputs"
    ],
    "update_prefill_for_next_step": [
      "self",
      "model_inputs",
      "extra_inputs",
      "next_token_ids",
      "model_metas",
      "extra_outputs"
    ],
    "update_decoding_for_next_step": [
      "self",
      "model_inputs",
      "next_token_ids",
      "model_metas",
      "extra_inputs"
    ],
    "post_sampling": [
      "self",
      "inputs",
      "logits",
      "next_token_ids",
      "extra_inputs"
    ],
    "broadcast_next_token": [
      "self",
      "next_token_ids",
      "extra_inputs",
      "dist_ctx"
    ]
  },
  "SchedulerSequenceDefault": {
    "update_token_ids": [
      "self",
      "token_ids",
      "multimodals",
      "embeddings",
      "model_meta",
      "mode",
      "routed_experts"
    ],
    "set_step": [
      "self",
      "step"
    ]
  },
  "ARSequenceStrategy": {
    "make_sequence": [
      "self",
      "seq_id",
      "session",
      "sampling_param",
      "adapter_name",
      "migration_request",
      "resp_cache",
      "preserve_cache"
    ],
    "update_running": [
      "self",
      "running",
      "batched_outputs",
      "model_inputs",
      "delta"
    ]
  },
  "merge_model_inputs": [
    "inputs",
    "other"
  ],
  "ARModelInputsStrategy": {
    "make_dummy": [
      "self",
      "batch_size",
      "is_decoding",
      "device",
      "dummy_block_id",
      "vocab_size"
    ],
    "merge": [
      "self",
      "inputs",
      "other"
    ],
    "index_select": [
      "inputs",
      "indices",
      "indice_cpu",
      "block_offsets",
      "max_q_seqlen",
      "max_kv_seqlen",
      "sum_kv_seqlen",
      "num_ignored_history"
    ],
    "update_inputs": [
      "self",
      "inputs",
      "delta"
    ]
  },
  "SamplingStrategy": {
    "make_sampling_inputs": [
      "self",
      "seqs"
    ],
    "on_session_end": [
      "self",
      "session_id"
    ],
    "merge_sampling_delta": [
      "self",
      "sampling_delta",
      "other"
    ],
    "step_sampling_delta": [
      "self",
      "sampling_delta",
      "next_token_ids",
      "extra_inputs"
    ],
    "update_sampling_delta": [
      "self",
      "sampling_delta",
      "delta"
    ]
  },
  "CudagraphStrategy": {
    "get_max_tokens": [
      "self",
      "batch_size",
      "origin_batch_size",
      "num_tokens"
    ]
  },
  "StrategyFactoryBase": {
    "build_cudagraph_strategy": [
      "self"
    ],
    "build_sampling_strategy": [
      "self"
    ],
    "build_model_inputs_strategy": [
      "self"
    ],
    "build_model_agent_strategy": [
      "self"
    ],
    "build_engine_strategy": [
      "self",
      "cache_config",
      "scheduler_config"
    ],
    "build_sequence_strategy": [
      "self"
    ]
  },
  "EngineStrategy": {
    "get_prealloc_size": [
      "self",
      "is_decoding"
    ],
    "get_num_loops": [
      "self",
      "is_decoding"
    ],
    "get_num_decode_tokens": [
      "self"
    ],
    "get_num_required_tokens": [
      "self"
    ]
  },
  "to_device": [
    "self",
    "device",
    "non_blocking"
  ],
  "ExtraInputs": {
    "to_device": [
      "self",
      "device",
      "non_blocking"
    ],
    "broadcast": [
      "self",
      "src",
      "group",
      "async_op"
    ],
    "merge": [
      "self",
      "other"
    ]
  },
  "ExtraOutputs": {
    "to_device": [
      "self",
      "device",
      "non_blocking"
    ],
    "to_cpu": [
      "self"
    ],
    "to_numpy": [
      "self"
    ],
    "to_tensor": [
      "self"
    ]
  },
  "StoppingCriteria": {
    "clone": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "update": [
      "self",
      "delta"
    ],
    "step": [
      "self",
      "token_ids",
      "stop_words",
      "inputs",
      "extra_inputs"
    ],
    "to_device": [
      "self",
      "device",
      "non_blocking"
    ]
  },
  "ModelAgentStrategy": {
    "slice_outputs": [
      "self",
      "inputs",
      "seq_length"
    ],
    "slice_extra_inputs": [
      "self",
      "extra_inputs",
      "model_inputs",
      "model_outputs"
    ],
    "make_stopping_criteria": [
      "self",
      "seqs"
    ],
    "make_extra_inputs": [
      "self",
      "seqs",
      "model_inputs"
    ],
    "update_extra_inputs": [
      "self",
      "extra_inputs",
      "delta"
    ],
    "make_extra_outputs": [
      "self",
      "extra_inputs"
    ],
    "step_sampling_inputs": [
      "self",
      "sampling_inputs",
      "next_token_ids",
      "extra_inputs"
    ],
    "update_prefill_for_next_step": [
      "self",
      "model_inputs",
      "extra_inputs",
      "next_token_ids",
      "model_metas",
      "extra_outputs"
    ],
    "update_decoding_for_next_step": [
      "self",
      "model_inputs",
      "next_token_ids",
      "model_metas",
      "extra_inputs",
      "extra_outputs"
    ],
    "post_sampling": [
      "self",
      "inputs",
      "logits",
      "next_token_ids",
      "extra_inputs"
    ],
    "make_dummy_next_token": [
      "self",
      "inputs",
      "logits",
      "extra_inputs"
    ],
    "broadcast_next_token": [
      "self",
      "next_token_ids",
      "extra_inputs",
      "dist_ctx"
    ]
  },
  "SequenceStrategy": {
    "make_sequence": [
      "self",
      "seq_id",
      "session",
      "sampling_param",
      "adapter_name",
      "migration_request",
      "resp_cache",
      "preserve_cache"
    ],
    "update_running": [
      "self",
      "running",
      "batched_outputs",
      "model_inputs",
      "delta"
    ]
  },
  "make_dummy_inputs": [
    "batch_size",
    "max_q_seqlen",
    "is_decoding",
    "device",
    "dummy_block_id",
    "vocab_size"
  ],
  "ModelInputsStrategy": {
    "make_dummy": [
      "self",
      "batch_size",
      "is_decoding",
      "device",
      "dummy_block_id",
      "vocab_size"
    ],
    "merge": [
      "self",
      "inputs",
      "other"
    ],
    "update_inputs": [
      "self",
      "inputs",
      "delta"
    ]
  },
  "get_ranks_and_scalings": [
    "target_name",
    "cfgs",
    "device"
  ],
  "find_all_target": [
    "model",
    "target_name"
  ],
  "get_layer_index": [
    "key",
    "layers_pattern"
  ],
  "_get_reverse_pack_map": [
    "model"
  ],
  "_get_key_map": [
    "reverse_map"
  ],
  "load_lora_weights": [
    "model",
    "weights",
    "adapter_id"
  ],
  "AdapterManager": {
    "__init__": [
      "self",
      "adapters"
    ],
    "get_adapter_ids": [
      "self",
      "names"
    ],
    "num_adapters": [
      "self"
    ]
  },
  "per_channel_quant": [],
  "matmul_kernel_dynamic_quant": [],
  "per_token_quant_int8": [],
  "rms_norm_dynamic_quant": [],
  "_default_api": [],
  "ParamParser": {
    "__init__": [
      "self",
      "param"
    ],
    "name": [
      "self"
    ],
    "func_arg": [
      "self"
    ],
    "func_input": [
      "self"
    ]
  },
  "FunctionDispatcher": {
    "__init__": [
      "self",
      "func_name"
    ],
    "device_callback": [
      "self",
      "context"
    ],
    "load_func": [
      "self",
      "device"
    ],
    "load_and_call": [
      "self"
    ],
    "make_caller": [
      "self",
      "api",
      "globals"
    ]
  },
  "moe_gating_topk_softmax": [
    "router_logits",
    "topk",
    "moe_metadata"
  ],
  "silu_and_mul": [
    "input_tensor"
  ],
  "dynamic_quant": [
    "x",
    "quant_dtype",
    "quant_granularity"
  ],
  "linear_w8a8": [
    "a",
    "b",
    "rms_scale",
    "linear_scale",
    "out_dtype",
    "quant_dtype",
    "bias"
  ],
  "rms_norm_w8a8": [
    "hidden_states",
    "weight",
    "epsilon",
    "quant_dtype",
    "residual"
  ],
  "fill_kv_cache": [
    "key_states",
    "value_states",
    "key_caches",
    "value_caches",
    "kv_start_indices",
    "k_scales_zeros",
    "v_scales_zeros",
    "quant_bits"
  ],
  "rms_norm": [
    "hidden_states",
    "weight",
    "epsilon",
    "residual",
    "out"
  ],
  "flash_attention_fwd": [
    "query_states",
    "key_states",
    "value_states",
    "attn_output",
    "q_start_loc",
    "q_seqlens",
    "kv_start_loc",
    "kv_seqlens",
    "num_heads",
    "num_kv_heads",
    "max_q_seqlen",
    "window_size",
    "sm_scale",
    "logit_softcapping",
    "causal"
  ],
  "linear": [
    "x",
    "weight",
    "bias",
    "all_reduce",
    "group"
  ],
  "awq_linear": [
    "x",
    "qweight",
    "scales",
    "qzeros",
    "bias",
    "all_reduce",
    "group_size"
  ],
  "apply_rotary_pos_emb": [
    "query_states",
    "key_states",
    "cos",
    "sin",
    "q_embed",
    "k_embed"
  ],
  "fused_rotary_emb": [
    "query_states",
    "key_states",
    "position_ids",
    "inv_freq",
    "scaling_factor",
    "out_q",
    "out_k",
    "context"
  ],
  "prefill_attention": [
    "query_states",
    "key_states",
    "value_states",
    "attn_output",
    "key_cache",
    "value_cache",
    "block_offsets",
    "q_start_loc",
    "q_seq_len",
    "kv_seq_len",
    "cu_seq_lens_kv",
    "max_q_seq_len",
    "max_kv_seq_len",
    "block_size",
    "num_q_heads",
    "num_kv_heads",
    "head_size_v",
    "attn_mask",
    "softmax_scale",
    "is_unpaged_prefill",
    "kv_scales",
    "kv_zeros",
    "quant_bits"
  ],
  "paged_token_attention": [
    "q",
    "k_cache",
    "v_cache",
    "attn_output",
    "kv_seq_len",
    "max_kv_seq_len",
    "block_offsets",
    "block_size",
    "num_q_heads",
    "num_kv_heads",
    "head_size_v",
    "softmax_scale",
    "kv_scales",
    "kv_zeros",
    "quant_bits"
  ],
  "paged_attention_fwd": [
    "query_states",
    "key_states",
    "value_states",
    "attn_output",
    "key_cache",
    "value_cache",
    "block_offsets",
    "q_start_loc",
    "q_seqlens",
    "kv_seqlens",
    "cu_seq_lens_kv",
    "max_q_seq_len",
    "max_kv_seq_len",
    "is_decoding",
    "block_size",
    "num_heads",
    "num_kv_heads",
    "v_head_size",
    "attn_mask",
    "softmax_scale",
    "is_unpaged_prefill",
    "kv_scales",
    "kv_zeros",
    "quant_bits"
  ],
  "fused_moe": [
    "hidden_states",
    "gate_up_weights",
    "down_weights",
    "topk_weights",
    "topk_ids",
    "topk",
    "renormalize",
    "moe_metadata"
  ],
  "multinomial_sampling": [
    "scores",
    "seeds",
    "offsets",
    "indices"
  ],
  "_indicator": [
    "n_dims",
    "j"
  ],
  "_flip_along_middle": [
    "x",
    "n_dims",
    "i"
  ],
  "_compare_and_swap": [
    "x",
    "ids",
    "flip",
    "i"
  ],
  "_bitonic_merge_hypercube": [
    "x",
    "ids",
    "stage",
    "order"
  ],
  "_bitonic_merge": [
    "x",
    "ids",
    "stage",
    "order",
    "n_dims"
  ],
  "argsort": [
    "x",
    "ids",
    "dim",
    "descending"
  ],
  "_bitonic_topk_kernel0": [
    "score_ptr",
    "seqlen_ptr",
    "out_ptr",
    "ids_ptr",
    "stride_m",
    "K",
    "fill",
    "descending",
    "sorted"
  ],
  "_concate": [
    "a",
    "b"
  ],
  "_split": [
    "a",
    "k"
  ],
  "_bitonic_topk_kernel1": [
    "score_ptr",
    "ids_ptr",
    "seqlen_ptr",
    "out_ptr",
    "stride_m",
    "K",
    "fill",
    "threshold",
    "descending"
  ],
  "bitonic_topk": [
    "scores",
    "q_seqlens",
    "kv_seqlens",
    "k",
    "fill",
    "descending",
    "sorted",
    "threshold"
  ],
  "get_cuda_autotune_config": [],
  "fused_moe_blocked_f8_kernel": [
    "A",
    "A_scale",
    "B",
    "B_scale",
    "bias",
    "C",
    "SortedIdx",
    "ExpStart",
    "ExpEnd",
    "N",
    "K",
    "group_ak",
    "group_bk",
    "group_bn",
    "stride_am",
    "stride_ak",
    "stride_asm",
    "stride_ask",
    "stride_be",
    "stride_bn",
    "stride_bk",
    "stride_bse",
    "stride_bsk",
    "stride_bsn",
    "stride_bie",
    "stride_bin",
    "stride_cm",
    "stride_cn",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "M_NP2",
    "top_k",
    "expert_offset",
    "reindex_a",
    "reindex_c"
  ],
  "fused_moe_blocked_fp8_kernel_launcher": [
    "A",
    "A_scale",
    "B",
    "B_scale",
    "C",
    "sorted_idx",
    "exp_start",
    "exp_end",
    "bias",
    "top_k",
    "num_tokens",
    "expert_offset",
    "reindex_a",
    "reindex_c"
  ],
  "fused_moe_blocked_fp8": [
    "input",
    "input_scale",
    "w1",
    "w1_scale",
    "w2",
    "w2_scale",
    "topk_weights",
    "topk_ids",
    "topk",
    "w1_bias",
    "w2_bias",
    "out_dtype",
    "expert_offset",
    "num_experts",
    "renormalize",
    "act_func"
  ],
  "fast_log2_ceil": [
    "x"
  ],
  "fast_pow2": [
    "x"
  ],
  "fast_round_scale": [
    "amax",
    "fp8_max_inv"
  ],
  "_quant_fp8_kernel": [
    "a_ptr",
    "out_ptr",
    "scale_ptr",
    "M",
    "M_out",
    "K",
    "num_groups_per_cta",
    "fp8_min",
    "fp8_max",
    "stride_am",
    "stride_ak",
    "stride_om",
    "stride_ok",
    "stride_sm",
    "stride_sg",
    "ROUND_SCALE",
    "GROUP_SIZE",
    "NUM_STAGES"
  ],
  "_quant_fp8_launcher": [
    "A",
    "group_size",
    "out",
    "scales",
    "scale_fmt"
  ],
  "quant_fp8": [
    "A",
    "group_size",
    "dtype",
    "trans_scale",
    "scale_fmt"
  ],
  "quant_fp8_tma": [
    "A",
    "group_size",
    "dtype",
    "scale_fmt"
  ],
  "_gemm_fp8_tma_pre_hook": [
    "nargs"
  ],
  "_gemm_fp8_tma_kernel": [
    "desc_a",
    "a_scale_ptr",
    "desc_b",
    "b_scale_ptr",
    "C",
    "M",
    "N",
    "K",
    "group_ak",
    "group_bk",
    "group_bn",
    "stride_asm",
    "stride_ask",
    "stride_bsk",
    "stride_bsn",
    "stride_cm",
    "stride_cn",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "GROUP_M"
  ],
  "_gemm_fp8_kernel": [
    "A",
    "a_scale_ptr",
    "B",
    "b_scale_ptr",
    "C",
    "M",
    "N",
    "K",
    "group_ak",
    "group_bk",
    "group_bn",
    "stride_am",
    "stride_ak",
    "stride_asm",
    "stride_ask",
    "stride_bk",
    "stride_bn",
    "stride_bsk",
    "stride_bsn",
    "stride_cm",
    "stride_cn",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "GROUP_M"
  ],
  "blocked_gemm_fp8": [
    "A",
    "A_scale",
    "B",
    "B_scale",
    "out_dtype"
  ],
  "deep_gemm_fp8": [
    "A",
    "A_scale",
    "B",
    "B_scale",
    "out_dtype"
  ],
  "WARPS_PER_SM": [],
  "BLOCKS_PER_SM": [],
  "TRITON_VERSION": [],
  "get_device_props": [
    "device"
  ],
  "is_cuda": [],
  "supports_tma": [],
  "_silu_and_mul_kernel": [
    "gateup_ptr",
    "out_ptr",
    "N",
    "M",
    "stride_gum",
    "stride_gun",
    "stride_om",
    "stride_on",
    "BLOCK_SIZE_N"
  ],
  "_silu_and_mul_moe_ep_kernel": [
    "gateup_ptr",
    "out_ptr",
    "mask_ptr",
    "N",
    "M",
    "stride_gue",
    "stride_gum",
    "stride_gun",
    "stride_oe",
    "stride_om",
    "stride_on",
    "stride_m",
    "BLOCK_SIZE_N"
  ],
  "silu_and_mul_moe_ep": [
    "gate_up",
    "mask_m",
    "out"
  ],
  "_fp8_index_kernel": [
    "q_ptr",
    "q_s_ptr",
    "k_cache_ptr",
    "k_s_cache_ptr",
    "cu_seqlen_q_ptr",
    "k_seqlen_ptr",
    "block_offset_ptr",
    "out_ptr",
    "stride_qm",
    "stride_qh",
    "stride_qd",
    "stride_qsm",
    "stride_qsh",
    "stride_kb",
    "stride_kn",
    "stride_kd",
    "stride_ksb",
    "stride_ksn",
    "stride_boff0",
    "stride_boff1",
    "stride_om",
    "stride_on",
    "max_q_seqlen",
    "causal",
    "BLOCK_H",
    "BLOCK_N",
    "BLOCK_D",
    "NUM_SPLIT"
  ],
  "fp8_index": [
    "q",
    "q_s",
    "k_cache",
    "k_s_cache",
    "cu_seqlen_q",
    "k_seqlens",
    "block_offset",
    "max_q_seqlen",
    "max_k_seqlen",
    "causal"
  ],
  "_flatten_kv_cache": [
    "kc_ptr",
    "vc_ptr",
    "ko_ptr",
    "vo_ptr",
    "start_loc_ptr",
    "seqlens_ptr",
    "block_offsets_ptr",
    "stride_kcb",
    "stride_kcs",
    "stride_kch",
    "stride_kcd",
    "stride_vcb",
    "stride_vcs",
    "stride_vch",
    "stride_vcd",
    "stride_koh",
    "stride_kos",
    "stride_kod",
    "stride_voh",
    "stride_vos",
    "stride_vod",
    "stride_boff",
    "OUT_SIZE",
    "HEAD_DIM_K",
    "HEAD_DIM_V",
    "BLOCK_BS",
    "BLOCK_DK",
    "BLOCK_DV"
  ],
  "_dequant_int4": [
    "val",
    "HEAD_DIM",
    "BLOCK"
  ],
  "_flatten_kv_cache_quant": [
    "kc_ptr",
    "vc_ptr",
    "ko_ptr",
    "vo_ptr",
    "ksz_ptr",
    "vsz_ptr",
    "start_loc_ptr",
    "seqlens_ptr",
    "block_offsets_ptr",
    "stride_kcb",
    "stride_kcs",
    "stride_kch",
    "stride_kcd",
    "stride_vcb",
    "stride_vcs",
    "stride_vch",
    "stride_vcd",
    "stride_kszb",
    "stride_kszs",
    "stride_kszh",
    "stride_kszd",
    "stride_vszb",
    "stride_vszs",
    "stride_vszh",
    "stride_vszd",
    "stride_koh",
    "stride_kos",
    "stride_kod",
    "stride_voh",
    "stride_vos",
    "stride_vod",
    "stride_boff",
    "quant_policy",
    "OUT_SIZE",
    "HEAD_DIM_K",
    "HEAD_DIM_V",
    "BLOCK_BS",
    "BLOCK_DK",
    "BLOCK_DV"
  ],
  "flatten_kv_cache": [
    "k_caches",
    "v_caches",
    "seqlens",
    "block_offsets",
    "start_loc",
    "out_size",
    "out_dtype",
    "k_scales_zeros",
    "v_scales_zeros",
    "quant_policy",
    "kv_layout",
    "flatten_kv_layout"
  ],
  "dequant_fp8": [
    "x",
    "scale",
    "GROUP_SIZE"
  ],
  "flatten_kv_cache_mla_fp8_kernel": [
    "kc_nope_ptr",
    "kc_scale_ptr",
    "kc_pe_ptr",
    "ko_ptr",
    "start_loc_ptr",
    "seqlens_ptr",
    "block_offsets_ptr",
    "stride_kcb",
    "stride_kcs",
    "stride_kch",
    "stride_kcd",
    "stride_kcsb",
    "stride_kcss",
    "stride_kcsh",
    "stride_kcsd",
    "stride_kcpb",
    "stride_kcps",
    "stride_kcph",
    "stride_kcpd",
    "stride_koh",
    "stride_kos",
    "stride_kod",
    "stride_boff",
    "OUT_SIZE",
    "BLOCK_BS",
    "BLOCK_NOPE",
    "BLOCK_PE",
    "GROUP_SIZE"
  ],
  "flatten_kv_cache_mla_fp8": [
    "k_caches",
    "seqlens",
    "block_offsets",
    "start_loc",
    "out_size",
    "out_dtype",
    "flatten_kv_layout"
  ],
  "_quant_int8": [
    "val"
  ],
  "_quant_int4": [
    "val1",
    "val2"
  ],
  "_fill_kv_cache_kernel": [
    "KStates",
    "VStates",
    "KCaches",
    "VCaches",
    "QStartLoc",
    "QSeqLens",
    "KVSeqLens",
    "BlockOffsets",
    "is_decoding",
    "head_dim",
    "head_dim_v",
    "stride_kss",
    "stride_ksh",
    "stride_ksd",
    "stride_vss",
    "stride_vsh",
    "stride_vsd",
    "stride_kcn",
    "stride_kcb",
    "stride_kch",
    "stride_kcd",
    "stride_vcn",
    "stride_vcb",
    "stride_vch",
    "stride_vcd",
    "stride_boff",
    "BLOCK",
    "BLOCK_D",
    "BLOCK_DV"
  ],
  "_fill_page_quant_int8": [
    "state_ptr",
    "cache_ptr",
    "scales_zeros_ptr",
    "block_off",
    "head_id",
    "page_offs",
    "q_offs",
    "kv_mask",
    "head_dim",
    "stride_ss",
    "stride_sh",
    "stride_sd",
    "stride_cn",
    "stride_cb",
    "stride_ch",
    "stride_cd",
    "stride_szn",
    "stride_szb",
    "stride_szh",
    "stride_szd",
    "BLOCK_D"
  ],
  "_fill_page_quant_int4": [
    "state_ptr",
    "cache_ptr",
    "scales_zeros_ptr",
    "block_off",
    "head_id",
    "page_offs",
    "q_offs",
    "kv_mask",
    "head_dim",
    "stride_ss",
    "stride_sh",
    "stride_sd",
    "stride_cn",
    "stride_cb",
    "stride_ch",
    "stride_cd",
    "stride_szn",
    "stride_szb",
    "stride_szh",
    "stride_szd",
    "BLOCK_D"
  ],
  "_fill_page_quant": [
    "state_ptr",
    "cache_ptr",
    "scales_zeros_ptr",
    "block_off",
    "head_id",
    "page_offs",
    "q_offs",
    "kv_mask",
    "head_dim",
    "stride_ss",
    "stride_sh",
    "stride_sd",
    "stride_cn",
    "stride_cb",
    "stride_ch",
    "stride_cd",
    "stride_szn",
    "stride_szb",
    "stride_szh",
    "stride_szd",
    "BLOCK_D",
    "quant_policy"
  ],
  "_fill_kv_cache_quant_kernel": [
    "KStates",
    "VStates",
    "KCaches",
    "VCaches",
    "KScalesZeros",
    "VScalesZeros",
    "QStartLoc",
    "QSeqLens",
    "KVSeqLens",
    "BlockOffsets",
    "is_decoding",
    "head_dim",
    "head_dim_v",
    "stride_kss",
    "stride_ksh",
    "stride_ksd",
    "stride_vss",
    "stride_vsh",
    "stride_vsd",
    "stride_kcn",
    "stride_kcb",
    "stride_kch",
    "stride_kcd",
    "stride_vcn",
    "stride_vcb",
    "stride_vch",
    "stride_vcd",
    "stride_kszn",
    "stride_kszb",
    "stride_kszh",
    "stride_kszd",
    "stride_vszn",
    "stride_vszb",
    "stride_vszh",
    "stride_vszd",
    "quant_policy",
    "stride_boff",
    "BLOCK",
    "BLOCK_D",
    "BLOCK_DV"
  ],
  "_quant_blocked_fp8": [
    "x",
    "fp8_min",
    "fp8_max",
    "dtype",
    "GROUP_SIZE",
    "ROUND_SCALE"
  ],
  "_fill_kv_cache_blocked_fp8_kernel": [
    "KStates",
    "VStates",
    "KCaches",
    "VCaches",
    "KSCaches",
    "VSCaches",
    "cu_seqlen_q_ptr",
    "KVSeqLens",
    "BlockOffsets",
    "fp8_min",
    "fp8_max",
    "is_decoding",
    "head_dim",
    "head_dim_v",
    "stride_kss",
    "stride_ksh",
    "stride_ksd",
    "stride_vss",
    "stride_vsh",
    "stride_vsd",
    "stride_kcn",
    "stride_kcb",
    "stride_kch",
    "stride_kcd",
    "stride_vcn",
    "stride_vcb",
    "stride_vch",
    "stride_vcd",
    "stride_kscn",
    "stride_kscb",
    "stride_ksch",
    "stride_kscd",
    "stride_vscn",
    "stride_vscb",
    "stride_vsch",
    "stride_vscd",
    "stride_boff",
    "ROUND_SCALE",
    "GROUP_SIZE",
    "BLOCK",
    "BLOCK_D",
    "BLOCK_DV"
  ],
  "fill_kv_cache_blocked_fp8": [
    "k_states",
    "v_states",
    "k_caches",
    "v_caches",
    "ks_caches",
    "vs_caches",
    "cu_seqlen_q",
    "kv_seqlens",
    "max_q_seqlen",
    "block_offsets",
    "group_size",
    "kv_layout",
    "scale_fmt"
  ],
  "_noaux_routing_kernel": [
    "logits_ptr",
    "bias_ptr",
    "scores_ptr",
    "tmp_scores_ptr",
    "batch_size",
    "num_experts",
    "n_group",
    "group_size",
    "topk_group",
    "renormalize",
    "routed_scaling_factor",
    "logits_stride_0",
    "logits_stride_1",
    "bias_stride_0",
    "scores_stride_0",
    "scores_stride_1",
    "tmp_scores_stride_0",
    "tmp_scores_stride_1",
    "BLOCK_SIZE"
  ],
  "fused_noaux_tc_routing": [
    "logits",
    "bias",
    "num_experts",
    "n_group",
    "topk_group",
    "top_k",
    "renormalize",
    "routed_scaling_factor"
  ],
  "_compute_rms_norm": [
    "x",
    "w",
    "eps",
    "N_COLS"
  ],
  "add_rms_norm_kernel": [
    "input",
    "weight",
    "residual",
    "output",
    "out_residual",
    "num_feats",
    "num_groups",
    "stride_ib",
    "stride_ih",
    "stride_id",
    "stride_rb",
    "stride_rh",
    "stride_rd",
    "stride_ob",
    "stride_oh",
    "stride_od",
    "stride_rob",
    "stride_roh",
    "stride_rod",
    "has_residual",
    "eps",
    "N_COLS",
    "BLOCK_N",
    "NUM_STAGES"
  ],
  "_unsqueeze_to_3d": [
    "tensor"
  ],
  "_squeeze_to_origin_dim": [
    "tensor",
    "origin_dim"
  ],
  "_multinomial_sampling_kernel": [
    "Scores",
    "Seeds",
    "Offsets",
    "Indices",
    "Outputs",
    "stride_sb",
    "stride_st",
    "stride_ib",
    "stride_it",
    "num_tokens",
    "BLOCK_N"
  ],
  "_linear": [
    "A",
    "B",
    "C",
    "M",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "GROUP_SIZE_M",
    "rms_scale_ptr",
    "linear_scale_ptr",
    "ACCUMULATOR_DTYPE"
  ],
  "_linear_add": [
    "A",
    "B",
    "C",
    "residual_ptr",
    "M",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "GROUP_SIZE_M",
    "rms_scale_ptr",
    "linear_scale_ptr",
    "ACCUMULATOR_DTYPE"
  ],
  "_per_token_quant_int8": [
    "y_ptr",
    "y_q_ptr",
    "y_s_ptr",
    "y_stride",
    "yq_stride",
    "N",
    "eps",
    "BLOCK",
    "Q_MAX",
    "IS_FLOATING_POINT"
  ],
  "rms_norm_quant_kernel": [
    "input",
    "weight",
    "output",
    "out_scale",
    "input_row_stride",
    "eps",
    "N_COLS",
    "BLOCK_N",
    "Q_MIN",
    "Q_MAX",
    "IS_FLOATING_POINT"
  ],
  "add_rms_norm_quant_kernel": [
    "input",
    "weight",
    "residual",
    "output",
    "out_scale",
    "out_residual",
    "input_row_stride",
    "residual_row_stride",
    "eps",
    "N_COLS",
    "BLOCK_N",
    "Q_MIN",
    "Q_MAX",
    "IS_FLOATING_POINT"
  ],
  "test_rms_and_linear": [
    "x",
    "rms_weight",
    "linear_weight",
    "output_dtype",
    "quant_dtype",
    "eps"
  ],
  "test_per_token_quant": [
    "x",
    "eps",
    "quant_dtype"
  ],
  "bench_rms_and_linear": [
    "M",
    "provider",
    "dtype",
    "eps"
  ],
  "fused_moe_w8a8_kernel": [
    "A",
    "A_scale",
    "B",
    "B_scale",
    "C",
    "SortedIdx",
    "ExpStart",
    "ExpEnd",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_be",
    "stride_bn",
    "stride_bk",
    "stride_bse",
    "stride_cm",
    "stride_cn",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "M_NP2",
    "top_k",
    "expert_offset",
    "reindex_a",
    "reindex_c",
    "ACCUMULATOR_DTYPE"
  ],
  "fused_moe_w8a8_kernel_launcher": [
    "A",
    "A_scale",
    "B",
    "B_scale",
    "C",
    "sorted_idx",
    "exp_start",
    "exp_end",
    "top_k",
    "num_tokens",
    "expert_offset",
    "reindex_a",
    "reindex_c"
  ],
  "fused_moe_w8a8": [
    "input",
    "input_scale",
    "w1",
    "w1_scale",
    "w2",
    "w2_scale",
    "topk_weights",
    "topk_ids",
    "topk",
    "out_dtype",
    "quant_dtype",
    "expert_offset",
    "num_experts",
    "renormalize"
  ],
  "get_autotune_config": [],
  "_atomic_store": [
    "ptrs",
    "val",
    "mask"
  ],
  "_fused_lora_kernel": [
    "a_ptr",
    "lora_a_ptr",
    "lora_b_ptr",
    "c_ptr",
    "scaling_ptr",
    "rank_start_ptr",
    "ranks_ptr",
    "seq_start_ptr",
    "seq_lens_ptr",
    "adapter_ids_ptr",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_lar",
    "stride_lak",
    "stride_lbr",
    "stride_lbn",
    "stride_cm",
    "stride_cn",
    "BLOCK_SIZE_R",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "CUM"
  ],
  "fused_lora": [
    "input",
    "lora_a",
    "lora_b",
    "scaling",
    "rank_start",
    "ranks",
    "seq_start",
    "seq_lens",
    "adapter_ids",
    "max_rank",
    "max_seqlen",
    "output",
    "cum"
  ],
  "_dequant_s4_to_f16x2": [
    "weight",
    "shift",
    "is_top"
  ],
  "_unpack_weight": [
    "weight"
  ],
  "awq_linear_kernel": [
    "a_ptr",
    "qw_ptr",
    "s_ptr",
    "qz_ptr",
    "c_ptr",
    "M",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_wk",
    "stride_wn",
    "stride_sk",
    "stride_sn",
    "stride_zk",
    "stride_zn",
    "stride_cm",
    "stride_cn",
    "SPLIT_K",
    "NUM_STAGES",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M"
  ],
  "_apply_rotary_impl": [
    "x_l",
    "x_h",
    "cos_l",
    "cos_h",
    "sin_l",
    "sin_h"
  ],
  "apply_rotary_pos_emb_qk_kernel": [
    "Q",
    "K",
    "COS",
    "SIN",
    "Q_EMB",
    "K_EMB",
    "seq_len",
    "stride_qs",
    "stride_qh",
    "stride_qd",
    "stride_ks",
    "stride_kh",
    "stride_kd",
    "stride_qes",
    "stride_qeh",
    "stride_qed",
    "stride_kes",
    "stride_keh",
    "stride_ked",
    "half_size",
    "BLOCK",
    "BLOCK_QH",
    "BLOCK_N"
  ],
  "VERSION_300": [],
  "VERSION_320": [],
  "tanh": [],
  "tl_log2": [],
  "tl_exp2": [],
  "_get_block_d": [
    "head_dim_k",
    "head_dim_v"
  ],
  "softcapping": [
    "qk",
    "logit_softcapping"
  ],
  "_load_kv": [
    "ptrs",
    "boundary_check"
  ],
  "_prefill_fwd_inner": [
    "acc",
    "l_i",
    "m_i",
    "q",
    "k_ptrs",
    "v_ptrs",
    "q1",
    "k1_ptrs",
    "loop_start",
    "loop_end",
    "sm_scale",
    "alibi_slope",
    "global_offs_m",
    "history_mask",
    "kv_min_loc",
    "causal_mask",
    "window_size",
    "logit_softcapping",
    "k_bound",
    "v_bound",
    "shared_kv",
    "block_sparse_size",
    "BLOCK_N",
    "BLOCK_DK1"
  ],
  "_flash_prefill_fwd_kernel": [
    "q_ptr",
    "k_ptr",
    "v_ptr",
    "o_ptr",
    "cu_seqlens_q_ptr",
    "cu_seqlens_k_ptr",
    "q_start_loc_ptr",
    "q_seqlens_ptr",
    "kv_start_loc_ptr",
    "kv_seqlens_ptr",
    "sinks",
    "alibi_slopes_ptr",
    "sm_scale",
    "stride_qs",
    "stride_qh",
    "stride_qd",
    "stride_ks",
    "stride_kh",
    "stride_kd",
    "stride_vs",
    "stride_vh",
    "stride_vd",
    "stride_os",
    "stride_oh",
    "stride_od",
    "kv_group_num",
    "head_dim_k",
    "head_dim_v",
    "causal",
    "window_size",
    "logit_softcapping",
    "shared_kv",
    "block_sparse_size",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_DK",
    "BLOCK_DK1",
    "BLOCK_DV"
  ],
  "_nv_cap": [],
  "_kernel_meta_sm7x": [
    "BLOCK_DK"
  ],
  "_kernel_meta_sm8x": [
    "BLOCK_DK",
    "shared_kv"
  ],
  "_kernel_meta_sm86": [
    "BLOCK_DK",
    "shared_kv"
  ],
  "_kernel_meta_sm9x": [
    "BLOCK_DK",
    "shared_kv"
  ],
  "_kernel_meta_sm12x": [
    "BLOCK_DK",
    "shared_kv"
  ],
  "_kernel_meta_rocm": [
    "BLOCK_DK",
    "shared_kv"
  ],
  "flash_attn_varlen_func": [
    "q",
    "k",
    "v",
    "cu_seqlens_q",
    "cu_seqlens_k",
    "max_seqlen_q",
    "max_seqlen_k",
    "softmax_scale",
    "causal",
    "window_size",
    "softcap",
    "q_start_loc",
    "q_seqlens",
    "kv_start_loc",
    "kv_seqlens",
    "alibi_slopes",
    "sinks",
    "block_sparse_size",
    "kv_layout"
  ],
  "_fwd_kernel_ep_scatter_step1": [
    "num_recv_tokens_per_expert",
    "expert_start_loc",
    "m_indices",
    "num_experts",
    "BLOCK_E",
    "BLOCK_EXPERT_NUM"
  ],
  "_fwd_kernel_ep_scatter_step2": [
    "total_token_num",
    "expert_start_loc",
    "recv_x",
    "recv_x_stride0",
    "recv_x_stride1",
    "recv_topk",
    "recv_topk_stride0",
    "recv_topk_stride1",
    "output_tensor",
    "output_tensor_stride0",
    "output_tensor_stride1",
    "output_index",
    "output_index_stride0",
    "output_index_stride1",
    "topk_num",
    "HIDDEN_SIZE",
    "HIDDEN_SIZE_PAD"
  ],
  "ep_scatter": [
    "recv_x",
    "recv_topk",
    "num_recv_tokens_per_expert",
    "expert_start_loc",
    "output_tensor",
    "m_indices",
    "output_index"
  ],
  "_fwd_kernel_ep_gather": [
    "total_token_num",
    "input_tensor",
    "input_tensor_stride0",
    "input_tensor_stride1",
    "recv_topk_ids",
    "recv_topk_ids_stride0",
    "recv_topk_ids_stride1",
    "recv_topk_weight",
    "recv_topk_weight_stride0",
    "recv_topk_weight_stride1",
    "input_index",
    "input_index_stride0",
    "input_index_stride1",
    "output_tensor",
    "output_tensor_stride0",
    "output_tensor_stride1",
    "topk_num",
    "BLOCK_D"
  ],
  "ep_gather": [
    "input_tensor",
    "recv_topk_ids",
    "recv_topk_weight",
    "input_index",
    "output_tensor"
  ],
  "_deepgemm_grouped_bf16_nt_contiguous": [
    "x",
    "w",
    "out",
    "m_indices"
  ],
  "fused_moe_v3": [
    "hidden_states",
    "topk_idx",
    "topk_weights",
    "w13_weight",
    "w2_weight",
    "num_recv_tokens_per_expert"
  ],
  "_fwd_grouped_split_kernel": [
    "q_ptr",
    "k_ptr",
    "v_ptr",
    "sm_scale",
    "cache_seqlens_ptr",
    "page_table_ptr",
    "acc_out_ptr",
    "alibi_slopes_ptr",
    "stride_qbs",
    "stride_qh",
    "stride_qd",
    "stride_kp",
    "stride_kbs",
    "stride_kh",
    "stride_kd",
    "stride_vp",
    "stride_vbs",
    "stride_vh",
    "stride_vd",
    "stride_ok",
    "stride_obs",
    "stride_oh",
    "stride_od",
    "stride_boffb",
    "kv_group_num",
    "seq_len",
    "window_size",
    "head_size",
    "head_size_v",
    "num_heads_q",
    "logit_softcapping",
    "shared_kv",
    "SPLIT_K",
    "BLOCK_DMODEL",
    "BLOCK_DV",
    "BLOCK_N",
    "BLOCK_H",
    "BLOCK_DMODEL1"
  ],
  "_fwd_grouped_split_quant_kernel": [
    "q_ptr",
    "k_ptr",
    "v_ptr",
    "KScalesZeros",
    "VScalesZeros",
    "sm_scale",
    "cache_seqlens_ptr",
    "page_table_ptr",
    "acc_out_ptr",
    "alibi_slopes_ptr",
    "stride_qbs",
    "stride_qh",
    "stride_qd",
    "stride_kp",
    "stride_kbs",
    "stride_kh",
    "stride_kd",
    "stride_vp",
    "stride_vbs",
    "stride_vh",
    "stride_vd",
    "stride_kszp",
    "stride_kszbs",
    "stride_kszh",
    "stride_kszd",
    "stride_vszp",
    "stride_vszbs",
    "stride_vszh",
    "stride_vszd",
    "quant_policy",
    "stride_ok",
    "stride_obs",
    "stride_oh",
    "stride_od",
    "stride_boffb",
    "kv_group_num",
    "window_size",
    "head_size",
    "head_size_v",
    "num_heads_q",
    "logit_softcapping",
    "SPLIT_K",
    "BLOCK_DMODEL",
    "BLOCK_DV",
    "BLOCK_N",
    "BLOCK_H",
    "BLOCK_DMODEL1"
  ],
  "_reduce_split_kernel": [
    "acc_ptr",
    "out_ptr",
    "sinks_ptr",
    "stride_ak",
    "stride_abs",
    "stride_ah",
    "stride_ad",
    "stride_obs",
    "stride_oh",
    "stride_od",
    "head_size_v",
    "SPLIT_K",
    "BLOCK_DV"
  ],
  "_convert_pv": [
    "p",
    "v"
  ],
  "_kernel_meta_default": [
    "BLOCK_DMODEL",
    "BLOCK_H"
  ],
  "_get_split_k": [
    "device_idx",
    "head_grid",
    "batch_size",
    "num_warps"
  ],
  "flash_attn_with_kvcache": [
    "q",
    "k_cache",
    "v_cache",
    "cache_seqlens",
    "page_table",
    "cu_seqlens_q",
    "max_seqlen_q",
    "softmax_scale",
    "causal",
    "window_size",
    "softcap",
    "scheduler_metadata",
    "alibi_slopes",
    "k_scales_zeros",
    "v_scales_zeros",
    "quant_policy",
    "sinks",
    "kv_layout"
  ],
  "_config_prune_func": [
    "config"
  ],
  "fused_moe_kernel": [
    "A",
    "B",
    "bias",
    "C",
    "SortedIdx",
    "ExpStart",
    "ExpEnd",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_be",
    "stride_bn",
    "stride_bk",
    "stride_cm",
    "stride_cn",
    "stride_bie",
    "stride_bin",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "M_NP2",
    "tune_hint",
    "top_k",
    "expert_offset",
    "reindex_a",
    "reindex_c"
  ],
  "fused_moe_kernel_launcher": [
    "A",
    "B",
    "C",
    "sorted_idx",
    "exp_start",
    "exp_end",
    "bias",
    "top_k",
    "num_tokens",
    "expert_offset",
    "reindex_a",
    "reindex_c"
  ],
  "_get_exp_mask_kernel": [
    "a_ptr",
    "o_mask_ptr",
    "o_k_ptr",
    "stride_a_token",
    "stride_a_exp",
    "stride_o_exp",
    "stride_o_token",
    "topk",
    "num_experts",
    "BLOCK_NA",
    "BLOCK_NO"
  ],
  "_get_exp_mask": [
    "topk_ids",
    "num_experts"
  ],
  "_get_start_end_kernel": [
    "exp_cum_ptr",
    "exp_topk_ptr",
    "exp_out_ptr",
    "start_ptr",
    "end_ptr",
    "stride_cum_exp",
    "stride_cum_token",
    "stride_out",
    "num_tokens",
    "num_experts",
    "topk",
    "BLOCK_N"
  ],
  "get_start_end": [
    "exp_cum",
    "exp_topk",
    "topk"
  ],
  "_get_sorted_idx": [
    "topk_ids",
    "num_experts"
  ],
  "_renormalize": [
    "topk_weights",
    "renormalize"
  ],
  "_make_intermediate": [
    "shape",
    "dtype",
    "device",
    "zeros"
  ],
  "_moe_reduce_kernel": [
    "hidden_states_ptr",
    "weights_ptr",
    "out_ptr",
    "stride_hm",
    "stride_hk",
    "stride_hn",
    "stride_wm",
    "stride_wk",
    "stride_om",
    "stride_on",
    "fp32_acc",
    "K",
    "N",
    "BLOCK_K",
    "BLOCK_N"
  ],
  "moe_reduce": [
    "hidden_states",
    "topk_weights",
    "fp32_acc"
  ],
  "register_config": [
    "model_type"
  ],
  "config_from_pretrained": [
    "pretrained_model_name_or_path"
  ],
  "DeepseekV32Config": {
    "model_type": [],
    "__init__": [
      "self",
      "index_head_dim",
      "index_n_heads",
      "index_topk"
    ]
  },
  "DeviceContext": {},
  "DeviceManager": {
    "__init__": [
      "self"
    ],
    "register_context_callback": [
      "self",
      "callback"
    ],
    "unregister_context_callback": [
      "self",
      "handle"
    ]
  },
  "get_device_manager": [],
  "MapType": [],
  "SchedulerOutput": {},
  "Scheduler": {
    "__init__": [
      "self",
      "scheduler_config",
      "cache_config",
      "seq_meta"
    ],
    "create_status_list_property": [
      "status"
    ],
    "create_num_status_method": [
      "status"
    ],
    "create_has_status_method": [
      "status"
    ],
    "waiting": [],
    "ready": [],
    "hanging": [],
    "running": [],
    "migration_waiting": [],
    "migration_done": [],
    "num_waiting": [],
    "num_ready": [],
    "num_running": [],
    "num_migration_waiting": [],
    "num_migration_done": [],
    "has_waiting": [],
    "has_ready": [],
    "has_migration_waiting": [],
    "has_migration_done": [],
    "add_session": [
      "self",
      "session_id"
    ],
    "_schedule_migration": [
      "self"
    ],
    "_schedule_prefill": [
      "self",
      "prealloc_size"
    ],
    "_schedule_decoding": [
      "self",
      "prealloc_size"
    ],
    "schedule": [
      "self",
      "is_prefill",
      "prealloc_size"
    ],
    "schedule_running": [
      "self",
      "running",
      "num_decode_tokens",
      "prealloc_size"
    ],
    "stop_session": [
      "self",
      "session_id"
    ],
    "end_session": [
      "self",
      "session_id"
    ],
    "has_unfinished": [
      "self"
    ],
    "get_block_tables": [
      "self",
      "seqs"
    ],
    "evict_seqs": [
      "self",
      "running"
    ],
    "activate_seqs": [
      "self",
      "running",
      "filter_status"
    ],
    "deactivate_seqs": [
      "self",
      "running",
      "filter_status"
    ],
    "seqs_activation": [
      "self",
      "running"
    ],
    "activate_migration_seqs": [
      "self",
      "running"
    ],
    "deactivate_migration_seqs": [
      "self",
      "running"
    ],
    "seqs_migration_activation": [
      "self",
      "running"
    ],
    "collect_migration_done": [
      "self"
    ],
    "schedule_metrics": [
      "self"
    ]
  },
  "PrefixCacheStats": {
    "reset": [
      "self"
    ],
    "hit_rate": [
      "self"
    ]
  },
  "Node": {
    "__init__": [
      "self",
      "hash_key",
      "block",
      "tokens",
      "num_matched"
    ],
    "parent": [
      "self",
      "val"
    ],
    "__lt__": [
      "self",
      "other"
    ],
    "__le__": [
      "self",
      "other"
    ]
  },
  "BlockTrie": {
    "__init__": [
      "self",
      "cache_config",
      "block_manager"
    ],
    "hit_rate": [
      "self"
    ],
    "get_root": [
      "self",
      "adapter_name"
    ],
    "match": [
      "self",
      "seq"
    ],
    "allocate": [
      "self",
      "seq"
    ],
    "evict": [
      "self",
      "max_num_blocks"
    ]
  },
  "StateAllocator": {
    "__init__": [
      "self",
      "num_states",
      "offset"
    ],
    "allocate": [
      "self"
    ],
    "free": [
      "self",
      "state_id"
    ],
    "get_num_free": [
      "self"
    ]
  },
  "StateManager": {
    "__init__": [
      "self",
      "num_states",
      "num_reserved"
    ],
    "is_allocated": [
      "self",
      "seq"
    ],
    "allocate": [
      "self",
      "seq"
    ],
    "free": [
      "self",
      "seq"
    ],
    "get_num_free": [
      "self"
    ]
  },
  "build_state_manager": [
    "cache_config"
  ],
  "BaseEvictionHelper": {
    "__init__": [
      "self",
      "scheduler"
    ],
    "need_swap_in": [
      "self",
      "seq"
    ],
    "evict_for_seq": [
      "self",
      "seq",
      "evictable_seqs",
      "prealloc_size"
    ]
  },
  "build_eviction_helper": [
    "scheduler",
    "eviction_type"
  ],
  "RecomputeEvictionHelper": {
    "__init__": [
      "self",
      "scheduler"
    ],
    "_evict_for_seq_default": [
      "self",
      "seq",
      "evictable_seqs",
      "prealloc_size"
    ],
    "_evict_for_ssm": [
      "self",
      "seq",
      "evictable_seqs",
      "prealloc_size"
    ]
  },
  "build_block_manager": [
    "cache_config"
  ],
  "BlockTable": [],
  "_num_blocks_to_drop": [
    "seq",
    "window_size"
  ],
  "WindowBlockManager": {
    "__init__": [
      "self",
      "num_gpu_blocks",
      "num_cpu_blocks",
      "window_size",
      "num_gpu_reserved"
    ],
    "num_required_blocks": [
      "self",
      "obj",
      "prealloc_size"
    ],
    "can_allocate": [
      "self",
      "msg",
      "prealloc_size"
    ],
    "allocate_msg": [
      "self",
      "msg",
      "prealloc_size"
    ]
  },
  "DefaultBlockManager": {
    "num_required_blocks": [
      "cls",
      "obj",
      "prealloc_size"
    ],
    "can_allocate": [
      "self",
      "msg",
      "prealloc_size"
    ],
    "allocate_msg": [
      "self",
      "msg",
      "prealloc_size"
    ],
    "free": [
      "self",
      "msg"
    ],
    "try_swap_out": [
      "self",
      "msg"
    ],
    "try_swap_in": [
      "self",
      "msg"
    ]
  },
  "LogicalMemory": {
    "__init__": [
      "self",
      "num_blocks"
    ],
    "get_physical_blocks": [
      "self",
      "logical_address"
    ],
    "num_blocks": [
      "self"
    ]
  },
  "PhysicalAllocator": {
    "__init__": [
      "self",
      "num_blocks",
      "offset"
    ],
    "allocate": [
      "self",
      "num_blocks"
    ],
    "free": [
      "self",
      "blocks"
    ],
    "get_num_free_blocks": [
      "self"
    ]
  },
  "LogicalAllocator": {
    "__init__": [
      "self",
      "num_cpu_blocks",
      "num_gpu_blocks",
      "num_gpu_reserved"
    ],
    "get_phy_allocator": [
      "self",
      "device"
    ],
    "allocate": [
      "self",
      "num_blocks",
      "device"
    ],
    "free": [
      "self",
      "blocks"
    ],
    "get_num_free_blocks": [
      "self"
    ],
    "get_physical_blocks": [
      "self",
      "blocks"
    ],
    "get_ref_count": [
      "self",
      "blocks"
    ],
    "add_ref_count": [
      "self",
      "blocks",
      "value"
    ],
    "get_access_time": [
      "self",
      "blocks"
    ],
    "update_access_time": [
      "self",
      "blocks"
    ],
    "cpu_mem_offset": [
      "self"
    ],
    "count_cpu_blocks": [
      "self",
      "blocks"
    ],
    "count_gpu_blocks": [
      "self",
      "blocks"
    ],
    "update_phy_map": [
      "self",
      "log_blocks",
      "phy_blocks"
    ],
    "on_device": [
      "self",
      "blocks",
      "device"
    ]
  },
  "BaseBlockManager": {
    "__init__": [
      "self",
      "num_gpu_blocks",
      "num_cpu_blocks",
      "num_gpu_reserved"
    ],
    "num_required_blocks": [
      "cls",
      "obj",
      "prealloc_size"
    ],
    "can_allocate": [
      "self",
      "msg",
      "prealloc_size"
    ],
    "allocate_msg": [
      "self",
      "msg",
      "prealloc_size"
    ],
    "free": [
      "self",
      "msg"
    ],
    "try_swap_out": [
      "self",
      "msg"
    ],
    "try_swap_in": [
      "self",
      "msg"
    ],
    "get_block_table": [
      "self",
      "msg"
    ],
    "allocate": [
      "self",
      "data",
      "prealloc_size"
    ],
    "get_num_free_gpu_blocks": [
      "self"
    ],
    "get_num_free_cpu_blocks": [
      "self"
    ],
    "on_device": [
      "self",
      "msg",
      "device"
    ]
  },
  "_free_seq": [
    "seq",
    "scheduler"
  ],
  "StateBase": {
    "status": [],
    "_registry": [],
    "__init_subclass__": [
      "cls"
    ],
    "build": [
      "cls",
      "scheduler",
      "seq",
      "status"
    ],
    "__init__": [
      "self",
      "seq",
      "scheduler"
    ],
    "to_state": [
      "self",
      "new_state"
    ],
    "evict": [
      "self"
    ],
    "activate": [
      "self"
    ],
    "deactivate": [
      "self"
    ],
    "finish": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "free": [
      "self"
    ]
  },
  "WaitingState": {
    "status": [],
    "activate": [
      "self"
    ],
    "evict": [
      "self"
    ]
  },
  "ReadyState": {
    "status": [],
    "activate": [
      "self"
    ],
    "evict": [
      "self"
    ]
  },
  "StoppedState": {
    "status": [],
    "activate": [
      "self"
    ],
    "evict": [
      "self"
    ]
  },
  "RunningState": {
    "status": [],
    "deactivate": [
      "self"
    ],
    "finish": [
      "self"
    ]
  },
  "ToBeMigratedState": {
    "status": [],
    "finish": [
      "self"
    ]
  },
  "MigrationWaitingState": {
    "status": [],
    "activate": [
      "self"
    ],
    "evict": [
      "self"
    ]
  },
  "MigrationReadyState": {
    "status": [],
    "activate": [
      "self"
    ],
    "evict": [
      "self"
    ]
  },
  "MigrationDoneState": {
    "status": [],
    "activate": [
      "self"
    ],
    "finish": [
      "self"
    ]
  },
  "MigrationRunningState": {
    "status": [],
    "deactivate": [
      "self"
    ],
    "finish": [
      "self"
    ]
  },
  "build_seq_state": [
    "scheduler",
    "seq",
    "status"
  ],
  "_check_env_qwen3_next": [
    "device"
  ],
  "Qwen3NextModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path",
      "tp"
    ]
  },
  "GemmaModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "GemmaVLModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "InternVLModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "Qwen3VLModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "DefaultModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "LlavaHfModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "InternVL3ModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "SDARModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "Llama4ModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "flash_mla_available": [],
  "flash_attn_v3_available": [],
  "QwenModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "AutoModelConfigBuilder": {
    "_sub_classes": [],
    "__init_subclass__": [
      "cls"
    ],
    "register_builder": [
      "cls",
      "sub_cls"
    ],
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ],
    "update_num_kv_heads": [
      "cls",
      "hf_config",
      "tp",
      "num_key_value_heads"
    ]
  },
  "DeepseekVLV2ModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "MiniCPM3ModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "LlamaModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path",
      "is_draft_model",
      "spec_method"
    ]
  },
  "_check_env_v32": [
    "device"
  ],
  "DeepseekV2ModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path",
      "is_draft_model",
      "spec_method"
    ]
  },
  "InterS1ProModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "CogVLMModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "GptOSSModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "ChatGLMModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path"
    ]
  },
  "Glm4MoeLiteModelConfigBuilder": {
    "condition": [
      "cls",
      "hf_config"
    ],
    "build": [
      "cls",
      "hf_config",
      "model_path",
      "is_draft_model",
      "spec_method"
    ]
  },
  "RMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps",
      "dtype",
      "device",
      "quant_config",
      "tp",
      "align",
      "prefix"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "create_weight": [
      "hidden_size",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "residual"
    ]
  },
  "LayerNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps",
      "bias",
      "dtype",
      "device"
    ],
    "create_weight": [
      "hidden_size",
      "bias",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "residual"
    ]
  },
  "IndexerTopKFP8": {
    "__init__": [
      "self",
      "topk",
      "softmax_scale",
      "block_size",
      "fill"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "weights",
      "k_cache",
      "k_s_cache",
      "attn_metadata"
    ]
  },
  "DEFAULT_VOCAB_PADDING_SIZE": [],
  "pad_vocab_size": [
    "vocab_size",
    "pad_to"
  ],
  "ParallelEmbedding": {
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "padding_idx",
      "dtype",
      "device",
      "is_tp",
      "padding_size",
      "layer_type"
    ],
    "create_weight": [
      "vocab_size",
      "hidden_size",
      "dtype",
      "device"
    ],
    "_weight_loader_tp_rowwise": [
      "self",
      "param",
      "loaded_weight"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "div_up": [
    "a",
    "b"
  ],
  "get_distribute_size": [
    "feature_size",
    "world_size",
    "rank",
    "align"
  ],
  "chunk_aligned": [
    "weight",
    "chunks",
    "dim",
    "align"
  ],
  "SiluAndMul": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GeluAndMul": {
    "__init__": [
      "self",
      "approximate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_update_num_heads": [
    "num_heads",
    "num_kv_heads"
  ],
  "Attention": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "v_head_size",
      "alibi",
      "sliding_window",
      "logit_softcapping",
      "causal",
      "use_flash_mla",
      "learnable_sink",
      "block_sparse_size"
    ],
    "_lazy_init": [
      "self",
      "device"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "k_scales_zeros",
      "v_scales_zeros",
      "s_aux",
      "nsa_indices",
      "inplace"
    ],
    "update_meta_flashmla": [
      "attn_metadata",
      "num_attention_heads"
    ]
  },
  "FlashAttention": {
    "__init__": [
      "self",
      "num_heads",
      "head_dim",
      "scale",
      "num_kv_heads",
      "v_head_dim",
      "causal",
      "sliding_window",
      "logit_softcapping"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "q_start_loc",
      "q_seqlens",
      "kv_start_loc",
      "kv_seqlens",
      "max_q_seqlen"
    ]
  },
  "EPLBDispatchInfo": {
    "__init__": [
      "self",
      "info"
    ]
  },
  "EPLBManager": {
    "eplb": [],
    "init_global_eplb_metadata": [
      "cls",
      "ep_size",
      "num_routed_experts",
      "num_hidden_layers"
    ],
    "num_physical_experts": [
      "cls"
    ],
    "topk_ids_logical_to_physical": [
      "cls",
      "topk_ids",
      "eplb_dispatch_info"
    ],
    "get_dispatch_info": [
      "cls",
      "ep_rank",
      "layer_idx"
    ]
  },
  "get_rope_parameters": [
    "config"
  ],
  "_get_default_rope_parameters": [
    "config"
  ],
  "_get_linear_scaling_rope_parameters": [
    "config"
  ],
  "_get_dynamic_ntk_parameters": [
    "config"
  ],
  "_get_yarn_parameters": [
    "config"
  ],
  "_get_longrope_parameters": [
    "config"
  ],
  "_get_llama3_parameters": [
    "config"
  ],
  "_get_fope_parameters": [
    "config"
  ],
  "build_rotary_params": [
    "config"
  ],
  "build_rotary_embedding": [
    "dim",
    "max_position_embeddings",
    "base",
    "scaling_factor",
    "yarn_params",
    "longrope_params",
    "llama3_params",
    "fope_params",
    "emb_type",
    "partial_rotary_factor",
    "device"
  ],
  "get_rope_theta": [
    "config",
    "default"
  ],
  "build_rotary_embedding_from_config": [
    "config",
    "device"
  ],
  "ApplyRotaryEmb": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "cos",
      "sin",
      "inplace"
    ]
  },
  "FopeRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "attention_scaling",
      "params",
      "device"
    ],
    "update_num_kv_heads": [
      "num_key_value_heads"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "LinearWeights": {
    "__init__": [
      "self",
      "num_experts",
      "in_features",
      "out_features",
      "weight_type",
      "dtype",
      "device",
      "bias",
      "expert_list"
    ],
    "setup_weight_loader": [
      "self"
    ],
    "update_weight": [
      "self",
      "weight"
    ],
    "weight_loader_tp": [
      "self",
      "param",
      "loaded_weight",
      "expert_id",
      "shard_id"
    ],
    "weight_loader_ep": [
      "self",
      "param",
      "loaded_weight",
      "expert_id",
      "shard_id"
    ]
  },
  "FusedMoE": {
    "__init__": [
      "self",
      "hidden_dim",
      "ffn_dim",
      "num_experts",
      "top_k",
      "bias",
      "renormalize",
      "dtype",
      "device",
      "all_reduce",
      "layer_idx",
      "act_func"
    ],
    "update_weights": [
      "self"
    ],
    "before_dispatch": [
      "self",
      "state"
    ],
    "dispatch": [
      "self",
      "state"
    ],
    "gemm": [
      "self",
      "state"
    ],
    "combine": [
      "self",
      "state"
    ],
    "wait": [
      "self",
      "state"
    ],
    "fusedmoe_build": [
      "self",
      "low_latency_mode"
    ]
  },
  "MoeType": {
    "Default": [],
    "DSAsyncDecode": [],
    "DSAsyncPrefill": []
  },
  "SoftmaxTopK": {
    "__init__": [
      "self",
      "top_k",
      "dim",
      "n_groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "update_dims": [
    "hidden_dim",
    "ffn_dim"
  ],
  "split_size": [
    "size",
    "world_size",
    "align"
  ],
  "moe_gather_inputs": [
    "hidden_states",
    "topk_weights",
    "topk_ids",
    "group"
  ],
  "MoEForwardDPTP": {
    "__init__": [
      "self",
      "gemm_func",
      "max_tokens_per_round"
    ],
    "all_gather": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids",
      "tp_sizes"
    ],
    "reduce_scatter": [
      "self",
      "hidden_states",
      "out_states",
      "tp_sizes"
    ],
    "_gemm_and_reduce_scatter": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids",
      "output_states",
      "tp_sizes",
      "handles"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids"
    ]
  },
  "DispatchInputs": {
    "from_dict": [
      "cls",
      "input"
    ],
    "to_dict": [
      "self"
    ]
  },
  "FusedMoEBase": {
    "__init__": [
      "self",
      "tp",
      "tp_mode",
      "do_renormalize"
    ],
    "init_dist_args": [
      "self",
      "all_reduce"
    ],
    "before_dispatch": [
      "self",
      "state"
    ],
    "dispatch": [
      "self",
      "state"
    ],
    "gemm": [
      "self",
      "state"
    ],
    "combine": [
      "self",
      "state"
    ],
    "wait": [
      "self",
      "state"
    ],
    "forward_dptp": [
      "self"
    ],
    "forward_default": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_idx"
    ],
    "renormalize": [
      "self",
      "topk_weights"
    ]
  },
  "build_fused_moe": [
    "hidden_dim",
    "ffn_dim",
    "num_experts",
    "top_k",
    "bias",
    "renormalize",
    "dtype",
    "device",
    "all_reduce",
    "enable_ep",
    "quant_config",
    "layer_idx",
    "act_func",
    "prefix"
  ],
  "NoauxTCRouter": {
    "__init__": [
      "self",
      "scoring_func",
      "top_k",
      "n_group",
      "topk_group",
      "n_routed_experts",
      "routed_scaling_factor",
      "renormalize",
      "router_n_groups"
    ],
    "forward": [
      "self",
      "router_logits",
      "e_score_correction_bias"
    ]
  },
  "LinearWeightsW8A8": {
    "__init__": [
      "self",
      "num_experts",
      "in_features",
      "out_features",
      "weight_type",
      "device",
      "expert_list",
      "quant_dtype"
    ],
    "update_weight": [
      "self",
      "weight",
      "scale"
    ],
    "weight_loader_scale_tp": [
      "self",
      "param",
      "loaded_weight",
      "expert_id",
      "shard_id"
    ]
  },
  "FusedMoEW8A8": {
    "__init__": [
      "self",
      "hidden_dim",
      "ffn_dim",
      "num_experts",
      "top_k",
      "renormalize",
      "dtype",
      "quant_dtype",
      "device",
      "all_reduce"
    ],
    "update_weights": [
      "self"
    ],
    "dispatch": [
      "self",
      "state"
    ],
    "gemm": [
      "self",
      "state"
    ],
    "combine": [
      "self",
      "state"
    ],
    "wait": [
      "self",
      "state"
    ]
  },
  "LinearWeightsBlockedF8": {
    "__init__": [
      "self",
      "num_experts",
      "in_features",
      "out_features",
      "weight_type",
      "block_size",
      "dtype",
      "device",
      "bias",
      "expert_list",
      "scale_fmt"
    ],
    "update_weight": [
      "self",
      "weight",
      "weight_scale_inv"
    ],
    "weight_loader_scale_ep": [
      "self",
      "param",
      "loaded_weight",
      "expert_id",
      "shard_id"
    ],
    "_chunk_weight_tp": [
      "self",
      "weight",
      "dim",
      "world_size",
      "rank",
      "align"
    ],
    "weight_loader_tp_blocked_fp8": [
      "self",
      "param",
      "loaded_weight",
      "expert_id",
      "shard_id"
    ],
    "weight_loader_scale_tp": [
      "self",
      "param",
      "loaded_weight",
      "expert_id",
      "shard_id"
    ],
    "weight_loader_with_quant": [
      "self",
      "param",
      "loaded_weight",
      "expert_id",
      "shard_id"
    ]
  },
  "FusedMoEBlockedF8": {
    "__init__": [
      "self",
      "hidden_dim",
      "ffn_dim",
      "num_experts",
      "top_k",
      "bias",
      "renormalize",
      "fp8_dtype",
      "scale_fmt",
      "dtype",
      "device",
      "all_reduce",
      "layer_idx",
      "act_func"
    ],
    "_update_args": [
      "hidden_dim",
      "ffn_dim",
      "align"
    ],
    "update_weights": [
      "self"
    ],
    "before_dispatch": [
      "self",
      "state"
    ],
    "dispatch": [
      "self",
      "state"
    ],
    "gemm": [
      "self",
      "state"
    ],
    "combine": [
      "self",
      "state"
    ],
    "wait": [
      "self",
      "state"
    ],
    "fusedmoe_build": [
      "self",
      "low_latency_mode"
    ]
  },
  "LoRA": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "ranks",
      "scalings",
      "lora_a",
      "lora_b",
      "base_slice",
      "ctx_mgr",
      "colwise",
      "is_tp",
      "lora_b_spliter"
    ],
    "forward": [
      "self",
      "x",
      "base_output"
    ],
    "weight_loader_A": [
      "self",
      "param",
      "loaded_weight",
      "adapter_id"
    ],
    "weight_loader_B": [
      "self",
      "param",
      "loaded_weight",
      "adapter_id"
    ]
  },
  "BaseLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "dtype",
      "device",
      "colwise",
      "is_tp",
      "all_reduce",
      "tp_align_size",
      "dp_gather",
      "layer_type"
    ],
    "setup_loaders": [
      "self"
    ],
    "register_all_parameters": [
      "self",
      "weight",
      "bias"
    ],
    "_get_io_features": [
      "self",
      "in_features",
      "out_features",
      "colwise"
    ],
    "_weight_loader_tp_colwise": [
      "self",
      "param",
      "loaded_weight",
      "rank",
      "world_size"
    ],
    "_weight_loader_tp_rowwise": [
      "self",
      "param",
      "loaded_weight",
      "rank",
      "world_size"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "create_weights": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "dtype",
      "device"
    ],
    "update_weights": [
      "self"
    ],
    "_forward_default": [
      "self",
      "x",
      "all_reduce",
      "tp_sizes"
    ]
  },
  "MergedBaseLinear": {
    "__init__": [
      "self",
      "in_features",
      "all_out_features",
      "bias",
      "dtype",
      "device",
      "is_tp",
      "out_names",
      "dp_gather",
      "layer_type"
    ],
    "setup_loaders": [
      "self"
    ],
    "_get_io_features": [
      "self",
      "in_features",
      "out_features",
      "colwise"
    ],
    "_update_all_out_features": [
      "self",
      "all_out_features"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "shard_id"
    ],
    "weight_spliter": [
      "self",
      "loaded_weight"
    ],
    "weight_spliter_lora_b": [
      "self",
      "loaded_weight"
    ]
  },
  "QKVBaseLinear": {
    "__init__": [
      "self",
      "in_features",
      "num_q_heads",
      "num_kv_heads",
      "head_size",
      "head_size_v",
      "bias",
      "dtype",
      "device",
      "is_tp",
      "num_replicate_kv_heads"
    ],
    "_update_all_out_features": [
      "self",
      "all_out_features"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "shard_id"
    ],
    "weight_spliter": [
      "self",
      "loaded_weight",
      "layout"
    ],
    "weight_spliter_lora_b": [
      "self",
      "loaded_weight"
    ]
  },
  "AwqLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "w_bit",
      "group_size",
      "bias",
      "device",
      "colwise",
      "is_tp",
      "all_reduce",
      "layer_type"
    ],
    "setup_loaders": [
      "self"
    ],
    "register_all_parameters": [
      "self",
      "qweight",
      "scales",
      "qzeros",
      "bias"
    ],
    "_get_io_features": [
      "self",
      "in_features",
      "out_features",
      "w_bit",
      "group_size",
      "colwise"
    ],
    "_weight_loader_tp_colwise": [
      "self",
      "param",
      "loaded_weight",
      "rank",
      "world_size"
    ],
    "_weight_loader_tp_rowwise": [
      "self",
      "param",
      "loaded_weight",
      "rank",
      "world_size"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "create_weights": [
      "self",
      "in_features",
      "out_features",
      "w_bit",
      "group_size",
      "bias",
      "dtype",
      "device"
    ],
    "update_weights": [
      "self"
    ],
    "_forward_default": [
      "self",
      "x",
      "all_reduce",
      "tp_sizes"
    ]
  },
  "MergedAwqLinear": {
    "__init__": [
      "self",
      "in_features",
      "all_out_features",
      "w_bit",
      "group_size",
      "bias",
      "device",
      "is_tp",
      "out_names",
      "layer_type"
    ],
    "setup_loaders": [
      "self"
    ],
    "_get_io_features": [
      "self",
      "in_features",
      "out_features",
      "w_bit",
      "group_size",
      "colwise"
    ],
    "_update_all_out_features": [
      "self",
      "all_out_features",
      "w_bit",
      "group_size"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "shard_id"
    ],
    "weight_spliter_wz": [
      "self",
      "loaded_weight"
    ],
    "weight_spliter_s": [
      "self",
      "loaded_weight"
    ]
  },
  "QKVAwqLinear": {
    "__init__": [
      "self",
      "in_features",
      "num_q_heads",
      "num_kv_heads",
      "head_size",
      "head_size_v",
      "w_bit",
      "group_size",
      "bias",
      "device",
      "is_tp",
      "num_replicate_kv_heads"
    ],
    "_update_all_out_features": [
      "self",
      "all_out_features",
      "w_bit",
      "group_size"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "shard_id"
    ],
    "weight_spliter_wz": [
      "self",
      "loaded_weight",
      "layout"
    ],
    "weight_spliter_s": [
      "self",
      "loaded_weight",
      "layout"
    ],
    "weight_spliter_lora_b": [
      "self",
      "loaded_weight"
    ]
  },
  "LinearForwardDPTP": {
    "__init__": [
      "self",
      "gemm_func",
      "max_tokens_per_round"
    ],
    "all_gather": [
      "self",
      "hidden_states",
      "tp_sizes"
    ],
    "reduce_scatter": [
      "self",
      "hidden_states",
      "out_states",
      "tp_sizes"
    ],
    "_gemm_and_reduce_scatter": [
      "self",
      "hidden_states",
      "output_states",
      "tp_sizes",
      "handle"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LinearBase": {
    "__init__": [
      "self",
      "dtype",
      "device",
      "colwise",
      "is_tp",
      "all_reduce",
      "tp_align_size",
      "dp_gather",
      "layer_type"
    ],
    "init_tp_args": [
      "self",
      "is_tp",
      "all_reduce",
      "colwise",
      "layer_type"
    ],
    "get_tp_world_rank": [
      "self"
    ],
    "update_weights": [
      "self"
    ],
    "_forward_default": [
      "self",
      "x",
      "all_reduce",
      "tp_sizes"
    ],
    "_forward_lora": [
      "self",
      "x",
      "tp_sizes"
    ],
    "_forward_dp_tp": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QKV_SPLIT_LAYOUTS": [],
  "check_qkv_split_layout": [
    "layout"
  ],
  "update_tp_args": [
    "is_tp",
    "all_reduce",
    "colwise",
    "layer_type"
  ],
  "QKVMixin": {
    "__init__": [
      "self",
      "num_q_heads",
      "num_kv_heads",
      "head_size",
      "head_size_v",
      "num_replicate_kv_heads",
      "is_tp",
      "tp",
      "tp_rank"
    ],
    "get_qkv_out_feautures": [
      "self"
    ],
    "_get_qkv_out_features": [
      "self",
      "num_q_heads",
      "num_kv_heads",
      "head_size",
      "head_size_v",
      "num_replicate_kv_heads"
    ],
    "_update_num_heads": [
      "self",
      "is_tp",
      "tp",
      "tp_rank",
      "num_q_heads",
      "num_kv_heads"
    ],
    "split_qkv": [
      "self",
      "x"
    ]
  },
  "build_linear": [
    "in_features",
    "out_features",
    "bias",
    "dtype",
    "device",
    "colwise",
    "is_tp",
    "quant_config",
    "all_reduce",
    "tp_align_size",
    "dp_gather",
    "layer_type",
    "prefix"
  ],
  "build_colwise_linear": [
    "in_features",
    "out_features",
    "bias",
    "dtype",
    "device",
    "is_tp",
    "tp_align_size",
    "quant_config",
    "dp_disable_tp",
    "dp_gather",
    "check_dist",
    "layer_type",
    "prefix"
  ],
  "build_rowwise_linear": [
    "in_features",
    "out_features",
    "bias",
    "dtype",
    "device",
    "is_tp",
    "tp_align_size",
    "quant_config",
    "all_reduce",
    "dp_disable_tp",
    "check_dist",
    "layer_type",
    "prefix"
  ],
  "build_merged_colwise_linear": [
    "in_features",
    "all_out_features",
    "bias",
    "dtype",
    "device",
    "quant_config",
    "is_tp",
    "out_names",
    "dp_gather",
    "check_dist",
    "layer_type",
    "prefix"
  ],
  "build_qkv_proj": [
    "in_features",
    "num_q_heads",
    "num_kv_heads",
    "head_size",
    "head_size_v",
    "bias",
    "quant_config",
    "dtype",
    "device",
    "is_tp",
    "num_replicate_kv_heads",
    "prefix"
  ],
  "build_o_proj": [
    "in_features",
    "out_features",
    "bias",
    "dtype",
    "device",
    "is_tp",
    "tp_align_size",
    "quant_config",
    "all_reduce",
    "prefix"
  ],
  "build_gateup_linear": [
    "in_features",
    "all_out_features",
    "bias",
    "dtype",
    "device",
    "quant_config",
    "is_tp",
    "out_names",
    "dp_gather",
    "prefix"
  ],
  "build_down_linear": [
    "in_features",
    "out_features",
    "bias",
    "dtype",
    "device",
    "is_tp",
    "tp_align_size",
    "quant_config",
    "all_reduce",
    "prefix"
  ],
  "W8A8Linear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "dtype",
      "device",
      "colwise",
      "is_tp",
      "all_reduce",
      "quant_dtype",
      "layer_type"
    ],
    "setup_loaders": [
      "self"
    ],
    "register_all_parameters": [
      "self",
      "weight",
      "scale",
      "bias"
    ],
    "_get_io_features": [
      "self",
      "in_features",
      "out_features",
      "colwise"
    ],
    "_weight_loader_tp_colwise": [
      "self",
      "param",
      "loaded_weight",
      "rank",
      "world_size"
    ],
    "_weight_loader_tp_rowwise": [
      "self",
      "param",
      "loaded_weight",
      "rank",
      "world_size"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "create_weights": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "dtype",
      "device"
    ],
    "update_weights": [
      "self"
    ],
    "_forward_default": [
      "self",
      "x",
      "all_reduce",
      "tp_sizes"
    ]
  },
  "MergedW8A8Linear": {
    "__init__": [
      "self",
      "in_features",
      "all_out_features",
      "bias",
      "dtype",
      "device",
      "is_tp",
      "out_names",
      "quant_dtype",
      "layer_type"
    ],
    "setup_loaders": [
      "self"
    ],
    "_get_io_features": [
      "self",
      "in_features",
      "out_features",
      "colwise"
    ],
    "_update_all_out_features": [
      "self",
      "all_out_features"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "shard_id"
    ],
    "weight_spliter": [
      "self",
      "loaded_weight"
    ],
    "weight_spliter_lora_b": [
      "self",
      "loaded_weight"
    ]
  },
  "QKVW8A8Linear": {
    "__init__": [
      "self",
      "in_features",
      "num_q_heads",
      "num_kv_heads",
      "head_size",
      "head_size_v",
      "bias",
      "dtype",
      "device",
      "is_tp",
      "num_replicate_kv_heads",
      "quant_dtype"
    ],
    "_update_all_out_features": [
      "self",
      "all_out_features"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "shard_id"
    ],
    "weight_spliter": [
      "self",
      "loaded_weight",
      "layout"
    ],
    "weight_spliter_lora_b": [
      "self",
      "loaded_weight"
    ]
  },
  "BlockedF8Linear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "dtype",
      "device",
      "fp8_dtype",
      "scale_fmt",
      "colwise",
      "is_tp",
      "all_reduce",
      "dp_gather",
      "layer_type"
    ],
    "setup_loaders": [
      "self"
    ],
    "register_all_parameters": [
      "self",
      "weight",
      "weight_scale_inv",
      "bias"
    ],
    "_get_io_features": [
      "self",
      "in_features",
      "out_features",
      "colwise"
    ],
    "_weight_loader_tp_colwise": [
      "self",
      "param",
      "loaded_weight",
      "rank",
      "world_size"
    ],
    "_weight_loader_tp_rowwise": [
      "self",
      "param",
      "loaded_weight",
      "rank",
      "world_size"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "weight_loader_with_quant": [
      "self",
      "param",
      "loaded_weight"
    ],
    "create_weights": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "dtype",
      "device"
    ],
    "update_weights": [
      "self"
    ],
    "_forward_default": [
      "self",
      "x",
      "all_reduce",
      "tp_sizes"
    ]
  },
  "MergedBlockedF8Linear": {
    "__init__": [
      "self",
      "in_features",
      "all_out_features",
      "bias",
      "fp8_dtype",
      "scale_fmt",
      "replicate",
      "dtype",
      "device",
      "is_tp",
      "out_names",
      "dp_gather",
      "layer_type"
    ],
    "setup_loaders": [
      "self"
    ],
    "_get_io_features": [
      "self",
      "in_features",
      "out_features",
      "colwise"
    ],
    "_update_all_out_features": [
      "self",
      "all_out_features",
      "replicate"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "shard_id"
    ],
    "weight_loader_with_quant": [
      "self",
      "param",
      "loaded_weight",
      "shard_id"
    ],
    "weight_spliter": [
      "self",
      "loaded_weight"
    ],
    "weight_spliter_lora_b": [
      "self",
      "loaded_weight"
    ]
  },
  "QKVBlockedF8Linear": {
    "__init__": [
      "self",
      "in_features",
      "num_q_heads",
      "num_kv_heads",
      "head_size",
      "head_size_v",
      "bias",
      "fp8_dtype",
      "scale_fmt",
      "dtype",
      "device",
      "is_tp",
      "dp_gather",
      "num_replicate_kv_heads"
    ],
    "_update_all_out_features": [
      "self",
      "all_out_features",
      "replicate"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "shard_id"
    ],
    "weight_loader_with_quant": [
      "self",
      "param",
      "loaded_weight",
      "shard_id"
    ],
    "weight_spliter": [
      "self",
      "loaded_weight",
      "layout"
    ]
  },
  "RequestType": {
    "ADD_SESSION": [],
    "ADD_MESSAGE": [],
    "STOP_SESSION": [],
    "END_SESSION": [],
    "STOP_ENGINE": [],
    "RESUME_ENGINE": []
  },
  "Request": {},
  "ReqList": [],
  "_run_until_complete": [
    "future"
  ],
  "RequestSender": {
    "new": [
      "cls",
      "sender_id",
      "manager"
    ],
    "req_que": [
      "self"
    ],
    "event_loop": [
      "self"
    ],
    "is_loop_alive": [
      "self"
    ],
    "run_until_complete": [
      "self",
      "future"
    ],
    "_req_put": [
      "self",
      "reqs"
    ],
    "_gather_request": [
      "self",
      "req_types",
      "data"
    ],
    "batched_send_async": [
      "self",
      "req_types",
      "data"
    ],
    "send_async": [
      "self",
      "req_type",
      "data"
    ],
    "async_recv": [
      "self",
      "resp",
      "wait_main"
    ],
    "recv": [
      "self",
      "resp"
    ],
    "async_send": [
      "self",
      "req_type",
      "data"
    ],
    "send": [
      "self",
      "req_type",
      "data"
    ]
  },
  "RequestManager": {
    "__init__": [
      "self"
    ],
    "prepare_send": [
      "self"
    ],
    "sender_wait_loop": [
      "self"
    ],
    "create_loop_task": [
      "self"
    ],
    "wait_tasks": [
      "self"
    ],
    "event_loop": [
      "self"
    ],
    "set_main_loop_func": [
      "self",
      "loop"
    ],
    "stop_loop": [
      "self"
    ],
    "is_loop_alive": [
      "self"
    ],
    "build_sender": [
      "self"
    ],
    "has_requests": [
      "self"
    ],
    "get_all_requests": [
      "self"
    ],
    "bind_func": [
      "self",
      "req_type",
      "callback"
    ],
    "set_request_priority": [
      "self",
      "priority"
    ],
    "response": [
      "self",
      "resp"
    ],
    "process_request": [
      "self",
      "req_type",
      "reqs"
    ],
    "step": [
      "self"
    ],
    "run_until_complete": [
      "self",
      "future"
    ]
  },
  "KVCache": [],
  "round_up": [
    "x",
    "alignment"
  ],
  "CacheDesc": {
    "__post_init__": [
      "self"
    ]
  },
  "_get_kv_cache_dtype": [
    "model_config"
  ],
  "MLA_FP8_HEAD_DIM": [],
  "CacheEngine": {
    "__init__": [
      "self",
      "cache_config",
      "model_config",
      "rank",
      "tp_rank",
      "world_size",
      "cache_stream"
    ],
    "cpu_cache": [
      "self"
    ],
    "gpu_cache": [
      "self"
    ],
    "num_gpu_blocks": [
      "self"
    ],
    "num_cpu_blocks": [
      "self"
    ],
    "_get_key_block_shape_impl": [
      "cls",
      "model_config",
      "block_size",
      "head_size",
      "world_size",
      "quant_policy"
    ],
    "_get_value_block_shape_impl": [
      "cls",
      "model_config",
      "block_size",
      "head_size",
      "world_size",
      "quant_policy"
    ],
    "get_k_cache_desc": [
      "cls",
      "model_config",
      "cache_config",
      "world_size"
    ],
    "get_v_cache_desc": [
      "cls",
      "model_config",
      "cache_config",
      "world_size"
    ],
    "get_quant_cache_descs": [
      "cls",
      "k_cache_desc",
      "v_cache_desc",
      "model_config",
      "cache_config"
    ],
    "get_custom_cache_descs": [
      "cls",
      "model_config",
      "cache_config"
    ],
    "allocate_caches": [
      "cls",
      "num_blocks",
      "model_config",
      "cache_config",
      "world_size",
      "device"
    ],
    "allocate_gpu_cache": [
      "self"
    ],
    "allocate_cpu_cache": [
      "self"
    ],
    "get_custom_cache_shape_impl": [
      "num_layers",
      "num_blocks",
      "block_size",
      "shape"
    ],
    "_allocate_single_custom_cache": [
      "shape",
      "dtype",
      "device"
    ],
    "allocate_custom_cache": [
      "self",
      "device"
    ],
    "_swap": [
      "self",
      "src",
      "dst",
      "src_to_dst"
    ],
    "swap_in": [
      "self",
      "src_to_dst"
    ],
    "swap_out": [
      "self",
      "src_to_dst"
    ],
    "get_cache_block_size": [
      "cls",
      "cache_config",
      "model_config",
      "world_size"
    ],
    "p2p_initialize": [
      "self",
      "migration_init_request"
    ],
    "p2p_connect": [
      "self",
      "remote_engine_id",
      "migration_conn_request"
    ],
    "migrate": [
      "self",
      "migration_execution_inputs"
    ]
  },
  "StateCacheEngine": {
    "__init__": [
      "self",
      "cache_config"
    ],
    "allocate_caches": [
      "num_caches",
      "state_shapes",
      "device"
    ],
    "get_cache_state_size": [
      "state_shapes"
    ],
    "state_caches": [
      "self"
    ],
    "init_caches": [
      "self",
      "idx",
      "mask"
    ]
  },
  "EngineBase": {
    "close": [
      "self"
    ],
    "start_loop": [
      "self"
    ],
    "end_session": [
      "self",
      "session_id"
    ],
    "p2p_initialize": [
      "self",
      "conn_request"
    ],
    "p2p_connect": [
      "self",
      "conn_request"
    ],
    "p2p_drop_connect": [
      "self",
      "drop_conn_request"
    ],
    "create_instance": [
      "self",
      "cuda_stream_id"
    ]
  },
  "EngineInstanceBase": {
    "async_end": [
      "self",
      "session_id"
    ],
    "async_cancel": [
      "self",
      "session_id"
    ],
    "async_stream_infer": [
      "self"
    ]
  },
  "GuidedDecodingManager": {
    "processors": [],
    "__init__": [
      "self",
      "tokenizer",
      "vocab_size"
    ],
    "get_processors": [
      "self",
      "session_ctx",
      "response_formats"
    ],
    "get_processor": [
      "self",
      "session_id",
      "seq_id",
      "schema",
      "type"
    ],
    "remove_processor": [
      "self",
      "session_id"
    ],
    "allocate_batched_bitmap": [
      "self",
      "batch_size"
    ],
    "fill_bitmap": [
      "self",
      "processor",
      "guided_bitmask",
      "index"
    ],
    "accept_token": [
      "self",
      "processor",
      "token"
    ],
    "apply_batched_bitmap": [
      "self",
      "logits",
      "guided_bitmask"
    ],
    "clear": [
      "self"
    ]
  },
  "_tensorlize_block_offsets": [
    "block_offsets",
    "dtype"
  ],
  "InputsMakerConfig": {
    "from_engine": [
      "engine"
    ]
  },
  "LongContextChunker": {
    "__init__": [
      "self",
      "max_prefill_token_num"
    ],
    "enabled": [
      "self"
    ],
    "is_long_context": [
      "self",
      "seq"
    ],
    "set_seq": [
      "self",
      "seq"
    ],
    "multimodal_iter": [
      "self"
    ],
    "next_chunk_size": [
      "self"
    ],
    "is_last_chunk": [
      "self"
    ],
    "clear": [
      "self"
    ],
    "update_step": [
      "self",
      "inputs"
    ],
    "check_enable": [
      "self"
    ]
  },
  "InputsMakerAsync": {
    "__init__": [
      "self",
      "executor",
      "scheduler",
      "adapter_manager",
      "engine_strategy",
      "sampling_strategy",
      "model_agent_strategy",
      "config"
    ],
    "_init_do_prefill": [
      "self",
      "config"
    ],
    "_create_vision_model_inputs": [
      "self",
      "messages",
      "model_inputs"
    ],
    "torch_int_dtype": [
      "self"
    ],
    "_set_adapter_ids": [
      "self",
      "model_inputs",
      "messages"
    ],
    "create_model_inputs": [
      "self",
      "messages",
      "is_prefill"
    ],
    "create_model_inputs_long_context": [
      "self",
      "seq",
      "chunk_size",
      "multimodals"
    ],
    "create_model_inputs_delta": [
      "self"
    ],
    "create_model_inputs_delta_valid_only": [
      "self"
    ],
    "update_running_seqs": [
      "self",
      "running",
      "inputs"
    ],
    "deactivate_evict_seqs": [
      "self"
    ],
    "_make_forward_inputs": [
      "self",
      "prefill",
      "enable_empty"
    ],
    "do_prefill_pnode": [
      "self"
    ],
    "do_prefill_default": [
      "self"
    ],
    "do_prefill_chunked": [
      "self"
    ],
    "_send_next_inputs_impl": [
      "self",
      "prefill",
      "enable_empty"
    ],
    "send_next_inputs": [
      "self"
    ],
    "prefetch_next_inputs": [
      "self"
    ]
  },
  "build_inputs_maker": [
    "engine"
  ],
  "TypeModelMetas": [],
  "InputMultiModalType": [],
  "PreprocessInputResult": {},
  "BaseModelInputProcessor": {
    "preprocess_input": [
      "self",
      "input_ids",
      "input_mms"
    ]
  },
  "DefaultModelInputProcessor": {
    "preprocess_input": [
      "self",
      "input_ids",
      "input_mms"
    ]
  },
  "InferOutput": {},
  "_build_seq_meta": [
    "cache_config",
    "seq_strategy",
    "sampling_strategy"
  ],
  "response_reqs": [
    "req_manager",
    "resp",
    "resp_type",
    "data",
    "err_msg"
  ],
  "Engine": {
    "__init__": [
      "self",
      "model_path",
      "engine_config",
      "trust_remote_code",
      "speculative_config"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path",
      "engine_config",
      "trust_remote_code",
      "speculative_config"
    ],
    "_download_adapters": [
      "self",
      "adapters",
      "engine_config"
    ],
    "_build_adapter_manager": [
      "self",
      "adapters"
    ],
    "_bind_request_manager": [
      "self"
    ],
    "_response": [
      "self",
      "resp",
      "resp_type",
      "data",
      "err_msg"
    ],
    "_get_max_session_len": [
      "self"
    ],
    "_on_add_session": [
      "self",
      "reqs"
    ],
    "_on_stop_session": [
      "self",
      "reqs"
    ],
    "_on_end_session": [
      "self",
      "reqs"
    ],
    "_on_add_message": [
      "self",
      "reqs"
    ],
    "_add_message": [
      "self",
      "reqs"
    ],
    "model_config": [
      "self"
    ],
    "p2p_initialize": [
      "self",
      "init_request"
    ],
    "p2p_connect": [
      "self",
      "conn_request"
    ],
    "p2p_drop_connect": [
      "self",
      "drop_conn_request"
    ],
    "_loop_finally": [
      "self"
    ],
    "update_params": [
      "self",
      "request"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wakeup": [
      "self",
      "tags"
    ],
    "async_loop": [
      "self"
    ],
    "close": [
      "self"
    ],
    "start": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "wait_tasks": [
      "self"
    ],
    "create_instance": [
      "self",
      "cuda_stream_id"
    ],
    "start_loop": [
      "self"
    ],
    "end_session": [
      "self",
      "session_id"
    ],
    "get_engine_config": [
      "self"
    ],
    "get_schedule_metrics": [
      "self"
    ]
  },
  "_EMPTY_TOKEN": [],
  "CounterEvent": {
    "__init__": [
      "self"
    ],
    "set": [
      "self"
    ],
    "clear": [
      "self"
    ]
  },
  "RunableEventAsync": {
    "__init__": [
      "self",
      "scheduler"
    ],
    "wait": [
      "self"
    ],
    "set": [
      "self"
    ]
  },
  "build_runable_event": [
    "scheduler"
  ],
  "EngineLoopConfig": {
    "from_engine": [
      "engine"
    ]
  },
  "EngineLoop": {
    "__init__": [
      "self",
      "req_manager",
      "scheduler",
      "executor",
      "seq_strategy",
      "inputs_maker",
      "config",
      "engine_conn"
    ],
    "preprocess_loop": [
      "self"
    ],
    "_log_resps": [
      "outputs"
    ],
    "_send_resp": [
      "self",
      "out"
    ],
    "_update_logprobs": [
      "step_outputs"
    ],
    "_send_resps": [
      "self",
      "step_outputs"
    ],
    "send_response_loop": [
      "self"
    ],
    "_make_infer_outputs": [
      "self",
      "batched_outputs",
      "running",
      "model_inputs",
      "delta"
    ],
    "_main_loop_try_send_next_inputs": [
      "self"
    ],
    "_main_loop_get_outputs": [
      "self",
      "running",
      "forward_inputs"
    ],
    "main_loop": [
      "self"
    ],
    "update_running_migration": [
      "self",
      "running",
      "next_token_ids",
      "stopped",
      "model_metas"
    ],
    "_migration_loop_migrate": [
      "self",
      "migration_ready"
    ],
    "_migration_loop_get_outputs": [
      "self",
      "migration_ready"
    ],
    "_migration_loop_process_ready": [
      "self",
      "migration_ready"
    ],
    "migration_loop": [
      "self"
    ],
    "start": [
      "self",
      "event_loop"
    ],
    "wait_tasks": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "cancel": [
      "self"
    ]
  },
  "build_engine_loop": [
    "engine"
  ],
  "ConfigBuilder": {
    "update_engine_config": [
      "engine_config"
    ],
    "build_scheduler_config": [
      "engine_config"
    ],
    "build_cache_config": [
      "engine_config"
    ],
    "build_backend_config": [
      "engine_config"
    ],
    "build_dist_config": [
      "engine_config"
    ],
    "build_misc_config": [
      "engine_config"
    ],
    "build_specdecode_config": [
      "target_model",
      "speculative_config",
      "engine_config",
      "cache_config"
    ]
  },
  "EngineChecker": {
    "__init__": [
      "self",
      "model_path",
      "engine_config",
      "trust_remote_code",
      "logger"
    ],
    "check": [
      "self"
    ],
    "_handle_impl": [
      "self"
    ],
    "handle": [
      "self"
    ]
  },
  "_process_temperature_": [
    "scores",
    "temperature"
  ],
  "_process_bad_words_": [
    "scores",
    "bad_words",
    "mask",
    "filter_value"
  ],
  "_process_repetition_penalty_": [
    "scores",
    "input_ids",
    "penalty"
  ],
  "_filter_topk_sorted_": [
    "scores",
    "topk",
    "filter_value"
  ],
  "_filter_topp_sorted_": [
    "scores",
    "topp",
    "filter_value"
  ],
  "_filter_minp_sorted_": [
    "scores",
    "minp",
    "filter_value"
  ],
  "_multinomial_sampling": [
    "scores",
    "seeds",
    "offsets",
    "indices"
  ],
  "SamplingInputsDelta": {},
  "SamplingInputs": {
    "to_device": [
      "self",
      "device",
      "non_blocking"
    ],
    "get_delta": [
      "self"
    ],
    "update_delta": [
      "self",
      "delta"
    ]
  },
  "_apply_custom_logits_processors": [
    "batched_logits_processors",
    "all_ids",
    "logits"
  ],
  "_torch_topk": [
    "x",
    "k",
    "dim",
    "largest",
    "sorted"
  ],
  "FusedLogitsProcessor": {
    "__init__": [
      "self",
      "sampling_inputs",
      "logprobs_mode",
      "guided_decoding_manager"
    ],
    "_wait_stream_once": [
      "self"
    ],
    "__call__": [
      "self",
      "scores"
    ],
    "sampling": [
      "self",
      "logits"
    ],
    "compute_logprobs": [
      "self",
      "raw_logprobs",
      "token_ids"
    ],
    "cleanup_sessions": [
      "self",
      "session_ids"
    ]
  },
  "_check_resp": [
    "resp",
    "state",
    "warning_msg"
  ],
  "_check_resp_success": [
    "resp",
    "warning_msg"
  ],
  "async_try_add_session": [
    "req_sender",
    "session_id"
  ],
  "async_cancel": [
    "req_sender",
    "session_id"
  ],
  "try_add_session": [
    "req_sender",
    "session_id"
  ],
  "end": [
    "req_sender",
    "session_id"
  ],
  "cancel": [
    "req_sender",
    "session_id"
  ],
  "EngineInstance": {
    "__init__": [
      "self",
      "engine"
    ],
    "__del__": [
      "self"
    ],
    "_get_extra_outputs": [
      "self",
      "resp"
    ],
    "_async_try_add_session": [
      "self",
      "session_id"
    ],
    "_try_add_session": [
      "self",
      "session_id"
    ],
    "async_stream_infer": [
      "self",
      "session_id",
      "input_ids",
      "gen_config",
      "multimodal",
      "adapter_name"
    ],
    "async_infer": [
      "self",
      "session_id",
      "input_ids",
      "multimodal",
      "gen_config"
    ],
    "stream_infer": [
      "self",
      "session_id",
      "input_ids",
      "multimodal",
      "gen_config",
      "adapter_name"
    ],
    "infer": [
      "self",
      "session_id",
      "input_ids",
      "multimodal",
      "gen_config"
    ],
    "async_end": [
      "self",
      "session_id"
    ],
    "end": [
      "self",
      "session_id"
    ],
    "async_cancel": [
      "self",
      "session_id"
    ],
    "cancel": [
      "self",
      "session_id"
    ]
  },
  "DefaultForwardInputsMaker": {
    "__init__": [
      "self",
      "model_agent"
    ],
    "get": [
      "self"
    ],
    "step": [
      "self"
    ]
  },
  "DPForwardInputsMaker": {
    "__init__": [
      "self",
      "model_agent"
    ],
    "_make_dummy_forward_inputs": [
      "self"
    ],
    "_gather_has_inputs": [
      "self",
      "has_inputs"
    ],
    "_get_inputs": [
      "self"
    ],
    "get": [
      "self"
    ],
    "step": [
      "self"
    ]
  },
  "build_model_agent": [
    "model_path",
    "model_config",
    "cache_config",
    "backend_config",
    "misc_config",
    "dist_ctx",
    "device_ctx",
    "adapters",
    "specdecode_config"
  ],
  "SleepWakeupState": {},
  "BatchedLogProbs": {
    "to_cpu": [
      "self"
    ],
    "to_numpy": [
      "self"
    ],
    "to_tensor": [
      "self"
    ]
  },
  "BatchedOutputs": {
    "to_cpu": [
      "self"
    ],
    "to_numpy": [
      "self"
    ],
    "to_tensor": [
      "self"
    ]
  },
  "msg_with_rank": [
    "rank",
    "msg"
  ],
  "cache_swapping": [
    "cache_engine",
    "swap_in_map",
    "swap_out_map"
  ],
  "model_forward": [
    "model",
    "inputs",
    "cache_engine",
    "state_cache_engine",
    "stream"
  ],
  "_try_to_cuda": [
    "val",
    "non_blocking"
  ],
  "DistGatherScalar": {
    "__init__": [
      "self",
      "val",
      "size",
      "device",
      "group"
    ],
    "async_wait": [
      "self",
      "timeout"
    ]
  },
  "SwapMap": [],
  "StepInputs": {
    "merge": [
      "self",
      "inputs",
      "extra_inputs",
      "stopping_criteria",
      "sampling_delta",
      "next_token_ids",
      "model_metas",
      "extra_outputs",
      "model_agent"
    ],
    "update_delta": [
      "self",
      "delta",
      "model_agent"
    ],
    "step": [
      "self",
      "model_inputs",
      "extra_inputs",
      "stopping_criteria",
      "sampling_delta",
      "next_token_ids",
      "model_metas",
      "extra_outputs",
      "model_agent"
    ]
  },
  "BaseModelAgent": {
    "__init__": [
      "self",
      "model_path",
      "model_config",
      "cache_config",
      "backend_config",
      "misc_config",
      "dist_ctx",
      "device_ctx",
      "adapters",
      "specdecode_config"
    ],
    "all_context": [
      "self"
    ],
    "set_cache_config": [
      "self",
      "cache_config",
      "spec_cache_config"
    ],
    "set_model_config": [
      "self",
      "model_config",
      "spec_model_config"
    ],
    "get_free_mem": [
      "self"
    ],
    "warmup": [
      "self"
    ],
    "_slice_outs": [
      "self",
      "inputs",
      "seq_length"
    ],
    "_postprocess_forward_output": [
      "self",
      "output",
      "inputs"
    ],
    "_async_model_forward": [
      "self",
      "inputs",
      "return_logits"
    ],
    "async_sampling_logits": [
      "self",
      "logits",
      "sampling_inputs"
    ],
    "_push_output": [
      "self",
      "output"
    ],
    "_broadcast_next_token": [
      "self",
      "next_token_ids",
      "extra_inputs",
      "enable"
    ],
    "_prepare_dp_v1": [
      "self",
      "inputs"
    ],
    "_get_inputs_from_delta": [
      "self",
      "delta",
      "sampling_inputs"
    ],
    "_prepare_inputs_prefill": [
      "self",
      "inputs",
      "delta"
    ],
    "_step_postprocess_with_output": [
      "self",
      "last_logits",
      "logits",
      "inputs",
      "sampling_inputs",
      "stopping_criteria",
      "model_metas",
      "need_broadcast_next",
      "return_logits",
      "all_routed_experts",
      "extra_inputs"
    ],
    "_step_postprocess_without_output": [
      "self",
      "inputs",
      "last_logits",
      "extra_inputs",
      "need_broadcast_next"
    ],
    "_async_step": [
      "self",
      "inputs",
      "delta",
      "swap_in_map",
      "swap_out_map",
      "sampling_inputs",
      "stopping_criteria",
      "return_logits",
      "return_routed_experts",
      "extra_inputs"
    ],
    "_async_loop_background": [
      "self",
      "forward_event"
    ],
    "_async_loop_inputs_preprocess": [
      "self",
      "forward_event"
    ],
    "start": [
      "self",
      "forward_event"
    ],
    "wait_tasks": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "stop_async": [
      "self"
    ],
    "set_forward_inputs": [
      "self",
      "inputs"
    ],
    "get_output_async": [
      "self"
    ],
    "_build_model": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "build_graph_runner": [
      "self"
    ],
    "build_cache_engine": [
      "self"
    ],
    "_forward_impl": [
      "self",
      "inputs"
    ],
    "async_forward": [
      "self",
      "inputs"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_processor": [
      "self"
    ],
    "reset_graph_runner": [
      "self"
    ],
    "update_params": [
      "self",
      "request"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wakeup": [
      "self",
      "tags"
    ],
    "release": [
      "self"
    ]
  },
  "AgentProfiler": {
    "__init__": [
      "self",
      "dist_ctx",
      "stream"
    ],
    "_build_profiler": [
      "self"
    ],
    "dump": [
      "self"
    ],
    "profile_task": [
      "self"
    ],
    "create_task": [
      "self"
    ]
  },
  "find_available_port": [],
  "setup_master_addr": [
    "addr",
    "port"
  ],
  "init_dist_environ": [
    "rank",
    "world_size"
  ],
  "init_process_group": [
    "rank",
    "world_size"
  ],
  "ExecutorBase": {
    "__init__": [
      "self",
      "model_path",
      "model_config",
      "cache_config",
      "backend_config",
      "dist_config",
      "misc_config",
      "adapters",
      "specdecode_config",
      "device_type"
    ],
    "download_models": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "gather_free_mem": [
      "self"
    ],
    "set_cache_config": [
      "self",
      "cache_config",
      "spec_cache_config"
    ],
    "set_model_config": [
      "self",
      "model_config",
      "spec_model_config"
    ],
    "build_graph_runner": [
      "self"
    ],
    "build_cache_engine": [
      "self"
    ],
    "warmup": [
      "self"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wakeup": [
      "self",
      "tags"
    ],
    "update_params": [
      "self",
      "request"
    ],
    "get_input_processor": [
      "self"
    ],
    "start": [
      "self",
      "forward_event"
    ],
    "wait_tasks": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "release": [
      "self"
    ],
    "forward_async": [
      "self",
      "inputs"
    ],
    "get_output_async": [
      "self"
    ],
    "p2p_initialize": [
      "self",
      "remote_engine_config"
    ],
    "p2p_connect": [
      "self",
      "conn_request"
    ],
    "migrate": [
      "self",
      "batch"
    ],
    "_get_runtime_size": [
      "self",
      "num_free_gpu_mem",
      "cache_block_size",
      "vocal_size"
    ],
    "_adjust_block_size": [
      "self"
    ],
    "_get_state_cache_mem": [
      "self"
    ],
    "update_configs": [
      "self"
    ],
    "init": [
      "self"
    ],
    "remote_log": [
      "self",
      "msg"
    ]
  },
  "get_distributed_executor_backend": [
    "world_size",
    "dp",
    "device_type",
    "logger"
  ],
  "build_executor": [
    "model_path",
    "cache_config",
    "backend_config",
    "dist_config",
    "misc_config",
    "adapters",
    "device_type",
    "distributed_executor_backend",
    "dtype",
    "specdecode_config"
  ],
  "_get_master_addr": [],
  "_get_master_port": [],
  "get_ascend_device_rank_mapping": [
    "master_addr"
  ],
  "_update_env_cuda_alloc_conf": [
    "env_vars"
  ],
  "_update_runtime_envs": [
    "runtime_env"
  ],
  "_update_runtime_env_nsys": [
    "runtime_env"
  ],
  "RemoteLogger": {
    "__init__": [
      "self"
    ],
    "start": [
      "self",
      "msg"
    ],
    "end": [
      "self",
      "handle"
    ]
  },
  "RayWorkerWrapper": {
    "__init__": [
      "self",
      "model_path",
      "cache_config",
      "backend_config",
      "model_config",
      "dist_config",
      "misc_config",
      "adapters",
      "device_type",
      "dtype",
      "log_level",
      "specdecode_config"
    ],
    "set_device": [
      "self",
      "local_rank"
    ],
    "set_env": [
      "self",
      "envs"
    ],
    "get_node_ip": [
      "self"
    ],
    "warmup_dist": [
      "self"
    ],
    "pack_output": [
      "self",
      "output"
    ],
    "remote_log_start": [
      "self",
      "msg"
    ],
    "remote_log_end": [
      "self",
      "handle"
    ],
    "exit": [
      "self"
    ]
  },
  "RayExecutor": {
    "__init__": [
      "self",
      "model_path",
      "model_config",
      "cache_config",
      "backend_config",
      "dist_config",
      "misc_config",
      "adapters",
      "device_type",
      "dtype",
      "specdecode_config"
    ],
    "collective_rpc": [
      "self",
      "method",
      "args",
      "kwargs",
      "timeout"
    ],
    "build_model": [
      "self"
    ],
    "gather_free_mem": [
      "self"
    ],
    "set_cache_config": [
      "self",
      "cache_config",
      "spec_cache_config"
    ],
    "set_model_config": [
      "self",
      "model_config",
      "spec_model_config"
    ],
    "build_graph_runner": [
      "self"
    ],
    "build_cache_engine": [
      "self"
    ],
    "update_params": [
      "self",
      "request"
    ],
    "warmup": [
      "self"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wakeup": [
      "self",
      "tags"
    ],
    "get_input_processor": [
      "self"
    ],
    "_prefetch_task_callback": [
      "self",
      "task"
    ],
    "start": [
      "self",
      "forward_event"
    ],
    "wait_tasks": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "release": [
      "self"
    ],
    "_compile_dag": [
      "self"
    ],
    "forward_async": [
      "self",
      "inputs"
    ],
    "get_output_async": [
      "self"
    ],
    "remote_log": [
      "self",
      "msg"
    ],
    "_sort_workers": [
      "self",
      "driver_ip",
      "workers"
    ],
    "_sort_workers_by_ip": [
      "self",
      "ips",
      "workers"
    ],
    "_valid_bundle_id": [
      "self",
      "bundle_id"
    ],
    "_init_workers_ray": [
      "self",
      "placement_group",
      "worker_kwargs"
    ],
    "_init_distributed_environment_by_device": [
      "self",
      "device_str"
    ],
    "_init_ascend_distributed_environment": [
      "self",
      "driver_ip"
    ],
    "p2p_initialize": [
      "self",
      "init_request"
    ],
    "p2p_connect": [
      "self",
      "remote_engine_id",
      "conn_request"
    ],
    "migrate": [
      "self",
      "batch"
    ]
  },
  "SHARED_BLOCK_SIZE": [],
  "NUM_SHARED_BLOCK": [],
  "HEAD_SIZE": [],
  "SHARED_BLOCK_REAL_SIZE": [],
  "get_num_packages": [
    "data_size"
  ],
  "Notifier": {
    "__init__": [
      "self",
      "num_receiver",
      "mp_ctx"
    ],
    "_update_event_id": [
      "self"
    ],
    "set": [
      "self"
    ],
    "set_async": [
      "self"
    ],
    "wait": [
      "self"
    ],
    "wait_async": [
      "self"
    ],
    "close": [
      "self"
    ]
  },
  "SharedBuffer": {
    "__init__": [
      "self",
      "proc_id",
      "notifier",
      "name"
    ],
    "acquire_buf": [
      "self"
    ],
    "name": [
      "self"
    ],
    "pack_data": [
      "self",
      "data",
      "receiver_mask"
    ],
    "send": [
      "self",
      "data",
      "receiver_mask"
    ],
    "send_async": [
      "self",
      "data",
      "receiver_mask"
    ],
    "_receive_step0": [
      "self"
    ],
    "_receive_step1": [
      "self",
      "dumped_data",
      "is_receiver",
      "remain_size"
    ],
    "receive": [
      "self"
    ],
    "receive_async": [
      "self"
    ],
    "close": [
      "self"
    ]
  },
  "MPExecutor": {
    "setup_master_addr": [
      "cls"
    ],
    "__init__": [
      "self",
      "model_path",
      "model_config",
      "cache_config",
      "backend_config",
      "dist_config",
      "misc_config",
      "adapters",
      "specdecode_config",
      "device_type"
    ],
    "collective_rpc": [
      "self",
      "method",
      "args",
      "kwargs",
      "receiver_mask",
      "return_mask"
    ],
    "collective_rpc_async": [
      "self",
      "method",
      "args",
      "kwargs",
      "receiver_mask",
      "return_mask"
    ],
    "download_models": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "gather_free_mem": [
      "self"
    ],
    "set_cache_config": [
      "self",
      "cache_config",
      "spec_cache_config"
    ],
    "set_model_config": [
      "self",
      "model_config",
      "spec_model_config"
    ],
    "build_graph_runner": [
      "self"
    ],
    "build_cache_engine": [
      "self"
    ],
    "warmup": [
      "self"
    ],
    "_prefetch_outputs": [
      "self"
    ],
    "start": [
      "self",
      "forward_event"
    ],
    "wait_tasks": [
      "self"
    ],
    "forward_async": [
      "self",
      "inputs"
    ],
    "get_output_async": [
      "self"
    ],
    "get_input_processor": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "release": [
      "self"
    ]
  },
  "MPWorkerWrapper": {
    "__init__": [
      "self",
      "model_path",
      "cache_config",
      "backend_config",
      "model_config",
      "dist_config",
      "misc_config",
      "specdecode_config",
      "adapters",
      "device_type",
      "log_level"
    ]
  },
  "ExecutorProc": {
    "__init__": [
      "self",
      "proc_id",
      "mp_ctx"
    ],
    "start": [
      "self"
    ],
    "close": [
      "self"
    ],
    "join": [
      "self"
    ],
    "_main_loop": [
      "self",
      "proc_id",
      "comm_notifier",
      "comm_buf_name",
      "ret_notifier",
      "ret_buf_name",
      "model_path",
      "model_config",
      "cache_config",
      "backend_config",
      "dist_config",
      "misc_config",
      "specdecode_config",
      "adapters",
      "device_type",
      "log_level"
    ],
    "_task_wrapper": [
      "func",
      "args",
      "kwargs",
      "need_return",
      "ret_buf"
    ],
    "_main_loop_impl": [
      "self",
      "proc_id",
      "comm_buf",
      "ret_buf",
      "worker"
    ]
  },
  "WorkerWrapperBase": {
    "__init__": [
      "self",
      "model_path",
      "cache_config",
      "backend_config",
      "model_config",
      "dist_config",
      "misc_config",
      "adapters",
      "device_type",
      "log_level",
      "specdecode_config"
    ],
    "init_process_group": [
      "self",
      "rank",
      "master_addr",
      "master_port"
    ],
    "pack_output": [
      "self",
      "output"
    ],
    "get_outputs": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "get_free_mem": [
      "self"
    ],
    "set_cache_config": [
      "self",
      "cache_config",
      "spec_cache_config"
    ],
    "set_model_config": [
      "self",
      "model_config",
      "spec_model_config"
    ],
    "build_graph_runner": [
      "self"
    ],
    "build_cache_engine": [
      "self"
    ],
    "update_params": [
      "self",
      "request"
    ],
    "warmup": [
      "self"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wakeup": [
      "self",
      "tags"
    ],
    "get_input_processor": [
      "self"
    ],
    "start": [
      "self"
    ],
    "wait_tasks": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "stop_async": [
      "self"
    ],
    "forward_async": [
      "self",
      "inputs"
    ],
    "get_output_async": [
      "self"
    ],
    "release": [
      "self"
    ],
    "p2p_initialize": [
      "self",
      "init_request"
    ],
    "p2p_connect": [
      "self",
      "remote_engine_id",
      "conn_request"
    ],
    "migrate": [
      "self",
      "inputs"
    ]
  },
  "UniExecutor": {
    "__init__": [
      "self",
      "model_path",
      "model_config",
      "cache_config",
      "backend_config",
      "misc_config",
      "adapters",
      "device_type",
      "specdecode_config"
    ],
    "download_models": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "gather_free_mem": [
      "self"
    ],
    "set_cache_config": [
      "self",
      "cache_config",
      "spec_cache_config"
    ],
    "set_model_config": [
      "self",
      "model_config",
      "spec_model_config"
    ],
    "build_graph_runner": [
      "self"
    ],
    "build_cache_engine": [
      "self"
    ],
    "warmup": [
      "self"
    ],
    "start": [
      "self",
      "forward_event"
    ],
    "wait_tasks": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "release": [
      "self"
    ],
    "forward_async": [
      "self",
      "inputs"
    ],
    "get_output_async": [
      "self",
      "dp_rank"
    ],
    "get_input_processor": [
      "self"
    ],
    "p2p_initialize": [
      "self",
      "init_request"
    ],
    "p2p_connect": [
      "self",
      "remote_engine_id",
      "conn_request"
    ],
    "migrate": [
      "self",
      "batch"
    ]
  },
  "SessionState": {},
  "MPEngine": {
    "__init__": [
      "self"
    ],
    "_collective_rpc": [
      "self",
      "func"
    ],
    "_collective_rpc_async": [
      "self",
      "func"
    ],
    "_collective_rpc_streaming_async": [
      "self",
      "func"
    ],
    "close": [
      "self"
    ],
    "start_loop": [
      "self"
    ],
    "end_session": [
      "self",
      "session_id"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wakeup": [
      "self",
      "tags"
    ],
    "update_params": [
      "self",
      "request"
    ],
    "get_schedule_metrics": [
      "self"
    ],
    "p2p_initialize": [
      "self",
      "conn_request"
    ],
    "p2p_connect": [
      "self",
      "conn_request"
    ],
    "p2p_drop_connect": [
      "self",
      "drop_conn_request"
    ],
    "create_instance": [
      "self",
      "cuda_stream_id"
    ]
  },
  "MPEngineInstance": {
    "__init__": [
      "self",
      "engine"
    ],
    "async_end": [
      "self",
      "session_id"
    ],
    "async_cancel": [
      "self",
      "session_id"
    ],
    "async_stream_infer": [
      "self",
      "session_id"
    ]
  },
  "RayEngineWorker": {
    "__init__": [
      "self",
      "model_path",
      "engine_config",
      "log_level"
    ],
    "_stream_task_wrapper": [
      "self",
      "stream_id",
      "init_event",
      "func"
    ],
    "create_stream_task": [
      "self",
      "func"
    ],
    "get_stream_task_result": [
      "self",
      "stream_id"
    ]
  },
  "RayMPEngine": {
    "__init__": [
      "self",
      "model_path",
      "engine_config"
    ],
    "_init_ray": [
      "self",
      "engine_config"
    ],
    "_create_worker": [
      "self",
      "model_path",
      "engine_config"
    ],
    "_collective_rpc": [
      "self",
      "func"
    ],
    "_collective_rpc_async": [
      "self",
      "func"
    ],
    "_collective_rpc_streaming_async": [
      "self",
      "func"
    ],
    "close": [
      "self"
    ],
    "start_loop": [
      "self"
    ]
  },
  "build_mp_engine": [
    "backend",
    "model_path",
    "engine_config"
  ],
  "ZMQMPEngine": {
    "__init__": [
      "self",
      "model_path",
      "engine_config",
      "speculative_config"
    ],
    "_start_mp_proc": [
      "self",
      "model_path",
      "engine_config",
      "speculative_config"
    ],
    "_mp_proc": [
      "shared_dict",
      "condition",
      "model_path",
      "engine_config",
      "log_level",
      "speculative_config"
    ],
    "_mp_proc_async": [
      "server",
      "engine"
    ],
    "_collective_rpc": [
      "self",
      "func"
    ],
    "_collective_rpc_async": [
      "self",
      "func"
    ],
    "_collective_rpc_streaming_async": [
      "self",
      "func"
    ],
    "close": [
      "self"
    ],
    "start_loop": [
      "self"
    ]
  },
  "EngineInstancePool": {
    "__init__": [
      "self",
      "engine"
    ],
    "create_instance_pool": [
      "self",
      "num_instance"
    ],
    "instance": [
      "self"
    ],
    "async_end": [
      "self",
      "session_id"
    ],
    "async_cancel": [
      "self",
      "session_id"
    ],
    "async_stream_infer": [
      "self"
    ]
  },
  "EngineWorkerBase": {
    "__init__": [
      "self",
      "engine"
    ],
    "end_session": [
      "self",
      "session_id"
    ],
    "get_engine_config": [
      "self"
    ],
    "get_schedule_metrics": [
      "self"
    ],
    "p2p_initialize": [
      "self",
      "conn_request"
    ],
    "p2p_connect": [
      "self",
      "conn_request"
    ],
    "p2p_drop_connect": [
      "self",
      "drop_conn_request"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wakeup": [
      "self",
      "tags"
    ],
    "update_params": [
      "self",
      "request"
    ],
    "close": [
      "self"
    ],
    "instance_async_end": [
      "self",
      "session_id"
    ],
    "instance_async_cancel": [
      "self",
      "session_id"
    ],
    "instance_async_stream_infer": [
      "self"
    ]
  },
  "EngineOutputGather": {
    "__init__": [
      "self"
    ],
    "get": [
      "self",
      "stream_id"
    ],
    "add": [
      "self",
      "stream_id",
      "result"
    ],
    "pop": [
      "self",
      "stream_id",
      "result"
    ]
  },
  "_task_callback": [
    "task"
  ],
  "AsyncRPCServer": {
    "__init__": [
      "self"
    ],
    "get_port": [
      "self"
    ],
    "_get_next_stream_id": [
      "self"
    ],
    "register_method": [
      "self",
      "name",
      "func"
    ],
    "send_multipart": [
      "self",
      "client_id",
      "data"
    ],
    "call_method_default": [
      "self",
      "client_id",
      "method",
      "request"
    ],
    "_method_async_task": [
      "self",
      "client_id",
      "request_id",
      "method",
      "args",
      "kwargs"
    ],
    "_method_async_streaming_task": [
      "self",
      "stream_id",
      "request_id",
      "client_id",
      "method",
      "args",
      "kwargs"
    ],
    "get_stream_output": [
      "self",
      "stream_id"
    ],
    "call_method_async": [
      "self",
      "client_id",
      "method",
      "request"
    ],
    "call_and_response": [
      "self"
    ],
    "run": [
      "self"
    ],
    "stop": [
      "self"
    ]
  },
  "AsyncRPCClient": {
    "__init__": [
      "self",
      "port"
    ],
    "_set_reply_default": [
      "self",
      "request_id",
      "reply"
    ],
    "_set_reply": [
      "self",
      "reply"
    ],
    "_poll_recv": [
      "self",
      "timeout"
    ],
    "_try_start_listen": [
      "self"
    ],
    "call": [
      "self",
      "method"
    ],
    "_async_call_impl": [
      "self",
      "method",
      "streaming"
    ],
    "async_call": [
      "self",
      "method"
    ],
    "async_stream_call": [
      "self",
      "method"
    ],
    "listen": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "close_sockets": [
      "self"
    ]
  },
  "TorchChecker": {
    "__init__": [
      "self",
      "device",
      "logger"
    ],
    "check": [
      "self"
    ]
  },
  "DeeplinkChecker": {
    "__init__": [
      "self",
      "device_type",
      "logger"
    ],
    "check": [
      "self"
    ]
  },
  "RED_COLOR": [],
  "RESET_COLOR": [],
  "_red_text": [
    "text"
  ],
  "BaseChecker": {
    "__init__": [
      "self",
      "logger"
    ],
    "get_logger": [
      "self"
    ],
    "register_required_checker": [
      "self",
      "checker"
    ],
    "handle": [
      "self"
    ],
    "log_and_exit": [
      "self",
      "e",
      "mod_name",
      "message"
    ],
    "check": [
      "self"
    ]
  },
  "MIN_TRANSFORMERS_VERSION": [],
  "MAX_TRANSFORMERS_VERSION": [],
  "TransformersChecker": {
    "check": [
      "self"
    ]
  },
  "DistChecker": {
    "__init__": [
      "self",
      "tp",
      "dp",
      "ep",
      "distributed_executor_backend",
      "device_type",
      "logger"
    ],
    "check": [
      "self"
    ]
  },
  "MAX_TRITON_VERSION": [],
  "MIN_TRITON_VERSION": [],
  "TritonChecker": {
    "check_version": [
      "self"
    ],
    "check": [
      "self"
    ]
  },
  "ModelChecker": {
    "__init__": [
      "self",
      "model_path",
      "trust_remote_code",
      "dtype",
      "device_type",
      "logger"
    ],
    "check_config": [
      "self",
      "trans_version"
    ],
    "check_trans_version": [
      "self",
      "config",
      "trans_version"
    ],
    "check_dtype": [
      "self",
      "config"
    ],
    "check": [
      "self"
    ]
  },
  "AdapterChecker": {
    "__init__": [
      "self",
      "adapter_path",
      "logger"
    ],
    "check": [
      "self"
    ]
  },
  "_add_kernel": [
    "A",
    "B",
    "C",
    "size",
    "BLOCK"
  ],
  "custom_add": [
    "a",
    "b"
  ],
  "CudaChecker": {
    "__init__": [
      "self",
      "model_format",
      "logger"
    ],
    "check": [
      "self"
    ]
  },
  "ImageData": {},
  "MultiModalData": {},
  "MultiModalDataList": [],
  "NestedTensor": [],
  "MultiModalTensor": {
    "__post_init__": [
      "self"
    ],
    "to_device": [
      "self",
      "device",
      "non_blocking"
    ]
  },
  "MultiModalInputs": [],
  "load_weight": [
    "param",
    "loaded_weight"
  ],
  "default_weight_loader": [
    "param",
    "loaded_weight"
  ],
  "_get_weight_type": [
    "model_path",
    "use_safetensors"
  ],
  "_get_weight_map": [
    "model_path",
    "weight_type"
  ],
  "_get_weight_path": [
    "model_path",
    "weight_type"
  ],
  "_get_safetensors_weights_iterator": [
    "file",
    "prefix"
  ],
  "_get_pt_weights_iterator": [
    "file",
    "prefix"
  ],
  "ModelWeightLoader": {
    "__init__": [
      "self",
      "model_path",
      "prefix"
    ],
    "_get_shard_paths": [
      "model_path",
      "is_sharded",
      "weight_type"
    ],
    "_get_weights_iterator": [
      "self",
      "path"
    ],
    "_skip_dummy_iterator": [
      "iterator",
      "dummy_prefix"
    ],
    "_rename_weights_iterator": [
      "iterator",
      "model"
    ],
    "load_model_weights": [
      "self",
      "model",
      "device"
    ]
  },
  "load_model_weights": [
    "model",
    "checkpoint_path",
    "prefix",
    "device"
  ],
  "BaseSpecModelAgent": {
    "__init__": [
      "self",
      "enable"
    ],
    "is_enabled": [
      "self"
    ],
    "set_cache_config": [
      "self",
      "cache_config"
    ],
    "set_model_config": [
      "self",
      "model_config"
    ],
    "build_model": [
      "self",
      "empty_init",
      "target_model",
      "build_model_ctx"
    ],
    "build_graph_runner": [
      "self"
    ],
    "build_cache_engine": [
      "self",
      "cache_stream"
    ],
    "async_model_forward": [
      "self",
      "next_token_ids",
      "model_inputs",
      "extra_inputs",
      "sampling_inputs"
    ],
    "warmup": [
      "self",
      "max_batches",
      "target_model_config"
    ],
    "reset_graph_runner": [
      "self"
    ],
    "update_main_model_outputs": [
      "self",
      "output",
      "model_inputs"
    ]
  },
  "SamplePolicy": {
    "ALL_GREEDY": []
  },
  "RejectionSampler": {
    "__init__": [
      "self",
      "sample_policy"
    ],
    "forward": [
      "self",
      "target_logits",
      "draft_token_ids",
      "bonus_token_ids",
      "draft_probs"
    ]
  },
  "rejection_sample": [
    "target_probs",
    "draft_token_ids",
    "bonus_token_ids",
    "sample_policy",
    "draft_probs"
  ],
  "greedy_reject_sampler": [
    "draft_token_ids",
    "target_token_ids",
    "bonus_token_ids"
  ],
  "build_spec_agent": [
    "specdecode_config",
    "backend_config",
    "dist_ctx",
    "inputs_strategy",
    "agent_strategy",
    "device"
  ],
  "SpecModelAgent": {
    "__init__": [
      "self",
      "specdecode_config",
      "backend_config",
      "inputs_strategy",
      "agent_strategy",
      "device"
    ],
    "set_cache_config": [
      "self",
      "cache_config"
    ],
    "set_model_config": [
      "self",
      "model_config"
    ],
    "build_model": [
      "self",
      "empty_init",
      "target_model",
      "build_model_ctx"
    ],
    "build_graph_runner": [
      "self"
    ],
    "build_cache_engine": [
      "self",
      "cache_stream"
    ],
    "_rejection_sampling": [
      "self",
      "next_token_ids",
      "model_inputs",
      "extra_inputs"
    ],
    "_forward_impl": [
      "self",
      "inputs"
    ],
    "_async_forward": [
      "self",
      "inputs"
    ],
    "_async_model_forward": [
      "self",
      "inputs",
      "extra_inputs",
      "sampling_inputs"
    ],
    "async_model_forward": [
      "self",
      "next_token_ids",
      "model_inputs",
      "extra_inputs",
      "sampling_inputs"
    ],
    "warmup": [
      "self",
      "max_batches",
      "target_model_config"
    ],
    "reset_graph_runner": [
      "self"
    ]
  },
  "DeepseekMTP": {
    "get_outputs": [
      "self",
      "model_outputs",
      "model_inputs",
      "extra_inputs"
    ]
  },
  "SPEC_PROPOSERS": [],
  "draft_model_forward": [
    "model",
    "inputs",
    "model_config",
    "cache_engine"
  ],
  "BaseSpecProposer": {
    "__init__": [
      "self",
      "specdecode_config",
      "device"
    ],
    "build_model": [
      "self",
      "empty_init",
      "target_model",
      "build_model_ctx"
    ],
    "get_outputs": [
      "self",
      "model_outputs",
      "model_inputs",
      "extra_inputs"
    ],
    "_forward": [
      "self",
      "model_inputs",
      "cache_engine"
    ],
    "update_inputs_decoding": [
      "self",
      "model_inputs",
      "extra_inputs",
      "next_input_ids",
      "target_hidden_states",
      "model_metas"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_target_hidden_size": [
      "self",
      "model_config"
    ]
  },
  "build_specdecode_proposer": [
    "specdecode_config",
    "device"
  ],
  "Eagle": {},
  "Eagle3": {
    "build_model": [
      "self",
      "empty_init",
      "target_model",
      "build_model_ctx"
    ],
    "get_target_hidden_size": [
      "self",
      "model_config"
    ],
    "get_outputs": [
      "self",
      "model_outputs",
      "model_inputs",
      "extra_inputs"
    ]
  },
  "_get_backend": [],
  "get_backend": [
    "backend_type"
  ],
  "init_backend": [
    "backend_type"
  ],
  "RMSNormImpl": {
    "forward": [
      "self",
      "x",
      "weight",
      "residual"
    ]
  },
  "RMSNormBuilder": {
    "build": [
      "hidden_size",
      "eps"
    ]
  },
  "LayerNormImpl": {
    "forward": [
      "self",
      "x",
      "weight",
      "bias",
      "residual"
    ]
  },
  "LayerNormBuilder": {
    "build": [
      "normalized_shape",
      "eps"
    ]
  },
  "AdapterInfo": {
    "__post_init__": [
      "self"
    ]
  },
  "LoRAImpl": {
    "forward": [
      "self",
      "x",
      "base_output",
      "lora_A",
      "lora_B",
      "adapter_info",
      "ctx_mgr",
      "colwise",
      "is_tp"
    ]
  },
  "LoRABuilder": {
    "build": []
  },
  "OpType": {
    "PagedAttention": [],
    "FlashAttention": [],
    "Linear": [],
    "RotaryEmbedding": [],
    "ApplyRotaryEmb": [],
    "SiluAndMul": [],
    "GeluAndMul": [],
    "RMSNorm": [],
    "LayerNorm": [],
    "LoRA": [],
    "LinearW8A8": [],
    "RMSNormW8A8": [],
    "MultinomialSampling": [],
    "LinearW4A16": [],
    "SoftmaxTopK": [],
    "FusedMoE": [],
    "FusedMoEW8A8": [],
    "LinearBlockedF8": [],
    "FusedMoEBlockedF8": [],
    "NSAIndexFP8": [],
    "Embedding": [],
    "RouterNoauxTC": []
  },
  "OpsBackend": {
    "get_name": [],
    "get_layer_impl_builder": [
      "cls",
      "layer_type"
    ],
    "get_attention_metadata_cls": [],
    "get_k_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "get_v_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "update_step_context": [
      "cls",
      "step_context"
    ],
    "build_graph_runner": [
      "model",
      "model_config",
      "cache_config",
      "backend_config",
      "device"
    ],
    "device_count": [],
    "support_ray": []
  },
  "NSAIndexMeta": {},
  "BaseNSAIndexFP8": {
    "forward": [
      "self",
      "q",
      "k",
      "weights",
      "k_cache",
      "k_s_cache",
      "meta"
    ]
  },
  "BaseNSAIndexFP8Builder": {
    "build": [
      "topk",
      "softmax_scale",
      "block_size",
      "fill"
    ]
  },
  "RMSNormW8A8Impl": {
    "create_weight": [
      "hidden_size",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "residual"
    ]
  },
  "RMSNormW8A8Builder": {
    "build": [
      "hidden_size",
      "eps",
      "quant_dtype"
    ]
  },
  "LinearW8A8Impl": {
    "update_weights": [
      "self",
      "weight",
      "scale",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "scale",
      "bias",
      "all_reduce",
      "group"
    ]
  },
  "LinearW8A8Builder": {
    "build": [
      "in_features",
      "out_features",
      "bias",
      "dtype",
      "quant_dtype"
    ]
  },
  "LinearW4A16Impl": {
    "update_weights": [
      "self",
      "qweight",
      "scales",
      "qzeros",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "bias",
      "all_reduce",
      "group"
    ]
  },
  "LinearW4A16Builder": {
    "build": [
      "in_features",
      "out_features",
      "w_bit",
      "group_size",
      "bias",
      "dtype"
    ]
  },
  "EmbeddingImpl": {
    "forward": [
      "self",
      "x",
      "weight",
      "all_reduce",
      "group"
    ]
  },
  "EmbeddingBuilder": {
    "build": [
      "start_index",
      "end_index"
    ]
  },
  "SiluAndMulImpl": {
    "forward": [
      "self",
      "x"
    ]
  },
  "SiluAndMulBuilder": {
    "build": [
      "inplace"
    ]
  },
  "GeluAndMulImpl": {
    "forward": [
      "self",
      "x"
    ]
  },
  "GeluAndMulBuilder": {
    "build": [
      "approximate"
    ]
  },
  "LinearBlockedF8Impl": {
    "__init__": [
      "self"
    ],
    "update_weights": [
      "self",
      "weight",
      "scale",
      "bias"
    ],
    "set_scale_fmt": [
      "self",
      "scale_fmt"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "scale",
      "bias",
      "all_reduce",
      "group",
      "rank",
      "scatter_size"
    ]
  },
  "LinearBlockedF8Builder": {
    "build": [
      "in_features",
      "out_features",
      "bias",
      "dtype"
    ]
  },
  "AttentionMetadata": {},
  "AttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "v_head_size",
      "alibi",
      "sliding_window",
      "logit_softcapping",
      "causal",
      "use_flash_mla"
    ],
    "make_alibi_slopes": [
      "head_start",
      "head_end",
      "num_heads",
      "alibi_scale",
      "dtype",
      "device"
    ],
    "set_alibi_slopes": [
      "self",
      "slopes"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "k_scales_zeros",
      "v_scales_zeros",
      "learnable_sink",
      "nsa_indices",
      "inplace"
    ]
  },
  "AttentionBuilder": {
    "build": [
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "v_head_size",
      "alibi",
      "sliding_window",
      "logit_softcapping",
      "causal",
      "use_flash_mla",
      "learnable_sink",
      "block_sparse_size"
    ]
  },
  "MoEBackend": {
    "__init__": [
      "self"
    ],
    "set_deepep_moe_backend": [
      "self"
    ],
    "use_deepep_moe_backend": [
      "self"
    ]
  },
  "get_moe_backend": [],
  "ApplyRotaryEmbImpl": {
    "forward": [
      "self",
      "query",
      "key",
      "cos",
      "sin",
      "inplace"
    ]
  },
  "ApplyRotaryEmbBuilder": {
    "build": []
  },
  "RopeType": {
    "Default": [],
    "LinearScaling": [],
    "DynamicNTKScaling": [],
    "Llama3": [],
    "Yarn": [],
    "LongRoPEScaling": [],
    "Fope": []
  },
  "YarnParameters": {},
  "LongRoPEScalingParameters": {},
  "Llama3Parameters": {},
  "FopeParameters": {},
  "RotaryEmbeddingImpl": {
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "RotaryEmbeddingBuilder": {
    "build": [
      "dim",
      "max_position_embeddings",
      "base",
      "scaling_factor",
      "yarn_params",
      "longrope_params",
      "llama3_params",
      "fope_params",
      "emb_type"
    ]
  },
  "GraphRunnerMeta": {},
  "_get_capture_batch_size_impl": [
    "max_batches"
  ],
  "GraphRunner": {
    "__init__": [
      "self",
      "model",
      "model_config",
      "cache_config",
      "backend_config",
      "device"
    ],
    "__call__": [
      "self"
    ],
    "get_model": [
      "self"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "update_model_metas": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "get_input_processor": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "get_meta": [
      "self"
    ],
    "update_inputs": [
      "self",
      "inputs"
    ],
    "get_capture_batch_sizes": [
      "self"
    ]
  },
  "MultinomialSamplingImpl": {
    "forward": [
      "scores",
      "seeds",
      "offsets",
      "indices"
    ]
  },
  "MultinomialSamplingBuilder": {
    "build": []
  },
  "TokenDispatcherImpl": {
    "permute": [
      "self",
      "tokens",
      "routing_map"
    ],
    "unpermute": [
      "self",
      "permuted_tokens",
      "sorted_indices",
      "restore_shape",
      "probs",
      "routing_map"
    ],
    "indices_to_multihot": [
      "self",
      "topk_ids",
      "topk_weight",
      "num_experts"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "probs",
      "topk_ids",
      "local_expert_indices"
    ],
    "combine": [
      "self",
      "hidden_states"
    ]
  },
  "FlashAttentionImpl": {
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "q_start_loc",
      "q_seqlens",
      "kv_start_loc",
      "kv_seqlens",
      "max_q_seqlen"
    ]
  },
  "FlashAttentionBuilder": {
    "build": [
      "num_heads",
      "head_dim",
      "scale",
      "num_kv_heads",
      "v_head_dim",
      "causal",
      "sliding_window",
      "logit_softcapping"
    ]
  },
  "RouterNoauxTCImpl": {
    "forward": [
      "self",
      "logits",
      "bias"
    ]
  },
  "RouterNoauxTCBuilder": {
    "build": [
      "scoring_func",
      "top_k",
      "n_group",
      "topk_group",
      "n_routed_experts",
      "routed_scaling_factor",
      "renormalize",
      "router_n_groups"
    ]
  },
  "LinearImpl": {
    "update_weights": [
      "self",
      "weight",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "bias",
      "all_reduce",
      "group",
      "rank",
      "scatter_size"
    ]
  },
  "LinearBuilder": {
    "build": [
      "in_features",
      "out_features",
      "bias",
      "dtype"
    ]
  },
  "SoftmaxTopKImpl": {
    "get_group_offsets": [
      "n_groups",
      "group_size",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SoftmaxTopKBuilder": {
    "build": [
      "top_k",
      "dim",
      "n_groups"
    ]
  },
  "FusedMoEImpl": {
    "update_weights": [
      "self",
      "gate_up_weights",
      "down_weights"
    ],
    "ep_expert_list": [
      "self",
      "world_size",
      "rank"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids",
      "gate_up_weights",
      "down_weights",
      "gate_up_bias",
      "down_bias",
      "expert_list",
      "act_func"
    ]
  },
  "FusedMoEBuilder": {
    "build": [
      "top_k",
      "num_experts",
      "renormalize",
      "hidden_dim",
      "ep_size",
      "ep_group",
      "layer_idx",
      "out_dtype"
    ]
  },
  "FusedMoEW8A8Impl": {
    "update_weights": [
      "self",
      "gate_up_weights",
      "down_weights",
      "gate_up_scale",
      "down_scale"
    ],
    "ep_expert_list": [
      "self",
      "world_size",
      "rank"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_scale",
      "topk_weights",
      "topk_ids",
      "gate_up_weights",
      "gate_up_scale",
      "down_weights",
      "down_scale",
      "expert_list"
    ]
  },
  "FusedMoEW8A8Builder": {
    "build": [
      "top_k",
      "num_experts",
      "renormalize",
      "out_dtype",
      "quant_dtype"
    ]
  },
  "FusedMoEBlockedF8Impl": {
    "__init__": [
      "self"
    ],
    "update_weights": [
      "self",
      "gate_up_weights",
      "down_weights",
      "gate_up_scale",
      "down_scale"
    ],
    "ep_expert_list": [
      "self",
      "world_size",
      "rank"
    ],
    "set_scale_fmt": [
      "self",
      "scale_fmt"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_scale",
      "topk_weights",
      "topk_ids",
      "gate_up_weights",
      "gate_up_scale",
      "down_weights",
      "down_scale",
      "gate_up_bias",
      "down_bias",
      "expert_list",
      "act_func"
    ]
  },
  "FusedMoEBlockedF8Builder": {
    "build": [
      "top_k",
      "num_experts",
      "hidden_dim",
      "renormalize",
      "block_size",
      "ep_size",
      "ep_group",
      "out_dtype",
      "layer_idx",
      "custom_gateup_act"
    ]
  },
  "DlinferRMSNormImpl": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "residual"
    ]
  },
  "DlinferRMSNormBuilder": {
    "build": [
      "weight",
      "eps"
    ]
  },
  "DlinferLinearW8A8Impl": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "out_dtype",
      "quant_dtype"
    ],
    "update_weights": [
      "self",
      "weight",
      "scale",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "scale",
      "bias",
      "all_reduce",
      "group"
    ]
  },
  "DlinferLinearW8A8Builder": {
    "build": [
      "in_features",
      "out_features",
      "bias",
      "dtype",
      "quant_dtype"
    ]
  },
  "DlinferRMSNormW8A8Impl": {
    "__init__": [
      "self",
      "hidden_size",
      "eps",
      "quant_dtype"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "residual"
    ]
  },
  "DlinferRMSNormW8A8Builder": {
    "build": [
      "hidden_size",
      "eps",
      "quant_dtype"
    ]
  },
  "AwqLinearW4A16Impl": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "w_bit",
      "group_size"
    ],
    "forward": [
      "self",
      "x",
      "qweight",
      "scales",
      "qzeros",
      "bias",
      "all_reduce",
      "group"
    ]
  },
  "AwqLinearW4A16Builder": {
    "build": [
      "in_features",
      "out_features",
      "w_bit",
      "group_size",
      "bias",
      "dtype"
    ]
  },
  "DlinferSiluAndMulImpl": {
    "forward": [
      "self",
      "x"
    ]
  },
  "DlinferSiluAndMulBuilder": {
    "build": [
      "inplace"
    ]
  },
  "DlinferOpsBackend": {
    "get_name": [],
    "get_layer_impl_builder": [
      "cls",
      "layer_type"
    ],
    "get_attention_metadata_cls": [],
    "get_k_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "get_v_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "update_step_context": [
      "cls",
      "step_context"
    ]
  },
  "DlinferAttentionMetadata": {},
  "DlinferAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "v_head_size",
      "alibi",
      "sliding_window",
      "logit_softcapping",
      "causal"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "k_scales_zeros",
      "v_scales_zeros",
      "learnable_sink",
      "nsa_indices",
      "inplace"
    ]
  },
  "DlinferAttentionBuilder": {
    "build": [
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "v_head_size",
      "alibi_scale",
      "sliding_window",
      "logit_softcapping",
      "causal",
      "learnable_sink"
    ]
  },
  "DlinferApplyRotaryEmbImpl": {
    "forward": [
      "self",
      "query",
      "key",
      "cos",
      "sin",
      "inplace"
    ]
  },
  "DlinferApplyRotaryEmbBuilder": {
    "build": []
  },
  "_rotary_embedding_fwd": [
    "position_ids",
    "inv_freq",
    "scaling_factor",
    "mscale",
    "dtype"
  ],
  "DlinferRotaryEmbeddingImpl": {
    "__init__": [
      "self",
      "dim",
      "base",
      "scaling_factor"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "DlinferLlamaDynamicNTKScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "base",
      "scaling_factor",
      "max_position_embeddings"
    ],
    "_ntk_inv_freq": [
      "self",
      "seq_len"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "DlinferLlama3RotaryEmbeddingImpl": {
    "__init__": [
      "self",
      "dim",
      "base",
      "scaling_factor",
      "low_freq_factor",
      "high_freq_factor",
      "original_max_position_embeddings"
    ]
  },
  "DlinferYarnRotaryEmbeddingImpl": {
    "__init__": [
      "self",
      "dim",
      "base",
      "scaling_factor",
      "original_max_position_embeddings",
      "yarn_params"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "DlinferRotaryEmbeddingBuilder": {
    "build": [
      "dim",
      "max_position_embeddings",
      "base",
      "scaling_factor",
      "yarn_params",
      "longrope_params",
      "llama3_params",
      "emb_type"
    ]
  },
  "DlinferFlashAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_dim",
      "scale",
      "num_kv_heads",
      "v_head_dim",
      "causal",
      "sliding_window",
      "logit_softcapping"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "q_start_loc",
      "q_seqlens",
      "kv_start_loc",
      "kv_seqlens",
      "max_q_seqlen"
    ]
  },
  "DlinferFlashAttentionBuilder": {
    "build": [
      "num_heads",
      "head_dim",
      "scale",
      "num_kv_heads",
      "v_head_dim",
      "causal",
      "sliding_window",
      "logit_softcapping"
    ]
  },
  "DlinferLinearImpl": {
    "update_weights": [
      "self",
      "weight",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "bias",
      "all_reduce",
      "group",
      "rank",
      "scatter_size"
    ]
  },
  "DlinferLinearBuilder": {
    "build": [
      "in_features",
      "out_features",
      "bias",
      "dtype"
    ]
  },
  "DlinferSoftmaxTopKImpl": {
    "__init__": [
      "self",
      "top_k",
      "dim",
      "n_groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DlinferSoftmaxTopKBuilder": {
    "build": [
      "top_k",
      "dim",
      "n_groups"
    ]
  },
  "DlinferFusedMoEImpl": {
    "__init__": [
      "self",
      "top_k",
      "num_experts",
      "renormalize",
      "ep_size",
      "ep_group"
    ],
    "update_weights": [
      "self",
      "gate_up_weights",
      "down_weights"
    ],
    "ep_expert_list": [
      "self",
      "world_size",
      "rank"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids",
      "gate_up_weights",
      "down_weights",
      "gate_up_bias",
      "down_bias",
      "expert_list",
      "act_func"
    ]
  },
  "DlinferFusedMoEBuilder": {
    "build": [
      "top_k",
      "num_experts",
      "renormalize",
      "hidden_dim",
      "ep_size",
      "ep_group",
      "layer_idx",
      "out_dtype"
    ]
  },
  "MacaOpsBackend": {
    "total_slots": [],
    "get_name": [],
    "get_k_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "get_v_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "update_step_context": [
      "cls",
      "step_context"
    ],
    "build_graph_runner": [
      "model",
      "model_config",
      "cache_config",
      "backend_config",
      "device"
    ],
    "support_ray": []
  },
  "CambOpsBackend": {
    "total_slots": [],
    "get_name": [],
    "get_k_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "get_v_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "update_step_context": [
      "cls",
      "step_context"
    ],
    "build_graph_runner": [
      "model",
      "model_config",
      "cache_config",
      "backend_config",
      "device"
    ],
    "support_ray": []
  },
  "ACL_FORMAT_FRACTAL_NZ": [],
  "nd_to_nz_spec": [
    "tensor"
  ],
  "SocVersion": {
    "device_name": [
      "cls"
    ],
    "is_Ascend310P": [
      "cls"
    ],
    "is_Ascend910": [
      "cls"
    ],
    "soc_version": [
      "cls"
    ],
    "is_A2": [
      "cls"
    ],
    "is_A3": [
      "cls"
    ]
  },
  "DistMeta": {},
  "AscendKVQuantMeta": {
    "set_value": [
      "cls",
      "device",
      "dtype",
      "record_file",
      "total_layers"
    ]
  },
  "AscendOpsBackend": {
    "total_slots": [],
    "max_batches": [],
    "get_name": [],
    "get_k_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "get_v_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "update_step_context": [
      "cls",
      "step_context"
    ],
    "build_graph_runner": [
      "model",
      "model_config",
      "cache_config",
      "backend_config",
      "device"
    ],
    "init": [],
    "ccl_backend": [],
    "device_count": [],
    "support_ray": []
  },
  "DefaultRMSNormImpl": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "residual"
    ]
  },
  "DefaultRMSNormBuilder": {
    "build": [
      "hidden_size",
      "eps"
    ]
  },
  "DefaultLayerNormImpl": {
    "__init__": [
      "self",
      "normalized_shape",
      "eps"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "bias",
      "residual"
    ]
  },
  "DefaultLayerNormBuilder": {
    "build": [
      "normalized_shape",
      "eps"
    ]
  },
  "get_shifts": [
    "bits",
    "device"
  ],
  "unpack_awq": [
    "qweight",
    "qzeros",
    "bits"
  ],
  "dequantize_gemm": [
    "qweight",
    "qzeros",
    "scales",
    "bits",
    "group_size"
  ],
  "DefaultLinearW4A16Impl": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "w_bit",
      "group_size"
    ],
    "forward": [
      "self",
      "x",
      "qweight",
      "scales",
      "qzeros",
      "bias",
      "all_reduce",
      "group"
    ]
  },
  "DefaultLinearW4A16Builder": {
    "build": [
      "in_features",
      "out_features",
      "w_bit",
      "group_size",
      "bias",
      "dtype"
    ]
  },
  "get_masked_input_and_mask": [
    "input",
    "start_index",
    "end_index"
  ],
  "DefaultEmbeddingImpl": {
    "__init__": [
      "self",
      "start_index",
      "end_index"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "all_reduce",
      "group"
    ]
  },
  "DefaultEmbeddingBuilder": {
    "build": [
      "start_index",
      "end_index"
    ]
  },
  "DefaultSiluAndMulImpl": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DefaultSiluAndMulBuilder": {
    "build": [
      "inplace"
    ]
  },
  "DefaultGeluAndMulImpl": {
    "__init__": [
      "self",
      "approximate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DefaultGeluAndMulBuilder": {
    "build": [
      "approximate"
    ]
  },
  "DefaultOpsBackend": {
    "get_name": [],
    "get_layer_impl_builder": [
      "cls",
      "layer_type"
    ],
    "get_k_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "get_v_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "init": [],
    "ccl_backend": []
  },
  "rotate_half": [
    "x"
  ],
  "DefaultApplyRotaryEmbImpl": {
    "forward": [
      "self",
      "query",
      "key",
      "cos",
      "sin",
      "inplace"
    ]
  },
  "DefaultApplyRotaryEmbBuilder": {
    "build": []
  },
  "safe_torch_compile": [],
  "LlamaDynamicNTKScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "base",
      "scaling_factor",
      "max_position_embeddings"
    ],
    "_ntk_inv_freq": [
      "self",
      "seq_len"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "Llama3RotaryEmbeddingImpl": {
    "__init__": [
      "self",
      "dim",
      "base",
      "scaling_factor",
      "low_freq_factor",
      "high_freq_factor",
      "original_max_position_embeddings"
    ]
  },
  "yarn_find_correction_dim": [
    "num_rotations",
    "dim",
    "base",
    "max_position_embeddings"
  ],
  "yarn_find_correction_range": [
    "low_rot",
    "high_rot",
    "dim",
    "base",
    "max_position_embeddings",
    "truncate"
  ],
  "yarn_get_mscale": [
    "scale",
    "mscale"
  ],
  "yarn_linear_ramp_mask": [
    "min",
    "max",
    "dim"
  ],
  "YarnRotaryEmbeddingImpl": {
    "__init__": [
      "self",
      "dim",
      "base",
      "scaling_factor",
      "original_max_position_embeddings",
      "yarn_params"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "LongRoPEScalingRotaryEmbeddingImpl": {
    "__init__": [
      "self",
      "dim",
      "base",
      "max_position_embeddings",
      "longrope_params"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "FopeRotaryEmbeddingImpl": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "scaling_factor",
      "params"
    ],
    "forward": [
      "self",
      "x",
      "position_ids",
      "sin_coef",
      "cos_coef"
    ]
  },
  "DefaultRotaryEmbeddingBuilder": {
    "build": [
      "dim",
      "max_position_embeddings",
      "base",
      "scaling_factor",
      "yarn_params",
      "longrope_params",
      "llama3_params",
      "fope_params",
      "emb_type"
    ]
  },
  "DefaultMultinomialSamplingImpl": {
    "forward": [
      "self",
      "scores",
      "seeds",
      "offsets",
      "indices"
    ]
  },
  "DefaultMultinomialSamplingBuilder": {
    "build": []
  },
  "AlltoAllTokenDispatcher": {
    "__init__": [
      "self",
      "ep_group",
      "num_experts",
      "num_local_experts"
    ],
    "sort_chunks_by_idxs": [
      "self",
      "input",
      "split_sizes",
      "sorted_idxs"
    ],
    "all_to_all": [
      "self",
      "group",
      "input_",
      "output_split",
      "input_split"
    ],
    "preprocess": [
      "self",
      "routing_map",
      "local_expert_indices"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "topk_ids",
      "probs",
      "local_expert_indices"
    ],
    "combine": [
      "self",
      "hidden_states"
    ]
  },
  "_compute_scores": [
    "scoring_func",
    "logits"
  ],
  "get_group_offsets": [
    "n_groups",
    "group_size",
    "device"
  ],
  "DefaultRouterNoauxTCImpl": {
    "__init__": [
      "self",
      "scoring_func",
      "top_k",
      "n_group",
      "topk_group",
      "n_routed_experts",
      "routed_scaling_factor",
      "renormalize",
      "router_n_groups"
    ],
    "_forward_router_n_groups": [
      "self",
      "scores_for_choice"
    ],
    "_forward_default": [
      "self",
      "scores",
      "scores_for_choice",
      "sequence_length"
    ],
    "renorm": [
      "self",
      "topk_weight"
    ],
    "forward": [
      "self",
      "logits",
      "bias"
    ]
  },
  "DefaultRouterNoauxTCBuilder": {
    "build": [
      "scoring_func",
      "top_k",
      "n_group",
      "topk_group",
      "n_routed_experts",
      "routed_scaling_factor",
      "renormalize",
      "router_n_groups"
    ]
  },
  "DefaultLinearImpl": {
    "forward": [
      "self",
      "x",
      "weight",
      "bias",
      "all_reduce",
      "group",
      "rank",
      "scatter_size"
    ]
  },
  "DefaultLinearBuilder": {
    "build": [
      "in_features",
      "out_features",
      "bias",
      "dtype"
    ]
  },
  "DefaultSoftmaxTopKImpl": {
    "__init__": [
      "self",
      "top_k",
      "dim",
      "n_groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DefaultSoftmaxTopKBuilder": {
    "build": [
      "top_k",
      "dim",
      "n_groups"
    ]
  },
  "TritonRMSNormImpl": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "residual"
    ]
  },
  "TritonRMSNormBuilder": {
    "build": [
      "weight",
      "eps"
    ]
  },
  "PackedLoRAInput": {},
  "TritonLoRAImpl": {
    "_make_packed_lora_input": [
      "x",
      "ctx_mgr"
    ],
    "forward": [
      "self",
      "x",
      "lora_A",
      "lora_B",
      "base_output",
      "adapter_info",
      "ctx_mgr",
      "colwise",
      "is_tp"
    ]
  },
  "TritonLoRABuilder": {
    "build": []
  },
  "WarmupMeta": {},
  "WarmupManager": {
    "__init__": [
      "self"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "val"
    ],
    "warmup": [
      "self",
      "warmup_meta"
    ]
  },
  "get_warmup_manager": [],
  "TritonNSAIndexFP8": {
    "__init__": [
      "self",
      "topk",
      "softmax_scale",
      "block_size",
      "fill"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "weights",
      "k_cache",
      "k_s_cache",
      "meta"
    ]
  },
  "TritonNSAIndexFP8Builder": {
    "build": [
      "topk",
      "softmax_scale",
      "block_size",
      "fill"
    ]
  },
  "TritonRMSNormW8A8Impl": {
    "__init__": [
      "self",
      "hidden_size",
      "eps",
      "quant_dtype"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "residual"
    ]
  },
  "TritonLinearW8A8Impl": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "out_dtype",
      "quant_dtype"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "scale",
      "bias",
      "all_reduce",
      "group"
    ]
  },
  "TritonLinearW8A8Builder": {
    "build": [
      "in_features",
      "out_features",
      "bias",
      "dtype",
      "quant_dtype"
    ]
  },
  "wq_gemm_forward": [
    "x",
    "qweight",
    "qzeros",
    "scales",
    "w_bit",
    "group_size",
    "bias",
    "out_features"
  ],
  "TritonSiluAndMulImpl": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TritonSiluAndMulBuilder": {
    "build": [
      "inplace"
    ]
  },
  "TritonLinearBlockedF8Impl": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "block_size",
      "out_dtype"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "scale",
      "bias",
      "all_reduce",
      "group",
      "rank",
      "scatter_size"
    ]
  },
  "TritonLinearBlockedF8Builder": {
    "build": [
      "in_features",
      "out_features",
      "block_size",
      "bias",
      "dtype"
    ]
  },
  "DeepGemmLinearBlockedF8Impl": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "block_size",
      "out_dtype"
    ],
    "warmup": [
      "self",
      "warmup_meta"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "scale",
      "bias",
      "all_reduce",
      "group",
      "rank",
      "scatter_size"
    ]
  },
  "CudaOpsBackend": {
    "get_name": [],
    "get_layer_impl_builder": [
      "cls",
      "layer_type"
    ],
    "get_attention_metadata_cls": [],
    "get_k_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "get_v_block_shape": [
      "block_size",
      "num_heads",
      "head_size",
      "dtype"
    ],
    "update_meta_flashmla": [
      "cls",
      "attn_metadata",
      "model_config",
      "decoding_query_len"
    ],
    "update_meta_flashattn": [
      "cls",
      "attn_metadata",
      "step_context"
    ],
    "update_step_context": [
      "cls",
      "step_context"
    ],
    "build_graph_runner": [
      "model",
      "model_config",
      "cache_config",
      "backend_config",
      "device"
    ],
    "device_count": [],
    "support_ray": []
  },
  "TritonApplyRotaryEmbImpl": {
    "forward": [
      "self",
      "query",
      "key",
      "cos",
      "sin",
      "inplace"
    ]
  },
  "TritonApplyRotaryEmbBuilder": {
    "build": []
  },
  "next_power_of_2": [
    "n"
  ],
  "_false": [],
  "CUDASingleGraphRunner": {
    "__init__": [
      "self",
      "model",
      "max_batches",
      "max_tokens",
      "num_blocks",
      "is_decoding",
      "pool",
      "model_config",
      "device",
      "decode_query_len"
    ],
    "capture": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "CUDAGraphRunner": {
    "__init__": [
      "self",
      "model",
      "model_config",
      "cache_config",
      "backend_config",
      "device"
    ],
    "check_enable_graph": [
      "self"
    ],
    "_try_compile_model_once": [
      "self"
    ],
    "_get_capture_tokens": [
      "self",
      "batch_size"
    ],
    "get_graph_key": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "_prepare_inputs": [
      "self"
    ],
    "_get_max_tokens": [
      "self",
      "graph_key",
      "input_ids",
      "q_seqlens"
    ],
    "__call__": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "reset": [
      "self"
    ],
    "update_inputs": [
      "self",
      "inputs"
    ],
    "get_capture_batch_sizes": [
      "self"
    ]
  },
  "TritonMultinomialSamplingImpl": {
    "forward": [
      "self",
      "scores",
      "seeds",
      "offsets",
      "indices"
    ]
  },
  "TritonMultinomialSamplingBuilder": {
    "build": []
  },
  "_buffer_normal": [],
  "_buffer_low_latency": [],
  "_buffer_common": [],
  "get_buffer_common": [
    "group",
    "num_max_dispatch_tokens_per_rank",
    "hidden",
    "num_experts",
    "hidden_bytes"
  ],
  "get_buffer_normal": [
    "group",
    "hidden_bytes"
  ],
  "get_buffer_low_latency": [
    "group",
    "num_max_dispatch_tokens_per_rank",
    "hidden",
    "num_experts"
  ],
  "DeepEPTokenDispatcher": {
    "__init__": [
      "self",
      "group",
      "num_experts",
      "num_local_experts",
      "hidden_size",
      "params_dtype",
      "num_max_dispatch_tokens_per_rank"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "topk_idx",
      "topk_weights",
      "expert_list",
      "previous_event"
    ],
    "dispatch_normal": [
      "self",
      "x",
      "topk_idx",
      "topk_weights",
      "num_experts",
      "previous_event"
    ],
    "dispatch_normal_async": [
      "self",
      "x",
      "topk_idx",
      "topk_weights",
      "num_experts",
      "previous_event",
      "async_finish"
    ],
    "combine": [
      "self",
      "hidden_states"
    ],
    "combine_normal": [
      "self",
      "x",
      "handle",
      "previous_event"
    ],
    "combine_normal_async": [
      "self",
      "x",
      "handle",
      "previous_event",
      "async_finish"
    ],
    "release": [
      "self"
    ],
    "get_number_of_tokens_per_expert": [
      "self"
    ],
    "get_permuted_hidden_states_by_experts": [
      "self",
      "hidden_states",
      "topk_idx",
      "topk_weights",
      "num_experts"
    ],
    "get_restored_hidden_states_by_experts": [
      "self",
      "hidden_states",
      "reversed_mapping_for_combine",
      "hidden_shape_before_permute",
      "dispatched_routing_map",
      "topk_weights"
    ]
  },
  "DeepEPTokenDispatcherLowLatency": {
    "__init__": [
      "self",
      "group",
      "num_experts",
      "num_local_experts",
      "hidden_size",
      "params_dtype",
      "return_recv_hook"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "topk_idx",
      "topk_weights",
      "num_experts"
    ],
    "dispatch_async": [
      "self",
      "hidden_states",
      "topk_idx",
      "num_experts",
      "use_fp8",
      "async_finish"
    ],
    "combine": [
      "self",
      "hidden_states",
      "topk_idx",
      "topk_weights"
    ],
    "combine_async": [
      "self",
      "hidden_states",
      "topk_idx",
      "topk_weights",
      "handle",
      "async_finish"
    ]
  },
  "TokenDispatcherBuilder": {
    "build": [
      "group",
      "num_experts",
      "num_local_experts",
      "hidden_size",
      "params_dtype"
    ]
  },
  "TritonFlashAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_dim",
      "scale",
      "num_kv_heads",
      "v_head_dim",
      "causal",
      "sliding_window",
      "logit_softcapping"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "q_start_loc",
      "q_seqlens",
      "kv_start_loc",
      "kv_seqlens",
      "max_q_seqlen"
    ]
  },
  "TritonFlashAttentionBuilder": {
    "build": [
      "num_heads",
      "head_dim",
      "scale",
      "num_kv_heads",
      "v_head_dim",
      "causal",
      "sliding_window",
      "logit_softcapping"
    ]
  },
  "is_power_of_two": [
    "n"
  ],
  "TritonRouterNoauxTCImpl": {
    "__init__": [
      "self",
      "scoring_func",
      "top_k",
      "n_group",
      "topk_group",
      "n_routed_experts",
      "routed_scaling_factor",
      "renormalize",
      "router_n_groups"
    ],
    "should_enable_custom_kernel": [
      "self"
    ],
    "forward": [
      "self",
      "logits",
      "bias"
    ]
  },
  "TritonRouterNoauxTCBuilder": {
    "build": [
      "scoring_func",
      "top_k",
      "n_group",
      "topk_group",
      "n_routed_experts",
      "routed_scaling_factor",
      "renormalize",
      "router_n_groups"
    ]
  },
  "TritonFusedMoEImpl": {
    "__init__": [
      "self",
      "top_k",
      "num_experts",
      "renormalize"
    ],
    "update_weights": [
      "self",
      "gate_up_weights",
      "down_weights"
    ],
    "ep_expert_list": [
      "self",
      "world_size",
      "rank"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids",
      "gate_up_weights",
      "down_weights",
      "gate_up_bias",
      "down_bias",
      "expert_list",
      "act_func"
    ]
  },
  "FusedMoENormal": {
    "__init__": [
      "self",
      "ep_size",
      "ep_group",
      "num_experts",
      "hidden_dim",
      "layer_index",
      "top_k",
      "out_dtype"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids",
      "up_weights",
      "down_weights",
      "expert_list"
    ],
    "capture": [
      "self"
    ],
    "wait": [
      "self",
      "event"
    ],
    "dispatch_async": [
      "self",
      "x",
      "topk_idx",
      "topk_weights",
      "num_experts",
      "previous_event",
      "async_finish"
    ],
    "combine_async": [
      "self",
      "x",
      "handle",
      "previous_event",
      "async_finish"
    ],
    "release": [
      "self"
    ],
    "fusedmoe_forward": [
      "self",
      "state",
      "up_weight",
      "down_weight"
    ]
  },
  "_disposible_tensor": [
    "tensor"
  ],
  "dispatch_ll": [
    "self",
    "hidden_states",
    "topk_idx",
    "topk_weights",
    "num_experts",
    "use_fp8"
  ],
  "dispatch_async_ll": [
    "self",
    "hidden_states",
    "topk_idx",
    "num_experts",
    "use_fp8",
    "async_finish"
  ],
  "FusedMoELowLatency": {
    "__init__": [
      "self",
      "ep_size",
      "ep_group",
      "num_experts",
      "hidden_dim",
      "layer_index",
      "out_dtype"
    ],
    "experts": [
      "self",
      "hidden_states",
      "gate_up_weight",
      "gate_down_weight",
      "masked_m",
      "expected_m"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids",
      "up_weights",
      "down_weights",
      "expert_list"
    ],
    "wait": [
      "self",
      "event"
    ],
    "dispatch_async": [
      "self",
      "hidden_states",
      "topk_idx",
      "num_experts",
      "use_fp8",
      "async_finish"
    ],
    "combine_async": [
      "self",
      "hidden_states",
      "topk_idx",
      "topk_weights",
      "handle",
      "async_finish"
    ],
    "fusedmoe_forward": [
      "self",
      "state",
      "up_weight",
      "down_weight"
    ]
  },
  "build_deepep_moe": [
    "low_latency_mode",
    "ep_size",
    "ep_group",
    "num_experts",
    "hidden_dim",
    "top_k",
    "layer_idx",
    "out_dtype"
  ],
  "FusedMoEEPImpl": {
    "__init__": [
      "self",
      "ep_size",
      "ep_group",
      "top_k",
      "num_experts",
      "hidden_dim",
      "renormalize",
      "layer_idx",
      "out_dtype"
    ],
    "update_weights": [
      "self",
      "gate_up_weights",
      "down_weights"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids",
      "gate_up_weights",
      "down_weights",
      "gate_up_bias",
      "down_bias",
      "expert_list",
      "act_func"
    ],
    "ep_expert_list": [
      "self",
      "world_size",
      "rank"
    ],
    "do_renormalize": [
      "self",
      "topk_weights"
    ],
    "fusedmoe_build": [
      "self",
      "low_latency_mode"
    ]
  },
  "TritonFusedMoEBuilder": {
    "build": [
      "top_k",
      "num_experts",
      "renormalize",
      "hidden_dim",
      "ep_size",
      "ep_group",
      "layer_idx",
      "out_dtype"
    ]
  },
  "TritonFusedMoEW8A8Impl": {
    "__init__": [
      "self",
      "top_k",
      "num_experts",
      "renormalize",
      "out_dtype",
      "quant_dtype"
    ],
    "update_weights": [
      "self",
      "gate_up_weights",
      "down_weights",
      "gate_up_scale",
      "down_scale"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids",
      "gate_up_weights",
      "gate_up_scale",
      "down_weights",
      "down_scale",
      "expert_list"
    ]
  },
  "TritonFusedMoEW8A8Builder": {
    "build": [
      "top_k",
      "num_experts",
      "renormalize",
      "out_dtype",
      "quant_dtype"
    ]
  },
  "TritonFusedMoEBlockedF8Impl": {
    "__init__": [
      "self",
      "top_k",
      "num_experts",
      "renormalize",
      "block_size",
      "out_dtype"
    ],
    "ep_expert_list": [
      "self",
      "world_size",
      "rank"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids",
      "gate_up_weights",
      "gate_up_scale",
      "down_weights",
      "down_scale",
      "gate_up_bias",
      "down_bias",
      "expert_list",
      "act_func"
    ]
  },
  "FusedDeepEpMoEBlockedF8Impl": {
    "__init__": [
      "self",
      "ep_size",
      "ep_group",
      "top_k",
      "num_experts",
      "hidden_dim",
      "renormalize",
      "block_size",
      "out_dtype",
      "layer_idx"
    ],
    "ep_expert_list": [
      "self",
      "world_size",
      "rank"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids",
      "gate_up_weights",
      "gate_up_scale",
      "down_weights",
      "down_scale",
      "gate_up_bias",
      "down_bias",
      "expert_list",
      "act_func"
    ],
    "do_renormalize": [
      "self",
      "topk_weights"
    ],
    "fusedmoe_build": [
      "self",
      "low_latency_mode"
    ]
  },
  "TritonFusedMoEBlockedF8Builder": {
    "build": [
      "top_k",
      "num_experts",
      "hidden_dim",
      "renormalize",
      "block_size",
      "ep_size",
      "ep_group",
      "out_dtype",
      "layer_idx",
      "custom_gateup_act"
    ]
  },
  "split_inputs_by_attn_tp": [
    "hidden_states",
    "topk_weights",
    "topk_ids"
  ],
  "gather_outputs_by_attn_tp": [
    "out_states",
    "split_size"
  ],
  "TritonAttentionMetadata": {},
  "_cdiv": [
    "a",
    "b"
  ],
  "TritonAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "v_head_size",
      "alibi",
      "sliding_window",
      "logit_softcapping",
      "causal",
      "block_sparse_size"
    ],
    "_get_max_q_seqlen": [
      "self",
      "query",
      "attn_metadata"
    ],
    "_get_fill_meta": [
      "self",
      "key",
      "attn_metadata",
      "max_q_seqlen"
    ],
    "_fill_kv_cache_impl": [
      "self",
      "key",
      "value",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "max_q_seqlen",
      "k_scales_zeros",
      "v_scales_zeros"
    ],
    "_forward_decoding": [
      "self",
      "query",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "max_q_seqlen",
      "k_scales_zeros",
      "v_scales_zeros",
      "learnable_sink"
    ],
    "_forward_prefill": [
      "self",
      "query",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "max_q_seqlen",
      "k_scales_zeros",
      "v_scales_zeros",
      "learnable_sink"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "k_scales_zeros",
      "v_scales_zeros",
      "learnable_sink",
      "inplace"
    ]
  },
  "use_fa3": [],
  "use_fa3_warning": [],
  "_enable_fa3": [
    "alibi",
    "learnable_sink",
    "block_sparse_size",
    "head_size"
  ],
  "_normalize_sliding_window": [
    "sliding_window"
  ],
  "TritonAttentionBuilder": {
    "build": [
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "v_head_size",
      "alibi",
      "sliding_window",
      "logit_softcapping",
      "causal",
      "use_flash_mla",
      "learnable_sink",
      "block_sparse_size"
    ]
  },
  "_try_dynamic_compile": [
    "func"
  ],
  "NSAIndicesUpdater": {
    "__init__": [
      "self"
    ],
    "_update_decode_impl": [
      "self",
      "nsa_indices",
      "block_offsets",
      "block_size"
    ],
    "update_decode": [
      "self",
      "nsa_indices",
      "block_offsets",
      "block_size"
    ],
    "_update_prefill_impl": [
      "self",
      "nsa_indices",
      "q_seqlens",
      "cu_seqlens_k"
    ],
    "update_prefill": [
      "self",
      "nsa_indices",
      "q_seqlens",
      "cu_seqlens_k"
    ],
    "build": []
  },
  "FlashMLAImpl": {
    "_MLA_HEAD_ALIGNMENT": [],
    "_MLA_NOPE_SIZE": [],
    "_MLA_SCALE_SIZE": [],
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "v_head_size",
      "alibi",
      "sliding_window",
      "logit_softcapping",
      "causal",
      "use_fa3"
    ],
    "_get_flash_mla_sparse_fwd": [
      "self"
    ],
    "flash_mla_decoding": [
      "self",
      "query",
      "k_cache",
      "nsa_indices",
      "attn_metadata"
    ],
    "_prefill_sparse": [
      "self",
      "query",
      "flatten_k",
      "nsa_indices",
      "attn_metadata"
    ],
    "_prefill_triton": [
      "self",
      "query",
      "flatten_k",
      "flatten_v",
      "attn_metadata"
    ],
    "_prefill_fa3": [
      "self",
      "query",
      "flatten_k",
      "attn_metadata"
    ],
    "run_flatten_kv_cache": [
      "self",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "out_dtype",
      "is_nsa",
      "k_scales_zeros",
      "v_scales_zeros"
    ],
    "_get_max_q_seqlen": [
      "self",
      "query",
      "attn_metadata"
    ],
    "_fill_kv_cache_impl": [
      "self",
      "key",
      "value",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "max_q_seqlen",
      "k_scales_zeros",
      "v_scales_zeros"
    ],
    "_forward_decoding": [
      "self",
      "query",
      "k_cache",
      "attn_metadata",
      "nsa_indices"
    ],
    "_forward_prefill": [
      "self",
      "query",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "nsa_indices",
      "k_scales_zeros",
      "v_scales_zeros"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "k_scales_zeros",
      "v_scales_zeros",
      "nsa_indices"
    ]
  },
  "FA3Impl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "v_head_size",
      "alibi",
      "sliding_window",
      "logit_softcapping",
      "causal"
    ],
    "_get_max_q_seqlen": [
      "self",
      "query",
      "attn_metadata"
    ],
    "_normalize_sliding_window": [
      "self",
      "sliding_window"
    ],
    "_decoding_speculative": [
      "self",
      "query",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "max_q_seqlen"
    ],
    "_decoding_standard": [
      "self",
      "query",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "max_q_seqlen",
      "k_scales_zeros",
      "v_scales_zeros"
    ],
    "_forward_decoding": [
      "self",
      "query",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "max_q_seqlen",
      "k_scales_zeros",
      "v_scales_zeros"
    ],
    "_forward_prefill": [
      "self",
      "query",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "max_q_seqlen",
      "k_scales_zeros",
      "v_scales_zeros"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "k_cache",
      "v_cache",
      "attn_metadata",
      "k_scales_zeros",
      "v_scales_zeros",
      "learnable_sink",
      "inplace"
    ]
  },
  "_get_rewrite_qualname": [
    "origin_qualname",
    "module_map"
  ],
  "_class_from_qualname": [
    "qualname"
  ],
  "_find_rewrite_module_qualname": [
    "model",
    "module_map"
  ],
  "get_rewrite_cls": [
    "model",
    "module_map"
  ],
  "_get_module_map": [],
  "update_custom_module_map": [
    "module_map_path"
  ],
  "_get_model_class": [
    "config",
    "module_map"
  ],
  "build_model_from_hf_config": [
    "model_config",
    "dtype",
    "device",
    "ctx_mgr",
    "build_model_ctx"
  ],
  "build_patched_model": [
    "config",
    "device",
    "build_model_ctx"
  ],
  "add_adapters": [
    "model",
    "adapters",
    "dtype",
    "device"
  ],
  "BUILD_MODEL_CTX": [],
  "build_model_context": [
    "ctx"
  ],
  "get_build_model_context": [],
  "add_prefix": [
    "name",
    "prefix"
  ],
  "WhisperAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "bias",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "WhisperEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "InternLM2ForRewardModel": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_lora_weights": [
      "self",
      "weights",
      "adapter_id"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "InternVisionEmbeddings": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "_get_pos_embed": [
      "self",
      "pos_embed",
      "H",
      "W"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "InternVisionPatchModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "Qwen2Attention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "Qwen2MLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "Qwen2Model": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "Qwen2ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GatedDeltaMeta": {
    "__init__": [
      "self",
      "num_tokens",
      "conv_kernel_size",
      "state_ids",
      "attn_metadata"
    ]
  },
  "CausalConv1dFunc": {
    "__init__": [
      "self",
      "activation"
    ],
    "conv1d_func": [
      "self",
      "x",
      "weight",
      "bias",
      "conv_state",
      "gated_delta_meta"
    ],
    "conv1d_update": [
      "self",
      "x",
      "weight",
      "bias",
      "conv_state"
    ],
    "__call__": [
      "self",
      "x",
      "weight",
      "bias",
      "conv_state",
      "gated_delta_meta"
    ]
  },
  "GatedDelta": {
    "__init__": [
      "self",
      "use_qk_l2norm_in_kernel"
    ],
    "__call__": [
      "self",
      "query",
      "key",
      "value",
      "g",
      "beta",
      "recurrent_state",
      "gated_delta_meta"
    ]
  },
  "build_rmsnorm_gated": [
    "hidden_size",
    "eps"
  ],
  "CausalConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "groups",
      "bias",
      "split",
      "device",
      "dtype"
    ],
    "make_weight": [
      "in_channels",
      "out_channels",
      "kernel_size",
      "groups",
      "bias",
      "device",
      "dtype"
    ],
    "register_weight": [
      "self",
      "weight",
      "bias"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "x",
      "conv_state",
      "gated_delta_meta"
    ]
  },
  "Qwen3NextGatedDeltaNet": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "get_A_log_exp": [
      "self"
    ],
    "make_params": [
      "self",
      "num_v_heads",
      "device"
    ],
    "weight_loader_qkvz": [
      "self",
      "param",
      "loaded_weight"
    ],
    "weight_loader_a_dt": [
      "self",
      "param",
      "loaded_weight"
    ],
    "fix_query_key_value_ordering": [
      "self",
      "mixed_qkvz",
      "mixed_ba"
    ],
    "_load_state": [
      "self",
      "past_key_value",
      "gated_delta_meta"
    ],
    "_store_state": [
      "self",
      "conv_state",
      "recurrent_state",
      "past_key_value",
      "gated_delta_meta"
    ],
    "forward": [
      "self",
      "hidden_states",
      "past_key_value",
      "gated_delta_meta"
    ]
  },
  "Qwen3NextAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "Qwen3NextMLP": {
    "__init__": [
      "self",
      "config",
      "intermediate_size",
      "dtype",
      "device",
      "is_tp",
      "all_reduce"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3NextSparseMoeBlock": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen3NextDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata",
      "gated_delta_meta"
    ]
  },
  "Qwen3NextModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "state_ids",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "Qwen3NextForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "state_ids"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "make_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "fill_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "_load_weight_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "expert_params_mapping"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen2_5_PatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "temporal_patch_size",
      "in_channels",
      "embed_dim",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen2_5_VisionRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta",
      "device"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "Qwen2_5_VLVisionAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "Qwen2_5_VLMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2_5_VLVisionBlock": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "Qwen2_5_VLPatchMerger": {
    "__init__": [
      "self",
      "dim",
      "context_dim",
      "spatial_merge_size",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2_5_VisionTransformerPretrainedModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "get_window_index": [
      "self",
      "grid_thw"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb",
      "window_index",
      "cu_window_seqlens"
    ]
  },
  "Qwen2_5_VLForConditionalGeneration": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "mrope_position_ids",
      "pixel_values",
      "vis_cu_seqlens",
      "vis_pos_emb",
      "window_index",
      "cu_window_seqlens",
      "image_mask"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "make_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "fill_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "_get_model_metas": [
      "self",
      "context"
    ],
    "_update_model_meta_decoding": [
      "self",
      "context"
    ],
    "_get_multimodal_pos_ids": [
      "self",
      "grid_thw",
      "device"
    ],
    "_update_model_meta_prefilling": [
      "self",
      "context"
    ],
    "update_model_metas": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "Qwen2_5_VLInputProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "MistralAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "MistralMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MistralDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "MistralModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "MistralForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GemmaAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "rotary_pos_emb_local",
      "past_key_value",
      "attn_metadata",
      "global_attn_masks",
      "local_attn_masks"
    ],
    "naive_attn_with_masks": [
      "self",
      "q",
      "k",
      "v",
      "out",
      "attn_masks",
      "seq_lens"
    ]
  },
  "GemmaMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GemmaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "rotary_pos_emb_local",
      "residual",
      "attn_metadata",
      "global_attn_masks",
      "local_attn_masks"
    ]
  },
  "Gemma3TextScaledWordEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "padding_idx",
      "dtype",
      "embed_scale"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "GemmaModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "global_attn_masks",
      "local_attn_masks"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "GemmaForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "global_attn_masks",
      "local_attn_masks"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "update_weights": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "sparsemixer": [
    "scores",
    "top_k",
    "jitter_eps"
  ],
  "PhiMoEAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "PhiMoESparseMoeBlock": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "PhiMoEDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "PhiMoEModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "PhiMoEForCausalLM": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Gating": {
    "__init__": [
      "self",
      "hidden_size",
      "expansion_factor",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CrossAttentionPooling": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "batched_tokens"
    ]
  },
  "NORM2FN": [],
  "pre_rms_norm": [
    "q",
    "k"
  ],
  "post_rms_norm": [
    "q",
    "k",
    "weight_q",
    "weight_k",
    "variance",
    "eps",
    "embed_dim",
    "dtype"
  ],
  "InternAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "pre_rms_norm": [
      "self",
      "q",
      "k"
    ],
    "post_rms_norm": [
      "self",
      "q",
      "k",
      "variance",
      "dtype"
    ],
    "qkv_norm": [
      "self",
      "q",
      "k"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "InternMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "InternVisionEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "_attn": [
      "self",
      "hidden_states"
    ],
    "_mlp": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "InternVisionEncoder": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "inputs_embeds"
    ]
  },
  "InternVisionModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "InternVLChatModel": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "compile_model": [
      "self"
    ],
    "_mark_dynamic_once": [
      "self",
      "pixel_values",
      "dims"
    ],
    "pixel_shuffle": [
      "self",
      "x",
      "scale_factor"
    ],
    "extract_feature": [
      "self",
      "pixel_values"
    ],
    "compress_visual_tokens_in_sentence": [
      "self",
      "input_embeds",
      "input_ids",
      "img_context_token_id",
      "gate_result"
    ],
    "get_image_num_per_sample": [
      "self",
      "input_ids",
      "img_context_token_id"
    ],
    "split_and_merge": [
      "self",
      "features",
      "split_sizes"
    ],
    "extract_feature_flash": [
      "self",
      "pixel_values",
      "lengths"
    ],
    "extract_and_compress": [
      "self",
      "pixel_values",
      "input_ids",
      "img_context_token_id"
    ],
    "update_forward_inputs": [
      "self",
      "input_ids",
      "new_seqlens",
      "context"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "pixel_values",
      "image_mask",
      "inputs_embeds",
      "vision_embedding_indexing",
      "text_embedding_indexing",
      "image_token_id",
      "context"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_lora_weights": [
      "self",
      "weights",
      "adapter_id"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "InternVLInputProcessor": {
    "__init__": [
      "self",
      "config",
      "dtype"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "Qwen3VLTextRotaryEmbedding": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "_pack_for_trans5": [
      "self",
      "config"
    ],
    "apply_interleaved_mrope": [
      "self",
      "freqs",
      "mrope_section"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "Qwen3VLTextModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "mrope_position_ids",
      "visual_pos_masks",
      "deepstack_visual_embeds"
    ],
    "_deepstack_process": [
      "self",
      "hidden_states",
      "visual_pos_masks",
      "visual_embeds"
    ]
  },
  "Qwen3VLVisionPatchEmbed": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen3VLVisionMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3VLVisionBlock": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "Qwen3VLVisionPatchMerger": {
    "__init__": [
      "self",
      "config",
      "use_postshuffle_norm",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3VLVisionModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device",
      "prefix"
    ],
    "rot_pos_ids": [
      "h",
      "w",
      "spatial_merge_size"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "fast_pos_embed_interpolate": [
      "self",
      "grid_thw"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb",
      "pos_embeds"
    ]
  },
  "Qwen3VLForConditionalGeneration": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "mrope_position_ids",
      "pixel_values",
      "vis_cu_seqlens",
      "vis_pos_emb",
      "image_mask",
      "pos_embeds",
      "grid_thw"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "rename_weight": [
      "cls",
      "name"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "make_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "fill_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "_get_model_metas": [
      "self",
      "context"
    ],
    "_update_model_meta_decoding": [
      "self",
      "context"
    ],
    "_get_multimodal_pos_ids": [
      "self",
      "grid_thw",
      "device"
    ],
    "_update_model_meta_prefilling": [
      "self",
      "context"
    ],
    "update_model_metas": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "Glm4MoeAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "Glm4MoeMLP": {
    "__init__": [
      "self",
      "config",
      "intermediate_size",
      "dtype",
      "device",
      "is_tp",
      "all_reduce"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Glm4MoE": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Glm4MoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "Glm4MoeModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "_build_rotary_embedding": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ]
  },
  "Glm4MoeForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "_load_weight_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "expert_params_mapping"
    ],
    "_load_weight_fused_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "InternLM3Attention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "InternLM3MLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InternLM3DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "InternLM3Model": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "InternLM3ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "update_weights": [
      "self"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "InternLM2Attention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "InternLM2MLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InternLM2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "InternLM2Model": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "InternLM2ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_lora_weights": [
      "self",
      "weights",
      "adapter_id"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "InternVLVisionPatchEmbeddings": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "InternVLVisionEmbeddings": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "interpolate_pos_encoding": [
      "self",
      "embeddings",
      "height",
      "width"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "InternVLVisionAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "pre_rms_norm": [
      "self",
      "q",
      "k"
    ],
    "post_rms_norm": [
      "self",
      "q",
      "k",
      "variance",
      "dtype"
    ],
    "qkv_norm": [
      "self",
      "q",
      "k"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "InternVLVisionMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "InternVLVisionLayer": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "_attn": [
      "self",
      "hidden_states"
    ],
    "_mlp": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "InternVLVisionEncoder": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "inputs_embeds"
    ]
  },
  "InternVLVisionModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "InternVLMultiModalProjector": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "InternVLForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "compile_model": [
      "self"
    ],
    "_mark_dynamic_once": [
      "self",
      "pixel_values",
      "dims"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "vision_feature_layer",
      "vision_feature_select_strategy"
    ],
    "pixel_shuffle": [
      "self",
      "vision_features",
      "scale_factor"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "pixel_values",
      "image_mask",
      "inputs_embeds"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_lora_weights": [
      "self",
      "weights",
      "adapter_id"
    ],
    "rename_weight": [
      "cls",
      "name"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "InternVLProcessor": {
    "__init__": [
      "self",
      "config",
      "dtype"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "Qwen2MoeAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "Qwen2MoeMLP": {
    "__init__": [
      "self",
      "config",
      "intermediate_size",
      "dtype",
      "device",
      "is_tp",
      "all_reduce"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2MoeSparseMoeBlock": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen2MoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "Qwen2MoeModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "Qwen2MoeForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "_load_weight_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "expert_params_mapping"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DeepseekV2BMM": {
    "__init__": [
      "self",
      "batch",
      "in_features",
      "out_features",
      "dtype",
      "device"
    ],
    "create_weight": [
      "self",
      "batch",
      "in_features",
      "out_features",
      "dtype",
      "device"
    ],
    "weight_loader": [
      "self",
      "param",
      "weight"
    ],
    "forward": [
      "self",
      "x",
      "output"
    ]
  },
  "DeepseekV2Attention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "DeepseekV2MoE": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DeepseekV2MLP": {
    "__init__": [
      "self",
      "config",
      "intermediate_size",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DeepseekV2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ]
  },
  "SharedHead": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DeepSeekMultiTokenPredictorLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "previous_hidden_states",
      "past_key_value",
      "inputs_embeds",
      "attn_metadata",
      "spec_step_index"
    ]
  },
  "DeepSeekMultiTokenPredictor": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "previous_hidden_states",
      "past_key_values",
      "inputs_embeds",
      "attn_metadata",
      "spec_step_idx"
    ],
    "get_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ]
  },
  "DeepseekMTPModel": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "get_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "target_hidden_states",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "make_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "fill_buffers_cudagraph": [
      "self",
      "graph_meta",
      "input_ids"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "_load_weight_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "expert_params_mapping"
    ],
    "_load_weight_attention": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "update_pe_mapping"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_rewrite_spec_layer_name": [
      "self",
      "spec_layer",
      "name"
    ]
  },
  "_is_baichuan_13b": [
    "config"
  ],
  "BaichuanAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "MLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "BaichuanModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "BaichuanForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DeepseekAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "DeepseekMoE": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DeepseekMLP": {
    "__init__": [
      "self",
      "config",
      "intermediate_size",
      "dtype",
      "device",
      "is_tp",
      "all_reduce"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DeepseekDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "DeepseekModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "DeepseekForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "_load_weight_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "expert_params_mapping"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LMDEPLOY_PYTORCH_MODEL_PATH": [],
  "MODULE_MAP": [],
  "ASCEND_MODULE_MAP": [],
  "MACA_MODULE_MAP": [],
  "CAMB_MODULE_MAP": [],
  "DEVICE_SPECIAL_MODULE_MAP": [],
  "CUSTOM_MODULE_MAP": [],
  "_apply_mrope_selection": [
    "hidden_states",
    "mrope_position_ids",
    "mrope_section",
    "position_ids",
    "rotary_emb_func"
  ],
  "Glm4vTextModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "mrope_position_ids"
    ]
  },
  "Glm4VisionMLP": {
    "__init__": [
      "self",
      "config",
      "bias",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Glm4vVisionPatchEmbed": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Glm4vVisionRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta",
      "device"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "Glm4vVisionPatchMerger": {
    "__init__": [
      "self",
      "dim",
      "context_dim",
      "hidden_act",
      "bias",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "Glm4vVisionEmbeddings": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "embeddings",
      "lengths",
      "image_shapes",
      "h_coords",
      "w_coords"
    ]
  },
  "Glm4vVisionAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "Glm4vVisionBlock": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb",
      "residual"
    ]
  },
  "Glm4vVisionModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb",
      "grid_thw",
      "image_type_ids"
    ]
  },
  "Glm4vForConditionalGeneration": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "mrope_position_ids",
      "pixel_values",
      "vis_cu_seqlens",
      "vis_pos_emb",
      "image_type_ids",
      "grid_thw",
      "image_mask"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "rename_weight": [
      "cls",
      "name"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "make_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "fill_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "_get_model_metas": [
      "self",
      "context"
    ],
    "_update_model_meta_decoding": [
      "self",
      "context"
    ],
    "_get_multimodal_pos_ids": [
      "self",
      "grid_thw",
      "device"
    ],
    "_update_model_meta_prefilling": [
      "self",
      "context"
    ],
    "update_model_metas": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "Glm4vInputProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "SDARAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "SDARMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SDARDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "SDARModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "SDARForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MixtralAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "MixtralSparseMoeBlock": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MixtralDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "MixtralModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "MixtralForCausalLM": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Llama4TextAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "Llama4TextMLP": {
    "__init__": [
      "self",
      "config",
      "intermediate_size",
      "dtype",
      "device",
      "is_tp",
      "all_reduce"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Llama4TextMoe": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Llama4TextDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "Llama4TextModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "build_llama4_rotary_embedding": [
      "config"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "position_ids",
      "past_key_values",
      "attn_metadata"
    ]
  },
  "Llama4ForCausalLM": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "position_ids",
      "past_key_values",
      "attn_metadata"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ]
  },
  "Llama4MultiModalProjector": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "Llama4UnfoldConvolution": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Llama4VisionRotaryEmbedding": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "reshape_for_broadcast": [
    "freqs_ci",
    "query"
  ],
  "vision_apply_rotary_emb": [
    "query",
    "key",
    "freqs_ci"
  ],
  "Llama4VisionAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "freqs_ci"
    ]
  },
  "Llama4VisionMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Llama4VisionEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_state",
      "freqs_ci"
    ]
  },
  "Llama4VisionEncoder": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "freqs_ci"
    ]
  },
  "pixel_shuffle": [
    "input_tensor",
    "shuffle_ratio"
  ],
  "Llama4VisionMLP2": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Llama4VisionPixelShuffleMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "encoded_patches"
    ]
  },
  "Llama4VisionModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "Llama4ForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "_update_quant_config": [
      "config"
    ],
    "get_image_features": [
      "self",
      "pixel_values"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "pixel_values",
      "image_mask"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "Llama4InputProcessor": {
    "__init__": [
      "self",
      "config",
      "dtype"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "Gemma3RMSNorm": {
    "__init__": [
      "self",
      "dim",
      "eps"
    ],
    "_norm": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "Gemma3MultiModalProjector": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "vision_outputs"
    ]
  },
  "Gemma3VLInputProcessor": {
    "__init__": [
      "self",
      "config",
      "dtype"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "Gemma3ForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_image_features": [
      "self",
      "pixel_values"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "pixel_values",
      "image_mask",
      "inputs_embeds",
      "vision_embedding_indexing",
      "text_embedding_indexing"
    ],
    "prepare_attn_masks": [
      "self",
      "input_ids",
      "positions",
      "mask_dtype"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "tie_weights": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "Qwen3MoeAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "Qwen3MoeMLP": {
    "__init__": [
      "self",
      "config",
      "intermediate_size",
      "dtype",
      "device",
      "is_tp",
      "all_reduce",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3MoeSparseMoeBlock": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "all_routed_experts"
    ]
  },
  "Qwen3MoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata",
      "all_routed_experts"
    ]
  },
  "Qwen3MoeModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "all_routed_experts"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "Qwen3MoeForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "_load_weight_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "expert_params_mapping"
    ],
    "_load_weight_fused_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "SiglipVisionEmbeddings": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "interpolate_pos_encoding": [
      "self",
      "embeddings",
      "height",
      "width"
    ],
    "forward": [
      "self",
      "pixel_values",
      "interpolate_pos_encoding"
    ]
  },
  "SiglipAttention": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SiglipMLP": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SiglipEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SiglipEncoder": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "inputs_embeds"
    ]
  },
  "SiglipMultiheadAttentionPoolingHead": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "SiglipVisionTransformer": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "pixel_values",
      "interpolate_pos_encoding"
    ]
  },
  "SiglipVisionModel": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "interpolate_pos_encoding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "QTensor": {
    "__post_init__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "QRMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps",
      "quant_dtype"
    ],
    "from_float": [
      "cls",
      "mod",
      "initialization",
      "quant_dtype"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "QLinear": {
    "__constants__": [],
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "device",
      "dtype",
      "quant_dtype"
    ],
    "from_float": [
      "cls",
      "mod",
      "initialization",
      "quant_dtype"
    ],
    "forward": [
      "self",
      "input"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "MiniCPMV26Attention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "MiniCPMV26MLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MiniCPMV26DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "MiniCPMV26Model": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "MiniCPMVForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "SDARMoeAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "SDARMoeMLP": {
    "__init__": [
      "self",
      "config",
      "intermediate_size",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SDARMoeSparseMoeBlock": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SDARMoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "SDARMoeModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "SDARMoeForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "_load_weight_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "expert_params_mapping"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3VLMoeTextModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "mrope_position_ids",
      "visual_pos_masks",
      "deepstack_visual_embeds"
    ],
    "_deepstack_process": [
      "self",
      "hidden_states",
      "visual_pos_masks",
      "visual_embeds"
    ]
  },
  "Qwen3VLMoeForConditionalGeneration": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device",
      "prefix"
    ],
    "_load_weight_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "expert_params_mapping"
    ],
    "_load_weight_fused_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "fused_expert_params_mapping"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "QWenAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "QWenMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QWenBlock": {
    "__init__": [
      "self",
      "config",
      "layer_number",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "QWenModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "QWenLMHeadModel": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MlpProjector": {
    "__init__": [
      "self",
      "cfg",
      "dtype"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DeepseekVLV2ForCausalLM": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "_init_vision_module": [
      "self",
      "dtype"
    ],
    "prepare_inputs_embeds": [
      "self",
      "input_ids",
      "images",
      "images_seq_mask",
      "images_spatial_crop"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "pixel_values",
      "image_mask",
      "images_spatial_crop",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "DeepSeekVLV2InputProcessor": {
    "__init__": [
      "self",
      "config",
      "dtype"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "MiniCPMAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "MiniCPMMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MiniCPMDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "MiniCPM3Model": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "MiniCPM3ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "EagleLlamaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ]
  },
  "EagleLlamaModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "previous_hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "EagleLlamaForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "target_hidden_states"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "make_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "fill_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "rotate_activation": [
    "x"
  ],
  "Indexer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "qr",
      "freqs_cis",
      "index_cache",
      "attn_metadata"
    ]
  },
  "DeepseekV32Attention": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "_q_proj": [
      "self",
      "hidden_states",
      "num_heads",
      "nope_size",
      "pe_size"
    ],
    "_kv_proj": [
      "self",
      "hidden_states",
      "nope_size"
    ],
    "_qkv_proj": [
      "self",
      "hidden_states",
      "num_heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "DeepseekV32DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ]
  },
  "DeepseekV32Model": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ]
  },
  "DeepseekV32ForCausalLM": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ]
  },
  "CLIP_VIT_LARGE_PATCH14_336_CONFIG": [],
  "Phi3ImageEmbedding": {
    "__init__": [
      "self",
      "config",
      "wte",
      "dtype",
      "device"
    ],
    "get_img_features": [
      "self",
      "img_embeds"
    ],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "image_sizes",
      "image_mask"
    ],
    "hd_feature_transform": [
      "self",
      "image_features",
      "image_sizes"
    ],
    "reshape_hd_patches_2x2merge": [
      "self",
      "image_features",
      "h_crop",
      "w_crop"
    ],
    "add_image_newline": [
      "self",
      "image_features_hd"
    ]
  },
  "Phi3VModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "pixel_values",
      "image_sizes",
      "image_mask",
      "inputs_embeds"
    ]
  },
  "Phi3VForCausalLM": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "pixel_values",
      "image_sizes",
      "image_mask",
      "inputs_embeds"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "Phi3VInputProcessor": {
    "__init__": [
      "self",
      "config",
      "dtype"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "LANGUAGE_TOKEN_TYPE": [],
  "VISION_TOKEN_TYPE": [],
  "SelfAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "_extract_rope": [
      "states"
    ],
    "_fill_rope": [
      "states",
      "rope"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "GLMBlock": {
    "__init__": [
      "self",
      "config",
      "layer_number",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "GLMTransformer": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "_get_layer": [
      "self",
      "layer_number"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_values",
      "attn_metadata"
    ]
  },
  "Embedding": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "PatchEmbedding": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "images"
    ]
  },
  "EVA2CLIPAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EVA2CLIPMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EVA2CLIPTransformerLayer": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EVA2CLIPTransformer": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GLU": {
    "__init__": [
      "self",
      "config",
      "in_features",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EVA2CLIPModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "images"
    ]
  },
  "ChatGLMModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "images",
      "image_mask",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "ChatGLMForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "images",
      "image_mask",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "_get_model_metas": [
      "self",
      "context"
    ],
    "update_model_metas": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "ChatGLMInputProcessor": {
    "__init__": [
      "self",
      "config",
      "dtype"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "Phi3Attention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "Phi3MLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Phi3DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "Phi3Model": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "Phi3ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlamaAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device",
      "is_tp"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "LlamaMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device",
      "is_tp"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LlamaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device",
      "is_tp"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "LlamaModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "LlamaForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "update_weights": [
      "self"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_outputs_cudagraph": [
      "self",
      "output_buffers",
      "input_ids"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "ExecType": {
    "One": [],
    "Two0101": [],
    "Two0110": [],
    "TwoLikeOne": [],
    "TwoPrefill": [],
    "TwoDecode": []
  },
  "BatchWorker": {
    "__init__": [
      "self",
      "tag",
      "generator"
    ],
    "next": [
      "self"
    ],
    "done": [
      "self"
    ]
  },
  "execute_batch": [
    "inputs",
    "fn",
    "delta_stages",
    "exec_type",
    "extern_tag"
  ],
  "get_new_meta": [
    "attn_metadata",
    "start_idx",
    "end_idx"
  ],
  "get_new_rotary_pos_emb": [
    "rotary_pos_emb",
    "start_loc",
    "end_loc"
  ],
  "get_new_input": [
    "hidden_states",
    "rotary_pos_emb",
    "past_key_values",
    "residual",
    "attn_metadata",
    "start_idx",
    "end_idx",
    "start_loc",
    "end_loc"
  ],
  "get_split_flags": [
    "attn_metadata",
    "num"
  ],
  "split_input": [
    "hidden_states",
    "rotary_pos_emb",
    "past_key_values",
    "residual",
    "attn_metadata",
    "moe_start_idx",
    "moe_end_idx",
    "num"
  ],
  "merge_output": [
    "output_list"
  ],
  "MoEGate": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device",
      "info"
    ],
    "_compute_scores": [
      "self",
      "logits"
    ],
    "_postprocess_topk_weight": [
      "self",
      "topk_weight"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DeepseekV2Model": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "forward_microbatch": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "forward_yieldlayers": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_values",
      "residual",
      "attn_metadata",
      "start_idx",
      "end_idx",
      "tag"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "DeepseekV2ForCausalLM": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "_load_weight_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "expert_params_mapping"
    ],
    "_load_weight_attention": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "update_pe_mapping"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlavaMultiModalProjector": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "CLIPVisionEmbeddings": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "interpolate_pos_encoding": [
      "self",
      "embeddings",
      "height",
      "width"
    ],
    "forward": [
      "self",
      "pixel_values",
      "interpolate_pos_encoding"
    ]
  },
  "CLIPAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "causal_attention_mask"
    ]
  },
  "CLIPMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CLIPEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "causal_attention_mask"
    ]
  },
  "CLIPEncoder": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "causal_attention_mask",
      "vision_feature_layer"
    ]
  },
  "CLIPVisionTransformer": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "pixel_values",
      "interpolate_pos_encoding",
      "vision_feature_layer"
    ]
  },
  "CLIPVisionModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "pixel_values",
      "interpolate_pos_encoding",
      "vision_feature_layer"
    ]
  },
  "build_vision_model": [
    "vision_config",
    "dtype",
    "device"
  ],
  "LlavaForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "vision_feature_layer",
      "vision_feature_select_strategy"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "pixel_values",
      "image_mask",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "LLavaInputProcessor": {
    "__init__": [
      "self",
      "config",
      "dtype"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "get_anyres_image_grid_shape": [
    "image_size",
    "grid_pinpoints",
    "patch_size"
  ],
  "unpad_image": [
    "tensor",
    "original_size"
  ],
  "image_size_to_num_patches": [
    "image_size",
    "grid_pinpoints",
    "patch_size"
  ],
  "LlavaNextForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "image_sizes",
      "vision_feature_layer",
      "vision_feature_select_strategy"
    ],
    "pack_image_features": [
      "self",
      "image_features",
      "image_sizes",
      "vision_feature_select_strategy",
      "image_newline"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "pixel_values",
      "image_sizes",
      "image_mask",
      "inputs_embeds"
    ],
    "get_input_processor": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ]
  },
  "LLavaNextInputProcessor": {
    "__init__": [
      "self",
      "config",
      "dtype"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "InternS1ProForConditionalGeneration": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "pixel_values",
      "vis_cu_seqlens",
      "vis_pos_emb",
      "image_mask",
      "pos_embeds",
      "grid_thw",
      "ts_values",
      "ts_lens",
      "ts_sr",
      "ts_mask"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "rename_weight": [
      "cls",
      "name"
    ],
    "_load_weight_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "expert_params_mapping"
    ],
    "_load_weight_fused_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "fused_expert_params_mapping"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "InternS1ProInputProcessor": {
    "__init__": [
      "self",
      "config",
      "dtype"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "InternS1ProTimeSeriesEncoder": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "_make_causal_mask": [
      "self",
      "input_ids_shape",
      "dtype",
      "device",
      "past_key_values_length"
    ],
    "_prepare_decoder_attention_mask": [
      "self",
      "input_shape",
      "inputs_embeds",
      "past_key_values_length"
    ],
    "forward": [
      "self",
      "input_features"
    ]
  },
  "InternS1ProTimeSeriesConcatSubsampling": {
    "__init__": [
      "self",
      "in_channels",
      "concat_size"
    ],
    "forward": [
      "self",
      "ts_signals",
      "ts_lens"
    ]
  },
  "InternS1ProTimeSeriesFixPositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "max_len",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InternS1ProTimeSeriesMultiChannelAdaptiveSubsampling": {
    "__init__": [
      "self",
      "hidden_dim",
      "nhead",
      "num_encoder_layers",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "inputs",
      "input_lens",
      "sr"
    ],
    "forward_encoder": [
      "self",
      "x"
    ]
  },
  "InternS1ProTimeSeriesProjector": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "ts_features"
    ]
  },
  "InternS1ProTimeSeriesModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "time_series_signals",
      "ts_lens",
      "sr",
      "time_series_embeds"
    ]
  },
  "Qwen3Attention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "Qwen3MLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "Qwen3model": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "Qwen3ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "InternLMAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "InternLMMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InternLMDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "InternLMModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "InternLMForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "PatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "temporal_patch_size",
      "in_channels",
      "embed_dim",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "VisionRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta",
      "device"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "VisionAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "VisionMlp": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2VLVisionBlock": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb",
      "residual"
    ]
  },
  "PatchMerger": {
    "__init__": [
      "self",
      "dim",
      "context_dim",
      "spatial_merge_size",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2VisionTransformerPretrainedModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "Qwen2VLForConditionalGeneration": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "mrope_position_ids",
      "pixel_values",
      "vis_cu_seqlens",
      "vis_pos_emb",
      "image_mask"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "make_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "fill_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "_get_model_metas": [
      "self",
      "context"
    ],
    "_update_model_meta_decoding": [
      "self",
      "context"
    ],
    "_get_multimodal_pos_ids": [
      "self",
      "grid_thw",
      "device"
    ],
    "_update_model_meta_prefilling": [
      "self",
      "context"
    ],
    "update_model_metas": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "Qwen2VLInputProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "Eagle3LlamaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "embeds",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "Eagle3LlamaModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "previous_hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "Eagle3LlamaForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "target_hidden_states"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "make_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "fill_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "get_outputs_cudagraph": [
      "self",
      "output_buffers",
      "input_ids"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "VisionExpertAttention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata",
      "lang_ids",
      "vision_ids"
    ]
  },
  "VisionExpertMLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "lang_ids",
      "vision_ids"
    ]
  },
  "CogVLMDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata",
      "lang_ids",
      "vision_ids"
    ]
  },
  "CogVLMModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "images",
      "inputs_embeds",
      "lang_ids",
      "vision_ids"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "CogVLMForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "images",
      "inputs_embeds",
      "lang_ids",
      "vision_ids"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_get_model_metas": [
      "self",
      "context"
    ],
    "update_model_metas": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "get_input_processor": [
      "self"
    ]
  },
  "CogVLMInputProcessor": {
    "__init__": [
      "self",
      "config",
      "dtype"
    ],
    "preprocess_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "Qwen2ForRewardModel": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "InternLM2VEDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata",
      "vision_embedding_indexing",
      "text_embedding_indexing"
    ]
  },
  "InternLM2VEModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "vision_embedding_indexing",
      "text_embedding_indexing"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "InternLM2VEForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "vision_embedding_indexing",
      "text_embedding_indexing"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "support_cuda_graph": [
      "self",
      "input_ids",
      "attn_metadata"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GptOssAttention": {
    "__init__": [
      "self",
      "config",
      "attention_type",
      "layer_idx",
      "dtype",
      "device"
    ],
    "build_sinks": [
      "cls",
      "config",
      "device"
    ],
    "weight_loader_sinks": [
      "cls",
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "GateupAct": {
    "__init__": [
      "self",
      "limit",
      "alpha"
    ],
    "_impl": [
      "self",
      "gateup"
    ],
    "build": [
      "limit",
      "alpha"
    ],
    "_try_compile": [
      "self",
      "gateup"
    ],
    "__call__": [
      "self",
      "gateup"
    ]
  },
  "GptOssExperts": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "router_indices",
      "routing_weights"
    ]
  },
  "GptOssTopKRouter": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GptOssMLP": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "all_routed_experts"
    ]
  },
  "GptOssDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata",
      "all_routed_experts"
    ]
  },
  "GptOssModel": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds",
      "all_routed_experts"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "GptOssForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "_load_weight_experts_gate_up": [
      "self",
      "name",
      "loaded_weight",
      "params_dict"
    ],
    "_load_weight_experts_down": [
      "self",
      "name",
      "loaded_weight",
      "params_dict"
    ],
    "_load_weight_experts": [
      "self",
      "name",
      "loaded_weight",
      "params_dict"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Starcoder2Attention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "Starcoder2MLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Starcoder2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "Starcoder2Model": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "Starcoder2ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Glm4Attention": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "_extract_rope": [
      "states"
    ],
    "_fill_rope": [
      "states",
      "rope"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "attn_metadata"
    ]
  },
  "Glm4MLP": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Glm4DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb",
      "past_key_value",
      "residual",
      "attn_metadata"
    ]
  },
  "Glm4Model": {
    "__init__": [
      "self",
      "config",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ]
  },
  "Glm4ForCausalLM": {
    "__init__": [
      "self",
      "config",
      "ctx_mgr",
      "dtype",
      "device"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "update_weights": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "PreparedInputs": [],
  "MultiModalMixin": {
    "prepare_multimodal_input": [
      "self",
      "input_ids",
      "input_multimodals"
    ]
  },
  "BuffType": [],
  "_get_meta_flashattn": [
    "batch_size",
    "max_seqlen_q",
    "max_seqlen_k",
    "num_heads_q",
    "num_heads_kv",
    "headdim",
    "cache_seqlens",
    "qkv_dtype",
    "headdim_v",
    "cu_seqlens_q",
    "cu_seqlens_k_new",
    "page_size",
    "causal",
    "window_size",
    "num_splits"
  ],
  "CudaGraphMeta": {},
  "CudaGraphMixin": {
    "support_cuda_graph": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "make_output_buffers": [
      "self",
      "output"
    ],
    "update_meta_flashattn": [
      "self",
      "graph_meta",
      "block_size",
      "max_seqlen_k",
      "cache_seqlens"
    ],
    "make_buffers_cudagraph": [
      "self",
      "graph_meta"
    ],
    "fill_buffers_cudagraph": [
      "self",
      "graph_meta",
      "input_ids",
      "position_ids",
      "past_key_values",
      "attn_metadata",
      "inputs_embeds"
    ],
    "update_context_cudagraph": [
      "self",
      "graph_meta",
      "context"
    ],
    "get_outputs_cudagraph": [
      "self",
      "output_buffers",
      "input_ids"
    ]
  },
  "DeployModelMixin": {
    "forward": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "rename_weight": [
      "cls",
      "name"
    ],
    "update_weights": [
      "self"
    ],
    "update_model_metas": [
      "self",
      "past_key_values",
      "inputs_embeds",
      "context"
    ],
    "get_input_processor": [
      "self"
    ],
    "update_quant_config": [
      "cls",
      "quant_config"
    ]
  },
  "vlm_model": [
    "vlm_cls"
  ],
  "enable_micro_batch": [
    "param_name",
    "index"
  ],
  "split_batch": [
    "func",
    "param_name",
    "index",
    "num_splits"
  ],
  "MigrationExecutionBatch": {},
  "AssignmentInstruct": {},
  "MigrationAssignment": {},
  "PDConnectionMessage": {},
  "DistServeRegisterMRMessage": {},
  "ServingStrategy": {
    "Hybrid": [],
    "DistServe": []
  },
  "EngineRole": {
    "Hybrid": [],
    "Prefill": [],
    "Decode": []
  },
  "MigrationBackend": {
    "DLSlime": [],
    "Mooncake": []
  },
  "RDMALinkType": {
    "IB": [],
    "RoCE": []
  },
  "DistServeRDMAConfig": {},
  "DistServeTCPConfig": {},
  "DistServeNVLinkConfig": {},
  "DistServeEngineConfig": {},
  "MooncakeEngineConfig": {},
  "MigrationProtocol": {
    "TCP": [],
    "RDMA": [],
    "NVLINK": []
  },
  "DistServeConnectionStatus": {
    "SUCCESS": [],
    "FAIL": []
  },
  "DistServeInitRequest": {},
  "DistServeEngineEndpointInfo": {},
  "DistServeKVTransferEndpointInfo": {},
  "DistServeInitResponse": {},
  "DistServeConnectionRequest": {},
  "DistServeConnectionResponse": {},
  "MigrationRequest": {},
  "DistServeCacheFreeRequest": {},
  "DistServeDropConnectionRequest": {},
  "EngineP2PConnection": {
    "__init__": [
      "self",
      "engine"
    ],
    "p2p_initialize": [
      "self",
      "init_request"
    ],
    "p2p_connect": [
      "self",
      "conn_request"
    ],
    "p2p_drop_connect": [
      "self",
      "drop_conn_request"
    ],
    "zmq_send": [
      "self",
      "remote_engine_id",
      "remote_session_id"
    ],
    "handle_zmq_recv": [
      "self",
      "remote_engine_id"
    ],
    "zmq_disconnect": [
      "self",
      "remote_engine_id"
    ]
  },
  "AIOHTTP_TIMEOUT": [],
  "PDConnectionStatus": {
    "Disconnected": [],
    "Connected": [],
    "Connecting": []
  },
  "PDConnectionState": {
    "__init__": [
      "self",
      "status",
      "event"
    ],
    "wait": [
      "self"
    ],
    "set_status": [
      "self",
      "status"
    ]
  },
  "get_server_api": [
    "url",
    "api"
  ],
  "PDConnectionPool": {
    "CONN_SEMAPHORE_SIZE": [],
    "__init__": [
      "self"
    ],
    "reg_instance": [
      "self",
      "role",
      "endpoint"
    ],
    "dereg_instance": [
      "self",
      "endpoint"
    ],
    "shelf_prefill_session": [
      "self",
      "conn_key",
      "session_id"
    ],
    "unshelf_prefill_session": [
      "self",
      "conn_key",
      "session_id"
    ],
    "connect": [
      "self",
      "conn_req"
    ],
    "is_connected": [
      "self",
      "p_url",
      "d_url"
    ],
    "drop": [
      "self",
      "pd_key"
    ]
  },
  "MIGRATION_BACKENDS": [],
  "MigrationBackendImpl": {
    "p2p_initialize": [
      "self",
      "init_request"
    ],
    "register_memory_region": [
      "self",
      "register_mr_request"
    ],
    "endpoint_info": [
      "self",
      "remote_engine_id",
      "protocol"
    ],
    "p2p_connect": [
      "self",
      "remote_engine_id",
      "conn_req"
    ],
    "p2p_migrate": [
      "self",
      "assignment",
      "async_op"
    ],
    "store": [
      "self",
      "assignment",
      "async_op"
    ],
    "load": [
      "self",
      "assignment",
      "async_op"
    ]
  },
  "LMDEPLOY_USE_ASYNC_MIGRATION": [],
  "DLSlimeMigrationManagement": {
    "__init__": [
      "self",
      "init_request"
    ],
    "register_memory_region": [
      "self",
      "register_mr_request"
    ],
    "connect": [
      "self",
      "kvtransfer_endpoint_info"
    ],
    "p2p_migrate": [
      "self",
      "assignment"
    ]
  },
  "DLSlimeBackend": {
    "__init__": [
      "self"
    ],
    "p2p_initialize": [
      "self",
      "init_request"
    ],
    "register_memory_region": [
      "self",
      "register_mr_request"
    ],
    "endpoint_info": [
      "self",
      "remote_engine_id",
      "protocol"
    ],
    "p2p_connect": [
      "self",
      "remote_engine_id",
      "conn_req"
    ],
    "p2p_migrate": [
      "self",
      "assignment",
      "async_op"
    ],
    "store": [
      "self",
      "assignment",
      "async_op"
    ],
    "load": [
      "self",
      "assignment",
      "async_op"
    ]
  },
  "get_rdma_nics": [],
  "get_local_ip_by_remote": [],
  "MooncakeMigrationManagement": {
    "__init__": [
      "self",
      "init_request"
    ],
    "_initialize_p2p": [
      "self",
      "init_request"
    ],
    "register_memory_region": [
      "self",
      "register_mr_request"
    ],
    "endpoint_info": [
      "self"
    ],
    "connect": [
      "self",
      "connect_request"
    ],
    "p2p_migrate": [
      "self",
      "assignment",
      "async_op"
    ],
    "_migrate": [
      "self",
      "assignment"
    ]
  },
  "MooncakeBackend": {
    "__init__": [
      "self"
    ],
    "p2p_initialize": [
      "self",
      "init_request"
    ],
    "register_memory_region": [
      "self",
      "register_mr_request"
    ],
    "endpoint_info": [
      "self",
      "remote_engine_id",
      "protocol"
    ],
    "p2p_connect": [
      "self",
      "remote_engine_id",
      "connect_request"
    ],
    "p2p_migrate": [
      "self",
      "assignment",
      "async_op"
    ],
    "store": [
      "self",
      "assignment",
      "async_op"
    ],
    "load": [
      "self",
      "assignment",
      "async_op"
    ]
  },
  "Timer": {
    "__init__": [
      "self"
    ],
    "tic_cpu": [
      "self"
    ],
    "toc_cpu": [
      "self"
    ],
    "tic_cuda": [
      "self"
    ],
    "toc_cuda": [
      "self"
    ],
    "tic": [
      "cls",
      "is_cuda"
    ],
    "toc": [
      "self"
    ],
    "timing": [
      "cls",
      "is_cuda"
    ],
    "format_duration": [
      "duration",
      "acc"
    ],
    "format_flops": [
      "flops",
      "acc"
    ],
    "formatted_print": [
      "out_info",
      "title"
    ],
    "print": [
      "self",
      "flop",
      "title"
    ],
    "toc_print": [
      "self",
      "flop",
      "title"
    ]
  },
  "visualize_pipe_out": [
    "outputs",
    "enable_meta"
  ],
  "visualize_chat_completions": [
    "outputs",
    "enable_meta"
  ],
  "encode_image_base64": [
    "image"
  ],
  "load_image_from_base64": [
    "image"
  ],
  "load_image": [
    "image_url"
  ],
  "_raise_exception_on_finish": [
    "task"
  ],
  "_accepts_arg": [
    "func",
    "arg_name"
  ],
  "ImageEncoder": {
    "__init__": [
      "self",
      "model_path",
      "backend",
      "vision_config",
      "backend_config"
    ],
    "preprocess": [
      "self",
      "messages",
      "mm_processor_kwargs"
    ],
    "async_infer": [
      "self",
      "messages"
    ],
    "wrap_for_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start",
      "tools",
      "chat_template_kwargs"
    ],
    "wrap_for_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start",
      "tools",
      "chat_template_kwargs"
    ]
  },
  "FETCH_TIMEOUT": [],
  "HEADERS": [],
  "encode_time_series_base64": [
    "data"
  ],
  "load_time_series_from_base64": [
    "ts_base64"
  ],
  "load_time_series": [
    "data_source"
  ],
  "_load_bytes": [
    "content",
    "hint"
  ],
  "_load_path": [
    "path"
  ],
  "_load_csv": [
    "source"
  ],
  "_load_audio": [
    "source"
  ],
  "IMAGE_DUMMY_TOKEN_INDEX": [],
  "IMAGE_TOKEN": [],
  "MiniCPMVModel": {
    "_arch": [],
    "__init__": [
      "self",
      "model_path",
      "with_llm",
      "max_memory",
      "hf_config",
      "backend"
    ],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "_get_slice_image": [
      "self",
      "image"
    ],
    "_reshape_by_patch": [
      "self",
      "slice_images"
    ],
    "_preprocess_v2_5": [
      "self",
      "image",
      "params"
    ],
    "_preprocess_v2_6": [
      "self",
      "image",
      "params"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ],
    "proc_messages": [
      "self",
      "messages",
      "chat_template",
      "sequence_start"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ],
    "to_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ]
  },
  "GLM4VisionModel": {
    "_arch": [],
    "match": [
      "cls",
      "config"
    ],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "proc_messages": [
      "messages",
      "chat_template",
      "sequence_start"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ]
  },
  "check_qwen_vl_deps_install": [],
  "Qwen2VLModel": {
    "_arch": [],
    "build_preprocessor": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "build_model": [
      "self"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ],
    "proc_messages": [
      "self",
      "messages",
      "chat_template",
      "sequence_start",
      "chat_template_kwargs"
    ],
    "get_mrope_info": [
      "seq_len",
      "grid_thws",
      "ranges"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start",
      "chat_template_kwargs"
    ],
    "to_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start",
      "chat_template_kwargs"
    ]
  },
  "check_transformers": [],
  "MllamaVLModel": {
    "_arch": [],
    "build_preprocessor": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "build_model": [
      "self"
    ],
    "proc_messages": [
      "messages",
      "chat_template",
      "sequence_start"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ]
  },
  "_model_path": [],
  "_build_vision_projector": [
    "config",
    "delay_load"
  ],
  "_build_vision_tower": [
    "vision_tower_cfg"
  ],
  "init_yi_model": [],
  "YiVisionModel": {
    "match": [
      "cls",
      "config"
    ],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ]
  },
  "find_closest_aspect_ratio": [
    "aspect_ratio",
    "target_ratios",
    "width",
    "height",
    "image_size"
  ],
  "dynamic_preprocess": [
    "image",
    "min_num",
    "max_num",
    "image_size",
    "use_thumbnail"
  ],
  "LlavaHfVisionModel": {
    "_arch": [],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ],
    "proc_messages": [
      "messages",
      "chat_template",
      "sequence_start"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ],
    "to_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ]
  },
  "InternVLImagesKwargs": {},
  "InternVLProcessorKwargs": {
    "_defaults": []
  },
  "InternVL3VisionModel": {
    "_arch": [],
    "__init__": [
      "self",
      "model_path",
      "with_llm",
      "max_memory",
      "hf_config",
      "backend"
    ],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ]
  },
  "check_llava_install": [],
  "_intern_vision_model__from_pretrained": [
    "vision_tower_name"
  ],
  "_intern_vl_model__from_pretrained": [
    "vision_tower_name"
  ],
  "init_empty_vit": [],
  "InternVLLlavaVisionModel": {
    "match": [
      "cls",
      "config"
    ],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ]
  },
  "VISION_MODELS": [],
  "VisionModel": {
    "__init__": [
      "self",
      "model_path",
      "with_llm",
      "max_memory",
      "hf_config",
      "backend"
    ],
    "get_pad_token_id": [
      "self",
      "model_path",
      "hf_config"
    ],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "has_input_ids": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start",
      "chat_template_kwargs"
    ],
    "to_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start",
      "chat_template_kwargs"
    ],
    "collect_images": [
      "messages"
    ],
    "collect_time_series": [
      "messages"
    ],
    "IMAGE_TOKEN_included": [
      "messages"
    ],
    "to_pytorch_with_input_ids": [
      "self",
      "messages"
    ],
    "to_pytorch_aux": [
      "self",
      "messages",
      "prompt",
      "IMAGE_TOKEN",
      "tokenizer",
      "sequence_start"
    ],
    "to_turbomind_aux": [
      "self",
      "messages",
      "prompt",
      "IMAGE_TOKEN",
      "tokenizer",
      "sequence_start"
    ],
    "match": [
      "cls",
      "config"
    ]
  },
  "Phi3VisionModel": {
    "_arch": [],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ]
  },
  "check_deepseek_vl_install": [],
  "DeepSeekVisionModel": {
    "_arch": [],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ],
    "proc_messages": [
      "messages",
      "chat_template",
      "sequence_start"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ],
    "to_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ]
  },
  "check_xcomposer_install": [],
  "ModelType": {
    "XCOMPOSER2": [],
    "XCOMPOSER2_4KHD": [],
    "XCOMPOSER2D5": []
  },
  "get_xcomposer_type": [
    "model_path"
  ],
  "_CLIPVisionModel_from_pretrained": [
    "vision_tower_name"
  ],
  "Xcomposer2VisionModel": {
    "__init__": [
      "self",
      "model_path",
      "with_llm",
      "max_memory",
      "hf_config",
      "backend"
    ],
    "match": [
      "cls",
      "config"
    ],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "_preprocess_2d5": [
      "self",
      "image",
      "params"
    ],
    "_preprocess_7b": [
      "self",
      "image",
      "params"
    ],
    "_preprocess_4khd_7b": [
      "self",
      "image",
      "params"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ],
    "proc_messages": [
      "messages",
      "chat_template",
      "sequence_start",
      "model_type"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ],
    "to_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ]
  },
  "GLM4_1_VisionModel": {
    "_arch": [],
    "match": [
      "cls",
      "config"
    ],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "proc_messages": [
      "messages",
      "chat_template",
      "sequence_start"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ]
  },
  "LlavaNextVisionModel": {
    "_arch": [],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ]
  },
  "check_trans_version": [],
  "LLama4VisionModel": {
    "_arch": [],
    "match": [
      "cls",
      "config"
    ],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ],
    "proc_messages": [
      "messages",
      "chat_template",
      "sequence_start"
    ],
    "to_pytorch_aux": [
      "self",
      "messages",
      "prompt",
      "IMAGE_TOKEN",
      "tokenizer",
      "sequence_start"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ],
    "to_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ]
  },
  "load_weight_ckpt": [
    "ckpt"
  ],
  "get_used_weight_files": [
    "folder",
    "state_dict"
  ],
  "load_model_from_weight_files": [
    "model",
    "folder"
  ],
  "add_sys_path": [
    "path"
  ],
  "disable_transformers_logging": [],
  "disable_logging": [],
  "hack_import_with": [
    "src",
    "dst"
  ],
  "_set_func": [
    "origin_func_path",
    "rewrite_func",
    "origin_func"
  ],
  "rewrite_ctx": [
    "origin_func_path",
    "rewrite_func"
  ],
  "add_device_hook": [
    "module",
    "device",
    "fn"
  ],
  "Gemma3ImagesKwargs": {},
  "Gemma3ProcessorKwargs": {
    "_defaults": []
  },
  "Gemma3VisionModel": {
    "_arch": [],
    "__init__": [
      "self",
      "model_path",
      "with_llm",
      "max_memory",
      "hf_config",
      "backend"
    ],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ],
    "proc_messages": [
      "messages",
      "chat_template",
      "sequence_start"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ],
    "to_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ]
  },
  "QwenVisionModel": {
    "_arch": [],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ],
    "proc_messages": [
      "messages",
      "chat_template",
      "sequence_start"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ],
    "to_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ]
  },
  "load_vl_model": [
    "model_path",
    "backend",
    "with_llm",
    "backend_config"
  ],
  "check_deepseek_vl2_install": [],
  "DeepSeek2VisionModel": {
    "_arch": [],
    "match": [
      "cls",
      "config"
    ],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ],
    "proc_single_message": [
      "message"
    ],
    "proc_messages": [
      "messages",
      "chat_template",
      "sequence_start"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ],
    "to_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ]
  },
  "_clip_vision_tower_load_model": [
    "self"
  ],
  "init_llava_vision_tower": [
    "config"
  ],
  "select_best_resolution": [
    "original_size",
    "possible_resolutions"
  ],
  "resize_and_pad_image": [
    "image",
    "target_resolution"
  ],
  "divide_to_patches": [
    "image",
    "patch_size"
  ],
  "process_anyres_image": [
    "image",
    "processor",
    "grid_pinpoints"
  ],
  "expand2square": [
    "pil_img",
    "background_color"
  ],
  "process_images": [
    "images",
    "image_processor",
    "model_cfg"
  ],
  "LlavaVisionModel": {
    "match": [
      "cls",
      "config"
    ],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "encode_images": [
      "self",
      "images"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ]
  },
  "InternS1ProVisionModel": {
    "_arch": [],
    "build_preprocessor": [
      "self"
    ],
    "get_processor_args": [
      "self",
      "mm_processor_kwargs"
    ],
    "check_time_series_input": [
      "self",
      "messages"
    ],
    "time_series_processor": [
      "self",
      "ts_input",
      "sr"
    ],
    "preprocess": [
      "self",
      "messages",
      "mm_processor_kwargs"
    ],
    "proc_messages": [
      "self",
      "messages",
      "chat_template",
      "sequence_start",
      "tools",
      "chat_template_kwargs"
    ],
    "ts_to_pytorch_aux": [
      "self",
      "messages",
      "prompt",
      "TS_TOKEN",
      "tokenizer",
      "sequence_start"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start",
      "tools",
      "chat_template_kwargs"
    ],
    "build_model": [
      "self"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ],
    "to_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start",
      "chat_template_kwargs"
    ]
  },
  "Qwen3VLModel": {
    "_arch": [],
    "build_preprocessor": [
      "self"
    ],
    "get_processor_args": [
      "self",
      "mm_processor_kwargs"
    ],
    "preprocess": [
      "self",
      "messages",
      "mm_processor_kwargs"
    ],
    "proc_messages": [
      "self",
      "messages",
      "chat_template",
      "sequence_start",
      "chat_template_kwargs"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start",
      "chat_template_kwargs"
    ],
    "build_model": [
      "self"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ],
    "to_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start",
      "chat_template_kwargs"
    ]
  },
  "CogVLMVisionModel": {
    "_arch": [],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "proc_messages": [
      "messages",
      "chat_template",
      "sequence_start"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ]
  },
  "MolmoVisionModel": {
    "_arch": [],
    "build_preprocessor": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "preprocess": [
      "self",
      "messages"
    ],
    "forward": [
      "self",
      "messages",
      "max_batch_size"
    ],
    "proc_messages": [
      "messages"
    ],
    "to_pytorch": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ],
    "to_turbomind": [
      "self",
      "messages",
      "chat_template",
      "tokenizer",
      "sequence_start"
    ]
  },
  "VocabType": {
    "RAW": [],
    "BYTE_FALLBACK": [],
    "BYTE_LEVEL": []
  },
  "TokenizerInfo": {
    "__init__": [
      "self",
      "encoded_vocab",
      "vocab_type"
    ],
    "_is_tiktoken_tokenizer": [
      "tokenizer"
    ],
    "_is_sentencepiece_tokenizer": [
      "tokenizer"
    ],
    "from_huggingface": [
      "tokenizer"
    ]
  },
  "SUPPORTED_ARCHS": [],
  "is_supported": [
    "model_path"
  ],
  "bootstrap": [],
  "lmdeploy_dir": [],
  "MAX_LOGPROBS": [],
  "_construct_stop_or_bad_words": [
    "words"
  ],
  "_np_dict_to_tm_dict": [
    "np_dict"
  ],
  "_tm_dict_to_torch_dict": [
    "tm_dict"
  ],
  "complete_parallel_config": [
    "cfg"
  ],
  "update_parallel_config": [
    "cfg"
  ],
  "TurboMind": {
    "__init__": [
      "self",
      "model_path",
      "model_name",
      "chat_template_name",
      "engine_config"
    ],
    "_check_unloaded_tm_params": [
      "self"
    ],
    "_load_weights": [
      "self"
    ],
    "_process_weights": [
      "self"
    ],
    "_create_engine": [
      "self"
    ],
    "_create_weight": [
      "self",
      "model_comm"
    ],
    "_get_model_params": [
      "self"
    ],
    "_postprocess_config": [
      "self",
      "tm_config",
      "engine_config"
    ],
    "_from_hf": [
      "self",
      "model_path",
      "engine_config"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wakeup": [
      "self",
      "tags"
    ],
    "update_params": [
      "self",
      "request"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path",
      "model_name",
      "chat_template_name",
      "engine_config"
    ],
    "close": [
      "self"
    ],
    "create_instance": [
      "self",
      "cuda_stream_id"
    ],
    "get_schedule_metrics": [
      "self"
    ]
  },
  "_get_logits": [
    "outputs",
    "offset"
  ],
  "_get_last_hidden_state": [
    "outputs",
    "offset"
  ],
  "_get_logprobs_impl": [
    "logprob_vals",
    "logprob_idxs",
    "logprob_nums",
    "output_ids",
    "logprobs",
    "offset"
  ],
  "_get_logprobs": [
    "outputs",
    "output_logprobs"
  ],
  "_get_metrics": [
    "metrics"
  ],
  "StreamingSemaphore": {
    "__init__": [
      "self"
    ],
    "acquire": [
      "self"
    ],
    "release": [
      "self"
    ]
  },
  "TurboMindInstance": {
    "__init__": [
      "self",
      "tm_model",
      "config",
      "cuda_stream_id"
    ],
    "model_inst": [
      "self"
    ],
    "_create_model_instance": [
      "self"
    ],
    "_get_extra_output_processors": [
      "self",
      "outputs",
      "gen_config",
      "input_len",
      "metrics"
    ],
    "prepare_embeddings": [
      "self",
      "input_embeddings",
      "input_embedding_ranges"
    ],
    "prepare_mrope": [
      "self",
      "input_meta",
      "input_len"
    ],
    "prepare_inputs": [
      "self",
      "input_ids",
      "gen_config",
      "input_embeddings",
      "input_embedding_ranges",
      "input_meta"
    ],
    "async_cancel": [
      "self",
      "session_id"
    ],
    "async_end_cb": [
      "self",
      "fut",
      "status"
    ],
    "async_end": [
      "self",
      "session_id"
    ],
    "async_signal_cb": [
      "self",
      "s"
    ],
    "async_stream_infer": [
      "self",
      "session_id",
      "input_ids",
      "input_embeddings",
      "input_embedding_ranges",
      "input_meta",
      "sequence_start",
      "sequence_end",
      "step",
      "gen_config",
      "stream_output"
    ],
    "_get_error_output": [
      "self",
      "status"
    ],
    "_get_generation_config": [
      "self",
      "cfg"
    ]
  },
  "identity": [
    "x"
  ],
  "to_half": [
    "x"
  ],
  "to_float": [
    "x"
  ],
  "to_fp8": [
    "x"
  ],
  "pack_u4_row": [
    "x"
  ],
  "generate_zero_point": [
    "g"
  ],
  "Parameter": {
    "KEY": [],
    "take": [
      "cls",
      "keys"
    ],
    "__call__": [
      "cls",
      "f",
      "g",
      "i"
    ]
  },
  "QuantWeightOnly": {
    "KEYS": [],
    "__call__": [
      "self",
      "f",
      "g",
      "i"
    ]
  },
  "WeightScaleInv": {
    "KEYS": [],
    "__call__": [
      "self",
      "f",
      "g",
      "i"
    ]
  },
  "CompressedWeight": {
    "KEYS": [],
    "__init__": [
      "self",
      "xs"
    ],
    "__call__": [
      "self",
      "f",
      "g",
      "i"
    ]
  },
  "Mxfp4Weight": {
    "KEYS": [],
    "__call__": [
      "self",
      "f",
      "g",
      "i"
    ]
  },
  "Weight": {
    "KEYS": [],
    "__call__": [
      "self",
      "f",
      "g",
      "i"
    ]
  },
  "Bias": {
    "KEYS": [],
    "__call__": [
      "self",
      "f",
      "g",
      "i"
    ]
  },
  "PLora": {
    "KEYS": [],
    "__call__": [
      "self",
      "f",
      "g",
      "i"
    ]
  },
  "get_params": [
    "keys",
    "bias"
  ],
  "WEIGHT_INDEX_NAME": [],
  "WEIGHT_PATTERN": [],
  "SAFE_WEIGHT_INDEX_NAME": [],
  "SAFE_WEIGHT_PATTERN": [],
  "EXTRA_WEIGHT_PATTERNS": [],
  "EXTRA_SAFE_WEIGHT_PATTERN": [],
  "BaseLoader": {
    "__init__": [
      "self",
      "model_path",
      "pattern",
      "mappings"
    ],
    "get_index": [
      "self",
      "index_name",
      "file_pattern"
    ],
    "map_key": [
      "self",
      "key"
    ],
    "items": [
      "self"
    ]
  },
  "SafetensorsLoader": {
    "__init__": [
      "self",
      "model_path",
      "pattern",
      "mappings",
      "index_name",
      "file_pattern"
    ],
    "items": [
      "self"
    ]
  },
  "PytorchLoader": {
    "__init__": [
      "self",
      "model_path",
      "pattern",
      "mappings",
      "index_name",
      "file_pattern"
    ],
    "items": [
      "self"
    ]
  },
  "StateDictLoader": {
    "__init__": [
      "self",
      "queue",
      "pattern",
      "mappings"
    ],
    "items": [
      "self"
    ]
  },
  "create_loader": [
    "model_path",
    "pattern",
    "mappings"
  ],
  "SUPPORTED_FORMATS": [],
  "get_input_model_registered_name": [
    "model_path",
    "model_format"
  ],
  "get_output_model_registered_name_and_config": [
    "model_path",
    "model_format",
    "dtype",
    "group_size"
  ],
  "get_tm_model": [
    "model_path",
    "model_name",
    "chat_template_name",
    "engine_config",
    "group_size",
    "out_dir"
  ],
  "permute_v2": [
    "x",
    "size_per_head"
  ],
  "merge_qkv_v2": [
    "q",
    "k",
    "v",
    "tp"
  ],
  "transpose": [
    "x"
  ],
  "pad_out_dims": [
    "x",
    "dims"
  ],
  "pad_in_dims": [
    "x",
    "dims"
  ],
  "get_lora_flags": [
    "kind"
  ],
  "Module": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self"
    ],
    "apply": [
      "self",
      "idx",
      "r"
    ]
  },
  "Ffn": {
    "_ffn": [],
    "__init__": [
      "self",
      "model"
    ],
    "_export": [
      "self",
      "inter_size",
      "fmt",
      "idx",
      "w123",
      "kind",
      "pack_fn",
      "apply_gs"
    ],
    "apply": [
      "self",
      "i",
      "r"
    ]
  },
  "MoeFfn": {
    "_moe_ffn_expert": [],
    "_moe_ffn_gate": [],
    "_moe_ffn_shared_gate": [],
    "__init__": [
      "self",
      "model"
    ],
    "apply": [
      "self",
      "i",
      "r"
    ]
  },
  "Attn": {
    "_attn": [],
    "__init__": [
      "self",
      "model"
    ],
    "_reorder_and_merge": [
      "self",
      "qkvo",
      "gs"
    ],
    "_repeat_kv": [
      "self",
      "qkvo",
      "gs",
      "kind"
    ],
    "_export": [
      "self",
      "idx",
      "qkvo",
      "kind",
      "pack_fn",
      "apply_gs"
    ],
    "apply": [
      "self",
      "i",
      "r"
    ]
  },
  "MLA": {
    "_mla": [],
    "__init__": [
      "self",
      "model"
    ],
    "_export": [
      "self",
      "idx",
      "xs",
      "kind",
      "pack_fn"
    ],
    "_layernorm": [],
    "apply": [
      "self",
      "i",
      "r"
    ]
  },
  "Misc": {
    "apply": [
      "self",
      "i",
      "r"
    ]
  },
  "Transformer": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "i",
      "r"
    ]
  },
  "to_cuda": [
    "x"
  ],
  "get_u4_slices": [
    "x",
    "dtype"
  ],
  "unpack_awq_gemm": [
    "x"
  ],
  "process_awq_gemm": [
    "x",
    "kind"
  ],
  "process_gptq": [
    "x",
    "kind"
  ],
  "process_mxfp4": [
    "x",
    "kind"
  ],
  "process_fp8": [
    "x",
    "kind"
  ],
  "process_compressed_tensor": [
    "x",
    "kind"
  ],
  "get_input_policy": [
    "model_format"
  ],
  "config_from_dict": [
    "cls",
    "env"
  ],
  "config_to_dict": [
    "config"
  ],
  "RopeParam": {},
  "AttentionConfig": {},
  "LoraConfig": {},
  "TurbomindModelConfig": {
    "update_from_engine_config": [
      "self",
      "config"
    ],
    "from_dict": [
      "cls",
      "config"
    ],
    "to_dict": [
      "self"
    ],
    "session_len": [
      "self"
    ],
    "weight_type": [
      "self"
    ],
    "group_size": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "OUTPUT_MODELS": [],
  "tprint": [],
  "_weight_dtype_map": [
    "weight_type",
    "default"
  ],
  "_pad_inter_size": [
    "inter_size",
    "group_size",
    "tp"
  ],
  "BaseOutputModel": {
    "__init__": [
      "self",
      "input_model",
      "cfg",
      "model_cls",
      "out_dir"
    ],
    "single_to_list": [
      "self",
      "config",
      "keys"
    ],
    "update_model_config": [
      "self"
    ],
    "update_attention_config": [
      "self"
    ],
    "update_lora_config": [
      "self"
    ],
    "export_config": [
      "self"
    ],
    "export_weight": [
      "self",
      "param",
      "name"
    ],
    "save_split": [
      "self",
      "tensor",
      "name",
      "split_dim",
      "split_num",
      "copy"
    ],
    "export": [
      "self"
    ],
    "export_iter": [
      "self"
    ],
    "tm_config": [
      "self"
    ]
  },
  "TurbomindModel": {},
  "MiniCPMVReader": {
    "attn_layer_prefix": [],
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": []
  },
  "InternVLReader": {
    "attn_layer_prefix": [],
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "__init__": [
      "self",
      "new_params",
      "unused_params",
      "last_bin",
      "model_cfg"
    ]
  },
  "InternVL2Reader": {
    "attn_layer_prefix": [],
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "__init__": [
      "self",
      "new_params",
      "unused_params",
      "last_bin",
      "model_cfg"
    ]
  },
  "InternVL3d5Reader": {
    "attn_layer_prefix": [],
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "__init__": [
      "self",
      "new_params",
      "unused_params",
      "last_bin",
      "model_cfg"
    ]
  },
  "InternVL3d5Qwen3MoEReader": {
    "attn_layer_prefix": [],
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "__init__": [
      "self",
      "new_params",
      "unused_params",
      "last_bin",
      "model_cfg"
    ]
  },
  "InternVL3d5GptOSSReader": {
    "attn_layer_prefix": [],
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "__init__": [
      "self",
      "new_params",
      "unused_params",
      "last_bin",
      "model_cfg"
    ]
  },
  "InternS1Reader": {
    "attn_layer_prefix": [],
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "__init__": [
      "self",
      "new_params",
      "unused_params",
      "last_bin",
      "model_cfg"
    ]
  },
  "InternS1MiniReader": {
    "attn_layer_prefix": [],
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "__init__": [
      "self",
      "new_params",
      "unused_params",
      "last_bin",
      "model_cfg"
    ]
  },
  "InternVLModel": {
    "__init__": [
      "self",
      "model_path",
      "tokenizer_path"
    ],
    "model_info": [
      "self"
    ]
  },
  "InternLM2Reader": {
    "attn_layer_prefix": [],
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "attn_pattern": [],
    "ffn_pattern": [],
    "_attn": [
      "self",
      "i",
      "kind"
    ],
    "attn_norm": [
      "self",
      "i"
    ],
    "_ffn": [
      "self",
      "i",
      "kind"
    ],
    "ffn_norm": [
      "self",
      "i"
    ]
  },
  "INPUT_MODELS": [],
  "BaseReader": {
    "__init__": [
      "self"
    ],
    "transform": [
      "self",
      "x",
      "kind"
    ],
    "_transform": [
      "self",
      "x",
      "kind"
    ]
  },
  "BaseInputModel": {
    "__init__": [
      "self",
      "model_path",
      "tokenizer_path"
    ],
    "model_info": [
      "self"
    ],
    "readers": [
      "self"
    ]
  },
  "BaichuanReader": {
    "_attn": [
      "self",
      "i",
      "kind"
    ]
  },
  "Baichuan2Reader": {
    "output_weight": [
      "self"
    ]
  },
  "Baichuan2Model": {
    "Reader": []
  },
  "Xcomposer2Reader": {
    "attn_pattern": [],
    "ffn_pattern": [],
    "_attn": [
      "self",
      "i",
      "kind"
    ]
  },
  "Xcomposer2Model": {
    "Reader": [],
    "_lora_cfg_7b": [
      "self"
    ],
    "_lora_cfg_4khd_7b": [
      "self",
      "model_info"
    ],
    "model_info": [
      "self"
    ]
  },
  "DeepSeek2Reader": {
    "moe_ffn_gate": [
      "self",
      "i",
      "kind"
    ],
    "moe_ffn_expert": [
      "self",
      "e",
      "i",
      "kind"
    ],
    "_ffn": [
      "self",
      "i",
      "kind"
    ],
    "mla": [
      "self",
      "i",
      "kind"
    ],
    "mla_norm": [
      "self",
      "i"
    ]
  },
  "get_yarn_params": [
    "rope_scaling"
  ],
  "DeepSeek2Model": {
    "Reader": [],
    "model_info": [
      "self"
    ]
  },
  "MixtralReader": {
    "moe_ffn_expert": [
      "self",
      "e",
      "i",
      "kind"
    ],
    "moe_ffn_gate": [
      "self",
      "i",
      "kind"
    ]
  },
  "QwenReader": {
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "attn_pattern": [],
    "ffn_pattern": [],
    "_attn": [
      "self",
      "i",
      "kind"
    ],
    "attn_norm": [
      "self",
      "i"
    ],
    "_ffn": [
      "self",
      "i",
      "kind"
    ],
    "ffn_norm": [
      "self",
      "i"
    ]
  },
  "QwenModel": {
    "Reader": [],
    "model_info": [
      "self"
    ]
  },
  "Qwen2MoeReader": {
    "ffn_pattern": [],
    "moe_ffn_expert": [
      "self",
      "e",
      "i",
      "kind"
    ],
    "moe_ffn_gate": [
      "self",
      "i",
      "kind"
    ],
    "_ffn": [
      "self",
      "i",
      "kind"
    ],
    "moe_ffn_shared_gate": [
      "self",
      "i"
    ]
  },
  "Qwen3Reader": {
    "qk_norm": [
      "self",
      "i"
    ]
  },
  "Qwen3Model": {
    "Reader": [],
    "model_info": [
      "self"
    ]
  },
  "Qwen3MoeReader": {
    "qk_norm": [
      "self",
      "i"
    ]
  },
  "LlamaReader": {
    "attn_layer_prefix": [],
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "attn_pattern": [],
    "ffn_pattern": [],
    "__init__": [
      "self",
      "new_params",
      "unused_params",
      "last_bin",
      "model_cfg",
      "policy"
    ],
    "filter": [
      "self",
      "pattern"
    ],
    "tok_embeddings": [
      "self"
    ],
    "norm_weight": [
      "self"
    ],
    "output_weight": [
      "self"
    ],
    "_transform": [
      "self",
      "x",
      "kind"
    ],
    "_attn": [
      "self",
      "i",
      "kind"
    ],
    "attn": [
      "self",
      "i",
      "kind"
    ],
    "attn_norm": [
      "self",
      "i"
    ],
    "_ffn": [
      "self",
      "i",
      "kind"
    ],
    "ffn": [
      "self",
      "i",
      "kind"
    ],
    "ffn_norm": [
      "self",
      "i"
    ]
  },
  "LlavaReader": {
    "attn_layer_prefix": [],
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "__init__": [
      "self",
      "new_params",
      "unused_params",
      "last_bin",
      "model_cfg",
      "policy"
    ]
  },
  "LlavaModel": {
    "__init__": [
      "self",
      "model_path",
      "tokenizer_path"
    ],
    "model_info": [
      "self"
    ]
  },
  "DeepSeekVLReader": {
    "attn_layer_prefix": [],
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "__init__": [
      "self",
      "new_params",
      "unused_params",
      "last_bin",
      "model_cfg"
    ],
    "attn_norm": [
      "self",
      "i"
    ],
    "ffn_norm": [
      "self",
      "i"
    ]
  },
  "DeepSeekVLModel": {
    "Reader": [],
    "model_info": [
      "self"
    ]
  },
  "map_experts": [
    "str"
  ],
  "GptOssReader": {
    "mappings": [],
    "moe_ffn_expert": [
      "self",
      "e",
      "i",
      "kind"
    ],
    "moe_ffn_gate": [
      "self",
      "i",
      "kind"
    ],
    "attn_sinks": [
      "self",
      "i"
    ]
  },
  "MolmoReader": {
    "attn_layer_prefix": [],
    "attn_layer_patten": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "attn_pattern": [],
    "ffn_pattern": [],
    "tok_embeddings": [
      "self"
    ],
    "attn_norm": [
      "self",
      "i"
    ],
    "_attn": [
      "self",
      "i",
      "kind"
    ],
    "_ffn": [
      "self",
      "i",
      "kind"
    ],
    "ffn_norm": [
      "self",
      "i"
    ]
  },
  "MolmoModel": {
    "Reader": [],
    "__init__": [
      "self",
      "model_path",
      "tokenizer_path"
    ],
    "model_info": [
      "self"
    ]
  },
  "Glm4Reader": {
    "attn_layer_patten": [],
    "tok_embeddings_key": [],
    "norm_weight_key": [],
    "output_weight_key": [],
    "attn_pattern": [],
    "_attn": [
      "self",
      "i",
      "kind"
    ],
    "attn_norm": [
      "self",
      "i"
    ],
    "_ffn": [
      "self",
      "i",
      "kind"
    ],
    "ffn_norm": [
      "self",
      "i"
    ]
  },
  "OFFLOAD_MOD": [],
  "KV_CACHE_SIGNATURE": [],
  "InternLM2GPTQForCausalLM": {
    "layer_type": [],
    "layers_block_name": [],
    "outside_layer_modules": [],
    "inside_layer_modules": []
  },
  "InternLM3GPTQForCausalLM": {
    "layer_type": [],
    "layers_block_name": [],
    "outside_layer_modules": [],
    "inside_layer_modules": []
  },
  "save_vl_model": [
    "vl_model",
    "model_path",
    "dst_path"
  ],
  "auto_awq": [
    "model",
    "work_dir",
    "calib_dataset",
    "calib_samples",
    "batch_size",
    "calib_seqlen",
    "w_bits",
    "w_sym",
    "w_group_size",
    "search_scale",
    "device",
    "revision",
    "dtype",
    "download_dir"
  ],
  "LAYER_TYPE_MAP": [],
  "NORM_TYPE_MAP": [],
  "HEAD_NAME_MAP": [],
  "_prepare_for_calibrate": [
    "model",
    "layer_type",
    "head_name",
    "device",
    "prefix"
  ],
  "make_compatible_internvl_config": [
    "model_path"
  ],
  "update_moe_mapping": [
    "model",
    "model_type"
  ],
  "calibrate": [
    "model",
    "calib_dataset",
    "calib_samples",
    "calib_seqlen",
    "work_dir",
    "device",
    "w_bits",
    "w_group_size",
    "search_scale",
    "dtype",
    "batch_size"
  ],
  "smooth_quant": [
    "model",
    "work_dir",
    "calib_dataset",
    "calib_samples",
    "calib_seqlen",
    "search_scale",
    "batch_size",
    "w_bits",
    "dtype",
    "device",
    "quant_dtype",
    "revision",
    "download_dir"
  ],
  "parse_args": [],
  "auto_gptq": [
    "model",
    "work_dir",
    "w_bits",
    "w_group_size",
    "calib_dataset",
    "calib_samples",
    "calib_seqlen",
    "batch_size",
    "dtype",
    "revision"
  ],
  "NUM_LOADED_SAMPLES": [],
  "set_seed": [
    "seed"
  ],
  "process_dataset": [
    "ds",
    "tokenizer",
    "max_seq_length"
  ],
  "get_wikitext2": [
    "dataset",
    "tokenizer",
    "nsamples",
    "seed",
    "seqlen"
  ],
  "get_c4": [
    "dataset",
    "tokenizer",
    "nsamples",
    "seed",
    "seqlen"
  ],
  "get_pileval": [
    "dataset",
    "tokenizer",
    "nsamples",
    "seed",
    "seqlen"
  ],
  "get_gsm8k": [
    "dataset",
    "tokenizer",
    "nsamples",
    "seed",
    "seqlen"
  ],
  "get_neuralmagic_calibration": [
    "dataset",
    "tokenizer",
    "nsamples",
    "seed",
    "seqlen"
  ],
  "get_open_platypus": [
    "dataset",
    "tokenizer",
    "nsamples",
    "seed",
    "seqlen"
  ],
  "get_openwebtext": [
    "dataset",
    "tokenizer",
    "nsamples",
    "seed",
    "seqlen"
  ],
  "get_calib_loaders": [
    "name",
    "tokenizer",
    "nsamples",
    "seed",
    "seqlen"
  ],
  "GlobalAvailMixin": {
    "global_available": [
      "self",
      "key",
      "group"
    ],
    "_save_instance": [
      "cls",
      "instance",
      "key",
      "group"
    ],
    "find": [
      "cls",
      "key",
      "group"
    ],
    "find_group": [
      "cls",
      "group"
    ],
    "instances": [
      "cls"
    ]
  },
  "split_decoder_layer_inputs": [
    "batch_size"
  ],
  "concat_decoder_layer_outputs": [
    "batch_outputs"
  ],
  "LoadNoInit": {
    "__init__": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "load_hf_from_pretrained": [
    "pretrained_model_name_or_path",
    "dtype"
  ],
  "QParams": {},
  "precise_round": [
    "x"
  ],
  "cal_qparams_per_channel_absmax": [
    "w",
    "n_bits",
    "return_stats"
  ],
  "cal_qparams_per_channel_minmax": [
    "w",
    "n_bits",
    "return_stats"
  ],
  "cal_qparams_per_group_absmax": [
    "w",
    "n_bits",
    "group_size",
    "return_stats"
  ],
  "cal_qparams_per_group_minmax": [
    "w",
    "n_bits",
    "group_size",
    "return_stats"
  ],
  "cal_qparams_per_tensor_minmax": [
    "w",
    "n_bits",
    "return_stats"
  ],
  "cal_qparams_per_tensor_absmax": [
    "w",
    "n_bits",
    "return_stats"
  ],
  "extract_return_values": [
    "module"
  ],
  "find_kv_cache_idx": [
    "module"
  ],
  "find_modules_by_return_value": [
    "model",
    "value"
  ],
  "offload_kv_cache": [
    "model",
    "device"
  ],
  "offload_weights": [
    "model",
    "device"
  ],
  "memory_efficient_inference": [
    "model",
    "offload",
    "device"
  ],
  "collect_target_modules": [
    "model",
    "target",
    "skip_names",
    "prefix"
  ],
  "collect_target_weights": [
    "model",
    "target",
    "skip_names"
  ],
  "bimap_name_mod": [
    "name2mod_mappings"
  ],
  "CalibrationContext": {
    "inp_obs_group": [],
    "out_obs_group": [],
    "__init__": [
      "self",
      "model",
      "tokenizer",
      "layer_type",
      "norm_type",
      "batch_size",
      "device"
    ],
    "_guess_num_heads": [
      "self",
      "model"
    ],
    "_init_input_observers": [
      "self",
      "name2mod"
    ],
    "_init_output_observers": [
      "self",
      "name2mod"
    ],
    "_insert_input_observers": [
      "self"
    ],
    "_insert_output_observers": [
      "self"
    ],
    "_wrap_decoder_layers": [
      "self"
    ],
    "collect_inputs_stats": [
      "self"
    ],
    "collect_outputs_stats": [
      "self"
    ],
    "export": [
      "self",
      "out_dir"
    ],
    "calibrate": [
      "self",
      "data"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "auto_scale_block": [
    "module",
    "module_kwargs",
    "w_bit",
    "w_group_size",
    "input_feat",
    "mod_name"
  ],
  "CalibrationContextV2": {
    "__init__": [
      "self",
      "model",
      "tokenizer",
      "layer_type",
      "norm_type",
      "batch_size",
      "device",
      "search_scale",
      "w_bits",
      "w_group_size"
    ],
    "_insert_input_observers": [
      "self"
    ],
    "export": [
      "self",
      "out_dir"
    ],
    "_wrap_decoder_layers_for_search": [
      "self"
    ],
    "__enter__": [
      "self"
    ]
  },
  "NORM_FCS_MAP": [],
  "FC_FCS_MAP": [],
  "SKIPPED_MODULE": [],
  "skipped_module": [
    "name"
  ],
  "get_weight_scale": [
    "weight",
    "q_group_size"
  ],
  "smooth_ln_fcs": [
    "ln",
    "fcs",
    "act_scales",
    "group_size",
    "alpha"
  ],
  "smooth_fc_fcs": [
    "pre_fc",
    "fcs",
    "act_scales",
    "group_size",
    "alpha"
  ],
  "check_awq_supported": [
    "layer_type"
  ],
  "quant_weights": [
    "model",
    "fcs",
    "bits",
    "symmetry",
    "group_size",
    "device"
  ],
  "smooth_layers": [
    "layers",
    "fc2fcs",
    "norm2fcs",
    "a_scales",
    "group_size",
    "device"
  ],
  "pseudo_quantize_tensor": [
    "w",
    "w_bit",
    "w_group_size",
    "return_scale_zeros"
  ],
  "awq_layers": [
    "layers",
    "fc2fcs",
    "norm2fcs",
    "a_scales",
    "a_ratios",
    "group_size",
    "device"
  ],
  "KVCacheObserver": {
    "__init__": [
      "self",
      "num_head",
      "head_dim"
    ],
    "observe": [
      "self",
      "x"
    ]
  },
  "ActivationObserver": {
    "observed": [],
    "__init__": [
      "self",
      "dim"
    ],
    "disable": [
      "cls"
    ],
    "enable": [
      "cls"
    ],
    "observe": [
      "self",
      "x",
      "save_input"
    ],
    "save_ratio": [
      "self",
      "ratio"
    ]
  },
  "WeightQuantizer": {
    "__init__": [
      "self",
      "bits",
      "symmetry",
      "granularity",
      "group_size"
    ],
    "calculate_qparams": [
      "self",
      "weight"
    ],
    "quant": [
      "self",
      "weight",
      "qparams",
      "real"
    ]
  },
  "_aligned_size": [
    "a",
    "b"
  ],
  "fast_log2_ceil_torch": [
    "x"
  ],
  "fast_pow2_torch": [
    "x"
  ],
  "fast_round_scale_torch": [
    "amax",
    "fp8_max"
  ],
  "_get_quant_scaling": [
    "weight",
    "fp8_dtype",
    "dim",
    "scale_fmt"
  ],
  "quant_blocked_fp8": [
    "weight",
    "fp8_dtype",
    "block_size",
    "scale_fmt"
  ],
  "WeightOnlyQLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "w_bit",
      "symmetry",
      "group_size"
    ],
    "from_linear": [
      "cls",
      "linear",
      "quantizer",
      "awq_layout",
      "qparams"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "check_request": [
    "request",
    "server_context"
  ],
  "find_available_ports": [
    "num"
  ],
  "get_host_ip": [],
  "_run_server": [
    "gpu_ids",
    "model_path"
  ],
  "cleanup_processes": [
    "processes"
  ],
  "launch_server": [
    "num_nodes",
    "node_rank",
    "model_path",
    "backend_config",
    "proxy_url"
  ],
  "VariableInterface": {
    "request_hosts": [],
    "get_session": [
      "session_id"
    ],
    "get_session_manager": [],
    "get_engine_config": []
  },
  "router": [],
  "get_bearer_token": [],
  "server_context": [],
  "check_api_key": [
    "auth"
  ],
  "get_model_list": [],
  "available_models": [],
  "create_error_response": [
    "status",
    "message",
    "error_type"
  ],
  "_create_completion_logprobs": [
    "tokenizer",
    "token_ids",
    "logprobs",
    "skip_special_tokens",
    "offset",
    "all_token_ids",
    "state",
    "spaces_between_special_tokens"
  ],
  "_create_chat_completion_logprobs": [
    "tokenizer",
    "token_ids",
    "logprobs"
  ],
  "health": [],
  "terminate": [],
  "logit_bias_logits_processor": [
    "logit_bias",
    "tokenizer"
  ],
  "chat_completions_v1": [
    "request",
    "raw_request"
  ],
  "completions_v1": [
    "request",
    "raw_request"
  ],
  "generate": [
    "request",
    "raw_request"
  ],
  "create_embeddings": [
    "request",
    "raw_request"
  ],
  "encode": [
    "request",
    "raw_request"
  ],
  "pooling": [
    "request",
    "raw_request"
  ],
  "update_params": [
    "request",
    "raw_request"
  ],
  "sleep": [
    "raw_request"
  ],
  "wakeup": [
    "raw_request"
  ],
  "is_sleeping": [
    "raw_request"
  ],
  "engine_info": [],
  "p2p_initialize": [
    "init_request"
  ],
  "p2p_connect": [
    "conn_request"
  ],
  "p2p_drop_connect": [
    "drop_conn_request"
  ],
  "free_cache": [
    "cache_free_request"
  ],
  "abort_request": [
    "request",
    "raw_request"
  ],
  "chat_interactive_v1": [
    "request",
    "raw_request"
  ],
  "handle_torchrun": [],
  "startup_event": [],
  "shutdown_event": [],
  "validation_exception_handler": [
    "request",
    "exc"
  ],
  "ConcurrencyLimitMiddleware": {
    "__init__": [
      "self",
      "app",
      "max_concurrent_requests"
    ],
    "dispatch": [
      "self",
      "request",
      "call_next"
    ]
  },
  "set_parsers": [
    "reasoning_parser",
    "tool_parser"
  ],
  "mount_metrics": [
    "app",
    "backend_config"
  ],
  "create_lifespan_handler": [
    "backend_config",
    "async_engine"
  ],
  "ErrorResponse": {},
  "ModelPermission": {},
  "ModelCard": {},
  "ModelList": {},
  "UsageInfo": {},
  "Function": {},
  "Tool": {},
  "ToolChoiceFuncName": {},
  "ToolChoice": {},
  "StreamOptions": {},
  "JsonSchema": {
    "model_config": []
  },
  "ResponseFormat": {},
  "ChatCompletionRequest": {},
  "FunctionCall": {},
  "ToolCall": {},
  "ExtractedToolCallInformation": {},
  "ChatMessage": {},
  "LogProbs": {},
  "TopLogprob": {},
  "ChatCompletionTokenLogprob": {},
  "ChoiceLogprobs": {},
  "ChatCompletionResponseChoice": {},
  "ChatCompletionResponse": {},
  "DeltaFunctionCall": {},
  "DeltaToolCall": {},
  "DeltaMessage": {},
  "ChatCompletionResponseStreamChoice": {},
  "ChatCompletionStreamResponse": {},
  "CompletionRequest": {},
  "CompletionResponseChoice": {},
  "CompletionResponse": {},
  "CompletionResponseStreamChoice": {},
  "CompletionStreamResponse": {},
  "EmbeddingsRequest": {},
  "EmbeddingsResponse": {},
  "PoolingRequest": {},
  "PoolingResponse": {},
  "EncodeRequest": {},
  "EncodeResponse": {},
  "GenerateResponse": {},
  "UpdateParamsRequest": {},
  "ImageDataInputItem": [],
  "ImageDataFormat": [],
  "GenerateReqInput": {},
  "GenerateReqMetaOutput": {},
  "GenerateReqOutput": {},
  "AbortRequest": {},
  "_harmony_encoding": [],
  "get_encoding": [],
  "get_streamable_parser_for_assistant": [],
  "GptOssChatParser": {
    "__init__": [
      "self"
    ],
    "parse_streaming": [
      "self",
      "tokens"
    ],
    "parse_full": [
      "self",
      "tokens"
    ]
  },
  "json_loads": [
    "content"
  ],
  "APIClient": {
    "__init__": [
      "self",
      "api_server_url",
      "api_key"
    ],
    "available_models": [
      "self"
    ],
    "encode": [
      "self",
      "input",
      "do_preprocess",
      "add_bos"
    ],
    "chat_completions_v1": [
      "self",
      "model",
      "messages",
      "temperature",
      "top_p",
      "logprobs",
      "top_logprobs",
      "n",
      "max_completion_tokens",
      "max_tokens",
      "stop",
      "stream",
      "presence_penalty",
      "frequency_penalty",
      "user",
      "repetition_penalty",
      "ignore_eos",
      "skip_special_tokens",
      "spaces_between_special_tokens",
      "top_k",
      "min_new_tokens",
      "min_p",
      "logit_bias",
      "stream_options"
    ],
    "completions_v1": [
      "self",
      "model",
      "prompt",
      "suffix",
      "temperature",
      "n",
      "max_completion_tokens",
      "max_tokens",
      "stream",
      "stop",
      "top_p",
      "top_k",
      "user",
      "repetition_penalty",
      "ignore_eos",
      "skip_special_tokens",
      "spaces_between_special_tokens",
      "stream_options"
    ]
  },
  "Qwen2d5ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "get_argments": [
      "self",
      "obj"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ]
  },
  "Llama3JsonToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "find_common_prefix": [
    "s1",
    "s2"
  ],
  "find_common_suffix": [
    "s1",
    "s2"
  ],
  "extract_intermediate_diff": [
    "curr",
    "old"
  ],
  "find_all_indices": [
    "string",
    "substring"
  ],
  "partial_json_loads": [
    "input_str",
    "flags"
  ],
  "is_complete_json": [
    "input_str"
  ],
  "consume_space": [
    "i",
    "s"
  ],
  "Internlm2ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "adjust_request": [
      "self",
      "request"
    ],
    "get_argments": [
      "self",
      "obj"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ]
  },
  "ParserState": {
    "reset_tool_call": [
      "self"
    ]
  },
  "Qwen3ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "get_argments": [
      "self",
      "obj"
    ],
    "_split": [
      "self",
      "parser_state",
      "parsing_content"
    ],
    "_parse_delta_tool_call": [
      "self",
      "parser_state",
      "tool_content"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ]
  },
  "ToolParserManager": [],
  "ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "vocab": [
      "self"
    ],
    "adjust_request": [
      "self",
      "request"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "QwenQwQReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_reasoning_content_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ],
    "extract_reasoning_content": [
      "self",
      "model_output",
      "request"
    ]
  },
  "ReasoningParserManager": [],
  "ReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "vocab": [
      "self"
    ],
    "extract_reasoning_content_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ],
    "extract_reasoning_content": [
      "self",
      "model_output",
      "request"
    ]
  },
  "DeepSeekR1ReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_reasoning_content_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ],
    "extract_reasoning_content": [
      "self",
      "model_output",
      "request"
    ]
  },
  "Status": {},
  "CONTROLLER_HEART_BEAT_EXPIRATION": [],
  "heart_beat_controller": [
    "proxy_controller"
  ],
  "NodeManager": {
    "__init__": [
      "self",
      "config_path",
      "serving_strategy",
      "routing_strategy",
      "migration_protocol",
      "link_type",
      "with_gdr",
      "cache_status"
    ],
    "get_nodes": [
      "self",
      "role"
    ],
    "hybrid_nodes": [
      "self"
    ],
    "prefill_nodes": [
      "self"
    ],
    "decode_nodes": [
      "self"
    ],
    "update_config_file": [
      "self"
    ],
    "add": [
      "self",
      "node_url",
      "status"
    ],
    "remove": [
      "self",
      "node_url"
    ],
    "terminate_node": [
      "self",
      "node_url"
    ],
    "terminate_all_nodes": [
      "self"
    ],
    "remove_stale_nodes_by_expiration": [
      "self"
    ],
    "model_list": [
      "self"
    ],
    "status": [
      "self"
    ],
    "get_node_url": [
      "self",
      "model_name",
      "role"
    ],
    "check_request_model": [
      "self",
      "model_name"
    ],
    "handle_unavailable_model": [
      "self",
      "model_name"
    ],
    "handle_api_timeout": [
      "self",
      "node_url"
    ],
    "stream_generate": [
      "self",
      "request",
      "node_url",
      "endpoint"
    ],
    "generate": [
      "self",
      "request",
      "node_url",
      "endpoint"
    ],
    "pre_call": [
      "self",
      "node_url"
    ],
    "post_call": [
      "self",
      "node_url",
      "start"
    ],
    "create_background_tasks": [
      "self",
      "url",
      "start"
    ]
  },
  "app": [],
  "node_manager": [],
  "node_status": [],
  "add_node": [
    "node",
    "raw_request"
  ],
  "remove_node": [
    "node"
  ],
  "terminate_node": [
    "node"
  ],
  "terminate_node_all": [],
  "connection_warmup": [],
  "cache_block_gc_to_be_migrated": [],
  "proxy": [
    "server_name",
    "server_port",
    "serving_strategy",
    "routing_strategy",
    "api_keys",
    "ssl",
    "log_level",
    "disable_cache_status",
    "link_type",
    "migration_protocol",
    "dummy_prefill"
  ],
  "LATENCY_DEQUE_LEN": [],
  "RoutingStrategy": {
    "RANDOM": [],
    "MIN_EXPECTED_LATENCY": [],
    "MIN_OBSERVED_LATENCY": [],
    "from_str": [
      "cls",
      "name"
    ]
  },
  "ErrorCodes": {
    "MODEL_NOT_FOUND": [],
    "SERVICE_UNAVAILABLE": [],
    "API_TIMEOUT": []
  },
  "err_msg": [],
  "RequestHandlePool": {
    "__init__": [
      "self",
      "engine",
      "size"
    ],
    "get": [
      "self"
    ],
    "put": [
      "self",
      "handle"
    ],
    "clear": [
      "self"
    ]
  },
  "SessionManager": {
    "__init__": [
      "self"
    ],
    "get": [
      "self",
      "session_id"
    ],
    "async_abort_all": [
      "self"
    ],
    "has": [
      "self",
      "session_id"
    ],
    "remove": [
      "self",
      "session"
    ],
    "clear": [
      "self"
    ],
    "attach_event_loop": [
      "self",
      "loop"
    ],
    "build_request_handle_pool": [
      "self",
      "engine",
      "size"
    ]
  },
  "MultimodalProcessor": {
    "__init__": [
      "self",
      "tokenizer",
      "chat_template",
      "vl_encoder",
      "backend"
    ],
    "merge_message_content": [
      "msg"
    ],
    "async_convert_multimodal_data": [
      "messages"
    ],
    "get_prompt_input": [
      "self",
      "prompt",
      "do_preprocess",
      "sequence_start",
      "adapter_name",
      "tools",
      "reasoning_effort",
      "chat_template_kwargs",
      "mm_processor_kwargs"
    ],
    "format_prompts": [
      "prompts"
    ],
    "_is_openai_message": [
      "message"
    ],
    "_is_str_images_pair": [
      "message"
    ],
    "_is_image": [
      "obj"
    ],
    "_is_image_list": [
      "obj"
    ],
    "_re_format_prompt_images_pair": [
      "prompt"
    ],
    "_has_multimodal_input": [
      "self",
      "messages"
    ],
    "_get_text_prompt_input": [
      "self",
      "prompt",
      "do_preprocess",
      "sequence_start",
      "adapter_name",
      "tools",
      "reasoning_effort",
      "chat_template_kwargs"
    ],
    "_get_multimodal_prompt_input": [
      "self",
      "messages",
      "do_preprocess",
      "sequence_start",
      "adapter_name",
      "tools",
      "chat_template_kwargs",
      "mm_processor_kwargs"
    ]
  },
  "SafeRunException": {},
  "VLAsyncEngine": {
    "__init__": [
      "self",
      "model_path",
      "backend",
      "backend_config",
      "vision_config"
    ],
    "close": [
      "self"
    ]
  },
  "GenOut": {
    "to_response": [
      "self",
      "index"
    ]
  },
  "AsyncEngine": {
    "__init__": [
      "self",
      "model_path",
      "model_name",
      "backend",
      "backend_config",
      "chat_template_config",
      "max_log_len",
      "speculative_config"
    ],
    "close": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "_build_turbomind": [
      "self",
      "model_path",
      "backend_config"
    ],
    "_build_pytorch": [
      "self",
      "model_path",
      "backend_config",
      "speculative_config"
    ],
    "_build_stat_loggers": [
      "self"
    ],
    "get_schedule_metrics": [
      "self"
    ],
    "do_log_stats": [
      "self"
    ],
    "stop_all_session": [
      "self"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wakeup": [
      "self",
      "tags"
    ],
    "_determine_gen_config": [
      "self",
      "session",
      "input_ids",
      "gen_config"
    ],
    "safe_run": [
      "self",
      "handle",
      "session"
    ],
    "generate": [
      "self",
      "messages",
      "session_id",
      "gen_config",
      "tools",
      "reasoning_effort",
      "stream_response",
      "sequence_start",
      "sequence_end",
      "step",
      "do_preprocess",
      "adapter_name",
      "rewind_stop_tokens",
      "input_ids",
      "enable_thinking",
      "chat_template_kwargs",
      "mm_processor_kwargs"
    ],
    "start_loop": [
      "self",
      "loop",
      "use_async_api"
    ],
    "free_cache": [
      "self",
      "session_id"
    ],
    "p2p_initialize": [
      "self",
      "init_request"
    ],
    "p2p_connect": [
      "self",
      "conn_request"
    ],
    "p2p_drop_connect": [
      "self",
      "drop_conn_request"
    ],
    "async_get_reward_score": [
      "self",
      "input_ids"
    ],
    "async_get_logits": [
      "self",
      "input_ids",
      "sessions",
      "sequence_start",
      "sequence_end"
    ]
  }
}