{
  "__version__": [],
  "__all__": [],
  "hanning": [
    "size",
    "periodic"
  ],
  "hamming": [
    "size",
    "periodic"
  ],
  "blackman": [
    "size",
    "periodic"
  ],
  "bartlett": [
    "size",
    "periodic"
  ],
  "STR_TO_WINDOW_FN": [],
  "stft": [
    "x",
    "n_fft",
    "hop_length",
    "win_length",
    "window",
    "center",
    "pad_mode"
  ],
  "istft": [
    "x",
    "hop_length",
    "win_length",
    "window",
    "center",
    "length",
    "normalized"
  ],
  "mel_filters": [
    "sample_rate",
    "n_fft",
    "n_mels",
    "f_min",
    "f_max",
    "norm",
    "mel_scale"
  ],
  "ISTFTCache": {
    "__init__": [
      "self"
    ],
    "get_positions": [
      "self",
      "num_frames",
      "frame_length",
      "hop_length"
    ],
    "get_norm_buffer": [
      "self",
      "n_fft",
      "hop_length",
      "win_length",
      "window",
      "num_frames"
    ],
    "istft": [
      "self",
      "real_part",
      "imag_part",
      "n_fft",
      "hop_length",
      "win_length",
      "window",
      "center",
      "audio_length"
    ],
    "clear_cache": [
      "self"
    ],
    "cache_info": [
      "self"
    ]
  },
  "compute_deltas_kaldi": [
    "specgram",
    "win_length",
    "mode"
  ],
  "mel_scale_kaldi": [
    "freq"
  ],
  "inverse_mel_scale_kaldi": [
    "mel_freq"
  ],
  "_next_power_of_2": [
    "x"
  ],
  "_get_strided_kaldi": [
    "waveform",
    "window_size",
    "window_shift",
    "snip_edges"
  ],
  "get_mel_banks_kaldi": [
    "num_bins",
    "window_length_padded",
    "sample_freq",
    "low_freq",
    "high_freq"
  ],
  "compute_fbank_kaldi": [
    "waveform",
    "sample_rate",
    "win_len",
    "win_inc",
    "num_mels",
    "win_type",
    "preemphasis",
    "dither",
    "snip_edges",
    "low_freq",
    "high_freq"
  ],
  "BaseModelArgs": {
    "from_dict": [
      "cls",
      "params"
    ]
  },
  "check_array_shape": [
    "arr"
  ],
  "T": [],
  "from_dict": [
    "data_class",
    "data"
  ],
  "DEFAULT_ALLOW_PATTERNS": [],
  "_is_local_path": [
    "path"
  ],
  "get_model_path": [
    "path_or_hf_repo",
    "revision",
    "force_download",
    "allow_patterns"
  ],
  "load_config": [
    "model_path"
  ],
  "load_weights": [
    "model_path"
  ],
  "apply_quantization": [
    "model",
    "config",
    "weights",
    "model_quant_predicate"
  ],
  "get_model_class": [
    "model_type",
    "model_name",
    "category",
    "model_remapping"
  ],
  "base_load_model": [
    "model_path",
    "category",
    "model_remapping",
    "lazy",
    "strict"
  ],
  "_stt_utils": [],
  "_tts_utils": [],
  "_get_stt_utils": [],
  "_get_tts_utils": [],
  "audio_volume_normalize": [
    "audio",
    "coeff"
  ],
  "random_select_audio_segment": [
    "audio",
    "length"
  ],
  "load_audio": [
    "audio",
    "sample_rate",
    "length",
    "volume_normalize",
    "segment_duration"
  ],
  "is_valid_module_name": [
    "name"
  ],
  "get_model_category": [
    "model_type",
    "model_name"
  ],
  "get_model_name_parts": [
    "model_path"
  ],
  "load_model": [
    "model_name"
  ],
  "MODEL_CONVERSION_DTYPES": [],
  "QUANT_RECIPES": [],
  "Domain": {
    "TTS": [],
    "STT": [],
    "STS": []
  },
  "DomainConfig": {},
  "DOMAIN_CONFIGS": [],
  "_discover_model_types": [
    "domain"
  ],
  "get_model_types": [
    "domain"
  ],
  "_get_config_keys": [
    "config_class"
  ],
  "_discover_detection_hints": [
    "domain"
  ],
  "get_detection_hints": [
    "domain"
  ],
  "_match_by_model_type": [
    "model_type"
  ],
  "_get_model_identifier": [
    "config"
  ],
  "_match_by_config_keys": [
    "config"
  ],
  "_match_by_path": [
    "model_path"
  ],
  "detect_model_domain": [
    "config",
    "model_path"
  ],
  "get_model_type": [
    "config",
    "model_path",
    "domain"
  ],
  "generate_readme_content": [
    "upload_repo",
    "hf_path",
    "domain"
  ],
  "upload_to_hub": [
    "path",
    "upload_repo",
    "hf_path",
    "domain"
  ],
  "build_quant_predicate": [
    "model",
    "quant_predicate_name"
  ],
  "copy_model_files": [
    "source",
    "dest"
  ],
  "convert": [
    "hf_path",
    "mlx_path",
    "quantize",
    "q_group_size",
    "q_bits",
    "dtype",
    "upload_repo",
    "revision",
    "dequantize",
    "quant_predicate",
    "model_domain"
  ],
  "configure_parser": [],
  "main": [],
  "sanitize_for_json": [
    "obj"
  ],
  "MLX_AUDIO_NUM_WORKERS": [],
  "ModelProvider": {
    "__init__": [
      "self"
    ],
    "load_model": [
      "self",
      "model_name"
    ],
    "remove_model": [
      "self",
      "model_name"
    ],
    "get_available_models": [
      "self"
    ]
  },
  "app": [],
  "int_or_float": [
    "value"
  ],
  "calculate_default_workers": [
    "workers"
  ],
  "setup_cors": [
    "app",
    "allowed_origins"
  ],
  "allowed_origins_env": [],
  "default_origins": [],
  "SpeechRequest": {},
  "TranscriptionRequest": {},
  "model_provider": [],
  "root": [],
  "list_models": [],
  "add_model": [
    "model_name"
  ],
  "remove_model": [
    "model_name"
  ],
  "generate_audio": [
    "model",
    "payload"
  ],
  "tts_speech": [
    "payload"
  ],
  "generate_transcription_stream": [
    "stt_model",
    "tmp_path",
    "gen_kwargs"
  ],
  "stt_transcriptions": [
    "file",
    "model",
    "language",
    "verbose",
    "max_tokens",
    "chunk_duration",
    "frame_threshold",
    "stream",
    "context",
    "prefill_step_size",
    "text"
  ],
  "stt_realtime_transcriptions": [
    "websocket"
  ],
  "MLXAudioStudioServer": {
    "__init__": [
      "self",
      "start_ui",
      "log_dir"
    ],
    "start_ui_background": [
      "self"
    ],
    "start_server": [
      "self",
      "host",
      "port",
      "reload",
      "workers"
    ]
  },
  "_FORMAT_MAP": [],
  "_SAMPLE_FORMAT_MAP": [],
  "_detect_format_from_bytes": [
    "data"
  ],
  "_decode_ffmpeg": [
    "input_data"
  ],
  "read": [
    "file",
    "always_2d",
    "dtype"
  ],
  "_check_ffmpeg_available": [],
  "_get_ffmpeg_path": [],
  "_encode_ffmpeg": [
    "data",
    "samplerate",
    "nchannels",
    "output",
    "format",
    "bitrate"
  ],
  "write": [
    "file",
    "data",
    "samplerate",
    "format"
  ],
  "sf_read": [
    "file",
    "always_2d"
  ],
  "sf_write": [
    "file",
    "data",
    "samplerate",
    "format"
  ],
  "detect_speech_boundaries": [
    "wav",
    "sample_rate",
    "window_duration",
    "energy_threshold",
    "margin_factor"
  ],
  "remove_silence_on_both_ends": [
    "wav",
    "sample_rate",
    "window_duration",
    "volume_threshold"
  ],
  "hertz_to_mel": [
    "pitch"
  ],
  "parse_args": [],
  "AudioPlayer": {
    "min_buffer_seconds": [],
    "measure_window": [],
    "ema_alpha": [],
    "__init__": [
      "self",
      "sample_rate",
      "buffer_size"
    ],
    "callback": [
      "self",
      "outdata",
      "frames",
      "time",
      "status"
    ],
    "start_stream": [
      "self"
    ],
    "stop_stream": [
      "self"
    ],
    "buffered_samples": [
      "self"
    ],
    "queue_audio": [
      "self",
      "samples"
    ],
    "wait_for_drain": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "flush": [
      "self"
    ]
  },
  "MODEL_REMAPPING": [],
  "MAX_FILE_SIZE_GB": [],
  "get_available_models": [],
  "get_model_and_args": [
    "model_type",
    "model_name"
  ],
  "load": [
    "model_path",
    "lazy",
    "strict"
  ],
  "fetch_from_hub": [
    "model_path",
    "lazy"
  ],
  "TestVoxCPMIntegration": {
    "test_sanitize_rope_generation": [
      "self"
    ],
    "test_sanitize_audio_vae_prefix_strip": [
      "self"
    ]
  },
  "patched_open_text": [
    "package",
    "resource"
  ],
  "TestSanitizeLSTMWeights": {
    "test_sanitize_lstm_weights": [
      "self"
    ]
  },
  "TestKokoroModel": {
    "test_init": [
      "self",
      "mock_load_weights",
      "mock_mx_load",
      "mock_open",
      "mock_json_load"
    ],
    "test_output_dataclass": [
      "self"
    ]
  },
  "TestKokoroPipeline": {
    "test_aliases_and_lang_codes": [
      "self"
    ],
    "test_init": [
      "self"
    ],
    "test_load_voice": [
      "self"
    ],
    "test_tokens_to_ps": [
      "self"
    ],
    "test_tokens_to_text": [
      "self"
    ],
    "test_result_dataclass": [
      "self"
    ]
  },
  "TestBarkModel": {
    "test_init": [
      "self",
      "mock_tokenizer"
    ],
    "test_sanitize_weights": [
      "self"
    ]
  },
  "TestBarkPipeline": {
    "setUp": [
      "self"
    ],
    "test_generate_text_semantic": [
      "self"
    ],
    "test_generate_coarse": [
      "self",
      "mock_mlx_categorical"
    ],
    "test_generate_fine": [
      "self"
    ]
  },
  "TestLlamaModel": {
    "_default_config": [
      "self"
    ],
    "test_init": [
      "self",
      "mock_tokenizer"
    ],
    "test_generate": [
      "self",
      "mock_tokenizer"
    ],
    "test_sanitize": [
      "self",
      "mock_tokenizer"
    ]
  },
  "TestQwen3Model": {
    "_default_config": [
      "self"
    ],
    "test_init": [
      "self",
      "mock_tokenizer"
    ],
    "test_forward": [
      "self",
      "mock_tokenizer"
    ],
    "test_prepare_input_ids_with_voice": [
      "self",
      "mock_tokenizer"
    ],
    "test_parse_output": [
      "self",
      "mock_tokenizer"
    ],
    "test_sample_rate": [
      "self",
      "mock_tokenizer"
    ],
    "test_layers_property": [
      "self",
      "mock_tokenizer"
    ]
  },
  "TestOuteTTSModel": {
    "_default_config": [
      "self"
    ],
    "test_init": [
      "self",
      "mock_tokenizer"
    ],
    "test_generate": [
      "self",
      "mock_tokenizer"
    ]
  },
  "TestDiaModel": {
    "_default_config": [
      "self"
    ],
    "test_init": [
      "self"
    ]
  },
  "TestSparkTTSModel": {
    "_default_config": [
      "self"
    ],
    "test_init": [
      "self",
      "mock_qwen2_model"
    ]
  },
  "TestIndexTTS": {
    "_default_config": [
      "self"
    ],
    "test_init": [
      "self"
    ]
  },
  "TestVibeVoiceModel": {
    "_default_config": [
      "self"
    ],
    "test_init": [
      "self"
    ],
    "test_sample_rate": [
      "self"
    ],
    "test_get_input_embeddings": [
      "self"
    ],
    "test_sanitize": [
      "self"
    ],
    "test_sanitize_huggingface_keys": [
      "self"
    ],
    "test_config_defaults": [
      "self"
    ]
  },
  "TestChatterboxConfig": {
    "test_t3_config_defaults": [
      "self"
    ],
    "test_model_config_defaults": [
      "self"
    ],
    "test_model_config_from_dict": [
      "self"
    ]
  },
  "TestChatterboxModel": {
    "test_init": [
      "self",
      "mock_s3_tokenizer",
      "mock_ve",
      "mock_s3gen",
      "mock_t3"
    ],
    "test_sanitize": [
      "self",
      "mock_s3_tokenizer",
      "mock_ve_class",
      "mock_s3gen_class",
      "mock_t3_class"
    ]
  },
  "TestChatterboxTurboConfig": {
    "test_t3_config_defaults": [
      "self"
    ],
    "test_t3_config_turbo_factory": [
      "self"
    ],
    "test_t3_config_is_multilingual": [
      "self"
    ]
  },
  "TestChatterboxTurboPuncNorm": {
    "test_empty_string": [
      "self"
    ],
    "test_capitalizes_first_letter": [
      "self"
    ],
    "test_adds_period_if_missing": [
      "self"
    ],
    "test_keeps_existing_punctuation": [
      "self"
    ],
    "test_removes_multiple_spaces": [
      "self"
    ],
    "test_replaces_special_punctuation": [
      "self"
    ]
  },
  "TestChatterboxTurboModel": {
    "test_init_with_config": [
      "self",
      "mock_s3_tokenizer",
      "mock_ve",
      "mock_s3gen",
      "mock_t3"
    ],
    "test_init_with_none": [
      "self",
      "mock_s3_tokenizer",
      "mock_ve",
      "mock_s3gen",
      "mock_t3"
    ],
    "test_sanitize": [
      "self",
      "mock_s3_tokenizer",
      "mock_ve_class",
      "mock_s3gen_class",
      "mock_t3_class"
    ],
    "test_sanitize_with_other_weights": [
      "self",
      "mock_s3_tokenizer",
      "mock_ve_class",
      "mock_s3gen_class",
      "mock_t3_class"
    ]
  },
  "TestChatterboxTurboConditionals": {
    "test_conditionals_dataclass": [
      "self"
    ]
  },
  "TestChatterboxTurboModelAlias": {
    "test_model_alias": [
      "self"
    ]
  },
  "TestSoprano": {
    "_default_config": [
      "self"
    ],
    "test_decoder_config_defaults": [
      "self"
    ],
    "test_model_config_defaults": [
      "self"
    ],
    "test_model_config_post_init": [
      "self"
    ],
    "test_model_init": [
      "self"
    ],
    "test_sample_rate_property": [
      "self"
    ],
    "test_layers_property": [
      "self"
    ],
    "test_sanitize": [
      "self"
    ],
    "test_sanitize_decoder_float32": [
      "self"
    ],
    "test_format_duration": [
      "self"
    ],
    "test_clean_text": [
      "self"
    ],
    "test_normalize_numbers": [
      "self"
    ],
    "test_expand_abbreviations": [
      "self"
    ],
    "test_expand_special_characters": [
      "self"
    ],
    "test_collapse_whitespace": [
      "self"
    ],
    "test_dedup_punctuation": [
      "self"
    ],
    "test_convert_to_ascii": [
      "self"
    ],
    "test_num_to_words": [
      "self"
    ],
    "test_ordinal_to_words": [
      "self"
    ],
    "test_decoder_init": [
      "self"
    ],
    "test_decoder_default_intermediate_dim": [
      "self"
    ],
    "test_istft_head_init": [
      "self"
    ],
    "test_istft_head_forward": [
      "self"
    ]
  },
  "TestQwen3TTSModel": {
    "_default_talker_config": [
      "self"
    ],
    "_default_config": [
      "self",
      "tts_model_type"
    ],
    "test_config_init": [
      "self"
    ],
    "test_config_custom_voice": [
      "self"
    ],
    "test_config_voice_design": [
      "self"
    ],
    "test_model_init": [
      "self"
    ],
    "test_model_supported_speakers": [
      "self"
    ],
    "test_model_supported_languages": [
      "self"
    ],
    "test_talker_init": [
      "self"
    ],
    "test_talker_forward": [
      "self"
    ],
    "test_code_predictor_init": [
      "self"
    ],
    "test_code_predictor_forward": [
      "self"
    ],
    "test_generate_routing_base": [
      "self"
    ],
    "test_generate_routing_custom_voice_requires_voice": [
      "self"
    ],
    "test_generate_routing_voice_design_requires_instruct": [
      "self"
    ],
    "test_speaker_encoder_config": [
      "self"
    ],
    "test_mel_spectrogram": [
      "self"
    ]
  },
  "TestQwen3TTSEncoder": {
    "_default_encoder_config": [
      "self"
    ],
    "test_encoder_init": [
      "self"
    ],
    "test_encoder_components": [
      "self"
    ],
    "test_encoder_cache_init": [
      "self"
    ],
    "test_encoder_encode_output_shape": [
      "self"
    ],
    "test_encoder_encode_different_lengths": [
      "self"
    ],
    "test_encoder_encode_truncates_quantizers": [
      "self"
    ],
    "test_encoder_encode_code_range": [
      "self"
    ],
    "test_encoder_causal_mask": [
      "self"
    ],
    "test_encoder_downsample_stride": [
      "self"
    ]
  },
  "TestQwen3TTSPrepareICLInputs": {
    "_make_model_with_mocks": [
      "self",
      "hidden_size",
      "num_code_groups",
      "vocab_size"
    ],
    "test_prepare_icl_output_shapes": [
      "self"
    ],
    "test_prepare_icl_non_streaming_structure": [
      "self"
    ],
    "test_prepare_icl_trailing_is_tts_pad": [
      "self"
    ],
    "test_prepare_icl_ref_audio_dim_handling": [
      "self"
    ],
    "test_prepare_icl_ref_audio_2d_handling": [
      "self"
    ],
    "test_prepare_icl_language_id": [
      "self"
    ],
    "test_prepare_icl_no_tokenizer_raises": [
      "self"
    ],
    "test_prepare_icl_codec_embed_includes_bos": [
      "self"
    ]
  },
  "TestQwen3TTSGenerateICL": {
    "_make_icl_model": [
      "self",
      "hidden_size",
      "num_code_groups",
      "vocab_size"
    ],
    "test_generate_icl_produces_result": [
      "self"
    ],
    "test_generate_icl_calls_speech_tokenizer_decode": [
      "self"
    ],
    "test_generate_icl_eos_stops_generation": [
      "self"
    ],
    "test_generate_icl_max_tokens_limit": [
      "self"
    ],
    "test_generate_icl_text_based_max_tokens_cap": [
      "self"
    ],
    "test_generate_icl_repetition_penalty_applied": [
      "self"
    ],
    "test_generate_icl_ref_codes_prepended": [
      "self"
    ],
    "test_generate_icl_proportional_trimming": [
      "self"
    ],
    "test_generate_routing_uses_icl_when_ref_audio_provided": [
      "self"
    ],
    "test_generate_routing_icl_rep_penalty_floor": [
      "self"
    ],
    "test_generate_routing_icl_rep_penalty_passthrough": [
      "self"
    ],
    "test_generate_routing_no_icl_without_encoder": [
      "self"
    ],
    "test_generate_routing_no_icl_without_ref_text": [
      "self"
    ]
  },
  "TestQwen3TTSStreamingDecode": {
    "_make_model": [
      "self",
      "hidden_size",
      "num_code_groups",
      "vocab_size"
    ],
    "test_decode_chunk_uses_streaming_decode": [
      "self"
    ],
    "test_decode_chunk_respects_chunk_tokens_parameter": [
      "self"
    ],
    "test_streaming_chunk_size_calculation": [
      "self"
    ]
  },
  "TestInterpolate": {
    "test_interpolate_input_validation": [
      "self"
    ],
    "test_interpolate_size_handling": [
      "self"
    ],
    "test_interpolate1d_nearest": [
      "self"
    ],
    "test_interpolate1d_linear": [
      "self"
    ]
  },
  "TestVoxCPM": {
    "test_audio_vae_shape": [
      "self"
    ],
    "test_sanitize_weight_norm": [
      "self"
    ],
    "test_model_init": [
      "self"
    ]
  },
  "TestConvert": {
    "setUp": [
      "self"
    ],
    "tearDown": [
      "self"
    ],
    "test_basic_conversion": [
      "self"
    ],
    "test_quantized_conversion": [
      "self"
    ],
    "test_quantized_conversion_invalid_group_size_raises_error": [
      "self"
    ],
    "test_quantization_recipes": [
      "self"
    ],
    "test_dequantize_flag": [
      "self"
    ],
    "test_upload_repo_argument": [
      "self"
    ]
  },
  "TestReflectPad1d": {
    "test_no_padding": [
      "self"
    ],
    "test_pad_1": [
      "self"
    ],
    "test_pad_2": [
      "self"
    ],
    "test_output_shape": [
      "self"
    ],
    "test_multichannel": [
      "self"
    ]
  },
  "TestTimeDelayNetBlockReflectPadding": {
    "test_output_shape_preserves_time": [
      "self"
    ],
    "test_output_shape_with_dilation": [
      "self"
    ],
    "test_output_shape_kernel5_dilation2": [
      "self"
    ],
    "test_kernel1_no_padding": [
      "self"
    ],
    "test_pad_calculation": [
      "self"
    ],
    "test_output_is_relu_activated": [
      "self"
    ]
  },
  "TestMelSpectrogram": {
    "_get_random_audio": [
      "self"
    ],
    "test_output_shape_with_padding": [
      "self"
    ],
    "test_slaney_norm_values": [
      "self"
    ],
    "test_slaney_mel_scale": [
      "self"
    ],
    "test_reflect_padding_values": [
      "self"
    ],
    "test_sine_wave_mel_bins": [
      "self"
    ],
    "test_overall_statistics": [
      "self"
    ]
  },
  "TestBaseModel": {
    "test_base_model_args_from_dict": [
      "self"
    ],
    "test_check_array_shape": [
      "self"
    ]
  },
  "interpolate": [
    "input",
    "size",
    "scale_factor",
    "mode",
    "align_corners"
  ],
  "interpolate1d": [
    "input",
    "size",
    "mode",
    "align_corners"
  ],
  "adjust_speed": [
    "audio_array",
    "speed_factor"
  ],
  "GenerationResult": {},
  "ConvRMSNorm": {
    "__init__": [
      "self",
      "dim",
      "eps",
      "elementwise_affine"
    ],
    "_norm": [
      "self",
      "x"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "CausalConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "groups",
      "bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "CausalConvTranspose1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "bias",
      "trim_right_ratio"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DepthwiseConv": {
    "__init__": [
      "self",
      "dim",
      "kernel_size",
      "causal",
      "bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Mixer": {
    "__init__": [
      "self",
      "dim",
      "kernel_size",
      "causal",
      "bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "FeedForward": {
    "__init__": [
      "self",
      "dim",
      "mult",
      "bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Block1D": {
    "__init__": [
      "self",
      "dim",
      "layernorm",
      "eps",
      "causal",
      "bias",
      "layer_scale_init_value"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "StemConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "UpsampleLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "HeadConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "TokenizerDecoder": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "AcousticTokenizer": {
    "__init__": [
      "self",
      "config"
    ],
    "decode": [
      "self",
      "latents"
    ],
    "__call__": [
      "self",
      "latents"
    ]
  },
  "RMSNorm": {
    "__init__": [
      "self",
      "dim",
      "eps",
      "elementwise_affine"
    ],
    "_norm": [
      "self",
      "x"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "modulate": [
    "x",
    "shift",
    "scale"
  ],
  "TimestepEmbedder": {
    "__init__": [
      "self",
      "hidden_size",
      "frequency_embedding_size"
    ],
    "timestep_embedding": [
      "t",
      "dim",
      "max_period"
    ],
    "__call__": [
      "self",
      "t"
    ]
  },
  "FeedForwardNetwork": {
    "__init__": [
      "self",
      "embed_dim",
      "ffn_dim"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "HeadLayer": {
    "__init__": [
      "self",
      "embed_dim",
      "ffn_dim",
      "cond_dim",
      "norm_eps"
    ],
    "__call__": [
      "self",
      "x",
      "c"
    ]
  },
  "FinalLayer": {
    "__init__": [
      "self",
      "hidden_size",
      "output_size",
      "cond_size",
      "norm_eps"
    ],
    "__call__": [
      "self",
      "x",
      "c"
    ]
  },
  "DiffusionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "noisy_images",
      "timesteps",
      "condition"
    ]
  },
  "TTS_TEXT_WINDOW_SIZE": [],
  "TTS_SPEECH_WINDOW_SIZE": [],
  "Model": {
    "__init__": [
      "self",
      "config"
    ],
    "sample_rate": [
      "self"
    ],
    "load_voice": [
      "self",
      "voice"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "sanitize": [
      "self",
      "weights"
    ],
    "post_load_hook": [
      "cls",
      "model",
      "model_path"
    ],
    "sample_speech_tokens": [
      "self",
      "condition",
      "neg_condition",
      "cfg_scale",
      "ddpm_steps"
    ],
    "generate": [
      "self",
      "text",
      "max_tokens",
      "cfg_scale",
      "ddpm_steps",
      "voice",
      "verbose"
    ],
    "_generate_multi_speaker": [
      "self",
      "dialogue",
      "max_tokens",
      "cfg_scale",
      "ddpm_steps",
      "verbose"
    ],
    "_generate_single_speaker": [
      "self",
      "text",
      "max_tokens",
      "cfg_scale",
      "ddpm_steps",
      "verbose"
    ]
  },
  "betas_for_alpha_bar": [
    "num_diffusion_timesteps",
    "max_beta",
    "alpha_transform_type"
  ],
  "SchedulerOutput": {},
  "DPMSolverMultistepScheduler": {
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "prediction_type",
      "solver_order",
      "lower_order_final",
      "final_sigmas_type"
    ],
    "step_index": [
      "self"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps"
    ],
    "_convert_model_output": [
      "self",
      "model_output",
      "sample",
      "step_idx"
    ],
    "_dpm_solver_first_order_update": [
      "self",
      "x0_pred",
      "sample",
      "step_idx"
    ],
    "_dpm_solver_second_order_update": [
      "self",
      "x0_pred",
      "prev_x0",
      "sample",
      "step_idx"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "prev_x0"
    ],
    "reset": [
      "self"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ]
  },
  "AcousticTokenizerConfig": {},
  "DiffusionHeadConfig": {},
  "Qwen2DecoderConfig": {},
  "ModelConfig": {
    "from_dict": [
      "cls",
      "params"
    ]
  },
  "RotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "base"
    ],
    "_compute_inv_freq": [
      "self"
    ],
    "__call__": [
      "self",
      "position_ids"
    ]
  },
  "rotate_half": [
    "x"
  ],
  "apply_rotary_pos_emb": [
    "q",
    "k",
    "cos",
    "sin"
  ],
  "Attention": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x",
      "cos",
      "sin",
      "mask",
      "cache"
    ]
  },
  "MLP": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DecoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x",
      "cos",
      "sin",
      "mask",
      "cache"
    ]
  },
  "SpeechConnector": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "eps"
    ],
    "__call__": [
      "self",
      "features"
    ]
  },
  "BinaryClassifier": {
    "__init__": [
      "self",
      "hidden_size"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Qwen2Model": {
    "__init__": [
      "self",
      "config",
      "use_norm"
    ],
    "__call__": [
      "self",
      "inputs_embeds",
      "input_ids",
      "mask",
      "cache",
      "is_causal"
    ]
  },
  "VibeVoiceLanguageModel": {
    "__init__": [
      "self",
      "config",
      "tts_backbone_num_hidden_layers"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "embeddings"
    ]
  },
  "ScalarQuantizationLayer": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "latent_dim",
      "scale"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "SinusoidalPosEmb": {
    "__init__": [
      "self",
      "dim"
    ],
    "__call__": [
      "self",
      "x",
      "scale"
    ]
  },
  "TimestepEmbedding": {
    "__init__": [
      "self",
      "in_channels",
      "time_embed_dim",
      "out_dim"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "VoxCPMLocDiT": {
    "__init__": [
      "self",
      "config",
      "in_channels"
    ],
    "__call__": [
      "self",
      "x",
      "mu",
      "t",
      "cond",
      "dt"
    ]
  },
  "UnifiedCFM": {
    "__init__": [
      "self",
      "in_channels",
      "cfm_params",
      "estimator",
      "mean_mode"
    ],
    "solve_euler": [
      "self",
      "x",
      "t_span",
      "mu",
      "cond",
      "cfg_value",
      "use_cfg_zero_star"
    ],
    "sample": [
      "self",
      "mu",
      "n_timesteps",
      "patch_size",
      "cond",
      "temperature",
      "cfg_value"
    ]
  },
  "CausalTransposeConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "output_padding",
      "bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Snake1d": {
    "__init__": [
      "self",
      "channels"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "CausalResidualUnit": {
    "__init__": [
      "self",
      "dim",
      "dilation",
      "kernel",
      "groups"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "CausalEncoderBlock": {
    "__init__": [
      "self",
      "output_dim",
      "input_dim",
      "stride",
      "groups"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "CausalEncoder": {
    "__init__": [
      "self",
      "d_model",
      "latent_dim",
      "strides",
      "depthwise"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "NoiseBlock": {
    "__init__": [
      "self",
      "dim"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "CausalDecoderBlock": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "stride",
      "groups",
      "use_noise_block"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "CausalDecoder": {
    "__init__": [
      "self",
      "input_channel",
      "channels",
      "rates",
      "depthwise",
      "d_out",
      "use_noise_block"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "AudioVAE": {
    "__init__": [
      "self",
      "config"
    ],
    "encode": [
      "self",
      "x",
      "sample_rate"
    ],
    "decode": [
      "self",
      "z"
    ],
    "preprocess": [
      "self",
      "audio_data",
      "sample_rate"
    ],
    "sanitize": [
      "self",
      "weights"
    ]
  },
  "MiniCPMLongRoPE": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "position_ids"
    ]
  },
  "MiniCPMDecoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x",
      "cos",
      "sin",
      "mask",
      "cache"
    ]
  },
  "MiniCPMModel": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "inputs_embeds",
      "input_ids",
      "mask",
      "cache",
      "is_causal"
    ]
  },
  "LMConfig": {},
  "EncoderConfig": {},
  "CFMConfig": {},
  "DiTConfig": {},
  "AudioVAEConfig": {},
  "ModelArgs": {
    "from_dict": [
      "cls",
      "config"
    ]
  },
  "VoxCPMLocEnc": {
    "__init__": [
      "self",
      "config",
      "input_dim"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ISTFTHead": {
    "__init__": [
      "self",
      "dim",
      "n_fft",
      "hop_length",
      "padding"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "SopranoDecoder": {
    "__init__": [
      "self",
      "num_input_channels",
      "decoder_num_layers",
      "decoder_dim",
      "decoder_intermediate_dim",
      "hop_length",
      "n_fft",
      "upscale",
      "dw_kernel"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DecoderConfig": {},
  "SopranoModel": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "input_ids",
      "cache"
    ]
  },
  "ONES": [],
  "TENS": [],
  "ORDINALS": [],
  "_num_to_words": [
    "n"
  ],
  "_ordinal_to_words": [
    "n"
  ],
  "_abbreviations": [],
  "_cased_abbreviations": [],
  "expand_abbreviations": [
    "text"
  ],
  "_num_prefix_re": [],
  "_num_suffix_re": [],
  "_comma_number_re": [],
  "_dollars_re": [],
  "_ordinal_re": [],
  "_number_re": [],
  "_expand_num_prefix": [
    "m"
  ],
  "_expand_num_suffix": [
    "m"
  ],
  "_remove_commas": [
    "m"
  ],
  "_expand_dollars": [
    "m"
  ],
  "_expand_ordinal": [
    "m"
  ],
  "_expand_number": [
    "m"
  ],
  "normalize_numbers": [
    "text"
  ],
  "_special_characters": [],
  "expand_special_characters": [
    "text"
  ],
  "lowercase": [
    "text"
  ],
  "convert_to_ascii": [
    "text"
  ],
  "remove_unknown_characters": [
    "text"
  ],
  "collapse_whitespace": [
    "text"
  ],
  "dedup_punctuation": [
    "text"
  ],
  "clean_text": [
    "text"
  ],
  "TOKENIZER_LENGTH": [],
  "START_OF_TEXT": [],
  "END_OF_TEXT": [],
  "START_OF_SPEECH": [],
  "END_OF_SPEECH": [],
  "START_OF_HUMAN": [],
  "END_OF_HUMAN": [],
  "START_OF_AI": [],
  "END_OF_AI": [],
  "PAD_TOKEN": [],
  "AUDIO_TOKENS_START": [],
  "snac_model": [],
  "decode_audio_from_codes": [
    "code_list"
  ],
  "encode_audio_to_codes": [
    "audio"
  ],
  "logger": [],
  "TokenizedText": {},
  "SentencePieceTokenizer": {
    "__init__": [
      "self",
      "n_bins",
      "tokenizer_path"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "LUTConditioner": {
    "__init__": [
      "self",
      "n_bins",
      "tokenizer_path",
      "dim",
      "output_dim"
    ],
    "prepare": [
      "self",
      "text"
    ],
    "__call__": [
      "self",
      "inputs"
    ]
  },
  "FlowNet2": [],
  "lsd_decode": [
    "v_t",
    "x_0",
    "num_steps"
  ],
  "FlowLMModel": {
    "__init__": [
      "self",
      "conditioner",
      "flow_net",
      "transformer",
      "dim",
      "ldim",
      "stats_ema_decay",
      "text_padding_weight",
      "dtype"
    ],
    "make_cache": [
      "self"
    ],
    "backbone": [
      "self",
      "input_",
      "text_embeddings",
      "sequence",
      "cache"
    ],
    "__call__": [
      "self",
      "sequence",
      "text_embeddings",
      "cache",
      "lsd_decode_steps",
      "temp",
      "noise_clamp",
      "eos_threshold"
    ],
    "_sample_next_latent": [
      "self",
      "sequence",
      "text_embeddings",
      "cache",
      "lsd_decode_steps",
      "temp",
      "noise_clamp",
      "eos_threshold"
    ],
    "from_config": [
      "cls",
      "config",
      "latent_dim"
    ]
  },
  "_reset_kv_cache": [
    "cache"
  ],
  "pad_for_conv1d": [
    "x",
    "kernel_size",
    "stride",
    "padding_total"
  ],
  "DummyQuantizer": {
    "__init__": [
      "self",
      "dimension",
      "output_dimension"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "MimiAdapter": {
    "__init__": [
      "self",
      "encoder",
      "decoder",
      "quantizer",
      "frame_rate",
      "encoder_frame_rate",
      "sample_rate",
      "channels",
      "encoder_transformer",
      "decoder_transformer"
    ],
    "frame_size": [
      "self"
    ],
    "reset_state": [
      "self"
    ],
    "_to_framerate": [
      "self",
      "x"
    ],
    "_to_encoder_framerate": [
      "self",
      "x"
    ],
    "_to_encoder_framerate_step": [
      "self",
      "x"
    ],
    "encode_to_latent": [
      "self",
      "x"
    ],
    "decode_from_latent": [
      "self",
      "latent"
    ],
    "decode_step": [
      "self",
      "latent"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "_voices_names": [],
  "PREDEFINED_VOICES": [],
  "make_cache_directory": [],
  "download_if_necessary": [
    "path"
  ],
  "load_predefined_voice": [
    "voice_name"
  ],
  "_rms_norm": [
    "x",
    "alpha",
    "eps"
  ],
  "LayerNorm": {
    "__init__": [
      "self",
      "channels",
      "eps",
      "elementwise_affine"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ResBlock": {
    "__init__": [
      "self",
      "channels"
    ],
    "__call__": [
      "self",
      "x",
      "y"
    ]
  },
  "SimpleMLPAdaLN": {
    "__init__": [
      "self",
      "in_channels",
      "model_channels",
      "out_channels",
      "cond_channels",
      "num_res_blocks",
      "num_time_conds"
    ],
    "from_pydantic_config": [
      "cls",
      "cfg",
      "latent_dim",
      "cond_dim"
    ],
    "__call__": [
      "self",
      "c",
      "s",
      "t",
      "x"
    ]
  },
  "create_additive_causal_mask": [
    "N",
    "offset"
  ],
  "LayerScale": {
    "__init__": [
      "self",
      "channels",
      "init"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "StreamingMultiheadAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "rope"
    ],
    "__call__": [
      "self",
      "query",
      "cache"
    ]
  },
  "StreamingTransformerLayer": {
    "__init__": [
      "self",
      "d_model",
      "num_heads",
      "dim_feedforward",
      "rope",
      "layer_scale"
    ],
    "_apply_scale": [
      "self",
      "x",
      "layer_scale"
    ],
    "__call__": [
      "self",
      "x",
      "cache"
    ]
  },
  "StreamingTransformer": {
    "__init__": [
      "self",
      "d_model",
      "num_heads",
      "num_layers",
      "dim_feedforward",
      "max_period",
      "layer_scale"
    ],
    "__call__": [
      "self",
      "x",
      "cache"
    ],
    "make_cache": [
      "self"
    ]
  },
  "DEFAULT_TEMPERATURE": [],
  "DEFAULT_LSD_DECODE_STEPS": [],
  "DEFAULT_NOISE_CLAMP": [],
  "DEFAULT_EOS_THRESHOLD": [],
  "DEFAULT_AUDIO_PROMPT": [],
  "_format_duration": [
    "duration_seconds"
  ],
  "_build_generation_result": [
    "audio",
    "sample_rate",
    "start_time",
    "segment_idx",
    "token_count"
  ],
  "prepare_text_prompt": [
    "text"
  ],
  "split_into_best_sentences": [
    "tokenizer",
    "text_to_generate"
  ],
  "_filter_fields": [
    "cls",
    "data"
  ],
  "FlowConfig": {
    "from_dict": [
      "cls",
      "config"
    ]
  },
  "FlowLMTransformerConfig": {
    "from_dict": [
      "cls",
      "config"
    ]
  },
  "LookupTable": {
    "from_dict": [
      "cls",
      "config"
    ]
  },
  "FlowLMConfig": {
    "from_dict": [
      "cls",
      "config"
    ]
  },
  "SEANetConfig": {
    "from_dict": [
      "cls",
      "config"
    ]
  },
  "MimiTransformerConfig": {
    "from_dict": [
      "cls",
      "config"
    ]
  },
  "QuantizerConfig": {
    "from_dict": [
      "cls",
      "config"
    ]
  },
  "MimiConfig": {
    "from_dict": [
      "cls",
      "config"
    ]
  },
  "load_yaml_config": [
    "path"
  ],
  "apply_rope": [
    "q",
    "k",
    "offset",
    "max_period"
  ],
  "sanitize_lstm_weights": [
    "key",
    "state_dict"
  ],
  "ALIASES": [],
  "LANG_CODES": [],
  "KokoroPipeline": {
    "__init__": [
      "self",
      "lang_code",
      "model",
      "repo_id",
      "trf"
    ],
    "load_single_voice": [
      "self",
      "voice"
    ],
    "load_voice": [
      "self",
      "voice",
      "delimiter"
    ],
    "tokens_to_ps": [
      "cls",
      "tokens"
    ],
    "waterfall_last": [
      "cls",
      "tokens",
      "next_count",
      "waterfall",
      "bumps"
    ],
    "tokens_to_text": [
      "cls",
      "tokens"
    ],
    "en_tokenize": [
      "self",
      "tokens"
    ],
    "infer": [
      "cls",
      "model",
      "ps",
      "pack",
      "speed"
    ],
    "generate_from_tokens": [
      "self",
      "tokens",
      "voice",
      "speed",
      "model"
    ],
    "join_timestamps": [
      "cls",
      "tokens",
      "pred_dur"
    ],
    "__call__": [
      "self",
      "text",
      "voice",
      "speed",
      "split_pattern"
    ]
  },
  "load_voice_tensor": [
    "path"
  ],
  "get_padding": [
    "kernel_size",
    "dilation"
  ],
  "compute_norm": [
    "x",
    "p",
    "dim",
    "keepdim"
  ],
  "weight_norm": [
    "weight_v",
    "weight_g",
    "dim"
  ],
  "ConvWeighted": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "encode"
    ],
    "__call__": [
      "self",
      "x",
      "conv"
    ]
  },
  "_InstanceNorm": {
    "__init__": [
      "self",
      "num_features",
      "eps",
      "momentum",
      "affine",
      "track_running_stats"
    ],
    "_check_input_dim": [
      "self",
      "input"
    ],
    "_get_no_batch_dim": [
      "self"
    ],
    "_handle_no_batch_input": [
      "self",
      "input"
    ],
    "_apply_instance_norm": [
      "self",
      "input"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "InstanceNorm1d": {
    "_get_no_batch_dim": [
      "self"
    ],
    "_check_input_dim": [
      "self",
      "input"
    ]
  },
  "AdaIN1d": {
    "__init__": [
      "self",
      "style_dim",
      "num_features"
    ],
    "__call__": [
      "self",
      "x",
      "s"
    ]
  },
  "AdaINResBlock1": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "dilation",
      "style_dim"
    ],
    "__call__": [
      "self",
      "x",
      "s"
    ]
  },
  "mlx_angle": [
    "z",
    "deg"
  ],
  "mlx_unwrap": [
    "p",
    "discont",
    "axis",
    "period"
  ],
  "MLXSTFT": {
    "__init__": [
      "self",
      "filter_length",
      "hop_length",
      "win_length",
      "window"
    ],
    "transform": [
      "self",
      "input_data"
    ],
    "inverse": [
      "self",
      "magnitude",
      "phase"
    ],
    "__call__": [
      "self",
      "input_data"
    ]
  },
  "SineGen": {
    "__init__": [
      "self",
      "samp_rate",
      "upsample_scale",
      "harmonic_num",
      "sine_amp",
      "noise_std",
      "voiced_threshold",
      "flag_for_pulse"
    ],
    "_f02uv": [
      "self",
      "f0"
    ],
    "_f02sine": [
      "self",
      "f0_values"
    ],
    "__call__": [
      "self",
      "f0"
    ]
  },
  "SourceModuleHnNSF": {
    "__init__": [
      "self",
      "sampling_rate",
      "upsample_scale",
      "harmonic_num",
      "sine_amp",
      "add_noise_std",
      "voiced_threshod"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ReflectionPad1d": {
    "__init__": [
      "self",
      "padding"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "leaky_relu": [
    "x",
    "negative_slope"
  ],
  "Generator": {
    "__init__": [
      "self",
      "style_dim",
      "resblock_kernel_sizes",
      "upsample_rates",
      "upsample_initial_channel",
      "resblock_dilation_sizes",
      "upsample_kernel_sizes",
      "gen_istft_n_fft",
      "gen_istft_hop_size"
    ],
    "__call__": [
      "self",
      "x",
      "s",
      "f0"
    ]
  },
  "UpSample1d": {
    "__init__": [
      "self",
      "layer_type"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "AdainResBlk1d": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "style_dim",
      "actv",
      "upsample",
      "dropout_p",
      "bias",
      "conv_type"
    ],
    "_build_weights": [
      "self",
      "dim_in",
      "dim_out",
      "style_dim"
    ],
    "_shortcut": [
      "self",
      "x"
    ],
    "_residual": [
      "self",
      "x",
      "s"
    ],
    "__call__": [
      "self",
      "x",
      "s"
    ]
  },
  "Decoder": {
    "__init__": [
      "self",
      "dim_in",
      "style_dim",
      "dim_out",
      "resblock_kernel_sizes",
      "upsample_rates",
      "upsample_initial_channel",
      "resblock_dilation_sizes",
      "upsample_kernel_sizes",
      "gen_istft_n_fft",
      "gen_istft_hop_size"
    ],
    "__call__": [
      "self",
      "asr",
      "F0_curve",
      "N",
      "s"
    ],
    "sanitize": [
      "self",
      "key",
      "weights"
    ]
  },
  "LinearNorm": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "bias",
      "w_init_gain"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "TextEncoder": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "depth",
      "n_symbols",
      "actv"
    ],
    "__call__": [
      "self",
      "x",
      "input_lengths",
      "m"
    ]
  },
  "AdaLayerNorm": {
    "__init__": [
      "self",
      "style_dim",
      "channels",
      "eps"
    ],
    "__call__": [
      "self",
      "x",
      "s"
    ]
  },
  "LSTM": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "bias",
      "batch_first"
    ],
    "_extra_repr": [
      "self"
    ],
    "_forward_direction": [
      "self",
      "x",
      "hidden",
      "cell"
    ],
    "_backward_direction": [
      "self",
      "x",
      "hidden",
      "cell"
    ],
    "__call__": [
      "self",
      "x",
      "hidden_forward",
      "cell_forward",
      "hidden_backward",
      "cell_backward"
    ]
  },
  "ProsodyPredictor": {
    "__init__": [
      "self",
      "style_dim",
      "d_hid",
      "nlayers",
      "max_dur",
      "dropout"
    ],
    "__call__": [
      "self",
      "texts",
      "style",
      "text_lengths",
      "alignment",
      "m"
    ],
    "F0Ntrain": [
      "self",
      "x",
      "s"
    ]
  },
  "DurationEncoder": {
    "__init__": [
      "self",
      "sty_dim",
      "d_model",
      "nlayers",
      "dropout"
    ],
    "__call__": [
      "self",
      "x",
      "style",
      "text_lengths",
      "m"
    ]
  },
  "AlbertModelArgs": {},
  "AlbertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids"
    ]
  },
  "AlbertSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "AlbertSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "AlbertIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "AlbertOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "AlbertLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask"
    ],
    "ff_chunk": [
      "self",
      "attention_output"
    ]
  },
  "AlbertLayerGroup": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "AlbertEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "CustomAlbert": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ],
    "sanitize": [
      "self",
      "weights"
    ]
  },
  "process_audio_array": [
    "audio",
    "sample_rate",
    "target_loudness",
    "peak_limit",
    "block_size"
  ],
  "DacInterface": {
    "__init__": [
      "self",
      "repo_id"
    ],
    "convert_audio": [
      "self",
      "audio",
      "sr",
      "target_sr",
      "target_channels"
    ],
    "convert_audio_array": [
      "self",
      "audio",
      "sr"
    ],
    "load_audio": [
      "self",
      "path"
    ],
    "preprocess": [
      "self",
      "audio_data"
    ],
    "encode": [
      "self",
      "x",
      "win_duration",
      "verbose"
    ],
    "decode": [
      "self",
      "codes",
      "verbose"
    ]
  },
  "SpecialTokens": {
    "to_dict": [
      "self"
    ]
  },
  "calculate_pitch": [
    "audio_array",
    "sr",
    "min_freq",
    "max_freq",
    "frame_length",
    "hop_length",
    "threshold"
  ],
  "extract_single_pitch_value": [
    "audio_array",
    "sr",
    "min_freq",
    "max_freq",
    "frame_length",
    "hop_length",
    "threshold"
  ],
  "Features": {
    "__init__": [
      "self"
    ],
    "scale_values": [
      "self",
      "value"
    ],
    "features_to_tokens": [
      "self",
      "features"
    ],
    "validate_audio": [
      "self",
      "audio"
    ],
    "get_default_features": [
      "self"
    ],
    "extract_audio_features": [
      "self",
      "audio",
      "sr"
    ]
  },
  "AudioProcessor": {
    "__init__": [
      "self",
      "audio_codec_path"
    ],
    "create_speaker_from_whisper": [
      "self",
      "audio",
      "whisper_model"
    ],
    "create_speaker_from_dict": [
      "self",
      "data"
    ],
    "save_speaker": [
      "self",
      "speaker",
      "path"
    ],
    "load_speaker": [
      "self",
      "path"
    ]
  },
  "PromptProcessor": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "get_audio_token_map": [
      "self"
    ],
    "get_features": [
      "self",
      "f"
    ],
    "get_global_features": [
      "self",
      "f"
    ],
    "create_codes": [
      "self",
      "words"
    ],
    "_init_prompt": [
      "self",
      "text"
    ],
    "_get_separator": [
      "self",
      "text"
    ],
    "merge_speaker_text": [
      "self",
      "input_text",
      "speaker_text"
    ],
    "text_normalizations": [
      "text"
    ],
    "get_completion_prompt": [
      "self",
      "text",
      "speaker"
    ],
    "get_training_prompt": [
      "self",
      "speaker"
    ],
    "extract_audio_from_tokens": [
      "self",
      "tokens"
    ]
  },
  "TEXT_ENCODING_OFFSET": [],
  "SEMANTIC_PAD_TOKEN": [],
  "TEXT_PAD_TOKEN": [],
  "SEMANTIC_INFER_TOKEN": [],
  "CONTEXT_WINDOW_SIZE": [],
  "SEMANTIC_RATE_HZ": [],
  "SEMANTIC_VOCAB_SIZE": [],
  "CODEBOOK_SIZE": [],
  "N_COARSE_CODEBOOKS": [],
  "N_FINE_CODEBOOKS": [],
  "COARSE_RATE_HZ": [],
  "COARSE_SEMANTIC_PAD_TOKEN": [],
  "COARSE_INFER_TOKEN": [],
  "SAMPLE_RATE": [],
  "filter_dataclass_fields": [
    "data_dict",
    "dataclass_type"
  ],
  "SemanticConfig": {},
  "CoarseAcousticsConfig": {},
  "FineAcousticsConfig": {},
  "CodecConfig": {},
  "CausalSelfAttention": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "x",
      "past_kv",
      "use_cache"
    ]
  },
  "NonCausalSelfAttention": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Block": {
    "__init__": [
      "self",
      "args",
      "layer_idx"
    ],
    "__call__": [
      "self",
      "x",
      "past_kv",
      "use_cache"
    ]
  },
  "FineBlock": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "GPT": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "x",
      "merge_context",
      "past_kv",
      "position_ids",
      "use_cache"
    ]
  },
  "FineGPT": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "pred_idx",
      "idx"
    ]
  },
  "CUR_PATH": [],
  "SUPPORTED_LANGS": [],
  "ALLOWED_PROMPTS": [],
  "Result": {
    "__iter__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "_load_voice_prompt": [
    "voice_prompt_input"
  ],
  "_flatten_codebooks": [
    "arr",
    "offset_size"
  ],
  "Pipeline": {
    "__init__": [
      "self",
      "model",
      "tokenizer",
      "config"
    ],
    "generate_text_semantic": [
      "self",
      "text",
      "voice",
      "temperature",
      "use_kv_caching",
      "allow_early_stop"
    ],
    "generate_coarse": [
      "self",
      "x_semantic",
      "voice",
      "temperature",
      "max_coarse_history",
      "sliding_window_len",
      "use_kv_caching"
    ],
    "generate_fine": [
      "self",
      "x_coarse_gen",
      "temperature"
    ],
    "__call__": [
      "self",
      "text",
      "voice",
      "temperature",
      "speed",
      "use_kv_caching"
    ]
  },
  "codec_decode": [
    "codec",
    "fine_tokens"
  ],
  "mel_spectrogram": [
    "audio",
    "n_fft",
    "num_mels",
    "sample_rate",
    "hop_size",
    "win_size",
    "fmin",
    "fmax"
  ],
  "check_array_shape_qwen3": [
    "arr"
  ],
  "format_duration": [
    "seconds"
  ],
  "DepthwiseConvWeight": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "in_per_group"
    ]
  },
  "SnakeBeta": {
    "__init__": [
      "self",
      "channels",
      "alpha"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ConvNeXtBlock": {
    "__init__": [
      "self",
      "dim"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DecoderRMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DecoderRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "base"
    ],
    "__call__": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "DecoderAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "__call__": [
      "self",
      "x",
      "position_embeddings",
      "mask",
      "cache"
    ]
  },
  "DecoderMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DecoderTransformerLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "__call__": [
      "self",
      "x",
      "position_embeddings",
      "mask",
      "cache"
    ]
  },
  "DecoderTransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "make_cache": [
      "self"
    ],
    "__call__": [
      "self",
      "inputs_embeds",
      "mask",
      "cache"
    ]
  },
  "EuclideanCodebook": {
    "__init__": [
      "self",
      "dim",
      "codebook_size",
      "eps"
    ],
    "decode": [
      "self",
      "codes"
    ]
  },
  "VectorQuantization": {
    "__init__": [
      "self",
      "dim",
      "codebook_size",
      "codebook_dim",
      "eps"
    ],
    "decode": [
      "self",
      "codes"
    ]
  },
  "ResidualVectorQuantization": {
    "__init__": [
      "self",
      "num_quantizers",
      "dim",
      "codebook_size",
      "codebook_dim"
    ],
    "decode": [
      "self",
      "codes"
    ]
  },
  "ResidualVectorQuantizer": {
    "__init__": [
      "self",
      "dimension",
      "input_dimension",
      "output_dimension",
      "n_q",
      "bins",
      "force_projection"
    ],
    "decode": [
      "self",
      "codes"
    ]
  },
  "SplitResidualVectorQuantizer": {
    "__init__": [
      "self",
      "n_q",
      "n_q_semantic",
      "dimension",
      "input_dimension",
      "output_dimension",
      "bins"
    ],
    "decode": [
      "self",
      "codes"
    ]
  },
  "DecoderResidualUnit": {
    "__init__": [
      "self",
      "dim",
      "dilation"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DecoderBlockUpsample": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "upsample_rate"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DecoderBlock": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DecoderInitialConv": {
    "__init__": [
      "self",
      "latent_dim",
      "decoder_dim",
      "kernel_size"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DecoderOutputSnake": {
    "__init__": [
      "self",
      "channels"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DecoderOutputConv": {
    "__init__": [
      "self",
      "channels",
      "kernel_size"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Qwen3TTSSpeechTokenizerDecoder": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "codes"
    ],
    "chunked_decode": [
      "self",
      "codes",
      "chunk_size",
      "left_context_size"
    ]
  },
  "Qwen3TTSSpeechTokenizerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "encode": [
      "self",
      "audio"
    ]
  },
  "Qwen3TTSSpeechTokenizer": {
    "__init__": [
      "self",
      "config"
    ],
    "encode": [
      "self",
      "audio"
    ],
    "has_encoder": [
      "self"
    ],
    "decode": [
      "self",
      "audio_codes"
    ],
    "streaming_decode": [
      "self",
      "audio_codes",
      "chunk_tokens"
    ],
    "sanitize": [
      "weights"
    ]
  },
  "apply_multimodal_rotary_pos_emb": [
    "q",
    "k",
    "cos",
    "sin",
    "unsqueeze_dim"
  ],
  "TalkerRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "base",
      "mrope_section"
    ],
    "apply_interleaved_mrope": [
      "self",
      "freqs",
      "mrope_section"
    ],
    "__call__": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "TalkerAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "__call__": [
      "self",
      "x",
      "position_embeddings",
      "mask",
      "cache"
    ]
  },
  "TalkerMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ResizeMLP": {
    "__init__": [
      "self",
      "input_size",
      "intermediate_size",
      "output_size",
      "hidden_act",
      "bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "TalkerDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "__call__": [
      "self",
      "x",
      "position_embeddings",
      "mask",
      "cache"
    ]
  },
  "Qwen3TTSTalkerModel": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "inputs_embeds",
      "position_ids",
      "mask",
      "cache"
    ],
    "make_cache": [
      "self"
    ]
  },
  "CodePredictorAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "__call__": [
      "self",
      "x",
      "position_embeddings",
      "mask",
      "cache"
    ]
  },
  "CodePredictorMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "CodePredictorDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "__call__": [
      "self",
      "x",
      "position_embeddings",
      "mask",
      "cache"
    ]
  },
  "CodePredictorModel": {
    "__init__": [
      "self",
      "config",
      "talker_hidden_size"
    ],
    "__call__": [
      "self",
      "inputs_embeds",
      "position_ids",
      "mask",
      "cache"
    ],
    "make_cache": [
      "self"
    ]
  },
  "Qwen3TTSTalkerCodePredictor": {
    "__init__": [
      "self",
      "config",
      "talker_hidden_size"
    ],
    "codec_embedding": [
      "self"
    ],
    "__call__": [
      "self",
      "inputs_embeds",
      "position_ids",
      "mask",
      "cache",
      "generation_step"
    ],
    "make_cache": [
      "self"
    ]
  },
  "Qwen3TTSTalkerForConditionalGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_text_embeddings": [
      "self"
    ],
    "__call__": [
      "self",
      "inputs_embeds",
      "position_ids",
      "mask",
      "cache"
    ],
    "make_cache": [
      "self"
    ],
    "sanitize": [
      "weights"
    ]
  },
  "filter_dict_for_dataclass": [
    "cls",
    "data"
  ],
  "Qwen3TTSSpeakerEncoderConfig": {},
  "Qwen3TTSTalkerCodePredictorConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "Qwen3TTSTalkerConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "Qwen3TTSTokenizerDecoderConfig": {},
  "Qwen3TTSTokenizerEncoderConfig": {},
  "Qwen3TTSTokenizerConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "reflect_pad_1d": [
    "x",
    "pad"
  ],
  "TimeDelayNetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dilation"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Res2NetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "scale",
      "kernel_size",
      "dilation"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "SqueezeExcitationBlock": {
    "__init__": [
      "self",
      "in_channels",
      "se_channels",
      "out_channels"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "SqueezeExcitationRes2NetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "res2net_scale",
      "se_channels",
      "kernel_size",
      "dilation"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "AttentiveStatisticsPooling": {
    "__init__": [
      "self",
      "channels",
      "attention_channels"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Qwen3TTSSpeakerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "sanitize": [
      "weights"
    ]
  },
  "SOT": [],
  "EOT": [],
  "UNK": [],
  "SPACE": [],
  "SPECIAL_TOKENS": [],
  "EnTokenizer": {
    "__init__": [
      "self",
      "vocab_file_path"
    ],
    "check_vocabset_sot_eot": [
      "self"
    ],
    "text_to_tokens": [
      "self",
      "text"
    ],
    "encode": [
      "self",
      "txt"
    ],
    "decode": [
      "self",
      "seq"
    ]
  },
  "REPO_ID": [],
  "_kakasi": [],
  "_dicta": [],
  "_russian_stresser": [],
  "is_kanji": [
    "c"
  ],
  "is_katakana": [
    "c"
  ],
  "hiragana_normalize": [
    "text"
  ],
  "add_hebrew_diacritics": [
    "text"
  ],
  "korean_normalize": [
    "text"
  ],
  "ChineseCangjieConverter": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_load_cangjie_mapping": [
      "self",
      "model_dir"
    ],
    "_init_segmenter": [
      "self"
    ],
    "_cangjie_encode": [
      "self",
      "glyph"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "add_russian_stress": [
    "text"
  ],
  "MTLTokenizer": {
    "__init__": [
      "self",
      "vocab_file_path"
    ],
    "check_vocabset_sot_eot": [
      "self"
    ],
    "preprocess_text": [
      "self",
      "raw_text",
      "language_id",
      "lowercase",
      "nfkd_normalize"
    ],
    "text_to_tokens": [
      "self",
      "text",
      "language_id",
      "lowercase",
      "nfkd_normalize"
    ],
    "encode": [
      "self",
      "txt",
      "language_id",
      "lowercase",
      "nfkd_normalize"
    ],
    "decode": [
      "self",
      "seq"
    ]
  },
  "S3_SR": [],
  "S3GEN_SR": [],
  "SPEECH_VOCAB_SIZE": [],
  "resample_audio": [
    "audio",
    "orig_sr",
    "target_sr"
  ],
  "punc_norm": [
    "text"
  ],
  "drop_invalid_tokens": [
    "x"
  ],
  "Conditionals": {},
  "LLAMA_520M_CONFIG": [],
  "LLAMA_CONFIGS": [],
  "T3Config": {
    "n_channels": [
      "self"
    ],
    "is_multilingual": [
      "self"
    ],
    "english_only": [
      "cls"
    ],
    "multilingual": [
      "cls"
    ]
  },
  "log_mel_spectrogram": [
    "audio",
    "n_mels",
    "padding"
  ],
  "T3Cond": {
    "__post_init__": [
      "self"
    ]
  },
  "T3CondEnc": {
    "__init__": [
      "self",
      "hp"
    ],
    "__call__": [
      "self",
      "cond"
    ]
  },
  "AttentionQKV": {
    "__init__": [
      "self",
      "n_heads",
      "head_dim",
      "dropout_rate",
      "scale"
    ],
    "__call__": [
      "self",
      "q",
      "k",
      "v",
      "mask"
    ],
    "split_heads": [
      "self",
      "x"
    ],
    "combine_heads": [
      "self",
      "x"
    ]
  },
  "AttentionBlock": {
    "__init__": [
      "self",
      "channels",
      "num_heads",
      "dropout_rate",
      "scale"
    ],
    "__call__": [
      "self",
      "x1",
      "x2",
      "mask"
    ]
  },
  "Perceiver": {
    "__init__": [
      "self",
      "pre_attention_query_token",
      "pre_attention_query_size",
      "embedding_dim",
      "num_attn_heads"
    ],
    "__call__": [
      "self",
      "h"
    ],
    "parameters": [
      "self"
    ]
  },
  "LearnedPositionEmbeddings": {
    "__init__": [
      "self",
      "seq_len",
      "model_dim",
      "init"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "get_fixed_embedding": [
      "self",
      "idx"
    ]
  },
  "T3": {
    "__init__": [
      "self",
      "hp"
    ],
    "sanitize": [
      "self",
      "weights"
    ],
    "prepare_conditioning": [
      "self",
      "t3_cond"
    ],
    "prepare_input_embeds": [
      "self",
      "t3_cond",
      "text_tokens",
      "speech_tokens",
      "cfg_weight"
    ],
    "__call__": [
      "self",
      "t3_cond",
      "text_tokens",
      "text_token_lens",
      "speech_tokens",
      "speech_token_lens",
      "cache"
    ],
    "inference": [
      "self",
      "t3_cond",
      "text_tokens",
      "initial_speech_tokens",
      "max_new_tokens",
      "temperature",
      "top_p",
      "min_p",
      "repetition_penalty",
      "cfg_weight"
    ]
  },
  "melspectrogram": [
    "wav",
    "hp",
    "pad"
  ],
  "VoiceEncConfig": {},
  "get_num_wins": [
    "n_frames",
    "step",
    "min_coverage",
    "hp"
  ],
  "get_frame_step": [
    "overlap",
    "rate",
    "hp"
  ],
  "StackedLSTM": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers"
    ],
    "__call__": [
      "self",
      "x",
      "hidden"
    ]
  },
  "VoiceEncoder": {
    "__init__": [
      "self",
      "hp"
    ],
    "sanitize": [
      "self",
      "weights"
    ],
    "__call__": [
      "self",
      "mels"
    ],
    "inference": [
      "self",
      "mels",
      "mel_lens",
      "overlap",
      "rate",
      "min_coverage",
      "batch_size"
    ],
    "utt_to_spk_embed": [
      "utt_embeds"
    ],
    "voice_similarity": [
      "embeds_x",
      "embeds_y"
    ],
    "embeds_from_mels": [
      "self",
      "mels",
      "mel_lens",
      "as_spk",
      "batch_size"
    ],
    "embeds_from_wavs": [
      "self",
      "wavs",
      "sample_rate",
      "as_spk",
      "batch_size",
      "trim_top_db"
    ]
  },
  "ConvRNNF0Predictor": {
    "__init__": [
      "self",
      "num_class",
      "in_channels",
      "cond_channels"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "hann_window_periodic": [
    "size"
  ],
  "Snake": {
    "__init__": [
      "self",
      "in_features",
      "alpha",
      "alpha_trainable",
      "alpha_logscale"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "_linear_interpolate_1d_to_size": [
    "x",
    "new_size"
  ],
  "HiFTGenerator": {
    "__init__": [
      "self",
      "in_channels",
      "base_channels",
      "nb_harmonics",
      "sampling_rate",
      "nsf_alpha",
      "nsf_sigma",
      "nsf_voiced_threshold",
      "upsample_rates",
      "upsample_kernel_sizes",
      "istft_params",
      "resblock_kernel_sizes",
      "resblock_dilation_sizes",
      "source_resblock_kernel_sizes",
      "source_resblock_dilation_sizes",
      "lrelu_slope",
      "audio_limit",
      "f0_predictor",
      "use_interpolation"
    ],
    "_f0_upsample": [
      "self",
      "f0"
    ],
    "_stft": [
      "self",
      "x"
    ],
    "_istft": [
      "self",
      "magnitude",
      "phase"
    ],
    "decode": [
      "self",
      "x",
      "s"
    ],
    "__call__": [
      "self",
      "speech_feat",
      "cache_source"
    ],
    "inference": [
      "self",
      "speech_feat",
      "cache_source"
    ]
  },
  "_povey_window": [
    "size"
  ],
  "kaldi_fbank": [
    "audio",
    "sample_rate",
    "num_mel_bins",
    "frame_length",
    "frame_shift"
  ],
  "BasicResBlock": {
    "expansion": [],
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "FCM": {
    "__init__": [
      "self",
      "block",
      "num_blocks",
      "m_channels",
      "feat_dim"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "num_blocks",
      "stride"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "get_nonlinear": [
    "config_str",
    "channels"
  ],
  "statistics_pooling": [
    "x",
    "axis",
    "keepdim"
  ],
  "conv1d_pytorch_format": [
    "x",
    "conv_layer"
  ],
  "StatsPool": {
    "__call__": [
      "self",
      "x"
    ]
  },
  "TDNNLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "config_str"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "CAMLayer": {
    "__init__": [
      "self",
      "bn_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "reduction"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "seg_pooling": [
      "self",
      "x",
      "seg_len",
      "stype"
    ]
  },
  "CAMDenseTDNNLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bn_channels",
      "kernel_size",
      "stride",
      "dilation",
      "bias",
      "config_str",
      "memory_efficient"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "CAMDenseTDNNBlock": {
    "__init__": [
      "self",
      "num_layers",
      "in_channels",
      "out_channels",
      "bn_channels",
      "kernel_size",
      "stride",
      "dilation",
      "bias",
      "config_str",
      "memory_efficient"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "TransitLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bias",
      "config_str"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DenseLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bias",
      "config_str"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "CAMPPlus": {
    "__init__": [
      "self",
      "feat_dim",
      "embedding_size",
      "growth_rate",
      "bn_size",
      "init_channels",
      "config_str",
      "memory_efficient",
      "output_level"
    ],
    "sanitize": [
      "self",
      "weights"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "inference": [
      "self",
      "audio"
    ]
  },
  "subsequent_chunk_mask": [
    "size",
    "chunk_size",
    "num_left_chunks"
  ],
  "add_optional_chunk_mask": [
    "xs",
    "masks",
    "use_dynamic_chunk",
    "use_dynamic_left_chunk",
    "decoding_chunk_size",
    "static_chunk_size",
    "num_decoding_left_chunks"
  ],
  "mask_to_bias": [
    "mask",
    "dtype"
  ],
  "CausalBlock1D": {
    "__init__": [
      "self",
      "dim",
      "dim_out"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "CausalResnetBlock1D": {
    "__init__": [
      "self",
      "dim",
      "dim_out",
      "time_emb_dim",
      "groups"
    ]
  },
  "DownBlock": {
    "__init__": [
      "self",
      "resnet",
      "transformer_blocks",
      "downsample"
    ],
    "transformer_blocks": [
      "self"
    ]
  },
  "MidBlock": {
    "__init__": [
      "self",
      "resnet",
      "transformer_blocks"
    ],
    "transformer_blocks": [
      "self"
    ]
  },
  "UpBlock": {
    "__init__": [
      "self",
      "resnet",
      "transformer_blocks",
      "upsample"
    ],
    "transformer_blocks": [
      "self"
    ]
  },
  "ConditionalDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "causal",
      "channels",
      "dropout",
      "attention_head_dim",
      "n_blocks",
      "num_mid_blocks",
      "num_heads",
      "act_fn",
      "static_chunk_size",
      "num_decoding_left_chunks"
    ],
    "down_blocks": [
      "self"
    ],
    "mid_blocks": [
      "self"
    ],
    "up_blocks": [
      "self"
    ],
    "__call__": [
      "self",
      "x",
      "mask",
      "mu",
      "t",
      "spks",
      "cond",
      "streaming"
    ]
  },
  "_reflect_pad_2d": [
    "x",
    "pad_amount"
  ],
  "CFM_PARAMS": [],
  "ConditionalCFM": {
    "__init__": [
      "self",
      "in_channels",
      "cfm_params",
      "n_spks",
      "spk_emb_dim",
      "estimator"
    ],
    "__call__": [
      "self",
      "mu",
      "mask",
      "n_timesteps",
      "temperature",
      "spks",
      "cond",
      "prompt_len",
      "flow_cache"
    ],
    "solve_euler": [
      "self",
      "x",
      "t_span",
      "mu",
      "mask",
      "spks",
      "cond"
    ]
  },
  "CausalConditionalCFM": {
    "MEL_CHANNELS": [],
    "__init__": [
      "self",
      "in_channels",
      "cfm_params",
      "n_spks",
      "spk_emb_dim",
      "estimator"
    ],
    "__call__": [
      "self",
      "mu",
      "mask",
      "n_timesteps",
      "temperature",
      "spks",
      "cond",
      "streaming"
    ]
  },
  "CausalMaskedDiffWithXvec": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "spk_embed_dim",
      "output_type",
      "vocab_size",
      "input_frame_rate",
      "only_mask_loss",
      "token_mel_ratio",
      "pre_lookahead_len",
      "n_timesteps",
      "encoder",
      "decoder",
      "decoder_conf",
      "mel_feat_conf"
    ],
    "inference": [
      "self",
      "token",
      "token_len",
      "prompt_token",
      "prompt_token_len",
      "prompt_feat",
      "prompt_feat_len",
      "embedding",
      "finalize",
      "n_timesteps",
      "streaming"
    ]
  },
  "S3Token2Mel": {
    "__init__": [
      "self"
    ],
    "embed_ref": [
      "self",
      "ref_wav",
      "ref_sr",
      "ref_speech_tokens",
      "ref_speech_token_lens"
    ],
    "__call__": [
      "self",
      "speech_tokens",
      "ref_dict",
      "finalize"
    ]
  },
  "S3Token2Wav": {
    "sanitize": [
      "self",
      "weights"
    ],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "speech_tokens",
      "ref_dict",
      "finalize"
    ],
    "flow_inference": [
      "self",
      "speech_tokens",
      "ref_dict",
      "finalize"
    ],
    "hift_inference": [
      "self",
      "speech_feat",
      "cache_source"
    ],
    "inference": [
      "self",
      "speech_tokens",
      "ref_dict",
      "cache_source",
      "finalize"
    ]
  },
  "ResnetBlock1D": {
    "__init__": [
      "self",
      "dim",
      "dim_out",
      "time_emb_dim",
      "groups"
    ],
    "__call__": [
      "self",
      "x",
      "mask",
      "time_emb"
    ]
  },
  "Downsample1D": {
    "__init__": [
      "self",
      "dim"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Upsample1D": {
    "__init__": [
      "self",
      "channels",
      "use_conv_transpose"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DiffusersAttention": {
    "__init__": [
      "self",
      "query_dim",
      "heads",
      "dim_head",
      "qkv_bias",
      "out_bias"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "BasicTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "dropout",
      "activation_fn"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask",
      "timestep"
    ]
  },
  "LayerList": {
    "__init__": [
      "self",
      "layers"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ]
  },
  "CFMParams": {},
  "BASECFM": {
    "__init__": [
      "self",
      "n_feats",
      "cfm_params",
      "n_spks",
      "spk_emb_dim"
    ],
    "__call__": [
      "self",
      "mu",
      "mask",
      "n_timesteps",
      "temperature",
      "spks",
      "cond"
    ],
    "solve_euler": [
      "self",
      "x",
      "t_span",
      "mu",
      "mask",
      "spks",
      "cond"
    ]
  },
  "BaseSubsampling": {
    "__init__": [
      "self"
    ],
    "position_encoding": [
      "self",
      "offset",
      "size"
    ]
  },
  "LinearNoSubsampling": {
    "__init__": [
      "self",
      "idim",
      "odim",
      "dropout_rate",
      "pos_enc_class"
    ],
    "__call__": [
      "self",
      "x",
      "x_mask",
      "offset"
    ]
  },
  "PositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate",
      "max_len"
    ],
    "_create_pe": [
      "self",
      "max_len",
      "d_model"
    ],
    "__call__": [
      "self",
      "x",
      "offset"
    ],
    "position_encoding": [
      "self",
      "offset",
      "size"
    ]
  },
  "RelPositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate",
      "max_len"
    ],
    "__call__": [
      "self",
      "x",
      "offset"
    ]
  },
  "EspnetRelPositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate",
      "max_len"
    ],
    "_extend_pe": [
      "self",
      "size"
    ],
    "__call__": [
      "self",
      "x",
      "offset"
    ],
    "position_encoding": [
      "self",
      "size",
      "offset"
    ]
  },
  "NoPositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate"
    ],
    "__call__": [
      "self",
      "x",
      "offset"
    ],
    "position_encoding": [
      "self",
      "offset",
      "size"
    ]
  },
  "Swish": [],
  "MultiHeadedAttention": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "dropout_rate",
      "key_bias"
    ],
    "forward_qkv": [
      "self",
      "query",
      "key",
      "value"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask"
    ],
    "__call__": [
      "self",
      "query",
      "key",
      "value",
      "mask",
      "pos_emb",
      "cache"
    ]
  },
  "RelPositionMultiHeadedAttention": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "dropout_rate",
      "key_bias"
    ],
    "rel_shift": [
      "self",
      "x"
    ],
    "__call__": [
      "self",
      "query",
      "key",
      "value",
      "mask",
      "pos_emb",
      "cache"
    ]
  },
  "PreLookaheadLayer": {
    "__init__": [
      "self",
      "channels",
      "pre_lookahead_len"
    ],
    "__call__": [
      "self",
      "inputs",
      "context"
    ]
  },
  "make_pad_mask": [
    "lengths",
    "max_len"
  ],
  "UpsampleConformerEncoder": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "num_up_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "attention_dropout_rate",
      "input_layer",
      "pos_enc_layer_type",
      "normalize_before",
      "static_chunk_size",
      "use_dynamic_chunk",
      "use_dynamic_left_chunk",
      "positionwise_conv_kernel_size",
      "macaron_style",
      "selfattention_layer_type",
      "activation_type",
      "use_cnn_module",
      "cnn_module_kernel",
      "causal",
      "cnn_module_norm",
      "key_bias",
      "pre_lookahead_len",
      "upsample_stride"
    ],
    "output_size": [
      "self"
    ],
    "__call__": [
      "self",
      "xs",
      "xs_lens",
      "context",
      "decoding_chunk_size",
      "num_decoding_left_chunks",
      "streaming"
    ],
    "encoders": [
      "self"
    ],
    "up_encoders": [
      "self"
    ],
    "forward_layers": [
      "self",
      "xs",
      "chunk_masks",
      "pos_emb",
      "mask_pad"
    ],
    "forward_up_layers": [
      "self",
      "xs",
      "chunk_masks",
      "pos_emb",
      "mask_pad"
    ]
  },
  "ConformerEncoderLayer": {
    "__init__": [
      "self",
      "size",
      "self_attn",
      "feed_forward",
      "feed_forward_macaron",
      "conv_module",
      "dropout_rate",
      "normalize_before"
    ],
    "__call__": [
      "self",
      "x",
      "mask",
      "pos_emb",
      "mask_pad",
      "att_cache",
      "cnn_cache"
    ]
  },
  "ConvolutionModule": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "activation",
      "norm",
      "causal",
      "bias"
    ],
    "__call__": [
      "self",
      "x",
      "mask_pad",
      "cache"
    ]
  },
  "PositionwiseFeedForward": {
    "__init__": [
      "self",
      "idim",
      "hidden_units",
      "dropout_rate",
      "activation"
    ],
    "__call__": [
      "self",
      "xs"
    ]
  },
  "download_chatterbox_weights": [
    "cache_dir"
  ],
  "download_s3tokenizer_onnx": [
    "cache_dir"
  ],
  "load_pytorch_safetensors": [
    "path"
  ],
  "load_onnx_weights": [
    "path"
  ],
  "numpy_to_mlx": [
    "weights"
  ],
  "mlx_to_numpy": [
    "weights"
  ],
  "save_mlx_safetensors": [
    "weights",
    "path"
  ],
  "save_mlx_quantized": [
    "weights",
    "path"
  ],
  "quantize_t3_backbone": [
    "model",
    "bits",
    "group_size"
  ],
  "generate_readme": [
    "path",
    "upload_repo"
  ],
  "generate_s3_tokenizer_readme": [
    "path",
    "upload_repo"
  ],
  "convert_s3_tokenizer": [
    "output_dir",
    "cache_dir",
    "upload_repo",
    "dry_run"
  ],
  "convert_all": [
    "output_dir",
    "cache_dir",
    "upload_repo",
    "quantize",
    "bits",
    "group_size",
    "dry_run"
  ],
  "convert_from_source": [
    "repo_id",
    "output_dir",
    "quantize",
    "q_bits",
    "q_group_size",
    "upload_repo",
    "dry_run"
  ],
  "CHAR_MAP": [],
  "ZH_CHAR_MAP": [],
  "PINYIN_PATTERN": [],
  "NAME_PATTERN": [],
  "CONTRACTION_PATTERN": [],
  "EMAIL_PATTERN": [],
  "is_email": [
    "text"
  ],
  "has_chinese": [
    "text"
  ],
  "has_alpha": [
    "text"
  ],
  "has_pinyin": [
    "text"
  ],
  "use_chinese": [
    "text"
  ],
  "replace_chars": [
    "text",
    "char_map"
  ],
  "extract_all_digits": [
    "text"
  ],
  "expand_contractions": [
    "text"
  ],
  "correct_pinyin": [
    "pinyin"
  ],
  "extract_patterns": [
    "text",
    "pattern"
  ],
  "create_placeholders": [
    "items",
    "prefix"
  ],
  "apply_placeholders": [
    "text",
    "placeholders"
  ],
  "restore_placeholders": [
    "text",
    "placeholders",
    "transform_fn"
  ],
  "save_and_replace": [
    "text",
    "pattern",
    "prefix"
  ],
  "number_to_words": [
    "n"
  ],
  "normalize_chinese": [
    "text"
  ],
  "normalize_english": [
    "text"
  ],
  "normalize": [
    "text"
  ],
  "tokenize_by_CJK_char": [
    "line",
    "do_upper_case"
  ],
  "ConformerArgs": {},
  "Convolution": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ConformerBlock": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "x",
      "pos_emb",
      "mask",
      "cache"
    ]
  },
  "Conv2dSubsampling": {
    "CONV_LAYERS": [],
    "CONV_MASKS": [],
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "Conformer": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "x",
      "mask",
      "cache"
    ]
  },
  "PerceiverResampler": {
    "__init__": [
      "self",
      "n_dim",
      "n_depth",
      "n_dim_context",
      "n_latents",
      "n_dim_head",
      "n_heads",
      "n_ff_mult"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "GPTConfig": {},
  "GPT2Model": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "inputs",
      "mask",
      "cache"
    ]
  },
  "MultiHeadAttention": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "bias",
      "head_dim"
    ],
    "__call__": [
      "self",
      "q",
      "k",
      "v",
      "pos_emb",
      "mask",
      "cache"
    ]
  },
  "RelPositionMultiHeadAttention": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "bias",
      "head_dim",
      "pos_bias_u",
      "pos_bias_v"
    ],
    "__call__": [
      "self",
      "q",
      "k",
      "v",
      "pos_emb",
      "mask",
      "cache"
    ]
  },
  "LearnedPositionEncoding": {
    "__init__": [
      "self",
      "seq_len",
      "model_dim"
    ],
    "__call__": [
      "self",
      "x",
      "offset"
    ]
  },
  "BigVGANConditioningConfig": {},
  "BigVGANConditioning": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x",
      "mel_refer"
    ],
    "sanitize": [
      "self",
      "weights"
    ]
  },
  "Res2Net": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "scale",
      "dilation",
      "groups",
      "bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "SE": {
    "__init__": [
      "self",
      "in_channels",
      "se_channels",
      "out_channels"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "SeRes2Net": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "scale",
      "attention_channels",
      "kernel_size",
      "dilation",
      "groups",
      "bias"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "ECPATDNNArgs": {},
  "ECPATDNN": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "TDNN": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dilation",
      "groups",
      "bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ChatterboxTurboTTS": {
    "ENC_COND_LEN": [],
    "DEC_COND_LEN": [],
    "__init__": [
      "self",
      "config_or_t3",
      "s3gen",
      "ve",
      "tokenizer",
      "s3tokenizer",
      "conds",
      "local_path"
    ],
    "sample_rate": [
      "self"
    ],
    "sanitize": [
      "self",
      "weights"
    ],
    "load_weights": [
      "self",
      "weights",
      "strict"
    ],
    "post_load_hook": [
      "model",
      "model_path"
    ],
    "from_local": [
      "cls",
      "ckpt_dir",
      "device"
    ],
    "from_pretrained": [
      "cls",
      "device",
      "weights_path"
    ],
    "norm_loudness": [
      "self",
      "wav",
      "sr",
      "target_lufs"
    ],
    "_extract_conditionals": [
      "self",
      "ref_wav_24k",
      "ref_wav_16k"
    ],
    "prepare_conditionals": [
      "self",
      "ref_audio",
      "sample_rate",
      "exaggeration",
      "norm_loudness"
    ],
    "generate": [
      "self",
      "text",
      "repetition_penalty",
      "min_p",
      "top_p",
      "ref_audio",
      "sample_rate",
      "exaggeration",
      "cfg_weight",
      "temperature",
      "top_k",
      "norm_loudness",
      "stream",
      "streaming_interval",
      "split_pattern",
      "max_tokens"
    ],
    "stream_generate": [
      "self",
      "text",
      "repetition_penalty",
      "min_p",
      "top_p",
      "ref_audio",
      "sample_rate",
      "exaggeration",
      "cfg_weight",
      "temperature",
      "top_k",
      "norm_loudness",
      "chunk_size",
      "split_pattern",
      "max_tokens"
    ]
  },
  "GPT2_MEDIUM_CONFIG": [],
  "GPT2Config": {
    "hidden_size": [
      "self"
    ],
    "num_attention_heads": [
      "self"
    ],
    "num_hidden_layers": [
      "self"
    ]
  },
  "gelu_new": [
    "x"
  ],
  "GPT2Attention": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask",
      "cache"
    ]
  },
  "GPT2MLP": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "GPT2Block": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask",
      "cache"
    ]
  },
  "create_gpt2_config": [],
  "mel_basis": [
    "hp"
  ],
  "preemphasis": [
    "wav",
    "hp"
  ],
  "_stft": [
    "y",
    "hp",
    "pad"
  ],
  "_amp_to_db": [
    "x",
    "hp"
  ],
  "_db_to_amp": [
    "x"
  ],
  "_normalize": [
    "s",
    "hp",
    "headroom_db"
  ],
  "pack": [
    "arrays",
    "seq_len",
    "pad_value"
  ],
  "stride_as_partials": [
    "mel",
    "hp",
    "overlap",
    "rate",
    "min_coverage"
  ],
  "Conv1dPT": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ConvTranspose1dPT": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "SourceModule": {
    "__init__": [
      "self",
      "sampling_rate",
      "upsample_scale",
      "harmonic_num",
      "sine_amp",
      "add_noise_std",
      "voiced_threshold"
    ],
    "__call__": [
      "self",
      "f0"
    ]
  },
  "elu": [
    "x",
    "alpha"
  ],
  "F0Predictor": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_channels",
      "num_layers"
    ],
    "__call__": [
      "self",
      "mel"
    ]
  },
  "pad_list": [
    "xs",
    "pad_value"
  ],
  "_mel_scale": [
    "freq"
  ],
  "_inverse_mel_scale": [
    "mel"
  ],
  "_get_mel_banks_kaldi": [
    "num_bins",
    "padded_window_size",
    "sample_freq",
    "low_freq",
    "high_freq"
  ],
  "extract_fbank_features": [
    "audio",
    "num_mel_bins",
    "sample_rate",
    "frame_length_ms",
    "frame_shift_ms",
    "low_freq",
    "high_freq",
    "preemphasis_coeff",
    "remove_dc_offset",
    "use_power",
    "snip_edges"
  ],
  "sinusoidal_pos_emb": [
    "timesteps",
    "dim",
    "scale"
  ],
  "SelfAttention1D": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "head_dim",
      "dropout"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "GELU": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "TransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "head_dim",
      "ff_mult",
      "dropout"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "get_mel_basis": [
    "n_fft",
    "num_mels",
    "sampling_rate",
    "fmin",
    "fmax"
  ],
  "get_hann_window": [
    "win_size"
  ],
  "dynamic_range_compression": [
    "x",
    "C",
    "clip_val"
  ],
  "spectral_normalize": [
    "magnitudes"
  ],
  "LinearInput": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "dropout"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "Upsample1DEncoder": {
    "__init__": [
      "self",
      "channels",
      "stride"
    ],
    "__call__": [
      "self",
      "x",
      "x_lens"
    ]
  },
  "S3GEN_SIL": [],
  "S3Gen": [],
  "CSM_1B_GH_WATERMARK": [],
  "cli_check_audio": [],
  "load_watermarker": [],
  "watermark": [
    "watermarker",
    "audio_array",
    "sample_rate",
    "watermark_key"
  ],
  "verify": [
    "watermarker",
    "watermarked_audio",
    "sample_rate",
    "watermark_key"
  ],
  "check_audio_from_file": [
    "audio_path"
  ],
  "MIMI_REPO": [],
  "TOKENIZER_REPO": [],
  "DepthDecoderConfig": {
    "__init__": [
      "self",
      "attention_bias",
      "attention_dropout",
      "backbone_hidden_size",
      "head_dim",
      "hidden_act",
      "hidden_size",
      "initializer_range",
      "intermediate_size",
      "max_position_embeddings",
      "mlp_bias",
      "model_type",
      "num_attention_heads",
      "num_codebooks",
      "num_hidden_layers",
      "num_key_value_heads",
      "rms_norm_eps",
      "rope_scaling",
      "rope_theta",
      "use_cache",
      "vocab_size"
    ]
  },
  "SesameModelArgs": {
    "__init__": [
      "self"
    ]
  },
  "create_llama_model_args_for_backbone": [
    "cfg"
  ],
  "create_llama_model_args_for_decoder": [
    "decoder_cfg"
  ],
  "create_llama_model_args": [
    "flavor"
  ],
  "SesameModel": {
    "__init__": [
      "self",
      "config"
    ],
    "setup_caches": [
      "self",
      "max_batch_size"
    ],
    "caches_are_enabled": [
      "self"
    ],
    "reset_caches": [
      "self"
    ],
    "generate_frame": [
      "self",
      "tokens",
      "tokens_mask",
      "input_pos",
      "sampler"
    ],
    "_embed_audio": [
      "self",
      "codebook",
      "tokens"
    ],
    "_embed_tokens": [
      "self",
      "tokens"
    ]
  },
  "Segment": {},
  "load_llama3_tokenizer": [
    "path_or_hf_repo"
  ],
  "Llama3ScaledRoPE": {
    "__init__": [
      "self",
      "dim",
      "max_seq_len",
      "base",
      "scale_factor",
      "low_freq_factor",
      "high_freq_factor",
      "old_context_len"
    ],
    "rope_init": [
      "self"
    ],
    "_apply_scaling": [
      "self",
      "freqs"
    ],
    "_get_cache": [
      "self",
      "dtype",
      "seq_len",
      "offset"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "codes_to_layers": [
    "code_list"
  ],
  "decode_audio_stream": [
    "code_list",
    "prev_codes",
    "context_frames"
  ],
  "get_new_codes": [
    "all_codes",
    "prev_code_count"
  ],
  "build_delay_indices": [
    "B",
    "T",
    "C",
    "delay_pattern"
  ],
  "apply_audio_delay": [
    "audio_BxTxC",
    "pad_value",
    "bos_value",
    "precomp"
  ],
  "audio_to_codebook": [
    "model",
    "input_values",
    "data_config",
    "padding_mask",
    "sample_rate"
  ],
  "build_revert_indices": [
    "B",
    "T",
    "C",
    "delay_pattern"
  ],
  "revert_audio_delay": [
    "audio_BxTxC",
    "pad_value",
    "precomp",
    "T"
  ],
  "decode": [
    "model",
    "audio_codes"
  ],
  "codebook_to_audio": [
    "generated_codes",
    "model",
    "delay_pattern",
    "B",
    "T",
    "C"
  ],
  "_sample_next_token": [
    "logits_BCxV",
    "temperature",
    "sampler"
  ],
  "DataConfig": {
    "__post_init__": [
      "self"
    ],
    "__hash__": [
      "self"
    ]
  },
  "TrainingConfig": {},
  "DiaConfig": {
    "save": [
      "self",
      "path"
    ],
    "load_dict": [
      "cls",
      "config"
    ],
    "load": [
      "cls",
      "path"
    ]
  },
  "_normalize_axes": [
    "axes",
    "ndim"
  ],
  "_str_to_dtype": [
    "dtype_str"
  ],
  "DenseGeneral": {
    "__init__": [
      "self",
      "in_shapes",
      "out_features",
      "axis",
      "dtype",
      "weight_dtype"
    ],
    "__call__": [
      "self",
      "inputs"
    ]
  },
  "get_activation_fn": [
    "activation_string"
  ],
  "MlpBlock": {
    "__init__": [
      "self",
      "config",
      "embed_dim",
      "intermediate_dim",
      "dropout_rate",
      "activations",
      "use_pre_norm"
    ],
    "__call__": [
      "self",
      "x",
      "deterministic"
    ]
  },
  "KVCache": {
    "__init__": [
      "self",
      "num_heads",
      "max_len",
      "head_dim",
      "k",
      "v"
    ],
    "update_and_fetch": [
      "self",
      "k",
      "v"
    ],
    "prefill_kv": [
      "self",
      "k",
      "v"
    ]
  },
  "EncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x",
      "src_positions",
      "deterministic",
      "attn_mask"
    ]
  },
  "Encoder": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x_ids",
      "src_positions",
      "deterministic",
      "attn_mask"
    ]
  },
  "DiaModel": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "src_BxS",
      "tgt_BxTxC",
      "src_positions",
      "tgt_positions",
      "enc_self_attn_mask",
      "dec_self_attn_mask",
      "dec_cross_attn_mask",
      "enable_dropout"
    ]
  },
  "BiCodecTokenizer": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_initialize_model": [
      "self"
    ],
    "get_ref_clip": [
      "self",
      "wav"
    ],
    "process_audio": [
      "self",
      "wav_path"
    ],
    "extract_wav2vec2_features": [
      "self",
      "wavs"
    ],
    "tokenize_batch": [
      "self",
      "batch"
    ],
    "tokenize": [
      "self",
      "audio_path"
    ],
    "detokenize": [
      "self",
      "global_tokens",
      "semantic_tokens"
    ]
  },
  "PITCH_MAP": [],
  "SPEED_MAP": [],
  "BiCodec": {
    "__init__": [
      "self",
      "mel_params",
      "encoder",
      "decoder",
      "quantizer",
      "speaker_encoder",
      "prenet",
      "postnet"
    ],
    "load_from_checkpoint": [
      "cls",
      "model_dir"
    ],
    "__call__": [
      "self",
      "batch"
    ],
    "tokenize": [
      "self",
      "batch"
    ],
    "detokenize": [
      "self",
      "semantic_tokens",
      "global_tokens"
    ],
    "get_mel_spectrogram": [
      "self",
      "wav"
    ]
  },
  "TASK_TOKEN_MAP": [],
  "LEVELS_MAP": [],
  "LEVELS_MAP_UI": [],
  "GENDER_MAP": [],
  "AGE_MAP": [],
  "EMO_MAP": [],
  "TokenParser": {
    "__init__": [
      "self"
    ],
    "age": [
      "age"
    ],
    "gender": [
      "gender"
    ],
    "mel_value": [
      "mel"
    ],
    "mel_level": [
      "level"
    ],
    "pitch_var_value": [
      "pitch_std"
    ],
    "pitch_var_level": [
      "level"
    ],
    "loudness_value": [
      "loudness"
    ],
    "loudness_level": [
      "level"
    ],
    "speed_value": [
      "speed"
    ],
    "speed_level": [
      "level"
    ],
    "task": [
      "task"
    ],
    "emotion": [
      "emotion"
    ]
  },
  "resolve_symbolic_link": [
    "symbolic_link_path"
  ],
  "write_jsonl": [
    "metadata",
    "file_path"
  ],
  "read_jsonl": [
    "file_path"
  ],
  "read_json_as_jsonl": [
    "file_path"
  ],
  "decode_unicode_strings": [
    "meta"
  ],
  "_deep_merge": [
    "base",
    "override"
  ],
  "jsonl_to_csv": [
    "jsonl_file_path",
    "csv_file_path"
  ],
  "save_metadata": [
    "data",
    "filename",
    "headers"
  ],
  "read_metadata": [
    "filename",
    "headers"
  ],
  "exists": [
    "val"
  ],
  "default": [
    "val",
    "d"
  ],
  "FactorizedVectorQuantize": {
    "__init__": [
      "self",
      "input_dim",
      "codebook_size",
      "codebook_dim",
      "commitment",
      "codebook_loss_weight",
      "decay",
      "threshold_ema_dead_code",
      "momentum"
    ],
    "__call__": [
      "self",
      "z"
    ],
    "vq2emb": [
      "self",
      "vq",
      "out_proj"
    ],
    "tokenize": [
      "self",
      "z"
    ],
    "detokenize": [
      "self",
      "indices"
    ],
    "get_emb": [
      "self"
    ],
    "embed_code": [
      "self",
      "embed_id"
    ],
    "decode_code": [
      "self",
      "embed_id"
    ],
    "normalize": [
      "self",
      "x"
    ],
    "decode_latents": [
      "self",
      "latents"
    ],
    "get_codes_from_indices": [
      "self",
      "indices"
    ],
    "get_output_from_indices": [
      "self",
      "indices"
    ],
    "sanitize": [
      "self",
      "weights"
    ]
  },
  "first": [
    "l"
  ],
  "round_up_multiple": [
    "num",
    "mult"
  ],
  "ResidualFSQ": {
    "__init__": [
      "self"
    ],
    "codebooks": [
      "self"
    ],
    "get_codes_from_indices": [
      "self",
      "indices"
    ],
    "get_output_from_indices": [
      "self",
      "indices"
    ],
    "__call__": [
      "self",
      "x",
      "return_all_codes",
      "rand_quantize_dropout_fixed_seed"
    ]
  },
  "maybe": [
    "fn"
  ],
  "round_ste": [
    "z"
  ],
  "FSQ": {
    "__init__": [
      "self",
      "levels",
      "dim",
      "num_codebooks",
      "keep_num_codebooks_dim",
      "scale",
      "allowed_dtypes",
      "channel_first",
      "projection_has_bias",
      "return_indices",
      "force_quantization_f32"
    ],
    "atanh": [
      "self",
      "x"
    ],
    "bound": [
      "self",
      "z",
      "eps"
    ],
    "quantize": [
      "self",
      "z"
    ],
    "_scale_and_shift": [
      "self",
      "zhat_normalized"
    ],
    "_scale_and_shift_inverse": [
      "self",
      "zhat"
    ],
    "_indices_to_codes": [
      "self",
      "indices"
    ],
    "codes_to_indices": [
      "self",
      "zhat"
    ],
    "indices_to_level_indices": [
      "self",
      "indices"
    ],
    "indices_to_codes": [
      "self",
      "indices"
    ],
    "__call__": [
      "self",
      "z"
    ]
  },
  "TAP": {
    "__init__": [
      "self",
      "in_dim"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "get_out_dim": [
      "self"
    ]
  },
  "TSDP": {
    "__init__": [
      "self",
      "in_dim"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "get_out_dim": [
      "self"
    ]
  },
  "TSTP": {
    "__init__": [
      "self",
      "in_dim"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "get_out_dim": [
      "self"
    ]
  },
  "ASTP": {
    "__init__": [
      "self",
      "in_dim",
      "bottleneck_dim",
      "global_context_att"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "get_out_dim": [
      "self"
    ]
  },
  "MHASTP": {
    "__init__": [
      "self",
      "in_dim",
      "layer_num",
      "head_num",
      "d_s",
      "bottleneck_dim"
    ],
    "__call__": [
      "self",
      "input"
    ],
    "get_out_dim": [
      "self"
    ]
  },
  "MQMHASTP": {
    "__init__": [
      "self",
      "in_dim",
      "layer_num",
      "query_num",
      "head_num",
      "d_s",
      "bottleneck_dim"
    ],
    "__call__": [
      "self",
      "input"
    ],
    "get_out_dim": [
      "self"
    ]
  },
  "Res2Conv1dReluBn": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "scale"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Conv1dReluBn": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "SE_Connect": {
    "__init__": [
      "self",
      "channels",
      "se_bottleneck_dim"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "SE_Res2Block": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "scale"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ECAPA_TDNN": {
    "__init__": [
      "self",
      "channels",
      "feat_dim",
      "embed_dim",
      "pooling_func",
      "global_context_att",
      "emb_bn"
    ],
    "__call__": [
      "self",
      "x",
      "return_latent"
    ]
  },
  "ECAPA_TDNN_c1024": [
    "feat_dim",
    "embed_dim",
    "pooling_func",
    "emb_bn"
  ],
  "ECAPA_TDNN_GLOB_c1024": [
    "feat_dim",
    "embed_dim",
    "pooling_func",
    "emb_bn"
  ],
  "ECAPA_TDNN_c512": [
    "feat_dim",
    "embed_dim",
    "pooling_func",
    "emb_bn"
  ],
  "ECAPA_TDNN_GLOB_c512": [
    "feat_dim",
    "embed_dim",
    "pooling_func",
    "emb_bn"
  ],
  "SpeakerEncoder": {
    "__init__": [
      "self",
      "input_dim",
      "out_dim",
      "latent_dim",
      "token_num",
      "fsq_levels",
      "fsq_num_quantizers"
    ],
    "get_codes_from_indices": [
      "self",
      "indices"
    ],
    "get_indices": [
      "self",
      "mels"
    ],
    "__call__": [
      "self",
      "mels"
    ],
    "tokenize": [
      "self",
      "mels"
    ],
    "detokenize": [
      "self",
      "indices"
    ],
    "sanitize": [
      "self",
      "weights"
    ]
  },
  "once": [
    "fn"
  ],
  "print_once": [],
  "Attend": {
    "__init__": [
      "self",
      "dropout",
      "causal"
    ],
    "get_mask": [
      "self",
      "n",
      "device"
    ],
    "__call__": [
      "self",
      "q",
      "k",
      "v",
      "mask"
    ]
  },
  "Sequential": [],
  "GEGLU": {
    "__call__": [
      "self",
      "x"
    ]
  },
  "SamplingBlock": {
    "__init__": [
      "self",
      "dim",
      "groups",
      "upsample_scale",
      "downsample_scale"
    ],
    "repeat_upsampler": [
      "x",
      "upsample_scale"
    ],
    "skip_downsampler": [
      "x",
      "downsample_scale"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "WaveGenerator": {
    "__init__": [
      "self",
      "input_channel",
      "channels",
      "rates",
      "kernel_sizes",
      "d_out"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "sanitize": [
      "self",
      "weights"
    ]
  },
  "test_dsp_import_isolation": [],
  "test_dsp_backward_compat": [],
  "test_dsp_all_exports": [],
  "test_utils_lazy_imports": [],
  "test_stt_utils_no_eager_imports": [],
  "test_tts_utils_no_eager_imports": [],
  "test_codec_no_eager_imports": [],
  "PROJECT_ROOT": [],
  "get_package_metadata": [],
  "extract_package_name": [
    "req"
  ],
  "get_package_manager": [],
  "run_dry_run": [
    "extra"
  ],
  "TestOptionalDeps": {
    "test_core_deps_defined": [
      "self"
    ],
    "test_stt_extra_defined": [
      "self"
    ],
    "test_tts_extra_defined": [
      "self"
    ],
    "test_server_extra_defined": [
      "self"
    ],
    "test_dev_extra_defined": [
      "self"
    ],
    "test_core_resolves": [
      "self"
    ],
    "test_stt_extra_resolves": [
      "self"
    ],
    "test_tts_extra_resolves": [
      "self"
    ],
    "test_sts_extra_resolves": [
      "self"
    ],
    "test_server_extra_resolves": [
      "self"
    ],
    "test_all_extra_resolves": [
      "self"
    ],
    "test_dev_extra_resolves": [
      "self"
    ]
  },
  "client": [],
  "mock_model_provider": [],
  "test_list_models_empty": [
    "client",
    "mock_model_provider"
  ],
  "test_list_models_with_data": [
    "client",
    "mock_model_provider"
  ],
  "test_add_model": [
    "client",
    "mock_model_provider"
  ],
  "test_remove_model_success": [
    "client",
    "mock_model_provider"
  ],
  "test_remove_model_not_found": [
    "client",
    "mock_model_provider"
  ],
  "test_remove_model_with_quotes_in_name": [
    "client",
    "mock_model_provider"
  ],
  "MockAudioResult": {
    "__init__": [
      "self",
      "audio_data",
      "sample_rate"
    ]
  },
  "sync_mock_audio_stream_generator": [
    "input_text"
  ],
  "test_tts_speech": [
    "client",
    "mock_model_provider"
  ],
  "test_stt_transcriptions": [
    "client",
    "mock_model_provider"
  ],
  "config": [],
  "TestSNAC": {
    "test_snac": [
      "self"
    ]
  },
  "TestBigVGAN": {
    "test_bigvgan_22khz_80bands": [
      "self"
    ],
    "test_bigvgan_44khz_128bands_512x": [
      "self"
    ]
  },
  "TestEncodec": {
    "test_encodec_24khz": [
      "self"
    ]
  },
  "TestS3TokenizerV2": {
    "test_s3_tokenizer_v2": [
      "self"
    ]
  },
  "config_mel": [],
  "config_encodec": [],
  "TestVocos": {
    "test_vocos_24khz": [
      "self"
    ]
  },
  "TestDescript": {
    "test_descript_16khz": [
      "self"
    ],
    "test_descript_24khz": [
      "self"
    ],
    "test_descript_44khz": [
      "self"
    ]
  },
  "TestMimi": {
    "test_mimi_model": [
      "self"
    ]
  },
  "LocalMHA": {
    "__init__": [
      "self",
      "dim",
      "window_size",
      "dim_head",
      "use_rotary_pos_emb"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "SinusoidalEmbeddings": {
    "__init__": [
      "self",
      "dim",
      "scale_base",
      "use_xpos"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "SNAC": {
    "__init__": [
      "self",
      "sampling_rate",
      "encoder_dim",
      "encoder_rates",
      "latent_dim",
      "decoder_dim",
      "decoder_rates",
      "attn_window_size",
      "codebook_size",
      "codebook_dim",
      "vq_strides",
      "noise",
      "depthwise"
    ],
    "preprocess": [
      "self",
      "audio_data"
    ],
    "__call__": [
      "self",
      "audio_data"
    ],
    "encode": [
      "self",
      "audio_data"
    ],
    "decode": [
      "self",
      "codes"
    ],
    "decode_stream": [
      "self",
      "codes",
      "prev_codes",
      "context_frames"
    ],
    "_extra_repr": [
      "self"
    ],
    "from_config": [
      "cls",
      "config_path"
    ],
    "from_pretrained": [
      "cls",
      "repo_id"
    ]
  },
  "normalize_weight": [
    "x",
    "except_dim"
  ],
  "WNConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias"
    ],
    "_extra_repr": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "WNConvTranspose1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "output_padding",
      "groups",
      "bias"
    ],
    "_extra_repr": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "snake": [
    "x",
    "alpha"
  ],
  "ResidualUnit": {
    "__init__": [
      "self",
      "dim",
      "dilation",
      "kernel",
      "groups"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "EncoderBlock": {
    "__init__": [
      "self",
      "output_dim",
      "input_dim",
      "stride",
      "groups"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "VectorQuantize": {
    "__init__": [
      "self",
      "input_dim",
      "codebook_size",
      "codebook_dim",
      "stride"
    ],
    "__call__": [
      "self",
      "z"
    ],
    "embed_code": [
      "self",
      "embed_id"
    ],
    "decode_code": [
      "self",
      "embed_id"
    ],
    "decode_latents": [
      "self",
      "latents"
    ]
  },
  "ResidualVectorQuantize": {
    "__init__": [
      "self",
      "input_dim",
      "codebook_size",
      "codebook_dim",
      "vq_strides"
    ],
    "__call__": [
      "self",
      "z"
    ],
    "from_codes": [
      "self",
      "codes"
    ]
  },
  "mimi_202407": [
    "num_codebooks"
  ],
  "Mimi": {
    "__init__": [
      "self",
      "cfg"
    ],
    "reset_state": [
      "self"
    ],
    "encode": [
      "self",
      "xs"
    ],
    "decode": [
      "self",
      "xs"
    ],
    "encode_step": [
      "self",
      "xs"
    ],
    "decode_step": [
      "self",
      "xs"
    ],
    "warmup": [
      "self"
    ],
    "frame_rate": [
      "self"
    ],
    "sample_rate": [
      "self"
    ],
    "load_pytorch_weights": [
      "self",
      "file",
      "strict"
    ],
    "from_pretrained": [
      "cls",
      "repo_id",
      "filename"
    ]
  },
  "MimiStreamingDecoder": {
    "__init__": [
      "self",
      "mimi"
    ],
    "reset": [
      "self"
    ],
    "decode_frames": [
      "self",
      "tokens"
    ]
  },
  "Conv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "ksize",
      "stride",
      "padding",
      "groups",
      "dilation",
      "bias"
    ],
    "__call__": [
      "self",
      "xs"
    ]
  },
  "ConvTranspose1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "ksize",
      "stride",
      "padding",
      "groups",
      "bias"
    ],
    "update_in_place": [
      "self"
    ],
    "update": [
      "self",
      "parameters",
      "strict"
    ],
    "__call__": [
      "self",
      "xs"
    ]
  },
  "NormConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "ksize",
      "stride",
      "padding",
      "groups",
      "dilation",
      "bias"
    ],
    "__call__": [
      "self",
      "xs"
    ]
  },
  "NormConvTranspose1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "ksize",
      "stride",
      "padding",
      "groups",
      "bias"
    ],
    "__call__": [
      "self",
      "xs"
    ]
  },
  "get_extra_padding_for_conv1d": [
    "xs",
    "ksize",
    "stride",
    "padding_total"
  ],
  "unpad1d": [
    "xs",
    "unpad_l",
    "unpad_r"
  ],
  "StreamableConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "ksize",
      "stride",
      "dilation",
      "groups",
      "bias",
      "causal",
      "pad_mode"
    ],
    "reset_state": [
      "self"
    ],
    "__call__": [
      "self",
      "xs"
    ],
    "step": [
      "self",
      "xs"
    ]
  },
  "StreamableConvTranspose1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "ksize",
      "stride",
      "groups",
      "bias",
      "causal"
    ],
    "reset_state": [
      "self"
    ],
    "__call__": [
      "self",
      "xs"
    ],
    "step": [
      "self",
      "xs"
    ]
  },
  "ConvDownsample1d": {
    "__init__": [
      "self",
      "stride",
      "dim",
      "causal"
    ],
    "reset_state": [
      "self"
    ],
    "__call__": [
      "self",
      "xs"
    ],
    "step": [
      "self",
      "xs"
    ]
  },
  "ConvTrUpsample1d": {
    "__init__": [
      "self",
      "stride",
      "dim",
      "causal"
    ],
    "reset_state": [
      "self"
    ],
    "__call__": [
      "self",
      "xs"
    ],
    "step": [
      "self",
      "xs"
    ]
  },
  "TransformerConfig": {
    "head_dim": [
      "self"
    ]
  },
  "Id": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "xs"
    ]
  },
  "MlpGating": {
    "__init__": [
      "self",
      "cfg"
    ],
    "__call__": [
      "self",
      "xs"
    ]
  },
  "MlpNoGating": {
    "__init__": [
      "self",
      "cfg"
    ],
    "__call__": [
      "self",
      "xs"
    ]
  },
  "TransformerLayer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "__call__": [
      "self",
      "xs",
      "cache",
      "mask"
    ]
  },
  "Transformer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "__call__": [
      "self",
      "xs",
      "cache",
      "mask"
    ],
    "make_cache": [
      "self"
    ],
    "make_rot_cache": [
      "self"
    ]
  },
  "ProjectedTransformer": {
    "__init__": [
      "self",
      "cfg",
      "input_dim",
      "output_dims"
    ],
    "__call__": [
      "self",
      "xs",
      "cache",
      "mask"
    ],
    "make_cache": [
      "self"
    ],
    "make_rot_cache": [
      "self"
    ]
  },
  "SeanetConfig": {},
  "StreamingAdd": {
    "__init__": [
      "self"
    ],
    "step": [
      "self",
      "lhs",
      "rhs"
    ]
  },
  "SeanetResnetBlock": {
    "__init__": [
      "self",
      "cfg",
      "dim",
      "ksizes_and_dilations"
    ],
    "reset_state": [
      "self"
    ],
    "__call__": [
      "self",
      "xs"
    ],
    "step": [
      "self",
      "xs"
    ]
  },
  "SeanetEncoder": {
    "__init__": [
      "self",
      "cfg"
    ],
    "reset_state": [
      "self"
    ],
    "__call__": [
      "self",
      "xs"
    ],
    "step": [
      "self",
      "xs"
    ]
  },
  "SeanetDecoder": {
    "__init__": [
      "self",
      "cfg"
    ],
    "reset_state": [
      "self"
    ],
    "__call__": [
      "self",
      "xs"
    ],
    "step": [
      "self",
      "xs"
    ]
  },
  "Seanet": {
    "__init__": [
      "self",
      "cfg"
    ]
  },
  "FeatureExtractor": {
    "__call__": [
      "self",
      "audio"
    ]
  },
  "MelSpectrogramFeatures": {
    "__init__": [
      "self",
      "sample_rate",
      "n_fft",
      "hop_length",
      "n_mels",
      "padding"
    ],
    "__call__": [
      "self",
      "audio"
    ]
  },
  "EncodecFeatures": {
    "__init__": [
      "self",
      "encodec_model",
      "bandwidths",
      "train_codebooks"
    ],
    "get_encodec_codes": [
      "self",
      "audio",
      "bandwidth_id"
    ],
    "get_features_from_codes": [
      "self",
      "codes"
    ],
    "__call__": [
      "self",
      "audio"
    ]
  },
  "VocosBackbone": {
    "__init__": [
      "self",
      "input_channels",
      "dim",
      "intermediate_dim",
      "num_layers",
      "layer_scale_init_value",
      "adanorm_num_embeddings",
      "bias",
      "input_kernel_size",
      "dw_kernel_size"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Vocos": {
    "__init__": [
      "self",
      "feature_extractor",
      "backbone",
      "head"
    ],
    "from_hparams": [
      "cls",
      "config"
    ],
    "from_pretrained": [
      "cls",
      "path_or_repo"
    ],
    "__call__": [
      "self",
      "audio_input"
    ],
    "get_encodec_codes": [
      "self",
      "audio_input",
      "bandwidth_id"
    ],
    "decode": [
      "self",
      "features_input"
    ],
    "decode_from_codes": [
      "self",
      "codes"
    ]
  },
  "DACVAEConfig": {
    "hop_length": [
      "self"
    ]
  },
  "LSTMBlock": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "skip"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "MsgProcessor": {
    "__init__": [
      "self",
      "nbits",
      "hidden_size"
    ],
    "__call__": [
      "self",
      "hidden",
      "msg"
    ]
  },
  "WatermarkEncoderBlock": {
    "__init__": [
      "self",
      "out_dim",
      "wm_channels",
      "hidden",
      "lstm_layers"
    ],
    "set_shared_layers": [
      "self",
      "snake_out",
      "conv_out"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "forward_no_wm_conv": [
      "self",
      "x"
    ],
    "post_process": [
      "self",
      "x"
    ]
  },
  "WatermarkDecoderBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "channels",
      "hidden",
      "lstm_layers"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "post_process": [
      "self",
      "x"
    ]
  },
  "Watermarker": {
    "__init__": [
      "self",
      "d_out",
      "d_latent",
      "channels",
      "hidden",
      "nbits",
      "lstm_layers"
    ],
    "set_shared_layers": [
      "self",
      "snake_out",
      "conv_out"
    ],
    "random_message": [
      "self",
      "batch_size"
    ]
  },
  "QuantizerInProj": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "QuantizerOutProj": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DACVAE": {
    "__init__": [
      "self",
      "config"
    ],
    "_pad": [
      "self",
      "wavs"
    ],
    "encode": [
      "self",
      "waveform"
    ],
    "decode": [
      "self",
      "encoded_frames",
      "chunk_size"
    ],
    "_decode_chunked": [
      "self",
      "encoded_frames",
      "chunk_size",
      "overlap"
    ],
    "decode_streaming": [
      "self",
      "encoded_frames",
      "chunk_size",
      "overlap"
    ],
    "decode_stream": [
      "self",
      "encoded_frames",
      "callback",
      "chunk_size",
      "overlap"
    ],
    "__call__": [
      "self",
      "waveform"
    ],
    "wav_idx_to_feature_idx": [
      "self",
      "wav_idx",
      "sample_rate"
    ],
    "feature_idx_to_wav_idx": [
      "self",
      "feature_idx",
      "sample_rate"
    ],
    "from_pretrained": [
      "cls",
      "repo_id"
    ]
  },
  "EncodecConfig": {},
  "preprocess_audio": [
    "raw_audio",
    "sampling_rate",
    "chunk_length",
    "chunk_stride"
  ],
  "_lstm_kernel": [],
  "lstm_custom": [
    "x",
    "h_in",
    "cell",
    "time_step"
  ],
  "EncodecConv1d": {
    "__init__": [
      "self",
      "config",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation"
    ],
    "_get_extra_padding_for_conv1d": [
      "self",
      "hidden_states"
    ],
    "_pad1d": [
      "self",
      "hidden_states",
      "paddings",
      "mode",
      "value"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "EncodecConvTranspose1d": {
    "__init__": [
      "self",
      "config",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "EncodecLSTM": {
    "__init__": [
      "self",
      "config",
      "dimension"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "EncodecResnetBlock": {
    "__init__": [
      "self",
      "config",
      "dim",
      "dilations"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "EncodecEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "EncodecDecoder": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "EncodecEuclideanCodebook": {
    "__init__": [
      "self",
      "config"
    ],
    "quantize": [
      "self",
      "hidden_states"
    ],
    "encode": [
      "self",
      "hidden_states"
    ],
    "decode": [
      "self",
      "embed_ind"
    ]
  },
  "EncodecVectorQuantization": {
    "__init__": [
      "self",
      "config"
    ],
    "encode": [
      "self",
      "hidden_states"
    ],
    "decode": [
      "self",
      "embed_ind"
    ]
  },
  "EncodecResidualVectorQuantizer": {
    "__init__": [
      "self",
      "config"
    ],
    "get_num_quantizers_for_bandwidth": [
      "self",
      "bandwidth"
    ],
    "encode": [
      "self",
      "embeddings",
      "bandwidth"
    ],
    "decode": [
      "self",
      "codes"
    ]
  },
  "Encodec": {
    "__init__": [
      "self",
      "config"
    ],
    "_encode_frame": [
      "self",
      "input_values",
      "bandwidth",
      "padding_mask"
    ],
    "encode": [
      "self",
      "input_values",
      "padding_mask",
      "bandwidth"
    ],
    "_linear_overlap_add": [
      "frames",
      "stride"
    ],
    "_decode_frame": [
      "self",
      "codes",
      "scale"
    ],
    "channels": [
      "self"
    ],
    "sampling_rate": [
      "self"
    ],
    "chunk_length": [
      "self"
    ],
    "chunk_stride": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "path_or_repo"
    ],
    "decode": [
      "self",
      "audio_codes",
      "audio_scales",
      "padding_mask"
    ]
  },
  "SUPPORTED_VERSIONS": [],
  "DACFile": {
    "save": [
      "self",
      "path"
    ],
    "load": [
      "cls",
      "path"
    ]
  },
  "CodecMixin": {
    "padding": [
      "self",
      "value"
    ],
    "get_delay": [
      "self"
    ],
    "get_output_length": [
      "self",
      "input_length"
    ],
    "compress": [
      "self",
      "audio_path",
      "win_duration",
      "normalize_db",
      "n_quantizers"
    ],
    "decompress": [
      "self",
      "obj"
    ]
  },
  "DAC": {
    "__init__": [
      "self",
      "encoder_dim",
      "encoder_rates",
      "latent_dim",
      "decoder_dim",
      "decoder_rates",
      "n_codebooks",
      "codebook_size",
      "codebook_dim",
      "sample_rate"
    ],
    "preprocess": [
      "self",
      "audio_data",
      "sample_rate"
    ],
    "encode": [
      "self",
      "audio_data",
      "n_quantizers"
    ],
    "decode": [
      "self",
      "z"
    ],
    "_extra_repr": [
      "self"
    ],
    "__call__": [
      "self",
      "audio_data",
      "sample_rate",
      "n_quantizers",
      "use_rvq",
      "return_loss"
    ],
    "from_pretrained": [
      "cls",
      "repo_id"
    ]
  },
  "sinc": [
    "x"
  ],
  "kaiser_sinc_filter1d": [
    "cutoff",
    "half_width",
    "kernel_size"
  ],
  "LowPassFilter1d": {
    "__init__": [
      "self",
      "cutoff",
      "half_width",
      "stride",
      "padding",
      "padding_mode",
      "kernel_size"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DownSample1d": {
    "__init__": [
      "self",
      "ratio",
      "kernel_size"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Activation1d": {
    "__init__": [
      "self",
      "activation",
      "up_ratio",
      "down_ratio",
      "up_kernel_size",
      "down_kernel_size"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "BigVGANConfig": {},
  "BigVGAN": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "sanitize": [
      "self",
      "weights"
    ]
  },
  "AMPBlock1": {
    "__init__": [
      "self",
      "channels",
      "snake_logscale",
      "activation",
      "kernel_size",
      "dilation"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "AMPBlock2": {
    "__init__": [
      "self",
      "channels",
      "snake_logscale",
      "activation",
      "kernel_size",
      "dilation"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "make_non_pad_mask": [
    "lengths",
    "max_len"
  ],
  "padding": [
    "data"
  ],
  "merge_tokenized_segments": [
    "tokenized_segments",
    "overlap",
    "token_rate"
  ],
  "S3_HOP": [],
  "S3_TOKEN_HOP": [],
  "S3_TOKEN_RATE": [],
  "sinusoids": [
    "length",
    "channels",
    "max_timescale"
  ],
  "ResidualAttentionBlock": {
    "__init__": [
      "self",
      "n_state",
      "n_head"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "AudioEncoder": {
    "__init__": [
      "self",
      "n_mels",
      "n_ctx",
      "n_state",
      "n_head",
      "n_layer",
      "stride"
    ],
    "__call__": [
      "self",
      "x",
      "x_len"
    ]
  },
  "S3Tokenizer": {
    "__init__": [
      "self",
      "name",
      "config"
    ],
    "__call__": [
      "self",
      "mel",
      "mel_len"
    ],
    "quantize": [
      "self",
      "mel",
      "mel_len"
    ]
  },
  "precompute_freqs_cis": [
    "dim",
    "end",
    "theta",
    "scaling"
  ],
  "apply_rotary_emb": [
    "xq",
    "xk",
    "cos",
    "sin"
  ],
  "FSQCodebook": {
    "__init__": [
      "self",
      "dim",
      "level"
    ],
    "preprocess": [
      "self",
      "x"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "embed_ind"
    ]
  },
  "FSQVectorQuantization": {
    "__init__": [
      "self",
      "dim",
      "codebook_size"
    ],
    "codebook": [
      "self"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "embed_ind"
    ]
  },
  "FSMNMultiHeadAttention": {
    "__init__": [
      "self",
      "n_state",
      "n_head",
      "kernel_size"
    ],
    "forward_fsmn": [
      "self",
      "inputs",
      "mask"
    ],
    "qkv_attention": [
      "self",
      "q",
      "k",
      "v",
      "mask",
      "mask_pad",
      "freqs_cis"
    ],
    "__call__": [
      "self",
      "x",
      "mask",
      "mask_pad",
      "freqs_cis"
    ]
  },
  "AudioEncoderV2": {
    "__init__": [
      "self",
      "n_mels",
      "n_state",
      "n_head",
      "n_layer",
      "stride"
    ],
    "__call__": [
      "self",
      "x",
      "x_len"
    ]
  },
  "S3TokenizerV2": {
    "__init__": [
      "self",
      "name",
      "config"
    ],
    "__call__": [
      "self",
      "mel",
      "mel_len"
    ],
    "quantize": [
      "self",
      "mel",
      "mel_len"
    ],
    "_quantize_mixed_batch": [
      "self",
      "mel",
      "mel_len",
      "long_audio_mask",
      "max_frames"
    ],
    "quantize_simple": [
      "self",
      "mel",
      "mel_len"
    ],
    "sanitize": [
      "self",
      "weights"
    ],
    "from_pretrained": [
      "cls",
      "name",
      "repo_id"
    ]
  },
  "format_timestamp": [
    "seconds"
  ],
  "format_vtt_timestamp": [
    "seconds"
  ],
  "save_as_txt": [
    "segments",
    "output_path"
  ],
  "save_as_srt": [
    "segments",
    "output_path"
  ],
  "save_as_vtt": [
    "segments",
    "output_path"
  ],
  "save_as_json": [
    "segments",
    "output_path"
  ],
  "generation_stream": [],
  "wired_limit": [
    "model",
    "streams"
  ],
  "generate_transcription": [
    "model",
    "audio",
    "output_path",
    "format",
    "verbose",
    "text"
  ],
  "TestWhisperModel": {
    "setUp": [
      "self"
    ],
    "test_from_pretrained": [
      "self",
      "mock_open",
      "mock_glob",
      "mock_json_loads_in_whisper",
      "mock_mx_load",
      "mock_snapshot_download",
      "mock_pathlib_path"
    ],
    "test_generate_simple_case": [
      "self",
      "mock_log_mel",
      "mock_tqdm_tqdm",
      "mock_pad_or_trim"
    ]
  },
  "TestParakeetModel": {
    "test_parakeet_tdt_from_pretrained": [
      "self",
      "mock_mlx_core_load",
      "mock_parakeet_module_open",
      "mock_parakeet_json_load",
      "mock_hf_hub_download",
      "mock_module_load_weights"
    ]
  },
  "TestGLMASRModel": {
    "setUp": [
      "self"
    ],
    "test_whisper_config_from_dict": [
      "self"
    ],
    "test_llama_config_from_dict": [
      "self"
    ],
    "test_model_config_from_dict": [
      "self"
    ],
    "test_whisper_encoder_output_shape": [
      "self"
    ],
    "test_audio_encoder_output_shape": [
      "self"
    ],
    "test_audio_encoder_boa_eoa_tokens": [
      "self"
    ],
    "test_model_sanitize_weights": [
      "self"
    ],
    "test_model_sanitize_conv_transpose": [
      "self"
    ],
    "test_model_forward_pass": [
      "self"
    ],
    "test_from_pretrained": [
      "self",
      "mock_auto_tokenizer",
      "mock_json_load",
      "mock_open",
      "mock_mx_load",
      "mock_glob",
      "mock_get_model_path",
      "mock_load_config",
      "mock_load_weights"
    ]
  },
  "TestQwen3ASRConfig": {
    "setUp": [
      "self"
    ],
    "test_audio_encoder_config_default_values": [
      "self"
    ],
    "test_audio_encoder_config_from_dict": [
      "self"
    ],
    "test_text_config_default_values": [
      "self"
    ],
    "test_text_config_from_dict": [
      "self"
    ],
    "test_model_config_default_nested_configs": [
      "self"
    ],
    "test_model_config_from_dict_with_nested": [
      "self"
    ],
    "test_model_config_from_dict_with_thinker_config": [
      "self"
    ],
    "test_model_config_from_dict_detects_forced_aligner": [
      "self"
    ],
    "test_forced_aligner_config_default_values": [
      "self"
    ],
    "test_forced_aligner_config_from_dict": [
      "self"
    ]
  },
  "TestQwen3ASRForceAlignProcessor": {
    "setUp": [
      "self"
    ],
    "test_is_kept_char": [
      "self"
    ],
    "test_clean_token": [
      "self"
    ],
    "test_is_cjk_char": [
      "self"
    ],
    "test_tokenize_chinese_mixed": [
      "self"
    ],
    "test_tokenize_space_lang": [
      "self"
    ],
    "test_encode_timestamp_english": [
      "self"
    ],
    "test_encode_timestamp_chinese": [
      "self"
    ],
    "test_fix_timestamp_monotonic": [
      "self"
    ],
    "test_fix_timestamp_non_monotonic": [
      "self"
    ],
    "test_fix_timestamp_empty": [
      "self"
    ],
    "test_parse_timestamp": [
      "self"
    ]
  },
  "TestQwen3ASRForcedAlignResult": {
    "setUp": [
      "self"
    ],
    "test_forced_align_item": [
      "self"
    ],
    "test_forced_align_result_text_property": [
      "self"
    ],
    "test_forced_align_result_segments_property": [
      "self"
    ],
    "test_forced_align_result_iteration": [
      "self"
    ]
  },
  "TestQwen3ASRModel": {
    "setUp": [
      "self"
    ],
    "test_sinusoidal_position_embedding_output_shape": [
      "self"
    ],
    "test_sinusoidal_position_embedding_even_channels_required": [
      "self"
    ],
    "test_create_additive_causal_mask_shape": [
      "self"
    ],
    "test_create_additive_causal_mask_is_causal": [
      "self"
    ],
    "test_get_feat_extract_output_lengths": [
      "self"
    ],
    "test_split_audio_into_chunks_single": [
      "self"
    ],
    "test_split_audio_into_chunks_multiple": [
      "self"
    ],
    "test_audio_attention_output_shape": [
      "self"
    ],
    "test_audio_encoder_layer_output_shape": [
      "self"
    ],
    "test_text_model_forward_with_input_ids": [
      "self"
    ],
    "test_text_model_forward_with_embeddings": [
      "self"
    ],
    "test_qwen3_asr_model_init": [
      "self"
    ],
    "test_qwen3_asr_model_forward_logits_shape": [
      "self"
    ],
    "test_qwen3_asr_model_sample_rate": [
      "self"
    ],
    "test_qwen3_asr_model_sanitize_removes_thinker_prefix": [
      "self"
    ],
    "test_qwen3_asr_model_sanitize_transposes_conv_weights": [
      "self"
    ],
    "test_qwen3_asr_model_sanitize_skips_lm_head": [
      "self"
    ],
    "test_qwen3_asr_model_quant_predicate": [
      "self"
    ],
    "test_forced_aligner_model_init": [
      "self"
    ],
    "test_forced_aligner_model_lm_head_output_size": [
      "self"
    ],
    "test_forced_aligner_model_forward_logits_shape": [
      "self"
    ],
    "test_forced_aligner_model_sanitize_keeps_lm_head": [
      "self"
    ],
    "test_model_wrapper_creates_asr_model_for_asr_config": [
      "self"
    ],
    "test_model_wrapper_creates_aligner_model_for_aligner_config": [
      "self"
    ],
    "test_model_wrapper_delegation": [
      "self"
    ],
    "test_model_wrapper_call_delegation": [
      "self"
    ],
    "test_model_wrapper_is_forced_aligner_weights": [
      "self"
    ],
    "test_model_wrapper_sanitize_uses_correct_method": [
      "self"
    ]
  },
  "STTOutput": {},
  "Wav2Vec2NoLayerNormConvLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "Wav2Vec2LayerNormConvLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "Wav2Vec2GroupNormConvLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "Wav2Vec2PositionalConvEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "Wav2Vec2SamePadLayer": {
    "__init__": [
      "self",
      "num_conv_pos_embeddings"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "Wav2Vec2FeatureEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "input_values"
    ]
  },
  "Wav2Vec2FeatureProjection": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "Wav2Vec2Attention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "dropout",
      "is_decoder",
      "bias",
      "is_causal",
      "config"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "key_value_states",
      "past_key_value",
      "attention_mask"
    ]
  },
  "Wav2Vec2FeedForward": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "Wav2Vec2EncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "Wav2Vec2EncoderLayerStableLayerNorm": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "Wav2Vec2Encoder": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "Wav2Vec2EncoderStableLayerNorm": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "Wav2Vec2BaseModelOutput": {},
  "Wav2Vec2Model": {
    "__init__": [
      "self",
      "config"
    ],
    "_mask_hidden_states": [
      "self",
      "hidden_states",
      "mask_time_indices",
      "attention_mask"
    ],
    "__call__": [
      "self",
      "input_values",
      "attention_mask",
      "output_hidden_states",
      "return_dict"
    ],
    "sanitize": [
      "self",
      "weights"
    ],
    "from_pretrained": [
      "cls",
      "repo_id"
    ]
  },
  "TensorType": {
    "MX": [],
    "NP": []
  },
  "BatchFeature": {
    "__init__": [
      "self",
      "data",
      "input_values",
      "attention_mask",
      "tensor_type"
    ]
  },
  "PaddingStrategy": {
    "LONGEST": [],
    "MAX_LENGTH": [],
    "DO_NOT_PAD": []
  },
  "load_json": [
    "path"
  ],
  "Wav2Vec2FeatureExtractor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "feature_size",
      "sampling_rate",
      "padding_value",
      "return_attention_mask",
      "do_normalize"
    ],
    "zero_mean_unit_var_norm": [
      "input_values",
      "attention_mask",
      "padding_value"
    ],
    "_truncate": [
      "self",
      "processed_features",
      "max_length",
      "pad_to_multiple_of",
      "truncation"
    ],
    "_get_padding_strategies": [
      "self",
      "padding",
      "max_length"
    ],
    "pad": [
      "self",
      "processed_features",
      "padding",
      "max_length",
      "truncation",
      "pad_to_multiple_of",
      "return_attention_mask",
      "return_tensors"
    ],
    "_pad": [
      "self",
      "processed_features",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ],
    "__call__": [
      "self",
      "raw_speech",
      "padding",
      "max_length",
      "truncation",
      "pad_to_multiple_of",
      "return_attention_mask",
      "return_tensors",
      "sampling_rate"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path",
      "file_name",
      "revision"
    ],
    "from_dict": [
      "cls",
      "feature_extractor_dict"
    ]
  },
  "AudioConfig": {
    "from_dict": [
      "cls",
      "params"
    ]
  },
  "TextConfig": {
    "from_dict": [
      "cls",
      "params"
    ],
    "__post_init__": [
      "self"
    ]
  },
  "VoxtralEncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "MultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "audio_features"
    ]
  },
  "LanguageModel": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "inputs",
      "cache",
      "input_embeddings"
    ],
    "layers": [
      "self"
    ]
  },
  "StreamingResult": {},
  "split_audio_into_chunks": [
    "wav",
    "sr",
    "chunk_duration",
    "min_chunk_duration",
    "search_expand_sec",
    "min_window_ms"
  ],
  "_floor_div": [
    "a",
    "b"
  ],
  "_get_feat_extract_output_lengths": [
    "input_lengths"
  ],
  "SinusoidalPositionEmbedding": {
    "__init__": [
      "self",
      "length",
      "channels",
      "max_timescale"
    ],
    "__call__": [
      "self",
      "seqlen"
    ]
  },
  "AudioAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "mask"
    ]
  },
  "AudioEncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "mask"
    ]
  },
  "TextAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "cache"
    ]
  },
  "TextMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "TextDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "cache"
    ]
  },
  "TextModel": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "input_ids",
      "inputs_embeds",
      "cache"
    ]
  },
  "Qwen3ASRModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_audio_features": [
      "self",
      "input_features",
      "feature_attention_mask"
    ],
    "_build_inputs_embeds": [
      "self",
      "input_ids",
      "audio_features"
    ],
    "_forward_with_embeds": [
      "self",
      "inputs_embeds",
      "cache"
    ],
    "__call__": [
      "self",
      "input_ids",
      "input_embeddings",
      "input_features",
      "feature_attention_mask",
      "cache"
    ],
    "layers": [
      "self"
    ],
    "sample_rate": [
      "self"
    ],
    "make_cache": [
      "self"
    ],
    "sanitize": [
      "weights"
    ],
    "model_quant_predicate": [
      "self",
      "p",
      "m"
    ],
    "post_load_hook": [
      "cls",
      "model",
      "model_path"
    ],
    "_preprocess_audio": [
      "self",
      "audio"
    ],
    "_build_prompt": [
      "self",
      "num_audio_tokens",
      "language"
    ],
    "stream_generate": [
      "self",
      "audio"
    ],
    "_generate_single_chunk": [
      "self",
      "audio_chunk"
    ],
    "generate": [
      "self",
      "audio"
    ],
    "stream_transcribe": [
      "self",
      "audio"
    ]
  },
  "ForceAlignProcessor": {
    "__init__": [
      "self"
    ],
    "is_kept_char": [
      "self",
      "ch"
    ],
    "clean_token": [
      "self",
      "token"
    ],
    "is_cjk_char": [
      "self",
      "ch"
    ],
    "tokenize_chinese_mixed": [
      "self",
      "text"
    ],
    "tokenize_japanese": [
      "self",
      "text"
    ],
    "tokenize_korean": [
      "self",
      "text"
    ],
    "split_segment_with_chinese": [
      "self",
      "seg"
    ],
    "tokenize_space_lang": [
      "self",
      "text"
    ],
    "fix_timestamp": [
      "self",
      "data"
    ],
    "encode_timestamp": [
      "self",
      "text",
      "language"
    ],
    "parse_timestamp": [
      "self",
      "word_list",
      "timestamp"
    ]
  },
  "ForcedAlignItem": {},
  "ForcedAlignResult": {
    "text": [
      "self"
    ],
    "segments": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "ForcedAlignerConfig": {
    "__post_init__": [
      "self"
    ],
    "from_dict": [
      "cls",
      "params"
    ]
  },
  "ForcedAlignerModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_audio_features": [
      "self",
      "input_features",
      "feature_attention_mask"
    ],
    "__call__": [
      "self",
      "input_ids",
      "input_features",
      "feature_attention_mask"
    ],
    "layers": [
      "self"
    ],
    "sample_rate": [
      "self"
    ],
    "sanitize": [
      "weights"
    ],
    "model_quant_predicate": [
      "self",
      "p",
      "m"
    ],
    "post_load_hook": [
      "cls",
      "model",
      "model_path"
    ],
    "_preprocess_audio": [
      "self",
      "audio"
    ],
    "generate": [
      "self",
      "audio",
      "text",
      "language"
    ],
    "get_supported_languages": [
      "self"
    ]
  },
  "AudioEncoderConfig": {
    "from_dict": [
      "cls",
      "params"
    ]
  },
  "DwStridingSubsampling": {
    "__init__": [
      "self",
      "args"
    ],
    "conv_forward": [
      "self",
      "x"
    ],
    "conv_split_by_batch": [
      "self",
      "x"
    ],
    "__call__": [
      "self",
      "x",
      "lengths"
    ]
  },
  "PreprocessArgs": {
    "win_length": [
      "self"
    ],
    "hop_length": [
      "self"
    ]
  },
  "AlignedToken": {
    "__post_init__": [
      "self"
    ]
  },
  "AlignedSentence": {
    "__post_init__": [
      "self"
    ]
  },
  "AlignedResult": {
    "__post_init__": [
      "self"
    ]
  },
  "tokens_to_sentences": [
    "tokens"
  ],
  "sentences_to_result": [
    "sentences"
  ],
  "merge_longest_contiguous": [
    "a",
    "b"
  ],
  "merge_longest_common_subsequence": [
    "a",
    "b"
  ],
  "TDTDecodingArgs": {},
  "RNNTDecodingArgs": {},
  "CTCDecodingArgs": {},
  "ParakeetTDTArgs": {},
  "ParakeetRNNTArgs": {},
  "ParakeetCTCArgs": {},
  "ParakeetTDTCTCArgs": {},
  "ParakeetTDT": {
    "__init__": [
      "self",
      "args"
    ],
    "decode": [
      "self",
      "mel"
    ]
  },
  "ParakeetRNNT": {
    "__init__": [
      "self",
      "args"
    ],
    "decode": [
      "self",
      "mel"
    ]
  },
  "ParakeetCTC": {
    "__init__": [
      "self",
      "args"
    ],
    "decode": [
      "self",
      "mel"
    ]
  },
  "ParakeetTDTCTC": {
    "__init__": [
      "self",
      "args"
    ]
  },
  "PredictNetworkArgs": {},
  "JointNetworkArgs": {},
  "PredictArgs": {},
  "JointArgs": {},
  "PredictNetwork": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "y",
      "h_c"
    ]
  },
  "JointNetwork": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "enc",
      "pred"
    ]
  },
  "ConvASRDecoderArgs": {},
  "AuxCTCArgs": {},
  "ConvASRDecoder": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "HFTokenizerWrapper": {
    "__init__": [
      "self",
      "hf_tokenizer",
      "multilingual",
      "num_languages",
      "language",
      "task"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "tokens",
      "skip_special_tokens"
    ],
    "decode_with_timestamps": [
      "self",
      "tokens"
    ],
    "eot": [
      "self"
    ],
    "timestamp_begin": [
      "self"
    ],
    "sot": [
      "self"
    ],
    "sot_lm": [
      "self"
    ],
    "no_timestamps": [
      "self"
    ],
    "no_speech": [
      "self"
    ],
    "transcribe": [
      "self"
    ],
    "translate": [
      "self"
    ],
    "sot_prev": [
      "self"
    ],
    "language_token": [
      "self"
    ],
    "sot_sequence": [
      "self"
    ],
    "sot_sequence_including_notimestamps": [
      "self"
    ],
    "task_token": [
      "self"
    ],
    "all_language_tokens": [
      "self"
    ],
    "all_language_codes": [
      "self"
    ],
    "non_speech_tokens": [
      "self"
    ],
    "split_to_word_tokens": [
      "self",
      "tokens"
    ],
    "_split_tokens_on_unicode": [
      "self",
      "tokens"
    ],
    "_split_tokens_on_spaces": [
      "self",
      "tokens"
    ]
  },
  "_format_timestamp": [
    "seconds"
  ],
  "_get_end": [
    "segments"
  ],
  "ModelDimensions": {
    "from_dict": [
      "cls",
      "config"
    ]
  },
  "TextDecoder": {
    "__init__": [
      "self",
      "n_vocab",
      "n_ctx",
      "n_state",
      "n_head",
      "n_layer",
      "dtype"
    ],
    "__call__": [
      "self",
      "x",
      "xa",
      "kv_cache"
    ]
  },
  "N_FFT": [],
  "HOP_LENGTH": [],
  "CHUNK_LENGTH": [],
  "N_SAMPLES": [],
  "N_FRAMES": [],
  "N_SAMPLES_PER_TOKEN": [],
  "FRAMES_PER_SECOND": [],
  "TOKENS_PER_SECOND": [],
  "pad_or_trim": [
    "array",
    "length"
  ],
  "median_filter": [
    "x",
    "filter_width"
  ],
  "backtrace": [
    "trace"
  ],
  "dtw_cpu": [
    "x"
  ],
  "dtw": [
    "x"
  ],
  "WordTiming": {},
  "find_alignment": [
    "model",
    "tokenizer",
    "text_tokens",
    "mel",
    "num_frames"
  ],
  "merge_punctuations": [
    "alignment",
    "prepended",
    "appended"
  ],
  "add_word_timestamps": [],
  "LANGUAGES": [],
  "TO_LANGUAGE_CODE": [],
  "get_start": [
    "segments"
  ],
  "ResultWriter": {
    "__init__": [
      "self",
      "output_dir"
    ],
    "__call__": [
      "self",
      "result",
      "output_name",
      "options"
    ],
    "write_result": [
      "self",
      "result",
      "file",
      "options"
    ]
  },
  "WriteTXT": {
    "write_result": [
      "self",
      "result",
      "file",
      "options"
    ]
  },
  "SubtitlesWriter": {
    "iterate_result": [
      "self",
      "result",
      "options"
    ],
    "format_timestamp": [
      "self",
      "seconds"
    ]
  },
  "WriteVTT": {
    "write_result": [
      "self",
      "result",
      "file",
      "options"
    ]
  },
  "WriteSRT": {
    "write_result": [
      "self",
      "result",
      "file",
      "options"
    ]
  },
  "WriteTSV": {
    "write_result": [
      "self",
      "result",
      "file",
      "options"
    ]
  },
  "WriteJSON": {
    "write_result": [
      "self",
      "result",
      "file",
      "options"
    ]
  },
  "get_writer": [
    "output_format",
    "output_dir"
  ],
  "compression_ratio": [
    "text"
  ],
  "detect_language": [
    "model",
    "mel",
    "tokenizer"
  ],
  "get_suppress_tokens": [
    "tokenizer",
    "suppress_tokens"
  ],
  "DecodingOptions": {},
  "DecodingResult": {},
  "Inference": {
    "__init__": [
      "self",
      "model"
    ],
    "logits": [
      "self",
      "tokens",
      "audio_features"
    ],
    "logits_with_cross_qk": [
      "self",
      "tokens",
      "audio_features"
    ],
    "rearrange_kv_cache": [
      "self",
      "source_indices"
    ],
    "reset": [
      "self"
    ]
  },
  "SequenceRanker": {
    "rank": [
      "self",
      "tokens",
      "sum_logprobs"
    ]
  },
  "MaximumLikelihoodRanker": {
    "__init__": [
      "self",
      "length_penalty"
    ],
    "rank": [
      "self",
      "tokens",
      "sum_logprobs"
    ]
  },
  "TokenDecoder": {
    "reset": [
      "self"
    ],
    "update": [
      "self",
      "tokens",
      "logits",
      "sum_logprobs"
    ],
    "finalize": [
      "self",
      "tokens",
      "sum_logprobs"
    ]
  },
  "categorical": [
    "logits",
    "temp"
  ],
  "GreedyDecoder": {
    "__init__": [
      "self",
      "temperature",
      "eot"
    ],
    "update": [
      "self",
      "tokens",
      "logits",
      "sum_logprobs"
    ],
    "finalize": [
      "self",
      "tokens",
      "sum_logprobs"
    ]
  },
  "LogitFilter": {
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "SuppressBlank": {
    "__init__": [
      "self",
      "tokenizer",
      "sample_begin",
      "n_vocab"
    ],
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "SuppressTokens": {
    "__init__": [
      "self",
      "suppress_tokens",
      "n_vocab"
    ],
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "ApplyTimestampRules": {
    "__init__": [
      "self",
      "tokenizer",
      "sample_begin",
      "max_initial_timestamp_index"
    ],
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "DecodingTask": {
    "__init__": [
      "self",
      "model",
      "options"
    ],
    "_verify_options": [
      "self",
      "options"
    ],
    "_get_initial_tokens": [
      "self"
    ],
    "_get_audio_features": [
      "self",
      "mel"
    ],
    "_detect_language": [
      "self",
      "audio_features",
      "tokens"
    ],
    "_main_loop": [
      "self",
      "audio_features",
      "tokens"
    ],
    "run": [
      "self",
      "mel"
    ]
  },
  "StreamingConfig": {},
  "get_most_attended_frame": [
    "cross_qk",
    "alignment_heads"
  ],
  "should_emit": [
    "most_attended_frame",
    "content_frames",
    "config"
  ],
  "StreamingDecoder": {
    "__init__": [
      "self",
      "model",
      "config",
      "language",
      "task"
    ],
    "reset": [
      "self"
    ],
    "decode_chunk": [
      "self",
      "mel",
      "is_last"
    ]
  },
  "TestStreamingConfig": {
    "test_default_values": [
      "self"
    ],
    "test_custom_values": [
      "self"
    ]
  },
  "TestStreamingResult": {
    "test_creation": [
      "self"
    ],
    "test_final_result": [
      "self"
    ]
  },
  "TestInferenceWithCrossAttention": {
    "mock_model": [
      "self"
    ],
    "test_logits_with_cross_qk": [
      "self",
      "mock_model"
    ]
  },
  "TestGetMostAttendedFrame": {
    "test_single_head": [
      "self"
    ],
    "test_multiple_heads_averaged": [
      "self"
    ]
  },
  "TestShouldEmit": {
    "test_emit_when_attention_near_end": [
      "self"
    ],
    "test_no_emit_when_attention_far_from_end": [
      "self"
    ],
    "test_emit_at_exact_threshold": [
      "self"
    ]
  },
  "TestStreamingDecoder": {
    "whisper_model": [
      "self"
    ],
    "test_initialization": [
      "self",
      "whisper_model"
    ],
    "test_reset_clears_state": [
      "self",
      "whisper_model"
    ]
  },
  "TestDecodeChunk": {
    "whisper_model": [
      "self"
    ],
    "sample_audio": [
      "self"
    ],
    "test_decode_chunk_returns_result": [
      "self",
      "whisper_model",
      "sample_audio"
    ],
    "test_decode_chunk_accumulates_audio": [
      "self",
      "whisper_model",
      "sample_audio"
    ]
  },
  "TestGenerateStreaming": {
    "whisper_model": [
      "self"
    ],
    "sample_audio_file": [
      "self",
      "tmp_path"
    ],
    "test_generate_streaming_is_generator": [
      "self",
      "whisper_model",
      "sample_audio_file"
    ],
    "test_generate_streaming_final_result": [
      "self",
      "whisper_model",
      "sample_audio_file"
    ],
    "test_generate_streaming_auto_language_detection": [
      "self",
      "whisper_model",
      "sample_audio_file"
    ]
  },
  "TestStreamingIntegration": {
    "whisper_model": [
      "self"
    ],
    "speech_audio": [
      "self",
      "tmp_path"
    ],
    "test_streaming_produces_results": [
      "self",
      "whisper_model",
      "speech_audio"
    ],
    "test_streaming_lower_latency_than_batch": [
      "self",
      "whisper_model",
      "speech_audio"
    ]
  },
  "TestModuleExports": {
    "test_import_from_whisper_module": [
      "self"
    ]
  },
  "TestSharedHelpers": {
    "whisper_model": [
      "self"
    ],
    "test_prepare_audio_from_path": [
      "self",
      "whisper_model",
      "tmp_path"
    ],
    "test_prepare_audio_from_array": [
      "self",
      "whisper_model"
    ],
    "test_detect_language_returns_code": [
      "self",
      "whisper_model"
    ],
    "test_detect_language_respects_override": [
      "self",
      "whisper_model"
    ],
    "test_get_suppress_tokens_helper": [
      "self"
    ]
  },
  "WhisperAttention": {
    "__init__": [
      "self",
      "config",
      "use_rope"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "WhisperEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "use_rope"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "WhisperEncoder": {
    "__init__": [
      "self",
      "config",
      "use_rope"
    ],
    "__call__": [
      "self",
      "input_features"
    ]
  },
  "AdaptingMLP": {
    "__init__": [
      "self",
      "input_dim",
      "intermediate_dim",
      "output_dim"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "WhisperConfig": {
    "from_dict": [
      "cls",
      "params"
    ]
  },
  "LlamaConfig": {
    "__post_init__": [
      "self"
    ],
    "from_dict": [
      "cls",
      "params"
    ]
  },
  "SConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "groups",
      "bias",
      "causal",
      "pad_mode"
    ],
    "_get_extra_padding": [
      "self",
      "length"
    ],
    "_MAX_DEPTHWISE_ELEMENTS": [],
    "_depthwise_conv_chunk": [
      "self",
      "x",
      "T_out"
    ],
    "_depthwise_conv": [
      "self",
      "x",
      "padding_left",
      "padding_right"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "_chunked_standard_conv": [
      "self",
      "x",
      "padding_left",
      "padding_right",
      "T_out"
    ]
  },
  "FFN": {
    "_MAX_INTERMEDIATE_ELEMENTS": [],
    "__init__": [
      "self",
      "embed_dim",
      "ffn_dim",
      "bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "TokenizerEncoder": {
    "__init__": [
      "self",
      "channels",
      "vae_dim",
      "n_filters",
      "ratios",
      "depths",
      "causal",
      "pad_mode",
      "conv_bias",
      "layernorm",
      "layernorm_eps",
      "layernorm_elementwise_affine",
      "mixer_layer",
      "layer_scale_init_value",
      "disable_last_norm"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "AcousticTokenizerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "encode": [
      "self",
      "audio"
    ],
    "sample": [
      "self",
      "mean"
    ],
    "__call__": [
      "self",
      "audio"
    ]
  },
  "SemanticTokenizerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "encode": [
      "self",
      "audio"
    ],
    "__call__": [
      "self",
      "audio"
    ]
  },
  "_filter_kwargs": [
    "cls",
    "kwargs"
  ],
  "SemanticTokenizerConfig": {
    "from_dict": [
      "cls",
      "d"
    ],
    "parsed_encoder_depths": [
      "self"
    ]
  },
  "Qwen2Config": {
    "from_dict": [
      "cls",
      "d"
    ],
    "head_dim": [
      "self"
    ]
  },
  "_small_acoustic_config": [],
  "_small_semantic_config": [],
  "_small_qwen2_config": [],
  "_small_model_config": [],
  "TestConfig": {
    "test_acoustic_tokenizer_config_from_dict": [
      "self"
    ],
    "test_acoustic_tokenizer_parsed_depths": [
      "self"
    ],
    "test_acoustic_tokenizer_parsed_depths_list": [
      "self"
    ],
    "test_semantic_tokenizer_config_from_dict": [
      "self"
    ],
    "test_qwen2_config_from_dict": [
      "self"
    ],
    "test_qwen2_config_head_dim": [
      "self"
    ],
    "test_model_config_from_dict": [
      "self"
    ],
    "test_model_config_ignores_extra_keys": [
      "self"
    ]
  },
  "TestSConv1d": {
    "test_output_shape_stride1": [
      "self"
    ],
    "test_output_shape_stride2": [
      "self"
    ],
    "test_groups_parameter": [
      "self"
    ]
  },
  "TestConvRMSNorm": {
    "test_output_shape": [
      "self"
    ],
    "test_normalization": [
      "self"
    ]
  },
  "TestBlock1D": {
    "test_output_shape": [
      "self"
    ],
    "test_residual_connection": [
      "self"
    ]
  },
  "TestTokenizerEncoder": {
    "test_output_shape": [
      "self"
    ],
    "test_2d_input": [
      "self"
    ],
    "test_hop_length": [
      "self"
    ]
  },
  "TestAcousticTokenizerEncoder": {
    "test_encode_output_shape": [
      "self"
    ],
    "test_sample_gaussian": [
      "self"
    ],
    "test_sample_none": [
      "self"
    ]
  },
  "TestSemanticTokenizerEncoder": {
    "test_encode_output_shape": [
      "self"
    ]
  },
  "TestSpeechConnector": {
    "test_output_shape": [
      "self"
    ],
    "test_different_dims": [
      "self"
    ]
  },
  "TestLanguageModel": {
    "test_forward_pass": [
      "self"
    ],
    "test_forward_with_embeddings": [
      "self"
    ],
    "test_embed_tokens_property": [
      "self"
    ],
    "test_layers_property": [
      "self"
    ]
  },
  "TestModelSanitize": {
    "setUp": [
      "self"
    ],
    "test_removes_model_prefix": [
      "self"
    ],
    "test_skips_decoder_weights": [
      "self"
    ],
    "test_downsample_layers_remap": [
      "self"
    ],
    "test_head_conv_remap": [
      "self"
    ],
    "test_mixer_conv_remap": [
      "self"
    ],
    "test_language_model_layers_remap": [
      "self"
    ],
    "test_language_model_embed_tokens_remap": [
      "self"
    ],
    "test_language_model_norm_remap": [
      "self"
    ],
    "test_lm_head_remap": [
      "self"
    ],
    "test_conv_transpose_pytorch_weights": [
      "self"
    ],
    "test_no_transpose_already_converted": [
      "self"
    ],
    "test_skips_position_ids": [
      "self"
    ],
    "test_skips_fix_std": [
      "self"
    ]
  },
  "TestModelQuantPredicate": {
    "setUp": [
      "self"
    ],
    "test_quantize_language_model": [
      "self"
    ],
    "test_skip_acoustic_tokenizer": [
      "self"
    ],
    "test_skip_semantic_tokenizer": [
      "self"
    ],
    "test_skip_connectors": [
      "self"
    ]
  },
  "TestModel": {
    "setUp": [
      "self"
    ],
    "test_model_init": [
      "self"
    ],
    "test_get_input_embeddings": [
      "self"
    ],
    "test_encode_speech_1d": [
      "self"
    ],
    "test_encode_speech_2d": [
      "self"
    ],
    "test_encode_speech_3d": [
      "self"
    ],
    "test_language_model_forward": [
      "self"
    ],
    "test_merge_speech_text_embeddings": [
      "self"
    ],
    "test_merge_no_speech_features": [
      "self"
    ]
  },
  "VoicePipeline": {
    "__init__": [
      "self",
      "silence_threshold",
      "silence_duration",
      "input_sample_rate",
      "output_sample_rate",
      "streaming_interval",
      "frame_duration_ms",
      "vad_mode",
      "stt_model",
      "llm_model",
      "tts_model"
    ],
    "init_models": [
      "self"
    ],
    "start": [
      "self"
    ],
    "_is_silent": [
      "self",
      "audio_data"
    ],
    "_voice_activity_detection": [
      "self",
      "frame"
    ],
    "_listener": [
      "self"
    ],
    "_sd_callback": [
      "self",
      "indata",
      "frames",
      "_time",
      "status"
    ],
    "_process_audio": [
      "self",
      "frames"
    ],
    "_response_processor": [
      "self"
    ],
    "_generate_response": [
      "self",
      "text"
    ],
    "_speak_response": [
      "self",
      "text",
      "cancel_event"
    ],
    "_audio_output_processor": [
      "self"
    ]
  },
  "TestVoicePipeline": {
    "test_initialization_default_params": [
      "self"
    ],
    "test_initialization_custom_params": [
      "self"
    ],
    "test_init_models": [
      "self",
      "mock_whisper_load",
      "mock_tts_load",
      "mock_llm_load"
    ],
    "test_is_silent_true": [
      "self"
    ],
    "test_is_silent_false": [
      "self"
    ],
    "test_voice_activity_detection_vad_speech": [
      "self",
      "mock_is_speech"
    ],
    "test_voice_activity_detection_vad_silence": [
      "self",
      "mock_is_speech"
    ],
    "test_voice_activity_detection_vad_error_fallback_silent": [
      "self",
      "mock_is_speech"
    ],
    "test_voice_activity_detection_vad_error_fallback_speech": [
      "self",
      "mock_is_speech"
    ]
  },
  "TestMossFormer2SEConfig": {
    "test_config_defaults": [
      "self"
    ],
    "test_config_from_dict": [
      "self"
    ],
    "test_config_to_dict": [
      "self"
    ],
    "test_config_sampling_rate_alias": [
      "self"
    ]
  },
  "TestSTFT": {
    "test_create_window_hamming": [
      "self"
    ],
    "test_create_window_hann": [
      "self"
    ],
    "test_stft_shape": [
      "self"
    ],
    "test_istft_cache": [
      "self"
    ]
  },
  "TestFeatures": {
    "test_compute_deltas_shape": [
      "self"
    ],
    "test_fbank_computation": [
      "self"
    ],
    "test_compute_deltas_vs_torchaudio": [
      "self"
    ],
    "test_fbank_vs_torchaudio": [
      "self"
    ]
  },
  "TestModelComponents": {
    "test_scale_norm": [
      "self"
    ],
    "test_global_layer_norm_3d": [
      "self"
    ],
    "test_clayer_norm": [
      "self"
    ],
    "test_scaled_sinu_embedding": [
      "self"
    ],
    "test_offset_scale": [
      "self"
    ]
  },
  "TestMossFormer2SE": {
    "test_model_initialization": [
      "self"
    ],
    "test_masknet_output_shape": [
      "self"
    ]
  },
  "DEFAULT_LFM_CONFIG": [],
  "get_test_config": [],
  "TestPreprocessorConfig": {
    "test_defaults": [
      "self"
    ]
  },
  "TestConformerEncoderConfig": {
    "test_defaults": [
      "self"
    ]
  },
  "TestDepthformerConfig": {
    "test_defaults": [
      "self"
    ]
  },
  "TestLFM2AudioConfig": {
    "test_from_dict": [
      "self"
    ]
  },
  "TestLFM2AudioModelOutput": {
    "test_call_returns_text_and_audio_logits": [
      "self"
    ]
  },
  "TestLFM2AudioModelDtype": {
    "test_model_components_exist": [
      "self"
    ],
    "test_sample_rate_property": [
      "self"
    ]
  },
  "TestLFMModality": {
    "test_modality_values": [
      "self"
    ]
  },
  "TestSpecialTokens": {
    "test_token_values": [
      "self"
    ]
  },
  "TestGenerationConfig": {
    "test_defaults": [
      "self"
    ]
  },
  "TestSAMAudioConfig": {
    "test_dacvae_config_defaults": [
      "self"
    ],
    "test_dacvae_config_hop_length": [
      "self"
    ],
    "test_t5_encoder_config_defaults": [
      "self"
    ],
    "test_transformer_config_defaults": [
      "self"
    ],
    "test_sam_audio_config_defaults": [
      "self"
    ],
    "test_sam_audio_config_from_dict": [
      "self"
    ]
  },
  "TestSeparationResult": {
    "test_separation_result_creation": [
      "self"
    ]
  },
  "TestDACVAECodec": {
    "setUp": [
      "self"
    ],
    "test_codec_initialization": [
      "self"
    ],
    "test_codec_hop_length": [
      "self"
    ],
    "test_codec_encode_shape": [
      "self"
    ],
    "test_codec_decode_shape": [
      "self"
    ],
    "test_codec_chunked_decode": [
      "self"
    ],
    "test_wav_idx_to_feature_idx": [
      "self"
    ],
    "test_feature_idx_to_wav_idx": [
      "self"
    ]
  },
  "TestSAMAudioModel": {
    "setUp": [
      "self"
    ],
    "test_model_initialization": [
      "self"
    ],
    "test_model_sample_rate": [
      "self"
    ],
    "test_sanitize_weights": [
      "self"
    ],
    "test_get_audio_features_shape": [
      "self"
    ]
  },
  "TestSAMAudioProcessor": {
    "test_processor_initialization": [
      "self"
    ],
    "test_batch_dataclass": [
      "self"
    ],
    "test_wav_to_feature_idx": [
      "self"
    ]
  },
  "TestODEStepFunctions": {
    "setUp": [
      "self"
    ],
    "test_ode_step_euler_shape": [
      "self"
    ],
    "test_ode_step_midpoint_shape": [
      "self"
    ]
  },
  "RelativePositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "max_len",
      "xscale"
    ],
    "_extend_pe": [
      "self",
      "length"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ConformerFeedForward": {
    "__init__": [
      "self",
      "d_model",
      "d_ff",
      "dropout"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ConformerConvolution": {
    "__init__": [
      "self",
      "d_model",
      "kernel_size",
      "norm_type",
      "dropout"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "RelativeMultiHeadAttention": {
    "__init__": [
      "self",
      "d_model",
      "num_heads",
      "dropout",
      "pos_bias"
    ],
    "_rel_shift": [
      "self",
      "x"
    ],
    "__call__": [
      "self",
      "x",
      "pos_emb",
      "mask"
    ]
  },
  "ConformerLayer": {
    "__init__": [
      "self",
      "d_model",
      "num_heads",
      "ff_expansion_factor",
      "conv_kernel_size",
      "conv_norm_type",
      "dropout",
      "dropout_att"
    ],
    "__call__": [
      "self",
      "x",
      "pos_emb",
      "mask"
    ]
  },
  "ConvSubsampling": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "subsampling_factor",
      "conv_channels",
      "subsampling_type"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ConformerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x",
      "lengths"
    ]
  },
  "SwiGLU": {
    "__init__": [
      "self",
      "dim",
      "hidden_dim",
      "multiple_of"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ConvBlock": {
    "__init__": [
      "self",
      "dim",
      "kernel_size",
      "bias"
    ],
    "__call__": [
      "self",
      "x",
      "cache"
    ]
  },
  "ConvTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "ff_dim",
      "kernel_size",
      "norm_eps",
      "multiple_of",
      "bias"
    ],
    "__call__": [
      "self",
      "x",
      "cache"
    ]
  },
  "Depthformer": {
    "__init__": [
      "self",
      "layers",
      "dim",
      "num_heads",
      "num_kv_heads",
      "ff_dim",
      "tie"
    ],
    "__call__": [
      "self",
      "x",
      "cache",
      "use_cache"
    ]
  },
  "SharedEmbedding": {
    "__init__": [
      "self",
      "vocab_size",
      "dim",
      "tie_weights"
    ],
    "embed": [
      "self",
      "x"
    ],
    "project": [
      "self",
      "x"
    ]
  },
  "LFMModality": {
    "TEXT": [],
    "AUDIO_IN": [],
    "AUDIO_OUT": []
  },
  "AudioPreprocessor": {
    "__init__": [
      "self",
      "config"
    ],
    "hop_length": [
      "self"
    ],
    "win_length": [
      "self"
    ],
    "__call__": [
      "self",
      "audio"
    ]
  },
  "LFM2AudioProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer",
      "mimi",
      "detokenizer"
    ],
    "tokenizer": [
      "self"
    ],
    "mimi": [
      "self"
    ],
    "detokenizer": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path"
    ],
    "preprocess_audio": [
      "self",
      "audio",
      "sample_rate"
    ],
    "tokenize_audio": [
      "self",
      "audio",
      "sample_rate"
    ],
    "decode_audio": [
      "self",
      "codes",
      "codec"
    ],
    "tokenize_text": [
      "self",
      "text"
    ],
    "format_chat": [
      "self",
      "messages",
      "add_generation_prompt"
    ],
    "tokenize_chat": [
      "self",
      "messages",
      "add_generation_prompt"
    ],
    "decode_text": [
      "self",
      "tokens"
    ],
    "_resample": [
      "self",
      "audio",
      "orig_sr",
      "target_sr"
    ]
  },
  "ChatState": {
    "__init__": [
      "self",
      "processor",
      "add_bos"
    ],
    "new_turn": [
      "self",
      "role"
    ],
    "end_turn": [
      "self"
    ],
    "add_text": [
      "self",
      "text"
    ],
    "add_audio": [
      "self",
      "audio",
      "sample_rate"
    ],
    "append": [
      "self",
      "token",
      "modality"
    ],
    "get_text_tokens": [
      "self"
    ],
    "get_audio_features": [
      "self"
    ],
    "get_modalities": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "items": [
      "self"
    ]
  },
  "PreprocessorConfig": {
    "hop_length": [
      "self"
    ],
    "win_length": [
      "self"
    ]
  },
  "ConformerEncoderConfig": {},
  "DepthformerConfig": {},
  "LFM2AudioConfig": {
    "from_dict": [
      "cls",
      "config_dict"
    ],
    "to_dict": [
      "self"
    ]
  },
  "DetokenizerConfig": {},
  "AUDIO_START_TOKEN": [],
  "IM_END_TOKEN": [],
  "TEXT_END_TOKEN": [],
  "AUDIO_EOS_TOKEN": [],
  "GenerationConfig": {},
  "AudioEmbeddingWithNorm": {
    "__init__": [
      "self",
      "vocab_size",
      "dim"
    ],
    "embed": [
      "self",
      "x"
    ],
    "embed_raw": [
      "self",
      "x"
    ],
    "logits": [
      "self",
      "x"
    ]
  },
  "AudioEmbedding": {
    "__init__": [
      "self",
      "vocab_size",
      "dim",
      "num_codebooks",
      "tie"
    ],
    "__call__": [
      "self",
      "codes"
    ]
  },
  "AudioHead": {
    "__init__": [
      "self",
      "input_dim",
      "depthformer_config",
      "num_codebooks",
      "vocab_size",
      "codebook_weight"
    ],
    "__call__": [
      "self",
      "x",
      "cache",
      "use_cache"
    ]
  },
  "LFM2AudioModel": {
    "__init__": [
      "self",
      "config"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path"
    ],
    "model_quant_predicate": [
      "self",
      "p",
      "m"
    ],
    "sanitize": [
      "weights"
    ],
    "sample_rate": [
      "self"
    ],
    "make_cache": [
      "self"
    ],
    "_embed_text": [
      "self",
      "input_ids"
    ],
    "_embed_audio_in": [
      "self",
      "audio_codes"
    ],
    "_embed_audio_out": [
      "self",
      "audio_codes"
    ],
    "_encode_audio": [
      "self",
      "mel_features",
      "lengths"
    ],
    "_prefill": [
      "self",
      "text_tokens",
      "audio_features",
      "audio_codes",
      "modalities",
      "cache"
    ],
    "_build_interleaved_embeddings": [
      "self",
      "text_tokens",
      "audio_features",
      "audio_codes",
      "modalities"
    ],
    "_sample_text_token": [
      "self",
      "logits",
      "temperature",
      "top_k"
    ],
    "_sample_audio_frame": [
      "self",
      "hidden_state",
      "audio_cache",
      "temperature",
      "top_k"
    ],
    "generate_interleaved": [
      "self",
      "text_tokens",
      "audio_features",
      "audio_codes",
      "modalities",
      "max_new_tokens",
      "temperature",
      "top_k",
      "audio_temperature",
      "audio_top_k",
      "interleaved_n_text",
      "interleaved_n_audio"
    ],
    "generate_sequential": [
      "self",
      "text_tokens",
      "audio_features",
      "audio_codes",
      "modalities",
      "max_new_tokens",
      "temperature",
      "top_k",
      "audio_temperature",
      "audio_top_k"
    ],
    "__call__": [
      "self",
      "text_tokens",
      "audio_features",
      "audio_codes"
    ],
    "generate_from_chat_state": [
      "self",
      "chat_state",
      "mode",
      "max_new_tokens",
      "temperature",
      "top_k",
      "audio_temperature",
      "audio_top_k"
    ]
  },
  "FusedEmbedding": {
    "__init__": [
      "self",
      "num_codebooks",
      "vocab_size",
      "dim"
    ],
    "__call__": [
      "self",
      "codes"
    ]
  },
  "ConvLayer": {
    "__init__": [
      "self",
      "dim"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "SlidingWindowAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "num_kv_heads",
      "sliding_window",
      "rope_theta"
    ],
    "_rope": [
      "self",
      "x",
      "offset"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "DetokenizerBlock": {
    "__init__": [
      "self",
      "dim",
      "hidden_dim",
      "layer_type",
      "num_heads",
      "num_kv_heads",
      "sliding_window",
      "norm_eps",
      "rope_theta"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "LFMDetokenizerModel": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ]
  },
  "LFM2AudioDetokenizer": {
    "__init__": [
      "self",
      "config"
    ],
    "window": [
      "self"
    ],
    "_create_sliding_window_mask": [
      "self",
      "T"
    ],
    "__call__": [
      "self",
      "codes"
    ],
    "_istft": [
      "self",
      "mag",
      "phase"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path"
    ],
    "sanitize": [
      "weights"
    ]
  },
  "pad1d": [
    "x",
    "paddings",
    "mode",
    "value"
  ],
  "_reflect_pad_1d": [
    "x",
    "left",
    "right"
  ],
  "ConvBlock1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "num_groups"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ResnetBlock1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "num_groups"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Patcher": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "patch_size"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "get_nonlinearity": [
    "kind"
  ],
  "ProjectionLayer": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "non_linearity",
      "dropout",
      "fc_bias"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ContextEmbedder": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "non_linearity",
      "dropout",
      "fc_bias",
      "norm_eps",
      "context_norm"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DiTBlock": {
    "__init__": [
      "self",
      "dim",
      "n_heads",
      "n_kv_heads",
      "dropout",
      "norm_eps",
      "qk_norm",
      "fc_bias",
      "ffn_exp",
      "ffn_dim_multiplier",
      "multiple_of",
      "non_linearity",
      "no_cross_attention"
    ],
    "__call__": [
      "self",
      "x",
      "cross_x",
      "t",
      "padding_mask",
      "memory_padding_mask",
      "rope"
    ]
  },
  "DiT": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x",
      "time",
      "padding_mask",
      "memory",
      "memory_padding_mask"
    ]
  },
  "T5Config": {
    "from_hf_config": [
      "cls",
      "hf_config"
    ]
  },
  "T5LayerNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "T5DenseActDense": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "T5DenseGatedActDense": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "T5LayerFF": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "T5Attention": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "_relative_position_bucket": [
      "relative_position",
      "bidirectional",
      "num_buckets",
      "max_distance"
    ],
    "compute_bias": [
      "self",
      "query_length",
      "key_length"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "mask",
      "position_bias"
    ]
  },
  "T5LayerSelfAttention": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias"
    ]
  },
  "T5Block": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias"
    ]
  },
  "T5Stack": {
    "__init__": [
      "self",
      "config"
    ],
    "set_input_embeddings": [
      "self",
      "embeddings"
    ],
    "__call__": [
      "self",
      "input_ids",
      "attention_mask",
      "inputs_embeds"
    ]
  },
  "T5Encoder": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "input_ids",
      "attention_mask"
    ],
    "sanitize": [
      "weights",
      "prefix"
    ],
    "from_pretrained": [
      "cls",
      "model_name"
    ]
  },
  "T5TextEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "_lazy_load": [
      "self"
    ],
    "__call__": [
      "self",
      "texts"
    ]
  },
  "Anchor": [],
  "batch_audio": [
    "audios",
    "audio_sampling_rate"
  ],
  "mask_from_sizes": [
    "sizes"
  ],
  "Batch": {
    "__post_init__": [
      "self"
    ]
  },
  "SAMAudioProcessor": {
    "ANCHOR_DICT": [],
    "__init__": [
      "self",
      "audio_hop_length",
      "audio_sampling_rate"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path"
    ],
    "wav_to_feature_idx": [
      "self",
      "wav_idx"
    ],
    "feature_to_wav_idx": [
      "self",
      "feature_idx"
    ],
    "process_anchors": [
      "self",
      "anchors",
      "audio_pad_mask",
      "batch_size"
    ],
    "__call__": [
      "self",
      "descriptions",
      "audios",
      "anchors"
    ]
  },
  "save_audio": [
    "audio",
    "path",
    "sample_rate"
  ],
  "T5EncoderConfig": {},
  "SAMAudioConfig": {
    "from_dict": [
      "cls",
      "config_dict"
    ]
  },
  "SAM_AUDIO_SMALL_CONFIG": [],
  "SAM_AUDIO_BASE_CONFIG": [],
  "SAM_AUDIO_LARGE_CONFIG": [],
  "_fallback": [
    "value",
    "default"
  ],
  "DFLT_ODE_OPT": [],
  "SinusoidalEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta"
    ],
    "__call__": [
      "self",
      "x",
      "pos"
    ]
  },
  "SeparationResult": {},
  "SAMAudio": {
    "__init__": [
      "self",
      "config"
    ],
    "sample_rate": [
      "self"
    ],
    "_prepare_inputs": [
      "self",
      "audios",
      "descriptions",
      "anchors"
    ],
    "post_load_hook": [
      "self",
      "model_path"
    ],
    "sanitize": [
      "weights"
    ],
    "align_inputs": [
      "self",
      "noisy_audio",
      "audio_features",
      "anchor_ids",
      "anchor_alignment"
    ],
    "__call__": [
      "self",
      "noisy_audio",
      "audio_features",
      "text_features",
      "time",
      "text_mask",
      "anchor_ids",
      "anchor_alignment",
      "audio_pad_mask"
    ],
    "_get_audio_features": [
      "self",
      "audios"
    ],
    "_ode_step_euler": [
      "self",
      "t",
      "dt",
      "noisy_audio",
      "audio_features",
      "text_features",
      "text_mask",
      "anchor_ids",
      "anchor_alignment",
      "audio_pad_mask"
    ],
    "_ode_step_midpoint": [
      "self",
      "t",
      "dt",
      "noisy_audio",
      "audio_features",
      "text_features",
      "text_mask",
      "anchor_ids",
      "anchor_alignment",
      "audio_pad_mask"
    ],
    "separate": [
      "self",
      "audios",
      "descriptions",
      "sizes",
      "anchors",
      "anchor_ids",
      "anchor_alignment",
      "audio_pad_mask",
      "noise",
      "ode_opt",
      "ode_decode_chunk_size",
      "_text_features",
      "_text_mask"
    ],
    "separate_long": [
      "self",
      "audios",
      "descriptions",
      "chunk_seconds",
      "overlap_seconds",
      "anchor_ids",
      "anchor_alignment",
      "ode_opt",
      "ode_decode_chunk_size",
      "seed",
      "verbose"
    ],
    "separate_streaming": [
      "self",
      "audios",
      "descriptions",
      "target_callback",
      "residual_callback",
      "chunk_seconds",
      "overlap_seconds",
      "anchor_ids",
      "anchor_alignment",
      "ode_opt",
      "seed",
      "verbose"
    ],
    "_separate_streaming_generator": [
      "self",
      "audios",
      "descriptions",
      "chunk_seconds",
      "overlap_seconds",
      "anchor_ids",
      "anchor_alignment",
      "ode_opt",
      "seed",
      "verbose"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path"
    ]
  },
  "_load_weights": [
    "model",
    "weights",
    "strict"
  ],
  "_convert_weight_name": [
    "name"
  ],
  "_map_residual_unit": [
    "name",
    "prefix"
  ],
  "_map_decoder_residual_unit": [
    "name",
    "prefix"
  ],
  "AlignModalities": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "normalize",
      "with_gate"
    ],
    "__call__": [
      "self",
      "anchor",
      "tgt"
    ]
  },
  "EmbedAnchors": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "out_dim"
    ],
    "__call__": [
      "self",
      "x",
      "anchor_ids",
      "anchor_alignment"
    ]
  },
  "MossFormerBlock_GFSMN": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "x",
      "mask"
    ],
    "eval": [
      "self"
    ],
    "train": [
      "self"
    ]
  },
  "OffsetScale": {
    "__init__": [
      "self",
      "dim",
      "heads"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ConvModule": {
    "__init__": [
      "self",
      "in_channels",
      "kernel_size",
      "expansion_factor",
      "dropout_p"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "MossFormerBlock": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "_depthwise_conv1d_kernel": [],
  "depthwise_conv1d": [
    "x",
    "weight"
  ],
  "GlobalLayerNorm": {
    "__init__": [
      "self",
      "dim",
      "shape",
      "eps",
      "elementwise_affine"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "relu_squared_kernel": [],
  "fused_multiply_add": [],
  "qk_relu_squared": [],
  "FlashAttentionImplementations": {
    "standard": [
      "q",
      "k",
      "v",
      "group_size"
    ],
    "simple_kernel": [
      "q",
      "k",
      "v",
      "group_size"
    ],
    "optimized_ops": [
      "q",
      "k",
      "v",
      "group_size"
    ],
    "fused_kernel": [
      "q",
      "k",
      "v",
      "group_size"
    ]
  },
  "TestNet": {
    "__init__": [
      "self",
      "n_layers"
    ],
    "_forward": [
      "self",
      "input"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "MossFormer2SE": {
    "__init__": [
      "self",
      "args"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "UniDeepFsmn": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "lorder",
      "hidden_size"
    ],
    "__call__": [
      "self",
      "input_tensor"
    ]
  },
  "MossFormer2SEConfig": {
    "from_dict": [
      "cls",
      "config_dict"
    ],
    "to_dict": [
      "self"
    ],
    "sampling_rate": [
      "self"
    ]
  },
  "FLASH_ShareA_FFConvM": {
    "__init__": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "train": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "cal_attention": [
      "self",
      "x",
      "quad_q",
      "lin_q",
      "quad_k",
      "lin_k",
      "v",
      "u",
      "mask"
    ]
  },
  "MAX_WAV_VALUE": [],
  "DEFAULT_REPO": [],
  "MossFormer2SEModel": {
    "__init__": [
      "self",
      "model",
      "config"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path"
    ],
    "warmup": [
      "self",
      "chunked"
    ],
    "enhance": [
      "self",
      "audio_input",
      "chunked"
    ],
    "_decode_one_audio": [
      "self",
      "inputs"
    ],
    "_decode_chunked": [
      "self",
      "inputs"
    ],
    "_process_chunk": [
      "self",
      "audio_segment",
      "window",
      "chunk_length"
    ]
  },
  "ScaleNorm": {
    "__init__": [
      "self",
      "dim",
      "eps"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "FFConvM": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "norm_klass",
      "dropout"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "eval": [
      "self"
    ],
    "train": [
      "self"
    ]
  },
  "CLayerNorm": {
    "__init__": [
      "self",
      "normalized_shape",
      "eps",
      "elementwise_affine"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Gated_FSMN_Block": {
    "__init__": [
      "self",
      "dim",
      "inner_channels",
      "group_size",
      "norm_type"
    ],
    "eval": [
      "self"
    ],
    "train": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Computation_Block": {
    "__init__": [
      "self",
      "num_blocks",
      "out_channels",
      "norm",
      "skip_around_intra",
      "use_mossformer2"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "eval": [
      "self"
    ],
    "train": [
      "self"
    ]
  },
  "MossFormer_MaskNet": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "out_channels_final",
      "num_blocks",
      "norm",
      "num_spks",
      "skip_around_intra",
      "use_global_pos_enc",
      "max_length"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "eval": [
      "self"
    ],
    "train": [
      "self"
    ]
  },
  "MossFormerM2": {
    "__init__": [
      "self",
      "num_blocks",
      "d_model",
      "causal",
      "group_size",
      "query_key_dim",
      "expansion_factor",
      "attn_dropout"
    ],
    "__call__": [
      "self",
      "src"
    ]
  },
  "Gated_FSMN": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "lorder",
      "hidden_size"
    ],
    "eval": [
      "self"
    ],
    "train": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ScaledSinuEmbedding": {
    "__init__": [
      "self",
      "dim",
      "use_cache",
      "max_cache_size"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "clear_cache": [
      "self"
    ]
  },
  "MossFormerM": {
    "__init__": [
      "self",
      "num_blocks",
      "d_model",
      "causal",
      "group_size",
      "query_key_dim",
      "expansion_factor",
      "attn_dropout"
    ],
    "__call__": [
      "self",
      "src"
    ],
    "eval": [
      "self"
    ],
    "train": [
      "self"
    ]
  }
}