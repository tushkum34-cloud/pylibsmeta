{
  "__version__": [],
  "BaseModel": {
    "__init__": [
      "self",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_setup_device": [
      "self",
      "device"
    ],
    "_setup_path": [
      "self",
      "saving_path"
    ],
    "_send_model_to_given_device": [
      "self"
    ],
    "_send_data_to_given_device": [
      "self",
      "data"
    ],
    "_save_log_into_tb_file": [
      "self",
      "step",
      "stage",
      "loss_dict"
    ],
    "_auto_save_model_if_necessary": [
      "self",
      "confirm_saving",
      "saving_name"
    ],
    "_organize_content_to_save": [
      "self"
    ],
    "save": [
      "self",
      "saving_path",
      "overwrite"
    ],
    "load": [
      "self",
      "path"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "to": [
      "self",
      "device"
    ]
  },
  "BaseNNModel": {
    "__init__": [
      "self",
      "training_loss",
      "validation_metric",
      "batch_size",
      "epochs",
      "patience",
      "num_workers",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_print_model_size": [
      "self"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "_train_model": [
      "self",
      "train_dataloader",
      "val_dataloader"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "__all__": [],
  "BaseDetector": {
    "__init__": [
      "self",
      "anomaly_rate",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "detect": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "BaseNNDetector": {
    "__init__": [
      "self",
      "anomaly_rate",
      "training_loss",
      "validation_metric",
      "batch_size",
      "epochs",
      "patience",
      "num_workers",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "detect": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "FEDformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "moving_avg_window_size",
      "dropout",
      "version",
      "modes",
      "mode_select",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "Pyraformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "window_size",
      "inner_size",
      "dropout",
      "attn_dropout",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "TEFN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_fod",
      "apply_nonstationary_norm",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "Autoformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "factor",
      "moving_avg_window_size",
      "dropout",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "TimeMixerPP": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "d_model",
      "d_ffn",
      "top_k",
      "n_heads",
      "n_kernels",
      "dropout",
      "channel_mixing",
      "channel_independence",
      "downsampling_layers",
      "downsampling_window",
      "apply_nonstationary_norm",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "iTransformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout",
      "attn_dropout",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose",
      "ORT_weight",
      "MIT_weight"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "Reformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "d_model",
      "n_heads",
      "bucket_size",
      "n_hashes",
      "causal",
      "d_ffn",
      "dropout",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "SAITS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout",
      "attn_dropout",
      "diagonal_attention_mask",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "ETSformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_encoder_layers",
      "n_decoder_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "top_k",
      "dropout",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "SegRNN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "seg_len",
      "d_model",
      "dropout",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "SCINet": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_stacks",
      "n_levels",
      "n_groups",
      "n_decoder_layers",
      "d_hidden",
      "kernel_size",
      "concat_len",
      "dropout",
      "pos_enc",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "TimeMixer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "d_model",
      "d_ffn",
      "top_k",
      "dropout",
      "channel_independence",
      "decomp_method",
      "moving_avg",
      "downsampling_layers",
      "downsampling_window",
      "apply_nonstationary_norm",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "DLinear": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "moving_avg_window_size",
      "individual",
      "d_model",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "TimesNet": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "top_k",
      "d_model",
      "d_ffn",
      "n_kernels",
      "dropout",
      "apply_nonstationary_norm",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "FiLM": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "window_size",
      "multiscale",
      "modes1",
      "dropout",
      "mode_type",
      "d_model",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "Informer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "factor",
      "dropout",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "Crossformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "factor",
      "seg_len",
      "win_size",
      "dropout",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "NonstationaryTransformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "d_projector_hidden",
      "n_projector_hidden_layers",
      "dropout",
      "attn_dropout",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "Transformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout",
      "attn_dropout",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "PatchTST": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "patch_size",
      "patch_stride",
      "n_layers",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout",
      "attn_dropout",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "ImputeFormer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "anomaly_rate",
      "n_layers",
      "d_input_embed",
      "d_learnable_embed",
      "d_proj",
      "d_ffn",
      "n_temporal_heads",
      "dropout",
      "input_dim",
      "output_dim",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "IMPORT_ERROR_MESSAGE": [],
  "dev_command_factory": [
    "args"
  ],
  "DevCommand": {
    "register_subcommand": [
      "parser"
    ],
    "__init__": [
      "self",
      "build",
      "cleanup",
      "run_tests",
      "k",
      "show_coverage",
      "lint_code"
    ],
    "checkup": [
      "self"
    ],
    "run": [
      "self"
    ]
  },
  "BaseCommand": {
    "register_subcommand": [
      "parser"
    ],
    "execute_command": [
      "command",
      "verbose"
    ],
    "check_if_under_root_dir": [
      "strict"
    ],
    "checkup": [
      "self"
    ],
    "run": [
      "self"
    ]
  },
  "load_package_from_path": [
    "pkg_path"
  ],
  "NN_MODELS": [],
  "env_command_factory": [
    "args"
  ],
  "HPOCommand": {
    "register_subcommand": [
      "parser"
    ],
    "__init__": [
      "self",
      "model",
      "model_package_path",
      "train_set",
      "val_set",
      "lazy_load",
      "torch_n_threads"
    ],
    "checkup": [
      "self"
    ],
    "run": [
      "self"
    ]
  },
  "EnvCommand": {
    "register_subcommand": [
      "parser"
    ],
    "__init__": [
      "self",
      "install",
      "tool"
    ],
    "checkup": [
      "self"
    ],
    "run": [
      "self"
    ]
  },
  "main": [],
  "CLONED_LATEST_PYPOTS": [],
  "DOC_RST_FILES": [],
  "doc_command_factory": [
    "args"
  ],
  "purge_temp_files": [],
  "DocCommand": {
    "register_subcommand": [
      "parser"
    ],
    "__init__": [
      "self",
      "gene_rst",
      "branch",
      "gene_html",
      "view_doc",
      "port",
      "cleanup"
    ],
    "checkup": [
      "self"
    ],
    "run": [
      "self"
    ]
  },
  "BaseRepresentor": {
    "__init__": [
      "self",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "represent": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "BaseNNRepresentor": {
    "__init__": [
      "self",
      "training_loss",
      "validation_metric",
      "batch_size",
      "epochs",
      "patience",
      "num_workers",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "represent": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "_TS2Vec": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_features",
      "d_hidden",
      "n_layers",
      "mask_mode",
      "temporal_unit"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion",
      "mask",
      "encoding_window",
      "causal",
      "sliding_length",
      "sliding_padding"
    ]
  },
  "TS2Vec": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_output_dims",
      "d_hidden",
      "n_layers",
      "mask_mode",
      "batch_size",
      "epochs",
      "patience",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type",
      "mask",
      "encoding_window",
      "causal",
      "sliding_length",
      "sliding_padding"
    ],
    "represent": [
      "self",
      "test_set",
      "file_type",
      "mask",
      "encoding_window",
      "causal",
      "sliding_length",
      "sliding_padding"
    ]
  },
  "_check_inputs": [
    "predictions",
    "targets",
    "masks",
    "check_shape"
  ],
  "calc_mae": [
    "predictions",
    "targets",
    "masks"
  ],
  "calc_mse": [
    "predictions",
    "targets",
    "masks"
  ],
  "calc_rmse": [
    "predictions",
    "targets",
    "masks"
  ],
  "calc_mre": [
    "predictions",
    "targets",
    "masks"
  ],
  "calc_quantile_loss": [
    "predictions",
    "targets",
    "q",
    "eval_points"
  ],
  "calc_quantile_crps": [
    "predictions",
    "targets",
    "masks",
    "scaler_mean",
    "scaler_stddev"
  ],
  "calc_quantile_crps_sum": [
    "predictions",
    "targets",
    "masks",
    "scaler_mean",
    "scaler_stddev"
  ],
  "nonstationary_norm": [
    "X",
    "missing_mask"
  ],
  "nonstationary_denorm": [
    "X",
    "means",
    "stdev"
  ],
  "calc_binary_classification_metrics": [
    "prob_predictions",
    "targets",
    "pos_label"
  ],
  "calc_precision_recall_f1": [
    "prob_predictions",
    "targets",
    "pos_label"
  ],
  "calc_pr_auc": [
    "prob_predictions",
    "targets",
    "pos_label"
  ],
  "calc_roc_auc": [
    "prob_predictions",
    "targets",
    "pos_label"
  ],
  "calc_acc": [
    "class_predictions",
    "targets"
  ],
  "gather_listed_dicts": [
    "dict_list"
  ],
  "calc_rand_index": [
    "class_predictions",
    "targets"
  ],
  "calc_adjusted_rand_index": [
    "class_predictions",
    "targets"
  ],
  "calc_nmi": [
    "class_predictions",
    "targets"
  ],
  "calc_cluster_purity": [
    "class_predictions",
    "targets"
  ],
  "calc_external_cluster_validation_metrics": [
    "class_predictions",
    "targets"
  ],
  "calc_silhouette": [
    "X",
    "predicted_labels"
  ],
  "calc_chs": [
    "X",
    "predicted_labels"
  ],
  "calc_dbs": [
    "X",
    "predicted_labels"
  ],
  "calc_internal_cluster_validation_metrics": [
    "X",
    "predicted_labels"
  ],
  "autocast": [],
  "Criterion": {
    "__init__": [
      "self",
      "lower_better"
    ],
    "forward": [
      "self",
      "logits",
      "targets"
    ]
  },
  "MSE": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "logits",
      "targets",
      "masks"
    ]
  },
  "MAE": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "logits",
      "targets",
      "masks"
    ]
  },
  "RMSE": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "logits",
      "targets",
      "masks"
    ]
  },
  "MRE": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "logits",
      "targets",
      "masks"
    ]
  },
  "CrossEntropy": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "logits",
      "targets"
    ]
  },
  "NLL": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "log_probs",
      "targets"
    ]
  },
  "ModelCore": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "PR_AUC": {
    "__init__": [
      "self",
      "pos_label"
    ],
    "forward": [
      "self",
      "logits",
      "targets"
    ]
  },
  "ROC_AUC": {
    "__init__": [
      "self",
      "pos_label"
    ],
    "forward": [
      "self",
      "logits",
      "targets"
    ]
  },
  "Accuracy": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "logits",
      "targets"
    ]
  },
  "Chomp1d": {
    "__init__": [
      "self",
      "chomp_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TemporalBlock": {
    "__init__": [
      "self",
      "n_inputs",
      "n_outputs",
      "kernel_size",
      "stride",
      "dilation",
      "padding",
      "dropout"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BackboneTCN": {
    "__init__": [
      "self",
      "num_inputs",
      "num_channels",
      "kernel_size",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BackboneGPT4TS": {
    "__init__": [
      "self",
      "task_name",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "n_layers",
      "patch_size",
      "patch_stride",
      "train_gpt_mlp",
      "d_ffn",
      "dropout",
      "embed",
      "freq",
      "n_classes"
    ],
    "imputation": [
      "self",
      "x_enc",
      "x_mark_enc",
      "mask"
    ],
    "forecast": [
      "self",
      "x_enc",
      "x_mark_enc"
    ],
    "anomaly_detection": [
      "self",
      "x_enc"
    ],
    "classification": [
      "self",
      "x_enc"
    ],
    "forward": [
      "self",
      "x_enc",
      "x_mark_enc",
      "mask"
    ]
  },
  "legendreDer": [
    "k",
    "x"
  ],
  "phi_": [
    "phi_c",
    "x",
    "lb",
    "ub"
  ],
  "get_phi_psi": [
    "k",
    "base"
  ],
  "get_filter": [
    "base",
    "k"
  ],
  "sparseKernelFT1d": {
    "__init__": [
      "self",
      "k",
      "alpha",
      "c",
      "nl",
      "initializer"
    ],
    "compl_mul1d": [
      "self",
      "order",
      "x",
      "weights"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MWT_CZ1d": {
    "__init__": [
      "self",
      "k",
      "alpha",
      "L",
      "c",
      "base",
      "initializer"
    ],
    "forward": [
      "self",
      "x"
    ],
    "wavelet_transform": [
      "self",
      "x"
    ],
    "evenOdd": [
      "self",
      "x"
    ]
  },
  "MultiWaveletTransform": {
    "__init__": [
      "self",
      "ich",
      "k",
      "alpha",
      "c",
      "nCZ",
      "L",
      "base",
      "attention_dropout"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "attn_mask"
    ]
  },
  "FourierCrossAttentionW": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "seq_len_q",
      "seq_len_kv",
      "modes",
      "activation",
      "mode_select_method"
    ],
    "compl_mul1d": [
      "self",
      "order",
      "x",
      "weights"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "mask"
    ]
  },
  "MultiWaveletCross": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "seq_len_q",
      "seq_len_kv",
      "modes",
      "c",
      "k",
      "ich",
      "L",
      "base",
      "mode_select_method",
      "initializer",
      "activation"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "attn_mask"
    ],
    "wavelet_transform": [
      "self",
      "x"
    ],
    "evenOdd": [
      "self",
      "x"
    ]
  },
  "get_frequency_modes": [
    "seq_len",
    "modes",
    "mode_select_method"
  ],
  "FourierBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "seq_len",
      "modes",
      "mode_select_method"
    ],
    "compl_mul1d": [
      "self",
      "input",
      "weights"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "attn_mask"
    ]
  },
  "FourierCrossAttention": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "seq_len_q",
      "seq_len_kv",
      "modes",
      "mode_select_method",
      "activation",
      "policy",
      "num_heads"
    ],
    "compl_mul1d": [
      "self",
      "order",
      "x",
      "weights"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "attn_mask"
    ]
  },
  "SeriesDecompositionMultiBlock": {
    "__init__": [
      "self",
      "kernel_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FEDformerEncoder": {
    "__init__": [
      "self",
      "n_steps",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "moving_avg_window_size",
      "dropout",
      "version",
      "modes",
      "mode_select",
      "activation"
    ],
    "forward": [
      "self",
      "X",
      "attn_mask"
    ]
  },
  "FEDformerDecoder": {
    "__init__": [
      "self",
      "n_steps",
      "n_pred_steps",
      "n_layers",
      "n_heads",
      "d_model",
      "d_ffn",
      "d_output",
      "moving_avg_window_size",
      "dropout",
      "version",
      "modes",
      "mode_select",
      "activation"
    ],
    "forward": [
      "self",
      "X",
      "attn_mask"
    ]
  },
  "get_mask": [
    "input_size",
    "window_size",
    "inner_size"
  ],
  "refer_points": [
    "all_sizes",
    "window_size"
  ],
  "ConvLayer": {
    "__init__": [
      "self",
      "c_in",
      "window_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Bottleneck_Construct": {
    "__init__": [
      "self",
      "d_model",
      "window_size",
      "d_inner"
    ],
    "forward": [
      "self",
      "enc_input"
    ]
  },
  "PyraformerEncoder": {
    "__init__": [
      "self",
      "n_steps",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "dropout",
      "attn_dropout",
      "window_size",
      "inner_size"
    ],
    "forward": [
      "self",
      "x",
      "src_mask"
    ]
  },
  "FourierFilter": {
    "__init__": [
      "self",
      "mask_spectrum"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MLP": {
    "__init__": [
      "self",
      "d_in",
      "d_out",
      "d_hidden",
      "n_hidden_layers",
      "dropout",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "KPLayer": {
    "__init__": [
      "self"
    ],
    "one_step_forward": [
      "self",
      "z",
      "return_rec",
      "return_K"
    ],
    "forward": [
      "self",
      "z",
      "pred_len"
    ]
  },
  "KPLayerApprox": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "z",
      "pred_len"
    ]
  },
  "TimeVarKP": {
    "__init__": [
      "self",
      "enc_in",
      "input_len",
      "pred_len",
      "seg_len",
      "dynamic_dim",
      "encoder",
      "decoder",
      "multistep"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TimeInvKP": {
    "__init__": [
      "self",
      "input_len",
      "pred_len",
      "dynamic_dim",
      "encoder",
      "decoder"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BackboneKoopa": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_seg_steps",
      "d_dynamic",
      "d_hidden",
      "n_hidden_layers",
      "n_blocks",
      "multistep",
      "alpha"
    ],
    "_get_mask_spectrum": [
      "self",
      "train_dataloader"
    ],
    "init_mask_spectrum": [
      "self",
      "train_dataloader"
    ],
    "forward": [
      "self",
      "X"
    ]
  },
  "EvidenceMachineKernel": {
    "__init__": [
      "self",
      "C",
      "F"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BackboneTEFN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_fod"
    ],
    "forward": [
      "self",
      "X"
    ]
  },
  "AutoCorrelation": {
    "__init__": [
      "self",
      "factor",
      "attention_dropout"
    ],
    "time_delay_agg_training": [
      "self",
      "values",
      "corr"
    ],
    "time_delay_agg_inference": [
      "self",
      "values",
      "corr"
    ],
    "time_delay_agg_full": [
      "self",
      "values",
      "corr"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "attn_mask"
    ]
  },
  "SeasonalLayerNorm": {
    "__init__": [
      "self",
      "n_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MovingAvgBlock": {
    "__init__": [
      "self",
      "kernel_size",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SeriesDecompositionBlock": {
    "__init__": [
      "self",
      "kernel_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AutoformerEncoderLayer": {
    "__init__": [
      "self",
      "attn_opt",
      "d_model",
      "n_heads",
      "d_ffn",
      "moving_avg",
      "dropout",
      "activation"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask"
    ]
  },
  "AutoformerDecoderLayer": {
    "__init__": [
      "self",
      "self_attn_opt",
      "cross_attn_opt",
      "d_model",
      "n_heads",
      "d_out",
      "d_ff",
      "moving_avg",
      "dropout",
      "activation"
    ],
    "forward": [
      "self",
      "x",
      "cross",
      "x_mask",
      "cross_mask"
    ]
  },
  "AutoformerEncoder": {
    "__init__": [
      "self",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "factor",
      "moving_avg_window_size",
      "dropout",
      "activation"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask"
    ]
  },
  "MrnnFcnRegression": {
    "__init__": [
      "self",
      "feature_num"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "missing_mask",
      "target"
    ]
  },
  "BackboneMRNN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size"
    ],
    "gene_hidden_states": [
      "self",
      "inputs",
      "feature_idx"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "RevIN": {
    "__init__": [
      "self",
      "n_features",
      "eps",
      "affine"
    ],
    "forward": [
      "self",
      "x",
      "missing_mask",
      "mode"
    ],
    "_init_params": [
      "self"
    ],
    "_normalize": [
      "self",
      "x",
      "missing_mask"
    ],
    "_denormalize": [
      "self",
      "x"
    ]
  },
  "Masking": {
    "__init__": [
      "self",
      "mask_ratio",
      "patch_size",
      "stride"
    ],
    "convert_seq_to_patch_view": [
      "mask",
      "patch_size",
      "stride"
    ],
    "convert_patch_to_seq_view": [
      "mask",
      "patch_size"
    ],
    "generate_mask": [
      "self",
      "x",
      "input_mask"
    ],
    "_mask_patch_view": [
      "self",
      "x",
      "input_mask"
    ],
    "_mask_seq_view": [
      "self",
      "x",
      "input_mask"
    ]
  },
  "SUPPORTED_HUGGINGFACE_MODELS": [],
  "TUNING_MODE": [],
  "TRANSFORMER_TYPE": [],
  "BackboneMOMENT": {
    "__init__": [
      "self",
      "configs"
    ],
    "_update_inputs": [
      "self",
      "configs"
    ],
    "_validate_inputs": [
      "self",
      "configs"
    ],
    "_get_head": [
      "self",
      "task_name"
    ],
    "_get_transformer_backbone": [
      "self",
      "configs"
    ],
    "_get_huggingface_transformer": [
      "self",
      "configs"
    ],
    "_get_patchtst_encoder": [
      "self",
      "configs"
    ],
    "embed": [
      "self",
      "x_enc",
      "input_mask",
      "reduction"
    ],
    "pretraining": [
      "self",
      "x_enc",
      "input_mask",
      "mask"
    ],
    "initialize_soft_prompt": [
      "self"
    ],
    "_cat_learned_embedding_to_input": [
      "self",
      "prompt_embeds",
      "enc_in"
    ],
    "_extend_attention_mask": [
      "self",
      "attention_mask",
      "n_tokens"
    ],
    "reconstruct": [
      "self",
      "x_enc",
      "input_mask",
      "mask"
    ],
    "detect_anomalies": [
      "self",
      "x_enc",
      "input_mask",
      "anomaly_criterion"
    ],
    "long_forecast": [
      "self",
      "x_enc",
      "input_mask"
    ],
    "short_forecast": [
      "self",
      "x_enc",
      "input_mask",
      "forecast_horizon"
    ],
    "forward": [
      "self",
      "x_enc",
      "mask",
      "input_mask"
    ],
    "_check_model_weights_for_illegal_values": [
      "self"
    ]
  },
  "TASKS": {},
  "TimeseriesOutputs": {},
  "NamespaceWithDefaults": {
    "from_namespace": [
      "cls",
      "namespace"
    ],
    "getattr": [
      "self",
      "key",
      "default"
    ]
  },
  "get_anomaly_criterion": [
    "anomaly_criterion"
  ],
  "get_huggingface_model_dimensions": [
    "model_name"
  ],
  "nanvar": [
    "tensor",
    "dim",
    "keepdim"
  ],
  "nanstd": [
    "tensor",
    "dim",
    "keepdim"
  ],
  "Patching": {
    "__init__": [
      "self",
      "patch_size",
      "patch_stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PatchEmbedding": {
    "__init__": [
      "self",
      "d_model",
      "seq_len",
      "patch_size",
      "patch_stride",
      "dropout",
      "add_positional_embedding",
      "value_embedding_bias",
      "orth_gain"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "PretrainHead": {
    "__init__": [
      "self",
      "d_model",
      "patch_size",
      "head_dropout",
      "orth_gain"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ClassificationHead": {
    "__init__": [
      "self",
      "n_channels",
      "d_model",
      "n_classes",
      "head_dropout"
    ],
    "forward": [
      "self",
      "x",
      "input_mask"
    ]
  },
  "ForecastingHead": {
    "__init__": [
      "self",
      "head_nf",
      "forecast_horizon",
      "head_dropout"
    ],
    "forward": [
      "self",
      "x",
      "input_mask"
    ]
  },
  "FeatureRegression": {
    "__init__": [
      "self",
      "input_size"
    ],
    "_reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BackboneRITS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size",
      "training_loss"
    ],
    "forward": [
      "self",
      "inputs",
      "direction"
    ]
  },
  "BackboneBRITS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size",
      "training_loss"
    ],
    "_get_consistency_loss": [
      "pred_f",
      "pred_b"
    ],
    "_reverse": [
      "ret"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "FFT_for_Period": [
    "x",
    "k"
  ],
  "RowAttention": {
    "__init__": [
      "self",
      "in_dim",
      "q_k_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ColAttention": {
    "__init__": [
      "self",
      "in_dim",
      "q_k_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MultiScaleSeasonCross": {
    "__init__": [
      "self",
      "d_model",
      "d_ff",
      "num_kernels",
      "downsampling_window"
    ],
    "forward": [
      "self",
      "season_list"
    ]
  },
  "MultiScaleTrendCross": {
    "__init__": [
      "self",
      "d_model",
      "d_ff",
      "num_kernels",
      "downsampling_window"
    ],
    "forward": [
      "self",
      "trend_list"
    ]
  },
  "MixerBlock": {
    "__init__": [
      "self",
      "seq_len",
      "pred_len",
      "top_k",
      "d_model",
      "d_ff",
      "num_kernels",
      "downsampling_window"
    ],
    "forward": [
      "self",
      "x_list"
    ],
    "time_imaging": [
      "self",
      "x",
      "period"
    ],
    "dual_axis_attn": [
      "self",
      "out"
    ],
    "multi_scale_mixing": [
      "self",
      "season_list",
      "trend_list",
      "length_list"
    ],
    "__conv_padding": [
      "x",
      "period",
      "downsampling_window"
    ],
    "multi_reso_mixing": [
      "period_weight",
      "x",
      "res"
    ]
  },
  "BackboneTimeMixerPP": {
    "__init__": [
      "self",
      "task_name",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "n_layers",
      "d_model",
      "d_ffn",
      "n_heads",
      "dropout",
      "top_k",
      "n_kernels",
      "channel_mixing",
      "channel_independence",
      "downsampling_layers",
      "downsampling_window",
      "downsampling_method",
      "use_future_temporal_feature",
      "use_norm",
      "embed",
      "freq",
      "n_classes"
    ],
    "__multi_scale_process_inputs": [
      "self",
      "x_enc",
      "x_mark_enc"
    ],
    "forecast": [
      "self",
      "x_enc",
      "x_mark_enc",
      "x_dec",
      "x_mark_dec"
    ],
    "classification": [
      "self",
      "x_enc",
      "x_mark_enc"
    ],
    "anomaly_detection": [
      "self",
      "x_enc"
    ],
    "imputation": [
      "self",
      "x_enc",
      "x_mark_enc"
    ]
  },
  "TOKEN_SELF_ATTN_VALUE": [],
  "exists": [
    "val"
  ],
  "rotate_half": [
    "x"
  ],
  "apply_rotary_pos_emb": [
    "q",
    "k",
    "freqs",
    "scale"
  ],
  "default": [
    "value",
    "d"
  ],
  "to": [
    "t"
  ],
  "max_neg_value": [
    "tensor"
  ],
  "l2norm": [
    "tensor"
  ],
  "pad_to_multiple": [
    "tensor",
    "multiple",
    "dim",
    "value"
  ],
  "look_around": [
    "x",
    "backward",
    "forward",
    "pad_value",
    "dim"
  ],
  "SinusoidalEmbeddings": {
    "__init__": [
      "self",
      "dim",
      "scale_base",
      "use_xpos"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LocalAttention": {
    "__init__": [
      "self",
      "window_size",
      "causal",
      "look_backward",
      "look_forward",
      "dropout",
      "shared_qk",
      "rel_pos_emb_config",
      "dim",
      "autopad",
      "exact_windowsize",
      "scale",
      "use_rotary_pos_emb",
      "use_xpos",
      "xpos_scale_base"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "mask",
      "input_mask",
      "attn_bias",
      "window_size"
    ]
  },
  "rotate_every_two": [
    "x"
  ],
  "sort_key_val": [
    "t1",
    "t2",
    "dim"
  ],
  "batched_index_select": [
    "values",
    "indices"
  ],
  "process_inputs_chunk": [
    "fn",
    "chunks",
    "dim"
  ],
  "chunked_sum": [
    "tensor",
    "chunks"
  ],
  "cast_tuple": [
    "x"
  ],
  "cache_fn": [
    "f"
  ],
  "cache_method_decorator": [
    "cache_attr",
    "cache_namespace",
    "reexecute"
  ],
  "expand_dim": [
    "dim",
    "k",
    "t"
  ],
  "merge_dims": [
    "ind_from",
    "ind_to",
    "tensor"
  ],
  "split_at_index": [
    "dim",
    "index",
    "t"
  ],
  "FullQKAttention": {
    "__init__": [
      "self",
      "causal",
      "dropout"
    ],
    "forward": [
      "self",
      "qk",
      "v",
      "query_len",
      "input_mask",
      "input_attn_mask"
    ]
  },
  "LSHAttention": {
    "__init__": [
      "self",
      "dropout",
      "bucket_size",
      "n_hashes",
      "causal",
      "allow_duplicate_attention",
      "attend_across_buckets",
      "rehash_each_round",
      "drop_for_hash_rate",
      "random_rotations_per_head",
      "return_attn"
    ],
    "hash_vectors": [
      "self",
      "n_buckets",
      "vecs"
    ],
    "forward": [
      "self",
      "qk",
      "v",
      "query_len",
      "input_mask",
      "input_attn_mask",
      "pos_emb"
    ]
  },
  "LSHSelfAttention": {
    "__init__": [
      "self",
      "dim",
      "heads",
      "bucket_size",
      "n_hashes",
      "causal",
      "dim_head",
      "attn_chunks",
      "random_rotations_per_head",
      "attend_across_buckets",
      "allow_duplicate_attention",
      "num_mem_kv",
      "one_value_head",
      "use_full_attn",
      "full_attn_thres",
      "return_attn",
      "post_attn_dropout",
      "dropout",
      "n_local_attn_heads"
    ],
    "forward": [
      "self",
      "x",
      "keys",
      "input_mask",
      "input_attn_mask",
      "context_mask",
      "pos_emb"
    ]
  },
  "ReformerLayer": {
    "__init__": [
      "self",
      "d_model",
      "n_heads",
      "bucket_size",
      "n_hashes",
      "causal",
      "d_ffn",
      "dropout"
    ],
    "forward": [
      "self",
      "enc_input"
    ]
  },
  "ReformerEncoder": {
    "__init__": [
      "self",
      "n_steps",
      "n_layers",
      "d_model",
      "n_heads",
      "bucket_size",
      "n_hashes",
      "causal",
      "d_ffn",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SaitsLoss": {
    "__init__": [
      "self",
      "ORT_weight",
      "MIT_weight",
      "loss_calc_func"
    ],
    "forward": [
      "self",
      "reconstruction",
      "X_ori",
      "missing_mask",
      "indicating_mask"
    ]
  },
  "SaitsEmbedding": {
    "__init__": [
      "self",
      "d_in",
      "d_out",
      "with_pos",
      "n_max_steps",
      "dropout"
    ],
    "forward": [
      "self",
      "X",
      "missing_mask"
    ]
  },
  "BackboneSAITS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout",
      "attn_dropout"
    ],
    "forward": [
      "self",
      "X",
      "missing_mask",
      "attn_mask"
    ]
  },
  "ImplicitImputation": {
    "__init__": [
      "self",
      "d_input"
    ],
    "forward": [
      "self",
      "X",
      "missing_mask"
    ]
  },
  "PeepholeLSTMCell": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "bias"
    ],
    "forward": [
      "self",
      "X",
      "hx"
    ]
  },
  "GMMLayer": {
    "__init__": [
      "self",
      "d_hidden",
      "n_clusters"
    ],
    "set_values": [
      "self",
      "mu",
      "var",
      "phi"
    ],
    "forward": [
      "self"
    ]
  },
  "BackboneVaDER": {
    "__init__": [
      "self",
      "n_steps",
      "d_input",
      "n_clusters",
      "d_rnn_hidden",
      "d_mu_stddev",
      "eps",
      "alpha"
    ],
    "z_sampling": [
      "mu_tilde",
      "stddev_tilde"
    ],
    "encode": [
      "self",
      "X",
      "missing_mask"
    ],
    "decode": [
      "self",
      "z"
    ],
    "forward": [
      "self",
      "X",
      "missing_mask"
    ]
  },
  "Transform": {
    "__init__": [
      "self",
      "sigma"
    ],
    "transform": [
      "self",
      "x"
    ],
    "jitter": [
      "self",
      "x"
    ],
    "scale": [
      "self",
      "x"
    ],
    "shift": [
      "self",
      "x"
    ]
  },
  "conv1d_fft": [
    "f",
    "g",
    "dim"
  ],
  "ExponentialSmoothing": {
    "__init__": [
      "self",
      "dim",
      "nhead",
      "dropout",
      "aux"
    ],
    "forward": [
      "self",
      "values",
      "aux_values"
    ],
    "get_exponential_weight": [
      "self",
      "T"
    ],
    "weight": [
      "self"
    ]
  },
  "Feedforward": {
    "__init__": [
      "self",
      "d_model",
      "dim_feedforward",
      "dropout",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GrowthLayer": {
    "__init__": [
      "self",
      "d_model",
      "n_heads",
      "d_head",
      "dropout"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "FourierLayer": {
    "__init__": [
      "self",
      "d_model",
      "pred_len",
      "k",
      "low_freq"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extrapolate": [
      "self",
      "x_freq",
      "f",
      "t"
    ],
    "topk_freq": [
      "self",
      "x_freq"
    ]
  },
  "LevelLayer": {
    "__init__": [
      "self",
      "d_model",
      "c_out",
      "dropout"
    ],
    "forward": [
      "self",
      "level",
      "growth",
      "season"
    ]
  },
  "ETSformerEncoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "n_heads",
      "d_out",
      "seq_len",
      "pred_len",
      "k",
      "d_ffn",
      "dropout",
      "activation",
      "layer_norm_eps"
    ],
    "forward": [
      "self",
      "res",
      "level",
      "attn_mask"
    ],
    "_growth_block": [
      "self",
      "x"
    ],
    "_season_block": [
      "self",
      "x"
    ]
  },
  "DampingLayer": {
    "__init__": [
      "self",
      "pred_len",
      "n_heads",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ],
    "damping_factor": [
      "self"
    ]
  },
  "ETSformerDecoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "n_heads",
      "d_out",
      "pred_len",
      "dropout"
    ],
    "forward": [
      "self",
      "growth",
      "season"
    ]
  },
  "ETSformerEncoder": {
    "__init__": [
      "self",
      "layers"
    ],
    "forward": [
      "self",
      "res",
      "level",
      "attn_mask"
    ]
  },
  "ETSformerDecoder": {
    "__init__": [
      "self",
      "layers"
    ],
    "forward": [
      "self",
      "growths",
      "seasons"
    ]
  },
  "get_torch_trans": [
    "heads",
    "layers",
    "channels"
  ],
  "conv1d_with_init": [
    "in_channels",
    "out_channels",
    "kernel_size"
  ],
  "CsdiDiffusionEmbedding": {
    "__init__": [
      "self",
      "n_diffusion_steps",
      "d_embedding",
      "d_projection"
    ],
    "_build_embedding": [
      "n_steps",
      "d_embedding"
    ],
    "forward": [
      "self",
      "diffusion_step"
    ]
  },
  "CsdiResidualBlock": {
    "__init__": [
      "self",
      "d_side",
      "n_channels",
      "diffusion_embedding_dim",
      "nheads"
    ],
    "forward_time": [
      "self",
      "y",
      "base_shape"
    ],
    "forward_feature": [
      "self",
      "y",
      "base_shape"
    ],
    "forward": [
      "self",
      "x",
      "cond_info",
      "diffusion_emb"
    ]
  },
  "CsdiDiffusionModel": {
    "__init__": [
      "self",
      "n_diffusion_steps",
      "d_diffusion_embedding",
      "d_input",
      "d_side",
      "n_channels",
      "n_heads",
      "n_layers"
    ],
    "forward": [
      "self",
      "x",
      "cond_info",
      "diffusion_step"
    ]
  },
  "BackboneCSDI": {
    "__init__": [
      "self",
      "n_layers",
      "n_heads",
      "n_channels",
      "d_target",
      "d_time_embedding",
      "d_feature_embedding",
      "d_diffusion_embedding",
      "is_unconditional",
      "n_diffusion_steps",
      "schedule",
      "beta_start",
      "beta_end"
    ],
    "set_input_to_diffmodel": [
      "self",
      "noisy_data",
      "observed_data",
      "cond_mask"
    ],
    "calc_loss_valid": [
      "self",
      "observed_data",
      "cond_mask",
      "indicating_mask",
      "side_info"
    ],
    "calc_loss": [
      "self",
      "observed_data",
      "cond_mask",
      "indicating_mask",
      "side_info",
      "set_t"
    ],
    "forward": [
      "self",
      "observed_data",
      "cond_mask",
      "side_info",
      "n_sampling_times"
    ]
  },
  "MIC": {
    "__init__": [
      "self",
      "feature_size",
      "decomp_kernel",
      "conv_kernel",
      "isometric_kernel"
    ],
    "conv_trans_conv": [
      "self",
      "input",
      "conv1d",
      "conv1d_trans",
      "isometric"
    ],
    "forward": [
      "self",
      "src"
    ]
  },
  "SeasonalPrediction": {
    "__init__": [
      "self",
      "embedding_size",
      "d_layers",
      "decomp_kernel",
      "c_out",
      "conv_kernel",
      "isometric_kernel"
    ],
    "forward": [
      "self",
      "dec"
    ]
  },
  "BackboneMICN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "n_layers",
      "d_model",
      "decomp_kernel",
      "isometric_kernel",
      "conv_kernel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_conv1d": [
    "in_channels",
    "out_channels",
    "kernel_size",
    "stride",
    "padding",
    "dilation",
    "groups",
    "bias"
  ],
  "get_bn": [
    "channels"
  ],
  "conv_bn": [
    "in_channels",
    "out_channels",
    "kernel_size",
    "stride",
    "padding",
    "groups",
    "dilation",
    "bias"
  ],
  "fuse_bn": [
    "conv",
    "bn"
  ],
  "LayerNorm": {
    "__init__": [
      "self",
      "channels",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ReparamLargeKernelConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "groups",
      "small_kernel",
      "small_kernel_merged",
      "nvars"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "PaddingTwoEdge1d": [
      "self",
      "x",
      "pad_length_left",
      "pad_length_right",
      "pad_values"
    ],
    "get_equivalent_kernel_bias": [
      "self"
    ],
    "merge_kernel": [
      "self"
    ]
  },
  "Block": {
    "__init__": [
      "self",
      "large_size",
      "small_size",
      "dmodel",
      "dff",
      "nvars",
      "small_kernel_merged",
      "drop"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Stage": {
    "__init__": [
      "self",
      "ffn_ratio",
      "num_blocks",
      "large_size",
      "small_size",
      "dmodel",
      "nvars",
      "small_kernel_merged",
      "drop"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BackboneModernTCN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_predict_features",
      "patch_size",
      "patch_stride",
      "downsampling_ratio",
      "ffn_ratio",
      "num_blocks",
      "large_size",
      "small_size",
      "dims",
      "small_kernel_merged",
      "backbone_dropout",
      "head_dropout",
      "use_multi_scale",
      "individual",
      "freq"
    ],
    "structural_reparam": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UsganDiscriminator": {
    "__init__": [
      "self",
      "n_features",
      "rnn_hidden_size",
      "hint_rate",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "imputed_X",
      "missing_mask"
    ]
  },
  "BackboneUSGAN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size",
      "lambda_mse",
      "hint_rate",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "inputs",
      "training_object"
    ]
  },
  "BackboneSegRNN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "seg_len",
      "d_model",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PositionalEncoding": {
    "__init__": [
      "self",
      "d_pe",
      "max_len"
    ],
    "forward": [
      "self",
      "time_vectors"
    ]
  },
  "ObservationPropagation": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "n_nodes",
      "ob_dim",
      "heads",
      "concat",
      "beta",
      "dropout",
      "edge_dim",
      "bias",
      "root_weight"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "p_t",
      "edge_index",
      "edge_weights",
      "use_beta",
      "edge_attr",
      "return_attention_weights"
    ],
    "message_selfattention": [
      "self",
      "x_i",
      "x_j",
      "edge_weights",
      "edge_attr",
      "index",
      "ptr",
      "size_i"
    ],
    "message": [
      "self",
      "x_i",
      "x_j",
      "edge_weights",
      "edge_attr",
      "index",
      "ptr",
      "size_i"
    ],
    "aggregate": [
      "self",
      "inputs",
      "index",
      "ptr",
      "dim_size"
    ],
    "__repr__": [
      "self"
    ]
  },
  "BackboneRaindrop": {
    "__init__": [
      "self",
      "n_features",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "n_classes",
      "dropout",
      "max_len",
      "d_static",
      "d_pe",
      "aggregation",
      "sensor_wise_mask",
      "static"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "X",
      "timestamps",
      "lengths"
    ]
  },
  "Splitting": {
    "__init__": [
      "self"
    ],
    "even": [
      "self",
      "x"
    ],
    "odd": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Interactor": {
    "__init__": [
      "self",
      "in_planes",
      "splitting",
      "kernel",
      "dropout",
      "groups",
      "hidden_size",
      "INN"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InteractorLevel": {
    "__init__": [
      "self",
      "in_planes",
      "kernel",
      "dropout",
      "groups",
      "hidden_size",
      "INN"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LevelSCINet": {
    "__init__": [
      "self",
      "in_planes",
      "kernel_size",
      "dropout",
      "groups",
      "hidden_size",
      "INN"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SCINet_Tree": {
    "__init__": [
      "self",
      "in_planes",
      "current_level",
      "kernel_size",
      "dropout",
      "groups",
      "hidden_size",
      "INN"
    ],
    "zip_up_the_pants": [
      "self",
      "even",
      "odd"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EncoderTree": {
    "__init__": [
      "self",
      "in_planes",
      "num_levels",
      "kernel_size",
      "dropout",
      "groups",
      "hidden_size",
      "INN"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BackboneSCINet": {
    "__init__": [
      "self",
      "n_out_steps",
      "n_in_steps",
      "n_in_features",
      "d_hidden",
      "n_stacks",
      "n_levels",
      "n_decoder_layers",
      "n_groups",
      "kernel_size",
      "dropout",
      "concat_len",
      "pos_enc",
      "modified",
      "single_step_output_One"
    ],
    "get_position_encoding": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Residual": {
    "__init__": [
      "self",
      "in_channels",
      "num_hiddens",
      "num_residual_hiddens"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResidualStack": {
    "__init__": [
      "self",
      "in_channels",
      "num_hiddens",
      "num_residual_layers",
      "num_residual_hiddens"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Encoder": {
    "__init__": [
      "self",
      "in_channels",
      "num_hiddens",
      "num_residual_layers",
      "num_residual_hiddens",
      "embedding_dim",
      "compression_factor"
    ],
    "forward": [
      "self",
      "inputs",
      "compression_factor"
    ]
  },
  "Decoder": {
    "__init__": [
      "self",
      "in_channels",
      "num_hiddens",
      "num_residual_layers",
      "num_residual_hiddens",
      "compression_factor"
    ],
    "forward": [
      "self",
      "inputs",
      "compression_factor"
    ]
  },
  "VectorQuantizer": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "commitment_cost"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "VQVAE": {
    "__init__": [
      "self",
      "block_hidden_size",
      "num_residual_layers",
      "res_hidden_size",
      "embedding_dim",
      "num_embeddings",
      "commitment_cost",
      "compression_factor"
    ],
    "forward": [
      "self",
      "X"
    ]
  },
  "ResBlock": {
    "__init__": [
      "self",
      "input_dim",
      "hidden_dim",
      "output_dim",
      "dropout",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TiDE": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "d_hidden",
      "d_feature_encode",
      "d_temporal_decoder_hidden",
      "dropout"
    ],
    "forward": [
      "self",
      "X",
      "dynamic"
    ]
  },
  "TideEncoder": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "d_flatten",
      "d_hidden",
      "dropout"
    ],
    "forward": [
      "self",
      "X"
    ]
  },
  "TideDecoder": {
    "__init__": [
      "self",
      "n_steps",
      "n_pred_steps",
      "n_pred_features",
      "n_layers",
      "d_hidden",
      "d_feature_encode",
      "dropout"
    ],
    "forward": [
      "self",
      "X"
    ]
  },
  "DFT_series_decomp": {
    "__init__": [
      "self",
      "top_k"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MultiScaleSeasonMixing": {
    "__init__": [
      "self",
      "n_steps",
      "downsampling_window",
      "downsampling_layers"
    ],
    "forward": [
      "self",
      "season_list"
    ]
  },
  "MultiScaleTrendMixing": {
    "__init__": [
      "self",
      "n_steps",
      "downsampling_window",
      "downsampling_layers"
    ],
    "forward": [
      "self",
      "trend_list"
    ]
  },
  "PastDecomposableMixing": {
    "__init__": [
      "self",
      "n_steps",
      "n_pred_steps",
      "d_model",
      "d_ffn",
      "dropout",
      "channel_independence",
      "decomp_method",
      "top_k",
      "moving_avg",
      "downsampling_layers",
      "downsampling_window"
    ],
    "forward": [
      "self",
      "x_list"
    ]
  },
  "BackboneTimeMixer": {
    "__init__": [
      "self",
      "task_name",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "n_layers",
      "d_model",
      "d_ffn",
      "dropout",
      "top_k",
      "channel_independence",
      "decomp_method",
      "moving_avg",
      "downsampling_layers",
      "downsampling_window",
      "downsampling_method",
      "use_future_temporal_feature",
      "use_norm",
      "embed",
      "freq",
      "n_classes"
    ],
    "out_projection": [
      "self",
      "dec_out",
      "i",
      "out_res"
    ],
    "pre_enc": [
      "self",
      "x_list"
    ],
    "__multi_scale_process_inputs": [
      "self",
      "x_enc",
      "x_mark_enc"
    ],
    "forecast": [
      "self",
      "x_enc",
      "x_mark_enc",
      "x_dec",
      "x_mark_dec"
    ],
    "future_multi_mixing": [
      "self",
      "B",
      "enc_out_list",
      "x_list"
    ],
    "classification": [
      "self",
      "x_enc",
      "x_mark_enc"
    ],
    "anomaly_detection": [
      "self",
      "x_enc"
    ],
    "imputation": [
      "self",
      "x_enc",
      "x_mark_enc"
    ]
  },
  "hierarchical_contrastive_loss": [
    "z1",
    "z2",
    "alpha",
    "temporal_unit"
  ],
  "instance_contrastive_loss": [
    "z1",
    "z2"
  ],
  "temporal_contrastive_loss": [
    "z1",
    "z2"
  ],
  "generate_continuous_mask": [
    "B",
    "T",
    "n",
    "length"
  ],
  "generate_binomial_mask": [
    "B",
    "T",
    "p"
  ],
  "torch_pad_nan": [
    "arr",
    "left",
    "right",
    "dim"
  ],
  "take_per_row": [
    "A",
    "indx",
    "num_elem"
  ],
  "SamePadConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dilation",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dilation",
      "final"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DilatedConvEncoder": {
    "__init__": [
      "self",
      "in_channels",
      "channels",
      "kernel_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MASK_MODES": [],
  "TS2VecEncoder": {
    "__init__": [
      "self",
      "n_features",
      "n_pred_features",
      "d_hidden",
      "n_layers",
      "mask_mode"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ],
    "_eval_with_pooling": [
      "self",
      "x",
      "mask",
      "slicing",
      "encoding_window"
    ],
    "encode": [
      "self",
      "x",
      "mask",
      "encoding_window",
      "causal",
      "sliding_length",
      "sliding_padding"
    ],
    "fit_svm": [
      "features",
      "y",
      "MAX_SAMPLES"
    ],
    "fit_lr": [
      "features",
      "y",
      "MAX_SAMPLES"
    ],
    "fit_knn": [
      "features",
      "y"
    ],
    "fit_ridge": [
      "train_features",
      "train_y",
      "valid_features",
      "valid_y",
      "MAX_SAMPLES"
    ]
  },
  "BackboneDLinear": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "individual",
      "d_model"
    ],
    "forward": [
      "self",
      "seasonal_init",
      "trend_init"
    ]
  },
  "RNN_CELL": [],
  "reverse_tensor": [
    "tensor_"
  ],
  "MultiRNNCell": {
    "__init__": [
      "self",
      "cell_type",
      "n_layer",
      "d_input",
      "d_hidden"
    ],
    "forward": [
      "self",
      "X",
      "missing_mask"
    ]
  },
  "CrliGenerator": {
    "__init__": [
      "self",
      "n_layers",
      "n_features",
      "d_hidden",
      "cell_type"
    ],
    "forward": [
      "self",
      "X",
      "missing_mask"
    ]
  },
  "CrliDiscriminator": {
    "__init__": [
      "self",
      "cell_type",
      "d_input"
    ],
    "forward": [
      "self",
      "X",
      "missing_mask",
      "imputation_latent"
    ]
  },
  "CrliDecoder": {
    "__init__": [
      "self",
      "n_steps",
      "d_input",
      "d_output",
      "fcn_output_dims"
    ],
    "forward": [
      "self",
      "generator_fb_hidden_states"
    ]
  },
  "BackboneCRLI": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_generator_layers",
      "rnn_hidden_size",
      "decoder_fcn_output_dims",
      "rnn_cell_type"
    ],
    "forward": [
      "self",
      "X",
      "missing_mask"
    ]
  },
  "TimesBlock": {
    "__init__": [
      "self",
      "seq_len",
      "pred_len",
      "top_k",
      "d_model",
      "d_ffn",
      "num_kernels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BackboneTimesNet": {
    "__init__": [
      "self",
      "n_layers",
      "n_steps",
      "n_pred_steps",
      "top_k",
      "d_model",
      "d_ffn",
      "n_kernels"
    ],
    "forward": [
      "self",
      "X"
    ]
  },
  "BackboneTRMF": {
    "__init__": [
      "self",
      "lags",
      "K",
      "lambda_f",
      "lambda_x",
      "lambda_w",
      "alpha",
      "eta",
      "max_iter",
      "F_step",
      "X_step",
      "W_step"
    ],
    "forward": [
      "self",
      "X",
      "missing_mask"
    ],
    "impute_missingness": [
      "self"
    ],
    "_update_F": [
      "self",
      "step",
      "n_iter"
    ],
    "_grad_F": [
      "self"
    ],
    "_update_X": [
      "self",
      "step",
      "n_iter"
    ],
    "_grad_X": [
      "self"
    ],
    "_update_W": [
      "self",
      "step",
      "n_iter"
    ],
    "_grad_W": [
      "self"
    ]
  },
  "HiPPO_LegT": {
    "__init__": [
      "self",
      "N",
      "dt",
      "discretization"
    ],
    "transition": [
      "N"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "reconstruct": [
      "self",
      "c"
    ]
  },
  "SpectralConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "seq_len",
      "modes1",
      "ratio",
      "mode_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BackboneFiLM": {
    "__init__": [
      "self",
      "n_steps",
      "in_channels",
      "n_pred_steps",
      "window_size",
      "multiscale",
      "modes1",
      "ratio",
      "mode_type"
    ],
    "forward": [
      "self",
      "X"
    ]
  },
  "ProbMask": {
    "__init__": [
      "self",
      "B",
      "H",
      "L",
      "index",
      "scores",
      "device"
    ],
    "mask": [
      "self"
    ]
  },
  "ProbAttention": {
    "__init__": [
      "self",
      "mask_flag",
      "factor",
      "attention_dropout",
      "scale"
    ],
    "_prob_QK": [
      "self",
      "Q",
      "K",
      "sample_k",
      "n_top"
    ],
    "_get_initial_context": [
      "self",
      "V",
      "L_Q"
    ],
    "_update_context": [
      "self",
      "context_in",
      "V",
      "scores",
      "index",
      "L_Q",
      "attn_mask"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "attn_mask"
    ]
  },
  "InformerEncoderLayer": {
    "__init__": [
      "self",
      "attention",
      "d_model",
      "d_ff",
      "dropout",
      "activation"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask"
    ]
  },
  "InformerDecoderLayer": {
    "__init__": [
      "self",
      "self_attention",
      "cross_attention",
      "d_model",
      "d_ff",
      "dropout",
      "activation"
    ],
    "forward": [
      "self",
      "x",
      "cross",
      "x_mask",
      "cross_mask",
      "tau",
      "delta"
    ]
  },
  "InformerEncoder": {
    "__init__": [
      "self",
      "attn_layers",
      "conv_layers",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask"
    ]
  },
  "InformerDecoder": {
    "__init__": [
      "self",
      "layers",
      "norm_layer",
      "projection"
    ],
    "forward": [
      "self",
      "x",
      "cross",
      "x_mask",
      "cross_mask",
      "trend"
    ]
  },
  "ReprogrammingLayer": {
    "__init__": [
      "self",
      "d_model",
      "n_heads",
      "d_k",
      "d_llm",
      "attention_dropout"
    ],
    "forward": [
      "self",
      "target_embedding",
      "source_embedding",
      "value_embedding"
    ],
    "reprogramming": [
      "self",
      "target_embedding",
      "source_embedding",
      "value_embedding"
    ]
  },
  "SUPPORTED_LLM": [],
  "SUPPORTED_TASKS": [],
  "BackboneTimeLLM": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_layers",
      "patch_size",
      "patch_stride",
      "d_model",
      "d_ffn",
      "d_llm",
      "n_heads",
      "llm_model_type",
      "dropout",
      "domain_prompt_content",
      "task_name"
    ],
    "calc_lags": [
      "self",
      "x_enc"
    ],
    "forward": [
      "self",
      "x_enc",
      "missing_mask"
    ]
  },
  "TwoStageAttentionLayer": {
    "__init__": [
      "self",
      "seg_num",
      "factor",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ff",
      "dropout",
      "attn_dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SegMerging": {
    "__init__": [
      "self",
      "d_model",
      "win_size",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ScaleBlock": {
    "__init__": [
      "self",
      "win_size",
      "d_model",
      "n_heads",
      "d_ff",
      "depth",
      "dropout",
      "seg_num",
      "factor"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask",
      "tau",
      "delta"
    ]
  },
  "CrossformerDecoderLayer": {
    "__init__": [
      "self",
      "self_attention",
      "cross_attention",
      "seg_len",
      "d_model",
      "d_ff",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "cross"
    ]
  },
  "CrossformerEncoder": {
    "__init__": [
      "self",
      "attn_layers"
    ],
    "forward": [
      "self",
      "x",
      "src_mask"
    ]
  },
  "CrossformerDecoder": {
    "__init__": [
      "self",
      "layers"
    ],
    "forward": [
      "self",
      "x",
      "cross"
    ]
  },
  "TemporalDecay": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "diag"
    ],
    "_reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "delta"
    ]
  },
  "BackboneGRUD": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size"
    ],
    "forward": [
      "self",
      "X",
      "missing_mask",
      "deltas",
      "empirical_mean",
      "X_filledLOCF"
    ]
  },
  "DeStationaryAttention": {
    "__init__": [
      "self",
      "temperature",
      "attn_dropout"
    ],
    "forward": [
      "self",
      "q",
      "v",
      "k",
      "attn_mask"
    ]
  },
  "Projector": {
    "__init__": [
      "self",
      "d_in",
      "n_steps",
      "d_hidden",
      "n_hidden_layers",
      "d_output",
      "kernel_size"
    ],
    "forward": [
      "self",
      "x",
      "stats"
    ]
  },
  "NonstationaryTransformerEncoder": {
    "__init__": [
      "self",
      "n_layers",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout",
      "attn_dropout"
    ],
    "forward": [
      "self",
      "x",
      "src_mask"
    ]
  },
  "TokenEmbedding": {
    "__init__": [
      "self",
      "c_in",
      "d_model"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FixedEmbedding": {
    "__init__": [
      "self",
      "c_in",
      "d_model"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TemporalEmbedding": {
    "__init__": [
      "self",
      "d_model",
      "embed_type",
      "freq"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TimeFeatureEmbedding": {
    "__init__": [
      "self",
      "d_model",
      "freq"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DataEmbedding": {
    "__init__": [
      "self",
      "c_in",
      "d_model",
      "embed_type",
      "freq",
      "dropout",
      "with_pos",
      "n_max_steps"
    ],
    "forward": [
      "self",
      "x",
      "x_timestamp"
    ]
  },
  "AttentionOperator": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "attn_mask"
    ]
  },
  "ScaledDotProductAttention": {
    "__init__": [
      "self",
      "temperature",
      "attn_dropout"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "attn_mask"
    ]
  },
  "MultiHeadAttention": {
    "__init__": [
      "self",
      "attn_opt",
      "d_model",
      "n_heads",
      "d_k",
      "d_v"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "attn_mask"
    ]
  },
  "PositionWiseFeedForward": {
    "__init__": [
      "self",
      "d_in",
      "d_hid",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TransformerEncoderLayer": {
    "__init__": [
      "self",
      "attn_opt",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout"
    ],
    "forward": [
      "self",
      "enc_input",
      "src_mask"
    ]
  },
  "TransformerDecoderLayer": {
    "__init__": [
      "self",
      "slf_attn_opt",
      "enc_attn_opt",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout"
    ],
    "forward": [
      "self",
      "dec_input",
      "enc_output",
      "slf_attn_mask",
      "dec_enc_attn_mask"
    ]
  },
  "TransformerEncoder": {
    "__init__": [
      "self",
      "n_layers",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout",
      "attn_dropout"
    ],
    "forward": [
      "self",
      "x",
      "src_mask"
    ]
  },
  "TransformerDecoder": {
    "__init__": [
      "self",
      "n_layers",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout",
      "attn_dropout"
    ],
    "forward": [
      "self",
      "trg_seq",
      "enc_output",
      "trg_mask",
      "src_mask"
    ]
  },
  "GLU": {
    "__init__": [
      "self",
      "input_channel",
      "output_channel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StockBlockLayer": {
    "__init__": [
      "self",
      "time_step",
      "unit",
      "multi_layer",
      "stack_cnt"
    ],
    "spe_seq_cell": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "x",
      "mul_L"
    ]
  },
  "BackboneStemGNN": {
    "__init__": [
      "self",
      "units",
      "stack_cnt",
      "time_step",
      "multi_layer",
      "horizon",
      "dropout_rate",
      "leaky_rate"
    ],
    "get_laplacian": [
      "graph",
      "normalize"
    ],
    "cheb_polynomial": [
      "laplacian"
    ],
    "latent_correlation_layer": [
      "self",
      "x"
    ],
    "self_graph_attention": [
      "self",
      "input"
    ],
    "graph_fft": [
      "input",
      "eigenvectors"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InceptionBlockV1": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_kernels",
      "stride",
      "init_weight"
    ],
    "_initialize_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InceptionTransBlockV1": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "num_kernels",
      "init_weight"
    ],
    "_initialize_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "output_size"
    ]
  },
  "BackboneFreTS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "embed_size",
      "n_pred_steps",
      "hidden_size",
      "channel_independence"
    ],
    "MLP_temporal": [
      "self",
      "x",
      "B",
      "N",
      "L"
    ],
    "MLP_channel": [
      "self",
      "x",
      "B",
      "N",
      "L"
    ],
    "FreMLP": [
      "self",
      "B",
      "nd",
      "dimension",
      "x",
      "r",
      "i",
      "rb",
      "ib"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BackboneFITS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "cut_freq",
      "individual"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "drop_path": [
    "x",
    "drop_prob",
    "training",
    "scale_by_keep"
  ],
  "DropPath": {
    "__init__": [
      "self",
      "drop_prob",
      "scale_by_keep"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "_trunc_normal_": [
    "tensor",
    "mean",
    "std",
    "a",
    "b"
  ],
  "trunc_normal_": [
    "tensor",
    "mean",
    "std",
    "a",
    "b"
  ],
  "ICB": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "drop"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Adaptive_Spectral_Block": {
    "__init__": [
      "self",
      "dim",
      "adaptive_filter"
    ],
    "create_adaptive_high_freq_mask": [
      "self",
      "x_fft"
    ],
    "forward": [
      "self",
      "x_in"
    ]
  },
  "TSLANet_layer": {
    "__init__": [
      "self",
      "dim",
      "mlp_ratio",
      "drop",
      "drop_path",
      "norm_layer",
      "adaptive_filter",
      "apply_ICB",
      "apply_ASB"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PatchEmbed": {
    "__init__": [
      "self",
      "seq_len",
      "patch_size",
      "in_chans",
      "embed_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "random_masking_3D": [
    "xb",
    "mask_ratio"
  ],
  "BackboneTSLANet": {
    "__init__": [
      "self",
      "task_name",
      "seq_len",
      "num_channels",
      "pred_len",
      "n_layers",
      "patch_size",
      "emb_dim",
      "dropout",
      "mask_ratio",
      "num_classes"
    ],
    "_init_weights": [
      "m"
    ],
    "pretrain": [
      "self",
      "x_in"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SigmoidRange": {
    "__init__": [
      "self",
      "low",
      "high"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RegressionHead": {
    "__init__": [
      "self",
      "n_features",
      "d_model",
      "d_output",
      "head_dropout",
      "y_range"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PredictionHead": {
    "__init__": [
      "self",
      "d_model",
      "n_patches",
      "n_steps_forecast",
      "head_dropout",
      "individual",
      "n_features"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FlattenHead": {
    "__init__": [
      "self",
      "d_input",
      "d_output",
      "n_features",
      "head_dropout",
      "individual"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PatchtstEncoder": {
    "__init__": [
      "self",
      "n_layers",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout",
      "attn_dropout"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask"
    ]
  },
  "Decay": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "diag"
    ],
    "build": [
      "self",
      "input_size",
      "output_size"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "d"
    ]
  },
  "Decay_obs": {
    "__init__": [
      "self",
      "input_size",
      "output_size"
    ],
    "forward": [
      "self",
      "delta_diff"
    ]
  },
  "TorchTransformerEncoder": {
    "__init__": [
      "self",
      "heads",
      "layers",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv1dWithInit": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BackboneCSAI": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size",
      "step_channels",
      "training_loss"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "deltas",
      "last_obs",
      "intervals",
      "h"
    ]
  },
  "BackboneBCSAI": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size",
      "step_channels",
      "training_loss"
    ],
    "forward": [
      "self",
      "xdata"
    ]
  },
  "rbf_kernel": [
    "T",
    "length_scale"
  ],
  "diffusion_kernel": [
    "T",
    "length_scale"
  ],
  "matern_kernel": [
    "T",
    "length_scale"
  ],
  "cauchy_kernel": [
    "T",
    "sigma",
    "length_scale"
  ],
  "make_nn": [
    "input_size",
    "output_size",
    "hidden_sizes"
  ],
  "CustomConv1d": {
    "__init": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "make_cnn": [
    "input_size",
    "output_size",
    "hidden_sizes",
    "kernel_size"
  ],
  "GpvaeEncoder": {
    "__init__": [
      "self",
      "input_size",
      "z_size",
      "hidden_sizes",
      "window_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GpvaeDecoder": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "hidden_sizes"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BackboneGPVAE": {
    "__init__": [
      "self",
      "input_dim",
      "time_length",
      "latent_dim",
      "encoder_sizes",
      "decoder_sizes",
      "beta",
      "M",
      "K",
      "kernel",
      "sigma",
      "length_scale",
      "kernel_scales",
      "window_size"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "z"
    ],
    "kl_divergence": [
      "a",
      "b"
    ],
    "_init_prior": [
      "self",
      "device"
    ],
    "impute": [
      "self",
      "X",
      "missing_mask",
      "n_sampling_times"
    ],
    "forward": [
      "self",
      "X",
      "missing_mask"
    ]
  },
  "Dense": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "dropout",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AttentionLayer": {
    "__init__": [
      "self",
      "model_dim",
      "num_heads",
      "mask"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value"
    ]
  },
  "ProjectedAttentionLayer": {
    "__init__": [
      "self",
      "seq_len",
      "dim_proj",
      "d_model",
      "n_heads",
      "d_ff",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EmbeddedAttention": {
    "__init__": [
      "self",
      "model_dim",
      "node_embedding_dim"
    ],
    "forward": [
      "self",
      "value",
      "emb"
    ]
  },
  "EmbeddedAttentionLayer": {
    "__init__": [
      "self",
      "model_dim",
      "node_embedding_dim",
      "feed_forward_dim",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "emb",
      "dim"
    ]
  },
  "BaseForecaster": {
    "__init__": [
      "self",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "forecast": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "BaseNNForecaster": {
    "__init__": [
      "self",
      "training_loss",
      "validation_metric",
      "batch_size",
      "epochs",
      "patience",
      "num_workers",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "forecast": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "_GPT4TS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "term",
      "n_layers",
      "patch_size",
      "patch_stride",
      "train_gpt_mlp",
      "d_ffn",
      "dropout",
      "embed",
      "freq",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "GPT4TS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "term",
      "patch_size",
      "patch_stride",
      "n_layers",
      "train_gpt_mlp",
      "d_ffn",
      "dropout",
      "embed",
      "freq",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_organize_content_to_save": [
      "self"
    ]
  },
  "_TEFN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "n_fod",
      "apply_nonstationary_norm",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_MOMENT": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "term",
      "transformer_backbone",
      "transformer_type",
      "patch_size",
      "patch_stride",
      "d_model",
      "d_ffn",
      "dropout",
      "head_dropout",
      "finetuning_mode",
      "revin_affine",
      "add_positional_embedding",
      "value_embedding_bias",
      "orth_gain",
      "mask_ratio",
      "device",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "MOMENT": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "term",
      "patch_size",
      "patch_stride",
      "transformer_backbone",
      "transformer_type",
      "n_layers",
      "d_ffn",
      "d_model",
      "dropout",
      "head_dropout",
      "finetuning_mode",
      "revin_affine",
      "add_positional_embedding",
      "value_embedding_bias",
      "orth_gain",
      "mask_ratio",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ]
  },
  "_CSDI": {
    "__init__": [
      "self",
      "n_features",
      "n_pred_features",
      "n_layers",
      "n_heads",
      "n_channels",
      "d_time_embedding",
      "d_feature_embedding",
      "d_diffusion_embedding",
      "is_unconditional",
      "n_diffusion_steps",
      "schedule",
      "beta_start",
      "beta_end"
    ],
    "time_embedding": [
      "pos",
      "d_model"
    ],
    "get_side_info": [
      "self",
      "observed_tp",
      "cond_mask",
      "feature_id"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion",
      "n_sampling_times"
    ]
  },
  "CSDI": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "n_layers",
      "n_heads",
      "n_channels",
      "d_time_embedding",
      "d_feature_embedding",
      "d_diffusion_embedding",
      "n_diffusion_steps",
      "target_strategy",
      "is_unconditional",
      "schedule",
      "beta_start",
      "beta_end",
      "batch_size",
      "epochs",
      "patience",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type",
      "n_sampling_times"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type",
      "n_sampling_times"
    ]
  },
  "DatasetForCSDI": {
    "__init__": [
      "self",
      "data",
      "file_type"
    ],
    "sample_features": [
      "self",
      "observed_data",
      "observed_mask",
      "feature_id",
      "gt_mask"
    ],
    "_fetch_data_from_array": [
      "self",
      "idx"
    ],
    "_fetch_data_from_file": [
      "self",
      "idx"
    ]
  },
  "TestDatasetForCSDI": {
    "__init__": [
      "self",
      "data",
      "n_pred_steps",
      "n_pred_features",
      "file_type"
    ],
    "_fetch_data_from_array": [
      "self",
      "idx"
    ],
    "_fetch_data_from_file": [
      "self",
      "idx"
    ]
  },
  "_MICN": {
    "__init__": [
      "self",
      "n_layers",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "d_model",
      "dropout",
      "conv_kernel",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "MICN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "n_layers",
      "d_model",
      "conv_kernel",
      "dropout",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ]
  },
  "_ModernTCN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "patch_size",
      "patch_stride",
      "downsampling_ratio",
      "ffn_ratio",
      "num_blocks",
      "large_size",
      "small_size",
      "dims",
      "small_kernel_merged",
      "backbone_dropout",
      "head_dropout",
      "use_multi_scale",
      "individual",
      "apply_nonstationary_norm",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "ModernTCN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "patch_size",
      "patch_stride",
      "downsampling_ratio",
      "ffn_ratio",
      "num_blocks",
      "large_size",
      "small_size",
      "dims",
      "small_kernel_merged",
      "backbone_dropout",
      "head_dropout",
      "use_multi_scale",
      "individual",
      "apply_nonstationary_norm",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ]
  },
  "_SegRNN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "seg_len",
      "d_model",
      "dropout",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_TimeMixer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "term",
      "n_layers",
      "d_model",
      "d_ffn",
      "dropout",
      "top_k",
      "channel_independence",
      "decomp_method",
      "moving_avg",
      "downsampling_layers",
      "downsampling_window",
      "use_norm",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_DLinear": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "moving_avg_window_size",
      "individual",
      "d_model",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_TimesNet": {
    "__init__": [
      "self",
      "n_layers",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "top_k",
      "d_model",
      "d_ffn",
      "n_kernels",
      "dropout",
      "apply_nonstationary_norm",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_FiLM": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "window_size",
      "multiscale",
      "modes1",
      "ratio",
      "mode_type",
      "d_model",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_TimeLLM": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "term",
      "n_layers",
      "patch_size",
      "patch_stride",
      "d_model",
      "d_ffn",
      "d_llm",
      "n_heads",
      "llm_model_type",
      "dropout",
      "domain_prompt_content",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "TimeLLM": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "term",
      "llm_model_type",
      "n_layers",
      "patch_size",
      "patch_stride",
      "d_llm",
      "d_model",
      "d_ffn",
      "n_heads",
      "dropout",
      "domain_prompt_content",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_organize_content_to_save": [
      "self"
    ]
  },
  "_Transformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "n_encoder_layers",
      "n_decoder_layers",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout",
      "attn_dropout",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_FITS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "cut_freq",
      "individual",
      "apply_nonstationary_norm",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "FITS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_pred_steps",
      "n_pred_features",
      "cut_freq",
      "individual",
      "apply_nonstationary_norm",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ]
  },
  "_BTTF": [
    "dense_tensor",
    "sparse_tensor",
    "init",
    "rank",
    "time_lags",
    "burn_iter",
    "gibbs_iter",
    "multi_step"
  ],
  "sample_factor_x_partial": [
    "tau_sparse_tensor",
    "tau_ind",
    "time_lags",
    "U",
    "V",
    "X",
    "A",
    "Lambda_x",
    "back_step"
  ],
  "_BTTF_partial": [
    "sparse_tensor",
    "init",
    "rank",
    "time_lags",
    "gibbs_iter",
    "multi_step",
    "gamma"
  ],
  "BTTF_forecast": [
    "dense_tensor",
    "sparse_tensor",
    "pred_step",
    "multi_step",
    "rank",
    "time_lags",
    "burn_iter",
    "gibbs_iter",
    "gamma"
  ],
  "mvnrnd_pre": [
    "mu",
    "Lambda"
  ],
  "cov_mat": [
    "mat",
    "mat_bar"
  ],
  "ten2mat": [
    "tensor",
    "mode"
  ],
  "sample_factor_u": [
    "tau_sparse_tensor",
    "tau_ind",
    "U",
    "V",
    "X",
    "beta0"
  ],
  "sample_factor_v": [
    "tau_sparse_tensor",
    "tau_ind",
    "U",
    "V",
    "X",
    "beta0"
  ],
  "mnrnd": [
    "M",
    "U",
    "V"
  ],
  "sample_var_coefficient": [
    "X",
    "time_lags"
  ],
  "sample_factor_x": [
    "tau_sparse_tensor",
    "tau_ind",
    "time_lags",
    "U",
    "V",
    "X",
    "A",
    "Lambda_x"
  ],
  "compute_mape": [
    "var",
    "var_hat"
  ],
  "compute_rmse": [
    "var",
    "var_hat"
  ],
  "ar4cast": [
    "A",
    "X",
    "Sigma",
    "time_lags",
    "multi_step"
  ],
  "BTTF": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "pred_step",
      "rank",
      "time_lags",
      "burn_iter",
      "gibbs_iter",
      "gamma",
      "multi_step",
      "device"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "logger_creator": [],
  "logger": [],
  "extract_parent_dir": [
    "path"
  ],
  "create_dir_if_not_exist": [
    "path",
    "is_dir"
  ],
  "get_class_full_path": [
    "cls"
  ],
  "set_random_seed": [
    "random_seed"
  ],
  "get_random_seed": [],
  "get_cluster_members": [
    "test_data",
    "class_predictions"
  ],
  "clusters_for_plotting": [
    "cluster_members"
  ],
  "plot_clusters": [
    "dict_to_plot"
  ],
  "get_cluster_means": [
    "dict_to_plot"
  ],
  "plot_cluster_means": [
    "cluster_means"
  ],
  "plot_data": [
    "X",
    "X_ori",
    "X_imputed",
    "sample_idx",
    "n_rows",
    "n_cols",
    "fig_size"
  ],
  "plot_missingness": [
    "missing_mask",
    "min_step",
    "max_step",
    "sample_idx"
  ],
  "plot_attention": [
    "timeSteps",
    "attention",
    "fontscale"
  ],
  "BaseClusterer": {
    "__init__": [
      "self",
      "n_clusters",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "cluster": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "BaseNNClusterer": {
    "__init__": [
      "self",
      "n_clusters",
      "training_loss",
      "validation_metric",
      "batch_size",
      "epochs",
      "patience",
      "num_workers",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "cluster": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "inverse_softplus": [
    "x"
  ],
  "_VaDER": {
    "__init__": [
      "self",
      "n_steps",
      "d_input",
      "n_clusters",
      "d_rnn_hidden",
      "d_mu_stddev",
      "eps",
      "alpha"
    ],
    "forward": [
      "self",
      "inputs",
      "pretrain"
    ]
  },
  "VaDER": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_clusters",
      "rnn_hidden_size",
      "d_mu_stddev",
      "batch_size",
      "epochs",
      "pretrain_epochs",
      "patience",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "_train_model": [
      "self",
      "train_dataloader",
      "val_dataloader"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type",
      "return_latent_vars"
    ]
  },
  "DatasetForVaDER": {
    "__init__": [
      "self",
      "data",
      "return_y",
      "file_type"
    ],
    "_fetch_data_from_array": [
      "self",
      "idx"
    ],
    "_fetch_data_from_file": [
      "self",
      "idx"
    ]
  },
  "_CRLI": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_clusters",
      "n_generator_layers",
      "rnn_hidden_size",
      "decoder_fcn_output_dims",
      "lambda_kmeans",
      "rnn_cell_type"
    ],
    "forward": [
      "self",
      "inputs",
      "training_object"
    ]
  },
  "CRLI": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_clusters",
      "n_generator_layers",
      "rnn_hidden_size",
      "rnn_cell_type",
      "lambda_kmeans",
      "decoder_fcn_output_dims",
      "G_steps",
      "D_steps",
      "batch_size",
      "epochs",
      "patience",
      "G_optimizer",
      "D_optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "_train_model": [
      "self",
      "train_dataloader",
      "val_dataloader"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type",
      "return_latent_vars"
    ]
  },
  "DatasetForCRLI": {
    "__init__": [
      "self",
      "data",
      "return_y",
      "file_type"
    ],
    "_fetch_data_from_array": [
      "self",
      "idx"
    ],
    "_fetch_data_from_file": [
      "self",
      "idx"
    ]
  },
  "BaseClassifier": {
    "__init__": [
      "self",
      "n_classes",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "predict_proba": [
      "self",
      "test_set",
      "file_type"
    ],
    "classify": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "BaseNNClassifier": {
    "__init__": [
      "self",
      "n_classes",
      "training_loss",
      "validation_metric",
      "batch_size",
      "epochs",
      "patience",
      "num_workers",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "predict_proba": [
      "self",
      "test_set",
      "file_type"
    ],
    "classify": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "_Autoformer": {
    "__init__": [
      "self",
      "n_classes",
      "n_steps",
      "n_features",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "factor",
      "moving_avg_window_size",
      "dropout",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_BRITS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size",
      "n_classes",
      "classification_weight",
      "reconstruction_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "BRITS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_classes",
      "rnn_hidden_size",
      "classification_weight",
      "reconstruction_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "_iTransformer": {
    "__init__": [
      "self",
      "n_classes",
      "n_steps",
      "n_features",
      "n_layers",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout",
      "attn_dropout",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_SAITS": {
    "__init__": [
      "self",
      "n_classes",
      "n_layers",
      "n_steps",
      "n_features",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "dropout",
      "attn_dropout",
      "diagonal_attention_mask",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion",
      "diagonal_attention_mask"
    ]
  },
  "_Raindrop": {
    "__init__": [
      "self",
      "n_features",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "n_classes",
      "dropout",
      "max_len",
      "d_static",
      "aggregation",
      "sensor_wise_mask",
      "static",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "Raindrop": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_classes",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "dropout",
      "d_static",
      "aggregation",
      "sensor_wise_mask",
      "static",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "SUPPORTED_CLASSIFIERS": [],
  "_GRUD": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size",
      "n_classes",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "GRUD": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_classes",
      "rnn_hidden_size",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "DatasetForGRUD": {
    "__init__": [
      "self",
      "data",
      "return_y",
      "file_type"
    ],
    "_fetch_data_from_array": [
      "self",
      "idx"
    ],
    "_fetch_data_from_file": [
      "self",
      "idx"
    ]
  },
  "_PatchTST": {
    "__init__": [
      "self",
      "n_classes",
      "n_steps",
      "n_features",
      "n_layers",
      "d_model",
      "n_heads",
      "d_k",
      "d_v",
      "d_ffn",
      "patch_size",
      "patch_stride",
      "dropout",
      "attn_dropout",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_BCSAI": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size",
      "imputation_weight",
      "consistency_weight",
      "classification_weight",
      "n_classes",
      "step_channels",
      "dropout",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "CSAI": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size",
      "imputation_weight",
      "consistency_weight",
      "classification_weight",
      "n_classes",
      "removal_percent",
      "increase_factor",
      "step_channels",
      "dropout",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "TimeSeriesAI": {
    "__init__": [
      "self"
    ]
  },
  "turn_data_into_specified_dtype": [
    "data",
    "dtype"
  ],
  "_parse_delta_torch": [
    "missing_mask"
  ],
  "_parse_delta_numpy": [
    "missing_mask"
  ],
  "parse_delta": [
    "missing_mask"
  ],
  "sliding_window": [
    "time_series",
    "window_len",
    "sliding_len"
  ],
  "inverse_sliding_window": [
    "X",
    "sliding_len"
  ],
  "key_in_data_set": [
    "key",
    "dataset"
  ],
  "BaseDataset": {
    "__init__": [
      "self",
      "data",
      "return_X_ori",
      "return_X_pred",
      "return_y",
      "file_type"
    ],
    "_get_data_sizes": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "_check_array_input": [
      "X",
      "X_ori",
      "X_pred",
      "y",
      "out_dtype"
    ],
    "_fetch_data_from_array": [
      "self",
      "idx"
    ],
    "_open_file_handle": [
      "self"
    ],
    "_fetch_data_from_file": [
      "self",
      "idx"
    ],
    "fetch_entire_dataset": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "SUPPORTED_DATASET_FILE_FORMATS": [],
  "save_dict_into_h5": [
    "data_dict",
    "saving_path",
    "file_name"
  ],
  "load_dict_from_h5": [
    "file_path"
  ],
  "pickle_dump": [
    "data",
    "path"
  ],
  "pickle_load": [
    "path"
  ],
  "Adadelta": {
    "__init__": [
      "self",
      "lr",
      "rho",
      "eps",
      "weight_decay",
      "lr_scheduler"
    ],
    "init_optimizer": [
      "self",
      "params"
    ]
  },
  "Adam": {
    "__init__": [
      "self",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "lr_scheduler"
    ],
    "init_optimizer": [
      "self",
      "params"
    ]
  },
  "Optimizer": {
    "__init__": [
      "self",
      "lr",
      "lr_scheduler"
    ],
    "init_optimizer": [
      "self",
      "params"
    ],
    "add_param_group": [
      "self",
      "param_group"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "state_dict": [
      "self"
    ],
    "step": [
      "self",
      "closure"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ]
  },
  "SGD": {
    "__init__": [
      "self",
      "lr",
      "momentum",
      "weight_decay",
      "dampening",
      "nesterov",
      "lr_scheduler"
    ],
    "init_optimizer": [
      "self",
      "params"
    ]
  },
  "RMSprop": {
    "__init__": [
      "self",
      "lr",
      "momentum",
      "alpha",
      "eps",
      "centered",
      "weight_decay",
      "lr_scheduler"
    ],
    "init_optimizer": [
      "self",
      "params"
    ]
  },
  "Adagrad": {
    "__init__": [
      "self",
      "lr",
      "lr_decay",
      "weight_decay",
      "initial_accumulator_value",
      "eps",
      "lr_scheduler"
    ],
    "init_optimizer": [
      "self",
      "params"
    ]
  },
  "AdamW": {
    "__init__": [
      "self",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "lr_scheduler"
    ],
    "init_optimizer": [
      "self",
      "params"
    ]
  },
  "MultiStepLR": {
    "__init__": [
      "self",
      "milestones",
      "gamma",
      "last_epoch",
      "verbose"
    ],
    "get_lr": [
      "self"
    ],
    "_get_closed_form_lr": [
      "self"
    ]
  },
  "LinearLR": {
    "__init__": [
      "self",
      "start_factor",
      "end_factor",
      "total_iters",
      "last_epoch",
      "verbose"
    ],
    "get_lr": [
      "self"
    ],
    "_get_closed_form_lr": [
      "self"
    ]
  },
  "LambdaLR": {
    "__init__": [
      "self",
      "lr_lambda",
      "last_epoch",
      "verbose"
    ],
    "init_scheduler": [
      "self",
      "optimizer"
    ],
    "get_lr": [
      "self"
    ]
  },
  "LRScheduler": {
    "__init__": [
      "self",
      "last_epoch",
      "verbose"
    ],
    "init_scheduler": [
      "self",
      "optimizer"
    ],
    "get_lr": [
      "self"
    ],
    "get_last_lr": [
      "self"
    ],
    "print_lr": [
      "is_verbose",
      "group",
      "lr"
    ],
    "step": [
      "self"
    ]
  },
  "ConstantLR": {
    "__init__": [
      "self",
      "factor",
      "total_iters",
      "last_epoch",
      "verbose"
    ],
    "get_lr": [
      "self"
    ],
    "_get_closed_form_lr": [
      "self"
    ]
  },
  "MultiplicativeLR": {
    "__init__": [
      "self",
      "lr_lambda",
      "last_epoch",
      "verbose"
    ],
    "init_scheduler": [
      "self",
      "optimizer"
    ],
    "get_lr": [
      "self"
    ]
  },
  "StepLR": {
    "__init__": [
      "self",
      "step_size",
      "gamma",
      "last_epoch",
      "verbose"
    ],
    "get_lr": [
      "self"
    ],
    "_get_closed_form_lr": [
      "self"
    ]
  },
  "ExponentialLR": {
    "__init__": [
      "self",
      "gamma",
      "last_epoch",
      "verbose"
    ],
    "get_lr": [
      "self"
    ],
    "_get_closed_form_lr": [
      "self"
    ]
  },
  "BaseImputer": {
    "__init__": [
      "self",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "impute": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "BaseNNImputer": {
    "__init__": [
      "self",
      "training_loss",
      "validation_metric",
      "batch_size",
      "epochs",
      "patience",
      "num_workers",
      "device",
      "enable_amp",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "impute": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "_TCN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_levels",
      "d_hidden",
      "kernel_size",
      "dropout",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "TCN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_levels",
      "d_hidden",
      "kernel_size",
      "dropout",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "_FEDformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "moving_avg_window_size",
      "dropout",
      "version",
      "modes",
      "mode_select",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_Pyraformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "dropout",
      "attn_dropout",
      "window_size",
      "inner_size",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_Koopa": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_seg_steps",
      "d_dynamic",
      "d_hidden",
      "n_hidden_layers",
      "n_blocks",
      "multistep",
      "alpha",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "Koopa": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_seg_steps",
      "d_dynamic",
      "d_hidden",
      "n_hidden_layers",
      "n_blocks",
      "multistep",
      "alpha",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "_RevIN_SCINet": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_stacks",
      "n_levels",
      "n_groups",
      "n_decoder_layers",
      "d_hidden",
      "kernel_size",
      "dropout",
      "concat_len",
      "pos_enc",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "RevIN_SCINet": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_stacks",
      "n_levels",
      "n_groups",
      "n_decoder_layers",
      "d_hidden",
      "kernel_size",
      "concat_len",
      "dropout",
      "pos_enc",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "_MRNN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "MRNN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "DatasetForMRNN": {
    "__init__": [
      "self",
      "data",
      "return_X_ori",
      "return_y",
      "file_type"
    ],
    "_fetch_data_from_array": [
      "self",
      "idx"
    ],
    "_fetch_data_from_file": [
      "self",
      "idx"
    ]
  },
  "DatasetForBRITS": {
    "__init__": [
      "self",
      "data",
      "return_X_ori",
      "return_y",
      "file_type"
    ],
    "_fetch_data_from_array": [
      "self",
      "idx"
    ],
    "_fetch_data_from_file": [
      "self",
      "idx"
    ]
  },
  "_TimeMixerPP": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "d_model",
      "d_ffn",
      "n_heads",
      "dropout",
      "top_k",
      "n_kernels",
      "channel_mixing",
      "channel_independence",
      "downsampling_layers",
      "downsampling_window",
      "apply_nonstationary_norm",
      "training_loss",
      "validation_metric",
      "task_name"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_Reformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "d_model",
      "n_heads",
      "bucket_size",
      "n_hashes",
      "causal",
      "d_ffn",
      "dropout",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "DatasetForSAITS": {
    "__init__": [
      "self",
      "data",
      "return_X_ori",
      "return_y",
      "file_type",
      "rate"
    ],
    "_fetch_data_from_array": [
      "self",
      "idx"
    ],
    "_fetch_data_from_file": [
      "self",
      "idx"
    ]
  },
  "_ETSformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_encoder_layers",
      "n_decoder_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "dropout",
      "top_k",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "locf_numpy": [
    "X",
    "first_step_imputation"
  ],
  "locf_torch": [
    "X",
    "first_step_imputation"
  ],
  "LOCF": {
    "__init__": [
      "self",
      "first_step_imputation",
      "device"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "_USGAN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size",
      "lambda_mse",
      "hint_rate",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "inputs",
      "training_object"
    ]
  },
  "USGAN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "rnn_hidden_size",
      "lambda_mse",
      "hint_rate",
      "dropout",
      "G_steps",
      "D_steps",
      "batch_size",
      "epochs",
      "patience",
      "G_optimizer",
      "D_optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "_train_model": [
      "self",
      "train_dataloader",
      "val_dataloader"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "Mean": {
    "__init__": [
      "self"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "_SCINet": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_stacks",
      "n_levels",
      "n_groups",
      "n_decoder_layers",
      "d_hidden",
      "kernel_size",
      "dropout",
      "concat_len",
      "pos_enc",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_TOTEM": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "block_hidden_size",
      "num_residual_layers",
      "res_hidden_size",
      "embedding_dim",
      "num_embeddings",
      "commitment_cost",
      "compression_factor"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "TOTEM": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "d_block_hidden",
      "n_residual_layers",
      "d_residual_hidden",
      "d_embedding",
      "n_embeddings",
      "commitment_cost",
      "compression_factor",
      "batch_size",
      "epochs",
      "patience",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "_TiDE": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "d_model",
      "d_hidden",
      "d_feature_encode",
      "d_temporal_decoder_hidden",
      "dropout",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_TRMF": {
    "__init__": [
      "self",
      "lags",
      "K",
      "lambda_f",
      "lambda_x",
      "lambda_w",
      "alpha",
      "eta",
      "max_iter",
      "F_step",
      "X_step",
      "W_step"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "TRMF": {
    "__init__": [
      "self",
      "lags",
      "K",
      "lambda_f",
      "lambda_x",
      "lambda_w",
      "alpha",
      "eta",
      "max_iter",
      "F_step",
      "X_step",
      "W_step",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ],
    "impute": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "DatasetForTRMF": {
    "__init__": [
      "self",
      "data"
    ]
  },
  "_Informer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "factor",
      "dropout",
      "distil",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_Crossformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "factor",
      "seg_len",
      "win_size",
      "dropout",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_NonstationaryTransformer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "d_model",
      "n_heads",
      "d_ffn",
      "d_projector_hidden",
      "n_projector_hidden_layers",
      "dropout",
      "attn_dropout",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "_StemGNN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "n_stacks",
      "d_model",
      "dropout_rate",
      "leaky_rate",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "StemGNN": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "n_stacks",
      "d_model",
      "dropout",
      "leaky_rate",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "_FreTS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "embed_size",
      "hidden_size",
      "channel_independence",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "FreTS": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "embed_size",
      "hidden_size",
      "channel_independence",
      "ORT_weight",
      "MIT_weight",
      "batch_size",
      "epochs",
      "patience",
      "training_loss",
      "validation_metric",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "_TSLANet": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "patch_size",
      "d_embedding",
      "dropout",
      "mask_ratio"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  },
  "TSLANet": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "patch_size",
      "d_embedding",
      "mask_ratio",
      "dropout",
      "batch_size",
      "epochs",
      "patience",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ]
  },
  "Lerp": {
    "__init__": [
      "self"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "compute_intervals": [
    "data"
  ],
  "compute_last_obs": [
    "data",
    "masks"
  ],
  "non_uniform_sample": [
    "data",
    "removal_percent",
    "pre_replacement_probabilities",
    "increase_factor"
  ],
  "DatasetForCSAI": {
    "__init__": [
      "self",
      "data",
      "return_X_ori",
      "return_y",
      "file_type",
      "removal_percent",
      "increase_factor",
      "replacement_probabilities"
    ],
    "_fetch_data_from_array": [
      "self",
      "idx"
    ],
    "_fetch_data_from_file": [
      "self",
      "idx"
    ]
  },
  "_GPVAE": {
    "__init__": [
      "self",
      "input_dim",
      "time_length",
      "latent_dim",
      "encoder_sizes",
      "decoder_sizes",
      "beta",
      "M",
      "K",
      "kernel",
      "sigma",
      "length_scale",
      "kernel_scales",
      "window_size"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion",
      "n_sampling_times"
    ]
  },
  "GPVAE": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "latent_size",
      "encoder_sizes",
      "decoder_sizes",
      "kernel",
      "beta",
      "M",
      "K",
      "sigma",
      "length_scale",
      "kernel_scales",
      "window_size",
      "batch_size",
      "epochs",
      "patience",
      "optimizer",
      "num_workers",
      "device",
      "saving_path",
      "model_saving_strategy",
      "verbose"
    ],
    "_assemble_input_for_training": [
      "self",
      "data"
    ],
    "_assemble_input_for_validating": [
      "self",
      "data"
    ],
    "_assemble_input_for_testing": [
      "self",
      "data"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type",
      "n_sampling_times"
    ],
    "impute": [
      "self",
      "test_set",
      "file_type",
      "n_sampling_times"
    ]
  },
  "Median": {
    "__init__": [
      "self"
    ],
    "fit": [
      "self",
      "train_set",
      "val_set",
      "file_type"
    ],
    "predict": [
      "self",
      "test_set",
      "file_type"
    ]
  },
  "_ImputeFormer": {
    "__init__": [
      "self",
      "n_steps",
      "n_features",
      "n_layers",
      "d_input_embed",
      "d_learnable_embed",
      "d_proj",
      "d_ffn",
      "n_temporal_heads",
      "dropout",
      "input_dim",
      "output_dim",
      "ORT_weight",
      "MIT_weight",
      "training_loss",
      "validation_metric"
    ],
    "forward": [
      "self",
      "inputs",
      "calc_criterion"
    ]
  }
}