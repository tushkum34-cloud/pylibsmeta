{
  "PipelineCallback": {
    "config_name": [],
    "__init__": [
      "self",
      "cutoff_step_ratio",
      "cutoff_step_index"
    ],
    "tensor_inputs": [
      "self"
    ],
    "callback_fn": [
      "self",
      "pipeline",
      "step_index",
      "timesteps",
      "callback_kwargs"
    ],
    "__call__": [
      "self",
      "pipeline",
      "step_index",
      "timestep",
      "callback_kwargs"
    ]
  },
  "MultiPipelineCallbacks": {
    "__init__": [
      "self",
      "callbacks"
    ],
    "tensor_inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "pipeline",
      "step_index",
      "timestep",
      "callback_kwargs"
    ]
  },
  "SDCFGCutoffCallback": {
    "tensor_inputs": [],
    "callback_fn": [
      "self",
      "pipeline",
      "step_index",
      "timestep",
      "callback_kwargs"
    ]
  },
  "SDXLCFGCutoffCallback": {
    "tensor_inputs": [],
    "callback_fn": [
      "self",
      "pipeline",
      "step_index",
      "timestep",
      "callback_kwargs"
    ]
  },
  "SDXLControlnetCFGCutoffCallback": {
    "tensor_inputs": [],
    "callback_fn": [
      "self",
      "pipeline",
      "step_index",
      "timestep",
      "callback_kwargs"
    ]
  },
  "IPAdapterScaleCutoffCallback": {
    "tensor_inputs": [],
    "callback_fn": [
      "self",
      "pipeline",
      "step_index",
      "timestep",
      "callback_kwargs"
    ]
  },
  "SD3CFGCutoffCallback": {
    "tensor_inputs": [],
    "callback_fn": [
      "self",
      "pipeline",
      "step_index",
      "timestep",
      "callback_kwargs"
    ]
  },
  "logger": [],
  "SchedulerType": {
    "LINEAR": [],
    "COSINE": [],
    "COSINE_WITH_RESTARTS": [],
    "POLYNOMIAL": [],
    "CONSTANT": [],
    "CONSTANT_WITH_WARMUP": [],
    "PIECEWISE_CONSTANT": []
  },
  "get_constant_schedule": [
    "optimizer",
    "last_epoch"
  ],
  "get_constant_schedule_with_warmup": [
    "optimizer",
    "num_warmup_steps",
    "last_epoch"
  ],
  "get_piecewise_constant_schedule": [
    "optimizer",
    "step_rules",
    "last_epoch"
  ],
  "get_linear_schedule_with_warmup": [
    "optimizer",
    "num_warmup_steps",
    "num_training_steps",
    "last_epoch"
  ],
  "get_cosine_schedule_with_warmup": [
    "optimizer",
    "num_warmup_steps",
    "num_training_steps",
    "num_cycles",
    "last_epoch"
  ],
  "get_cosine_with_hard_restarts_schedule_with_warmup": [
    "optimizer",
    "num_warmup_steps",
    "num_training_steps",
    "num_cycles",
    "last_epoch"
  ],
  "get_polynomial_decay_schedule_with_warmup": [
    "optimizer",
    "num_warmup_steps",
    "num_training_steps",
    "lr_end",
    "power",
    "last_epoch"
  ],
  "TYPE_TO_SCHEDULER_FUNCTION": [],
  "get_scheduler": [
    "name",
    "optimizer",
    "step_rules",
    "num_warmup_steps",
    "num_training_steps",
    "num_cycles",
    "power",
    "last_epoch"
  ],
  "__version__": [],
  "_import_structure": [],
  "set_seed": [
    "seed"
  ],
  "compute_snr": [
    "noise_scheduler",
    "timesteps"
  ],
  "resolve_interpolation_mode": [
    "interpolation_type"
  ],
  "compute_dream_and_update_latents": [
    "unet",
    "noise_scheduler",
    "timesteps",
    "noise",
    "noisy_latents",
    "target",
    "encoder_hidden_states",
    "dream_detail_preservation"
  ],
  "unet_lora_state_dict": [
    "unet"
  ],
  "cast_training_params": [
    "model",
    "dtype"
  ],
  "_set_state_dict_into_text_encoder": [
    "lora_state_dict",
    "prefix",
    "text_encoder"
  ],
  "_collate_lora_metadata": [
    "modules_to_save"
  ],
  "compute_density_for_timestep_sampling": [
    "weighting_scheme",
    "batch_size",
    "logit_mean",
    "logit_std",
    "mode_scale",
    "device",
    "generator"
  ],
  "compute_loss_weighting_for_sd3": [
    "weighting_scheme",
    "sigmas"
  ],
  "free_memory": [],
  "offload_models": [],
  "parse_buckets_string": [
    "buckets_str"
  ],
  "find_nearest_bucket": [
    "h",
    "w",
    "bucket_options"
  ],
  "EMAModel": {
    "__init__": [
      "self",
      "parameters",
      "decay",
      "min_decay",
      "update_after_step",
      "use_ema_warmup",
      "inv_gamma",
      "power",
      "foreach",
      "model_cls",
      "model_config"
    ],
    "from_pretrained": [
      "cls",
      "path",
      "model_cls",
      "foreach"
    ],
    "save_pretrained": [
      "self",
      "path"
    ],
    "get_decay": [
      "self",
      "optimization_step"
    ],
    "step": [
      "self",
      "parameters"
    ],
    "copy_to": [
      "self",
      "parameters"
    ],
    "pin_memory": [
      "self"
    ],
    "to": [
      "self",
      "device",
      "dtype",
      "non_blocking"
    ],
    "state_dict": [
      "self"
    ],
    "store": [
      "self",
      "parameters"
    ],
    "restore": [
      "self",
      "parameters"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "_re_configuration_file": [],
  "FrozenDict": {
    "__init__": [
      "self"
    ],
    "__delitem__": [
      "self"
    ],
    "setdefault": [
      "self"
    ],
    "pop": [
      "self"
    ],
    "update": [
      "self"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "__setitem__": [
      "self",
      "name",
      "value"
    ]
  },
  "ConfigMixin": {
    "config_name": [],
    "ignore_for_config": [],
    "has_compatibles": [],
    "_deprecated_kwargs": [],
    "register_to_config": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "save_config": [
      "self",
      "save_directory",
      "push_to_hub"
    ],
    "from_config": [
      "cls",
      "config",
      "return_unused_kwargs"
    ],
    "get_config_dict": [
      "cls"
    ],
    "load_config": [
      "cls",
      "pretrained_model_name_or_path",
      "return_unused_kwargs",
      "return_commit_hash"
    ],
    "_get_init_keys": [
      "input_class"
    ],
    "extract_init_dict": [
      "cls",
      "config_dict"
    ],
    "_dict_from_json_file": [
      "cls",
      "json_file",
      "dduf_entries"
    ],
    "__repr__": [
      "self"
    ],
    "config": [
      "self"
    ],
    "to_json_string": [
      "self"
    ],
    "to_json_file": [
      "self",
      "json_file_path"
    ],
    "_get_config_file_from_dduf": [
      "cls",
      "pretrained_model_name_or_path",
      "dduf_entries"
    ]
  },
  "register_to_config": [
    "init"
  ],
  "flax_register_to_config": [
    "cls"
  ],
  "LegacyConfigMixin": {
    "from_config": [
      "cls",
      "config",
      "return_unused_kwargs"
    ]
  },
  "pkgs_to_check_at_runtime": [],
  "dep_version_check": [
    "pkg",
    "hint"
  ],
  "VideoProcessor": {
    "preprocess_video": [
      "self",
      "video",
      "height",
      "width"
    ],
    "postprocess_video": [
      "self",
      "video",
      "output_type"
    ],
    "classify_height_width_bin": [
      "height",
      "width",
      "ratios"
    ],
    "resize_and_crop_tensor": [
      "samples",
      "new_width",
      "new_height"
    ]
  },
  "PipelineImageInput": [],
  "PipelineDepthInput": [],
  "is_valid_image": [
    "image"
  ],
  "is_valid_image_imagelist": [
    "images"
  ],
  "VaeImageProcessor": {
    "config_name": [],
    "__init__": [
      "self",
      "do_resize",
      "vae_scale_factor",
      "vae_latent_channels",
      "resample",
      "reducing_gap",
      "do_normalize",
      "do_binarize",
      "do_convert_rgb",
      "do_convert_grayscale"
    ],
    "numpy_to_pil": [
      "images"
    ],
    "pil_to_numpy": [
      "images"
    ],
    "numpy_to_pt": [
      "images"
    ],
    "pt_to_numpy": [
      "images"
    ],
    "normalize": [
      "images"
    ],
    "denormalize": [
      "images"
    ],
    "convert_to_rgb": [
      "image"
    ],
    "convert_to_grayscale": [
      "image"
    ],
    "blur": [
      "image",
      "blur_factor"
    ],
    "get_crop_region": [
      "mask_image",
      "width",
      "height",
      "pad"
    ],
    "_resize_and_fill": [
      "self",
      "image",
      "width",
      "height"
    ],
    "_resize_and_crop": [
      "self",
      "image",
      "width",
      "height"
    ],
    "resize": [
      "self",
      "image",
      "height",
      "width",
      "resize_mode"
    ],
    "binarize": [
      "self",
      "image"
    ],
    "_denormalize_conditionally": [
      "self",
      "images",
      "do_denormalize"
    ],
    "get_default_height_width": [
      "self",
      "image",
      "height",
      "width"
    ],
    "preprocess": [
      "self",
      "image",
      "height",
      "width",
      "resize_mode",
      "crops_coords"
    ],
    "postprocess": [
      "self",
      "image",
      "output_type",
      "do_denormalize"
    ],
    "apply_overlay": [
      "self",
      "mask",
      "init_image",
      "image",
      "crop_coords"
    ]
  },
  "InpaintProcessor": {
    "config_name": [],
    "__init__": [
      "self",
      "do_resize",
      "vae_scale_factor",
      "vae_latent_channels",
      "resample",
      "reducing_gap",
      "do_normalize",
      "do_binarize",
      "do_convert_grayscale",
      "mask_do_normalize",
      "mask_do_binarize",
      "mask_do_convert_grayscale"
    ],
    "preprocess": [
      "self",
      "image",
      "mask",
      "height",
      "width",
      "padding_mask_crop"
    ],
    "postprocess": [
      "self",
      "image",
      "output_type",
      "original_image",
      "original_mask",
      "crops_coords"
    ]
  },
  "VaeImageProcessorLDM3D": {
    "config_name": [],
    "__init__": [
      "self",
      "do_resize",
      "vae_scale_factor",
      "resample",
      "do_normalize"
    ],
    "numpy_to_pil": [
      "images"
    ],
    "depth_pil_to_numpy": [
      "images"
    ],
    "rgblike_to_depthmap": [
      "image"
    ],
    "numpy_to_depth": [
      "self",
      "images"
    ],
    "postprocess": [
      "self",
      "image",
      "output_type",
      "do_denormalize"
    ],
    "preprocess": [
      "self",
      "rgb",
      "depth",
      "height",
      "width",
      "target_res"
    ]
  },
  "IPAdapterMaskProcessor": {
    "config_name": [],
    "__init__": [
      "self",
      "do_resize",
      "vae_scale_factor",
      "resample",
      "do_normalize",
      "do_binarize",
      "do_convert_grayscale"
    ],
    "downsample": [
      "mask",
      "batch_size",
      "num_queries",
      "value_embed_dim"
    ]
  },
  "PixArtImageProcessor": {
    "__init__": [
      "self",
      "do_resize",
      "vae_scale_factor",
      "resample",
      "do_normalize",
      "do_binarize",
      "do_convert_grayscale"
    ],
    "classify_height_width_bin": [
      "height",
      "width",
      "ratios"
    ],
    "resize_and_crop_tensor": [
      "samples",
      "new_width",
      "new_height"
    ]
  },
  "deps": [],
  "ValueGuidedRLPipeline": {
    "__init__": [
      "self",
      "value_function",
      "unet",
      "scheduler",
      "env"
    ],
    "normalize": [
      "self",
      "x_in",
      "key"
    ],
    "de_normalize": [
      "self",
      "x_in",
      "key"
    ],
    "to_torch": [
      "self",
      "x_in"
    ],
    "reset_x0": [
      "self",
      "x_in",
      "cond",
      "act_dim"
    ],
    "run_diffusion": [
      "self",
      "x",
      "conditions",
      "n_guide_steps",
      "scale"
    ],
    "__call__": [
      "self",
      "obs",
      "batch_size",
      "planning_horizon",
      "n_guide_steps",
      "scale"
    ]
  },
  "EXPECTED_PARENT_CLASSES": [],
  "CONFIG": [],
  "conversion_command_factory": [
    "args"
  ],
  "CustomBlocksCommand": {
    "register_subcommand": [
      "parser"
    ],
    "__init__": [
      "self",
      "block_module_name",
      "block_class_name"
    ],
    "run": [
      "self"
    ],
    "_choose_block": [
      "self",
      "candidates",
      "chosen"
    ],
    "_get_class_names": [
      "self",
      "file_path"
    ],
    "_get_base_name": [
      "self",
      "node"
    ],
    "_create_automap": [
      "self",
      "parent_class",
      "child_class"
    ]
  },
  "BaseDiffusersCLICommand": {
    "register_subcommand": [
      "parser"
    ],
    "run": [
      "self"
    ]
  },
  "main": [],
  "FP16SafetensorsCommand": {
    "register_subcommand": [
      "parser"
    ],
    "__init__": [
      "self",
      "ckpt_id",
      "fp16",
      "use_safetensors"
    ],
    "run": [
      "self"
    ]
  },
  "info_command_factory": [
    "_"
  ],
  "EnvironmentCommand": {
    "register_subcommand": [
      "parser"
    ],
    "run": [
      "self"
    ],
    "format_dict": [
      "d"
    ]
  },
  "QuantizationMethod": {
    "BITS_AND_BYTES": [],
    "GGUF": [],
    "TORCHAO": [],
    "QUANTO": [],
    "MODELOPT": []
  },
  "QuantizationConfigMixin": {
    "_exclude_attributes_at_init": [],
    "from_dict": [
      "cls",
      "config_dict",
      "return_unused_kwargs"
    ],
    "to_json_file": [
      "self",
      "json_file_path"
    ],
    "to_dict": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "to_json_string": [
      "self",
      "use_diff"
    ],
    "update": [
      "self"
    ]
  },
  "BitsAndBytesConfig": {
    "_exclude_attributes_at_init": [],
    "__init__": [
      "self",
      "load_in_8bit",
      "load_in_4bit",
      "llm_int8_threshold",
      "llm_int8_skip_modules",
      "llm_int8_enable_fp32_cpu_offload",
      "llm_int8_has_fp16_weight",
      "bnb_4bit_compute_dtype",
      "bnb_4bit_quant_type",
      "bnb_4bit_use_double_quant",
      "bnb_4bit_quant_storage"
    ],
    "load_in_4bit": [
      "self",
      "value"
    ],
    "load_in_8bit": [
      "self",
      "value"
    ],
    "post_init": [
      "self"
    ],
    "is_quantizable": [
      "self"
    ],
    "quantization_method": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "to_diff_dict": [
      "self"
    ]
  },
  "GGUFQuantizationConfig": {
    "__init__": [
      "self",
      "compute_dtype"
    ]
  },
  "TorchAoConfig": {
    "__init__": [
      "self",
      "quant_type",
      "modules_to_not_convert"
    ],
    "post_init": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "from_dict": [
      "cls",
      "config_dict",
      "return_unused_kwargs"
    ],
    "_get_torchao_quant_type_to_method": [
      "cls"
    ],
    "_is_xpu_or_cuda_capability_atleast_8_9": [],
    "get_apply_tensor_subclass": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "QuantoConfig": {
    "__init__": [
      "self",
      "weights_dtype",
      "modules_to_not_convert"
    ],
    "post_init": [
      "self"
    ]
  },
  "NVIDIAModelOptConfig": {
    "quanttype_to_numbits": [],
    "quanttype_to_scalingbits": [],
    "__init__": [
      "self",
      "quant_type",
      "modules_to_not_convert",
      "weight_only",
      "channel_quantize",
      "block_quantize",
      "scale_channel_quantize",
      "scale_block_quantize",
      "algorithm",
      "forward_loop",
      "modelopt_config",
      "disable_conv_quantization"
    ],
    "check_model_patching": [
      "self",
      "operation"
    ],
    "_normalize_quant_type": [
      "self",
      "quant_type"
    ],
    "get_config_from_quant_type": [
      "self"
    ]
  },
  "DiffusersQuantizer": {
    "requires_calibration": [],
    "required_packages": [],
    "__init__": [
      "self",
      "quantization_config"
    ],
    "update_torch_dtype": [
      "self",
      "torch_dtype"
    ],
    "update_device_map": [
      "self",
      "device_map"
    ],
    "adjust_target_dtype": [
      "self",
      "torch_dtype"
    ],
    "update_missing_keys": [
      "self",
      "model",
      "missing_keys",
      "prefix"
    ],
    "get_special_dtypes_update": [
      "self",
      "model",
      "torch_dtype"
    ],
    "adjust_max_memory": [
      "self",
      "max_memory"
    ],
    "check_if_quantized_param": [
      "self",
      "model",
      "param_value",
      "param_name",
      "state_dict"
    ],
    "create_quantized_param": [
      "self"
    ],
    "check_quantized_param_shape": [
      "self"
    ],
    "validate_environment": [
      "self"
    ],
    "preprocess_model": [
      "self",
      "model"
    ],
    "postprocess_model": [
      "self",
      "model"
    ],
    "dequantize": [
      "self",
      "model"
    ],
    "get_cuda_warm_up_factor": [
      "self"
    ],
    "_dequantize": [
      "self",
      "model"
    ],
    "_process_model_before_weight_loading": [
      "self",
      "model"
    ],
    "_process_model_after_weight_loading": [
      "self",
      "model"
    ],
    "is_serializable": [
      "self"
    ],
    "is_trainable": [
      "self"
    ],
    "is_compileable": [
      "self"
    ]
  },
  "PipelineQuantizationConfig": {
    "__init__": [
      "self",
      "quant_backend",
      "quant_kwargs",
      "components_to_quantize",
      "quant_mapping"
    ],
    "post_init": [
      "self"
    ],
    "_validate_init_args": [
      "self"
    ],
    "_validate_init_kwargs_in_backends": [
      "self"
    ],
    "_validate_quant_mapping_args": [
      "self"
    ],
    "_check_backend_availability": [
      "self",
      "quant_backend"
    ],
    "_resolve_quant_config": [
      "self",
      "is_diffusers",
      "module_name"
    ],
    "_get_quant_config_list": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "AUTO_QUANTIZER_MAPPING": [],
  "AUTO_QUANTIZATION_CONFIG_MAPPING": [],
  "DiffusersAutoQuantizer": {
    "from_dict": [
      "cls",
      "quantization_config_dict"
    ],
    "from_config": [
      "cls",
      "quantization_config"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "merge_quantization_configs": [
      "cls",
      "quantization_config",
      "quantization_config_from_args"
    ]
  },
  "_update_torch_safe_globals": [],
  "fuzzy_match_size": [
    "config_name"
  ],
  "_quantization_type": [
    "weight"
  ],
  "_linear_extra_repr": [
    "self"
  ],
  "TorchAoHfQuantizer": {
    "requires_calibration": [],
    "required_packages": [],
    "__init__": [
      "self",
      "quantization_config"
    ],
    "validate_environment": [
      "self"
    ],
    "update_torch_dtype": [
      "self",
      "torch_dtype"
    ],
    "adjust_target_dtype": [
      "self",
      "target_dtype"
    ],
    "adjust_max_memory": [
      "self",
      "max_memory"
    ],
    "check_if_quantized_param": [
      "self",
      "model",
      "param_value",
      "param_name",
      "state_dict"
    ],
    "create_quantized_param": [
      "self",
      "model",
      "param_value",
      "param_name",
      "target_device",
      "state_dict",
      "unexpected_keys"
    ],
    "get_cuda_warm_up_factor": [
      "self"
    ],
    "_process_model_before_weight_loading": [
      "self",
      "model",
      "device_map",
      "keep_in_fp32_modules"
    ],
    "_process_model_after_weight_loading": [
      "self",
      "model"
    ],
    "is_serializable": [
      "self",
      "safe_serialization"
    ],
    "is_trainable": [
      "self"
    ],
    "is_compileable": [
      "self"
    ]
  },
  "GGUFQuantizer": {
    "use_keep_in_fp32_modules": [],
    "__init__": [
      "self",
      "quantization_config"
    ],
    "validate_environment": [
      "self"
    ],
    "adjust_max_memory": [
      "self",
      "max_memory"
    ],
    "adjust_target_dtype": [
      "self",
      "target_dtype"
    ],
    "update_torch_dtype": [
      "self",
      "torch_dtype"
    ],
    "check_quantized_param_shape": [
      "self",
      "param_name",
      "current_param",
      "loaded_param"
    ],
    "check_if_quantized_param": [
      "self",
      "model",
      "param_value",
      "param_name",
      "state_dict"
    ],
    "create_quantized_param": [
      "self",
      "model",
      "param_value",
      "param_name",
      "target_device",
      "state_dict",
      "unexpected_keys"
    ],
    "_process_model_before_weight_loading": [
      "self",
      "model",
      "device_map",
      "keep_in_fp32_modules"
    ],
    "_process_model_after_weight_loading": [
      "self",
      "model"
    ],
    "is_serializable": [
      "self"
    ],
    "is_trainable": [
      "self"
    ],
    "is_compileable": [
      "self"
    ],
    "_dequantize": [
      "self",
      "model"
    ]
  },
  "can_use_cuda_kernels": [],
  "UNQUANTIZED_TYPES": [],
  "STANDARD_QUANT_TYPES": [],
  "KQUANT_TYPES": [],
  "IMATRIX_QUANT_TYPES": [],
  "DEQUANT_TYPES": [],
  "MMVQ_QUANT_TYPES": [],
  "MMQ_QUANT_TYPES": [],
  "_fused_mul_mat_gguf": [
    "x",
    "qweight",
    "qweight_type"
  ],
  "_create_accelerate_new_hook": [
    "old_hook"
  ],
  "_replace_with_gguf_linear": [
    "model",
    "compute_dtype",
    "state_dict",
    "prefix",
    "modules_to_not_convert"
  ],
  "_dequantize_gguf_and_restore_linear": [
    "model",
    "modules_to_not_convert"
  ],
  "QK_K": [],
  "K_SCALE_SIZE": [],
  "to_uint32": [
    "x"
  ],
  "split_block_dims": [
    "blocks"
  ],
  "get_scale_min": [
    "scales"
  ],
  "dequantize_blocks_Q8_0": [
    "blocks",
    "block_size",
    "type_size",
    "dtype"
  ],
  "dequantize_blocks_Q5_1": [
    "blocks",
    "block_size",
    "type_size",
    "dtype"
  ],
  "dequantize_blocks_Q5_0": [
    "blocks",
    "block_size",
    "type_size",
    "dtype"
  ],
  "dequantize_blocks_Q4_1": [
    "blocks",
    "block_size",
    "type_size",
    "dtype"
  ],
  "dequantize_blocks_Q4_0": [
    "blocks",
    "block_size",
    "type_size",
    "dtype"
  ],
  "dequantize_blocks_Q6_K": [
    "blocks",
    "block_size",
    "type_size",
    "dtype"
  ],
  "dequantize_blocks_Q5_K": [
    "blocks",
    "block_size",
    "type_size",
    "dtype"
  ],
  "dequantize_blocks_Q4_K": [
    "blocks",
    "block_size",
    "type_size",
    "dtype"
  ],
  "dequantize_blocks_Q3_K": [
    "blocks",
    "block_size",
    "type_size",
    "dtype"
  ],
  "dequantize_blocks_Q2_K": [
    "blocks",
    "block_size",
    "type_size",
    "dtype"
  ],
  "dequantize_blocks_BF16": [
    "blocks",
    "block_size",
    "type_size",
    "dtype"
  ],
  "dequantize_blocks_IQ4_NL": [
    "blocks",
    "block_size",
    "type_size",
    "dtype"
  ],
  "dequantize_blocks_IQ4_XS": [
    "blocks",
    "block_size",
    "type_size",
    "dtype"
  ],
  "GGML_QUANT_SIZES": [],
  "dequantize_functions": [],
  "SUPPORTED_GGUF_QUANT_TYPES": [],
  "_quant_shape_from_byte_shape": [
    "shape",
    "type_size",
    "block_size"
  ],
  "dequantize_gguf_tensor": [
    "tensor"
  ],
  "GGUFParameter": {
    "__new__": [
      "cls",
      "data",
      "requires_grad",
      "quant_type"
    ],
    "as_tensor": [
      "self"
    ],
    "_extract_quant_type": [
      "args"
    ],
    "__torch_function__": [
      "cls",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "GGUFLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "compute_dtype",
      "device"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "forward_native": [
      "self",
      "inputs"
    ],
    "forward_cuda": [
      "self",
      "inputs"
    ]
  },
  "NVIDIAModelOptQuantizer": {
    "use_keep_in_fp32_modules": [],
    "requires_calibration": [],
    "required_packages": [],
    "__init__": [
      "self",
      "quantization_config"
    ],
    "validate_environment": [
      "self"
    ],
    "check_if_quantized_param": [
      "self",
      "model",
      "param_value",
      "param_name",
      "state_dict"
    ],
    "create_quantized_param": [
      "self",
      "model",
      "param_value",
      "param_name",
      "target_device"
    ],
    "adjust_max_memory": [
      "self",
      "max_memory"
    ],
    "adjust_target_dtype": [
      "self",
      "target_dtype"
    ],
    "update_torch_dtype": [
      "self",
      "torch_dtype"
    ],
    "get_conv_param_names": [
      "self",
      "model"
    ],
    "_process_model_before_weight_loading": [
      "self",
      "model",
      "device_map",
      "keep_in_fp32_modules"
    ],
    "_process_model_after_weight_loading": [
      "self",
      "model"
    ],
    "is_trainable": [
      "self"
    ],
    "is_serializable": [
      "self"
    ]
  },
  "_replace_with_quanto_layers": [
    "model",
    "quantization_config",
    "modules_to_not_convert",
    "pre_quantized"
  ],
  "QuantoQuantizer": {
    "use_keep_in_fp32_modules": [],
    "requires_calibration": [],
    "required_packages": [],
    "__init__": [
      "self",
      "quantization_config"
    ],
    "validate_environment": [
      "self"
    ],
    "check_if_quantized_param": [
      "self",
      "model",
      "param_value",
      "param_name",
      "state_dict"
    ],
    "create_quantized_param": [
      "self",
      "model",
      "param_value",
      "param_name",
      "target_device"
    ],
    "adjust_max_memory": [
      "self",
      "max_memory"
    ],
    "adjust_target_dtype": [
      "self",
      "target_dtype"
    ],
    "update_torch_dtype": [
      "self",
      "torch_dtype"
    ],
    "update_missing_keys": [
      "self",
      "model",
      "missing_keys",
      "prefix"
    ],
    "_process_model_before_weight_loading": [
      "self",
      "model",
      "device_map",
      "keep_in_fp32_modules"
    ],
    "_process_model_after_weight_loading": [
      "self",
      "model"
    ],
    "is_trainable": [
      "self"
    ],
    "is_serializable": [
      "self"
    ],
    "is_compileable": [
      "self"
    ]
  },
  "_replace_with_bnb_linear": [
    "model",
    "modules_to_not_convert",
    "current_key_name",
    "quantization_config",
    "has_been_replaced"
  ],
  "replace_with_bnb_linear": [
    "model",
    "modules_to_not_convert",
    "current_key_name",
    "quantization_config"
  ],
  "dequantize_bnb_weight": [
    "weight",
    "state",
    "dtype"
  ],
  "_dequantize_and_replace": [
    "model",
    "dtype",
    "modules_to_not_convert",
    "current_key_name",
    "quantization_config",
    "has_been_replaced"
  ],
  "dequantize_and_replace": [
    "model",
    "modules_to_not_convert",
    "quantization_config"
  ],
  "_check_bnb_status": [
    "module"
  ],
  "BnB4BitDiffusersQuantizer": {
    "use_keep_in_fp32_modules": [],
    "requires_calibration": [],
    "__init__": [
      "self",
      "quantization_config"
    ],
    "validate_environment": [
      "self"
    ],
    "adjust_target_dtype": [
      "self",
      "target_dtype"
    ],
    "check_if_quantized_param": [
      "self",
      "model",
      "param_value",
      "param_name",
      "state_dict"
    ],
    "create_quantized_param": [
      "self",
      "model",
      "param_value",
      "param_name",
      "target_device",
      "state_dict",
      "unexpected_keys"
    ],
    "check_quantized_param_shape": [
      "self",
      "param_name",
      "current_param",
      "loaded_param"
    ],
    "adjust_max_memory": [
      "self",
      "max_memory"
    ],
    "update_torch_dtype": [
      "self",
      "torch_dtype"
    ],
    "update_device_map": [
      "self",
      "device_map"
    ],
    "_process_model_before_weight_loading": [
      "self",
      "model",
      "device_map",
      "keep_in_fp32_modules"
    ],
    "_process_model_after_weight_loading": [
      "self",
      "model"
    ],
    "is_serializable": [
      "self"
    ],
    "is_trainable": [
      "self"
    ],
    "_dequantize": [
      "self",
      "model"
    ]
  },
  "BnB8BitDiffusersQuantizer": {
    "use_keep_in_fp32_modules": [],
    "requires_calibration": [],
    "__init__": [
      "self",
      "quantization_config"
    ],
    "validate_environment": [
      "self"
    ],
    "adjust_max_memory": [
      "self",
      "max_memory"
    ],
    "update_torch_dtype": [
      "self",
      "torch_dtype"
    ],
    "update_device_map": [
      "self",
      "device_map"
    ],
    "adjust_target_dtype": [
      "self",
      "target_dtype"
    ],
    "check_if_quantized_param": [
      "self",
      "model",
      "param_value",
      "param_name",
      "state_dict"
    ],
    "create_quantized_param": [
      "self",
      "model",
      "param_value",
      "param_name",
      "target_device",
      "state_dict",
      "unexpected_keys"
    ],
    "_process_model_after_weight_loading": [
      "self",
      "model"
    ],
    "_process_model_before_weight_loading": [
      "self",
      "model",
      "device_map",
      "keep_in_fp32_modules"
    ],
    "is_serializable": [
      "self"
    ],
    "is_trainable": [
      "self"
    ],
    "is_compileable": [
      "self"
    ],
    "_dequantize": [
      "self",
      "model"
    ]
  },
  "betas_for_alpha_bar": [
    "num_diffusion_timesteps",
    "max_beta",
    "alpha_transform_type"
  ],
  "DEISMultistepScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "solver_order",
      "prediction_type",
      "thresholding",
      "dynamic_thresholding_ratio",
      "sample_max_value",
      "algorithm_type",
      "solver_type",
      "lower_order_final",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "use_flow_sigmas",
      "flow_shift",
      "timestep_spacing",
      "steps_offset",
      "use_dynamic_shifting",
      "time_shift_type"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "mu"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_sigma_to_alpha_sigma_t": [
      "self",
      "sigma"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "convert_model_output": [
      "self",
      "model_output"
    ],
    "deis_first_order_update": [
      "self",
      "model_output"
    ],
    "multistep_deis_second_order_update": [
      "self",
      "model_output_list"
    ],
    "multistep_deis_third_order_update": [
      "self",
      "model_output_list"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "scale_model_input": [
      "self",
      "sample"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "DDIMSchedulerOutput": {},
  "rescale_zero_terminal_snr": [
    "alphas_cumprod"
  ],
  "CogVideoXDDIMScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "clip_sample",
      "set_alpha_to_one",
      "steps_offset",
      "prediction_type",
      "clip_sample_range",
      "sample_max_value",
      "timestep_spacing",
      "rescale_betas_zero_snr",
      "snr_shift_scale"
    ],
    "_get_variance": [
      "self",
      "timestep",
      "prev_timestep"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "eta",
      "use_clipped_model_output",
      "generator",
      "variance_noise",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "get_velocity": [
      "self",
      "sample",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "VQDiffusionSchedulerOutput": {},
  "index_to_log_onehot": [
    "x",
    "num_classes"
  ],
  "gumbel_noised": [
    "logits",
    "generator"
  ],
  "alpha_schedules": [
    "num_diffusion_timesteps",
    "alpha_cum_start",
    "alpha_cum_end"
  ],
  "gamma_schedules": [
    "num_diffusion_timesteps",
    "gamma_cum_start",
    "gamma_cum_end"
  ],
  "VQDiffusionScheduler": {
    "order": [],
    "__init__": [
      "self",
      "num_vec_classes",
      "num_train_timesteps",
      "alpha_cum_start",
      "alpha_cum_end",
      "gamma_cum_start",
      "gamma_cum_end"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "q_posterior": [
      "self",
      "log_p_x_0",
      "x_t",
      "t"
    ],
    "log_Q_t_transitioning_to_known_class": [
      "self"
    ],
    "apply_cumulative_transitions": [
      "self",
      "q",
      "t"
    ]
  },
  "DDPMSchedulerState": {
    "create": [
      "cls",
      "common",
      "init_noise_sigma",
      "timesteps"
    ]
  },
  "FlaxDDPMSchedulerOutput": {},
  "FlaxDDPMScheduler": {
    "_compatibles": [],
    "has_state": [
      "self"
    ],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "variance_type",
      "clip_sample",
      "prediction_type",
      "dtype"
    ],
    "create_state": [
      "self",
      "common"
    ],
    "scale_model_input": [
      "self",
      "state",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "state",
      "num_inference_steps",
      "shape"
    ],
    "_get_variance": [
      "self",
      "state",
      "t",
      "predicted_variance",
      "variance_type"
    ],
    "step": [
      "self",
      "state",
      "model_output",
      "timestep",
      "sample",
      "key",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "state",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "get_velocity": [
      "self",
      "state",
      "sample",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "SCHEDULER_CONFIG_NAME": [],
  "FlaxKarrasDiffusionSchedulers": {
    "FlaxDDIMScheduler": [],
    "FlaxDDPMScheduler": [],
    "FlaxPNDMScheduler": [],
    "FlaxLMSDiscreteScheduler": [],
    "FlaxDPMSolverMultistepScheduler": [],
    "FlaxEulerDiscreteScheduler": []
  },
  "FlaxSchedulerOutput": {},
  "FlaxSchedulerMixin": {
    "config_name": [],
    "ignore_for_config": [],
    "_compatibles": [],
    "has_compatibles": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path",
      "subfolder",
      "return_unused_kwargs"
    ],
    "save_pretrained": [
      "self",
      "save_directory",
      "push_to_hub"
    ],
    "compatibles": [
      "self"
    ],
    "_get_compatibles": [
      "cls"
    ]
  },
  "broadcast_to_shape_from_left": [
    "x",
    "shape"
  ],
  "CommonSchedulerState": {
    "create": [
      "cls",
      "scheduler"
    ]
  },
  "get_sqrt_alpha_prod": [
    "state",
    "original_samples",
    "noise",
    "timesteps"
  ],
  "add_noise_common": [
    "state",
    "original_samples",
    "noise",
    "timesteps"
  ],
  "get_velocity_common": [
    "state",
    "sample",
    "noise",
    "timesteps"
  ],
  "CogVideoXDPMScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "clip_sample",
      "set_alpha_to_one",
      "steps_offset",
      "prediction_type",
      "clip_sample_range",
      "sample_max_value",
      "timestep_spacing",
      "rescale_betas_zero_snr",
      "snr_shift_scale"
    ],
    "_get_variance": [
      "self",
      "timestep",
      "prev_timestep"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "get_variables": [
      "self",
      "alpha_prod_t",
      "alpha_prod_t_prev",
      "alpha_prod_t_back"
    ],
    "get_mult": [
      "self",
      "h",
      "r",
      "alpha_prod_t",
      "alpha_prod_t_prev",
      "alpha_prod_t_back"
    ],
    "step": [
      "self",
      "model_output",
      "old_pred_original_sample",
      "timestep",
      "timestep_back",
      "sample",
      "eta",
      "use_clipped_model_output",
      "generator",
      "variance_noise",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "get_velocity": [
      "self",
      "sample",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "FlowMatchHeunDiscreteSchedulerOutput": {},
  "FlowMatchHeunDiscreteScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "shift"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "scale_noise": [
      "self",
      "sample",
      "timestep",
      "noise"
    ],
    "_sigma_to_t": [
      "self",
      "sigma"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "state_in_first_order": [
      "self"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "s_churn",
      "s_tmin",
      "s_tmax",
      "s_noise",
      "generator",
      "return_dict"
    ],
    "__len__": [
      "self"
    ]
  },
  "RePaintSchedulerOutput": {},
  "RePaintScheduler": {
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "eta",
      "trained_betas",
      "clip_sample"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "jump_length",
      "jump_n_sample",
      "device"
    ],
    "_get_variance": [
      "self",
      "t"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "original_image",
      "mask",
      "generator",
      "return_dict"
    ],
    "undo_step": [
      "self",
      "sample",
      "timestep",
      "generator"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "TCDSchedulerOutput": {},
  "TCDScheduler": {
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "original_inference_steps",
      "clip_sample",
      "clip_sample_range",
      "set_alpha_to_one",
      "steps_offset",
      "prediction_type",
      "thresholding",
      "dynamic_thresholding_ratio",
      "sample_max_value",
      "timestep_spacing",
      "timestep_scaling",
      "rescale_betas_zero_snr"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "_get_variance": [
      "self",
      "timestep",
      "prev_timestep"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "original_inference_steps",
      "timesteps",
      "strength"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "eta",
      "generator",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "get_velocity": [
      "self",
      "sample",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ],
    "previous_timestep": [
      "self",
      "timestep"
    ]
  },
  "DDIMScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "clip_sample",
      "set_alpha_to_one",
      "steps_offset",
      "prediction_type",
      "thresholding",
      "dynamic_thresholding_ratio",
      "clip_sample_range",
      "sample_max_value",
      "timestep_spacing",
      "rescale_betas_zero_snr"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "_get_variance": [
      "self",
      "timestep",
      "prev_timestep"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "eta",
      "use_clipped_model_output",
      "generator",
      "variance_noise",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "get_velocity": [
      "self",
      "sample",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "FlowMatchLCMSchedulerOutput": {},
  "FlowMatchLCMScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "shift",
      "use_dynamic_shifting",
      "base_shift",
      "max_shift",
      "base_image_seq_len",
      "max_image_seq_len",
      "invert_sigmas",
      "shift_terminal",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "time_shift_type",
      "scale_factors",
      "upscale_mode"
    ],
    "shift": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "set_shift": [
      "self",
      "shift"
    ],
    "set_scale_factors": [
      "self",
      "scale_factors",
      "upscale_mode"
    ],
    "scale_noise": [
      "self",
      "sample",
      "timestep",
      "noise"
    ],
    "_sigma_to_t": [
      "self",
      "sigma"
    ],
    "time_shift": [
      "self",
      "mu",
      "sigma",
      "t"
    ],
    "stretch_shift_to_terminal": [
      "self",
      "t"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "sigmas",
      "mu",
      "timesteps"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "_time_shift_exponential": [
      "self",
      "mu",
      "sigma",
      "t"
    ],
    "_time_shift_linear": [
      "self",
      "mu",
      "sigma",
      "t"
    ],
    "__len__": [
      "self"
    ]
  },
  "FlowMatchEulerDiscreteSchedulerOutput": {},
  "FlowMatchEulerDiscreteScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "shift",
      "use_dynamic_shifting",
      "base_shift",
      "max_shift",
      "base_image_seq_len",
      "max_image_seq_len",
      "invert_sigmas",
      "shift_terminal",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "time_shift_type",
      "stochastic_sampling"
    ],
    "shift": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "set_shift": [
      "self",
      "shift"
    ],
    "scale_noise": [
      "self",
      "sample",
      "timestep",
      "noise"
    ],
    "_sigma_to_t": [
      "self",
      "sigma"
    ],
    "time_shift": [
      "self",
      "mu",
      "sigma",
      "t"
    ],
    "stretch_shift_to_terminal": [
      "self",
      "t"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "sigmas",
      "mu",
      "timesteps"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "s_churn",
      "s_tmin",
      "s_tmax",
      "s_noise",
      "generator",
      "per_token_timesteps",
      "return_dict"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "_time_shift_exponential": [
      "self",
      "mu",
      "sigma",
      "t"
    ],
    "_time_shift_linear": [
      "self",
      "mu",
      "sigma",
      "t"
    ],
    "__len__": [
      "self"
    ]
  },
  "SdeVeOutput": {},
  "ScoreSdeVeScheduler": {
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "snr",
      "sigma_min",
      "sigma_max",
      "sampling_eps",
      "correct_steps"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "sampling_eps",
      "device"
    ],
    "set_sigmas": [
      "self",
      "num_inference_steps",
      "sigma_min",
      "sigma_max",
      "sampling_eps"
    ],
    "get_adjacent_sigma": [
      "self",
      "timesteps",
      "t"
    ],
    "step_pred": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "step_correct": [
      "self",
      "model_output",
      "sample",
      "generator",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "DDIMParallelSchedulerOutput": {},
  "DDIMParallelScheduler": {
    "_compatibles": [],
    "order": [],
    "_is_ode_scheduler": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "clip_sample",
      "set_alpha_to_one",
      "steps_offset",
      "prediction_type",
      "thresholding",
      "dynamic_thresholding_ratio",
      "clip_sample_range",
      "sample_max_value",
      "timestep_spacing",
      "rescale_betas_zero_snr"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "_get_variance": [
      "self",
      "timestep",
      "prev_timestep"
    ],
    "_batch_get_variance": [
      "self",
      "t",
      "prev_t"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "eta",
      "use_clipped_model_output",
      "generator",
      "variance_noise",
      "return_dict"
    ],
    "batch_step_no_noise": [
      "self",
      "model_output",
      "timesteps",
      "sample",
      "eta",
      "use_clipped_model_output"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "get_velocity": [
      "self",
      "sample",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "ConsistencyDecoderSchedulerOutput": {},
  "ConsistencyDecoderScheduler": {
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "sigma_data"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "init_noise_sigma": [
      "self"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ]
  },
  "DDPMWuerstchenSchedulerOutput": {},
  "DDPMWuerstchenScheduler": {
    "__init__": [
      "self",
      "scaler",
      "s"
    ],
    "_alpha_cumprod": [
      "self",
      "t",
      "device"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "timesteps",
      "device"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ],
    "previous_timestep": [
      "self",
      "timestep"
    ]
  },
  "UnCLIPSchedulerOutput": {},
  "UnCLIPScheduler": {
    "__init__": [
      "self",
      "num_train_timesteps",
      "variance_type",
      "clip_sample",
      "clip_sample_range",
      "prediction_type",
      "beta_schedule"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "_get_variance": [
      "self",
      "t",
      "prev_timestep",
      "predicted_variance",
      "variance_type"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "prev_timestep",
      "generator",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ]
  },
  "KarrasDiffusionSchedulers": {
    "DDIMScheduler": [],
    "DDPMScheduler": [],
    "PNDMScheduler": [],
    "LMSDiscreteScheduler": [],
    "EulerDiscreteScheduler": [],
    "HeunDiscreteScheduler": [],
    "EulerAncestralDiscreteScheduler": [],
    "DPMSolverMultistepScheduler": [],
    "DPMSolverSinglestepScheduler": [],
    "KDPM2DiscreteScheduler": [],
    "KDPM2AncestralDiscreteScheduler": [],
    "DEISMultistepScheduler": [],
    "UniPCMultistepScheduler": [],
    "DPMSolverSDEScheduler": [],
    "EDMEulerScheduler": []
  },
  "AysSchedules": [],
  "SchedulerOutput": {},
  "SchedulerMixin": {
    "config_name": [],
    "_compatibles": [],
    "has_compatibles": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path",
      "subfolder",
      "return_unused_kwargs"
    ],
    "save_pretrained": [
      "self",
      "save_directory",
      "push_to_hub"
    ],
    "compatibles": [
      "self"
    ],
    "_get_compatibles": [
      "cls"
    ]
  },
  "SASolverScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "predictor_order",
      "corrector_order",
      "prediction_type",
      "tau_func",
      "thresholding",
      "dynamic_thresholding_ratio",
      "sample_max_value",
      "algorithm_type",
      "lower_order_final",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "use_flow_sigmas",
      "flow_shift",
      "lambda_min_clipped",
      "variance_type",
      "timestep_spacing",
      "steps_offset"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_sigma_to_alpha_sigma_t": [
      "self",
      "sigma"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "convert_model_output": [
      "self",
      "model_output"
    ],
    "get_coefficients_exponential_negative": [
      "self",
      "order",
      "interval_start",
      "interval_end"
    ],
    "get_coefficients_exponential_positive": [
      "self",
      "order",
      "interval_start",
      "interval_end",
      "tau"
    ],
    "lagrange_polynomial_coefficient": [
      "self",
      "order",
      "lambda_list"
    ],
    "get_coefficients_fn": [
      "self",
      "order",
      "interval_start",
      "interval_end",
      "lambda_list",
      "tau"
    ],
    "stochastic_adams_bashforth_update": [
      "self",
      "model_output"
    ],
    "stochastic_adams_moulton_update": [
      "self",
      "this_model_output"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "scale_model_input": [
      "self",
      "sample"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "DPMSolverMultistepSchedulerState": {
    "create": [
      "cls",
      "common",
      "alpha_t",
      "sigma_t",
      "lambda_t",
      "init_noise_sigma",
      "timesteps"
    ]
  },
  "FlaxDPMSolverMultistepSchedulerOutput": {},
  "FlaxDPMSolverMultistepScheduler": {
    "_compatibles": [],
    "has_state": [
      "self"
    ],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "solver_order",
      "prediction_type",
      "thresholding",
      "dynamic_thresholding_ratio",
      "sample_max_value",
      "algorithm_type",
      "solver_type",
      "lower_order_final",
      "timestep_spacing",
      "dtype"
    ],
    "create_state": [
      "self",
      "common"
    ],
    "set_timesteps": [
      "self",
      "state",
      "num_inference_steps",
      "shape"
    ],
    "convert_model_output": [
      "self",
      "state",
      "model_output",
      "timestep",
      "sample"
    ],
    "dpm_solver_first_order_update": [
      "self",
      "state",
      "model_output",
      "timestep",
      "prev_timestep",
      "sample"
    ],
    "multistep_dpm_solver_second_order_update": [
      "self",
      "state",
      "model_output_list",
      "timestep_list",
      "prev_timestep",
      "sample"
    ],
    "multistep_dpm_solver_third_order_update": [
      "self",
      "state",
      "model_output_list",
      "timestep_list",
      "prev_timestep",
      "sample"
    ],
    "step": [
      "self",
      "state",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "scale_model_input": [
      "self",
      "state",
      "sample",
      "timestep"
    ],
    "add_noise": [
      "self",
      "state",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "DDPMSchedulerOutput": {},
  "DDPMScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "variance_type",
      "clip_sample",
      "prediction_type",
      "thresholding",
      "dynamic_thresholding_ratio",
      "clip_sample_range",
      "sample_max_value",
      "timestep_spacing",
      "steps_offset",
      "rescale_betas_zero_snr"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "timesteps"
    ],
    "_get_variance": [
      "self",
      "t",
      "predicted_variance",
      "variance_type"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "get_velocity": [
      "self",
      "sample",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ],
    "previous_timestep": [
      "self",
      "timestep"
    ]
  },
  "DDPMParallelSchedulerOutput": {},
  "DDPMParallelScheduler": {
    "_compatibles": [],
    "order": [],
    "_is_ode_scheduler": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "variance_type",
      "clip_sample",
      "prediction_type",
      "thresholding",
      "dynamic_thresholding_ratio",
      "clip_sample_range",
      "sample_max_value",
      "timestep_spacing",
      "steps_offset",
      "rescale_betas_zero_snr"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "timesteps"
    ],
    "_get_variance": [
      "self",
      "t",
      "predicted_variance",
      "variance_type"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "batch_step_no_noise": [
      "self",
      "model_output",
      "timesteps",
      "sample"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "get_velocity": [
      "self",
      "sample",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ],
    "previous_timestep": [
      "self",
      "timestep"
    ]
  },
  "EDMDPMSolverMultistepScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "sigma_min",
      "sigma_max",
      "sigma_data",
      "sigma_schedule",
      "num_train_timesteps",
      "prediction_type",
      "rho",
      "solver_order",
      "thresholding",
      "dynamic_thresholding_ratio",
      "sample_max_value",
      "algorithm_type",
      "solver_type",
      "lower_order_final",
      "euler_at_final",
      "final_sigmas_type"
    ],
    "init_noise_sigma": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "precondition_inputs": [
      "self",
      "sample",
      "sigma"
    ],
    "precondition_noise": [
      "self",
      "sigma"
    ],
    "precondition_outputs": [
      "self",
      "sample",
      "model_output",
      "sigma"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "_compute_karras_sigmas": [
      "self",
      "ramp",
      "sigma_min",
      "sigma_max"
    ],
    "_compute_exponential_sigmas": [
      "self",
      "ramp",
      "sigma_min",
      "sigma_max"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_sigma_to_alpha_sigma_t": [
      "self",
      "sigma"
    ],
    "convert_model_output": [
      "self",
      "model_output",
      "sample"
    ],
    "dpm_solver_first_order_update": [
      "self",
      "model_output",
      "sample",
      "noise"
    ],
    "multistep_dpm_solver_second_order_update": [
      "self",
      "model_output_list",
      "sample",
      "noise"
    ],
    "multistep_dpm_solver_third_order_update": [
      "self",
      "model_output_list",
      "sample"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "_get_conditioning_c_in": [
      "self",
      "sigma"
    ],
    "__len__": [
      "self"
    ]
  },
  "DPMSolverSDESchedulerOutput": {},
  "BatchedBrownianTree": {
    "__init__": [
      "self",
      "x",
      "t0",
      "t1",
      "seed"
    ],
    "sort": [
      "a",
      "b"
    ],
    "__call__": [
      "self",
      "t0",
      "t1"
    ]
  },
  "BrownianTreeNoiseSampler": {
    "__init__": [
      "self",
      "x",
      "sigma_min",
      "sigma_max",
      "seed",
      "transform"
    ],
    "__call__": [
      "self",
      "sigma",
      "sigma_next"
    ]
  },
  "DPMSolverSDEScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "prediction_type",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "noise_sampler_seed",
      "timestep_spacing",
      "steps_offset"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "init_noise_sigma": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "num_train_timesteps"
    ],
    "_second_order_timesteps": [
      "self",
      "sigmas",
      "log_sigmas"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "state_in_first_order": [
      "self"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "return_dict",
      "s_noise"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "_dummy_modules": [],
  "PNDMScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "skip_prk_steps",
      "set_alpha_to_one",
      "prediction_type",
      "timestep_spacing",
      "steps_offset"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "step_prk": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "step_plms": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "scale_model_input": [
      "self",
      "sample"
    ],
    "_get_prev_sample": [
      "self",
      "sample",
      "timestep",
      "prev_timestep",
      "model_output"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "LMSDiscreteSchedulerState": {
    "create": [
      "cls",
      "common",
      "init_noise_sigma",
      "timesteps",
      "sigmas"
    ]
  },
  "FlaxLMSSchedulerOutput": {},
  "FlaxLMSDiscreteScheduler": {
    "_compatibles": [],
    "has_state": [
      "self"
    ],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "prediction_type",
      "dtype"
    ],
    "create_state": [
      "self",
      "common"
    ],
    "scale_model_input": [
      "self",
      "state",
      "sample",
      "timestep"
    ],
    "get_lms_coefficient": [
      "self",
      "state",
      "order",
      "t",
      "current_order"
    ],
    "set_timesteps": [
      "self",
      "state",
      "num_inference_steps",
      "shape"
    ],
    "step": [
      "self",
      "state",
      "model_output",
      "timestep",
      "sample",
      "order",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "state",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "EulerAncestralDiscreteSchedulerOutput": {},
  "EulerAncestralDiscreteScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "prediction_type",
      "timestep_spacing",
      "steps_offset",
      "rescale_betas_zero_snr"
    ],
    "init_noise_sigma": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "DPMSolverMultistepScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "solver_order",
      "prediction_type",
      "thresholding",
      "dynamic_thresholding_ratio",
      "sample_max_value",
      "algorithm_type",
      "solver_type",
      "lower_order_final",
      "euler_at_final",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "use_lu_lambdas",
      "use_flow_sigmas",
      "flow_shift",
      "final_sigmas_type",
      "lambda_min_clipped",
      "variance_type",
      "timestep_spacing",
      "steps_offset",
      "rescale_betas_zero_snr",
      "use_dynamic_shifting",
      "time_shift_type"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "mu",
      "timesteps"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_sigma_to_alpha_sigma_t": [
      "self",
      "sigma"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_lu": [
      "self",
      "in_lambdas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "convert_model_output": [
      "self",
      "model_output"
    ],
    "dpm_solver_first_order_update": [
      "self",
      "model_output"
    ],
    "multistep_dpm_solver_second_order_update": [
      "self",
      "model_output_list"
    ],
    "multistep_dpm_solver_third_order_update": [
      "self",
      "model_output_list"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "variance_noise",
      "return_dict"
    ],
    "scale_model_input": [
      "self",
      "sample"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "gumbel_noise": [
    "t",
    "generator"
  ],
  "mask_by_random_topk": [
    "mask_len",
    "probs",
    "temperature",
    "generator"
  ],
  "AmusedSchedulerOutput": {},
  "AmusedScheduler": {
    "order": [],
    "__init__": [
      "self",
      "mask_token_id",
      "masking_schedule"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "temperature",
      "device"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "starting_mask_ratio",
      "generator",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "sample",
      "timesteps",
      "generator"
    ]
  },
  "CMStochasticIterativeSchedulerOutput": {},
  "CMStochasticIterativeScheduler": {
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "sigma_min",
      "sigma_max",
      "sigma_data",
      "s_noise",
      "rho",
      "clip_denoised"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "sigma_to_t": [
      "self",
      "sigmas"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "timesteps"
    ],
    "_convert_to_karras": [
      "self",
      "ramp"
    ],
    "get_scalings": [
      "self",
      "sigma"
    ],
    "get_scalings_for_boundary_condition": [
      "self",
      "sigma"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "CosineDPMSolverMultistepScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "sigma_min",
      "sigma_max",
      "sigma_data",
      "sigma_schedule",
      "num_train_timesteps",
      "solver_order",
      "prediction_type",
      "rho",
      "solver_type",
      "lower_order_final",
      "euler_at_final",
      "final_sigmas_type"
    ],
    "init_noise_sigma": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "precondition_inputs": [
      "self",
      "sample",
      "sigma"
    ],
    "precondition_noise": [
      "self",
      "sigma"
    ],
    "precondition_outputs": [
      "self",
      "sample",
      "model_output",
      "sigma"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "_compute_karras_sigmas": [
      "self",
      "ramp",
      "sigma_min",
      "sigma_max"
    ],
    "_compute_exponential_sigmas": [
      "self",
      "ramp",
      "sigma_min",
      "sigma_max"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_sigma_to_alpha_sigma_t": [
      "self",
      "sigma"
    ],
    "convert_model_output": [
      "self",
      "model_output",
      "sample"
    ],
    "dpm_solver_first_order_update": [
      "self",
      "model_output",
      "sample",
      "noise"
    ],
    "multistep_dpm_solver_second_order_update": [
      "self",
      "model_output_list",
      "sample",
      "noise"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "_get_conditioning_c_in": [
      "self",
      "sigma"
    ],
    "__len__": [
      "self"
    ]
  },
  "LCMSchedulerOutput": {},
  "LCMScheduler": {
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "original_inference_steps",
      "clip_sample",
      "clip_sample_range",
      "set_alpha_to_one",
      "steps_offset",
      "prediction_type",
      "thresholding",
      "dynamic_thresholding_ratio",
      "sample_max_value",
      "timestep_spacing",
      "timestep_scaling",
      "rescale_betas_zero_snr"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "original_inference_steps",
      "timesteps",
      "strength"
    ],
    "get_scalings_for_boundary_condition_discrete": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "get_velocity": [
      "self",
      "sample",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ],
    "previous_timestep": [
      "self",
      "timestep"
    ]
  },
  "SCMSchedulerOutput": {},
  "SCMScheduler": {
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "prediction_type",
      "sigma_data"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "timesteps",
      "device",
      "max_timesteps",
      "intermediate_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "__len__": [
      "self"
    ]
  },
  "KDPM2AncestralDiscreteSchedulerOutput": {},
  "KDPM2AncestralDiscreteScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "prediction_type",
      "timestep_spacing",
      "steps_offset"
    ],
    "init_noise_sigma": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "num_train_timesteps"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "state_in_first_order": [
      "self"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "EulerDiscreteSchedulerOutput": {},
  "EulerDiscreteScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "prediction_type",
      "interpolation_type",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "sigma_min",
      "sigma_max",
      "timestep_spacing",
      "timestep_type",
      "steps_offset",
      "rescale_betas_zero_snr",
      "final_sigmas_type"
    ],
    "init_noise_sigma": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "timesteps",
      "sigmas"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "s_churn",
      "s_tmin",
      "s_tmax",
      "s_noise",
      "generator",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "get_velocity": [
      "self",
      "sample",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "IPNDMScheduler": {
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "trained_betas"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "scale_model_input": [
      "self",
      "sample"
    ],
    "_get_prev_sample": [
      "self",
      "sample",
      "timestep_index",
      "prev_timestep_index",
      "ets"
    ],
    "__len__": [
      "self"
    ]
  },
  "UniPCMultistepScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "solver_order",
      "prediction_type",
      "thresholding",
      "dynamic_thresholding_ratio",
      "sample_max_value",
      "predict_x0",
      "solver_type",
      "lower_order_final",
      "disable_corrector",
      "solver_p",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "use_flow_sigmas",
      "flow_shift",
      "timestep_spacing",
      "steps_offset",
      "final_sigmas_type",
      "rescale_betas_zero_snr",
      "use_dynamic_shifting",
      "time_shift_type"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "mu"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_sigma_to_alpha_sigma_t": [
      "self",
      "sigma"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "convert_model_output": [
      "self",
      "model_output"
    ],
    "multistep_uni_p_bh_update": [
      "self",
      "model_output"
    ],
    "multistep_uni_c_bh_update": [
      "self",
      "this_model_output"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "scale_model_input": [
      "self",
      "sample"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "DDIMSchedulerState": {
    "create": [
      "cls",
      "common",
      "final_alpha_cumprod",
      "init_noise_sigma",
      "timesteps"
    ]
  },
  "FlaxDDIMSchedulerOutput": {},
  "FlaxDDIMScheduler": {
    "_compatibles": [],
    "has_state": [
      "self"
    ],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "clip_sample",
      "clip_sample_range",
      "set_alpha_to_one",
      "steps_offset",
      "prediction_type",
      "dtype"
    ],
    "create_state": [
      "self",
      "common"
    ],
    "scale_model_input": [
      "self",
      "state",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "state",
      "num_inference_steps",
      "shape"
    ],
    "_get_variance": [
      "self",
      "state",
      "timestep",
      "prev_timestep"
    ],
    "step": [
      "self",
      "state",
      "model_output",
      "timestep",
      "sample",
      "eta",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "state",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "get_velocity": [
      "self",
      "state",
      "sample",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "DPMSolverMultistepInverseScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "solver_order",
      "prediction_type",
      "thresholding",
      "dynamic_thresholding_ratio",
      "sample_max_value",
      "algorithm_type",
      "solver_type",
      "lower_order_final",
      "euler_at_final",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "use_flow_sigmas",
      "flow_shift",
      "lambda_min_clipped",
      "variance_type",
      "timestep_spacing",
      "steps_offset"
    ],
    "step_index": [
      "self"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_sigma_to_alpha_sigma_t": [
      "self",
      "sigma"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "convert_model_output": [
      "self",
      "model_output"
    ],
    "dpm_solver_first_order_update": [
      "self",
      "model_output"
    ],
    "multistep_dpm_solver_second_order_update": [
      "self",
      "model_output_list"
    ],
    "multistep_dpm_solver_third_order_update": [
      "self",
      "model_output_list"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "variance_noise",
      "return_dict"
    ],
    "scale_model_input": [
      "self",
      "sample"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "KarrasVeSchedulerState": {
    "create": [
      "cls"
    ]
  },
  "FlaxKarrasVeOutput": {},
  "FlaxKarrasVeScheduler": {
    "has_state": [
      "self"
    ],
    "__init__": [
      "self",
      "sigma_min",
      "sigma_max",
      "s_noise",
      "s_churn",
      "s_min",
      "s_max"
    ],
    "create_state": [
      "self"
    ],
    "set_timesteps": [
      "self",
      "state",
      "num_inference_steps",
      "shape"
    ],
    "add_noise_to_input": [
      "self",
      "state",
      "sample",
      "sigma",
      "key"
    ],
    "step": [
      "self",
      "state",
      "model_output",
      "sigma_hat",
      "sigma_prev",
      "sample_hat",
      "return_dict"
    ],
    "step_correct": [
      "self",
      "state",
      "model_output",
      "sigma_hat",
      "sigma_prev",
      "sample_hat",
      "sample_prev",
      "derivative",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "state",
      "original_samples",
      "noise",
      "timesteps"
    ]
  },
  "EulerDiscreteSchedulerState": {
    "create": [
      "cls",
      "common",
      "init_noise_sigma",
      "timesteps",
      "sigmas"
    ]
  },
  "FlaxEulerDiscreteSchedulerOutput": {},
  "FlaxEulerDiscreteScheduler": {
    "_compatibles": [],
    "has_state": [
      "self"
    ],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "prediction_type",
      "timestep_spacing",
      "dtype"
    ],
    "create_state": [
      "self",
      "common"
    ],
    "scale_model_input": [
      "self",
      "state",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "state",
      "num_inference_steps",
      "shape"
    ],
    "step": [
      "self",
      "state",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "state",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "LMSDiscreteSchedulerOutput": {},
  "LMSDiscreteScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "prediction_type",
      "timestep_spacing",
      "steps_offset"
    ],
    "init_noise_sigma": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "get_lms_coefficient": [
      "self",
      "order",
      "t",
      "current_order"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "order",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "DPMSolverSinglestepScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "solver_order",
      "prediction_type",
      "thresholding",
      "dynamic_thresholding_ratio",
      "sample_max_value",
      "algorithm_type",
      "solver_type",
      "lower_order_final",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "use_flow_sigmas",
      "flow_shift",
      "final_sigmas_type",
      "lambda_min_clipped",
      "variance_type",
      "use_dynamic_shifting",
      "time_shift_type"
    ],
    "get_order_list": [
      "self",
      "num_inference_steps"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "mu",
      "timesteps"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_sigma_to_alpha_sigma_t": [
      "self",
      "sigma"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "convert_model_output": [
      "self",
      "model_output"
    ],
    "dpm_solver_first_order_update": [
      "self",
      "model_output"
    ],
    "singlestep_dpm_solver_second_order_update": [
      "self",
      "model_output_list"
    ],
    "singlestep_dpm_solver_third_order_update": [
      "self",
      "model_output_list"
    ],
    "singlestep_dpm_solver_update": [
      "self",
      "model_output_list"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "generator",
      "return_dict"
    ],
    "scale_model_input": [
      "self",
      "sample"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "ScoreSdeVeSchedulerState": {
    "create": [
      "cls"
    ]
  },
  "FlaxSdeVeOutput": {},
  "FlaxScoreSdeVeScheduler": {
    "has_state": [
      "self"
    ],
    "__init__": [
      "self",
      "num_train_timesteps",
      "snr",
      "sigma_min",
      "sigma_max",
      "sampling_eps",
      "correct_steps"
    ],
    "create_state": [
      "self"
    ],
    "set_timesteps": [
      "self",
      "state",
      "num_inference_steps",
      "shape",
      "sampling_eps"
    ],
    "set_sigmas": [
      "self",
      "state",
      "num_inference_steps",
      "sigma_min",
      "sigma_max",
      "sampling_eps"
    ],
    "get_adjacent_sigma": [
      "self",
      "state",
      "timesteps",
      "t"
    ],
    "step_pred": [
      "self",
      "state",
      "model_output",
      "timestep",
      "sample",
      "key",
      "return_dict"
    ],
    "step_correct": [
      "self",
      "state",
      "model_output",
      "sample",
      "key",
      "return_dict"
    ],
    "__len__": [
      "self"
    ]
  },
  "HeunDiscreteSchedulerOutput": {},
  "HeunDiscreteScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "prediction_type",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "clip_sample",
      "clip_sample_range",
      "timestep_spacing",
      "steps_offset"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "init_noise_sigma": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "num_train_timesteps",
      "timesteps"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "state_in_first_order": [
      "self"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "DDIMInverseScheduler": {
    "order": [],
    "ignore_for_config": [],
    "_deprecated_kwargs": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "clip_sample",
      "set_alpha_to_one",
      "steps_offset",
      "prediction_type",
      "clip_sample_range",
      "timestep_spacing",
      "rescale_betas_zero_snr"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "__len__": [
      "self"
    ]
  },
  "EDMEulerSchedulerOutput": {},
  "EDMEulerScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "sigma_min",
      "sigma_max",
      "sigma_data",
      "sigma_schedule",
      "num_train_timesteps",
      "prediction_type",
      "rho",
      "final_sigmas_type"
    ],
    "init_noise_sigma": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "precondition_inputs": [
      "self",
      "sample",
      "sigma"
    ],
    "precondition_noise": [
      "self",
      "sigma"
    ],
    "precondition_outputs": [
      "self",
      "sample",
      "model_output",
      "sigma"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "sigmas"
    ],
    "_compute_karras_sigmas": [
      "self",
      "ramp",
      "sigma_min",
      "sigma_max"
    ],
    "_compute_exponential_sigmas": [
      "self",
      "ramp",
      "sigma_min",
      "sigma_max"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "s_churn",
      "s_tmin",
      "s_tmax",
      "s_noise",
      "generator",
      "return_dict",
      "pred_original_sample"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "_get_conditioning_c_in": [
      "self",
      "sigma"
    ],
    "__len__": [
      "self"
    ]
  },
  "KDPM2DiscreteSchedulerOutput": {},
  "KDPM2DiscreteScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "prediction_type",
      "timestep_spacing",
      "steps_offset"
    ],
    "init_noise_sigma": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "num_train_timesteps"
    ],
    "state_in_first_order": [
      "self"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "PNDMSchedulerState": {
    "create": [
      "cls",
      "common",
      "final_alpha_cumprod",
      "init_noise_sigma",
      "timesteps"
    ]
  },
  "FlaxPNDMSchedulerOutput": {},
  "FlaxPNDMScheduler": {
    "_compatibles": [],
    "has_state": [
      "self"
    ],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "skip_prk_steps",
      "set_alpha_to_one",
      "steps_offset",
      "prediction_type",
      "dtype"
    ],
    "create_state": [
      "self",
      "common"
    ],
    "set_timesteps": [
      "self",
      "state",
      "num_inference_steps",
      "shape"
    ],
    "scale_model_input": [
      "self",
      "state",
      "sample",
      "timestep"
    ],
    "step": [
      "self",
      "state",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "step_prk": [
      "self",
      "state",
      "model_output",
      "timestep",
      "sample"
    ],
    "step_plms": [
      "self",
      "state",
      "model_output",
      "timestep",
      "sample"
    ],
    "_get_prev_sample": [
      "self",
      "state",
      "sample",
      "timestep",
      "prev_timestep",
      "model_output"
    ],
    "add_noise": [
      "self",
      "state",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "ScoreSdeVpScheduler": {
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_min",
      "beta_max",
      "sampling_eps"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "step_pred": [
      "self",
      "score",
      "x",
      "t",
      "generator"
    ],
    "__len__": [
      "self"
    ]
  },
  "_dummy_objects": [],
  "KarrasVeOutput": {},
  "KarrasVeScheduler": {
    "order": [],
    "__init__": [
      "self",
      "sigma_min",
      "sigma_max",
      "s_noise",
      "s_churn",
      "s_min",
      "s_max"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device"
    ],
    "add_noise_to_input": [
      "self",
      "sample",
      "sigma",
      "generator"
    ],
    "step": [
      "self",
      "model_output",
      "sigma_hat",
      "sigma_prev",
      "sample_hat",
      "return_dict"
    ],
    "step_correct": [
      "self",
      "model_output",
      "sigma_hat",
      "sigma_prev",
      "sample_hat",
      "sample_prev",
      "derivative",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ]
  },
  "is_tensor": [
    "x"
  ],
  "BaseOutput": {
    "__init_subclass__": [
      "cls"
    ],
    "__post_init__": [
      "self"
    ],
    "__delitem__": [
      "self"
    ],
    "setdefault": [
      "self"
    ],
    "pop": [
      "self"
    ],
    "update": [
      "self"
    ],
    "__getitem__": [
      "self",
      "k"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "__reduce__": [
      "self"
    ],
    "to_tuple": [
      "self"
    ]
  },
  "replace_example_docstring": [
    "example_docstring"
  ],
  "_is_valid_type": [
    "obj",
    "class_or_tuple"
  ],
  "_get_detailed_type": [
    "obj"
  ],
  "AdaptiveProjectedGuidance": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AdaptiveProjectedMixGuidance": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoGuidance": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "BaseGuidance": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ClassifierFreeGuidance": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ClassifierFreeZeroStarGuidance": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FrequencyDecoupledGuidance": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "PerturbedAttentionGuidance": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SkipLayerGuidance": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SmoothedEnergyGuidance": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "TangentialClassifierFreeGuidance": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FasterCacheConfig": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FirstBlockCacheConfig": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HookRegistry": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LayerSkipConfig": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "PyramidAttentionBroadcastConfig": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SmoothedEnergyGuidanceConfig": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "TaylorSeerCacheConfig": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "apply_faster_cache": [],
  "apply_first_block_cache": [],
  "apply_layer_skip": [],
  "apply_pyramid_attention_broadcast": [],
  "apply_taylorseer_cache": [],
  "AllegroTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AsymmetricAutoencoderKL": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AttentionBackendName": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AuraFlowTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderDC": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKL": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLAllegro": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLCogVideoX": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLCosmos": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLFlux2": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLHunyuanImage": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLHunyuanImageRefiner": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLHunyuanVideo": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLHunyuanVideo15": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLLTXVideo": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLMagvit": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLMochi": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLQwenImage": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLTemporalDecoder": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderKLWan": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderOobleck": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoencoderTiny": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "BriaFiboTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "BriaTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CacheMixin": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ChromaTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ChronoEditTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CogVideoXTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CogView3PlusTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CogView4Transformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ConsisIDTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ConsistencyDecoderVAE": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ContextParallelConfig": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ControlNetModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ControlNetUnionModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ControlNetXSAdapter": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CosmosTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "DiTTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "EasyAnimateTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Flux2Transformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxControlNetModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxMultiControlNetModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HiDreamImageTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanDiT2DControlNetModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanDiT2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanDiT2DMultiControlNetModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanImageTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanVideo15Transformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanVideoFramepackTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanVideoTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "I2VGenXLUNet": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Kandinsky3UNet": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Kandinsky5Transformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LatteTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LTXVideoTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Lumina2Transformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LuminaNextDiT2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "MochiTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ModelMixin": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "MotionAdapter": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "MultiAdapter": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "MultiControlNetModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "OmniGenTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "OvisImageTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ParallelConfig": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "PixArtTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "PriorTransformer": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "PRXTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageControlNetModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageMultiControlNetModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SanaControlNetModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SanaTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SanaVideoTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SD3ControlNetModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SD3MultiControlNetModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SD3Transformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SkyReelsV2Transformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SparseControlNetModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableAudioDiTModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "T2IAdapter": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "T5FilmDecoder": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Transformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "TransformerTemporalModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "UNet1DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "UNet2DConditionModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "UNet2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "UNet3DConditionModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "UNetControlNetXSModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "UNetMotionModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "UNetSpatioTemporalConditionModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "UVit2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "VQModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "WanAnimateTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "WanTransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "WanVACETransformer3DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ZImageTransformer2DModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "attention_backend": [],
  "ComponentsManager": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ComponentSpec": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ModularPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ModularPipelineBlocks": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AudioPipelineOutput": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoPipelineForImage2Image": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoPipelineForInpainting": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AutoPipelineForText2Image": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "BlipDiffusionControlNetPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "BlipDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CLIPImageProjection": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ConsistencyModelPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "DanceDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "DDIMPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "DDPMPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "DiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "DiTPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ImagePipelineOutput": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KarrasVePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LDMPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LDMSuperResolutionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "PNDMPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "RePaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ScoreSdeVePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionMixin": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "_device_agnostic_dispatch": [
    "device",
    "dispatch_table"
  ],
  "backend_manual_seed": [
    "device",
    "seed"
  ],
  "backend_synchronize": [
    "device"
  ],
  "backend_empty_cache": [
    "device"
  ],
  "backend_device_count": [
    "device"
  ],
  "backend_reset_peak_memory_stats": [
    "device"
  ],
  "backend_reset_max_memory_allocated": [
    "device"
  ],
  "backend_max_memory_allocated": [
    "device"
  ],
  "backend_supports_training": [
    "device"
  ],
  "randn_tensor": [
    "shape",
    "generator",
    "device",
    "dtype",
    "layout"
  ],
  "is_compiled_module": [
    "module"
  ],
  "unwrap_module": [
    "module"
  ],
  "fourier_filter": [
    "x_in",
    "threshold",
    "scale"
  ],
  "apply_freeu": [
    "resolution_idx",
    "hidden_states",
    "res_hidden_states"
  ],
  "get_torch_cuda_device_capability": [],
  "get_device": [],
  "empty_device_cache": [
    "device_type"
  ],
  "device_synchronize": [
    "device_type"
  ],
  "enable_full_determinism": [],
  "disable_full_determinism": [],
  "FluxAutoBlocks": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxKontextAutoBlocks": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxKontextModularPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxModularPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageAutoBlocks": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageEditAutoBlocks": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageEditModularPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageEditPlusAutoBlocks": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageEditPlusModularPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageModularPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLAutoBlocks": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLModularPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Wan22AutoBlocks": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "WanAutoBlocks": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "WanModularPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AllegroPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AltDiffusionImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AltDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AmusedImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AmusedInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AmusedPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AnimateDiffControlNetPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AnimateDiffPAGPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AnimateDiffPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AnimateDiffSDXLPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AnimateDiffSparseControlNetPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AnimateDiffVideoToVideoControlNetPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AnimateDiffVideoToVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AudioLDM2Pipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AudioLDM2ProjectionModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AudioLDM2UNet2DConditionModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AudioLDMPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "AuraFlowPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "BriaFiboPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "BriaPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ChromaImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ChromaPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ChronoEditPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CogVideoXFunControlPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CogVideoXImageToVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CogVideoXPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CogVideoXVideoToVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CogView3PlusPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CogView4ControlPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CogView4Pipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ConsisIDPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Cosmos2TextToImagePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Cosmos2VideoToWorldPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CosmosTextToWorldPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CosmosVideoToWorldPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "CycleDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "EasyAnimateControlPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "EasyAnimateInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "EasyAnimatePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Flux2Pipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxControlImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxControlInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxControlNetImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxControlNetInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxControlNetPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxControlPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxFillPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxKontextInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxKontextPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FluxPriorReduxPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HiDreamImagePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanDiTControlNetPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanDiTPAGPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanDiTPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanImagePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanImageRefinerPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanSkyreelsImageToVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanVideo15ImageToVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanVideo15Pipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanVideoFramepackPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanVideoImageToVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "HunyuanVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "I2VGenXLPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "IFImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "IFImg2ImgSuperResolutionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "IFInpaintingPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "IFInpaintingSuperResolutionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "IFPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "IFSuperResolutionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ImageTextPipelineOutput": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Kandinsky3Img2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Kandinsky3Pipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Kandinsky5I2IPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Kandinsky5I2VPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Kandinsky5T2IPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Kandinsky5T2VPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyCombinedPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyImg2ImgCombinedPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyInpaintCombinedPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyPriorPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyV22CombinedPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyV22ControlnetImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyV22ControlnetPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyV22Img2ImgCombinedPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyV22Img2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyV22InpaintCombinedPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyV22InpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyV22Pipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyV22PriorEmb2EmbPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KandinskyV22PriorPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LatentConsistencyModelImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LatentConsistencyModelPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LattePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LDMTextToImagePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LEditsPPPipelineStableDiffusion": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LEditsPPPipelineStableDiffusionXL": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LTXConditionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LTXImageToVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LTXLatentUpsamplePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LTXPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LucyEditPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Lumina2Pipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Lumina2Text2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LuminaPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "LuminaText2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "MarigoldDepthPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "MarigoldIntrinsicsPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "MarigoldNormalsPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "MochiPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "MusicLDMPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "OmniGenPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "OvisImagePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "PaintByExamplePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "PIAPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "PixArtAlphaPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "PixArtSigmaPAGPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "PixArtSigmaPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "PRXPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageControlNetInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageControlNetPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageEditInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageEditPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageEditPlusPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImageInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "QwenImagePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ReduxImageEncoder": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SanaControlNetPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SanaImageToVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SanaPAGPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SanaPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SanaSprintImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SanaSprintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SanaVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SemanticStableDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ShapEImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ShapEPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SkyReelsV2DiffusionForcingImageToVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SkyReelsV2DiffusionForcingPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SkyReelsV2DiffusionForcingVideoToVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SkyReelsV2ImageToVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SkyReelsV2Pipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableAudioPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableAudioProjectionModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableCascadeCombinedPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableCascadeDecoderPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableCascadePriorPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusion3ControlNetInpaintingPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusion3ControlNetPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusion3Img2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusion3InpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusion3PAGImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusion3PAGPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusion3Pipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionAdapterPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionAttendAndExcitePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionControlNetImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionControlNetInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionControlNetPAGInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionControlNetPAGPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionControlNetPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionControlNetXSPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionDepth2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionDiffEditPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionGLIGENPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionGLIGENTextImagePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionImageVariationPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionInpaintPipelineLegacy": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionInstructPix2PixPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionLatentUpscalePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionLDM3DPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionModelEditingPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionPAGImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionPAGInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionPAGPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionPanoramaPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionParadigmsPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionPipelineSafe": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionPix2PixZeroPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionSAGPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionUpscalePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLAdapterPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLControlNetImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLControlNetInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLControlNetPAGImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLControlNetPAGPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLControlNetPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLControlNetUnionImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLControlNetUnionInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLControlNetUnionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLControlNetXSPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLInstructPix2PixPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLPAGImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLPAGInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLPAGPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableUnCLIPImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableUnCLIPPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableVideoDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "TextToVideoSDPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "TextToVideoZeroPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "TextToVideoZeroSDXLPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "UnCLIPImageVariationPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "UnCLIPPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "UniDiffuserModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "UniDiffuserPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "UniDiffuserTextDecoder": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "VersatileDiffusionDualGuidedPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "VersatileDiffusionImageVariationPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "VersatileDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "VersatileDiffusionTextToImagePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "VideoToVideoSDPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "VisualClozeGenerationPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "VisualClozePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "VQDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "WanAnimatePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "WanImageToVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "WanPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "WanVACEPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "WanVideoToVideoPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "WuerstchenCombinedPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "WuerstchenDecoderPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "WuerstchenPriorPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ZImageImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ZImagePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "detect_image_type": [
    "data"
  ],
  "check_inputs_decode": [
    "endpoint",
    "tensor",
    "processor",
    "do_scaling",
    "scaling_factor",
    "shift_factor",
    "output_type",
    "return_type",
    "image_format",
    "partial_postprocess",
    "input_tensor_type",
    "output_tensor_type",
    "height",
    "width"
  ],
  "postprocess_decode": [
    "response",
    "processor",
    "output_type",
    "return_type",
    "partial_postprocess"
  ],
  "prepare_decode": [
    "tensor",
    "processor",
    "do_scaling",
    "scaling_factor",
    "shift_factor",
    "output_type",
    "image_format",
    "partial_postprocess",
    "height",
    "width"
  ],
  "remote_decode": [
    "endpoint",
    "tensor",
    "processor",
    "do_scaling",
    "scaling_factor",
    "shift_factor",
    "output_type",
    "return_type",
    "image_format",
    "partial_postprocess",
    "input_tensor_type",
    "output_tensor_type",
    "height",
    "width"
  ],
  "check_inputs_encode": [
    "endpoint",
    "image",
    "scaling_factor",
    "shift_factor"
  ],
  "postprocess_encode": [
    "response"
  ],
  "prepare_encode": [
    "image",
    "scaling_factor",
    "shift_factor"
  ],
  "remote_encode": [
    "endpoint",
    "image",
    "scaling_factor",
    "shift_factor"
  ],
  "apply_forward_hook": [
    "method"
  ],
  "OnnxRuntimeModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "global_rng": [],
  "buffered_writer": [
    "raw_f"
  ],
  "export_to_gif": [
    "image",
    "output_gif_path",
    "fps"
  ],
  "export_to_ply": [
    "mesh",
    "output_ply_path"
  ],
  "export_to_obj": [
    "mesh",
    "output_obj_path"
  ],
  "_legacy_export_to_video": [
    "video_frames",
    "output_video_path",
    "fps"
  ],
  "export_to_video": [
    "video_frames",
    "output_video_path",
    "fps",
    "quality",
    "bitrate",
    "macro_block_size"
  ],
  "OnnxStableDiffusionImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "OnnxStableDiffusionInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "OnnxStableDiffusionInpaintPipelineLegacy": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "OnnxStableDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "OnnxStableDiffusionUpscalePipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionOnnxPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "MODEL_CARD_TEMPLATE_PATH": [],
  "SESSION_ID": [],
  "http_user_agent": [
    "user_agent"
  ],
  "load_or_create_model_card": [
    "repo_id_or_path",
    "token",
    "is_pipeline",
    "from_training",
    "model_description",
    "base_model",
    "prompt",
    "license",
    "widget",
    "inference"
  ],
  "populate_model_card": [
    "model_card",
    "tags"
  ],
  "extract_commit_hash": [
    "resolved_file",
    "commit_hash"
  ],
  "_add_variant": [
    "weights_name",
    "variant"
  ],
  "_get_model_file": [
    "pretrained_model_name_or_path"
  ],
  "_get_checkpoint_shard_files": [
    "pretrained_model_name_or_path",
    "index_filename",
    "cache_dir",
    "proxies",
    "local_files_only",
    "token",
    "user_agent",
    "revision",
    "subfolder",
    "dduf_entries"
  ],
  "_check_legacy_sharding_variant_format": [
    "folder",
    "filenames",
    "variant"
  ],
  "PushToHubMixin": {
    "_upload_folder": [
      "self",
      "working_dir",
      "repo_id",
      "token",
      "commit_message",
      "create_pr",
      "subfolder"
    ],
    "push_to_hub": [
      "self",
      "repo_id",
      "commit_message",
      "private",
      "token",
      "create_pr",
      "safe_serialization",
      "variant",
      "subfolder"
    ]
  },
  "_TRANSFORMERS_CLASS_REMAPPING": [],
  "_maybe_remap_transformers_class": [
    "class_name"
  ],
  "deprecate": [],
  "AudioDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "Mel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "check_min_version": [
    "min_version"
  ],
  "FlaxControlNetModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FlaxModelMixin": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FlaxUNet2DConditionModel": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FlaxAutoencoderKL": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FlaxDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "SpectrogramDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KolorsImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KolorsPAGPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "KolorsPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "COMMUNITY_PIPELINES_MIRROR_ID": [],
  "TIME_OUT_REMOTE_CODE": [],
  "_HF_REMOTE_CODE_LOCK": [],
  "get_diffusers_versions": [],
  "init_hf_modules": [],
  "create_dynamic_module": [
    "name"
  ],
  "get_relative_imports": [
    "module_file"
  ],
  "get_relative_import_files": [
    "module_file"
  ],
  "check_imports": [
    "filename"
  ],
  "resolve_trust_remote_code": [
    "trust_remote_code",
    "model_name",
    "has_remote_code"
  ],
  "get_class_in_module": [
    "class_name",
    "module_path",
    "force_reload"
  ],
  "find_pipeline_class": [
    "loaded_module"
  ],
  "get_cached_module_file": [
    "pretrained_model_name_or_path",
    "module_file",
    "subfolder",
    "cache_dir",
    "force_download",
    "proxies",
    "token",
    "revision",
    "local_files_only",
    "local_dir"
  ],
  "get_class_from_dynamic_module": [
    "pretrained_model_name_or_path",
    "module_file",
    "subfolder",
    "class_name",
    "cache_dir",
    "force_download",
    "proxies",
    "token",
    "revision",
    "local_files_only",
    "local_dir"
  ],
  "ReturnNameVisitor": {
    "__init__": [
      "self"
    ],
    "visit_Return": [
      "self",
      "node"
    ],
    "_determine_parent_module": [
      "self",
      "cls"
    ],
    "get_ast_tree": [
      "self",
      "cls",
      "attribute_name"
    ]
  },
  "load_image": [
    "image",
    "convert_method"
  ],
  "load_video": [
    "video",
    "convert_method"
  ],
  "get_module_from_name": [
    "module",
    "tensor_name"
  ],
  "get_submodule_by_name": [
    "root_module",
    "module_path"
  ],
  "ENV_VARS_TRUE_VALUES": [],
  "ENV_VARS_TRUE_AND_AUTO_VALUES": [],
  "USE_TF": [],
  "USE_TORCH": [],
  "USE_JAX": [],
  "USE_SAFETENSORS": [],
  "DIFFUSERS_SLOW_IMPORT": [],
  "STR_OPERATION_TO_FUNC": [],
  "_is_google_colab": [],
  "_is_package_available": [
    "pkg_name",
    "get_dist_name"
  ],
  "_jax_version": [],
  "_flax_version": [],
  "_onnxruntime_version": [],
  "_onnx_available": [],
  "_bs4_available": [],
  "_invisible_watermark_available": [],
  "is_torch_available": [],
  "is_torch_xla_available": [],
  "is_torch_npu_available": [],
  "is_torch_mlu_available": [],
  "is_flax_available": [],
  "is_transformers_available": [],
  "is_inflect_available": [],
  "is_unidecode_available": [],
  "is_onnx_available": [],
  "is_opencv_available": [],
  "is_scipy_available": [],
  "is_librosa_available": [],
  "is_xformers_available": [],
  "is_accelerate_available": [],
  "is_kernels_available": [],
  "is_k_diffusion_available": [],
  "is_note_seq_available": [],
  "is_wandb_available": [],
  "is_tensorboard_available": [],
  "is_compel_available": [],
  "is_ftfy_available": [],
  "is_bs4_available": [],
  "is_torchsde_available": [],
  "is_invisible_watermark_available": [],
  "is_peft_available": [],
  "is_torchvision_available": [],
  "is_matplotlib_available": [],
  "is_safetensors_available": [],
  "is_bitsandbytes_available": [],
  "is_google_colab": [],
  "is_sentencepiece_available": [],
  "is_imageio_available": [],
  "is_gguf_available": [],
  "is_torchao_available": [],
  "is_optimum_quanto_available": [],
  "is_nvidia_modelopt_available": [],
  "is_timm_available": [],
  "is_pytorch_retinaface_available": [],
  "is_better_profanity_available": [],
  "is_nltk_available": [],
  "is_cosmos_guardrail_available": [],
  "is_hpu_available": [],
  "is_sageattention_available": [],
  "is_flash_attn_available": [],
  "is_flash_attn_3_available": [],
  "is_aiter_available": [],
  "is_kornia_available": [],
  "FLAX_IMPORT_ERROR": [],
  "INFLECT_IMPORT_ERROR": [],
  "PYTORCH_IMPORT_ERROR": [],
  "ONNX_IMPORT_ERROR": [],
  "OPENCV_IMPORT_ERROR": [],
  "SCIPY_IMPORT_ERROR": [],
  "LIBROSA_IMPORT_ERROR": [],
  "TRANSFORMERS_IMPORT_ERROR": [],
  "UNIDECODE_IMPORT_ERROR": [],
  "K_DIFFUSION_IMPORT_ERROR": [],
  "NOTE_SEQ_IMPORT_ERROR": [],
  "WANDB_IMPORT_ERROR": [],
  "TENSORBOARD_IMPORT_ERROR": [],
  "COMPEL_IMPORT_ERROR": [],
  "BS4_IMPORT_ERROR": [],
  "FTFY_IMPORT_ERROR": [],
  "TORCHSDE_IMPORT_ERROR": [],
  "INVISIBLE_WATERMARK_IMPORT_ERROR": [],
  "PEFT_IMPORT_ERROR": [],
  "SAFETENSORS_IMPORT_ERROR": [],
  "SENTENCEPIECE_IMPORT_ERROR": [],
  "BITSANDBYTES_IMPORT_ERROR": [],
  "IMAGEIO_IMPORT_ERROR": [],
  "GGUF_IMPORT_ERROR": [],
  "TORCHAO_IMPORT_ERROR": [],
  "QUANTO_IMPORT_ERROR": [],
  "PYTORCH_RETINAFACE_IMPORT_ERROR": [],
  "BETTER_PROFANITY_IMPORT_ERROR": [],
  "NLTK_IMPORT_ERROR": [],
  "BACKENDS_MAPPING": [],
  "requires_backends": [
    "obj",
    "backends"
  ],
  "DummyObject": {
    "__getattr__": [
      "cls",
      "key"
    ]
  },
  "compare_versions": [
    "library_or_version",
    "operation",
    "requirement_version"
  ],
  "is_torch_version": [
    "operation",
    "version"
  ],
  "is_torch_xla_version": [
    "operation",
    "version"
  ],
  "is_transformers_version": [
    "operation",
    "version"
  ],
  "is_hf_hub_version": [
    "operation",
    "version"
  ],
  "is_accelerate_version": [
    "operation",
    "version"
  ],
  "is_peft_version": [
    "operation",
    "version"
  ],
  "is_bitsandbytes_version": [
    "operation",
    "version"
  ],
  "is_gguf_version": [
    "operation",
    "version"
  ],
  "is_torchao_version": [
    "operation",
    "version"
  ],
  "is_k_diffusion_version": [
    "operation",
    "version"
  ],
  "is_optimum_quanto_version": [
    "operation",
    "version"
  ],
  "is_nvidia_modelopt_version": [
    "operation",
    "version"
  ],
  "is_xformers_version": [
    "operation",
    "version"
  ],
  "is_sageattention_version": [
    "operation",
    "version"
  ],
  "is_flash_attn_version": [
    "operation",
    "version"
  ],
  "is_aiter_version": [
    "operation",
    "version"
  ],
  "get_objects_from_module": [
    "module"
  ],
  "OptionalDependencyNotAvailable": {},
  "_LazyModule": {
    "__init__": [
      "self",
      "name",
      "module_file",
      "import_structure",
      "module_spec",
      "extra_objects"
    ],
    "__dir__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "_get_module": [
      "self",
      "module_name"
    ],
    "__reduce__": [
      "self"
    ]
  },
  "_required_peft_version": [],
  "_required_transformers_version": [],
  "USE_PEFT_BACKEND": [],
  "BIG_GPU_MEMORY": [],
  "torch_all_close": [
    "a",
    "b"
  ],
  "numpy_cosine_similarity_distance": [
    "a",
    "b"
  ],
  "check_if_dicts_are_equal": [
    "dict1",
    "dict2"
  ],
  "print_tensor_test": [
    "tensor",
    "limit_to_slices",
    "max_torch_print",
    "filename",
    "expected_tensor_name"
  ],
  "get_tests_dir": [
    "append_path"
  ],
  "str_to_bool": [
    "value"
  ],
  "parse_flag_from_env": [
    "key",
    "default"
  ],
  "_run_slow_tests": [],
  "_run_nightly_tests": [],
  "_run_compile_tests": [],
  "floats_tensor": [
    "shape",
    "scale",
    "rng",
    "name"
  ],
  "slow": [
    "test_case"
  ],
  "nightly": [
    "test_case"
  ],
  "is_torch_compile": [
    "test_case"
  ],
  "require_torch": [
    "test_case"
  ],
  "require_torch_2": [
    "test_case"
  ],
  "require_torch_version_greater_equal": [
    "torch_version"
  ],
  "require_torch_version_greater": [
    "torch_version"
  ],
  "require_torch_gpu": [
    "test_case"
  ],
  "require_torch_cuda_compatibility": [
    "expected_compute_capability"
  ],
  "require_torch_accelerator": [
    "test_case"
  ],
  "require_torch_multi_gpu": [
    "test_case"
  ],
  "require_torch_multi_accelerator": [
    "test_case"
  ],
  "require_torch_accelerator_with_fp16": [
    "test_case"
  ],
  "require_torch_accelerator_with_fp64": [
    "test_case"
  ],
  "require_big_gpu_with_torch_cuda": [
    "test_case"
  ],
  "require_big_accelerator": [
    "test_case"
  ],
  "require_torch_accelerator_with_training": [
    "test_case"
  ],
  "skip_mps": [
    "test_case"
  ],
  "require_flax": [
    "test_case"
  ],
  "require_compel": [
    "test_case"
  ],
  "require_onnxruntime": [
    "test_case"
  ],
  "require_note_seq": [
    "test_case"
  ],
  "require_accelerator": [
    "test_case"
  ],
  "require_torchsde": [
    "test_case"
  ],
  "require_peft_backend": [
    "test_case"
  ],
  "require_timm": [
    "test_case"
  ],
  "require_bitsandbytes": [
    "test_case"
  ],
  "require_quanto": [
    "test_case"
  ],
  "require_accelerate": [
    "test_case"
  ],
  "require_peft_version_greater": [
    "peft_version"
  ],
  "require_transformers_version_greater": [
    "transformers_version"
  ],
  "require_accelerate_version_greater": [
    "accelerate_version"
  ],
  "require_bitsandbytes_version_greater": [
    "bnb_version"
  ],
  "require_hf_hub_version_greater": [
    "hf_hub_version"
  ],
  "require_gguf_version_greater_or_equal": [
    "gguf_version"
  ],
  "require_torchao_version_greater_or_equal": [
    "torchao_version"
  ],
  "require_modelopt_version_greater_or_equal": [
    "modelopt_version"
  ],
  "require_kernels_version_greater_or_equal": [
    "kernels_version"
  ],
  "deprecate_after_peft_backend": [
    "test_case"
  ],
  "get_python_version": [],
  "load_numpy": [
    "arry",
    "local_path"
  ],
  "load_pt": [
    "url",
    "map_location",
    "weights_only"
  ],
  "preprocess_image": [
    "image",
    "batch_size"
  ],
  "load_hf_numpy": [
    "path"
  ],
  "pytest_opt_registered": [],
  "pytest_addoption_shared": [
    "parser"
  ],
  "pytest_terminal_summary_main": [
    "tr",
    "id"
  ],
  "is_flaky": [
    "max_attempts",
    "wait_before_retry",
    "description"
  ],
  "run_test_in_subprocess": [
    "test_case",
    "target_func",
    "inputs",
    "timeout"
  ],
  "CaptureLogger": {
    "__init__": [
      "self",
      "logger"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_is_torch_fp16_available": [
    "device"
  ],
  "_is_torch_fp64_available": [
    "device"
  ],
  "DeviceProperties": [],
  "get_device_properties": [],
  "Expectations": {
    "get_expectation": [
      "self"
    ],
    "is_default": [
      "key"
    ],
    "score": [
      "key",
      "other"
    ],
    "find_expectation": [
      "self",
      "key"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_lock": [],
  "log_levels": [],
  "_default_log_level": [],
  "_tqdm_active": [],
  "_get_default_logging_level": [],
  "_get_library_name": [],
  "_get_library_root_logger": [],
  "_configure_library_root_logger": [],
  "_reset_library_root_logger": [],
  "get_log_levels_dict": [],
  "get_logger": [
    "name"
  ],
  "get_verbosity": [],
  "set_verbosity": [
    "verbosity"
  ],
  "set_verbosity_info": [],
  "set_verbosity_warning": [],
  "set_verbosity_debug": [],
  "set_verbosity_error": [],
  "disable_default_handler": [],
  "enable_default_handler": [],
  "add_handler": [
    "handler"
  ],
  "remove_handler": [
    "handler"
  ],
  "disable_propagation": [],
  "enable_propagation": [],
  "enable_explicit_format": [],
  "reset_format": [],
  "warning_advice": [
    "self"
  ],
  "EmptyTqdm": {
    "__init__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "_"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "type_",
      "value",
      "traceback"
    ]
  },
  "_tqdm_cls": {
    "__call__": [
      "self"
    ],
    "set_lock": [
      "self"
    ],
    "get_lock": [
      "self"
    ]
  },
  "tqdm": [],
  "is_progress_bar_enabled": [],
  "enable_progress_bar": [],
  "disable_progress_bar": [],
  "StableDiffusionKDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "StableDiffusionXLKDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "recurse_remove_peft_layers": [
    "model"
  ],
  "scale_lora_layers": [
    "model",
    "weight"
  ],
  "unscale_lora_layers": [
    "model",
    "weight"
  ],
  "get_peft_kwargs": [
    "rank_dict",
    "network_alpha_dict",
    "peft_state_dict",
    "is_unet",
    "model_state_dict",
    "adapter_name"
  ],
  "get_adapter_name": [
    "model"
  ],
  "set_adapter_layers": [
    "model",
    "enabled"
  ],
  "delete_adapter_layers": [
    "model",
    "adapter_name"
  ],
  "set_weights_and_activate_adapters": [
    "model",
    "adapter_names",
    "weights"
  ],
  "check_peft_version": [
    "min_version"
  ],
  "_create_lora_config": [
    "state_dict",
    "network_alphas",
    "metadata",
    "rank_pattern_dict",
    "is_unet",
    "model_state_dict",
    "adapter_name"
  ],
  "_maybe_raise_error_for_ambiguous_keys": [
    "config"
  ],
  "_maybe_warn_for_unhandled_keys": [
    "incompatible_keys",
    "adapter_name"
  ],
  "FlaxStableDiffusionControlNetPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FlaxStableDiffusionImg2ImgPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FlaxStableDiffusionInpaintPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FlaxStableDiffusionPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "FlaxStableDiffusionXLPipeline": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "MIN_PEFT_VERSION": [],
  "MIN_TRANSFORMERS_VERSION": [],
  "_CHECK_PEFT": [],
  "CONFIG_NAME": [],
  "WEIGHTS_NAME": [],
  "WEIGHTS_INDEX_NAME": [],
  "FLAX_WEIGHTS_NAME": [],
  "ONNX_WEIGHTS_NAME": [],
  "SAFETENSORS_WEIGHTS_NAME": [],
  "SAFE_WEIGHTS_INDEX_NAME": [],
  "SAFETENSORS_FILE_EXTENSION": [],
  "GGUF_FILE_EXTENSION": [],
  "ONNX_EXTERNAL_WEIGHTS_NAME": [],
  "HUGGINGFACE_CO_RESOLVE_ENDPOINT": [],
  "DIFFUSERS_DYNAMIC_MODULE_NAME": [],
  "HF_MODULES_CACHE": [],
  "DEPRECATED_REVISION_ARGS": [],
  "DIFFUSERS_REQUEST_TIMEOUT": [],
  "DIFFUSERS_ATTN_BACKEND": [],
  "DIFFUSERS_ATTN_CHECKS": [],
  "DEFAULT_HF_PARALLEL_LOADING_WORKERS": [],
  "HF_ENABLE_PARALLEL_LOADING": [],
  "DIFFUSERS_DISABLE_REMOTE_CODE": [],
  "DECODE_ENDPOINT_SD_V1": [],
  "DECODE_ENDPOINT_SD_XL": [],
  "DECODE_ENDPOINT_FLUX": [],
  "DECODE_ENDPOINT_HUNYUAN_VIDEO": [],
  "ENCODE_ENDPOINT_SD_V1": [],
  "ENCODE_ENDPOINT_SD_XL": [],
  "ENCODE_ENDPOINT_FLUX": [],
  "StateDictType": {
    "DIFFUSERS_OLD": [],
    "KOHYA_SS": [],
    "PEFT": [],
    "DIFFUSERS": []
  },
  "UNET_TO_DIFFUSERS": [],
  "DIFFUSERS_TO_PEFT": [],
  "DIFFUSERS_OLD_TO_PEFT": [],
  "PEFT_TO_DIFFUSERS": [],
  "DIFFUSERS_OLD_TO_DIFFUSERS": [],
  "PEFT_TO_KOHYA_SS": [],
  "PEFT_STATE_DICT_MAPPINGS": [],
  "DIFFUSERS_STATE_DICT_MAPPINGS": [],
  "KOHYA_STATE_DICT_MAPPINGS": [],
  "KEYS_TO_ALWAYS_REPLACE": [],
  "convert_state_dict": [
    "state_dict",
    "mapping"
  ],
  "convert_state_dict_to_peft": [
    "state_dict",
    "original_type"
  ],
  "convert_state_dict_to_diffusers": [
    "state_dict",
    "original_type"
  ],
  "convert_unet_state_dict_to_peft": [
    "state_dict"
  ],
  "convert_all_state_dict_to_peft": [
    "state_dict"
  ],
  "convert_state_dict_to_kohya": [
    "state_dict",
    "original_type"
  ],
  "state_dict_all_zero": [
    "state_dict",
    "filter_str"
  ],
  "_load_sft_state_dict_metadata": [
    "model_file"
  ],
  "MidiProcessor": {
    "_backends": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ops": [],
  "_compare_versions": [
    "op",
    "got_ver",
    "want_ver",
    "requirement",
    "pkg",
    "hint"
  ],
  "require_version": [
    "requirement",
    "hint"
  ],
  "require_version_core": [
    "requirement"
  ],
  "pt_to_pil": [
    "images"
  ],
  "numpy_to_pil": [
    "images"
  ],
  "make_image_grid": [
    "images",
    "rows",
    "cols",
    "resize"
  ],
  "_LOW_CPU_MEM_USAGE_DEFAULT_LORA": [],
  "TEXT_ENCODER_NAME": [],
  "UNET_NAME": [],
  "TRANSFORMER_NAME": [],
  "_MODULE_NAME_TO_ATTRIBUTE_MAP_FLUX": [],
  "_maybe_dequantize_weight_for_expanded_lora": [
    "model",
    "module"
  ],
  "StableDiffusionLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "unet_name": [],
    "text_encoder_name": [],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_into_unet": [
      "cls",
      "state_dict",
      "network_alphas",
      "unet",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "load_lora_into_text_encoder": [
      "cls",
      "state_dict",
      "network_alphas",
      "text_encoder",
      "prefix",
      "lora_scale",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "unet_lora_layers",
      "text_encoder_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "unet_lora_adapter_metadata",
      "text_encoder_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "StableDiffusionXLLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "unet_name": [],
    "text_encoder_name": [],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_into_unet": [
      "cls",
      "state_dict",
      "network_alphas",
      "unet",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "load_lora_into_text_encoder": [
      "cls",
      "state_dict",
      "network_alphas",
      "text_encoder",
      "prefix",
      "lora_scale",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "unet_lora_layers",
      "text_encoder_lora_layers",
      "text_encoder_2_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "unet_lora_adapter_metadata",
      "text_encoder_lora_adapter_metadata",
      "text_encoder_2_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "SD3LoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "text_encoder_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "load_lora_into_text_encoder": [
      "cls",
      "state_dict",
      "network_alphas",
      "text_encoder",
      "prefix",
      "lora_scale",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "text_encoder_lora_layers",
      "text_encoder_2_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata",
      "text_encoder_lora_adapter_metadata",
      "text_encoder_2_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "AuraFlowLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "FluxLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "text_encoder_name": [],
    "_control_lora_supported_norm_keys": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict",
      "return_alphas"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "network_alphas",
      "transformer",
      "adapter_name",
      "metadata",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap"
    ],
    "_load_norm_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "prefix",
      "discard_original_layers"
    ],
    "load_lora_into_text_encoder": [
      "cls",
      "state_dict",
      "network_alphas",
      "text_encoder",
      "prefix",
      "lora_scale",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "text_encoder_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata",
      "text_encoder_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ],
    "unload_lora_weights": [
      "self",
      "reset_to_overwritten_params"
    ],
    "_maybe_expand_transformer_param_shape_or_error_": [
      "cls",
      "transformer",
      "lora_state_dict",
      "norm_state_dict",
      "prefix"
    ],
    "_maybe_expand_lora_state_dict": [
      "cls",
      "transformer",
      "lora_state_dict"
    ],
    "_calculate_module_shape": [
      "model",
      "base_module",
      "base_weight_param_name"
    ],
    "_prepare_outputs": [
      "state_dict",
      "metadata",
      "alphas",
      "return_alphas",
      "return_metadata"
    ]
  },
  "AmusedLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "text_encoder_name": [],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "network_alphas",
      "transformer",
      "adapter_name",
      "metadata",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap"
    ],
    "load_lora_into_text_encoder": [
      "cls",
      "state_dict",
      "network_alphas",
      "text_encoder",
      "prefix",
      "lora_scale",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "text_encoder_lora_layers",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization"
    ]
  },
  "CogVideoXLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "Mochi1LoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "LTXVideoLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "SanaLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "HunyuanVideoLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "Lumina2LoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "KandinskyLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "WanLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "_maybe_expand_t2v_lora_for_i2v": [
      "cls",
      "transformer",
      "state_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "SkyReelsV2LoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "_maybe_expand_t2v_lora_for_i2v": [
      "cls",
      "transformer",
      "state_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "CogView4LoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "HiDreamImageLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "QwenImageLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "ZImageLoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "Flux2LoraLoaderMixin": {
    "_lora_loadable_modules": [],
    "transformer_name": [],
    "lora_state_dict": [
      "cls",
      "pretrained_model_name_or_path_or_dict"
    ],
    "load_lora_weights": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "adapter_name",
      "hotswap"
    ],
    "load_lora_into_transformer": [
      "cls",
      "state_dict",
      "transformer",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage",
      "hotswap",
      "metadata"
    ],
    "save_lora_weights": [
      "cls",
      "save_directory",
      "transformer_lora_layers",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "transformer_lora_adapter_metadata"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ]
  },
  "LoraLoaderMixin": {
    "__init__": [
      "self"
    ]
  },
  "swap_scale_shift": [
    "weight"
  ],
  "_maybe_map_sgm_blocks_to_diffusers": [
    "state_dict",
    "unet_config",
    "delimiter",
    "block_slice_pos"
  ],
  "_convert_non_diffusers_lora_to_diffusers": [
    "state_dict",
    "unet_name",
    "text_encoder_name"
  ],
  "_convert_unet_lora_key": [
    "key"
  ],
  "_convert_text_encoder_lora_key": [
    "key",
    "lora_name"
  ],
  "_get_alpha_name": [
    "lora_name_alpha",
    "diffusers_name",
    "alpha"
  ],
  "_convert_kohya_flux_lora_to_diffusers": [
    "state_dict"
  ],
  "_convert_xlabs_flux_lora_to_diffusers": [
    "old_state_dict"
  ],
  "_custom_replace": [
    "key",
    "substrings"
  ],
  "_convert_bfl_flux_control_lora_to_diffusers": [
    "original_state_dict"
  ],
  "_convert_fal_kontext_lora_to_diffusers": [
    "original_state_dict"
  ],
  "_convert_hunyuan_video_lora_to_diffusers": [
    "original_state_dict"
  ],
  "_convert_non_diffusers_lumina2_lora_to_diffusers": [
    "state_dict"
  ],
  "_convert_non_diffusers_wan_lora_to_diffusers": [
    "state_dict"
  ],
  "_convert_musubi_wan_lora_to_diffusers": [
    "state_dict"
  ],
  "_convert_non_diffusers_hidream_lora_to_diffusers": [
    "state_dict",
    "non_diffusers_prefix"
  ],
  "_convert_non_diffusers_ltxv_lora_to_diffusers": [
    "state_dict",
    "non_diffusers_prefix"
  ],
  "_convert_non_diffusers_qwen_lora_to_diffusers": [
    "state_dict"
  ],
  "_convert_non_diffusers_flux2_lora_to_diffusers": [
    "state_dict"
  ],
  "_convert_non_diffusers_z_image_lora_to_diffusers": [
    "state_dict"
  ],
  "CHECKPOINT_KEY_NAMES": [],
  "DIFFUSERS_DEFAULT_PIPELINE_PATHS": [],
  "DIFFUSERS_TO_LDM_DEFAULT_IMAGE_SIZE_MAP": [],
  "DIFFUSERS_TO_LDM_MAPPING": [],
  "SD_2_TEXT_ENCODER_KEYS_TO_IGNORE": [],
  "SCHEDULER_DEFAULT_CONFIG": [],
  "LDM_VAE_KEYS": [],
  "LDM_VAE_DEFAULT_SCALING_FACTOR": [],
  "PLAYGROUND_VAE_SCALING_FACTOR": [],
  "LDM_UNET_KEY": [],
  "LDM_CONTROLNET_KEY": [],
  "LDM_CLIP_PREFIX_TO_REMOVE": [],
  "LDM_OPEN_CLIP_TEXT_PROJECTION_DIM": [],
  "SCHEDULER_LEGACY_KWARGS": [],
  "VALID_URL_PREFIXES": [],
  "SingleFileComponentError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "is_valid_url": [
    "url"
  ],
  "_is_single_file_path_or_url": [
    "pretrained_model_name_or_path"
  ],
  "_extract_repo_id_and_weights_name": [
    "pretrained_model_name_or_path"
  ],
  "_is_model_weights_in_cached_folder": [
    "cached_folder",
    "name"
  ],
  "_is_legacy_scheduler_kwargs": [
    "kwargs"
  ],
  "load_single_file_checkpoint": [
    "pretrained_model_link_or_path",
    "force_download",
    "proxies",
    "token",
    "cache_dir",
    "local_files_only",
    "revision",
    "disable_mmap",
    "user_agent"
  ],
  "fetch_original_config": [
    "original_config_file",
    "local_files_only"
  ],
  "is_clip_model": [
    "checkpoint"
  ],
  "is_clip_sdxl_model": [
    "checkpoint"
  ],
  "is_clip_sd3_model": [
    "checkpoint"
  ],
  "is_open_clip_model": [
    "checkpoint"
  ],
  "is_open_clip_sdxl_model": [
    "checkpoint"
  ],
  "is_open_clip_sd3_model": [
    "checkpoint"
  ],
  "is_open_clip_sdxl_refiner_model": [
    "checkpoint"
  ],
  "is_clip_model_in_single_file": [
    "class_obj",
    "checkpoint"
  ],
  "infer_diffusers_model_type": [
    "checkpoint"
  ],
  "fetch_diffusers_config": [
    "checkpoint"
  ],
  "set_image_size": [
    "checkpoint",
    "image_size"
  ],
  "conv_attn_to_linear": [
    "checkpoint"
  ],
  "create_unet_diffusers_config_from_ldm": [
    "original_config",
    "checkpoint",
    "image_size",
    "upcast_attention",
    "num_in_channels"
  ],
  "create_controlnet_diffusers_config_from_ldm": [
    "original_config",
    "checkpoint",
    "image_size"
  ],
  "create_vae_diffusers_config_from_ldm": [
    "original_config",
    "checkpoint",
    "image_size",
    "scaling_factor"
  ],
  "update_unet_resnet_ldm_to_diffusers": [
    "ldm_keys",
    "new_checkpoint",
    "checkpoint",
    "mapping"
  ],
  "update_unet_attention_ldm_to_diffusers": [
    "ldm_keys",
    "new_checkpoint",
    "checkpoint",
    "mapping"
  ],
  "update_vae_resnet_ldm_to_diffusers": [
    "keys",
    "new_checkpoint",
    "checkpoint",
    "mapping"
  ],
  "update_vae_attentions_ldm_to_diffusers": [
    "keys",
    "new_checkpoint",
    "checkpoint",
    "mapping"
  ],
  "convert_stable_cascade_unet_single_file_to_diffusers": [
    "checkpoint"
  ],
  "convert_ldm_unet_checkpoint": [
    "checkpoint",
    "config",
    "extract_ema"
  ],
  "convert_controlnet_checkpoint": [
    "checkpoint",
    "config"
  ],
  "convert_ldm_vae_checkpoint": [
    "checkpoint",
    "config"
  ],
  "convert_ldm_clip_checkpoint": [
    "checkpoint",
    "remove_prefix"
  ],
  "convert_open_clip_checkpoint": [
    "text_model",
    "checkpoint",
    "prefix"
  ],
  "create_diffusers_clip_model_from_ldm": [
    "cls",
    "checkpoint",
    "subfolder",
    "config",
    "torch_dtype",
    "local_files_only",
    "is_legacy_loading"
  ],
  "_legacy_load_scheduler": [
    "cls",
    "checkpoint",
    "component_name",
    "original_config"
  ],
  "_legacy_load_clip_tokenizer": [
    "cls",
    "checkpoint",
    "config",
    "local_files_only"
  ],
  "_legacy_load_safety_checker": [
    "local_files_only",
    "torch_dtype"
  ],
  "swap_proj_gate": [
    "weight"
  ],
  "get_attn2_layers": [
    "state_dict"
  ],
  "get_caption_projection_dim": [
    "state_dict"
  ],
  "convert_sd3_transformer_checkpoint_to_diffusers": [
    "checkpoint"
  ],
  "is_t5_in_single_file": [
    "checkpoint"
  ],
  "convert_sd3_t5_checkpoint_to_diffusers": [
    "checkpoint"
  ],
  "create_diffusers_t5_model_from_checkpoint": [
    "cls",
    "checkpoint",
    "subfolder",
    "config",
    "torch_dtype",
    "local_files_only"
  ],
  "convert_animatediff_checkpoint_to_diffusers": [
    "checkpoint"
  ],
  "convert_flux_transformer_checkpoint_to_diffusers": [
    "checkpoint"
  ],
  "convert_ltx_transformer_checkpoint_to_diffusers": [
    "checkpoint"
  ],
  "convert_ltx_vae_checkpoint_to_diffusers": [
    "checkpoint"
  ],
  "convert_autoencoder_dc_checkpoint_to_diffusers": [
    "checkpoint"
  ],
  "convert_mochi_transformer_checkpoint_to_diffusers": [
    "checkpoint"
  ],
  "convert_hunyuan_video_transformer_to_diffusers": [
    "checkpoint"
  ],
  "convert_auraflow_transformer_checkpoint_to_diffusers": [
    "checkpoint"
  ],
  "convert_lumina2_to_diffusers": [
    "checkpoint"
  ],
  "convert_sana_transformer_to_diffusers": [
    "checkpoint"
  ],
  "convert_wan_transformer_to_diffusers": [
    "checkpoint"
  ],
  "convert_wan_vae_to_diffusers": [
    "checkpoint"
  ],
  "convert_hidream_transformer_to_diffusers": [
    "checkpoint"
  ],
  "convert_chroma_transformer_checkpoint_to_diffusers": [
    "checkpoint"
  ],
  "convert_cosmos_transformer_checkpoint_to_diffusers": [
    "checkpoint"
  ],
  "convert_flux2_transformer_checkpoint_to_diffusers": [
    "checkpoint"
  ],
  "convert_z_image_transformer_checkpoint_to_diffusers": [
    "checkpoint"
  ],
  "_translate_into_actual_layer_name": [
    "name"
  ],
  "_maybe_expand_lora_scales": [
    "unet",
    "weight_scales",
    "default_scale"
  ],
  "_maybe_expand_lora_scales_for_one_adapter": [
    "scales",
    "blocks_with_transformer",
    "transformer_per_block",
    "model",
    "default_scale"
  ],
  "AttnProcsLayers": {
    "__init__": [
      "self",
      "state_dict"
    ]
  },
  "TEXT_INVERSION_NAME": [],
  "TEXT_INVERSION_NAME_SAFE": [],
  "load_textual_inversion_state_dicts": [
    "pretrained_model_name_or_paths"
  ],
  "TextualInversionLoaderMixin": {
    "maybe_convert_prompt": [
      "self",
      "prompt",
      "tokenizer"
    ],
    "_maybe_convert_prompt": [
      "self",
      "prompt",
      "tokenizer"
    ],
    "_check_text_inv_inputs": [
      "self",
      "tokenizer",
      "text_encoder",
      "pretrained_model_name_or_paths",
      "tokens"
    ],
    "_retrieve_tokens_and_embeddings": [
      "tokens",
      "state_dicts",
      "tokenizer"
    ],
    "_extend_tokens_and_embeddings": [
      "tokens",
      "embeddings",
      "tokenizer"
    ],
    "load_textual_inversion": [
      "self",
      "pretrained_model_name_or_path",
      "token",
      "tokenizer",
      "text_encoder"
    ],
    "unload_textual_inversion": [
      "self",
      "tokens",
      "tokenizer",
      "text_encoder"
    ]
  },
  "CUSTOM_DIFFUSION_WEIGHT_NAME": [],
  "CUSTOM_DIFFUSION_WEIGHT_NAME_SAFE": [],
  "UNet2DConditionLoadersMixin": {
    "text_encoder_name": [],
    "unet_name": [],
    "load_attn_procs": [
      "self",
      "pretrained_model_name_or_path_or_dict"
    ],
    "_process_custom_diffusion": [
      "self",
      "state_dict"
    ],
    "_process_lora": [
      "self",
      "state_dict",
      "unet_identifier_key",
      "network_alphas",
      "adapter_name",
      "_pipeline",
      "low_cpu_mem_usage"
    ],
    "_optionally_disable_offloading": [
      "cls",
      "_pipeline"
    ],
    "save_attn_procs": [
      "self",
      "save_directory",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization"
    ],
    "_get_custom_diffusion_state_dict": [
      "self"
    ],
    "_convert_ip_adapter_image_proj_to_diffusers": [
      "self",
      "state_dict",
      "low_cpu_mem_usage"
    ],
    "_convert_ip_adapter_attn_to_diffusers": [
      "self",
      "state_dicts",
      "low_cpu_mem_usage"
    ],
    "_load_ip_adapter_weights": [
      "self",
      "state_dicts",
      "low_cpu_mem_usage"
    ],
    "_load_ip_adapter_loras": [
      "self",
      "state_dicts"
    ]
  },
  "text_encoder_lora_state_dict": [
    "text_encoder"
  ],
  "IPAdapterMixin": {
    "load_ip_adapter": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "subfolder",
      "weight_name",
      "image_encoder_folder"
    ],
    "set_ip_adapter_scale": [
      "self",
      "scale"
    ],
    "unload_ip_adapter": [
      "self"
    ]
  },
  "ModularIPAdapterMixin": {
    "load_ip_adapter": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "subfolder",
      "weight_name"
    ],
    "set_ip_adapter_scale": [
      "self",
      "scale"
    ],
    "unload_ip_adapter": [
      "self"
    ]
  },
  "FluxIPAdapterMixin": {
    "load_ip_adapter": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "weight_name",
      "subfolder",
      "image_encoder_pretrained_model_name_or_path",
      "image_encoder_subfolder",
      "image_encoder_dtype"
    ],
    "set_ip_adapter_scale": [
      "self",
      "scale"
    ],
    "unload_ip_adapter": [
      "self"
    ]
  },
  "SD3IPAdapterMixin": {
    "is_ip_adapter_active": [
      "self"
    ],
    "load_ip_adapter": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "weight_name",
      "subfolder",
      "image_encoder_folder"
    ],
    "set_ip_adapter_scale": [
      "self",
      "scale"
    ],
    "unload_ip_adapter": [
      "self"
    ]
  },
  "SINGLE_FILE_LOADABLE_CLASSES": [],
  "_should_convert_state_dict_to_diffusers": [
    "model_state_dict",
    "checkpoint_state_dict"
  ],
  "_get_single_file_loadable_mapping_class": [
    "cls"
  ],
  "_get_mapping_function_kwargs": [
    "mapping_fn"
  ],
  "FromOriginalModelMixin": {
    "from_single_file": [
      "cls",
      "pretrained_model_link_or_path_or_dict"
    ]
  },
  "SD3Transformer2DLoadersMixin": {
    "_convert_ip_adapter_attn_to_diffusers": [
      "self",
      "state_dict",
      "low_cpu_mem_usage"
    ],
    "_convert_ip_adapter_image_proj_to_diffusers": [
      "self",
      "state_dict",
      "low_cpu_mem_usage"
    ],
    "_load_ip_adapter_weights": [
      "self",
      "state_dict",
      "low_cpu_mem_usage"
    ]
  },
  "FluxTransformer2DLoadersMixin": {
    "_convert_ip_adapter_image_proj_to_diffusers": [
      "self",
      "state_dict",
      "low_cpu_mem_usage"
    ],
    "_convert_ip_adapter_attn_to_diffusers": [
      "self",
      "state_dicts",
      "low_cpu_mem_usage"
    ],
    "_load_ip_adapter_weights": [
      "self",
      "state_dicts",
      "low_cpu_mem_usage"
    ]
  },
  "_SET_ADAPTER_SCALE_FN_MAPPING": [],
  "PeftAdapterMixin": {
    "_hf_peft_config_loaded": [],
    "_optionally_disable_offloading": [
      "cls",
      "_pipeline"
    ],
    "load_lora_adapter": [
      "self",
      "pretrained_model_name_or_path_or_dict",
      "prefix",
      "hotswap"
    ],
    "save_lora_adapter": [
      "self",
      "save_directory",
      "adapter_name",
      "upcast_before_saving",
      "safe_serialization",
      "weight_name"
    ],
    "set_adapters": [
      "self",
      "adapter_names",
      "weights"
    ],
    "add_adapter": [
      "self",
      "adapter_config",
      "adapter_name"
    ],
    "set_adapter": [
      "self",
      "adapter_name"
    ],
    "disable_adapters": [
      "self"
    ],
    "enable_adapters": [
      "self"
    ],
    "active_adapters": [
      "self"
    ],
    "fuse_lora": [
      "self",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "_fuse_lora_apply": [
      "self",
      "module",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self"
    ],
    "_unfuse_lora_apply": [
      "self",
      "module"
    ],
    "unload_lora": [
      "self"
    ],
    "disable_lora": [
      "self"
    ],
    "enable_lora": [
      "self"
    ],
    "delete_adapters": [
      "self",
      "adapter_names"
    ],
    "enable_lora_hotswap": [
      "self",
      "target_rank",
      "check_compiled"
    ]
  },
  "SINGLE_FILE_OPTIONAL_COMPONENTS": [],
  "load_single_file_sub_model": [
    "library_name",
    "class_name",
    "name",
    "checkpoint",
    "pipelines",
    "is_pipeline_module",
    "cached_model_config_path",
    "original_config",
    "local_files_only",
    "torch_dtype",
    "is_legacy_loading",
    "disable_mmap"
  ],
  "_map_component_types_to_config_dict": [
    "component_types"
  ],
  "_infer_pipeline_config_dict": [
    "pipeline_class"
  ],
  "_download_diffusers_model_config_from_hub": [
    "pretrained_model_name_or_path",
    "cache_dir",
    "revision",
    "proxies",
    "force_download",
    "local_files_only",
    "token"
  ],
  "FromSingleFileMixin": {
    "from_single_file": [
      "cls",
      "pretrained_model_link_or_path"
    ]
  },
  "LORA_WEIGHT_NAME": [],
  "LORA_WEIGHT_NAME_SAFE": [],
  "LORA_ADAPTER_METADATA_KEY": [],
  "fuse_text_encoder_lora": [
    "text_encoder",
    "lora_scale",
    "safe_fusing",
    "adapter_names"
  ],
  "unfuse_text_encoder_lora": [
    "text_encoder"
  ],
  "set_adapters_for_text_encoder": [
    "adapter_names",
    "text_encoder",
    "text_encoder_weights"
  ],
  "disable_lora_for_text_encoder": [
    "text_encoder"
  ],
  "enable_lora_for_text_encoder": [
    "text_encoder"
  ],
  "_remove_text_encoder_monkey_patch": [
    "text_encoder"
  ],
  "_fetch_state_dict": [
    "pretrained_model_name_or_path_or_dict",
    "weight_name",
    "use_safetensors",
    "local_files_only",
    "cache_dir",
    "force_download",
    "proxies",
    "token",
    "revision",
    "subfolder",
    "user_agent",
    "allow_pickle",
    "metadata"
  ],
  "_best_guess_weight_name": [
    "pretrained_model_name_or_path_or_dict",
    "file_extension",
    "local_files_only"
  ],
  "_pack_dict_with_prefix": [
    "state_dict",
    "prefix"
  ],
  "_load_lora_into_text_encoder": [
    "state_dict",
    "network_alphas",
    "text_encoder",
    "prefix",
    "lora_scale",
    "text_encoder_name",
    "adapter_name",
    "_pipeline",
    "low_cpu_mem_usage",
    "hotswap",
    "metadata"
  ],
  "_func_optionally_disable_offloading": [
    "_pipeline"
  ],
  "LoraBaseMixin": {
    "_lora_loadable_modules": [],
    "_merged_adapters": [],
    "lora_scale": [
      "self"
    ],
    "num_fused_loras": [
      "self"
    ],
    "fused_loras": [
      "self"
    ],
    "load_lora_weights": [
      "self"
    ],
    "save_lora_weights": [
      "cls"
    ],
    "lora_state_dict": [
      "cls"
    ],
    "unload_lora_weights": [
      "self"
    ],
    "fuse_lora": [
      "self",
      "components",
      "lora_scale",
      "safe_fusing",
      "adapter_names"
    ],
    "unfuse_lora": [
      "self",
      "components"
    ],
    "set_adapters": [
      "self",
      "adapter_names",
      "adapter_weights"
    ],
    "disable_lora": [
      "self"
    ],
    "enable_lora": [
      "self"
    ],
    "delete_adapters": [
      "self",
      "adapter_names"
    ],
    "get_active_adapters": [
      "self"
    ],
    "get_list_adapters": [
      "self"
    ],
    "set_lora_device": [
      "self",
      "adapter_names",
      "device"
    ],
    "enable_lora_hotswap": [
      "self"
    ],
    "pack_weights": [
      "layers",
      "prefix"
    ],
    "write_lora_layers": [
      "state_dict",
      "save_directory",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization",
      "lora_adapter_metadata"
    ],
    "_save_lora_weights": [
      "cls",
      "save_directory",
      "lora_layers",
      "lora_metadata",
      "is_main_process",
      "weight_name",
      "save_function",
      "safe_serialization"
    ],
    "_optionally_disable_offloading": [
      "cls",
      "_pipeline"
    ]
  },
  "BaseState": {
    "reset": [
      "self"
    ]
  },
  "StateManager": {
    "__init__": [
      "self",
      "state_cls",
      "init_args",
      "init_kwargs"
    ],
    "get_state": [
      "self"
    ],
    "set_context": [
      "self",
      "name"
    ],
    "reset": [
      "self"
    ]
  },
  "ModelHook": {
    "_is_stateful": [],
    "__init__": [
      "self"
    ],
    "initialize_hook": [
      "self",
      "module"
    ],
    "deinitalize_hook": [
      "self",
      "module"
    ],
    "pre_forward": [
      "self",
      "module"
    ],
    "post_forward": [
      "self",
      "module",
      "output"
    ],
    "detach_hook": [
      "self",
      "module"
    ],
    "reset_state": [
      "self",
      "module"
    ],
    "_set_context": [
      "self",
      "module",
      "name"
    ]
  },
  "HookFunctionReference": {
    "__init__": [
      "self"
    ]
  },
  "_SMOOTHED_ENERGY_GUIDANCE_HOOK": [],
  "SmoothedEnergyGuidanceHook": {
    "__init__": [
      "self",
      "blur_sigma",
      "blur_threshold_inf"
    ],
    "post_forward": [
      "self",
      "module",
      "output"
    ]
  },
  "_apply_smoothed_energy_guidance_hook": [
    "module",
    "config",
    "blur_sigma",
    "name"
  ],
  "_gaussian_blur_2d": [
    "query",
    "kernel_size",
    "sigma",
    "sigma_threshold_inf"
  ],
  "_TAYLORSEER_CACHE_HOOK": [],
  "_SPATIAL_ATTENTION_BLOCK_IDENTIFIERS": [],
  "_TEMPORAL_ATTENTION_BLOCK_IDENTIFIERS": [],
  "_TRANSFORMER_BLOCK_IDENTIFIERS": [],
  "_BLOCK_IDENTIFIERS": [],
  "_PROJ_OUT_IDENTIFIERS": [],
  "TaylorSeerState": {
    "__init__": [
      "self",
      "taylor_factors_dtype",
      "max_order",
      "is_inactive"
    ],
    "reset": [
      "self"
    ],
    "update": [
      "self",
      "outputs"
    ],
    "predict": [
      "self"
    ]
  },
  "TaylorSeerCacheHook": {
    "_is_stateful": [],
    "__init__": [
      "self",
      "cache_interval",
      "disable_cache_before_step",
      "taylor_factors_dtype",
      "state_manager",
      "disable_cache_after_step"
    ],
    "initialize_hook": [
      "self",
      "module"
    ],
    "reset_state": [
      "self",
      "module"
    ],
    "_measure_should_compute": [
      "self"
    ],
    "new_forward": [
      "self",
      "module"
    ]
  },
  "_resolve_patterns": [
    "config"
  ],
  "_apply_taylorseer_cache_hook": [
    "module",
    "config",
    "is_inactive"
  ],
  "_LAYER_SKIP_HOOK": [],
  "AttentionScoreSkipFunctionMode": {
    "__torch_function__": [
      "self",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "AttentionProcessorSkipHook": {
    "__init__": [
      "self",
      "skip_processor_output_fn",
      "skip_attention_scores",
      "dropout"
    ],
    "new_forward": [
      "self",
      "module"
    ]
  },
  "FeedForwardSkipHook": {
    "__init__": [
      "self",
      "dropout"
    ],
    "new_forward": [
      "self",
      "module"
    ]
  },
  "TransformerBlockSkipHook": {
    "__init__": [
      "self",
      "dropout"
    ],
    "initialize_hook": [
      "self",
      "module"
    ],
    "new_forward": [
      "self",
      "module"
    ]
  },
  "_apply_layer_skip_hook": [
    "module",
    "config",
    "name"
  ],
  "_get_identifiable_transformer_blocks_in_module": [
    "module"
  ],
  "_get_identifiable_attention_layers_in_module": [
    "module"
  ],
  "_get_identifiable_feedforward_layers_in_module": [
    "module"
  ],
  "_FBC_LEADER_BLOCK_HOOK": [],
  "_FBC_BLOCK_HOOK": [],
  "FBCSharedBlockState": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "FBCHeadBlockHook": {
    "_is_stateful": [],
    "__init__": [
      "self",
      "state_manager",
      "threshold"
    ],
    "initialize_hook": [
      "self",
      "module"
    ],
    "new_forward": [
      "self",
      "module"
    ],
    "reset_state": [
      "self",
      "module"
    ],
    "_should_compute_remaining_blocks": [
      "self",
      "hidden_states_residual"
    ]
  },
  "FBCBlockHook": {
    "__init__": [
      "self",
      "state_manager",
      "is_tail"
    ],
    "initialize_hook": [
      "self",
      "module"
    ],
    "new_forward": [
      "self",
      "module"
    ]
  },
  "_apply_fbc_head_block_hook": [
    "block",
    "state_manager",
    "threshold"
  ],
  "_apply_fbc_block_hook": [
    "block",
    "state_manager",
    "is_tail"
  ],
  "_ATTENTION_CLASSES": [],
  "_FEEDFORWARD_CLASSES": [],
  "_SPATIAL_TRANSFORMER_BLOCK_IDENTIFIERS": [],
  "_TEMPORAL_TRANSFORMER_BLOCK_IDENTIFIERS": [],
  "_CROSS_TRANSFORMER_BLOCK_IDENTIFIERS": [],
  "_ALL_TRANSFORMER_BLOCK_IDENTIFIERS": [],
  "_GO_LC_SUPPORTED_PYTORCH_LAYERS": [],
  "_get_submodule_from_fqn": [
    "module",
    "fqn"
  ],
  "_GROUP_OFFLOADING": [],
  "_LAYER_EXECUTION_TRACKER": [],
  "_LAZY_PREFETCH_GROUP_OFFLOADING": [],
  "_GROUP_ID_LAZY_LEAF": [],
  "GroupOffloadingType": {
    "BLOCK_LEVEL": [],
    "LEAF_LEVEL": []
  },
  "GroupOffloadingConfig": {},
  "ModuleGroup": {
    "__init__": [
      "self",
      "modules",
      "offload_device",
      "onload_device",
      "offload_leader",
      "onload_leader",
      "parameters",
      "buffers",
      "non_blocking",
      "stream",
      "record_stream",
      "low_cpu_mem_usage",
      "onload_self",
      "offload_to_disk_path",
      "group_id"
    ],
    "_init_cpu_param_dict": [
      "self"
    ],
    "_pinned_memory_tensors": [
      "self"
    ],
    "_transfer_tensor_to_device": [
      "self",
      "tensor",
      "source_tensor",
      "default_stream"
    ],
    "_process_tensors_from_modules": [
      "self",
      "pinned_memory",
      "default_stream"
    ],
    "_onload_from_disk": [
      "self"
    ],
    "_onload_from_memory": [
      "self"
    ],
    "_offload_to_disk": [
      "self"
    ],
    "_offload_to_memory": [
      "self"
    ],
    "onload_": [
      "self"
    ],
    "offload_": [
      "self"
    ]
  },
  "GroupOffloadingHook": {
    "_is_stateful": [],
    "__init__": [
      "self",
      "group"
    ],
    "initialize_hook": [
      "self",
      "module"
    ],
    "pre_forward": [
      "self",
      "module"
    ],
    "post_forward": [
      "self",
      "module",
      "output"
    ]
  },
  "LazyPrefetchGroupOffloadingHook": {
    "_is_stateful": [],
    "__init__": [
      "self"
    ],
    "initialize_hook": [
      "self",
      "module"
    ],
    "post_forward": [
      "self",
      "module",
      "output"
    ]
  },
  "LayerExecutionTrackerHook": {
    "_is_stateful": [],
    "__init__": [
      "self",
      "execution_order_update_callback"
    ],
    "pre_forward": [
      "self",
      "module"
    ]
  },
  "apply_group_offloading": [
    "module",
    "onload_device",
    "offload_device",
    "offload_type",
    "num_blocks_per_group",
    "non_blocking",
    "use_stream",
    "record_stream",
    "low_cpu_mem_usage",
    "offload_to_disk_path",
    "block_modules",
    "exclude_kwargs"
  ],
  "_apply_group_offloading": [
    "module",
    "config"
  ],
  "_apply_group_offloading_block_level": [
    "module",
    "config"
  ],
  "_apply_group_offloading_leaf_level": [
    "module",
    "config"
  ],
  "_apply_group_offloading_hook": [
    "module",
    "group"
  ],
  "_apply_lazy_group_offloading_hook": [
    "module",
    "group"
  ],
  "_gather_parameters_with_no_group_offloading_parent": [
    "module",
    "modules_with_group_offloading"
  ],
  "_gather_buffers_with_no_group_offloading_parent": [
    "module",
    "modules_with_group_offloading"
  ],
  "_find_parent_module_in_module_dict": [
    "name",
    "module_dict"
  ],
  "_raise_error_if_accelerate_model_or_sequential_hook_present": [
    "module"
  ],
  "_get_top_level_group_offload_hook": [
    "module"
  ],
  "_is_group_offload_enabled": [
    "module"
  ],
  "_get_group_onload_device": [
    "module"
  ],
  "_compute_group_hash": [
    "group_id"
  ],
  "_maybe_remove_and_reapply_group_offloading": [
    "module"
  ],
  "_LAYERWISE_CASTING_HOOK": [],
  "_PEFT_AUTOCAST_DISABLE_HOOK": [],
  "DEFAULT_SKIP_MODULES_PATTERN": [],
  "_SHOULD_DISABLE_PEFT_INPUT_AUTOCAST": [],
  "LayerwiseCastingHook": {
    "_is_stateful": [],
    "__init__": [
      "self",
      "storage_dtype",
      "compute_dtype",
      "non_blocking"
    ],
    "initialize_hook": [
      "self",
      "module"
    ],
    "deinitalize_hook": [
      "self",
      "module"
    ],
    "pre_forward": [
      "self",
      "module"
    ],
    "post_forward": [
      "self",
      "module",
      "output"
    ]
  },
  "PeftInputAutocastDisableHook": {
    "new_forward": [
      "self",
      "module"
    ]
  },
  "apply_layerwise_casting": [
    "module",
    "storage_dtype",
    "compute_dtype",
    "skip_modules_pattern",
    "skip_modules_classes",
    "non_blocking"
  ],
  "_apply_layerwise_casting": [
    "module",
    "storage_dtype",
    "compute_dtype",
    "skip_modules_pattern",
    "skip_modules_classes",
    "non_blocking",
    "_prefix"
  ],
  "apply_layerwise_casting_hook": [
    "module",
    "storage_dtype",
    "compute_dtype",
    "non_blocking"
  ],
  "_is_layerwise_casting_active": [
    "module"
  ],
  "_disable_peft_input_autocast": [
    "module"
  ],
  "AttentionProcessorMetadata": {},
  "TransformerBlockMetadata": {
    "_get_parameter_from_args_kwargs": [
      "self",
      "identifier",
      "args",
      "kwargs"
    ]
  },
  "AttentionProcessorRegistry": {
    "_registry": [],
    "_is_registered": [],
    "register": [
      "cls",
      "model_class",
      "metadata"
    ],
    "get": [
      "cls",
      "model_class"
    ],
    "_register": [
      "cls"
    ]
  },
  "TransformerBlockRegistry": {
    "_registry": [],
    "_is_registered": [],
    "register": [
      "cls",
      "model_class",
      "metadata"
    ],
    "get": [
      "cls",
      "model_class"
    ],
    "_register": [
      "cls"
    ]
  },
  "_register_attention_processors_metadata": [],
  "_register_transformer_blocks_metadata": [],
  "_skip_attention___ret___hidden_states": [
    "self"
  ],
  "_skip_attention___ret___hidden_states___encoder_hidden_states": [
    "self"
  ],
  "_skip_proc_output_fn_Attention_AttnProcessor2_0": [],
  "_skip_proc_output_fn_Attention_CogView4AttnProcessor": [],
  "_skip_proc_output_fn_Attention_WanAttnProcessor2_0": [],
  "_skip_proc_output_fn_Attention_FluxAttnProcessor": [],
  "_skip_proc_output_fn_Attention_QwenDoubleStreamAttnProcessor2_0": [],
  "_skip_proc_output_fn_Attention_HunyuanImageAttnProcessor": [],
  "_skip_proc_output_fn_Attention_ZSingleStreamAttnProcessor": [],
  "_CONTEXT_PARALLEL_INPUT_HOOK_TEMPLATE": [],
  "_CONTEXT_PARALLEL_OUTPUT_HOOK_TEMPLATE": [],
  "ModuleForwardMetadata": {
    "_get_parameter_from_args_kwargs": [
      "self",
      "identifier",
      "args",
      "kwargs"
    ]
  },
  "apply_context_parallel": [
    "module",
    "parallel_config",
    "plan"
  ],
  "remove_context_parallel": [
    "module",
    "plan"
  ],
  "ContextParallelSplitHook": {
    "__init__": [
      "self",
      "metadata",
      "parallel_config"
    ],
    "initialize_hook": [
      "self",
      "module"
    ],
    "pre_forward": [
      "self",
      "module"
    ],
    "post_forward": [
      "self",
      "module",
      "output"
    ],
    "_prepare_cp_input": [
      "self",
      "x",
      "cp_input"
    ]
  },
  "ContextParallelGatherHook": {
    "__init__": [
      "self",
      "metadata",
      "parallel_config"
    ],
    "post_forward": [
      "self",
      "module",
      "output"
    ]
  },
  "AllGatherFunction": {
    "forward": [
      "ctx",
      "tensor",
      "dim",
      "group"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "EquipartitionSharder": {
    "shard": [
      "cls",
      "tensor",
      "dim",
      "mesh"
    ],
    "unshard": [
      "cls",
      "tensor",
      "dim",
      "mesh"
    ]
  },
  "_get_submodule_by_name": [
    "model",
    "name"
  ],
  "_find_submodule_by_name": [
    "model",
    "name"
  ],
  "_FASTER_CACHE_DENOISER_HOOK": [],
  "_FASTER_CACHE_BLOCK_HOOK": [],
  "_UNCOND_COND_INPUT_KWARGS_IDENTIFIERS": [],
  "FasterCacheDenoiserState": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "FasterCacheBlockState": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "FasterCacheDenoiserHook": {
    "_is_stateful": [],
    "__init__": [
      "self",
      "unconditional_batch_skip_range",
      "unconditional_batch_timestep_skip_range",
      "tensor_format",
      "is_guidance_distilled",
      "uncond_cond_input_kwargs_identifiers",
      "current_timestep_callback",
      "low_frequency_weight_callback",
      "high_frequency_weight_callback"
    ],
    "initialize_hook": [
      "self",
      "module"
    ],
    "_get_cond_input": [
      "input"
    ],
    "new_forward": [
      "self",
      "module"
    ],
    "reset_state": [
      "self",
      "module"
    ]
  },
  "FasterCacheBlockHook": {
    "_is_stateful": [],
    "__init__": [
      "self",
      "block_skip_range",
      "timestep_skip_range",
      "is_guidance_distilled",
      "weight_callback",
      "current_timestep_callback"
    ],
    "initialize_hook": [
      "self",
      "module"
    ],
    "_compute_approximated_attention_output": [
      "self",
      "t_2_output",
      "t_output",
      "weight",
      "batch_size"
    ],
    "new_forward": [
      "self",
      "module"
    ],
    "reset_state": [
      "self",
      "module"
    ]
  },
  "_apply_faster_cache_on_denoiser": [
    "module",
    "config"
  ],
  "_apply_faster_cache_on_attention_class": [
    "name",
    "module",
    "config"
  ],
  "_split_low_high_freq": [
    "x"
  ],
  "_PYRAMID_ATTENTION_BROADCAST_HOOK": [],
  "PyramidAttentionBroadcastState": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "PyramidAttentionBroadcastHook": {
    "_is_stateful": [],
    "__init__": [
      "self",
      "timestep_skip_range",
      "block_skip_range",
      "current_timestep_callback"
    ],
    "initialize_hook": [
      "self",
      "module"
    ],
    "new_forward": [
      "self",
      "module"
    ],
    "reset_state": [
      "self",
      "module"
    ]
  },
  "_apply_pyramid_attention_broadcast_on_attention_class": [
    "name",
    "module",
    "config"
  ],
  "_apply_pyramid_attention_broadcast_hook": [
    "module",
    "timestep_skip_range",
    "block_skip_range",
    "current_timestep_callback"
  ],
  "InsertableDict": {
    "insert": [
      "self",
      "key",
      "value",
      "index"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ConfigSpec": {},
  "InputParam": {
    "__repr__": [
      "self"
    ]
  },
  "OutputParam": {
    "__repr__": [
      "self"
    ]
  },
  "format_inputs_short": [
    "inputs"
  ],
  "format_intermediates_short": [
    "intermediate_inputs",
    "required_intermediate_inputs",
    "intermediate_outputs"
  ],
  "format_params": [
    "params",
    "header",
    "indent_level",
    "max_line_length"
  ],
  "format_input_params": [
    "input_params",
    "indent_level",
    "max_line_length"
  ],
  "format_output_params": [
    "output_params",
    "indent_level",
    "max_line_length"
  ],
  "format_components": [
    "components",
    "indent_level",
    "max_line_length",
    "add_empty_lines"
  ],
  "format_configs": [
    "configs",
    "indent_level",
    "max_line_length",
    "add_empty_lines"
  ],
  "make_doc_string": [
    "inputs",
    "outputs",
    "description",
    "class_name",
    "expected_components",
    "expected_configs"
  ],
  "SUPPORTED_NODE_TYPES": [],
  "MELLON_INPUT_PARAMS": [],
  "MELLON_MODEL_PARAMS": [],
  "MELLON_OUTPUT_PARAMS": [],
  "NODE_TYPE_PARAMS_MAP": [],
  "MellonParam": {
    "to_dict": [
      "self"
    ]
  },
  "MellonNodeConfig": {
    "config_name": [],
    "__post_init__": [
      "self"
    ],
    "_resolve_params_list": [
      "params",
      "default_map"
    ],
    "load_mellon_config": [
      "cls",
      "pretrained_model_name_or_path",
      "return_unused_kwargs",
      "return_commit_hash"
    ],
    "save_mellon_config": [
      "self",
      "save_directory",
      "push_to_hub"
    ],
    "to_json_file": [
      "self",
      "json_file_path"
    ],
    "to_json_string": [
      "self"
    ],
    "to_mellon_dict": [
      "self"
    ],
    "from_mellon_dict": [
      "cls",
      "mellon_dict"
    ],
    "from_blocks": [
      "cls",
      "blocks",
      "node_type"
    ]
  },
  "ModularMellonNodeRegistry": {
    "__init__": [
      "self"
    ],
    "register": [
      "self",
      "pipeline_cls",
      "node_params"
    ],
    "get": [
      "self",
      "pipeline_cls"
    ],
    "get_all": [
      "self"
    ]
  },
  "_register_preset_node_types": [
    "pipeline_cls",
    "params_map",
    "registry"
  ],
  "_initialize_registry": [
    "registry"
  ],
  "SDXL_INPUTS_SCHEMA": [],
  "SDXL_INTERMEDIATE_INPUTS_SCHEMA": [],
  "SDXL_PARAM_SCHEMA": [],
  "DEFAULT_PARAM_MAPS": [],
  "DEFAULT_TYPE_MAPS": [],
  "DEFAULT_MODEL_KEYS": [],
  "DEFAULT_CATEGORY": [],
  "DEFAULT_EXCLUDE_MODEL_KEYS": [],
  "DEFAULT_PARAMS_GROUPS_KEYS": [],
  "get_group_name": [
    "name",
    "group_params_keys"
  ],
  "ModularNode": {
    "config_name": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path",
      "trust_remote_code"
    ],
    "__init__": [
      "self",
      "blocks",
      "category",
      "label"
    ],
    "setup": [
      "self",
      "components_manager",
      "collection"
    ],
    "mellon_config": [
      "self"
    ],
    "_convert_to_mellon_config": [
      "self"
    ],
    "save_mellon_config": [
      "self",
      "file_path"
    ],
    "load_mellon_config": [
      "cls",
      "file_path"
    ],
    "process_inputs": [
      "self"
    ],
    "execute": [
      "self"
    ]
  },
  "MODULAR_PIPELINE_MAPPING": [],
  "PipelineState": {
    "set": [
      "self",
      "key",
      "value",
      "kwargs_type"
    ],
    "get": [
      "self",
      "keys",
      "default"
    ],
    "get_by_kwargs": [
      "self",
      "kwargs_type"
    ],
    "to_dict": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "__repr__": [
      "self"
    ]
  },
  "BlockState": {
    "__init__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "as_dict": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "AutoPipelineBlocks": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "__init__": [
      "self"
    ],
    "model_name": [
      "self"
    ],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "expected_configs": [
      "self"
    ],
    "required_inputs": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "pipeline",
      "state"
    ],
    "_get_trigger_inputs": [
      "self"
    ],
    "trigger_inputs": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "doc": [
      "self"
    ]
  },
  "SequentialPipelineBlocks": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ],
    "model_name": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "expected_configs": [
      "self"
    ],
    "from_blocks_dict": [
      "cls",
      "blocks_dict",
      "description"
    ],
    "__init__": [
      "self"
    ],
    "_get_inputs": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "required_inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "pipeline",
      "state"
    ],
    "_get_trigger_inputs": [
      "self"
    ],
    "trigger_inputs": [
      "self"
    ],
    "_traverse_trigger_blocks": [
      "self",
      "trigger_inputs"
    ],
    "get_execution_blocks": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "doc": [
      "self"
    ]
  },
  "LoopSequentialPipelineBlocks": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ],
    "loop_expected_components": [
      "self"
    ],
    "loop_expected_configs": [
      "self"
    ],
    "loop_inputs": [
      "self"
    ],
    "loop_required_inputs": [
      "self"
    ],
    "loop_intermediate_outputs": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "expected_configs": [
      "self"
    ],
    "_get_inputs": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "required_inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "from_blocks_dict": [
      "cls",
      "blocks_dict"
    ],
    "loop_step": [
      "self",
      "components",
      "state"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ],
    "doc": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "progress_bar": [
      "self",
      "iterable",
      "total"
    ],
    "set_progress_bar_config": [
      "self"
    ]
  },
  "CustomOffloadHook": {
    "no_grad": [],
    "__init__": [
      "self",
      "execution_device",
      "other_hooks",
      "offload_strategy"
    ],
    "set_strategy": [
      "self",
      "offload_strategy"
    ],
    "add_other_hook": [
      "self",
      "hook"
    ],
    "init_hook": [
      "self",
      "module"
    ],
    "pre_forward": [
      "self",
      "module"
    ]
  },
  "UserCustomOffloadHook": {
    "__init__": [
      "self",
      "model_id",
      "model",
      "hook"
    ],
    "offload": [
      "self"
    ],
    "attach": [
      "self"
    ],
    "remove": [
      "self"
    ],
    "add_other_hook": [
      "self",
      "hook"
    ]
  },
  "custom_offload_with_hook": [
    "model_id",
    "model",
    "execution_device",
    "offload_strategy"
  ],
  "AutoOffloadStrategy": {
    "__init__": [
      "self",
      "memory_reserve_margin"
    ],
    "__call__": [
      "self",
      "hooks",
      "model_id",
      "model",
      "execution_device"
    ]
  },
  "summarize_dict_by_value_and_parts": [
    "d"
  ],
  "repeat_tensor_to_batch_size": [
    "input_name",
    "input_tensor",
    "batch_size",
    "num_images_per_prompt"
  ],
  "calculate_dimension_from_latents": [
    "latents",
    "vae_scale_factor"
  ],
  "QwenImageTextInputsStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "prompt_embeds",
      "prompt_embeds_mask",
      "negative_prompt_embeds",
      "negative_prompt_embeds_mask"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageInputsDynamicStep": {
    "model_name": [],
    "__init__": [
      "self",
      "image_latent_inputs",
      "additional_batch_inputs"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageControlNetInputsStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageLoopBeforeDenoiser": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "QwenImageEditLoopBeforeDenoiser": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "QwenImageLoopBeforeDenoiserControlNet": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "QwenImageLoopDenoiser": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "QwenImageEditLoopDenoiser": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "QwenImageLoopAfterDenoiser": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "QwenImageLoopAfterDenoiserInpaint": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "QwenImageDenoiseLoopWrapper": {
    "model_name": [],
    "description": [
      "self"
    ],
    "loop_expected_components": [
      "self"
    ],
    "loop_inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageInpaintDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageControlNetDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageInpaintControlNetDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageEditDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageEditInpaintDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "calculate_shift": [
    "image_seq_len",
    "base_seq_len",
    "max_seq_len",
    "base_shift",
    "max_shift"
  ],
  "retrieve_timesteps": [
    "scheduler",
    "num_inference_steps",
    "device",
    "timesteps",
    "sigmas"
  ],
  "get_timesteps": [
    "scheduler",
    "num_inference_steps",
    "strength"
  ],
  "QwenImagePrepareLatentsStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "height",
      "width",
      "vae_scale_factor"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImagePrepareLatentsWithStrengthStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "image_latents",
      "latents"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageCreateMaskLatentsStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageSetTimestepsStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageSetTimestepsWithStrengthStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageRoPEInputsStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageEditRoPEInputsStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageControlNetBeforeDenoiserStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageDecoderStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageProcessImagesOutputStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "check_inputs": [
      "output_type"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageInpaintProcessImagesOutputStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "check_inputs": [
      "output_type",
      "mask_overlay_kwargs"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImage_NODE_TYPES_PARAMS_MAP": [],
  "QwenImagePachifier": {
    "config_name": [],
    "__init__": [
      "self",
      "patch_size"
    ],
    "pack_latents": [
      "self",
      "latents"
    ],
    "unpack_latents": [
      "self",
      "latents",
      "height",
      "width",
      "vae_scale_factor"
    ]
  },
  "_extract_masked_hidden": [
    "hidden_states",
    "mask"
  ],
  "get_qwen_prompt_embeds": [
    "text_encoder",
    "tokenizer",
    "prompt",
    "prompt_template_encode",
    "prompt_template_encode_start_idx",
    "tokenizer_max_length",
    "device"
  ],
  "get_qwen_prompt_embeds_edit": [
    "text_encoder",
    "processor",
    "prompt",
    "image",
    "prompt_template_encode",
    "prompt_template_encode_start_idx",
    "device"
  ],
  "get_qwen_prompt_embeds_edit_plus": [
    "text_encoder",
    "processor",
    "prompt",
    "image",
    "prompt_template_encode",
    "img_template_encode",
    "prompt_template_encode_start_idx",
    "device"
  ],
  "retrieve_latents": [
    "encoder_output",
    "generator",
    "sample_mode"
  ],
  "encode_vae_image": [
    "image",
    "vae",
    "generator",
    "device",
    "dtype",
    "latent_channels",
    "sample_mode"
  ],
  "QwenImageEditResizeDynamicStep": {
    "model_name": [],
    "__init__": [
      "self",
      "input_name",
      "output_name"
    ],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageEditPlusResizeDynamicStep": {
    "model_name": [],
    "__init__": [
      "self",
      "input_name",
      "output_name",
      "vae_image_output_name"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageTextEncoderStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "expected_configs": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "prompt",
      "negative_prompt",
      "max_sequence_length"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageEditTextEncoderStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "expected_configs": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "prompt",
      "negative_prompt"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageEditPlusTextEncoderStep": {
    "model_name": [],
    "expected_configs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageInpaintProcessImagesInputStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "height",
      "width",
      "vae_scale_factor"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageProcessImagesInputStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "height",
      "width",
      "vae_scale_factor"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageEditPlusProcessImagesInputStep": {
    "model_name": [],
    "vae_image_size": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageVaeEncoderDynamicStep": {
    "model_name": [],
    "__init__": [
      "self",
      "input_name",
      "output_name"
    ],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageControlNetVaeEncoderStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "height",
      "width",
      "vae_scale_factor"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "QwenImageDecodeBlocks": [],
  "QwenImageDecodeStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "TEXT2IMAGE_BLOCKS": [],
  "QwenImageInpaintVaeEncoderBlocks": [],
  "QwenImageInpaintVaeEncoderStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageInpaintInputBlocks": [],
  "QwenImageInpaintInputStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageInpaintPrepareLatentsBlocks": [],
  "QwenImageInpaintPrepareLatentsStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageInpaintDecodeBlocks": [],
  "QwenImageInpaintDecodeStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "INPAINT_BLOCKS": [],
  "QwenImageImg2ImgVaeEncoderBlocks": [],
  "QwenImageImg2ImgVaeEncoderStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageImg2ImgInputBlocks": [],
  "QwenImageImg2ImgInputStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "IMAGE2IMAGE_BLOCKS": [],
  "CONTROLNET_BLOCKS": [],
  "QwenImageAutoVaeEncoderStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageOptionalControlNetVaeEncoderStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageAutoInputStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageOptionalControlNetInputStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageText2ImageBeforeDenoiseBlocks": [],
  "QwenImageText2ImageBeforeDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageInpaintBeforeDenoiseBlocks": [],
  "QwenImageInpaintBeforeDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageImg2ImgBeforeDenoiseBlocks": [],
  "QwenImageImg2ImgBeforeDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageAutoBeforeDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageOptionalControlNetBeforeDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageControlNetAutoDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageAutoDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageAutoDecodeStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageCoreDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "AUTO_BLOCKS": [],
  "QwenImageEditVLEncoderBlocks": [],
  "QwenImageEditVLEncoderStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageEditVaeEncoderBlocks": [],
  "QwenImageEditVaeEncoderStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageEditInputBlocks": [],
  "QwenImageEditInputStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "EDIT_BLOCKS": [],
  "QwenImageEditInpaintVaeEncoderBlocks": [],
  "QwenImageEditInpaintVaeEncoderStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "EDIT_INPAINT_BLOCKS": [],
  "QwenImageEditAutoVaeEncoderStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageEditAutoInputStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageEditBeforeDenoiseBlocks": [],
  "QwenImageEditBeforeDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageEditInpaintBeforeDenoiseBlocks": [],
  "QwenImageEditInpaintBeforeDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageEditAutoBeforeDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageEditAutoDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageEditCoreDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "EDIT_AUTO_BLOCKS": [],
  "QwenImageEditPlusVLEncoderBlocks": [],
  "QwenImageEditPlusVLEncoderStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "QwenImageEditPlusVaeEncoderBlocks": [],
  "QwenImageEditPlusVaeEncoderStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "EDIT_PLUS_BLOCKS": [],
  "QwenImageEditPlusAutoBeforeDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageEditPlusAutoVaeEncoderStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "QwenImageEditPlusCoreDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "EDIT_PLUS_AUTO_BLOCKS": [],
  "ALL_BLOCKS": [],
  "WanLoopBeforeDenoiser": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "WanImage2VideoLoopBeforeDenoiser": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "WanFLF2VLoopBeforeDenoiser": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "WanLoopDenoiser": {
    "model_name": [],
    "__init__": [
      "self",
      "guider_input_fields"
    ],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "Wan22LoopDenoiser": {
    "model_name": [],
    "__init__": [
      "self",
      "guider_input_fields"
    ],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "expected_configs": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "WanLoopAfterDenoiser": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "WanDenoiseLoopWrapper": {
    "model_name": [],
    "description": [
      "self"
    ],
    "loop_expected_components": [
      "self"
    ],
    "loop_inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "Wan22DenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "WanImage2VideoDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "Wan22Image2VideoDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "WanFLF2VDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "WanTextInputStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "self",
      "components",
      "block_state"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanAdditionalInputsStep": {
    "model_name": [],
    "__init__": [
      "self",
      "image_latent_inputs",
      "additional_batch_inputs"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanSetTimestepsStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanPrepareLatentsStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "components",
      "block_state"
    ],
    "prepare_latents": [
      "comp",
      "batch_size",
      "num_channels_latents",
      "height",
      "width",
      "num_frames",
      "dtype",
      "device",
      "generator",
      "latents"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanPrepareFirstFrameLatentsStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanPrepareFirstLastFrameLatentsStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanImageVaeDecoderStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "basic_clean": [
    "text"
  ],
  "whitespace_clean": [
    "text"
  ],
  "prompt_clean": [
    "text"
  ],
  "get_t5_prompt_embeds": [
    "text_encoder",
    "tokenizer",
    "prompt",
    "max_sequence_length",
    "device"
  ],
  "encode_image": [
    "image",
    "image_processor",
    "image_encoder",
    "device"
  ],
  "WanTextEncoderStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "block_state"
    ],
    "encode_prompt": [
      "components",
      "prompt",
      "device",
      "prepare_unconditional_embeds",
      "negative_prompt",
      "max_sequence_length"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanImageResizeStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanImageCropResizeStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanImageEncoderStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanFirstLastFrameImageEncoderStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanVaeImageEncoderStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "components",
      "block_state"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanFirstLastFrameVaeImageEncoderStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "components",
      "block_state"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "WanCoreDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "WanImage2VideoImageEncoderStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "WanImage2VideoVaeImageEncoderStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "WanImage2VideoCoreDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "WanFLF2VImageEncoderStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "WanFLF2VVaeImageEncoderStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "WanFLF2VCoreDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "WanAutoImageEncoderStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "WanAutoVaeImageEncoderStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "WanAutoDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "Wan22CoreDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "Wan22Image2VideoCoreDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "Wan22AutoDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "TEXT2VIDEO_BLOCKS": [],
  "IMAGE2VIDEO_BLOCKS": [],
  "FLF2V_BLOCKS": [],
  "TEXT2VIDEO_BLOCKS_WAN22": [],
  "IMAGE2VIDEO_BLOCKS_WAN22": [],
  "AUTO_BLOCKS_WAN22": [],
  "StableDiffusionXLLoopBeforeDenoiser": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "StableDiffusionXLInpaintLoopBeforeDenoiser": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "check_inputs": [
      "components",
      "block_state"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "StableDiffusionXLLoopDenoiser": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "StableDiffusionXLControlNetLoopDenoiser": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "prepare_extra_kwargs": [
      "func",
      "exclude_kwargs"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "StableDiffusionXLLoopAfterDenoiser": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "prepare_extra_kwargs": [
      "func",
      "exclude_kwargs"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "StableDiffusionXLInpaintLoopAfterDenoiser": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "prepare_extra_kwargs": [
      "func",
      "exclude_kwargs"
    ],
    "check_inputs": [
      "self",
      "components",
      "block_state"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "StableDiffusionXLDenoiseLoopWrapper": {
    "model_name": [],
    "description": [
      "self"
    ],
    "loop_expected_components": [
      "self"
    ],
    "loop_inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLControlNetDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLInpaintDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLInpaintControlNetDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "prepare_latents_img2img": [
    "vae",
    "scheduler",
    "image",
    "timestep",
    "batch_size",
    "num_images_per_prompt",
    "dtype",
    "device",
    "generator",
    "add_noise"
  ],
  "StableDiffusionXLInputStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "self",
      "components",
      "block_state"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLImg2ImgSetTimestepsStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "get_timesteps": [
      "components",
      "num_inference_steps",
      "strength",
      "device",
      "denoising_start"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLSetTimestepsStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLInpaintPrepareLatentsStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "_encode_vae_image": [
      "components",
      "image",
      "generator"
    ],
    "prepare_latents_inpaint": [
      "self",
      "components",
      "batch_size",
      "num_channels_latents",
      "height",
      "width",
      "dtype",
      "device",
      "generator",
      "latents",
      "image",
      "timestep",
      "is_strength_max",
      "add_noise"
    ],
    "prepare_mask_latents": [
      "self",
      "components",
      "mask",
      "masked_image",
      "batch_size",
      "height",
      "width",
      "dtype",
      "device",
      "generator"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLImg2ImgPrepareLatentsStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLPrepareLatentsStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "components",
      "block_state"
    ],
    "prepare_latents": [
      "comp",
      "batch_size",
      "num_channels_latents",
      "height",
      "width",
      "dtype",
      "device",
      "generator",
      "latents"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLImg2ImgPrepareAdditionalConditioningStep": {
    "model_name": [],
    "expected_configs": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "_get_add_time_ids": [
      "components",
      "original_size",
      "crops_coords_top_left",
      "target_size",
      "aesthetic_score",
      "negative_aesthetic_score",
      "negative_original_size",
      "negative_crops_coords_top_left",
      "negative_target_size",
      "dtype",
      "text_encoder_projection_dim"
    ],
    "get_guidance_scale_embedding": [
      "self",
      "w",
      "embedding_dim",
      "dtype"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLPrepareAdditionalConditioningStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "_get_add_time_ids": [
      "components",
      "original_size",
      "crops_coords_top_left",
      "target_size",
      "dtype",
      "text_encoder_projection_dim"
    ],
    "get_guidance_scale_embedding": [
      "self",
      "w",
      "embedding_dim",
      "dtype"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLControlNetInputStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "prepare_control_image": [
      "components",
      "image",
      "width",
      "height",
      "batch_size",
      "num_images_per_prompt",
      "device",
      "dtype",
      "crops_coords"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLControlNetUnionInputStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "prepare_control_image": [
      "components",
      "image",
      "width",
      "height",
      "batch_size",
      "num_images_per_prompt",
      "device",
      "dtype",
      "crops_coords"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLDecodeStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "upcast_vae": [
      "components"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLInpaintOverlayMaskStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "SDXL_NODE_TYPES_PARAMS_MAP": [],
  "SDXL_INTERMEDIATE_OUTPUTS_SCHEMA": [],
  "SDXL_OUTPUTS_SCHEMA": [],
  "StableDiffusionXLIPAdapterStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "encode_image": [
      "components",
      "image",
      "device",
      "num_images_per_prompt",
      "output_hidden_states"
    ],
    "prepare_ip_adapter_image_embeds": [
      "self",
      "components",
      "ip_adapter_image",
      "ip_adapter_image_embeds",
      "device",
      "num_images_per_prompt",
      "prepare_unconditional_embeds"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLTextEncoderStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "expected_configs": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "block_state"
    ],
    "encode_prompt": [
      "components",
      "prompt",
      "prompt_2",
      "device",
      "num_images_per_prompt",
      "prepare_unconditional_embeds",
      "negative_prompt",
      "negative_prompt_2",
      "prompt_embeds",
      "negative_prompt_embeds",
      "pooled_prompt_embeds",
      "negative_pooled_prompt_embeds",
      "lora_scale",
      "clip_skip"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLVaeEncoderStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "_encode_vae_image": [
      "self",
      "components",
      "image",
      "generator"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLInpaintVaeEncoderStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "_encode_vae_image": [
      "self",
      "components",
      "image",
      "generator"
    ],
    "prepare_mask_latents": [
      "self",
      "components",
      "mask",
      "masked_image",
      "batch_size",
      "height",
      "width",
      "dtype",
      "device",
      "generator"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "StableDiffusionXLAutoVaeEncoderStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLAutoIPAdapterStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLBeforeDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLImg2ImgBeforeDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLInpaintBeforeDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLAutoBeforeDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLAutoControlNetInputStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLAutoControlNetDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLAutoDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLInpaintDecodeStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLAutoDecodeStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLCoreDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "StableDiffusionXLAutoControlnetStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "IP_ADAPTER_BLOCKS": [],
  "FluxTextInputStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "self",
      "components",
      "block_state"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxInputsDynamicStep": {
    "model_name": [],
    "__init__": [
      "self",
      "image_latent_inputs",
      "additional_batch_inputs"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxKontextInputsDynamicStep": {
    "model_name": [],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxKontextSetResolutionStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "height",
      "width",
      "vae_scale_factor"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxLoopDenoiser": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "FluxKontextLoopDenoiser": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "FluxLoopAfterDenoiser": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "block_state",
      "i",
      "t"
    ]
  },
  "FluxDenoiseLoopWrapper": {
    "model_name": [],
    "description": [
      "self"
    ],
    "loop_expected_components": [
      "self"
    ],
    "loop_inputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "FluxKontextDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "_get_initial_timesteps_and_optionals": [
    "transformer",
    "scheduler",
    "batch_size",
    "height",
    "width",
    "vae_scale_factor",
    "num_inference_steps",
    "guidance_scale",
    "sigmas",
    "device"
  ],
  "FluxSetTimestepsStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxImg2ImgSetTimestepsStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "get_timesteps": [
      "scheduler",
      "num_inference_steps",
      "strength",
      "device"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxPrepareLatentsStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "components",
      "block_state"
    ],
    "prepare_latents": [
      "comp",
      "batch_size",
      "num_channels_latents",
      "height",
      "width",
      "dtype",
      "device",
      "generator",
      "latents"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxImg2ImgPrepareLatentsStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "image_latents",
      "latents"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxRoPEInputsStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxKontextRoPEInputsStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "_unpack_latents": [
    "latents",
    "height",
    "width",
    "vae_scale_factor"
  ],
  "FluxDecodeStep": {
    "model_name": [],
    "expected_components": [
      "self"
    ],
    "description": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxProcessImagesInputStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "height",
      "width",
      "vae_scale_factor"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxKontextProcessImagesInputStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxVaeEncoderDynamicStep": {
    "model_name": [],
    "__init__": [
      "self",
      "input_name",
      "output_name",
      "sample_mode"
    ],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxTextEncoderStep": {
    "model_name": [],
    "description": [
      "self"
    ],
    "expected_components": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "intermediate_outputs": [
      "self"
    ],
    "check_inputs": [
      "block_state"
    ],
    "_get_t5_prompt_embeds": [
      "components",
      "prompt",
      "max_sequence_length",
      "device"
    ],
    "_get_clip_prompt_embeds": [
      "components",
      "prompt",
      "device"
    ],
    "encode_prompt": [
      "components",
      "prompt",
      "prompt_2",
      "device",
      "prompt_embeds",
      "pooled_prompt_embeds",
      "max_sequence_length",
      "lora_scale"
    ],
    "__call__": [
      "self",
      "components",
      "state"
    ]
  },
  "FluxImg2ImgVaeEncoderBlocks": [],
  "FluxImg2ImgVaeEncoderStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "FluxAutoVaeEncoderStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "FluxKontextVaeEncoderBlocks": [],
  "FluxKontextVaeEncoderStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "FluxKontextAutoVaeEncoderStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "FluxBeforeDenoiseBlocks": [],
  "FluxBeforeDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "FluxImg2ImgBeforeDenoiseBlocks": [],
  "FluxImg2ImgBeforeDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "FluxAutoBeforeDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "FluxKontextBeforeDenoiseBlocks": [],
  "FluxKontextBeforeDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "FluxKontextAutoBeforeDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "FluxAutoDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "FluxKontextAutoDenoiseStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "FluxAutoDecodeStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "FluxImg2ImgBlocks": [],
  "FluxImg2ImgInputStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "FluxAutoInputStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "FluxKontextBlocks": [],
  "FluxKontextInputStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "FluxKontextAutoInputStep": {
    "block_classes": [],
    "block_names": [],
    "block_trigger_inputs": [],
    "description": [
      "self"
    ]
  },
  "FluxCoreDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "FluxKontextCoreDenoiseStep": {
    "model_name": [],
    "block_classes": [],
    "block_names": [],
    "description": [
      "self"
    ]
  },
  "AUTO_BLOCKS_KONTEXT": [],
  "FLUX_KONTEXT_BLOCKS": [],
  "INDEX_FILE": [],
  "CUSTOM_PIPELINE_FILE_NAME": [],
  "DUMMY_MODULES_FOLDER": [],
  "TRANSFORMERS_DUMMY_MODULES_FOLDER": [],
  "CONNECTED_PIPES_KEYS": [],
  "LOADABLE_CLASSES": [],
  "ALL_IMPORTABLE_CLASSES": [],
  "is_safetensors_compatible": [
    "filenames",
    "passed_components",
    "folder_names",
    "variant"
  ],
  "filter_model_files": [
    "filenames"
  ],
  "filter_with_regex": [
    "filenames",
    "pattern_re"
  ],
  "variant_compatible_siblings": [
    "filenames",
    "variant",
    "ignore_patterns"
  ],
  "warn_deprecated_model_variant": [
    "pretrained_model_name_or_path",
    "token",
    "variant",
    "revision",
    "model_filenames"
  ],
  "_unwrap_model": [
    "model"
  ],
  "maybe_raise_or_warn": [
    "library_name",
    "library",
    "class_name",
    "importable_classes",
    "passed_class_obj",
    "name",
    "is_pipeline_module"
  ],
  "simple_get_class_obj": [
    "library_name",
    "class_name"
  ],
  "get_class_obj_and_candidates": [
    "library_name",
    "class_name",
    "importable_classes",
    "pipelines",
    "is_pipeline_module",
    "component_name",
    "cache_dir"
  ],
  "_get_custom_pipeline_class": [
    "custom_pipeline",
    "repo_id",
    "hub_revision",
    "class_name",
    "cache_dir",
    "revision"
  ],
  "_get_pipeline_class": [
    "class_obj",
    "config",
    "load_connected_pipeline",
    "custom_pipeline",
    "repo_id",
    "hub_revision",
    "class_name",
    "cache_dir",
    "revision"
  ],
  "_load_empty_model": [
    "library_name",
    "class_name",
    "importable_classes",
    "pipelines",
    "is_pipeline_module",
    "name",
    "torch_dtype",
    "cached_folder"
  ],
  "_assign_components_to_devices": [
    "module_sizes",
    "device_memory",
    "device_mapping_strategy"
  ],
  "_get_final_device_map": [
    "device_map",
    "pipeline_class",
    "passed_class_obj",
    "init_dict",
    "library",
    "max_memory"
  ],
  "load_sub_model": [
    "library_name",
    "class_name",
    "importable_classes",
    "pipelines",
    "is_pipeline_module",
    "pipeline_class",
    "torch_dtype",
    "provider",
    "sess_options",
    "device_map",
    "max_memory",
    "offload_folder",
    "offload_state_dict",
    "model_variants",
    "name",
    "from_flax",
    "variant",
    "low_cpu_mem_usage",
    "cached_folder",
    "use_safetensors",
    "dduf_entries",
    "provider_options",
    "quantization_config"
  ],
  "_get_load_method": [
    "class_obj",
    "load_method_name",
    "is_dduf"
  ],
  "_fetch_class_library_tuple": [
    "module"
  ],
  "_identify_model_variants": [
    "folder",
    "variant",
    "config"
  ],
  "_resolve_custom_pipeline_and_cls": [
    "folder",
    "config",
    "custom_pipeline"
  ],
  "_maybe_raise_warning_for_inpainting": [
    "pipeline_class",
    "pretrained_model_name_or_path",
    "config"
  ],
  "_update_init_kwargs_with_connected_pipeline": [
    "init_kwargs",
    "passed_pipe_kwargs",
    "passed_class_objs",
    "folder"
  ],
  "_get_custom_components_and_folders": [
    "pretrained_model_name",
    "config_dict",
    "filenames",
    "variant_filenames",
    "variant"
  ],
  "_get_ignore_patterns": [
    "passed_components",
    "model_folder_names",
    "model_filenames",
    "use_safetensors",
    "from_flax",
    "allow_pickle",
    "use_onnx",
    "is_onnx",
    "variant"
  ],
  "_download_dduf_file": [
    "pretrained_model_name",
    "dduf_file",
    "pipeline_class_name",
    "cache_dir",
    "proxies",
    "local_files_only",
    "token",
    "revision"
  ],
  "_maybe_raise_error_for_incorrect_transformers": [
    "config_dict"
  ],
  "_maybe_warn_for_wrong_component_in_quant_config": [
    "pipe_init_dict",
    "quant_config"
  ],
  "LIBRARIES": [],
  "SUPPORTED_DEVICE_MAP": [],
  "DeprecatedPipelineMixin": {
    "_last_supported_version": [],
    "__init__": [
      "self"
    ]
  },
  "FreeInitMixin": {
    "enable_free_init": [
      "self",
      "num_iters",
      "use_fast_sampling",
      "method",
      "order",
      "spatial_stop_frequency",
      "temporal_stop_frequency"
    ],
    "disable_free_init": [
      "self"
    ],
    "free_init_enabled": [
      "self"
    ],
    "_get_free_init_freq_filter": [
      "self",
      "shape",
      "device",
      "filter_type",
      "order",
      "spatial_stop_frequency",
      "temporal_stop_frequency"
    ],
    "_apply_freq_filter": [
      "self",
      "x",
      "noise",
      "low_pass_filter"
    ],
    "_apply_free_init": [
      "self",
      "latents",
      "free_init_iteration",
      "num_inference_steps",
      "device",
      "dtype",
      "generator"
    ]
  },
  "_load_tokenizer_from_dduf": [
    "cls",
    "name",
    "dduf_entries"
  ],
  "_load_transformers_model_from_dduf": [
    "cls",
    "name",
    "dduf_entries"
  ],
  "import_flax_or_no_model": [
    "module",
    "class_name"
  ],
  "FlaxImagePipelineOutput": {},
  "AUTO_TEXT2IMAGE_PIPELINES_MAPPING": [],
  "AUTO_IMAGE2IMAGE_PIPELINES_MAPPING": [],
  "AUTO_INPAINT_PIPELINES_MAPPING": [],
  "AUTO_TEXT2VIDEO_PIPELINES_MAPPING": [],
  "AUTO_IMAGE2VIDEO_PIPELINES_MAPPING": [],
  "AUTO_VIDEO2VIDEO_PIPELINES_MAPPING": [],
  "_AUTO_TEXT2IMAGE_DECODER_PIPELINES_MAPPING": [],
  "_AUTO_IMAGE2IMAGE_DECODER_PIPELINES_MAPPING": [],
  "_AUTO_INPAINT_DECODER_PIPELINES_MAPPING": [],
  "SUPPORTED_TASKS_MAPPINGS": [],
  "_get_connected_pipeline": [
    "pipeline_cls"
  ],
  "_get_model": [
    "pipeline_class_name"
  ],
  "_get_task_class": [
    "mapping",
    "pipeline_class_name",
    "throw_error_if_not_exist"
  ],
  "ORT_TO_NP_TYPE": [],
  "SplitInferenceModule": {
    "__init__": [
      "self",
      "module",
      "split_size",
      "split_dim",
      "input_kwargs_to_split"
    ],
    "forward": [
      "self"
    ]
  },
  "AnimateDiffFreeNoiseMixin": {
    "_enable_free_noise_in_block": [
      "self",
      "block"
    ],
    "_disable_free_noise_in_block": [
      "self",
      "block"
    ],
    "_check_inputs_free_noise": [
      "self",
      "prompt",
      "negative_prompt",
      "prompt_embeds",
      "negative_prompt_embeds",
      "num_frames"
    ],
    "_encode_prompt_free_noise": [
      "self",
      "prompt",
      "num_frames",
      "device",
      "num_videos_per_prompt",
      "do_classifier_free_guidance",
      "negative_prompt",
      "prompt_embeds",
      "negative_prompt_embeds",
      "lora_scale",
      "clip_skip"
    ],
    "_prepare_latents_free_noise": [
      "self",
      "batch_size",
      "num_channels_latents",
      "num_frames",
      "height",
      "width",
      "dtype",
      "device",
      "generator",
      "latents"
    ],
    "_lerp": [
      "self",
      "start_index",
      "end_index",
      "start_tensor",
      "end_tensor"
    ],
    "enable_free_noise": [
      "self",
      "context_length",
      "context_stride",
      "weighting_scheme",
      "noise_type",
      "prompt_interpolation_callback"
    ],
    "disable_free_noise": [
      "self"
    ],
    "_enable_split_inference_motion_modules_": [
      "self",
      "motion_modules",
      "spatial_split_size"
    ],
    "_enable_split_inference_attentions_": [
      "self",
      "attentions",
      "temporal_split_size"
    ],
    "_enable_split_inference_resnets_": [
      "self",
      "resnets",
      "temporal_split_size"
    ],
    "_enable_split_inference_samplers_": [
      "self",
      "samplers",
      "temporal_split_size"
    ],
    "enable_free_noise_split_inference": [
      "self",
      "spatial_split_size",
      "temporal_split_size"
    ],
    "free_noise_enabled": [
      "self"
    ]
  },
  "prepare_mask_and_masked_image": [
    "image",
    "mask"
  ],
  "PaintByExampleImageEncoder": {
    "__init__": [
      "self",
      "config",
      "proj_size"
    ],
    "forward": [
      "self",
      "pixel_values",
      "return_uncond_vector"
    ]
  },
  "PaintByExampleMapper": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EXAMPLE_DOC_STRING": [],
  "DEFAULT_PROMPT_TEMPLATE": [],
  "FramepackSamplingType": {
    "VANILLA": [],
    "INVERTED_ANTI_DRIFTING": []
  },
  "_expand_input_ids_with_image_tokens": [
    "text_input_ids",
    "prompt_attention_mask",
    "max_sequence_length",
    "image_token_index",
    "image_emb_len",
    "image_emb_start",
    "image_emb_end",
    "pad_token_id"
  ],
  "HunyuanVideoPipelineOutput": {},
  "HunyuanVideoFramepackPipelineOutput": {},
  "BriaPipelineOutput": {},
  "is_ng_none": [
    "negative_prompt"
  ],
  "get_original_sigmas": [
    "num_train_timesteps",
    "num_inference_steps"
  ],
  "SanaVideoPipelineOutput": {},
  "ASPECT_RATIO_480_BIN": [],
  "ASPECT_RATIO_720_BIN": [],
  "I2VGenXLPipelineOutput": {},
  "_convert_pt_to_pil": [
    "image"
  ],
  "_resize_bilinear": [
    "image",
    "resolution"
  ],
  "_center_crop_wide": [
    "image",
    "resolution"
  ],
  "calculate_dimensions": [
    "target_area",
    "ratio"
  ],
  "_additional_imports": [],
  "QwenImagePipelineOutput": {},
  "CONDITION_IMAGE_SIZE": [],
  "VAE_IMAGE_SIZE": [],
  "LucyPipelineOutput": {},
  "EXAMPLE_INTERPOLATE_DOC_STRING": [],
  "TEXT2IMAGE_EXAMPLE_DOC_STRING": [],
  "IMAGE2IMAGE_EXAMPLE_DOC_STRING": [],
  "INPAINT_EXAMPLE_DOC_STRING": [],
  "downscale_height_and_width": [
    "height",
    "width",
    "scale_factor"
  ],
  "prepare_mask": [
    "masks"
  ],
  "DiffEditInversionPipelineOutput": {},
  "EXAMPLE_INVERT_DOC_STRING": [],
  "auto_corr_loss": [
    "hidden_states",
    "generator"
  ],
  "kl_divergence": [
    "hidden_states"
  ],
  "preprocess": [
    "image"
  ],
  "preprocess_mask": [
    "mask",
    "batch_size"
  ],
  "_no_grad_trunc_normal_": [
    "tensor",
    "mean",
    "std",
    "a",
    "b"
  ],
  "trunc_normal_": [
    "tensor",
    "mean",
    "std",
    "a",
    "b"
  ],
  "PatchEmbed": {
    "__init__": [
      "self",
      "height",
      "width",
      "patch_size",
      "in_channels",
      "embed_dim",
      "layer_norm",
      "flatten",
      "bias",
      "use_pos_embed"
    ],
    "forward": [
      "self",
      "latent"
    ]
  },
  "SkipBlock": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x",
      "skip"
    ]
  },
  "UTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "dropout",
      "cross_attention_dim",
      "activation_fn",
      "num_embeds_ada_norm",
      "attention_bias",
      "only_cross_attention",
      "double_self_attention",
      "upcast_attention",
      "norm_elementwise_affine",
      "norm_type",
      "pre_layer_norm",
      "final_dropout"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "timestep",
      "cross_attention_kwargs",
      "class_labels"
    ]
  },
  "UniDiffuserBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "dropout",
      "cross_attention_dim",
      "activation_fn",
      "num_embeds_ada_norm",
      "attention_bias",
      "only_cross_attention",
      "double_self_attention",
      "upcast_attention",
      "norm_elementwise_affine",
      "norm_type",
      "pre_layer_norm",
      "final_dropout"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "timestep",
      "cross_attention_kwargs",
      "class_labels"
    ]
  },
  "UTransformer2DModel": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "in_channels",
      "out_channels",
      "num_layers",
      "dropout",
      "norm_num_groups",
      "cross_attention_dim",
      "attention_bias",
      "sample_size",
      "num_vector_embeds",
      "patch_size",
      "activation_fn",
      "num_embeds_ada_norm",
      "use_linear_projection",
      "only_cross_attention",
      "upcast_attention",
      "norm_type",
      "block_type",
      "pre_layer_norm",
      "norm_elementwise_affine",
      "use_patch_pos_embed",
      "ff_final_dropout"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "timestep",
      "class_labels",
      "cross_attention_kwargs",
      "return_dict",
      "hidden_states_is_embedding",
      "unpatchify"
    ]
  },
  "DEFAULT_RESOLUTION": [],
  "ASPECT_RATIO_256_BIN": [],
  "ASPECT_RATIO_512_BIN": [],
  "ASPECT_RATIO_1024_BIN": [],
  "ASPECT_RATIO_BINS": [],
  "TextPreprocessor": {
    "__init__": [
      "self"
    ],
    "clean_text": [
      "self",
      "text"
    ]
  },
  "PRXPipelineOutput": {},
  "ChromaPipelineOutput": {},
  "CogView4PipelineOutput": {},
  "LattePipelineOutput": {},
  "LDMBERT_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "LDMBERT_PRETRAINED_CONFIG_ARCHIVE_MAP": [],
  "LDMBertConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "max_position_embeddings",
      "encoder_layers",
      "encoder_ffn_dim",
      "encoder_attention_heads",
      "head_dim",
      "encoder_layerdrop",
      "activation_function",
      "d_model",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "init_std",
      "classifier_dropout",
      "scale_embedding",
      "use_cache",
      "pad_token_id"
    ]
  },
  "_expand_mask": [
    "mask",
    "dtype",
    "tgt_len"
  ],
  "LDMBertAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "head_dim",
      "dropout",
      "is_decoder",
      "bias"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states",
      "key_value_states",
      "past_key_value",
      "attention_mask",
      "layer_head_mask",
      "output_attentions"
    ]
  },
  "LDMBertEncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "layer_head_mask",
      "output_attentions"
    ]
  },
  "LDMBertPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "_supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "dummy_inputs": [
      "self"
    ]
  },
  "LDMBertEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "LDMBertModel": {
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CosmosPipelineOutput": {},
  "CosmosImagePipelineOutput": {},
  "KandinskyPipelineOutput": {},
  "KandinskyImagePipelineOutput": {},
  "rescale_noise_cfg": [
    "noise_cfg",
    "noise_pred_text",
    "guidance_rescale"
  ],
  "TransformationModelOutput": {},
  "RobertaSeriesConfig": {
    "__init__": [
      "self",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "project_dim",
      "pooler_fn",
      "learn_encoder",
      "use_attention_mask"
    ]
  },
  "RobertaSeriesModelWithTransformation": {
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_load_missing": [],
    "base_model_prefix": [],
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "output_attentions",
      "return_dict",
      "output_hidden_states"
    ]
  },
  "AltDiffusionPipelineOutput": {},
  "Pix2PixInversionPipelineOutput": {},
  "prepare_unet": [
    "unet"
  ],
  "Pix2PixZeroL2Loss": {
    "__init__": [
      "self"
    ],
    "compute_loss": [
      "self",
      "predictions",
      "targets"
    ]
  },
  "Pix2PixZeroAttnProcessor": {
    "__init__": [
      "self",
      "is_pix2pix_zero"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "timestep",
      "loss"
    ]
  },
  "posterior_sample": [
    "scheduler",
    "latents",
    "timestep",
    "clean_latents",
    "generator",
    "eta"
  ],
  "compute_noise": [
    "scheduler",
    "prev_latents",
    "latents",
    "timestep",
    "noise_pred",
    "eta"
  ],
  "AUGS_CONST": [],
  "SpectrogramContEncoder": {
    "__init__": [
      "self",
      "input_dims",
      "targets_context_length",
      "d_model",
      "dropout_rate",
      "num_layers",
      "num_heads",
      "d_kv",
      "d_ff",
      "feed_forward_proj",
      "is_decoder"
    ],
    "forward": [
      "self",
      "encoder_inputs",
      "encoder_inputs_mask"
    ]
  },
  "TARGET_FEATURE_LENGTH": [],
  "SpectrogramNotesEncoder": {
    "__init__": [
      "self",
      "max_length",
      "vocab_size",
      "d_model",
      "dropout_rate",
      "num_layers",
      "num_heads",
      "d_kv",
      "d_ff",
      "feed_forward_proj",
      "is_decoder"
    ],
    "forward": [
      "self",
      "encoder_input_tokens",
      "encoder_inputs_mask"
    ]
  },
  "INPUT_FEATURE_LENGTH": [],
  "SAMPLE_RATE": [],
  "HOP_SIZE": [],
  "FRAME_RATE": [],
  "DEFAULT_STEPS_PER_SECOND": [],
  "DEFAULT_MAX_SHIFT_SECONDS": [],
  "DEFAULT_NUM_VELOCITY_BINS": [],
  "SLAKH_CLASS_PROGRAMS": [],
  "NoteRepresentationConfig": {},
  "NoteEventData": {},
  "NoteEncodingState": {},
  "EventRange": {},
  "Event": {},
  "Tokenizer": {
    "__init__": [
      "self",
      "regular_ids"
    ],
    "encode": [
      "self",
      "token_ids"
    ]
  },
  "Codec": {
    "__init__": [
      "self",
      "max_shift_steps",
      "steps_per_second",
      "event_ranges"
    ],
    "num_classes": [
      "self"
    ],
    "is_shift_event_index": [
      "self",
      "index"
    ],
    "max_shift_steps": [
      "self"
    ],
    "encode_event": [
      "self",
      "event"
    ],
    "event_type_range": [
      "self",
      "event_type"
    ],
    "decode_event_index": [
      "self",
      "index"
    ]
  },
  "ProgramGranularity": {},
  "drop_programs": [
    "tokens",
    "codec"
  ],
  "programs_to_midi_classes": [
    "tokens",
    "codec"
  ],
  "PROGRAM_GRANULARITIES": [],
  "frame": [
    "signal",
    "frame_length",
    "frame_step",
    "pad_end",
    "pad_value",
    "axis"
  ],
  "program_to_slakh_program": [
    "program"
  ],
  "audio_to_frames": [
    "samples",
    "hop_size",
    "frame_rate"
  ],
  "note_sequence_to_onsets_and_offsets_and_programs": [
    "ns"
  ],
  "num_velocity_bins_from_codec": [
    "codec"
  ],
  "segment": [
    "a",
    "n"
  ],
  "velocity_to_bin": [
    "velocity",
    "num_velocity_bins"
  ],
  "note_event_data_to_events": [
    "state",
    "value",
    "codec"
  ],
  "note_encoding_state_to_events": [
    "state"
  ],
  "encode_and_index_events": [
    "state",
    "event_times",
    "event_values",
    "codec",
    "frame_times",
    "encode_event_fn",
    "encoding_state_to_events_fn"
  ],
  "extract_sequence_with_indices": [
    "features",
    "state_events_end_token",
    "feature_key"
  ],
  "map_midi_programs": [
    "feature",
    "codec",
    "granularity_type",
    "feature_key"
  ],
  "run_length_encode_shifts_fn": [
    "features",
    "codec",
    "feature_key",
    "state_change_event_types"
  ],
  "note_representation_processor_chain": [
    "features",
    "codec",
    "note_representation_config"
  ],
  "_preprocess_image": [
    "image"
  ],
  "_preprocess_mask": [
    "mask"
  ],
  "get_down_block": [
    "down_block_type",
    "num_layers",
    "in_channels",
    "out_channels",
    "temb_channels",
    "add_downsample",
    "resnet_eps",
    "resnet_act_fn",
    "num_attention_heads",
    "transformer_layers_per_block",
    "attention_type",
    "attention_head_dim",
    "resnet_groups",
    "cross_attention_dim",
    "downsample_padding",
    "dual_cross_attention",
    "use_linear_projection",
    "only_cross_attention",
    "upcast_attention",
    "resnet_time_scale_shift",
    "resnet_skip_time_act",
    "resnet_out_scale_factor",
    "cross_attention_norm",
    "dropout"
  ],
  "get_up_block": [
    "up_block_type",
    "num_layers",
    "in_channels",
    "out_channels",
    "prev_output_channel",
    "temb_channels",
    "add_upsample",
    "resnet_eps",
    "resnet_act_fn",
    "num_attention_heads",
    "transformer_layers_per_block",
    "resolution_idx",
    "attention_type",
    "attention_head_dim",
    "resnet_groups",
    "cross_attention_dim",
    "dual_cross_attention",
    "use_linear_projection",
    "only_cross_attention",
    "upcast_attention",
    "resnet_time_scale_shift",
    "resnet_skip_time_act",
    "resnet_out_scale_factor",
    "cross_attention_norm",
    "dropout"
  ],
  "FourierEmbedder": {
    "__init__": [
      "self",
      "num_freqs",
      "temperature"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "GLIGENTextBoundingboxProjection": {
    "__init__": [
      "self",
      "positive_len",
      "out_dim",
      "feature_type",
      "fourier_freqs"
    ],
    "forward": [
      "self",
      "boxes",
      "masks",
      "positive_embeddings",
      "phrases_masks",
      "image_masks",
      "phrases_embeddings",
      "image_embeddings"
    ]
  },
  "UNetFlatConditionModel": {
    "_supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "sample_size",
      "in_channels",
      "out_channels",
      "center_input_sample",
      "flip_sin_to_cos",
      "freq_shift",
      "down_block_types",
      "mid_block_type",
      "up_block_types",
      "only_cross_attention",
      "block_out_channels",
      "layers_per_block",
      "downsample_padding",
      "mid_block_scale_factor",
      "dropout",
      "act_fn",
      "norm_num_groups",
      "norm_eps",
      "cross_attention_dim",
      "transformer_layers_per_block",
      "reverse_transformer_layers_per_block",
      "encoder_hid_dim",
      "encoder_hid_dim_type",
      "attention_head_dim",
      "num_attention_heads",
      "dual_cross_attention",
      "use_linear_projection",
      "class_embed_type",
      "addition_embed_type",
      "addition_time_embed_dim",
      "num_class_embeds",
      "upcast_attention",
      "resnet_time_scale_shift",
      "resnet_skip_time_act",
      "resnet_out_scale_factor",
      "time_embedding_type",
      "time_embedding_dim",
      "time_embedding_act_fn",
      "timestep_post_act",
      "time_cond_proj_dim",
      "conv_in_kernel",
      "conv_out_kernel",
      "projection_class_embeddings_input_dim",
      "attention_type",
      "class_embeddings_concat",
      "mid_block_only_cross_attention",
      "cross_attention_norm",
      "addition_embed_type_num_heads"
    ],
    "attn_processors": [
      "self"
    ],
    "set_attn_processor": [
      "self",
      "processor"
    ],
    "set_default_attn_processor": [
      "self"
    ],
    "set_attention_slice": [
      "self",
      "slice_size"
    ],
    "enable_freeu": [
      "self",
      "s1",
      "s2",
      "b1",
      "b2"
    ],
    "disable_freeu": [
      "self"
    ],
    "fuse_qkv_projections": [
      "self"
    ],
    "unfuse_qkv_projections": [
      "self"
    ],
    "unload_lora": [
      "self"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "encoder_hidden_states",
      "class_labels",
      "timestep_cond",
      "attention_mask",
      "cross_attention_kwargs",
      "added_cond_kwargs",
      "down_block_additional_residuals",
      "mid_block_additional_residual",
      "down_intrablock_additional_residuals",
      "encoder_attention_mask",
      "return_dict"
    ]
  },
  "LinearMultiDim": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "second_dim"
    ],
    "forward": [
      "self",
      "input_tensor"
    ]
  },
  "ResnetBlockFlat": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_tensor",
      "temb"
    ]
  },
  "DownBlockFlat": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_downsample",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "CrossAttnDownBlockFlat": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "transformer_layers_per_block",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "num_attention_heads",
      "cross_attention_dim",
      "output_scale_factor",
      "downsample_padding",
      "add_downsample",
      "dual_cross_attention",
      "use_linear_projection",
      "only_cross_attention",
      "upcast_attention",
      "attention_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask",
      "additional_residuals"
    ]
  },
  "UpBlockFlat": {
    "__init__": [
      "self",
      "in_channels",
      "prev_output_channel",
      "out_channels",
      "temb_channels",
      "resolution_idx",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_upsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "upsample_size"
    ]
  },
  "CrossAttnUpBlockFlat": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "prev_output_channel",
      "temb_channels",
      "resolution_idx",
      "dropout",
      "num_layers",
      "transformer_layers_per_block",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "num_attention_heads",
      "cross_attention_dim",
      "output_scale_factor",
      "add_upsample",
      "dual_cross_attention",
      "use_linear_projection",
      "only_cross_attention",
      "upcast_attention",
      "attention_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "encoder_hidden_states",
      "cross_attention_kwargs",
      "upsample_size",
      "attention_mask",
      "encoder_attention_mask"
    ]
  },
  "UNetMidBlockFlat": {
    "__init__": [
      "self",
      "in_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "attn_groups",
      "resnet_pre_norm",
      "add_attention",
      "attention_head_dim",
      "output_scale_factor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "UNetMidBlockFlatCrossAttn": {
    "__init__": [
      "self",
      "in_channels",
      "temb_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "transformer_layers_per_block",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_groups_out",
      "resnet_pre_norm",
      "num_attention_heads",
      "output_scale_factor",
      "cross_attention_dim",
      "dual_cross_attention",
      "use_linear_projection",
      "upcast_attention",
      "attention_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask"
    ]
  },
  "UNetMidBlockFlatSimpleCrossAttn": {
    "__init__": [
      "self",
      "in_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "cross_attention_dim",
      "skip_time_act",
      "only_cross_attention",
      "cross_attention_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask"
    ]
  },
  "LearnedClassifierFreeSamplingEmbeddings": {
    "__init__": [
      "self",
      "learnable",
      "hidden_size",
      "length"
    ]
  },
  "LDM3DPipelineOutput": {},
  "OvisImagePipelineOutput": {},
  "StableDiffusion3PipelineOutput": {},
  "STANDARD_RATIO": [],
  "STANDARD_SHAPE": [],
  "STANDARD_AREA": [],
  "SUPPORTED_SHAPE": [],
  "map_to_standard_shapes": [
    "target_width",
    "target_height"
  ],
  "get_resize_crop_region_for_grid": [
    "src",
    "tgt_size"
  ],
  "PAGMixin": {
    "_set_pag_attn_processor": [
      "self",
      "pag_applied_layers",
      "do_classifier_free_guidance"
    ],
    "_get_pag_scale": [
      "self",
      "t"
    ],
    "_apply_perturbed_attention_guidance": [
      "self",
      "noise_pred",
      "do_classifier_free_guidance",
      "guidance_scale",
      "t",
      "return_pred_text"
    ],
    "_prepare_perturbed_attention_guidance": [
      "self",
      "cond",
      "uncond",
      "do_classifier_free_guidance"
    ],
    "set_pag_applied_layers": [
      "self",
      "pag_applied_layers",
      "pag_attn_processors"
    ],
    "pag_scale": [
      "self"
    ],
    "pag_adaptive_scale": [
      "self"
    ],
    "do_pag_adaptive_scaling": [
      "self"
    ],
    "do_perturbed_attention_guidance": [
      "self"
    ],
    "pag_attn_processors": [
      "self"
    ]
  },
  "HunyuanVideo15PipelineOutput": {},
  "generate_crop_size_list": [
    "base_size",
    "patch_size",
    "max_ratio"
  ],
  "get_closest_ratio": [
    "height",
    "width",
    "ratios",
    "buckets"
  ],
  "HunyuanVideo15ImageProcessor": {
    "__init__": [
      "self",
      "do_resize",
      "vae_scale_factor",
      "vae_latent_channels",
      "do_convert_rgb"
    ],
    "calculate_default_height_width": [
      "self",
      "height",
      "width",
      "target_size"
    ]
  },
  "format_text_input": [
    "prompt",
    "system_message"
  ],
  "extract_glyph_texts": [
    "prompt"
  ],
  "HiDreamImagePipelineOutput": {},
  "StableAudioPositionalEmbedding": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "times"
    ]
  },
  "StableAudioProjectionModelOutput": {},
  "StableAudioNumberConditioner": {
    "__init__": [
      "self",
      "number_embedding_dim",
      "min_value",
      "max_value",
      "internal_dim"
    ],
    "forward": [
      "self",
      "floats"
    ]
  },
  "DEBUG": [],
  "_p_generate": [
    "pipe",
    "prompt_ids",
    "image",
    "params",
    "prng_seed",
    "num_inference_steps",
    "guidance_scale",
    "latents",
    "neg_prompt_ids",
    "controlnet_conditioning_scale"
  ],
  "_p_get_has_nsfw_concepts": [
    "pipe",
    "features",
    "params"
  ],
  "unshard": [
    "x"
  ],
  "prepare_image": [
    "image"
  ],
  "MochiPipelineOutput": {},
  "linear_quadratic_schedule": [
    "num_steps",
    "threshold_noise",
    "linear_steps"
  ],
  "MarigoldImageProcessor": {
    "config_name": [],
    "__init__": [
      "self",
      "vae_scale_factor",
      "do_normalize",
      "do_range_check"
    ],
    "expand_tensor_or_array": [
      "images"
    ],
    "pt_to_numpy": [
      "images"
    ],
    "numpy_to_pt": [
      "images"
    ],
    "resize_antialias": [
      "image",
      "size",
      "mode",
      "is_aa"
    ],
    "resize_to_max_edge": [
      "image",
      "max_edge_sz",
      "mode"
    ],
    "pad_image": [
      "image",
      "align"
    ],
    "unpad_image": [
      "image",
      "padding"
    ],
    "load_image_canonical": [
      "image",
      "device",
      "dtype"
    ],
    "check_image_values_range": [
      "image"
    ],
    "preprocess": [
      "self",
      "image",
      "processing_resolution",
      "resample_method_input",
      "device",
      "dtype"
    ],
    "colormap": [
      "image",
      "cmap",
      "bytes",
      "_force_method"
    ],
    "visualize_depth": [
      "depth",
      "val_min",
      "val_max",
      "color_map"
    ],
    "export_depth_to_16bit_png": [
      "depth",
      "val_min",
      "val_max"
    ],
    "visualize_normals": [
      "normals",
      "flip_x",
      "flip_y",
      "flip_z"
    ],
    "visualize_intrinsics": [
      "prediction",
      "target_properties",
      "color_map"
    ],
    "visualize_uncertainty": [
      "uncertainty",
      "saturation_percentile"
    ]
  },
  "MarigoldIntrinsicsOutput": {},
  "MarigoldDepthOutput": {},
  "MarigoldNormalsOutput": {},
  "ShapEPipelineOutput": {},
  "DifferentiableProjectiveCamera": {
    "__post_init__": [
      "self"
    ],
    "resolution": [
      "self"
    ],
    "fov": [
      "self"
    ],
    "get_image_coords": [
      "self"
    ],
    "camera_rays": [
      "self"
    ],
    "get_camera_rays": [
      "self",
      "coords"
    ],
    "resize_image": [
      "self",
      "width",
      "height"
    ]
  },
  "create_pan_cameras": [
    "size"
  ],
  "sample_pmf": [
    "pmf",
    "n_samples"
  ],
  "posenc_nerf": [
    "x",
    "min_deg",
    "max_deg"
  ],
  "encode_position": [
    "position"
  ],
  "encode_direction": [
    "position",
    "direction"
  ],
  "_sanitize_name": [
    "x"
  ],
  "integrate_samples": [
    "volume_range",
    "ts",
    "density",
    "channels"
  ],
  "volume_query_points": [
    "volume",
    "grid_size"
  ],
  "_convert_srgb_to_linear": [
    "u"
  ],
  "_create_flat_edge_indices": [
    "flat_cube_indices",
    "grid_size"
  ],
  "VoidNeRFModel": {
    "__init__": [
      "self",
      "background",
      "channel_scale"
    ],
    "forward": [
      "self",
      "position"
    ]
  },
  "VolumeRange": {
    "__post_init__": [
      "self"
    ],
    "partition": [
      "self",
      "ts"
    ]
  },
  "BoundingBoxVolume": {
    "__init__": [
      "self"
    ],
    "intersect": [
      "self",
      "origin",
      "direction",
      "t0_lower",
      "epsilon"
    ]
  },
  "StratifiedRaySampler": {
    "__init__": [
      "self",
      "depth_mode"
    ],
    "sample": [
      "self",
      "t0",
      "t1",
      "n_samples",
      "epsilon"
    ]
  },
  "ImportanceRaySampler": {
    "__init__": [
      "self",
      "volume_range",
      "ts",
      "weights",
      "blur_pool",
      "alpha"
    ],
    "sample": [
      "self",
      "t0",
      "t1",
      "n_samples"
    ]
  },
  "MeshDecoderOutput": {},
  "MeshDecoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "field",
      "min_point",
      "size"
    ]
  },
  "MLPNeRFModelOutput": {},
  "MLPNeRSTFModel": {
    "__init__": [
      "self",
      "d_hidden",
      "n_output",
      "n_hidden_layers",
      "act_fn",
      "insert_direction_at"
    ],
    "map_indices_to_keys": [
      "self",
      "output"
    ],
    "forward": [
      "self"
    ]
  },
  "ChannelsProj": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ShapEParamsProjModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ShapERenderer": {
    "__init__": [
      "self"
    ],
    "render_rays": [
      "self",
      "rays",
      "sampler",
      "n_samples",
      "prev_model_out",
      "render_with_direction"
    ],
    "decode_to_image": [
      "self",
      "latents",
      "device",
      "size",
      "ray_batch_size",
      "n_coarse_samples",
      "n_fine_samples"
    ],
    "decode_to_mesh": [
      "self",
      "latents",
      "device",
      "grid_size",
      "query_batch_size",
      "texture_channels"
    ]
  },
  "UPSAMPLING_MAX_IMAGE_SIZE": [],
  "format_input": [
    "prompts",
    "system_message",
    "images"
  ],
  "_validate_and_process_images": [
    "images",
    "image_processor",
    "upsampling_max_image_size"
  ],
  "compute_empirical_mu": [
    "image_seq_len",
    "num_steps"
  ],
  "Flux2PipelineOutput": {},
  "Flux2ImageProcessor": {
    "__init__": [
      "self",
      "do_resize",
      "vae_scale_factor",
      "vae_latent_channels",
      "do_normalize",
      "do_convert_rgb"
    ],
    "check_image_input": [
      "image",
      "max_aspect_ratio",
      "min_side_length",
      "max_area"
    ],
    "_resize_to_target_area": [
      "image",
      "target_area"
    ],
    "_resize_if_exceeds_area": [
      "image",
      "target_area"
    ],
    "_resize_and_crop": [
      "self",
      "image",
      "width",
      "height"
    ],
    "concatenate_images": [
      "images"
    ]
  },
  "SYSTEM_MESSAGE": [],
  "SYSTEM_MESSAGE_UPSAMPLING_T2I": [],
  "SYSTEM_MESSAGE_UPSAMPLING_I2I": [],
  "AttentionStore": {
    "get_empty_store": [],
    "__call__": [
      "self",
      "attn",
      "is_cross",
      "place_in_unet"
    ],
    "between_steps": [
      "self"
    ],
    "get_average_attention": [
      "self"
    ],
    "aggregate_attention": [
      "self",
      "from_where"
    ],
    "reset": [
      "self"
    ],
    "__init__": [
      "self",
      "attn_res"
    ]
  },
  "AttendExciteAttnProcessor": {
    "__init__": [
      "self",
      "attnstore",
      "place_in_unet"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "GaussianSmoothing": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "sigma",
      "dim"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ModelWrapper": {
    "__init__": [
      "self",
      "model",
      "alphas_cumprod"
    ],
    "apply_model": [
      "self"
    ]
  },
  "RANGE_LIST": [],
  "prepare_mask_coef_by_statistics": [
    "num_frames",
    "cond_frame",
    "motion_scale"
  ],
  "PIAPipelineOutput": {},
  "DEFAULT_STAGE_C_TIMESTEPS": [],
  "WuerstchenPriorPipelineOutput": {},
  "WuerstchenLayerNorm": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TimestepBlock": {
    "__init__": [
      "self",
      "c",
      "c_timestep"
    ],
    "forward": [
      "self",
      "x",
      "t"
    ]
  },
  "ResBlock": {
    "__init__": [
      "self",
      "c",
      "c_skip",
      "kernel_size",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "x_skip"
    ]
  },
  "GlobalResponseNorm": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AttnBlock": {
    "__init__": [
      "self",
      "c",
      "c_cond",
      "nhead",
      "self_attn",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "kv"
    ]
  },
  "WuerstchenDiffNeXt": {
    "__init__": [
      "self",
      "c_in",
      "c_out",
      "c_r",
      "patch_size",
      "c_cond",
      "c_hidden",
      "nhead",
      "blocks",
      "level_config",
      "inject_effnet",
      "effnet_embd",
      "clip_embd",
      "kernel_size",
      "dropout"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "gen_r_embedding": [
      "self",
      "r",
      "max_positions"
    ],
    "gen_c_embeddings": [
      "self",
      "clip"
    ],
    "_down_encode": [
      "self",
      "x",
      "r_embed",
      "effnet",
      "clip"
    ],
    "_up_decode": [
      "self",
      "level_outputs",
      "r_embed",
      "effnet",
      "clip"
    ],
    "forward": [
      "self",
      "x",
      "r",
      "effnet",
      "clip",
      "x_cat",
      "eps",
      "return_noise"
    ]
  },
  "ResBlockStageB": {
    "__init__": [
      "self",
      "c",
      "c_skip",
      "kernel_size",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "x_skip"
    ]
  },
  "WuerstchenPrior": {
    "unet_name": [],
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "c_in",
      "c",
      "c_cond",
      "c_r",
      "depth",
      "nhead",
      "dropout"
    ],
    "set_default_attn_processor": [
      "self"
    ],
    "gen_r_embedding": [
      "self",
      "r",
      "max_positions"
    ],
    "forward": [
      "self",
      "x",
      "r",
      "c"
    ]
  },
  "MixingResidualBlock": {
    "__init__": [
      "self",
      "inp_channels",
      "embed_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PaellaVQModel": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "up_down_scale_factor",
      "levels",
      "bottleneck_blocks",
      "embed_dim",
      "latent_channels",
      "num_vq_embeddings",
      "scale_factor"
    ],
    "encode": [
      "self",
      "x",
      "return_dict"
    ],
    "decode": [
      "self",
      "h",
      "force_not_quantize",
      "return_dict"
    ],
    "forward": [
      "self",
      "sample",
      "return_dict"
    ]
  },
  "_preprocess_adapter_image": [
    "image",
    "height",
    "width"
  ],
  "StableDiffusionAdapterPipelineOutput": {},
  "resize": [
    "images",
    "img_size"
  ],
  "IFSafetyChecker": {
    "config_class": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "clip_input",
      "images",
      "p_threshold",
      "w_threshold"
    ]
  },
  "IFPipelineOutput": {},
  "IFWatermarker": {
    "__init__": [
      "self"
    ],
    "apply_watermark": [
      "self",
      "images",
      "sample_size"
    ]
  },
  "fast27_timesteps": [],
  "smart27_timesteps": [],
  "smart50_timesteps": [],
  "smart100_timesteps": [],
  "smart185_timesteps": [],
  "super27_timesteps": [],
  "super40_timesteps": [],
  "super100_timesteps": [],
  "CrossAttnStoreProcessor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "gaussian_blur_2d": [
    "img",
    "kernel_size",
    "sigma"
  ],
  "AllegroPipelineOutput": {},
  "WanPipelineOutput": {},
  "WanAnimateImageProcessor": {
    "__init__": [
      "self",
      "do_resize",
      "vae_scale_factor",
      "vae_latent_channels",
      "spatial_patch_size",
      "resample",
      "reducing_gap",
      "do_normalize",
      "do_binarize",
      "do_convert_rgb",
      "do_convert_grayscale",
      "fill_color"
    ],
    "_resize_and_fill": [
      "self",
      "image",
      "width",
      "height"
    ],
    "get_default_height_width": [
      "self",
      "image",
      "height",
      "width"
    ]
  },
  "SemanticStableDiffusionPipelineOutput": {},
  "get_image_to_video_latent": [
    "validation_image_start",
    "validation_image_end",
    "num_frames",
    "sample_size"
  ],
  "resize_mask": [
    "mask",
    "latent",
    "process_first_frame_only"
  ],
  "add_noise_to_reference_video": [
    "image",
    "ratio",
    "generator"
  ],
  "get_video_to_video_latent": [
    "input_video",
    "num_frames",
    "sample_size",
    "validation_video_mask",
    "ref_image"
  ],
  "EasyAnimatePipelineOutput": {},
  "CogView3PipelineOutput": {},
  "LeditsAttentionStore": {
    "get_empty_store": [],
    "__call__": [
      "self",
      "attn",
      "is_cross",
      "place_in_unet",
      "editing_prompts",
      "PnP"
    ],
    "forward": [
      "self",
      "attn",
      "is_cross",
      "place_in_unet"
    ],
    "between_steps": [
      "self",
      "store_step"
    ],
    "get_attention": [
      "self",
      "step"
    ],
    "aggregate_attention": [
      "self",
      "attention_maps",
      "prompts",
      "res",
      "from_where",
      "is_cross",
      "select"
    ],
    "__init__": [
      "self",
      "average",
      "batch_size",
      "max_resolution",
      "max_size"
    ]
  },
  "LeditsGaussianSmoothing": {
    "__init__": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "LEDITSCrossAttnProcessor": {
    "__init__": [
      "self",
      "attention_store",
      "place_in_unet",
      "pnp",
      "editing_prompts"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb"
    ]
  },
  "compute_noise_ddim": [
    "scheduler",
    "prev_latents",
    "latents",
    "timestep",
    "noise_pred",
    "eta"
  ],
  "compute_noise_sde_dpm_pp_2nd": [
    "scheduler",
    "prev_latents",
    "latents",
    "timestep",
    "noise_pred",
    "eta"
  ],
  "LEditsPPDiffusionPipelineOutput": {},
  "LEditsPPInversionPipelineOutput": {},
  "StableCascadePriorPipelineOutput": {},
  "ZImagePipelineOutput": {},
  "rearrange_0": [
    "tensor",
    "f"
  ],
  "rearrange_1": [
    "tensor"
  ],
  "rearrange_3": [
    "tensor",
    "f"
  ],
  "rearrange_4": [
    "tensor"
  ],
  "CrossFrameAttnProcessor": {
    "__init__": [
      "self",
      "batch_size"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "CrossFrameAttnProcessor2_0": {
    "__init__": [
      "self",
      "batch_size"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "TextToVideoSDXLPipelineOutput": {},
  "coords_grid": [
    "batch",
    "ht",
    "wd",
    "device"
  ],
  "warp_single_latent": [
    "latent",
    "reference_flow"
  ],
  "create_motion_field": [
    "motion_field_strength_x",
    "motion_field_strength_y",
    "frame_ids",
    "device",
    "dtype"
  ],
  "create_motion_field_and_warp_latents": [
    "motion_field_strength_x",
    "motion_field_strength_y",
    "frame_ids",
    "latents"
  ],
  "TextToVideoSDPipelineOutput": {},
  "TextToVideoPipelineOutput": {},
  "VisualClozeProcessor": {
    "__init__": [
      "self"
    ],
    "preprocess_image": [
      "self",
      "input_images",
      "vae_scale_factor"
    ],
    "preprocess_mask": [
      "self",
      "input_images",
      "target_position"
    ],
    "preprocess_image_upsampling": [
      "self",
      "input_images",
      "height",
      "width"
    ],
    "preprocess_mask_upsampling": [
      "self",
      "input_images"
    ],
    "get_layout_prompt": [
      "self",
      "size"
    ],
    "preprocess": [
      "self",
      "task_prompt",
      "content_prompt",
      "input_images",
      "height",
      "width",
      "upsampling",
      "vae_scale_factor"
    ]
  },
  "LTXVideoCondition": {},
  "LTXPipelineOutput": {},
  "PixelShuffleND": {
    "__init__": [
      "self",
      "dims",
      "upscale_factors"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LTXLatentUpsamplerModel": {
    "__init__": [
      "self",
      "in_channels",
      "mid_channels",
      "num_blocks_per_stage",
      "dims",
      "spatial_upsample",
      "temporal_upsample"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "draw_kps": [
    "image_pil",
    "kps",
    "color_list"
  ],
  "ConsisIDPipelineOutput": {},
  "_insightface_available": [],
  "_consisid_eva_clip_available": [],
  "_facexlib_available": [],
  "resize_numpy_image_long": [
    "image",
    "resize_long_edge"
  ],
  "img2tensor": [
    "imgs",
    "bgr2rgb",
    "float32"
  ],
  "to_gray": [
    "img"
  ],
  "process_face_embeddings": [
    "face_helper_1",
    "clip_vision_model",
    "face_helper_2",
    "eva_transform_mean",
    "eva_transform_std",
    "app",
    "device",
    "weight_dtype",
    "image",
    "original_id_image",
    "is_align_face"
  ],
  "process_face_embeddings_infer": [
    "face_helper_1",
    "clip_vision_model",
    "face_helper_2",
    "eva_transform_mean",
    "eva_transform_std",
    "app",
    "device",
    "weight_dtype",
    "img_file_path",
    "is_align_face"
  ],
  "prepare_face_models": [
    "model_path",
    "device",
    "dtype"
  ],
  "ASPECT_RATIO_2048_BIN": [],
  "ContextCLIPTextModel": {
    "config_class": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "ctx_embeddings",
      "ctx_begin_pos",
      "input_ids",
      "attention_mask",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ContextCLIPTextTransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "ctx_embeddings",
      "ctx_begin_pos",
      "input_ids",
      "attention_mask",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_build_causal_attention_mask": [
      "self",
      "bsz",
      "seq_len",
      "dtype"
    ]
  },
  "ContextCLIPTextEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "ctx_embeddings",
      "ctx_begin_pos",
      "input_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "BlipImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "do_center_crop"
    ],
    "resize": [
      "self",
      "image",
      "size",
      "resample",
      "data_format",
      "input_data_format"
    ],
    "preprocess": [
      "self",
      "images",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "do_center_crop",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "return_tensors",
      "do_convert_rgb",
      "data_format",
      "input_data_format"
    ],
    "postprocess": [
      "self",
      "sample",
      "output_type"
    ]
  },
  "Blip2TextEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "query_embeds",
      "past_key_values_length"
    ]
  },
  "Blip2VisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "Blip2QFormerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "query_length"
    ]
  },
  "Blip2QFormerLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "query_length"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ],
    "feed_forward_chunk_query": [
      "self",
      "attention_output"
    ]
  },
  "ProjLayer": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "hidden_dim",
      "drop_p",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Blip2VisionModel": {
    "main_input_name": [],
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "Blip2QFormerModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "get_extended_attention_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "device",
      "has_query"
    ],
    "forward": [
      "self",
      "text_input",
      "image_input",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "SkyReelsV2PipelineOutput": {},
  "mask_pil_to_torch": [
    "mask",
    "height",
    "width"
  ],
  "StableDiffusionXLPipelineOutput": {},
  "WATERMARK_MESSAGE": [],
  "WATERMARK_BITS": [],
  "StableDiffusionXLWatermarker": {
    "__init__": [
      "self"
    ],
    "apply_watermark": [
      "self",
      "images"
    ]
  },
  "CogVideoXPipelineOutput": {},
  "crop_image": [
    "pil_image",
    "max_image_size"
  ],
  "OmniGenMultiModalProcessor": {
    "__init__": [
      "self",
      "text_tokenizer",
      "max_image_size"
    ],
    "reset_max_image_size": [
      "self",
      "max_image_size"
    ],
    "process_image": [
      "self",
      "image"
    ],
    "process_multi_modal_prompt": [
      "self",
      "text",
      "input_images"
    ],
    "add_prefix_instruction": [
      "self",
      "prompt"
    ],
    "__call__": [
      "self",
      "instructions",
      "input_images",
      "height",
      "width",
      "negative_prompt",
      "use_img_cfg",
      "separate_cfg_input",
      "use_input_image_size_as_output",
      "num_images_per_prompt"
    ]
  },
  "OmniGenCollator": {
    "__init__": [
      "self",
      "pad_token_id",
      "hidden_size"
    ],
    "create_position": [
      "self",
      "attention_mask",
      "num_tokens_for_output_images"
    ],
    "create_mask": [
      "self",
      "attention_mask",
      "num_tokens_for_output_images"
    ],
    "adjust_attention_for_input_images": [
      "self",
      "attention_mask",
      "image_sizes"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "image_sizes"
    ],
    "process_mllm_input": [
      "self",
      "mllm_inputs",
      "target_img_size"
    ],
    "__call__": [
      "self",
      "features"
    ]
  },
  "PREFERRED_KONTEXT_RESOLUTIONS": [],
  "FluxPipelineOutput": {},
  "FluxPriorReduxPipelineOutput": {},
  "ReduxImageEncoderOutput": {},
  "AnimateDiffPipelineOutput": {},
  "UnCLIPTextProjModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "ChronoEditPipelineOutput": {},
  "_append_dims": [
    "x",
    "target_dims"
  ],
  "StableVideoDiffusionPipelineOutput": {},
  "_resize_with_antialiasing": [
    "input",
    "size",
    "interpolation",
    "align_corners"
  ],
  "_compute_padding": [
    "kernel_size"
  ],
  "_filter2d": [
    "input",
    "kernel"
  ],
  "_gaussian": [
    "window_size",
    "sigma"
  ],
  "_gaussian_blur2d": [
    "input",
    "kernel_size",
    "sigma"
  ],
  "SPTokenizer": {
    "__init__": [
      "self",
      "model_path"
    ],
    "tokenize": [
      "self",
      "s",
      "encode_special_tokens"
    ],
    "encode": [
      "self",
      "s",
      "bos",
      "eos"
    ],
    "decode": [
      "self",
      "t"
    ],
    "decode_tokens": [
      "self",
      "tokens"
    ],
    "convert_token_to_id": [
      "self",
      "token"
    ],
    "convert_id_to_token": [
      "self",
      "index"
    ]
  },
  "ChatGLMTokenizer": {
    "vocab_files_names": [],
    "model_input_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "padding_side",
      "clean_up_tokenization_spaces",
      "encode_special_tokens"
    ],
    "get_command": [
      "self",
      "token"
    ],
    "unk_token": [
      "self",
      "value"
    ],
    "pad_token": [
      "self",
      "value"
    ],
    "pad_token_id": [
      "self"
    ],
    "eos_token": [
      "self",
      "value"
    ],
    "eos_token_id": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "get_prefix_tokens": [
      "self"
    ],
    "build_single_message": [
      "self",
      "role",
      "metadata",
      "message"
    ],
    "build_chat_input": [
      "self",
      "query",
      "history",
      "role"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask",
      "padding_side"
    ]
  },
  "ChatGLMConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "num_layers",
      "padded_vocab_size",
      "hidden_size",
      "ffn_hidden_size",
      "kv_channels",
      "num_attention_heads",
      "seq_length",
      "hidden_dropout",
      "classifier_dropout",
      "attention_dropout",
      "layernorm_epsilon",
      "rmsnorm",
      "apply_residual_connection_post_layernorm",
      "post_layer_norm",
      "add_bias_linear",
      "add_qkv_bias",
      "bias_dropout_fusion",
      "multi_query_attention",
      "multi_query_group_num",
      "apply_query_key_layer_scaling",
      "attention_softmax_in_fp32",
      "fp32_residual_connection",
      "quantization_bit",
      "pre_seq_len",
      "prefix_projection"
    ]
  },
  "RMSNorm": {
    "__init__": [
      "self",
      "normalized_shape",
      "eps",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CoreAttention": {
    "__init__": [
      "self",
      "config",
      "layer_number"
    ],
    "forward": [
      "self",
      "query_layer",
      "key_layer",
      "value_layer",
      "attention_mask"
    ]
  },
  "split_tensor_along_last_dim": [
    "tensor",
    "num_partitions",
    "contiguous_split_chunks"
  ],
  "apply_rotary_pos_emb": [
    "x",
    "rope_cache"
  ],
  "SelfAttention": {
    "__init__": [
      "self",
      "config",
      "layer_number",
      "device"
    ],
    "_allocate_memory": [
      "self",
      "inference_max_sequence_len",
      "batch_size",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "rotary_pos_emb",
      "kv_cache",
      "use_cache"
    ]
  },
  "MLP": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GLMBlock": {
    "__init__": [
      "self",
      "config",
      "layer_number",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "rotary_pos_emb",
      "kv_cache",
      "use_cache"
    ]
  },
  "GLMTransformer": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "_get_layer": [
      "self",
      "layer_number"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "rotary_pos_emb",
      "kv_caches",
      "use_cache",
      "output_hidden_states"
    ]
  },
  "ChatGLMPreTrainedModel": {
    "is_parallelizable": [],
    "supports_gradient_checkpointing": [],
    "config_class": [],
    "base_model_prefix": [],
    "_no_split_modules": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "get_masks": [
      "self",
      "input_ids",
      "past_key_values",
      "padding_mask"
    ],
    "get_position_ids": [
      "self",
      "input_ids",
      "device"
    ]
  },
  "default_init": [
    "cls"
  ],
  "Embedding": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "RotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "original_impl",
      "device",
      "dtype"
    ],
    "forward_impl": [
      "self",
      "seq_len",
      "n_elem",
      "dtype",
      "device",
      "base"
    ],
    "forward": [
      "self",
      "max_seq_len",
      "offset"
    ]
  },
  "PrefixEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "prefix"
    ]
  },
  "ChatGLMModel": {
    "__init__": [
      "self",
      "config",
      "device",
      "empty_init"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_prompt": [
      "self",
      "batch_size",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "full_attention_mask",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "KolorsPipelineOutput": {},
  "HunyuanImagePipelineOutput": {},
  "extract_glyph_text": [
    "prompt"
  ],
  "cosine_distance": [
    "image_embeds",
    "text_embeds"
  ],
  "SafeStableDiffusionSafetyChecker": {
    "config_class": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "clip_input",
      "images"
    ],
    "forward_onnx": [
      "self",
      "clip_input",
      "images"
    ]
  },
  "SafetyConfig": {
    "WEAK": [],
    "MEDIUM": [],
    "STRONG": [],
    "MAX": []
  },
  "StableDiffusionSafePipelineOutput": {},
  "StableDiffusionSafetyChecker": {
    "config_class": [],
    "main_input_name": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "clip_input",
      "images"
    ],
    "forward_onnx": [
      "self",
      "clip_input",
      "images"
    ]
  },
  "shave_segments": [
    "path",
    "n_shave_prefix_segments"
  ],
  "renew_resnet_paths": [
    "old_list",
    "n_shave_prefix_segments"
  ],
  "renew_vae_resnet_paths": [
    "old_list",
    "n_shave_prefix_segments"
  ],
  "renew_attention_paths": [
    "old_list",
    "n_shave_prefix_segments"
  ],
  "renew_vae_attention_paths": [
    "old_list",
    "n_shave_prefix_segments"
  ],
  "assign_to_checkpoint": [
    "paths",
    "checkpoint",
    "old_checkpoint",
    "attention_paths_to_split",
    "additional_replacements",
    "config"
  ],
  "create_unet_diffusers_config": [
    "original_config",
    "image_size",
    "controlnet"
  ],
  "create_vae_diffusers_config": [
    "original_config",
    "image_size"
  ],
  "create_diffusers_schedular": [
    "original_config"
  ],
  "create_ldm_bert_config": [
    "original_config"
  ],
  "convert_ldm_bert_checkpoint": [
    "checkpoint",
    "config"
  ],
  "textenc_conversion_lst": [],
  "textenc_conversion_map": [],
  "textenc_transformer_conversion_lst": [],
  "protected": [],
  "textenc_pattern": [],
  "convert_paint_by_example_checkpoint": [
    "checkpoint",
    "local_files_only"
  ],
  "stable_unclip_image_encoder": [
    "original_config",
    "local_files_only"
  ],
  "stable_unclip_image_noising_components": [
    "original_config",
    "clip_stats_path",
    "device"
  ],
  "download_from_original_stable_diffusion_ckpt": [
    "checkpoint_path_or_dict",
    "original_config_file",
    "image_size",
    "prediction_type",
    "model_type",
    "extract_ema",
    "scheduler_type",
    "num_in_channels",
    "upcast_attention",
    "device",
    "from_safetensors",
    "stable_unclip",
    "stable_unclip_prior",
    "clip_stats_path",
    "controlnet",
    "adapter",
    "load_safety_checker",
    "safety_checker",
    "feature_extractor",
    "pipeline_class",
    "local_files_only",
    "vae_path",
    "vae",
    "text_encoder",
    "text_encoder_2",
    "tokenizer",
    "tokenizer_2",
    "config_files"
  ],
  "download_controlnet_from_original_ckpt": [
    "checkpoint_path",
    "original_config_file",
    "image_size",
    "extract_ema",
    "num_in_channels",
    "upcast_attention",
    "device",
    "from_safetensors",
    "use_linear_projection",
    "cross_attention_dim"
  ],
  "StableUnCLIPImageNormalizer": {
    "__init__": [
      "self",
      "embedding_dim"
    ],
    "to": [
      "self",
      "torch_device",
      "torch_dtype"
    ],
    "scale": [
      "self",
      "embeds"
    ],
    "unscale": [
      "self",
      "embeds"
    ]
  },
  "StableDiffusionPipelineOutput": {},
  "jax_cosine_distance": [
    "emb_1",
    "emb_2",
    "eps"
  ],
  "FlaxStableDiffusionSafetyCheckerModule": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "clip_input"
    ]
  },
  "FlaxStableDiffusionSafetyChecker": {
    "config_class": [],
    "main_input_name": [],
    "module_class": [],
    "__init__": [
      "self",
      "config",
      "input_shape",
      "seed",
      "dtype",
      "_do_init"
    ],
    "init_weights": [
      "self",
      "rng",
      "input_shape",
      "params"
    ],
    "__call__": [
      "self",
      "clip_input",
      "params"
    ]
  },
  "NUM_UNET_INPUT_CHANNELS": [],
  "NUM_LATENT_CHANNELS": [],
  "ASPECT_RATIO_4096_BIN": [],
  "SanaPipelineOutput": {},
  "get_new_h_w": [
    "h",
    "w",
    "scale_factor"
  ],
  "KandinskyPriorPipelineOutput": {},
  "MCLIPConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "transformerDimSize",
      "imageDimSize"
    ]
  },
  "MultilingualCLIP": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "BriaFiboPipelineOutput": {},
  "MAPPING": [],
  "DYNAMIC_MAP": [],
  "add_special_tokens": [
    "hidden_states",
    "attention_mask",
    "sos_token",
    "eos_token"
  ],
  "AudioLDM2ProjectionModelOutput": {},
  "CrossAttnDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "transformer_layers_per_block",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "num_attention_heads",
      "cross_attention_dim",
      "output_scale_factor",
      "downsample_padding",
      "add_downsample",
      "use_linear_projection",
      "only_cross_attention",
      "upcast_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask",
      "encoder_hidden_states_1",
      "encoder_attention_mask_1"
    ]
  },
  "UNetMidBlock2DCrossAttn": {
    "__init__": [
      "self",
      "in_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "transformer_layers_per_block",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "num_attention_heads",
      "output_scale_factor",
      "cross_attention_dim",
      "use_linear_projection",
      "upcast_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask",
      "encoder_hidden_states_1",
      "encoder_attention_mask_1"
    ]
  },
  "CrossAttnUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "prev_output_channel",
      "temb_channels",
      "dropout",
      "num_layers",
      "transformer_layers_per_block",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "num_attention_heads",
      "cross_attention_dim",
      "output_scale_factor",
      "add_upsample",
      "use_linear_projection",
      "only_cross_attention",
      "upcast_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "encoder_hidden_states",
      "cross_attention_kwargs",
      "upsample_size",
      "attention_mask",
      "encoder_attention_mask",
      "encoder_hidden_states_1",
      "encoder_attention_mask_1"
    ]
  },
  "prepare_inputs_for_generation": [
    "inputs_embeds",
    "attention_mask",
    "past_key_values"
  ],
  "ContextParallelInput": {
    "__repr__": [
      "self"
    ]
  },
  "ContextParallelOutput": {
    "__repr__": [
      "self"
    ]
  },
  "ContextParallelInputType": [],
  "ContextParallelOutputType": [],
  "ContextParallelModelPlan": [],
  "Downsample1D": {
    "__init__": [
      "self",
      "channels",
      "use_conv",
      "out_channels",
      "padding",
      "name"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "Downsample2D": {
    "__init__": [
      "self",
      "channels",
      "use_conv",
      "out_channels",
      "padding",
      "name",
      "kernel_size",
      "norm_type",
      "eps",
      "elementwise_affine",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "FirDownsample2D": {
    "__init__": [
      "self",
      "channels",
      "out_channels",
      "use_conv",
      "fir_kernel"
    ],
    "_downsample_2d": [
      "self",
      "hidden_states",
      "weight",
      "kernel",
      "factor",
      "gain"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "KDownsample2D": {
    "__init__": [
      "self",
      "pad_mode"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "CogVideoXDownsample3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "compress_time"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "downsample_2d": [
    "hidden_states",
    "kernel",
    "factor",
    "gain"
  ],
  "_query_chunk_attention": [
    "query",
    "key",
    "value",
    "precision",
    "key_chunk_size"
  ],
  "jax_memory_efficient_attention": [
    "query",
    "key",
    "value",
    "precision",
    "query_chunk_size",
    "key_chunk_size"
  ],
  "FlaxAttention": {
    "setup": [
      "self"
    ],
    "reshape_heads_to_batch_dim": [
      "self",
      "tensor"
    ],
    "reshape_batch_dim_to_heads": [
      "self",
      "tensor"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "context",
      "deterministic"
    ]
  },
  "FlaxBasicTransformerBlock": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "context",
      "deterministic"
    ]
  },
  "FlaxTransformer2DModel": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "context",
      "deterministic"
    ]
  },
  "FlaxFeedForward": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "deterministic"
    ]
  },
  "FlaxGEGLU": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "deterministic"
    ]
  },
  "rename_key": [
    "key"
  ],
  "rename_key_and_reshape_tensor": [
    "pt_tuple_key",
    "pt_tensor",
    "random_flax_state_dict"
  ],
  "convert_pytorch_state_dict_to_flax": [
    "pt_state_dict",
    "flax_model",
    "init_key"
  ],
  "text_encoder_attn_modules": [
    "text_encoder"
  ],
  "text_encoder_mlp_modules": [
    "text_encoder"
  ],
  "adjust_lora_scale_text_encoder": [
    "text_encoder",
    "lora_scale"
  ],
  "PatchedLoraProjection": {
    "__init__": [
      "self",
      "regular_linear_layer",
      "lora_scale",
      "network_alpha",
      "rank",
      "dtype"
    ],
    "state_dict": [
      "self"
    ],
    "_fuse_lora": [
      "self",
      "lora_scale",
      "safe_fusing"
    ],
    "_unfuse_lora": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "LoRALinearLayer": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "rank",
      "network_alpha",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LoRAConv2dLayer": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "rank",
      "kernel_size",
      "stride",
      "padding",
      "network_alpha"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LoRACompatibleConv": {
    "__init__": [
      "self"
    ],
    "set_lora_layer": [
      "self",
      "lora_layer"
    ],
    "_fuse_lora": [
      "self",
      "lora_scale",
      "safe_fusing"
    ],
    "_unfuse_lora": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "scale"
    ]
  },
  "LoRACompatibleLinear": {
    "__init__": [
      "self"
    ],
    "set_lora_layer": [
      "self",
      "lora_layer"
    ],
    "_fuse_lora": [
      "self",
      "lora_scale",
      "safe_fusing"
    ],
    "_unfuse_lora": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "scale"
    ]
  },
  "VQEncoderOutput": {
    "__init__": [
      "self"
    ]
  },
  "_CLASS_REMAPPING_DICT": [],
  "_determine_device_map": [
    "model",
    "device_map",
    "max_memory",
    "torch_dtype",
    "keep_in_fp32_modules",
    "hf_quantizer"
  ],
  "_fetch_remapped_cls_from_config": [
    "config",
    "old_class"
  ],
  "_determine_param_device": [
    "param_name",
    "device_map"
  ],
  "load_state_dict": [
    "checkpoint_file",
    "dduf_entries",
    "disable_mmap",
    "map_location"
  ],
  "load_model_dict_into_meta": [
    "model",
    "state_dict",
    "dtype",
    "model_name_or_path",
    "hf_quantizer",
    "keep_in_fp32_modules",
    "device_map",
    "unexpected_keys",
    "offload_folder",
    "offload_index",
    "state_dict_index",
    "state_dict_folder"
  ],
  "check_support_param_buffer_assignment": [
    "model_to_load",
    "state_dict",
    "start_prefix"
  ],
  "_load_shard_file": [
    "shard_file",
    "model",
    "model_state_dict",
    "device_map",
    "dtype",
    "hf_quantizer",
    "keep_in_fp32_modules",
    "dduf_entries",
    "loaded_keys",
    "unexpected_keys",
    "offload_index",
    "offload_folder",
    "state_dict_index",
    "state_dict_folder",
    "ignore_mismatched_sizes",
    "low_cpu_mem_usage"
  ],
  "_load_shard_files_with_threadpool": [
    "shard_files",
    "model",
    "model_state_dict",
    "device_map",
    "dtype",
    "hf_quantizer",
    "keep_in_fp32_modules",
    "dduf_entries",
    "loaded_keys",
    "unexpected_keys",
    "offload_index",
    "offload_folder",
    "state_dict_index",
    "state_dict_folder",
    "ignore_mismatched_sizes",
    "low_cpu_mem_usage"
  ],
  "_find_mismatched_keys": [
    "state_dict",
    "model_state_dict",
    "loaded_keys",
    "ignore_mismatched_sizes"
  ],
  "_load_state_dict_into_model": [
    "model_to_load",
    "state_dict",
    "assign_to_params_buffers"
  ],
  "_fetch_index_file": [
    "is_local",
    "pretrained_model_name_or_path",
    "subfolder",
    "use_safetensors",
    "cache_dir",
    "variant",
    "force_download",
    "proxies",
    "local_files_only",
    "token",
    "revision",
    "user_agent",
    "commit_hash",
    "dduf_entries"
  ],
  "_fetch_index_file_legacy": [
    "is_local",
    "pretrained_model_name_or_path",
    "subfolder",
    "use_safetensors",
    "cache_dir",
    "variant",
    "force_download",
    "proxies",
    "local_files_only",
    "token",
    "revision",
    "user_agent",
    "commit_hash",
    "dduf_entries"
  ],
  "_gguf_parse_value": [
    "_value",
    "data_type"
  ],
  "load_gguf_checkpoint": [
    "gguf_checkpoint_path",
    "return_tensors"
  ],
  "_expand_device_map": [
    "device_map",
    "param_names"
  ],
  "_caching_allocator_warmup": [
    "model",
    "expanded_device_map",
    "dtype",
    "hf_quantizer"
  ],
  "get_timestep_embedding": [
    "timesteps",
    "embedding_dim",
    "flip_sin_to_cos",
    "downscale_freq_shift",
    "scale",
    "max_period"
  ],
  "get_3d_sincos_pos_embed": [
    "embed_dim",
    "spatial_size",
    "temporal_size",
    "spatial_interpolation_scale",
    "temporal_interpolation_scale",
    "device",
    "output_type"
  ],
  "_get_3d_sincos_pos_embed_np": [
    "embed_dim",
    "spatial_size",
    "temporal_size",
    "spatial_interpolation_scale",
    "temporal_interpolation_scale"
  ],
  "get_2d_sincos_pos_embed": [
    "embed_dim",
    "grid_size",
    "cls_token",
    "extra_tokens",
    "interpolation_scale",
    "base_size",
    "device",
    "output_type"
  ],
  "get_2d_sincos_pos_embed_from_grid": [
    "embed_dim",
    "grid",
    "output_type"
  ],
  "get_1d_sincos_pos_embed_from_grid": [
    "embed_dim",
    "pos",
    "output_type",
    "flip_sin_to_cos",
    "dtype"
  ],
  "get_2d_sincos_pos_embed_np": [
    "embed_dim",
    "grid_size",
    "cls_token",
    "extra_tokens",
    "interpolation_scale",
    "base_size"
  ],
  "get_2d_sincos_pos_embed_from_grid_np": [
    "embed_dim",
    "grid"
  ],
  "get_1d_sincos_pos_embed_from_grid_np": [
    "embed_dim",
    "pos"
  ],
  "LuminaPatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "in_channels",
      "embed_dim",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "freqs_cis"
    ]
  },
  "CogVideoXPatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "patch_size_t",
      "in_channels",
      "embed_dim",
      "text_embed_dim",
      "bias",
      "sample_width",
      "sample_height",
      "sample_frames",
      "temporal_compression_ratio",
      "max_text_seq_length",
      "spatial_interpolation_scale",
      "temporal_interpolation_scale",
      "use_positional_embeddings",
      "use_learned_positional_embeddings"
    ],
    "_get_positional_embeddings": [
      "self",
      "sample_height",
      "sample_width",
      "sample_frames",
      "device"
    ],
    "forward": [
      "self",
      "text_embeds",
      "image_embeds"
    ]
  },
  "CogView3PlusPatchEmbed": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_size",
      "patch_size",
      "text_hidden_size",
      "pos_embed_max_size"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ]
  },
  "get_3d_rotary_pos_embed": [
    "embed_dim",
    "crops_coords",
    "grid_size",
    "temporal_size",
    "theta",
    "use_real",
    "grid_type",
    "max_size",
    "device"
  ],
  "get_3d_rotary_pos_embed_allegro": [
    "embed_dim",
    "crops_coords",
    "grid_size",
    "temporal_size",
    "interpolation_scale",
    "theta",
    "device"
  ],
  "get_2d_rotary_pos_embed": [
    "embed_dim",
    "crops_coords",
    "grid_size",
    "use_real",
    "device",
    "output_type"
  ],
  "_get_2d_rotary_pos_embed_np": [
    "embed_dim",
    "crops_coords",
    "grid_size",
    "use_real"
  ],
  "get_2d_rotary_pos_embed_from_grid": [
    "embed_dim",
    "grid",
    "use_real"
  ],
  "get_2d_rotary_pos_embed_lumina": [
    "embed_dim",
    "len_h",
    "len_w",
    "linear_factor",
    "ntk_factor"
  ],
  "get_1d_rotary_pos_embed": [
    "dim",
    "pos",
    "theta",
    "use_real",
    "linear_factor",
    "ntk_factor",
    "repeat_interleave_real",
    "freqs_dtype"
  ],
  "apply_rotary_emb": [
    "x",
    "freqs_cis",
    "use_real",
    "use_real_unbind_dim",
    "sequence_dim"
  ],
  "apply_rotary_emb_allegro": [
    "x",
    "freqs_cis",
    "positions"
  ],
  "TimestepEmbedding": {
    "__init__": [
      "self",
      "in_channels",
      "time_embed_dim",
      "act_fn",
      "out_dim",
      "post_act_fn",
      "cond_proj_dim",
      "sample_proj_bias"
    ],
    "forward": [
      "self",
      "sample",
      "condition"
    ]
  },
  "Timesteps": {
    "__init__": [
      "self",
      "num_channels",
      "flip_sin_to_cos",
      "downscale_freq_shift",
      "scale"
    ],
    "forward": [
      "self",
      "timesteps"
    ]
  },
  "GaussianFourierProjection": {
    "__init__": [
      "self",
      "embedding_size",
      "scale",
      "set_W_to_weight",
      "log",
      "flip_sin_to_cos"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SinusoidalPositionalEmbedding": {
    "__init__": [
      "self",
      "embed_dim",
      "max_seq_length"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ImagePositionalEmbeddings": {
    "__init__": [
      "self",
      "num_embed",
      "height",
      "width",
      "embed_dim"
    ],
    "forward": [
      "self",
      "index"
    ]
  },
  "LabelEmbedding": {
    "__init__": [
      "self",
      "num_classes",
      "hidden_size",
      "dropout_prob"
    ],
    "token_drop": [
      "self",
      "labels",
      "force_drop_ids"
    ],
    "forward": [
      "self",
      "labels",
      "force_drop_ids"
    ]
  },
  "TextImageProjection": {
    "__init__": [
      "self",
      "text_embed_dim",
      "image_embed_dim",
      "cross_attention_dim",
      "num_image_text_embeds"
    ],
    "forward": [
      "self",
      "text_embeds",
      "image_embeds"
    ]
  },
  "ImageProjection": {
    "__init__": [
      "self",
      "image_embed_dim",
      "cross_attention_dim",
      "num_image_text_embeds"
    ],
    "forward": [
      "self",
      "image_embeds"
    ]
  },
  "IPAdapterFullImageProjection": {
    "__init__": [
      "self",
      "image_embed_dim",
      "cross_attention_dim"
    ],
    "forward": [
      "self",
      "image_embeds"
    ]
  },
  "IPAdapterFaceIDImageProjection": {
    "__init__": [
      "self",
      "image_embed_dim",
      "cross_attention_dim",
      "mult",
      "num_tokens"
    ],
    "forward": [
      "self",
      "image_embeds"
    ]
  },
  "CombinedTimestepLabelEmbeddings": {
    "__init__": [
      "self",
      "num_classes",
      "embedding_dim",
      "class_dropout_prob"
    ],
    "forward": [
      "self",
      "timestep",
      "class_labels",
      "hidden_dtype"
    ]
  },
  "CombinedTimestepTextProjEmbeddings": {
    "__init__": [
      "self",
      "embedding_dim",
      "pooled_projection_dim"
    ],
    "forward": [
      "self",
      "timestep",
      "pooled_projection"
    ]
  },
  "CombinedTimestepGuidanceTextProjEmbeddings": {
    "__init__": [
      "self",
      "embedding_dim",
      "pooled_projection_dim"
    ],
    "forward": [
      "self",
      "timestep",
      "guidance",
      "pooled_projection"
    ]
  },
  "CogView3CombinedTimestepSizeEmbeddings": {
    "__init__": [
      "self",
      "embedding_dim",
      "condition_dim",
      "pooled_projection_dim",
      "timesteps_dim"
    ],
    "forward": [
      "self",
      "timestep",
      "original_size",
      "target_size",
      "crop_coords",
      "hidden_dtype"
    ]
  },
  "HunyuanDiTAttentionPool": {
    "__init__": [
      "self",
      "spacial_dim",
      "embed_dim",
      "num_heads",
      "output_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanCombinedTimestepTextSizeStyleEmbedding": {
    "__init__": [
      "self",
      "embedding_dim",
      "pooled_projection_dim",
      "seq_len",
      "cross_attention_dim",
      "use_style_cond_and_image_meta_size"
    ],
    "forward": [
      "self",
      "timestep",
      "encoder_hidden_states",
      "image_meta_size",
      "style",
      "hidden_dtype"
    ]
  },
  "LuminaCombinedTimestepCaptionEmbedding": {
    "__init__": [
      "self",
      "hidden_size",
      "cross_attention_dim",
      "frequency_embedding_size"
    ],
    "forward": [
      "self",
      "timestep",
      "caption_feat",
      "caption_mask"
    ]
  },
  "MochiCombinedTimestepCaptionEmbedding": {
    "__init__": [
      "self",
      "embedding_dim",
      "pooled_projection_dim",
      "text_embed_dim",
      "time_embed_dim",
      "num_attention_heads"
    ],
    "forward": [
      "self",
      "timestep",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "hidden_dtype"
    ]
  },
  "TextTimeEmbedding": {
    "__init__": [
      "self",
      "encoder_dim",
      "time_embed_dim",
      "num_heads"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "TextImageTimeEmbedding": {
    "__init__": [
      "self",
      "text_embed_dim",
      "image_embed_dim",
      "time_embed_dim"
    ],
    "forward": [
      "self",
      "text_embeds",
      "image_embeds"
    ]
  },
  "ImageTimeEmbedding": {
    "__init__": [
      "self",
      "image_embed_dim",
      "time_embed_dim"
    ],
    "forward": [
      "self",
      "image_embeds"
    ]
  },
  "ImageHintTimeEmbedding": {
    "__init__": [
      "self",
      "image_embed_dim",
      "time_embed_dim"
    ],
    "forward": [
      "self",
      "image_embeds",
      "hint"
    ]
  },
  "AttentionPooling": {
    "__init__": [
      "self",
      "num_heads",
      "embed_dim",
      "dtype"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MochiAttentionPool": {
    "__init__": [
      "self",
      "num_attention_heads",
      "embed_dim",
      "output_dim"
    ],
    "pool_tokens": [
      "x",
      "mask"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "get_fourier_embeds_from_boundingbox": [
    "embed_dim",
    "box"
  ],
  "PixArtAlphaCombinedTimestepSizeEmbeddings": {
    "__init__": [
      "self",
      "embedding_dim",
      "size_emb_dim",
      "use_additional_conditions"
    ],
    "forward": [
      "self",
      "timestep",
      "resolution",
      "aspect_ratio",
      "batch_size",
      "hidden_dtype"
    ]
  },
  "PixArtAlphaTextProjection": {
    "__init__": [
      "self",
      "in_features",
      "hidden_size",
      "out_features",
      "act_fn"
    ],
    "forward": [
      "self",
      "caption"
    ]
  },
  "IPAdapterPlusImageProjectionBlock": {
    "__init__": [
      "self",
      "embed_dims",
      "dim_head",
      "heads",
      "ffn_ratio"
    ],
    "forward": [
      "self",
      "x",
      "latents",
      "residual"
    ]
  },
  "IPAdapterPlusImageProjection": {
    "__init__": [
      "self",
      "embed_dims",
      "output_dims",
      "hidden_dims",
      "depth",
      "dim_head",
      "heads",
      "num_queries",
      "ffn_ratio"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "IPAdapterFaceIDPlusImageProjection": {
    "__init__": [
      "self",
      "embed_dims",
      "output_dims",
      "hidden_dims",
      "id_embeddings_dim",
      "depth",
      "dim_head",
      "heads",
      "num_tokens",
      "num_queries",
      "ffn_ratio",
      "ffproj_ratio"
    ],
    "forward": [
      "self",
      "id_embeds"
    ]
  },
  "IPAdapterTimeImageProjectionBlock": {
    "__init__": [
      "self",
      "hidden_dim",
      "dim_head",
      "heads",
      "ffn_ratio"
    ],
    "forward": [
      "self",
      "x",
      "latents",
      "timestep_emb"
    ]
  },
  "IPAdapterTimeImageProjection": {
    "__init__": [
      "self",
      "embed_dim",
      "output_dim",
      "hidden_dim",
      "depth",
      "dim_head",
      "heads",
      "num_queries",
      "ffn_ratio",
      "timestep_in_dim",
      "timestep_flip_sin_to_cos",
      "timestep_freq_shift"
    ],
    "forward": [
      "self",
      "x",
      "timestep"
    ]
  },
  "MultiIPAdapterImageProjection": {
    "__init__": [
      "self",
      "IPAdapterImageProjectionLayers"
    ],
    "num_ip_adapters": [
      "self"
    ],
    "forward": [
      "self",
      "image_embeds"
    ]
  },
  "FluxPosEmbed": {
    "__new__": [
      "cls"
    ]
  },
  "ACT2CLS": [],
  "get_activation": [
    "act_fn"
  ],
  "FP32SiLU": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "GELU": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "approximate",
      "bias"
    ],
    "gelu": [
      "self",
      "gate"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GEGLU": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "bias"
    ],
    "gelu": [
      "self",
      "gate"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SwiGLU": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ApproximateGELU": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LinearActivation": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "bias",
      "activation"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ResnetBlockCondNorm2D": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_tensor",
      "temb"
    ]
  },
  "ResnetBlock2D": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_tensor",
      "temb"
    ]
  },
  "rearrange_dims": [
    "tensor"
  ],
  "Conv1dBlock": {
    "__init__": [
      "self",
      "inp_channels",
      "out_channels",
      "kernel_size",
      "n_groups",
      "activation"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "ResidualTemporalBlock1D": {
    "__init__": [
      "self",
      "inp_channels",
      "out_channels",
      "embed_dim",
      "kernel_size",
      "activation"
    ],
    "forward": [
      "self",
      "inputs",
      "t"
    ]
  },
  "TemporalConvLayer": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "dropout",
      "norm_num_groups"
    ],
    "forward": [
      "self",
      "hidden_states",
      "num_frames"
    ]
  },
  "TemporalResnetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "eps"
    ],
    "forward": [
      "self",
      "input_tensor",
      "temb"
    ]
  },
  "SpatioTemporalResBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "eps",
      "temporal_eps",
      "merge_factor",
      "merge_strategy",
      "switch_spatial_to_temporal_mix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "image_only_indicator"
    ]
  },
  "AlphaBlender": {
    "strategies": [],
    "__init__": [
      "self",
      "alpha",
      "merge_strategy",
      "switch_spatial_to_temporal_mix"
    ],
    "get_alpha": [
      "self",
      "image_only_indicator",
      "ndims"
    ],
    "forward": [
      "self",
      "x_spatial",
      "x_temporal",
      "image_only_indicator"
    ]
  },
  "FluxControlNetOutput": {
    "__init__": [
      "self"
    ]
  },
  "Upsample1D": {
    "__init__": [
      "self",
      "channels",
      "use_conv",
      "use_conv_transpose",
      "out_channels",
      "name"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "Upsample2D": {
    "__init__": [
      "self",
      "channels",
      "use_conv",
      "use_conv_transpose",
      "out_channels",
      "name",
      "kernel_size",
      "padding",
      "norm_type",
      "eps",
      "elementwise_affine",
      "bias",
      "interpolate"
    ],
    "forward": [
      "self",
      "hidden_states",
      "output_size"
    ]
  },
  "FirUpsample2D": {
    "__init__": [
      "self",
      "channels",
      "out_channels",
      "use_conv",
      "fir_kernel"
    ],
    "_upsample_2d": [
      "self",
      "hidden_states",
      "weight",
      "kernel",
      "factor",
      "gain"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "KUpsample2D": {
    "__init__": [
      "self",
      "pad_mode"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "CogVideoXUpsample3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "compress_time"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "upfirdn2d_native": [
    "tensor",
    "kernel",
    "up",
    "down",
    "pad"
  ],
  "upsample_2d": [
    "hidden_states",
    "kernel",
    "factor",
    "gain"
  ],
  "AdaLayerNorm": {
    "__init__": [
      "self",
      "embedding_dim",
      "num_embeddings",
      "output_dim",
      "norm_elementwise_affine",
      "norm_eps",
      "chunk_dim"
    ],
    "forward": [
      "self",
      "x",
      "timestep",
      "temb"
    ]
  },
  "FP32LayerNorm": {
    "forward": [
      "self",
      "inputs"
    ]
  },
  "SD35AdaLayerNormZeroX": {
    "__init__": [
      "self",
      "embedding_dim",
      "norm_type",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "emb"
    ]
  },
  "AdaLayerNormZero": {
    "__init__": [
      "self",
      "embedding_dim",
      "num_embeddings",
      "norm_type",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "timestep",
      "class_labels",
      "hidden_dtype",
      "emb"
    ]
  },
  "AdaLayerNormZeroSingle": {
    "__init__": [
      "self",
      "embedding_dim",
      "norm_type",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "emb"
    ]
  },
  "LuminaRMSNormZero": {
    "__init__": [
      "self",
      "embedding_dim",
      "norm_eps",
      "norm_elementwise_affine"
    ],
    "forward": [
      "self",
      "x",
      "emb"
    ]
  },
  "AdaLayerNormSingle": {
    "__init__": [
      "self",
      "embedding_dim",
      "use_additional_conditions"
    ],
    "forward": [
      "self",
      "timestep",
      "added_cond_kwargs",
      "batch_size",
      "hidden_dtype"
    ]
  },
  "AdaGroupNorm": {
    "__init__": [
      "self",
      "embedding_dim",
      "out_dim",
      "num_groups",
      "act_fn",
      "eps"
    ],
    "forward": [
      "self",
      "x",
      "emb"
    ]
  },
  "AdaLayerNormContinuous": {
    "__init__": [
      "self",
      "embedding_dim",
      "conditioning_embedding_dim",
      "elementwise_affine",
      "eps",
      "bias",
      "norm_type"
    ],
    "forward": [
      "self",
      "x",
      "conditioning_embedding"
    ]
  },
  "LuminaLayerNormContinuous": {
    "__init__": [
      "self",
      "embedding_dim",
      "conditioning_embedding_dim",
      "elementwise_affine",
      "eps",
      "bias",
      "norm_type",
      "out_dim"
    ],
    "forward": [
      "self",
      "x",
      "conditioning_embedding"
    ]
  },
  "CogView3PlusAdaLayerNormZeroTextImage": {
    "__init__": [
      "self",
      "embedding_dim",
      "dim"
    ],
    "forward": [
      "self",
      "x",
      "context",
      "emb"
    ]
  },
  "CogVideoXLayerNormZero": {
    "__init__": [
      "self",
      "conditioning_dim",
      "embedding_dim",
      "elementwise_affine",
      "eps",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb"
    ]
  },
  "MochiRMSNorm": {
    "__init__": [
      "self",
      "dim",
      "eps",
      "elementwise_affine"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LpNorm": {
    "__init__": [
      "self",
      "p",
      "dim",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "get_normalization": [
    "norm_type",
    "num_features",
    "eps",
    "elementwise_affine",
    "bias"
  ],
  "get_sinusoidal_embeddings": [
    "timesteps",
    "embedding_dim",
    "freq_shift",
    "min_timescale",
    "max_timescale",
    "flip_sin_to_cos",
    "scale"
  ],
  "FlaxTimestepEmbedding": {
    "__call__": [
      "self",
      "temb"
    ]
  },
  "FlaxTimesteps": {
    "__call__": [
      "self",
      "timesteps"
    ]
  },
  "AttentionMixin": {
    "attn_processors": [
      "self"
    ],
    "set_attn_processor": [
      "self",
      "processor"
    ],
    "fuse_qkv_projections": [
      "self"
    ],
    "unfuse_qkv_projections": [
      "self"
    ]
  },
  "AttentionModuleMixin": {
    "_default_processor_cls": [],
    "_available_processors": [],
    "_supports_qkv_fusion": [],
    "fused_projections": [],
    "set_processor": [
      "self",
      "processor"
    ],
    "get_processor": [
      "self",
      "return_deprecated_lora"
    ],
    "set_attention_backend": [
      "self",
      "backend"
    ],
    "set_use_npu_flash_attention": [
      "self",
      "use_npu_flash_attention"
    ],
    "set_use_xla_flash_attention": [
      "self",
      "use_xla_flash_attention",
      "partition_spec",
      "is_flux"
    ],
    "set_use_memory_efficient_attention_xformers": [
      "self",
      "use_memory_efficient_attention_xformers",
      "attention_op"
    ],
    "fuse_projections": [
      "self"
    ],
    "unfuse_projections": [
      "self"
    ],
    "set_attention_slice": [
      "self",
      "slice_size"
    ],
    "batch_to_head_dim": [
      "self",
      "tensor"
    ],
    "head_to_batch_dim": [
      "self",
      "tensor",
      "out_dim"
    ],
    "get_attention_scores": [
      "self",
      "query",
      "key",
      "attention_mask"
    ],
    "prepare_attention_mask": [
      "self",
      "attention_mask",
      "target_length",
      "batch_size",
      "out_dim"
    ],
    "norm_encoder_hidden_states": [
      "self",
      "encoder_hidden_states"
    ]
  },
  "_chunked_feed_forward": [
    "ff",
    "hidden_states",
    "chunk_dim",
    "chunk_size"
  ],
  "GatedSelfAttentionDense": {
    "__init__": [
      "self",
      "query_dim",
      "context_dim",
      "n_heads",
      "d_head"
    ],
    "forward": [
      "self",
      "x",
      "objs"
    ]
  },
  "JointTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "context_pre_only",
      "qk_norm",
      "use_dual_attention"
    ],
    "set_chunk_feed_forward": [
      "self",
      "chunk_size",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "joint_attention_kwargs"
    ]
  },
  "BasicTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "dropout",
      "cross_attention_dim",
      "activation_fn",
      "num_embeds_ada_norm",
      "attention_bias",
      "only_cross_attention",
      "double_self_attention",
      "upcast_attention",
      "norm_elementwise_affine",
      "norm_type",
      "norm_eps",
      "final_dropout",
      "attention_type",
      "positional_embeddings",
      "num_positional_embeddings",
      "ada_norm_continous_conditioning_embedding_dim",
      "ada_norm_bias",
      "ff_inner_dim",
      "ff_bias",
      "attention_out_bias"
    ],
    "set_chunk_feed_forward": [
      "self",
      "chunk_size",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "timestep",
      "cross_attention_kwargs",
      "class_labels",
      "added_cond_kwargs"
    ]
  },
  "LuminaFeedForward": {
    "__init__": [
      "self",
      "dim",
      "inner_dim",
      "multiple_of",
      "ffn_dim_multiplier"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TemporalBasicTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "time_mix_inner_dim",
      "num_attention_heads",
      "attention_head_dim",
      "cross_attention_dim"
    ],
    "set_chunk_feed_forward": [
      "self",
      "chunk_size"
    ],
    "forward": [
      "self",
      "hidden_states",
      "num_frames",
      "encoder_hidden_states"
    ]
  },
  "SkipFFTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "kv_input_dim",
      "kv_input_dim_proj_use_bias",
      "dropout",
      "cross_attention_dim",
      "attention_bias",
      "attention_out_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "cross_attention_kwargs"
    ]
  },
  "FreeNoiseTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "dropout",
      "cross_attention_dim",
      "activation_fn",
      "num_embeds_ada_norm",
      "attention_bias",
      "only_cross_attention",
      "double_self_attention",
      "upcast_attention",
      "norm_elementwise_affine",
      "norm_type",
      "norm_eps",
      "final_dropout",
      "positional_embeddings",
      "num_positional_embeddings",
      "ff_inner_dim",
      "ff_bias",
      "attention_out_bias",
      "context_length",
      "context_stride",
      "weighting_scheme"
    ],
    "_get_frame_indices": [
      "self",
      "num_frames"
    ],
    "_get_frame_weights": [
      "self",
      "num_frames",
      "weighting_scheme"
    ],
    "set_free_noise_properties": [
      "self",
      "context_length",
      "context_stride",
      "weighting_scheme"
    ],
    "set_chunk_feed_forward": [
      "self",
      "chunk_size",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "cross_attention_kwargs"
    ]
  },
  "FeedForward": {
    "__init__": [
      "self",
      "dim",
      "dim_out",
      "mult",
      "dropout",
      "activation_fn",
      "final_dropout",
      "inner_dim",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "FullAdapter": {
    "__init__": [
      "self",
      "in_channels",
      "channels",
      "num_res_blocks",
      "downscale_factor"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FullAdapterXL": {
    "__init__": [
      "self",
      "in_channels",
      "channels",
      "num_res_blocks",
      "downscale_factor"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AdapterBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_res_blocks",
      "down"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AdapterResnetBlock": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LightAdapter": {
    "__init__": [
      "self",
      "in_channels",
      "channels",
      "num_res_blocks",
      "downscale_factor"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LightAdapterBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_res_blocks",
      "down"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LightAdapterResnetBlock": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "load_flax_checkpoint_in_pytorch_model": [
    "pt_model",
    "model_file"
  ],
  "load_flax_weights_in_pytorch_model": [
    "pt_model",
    "flax_state"
  ],
  "ContextManagers": {
    "__init__": [
      "self",
      "context_managers"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "_REGEX_SHARD": [],
  "TORCH_INIT_FUNCTIONS": [],
  "get_parameter_device": [
    "parameter"
  ],
  "get_parameter_dtype": [
    "parameter"
  ],
  "no_init_weights": [],
  "LegacyModelMixin": {
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "SD3ControlNetOutput": {
    "__init__": [
      "self"
    ]
  },
  "Attention": {
    "__init__": [
      "self",
      "query_dim",
      "cross_attention_dim",
      "heads",
      "kv_heads",
      "dim_head",
      "dropout",
      "bias",
      "upcast_attention",
      "upcast_softmax",
      "cross_attention_norm",
      "cross_attention_norm_num_groups",
      "qk_norm",
      "added_kv_proj_dim",
      "added_proj_bias",
      "norm_num_groups",
      "spatial_norm_dim",
      "out_bias",
      "scale_qk",
      "only_cross_attention",
      "eps",
      "rescale_output_factor",
      "residual_connection",
      "_from_deprecated_attn_block",
      "processor",
      "out_dim",
      "out_context_dim",
      "context_pre_only",
      "pre_only",
      "elementwise_affine",
      "is_causal"
    ],
    "set_use_xla_flash_attention": [
      "self",
      "use_xla_flash_attention",
      "partition_spec",
      "is_flux"
    ],
    "set_use_npu_flash_attention": [
      "self",
      "use_npu_flash_attention"
    ],
    "set_use_memory_efficient_attention_xformers": [
      "self",
      "use_memory_efficient_attention_xformers",
      "attention_op"
    ],
    "set_attention_slice": [
      "self",
      "slice_size"
    ],
    "set_processor": [
      "self",
      "processor"
    ],
    "get_processor": [
      "self",
      "return_deprecated_lora"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ],
    "batch_to_head_dim": [
      "self",
      "tensor"
    ],
    "head_to_batch_dim": [
      "self",
      "tensor",
      "out_dim"
    ],
    "get_attention_scores": [
      "self",
      "query",
      "key",
      "attention_mask"
    ],
    "prepare_attention_mask": [
      "self",
      "attention_mask",
      "target_length",
      "batch_size",
      "out_dim"
    ],
    "norm_encoder_hidden_states": [
      "self",
      "encoder_hidden_states"
    ],
    "fuse_projections": [
      "self",
      "fuse"
    ]
  },
  "SanaMultiscaleAttentionProjection": {
    "__init__": [
      "self",
      "in_channels",
      "num_attention_heads",
      "kernel_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SanaMultiscaleLinearAttention": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_attention_heads",
      "attention_head_dim",
      "mult",
      "norm_type",
      "kernel_sizes",
      "eps",
      "residual_connection"
    ],
    "apply_linear_attention": [
      "self",
      "query",
      "key",
      "value"
    ],
    "apply_quadratic_attention": [
      "self",
      "query",
      "key",
      "value"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MochiAttention": {
    "__init__": [
      "self",
      "query_dim",
      "added_kv_proj_dim",
      "processor",
      "heads",
      "dim_head",
      "dropout",
      "bias",
      "added_proj_bias",
      "out_dim",
      "out_context_dim",
      "out_bias",
      "context_pre_only",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "MochiAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "AttnProcessor": {
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb"
    ]
  },
  "CustomDiffusionAttnProcessor": {
    "__init__": [
      "self",
      "train_kv",
      "train_q_out",
      "hidden_size",
      "cross_attention_dim",
      "out_bias",
      "dropout"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "AttnAddedKVProcessor": {
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "AttnAddedKVProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "JointAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "PAGJointAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "PAGCFGJointAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "FusedJointAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "XFormersJointAttnProcessor": {
    "__init__": [
      "self",
      "attention_op"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "AllegroAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb",
      "image_rotary_emb"
    ]
  },
  "AuraFlowAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states"
    ]
  },
  "FusedAuraFlowAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states"
    ]
  },
  "CogVideoXAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "FusedCogVideoXAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "XFormersAttnAddedKVProcessor": {
    "__init__": [
      "self",
      "attention_op"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "XFormersAttnProcessor": {
    "__init__": [
      "self",
      "attention_op"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb"
    ]
  },
  "AttnProcessorNPU": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb"
    ]
  },
  "AttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb"
    ]
  },
  "XLAFlashAttnProcessor2_0": {
    "__init__": [
      "self",
      "partition_spec"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb"
    ]
  },
  "MochiVaeAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "StableAudioAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "apply_partial_rotary_emb": [
      "self",
      "x",
      "freqs_cis"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "rotary_emb"
    ]
  },
  "HunyuanAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb",
      "image_rotary_emb"
    ]
  },
  "FusedHunyuanAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb",
      "image_rotary_emb"
    ]
  },
  "PAGHunyuanAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb",
      "image_rotary_emb"
    ]
  },
  "PAGCFGHunyuanAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb",
      "image_rotary_emb"
    ]
  },
  "LuminaAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "query_rotary_emb",
      "key_rotary_emb",
      "base_sequence_length"
    ]
  },
  "FusedAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb"
    ]
  },
  "CustomDiffusionXFormersAttnProcessor": {
    "__init__": [
      "self",
      "train_kv",
      "train_q_out",
      "hidden_size",
      "cross_attention_dim",
      "out_bias",
      "dropout",
      "attention_op"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "CustomDiffusionAttnProcessor2_0": {
    "__init__": [
      "self",
      "train_kv",
      "train_q_out",
      "hidden_size",
      "cross_attention_dim",
      "out_bias",
      "dropout"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "SlicedAttnProcessor": {
    "__init__": [
      "self",
      "slice_size"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "SlicedAttnAddedKVProcessor": {
    "__init__": [
      "self",
      "slice_size"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb"
    ]
  },
  "SpatialNorm": {
    "__init__": [
      "self",
      "f_channels",
      "zq_channels"
    ],
    "forward": [
      "self",
      "f",
      "zq"
    ]
  },
  "IPAdapterAttnProcessor": {
    "__init__": [
      "self",
      "hidden_size",
      "cross_attention_dim",
      "num_tokens",
      "scale"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb",
      "scale",
      "ip_adapter_masks"
    ]
  },
  "IPAdapterAttnProcessor2_0": {
    "__init__": [
      "self",
      "hidden_size",
      "cross_attention_dim",
      "num_tokens",
      "scale"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb",
      "scale",
      "ip_adapter_masks"
    ]
  },
  "IPAdapterXFormersAttnProcessor": {
    "__init__": [
      "self",
      "hidden_size",
      "cross_attention_dim",
      "num_tokens",
      "scale",
      "attention_op"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb",
      "scale",
      "ip_adapter_masks"
    ]
  },
  "SD3IPAdapterJointAttnProcessor2_0": {
    "__init__": [
      "self",
      "hidden_size",
      "ip_hidden_states_dim",
      "head_dim",
      "timesteps_emb_dim",
      "scale"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "ip_hidden_states",
      "temb"
    ]
  },
  "PAGIdentitySelfAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb"
    ]
  },
  "PAGCFGIdentitySelfAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "temb"
    ]
  },
  "SanaMultiscaleAttnProcessor2_0": {
    "__call__": [
      "self",
      "attn",
      "hidden_states"
    ]
  },
  "LoRAAttnProcessor": {
    "__init__": [
      "self"
    ]
  },
  "LoRAAttnProcessor2_0": {
    "__init__": [
      "self"
    ]
  },
  "LoRAXFormersAttnProcessor": {
    "__init__": [
      "self"
    ]
  },
  "LoRAAttnAddedKVProcessor": {
    "__init__": [
      "self"
    ]
  },
  "SanaLinearAttnProcessor2_0": {
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "PAGCFGSanaLinearAttnProcessor2_0": {
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "PAGIdentitySanaLinearAttnProcessor2_0": {
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "FluxAttnProcessor2_0": {
    "__new__": [
      "cls"
    ]
  },
  "FluxSingleAttnProcessor2_0": {
    "__new__": [
      "cls"
    ]
  },
  "FusedFluxAttnProcessor2_0": {
    "__new__": [
      "cls"
    ]
  },
  "FluxIPAdapterJointAttnProcessor2_0": {
    "__new__": [
      "cls"
    ]
  },
  "FluxAttnProcessor2_0_NPU": {
    "__new__": [
      "cls"
    ]
  },
  "FusedFluxAttnProcessor2_0_NPU": {
    "__new__": [
      "self"
    ]
  },
  "XLAFluxFlashAttnProcessor2_0": {
    "__new__": [
      "cls"
    ]
  },
  "ADDED_KV_ATTENTION_PROCESSORS": [],
  "CROSS_ATTENTION_PROCESSORS": [],
  "AttentionProcessor": [],
  "SparseControlNetOutput": {
    "__init__": [
      "self"
    ]
  },
  "SparseControlNetConditioningEmbedding": {
    "__init__": [
      "self"
    ]
  },
  "_REQUIRED_FLASH_VERSION": [],
  "_REQUIRED_AITER_VERSION": [],
  "_REQUIRED_SAGE_VERSION": [],
  "_REQUIRED_FLEX_VERSION": [],
  "_REQUIRED_XLA_VERSION": [],
  "_REQUIRED_XFORMERS_VERSION": [],
  "_CAN_USE_FLASH_ATTN": [],
  "_CAN_USE_FLASH_ATTN_3": [],
  "_CAN_USE_AITER_ATTN": [],
  "_CAN_USE_SAGE_ATTN": [],
  "_CAN_USE_FLEX_ATTN": [],
  "_CAN_USE_NPU_ATTN": [],
  "_CAN_USE_XLA_ATTN": [],
  "_CAN_USE_XFORMERS_ATTN": [],
  "_AttentionBackendRegistry": {
    "_backends": [],
    "_constraints": [],
    "_supported_arg_names": [],
    "_supports_context_parallel": [],
    "_active_backend": [],
    "_checks_enabled": [],
    "register": [
      "cls",
      "backend",
      "constraints",
      "supports_context_parallel"
    ],
    "get_active_backend": [
      "cls"
    ],
    "list_backends": [
      "cls"
    ],
    "_is_context_parallel_available": [
      "cls",
      "backend"
    ]
  },
  "_HubKernelConfig": {},
  "dispatch_attention_fn": [
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal",
    "scale",
    "enable_gqa",
    "attention_kwargs"
  ],
  "_check_attn_mask_or_causal": [
    "attn_mask",
    "is_causal"
  ],
  "_check_device": [
    "query",
    "key",
    "value"
  ],
  "_check_device_cuda": [
    "query",
    "key",
    "value"
  ],
  "_check_device_cuda_atleast_smXY": [
    "major",
    "minor"
  ],
  "_check_qkv_dtype_match": [
    "query",
    "key",
    "value"
  ],
  "_check_qkv_dtype_bf16_or_fp16": [
    "query",
    "key",
    "value"
  ],
  "_check_shape": [
    "query",
    "key",
    "value",
    "attn_mask"
  ],
  "_check_attention_backend_requirements": [
    "backend"
  ],
  "_prepare_for_flash_attn_or_sage_varlen_without_mask": [
    "batch_size",
    "seq_len_q",
    "seq_len_kv",
    "device"
  ],
  "_prepare_for_flash_attn_or_sage_varlen_with_mask": [
    "batch_size",
    "seq_len_q",
    "attn_mask",
    "device"
  ],
  "_prepare_for_flash_attn_or_sage_varlen": [
    "batch_size",
    "seq_len_q",
    "seq_len_kv",
    "attn_mask",
    "device"
  ],
  "_normalize_attn_mask": [
    "attn_mask",
    "batch_size",
    "seq_len_k"
  ],
  "_flex_attention_causal_mask_mod": [
    "batch_idx",
    "head_idx",
    "q_idx",
    "kv_idx"
  ],
  "_maybe_download_kernel_for_backend": [
    "backend"
  ],
  "_wrapped_flash_attn_3": [
    "q",
    "k",
    "v",
    "softmax_scale",
    "causal",
    "qv",
    "q_descale",
    "k_descale",
    "v_descale",
    "attention_chunk",
    "softcap",
    "num_splits",
    "pack_gqa",
    "deterministic",
    "sm_margin"
  ],
  "_": [
    "q",
    "k",
    "v",
    "softmax_scale",
    "causal",
    "qv",
    "q_descale",
    "k_descale",
    "v_descale",
    "attention_chunk",
    "softcap",
    "num_splits",
    "pack_gqa",
    "deterministic",
    "sm_margin"
  ],
  "_native_attention_forward_op": [
    "ctx",
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal",
    "scale",
    "enable_gqa",
    "return_lse",
    "_save_ctx",
    "_parallel_config"
  ],
  "_native_attention_backward_op": [
    "ctx",
    "grad_out"
  ],
  "_cudnn_attention_forward_op": [
    "ctx",
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal",
    "scale",
    "enable_gqa",
    "return_lse",
    "_save_ctx",
    "_parallel_config"
  ],
  "_cudnn_attention_backward_op": [
    "ctx",
    "grad_out"
  ],
  "_flash_attention_forward_op": [
    "ctx",
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal",
    "scale",
    "enable_gqa",
    "return_lse",
    "_save_ctx",
    "_parallel_config"
  ],
  "_flash_attention_backward_op": [
    "ctx",
    "grad_out"
  ],
  "_sage_attention_forward_op": [
    "ctx",
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal",
    "scale",
    "enable_gqa",
    "return_lse",
    "_save_ctx",
    "_parallel_config"
  ],
  "_sage_attention_backward_op": [
    "ctx",
    "grad_out"
  ],
  "_wait_tensor": [
    "tensor"
  ],
  "_all_to_all_single": [
    "x",
    "group"
  ],
  "TemplatedRingAttention": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "enable_gqa",
      "return_lse",
      "forward_op",
      "backward_op",
      "_parallel_config"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "TemplatedUlyssesAttention": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "enable_gqa",
      "return_lse",
      "forward_op",
      "backward_op",
      "_parallel_config"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "_templated_context_parallel_attention": [
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal",
    "scale",
    "enable_gqa",
    "return_lse"
  ],
  "_flash_attention": [
    "query",
    "key",
    "value",
    "dropout_p",
    "is_causal",
    "scale",
    "return_lse",
    "_parallel_config"
  ],
  "_flash_attention_hub": [
    "query",
    "key",
    "value",
    "dropout_p",
    "is_causal",
    "scale",
    "return_lse",
    "_parallel_config"
  ],
  "_flash_varlen_attention_hub": [
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "scale",
    "is_causal",
    "return_lse",
    "_parallel_config"
  ],
  "_flash_varlen_attention": [
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "scale",
    "is_causal",
    "return_lse",
    "_parallel_config"
  ],
  "_flash_attention_3": [
    "query",
    "key",
    "value",
    "scale",
    "is_causal",
    "return_lse",
    "_parallel_config"
  ],
  "_flash_attention_3_hub": [
    "query",
    "key",
    "value",
    "scale",
    "is_causal",
    "window_size",
    "softcap",
    "deterministic",
    "return_attn_probs",
    "_parallel_config"
  ],
  "_flash_attention_3_varlen_hub": [
    "query",
    "key",
    "value",
    "attn_mask",
    "scale",
    "is_causal",
    "return_lse",
    "_parallel_config"
  ],
  "_flash_varlen_attention_3": [
    "query",
    "key",
    "value",
    "attn_mask",
    "scale",
    "is_causal",
    "return_lse",
    "_parallel_config"
  ],
  "_aiter_flash_attention": [
    "query",
    "key",
    "value",
    "dropout_p",
    "is_causal",
    "scale",
    "return_lse",
    "_parallel_config"
  ],
  "_native_flex_attention": [
    "query",
    "key",
    "value",
    "attn_mask",
    "is_causal",
    "scale",
    "enable_gqa",
    "return_lse",
    "_parallel_config"
  ],
  "_native_attention": [
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal",
    "scale",
    "enable_gqa",
    "return_lse",
    "_parallel_config"
  ],
  "_native_cudnn_attention": [
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal",
    "scale",
    "enable_gqa",
    "return_lse",
    "_parallel_config"
  ],
  "_native_efficient_attention": [
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal",
    "scale",
    "enable_gqa",
    "return_lse",
    "_parallel_config"
  ],
  "_native_flash_attention": [
    "query",
    "key",
    "value",
    "dropout_p",
    "is_causal",
    "scale",
    "enable_gqa",
    "return_lse",
    "_parallel_config"
  ],
  "_native_math_attention": [
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal",
    "scale",
    "enable_gqa",
    "return_lse",
    "_parallel_config"
  ],
  "_native_npu_attention": [
    "query",
    "key",
    "value",
    "dropout_p",
    "scale",
    "return_lse",
    "_parallel_config"
  ],
  "_native_xla_attention": [
    "query",
    "key",
    "value",
    "is_causal",
    "return_lse",
    "_parallel_config"
  ],
  "_sage_attention": [
    "query",
    "key",
    "value",
    "is_causal",
    "scale",
    "return_lse",
    "_parallel_config"
  ],
  "_sage_attention_hub": [
    "query",
    "key",
    "value",
    "is_causal",
    "scale",
    "return_lse",
    "_parallel_config"
  ],
  "_sage_varlen_attention": [
    "query",
    "key",
    "value",
    "attn_mask",
    "is_causal",
    "scale",
    "return_lse",
    "_parallel_config"
  ],
  "_sage_qk_int8_pv_fp8_cuda_attention": [
    "query",
    "key",
    "value",
    "is_causal",
    "scale",
    "return_lse",
    "_parallel_config"
  ],
  "_sage_qk_int8_pv_fp8_cuda_sm90_attention": [
    "query",
    "key",
    "value",
    "is_causal",
    "scale",
    "return_lse",
    "_parallel_config"
  ],
  "_sage_qk_int8_pv_fp16_cuda_attention": [
    "query",
    "key",
    "value",
    "is_causal",
    "scale",
    "return_lse",
    "_parallel_config"
  ],
  "_sage_qk_int8_pv_fp16_triton_attention": [
    "query",
    "key",
    "value",
    "is_causal",
    "scale",
    "return_lse",
    "_parallel_config"
  ],
  "_xformers_attention": [
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal",
    "scale",
    "enable_gqa",
    "return_lse",
    "_parallel_config"
  ],
  "ControlNetOutput": {
    "__init__": [
      "self"
    ]
  },
  "ControlNetConditioningEmbedding": {
    "__init__": [
      "self"
    ]
  },
  "FlaxUpsample2D": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "FlaxDownsample2D": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "FlaxResnetBlock2D": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "temb",
      "deterministic"
    ]
  },
  "AutoencoderKLOutput": {},
  "Transformer2DModelOutput": {},
  "FlaxDecoderOutput": {},
  "FlaxAutoencoderKLOutput": {},
  "FlaxAttentionBlock": {
    "setup": [
      "self"
    ],
    "transpose_for_scores": [
      "self",
      "projection"
    ],
    "__call__": [
      "self",
      "hidden_states"
    ]
  },
  "FlaxDownEncoderBlock2D": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "deterministic"
    ]
  },
  "FlaxUpDecoderBlock2D": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "deterministic"
    ]
  },
  "FlaxUNetMidBlock2D": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "deterministic"
    ]
  },
  "FlaxEncoder": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "sample",
      "deterministic"
    ]
  },
  "FlaxDecoder": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "sample",
      "deterministic"
    ]
  },
  "FlaxDiagonalGaussianDistribution": {
    "__init__": [
      "self",
      "parameters",
      "deterministic"
    ],
    "sample": [
      "self",
      "key"
    ],
    "kl": [
      "self",
      "other"
    ],
    "nll": [
      "self",
      "sample",
      "axis"
    ],
    "mode": [
      "self"
    ]
  },
  "Lumina2CombinedTimestepCaptionEmbedding": {
    "__init__": [
      "self",
      "hidden_size",
      "cap_feat_dim",
      "frequency_embedding_size",
      "norm_eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "timestep",
      "encoder_hidden_states"
    ]
  },
  "Lumina2AttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb",
      "base_sequence_length"
    ]
  },
  "Lumina2TransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "num_kv_heads",
      "multiple_of",
      "ffn_dim_multiplier",
      "norm_eps",
      "modulation"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "image_rotary_emb",
      "temb"
    ]
  },
  "Lumina2RotaryPosEmbed": {
    "__init__": [
      "self",
      "theta",
      "axes_dim",
      "axes_lens",
      "patch_size"
    ],
    "_precompute_freqs_cis": [
      "self",
      "axes_dim",
      "axes_lens",
      "theta"
    ],
    "_get_freqs_cis": [
      "self",
      "ids"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "CogView4PatchEmbed": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_size",
      "patch_size",
      "text_hidden_size"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ]
  },
  "CogView4AdaLayerNormZero": {
    "__init__": [
      "self",
      "embedding_dim",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb"
    ]
  },
  "CogView4AttnProcessor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "CogView4TrainingAttnProcessor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "latent_attn_mask",
      "text_attn_mask",
      "batch_flag",
      "image_rotary_emb"
    ]
  },
  "CogView4TransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "time_embed_dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "attention_mask",
      "attention_kwargs"
    ]
  },
  "CogView4RotaryPosEmbed": {
    "__init__": [
      "self",
      "dim",
      "patch_size",
      "rope_axes_dim",
      "theta"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CogView4AdaLayerNormContinuous": {
    "__init__": [
      "self",
      "embedding_dim",
      "conditioning_embedding_dim",
      "elementwise_affine",
      "eps",
      "bias",
      "norm_type"
    ],
    "forward": [
      "self",
      "x",
      "conditioning_embedding"
    ]
  },
  "_get_projections": [
    "attn",
    "hidden_states",
    "encoder_hidden_states"
  ],
  "_get_fused_projections": [
    "attn",
    "hidden_states",
    "encoder_hidden_states"
  ],
  "_get_qkv_projections": [
    "attn",
    "hidden_states",
    "encoder_hidden_states"
  ],
  "Flux2SwiGLU": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Flux2FeedForward": {
    "__init__": [
      "self",
      "dim",
      "dim_out",
      "mult",
      "inner_dim",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Flux2AttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "Flux2Attention": {
    "_default_processor_cls": [],
    "_available_processors": [],
    "__init__": [
      "self",
      "query_dim",
      "heads",
      "dim_head",
      "dropout",
      "bias",
      "added_kv_proj_dim",
      "added_proj_bias",
      "out_bias",
      "eps",
      "out_dim",
      "elementwise_affine",
      "processor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "Flux2ParallelSelfAttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "Flux2ParallelSelfAttention": {
    "_default_processor_cls": [],
    "_available_processors": [],
    "_supports_qkv_fusion": [],
    "__init__": [
      "self",
      "query_dim",
      "heads",
      "dim_head",
      "dropout",
      "bias",
      "out_bias",
      "eps",
      "out_dim",
      "elementwise_affine",
      "mlp_ratio",
      "mlp_mult_factor",
      "processor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "Flux2SingleTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio",
      "eps",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb_mod_params",
      "image_rotary_emb",
      "joint_attention_kwargs",
      "split_hidden_states",
      "text_seq_len"
    ]
  },
  "Flux2TransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio",
      "eps",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb_mod_params_img",
      "temb_mod_params_txt",
      "image_rotary_emb",
      "joint_attention_kwargs"
    ]
  },
  "Flux2PosEmbed": {
    "__init__": [
      "self",
      "theta",
      "axes_dim"
    ],
    "forward": [
      "self",
      "ids"
    ]
  },
  "Flux2TimestepGuidanceEmbeddings": {
    "__init__": [
      "self",
      "in_channels",
      "embedding_dim",
      "bias"
    ],
    "forward": [
      "self",
      "timestep",
      "guidance"
    ]
  },
  "Flux2Modulation": {
    "__init__": [
      "self",
      "dim",
      "mod_param_sets",
      "bias"
    ],
    "forward": [
      "self",
      "temb"
    ]
  },
  "ChromaAdaLayerNormZeroPruned": {
    "__init__": [
      "self",
      "embedding_dim",
      "num_embeddings",
      "norm_type",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "timestep",
      "class_labels",
      "hidden_dtype",
      "emb"
    ]
  },
  "ChromaAdaLayerNormZeroSinglePruned": {
    "__init__": [
      "self",
      "embedding_dim",
      "norm_type",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "emb"
    ]
  },
  "ChromaAdaLayerNormContinuousPruned": {
    "__init__": [
      "self",
      "embedding_dim",
      "conditioning_embedding_dim",
      "elementwise_affine",
      "eps",
      "bias",
      "norm_type"
    ],
    "forward": [
      "self",
      "x",
      "emb"
    ]
  },
  "ChromaCombinedTimestepTextProjEmbeddings": {
    "__init__": [
      "self",
      "num_channels",
      "out_dim"
    ],
    "forward": [
      "self",
      "timestep"
    ]
  },
  "ChromaApproximator": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "hidden_dim",
      "n_layers"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ChromaSingleTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "image_rotary_emb",
      "attention_mask",
      "joint_attention_kwargs"
    ]
  },
  "ChromaTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "qk_norm",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "attention_mask",
      "joint_attention_kwargs"
    ]
  },
  "AllegroTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "dropout",
      "cross_attention_dim",
      "activation_fn",
      "attention_bias",
      "norm_elementwise_affine",
      "norm_eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "attention_mask",
      "encoder_attention_mask",
      "image_rotary_emb"
    ]
  },
  "HunyuanVideoFramepackRotaryPosEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "patch_size_t",
      "rope_dim",
      "theta"
    ],
    "forward": [
      "self",
      "frame_indices",
      "height",
      "width",
      "device"
    ]
  },
  "FramepackClipVisionProjection": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoHistoryPatchEmbed": {
    "__init__": [
      "self",
      "in_channels",
      "inner_dim"
    ],
    "forward": [
      "self",
      "latents_clean",
      "latents_clean_2x",
      "latents_clean_4x"
    ]
  },
  "_pad_for_3d_conv": [
    "x",
    "kernel_size"
  ],
  "_center_down_sample_3d": [
    "x",
    "kernel_size"
  ],
  "CosmosPatchEmbed": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "patch_size",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CosmosTimestepEmbedding": {
    "__init__": [
      "self",
      "in_features",
      "out_features"
    ],
    "forward": [
      "self",
      "timesteps"
    ]
  },
  "CosmosEmbedding": {
    "__init__": [
      "self",
      "embedding_dim",
      "condition_dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "timestep"
    ]
  },
  "CosmosAdaLayerNorm": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features"
    ],
    "forward": [
      "self",
      "hidden_states",
      "embedded_timestep",
      "temb"
    ]
  },
  "CosmosAdaLayerNormZero": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features"
    ],
    "forward": [
      "self",
      "hidden_states",
      "embedded_timestep",
      "temb"
    ]
  },
  "CosmosAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "CosmosTransformerBlock": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "cross_attention_dim",
      "mlp_ratio",
      "adaln_lora_dim",
      "qk_norm",
      "out_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "embedded_timestep",
      "temb",
      "image_rotary_emb",
      "extra_pos_emb",
      "attention_mask"
    ]
  },
  "CosmosRotaryPosEmbed": {
    "__init__": [
      "self",
      "hidden_size",
      "max_size",
      "patch_size",
      "base_fps",
      "rope_scale"
    ],
    "forward": [
      "self",
      "hidden_states",
      "fps"
    ]
  },
  "CosmosLearnablePositionalEmbed": {
    "__init__": [
      "self",
      "hidden_size",
      "max_size",
      "patch_size",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "OvisImageAttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "OvisImageAttention": {
    "_default_processor_cls": [],
    "_available_processors": [],
    "__init__": [
      "self",
      "query_dim",
      "heads",
      "dim_head",
      "dropout",
      "bias",
      "added_kv_proj_dim",
      "added_proj_bias",
      "out_bias",
      "eps",
      "out_dim",
      "context_pre_only",
      "pre_only",
      "elementwise_affine",
      "processor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "OvisImageSingleTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "joint_attention_kwargs"
    ]
  },
  "OvisImageTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "qk_norm",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "joint_attention_kwargs"
    ]
  },
  "OvisImagePosEmbed": {
    "__init__": [
      "self",
      "theta",
      "axes_dim"
    ],
    "forward": [
      "self",
      "ids"
    ]
  },
  "BriaFiboAttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "BriaFiboAttention": {
    "_default_processor_cls": [],
    "_available_processors": [],
    "__init__": [
      "self",
      "query_dim",
      "heads",
      "dim_head",
      "dropout",
      "bias",
      "added_kv_proj_dim",
      "added_proj_bias",
      "out_bias",
      "eps",
      "out_dim",
      "context_pre_only",
      "pre_only",
      "elementwise_affine",
      "processor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "BriaFiboEmbedND": {
    "__init__": [
      "self",
      "theta",
      "axes_dim"
    ],
    "forward": [
      "self",
      "ids"
    ]
  },
  "BriaFiboSingleTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "image_rotary_emb",
      "joint_attention_kwargs"
    ]
  },
  "BriaFiboTextProjection": {
    "__init__": [
      "self",
      "in_features",
      "hidden_size"
    ],
    "forward": [
      "self",
      "caption"
    ]
  },
  "BriaFiboTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "qk_norm",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "joint_attention_kwargs"
    ]
  },
  "BriaFiboTimesteps": {
    "__init__": [
      "self",
      "num_channels",
      "flip_sin_to_cos",
      "downscale_freq_shift",
      "scale",
      "time_theta"
    ],
    "forward": [
      "self",
      "timesteps"
    ]
  },
  "BriaFiboTimestepProjEmbeddings": {
    "__init__": [
      "self",
      "embedding_dim",
      "time_theta"
    ],
    "forward": [
      "self",
      "timestep",
      "dtype"
    ]
  },
  "_get_added_kv_projections": [
    "attn",
    "encoder_hidden_states_img"
  ],
  "WanAttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "rotary_emb"
    ]
  },
  "WanAttnProcessor2_0": {
    "__new__": [
      "cls"
    ]
  },
  "WanAttention": {
    "_default_processor_cls": [],
    "_available_processors": [],
    "__init__": [
      "self",
      "dim",
      "heads",
      "dim_head",
      "eps",
      "dropout",
      "added_kv_proj_dim",
      "cross_attention_dim_head",
      "processor",
      "is_cross_attention"
    ],
    "fuse_projections": [
      "self"
    ],
    "unfuse_projections": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "rotary_emb"
    ]
  },
  "WanImageEmbedding": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "pos_embed_seq_len"
    ],
    "forward": [
      "self",
      "encoder_hidden_states_image"
    ]
  },
  "WanTimeTextImageEmbedding": {
    "__init__": [
      "self",
      "dim",
      "time_freq_dim",
      "time_proj_dim",
      "text_embed_dim",
      "image_embed_dim",
      "pos_embed_seq_len"
    ],
    "forward": [
      "self",
      "timestep",
      "encoder_hidden_states",
      "encoder_hidden_states_image",
      "timestep_seq_len"
    ]
  },
  "WanRotaryPosEmbed": {
    "__init__": [
      "self",
      "attention_head_dim",
      "patch_size",
      "max_seq_len",
      "theta"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "WanTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "ffn_dim",
      "num_heads",
      "qk_norm",
      "cross_attn_norm",
      "eps",
      "added_kv_proj_dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "rotary_emb"
    ]
  },
  "HunyuanVideo15AttnProcessor2_0": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "HunyuanVideo15PatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "in_chans",
      "embed_dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideo15AdaNorm": {
    "__init__": [
      "self",
      "in_features",
      "out_features"
    ],
    "forward": [
      "self",
      "temb"
    ]
  },
  "HunyuanVideo15TimeEmbedding": {
    "__init__": [
      "self",
      "embedding_dim",
      "use_meanflow"
    ],
    "forward": [
      "self",
      "timestep",
      "timestep_r"
    ]
  },
  "HunyuanVideo15IndividualTokenRefinerBlock": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_width_ratio",
      "mlp_drop_rate",
      "attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "attention_mask"
    ]
  },
  "HunyuanVideo15IndividualTokenRefiner": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "num_layers",
      "mlp_width_ratio",
      "mlp_drop_rate",
      "attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "attention_mask"
    ]
  },
  "HunyuanVideo15TokenRefiner": {
    "__init__": [
      "self",
      "in_channels",
      "num_attention_heads",
      "attention_head_dim",
      "num_layers",
      "mlp_ratio",
      "mlp_drop_rate",
      "attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "timestep",
      "attention_mask"
    ]
  },
  "HunyuanVideo15RotaryPosEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "patch_size_t",
      "rope_dim",
      "theta"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideo15ByT5TextProjection": {
    "__init__": [
      "self",
      "in_features",
      "hidden_size",
      "out_features"
    ],
    "forward": [
      "self",
      "encoder_hidden_states"
    ]
  },
  "HunyuanVideo15ImageProjection": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_size"
    ],
    "forward": [
      "self",
      "image_embeds"
    ]
  },
  "HunyuanVideo15TransformerBlock": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio",
      "qk_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "attention_mask",
      "freqs_cis"
    ]
  },
  "TransformerTemporalModelOutput": {},
  "TransformerSpatioTemporalModel": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "in_channels",
      "out_channels",
      "num_layers",
      "cross_attention_dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "image_only_indicator",
      "return_dict"
    ]
  },
  "AdaLayerNormShift": {
    "__init__": [
      "self",
      "embedding_dim",
      "elementwise_affine",
      "eps"
    ],
    "forward": [
      "self",
      "x",
      "emb"
    ]
  },
  "HunyuanDiTBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "cross_attention_dim",
      "dropout",
      "activation_fn",
      "norm_elementwise_affine",
      "norm_eps",
      "final_dropout",
      "ff_inner_dim",
      "ff_bias",
      "skip",
      "qk_norm"
    ],
    "set_chunk_feed_forward": [
      "self",
      "chunk_size",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "skip"
    ]
  },
  "apply_rotary_emb_qwen": [
    "x",
    "freqs_cis",
    "use_real",
    "use_real_unbind_dim"
  ],
  "QwenTimestepProjEmbeddings": {
    "__init__": [
      "self",
      "embedding_dim"
    ],
    "forward": [
      "self",
      "timestep",
      "hidden_states"
    ]
  },
  "QwenEmbedRope": {
    "__init__": [
      "self",
      "theta",
      "axes_dim",
      "scale_rope"
    ],
    "rope_params": [
      "self",
      "index",
      "dim",
      "theta"
    ],
    "forward": [
      "self",
      "video_fhw",
      "txt_seq_lens",
      "device"
    ],
    "_compute_video_freqs": [
      "self",
      "frame",
      "height",
      "width",
      "idx"
    ]
  },
  "QwenDoubleStreamAttnProcessor2_0": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "encoder_hidden_states_mask",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "QwenImageTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "qk_norm",
      "eps"
    ],
    "_modulate": [
      "self",
      "x",
      "mod_params"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "encoder_hidden_states_mask",
      "temb",
      "image_rotary_emb",
      "joint_attention_kwargs"
    ]
  },
  "HunyuanVideoAttnProcessor2_0": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "HunyuanVideoPatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "in_chans",
      "embed_dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoAdaNorm": {
    "__init__": [
      "self",
      "in_features",
      "out_features"
    ],
    "forward": [
      "self",
      "temb"
    ]
  },
  "HunyuanVideoTokenReplaceAdaLayerNormZero": {
    "__init__": [
      "self",
      "embedding_dim",
      "norm_type",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "emb",
      "token_replace_emb",
      "first_frame_num_tokens"
    ]
  },
  "HunyuanVideoTokenReplaceAdaLayerNormZeroSingle": {
    "__init__": [
      "self",
      "embedding_dim",
      "norm_type",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "emb",
      "token_replace_emb",
      "first_frame_num_tokens"
    ]
  },
  "HunyuanVideoConditionEmbedding": {
    "__init__": [
      "self",
      "embedding_dim",
      "pooled_projection_dim",
      "guidance_embeds",
      "image_condition_type"
    ],
    "forward": [
      "self",
      "timestep",
      "pooled_projection",
      "guidance"
    ]
  },
  "HunyuanVideoIndividualTokenRefinerBlock": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_width_ratio",
      "mlp_drop_rate",
      "attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "attention_mask"
    ]
  },
  "HunyuanVideoIndividualTokenRefiner": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "num_layers",
      "mlp_width_ratio",
      "mlp_drop_rate",
      "attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "attention_mask"
    ]
  },
  "HunyuanVideoTokenRefiner": {
    "__init__": [
      "self",
      "in_channels",
      "num_attention_heads",
      "attention_head_dim",
      "num_layers",
      "mlp_ratio",
      "mlp_drop_rate",
      "attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "timestep",
      "attention_mask"
    ]
  },
  "HunyuanVideoRotaryPosEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "patch_size_t",
      "rope_dim",
      "theta"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoSingleTransformerBlock": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio",
      "qk_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "HunyuanVideoTransformerBlock": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio",
      "qk_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "attention_mask",
      "freqs_cis"
    ]
  },
  "HunyuanVideoTokenReplaceSingleTransformerBlock": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio",
      "qk_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "attention_mask",
      "image_rotary_emb",
      "token_replace_emb",
      "num_tokens"
    ]
  },
  "HunyuanVideoTokenReplaceTransformerBlock": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio",
      "qk_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "attention_mask",
      "freqs_cis",
      "token_replace_emb",
      "num_tokens"
    ]
  },
  "HiDreamImageFeedForwardSwiGLU": {
    "__init__": [
      "self",
      "dim",
      "hidden_dim",
      "multiple_of",
      "ffn_dim_multiplier"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HiDreamImagePooledEmbed": {
    "__init__": [
      "self",
      "text_emb_dim",
      "hidden_size"
    ],
    "forward": [
      "self",
      "pooled_embed"
    ]
  },
  "HiDreamImageTimestepEmbed": {
    "__init__": [
      "self",
      "hidden_size",
      "frequency_embedding_size"
    ],
    "forward": [
      "self",
      "timesteps",
      "wdtype"
    ]
  },
  "HiDreamImageOutEmbed": {
    "__init__": [
      "self",
      "hidden_size",
      "patch_size",
      "out_channels"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "HiDreamImagePatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "latent"
    ]
  },
  "rope": [
    "pos",
    "dim",
    "theta"
  ],
  "HiDreamImageEmbedND": {
    "__init__": [
      "self",
      "theta",
      "axes_dim"
    ],
    "forward": [
      "self",
      "ids"
    ]
  },
  "apply_rope": [
    "xq",
    "xk",
    "freqs_cis"
  ],
  "HiDreamAttention": {
    "__init__": [
      "self",
      "query_dim",
      "heads",
      "dim_head",
      "upcast_attention",
      "upcast_softmax",
      "scale_qk",
      "eps",
      "processor",
      "out_dim",
      "single"
    ],
    "forward": [
      "self",
      "norm_hidden_states",
      "hidden_states_masks",
      "norm_encoder_hidden_states",
      "image_rotary_emb"
    ]
  },
  "HiDreamAttnProcessor": {
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "hidden_states_masks",
      "encoder_hidden_states",
      "image_rotary_emb"
    ]
  },
  "MoEGate": {
    "__init__": [
      "self",
      "embed_dim",
      "num_routed_experts",
      "num_activated_experts",
      "aux_loss_alpha",
      "_force_inference_output"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MOEFeedForwardSwiGLU": {
    "__init__": [
      "self",
      "dim",
      "hidden_dim",
      "num_routed_experts",
      "num_activated_experts",
      "_force_inference_output"
    ],
    "forward": [
      "self",
      "x"
    ],
    "moe_infer": [
      "self",
      "x",
      "flat_expert_indices",
      "flat_expert_weights"
    ]
  },
  "TextProjection": {
    "__init__": [
      "self",
      "in_features",
      "hidden_size"
    ],
    "forward": [
      "self",
      "caption"
    ]
  },
  "HiDreamImageSingleTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "num_routed_experts",
      "num_activated_experts",
      "_force_inference_output"
    ],
    "forward": [
      "self",
      "hidden_states",
      "hidden_states_masks",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb"
    ]
  },
  "HiDreamImageTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "num_routed_experts",
      "num_activated_experts",
      "_force_inference_output"
    ],
    "forward": [
      "self",
      "hidden_states",
      "hidden_states_masks",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb"
    ]
  },
  "HiDreamBlock": {
    "__init__": [
      "self",
      "block"
    ],
    "forward": [
      "self",
      "hidden_states",
      "hidden_states_masks",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb"
    ]
  },
  "find_multiple": [
    "n",
    "k"
  ],
  "AuraFlowPatchEmbed": {
    "__init__": [
      "self",
      "height",
      "width",
      "patch_size",
      "in_channels",
      "embed_dim",
      "pos_embed_max_size"
    ],
    "pe_selection_index_based_on_dim": [
      "self",
      "h",
      "w"
    ],
    "forward": [
      "self",
      "latent"
    ]
  },
  "AuraFlowFeedForward": {
    "__init__": [
      "self",
      "dim",
      "hidden_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AuraFlowPreFinalBlock": {
    "__init__": [
      "self",
      "embedding_dim",
      "conditioning_embedding_dim"
    ],
    "forward": [
      "self",
      "x",
      "conditioning_embedding"
    ]
  },
  "AuraFlowSingleTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "attention_kwargs"
    ]
  },
  "AuraFlowJointTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "attention_kwargs"
    ]
  },
  "GLUMBTempConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "expand_ratio",
      "norm_type",
      "residual_connection"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SanaLinearAttnProcessor3_0": {
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "rotary_emb"
    ]
  },
  "SanaModulatedNorm": {
    "__init__": [
      "self",
      "dim",
      "elementwise_affine",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "scale_shift_table"
    ]
  },
  "SanaCombinedTimestepGuidanceEmbeddings": {
    "__init__": [
      "self",
      "embedding_dim"
    ],
    "forward": [
      "self",
      "timestep",
      "guidance",
      "hidden_dtype"
    ]
  },
  "SanaAttnProcessor2_0": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "SanaVideoTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "dropout",
      "num_cross_attention_heads",
      "cross_attention_head_dim",
      "cross_attention_dim",
      "attention_bias",
      "norm_elementwise_affine",
      "norm_eps",
      "attention_out_bias",
      "mlp_ratio",
      "qk_norm",
      "rope_max_seq_len"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "timestep",
      "frames",
      "height",
      "width",
      "rotary_emb"
    ]
  },
  "HunyuanImageAttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "HunyuanImagePatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "in_chans",
      "embed_dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanImageByT5TextProjection": {
    "__init__": [
      "self",
      "in_features",
      "hidden_size",
      "out_features"
    ],
    "forward": [
      "self",
      "encoder_hidden_states"
    ]
  },
  "HunyuanImageAdaNorm": {
    "__init__": [
      "self",
      "in_features",
      "out_features"
    ],
    "forward": [
      "self",
      "temb"
    ]
  },
  "HunyuanImageCombinedTimeGuidanceEmbedding": {
    "__init__": [
      "self",
      "embedding_dim",
      "guidance_embeds",
      "use_meanflow"
    ],
    "forward": [
      "self",
      "timestep",
      "timestep_r",
      "guidance"
    ]
  },
  "HunyuanImageIndividualTokenRefinerBlock": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_width_ratio",
      "mlp_drop_rate",
      "attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "attention_mask"
    ]
  },
  "HunyuanImageIndividualTokenRefiner": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "num_layers",
      "mlp_width_ratio",
      "mlp_drop_rate",
      "attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "attention_mask"
    ]
  },
  "HunyuanImageTokenRefiner": {
    "__init__": [
      "self",
      "in_channels",
      "num_attention_heads",
      "attention_head_dim",
      "num_layers",
      "mlp_ratio",
      "mlp_drop_rate",
      "attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "timestep",
      "attention_mask"
    ]
  },
  "HunyuanImageRotaryPosEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "rope_dim",
      "theta"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanImageSingleTransformerBlock": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio",
      "qk_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "HunyuanImageTransformerBlock": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio",
      "qk_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "PerceiverAttention": {
    "__init__": [
      "self",
      "dim",
      "dim_head",
      "heads",
      "kv_dim"
    ],
    "forward": [
      "self",
      "image_embeds",
      "latents"
    ]
  },
  "LocalFacialExtractor": {
    "__init__": [
      "self",
      "id_dim",
      "vit_dim",
      "depth",
      "dim_head",
      "heads",
      "num_id_token",
      "num_queries",
      "output_dim",
      "ff_mult",
      "num_scale"
    ],
    "forward": [
      "self",
      "id_embeds",
      "vit_hidden_states"
    ]
  },
  "PerceiverCrossAttention": {
    "__init__": [
      "self",
      "dim",
      "dim_head",
      "heads",
      "kv_dim"
    ],
    "forward": [
      "self",
      "image_embeds",
      "hidden_states"
    ]
  },
  "ConsisIDBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "time_embed_dim",
      "dropout",
      "activation_fn",
      "attention_bias",
      "qk_norm",
      "norm_elementwise_affine",
      "norm_eps",
      "final_dropout",
      "ff_inner_dim",
      "ff_bias",
      "attention_out_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb"
    ]
  },
  "WAN_ANIMATE_MOTION_ENCODER_CHANNEL_SIZES": [],
  "FusedLeakyReLU": {
    "__init__": [
      "self",
      "negative_slope",
      "scale",
      "bias_channels"
    ],
    "forward": [
      "self",
      "x",
      "channel_dim"
    ]
  },
  "MotionConv2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "bias",
      "blur_kernel",
      "blur_upsample_factor",
      "use_activation"
    ],
    "forward": [
      "self",
      "x",
      "channel_dim"
    ],
    "__repr__": [
      "self"
    ]
  },
  "MotionLinear": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "bias",
      "use_activation"
    ],
    "forward": [
      "self",
      "input",
      "channel_dim"
    ],
    "__repr__": [
      "self"
    ]
  },
  "MotionEncoderResBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "kernel_size_skip",
      "blur_kernel",
      "downsample_factor"
    ],
    "forward": [
      "self",
      "x",
      "channel_dim"
    ]
  },
  "WanAnimateMotionEncoder": {
    "__init__": [
      "self",
      "size",
      "style_dim",
      "motion_dim",
      "out_dim",
      "motion_blocks",
      "channels"
    ],
    "forward": [
      "self",
      "face_image",
      "channel_dim"
    ]
  },
  "WanAnimateFaceEncoder": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "hidden_dim",
      "num_heads",
      "kernel_size",
      "eps",
      "pad_mode"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanAnimateFaceBlockAttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "WanAnimateFaceBlockCrossAttention": {
    "_default_processor_cls": [],
    "_available_processors": [],
    "__init__": [
      "self",
      "dim",
      "heads",
      "dim_head",
      "eps",
      "cross_attention_dim_head",
      "processor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "LuminaNextDiTBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "num_kv_heads",
      "multiple_of",
      "ffn_dim_multiplier",
      "norm_eps",
      "qk_norm",
      "cross_attention_dim",
      "norm_elementwise_affine"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "image_rotary_emb",
      "encoder_hidden_states",
      "encoder_mask",
      "temb",
      "cross_attention_kwargs"
    ]
  },
  "CogView3PlusTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "time_embed_dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "emb"
    ]
  },
  "GLUMBConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "expand_ratio",
      "norm_type",
      "residual_connection"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SanaTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "dropout",
      "num_cross_attention_heads",
      "cross_attention_head_dim",
      "cross_attention_dim",
      "attention_bias",
      "norm_elementwise_affine",
      "norm_eps",
      "attention_out_bias",
      "mlp_ratio",
      "qk_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "timestep",
      "height",
      "width"
    ]
  },
  "WanVACETransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "ffn_dim",
      "num_heads",
      "qk_norm",
      "cross_attn_norm",
      "eps",
      "added_kv_proj_dim",
      "apply_input_projection",
      "apply_output_projection"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "control_hidden_states",
      "temb",
      "rotary_emb"
    ]
  },
  "SD3SingleTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "SkyReelsV2AttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "rotary_emb"
    ]
  },
  "SkyReelsV2AttnProcessor2_0": {
    "__new__": [
      "cls"
    ]
  },
  "SkyReelsV2Attention": {
    "_default_processor_cls": [],
    "_available_processors": [],
    "__init__": [
      "self",
      "dim",
      "heads",
      "dim_head",
      "eps",
      "dropout",
      "added_kv_proj_dim",
      "cross_attention_dim_head",
      "processor",
      "is_cross_attention"
    ],
    "fuse_projections": [
      "self"
    ],
    "unfuse_projections": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "rotary_emb"
    ]
  },
  "SkyReelsV2ImageEmbedding": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "pos_embed_seq_len"
    ],
    "forward": [
      "self",
      "encoder_hidden_states_image"
    ]
  },
  "SkyReelsV2Timesteps": {
    "__init__": [
      "self",
      "num_channels",
      "flip_sin_to_cos",
      "output_type"
    ],
    "forward": [
      "self",
      "timesteps"
    ]
  },
  "SkyReelsV2TimeTextImageEmbedding": {
    "__init__": [
      "self",
      "dim",
      "time_freq_dim",
      "time_proj_dim",
      "text_embed_dim",
      "image_embed_dim",
      "pos_embed_seq_len"
    ],
    "forward": [
      "self",
      "timestep",
      "encoder_hidden_states",
      "encoder_hidden_states_image"
    ]
  },
  "SkyReelsV2RotaryPosEmbed": {
    "__init__": [
      "self",
      "attention_head_dim",
      "patch_size",
      "max_seq_len",
      "theta"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SkyReelsV2TransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "ffn_dim",
      "num_heads",
      "qk_norm",
      "cross_attn_norm",
      "eps",
      "added_kv_proj_dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "rotary_emb",
      "attention_mask"
    ]
  },
  "FluxAttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "FluxIPAdapterAttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self",
      "hidden_size",
      "cross_attention_dim",
      "num_tokens",
      "scale",
      "device",
      "dtype"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb",
      "ip_hidden_states",
      "ip_adapter_masks"
    ]
  },
  "FluxAttention": {
    "_default_processor_cls": [],
    "_available_processors": [],
    "__init__": [
      "self",
      "query_dim",
      "heads",
      "dim_head",
      "dropout",
      "bias",
      "added_kv_proj_dim",
      "added_proj_bias",
      "out_bias",
      "eps",
      "out_dim",
      "context_pre_only",
      "pre_only",
      "elementwise_affine",
      "processor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "FluxSingleTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "joint_attention_kwargs"
    ]
  },
  "FluxTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "qk_norm",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "joint_attention_kwargs"
    ]
  },
  "get_image_ids": [
    "batch_size",
    "height",
    "width",
    "patch_size",
    "device"
  ],
  "PRXAttnProcessor2_0": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "PRXAttention": {
    "_default_processor_cls": [],
    "_available_processors": [],
    "__init__": [
      "self",
      "query_dim",
      "heads",
      "dim_head",
      "bias",
      "out_bias",
      "eps",
      "processor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "PRXEmbedND": {
    "__init__": [
      "self",
      "dim",
      "theta",
      "axes_dim"
    ],
    "rope": [
      "self",
      "pos",
      "dim",
      "theta"
    ],
    "forward": [
      "self",
      "ids"
    ]
  },
  "MLPEmbedder": {
    "__init__": [
      "self",
      "in_dim",
      "hidden_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Modulation": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "vec"
    ]
  },
  "PRXBlock": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "mlp_ratio",
      "qk_scale"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "attention_mask"
    ]
  },
  "FinalLayer": {
    "__init__": [
      "self",
      "hidden_size",
      "patch_size",
      "out_channels"
    ],
    "forward": [
      "self",
      "x",
      "vec"
    ]
  },
  "img2seq": [
    "img",
    "patch_size"
  ],
  "seq2img": [
    "seq",
    "patch_size",
    "shape"
  ],
  "ADALN_EMBED_DIM": [],
  "SEQ_MULTI_OF": [],
  "TimestepEmbedder": {
    "__init__": [
      "self",
      "out_size",
      "mid_size",
      "frequency_embedding_size"
    ],
    "timestep_embedding": [
      "t",
      "dim",
      "max_period"
    ],
    "forward": [
      "self",
      "t"
    ]
  },
  "ZSingleStreamAttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "freqs_cis"
    ]
  },
  "ZImageTransformerBlock": {
    "__init__": [
      "self",
      "layer_id",
      "dim",
      "n_heads",
      "n_kv_heads",
      "norm_eps",
      "qk_norm",
      "modulation"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask",
      "freqs_cis",
      "adaln_input"
    ]
  },
  "RopeEmbedder": {
    "__init__": [
      "self",
      "theta",
      "axes_dims",
      "axes_lens"
    ],
    "precompute_freqs_cis": [
      "dim",
      "end",
      "theta"
    ],
    "__call__": [
      "self",
      "ids"
    ]
  },
  "LTXVideoAttentionProcessor2_0": {
    "__new__": [
      "cls"
    ]
  },
  "LTXVideoAttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "LTXAttention": {
    "_default_processor_cls": [],
    "_available_processors": [],
    "__init__": [
      "self",
      "query_dim",
      "heads",
      "kv_heads",
      "dim_head",
      "dropout",
      "bias",
      "cross_attention_dim",
      "out_bias",
      "qk_norm",
      "processor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "LTXVideoRotaryPosEmbed": {
    "__init__": [
      "self",
      "dim",
      "base_num_frames",
      "base_height",
      "base_width",
      "patch_size",
      "patch_size_t",
      "theta"
    ],
    "_prepare_video_coords": [
      "self",
      "batch_size",
      "num_frames",
      "height",
      "width",
      "rope_interpolation_scale",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "num_frames",
      "height",
      "width",
      "rope_interpolation_scale",
      "video_coords"
    ]
  },
  "LTXVideoTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "cross_attention_dim",
      "qk_norm",
      "activation_fn",
      "attention_bias",
      "attention_out_bias",
      "eps",
      "elementwise_affine"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "encoder_attention_mask"
    ]
  },
  "DecoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "d_kv",
      "num_heads",
      "d_ff",
      "dropout_rate",
      "layer_norm_epsilon"
    ],
    "forward": [
      "self",
      "hidden_states",
      "conditioning_emb",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "encoder_decoder_position_bias"
    ]
  },
  "T5LayerSelfAttentionCond": {
    "__init__": [
      "self",
      "d_model",
      "d_kv",
      "num_heads",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "hidden_states",
      "conditioning_emb",
      "attention_mask"
    ]
  },
  "T5LayerCrossAttention": {
    "__init__": [
      "self",
      "d_model",
      "d_kv",
      "num_heads",
      "dropout_rate",
      "layer_norm_epsilon"
    ],
    "forward": [
      "self",
      "hidden_states",
      "key_value_states",
      "attention_mask"
    ]
  },
  "T5LayerFFCond": {
    "__init__": [
      "self",
      "d_model",
      "d_ff",
      "dropout_rate",
      "layer_norm_epsilon"
    ],
    "forward": [
      "self",
      "hidden_states",
      "conditioning_emb"
    ]
  },
  "T5DenseGatedActDense": {
    "__init__": [
      "self",
      "d_model",
      "d_ff",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5LayerNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "NewGELUActivation": {
    "forward": [
      "self",
      "input"
    ]
  },
  "T5FiLMLayer": {
    "__init__": [
      "self",
      "in_features",
      "out_features"
    ],
    "forward": [
      "self",
      "x",
      "conditioning_emb"
    ]
  },
  "OmniGenFeedForward": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "OmniGenPatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "in_channels",
      "embed_dim",
      "bias",
      "interpolation_scale",
      "pos_embed_max_size",
      "base_size"
    ],
    "_cropped_pos_embed": [
      "self",
      "height",
      "width"
    ],
    "_patch_embeddings": [
      "self",
      "hidden_states",
      "is_input_image"
    ],
    "forward": [
      "self",
      "hidden_states",
      "is_input_image",
      "padding_latent"
    ]
  },
  "OmniGenSuScaledRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "original_max_position_embeddings",
      "base",
      "rope_scaling"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids"
    ]
  },
  "OmniGenAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "OmniGenBlock": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "num_key_value_heads",
      "intermediate_size",
      "rms_norm_eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "DualTransformer2DModel": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "in_channels",
      "num_layers",
      "dropout",
      "norm_num_groups",
      "cross_attention_dim",
      "attention_bias",
      "sample_size",
      "num_vector_embeds",
      "activation_fn",
      "num_embeds_ada_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "timestep",
      "attention_mask",
      "cross_attention_kwargs",
      "return_dict"
    ]
  },
  "BriaAttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "BriaAttention": {
    "_default_processor_cls": [],
    "_available_processors": [],
    "__init__": [
      "self",
      "query_dim",
      "heads",
      "dim_head",
      "dropout",
      "bias",
      "added_kv_proj_dim",
      "added_proj_bias",
      "out_bias",
      "eps",
      "out_dim",
      "context_pre_only",
      "pre_only",
      "elementwise_affine",
      "processor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "BriaEmbedND": {
    "__init__": [
      "self",
      "theta",
      "axes_dim"
    ],
    "forward": [
      "self",
      "ids"
    ]
  },
  "BriaTimesteps": {
    "__init__": [
      "self",
      "num_channels",
      "flip_sin_to_cos",
      "downscale_freq_shift",
      "scale",
      "time_theta"
    ],
    "forward": [
      "self",
      "timesteps"
    ]
  },
  "BriaTimestepProjEmbeddings": {
    "__init__": [
      "self",
      "embedding_dim",
      "time_theta"
    ],
    "forward": [
      "self",
      "timestep",
      "dtype"
    ]
  },
  "BriaPosEmbed": {
    "__init__": [
      "self",
      "theta",
      "axes_dim"
    ],
    "forward": [
      "self",
      "ids"
    ]
  },
  "BriaTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "qk_norm",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "attention_kwargs"
    ]
  },
  "BriaSingleTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "attention_kwargs"
    ]
  },
  "StableAudioGaussianFourierProjection": {
    "__init__": [
      "self",
      "embedding_size",
      "scale",
      "set_W_to_weight",
      "log",
      "flip_sin_to_cos"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StableAudioDiTBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "num_key_value_attention_heads",
      "attention_head_dim",
      "dropout",
      "cross_attention_dim",
      "upcast_attention",
      "norm_eps",
      "ff_inner_dim"
    ],
    "set_chunk_feed_forward": [
      "self",
      "chunk_size",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "rotary_embedding"
    ]
  },
  "EasyAnimateLayerNormZero": {
    "__init__": [
      "self",
      "conditioning_dim",
      "embedding_dim",
      "elementwise_affine",
      "eps",
      "bias",
      "norm_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb"
    ]
  },
  "EasyAnimateRotaryPosEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "rope_dim"
    ],
    "get_resize_crop_region_for_grid": [
      "self",
      "src",
      "tgt_width",
      "tgt_height"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EasyAnimateAttnProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb"
    ]
  },
  "EasyAnimateTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "time_embed_dim",
      "dropout",
      "activation_fn",
      "norm_elementwise_affine",
      "norm_eps",
      "final_dropout",
      "ff_inner_dim",
      "ff_bias",
      "qk_norm",
      "after_norm",
      "norm_type",
      "is_mmdit_block"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb"
    ]
  },
  "PriorTransformerOutput": {},
  "MochiModulatedRMSNorm": {
    "__init__": [
      "self",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "scale"
    ]
  },
  "MochiLayerNormContinuous": {
    "__init__": [
      "self",
      "embedding_dim",
      "conditioning_embedding_dim",
      "eps",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "conditioning_embedding"
    ]
  },
  "MochiRMSNormZero": {
    "__init__": [
      "self",
      "embedding_dim",
      "hidden_dim",
      "eps",
      "elementwise_affine"
    ],
    "forward": [
      "self",
      "hidden_states",
      "emb"
    ]
  },
  "MochiTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "pooled_projection_dim",
      "qk_norm",
      "activation_fn",
      "context_pre_only",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "encoder_attention_mask",
      "image_rotary_emb"
    ]
  },
  "MochiRoPE": {
    "__init__": [
      "self",
      "base_height",
      "base_width"
    ],
    "_centers": [
      "self",
      "start",
      "stop",
      "num",
      "device",
      "dtype"
    ],
    "_get_positions": [
      "self",
      "num_frames",
      "height",
      "width",
      "device",
      "dtype"
    ],
    "_create_rope": [
      "self",
      "freqs",
      "pos"
    ],
    "forward": [
      "self",
      "pos_frequencies",
      "num_frames",
      "height",
      "width",
      "device",
      "dtype"
    ]
  },
  "CogVideoXBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "time_embed_dim",
      "dropout",
      "activation_fn",
      "attention_bias",
      "qk_norm",
      "norm_elementwise_affine",
      "norm_eps",
      "final_dropout",
      "ff_inner_dim",
      "ff_bias",
      "attention_out_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "attention_kwargs"
    ]
  },
  "ChronoEditRotaryPosEmbed": {
    "__init__": [
      "self",
      "attention_head_dim",
      "patch_size",
      "max_seq_len",
      "theta",
      "temporal_skip_len"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "get_freqs": [
    "dim",
    "max_period"
  ],
  "fractal_flatten": [
    "x",
    "rope",
    "shape",
    "block_mask"
  ],
  "fractal_unflatten": [
    "x",
    "shape",
    "block_mask"
  ],
  "local_patching": [
    "x",
    "shape",
    "group_size",
    "dim"
  ],
  "local_merge": [
    "x",
    "shape",
    "group_size",
    "dim"
  ],
  "nablaT_v2": [
    "q",
    "k",
    "sta",
    "thr"
  ],
  "Kandinsky5TimeEmbeddings": {
    "__init__": [
      "self",
      "model_dim",
      "time_dim",
      "max_period"
    ],
    "forward": [
      "self",
      "time"
    ]
  },
  "Kandinsky5TextEmbeddings": {
    "__init__": [
      "self",
      "text_dim",
      "model_dim"
    ],
    "forward": [
      "self",
      "text_embed"
    ]
  },
  "Kandinsky5VisualEmbeddings": {
    "__init__": [
      "self",
      "visual_dim",
      "model_dim",
      "patch_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Kandinsky5RoPE1D": {
    "__init__": [
      "self",
      "dim",
      "max_pos",
      "max_period"
    ],
    "forward": [
      "self",
      "pos"
    ]
  },
  "Kandinsky5RoPE3D": {
    "__init__": [
      "self",
      "axes_dims",
      "max_pos",
      "max_period"
    ],
    "forward": [
      "self",
      "shape",
      "pos",
      "scale_factor"
    ]
  },
  "Kandinsky5Modulation": {
    "__init__": [
      "self",
      "time_dim",
      "model_dim",
      "num_params"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Kandinsky5AttnProcessor": {
    "_attention_backend": [],
    "_parallel_config": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "rotary_emb",
      "sparse_params"
    ]
  },
  "Kandinsky5Attention": {
    "_default_processor_cls": [],
    "_available_processors": [],
    "__init__": [
      "self",
      "num_channels",
      "head_dim",
      "processor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "sparse_params",
      "rotary_emb"
    ]
  },
  "Kandinsky5FeedForward": {
    "__init__": [
      "self",
      "dim",
      "ff_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Kandinsky5OutLayer": {
    "__init__": [
      "self",
      "model_dim",
      "time_dim",
      "visual_dim",
      "patch_size"
    ],
    "forward": [
      "self",
      "visual_embed",
      "text_embed",
      "time_embed"
    ]
  },
  "Kandinsky5TransformerEncoderBlock": {
    "__init__": [
      "self",
      "model_dim",
      "time_dim",
      "ff_dim",
      "head_dim"
    ],
    "forward": [
      "self",
      "x",
      "time_embed",
      "rope"
    ]
  },
  "Kandinsky5TransformerDecoderBlock": {
    "__init__": [
      "self",
      "model_dim",
      "time_dim",
      "ff_dim",
      "head_dim"
    ],
    "forward": [
      "self",
      "visual_embed",
      "text_embed",
      "time_embed",
      "rope",
      "sparse_params"
    ]
  },
  "AllegroTemporalConvLayer": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "dropout",
      "norm_num_groups",
      "up_sample",
      "down_sample",
      "stride"
    ],
    "_pad_temporal_dim": [
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "batch_size"
    ]
  },
  "AllegroDownBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "spatial_downsample",
      "temporal_downsample",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AllegroUpBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "spatial_upsample",
      "temporal_upsample",
      "temb_channels"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AllegroMidBlock3DConv": {
    "__init__": [
      "self",
      "in_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "add_attention",
      "attention_head_dim",
      "output_scale_factor"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AllegroEncoder3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "down_block_types",
      "block_out_channels",
      "temporal_downsample_blocks",
      "layers_per_block",
      "norm_num_groups",
      "act_fn",
      "double_z"
    ],
    "forward": [
      "self",
      "sample"
    ]
  },
  "AllegroDecoder3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "up_block_types",
      "temporal_upsample_blocks",
      "block_out_channels",
      "layers_per_block",
      "norm_num_groups",
      "act_fn",
      "norm_type"
    ],
    "forward": [
      "self",
      "sample"
    ]
  },
  "_prepare_for_blend": [
    "n_param",
    "h_param",
    "w_param",
    "x"
  ],
  "CACHE_T": [],
  "AvgDown3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "factor_t",
      "factor_s"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DupUp3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "factor_t",
      "factor_s"
    ],
    "forward": [
      "self",
      "x",
      "first_chunk"
    ]
  },
  "WanCausalConv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding"
    ],
    "forward": [
      "self",
      "x",
      "cache_x"
    ]
  },
  "WanRMS_norm": {
    "__init__": [
      "self",
      "dim",
      "channel_first",
      "images",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanUpsample": {
    "forward": [
      "self",
      "x"
    ]
  },
  "WanResample": {
    "__init__": [
      "self",
      "dim",
      "mode",
      "upsample_out_dim"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "WanResidualBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "dropout",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "WanAttentionBlock": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanMidBlock": {
    "__init__": [
      "self",
      "dim",
      "dropout",
      "non_linearity",
      "num_layers"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "WanResidualDownBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "dropout",
      "num_res_blocks",
      "temperal_downsample",
      "down_flag"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "WanEncoder3d": {
    "__init__": [
      "self",
      "in_channels",
      "dim",
      "z_dim",
      "dim_mult",
      "num_res_blocks",
      "attn_scales",
      "temperal_downsample",
      "dropout",
      "non_linearity",
      "is_residual"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "WanResidualUpBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "num_res_blocks",
      "dropout",
      "temperal_upsample",
      "up_flag",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx",
      "first_chunk"
    ]
  },
  "WanUpBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "num_res_blocks",
      "dropout",
      "upsample_mode",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx",
      "first_chunk"
    ]
  },
  "WanDecoder3d": {
    "__init__": [
      "self",
      "dim",
      "z_dim",
      "dim_mult",
      "num_res_blocks",
      "attn_scales",
      "temperal_upsample",
      "dropout",
      "non_linearity",
      "out_channels",
      "is_residual"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx",
      "first_chunk"
    ]
  },
  "patchify": [
    "x",
    "patch_size"
  ],
  "unpatchify": [
    "x",
    "patch_size"
  ],
  "EasyAnimateCausalConv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "padding_mode"
    ],
    "_clear_conv_cache": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EasyAnimateResidualBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "non_linearity",
      "norm_num_groups",
      "norm_eps",
      "spatial_group_norm",
      "dropout",
      "output_scale_factor"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EasyAnimateDownsampler3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EasyAnimateUpsampler3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "temporal_upsample",
      "spatial_group_norm"
    ],
    "_clear_conv_cache": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EasyAnimateDownBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "act_fn",
      "norm_num_groups",
      "norm_eps",
      "spatial_group_norm",
      "dropout",
      "output_scale_factor",
      "add_downsample",
      "add_temporal_downsample"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EasyAnimateUpBlock3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "act_fn",
      "norm_num_groups",
      "norm_eps",
      "spatial_group_norm",
      "dropout",
      "output_scale_factor",
      "add_upsample",
      "add_temporal_upsample"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EasyAnimateMidBlock3d": {
    "__init__": [
      "self",
      "in_channels",
      "num_layers",
      "act_fn",
      "norm_num_groups",
      "norm_eps",
      "spatial_group_norm",
      "dropout",
      "output_scale_factor"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EasyAnimateEncoder": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "down_block_types",
      "block_out_channels",
      "layers_per_block",
      "norm_num_groups",
      "act_fn",
      "double_z",
      "spatial_group_norm"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EasyAnimateDecoder": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "up_block_types",
      "block_out_channels",
      "layers_per_block",
      "norm_num_groups",
      "act_fn",
      "spatial_group_norm"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LTXVideoCausalConv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "groups",
      "padding_mode",
      "is_causal"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LTXVideoResnetBlock3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "eps",
      "elementwise_affine",
      "non_linearity",
      "is_causal",
      "inject_noise",
      "timestep_conditioning"
    ],
    "forward": [
      "self",
      "inputs",
      "temb",
      "generator"
    ]
  },
  "LTXVideoDownsampler3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "is_causal",
      "padding_mode"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LTXVideoUpsampler3d": {
    "__init__": [
      "self",
      "in_channels",
      "stride",
      "is_causal",
      "residual",
      "upscale_factor",
      "padding_mode"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LTXVideoDownBlock3D": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "dropout",
      "resnet_eps",
      "resnet_act_fn",
      "spatio_temporal_scale",
      "is_causal"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "generator"
    ]
  },
  "LTXVideo095DownBlock3D": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "dropout",
      "resnet_eps",
      "resnet_act_fn",
      "spatio_temporal_scale",
      "is_causal",
      "downsample_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "generator"
    ]
  },
  "LTXVideoMidBlock3d": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "in_channels",
      "num_layers",
      "dropout",
      "resnet_eps",
      "resnet_act_fn",
      "is_causal",
      "inject_noise",
      "timestep_conditioning"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "generator"
    ]
  },
  "LTXVideoUpBlock3d": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "dropout",
      "resnet_eps",
      "resnet_act_fn",
      "spatio_temporal_scale",
      "is_causal",
      "inject_noise",
      "timestep_conditioning",
      "upsample_residual",
      "upscale_factor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "generator"
    ]
  },
  "LTXVideoEncoder3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "block_out_channels",
      "down_block_types",
      "spatio_temporal_scaling",
      "layers_per_block",
      "downsample_type",
      "patch_size",
      "patch_size_t",
      "resnet_norm_eps",
      "is_causal"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LTXVideoDecoder3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "block_out_channels",
      "spatio_temporal_scaling",
      "layers_per_block",
      "patch_size",
      "patch_size_t",
      "resnet_norm_eps",
      "is_causal",
      "inject_noise",
      "timestep_conditioning",
      "upsample_residual",
      "upsample_factor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "CogVideoXSafeConv3d": {
    "forward": [
      "self",
      "input"
    ]
  },
  "CogVideoXCausalConv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "pad_mode"
    ],
    "fake_context_parallel_forward": [
      "self",
      "inputs",
      "conv_cache"
    ],
    "forward": [
      "self",
      "inputs",
      "conv_cache"
    ]
  },
  "CogVideoXSpatialNorm3D": {
    "__init__": [
      "self",
      "f_channels",
      "zq_channels",
      "groups"
    ],
    "forward": [
      "self",
      "f",
      "zq",
      "conv_cache"
    ]
  },
  "CogVideoXResnetBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "temb_channels",
      "groups",
      "eps",
      "non_linearity",
      "conv_shortcut",
      "spatial_norm_dim",
      "pad_mode"
    ],
    "forward": [
      "self",
      "inputs",
      "temb",
      "zq",
      "conv_cache"
    ]
  },
  "CogVideoXDownBlock3D": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_groups",
      "add_downsample",
      "downsample_padding",
      "compress_time",
      "pad_mode"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "zq",
      "conv_cache"
    ]
  },
  "CogVideoXMidBlock3D": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "in_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_groups",
      "spatial_norm_dim",
      "pad_mode"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "zq",
      "conv_cache"
    ]
  },
  "CogVideoXUpBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_groups",
      "spatial_norm_dim",
      "add_upsample",
      "upsample_padding",
      "compress_time",
      "pad_mode"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "zq",
      "conv_cache"
    ]
  },
  "CogVideoXEncoder3D": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "down_block_types",
      "block_out_channels",
      "layers_per_block",
      "act_fn",
      "norm_eps",
      "norm_num_groups",
      "dropout",
      "pad_mode",
      "temporal_compression_ratio"
    ],
    "forward": [
      "self",
      "sample",
      "temb",
      "conv_cache"
    ]
  },
  "CogVideoXDecoder3D": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "up_block_types",
      "block_out_channels",
      "layers_per_block",
      "act_fn",
      "norm_eps",
      "norm_num_groups",
      "dropout",
      "pad_mode",
      "temporal_compression_ratio"
    ],
    "forward": [
      "self",
      "sample",
      "temb",
      "conv_cache"
    ]
  },
  "Snake1d": {
    "__init__": [
      "self",
      "hidden_dim",
      "logscale"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "OobleckResidualUnit": {
    "__init__": [
      "self",
      "dimension",
      "dilation"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "OobleckEncoderBlock": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "stride"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "OobleckDecoderBlock": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "stride"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "OobleckDiagonalGaussianDistribution": {
    "__init__": [
      "self",
      "parameters",
      "deterministic"
    ],
    "sample": [
      "self",
      "generator"
    ],
    "kl": [
      "self",
      "other"
    ],
    "mode": [
      "self"
    ]
  },
  "AutoencoderOobleckOutput": {},
  "OobleckDecoderOutput": {},
  "OobleckEncoder": {
    "__init__": [
      "self",
      "encoder_hidden_size",
      "audio_channels",
      "downsampling_ratios",
      "channel_multiples"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "OobleckDecoder": {
    "__init__": [
      "self",
      "channels",
      "input_channels",
      "audio_channels",
      "upsampling_ratios",
      "channel_multiples"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "TemporalDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "block_out_channels",
      "layers_per_block"
    ],
    "forward": [
      "self",
      "sample",
      "image_only_indicator",
      "num_frames"
    ]
  },
  "ConsistencyDecoderVAEOutput": {},
  "QwenImageCausalConv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding"
    ],
    "forward": [
      "self",
      "x",
      "cache_x"
    ]
  },
  "QwenImageRMS_norm": {
    "__init__": [
      "self",
      "dim",
      "channel_first",
      "images",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QwenImageUpsample": {
    "forward": [
      "self",
      "x"
    ]
  },
  "QwenImageResample": {
    "__init__": [
      "self",
      "dim",
      "mode"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "QwenImageResidualBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "dropout",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "QwenImageAttentionBlock": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QwenImageMidBlock": {
    "__init__": [
      "self",
      "dim",
      "dropout",
      "non_linearity",
      "num_layers"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "QwenImageEncoder3d": {
    "__init__": [
      "self",
      "dim",
      "z_dim",
      "dim_mult",
      "num_res_blocks",
      "attn_scales",
      "temperal_downsample",
      "dropout",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "QwenImageUpBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "num_res_blocks",
      "dropout",
      "upsample_mode",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "QwenImageDecoder3d": {
    "__init__": [
      "self",
      "dim",
      "z_dim",
      "dim_mult",
      "num_res_blocks",
      "attn_scales",
      "temperal_upsample",
      "dropout",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "prepare_causal_attention_mask": [
    "num_frames",
    "height_width",
    "dtype",
    "device",
    "batch_size"
  ],
  "HunyuanVideoCausalConv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "pad_mode"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoUpsampleCausal3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "bias",
      "upsample_factor"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoDownsampleCausal3D": {
    "__init__": [
      "self",
      "channels",
      "out_channels",
      "padding",
      "kernel_size",
      "bias",
      "stride"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoResnetBlockCausal3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "groups",
      "eps",
      "non_linearity"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoMidBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_groups",
      "add_attention",
      "attention_head_dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoDownBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_groups",
      "add_downsample",
      "downsample_stride",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoUpBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_groups",
      "add_upsample",
      "upsample_scale_factor"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoEncoder3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "down_block_types",
      "block_out_channels",
      "layers_per_block",
      "norm_num_groups",
      "act_fn",
      "double_z",
      "mid_block_add_attention",
      "temporal_compression_ratio",
      "spatial_compression_ratio"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoDecoder3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "up_block_types",
      "block_out_channels",
      "layers_per_block",
      "norm_num_groups",
      "act_fn",
      "mid_block_add_attention",
      "time_compression_ratio",
      "spatial_compression_ratio"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LATENTS_MEAN": [],
  "LATENTS_STD": [],
  "_WAVELETS": [],
  "CosmosCausalConv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dilation",
      "stride",
      "padding",
      "pad_mode"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CosmosCausalGroupNorm": {
    "__init__": [
      "self",
      "in_channels",
      "num_groups"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CosmosPatchEmbed3d": {
    "__init__": [
      "self",
      "patch_size",
      "patch_method"
    ],
    "_dwt": [
      "self",
      "hidden_states",
      "mode",
      "rescale"
    ],
    "_haar": [
      "self",
      "hidden_states"
    ],
    "_arrange": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CosmosUnpatcher3d": {
    "__init__": [
      "self",
      "patch_size",
      "patch_method"
    ],
    "_idwt": [
      "self",
      "hidden_states",
      "rescale"
    ],
    "_ihaar": [
      "self",
      "hidden_states"
    ],
    "_irearrange": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CosmosConvProjection3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CosmosResnetBlock3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_groups"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CosmosDownsample3d": {
    "__init__": [
      "self",
      "in_channels",
      "spatial_downsample",
      "temporal_downsample"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CosmosUpsample3d": {
    "__init__": [
      "self",
      "in_channels",
      "spatial_upsample",
      "temporal_upsample"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CosmosCausalAttention": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "num_groups",
      "dropout",
      "processor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "CosmosSpatialAttentionProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "attention_mask"
    ]
  },
  "CosmosTemporalAttentionProcessor2_0": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "attention_mask"
    ]
  },
  "CosmosDownBlock3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "dropout",
      "use_attention",
      "use_downsample",
      "spatial_downsample",
      "temporal_downsample"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CosmosMidBlock3d": {
    "__init__": [
      "self",
      "in_channels",
      "num_layers",
      "dropout",
      "num_groups"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CosmosUpBlock3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "dropout",
      "use_attention",
      "use_upsample",
      "spatial_upsample",
      "temporal_upsample"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CosmosEncoder3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "block_out_channels",
      "num_resnet_blocks",
      "attention_resolutions",
      "resolution",
      "patch_size",
      "patch_type",
      "dropout",
      "spatial_compression_ratio",
      "temporal_compression_ratio"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CosmosDecoder3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "block_out_channels",
      "num_resnet_blocks",
      "attention_resolutions",
      "resolution",
      "patch_size",
      "patch_type",
      "dropout",
      "spatial_compression_ratio",
      "temporal_compression_ratio"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AutoencoderTinyOutput": {},
  "HunyuanImageRefinerCausalConv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "pad_mode"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanImageRefinerRMS_norm": {
    "__init__": [
      "self",
      "dim",
      "channel_first",
      "images",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanImageRefinerAttnBlock": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanImageRefinerUpsampleDCAE": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "add_temporal_upsample"
    ],
    "_dcae_upsample_rearrange": [
      "tensor",
      "r1",
      "r2",
      "r3"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanImageRefinerDownsampleDCAE": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "add_temporal_downsample"
    ],
    "_dcae_downsample_rearrange": [
      "tensor",
      "r1",
      "r2",
      "r3"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanImageRefinerResnetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "non_linearity"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanImageRefinerMidBlock": {
    "__init__": [
      "self",
      "in_channels",
      "num_layers",
      "add_attention"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanImageRefinerDownBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "downsample_out_channels",
      "add_temporal_downsample"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanImageRefinerUpBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "upsample_out_channels",
      "add_temporal_upsample"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanImageRefinerEncoder3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "block_out_channels",
      "layers_per_block",
      "temporal_compression_ratio",
      "spatial_compression_ratio",
      "downsample_match_channel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanImageRefinerDecoder3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "block_out_channels",
      "layers_per_block",
      "spatial_compression_ratio",
      "temporal_compression_ratio",
      "upsample_match_channel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanImageResnetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanImageAttentionBlock": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanImageDownsample": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanImageUpsample": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanImageMidBlock": {
    "__init__": [
      "self",
      "in_channels",
      "num_layers"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanImageEncoder2D": {
    "__init__": [
      "self",
      "in_channels",
      "z_channels",
      "block_out_channels",
      "num_res_blocks",
      "spatial_compression_ratio",
      "non_linearity",
      "downsample_match_channel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanImageDecoder2D": {
    "__init__": [
      "self",
      "z_channels",
      "out_channels",
      "block_out_channels",
      "num_res_blocks",
      "spatial_compression_ratio",
      "upsample_match_channel",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanVideo15CausalConv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "pad_mode"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideo15RMS_norm": {
    "__init__": [
      "self",
      "dim",
      "channel_first",
      "images",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanVideo15AttnBlock": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "prepare_causal_attention_mask": [
      "n_frame",
      "n_hw",
      "dtype",
      "device",
      "batch_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanVideo15Upsample": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "add_temporal_upsample"
    ],
    "_dcae_upsample_rearrange": [
      "tensor",
      "r1",
      "r2",
      "r3"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanVideo15Downsample": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "add_temporal_downsample"
    ],
    "_dcae_downsample_rearrange": [
      "tensor",
      "r1",
      "r2",
      "r3"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunyuanVideo15ResnetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "non_linearity"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideo15MidBlock": {
    "__init__": [
      "self",
      "in_channels",
      "num_layers",
      "add_attention"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideo15DownBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "downsample_out_channels",
      "add_temporal_downsample"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideo15UpBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "upsample_out_channels",
      "add_temporal_upsample"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideo15Encoder3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "block_out_channels",
      "layers_per_block",
      "temporal_compression_ratio",
      "spatial_compression_ratio",
      "downsample_match_channel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideo15Decoder3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "block_out_channels",
      "layers_per_block",
      "spatial_compression_ratio",
      "temporal_compression_ratio",
      "upsample_match_channel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MochiChunkedGroupNorm3D": {
    "__init__": [
      "self",
      "num_channels",
      "num_groups",
      "affine",
      "chunk_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MochiResnetBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "act_fn"
    ],
    "forward": [
      "self",
      "inputs",
      "conv_cache"
    ]
  },
  "MochiDownBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "temporal_expansion",
      "spatial_expansion",
      "add_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "conv_cache",
      "chunk_size"
    ]
  },
  "MochiMidBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "num_layers",
      "add_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "conv_cache"
    ]
  },
  "MochiUpBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "temporal_expansion",
      "spatial_expansion"
    ],
    "forward": [
      "self",
      "hidden_states",
      "conv_cache"
    ]
  },
  "FourierFeatures": {
    "__init__": [
      "self",
      "start",
      "stop",
      "step"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "MochiEncoder3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "block_out_channels",
      "layers_per_block",
      "temporal_expansions",
      "spatial_expansions",
      "add_attention_block",
      "act_fn"
    ],
    "forward": [
      "self",
      "hidden_states",
      "conv_cache"
    ]
  },
  "MochiDecoder3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "block_out_channels",
      "layers_per_block",
      "temporal_expansions",
      "spatial_expansions",
      "act_fn"
    ],
    "forward": [
      "self",
      "hidden_states",
      "conv_cache"
    ]
  },
  "EncoderOutput": {},
  "DecoderOutput": {},
  "Encoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "down_block_types",
      "block_out_channels",
      "layers_per_block",
      "norm_num_groups",
      "act_fn",
      "double_z",
      "mid_block_add_attention"
    ],
    "forward": [
      "self",
      "sample"
    ]
  },
  "Decoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "up_block_types",
      "block_out_channels",
      "layers_per_block",
      "norm_num_groups",
      "act_fn",
      "norm_type",
      "mid_block_add_attention"
    ],
    "forward": [
      "self",
      "sample",
      "latent_embeds"
    ]
  },
  "UpSample": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MaskConditionEncoder": {
    "__init__": [
      "self",
      "in_ch",
      "out_ch",
      "res_ch",
      "stride"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "MaskConditionDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "up_block_types",
      "block_out_channels",
      "layers_per_block",
      "norm_num_groups",
      "act_fn",
      "norm_type"
    ],
    "forward": [
      "self",
      "z",
      "image",
      "mask",
      "latent_embeds"
    ]
  },
  "VectorQuantizer": {
    "__init__": [
      "self",
      "n_e",
      "vq_embed_dim",
      "beta",
      "remap",
      "unknown_index",
      "sane_index_shape",
      "legacy"
    ],
    "remap_to_used": [
      "self",
      "inds"
    ],
    "unmap_to_all": [
      "self",
      "inds"
    ],
    "forward": [
      "self",
      "z"
    ],
    "get_codebook_entry": [
      "self",
      "indices",
      "shape"
    ]
  },
  "DiagonalGaussianDistribution": {
    "__init__": [
      "self",
      "parameters",
      "deterministic"
    ],
    "sample": [
      "self",
      "generator"
    ],
    "kl": [
      "self",
      "other"
    ],
    "nll": [
      "self",
      "sample",
      "dims"
    ],
    "mode": [
      "self"
    ]
  },
  "IdentityDistribution": {
    "__init__": [
      "self",
      "parameters"
    ],
    "sample": [
      "self",
      "generator"
    ],
    "mode": [
      "self"
    ]
  },
  "EncoderTiny": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_blocks",
      "block_out_channels",
      "act_fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DecoderTiny": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_blocks",
      "block_out_channels",
      "upsampling_scaling_factor",
      "act_fn",
      "upsample_fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AutoencoderMixin": {
    "enable_tiling": [
      "self"
    ],
    "disable_tiling": [
      "self"
    ],
    "enable_slicing": [
      "self"
    ],
    "disable_slicing": [
      "self"
    ]
  },
  "EfficientViTBlock": {
    "__init__": [
      "self",
      "in_channels",
      "mult",
      "attention_head_dim",
      "qkv_multiscales",
      "norm_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_block": [
    "block_type",
    "in_channels",
    "out_channels",
    "attention_head_dim",
    "norm_type",
    "act_fn",
    "qkv_mutliscales"
  ],
  "DCDownBlock2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "downsample",
      "shortcut"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DCUpBlock2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "interpolate",
      "shortcut",
      "interpolation_mode"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "get_mid_block": [
    "mid_block_type",
    "temb_channels",
    "in_channels",
    "resnet_eps",
    "resnet_act_fn",
    "resnet_groups",
    "output_scale_factor",
    "transformer_layers_per_block",
    "num_attention_heads",
    "cross_attention_dim",
    "dual_cross_attention",
    "use_linear_projection",
    "mid_block_only_cross_attention",
    "upcast_attention",
    "resnet_time_scale_shift",
    "attention_type",
    "resnet_skip_time_act",
    "cross_attention_norm",
    "attention_head_dim",
    "dropout"
  ],
  "AutoencoderTinyBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "act_fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UNetMidBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "attn_groups",
      "resnet_pre_norm",
      "add_attention",
      "attention_head_dim",
      "output_scale_factor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "UNetMidBlock2DSimpleCrossAttn": {
    "__init__": [
      "self",
      "in_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "cross_attention_dim",
      "skip_time_act",
      "only_cross_attention",
      "cross_attention_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask"
    ]
  },
  "AttnDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "downsample_padding",
      "downsample_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "upsample_size",
      "cross_attention_kwargs"
    ]
  },
  "DownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_downsample",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "DownEncoderBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_downsample",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AttnDownEncoderBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "add_downsample",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AttnSkipDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "add_downsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "skip_sample"
    ]
  },
  "SkipDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_downsample",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "skip_sample"
    ]
  },
  "ResnetDownsampleBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_downsample",
      "skip_time_act"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "SimpleCrossAttnDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "cross_attention_dim",
      "output_scale_factor",
      "add_downsample",
      "skip_time_act",
      "only_cross_attention",
      "cross_attention_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask"
    ]
  },
  "KDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_group_size",
      "add_downsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "KCrossAttnDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "cross_attention_dim",
      "dropout",
      "num_layers",
      "resnet_group_size",
      "add_downsample",
      "attention_head_dim",
      "add_self_attention",
      "resnet_eps",
      "resnet_act_fn"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask"
    ]
  },
  "AttnUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "prev_output_channel",
      "out_channels",
      "temb_channels",
      "resolution_idx",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "upsample_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "upsample_size"
    ]
  },
  "UpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "prev_output_channel",
      "out_channels",
      "temb_channels",
      "resolution_idx",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_upsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "upsample_size"
    ]
  },
  "UpDecoderBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "resolution_idx",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_upsample",
      "temb_channels"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "AttnUpDecoderBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "resolution_idx",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "add_upsample",
      "temb_channels"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "AttnSkipUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "prev_output_channel",
      "out_channels",
      "temb_channels",
      "resolution_idx",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "add_upsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "skip_sample"
    ]
  },
  "SkipUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "prev_output_channel",
      "out_channels",
      "temb_channels",
      "resolution_idx",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_upsample",
      "upsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "skip_sample"
    ]
  },
  "ResnetUpsampleBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "prev_output_channel",
      "out_channels",
      "temb_channels",
      "resolution_idx",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_upsample",
      "skip_time_act"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "upsample_size"
    ]
  },
  "SimpleCrossAttnUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "prev_output_channel",
      "temb_channels",
      "resolution_idx",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "cross_attention_dim",
      "output_scale_factor",
      "add_upsample",
      "skip_time_act",
      "only_cross_attention",
      "cross_attention_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "encoder_hidden_states",
      "upsample_size",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask"
    ]
  },
  "KUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "resolution_idx",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_group_size",
      "add_upsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "upsample_size"
    ]
  },
  "KCrossAttnUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "resolution_idx",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_group_size",
      "attention_head_dim",
      "cross_attention_dim",
      "add_upsample",
      "upcast_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "encoder_hidden_states",
      "cross_attention_kwargs",
      "upsample_size",
      "attention_mask",
      "encoder_attention_mask"
    ]
  },
  "KAttentionBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "dropout",
      "cross_attention_dim",
      "attention_bias",
      "upcast_attention",
      "temb_channels",
      "add_self_attention",
      "cross_attention_norm",
      "group_size"
    ],
    "_to_3d": [
      "self",
      "hidden_states",
      "height",
      "weight"
    ],
    "_to_4d": [
      "self",
      "hidden_states",
      "height",
      "weight"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "emb",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask"
    ]
  },
  "UVit2DConvEmbed": {
    "__init__": [
      "self",
      "in_channels",
      "block_out_channels",
      "vocab_size",
      "elementwise_affine",
      "eps",
      "bias"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "UVitBlock": {
    "__init__": [
      "self",
      "channels",
      "num_res_blocks",
      "hidden_size",
      "hidden_dropout",
      "ln_elementwise_affine",
      "layer_norm_eps",
      "use_bias",
      "block_num_heads",
      "attention_dropout",
      "downsample",
      "upsample"
    ],
    "forward": [
      "self",
      "x",
      "pooled_text_emb",
      "encoder_hidden_states",
      "cross_attention_kwargs"
    ]
  },
  "ConvNextBlock": {
    "__init__": [
      "self",
      "channels",
      "layer_norm_eps",
      "ln_elementwise_affine",
      "use_bias",
      "hidden_dropout",
      "hidden_size",
      "res_ffn_factor"
    ],
    "forward": [
      "self",
      "x",
      "cond_embeds"
    ]
  },
  "ConvMlmLayer": {
    "__init__": [
      "self",
      "block_out_channels",
      "in_channels",
      "use_bias",
      "ln_elementwise_affine",
      "layer_norm_eps",
      "codebook_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Kandinsky3UNetOutput": {},
  "Kandinsky3EncoderProj": {
    "__init__": [
      "self",
      "encoder_hid_dim",
      "cross_attention_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Kandinsky3UpSampleBlock": {
    "__init__": [
      "self",
      "in_channels",
      "cat_dim",
      "out_channels",
      "time_embed_dim",
      "context_dim",
      "num_blocks",
      "groups",
      "head_dim",
      "expansion_ratio",
      "compression_ratio",
      "up_sample",
      "self_attention"
    ],
    "forward": [
      "self",
      "x",
      "time_embed",
      "context",
      "context_mask",
      "image_mask"
    ]
  },
  "Kandinsky3DownSampleBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "time_embed_dim",
      "context_dim",
      "num_blocks",
      "groups",
      "head_dim",
      "expansion_ratio",
      "compression_ratio",
      "down_sample",
      "self_attention"
    ],
    "forward": [
      "self",
      "x",
      "time_embed",
      "context",
      "context_mask",
      "image_mask"
    ]
  },
  "Kandinsky3ConditionalGroupNorm": {
    "__init__": [
      "self",
      "groups",
      "normalized_shape",
      "context_dim"
    ],
    "forward": [
      "self",
      "x",
      "context"
    ]
  },
  "Kandinsky3Block": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "time_embed_dim",
      "kernel_size",
      "norm_groups",
      "up_resolution"
    ],
    "forward": [
      "self",
      "x",
      "time_embed"
    ]
  },
  "Kandinsky3ResNetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "time_embed_dim",
      "norm_groups",
      "compression_ratio",
      "up_resolutions"
    ],
    "forward": [
      "self",
      "x",
      "time_embed"
    ]
  },
  "Kandinsky3AttentionPooling": {
    "__init__": [
      "self",
      "num_channels",
      "context_dim",
      "head_dim"
    ],
    "forward": [
      "self",
      "x",
      "context",
      "context_mask"
    ]
  },
  "Kandinsky3AttentionBlock": {
    "__init__": [
      "self",
      "num_channels",
      "time_embed_dim",
      "context_dim",
      "norm_groups",
      "head_dim",
      "expansion_ratio"
    ],
    "forward": [
      "self",
      "x",
      "time_embed",
      "context",
      "context_mask",
      "image_mask"
    ]
  },
  "DownResnetBlock1D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "conv_shortcut",
      "temb_channels",
      "groups",
      "groups_out",
      "non_linearity",
      "time_embedding_norm",
      "output_scale_factor",
      "add_downsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "UpResnetBlock1D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "temb_channels",
      "groups",
      "groups_out",
      "non_linearity",
      "time_embedding_norm",
      "output_scale_factor",
      "add_upsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb"
    ]
  },
  "ValueFunctionMidBlock1D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "embed_dim"
    ],
    "forward": [
      "self",
      "x",
      "temb"
    ]
  },
  "MidResTemporalBlock1D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "embed_dim",
      "num_layers",
      "add_downsample",
      "add_upsample",
      "non_linearity"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "OutConv1DBlock": {
    "__init__": [
      "self",
      "num_groups_out",
      "out_channels",
      "embed_dim",
      "act_fn"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "OutValueFunctionBlock": {
    "__init__": [
      "self",
      "fc_dim",
      "embed_dim",
      "act_fn"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "_kernels": [],
  "Downsample1d": {
    "__init__": [
      "self",
      "kernel",
      "pad_mode"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Upsample1d": {
    "__init__": [
      "self",
      "kernel",
      "pad_mode"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "SelfAttention1d": {
    "__init__": [
      "self",
      "in_channels",
      "n_head",
      "dropout_rate"
    ],
    "transpose_for_scores": [
      "self",
      "projection"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ResConvBlock": {
    "__init__": [
      "self",
      "in_channels",
      "mid_channels",
      "out_channels",
      "is_last"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "UNetMidBlock1D": {
    "__init__": [
      "self",
      "mid_channels",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "AttnDownBlock1D": {
    "__init__": [
      "self",
      "out_channels",
      "in_channels",
      "mid_channels"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "DownBlock1D": {
    "__init__": [
      "self",
      "out_channels",
      "in_channels",
      "mid_channels"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "DownBlock1DNoSkip": {
    "__init__": [
      "self",
      "out_channels",
      "in_channels",
      "mid_channels"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "AttnUpBlock1D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "mid_channels"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb"
    ]
  },
  "UpBlock1D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "mid_channels"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb"
    ]
  },
  "UpBlock1DNoSkip": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "mid_channels"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb"
    ]
  },
  "DownBlockType": [],
  "MidBlockType": [],
  "OutBlockType": [],
  "UpBlockType": [],
  "get_out_block": [],
  "UNet1DOutput": {},
  "DownBlockMotion": {
    "__init__": [
      "self"
    ]
  },
  "CrossAttnDownBlockMotion": {
    "__init__": [
      "self"
    ]
  },
  "UpBlockMotion": {
    "__init__": [
      "self"
    ]
  },
  "CrossAttnUpBlockMotion": {
    "__init__": [
      "self"
    ]
  },
  "UNetMidBlockCrossAttnMotion": {
    "__init__": [
      "self"
    ]
  },
  "UNetMidBlock3DCrossAttn": {
    "__init__": [
      "self",
      "in_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "num_attention_heads",
      "output_scale_factor",
      "cross_attention_dim",
      "dual_cross_attention",
      "use_linear_projection",
      "upcast_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "num_frames",
      "cross_attention_kwargs"
    ]
  },
  "CrossAttnDownBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "num_attention_heads",
      "cross_attention_dim",
      "output_scale_factor",
      "downsample_padding",
      "add_downsample",
      "dual_cross_attention",
      "use_linear_projection",
      "only_cross_attention",
      "upcast_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "num_frames",
      "cross_attention_kwargs"
    ]
  },
  "DownBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_downsample",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "num_frames"
    ]
  },
  "CrossAttnUpBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "prev_output_channel",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "num_attention_heads",
      "cross_attention_dim",
      "output_scale_factor",
      "add_upsample",
      "dual_cross_attention",
      "use_linear_projection",
      "only_cross_attention",
      "upcast_attention",
      "resolution_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "encoder_hidden_states",
      "upsample_size",
      "attention_mask",
      "num_frames",
      "cross_attention_kwargs"
    ]
  },
  "UpBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "prev_output_channel",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_upsample",
      "resolution_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "upsample_size",
      "num_frames"
    ]
  },
  "MidBlockTemporalDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "attention_head_dim",
      "num_layers",
      "upcast_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "image_only_indicator"
    ]
  },
  "UpBlockTemporalDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "add_upsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "image_only_indicator"
    ]
  },
  "UNetMidBlockSpatioTemporal": {
    "__init__": [
      "self",
      "in_channels",
      "temb_channels",
      "num_layers",
      "transformer_layers_per_block",
      "num_attention_heads",
      "cross_attention_dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "image_only_indicator"
    ]
  },
  "DownBlockSpatioTemporal": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "num_layers",
      "add_downsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "image_only_indicator"
    ]
  },
  "CrossAttnDownBlockSpatioTemporal": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "num_layers",
      "transformer_layers_per_block",
      "num_attention_heads",
      "cross_attention_dim",
      "add_downsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "image_only_indicator"
    ]
  },
  "UpBlockSpatioTemporal": {
    "__init__": [
      "self",
      "in_channels",
      "prev_output_channel",
      "out_channels",
      "temb_channels",
      "resolution_idx",
      "num_layers",
      "resnet_eps",
      "add_upsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "image_only_indicator",
      "upsample_size"
    ]
  },
  "CrossAttnUpBlockSpatioTemporal": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "prev_output_channel",
      "temb_channels",
      "resolution_idx",
      "num_layers",
      "transformer_layers_per_block",
      "resnet_eps",
      "num_attention_heads",
      "cross_attention_dim",
      "add_upsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "encoder_hidden_states",
      "image_only_indicator",
      "upsample_size"
    ]
  },
  "I2VGenXLTransformerTemporalEncoder": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "activation_fn",
      "upcast_attention",
      "ff_inner_dim",
      "dropout"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "UNet2DOutput": {},
  "FlaxUNet2DConditionOutput": {},
  "UNet3DConditionOutput": {},
  "UNet2DConditionOutput": {},
  "UNetSpatioTemporalConditionOutput": {},
  "SDCascadeLayerNorm": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SDCascadeTimestepBlock": {
    "__init__": [
      "self",
      "c",
      "c_timestep",
      "conds"
    ],
    "forward": [
      "self",
      "x",
      "t"
    ]
  },
  "SDCascadeResBlock": {
    "__init__": [
      "self",
      "c",
      "c_skip",
      "kernel_size",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "x_skip"
    ]
  },
  "SDCascadeAttnBlock": {
    "__init__": [
      "self",
      "c",
      "c_cond",
      "nhead",
      "self_attn",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "kv"
    ]
  },
  "UpDownBlock2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "mode",
      "enabled"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StableCascadeUNetOutput": {},
  "StableCascadeUNet": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "timestep_ratio_embedding_dim",
      "patch_size",
      "conditioning_dim",
      "block_out_channels",
      "num_attention_heads",
      "down_num_layers_per_block",
      "up_num_layers_per_block",
      "down_blocks_repeat_mappers",
      "up_blocks_repeat_mappers",
      "block_types_per_layer",
      "clip_text_in_channels",
      "clip_text_pooled_in_channels",
      "clip_image_in_channels",
      "clip_seq",
      "effnet_in_channels",
      "pixel_mapper_in_channels",
      "kernel_size",
      "dropout",
      "self_attn",
      "timestep_conditioning_type",
      "switch_level"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "get_timestep_ratio_embedding": [
      "self",
      "timestep_ratio",
      "max_positions"
    ],
    "get_clip_embeddings": [
      "self",
      "clip_txt_pooled",
      "clip_txt",
      "clip_img"
    ],
    "_down_encode": [
      "self",
      "x",
      "r_embed",
      "clip"
    ],
    "_up_decode": [
      "self",
      "level_outputs",
      "r_embed",
      "clip"
    ],
    "forward": [
      "self",
      "sample",
      "timestep_ratio",
      "clip_text_pooled",
      "clip_text",
      "clip_img",
      "effnet",
      "pixels",
      "sca",
      "crp",
      "return_dict"
    ]
  },
  "UNetMotionOutput": {},
  "AnimateDiffTransformer3D": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "in_channels",
      "out_channels",
      "num_layers",
      "dropout",
      "norm_num_groups",
      "cross_attention_dim",
      "attention_bias",
      "sample_size",
      "activation_fn",
      "norm_elementwise_affine",
      "double_self_attention",
      "positional_embeddings",
      "num_positional_embeddings"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "timestep",
      "class_labels",
      "num_frames",
      "cross_attention_kwargs"
    ]
  },
  "MotionModules": {
    "__init__": [
      "self",
      "in_channels",
      "layers_per_block",
      "transformer_layers_per_block",
      "num_attention_heads",
      "attention_bias",
      "cross_attention_dim",
      "activation_fn",
      "norm_num_groups",
      "max_seq_length"
    ]
  },
  "FlaxCrossAttnDownBlock2D": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "deterministic"
    ]
  },
  "FlaxDownBlock2D": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "temb",
      "deterministic"
    ]
  },
  "FlaxCrossAttnUpBlock2D": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "encoder_hidden_states",
      "deterministic"
    ]
  },
  "FlaxUpBlock2D": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "deterministic"
    ]
  },
  "FlaxUNetMidBlock2DCrossAttn": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "deterministic"
    ]
  },
  "MultiControlNetUnionModel": {
    "__init__": [
      "self",
      "controlnets"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "encoder_hidden_states",
      "controlnet_cond",
      "control_type",
      "control_type_idx",
      "conditioning_scale",
      "class_labels",
      "timestep_cond",
      "attention_mask",
      "added_cond_kwargs",
      "cross_attention_kwargs",
      "guess_mode",
      "return_dict"
    ],
    "save_pretrained": [
      "self",
      "save_directory",
      "is_main_process",
      "save_function",
      "safe_serialization",
      "variant"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_path"
    ]
  },
  "QwenImageControlNetOutput": {},
  "ControlNetXSOutput": {},
  "DownBlockControlNetXSAdapter": {
    "__init__": [
      "self",
      "resnets",
      "base_to_ctrl",
      "ctrl_to_base",
      "attentions",
      "downsampler"
    ]
  },
  "MidBlockControlNetXSAdapter": {
    "__init__": [
      "self",
      "midblock",
      "base_to_ctrl",
      "ctrl_to_base"
    ]
  },
  "UpBlockControlNetXSAdapter": {
    "__init__": [
      "self",
      "ctrl_to_base"
    ]
  },
  "get_down_block_adapter": [
    "base_in_channels",
    "base_out_channels",
    "ctrl_in_channels",
    "ctrl_out_channels",
    "temb_channels",
    "max_norm_num_groups",
    "has_crossattn",
    "transformer_layers_per_block",
    "num_attention_heads",
    "cross_attention_dim",
    "add_downsample",
    "upcast_attention",
    "use_linear_projection"
  ],
  "get_mid_block_adapter": [
    "base_channels",
    "ctrl_channels",
    "temb_channels",
    "max_norm_num_groups",
    "transformer_layers_per_block",
    "num_attention_heads",
    "cross_attention_dim",
    "upcast_attention",
    "use_linear_projection"
  ],
  "get_up_block_adapter": [
    "out_channels",
    "prev_output_channel",
    "ctrl_skip_channels"
  ],
  "ControlNetXSCrossAttnDownBlock2D": {
    "__init__": [
      "self",
      "base_in_channels",
      "base_out_channels",
      "ctrl_in_channels",
      "ctrl_out_channels",
      "temb_channels",
      "norm_num_groups",
      "ctrl_max_norm_num_groups",
      "has_crossattn",
      "transformer_layers_per_block",
      "base_num_attention_heads",
      "ctrl_num_attention_heads",
      "cross_attention_dim",
      "add_downsample",
      "upcast_attention",
      "use_linear_projection"
    ],
    "from_modules": [
      "cls",
      "base_downblock",
      "ctrl_downblock"
    ],
    "freeze_base_params": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states_base",
      "temb",
      "encoder_hidden_states",
      "hidden_states_ctrl",
      "conditioning_scale",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask",
      "apply_control"
    ]
  },
  "ControlNetXSCrossAttnMidBlock2D": {
    "__init__": [
      "self",
      "base_channels",
      "ctrl_channels",
      "temb_channels",
      "norm_num_groups",
      "ctrl_max_norm_num_groups",
      "transformer_layers_per_block",
      "base_num_attention_heads",
      "ctrl_num_attention_heads",
      "cross_attention_dim",
      "upcast_attention",
      "use_linear_projection"
    ],
    "from_modules": [
      "cls",
      "base_midblock",
      "ctrl_midblock"
    ],
    "freeze_base_params": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states_base",
      "temb",
      "encoder_hidden_states",
      "hidden_states_ctrl",
      "conditioning_scale",
      "cross_attention_kwargs",
      "attention_mask",
      "encoder_attention_mask",
      "apply_control"
    ]
  },
  "ControlNetXSCrossAttnUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "prev_output_channel",
      "ctrl_skip_channels",
      "temb_channels",
      "norm_num_groups",
      "resolution_idx",
      "has_crossattn",
      "transformer_layers_per_block",
      "num_attention_heads",
      "cross_attention_dim",
      "add_upsample",
      "upcast_attention",
      "use_linear_projection"
    ],
    "from_modules": [
      "cls",
      "base_upblock",
      "ctrl_upblock"
    ],
    "freeze_base_params": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple_base",
      "res_hidden_states_tuple_ctrl",
      "temb",
      "encoder_hidden_states",
      "conditioning_scale",
      "cross_attention_kwargs",
      "attention_mask",
      "upsample_size",
      "encoder_attention_mask",
      "apply_control"
    ]
  },
  "make_zero_conv": [
    "in_channels",
    "out_channels"
  ],
  "zero_module": [
    "module"
  ],
  "find_largest_factor": [
    "number",
    "max_factor"
  ],
  "FlaxControlNetOutput": {},
  "FlaxControlNetConditioningEmbedding": {
    "setup": [
      "self"
    ],
    "__call__": [
      "self",
      "conditioning"
    ]
  },
  "SanaControlNetOutput": {},
  "HunyuanControlNetOutput": {},
  "QuickGELU": {
    "forward": [
      "self",
      "input"
    ]
  },
  "ResidualAttentionMlp": {
    "__init__": [
      "self",
      "d_model"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResidualAttentionBlock": {
    "__init__": [
      "self",
      "d_model",
      "n_head",
      "attn_mask"
    ],
    "attention": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GUIDER_CONFIG_NAME": [],
  "GuiderOutput": {},
  "MomentumBuffer": {
    "__init__": [
      "self",
      "momentum"
    ],
    "update": [
      "self",
      "update_value"
    ],
    "__repr__": [
      "self"
    ]
  },
  "update_momentum_buffer": [
    "pred_cond",
    "pred_uncond",
    "momentum_buffer"
  ],
  "normalized_guidance": [
    "pred_cond",
    "pred_uncond",
    "guidance_scale",
    "momentum_buffer",
    "eta",
    "norm_threshold",
    "use_original_formulation"
  ],
  "cfg_zero_star_scale": [
    "cond",
    "uncond",
    "eps"
  ],
  "_CAN_USE_KORNIA": [],
  "project": [
    "v0",
    "v1",
    "upcast_to_double"
  ],
  "build_image_from_pyramid": [
    "pyramid"
  ]
}