{
  "BasicAuth": {
    "__init__": [
      "self",
      "username",
      "password"
    ],
    "__call__": [
      "self",
      "request"
    ]
  },
  "InferenceServerClientBase": {
    "__init__": [
      "self"
    ],
    "_call_plugin": [
      "self",
      "request"
    ],
    "register_plugin": [
      "self",
      "plugin"
    ],
    "plugin": [
      "self"
    ],
    "unregister_plugin": [
      "self"
    ]
  },
  "Request": {
    "__init__": [
      "self",
      "headers"
    ]
  },
  "InferenceServerClientPlugin": {
    "__call__": [
      "self",
      "request"
    ]
  },
  "SharedMemoryTensor": {
    "__init__": [
      "self",
      "dtype",
      "shape",
      "shm_addr",
      "offset",
      "byte_size",
      "device_id"
    ],
    "__dlpack__": [
      "self",
      "stream"
    ],
    "__dlpack_device__": [
      "self"
    ]
  },
  "c_str_dltensor": [],
  "DLDeviceType": {
    "kDLCPU": [],
    "kDLCUDA": [],
    "kDLCUDAHost": [],
    "kDLOpenCL": [],
    "kDLVulkan": [],
    "kDLMetal": [],
    "kDLVPI": [],
    "kDLROCM": [],
    "kDLROCMHost": [],
    "kDLExtDev": [],
    "kDLCUDAManaged": [],
    "kDLOneAPI": [],
    "kDLWebGPU": [],
    "kDLHexagon": []
  },
  "DLDevice": {
    "_fields_": []
  },
  "DLDataTypeCode": {
    "kDLInt": [],
    "kDLUInt": [],
    "kDLFloat": [],
    "kDLOpaquePointer": [],
    "kDLBfloat": [],
    "kDLComplex": [],
    "kDLBool": []
  },
  "DLDataType": {
    "_fields_": []
  },
  "DLTensor": {
    "_fields_": []
  },
  "DLManagedTensor": {
    "_fields_": []
  },
  "_raise_error": [
    "msg"
  ],
  "DataViewContext": {
    "__init__": [
      "self",
      "shape"
    ],
    "as_manager_ctx": [
      "self"
    ]
  },
  "managed_tensor_deleter": [
    "handle"
  ],
  "pycapsule_deleter": [
    "handle"
  ],
  "triton_to_dlpack_dtype": [
    "dtype"
  ],
  "is_contiguous_data": [
    "ndim",
    "shape",
    "stride"
  ],
  "get_byte_size": [
    "dtype",
    "ndim",
    "shape"
  ],
  "get_dlpack_capsule": [
    "dlpack_obj",
    "stream"
  ],
  "get_dlpack_device": [
    "dlpack_obj"
  ],
  "get_managed_tensor": [
    "dlcapsule"
  ],
  "raise_error": [
    "msg"
  ],
  "serialized_byte_size": [
    "tensor_value"
  ],
  "InferenceServerException": {
    "__init__": [
      "self",
      "msg",
      "status",
      "debug_details"
    ],
    "__str__": [
      "self"
    ],
    "message": [
      "self"
    ],
    "status": [
      "self"
    ],
    "debug_details": [
      "self"
    ]
  },
  "np_to_triton_dtype": [
    "np_dtype"
  ],
  "triton_to_np_dtype": [
    "dtype"
  ],
  "serialize_byte_tensor": [
    "input_tensor"
  ],
  "deserialize_bytes_tensor": [
    "encoded_tensor"
  ],
  "serialize_bf16_tensor": [
    "input_tensor"
  ],
  "deserialize_bf16_tensor": [
    "encoded_tensor"
  ],
  "_key_mapping": [],
  "SharedMemoryRegion": {
    "__init__": [
      "self",
      "triton_shm_name",
      "shm_key"
    ]
  },
  "create_shared_memory_region": [
    "triton_shm_name",
    "shm_key",
    "byte_size",
    "create_only"
  ],
  "set_shared_memory_region": [
    "shm_handle",
    "input_values",
    "offset"
  ],
  "get_contents_as_numpy": [
    "shm_handle",
    "datatype",
    "shape",
    "offset"
  ],
  "mapped_shared_memory_regions": [],
  "destroy_shared_memory_region": [
    "shm_handle"
  ],
  "SharedMemoryException": {},
  "call_cuda_function": [
    "function"
  ],
  "CudaSharedMemoryException": {
    "__init__": [
      "self",
      "msg"
    ],
    "__str__": [
      "self"
    ]
  },
  "CudaSharedMemoryRegion": {
    "__init__": [
      "self",
      "triton_shm_name",
      "cuda_shm_handle",
      "base_addr",
      "byte_size",
      "device_id"
    ],
    "__del__": [
      "self"
    ]
  },
  "CudaStream": {
    "__init__": [
      "self",
      "device_id"
    ],
    "__del__": [
      "self"
    ]
  },
  "maybe_set_device": [
    "device_id"
  ],
  "allocated_shm_regions": [],
  "_dlpack_stream": [],
  "_get_or_create_global_cuda_stream": [
    "device_id"
  ],
  "_support_uva": [
    "shm_device_id",
    "ext_device_id"
  ],
  "_is_device_supported": [
    "device"
  ],
  "get_raw_handle": [
    "cuda_shm_handle"
  ],
  "set_shared_memory_region_from_dlpack": [
    "cuda_shm_handle",
    "input_values"
  ],
  "as_shared_memory_tensor": [
    "cuda_shm_handle",
    "datatype",
    "shape"
  ],
  "allocated_shared_memory_regions": [],
  "get_error_grpc": [
    "rpc_error"
  ],
  "get_cancelled_error": [
    "msg"
  ],
  "raise_error_grpc": [
    "rpc_error"
  ],
  "_get_inference_request": [
    "model_name",
    "inputs",
    "model_version",
    "request_id",
    "outputs",
    "sequence_id",
    "sequence_start",
    "sequence_end",
    "priority",
    "timeout",
    "parameters"
  ],
  "_grpc_compression_type": [
    "algorithm_str"
  ],
  "_sym_db": [],
  "DESCRIPTOR": [],
  "INT32_MAX": [],
  "MAX_GRPC_MESSAGE_SIZE": [],
  "KeepAliveOptions": {
    "__init__": [
      "self",
      "keepalive_time_ms",
      "keepalive_timeout_ms",
      "keepalive_permit_without_calls",
      "http2_max_pings_without_data"
    ]
  },
  "CallContext": {
    "__init__": [
      "self",
      "grpc_future"
    ],
    "cancel": [
      "self"
    ]
  },
  "InferenceServerClient": {
    "__init__": [
      "self",
      "url",
      "verbose",
      "ssl",
      "root_certificates",
      "private_key",
      "certificate_chain",
      "creds",
      "keepalive_options",
      "channel_args"
    ],
    "_get_metadata": [
      "self",
      "headers"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "type",
      "value",
      "traceback"
    ],
    "__del__": [
      "self"
    ],
    "close": [
      "self"
    ],
    "is_server_live": [
      "self",
      "headers",
      "client_timeout"
    ],
    "is_server_ready": [
      "self",
      "headers",
      "client_timeout"
    ],
    "is_model_ready": [
      "self",
      "model_name",
      "model_version",
      "headers",
      "client_timeout"
    ],
    "get_server_metadata": [
      "self",
      "headers",
      "as_json",
      "client_timeout"
    ],
    "get_model_metadata": [
      "self",
      "model_name",
      "model_version",
      "headers",
      "as_json",
      "client_timeout"
    ],
    "get_model_config": [
      "self",
      "model_name",
      "model_version",
      "headers",
      "as_json",
      "client_timeout"
    ],
    "get_model_repository_index": [
      "self",
      "headers",
      "as_json",
      "client_timeout"
    ],
    "load_model": [
      "self",
      "model_name",
      "headers",
      "config",
      "files",
      "client_timeout"
    ],
    "unload_model": [
      "self",
      "model_name",
      "headers",
      "unload_dependents",
      "client_timeout"
    ],
    "get_inference_statistics": [
      "self",
      "model_name",
      "model_version",
      "headers",
      "as_json",
      "client_timeout"
    ],
    "update_trace_settings": [
      "self",
      "model_name",
      "settings",
      "headers",
      "as_json",
      "client_timeout"
    ],
    "get_trace_settings": [
      "self",
      "model_name",
      "headers",
      "as_json",
      "client_timeout"
    ],
    "update_log_settings": [
      "self",
      "settings",
      "headers",
      "as_json",
      "client_timeout"
    ],
    "get_log_settings": [
      "self",
      "headers",
      "as_json",
      "client_timeout"
    ],
    "get_system_shared_memory_status": [
      "self",
      "region_name",
      "headers",
      "as_json",
      "client_timeout"
    ],
    "register_system_shared_memory": [
      "self",
      "name",
      "key",
      "byte_size",
      "offset",
      "headers",
      "client_timeout"
    ],
    "unregister_system_shared_memory": [
      "self",
      "name",
      "headers",
      "client_timeout"
    ],
    "get_cuda_shared_memory_status": [
      "self",
      "region_name",
      "headers",
      "as_json",
      "client_timeout"
    ],
    "register_cuda_shared_memory": [
      "self",
      "name",
      "raw_handle",
      "device_id",
      "byte_size",
      "headers",
      "client_timeout"
    ],
    "unregister_cuda_shared_memory": [
      "self",
      "name",
      "headers",
      "client_timeout"
    ],
    "infer": [
      "self",
      "model_name",
      "inputs",
      "model_version",
      "outputs",
      "request_id",
      "sequence_id",
      "sequence_start",
      "sequence_end",
      "priority",
      "timeout",
      "client_timeout",
      "headers",
      "compression_algorithm",
      "parameters"
    ],
    "async_infer": [
      "self",
      "model_name",
      "inputs",
      "callback",
      "model_version",
      "outputs",
      "request_id",
      "sequence_id",
      "sequence_start",
      "sequence_end",
      "priority",
      "timeout",
      "client_timeout",
      "headers",
      "compression_algorithm",
      "parameters"
    ],
    "start_stream": [
      "self",
      "callback",
      "stream_timeout",
      "headers",
      "compression_algorithm"
    ],
    "stop_stream": [
      "self",
      "cancel_requests"
    ],
    "async_stream_infer": [
      "self",
      "model_name",
      "inputs",
      "model_version",
      "outputs",
      "request_id",
      "sequence_id",
      "sequence_start",
      "sequence_end",
      "enable_empty_final_response",
      "priority",
      "timeout",
      "parameters"
    ]
  },
  "__all__": [],
  "InferInput": {
    "__init__": [
      "self",
      "name",
      "shape",
      "datatype"
    ],
    "name": [
      "self"
    ],
    "datatype": [
      "self"
    ],
    "shape": [
      "self"
    ],
    "set_shape": [
      "self",
      "shape"
    ],
    "set_data_from_numpy": [
      "self",
      "input_tensor"
    ],
    "set_shared_memory": [
      "self",
      "region_name",
      "byte_size",
      "offset"
    ],
    "_get_tensor": [
      "self"
    ],
    "_get_content": [
      "self"
    ]
  },
  "InferResult": {
    "__init__": [
      "self",
      "result"
    ],
    "as_numpy": [
      "self",
      "name"
    ],
    "get_output": [
      "self",
      "name",
      "as_json"
    ],
    "get_response": [
      "self",
      "as_json"
    ]
  },
  "InferRequestedOutput": {
    "__init__": [
      "self",
      "name",
      "class_count"
    ],
    "name": [
      "self"
    ],
    "set_shared_memory": [
      "self",
      "region_name",
      "byte_size",
      "offset"
    ],
    "unset_shared_memory": [
      "self"
    ],
    "_get_tensor": [
      "self"
    ]
  },
  "_InferStream": {
    "__init__": [
      "self",
      "callback",
      "verbose"
    ],
    "__del__": [
      "self"
    ],
    "close": [
      "self",
      "cancel_requests"
    ],
    "_init_handler": [
      "self",
      "response_iterator"
    ],
    "_enqueue_request": [
      "self",
      "request"
    ],
    "_get_request": [
      "self"
    ],
    "_process_response": [
      "self"
    ]
  },
  "_RequestIterator": {
    "__init__": [
      "self",
      "stream"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ]
  },
  "GRPC_GENERATED_VERSION": [],
  "GRPC_VERSION": [],
  "_version_not_supported": [],
  "GRPCInferenceServiceStub": {
    "__init__": [
      "self",
      "channel"
    ]
  },
  "GRPCInferenceServiceServicer": {
    "ServerLive": [
      "self",
      "request",
      "context"
    ],
    "ServerReady": [
      "self",
      "request",
      "context"
    ],
    "ModelReady": [
      "self",
      "request",
      "context"
    ],
    "ServerMetadata": [
      "self",
      "request",
      "context"
    ],
    "ModelMetadata": [
      "self",
      "request",
      "context"
    ],
    "ModelInfer": [
      "self",
      "request",
      "context"
    ],
    "ModelStreamInfer": [
      "self",
      "request_iterator",
      "context"
    ],
    "ModelConfig": [
      "self",
      "request",
      "context"
    ],
    "ModelStatistics": [
      "self",
      "request",
      "context"
    ],
    "RepositoryIndex": [
      "self",
      "request",
      "context"
    ],
    "RepositoryModelLoad": [
      "self",
      "request",
      "context"
    ],
    "RepositoryModelUnload": [
      "self",
      "request",
      "context"
    ],
    "SystemSharedMemoryStatus": [
      "self",
      "request",
      "context"
    ],
    "SystemSharedMemoryRegister": [
      "self",
      "request",
      "context"
    ],
    "SystemSharedMemoryUnregister": [
      "self",
      "request",
      "context"
    ],
    "CudaSharedMemoryStatus": [
      "self",
      "request",
      "context"
    ],
    "CudaSharedMemoryRegister": [
      "self",
      "request",
      "context"
    ],
    "CudaSharedMemoryUnregister": [
      "self",
      "request",
      "context"
    ],
    "TraceSetting": [
      "self",
      "request",
      "context"
    ],
    "LogSettings": [
      "self",
      "request",
      "context"
    ]
  },
  "add_GRPCInferenceServiceServicer_to_server": [
    "servicer",
    "server"
  ],
  "GRPCInferenceService": {
    "ServerLive": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "ServerReady": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "ModelReady": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "ServerMetadata": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "ModelMetadata": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "ModelInfer": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "ModelStreamInfer": [
      "request_iterator",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "ModelConfig": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "ModelStatistics": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "RepositoryIndex": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "RepositoryModelLoad": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "RepositoryModelUnload": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "SystemSharedMemoryStatus": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "SystemSharedMemoryRegister": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "SystemSharedMemoryUnregister": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "CudaSharedMemoryStatus": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "CudaSharedMemoryRegister": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "CudaSharedMemoryUnregister": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "TraceSetting": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "LogSettings": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ]
  },
  "_get_error": [
    "response"
  ],
  "_raise_if_error": [
    "response"
  ],
  "_get_query_string": [
    "query_params"
  ],
  "InferAsyncRequest": {
    "__init__": [
      "self",
      "greenlet",
      "verbose"
    ],
    "get_result": [
      "self",
      "block",
      "timeout"
    ]
  }
}