{
  "RegisterTables": {
    "model_classes": [],
    "frontend_classes": [],
    "specaug_classes": [],
    "normalize_classes": [],
    "encoder_classes": [],
    "decoder_classes": [],
    "joint_network_classes": [],
    "predictor_classes": [],
    "stride_conv_classes": [],
    "tokenizer_classes": [],
    "dataloader_classes": [],
    "batch_sampler_classes": [],
    "dataset_classes": [],
    "index_ds_classes": [],
    "print": [
      "self",
      "key"
    ],
    "register": [
      "self",
      "register_tables_key",
      "key"
    ]
  },
  "tables": [],
  "dirname": [],
  "version_file": [],
  "import_submodules": [
    "package",
    "recursive"
  ],
  "LabelSmoothingLoss": {
    "__init__": [
      "self",
      "size",
      "padding_idx",
      "smoothing",
      "normalize_length",
      "criterion"
    ],
    "forward": [
      "self",
      "x",
      "target"
    ]
  },
  "SequenceBinaryCrossEntropy": {
    "__init__": [
      "self",
      "normalize_length",
      "criterion"
    ],
    "forward": [
      "self",
      "pred",
      "label",
      "lengths"
    ]
  },
  "NllLoss": {
    "__init__": [
      "self",
      "size",
      "padding_idx",
      "normalize_length",
      "criterion"
    ],
    "forward": [
      "self",
      "x",
      "target"
    ]
  },
  "end_detect": [
    "ended_hyps",
    "i",
    "M",
    "D_end"
  ],
  "label_smoothing_dist": [
    "odim",
    "lsm_type",
    "transcript",
    "blank"
  ],
  "get_vgg2l_odim": [
    "idim",
    "in_channel",
    "out_channel"
  ],
  "ErrorCalculator": {
    "__init__": [
      "self",
      "char_list",
      "sym_space",
      "sym_blank",
      "report_cer",
      "report_wer"
    ],
    "__call__": [
      "self",
      "ys_hat",
      "ys_pad",
      "is_ctc"
    ],
    "calculate_cer_ctc": [
      "self",
      "ys_hat",
      "ys_pad"
    ],
    "convert_to_char": [
      "self",
      "ys_hat",
      "ys_pad"
    ],
    "calculate_cer": [
      "self",
      "seqs_hat",
      "seqs_true"
    ],
    "calculate_wer": [
      "self",
      "seqs_hat",
      "seqs_true"
    ]
  },
  "th_accuracy": [
    "pad_outputs",
    "pad_targets",
    "ignore_label"
  ],
  "compute_accuracy": [
    "pad_outputs",
    "pad_targets",
    "ignore_label"
  ],
  "GetArgs": [],
  "CheckArgs": [
    "args"
  ],
  "ComputeErrorRates": [
    "scores",
    "labels"
  ],
  "ComputeMinDcf": [
    "fnrs",
    "fprs",
    "thresholds",
    "p_target",
    "c_miss",
    "c_fa"
  ],
  "compute_min_dcf": [
    "scores_filename",
    "trials_filename",
    "c_miss",
    "c_fa",
    "p_target"
  ],
  "main": [],
  "_compute_eer": [
    "label",
    "pred",
    "positive_label"
  ],
  "compute_eer": [
    "trials_path",
    "scores_path"
  ],
  "compute_wer": [
    "ref_file",
    "hyp_file",
    "cer_file",
    "cn_postprocess"
  ],
  "compute_wer_by_line": [
    "hyp",
    "ref"
  ],
  "print_cer_detail": [
    "rst"
  ],
  "main_hydra": [
    "cfg"
  ],
  "name_maps_ms": [],
  "name_maps_hf": [],
  "name_maps_openai": [],
  "download_model": [],
  "download_from_ms": [],
  "download_from_hf": [],
  "add_file_root_path": [
    "model_or_path",
    "file_path_metas",
    "cfg"
  ],
  "get_or_download_model_dir": [
    "model",
    "model_revision",
    "is_training",
    "check_latest"
  ],
  "get_or_download_model_dir_hf": [
    "model",
    "model_revision",
    "is_training",
    "check_latest"
  ],
  "download_from_url": [
    "url"
  ],
  "Storage": {
    "read": [
      "self",
      "filepath"
    ],
    "read_text": [
      "self",
      "filepath"
    ],
    "write": [
      "self",
      "obj",
      "filepath"
    ],
    "write_text": [
      "self",
      "obj",
      "filepath",
      "encoding"
    ]
  },
  "LocalStorage": {
    "read": [
      "self",
      "filepath"
    ],
    "read_text": [
      "self",
      "filepath",
      "encoding"
    ],
    "write": [
      "self",
      "obj",
      "filepath"
    ],
    "write_text": [
      "self",
      "obj",
      "filepath",
      "encoding"
    ],
    "as_local_path": [
      "self",
      "filepath"
    ]
  },
  "HTTPStorage": {
    "read": [
      "self",
      "url"
    ],
    "read_text": [
      "self",
      "url"
    ],
    "as_local_path": [
      "self",
      "filepath"
    ],
    "write": [
      "self",
      "obj",
      "url"
    ],
    "write_text": [
      "self",
      "obj",
      "url",
      "encoding"
    ]
  },
  "OSSStorage": {
    "__init__": [
      "self",
      "oss_config_file"
    ],
    "read": [
      "self",
      "filepath"
    ],
    "read_text": [
      "self",
      "filepath",
      "encoding"
    ],
    "as_local_path": [
      "self",
      "filepath"
    ],
    "write": [
      "self",
      "obj",
      "filepath"
    ],
    "write_text": [
      "self",
      "obj",
      "filepath",
      "encoding"
    ]
  },
  "G_STORAGES": [],
  "File": {
    "_get_storage": [
      "uri"
    ],
    "read": [
      "uri"
    ],
    "read_text": [
      "uri",
      "encoding"
    ],
    "write": [
      "obj",
      "uri"
    ],
    "write_text": [
      "obj",
      "uri",
      "encoding"
    ],
    "as_local_path": [
      "uri"
    ]
  },
  "download_dataset": [],
  "download_dataset_from_ms": [],
  "DataloaderMapStyle": {
    "__init__": [
      "self",
      "frontend",
      "tokenizer"
    ],
    "build_iter": [
      "self",
      "epoch",
      "data_split_i",
      "start_step"
    ]
  },
  "DataloaderIterable": [
    "frontend",
    "tokenizer"
  ],
  "TextPreprocessRemovePunctuation": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "text"
    ]
  },
  "AudioLLMNARDataset": {
    "__init__": [
      "self",
      "path",
      "index_ds",
      "frontend",
      "tokenizer",
      "int_pad_value",
      "float_pad_value"
    ],
    "get_source_len": [
      "self",
      "index"
    ],
    "get_target_len": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collator": [
      "self",
      "samples"
    ]
  },
  "AudioLLMDataset": {
    "__init__": [
      "self",
      "path",
      "index_ds",
      "frontend",
      "tokenizer",
      "int_pad_value",
      "float_pad_value"
    ],
    "get_source_len": [
      "self",
      "index"
    ],
    "get_target_len": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collator": [
      "self",
      "samples"
    ]
  },
  "AudioLLMARDataset": {
    "__init__": [
      "self",
      "path",
      "index_ds",
      "frontend",
      "tokenizer",
      "int_pad_value",
      "float_pad_value"
    ],
    "get_source_len": [
      "self",
      "index"
    ],
    "get_target_len": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collator": [
      "self",
      "samples"
    ]
  },
  "IndexDSJsonlRankFull": {
    "__init__": [
      "self",
      "path"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "get_source_len": [
      "self",
      "data_dict"
    ],
    "get_target_len": [
      "self",
      "data_dict"
    ]
  },
  "EspnetStyleBatchSampler_fn": [
    "dataset"
  ],
  "EspnetStyleBatchSampler": {
    "__init__": [
      "self",
      "dataset",
      "batch_size",
      "batch_type",
      "rank",
      "num_replicas",
      "rank_split",
      "shuffle",
      "drop_last",
      "is_training",
      "sort_size",
      "start_step"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "gen_jsonl_from_wav_text_list": [
    "path",
    "data_type_list",
    "jsonl_file_out",
    "model_dir"
  ],
  "contains_punctuation": [
    "s"
  ],
  "parse_context_length": [
    "data_list",
    "data_type",
    "id"
  ],
  "SpeechPreprocessSpeedPerturb": {
    "__init__": [
      "self",
      "speed_perturb"
    ],
    "forward": [
      "self",
      "waveform",
      "fs"
    ]
  },
  "TextPreprocessSegDict": {
    "__init__": [
      "self",
      "seg_dict",
      "text_cleaner",
      "split_with_space"
    ],
    "forward": [
      "self",
      "text"
    ]
  },
  "AudioDataset": {
    "__init__": [
      "self",
      "path",
      "index_ds",
      "frontend",
      "tokenizer",
      "is_training",
      "int_pad_value",
      "float_pad_value"
    ],
    "get_source_len": [
      "self",
      "index"
    ],
    "get_target_len": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collator": [
      "self",
      "samples"
    ]
  },
  "AudioDatasetHotword": {
    "__init__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collator": [
      "self",
      "samples"
    ]
  },
  "gen_scp_from_jsonl": [
    "jsonl_file",
    "jsonl_file_out",
    "ncpu"
  ],
  "update_data": [
    "lines",
    "i"
  ],
  "update_wav_len": [
    "jsonl_file_list_in",
    "jsonl_file_out_dir",
    "ncpu"
  ],
  "CustomDistributedBatchSampler_fn": [
    "dataset"
  ],
  "CustomDistributedBatchSampler": {
    "__init__": [
      "self",
      "dataset",
      "batch_size",
      "num_replicas",
      "rank",
      "shuffle",
      "drop_last",
      "is_training"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "CustomDistributedBufferBatchSampler": {
    "__init__": [
      "self",
      "dataset",
      "batch_size",
      "num_replicas",
      "rank",
      "shuffle",
      "drop_last",
      "is_training",
      "sort_size"
    ],
    "__iter__": [
      "self"
    ],
    "_create_batches_from_buffer": [
      "self",
      "buffer"
    ],
    "__len__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "CustomDistributedDynamicBatchSampler": {
    "__init__": [
      "self",
      "dataset",
      "batch_size",
      "num_replicas",
      "rank",
      "shuffle",
      "drop_last",
      "is_training"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "CustomDistributedBufferDynamicBatchSampler": {
    "__init__": [
      "self",
      "dataset",
      "batch_size",
      "batch_type",
      "num_replicas",
      "rank",
      "rank_split",
      "shuffle",
      "drop_last",
      "is_training",
      "sort_size",
      "start_step"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "DistributedSamplerWarp": {
    "__init__": [
      "self",
      "dataset",
      "batch_size",
      "num_replicas",
      "rank",
      "shuffle",
      "drop_last"
    ],
    "__iter__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "SenseVoiceDataset": {
    "__init__": [
      "self",
      "path",
      "index_ds",
      "frontend",
      "tokenizer",
      "int_pad_value",
      "float_pad_value"
    ],
    "get_source_len": [
      "self",
      "index"
    ],
    "get_target_len": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collator": [
      "self",
      "samples"
    ],
    "_filter_badcase": [
      "self",
      "outputs",
      "i"
    ]
  },
  "SenseVoiceCTCDataset": {
    "__init__": [
      "self",
      "path",
      "index_ds",
      "frontend",
      "tokenizer",
      "int_pad_value",
      "float_pad_value"
    ],
    "get_source_len": [
      "self",
      "index"
    ],
    "get_target_len": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collator": [
      "self",
      "samples"
    ],
    "_filter_badcase": [
      "self",
      "outputs",
      "i"
    ]
  },
  "OpenAIIndexDSJsonl": {
    "__init__": [
      "self",
      "path"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "get_source_len": [
      "self",
      "data_dict"
    ],
    "get_target_len": [
      "self",
      "data_dict"
    ]
  },
  "OpenAIDataset": {
    "__init__": [
      "self",
      "path",
      "index_ds",
      "frontend",
      "tokenizer",
      "int_pad_value",
      "float_pad_value"
    ],
    "get_source_len": [
      "self",
      "index"
    ],
    "get_target_len": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collator": [
      "self",
      "samples"
    ]
  },
  "OpenAIDatasetMultiTurn": {
    "__init__": [
      "self",
      "path",
      "index_ds",
      "frontend",
      "tokenizer",
      "int_pad_value",
      "float_pad_value"
    ],
    "get_source_len": [
      "self",
      "index"
    ],
    "get_target_len": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collator": [
      "self",
      "samples"
    ]
  },
  "AudioLLMQwenAudioDataset": {
    "__init__": [
      "self",
      "path",
      "index_ds",
      "frontend",
      "tokenizer",
      "int_pad_value",
      "float_pad_value"
    ],
    "get_source_len": [
      "self",
      "index"
    ],
    "get_target_len": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collator": [
      "self",
      "samples"
    ]
  },
  "FunASR": {
    "__init__": [
      "self",
      "path"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "get_source_len": [
      "self",
      "data_dict"
    ],
    "get_target_len": [
      "self",
      "data_dict"
    ]
  },
  "MultiContextPrompt": {
    "CONTEXT_TEMPLATES": [],
    "__init__": [
      "self",
      "use_hist",
      "use_one_pass_result",
      "use_hotwords",
      "use_asr_hotwords",
      "use_multi_lingual_prompt"
    ],
    "get_hotwords_list": [
      "self",
      "hotwords_file"
    ],
    "detect_language": [
      "self",
      "text"
    ],
    "hotwords_sampling": [
      "self",
      "hotwords"
    ],
    "get_prompt": [
      "self",
      "item",
      "language"
    ],
    "get_inference_prompt": [
      "self",
      "item",
      "language"
    ]
  },
  "MultiContextPromptNew": {
    "CONTEXT_TEMPLATES": [],
    "__init__": [
      "self",
      "use_hist",
      "use_one_pass_result",
      "use_hotwords",
      "use_multi_lingual_prompt"
    ],
    "hotwords_sampling": [
      "self",
      "hotwords"
    ],
    "get_prompt": [
      "self",
      "item",
      "language"
    ],
    "get_inference_prompt": [
      "self",
      "hist_context",
      "one_pass_result",
      "hotwords"
    ]
  },
  "KwsMTDataset": {
    "__init__": [
      "self",
      "path",
      "index_ds",
      "frontend",
      "tokenizer",
      "is_training",
      "int_pad_value",
      "float_pad_value"
    ],
    "get_source_len": [
      "self",
      "index"
    ],
    "get_target_len": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collator": [
      "self",
      "samples"
    ]
  },
  "AudioLLMVicunaDataset": {
    "__init__": [
      "self",
      "path",
      "index_ds",
      "frontend",
      "tokenizer",
      "int_pad_value",
      "float_pad_value"
    ],
    "get_source_len": [
      "self",
      "index"
    ],
    "get_target_len": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collator": [
      "self",
      "samples"
    ]
  },
  "maybe_autocast": [
    "dtype",
    "use_deepspeed"
  ],
  "Trainer": {
    "__init__": [
      "self",
      "rank",
      "local_rank",
      "world_size",
      "use_ddp",
      "use_fsdp",
      "use_fp16",
      "use_bf16",
      "use_deepspeed",
      "output_dir"
    ],
    "save_checkpoint": [
      "self",
      "epoch",
      "step",
      "model",
      "optim",
      "scheduler",
      "scaler",
      "step_in_epoch"
    ],
    "resume_checkpoint": [
      "self",
      "model",
      "optim",
      "scheduler",
      "scaler"
    ],
    "train_epoch": [
      "self",
      "model",
      "optim",
      "scheduler",
      "scaler",
      "dataloader_train",
      "dataloader_val",
      "epoch"
    ],
    "forward_step": [
      "self",
      "model",
      "batch",
      "loss_dict"
    ],
    "backward_step": [
      "self",
      "model",
      "scaler",
      "loss_dict"
    ],
    "update_step": [
      "self",
      "model",
      "optim",
      "scheduler",
      "scaler",
      "loss_dict"
    ],
    "validate_epoch": [
      "self",
      "model",
      "dataloader_val",
      "epoch",
      "writer"
    ],
    "log": [
      "self",
      "loss_dict",
      "tag"
    ],
    "close": [
      "self",
      "writer"
    ],
    "warp_model": [
      "self",
      "model"
    ],
    "warp_optim_scheduler": [
      "self",
      "model"
    ]
  },
  "to_device": [
    "data",
    "device",
    "dtype",
    "non_blocking",
    "copy"
  ],
  "force_gatherable": [
    "data",
    "device"
  ],
  "add_gradient_noise": [
    "model",
    "iteration",
    "duration",
    "eta",
    "scale_factor"
  ],
  "get_human_readable_count": [
    "number"
  ],
  "to_bytes": [
    "dtype"
  ],
  "model_summary": [
    "model"
  ],
  "initialize": [
    "model",
    "init"
  ],
  "ForwardAdaptor": {
    "__init__": [
      "self",
      "module",
      "name"
    ],
    "forward": [
      "self"
    ]
  },
  "recursive_sum": [
    "obj",
    "weight",
    "distributed"
  ],
  "recursive_divide": [
    "a",
    "b"
  ],
  "recursive_average": [
    "obj",
    "weight",
    "distributed"
  ],
  "set_all_random_seed": [
    "seed"
  ],
  "load_pretrained_model": [
    "path",
    "model",
    "ignore_init_mismatch",
    "map_location",
    "oss_bucket",
    "scope_map",
    "excludes"
  ],
  "_get_checkpoint_paths": [
    "output_dir",
    "last_n",
    "use_deepspeed"
  ],
  "average_checkpoints": [
    "output_dir",
    "last_n"
  ],
  "AbsScheduler": {
    "step": [
      "self",
      "epoch"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state"
    ]
  },
  "AbsBatchStepScheduler": {
    "step": [
      "self",
      "epoch"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state"
    ]
  },
  "AbsEpochStepScheduler": {
    "step": [
      "self",
      "epoch"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state"
    ]
  },
  "AbsValEpochStepScheduler": {
    "step": [
      "self",
      "val",
      "epoch"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state"
    ]
  },
  "TriStageLR": {
    "__init__": [
      "self",
      "optimizer",
      "last_epoch",
      "phase_ratio",
      "init_lr_scale",
      "final_lr_scale"
    ],
    "init_tri_stage_scheudler": [
      "self",
      "max_update"
    ],
    "_decide_stage": [
      "self",
      "update_step"
    ],
    "step_update": [
      "self",
      "num_updates"
    ],
    "set_optimizer_lr": [
      "self",
      "lr"
    ],
    "get_lr": [
      "self"
    ]
  },
  "NoamLR": {
    "__init__": [
      "self",
      "optimizer",
      "model_size",
      "warmup_steps",
      "last_epoch"
    ],
    "lr_for_WarmupLR": [
      "self",
      "lr"
    ],
    "__repr__": [
      "self"
    ],
    "get_lr": [
      "self"
    ]
  },
  "scheduler_classes": [],
  "CustomLambdaLR": {
    "__init__": [
      "self",
      "optimizer",
      "warmup_steps",
      "total_steps",
      "last_epoch",
      "verbose"
    ],
    "get_lr": [
      "self"
    ]
  },
  "WarmupLR": {
    "__init__": [
      "self",
      "optimizer",
      "warmup_steps",
      "last_epoch"
    ],
    "__repr__": [
      "self"
    ],
    "get_lr": [
      "self"
    ]
  },
  "str2bool": [
    "value"
  ],
  "remove_parenthesis": [
    "value"
  ],
  "remove_quotes": [
    "value"
  ],
  "int_or_none": [
    "value"
  ],
  "float_or_none": [
    "value"
  ],
  "humanfriendly_parse_size_or_none": [
    "value"
  ],
  "str_or_int": [
    "value"
  ],
  "str_or_none": [
    "value"
  ],
  "str2pair_str": [
    "value"
  ],
  "str2triple_str": [
    "value"
  ],
  "thread_wrapper": {
    "__init__": [
      "self",
      "func",
      "args"
    ],
    "run": [
      "self"
    ],
    "get_result": [
      "self"
    ]
  },
  "space_mixed_label": [
    "input_str"
  ],
  "read_lists": [
    "list_file"
  ],
  "make_pair": [
    "wav_lists",
    "trans_lists"
  ],
  "count_duration": [
    "tid",
    "data_lists"
  ],
  "load_data_and_score": [
    "keywords_list",
    "data_file",
    "trans_file",
    "score_file"
  ],
  "export": [
    "model",
    "data_in",
    "quantize",
    "opset_version",
    "type"
  ],
  "_onnx": [
    "model",
    "data_in",
    "quantize",
    "opset_version",
    "export_dir"
  ],
  "_torchscripts": [
    "model",
    "path",
    "device"
  ],
  "_bladedisc_opt": [
    "model",
    "model_inputs",
    "enable_fp16"
  ],
  "_rescale_input_hook": [
    "m",
    "x",
    "scale"
  ],
  "_rescale_output_hook": [
    "m",
    "x",
    "y",
    "scale"
  ],
  "_rescale_encoder_model": [
    "model",
    "input_data"
  ],
  "_bladedisc_opt_for_encdec": [
    "model",
    "path",
    "enable_fp16"
  ],
  "_onnx_opt_for_encdec": [
    "model",
    "path",
    "enable_fp16"
  ],
  "cif_wo_hidden": [
    "alphas",
    "threshold"
  ],
  "ts_prediction_lfr6_standard": [
    "us_alphas",
    "us_peaks",
    "char_list",
    "vad_offset",
    "force_time_shift",
    "sil_in_str",
    "upsample_rate"
  ],
  "timestamp_sentence": [
    "punc_id_list",
    "timestamp_postprocessed",
    "text_postprocessed",
    "return_raw_text"
  ],
  "timestamp_sentence_en": [
    "punc_id_list",
    "timestamp_postprocessed",
    "text_postprocessed",
    "return_raw_text"
  ],
  "load_module_from_path": [
    "file_path"
  ],
  "import_module_from_path": [
    "file_path"
  ],
  "is_ffmpeg_installed": [],
  "use_ffmpeg": [],
  "load_audio_text_image_video": [
    "data_or_path_or_list",
    "fs",
    "audio_fs",
    "data_type",
    "tokenizer"
  ],
  "load_bytes": [
    "input"
  ],
  "validate_frame_rate": [
    "input",
    "fs"
  ],
  "extract_fbank": [
    "data",
    "data_len",
    "data_type",
    "frontend"
  ],
  "_load_audio_ffmpeg": [
    "file",
    "sr"
  ],
  "symbol_str": [],
  "split_mixed_label": [
    "input_str"
  ],
  "query_token_set": [
    "txt",
    "symbol_table",
    "lexicon_table"
  ],
  "KwsCtcPrefixDecoder": {
    "__init__": [
      "self",
      "ctc",
      "keywords",
      "token_list",
      "seg_dict"
    ],
    "beam_search": [
      "self",
      "logits",
      "logits_lengths",
      "keywords_tokenset",
      "score_beam_size",
      "path_beam_size"
    ],
    "is_sublist": [
      "self",
      "main_list",
      "check_list"
    ],
    "_decode_inside": [
      "self",
      "logits",
      "logits_lengths"
    ],
    "decode": [
      "self",
      "x"
    ]
  },
  "slice_padding_fbank": [
    "speech",
    "speech_lengths",
    "vad_segments"
  ],
  "slice_padding_audio_samples": [
    "speech",
    "speech_lengths",
    "vad_segments"
  ],
  "merge_vad": [
    "vad_result",
    "max_length",
    "min_length"
  ],
  "DatadirWriter": {
    "__init__": [
      "self",
      "p"
    ],
    "__enter__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "close": [
      "self"
    ]
  },
  "isChinese": [
    "ch"
  ],
  "isAllChinese": [
    "word"
  ],
  "isAllAlpha": [
    "word"
  ],
  "abbr_dispose": [
    "words",
    "time_stamp"
  ],
  "sentence_postprocess": [
    "words",
    "time_stamp"
  ],
  "sentence_postprocess_sentencepiece": [
    "words"
  ],
  "emo_dict": [],
  "event_dict": [],
  "lang_dict": [],
  "emoji_dict": [],
  "emo_set": [],
  "event_set": [],
  "format_str_v2": [
    "s"
  ],
  "rich_transcription_postprocess": [
    "s"
  ],
  "check_audio_list": [
    "audio"
  ],
  "sv_preprocess": [
    "inputs"
  ],
  "sv_chunk": [
    "vad_segments",
    "fs"
  ],
  "extract_feature": [
    "audio"
  ],
  "postprocess": [
    "segments",
    "vad_segments",
    "labels",
    "embeddings"
  ],
  "correct_labels": [
    "labels"
  ],
  "merge_seque": [
    "distribute_res"
  ],
  "smooth": [
    "res",
    "mindur"
  ],
  "distribute_spk": [
    "sentence_list",
    "sd_time_list"
  ],
  "statistic_model_parameters": [
    "model",
    "prefix"
  ],
  "int2vec": [
    "x",
    "vec_dim",
    "dtype"
  ],
  "seq2arr": [
    "seq",
    "vec_dim"
  ],
  "load_scp_as_dict": [
    "scp_path",
    "value_type",
    "kv_sep"
  ],
  "load_scp_as_list": [
    "scp_path",
    "value_type",
    "kv_sep"
  ],
  "deep_update": [
    "original",
    "update"
  ],
  "prepare_model_dir": [],
  "extract_filename_without_extension": [
    "file_path"
  ],
  "smart_remove": [
    "path"
  ],
  "MakePadMask": {
    "__init__": [
      "self",
      "max_seq_len",
      "flip"
    ],
    "forward": [
      "self",
      "lengths",
      "xs",
      "length_dim",
      "maxlen"
    ]
  },
  "sequence_mask": {
    "__init__": [
      "self",
      "max_seq_len",
      "flip"
    ],
    "forward": [
      "self",
      "lengths",
      "max_seq_len",
      "dtype",
      "device"
    ]
  },
  "normalize": [
    "input",
    "p",
    "dim",
    "out"
  ],
  "subsequent_mask": [
    "size"
  ],
  "MakePadMask_test": [],
  "install_requirements": [
    "requirements_path"
  ],
  "pip_install_r": [
    "requirements_path"
  ],
  "get_pypi_version": [
    "package_name"
  ],
  "check_for_update": [
    "disable"
  ],
  "SGD": {
    "__init__": [
      "self",
      "params",
      "lr",
      "momentum",
      "dampening",
      "weight_decay",
      "nesterov"
    ]
  },
  "FairseqAdam": {
    "__init__": [
      "self",
      "params",
      "lr",
      "adam_betas",
      "adam_eps",
      "weight_decay",
      "amsgrad"
    ],
    "supports_memory_efficient_fp16": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ],
    "step": [
      "self",
      "closure"
    ],
    "set_lr": [
      "self",
      "lr"
    ]
  },
  "optim_classes": [],
  "_resolve_ncpu": [
    "config",
    "fallback"
  ],
  "prepare_data_iterator": [
    "data_in",
    "input_len",
    "data_type",
    "key"
  ],
  "AutoModel": {
    "__init__": [
      "self"
    ],
    "build_model": [],
    "__call__": [
      "self"
    ],
    "generate": [
      "self",
      "input",
      "input_len",
      "progress_callback"
    ],
    "inference": [
      "self",
      "input",
      "input_len",
      "model",
      "kwargs",
      "key",
      "progress_callback"
    ],
    "inference_with_vad": [
      "self",
      "input",
      "input_len"
    ],
    "export": [
      "self",
      "input"
    ],
    "_store_base_configs": [
      "self"
    ],
    "_reset_runtime_configs": [
      "self"
    ]
  },
  "AutoTokenizer": {
    "__init__": [
      "self"
    ]
  },
  "AutoFrontend": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "input",
      "input_len",
      "kwargs"
    ]
  },
  "transform": [
    "Y",
    "dtype"
  ],
  "subsample": [
    "Y",
    "T",
    "subsampling"
  ],
  "splice": [
    "Y",
    "context_size"
  ],
  "stft": [
    "data",
    "frame_size",
    "frame_shift"
  ],
  "base_s3prl_setup": [
    "args"
  ],
  "S3prlFrontend": {
    "__init__": [
      "self",
      "fs",
      "frontend_conf",
      "download_dir",
      "multilayer_feature"
    ],
    "_get_upstream": [
      "self",
      "frontend_conf"
    ],
    "_tile_representations": [
      "self",
      "feature"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_lengths"
    ],
    "reload_pretrained_parameters": [
      "self"
    ]
  },
  "DefaultFrontend": {
    "__init__": [
      "self",
      "fs",
      "n_fft",
      "win_length",
      "hop_length",
      "window",
      "center",
      "normalized",
      "onesided",
      "n_mels",
      "fmin",
      "fmax",
      "htk",
      "frontend_conf",
      "apply_stft",
      "use_channel"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_lengths"
    ],
    "_compute_stft": [
      "self",
      "input",
      "input_lengths"
    ]
  },
  "MultiChannelFrontend": {
    "__init__": [
      "self",
      "fs",
      "n_fft",
      "win_length",
      "hop_length",
      "frame_length",
      "frame_shift",
      "window",
      "center",
      "normalized",
      "onesided",
      "n_mels",
      "fmin",
      "fmax",
      "htk",
      "frontend_conf",
      "apply_stft",
      "use_channel",
      "lfr_m",
      "lfr_n",
      "cmvn_file",
      "mc"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_lengths"
    ],
    "_compute_stft": [
      "self",
      "input",
      "input_lengths"
    ],
    "_load_cmvn": [
      "self",
      "cmvn_file"
    ]
  },
  "WhisperFrontend": {
    "__init__": [
      "self",
      "fs",
      "whisper_model",
      "do_pad_trim",
      "n_mels",
      "permute"
    ],
    "output_size": [
      "self"
    ],
    "log_mel_spectrogram": [
      "self",
      "audio",
      "ilens"
    ],
    "forward": [
      "self",
      "input",
      "input_lengths"
    ]
  },
  "FusedFrontends": {
    "__init__": [
      "self",
      "frontends",
      "align_method",
      "proj_dim",
      "fs"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_lengths"
    ]
  },
  "load_cmvn": [
    "cmvn_file"
  ],
  "apply_cmvn": [
    "inputs",
    "cmvn"
  ],
  "apply_lfr": [
    "inputs",
    "lfr_m",
    "lfr_n"
  ],
  "WavFrontend": {
    "__init__": [
      "self",
      "cmvn_file",
      "fs",
      "window",
      "n_mels",
      "frame_length",
      "frame_shift",
      "filter_length_min",
      "filter_length_max",
      "lfr_m",
      "lfr_n",
      "dither",
      "snip_edges",
      "upsacle_samples"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_lengths"
    ],
    "forward_fbank": [
      "self",
      "input",
      "input_lengths"
    ],
    "forward_lfr_cmvn": [
      "self",
      "input",
      "input_lengths"
    ]
  },
  "WavFrontendOnline": {
    "__init__": [
      "self",
      "cmvn_file",
      "fs",
      "window",
      "n_mels",
      "frame_length",
      "frame_shift",
      "filter_length_min",
      "filter_length_max",
      "lfr_m",
      "lfr_n",
      "dither",
      "snip_edges",
      "upsacle_samples"
    ],
    "output_size": [
      "self"
    ],
    "apply_cmvn": [
      "inputs",
      "cmvn"
    ],
    "apply_lfr": [
      "inputs",
      "lfr_m",
      "lfr_n",
      "is_final"
    ],
    "compute_frame_num": [
      "sample_length",
      "frame_sample_length",
      "frame_shift_sample_length"
    ],
    "forward_fbank": [
      "self",
      "input",
      "input_lengths",
      "cache"
    ],
    "forward_lfr_cmvn": [
      "self",
      "input",
      "input_lengths",
      "is_final",
      "cache"
    ],
    "forward": [
      "self",
      "input",
      "input_lengths"
    ],
    "init_cache": [
      "self",
      "cache"
    ]
  },
  "WavFrontendMel23": {
    "__init__": [
      "self",
      "fs",
      "frame_length",
      "frame_shift",
      "lfr_m",
      "lfr_n"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_lengths"
    ]
  },
  "SlidingWindow": {
    "__init__": [
      "self",
      "win_length",
      "hop_length",
      "channels",
      "padding",
      "fs"
    ],
    "forward": [
      "self",
      "input",
      "input_lengths"
    ],
    "output_size": [
      "self"
    ]
  },
  "MaskEstimator": {
    "__init__": [
      "self",
      "type",
      "idim",
      "layers",
      "units",
      "projs",
      "dropout",
      "nmask"
    ],
    "forward": [
      "self",
      "xs",
      "ilens"
    ]
  },
  "FeatureTransform": {
    "__init__": [
      "self",
      "fs",
      "n_fft",
      "n_mels",
      "fmin",
      "fmax",
      "stats_file",
      "apply_uttmvn",
      "uttmvn_norm_means",
      "uttmvn_norm_vars"
    ],
    "forward": [
      "self",
      "x",
      "ilens"
    ]
  },
  "LogMel": {
    "__init__": [
      "self",
      "fs",
      "n_fft",
      "n_mels",
      "fmin",
      "fmax",
      "htk",
      "norm"
    ],
    "extra_repr": [
      "self"
    ],
    "forward": [
      "self",
      "feat",
      "ilens"
    ]
  },
  "GlobalMVN": {
    "__init__": [
      "self",
      "stats_file",
      "norm_means",
      "norm_vars",
      "eps"
    ],
    "extra_repr": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "ilens"
    ]
  },
  "UtteranceMVN": {
    "__init__": [
      "self",
      "norm_means",
      "norm_vars",
      "eps"
    ],
    "extra_repr": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "ilens"
    ]
  },
  "utterance_mvn": [
    "x",
    "ilens",
    "norm_means",
    "norm_vars",
    "eps"
  ],
  "feature_transform_for": [
    "args",
    "n_fft"
  ],
  "Frontend": {
    "__init__": [
      "self",
      "idim",
      "use_wpe",
      "wtype",
      "wlayers",
      "wunits",
      "wprojs",
      "wdropout_rate",
      "taps",
      "delay",
      "use_dnn_mask_for_wpe",
      "use_beamformer",
      "btype",
      "blayers",
      "bunits",
      "bprojs",
      "bnmask",
      "badim",
      "ref_channel",
      "bdropout_rate"
    ],
    "forward": [
      "self",
      "x",
      "ilens"
    ]
  },
  "frontend_for": [
    "args",
    "idim"
  ],
  "EPS": [],
  "is_torch_1_8_plus": [],
  "is_torch_1_9_plus": [],
  "new_complex_like": [
    "ref",
    "real_imag"
  ],
  "is_torch_complex_tensor": [
    "c"
  ],
  "is_complex": [
    "c"
  ],
  "to_double": [
    "c"
  ],
  "to_float": [
    "c"
  ],
  "cat": [
    "seq"
  ],
  "complex_norm": [
    "c",
    "dim",
    "keepdim"
  ],
  "einsum": [
    "equation"
  ],
  "inverse": [
    "c"
  ],
  "matmul": [
    "a",
    "b"
  ],
  "trace": [
    "a"
  ],
  "reverse": [
    "a",
    "dim"
  ],
  "solve": [
    "b",
    "a"
  ],
  "stack": [
    "seq"
  ],
  "DNN_Beamformer": {
    "__init__": [
      "self",
      "bidim",
      "btype",
      "blayers",
      "bunits",
      "bprojs",
      "bnmask",
      "dropout_rate",
      "badim",
      "ref_channel",
      "beamformer_type"
    ],
    "forward": [
      "self",
      "data",
      "ilens"
    ]
  },
  "AttentionReference": {
    "__init__": [
      "self",
      "bidim",
      "att_dim"
    ],
    "forward": [
      "self",
      "psd_in",
      "ilens",
      "scaling"
    ]
  },
  "get_power_spectral_density_matrix": [
    "xs",
    "mask",
    "normalization",
    "eps"
  ],
  "get_mvdr_vector": [
    "psd_s",
    "psd_n",
    "reference_vector",
    "eps"
  ],
  "apply_beamforming_vector": [
    "beamform_vector",
    "mix"
  ],
  "DNN_WPE": {
    "__init__": [
      "self",
      "wtype",
      "widim",
      "wlayers",
      "wunits",
      "wprojs",
      "dropout_rate",
      "taps",
      "delay",
      "use_dnn_mask",
      "iterations",
      "normalization"
    ],
    "forward": [
      "self",
      "data",
      "ilens"
    ]
  },
  "is_torch_1_7_plus": [],
  "Stft": {
    "__init__": [
      "self",
      "n_fft",
      "win_length",
      "hop_length",
      "window",
      "center",
      "normalized",
      "onesided"
    ],
    "extra_repr": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "ilens"
    ],
    "inverse": [
      "self",
      "input",
      "ilens"
    ]
  },
  "field2slice": [
    "field"
  ],
  "tokenize": [
    "input",
    "output",
    "field",
    "delimiter",
    "token_type",
    "space_symbol",
    "non_linguistic_symbols",
    "bpemodel",
    "log_level",
    "write_vocabulary",
    "vocabulary_size",
    "remove_non_linguistic_symbols",
    "cutoff",
    "add_symbol",
    "cleaner",
    "g2p"
  ],
  "get_parser": [],
  "TokenIDConverter": {
    "__init__": [
      "self",
      "token_list",
      "unk_symbol"
    ],
    "get_num_vocabulary_size": [
      "self"
    ],
    "ids2tokens": [
      "self",
      "integers"
    ],
    "tokens2ids": [
      "self",
      "tokens"
    ]
  },
  "AbsTokenizer": {
    "text2tokens": [
      "self",
      "line"
    ],
    "tokens2text": [
      "self",
      "tokens"
    ]
  },
  "BaseTokenizer": {
    "__init__": [
      "self",
      "token_list",
      "unk_symbol"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "text_ints"
    ],
    "get_num_vocabulary_size": [
      "self"
    ],
    "ids2tokens": [
      "self",
      "integers"
    ],
    "tokens2ids": [
      "self",
      "tokens"
    ],
    "text2tokens": [
      "self",
      "line"
    ],
    "tokens2text": [
      "self",
      "tokens"
    ]
  },
  "WhisperTokenizer": [],
  "SenseVoiceTokenizer": [],
  "build_tokenizer": [
    "token_type",
    "bpemodel",
    "non_linguistic_symbols",
    "remove_non_linguistic_symbols",
    "space_symbol",
    "delimiter",
    "g2p_type"
  ],
  "CharTokenizer": {
    "__init__": [
      "self",
      "non_linguistic_symbols",
      "space_symbol",
      "remove_non_linguistic_symbols",
      "split_with_space",
      "seg_dict"
    ],
    "__repr__": [
      "self"
    ],
    "text2tokens": [
      "self",
      "line"
    ],
    "tokens2text": [
      "self",
      "tokens"
    ]
  },
  "load_seg_dict": [
    "seg_dict_file"
  ],
  "seg_tokenize": [
    "txt",
    "seg_dict"
  ],
  "g2p_classes": [],
  "split_by_space": [
    "text"
  ],
  "pyopenjtalk_g2p": [
    "text"
  ],
  "pyopenjtalk_g2p_accent": [
    "text"
  ],
  "pyopenjtalk_g2p_accent_with_pause": [
    "text"
  ],
  "pyopenjtalk_g2p_kana": [
    "text"
  ],
  "pyopenjtalk_g2p_prosody": [
    "text",
    "drop_unvoiced_vowels"
  ],
  "_numeric_feature_by_regex": [
    "regex",
    "s"
  ],
  "pypinyin_g2p": [
    "text"
  ],
  "pypinyin_g2p_phone": [
    "text"
  ],
  "G2p_en": {
    "__init__": [
      "self",
      "no_space"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "G2pk": {
    "__init__": [
      "self",
      "descritive",
      "group_vowels",
      "to_syl",
      "no_space"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "Jaso": {
    "PUNC": [],
    "SPACE": [],
    "JAMO_LEADS": [],
    "JAMO_VOWELS": [],
    "JAMO_TAILS": [],
    "VALID_CHARS": [],
    "__init__": [
      "self",
      "space_symbol",
      "no_space"
    ],
    "_text_to_jaso": [
      "self",
      "line"
    ],
    "_remove_non_korean_characters": [
      "self",
      "tokens"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "Phonemizer": {
    "__init__": [
      "self",
      "backend",
      "word_separator",
      "syllable_separator",
      "phone_separator",
      "strip",
      "split_by_single_token"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "PhonemeTokenizer": {
    "__init__": [
      "self",
      "g2p_type",
      "non_linguistic_symbols",
      "space_symbol",
      "remove_non_linguistic_symbols"
    ],
    "__repr__": [
      "self"
    ],
    "text2tokens": [
      "self",
      "line"
    ],
    "tokens2text": [
      "self",
      "tokens"
    ]
  },
  "TextCleaner": {
    "__init__": [
      "self",
      "cleaner_types"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "WordTokenizer": {
    "__init__": [
      "self",
      "delimiter",
      "non_linguistic_symbols",
      "remove_non_linguistic_symbols"
    ],
    "__repr__": [
      "self"
    ],
    "text2tokens": [
      "self",
      "line"
    ],
    "tokens2text": [
      "self",
      "tokens"
    ]
  },
  "HuggingfaceTokenizer": [
    "init_param_path"
  ],
  "KoreanCleaner": {
    "_normalize_numbers": [
      "cls",
      "text"
    ],
    "_normalize_english_text": [
      "cls",
      "text"
    ],
    "normalize_text": [
      "cls",
      "text"
    ]
  },
  "SentencepiecesTokenizer": {
    "__init__": [
      "self",
      "bpemodel"
    ],
    "__repr__": [
      "self"
    ],
    "_build_sentence_piece_processor": [
      "self"
    ],
    "text2tokens": [
      "self",
      "line"
    ],
    "tokens2text": [
      "self",
      "tokens"
    ],
    "encode": [
      "self",
      "line"
    ],
    "decode": [
      "self",
      "line"
    ],
    "get_vocab_size": [
      "self"
    ],
    "ids2tokens": [
      "self"
    ],
    "tokens2ids": [
      "self"
    ]
  },
  "FsmnKWS": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "ctc",
      "ctc_conf",
      "ctc_weight",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "_calc_ctc_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "FsmnKWSConvert": {
    "__init__": [
      "self",
      "encoder",
      "encoder_conf",
      "ctc",
      "ctc_conf",
      "ctc_weight",
      "input_size",
      "vocab_size",
      "blank_id"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "kaldi_file"
    ]
  },
  "toKaldiMatrix": [
    "np_mat"
  ],
  "LinearTransform": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim"
    ],
    "forward": [
      "self",
      "input"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "fread"
    ]
  },
  "AffineTransform": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim"
    ],
    "forward": [
      "self",
      "input"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "fread"
    ]
  },
  "RectifiedLinear": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim"
    ],
    "forward": [
      "self",
      "input"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "fread"
    ]
  },
  "FSMNBlock": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "lorder",
      "rorder",
      "lstride",
      "rstride"
    ],
    "forward": [
      "self",
      "input",
      "cache"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "fread"
    ]
  },
  "BasicBlock": {
    "__init__": [
      "self",
      "linear_dim",
      "proj_dim",
      "lorder",
      "rorder",
      "lstride",
      "rstride",
      "stack_layer"
    ],
    "forward": [
      "self",
      "input",
      "cache"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "fread"
    ]
  },
  "BasicBlock_export": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "input",
      "in_cache"
    ]
  },
  "FsmnStack": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "cache"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "fread"
    ]
  },
  "FSMNConvert": {
    "__init__": [
      "self",
      "input_dim",
      "input_affine_dim",
      "fsmn_layers",
      "linear_dim",
      "proj_dim",
      "lorder",
      "rorder",
      "lstride",
      "rstride",
      "output_affine_dim",
      "output_dim",
      "use_softmax"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "cache"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "kaldi_file"
    ]
  },
  "FsmnKWSMT": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "ctc_conf",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths",
      "text2",
      "text2_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "_calc_ctc_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "_calc_ctc2_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "FsmnKWSMTConvert": {
    "__init__": [
      "self",
      "encoder",
      "encoder_conf",
      "ctc_conf",
      "ctc_weight",
      "input_size",
      "blank_id"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_kaldi_net2": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "kaldi_file"
    ]
  },
  "FSMNMT": {
    "__init__": [
      "self",
      "input_dim",
      "input_affine_dim",
      "fsmn_layers",
      "linear_dim",
      "proj_dim",
      "lorder",
      "rorder",
      "lstride",
      "rstride",
      "output_affine_dim",
      "output_dim",
      "output_dim2",
      "use_softmax"
    ],
    "output_size": [
      "self"
    ],
    "output_size2": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "cache"
    ]
  },
  "FSMNMTConvert": {
    "__init__": [
      "self",
      "input_dim",
      "input_affine_dim",
      "fsmn_layers",
      "linear_dim",
      "proj_dim",
      "lorder",
      "rorder",
      "lstride",
      "rstride",
      "output_affine_dim",
      "output_dim",
      "output_dim2",
      "use_softmax"
    ],
    "output_size": [
      "self"
    ],
    "output_size2": [
      "self"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_kaldi_net2": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "kaldi_file"
    ]
  },
  "export_rebuild_model": [
    "model"
  ],
  "export_forward": [
    "self",
    "feats"
  ],
  "export_dummy_inputs": [
    "self",
    "data_in",
    "frame"
  ],
  "export_input_names": [
    "self"
  ],
  "export_output_names": [
    "self"
  ],
  "export_dynamic_axes": [
    "self"
  ],
  "export_name": [
    "self"
  ],
  "VadStateMachine": {
    "kVadInStateStartPointNotDetected": [],
    "kVadInStateInSpeechSegment": [],
    "kVadInStateEndPointDetected": []
  },
  "FrameState": {
    "kFrameStateInvalid": [],
    "kFrameStateSpeech": [],
    "kFrameStateSil": []
  },
  "AudioChangeState": {
    "kChangeStateSpeech2Speech": [],
    "kChangeStateSpeech2Sil": [],
    "kChangeStateSil2Sil": [],
    "kChangeStateSil2Speech": [],
    "kChangeStateNoBegin": [],
    "kChangeStateInvalid": []
  },
  "VadDetectMode": {
    "kVadSingleUtteranceDetectMode": [],
    "kVadMutipleUtteranceDetectMode": []
  },
  "VADXOptions": {
    "__init__": [
      "self",
      "sample_rate",
      "detect_mode",
      "snr_mode",
      "max_end_silence_time",
      "max_start_silence_time",
      "do_start_point_detection",
      "do_end_point_detection",
      "window_size_ms",
      "sil_to_speech_time_thres",
      "speech_to_sil_time_thres",
      "speech_2_noise_ratio",
      "do_extend",
      "lookback_time_start_point",
      "lookahead_time_end_point",
      "max_single_segment_time",
      "nn_eval_block_size",
      "dcd_block_size",
      "snr_thres",
      "noise_frame_num_used_for_snr",
      "decibel_thres",
      "speech_noise_thres",
      "fe_prior_thres",
      "silence_pdf_num",
      "sil_pdf_ids",
      "speech_noise_thresh_low",
      "speech_noise_thresh_high",
      "output_frame_probs",
      "frame_in_ms",
      "frame_length_ms"
    ]
  },
  "E2EVadSpeechBufWithDoa": {
    "__init__": [
      "self"
    ],
    "Reset": [
      "self"
    ]
  },
  "E2EVadFrameProb": {
    "__init__": [
      "self"
    ]
  },
  "WindowDetector": {
    "__init__": [
      "self",
      "window_size_ms",
      "sil_to_speech_time",
      "speech_to_sil_time",
      "frame_size_ms"
    ],
    "Reset": [
      "self"
    ],
    "GetWinSize": [
      "self"
    ],
    "DetectOneFrame": [
      "self",
      "frameState",
      "frame_count",
      "cache"
    ],
    "FrameSizeMs": [
      "self"
    ]
  },
  "Stats": {
    "__init__": [
      "self",
      "sil_pdf_ids",
      "max_end_sil_frame_cnt_thresh",
      "speech_noise_thres"
    ]
  },
  "FsmnVADStreaming": {
    "__init__": [
      "self",
      "encoder",
      "encoder_conf",
      "vad_post_args"
    ],
    "ResetDetection": [
      "self",
      "cache"
    ],
    "ComputeDecibel": [
      "self",
      "cache"
    ],
    "ComputeScores": [
      "self",
      "feats",
      "cache"
    ],
    "PopDataBufTillFrame": [
      "self",
      "frame_idx",
      "cache"
    ],
    "PopDataToOutputBuf": [
      "self",
      "start_frm",
      "frm_cnt",
      "first_frm_is_start_point",
      "last_frm_is_end_point",
      "end_point_is_sent_end",
      "cache"
    ],
    "OnSilenceDetected": [
      "self",
      "valid_frame",
      "cache"
    ],
    "OnVoiceDetected": [
      "self",
      "valid_frame",
      "cache"
    ],
    "OnVoiceStart": [
      "self",
      "start_frame",
      "fake_result",
      "cache"
    ],
    "OnVoiceEnd": [
      "self",
      "end_frame",
      "fake_result",
      "is_last_frame",
      "cache"
    ],
    "MaybeOnVoiceEndIfLastFrame": [
      "self",
      "is_final_frame",
      "cur_frm_idx",
      "cache"
    ],
    "GetLatency": [
      "self",
      "cache"
    ],
    "LatencyFrmNumAtStartPoint": [
      "self",
      "cache"
    ],
    "GetFrameState": [
      "self",
      "t",
      "cache"
    ],
    "forward": [
      "self",
      "feats",
      "waveform",
      "cache",
      "is_final"
    ],
    "init_cache": [
      "self",
      "cache"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend",
      "cache"
    ],
    "export": [
      "self"
    ],
    "DetectCommonFrames": [
      "self",
      "cache"
    ],
    "DetectLastFrames": [
      "self",
      "cache"
    ],
    "DetectOneFrame": [
      "self",
      "cur_frm_state",
      "cur_frm_idx",
      "is_final_frame",
      "cache"
    ]
  },
  "FSMN": {
    "__init__": [
      "self",
      "input_dim",
      "input_affine_dim",
      "fsmn_layers",
      "linear_dim",
      "proj_dim",
      "lorder",
      "rorder",
      "lstride",
      "rstride",
      "output_affine_dim",
      "output_dim",
      "use_softmax"
    ],
    "fuse_modules": [
      "self"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "cache"
    ]
  },
  "FSMNExport": {
    "__init__": [
      "self",
      "model"
    ],
    "fuse_modules": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Hypothesis": {
    "asdict": [
      "self"
    ]
  },
  "BeamSearchPara": {
    "__init__": [
      "self",
      "scorers",
      "weights",
      "beam_size",
      "vocab_size",
      "sos",
      "eos",
      "token_list",
      "pre_beam_ratio",
      "pre_beam_score_key"
    ],
    "init_hyp": [
      "self",
      "x"
    ],
    "append_token": [
      "xs",
      "x"
    ],
    "score_full": [
      "self",
      "hyp",
      "x"
    ],
    "score_partial": [
      "self",
      "hyp",
      "ids",
      "x"
    ],
    "beam": [
      "self",
      "weighted_scores",
      "ids"
    ],
    "merge_scores": [
      "prev_scores",
      "next_full_scores",
      "full_idx",
      "next_part_scores",
      "part_idx"
    ],
    "merge_states": [
      "self",
      "states",
      "part_states",
      "part_idx"
    ],
    "search": [
      "self",
      "running_hyps",
      "x",
      "am_score"
    ],
    "forward": [
      "self",
      "x",
      "am_scores",
      "maxlenratio",
      "minlenratio"
    ],
    "post_process": [
      "self",
      "i",
      "maxlen",
      "maxlenratio",
      "running_hyps",
      "ended_hyps"
    ]
  },
  "DecoderLayerSANM": {
    "__init__": [
      "self",
      "size",
      "self_attn",
      "src_attn",
      "feed_forward",
      "dropout_rate",
      "normalize_before",
      "concat_after"
    ],
    "forward": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "memory_mask",
      "cache"
    ],
    "get_attn_mat": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "memory_mask",
      "cache"
    ],
    "forward_one_step": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "memory_mask",
      "cache"
    ],
    "forward_chunk": [
      "self",
      "tgt",
      "memory",
      "fsmn_cache",
      "opt_cache",
      "chunk_size",
      "look_back"
    ]
  },
  "ParaformerSANMDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "self_attention_dropout_rate",
      "src_attention_dropout_rate",
      "input_layer",
      "use_output_layer",
      "wo_input_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "att_layer_num",
      "kernel_size",
      "sanm_shfit",
      "lora_list",
      "lora_rank",
      "lora_alpha",
      "lora_dropout",
      "chunk_multiply_factor",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens",
      "chunk_mask",
      "return_hidden",
      "return_both"
    ],
    "score": [
      "self",
      "ys",
      "state",
      "x"
    ],
    "forward_asf2": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens"
    ],
    "forward_asf6": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens"
    ],
    "forward_chunk": [
      "self",
      "memory",
      "tgt",
      "cache"
    ],
    "forward_one_step": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "cache"
    ]
  },
  "DecoderLayerSANMExport": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "memory_mask",
      "cache"
    ],
    "get_attn_mat": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "memory_mask",
      "cache"
    ]
  },
  "ParaformerSANMDecoderExport": {
    "__init__": [
      "self",
      "model",
      "max_seq_len",
      "model_name",
      "onnx"
    ],
    "prepare_mask": [
      "self",
      "mask"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens",
      "return_hidden",
      "return_both"
    ],
    "forward_asf2": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens"
    ],
    "forward_asf6": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens"
    ]
  },
  "ParaformerSANMDecoderOnlineExport": {
    "__init__": [
      "self",
      "model",
      "max_seq_len",
      "model_name",
      "onnx"
    ],
    "prepare_mask": [
      "self",
      "mask"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens"
    ],
    "get_dummy_inputs": [
      "self",
      "enc_size"
    ],
    "get_input_names": [
      "self"
    ],
    "get_output_names": [
      "self"
    ],
    "get_dynamic_axes": [
      "self"
    ]
  },
  "ParaformerSANDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "self_attention_dropout_rate",
      "src_attention_dropout_rate",
      "input_layer",
      "use_output_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "embeds_id"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens"
    ]
  },
  "ParaformerDecoderSANExport": {
    "__init__": [
      "self",
      "model",
      "max_seq_len",
      "model_name",
      "onnx"
    ],
    "prepare_mask": [
      "self",
      "mask"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens"
    ],
    "get_dummy_inputs": [
      "self",
      "enc_size"
    ],
    "is_optimizable": [
      "self"
    ],
    "get_input_names": [
      "self"
    ],
    "get_output_names": [
      "self"
    ],
    "get_dynamic_axes": [
      "self"
    ]
  },
  "Paraformer": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "decoder",
      "decoder_conf",
      "ctc",
      "ctc_conf",
      "predictor",
      "predictor_conf",
      "ctc_weight",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos",
      "lsm_weight",
      "length_normalized_loss",
      "predictor_weight",
      "predictor_bias",
      "sampling_ratio",
      "share_embedding",
      "use_1st_decoder_loss"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "calc_predictor": [
      "self",
      "encoder_out",
      "encoder_out_lens"
    ],
    "cal_decoder_with_predictor": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "sematic_embeds",
      "ys_pad_lens"
    ],
    "_calc_att_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "sampler": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens",
      "pre_acoustic_embeds"
    ],
    "_calc_ctc_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "init_beam_search": [
      "self"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "export": [
      "self"
    ]
  },
  "CifPredictor": {
    "__init__": [
      "self",
      "idim",
      "l_order",
      "r_order",
      "threshold",
      "dropout",
      "smooth_factor",
      "noise_threshold",
      "tail_threshold"
    ],
    "forward": [
      "self",
      "hidden",
      "target_label",
      "mask",
      "ignore_id",
      "mask_chunk_predictor",
      "target_label_length"
    ],
    "tail_process_fn": [
      "self",
      "hidden",
      "alphas",
      "token_num",
      "mask"
    ],
    "gen_frame_alignments": [
      "self",
      "alphas",
      "encoder_sequence_length"
    ]
  },
  "CifPredictorV2": {
    "__init__": [
      "self",
      "idim",
      "l_order",
      "r_order",
      "threshold",
      "dropout",
      "smooth_factor",
      "noise_threshold",
      "tail_threshold",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf",
      "tail_mask"
    ],
    "forward": [
      "self",
      "hidden",
      "target_label",
      "mask",
      "ignore_id",
      "mask_chunk_predictor",
      "target_label_length"
    ],
    "forward_chunk": [
      "self",
      "hidden",
      "cache"
    ],
    "tail_process_fn": [
      "self",
      "hidden",
      "alphas",
      "token_num",
      "mask"
    ],
    "gen_frame_alignments": [
      "self",
      "alphas",
      "encoder_sequence_length"
    ]
  },
  "CifPredictorV2Export": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "hidden",
      "mask"
    ],
    "forward_cnn": [
      "self",
      "hidden",
      "mask"
    ],
    "tail_process_fn": [
      "self",
      "hidden",
      "alphas",
      "token_num",
      "mask"
    ]
  },
  "cif_v1_export": [
    "hidden",
    "alphas",
    "threshold"
  ],
  "cif_export": [
    "hidden",
    "alphas",
    "threshold"
  ],
  "mae_loss": {
    "__init__": [
      "self",
      "normalize_length"
    ],
    "forward": [
      "self",
      "token_length",
      "pre_token_length"
    ]
  },
  "cif": [
    "hidden",
    "alphas",
    "threshold"
  ],
  "cif_wo_hidden_v1": [
    "alphas",
    "threshold",
    "return_fire_idxs"
  ],
  "cif_v1": [
    "hidden",
    "alphas",
    "threshold"
  ],
  "ReLU": {
    "__init__": [
      "self",
      "inplace"
    ],
    "__repr__": [
      "self"
    ]
  },
  "conv1x1": [
    "in_planes",
    "out_planes",
    "stride"
  ],
  "conv3x3": [
    "in_planes",
    "out_planes",
    "stride"
  ],
  "BasicBlockERes2Net": {
    "expansion": [],
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride",
      "baseWidth",
      "scale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BasicBlockERes2Net_diff_AFF": {
    "expansion": [],
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride",
      "baseWidth",
      "scale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ERes2NetAug": {
    "__init__": [
      "self",
      "block",
      "block_fuse",
      "num_blocks",
      "m_channels",
      "feat_dim",
      "embedding_size",
      "pooling_func",
      "two_emb_layer"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "num_blocks",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ERes2Net": {
    "__init__": [
      "self",
      "block",
      "block_fuse",
      "num_blocks",
      "m_channels",
      "feat_dim",
      "embedding_size",
      "pooling_func",
      "two_emb_layer"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "num_blocks",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BasicBlockRes2Net": {
    "expansion": [],
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride",
      "baseWidth",
      "scale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Res2Net": {
    "__init__": [
      "self",
      "block",
      "num_blocks",
      "m_channels",
      "feat_dim",
      "embedding_size",
      "pooling_func",
      "two_emb_layer"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "num_blocks",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AFF": {
    "__init__": [
      "self",
      "channels",
      "r"
    ],
    "forward": [
      "self",
      "x",
      "ds_y"
    ]
  },
  "MultiHeadedAttentionReturnWeight": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "dropout_rate"
    ],
    "forward_qkv": [
      "self",
      "query",
      "key",
      "value"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask"
    ]
  },
  "LCBNet": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "decoder",
      "decoder_conf",
      "text_encoder",
      "text_encoder_conf",
      "bias_predictor",
      "bias_predictor_conf",
      "fusion_encoder",
      "fusion_encoder_conf",
      "ctc",
      "ctc_conf",
      "ctc_weight",
      "interctc_weight",
      "select_num",
      "select_length",
      "insert_blank",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos",
      "lsm_weight",
      "length_normalized_loss",
      "report_cer",
      "report_wer",
      "sym_space",
      "sym_blank",
      "share_embedding"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "_calc_att_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "_calc_ctc_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "init_beam_search": [
      "self"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "EncoderLayer": {
    "__init__": [
      "self",
      "size",
      "self_attn",
      "feed_forward",
      "dropout_rate",
      "normalize_before",
      "concat_after",
      "stochastic_depth_rate"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "cache"
    ]
  },
  "TransformerTextEncoder": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "attention_dropout_rate",
      "pos_enc_class",
      "normalize_before",
      "concat_after"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens"
    ]
  },
  "SelfSrcAttention": {
    "__init__": [
      "self",
      "size",
      "attention_heads",
      "attention_dim",
      "linear_units",
      "self_attention_dropout_rate",
      "src_attention_dropout_rate",
      "positional_dropout_rate",
      "dropout_rate",
      "normalize_before",
      "concat_after"
    ],
    "forward": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "memory_mask",
      "cache"
    ]
  },
  "ConvPredictor": {
    "__init__": [
      "self",
      "size",
      "l_order",
      "r_order",
      "attention_heads",
      "attention_dropout_rate",
      "linear_units"
    ],
    "forward": [
      "self",
      "text_enc",
      "asr_enc"
    ]
  },
  "PifPredictor": {
    "__init__": [
      "self",
      "idim",
      "l_order",
      "r_order",
      "threshold",
      "dropout",
      "smooth_factor",
      "noise_threshold",
      "sigma",
      "bias",
      "sigma_heads"
    ],
    "forward": [
      "self",
      "hidden",
      "target_label",
      "mask",
      "ignore_id",
      "mask_chunk_predictor",
      "target_label_length"
    ]
  },
  "EParaformer": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "decoder",
      "decoder_conf",
      "ctc",
      "ctc_conf",
      "predictor",
      "predictor_conf",
      "ctc_weight",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos",
      "lsm_weight",
      "length_normalized_loss",
      "predictor_weight",
      "predictor_bias",
      "sampling_ratio",
      "share_embedding",
      "use_1st_decoder_loss"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "calc_predictor": [
      "self",
      "encoder_out",
      "encoder_out_lens"
    ],
    "cal_decoder_with_predictor": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "sematic_embeds",
      "ys_pad_lens"
    ],
    "_calc_att_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "sampler": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens",
      "pre_acoustic_embeds"
    ],
    "sampler_with_grad": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens",
      "pre_acoustic_embeds"
    ],
    "_calc_ctc_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "init_beam_search": [
      "self"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "export": [
      "self"
    ]
  },
  "SinusoidalPositionEncoder": {
    "__int__": [
      "self",
      "d_model",
      "dropout_rate"
    ],
    "encode": [
      "self",
      "positions",
      "depth",
      "dtype"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PositionwiseFeedForward": {
    "__init__": [
      "self",
      "idim",
      "hidden_units",
      "dropout_rate",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MultiHeadedAttentionSANM": {
    "__init__": [
      "self",
      "n_head",
      "in_feat",
      "n_feat",
      "dropout_rate",
      "kernel_size",
      "sanm_shfit",
      "lora_list",
      "lora_rank",
      "lora_alpha",
      "lora_dropout"
    ],
    "forward_fsmn": [
      "self",
      "inputs",
      "mask",
      "mask_shfit_chunk"
    ],
    "forward_qkv": [
      "self",
      "x"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask",
      "mask_att_chunk_encoder"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "mask_shfit_chunk",
      "mask_att_chunk_encoder"
    ],
    "forward_chunk": [
      "self",
      "x",
      "cache",
      "chunk_size",
      "look_back"
    ]
  },
  "LayerNorm": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "EncoderLayerSANM": {
    "__init__": [
      "self",
      "in_size",
      "size",
      "self_attn",
      "feed_forward",
      "dropout_rate",
      "normalize_before",
      "concat_after",
      "stochastic_depth_rate"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "cache",
      "mask_shfit_chunk",
      "mask_att_chunk_encoder"
    ],
    "forward_chunk": [
      "self",
      "x",
      "cache",
      "chunk_size",
      "look_back"
    ]
  },
  "SenseVoiceEncoderSmall": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "tp_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "attention_dropout_rate",
      "stochastic_depth_rate",
      "input_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "positionwise_layer_type",
      "positionwise_conv_kernel_size",
      "padding_idx",
      "kernel_size",
      "sanm_shfit",
      "selfattention_layer_type"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens"
    ]
  },
  "SenseVoiceSmall": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "ctc_conf",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos",
      "length_normalized_loss"
    ],
    "from_pretrained": [
      "model"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths",
      "text"
    ],
    "_calc_ctc_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "_calc_rich_ce_loss": [
      "self",
      "encoder_out",
      "ys_pad"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "post": [
      "self",
      "timestamp"
    ],
    "export": [
      "self"
    ]
  },
  "__version__": [],
  "SAMPLE_RATE": [],
  "N_FFT": [],
  "HOP_LENGTH": [],
  "CHUNK_LENGTH": [],
  "N_SAMPLES": [],
  "N_FRAMES": [],
  "N_SAMPLES_PER_TOKEN": [],
  "FRAMES_PER_SECOND": [],
  "TOKENS_PER_SECOND": [],
  "load_audio": [
    "file",
    "sr"
  ],
  "pad_or_trim": [
    "array",
    "length"
  ],
  "mel_filters": [
    "device",
    "n_mels",
    "filters_path"
  ],
  "log_mel_spectrogram": [
    "audio",
    "n_mels",
    "padding",
    "device"
  ],
  "median_filter": [
    "x",
    "filter_width"
  ],
  "backtrace": [
    "trace"
  ],
  "dtw_cpu": [
    "x"
  ],
  "dtw_cuda": [
    "x",
    "BLOCK_SIZE"
  ],
  "dtw": [
    "x"
  ],
  "WordTiming": {},
  "find_alignment": [
    "model",
    "tokenizer",
    "text_tokens",
    "mel",
    "num_frames"
  ],
  "merge_punctuations": [
    "alignment",
    "prepended",
    "appended"
  ],
  "add_word_timestamps": [],
  "system_encoding": [],
  "exact_div": [
    "x",
    "y"
  ],
  "optional_int": [
    "string"
  ],
  "optional_float": [
    "string"
  ],
  "compression_ratio": [
    "text"
  ],
  "format_timestamp": [
    "seconds",
    "always_include_hours",
    "decimal_marker"
  ],
  "get_start": [
    "segments"
  ],
  "get_end": [
    "segments"
  ],
  "ResultWriter": {
    "__init__": [
      "self",
      "output_dir"
    ],
    "__call__": [
      "self",
      "result",
      "audio_path",
      "options"
    ],
    "write_result": [
      "self",
      "result",
      "file",
      "options"
    ]
  },
  "WriteTXT": {
    "write_result": [
      "self",
      "result",
      "file",
      "options"
    ]
  },
  "SubtitlesWriter": {
    "iterate_result": [
      "self",
      "result",
      "options"
    ],
    "format_timestamp": [
      "self",
      "seconds"
    ]
  },
  "WriteVTT": {
    "write_result": [
      "self",
      "result",
      "file",
      "options"
    ]
  },
  "WriteSRT": {
    "write_result": [
      "self",
      "result",
      "file",
      "options"
    ]
  },
  "WriteTSV": {
    "write_result": [
      "self",
      "result",
      "file",
      "options"
    ]
  },
  "WriteJSON": {
    "write_result": [
      "self",
      "result",
      "file",
      "options"
    ]
  },
  "get_writer": [
    "output_format",
    "output_dir"
  ],
  "LANGUAGES": [],
  "TO_LANGUAGE_CODE": [],
  "AUDIO_EVENT": [],
  "EMOTION": [],
  "Tokenizer": {
    "__post_init__": [
      "self"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "token_ids"
    ],
    "decode_with_timestamps": [
      "self",
      "token_ids"
    ],
    "get_vocab_size": [
      "self"
    ],
    "eot": [
      "self"
    ],
    "transcribe": [
      "self"
    ],
    "translate": [
      "self"
    ],
    "sot": [
      "self"
    ],
    "sot_sense": [
      "self"
    ],
    "sot_lm": [
      "self"
    ],
    "sot_prev": [
      "self"
    ],
    "no_speech": [
      "self"
    ],
    "no_timestamps": [
      "self"
    ],
    "timestamp_begin": [
      "self"
    ],
    "language_token": [
      "self"
    ],
    "to_language_token": [
      "self",
      "language"
    ],
    "all_language_tokens": [
      "self"
    ],
    "all_language_codes": [
      "self"
    ],
    "sot_sequence_including_notimestamps": [
      "self"
    ],
    "non_speech_tokens": [
      "self"
    ],
    "split_to_word_tokens": [
      "self",
      "tokens"
    ],
    "split_tokens_on_unicode": [
      "self",
      "tokens"
    ],
    "split_tokens_on_spaces": [
      "self",
      "tokens"
    ]
  },
  "get_encoding": [
    "name",
    "num_languages",
    "vocab_path"
  ],
  "get_tokenizer": [
    "multilingual"
  ],
  "_MODELS": [],
  "_ALIGNMENT_HEADS": [],
  "_download": [
    "url",
    "root",
    "in_memory"
  ],
  "available_models": [],
  "load_model": [
    "name",
    "device",
    "download_root",
    "in_memory"
  ],
  "detect_language": [
    "model",
    "mel",
    "tokenizer",
    "initial_prompt",
    "x"
  ],
  "DecodingOptions": {},
  "DecodingResult": {},
  "Inference": {
    "logits": [
      "self",
      "tokens",
      "audio_features"
    ],
    "rearrange_kv_cache": [
      "self",
      "source_indices"
    ],
    "cleanup_caching": [
      "self"
    ]
  },
  "PyTorchInference": {
    "__init__": [
      "self",
      "model",
      "initial_token_length"
    ],
    "logits": [
      "self",
      "tokens",
      "audio_features"
    ],
    "cleanup_caching": [
      "self"
    ],
    "rearrange_kv_cache": [
      "self",
      "source_indices"
    ]
  },
  "SequenceRanker": {
    "rank": [
      "self",
      "tokens",
      "sum_logprobs"
    ]
  },
  "MaximumLikelihoodRanker": {
    "__init__": [
      "self",
      "length_penalty"
    ],
    "rank": [
      "self",
      "tokens",
      "sum_logprobs"
    ]
  },
  "TokenDecoder": {
    "reset": [
      "self"
    ],
    "update": [
      "self",
      "tokens",
      "logits",
      "sum_logprobs"
    ],
    "finalize": [
      "self",
      "tokens",
      "sum_logprobs"
    ]
  },
  "GreedyDecoder": {
    "__init__": [
      "self",
      "temperature",
      "eot"
    ],
    "update": [
      "self",
      "tokens",
      "logits",
      "sum_logprobs"
    ],
    "finalize": [
      "self",
      "tokens",
      "sum_logprobs"
    ]
  },
  "BeamSearchDecoder": {
    "__init__": [
      "self",
      "beam_size",
      "eot",
      "inference",
      "patience"
    ],
    "reset": [
      "self"
    ],
    "update": [
      "self",
      "tokens",
      "logits",
      "sum_logprobs"
    ],
    "finalize": [
      "self",
      "preceding_tokens",
      "sum_logprobs"
    ]
  },
  "LogitFilter": {
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "SuppressBlank": {
    "__init__": [
      "self",
      "tokenizer",
      "sample_begin"
    ],
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "SuppressTokens": {
    "__init__": [
      "self",
      "suppress_tokens"
    ],
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "GainEventToken": {
    "__init__": [
      "self",
      "bg_tokens",
      "ed_tokens",
      "gain_values"
    ],
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "ThresholdEmoToken": {
    "__init__": [
      "self",
      "unk_tokens",
      "emo_tokens",
      "th_values"
    ],
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "ApplyTimestampRules": {
    "__init__": [
      "self",
      "tokenizer",
      "sample_begin",
      "max_initial_timestamp_index"
    ],
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "DecodingTask": {
    "__init__": [
      "self",
      "model",
      "options"
    ],
    "_verify_options": [
      "self",
      "options"
    ],
    "_get_initial_tokens": [
      "self"
    ],
    "_get_suppress_tokens": [
      "self"
    ],
    "_get_audio_features": [
      "self",
      "mel"
    ],
    "_detect_language": [
      "self",
      "audio_features",
      "tokens"
    ],
    "_main_loop": [
      "self",
      "audio_features",
      "tokens"
    ],
    "run": [
      "self",
      "mel"
    ]
  },
  "decode": [
    "model",
    "mel",
    "options"
  ],
  "ModelDimensions": {},
  "Linear": {
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv1d": {
    "_conv_forward": [
      "self",
      "x",
      "weight",
      "bias"
    ]
  },
  "sinusoids": [
    "length",
    "channels",
    "max_timescale"
  ],
  "MultiHeadAttention": {
    "__init__": [
      "self",
      "n_state",
      "n_head"
    ],
    "forward": [
      "self",
      "x",
      "xa",
      "mask",
      "kv_cache"
    ],
    "qkv_attention": [
      "self",
      "q",
      "k",
      "v",
      "mask"
    ]
  },
  "MultiHeadAttentionSdpa": {
    "__init__": [
      "self",
      "n_state",
      "n_head"
    ],
    "forward": [
      "self",
      "x",
      "xa",
      "mask",
      "kv_cache"
    ],
    "qkv_attention": [
      "self",
      "q",
      "k",
      "v",
      "mask"
    ]
  },
  "att_type_dict": [],
  "ResidualAttentionBlock": {
    "__init__": [
      "self",
      "n_state",
      "n_head",
      "cross_attention"
    ],
    "forward": [
      "self",
      "x",
      "xa",
      "mask",
      "kv_cache"
    ]
  },
  "AudioEncoder": {
    "__init__": [
      "self",
      "n_mels",
      "n_ctx",
      "n_state",
      "n_head",
      "n_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TextDecoder": {
    "__init__": [
      "self",
      "n_vocab",
      "n_ctx",
      "n_state",
      "n_head",
      "n_layer"
    ],
    "forward": [
      "self",
      "x",
      "xa",
      "kv_cache"
    ],
    "init_state": [
      "self",
      "x"
    ],
    "final_score": [
      "self",
      "state"
    ],
    "score": [
      "self",
      "ys",
      "state",
      "x"
    ]
  },
  "Whisper": {
    "__init__": [
      "self",
      "dims"
    ],
    "set_alignment_heads": [
      "self",
      "dump"
    ],
    "embed_audio": [
      "self",
      "mel"
    ],
    "logits": [
      "self",
      "tokens",
      "audio_features"
    ],
    "forward": [
      "self",
      "mel",
      "tokens"
    ],
    "device": [
      "self"
    ],
    "is_multilingual": [
      "self"
    ],
    "num_languages": [
      "self"
    ],
    "install_kv_cache_hooks": [
      "self",
      "cache"
    ],
    "detect_language": [],
    "transcribe": [],
    "decode": []
  },
  "dtw_kernel": [
    "cost",
    "trace",
    "x",
    "x_stride",
    "cost_stride",
    "trace_stride",
    "N",
    "M",
    "BLOCK_SIZE"
  ],
  "median_kernel": [
    "filter_width"
  ],
  "median_filter_cuda": [
    "x",
    "filter_width"
  ],
  "transcribe": [
    "model",
    "audio"
  ],
  "cli": [],
  "EnglishNumberNormalizer": {
    "__init__": [
      "self"
    ],
    "process_words": [
      "self",
      "words"
    ],
    "preprocess": [
      "self",
      "s"
    ],
    "postprocess": [
      "self",
      "s"
    ],
    "__call__": [
      "self",
      "s"
    ]
  },
  "EnglishSpellingNormalizer": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "s"
    ]
  },
  "EnglishTextNormalizer": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "s"
    ]
  },
  "ADDITIONAL_DIACRITICS": [],
  "remove_symbols_and_diacritics": [
    "s",
    "keep"
  ],
  "remove_symbols": [
    "s"
  ],
  "BasicTextNormalizer": {
    "__init__": [
      "self",
      "remove_diacritics",
      "split_letters"
    ],
    "__call__": [
      "self",
      "s"
    ]
  },
  "ctc_forced_align": [
    "log_probs",
    "targets",
    "input_lengths",
    "target_lengths",
    "blank",
    "ignore_id"
  ],
  "JointNetwork": {
    "__init__": [
      "self",
      "output_size",
      "encoder_size",
      "decoder_size",
      "joint_space_size",
      "joint_activation_type"
    ],
    "forward": [
      "self",
      "enc_out",
      "dec_out",
      "project_input"
    ]
  },
  "RNNTDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "embed_size",
      "hidden_size",
      "rnn_type",
      "num_layers",
      "dropout_rate",
      "embed_dropout_rate",
      "embed_pad",
      "use_embed_mask"
    ],
    "forward": [
      "self",
      "labels",
      "label_lens",
      "states"
    ],
    "rnn_forward": [
      "self",
      "x",
      "state"
    ],
    "score": [
      "self",
      "label",
      "label_sequence",
      "dec_state"
    ],
    "batch_score": [
      "self",
      "hyps"
    ],
    "set_device": [
      "self",
      "device"
    ],
    "init_state": [
      "self",
      "batch_size"
    ],
    "select_state": [
      "self",
      "states",
      "idx"
    ],
    "create_batch_states": [
      "self",
      "new_states"
    ]
  },
  "Transducer": {
    "__init__": [
      "self",
      "frontend",
      "frontend_conf",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "decoder",
      "decoder_conf",
      "joint_network",
      "joint_network_conf",
      "transducer_weight",
      "fastemit_lambda",
      "auxiliary_ctc_weight",
      "auxiliary_ctc_dropout_rate",
      "auxiliary_lm_loss_weight",
      "auxiliary_lm_loss_smoothing",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos",
      "lsm_weight",
      "length_normalized_loss",
      "share_embedding"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "_calc_transducer_loss": [
      "self",
      "encoder_out",
      "joint_out",
      "target",
      "t_len",
      "u_len"
    ],
    "_calc_ctc_loss": [
      "self",
      "encoder_out",
      "target",
      "t_len",
      "u_len"
    ],
    "_calc_lm_loss": [
      "self",
      "decoder_out",
      "target"
    ],
    "init_beam_search": [
      "self"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer"
    ]
  },
  "build_attention_list": [
    "eprojs",
    "dunits",
    "atype",
    "num_att",
    "num_encs",
    "aheads",
    "adim",
    "awin",
    "aconv_chans",
    "aconv_filts",
    "han_mode",
    "han_type",
    "han_heads",
    "han_dim",
    "han_conv_chans",
    "han_conv_filts",
    "han_win"
  ],
  "RNNDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "rnn_type",
      "num_layers",
      "hidden_size",
      "sampling_probability",
      "dropout",
      "context_residual",
      "replace_sos",
      "num_encs",
      "att_conf"
    ],
    "zero_state": [
      "self",
      "hs_pad"
    ],
    "rnn_forward": [
      "self",
      "ey",
      "z_list",
      "c_list",
      "z_prev",
      "c_prev"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens",
      "strm_idx"
    ],
    "init_state": [
      "self",
      "x"
    ],
    "score": [
      "self",
      "yseq",
      "state",
      "x"
    ]
  },
  "ExtendedHypothesis": {},
  "BeamSearchTransducer": {
    "__init__": [
      "self",
      "decoder",
      "joint_network",
      "beam_size",
      "lm",
      "lm_weight",
      "search_type",
      "max_sym_exp",
      "u_max",
      "nstep",
      "expansion_gamma",
      "expansion_beta",
      "score_norm",
      "nbest",
      "streaming"
    ],
    "__call__": [
      "self",
      "enc_out",
      "is_final"
    ],
    "reset_inference_cache": [
      "self"
    ],
    "sort_nbest": [
      "self",
      "hyps"
    ],
    "recombine_hyps": [
      "self",
      "hyps"
    ],
    "select_k_expansions": [
      "self",
      "hyps",
      "topk_idx",
      "topk_logp"
    ],
    "create_lm_batch_inputs": [
      "self",
      "hyps_seq"
    ],
    "default_beam_search": [
      "self",
      "enc_out"
    ],
    "align_length_sync_decoding": [
      "self",
      "enc_out"
    ],
    "time_sync_decoding": [
      "self",
      "enc_out"
    ],
    "modified_adaptive_expansion_search": [
      "self",
      "enc_out"
    ]
  },
  "export_encoder_forward": [
    "self",
    "speech",
    "speech_lengths"
  ],
  "export_encoder_dummy_inputs": [
    "self"
  ],
  "export_encoder_input_names": [
    "self"
  ],
  "export_encoder_output_names": [
    "self"
  ],
  "export_encoder_dynamic_axes": [
    "self"
  ],
  "export_encoder_name": [
    "self"
  ],
  "SanmKWS": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "ctc",
      "ctc_conf",
      "ctc_weight",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "_calc_ctc_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "export": [
      "self"
    ]
  },
  "EncoderProjectorQFormer": {
    "__init__": [
      "self",
      "downsample_rate",
      "encoder_dim",
      "llm_dim",
      "ffn_dim"
    ],
    "split_frames": [
      "self",
      "speech_embeds"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Transformer": {
    "__init__": [
      "self",
      "downsample_rate",
      "encoder_dim",
      "llm_dim",
      "ffn_dim"
    ],
    "forward": [
      "self",
      "x",
      "ilens"
    ]
  },
  "dtype_map": [],
  "LLMASR": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "audio_encoder",
      "audio_encoder_conf",
      "audio_adaptor",
      "audio_adaptor_conf",
      "decoder",
      "decoder_conf",
      "ctc",
      "ctc_conf",
      "ctc_weight",
      "llm",
      "llm_conf",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos",
      "lsm_weight",
      "length_normalized_loss",
      "report_cer",
      "report_wer",
      "sym_space",
      "sym_blank",
      "share_embedding"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths",
      "input_ids",
      "attention_mask",
      "labels_ids",
      "label_mask",
      "audio_mask"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "LLMASR2": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "audio_encoder",
      "audio_encoder_conf",
      "audio_adaptor",
      "audio_adaptor_conf",
      "decoder",
      "decoder_conf",
      "ctc",
      "ctc_conf",
      "ctc_weight",
      "llm",
      "llm_conf",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos",
      "lsm_weight",
      "length_normalized_loss",
      "report_cer",
      "report_wer",
      "sym_space",
      "sym_blank",
      "share_embedding"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "input_ids",
      "attention_mask",
      "labels_ids",
      "fbank_beg",
      "fbank_mask"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "data_template": [
      "self",
      "data"
    ],
    "data_load_speech": [
      "self",
      "contents",
      "tokenizer",
      "frontend",
      "meta_data"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "LLMASR3": {
    "__init__": [
      "self"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ]
  },
  "LLMASR4": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "audio_encoder",
      "audio_encoder_conf",
      "audio_adaptor",
      "audio_adaptor_conf",
      "decoder",
      "decoder_conf",
      "ctc",
      "ctc_conf",
      "ctc_weight",
      "llm",
      "llm_conf",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos",
      "lsm_weight",
      "length_normalized_loss",
      "report_cer",
      "report_wer",
      "sym_space",
      "sym_blank",
      "share_embedding"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "input_ids",
      "attention_mask",
      "labels_ids",
      "fbank_beg",
      "fbank_mask"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "data_template": [
      "self",
      "data"
    ],
    "data_load_speech": [
      "self",
      "contents",
      "tokenizer",
      "frontend",
      "meta_data"
    ],
    "inference_prepare": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "Conformer": {
    "__init__": [
      "self"
    ]
  },
  "ConvolutionModule": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "activation",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConformerEncoder": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "attention_dropout_rate",
      "input_layer",
      "normalize_before",
      "concat_after",
      "positionwise_layer_type",
      "positionwise_conv_kernel_size",
      "macaron_style",
      "rel_pos_type",
      "pos_enc_layer_type",
      "selfattention_layer_type",
      "activation_type",
      "use_cnn_module",
      "zero_triu",
      "cnn_module_kernel",
      "padding_idx",
      "interctc_layer_idx",
      "interctc_use_conditioning",
      "stochastic_depth_rate"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states",
      "ctc"
    ]
  },
  "CausalConvolution": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "activation",
      "norm_args",
      "causal"
    ],
    "forward": [
      "self",
      "x",
      "cache",
      "right_context"
    ]
  },
  "ChunkEncoderLayer": {
    "__init__": [
      "self",
      "block_size",
      "self_att",
      "feed_forward",
      "feed_forward_macaron",
      "conv_mod",
      "norm_class",
      "norm_args",
      "dropout_rate"
    ],
    "reset_streaming_cache": [
      "self",
      "left_context",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "pos_enc",
      "mask",
      "chunk_mask"
    ],
    "chunk_forward": [
      "self",
      "x",
      "pos_enc",
      "mask",
      "chunk_size",
      "left_context",
      "right_context"
    ]
  },
  "ConformerChunkEncoder": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "attention_dropout_rate",
      "embed_vgg_like",
      "normalize_before",
      "concat_after",
      "positionwise_layer_type",
      "positionwise_conv_kernel_size",
      "macaron_style",
      "rel_pos_type",
      "pos_enc_layer_type",
      "selfattention_layer_type",
      "activation_type",
      "use_cnn_module",
      "zero_triu",
      "norm_type",
      "cnn_module_kernel",
      "conv_mod_norm_eps",
      "conv_mod_norm_momentum",
      "simplified_att_score",
      "dynamic_chunk_training",
      "short_chunk_threshold",
      "short_chunk_size",
      "left_chunk_size",
      "time_reduction_factor",
      "unified_model_training",
      "default_chunk_size",
      "jitter_range",
      "subsampling_factor"
    ],
    "output_size": [
      "self"
    ],
    "get_encoder_input_raw_size": [
      "self",
      "size",
      "hop_length"
    ],
    "get_encoder_input_size": [
      "self",
      "size"
    ],
    "reset_streaming_cache": [
      "self",
      "left_context",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "x_len"
    ],
    "full_utt_forward": [
      "self",
      "x",
      "x_len"
    ],
    "simu_chunk_forward": [
      "self",
      "x",
      "x_len",
      "chunk_size",
      "left_context",
      "right_context"
    ],
    "chunk_forward": [
      "self",
      "x",
      "x_len",
      "processed_frames",
      "chunk_size",
      "left_context",
      "right_context"
    ]
  },
  "OpenAIWhisperDecoderWarp": {
    "__init__": [
      "self",
      "dropout_rate",
      "whisper_model",
      "download_dir",
      "use_padmask"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens"
    ],
    "forward_one_step": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "cache"
    ],
    "score": [
      "self",
      "ys",
      "state",
      "x"
    ],
    "batch_score": [
      "self",
      "ys",
      "states",
      "xs"
    ]
  },
  "OpenAIWhisperModel": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "decoder",
      "decoder_conf",
      "ctc",
      "ctc_conf",
      "ctc_weight",
      "interctc_weight",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos",
      "lsm_weight",
      "length_normalized_loss",
      "report_cer",
      "report_wer",
      "sym_space",
      "sym_blank",
      "share_embedding"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "_calc_att_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "_calc_ctc_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "init_beam_search": [
      "self"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "OpenAIWhisperLIDModel": {
    "__init__": [
      "self",
      "vocab_size",
      "specaug",
      "specaug_conf",
      "encoder",
      "encoder_conf",
      "lid_predictor",
      "lid_predictor_conf",
      "proj_dim",
      "clip_frames",
      "random_clip"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "lid",
      "lid_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "OpenAIWhisperEncoderWarp": {
    "__init__": [
      "self",
      "dropout_rate",
      "whisper_model",
      "download_dir",
      "use_specaug",
      "use_padmask",
      "specaug_conf"
    ],
    "whisper_encode": [
      "self",
      "input",
      "ilens"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states"
    ]
  },
  "LidPredictor": {
    "__init__": [
      "self",
      "block",
      "block_fuse",
      "num_blocks",
      "m_channels",
      "feat_dim",
      "embedding_size",
      "pooling_func",
      "two_emb_layer"
    ]
  },
  "SimpleAvg": {
    "__init__": [
      "self",
      "feat_dim"
    ],
    "forward": [
      "self",
      "x",
      "ilens"
    ],
    "output_size": [
      "self"
    ]
  },
  "TAP": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TSDP": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TSTP": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "olens"
    ]
  },
  "ASTP": {
    "__init__": [
      "self",
      "in_dim",
      "bottleneck_dim",
      "global_context_att"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BAT": {},
  "EBranchformer": {
    "__init__": [
      "self"
    ]
  },
  "EBranchformerEncoderLayer": {
    "__init__": [
      "self",
      "size",
      "attn",
      "cgmlp",
      "feed_forward",
      "feed_forward_macaron",
      "dropout_rate",
      "merge_conv_kernel"
    ],
    "forward": [
      "self",
      "x_input",
      "mask",
      "cache"
    ]
  },
  "EBranchformerEncoder": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "attention_heads",
      "attention_layer_type",
      "pos_enc_layer_type",
      "rel_pos_type",
      "cgmlp_linear_units",
      "cgmlp_conv_kernel",
      "use_linear_after_conv",
      "gate_activation",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "attention_dropout_rate",
      "input_layer",
      "zero_triu",
      "padding_idx",
      "layer_drop_rate",
      "max_pos_emb_len",
      "use_ffn",
      "macaron_ffn",
      "ffn_activation_type",
      "linear_units",
      "positionwise_layer_type",
      "merge_conv_kernel",
      "interctc_layer_idx",
      "interctc_use_conditioning"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states",
      "ctc",
      "max_layer"
    ]
  },
  "FunASRNano": {
    "__init__": [
      "self",
      "audio_encoder",
      "audio_encoder_conf",
      "audio_adaptor",
      "audio_adaptor_conf",
      "llm",
      "llm_conf",
      "input_size",
      "length_normalized_loss"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "input_ids",
      "attention_mask",
      "labels_ids",
      "fbank_beg",
      "fbank_mask"
    ],
    "forward_export": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "data_template": [
      "self",
      "data"
    ],
    "data_load_speech": [
      "self",
      "contents",
      "tokenizer",
      "frontend",
      "meta_data"
    ],
    "inference_prepare": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "get_prompt": [
      "self",
      "hotwords",
      "language",
      "itn"
    ],
    "generate_chatml": [
      "self",
      "prompt",
      "data"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "inference_llm": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "from_pretrained": [
      "model"
    ]
  },
  "CTC": {
    "__init__": [
      "self",
      "odim",
      "encoder_output_size",
      "dropout_rate",
      "reduce",
      "blank_id"
    ],
    "softmax": [
      "self",
      "hs_pad"
    ],
    "log_softmax": [
      "self",
      "hs_pad"
    ],
    "argmax": [
      "self",
      "hs_pad"
    ]
  },
  "scoreformat": [
    "name",
    "line",
    "flag"
  ],
  "recoformat": [
    "line"
  ],
  "numbersingle": [
    "line"
  ],
  "ch_number2digit": [
    "line"
  ],
  "special": [
    "line"
  ],
  "all_convert": [
    "content"
  ],
  "forced_align": [
    "log_probs",
    "targets",
    "blank"
  ],
  "CHINESE_DIGIS": [],
  "BIG_CHINESE_DIGIS_SIMPLIFIED": [],
  "BIG_CHINESE_DIGIS_TRADITIONAL": [],
  "SMALLER_BIG_CHINESE_UNITS_SIMPLIFIED": [],
  "SMALLER_BIG_CHINESE_UNITS_TRADITIONAL": [],
  "LARGER_CHINESE_NUMERING_UNITS_SIMPLIFIED": [],
  "LARGER_CHINESE_NUMERING_UNITS_TRADITIONAL": [],
  "SMALLER_CHINESE_NUMERING_UNITS_SIMPLIFIED": [],
  "SMALLER_CHINESE_NUMERING_UNITS_TRADITIONAL": [],
  "ZERO_ALT": [],
  "ONE_ALT": [],
  "TWO_ALTS": [],
  "POSITIVE": [],
  "NEGATIVE": [],
  "POINT": [],
  "FILLER_CHARS": [],
  "ER_WHITELIST": [],
  "ER_WHITELIST_PATTERN": [],
  "NUMBERING_TYPES": [],
  "CURRENCY_NAMES": [],
  "CURRENCY_UNITS": [],
  "COM_QUANTIFIERS": [],
  "CN_PUNCS_STOP": [],
  "CN_PUNCS_NONSTOP": [],
  "CN_PUNCS": [],
  "PUNCS": [],
  "PUNCS_TRANSFORM": [],
  "QJ2BJ": [],
  "QJ2BJ_TRANSFORM": [],
  "CN_CHARS_COMMON": [],
  "CN_CHARS_EXT": [],
  "CN_CHARS": [],
  "IN_CH_CHARS": [],
  "EN_CHARS": [],
  "IN_EN_CHARS": [],
  "VALID_CHARS": [],
  "IN_VALID_CHARS": [],
  "ChineseChar": {
    "__init__": [
      "self",
      "simplified",
      "traditional"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ChineseNumberUnit": {
    "__init__": [
      "self",
      "power",
      "simplified",
      "traditional",
      "big_s",
      "big_t"
    ],
    "__str__": [
      "self"
    ],
    "create": [
      "cls",
      "index",
      "value",
      "numbering_type",
      "small_unit"
    ]
  },
  "ChineseNumberDigit": {
    "__init__": [
      "self",
      "value",
      "simplified",
      "traditional",
      "big_s",
      "big_t",
      "alt_s",
      "alt_t"
    ],
    "__str__": [
      "self"
    ],
    "create": [
      "cls",
      "i",
      "v"
    ]
  },
  "ChineseMath": {
    "__init__": [
      "self",
      "simplified",
      "traditional",
      "symbol",
      "expression"
    ]
  },
  "NumberSystem": {},
  "MathSymbol": {
    "__init__": [
      "self",
      "positive",
      "negative",
      "point"
    ],
    "__iter__": [
      "self"
    ]
  },
  "create_system": [
    "numbering_type"
  ],
  "chn2num": [
    "chinese_string",
    "numbering_type"
  ],
  "num2chn": [
    "number_string",
    "numbering_type",
    "big",
    "traditional",
    "alt_zero",
    "alt_one",
    "alt_two",
    "use_zeros",
    "use_units"
  ],
  "Cardinal": {
    "__init__": [
      "self",
      "cardinal",
      "chntext"
    ],
    "chntext2cardinal": [
      "self"
    ],
    "cardinal2chntext": [
      "self"
    ]
  },
  "Digit": {
    "__init__": [
      "self",
      "digit",
      "chntext"
    ],
    "digit2chntext": [
      "self"
    ]
  },
  "TelePhone": {
    "__init__": [
      "self",
      "telephone",
      "raw_chntext",
      "chntext"
    ],
    "telephone2chntext": [
      "self",
      "fixed"
    ]
  },
  "Fraction": {
    "__init__": [
      "self",
      "fraction",
      "chntext"
    ],
    "chntext2fraction": [
      "self"
    ],
    "fraction2chntext": [
      "self"
    ]
  },
  "Date": {
    "__init__": [
      "self",
      "date",
      "chntext"
    ],
    "date2chntext": [
      "self"
    ]
  },
  "Money": {
    "__init__": [
      "self",
      "money",
      "chntext"
    ],
    "money2chntext": [
      "self"
    ]
  },
  "Percentage": {
    "__init__": [
      "self",
      "percentage",
      "chntext"
    ],
    "chntext2percentage": [
      "self"
    ],
    "percentage2chntext": [
      "self"
    ]
  },
  "normalize_nsw": [
    "raw_text"
  ],
  "remove_erhua": [
    "text"
  ],
  "remove_space": [
    "text"
  ],
  "TextNorm": {
    "__init__": [
      "self",
      "to_banjiao",
      "to_upper",
      "to_lower",
      "remove_fillers",
      "remove_erhua",
      "check_chars",
      "remove_space"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "basic_normalizer": [],
  "english_normalizer": [],
  "is_only_chinese_and_english": [
    "s"
  ],
  "is_only_english": [
    "s"
  ],
  "is_number": [
    "s"
  ],
  "safe_ja_g2p": [
    "text",
    "kana",
    "max_length"
  ],
  "normalize_text": [
    "srcfn",
    "dstfn",
    "kana"
  ],
  "LineProcessor": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "process_line": [
      "self",
      "line_pair"
    ]
  },
  "MossFormer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_blocks",
      "kernel_size",
      "norm",
      "num_spks",
      "skip_around_intra",
      "use_global_pos_enc",
      "max_length"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "select_norm": [
    "norm",
    "dim",
    "shape"
  ],
  "MossformerBlock": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MossFormer_MaskNet": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_blocks",
      "norm",
      "num_spks",
      "skip_around_intra",
      "use_global_pos_enc",
      "max_length"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MossFormerEncoder": {
    "__init__": [
      "self",
      "kernel_size",
      "out_channels",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MossFormerM": {
    "__init__": [
      "self",
      "num_blocks",
      "d_model",
      "causal",
      "group_size",
      "query_key_dim",
      "expansion_factor",
      "attn_dropout"
    ],
    "forward": [
      "self",
      "src"
    ]
  },
  "Computation_Block": {
    "__init__": [
      "self",
      "num_blocks",
      "out_channels",
      "norm",
      "skip_around_intra"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "identity": [
    "t"
  ],
  "append_dims": [
    "x",
    "num_dims"
  ],
  "exists": [
    "val"
  ],
  "default": [
    "val",
    "d"
  ],
  "padding_to_multiple_of": [
    "n",
    "mult"
  ],
  "Transpose": {
    "__init__": [
      "self",
      "shape"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DepthwiseConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "bias"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "ConvModule": {
    "__init__": [
      "self",
      "in_channels",
      "kernel_size",
      "expansion_factor",
      "dropout_p"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "OffsetScale": {
    "__init__": [
      "self",
      "dim",
      "heads"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FFConvM": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "norm_klass",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FLASH_ShareA_FFConvM": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "cal_attention": [
      "self",
      "x",
      "quad_q",
      "lin_q",
      "quad_k",
      "lin_k",
      "v",
      "u",
      "mask"
    ]
  },
  "MossFormerDecoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_annealed_rate": [
    "start",
    "end",
    "curr_step",
    "total_steps"
  ],
  "Data2VecEncoder": {
    "__init__": [
      "self",
      "input_size",
      "extractor_mode",
      "conv_feature_layers",
      "layer_type",
      "layer_norm_first",
      "encoder_layers",
      "encoder_embed_dim",
      "encoder_ffn_embed_dim",
      "encoder_attention_heads",
      "activation_fn",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "encoder_layerdrop",
      "dropout_input",
      "dropout_features",
      "feature_grad_mult",
      "mask_prob",
      "mask_length",
      "mask_selection",
      "mask_other",
      "no_mask_overlap",
      "mask_min_space",
      "require_same_masks",
      "mask_dropout",
      "mask_channel_length",
      "mask_channel_prob",
      "mask_channel_before",
      "mask_channel_selection",
      "mask_channel_other",
      "no_mask_channel_overlap",
      "mask_channel_min_space",
      "conv_pos",
      "conv_pos_groups",
      "pos_conv_depth",
      "max_positions",
      "average_top_k_layers",
      "layer_norm_target_layer",
      "instance_norm_target_layer",
      "instance_norm_targets",
      "layer_norm_targets",
      "batch_norm_target_layer",
      "group_norm_target_layer",
      "ema_decay",
      "ema_end_decay",
      "ema_anneal_end_step",
      "ema_transformer_only",
      "ema_layers_only",
      "min_target_var",
      "min_pred_var",
      "loss_beta",
      "loss_scale",
      "required_seq_len_multiple"
    ],
    "make_ema_teacher": [
      "self"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "apply_mask": [
      "self",
      "x",
      "padding_mask",
      "mask_indices",
      "mask_channel_indices"
    ],
    "_get_feat_extract_output_lengths": [
      "self",
      "input_lengths"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "mask",
      "features_only",
      "layer",
      "mask_indices",
      "mask_channel_indices",
      "padding_count"
    ],
    "compute_var": [
      "y"
    ],
    "extract_features": [
      "self",
      "xs_pad",
      "ilens",
      "mask",
      "layer"
    ],
    "remove_pretraining_modules": [
      "self",
      "last_layer"
    ],
    "output_size": [
      "self"
    ]
  },
  "ConvFeatureExtractionModel": {
    "__init__": [
      "self",
      "conv_layers",
      "dropout",
      "mode",
      "conv_bias",
      "in_d"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "make_conv_pos": [
    "e",
    "k",
    "g"
  ],
  "TransformerEncoder": {
    "build_encoder_layer": [
      "self"
    ],
    "__init__": [
      "self",
      "dropout",
      "encoder_embed_dim",
      "required_seq_len_multiple",
      "pos_conv_depth",
      "conv_pos",
      "conv_pos_groups",
      "layer_type",
      "encoder_layers",
      "encoder_ffn_embed_dim",
      "encoder_attention_heads",
      "attention_dropout",
      "activation_dropout",
      "activation_fn",
      "layer_norm_first",
      "encoder_layerdrop",
      "max_positions"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask",
      "layer"
    ],
    "extract_features": [
      "self",
      "x",
      "padding_mask",
      "tgt_layer",
      "min_layer"
    ],
    "max_positions": [
      "self"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "TransformerSentenceEncoderLayer": {
    "__init__": [
      "self",
      "embedding_dim",
      "ffn_embedding_dim",
      "num_attention_heads",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "activation_fn",
      "layer_norm_first"
    ],
    "forward": [
      "self",
      "x",
      "self_attn_mask",
      "self_attn_padding_mask"
    ]
  },
  "EMAModule": {
    "__init__": [
      "self",
      "model",
      "ema_decay",
      "ema_fp32",
      "device",
      "skip_keys"
    ],
    "build_fp32_params": [
      "self",
      "state_dict"
    ],
    "restore": [
      "self",
      "state_dict",
      "build_fp32_params"
    ],
    "set_decay": [
      "self",
      "decay"
    ],
    "get_decay": [
      "self"
    ],
    "_step_internal": [
      "self",
      "new_model"
    ],
    "step": [
      "self",
      "new_model"
    ],
    "reverse": [
      "self",
      "model"
    ]
  },
  "quant_noise": [
    "module",
    "p",
    "block_size"
  ],
  "Fp32LayerNorm": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Fp32GroupNorm": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TransposeLast": {
    "__init__": [
      "self",
      "deconstruct_idx"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SamePad": {
    "__init__": [
      "self",
      "kernel_size",
      "causal"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "pad_to_multiple": [
    "x",
    "multiple",
    "dim",
    "value"
  ],
  "gelu_accurate": [
    "x"
  ],
  "gelu": [
    "x"
  ],
  "get_available_activation_fns": [],
  "get_activation_fn": [
    "activation"
  ],
  "init_bert_params": [
    "module"
  ],
  "Data2VecPretrainModel": {
    "__init__": [
      "self",
      "frontend",
      "specaug",
      "normalize",
      "encoder",
      "preencoder"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "collect_feats": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "_extract_feats": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "get_num_updates": [
      "self"
    ]
  },
  "FairseqDropout": {
    "__init__": [
      "self",
      "p",
      "module_name"
    ],
    "forward": [
      "self",
      "x",
      "inplace"
    ],
    "make_generation_fast_": [
      "self",
      "name",
      "retain_dropout",
      "retain_dropout_modules"
    ]
  },
  "MultiheadAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "kdim",
      "vdim",
      "dropout",
      "bias",
      "add_bias_kv",
      "add_zero_attn",
      "self_attention",
      "encoder_decoder_attention",
      "q_noise",
      "qn_block_size"
    ],
    "prepare_for_onnx_export_": [
      "self"
    ],
    "reset_parameters": [
      "self"
    ],
    "_get_reserve_head_index": [
      "self",
      "num_heads_to_keep"
    ],
    "_adaptive_prune_heads": [
      "self",
      "reserve_head_index"
    ],
    "_set_skip_embed_dim_check": [
      "self"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask",
      "incremental_state",
      "need_weights",
      "static_kv",
      "attn_mask",
      "before_softmax",
      "need_head_weights"
    ],
    "_append_prev_key_padding_mask": [
      "key_padding_mask",
      "prev_key_padding_mask",
      "batch_size",
      "src_len",
      "static_kv"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "_get_input_buffer": [
      "self",
      "incremental_state"
    ],
    "_set_input_buffer": [
      "self",
      "incremental_state",
      "buffer"
    ],
    "apply_sparse_mask": [
      "self",
      "attn_weights",
      "tgt_len",
      "src_len",
      "bsz"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "GradMultiply": {
    "forward": [
      "ctx",
      "x",
      "scale"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "compute_mask_indices": [
    "shape",
    "padding_mask",
    "mask_prob",
    "mask_length",
    "mask_type",
    "mask_other",
    "min_masks",
    "no_overlap",
    "min_space",
    "require_same_masks",
    "mask_dropout"
  ],
  "LLMASRNAR": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "decoder",
      "decoder_conf",
      "ctc",
      "ctc_conf",
      "ctc_weight",
      "llm",
      "llm_conf",
      "adaptor",
      "adaptor_conf",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos",
      "lsm_weight",
      "length_normalized_loss",
      "report_cer",
      "report_wer",
      "sym_space",
      "sym_blank",
      "share_embedding"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths",
      "input_ids",
      "attention_mask",
      "labels_ids",
      "label_mask",
      "audio_mask"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "LLMASRNARPrompt": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "decoder",
      "decoder_conf",
      "ctc",
      "ctc_conf",
      "ctc_weight",
      "llm",
      "llm_conf",
      "adaptor",
      "adaptor_conf",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos",
      "lsm_weight",
      "length_normalized_loss",
      "predictor_weight",
      "report_cer",
      "report_wer",
      "sym_space",
      "sym_blank",
      "share_embedding"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths",
      "input_ids",
      "attention_mask",
      "labels_ids",
      "label_mask",
      "audio_mask"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "_calc_ctc_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "mark_only_lora_as_trainable": [
    "model",
    "bias"
  ],
  "lora_state_dict": [
    "model",
    "bias"
  ],
  "LoRALayer": {
    "__init__": [
      "self",
      "r",
      "lora_alpha",
      "lora_dropout",
      "merge_weights"
    ]
  },
  "Embedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "r",
      "lora_alpha",
      "merge_weights"
    ],
    "reset_parameters": [
      "self"
    ],
    "train": [
      "self",
      "mode"
    ],
    "eval": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MergedLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "r",
      "lora_alpha",
      "lora_dropout",
      "enable_lora",
      "fan_in_fan_out",
      "merge_weights"
    ],
    "reset_parameters": [
      "self"
    ],
    "zero_pad": [
      "self",
      "x"
    ],
    "train": [
      "self",
      "mode"
    ],
    "eval": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "r",
      "lora_alpha",
      "lora_dropout",
      "merge_weights"
    ],
    "reset_parameters": [
      "self"
    ],
    "train": [
      "self",
      "mode"
    ],
    "eval": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SpectralCluster": {
    "__init__": [
      "self",
      "min_num_spks",
      "max_num_spks",
      "pval"
    ],
    "__call__": [
      "self",
      "X",
      "oracle_num"
    ],
    "get_sim_mat": [
      "self",
      "X"
    ],
    "p_pruning": [
      "self",
      "A"
    ],
    "get_laplacian": [
      "self",
      "M"
    ],
    "get_spec_embs": [
      "self",
      "L",
      "k_oracle"
    ],
    "cluster_embs": [
      "self",
      "emb",
      "k"
    ],
    "getEigenGaps": [
      "self",
      "eig_vals"
    ]
  },
  "UmapHdbscan": {
    "__init__": [
      "self",
      "n_neighbors",
      "n_components",
      "min_samples",
      "min_cluster_size",
      "metric"
    ],
    "__call__": [
      "self",
      "X"
    ]
  },
  "ClusterBackend": {
    "__init__": [
      "self",
      "merge_thr"
    ],
    "forward": [
      "self",
      "X"
    ],
    "merge_by_cos": [
      "self",
      "labels",
      "embs",
      "cos_thr"
    ]
  },
  "BasicResBlock": {
    "expansion": [],
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FCM": {
    "__init__": [
      "self",
      "block",
      "num_blocks",
      "m_channels",
      "feat_dim"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "num_blocks",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_nonlinear": [
    "config_str",
    "channels"
  ],
  "statistics_pooling": [
    "x",
    "dim",
    "keepdim",
    "unbiased",
    "eps"
  ],
  "StatsPool": {
    "forward": [
      "self",
      "x"
    ]
  },
  "TDNNLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "config_str"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CAMLayer": {
    "__init__": [
      "self",
      "bn_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "reduction"
    ],
    "forward": [
      "self",
      "x"
    ],
    "seg_pooling": [
      "self",
      "x",
      "seg_len",
      "stype"
    ]
  },
  "CAMDenseTDNNLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bn_channels",
      "kernel_size",
      "stride",
      "dilation",
      "bias",
      "config_str",
      "memory_efficient"
    ],
    "bn_function": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CAMDenseTDNNBlock": {
    "__init__": [
      "self",
      "num_layers",
      "in_channels",
      "out_channels",
      "bn_channels",
      "kernel_size",
      "stride",
      "dilation",
      "bias",
      "config_str",
      "memory_efficient"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TransitLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bias",
      "config_str"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DenseLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bias",
      "config_str"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CAMPPlus": {
    "__init__": [
      "self",
      "feat_dim",
      "embedding_size",
      "growth_rate",
      "bn_size",
      "init_channels",
      "config_str",
      "memory_efficient",
      "output_level"
    ],
    "forward": [
      "self",
      "x"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "DecoderLayer": {
    "__init__": [
      "self",
      "size",
      "src_attn",
      "feed_forward",
      "dropout_rate",
      "normalize_before",
      "concat_after",
      "layer_id",
      "args"
    ],
    "forward": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "memory_mask",
      "cache"
    ]
  },
  "BaseTransformerDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "dropout_rate",
      "positional_dropout_rate",
      "input_layer",
      "use_output_layer",
      "pos_enc_class",
      "normalize_before"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens"
    ],
    "forward_one_step": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "cache"
    ],
    "score": [
      "self",
      "ys",
      "state",
      "x"
    ],
    "batch_score": [
      "self",
      "ys",
      "states",
      "xs"
    ]
  },
  "TransformerRWKVDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "self_attention_dropout_rate",
      "src_attention_dropout_rate",
      "input_layer",
      "use_output_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens"
    ],
    "forward_one_step": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "cache"
    ]
  },
  "ConvolutionalSpatialGatingUnit": {
    "__init__": [
      "self",
      "size",
      "kernel_size",
      "dropout_rate",
      "use_linear_after_conv",
      "gate_activation"
    ],
    "espnet_initialization_fn": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "gate_add"
    ]
  },
  "ConvolutionalGatingMLP": {
    "__init__": [
      "self",
      "size",
      "linear_units",
      "kernel_size",
      "dropout_rate",
      "use_linear_after_conv",
      "gate_activation"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "FastSelfAttention": {
    "__init__": [
      "self",
      "size",
      "attention_heads",
      "dropout_rate"
    ],
    "espnet_initialization_fn": [
      "self"
    ],
    "init_weights": [
      "self",
      "module"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "xs_pad",
      "mask"
    ]
  },
  "Branchformer": {
    "__init__": [
      "self"
    ]
  },
  "BranchformerEncoderLayer": {
    "__init__": [
      "self",
      "size",
      "attn",
      "cgmlp",
      "dropout_rate",
      "merge_method",
      "cgmlp_weight",
      "attn_branch_drop_rate",
      "stochastic_depth_rate"
    ],
    "forward": [
      "self",
      "x_input",
      "mask",
      "cache"
    ]
  },
  "BranchformerEncoder": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "use_attn",
      "attention_heads",
      "attention_layer_type",
      "pos_enc_layer_type",
      "rel_pos_type",
      "use_cgmlp",
      "cgmlp_linear_units",
      "cgmlp_conv_kernel",
      "use_linear_after_conv",
      "gate_activation",
      "merge_method",
      "cgmlp_weight",
      "attn_branch_drop_rate",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "attention_dropout_rate",
      "input_layer",
      "zero_triu",
      "padding_idx",
      "stochastic_depth_rate"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states"
    ]
  },
  "ContextualEmbedderExport": {
    "__init__": [
      "self",
      "model",
      "max_seq_len",
      "feats_dim"
    ],
    "forward": [
      "self",
      "hotword"
    ],
    "export_dummy_inputs": [
      "self"
    ],
    "export_input_names": [
      "self"
    ],
    "export_output_names": [
      "self"
    ],
    "export_dynamic_axes": [
      "self"
    ],
    "export_name": [
      "self"
    ]
  },
  "export_backbone_forward": [
    "self",
    "speech",
    "speech_lengths",
    "bias_embed"
  ],
  "export_backbone_dummy_inputs": [
    "self"
  ],
  "export_backbone_input_names": [
    "self"
  ],
  "export_backbone_output_names": [
    "self"
  ],
  "export_backbone_dynamic_axes": [
    "self"
  ],
  "SeacoParaformer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "_merge": [
      "self",
      "cif_attended",
      "dec_attended"
    ],
    "calc_predictor": [
      "self",
      "encoder_out",
      "encoder_out_lens"
    ],
    "_calc_seaco_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_lengths",
      "hotword_pad",
      "hotword_lengths",
      "seaco_label_pad"
    ],
    "_seaco_decode_with_ASF": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "sematic_embeds",
      "ys_pad_lens",
      "hw_list",
      "nfilter",
      "seaco_weight"
    ],
    "_hotword_representation": [
      "self",
      "hotword_pad",
      "hotword_lengths"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "generate_hotwords_list": [
      "self",
      "hotword_list_or_file",
      "tokenizer",
      "frontend"
    ],
    "export": [
      "self"
    ]
  },
  "split_to_mini_sentence": [
    "words",
    "word_limit"
  ],
  "split_words": [
    "text",
    "jieba_usr_dict"
  ],
  "isEnglish": [
    "text"
  ],
  "join_chinese_and_english": [
    "input_list"
  ],
  "CTTransformer": {
    "__init__": [
      "self",
      "encoder",
      "encoder_conf",
      "vocab_size",
      "punc_list",
      "punc_weight",
      "embed_unit",
      "att_unit",
      "dropout_rate",
      "ignore_id",
      "sos",
      "eos",
      "sentence_end_id"
    ],
    "punc_forward": [
      "self",
      "text",
      "text_lengths"
    ],
    "with_vad": [
      "self"
    ],
    "score": [
      "self",
      "y",
      "state",
      "x"
    ],
    "batch_score": [
      "self",
      "ys",
      "states",
      "xs"
    ],
    "nll": [
      "self",
      "text",
      "punc",
      "text_lengths",
      "punc_lengths",
      "max_length",
      "vad_indexes",
      "vad_indexes_lengths"
    ],
    "forward": [
      "self",
      "text",
      "punc",
      "text_lengths",
      "punc_lengths",
      "vad_indexes",
      "vad_indexes_lengths"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "export": [
      "self"
    ]
  },
  "ContextualEmbedderExport2": {
    "__init__": [
      "self",
      "model"
    ],
    "export_dummy_inputs": [
      "self"
    ]
  },
  "export_backbone_name": [
    "self"
  ],
  "ContextualDecoderLayer": {
    "__init__": [
      "self",
      "size",
      "self_attn",
      "src_attn",
      "feed_forward",
      "dropout_rate",
      "normalize_before",
      "concat_after"
    ],
    "forward": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "memory_mask",
      "cache"
    ]
  },
  "ContextualBiasDecoder": {
    "__init__": [
      "self",
      "size",
      "src_attn",
      "dropout_rate",
      "normalize_before"
    ],
    "forward": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "memory_mask",
      "cache"
    ]
  },
  "ContextualParaformerDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "self_attention_dropout_rate",
      "src_attention_dropout_rate",
      "input_layer",
      "use_output_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "att_layer_num",
      "kernel_size",
      "sanm_shfit"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens",
      "contextual_info",
      "clas_scale",
      "return_hidden"
    ]
  },
  "ContextualParaformerDecoderExport": {
    "__init__": [
      "self",
      "model",
      "max_seq_len",
      "model_name",
      "onnx"
    ],
    "prepare_mask": [
      "self",
      "mask"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens",
      "bias_embed"
    ]
  },
  "ContextualParaformer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "_calc_att_clas_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens",
      "hotword_pad",
      "hotword_lengths"
    ],
    "sampler": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens",
      "pre_acoustic_embeds",
      "contextual_info"
    ],
    "cal_decoder_with_predictor": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "sematic_embeds",
      "ys_pad_lens",
      "hw_list",
      "clas_scale"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "generate_hotwords_list": [
      "self",
      "hotword_list_or_file",
      "tokenizer",
      "frontend"
    ],
    "export": [
      "self"
    ]
  },
  "LabelAggregate": {
    "__init__": [
      "self",
      "win_length",
      "hop_length",
      "center"
    ],
    "extra_repr": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "ilens"
    ]
  },
  "LabelAggregateMaxPooling": {
    "__init__": [
      "self",
      "hop_length"
    ],
    "extra_repr": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "ilens"
    ]
  },
  "DenseDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "num_nodes_resnet1",
      "num_nodes_last_layer",
      "batchnorm_momentum"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "MultiHeadedAttention": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "dropout_rate"
    ],
    "forward_qkv": [
      "self",
      "query",
      "key",
      "value"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask"
    ]
  },
  "RelPositionMultiHeadedAttention": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "dropout_rate",
      "zero_triu"
    ],
    "rel_shift": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "pos_emb",
      "mask"
    ]
  },
  "MultiHeadSelfAttention": {
    "__init__": [
      "self",
      "n_head",
      "in_feat",
      "n_feat",
      "dropout_rate"
    ],
    "forward_qkv": [
      "self",
      "x"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask",
      "mask_att_chunk_encoder"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "mask_att_chunk_encoder"
    ]
  },
  "DiarSondModel": {
    "__init__": [
      "self",
      "vocab_size",
      "frontend",
      "specaug",
      "profileaug",
      "normalize",
      "encoder",
      "speaker_encoder",
      "ci_scorer",
      "cd_scorer",
      "decoder",
      "token_list",
      "lsm_weight",
      "length_normalized_loss",
      "max_spk_num",
      "label_aggregator",
      "normalize_speech_speaker",
      "ignore_id",
      "speaker_discrimination_loss_weight",
      "inter_score_loss_weight",
      "inputs_type",
      "model_regularizer_weight",
      "freeze_encoder",
      "onfly_shuffle_speaker"
    ],
    "get_regularize_parameters": [
      "self"
    ],
    "generate_pse_embedding": [
      "self"
    ],
    "rand_permute_speaker": [
      "self",
      "raw_profile",
      "raw_binary_labels"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "profile",
      "profile_lengths",
      "binary_labels",
      "binary_labels_lengths"
    ],
    "calculate_regularizer_loss": [
      "self"
    ],
    "classification_loss": [
      "self",
      "predictions",
      "labels",
      "prediction_lengths"
    ],
    "speaker_discrimination_loss": [
      "self",
      "profile",
      "profile_lengths"
    ],
    "calculate_multi_labels": [
      "self",
      "pse_labels",
      "pse_labels_lengths"
    ],
    "internal_score_loss": [
      "self",
      "cd_score",
      "ci_score",
      "pse_labels",
      "pse_labels_lengths"
    ],
    "collect_feats": [
      "self",
      "speech",
      "speech_lengths",
      "profile",
      "profile_lengths",
      "binary_labels",
      "binary_labels_lengths"
    ],
    "encode_speaker": [
      "self",
      "profile",
      "profile_lengths"
    ],
    "encode_speech": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "concate_speech_ivc": [
      "speech",
      "ivc"
    ],
    "calc_similarity": [
      "self",
      "speech_encoder_outputs",
      "speaker_encoder_outputs",
      "seq_len",
      "spk_len"
    ],
    "post_net_forward": [
      "self",
      "simi",
      "seq_len"
    ],
    "prediction_forward": [
      "self",
      "speech",
      "speech_lengths",
      "profile",
      "profile_lengths",
      "return_inter_outputs"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "_extract_feats": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "calc_diarization_error": [
      "pred",
      "label",
      "length"
    ]
  },
  "VAR2STD_EPSILON": [],
  "StatisticPooling": {
    "__init__": [
      "self",
      "pooling_dim",
      "eps"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens"
    ]
  },
  "statistic_pooling": [
    "xs_pad",
    "ilens",
    "pooling_dim"
  ],
  "windowed_statistic_pooling": [
    "xs_pad",
    "ilens",
    "pooling_dim",
    "pooling_size",
    "pooling_stride"
  ],
  "BasicLayer": {
    "__init__": [
      "self",
      "in_filters",
      "filters",
      "stride",
      "bn_momentum"
    ],
    "proper_padding": [
      "self",
      "x",
      "stride"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens"
    ]
  },
  "ResNet34": {
    "__init__": [
      "self",
      "input_size",
      "use_head_conv",
      "batchnorm_momentum",
      "use_head_maxpool",
      "num_nodes_pooling_layer",
      "layers_in_block",
      "filters_in_block"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states"
    ]
  },
  "ResNet34_SP_L2Reg": {
    "__init__": [
      "self",
      "input_size",
      "use_head_conv",
      "batchnorm_momentum",
      "use_head_maxpool",
      "num_nodes_pooling_layer",
      "layers_in_block",
      "filters_in_block",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf",
      "tf_train_steps"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states"
    ]
  },
  "ResNet34Diar": {
    "__init__": [
      "self",
      "input_size",
      "embedding_node",
      "use_head_conv",
      "batchnorm_momentum",
      "use_head_maxpool",
      "num_nodes_pooling_layer",
      "layers_in_block",
      "filters_in_block",
      "num_nodes_resnet1",
      "num_nodes_last_layer",
      "pooling_type",
      "pool_size",
      "stride",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states"
    ]
  },
  "ResNet34SpL2RegDiar": {
    "__init__": [
      "self",
      "input_size",
      "embedding_node",
      "use_head_conv",
      "batchnorm_momentum",
      "use_head_maxpool",
      "num_nodes_pooling_layer",
      "layers_in_block",
      "filters_in_block",
      "num_nodes_resnet1",
      "num_nodes_last_layer",
      "pooling_type",
      "pool_size",
      "stride",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states"
    ]
  },
  "DotScorer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "spk_emb"
    ]
  },
  "CosScorer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "spk_emb"
    ]
  },
  "_BatchNorm1d": {
    "__init__": [
      "self",
      "input_shape",
      "input_size",
      "eps",
      "momentum",
      "affine",
      "track_running_stats",
      "combine_batch_time",
      "skip_transpose"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_Conv1d": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "input_shape",
      "in_channels",
      "stride",
      "dilation",
      "padding",
      "groups",
      "bias",
      "padding_mode",
      "skip_transpose"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_manage_padding": [
      "self",
      "x",
      "kernel_size",
      "dilation",
      "stride"
    ],
    "_check_input_shape": [
      "self",
      "shape"
    ]
  },
  "get_padding_elem": [
    "L_in",
    "stride",
    "kernel_size",
    "dilation"
  ],
  "BatchNorm1d": {
    "__init__": [
      "self"
    ]
  },
  "length_to_mask": [
    "length",
    "max_len",
    "dtype",
    "device"
  ],
  "TDNNBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dilation",
      "activation",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Res2NetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "scale",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SEBlock": {
    "__init__": [
      "self",
      "in_channels",
      "se_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "AttentiveStatisticsPooling": {
    "__init__": [
      "self",
      "channels",
      "attention_channels",
      "global_context"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "SERes2NetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "res2net_scale",
      "se_channels",
      "kernel_size",
      "dilation",
      "activation",
      "groups"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "ECAPA_TDNN": {
    "__init__": [
      "self",
      "input_size",
      "lin_neurons",
      "activation",
      "channels",
      "kernel_sizes",
      "dilations",
      "attention_channels",
      "res2net_scale",
      "se_channels",
      "global_context",
      "groups",
      "window_size",
      "window_shift"
    ],
    "windowed_pooling": [
      "self",
      "x",
      "lengths"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "SelfAttentionEncoder": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "attention_dropout_rate",
      "input_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "positionwise_layer_type",
      "positionwise_conv_kernel_size",
      "padding_idx",
      "interctc_layer_idx",
      "interctc_use_conditioning",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf",
      "out_units"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states",
      "ctc"
    ]
  },
  "ConvEncoder": {
    "__init__": [
      "self",
      "num_layers",
      "input_units",
      "num_units",
      "kernel_size",
      "dropout_rate",
      "position_encoder",
      "activation",
      "auxiliary_states",
      "out_units",
      "out_norm",
      "out_residual",
      "include_batchnorm",
      "regularization_weight",
      "stride",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states"
    ]
  },
  "FsmnBlock": {
    "__init__": [
      "self",
      "n_feat",
      "dropout_rate",
      "kernel_size",
      "fsmn_shift"
    ],
    "forward": [
      "self",
      "inputs",
      "mask",
      "mask_shfit_chunk"
    ]
  },
  "FsmnEncoder": {
    "__init__": [
      "self",
      "in_units",
      "filter_size",
      "fsmn_num_layers",
      "dnn_num_layers",
      "num_memory_units",
      "ffn_inner_dim",
      "dropout_rate",
      "shift",
      "position_encoder",
      "sample_rate",
      "out_units",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states"
    ]
  },
  "WhisperWarp": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "SanmKWSStreaming": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode_chunk": [
      "self",
      "speech",
      "speech_lengths",
      "cache"
    ],
    "init_cache": [
      "self",
      "cache"
    ],
    "generate_chunk": [
      "self",
      "speech",
      "speech_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend",
      "cache"
    ],
    "export": [
      "self"
    ]
  },
  "BiCifParaformer": {
    "__init__": [
      "self"
    ],
    "_calc_pre2_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "_calc_att_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "calc_predictor": [
      "self",
      "encoder_out",
      "encoder_out_lens"
    ],
    "calc_predictor_timestamp": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "token_num"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "export": [
      "self"
    ]
  },
  "CifPredictorV3": {
    "__init__": [
      "self",
      "idim",
      "l_order",
      "r_order",
      "threshold",
      "dropout",
      "smooth_factor",
      "noise_threshold",
      "tail_threshold",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf",
      "smooth_factor2",
      "noise_threshold2",
      "upsample_times",
      "upsample_type",
      "use_cif1_cnn",
      "tail_mask"
    ],
    "forward": [
      "self",
      "hidden",
      "target_label",
      "mask",
      "ignore_id",
      "mask_chunk_predictor",
      "target_label_length"
    ],
    "get_upsample_timestamp": [
      "self",
      "hidden",
      "mask",
      "token_num"
    ],
    "tail_process_fn": [
      "self",
      "hidden",
      "alphas",
      "token_num",
      "mask"
    ],
    "gen_frame_alignments": [
      "self",
      "alphas",
      "encoder_sequence_length"
    ]
  },
  "CifPredictorV3Export": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "hidden",
      "mask"
    ],
    "get_upsample_timestmap": [
      "self",
      "hidden",
      "mask",
      "token_num"
    ],
    "tail_process_fn": [
      "self",
      "hidden",
      "alphas",
      "token_num",
      "mask"
    ]
  },
  "cif_wo_hidden_export": [
    "alphas",
    "threshold"
  ],
  "drop_and_add": [
    "inputs",
    "outputs",
    "training",
    "dropout_rate",
    "stoch_layer_coeff"
  ],
  "proc_tf_vocab": [
    "vocab_path"
  ],
  "gen_config_for_tfmodel": [
    "config_path",
    "vocab_path",
    "output_dir"
  ],
  "NoAliasSafeDumper": {
    "ignore_aliases": [
      "self",
      "data"
    ]
  },
  "yaml_no_alias_safe_dump": [
    "data",
    "stream"
  ],
  "FsmnDecoderSCAMAOpt": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "self_attention_dropout_rate",
      "src_attention_dropout_rate",
      "input_layer",
      "use_output_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "att_layer_num",
      "kernel_size",
      "sanm_shfit",
      "concat_embeds",
      "attention_dim",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf",
      "embed_tensor_name_prefix_tf"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens",
      "chunk_mask",
      "pre_acoustic_embeds"
    ],
    "score": [
      "self",
      "ys",
      "state",
      "x",
      "x_mask",
      "pre_acoustic_embeds"
    ],
    "forward_one_step": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "memory_mask",
      "pre_acoustic_embeds",
      "cache"
    ]
  },
  "SCAMA": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "decoder",
      "decoder_conf",
      "ctc",
      "ctc_conf",
      "ctc_weight",
      "predictor",
      "predictor_conf",
      "predictor_bias",
      "predictor_weight",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos",
      "lsm_weight",
      "length_normalized_loss",
      "share_embedding"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "encode_chunk": [
      "self",
      "speech",
      "speech_lengths",
      "cache"
    ],
    "calc_predictor_chunk": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "cache"
    ],
    "_calc_att_predictor_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "calc_predictor_mask": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "init_beam_search": [
      "self"
    ],
    "generate_chunk": [
      "self",
      "speech",
      "speech_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "init_cache": [
      "self",
      "cache"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend",
      "cache"
    ]
  },
  "BeamSearchScama": {
    "__init__": [
      "self",
      "scorers",
      "weights",
      "beam_size",
      "vocab_size",
      "sos",
      "eos",
      "token_list",
      "pre_beam_ratio",
      "pre_beam_score_key"
    ],
    "init_hyp": [
      "self",
      "x"
    ],
    "append_token": [
      "xs",
      "x"
    ],
    "score_full": [
      "self",
      "hyp",
      "x",
      "x_mask",
      "pre_acoustic_embeds"
    ],
    "score_partial": [
      "self",
      "hyp",
      "ids",
      "x"
    ],
    "beam": [
      "self",
      "weighted_scores",
      "ids"
    ],
    "merge_scores": [
      "prev_scores",
      "next_full_scores",
      "full_idx",
      "next_part_scores",
      "part_idx"
    ],
    "merge_states": [
      "self",
      "states",
      "part_states",
      "part_idx"
    ],
    "search": [
      "self",
      "running_hyps",
      "x",
      "x_mask",
      "pre_acoustic_embeds"
    ],
    "forward": [
      "self",
      "x",
      "scama_mask",
      "pre_acoustic_embeds",
      "maxlenratio",
      "minlenratio",
      "maxlen",
      "minlen"
    ],
    "post_process": [
      "self",
      "i",
      "maxlen",
      "maxlenratio",
      "running_hyps",
      "ended_hyps"
    ]
  },
  "BeamSearchScamaStreaming": {
    "__init__": [
      "self",
      "scorers",
      "weights",
      "beam_size",
      "vocab_size",
      "sos",
      "eos",
      "token_list",
      "pre_beam_ratio",
      "pre_beam_score_key"
    ],
    "init_hyp": [
      "self",
      "x"
    ],
    "append_token": [
      "xs",
      "x"
    ],
    "score_full": [
      "self",
      "hyp",
      "x",
      "x_mask",
      "pre_acoustic_embeds",
      "cache"
    ],
    "score_partial": [
      "self",
      "hyp",
      "ids",
      "x"
    ],
    "beam": [
      "self",
      "weighted_scores",
      "ids"
    ],
    "merge_scores": [
      "prev_scores",
      "next_full_scores",
      "full_idx",
      "next_part_scores",
      "part_idx"
    ],
    "merge_states": [
      "self",
      "states",
      "part_states",
      "part_idx"
    ],
    "search": [
      "self",
      "running_hyps",
      "x",
      "x_mask",
      "pre_acoustic_embeds",
      "cache"
    ],
    "forward": [
      "self",
      "x",
      "scama_mask",
      "pre_acoustic_embeds",
      "maxlenratio",
      "minlenratio",
      "maxlen",
      "minlen",
      "cache"
    ],
    "post_process": [
      "self",
      "i",
      "maxlen",
      "maxlenratio",
      "running_hyps",
      "ended_hyps"
    ]
  },
  "SANMEncoderChunkOpt": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "attention_dropout_rate",
      "input_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "positionwise_layer_type",
      "positionwise_conv_kernel_size",
      "padding_idx",
      "interctc_layer_idx",
      "interctc_use_conditioning",
      "kernel_size",
      "sanm_shfit",
      "selfattention_layer_type",
      "chunk_size",
      "stride",
      "pad_left",
      "encoder_att_look_back_factor",
      "decoder_att_look_back_factor",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states",
      "ctc",
      "ind"
    ],
    "_add_overlap_chunk": [
      "self",
      "feats",
      "cache"
    ],
    "forward_chunk": [
      "self",
      "xs_pad",
      "ilens",
      "cache"
    ]
  },
  "overlap_chunk": {
    "__init__": [
      "self",
      "chunk_size",
      "stride",
      "pad_left",
      "encoder_att_look_back_factor",
      "shfit_fsmn",
      "decoder_att_look_back_factor"
    ],
    "check_chunk_size_args": [
      "self",
      "chunk_size",
      "x"
    ],
    "get_chunk_size": [
      "self",
      "ind"
    ],
    "random_choice": [
      "self",
      "training",
      "decoding_ind"
    ],
    "gen_chunk_mask": [
      "self",
      "x_len",
      "ind",
      "num_units",
      "num_units_predictor"
    ],
    "split_chunk": [
      "self",
      "x",
      "x_len",
      "chunk_outs"
    ],
    "remove_chunk": [
      "self",
      "x_chunk",
      "x_len_chunk",
      "chunk_outs"
    ],
    "get_x_add_mask": [
      "self",
      "chunk_outs",
      "device",
      "idx",
      "dtype"
    ],
    "get_x_len_chunk": [
      "self",
      "chunk_outs",
      "device",
      "idx",
      "dtype"
    ],
    "get_x_rm_mask": [
      "self",
      "chunk_outs",
      "device",
      "idx",
      "dtype"
    ],
    "get_x_len": [
      "self",
      "chunk_outs",
      "device",
      "idx",
      "dtype"
    ],
    "get_mask_shfit_chunk": [
      "self",
      "chunk_outs",
      "device",
      "batch_size",
      "num_units",
      "idx",
      "dtype"
    ],
    "get_mask_chunk_predictor": [
      "self",
      "chunk_outs",
      "device",
      "batch_size",
      "num_units",
      "idx",
      "dtype"
    ],
    "get_mask_att_chunk_encoder": [
      "self",
      "chunk_outs",
      "device",
      "batch_size",
      "idx",
      "dtype"
    ],
    "get_mask_shift_att_chunk_decoder": [
      "self",
      "chunk_outs",
      "device",
      "batch_size",
      "idx",
      "dtype"
    ]
  },
  "build_scama_mask_for_cross_attention_decoder": [
    "predictor_alignments",
    "encoder_sequence_length",
    "chunk_size",
    "encoder_chunk_size",
    "attention_chunk_center_bias",
    "attention_chunk_size",
    "attention_chunk_type",
    "step",
    "predictor_mask_chunk_hopping",
    "decoder_att_look_back_factor",
    "mask_shift_att_chunk_decoder",
    "target_length",
    "is_training",
    "dtype"
  ],
  "MonotonicAligner": {
    "__init__": [
      "self",
      "input_size",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "predictor",
      "predictor_conf",
      "predictor_bias",
      "length_normalized_loss"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "calc_predictor_timestamp": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "token_num"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "export_decoder_forward": [
    "self",
    "enc",
    "enc_len",
    "acoustic_embeds",
    "acoustic_embeds_len"
  ],
  "export_decoder_dummy_inputs": [
    "self"
  ],
  "export_decoder_input_names": [
    "self"
  ],
  "export_decoder_output_names": [
    "self"
  ],
  "export_decoder_dynamic_axes": [
    "self"
  ],
  "export_decoder_name": [
    "self"
  ],
  "ParaformerStreaming": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode_chunk": [
      "self",
      "speech",
      "speech_lengths",
      "cache"
    ],
    "_calc_att_predictor_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "sampler": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens",
      "pre_acoustic_embeds",
      "chunk_mask"
    ],
    "calc_predictor": [
      "self",
      "encoder_out",
      "encoder_out_lens"
    ],
    "calc_predictor_chunk": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "cache"
    ],
    "cal_decoder_with_predictor": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "sematic_embeds",
      "ys_pad_lens"
    ],
    "cal_decoder_with_predictor_chunk": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "sematic_embeds",
      "ys_pad_lens",
      "cache"
    ],
    "init_cache": [
      "self",
      "cache"
    ],
    "generate_chunk": [
      "self",
      "speech",
      "speech_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend",
      "cache"
    ],
    "export": [
      "self"
    ]
  },
  "UniASR": {
    "__init__": [
      "self",
      "specaug",
      "specaug_conf",
      "normalize",
      "normalize_conf",
      "encoder",
      "encoder_conf",
      "encoder2",
      "encoder2_conf",
      "decoder",
      "decoder_conf",
      "decoder2",
      "decoder2_conf",
      "predictor",
      "predictor_conf",
      "predictor_bias",
      "predictor_weight",
      "predictor2",
      "predictor2_conf",
      "predictor2_bias",
      "predictor2_weight",
      "ctc",
      "ctc_conf",
      "ctc_weight",
      "ctc2",
      "ctc2_conf",
      "ctc2_weight",
      "decoder_attention_chunk_type",
      "decoder_attention_chunk_type2",
      "stride_conv",
      "stride_conv_conf",
      "loss_weight_model1",
      "input_size",
      "vocab_size",
      "ignore_id",
      "blank_id",
      "sos",
      "eos",
      "lsm_weight",
      "length_normalized_loss",
      "share_embedding"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "collect_feats": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "encode2": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "speech",
      "speech_lengths"
    ],
    "nll": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "batchify_nll": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens",
      "batch_size"
    ],
    "_calc_att_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "_calc_att_predictor_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "_calc_att_predictor_loss2": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "calc_predictor_mask": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "calc_predictor_mask2": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "init_beam_search": [
      "self"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "MFCCAEncoder": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "attention_dropout_rate",
      "input_layer",
      "normalize_before",
      "concat_after",
      "positionwise_layer_type",
      "positionwise_conv_kernel_size",
      "macaron_style",
      "rel_pos_type",
      "pos_enc_layer_type",
      "selfattention_layer_type",
      "activation_type",
      "use_cnn_module",
      "zero_triu",
      "cnn_module_kernel",
      "padding_idx"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "channel_size",
      "prev_states"
    ],
    "forward_hidden": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states"
    ]
  },
  "Encoder_Conformer_Layer": {
    "__init__": [
      "self",
      "size",
      "self_attn",
      "feed_forward",
      "feed_forward_macaron",
      "conv_module",
      "dropout_rate",
      "normalize_before",
      "concat_after",
      "cca_pos"
    ],
    "forward": [
      "self",
      "x_input",
      "mask",
      "cache"
    ]
  },
  "MFCCA": {
    "__init__": [
      "self",
      "vocab_size",
      "token_list",
      "frontend",
      "specaug",
      "normalize",
      "encoder",
      "decoder",
      "ctc",
      "rnnt_decoder",
      "ctc_weight",
      "ignore_id",
      "lsm_weight",
      "mask_ratio",
      "length_normalized_loss",
      "report_cer",
      "report_wer",
      "sym_space",
      "sym_blank",
      "preencoder"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "collect_feats": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "_extract_feats": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "_calc_att_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "_calc_ctc_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "_calc_rnnt_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ]
  },
  "_pre_hook": [
    "state_dict",
    "prefix",
    "local_metadata",
    "strict",
    "missing_keys",
    "unexpected_keys",
    "error_msgs"
  ],
  "PositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate",
      "max_len",
      "reverse"
    ],
    "extend_pe": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ScaledPositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate",
      "max_len"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LearnableFourierPosEnc": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate",
      "max_len",
      "gamma",
      "apply_scaling",
      "hidden_dim"
    ],
    "_reset": [
      "self"
    ],
    "extend_pe": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LegacyRelPositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate",
      "max_len"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RelPositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate",
      "max_len"
    ],
    "extend_pe": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StreamPositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate",
      "max_len"
    ],
    "extend_pe": [
      "self",
      "length",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "x",
      "start_idx"
    ]
  },
  "StreamSinusoidalPositionEncoder": {
    "__int__": [
      "self",
      "d_model",
      "dropout_rate"
    ],
    "encode": [
      "self",
      "positions",
      "depth",
      "dtype"
    ],
    "forward": [
      "self",
      "x",
      "cache"
    ]
  },
  "StreamingRelPositionalEncoding": {
    "__init__": [
      "self",
      "size",
      "dropout_rate",
      "max_len"
    ],
    "extend_pe": [
      "self",
      "x",
      "left_context"
    ],
    "forward": [
      "self",
      "x",
      "left_context"
    ]
  },
  "ScaledSinuEmbedding": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BeamSearch": {
    "__init__": [
      "self",
      "scorers",
      "weights",
      "beam_size",
      "vocab_size",
      "sos",
      "eos",
      "token_list",
      "pre_beam_ratio",
      "pre_beam_score_key"
    ],
    "init_hyp": [
      "self",
      "x"
    ],
    "append_token": [
      "xs",
      "x"
    ],
    "score_full": [
      "self",
      "hyp",
      "x"
    ],
    "score_partial": [
      "self",
      "hyp",
      "ids",
      "x"
    ],
    "beam": [
      "self",
      "weighted_scores",
      "ids"
    ],
    "merge_scores": [
      "prev_scores",
      "next_full_scores",
      "full_idx",
      "next_part_scores",
      "part_idx"
    ],
    "merge_states": [
      "self",
      "states",
      "part_states",
      "part_idx"
    ],
    "search": [
      "self",
      "running_hyps",
      "x"
    ],
    "forward": [
      "self",
      "x",
      "maxlenratio",
      "minlenratio"
    ],
    "post_process": [
      "self",
      "i",
      "maxlen",
      "maxlenratio",
      "running_hyps",
      "ended_hyps"
    ]
  },
  "DecoderLayerExport": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "memory_mask",
      "cache"
    ]
  },
  "TransformerDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "self_attention_dropout_rate",
      "src_attention_dropout_rate",
      "input_layer",
      "use_output_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after"
    ]
  },
  "LightweightConvolutionTransformerDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "self_attention_dropout_rate",
      "src_attention_dropout_rate",
      "input_layer",
      "use_output_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "conv_wshare",
      "conv_kernel_length",
      "conv_usebias"
    ]
  },
  "LightweightConvolution2DTransformerDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "self_attention_dropout_rate",
      "src_attention_dropout_rate",
      "input_layer",
      "use_output_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "conv_wshare",
      "conv_kernel_length",
      "conv_usebias"
    ]
  },
  "DynamicConvolutionTransformerDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "self_attention_dropout_rate",
      "src_attention_dropout_rate",
      "input_layer",
      "use_output_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "conv_wshare",
      "conv_kernel_length",
      "conv_usebias"
    ]
  },
  "DynamicConvolution2DTransformerDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "self_attention_dropout_rate",
      "src_attention_dropout_rate",
      "input_layer",
      "use_output_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "conv_wshare",
      "conv_kernel_length",
      "conv_usebias"
    ]
  },
  "GlobalLayerNorm": {
    "__init__": [
      "self",
      "dim",
      "shape",
      "eps",
      "elementwise_affine"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CumulativeLayerNorm": {
    "__init__": [
      "self",
      "dim",
      "elementwise_affine"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ScaleNorm": {
    "__init__": [
      "self",
      "dim",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MultiHeadedAttentionExport": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward_qkv": [
      "self",
      "query",
      "key",
      "value"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask"
    ]
  },
  "RelPosMultiHeadedAttentionExport": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "pos_emb",
      "mask"
    ],
    "rel_shift": [
      "self",
      "x"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask"
    ]
  },
  "LegacyRelPositionMultiHeadedAttention": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "dropout_rate",
      "zero_triu"
    ],
    "rel_shift": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "pos_emb",
      "mask"
    ]
  },
  "RelPositionMultiHeadedAttentionChunk": {
    "__init__": [
      "self",
      "num_heads",
      "embed_size",
      "dropout_rate",
      "simplified_attention_score"
    ],
    "rel_shift": [
      "self",
      "x",
      "left_context"
    ],
    "compute_simplified_attention_score": [
      "self",
      "query",
      "key",
      "pos_enc",
      "left_context"
    ],
    "compute_attention_score": [
      "self",
      "query",
      "key",
      "pos_enc",
      "left_context"
    ],
    "forward_qkv": [
      "self",
      "query",
      "key",
      "value"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask",
      "chunk_mask"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "pos_enc",
      "mask",
      "chunk_mask",
      "left_context"
    ]
  },
  "PositionwiseFeedForwardDecoderSANMExport": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ScorerInterface": {
    "init_state": [
      "self",
      "x"
    ],
    "select_state": [
      "self",
      "state",
      "i",
      "new_id"
    ],
    "score": [
      "self",
      "y",
      "state",
      "x"
    ],
    "final_score": [
      "self",
      "state"
    ]
  },
  "BatchScorerInterface": {
    "batch_init_state": [
      "self",
      "x"
    ],
    "batch_score": [
      "self",
      "ys",
      "states",
      "xs"
    ]
  },
  "PartialScorerInterface": {
    "score_partial": [
      "self",
      "y",
      "next_tokens",
      "state",
      "x"
    ]
  },
  "BatchPartialScorerInterface": {
    "batch_score_partial": [
      "self",
      "ys",
      "next_tokens",
      "states",
      "xs"
    ]
  },
  "LengthBonus": {
    "__init__": [
      "self",
      "n_vocab"
    ],
    "score": [
      "self",
      "y",
      "state",
      "x"
    ],
    "batch_score": [
      "self",
      "ys",
      "states",
      "xs"
    ]
  },
  "CTCPrefixScoreTH": {
    "__init__": [
      "self",
      "x",
      "xlens",
      "blank",
      "eos",
      "margin"
    ],
    "__call__": [
      "self",
      "y",
      "state",
      "scoring_ids",
      "att_w"
    ],
    "index_select_state": [
      "self",
      "state",
      "best_ids"
    ],
    "extend_prob": [
      "self",
      "x"
    ],
    "extend_state": [
      "self",
      "state"
    ]
  },
  "CTCPrefixScore": {
    "__init__": [
      "self",
      "x",
      "blank",
      "eos",
      "xp"
    ],
    "initial_state": [
      "self"
    ],
    "__call__": [
      "self",
      "y",
      "cs",
      "r_prev"
    ]
  },
  "CTCPrefixScorer": {
    "__init__": [
      "self",
      "ctc",
      "eos"
    ],
    "init_state": [
      "self",
      "x"
    ],
    "select_state": [
      "self",
      "state",
      "i",
      "new_id"
    ],
    "score_partial": [
      "self",
      "y",
      "ids",
      "state",
      "x"
    ],
    "batch_init_state": [
      "self",
      "x"
    ],
    "batch_score_partial": [
      "self",
      "y",
      "ids",
      "state",
      "x"
    ],
    "extend_prob": [
      "self",
      "x"
    ],
    "extend_state": [
      "self",
      "state"
    ]
  },
  "TooShortUttError": {
    "__init__": [
      "self",
      "message",
      "actual_size",
      "limit"
    ]
  },
  "check_short_utt": [
    "ins",
    "size"
  ],
  "Conv2dSubsampling": {
    "__init__": [
      "self",
      "idim",
      "odim",
      "dropout_rate",
      "pos_enc"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ],
    "__getitem__": [
      "self",
      "key"
    ]
  },
  "Conv2dSubsamplingPad": {
    "__init__": [
      "self",
      "idim",
      "odim",
      "dropout_rate",
      "pos_enc"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ],
    "__getitem__": [
      "self",
      "key"
    ]
  },
  "Conv2dSubsampling2": {
    "__init__": [
      "self",
      "idim",
      "odim",
      "dropout_rate",
      "pos_enc"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ],
    "__getitem__": [
      "self",
      "key"
    ]
  },
  "Conv2dSubsampling6": {
    "__init__": [
      "self",
      "idim",
      "odim",
      "dropout_rate",
      "pos_enc"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "Conv2dSubsampling8": {
    "__init__": [
      "self",
      "idim",
      "odim",
      "dropout_rate",
      "pos_enc"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "Conv1dSubsampling": {
    "__init__": [
      "self",
      "idim",
      "odim",
      "kernel_size",
      "stride",
      "pad",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "x_len"
    ]
  },
  "StreamingConvInput": {
    "__init__": [
      "self",
      "input_size",
      "conv_size",
      "subsampling_factor",
      "vgg_like",
      "conv_kernel_size",
      "output_size"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "chunk_size"
    ],
    "create_new_vgg_mask": [
      "self",
      "mask"
    ],
    "create_new_conv2d_mask": [
      "self",
      "mask"
    ],
    "get_size_before_subsampling": [
      "self",
      "size"
    ]
  },
  "MultiSequential": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "repeat": [
    "N",
    "fn",
    "layer_drop_rate"
  ],
  "MultiBlocks": {
    "__init__": [
      "self",
      "block_list",
      "output_size",
      "norm_class"
    ],
    "reset_streaming_cache": [
      "self",
      "left_context",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "pos_enc",
      "mask",
      "chunk_mask"
    ],
    "chunk_forward": [
      "self",
      "x",
      "pos_enc",
      "mask",
      "chunk_size",
      "left_context",
      "right_context"
    ]
  },
  "target_mask": [
    "ys_in_pad",
    "ignore_id"
  ],
  "vad_mask": [
    "size",
    "vad_pos",
    "device",
    "dtype"
  ],
  "MIN_VALUE": [],
  "DynamicConvolution": {
    "__init__": [
      "self",
      "wshare",
      "n_feat",
      "dropout_rate",
      "kernel_size",
      "use_kernel_mask",
      "use_bias"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask"
    ]
  },
  "VGG2L": {
    "__init__": [
      "self",
      "idim",
      "odim",
      "pos_enc"
    ],
    "forward": [
      "self",
      "feats",
      "feats_mask"
    ],
    "create_new_mask": [
      "self",
      "feats_mask"
    ]
  },
  "add_sos_eos": [
    "ys_pad",
    "sos",
    "eos",
    "ignore_id"
  ],
  "LightweightConvolution2D": {
    "__init__": [
      "self",
      "wshare",
      "n_feat",
      "dropout_rate",
      "kernel_size",
      "use_kernel_mask",
      "use_bias"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask"
    ]
  },
  "DynamicConvolution2D": {
    "__init__": [
      "self",
      "wshare",
      "n_feat",
      "dropout_rate",
      "kernel_size",
      "use_kernel_mask",
      "use_bias"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask"
    ]
  },
  "Conv2dSubsamplingWOPosEnc": {
    "__init__": [
      "self",
      "idim",
      "odim",
      "dropout_rate",
      "kernels",
      "strides"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "LightweightConvolution": {
    "__init__": [
      "self",
      "wshare",
      "n_feat",
      "dropout_rate",
      "kernel_size",
      "use_kernel_mask",
      "use_bias"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask"
    ]
  },
  "MultiLayeredConv1d": {
    "__init__": [
      "self",
      "in_chans",
      "hidden_chans",
      "kernel_size",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FsmnFeedForward": {
    "__init__": [
      "self",
      "in_chans",
      "hidden_chans",
      "out_chans",
      "kernel_size",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "x",
      "ilens"
    ]
  },
  "Conv1dLinear": {
    "__init__": [
      "self",
      "in_chans",
      "hidden_chans",
      "kernel_size",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "pad_list": [
    "xs",
    "pad_value"
  ],
  "pad_list_all_dim": [
    "xs",
    "pad_value"
  ],
  "make_pad_mask": [
    "lengths",
    "xs",
    "length_dim",
    "maxlen"
  ],
  "make_non_pad_mask": [
    "lengths",
    "xs",
    "length_dim"
  ],
  "mask_by_length": [
    "xs",
    "lengths",
    "fill"
  ],
  "to_torch_tensor": [
    "x"
  ],
  "get_subsample": [
    "train_args",
    "mode",
    "arch"
  ],
  "rename_state_dict": [
    "old_prefix",
    "new_prefix",
    "state_dict"
  ],
  "Swish": {
    "__init__": [
      "self",
      "beta",
      "use_builtin"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_activation": [
    "act"
  ],
  "sub_factor_to_params": [
    "sub_factor",
    "input_size"
  ],
  "make_chunk_mask": [
    "size",
    "chunk_size",
    "left_chunk_size",
    "device"
  ],
  "make_source_mask": [
    "lengths"
  ],
  "get_transducer_task_io": [
    "labels",
    "encoder_out_lens",
    "ignore_id",
    "blank_id"
  ],
  "pad_to_len": [
    "t",
    "pad_len",
    "dim"
  ],
  "EncoderDecoderAttractor": {
    "__init__": [
      "self",
      "n_units",
      "encoder_dropout",
      "decoder_dropout"
    ],
    "forward_core": [
      "self",
      "xs",
      "zeros"
    ],
    "forward": [
      "self",
      "xs",
      "n_speakers"
    ],
    "estimate": [
      "self",
      "xs",
      "max_n_speakers"
    ]
  },
  "EENDOLATransformerEncoder": {
    "__init__": [
      "self",
      "idim",
      "n_layers",
      "n_units",
      "e_units",
      "h",
      "dropout_rate",
      "use_pos_emb"
    ],
    "__call__": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "pad_attractor": [
    "att",
    "max_n_speakers"
  ],
  "pad_labels": [
    "ts",
    "out_size"
  ],
  "pad_results": [
    "ys",
    "out_size"
  ],
  "DiarEENDOLAModel": {
    "__init__": [
      "self",
      "frontend",
      "encoder",
      "encoder_decoder_attractor",
      "n_units",
      "max_n_speaker",
      "attractor_loss_weight",
      "mapping_dict"
    ],
    "forward_encoder": [
      "self",
      "xs",
      "ilens"
    ],
    "forward_post_net": [
      "self",
      "logits",
      "ilens"
    ],
    "forward": [
      "self",
      "speech",
      "speaker_labels",
      "orders"
    ],
    "estimate_sequential": [
      "self",
      "speech",
      "n_speakers",
      "shuffle",
      "threshold"
    ],
    "recover_y_from_powerlabel": [
      "self",
      "logit",
      "n_speaker"
    ],
    "inv_mapping_func": [
      "self",
      "label"
    ],
    "collect_feats": [
      "self"
    ]
  },
  "custom_collate": [
    "batch"
  ],
  "EENDOLADataset": {
    "__init__": [
      "self",
      "data_file"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "EENDOLADataLoader": {
    "__init__": [
      "self",
      "data_file",
      "batch_size",
      "shuffle",
      "num_workers"
    ],
    "build_iter": [
      "self",
      "epoch"
    ]
  },
  "standard_loss": [
    "ys",
    "ts"
  ],
  "fast_batch_pit_n_speaker_loss": [
    "ys",
    "ts"
  ],
  "cal_power_loss": [
    "logits",
    "power_ts"
  ],
  "get_input_dim": [
    "frame_size",
    "context_size",
    "transform_type"
  ],
  "_count_frames": [
    "data_len",
    "size",
    "shift"
  ],
  "get_frame_labels": [
    "kaldi_obj",
    "rec",
    "start",
    "end",
    "frame_size",
    "frame_shift",
    "n_speakers"
  ],
  "get_labeledSTFT": [
    "kaldi_obj",
    "rec",
    "start",
    "end",
    "frame_size",
    "frame_shift",
    "n_speakers",
    "use_speaker_id"
  ],
  "metrics": [],
  "recover_prediction": [
    "y",
    "n_speaker"
  ],
  "PowerReporter": {
    "__init__": [
      "self",
      "valid_data_loader",
      "mapping_dict",
      "max_n_speaker"
    ],
    "report": [
      "self",
      "model",
      "eidx",
      "device"
    ],
    "report_val": [
      "self",
      "model",
      "eidx",
      "device"
    ],
    "inv_mapping_func": [
      "self",
      "label",
      "mapping_dict"
    ],
    "report_core": [
      "self",
      "model",
      "data_loader",
      "device"
    ],
    "calc_diarization_error": [
      "self",
      "decisions",
      "label",
      "label_delay"
    ]
  },
  "load_segments": [
    "segments_file"
  ],
  "load_segments_hash": [
    "segments_file"
  ],
  "load_segments_rechash": [
    "segments_file"
  ],
  "load_wav_scp": [
    "wav_scp_file"
  ],
  "load_wav": [
    "wav_rxfilename",
    "start",
    "end"
  ],
  "load_utt2spk": [
    "utt2spk_file"
  ],
  "load_spk2utt": [
    "spk2utt_file"
  ],
  "load_reco2dur": [
    "reco2dur_file"
  ],
  "process_wav": [
    "wav_rxfilename",
    "process"
  ],
  "extract_segments": [
    "wavs",
    "segments"
  ],
  "KaldiData": {
    "__init__": [
      "self",
      "data_dir"
    ],
    "load_wav": [
      "self",
      "recid",
      "start",
      "end"
    ]
  },
  "generate_mapping_dict": [
    "max_speaker_num",
    "max_olp_speaker_num"
  ],
  "raw_dec_trans": [
    "x",
    "max_speaker_num"
  ],
  "mapping_func": [
    "num",
    "mapping_dict"
  ],
  "dec_trans": [
    "x",
    "max_speaker_num",
    "mapping_dict"
  ],
  "create_powerlabel": [
    "label",
    "mapping_dict",
    "max_speaker_num",
    "max_olp_speaker_num"
  ],
  "generate_perm_pse": [
    "label",
    "n_speaker",
    "mapping_dict",
    "max_speaker_num",
    "max_olp_speaker_num"
  ],
  "generate_min_pse": [
    "label",
    "n_speaker",
    "mapping_dict",
    "max_speaker_num",
    "pse_logit",
    "max_olp_speaker_num"
  ],
  "ESPnetSVModel": {
    "__init__": [
      "self",
      "vocab_size",
      "token_list",
      "frontend",
      "specaug",
      "normalize",
      "preencoder",
      "encoder",
      "postencoder",
      "pooling_layer",
      "decoder"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "collect_feats": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "_extract_feats": [
      "self",
      "speech",
      "speech_lengths"
    ]
  },
  "N_MELS": [],
  "get_T_after_cnn": [
    "L_in",
    "dilation"
  ],
  "load_bytesio_audio": [
    "content",
    "sr"
  ],
  "trim": [
    "array",
    "length"
  ],
  "QwenAudioEncoder": {
    "__init__": [
      "self",
      "n_mels",
      "n_ctx",
      "n_state",
      "n_head",
      "n_layer",
      "output_dim",
      "avg_pool",
      "add_audio_bos_eos_token"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask",
      "audio_lengths"
    ],
    "encode": [
      "self",
      "input_audios",
      "input_audio_lengths",
      "audio_span_tokens"
    ]
  },
  "QwenAudioWarp": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "QwenAudioChatWarp": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ]
  },
  "FsmnDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "self_attention_dropout_rate",
      "src_attention_dropout_rate",
      "input_layer",
      "use_output_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "att_layer_num",
      "kernel_size",
      "sanm_shfit",
      "concat_embeds",
      "attention_dim",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf",
      "embed_tensor_name_prefix_tf"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens",
      "chunk_mask",
      "pre_acoustic_embeds"
    ],
    "score": [
      "self",
      "ys",
      "state",
      "x",
      "x_mask",
      "pre_acoustic_embeds"
    ],
    "forward_one_step": [
      "self",
      "tgt",
      "tgt_mask",
      "memory",
      "memory_mask",
      "pre_acoustic_embeds",
      "cache"
    ]
  },
  "preprocess_for_attn": [
    "x",
    "mask",
    "cache",
    "pad_fn",
    "kernel_size"
  ],
  "torch_version": [],
  "MultiHeadedAttentionSANMExport": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward_qkv": [
      "self",
      "x"
    ],
    "forward_fsmn": [
      "self",
      "inputs",
      "mask"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask"
    ]
  },
  "MultiHeadedAttentionSANMDecoder": {
    "__init__": [
      "self",
      "n_feat",
      "dropout_rate",
      "kernel_size",
      "sanm_shfit"
    ],
    "forward": [
      "self",
      "inputs",
      "mask",
      "cache",
      "mask_shfit_chunk"
    ]
  },
  "MultiHeadedAttentionSANMDecoderExport": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "inputs",
      "mask",
      "cache"
    ]
  },
  "MultiHeadedAttentionCrossAtt": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "dropout_rate",
      "lora_list",
      "lora_rank",
      "lora_alpha",
      "lora_dropout",
      "encoder_output_size"
    ],
    "forward_qkv": [
      "self",
      "x",
      "memory"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask",
      "ret_attn"
    ],
    "forward": [
      "self",
      "x",
      "memory",
      "memory_mask",
      "ret_attn"
    ],
    "forward_chunk": [
      "self",
      "x",
      "memory",
      "cache",
      "chunk_size",
      "look_back"
    ]
  },
  "MultiHeadedAttentionCrossAttExport": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "x",
      "memory",
      "memory_mask",
      "ret_attn"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward_qkv": [
      "self",
      "x",
      "memory"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask",
      "ret_attn"
    ]
  },
  "SANM": {
    "__init__": [
      "self"
    ]
  },
  "SANMEncoder": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "attention_dropout_rate",
      "input_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "positionwise_layer_type",
      "positionwise_conv_kernel_size",
      "padding_idx",
      "interctc_layer_idx",
      "interctc_use_conditioning",
      "kernel_size",
      "sanm_shfit",
      "lora_list",
      "lora_rank",
      "lora_alpha",
      "lora_dropout",
      "selfattention_layer_type",
      "tf2torch_tensor_name_prefix_torch",
      "tf2torch_tensor_name_prefix_tf"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states",
      "ctc"
    ],
    "_add_overlap_chunk": [
      "self",
      "feats",
      "cache"
    ],
    "forward_chunk": [
      "self",
      "xs_pad",
      "ilens",
      "cache",
      "ctc"
    ]
  },
  "EncoderLayerSANMExport": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "SANMEncoderExport": {
    "__init__": [
      "self",
      "model",
      "max_seq_len",
      "feats_dim",
      "model_name",
      "onnx",
      "ctc_linear"
    ],
    "prepare_mask": [
      "self",
      "mask"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "online"
    ],
    "get_output_size": [
      "self"
    ],
    "get_dummy_inputs": [
      "self"
    ],
    "get_input_names": [
      "self"
    ],
    "get_output_names": [
      "self"
    ],
    "get_dynamic_axes": [
      "self"
    ]
  },
  "PositionwiseFeedForwardDecoderSANM": {
    "__init__": [
      "self",
      "idim",
      "hidden_units",
      "dropout_rate",
      "adim",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OnnxMultiHeadedAttention": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward_qkv": [
      "self",
      "query",
      "key",
      "value"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask"
    ]
  },
  "OnnxRelPosMultiHeadedAttention": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "pos_emb",
      "mask"
    ],
    "rel_shift": [
      "self",
      "x"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask"
    ]
  },
  "CosineDistanceAttention": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "spk_decoder_out",
      "profile",
      "profile_lens"
    ]
  },
  "ParaformerDecoderSAN": {
    "__init__": [
      "self",
      "vocab_size",
      "encoder_output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "self_attention_dropout_rate",
      "src_attention_dropout_rate",
      "input_layer",
      "use_output_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "embeds_id"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_in_pad",
      "ys_in_lens"
    ]
  },
  "SAASRModel": {
    "__init__": [
      "self",
      "vocab_size",
      "max_spk_num",
      "token_list",
      "frontend",
      "specaug",
      "normalize",
      "asr_encoder",
      "spk_encoder",
      "decoder",
      "ctc",
      "spk_weight",
      "ctc_weight",
      "interctc_weight",
      "ignore_id",
      "lsm_weight",
      "length_normalized_loss",
      "report_cer",
      "report_wer",
      "sym_space",
      "sym_blank",
      "extract_feats_in_collect_stats"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths",
      "profile",
      "profile_lengths",
      "text_id",
      "text_id_lengths"
    ],
    "collect_feats": [
      "self",
      "speech",
      "speech_lengths",
      "text",
      "text_lengths"
    ],
    "encode": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "_extract_feats": [
      "self",
      "speech",
      "speech_lengths"
    ],
    "nll": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ],
    "batchify_nll": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens",
      "batch_size"
    ],
    "_calc_att_loss": [
      "self",
      "asr_encoder_out",
      "spk_encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens",
      "profile",
      "profile_lens",
      "text_id",
      "text_id_lengths"
    ],
    "_calc_ctc_loss": [
      "self",
      "encoder_out",
      "encoder_out_lens",
      "ys_pad",
      "ys_pad_lens"
    ]
  },
  "beam_search": [
    "x",
    "sos",
    "eos",
    "beam_size",
    "vocab_size",
    "scorers",
    "weights",
    "token_list",
    "maxlenratio",
    "minlenratio",
    "pre_beam_ratio",
    "pre_beam_score_key"
  ],
  "mask_along_axis": [
    "spec",
    "spec_lengths",
    "mask_width_range",
    "dim",
    "num_mask",
    "replace_with_zero"
  ],
  "mask_along_axis_lfr": [
    "spec",
    "spec_lengths",
    "mask_width_range",
    "dim",
    "num_mask",
    "replace_with_zero",
    "lfr_rate"
  ],
  "MaskAlongAxis": {
    "__init__": [
      "self",
      "mask_width_range",
      "num_mask",
      "dim",
      "replace_with_zero"
    ],
    "extra_repr": [
      "self"
    ],
    "forward": [
      "self",
      "spec",
      "spec_lengths"
    ]
  },
  "MaskAlongAxisVariableMaxWidth": {
    "__init__": [
      "self",
      "mask_width_ratio_range",
      "num_mask",
      "dim",
      "replace_with_zero"
    ],
    "extra_repr": [
      "self"
    ],
    "forward": [
      "self",
      "spec",
      "spec_lengths"
    ]
  },
  "MaskAlongAxisLFR": {
    "__init__": [
      "self",
      "mask_width_range",
      "num_mask",
      "dim",
      "replace_with_zero",
      "lfr_rate"
    ],
    "extra_repr": [
      "self"
    ],
    "forward": [
      "self",
      "spec",
      "spec_lengths"
    ]
  },
  "SpecAug": {
    "__init__": [
      "self",
      "apply_time_warp",
      "time_warp_window",
      "time_warp_mode",
      "apply_freq_mask",
      "freq_mask_width_range",
      "num_freq_mask",
      "apply_time_mask",
      "time_mask_width_range",
      "time_mask_width_ratio_range",
      "num_time_mask"
    ],
    "forward": [
      "self",
      "x",
      "x_lengths"
    ]
  },
  "SpecAugLFR": {
    "__init__": [
      "self",
      "apply_time_warp",
      "time_warp_window",
      "time_warp_mode",
      "apply_freq_mask",
      "freq_mask_width_range",
      "num_freq_mask",
      "lfr_rate",
      "apply_time_mask",
      "time_mask_width_range",
      "time_mask_width_ratio_range",
      "num_time_mask"
    ],
    "forward": [
      "self",
      "x",
      "x_lengths"
    ]
  },
  "DEFAULT_TIME_WARP_MODE": [],
  "time_warp": [
    "x",
    "window",
    "mode"
  ],
  "TimeWarp": {
    "__init__": [
      "self",
      "window",
      "mode"
    ],
    "extra_repr": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "x_lengths"
    ]
  },
  "ProfileAug": {
    "__init__": [
      "self",
      "apply_split_aug",
      "split_aug_prob",
      "apply_merge_aug",
      "merge_aug_prob",
      "apply_disturb_aug",
      "disturb_aug_prob",
      "disturb_alpha"
    ],
    "split_aug": [
      "self",
      "profile",
      "binary_labels",
      "mask"
    ],
    "merge_aug": [
      "self",
      "profile",
      "binary_labels",
      "mask"
    ],
    "disturb_aug": [
      "self",
      "profile",
      "binary_labels",
      "mask"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "profile",
      "profile_lengths",
      "binary_labels",
      "labels_length"
    ]
  },
  "TransformerEncoder_lm": {
    "__init__": [
      "self",
      "idim",
      "attention_dim",
      "attention_heads",
      "conv_wshare",
      "conv_kernel_length",
      "conv_usebias",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "attention_dropout_rate",
      "input_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "positionwise_layer_type",
      "positionwise_conv_kernel_size",
      "selfattention_layer_type",
      "padding_idx",
      "stochastic_depth_rate",
      "intermediate_layers",
      "ctc_softmax",
      "conditioning_layer_dim"
    ],
    "get_positionwise_layer": [
      "self",
      "positionwise_layer_type",
      "attention_dim",
      "linear_units",
      "dropout_rate",
      "positionwise_conv_kernel_size"
    ],
    "forward": [
      "self",
      "xs",
      "masks"
    ],
    "forward_one_step": [
      "self",
      "xs",
      "masks",
      "cache"
    ]
  },
  "SequentialRNNLM": {
    "__init__": [
      "self",
      "vocab_size",
      "unit",
      "nhid",
      "nlayers",
      "dropout_rate",
      "tie_weights",
      "rnn_type",
      "ignore_id"
    ],
    "zero_state": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "hidden"
    ],
    "score": [
      "self",
      "y",
      "state",
      "x"
    ],
    "batch_score": [
      "self",
      "ys",
      "states",
      "xs"
    ]
  },
  "TransformerLM": {
    "__init__": [
      "self",
      "vocab_size",
      "pos_enc",
      "embed_unit",
      "att_unit",
      "head",
      "unit",
      "layer",
      "dropout_rate"
    ],
    "_target_mask": [
      "self",
      "ys_in_pad"
    ],
    "forward": [
      "self",
      "input",
      "hidden"
    ],
    "score": [
      "self",
      "y",
      "state",
      "x"
    ],
    "batch_score": [
      "self",
      "ys",
      "states",
      "xs"
    ]
  },
  "_apply_attention_constraint": [
    "e",
    "last_attended_idx",
    "backward_window",
    "forward_window"
  ],
  "NoAtt": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev"
    ]
  },
  "AttDot": {
    "__init__": [
      "self",
      "eprojs",
      "dunits",
      "att_dim",
      "han_mode"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev",
      "scaling"
    ]
  },
  "AttAdd": {
    "__init__": [
      "self",
      "eprojs",
      "dunits",
      "att_dim",
      "han_mode"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev",
      "scaling"
    ]
  },
  "AttLoc": {
    "__init__": [
      "self",
      "eprojs",
      "dunits",
      "att_dim",
      "aconv_chans",
      "aconv_filts",
      "han_mode"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev",
      "scaling",
      "last_attended_idx",
      "backward_window",
      "forward_window"
    ]
  },
  "AttCov": {
    "__init__": [
      "self",
      "eprojs",
      "dunits",
      "att_dim",
      "han_mode"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev_list",
      "scaling"
    ]
  },
  "AttLoc2D": {
    "__init__": [
      "self",
      "eprojs",
      "dunits",
      "att_dim",
      "att_win",
      "aconv_chans",
      "aconv_filts",
      "han_mode"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev",
      "scaling"
    ]
  },
  "AttLocRec": {
    "__init__": [
      "self",
      "eprojs",
      "dunits",
      "att_dim",
      "aconv_chans",
      "aconv_filts",
      "han_mode"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev_states",
      "scaling"
    ]
  },
  "AttCovLoc": {
    "__init__": [
      "self",
      "eprojs",
      "dunits",
      "att_dim",
      "aconv_chans",
      "aconv_filts",
      "han_mode"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev_list",
      "scaling"
    ]
  },
  "AttMultiHeadDot": {
    "__init__": [
      "self",
      "eprojs",
      "dunits",
      "aheads",
      "att_dim_k",
      "att_dim_v",
      "han_mode"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev"
    ]
  },
  "AttMultiHeadAdd": {
    "__init__": [
      "self",
      "eprojs",
      "dunits",
      "aheads",
      "att_dim_k",
      "att_dim_v",
      "han_mode"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev"
    ]
  },
  "AttMultiHeadLoc": {
    "__init__": [
      "self",
      "eprojs",
      "dunits",
      "aheads",
      "att_dim_k",
      "att_dim_v",
      "aconv_chans",
      "aconv_filts",
      "han_mode"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev",
      "scaling"
    ]
  },
  "AttMultiHeadMultiResLoc": {
    "__init__": [
      "self",
      "eprojs",
      "dunits",
      "aheads",
      "att_dim_k",
      "att_dim_v",
      "aconv_chans",
      "aconv_filts",
      "han_mode"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev"
    ]
  },
  "AttForward": {
    "__init__": [
      "self",
      "eprojs",
      "dunits",
      "att_dim",
      "aconv_chans",
      "aconv_filts"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev",
      "scaling",
      "last_attended_idx",
      "backward_window",
      "forward_window"
    ]
  },
  "AttForwardTA": {
    "__init__": [
      "self",
      "eunits",
      "dunits",
      "att_dim",
      "aconv_chans",
      "aconv_filts",
      "odim"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_hs_pad",
      "enc_hs_len",
      "dec_z",
      "att_prev",
      "out_prev",
      "scaling",
      "last_attended_idx",
      "backward_window",
      "forward_window"
    ]
  },
  "att_for": [
    "args",
    "num_att",
    "han_mode"
  ],
  "initial_att": [
    "atype",
    "eprojs",
    "dunits",
    "aheads",
    "adim",
    "awin",
    "aconv_chans",
    "aconv_filts",
    "han_mode"
  ],
  "att_to_numpy": [
    "att_ws",
    "att"
  ],
  "MAX_DECODER_OUTPUT": [],
  "CTC_SCORING_RATIO": [],
  "Decoder": {
    "__init__": [
      "self",
      "eprojs",
      "odim",
      "dtype",
      "dlayers",
      "dunits",
      "sos",
      "eos",
      "att",
      "verbose",
      "char_list",
      "labeldist",
      "lsm_weight",
      "sampling_probability",
      "dropout",
      "context_residual",
      "replace_sos",
      "num_encs"
    ],
    "zero_state": [
      "self",
      "hs_pad"
    ],
    "rnn_forward": [
      "self",
      "ey",
      "z_list",
      "c_list",
      "z_prev",
      "c_prev"
    ],
    "forward": [
      "self",
      "hs_pad",
      "hlens",
      "ys_pad",
      "strm_idx",
      "lang_ids"
    ],
    "recognize_beam": [
      "self",
      "h",
      "lpz",
      "recog_args",
      "char_list",
      "rnnlm",
      "strm_idx"
    ],
    "recognize_beam_batch": [
      "self",
      "h",
      "hlens",
      "lpz",
      "recog_args",
      "char_list",
      "rnnlm",
      "normalize_score",
      "strm_idx",
      "lang_ids"
    ],
    "calculate_all_attentions": [
      "self",
      "hs_pad",
      "hlen",
      "ys_pad",
      "strm_idx",
      "lang_ids"
    ],
    "_get_last_yseq": [
      "exp_yseq"
    ],
    "_append_ids": [
      "yseq",
      "ids"
    ],
    "_index_select_list": [
      "yseq",
      "lst"
    ],
    "_index_select_lm_state": [
      "rnnlm_state",
      "dim",
      "vidx"
    ],
    "init_state": [
      "self",
      "x"
    ],
    "score": [
      "self",
      "yseq",
      "state",
      "x"
    ]
  },
  "decoder_for": [
    "args",
    "odim",
    "sos",
    "eos",
    "att",
    "labeldist"
  ],
  "RNNP": {
    "__init__": [
      "self",
      "idim",
      "elayers",
      "cdim",
      "hdim",
      "subsample",
      "dropout",
      "typ"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_state"
    ]
  },
  "RNN": {
    "__init__": [
      "self",
      "idim",
      "elayers",
      "cdim",
      "hdim",
      "dropout",
      "typ"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_state"
    ]
  },
  "reset_backward_rnn_state": [
    "states"
  ],
  "Encoder": {
    "__init__": [
      "self",
      "etype",
      "idim",
      "elayers",
      "eunits",
      "eprojs",
      "subsample",
      "dropout",
      "in_channel"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "prev_states"
    ]
  },
  "encoder_for": [
    "args",
    "idim",
    "subsample"
  ],
  "add_arguments_rnn_encoder_common": [
    "group"
  ],
  "add_arguments_rnn_decoder_common": [
    "group"
  ],
  "add_arguments_rnn_attention_common": [
    "group"
  ],
  "MultiHeadedAttentionSANMwithMask": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "mask_shfit_chunk",
      "mask_att_chunk_encoder"
    ]
  },
  "CTTransformerStreaming": {
    "__init__": [
      "self"
    ],
    "punc_forward": [
      "self",
      "text",
      "text_lengths",
      "vad_indexes"
    ],
    "with_vad": [
      "self"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend",
      "cache"
    ],
    "export": [
      "self"
    ]
  },
  "SANMVadEncoder": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "positional_dropout_rate",
      "attention_dropout_rate",
      "input_layer",
      "pos_enc_class",
      "normalize_before",
      "concat_after",
      "positionwise_layer_type",
      "positionwise_conv_kernel_size",
      "padding_idx",
      "interctc_layer_idx",
      "interctc_use_conditioning",
      "kernel_size",
      "sanm_shfit",
      "selfattention_layer_type"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "xs_pad",
      "ilens",
      "vad_indexes",
      "prev_states",
      "ctc"
    ]
  },
  "SANMVadEncoderExport": {
    "__init__": [
      "self",
      "model",
      "max_seq_len",
      "feats_dim",
      "model_name",
      "onnx"
    ],
    "prepare_mask": [
      "self",
      "mask",
      "sub_masks"
    ],
    "forward": [
      "self",
      "speech",
      "speech_lengths",
      "vad_masks",
      "sub_masks"
    ],
    "get_output_size": [
      "self"
    ]
  },
  "logger": [],
  "MaskSeed": [],
  "MaskInfo": [],
  "ModalitySpecificEncoder": {
    "__init__": [
      "self",
      "modality_cfg",
      "embed_dim",
      "local_encoder",
      "project_features",
      "fixed_positional_encoder",
      "relative_positional_encoder",
      "context_encoder",
      "decoder",
      "get_alibi_bias"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "convert_padding_mask": [
      "self",
      "x",
      "padding_mask"
    ],
    "decoder_input": [
      "self",
      "x",
      "mask_info"
    ],
    "local_features": [
      "self",
      "features"
    ],
    "contextualized_features": [
      "self",
      "x",
      "padding_mask",
      "mask",
      "remove_masked",
      "clone_batch",
      "mask_seeds",
      "precomputed_mask"
    ],
    "forward": [
      "self",
      "features",
      "padding_mask",
      "mask",
      "remove_masked",
      "clone_batch",
      "mask_seeds",
      "precomputed_mask"
    ],
    "reset_parameters": [
      "self"
    ],
    "compute_mask": [
      "self",
      "x",
      "padding_mask",
      "mask_seed",
      "apply",
      "precomputed_mask"
    ],
    "make_maskinfo": [
      "self",
      "x",
      "mask",
      "shape"
    ],
    "apply_mask": [
      "self",
      "x",
      "mask_info"
    ],
    "remove_pretraining_modules": [
      "self",
      "keep_decoder"
    ]
  },
  "random_masking": [
    "x",
    "mask_ratio",
    "mask_seed"
  ],
  "gather_unmasked": [
    "x",
    "mask_info"
  ],
  "gather_unmasked_mask": [
    "x",
    "mask_info"
  ],
  "get_alibi": [
    "max_positions",
    "attention_heads",
    "dims",
    "distance"
  ],
  "get_alibi_bias": [
    "alibi_biases",
    "batch_size",
    "time_steps",
    "heads",
    "dtype",
    "device",
    "dims",
    "distance"
  ],
  "_learned_alibi_bias": [
    "alibi_bias",
    "batch_size",
    "time_steps",
    "heads",
    "scale",
    "dtype",
    "device"
  ],
  "masked_alibi": [
    "alibi_bias",
    "mask_info"
  ],
  "drop_path": [
    "x",
    "drop_prob",
    "training",
    "scale_by_keep"
  ],
  "DropPath": {
    "__init__": [
      "self",
      "drop_prob",
      "scale_by_keep"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "_ntuple": [
    "n"
  ],
  "to_1tuple": [],
  "to_2tuple": [],
  "to_3tuple": [],
  "to_4tuple": [],
  "to_ntuple": [],
  "Mlp": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "act_layer",
      "norm_layer",
      "bias",
      "drop",
      "use_conv"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Emotion2vec": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "source",
      "target",
      "id",
      "mode",
      "padding_mask",
      "mask",
      "features_only",
      "force_remove_masked",
      "remove_extra_tokens",
      "precomputed_mask"
    ],
    "extract_features": [
      "self",
      "source",
      "mode",
      "padding_mask",
      "mask",
      "remove_extra_tokens"
    ],
    "inference": [
      "self",
      "data_in",
      "data_lengths",
      "key",
      "tokenizer",
      "frontend"
    ],
    "export": [
      "self"
    ]
  },
  "is_xla_tensor": [
    "tensor"
  ],
  "index_put": [
    "tensor",
    "indices",
    "value"
  ],
  "Modality": {
    "AUDIO": []
  },
  "D2vDecoderConfig": {},
  "FixedPositionalEncoder": {
    "__init__": [
      "self",
      "pos_embed"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask"
    ]
  },
  "TextFeatPositionalEncoder": {
    "__init__": [
      "self",
      "pos_encoder"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask"
    ]
  },
  "BlockEncoder": {
    "__init__": [
      "self",
      "blocks",
      "norm_layer",
      "layer_norm_first",
      "layerdrop",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask",
      "alibi_bias",
      "alibi_scale"
    ]
  },
  "DecoderBase": {
    "__init__": [
      "self",
      "cfg"
    ],
    "reset_parameters": [
      "self"
    ],
    "add_residual": [
      "self",
      "x",
      "residual",
      "i",
      "mask_info"
    ]
  },
  "Decoder1d": {
    "__init__": [
      "self",
      "cfg",
      "input_dim"
    ],
    "forward": [
      "self",
      "x",
      "mask_info"
    ]
  },
  "AltBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "mlp_drop",
      "post_mlp_drop",
      "drop_path",
      "act_layer",
      "norm_layer",
      "layer_norm_first",
      "ffn_targets",
      "cosine_attention"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask",
      "alibi_bias"
    ]
  },
  "AltAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "qkv_bias",
      "qk_scale",
      "attn_drop",
      "proj_drop",
      "cosine_attention"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask",
      "alibi_bias"
    ]
  },
  "RWKV": {
    "__init__": [
      "self",
      "size",
      "linear_size",
      "attention_size",
      "context_size",
      "block_id",
      "num_blocks",
      "att_dropout_rate",
      "ffn_dropout_rate",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "x",
      "state"
    ]
  },
  "RWKVDecoderLayer": {
    "__init__": [
      "self",
      "size",
      "linear_size",
      "attention_size",
      "context_size",
      "block_id",
      "num_blocks",
      "att_dropout_rate",
      "ffn_dropout_rate",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "x",
      "state"
    ]
  },
  "RWKVConvInput": {
    "__init__": [
      "self",
      "input_size",
      "conv_size",
      "subsampling_factor",
      "conv_kernel_size",
      "output_size"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "chunk_size"
    ],
    "create_new_vgg_mask": [
      "self",
      "mask"
    ],
    "get_size_before_subsampling": [
      "self",
      "size"
    ]
  },
  "FeedForward": {
    "__init__": [
      "self",
      "size",
      "hidden_size",
      "block_id",
      "dropout_rate",
      "num_blocks"
    ],
    "reset_parameters": [
      "self",
      "size",
      "block_id",
      "num_blocks"
    ],
    "forward": [
      "self",
      "x",
      "state"
    ]
  },
  "RWKVEncoder": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "context_size",
      "linear_size",
      "attention_size",
      "num_blocks",
      "att_dropout_rate",
      "ffn_dropout_rate",
      "dropout_rate",
      "subsampling_factor",
      "time_reduction_factor",
      "kernel"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "x_len"
    ],
    "rwkv_infer": [
      "self",
      "xs_pad"
    ]
  },
  "wkv_kernel_encoder": [],
  "wkv_kernel_decoder": [],
  "WKVLinearAttentionEncoder": {
    "forward": [
      "ctx",
      "time_decay",
      "time_first",
      "key",
      "value"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "WKVLinearAttentionDecoder": {
    "forward": [
      "ctx",
      "time_decay",
      "time_first",
      "key",
      "value"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "load_encoder_wkv_kernel": [
    "context_size"
  ],
  "load_decoder_wkv_kernel": [
    "context_size"
  ],
  "SelfAttention": {
    "__init__": [
      "self",
      "size",
      "attention_size",
      "block_id",
      "dropout_rate",
      "num_blocks"
    ],
    "reset_parameters": [
      "self",
      "size",
      "attention_size",
      "block_id",
      "num_blocks"
    ],
    "wkv_linear_attention": [
      "self",
      "time_decay",
      "time_first",
      "key",
      "value",
      "state"
    ]
  },
  "DecoderSelfAttention": {
    "__init__": [
      "self",
      "size",
      "attention_size",
      "context_size",
      "block_id",
      "dropout_rate",
      "num_blocks"
    ],
    "forward": [
      "self",
      "x",
      "state"
    ]
  },
  "EncoderSelfAttention": {
    "__init__": [
      "self",
      "size",
      "attention_size",
      "context_size",
      "block_id",
      "dropout_rate",
      "num_blocks"
    ],
    "forward": [
      "self",
      "x",
      "state"
    ]
  }
}