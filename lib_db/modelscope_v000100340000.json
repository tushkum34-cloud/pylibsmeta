{
  "__version__": [],
  "__release_datetime__": [],
  "InputKeys": {
    "IMAGE": [],
    "TEXT": [],
    "VIDEO": []
  },
  "InputType": {
    "IMAGE": [],
    "TEXT": [],
    "AUDIO": [],
    "VIDEO": [],
    "BOX": [],
    "DICT": [],
    "LIST": [],
    "NUMBER": []
  },
  "INPUT_TYPE": [],
  "INPUT_TYPE_SCHEMA": [],
  "check_input_type": [
    "input_type",
    "input"
  ],
  "TASK_INPUTS": [],
  "Models": {
    "tinynas_detection": [],
    "tinynas_damoyolo": [],
    "detection": [],
    "mask_scoring": [],
    "image_restoration": [],
    "realtime_object_detection": [],
    "realtime_video_object_detection": [],
    "scrfd": [],
    "depe": [],
    "classification_model": [],
    "easyrobust_model": [],
    "bnext": [],
    "yolopv2": [],
    "nafnet": [],
    "csrnet": [],
    "adaint": [],
    "deeplpfnet": [],
    "rrdb": [],
    "cascade_mask_rcnn_swin": [],
    "maskdino_swin": [],
    "gpen": [],
    "product_retrieval_embedding": [],
    "body_2d_keypoints": [],
    "body_3d_keypoints": [],
    "body_3d_keypoints_hdformer": [],
    "crowd_counting": [],
    "face_2d_keypoints": [],
    "star_68ldk_detection": [],
    "panoptic_segmentation": [],
    "r50_panoptic_segmentation": [],
    "image_reid_person": [],
    "image_inpainting": [],
    "image_paintbyexample": [],
    "video_summarization": [],
    "video_panoptic_segmentation": [],
    "video_instance_segmentation": [],
    "language_guided_video_summarization": [],
    "swinL_semantic_segmentation": [],
    "vitadapter_semantic_segmentation": [],
    "text_driven_segmentation": [],
    "newcrfs_depth_estimation": [],
    "omnidata_normal_estimation": [],
    "panovit_layout_estimation": [],
    "unifuse_depth_estimation": [],
    "s2net_depth_estimation": [],
    "dro_resnet18_depth_estimation": [],
    "raft_dense_optical_flow_estimation": [],
    "human_normal_estimation": [],
    "resnet50_bert": [],
    "referring_video_object_segmentation": [],
    "fer": [],
    "fairface": [],
    "retinaface": [],
    "damofd": [],
    "shop_segmentation": [],
    "mogface": [],
    "mtcnn": [],
    "ulfd": [],
    "rts": [],
    "flir": [],
    "arcface": [],
    "facemask": [],
    "flc": [],
    "tinymog": [],
    "video_inpainting": [],
    "human_wholebody_keypoint": [],
    "hand_static": [],
    "face_human_hand_detection": [],
    "face_emotion": [],
    "product_segmentation": [],
    "image_body_reshaping": [],
    "image_skychange": [],
    "video_human_matting": [],
    "human_reconstruction": [],
    "text_texture_generation": [],
    "video_frame_interpolation": [],
    "video_object_segmentation": [],
    "video_deinterlace": [],
    "quadtree_attention_image_matching": [],
    "loftr_image_local_feature_matching": [],
    "lightglue_image_matching": [],
    "vision_middleware": [],
    "vidt": [],
    "video_stabilization": [],
    "real_basicvsr": [],
    "rcp_sceneflow_estimation": [],
    "image_casmvs_depth_estimation": [],
    "image_geomvsnet_depth_estimation": [],
    "vop_retrieval_model": [],
    "vop_retrieval_model_se": [],
    "ddcolor": [],
    "image_probing_model": [],
    "defrcn": [],
    "image_face_fusion": [],
    "content_check": [],
    "open_vocabulary_detection_vild": [],
    "ecbsr": [],
    "msrresnet_lite": [],
    "object_detection_3d": [],
    "ddpm": [],
    "ocr_recognition": [],
    "ocr_detection": [],
    "lineless_table_recognition": [],
    "image_quality_assessment_mos": [],
    "image_quality_assessment_man": [],
    "image_quality_assessment_degradation": [],
    "m2fp": [],
    "nerf_recon_acc": [],
    "nerf_recon_4k": [],
    "nerf_recon_vq_compression": [],
    "surface_recon_common": [],
    "bts_depth_estimation": [],
    "vision_efficient_tuning": [],
    "bad_image_detecting": [],
    "controllable_image_generation": [],
    "longshortnet": [],
    "fastinst": [],
    "pedestrian_attribute_recognition": [],
    "image_try_on": [],
    "human_image_generation": [],
    "image_view_transform": [],
    "image_control_3d_portrait": [],
    "rife": [],
    "anydoor": [],
    "self_supervised_depth_completion": [],
    "bert": [],
    "palm": [],
    "structbert": [],
    "deberta_v2": [],
    "veco": [],
    "translation": [],
    "canmt": [],
    "space_dst": [],
    "space_intent": [],
    "space_modeling": [],
    "space_T_en": [],
    "space_T_cn": [],
    "tcrf": [],
    "token_classification_for_ner": [],
    "tcrf_wseg": [],
    "transformer_softmax": [],
    "lcrf": [],
    "lcrf_wseg": [],
    "gcnncrf": [],
    "bart": [],
    "gpt2": [],
    "gpt3": [],
    "gpt_moe": [],
    "gpt_neo": [],
    "plug": [],
    "bert_for_ds": [],
    "ponet_for_ds": [],
    "ponet": [],
    "polylm": [],
    "T5": [],
    "mglm": [],
    "codegeex": [],
    "glm130b": [],
    "bloom": [],
    "unite": [],
    "megatron_bert": [],
    "use": [],
    "fid_plug": [],
    "fid_T5": [],
    "lstm": [],
    "xlm_roberta": [],
    "transformers": [],
    "plug_mental": [],
    "doc2bot": [],
    "peer": [],
    "llama": [],
    "llama2": [],
    "chatglm_6b": [],
    "chatglm2_6b": [],
    "qwen_7b": [],
    "sambert_hifigan": [],
    "speech_frcrn_ans_cirm_16k": [],
    "speech_zipenhancer_ans_multiloss_16k_base": [],
    "speech_dfsmn_ans": [],
    "speech_dfsmn_kws_char_farfield": [],
    "speech_dfsmn_kws_char_farfield_iot": [],
    "speech_kws_fsmn_char_ctc_nearfield": [],
    "speech_mossformer_separation_temporal_8k": [],
    "speech_mossformer2_separation_temporal_8k": [],
    "kws_kwsbp": [],
    "generic_asr": [],
    "wenet_asr": [],
    "generic_itn": [],
    "generic_punc": [],
    "generic_sv": [],
    "tdnn_sv": [],
    "ecapa_tdnn_sv": [],
    "campplus_sv": [],
    "eres2net_sv": [],
    "eres2netv2_sv": [],
    "resnet_sv": [],
    "res2net_sv": [],
    "eres2net_aug_sv": [],
    "scl_sd": [],
    "scl_sd_xvector": [],
    "campplus_lre": [],
    "eres2net_lre": [],
    "cluster_backend": [],
    "rdino_tdnn_sv": [],
    "sdpn_sv": [],
    "generic_lm": [],
    "audio_quantization": [],
    "laura_codec": [],
    "funasr": [],
    "hifissr": [],
    "unetvc_16k": [],
    "ofa": [],
    "clip": [],
    "gemm": [],
    "rleg": [],
    "mplug": [],
    "diffusion": [],
    "multi_stage_diffusion": [],
    "video_synthesis": [],
    "team": [],
    "video_clip": [],
    "prost": [],
    "mgeo": [],
    "vldoc": [],
    "hitea": [],
    "soonet": [],
    "efficient_diffusion_tuning": [],
    "cones2_inference": [],
    "mplug_owl": [],
    "clip_interrogator": [],
    "stable_diffusion": [],
    "stable_diffusion_xl": [],
    "videocomposer": [],
    "text_to_360panorama_image": [],
    "image_to_video_model": [],
    "video_to_video_model": [],
    "unifold": [],
    "unifold_symmetry": []
  },
  "TaskModels": {
    "text_classification": [],
    "token_classification": [],
    "information_extraction": [],
    "fill_mask": [],
    "feature_extraction": [],
    "text_generation": [],
    "text_ranking": [],
    "machine_reading_comprehension": []
  },
  "Heads": {
    "text_classification": [],
    "fill_mask": [],
    "bert_mlm": [],
    "roberta_mlm": [],
    "xlm_roberta_mlm": [],
    "token_classification": [],
    "information_extraction": [],
    "text_generation": [],
    "text_ranking": [],
    "lstm_crf": [],
    "transformer_crf": []
  },
  "Pipelines": {
    "pipeline_template": [],
    "portrait_matting": [],
    "universal_matting": [],
    "image_denoise": [],
    "image_deblur": [],
    "image_editing": [],
    "freeu_stable_diffusion_text2image": [],
    "person_image_cartoon": [],
    "ocr_detection": [],
    "table_recognition": [],
    "lineless_table_recognition": [],
    "license_plate_detection": [],
    "card_detection_correction": [],
    "action_recognition": [],
    "animal_recognition": [],
    "general_recognition": [],
    "cmdssl_video_embedding": [],
    "hicossl_video_embedding": [],
    "body_2d_keypoints": [],
    "body_3d_keypoints": [],
    "hand_2d_keypoints": [],
    "human_detection": [],
    "tbs_detection": [],
    "object_detection": [],
    "abnormal_object_detection": [],
    "face_2d_keypoints": [],
    "salient_detection": [],
    "salient_boudary_detection": [],
    "camouflaged_detection": [],
    "image_demoire": [],
    "image_classification": [],
    "face_detection": [],
    "face_liveness_ir": [],
    "face_liveness_rgb": [],
    "face_liveness_xc": [],
    "card_detection": [],
    "ulfd_face_detection": [],
    "tinymog_face_detection": [],
    "facial_expression_recognition": [],
    "facial_landmark_confidence": [],
    "facial_68ldk_detection": [],
    "face_attribute_recognition": [],
    "retina_face_detection": [],
    "mog_face_detection": [],
    "mtcnn_face_detection": [],
    "live_category": [],
    "general_image_classification": [],
    "daily_image_classification": [],
    "nextvit_small_daily_image_classification": [],
    "convnext_base_image_classification_garbage": [],
    "bnext_small_image_classification": [],
    "yolopv2_image_driving_percetion_bdd100k": [],
    "common_image_classification": [],
    "image_color_enhance": [],
    "adaint_image_color_enhance": [],
    "deeplpf_image_color_enhance": [],
    "virtual_try_on": [],
    "image_colorization": [],
    "image_style_transfer": [],
    "image_super_resolution": [],
    "image_super_resolution_pasd": [],
    "image_debanding": [],
    "face_image_generation": [],
    "product_retrieval_embedding": [],
    "realtime_video_object_detection": [],
    "face_recognition": [],
    "face_recognition_ood": [],
    "face_quality_assessment": [],
    "face_recognition_onnx_ir": [],
    "face_recognition_onnx_fm": [],
    "arc_face_recognition": [],
    "mask_face_recognition": [],
    "content_check": [],
    "image_instance_segmentation": [],
    "maskdino_instance_segmentation": [],
    "image2image_translation": [],
    "video_category": [],
    "ocr_recognition": [],
    "image_portrait_enhancement": [],
    "image_to_image_generation": [],
    "image_object_detection_auto": [],
    "hand_detection": [],
    "skin_retouching": [],
    "face_reconstruction": [],
    "head_reconstruction": [],
    "text_to_head": [],
    "tinynas_classification": [],
    "easyrobust_classification": [],
    "tinynas_detection": [],
    "crowd_counting": [],
    "action_detection": [],
    "video_single_object_tracking": [],
    "video_single_object_tracking_procontext": [],
    "video_multi_object_tracking": [],
    "image_panoptic_segmentation": [],
    "video_summarization": [],
    "language_guided_video_summarization": [],
    "image_semantic_segmentation": [],
    "image_depth_estimation": [],
    "image_normal_estimation": [],
    "indoor_layout_estimation": [],
    "image_local_feature_matching": [],
    "video_depth_estimation": [],
    "panorama_depth_estimation": [],
    "panorama_depth_estimation_s2net": [],
    "dense_optical_flow_estimation": [],
    "image_reid_person": [],
    "image_inpainting": [],
    "image_paintbyexample": [],
    "image_inpainting_sdv2": [],
    "text_driven_segmentation": [],
    "movie_scene_segmentation": [],
    "shop_segmentation": [],
    "video_inpainting": [],
    "human_wholebody_keypoint": [],
    "pst_action_recognition": [],
    "hand_static": [],
    "face_human_hand_detection": [],
    "face_emotion": [],
    "product_segmentation": [],
    "image_body_reshaping": [],
    "referring_video_object_segmentation": [],
    "image_skychange": [],
    "video_human_matting": [],
    "human_reconstruction": [],
    "text_texture_generation": [],
    "vision_middleware_multi_task": [],
    "vidt": [],
    "video_frame_interpolation": [],
    "video_object_segmentation": [],
    "video_deinterlace": [],
    "image_matching": [],
    "image_matching_fast": [],
    "video_stabilization": [],
    "video_super_resolution": [],
    "pointcloud_sceneflow_estimation": [],
    "image_multi_view_depth_estimation": [],
    "video_panoptic_segmentation": [],
    "video_instance_segmentation": [],
    "vop_retrieval": [],
    "vop_retrieval_se": [],
    "ddcolor_image_colorization": [],
    "image_structured_model_probing": [],
    "image_fewshot_detection": [],
    "image_face_fusion": [],
    "open_vocabulary_detection_vild": [],
    "ddpm_image_semantic_segmentation": [],
    "video_colorization": [],
    "motion_generattion": [],
    "mobile_image_super_resolution": [],
    "image_human_parsing": [],
    "object_detection_3d_depe": [],
    "nerf_recon_acc": [],
    "nerf_recon_4k": [],
    "nerf_recon_vq_compression": [],
    "surface_recon_common": [],
    "bad_image_detecting": [],
    "controllable_image_generation": [],
    "fast_instance_segmentation": [],
    "image_quality_assessment_mos": [],
    "image_quality_assessment_man": [],
    "image_quality_assessment_degradation": [],
    "vision_efficient_tuning": [],
    "image_bts_depth_estimation": [],
    "image_depth_estimation_marigold": [],
    "pedestrian_attribute_recognition": [],
    "text_to_360panorama_image": [],
    "image_try_on": [],
    "human_image_generation": [],
    "human3d_render": [],
    "human3d_animation": [],
    "image_view_transform": [],
    "image_control_3d_portrait": [],
    "rife_video_frame_interpolation": [],
    "anydoor": [],
    "image_to_3d": [],
    "self_supervised_depth_completion": [],
    "human_normal_estimation": [],
    "automatic_post_editing": [],
    "translation_quality_estimation": [],
    "domain_classification": [],
    "sentence_similarity": [],
    "word_segmentation": [],
    "multilingual_word_segmentation": [],
    "word_segmentation_thai": [],
    "part_of_speech": [],
    "named_entity_recognition": [],
    "named_entity_recognition_thai": [],
    "named_entity_recognition_viet": [],
    "text_generation": [],
    "fid_dialogue": [],
    "text2text_generation": [],
    "sentiment_analysis": [],
    "sentiment_classification": [],
    "text_classification": [],
    "fill_mask": [],
    "fill_mask_ponet": [],
    "csanmt_translation": [],
    "canmt_translation": [],
    "interactive_translation": [],
    "nli": [],
    "dialog_intent_prediction": [],
    "dialog_modeling": [],
    "dialog_state_tracking": [],
    "zero_shot_classification": [],
    "text_error_correction": [],
    "word_alignment": [],
    "plug_generation": [],
    "gpt3_generation": [],
    "polylm_text_generation": [],
    "gpt_moe_generation": [],
    "faq_question_answering": [],
    "conversational_text_to_sql": [],
    "table_question_answering_pipeline": [],
    "sentence_embedding": [],
    "text_ranking": [],
    "mgeo_ranking": [],
    "relation_extraction": [],
    "document_segmentation": [],
    "extractive_summarization": [],
    "feature_extraction": [],
    "mglm_text_summarization": [],
    "codegeex_code_translation": [],
    "codegeex_code_generation": [],
    "glm130b_text_generation": [],
    "translation_en_to_de": [],
    "translation_en_to_ro": [],
    "translation_en_to_fr": [],
    "token_classification": [],
    "translation_evaluation": [],
    "user_satisfaction_estimation": [],
    "siamese_uie": [],
    "document_grounded_dialog_retrieval": [],
    "document_grounded_dialog_rerank": [],
    "document_grounded_dialog_generate": [],
    "language_identification": [],
    "machine_reading_comprehension_for_ner": [],
    "llm": [],
    "sambert_hifigan_tts": [],
    "speech_dfsmn_aec_psm_16k": [],
    "speech_frcrn_ans_cirm_16k": [],
    "speech_zipenhancer_ans_multiloss_16k_base": [],
    "speech_dfsmn_ans_psm_48k_causal": [],
    "speech_dfsmn_kws_char_farfield": [],
    "speech_separation": [],
    "kws_kwsbp": [],
    "asr_wenet_inference": [],
    "itn_inference": [],
    "speaker_diarization_inference": [],
    "vad_inference": [],
    "funasr_speech_separation": [],
    "speaker_verification": [],
    "speaker_verification_tdnn": [],
    "speaker_verification_rdino": [],
    "speaker_verification_sdpn": [],
    "speaker_verification_eres2net": [],
    "speaker_verification_eres2netv2": [],
    "speaker_verification_resnet": [],
    "speaker_verification_res2net": [],
    "speech_language_recognition": [],
    "speech_language_recognition_eres2net": [],
    "speaker_change_locating": [],
    "speaker_diarization_dialogue_detection": [],
    "speaker_diarization_semantic_speaker_turn_detection": [],
    "segmentation_clustering": [],
    "lm_inference": [],
    "speech_timestamp_inference": [],
    "audio_quantization": [],
    "audio_quantization_inference": [],
    "laura_codec_tts_inference": [],
    "speech_super_resolution_inference": [],
    "voice_conversion": [],
    "image_captioning": [],
    "multi_modal_embedding": [],
    "generative_multi_modal_embedding": [],
    "visual_question_answering": [],
    "visual_grounding": [],
    "visual_entailment": [],
    "multi_modal_similarity": [],
    "text_to_image_synthesis": [],
    "video_multi_modal_embedding": [],
    "prost_text_video_retrieval": [],
    "videocomposer": [],
    "image_text_retrieval": [],
    "ofa_ocr_recognition": [],
    "ofa_asr": [],
    "ofa_sudoku": [],
    "ofa_text2sql": [],
    "video_captioning": [],
    "video_question_answering": [],
    "diffusers_stable_diffusion": [],
    "disco_guided_diffusion": [],
    "document_vl_embedding": [],
    "chinese_stable_diffusion": [],
    "cones2_inference": [],
    "text_to_video_synthesis": [],
    "gridvlp_multi_modal_classification": [],
    "gridvlp_multi_modal_embedding": [],
    "soonet_video_temporal_grounding": [],
    "efficient_diffusion_tuning": [],
    "multimodal_dialogue": [],
    "llama2_text_generation_pipeline": [],
    "llama2_text_generation_chat_pipeline": [],
    "image_to_video_task_pipeline": [],
    "video_to_video_pipeline": [],
    "protein_structure": [],
    "funasr_pipeline": []
  },
  "DEFAULT_MODEL_FOR_PIPELINE": [],
  "CVTrainers": {
    "image_instance_segmentation": [],
    "image_portrait_enhancement": [],
    "video_summarization": [],
    "movie_scene_segmentation": [],
    "face_detection_scrfd": [],
    "card_detection_scrfd": [],
    "image_inpainting": [],
    "referring_video_object_segmentation": [],
    "image_classification_team": [],
    "image_classification": [],
    "image_fewshot_detection": [],
    "ocr_recognition": [],
    "ocr_detection_db": [],
    "nerf_recon_acc": [],
    "nerf_recon_4k": [],
    "action_detection": [],
    "vision_efficient_tuning": [],
    "self_supervised_depth_completion": []
  },
  "NLPTrainers": {
    "bert_sentiment_analysis": [],
    "dialog_modeling_trainer": [],
    "dialog_intent_trainer": [],
    "nlp_base_trainer": [],
    "nlp_veco_trainer": [],
    "nlp_text_ranking_trainer": [],
    "nlp_sentence_embedding_trainer": [],
    "text_generation_trainer": [],
    "nlp_plug_trainer": [],
    "gpt3_trainer": [],
    "faq_question_answering_trainer": [],
    "gpt_moe_trainer": [],
    "table_question_answering_trainer": [],
    "document_grounded_dialog_generate_trainer": [],
    "document_grounded_dialog_rerank_trainer": [],
    "document_grounded_dialog_retrieval_trainer": [],
    "siamese_uie_trainer": [],
    "translation_evaluation_trainer": []
  },
  "MultiModalTrainers": {
    "clip_multi_modal_embedding": [],
    "ofa": [],
    "mplug": [],
    "mgeo_ranking_trainer": [],
    "efficient_diffusion_tuning": [],
    "stable_diffusion": [],
    "lora_diffusion": [],
    "lora_diffusion_xl": [],
    "dreambooth_diffusion": [],
    "custom_diffusion": [],
    "cones2_inference": []
  },
  "AudioTrainers": {
    "speech_frcrn_ans_cirm_16k": [],
    "speech_dfsmn_kws_char_farfield": [],
    "speech_kws_fsmn_char_ctc_nearfield": [],
    "speech_kantts_trainer": [],
    "speech_asr_trainer": [],
    "speech_separation": []
  },
  "Trainers": {
    "default": [],
    "tinynas_damoyolo": [],
    "get_trainer_domain": [
      "attribute_or_value"
    ]
  },
  "Preprocessors": {
    "load_image": [],
    "image_denoise_preprocessor": [],
    "image_deblur_preprocessor": [],
    "object_detection_tinynas_preprocessor": [],
    "image_classification_mmcv_preprocessor": [],
    "image_color_enhance_preprocessor": [],
    "image_instance_segmentation_preprocessor": [],
    "image_driving_perception_preprocessor": [],
    "image_portrait_enhancement_preprocessor": [],
    "image_quality_assessment_man_preprocessor": [],
    "image_quality_assessment_mos_preprocessor": [],
    "video_summarization_preprocessor": [],
    "movie_scene_segmentation_preprocessor": [],
    "image_classification_bypass_preprocessor": [],
    "object_detection_scrfd": [],
    "image_sky_change_preprocessor": [],
    "image_demoire_preprocessor": [],
    "ocr_recognition": [],
    "ocr_detection": [],
    "bad_image_detecting_preprocessor": [],
    "nerf_recon_acc_preprocessor": [],
    "nerf_recon_4k_preprocessor": [],
    "nerf_recon_vq_compression_preprocessor": [],
    "controllable_image_generation_preprocessor": [],
    "image_classification_preprocessor": [],
    "sen_sim_tokenizer": [],
    "cross_encoder_tokenizer": [],
    "bert_seq_cls_tokenizer": [],
    "text_gen_tokenizer": [],
    "text2text_gen_preprocessor": [],
    "text_gen_jieba_tokenizer": [],
    "text2text_translate_preprocessor": [],
    "token_cls_tokenizer": [],
    "ner_tokenizer": [],
    "thai_ner_tokenizer": [],
    "viet_ner_tokenizer": [],
    "nli_tokenizer": [],
    "sen_cls_tokenizer": [],
    "dialog_intent_preprocessor": [],
    "dialog_modeling_preprocessor": [],
    "dialog_state_tracking_preprocessor": [],
    "sbert_token_cls_tokenizer": [],
    "zero_shot_cls_tokenizer": [],
    "text_error_correction": [],
    "word_alignment": [],
    "sentence_embedding": [],
    "text_ranking": [],
    "sequence_labeling_tokenizer": [],
    "word_segment_text_to_label_preprocessor": [],
    "thai_wseg_tokenizer": [],
    "fill_mask": [],
    "fill_mask_ponet": [],
    "faq_question_answering_preprocessor": [],
    "conversational_text_to_sql": [],
    "table_question_answering_preprocessor": [],
    "re_tokenizer": [],
    "document_segmentation": [],
    "feature_extraction": [],
    "mglm_summarization": [],
    "sentence_piece": [],
    "translation_evaluation": [],
    "canmt_translation": [],
    "dialog_use_preprocessor": [],
    "siamese_uie_preprocessor": [],
    "document_grounded_dialog_retrieval": [],
    "document_grounded_dialog_rerank": [],
    "document_grounded_dialog_generate": [],
    "machine_reading_comprehension_for_ner": [],
    "linear_aec_fbank": [],
    "text_to_tacotron_symbols": [],
    "wav_to_lists": [],
    "wav_to_scp": [],
    "kantts_data_preprocessor": [],
    "ofa_tasks_preprocessor": [],
    "clip_preprocessor": [],
    "mplug_tasks_preprocessor": [],
    "mgeo_ranking": [],
    "vldoc_preprocessor": [],
    "hitea_tasks_preprocessor": [],
    "diffusion_image_generation_preprocessor": [],
    "mplug_owl_preprocessor": [],
    "image_captioning_clip_interrogator_preprocessor": [],
    "unifold_preprocessor": []
  },
  "Metrics": {
    "accuracy": [],
    "multi_average_precision": [],
    "audio_noise_metric": [],
    "PPL": [],
    "BLEU": [],
    "image_denoise_metric": [],
    "video_frame_interpolation_metric": [],
    "video_super_resolution_metric": [],
    "image_ins_seg_coco_metric": [],
    "seq_cls_metric": [],
    "loss_metric": [],
    "token_cls_metric": [],
    "text_gen_metric": [],
    "prediction_saving_wrapper": [],
    "image_color_enhance_metric": [],
    "image_portrait_enhancement_metric": [],
    "video_summarization_metric": [],
    "movie_scene_segmentation_metric": [],
    "image_inpainting_metric": [],
    "NED": [],
    "inbatch_recall": [],
    "referring_video_object_segmentation_metric": [],
    "video_stabilization_metric": [],
    "image_quality_assessment_mos_metric": [],
    "image_quality_assessment_degradation_metric": [],
    "text_ranking_metric": [],
    "image_colorization_metric": [],
    "ocr_recognition_metric": [],
    "translation_evaluation_metric": []
  },
  "Optimizers": {
    "default": [],
    "SGD": []
  },
  "Hooks": {
    "LrSchedulerHook": [],
    "PlateauLrSchedulerHook": [],
    "NoneLrSchedulerHook": [],
    "OptimizerHook": [],
    "TorchAMPOptimizerHook": [],
    "ApexAMPOptimizerHook": [],
    "NoneOptimizerHook": [],
    "CheckpointHook": [],
    "BestCkptSaverHook": [],
    "LoadCheckpointHook": [],
    "TextLoggerHook": [],
    "TensorboardHook": [],
    "IterTimerHook": [],
    "EvaluationHook": [],
    "SparsityHook": [],
    "ClipClampLogitScaleHook": [],
    "EarlyStopHook": [],
    "DeepspeedHook": [],
    "MegatronHook": [],
    "DDPHook": [],
    "SwiftHook": []
  },
  "LR_Schedulers": {
    "LinearWarmup": [],
    "ConstantWarmup": [],
    "ExponentialWarmup": []
  },
  "CustomDatasets": {
    "PairedDataset": [],
    "SiddDataset": [],
    "GoproDataset": [],
    "RedsDataset": []
  },
  "__all__": [],
  "LUTTransformFunction": {
    "forward": [
      "ctx",
      "img",
      "lut"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "AiLUTTransformFunction": {
    "forward": [
      "ctx",
      "img",
      "lut",
      "vertices"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "ailut_transform": [
    "img",
    "lut",
    "vertices"
  ],
  "lut_transform": [
    "img",
    "lut"
  ],
  "EasyDict": {
    "__getattr__": [
      "self",
      "name"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "__delattr__": [
      "self",
      "name"
    ]
  },
  "_dnnlib_cache_dir": [],
  "set_cache_dir": [
    "path"
  ],
  "make_cache_dir_path": [],
  "verbosity": [],
  "_find_compiler_bindir": [],
  "_get_mangled_gpu_name": [],
  "_cached_plugins": [],
  "get_plugin": [
    "module_name",
    "sources",
    "headers",
    "source_dir"
  ],
  "_constant_cache": [],
  "constant": [
    "value",
    "shape",
    "dtype",
    "device",
    "memory_format"
  ],
  "suppress_tracer_warnings": [],
  "assert_shape": [
    "tensor",
    "ref_shape"
  ],
  "profiled_function": [
    "fn"
  ],
  "InfiniteSampler": {
    "__init__": [
      "self",
      "dataset",
      "rank",
      "num_replicas",
      "shuffle",
      "seed",
      "window_size"
    ],
    "__iter__": [
      "self"
    ]
  },
  "params_and_buffers": [
    "module"
  ],
  "named_params_and_buffers": [
    "module"
  ],
  "copy_params_and_buffers": [
    "src_module",
    "dst_module",
    "require_all"
  ],
  "ddp_sync": [
    "module",
    "sync"
  ],
  "check_ddp_consistency": [
    "module",
    "ignore_regex"
  ],
  "print_module_summary": [
    "module",
    "inputs",
    "max_nesting",
    "skip_redundant"
  ],
  "_version": [],
  "_decorators": [],
  "_import_hooks": [],
  "_module_to_src_dict": [],
  "_src_to_module_dict": [],
  "persistent_class": [
    "orig_class"
  ],
  "is_persistent": [
    "obj"
  ],
  "import_hook": [
    "hook"
  ],
  "_reconstruct_persistent_obj": [
    "meta"
  ],
  "_module_to_src": [
    "module"
  ],
  "_src_to_module": [
    "src"
  ],
  "_check_pickleable": [
    "obj"
  ],
  "_get_weight_shape": [
    "w"
  ],
  "_conv2d_wrapper": [
    "x",
    "w",
    "stride",
    "padding",
    "groups",
    "transpose",
    "flip_weight"
  ],
  "conv2d_resample": [
    "x",
    "w",
    "f",
    "up",
    "down",
    "padding",
    "groups",
    "flip_weight",
    "flip_filter"
  ],
  "enabled": [],
  "weight_gradients_disabled": [],
  "no_weight_gradients": [
    "disable"
  ],
  "conv2d": [
    "input",
    "weight",
    "bias",
    "stride",
    "padding",
    "dilation",
    "groups"
  ],
  "conv_transpose2d": [
    "input",
    "weight",
    "bias",
    "stride",
    "padding",
    "output_padding",
    "groups",
    "dilation"
  ],
  "_should_use_custom_op": [
    "input"
  ],
  "_tuple_of_ints": [
    "xs",
    "ndim"
  ],
  "_conv2d_gradfix_cache": [],
  "_null_tensor": [],
  "_conv2d_gradfix": [
    "transpose",
    "weight_shape",
    "stride",
    "padding",
    "output_padding",
    "dilation",
    "groups"
  ],
  "grid_sample": [
    "input",
    "grid"
  ],
  "_GridSample2dForward": {
    "forward": [
      "ctx",
      "input",
      "grid"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "_GridSample2dBackward": {
    "forward": [
      "ctx",
      "grad_output",
      "input",
      "grid"
    ],
    "backward": [
      "ctx",
      "grad2_grad_input",
      "grad2_grad_grid"
    ]
  },
  "_plugin": [],
  "_init": [],
  "_parse_scaling": [
    "scaling"
  ],
  "_parse_padding": [
    "padding"
  ],
  "_get_filter_size": [
    "f"
  ],
  "setup_filter": [
    "f",
    "device",
    "normalize",
    "flip_filter",
    "gain",
    "separable"
  ],
  "upfirdn2d": [
    "x",
    "f",
    "up",
    "down",
    "padding",
    "flip_filter",
    "gain",
    "impl"
  ],
  "_upfirdn2d_ref": [
    "x",
    "f",
    "up",
    "down",
    "padding",
    "flip_filter",
    "gain"
  ],
  "_upfirdn2d_cuda_cache": [],
  "_upfirdn2d_cuda": [
    "up",
    "down",
    "padding",
    "flip_filter",
    "gain"
  ],
  "filter2d": [
    "x",
    "f",
    "padding",
    "flip_filter",
    "gain",
    "impl"
  ],
  "upsample2d": [
    "x",
    "f",
    "up",
    "padding",
    "flip_filter",
    "gain",
    "impl"
  ],
  "downsample2d": [
    "x",
    "f",
    "down",
    "padding",
    "flip_filter",
    "gain",
    "impl"
  ],
  "filtered_lrelu": [
    "x",
    "fu",
    "fd",
    "b",
    "up",
    "down",
    "padding",
    "gain",
    "slope",
    "clamp",
    "flip_filter",
    "impl"
  ],
  "_filtered_lrelu_ref": [
    "x",
    "fu",
    "fd",
    "b",
    "up",
    "down",
    "padding",
    "gain",
    "slope",
    "clamp",
    "flip_filter"
  ],
  "_filtered_lrelu_cuda_cache": [],
  "_filtered_lrelu_cuda": [
    "up",
    "down",
    "padding",
    "gain",
    "slope",
    "clamp",
    "flip_filter"
  ],
  "fma": [
    "a",
    "b",
    "c"
  ],
  "_FusedMultiplyAdd": {
    "forward": [
      "ctx",
      "a",
      "b",
      "c"
    ],
    "backward": [
      "ctx",
      "dout"
    ]
  },
  "_unbroadcast": [
    "x",
    "shape"
  ],
  "activation_funcs": [],
  "bias_act": [
    "x",
    "b",
    "dim",
    "act",
    "alpha",
    "gain",
    "clamp",
    "impl"
  ],
  "_bias_act_ref": [
    "x",
    "b",
    "dim",
    "act",
    "alpha",
    "gain",
    "clamp"
  ],
  "_bias_act_cuda_cache": [],
  "_bias_act_cuda": [
    "dim",
    "act",
    "alpha",
    "gain",
    "clamp"
  ],
  "cur_dir": [],
  "score_computation_cuda": [],
  "value_aggregation_cuda": [],
  "ScoreComputation": {
    "forward": [
      "ctx",
      "query",
      "key",
      "index"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "score_computation_op": [],
  "value_aggregation": {
    "forward": [
      "ctx",
      "score",
      "value",
      "index"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "value_aggregation_op": [],
  "QTAttA": {
    "__init__": [
      "self",
      "nhead",
      "dim",
      "topks",
      "scale",
      "use_dropout",
      "attention_dropout"
    ],
    "process_coarse_level": [
      "self",
      "query",
      "key",
      "value",
      "topk"
    ],
    "process_fine_level": [
      "self",
      "query",
      "key",
      "value",
      "topk_score",
      "topk_pos",
      "topk_prev",
      "topk",
      "final"
    ],
    "forward": [
      "self",
      "queries",
      "keys",
      "values",
      "q_mask",
      "kv_mask"
    ]
  },
  "QTAttB": {
    "__init__": [
      "self",
      "nhead",
      "dim",
      "scale",
      "topks",
      "use_dropout",
      "attention_dropout",
      "lepe"
    ],
    "process_coarse_level": [
      "self",
      "query",
      "key",
      "value",
      "topk"
    ],
    "process_fine_level": [
      "self",
      "query",
      "key",
      "value",
      "topk_score",
      "topk_pos",
      "topk_prev",
      "topk",
      "final"
    ],
    "forward": [
      "self",
      "queries",
      "keys",
      "values",
      "q_mask",
      "kv_mask"
    ]
  },
  "module_path": [],
  "fused": [],
  "FusedLeakyReLUFunctionBackward": {
    "forward": [
      "ctx",
      "grad_output",
      "out",
      "bias",
      "negative_slope",
      "scale"
    ],
    "backward": [
      "ctx",
      "gradgrad_input",
      "gradgrad_bias"
    ]
  },
  "FusedLeakyReLUFunction": {
    "forward": [
      "ctx",
      "input",
      "bias",
      "negative_slope",
      "scale"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "FusedLeakyReLU": {
    "__init__": [
      "self",
      "channel",
      "bias",
      "negative_slope",
      "scale"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "fused_leaky_relu": [
    "input",
    "bias",
    "negative_slope",
    "scale"
  ],
  "upfirdn2d_op": [],
  "UpFirDn2dBackward": {
    "forward": [
      "ctx",
      "grad_output",
      "kernel",
      "grad_kernel",
      "up",
      "down",
      "pad",
      "g_pad",
      "in_size",
      "out_size"
    ],
    "backward": [
      "ctx",
      "gradgrad_input"
    ]
  },
  "UpFirDn2d": {
    "forward": [
      "ctx",
      "input",
      "kernel",
      "up",
      "down",
      "pad"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "upfirdn2d_native": [
    "input",
    "kernel",
    "up_x",
    "up_y",
    "down_x",
    "down_y",
    "pad_x0",
    "pad_x1",
    "pad_y0",
    "pad_y1"
  ],
  "logger": [],
  "current_path": [],
  "template_path": [],
  "subparser_func": [
    "args"
  ],
  "ModelCardCMD": {
    "name": [],
    "__init__": [
      "self",
      "args"
    ],
    "define_args": [
      "parsers"
    ],
    "create_model": [
      "self"
    ],
    "get_model_url": [
      "self"
    ],
    "push_model": [
      "self",
      "tpl_dir"
    ],
    "pprint": [
      "self"
    ],
    "execute": [
      "self"
    ]
  },
  "CLICommand": {
    "define_args": [
      "parsers"
    ],
    "execute": [
      "self"
    ]
  },
  "LoginCMD": {
    "name": [],
    "__init__": [
      "self",
      "args"
    ],
    "define_args": [
      "parsers"
    ],
    "execute": [
      "self"
    ]
  },
  "plugins_manager": [],
  "PluginsCMD": {
    "name": [],
    "__init__": [
      "self",
      "args"
    ],
    "define_args": [
      "parsers"
    ],
    "execute": [
      "self"
    ]
  },
  "PluginsInstallCMD": {
    "name": [],
    "define_args": [
      "parsers"
    ],
    "execute": [
      "args"
    ]
  },
  "PluginsUninstallCMD": {
    "name": [],
    "define_args": [
      "parsers"
    ],
    "execute": [
      "args"
    ]
  },
  "PluginsListCMD": {
    "name": [],
    "define_args": [
      "parsers"
    ],
    "execute": [
      "args"
    ]
  },
  "UploadCMD": {
    "name": [],
    "__init__": [
      "self",
      "args"
    ],
    "define_args": [
      "parsers"
    ],
    "execute": [
      "self"
    ]
  },
  "run_cmd": [],
  "PipelineCMD": {
    "name": [],
    "__init__": [
      "self",
      "args"
    ],
    "define_args": [
      "parsers"
    ],
    "create_template": [
      "self"
    ],
    "execute": [
      "self"
    ]
  },
  "LlamafileCMD": {
    "name": [],
    "__init__": [
      "self",
      "args"
    ],
    "define_args": [
      "parsers"
    ],
    "execute": [
      "self"
    ],
    "_execute_llamafile": [
      "self",
      "file_path"
    ],
    "_rename_extension": [
      "self",
      "original_file_name"
    ]
  },
  "ServerCMD": {
    "name": [],
    "__init__": [
      "self",
      "args"
    ],
    "define_args": [
      "parsers"
    ],
    "execute": [
      "self"
    ]
  },
  "ClearCacheCMD": {
    "name": [],
    "__init__": [
      "self",
      "args"
    ],
    "define_args": [
      "parsers"
    ],
    "execute": [
      "self"
    ],
    "_execute_with_confirmation": [
      "self"
    ],
    "_remove_directory": [
      "self",
      "path"
    ]
  },
  "DownloadCMD": {
    "name": [],
    "__init__": [
      "self",
      "args"
    ],
    "define_args": [
      "parsers"
    ],
    "execute": [
      "self"
    ]
  },
  "ScanCacheCMD": {
    "name": [],
    "__init__": [
      "self",
      "args"
    ],
    "define_args": [
      "parsers"
    ],
    "execute": [
      "self"
    ]
  },
  "CreateCMD": {
    "name": [],
    "__init__": [
      "self",
      "args"
    ],
    "define_args": [
      "parsers"
    ],
    "execute": [
      "self"
    ],
    "_create_regular_repo": [
      "self"
    ],
    "_create_aigc_model": [
      "self"
    ]
  },
  "PredictionSavingWrapper": {
    "__init__": [
      "self",
      "saving_fn"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "DetEvaluator": {
    "__init__": [
      "self",
      "class_names",
      "output_dir",
      "distributed"
    ],
    "reset": [
      "self"
    ],
    "process": [
      "self",
      "input",
      "output"
    ],
    "get_instance_by_class": [
      "self",
      "instances",
      "c"
    ],
    "evaluate": [
      "self"
    ],
    "calc_map": [
      "self",
      "iou_th"
    ],
    "det_eval": [
      "self",
      "iou_th",
      "class_id"
    ]
  },
  "interpolate_precision": [
    "rec",
    "prec"
  ],
  "TranslationEvaluationMetric": {
    "__init__": [
      "self",
      "gap_threshold"
    ],
    "clear": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "compute_kendall_tau": [
      "self",
      "csv_data"
    ]
  },
  "EVAL_BLEU_ORDER": [],
  "BleuMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "calculate_psnr": [
    "img",
    "img2"
  ],
  "ImagePortraitEnhancementMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "TextRankingMetric": {
    "__init__": [
      "self",
      "mrr_k",
      "ndcg_k"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "_sigmoid": [
      "logits"
    ],
    "_compute_mrr": [
      "self",
      "result"
    ],
    "_compute_ndcg": [
      "self",
      "result"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "Metric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ]
  },
  "MovieSceneSegmentationMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "ImageQualityAssessmentMosMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "AudioNoiseMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "SequenceClassificationMetric": {
    "__init__": [
      "self",
      "label_name",
      "logit_name"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "evaluate_summary": [
    "predicted_summary",
    "user_summary",
    "eval_method"
  ],
  "calculate_f_score": [
    "outputs",
    "inputs"
  ],
  "VideoSummarizationMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "TokenClassificationMetric": {
    "__init__": [
      "self",
      "label_name",
      "logit_name",
      "return_entity_level_metrics",
      "label2id"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "_compute": [
      "predictions",
      "references",
      "suffix",
      "scheme",
      "mode",
      "sample_weight",
      "zero_division"
    ]
  },
  "VideoStabilizationMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "warpprocess": [
    "inputs"
  ],
  "video_merger": [
    "inputs"
  ],
  "metrics": [
    "original_v",
    "pred_v"
  ],
  "LossMetric": {
    "__init__": [
      "self",
      "loss_key"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "METRICS": [],
  "MetricKeys": {
    "ACCURACY": [],
    "F1": [],
    "Binary_F1": [],
    "Macro_F1": [],
    "Micro_F1": [],
    "PRECISION": [],
    "RECALL": [],
    "PSNR": [],
    "SSIM": [],
    "LPIPS": [],
    "NIQE": [],
    "AVERAGE_LOSS": [],
    "FScore": [],
    "FID": [],
    "BLEU_1": [],
    "BLEU_4": [],
    "ROUGE_1": [],
    "ROUGE_L": [],
    "NED": [],
    "mAP": [],
    "BatchAcc": [],
    "CROPPING_RATIO": [],
    "DISTORTION_VALUE": [],
    "STABILITY_SCORE": [],
    "PPL": [],
    "PLCC": [],
    "SRCC": [],
    "RMSE": [],
    "MRR": [],
    "NDCG": [],
    "AR": [],
    "Colorfulness": [],
    "Kendall_Tau_Correlation": []
  },
  "task_default_metrics": [],
  "build_metric": [
    "metric_cfg",
    "field",
    "default_args"
  ],
  "AccuracyMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "VideoFrameInterpolationMetric": {
    "pred_name": [],
    "label_name": [],
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "gaussian": [
    "window_size",
    "sigma"
  ],
  "create_window_3d": [
    "window_size",
    "channel",
    "device"
  ],
  "calculate_ssim": [
    "img1",
    "img2",
    "window_size",
    "window",
    "size_average",
    "full",
    "val_range"
  ],
  "calculate_lpips": [
    "img1",
    "img2",
    "loss_fn_alex"
  ],
  "ImageColorizationMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "image_colorfulness": [
    "image"
  ],
  "calculate_colorfulness": [
    "pred"
  ],
  "INCEPTION_V3_FID": {
    "DEFAULT_BLOCK_INDEX": [],
    "BLOCK_INDEX_BY_DIM": [],
    "__init__": [
      "self",
      "incep_state_dict",
      "output_blocks",
      "resize_input"
    ],
    "forward": [
      "self",
      "inp"
    ]
  },
  "get_activations": [
    "images",
    "model",
    "batch_size",
    "verbose"
  ],
  "calculate_activation_statistics": [
    "act"
  ],
  "calculate_frechet_distance": [
    "mu1",
    "sigma1",
    "mu2",
    "sigma2",
    "eps"
  ],
  "calculate_fid": [
    "preds",
    "targets",
    "device"
  ],
  "ReferringVideoObjectSegmentationMetric": {
    "__init__": [
      "self",
      "ann_file",
      "calculate_precision_and_iou_metrics"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "compute_iou": [
    "outputs",
    "labels",
    "EPS"
  ],
  "calculate_precision_at_k_and_iou_metrics": [
    "coco_gt",
    "coco_pred"
  ],
  "fid_calculate_activation_statistics": [
    "act"
  ],
  "FIDScore": {
    "__init__": [
      "self",
      "dims",
      "eps"
    ],
    "forward": [
      "self",
      "pred_batch",
      "target_batch",
      "mask"
    ],
    "get_value": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "_get_activations": [
      "self",
      "batch"
    ]
  },
  "SSIM": {
    "__init__": [
      "self",
      "window_size",
      "size_average"
    ],
    "forward": [
      "self",
      "img1",
      "img2"
    ],
    "_gaussian": [
      "self",
      "window_size",
      "sigma"
    ],
    "_create_window": [
      "self",
      "window_size",
      "channel"
    ],
    "_ssim": [
      "self",
      "img1",
      "img2",
      "window",
      "window_size",
      "channel",
      "size_average"
    ],
    "_load_from_state_dict": [
      "self",
      "state_dict",
      "prefix",
      "local_metadata",
      "strict",
      "missing_keys",
      "unexpected_keys",
      "error_msgs"
    ]
  },
  "ImageInpaintingMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "TextGenerationMetric": {
    "__init__": [
      "self",
      "target_text",
      "pred_text"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "_check": [
      "self",
      "pred",
      "tgt"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "extend_recursion_limit": [
    "preds",
    "tgts"
  ],
  "PplMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "_get_loss": [
      "logits",
      "labels"
    ],
    "_get_batch_num": [
      "matrix"
    ],
    "_average_loss": [
      "self",
      "in_loss",
      "in_batch_num"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "ImageQualityAssessmentDegradationMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "ImageDenoiseMetric": {
    "pred_name": [],
    "label_name": [],
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "reorder_image": [
    "img",
    "input_order"
  ],
  "_ssim": [
    "img",
    "img2",
    "max_value"
  ],
  "_3d_gaussian_calculator": [
    "img",
    "conv3d"
  ],
  "_generate_3d_gaussian_kernel": [],
  "_ssim_3d": [
    "img1",
    "img2",
    "max_value"
  ],
  "bgr2ycbcr": [
    "img",
    "y_only"
  ],
  "to_y_channel": [
    "img"
  ],
  "ImageColorEnhanceMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "cal_distance": [
    "label_list",
    "pre_list"
  ],
  "OCRRecognitionMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "AveragePrecisionMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "_calculate_ap_score": [
      "self",
      "preds",
      "labels",
      "thresh"
    ]
  },
  "ImageInstanceSegmentationCOCOMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "format_results": [
      "self",
      "results",
      "img_ids",
      "jsonfile_prefix"
    ],
    "xyxy2xywh": [
      "self",
      "bbox"
    ],
    "_proposal2json": [
      "self",
      "results"
    ],
    "_det2json": [
      "self",
      "results"
    ],
    "_segm2json": [
      "self",
      "results"
    ],
    "results2json": [
      "self",
      "results",
      "outfile_prefix"
    ]
  },
  "encode_mask_results": [
    "mask_results"
  ],
  "NedMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "_distance": [
      "pred",
      "ref"
    ]
  },
  "InbatchRecallMetric": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "CiderD": {
    "__init__": [
      "self",
      "n",
      "sigma",
      "df"
    ],
    "compute_score": [
      "self",
      "gts",
      "res"
    ],
    "method": [
      "self"
    ]
  },
  "precook": [
    "s",
    "n",
    "out"
  ],
  "cook_refs": [
    "refs",
    "n"
  ],
  "cook_test": [
    "test",
    "n"
  ],
  "CiderScorer": {
    "copy": [
      "self"
    ],
    "copy_empty": [
      "self"
    ],
    "__init__": [
      "self",
      "df_mode",
      "test",
      "refs",
      "n",
      "sigma"
    ],
    "clear": [
      "self"
    ],
    "cook_append": [
      "self",
      "test",
      "refs"
    ],
    "size": [
      "self"
    ],
    "__iadd__": [
      "self",
      "other"
    ],
    "compute_doc_freq": [
      "self"
    ],
    "compute_cider": [
      "self"
    ],
    "compute_score": [
      "self",
      "option",
      "verbose"
    ]
  },
  "__author__": [],
  "_convert_input_type_range": [
    "img"
  ],
  "_convert_output_type_range": [
    "img",
    "dst_type"
  ],
  "downloaded_file_path": [],
  "estimate_aggd_param": [
    "block"
  ],
  "compute_feature": [
    "block"
  ],
  "niqe": [
    "img",
    "mu_pris_param",
    "cov_pris_param",
    "gaussian_window",
    "block_size_h",
    "block_size_w"
  ],
  "calculate_niqe": [
    "img",
    "crop_border",
    "input_order",
    "convert_to"
  ],
  "VideoSuperResolutionMetric": {
    "pred_name": [],
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "outputs",
      "inputs"
    ],
    "evaluate": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "cubic": [
    "x"
  ],
  "calculate_weights_indices": [
    "in_length",
    "out_length",
    "scale",
    "kernel",
    "kernel_width",
    "antialiasing"
  ],
  "imresize": [
    "img",
    "scale",
    "antialiasing"
  ],
  "format_handlers": [],
  "load": [
    "file",
    "file_format"
  ],
  "dump": [
    "obj",
    "file",
    "file_format"
  ],
  "dumps": [
    "obj",
    "format"
  ],
  "Storage": {
    "read": [
      "self",
      "filepath"
    ],
    "read_text": [
      "self",
      "filepath"
    ],
    "write": [
      "self",
      "obj",
      "filepath"
    ],
    "write_text": [
      "self",
      "obj",
      "filepath",
      "encoding"
    ]
  },
  "LocalStorage": {
    "read": [
      "self",
      "filepath"
    ],
    "read_text": [
      "self",
      "filepath",
      "encoding"
    ],
    "write": [
      "self",
      "obj",
      "filepath"
    ],
    "write_text": [
      "self",
      "obj",
      "filepath",
      "encoding"
    ],
    "as_local_path": [
      "self",
      "filepath"
    ]
  },
  "HTTPStorage": {
    "read": [
      "self",
      "url"
    ],
    "read_text": [
      "self",
      "url"
    ],
    "as_local_path": [
      "self",
      "filepath"
    ],
    "write": [
      "self",
      "obj",
      "url"
    ],
    "write_text": [
      "self",
      "obj",
      "url",
      "encoding"
    ]
  },
  "OSSStorage": {
    "__init__": [
      "self",
      "oss_config_file"
    ],
    "read": [
      "self",
      "filepath"
    ],
    "read_text": [
      "self",
      "filepath",
      "encoding"
    ],
    "as_local_path": [
      "self",
      "filepath"
    ],
    "write": [
      "self",
      "obj",
      "filepath"
    ],
    "write_text": [
      "self",
      "obj",
      "filepath",
      "encoding"
    ]
  },
  "G_STORAGES": [],
  "File": {
    "_get_storage": [
      "uri"
    ],
    "read": [
      "uri"
    ],
    "read_text": [
      "uri",
      "encoding"
    ],
    "write": [
      "obj",
      "uri"
    ],
    "write_text": [
      "obj",
      "uri",
      "encoding"
    ],
    "as_local_path": [
      "uri"
    ]
  },
  "FormatHandler": {
    "text_mode": [],
    "load": [
      "self",
      "file"
    ],
    "dump": [
      "self",
      "obj",
      "file"
    ],
    "dumps": [
      "self",
      "obj"
    ]
  },
  "EXACT": [],
  "COMPAT": [],
  "CODING_DEFAULT": [],
  "_local": [],
  "prefer": [
    "coding"
  ],
  "prefer_exact": [],
  "prefer_compat": [],
  "getattrs": [
    "value",
    "attrs"
  ],
  "kwargified": [
    "constructor"
  ],
  "_PredicatedEncoder": [],
  "encoder": [
    "classname",
    "predicate",
    "priority",
    "exact"
  ],
  "_json_default_exact": [
    "obj"
  ],
  "_json_default_compat": [
    "obj"
  ],
  "decoder": [
    "classname"
  ],
  "_json_object_hook": [
    "dict"
  ],
  "_encoder_default_args": [
    "kw"
  ],
  "_decoder_default_args": [
    "kw"
  ],
  "JSONEncoder": {
    "__init__": [
      "self"
    ]
  },
  "JSONDecoder": {
    "__init__": [
      "self"
    ]
  },
  "loads": [],
  "pretty": [
    "x",
    "sort_keys",
    "indent",
    "separators"
  ],
  "json_dumps": [],
  "json_loads": [],
  "json_prettydump": [],
  "np_to_list": [
    "value"
  ],
  "generic_to_item": [
    "value"
  ],
  "_encode_handlers": [],
  "_decode_handlers": [],
  "_dump_namedtuple": [
    "obj"
  ],
  "_load_namedtuple": [
    "val"
  ],
  "_timedelta_total_seconds": [
    "td"
  ],
  "_dump_currency": [
    "obj"
  ],
  "_load_currency": [
    "val"
  ],
  "_load_money": [
    "val"
  ],
  "YamlHandler": {
    "load": [
      "self",
      "file"
    ],
    "dump": [
      "self",
      "obj",
      "file"
    ],
    "dumps": [
      "self",
      "obj"
    ]
  },
  "set_default": [
    "obj"
  ],
  "JsonHandler": {
    "load": [
      "self",
      "file"
    ],
    "dump": [
      "self",
      "obj",
      "file"
    ],
    "dumps": [
      "self",
      "obj"
    ]
  },
  "type_assert": [],
  "_find_free_port": [],
  "_is_free_port": [
    "port"
  ],
  "compile_model": [
    "model"
  ],
  "init_dist": [
    "launcher",
    "backend"
  ],
  "_init_dist_pytorch": [
    "backend"
  ],
  "_init_dist_mpi": [
    "backend"
  ],
  "_init_dist_slurm": [
    "backend",
    "port"
  ],
  "get_dist_info": [
    "group"
  ],
  "get_local_rank": [],
  "get_rank": [],
  "get_world_size": [],
  "synchronize": [],
  "is_dist": [],
  "is_master": [
    "group"
  ],
  "master_only": [
    "group"
  ],
  "make_tmp_dir": [],
  "broadcast": [
    "inputs",
    "src"
  ],
  "set_random_seed": [
    "seed"
  ],
  "_get_global_gloo_group": [],
  "_serialize_to_tensor": [
    "data",
    "group"
  ],
  "_pad_to_largest_tensor": [
    "tensor",
    "group"
  ],
  "all_gather": [
    "data",
    "group"
  ],
  "is_on_same_device": [
    "model"
  ],
  "apply_chunking_to_forward": [
    "forward_fn",
    "chunk_size",
    "chunk_dim"
  ],
  "find_pruneable_heads_and_indices": [
    "heads",
    "n_heads",
    "head_size",
    "already_pruned_heads"
  ],
  "prune_linear_layer": [
    "layer",
    "index",
    "dim"
  ],
  "func_receive_dict_inputs": [
    "func"
  ],
  "get_default_modelscope_cache_dir": [],
  "get_modelscope_cache_dir": [],
  "get_model_cache_root": [],
  "get_dataset_cache_root": [],
  "get_dataset_cache_dir": [
    "dataset_id"
  ],
  "get_model_cache_dir": [
    "model_id"
  ],
  "read_file": [
    "path"
  ],
  "copytree_py37": [
    "src",
    "dst",
    "symlinks",
    "ignore",
    "copy_function",
    "ignore_dangling_symlinks",
    "dirs_exist_ok"
  ],
  "get_file_size": [
    "file_path_or_obj"
  ],
  "get_file_hash": [
    "file_path_or_obj",
    "buffer_size_mb",
    "tqdm_desc",
    "disable_tqdm"
  ],
  "is_relative_path": [
    "url_or_filename"
  ],
  "init_loggers": [],
  "formatter": [],
  "default_log_level": [],
  "get_logger": [
    "log_file",
    "log_level",
    "file_mode"
  ],
  "add_file_handler_if_needed": [
    "logger",
    "log_file",
    "file_mode",
    "log_level"
  ],
  "compatible_position_ids": [
    "state_dict",
    "position_id_key"
  ],
  "p": [],
  "SKIP_FUNCTION_SCANNING": [],
  "MODELSCOPE_PATH": [],
  "INDEXER_FILE_DIR": [],
  "REGISTER_MODULE": [],
  "IGNORED_PACKAGES": [],
  "SCAN_SUB_FOLDERS": [],
  "INDEXER_FILE": [],
  "DECORATOR_KEY": [],
  "EXPRESS_KEY": [],
  "FROM_IMPORT_KEY": [],
  "IMPORT_KEY": [],
  "FILE_NAME_KEY": [],
  "MODELSCOPE_PATH_KEY": [],
  "VERSION_KEY": [],
  "MD5_KEY": [],
  "INDEX_KEY": [],
  "FILES_MTIME_KEY": [],
  "REQUIREMENT_KEY": [],
  "MODULE_KEY": [],
  "CLASS_NAME": [],
  "GROUP_KEY": [],
  "MODULE_NAME": [],
  "MODULE_CLS": [],
  "TEMPLATE_PATH": [],
  "TEMPLATE_FILE": [],
  "get_ast_logger": [],
  "AstScanning": {
    "__init__": [
      "self"
    ],
    "_is_sub_node": [
      "self",
      "node"
    ],
    "_is_leaf": [
      "self",
      "node"
    ],
    "_skip_function": [
      "self",
      "node"
    ],
    "_fields": [
      "self",
      "n",
      "show_offsets"
    ],
    "_leaf": [
      "self",
      "node",
      "show_offsets"
    ],
    "_refresh": [
      "self"
    ],
    "scan_ast": [
      "self",
      "node"
    ],
    "scan_import": [
      "self",
      "node",
      "show_offsets",
      "parent_node_name"
    ],
    "_parse_decorator": [
      "self",
      "node"
    ],
    "_get_registry_value": [
      "self",
      "key_item"
    ],
    "_registry_indexer": [
      "self",
      "parsed_input",
      "class_name"
    ],
    "parse_decorators": [
      "self",
      "nodes"
    ],
    "generate_ast": [
      "self",
      "file"
    ]
  },
  "FilesAstScanning": {
    "__init__": [
      "self"
    ],
    "_parse_import_path": [
      "self",
      "import_package",
      "current_path"
    ],
    "_traversal_import": [
      "self",
      "import_abs_path"
    ],
    "parse_import": [
      "self",
      "scan_result"
    ],
    "traversal_files": [
      "self",
      "path",
      "check_sub_dir",
      "include_init"
    ],
    "_traversal_files": [
      "self",
      "path",
      "include_init"
    ],
    "_get_single_file_scan_result": [
      "self",
      "file"
    ],
    "_inverted_index": [
      "self",
      "forward_index"
    ],
    "_module_import": [
      "self",
      "forward_index"
    ],
    "_ignore_useless_keys": [
      "self",
      "inverted_index"
    ],
    "get_files_scan_results": [
      "self",
      "target_file_list",
      "target_dir",
      "target_folders"
    ],
    "files_mtime_md5": [
      "self",
      "target_path",
      "target_subfolder",
      "file_list"
    ]
  },
  "file_scanner": [],
  "ensure_write": [
    "obj",
    "filepath"
  ],
  "_save_index": [
    "index",
    "file_path",
    "file_list",
    "with_template"
  ],
  "_load_index": [
    "file_path",
    "with_template"
  ],
  "_update_index": [
    "index",
    "files_mtime"
  ],
  "__is_develop_model": [],
  "load_index": [
    "file_list",
    "force_rebuild",
    "indexer_file_dir",
    "indexer_file"
  ],
  "load_from_prebuilt": [
    "file_path"
  ],
  "generate_ast_template": [
    "file_path",
    "force_rebuild"
  ],
  "TreeNode": {
    "__init__": [
      "self"
    ]
  },
  "Trie": {
    "__init__": [
      "self",
      "eos"
    ],
    "insert": [
      "self",
      "word"
    ],
    "get_next_layer": [
      "self",
      "word"
    ]
  },
  "AUDIO_IMPORT_ERROR": [],
  "PROTOBUF_IMPORT_ERROR": [],
  "SENTENCEPIECE_IMPORT_ERROR": [],
  "SKLEARN_IMPORT_ERROR": [],
  "TENSORFLOW_IMPORT_ERROR": [],
  "TENSORFLOW_IMPORT_WARNING": [],
  "TIMM_IMPORT_ERROR": [],
  "TOKENIZERS_IMPORT_ERROR": [],
  "PYTORCH_IMPORT_ERROR": [],
  "WENETRUNTIME_IMPORT_ERROR": [],
  "SCIPY_IMPORT_ERROR": [],
  "OPENCV_IMPORT_ERROR": [],
  "PILLOW_IMPORT_ERROR": [],
  "GENERAL_IMPORT_ERROR": [],
  "DECORD_IMPORT_ERROR": [],
  "DEEPSPEED_IMPORT_ERROR": [],
  "FAIRSEQ_IMPORT_ERROR": [],
  "FASTTEXT_IMPORT_ERROR": [],
  "EASYNLP_IMPORT_ERROR": [],
  "MEGATRON_UTIL_IMPORT_ERROR": [],
  "TEXT2SQL_LGESQL_IMPORT_ERROR": [],
  "MPI4PY_IMPORT_ERROR": [],
  "OPENCLIP_IMPORT_ERROR": [],
  "TAMING_IMPORT_ERROR": [],
  "XFORMERS_IMPORT_ERROR": [],
  "SWIFT_IMPORT_ERROR": [],
  "thread_executor": [
    "max_workers",
    "disable_tqdm",
    "tqdm_desc"
  ],
  "storage": [],
  "MODELSCOPE_FILE_DIR": [],
  "MODELSCOPE_DYNAMIC_MODULE": [],
  "BASE_MODULE_DIR": [],
  "PLUGINS_FILENAME": [],
  "OFFICIAL_PLUGINS": [],
  "LOCAL_PLUGINS_FILENAME": [],
  "GLOBAL_PLUGINS_FILENAME": [],
  "DEFAULT_PLUGINS": [],
  "pushd": [
    "new_dir",
    "verbose"
  ],
  "push_python_path": [
    "path"
  ],
  "discover_file_plugins": [
    "filename"
  ],
  "discover_plugins": [
    "requirement_path"
  ],
  "import_all_plugins": [
    "plugins"
  ],
  "import_plugins": [
    "plugins"
  ],
  "import_file_plugins": [
    "requirement_path"
  ],
  "import_module_and_submodules": [
    "package_name",
    "include",
    "exclude"
  ],
  "install_module_from_requirements": [
    "requirement_path"
  ],
  "import_module_from_file": [
    "module_name",
    "file_path"
  ],
  "create_module_from_files": [
    "file_list",
    "file_prefix",
    "module_name"
  ],
  "import_module_from_model_dir": [
    "model_dir"
  ],
  "install_requirements_by_names": [
    "plugins"
  ],
  "install_requirements_by_files": [
    "requirements"
  ],
  "register_plugins_repo": [
    "plugins"
  ],
  "register_modelhub_repo": [
    "model_dir",
    "allow_remote"
  ],
  "DEFAULT_INDEX": [],
  "get_modules_from_package": [
    "package"
  ],
  "PluginsManager": {
    "__init__": [
      "self",
      "cache_dir",
      "plugins_file"
    ],
    "file_path": [
      "self",
      "value"
    ],
    "check_plugin_installed": [
      "package"
    ],
    "_check_plugin_installed": [
      "package",
      "verified_version"
    ],
    "pip_command": [
      "command",
      "command_args"
    ],
    "install_plugins": [
      "self",
      "install_args",
      "index_url",
      "force_update"
    ],
    "parse_args_info": [
      "self",
      "args",
      "options"
    ],
    "uninstall_plugins": [
      "self",
      "uninstall_args",
      "is_yes"
    ],
    "_get_plugins_from_file": [
      "self"
    ],
    "_update_plugins": [
      "self",
      "new_plugins_list",
      "local_plugins_info",
      "override"
    ],
    "_print_plugins_info": [
      "self",
      "local_plugins_info"
    ],
    "list_plugins": [
      "self",
      "show_all"
    ],
    "update_plugins_file": [
      "self",
      "plugins_list",
      "override"
    ],
    "remove_plugins_from_file": [
      "self",
      "package_names"
    ]
  },
  "EnvsManager": {
    "name": [],
    "__init__": [
      "self",
      "model_id",
      "model_revision",
      "cache_dir"
    ],
    "get_env_dir": [
      "self"
    ],
    "get_activate_dir": [
      "self"
    ],
    "check_if_need_env": [
      "self"
    ],
    "create_env": [
      "self"
    ],
    "clean_env": [
      "self"
    ],
    "run_process": [
      "cmd"
    ]
  },
  "can_load_by_ms": [
    "model_dir",
    "task_name",
    "model_type"
  ],
  "fix_upgrade": [
    "module_obj"
  ],
  "post_init": [
    "self"
  ],
  "fix_transformers_upgrade": [],
  "_can_load_by_hf_automodel": [
    "automodel_class",
    "config"
  ],
  "get_default_automodel": [
    "config"
  ],
  "get_hf_automodel_class": [
    "model_dir",
    "task_name"
  ],
  "try_to_load_hf_model": [
    "model_dir",
    "task_name",
    "use_hf"
  ],
  "check_model_from_owner_group": [
    "model_dir",
    "owner_group"
  ],
  "create_model_if_not_exist": [
    "api",
    "model_id",
    "chinese_name",
    "visibility",
    "license"
  ],
  "read_config": [
    "model_id_or_path",
    "revision"
  ],
  "auto_load": [
    "model"
  ],
  "get_model_type": [
    "model_dir"
  ],
  "parse_label_mapping": [
    "model_dir"
  ],
  "weights_to_cpu": [
    "state_dict"
  ],
  "save_checkpoint": [
    "model",
    "filename",
    "optimizer",
    "lr_scheduler",
    "meta",
    "with_meta",
    "with_model"
  ],
  "load_checkpoint": [
    "filename",
    "model",
    "optimizer",
    "lr_scheduler"
  ],
  "load_task_model_checkpoint": [
    "model_to_load",
    "model_local_dir",
    "default_dtype",
    "load_state_fn"
  ],
  "save_configuration": [
    "target_folder",
    "config"
  ],
  "save_pretrained": [
    "model",
    "target_folder",
    "save_checkpoint_name",
    "save_function"
  ],
  "StreamingOutputMixin": {
    "stream_generate": [
      "self"
    ]
  },
  "PipelineStreamingOutputMixin": {
    "stream_generate": [
      "self",
      "input"
    ],
    "_preprocess_with_check": [
      "self",
      "input",
      "preprocess_params"
    ],
    "_stream_single": [
      "self",
      "model_input",
      "forward_params",
      "postprocess_params"
    ],
    "_stream_batch": [
      "self",
      "model_input_list",
      "batch_size",
      "forward_params",
      "postprocess_params"
    ]
  },
  "PretrainedModelStreamingOutputMixin": {
    "stream_generate": [
      "self"
    ],
    "_replace_generate": [
      "self",
      "model"
    ],
    "stream_greedy_search": [
      "self",
      "input_ids",
      "logits_processor",
      "stopping_criteria",
      "max_length",
      "pad_token_id",
      "eos_token_id",
      "output_attentions",
      "output_hidden_states",
      "output_scores",
      "return_dict_in_generate",
      "synced_gpus"
    ],
    "stream_sample": [
      "self",
      "input_ids",
      "logits_processor",
      "stopping_criteria",
      "logits_warper",
      "max_length",
      "pad_token_id",
      "eos_token_id",
      "output_attentions",
      "output_hidden_states",
      "output_scores",
      "return_dict_in_generate",
      "synced_gpus"
    ]
  },
  "add_stream_generate": [
    "model"
  ],
  "TEST_LEVEL": [],
  "TEST_LEVEL_STR": [],
  "TEST_ACCESS_TOKEN1": [],
  "TEST_ACCESS_TOKEN2": [],
  "TEST_MODEL_CHINESE_NAME": [],
  "TEST_MODEL_ORG": [],
  "delete_credential": [],
  "test_level": [],
  "require_tf": [
    "test_case"
  ],
  "require_torch": [
    "test_case"
  ],
  "set_test_level": [
    "level"
  ],
  "DummyTorchDataset": {
    "__init__": [
      "self",
      "feat",
      "label",
      "num"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "create_dummy_test_dataset": [
    "feat",
    "label",
    "num"
  ],
  "download_and_untar": [
    "fpath",
    "furl",
    "dst"
  ],
  "get_case_model_info": [],
  "compare_arguments_nested": [
    "print_content",
    "arg1",
    "arg2",
    "rtol",
    "atol",
    "ignore_unknown_type"
  ],
  "_DIST_SCRIPT_TEMPLATE": [],
  "DistributedTestCase": {
    "_start": [
      "self",
      "dist_start_cmd",
      "func",
      "num_gpus",
      "assert_callback",
      "save_all_ranks"
    ],
    "start": [
      "self",
      "func",
      "num_gpus",
      "assert_callback",
      "save_all_ranks"
    ],
    "clean_tmp": [
      "self",
      "tmp_file_list"
    ]
  },
  "verify_device": [
    "device_name"
  ],
  "device_placement": [
    "framework",
    "device_name"
  ],
  "create_device": [
    "device_name"
  ],
  "get_device": [],
  "ModelTag": {
    "_URL": [],
    "BATCH_COMMIT_RESULT_URL": [],
    "BATCH_REFRESH_STAGE_URL": [],
    "QUERY_MODEL_STAGE_URL": [],
    "HEADER": [],
    "MODEL_SKIP": [],
    "MODEL_FAIL": [],
    "MODEL_PASS": [],
    "__init__": [
      "self"
    ],
    "_post_request": [
      "self",
      "url",
      "param"
    ],
    "batch_commit_result": [
      "self"
    ],
    "batch_refresh_stage": [
      "self"
    ],
    "query_model_stage": [
      "self"
    ],
    "commit_ut_result": [
      "self"
    ]
  },
  "commit_model_ut_result": [
    "model_name",
    "ut_result"
  ],
  "_DEFAULT_CFG_WITH_MODEL_TYPE": [],
  "_CHECKPOINT_FORMAT": [],
  "_IS_MEGATRON_INITIALIZED": [],
  "init_megatron_util": [
    "megatron_cfg",
    "model_dir"
  ],
  "is_megatron_initialized": [],
  "convert_megatron_checkpoint": [
    "model",
    "checkpoint_dir",
    "target_dir"
  ],
  "_check_origin_dir": [
    "origin_dir"
  ],
  "_check_target_num_partitions": [
    "num_partitions"
  ],
  "_split_checkpoint": [
    "model",
    "checkpoint_dir",
    "num_partitions"
  ],
  "_merge_checkpoint": [
    "model",
    "checkpoint_dir",
    "num_partitions"
  ],
  "_save_converted_checkpoint": [
    "state_dict",
    "target_dir"
  ],
  "_get_diff_dim": [
    "tensor1",
    "tensor2"
  ],
  "_load_by_rank": [
    "checkpoint_dir",
    "rank"
  ],
  "_split_tensor": [
    "tensor",
    "num_partitions",
    "partition_dim"
  ],
  "SUB_TASKS": [],
  "PARENT_TASK": [],
  "TASK_MODEL": [],
  "DEFAULT_TASKS_LEVEL": [],
  "_inverted_index": [
    "forward_index"
  ],
  "INVERTED_TASKS_LEVEL": [],
  "is_embedding_task": [
    "task"
  ],
  "get_task_by_subtask_name": [
    "group_key"
  ],
  "T": [],
  "DEFAULT_IGNORE_PATTERNS": [],
  "UploadMode": [],
  "DATASET_LFS_SUFFIX": [],
  "MODEL_LFS_SUFFIX": [],
  "RepoUtils": {
    "filter_repo_objects": [
      "items"
    ],
    "_add_wildcard_to_directories": [
      "pattern"
    ]
  },
  "CommitInfo": {
    "to_dict": [
      "cls"
    ]
  },
  "DetailedCommitInfo": {
    "from_api_response": [
      "cls",
      "data"
    ],
    "to_dict": [
      "self"
    ]
  },
  "CommitHistoryResponse": {
    "from_api_response": [
      "cls",
      "data"
    ]
  },
  "RepoUrl": {
    "__repr__": [
      "self"
    ]
  },
  "git_hash": [
    "data"
  ],
  "UploadInfo": {
    "from_path": [
      "cls",
      "path",
      "file_hash_info"
    ],
    "from_bytes": [
      "cls",
      "data",
      "file_hash_info"
    ],
    "from_fileobj": [
      "cls",
      "fileobj",
      "file_hash_info"
    ]
  },
  "CommitOperationAdd": {
    "__post_init__": [
      "self"
    ],
    "as_file": [
      "self"
    ],
    "b64content": [
      "self"
    ],
    "_local_oid": [
      "self"
    ]
  },
  "_validate_path_in_repo": [
    "path_in_repo"
  ],
  "CommitOperation": [],
  "create_pipeline": [
    "model_id",
    "revision",
    "external_engine_for_llm"
  ],
  "get_class_user_attributes": [
    "cls"
  ],
  "get_input_type": [
    "task_inputs"
  ],
  "get_input_schema": [
    "task_name",
    "input_type"
  ],
  "get_output_schema": [
    "task_name"
  ],
  "get_input_info": [
    "task_name"
  ],
  "get_output_info": [
    "task_name"
  ],
  "get_task_io_info": [
    "task_name"
  ],
  "process_arg_type_annotation": [
    "arg",
    "default_value"
  ],
  "convert_to_value": [
    "item"
  ],
  "process_args": [
    "args"
  ],
  "PipelineClassAnalyzer": {
    "__init__": [
      "self"
    ],
    "visit_FunctionDef": [
      "self",
      "node"
    ],
    "get_input_parameters": [
      "self"
    ]
  },
  "AnalysisSourceFileRegisterModules": {
    "__init__": [
      "self",
      "source_file_path",
      "class_name"
    ],
    "visit_ClassDef": [
      "self",
      "node"
    ]
  },
  "get_pipeline_input_parameters": [
    "source_file_path",
    "class_name"
  ],
  "meta_type_schema_map": [],
  "generate_pipeline_parameters_schema": [
    "parameters"
  ],
  "get_pipeline_information_by_pipeline": [
    "pipeline"
  ],
  "PipelineInfomation": {
    "__init__": [
      "self",
      "task_name",
      "class_name",
      "source_path"
    ],
    "_analyze": [
      "self"
    ],
    "task_name": [
      "self"
    ],
    "is_custom_call": [
      "self"
    ],
    "input_schema": [
      "self"
    ],
    "output_schema": [
      "self"
    ],
    "parameters_schema": [
      "self"
    ],
    "schema": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ]
  },
  "is_url": [
    "url"
  ],
  "decode_base64_to_image": [
    "content"
  ],
  "decode_base64_to_audio": [
    "content"
  ],
  "decode_base64_to_video": [
    "content"
  ],
  "return_origin": [
    "content"
  ],
  "decode_box": [
    "content"
  ],
  "service_multipart_input_to_pipeline_input": [
    "body"
  ],
  "pipeline_output_to_service_multipart_output": [
    "output"
  ],
  "base64_decoder_map": [],
  "call_pipeline_with_json": [
    "pipeline_info",
    "pipeline",
    "body"
  ],
  "service_base64_input_to_pipeline_input": [
    "task_name",
    "body"
  ],
  "encode_numpy_image_to_base64": [
    "image"
  ],
  "encode_video_to_base64": [
    "video"
  ],
  "encode_pcm_to_base64": [
    "pcm"
  ],
  "encode_wav_to_base64": [
    "wav"
  ],
  "encode_bytes_to_base64": [
    "bts"
  ],
  "base64_encoder_map": [],
  "type_to_python_type": [],
  "_convert_to_python_type": [
    "inputs"
  ],
  "pipeline_output_to_service_base64_output": [
    "task_name",
    "pipeline_output"
  ],
  "get_task_input_examples": [
    "task"
  ],
  "get_task_schemas": [
    "task"
  ],
  "pre_compile_megatron_util": [],
  "pre_compile_all": [],
  "valid_url": [
    "url"
  ],
  "fetch_csv_with_url": [
    "csv_url"
  ],
  "gpu_mem_usage": [],
  "AverageMeter": {
    "__init__": [
      "self",
      "window_size"
    ],
    "update": [
      "self",
      "value"
    ],
    "median": [
      "self"
    ],
    "avg": [
      "self"
    ],
    "global_avg": [
      "self"
    ],
    "latest": [
      "self"
    ],
    "total": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "clear": [
      "self"
    ]
  },
  "MeterBuffer": {
    "__init__": [
      "self",
      "window_size"
    ],
    "reset": [
      "self"
    ],
    "get_filtered_meter": [
      "self",
      "filter_key"
    ],
    "update": [
      "self",
      "values"
    ],
    "clear_meters": [
      "self"
    ]
  },
  "import_modules_from_file": [
    "py_file"
  ],
  "is_method_overridden": [
    "method",
    "base_class",
    "derived_class"
  ],
  "has_method": [
    "obj",
    "method"
  ],
  "import_modules": [
    "imports",
    "allow_failed_imports"
  ],
  "validate_py_syntax": [
    "filename"
  ],
  "ENV_VARS_TRUE_VALUES": [],
  "ENV_VARS_TRUE_AND_AUTO_VALUES": [],
  "USE_TF": [],
  "USE_TORCH": [],
  "_torch_version": [],
  "_timm_available": [],
  "_tf_version": [],
  "is_scipy_available": [],
  "is_sklearn_available": [],
  "is_sentencepiece_available": [],
  "is_protobuf_available": [],
  "is_tokenizers_available": [],
  "is_timm_available": [],
  "is_torch_available": [],
  "is_torch_cuda_available": [],
  "is_wenetruntime_available": [],
  "is_swift_available": [],
  "is_tf_available": [],
  "is_opencv_available": [],
  "is_pillow_available": [],
  "_is_package_available_fn": [
    "pkg_name"
  ],
  "is_package_available": [
    "pkg_name"
  ],
  "is_espnet_available": [
    "pkg_name"
  ],
  "is_vllm_available": [],
  "is_transformers_available": [],
  "is_diffusers_available": [],
  "is_tensorrt_llm_available": [],
  "REQUIREMENTS_MAAPING": [],
  "SYSTEM_PACKAGE": [],
  "requires": [
    "obj",
    "requirements"
  ],
  "torch_required": [
    "func"
  ],
  "tf_required": [
    "func"
  ],
  "LazyImportModule": {
    "_AST_INDEX": [],
    "__init__": [
      "self",
      "name",
      "module_file",
      "import_structure",
      "module_spec",
      "extra_objects",
      "try_to_pre_import",
      "extra_import_func"
    ],
    "_try_to_import": [
      "self"
    ],
    "__dir__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "_get_module": [
      "self",
      "module_name"
    ],
    "__reduce__": [
      "self"
    ],
    "get_ast_index": [],
    "import_module": [
      "signature"
    ]
  },
  "has_attr_in_class": [
    "cls",
    "attribute_name"
  ],
  "BASE_KEY": [],
  "DELETE_KEY": [],
  "DEPRECATION_KEY": [],
  "RESERVED_KEYS": [],
  "ConfigDict": {
    "__missing__": [
      "self",
      "name"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "Config": {
    "_file2dict": [
      "filename"
    ],
    "from_file": [
      "filename"
    ],
    "from_string": [
      "cfg_str",
      "file_format"
    ],
    "__init__": [
      "self",
      "cfg_dict",
      "cfg_text",
      "filename"
    ],
    "filename": [
      "self"
    ],
    "text": [
      "self"
    ],
    "pretty_text": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "__getitem__": [
      "self",
      "name"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "__setitem__": [
      "self",
      "name",
      "value"
    ],
    "__iter__": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "__copy__": [
      "self"
    ],
    "__deepcopy__": [
      "self",
      "memo"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "safe_get": [
      "self",
      "key_chain",
      "default",
      "type_field"
    ],
    "dump": [
      "self",
      "file"
    ],
    "merge_from_dict": [
      "self",
      "options",
      "allow_list_keys",
      "force"
    ],
    "_merge_a_into_b": [
      "a",
      "b",
      "allow_list_keys",
      "force"
    ],
    "to_dict": [
      "self"
    ],
    "to_args": [
      "self",
      "parse_fn",
      "use_hyphen"
    ]
  },
  "check_config": [
    "cfg",
    "is_training"
  ],
  "JSONIteratorEncoder": {
    "default": [
      "self",
      "obj"
    ]
  },
  "Image": [],
  "Text": [],
  "Audio": [],
  "Video": [],
  "Tensor": [],
  "EnhancedEncoder": {
    "default": [
      "self",
      "obj"
    ]
  },
  "CHINESE_PUNCTUATION": [],
  "ENGLISH_PUNCTUATION": [],
  "remove_space_between_chinese_chars": [
    "decoded_str"
  ],
  "rebuild_chinese_str": [
    "string"
  ],
  "_is_chinese_str": [
    "string"
  ],
  "_is_chinese_char": [
    "cp"
  ],
  "normalize_chinese_number": [
    "text"
  ],
  "pre_chinese": [
    "text",
    "max_words"
  ],
  "RemoveColumnsCollator": {
    "__init__": [
      "self",
      "data_collator",
      "columns_to_remove",
      "model_name",
      "description"
    ],
    "_remove_columns": [
      "self",
      "feature"
    ],
    "__call__": [
      "self",
      "features"
    ]
  },
  "ModelTypeHelper": {
    "current_model_type": [],
    "_get_file_name": [
      "model",
      "cfg_name",
      "revision"
    ],
    "_parse_and_get": [
      "file",
      "pattern"
    ],
    "_get": [
      "cls",
      "model",
      "revision"
    ],
    "_get_adapter": [
      "cls",
      "model",
      "revision"
    ],
    "get": [
      "cls",
      "model",
      "revision",
      "with_adapter",
      "split",
      "use_cache"
    ],
    "clear_cache": [
      "cls"
    ]
  },
  "TYPE_NAME": [],
  "default_group": [],
  "Registry": {
    "__init__": [
      "self",
      "name"
    ],
    "__repr__": [
      "self"
    ],
    "name": [
      "self"
    ],
    "modules": [
      "self"
    ],
    "list": [
      "self"
    ],
    "get": [
      "self",
      "module_key",
      "group_key"
    ],
    "_register_module": [
      "self",
      "group_key",
      "module_name",
      "module_cls",
      "force"
    ],
    "register_module": [
      "self",
      "group_key",
      "module_name",
      "module_cls",
      "force"
    ]
  },
  "build_from_cfg": [
    "cfg",
    "registry",
    "group_key",
    "default_args"
  ],
  "Fields": {
    "hub": [],
    "datasets": [],
    "framework": [],
    "cv": [],
    "nlp": [],
    "audio": [],
    "multi_modal": [],
    "science": [],
    "server": []
  },
  "CVTasks": {
    "ocr_detection": [],
    "ocr_recognition": [],
    "table_recognition": [],
    "lineless_table_recognition": [],
    "license_plate_detection": [],
    "card_detection_correction": [],
    "animal_recognition": [],
    "face_detection": [],
    "face_liveness": [],
    "face_quality_assessment": [],
    "card_detection": [],
    "face_recognition": [],
    "facial_expression_recognition": [],
    "face_processing_base": [],
    "face_attribute_recognition": [],
    "face_2d_keypoints": [],
    "facial_68ldk_detection": [],
    "human_detection": [],
    "human_object_interaction": [],
    "face_image_generation": [],
    "body_2d_keypoints": [],
    "body_3d_keypoints": [],
    "hand_2d_keypoints": [],
    "general_recognition": [],
    "human_wholebody_keypoint": [],
    "pedestrian_attribute_recognition": [],
    "image_classification": [],
    "image_multilabel_classification": [],
    "image_classification_imagenet": [],
    "image_classification_dailylife": [],
    "image_object_detection": [],
    "video_object_detection": [],
    "image_fewshot_detection": [],
    "open_vocabulary_detection": [],
    "object_detection_3d": [],
    "image_segmentation": [],
    "semantic_segmentation": [],
    "image_driving_perception": [],
    "image_depth_estimation": [],
    "dense_optical_flow_estimation": [],
    "image_normal_estimation": [],
    "indoor_layout_estimation": [],
    "video_depth_estimation": [],
    "panorama_depth_estimation": [],
    "portrait_matting": [],
    "universal_matting": [],
    "text_driven_segmentation": [],
    "shop_segmentation": [],
    "hand_static": [],
    "face_human_hand_detection": [],
    "face_emotion": [],
    "product_segmentation": [],
    "image_matching": [],
    "image_local_feature_matching": [],
    "image_quality_assessment_degradation": [],
    "human_normal_estimation": [],
    "crowd_counting": [],
    "skin_retouching": [],
    "image_super_resolution": [],
    "image_super_resolution_pasd": [],
    "image_debanding": [],
    "image_colorization": [],
    "image_color_enhancement": [],
    "image_denoising": [],
    "image_deblurring": [],
    "image_portrait_enhancement": [],
    "image_inpainting": [],
    "image_paintbyexample": [],
    "image_skychange": [],
    "image_demoireing": [],
    "image_editing": [],
    "image_to_image_translation": [],
    "image_to_image_generation": [],
    "image_style_transfer": [],
    "image_portrait_stylization": [],
    "image_body_reshaping": [],
    "image_embedding": [],
    "image_face_fusion": [],
    "product_retrieval_embedding": [],
    "controllable_image_generation": [],
    "text_to_360panorama_image": [],
    "image_try_on": [],
    "human_image_generation": [],
    "image_view_transform": [],
    "live_category": [],
    "action_recognition": [],
    "action_detection": [],
    "video_category": [],
    "video_embedding": [],
    "virtual_try_on": [],
    "movie_scene_segmentation": [],
    "language_guided_video_summarization": [],
    "vop_retrieval": [],
    "video_object_segmentation": [],
    "referring_video_object_segmentation": [],
    "video_human_matting": [],
    "video_panoptic_segmentation": [],
    "video_instance_segmentation": [],
    "video_inpainting": [],
    "video_frame_interpolation": [],
    "video_stabilization": [],
    "video_super_resolution": [],
    "video_deinterlace": [],
    "video_colorization": [],
    "video_single_object_tracking": [],
    "video_multi_object_tracking": [],
    "video_summarization": [],
    "image_reid_person": [],
    "pointcloud_sceneflow_estimation": [],
    "image_multi_view_depth_estimation": [],
    "domain_specific_object_detection": [],
    "content_check": [],
    "face_reconstruction": [],
    "head_reconstruction": [],
    "text_to_head": [],
    "human_reconstruction": [],
    "text_texture_generation": [],
    "image_quality_assessment_mos": [],
    "motion_generation": [],
    "nerf_recon_acc": [],
    "nerf_recon_4k": [],
    "nerf_recon_vq_compression": [],
    "surface_recon_common": [],
    "human3d_render": [],
    "human3d_animation": [],
    "image_control_3d_portrait": [],
    "self_supervised_depth_completion": [],
    "image_to_3d": [],
    "vision_efficient_tuning": [],
    "bad_image_detecting": []
  },
  "NLPTasks": {
    "chat": [],
    "word_segmentation": [],
    "part_of_speech": [],
    "named_entity_recognition": [],
    "nli": [],
    "sentiment_classification": [],
    "sentiment_analysis": [],
    "sentence_similarity": [],
    "text_classification": [],
    "sentence_embedding": [],
    "text_ranking": [],
    "relation_extraction": [],
    "zero_shot": [],
    "translation": [],
    "competency_aware_translation": [],
    "token_classification": [],
    "transformer_crf": [],
    "conversational": [],
    "text_generation": [],
    "fid_dialogue": [],
    "text2text_generation": [],
    "task_oriented_conversation": [],
    "dialog_intent_prediction": [],
    "dialog_state_tracking": [],
    "table_question_answering": [],
    "fill_mask": [],
    "text_summarization": [],
    "question_answering": [],
    "code_translation": [],
    "code_generation": [],
    "zero_shot_classification": [],
    "backbone": [],
    "text_error_correction": [],
    "word_alignment": [],
    "faq_question_answering": [],
    "information_extraction": [],
    "document_segmentation": [],
    "extractive_summarization": [],
    "feature_extraction": [],
    "translation_evaluation": [],
    "sudoku": [],
    "text2sql": [],
    "siamese_uie": [],
    "document_grounded_dialog_retrieval": [],
    "document_grounded_dialog_rerank": [],
    "document_grounded_dialog_generate": [],
    "machine_reading_comprehension": []
  },
  "AudioTasks": {
    "auto_speech_recognition": [],
    "text_to_speech": [],
    "speech_signal_process": [],
    "speech_separation": [],
    "acoustic_echo_cancellation": [],
    "acoustic_noise_suppression": [],
    "keyword_spotting": [],
    "inverse_text_processing": [],
    "punctuation": [],
    "speaker_verification": [],
    "speech_language_recognition": [],
    "speaker_diarization": [],
    "audio_quantization": [],
    "voice_activity_detection": [],
    "language_score_prediction": [],
    "speech_timestamp": [],
    "speaker_diarization_dialogue_detection": [],
    "speaker_diarization_semantic_speaker_turn_detection": [],
    "emotion_recognition": [],
    "speech_super_resolution": [],
    "voice_conversion": []
  },
  "MultiModalTasks": {
    "image_captioning": [],
    "visual_grounding": [],
    "text_to_image_synthesis": [],
    "multi_modal_embedding": [],
    "text_video_retrieval": [],
    "generative_multi_modal_embedding": [],
    "multi_modal_similarity": [],
    "visual_question_answering": [],
    "visual_entailment": [],
    "video_multi_modal_embedding": [],
    "image_text_retrieval": [],
    "document_vl_embedding": [],
    "video_captioning": [],
    "video_question_answering": [],
    "video_temporal_grounding": [],
    "text_to_video_synthesis": [],
    "efficient_diffusion_tuning": [],
    "multimodal_dialogue": [],
    "image_to_video": [],
    "video_to_video": []
  },
  "ScienceTasks": {
    "protein_structure": []
  },
  "Other": {
    "other": []
  },
  "TasksIODescriptions": {
    "image_to_image": [],
    "images_to_image": [],
    "image_to_text": [],
    "seed_to_image": [],
    "text_to_speech": [],
    "text_to_text": [],
    "speech_to_text": [],
    "speech_to_speech": [],
    "speeches_to_speech": [],
    "visual_grounding": [],
    "visual_question_answering": [],
    "visual_entailment": [],
    "generative_multi_modal_embedding": [],
    "efficient_diffusion_tuning": []
  },
  "Tasks": {
    "reverse_field_index": [],
    "task_template": [],
    "find_field_by_task": [
      "task_name"
    ]
  },
  "InputFields": {
    "img": [],
    "text": [],
    "audio": []
  },
  "Hubs": {
    "modelscope": [],
    "huggingface": [],
    "virgo": []
  },
  "DownloadMode": {
    "REUSE_DATASET_IF_EXISTS": [],
    "FORCE_REDOWNLOAD": []
  },
  "DownloadChannel": {
    "LOCAL": [],
    "DSW": [],
    "EAIS": []
  },
  "DatasetFormations": {
    "hf_compatible": [],
    "native": [],
    "general": [],
    "formation_mark_ext": []
  },
  "DatasetMetaFormats": [],
  "ModelFile": {
    "CONFIGURATION": [],
    "README": [],
    "TF_SAVED_MODEL_FILE": [],
    "TF_GRAPH_FILE": [],
    "TF_CHECKPOINT_FOLDER": [],
    "TF_CKPT_PREFIX": [],
    "TORCH_MODEL_FILE": [],
    "TORCH_MODEL_BIN_FILE": [],
    "VOCAB_FILE": [],
    "ONNX_MODEL_FILE": [],
    "LABEL_MAPPING": [],
    "TRAIN_OUTPUT_DIR": [],
    "TRAIN_BEST_OUTPUT_DIR": [],
    "TS_MODEL_FILE": [],
    "YAML_FILE": [],
    "TOKENIZER_FOLDER": [],
    "CONFIG": []
  },
  "Invoke": {
    "KEY": [],
    "PRETRAINED": [],
    "PIPELINE": [],
    "TRAINER": [],
    "LOCAL_TRAINER": [],
    "PREPROCESSOR": []
  },
  "ThirdParty": {
    "KEY": [],
    "EASYCV": [],
    "ADASEQ": [],
    "ADADET": []
  },
  "ConfigFields": {
    "framework": [],
    "task": [],
    "pipeline": [],
    "model": [],
    "dataset": [],
    "preprocessor": [],
    "train": [],
    "evaluation": [],
    "postprocessor": []
  },
  "ConfigKeys": {
    "train": [],
    "val": [],
    "test": []
  },
  "Requirements": {
    "protobuf": [],
    "sentencepiece": [],
    "sklearn": [],
    "scipy": [],
    "timm": [],
    "tokenizers": [],
    "tf": [],
    "torch": []
  },
  "Frameworks": {
    "tf": [],
    "torch": [],
    "kaldi": []
  },
  "REPO_TYPE_MODEL": [],
  "REPO_TYPE_DATASET": [],
  "REPO_TYPE_SUPPORT": [],
  "DEFAULT_MODEL_REVISION": [],
  "MASTER_MODEL_BRANCH": [],
  "DEFAULT_REPOSITORY_REVISION": [],
  "DEFAULT_DATASET_REVISION": [],
  "DEFAULT_DATASET_NAMESPACE": [],
  "DEFAULT_DATA_ACCELERATION_ENDPOINT": [],
  "INTRA_CLOUD_ACCELERATION": [],
  "INTRA_CLOUD_ACCELERATION_REGION": [],
  "ModeKeys": {
    "TRAIN": [],
    "EVAL": [],
    "INFERENCE": []
  },
  "LogKeys": {
    "ITER": [],
    "ITER_TIME": [],
    "EPOCH": [],
    "LR": [],
    "MODE": [],
    "DATA_LOAD_TIME": [],
    "ETA": [],
    "MEMORY": [],
    "LOSS": []
  },
  "TrainerStages": {
    "after_init": [],
    "before_run": [],
    "before_val": [],
    "before_train_epoch": [],
    "before_train_iter": [],
    "after_train_iter": [],
    "after_train_epoch": [],
    "before_val_epoch": [],
    "before_val_iter": [],
    "after_val_iter": [],
    "after_val_epoch": [],
    "after_run": [],
    "after_val": []
  },
  "ColorCodes": {
    "MAGENTA": [],
    "YELLOW": [],
    "GREEN": [],
    "RED": [],
    "END": []
  },
  "Devices": {
    "cpu": [],
    "gpu": []
  },
  "EXTENSIONS_TO_LOAD": [],
  "META_FILES_FORMAT": [],
  "DatasetPathName": {
    "META_NAME": [],
    "DATA_FILES_NAME": [],
    "LOCK_FILE_NAME_ANY": [],
    "LOCK_FILE_NAME_DELIMITER": []
  },
  "MetaDataFields": {
    "ARGS_BIG_DATA": []
  },
  "DistributedParallelType": {
    "DP": [],
    "TP": [],
    "PP": []
  },
  "DatasetTensorflowConfig": {
    "BATCH_SIZE": [],
    "DEFAULT_BATCH_SIZE_VALUE": []
  },
  "VirgoDatasetConfig": {
    "default_virgo_namespace": [],
    "default_dataset_version": [],
    "env_virgo_endpoint": [],
    "meta_content": [],
    "sampling_type": [],
    "col_id": [],
    "col_meta_info": [],
    "col_analysis_result": [],
    "col_external_info": [],
    "col_cache_file": []
  },
  "DEFAULT_MAXCOMPUTE_ENDPOINT": [],
  "MaxComputeEnvs": {
    "ACCESS_ID": [],
    "ACCESS_SECRET_KEY": [],
    "PROJECT_NAME": [],
    "ENDPOINT": []
  },
  "Timer": {
    "__init__": [
      "self"
    ],
    "average_time": [
      "self"
    ],
    "tic": [
      "self"
    ],
    "toc": [
      "self",
      "average"
    ],
    "add": [
      "self",
      "time_diff"
    ],
    "reset": [
      "self"
    ],
    "avg_time_str": [
      "self"
    ]
  },
  "get_time_str": [
    "time_diff"
  ],
  "ExampleDecoder": [
    "data"
  ],
  "ExampleEncoder": [
    "data"
  ],
  "CustomEncoder": [],
  "CustomDecoder": [],
  "NumpyEncoder": {
    "default": [
      "self",
      "obj"
    ]
  },
  "get_extension": [
    "encoding"
  ],
  "get_mimetype": [
    "filename"
  ],
  "decode_base64_to_binary": [
    "encoding"
  ],
  "encode_array_to_img_base64": [
    "image_array"
  ],
  "encode_url_to_base64": [
    "url"
  ],
  "encode_file_to_base64": [
    "f"
  ],
  "encode_url_or_file_to_base64": [
    "path"
  ],
  "service_data_decoder": [
    "task",
    "data"
  ],
  "service_data_encoder": [
    "task",
    "data"
  ],
  "MS_CACHE_HOME": [],
  "MS_DATASETS_CACHE": [],
  "DOWNLOADED_DATASETS_DIR": [],
  "DEFAULT_DOWNLOADED_DATASETS_PATH": [],
  "DOWNLOADED_DATASETS_PATH": [],
  "HUB_DATASET_ENDPOINT": [],
  "RegressTool": {
    "__init__": [
      "self",
      "baseline",
      "store_func",
      "load_func"
    ],
    "store": [
      "self",
      "local",
      "remote"
    ],
    "load": [
      "self",
      "local",
      "remote"
    ],
    "monitor_module_single_forward": [
      "self",
      "module",
      "file_name",
      "compare_fn",
      "compare_model_output"
    ],
    "monitor_module_train": [
      "self",
      "trainer",
      "file_name",
      "level",
      "compare_fn",
      "ignore_keys",
      "compare_random",
      "reset_dropout",
      "lazy_stop_callback"
    ]
  },
  "MsRegressTool": {
    "monitor_ms_train": [
      "self",
      "trainer",
      "file_name",
      "level",
      "compare_fn",
      "ignore_keys",
      "compare_random",
      "lazy_stop_callback"
    ]
  },
  "compare_module": [
    "module1",
    "module2"
  ],
  "numpify_tensor_nested": [
    "tensors",
    "reduction",
    "clip_value"
  ],
  "detach_tensor_nested": [
    "tensors"
  ],
  "hack_forward": [
    "module",
    "name",
    "io_json",
    "restore",
    "keep_tensors"
  ],
  "hack_backward": [
    "module",
    "optimizer",
    "io_json",
    "restore",
    "lazy_stop_callback"
  ],
  "intercept_module": [
    "module",
    "io_json",
    "parent_name",
    "restore"
  ],
  "compare_io_and_print": [
    "baseline_json",
    "io_json",
    "compare_fn"
  ],
  "compare_backward_and_print": [
    "baseline_json",
    "bw_json",
    "level",
    "ignore_keys",
    "compare_fn"
  ],
  "compare_cfg_and_optimizers": [
    "baseline_json",
    "cfg_json",
    "compare_fn"
  ],
  "IgnoreKeyFn": {
    "__init__": [
      "self",
      "keys"
    ],
    "__call__": [
      "self",
      "v1output",
      "v2output",
      "key",
      "type"
    ]
  },
  "DeployChecker": {
    "__init__": [
      "self"
    ],
    "check_model": [
      "self",
      "model_id",
      "model_revision"
    ]
  },
  "check_deploy": [
    "models",
    "revisions"
  ],
  "torch_nested_numpify": [
    "tensors"
  ],
  "torch_nested_detach": [
    "tensors"
  ],
  "to_device": [
    "batch",
    "device",
    "non_blocking"
  ],
  "InputPadder": {
    "__init__": [
      "self",
      "dims",
      "mode"
    ],
    "pad": [
      "self"
    ],
    "unpad": [
      "self",
      "x"
    ]
  },
  "numpy_to_cv2img": [
    "img_array"
  ],
  "draw_joints": [
    "image",
    "np_kps",
    "score",
    "threshold"
  ],
  "draw_box": [
    "image",
    "box"
  ],
  "realtime_object_detection_bbox_vis": [
    "image",
    "bboxes"
  ],
  "draw_attribute": [
    "image",
    "box",
    "labels"
  ],
  "draw_keypoints": [
    "output",
    "original_image"
  ],
  "draw_pedestrian_attribute": [
    "output",
    "original_image"
  ],
  "draw_106face_keypoints": [
    "in_path",
    "keypoints",
    "boxes",
    "scale",
    "save_path"
  ],
  "draw_face_detection_no_lm_result": [
    "img_path",
    "detection_result"
  ],
  "draw_facial_expression_result": [
    "img_path",
    "facial_expression_result"
  ],
  "draw_face_attribute_result": [
    "img_path",
    "face_attribute_result"
  ],
  "draw_face_detection_result": [
    "img_path",
    "detection_result"
  ],
  "draw_card_detection_result": [
    "img_path",
    "detection_result"
  ],
  "created_boxed_image": [
    "image_in",
    "box"
  ],
  "show_video_tracking_result": [
    "video_in_path",
    "bboxes",
    "video_save_path"
  ],
  "show_video_object_detection_result": [
    "video_in_path",
    "bboxes_list",
    "labels_list",
    "video_save_path"
  ],
  "panoptic_seg_masks_to_image": [
    "masks"
  ],
  "semantic_seg_masks_to_image": [
    "masks"
  ],
  "show_video_summarization_result": [
    "video_in_path",
    "result",
    "video_save_path"
  ],
  "show_image_object_detection_auto_result": [
    "img_path",
    "detection_result",
    "save_path"
  ],
  "depth_to_color": [
    "depth"
  ],
  "make_colorwheel": [],
  "flow_uv_to_colors": [
    "u",
    "v",
    "convert_to_bgr"
  ],
  "flow_to_image": [
    "flow_uv",
    "clip_flow",
    "convert_to_bgr"
  ],
  "flow_to_color": [
    "flow"
  ],
  "show_video_depth_estimation_result": [
    "depths",
    "video_save_path"
  ],
  "show_image_driving_perception_result": [
    "img",
    "results",
    "out_file",
    "if_draw"
  ],
  "masks_visualization": [
    "masks",
    "palette"
  ],
  "make_matching_figure": [
    "img0",
    "img1",
    "mkpts0",
    "mkpts1",
    "color",
    "kpts0",
    "kpts1",
    "text",
    "dpi",
    "path"
  ],
  "match_pair_visualization": [
    "img_name0",
    "img_name1",
    "kpts0",
    "kpts1",
    "conf",
    "output_filename",
    "method"
  ],
  "list_cut_average": [
    "ll",
    "intervals"
  ],
  "plot_3d_motion": [
    "save_path",
    "kinematic_tree",
    "joints",
    "title",
    "dataset",
    "figsize",
    "fps",
    "radius",
    "vis_mode",
    "gt_frames"
  ],
  "qinv": [
    "q"
  ],
  "qrot": [
    "q",
    "v"
  ],
  "recover_root_rot_pos": [
    "data"
  ],
  "recover_from_ric": [
    "data",
    "joints_num"
  ],
  "quaternion_to_matrix": [
    "quaternions"
  ],
  "_axis_angle_rotation": [
    "axis",
    "angle"
  ],
  "euler_angles_to_matrix": [
    "euler_angles",
    "convention"
  ],
  "axis_angle_to_matrix": [
    "axis_angle"
  ],
  "rotation_6d_to_matrix": [
    "d6"
  ],
  "TtsException": {},
  "TtsModelConfigurationException": {},
  "TtsModelNotExistsException": {},
  "TtsVoiceNotExistsException": {},
  "TtsFrontendException": {},
  "TtsFrontendInitializeFailedException": {},
  "TtsFrontendLanguageTypeInvalidException": {},
  "TtsVocoderException": {},
  "TtsVocoderMelspecShapeMismatchException": {},
  "TtsDataPreprocessorException": {},
  "TtsDataPreprocessorDirNotExistsException": {},
  "TtsDataPreprocessorAudioConfigNotExistsException": {},
  "TtsTrainingException": {},
  "TtsTrainingHparamsInvalidException": {},
  "TtsTrainingWorkDirNotExistsException": {},
  "TtsTrainingCfgNotExistsException": {},
  "TtsTrainingDatasetInvalidException": {},
  "TtsTrainingInvalidModelException": {},
  "SEGMENT_LENGTH_TRAIN": [],
  "SUPPORT_AUDIO_TYPE_SETS": [],
  "TtsTrainType": {
    "TRAIN_TYPE_SAMBERT": [],
    "TRAIN_TYPE_BERT": [],
    "TRAIN_TYPE_VOC": []
  },
  "TtsCustomParams": {
    "VOICE_NAME": [],
    "AM_CKPT": [],
    "VOC_CKPT": [],
    "AM_CONFIG": [],
    "VOC_CONFIG": [],
    "AUIDO_CONFIG": [],
    "SE_FILE": [],
    "SE_MODEL": [],
    "MVN_FILE": []
  },
  "to_segment": [
    "batch",
    "segment_length"
  ],
  "audio_norm": [
    "x"
  ],
  "update_conf": [
    "origin_config_file",
    "new_config_file",
    "conf_item"
  ],
  "extract_pcm_from_wav": [
    "wav"
  ],
  "expect_token_number": [
    "instr",
    "token"
  ],
  "expect_kaldi_matrix": [
    "instr"
  ],
  "ndarray_pcm_to_wav": [
    "fs",
    "data"
  ],
  "load_bytes_from_url": [
    "url"
  ],
  "generate_scp_from_url": [
    "url",
    "key"
  ],
  "generate_text_from_url": [
    "url"
  ],
  "generate_scp_for_sv": [
    "url",
    "key"
  ],
  "generate_sv_scp_from_url": [
    "urls"
  ],
  "generate_sd_scp_from_url": [
    "urls"
  ],
  "update_local_model": [
    "model_config",
    "model_path",
    "extra_args"
  ],
  "normal_init_method": [
    "mean",
    "std"
  ],
  "scaled_init_method": [
    "mean",
    "std",
    "num_layers"
  ],
  "DistributedDataParallel": {
    "__init__": [
      "self",
      "module"
    ],
    "forward": [
      "self"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ]
  },
  "import_external_nltk_data": [
    "nltk_data_dir",
    "package_name"
  ],
  "parse_labels_in_order": [
    "model_dir",
    "cfg"
  ],
  "_get_ckpt_name": [
    "mp_rank",
    "checkpoints_path",
    "tag"
  ],
  "pre_load": [
    "mp_rank",
    "load_dir",
    "tag"
  ],
  "_load_checkpoint": [
    "model",
    "load_dir",
    "tag",
    "load_module_strict",
    "load_optimizer_states",
    "load_lr_scheduler_states"
  ],
  "all_domains": [],
  "all_domains_with_bracket": [],
  "db_domains": [],
  "placeholder_tokens": [],
  "normlize_slot_names": [],
  "requestable_slots": [],
  "all_reqslot": [],
  "informable_slots": [],
  "all_infslot": [],
  "all_slots": [],
  "get_slot": [],
  "da_abbr_to_slot_name": [],
  "dialog_acts": [],
  "all_acts": [],
  "dialog_act_params": [],
  "dialog_act_all_slots": [],
  "slot_name_to_slot_token": [],
  "eos_tokens": [],
  "sos_tokens": [],
  "db_tokens": [],
  "get_understand_tokens": [
    "prompt_num_for_understand"
  ],
  "get_policy_tokens": [
    "prompt_num_for_policy"
  ],
  "get_special_tokens": [
    "other_tokens"
  ],
  "tracking_and_print_dialog_states": [
    "test_case",
    "pipelines"
  ],
  "batch_to_device": [
    "batch",
    "device"
  ],
  "max_lens": [
    "X"
  ],
  "list2np": [
    "X",
    "padding",
    "dtype"
  ],
  "clean_replace": [
    "s",
    "r",
    "t",
    "forward",
    "backward"
  ],
  "py2np": [
    "list"
  ],
  "write_dict": [
    "fn",
    "dic"
  ],
  "f1_score": [
    "label_list",
    "pred_list"
  ],
  "MultiWOZVocab": {
    "__init__": [
      "self",
      "vocab_size"
    ],
    "_absolute_add_word": [
      "self",
      "w"
    ],
    "add_word": [
      "self",
      "word"
    ],
    "has_word": [
      "self",
      "word"
    ],
    "_add_to_vocab": [
      "self",
      "word"
    ],
    "construct": [
      "self"
    ],
    "load_vocab": [
      "self",
      "vocab_path"
    ],
    "save_vocab": [
      "self",
      "vocab_path"
    ],
    "encode": [
      "self",
      "word",
      "include_oov"
    ],
    "sentence_encode": [
      "self",
      "word_list"
    ],
    "oov_idx_map": [
      "self",
      "idx"
    ],
    "sentence_oov_map": [
      "self",
      "index_list"
    ],
    "decode": [
      "self",
      "idx",
      "indicate_oov"
    ]
  },
  "compute_kl_loss": [
    "p",
    "q",
    "filter_scores"
  ],
  "CatKLLoss": {
    "__init__": [
      "self",
      "reduction"
    ],
    "forward": [
      "self",
      "log_qy",
      "log_py"
    ]
  },
  "hierarchical_set_score": [
    "frame1",
    "frame2"
  ],
  "clean_text_split_dot": [
    "text"
  ],
  "clean_text": [
    "data_dir",
    "text"
  ],
  "clean_time": [
    "utter"
  ],
  "clean_slot_values": [
    "data_dir",
    "domain",
    "slot",
    "value"
  ],
  "str2bool": [
    "v"
  ],
  "HParams": {
    "__getattr__": [
      "self",
      "name"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "save": [
      "self",
      "filename"
    ],
    "load": [
      "self",
      "filename"
    ]
  },
  "parse_args": [
    "parser"
  ],
  "MultiWozDB": {
    "__init__": [
      "self",
      "db_dir",
      "db_paths"
    ],
    "oneHotVector": [
      "self",
      "domain",
      "num"
    ],
    "addBookingPointer": [
      "self",
      "turn_da"
    ],
    "addDBPointer": [
      "self",
      "domain",
      "match_num",
      "return_num"
    ],
    "addDBIndicator": [
      "self",
      "domain",
      "match_num",
      "return_num"
    ],
    "get_match_num": [
      "self",
      "constraints",
      "return_entry"
    ],
    "pointerBack": [
      "self",
      "vector",
      "domain"
    ],
    "queryJsons": [
      "self",
      "domain",
      "constraints",
      "exactly_match",
      "return_name"
    ],
    "querySQL": [
      "self",
      "domain",
      "constraints"
    ]
  },
  "text2sql_tracking_and_print_results": [
    "test_case",
    "pipelines"
  ],
  "ignore_file_pattern": [],
  "get_all_imported_modules": [],
  "_patch_pretrained_class": [
    "all_imported_modules",
    "wrap"
  ],
  "_unpatch_pretrained_class": [
    "all_imported_modules"
  ],
  "_patch_hub": [],
  "_unpatch_hub": [],
  "patch_hub": [],
  "unpatch_hub": [],
  "patch_context": [],
  "_get_hf_device": [
    "device"
  ],
  "_get_hf_pipeline_class": [
    "task",
    "model"
  ],
  "hf_pipeline": [
    "task",
    "model",
    "framework",
    "device"
  ],
  "sentence_transformers_pipeline": [
    "model"
  ],
  "Compose": {
    "__init__": [
      "self",
      "transforms",
      "field_name",
      "profiling"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "__repr__": [
      "self"
    ]
  },
  "to_tensor": [
    "data"
  ],
  "ToTensor": {
    "__init__": [
      "self",
      "keys"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Filter": {
    "__init__": [
      "self",
      "reserved_keys"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "__repr__": [
      "self"
    ]
  },
  "to_numpy": [
    "data"
  ],
  "ToNumpy": {
    "__init__": [
      "self",
      "keys"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Rename": {
    "__init__": [
      "self",
      "input_keys",
      "output_keys"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Identity": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "item"
    ]
  },
  "AudioBrainPreprocessor": {
    "__init__": [
      "self",
      "takes",
      "provides",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "load_kaldi_feature_transform": [
    "filename"
  ],
  "Feature": {
    "__init__": [
      "self",
      "fbank_config",
      "feat_type",
      "mvn_file",
      "cuda"
    ],
    "compute": [
      "self",
      "utt"
    ],
    "normalize": [
      "self",
      "feat"
    ]
  },
  "LinearAECAndFbank": {
    "SAMPLE_RATE": [],
    "__init__": [
      "self",
      "io_config"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "load_wav": [
      "inputs"
    ]
  },
  "SpeakerDiarizationDialogueDetectionPreprocessor": {
    "_tokenize_text": [
      "self",
      "sequence1",
      "sequence2"
    ],
    "__init__": [
      "self",
      "model_dir",
      "first_sequence",
      "second_sequence",
      "label",
      "label2id",
      "mode",
      "max_length",
      "use_fast",
      "keep_original_columns"
    ]
  },
  "SpeakerDiarizationSemanticSpeakerTurnDetectionPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "first_sequence",
      "label",
      "label2id",
      "label_all_tokens",
      "mode",
      "max_length",
      "use_fast",
      "keep_original_columns",
      "return_text"
    ],
    "_tokenize_text": [
      "self",
      "text"
    ],
    "_tokenize_text_by_words": [
      "self",
      "tokens"
    ],
    "_tokenize_text_with_fast_tokenizer": [
      "self",
      "tokens"
    ],
    "_tokenize_text_with_slow_tokenizer": [
      "self",
      "tokens"
    ],
    "get_label_mask_and_offset_mapping_BertTokenizer": [
      "self",
      "text"
    ],
    "get_label_mask_and_offset_mapping_XLMRobertaTokenizer": [
      "self",
      "text"
    ]
  },
  "ReadVideoData": [
    "cfg",
    "video_path",
    "num_spatial_crops_override",
    "num_temporal_views_override"
  ],
  "kinetics400_tranform": [
    "cfg",
    "num_spatial_crops"
  ],
  "_interval_based_sampling": [
    "vid_length",
    "vid_fps",
    "target_fps",
    "clip_idx",
    "num_clips",
    "num_frames",
    "interval",
    "minus_interval"
  ],
  "_decode_video_frames_list": [
    "cfg",
    "frames_list",
    "vid_fps",
    "num_temporal_views_override"
  ],
  "_decode_video": [
    "cfg",
    "path",
    "num_temporal_views_override"
  ],
  "KineticsResizedCrop": {
    "__init__": [
      "self",
      "short_side_range",
      "crop_size",
      "num_spatial_crops"
    ],
    "_get_controlled_crop": [
      "self",
      "clip"
    ],
    "_get_random_crop": [
      "self",
      "clip"
    ],
    "set_spatial_index": [
      "self",
      "idx"
    ],
    "__call__": [
      "self",
      "clip"
    ]
  },
  "MovieSceneSegmentationPreprocessor": {
    "__init__": [
      "self"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "__call__": [
      "self",
      "results"
    ]
  },
  "PREPROCESSOR_MAP": [],
  "Preprocessor": {
    "__init__": [
      "self",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "mode": [
      "self",
      "value"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "revision",
      "cfg_dict",
      "preprocessor_mode"
    ],
    "save_pretrained": [
      "self",
      "target_folder",
      "config",
      "save_config_function"
    ]
  },
  "KanttsDataPreprocessor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "data_dir",
      "output_dir",
      "audio_config_path",
      "speaker_name",
      "target_lang",
      "skip_script",
      "se_model"
    ],
    "do_data_process": [
      "self",
      "datadir",
      "outputdir",
      "audio_config",
      "speaker_name",
      "targetLang",
      "skip_script",
      "se_model"
    ]
  },
  "DiffusionImageGenerationPreprocessor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "OfaPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode"
    ],
    "_build_dict": [
      "self",
      "input"
    ],
    "_ofa_input_compatibility_conversion": [
      "self",
      "data"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "_convert_to_rgb": [
    "image"
  ],
  "CLIPPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode"
    ],
    "_build_image_transform": [
      "self"
    ],
    "tokenize": [
      "self",
      "texts",
      "context_length"
    ],
    "set_input_img_key": [
      "self",
      "new_key"
    ],
    "set_input_text_key": [
      "self",
      "new_key"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "MPlugPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode",
      "tokenizer_max_length"
    ],
    "tokenizer": [
      "self"
    ],
    "patch_resize_transform": [
      "self"
    ],
    "image_open": [
      "self",
      "path"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "VLDocPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "HiTeAPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode",
      "tokenizer_max_length"
    ],
    "tokenizer": [
      "self"
    ],
    "patch_resize_transform": [
      "self"
    ],
    "num_frames": [
      "self"
    ],
    "video_open": [
      "self",
      "path"
    ],
    "sample_frames": [
      "self",
      "num_frames",
      "vlen"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "MplugOwlPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode"
    ],
    "tokenizer": [
      "self"
    ],
    "patch_resize_transform": [
      "self"
    ],
    "image_open": [
      "self",
      "path"
    ],
    "tokenize_text": [
      "self",
      "text"
    ],
    "convert": [
      "self",
      "messages"
    ],
    "__call__": [
      "self",
      "messages"
    ]
  },
  "ImageCaptioningClipInterrogatorPreprocessor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "PREPROCESSORS": [],
  "build_preprocessor": [
    "cfg",
    "field_name",
    "default_args"
  ],
  "WavToLists": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "model",
      "audio_in"
    ],
    "forward": [
      "self",
      "model",
      "audio_in"
    ],
    "read_config": [
      "self",
      "inputs"
    ],
    "generate_wav_lists": [
      "self",
      "inputs"
    ]
  },
  "WavToScp": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "model",
      "recog_type",
      "audio_format",
      "audio_in",
      "audio_fs"
    ],
    "forward": [
      "self",
      "model",
      "recog_type",
      "audio_format",
      "audio_in",
      "audio_fs",
      "cmd"
    ],
    "config_checking": [
      "self",
      "inputs"
    ],
    "env_setting": [
      "self",
      "inputs"
    ]
  },
  "LoadImage": {
    "__init__": [
      "self",
      "mode",
      "backend"
    ],
    "__call__": [
      "self",
      "input"
    ],
    "__repr__": [
      "self"
    ],
    "convert_to_ndarray": [
      "input"
    ],
    "convert_to_img": [
      "input"
    ]
  },
  "load_image": [
    "image_path_or_url"
  ],
  "ObjectDetectionTinynasPreprocessor": {
    "__init__": [
      "self",
      "size_divisible"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "ImageColorEnhanceFinetunePreprocessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "ImageDenoisePreprocessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "ImageDeblurPreprocessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "ImagePortraitEnhancementPreprocessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "ImageInstanceSegmentationPreprocessor": {
    "__init__": [
      "self"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "__call__": [
      "self",
      "results"
    ]
  },
  "VideoSummarizationPreprocessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "ImageClassificationBypassPreprocessor": {
    "__init__": [
      "self"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "__call__": [
      "self",
      "results"
    ]
  },
  "ocr_resize": [
    "img",
    "patch_image_size",
    "is_document"
  ],
  "OfaOcrRecognitionPreprocessor": {
    "__init__": [
      "self",
      "cfg",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_build_train_sample": [
      "self",
      "data"
    ],
    "_build_infer_sample": [
      "self",
      "data"
    ]
  },
  "OfaBasePreprocessor": {
    "__init__": [
      "self",
      "cfg",
      "model_dir",
      "mode"
    ],
    "tokenize_text": [
      "self",
      "text",
      "add_bos",
      "add_eos"
    ],
    "pre_caption": [
      "caption",
      "max_words"
    ],
    "pre_question": [
      "question",
      "max_ques_words"
    ],
    "add_constraint_mask": [
      "self",
      "sample"
    ],
    "get_img_pil": [
      "self",
      "path_or_url_or_pil"
    ],
    "get_audio_bytes": [
      "self",
      "path_or_url"
    ],
    "prepare_fbank": [
      "self",
      "waveform",
      "sample_rate",
      "speed",
      "target_sample_rate",
      "is_train"
    ],
    "pack_frames": [
      "self",
      "feature"
    ]
  },
  "OfaImageCaptioningPreprocessor": {
    "__init__": [
      "self",
      "cfg",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_build_train_sample": [
      "self",
      "data"
    ],
    "_build_infer_sample": [
      "self",
      "data"
    ]
  },
  "OfaTextToSqlPreprocessor": {
    "__init__": [
      "self",
      "cfg",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_build_train_sample": [
      "self",
      "data"
    ],
    "_build_infer_sample": [
      "self",
      "data"
    ]
  },
  "seq2seq_input": [
    "query",
    "question",
    "db_id",
    "db_path",
    "schema",
    "args",
    "is_train"
  ],
  "spider_pre_process_one_function": [
    "item",
    "args"
  ],
  "spider_get_target": [
    "query",
    "db_id",
    "normalize_query",
    "target_with_db_id"
  ],
  "normalize": [
    "query"
  ],
  "spider_add_serialized_schema": [
    "ex",
    "args"
  ],
  "serialize_schema_natural_language": [
    "question",
    "db_path",
    "db_id",
    "db_column_names",
    "db_table_names",
    "db_primary_keys",
    "db_foreign_keys",
    "schema_serialization_with_db_content",
    "normalize_query"
  ],
  "serialize_schema": [
    "question",
    "db_path",
    "db_id",
    "db_column_names",
    "db_table_names",
    "schema_serialization_type",
    "schema_serialization_randomized",
    "schema_serialization_with_db_id",
    "schema_serialization_with_db_content",
    "normalize_query"
  ],
  "form_input_for_construction": [
    "query",
    "question",
    "db_id",
    "db_path",
    "schema"
  ],
  "OfaVisualGroundingPreprocessor": {
    "__init__": [
      "self",
      "cfg",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_build_train_sample": [
      "self",
      "data"
    ],
    "_build_infer_sample": [
      "self",
      "data"
    ]
  },
  "OfaVisualQuestionAnsweringPreprocessor": {
    "__init__": [
      "self",
      "cfg",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_build_train_sample": [
      "self",
      "data"
    ],
    "_build_infer_sample": [
      "self",
      "data"
    ]
  },
  "OfaVisualEntailmentPreprocessor": {
    "__init__": [
      "self",
      "cfg",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_build_train_sample": [
      "self",
      "data"
    ],
    "_build_infer_sample": [
      "self",
      "data"
    ]
  },
  "OfaASRPreprocessor": {
    "__init__": [
      "self",
      "cfg",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_build_train_sample": [
      "self",
      "data"
    ],
    "_build_infer_sample": [
      "self",
      "data"
    ],
    "to_phone": [
      "self",
      "text"
    ],
    "build_phone_dict": [
      "self",
      "phone_dict_path"
    ]
  },
  "OfaTextToImageSynthesisPreprocessor": {
    "__init__": [
      "self",
      "cfg",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "OfaTextClassificationPreprocessor": {
    "__init__": [
      "self",
      "cfg",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_build_instruction": [
      "self",
      "data"
    ],
    "_build_train_sample": [
      "self",
      "data"
    ],
    "_build_infer_sample": [
      "self",
      "data"
    ]
  },
  "OfaSudokuPreprocessor": {
    "__init__": [
      "self",
      "cfg",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_build_train_sample": [
      "self",
      "data"
    ],
    "_build_infer_sample": [
      "self",
      "data"
    ]
  },
  "OfaImageClassificationPreprocessor": {
    "__init__": [
      "self",
      "cfg",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_build_train_sample": [
      "self",
      "data"
    ],
    "_build_infer_sample": [
      "self",
      "data"
    ]
  },
  "OfaSummarizationPreprocessor": {
    "__init__": [
      "self",
      "cfg",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_build_train_sample": [
      "self",
      "data"
    ],
    "_build_infer_sample": [
      "self",
      "data"
    ],
    "add_noise_to_tgt": [
      "self",
      "target"
    ]
  },
  "crop": [
    "image",
    "target",
    "region",
    "delete"
  ],
  "hflip": [
    "image",
    "target"
  ],
  "resize": [
    "image",
    "target",
    "size",
    "max_size"
  ],
  "CenterCrop": {
    "__init__": [
      "self",
      "size"
    ],
    "__call__": [
      "self",
      "img",
      "target"
    ]
  },
  "ObjectCenterCrop": {
    "__init__": [
      "self",
      "size"
    ],
    "__call__": [
      "self",
      "img",
      "target"
    ]
  },
  "RandomHorizontalFlip": {
    "__init__": [
      "self",
      "p"
    ],
    "__call__": [
      "self",
      "img",
      "target"
    ]
  },
  "RandomResize": {
    "__init__": [
      "self",
      "sizes",
      "max_size",
      "equal"
    ],
    "__call__": [
      "self",
      "img",
      "target"
    ]
  },
  "Normalize": {
    "__init__": [
      "self",
      "mean",
      "std",
      "max_image_size"
    ],
    "__call__": [
      "self",
      "image",
      "target"
    ]
  },
  "LargeScaleJitter": {
    "__init__": [
      "self",
      "output_size",
      "aug_scale_min",
      "aug_scale_max"
    ],
    "rescale_target": [
      "self",
      "scaled_size",
      "image_size",
      "target"
    ],
    "crop_target": [
      "self",
      "region",
      "target"
    ],
    "pad_target": [
      "self",
      "padding",
      "target"
    ],
    "__call__": [
      "self",
      "image",
      "target"
    ]
  },
  "OriginLargeScaleJitter": {
    "__init__": [
      "self",
      "output_size",
      "aug_scale_min",
      "aug_scale_max"
    ],
    "rescale_target": [
      "self",
      "scaled_size",
      "image_size",
      "target"
    ],
    "crop_target": [
      "self",
      "region",
      "target"
    ],
    "pad_target": [
      "self",
      "padding",
      "target"
    ],
    "__call__": [
      "self",
      "image",
      "target"
    ]
  },
  "RandomDistortion": {
    "__init__": [
      "self",
      "brightness",
      "contrast",
      "saturation",
      "hue",
      "prob"
    ],
    "__call__": [
      "self",
      "img",
      "target"
    ]
  },
  "collate_fn": [
    "samples",
    "pad_idx",
    "eos_idx"
  ],
  "collate_tokens": [
    "values",
    "pad_idx",
    "eos_idx",
    "left_pad",
    "move_eos_to_beginning",
    "pad_to_length",
    "pad_to_multiple",
    "pad_to_bsz"
  ],
  "_collate_frames": [
    "frames"
  ],
  "TrieNode": {
    "__init__": [
      "self"
    ]
  },
  "TrieTokenizer": {
    "__init__": [
      "self",
      "dict_path"
    ],
    "load_dict": [
      "self"
    ],
    "create_trie_tree": [
      "self"
    ],
    "mine_tree": [
      "self",
      "tree",
      "sentence",
      "trace_index"
    ],
    "tokenize": [
      "self",
      "sentence"
    ],
    "combine": [
      "self",
      "token_list"
    ]
  },
  "Text2Phone": {
    "__init__": [
      "self",
      "phone_dict_path"
    ],
    "get_phone_map": [
      "self",
      "phone_dict_path"
    ],
    "trans": [
      "self",
      "text"
    ]
  },
  "EXIST": [],
  "convert_fk_index": [
    "data"
  ],
  "dump_db_json_schema": [
    "db",
    "f"
  ],
  "convert_waveform": [
    "waveform",
    "sample_rate",
    "normalize_volume",
    "to_mono",
    "to_sample_rate"
  ],
  "_get_kaldi_fbank": [
    "waveform",
    "sample_rate",
    "n_bins"
  ],
  "_get_torchaudio_fbank": [
    "waveform",
    "sample_rate",
    "n_bins"
  ],
  "identity_func": [
    "img"
  ],
  "autocontrast_func": [
    "img",
    "cutoff"
  ],
  "equalize_func": [
    "img"
  ],
  "rotate_func": [
    "img",
    "degree",
    "fill"
  ],
  "solarize_func": [
    "img",
    "thresh"
  ],
  "color_func": [
    "img",
    "factor"
  ],
  "contrast_func": [
    "img",
    "factor"
  ],
  "brightness_func": [
    "img",
    "factor"
  ],
  "sharpness_func": [
    "img",
    "factor"
  ],
  "shear_x_func": [
    "img",
    "factor",
    "fill"
  ],
  "translate_x_func": [
    "img",
    "offset",
    "fill"
  ],
  "translate_y_func": [
    "img",
    "offset",
    "fill"
  ],
  "posterize_func": [
    "img",
    "bits"
  ],
  "shear_y_func": [
    "img",
    "factor",
    "fill"
  ],
  "cutout_func": [
    "img",
    "pad_size",
    "replace"
  ],
  "enhance_level_to_args": [
    "MAX_LEVEL"
  ],
  "shear_level_to_args": [
    "MAX_LEVEL",
    "replace_value"
  ],
  "translate_level_to_args": [
    "translate_const",
    "MAX_LEVEL",
    "replace_value"
  ],
  "cutout_level_to_args": [
    "cutout_const",
    "MAX_LEVEL",
    "replace_value"
  ],
  "solarize_level_to_args": [
    "MAX_LEVEL"
  ],
  "none_level_to_args": [
    "level"
  ],
  "posterize_level_to_args": [
    "MAX_LEVEL"
  ],
  "rotate_level_to_args": [
    "MAX_LEVEL",
    "replace_value"
  ],
  "func_dict": [],
  "translate_const": [],
  "MAX_LEVEL": [],
  "replace_value": [],
  "arg_dict": [],
  "RandomAugment": {
    "__init__": [
      "self",
      "N",
      "M",
      "isPIL",
      "augs"
    ],
    "get_random_ops": [
      "self"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "_stopwords": [],
  "_commonwords": [],
  "is_number": [
    "s"
  ],
  "is_stopword": [
    "s"
  ],
  "is_commonword": [
    "s"
  ],
  "is_common_db_term": [
    "s"
  ],
  "Match": {
    "__init__": [
      "self",
      "start",
      "size"
    ]
  },
  "is_span_separator": [
    "c"
  ],
  "split": [
    "s"
  ],
  "prefix_match": [
    "s1",
    "s2"
  ],
  "get_effective_match_source": [
    "s",
    "start",
    "end"
  ],
  "get_matched_entries": [
    "s",
    "field_values",
    "m_theta",
    "s_theta"
  ],
  "get_column_picklist": [
    "table_name",
    "column_name",
    "db_path"
  ],
  "get_database_matches": [
    "question",
    "table_name",
    "column_name",
    "db_path",
    "top_k_matches",
    "match_threshold"
  ],
  "OFA_TASK_KEY_MAPPING": [],
  "get_rng_state": [],
  "set_rng_state": [
    "state"
  ],
  "set_torch_seed": {
    "__init__": [
      "self",
      "seed"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "DEFAULT_SYSTEM": [],
  "get_template": [
    "template_type",
    "tokenizer",
    "default_system",
    "max_length",
    "truncation_strategy"
  ],
  "_findall": [
    "token_list",
    "sub_token_list"
  ],
  "replace_img_tag": [
    "messages",
    "replace_token",
    "pattern"
  ],
  "StopWordsCriteria": {
    "__init__": [
      "self",
      "tokenizer",
      "stop_words"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "Template": {
    "special_tokens": [],
    "special_keys": [],
    "grounding_type": [],
    "image_placeholder": [],
    "load_medias": [],
    "compute_per_round_loss": [],
    "output_prompt_answer": [],
    "__init__": [
      "self",
      "prefix",
      "prompt",
      "chat_sep",
      "suffix",
      "default_system",
      "system_prefix",
      "auto_add_bos",
      "tools_prompt",
      "tool_prompt",
      "padding_side",
      "infer_media_type"
    ],
    "_replace_system": [
      "prefix"
    ],
    "_has_system": [
      "prefix"
    ],
    "token_attr_to_id": [
      "tokenizer",
      "value"
    ],
    "init_template": [
      "self",
      "tokenizer",
      "default_system",
      "max_length",
      "truncation_strategy",
      "loss_scale",
      "rescale_image"
    ],
    "post_encode": [
      "self",
      "model",
      "data"
    ],
    "check_example": [
      "self",
      "example"
    ],
    "add_default_tags": [
      "self",
      "example"
    ],
    "replace_media_tags": [
      "self",
      "example"
    ],
    "_preprocess_media": [
      "self",
      "example"
    ],
    "preprocess": [
      "self",
      "example"
    ],
    "encode": [
      "self",
      "example",
      "streaming",
      "is_training"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "_concat_context_list": [
      "self",
      "context_list",
      "res_context_list",
      "loss_scale_list",
      "system",
      "query",
      "response",
      "round0",
      "compute_loss"
    ],
    "_simplify_context_list": [
      "self",
      "context_list",
      "loss_scale_list"
    ],
    "split_special_tokens": [
      "context_list",
      "loss_scale_list"
    ],
    "_tokenize": [
      "self",
      "context"
    ],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "replace_object": [
      "self",
      "index",
      "example"
    ],
    "replace_box": [
      "self",
      "index",
      "example"
    ],
    "normalize_bbox": [
      "cls",
      "objects",
      "images",
      "to_type"
    ],
    "pre_tokenize": [
      "self",
      "context_list",
      "loss_scale_list"
    ],
    "_encode_context_list": [
      "self",
      "context_list",
      "loss_scale_list"
    ],
    "use_dynamic_eos": [
      "labels",
      "suffix_tokens_id"
    ],
    "_concat_and_tokenize": [
      "self",
      "messages",
      "truncation_strategy",
      "auto_add_bos"
    ],
    "_get_tokenizer_kwargs": [
      "self",
      "context"
    ],
    "_concat_tokenizer_kwargs": [
      "self",
      "tokenizer_kwargs",
      "curr_tokenizer_kwargs"
    ],
    "pad_sequence": [
      "sequences",
      "padding_value",
      "padding_side"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ],
    "get_generate_ids": [
      "cls",
      "generate_ids",
      "input_token_len"
    ],
    "_get_generate_ids": [
      "generate_ids",
      "input_token_len"
    ],
    "_is_chinese_char": [
      "cp"
    ],
    "_get_safe_print_idx": [
      "cls",
      "response",
      "print_idx",
      "is_finished"
    ],
    "generate_ids_to_response": [
      "self",
      "generate_ids",
      "is_finished"
    ],
    "post_process_generate_response": [
      "self",
      "response",
      "example"
    ]
  },
  "History": [],
  "Prompt": [],
  "StopWords": [],
  "Context": [],
  "Messages": [],
  "IMAGENET_MEAN": [],
  "IMAGENET_STD": [],
  "split_str_parts_by": [
    "text",
    "delimiters"
  ],
  "split_parts_by_regex": [
    "text_list",
    "regex_delimiters"
  ],
  "_decode_prompt": [
    "prompt",
    "tmp_dir"
  ],
  "_to_base64": [
    "img_path"
  ],
  "_from_base64": [
    "img_base64",
    "tmp_dir"
  ],
  "decode_base64": [],
  "upper_bound": [
    "lo",
    "hi",
    "cond"
  ],
  "fetch_one": [
    "element",
    "type"
  ],
  "_build_transform": [
    "input_size"
  ],
  "_find_closest_aspect_ratio": [
    "aspect_ratio",
    "target_ratios",
    "width",
    "height",
    "image_size"
  ],
  "_dynamic_preprocess": [
    "image",
    "min_num",
    "max_num",
    "image_size",
    "use_thumbnail"
  ],
  "rescale_image": [
    "img",
    "rescale_image"
  ],
  "_T": [],
  "load_file": [
    "path"
  ],
  "load_file_decorator": [
    "func"
  ],
  "load_batch": [
    "path_list",
    "load_func"
  ],
  "_get_index": [
    "bound",
    "fps",
    "max_frame",
    "first_idx",
    "num_segments"
  ],
  "transform_image": [
    "image",
    "input_size",
    "max_num"
  ],
  "load_video_internvl": [
    "video_io",
    "bound",
    "num_segments"
  ],
  "draw_plot": [
    "img_dir",
    "bbox",
    "bbox_type",
    "output_file"
  ],
  "load_video_cogvlm2": [
    "video_io"
  ],
  "load_video_llava": [
    "video_io"
  ],
  "load_video_minicpmv_mplug_owl3": [
    "video_io",
    "max_num_frames"
  ],
  "load_audio_qwen": [
    "audio_io",
    "sampling_rate"
  ],
  "load_video_qwen2": [
    "video_path"
  ],
  "TemplateInfo": {},
  "cases": [],
  "chat_suffix": [],
  "no": [],
  "no_multi_modal": [],
  "template_info": [],
  "TemplateLoader": {
    "load_by_model_id": [
      "model_id"
    ],
    "load_by_template_name": [
      "template_name"
    ],
    "replace_and_concat": [
      "template",
      "template_list",
      "placeholder",
      "keyword"
    ],
    "_format_return": [
      "template_lines",
      "params",
      "split",
      "license"
    ],
    "to_ollama": [
      "model_id",
      "template_name",
      "gguf_file",
      "gguf_meta",
      "split",
      "debug"
    ],
    "_read_content_from_url": [
      "url"
    ]
  },
  "TemplateType": {
    "default_generation": [],
    "chatglm_generation": [],
    "qwen_vl_generation": [],
    "qwen_audio_generation": [],
    "default": [],
    "qwen": [],
    "qwen_vl": [],
    "qwen_audio": [],
    "qwen2_audio": [],
    "qwen2_audio_generation": [],
    "qwen2_vl": [],
    "modelscope_agent": [],
    "baichuan": [],
    "chatglm2": [],
    "chatglm3": [],
    "chatglm4": [],
    "codegeex4": [],
    "llama": [],
    "llama3": [],
    "reflection": [],
    "longwriter_llama3": [],
    "llava1_5": [],
    "llava_mistral": [],
    "llava_vicuna": [],
    "llava_yi": [],
    "llama3_llava_next_hf": [],
    "llava_next_llama3": [],
    "llava_qwen_hf": [],
    "llava_onevision_qwen": [],
    "llava_next_video": [],
    "llava_next_video_yi": [],
    "llama3_llava_next": [],
    "llava_qwen": [],
    "llava_llama_instruct": [],
    "idefics3": [],
    "mistral_nemo": [],
    "openbuddy": [],
    "openbuddy2": [],
    "internlm": [],
    "internlm2": [],
    "internlm_xcomposer2": [],
    "internlm_xcomposer2_4khd": [],
    "internlm_xcomposer2_5": [],
    "internvl": [],
    "internvl2": [],
    "internvl_phi3": [],
    "internvl2_phi3": [],
    "florence": [],
    "yi_coder": [],
    "yi_vl": [],
    "yuan": [],
    "xverse": [],
    "ziya": [],
    "skywork": [],
    "bluelm": [],
    "zephyr": [],
    "sus": [],
    "deepseek": [],
    "numina_math": [],
    "deepseek_coder": [],
    "deepseek_vl": [],
    "deepseek2": [],
    "deepseek2_5": [],
    "codefuse_codellama": [],
    "codefuse": [],
    "cogvlm": [],
    "cogvlm2_video": [],
    "glm4v": [],
    "cogagent_chat": [],
    "cogagent_instruct": [],
    "orion": [],
    "minicpm": [],
    "minicpm_v": [],
    "minicpm_v_v2_5": [],
    "minicpm_v_v2_6": [],
    "gemma": [],
    "paligemma": [],
    "mplug_owl2": [],
    "mplug_owl3": [],
    "wizardlm2_awq": [],
    "wizardlm2": [],
    "atom": [],
    "phi3": [],
    "phi3_vl": [],
    "telechat": [],
    "telechat_v2": [],
    "dbrx": [],
    "mengzi": [],
    "c4ai": [],
    "chatml": [],
    "default_generation_bos": [],
    "get_template_name_list": [
      "cls"
    ]
  },
  "register_template": [
    "template_type",
    "template"
  ],
  "DefaultGenerationTemplate": {
    "__init__": [
      "self"
    ]
  },
  "ChatmlTemplateMixin": {
    "system": [],
    "__init__": [
      "self",
      "auto_add_bos"
    ]
  },
  "ChatmlTemplate": {},
  "QwenTemplateMixin": {
    "system": [],
    "__init__": [
      "self"
    ]
  },
  "QwenTemplate": {},
  "_QwenVLTemplateMixin": {
    "load_medias": [],
    "check_example": [
      "self",
      "example"
    ],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "replace_object": [
      "self",
      "index",
      "example"
    ],
    "replace_box": [
      "self",
      "index",
      "example"
    ]
  },
  "QwenVLTemplate": {},
  "QwenVLGenerationTemplate": {},
  "_QwenAudioTemplateMixin": {
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "_get_tokenizer_kwargs": [
      "self",
      "context"
    ],
    "_concat_tokenizer_kwargs": [
      "self",
      "tokenizer_kwargs",
      "curr_tokenizer_kwargs"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ]
  },
  "QwenAudioTemplate": {},
  "QwenAudioGenerationTemplate": {},
  "_Qwen2AudioTemplateMixin": {
    "_encode": [
      "self",
      "example"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ]
  },
  "Qwen2AudioTemplate": {
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ]
  },
  "Qwen2AudioGenerationTemplate": {
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ]
  },
  "_process_image_qwen": [
    "image"
  ],
  "Qwen2VLTemplate": {
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "replace_object": [
      "self",
      "index",
      "example"
    ],
    "replace_box": [
      "self",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ]
  },
  "YiCoderTemplate": {
    "system": []
  },
  "yi_vl_default_system": [],
  "YiVLTemplate": {
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ]
  },
  "GLMTemplate": {
    "_init_template": [
      "self",
      "tokenizer"
    ]
  },
  "GLM4VTemplate": {
    "__init__": [
      "self"
    ],
    "check_example": [
      "self",
      "example"
    ],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ]
  },
  "codegeex4_system": [],
  "LLAMA_DEFAULT_SYSTEM": [],
  "Llama3TemplateMixin": {
    "system": [],
    "__init__": [
      "self"
    ]
  },
  "Llama3Template": {},
  "ReflectionTemplate": {
    "system": []
  },
  "OPENBUDDY_DEFAULT_SYSTEM": [],
  "OPENBUDDY2_DEFAULT_SYSTEM": [],
  "INTERNLM_SYSTEM": [],
  "_log_set": [],
  "get_env_args": [
    "args_name",
    "type_func",
    "default_value"
  ],
  "Internlm2Template": {
    "system": []
  },
  "InternLMXComposer2Template": {
    "INTERNLM_XCOMPOSER_SYSTEM": [],
    "image_placeholder": [],
    "__init__": [
      "self",
      "version"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "post_encode": [
      "self",
      "model",
      "data"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ],
    "_get_generate_ids": [
      "generate_ids",
      "input_token_len"
    ]
  },
  "InternLMXComposer2_5Template": {
    "INTERNLM_XCOMPOSER_SYSTEM": []
  },
  "InternvlTemplate": {
    "system": [],
    "num_image_token": [],
    "__init__": [
      "self"
    ],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "post_encode": [
      "self",
      "model",
      "data"
    ],
    "_get_generate_ids": [
      "generate_ids",
      "input_token_len"
    ]
  },
  "_replace_video2image": [
    "load_video_func",
    "example",
    "replace_tag"
  ],
  "Internvl2Template": {
    "video_segments": [],
    "system": [],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "replace_object": [
      "self",
      "index",
      "example"
    ],
    "replace_box": [
      "self",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ]
  },
  "InternvlPhi3TemplateMixin": {
    "__init__": [
      "self"
    ]
  },
  "InternvlPhi3Template": {
    "system": []
  },
  "Internvl2Phi3Template": {},
  "FlorenceTemplate": {
    "compute_per_round_loss": [],
    "output_prompt_answer": [],
    "__init__": [
      "self"
    ],
    "check_example": [
      "self",
      "example"
    ],
    "add_default_tags": [
      "self",
      "example"
    ],
    "replace_box": [
      "self",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "post_encode": [
      "self",
      "model",
      "data"
    ],
    "_get_generate_ids": [
      "generate_ids",
      "input_token_len"
    ],
    "post_process_generate_response": [
      "self",
      "response",
      "example"
    ]
  },
  "LlavaHfTemplate": {
    "__init__": [
      "self"
    ],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ]
  },
  "Llava1_6Llama3Template": {
    "default_system": [],
    "__init__": [
      "self"
    ],
    "_encode": [
      "self",
      "example"
    ]
  },
  "LlavaVideoTemplate": {
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ]
  },
  "align_image_inputs": [
    "input_ids",
    "labels",
    "new_input_ids",
    "image_token"
  ],
  "Idefics3Template": {
    "_encode": [
      "self",
      "example"
    ]
  },
  "Llava1_5Template": {
    "__init__": [
      "self"
    ]
  },
  "LLavaTemplate": {
    "__init__": [
      "self"
    ],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ],
    "_get_generate_ids": [
      "generate_ids",
      "input_token_len"
    ]
  },
  "Llava1_6Template": {
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ]
  },
  "Llava1_6MistralTemplate": {
    "__init__": [
      "self"
    ]
  },
  "Llava1_6VicunaTemplate": {
    "system": [],
    "__init__": [
      "self"
    ]
  },
  "LLava1_6YiTemplate": {
    "__init__": [
      "self"
    ],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ]
  },
  "Llama3LlavaNextHfTemplate": {},
  "LlavaQwenHfTemplate": {},
  "LlavaOneVisonTemplate": {
    "system": [],
    "_encode": [
      "self",
      "example"
    ]
  },
  "LLavaLlamaTemplate": {
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ]
  },
  "PaliGemmaTemplate": {
    "__init__": [
      "self"
    ],
    "check_example": [
      "self",
      "example"
    ],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ]
  },
  "Phi3Template": {
    "__init__": [
      "self"
    ]
  },
  "Phi3VisionTemplate": {
    "image_placeholder": [],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ]
  },
  "Llama3LlavaNextTemplate": {
    "system": []
  },
  "LLavaQwenTemplate": {},
  "DeepseekVLTemplate": {
    "DEEPSEEK_VL_SYSTEM": [],
    "image_placeholder": [],
    "__init__": [
      "self"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "post_encode": [
      "self",
      "model",
      "data"
    ],
    "_get_generate_ids": [
      "generate_ids",
      "input_token_len"
    ]
  },
  "CogTemplate": {
    "check_example": [
      "self",
      "example"
    ],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ]
  },
  "Cog2VideoTemplate": {
    "check_example": [
      "self",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ]
  },
  "_remove_idx": [
    "arr",
    "idx_list"
  ],
  "MiniCPMVTemplate": {
    "is_v2_5": [],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "check_example": [
      "self",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "post_encode": [
      "self",
      "model",
      "data"
    ],
    "_get_generate_ids": [
      "generate_ids",
      "input_token_len"
    ]
  },
  "MiniCPMV2_6Template": {
    "check_example": [
      "self",
      "example"
    ],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ]
  },
  "MiniCPMV2_5Template": {
    "is_v2_5": []
  },
  "gemma_template": [],
  "DBRX_SYSTEM": [],
  "DbrxTemplate": {
    "system": []
  },
  "C4AI_SYSTEM": [],
  "mPlugOwl2Template": {
    "__init__": [
      "self"
    ],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ]
  },
  "mPlugOwl3Template": {
    "system": [],
    "_get_image_token_list": [
      "self",
      "cut_shape"
    ],
    "replace_tag": [
      "self",
      "media_type",
      "index",
      "example"
    ],
    "_encode": [
      "self",
      "example"
    ],
    "_post_encode": [
      "self",
      "model",
      "data"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ]
  },
  "_wizardlm2_system": [],
  "RLHFTemplateMixin": {
    "encode": [
      "self",
      "example",
      "streaming"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ]
  },
  "KTOTemplateMixin": {
    "encode": [
      "self",
      "example",
      "streaming"
    ],
    "data_collator": [
      "self",
      "batch",
      "padding_to"
    ]
  },
  "format_react_en": [
    "tool_names",
    "tool_descs"
  ],
  "format_react_zh": [
    "tool_names",
    "tool_descs"
  ],
  "format_glm4": [
    "tool_names",
    "tool_descs"
  ],
  "format_toolbench": [
    "tool_names",
    "tool_descs"
  ],
  "tools_prompt": [],
  "get_tools_prompt": [
    "TOOLS",
    "prompt_format"
  ],
  "calculate_loss_scale": [
    "query",
    "response",
    "response_loss_scale_map",
    "query_loss_scale_map"
  ],
  "alpha_umi_loss_scale": [
    "query",
    "response"
  ],
  "agentflan_loss_scale": [
    "query",
    "response"
  ],
  "react_loss_scale": [
    "query",
    "response"
  ],
  "default_loss_scale": [
    "query",
    "response"
  ],
  "loss_scale_map": [],
  "BadImageDetectingPreprocessor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "ImageClassificationMmcvPreprocessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "HWC3": [
    "x"
  ],
  "resize_image": [
    "input_image",
    "resolution"
  ],
  "build_detector": [
    "control_type",
    "model_path",
    "device"
  ],
  "get_detected_map": [
    "detector",
    "control_type",
    "img"
  ],
  "ControllableImageGenerationPreprocessor": {
    "__init__": [
      "self",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "ImageQualityAssessmentMANPreprocessor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "_cv2_pad_to_str": [],
  "_cv2_interpolation_to_str": [],
  "_cv2_interpolation_from_str": [],
  "_is_tensor_image": [
    "img"
  ],
  "_is_numpy_image": [
    "img"
  ],
  "pad": [
    "img",
    "padding",
    "fill",
    "padding_mode"
  ],
  "center_crop": [
    "img",
    "output_size"
  ],
  "resized_crop": [
    "img",
    "i",
    "j",
    "h",
    "w",
    "size",
    "interpolation"
  ],
  "Resize": {
    "__init__": [
      "self",
      "size",
      "interpolation"
    ],
    "__call__": [
      "self",
      "img"
    ],
    "__repr__": [
      "self"
    ]
  },
  "RandomCrop": {
    "__init__": [
      "self",
      "size",
      "padding",
      "pad_if_needed",
      "fill",
      "padding_mode"
    ],
    "get_params": [
      "img",
      "output_size"
    ],
    "__call__": [
      "self",
      "img"
    ],
    "__repr__": [
      "self"
    ]
  },
  "RandomResizedCrop": {
    "__init__": [
      "self",
      "size",
      "scale",
      "ratio",
      "interpolation"
    ],
    "get_params": [
      "img",
      "scale",
      "ratio"
    ],
    "__call__": [
      "self",
      "img"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ImageQualityAssessmentMosPreprocessor": {
    "__init__": [
      "self"
    ],
    "preprocessors": [
      "self",
      "input"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "BACKEND_TORCHVISION": [],
  "BACKEND_PILLOW": [],
  "BACKEND_CV2": [],
  "BACKENDS": [],
  "INTERPOLATION_STYLE": [],
  "INTERPOLATION_STYLE_CV2": [],
  "is_pil_image": [
    "img"
  ],
  "is_cv2_image": [
    "img"
  ],
  "is_tensor": [
    "t"
  ],
  "ImageTransform": {
    "__init__": [
      "self",
      "backend",
      "input_key",
      "output_key"
    ],
    "check_image_type": [
      "self",
      "input_img"
    ]
  },
  "ImageToTensor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "item"
    ]
  },
  "build_preprocess_pipeline": [
    "pipeline",
    "group_name"
  ],
  "ImageClassificationPreprocessor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "results"
    ]
  },
  "check_file_exist": [
    "filename",
    "msg_tmpl"
  ],
  "mkdir_or_exist": [
    "dir_name",
    "mode"
  ],
  "ProgressBar": {
    "__init__": [
      "self",
      "task_num",
      "bar_width",
      "start",
      "file"
    ],
    "terminal_width": [
      "self"
    ],
    "start": [
      "self"
    ],
    "update": [
      "self",
      "num_tasks"
    ]
  },
  "track_progress": [
    "func",
    "tasks",
    "bar_width",
    "file"
  ],
  "Cache": {
    "__init__": [
      "self",
      "capacity"
    ],
    "capacity": [
      "self"
    ],
    "size": [
      "self"
    ],
    "put": [
      "self",
      "key",
      "val"
    ],
    "get": [
      "self",
      "key",
      "default"
    ]
  },
  "VideoReader": {
    "__init__": [
      "self",
      "filename",
      "cache_capacity"
    ],
    "vcap": [
      "self"
    ],
    "opened": [
      "self"
    ],
    "width": [
      "self"
    ],
    "height": [
      "self"
    ],
    "resolution": [
      "self"
    ],
    "fps": [
      "self"
    ],
    "frame_cnt": [
      "self"
    ],
    "fourcc": [
      "self"
    ],
    "position": [
      "self"
    ],
    "_get_real_position": [
      "self"
    ],
    "_set_real_position": [
      "self",
      "frame_id"
    ],
    "read": [
      "self"
    ],
    "get_frame": [
      "self",
      "frame_id"
    ],
    "current_frame": [
      "self"
    ],
    "cvt2frames": [
      "self",
      "frame_dir",
      "file_start",
      "filename_tmpl",
      "start",
      "max_num",
      "show_progress"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "next": [],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "ImageRestorationPreprocessor": {
    "__init__": [
      "self",
      "pad_32",
      "min_max_l"
    ],
    "img_pad_3": [
      "self",
      "x",
      "w_pad",
      "h_pad",
      "w_odd_pad",
      "h_odd_pad"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "TimerError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "_g_timers": [],
  "check_time": [
    "timer_id"
  ],
  "inp_boxes": [
    "boxes",
    "start",
    "end"
  ],
  "assign_label": [
    "start",
    "end",
    "data_dict"
  ],
  "VideoDetMapper": {
    "__init__": [
      "self",
      "classes_id_map",
      "used_seconds",
      "input_frames",
      "is_train",
      "tile"
    ],
    "__call__": [
      "self",
      "data_dict"
    ],
    "_call": [
      "self",
      "data_dict"
    ],
    "random_tile": [
      "self",
      "name",
      "imgs",
      "labels",
      "bboxes",
      "pos_choices"
    ],
    "random_extent": [
      "self",
      "imgs",
      "bboxes"
    ]
  },
  "stabilization_preprocessor": [
    "input",
    "cfg"
  ],
  "get_transform": [
    "lst"
  ],
  "build_transform": [
    "cfg"
  ],
  "VideoResizedCenterCrop": {
    "__init__": [
      "self",
      "image_size",
      "crop_size"
    ],
    "__call__": [
      "self",
      "imgmap"
    ]
  },
  "VideoToTensor": {
    "__init__": [
      "self",
      "mean",
      "std",
      "inplace"
    ],
    "__to_tensor__": [
      "self",
      "img"
    ],
    "__normalize__": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "imgmap"
    ]
  },
  "VideoRandomResizedCrop": {
    "__init__": [
      "self",
      "size",
      "bottom_area"
    ],
    "__call__": [
      "self",
      "imgmap"
    ]
  },
  "VideoRandomHFlip": {
    "__init__": [
      "self",
      "consistent",
      "command",
      "seq_len"
    ],
    "__call__": [
      "self",
      "imgmap"
    ]
  },
  "VideoRandomColorJitter": {
    "__init__": [
      "self",
      "brightness",
      "contrast",
      "saturation",
      "hue",
      "consistent",
      "p",
      "seq_len"
    ],
    "_check_input": [
      "self",
      "value",
      "name",
      "center",
      "bound",
      "clip_first_on_zero"
    ],
    "get_params": [
      "brightness",
      "contrast",
      "saturation",
      "hue"
    ],
    "__call__": [
      "self",
      "imgmap"
    ],
    "__repr__": [
      "self"
    ]
  },
  "VideoRandomGaussianBlur": {
    "__init__": [
      "self",
      "radius_min",
      "radius_max",
      "p"
    ],
    "__call__": [
      "self",
      "imgmap"
    ]
  },
  "apply_transform": [
    "images",
    "trans"
  ],
  "TQDM_BAR_FORMAT": [],
  "DEFAULT_API_SERVER": [],
  "run_mmseqs2": [
    "x",
    "prefix",
    "use_env",
    "use_templates",
    "use_pairing",
    "host_url"
  ],
  "get_null_template": [
    "query_sequence",
    "num_temp"
  ],
  "UniFoldPreprocessor": {
    "__init__": [
      "self"
    ],
    "clean_and_validate_sequence": [
      "self",
      "input_sequence",
      "min_length",
      "max_length"
    ],
    "validate_input": [
      "self",
      "input_sequences",
      "symmetry_group",
      "min_length",
      "max_length",
      "max_multimer_length"
    ],
    "add_hash": [
      "self",
      "x",
      "y"
    ],
    "get_msa_and_templates": [
      "self",
      "jobname",
      "query_seqs_unique",
      "result_dir",
      "msa_mode",
      "use_templates",
      "homooligomers_num",
      "host_url"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "TextClean": {
    "__init__": [
      "self"
    ],
    "sbc2dbc": [
      "self",
      "ch"
    ],
    "clean": [
      "self",
      "s"
    ]
  },
  "SiameseUiePreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "TextClassificationPreprocessorBase": {
    "__init__": [
      "self",
      "model_dir",
      "first_sequence",
      "second_sequence",
      "label",
      "label2id",
      "mode",
      "keep_original_columns"
    ],
    "id2label": [
      "self"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_tokenize_text": [
      "self",
      "sequence1",
      "sequence2"
    ]
  },
  "TextClassificationTransformersPreprocessor": {
    "_tokenize_text": [
      "self",
      "sequence1",
      "sequence2"
    ],
    "__init__": [
      "self",
      "model_dir",
      "first_sequence",
      "second_sequence",
      "label",
      "label2id",
      "mode",
      "max_length",
      "use_fast",
      "keep_original_columns"
    ]
  },
  "SentenceEmbeddingTransformersPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "first_sequence",
      "second_sequence",
      "mode",
      "use_fast",
      "max_length"
    ],
    "__call__": [
      "self",
      "data",
      "padding",
      "truncation"
    ],
    "tokenize": [
      "self",
      "texts",
      "is_query",
      "return_tensors"
    ],
    "add_eos_pt": [
      "self",
      "encoding",
      "eos"
    ],
    "add_eos": [
      "self",
      "encoding",
      "eos"
    ]
  },
  "MGLMSummarizationPreprocessor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "DocumentSegmentationTransformersPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "model_max_length",
      "mode",
      "question_column_name",
      "context_column_name",
      "example_id_column_name",
      "label_list"
    ],
    "__call__": [
      "self",
      "examples",
      "model_cfg"
    ]
  },
  "Tokenize": {
    "__init__": [
      "self",
      "tokenizer_name"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "parse_text_and_label": [
    "data",
    "mode",
    "first_sequence",
    "second_sequence",
    "label"
  ],
  "labels_to_id": [
    "labels",
    "output",
    "label2id"
  ],
  "FeatureExtractionTransformersPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "first_sequence",
      "second_sequence",
      "mode",
      "max_length",
      "use_fast"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_tokenize_text": [
      "self",
      "sequence1",
      "sequence2"
    ]
  },
  "WordAlignmentPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "sequence_pair",
      "mode",
      "use_fast",
      "sequence_length"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "NERPreprocessorThai": {
    "__call__": [
      "self",
      "data"
    ]
  },
  "WordSegmentationPreprocessorThai": {
    "__call__": [
      "self",
      "data"
    ]
  },
  "DocumentGroundedDialogGeneratePreprocessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "data",
      "invoke_mode"
    ]
  },
  "TranslationEvaluationTransformersPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "max_len",
      "pad_token_id",
      "eos_token_id",
      "input_format",
      "mode"
    ],
    "change_input_format": [
      "self",
      "input_format"
    ],
    "collect_input_ids": [
      "self",
      "input_dict"
    ],
    "__call__": [
      "self",
      "input_dict"
    ]
  },
  "RelationExtractionTransformersPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "CanmtTranslationPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "max_length"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "NLPTokenizer": {
    "__init__": [
      "self",
      "model_dir",
      "model_type",
      "use_fast",
      "tokenize_kwargs"
    ],
    "tokenizer": [
      "self"
    ],
    "use_fast": [
      "self"
    ],
    "build_tokenizer": [
      "self"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair"
    ],
    "get_tokenizer_kwarg": [
      "self",
      "key",
      "default_value"
    ]
  },
  "DocumentGroundedDialogRetrievalPreprocessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "data",
      "invoke_mode",
      "input_type"
    ]
  },
  "ZeroShotClassificationTransformersPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "first_sequence",
      "mode",
      "max_length",
      "use_fast"
    ],
    "__call__": [
      "self",
      "data",
      "hypothesis_template",
      "candidate_labels",
      "padding",
      "truncation",
      "truncation_strategy"
    ]
  },
  "DialogueClassificationUsePreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "label2id",
      "max_length"
    ],
    "id2label": [
      "self"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "TextGenerationPreprocessorBase": {
    "__init__": [
      "self",
      "mode",
      "src_txt",
      "tgt_txt",
      "keep_original_columns"
    ],
    "_tokenize_text": [
      "self",
      "sequence1",
      "sequence2"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "decode": [
      "self",
      "tokens"
    ]
  },
  "NLPTokenizerForRoberta": {
    "build_tokenizer": [
      "self"
    ]
  },
  "TextGenerationTransformersPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "tokenizer",
      "mode",
      "src_txt",
      "tgt_txt",
      "sequence_length",
      "use_fast",
      "keep_original_columns"
    ],
    "decode": [
      "self",
      "tokens"
    ],
    "_tokenize_text": [
      "self",
      "sequence1",
      "sequence2"
    ],
    "_get_labels_from_tgt": [
      "self",
      "sequence"
    ]
  },
  "TextGenerationJiebaPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode",
      "src_txt",
      "tgt_txt",
      "sequence_length",
      "use_fast"
    ],
    "decode": [
      "self",
      "tokens"
    ],
    "_tokenize_text": [
      "self",
      "sequence1",
      "sequence2"
    ],
    "_only_input": [
      "self",
      "input_tokens"
    ],
    "_input_and_output": [
      "self",
      "input_tokens",
      "output_tokens"
    ],
    "_truncate": [
      "self",
      "array"
    ]
  },
  "TextGenerationSentencePiecePreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode",
      "src_txt",
      "tgt_txt"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_tokenize_text": [
      "self",
      "sequence1",
      "sequence2"
    ],
    "decode": [
      "self",
      "tokens"
    ]
  },
  "TextGenerationT5Preprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode",
      "src_txt",
      "tgt_txt",
      "use_fast"
    ]
  },
  "SentencePiecePreprocessor": [],
  "TextRankingPreprocessorBase": {
    "__init__": [
      "self",
      "mode",
      "first_sequence",
      "second_sequence",
      "label",
      "qid"
    ]
  },
  "TextRankingTransformersPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode",
      "first_sequence",
      "second_sequence",
      "label",
      "qid",
      "max_length",
      "padding",
      "truncation",
      "use_fast"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "DocumentGroundedDialogRerankPreprocessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "GisUtt": {
    "__init__": [
      "self",
      "pad_token_id",
      "cls_token_id"
    ],
    "update": [
      "self",
      "gis_input_ids",
      "gis_token_type_ids",
      "gis_rel_type_ids",
      "gis_absolute_position_ids",
      "gis_relative_position_ids",
      "gis_prov_ids",
      "gis_city_ids",
      "gis_dist_ids",
      "china_version"
    ]
  },
  "MGeoRankingTransformersPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode",
      "first_sequence",
      "second_sequence",
      "first_sequence_gis",
      "second_sequence_gis",
      "label",
      "qid",
      "max_length",
      "padding",
      "truncation",
      "use_fast"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "WordSegmentationBlankSetToLabelPreprocessor": {
    "__init__": [
      "self",
      "generated_sentence",
      "generated_label"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "TokenClassificationPreprocessorBase": {
    "__init__": [
      "self",
      "model_dir",
      "first_sequence",
      "label",
      "label2id",
      "label_all_tokens",
      "mode",
      "keep_original_columns",
      "return_text"
    ],
    "id2label": [
      "self"
    ],
    "labels_to_id": [
      "self",
      "labels_list",
      "word_ids"
    ],
    "_tokenize_text": [
      "self",
      "sequence1"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "NLPTokenizerForLSTM": {
    "build_tokenizer": [
      "self"
    ],
    "get_tokenizer_class": [
      "self"
    ]
  },
  "TokenClassificationTransformersPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "first_sequence",
      "label",
      "label2id",
      "label_all_tokens",
      "mode",
      "max_length",
      "use_fast",
      "keep_original_columns",
      "return_text"
    ],
    "_tokenize_text": [
      "self",
      "text"
    ],
    "_tokenize_text_by_words": [
      "self",
      "tokens"
    ],
    "_tokenize_text_with_fast_tokenizer": [
      "self",
      "tokens"
    ],
    "_tokenize_text_with_slow_tokenizer": [
      "self",
      "tokens"
    ],
    "get_label_mask_and_offset_mapping_BertTokenizer": [
      "self",
      "text"
    ],
    "get_label_mask_and_offset_mapping_XLMRobertaTokenizer": [
      "self",
      "text"
    ]
  },
  "FaqQuestionAnsweringTransformersPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode",
      "tokenizer",
      "query_set",
      "support_set",
      "query_label",
      "label_in_support_set",
      "text_in_support_set",
      "sequence_length"
    ],
    "pad": [
      "self",
      "samples",
      "max_len"
    ],
    "set_label_dict": [
      "self",
      "label_dict"
    ],
    "get_label": [
      "self",
      "label_id"
    ],
    "encode_plus": [
      "self",
      "text"
    ],
    "preprocess": [
      "self",
      "support_set"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "batch_encode": [
      "self",
      "sentence_list",
      "max_length"
    ]
  },
  "MULTI_SEP_TOKENS_TOKENIZERS_SET": [],
  "MachineReadingComprehensionForNERPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "label2query"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "prompt": [
      "self",
      "all_data",
      "var"
    ],
    "encode": [
      "self",
      "data",
      "max_length",
      "max_query_length"
    ]
  },
  "collate_to_max_length_roberta": [
    "batch"
  ],
  "TextErrorCorrectionPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "max_length"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "FillMaskPreprocessorBase": {
    "__init__": [
      "self",
      "first_sequence",
      "second_sequence",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_tokenize_text": [
      "self",
      "sequence1",
      "sequence2"
    ],
    "mask_id": [
      "self"
    ],
    "decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ]
  },
  "FillMaskTransformersPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "first_sequence",
      "second_sequence",
      "mode",
      "max_length",
      "use_fast"
    ],
    "_tokenize_text": [
      "self",
      "sequence1",
      "sequence2"
    ],
    "mask_id": [
      "self"
    ],
    "decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ]
  },
  "FillMaskPoNetPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "first_sequence",
      "second_sequence",
      "mode",
      "max_length",
      "use_fast"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "mask_id": [
      "self"
    ],
    "decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ]
  },
  "NERPreprocessorViet": {
    "__call__": [
      "self",
      "data"
    ]
  },
  "TableQuestionAnsweringPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "db"
    ],
    "construct_data": [
      "self",
      "search_result_list",
      "nlu",
      "nlu_t",
      "db",
      "history_sql"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "SchemaLinker": {
    "__init__": [
      "self"
    ],
    "find_in_list": [
      "self",
      "comlist",
      "words"
    ],
    "get_continue_score": [
      "self",
      "pstr",
      "tstr"
    ],
    "get_match_score": [
      "self",
      "ptokens",
      "ttokens"
    ],
    "is_number": [
      "self",
      "s"
    ],
    "get_match_phrase": [
      "self",
      "query",
      "target"
    ],
    "allfindpairidx": [
      "self",
      "que_tok",
      "value_tok",
      "weight"
    ],
    "findnear": [
      "self",
      "ps1",
      "pe1",
      "ps2",
      "pe2"
    ],
    "get_column_type": [
      "self",
      "col_idx",
      "table"
    ],
    "add_type_all": [
      "self",
      "typeinfos",
      "index",
      "idxs",
      "label",
      "linktype",
      "value",
      "orgvalue"
    ],
    "save_info": [
      "self",
      "tinfo",
      "sinfo"
    ],
    "normal_type_infos": [
      "self",
      "infos"
    ],
    "findnear_typeinfo": [
      "self",
      "info1",
      "info2"
    ],
    "find_real_column": [
      "self",
      "infos",
      "table"
    ],
    "filter_column_infos": [
      "self",
      "infos"
    ],
    "filter_type_infos": [
      "self",
      "infos",
      "table"
    ],
    "get_table_match_score": [
      "self",
      "nlu_t",
      "schema_link"
    ],
    "get_entity_linking": [
      "self",
      "tokenizer",
      "nlu",
      "nlu_t",
      "tables",
      "col_syn_dict",
      "table_id",
      "history_sql"
    ]
  },
  "Database": {
    "__init__": [
      "self",
      "tokenizer",
      "table_file_path",
      "syn_dict_file_path",
      "is_use_sqlite"
    ],
    "__del__": [
      "self"
    ],
    "init_tables": [
      "self",
      "table_file_path"
    ],
    "init_syn_dict": [
      "self",
      "syn_dict_file_path"
    ]
  },
  "cond_ops": [],
  "agg_ops": [],
  "conn_ops": [],
  "SQLQuery": {
    "__init__": [
      "self",
      "string",
      "query",
      "sql_result"
    ]
  },
  "TypeInfo": {
    "__init__": [
      "self",
      "label",
      "index",
      "linktype",
      "value",
      "orgvalue",
      "pstart",
      "pend",
      "weight"
    ]
  },
  "Constant": {
    "__init__": [
      "self"
    ]
  },
  "batch": [
    "reader",
    "batch_size",
    "drop_last"
  ],
  "DialogModelingPreprocessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "LazyDataset": {
    "__init__": [
      "self",
      "data_file",
      "reader",
      "transform"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "get_data_loader": [
    "batch_size",
    "reader",
    "hparams",
    "file",
    "collate_fn",
    "is_test"
  ],
  "get_sequential_data_loader": [
    "batch_size",
    "reader",
    "hparams",
    "data_paths",
    "collate_fn",
    "data_type"
  ],
  "DataLoader": {
    "add_cmdline_argument": [
      "cls",
      "group"
    ],
    "__init__": [
      "self",
      "dataset",
      "batch_size",
      "hparams",
      "collate_fn",
      "sampler",
      "is_test"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "SequentialDataLoaderWrapper": {
    "__init__": [
      "self",
      "data_loaders"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "clean_string": [
    "string"
  ],
  "Tokenizer": {
    "__init__": [
      "self",
      "vocab_path",
      "special_tokens",
      "tokenizer_type"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids"
    ],
    "decode": [
      "self",
      "ids",
      "ignore_tokens"
    ]
  },
  "load_vocab": [
    "vocab_file"
  ],
  "whitespace_tokenize": [
    "text"
  ],
  "BertTokenizer": {
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "max_len",
      "do_basic_tokenize",
      "never_split"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids"
    ]
  },
  "BasicTokenizer": {
    "__init__": [
      "self",
      "do_lower_case",
      "never_split"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "_run_strip_accents": [
      "self",
      "text"
    ],
    "_run_split_on_punc": [
      "self",
      "text"
    ],
    "_tokenize_chinese_chars": [
      "self",
      "text"
    ],
    "_is_chinese_char": [
      "self",
      "cp"
    ],
    "_clean_text": [
      "self",
      "text"
    ]
  },
  "WordpieceTokenizer": {
    "__init__": [
      "self",
      "vocab",
      "unk_token",
      "max_input_chars_per_word"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "_is_whitespace": [
    "char"
  ],
  "_is_control": [
    "char"
  ],
  "_is_punctuation": [
    "char"
  ],
  "bytes_to_unicode": [],
  "get_pairs": [
    "word"
  ],
  "GPT2Tokenizer": {
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "special_tokens",
      "max_len"
    ],
    "__len__": [
      "self"
    ],
    "set_special_tokens": [
      "self",
      "special_tokens"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "tokens"
    ]
  },
  "USER_NAME": [],
  "SYSTEM_NAME": [],
  "DIALOG_ACT": [],
  "DSTProcessor": {
    "ACTS_DICT": [],
    "LABEL_MAPS": [],
    "__init__": [
      "self"
    ],
    "_convert_inputs_to_utterances": [
      "self",
      "inputs",
      "history_states"
    ],
    "_load_acts": [
      "self",
      "inputs",
      "dialog_id"
    ]
  },
  "multiwoz22Processor": {
    "__init__": [
      "self"
    ],
    "normalize_time": [
      "self",
      "text"
    ],
    "normalize_text": [
      "self",
      "text"
    ],
    "load_acts": [
      "self",
      "input_file"
    ],
    "normalize_label": [
      "self",
      "slot",
      "value_label"
    ],
    "tokenize": [
      "self",
      "utt"
    ],
    "delex_utt": [
      "self",
      "utt",
      "values",
      "unk_token"
    ],
    "get_token_pos": [
      "self",
      "tok_list",
      "value_label"
    ],
    "check_label_existence": [
      "self",
      "value_label",
      "usr_utt_tok"
    ],
    "check_slot_referral": [
      "self",
      "value_label",
      "slot",
      "seen_slots"
    ],
    "is_in_list": [
      "self",
      "tok",
      "value"
    ],
    "check_slot_inform": [
      "self",
      "value_label",
      "inform_label"
    ],
    "get_turn_label": [
      "self",
      "value_label",
      "inform_label",
      "sys_utt_tok",
      "usr_utt_tok",
      "slot",
      "seen_slots",
      "slot_last_occurrence"
    ],
    "_create_example": [
      "self",
      "utterances",
      "sys_inform_dict",
      "set_type",
      "slot_list",
      "label_maps",
      "append_history",
      "use_history_labels",
      "swap_utterances",
      "label_value_repetitions",
      "delexicalize_sys_utts",
      "unk_token",
      "analyze",
      "dialog_id"
    ],
    "create_example": [
      "self",
      "inputs",
      "history_states",
      "set_type",
      "slot_list",
      "label_maps",
      "append_history",
      "use_history_labels",
      "swap_utterances",
      "label_value_repetitions",
      "delexicalize_sys_utts",
      "unk_token",
      "analyze",
      "dialog_id"
    ],
    "create_examples": [
      "self",
      "input_file",
      "acts_file",
      "set_type",
      "slot_list",
      "label_maps",
      "append_history",
      "use_history_labels",
      "swap_utterances",
      "label_value_repetitions",
      "delexicalize_sys_utts",
      "unk_token",
      "analyze"
    ]
  },
  "DSTExample": {
    "__init__": [
      "self",
      "guid",
      "text_a",
      "text_b",
      "history",
      "text_a_label",
      "text_b_label",
      "history_label",
      "values",
      "inform_label",
      "inform_slot_label",
      "refer_label",
      "diag_state",
      "class_label"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "InputFeatures": {
    "__init__": [
      "self",
      "input_ids",
      "input_ids_unmasked",
      "input_mask",
      "segment_ids",
      "start_pos",
      "end_pos",
      "values",
      "inform",
      "inform_slot",
      "refer_id",
      "diag_state",
      "class_label_id",
      "guid"
    ]
  },
  "convert_examples_to_features": [
    "examples",
    "slot_list",
    "class_types",
    "model_type",
    "tokenizer",
    "max_seq_length",
    "slot_value_dropout"
  ],
  "convert_to_unicode": [
    "text"
  ],
  "TensorListDataset": {
    "__init__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "FILE_NAME": [],
  "intent_preprocess": [
    "path",
    "cfg"
  ],
  "DialogIntentPredictionPreprocessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "DialogStateTrackingPreprocessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "Sampler": {
    "__init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "SequentialSampler": {
    "__init__": [
      "self",
      "dataset"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "RandomSampler": {
    "__init__": [
      "self",
      "dataset"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "SortedSampler": {
    "__init__": [
      "self",
      "sampler",
      "sort_pool_size",
      "key"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "BPETextField": {
    "pad_token": [],
    "bos_token": [],
    "eos_token": [],
    "unk_token": [],
    "mask_token": [],
    "sos_u_token": [],
    "eos_u_token": [],
    "sos_b_token": [],
    "eos_b_token": [],
    "sos_db_token": [],
    "eos_db_token": [],
    "sos_a_token": [],
    "eos_a_token": [],
    "sos_r_token": [],
    "eos_r_token": [],
    "__init__": [
      "self",
      "model_dir",
      "config"
    ],
    "vocab_size": [
      "self"
    ],
    "num_specials": [
      "self"
    ],
    "pad_id": [
      "self"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "unk_id": [
      "self"
    ],
    "mask_id": [
      "self"
    ],
    "sos_u_id": [
      "self"
    ],
    "eos_u_id": [
      "self"
    ],
    "sos_b_id": [
      "self"
    ],
    "eos_b_id": [
      "self"
    ],
    "sos_db_id": [
      "self"
    ],
    "eos_db_id": [
      "self"
    ],
    "sos_a_id": [
      "self"
    ],
    "eos_a_id": [
      "self"
    ],
    "sos_r_id": [
      "self"
    ],
    "eos_r_id": [
      "self"
    ],
    "bot_id": [
      "self"
    ],
    "user_id": [
      "self"
    ],
    "add_sepcial_tokens": [
      "self"
    ],
    "filter_data_path": [
      "self",
      "data_paths"
    ],
    "load_score_matrix": [
      "self",
      "data_type",
      "data_iter"
    ],
    "random_word": [
      "self",
      "chars"
    ],
    "create_masked_lm_predictions": [
      "self",
      "sample"
    ],
    "create_span_masked_lm_predictions": [
      "self",
      "sample"
    ],
    "create_token_masked_lm_predictions": [
      "self",
      "sample"
    ],
    "numericalize": [
      "self",
      "tokens"
    ],
    "denumericalize": [
      "self",
      "numbers"
    ],
    "save_examples": [
      "self",
      "examples",
      "filename"
    ],
    "load_examples": [
      "self",
      "filename"
    ],
    "utt_filter_pred": [
      "self",
      "utt"
    ],
    "utts_filter_pred": [
      "self",
      "utts"
    ],
    "get_token_pos": [
      "self",
      "tok_list",
      "value_label"
    ],
    "build_score_matrix": [
      "self",
      "examples"
    ],
    "build_score_matrix_on_the_fly": [
      "self",
      "ids",
      "labels",
      "data_file",
      "is_post"
    ],
    "build_score_matrix_func": [
      "self",
      "examples",
      "start",
      "exclusive_end"
    ],
    "build_score_matrix_multiprocessing": [
      "self",
      "examples"
    ],
    "extract_span_texts": [
      "self",
      "text",
      "label"
    ],
    "fix_label": [
      "self",
      "label"
    ],
    "build_examples_multi_turn": [
      "self",
      "data_file",
      "data_type"
    ],
    "preprocessor": [
      "self",
      "text_list"
    ],
    "build_examples_single_turn": [
      "self",
      "data_file",
      "data_type"
    ],
    "collate_fn_multi_turn": [
      "self",
      "samples"
    ]
  },
  "IntentBPETextField": {
    "__init__": [
      "self",
      "model_dir",
      "config"
    ],
    "retrieve_examples": [
      "self",
      "dataset",
      "labels",
      "inds",
      "task",
      "num",
      "cache"
    ],
    "collate_fn_multi_turn": [
      "self",
      "samples"
    ]
  },
  "MultiWOZBPETextField": {
    "__init__": [
      "self",
      "config"
    ],
    "get_ids": [
      "self",
      "data"
    ],
    "inverse_transpose_turn": [
      "self",
      "turn_list"
    ],
    "inverse_transpose_batch": [
      "self",
      "turn_batch_list"
    ],
    "get_batches": [
      "self",
      "set_name"
    ],
    "add_sepcial_tokens": [
      "self"
    ],
    "_build_vocab": [
      "self",
      "model_dir"
    ],
    "_load_data": [
      "self",
      "data_dir",
      "save_temp"
    ],
    "_get_convert_str": [
      "self",
      "sent"
    ],
    "_get_encoded_data": [
      "self",
      "fn",
      "dial"
    ],
    "bspan_to_DBpointer": [
      "self",
      "bspan",
      "turn_domain"
    ],
    "bspan_to_constraint_dict": [
      "self",
      "bspan",
      "bspn_mode"
    ],
    "convert_batch_turn": [
      "self",
      "turn_batch",
      "pv_batch",
      "first_turn"
    ],
    "wrap_result_lm": [
      "self",
      "result_dict",
      "eos_syntax"
    ],
    "convert_turn_eval": [
      "self",
      "turn",
      "pv_turn",
      "first_turn"
    ],
    "restore": [
      "self",
      "resp",
      "domain",
      "constraint_dict",
      "mat_ents"
    ]
  },
  "ConversationalTextToSqlPreprocessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "CLAUSE_KEYWORDS": [],
  "JOIN_KEYWORDS": [],
  "WHERE_OPS": [],
  "UNIT_OPS": [],
  "AGG_OPS": [],
  "TABLE_TYPE": [],
  "COND_OPS": [],
  "SQL_OPS": [],
  "ORDER_OPS": [],
  "get_select_labels": [
    "select",
    "slot",
    "cur_nest"
  ],
  "get_groupby_labels": [
    "groupby",
    "slot",
    "cur_nest"
  ],
  "get_orderby_labels": [
    "orderby",
    "limit",
    "slot",
    "cur_nest"
  ],
  "get_intersect_labels": [
    "intersect",
    "slot",
    "cur_nest"
  ],
  "get_except_labels": [
    "texcept",
    "slot",
    "cur_nest"
  ],
  "get_union_labels": [
    "union",
    "slot",
    "cur_nest"
  ],
  "get_from_labels": [
    "tfrom",
    "slot",
    "cur_nest"
  ],
  "get_having_labels": [
    "having",
    "slot",
    "cur_nest"
  ],
  "get_where_labels": [
    "where",
    "slot",
    "cur_nest"
  ],
  "get_labels": [
    "sql_struct",
    "slot",
    "cur_nest"
  ],
  "get_label": [
    "sql",
    "column_len"
  ],
  "mwtokenizer": [],
  "quote_normalization": [
    "question"
  ],
  "SubPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "use_gpu",
      "db_content"
    ],
    "pipeline": [
      "self",
      "entry",
      "db",
      "verbose"
    ],
    "preprocess_database": [
      "self",
      "db",
      "verbose"
    ],
    "preprocess_question": [
      "self",
      "entry",
      "db",
      "verbose"
    ],
    "extract_subgraph": [
      "self",
      "entry",
      "db",
      "verbose"
    ],
    "extract_subgraph_from_sql": [
      "self",
      "sql",
      "used_schema"
    ],
    "extract_subgraph_from_conds": [
      "self",
      "conds",
      "used_schema"
    ],
    "schema_linking": [
      "self",
      "entry",
      "db",
      "verbose"
    ]
  },
  "preprocess_dataset": [
    "processor",
    "dataset",
    "output_tables",
    "database_id",
    "tables"
  ],
  "process_example": [
    "processor",
    "entry",
    "db",
    "trans",
    "verbose"
  ],
  "process_tables": [
    "processor",
    "tables_list",
    "output_path",
    "verbose"
  ],
  "process_dataset": [
    "model_dir",
    "processor",
    "dataset",
    "tables",
    "output_path",
    "skip_large",
    "verbose"
  ],
  "add_server_args": [
    "parser"
  ],
  "run_server": [
    "args"
  ],
  "get_app": [
    "args"
  ],
  "router": [],
  "inference": [
    "request",
    "body"
  ],
  "describe": [
    "request"
  ],
  "api_router": [],
  "health": [],
  "ModelScopeRequest": {
    "__init__": [
      "self",
      "input",
      "parameters"
    ]
  },
  "ResultType": [],
  "ApiResponse": {},
  "_startup_model": [
    "app"
  ],
  "_shutdown_model": [
    "app"
  ],
  "start_app_handler": [
    "app"
  ],
  "stop_app_handler": [
    "app"
  ],
  "Exporter": {
    "__init__": [
      "self",
      "model"
    ],
    "from_model": [
      "cls",
      "model"
    ],
    "export_onnx": [
      "self",
      "output_dir",
      "opset"
    ]
  },
  "TorchModelExporter": {
    "export_onnx": [
      "self",
      "output_dir",
      "opset"
    ],
    "export_torch_script": [
      "self",
      "output_dir"
    ],
    "generate_dummy_inputs": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "_decide_input_format": [
      "model",
      "args"
    ],
    "_torch_export_onnx": [
      "self",
      "model",
      "output",
      "opset",
      "device",
      "validation",
      "rtol",
      "atol"
    ],
    "_validate_onnx_model": [
      "self",
      "dummy_inputs",
      "model",
      "output",
      "onnx_outputs",
      "rtol",
      "atol"
    ],
    "_torch_export_torch_script": [
      "self",
      "model",
      "output",
      "device",
      "validation",
      "rtol",
      "atol",
      "strict"
    ],
    "_validate_torch_script_model": [
      "self",
      "dummy_inputs",
      "model",
      "output",
      "rtol",
      "atol"
    ]
  },
  "replace_call": [],
  "EXPORTERS": [],
  "build_exporter": [
    "cfg",
    "task_name",
    "default_args"
  ],
  "TfModelExporter": {
    "generate_dummy_inputs": [
      "self"
    ],
    "export_onnx": [
      "self",
      "output_dir",
      "opset"
    ],
    "export_saved_model": [
      "self",
      "output_dir"
    ],
    "export_frozen_graph_def": [
      "self",
      "output_dir"
    ],
    "_tf2_export_onnx": [
      "self",
      "model",
      "output",
      "opset",
      "validation",
      "rtol",
      "atol",
      "call_func"
    ],
    "_validate_model": [
      "self",
      "dummy_inputs",
      "model",
      "output",
      "rtol",
      "atol",
      "call_func"
    ]
  },
  "OCRRecognitionExporter": {
    "export_onnx": [
      "self",
      "output_dir",
      "opset",
      "input_shape"
    ]
  },
  "ObjectDetectionDamoyoloExporter": {
    "export_onnx": [
      "self",
      "output_dir",
      "opset",
      "input_shape"
    ]
  },
  "convert_ndarray_to_list": [
    "input_dict"
  ],
  "FaceDetectionSCRFDExporter": {
    "export_onnx": [
      "self",
      "output_dir",
      "opset",
      "simplify",
      "dynamic"
    ]
  },
  "OCRDetectionDBExporter": {
    "export_onnx": [
      "self",
      "output_dir",
      "opset",
      "input_shape"
    ]
  },
  "CartoonTranslationExporter": {
    "__init__": [
      "self",
      "model"
    ],
    "export_frozen_graph_def": [
      "self",
      "ckpt_path",
      "frozen_graph_path"
    ],
    "export_saved_model": [
      "self",
      "output_dir"
    ],
    "export_onnx": [
      "self",
      "output_dir"
    ]
  },
  "INPUT_NAME": [],
  "OUTPUT_NAME": [],
  "ANSDFSMNExporter": {
    "export_onnx": [
      "self",
      "output_dir",
      "opset"
    ]
  },
  "StableDiffusionExporter": {
    "export_onnx": [
      "self",
      "output_path",
      "opset",
      "fp16"
    ],
    "export_help": [
      "self",
      "model",
      "model_args",
      "output_path",
      "ordered_input_names",
      "output_names",
      "dynamic_axes",
      "opset",
      "use_external_data_format"
    ]
  },
  "SbertForZeroShotClassificationExporter": {
    "generate_dummy_inputs": [
      "self",
      "candidate_labels",
      "hypothesis_template",
      "max_length",
      "pair"
    ],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "CsanmtForTranslationExporter": {
    "__init__": [
      "self",
      "model"
    ],
    "generate_dummy_inputs": [
      "self"
    ],
    "export_saved_model": [
      "self",
      "output_dir",
      "rtol",
      "atol"
    ],
    "export_frozen_graph_def": [
      "self",
      "output_dir",
      "rtol",
      "atol"
    ],
    "export_onnx": [
      "self",
      "output_dir",
      "opset"
    ]
  },
  "SbertForSequenceClassificationExporter": {
    "generate_dummy_inputs": [
      "self",
      "shape",
      "pair"
    ],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "ModelForSequenceClassificationExporter": {
    "generate_dummy_inputs": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "_validate_onnx_model": [
      "self",
      "dummy_inputs",
      "model",
      "output",
      "onnx_outputs",
      "rtol",
      "atol"
    ]
  },
  "OutputKeys": {
    "LOSS": [],
    "LOGITS": [],
    "SCORES": [],
    "SCORE": [],
    "LABEL": [],
    "LABELS": [],
    "INPUT_IDS": [],
    "LABEL_POS": [],
    "POSES": [],
    "CAPTION": [],
    "BOXES": [],
    "KEYPOINTS": [],
    "MASKS": [],
    "DEPTHS": [],
    "DEPTHS_COLOR": [],
    "FLOWS": [],
    "FLOWS_COLOR": [],
    "NORMALS": [],
    "NORMALS_COLOR": [],
    "LAYOUT": [],
    "TEXT": [],
    "POLYGONS": [],
    "OUTPUT": [],
    "OUTPUT_IMG": [],
    "OUTPUT_IMGS": [],
    "OUTPUT_VIDEO": [],
    "OUTPUT_PCM": [],
    "OUTPUT_PCM_LIST": [],
    "OUTPUT_WAV": [],
    "OUTPUT_OBJ": [],
    "OUTPUT_MESH": [],
    "IMG_EMBEDDING": [],
    "SPK_EMBEDDING": [],
    "SPO_LIST": [],
    "TEXT_EMBEDDING": [],
    "TRANSLATION": [],
    "RESPONSE": [],
    "PREDICTION": [],
    "PREDICTIONS": [],
    "PROBABILITIES": [],
    "DIALOG_STATES": [],
    "VIDEO_EMBEDDING": [],
    "PHRASE_PROTOTYPE": [],
    "OBJECT_PROTOTYPE": [],
    "SENTENCE_PROTOTYPE": [],
    "EVENT_PROTOTYPE": [],
    "TEXTVIDEO_SIM": [],
    "UUID": [],
    "WORD": [],
    "KWS_LIST": [],
    "SQL_STRING": [],
    "SQL_QUERY": [],
    "HISTORY": [],
    "QUERY_RESULT": [],
    "TIMESTAMPS": [],
    "SHOT_NUM": [],
    "SCENE_NUM": [],
    "SCENE_META_LIST": [],
    "SHOT_META_LIST": [],
    "MATCHES": [],
    "PCD12": [],
    "PCD12_ALIGN": [],
    "TBOUNDS": [],
    "MV_IMGS": []
  },
  "OutputTypes": [],
  "OutputTypeSchema": [],
  "TASK_OUTPUTS": [],
  "ModelOutputBase": {
    "__post_init__": [
      "self"
    ],
    "reconstruct": [
      "self"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "__setattr__": [
      "self",
      "key",
      "value"
    ],
    "keys": [
      "self"
    ],
    "items": [
      "self"
    ],
    "to_dict": [
      "self"
    ]
  },
  "DetectionOutput": {},
  "BackboneModelOutput": {},
  "AttentionBackboneModelOutput": {},
  "Seq2SeqModelOutput": {},
  "FaqQuestionAnsweringOutput": {},
  "FeatureExtractionOutput": {},
  "FillMaskModelOutput": {},
  "AttentionFillMaskModelOutput": {},
  "InformationExtractionOutput": {},
  "Seq2SeqLMOutput": {},
  "TextClassificationModelOutput": {},
  "AttentionTextClassificationModelOutput": {},
  "TextErrorCorrectionOutput": {},
  "WordAlignmentOutput": {},
  "TextGenerationModelOutput": {},
  "AttentionTextGenerationModelOutput": {},
  "TokenGeneratorOutput": {},
  "TokenClassificationModelOutput": {},
  "AttentionTokenClassificationModelOutput": {},
  "DialogueUserSatisfactionEstimationModelOutput": {},
  "SentencEmbeddingModelOutput": {},
  "TranslationEvaluationOutput": {},
  "MachineReadingComprehensionOutput": {},
  "Accelerator": {
    "CPU": [],
    "GPU": []
  },
  "Vendor": {
    "EAS": []
  },
  "EASRegion": {
    "beijing": [],
    "hangzhou": []
  },
  "EASCpuInstanceType": {
    "tiny": [],
    "small": [],
    "medium": [],
    "large": []
  },
  "EASGpuInstanceType": {
    "tiny": [],
    "small": [],
    "medium": [],
    "large": []
  },
  "min_smaller_than_max": [
    "instance",
    "attribute",
    "value"
  ],
  "ServiceScalingConfig": {},
  "ServiceResourceConfig": {},
  "ServiceProviderParameters": {},
  "EASDeployParameters": {},
  "EASListParameters": {},
  "DeployServiceParameters": {},
  "AttrsToQueryString": {
    "to_query_str": [
      "self"
    ]
  },
  "ListServiceParameters": {},
  "GetServiceParameters": {},
  "DeleteServiceParameters": {},
  "ServiceDeployer": {
    "__init__": [
      "self",
      "endpoint",
      "token"
    ],
    "create": [
      "self",
      "model_id",
      "revision",
      "instance_name",
      "resource",
      "provider"
    ],
    "get": [
      "self",
      "instance_name",
      "provider"
    ],
    "delete": [
      "self",
      "instance_name",
      "provider"
    ],
    "list": [
      "self",
      "provider",
      "skip",
      "limit"
    ]
  },
  "NotSupportError": {},
  "NoValidRevisionError": {},
  "NotExistError": {},
  "RequestError": {},
  "GitError": {},
  "InvalidParameter": {},
  "NotLoginException": {},
  "FileIntegrityError": {},
  "FileDownloadError": {},
  "CacheNotFound": {
    "__init__": [
      "self",
      "msg",
      "cache_dir"
    ]
  },
  "CorruptedCacheException": {},
  "get_request_id": [
    "response"
  ],
  "is_ok": [
    "rsp"
  ],
  "_decode_response_error": [
    "response"
  ],
  "handle_http_post_error": [
    "response",
    "url",
    "request_body"
  ],
  "handle_http_response": [
    "response",
    "logger",
    "cookies",
    "model_id",
    "raise_on_error"
  ],
  "raise_on_error": [
    "rsp"
  ],
  "datahub_raise_on_error": [
    "url",
    "rsp",
    "http_response"
  ],
  "raise_for_http_status": [
    "rsp"
  ],
  "get_model_id_from_cache": [
    "model_root_path"
  ],
  "check_local_model_is_latest": [
    "model_root_path",
    "user_agent",
    "token"
  ],
  "check_model_is_id": [
    "model_id",
    "token"
  ],
  "_parse_siblings": [
    "siblings_data"
  ],
  "OrganizationInfo": {
    "__init__": [
      "self"
    ]
  },
  "BlobLfsInfo": {},
  "RepoSibling": {},
  "ModelInfo": {
    "__init__": [
      "self"
    ]
  },
  "DatasetInfo": {
    "__init__": [
      "self"
    ]
  },
  "FILES_TO_IGNORE": [],
  "CachedFileInfo": {
    "blob_last_accessed_str": [
      "self"
    ],
    "blob_last_modified_str": [
      "self"
    ],
    "size_on_disk_str": [
      "self"
    ]
  },
  "CachedRevisionInfo": {
    "last_modified_str": [
      "self"
    ],
    "size_on_disk_str": [
      "self"
    ],
    "nb_files": [
      "self"
    ]
  },
  "CachedRepoInfo": {
    "last_accessed_str": [
      "self"
    ],
    "last_modified_str": [
      "self"
    ],
    "size_on_disk_str": [
      "self"
    ]
  },
  "ModelScopeCacheInfo": {
    "size_on_disk_str": [
      "self"
    ],
    "export_as_table": [
      "self"
    ]
  },
  "scan_cache_dir": [
    "cache_dir"
  ],
  "_is_valid_dir": [
    "dir"
  ],
  "_scan_dir": [
    "dir",
    "repo_type",
    "inplace"
  ],
  "_scan_cached_repo": [
    "repo_path",
    "repo_type"
  ],
  "snapshot_download": [
    "model_id",
    "revision",
    "cache_dir",
    "user_agent",
    "local_files_only",
    "cookies",
    "ignore_file_pattern",
    "allow_file_pattern",
    "local_dir",
    "allow_patterns",
    "ignore_patterns",
    "max_workers",
    "repo_id",
    "repo_type",
    "enable_file_lock",
    "progress_callbacks",
    "token"
  ],
  "dataset_snapshot_download": [
    "dataset_id",
    "revision",
    "cache_dir",
    "local_dir",
    "user_agent",
    "local_files_only",
    "cookies",
    "ignore_file_pattern",
    "allow_file_pattern",
    "allow_patterns",
    "ignore_patterns",
    "enable_file_lock",
    "max_workers",
    "token"
  ],
  "_snapshot_download": [
    "repo_id"
  ],
  "fetch_repo_files": [
    "_api",
    "repo_id",
    "revision",
    "endpoint"
  ],
  "_is_valid_regex": [
    "pattern"
  ],
  "_normalize_patterns": [
    "patterns"
  ],
  "_get_valid_regex_pattern": [
    "patterns"
  ],
  "_download_file_lists": [
    "repo_files",
    "cache",
    "temporary_cache_dir",
    "repo_id",
    "api",
    "name",
    "group_or_owner",
    "headers",
    "repo_type",
    "revision",
    "cookies",
    "ignore_file_pattern",
    "allow_file_pattern",
    "allow_patterns",
    "ignore_patterns",
    "max_workers",
    "endpoint",
    "progress_callbacks"
  ],
  "Singleton": {
    "_instances": [],
    "__call__": [
      "cls"
    ]
  },
  "GitCommandWrapper": {
    "default_git_path": [],
    "__init__": [
      "self",
      "path"
    ],
    "_run_git_command": [
      "self"
    ],
    "config_auth_token": [
      "self",
      "repo_dir",
      "auth_token"
    ],
    "_add_token": [
      "self",
      "token",
      "url"
    ],
    "remove_token_from_url": [
      "self",
      "url"
    ],
    "is_lfs_installed": [
      "self"
    ],
    "git_lfs_install": [
      "self",
      "repo_dir"
    ],
    "clone": [
      "self",
      "repo_base_dir",
      "token",
      "url",
      "repo_name",
      "branch"
    ],
    "add_user_info": [
      "self",
      "repo_base_dir",
      "repo_name"
    ],
    "add": [
      "self",
      "repo_dir",
      "files",
      "all_files"
    ],
    "commit": [
      "self",
      "repo_dir",
      "message"
    ],
    "checkout": [
      "self",
      "repo_dir",
      "revision"
    ],
    "new_branch": [
      "self",
      "repo_dir",
      "revision"
    ],
    "get_remote_branches": [
      "self",
      "repo_dir"
    ],
    "pull": [
      "self",
      "repo_dir",
      "remote",
      "branch"
    ],
    "push": [
      "self",
      "repo_dir",
      "token",
      "url",
      "local_branch",
      "remote_branch",
      "force"
    ],
    "get_repo_remote_url": [
      "self",
      "repo_dir"
    ],
    "list_lfs_files": [
      "self",
      "repo_dir"
    ],
    "tag": [
      "self",
      "repo_dir",
      "tag_name",
      "message",
      "ref"
    ],
    "push_tag": [
      "self",
      "repo_dir",
      "tag_name"
    ]
  },
  "model_file_download": [
    "model_id",
    "file_path",
    "revision",
    "cache_dir",
    "user_agent",
    "local_files_only",
    "cookies",
    "local_dir",
    "token"
  ],
  "dataset_file_download": [
    "dataset_id",
    "file_path",
    "revision",
    "cache_dir",
    "local_dir",
    "user_agent",
    "local_files_only",
    "cookies",
    "token"
  ],
  "_repo_file_download": [
    "repo_id",
    "file_path"
  ],
  "move_legacy_cache_to_standard_dir": [
    "cache_dir",
    "model_id"
  ],
  "create_temporary_directory_and_cache": [
    "model_id",
    "local_dir",
    "cache_dir",
    "repo_type"
  ],
  "get_file_download_url": [
    "model_id",
    "file_path",
    "revision",
    "endpoint"
  ],
  "download_part_with_retry": [
    "params"
  ],
  "parallel_download": [
    "url",
    "local_dir",
    "file_name",
    "cookies",
    "headers",
    "file_size",
    "disable_tqdm",
    "progress_callbacks",
    "endpoint"
  ],
  "http_get_model_file": [
    "url",
    "local_dir",
    "file_name",
    "file_size",
    "cookies",
    "headers",
    "disable_tqdm",
    "progress_callbacks"
  ],
  "http_get_file": [
    "url",
    "local_dir",
    "file_name",
    "cookies",
    "headers"
  ],
  "download_file": [
    "url",
    "file_meta",
    "temporary_cache_dir",
    "cache",
    "headers",
    "cookies",
    "disable_tqdm",
    "progress_callbacks"
  ],
  "HubApi": {
    "__init__": [
      "self",
      "endpoint",
      "timeout",
      "max_retries",
      "token"
    ],
    "_get_cookies": [
      "self",
      "access_token"
    ],
    "get_cookies": [
      "self",
      "access_token",
      "cookies_required"
    ],
    "login": [
      "self",
      "access_token",
      "endpoint"
    ],
    "create_model": [
      "self",
      "model_id",
      "visibility",
      "license",
      "chinese_name",
      "original_model_id",
      "endpoint",
      "token",
      "aigc_model"
    ],
    "create_model_tag": [
      "self",
      "model_id",
      "tag_name",
      "endpoint",
      "token",
      "aigc_model"
    ],
    "delete_model": [
      "self",
      "model_id",
      "endpoint",
      "token"
    ],
    "get_model_url": [
      "self",
      "model_id",
      "endpoint"
    ],
    "get_model": [
      "self",
      "model_id",
      "revision",
      "endpoint",
      "token"
    ],
    "get_endpoint_for_read": [
      "self",
      "repo_id"
    ],
    "model_info": [
      "self",
      "repo_id"
    ],
    "dataset_info": [
      "self",
      "repo_id"
    ],
    "repo_info": [
      "self",
      "repo_id"
    ],
    "repo_exists": [
      "self",
      "repo_id"
    ],
    "delete_repo": [
      "self",
      "repo_id",
      "repo_type",
      "endpoint",
      "token"
    ],
    "_create_default_config": [
      "model_dir"
    ],
    "push_model": [
      "self",
      "model_id",
      "model_dir",
      "visibility",
      "license",
      "chinese_name",
      "commit_message",
      "tag",
      "revision",
      "original_model_id",
      "ignore_file_pattern",
      "lfs_suffix",
      "token"
    ],
    "list_models": [
      "self",
      "owner_or_group",
      "page_number",
      "page_size",
      "endpoint",
      "token"
    ],
    "list_datasets": [
      "self",
      "owner_or_group"
    ],
    "_check_cookie": [
      "self",
      "use_cookies"
    ],
    "list_model_revisions": [
      "self",
      "model_id",
      "cutoff_timestamp",
      "use_cookies"
    ],
    "list_model_revisions_detail": [
      "self",
      "model_id",
      "cutoff_timestamp",
      "use_cookies",
      "endpoint"
    ],
    "get_branch_tag_detail": [
      "self",
      "details",
      "name"
    ],
    "get_valid_revision_detail": [
      "self",
      "model_id",
      "revision",
      "cookies",
      "endpoint"
    ],
    "get_valid_revision": [
      "self",
      "model_id",
      "revision",
      "cookies",
      "endpoint"
    ],
    "get_model_branches_and_tags_details": [
      "self",
      "model_id",
      "use_cookies",
      "endpoint"
    ],
    "get_model_branches_and_tags": [
      "self",
      "model_id",
      "use_cookies"
    ],
    "get_model_files": [
      "self",
      "model_id",
      "revision",
      "root",
      "recursive",
      "use_cookies",
      "headers",
      "endpoint"
    ],
    "file_exists": [
      "self",
      "repo_id",
      "filename"
    ],
    "create_dataset": [
      "self",
      "dataset_name",
      "namespace",
      "chinese_name",
      "license",
      "visibility",
      "description",
      "endpoint",
      "token"
    ],
    "delete_dataset": [
      "self",
      "dataset_id",
      "endpoint",
      "token"
    ],
    "get_dataset_id_and_type": [
      "self",
      "dataset_name",
      "namespace",
      "endpoint",
      "token"
    ],
    "list_repo_tree": [
      "self",
      "dataset_name",
      "namespace",
      "revision",
      "root_path",
      "recursive",
      "page_number",
      "page_size",
      "endpoint",
      "token"
    ],
    "list_repo_commits": [
      "self",
      "repo_id"
    ],
    "get_dataset_files": [
      "self",
      "repo_id"
    ],
    "get_dataset": [
      "self",
      "dataset_id",
      "revision",
      "endpoint",
      "token"
    ],
    "get_dataset_meta_file_list": [
      "self",
      "dataset_name",
      "namespace",
      "dataset_id",
      "revision",
      "endpoint",
      "token"
    ],
    "dump_datatype_file": [
      "dataset_type",
      "meta_cache_dir"
    ],
    "get_dataset_meta_files_local_paths": [
      "self",
      "dataset_name",
      "namespace",
      "revision",
      "meta_cache_dir",
      "dataset_type",
      "file_list",
      "endpoint",
      "token"
    ],
    "fetch_meta_files_from_url": [
      "url",
      "out_path",
      "chunk_size",
      "mode",
      "token"
    ],
    "get_dataset_file_url": [
      "self",
      "file_name",
      "dataset_name",
      "namespace",
      "revision",
      "view",
      "extension_filter",
      "endpoint"
    ],
    "get_dataset_file_url_origin": [
      "self",
      "file_name",
      "dataset_name",
      "namespace",
      "revision",
      "endpoint"
    ],
    "get_dataset_access_config": [
      "self",
      "dataset_name",
      "namespace",
      "revision",
      "endpoint",
      "token"
    ],
    "get_dataset_access_config_session": [
      "self",
      "dataset_name",
      "namespace",
      "check_cookie",
      "revision",
      "endpoint",
      "token"
    ],
    "get_virgo_meta": [
      "self",
      "dataset_id",
      "version",
      "token"
    ],
    "get_dataset_access_config_for_unzipped": [
      "self",
      "dataset_name",
      "namespace",
      "revision",
      "zip_file_name",
      "endpoint",
      "token"
    ],
    "list_oss_dataset_objects": [
      "self",
      "dataset_name",
      "namespace",
      "max_limit",
      "is_recursive",
      "is_filter_dir",
      "revision",
      "endpoint",
      "token"
    ],
    "delete_oss_dataset_object": [
      "self",
      "object_name",
      "dataset_name",
      "namespace",
      "revision",
      "endpoint",
      "token"
    ],
    "delete_oss_dataset_dir": [
      "self",
      "object_name",
      "dataset_name",
      "namespace",
      "revision",
      "endpoint",
      "token"
    ],
    "datahub_remote_call": [
      "self",
      "url",
      "token"
    ],
    "dataset_download_statistics": [
      "self",
      "dataset_name",
      "namespace",
      "use_streaming",
      "endpoint",
      "token"
    ],
    "builder_headers": [
      "self",
      "headers"
    ],
    "get_file_base_path": [
      "self",
      "repo_id",
      "endpoint"
    ],
    "create_repo": [
      "self",
      "repo_id"
    ],
    "create_commit": [
      "self",
      "repo_id",
      "operations"
    ],
    "upload_file": [
      "self"
    ],
    "upload_folder": [
      "self"
    ],
    "_upload_blob": [
      "self"
    ],
    "_validate_blob": [
      "self"
    ],
    "_prepare_upload_folder": [
      "self",
      "folder_path_or_files",
      "path_in_repo",
      "allow_patterns",
      "ignore_patterns"
    ],
    "_prepare_commit_payload": [
      "operations",
      "commit_message"
    ],
    "_get_internal_acceleration_domain": [
      "self",
      "internal_timeout"
    ],
    "delete_files": [
      "self",
      "repo_id",
      "repo_type",
      "delete_patterns"
    ],
    "set_repo_visibility": [
      "self",
      "repo_id",
      "repo_type",
      "visibility",
      "token"
    ]
  },
  "ModelScopeConfig": {
    "path_credential": [],
    "COOKIES_FILE_NAME": [],
    "GIT_TOKEN_FILE_NAME": [],
    "USER_INFO_FILE_NAME": [],
    "USER_SESSION_ID_FILE_NAME": [],
    "cookie_expired_warning": [],
    "make_sure_credential_path_exist": [],
    "save_cookies": [
      "cookies"
    ],
    "get_cookies": [],
    "get_user_session_id": [],
    "save_token": [
      "token"
    ],
    "save_user_info": [
      "user_name",
      "user_email"
    ],
    "get_user_info": [],
    "get_token": [],
    "get_user_agent": [
      "user_agent"
    ]
  },
  "UploadingCheck": {
    "__init__": [
      "self",
      "max_file_count",
      "max_file_count_in_dir",
      "max_file_size",
      "size_threshold_to_enforce_lfs",
      "normal_file_size_total_limit"
    ],
    "check_file": [
      "self",
      "file_path_or_obj"
    ],
    "check_folder": [
      "self",
      "folder_path"
    ],
    "is_lfs": [
      "self",
      "file_path_or_obj",
      "repo_type"
    ],
    "check_normal_files": [
      "self",
      "file_path_list",
      "repo_type"
    ]
  },
  "ProgressCallback": {
    "__init__": [
      "self",
      "filename",
      "file_size"
    ],
    "update": [
      "self",
      "size"
    ],
    "end": [
      "self"
    ]
  },
  "TqdmCallback": {
    "__init__": [
      "self",
      "filename",
      "file_size"
    ],
    "update": [
      "self",
      "size"
    ],
    "end": [
      "self"
    ]
  },
  "IGNORE_GIT_FOLDER_PATTERNS": [],
  "patch_upload_folder_for_scheduler": [
    "scheduler_instance"
  ],
  "CommitScheduler": {
    "__init__": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "_run_scheduler": [
      "self"
    ],
    "trigger": [
      "self"
    ],
    "_commit_scheduled_changes": [
      "self"
    ],
    "commit_scheduled_changes": [
      "self"
    ]
  },
  "PartialFileIO": {
    "__init__": [
      "self",
      "file_path",
      "size_limit"
    ],
    "open": [
      "self"
    ],
    "close": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getattribute__": [
      "self",
      "name"
    ],
    "tell": [
      "self"
    ],
    "seek": [
      "self",
      "__offset",
      "__whence"
    ],
    "read": [
      "self",
      "__size"
    ]
  },
  "_executor": [],
  "_queues": [],
  "_flags": [],
  "_tasks": [],
  "_manager": [],
  "_push_files_to_hub": [
    "path_or_fileobj",
    "path_in_repo",
    "repo_id",
    "token",
    "revision",
    "commit_message",
    "commit_description"
  ],
  "_api_push_to_hub": [
    "repo_name",
    "output_dir",
    "token",
    "private",
    "commit_message",
    "tag",
    "source_repo",
    "ignore_file_pattern",
    "revision"
  ],
  "push_to_hub": [
    "repo_name",
    "output_dir",
    "token",
    "private",
    "retry",
    "commit_message",
    "tag",
    "source_repo",
    "ignore_file_pattern",
    "revision"
  ],
  "push_to_hub_async": [
    "repo_name",
    "output_dir",
    "token",
    "private",
    "commit_message",
    "tag",
    "source_repo",
    "ignore_file_pattern",
    "revision"
  ],
  "submit_task": [
    "q",
    "b"
  ],
  "UploadStrategy": {
    "cancel": [],
    "wait": []
  },
  "push_to_hub_in_queue": [
    "queue_name",
    "strategy"
  ],
  "wait_for_done": [
    "queue_name"
  ],
  "MCP_API_PATH": [],
  "MCPApiError": {},
  "MCPApiRequestError": {},
  "MCPApiResponseError": {},
  "MCPApi": {
    "__init__": [
      "self",
      "endpoint"
    ],
    "_handle_response": [
      "r"
    ],
    "_get_server_name_from_id": [
      "server_id"
    ],
    "list_mcp_servers": [
      "self",
      "token",
      "filter",
      "total_count",
      "search"
    ],
    "list_operational_mcp_servers": [
      "self",
      "token"
    ],
    "get_mcp_server": [
      "self",
      "server_id",
      "token"
    ]
  },
  "MODELSCOPE_URL_SCHEME": [],
  "DEFAULT_MODELSCOPE_DOMAIN": [],
  "DEFAULT_MODELSCOPE_INTL_DOMAIN": [],
  "DEFAULT_MODELSCOPE_DATA_ENDPOINT": [],
  "DEFAULT_MODELSCOPE_INTL_DATA_ENDPOINT": [],
  "MODELSCOPE_PARALLEL_DOWNLOAD_THRESHOLD_MB": [],
  "MODELSCOPE_DOWNLOAD_PARALLELS": [],
  "DEFAULT_MODELSCOPE_GROUP": [],
  "MODEL_ID_SEPARATOR": [],
  "FILE_HASH": [],
  "LOGGER_NAME": [],
  "DEFAULT_CREDENTIALS_PATH": [],
  "MODELSCOPE_CREDENTIALS_PATH": [],
  "REQUESTS_API_HTTP_METHOD": [],
  "API_HTTP_CLIENT_TIMEOUT": [],
  "API_HTTP_CLIENT_MAX_RETRIES": [],
  "API_RESPONSE_FIELD_DATA": [],
  "API_FILE_DOWNLOAD_RETRY_TIMES": [],
  "API_FILE_DOWNLOAD_TIMEOUT": [],
  "API_FILE_DOWNLOAD_CHUNK_SIZE": [],
  "API_RESPONSE_FIELD_GIT_ACCESS_TOKEN": [],
  "API_RESPONSE_FIELD_USERNAME": [],
  "API_RESPONSE_FIELD_EMAIL": [],
  "API_RESPONSE_FIELD_MESSAGE": [],
  "MODELSCOPE_CLOUD_ENVIRONMENT": [],
  "MODELSCOPE_CLOUD_USERNAME": [],
  "MODELSCOPE_SDK_DEBUG": [],
  "MODELSCOPE_PREFER_AI_SITE": [],
  "MODELSCOPE_DOMAIN": [],
  "MODELSCOPE_ENABLE_DEFAULT_HASH_VALIDATION": [],
  "ONE_YEAR_SECONDS": [],
  "MODELSCOPE_REQUEST_ID": [],
  "TEMPORARY_FOLDER_NAME": [],
  "DEFAULT_MAX_WORKERS": [],
  "UPLOAD_MAX_FILE_SIZE": [],
  "UPLOAD_SIZE_THRESHOLD_TO_ENFORCE_LFS": [],
  "UPLOAD_MAX_FILE_COUNT": [],
  "UPLOAD_MAX_FILE_COUNT_IN_DIR": [],
  "UPLOAD_NORMAL_FILE_SIZE_TOTAL_LIMIT": [],
  "UPLOAD_COMMIT_BATCH_SIZE": [],
  "UPLOAD_BLOB_TQDM_DISABLE_THRESHOLD": [],
  "MODELSCOPE_ASCII": [],
  "Licenses": {
    "APACHE_V2": [],
    "GPL_V2": [],
    "GPL_V3": [],
    "LGPL_V2_1": [],
    "LGPL_V3": [],
    "AFL_V3": [],
    "ECL_V2": [],
    "MIT": [],
    "to_list": [
      "cls"
    ]
  },
  "ModelVisibility": {
    "PRIVATE": [],
    "INTERNAL": [],
    "PUBLIC": []
  },
  "DatasetVisibility": {
    "PRIVATE": [],
    "INTERNAL": [],
    "PUBLIC": []
  },
  "Visibility": {
    "PRIVATE": [],
    "INTERNAL": [],
    "PUBLIC": []
  },
  "VisibilityMap": [],
  "SortKey": {
    "DEFAULT": [],
    "DOWNLOADS": [],
    "LIKES": [],
    "LAST_MODIFIED": []
  },
  "VALID_SORT_KEYS": [],
  "Repository": {
    "__init__": [
      "self",
      "model_dir",
      "clone_from",
      "revision",
      "auth_token",
      "git_path"
    ],
    "_get_model_id_url": [
      "self",
      "model_id"
    ],
    "_get_remote_url": [
      "self"
    ],
    "pull": [
      "self",
      "remote",
      "branch"
    ],
    "add_lfs_type": [
      "self",
      "file_name_suffix"
    ],
    "push": [
      "self",
      "commit_message",
      "local_branch",
      "remote_branch",
      "force"
    ],
    "tag": [
      "self",
      "tag_name",
      "message",
      "ref"
    ],
    "tag_and_push": [
      "self",
      "tag_name",
      "message",
      "ref"
    ]
  },
  "DatasetRepository": {
    "__init__": [
      "self",
      "repo_work_dir",
      "dataset_id",
      "revision",
      "auth_token",
      "git_path"
    ],
    "clone": [
      "self"
    ],
    "push": [
      "self",
      "commit_message",
      "branch",
      "force"
    ],
    "_get_repo_url": [
      "self",
      "dataset_id"
    ],
    "_get_remote_url": [
      "self"
    ]
  },
  "DEFAULT_AIGC_COVER_IMAGE": [],
  "AigcModel": {
    "AIGC_TYPES": [],
    "BASE_MODEL_TYPES": [],
    "OFFICIAL_TAGS": [],
    "__init__": [
      "self",
      "aigc_type",
      "base_model_type",
      "model_path",
      "base_model_id",
      "tag",
      "description",
      "cover_images",
      "path_in_repo",
      "trigger_words",
      "official_tags",
      "model_source",
      "base_model_sub_type"
    ],
    "_validate_aigc_type": [
      "self"
    ],
    "_validate_base_model_type": [
      "self"
    ],
    "_validate_official_tags": [
      "self"
    ],
    "_process_model_path": [
      "self"
    ],
    "upload_to_repo": [
      "self",
      "api",
      "model_id",
      "token"
    ],
    "preupload_weights": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "from_json_file": [
      "cls",
      "json_path"
    ]
  },
  "model_id_to_group_owner_name": [
    "model_id"
  ],
  "is_env_true": [
    "var_name"
  ],
  "get_domain": [
    "cn_site"
  ],
  "convert_patterns": [
    "raw_input"
  ],
  "get_model_masked_directory": [
    "directory",
    "model_id"
  ],
  "convert_readable_size": [
    "size_bytes"
  ],
  "get_folder_size": [
    "folder_path"
  ],
  "get_readable_folder_size": [
    "folder_path"
  ],
  "get_cache_dir": [
    "model_id"
  ],
  "get_release_datetime": [],
  "get_endpoint": [
    "cn_site"
  ],
  "compute_hash": [
    "file_path"
  ],
  "file_integrity_validation": [
    "file_path",
    "expected_sha256"
  ],
  "add_content_to_file": [
    "repo",
    "file_name",
    "patterns",
    "commit_message",
    "ignore_push_error"
  ],
  "_TIMESINCE_CHUNKS": [],
  "format_timesince": [
    "ts"
  ],
  "tabulate": [
    "rows",
    "headers"
  ],
  "strtobool": [
    "val"
  ],
  "weak_file_lock": [
    "lock_file"
  ],
  "convert_timestamp": [
    "time_stamp",
    "time_zone"
  ],
  "encode_media_to_base64": [
    "media_file_path"
  ],
  "enable_default_hash_validation": [],
  "FileSystemCache": {
    "KEY_FILE_NAME": [],
    "MODEL_META_FILE_NAME": [],
    "MODEL_META_MODEL_ID": [],
    "MODEL_VERSION_FILE_NAME": [],
    "__init__": [
      "self",
      "cache_root_location"
    ],
    "get_root_location": [
      "self"
    ],
    "load_cache": [
      "self"
    ],
    "save_cached_files": [
      "self"
    ],
    "get_file": [
      "self",
      "key"
    ],
    "put_file": [
      "self",
      "key",
      "location"
    ],
    "remove_key": [
      "self",
      "key"
    ],
    "exists": [
      "self",
      "key"
    ],
    "clear_cache": [
      "self"
    ],
    "hash_name": [
      "self",
      "key"
    ]
  },
  "ModelFileSystemCache": {
    "__init__": [
      "self",
      "cache_root",
      "owner",
      "name"
    ],
    "load_model_meta": [
      "self"
    ],
    "load_model_version": [
      "self"
    ],
    "save_model_version": [
      "self",
      "revision_info"
    ],
    "get_model_id": [
      "self"
    ],
    "save_model_meta": [
      "self"
    ],
    "get_file_by_path": [
      "self",
      "file_path"
    ],
    "get_file_by_path_and_commit_id": [
      "self",
      "file_path",
      "commit_id"
    ],
    "get_file_by_info": [
      "self",
      "model_file_info"
    ],
    "__get_cache_key": [
      "self",
      "model_file_info"
    ],
    "exists": [
      "self",
      "model_file_info"
    ],
    "remove_if_exists": [
      "self",
      "model_file_info"
    ],
    "put_file": [
      "self",
      "model_file_info",
      "model_file_location"
    ]
  },
  "format_list": [
    "para"
  ],
  "MsDataset": {
    "_hf_ds": [],
    "__init__": [
      "self",
      "ds_instance",
      "target"
    ],
    "__iter__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__len__": [
      "self"
    ],
    "ds_instance": [
      "self"
    ],
    "config_kwargs": [
      "self"
    ],
    "from_hf_dataset": [
      "cls",
      "hf_ds",
      "target"
    ],
    "to_ms_dataset": [
      "cls",
      "ds_instance",
      "target"
    ],
    "load": [
      "dataset_name",
      "namespace",
      "target",
      "version",
      "hub",
      "subset_name",
      "split",
      "data_dir",
      "data_files",
      "download_mode",
      "cache_dir",
      "features",
      "use_streaming",
      "stream_batch_size",
      "custom_cfg",
      "token",
      "dataset_info_only",
      "trust_remote_code"
    ],
    "upload": [
      "object_name",
      "local_file_path",
      "dataset_name",
      "namespace",
      "version",
      "num_processes",
      "chunksize",
      "filter_hidden_files",
      "upload_mode"
    ],
    "clone_meta": [
      "dataset_work_dir",
      "dataset_id",
      "revision",
      "auth_token",
      "git_path"
    ],
    "upload_meta": [
      "dataset_work_dir",
      "commit_message",
      "revision",
      "auth_token",
      "git_path",
      "force"
    ],
    "delete": [
      "object_name",
      "dataset_name",
      "namespace",
      "version"
    ],
    "to_torch_dataset": [
      "self",
      "columns",
      "preprocessors",
      "task_name",
      "data_config",
      "to_tensor"
    ],
    "to_tf_dataset": [
      "self",
      "batch_size",
      "shuffle",
      "preprocessors",
      "columns",
      "collate_fn",
      "drop_remainder",
      "collate_fn_args",
      "label_cols",
      "prefetch"
    ],
    "to_hf_dataset": [
      "self"
    ],
    "remap_columns": [
      "self",
      "column_mapping"
    ],
    "_to_torch_dataset_with_processors": [
      "self",
      "preprocessors",
      "columns",
      "to_tensor"
    ],
    "_to_tf_dataset_with_processors": [
      "self",
      "batch_size",
      "shuffle",
      "preprocessors",
      "drop_remainder",
      "prefetch",
      "label_cols",
      "columns"
    ],
    "to_custom_dataset": [
      "self",
      "custom_cfg",
      "preprocessor",
      "mode"
    ]
  },
  "DatasetContextConfig": {
    "__init__": [
      "self",
      "dataset_name",
      "namespace",
      "version",
      "subset_name",
      "split",
      "target",
      "hub",
      "data_dir",
      "data_files",
      "download_mode",
      "cache_root_dir",
      "use_streaming",
      "stream_batch_size",
      "trust_remote_code",
      "token"
    ],
    "config_kwargs": [
      "self",
      "val"
    ],
    "download_config": [
      "self",
      "val"
    ],
    "data_meta_config": [
      "self",
      "val"
    ],
    "dataset_version_cache_root_dir": [
      "self",
      "val"
    ],
    "global_meta_lock_file_path": [
      "self",
      "val"
    ],
    "global_data_lock_file_path": [
      "self",
      "val"
    ],
    "auth_config": [
      "self",
      "val"
    ]
  },
  "BaseAuthConfig": {
    "__init__": [
      "self",
      "cookies",
      "git_token",
      "user_info"
    ]
  },
  "OssAuthConfig": {
    "__init__": [
      "self",
      "cookies",
      "git_token",
      "user_info"
    ]
  },
  "VirgoAuthConfig": {
    "__init__": [
      "self",
      "cookies",
      "git_token",
      "user_info"
    ]
  },
  "MaxComputeAuthConfig": {
    "__init__": [
      "self",
      "cookies",
      "git_token",
      "user_info"
    ]
  },
  "DataDownloadManager": {
    "__init__": [
      "self",
      "download_config"
    ],
    "_download": [
      "self",
      "url_or_filename",
      "download_config"
    ],
    "_download_single": [
      "self",
      "url_or_filename",
      "download_config"
    ]
  },
  "DataStreamingDownloadManager": {
    "__init__": [
      "self",
      "download_config"
    ],
    "_download": [
      "self",
      "url_or_filename"
    ],
    "_download_single": [
      "self",
      "url_or_filename"
    ]
  },
  "DELIMITER_NAME": [],
  "DEFAULT_CSV_DELIMITER": [],
  "CsvDatasetBuilder": {
    "__init__": [
      "self",
      "dataset_context_config"
    ],
    "_build_cache_dir": [
      "self",
      "namespace"
    ],
    "_relative_data_dir": [
      "self",
      "with_version",
      "with_hash",
      "namespace"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_tables": [
      "self",
      "files",
      "base_dir"
    ],
    "download_and_prepare": [
      "self",
      "download_mode",
      "dl_manager"
    ],
    "_download_and_prepare": [
      "self",
      "dl_manager",
      "download_mode"
    ],
    "_convert_csv_to_dataset": [
      "self",
      "split_name",
      "csv_file_path"
    ],
    "as_dataset": [
      "self"
    ]
  },
  "TaskSpecificDatasetBuilder": {
    "__init__": [
      "self",
      "dataset_context_config"
    ],
    "download_and_prepare": [
      "self",
      "download_mode",
      "dl_manager"
    ],
    "_download_and_prepare": [
      "self",
      "dl_manager"
    ],
    "as_dataset": [
      "self"
    ]
  },
  "IterableDatasetBuilder": {
    "__init__": [
      "self",
      "dataset_context_config"
    ],
    "get_builder_instance": [
      "dataset_context_config"
    ],
    "as_streaming_dataset": [
      "self",
      "dl_manager"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_as_streaming_dataset_single": [
      "self",
      "splits_generator"
    ],
    "_generate_tables": [
      "self"
    ],
    "_get_meta_csv_df": [
      "self",
      "meta_file_url"
    ],
    "trans_data_to_mapping": [
      "headers",
      "texts",
      "delimiter"
    ]
  },
  "DataDownloadConfig": {
    "copy": [
      "self"
    ]
  },
  "DataMetaManager": {
    "__init__": [
      "self",
      "dataset_context_config"
    ],
    "fetch_meta_files": [
      "self"
    ],
    "parse_dataset_structure": [
      "self"
    ],
    "fetch_virgo_meta": [
      "self"
    ],
    "_fetch_meta_from_cache": [
      "self",
      "meta_cache_dir"
    ],
    "_fetch_meta_from_hub": [
      "self",
      "dataset_name",
      "namespace",
      "revision",
      "meta_cache_dir"
    ]
  },
  "DataMetaConfig": {
    "__init__": [
      "self"
    ]
  },
  "ExternalDataset": {
    "__init__": [
      "self",
      "split_path_dict",
      "config_kwargs"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "__iter__": [
      "self"
    ]
  },
  "NativeIterableDataset": {
    "__init__": [
      "self",
      "ex_iterable",
      "info",
      "split",
      "stream_batch_size"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_download_item": [
      "self",
      "item"
    ],
    "head": [
      "self",
      "n"
    ]
  },
  "VirgoDataset": {
    "__init__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "meta": [
      "self"
    ],
    "_parse_meta": [
      "self"
    ],
    "_get_odps_info": [],
    "_check_variables": [
      "self"
    ]
  },
  "DATASET_STRUCTURE": [],
  "ImageInstanceSegmentationCocoDataset": {
    "CLASSES": [],
    "__init__": [
      "self",
      "split_config",
      "preprocessor",
      "classes",
      "seg_prefix",
      "folder_name",
      "ann_file",
      "img_prefix",
      "test_mode",
      "filter_empty_gt"
    ],
    "__len__": [
      "self"
    ],
    "load_annotations": [
      "self",
      "ann_file"
    ],
    "get_ann_info": [
      "self",
      "idx"
    ],
    "get_cat_ids": [
      "self",
      "idx"
    ],
    "pre_pipeline": [
      "self",
      "results"
    ],
    "_filter_imgs": [
      "self",
      "min_size"
    ],
    "_parse_ann_info": [
      "self",
      "img_info",
      "ann_info"
    ],
    "_set_group_flag": [
      "self"
    ],
    "_rand_another": [
      "self",
      "idx"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "prepare_train_img": [
      "self",
      "idx"
    ],
    "prepare_test_img": [
      "self",
      "idx"
    ],
    "get_classes": [
      "cls",
      "classes"
    ]
  },
  "VecoDataset": {
    "__init__": [
      "self",
      "datasets",
      "mode",
      "preprocessor"
    ],
    "switch_dataset": [
      "self",
      "idx"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "prepare_dataset": [
      "self",
      "datasets"
    ]
  },
  "VideoSummarizationDataset": {
    "__init__": [
      "self",
      "mode",
      "opt",
      "root_dir"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "EasyCVBaseDataset": {
    "DATA_ROOT_PATTERN": [],
    "__init__": [
      "self",
      "split_config",
      "preprocessor",
      "mode",
      "args",
      "kwargs"
    ],
    "_update_data_root": [
      "self",
      "input_dict",
      "data_root"
    ],
    "_update_data_source": [
      "self",
      "data_source"
    ]
  },
  "MGeoRankingDataset": {
    "__init__": [
      "self",
      "datasets",
      "mode",
      "preprocessor"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__get_test_item__": [
      "self",
      "index"
    ],
    "__get_train_item__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "prepare_dataset": [
      "self",
      "datasets"
    ],
    "prepare_sample": [
      "self",
      "data"
    ]
  },
  "CUSTOM_DATASETS": [],
  "build_custom_dataset": [
    "cfg",
    "task_name",
    "default_args"
  ],
  "TorchCustomDataset": {
    "__init__": [
      "self",
      "datasets",
      "mode",
      "preprocessor"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "prepare_dataset": [
      "self",
      "datasets"
    ]
  },
  "default_loader": [
    "path"
  ],
  "GoproImageDeblurringDataset": {
    "__init__": [
      "self",
      "dataset",
      "opt",
      "is_train"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "LanguageGuidedVideoSummarizationDataset": {
    "__init__": [
      "self",
      "mode",
      "opt",
      "root_dir"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "TextRankingDataset": {
    "__init__": [
      "self",
      "datasets",
      "mode",
      "preprocessor"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__get_test_item__": [
      "self",
      "index"
    ],
    "__get_train_item__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "prepare_dataset": [
      "self",
      "datasets"
    ],
    "prepare_sample": [
      "self",
      "data"
    ]
  },
  "RedsImageDeblurringDataset": {
    "__init__": [
      "self",
      "dataset",
      "opt",
      "is_train"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "Q2B": [
    "uchar"
  ],
  "OCRRecognitionDataset": {
    "__init__": [
      "self",
      "local_lmdb",
      "preprocessor"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "VideoFrameInterpolationDataset": {
    "__init__": [
      "self",
      "dataset",
      "opt"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "img2tensor": [
    "imgs",
    "bgr2rgb",
    "float32"
  ],
  "img_padding": [
    "img_tensor",
    "height",
    "width",
    "pad_num"
  ],
  "BatchCollator": {
    "__init__": [
      "self",
      "size_divisible"
    ],
    "__call__": [
      "self",
      "batch"
    ]
  },
  "TTACollator": {
    "__call__": [
      "self",
      "batch"
    ]
  },
  "build_dataset": [
    "cfg",
    "image_dir",
    "ann_file",
    "is_train",
    "mosaic_mixup",
    "dataset_format"
  ],
  "make_data_sampler": [
    "dataset",
    "shuffle",
    "distributed"
  ],
  "_quantize": [
    "x",
    "bins"
  ],
  "_compute_aspect_ratios": [
    "dataset"
  ],
  "make_batch_sampler": [
    "dataset",
    "sampler",
    "images_per_batch",
    "num_iters",
    "start_iter",
    "mosaic_warpper"
  ],
  "build_dataloader": [
    "datasets",
    "augment",
    "batch_size",
    "start_epoch",
    "total_epochs",
    "no_aug_epochs",
    "is_train",
    "num_workers",
    "size_div",
    "distributed"
  ],
  "COCODataset": {
    "__init__": [
      "self",
      "ann_file",
      "root",
      "transforms"
    ],
    "__getitem__": [
      "self",
      "inp"
    ],
    "pull_item": [
      "self",
      "idx"
    ],
    "load_anno": [
      "self",
      "idx"
    ],
    "get_img_info": [
      "self",
      "index"
    ]
  },
  "xyn2xy": [
    "x",
    "scale",
    "padw",
    "padh"
  ],
  "resample_segments": [
    "segments",
    "n"
  ],
  "segment2box": [
    "segment",
    "width",
    "height"
  ],
  "get_aug_params": [
    "value",
    "center"
  ],
  "box_candidates": [
    "box1",
    "box2",
    "wh_thr",
    "ar_thr",
    "area_thr",
    "eps"
  ],
  "get_transform_matrix": [
    "img_shape",
    "new_shape",
    "degrees",
    "scale",
    "shear",
    "translate"
  ],
  "random_affine": [
    "img",
    "targets",
    "segments",
    "target_size",
    "degrees",
    "translate",
    "scales",
    "shear"
  ],
  "get_mosaic_coordinate": [
    "mosaic_image",
    "mosaic_index",
    "xc",
    "yc",
    "w",
    "h",
    "input_h",
    "input_w"
  ],
  "MosaicWrapper": {
    "__init__": [
      "self",
      "dataset",
      "img_size",
      "mosaic_prob",
      "mixup_prob",
      "transforms",
      "degrees",
      "translate",
      "mosaic_scale",
      "mixup_scale",
      "shear"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "inp"
    ],
    "mixup": [
      "self",
      "origin_img",
      "origin_labels",
      "input_dim"
    ],
    "get_img_info": [
      "self",
      "index"
    ]
  },
  "DistributedSampler": {
    "__init__": [
      "self",
      "dataset",
      "num_replicas",
      "rank",
      "shuffle"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "GroupedBatchSampler": {
    "__init__": [
      "self",
      "sampler",
      "group_ids",
      "batch_size",
      "drop_uneven"
    ],
    "_prepare_batches": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "IterationBasedBatchSampler": {
    "__init__": [
      "self",
      "batch_sampler",
      "num_iterations",
      "start_iter",
      "enable_mosaic"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "set_mosaic": [
      "self",
      "enable_mosaic"
    ]
  },
  "evaluate": [
    "dataset",
    "predictions",
    "output_folder"
  ],
  "coco_evaluation": [
    "dataset",
    "predictions",
    "output_folder",
    "box_only",
    "iou_types",
    "expected_results",
    "expected_results_sigma_tol"
  ],
  "do_coco_evaluation": [
    "dataset",
    "predictions",
    "box_only",
    "output_folder",
    "iou_types",
    "expected_results",
    "expected_results_sigma_tol"
  ],
  "prepare_for_coco_detection": [
    "predictions",
    "dataset"
  ],
  "evaluate_box_proposals": [
    "predictions",
    "dataset",
    "thresholds",
    "area",
    "limit"
  ],
  "evaluate_predictions_on_coco": [
    "coco_gt",
    "coco_results",
    "json_result_file",
    "iou_type"
  ],
  "compute_thresholds_for_classes": [
    "coco_eval"
  ],
  "COCOResults": {
    "METRICS": [],
    "__init__": [
      "self"
    ],
    "update": [
      "self",
      "coco_eval"
    ],
    "__repr__": [
      "self"
    ]
  },
  "check_expected_results": [
    "results",
    "expected_results",
    "sigma_tol"
  ],
  "build_transforms": [
    "start_epoch",
    "total_epochs",
    "no_aug_epochs",
    "iters_per_epoch",
    "num_workers",
    "batch_size",
    "num_gpus",
    "image_max_range",
    "flip_prob",
    "image_mean",
    "image_std",
    "autoaug_dict"
  ],
  "ImageQualityAssessmentMosDataset": {
    "__init__": [
      "self",
      "dataset",
      "opt",
      "preprocessor"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "ImageQualityAssessmentDegradationDataset": {
    "__init__": [
      "self",
      "dataset"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "BadImageDetectingDataset": {
    "__init__": [
      "self",
      "dataset",
      "opt"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "MovieSceneSegmentationDataset": {
    "__init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "load_data": [
      "self"
    ],
    "init_sampler": [
      "self",
      "cfg"
    ],
    "load_shot_list": [
      "self",
      "vid",
      "shot_idx"
    ],
    "load_shot_keyframes": [
      "self",
      "path"
    ]
  },
  "InstanceShotSampler": {
    "__call__": [
      "self",
      "center_sid"
    ]
  },
  "TemporalShotSampler": {
    "__init__": [
      "self",
      "neighbor_size"
    ],
    "__call__": [
      "self",
      "center_sid",
      "total_num_shot"
    ]
  },
  "SequenceShotSampler": {
    "__init__": [
      "self",
      "neighbor_size",
      "neighbor_interval"
    ],
    "__call__": [
      "self",
      "center_sid",
      "total_num_shot",
      "sparse_method"
    ]
  },
  "NeighborShotSampler": {
    "__init__": [
      "self",
      "neighbor_size"
    ],
    "__call__": [
      "self",
      "center_sid",
      "total_num_shot"
    ]
  },
  "VideoSuperResolutionDataset": {
    "__init__": [
      "self",
      "dataset"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "RandomSizeCrop": {
    "__init__": [
      "self",
      "min_size",
      "max_size"
    ],
    "__call__": [
      "self",
      "img",
      "target"
    ]
  },
  "RandomPad": {
    "__init__": [
      "self",
      "max_pad"
    ],
    "__call__": [
      "self",
      "img",
      "target"
    ]
  },
  "RandomSelect": {
    "__init__": [
      "self",
      "transforms1",
      "transforms2",
      "p"
    ],
    "__call__": [
      "self",
      "img",
      "target"
    ]
  },
  "RandomErasing": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "img",
      "target"
    ]
  },
  "LOGGER": [],
  "get_image_id": [
    "video_id",
    "frame_idx",
    "ref_instance_a2d_id"
  ],
  "ReferringVideoObjectSegmentationDataset": {
    "__init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "get_text_annotations": [
      "root_path",
      "subset",
      "distributed"
    ]
  },
  "A2dSentencesTransforms": {
    "__init__": [
      "self",
      "subset_type",
      "horizontal_flip_augmentations",
      "resize_and_crop_augmentations",
      "train_short_size",
      "train_max_size",
      "eval_short_size",
      "eval_max_size"
    ],
    "__call__": [
      "self",
      "source_frames",
      "targets",
      "text_query"
    ]
  },
  "Collator": {
    "__call__": [
      "self",
      "batch"
    ]
  },
  "get_text_annotations_gt": [
    "root_path",
    "subset"
  ],
  "create_a2d_sentences_ground_truth_test_annotations": [
    "dataset_path",
    "subset_type",
    "mask_annotations_dir",
    "output_path"
  ],
  "parse_wav": [
    "data"
  ],
  "filter": [
    "data",
    "max_length",
    "min_length"
  ],
  "resample": [
    "data",
    "resample_rate"
  ],
  "speed_perturb": [
    "data",
    "speeds"
  ],
  "compute_mfcc": [
    "data",
    "feature_type",
    "num_ceps",
    "num_mel_bins",
    "frame_length",
    "frame_shift",
    "dither"
  ],
  "compute_fbank": [
    "data",
    "feature_type",
    "num_mel_bins",
    "frame_length",
    "frame_shift",
    "dither"
  ],
  "spec_aug": [
    "data",
    "num_t_mask",
    "num_f_mask",
    "max_t",
    "max_f"
  ],
  "shuffle": [
    "data",
    "shuffle_size"
  ],
  "context_expansion": [
    "data",
    "left",
    "right"
  ],
  "frame_skip": [
    "data",
    "skip_rate"
  ],
  "padding": [
    "data"
  ],
  "ASRDataset": {
    "load_core": [
      "cls",
      "data_dir",
      "data_set"
    ],
    "load": [
      "cls",
      "dataset_name",
      "namespace",
      "train_set",
      "dev_set",
      "download_mode"
    ]
  },
  "Processor": {
    "__init__": [
      "self",
      "source",
      "f"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__iter__": [
      "self"
    ],
    "apply": [
      "self",
      "f"
    ]
  },
  "DataList": {
    "__init__": [
      "self",
      "lists",
      "shuffle",
      "partition"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__iter__": [
      "self"
    ],
    "dump": [
      "self",
      "dump_file"
    ]
  },
  "kws_nearfield_dataset": [
    "data_file",
    "trans_file",
    "conf",
    "symbol_table",
    "lexicon_table",
    "need_dump",
    "dump_file",
    "partition"
  ],
  "BLOCK_DEC": [],
  "BLOCK_CAT": [],
  "FBANK_SIZE": [],
  "LABEL_SIZE": [],
  "LABEL_GAIN": [],
  "KWSDataset": {
    "__init__": [
      "self",
      "conf_basetrain",
      "conf_finetune",
      "numworkers",
      "basetrainratio",
      "numclasses",
      "blockdec",
      "blockcat"
    ],
    "release": [
      "self"
    ],
    "setup_sims": [
      "self",
      "conf_basetrain",
      "conf_finetune",
      "numworkers",
      "basetrainratio"
    ],
    "getBatch": [
      "self",
      "id"
    ],
    "get_sim": [
      "self",
      "id"
    ]
  },
  "Worker": {
    "__init__": [
      "self",
      "id",
      "dataset",
      "pool"
    ],
    "run": [
      "self"
    ],
    "stopWorker": [
      "self"
    ]
  },
  "KWSDataLoader": {
    "__init__": [
      "self",
      "dataset",
      "batchsize",
      "numworkers",
      "prefetch"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "start": [
      "self"
    ],
    "stop": [
      "self"
    ]
  },
  "ImagePortraitEnhancementDataset": {
    "__init__": [
      "self",
      "dataset",
      "is_train"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "VideoStabilizationDataset": {
    "__init__": [
      "self",
      "dataset",
      "opt"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "IAAAffine2": {
    "__init__": [
      "self",
      "scale",
      "translate_percent",
      "translate_px",
      "rotate",
      "shear",
      "order",
      "cval",
      "mode",
      "always_apply",
      "p"
    ],
    "processor": [
      "self"
    ],
    "get_transform_init_args_names": [
      "self"
    ]
  },
  "IAAPerspective2": {
    "__init__": [
      "self",
      "scale",
      "keep_size",
      "always_apply",
      "p",
      "order",
      "cval",
      "mode"
    ],
    "processor": [
      "self"
    ],
    "get_transform_init_args_names": [
      "self"
    ]
  },
  "LinearRamp": {
    "__init__": [
      "self",
      "start_value",
      "end_value",
      "start_iter",
      "end_iter"
    ],
    "__call__": [
      "self",
      "i"
    ]
  },
  "DrawMethod": {
    "LINE": [],
    "CIRCLE": [],
    "SQUARE": []
  },
  "make_random_superres_mask": [
    "shape",
    "min_step",
    "max_step",
    "min_width",
    "max_width"
  ],
  "RandomSuperresMaskGenerator": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "img",
      "iter_i"
    ]
  },
  "make_random_rectangle_mask": [
    "shape",
    "margin",
    "bbox_min_size",
    "bbox_max_size",
    "min_times",
    "max_times"
  ],
  "RandomRectangleMaskGenerator": {
    "__init__": [
      "self",
      "margin",
      "bbox_min_size",
      "bbox_max_size",
      "min_times",
      "max_times",
      "ramp_kwargs"
    ],
    "__call__": [
      "self",
      "img",
      "iter_i",
      "raw_image"
    ]
  },
  "make_random_irregular_mask": [
    "shape",
    "max_angle",
    "max_len",
    "max_width",
    "min_times",
    "max_times",
    "draw_method"
  ],
  "RandomIrregularMaskGenerator": {
    "__init__": [
      "self",
      "max_angle",
      "max_len",
      "max_width",
      "min_times",
      "max_times",
      "ramp_kwargs",
      "draw_method"
    ],
    "__call__": [
      "self",
      "img",
      "iter_i",
      "raw_image"
    ]
  },
  "MixedMaskGenerator": {
    "__init__": [
      "self",
      "irregular_proba",
      "irregular_kwargs",
      "box_proba",
      "box_kwargs",
      "segm_proba",
      "segm_kwargs",
      "squares_proba",
      "squares_kwargs",
      "superres_proba",
      "superres_kwargs",
      "outpainting_proba",
      "outpainting_kwargs",
      "invert_proba"
    ],
    "__call__": [
      "self",
      "img",
      "iter_i",
      "raw_image"
    ]
  },
  "get_transforms": [
    "test_mode",
    "out_size"
  ],
  "ImageInpaintingDataset": {
    "__init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "mod_crop": [
    "img",
    "scale"
  ],
  "paired_random_crop": [
    "img_gts",
    "img_lqs",
    "gt_patch_size",
    "scale"
  ],
  "augment": [
    "imgs",
    "hflip",
    "rotation",
    "vflip"
  ],
  "SiddImageDenoisingDataset": {
    "__init__": [
      "self",
      "dataset",
      "opt",
      "is_train"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "ImageColorizationDataset": {
    "__init__": [
      "self",
      "dataset",
      "opt",
      "is_train"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "default_worker_init_fn": [
    "worker_id"
  ],
  "ImageDataset": {
    "__init__": [
      "self",
      "cfg",
      "data_dir",
      "data_list"
    ],
    "get_all_samples": [
      "self"
    ],
    "load_ann": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index",
      "retry"
    ],
    "__len__": [
      "self"
    ]
  },
  "AugmenterBuilder": {
    "__init__": [
      "self"
    ],
    "build": [
      "self",
      "args",
      "root"
    ],
    "to_tuple_if_list": [
      "self",
      "obj"
    ]
  },
  "QuadMeasurer": {
    "__init__": [
      "self"
    ],
    "measure": [
      "self",
      "batch",
      "output",
      "is_output_polygon",
      "box_thresh"
    ],
    "validate_measure": [
      "self",
      "batch",
      "output",
      "is_output_polygon",
      "box_thresh"
    ],
    "evaluate_measure": [
      "self",
      "batch",
      "output"
    ],
    "gather_measure": [
      "self",
      "raw_metrics"
    ]
  },
  "DetectionIoUEvaluator": {
    "__init__": [
      "self",
      "iou_constraint",
      "area_precision_constraint"
    ],
    "evaluate_image": [
      "self",
      "gt",
      "pred"
    ],
    "combine_results": [
      "self",
      "results"
    ]
  },
  "DataProcess": {
    "__call__": [
      "self",
      "data"
    ],
    "process": [
      "self",
      "data"
    ],
    "render_constant": [
      "self",
      "canvas",
      "xmin",
      "xmax",
      "ymin",
      "ymax",
      "value",
      "shrink"
    ]
  },
  "MakeICDARData": {
    "__init__": [
      "self",
      "debug"
    ],
    "process": [
      "self",
      "data"
    ],
    "draw_polygons": [
      "self",
      "image",
      "polygons",
      "ignore_tags"
    ],
    "polylines": []
  },
  "ICDARCollectFN": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "batch"
    ]
  },
  "MakeBorderMap": {
    "__init__": [
      "self"
    ],
    "process": [
      "self",
      "data"
    ],
    "draw_border_map": [
      "self",
      "polygon",
      "canvas",
      "mask"
    ],
    "distance": [
      "self",
      "xs",
      "ys",
      "point_1",
      "point_2"
    ],
    "extend_line": [
      "self",
      "point_1",
      "point_2",
      "result"
    ]
  },
  "AugmentData": {
    "__init__": [
      "self",
      "cfg"
    ],
    "may_augment_annotation": [
      "self",
      "aug",
      "data"
    ],
    "resize_image": [
      "self",
      "image"
    ],
    "process": [
      "self",
      "data"
    ]
  },
  "AugmentDetectionData": {
    "may_augment_annotation": [
      "self",
      "aug",
      "data",
      "shape"
    ]
  },
  "MakeSegDetectionData": {
    "__init__": [
      "self"
    ],
    "process": [
      "self",
      "data"
    ],
    "validate_polygons": [
      "self",
      "polygons",
      "ignore_tags",
      "h",
      "w"
    ],
    "polygon_area": [
      "self",
      "polygon"
    ]
  },
  "RandomCropData": {
    "__init__": [
      "self",
      "cfg"
    ],
    "process": [
      "self",
      "data"
    ],
    "is_poly_in_rect": [
      "self",
      "poly",
      "x",
      "y",
      "w",
      "h"
    ],
    "is_poly_outside_rect": [
      "self",
      "poly",
      "x",
      "y",
      "w",
      "h"
    ],
    "split_regions": [
      "self",
      "axis"
    ],
    "random_select": [
      "self",
      "axis",
      "max_size"
    ],
    "region_wise_random_select": [
      "self",
      "regions",
      "max_size"
    ],
    "crop_area": [
      "self",
      "img",
      "polys"
    ]
  },
  "NormalizeImage": {
    "RGB_MEAN": [],
    "process": [
      "self",
      "data"
    ],
    "restore": [
      "self",
      "image"
    ]
  },
  "DatasetUploadManager": {
    "__init__": [
      "self",
      "dataset_name",
      "namespace",
      "version"
    ],
    "upload": [
      "self",
      "object_name",
      "local_file_path",
      "upload_mode"
    ],
    "upload_dir": [
      "self",
      "object_dir_name",
      "local_dir_path",
      "num_processes",
      "chunksize",
      "filter_hidden_files",
      "upload_mode"
    ]
  },
  "get_datasets_user_agent_ms": [
    "user_agent"
  ],
  "_request_with_retry_ms": [
    "method",
    "url",
    "max_retries",
    "base_wait_time",
    "max_wait_time",
    "timeout"
  ],
  "http_head_ms": [
    "url",
    "proxies",
    "headers",
    "cookies",
    "allow_redirects",
    "timeout",
    "max_retries"
  ],
  "http_get_ms": [
    "url",
    "temp_file",
    "proxies",
    "resume_size",
    "headers",
    "cookies",
    "timeout",
    "max_retries",
    "desc"
  ],
  "get_from_cache_ms": [
    "url",
    "cache_dir",
    "force_download",
    "proxies",
    "etag_timeout",
    "resume_download",
    "user_agent",
    "local_files_only",
    "use_etag",
    "max_retries",
    "token",
    "use_auth_token",
    "ignore_url_params",
    "storage_options",
    "download_desc",
    "disable_tqdm"
  ],
  "ACCESS_ID": [],
  "ACCESS_SECRET": [],
  "SECURITY_TOKEN": [],
  "BUCKET": [],
  "BACK_DIR": [],
  "DIR": [],
  "CredentialProviderWrapper": {
    "__init__": [
      "self",
      "api",
      "dataset_name",
      "namespace",
      "revision"
    ],
    "get_credentials": [
      "self"
    ]
  },
  "OssUtilities": {
    "__init__": [
      "self",
      "dataset_name",
      "namespace",
      "revision"
    ],
    "_percentage": [
      "consumed_bytes",
      "total_bytes"
    ],
    "download": [
      "self",
      "oss_file_name",
      "download_config"
    ],
    "upload": [
      "self",
      "oss_object_name",
      "local_file_path",
      "indicate_individual_progress",
      "upload_mode"
    ]
  },
  "format_dataset_structure": [
    "dataset_structure"
  ],
  "get_target_dataset_structure": [
    "dataset_structure",
    "subset_name",
    "split"
  ],
  "list_dataset_objects": [
    "hub_api",
    "max_limit",
    "is_recursive",
    "dataset_name",
    "namespace",
    "version"
  ],
  "contains_dir": [
    "file_map"
  ],
  "get_subdir_hash_from_split": [
    "split",
    "version"
  ],
  "get_split_list": [
    "split"
  ],
  "get_split_objects_map": [
    "file_map",
    "objects"
  ],
  "get_dataset_files": [
    "subset_split_into",
    "dataset_name",
    "namespace",
    "context_config",
    "revision"
  ],
  "DatasetDeleteManager": {
    "__init__": [
      "self",
      "dataset_name",
      "namespace",
      "version"
    ],
    "delete": [
      "self",
      "object_name"
    ]
  },
  "MaxComputeUtil": {
    "__init__": [
      "self",
      "access_id",
      "access_key",
      "project_name",
      "endpoint"
    ],
    "_get_table": [
      "self",
      "table_name"
    ],
    "_read_data": [
      "self",
      "table_name",
      "pt_condition"
    ],
    "fetch_data_to_csv": [
      "self",
      "table_name",
      "pt_condition",
      "output_path"
    ],
    "_check_batch_args": [
      "reader",
      "batch_size",
      "limit"
    ],
    "gen_reader_batch": [
      "reader",
      "batch_size_in",
      "limit_in",
      "drop_last_in",
      "partitions",
      "columns"
    ],
    "gen_reader_item": [
      "reader",
      "index",
      "batch_size_in",
      "limit_in",
      "drop_last_in",
      "partitions",
      "columns"
    ],
    "get_table_reader_ins": [
      "self",
      "table_name",
      "pt_condition"
    ]
  },
  "ExpandDatasetProperty_T": [],
  "ListMs": {
    "__repr__": [
      "self"
    ]
  },
  "generate_from_dict_ms": [
    "obj"
  ],
  "_download_ms": [
    "self",
    "url_or_filename",
    "download_config"
  ],
  "_dataset_info": [
    "self",
    "repo_id"
  ],
  "_list_repo_tree": [
    "self",
    "repo_id",
    "path_in_repo"
  ],
  "_get_paths_info": [
    "self",
    "repo_id",
    "paths"
  ],
  "_download_repo_file": [
    "repo_id",
    "path_in_repo",
    "download_config",
    "revision"
  ],
  "get_fs_token_paths": [
    "urlpath",
    "storage_options",
    "protocol"
  ],
  "_resolve_pattern": [
    "pattern",
    "base_path",
    "allowed_extensions",
    "download_config"
  ],
  "_get_data_patterns": [
    "base_path",
    "download_config"
  ],
  "get_module_without_script": [
    "self"
  ],
  "_download_additional_modules": [
    "name",
    "dataset_name",
    "namespace",
    "revision",
    "imports",
    "download_config",
    "trust_remote_code"
  ],
  "get_module_with_script": [
    "self"
  ],
  "DatasetsWrapperHF": {
    "load_dataset": [
      "path",
      "name",
      "data_dir",
      "data_files",
      "split",
      "cache_dir",
      "features",
      "download_config",
      "download_mode",
      "verification_mode",
      "keep_in_memory",
      "save_infos",
      "revision",
      "token",
      "use_auth_token",
      "task",
      "streaming",
      "num_proc",
      "storage_options",
      "trust_remote_code",
      "dataset_info_only"
    ],
    "load_dataset_builder": [
      "path",
      "name",
      "data_dir",
      "data_files",
      "cache_dir",
      "features",
      "download_config",
      "download_mode",
      "revision",
      "token",
      "use_auth_token",
      "storage_options",
      "trust_remote_code",
      "_require_default_config_name"
    ],
    "dataset_module_factory": [
      "path",
      "revision",
      "download_config",
      "download_mode",
      "dynamic_modules_path",
      "data_dir",
      "data_files",
      "cache_dir",
      "trust_remote_code",
      "_require_default_config_name",
      "_require_custom_configs"
    ]
  },
  "load_dataset_with_ctx": [],
  "DataFilesManager": {
    "__init__": [
      "self",
      "dataset_context_config"
    ],
    "get_data_files_builder": [
      "self"
    ],
    "fetch_data_files": [
      "self",
      "builder"
    ]
  },
  "BaseDownloader": {
    "__init__": [
      "self",
      "dataset_context_config"
    ],
    "process": [
      "self"
    ],
    "_authorize": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "_prepare_and_download": [
      "self"
    ],
    "_post_process": [
      "self"
    ]
  },
  "OssDownloader": {
    "__init__": [
      "self",
      "dataset_context_config"
    ],
    "process": [
      "self"
    ],
    "_authorize": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "_prepare_and_download": [
      "self"
    ],
    "_post_process": [
      "self"
    ]
  },
  "VirgoDownloader": {
    "__init__": [
      "self",
      "dataset_context_config"
    ],
    "process": [
      "self"
    ],
    "_authorize": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "_prepare_and_download": [
      "self"
    ],
    "_post_process": [
      "self"
    ]
  },
  "MaxComputeDownloader": {
    "__init__": [
      "self",
      "dataset_context_config"
    ],
    "process": [
      "self"
    ],
    "_authorize": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "_prepare_and_download": [
      "self"
    ],
    "_post_process": [
      "self"
    ]
  },
  "LocalDataLoaderType": {
    "HF_DATA_LOADER": [],
    "TORCH_DATA_LOADER": [],
    "TF_DATA_LOADER": []
  },
  "RemoteDataLoaderType": {
    "HF_DATA_LOADER": [],
    "MS_DATA_LOADER": []
  },
  "DataLoaderManager": {
    "__init__": [
      "self",
      "dataset_context_config"
    ],
    "load_dataset": [
      "self",
      "data_loader_type"
    ]
  },
  "LocalDataLoaderManager": {
    "__init__": [
      "self",
      "dataset_context_config"
    ],
    "load_dataset": [
      "self",
      "data_loader_type"
    ]
  },
  "RemoteDataLoaderManager": {
    "__init__": [
      "self",
      "dataset_context_config"
    ],
    "load_dataset": [
      "self",
      "data_loader_type"
    ]
  },
  "CliArgumentParser": {
    "__init__": [
      "self",
      "training_args"
    ],
    "get_manual_args": [
      "self",
      "args"
    ],
    "_parse_known_args": [
      "self",
      "args",
      "namespace"
    ],
    "print_help": [
      "self",
      "file"
    ],
    "define_args": [
      "self"
    ]
  },
  "DictAction": {
    "parse_int_float_bool_str": [
      "val"
    ],
    "parse_iterable": [
      "val"
    ],
    "__call__": [
      "self",
      "parser",
      "namespace",
      "values",
      "option_string"
    ]
  },
  "SingleAction": {
    "__call__": [
      "self",
      "parser",
      "namespace",
      "value",
      "option_string"
    ]
  },
  "TunerConfig": [],
  "EpochBasedTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "cfg_modify_fn",
      "arg_parse_fn",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "preprocessor",
      "optimizers",
      "model_revision",
      "seed",
      "callbacks",
      "samplers",
      "efficient_tuners"
    ],
    "tune_module": [
      "self",
      "efficient_tuners"
    ],
    "place_model": [
      "self"
    ],
    "get_data_collator": [
      "self",
      "data_collator",
      "remove_unused_data"
    ],
    "init_dist": [
      "self",
      "launcher"
    ],
    "get_device": [
      "self",
      "device"
    ],
    "get_preprocessors": [
      "self",
      "preprocessor"
    ],
    "rebuild_config": [
      "self",
      "cfg"
    ],
    "dp_group": [
      "self"
    ],
    "tp_group": [
      "self"
    ],
    "pp_group": [
      "self"
    ],
    "is_dp_group_available": [
      "self"
    ],
    "is_tp_group_available": [
      "self"
    ],
    "is_pp_group_available": [
      "self"
    ],
    "mode": [
      "self"
    ],
    "hooks": [
      "self"
    ],
    "epoch": [
      "self"
    ],
    "iter": [
      "self"
    ],
    "inner_iter": [
      "self"
    ],
    "max_epochs": [
      "self"
    ],
    "max_iters": [
      "self"
    ],
    "iters_per_epoch": [
      "self"
    ],
    "build_dataset": [
      "self",
      "datasets",
      "model_cfg",
      "mode",
      "preprocessor"
    ],
    "to_task_dataset": [
      "self",
      "dataset",
      "mode",
      "preprocessor"
    ],
    "build_dataset_from_cfg": [
      "model_cfg",
      "mode",
      "preprocessor"
    ],
    "build_preprocessor": [
      "self"
    ],
    "get_metrics": [
      "self"
    ],
    "set_checkpoint_file_to_hook": [
      "self",
      "checkpoint_path",
      "load_all_state",
      "strict"
    ],
    "train": [
      "self",
      "checkpoint_path",
      "load_all_state"
    ],
    "predict": [
      "self",
      "predict_datasets",
      "saving_fn",
      "checkpoint_path",
      "strict"
    ],
    "evaluate": [
      "self",
      "checkpoint_path",
      "saving_fn"
    ],
    "metric_values": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "to_parallel": [
      "self",
      "model"
    ],
    "unwrap_module": [
      "self",
      "model"
    ],
    "train_step": [
      "self",
      "model",
      "inputs"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs"
    ],
    "get_train_dataloader": [
      "self"
    ],
    "get_eval_data_loader": [
      "self"
    ],
    "get_predict_dataloader": [
      "self",
      "predict_datasets"
    ],
    "build_optimizer": [
      "self",
      "cfg",
      "default_args"
    ],
    "build_lr_scheduler": [
      "self",
      "cfg",
      "default_args"
    ],
    "create_optimizer_and_scheduler": [
      "self"
    ],
    "register_optimizers_hook": [
      "self"
    ],
    "_build_dataloader_with_dataset": [
      "self",
      "dataset",
      "batch_size_per_gpu",
      "workers_per_gpu",
      "dist",
      "shuffle",
      "seed",
      "persistent_workers"
    ],
    "train_loop": [
      "self",
      "data_loader"
    ],
    "evaluation_step": [
      "self",
      "data"
    ],
    "evaluation_loop": [
      "self",
      "data_loader",
      "metric_classes"
    ],
    "visualization": [
      "self",
      "batch_result",
      "dataset"
    ],
    "register_hook": [
      "self",
      "hook"
    ],
    "register_hook_from_cfg": [
      "self",
      "hook_cfg"
    ],
    "register_processors": [
      "self"
    ],
    "get_hook": [
      "self",
      "cls"
    ],
    "invoke_hook": [
      "self",
      "fn_name"
    ],
    "print_cfg": [
      "self"
    ],
    "print_hook_info": [
      "self"
    ],
    "get_hook_info": [
      "self"
    ]
  },
  "worker_init_fn": [
    "worker_id",
    "num_workers",
    "rank",
    "seed"
  ],
  "BaseTrainer": {
    "__init__": [
      "self",
      "cfg_file",
      "arg_parse_fn"
    ],
    "get_or_download_model_dir": [
      "self",
      "model",
      "model_revision",
      "third_party"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "DummyTrainer": {
    "__init__": [
      "self",
      "cfg_file"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "TRAINERS": [],
  "build_trainer": [
    "name",
    "default_args"
  ],
  "NlpEpochBasedTrainer": {
    "__init__": [
      "self"
    ],
    "prepare_labels": [
      "self",
      "cfg"
    ],
    "rebuild_config": [
      "self",
      "cfg"
    ],
    "build_model": [
      "self"
    ],
    "build_preprocessor": [
      "self"
    ]
  },
  "VecoTrainer": {
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "DEFAULT_HOOKS_CONFIG": [],
  "_HOOK_KEY_CHAIN_MAP": [],
  "merge_cfg": [
    "cfg"
  ],
  "merge_hooks": [
    "cfg"
  ],
  "update_cfg": [
    "cfg"
  ],
  "_key_chain_to_hook": [
    "cfg",
    "key_chain",
    "hook_type"
  ],
  "_check_basic_hook": [
    "cfg",
    "key_chain",
    "hook_type"
  ],
  "_hook_split": [
    "hook"
  ],
  "set_flatten_value": [
    "values"
  ],
  "DatasetArgs": {},
  "ModelArgs": {},
  "TrainArgs": {},
  "TrainingArgs": {
    "__init__": [
      "self"
    ],
    "parse_cli": [
      "self",
      "parser_args"
    ],
    "to_config": [
      "self",
      "ignore_default_config"
    ],
    "get_metadata": [
      "self",
      "key"
    ]
  },
  "build_dataset_from_file": [
    "filename"
  ],
  "parse_value": [
    "value"
  ],
  "VisionEfficientTuningTrainer": {
    "__init__": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self"
    ],
    "freeze": [
      "self",
      "model",
      "freeze_part",
      "train_part"
    ],
    "print_model_params_status": [
      "self",
      "model",
      "logger"
    ]
  },
  "CardDetectionScrfdTrainer": {
    "__init__": [
      "self",
      "cfg_file"
    ]
  },
  "DefaultTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg"
    ],
    "resume_or_load": [
      "self",
      "resume"
    ],
    "build_hooks": [
      "self"
    ],
    "build_writers": [
      "self"
    ],
    "train": [
      "self"
    ],
    "build_evaluator": [
      "cls",
      "cfg",
      "dataset_name",
      "output_folder"
    ],
    "test": [
      "cls",
      "cfg",
      "model",
      "evaluators"
    ]
  },
  "ImageDefrcnFewshotTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "arg_parse_fn",
      "model_revision",
      "seed",
      "cfg_modify_fn"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ],
    "build_model": [
      "self"
    ],
    "model_surgery": [
      "cls",
      "src_path",
      "save_dir",
      "data_type",
      "method",
      "params_name"
    ]
  },
  "OCRDetectionDBTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "load_pretrain",
      "cache_path",
      "model_revision"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ],
    "_config_transform": [
      "self",
      "config"
    ]
  },
  "DBTrainer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "init_device": [
      "self"
    ],
    "init_model": [
      "self",
      "local_rank"
    ],
    "get_learning_rate": [
      "self",
      "epoch",
      "step"
    ],
    "update_learning_rate": [
      "self",
      "optimizer",
      "epoch",
      "step"
    ],
    "restore_model": [
      "self",
      "model",
      "model_path",
      "device"
    ],
    "create_optimizer": [
      "self",
      "lr",
      "momentum",
      "weight_decay"
    ],
    "maybe_save_model": [
      "self",
      "model",
      "epoch",
      "step"
    ],
    "save_model": [
      "self",
      "model",
      "epoch",
      "step"
    ],
    "save_checkpoint": [
      "self",
      "net",
      "name"
    ],
    "convert_model_for_inference": [
      "self",
      "finetune_model_name",
      "infer_model_name"
    ],
    "make_checkpoint_name": [
      "self",
      "name",
      "epoch",
      "step"
    ],
    "get_data_loader": [
      "self",
      "cfg",
      "distributed"
    ],
    "train": [
      "self",
      "local_rank"
    ],
    "train_step": [
      "self",
      "model",
      "optimizer",
      "batch",
      "epoch",
      "step"
    ],
    "init_torch_tensor": [
      "self"
    ],
    "represent": [
      "self",
      "batch",
      "_pred",
      "is_output_polygon"
    ],
    "evaluate": [
      "self",
      "local_rank"
    ]
  },
  "OCRRecognitionTrainer": {
    "evaluate": [
      "self"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs"
    ],
    "train_step": [
      "self",
      "model",
      "inputs"
    ],
    "evaluation_step": [
      "self",
      "data"
    ]
  },
  "ImageInpaintingTrainer": {
    "__init__": [
      "self"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs"
    ],
    "train_loop": [
      "self",
      "data_loader"
    ],
    "train_step": [
      "self",
      "model",
      "inputs",
      "idx"
    ]
  },
  "FaceDetectionScrfdTrainer": {
    "__init__": [
      "self",
      "cfg_file",
      "cfg_modify_fn"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "train_model": [
    "model",
    "dataset",
    "cfg",
    "distributed",
    "val_dataset",
    "timestamp",
    "device",
    "meta"
  ],
  "ImageClassifitionTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "arg_parse_fn",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "preprocessor",
      "optimizers",
      "model_revision",
      "seed",
      "cfg_modify_fn"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "CartoonTranslationTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "work_dir",
      "photo",
      "cartoon",
      "max_steps"
    ],
    "_override_params_from_file": [
      "self"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "ImageInstanceSegmentationTrainer": {
    "__init__": [
      "self"
    ],
    "collate_fn": [
      "self",
      "data"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs"
    ]
  },
  "MovieSceneSegmentationTrainer": {
    "__init__": [
      "self"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs"
    ]
  },
  "ReferringVideoObjectSegmentationTrainer": {
    "__init__": [
      "self"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs"
    ]
  },
  "ActionDetectionTrainer": {
    "__init__": [
      "self",
      "model_id",
      "train_dataset",
      "test_dataset",
      "cfg_file",
      "cfg_modify_fn"
    ],
    "start": [
      "self",
      "output_dir"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ],
    "do_train": [
      "self",
      "just_eval",
      "checkpoint_path"
    ],
    "do_test": [
      "self",
      "model"
    ],
    "get_or_download_model_dir": [
      "self",
      "model",
      "model_revision"
    ]
  },
  "ImagePortraitEnhancementTrainer": {
    "train_step": [
      "self",
      "model",
      "inputs"
    ],
    "create_optimizer_and_scheduler": [
      "self"
    ]
  },
  "ImageDetectionDamoyoloTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "load_pretrain",
      "cache_path",
      "model_revision"
    ],
    "_train": [
      "self",
      "local_rank",
      "world_size",
      "cfg"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ],
    "_config_transform": [
      "self",
      "config"
    ]
  },
  "DamoyoloTrainer": {
    "__init__": [
      "self",
      "cfg",
      "args",
      "tea_cfg"
    ],
    "get_data_loader": [
      "self",
      "cfg",
      "distributed"
    ],
    "setup_iters": [
      "self",
      "iters_per_epoch",
      "start_epoch",
      "total_epochs",
      "warmup_epochs",
      "no_aug_epochs",
      "eval_interval_epochs",
      "ckpt_interval_epochs",
      "print_interval_iters"
    ],
    "build_optimizer": [
      "self",
      "momentum",
      "weight_decay"
    ],
    "train": [
      "self",
      "local_rank"
    ],
    "save_ckpt": [
      "self",
      "ckpt_name",
      "local_rank",
      "update_best_ckpt"
    ],
    "resume_model": [
      "self",
      "resume_path",
      "load_optimizer"
    ],
    "evaluate": [
      "self",
      "local_rank",
      "val_ann"
    ]
  },
  "NeRFReconAccTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "data_type",
      "use_mask",
      "max_step",
      "train_num_rays",
      "max_train_num_rays",
      "log_every_n_steps",
      "work_dir",
      "render_images",
      "save_ckpt",
      "frame_count",
      "use_distortion"
    ],
    "set_random_seed": [
      "self",
      "seed"
    ],
    "_override_params_from_file": [
      "self"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ],
    "render_video": [
      "self",
      "save_dir",
      "save_video_path"
    ],
    "save_image": [
      "self",
      "filename",
      "img"
    ],
    "save_video": [
      "self",
      "filename",
      "img_dir",
      "fps"
    ],
    "write_obj": [
      "self",
      "filename",
      "v_pos",
      "t_pos_idx",
      "v_tex",
      "t_tex_idx"
    ],
    "save_obj": [
      "self",
      "filename",
      "v_pos",
      "t_pos_idx",
      "v_tex",
      "t_tex_idx"
    ]
  },
  "OPTIMIZERS": [],
  "build_optimizer": [
    "model",
    "cfg",
    "default_args"
  ],
  "register_torch_optimizers": [],
  "calculate_fisher": [
    "model",
    "data_loader",
    "forward_step",
    "reserve_p",
    "grad_clip"
  ],
  "ChildTuningAdamW": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "correct_bias",
      "reserve_p",
      "mode"
    ],
    "set_gradient_mask": [
      "self",
      "gradient_mask"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "ANSTrainer": {
    "__init__": [
      "self"
    ],
    "train_loop": [
      "self",
      "data_loader"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs"
    ]
  },
  "KWSNearfieldTrainer": {
    "__init__": [
      "self",
      "model",
      "work_dir",
      "cfg_file",
      "arg_parse_fn",
      "model_revision"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ],
    "build_model": [
      "self",
      "configs"
    ],
    "init_dist": [
      "self",
      "train_nodes"
    ],
    "uninit_dist": [
      "self",
      "train_nodes"
    ]
  },
  "BASETRAIN_CONF_EASY": [],
  "BASETRAIN_CONF_NORMAL": [],
  "BASETRAIN_CONF_HARD": [],
  "FINETUNE_CONF_EASY": [],
  "FINETUNE_CONF_NORMAL": [],
  "FINETUNE_CONF_HARD": [],
  "CKPT_PREFIX": [],
  "EASY_RATIO": [],
  "NORMAL_RATIO": [],
  "HARD_RATIO": [],
  "BASETRAIN_RATIO": [],
  "KWSFarfieldTrainer": {
    "DEFAULT_WORK_DIR": [],
    "conf_keys": [],
    "__init__": [
      "self",
      "model",
      "work_dir",
      "cfg_file",
      "arg_parse_fn",
      "model_revision",
      "custom_conf"
    ],
    "build_model": [
      "self"
    ],
    "train": [
      "self"
    ],
    "run_stage": [
      "self",
      "stage",
      "epochs_to_run"
    ],
    "gen_val": [
      "self"
    ],
    "create_dataloader": [
      "self",
      "base_path",
      "finetune_path"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ],
    "_dump_log": [
      "self",
      "msg"
    ]
  },
  "KanttsTrainer": {
    "DATA_DIR": [],
    "AM_TMP_DIR": [],
    "VOC_TMP_DIR": [],
    "ORIG_MODEL_DIR": [],
    "__init__": [
      "self",
      "model",
      "work_dir",
      "speaker",
      "lang_type",
      "cfg_file",
      "train_dataset",
      "train_dataset_namespace",
      "train_dataset_revision",
      "train_type",
      "preprocess_skip_script",
      "model_revision"
    ],
    "parse_cfg": [
      "self",
      "cfg_file"
    ],
    "load_dataset_raw_path": [
      "self",
      "dataset"
    ],
    "prepare_data": [
      "self"
    ],
    "prepare_text": [
      "self"
    ],
    "get_model": [
      "self",
      "model_dir",
      "speaker"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "ASRTrainer": {
    "DATA_DIR": [],
    "__init__": [
      "self",
      "model",
      "work_dir",
      "distributed",
      "dataset_type",
      "data_dir",
      "model_revision",
      "batch_bins",
      "max_epoch",
      "lr",
      "mate_params"
    ],
    "parse_cfg": [
      "self",
      "cfg_file"
    ],
    "load_dataset_raw_path": [
      "self",
      "dataset",
      "output_data_dir"
    ],
    "prepare_data": [
      "self",
      "dataset",
      "out_base_dir",
      "split"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "EVAL_KEY": [],
  "SeparationTrainer": {
    "__init__": [
      "self",
      "model",
      "work_dir",
      "cfg_file",
      "train_dataset",
      "eval_dataset",
      "model_revision"
    ],
    "build_model": [
      "self"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "Separation": {
    "compute_forward": [
      "self",
      "mix",
      "targets",
      "stage",
      "noise"
    ],
    "compute_objectives": [
      "self",
      "predictions",
      "targets"
    ],
    "fit_batch": [
      "self",
      "batch"
    ],
    "evaluate_batch": [
      "self",
      "batch",
      "stage"
    ],
    "on_stage_end": [
      "self",
      "stage",
      "stage_loss",
      "epoch"
    ],
    "add_speed_perturb": [
      "self",
      "targets",
      "targ_lens"
    ],
    "cut_signals": [
      "self",
      "mixture",
      "targets"
    ],
    "reset_layer_recursively": [
      "self",
      "layer"
    ],
    "save_results": [
      "self",
      "test_data"
    ],
    "save_audio": [
      "self",
      "snt_id",
      "mixture",
      "targets",
      "predictions"
    ]
  },
  "symbol_str": [],
  "split_mixed_label": [
    "input_str"
  ],
  "space_mixed_label": [
    "input_str"
  ],
  "read_lists": [
    "list_file"
  ],
  "make_pair": [
    "wav_lists",
    "trans_lists"
  ],
  "read_token": [
    "token_file"
  ],
  "read_lexicon": [
    "lexicon_file"
  ],
  "query_token_set": [
    "txt",
    "symbol_table",
    "lexicon_table"
  ],
  "query_token_list": [
    "txt",
    "symbol_table",
    "lexicon_table"
  ],
  "tokenize": [
    "data_list",
    "symbol_table",
    "lexicon_table"
  ],
  "count_parameters": [
    "model"
  ],
  "average_model": [],
  "convert_to_kaldi": [
    "model",
    "network_file",
    "model_dir"
  ],
  "convert_to_pytorch": [
    "model",
    "network_file",
    "model_dir"
  ],
  "font": [],
  "thread_wrapper": {
    "__init__": [
      "self",
      "func",
      "args"
    ],
    "run": [
      "self"
    ],
    "get_result": [
      "self"
    ]
  },
  "count_duration": [
    "tid",
    "data_lists"
  ],
  "load_data_and_score": [
    "keywords_list",
    "data_file",
    "trans_file",
    "score_file"
  ],
  "load_stats_file": [
    "stats_file"
  ],
  "compute_det": [],
  "plot_det": [],
  "make_runtime_res": [
    "model_dir",
    "dest_path",
    "kaldi_text",
    "keywords"
  ],
  "executor_train": [
    "model",
    "optimizer",
    "data_loader",
    "device",
    "writer",
    "args"
  ],
  "executor_cv": [
    "model",
    "data_loader",
    "device",
    "args"
  ],
  "executor_test": [
    "model",
    "data_loader",
    "device",
    "keywords_token",
    "keywords_idxset",
    "args"
  ],
  "is_sublist": [
    "main_list",
    "check_list"
  ],
  "ctc_loss": [
    "logits",
    "target",
    "logits_lengths",
    "target_lengths",
    "need_acc"
  ],
  "acc_utterance": [
    "logits",
    "target",
    "logits_length",
    "target_length"
  ],
  "ctc_prefix_beam_search": [
    "logits",
    "logits_lengths",
    "keywords_tokenset",
    "score_beam_size",
    "path_beam_size"
  ],
  "Calculator": {
    "__init__": [
      "self"
    ],
    "calculate": [
      "self",
      "lab",
      "rec"
    ],
    "overall": [
      "self"
    ],
    "cluster": [
      "self",
      "data"
    ],
    "keys": [
      "self"
    ]
  },
  "LogBuffer": {
    "__init__": [
      "self"
    ],
    "clear": [
      "self"
    ],
    "clear_output": [
      "self"
    ],
    "update": [
      "self",
      "vars",
      "count"
    ],
    "average": [
      "self",
      "n"
    ]
  },
  "single_gpu_test": [
    "trainer",
    "data_loader",
    "device",
    "metric_classes",
    "vis_closure",
    "data_loader_iters"
  ],
  "multi_gpu_test": [
    "trainer",
    "data_loader",
    "device",
    "metric_classes",
    "vis_closure",
    "tmpdir",
    "gpu_collect",
    "data_loader_iters_per_gpu"
  ],
  "evaluate_batch": [
    "trainer",
    "data",
    "metric_classes",
    "vis_closure"
  ],
  "get_metric_values": [
    "metric_classes"
  ],
  "collect_results_cpu": [
    "result_part",
    "trainer",
    "tmpdir"
  ],
  "collect_results_gpu": [
    "result_part",
    "dp_group"
  ],
  "merge_metrics": [
    "metric_classes_list"
  ],
  "GroupCollator": {
    "get_gis": [
      "self",
      "gis",
      "inps"
    ],
    "__call__": [
      "self",
      "features"
    ]
  },
  "MGeoRankingTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "cfg_modify_fn",
      "arg_parse_fn",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "preprocessor",
      "optimizers",
      "model_revision"
    ]
  },
  "recursive_overwrite": [
    "src",
    "dst",
    "ignore"
  ],
  "construct_rdrop_sample": [
    "x"
  ],
  "kl_loss": [
    "p",
    "q"
  ],
  "label_smoothed_nll_loss": [
    "lprobs",
    "target",
    "epsilon",
    "update_num",
    "reduce",
    "drop_worst_ratio",
    "drop_worst_after",
    "use_rdrop",
    "reg_alpha",
    "constraint_masks",
    "constraint_start",
    "constraint_end"
  ],
  "AdjustLabelSmoothedCrossEntropyCriterion": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "update_num",
      "reduce"
    ],
    "get_lprobs_and_target": [
      "self",
      "logits",
      "sample"
    ],
    "compute_loss": [
      "self",
      "logits",
      "sample",
      "update_num",
      "reduce"
    ],
    "compute_ctc_loss": [
      "self",
      "model",
      "output",
      "sample"
    ]
  },
  "get_schedule": [
    "scheduler"
  ],
  "OFATrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "cfg_modify_fn",
      "arg_parse_fn",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "preprocessor",
      "optimizers",
      "model_revision",
      "seed"
    ],
    "rebuild_config": [
      "self",
      "cfg"
    ],
    "get_config_file": [
      "self",
      "config_file"
    ],
    "train_step": [
      "self",
      "model",
      "inputs"
    ]
  },
  "EfficientDiffusionTuningTrainer": {
    "__init__": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "build_optimizer": [
      "self",
      "cfg",
      "default_args"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self"
    ],
    "print_model_params_status": [
      "self",
      "model",
      "logger"
    ]
  },
  "PROMPT_TEMPLETE": [],
  "ConesCheckpointProcessor": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "save_checkpoints": [
      "self",
      "trainer",
      "checkpoint_path_prefix",
      "output_dir",
      "meta",
      "save_optimizers"
    ]
  },
  "ConesDiffusionTrainer": {
    "__init__": [
      "self"
    ],
    "build_optimizer": [
      "self",
      "cfg",
      "default_args"
    ],
    "train_step": [
      "self",
      "model",
      "inputs"
    ]
  },
  "unet_attn_processors_state_dict": [
    "unet"
  ],
  "LoraDiffusionXLCheckpointProcessor": {
    "__init__": [
      "self",
      "safe_serialization"
    ],
    "save_checkpoints": [
      "self",
      "trainer",
      "checkpoint_path_prefix",
      "output_dir",
      "meta",
      "save_optimizers"
    ]
  },
  "LoraDiffusionXLTrainer": {
    "__init__": [
      "self"
    ],
    "build_optimizer": [
      "self",
      "cfg",
      "default_args"
    ]
  },
  "MPlugTrainer": {
    "__init__": [
      "self"
    ],
    "build_model": [
      "self"
    ],
    "_decode": [
      "self",
      "tokens"
    ],
    "evaluation_step": [
      "self",
      "data"
    ]
  },
  "exclude": [
    "n"
  ],
  "include": [
    "n"
  ],
  "CLIPTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "cfg_modify_fn",
      "arg_parse_fn",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "preprocessor",
      "optimizers",
      "model_revision",
      "seed"
    ],
    "train_step": [
      "self",
      "model",
      "inputs"
    ]
  },
  "get_optimizer_params": [
    "model_name",
    "cfg"
  ],
  "get_loss": [
    "model_outputs",
    "loss_img",
    "loss_txt",
    "loss_cfg"
  ],
  "lr_lambda": [
    "num_warmup_steps",
    "num_training_steps",
    "num_cycles",
    "current_step"
  ],
  "train_transforms": [],
  "val_transforms": [],
  "train_mapping": [
    "examples"
  ],
  "val_mapping": [
    "examples"
  ],
  "get_params_groups": [
    "ddp_model",
    "lr"
  ],
  "get_optimizer": [
    "ddp_model"
  ],
  "TEAMImgClsTrainer": {
    "__init__": [
      "self",
      "cfg_file",
      "model",
      "device_id",
      "data_collator",
      "train_dataset",
      "val_dataset"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "CustomCheckpointProcessor": {
    "__init__": [
      "self",
      "modifier_token",
      "modifier_token_id",
      "torch_type",
      "safe_serialization"
    ],
    "save_checkpoints": [
      "self",
      "trainer",
      "checkpoint_path_prefix",
      "output_dir",
      "meta",
      "save_optimizers"
    ]
  },
  "CustomDiffusionDataset": {
    "__init__": [
      "self",
      "concepts_list",
      "tokenizer",
      "size",
      "mask_size",
      "center_crop",
      "with_prior_preservation",
      "num_class_images",
      "hflip",
      "aug"
    ],
    "__len__": [
      "self"
    ],
    "preprocess": [
      "self",
      "image",
      "scale",
      "resample"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "PromptDataset": {
    "__init__": [
      "self",
      "prompt",
      "num_samples"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "CustomDiffusionTrainer": {
    "__init__": [
      "self"
    ],
    "freeze_params": [
      "self",
      "params"
    ],
    "collate_fn": [
      "self",
      "examples"
    ],
    "generate_image": [
      "self"
    ],
    "build_optimizer": [
      "self",
      "cfg",
      "default_args"
    ],
    "train_loop": [
      "self",
      "data_loader"
    ],
    "train_step": [
      "self",
      "model",
      "inputs"
    ]
  },
  "DreamboothCheckpointProcessor": {
    "__init__": [
      "self",
      "model_dir",
      "torch_type",
      "safe_serialization"
    ],
    "save_checkpoints": [
      "self",
      "trainer",
      "checkpoint_path_prefix",
      "output_dir",
      "meta",
      "save_optimizers"
    ]
  },
  "ClassDataset": {
    "__init__": [
      "self",
      "tokenizer",
      "class_data_root",
      "class_prompt",
      "class_num_images",
      "size",
      "center_crop"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "DreamboothDiffusionTrainer": {
    "__init__": [
      "self"
    ],
    "build_optimizer": [
      "self",
      "cfg",
      "default_args"
    ],
    "train_step": [
      "self",
      "model",
      "inputs"
    ]
  },
  "LoraDiffusionCheckpointProcessor": {
    "__init__": [
      "self",
      "torch_type",
      "safe_serialization"
    ],
    "save_checkpoints": [
      "self",
      "trainer",
      "checkpoint_path_prefix",
      "output_dir",
      "meta",
      "save_optimizers"
    ]
  },
  "LoraDiffusionTrainer": {
    "__init__": [
      "self"
    ],
    "build_optimizer": [
      "self",
      "cfg",
      "default_args"
    ]
  },
  "SwiftDiffusionCheckpointProcessor": {
    "save_checkpoints": [
      "self",
      "trainer",
      "checkpoint_path_prefix",
      "output_dir",
      "meta",
      "save_optimizers"
    ]
  },
  "StableDiffusionTrainer": {
    "__init__": [
      "self"
    ],
    "build_optimizer": [
      "self",
      "cfg",
      "default_args"
    ]
  },
  "is_parallel": [
    "module"
  ],
  "PARALLEL": [],
  "build_parallel": [
    "cfg",
    "default_args"
  ],
  "LR_SCHEDULER": [],
  "build_lr_scheduler": [
    "cfg",
    "default_args"
  ],
  "register_torch_lr_scheduler": [],
  "BaseWarmup": {
    "__init__": [
      "self",
      "base_scheduler",
      "warmup_iters",
      "last_epoch",
      "verbose"
    ],
    "get_lr": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "scale": [
      "self"
    ],
    "step": [
      "self"
    ],
    "get_warmup_scale": [
      "self",
      "cur_iter"
    ]
  },
  "ConstantWarmup": {
    "__init__": [
      "self",
      "base_scheduler",
      "warmup_iters",
      "warmup_ratio",
      "last_epoch"
    ],
    "get_warmup_scale": [
      "self",
      "cur_iter"
    ]
  },
  "LinearWarmup": {
    "__init__": [
      "self",
      "base_scheduler",
      "warmup_iters",
      "warmup_ratio",
      "last_epoch"
    ],
    "get_warmup_scale": [
      "self",
      "cur_iter"
    ]
  },
  "ExponentialWarmup": {
    "__init__": [
      "self",
      "base_scheduler",
      "warmup_iters",
      "warmup_ratio",
      "last_epoch"
    ],
    "get_warmup_scale": [
      "self",
      "cur_iter"
    ]
  },
  "DocumentGroundedDialogRerankTrainer": {
    "__init__": [
      "self",
      "model",
      "dataset"
    ],
    "one_instance": [
      "self",
      "query",
      "passages"
    ],
    "limit_gpu_sequences_binary": [
      "self",
      "passages",
      "target_mask",
      "rand"
    ],
    "limit_gpu_sequences": [
      "self",
      "passages",
      "correctness",
      "rand"
    ],
    "passage_correctness": [
      "self",
      "pid",
      "positive_pids",
      "positive_dids"
    ],
    "train": [
      "self"
    ]
  },
  "Reporting": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "is_time": [
      "self"
    ],
    "moving_averages": [
      "self"
    ],
    "get_samples": [
      "self",
      "name"
    ],
    "get_moving_average": [
      "self",
      "name"
    ],
    "get_count": [
      "self",
      "name"
    ],
    "elapsed_seconds": [
      "self"
    ],
    "elapsed_time_str": [
      "self"
    ],
    "progress_str": [
      "self",
      "instance_name"
    ],
    "display": [
      "self"
    ],
    "display_warn": [
      "self"
    ]
  },
  "LossHistory": {
    "__init__": [
      "self",
      "one_epoch_batch_count"
    ],
    "note_loss": [
      "self",
      "loss_val"
    ]
  },
  "TransformerOptimize": {
    "__init__": [
      "self",
      "hypers",
      "num_instances_to_train_over",
      "model"
    ],
    "should_continue": [
      "self"
    ],
    "backward_on_loss": [
      "self",
      "loss"
    ],
    "optimizer_step": [
      "self"
    ],
    "step_loss": [
      "self",
      "loss"
    ]
  },
  "block_shuffle": [
    "iter"
  ],
  "save_transformer": [
    "hypers",
    "model",
    "tokenizer"
  ],
  "kofn": [
    "kofn"
  ],
  "set_seed": [
    "seed"
  ],
  "PlugTrainer": {
    "build_model": [
      "self"
    ],
    "to_parallel": [
      "self",
      "model"
    ],
    "_get_params_for_weight_decay_optimization": [
      "self",
      "module"
    ],
    "create_optimizer_and_scheduler": [
      "self"
    ],
    "_get_masks_and_position_ids": [
      "self",
      "data",
      "eod_token"
    ],
    "train_step": [
      "self",
      "model",
      "inputs"
    ],
    "evaluation_step": [
      "self",
      "data"
    ]
  },
  "PATH": [],
  "SiameseUIETrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "cfg_modify_fn",
      "train_dataset",
      "eval_dataset",
      "preprocessor",
      "optimizers",
      "model_revision",
      "seed",
      "negative_sampling_rate",
      "slide_len",
      "max_len",
      "hint_max_len"
    ],
    "build_dataset": [
      "self",
      "datasets",
      "model_cfg",
      "mode",
      "preprocessor"
    ],
    "get_train_dataloader": [
      "self"
    ],
    "get_brother_type_map": [
      "self",
      "schema",
      "brother_type_map",
      "prefix_types"
    ],
    "load_dataset": [
      "self",
      "raw_dataset"
    ],
    "_get_labels": [
      "self",
      "text",
      "tokenized_input",
      "offsets",
      "entities"
    ],
    "_padding": [
      "self",
      "data",
      "val"
    ],
    "_nn_collate_fn": [
      "self",
      "batch"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ],
    "get_metrics": [
      "self"
    ],
    "compute_metrics": [
      "self",
      "num_pred",
      "num_recall",
      "num_correct"
    ]
  },
  "SequenceClassificationTrainer": {
    "__init__": [
      "self",
      "cfg_file"
    ],
    "train": [
      "self"
    ],
    "__attr_is_exist": [
      "self",
      "attr"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "numpy_seed": [
    "seed"
  ],
  "EpisodeSampler": {
    "__init__": [
      "self",
      "dataset",
      "k_shot",
      "n_way",
      "r_query",
      "min_labels",
      "seed",
      "n_iter",
      "rank",
      "world_size"
    ],
    "__iter__": [
      "self"
    ],
    "_get_field": [
      "self",
      "obj",
      "key",
      "default"
    ],
    "remove_invalid_labels": [
      "self",
      "domain_label_sampleid"
    ],
    "get_bad_sampleids": [
      "self",
      "dataset"
    ],
    "__len__": [
      "self"
    ]
  },
  "FewShotCollator": {
    "__init__": [
      "self",
      "preprocessor",
      "k_shot"
    ],
    "_get_field": [
      "self",
      "obj",
      "key",
      "default"
    ],
    "__call__": [
      "self",
      "samples"
    ]
  },
  "FaqDataset": {
    "__init__": [
      "self",
      "data"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "__len__": [
      "self"
    ]
  },
  "FaqQuestionAnsweringTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "cfg_modify_fn",
      "arg_parse_fn",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "preprocessor",
      "optimizers",
      "model_revision",
      "seed"
    ],
    "max_iters": [
      "self"
    ],
    "inner_iter": [
      "self"
    ],
    "_build_dataloader_with_dataset": [
      "self",
      "dataset",
      "workers_per_gpu",
      "dist",
      "shuffle",
      "seed",
      "persistent_workers"
    ]
  },
  "GPTMoETrainer": {
    "rebuild_config": [
      "self",
      "cfg"
    ],
    "train_step": [
      "self",
      "model",
      "inputs"
    ],
    "_decode": [
      "self",
      "tokens"
    ],
    "evaluation_step": [
      "self",
      "data"
    ]
  },
  "TextGenerationTrainer": {
    "_decode": [
      "self",
      "tokens"
    ],
    "evaluation_step": [
      "self",
      "data"
    ],
    "_eval_genarate": [
      "self",
      "model",
      "data"
    ]
  },
  "CsanmtTranslationTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file"
    ],
    "_override_params_from_file": [
      "self"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "input_fn": [
    "src_file",
    "trg_file",
    "src_vocab_file",
    "trg_vocab_file",
    "num_buckets",
    "max_len",
    "batch_size",
    "batch_size_words",
    "num_gpus",
    "is_train",
    "session",
    "epoch"
  ],
  "get_pretrained_variables_map": [
    "checkpoint_file_path",
    "ignore_scope"
  ],
  "TableQuestionAnsweringTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file"
    ],
    "get_linear_schedule_with_warmup": [
      "self",
      "optimizer",
      "num_warmup_steps",
      "num_training_steps",
      "last_epoch"
    ],
    "get_wc1": [
      "self",
      "conds"
    ],
    "get_wo1": [
      "self",
      "conds"
    ],
    "get_wv1": [
      "self",
      "conds"
    ],
    "set_from_to": [
      "self",
      "data",
      "start",
      "end",
      "value"
    ],
    "get_g": [
      "self",
      "sql_i",
      "l_hs",
      "action"
    ],
    "get_g_wvi_bert_from_g_wvi_corenlp": [
      "self",
      "g_wvi_corenlp",
      "l_n",
      "idxs"
    ],
    "loss_scco": [
      "self",
      "s_cco",
      "g_cond_conn_op"
    ],
    "loss_sw_se": [
      "self",
      "s_action",
      "s_sc",
      "s_sa",
      "s_cco",
      "s_wc",
      "s_wo",
      "s_wvs",
      "g_sc",
      "g_sa",
      "g_wn",
      "g_wc",
      "g_wo",
      "g_wvi",
      "g_cond_conn_op",
      "g_slen",
      "g_wvp",
      "max_h_len",
      "s_len",
      "g_action"
    ],
    "sort_agg_sel": [
      "self",
      "aggs",
      "sels"
    ],
    "sort_conds": [
      "self",
      "nlu",
      "conds"
    ],
    "calculate_scores": [
      "self",
      "answers",
      "results",
      "epoch"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ],
    "train": [
      "self",
      "batch_size",
      "total_epoches",
      "backbone_learning_rate",
      "head_learning_rate",
      "backbone_weight_decay",
      "head_weight_decay",
      "warmup_ratio"
    ]
  },
  "SentenceEmbeddingCollator": {
    "max_length": [],
    "tokenizer": [],
    "__call__": [
      "self",
      "features"
    ]
  },
  "SentenceEmbeddingTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "cfg_modify_fn",
      "arg_parse_fn",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "preprocessor",
      "optimizers",
      "model_revision"
    ],
    "get_data_collator": [
      "self",
      "data_collator"
    ],
    "evauate": [
      "self"
    ]
  },
  "TranslationEvaluationTrainingSampler": {
    "__init__": [
      "self",
      "num_of_samples",
      "batch_size_for_each_input_format"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "convert_csv_dict_to_input": [
    "batch",
    "preprocessor"
  ],
  "data_collate_fn": [
    "batch",
    "batch_size",
    "preprocessor"
  ],
  "TranslationEvaluationTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "device"
    ],
    "build_optimizer": [
      "self",
      "cfg"
    ],
    "get_train_dataloader": [
      "self"
    ],
    "get_eval_data_loader": [
      "self"
    ],
    "evaluation_loop": [
      "self",
      "data_loader",
      "metric_classes"
    ]
  },
  "GPT3Trainer": {
    "rebuild_config": [
      "self",
      "cfg"
    ],
    "to_parallel": [
      "self",
      "model"
    ],
    "_decode": [
      "self",
      "tokens"
    ],
    "evaluation_step": [
      "self",
      "data"
    ],
    "_generate_eval": [
      "self",
      "model",
      "data"
    ],
    "_forward_eval": [
      "self",
      "model",
      "data"
    ],
    "build_model": [
      "self"
    ]
  },
  "TextRankingTrainer": {
    "__init__": [
      "self",
      "model",
      "cfg_file",
      "cfg_modify_fn",
      "arg_parse_fn",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "preprocessor",
      "optimizers",
      "model_revision"
    ],
    "compute_mrr": [
      "self",
      "result",
      "k"
    ],
    "compute_ndcg": [
      "self",
      "result",
      "k"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "collate": [
    "batch"
  ],
  "prepare_optimizer": [
    "model",
    "lr",
    "weight_decay",
    "eps"
  ],
  "prepare_scheduler": [
    "optimizer",
    "epochs",
    "steps_per_epoch",
    "warmup_rate"
  ],
  "measure_result": [
    "result_dict"
  ],
  "DocumentGroundedDialogRetrievalTrainer": {
    "__init__": [
      "self",
      "model",
      "revision"
    ],
    "train": [
      "self",
      "total_epoches",
      "batch_size",
      "per_gpu_batch_size",
      "accumulation_steps",
      "learning_rate",
      "warmup_ratio",
      "weight_decay",
      "eps",
      "loss_log_freq"
    ],
    "evaluate": [
      "self",
      "per_gpu_batch_size",
      "checkpoint_path"
    ]
  },
  "normalize_answer": [
    "s"
  ],
  "exact_match_score": [
    "prediction",
    "ground_truth"
  ],
  "metric_max_over_ground_truths": [
    "metric_fn",
    "prediction",
    "ground_truths"
  ],
  "matching_evaluate": [
    "references",
    "predictions"
  ],
  "DocumentGroundedDialogGenerateTrainer": {
    "__init__": [
      "self",
      "model",
      "revision"
    ],
    "train": [
      "self",
      "total_epoches",
      "batch_size",
      "accumulation_steps",
      "learning_rate",
      "warmup_ratio",
      "weight_decay",
      "eps",
      "loss_log_freq"
    ],
    "evaluate": [
      "self",
      "batch_size",
      "checkpoint_path"
    ]
  },
  "DialogIntentTrainer": {
    "__init__": [
      "self",
      "cfg_file",
      "cfg_modify_fn"
    ],
    "_load_model": [
      "self"
    ],
    "rebuild_config": [
      "self",
      "cfg"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "similar": [
    "a",
    "b"
  ],
  "setsub": [
    "a",
    "b"
  ],
  "setsim": [
    "a",
    "b"
  ],
  "DA_evaluate": [
    "preds",
    "labels"
  ],
  "BLEUScorer": {
    "__init__": [
      "self"
    ],
    "score": [
      "self",
      "parallel_corpus"
    ]
  },
  "MultiWOZEvaluator": {
    "__init__": [
      "self",
      "reader"
    ],
    "pack_dial": [
      "self",
      "data"
    ],
    "validation_metric": [
      "self",
      "data",
      "fout"
    ],
    "bleu_metric": [
      "self",
      "data",
      "eval_dial_list"
    ],
    "context_to_response_eval": [
      "self",
      "data",
      "eval_dial_list",
      "same_eval_as_cambridge",
      "fout"
    ],
    "_evaluateGeneratedDialogue": [
      "self",
      "dialog",
      "goal",
      "real_requestables",
      "counts",
      "soft_acc",
      "same_eval_as_cambridge",
      "fout"
    ],
    "_parseGoal": [
      "self",
      "goal",
      "true_goal",
      "domain"
    ]
  },
  "GenericEvaluator": {
    "__init__": [
      "self",
      "reader"
    ],
    "pack_dial": [
      "self",
      "data"
    ],
    "run_metrics": [
      "self",
      "results"
    ],
    "bleu_metric": [
      "self",
      "data",
      "type"
    ],
    "_normalize_constraint": [
      "self",
      "constraint",
      "ignore_dontcare",
      "intersection"
    ],
    "_normalize_act": [
      "self",
      "aspn",
      "intersection"
    ],
    "tracker_metric": [
      "self",
      "data",
      "normalize"
    ],
    "request_metric": [
      "self",
      "data"
    ],
    "act_metric": [
      "self",
      "data"
    ]
  },
  "CamRestEvaluator": {
    "__init__": [
      "self",
      "reader"
    ],
    "run_metrics": [
      "self",
      "results"
    ],
    "get_entities": [
      "self",
      "entity_path"
    ],
    "constraint_same": [
      "self",
      "truth_cons",
      "gen_cons"
    ],
    "match_metric": [
      "self",
      "data"
    ],
    "clean": [
      "self",
      "resp"
    ]
  },
  "KvretEvaluator": {
    "__init__": [
      "self",
      "reader"
    ],
    "run_metrics": [
      "self",
      "results"
    ],
    "_normalize_constraint": [
      "self",
      "constraint",
      "ignore_dontcare",
      "intersection"
    ],
    "get_entities": [
      "self",
      "entity_path"
    ],
    "constraint_same": [
      "self",
      "truth_cons",
      "gen_cons"
    ],
    "match_metric": [
      "self",
      "data"
    ],
    "clean": [
      "self",
      "resp"
    ]
  },
  "setup_seed": [
    "seed"
  ],
  "DialogModelingTrainer": {
    "__init__": [
      "self",
      "cfg_file",
      "cfg_modify_fn"
    ],
    "_load_model": [
      "self"
    ],
    "rebuild_config": [
      "self",
      "cfg"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self",
      "checkpoint_path"
    ]
  },
  "MetricsTracker": {
    "__init__": [
      "self"
    ],
    "update": [
      "self",
      "metrics",
      "num_samples"
    ],
    "clear": [
      "self"
    ],
    "items": [
      "self"
    ],
    "get": [
      "self",
      "name"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "value": [
      "self"
    ],
    "summary": [
      "self"
    ]
  },
  "Trainer": {
    "__init__": [
      "self",
      "model",
      "to_tensor",
      "config",
      "logger",
      "lr_scheduler",
      "optimizer",
      "reader",
      "evaluator"
    ],
    "decode_generated_bspn_resp": [
      "self",
      "generated"
    ],
    "decode_generated_act_resp": [
      "self",
      "generated"
    ],
    "decode_generated_bspn": [
      "self",
      "generated"
    ],
    "set_optimizers": [
      "self"
    ],
    "train": [
      "self",
      "train_data",
      "dev_data"
    ],
    "train_epoch": [
      "self",
      "train_data",
      "dev_data"
    ],
    "infer": [
      "self",
      "data_type"
    ],
    "save": [
      "self",
      "is_best"
    ],
    "load": [
      "self"
    ]
  },
  "MultiWOZTrainer": {
    "__init__": [
      "self",
      "model",
      "to_tensor",
      "config",
      "logger",
      "lr_scheduler",
      "optimizer",
      "reader",
      "evaluator"
    ],
    "train_epoch": [
      "self",
      "train_data",
      "dev_data"
    ],
    "infer": [
      "self",
      "data_type"
    ],
    "_get_turn_domain": [
      "self",
      "old_pv_turn",
      "bspn_gen_ids",
      "first_turn"
    ],
    "forward": [
      "self",
      "first_turn",
      "batch",
      "prompt_id",
      "labels",
      "old_pv_turn"
    ]
  },
  "IntentTrainer": {
    "__init__": [
      "self",
      "model",
      "to_tensor",
      "config",
      "reader"
    ],
    "can_normalization": [
      "self",
      "y_pred",
      "y_true",
      "ex_data_iter"
    ],
    "train_epoch": [
      "self",
      "train_label_iter",
      "train_nolabel_iter",
      "valid_label_iter",
      "valid_nolabel_iter"
    ],
    "forward": [
      "self",
      "batch"
    ],
    "infer": [
      "self",
      "data_iter",
      "num_batches",
      "ex_data_iter"
    ],
    "track_and_log_message": [
      "self",
      "metrics",
      "batch_id",
      "batch_size",
      "num_batches",
      "times",
      "with_label"
    ],
    "save_and_log_message": [
      "self",
      "report_for_unlabeled_data",
      "cur_valid_metric"
    ],
    "balance_metrics": [
      "self",
      "metrics",
      "batch_size"
    ]
  },
  "IterTimerHook": {
    "PRIORITY": [],
    "before_epoch": [
      "self",
      "trainer"
    ],
    "before_iter": [
      "self",
      "trainer"
    ],
    "after_iter": [
      "self",
      "trainer"
    ]
  },
  "LrSchedulerProcessor": {
    "__init__": [
      "self"
    ],
    "set_lr_strategy": [
      "self",
      "lr_strategy"
    ],
    "set_warmup_lr_scheduler": [
      "self",
      "warmup_lr_scheduler"
    ],
    "initialize_lr_scheduler": [
      "self",
      "trainer"
    ],
    "step": [
      "self",
      "trainer"
    ],
    "get_current_lr": [
      "self",
      "trainer"
    ]
  },
  "LrStrategy": {
    "by_epoch": [],
    "by_step": [],
    "no": []
  },
  "LrSchedulerHook": {
    "PRIORITY": [],
    "__init__": [
      "self",
      "lr_strategy",
      "warmup"
    ],
    "set_processor": [
      "self",
      "processor"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "after_train_iter": [
      "self",
      "trainer"
    ],
    "before_train_epoch": [
      "self",
      "trainer"
    ],
    "after_train_epoch": [
      "self",
      "trainer"
    ],
    "_get_log_lr": [
      "self",
      "trainer"
    ]
  },
  "PlateauLrSchedulerProcessor": {
    "__init__": [
      "self",
      "metric_key"
    ],
    "step": [
      "self",
      "trainer"
    ]
  },
  "PlateauLrSchedulerHook": {
    "PRIORITY": [],
    "__init__": [
      "self",
      "metric_key"
    ],
    "register_processor": [
      "self",
      "trainer"
    ],
    "before_run": [
      "self",
      "trainer"
    ]
  },
  "NoneLrSchedulerHook": {
    "PRIORITY": [],
    "__init__": [
      "self",
      "by_epoch",
      "warmup"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "after_train_epoch": [
      "self",
      "trainer"
    ]
  },
  "Hook": {
    "stages": [],
    "PRIORITY": [],
    "after_init": [
      "self",
      "trainer"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "after_run": [
      "self",
      "trainer"
    ],
    "before_val": [
      "self",
      "trainer"
    ],
    "after_val": [
      "self",
      "trainer"
    ],
    "before_epoch": [
      "self",
      "trainer"
    ],
    "after_epoch": [
      "self",
      "trainer"
    ],
    "before_iter": [
      "self",
      "trainer"
    ],
    "after_iter": [
      "self",
      "trainer"
    ],
    "before_train_epoch": [
      "self",
      "trainer"
    ],
    "before_val_epoch": [
      "self",
      "trainer"
    ],
    "after_train_epoch": [
      "self",
      "trainer"
    ],
    "after_val_epoch": [
      "self",
      "trainer"
    ],
    "before_train_iter": [
      "self",
      "trainer"
    ],
    "before_val_iter": [
      "self",
      "trainer"
    ],
    "after_train_iter": [
      "self",
      "trainer"
    ],
    "after_val_iter": [
      "self",
      "trainer"
    ],
    "every_n_epochs": [
      "trainer",
      "n"
    ],
    "every_n_inner_iters": [
      "runner",
      "n"
    ],
    "every_n_iters": [
      "trainer",
      "n"
    ],
    "end_of_epoch": [
      "trainer"
    ],
    "is_last_epoch": [
      "trainer"
    ],
    "is_last_iter": [
      "trainer"
    ],
    "get_triggered_stages": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "ClipClampLogitScaleHook": {
    "after_train_iter": [
      "self",
      "trainer"
    ]
  },
  "EvaluationStrategy": {
    "by_epoch": [],
    "by_step": [],
    "no": []
  },
  "EvaluationHook": {
    "__init__": [
      "self",
      "interval",
      "eval_strategy",
      "start_idx"
    ],
    "after_train_iter": [
      "self",
      "trainer"
    ],
    "after_train_epoch": [
      "self",
      "trainer"
    ],
    "add_visualization_info": [
      "self",
      "trainer",
      "results"
    ],
    "do_evaluate": [
      "self",
      "trainer"
    ],
    "_should_evaluate": [
      "self",
      "trainer"
    ]
  },
  "HOOKS": [],
  "build_hook": [
    "cfg",
    "default_args"
  ],
  "EarlyStopStrategy": {
    "by_epoch": [],
    "by_step": [],
    "no": []
  },
  "EarlyStopHook": {
    "PRIORITY": [],
    "rule_map": [],
    "__init__": [
      "self",
      "metric_key",
      "rule",
      "patience",
      "min_delta",
      "check_finite",
      "early_stop_strategy",
      "interval"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "_should_stop": [
      "self",
      "trainer"
    ],
    "_stop_training": [
      "self",
      "trainer"
    ],
    "after_train_epoch": [
      "self",
      "trainer"
    ],
    "after_train_iter": [
      "self",
      "trainer"
    ]
  },
  "Priority": {
    "HIGHEST": [],
    "VERY_HIGH": [],
    "HIGH": [],
    "ABOVE_NORMAL": [],
    "NORMAL": [],
    "BELOW_NORMAL": [],
    "LOW": [],
    "VERY_LOW": [],
    "LOWEST": []
  },
  "get_priority": [
    "priority"
  ],
  "LoggerHook": {
    "__metaclass__": [],
    "PRIORITY": [],
    "__init__": [
      "self",
      "interval",
      "ignore_last",
      "reset_flag",
      "by_epoch"
    ],
    "log": [
      "self",
      "trainer"
    ],
    "is_scalar": [
      "val",
      "include_np",
      "include_torch"
    ],
    "fetch_tensor": [
      "self",
      "trainer",
      "n"
    ],
    "get_epoch": [
      "self",
      "trainer"
    ],
    "get_iter": [
      "self",
      "trainer",
      "inner_iter"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "before_epoch": [
      "self",
      "trainer"
    ],
    "after_train_iter": [
      "self",
      "trainer"
    ],
    "after_train_epoch": [
      "self",
      "trainer"
    ],
    "after_val_epoch": [
      "self",
      "trainer"
    ]
  },
  "TensorboardHook": {
    "__init__": [
      "self",
      "out_dir",
      "interval",
      "ignore_last",
      "reset_flag",
      "by_epoch",
      "skip_keys"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "log": [
      "self",
      "trainer"
    ],
    "visualization_log": [
      "self",
      "trainer"
    ],
    "after_train_iter": [
      "self",
      "trainer"
    ],
    "after_run": [
      "self",
      "trainer"
    ]
  },
  "TextLoggerHook": {
    "__init__": [
      "self",
      "by_epoch",
      "interval",
      "ignore_last",
      "reset_flag",
      "out_dir",
      "ignore_rounding_keys",
      "rounding_digits"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "_get_max_memory": [
      "self",
      "trainer"
    ],
    "_log_info": [
      "self",
      "log_dict",
      "trainer"
    ],
    "_dump_log": [
      "self",
      "log_dict"
    ],
    "_round_float": [
      "self",
      "items",
      "ndigits"
    ],
    "log": [
      "self",
      "trainer"
    ]
  },
  "SwiftCheckpointProcessor": {
    "_BIN_FILE_DIR": [],
    "SWIFT_SAVE_SUFFIX": [],
    "copy_files_and_dump_config": [
      "trainer",
      "output_dir",
      "config",
      "bin_file"
    ],
    "link_dir": [
      "self",
      "source_dir",
      "output_dir"
    ],
    "save_swift_model_state": [
      "self",
      "model",
      "filename"
    ],
    "save_checkpoints": [
      "self",
      "trainer",
      "checkpoint_path_prefix",
      "output_dir",
      "meta",
      "save_optimizers"
    ]
  },
  "SwiftHook": {
    "_BIN_FILE_DIR": [],
    "__init__": [
      "self"
    ],
    "register_processor": [
      "self",
      "trainer"
    ]
  },
  "OptimizerProcessor": {
    "initialize_optimizer": [
      "self",
      "trainer"
    ],
    "before_forward": [
      "self",
      "trainer"
    ],
    "backward": [
      "self",
      "trainer",
      "loss_keys",
      "cumulative_iters",
      "grad_clip"
    ],
    "clip_grads": [
      "params"
    ]
  },
  "OptimizerHook": {
    "PRIORITY": [],
    "__init__": [
      "self",
      "cumulative_iters",
      "grad_clip",
      "loss_keys"
    ],
    "set_processor": [
      "self",
      "processor"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "before_train_iter": [
      "self",
      "trainer"
    ],
    "after_train_iter": [
      "self",
      "trainer"
    ]
  },
  "NoneOptimizerHook": {
    "__init__": [
      "self",
      "cumulative_iters",
      "grad_clip",
      "loss_keys"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "after_train_iter": [
      "self",
      "trainer"
    ]
  },
  "ApexOptimizerProcessor": {
    "__init__": [
      "self",
      "opt_level"
    ],
    "initialize_optimizer": [
      "self",
      "trainer"
    ],
    "backward": [
      "self",
      "trainer",
      "loss_keys",
      "cumulative_iters",
      "grad_clip"
    ]
  },
  "ApexAMPOptimizerHook": {
    "PRIORITY": [],
    "__init__": [
      "self",
      "opt_level"
    ],
    "register_processor": [
      "self",
      "trainer"
    ]
  },
  "TorchAMPOptimizerProcessor": {
    "__init__": [
      "self",
      "scaler",
      "scale_update_param"
    ],
    "before_forward": [
      "self",
      "trainer"
    ],
    "initialize_optimizer": [
      "self",
      "trainer"
    ],
    "backward": [
      "self",
      "trainer",
      "loss_keys",
      "cumulative_iters",
      "grad_clip"
    ]
  },
  "TorchAMPOptimizerHook": {
    "PRIORITY": [],
    "__init__": [
      "self",
      "loss_scale"
    ],
    "register_processor": [
      "self",
      "trainer"
    ]
  },
  "SparseBinarizer": {
    "forward": [
      "ctx",
      "mask_scores",
      "sparsity"
    ],
    "backward": [
      "ctx",
      "gradOutput"
    ]
  },
  "SparseLinear": {
    "__init__": [
      "self",
      "module",
      "pruning_method",
      "weight_rank",
      "weight_beta",
      "mask_rank",
      "mask_alpha1",
      "mask_alpha2"
    ],
    "forward": [
      "self"
    ],
    "convert": [
      "self"
    ]
  },
  "_setattr": [
    "model",
    "name",
    "module"
  ],
  "convert_sparse_network": [
    "model",
    "pruning_method",
    "weight_rank",
    "weight_beta",
    "mask_rank",
    "mask_alpha1",
    "mask_alpha2",
    "logger"
  ],
  "update_network_sparsity": [
    "model",
    "sparsity"
  ],
  "schedule_sparsity_ratio": [
    "step",
    "total_step",
    "frequency",
    "initial_warmup",
    "final_warmup",
    "initial_sparsity",
    "final_sparsity"
  ],
  "generate_sparse_model": [
    "model",
    "logger"
  ],
  "SparsityHook": {
    "PRIORITY": [],
    "__init__": [
      "self",
      "pruning_method",
      "config",
      "save_dir"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "before_train_iter": [
      "self",
      "trainer"
    ],
    "after_run": [
      "self",
      "trainer"
    ],
    "_save_checkpoint": [
      "self",
      "trainer"
    ]
  },
  "MpuProcessor": {
    "_BIN_FILE_DIR": [],
    "rank_name": [
      "self"
    ],
    "get_bin_filename": [
      "self"
    ],
    "should_save_on_rank": [
      "self",
      "trainer"
    ],
    "prepare_output": [
      "self",
      "trainer",
      "output_dir"
    ],
    "save_checkpoints": [
      "self",
      "trainer",
      "checkpoint_path_prefix",
      "output_dir",
      "meta",
      "save_optimizers"
    ],
    "remove_checkpoints": [
      "self",
      "trainer",
      "checkpoint_path_prefix"
    ],
    "load_checkpoints": [
      "self",
      "checkpoint_path_prefix",
      "trainer",
      "load_all_state",
      "strict"
    ]
  },
  "MegatronHook": {
    "_BIN_FILE_DIR": [],
    "__init__": [
      "self"
    ],
    "register_processor": [
      "self",
      "trainer"
    ],
    "after_init": [
      "self",
      "trainer"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "before_val": [
      "self",
      "trainer"
    ],
    "wrap_module": [
      "self",
      "trainer"
    ]
  },
  "DDPHook": {
    "PRIORITY": [],
    "__init__": [
      "self",
      "launcher"
    ],
    "after_init": [
      "self",
      "trainer"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "before_val": [
      "self",
      "trainer"
    ],
    "wrap_module": [
      "self",
      "trainer"
    ]
  },
  "DeepSpeedConfig": {
    "is_auto": [
      "self",
      "ds_key_long"
    ],
    "trainer_config_finalize": [
      "self",
      "args",
      "model",
      "num_training_steps"
    ]
  },
  "deepspeed_optim_sched": [
    "trainer",
    "hf_deepspeed_config",
    "num_training_steps"
  ],
  "DeepspeedProcessor": {
    "_BIN_FILE_DIR": [],
    "rank_name": [
      "self"
    ],
    "get_bin_filename": [
      "self",
      "with_mpu"
    ],
    "save_checkpoints": [
      "self",
      "trainer",
      "checkpoint_path_prefix",
      "output_dir",
      "meta",
      "save_optimizers"
    ],
    "remove_checkpoints": [
      "self",
      "trainer",
      "checkpoint_path_prefix"
    ],
    "load_checkpoints": [
      "self",
      "checkpoint_path_prefix",
      "trainer",
      "load_all_state",
      "strict"
    ],
    "backward": [
      "self",
      "trainer",
      "loss_keys",
      "cumulative_iters",
      "grad_clip"
    ],
    "initialize_optimizer": [
      "self",
      "trainer"
    ],
    "step": [
      "self",
      "trainer"
    ],
    "should_save_on_rank": [
      "self",
      "trainer"
    ],
    "get_current_lr": [
      "self",
      "trainer"
    ]
  },
  "DeepspeedHook": {
    "PRIORITY": [],
    "__init__": [
      "self",
      "config",
      "deepspeed_activation_checkpointing",
      "save_zero_checkpoint",
      "with_mpu",
      "zero_stage"
    ],
    "register_processor": [
      "self",
      "trainer"
    ],
    "prepare_args": [
      "self",
      "args"
    ],
    "get_deepspeed_config": [
      "self",
      "trainer",
      "args",
      "max_steps"
    ],
    "after_init": [
      "self",
      "trainer"
    ],
    "before_val": [
      "self",
      "trainer"
    ],
    "before_run": [
      "self",
      "trainer"
    ]
  },
  "LoadCheckpointHook": {
    "PRIORITY": [],
    "_should_save": [],
    "_TWO_PTH_FILE_VERSION": [],
    "__init__": [
      "self",
      "checkpoint_file",
      "load_all_state",
      "strict"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "before_train_iter": [
      "self",
      "trainer"
    ],
    "_restore_training_state": [
      "trainer",
      "meta"
    ],
    "load_checkpoint": [
      "cls",
      "filename",
      "trainer",
      "load_all_state",
      "strict"
    ]
  },
  "CheckpointProcessor": {
    "TRAINER_STATE_SUFFIX": [],
    "MODEL_STATE_SUFFIX": [],
    "prepare_output": [
      "self",
      "trainer",
      "output_dir"
    ],
    "copy_files_and_dump_config": [
      "trainer",
      "output_dir",
      "config",
      "bin_file"
    ],
    "_bin_file": [
      "model"
    ],
    "save_checkpoints": [
      "self",
      "trainer",
      "checkpoint_path_prefix",
      "output_dir",
      "meta",
      "save_optimizers"
    ],
    "remove_checkpoints": [
      "self",
      "trainer",
      "checkpoint_path_prefix"
    ],
    "should_save_on_rank": [
      "self",
      "trainer"
    ],
    "link": [
      "self",
      "model",
      "src_file",
      "output_dir"
    ],
    "save_trainer_state": [
      "self",
      "trainer",
      "model",
      "train_state_file",
      "meta",
      "save_optimizers"
    ],
    "save_model_state": [
      "self",
      "model",
      "model_file"
    ],
    "load_checkpoints": [
      "self",
      "checkpoint_path_prefix",
      "trainer",
      "load_all_state",
      "strict"
    ],
    "load_trainer_state": [
      "trainer",
      "train_state_file",
      "load_all_state"
    ],
    "load_model_state": [
      "self",
      "trainer",
      "model_file",
      "strict"
    ],
    "_get_state_file_name": [
      "checkpoint_path_prefix"
    ]
  },
  "CheckpointStrategy": {
    "by_epoch": [],
    "by_step": [],
    "no": []
  },
  "CheckpointHook": {
    "PRIORITY": [],
    "EVAL_RESULT_FILE": [],
    "PUSH_TO_HUB_QUEUE_NAME": [],
    "__init__": [
      "self",
      "save_strategy",
      "interval",
      "save_dir",
      "output_dir",
      "save_last",
      "max_checkpoint_num",
      "push_to_hub",
      "hub_repo_id",
      "hub_token",
      "private_hub",
      "hub_revision",
      "upload_strategy",
      "save_trainer_state"
    ],
    "set_processor": [
      "self",
      "processor"
    ],
    "before_run": [
      "self",
      "trainer"
    ],
    "generate_prefix": [
      "self",
      "trainer",
      "save_strategy"
    ],
    "_do_save": [
      "self",
      "trainer",
      "save_strategy"
    ],
    "after_train_epoch": [
      "self",
      "trainer"
    ],
    "after_train_iter": [
      "self",
      "trainer"
    ],
    "after_run": [
      "self",
      "trainer"
    ],
    "_push_to_hub": [
      "self",
      "trainer",
      "prefix",
      "output_dir",
      "delete_dir"
    ],
    "save_evaluate_results": [
      "self",
      "trainer"
    ],
    "_save_checkpoint": [
      "self",
      "trainer",
      "prefix"
    ],
    "_remove_obsolete_checkpoints": [
      "self",
      "trainer"
    ],
    "_should_save": [
      "self",
      "trainer"
    ],
    "_create_training_state": [
      "self",
      "trainer"
    ]
  },
  "BestCkptSaverHook": {
    "PRIORITY": [],
    "rule_map": [],
    "__init__": [
      "self",
      "metric_key",
      "save_best",
      "rule",
      "save_file_name",
      "restore_best",
      "max_checkpoint_num",
      "save_trainer_state"
    ],
    "after_train_epoch": [
      "self",
      "trainer"
    ],
    "after_train_iter": [
      "self",
      "trainer"
    ],
    "_should_save": [
      "self",
      "trainer"
    ],
    "_is_best_metric": [
      "self",
      "metric_values"
    ],
    "generate_prefix": [
      "self",
      "trainer",
      "save_strategy"
    ],
    "_save_checkpoint": [
      "self",
      "trainer",
      "prefix"
    ],
    "_remove_obsolete_checkpoints": [
      "self",
      "trainer"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "after_run": [
      "self",
      "trainer"
    ]
  },
  "Input": [],
  "InputModel": [],
  "Pipeline": {
    "initiate_single_model": [
      "self",
      "model"
    ],
    "initiate_multiple_models": [
      "self",
      "input_models"
    ],
    "__init__": [
      "self",
      "config_file",
      "model",
      "preprocessor",
      "device",
      "auto_collate",
      "device_map"
    ],
    "check_trust_remote_code": [
      "self",
      "info_str",
      "model_dir"
    ],
    "prepare_model": [
      "self"
    ],
    "_get_framework": [
      "self"
    ],
    "__call__": [
      "self",
      "input"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "_process_iterator": [
      "self",
      "input"
    ],
    "_collate_fn": [
      "self",
      "data"
    ],
    "_process_single": [
      "self",
      "input"
    ],
    "_batch": [
      "self",
      "data_list"
    ],
    "_process_batch": [
      "self",
      "input",
      "batch_size"
    ],
    "_check_input": [
      "self",
      "input"
    ],
    "_check_output": [
      "self",
      "input"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "DistributedPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "auto_collate"
    ],
    "__del__": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "_instantiate_one": [
      "cls",
      "rank",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "_forward_one": [
      "cls",
      "inputs"
    ],
    "_get_world_size": [
      "self",
      "cfg"
    ]
  },
  "PipelineTemplate": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input",
      "max_length",
      "top_p"
    ],
    "forward": [
      "self",
      "input",
      "max_length",
      "top_p"
    ],
    "postprocess": [
      "self",
      "inputs",
      "postprocess_param1"
    ]
  },
  "PIPELINES": [],
  "normalize_model_input": [
    "model",
    "model_revision",
    "third_party",
    "ignore_file_pattern"
  ],
  "build_pipeline": [
    "cfg",
    "task_name",
    "default_args"
  ],
  "pipeline": [
    "task",
    "model",
    "preprocessor",
    "config_file",
    "pipeline_name",
    "framework",
    "device",
    "model_revision",
    "ignore_file_pattern"
  ],
  "add_default_pipeline_info": [
    "task",
    "model_name",
    "modelhub_name",
    "overwrite"
  ],
  "get_default_pipeline_info": [
    "task"
  ],
  "external_engine_for_llm_checker": [
    "model",
    "revision",
    "kwargs"
  ],
  "clear_llm_info": [
    "kwargs",
    "pipeline_name"
  ],
  "is_config_has_model": [
    "cfg_file"
  ],
  "is_official_hub_path": [
    "path",
    "revision"
  ],
  "is_model": [
    "path"
  ],
  "batch_process": [
    "model",
    "data"
  ],
  "CardDetectionCorrection": {
    "__init__": [
      "self",
      "model",
      "device",
      "device_map"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "distance": [
      "self",
      "x1",
      "y1",
      "x2",
      "y2"
    ],
    "crop_image": [
      "self",
      "img",
      "position"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageDepthEstimationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageDebandingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "SelfSupervisedDepthCompletionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageStyleTransferPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "preprocess": [
      "self",
      "content",
      "style"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "HeadReconstructionPipeline": {
    "__init__": [
      "self",
      "model",
      "device",
      "hair_tex"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "align_img": [
      "self",
      "img",
      "lm",
      "lm3D",
      "mask",
      "target_size",
      "rescale_factor"
    ],
    "read_data": [
      "self",
      "img",
      "lm",
      "lm3d_std",
      "to_tensor",
      "image_res",
      "img_fat",
      "head_mask",
      "rescale_factor"
    ],
    "prepare_data": [
      "self",
      "img",
      "lm_sess",
      "five_points"
    ],
    "infer_lmks": [
      "self",
      "img_bgr"
    ],
    "find_face_contour": [
      "self",
      "image"
    ],
    "fat_face": [
      "self",
      "img",
      "degree"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoPanopticSegmentationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoColorizationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageFaceFusionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "template",
      "user"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "IndoorLayoutEstimationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImagePortraitEnhancementPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "enhance_face": [
      "self",
      "img"
    ],
    "img2tensor": [
      "self",
      "img",
      "is_norm"
    ],
    "tensor2img": [
      "self",
      "img_t",
      "pmax",
      "is_denorm",
      "imtype"
    ],
    "sr_process": [
      "self",
      "img"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FaceReconstructionPipeline": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "read_data": [
      "self",
      "img",
      "lm",
      "lm3d_std",
      "to_tensor",
      "image_res"
    ],
    "parse_label": [
      "self",
      "label"
    ],
    "prepare_data": [
      "self",
      "img",
      "lm_sess",
      "five_points"
    ],
    "get_img_for_texture": [
      "self",
      "input_img_tensor"
    ],
    "infer_lmks": [
      "self",
      "img_bgr"
    ],
    "find_face_contour": [
      "self",
      "image"
    ],
    "fat_face": [
      "self",
      "img",
      "degree"
    ],
    "predict_base": [
      "self",
      "img"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "HICOSSLVideoEmbeddingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "perform_inference": [
      "self",
      "data",
      "max_bsz"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "NeRFReconVQCompressionPipeline": {
    "__init__": [
      "self",
      "model",
      "dataset_name",
      "data_dir",
      "downsample",
      "ndc_ray",
      "ckpt_path",
      "device"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VIDEO_EXTENSIONS": [],
  "tensor2img": [
    "tensor",
    "out_type",
    "min_max"
  ],
  "VideoSuperResolutionPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "SkinRetouchingPipeline": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "retouch_local": [
      "self",
      "image"
    ],
    "predict_roi": [
      "self",
      "roi",
      "degree",
      "smooth_border",
      "return_mg"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FaceQualityAssessmentPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "_batch": [
      "self",
      "data"
    ],
    "load_onnx_model": [
      "self",
      "onnx_path"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "RetinaFaceDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FacialExpressionRecognitionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "RBOX_DIM": [],
  "OFFSET_DIM": [],
  "WORD_POLYGON_DIM": [],
  "OFFSET_VARIANCE": [],
  "TF_NODE_THRESHOLD": [],
  "TF_LINK_THRESHOLD": [],
  "OCRDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "input"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoDeinterlacePipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "HandStaticPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FaceRecognitionOodPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageSkychangePipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TextDrivenSegmentationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageHumanParsingPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_get_preprocess_shape": [
      "self",
      "oldh",
      "oldw",
      "short_edge_length",
      "max_size"
    ],
    "preprocess": [
      "self",
      "input",
      "min_size",
      "max_size"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs",
      "score_thr"
    ]
  },
  "ImageNormalEstimationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FaceRecognitionOnnxIrPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "load_onnx_model": [
      "self",
      "onnx_path"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "LanguageGuidedVideoSummarizationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "inference": [
      "self",
      "clip_image_features",
      "clip_txt_features",
      "n_frames",
      "picks",
      "change_points"
    ],
    "sample_txt_feateures": [
      "self",
      "feat",
      "num"
    ],
    "norm_feature": [
      "self",
      "frames_feat"
    ]
  },
  "FaceLandmarkDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageOpenVocabularyDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "CrowdCountingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "resize": [
      "self",
      "img"
    ],
    "merge_crops": [
      "self",
      "eval_shape",
      "eval_p",
      "pred_m"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "perform_inference": [
      "self",
      "data"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "HumanNormalEstimationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImagePanopticSegmentationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TableRecognitionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageBTSDepthEstimationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FaceRecognitionPipeline": {
    "__init__": [
      "self",
      "model",
      "use_det"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageQualityAssessmentMANPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageLocalFeatureMatchingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "load_image": [
      "self",
      "img_name"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "GeneralImageClassificationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "_batch": [
      "self",
      "data"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageInpaintingPipeline": {
    "__init__": [
      "self",
      "model",
      "pad_out_to_modulo",
      "refine"
    ],
    "move_to_device": [
      "self",
      "obj",
      "device"
    ],
    "transforms": [
      "self",
      "img"
    ],
    "ceil_modulo": [
      "self",
      "x",
      "mod"
    ],
    "pad_img_to_modulo": [
      "self",
      "img",
      "mod"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "perform_inference": [
      "self",
      "data"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FaceLivenessXcPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "load_onnx_model": [
      "self",
      "onnx_path"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "MogFaceDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "DenseOpticalFlowEstimationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "load_image": [
      "self",
      "img_name"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoMultiObjectTrackingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "DDPMImageSemanticSegmentationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "OCRRecognitionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "input"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VopRetrievalSEPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImagePaintbyexamplePipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "get_tensor": [
      "self",
      "normalize",
      "toTensor"
    ],
    "get_tensor_clip": [
      "self",
      "normalize",
      "toTensor"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "perform_inference": [
      "self",
      "test_model_kwargs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FaceImageGenerationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageMattingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageDrivingPerceptionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "PanoramaDepthEstimationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "CardDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "input"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageMatchingFastPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "load_image": [
      "self",
      "img_name"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "ImageQualityAssessmentDegradationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "GeneralRecognitionPipeline": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ProductRetrievalEmbeddingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FaceDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "input"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageMatchingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "resize_image": [
      "self",
      "img",
      "max_image_size"
    ],
    "compute_paded_size": [
      "self",
      "size",
      "div"
    ],
    "pad_image": [
      "self",
      "img",
      "h",
      "w",
      "div"
    ],
    "load_image": [
      "self",
      "img_name"
    ],
    "preprocess": [
      "self",
      "input",
      "max_image_size"
    ],
    "postprocess_match": [
      "self",
      "kpt1",
      "kpt2",
      "conf",
      "scale1",
      "scale2",
      "scaled_h1",
      "scaled_w1",
      "scaled_h2",
      "scaled_w2"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "AnimalRecognitionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ContentCheckPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "LinelessTableRecognitionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoInstanceSegmentationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "MtcnnFaceDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageColorEnhancePipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "Text2360PanoramaImagePipeline": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "blend_h": [
      "a",
      "b",
      "blend_extent"
    ],
    "__call__": [
      "self",
      "inputs"
    ]
  },
  "ShopSegmentationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VidtPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "nested_tensor_from_tensor_list": [
    "tensor_list"
  ],
  "_max_by_axis": [
    "the_list"
  ],
  "NestedTensor": {
    "__init__": [
      "self",
      "tensors",
      "mask"
    ],
    "to": [
      "self",
      "device"
    ],
    "decompose": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "box_cxcywh_to_xyxy": [
    "x"
  ],
  "get_predictions": [
    "post_results",
    "bbox_thu"
  ],
  "PostProcess": {
    "__init__": [
      "self",
      "processor_dct"
    ],
    "forward": [
      "self",
      "out_logits",
      "out_bbox",
      "target_sizes"
    ]
  },
  "convert_2_h36m": [
    "joints",
    "joints_nbr"
  ],
  "smooth_pts": [
    "cur_pts",
    "pre_pts",
    "bbox",
    "smooth_x",
    "smooth_y"
  ],
  "smoothing": [
    "lst_kps",
    "lst_bboxes",
    "smooth_x",
    "smooth_y"
  ],
  "convert_2_h36m_data": [
    "lst_kps",
    "lst_bboxes",
    "joints_nbr"
  ],
  "Body3DKeypointsPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ],
    "read_video_frames": [
      "self",
      "video_url"
    ],
    "render_prediction": [
      "self",
      "pose3d_cam_rr",
      "output_video_path"
    ]
  },
  "ObjectDetection3DPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "input"
    ],
    "get_default_data": [
      "self"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "MobileImageSuperResolutionPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "ImageDepthEstimationMarigoldPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "_MarigoldPipeline": {
    "rgb_latent_scale_factor": [],
    "depth_latent_scale_factor": [],
    "__init__": [
      "self",
      "unet",
      "vae",
      "scheduler",
      "text_encoder",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "input_image",
      "denoising_steps",
      "ensemble_size",
      "processing_res",
      "match_input_res",
      "batch_size",
      "color_map",
      "show_progress_bar",
      "ensemble_kwargs"
    ],
    "__encode_empty_text": [
      "self"
    ],
    "single_infer": [
      "self",
      "rgb_in",
      "num_inference_steps",
      "show_pbar"
    ],
    "encode_rgb": [
      "self",
      "rgb_in"
    ],
    "decode_depth": [
      "self",
      "depth_latent"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ImageDeblurPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "crop_process": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "VideoHumanMattingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageInstanceSegmentationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_collate_fn": [
      "self",
      "data"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FaceProcessingBasePipeline": {
    "__init__": [
      "self",
      "model",
      "use_det"
    ],
    "_choose_face": [
      "self",
      "det_result",
      "min_face",
      "top_face",
      "center_face",
      "img_shape"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "align_face_padding": [
      "self",
      "img",
      "rect",
      "padding_size",
      "pad_pixel"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "im_normalization": [],
  "unpad": [
    "img",
    "pad"
  ],
  "all_to_onehot": [
    "masks",
    "labels"
  ],
  "VideoObjectSegmentationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "F3NetForProductSegmentationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ReferringVideoObjectSegmentationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "apply_mask": [
    "image",
    "mask",
    "color",
    "transparency"
  ],
  "timestamp_format": [
    "seconds"
  ],
  "NanoDettForFaceHumanHandDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageColorizationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FacialLandmarkConfidencePipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageDenoisePipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "crop_process": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "ImageQualityAssessmentMosPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageDefrcnDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "_load_pretrained": [
      "self",
      "net",
      "load_path",
      "device",
      "strict"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "load_model": [
    "cfg",
    "ckpt",
    "strict"
  ],
  "prepare_inputs": [
    "image_input",
    "elevation_input",
    "crop_size",
    "image_size"
  ],
  "Image23DPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "MovieSceneSegmentationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoSummarizationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "inference": [
      "self",
      "frame_features",
      "n_frames",
      "picks",
      "change_points"
    ]
  },
  "VirtualTryonPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "outputs"
    ]
  },
  "VideoDepthEstimationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageEditingPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "_MasaCtrlPipeline": {
    "next_step": [
      "self",
      "model_output",
      "timestep",
      "x",
      "eta",
      "verbose"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "x",
      "eta",
      "verbose"
    ],
    "image2latent": [
      "self",
      "image"
    ],
    "latent2image": [
      "self",
      "latents",
      "return_type"
    ],
    "__call__": [
      "self",
      "prompt",
      "batch_size",
      "height",
      "width",
      "num_inference_steps",
      "guidance_scale",
      "eta",
      "latents",
      "unconditioning",
      "neg_prompt",
      "ref_intermediate_latents",
      "return_intermediates"
    ],
    "invert": [
      "self",
      "image",
      "prompt",
      "num_inference_steps",
      "guidance_scale",
      "eta",
      "return_intermediates"
    ]
  },
  "SALForImageTryOnPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TextToHeadPipeline": {
    "__init__": [
      "self",
      "model",
      "device",
      "hair_tex"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VopRetrievalPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoInpaintingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TinynasDetectionPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "show_result": [
      "self",
      "img_path",
      "result",
      "save_path"
    ]
  },
  "CMDSSLVideoEmbeddingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VCompose": {
    "__init__": [
      "self",
      "transforms"
    ],
    "__call__": [
      "self",
      "item"
    ]
  },
  "VRescale": {
    "__init__": [
      "self",
      "size"
    ],
    "__call__": [
      "self",
      "vclip"
    ]
  },
  "VCenterCrop": {
    "__init__": [
      "self",
      "size"
    ],
    "__call__": [
      "self",
      "vclip"
    ]
  },
  "VToTensor": {
    "__call__": [
      "self",
      "vclip"
    ]
  },
  "VNormalize": {
    "__init__": [
      "self",
      "mean",
      "std"
    ],
    "__call__": [
      "self",
      "vclip"
    ]
  },
  "ImageMultiViewDepthEstimationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "check_input": [
      "self",
      "input_dir"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageSuperResolutionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "Tex2TexturePipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "SurfaceReconCommonPipeline": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FaceAttributeRecognitionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ActionRecognitionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "perform_inference": [
      "self",
      "data",
      "max_bsz"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "PSTActionRecognitionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "perform_inference": [
      "self",
      "data",
      "max_bsz"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TinynasClassificationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FastInstanceSegmentationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_get_preprocess_shape": [
      "self",
      "oldh",
      "oldw",
      "short_edge_length",
      "max_size"
    ],
    "preprocess": [
      "self",
      "input",
      "min_size",
      "max_size"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs",
      "score_thr"
    ]
  },
  "ImageInpaintingSDV2Pipeline": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageStructuredModelProbingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FreqHPTForHumanImageGenerationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "NeRFRecon4KPipeline": {
    "__init__": [
      "self",
      "model",
      "data_type",
      "test_ray_chunk",
      "test_tile",
      "stepsize",
      "factor",
      "load_sr",
      "device"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "LicensePlateDetection": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "NeRFReconAccPipeline": {
    "__init__": [
      "self",
      "model",
      "data_type",
      "use_mask",
      "ckpt_path",
      "save_mesh",
      "n_test_traj_steps",
      "test_ray_chunk",
      "device"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "PedestrainAttributeRecognitionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "get_labels": [
      "self",
      "outputs",
      "thres"
    ],
    "labels_transform": [
      "self",
      "labels"
    ],
    "get_results": [
      "self",
      "inputs"
    ],
    "image_transform": [
      "self",
      "input"
    ],
    "crop_image": [
      "self",
      "image",
      "box"
    ],
    "process_image": [
      "self",
      "input"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "ImageBodyReshapingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "DDColorImageColorizationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FaceEmotionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "PointCloudSceneFlowEstimationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "check_input_pcd": [
      "self",
      "pcd"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "save_ply_data": [
      "self",
      "pcd1",
      "pcd2"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "img_trans": [
    "img_tensor"
  ],
  "add_mean": [
    "x"
  ],
  "do_inference_lowers": [
    "flow_10",
    "flow_12",
    "flow_21",
    "flow_23",
    "img1",
    "img2",
    "inter_model",
    "read_count",
    "inter_count",
    "delta",
    "outputs",
    "start_end_flag"
  ],
  "do_inference_highers": [
    "flow_10",
    "flow_12",
    "flow_21",
    "flow_23",
    "img1",
    "img2",
    "img1_up",
    "img2_up",
    "inter_model",
    "read_count",
    "inter_count",
    "delta",
    "outputs",
    "start_end_flag"
  ],
  "inference_lowers": [
    "flow_model",
    "refine_model",
    "inter_model",
    "video_len",
    "read_count",
    "inter_count",
    "delta",
    "scene_change_flag",
    "img_tensor_list",
    "img_ori_list",
    "inputs",
    "outputs"
  ],
  "inference_highers": [
    "flow_model",
    "refine_model",
    "inter_model",
    "video_len",
    "read_count",
    "inter_count",
    "delta",
    "scene_change_flag",
    "img_tensor_list",
    "img_ori_list",
    "inputs",
    "outputs"
  ],
  "convert": [
    "param"
  ],
  "VideoFrameInterpolationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "input",
      "out_fps"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TBSDetectionPipeline": {
    "_defaults": [],
    "get_defaults": [
      "cls",
      "n"
    ],
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "ImageSalientDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageReidPersonPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "LiveCategoryPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageCartoonPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "load_sess": [
      "self",
      "model_path",
      "name"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "detect_face": [
      "self",
      "img"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageControl3dPortraitPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "Body2DKeypointsPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "KeypointsDetection": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "get_pts": [
      "self",
      "heatmaps"
    ],
    "pts_transform": [
      "self",
      "meta",
      "pts",
      "lt_x",
      "lt_y"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "image_crop_resize": [
      "self",
      "input",
      "margin"
    ],
    "image_transform": [
      "self",
      "input"
    ],
    "crop_image": [
      "self",
      "image",
      "box"
    ],
    "preprocess": [
      "self",
      "input"
    ]
  },
  "VisionEfficientTuningPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "BadImageDetecingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "Image2ImageGenerationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "RIFEVideoFrameInterpolationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "input",
      "out_fps"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageRestorationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoSingleObjectTrackingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ArcFaceRecognitionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageSuperResolutionPASDPipeline": {
    "__init__": [
      "self",
      "model",
      "device_name"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ActionDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FaceLivenessIrPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "load_onnx_model": [
      "self",
      "onnx_path"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "UlfdFaceDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "Human3DRenderPipeline": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "load_3d_model": [
      "self",
      "mesh_path"
    ],
    "format_nvdiffrast_format": [
      "self",
      "mesh",
      "tex"
    ],
    "render_scene": [
      "self",
      "mesh_path",
      "resolution"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageViewTransformPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "FaceRecognitionOnnxFmPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "load_onnx_model": [
      "self",
      "onnx_path"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ControllableImageGenerationPipeline": {
    "initiate_single_model": [
      "self",
      "model"
    ],
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "device",
      "auto_collate"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoStabilizationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VisionMiddlewarePipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoCategoryPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TimeFirstBatchNorm1d": {
    "__init__": [
      "self",
      "dim",
      "groups"
    ],
    "forward": [
      "self",
      "tensor"
    ]
  },
  "NeXtVLAD": {
    "__init__": [
      "self",
      "num_clusters",
      "dim",
      "alpha",
      "groups",
      "expansion",
      "normalize_input",
      "p_drop",
      "add_batchnorm"
    ],
    "_init_params": [
      "self"
    ],
    "general_weight_initialization": [
      "self",
      "module"
    ],
    "forward": [
      "self",
      "x",
      "masks"
    ]
  },
  "ModelWrapper": {
    "__init__": [
      "self",
      "class_num",
      "subclass_num",
      "frame_num"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "save_grid": [
    "imgs",
    "filename",
    "nrow"
  ],
  "Image2ImageTranslationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "Human3DAnimationPipeline": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "gen_skeleton": [
      "self",
      "case_dir",
      "action_dir",
      "action"
    ],
    "gen_weights": [
      "self",
      "save_dir"
    ],
    "animate": [
      "self",
      "mesh_path",
      "action_dir",
      "action",
      "save_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "AnydoorPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "_get_state_dict": [
      "ckpt_path",
      "location"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "item",
      "num_samples",
      "strength",
      "ddim_steps",
      "scale"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "MDMMotionGeneration": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageSemanticSegmentationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "MaskDINOInstanceSegmentationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "get_preprocess_shape": [
      "self",
      "oldh",
      "oldw",
      "short_edge_length",
      "max_size"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "HumanReconstructionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "MaskFaceRecognitionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "_prefix_revision": [
      "self",
      "state_dict"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "RealtimeVideoObjectDetectionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "rboxes_to_polygons": [
    "rboxes"
  ],
  "cal_width": [
    "box"
  ],
  "point_dist": [
    "x1",
    "y1",
    "x2",
    "y2"
  ],
  "draw_polygons": [
    "img",
    "polygons"
  ],
  "nms_python": [
    "boxes"
  ],
  "point_in_rbox": [
    "c",
    "rbox"
  ],
  "polygon2rbox": [
    "polygon"
  ],
  "point_line_dist": [
    "px",
    "py",
    "x1",
    "y1",
    "x2",
    "y2"
  ],
  "polygons_from_bitmap": [
    "pred",
    "_bitmap",
    "dest_width",
    "dest_height"
  ],
  "boxes_from_bitmap": [
    "pred",
    "_bitmap",
    "dest_width",
    "dest_height"
  ],
  "box_score_fast": [
    "bitmap",
    "_box"
  ],
  "unclip": [
    "box",
    "unclip_ratio"
  ],
  "get_mini_boxes": [
    "contour"
  ],
  "Block": {},
  "subsample": [
    "inputs",
    "factor",
    "scope"
  ],
  "conv2d_same": [
    "inputs",
    "num_outputs",
    "kernel_size",
    "stride",
    "rate",
    "scope"
  ],
  "stack_blocks_dense": [
    "net",
    "blocks",
    "output_stride",
    "outputs_collections"
  ],
  "resnet_arg_scope": [
    "weight_decay",
    "batch_norm_decay",
    "batch_norm_epsilon",
    "batch_norm_scale"
  ],
  "BN_MOMENTUM": [],
  "BasicBlock": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Bottleneck": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PoseResNet": {
    "__init__": [
      "self",
      "block",
      "layers",
      "heads",
      "head_conv"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "blocks",
      "stride"
    ],
    "_get_deconv_cfg": [
      "self",
      "deconv_kernel",
      "index"
    ],
    "_make_deconv_layer": [
      "self",
      "num_layers",
      "num_filters",
      "num_kernels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "resnet_spec": [],
  "LicensePlateDet": [
    "num_layers"
  ],
  "CardDetectionCorrectionModel": [
    "num_layers"
  ],
  "N_LOCAL_LINKS": [],
  "N_CROSS_LINKS": [],
  "N_SEG_CLASSES": [],
  "N_LNK_CLASSES": [],
  "POS_LABEL": [],
  "NEG_LABEL": [],
  "SegLinkDetector": {
    "__init__": [
      "self"
    ],
    "_detection_classifier": [
      "self",
      "maps",
      "ksize",
      "weight_decay",
      "cross_links",
      "scope"
    ],
    "_build_cnn": [
      "self",
      "images",
      "weight_decay",
      "is_training"
    ],
    "build_model": [
      "self",
      "images",
      "is_training",
      "scope"
    ]
  },
  "BatchNorm2d": [],
  "constant_init": [
    "module",
    "constant",
    "bias"
  ],
  "conv3x3": [
    "in_planes",
    "out_planes",
    "stride"
  ],
  "ResNet": {
    "__init__": [
      "self",
      "block",
      "layers",
      "num_classes",
      "dcn",
      "stage_with_dcn"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "blocks",
      "stride",
      "dcn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SegDetector": {
    "__init__": [
      "self",
      "in_channels",
      "inner_channels",
      "k",
      "bias",
      "adaptive",
      "smooth",
      "serial"
    ],
    "weights_init": [
      "self",
      "m"
    ],
    "_init_thresh": [
      "self",
      "inner_channels",
      "serial",
      "smooth",
      "bias"
    ],
    "_init_upsample": [
      "self",
      "in_channels",
      "out_channels",
      "smooth",
      "bias"
    ],
    "forward": [
      "self",
      "features",
      "gt",
      "masks",
      "training"
    ],
    "step_function": [
      "self",
      "x",
      "y"
    ]
  },
  "VLPTModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DBModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FLAGS": [],
  "MATCH_STATUS_POS": [],
  "MATCH_STATUS_NEG": [],
  "MATCH_STATUS_IGNORE": [],
  "MUT_LABEL": [],
  "N_DET_LAYERS": [],
  "load_oplib": [
    "lib_name"
  ],
  "_nn_variable": [
    "name",
    "shape",
    "init_method",
    "collection"
  ],
  "group_conv2d_relu": [
    "x",
    "n_in",
    "n_out",
    "ksize",
    "stride",
    "group",
    "padding",
    "weight_init",
    "bias",
    "relu",
    "name"
  ],
  "group_conv2d_bn_relu": [
    "x",
    "n_in",
    "n_out",
    "ksize",
    "stride",
    "group",
    "padding",
    "weight_init",
    "bias",
    "relu",
    "name"
  ],
  "next_conv": [
    "x",
    "n_in",
    "n_out",
    "ksize",
    "stride",
    "group",
    "padding",
    "weight_init",
    "bias",
    "relu",
    "name"
  ],
  "next_conv_bn": [
    "x",
    "n_in",
    "n_out",
    "ksize",
    "stride",
    "group",
    "padding",
    "weight_init",
    "bias",
    "relu",
    "name"
  ],
  "conv2d_ori": [
    "x",
    "n_in",
    "n_out",
    "ksize",
    "stride",
    "padding",
    "weight_init",
    "bias",
    "relu",
    "scope"
  ],
  "conv_relu": [],
  "conv_bn_relu": [],
  "conv_relu_ori": [],
  "atrous_conv2d": [
    "x",
    "n_in",
    "n_out",
    "ksize",
    "dilation",
    "padding",
    "weight_init",
    "bias",
    "relu",
    "scope"
  ],
  "avg_pool": [
    "x",
    "ksize",
    "stride",
    "padding",
    "scope"
  ],
  "max_pool": [
    "x",
    "ksize",
    "stride",
    "padding",
    "scope"
  ],
  "score_loss": [
    "gt_labels",
    "match_scores",
    "n_classes"
  ],
  "smooth_l1_loss": [
    "offsets",
    "gt_offsets",
    "scope"
  ],
  "polygon_to_rboxe": [
    "polygon"
  ],
  "get_combined_polygon": [
    "rboxes",
    "resize_size"
  ],
  "combine_segs": [
    "segs"
  ],
  "combine_segments_batch": [
    "segments_batch",
    "group_indices_batch",
    "segment_counts_batch"
  ],
  "combine_segments_python": [
    "segments",
    "group_indices",
    "segment_counts"
  ],
  "get_coord": [
    "offsets",
    "map_size",
    "offsets_defaults"
  ],
  "get_coord_link": [
    "offsets",
    "map_size",
    "offsets_defaults"
  ],
  "is_valid_coord": [
    "l_idx",
    "x",
    "y",
    "map_size"
  ],
  "get_neighbours": [
    "l_idx",
    "x",
    "y",
    "map_size",
    "offsets_defaults"
  ],
  "decode_segments_links_python": [
    "image_size",
    "all_nodes",
    "all_links",
    "all_reg",
    "anchor_sizes"
  ],
  "decode_segments_links_train": [
    "image_size",
    "all_nodes",
    "all_links",
    "all_reg",
    "anchor_sizes"
  ],
  "decode_batch": [
    "all_nodes",
    "all_links",
    "all_reg",
    "image_size",
    "anchor_sizes"
  ],
  "decode_image": [
    "image_node_scores",
    "image_link_scores",
    "image_reg",
    "image_size",
    "anchor_sizes"
  ],
  "decode_image_by_join": [
    "node_scores",
    "link_scores",
    "node_threshold",
    "link_threshold",
    "map_size",
    "offsets_defaults"
  ],
  "get_link_mask": [
    "node_mask",
    "offsets_defaults",
    "link_max"
  ],
  "get_link8": [
    "link_scores_raw",
    "map_size"
  ],
  "decode_image_by_mutex": [
    "node_scores",
    "link_scores",
    "node_threshold",
    "link_threshold",
    "map_size",
    "offsets_defaults"
  ],
  "basicblock": [
    "inputs",
    "depth",
    "depth_bottleneck",
    "stride",
    "rate",
    "outputs_collections",
    "scope"
  ],
  "bottleneck": [
    "inputs",
    "depth",
    "depth_bottleneck",
    "stride",
    "rate",
    "outputs_collections",
    "scope"
  ],
  "resnet_v1": [
    "inputs",
    "blocks",
    "num_classes",
    "is_training",
    "global_pool",
    "output_stride",
    "include_root_block",
    "spatial_squeeze",
    "reuse",
    "scope"
  ],
  "resnet_v1_18": [
    "inputs",
    "num_classes",
    "is_training",
    "global_pool",
    "output_stride",
    "spatial_squeeze",
    "reuse",
    "scope"
  ],
  "resnet_v1_50": [
    "inputs",
    "num_classes",
    "is_training",
    "global_pool",
    "output_stride",
    "spatial_squeeze",
    "reuse",
    "scope"
  ],
  "resnet_v1_101": [
    "inputs",
    "num_classes",
    "is_training",
    "global_pool",
    "output_stride",
    "spatial_squeeze",
    "reuse",
    "scope"
  ],
  "resnet_v1_152": [
    "inputs",
    "num_classes",
    "is_training",
    "global_pool",
    "output_stride",
    "spatial_squeeze",
    "reuse",
    "scope"
  ],
  "resnet_v1_200": [
    "inputs",
    "num_classes",
    "is_training",
    "global_pool",
    "output_stride",
    "spatial_squeeze",
    "reuse",
    "scope"
  ],
  "transform_preds": [
    "coords",
    "center",
    "scale",
    "output_size",
    "rot"
  ],
  "get_affine_transform": [
    "center",
    "scale",
    "rot",
    "output_size",
    "shift",
    "inv"
  ],
  "affine_transform": [
    "pt",
    "t"
  ],
  "get_dir": [
    "src_point",
    "rot_rad"
  ],
  "get_3rd_point": [
    "a",
    "b"
  ],
  "_sigmoid": [
    "x"
  ],
  "_gather_feat": [
    "feat",
    "ind",
    "mask"
  ],
  "_tranpose_and_gather_feat": [
    "feat",
    "ind"
  ],
  "_nms": [
    "heat",
    "kernel"
  ],
  "_topk": [
    "scores",
    "K"
  ],
  "decode_by_ind": [
    "heat",
    "inds",
    "K"
  ],
  "bbox_decode": [
    "heat",
    "wh",
    "reg",
    "K"
  ],
  "gbox_decode": [
    "mk",
    "st_reg",
    "reg",
    "K"
  ],
  "bbox_post_process": [
    "bbox",
    "c",
    "s",
    "h",
    "w"
  ],
  "gbox_post_process": [
    "gbox",
    "c",
    "s",
    "h",
    "w"
  ],
  "nms": [
    "dets",
    "thresh"
  ],
  "group_bbox_by_gbox": [
    "bboxes",
    "gboxes",
    "score_thred",
    "v2c_dist_thred",
    "c2v_dist_thred"
  ],
  "OCRRecModel": {
    "__init__": [
      "self",
      "num_classes"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "BatchNorm": [],
  "BottleneckX": {
    "expansion": [],
    "cardinality": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "dilation"
    ],
    "forward": [
      "self",
      "x",
      "residual"
    ]
  },
  "Root": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "residual"
    ],
    "forward": [
      "self"
    ]
  },
  "Tree": {
    "__init__": [
      "self",
      "levels",
      "block",
      "in_channels",
      "out_channels",
      "stride",
      "level_root",
      "root_dim",
      "root_kernel_size",
      "dilation",
      "root_residual"
    ],
    "forward": [
      "self",
      "x",
      "residual",
      "children"
    ]
  },
  "DLA": {
    "__init__": [
      "self",
      "levels",
      "channels",
      "num_classes",
      "block",
      "residual_root",
      "return_levels",
      "pool_size",
      "linear_root"
    ],
    "_make_level": [
      "self",
      "block",
      "inplanes",
      "planes",
      "blocks",
      "stride"
    ],
    "_make_conv_level": [
      "self",
      "inplanes",
      "planes",
      "convs",
      "stride",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "dla34": [
    "pretrained"
  ],
  "dla46_c": [
    "pretrained"
  ],
  "dla46x_c": [
    "pretrained"
  ],
  "dla60x_c": [
    "pretrained"
  ],
  "dla60": [
    "pretrained"
  ],
  "dla60x": [
    "pretrained"
  ],
  "dla102": [
    "pretrained"
  ],
  "dla102x": [
    "pretrained"
  ],
  "dla102x2": [
    "pretrained"
  ],
  "dla169": [
    "pretrained"
  ],
  "set_bn": [
    "bn"
  ],
  "fill_up_weights": [
    "up"
  ],
  "IDAUp": {
    "__init__": [
      "self",
      "node_kernel",
      "out_dim",
      "channels",
      "up_factors"
    ],
    "forward": [
      "self",
      "layers"
    ]
  },
  "DLAUp": {
    "__init__": [
      "self",
      "channels",
      "scales",
      "in_channels"
    ],
    "forward": [
      "self",
      "layers"
    ]
  },
  "fill_fc_weights": [
    "layers"
  ],
  "DLASeg": {
    "__init__": [
      "self",
      "base_name",
      "pretrained",
      "down_ratio",
      "head_conv"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TableRecModel": [],
  "ViTSTR": {
    "__init__": [
      "self"
    ],
    "reset_classifier": [
      "self",
      "num_classes"
    ],
    "forward_features": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "vitstr_tiny": [
    "num_tokens"
  ],
  "ConvNeXt": {
    "__init__": [
      "self",
      "in_chans",
      "num_classes",
      "depths",
      "dims",
      "drop_path_rate",
      "layer_scale_init_value",
      "head_init_scale"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "forward_features": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LayerNorm": {
    "__init__": [
      "self",
      "normalized_shape",
      "eps",
      "data_format"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "convnext_tiny": [],
  "_ntuple": [
    "n"
  ],
  "PatchEmbed": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "in_chans",
      "embed_dim",
      "norm_layer",
      "flatten"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Mlp": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "act_layer",
      "drop"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "drop_path": [
    "x",
    "drop_prob",
    "training"
  ],
  "DropPath": {
    "__init__": [
      "self",
      "drop_prob"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Attention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "qkv_bias",
      "attn_drop",
      "proj_drop"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "VisionTransformer": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "in_chans",
      "num_classes",
      "embed_dim",
      "depth",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "representation_size",
      "distilled",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "embed_layer",
      "norm_layer",
      "act_layer",
      "weight_init"
    ],
    "reset_classifier": [
      "self",
      "num_classes",
      "global_pool"
    ],
    "forward_features": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DecodeBox": {
    "__init__": [
      "self",
      "anchors",
      "num_classes",
      "img_size"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "letterbox_image": [
    "image",
    "size"
  ],
  "yolo_correct_boxes": [
    "top",
    "left",
    "bottom",
    "right",
    "input_shape",
    "image_shape"
  ],
  "bbox_iou": [
    "box1",
    "box2",
    "x1y1x2y2"
  ],
  "non_max_suppression": [
    "prediction",
    "num_classes",
    "conf_thres",
    "nms_thres"
  ],
  "merge_bboxes": [
    "bboxes",
    "cutx",
    "cuty"
  ],
  "_get_anchors": [
    "self"
  ],
  "generate": [
    "self"
  ],
  "post_process": [
    "self",
    "outputs",
    "img_path"
  ],
  "SpeakerVerificationTDNNPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "in_audios",
      "save_dir",
      "output_emb",
      "thr"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs",
      "in_audios",
      "save_dir"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "compute_cos_similarity": [
      "self",
      "emb1",
      "emb2"
    ]
  },
  "LanguageRecognitionPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "in_audios",
      "out_file"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs",
      "scores",
      "in_audios",
      "out_file"
    ],
    "preprocess": [
      "self",
      "inputs"
    ]
  },
  "KWSFarfieldPipeline": {
    "SAMPLE_RATE": [],
    "SAMPLE_WIDTH": [],
    "INPUT_CHANNELS": [],
    "OUTPUT_CHANNELS": [],
    "__init__": [
      "self",
      "model"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "_process": [
      "self",
      "frames",
      "kws_list",
      "fout"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "SeparationPipeline": {
    "__init__": [
      "self",
      "model",
      "ngpu"
    ],
    "__call__": [
      "self",
      "audio_in",
      "audio_fs",
      "recog_type",
      "audio_format",
      "output_dir",
      "param_dict"
    ],
    "get_cmd": [
      "self",
      "config_path",
      "extra_args",
      "model_path"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "audio_in"
    ],
    "run_inference": [
      "self",
      "cmd"
    ]
  },
  "VCPipeline": {
    "SAMPLE_RATE": [],
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "AudioQuantizationPipeline": {
    "__init__": [
      "self",
      "model",
      "ngpu"
    ],
    "__call__": [
      "self",
      "audio_in",
      "output_dir",
      "param_dict"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "get_cmd": [
      "self",
      "extra_args",
      "model_path"
    ],
    "forward": [
      "self",
      "audio_in"
    ],
    "run_inference": [
      "self",
      "cmd"
    ]
  },
  "WeNetAutomaticSpeechRecognitionPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "__call__": [
      "self",
      "audio_in",
      "audio_fs",
      "recog_type",
      "audio_format"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "SpeakerVerificationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "in_audios",
      "save_dir",
      "output_emb",
      "thr"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs",
      "in_audios",
      "save_dir"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "compute_cos_similarity": [
      "self",
      "emb1",
      "emb2"
    ]
  },
  "FunASRPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self"
    ]
  },
  "SegmentationClusteringPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "audio"
    ],
    "forward": [
      "self",
      "input"
    ],
    "clustering": [
      "self",
      "embeddings"
    ],
    "postprocess": [
      "self",
      "segments",
      "vad_segments",
      "labels",
      "embeddings"
    ],
    "preprocess": [
      "self",
      "audio"
    ],
    "check_audio_list": [
      "self",
      "audio"
    ],
    "chunk": [
      "self",
      "vad_segments"
    ],
    "cut_audio": [
      "self",
      "cut_st",
      "cut_ed",
      "audio"
    ],
    "correct_labels": [
      "self",
      "labels"
    ],
    "merge_seque": [
      "self",
      "distribute_res"
    ],
    "smooth": [
      "self",
      "res",
      "mindur"
    ]
  },
  "Res2Net_Pipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "in_audios",
      "save_dir",
      "output_emb",
      "thr"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs",
      "in_audios",
      "save_dir"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "compute_cos_similarity": [
      "self",
      "emb1",
      "emb2"
    ]
  },
  "ERes2NetV2_Pipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "in_audios",
      "save_dir",
      "output_emb",
      "thr"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs",
      "in_audios",
      "save_dir"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "compute_cos_similarity": [
      "self",
      "emb1",
      "emb2"
    ]
  },
  "InverseTextProcessingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "text_in"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "text_in"
    ],
    "run_inference": [
      "self",
      "cmd"
    ]
  },
  "RDINO_Pipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "in_audios",
      "thr"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "compute_cos_similarity": [
      "self",
      "emb1",
      "emb2"
    ]
  },
  "KeyWordSpottingKwsbpPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "__call__": [
      "self",
      "audio_in"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "run_with_kwsbp": [
      "self",
      "inputs"
    ]
  },
  "TextToSpeechSambertHifiganPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "_sanitize_parameters": [
      "self"
    ]
  },
  "LauraCodecTTSPipeline": {
    "__init__": [
      "self",
      "model",
      "codec_model",
      "codec_model_revision",
      "ngpu"
    ],
    "__call__": [
      "self",
      "text",
      "prompt_text",
      "prompt_audio",
      "output_dir",
      "param_dict"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "load_codec_model": [
      "self",
      "cmd"
    ],
    "get_cmd": [
      "self",
      "extra_args",
      "model_path"
    ],
    "forward": [
      "self",
      "text",
      "prompt_text",
      "prompt_audio"
    ],
    "run_inference": [
      "self",
      "cmd"
    ]
  },
  "FEATURE_MVN": [],
  "CONFIG_YAML": [],
  "initialize_config": [
    "module_cfg"
  ],
  "LinearAECPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "_init_model": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "_process": [
      "self",
      "fbanks",
      "mixture"
    ]
  },
  "ResNet_Pipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "in_audios",
      "save_dir",
      "output_emb",
      "thr"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs",
      "in_audios",
      "save_dir"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "compute_cos_similarity": [
      "self",
      "emb1",
      "emb2"
    ]
  },
  "HOP_LENGTH": [],
  "N_FFT": [],
  "WINDOW_NAME_HAM": [],
  "STFT_WIN_LEN": [],
  "WINLEN": [],
  "STRIDE": [],
  "ANSDFSMNPipeline": {
    "SAMPLE_RATE": [],
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "bytes2tensor": [
      "self",
      "file_bytes"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "_forward": [
      "self",
      "origin_audio"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "SpeakerDiarizationSemanticSpeakerTurnDetectionPipeline": {
    "PUNC_LIST": [],
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "sequence_length"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ERes2Net_Pipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "in_audios",
      "save_dir",
      "output_emb",
      "thr"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs",
      "in_audios",
      "save_dir"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "compute_cos_similarity": [
      "self",
      "emb1",
      "emb2"
    ]
  },
  "SSRPipeline": {
    "SAMPLE_RATE": [],
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ANSPipeline": {
    "SAMPLE_RATE": [],
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ANSZipEnhancerPipeline": {
    "SAMPLE_RATE": [],
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "SpeakerChangeLocatingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "audio",
      "embds",
      "output_res"
    ],
    "forward": [
      "self",
      "input",
      "anchors"
    ],
    "postprocess": [
      "self",
      "input"
    ],
    "preprocess": [
      "self",
      "input"
    ]
  },
  "SpeakerDiarizationDialogueDetectionPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs",
      "topk"
    ]
  },
  "SDPNPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "in_audios",
      "thr"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "compute_cos_similarity": [
      "self",
      "emb1",
      "emb2"
    ]
  },
  "automatic_chunk_size": [
    "seq_len"
  ],
  "load_feature_for_one_target": [
    "config",
    "data_folder",
    "seed",
    "is_multimer",
    "use_uniprot",
    "symmetry_group"
  ],
  "ProteinStructurePipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "_process_single": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "EfficientDiffusionTuningPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "_sanitize_parameters": [
      "self"
    ]
  },
  "TEAMMultiModalSimilarityPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VisualEntailmentPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_batch": [
      "self",
      "data"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoComposerPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "video_data_preprocess": [
      "self",
      "video_key",
      "feature_framerate",
      "total_frames",
      "visual_mv"
    ],
    "extract_motion_vectors": [
      "self",
      "input_video",
      "fps",
      "dump",
      "verbose",
      "visual_mv"
    ]
  },
  "SudokuPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_batch": [
      "self",
      "data"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VisualGroundingPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_batch": [
      "self",
      "data"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "DocumentVLEmbeddingPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "forward": [
      "self",
      "encodings"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageToVideoPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "tensor2vid": [
    "video",
    "mean",
    "std"
  ],
  "OcrRecognitionPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_batch": [
      "self",
      "data"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "MultimodalDialoguePipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ProSTTextVideoRetrievalPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "_process_single": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoQuestionAnsweringPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VisualQuestionAnsweringPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_batch": [
      "self",
      "data"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FreeUTextToImagePipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TextToVideoSynthesisPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TextToImageSynthesisPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "AutomaticSpeechRecognitionPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_batch": [
      "self",
      "data"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "MultiModalEmbeddingPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoCaptioningPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_batch": [
      "self",
      "data"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VisionChatPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "trust_remote_code"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageCaptioningPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_batch": [
      "self",
      "data"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "cost": [
    "end",
    "begin"
  ],
  "pre_processor": [
    "img"
  ],
  "GridVlpPipeline": {
    "__init__": [
      "self",
      "model_name_or_path"
    ],
    "preprocess": [
      "self",
      "inputs",
      "max_seq_length"
    ]
  },
  "GridVlpClassificationPipeline": {
    "__init__": [
      "self",
      "model_name_or_path"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "GridVlpEmbeddingPipeline": {
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoMultiModalEmbeddingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "_process_single": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TextToSqlPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_batch": [
      "self",
      "data"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "VideoToVideoPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ImageTextRetrievalPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "MGeoRankingPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "sequence_length"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "get_gis": [
      "self",
      "gis",
      "inps"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "GEMMMultiModalEmbeddingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "SOONetVideoTemporalGroundingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "pad": [
      "self",
      "arr",
      "pad_len"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "parse_prompt": [
    "prompt"
  ],
  "sinc": [
    "x"
  ],
  "lanczos": [
    "x",
    "a"
  ],
  "MakeCutoutsDango": {
    "__init__": [
      "self",
      "cut_size",
      "Overview",
      "InnerCrop",
      "IC_Size_Pow",
      "IC_Grey_P"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "spherical_dist_loss": [
    "x",
    "y"
  ],
  "tv_loss": [
    "input"
  ],
  "range_loss": [
    "input"
  ],
  "DiscoDiffusionPipeline": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "forward": [
      "self",
      "inputs",
      "init",
      "init_scale",
      "skip_steps",
      "randomize_class",
      "eta",
      "output_type",
      "return_dict",
      "clip_guidance_scale"
    ],
    "numpy_to_pil": [
      "images"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "NoneClass": {},
  "set_framework_dependencies": [
    "x"
  ],
  "support_sz": [
    "sz"
  ],
  "get_projected_grid": [
    "in_sz",
    "out_sz",
    "scale_factor",
    "fw",
    "by_convs",
    "device"
  ],
  "get_field_of_view": [
    "projected_grid",
    "cur_support_sz",
    "fw",
    "eps",
    "device"
  ],
  "calc_pad_sz": [
    "in_sz",
    "out_sz",
    "field_of_view",
    "projected_grid",
    "scale_factor",
    "dim_by_convs",
    "fw",
    "device"
  ],
  "get_weights": [
    "interp_method",
    "projected_grid",
    "field_of_view"
  ],
  "apply_weights": [
    "input",
    "field_of_view",
    "weights",
    "dim",
    "n_dims",
    "pad_sz",
    "pad_mode",
    "fw"
  ],
  "apply_convs": [
    "input",
    "scale_factor",
    "in_sz",
    "out_sz",
    "weights",
    "dim",
    "pad_sz",
    "pad_mode",
    "fw"
  ],
  "set_scale_and_out_sz": [
    "in_shape",
    "out_shape",
    "scale_factors",
    "by_convs",
    "scale_tolerance",
    "max_numerator",
    "eps",
    "fw"
  ],
  "apply_antialiasing_if_needed": [
    "interp_method",
    "support_sz",
    "scale_factor",
    "antialiasing"
  ],
  "fw_ceil": [
    "x",
    "fw"
  ],
  "fw_floor": [
    "x",
    "fw"
  ],
  "fw_cat": [
    "x",
    "fw"
  ],
  "fw_swapaxes": [
    "x",
    "ax_1",
    "ax_2",
    "fw"
  ],
  "fw_pad": [
    "x",
    "fw",
    "pad_sz",
    "pad_mode",
    "dim"
  ],
  "fw_conv": [
    "input",
    "filter",
    "stride"
  ],
  "fw_arange": [
    "upper_bound",
    "fw",
    "device"
  ],
  "fw_empty": [
    "shape",
    "fw",
    "device"
  ],
  "Cones2InferencePipeline": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "layout_guidance_sampling": [
      "self",
      "prompt",
      "residual_dict",
      "subject_list",
      "color_context",
      "layout",
      "cfg_scale",
      "inference_steps",
      "guidance_steps",
      "guidance_weight",
      "weight_negative"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "Cones2AttnProcessor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask"
    ]
  },
  "register_attention_control": [
    "unet"
  ],
  "_tokens_img_attention_weight": [
    "img_context_seperated",
    "tokenized_texts",
    "ratio",
    "original_shape"
  ],
  "_image_context_seperator": [
    "img",
    "color_context",
    "_tokenizer",
    "neg"
  ],
  "_extract_cross_attention": [
    "tokenizer",
    "device",
    "color_map_image",
    "color_context",
    "text_input",
    "neg"
  ],
  "_downsampling": [
    "img",
    "w",
    "h"
  ],
  "_latents_to_images": [
    "vae",
    "latents",
    "scale_factor"
  ],
  "_sanitize_parameters": [
    "self"
  ],
  "EXAMPLE_DOC_STRING": [],
  "PixelAwareStableDiffusionPipeline": {
    "_optional_components": [],
    "__init__": [
      "self",
      "vae",
      "text_encoder",
      "tokenizer",
      "unet",
      "controlnet",
      "scheduler",
      "safety_checker",
      "feature_extractor",
      "requires_safety_checker"
    ],
    "_init_tiled_vae": [
      "self",
      "encoder_tile_size",
      "decoder_tile_size",
      "fast_decoder",
      "fast_encoder",
      "color_fix",
      "vae_to_gpu"
    ],
    "enable_vae_slicing": [
      "self"
    ],
    "disable_vae_slicing": [
      "self"
    ],
    "enable_vae_tiling": [
      "self"
    ],
    "disable_vae_tiling": [
      "self"
    ],
    "enable_sequential_cpu_offload": [
      "self",
      "gpu_id"
    ],
    "enable_model_cpu_offload": [
      "self",
      "gpu_id"
    ],
    "_execution_device": [
      "self"
    ],
    "_encode_prompt": [
      "self",
      "prompt",
      "device",
      "num_images_per_prompt",
      "do_classifier_free_guidance",
      "negative_prompt",
      "prompt_embeds",
      "negative_prompt_embeds"
    ],
    "run_safety_checker": [
      "self",
      "image",
      "device",
      "dtype"
    ],
    "decode_latents": [
      "self",
      "latents"
    ],
    "prepare_extra_step_kwargs": [
      "self",
      "generator",
      "eta"
    ],
    "check_inputs": [
      "self",
      "prompt",
      "image",
      "height",
      "width",
      "callback_steps",
      "negative_prompt",
      "prompt_embeds",
      "negative_prompt_embeds",
      "controlnet_conditioning_scale"
    ],
    "check_image": [
      "self",
      "image",
      "prompt",
      "prompt_embeds"
    ],
    "prepare_image": [
      "self",
      "image",
      "width",
      "height",
      "batch_size",
      "num_images_per_prompt",
      "device",
      "dtype",
      "do_classifier_free_guidance",
      "guess_mode"
    ],
    "prepare_latents": [
      "self",
      "batch_size",
      "num_channels_latents",
      "height",
      "width",
      "dtype",
      "device",
      "generator",
      "latents"
    ],
    "_default_height_width": [
      "self",
      "height",
      "width",
      "image"
    ],
    "save_pretrained": [
      "self",
      "save_directory",
      "safe_serialization",
      "variant"
    ],
    "_gaussian_weights": [
      "self",
      "tile_width",
      "tile_height",
      "nbatches"
    ],
    "__call__": [
      "self",
      "prompt",
      "image",
      "height",
      "width",
      "num_inference_steps",
      "guidance_scale",
      "negative_prompt",
      "num_images_per_prompt",
      "eta",
      "generator",
      "latents",
      "prompt_embeds",
      "negative_prompt_embeds",
      "output_type",
      "return_dict",
      "callback",
      "callback_steps",
      "cross_attention_kwargs",
      "fg_mask",
      "conditioning_scale_fg",
      "conditioning_scale_bg",
      "guess_mode"
    ]
  },
  "DiffusersPipeline": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "has_mps": [],
  "get_cuda_device_string": [],
  "get_optimal_device_name": [],
  "get_optimal_device": [],
  "get_device_for": [
    "task"
  ],
  "torch_gc": [],
  "enable_tf32": [],
  "cpu": [],
  "device": [],
  "device_interrogate": [],
  "device_gfpgan": [],
  "device_esrgan": [],
  "device_codeformer": [],
  "dtype": [],
  "dtype_vae": [],
  "dtype_unet": [],
  "unet_needs_upcast": [],
  "cond_cast_unet": [
    "input"
  ],
  "cond_cast_float": [
    "input"
  ],
  "randn": [
    "seed",
    "shape"
  ],
  "randn_without_seed": [
    "shape"
  ],
  "autocast": [
    "disable"
  ],
  "without_autocast": [
    "disable"
  ],
  "NansException": {},
  "test_for_nans": [
    "x",
    "where"
  ],
  "sd_flag": [],
  "get_recommend_encoder_tile_size": [],
  "get_recommend_decoder_tile_size": [],
  "inplace_nonlinearity": [
    "x"
  ],
  "attn_forward_new": [
    "self",
    "h_"
  ],
  "attn2task": [
    "task_queue",
    "net"
  ],
  "resblock2task": [
    "queue",
    "block"
  ],
  "build_sampling": [
    "task_queue",
    "net",
    "is_decoder"
  ],
  "build_task_queue": [
    "net",
    "is_decoder"
  ],
  "clone_task_queue": [
    "task_queue"
  ],
  "get_var_mean": [
    "input",
    "num_groups"
  ],
  "custom_group_norm": [
    "input",
    "num_groups",
    "mean",
    "var",
    "weight",
    "bias",
    "eps"
  ],
  "crop_valid_region": [
    "x",
    "input_bbox",
    "target_bbox",
    "is_decoder"
  ],
  "perfcount": [
    "fn"
  ],
  "GroupNormParam": {
    "__init__": [
      "self"
    ],
    "add_tile": [
      "self",
      "tile",
      "layer"
    ],
    "summary": [
      "self"
    ],
    "from_tile": [
      "tile",
      "norm"
    ]
  },
  "VAEHook": {
    "__init__": [
      "self",
      "net",
      "tile_size",
      "is_decoder",
      "fast_decoder",
      "fast_encoder",
      "color_fix",
      "to_gpu"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "get_best_tile_size": [
      "self",
      "lowerbound",
      "upperbound"
    ],
    "split_tiles": [
      "self",
      "h",
      "w"
    ],
    "estimate_group_norm": [
      "self",
      "z",
      "task_queue",
      "color_fix"
    ],
    "vae_tile_forward": [
      "self",
      "z"
    ]
  },
  "StableDiffusionPipeline": {
    "__init__": [
      "self",
      "model",
      "lora_dir",
      "custom_dir",
      "modifier_token"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ChineseStableDiffusionPipeline": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "_DiffuersChineseStableDiffusionPipeline": {
    "_optional_components": [],
    "__init__": [
      "self",
      "vae",
      "text_encoder",
      "tokenizer",
      "unet",
      "scheduler",
      "safety_checker",
      "feature_extractor",
      "requires_safety_checker"
    ],
    "_encode_prompt": [
      "self",
      "prompt",
      "device",
      "num_images_per_prompt",
      "do_classifier_free_guidance",
      "negative_prompt",
      "prompt_embeds",
      "negative_prompt_embeds",
      "lora_scale"
    ]
  },
  "DistributedGPT3Pipeline": {
    "model": [],
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_instantiate_one": [
      "cls",
      "rank",
      "model_dir"
    ],
    "_forward_one": [
      "cls",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "_stream_single": [
      "self",
      "model_input",
      "forward_params",
      "postprocess_params"
    ],
    "_stream_one": [
      "cls",
      "inputs"
    ],
    "_next_one": [
      "cls",
      "idx"
    ]
  },
  "DialogIntentPredictionPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "GLM130bTextGenerationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "DistributedPlugPipeline": {
    "model": [],
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "first_sequence",
      "sequence_length"
    ],
    "_forward_one": [
      "cls",
      "inputs"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "_instantiate_one": [
      "cls",
      "rank",
      "model_dir"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TranslationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TextClassificationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "_batch": [
      "self",
      "data"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs",
      "topk"
    ]
  },
  "LanguageIdentificationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "_lid_preprocess": [
      "self",
      "input"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TableQuestionAnsweringPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "db",
      "config_file",
      "device",
      "auto_collate"
    ],
    "prepare_model": [
      "self"
    ],
    "post_process_multi_turn": [
      "self",
      "history_sql",
      "result",
      "table"
    ],
    "sql_dict_to_str": [
      "self",
      "result",
      "tables"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "_collate_fn": [
      "self",
      "data"
    ]
  },
  "DocumentGroundedDialogRerankPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "seed"
    ],
    "one_instance": [
      "self",
      "input_ids",
      "attention_mask"
    ],
    "forward": [
      "self",
      "dataset"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "_remove_duplicates": [
    "obj"
  ],
  "_get_ids_list": [
    "datapoint",
    "rank_keys",
    "verbose"
  ],
  "_computeRprec": [
    "guess_ids",
    "gold_ids"
  ],
  "_precision_at_k": [
    "rank",
    "k"
  ],
  "_recall_at_k": [
    "rank",
    "num_distinct_evidence_sets",
    "k"
  ],
  "_success_rate_at_k": [
    "rank",
    "k"
  ],
  "load_data": [
    "filename"
  ],
  "rprecision": [
    "guess_item",
    "gold_item",
    "rank_keys"
  ],
  "get_ranking_metrics": [
    "guess_item",
    "gold_item",
    "ks",
    "rank_keys"
  ],
  "compute": [
    "gold_dataset",
    "guess_dataset",
    "ks",
    "rank_keys"
  ],
  "to_distinct_doc_ids": [
    "passage_ids"
  ],
  "validate_input": [
    "gold_records",
    "guess_records"
  ],
  "get_gold_answers": [
    "gold"
  ],
  "_metric_max_over_ground_truths": [
    "metric_fn",
    "prediction",
    "ground_truths"
  ],
  "_calculate_metrics": [
    "gold_records",
    "guess_records"
  ],
  "TextGenerationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "first_sequence"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "decode": [
      "self",
      "inputs"
    ],
    "sentence_piece": [
      "self",
      "inputs"
    ],
    "roberta": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TextGenerationT5Pipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "sub_task"
    ],
    "_parse_specific_model_params": [
      "self",
      "model_dir",
      "key"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "ChatGLM6bTextGenerationPipeline": {
    "__init__": [
      "self",
      "model",
      "quantization_bit",
      "use_bf16"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "ChatGLM6bV2TextGenerationPipeline": {
    "__init__": [
      "self",
      "model",
      "quantization_bit",
      "use_bf16",
      "trust_remote_code"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "QWenChatPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "QWenTextGenerationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "SeqGPTPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "prompt"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "Llama2TaskPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "max_length",
      "do_sample",
      "top_p",
      "temperature",
      "repetition_penalty",
      "eos_token_id",
      "bos_token_id",
      "pad_token_id"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "Llama2chatTaskPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "max_length",
      "do_sample",
      "top_p",
      "temperature",
      "repetition_penalty",
      "eos_token_id",
      "bos_token_id",
      "pad_token_id",
      "system",
      "history"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "DocumentSegmentationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "__call__": [
      "self",
      "documents"
    ],
    "predict": [
      "self",
      "documents"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "cut_documents": [
      "self",
      "para"
    ],
    "cut_sentence": [
      "self",
      "para"
    ]
  },
  "DialogStateTrackingPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "predict_and_format": [
    "config",
    "tokenizer",
    "features",
    "per_slot_class_logits",
    "per_slot_start_logits",
    "per_slot_end_logits",
    "per_slot_refer_logits",
    "ids",
    "input_ids_unmasked",
    "values",
    "inform",
    "prefix",
    "ds"
  ],
  "DocumentGroundedDialogRetrievalPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "index_path",
      "per_gpu_batch_size"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "_collate_fn": [
      "self",
      "data"
    ],
    "load_index": [
      "self",
      "index_path"
    ],
    "save_index": [
      "self",
      "index_path"
    ],
    "add_passage": [
      "self",
      "passages"
    ]
  },
  "ExtractiveSummarizationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "__call__": [
      "self",
      "documents"
    ],
    "predict": [
      "self",
      "documents"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "cut_documents": [
      "self",
      "para"
    ],
    "cut_sentence": [
      "self",
      "para"
    ]
  },
  "SummarizationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "_batch": [
      "self",
      "data"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "MachineReadingComprehensionForNERPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "WordSegmentationPipeline": {
    "postprocess": [
      "self",
      "inputs",
      "output_final_sentence"
    ]
  },
  "MultilingualWordSegmentationPipeline": {
    "postprocess": [
      "self",
      "inputs",
      "output_final_sentence"
    ]
  },
  "WordSegmentationThaiPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "sequence_length"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ZeroShotClassificationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "sequence_length"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "_parse_labels": [
      "self",
      "labels"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs",
      "candidate_labels",
      "multi_label"
    ]
  },
  "context_template": [],
  "history_template": [],
  "knowledge_template": [],
  "user_profile_template": [],
  "bot_profile_template": [],
  "FidDialoguePipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "process_context": [
      "self",
      "context_list"
    ],
    "process_history": [
      "self",
      "history_list"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "sentencepiece_tokenize": [
    "sp_model",
    "sent"
  ],
  "FasttextSequenceClassificationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs",
      "topk"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TranslationQualityEstimationPipeline": {
    "__init__": [
      "self",
      "model",
      "device"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TokenClassificationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "sequence_length"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "_chunk_process": [
      "self",
      "inputs"
    ],
    "_process_single": [
      "self",
      "input"
    ],
    "_process_batch": [
      "self",
      "input",
      "batch_size"
    ],
    "_auto_split": [
      "self",
      "input_texts",
      "split_max_length"
    ],
    "_auto_join": [
      "self",
      "outputs",
      "index_mapping"
    ]
  },
  "CanmtTranslationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "SentenceEmbeddingPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "sequence_length"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "MGLMTextSummarizationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "CodeGeeXCodeTranslationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "CodeGeeXCodeGenerationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "NamedEntityRecognitionPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "sequence_length"
    ]
  },
  "TranslationEvaluationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "input_format",
      "device"
    ],
    "checking_input_format": [
      "self"
    ],
    "change_input_format": [
      "self",
      "input_format"
    ],
    "__call__": [
      "self",
      "input_dict"
    ],
    "forward": [
      "self",
      "input_dict"
    ],
    "postprocess": [
      "self",
      "output"
    ]
  },
  "FaqQuestionAnsweringPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "get_sentence_embedding": [
      "self",
      "inputs",
      "max_len"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FeatureExtractionPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "padding",
      "sequence_length"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "InteractiveTranslationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TextRankingPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "sequence_length"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "FillMaskPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "first_sequence",
      "sequence_length"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "SWIFT_FRAMEWORK": [],
  "LLMAdapterRegistry": {
    "llm_format_map": [],
    "_add_to_map": [
      "cls",
      "model_type",
      "value_index",
      "member"
    ],
    "_wrapper": [
      "cls",
      "model_type",
      "value_index",
      "member"
    ],
    "register_format_messages": [
      "cls",
      "model_type",
      "function"
    ],
    "register_format_output": [
      "cls",
      "model_type",
      "function"
    ],
    "register_tokenizer": [
      "cls",
      "model_type",
      "tokenizer_class"
    ],
    "contains": [
      "cls",
      "model_name"
    ],
    "get": [
      "cls",
      "model_name"
    ]
  },
  "LLMPipeline": {
    "initiate_single_model": [
      "self",
      "model"
    ],
    "_is_swift_model": [
      "self",
      "model"
    ],
    "_wrap_infer_framework": [
      "self",
      "model_dir",
      "framework"
    ],
    "__init__": [
      "self",
      "format_messages",
      "format_output",
      "tokenizer",
      "llm_framework",
      "trust_remote_code"
    ],
    "_init_swift": [
      "self",
      "model_id",
      "device"
    ],
    "_temp_configuration_file": [
      "self",
      "kwargs"
    ],
    "_process_single": [
      "self",
      "inputs"
    ],
    "stream_generate": [
      "self",
      "inputs"
    ],
    "_stream_single": [
      "self",
      "model_input",
      "forward_params",
      "postprocess_params"
    ],
    "preprocess": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "outputs"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "_get_tokenizer": [
      "self",
      "tokenizer_class"
    ],
    "format_messages": [
      "messages",
      "tokenizer"
    ],
    "format_output": [
      "response"
    ],
    "_message_iter": [
      "data"
    ],
    "_concat_with_special_tokens": [
      "ids",
      "role",
      "content",
      "tokenizer"
    ],
    "_encode": [
      "tokenizer",
      "content"
    ],
    "_concat": [
      "ids"
    ]
  },
  "chatglm2_format_messages": [
    "messages",
    "tokenizer"
  ],
  "chatglm2_format_output": [
    "response"
  ],
  "llama2_format_messages": [
    "messages",
    "tokenizer"
  ],
  "baichuan_format_messages": [
    "messages",
    "tokenizer"
  ],
  "wizardlm_format_messages": [
    "messages",
    "tokenizer"
  ],
  "wizardcode_format_messages": [
    "messages",
    "tokenizer"
  ],
  "chatglm3_format_messages": [
    "messages",
    "tokenizer"
  ],
  "qwen2_format_messages": [
    "messages",
    "tokenizer"
  ],
  "ConversationalTextToSqlPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "_collate_fn": [
      "self",
      "data"
    ]
  },
  "WordAlignmentPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "sequence_length"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "TextErrorCorrectionPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "DistributedGPTMoEPipeline": {
    "model": [],
    "__init__": [
      "self",
      "model",
      "preprocessor"
    ],
    "_instantiate_one": [
      "cls",
      "rank",
      "model_dir"
    ],
    "_forward_one": [
      "cls",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "DocumentGroundedDialogGeneratePipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "_collate_fn": [
      "self",
      "data"
    ]
  },
  "UserSatisfactionEstimationPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs",
      "topk"
    ]
  },
  "DialogModelingPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "SiameseUiePipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "__call__": [
      "self",
      "input"
    ],
    "_pad": [
      "self",
      "input_ids",
      "pad_token_id"
    ],
    "tokenize_sample": [
      "self",
      "text",
      "tokenized_text",
      "hints"
    ],
    "get_tokenized_data_and_data_loader": [
      "self",
      "text",
      "tokenized_text",
      "hints"
    ],
    "get_entities": [
      "self",
      "text",
      "offsets",
      "head_probs",
      "tail_probs"
    ],
    "get_prefix_infos": [
      "self",
      "text",
      "tokenized_text",
      "prefix_info",
      "schema_types"
    ],
    "forward": [
      "self",
      "text",
      "tokenized_text",
      "prefix_info",
      "curr_schema_dict",
      "pred_info_list",
      "output_all_prefix"
    ]
  },
  "AutomaticPostEditingPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "PolyLMTextGenerationPipeline": {
    "__init__": [
      "self",
      "model"
    ],
    "_sanitize_parameters": [
      "self"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "InformationExtractionPipeline": {
    "__init__": [
      "self",
      "model",
      "preprocessor",
      "config_file",
      "device",
      "auto_collate",
      "sequence_length"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "InferFramework": {
    "__init__": [
      "self",
      "model_id_or_dir"
    ],
    "__call__": [
      "self",
      "prompts"
    ],
    "model_type_supported": [
      "self",
      "model_type"
    ],
    "check_gpu_compatibility": [
      "major_version"
    ],
    "from_pretrained": [
      "cls",
      "model_id_or_dir",
      "framework"
    ]
  },
  "Vllm": {
    "__init__": [
      "self",
      "model_id_or_dir",
      "dtype",
      "quantization",
      "tensor_parallel_size",
      "trust_remote_code"
    ],
    "__call__": [
      "self",
      "prompts"
    ],
    "model_type_supported": [
      "self",
      "model_type"
    ]
  },
  "MODELS": [],
  "BACKBONES": [],
  "HEADS": [],
  "modules": [],
  "build_model": [
    "cfg",
    "task_name",
    "default_args"
  ],
  "build_backbone": [
    "cfg",
    "default_args"
  ],
  "build_head": [
    "cfg",
    "task_name",
    "default_args"
  ],
  "IMAGE_MAX_DIM": [],
  "IMAGE_MIN_DIM": [],
  "IMAGE_MAX_RATIO": [],
  "IMAGE_BLENDER_MASK_RESIZE_SCALE": [],
  "IMAGE_BLENDER_INNER_RECT_MAX_DIM": [],
  "IMAGE_BLENDER_DILATE_KERNEL_SIZE": [],
  "IMAGE_BLENDER_VALID_MASK_THRESHOLD": [],
  "IMAGE_BLENDER_MIN_VALID_SKY_AREA": [],
  "IMAGE_BLENDER_MIN_RESIZE_DIM": [],
  "IMAGE_BLENDER_BLUR_KERNEL_SIZE": [],
  "extract_sky_image": [
    "in_sky_image",
    "in_sky_mask"
  ],
  "blend": [
    "scene_image",
    "scene_mask",
    "sky_image",
    "sky_mask",
    "inBlendLevelNum"
  ],
  "get_max_inner_rect": [
    "in_image_mask",
    "in_alpha_threshold",
    "is_bigger_valid"
  ],
  "scale_rect": [
    "in_rect",
    "in_image_size",
    "in_scale"
  ],
  "get_fast_valid_rect": [
    "in_mask",
    "in_threshold"
  ],
  "min_size_match": [
    "in_image",
    "in_min_size",
    "type"
  ],
  "safe_roi_pad": [
    "in_pad_image",
    "in_rect",
    "out_base_image"
  ],
  "merge_image": [
    "in_base_image",
    "in_merge_image",
    "in_merge_mask",
    "in_point"
  ],
  "blend_merge": [
    "in_scene_image",
    "in_scene_mask",
    "in_valid_sky_image",
    "inBlendLevelNum"
  ],
  "ImageSkychange": {
    "__init__": [
      "self",
      "model_dir",
      "refine_cfg",
      "coarse_cfg"
    ],
    "load_model": [
      "self",
      "seg_model",
      "input_model_path"
    ],
    "convert_state_dict": [
      "self",
      "state_dict"
    ],
    "forward": [
      "self",
      "sky_image",
      "sky_image_refine",
      "scene_image",
      "scene_image_refine",
      "img_metas"
    ],
    "inference_mask": [
      "self",
      "img",
      "img_metas",
      "input_size"
    ]
  },
  "ImageSkyChangePreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode",
      "coarse_model_width",
      "coarse_model_height",
      "refine_model_width",
      "refine_model_height",
      "mean_vec",
      "std_vec"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "process_single_img": [
      "self",
      "img"
    ],
    "check_image": [
      "self",
      "input_img"
    ]
  },
  "get_refine_input": [
    "mat",
    "refine_input_size"
  ],
  "max_dim_match": [
    "image",
    "refine_model_size"
  ],
  "center_pad_image_withwh": [
    "image",
    "crop_size",
    "padvalue",
    "padding_mode"
  ],
  "image_transform": [
    "img",
    "normalize"
  ],
  "is_numpy_image": [
    "img"
  ],
  "ASPPModule": {
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "kernel_size",
      "padding",
      "dilation",
      "BatchNorm"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_init_weight": [
      "self"
    ]
  },
  "ASPP": {
    "__init__": [
      "self",
      "inplanes",
      "outplanes",
      "dilations",
      "drop_rate"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_init_weight": [
      "self"
    ]
  },
  "Conv2DBatchNormRelu": {
    "__init__": [
      "self",
      "in_channels",
      "n_filters",
      "k_size",
      "stride",
      "padding",
      "bias",
      "dilation",
      "with_bn",
      "with_relu"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "SegnetDown2": {
    "__init__": [
      "self",
      "in_size",
      "out_size"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "SegnetDown3": {
    "__init__": [
      "self",
      "in_size",
      "out_size"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "SegnetUp1": {
    "__init__": [
      "self",
      "in_size",
      "out_size"
    ],
    "forward": [
      "self",
      "inputs",
      "indices",
      "output_shape"
    ]
  },
  "Unet": {
    "__init__": [
      "self",
      "n_classes",
      "in_channels",
      "is_unpooling",
      "pretrain"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "init_vgg16_params": [
      "self",
      "vgg16"
    ]
  },
  "ALIGN_CORNERS": [],
  "ModuleHelper": {
    "BNReLU": [
      "num_features",
      "bn_type"
    ],
    "BatchNorm2d": []
  },
  "SpatialGatherModule": {
    "__init__": [
      "self",
      "cls_num",
      "scale"
    ],
    "forward": [
      "self",
      "feats",
      "probs"
    ]
  },
  "ObjectAttentionBlock": {
    "__init__": [
      "self",
      "in_channels",
      "key_channels",
      "scale",
      "bn_type"
    ],
    "forward": [
      "self",
      "x",
      "proxy"
    ]
  },
  "ObjectAttentionBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "key_channels",
      "scale",
      "bn_type"
    ]
  },
  "SpatialOCRModule": {
    "__init__": [
      "self",
      "in_channels",
      "key_channels",
      "out_channels",
      "scale",
      "dropout",
      "bn_type"
    ],
    "forward": [
      "self",
      "feats",
      "proxy_feats"
    ]
  },
  "HrnetSuperAndOcr": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_seg_model": [
    "cfg"
  ],
  "HighResolutionModule": {
    "__init__": [
      "self",
      "num_branches",
      "blocks",
      "num_blocks",
      "num_inchannels",
      "num_channels",
      "fuse_method",
      "multi_scale_output"
    ],
    "_check_branches": [
      "self",
      "num_branches",
      "blocks",
      "num_blocks",
      "num_inchannels",
      "num_channels"
    ],
    "_make_one_branch": [
      "self",
      "branch_index",
      "block",
      "num_blocks",
      "num_channels",
      "stride"
    ],
    "_make_branches": [
      "self",
      "num_branches",
      "block",
      "num_blocks",
      "num_channels"
    ],
    "_make_fuse_layers": [
      "self"
    ],
    "get_num_inchannels": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "model_w18v1": [],
  "model_w18v2": [],
  "model_w48": [],
  "model_version_dict": [],
  "blocks_dict": [],
  "HrnetBackBone": {
    "__init__": [
      "self"
    ],
    "_make_transition_layer": [
      "self",
      "num_channels_pre_layer",
      "num_channels_cur_layer"
    ],
    "_make_layer": [
      "self",
      "block",
      "inplanes",
      "planes",
      "blocks",
      "stride"
    ],
    "_make_stage": [
      "self",
      "layer_config",
      "num_inchannels",
      "multi_scale_output"
    ],
    "_backbone_forward": [
      "self",
      "x"
    ],
    "init_weights": [
      "self",
      "url",
      "cache_file"
    ]
  },
  "SwinLPanopticSegmentation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "inference": [
      "self",
      "data"
    ],
    "forward": [
      "self",
      "Inputs"
    ]
  },
  "build_neck": [
    "cfg"
  ],
  "build_rpn_head": [
    "cfg"
  ],
  "build_roi_head": [
    "cfg"
  ],
  "CascadeMaskRCNNSwin": {
    "__init__": [
      "self",
      "backbone",
      "neck",
      "rpn_head",
      "roi_head",
      "pretrained"
    ],
    "extract_feat": [
      "self",
      "img"
    ],
    "forward_train": [
      "self",
      "img",
      "img_metas",
      "gt_bboxes",
      "gt_labels",
      "gt_bboxes_ignore",
      "gt_masks",
      "proposals"
    ],
    "forward_test": [
      "self",
      "img",
      "img_metas",
      "proposals",
      "rescale"
    ],
    "forward": [
      "self",
      "img",
      "img_metas"
    ],
    "_parse_losses": [
      "self",
      "losses"
    ],
    "train_step": [
      "self",
      "data",
      "optimizer"
    ],
    "val_step": [
      "self",
      "data",
      "optimizer"
    ]
  },
  "FastInst": {
    "__init__": [
      "self",
      "model_dir",
      "backbone",
      "encoder",
      "decoder",
      "pretrained",
      "classes"
    ],
    "forward": [
      "self",
      "batched_inputs"
    ],
    "postprocess": [
      "self",
      "input"
    ],
    "device": [
      "self"
    ],
    "sem_seg_postprocess": [
      "self",
      "result",
      "img_size",
      "output_height",
      "output_width"
    ],
    "instance_inference": [
      "self",
      "mask_cls",
      "mask_pred"
    ]
  },
  "FastInstHead": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "features",
      "targets"
    ],
    "layers": [
      "self",
      "features",
      "targets"
    ]
  },
  "CascadeMaskRCNNSwinModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ],
    "compute_loss": [
      "self",
      "outputs",
      "labels"
    ]
  },
  "MaskDINOSwinModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ]
  },
  "get_seg_bboxes": [
    "bboxes",
    "labels",
    "segms",
    "class_names",
    "score_thr"
  ],
  "get_img_seg_results": [
    "det_rawdata",
    "class_names",
    "score_thr",
    "is_decode"
  ],
  "get_img_ins_seg_result": [
    "img_seg_result",
    "class_names",
    "score_thr"
  ],
  "show_result": [
    "img",
    "result",
    "out_file",
    "show_box",
    "show_label",
    "show_score",
    "alpha",
    "fontScale",
    "fontFace",
    "thickness"
  ],
  "get_maskdino_ins_seg_result": [
    "maskdino_seg_result",
    "class_names",
    "score_thr"
  ],
  "MaskDINOSwin": {
    "__init__": [
      "self",
      "backbone",
      "encoder",
      "decoder",
      "pretrained"
    ],
    "device": [
      "self"
    ],
    "forward": [
      "self",
      "batched_inputs"
    ],
    "instance_inference": [
      "self",
      "mask_cls",
      "mask_pred",
      "mask_box_result"
    ],
    "box_postprocess": [
      "self",
      "out_bbox",
      "img_h",
      "img_w"
    ]
  },
  "MaskDINOHead": {
    "__init__": [
      "self",
      "pixel_decoder",
      "transformer_predictor"
    ],
    "forward": [
      "self",
      "features",
      "mask",
      "targets"
    ],
    "layers": [
      "self",
      "features",
      "mask",
      "targets"
    ]
  },
  "ImageList": {
    "__init__": [
      "self",
      "tensor",
      "image_sizes"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "to": [
      "self"
    ],
    "device": [
      "self"
    ],
    "from_tensors": [
      "tensors",
      "size_divisibility",
      "pad_value"
    ]
  },
  "BasicStem": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "build_resnet_backbone": [
    "out_features",
    "depth",
    "num_groups",
    "width_per_group",
    "norm",
    "stem_out_channels",
    "res2_out_channels",
    "stride_in_1x1",
    "res4_dilation",
    "res5_dilation",
    "res5_multi_grid",
    "input_shape"
  ],
  "window_partition": [
    "x",
    "window_size"
  ],
  "window_reverse": [
    "windows",
    "window_size",
    "H",
    "W"
  ],
  "WindowAttention": {
    "__init__": [
      "self",
      "dim",
      "window_size",
      "num_heads",
      "qkv_bias",
      "qk_scale",
      "attn_drop",
      "proj_drop"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "SwinTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "window_size",
      "shift_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "drop_path",
      "act_layer",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x",
      "mask_matrix"
    ]
  },
  "PatchMerging": {
    "__init__": [
      "self",
      "dim",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x",
      "H",
      "W"
    ]
  },
  "BasicLayer": {
    "__init__": [
      "self",
      "dim",
      "depth",
      "num_heads",
      "window_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "drop_path",
      "norm_layer",
      "downsample",
      "use_checkpoint"
    ],
    "forward": [
      "self",
      "x",
      "H",
      "W"
    ]
  },
  "SwinTransformer": {
    "__init__": [
      "self",
      "pretrain_img_size",
      "patch_size",
      "in_chans",
      "embed_dim",
      "depths",
      "num_heads",
      "window_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "norm_layer",
      "ape",
      "patch_norm",
      "out_indices",
      "frozen_stages",
      "use_checkpoint"
    ],
    "_freeze_stages": [
      "self"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "train": [
      "self",
      "mode"
    ]
  },
  "D2SwinTransformer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "output_shape": [
      "self"
    ],
    "size_divisibility": [
      "self"
    ]
  },
  "PositionEmbeddingSine": {
    "__init__": [
      "self",
      "num_pos_feats",
      "temperature",
      "normalize",
      "scale"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ],
    "__repr__": [
      "self",
      "_repr_indent"
    ]
  },
  "MSDeformAttnTransformerEncoderOnly": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "num_encoder_layers",
      "dim_feedforward",
      "dropout",
      "activation",
      "num_feature_levels",
      "enc_n_points"
    ],
    "_reset_parameters": [
      "self"
    ],
    "get_valid_ratio": [
      "self",
      "mask"
    ],
    "forward": [
      "self",
      "srcs",
      "masks",
      "pos_embeds"
    ]
  },
  "MSDeformAttnTransformerEncoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "d_ffn",
      "dropout",
      "activation",
      "n_levels",
      "n_heads",
      "n_points"
    ],
    "with_pos_embed": [
      "tensor",
      "pos"
    ],
    "forward_ffn": [
      "self",
      "src"
    ],
    "forward": [
      "self",
      "src",
      "pos",
      "reference_points",
      "spatial_shapes",
      "level_start_index",
      "padding_mask"
    ]
  },
  "MSDeformAttnTransformerEncoder": {
    "__init__": [
      "self",
      "encoder_layer",
      "num_layers"
    ],
    "get_reference_points": [
      "spatial_shapes",
      "valid_ratios",
      "device"
    ],
    "forward": [
      "self",
      "src",
      "spatial_shapes",
      "level_start_index",
      "valid_ratios",
      "pos",
      "padding_mask"
    ]
  },
  "MaskDINOEncoder": {
    "__init__": [
      "self",
      "input_shape"
    ],
    "c2_xavier_fill": [
      "self",
      "module"
    ],
    "forward_features": [
      "self",
      "features",
      "masks"
    ]
  },
  "MaskDINODecoder": {
    "__init__": [
      "self",
      "in_channels",
      "mask_classification"
    ],
    "get_valid_ratio": [
      "self",
      "mask"
    ],
    "pred_box": [
      "self",
      "reference",
      "hs",
      "ref0"
    ],
    "forward": [
      "self",
      "x",
      "mask_features",
      "masks",
      "targets"
    ],
    "forward_prediction_heads": [
      "self",
      "output",
      "mask_features",
      "pred_mask"
    ],
    "_set_aux_loss": [
      "self",
      "outputs_class",
      "outputs_seg_masks",
      "out_boxes"
    ]
  },
  "Conv2d": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MLP": {
    "__init__": [
      "self",
      "input_dim",
      "hidden_dim",
      "output_dim",
      "num_layers"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_bounding_boxes": [
    "mask_tensor"
  ],
  "box_xyxy_to_cxcywh": [
    "x"
  ],
  "inverse_sigmoid": [
    "x",
    "eps"
  ],
  "gen_encoder_output_proposals": [
    "memory",
    "memory_padding_mask",
    "spatial_shapes"
  ],
  "gen_sineembed_for_position": [
    "pos_tensor"
  ],
  "_get_activation_fn": [
    "activation"
  ],
  "_get_clones": [
    "module",
    "N",
    "layer_share"
  ],
  "_is_power_of_2": [
    "n"
  ],
  "MSDeformAttn": {
    "__init__": [
      "self",
      "d_model",
      "n_levels",
      "n_heads",
      "n_points"
    ],
    "_reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "query",
      "reference_points",
      "input_flatten",
      "input_spatial_shapes",
      "input_level_start_index",
      "input_padding_mask"
    ]
  },
  "TransformerDecoder": {
    "__init__": [
      "self",
      "decoder_layer",
      "num_layers",
      "norm",
      "return_intermediate",
      "d_model",
      "query_dim",
      "modulate_hw_attn",
      "num_feature_levels",
      "deformable_decoder",
      "decoder_query_perturber",
      "dec_layer_number",
      "rm_dec_query_scale",
      "dec_layer_share",
      "dec_layer_dropout_prob"
    ],
    "_reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "tgt_key_padding_mask",
      "memory_key_padding_mask",
      "pos",
      "refpoints_unsigmoid",
      "level_start_index",
      "spatial_shapes",
      "valid_ratios"
    ]
  },
  "DeformableTransformerDecoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "d_ffn",
      "dropout",
      "activation",
      "n_levels",
      "n_heads",
      "n_points",
      "use_deformable_box_attn",
      "key_aware_type"
    ],
    "rm_self_attn_modules": [
      "self"
    ],
    "with_pos_embed": [
      "tensor",
      "pos"
    ],
    "forward_ffn": [
      "self",
      "tgt"
    ],
    "forward": [
      "self",
      "tgt",
      "tgt_query_pos",
      "tgt_query_sine_embed",
      "tgt_key_padding_mask",
      "tgt_reference_points",
      "memory",
      "memory_key_padding_mask",
      "memory_level_start_index",
      "memory_spatial_shapes",
      "memory_pos",
      "self_attn_mask",
      "cross_attn_mask"
    ]
  },
  "build_preprocess_transform": [
    "cfg"
  ],
  "LoadImageFromFile": {
    "__init__": [
      "self",
      "to_float32",
      "mode"
    ],
    "__call__": [
      "self",
      "results"
    ],
    "__repr__": [
      "self"
    ]
  },
  "BaseFPN": {
    "__init__": [
      "self",
      "input_shape"
    ],
    "forward_features": [
      "self",
      "features"
    ],
    "forward": [
      "self",
      "features",
      "targets"
    ]
  },
  "PyramidPoolingModule": {
    "__init__": [
      "self",
      "in_channels",
      "channels",
      "sizes"
    ],
    "_make_stage": [
      "self",
      "features",
      "out_features",
      "size"
    ],
    "forward": [
      "self",
      "feats"
    ]
  },
  "PyramidPoolingModuleFPN": {
    "__init__": [
      "self",
      "input_shape"
    ],
    "forward_features": [
      "self",
      "features"
    ]
  },
  "QueryProposal": {
    "__init__": [
      "self",
      "num_features",
      "num_queries",
      "num_classes"
    ],
    "compute_coordinates": [
      "self",
      "x"
    ],
    "seek_local_maximum": [
      "self",
      "x",
      "epsilon"
    ],
    "forward": [
      "self",
      "x",
      "pos_embeddings"
    ]
  },
  "FastInstDecoder": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x",
      "mask_features",
      "targets"
    ],
    "forward_one_layer": [
      "self",
      "query_features",
      "pixel_features",
      "query_pos_embeds",
      "pixel_pos_embeds",
      "attn_mask",
      "i"
    ],
    "forward_prediction_heads": [
      "self",
      "query_features",
      "pixel_features",
      "pixel_feature_size",
      "idx_layer",
      "return_attn_mask",
      "return_gt_attn_mask",
      "targets",
      "query_locations"
    ],
    "_set_aux_loss": [
      "self",
      "outputs_class",
      "outputs_seg_masks",
      "output_indices",
      "output_query_locations"
    ]
  },
  "ImageBodyReshaping": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "pred_joints": [
      "self",
      "img"
    ],
    "pred_flow": [
      "self",
      "img"
    ],
    "warp": [
      "self",
      "src_img",
      "flow"
    ],
    "inference": [
      "self",
      "img"
    ]
  },
  "PersonInfo": {
    "__init__": [
      "self",
      "joints"
    ],
    "update_attribute": [
      "self",
      "pad_border",
      "height_expand",
      "width_expand"
    ],
    "pred_flow": [
      "self",
      "img",
      "flow_net",
      "device"
    ],
    "blend_multiscale_flow": [
      "x_flows",
      "y_flows",
      "device"
    ],
    "__joint_to_body_box": [
      "self"
    ],
    "__joint_to_leg_box": [
      "self"
    ],
    "__joint_to_arm_box": [
      "self"
    ]
  },
  "resize_on_long_side": [
    "img",
    "long_side"
  ],
  "point_in_box": [
    "pt",
    "box"
  ],
  "enlarge_box_tblr": [
    "roi_bbox",
    "mask",
    "ratio",
    "use_long_side"
  ],
  "gen_PAF": [
    "image",
    "joints"
  ],
  "gen_skeleton_map": [
    "joints",
    "stack_mode",
    "input_roi_box"
  ],
  "plot_one_box": [
    "x",
    "img",
    "color",
    "label",
    "line_thickness"
  ],
  "draw_line": [
    "im",
    "points",
    "color",
    "stroke_size",
    "closed"
  ],
  "enlarged_bbox": [
    "bbox",
    "img_width",
    "img_height",
    "enlarge_ratio"
  ],
  "get_map_fusion_map_cuda": [
    "map_list",
    "threshold",
    "device"
  ],
  "gen_border_shade": [
    "height",
    "width",
    "height_band",
    "width_band"
  ],
  "get_mask_bbox": [
    "mask",
    "threshold"
  ],
  "visualize_flow": [
    "flow"
  ],
  "vis_joints": [
    "image",
    "joints",
    "color",
    "show_text",
    "confidence_threshold"
  ],
  "get_heatmap_cv": [
    "img",
    "magn",
    "max_flow_mag"
  ],
  "save_heatmap_cv": [
    "img",
    "flow",
    "suppression"
  ],
  "bilinear_interp": [
    "x",
    "y",
    "v11",
    "v12",
    "v21",
    "v22"
  ],
  "image_warp_grid1": [
    "rDx",
    "rDy",
    "oriImg",
    "transRatio",
    "width_expand",
    "height_expand"
  ],
  "ConvLayer": {
    "__init__": [
      "self",
      "in_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SASA": {
    "__init__": [
      "self",
      "in_dim"
    ],
    "structure_encoder": [
      "self",
      "paf_mag",
      "target_height",
      "target_width"
    ],
    "forward": [
      "self",
      "X",
      "PAF_mag"
    ]
  },
  "FlowGenerator": {
    "__init__": [
      "self",
      "n_channels",
      "deep_supervision"
    ],
    "warp": [
      "self",
      "x",
      "flow",
      "mode",
      "padding_mode",
      "coff"
    ],
    "forward": [
      "self",
      "img",
      "skeleton_map",
      "coef"
    ]
  },
  "pad_rightdown_corner": [
    "img",
    "stride",
    "padValue"
  ],
  "transfer": [
    "model",
    "model_weights"
  ],
  "make_layers": [
    "block",
    "no_relu_layers"
  ],
  "BodyposeModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Body": {
    "__init__": [
      "self",
      "model_path",
      "device"
    ],
    "__call__": [
      "self",
      "oriImg"
    ]
  },
  "HumanNormalEstimation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "inference": [
      "self",
      "data"
    ]
  },
  "INPUT_CHANNELS_DICT": [],
  "Encoder": {
    "__init__": [
      "self",
      "B",
      "pretrained",
      "ckpt"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvGRU": {
    "__init__": [
      "self",
      "hidden_dim",
      "input_dim",
      "ks"
    ],
    "forward": [
      "self",
      "h",
      "x"
    ]
  },
  "UpSampleBN": {
    "__init__": [
      "self",
      "skip_input",
      "output_features",
      "align_corners"
    ],
    "forward": [
      "self",
      "x",
      "concat_with"
    ]
  },
  "Conv2d_WS": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UpSampleGN": {
    "__init__": [
      "self",
      "skip_input",
      "output_features",
      "align_corners"
    ],
    "forward": [
      "self",
      "x",
      "concat_with"
    ]
  },
  "upsample_via_bilinear": [
    "out",
    "up_mask",
    "downsample_ratio"
  ],
  "upsample_via_mask": [
    "out",
    "up_mask",
    "downsample_ratio",
    "padding"
  ],
  "get_prediction_head": [
    "input_dim",
    "hidden_dim",
    "output_dim"
  ],
  "get_pixel_coords": [
    "h",
    "w"
  ],
  "normal_activation": [
    "out",
    "elu_kappa"
  ],
  "convert_arg_line_to_args": [
    "arg_line"
  ],
  "get_args": [
    "txt_file"
  ],
  "PROJECT_DIR": [],
  "NormalNet": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Decoder": {
    "__init__": [
      "self",
      "num_classes",
      "B",
      "NF",
      "BN",
      "learned_upsampling"
    ],
    "ray_embedding": [
      "self",
      "x",
      "intrins",
      "orig_H",
      "orig_W"
    ],
    "forward": [
      "self",
      "features",
      "intrins"
    ]
  },
  "Adapter": {
    "__init__": [
      "self",
      "dim",
      "adapter_length",
      "adapter_type",
      "act_layer"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "identity"
    ]
  },
  "LoRA": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "lora_length",
      "lora_type"
    ],
    "forward": [
      "self",
      "x",
      "q",
      "k",
      "v"
    ]
  },
  "Prefix": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "prefix_length",
      "prefix_type"
    ],
    "forward": [
      "self",
      "x",
      "q",
      "k",
      "v"
    ]
  },
  "SideTune": {
    "__init__": [
      "self",
      "sidetune_length",
      "sidetune_type"
    ],
    "forward": [
      "self",
      "x",
      "x_base"
    ]
  },
  "FCN4": {
    "__init__": [
      "self",
      "out_dims"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_logger": [],
  "to_1tuple": [],
  "to_2tuple": [],
  "to_3tuple": [],
  "to_4tuple": [],
  "to_ntuple": [],
  "LayerScale": {
    "__init__": [
      "self",
      "dim",
      "init_values",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResPostBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "drop",
      "attn_drop",
      "init_values",
      "drop_path",
      "act_layer",
      "norm_layer"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ParallelBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "num_parallel",
      "mlp_ratio",
      "qkv_bias",
      "init_values",
      "drop",
      "attn_drop",
      "drop_path",
      "act_layer",
      "norm_layer"
    ],
    "_forward_jit": [
      "self",
      "x"
    ],
    "_forward": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "init_weights_vit_timm": [
    "module",
    "name"
  ],
  "init_weights_vit_jax": [
    "module",
    "name",
    "head_bias"
  ],
  "init_weights_vit_moco": [
    "module",
    "name"
  ],
  "get_init_weights_vit": [
    "mode",
    "head_bias"
  ],
  "_load_weights": [
    "model",
    "checkpoint_path",
    "prefix"
  ],
  "resize_pos_embed": [
    "posemb",
    "posemb_new",
    "num_prefix_tokens",
    "gs_new"
  ],
  "VisionEfficientTuningModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "_trunc_normal_": [
    "tensor",
    "mean",
    "std",
    "a",
    "b"
  ],
  "trunc_normal_": [
    "tensor",
    "mean",
    "std",
    "a",
    "b"
  ],
  "trunc_normal_tf_": [
    "tensor",
    "mean",
    "std",
    "a",
    "b"
  ],
  "variance_scaling_": [
    "tensor",
    "scale",
    "mode",
    "distribution"
  ],
  "lecun_normal_": [
    "tensor"
  ],
  "named_apply": [
    "fn",
    "module",
    "name",
    "depth_first",
    "include_root"
  ],
  "adapt_input_conv": [
    "in_chans",
    "conv_weight"
  ],
  "checkpoint_seq": [
    "functions",
    "x",
    "every",
    "flatten",
    "skip_last",
    "preserve_rng_state"
  ],
  "AttentionPETL": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "qkv_bias",
      "attn_drop",
      "proj_drop",
      "prefix_length",
      "prefix_type",
      "lora_length",
      "lora_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BlockPETL": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "drop",
      "attn_drop",
      "init_values",
      "drop_path",
      "act_layer",
      "norm_layer",
      "attn_layer",
      "layer_num",
      "prompt_length",
      "prompt_type",
      "prefix_length",
      "prefix_type",
      "adapter_length",
      "adapter_type",
      "lora_length",
      "lora_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "VisionTransformerPETL": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "in_chans",
      "num_classes",
      "global_pool",
      "embed_dim",
      "depth",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "init_values",
      "class_token",
      "no_embed_class",
      "pre_norm",
      "fc_norm",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "weight_init",
      "embed_layer",
      "norm_layer",
      "act_layer",
      "block_fn",
      "prompt_length",
      "prompt_type",
      "prefix_length",
      "prefix_type",
      "adapter_length",
      "adapter_type",
      "lora_length",
      "lora_type",
      "sidetune_length",
      "sidetune_type"
    ],
    "forward_features": [
      "self",
      "x"
    ],
    "forward_head": [
      "self",
      "res",
      "pre_logits"
    ]
  },
  "VisionEfficientTuning": {
    "__init__": [
      "self",
      "backbone",
      "head",
      "loss",
      "pretrained",
      "finetune"
    ],
    "filter_weight": [
      "self",
      "weights",
      "unload_part"
    ],
    "forward": [
      "self",
      "imgs",
      "labels"
    ],
    "forward_train": [
      "self",
      "imgs",
      "labels"
    ],
    "forward_test": [
      "self",
      "imgs",
      "labels"
    ]
  },
  "ClassifierHead": {
    "__init__": [
      "self",
      "dim",
      "num_classes",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ControlNet": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "get_resolution": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "get_model_dir": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "OpenposeDetector": {
    "__init__": [
      "self",
      "annotator_ckpts_path",
      "device"
    ],
    "__call__": [
      "self",
      "oriImg",
      "hand"
    ]
  },
  "MLSDdetector": {
    "__init__": [
      "self",
      "annotator_ckpts_path",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "thr_v",
      "thr_d"
    ]
  },
  "MidasDetector": {
    "__init__": [
      "self",
      "model_root_path",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "a",
      "bg_th"
    ]
  },
  "HEDNetwork": {
    "__init__": [
      "self",
      "model_path"
    ],
    "forward": [
      "self",
      "tenInput"
    ]
  },
  "CannyDetector": {
    "__call__": [
      "self",
      "img",
      "low_threshold",
      "high_threshold"
    ]
  },
  "HEDdetector": {
    "__init__": [
      "self",
      "annotator_ckpts_path",
      "device"
    ],
    "__call__": [
      "self",
      "input_image"
    ]
  },
  "show_result_pyplot": [
    "model",
    "img",
    "result",
    "palette",
    "fig_size",
    "opacity",
    "title",
    "block"
  ],
  "SegformerDetector": {
    "__init__": [
      "self",
      "annotator_ckpts_path",
      "device"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "decode_output_score_and_ptss": [
    "tpMap",
    "topk_n",
    "ksize"
  ],
  "pred_lines": [
    "image",
    "model",
    "input_shape",
    "score_thr",
    "dist_thr"
  ],
  "params_glob": [],
  "pred_squares": [
    "image",
    "model",
    "input_shape",
    "params"
  ],
  "BlockTypeA": {
    "__init__": [
      "self",
      "in_c1",
      "in_c2",
      "out_c1",
      "out_c2",
      "upscale"
    ],
    "forward": [
      "self",
      "a",
      "b"
    ]
  },
  "BlockTypeB": {
    "__init__": [
      "self",
      "in_c",
      "out_c"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BlockTypeC": {
    "__init__": [
      "self",
      "in_c",
      "out_c"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_make_divisible": [
    "v",
    "divisor",
    "min_value"
  ],
  "ConvBNReLU": {
    "__init__": [
      "self",
      "in_planes",
      "out_planes",
      "kernel_size",
      "stride",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InvertedResidual": {
    "__init__": [
      "self",
      "inp",
      "oup",
      "stride",
      "expand_ratio"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MobileNetV2": {
    "__init__": [
      "self",
      "pretrained"
    ],
    "_forward_impl": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_load_pretrained_model": [
      "self"
    ]
  },
  "MobileV2_MLSD_Large": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Hand": {
    "__init__": [
      "self",
      "model_path",
      "device"
    ],
    "__call__": [
      "self",
      "oriImg"
    ]
  },
  "padRightDownCorner": [
    "img",
    "stride",
    "padValue"
  ],
  "draw_bodypose": [
    "canvas",
    "candidate",
    "subset"
  ],
  "draw_handpose": [
    "canvas",
    "all_hand_peaks",
    "show_number"
  ],
  "handDetect": [
    "candidate",
    "subset",
    "oriImg"
  ],
  "npmax": [
    "array"
  ],
  "bodypose_model": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "handpose_model": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "read_pfm": [
    "path"
  ],
  "write_pfm": [
    "path",
    "image",
    "scale"
  ],
  "read_image": [
    "path"
  ],
  "resize_depth": [
    "depth",
    "width",
    "height"
  ],
  "write_depth": [
    "path",
    "depth",
    "bits"
  ],
  "disabled_train": [
    "self",
    "mode"
  ],
  "load_midas_transform": [
    "model_type"
  ],
  "MiDaSInference": {
    "MODEL_TYPES_TORCH_HUB": [],
    "MODEL_TYPES_ISL": [],
    "__init__": [
      "self",
      "model_type",
      "model_root_path"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_make_encoder": [
    "backbone",
    "features",
    "use_pretrained",
    "groups",
    "expand",
    "exportable",
    "hooks",
    "use_vit_only",
    "use_readout"
  ],
  "_make_scratch": [
    "in_shape",
    "out_shape",
    "groups",
    "expand"
  ],
  "_make_pretrained_efficientnet_lite3": [
    "use_pretrained",
    "exportable"
  ],
  "_make_efficientnet_backbone": [
    "effnet"
  ],
  "_make_resnet_backbone": [
    "resnet"
  ],
  "_make_pretrained_resnext101_wsl": [
    "use_pretrained"
  ],
  "Interpolate": {
    "__init__": [
      "self",
      "scale_factor",
      "mode",
      "align_corners"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResidualConvUnit": {
    "__init__": [
      "self",
      "features"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FeatureFusionBlock": {
    "__init__": [
      "self",
      "features"
    ],
    "forward": [
      "self"
    ]
  },
  "ResidualConvUnit_custom": {
    "__init__": [
      "self",
      "features",
      "activation",
      "bn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FeatureFusionBlock_custom": {
    "__init__": [
      "self",
      "features",
      "activation",
      "deconv",
      "bn",
      "expand",
      "align_corners"
    ],
    "forward": [
      "self"
    ]
  },
  "MidasNet_small": {
    "__init__": [
      "self",
      "path",
      "features",
      "backbone",
      "non_negative",
      "exportable",
      "channels_last",
      "align_corners",
      "blocks"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "fuse_model": [
    "m"
  ],
  "apply_min_size": [
    "sample",
    "size",
    "image_interpolation_method"
  ],
  "PrepareForNet": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "sample"
    ]
  },
  "BaseModel": {
    "load": [
      "self",
      "path"
    ]
  },
  "MidasNet": {
    "__init__": [
      "self",
      "path",
      "features",
      "non_negative"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_make_fusion_block": [
    "features",
    "use_bn"
  ],
  "DPT": {
    "__init__": [
      "self",
      "head",
      "features",
      "backbone",
      "readout",
      "channels_last",
      "use_bn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DPTDepthModel": {
    "__init__": [
      "self",
      "path",
      "non_negative"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Slice": {
    "__init__": [
      "self",
      "start_index"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AddReadout": {
    "__init__": [
      "self",
      "start_index"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ProjectReadout": {
    "__init__": [
      "self",
      "in_features",
      "start_index"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Transpose": {
    "__init__": [
      "self",
      "dim0",
      "dim1"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "forward_vit": [
    "pretrained",
    "x"
  ],
  "_resize_pos_embed": [
    "self",
    "posemb",
    "gs_h",
    "gs_w"
  ],
  "forward_flex": [
    "self",
    "x"
  ],
  "activations": [],
  "get_activation": [
    "name"
  ],
  "get_readout_oper": [
    "vit_features",
    "features",
    "use_readout",
    "start_index"
  ],
  "_make_vit_b16_backbone": [
    "model",
    "features",
    "size",
    "hooks",
    "vit_features",
    "use_readout",
    "start_index"
  ],
  "_make_pretrained_vitl16_384": [
    "pretrained",
    "use_readout",
    "hooks"
  ],
  "_make_pretrained_vitb16_384": [
    "pretrained",
    "use_readout",
    "hooks"
  ],
  "_make_pretrained_deitb16_384": [
    "pretrained",
    "use_readout",
    "hooks"
  ],
  "_make_pretrained_deitb16_distil_384": [
    "pretrained",
    "use_readout",
    "hooks"
  ],
  "_make_vit_b_rn50_backbone": [
    "model",
    "features",
    "size",
    "hooks",
    "vit_features",
    "use_vit_only",
    "use_readout",
    "start_index"
  ],
  "_make_pretrained_vitb_rn50_384": [
    "pretrained",
    "use_readout",
    "hooks",
    "use_vit_only"
  ],
  "M2FP": {
    "__init__": [
      "self",
      "model_dir",
      "backbone",
      "encoder",
      "decoder",
      "pretrained",
      "input_single_human",
      "classes",
      "num_parsing",
      "single_human",
      "parsing_ins_score_thr",
      "parsing_on",
      "semantic_on",
      "sem_seg_postprocess_before_inference"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ],
    "device": [
      "self"
    ],
    "single_human_sem_seg_postprocess": [
      "self",
      "result",
      "img_size",
      "crop_box",
      "output_height",
      "output_width"
    ],
    "sem_seg_postprocess": [
      "self",
      "result",
      "img_size",
      "output_height",
      "output_width"
    ],
    "semantic_inference": [
      "self",
      "mask_cls",
      "mask_pred"
    ],
    "instance_parsing_inference": [
      "self",
      "mask_cls",
      "mask_pred"
    ],
    "paste_instance_to_semseg_probs": [
      "self",
      "labels",
      "scores",
      "mask_probs"
    ],
    "paste_category_probs": [
      "self",
      "scores",
      "mask_probs",
      "h",
      "w"
    ]
  },
  "M2FPHead": {
    "__init__": [
      "self",
      "pixel_decoder",
      "transformer_predictor"
    ],
    "forward": [
      "self",
      "features",
      "mask"
    ],
    "layers": [
      "self",
      "features",
      "mask"
    ]
  },
  "center_to_target_size_test": [
    "img",
    "target_size"
  ],
  "get_box": [
    "src_h",
    "src_w",
    "trg_h",
    "trg_w"
  ],
  "PadTransform": {
    "__init__": [
      "self",
      "src_h",
      "src_w",
      "trg_h",
      "trg_w"
    ],
    "apply_image": [
      "self",
      "img",
      "pad_value"
    ]
  },
  "ResizeTransform": {
    "__init__": [
      "self",
      "h",
      "w",
      "new_h",
      "new_w",
      "interp"
    ],
    "apply_image": [
      "self",
      "img",
      "interp"
    ]
  },
  "get_norm": [
    "norm",
    "out_channels"
  ],
  "BottleneckBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DeepLabStem": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DeeplabResNet": {
    "__init__": [
      "self",
      "stem",
      "stages",
      "num_classes",
      "out_features"
    ],
    "forward": [
      "self",
      "x"
    ],
    "output_shape": [
      "self"
    ],
    "size_divisibility": [
      "self"
    ],
    "make_stage": [
      "block_class",
      "num_blocks"
    ]
  },
  "build_resnet_deeplab_backbone": [
    "out_features",
    "depth",
    "num_groups",
    "width_per_group",
    "norm",
    "stem_out_channels",
    "res2_out_channels",
    "stride_in_1x1",
    "res4_dilation",
    "res5_dilation",
    "res5_multi_grid",
    "input_shape"
  ],
  "MSDeformAttnPixelDecoder": {
    "__init__": [
      "self",
      "input_shape"
    ],
    "forward_features": [
      "self",
      "features"
    ]
  },
  "MultiScaleMaskedTransformerDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "mask_classification"
    ],
    "forward": [
      "self",
      "x",
      "mask_features",
      "mask"
    ],
    "forward_prediction_heads": [
      "self",
      "output",
      "mask_features",
      "attn_mask_target_size"
    ],
    "_set_aux_loss": [
      "self",
      "outputs_class",
      "outputs_seg_masks"
    ]
  },
  "_get_4ps_feat": [
    "cc_match",
    "output"
  ],
  "corner_decode": [
    "mk",
    "st_reg",
    "mk_reg",
    "K"
  ],
  "ctdet_4ps_decode": [
    "heat",
    "wh",
    "ax",
    "cr",
    "corner_dict",
    "reg",
    "cat_spec_wh",
    "K",
    "wiz_rev"
  ],
  "get_affine_transform_upper_left": [
    "center",
    "scale",
    "rot",
    "output_size",
    "shift",
    "inv"
  ],
  "transform_preds_upper_left": [
    "coords",
    "center",
    "scale",
    "output_size",
    "rot"
  ],
  "ctdet_4ps_post_process_upper_left": [
    "dets",
    "c",
    "s",
    "h",
    "w",
    "num_classes",
    "rot"
  ],
  "ctdet_corner_post_process": [
    "corner_st_reg",
    "c",
    "s",
    "h",
    "w",
    "num_classes"
  ],
  "merge_outputs": [
    "detections"
  ],
  "normalized_ps": [
    "ps",
    "vocab_size"
  ],
  "process_detect_output": [
    "output",
    "meta"
  ],
  "process_logic_output": [
    "logi"
  ],
  "load_lore_model": [
    "model",
    "checkpoint",
    "mtype"
  ],
  "LoreModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ChannelAttention": {
    "__init__": [
      "self",
      "in_planes",
      "ratio"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SpatialAttention": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LoreDetectModel": {
    "__init__": [
      "self"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "blocks",
      "stride"
    ],
    "_get_deconv_cfg": [
      "self",
      "deconv_kernel",
      "index"
    ],
    "_make_deconv_layer": [
      "self",
      "num_layers",
      "num_filters",
      "num_kernels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_clones": [
    "module",
    "N"
  ],
  "Transformer": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "output_size",
      "n_layers",
      "heads",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "require_att"
    ]
  },
  "Norm": {
    "__init__": [
      "self",
      "d_model",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "attention": [
    "q",
    "k",
    "v",
    "d_k",
    "mask",
    "dropout"
  ],
  "attention_score": [
    "q",
    "k",
    "v",
    "d_k"
  ],
  "MultiHeadAttention": {
    "__init__": [
      "self",
      "heads",
      "d_model",
      "dropout"
    ],
    "attention_map": [
      "self",
      "q",
      "k",
      "v",
      "mask"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "mask"
    ]
  },
  "FeedForward": {
    "__init__": [
      "self",
      "d_model",
      "d_ff",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Embedder": {
    "__init__": [
      "self",
      "vocab_size",
      "d_model"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PositionalEncoder": {
    "__init__": [
      "self",
      "d_model",
      "max_seq_len",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EncoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "heads",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "require_att"
    ]
  },
  "DecoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "heads",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "e_outputs",
      "src_mask",
      "trg_mask"
    ]
  },
  "Stacker": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "output_size",
      "layers",
      "heads",
      "dropout"
    ],
    "forward": [
      "self",
      "outputs",
      "logi",
      "mask",
      "require_att"
    ]
  },
  "LoreProcessModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "outputs",
      "batch",
      "cc_match",
      "dets"
    ]
  },
  "VFINetForVideoFrameInterpolation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_load_pretrained": [
      "self",
      "flownet_path",
      "internet_path"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "_evaluate_postprocess": [
      "self",
      "input",
      "target"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "VFINet": {
    "__init__": [
      "self",
      "args",
      "Ds_flag"
    ],
    "img_trans": [
      "self",
      "img_tensor"
    ],
    "add_mean": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "imgs",
      "timestep"
    ]
  },
  "AcFusionLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "flo10",
      "flo12",
      "flo21",
      "flo23",
      "t"
    ]
  },
  "Get_gradient": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LowPassFilter": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "backwarp": [
    "img",
    "flow"
  ],
  "SmallMaskNet": {
    "__init__": [
      "self",
      "input",
      "output"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StaticMaskNet": {
    "__init__": [
      "self",
      "input",
      "output"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "tensor_erode": [
    "bin_img",
    "ksize"
  ],
  "QVI_inter_Ds": {
    "__init__": [
      "self",
      "debug_en",
      "is_training"
    ],
    "fill_flow_hole": [
      "self",
      "ft",
      "norm",
      "ft_fill"
    ],
    "forward": [
      "self",
      "F10_Ds",
      "F12_Ds",
      "F21_Ds",
      "F23_Ds",
      "I1_Ds",
      "I2_Ds",
      "I1",
      "I2",
      "t"
    ]
  },
  "QVI_inter": {
    "__init__": [
      "self",
      "debug_en",
      "is_training"
    ],
    "fill_flow_hole": [
      "self",
      "ft",
      "norm",
      "ft_fill"
    ],
    "forward": [
      "self",
      "F10",
      "F12",
      "F21",
      "F23",
      "I1",
      "I2",
      "t"
    ]
  },
  "InterpNetDs": {
    "__init__": [
      "self",
      "debug_en",
      "is_training"
    ],
    "forward": [
      "self",
      "img1",
      "img2",
      "F10_up",
      "F12_up",
      "F21_up",
      "F23_up",
      "UHD",
      "timestep"
    ]
  },
  "InterpNet": {
    "__init__": [
      "self",
      "debug_en",
      "is_training"
    ],
    "forward": [
      "self",
      "img1",
      "img2",
      "F10_up",
      "F12_up",
      "F21_up",
      "F23_up",
      "UHD",
      "timestep"
    ]
  },
  "backwarp_tenGrid": [],
  "warp": [
    "tenInput",
    "tenFlow"
  ],
  "conv_wo_act": [
    "in_planes",
    "out_planes",
    "kernel_size",
    "stride",
    "padding",
    "dilation"
  ],
  "conv": [
    "in_planes",
    "out_planes",
    "kernel_size",
    "stride",
    "padding",
    "dilation"
  ],
  "conv_bn": [
    "in_planes",
    "out_planes",
    "kernel_size",
    "stride",
    "padding",
    "dilation"
  ],
  "TransModel": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "embed_dim",
      "depths",
      "num_heads",
      "window_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "norm_layer",
      "ape",
      "patch_norm",
      "use_checkpoint",
      "resi_connection",
      "use_crossattn"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "no_weight_decay": [
      "self"
    ],
    "no_weight_decay_keywords": [
      "self"
    ],
    "forward_features": [
      "self",
      "x",
      "layers"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "IFBlock": {
    "__init__": [
      "self",
      "in_planes",
      "scale",
      "c"
    ],
    "forward": [
      "self",
      "x",
      "flow0",
      "flow1"
    ]
  },
  "IFBlock_wo_Swin": {
    "__init__": [
      "self",
      "in_planes",
      "scale",
      "c"
    ],
    "forward": [
      "self",
      "x",
      "flow0",
      "flow1"
    ]
  },
  "IFNet": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "img0",
      "img1",
      "flow0",
      "flow1",
      "sc_mode"
    ]
  },
  "FlowReversal": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "img",
      "flo"
    ],
    "get_gaussian_weights": [
      "self",
      "x",
      "y",
      "x1",
      "x2",
      "y1",
      "y2"
    ],
    "sample_one": [
      "self",
      "img",
      "shiftx",
      "shifty",
      "weight"
    ]
  },
  "WindowCrossAttention": {
    "__init__": [
      "self",
      "dim",
      "window_size",
      "num_heads",
      "qkv_bias",
      "qk_scale",
      "attn_drop",
      "proj_drop"
    ],
    "forward": [
      "self",
      "x",
      "y",
      "mask_x",
      "mask_y"
    ],
    "extra_repr": [
      "self"
    ],
    "flops": [
      "self",
      "N"
    ]
  },
  "TFL": {
    "__init__": [
      "self",
      "dim",
      "input_resolution",
      "num_heads",
      "window_size",
      "shift_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "drop_path",
      "act_layer",
      "norm_layer",
      "use_crossattn"
    ],
    "calculate_mask": [
      "self",
      "x_size"
    ],
    "calculate_mask2": [
      "self",
      "x_size"
    ],
    "forward": [
      "self",
      "x",
      "x_size"
    ],
    "extra_repr": [
      "self"
    ],
    "flops": [
      "self"
    ]
  },
  "RTFL": {
    "__init__": [
      "self",
      "dim",
      "input_resolution",
      "depth",
      "num_heads",
      "window_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "drop_path",
      "norm_layer",
      "downsample",
      "use_checkpoint",
      "img_size",
      "patch_size",
      "resi_connection",
      "use_crossattn"
    ],
    "forward": [
      "self",
      "x",
      "x_size"
    ],
    "flops": [
      "self"
    ]
  },
  "PatchUnEmbed": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "in_chans",
      "embed_dim",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x",
      "x_size"
    ],
    "flops": [
      "self"
    ]
  },
  "Upsample": {
    "__init__": [
      "self",
      "scale",
      "num_feat"
    ]
  },
  "UpsampleOneStep": {
    "__init__": [
      "self",
      "scale",
      "num_feat",
      "num_out_ch",
      "input_resolution"
    ],
    "flops": [
      "self"
    ]
  },
  "down": {
    "__init__": [
      "self",
      "inChannels",
      "outChannels",
      "filterSize"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "up": {
    "__init__": [
      "self",
      "inChannels",
      "outChannels"
    ],
    "forward": [
      "self",
      "x",
      "skpCn"
    ]
  },
  "Small_UNet": {
    "__init__": [
      "self",
      "inChannels",
      "outChannels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Small_UNet_Ds": {
    "__init__": [
      "self",
      "inChannels",
      "outChannels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "forward_interpolate": [
    "flow"
  ],
  "bilinear_sampler": [
    "img",
    "coords",
    "mode",
    "mask"
  ],
  "coords_grid": [
    "batch",
    "ht",
    "wd",
    "device"
  ],
  "upflow8": [
    "flow",
    "mode"
  ],
  "calc_hist": [
    "img_tensor"
  ],
  "do_scene_detect": [
    "F01_tensor",
    "F10_tensor",
    "img0_tensor",
    "img1_tensor"
  ],
  "EPE": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "flow",
      "gt",
      "loss_mask"
    ]
  },
  "Ternary": {
    "__init__": [
      "self"
    ],
    "transform": [
      "self",
      "img"
    ],
    "rgb2gray": [
      "self",
      "rgb"
    ],
    "hamming": [
      "self",
      "t1",
      "t2"
    ],
    "valid_mask": [
      "self",
      "t",
      "padding"
    ],
    "forward": [
      "self",
      "img0",
      "img1"
    ]
  },
  "SOBEL": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "pred",
      "gt"
    ]
  },
  "MeanShift": {
    "__init__": [
      "self",
      "data_mean",
      "data_std",
      "data_range",
      "norm"
    ]
  },
  "VGGPerceptualLoss": {
    "__init__": [
      "self",
      "rank"
    ],
    "forward": [
      "self",
      "X",
      "Y",
      "indices"
    ]
  },
  "RIFEModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "load_model": [
      "self",
      "path",
      "rank"
    ],
    "save_model": [
      "self",
      "path",
      "rank"
    ],
    "inference": [
      "self",
      "img0",
      "img1",
      "scale"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "update": [
      "self",
      "imgs",
      "gt",
      "learning_rate",
      "mul",
      "training",
      "flow_gt"
    ]
  },
  "RAFT": {
    "__init__": [
      "self",
      "args"
    ],
    "freeze_bn": [
      "self"
    ],
    "initialize_flow": [
      "self",
      "img"
    ],
    "upsample_flow": [
      "self",
      "flow",
      "mask"
    ],
    "forward": [
      "self",
      "image1",
      "image2",
      "iters",
      "flow_init",
      "upsample",
      "test_mode"
    ]
  },
  "CorrBlock": {
    "__init__": [
      "self",
      "fmap1",
      "fmap2",
      "num_levels",
      "radius"
    ],
    "__call__": [
      "self",
      "coords"
    ],
    "corr": [
      "fmap1",
      "fmap2"
    ]
  },
  "AlternateCorrBlock": {
    "__init__": [
      "self",
      "fmap1",
      "fmap2",
      "num_levels",
      "radius"
    ],
    "__call__": [
      "self",
      "coords"
    ]
  },
  "FlowHead": {
    "__init__": [
      "self",
      "input_dim",
      "hidden_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SepConvGRU": {
    "__init__": [
      "self",
      "hidden_dim",
      "input_dim"
    ],
    "forward": [
      "self",
      "h",
      "x"
    ]
  },
  "SmallMotionEncoder": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "flow",
      "corr"
    ]
  },
  "BasicMotionEncoder": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "flow",
      "corr"
    ]
  },
  "SmallUpdateBlock": {
    "__init__": [
      "self",
      "args",
      "hidden_dim"
    ],
    "forward": [
      "self",
      "net",
      "inp",
      "corr",
      "flow"
    ]
  },
  "BasicUpdateBlock": {
    "__init__": [
      "self",
      "args",
      "hidden_dim",
      "input_dim"
    ],
    "forward": [
      "self",
      "net",
      "inp",
      "corr",
      "flow",
      "upsample"
    ]
  },
  "ResidualBlock": {
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "norm_fn",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BasicEncoder": {
    "__init__": [
      "self",
      "output_dim",
      "norm_fn",
      "dropout"
    ],
    "_make_layer": [
      "self",
      "dim",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SmallEncoder": {
    "__init__": [
      "self",
      "output_dim",
      "norm_fn",
      "dropout"
    ],
    "_make_layer": [
      "self",
      "dim",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "extract_text": [
    "args"
  ],
  "extract_video_features": [
    "video_path",
    "tmp_path",
    "feature_type",
    "i3d_flow_path",
    "i3d_rgb_path",
    "kinetics_class_labels",
    "pwc_path",
    "vggish_model_path",
    "vggish_pca_path",
    "extraction_fps",
    "device"
  ],
  "video_features_to_txt": [
    "duration_in_secs",
    "pretrained_cap_model_path",
    "prop_generator_model_path",
    "features",
    "device_id"
  ],
  "ClipItVideoSummarization": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_train_forward": [
      "self",
      "input"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "PositionalEncoding": {
    "__init__": [
      "self",
      "d_hid",
      "n_position"
    ],
    "_get_sinusoid_encoding_table": [
      "self",
      "n_position",
      "d_hid"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PositionwiseFeedForward": {
    "__init__": [
      "self",
      "d_in",
      "d_hid",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ScaledDotProductAttention": {
    "__init__": [
      "self",
      "temperature",
      "attn_dropout"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "mask"
    ]
  },
  "cfg_128x128_15": [],
  "upsample": [
    "scale",
    "oup"
  ],
  "SE_Block": {
    "__init__": [
      "self",
      "c",
      "r"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BasicBlockSE": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "r"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BottleneckSE": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "r"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PoseHighResolutionNetV2": {
    "__init__": [
      "self",
      "cfg"
    ],
    "_make_transition_layer": [
      "self",
      "num_channels_pre_layer",
      "num_channels_cur_layer"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "blocks",
      "stride"
    ],
    "_make_stage": [
      "self",
      "layer_config",
      "num_inchannels",
      "multi_scale_output"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PanoramaDepthEstimation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "Inputs"
    ],
    "postprocess": [
      "self",
      "Inputs"
    ]
  },
  "mobilenet_v2": [
    "pretrained",
    "progress"
  ],
  "UniFuse": {
    "__init__": [
      "self",
      "num_layers",
      "equi_h",
      "equi_w",
      "pretrained",
      "max_depth",
      "fusion_type",
      "se_in_fusion"
    ],
    "forward": [
      "self",
      "input_equi_image",
      "input_cube_image"
    ]
  },
  "conv1x1": [
    "in_planes",
    "out_planes",
    "stride"
  ],
  "_resnet": [
    "arch",
    "block",
    "layers",
    "pretrained",
    "progress",
    "num_input_images"
  ],
  "resnet18": [
    "pretrained",
    "progress"
  ],
  "resnet34": [
    "pretrained",
    "progress"
  ],
  "resnet50": [
    "pretrained",
    "progress"
  ],
  "resnet101": [
    "pretrained",
    "progress"
  ],
  "resnet152": [
    "pretrained",
    "progress"
  ],
  "resnext50_32x4d": [
    "pretrained",
    "progress"
  ],
  "resnext101_32x8d": [
    "pretrained",
    "progress"
  ],
  "wide_resnet50_2": [
    "pretrained",
    "progress"
  ],
  "wide_resnet101_2": [
    "pretrained",
    "progress"
  ],
  "Equirec2Cube": {
    "__init__": [
      "self",
      "equ_h",
      "equ_w",
      "face_w"
    ],
    "_xyzcube": [
      "self"
    ],
    "_xyz2coor": [
      "self"
    ],
    "sample_equirec": [
      "self",
      "e_img",
      "order"
    ],
    "run": [
      "self",
      "equ_img",
      "equ_dep"
    ]
  },
  "Conv3x3": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Cube2Equirec": {
    "__init__": [
      "self",
      "face_w",
      "equ_h",
      "equ_w"
    ],
    "_equirect_facetype": [
      "self"
    ],
    "_equirect_faceuv": [
      "self"
    ],
    "forward": [
      "self",
      "cube_feat"
    ]
  },
  "Concat": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "equi_feat",
      "c2e_feat"
    ]
  },
  "BiProj": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "equi_feat",
      "c2e_feat"
    ]
  },
  "SELayer": {
    "__init__": [
      "self",
      "channel",
      "reduction"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CEELayer": {
    "__init__": [
      "self",
      "channels",
      "SE"
    ],
    "forward": [
      "self",
      "equi_feat",
      "c2e_feat"
    ]
  },
  "Equi": {
    "__init__": [
      "self",
      "num_layers",
      "equi_h",
      "equi_w",
      "pretrained",
      "max_depth"
    ],
    "forward": [
      "self",
      "input_equi_image",
      "input_cube_image"
    ]
  },
  "GetCropMatrix": {
    "__init__": [
      "self",
      "image_size",
      "target_face_scale",
      "align_corners"
    ],
    "_compose_rotate_and_scale": [
      "self",
      "angle",
      "scale",
      "shift_xy",
      "from_center",
      "to_center"
    ],
    "process": [
      "self",
      "scale",
      "center_w",
      "center_h"
    ]
  },
  "TransformPerspective": {
    "__init__": [
      "self",
      "image_size"
    ],
    "process": [
      "self",
      "image",
      "matrix"
    ]
  },
  "TransformPoints2D": {
    "process": [
      "self",
      "srcPoints",
      "matrix"
    ]
  },
  "Alignment": {
    "__init__": [
      "self",
      "args",
      "model_path",
      "dl_framework",
      "device_ids"
    ],
    "norm_points": [
      "self",
      "points",
      "align_corners"
    ],
    "denorm_points": [
      "self",
      "points",
      "align_corners"
    ],
    "preprocess": [
      "self",
      "image",
      "scale",
      "center_w",
      "center_h"
    ],
    "postprocess": [
      "self",
      "srcPoints",
      "coeff"
    ],
    "analyze": [
      "self",
      "image",
      "scale",
      "center_w",
      "center_h"
    ]
  },
  "FaceLandmarkDetection": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "Inputs"
    ],
    "postprocess": [
      "self",
      "Inputs"
    ],
    "inference": [
      "self",
      "data"
    ]
  },
  "get_config": [
    "args"
  ],
  "get_net": [
    "config"
  ],
  "set_environment": [
    "config"
  ],
  "AlignmentDataset": {
    "__init__": [
      "self",
      "tsv_flie",
      "image_dir",
      "transform",
      "width",
      "height",
      "channels",
      "means",
      "scale",
      "classes_num",
      "crop_op",
      "aug_prob",
      "edge_info",
      "flip_mapping",
      "is_train",
      "encoder_type"
    ],
    "_circle": [
      "self",
      "img",
      "pt",
      "sigma",
      "label_type"
    ],
    "_polylines": [
      "self",
      "img",
      "lmks",
      "is_closed",
      "color",
      "thickness",
      "draw_mode",
      "interpolate_mode",
      "scale"
    ],
    "_generate_edgemap": [
      "self",
      "points",
      "scale",
      "thickness"
    ],
    "_fit_curve": [
      "self",
      "lmks",
      "is_closed",
      "density"
    ],
    "_image_id": [
      "self",
      "image_path"
    ],
    "_load_image": [
      "self",
      "image_path"
    ],
    "_compose_rotate_and_scale": [
      "self",
      "angle",
      "scale",
      "shift_xy",
      "from_center",
      "to_center"
    ],
    "_transformPoints2D": [
      "self",
      "points",
      "matrix"
    ],
    "_transformPerspective": [
      "self",
      "image",
      "matrix",
      "target_shape"
    ],
    "_norm_points": [
      "self",
      "points",
      "h",
      "w",
      "align_corners"
    ],
    "_denorm_points": [
      "self",
      "points",
      "h",
      "w",
      "align_corners"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "get_decoder": [
    "decoder_type"
  ],
  "decoder_default": {
    "__init__": [
      "self",
      "weight",
      "use_weight_map"
    ],
    "_make_grid": [
      "self",
      "h",
      "w"
    ],
    "get_coords_from_heatmap": [
      "self",
      "heatmap"
    ]
  },
  "get_encoder": [
    "image_height",
    "image_width",
    "scale",
    "sigma",
    "encoder_type"
  ],
  "encoder_default": {
    "__init__": [
      "self",
      "image_height",
      "image_width",
      "scale",
      "sigma"
    ],
    "generate_heatmap": [
      "self",
      "points"
    ],
    "_circle": [
      "self",
      "img",
      "pt",
      "sigma",
      "label_type"
    ]
  },
  "Activation": {
    "__init__": [
      "self",
      "kind",
      "channel"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "ResBlock": {
    "__init__": [
      "self",
      "inp_dim",
      "out_dim",
      "mid_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Hourglass": {
    "__init__": [
      "self",
      "n",
      "f",
      "increase",
      "up_mode",
      "add_coord",
      "first_one",
      "x_dim",
      "y_dim"
    ],
    "forward": [
      "self",
      "x",
      "heatmap"
    ]
  },
  "E2HTransform": {
    "__init__": [
      "self",
      "edge_info",
      "num_points",
      "num_edges"
    ],
    "forward": [
      "self",
      "edgemaps"
    ]
  },
  "StackedHGNetV1": {
    "__init__": [
      "self",
      "config",
      "classes_num",
      "edge_info",
      "nstack",
      "nlevels",
      "in_channel",
      "increase",
      "add_coord",
      "decoder_type"
    ],
    "set_inference": [
      "self",
      "inference"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AddCoordsTh": {
    "__init__": [
      "self",
      "x_dim",
      "y_dim",
      "with_r",
      "with_boundary"
    ],
    "forward": [
      "self",
      "input_tensor",
      "heatmap"
    ]
  },
  "CoordConvTh": {
    "__init__": [
      "self",
      "x_dim",
      "y_dim",
      "with_r",
      "with_boundary",
      "in_channels",
      "out_channels",
      "first_one",
      "relu",
      "bn"
    ],
    "forward": [
      "self",
      "input_tensor",
      "heatmap"
    ]
  },
  "AddCoords": {
    "__init__": [
      "self",
      "with_r"
    ],
    "forward": [
      "self",
      "input_tensor"
    ]
  },
  "CoordConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "with_r"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Base": {
    "__init__": [
      "self",
      "config_name",
      "ckpt_dir",
      "image_dir",
      "annot_dir"
    ],
    "init_instance": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "init_from_args": [
      "self",
      "args"
    ]
  },
  "HighResolutionNet": {
    "__init__": [
      "self",
      "leaky_relu",
      "attn_weight",
      "fix_domain",
      "domain_center_model"
    ],
    "_make_transition_layer": [
      "self",
      "num_channels_pre_layer",
      "num_channels_cur_layer"
    ],
    "_make_layer": [
      "self",
      "block",
      "inplanes",
      "planes",
      "blocks",
      "stride"
    ],
    "_make_stage": [
      "self",
      "layer_config",
      "num_inchannels",
      "multi_scale_output"
    ],
    "forward": [
      "self",
      "x"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ]
  },
  "aspp": [
    "aspp_num",
    "aspp_stride",
    "in_channel",
    "use_bn"
  ],
  "HRNetCrowdCounting": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "CartoonModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "input_photo",
      "input_cartoon",
      "input_superpixel"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "VGG_MEAN": [],
  "Vgg19": {
    "__init__": [
      "self",
      "vgg19_npy_path"
    ],
    "build_conv4_4": [
      "self",
      "rgb",
      "include_fc"
    ],
    "max_pool": [
      "self",
      "bottom",
      "name"
    ],
    "conv_layer": [
      "self",
      "bottom",
      "name"
    ],
    "fc_layer": [
      "self",
      "bottom",
      "name"
    ],
    "get_conv_filter": [
      "self",
      "name"
    ],
    "get_bias": [
      "self",
      "name"
    ],
    "get_fc_weight": [
      "self",
      "name"
    ]
  },
  "content_loss": [
    "model_dir",
    "input_photo",
    "transfer_res",
    "input_superpixel"
  ],
  "style_loss": [
    "input_cartoon",
    "output_cartoon"
  ],
  "gan_loss": [
    "discriminator",
    "real",
    "fake",
    "scale",
    "channel",
    "patch",
    "name"
  ],
  "lsgan_loss": [
    "discriminator",
    "real",
    "fake",
    "scale",
    "channel",
    "patch",
    "name"
  ],
  "total_variation_loss": [
    "image",
    "k_size"
  ],
  "guided_filter": [
    "x",
    "y",
    "r",
    "eps"
  ],
  "color_shift": [
    "image1",
    "image2",
    "mode"
  ],
  "simple_superpixel": [
    "batch_image",
    "seg_num"
  ],
  "tf_box_filter": [
    "x",
    "r"
  ],
  "resblock": [
    "inputs",
    "out_channel",
    "name"
  ],
  "spectral_norm": [
    "w",
    "iteration"
  ],
  "conv_spectral_norm": [
    "x",
    "channel",
    "k_size",
    "stride",
    "name"
  ],
  "unet_generator": [
    "inputs",
    "channel",
    "num_blocks",
    "name",
    "reuse"
  ],
  "disc_sn": [
    "x",
    "scale",
    "channel",
    "patch",
    "name",
    "reuse"
  ],
  "resize_size": [
    "image",
    "size"
  ],
  "padTo16x": [
    "image"
  ],
  "get_f5p": [
    "landmarks",
    "np_img"
  ],
  "find_pupil": [
    "landmarks",
    "np_img"
  ],
  "next_batch": [
    "filename_list",
    "batch_size",
    "fineSize"
  ],
  "tf_data_loader": [
    "image_list",
    "batch_size"
  ],
  "write_batch_image": [
    "image",
    "save_dir",
    "name",
    "n"
  ],
  "grid_batch_image": [
    "image",
    "n"
  ],
  "all_file": [
    "file_dir"
  ],
  "MatlabCp2tormException": {
    "__str__": [
      "self"
    ]
  },
  "tformfwd": [
    "trans",
    "uv"
  ],
  "tforminv": [
    "trans",
    "uv"
  ],
  "findNonreflectiveSimilarity": [
    "uv",
    "xy",
    "options"
  ],
  "findSimilarity": [
    "uv",
    "xy",
    "options"
  ],
  "get_similarity_transform": [
    "src_pts",
    "dst_pts",
    "reflective"
  ],
  "cvt_tform_mat_for_cv2": [
    "trans"
  ],
  "get_similarity_transform_for_cv2": [
    "src_pts",
    "dst_pts",
    "reflective"
  ],
  "dx": [],
  "dy": [],
  "REFERENCE_FACIAL_POINTS": [],
  "DEFAULT_CROP_SIZE": [],
  "FaceWarpException": {
    "__str__": [
      "self"
    ]
  },
  "get_reference_facial_points": [
    "output_size",
    "inner_padding_factor",
    "outer_padding",
    "default_square"
  ],
  "get_affine_transform_matrix": [
    "src_pts",
    "dst_pts"
  ],
  "warp_and_crop_face": [
    "src_img",
    "facial_pts",
    "ratio",
    "reference_pts",
    "crop_size",
    "align_type",
    "return_trans_inv"
  ],
  "FaceAna": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "run": [
      "self",
      "image"
    ],
    "sort_res": [
      "self",
      "bboxes",
      "points"
    ],
    "diff_frames": [
      "self",
      "previous_frame",
      "image"
    ],
    "sort": [
      "self",
      "bboxes"
    ],
    "judge_boxs": [
      "self",
      "previous_bboxs",
      "now_bboxs"
    ],
    "smooth": [
      "self",
      "now_box",
      "previous_box"
    ],
    "do_moving_average": [
      "self",
      "p_now",
      "p_previous"
    ],
    "reset": [
      "self"
    ]
  },
  "FaceLandmark": {
    "__init__": [
      "self",
      "dir"
    ],
    "__call__": [
      "self",
      "img",
      "bboxes"
    ],
    "simple_run": [
      "self",
      "cropped_img"
    ],
    "_one_shot_run": [
      "self",
      "image",
      "bbox",
      "i"
    ],
    "init_model": [
      "self"
    ]
  },
  "FaceDetector": {
    "__init__": [
      "self",
      "dir"
    ],
    "__call__": [
      "self",
      "image"
    ],
    "preprocess": [
      "self",
      "image",
      "target_height",
      "target_width",
      "label"
    ],
    "init_model": [
      "self"
    ]
  },
  "config": [],
  "GroupTrack": {
    "__init__": [
      "self"
    ],
    "calculate": [
      "self",
      "img",
      "current_landmarks_set"
    ],
    "iou": [
      "self",
      "p_set0",
      "p_set1"
    ],
    "smooth": [
      "self",
      "now_landmarks",
      "previous_landmarks"
    ],
    "do_moving_average": [
      "self",
      "p_now",
      "p_previous"
    ]
  },
  "save_pickle": [
    "data",
    "pkl_path"
  ],
  "read_pickle": [
    "pkl_path"
  ],
  "draw_epipolar_line": [
    "F",
    "img0",
    "img1",
    "pt0",
    "color"
  ],
  "draw_epipolar_lines": [
    "F",
    "img0",
    "img1",
    "num"
  ],
  "compute_F": [
    "K1",
    "K2",
    "Rt0",
    "Rt1"
  ],
  "compute_dR_dt": [
    "Rt0",
    "Rt1"
  ],
  "concat_images": [
    "img0",
    "img1",
    "vert"
  ],
  "concat_images_list": [],
  "pose_inverse": [
    "pose"
  ],
  "project_points": [
    "pts",
    "RT",
    "K"
  ],
  "output_points": [
    "fn",
    "pts",
    "colors"
  ],
  "read_depth_objaverse": [
    "depth_fn"
  ],
  "mask_depth_to_pts": [
    "mask",
    "depth",
    "K",
    "rgb"
  ],
  "transform_points_pose": [
    "pts",
    "pose"
  ],
  "pose_apply": [
    "pose",
    "pts"
  ],
  "downsample_gaussian_blur": [
    "img",
    "ratio"
  ],
  "pil_rectangle_crop": [
    "im"
  ],
  "add_margin": [
    "pil_img",
    "color",
    "size"
  ],
  "create_carvekit_interface": [],
  "load_and_preprocess": [
    "interface",
    "input_im"
  ],
  "log_txt_as_img": [
    "wh",
    "xc",
    "size"
  ],
  "ismap": [
    "x"
  ],
  "isimage": [
    "x"
  ],
  "exists": [
    "x"
  ],
  "default": [
    "val",
    "d"
  ],
  "mean_flat": [
    "tensor"
  ],
  "count_params": [
    "model",
    "verbose"
  ],
  "instantiate_from_config": [
    "config"
  ],
  "get_obj_from_str": [
    "string",
    "reload"
  ],
  "AdamWwithEMAandWings": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "ema_decay",
      "ema_power",
      "param_names"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "VQModel": {
    "__init__": [
      "self",
      "ddconfig",
      "lossconfig",
      "n_embed",
      "embed_dim",
      "ckpt_path",
      "ignore_keys",
      "image_key",
      "colorize_nlabels",
      "monitor",
      "batch_resize_range",
      "scheduler_config",
      "lr_g_factor",
      "remap",
      "sane_index_shape",
      "use_ema"
    ],
    "ema_scope": [
      "self",
      "context"
    ],
    "init_from_ckpt": [
      "self",
      "path",
      "ignore_keys"
    ],
    "on_train_batch_end": [
      "self"
    ],
    "encode": [
      "self",
      "x"
    ],
    "encode_to_prequant": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "quant"
    ],
    "decode_code": [
      "self",
      "code_b"
    ],
    "forward": [
      "self",
      "input",
      "return_pred_indices"
    ],
    "get_input": [
      "self",
      "batch",
      "k"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx",
      "optimizer_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "_validation_step": [
      "self",
      "batch",
      "batch_idx",
      "suffix"
    ],
    "configure_optimizers": [
      "self"
    ],
    "get_last_layer": [
      "self"
    ],
    "log_images": [
      "self",
      "batch",
      "only_inputs",
      "plot_ema"
    ],
    "to_rgb": [
      "self",
      "x"
    ]
  },
  "VQModelInterface": {
    "__init__": [
      "self",
      "embed_dim"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "h",
      "force_not_quantize"
    ]
  },
  "AutoencoderKL": {
    "__init__": [
      "self",
      "ddconfig",
      "lossconfig",
      "embed_dim",
      "ckpt_path",
      "ignore_keys",
      "image_key",
      "colorize_nlabels",
      "monitor"
    ],
    "init_from_ckpt": [
      "self",
      "path",
      "ignore_keys"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "z"
    ],
    "forward": [
      "self",
      "input",
      "sample_posterior"
    ],
    "get_input": [
      "self",
      "batch",
      "k"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx",
      "optimizer_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "configure_optimizers": [
      "self"
    ],
    "get_last_layer": [
      "self"
    ],
    "log_images": [
      "self",
      "batch",
      "only_inputs"
    ],
    "to_rgb": [
      "self",
      "x"
    ]
  },
  "IdentityFirstStage": {
    "__init__": [
      "self"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "x"
    ],
    "quantize": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DepthAttention": {
    "__init__": [
      "self",
      "query_dim",
      "context_dim",
      "heads",
      "dim_head",
      "output_bias"
    ],
    "forward": [
      "self",
      "x",
      "context"
    ]
  },
  "DepthTransformer": {
    "__init__": [
      "self",
      "dim",
      "n_heads",
      "d_head",
      "context_dim",
      "checkpoint"
    ],
    "forward": [
      "self",
      "x",
      "context"
    ],
    "_forward": [
      "self",
      "x",
      "context"
    ]
  },
  "DepthWiseAttention": {
    "__init__": [
      "self",
      "volume_dims"
    ],
    "forward": [
      "self",
      "x",
      "timesteps",
      "context",
      "source_dict"
    ],
    "get_trainable_parameters": [
      "self"
    ]
  },
  "Image2DResBlockWithTV": {
    "__init__": [
      "self",
      "dim",
      "tdim",
      "vdim"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "v"
    ]
  },
  "NoisyTargetViewEncoder": {
    "__init__": [
      "self",
      "time_embed_dim",
      "viewpoint_dim",
      "run_dim",
      "output_dim"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "v"
    ]
  },
  "SpatialUpTimeBlock": {
    "__init__": [
      "self",
      "x_in_dim",
      "t_in_dim",
      "out_dim"
    ],
    "forward": [
      "self",
      "x",
      "t"
    ]
  },
  "SpatialTimeBlock": {
    "__init__": [
      "self",
      "x_in_dim",
      "t_in_dim",
      "out_dim",
      "stride"
    ],
    "forward": [
      "self",
      "x",
      "t"
    ]
  },
  "SpatialTime3DNet": {
    "__init__": [
      "self",
      "time_dim",
      "input_dim",
      "dims"
    ],
    "forward": [
      "self",
      "x",
      "t"
    ]
  },
  "FrustumTVBlock": {
    "__init__": [
      "self",
      "x_dim",
      "t_dim",
      "v_dim",
      "out_dim",
      "stride"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "v"
    ]
  },
  "FrustumTVUpBlock": {
    "__init__": [
      "self",
      "x_dim",
      "t_dim",
      "v_dim",
      "out_dim"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "v"
    ]
  },
  "FrustumTV3DNet": {
    "__init__": [
      "self",
      "in_dim",
      "t_dim",
      "v_dim",
      "dims"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "v"
    ]
  },
  "disable_training_module": [
    "module"
  ],
  "repeat_to_batch": [
    "tensor",
    "B",
    "VN"
  ],
  "UNetWrapper": {
    "__init__": [
      "self",
      "diff_model_config",
      "drop_conditions",
      "drop_scheme",
      "use_zero_123"
    ],
    "drop": [
      "self",
      "cond",
      "mask"
    ],
    "get_trainable_parameters": [
      "self"
    ],
    "get_drop_scheme": [
      "self",
      "B",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "clip_embed",
      "volume_feats",
      "x_concat",
      "is_train"
    ],
    "predict_with_unconditional_scale": [
      "self",
      "x",
      "t",
      "clip_embed",
      "volume_feats",
      "x_concat",
      "unconditional_scale"
    ]
  },
  "SpatialVolumeNet": {
    "__init__": [
      "self",
      "time_dim",
      "view_dim",
      "view_num",
      "input_image_size",
      "frustum_volume_depth",
      "spatial_volume_size",
      "spatial_volume_length",
      "frustum_volume_length"
    ],
    "construct_spatial_volume": [
      "self",
      "x",
      "t_embed",
      "v_embed",
      "target_poses",
      "target_Ks"
    ],
    "construct_view_frustum_volume": [
      "self",
      "spatial_volume",
      "t_embed",
      "v_embed",
      "poses",
      "Ks",
      "target_indices"
    ]
  },
  "SyncMultiviewDiffusion": {
    "__init__": [
      "self",
      "unet_config",
      "scheduler_config",
      "finetune_unet",
      "finetune_projection",
      "view_num",
      "image_size",
      "cfg_scale",
      "output_num",
      "batch_view_num",
      "drop_conditions",
      "drop_scheme",
      "clip_image_encoder_path"
    ],
    "_init_clip_projection": [
      "self"
    ],
    "_init_multiview": [
      "self"
    ],
    "get_viewpoint_embedding": [
      "self",
      "batch_size",
      "elevation_ref"
    ],
    "_init_first_stage": [
      "self"
    ],
    "_init_clip_image_encoder": [
      "self"
    ],
    "_init_schedule": [
      "self"
    ],
    "_init_time_step_embedding": [
      "self"
    ],
    "encode_first_stage": [
      "self",
      "x",
      "sample"
    ],
    "decode_first_stage": [
      "self",
      "z"
    ],
    "prepare": [
      "self",
      "batch"
    ],
    "embed_time": [
      "self",
      "t"
    ],
    "get_target_view_feats": [
      "self",
      "x_input",
      "spatial_volume",
      "clip_embed",
      "t_embed",
      "v_embed",
      "target_index"
    ],
    "training_step": [
      "self",
      "batch"
    ],
    "add_noise": [
      "self",
      "x_start",
      "t"
    ],
    "sample": [
      "self",
      "batch",
      "cfg_scale",
      "batch_view_num",
      "use_ddim",
      "return_inter_results",
      "inter_interval",
      "inter_view_interval"
    ],
    "log_image": [
      "self",
      "x_sample",
      "batch",
      "step",
      "output_dir",
      "only_first_row"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "configure_optimizers": [
      "self"
    ]
  },
  "SyncDDIMSampler": {
    "__init__": [
      "self",
      "model",
      "ddim_num_steps",
      "ddim_discretize",
      "ddim_eta",
      "latent_size"
    ],
    "_make_schedule": [
      "self",
      "ddim_num_steps",
      "ddim_discretize",
      "ddim_eta",
      "verbose"
    ],
    "denoise_apply_impl": [
      "self",
      "x_target_noisy",
      "index",
      "noise_pred",
      "is_step0"
    ],
    "denoise_apply": [
      "self",
      "x_target_noisy",
      "input_info",
      "clip_embed",
      "time_steps",
      "index",
      "unconditional_scale",
      "batch_view_num",
      "is_step0"
    ],
    "sample": [
      "self",
      "input_info",
      "clip_embed",
      "unconditional_scale",
      "log_every_t",
      "batch_view_num"
    ]
  },
  "project_and_normalize": [
    "ref_grid",
    "src_proj",
    "length"
  ],
  "construct_project_matrix": [
    "x_ratio",
    "y_ratio",
    "Ks",
    "poses"
  ],
  "get_warp_coordinates": [
    "volume_xyz",
    "warp_size",
    "input_size",
    "Ks",
    "warp_pose"
  ],
  "create_target_volume": [
    "depth_size",
    "volume_size",
    "input_image_size",
    "pose_target",
    "K",
    "near",
    "far"
  ],
  "near_far_from_unit_sphere_using_camera_poses": [
    "camera_poses"
  ],
  "Backbone": {
    "__init__": [
      "self",
      "input_size",
      "num_layers",
      "mode",
      "drop_ratio",
      "affine"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "IR_50": [
    "input_size"
  ],
  "IR_101": [
    "input_size"
  ],
  "IR_152": [
    "input_size"
  ],
  "IR_SE_50": [
    "input_size"
  ],
  "IR_SE_101": [
    "input_size"
  ],
  "IR_SE_152": [
    "input_size"
  ],
  "Flatten": {
    "forward": [
      "self",
      "input"
    ]
  },
  "l2_norm": [
    "input",
    "axis"
  ],
  "get_block": [
    "in_channel",
    "depth",
    "num_units",
    "stride"
  ],
  "get_blocks": [
    "num_layers"
  ],
  "SEModule": {
    "__init__": [
      "self",
      "channels",
      "reduction"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "bottleneck_IR": {
    "__init__": [
      "self",
      "in_channel",
      "depth",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "bottleneck_IR_SE": {
    "__init__": [
      "self",
      "in_channel",
      "depth",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "IDFeatures": {
    "__init__": [
      "self",
      "model_path"
    ],
    "forward": [
      "self",
      "x",
      "crop"
    ]
  },
  "DEFAULT_DIM_HEAD": [],
  "Intermediates": [],
  "LayerIntermediates": [],
  "AbsolutePositionalEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_seq_len"
    ],
    "init_": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FixedPositionalEmbedding": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x",
      "seq_dim",
      "offset"
    ]
  },
  "always": [
    "val"
  ],
  "not_equals": [
    "val"
  ],
  "equals": [
    "val"
  ],
  "max_neg_value": [
    "tensor"
  ],
  "pick_and_pop": [
    "keys",
    "d"
  ],
  "group_dict_by_key": [
    "cond",
    "d"
  ],
  "string_begins_with": [
    "prefix",
    "str"
  ],
  "group_by_key_prefix": [
    "prefix",
    "d"
  ],
  "groupby_prefix_and_trim": [
    "prefix",
    "d"
  ],
  "Scale": {
    "__init__": [
      "self",
      "value",
      "fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Rezero": {
    "__init__": [
      "self",
      "fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ScaleNorm": {
    "__init__": [
      "self",
      "dim",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RMSNorm": {
    "__init__": [
      "self",
      "dim",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Residual": {
    "forward": [
      "self",
      "x",
      "residual"
    ]
  },
  "GRUGating": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x",
      "residual"
    ]
  },
  "GEGLU": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AttentionLayers": {
    "__init__": [
      "self",
      "dim",
      "depth",
      "heads",
      "causal",
      "cross_attend",
      "only_cross",
      "use_scalenorm",
      "use_rmsnorm",
      "use_rezero",
      "rel_pos_num_buckets",
      "rel_pos_max_distance",
      "position_infused_attn",
      "custom_layers",
      "sandwich_coef",
      "par_ratio",
      "residual_attn",
      "cross_residual_attn",
      "macaron",
      "pre_norm",
      "gate_residual"
    ],
    "forward": [
      "self",
      "x",
      "context",
      "mask",
      "context_mask",
      "mems",
      "return_hiddens"
    ]
  },
  "TransformerWrapper": {
    "__init__": [
      "self"
    ],
    "init_": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "return_embeddings",
      "mask",
      "return_mems",
      "return_attn",
      "mems"
    ]
  },
  "uniq": [
    "arr"
  ],
  "init_": [
    "tensor"
  ],
  "ConvGEGLU": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "zero_module": [
    "module"
  ],
  "LinearAttention": {
    "__init__": [
      "self",
      "dim",
      "heads",
      "dim_head"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SpatialSelfAttention": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CrossAttention": {
    "__init__": [
      "self",
      "query_dim",
      "context_dim",
      "heads",
      "dim_head",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "context",
      "mask"
    ]
  },
  "BasicSpatialTransformer": {
    "__init__": [
      "self",
      "dim",
      "n_heads",
      "d_head",
      "context_dim",
      "checkpoint"
    ],
    "forward": [
      "self",
      "x",
      "context"
    ],
    "_forward": [
      "self",
      "x",
      "context"
    ]
  },
  "BasicTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "n_heads",
      "d_head",
      "dropout",
      "context_dim",
      "gated_ff",
      "checkpoint",
      "disable_self_attn"
    ],
    "forward": [
      "self",
      "x",
      "context"
    ],
    "_forward": [
      "self",
      "x",
      "context"
    ]
  },
  "ConvFeedForward": {
    "__init__": [
      "self",
      "dim",
      "dim_out",
      "mult",
      "glu",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SpatialTransformer": {
    "__init__": [
      "self",
      "in_channels",
      "n_heads",
      "d_head",
      "depth",
      "dropout",
      "context_dim",
      "disable_self_attn"
    ],
    "forward": [
      "self",
      "x",
      "context"
    ]
  },
  "AbstractEncoder": {
    "__init__": [
      "self"
    ],
    "encode": [
      "self"
    ]
  },
  "IdentityEncoder": {
    "encode": [
      "self",
      "x"
    ]
  },
  "FaceClipEncoder": {
    "__init__": [
      "self",
      "augment",
      "retreival_key"
    ],
    "forward": [
      "self",
      "img"
    ],
    "encode": [
      "self",
      "img"
    ]
  },
  "FaceIdClipEncoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "img"
    ],
    "encode": [
      "self",
      "img"
    ]
  },
  "ClassEmbedder": {
    "__init__": [
      "self",
      "embed_dim",
      "n_classes",
      "key"
    ],
    "forward": [
      "self",
      "batch",
      "key"
    ]
  },
  "TransformerEmbedder": {
    "__init__": [
      "self",
      "n_embed",
      "n_layer",
      "vocab_size",
      "max_seq_len",
      "device"
    ],
    "forward": [
      "self",
      "tokens"
    ],
    "encode": [
      "self",
      "x"
    ]
  },
  "BERTTokenizer": {
    "__init__": [
      "self",
      "device",
      "vq_interface",
      "max_length"
    ],
    "forward": [
      "self",
      "text"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "text"
    ]
  },
  "BERTEmbedder": {
    "__init__": [
      "self",
      "n_embed",
      "n_layer",
      "vocab_size",
      "max_seq_len",
      "device",
      "use_tokenizer",
      "embedding_dropout"
    ],
    "forward": [
      "self",
      "text"
    ],
    "encode": [
      "self",
      "text"
    ]
  },
  "FrozenT5Embedder": {
    "__init__": [
      "self",
      "version",
      "device",
      "max_length"
    ],
    "freeze": [
      "self"
    ],
    "forward": [
      "self",
      "text"
    ],
    "encode": [
      "self",
      "text"
    ]
  },
  "FrozenFaceEncoder": {
    "__init__": [
      "self",
      "model_path",
      "augment"
    ],
    "forward": [
      "self",
      "img"
    ],
    "encode": [
      "self",
      "img"
    ]
  },
  "FrozenCLIPEmbedder": {
    "__init__": [
      "self",
      "version",
      "device",
      "max_length"
    ],
    "freeze": [
      "self"
    ],
    "forward": [
      "self",
      "text"
    ],
    "encode": [
      "self",
      "text"
    ]
  },
  "ClipImageProjector": {
    "__init__": [
      "self",
      "version",
      "max_length"
    ],
    "get_null_cond": [
      "self",
      "version",
      "max_length"
    ],
    "preprocess": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ],
    "encode": [
      "self",
      "im"
    ]
  },
  "ProjectedFrozenCLIPEmbedder": {
    "__init__": [
      "self",
      "version",
      "device",
      "max_length"
    ],
    "forward": [
      "self",
      "text"
    ],
    "encode": [
      "self",
      "text"
    ]
  },
  "FrozenCLIPImageEmbedder": {
    "__init__": [
      "self",
      "model",
      "jit",
      "device",
      "antialias"
    ],
    "preprocess": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ],
    "encode": [
      "self",
      "im"
    ]
  },
  "FrozenCLIPImageMutliEmbedder": {
    "__init__": [
      "self",
      "model",
      "jit",
      "device",
      "antialias",
      "max_crops"
    ],
    "preprocess": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ],
    "encode": [
      "self",
      "im"
    ]
  },
  "SpatialRescaler": {
    "__init__": [
      "self",
      "n_stages",
      "method",
      "multiplier",
      "in_channels",
      "out_channels",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ],
    "encode": [
      "self",
      "x"
    ]
  },
  "LowScaleEncoder": {
    "__init__": [
      "self",
      "model_config",
      "linear_start",
      "linear_end",
      "timesteps",
      "max_noise_level",
      "output_size",
      "scale_factor"
    ],
    "register_schedule": [
      "self",
      "beta_schedule",
      "timesteps",
      "linear_start",
      "linear_end",
      "cosine_s"
    ],
    "q_sample": [
      "self",
      "x_start",
      "t",
      "noise"
    ],
    "forward": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "z"
    ]
  },
  "_MODELS": [],
  "_download": [
    "url",
    "root"
  ],
  "_convert_image_to_rgb": [
    "image"
  ],
  "_transform": [
    "n_px"
  ],
  "available_models": [],
  "AttentionPool2d": {
    "__init__": [
      "self",
      "spacial_dim",
      "embed_dim",
      "num_heads",
      "output_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ModifiedResNet": {
    "__init__": [
      "self",
      "layers",
      "output_dim",
      "heads",
      "input_resolution",
      "width"
    ],
    "_make_layer": [
      "self",
      "planes",
      "blocks",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QuickGELU": {
    "forward": [
      "self",
      "x"
    ]
  },
  "ResidualAttentionBlock": {
    "__init__": [
      "self",
      "d_model",
      "n_head",
      "attn_mask"
    ],
    "attention": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CLIP": {
    "__init__": [
      "self",
      "embed_dim",
      "image_resolution",
      "vision_layers",
      "vision_width",
      "vision_patch_size",
      "context_length",
      "vocab_size",
      "transformer_width",
      "transformer_heads",
      "transformer_layers"
    ],
    "initialize_parameters": [
      "self"
    ],
    "build_attention_mask": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "encode_image": [
      "self",
      "image"
    ],
    "encode_text": [
      "self",
      "text"
    ],
    "forward": [
      "self",
      "image",
      "text"
    ]
  },
  "convert_weights": [
    "model"
  ],
  "default_bpe": [],
  "basic_clean": [
    "text"
  ],
  "whitespace_clean": [
    "text"
  ],
  "SimpleTokenizer": {
    "__init__": [
      "self",
      "bpe_path"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "tokens"
    ]
  },
  "make_beta_schedule": [
    "schedule",
    "n_timestep",
    "linear_start",
    "linear_end",
    "cosine_s"
  ],
  "make_ddim_timesteps": [
    "ddim_discr_method",
    "num_ddim_timesteps",
    "num_ddpm_timesteps",
    "verbose"
  ],
  "make_ddim_sampling_parameters": [
    "alphacums",
    "ddim_timesteps",
    "eta",
    "verbose"
  ],
  "betas_for_alpha_bar": [
    "num_diffusion_timesteps",
    "alpha_bar",
    "max_beta"
  ],
  "extract_into_tensor": [
    "a",
    "t",
    "x_shape"
  ],
  "checkpoint": [
    "func",
    "inputs",
    "params",
    "flag"
  ],
  "CheckpointFunction": {
    "forward": [
      "ctx",
      "run_function",
      "length"
    ],
    "backward": [
      "ctx"
    ]
  },
  "timestep_embedding": [
    "timesteps",
    "dim",
    "max_period",
    "repeat_only"
  ],
  "scale_module": [
    "module",
    "scale"
  ],
  "normalization": [
    "channels"
  ],
  "SiLU": {
    "forward": [
      "self",
      "x"
    ]
  },
  "GroupNorm32": {
    "forward": [
      "self",
      "x"
    ]
  },
  "conv_nd": [
    "dims"
  ],
  "linear": [],
  "avg_pool_nd": [
    "dims"
  ],
  "HybridConditioner": {
    "__init__": [
      "self",
      "c_concat_config",
      "c_crossattn_config"
    ],
    "forward": [
      "self",
      "c_concat",
      "c_crossattn"
    ]
  },
  "noise_like": [
    "shape",
    "device",
    "repeat"
  ],
  "get_timestep_embedding": [
    "timesteps",
    "embedding_dim"
  ],
  "nonlinearity": [
    "x"
  ],
  "Downsample": {
    "__init__": [
      "self",
      "in_channels",
      "with_conv"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResnetBlock": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "temb"
    ]
  },
  "LinAttnBlock": {
    "__init__": [
      "self",
      "in_channels"
    ]
  },
  "AttnBlock": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "make_attn": [
    "in_channels",
    "attn_type"
  ],
  "Model": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "context"
    ],
    "get_last_layer": [
      "self"
    ]
  },
  "SimpleDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UpsampleDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "ch",
      "num_res_blocks",
      "resolution",
      "ch_mult",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LatentRescaler": {
    "__init__": [
      "self",
      "factor",
      "in_channels",
      "mid_channels",
      "out_channels",
      "depth"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MergedRescaleEncoder": {
    "__init__": [
      "self",
      "in_channels",
      "ch",
      "resolution",
      "out_ch",
      "num_res_blocks",
      "attn_resolutions",
      "dropout",
      "resamp_with_conv",
      "ch_mult",
      "rescale_factor",
      "rescale_module_depth"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MergedRescaleDecoder": {
    "__init__": [
      "self",
      "z_channels",
      "out_ch",
      "resolution",
      "num_res_blocks",
      "attn_resolutions",
      "ch",
      "ch_mult",
      "dropout",
      "resamp_with_conv",
      "rescale_factor",
      "rescale_module_depth"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Upsampler": {
    "__init__": [
      "self",
      "in_size",
      "out_size",
      "in_channels",
      "out_channels",
      "ch_mult"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FirstStagePostProcessor": {
    "__init__": [
      "self",
      "ch_mult",
      "in_channels",
      "pretrained_model",
      "reshape",
      "n_channels",
      "dropout",
      "pretrained_config"
    ],
    "instantiate_pretrained": [
      "self",
      "config"
    ],
    "encode_with_pretrained": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "convert_module_to_f16": [
    "x"
  ],
  "convert_module_to_f32": [
    "x"
  ],
  "TimestepBlock": {
    "forward": [
      "self",
      "x",
      "emb"
    ]
  },
  "TimestepEmbedSequential": {
    "forward": [
      "self",
      "x",
      "emb",
      "context"
    ]
  },
  "TransposedUpsample": {
    "__init__": [
      "self",
      "channels",
      "out_channels",
      "ks"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AttentionBlock": {
    "__init__": [
      "self",
      "channels",
      "num_heads",
      "num_head_channels",
      "use_checkpoint",
      "use_new_attention_order"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_forward": [
      "self",
      "x"
    ]
  },
  "count_flops_attn": [
    "model",
    "_x",
    "y"
  ],
  "QKVAttentionLegacy": {
    "__init__": [
      "self",
      "n_heads"
    ],
    "forward": [
      "self",
      "qkv"
    ],
    "count_flops": [
      "model",
      "_x",
      "y"
    ]
  },
  "QKVAttention": {
    "__init__": [
      "self",
      "n_heads"
    ],
    "forward": [
      "self",
      "qkv"
    ],
    "count_flops": [
      "model",
      "_x",
      "y"
    ]
  },
  "UNetModel": {
    "__init__": [
      "self",
      "image_size",
      "in_channels",
      "model_channels",
      "out_channels",
      "num_res_blocks",
      "attention_resolutions",
      "dropout",
      "channel_mult",
      "conv_resample",
      "dims",
      "num_classes",
      "use_checkpoint",
      "use_fp16",
      "num_heads",
      "num_head_channels",
      "num_heads_upsample",
      "use_scale_shift_norm",
      "resblock_updown",
      "use_new_attention_order",
      "use_spatial_transformer",
      "transformer_depth",
      "context_dim",
      "n_embed",
      "legacy",
      "disable_self_attentions",
      "num_attention_blocks"
    ],
    "convert_to_fp16": [
      "self"
    ],
    "convert_to_fp32": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "timesteps",
      "context",
      "y"
    ]
  },
  "EncoderUNetModel": {
    "__init__": [
      "self",
      "image_size",
      "in_channels",
      "model_channels",
      "out_channels",
      "num_res_blocks",
      "attention_resolutions",
      "dropout",
      "channel_mult",
      "conv_resample",
      "dims",
      "use_checkpoint",
      "use_fp16",
      "num_heads",
      "num_head_channels",
      "num_heads_upsample",
      "use_scale_shift_norm",
      "resblock_updown",
      "use_new_attention_order",
      "pool"
    ],
    "convert_to_fp16": [
      "self"
    ],
    "convert_to_fp32": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "timesteps"
    ]
  },
  "AbstractDistribution": {
    "sample": [
      "self"
    ],
    "mode": [
      "self"
    ]
  },
  "DiracDistribution": {
    "__init__": [
      "self",
      "value"
    ],
    "sample": [
      "self"
    ],
    "mode": [
      "self"
    ]
  },
  "DiagonalGaussianDistribution": {
    "__init__": [
      "self",
      "parameters",
      "deterministic"
    ],
    "sample": [
      "self"
    ],
    "kl": [
      "self",
      "other"
    ],
    "nll": [
      "self",
      "sample",
      "dims"
    ],
    "mode": [
      "self"
    ]
  },
  "normal_kl": [
    "mean1",
    "logvar1",
    "mean2",
    "logvar2"
  ],
  "DeinterlaceNet": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "frames"
    ]
  },
  "UNetForVideoDeinterlace": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_load_pretrained": [
      "self",
      "frenet_path",
      "enhnet_path"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "_evaluate_postprocess": [
      "self",
      "input",
      "target"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "DoubleConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "mid_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TripleConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "mid_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DownConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_conv"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UpCatConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bilinear"
    ],
    "interpolate": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x1",
      "x2"
    ]
  },
  "DeinterlaceFre": {
    "__init__": [
      "self",
      "num_in_ch",
      "num_out_ch",
      "ngf"
    ],
    "interpolate": [
      "self",
      "feat",
      "x2",
      "fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "freup_Periodicpadding": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DeinterlaceEnh": {
    "__init__": [
      "self",
      "num_in_ch",
      "num_feat"
    ],
    "forward": [
      "self",
      "frames"
    ]
  },
  "weights_init": [
    "init_type",
    "gain"
  ],
  "get_crop_bbox": [
    "detecting_results"
  ],
  "get_roi_without_padding": [
    "img",
    "bbox"
  ],
  "roi_to_tensor": [
    "img"
  ],
  "preprocess_roi": [
    "img"
  ],
  "patch_partition_overlap": [
    "image",
    "p1",
    "p2",
    "padding"
  ],
  "patch_aggregation_overlap": [
    "image",
    "h",
    "w",
    "padding"
  ],
  "smooth_border_mg": [
    "diffuse_mask",
    "mg"
  ],
  "whiten_img": [
    "image",
    "skin_mask",
    "whitening_degree",
    "flag_bigKernal"
  ],
  "gen_diffuse_mask": [
    "out_channels"
  ],
  "pad_to_size": [
    "target_size",
    "image",
    "bboxes",
    "keypoints"
  ],
  "unpad_from_size": [
    "pads",
    "image",
    "bboxes",
    "keypoints"
  ],
  "double_conv": {
    "__init__": [
      "self",
      "in_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "inconv": {
    "__init__": [
      "self",
      "in_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "outconv": {
    "__init__": [
      "self",
      "in_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UNet": {
    "__init__": [
      "self",
      "n_channels",
      "n_classes",
      "deep_supervision",
      "init_weights"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RetouchingNet": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "up_sampling_node",
      "init_weights"
    ],
    "forward": [
      "self",
      "input_images",
      "input_masks"
    ],
    "train": [
      "self",
      "mode"
    ]
  },
  "GatedConvBNActiv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bn",
      "sample",
      "activ",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GatedConvBNActiv2": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bn",
      "sample",
      "activ",
      "bias"
    ],
    "forward": [
      "self",
      "f_up",
      "f_skip",
      "mask"
    ]
  },
  "point_form": [
    "boxes"
  ],
  "center_size": [
    "boxes"
  ],
  "intersect": [
    "box_a",
    "box_b"
  ],
  "jaccard": [
    "box_a",
    "box_b"
  ],
  "matrix_iof": [
    "a",
    "b"
  ],
  "match": [
    "threshold",
    "box_gt",
    "priors",
    "variances",
    "labels_gt",
    "landmarks_gt",
    "box_t",
    "label_t",
    "landmarks_t",
    "batch_id"
  ],
  "encode": [
    "matched",
    "priors",
    "variances"
  ],
  "encode_landm": [
    "matched",
    "priors",
    "variances"
  ],
  "decode": [
    "loc",
    "priors",
    "variances"
  ],
  "decode_landm": [
    "pre",
    "priors",
    "variances"
  ],
  "log_sum_exp": [
    "x"
  ],
  "ClassHead": {
    "__init__": [
      "self",
      "in_channels",
      "num_anchors"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BboxHead": {
    "__init__": [
      "self",
      "in_channels",
      "num_anchors"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LandmarkHead": {
    "__init__": [
      "self",
      "in_channels",
      "num_anchors"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RetinaFace": {
    "__init__": [
      "self",
      "name",
      "pretrained",
      "in_channels",
      "return_layers",
      "out_channels"
    ],
    "_make_class_head": [
      "fpn_num",
      "in_channels",
      "anchor_num"
    ],
    "_make_bbox_head": [
      "fpn_num",
      "in_channels",
      "anchor_num"
    ],
    "_make_landmark_head": [
      "fpn_num",
      "in_channels",
      "anchor_num"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "tensor_from_rgb_image": [
    "image"
  ],
  "vis_annotations": [
    "image",
    "annotations"
  ],
  "conv_bn_no_relu": [
    "inp",
    "oup",
    "stride"
  ],
  "conv_bn1X1": [
    "inp",
    "oup",
    "stride",
    "leaky"
  ],
  "conv_dw": [
    "inp",
    "oup",
    "stride",
    "leaky"
  ],
  "SSH": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FPN": {
    "__init__": [
      "self",
      "in_channels_list",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "priorbox": [
    "min_sizes",
    "steps",
    "clip",
    "image_size"
  ],
  "DetectionUNet": {
    "__init__": [
      "self",
      "n_channels",
      "n_classes",
      "up_sampling_node",
      "init_weights"
    ],
    "forward": [
      "self",
      "input_images"
    ]
  },
  "ConvBNActiv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bn",
      "sample",
      "activ",
      "bias"
    ],
    "forward": [
      "self",
      "images"
    ]
  },
  "flatten_label": [
    "target"
  ],
  "cha_encdec": {
    "__init__": [
      "self",
      "charMapping",
      "case_sensitive"
    ],
    "encode": [
      "self",
      "label_batch"
    ]
  },
  "OCRRecognition": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "do_step": [
      "self",
      "batch"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "OCRRecognitionPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode"
    ],
    "keepratio_resize": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "inputs"
    ]
  },
  "BidirectionalLSTM": {
    "__init__": [
      "self",
      "nIn",
      "nHidden",
      "nOut"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "CRNN": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ConvNextViT": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "LightweightEdge": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "NasRecBackbone": {
    "__init__": [
      "self",
      "first_conv",
      "blocks"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_flops": [
      "self",
      "x"
    ]
  },
  "CompactRecBackboneMixSE": {
    "__init__": [
      "self",
      "first_stride",
      "input_channel",
      "stride_stages",
      "n_cell_stages",
      "width_stages",
      "conv_op_ids",
      "conv_candidates",
      "se_candidates"
    ]
  },
  "plnas_linear_mix_se": [
    "input_channel",
    "output_channel"
  ],
  "get_same_padding": [
    "kernel_size"
  ],
  "count_conv_flop": [
    "layer",
    "x"
  ],
  "set_layer_from_config": [
    "layer_config"
  ],
  "MobileInvertedResidualBlock": {
    "__init__": [
      "self",
      "mobile_inverted_conv",
      "shortcut"
    ],
    "forward": [
      "self",
      "x"
    ],
    "module_str": [
      "self"
    ],
    "config": [
      "self"
    ],
    "build_from_config": [
      "config"
    ],
    "get_flops": [
      "self",
      "x"
    ]
  },
  "MBInvertedConvLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "expand_ratio",
      "mid_channels"
    ],
    "forward": [
      "self",
      "x"
    ],
    "module_str": [
      "self"
    ],
    "config": [
      "self"
    ],
    "build_from_config": [
      "config"
    ],
    "is_zero_layer": [],
    "get_flops": [
      "self",
      "x"
    ]
  },
  "IdentityLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "module_str": [
      "self"
    ],
    "config": [
      "self"
    ],
    "build_from_config": [
      "config"
    ],
    "is_zero_layer": [],
    "get_flops": [
      "self",
      "x"
    ]
  },
  "ZeroLayer": {
    "__init__": [
      "self",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ],
    "module_str": [
      "self"
    ],
    "config": [
      "self"
    ],
    "build_from_config": [
      "config"
    ],
    "is_zero_layer": [],
    "get_flops": [
      "self",
      "x"
    ]
  },
  "split_layer": [
    "total_channels",
    "num_groups"
  ],
  "MBInvertedMixConvLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "mix_conv_size",
      "stride",
      "expand_ratio",
      "mid_channels"
    ],
    "forward": [
      "self",
      "x"
    ],
    "module_str": [
      "self"
    ],
    "config": [
      "self"
    ],
    "build_from_config": [
      "config"
    ],
    "is_zero_layer": [],
    "get_flops": [
      "self",
      "x"
    ]
  },
  "LinearMixConvLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "mix_conv_size",
      "stride",
      "mid_channels"
    ],
    "forward": [
      "self",
      "x"
    ],
    "module_str": [
      "self"
    ],
    "config": [
      "self"
    ],
    "build_from_config": [
      "config"
    ],
    "is_zero_layer": [],
    "get_flops": [
      "self",
      "x"
    ]
  },
  "MBInvertedRepConvLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "rep_conv_size",
      "stride",
      "expand_ratio",
      "mid_channels"
    ],
    "forward": [
      "self",
      "x"
    ],
    "module_str": [
      "self"
    ],
    "config": [
      "self"
    ],
    "build_from_config": [
      "config"
    ],
    "is_zero_layer": [],
    "switch_to_deploy": [
      "self"
    ],
    "get_equivalent_kernel_bias": [
      "self"
    ],
    "_pad_1x1_to_5x5_tensor": [
      "self",
      "kernel1x1"
    ],
    "_pad_3x3_to_5x5_tensor": [
      "self",
      "kernel3x3"
    ],
    "_fuse_bn_tensor": [
      "self",
      "branch"
    ],
    "get_flops": [
      "self",
      "x"
    ]
  },
  "detach_variable": [
    "inputs"
  ],
  "delta_ij": [
    "i",
    "j"
  ],
  "conv_func_by_name": [
    "name"
  ],
  "ImageQualityAssessmentDegradation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_train_forward": [
      "self",
      "input",
      "target"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "_evaluate_postprocess": [
      "self",
      "input",
      "item_id",
      "distortion_type",
      "target"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "DegradationIQA": {
    "__init__": [
      "self"
    ],
    "_initialize_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "require_map"
    ]
  },
  "CFM": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "left",
      "down"
    ]
  },
  "F3Net": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "shape"
    ]
  },
  "load_state_dict": [
    "model_dir",
    "device"
  ],
  "F3NetForProductSegmentation": {
    "__init__": [
      "self",
      "model_dir",
      "device_id"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ImageQualityAssessmentMAN": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_train_forward": [
      "self",
      "input",
      "target"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "_evaluate_postprocess": [
      "self",
      "input",
      "target"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "_no_grad_trunc_normal_": [
    "tensor",
    "mean",
    "std",
    "a",
    "b"
  ],
  "SwinBlock": {
    "__init__": [
      "self",
      "dim",
      "input_resolution",
      "num_heads",
      "window_size",
      "shift_size",
      "dim_mlp",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "drop_path",
      "act_layer",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ],
    "flops": [
      "self"
    ]
  },
  "TABlock": {
    "__init__": [
      "self",
      "dim",
      "drop"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SaveOutput": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "module",
      "module_in",
      "module_out"
    ],
    "clear": [
      "self"
    ]
  },
  "MANIQA": {
    "__init__": [
      "self",
      "embed_dim",
      "num_outputs",
      "patch_size",
      "drop",
      "depths",
      "window_size",
      "dim_mlp",
      "num_heads",
      "img_size",
      "num_tab",
      "scale"
    ],
    "extract_feature": [
      "self",
      "save_output"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "sem2ins_masks": [
    "gt_sem_seg",
    "num_thing_classes"
  ],
  "outs2results": [
    "bboxes",
    "labels",
    "masks",
    "ids",
    "num_classes"
  ],
  "KNetTrack": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "extract_feat": [
      "self",
      "img"
    ],
    "forward": [
      "self",
      "imgs",
      "img_metas"
    ],
    "aug_test": [
      "self",
      "imgs",
      "img_metas",
      "rescale"
    ],
    "simple_test": [
      "self",
      "imgs",
      "img_metas"
    ]
  },
  "MaskCost": {
    "__init__": [
      "self",
      "weight",
      "pred_act",
      "act_mode"
    ],
    "__call__": [
      "self",
      "cls_pred",
      "target"
    ]
  },
  "MaskHungarianAssignerVideo": {
    "__init__": [
      "self",
      "cls_cost",
      "mask_cost",
      "dice_cost",
      "boundary_cost",
      "topk"
    ],
    "assign": [
      "self",
      "bbox_pred",
      "cls_pred",
      "gt_bboxes",
      "gt_labels",
      "gt_instance_ids",
      "img_meta",
      "gt_bboxes_ignore",
      "eps"
    ]
  },
  "KernelUpdateHeadVideo": {
    "__init__": [
      "self",
      "with_cls",
      "num_proposals",
      "num_classes",
      "num_ffn_fcs",
      "num_heads",
      "num_cls_fcs",
      "num_mask_fcs",
      "feedforward_channels",
      "in_channels",
      "out_channels",
      "dropout",
      "mask_thr",
      "act_cfg",
      "ffn_act_cfg",
      "conv_kernel_size",
      "feat_transform_cfg",
      "hard_mask_thr",
      "kernel_init",
      "with_ffn",
      "mask_out_stride",
      "relative_coors",
      "relative_coors_off",
      "feat_gather_stride",
      "mask_transform_stride",
      "mask_upsample_stride",
      "num_thing_classes",
      "num_stuff_classes",
      "mask_assign_stride",
      "ignore_label",
      "thing_label_in_seg",
      "query_merge_method",
      "kernel_updator_cfg",
      "loss_rank",
      "loss_mask",
      "loss_dice",
      "loss_cls"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "proposal_feat",
      "mask_preds",
      "prev_cls_score",
      "mask_shape",
      "img_metas",
      "pos"
    ],
    "loss": [
      "self",
      "object_feats",
      "cls_score",
      "mask_pred",
      "labels",
      "label_weights",
      "mask_targets",
      "mask_weights",
      "imgs_whwh",
      "reduction_override"
    ],
    "_get_target_single": [
      "self",
      "pos_inds",
      "neg_inds",
      "pos_mask",
      "neg_mask",
      "pos_gt_mask",
      "pos_gt_labels",
      "gt_sem_seg",
      "gt_sem_cls",
      "cfg"
    ],
    "get_targets": [
      "self",
      "sampling_results",
      "rcnn_train_cfg",
      "concat",
      "gt_sem_seg",
      "gt_sem_cls"
    ],
    "rescale_masks": [
      "self",
      "masks_per_img",
      "img_meta"
    ],
    "get_seg_masks": [
      "self",
      "masks_per_img",
      "labels_per_img",
      "scores_per_img",
      "test_cfg",
      "img_meta"
    ],
    "segm2result": [
      "self",
      "mask_preds",
      "det_labels",
      "cls_scores"
    ],
    "get_seg_masks_tracking": [
      "self",
      "masks_per_img",
      "labels_per_img",
      "scores_per_img",
      "ids_per_img",
      "test_cfg",
      "img_meta"
    ]
  },
  "KernelUpdator": {
    "__init__": [
      "self",
      "in_channels",
      "feat_channels",
      "out_channels",
      "input_feat_shape",
      "gate_sigmoid",
      "gate_norm_act",
      "activate_out",
      "act_cfg",
      "norm_cfg"
    ],
    "forward": [
      "self",
      "update_feature",
      "input_feature"
    ]
  },
  "KernelIterHeadVideo": {
    "__init__": [
      "self",
      "num_stages",
      "recursive",
      "assign_stages",
      "stage_loss_weights",
      "proposal_feature_channel",
      "merge_cls_scores",
      "do_panoptic",
      "post_assign",
      "hard_target",
      "num_proposals",
      "num_thing_classes",
      "num_stuff_classes",
      "mask_assign_stride",
      "thing_label_in_seg",
      "mask_head",
      "mask_out_stride",
      "train_cfg",
      "test_cfg"
    ],
    "init_bbox_head": [
      "self",
      "mask_roi_extractor",
      "mask_head"
    ],
    "init_assigner_sampler": [
      "self"
    ],
    "init_weights": [
      "self"
    ],
    "init_mask_head": [
      "self",
      "mask_roi_extractor",
      "mask_head"
    ],
    "_mask_forward": [
      "self",
      "stage",
      "x",
      "object_feats",
      "mask_preds",
      "img_metas"
    ],
    "forward_train": [
      "self",
      "x",
      "proposal_feats",
      "mask_preds",
      "cls_score",
      "ref_img_metas",
      "gt_masks",
      "gt_labels",
      "gt_bboxes_ignore",
      "imgs_whwh",
      "gt_bboxes",
      "gt_sem_seg",
      "gt_sem_cls"
    ],
    "simple_test": [
      "self",
      "x",
      "proposal_feats",
      "mask_preds",
      "cls_score",
      "img_metas",
      "ref_img_metas",
      "imgs_whwh",
      "rescale"
    ],
    "aug_test": [
      "self",
      "features",
      "proposal_list",
      "img_metas",
      "rescale"
    ],
    "forward_dummy": [
      "self",
      "x",
      "proposal_boxes",
      "proposal_feats",
      "img_metas"
    ],
    "get_panoptic": [
      "self",
      "cls_scores",
      "mask_preds",
      "test_cfg",
      "img_meta"
    ],
    "merge_stuff_thing": [
      "self",
      "total_masks",
      "total_labels",
      "total_scores",
      "merge_cfg"
    ]
  },
  "KernelUpdateHead": {
    "__init__": [
      "self",
      "num_classes",
      "num_ffn_fcs",
      "num_heads",
      "num_cls_fcs",
      "num_mask_fcs",
      "feedforward_channels",
      "in_channels",
      "out_channels",
      "dropout",
      "mask_thr",
      "act_cfg",
      "ffn_act_cfg",
      "conv_kernel_size",
      "feat_transform_cfg",
      "hard_mask_thr",
      "kernel_init",
      "with_ffn",
      "mask_out_stride",
      "relative_coors",
      "relative_coors_off",
      "feat_gather_stride",
      "mask_transform_stride",
      "mask_upsample_stride",
      "num_thing_classes",
      "num_stuff_classes",
      "mask_assign_stride",
      "ignore_label",
      "thing_label_in_seg",
      "kernel_updator_cfg",
      "loss_rank",
      "loss_mask",
      "loss_dice",
      "loss_cls"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "proposal_feat",
      "mask_preds",
      "prev_cls_score",
      "mask_shape",
      "img_metas"
    ],
    "loss": [
      "self",
      "object_feats",
      "cls_score",
      "mask_pred",
      "labels",
      "label_weights",
      "mask_targets",
      "mask_weights",
      "imgs_whwh",
      "reduction_override"
    ],
    "_get_target_single": [
      "self",
      "pos_inds",
      "neg_inds",
      "pos_mask",
      "neg_mask",
      "pos_gt_mask",
      "pos_gt_labels",
      "gt_sem_seg",
      "gt_sem_cls",
      "cfg"
    ],
    "get_targets": [
      "self",
      "sampling_results",
      "rcnn_train_cfg",
      "concat",
      "gt_sem_seg",
      "gt_sem_cls"
    ],
    "rescale_masks": [
      "self",
      "masks_per_img",
      "img_meta"
    ],
    "get_seg_masks": [
      "self",
      "masks_per_img",
      "labels_per_img",
      "scores_per_img",
      "test_cfg",
      "img_meta"
    ],
    "segm2result": [
      "self",
      "mask_preds",
      "det_labels",
      "cls_scores"
    ],
    "get_seg_masks_tracking": [
      "self",
      "masks_per_img",
      "labels_per_img",
      "scores_per_img",
      "ids_per_img",
      "test_cfg",
      "img_meta"
    ]
  },
  "ConvKernelHeadVideo": {
    "__init__": [
      "self",
      "num_proposals",
      "in_channels",
      "out_channels",
      "num_heads",
      "num_cls_fcs",
      "num_seg_convs",
      "num_loc_convs",
      "att_dropout",
      "localization_fpn",
      "conv_kernel_size",
      "norm_cfg",
      "semantic_fpn",
      "train_cfg",
      "num_classes",
      "xavier_init_kernel",
      "kernel_init_std",
      "use_binary",
      "proposal_feats_with_obj",
      "loss_mask",
      "loss_seg",
      "loss_cls",
      "loss_dice",
      "loss_rank",
      "feat_downsample_stride",
      "feat_refine_stride",
      "feat_refine",
      "with_embed",
      "feat_embed_only",
      "conv_normal_init",
      "mask_out_stride",
      "hard_target",
      "num_thing_classes",
      "num_stuff_classes",
      "mask_assign_stride",
      "ignore_label",
      "thing_label_in_seg",
      "cat_stuff_mask"
    ],
    "_init_layers": [
      "self"
    ],
    "init_weights": [
      "self"
    ],
    "_decode_init_proposals": [
      "self",
      "img",
      "img_metas",
      "ref_img_metas"
    ],
    "forward_train": [
      "self",
      "img",
      "img_metas",
      "ref_img_metas",
      "gt_masks",
      "gt_labels",
      "gt_instance_ids",
      "gt_sem_seg",
      "gt_sem_cls"
    ],
    "loss": [
      "self",
      "mask_pred",
      "cls_scores",
      "seg_preds",
      "proposal_feats",
      "labels",
      "label_weights",
      "mask_targets",
      "mask_weights",
      "seg_targets",
      "reduction_override"
    ],
    "_get_target_single": [
      "self",
      "pos_inds",
      "neg_inds",
      "pos_mask",
      "neg_mask",
      "pos_gt_mask",
      "pos_gt_labels",
      "gt_sem_seg",
      "gt_sem_cls",
      "cfg"
    ],
    "get_targets": [
      "self",
      "sampling_results",
      "rpn_train_cfg",
      "concat",
      "gt_sem_seg",
      "gt_sem_cls"
    ],
    "simple_test_rpn": [
      "self",
      "img",
      "img_metas",
      "ref_img_metas"
    ],
    "forward_dummy": [
      "self",
      "img",
      "img_metas",
      "ref_img_metas"
    ]
  },
  "KernelFrameIterHeadVideo": {
    "__init__": [
      "self",
      "mask_head",
      "with_mask_init",
      "num_stages",
      "stage_loss_weights",
      "proposal_feature_channel",
      "assign_stages",
      "num_proposals",
      "num_thing_classes",
      "num_stuff_classes",
      "query_merge_method",
      "train_cfg",
      "test_cfg",
      "pretrained",
      "init_cfg"
    ],
    "init_mask_head": [
      "self",
      "bbox_roi_extractor",
      "mask_head"
    ],
    "init_assigner_sampler": [
      "self"
    ],
    "init_bbox_head": [
      "self",
      "mask_roi_extractor",
      "mask_head"
    ],
    "_mask_forward": [
      "self",
      "stage",
      "x",
      "object_feats",
      "mask_preds"
    ],
    "_query_fusion": [
      "self",
      "obj_feats",
      "num_imgs",
      "num_frames"
    ],
    "_mask_init": [
      "self",
      "object_feats",
      "x_feats",
      "num_imgs"
    ],
    "forward_train": [
      "self",
      "x",
      "ref_img_metas",
      "cls_scores",
      "masks",
      "obj_feats",
      "ref_gt_masks",
      "ref_gt_labels",
      "ref_gt_instance_ids"
    ],
    "simple_test": [
      "self",
      "x",
      "img_metas",
      "ref_img_metas",
      "cls_scores",
      "masks",
      "obj_feats"
    ],
    "init_weights": [
      "self"
    ]
  },
  "save_obj_mesh_with_color": [
    "mesh_path",
    "verts",
    "faces",
    "colors"
  ],
  "save_obj_mesh": [
    "mesh_path",
    "verts",
    "faces"
  ],
  "reconstruction": [
    "net",
    "calib_tensor",
    "coords",
    "mat",
    "num_samples"
  ],
  "keep_largest": [
    "mesh_big"
  ],
  "eval_grid": [
    "coords",
    "eval_func",
    "init_resolution",
    "threshold",
    "num_samples"
  ],
  "batch_eval": [
    "points",
    "eval_func",
    "num_samples"
  ],
  "create_grid": [
    "res",
    "b_min",
    "b_max",
    "transform"
  ],
  "get_submesh": [
    "verts",
    "faces",
    "color",
    "verts_retained",
    "faces_retained",
    "min_vert_in_face"
  ],
  "HumanReconstruction": {
    "__init__": [
      "self",
      "model_dir",
      "modelconfig"
    ],
    "get_mask": [
      "self",
      "img"
    ],
    "crop_img": [
      "self",
      "img_url"
    ],
    "generation_normal": [
      "self",
      "img",
      "mask"
    ]
  },
  "FasterRCNN": {
    "__init__": [
      "self",
      "ckpt",
      "device"
    ],
    "run": [
      "self",
      "input"
    ],
    "run_multi": [
      "self",
      "input"
    ]
  },
  "human_segmenter": {
    "__init__": [
      "self",
      "model_path"
    ],
    "image_preprocess": [
      "self",
      "img"
    ],
    "run": [
      "self",
      "img"
    ],
    "get_human_bbox": [
      "self",
      "mask"
    ],
    "release": [
      "self"
    ]
  },
  "Surface_Head": {
    "__init__": [
      "self",
      "filter_channels",
      "merge_layer",
      "res_layers",
      "norm",
      "last_op"
    ],
    "forward": [
      "self",
      "feature"
    ]
  },
  "Embedding": {
    "__init__": [
      "self",
      "in_channels",
      "N_freqs",
      "logscale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Pixto3DNet": {
    "__init__": [
      "self",
      "backbone",
      "head",
      "rgbhead",
      "embedding",
      "projection_mode",
      "error_term",
      "num_views"
    ],
    "extract_features": [
      "self",
      "images"
    ],
    "query": [
      "self",
      "points",
      "calibs",
      "transforms",
      "labels"
    ],
    "get_preds": [
      "self"
    ],
    "query_rgb": [
      "self",
      "points",
      "calibs",
      "transforms"
    ],
    "get_error": [
      "self"
    ],
    "forward": [
      "self",
      "images",
      "points",
      "calibs",
      "surpoint",
      "transforms",
      "labels"
    ]
  },
  "BlurPool": {
    "__init__": [
      "self",
      "channels",
      "pad_type",
      "filt_size",
      "stride",
      "pad_off"
    ],
    "forward": [
      "self",
      "inp"
    ]
  },
  "get_pad_layer": [
    "pad_type"
  ],
  "ConvBlockv1": {
    "__init__": [
      "self",
      "in_planes",
      "out_planes",
      "norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv2": {
    "__init__": [
      "self",
      "in_planes",
      "out_planes",
      "norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Res_hournet": {
    "__init__": [
      "self",
      "norm",
      "use_front",
      "use_back"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_norm_layer": [
    "norm_type"
  ],
  "define_G": [
    "input_nc",
    "output_nc",
    "ngf",
    "netG",
    "n_downsample_global",
    "n_blocks_global",
    "n_local_enhancers",
    "n_blocks_local",
    "norm",
    "gpu_ids",
    "last_op"
  ],
  "print_network": [
    "net"
  ],
  "LocalEnhancer": {
    "__init__": [
      "self",
      "input_nc",
      "output_nc",
      "ngf",
      "n_downsample_global",
      "n_blocks_global",
      "n_local_enhancers",
      "n_blocks_local",
      "norm_layer",
      "padding_type"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "GlobalGenerator": {
    "__init__": [
      "self",
      "input_nc",
      "output_nc",
      "ngf",
      "n_downsampling",
      "n_blocks",
      "norm_layer",
      "padding_type",
      "last_op"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "index": [
    "feat",
    "uv"
  ],
  "orthogonal": [
    "points",
    "calib",
    "transform"
  ],
  "perspective": [
    "points",
    "calib",
    "transform"
  ],
  "BinaryQuantClassificationModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs",
      "return_loss"
    ],
    "_convert_state_dict": [
      "self",
      "state_dict"
    ],
    "_load_pretrained_checkpoint": [
      "self"
    ]
  },
  "stage_out_channel_tiny": [],
  "stage_out_channel_small": [],
  "stage_out_channel_middle": [],
  "stage_out_channel_large": [],
  "HardSigmoid": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "firstconv3x3": {
    "__init__": [
      "self",
      "inp",
      "oup",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LearnableBias": {
    "__init__": [
      "self",
      "out_chn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HardSign": {
    "__init__": [
      "self",
      "range",
      "progressive"
    ],
    "adjust": [
      "self",
      "x",
      "scale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HardBinaryConv": {
    "__init__": [
      "self",
      "in_chn",
      "out_chn",
      "kernel_size",
      "stride",
      "padding",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SqueezeAndExpand": {
    "__init__": [
      "self",
      "channels",
      "planes",
      "ratio",
      "attention_mode"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FFN_3x3": {
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "drop_rate",
      "infor_recoupling",
      "groups"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "FFN_1x1": {
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "attention",
      "drop_rate",
      "infor_recoupling"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "BasicBlock_No_ELM_Attention": {
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "drop_rate",
      "mode"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "BasicBlock_No_Infor_Recoupling": {
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "drop_rate",
      "mode"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "BasicBlock_No_Extra_Design": {
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "drop_rate",
      "mode"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "BNext": {
    "__init__": [
      "self",
      "num_classes",
      "size",
      "ELM_Attention",
      "Infor_Recoupling"
    ],
    "forward": [
      "self",
      "img",
      "return_loss",
      "img_metas"
    ]
  },
  "LocalFeatureMatching": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "Inputs"
    ],
    "postprocess": [
      "self",
      "Inputs"
    ],
    "inference": [
      "self",
      "data"
    ]
  },
  "LoFTR": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "data"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "ResNetFPN_8_2": {
    "__init__": [
      "self",
      "config"
    ],
    "_make_layer": [
      "self",
      "block",
      "dim",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNetFPN_16_4": {
    "__init__": [
      "self",
      "config"
    ],
    "_make_layer": [
      "self",
      "block",
      "dim",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PositionEncodingSine": {
    "__init__": [
      "self",
      "d_model",
      "max_shape",
      "temp_bug_fix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "lower_config": [
    "yacs_cfg"
  ],
  "_CN": [],
  "default_cfg": [],
  "INF": [],
  "mask_border": [
    "m",
    "b",
    "v"
  ],
  "mask_border_with_padding": [
    "m",
    "bd",
    "v",
    "p_m0",
    "p_m1"
  ],
  "compute_max_candidates": [
    "p_m0",
    "p_m1"
  ],
  "CoarseMatching": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "feat_c0",
      "feat_c1",
      "data",
      "mask_c0",
      "mask_c1"
    ],
    "get_coarse_match": [
      "self",
      "conf_matrix",
      "data"
    ]
  },
  "create_meshgrid": [
    "height",
    "width",
    "normalized_coordinates",
    "device",
    "dtype"
  ],
  "spatial_expectation2d": [
    "input",
    "normalized_coordinates"
  ],
  "FineMatching": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "feat_f0",
      "feat_f1",
      "data"
    ],
    "get_fine_match": [
      "self",
      "coords_normed",
      "data"
    ]
  },
  "mask_pts_at_padded_regions": [
    "grid_pt",
    "mask"
  ],
  "spvs_coarse": [
    "data",
    "config"
  ],
  "compute_supervision_coarse": [
    "data",
    "config"
  ],
  "spvs_fine": [
    "data",
    "config"
  ],
  "compute_supervision_fine": [
    "data",
    "config"
  ],
  "warp_kpts": [
    "kpts0",
    "depth0",
    "depth1",
    "T_0to1",
    "K0",
    "K1"
  ],
  "LoFTREncoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "attention"
    ],
    "forward": [
      "self",
      "x",
      "source",
      "x_mask",
      "source_mask"
    ]
  },
  "LocalFeatureTransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "_reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "feat0",
      "feat1",
      "mask0",
      "mask1"
    ]
  },
  "elu_feature_map": [
    "x"
  ],
  "FullAttention": {
    "__init__": [
      "self",
      "use_dropout",
      "attention_dropout"
    ],
    "forward": [
      "self",
      "queries",
      "keys",
      "values",
      "q_mask",
      "kv_mask"
    ]
  },
  "FinePreprocess": {
    "__init__": [
      "self",
      "config"
    ],
    "_reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "feat_f0",
      "feat_f1",
      "feat_c0",
      "feat_c1",
      "data"
    ]
  },
  "_compute_conf_thresh": [
    "data"
  ],
  "_make_evaluation_figure": [
    "data",
    "b_id",
    "alpha"
  ],
  "_make_confidence_figure": [
    "data",
    "b_id"
  ],
  "make_matching_figures": [
    "data",
    "config",
    "mode"
  ],
  "dynamic_alpha": [
    "n_matches",
    "milestones",
    "alphas"
  ],
  "error_colormap": [
    "err",
    "thr",
    "alpha"
  ],
  "resize_n_crop": [
    "image",
    "M",
    "dsize"
  ],
  "PerceptualLoss": {
    "__init__": [
      "self",
      "recog_net",
      "input_size"
    ],
    "forward": [
      "self",
      "imageA",
      "imageB",
      "M"
    ]
  },
  "perceptual_loss": [
    "id_featureA",
    "id_featureB"
  ],
  "photo_loss": [
    "imageA",
    "imageB",
    "mask",
    "eps"
  ],
  "landmark_loss": [
    "predict_lm",
    "gt_lm",
    "weight"
  ],
  "reg_loss": [
    "coeffs_dict",
    "w_id",
    "w_exp",
    "w_tex"
  ],
  "reflectance_loss": [
    "texture",
    "mask"
  ],
  "lm_3d_loss": [
    "pred_lm_3d",
    "gt_lm_3d",
    "mask"
  ],
  "TVLoss": {
    "__init__": [
      "self",
      "TVLoss_weight"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_tensor_size": [
      "self",
      "t"
    ]
  },
  "TVLoss_std": {
    "__init__": [
      "self",
      "TVLoss_weight"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_tensor_size": [
      "self",
      "t"
    ]
  },
  "photo_loss_sum": [
    "imageA",
    "imageB",
    "mask",
    "eps"
  ],
  "points_loss_horizontal": [
    "verts",
    "left_points",
    "right_points",
    "width"
  ],
  "LaplacianLoss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_tensor_size": [
      "self",
      "t"
    ]
  },
  "LaplacianLoss_L1": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_tensor_size": [
      "self",
      "t"
    ]
  },
  "GANLoss": {
    "__init__": [
      "self",
      "gan_mode",
      "target_real_label",
      "target_fake_label",
      "tensor"
    ],
    "get_target_tensor": [
      "self",
      "input",
      "target_is_real"
    ],
    "get_zero_tensor": [
      "self",
      "input"
    ],
    "loss": [
      "self",
      "input",
      "target_is_real",
      "for_discriminator"
    ],
    "__call__": [
      "self",
      "input",
      "target_is_real",
      "for_discriminator"
    ]
  },
  "BinaryDiceLoss": {
    "__init__": [
      "self",
      "smooth",
      "p",
      "reduction"
    ],
    "forward": [
      "self",
      "predict",
      "target"
    ]
  },
  "bfm_folder": [],
  "bfm_model": [],
  "camera_d": [],
  "center": [],
  "focal": [],
  "isTrain": [],
  "net_recon": [],
  "phase": [],
  "use_ddp": [],
  "use_last_fc": [],
  "z_far": [],
  "z_near": [],
  "lr": [],
  "w_color": [],
  "w_reg": [],
  "w_gamma": [],
  "w_lm": [],
  "w_id": [],
  "w_exp": [],
  "w_tex": [],
  "HeadSegmentor": {
    "__init__": [
      "self",
      "model_root"
    ],
    "load_sess": [
      "self",
      "model_path"
    ],
    "process": [
      "self",
      "image"
    ],
    "pad_box": [
      "self",
      "y1",
      "y2",
      "x1",
      "x2",
      "left_ratio",
      "right_ratio",
      "top_ratio",
      "bottom_ratio",
      "h",
      "w"
    ],
    "detect_face": [
      "self",
      "img"
    ],
    "generate_json": [
      "self",
      "status_code",
      "status_msg",
      "ori_url",
      "result_element",
      "track_id"
    ],
    "get_box": [
      "self",
      "alpha"
    ]
  },
  "get_fade_out_mask": [
    "length",
    "start_value",
    "end_value",
    "fade_start_ratio",
    "fade_end_ratio"
  ],
  "TexProcesser": {
    "__init__": [
      "self",
      "model_root"
    ],
    "post_process_texture": [
      "self",
      "tex_map",
      "hair_tex"
    ]
  },
  "ndc_projection": [
    "x",
    "n",
    "f"
  ],
  "to_image": [
    "face_shape"
  ],
  "MeshRenderer": {
    "__init__": [
      "self",
      "rasterize_fov",
      "znear",
      "zfar",
      "rasterize_size"
    ],
    "forward": [
      "self",
      "vertex",
      "tri",
      "feat"
    ],
    "render_uv_texture": [
      "self",
      "vertex",
      "tri",
      "uv",
      "uv_texture"
    ],
    "pred_shape_and_texture": [
      "self",
      "vertex",
      "tri",
      "uv",
      "target_img",
      "base_tex"
    ]
  },
  "perspective_projection": [
    "focal",
    "center"
  ],
  "SH": {
    "__init__": [
      "self"
    ]
  },
  "ParametricFaceModel": {
    "__init__": [
      "self",
      "assets_root",
      "recenter",
      "camera_distance",
      "init_lit",
      "focal",
      "center",
      "is_train",
      "default_name"
    ],
    "to": [
      "self",
      "device"
    ],
    "compute_shape": [
      "self",
      "id_coeff",
      "exp_coeff",
      "nose_coeff",
      "neck_coeff",
      "eyes_coeff",
      "neckSlim_coeff",
      "neckStretch_coeff"
    ],
    "compute_texture": [
      "self",
      "tex_coeff",
      "normalize"
    ],
    "compute_norm": [
      "self",
      "face_shape"
    ],
    "compute_color": [
      "self",
      "face_texture",
      "face_norm",
      "gamma"
    ],
    "compute_rotation": [
      "self",
      "angles"
    ],
    "to_camera": [
      "self",
      "face_shape"
    ],
    "to_image": [
      "self",
      "face_shape"
    ],
    "transform": [
      "self",
      "face_shape",
      "rot",
      "trans"
    ],
    "get_landmarks": [
      "self",
      "face_proj"
    ],
    "split_coeff": [
      "self",
      "coeffs"
    ],
    "merge_coeff": [
      "self",
      "coeffs"
    ],
    "reverse_recenter": [
      "self",
      "face_shape"
    ],
    "add_nonlinear_offset_eyes": [
      "self",
      "face_shape",
      "shape_offset"
    ],
    "add_nonlinear_offset": [
      "self",
      "face_shape",
      "shape_offset_uv",
      "UVs"
    ],
    "compute_for_render_head_fitting": [
      "self",
      "coeffs",
      "shape_offset_uv",
      "texture_offset_uv",
      "shape_offset_uv_head",
      "texture_offset_uv_head",
      "UVs",
      "reverse_recenter",
      "get_eyes",
      "get_neck",
      "nose_coeff",
      "neck_coeff",
      "eyes_coeff"
    ],
    "compute_for_render_head": [
      "self",
      "coeffs",
      "shape_offset_uv",
      "texture_offset_uv",
      "shape_offset_uv_head",
      "texture_offset_uv_head",
      "UVs",
      "reverse_recenter",
      "nose_coeff",
      "neck_coeff",
      "eyes_coeff",
      "neckSlim_coeff",
      "neckStretch_coeff"
    ]
  },
  "filter_state_dict": [
    "state_dict",
    "remove_name"
  ],
  "define_net_recon": [
    "net_recon",
    "use_last_fc",
    "init_path"
  ],
  "define_net_recon2": [
    "net_recon",
    "use_last_fc",
    "init_path"
  ],
  "ReconNetWrapper": {
    "fc_dim": [],
    "__init__": [
      "self",
      "net_recon",
      "use_last_fc",
      "init_path"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ReconNetWrapper2": {
    "fc_dim": [],
    "__init__": [
      "self",
      "net_recon",
      "use_last_fc",
      "init_path"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "model_urls": [],
  "HeadReconModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "set_device": [
      "self",
      "device"
    ],
    "load_networks": [
      "self",
      "load_path"
    ],
    "setup": [
      "self",
      "checkpoint_path"
    ],
    "parallelize": [
      "self",
      "convert_sync_batchnorm"
    ],
    "eval": [
      "self"
    ],
    "set_render": [
      "self",
      "image_res"
    ],
    "set_input": [
      "self",
      "input"
    ],
    "check_head_pose": [
      "self",
      "coeffs"
    ],
    "get_fusion_mask": [
      "self",
      "keep_forehead"
    ],
    "get_edge_mask": [
      "self"
    ],
    "blur_shape_offset_uv": [
      "self",
      "global_blur",
      "blur_size"
    ],
    "blur_offset_edge": [
      "self"
    ],
    "fitting_nonlinear": [
      "self",
      "coeff",
      "n_iters"
    ],
    "forward": [
      "self"
    ],
    "get_edge_points_horizontal": [
      "self"
    ],
    "compute_losses_fitting": [
      "self"
    ]
  },
  "IMAGE_SIZE": [],
  "init_mesh": [
    "model_path",
    "device"
  ],
  "init_camera": [
    "num_views",
    "dist",
    "elev",
    "azim",
    "view_idx",
    "device"
  ],
  "init_renderer": [
    "camera",
    "device"
  ],
  "generation_gif": [
    "mesh_path"
  ],
  "Tex2Texture": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "init_mesh": [
      "self",
      "mesh_path"
    ],
    "normalize_mesh": [
      "self",
      "mesh"
    ],
    "save_normalized_obj": [
      "self",
      "verts",
      "faces",
      "aux",
      "path"
    ],
    "mesh_normalized": [
      "self",
      "mesh_path",
      "save_path"
    ]
  },
  "prepare_mask_and_masked_image": [
    "image",
    "mask",
    "height",
    "width",
    "return_image"
  ],
  "StableDiffusionControlinpaintPipeline": {
    "__call__": [
      "self",
      "prompt",
      "image",
      "mask_image",
      "control_image",
      "height",
      "width",
      "strength",
      "num_inference_steps",
      "guidance_scale",
      "negative_prompt",
      "num_images_per_prompt",
      "eta",
      "generator",
      "latents",
      "prompt_embeds",
      "negative_prompt_embeds",
      "output_type",
      "return_dict",
      "callback",
      "callback_steps",
      "cross_attention_kwargs",
      "controlnet_conditioning_scale",
      "guess_mode"
    ]
  },
  "BlendParams": {},
  "FlatTexelShader": {
    "__init__": [
      "self",
      "device",
      "cameras",
      "lights",
      "materials",
      "blend_params"
    ],
    "forward": [
      "self",
      "fragments",
      "meshes"
    ]
  },
  "init_soft_phong_shader": [
    "camera",
    "blend_params",
    "device"
  ],
  "init_flat_texel_shader": [
    "camera",
    "device"
  ],
  "render": [
    "mesh",
    "renderer",
    "pad_value"
  ],
  "check_visible_faces": [
    "mesh",
    "fragments"
  ],
  "get_all_4_locations": [
    "values_y",
    "values_x"
  ],
  "compose_quad_mask": [
    "new_mask_image",
    "update_mask_image",
    "old_mask_image",
    "device"
  ],
  "compute_view_heat": [
    "similarity_tensor",
    "quad_mask_tensor"
  ],
  "select_viewpoint": [
    "selected_view_ids",
    "view_punishments",
    "mode",
    "dist_list",
    "elev_list",
    "azim_list",
    "sector_list",
    "view_idx",
    "similarity_texture_cache",
    "exist_texture",
    "mesh",
    "faces",
    "verts_uvs",
    "image_size",
    "faces_per_pixel",
    "init_image_dir",
    "mask_image_dir",
    "normal_map_dir",
    "depth_map_dir",
    "similarity_map_dir",
    "device",
    "use_principle"
  ],
  "build_backproject_mask": [
    "mesh",
    "faces",
    "verts_uvs",
    "cameras",
    "reference_image",
    "faces_per_pixel",
    "image_size",
    "uv_size",
    "device"
  ],
  "build_diffusion_mask": [
    "mesh_stuff",
    "renderer",
    "exist_texture",
    "similarity_texture_cache",
    "target_value",
    "device",
    "image_size",
    "smooth_mask",
    "view_threshold"
  ],
  "render_one_view": [
    "mesh",
    "dist",
    "elev",
    "azim",
    "image_size",
    "faces_per_pixel",
    "device"
  ],
  "build_similarity_texture_cache_for_all_views": [
    "mesh",
    "faces",
    "verts_uvs",
    "dist_list",
    "elev_list",
    "azim_list",
    "image_size",
    "image_size_scaled",
    "uv_size",
    "faces_per_pixel",
    "device"
  ],
  "render_one_view_and_build_masks": [
    "dist",
    "elev",
    "azim",
    "selected_view_idx",
    "view_idx",
    "view_punishments",
    "similarity_texture_cache",
    "exist_texture",
    "mesh",
    "faces",
    "verts_uvs",
    "image_size",
    "faces_per_pixel",
    "init_image_dir",
    "mask_image_dir",
    "normal_map_dir",
    "depth_map_dir",
    "similarity_map_dir",
    "device",
    "save_intermediate",
    "smooth_mask",
    "view_threshold"
  ],
  "save_full_obj": [
    "output_dir",
    "obj_name",
    "verts",
    "faces",
    "verts_uvs",
    "faces_uvs",
    "projected_texture",
    "device"
  ],
  "backproject_from_image": [
    "mesh",
    "faces",
    "verts_uvs",
    "cameras",
    "reference_image",
    "new_mask_image",
    "update_mask_image",
    "init_texture",
    "exist_texture",
    "image_size",
    "uv_size",
    "faces_per_pixel",
    "device"
  ],
  "PALETTE": [],
  "QUAD_WEIGHTS": [],
  "VIEWPOINTS": [],
  "degree_to_radian": [
    "d"
  ],
  "radian_to_degree": [
    "r"
  ],
  "xyz_to_polar": [
    "xyz"
  ],
  "polar_to_xyz": [
    "theta",
    "phi",
    "dist"
  ],
  "filter_viewpoints": [
    "pre_viewpoints",
    "viewpoints"
  ],
  "init_viewpoints": [
    "init_dist",
    "init_elev",
    "init_azim",
    "use_principle",
    "use_shapenet",
    "use_objaverse"
  ],
  "init_principle_viewpoints": [
    "dist_list",
    "elev_list",
    "azim_list",
    "sector_list",
    "view_punishments",
    "use_shapenet",
    "use_objaverse"
  ],
  "init_predefined_viewpoints": [
    "sample_space",
    "init_dist",
    "init_elev"
  ],
  "visualize_quad_mask": [
    "mask_image_dir",
    "quad_mask_tensor",
    "view_idx",
    "view_score",
    "device"
  ],
  "visualize_outputs": [
    "output_dir",
    "init_image_dir",
    "mask_image_dir",
    "inpainted_image_dir",
    "num_views"
  ],
  "visualize_principle_viewpoints": [
    "output_dir",
    "dist_list",
    "elev_list",
    "azim_list"
  ],
  "visualize_refinement_viewpoints": [
    "output_dir",
    "selected_view_ids",
    "dist_list",
    "elev_list",
    "azim_list"
  ],
  "_make_grid": [
    "nx",
    "ny"
  ],
  "split_for_trace_model": [
    "pred",
    "anchor_grid"
  ],
  "scale_coords": [
    "img1_shape",
    "coords",
    "img0_shape",
    "ratio_pad"
  ],
  "clip_coords": [
    "boxes",
    "img_shape"
  ],
  "xywh2xyxy": [
    "x"
  ],
  "box_iou": [
    "box1",
    "box2"
  ],
  "driving_area_mask": [
    "da_predict",
    "out_shape"
  ],
  "lane_line_mask": [
    "ll_predict",
    "out_shape"
  ],
  "ImageDrivingPerceptionPreprocessor": {
    "__init__": [
      "self",
      "mode"
    ],
    "_check_image": [
      "self",
      "input_img"
    ],
    "_letterbox": [
      "self",
      "img",
      "new_shape",
      "color",
      "auto",
      "scaleFill",
      "scaleup",
      "stride"
    ],
    "__call__": [
      "self",
      "data",
      "output_shape",
      "new_shape"
    ]
  },
  "YOLOPv2": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "data"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "_load_pretrained_checkpoint": [
      "self"
    ]
  },
  "ClassificationModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "load_pretrained_checkpoint": [
      "self"
    ]
  },
  "get_trained_checkpoints_name": [
    "work_path"
  ],
  "preprocess_transform": [
    "cfgs"
  ],
  "get_ms_dataset_root": [
    "ms_dataset"
  ],
  "get_classes": [
    "classes"
  ],
  "MmDataset": {
    "__init__": [
      "self",
      "ms_dataset",
      "pipeline",
      "classes",
      "test_mode",
      "data_prefix"
    ],
    "load_annotations": [
      "self"
    ]
  },
  "ContentCheckBackbone": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "img"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "RelativePositionBias": {
    "__init__": [
      "self",
      "window_size",
      "num_heads"
    ],
    "forward": [
      "self"
    ]
  },
  "BEiTv2": {
    "embed_dims": [],
    "depths": [],
    "num_heads": [],
    "mlp_ratios": [],
    "__init__": [
      "self",
      "arch",
      "patch_size",
      "img_size",
      "in_chans",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "norm_layer",
      "init_values",
      "use_abs_pos_emb",
      "use_rel_pos_bias",
      "use_shared_rel_pos_bias",
      "use_mean_pooling",
      "init_scale",
      "out_indices",
      "frozen_stages",
      "init_cfg"
    ],
    "init_weights": [
      "self"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "fix_init_weight": [
      "self"
    ],
    "interpolate_pos_encoding": [
      "self",
      "x",
      "w",
      "h"
    ],
    "forward_features": [
      "self",
      "x",
      "return_patch_tokens",
      "return_all_tokens"
    ],
    "forward": [
      "self",
      "x",
      "return_patch_tokens",
      "return_all_tokens"
    ],
    "_freeze_stages": [
      "self"
    ],
    "train": [
      "self",
      "mode"
    ]
  },
  "NORM_EPS": [],
  "MHCA": {
    "__init__": [
      "self",
      "out_channels",
      "head_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NCB": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "path_dropout",
      "drop",
      "head_dim",
      "mlp_ratio"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "E_MHSA": {
    "__init__": [
      "self",
      "dim",
      "out_dim",
      "head_dim",
      "qkv_bias",
      "qk_scale",
      "attn_drop",
      "proj_drop",
      "sr_ratio"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NTB": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "path_dropout",
      "stride",
      "sr_ratio",
      "mlp_ratio",
      "head_dim",
      "mix_block_ratio",
      "attn_drop",
      "drop"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NextViT": {
    "stem_chs": [],
    "depths": [],
    "__init__": [
      "self",
      "arch",
      "path_dropout",
      "attn_drop",
      "drop",
      "strides",
      "sr_ratios",
      "head_dim",
      "mix_block_ratio",
      "resume",
      "with_extra_norm",
      "norm_eval",
      "norm_cfg",
      "out_indices",
      "frozen_stages",
      "init_cfg"
    ],
    "init_weights": [
      "self"
    ],
    "_initialize_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_freeze_stages": [
      "self"
    ],
    "train": [
      "self",
      "mode"
    ]
  },
  "BadImageDetecting": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_train_forward": [
      "self",
      "input",
      "target"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "_evaluate_postprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "NeRFReconPreprocessor": {
    "__init__": [
      "self",
      "mode",
      "data_type",
      "use_mask",
      "match_type",
      "frame_count",
      "use_distortion"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "split_frames": [
      "self",
      "video_path",
      "basedir",
      "frame_count"
    ],
    "run_colmap": [
      "self",
      "basedir",
      "match_type",
      "use_distortion"
    ],
    "gen_poses": [
      "self",
      "basedir",
      "match_type",
      "use_distortion"
    ]
  },
  "NeRFReconAcc": {
    "__init__": [
      "self",
      "model_dir",
      "network_cfg"
    ],
    "nerf_reconstruction": [
      "self",
      "data_dir",
      "render_dir"
    ],
    "render_video": [
      "self",
      "render_dir"
    ],
    "save_image": [
      "self",
      "filename",
      "img"
    ],
    "save_video": [
      "self",
      "filename",
      "img_dir",
      "fps"
    ],
    "write_obj": [
      "self",
      "filename",
      "v_pos",
      "t_pos_idx",
      "v_tex",
      "t_tex_idx"
    ],
    "save_obj": [
      "self",
      "filename",
      "v_pos",
      "t_pos_idx",
      "v_tex",
      "t_tex_idx"
    ]
  },
  "ObjectSegmenter": {
    "__init__": [
      "self",
      "model_path"
    ],
    "image_preprocess": [
      "self",
      "img"
    ],
    "run_mask": [
      "self",
      "img"
    ]
  },
  "VanillaMLP": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "n_neurons",
      "n_hidden_layers",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ],
    "make_linear": [
      "self",
      "dim_in",
      "dim_out"
    ],
    "make_activation": [
      "self"
    ]
  },
  "MarchingCubeHelper": {
    "__init__": [
      "self",
      "resolution",
      "use_torch"
    ],
    "grid_vertices": [
      "self"
    ],
    "forward": [
      "self",
      "level",
      "threshold"
    ]
  },
  "_TruncExp": {
    "forward": [
      "ctx",
      "x"
    ],
    "backward": [
      "ctx",
      "g"
    ]
  },
  "trunc_exp": [],
  "VolumeDensity": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "points"
    ],
    "forward_level": [
      "self",
      "points"
    ],
    "isosurface_": [
      "self",
      "vmin",
      "vmax"
    ],
    "isosurface": [
      "self"
    ]
  },
  "VolumeRadiance": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "features",
      "dirs"
    ]
  },
  "NeRFModel": {
    "__init__": [
      "self",
      "network_cfg"
    ],
    "update_step": [
      "self",
      "global_step"
    ],
    "isosurface": [
      "self"
    ],
    "forward": [
      "self",
      "rays"
    ],
    "inference": [
      "self",
      "rays"
    ]
  },
  "PSNR": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "targets",
      "valid_mask",
      "reduction"
    ]
  },
  "extract_fields": [
    "bound_min",
    "bound_max",
    "resolution",
    "query_func"
  ],
  "extract_geometry": [
    "bound_min",
    "bound_max",
    "resolution",
    "threshold",
    "query_func"
  ],
  "chunk_batch": [
    "func",
    "chunk_size"
  ],
  "dot": [
    "x",
    "y"
  ],
  "reflect": [
    "x",
    "n"
  ],
  "cleanup": [],
  "update_module_step": [
    "m",
    "epoch",
    "global_step"
  ],
  "get_rays": [
    "directions",
    "c2w",
    "keepdim"
  ],
  "get_ray_directions": [
    "W",
    "H",
    "fx",
    "fy",
    "cx",
    "cy",
    "use_pixel_centers"
  ],
  "get_center": [
    "pts"
  ],
  "normalize_poses": [
    "poses",
    "pts"
  ],
  "create_spheric_poses": [
    "cameras",
    "n_steps"
  ],
  "to4x4": [
    "pose"
  ],
  "get_spiral_path": [
    "cameras",
    "fx",
    "fy",
    "n_steps",
    "radius",
    "rots",
    "zrate"
  ],
  "BlenderDataset": {
    "__init__": [
      "self",
      "root_fp",
      "split",
      "img_wh",
      "max_size",
      "num_rays",
      "color_bkgd_aug",
      "near",
      "far",
      "batch_over_images"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "update_num_rays": [
      "self",
      "num_rays"
    ],
    "fetch_data": [
      "self",
      "index"
    ]
  },
  "ColmapDataset": {
    "__init__": [
      "self",
      "root_fp",
      "split",
      "img_wh",
      "max_size",
      "num_rays",
      "use_mask",
      "color_bkgd_aug",
      "batch_over_images",
      "n_test_traj_steps"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "update_num_rays": [
      "self",
      "num_rays"
    ],
    "fetch_data": [
      "self",
      "index"
    ]
  },
  "CameraModel": [],
  "Camera": [],
  "BaseImage": [],
  "Point3D": [],
  "CAMERA_MODELS": [],
  "CAMERA_MODEL_IDS": [],
  "CAMERA_MODEL_NAMES": [],
  "read_next_bytes": [
    "fid",
    "num_bytes",
    "format_char_sequence",
    "endian_character"
  ],
  "write_next_bytes": [
    "fid",
    "data",
    "format_char_sequence",
    "endian_character"
  ],
  "read_cameras_text": [
    "path"
  ],
  "read_cameras_binary": [
    "path_to_model_file"
  ],
  "write_cameras_text": [
    "cameras",
    "path"
  ],
  "write_cameras_binary": [
    "cameras",
    "path_to_model_file"
  ],
  "read_images_text": [
    "path"
  ],
  "read_images_binary": [
    "path_to_model_file"
  ],
  "write_images_text": [
    "images",
    "path"
  ],
  "write_images_binary": [
    "images",
    "path_to_model_file"
  ],
  "read_points3D_text": [
    "path"
  ],
  "read_points3D_binary": [
    "path_to_model_file"
  ],
  "write_points3D_text": [
    "points3D",
    "path"
  ],
  "write_points3D_binary": [
    "points3D",
    "path_to_model_file"
  ],
  "detect_model_format": [
    "path",
    "ext"
  ],
  "read_model": [
    "path",
    "ext"
  ],
  "write_model": [
    "cameras",
    "images",
    "points3D",
    "path",
    "ext"
  ],
  "qvec2rotmat": [
    "qvec"
  ],
  "RRDBImageDebanding": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_evaluate_postprocess": [
      "self",
      "src",
      "target"
    ],
    "_inference_forward": [
      "self",
      "src"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "vit_base_patch16_224_TransReID": [
    "img_size",
    "stride_size",
    "drop_path_rate",
    "camera",
    "view",
    "local_feature",
    "sie_xishu"
  ],
  "TransReID": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "stride_size",
      "in_chans",
      "num_classes",
      "embed_dim",
      "depth",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "attn_drop_rate",
      "camera",
      "view",
      "drop_path_rate",
      "norm_layer",
      "local_feature",
      "sie_xishu",
      "hw_ratio",
      "gem_pool",
      "stem_conv"
    ],
    "forward_features": [
      "self",
      "x",
      "camera_id",
      "view_id"
    ],
    "forward": [
      "self",
      "x",
      "cam_label",
      "view_label"
    ]
  },
  "GeneralizedMeanPooling": {
    "__init__": [
      "self",
      "norm",
      "output_size",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Fusions": {
    "CAT": [],
    "MEAN": []
  },
  "PASS": {
    "__init__": [
      "self",
      "cfg",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "load_param": [
      "self",
      "trained_path"
    ]
  },
  "SALForImageTryOn": {
    "__init__": [
      "self",
      "model_dir",
      "device_id"
    ],
    "forward": [
      "self",
      "x",
      "y"
    ]
  },
  "infer": [
    "ourgen_model",
    "model_path",
    "person_img",
    "garment_img",
    "mask_img",
    "device"
  ],
  "ResUnetSkipConnectionBlock": {
    "__init__": [
      "self",
      "outer_nc",
      "inner_nc",
      "input_nc",
      "submodule",
      "outermost",
      "innermost",
      "norm_layer",
      "use_dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LandmarkNorm": {
    "__init__": [
      "self",
      "param_free_norm_type",
      "norm_nc",
      "label_nc"
    ],
    "forward": [
      "self",
      "x",
      "segmap"
    ]
  },
  "LandmarkNormResnetBlock": {
    "__init__": [
      "self",
      "fin",
      "fout"
    ],
    "forward": [
      "self",
      "x",
      "seg"
    ],
    "shortcut": [
      "self",
      "x",
      "seg"
    ],
    "actvn": [
      "self",
      "x"
    ]
  },
  "VTONGenerator": {
    "__init__": [
      "self",
      "input_nc",
      "output_nc",
      "num_downs",
      "ngf",
      "norm_layer",
      "use_dropout"
    ],
    "forward": [
      "self",
      "inputs",
      "p_point_heatmap"
    ]
  },
  "ResUnetGenerator": {
    "__init__": [
      "self",
      "input_nc",
      "output_nc",
      "num_downs",
      "ngf",
      "norm_layer",
      "use_dropout"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "VGGLoss": {
    "__init__": [
      "self",
      "layids"
    ],
    "forward": [
      "self",
      "x",
      "y"
    ]
  },
  "load_checkpoint_parallel": [
    "model",
    "checkpoint_path"
  ],
  "DownSample": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LandmarkNet": {
    "__init__": [
      "self",
      "cfg",
      "in_channel",
      "class_num"
    ],
    "_make_transition_layer": [
      "self",
      "num_channels_pre_layer",
      "num_channels_cur_layer"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "blocks",
      "stride"
    ],
    "_make_stage": [
      "self",
      "layer_config",
      "num_inchannels",
      "multi_scale_output"
    ],
    "forward": [
      "self",
      "x"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ]
  },
  "VTONLandmark": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "cloth",
      "person"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ]
  },
  "apply_offset": [
    "offset"
  ],
  "Conv2dBlock": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "kernel_size",
      "stride",
      "padding",
      "norm",
      "activation",
      "pad_type",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResBlock_2": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x1",
      "x2"
    ]
  },
  "UpSample": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ],
    "upsample": [
      "self",
      "F",
      "scale"
    ]
  },
  "FeatureEncoder": {
    "__init__": [
      "self",
      "in_channels",
      "chns"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RefinePyramid": {
    "__init__": [
      "self",
      "chns",
      "fpn_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Round": [
    "x"
  ],
  "Camp": [
    "x",
    "mi",
    "ma"
  ],
  "CorrelationLayer": {
    "__init__": [
      "self",
      "init_scale"
    ],
    "forward": [
      "self",
      "location",
      "fea_c",
      "fea_p",
      "scale_param",
      "H",
      "W",
      "c_landmark",
      "p_landmark"
    ],
    "upsample": [
      "self",
      "F",
      "scale"
    ]
  },
  "LocalFlow": {
    "__init__": [
      "self",
      "fpn_dim",
      "use_num",
      "init_scale"
    ],
    "forward": [
      "self",
      "cloth",
      "fea_c",
      "fea_p",
      "c_landmark",
      "p_landmark"
    ]
  },
  "EqualLR": {
    "__init__": [
      "self",
      "name"
    ],
    "compute_weight": [
      "self",
      "module"
    ],
    "apply": [
      "module",
      "name"
    ],
    "__call__": [
      "self",
      "module",
      "input"
    ]
  },
  "equal_lr": [
    "module",
    "name"
  ],
  "EqualLinear": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ModulatedConv2d": {
    "__init__": [
      "self",
      "fin",
      "fout",
      "kernel_size",
      "padding_type",
      "upsample",
      "downsample",
      "latent_dim",
      "normalize_mlp"
    ],
    "forward": [
      "self",
      "input",
      "latent"
    ]
  },
  "StyledConvBlock": {
    "__init__": [
      "self",
      "fin",
      "fout",
      "latent_dim",
      "padding",
      "actvn",
      "normalize_affine_output",
      "modulated_conv"
    ],
    "forward": [
      "self",
      "input",
      "latent"
    ]
  },
  "Styled_F_ConvBlock": {
    "__init__": [
      "self",
      "fin",
      "fout",
      "latent_dim",
      "padding",
      "actvn",
      "normalize_affine_output",
      "modulated_conv"
    ],
    "forward": [
      "self",
      "input",
      "latent"
    ]
  },
  "AFlowNet": {
    "__init__": [
      "self",
      "num_pyramid",
      "fpn_dim",
      "use_num"
    ],
    "forward": [
      "self",
      "global_flow_input",
      "device",
      "warp_feature"
    ],
    "upsample": [
      "self",
      "F",
      "scale"
    ]
  },
  "Warping": {
    "__init__": [
      "self",
      "input_nc",
      "use_num"
    ],
    "forward": [
      "self",
      "warping_input"
    ],
    "warp": [
      "self",
      "x",
      "flo",
      "device"
    ]
  },
  "ImageQualityAssessmentMos": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_train_forward": [
      "self",
      "input",
      "target"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "_evaluate_postprocess": [
      "self",
      "input",
      "target"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "CenseoIVQAModel": {
    "__init__": [
      "self",
      "pretrained"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SimpleHead": {
    "__init__": [
      "self",
      "feats_dims",
      "out_num"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "compute_hp_neighmap": [
    "nsides"
  ],
  "precompute_pixelization_maps": [
    "nsides",
    "initial_img_size"
  ],
  "precompute_position_encoding": [
    "nsides"
  ],
  "auto_resume_helper": [
    "output_dir"
  ],
  "load_checkpoint_file": [
    "cfg",
    "model",
    "optimizer",
    "lr_scheduler"
  ],
  "reduce_tensor": [
    "tensor"
  ],
  "get_grad_norm": [
    "parameters",
    "norm_type"
  ],
  "TORCH_VERSION": [],
  "is_module_wrapper": [
    "module"
  ],
  "load_url_dist": [
    "url",
    "model_dir"
  ],
  "get_torchvision_models": [],
  "render_depth_map": [
    "hp_data",
    "image_to_sp"
  ],
  "compute_hp_info": [
    "nside",
    "img_size"
  ],
  "SphConv2d": {
    "__init__": [
      "self",
      "in_dims",
      "out_dims",
      "k",
      "neigh_map",
      "groups",
      "bias"
    ],
    "forward": [
      "self",
      "fmap"
    ]
  },
  "SphPixelization": {
    "__init__": [
      "self",
      "index"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SphPosEmbedding": {
    "__init__": [
      "self",
      "dim",
      "pos_enc"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SphInterpolate": {
    "__init__": [
      "self",
      "scale_factor"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PreNorm": {
    "__init__": [
      "self",
      "dim",
      "fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SphGSA": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "heads",
      "dim_head",
      "dropout",
      "k"
    ],
    "forward": [
      "self",
      "fmap"
    ]
  },
  "make_skip_connection": [
    "in_dim",
    "out_dim",
    "pix_index_maps"
  ],
  "ResidualConvBlock": {
    "__init__": [
      "self",
      "in_dim",
      "activation",
      "bn",
      "neighbor_map"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SphCrossAttFusionBlock": {
    "__init__": [
      "self",
      "dim",
      "heads",
      "dim_head",
      "dropout",
      "k0",
      "k1"
    ],
    "forward": [
      "self"
    ]
  },
  "SphCAFBlock": {
    "__init__": [
      "self",
      "dim",
      "pos_enc",
      "k0",
      "k1"
    ],
    "forward": [
      "self"
    ]
  },
  "FeatureFusion": {
    "__init__": [
      "self",
      "enable_caf",
      "dim",
      "neighbor_map",
      "activation",
      "bn",
      "k0",
      "k1",
      "pos_enc"
    ],
    "forward": [
      "self"
    ]
  },
  "FeatureFusionBottom": {
    "__init__": [
      "self",
      "enable_caf",
      "dim",
      "neighbor_map",
      "activation",
      "bn",
      "k",
      "pos_enc"
    ],
    "forward": [
      "self"
    ]
  },
  "SphDecoder": {
    "__init__": [
      "self",
      "cfg",
      "neighbor_maps",
      "num_ch_enc",
      "use_bn",
      "img_size"
    ],
    "forward": [
      "self",
      "enc_feat1",
      "enc_feat2",
      "enc_feat3",
      "enc_feat4"
    ]
  },
  "cfg": [],
  "update_cfg_from_file": [
    "config",
    "cfg_file"
  ],
  "SwinSphDecoderNet": {
    "__init__": [
      "self",
      "cfg",
      "pretrained"
    ],
    "init_weights": [
      "self",
      "pretrained_model"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResnetSphDecoderNet": {
    "__init__": [
      "self",
      "cfg",
      "pretrained"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EfficientNetEncoder": {
    "__init__": [
      "self",
      "backend"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EffnetSphDecoderNet": {
    "__init__": [
      "self",
      "cfg",
      "pretrained"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ActionDetONNX": {
    "__init__": [
      "self",
      "model_dir",
      "config"
    ],
    "resize_box": [
      "self",
      "det",
      "height",
      "width",
      "scale_h",
      "scale_w"
    ],
    "parse_frames": [
      "self",
      "frame_names"
    ],
    "forward_img": [
      "self",
      "imgs",
      "h",
      "w"
    ],
    "forward_video": [
      "self",
      "video_name",
      "scale"
    ],
    "forward": [
      "self",
      "video_name"
    ],
    "post_nms": [
      "self",
      "pred",
      "score_threshold",
      "nms_threshold"
    ],
    "_nms": [
      "self",
      "boxes",
      "scores",
      "idxs",
      "nms_threshold"
    ],
    "_get_sizes": [
      "self",
      "scale"
    ]
  },
  "ActionDetector": {
    "__init__": [
      "self"
    ],
    "load_init_backbone": [
      "self",
      "path"
    ],
    "preprocess_image": [
      "self",
      "batched_inputs"
    ],
    "match_anchors": [
      "self",
      "anchors",
      "gt_instances"
    ],
    "losses": [
      "self",
      "anchors",
      "pred_logits",
      "gt_labels",
      "pred_anchor_deltas",
      "gt_boxes",
      "pred_centerness"
    ],
    "label_anchors": [
      "self",
      "anchors",
      "gt_instances"
    ],
    "compute_ctrness_targets": [
      "self",
      "anchors",
      "gt_boxes"
    ]
  },
  "build_action_detection_model": [
    "num_classes",
    "device"
  ],
  "conv1x3x3": [
    "in_planes",
    "out_planes",
    "stride"
  ],
  "conv3x3x3": [
    "in_planes",
    "out_planes",
    "stride"
  ],
  "conv1x1x1": [
    "in_planes",
    "out_planes",
    "stride"
  ],
  "conv3x1x1": [
    "in_planes",
    "out_planes",
    "stride"
  ],
  "BasicBlock3D": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "op",
      "downsample",
      "base_width",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x"
    ],
    "out_channels": [
      "self"
    ]
  },
  "Bottleneck3D": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "op",
      "downsample",
      "base_width",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x"
    ],
    "out_channels": [
      "self"
    ]
  },
  "ResNet3D": {
    "__init__": [
      "self",
      "block",
      "layers",
      "ops",
      "t_stride",
      "num_classes",
      "zero_init_residual",
      "groups",
      "width_per_group",
      "replace_stride_with_dilation",
      "reduce_dim",
      "norm_layer"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "blocks",
      "ops",
      "stride"
    ],
    "features": [
      "self",
      "x"
    ],
    "logits": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ],
    "norm_x": [
      "self",
      "x"
    ]
  },
  "resnet101_3d": [
    "ops",
    "t_stride",
    "num_class",
    "reduce_dim"
  ],
  "resnet50_3d": [
    "ops",
    "t_stride",
    "num_class",
    "reduce_dim"
  ],
  "resnet34_3d": [
    "ops",
    "t_stride",
    "num_class",
    "reduce_dim"
  ],
  "resnet18_3d": [
    "ops",
    "t_stride",
    "num_class",
    "reduce_dim"
  ],
  "gem": [
    "x",
    "p",
    "eps"
  ],
  "GeM": {
    "__init__": [
      "self",
      "p",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__repr__": [
      "self"
    ]
  },
  "weights_init_kaiming": [
    "m"
  ],
  "weights_init_classifier": [
    "m"
  ],
  "PedestrainAttribute": {
    "__init__": [
      "self",
      "num_classes"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_down_block": [
    "down_block_type",
    "num_layers",
    "in_channels",
    "out_channels",
    "temb_channels",
    "add_downsample",
    "resnet_eps",
    "resnet_act_fn",
    "transformer_layers_per_block",
    "num_attention_heads",
    "resnet_groups",
    "cross_attention_dim",
    "downsample_padding",
    "dual_cross_attention",
    "use_linear_projection",
    "only_cross_attention",
    "upcast_attention",
    "resnet_time_scale_shift",
    "attention_type",
    "resnet_skip_time_act",
    "resnet_out_scale_factor",
    "cross_attention_norm",
    "attention_head_dim",
    "downsample_type"
  ],
  "get_up_block": [
    "up_block_type",
    "num_layers",
    "in_channels",
    "out_channels",
    "prev_output_channel",
    "temb_channels",
    "add_upsample",
    "resnet_eps",
    "resnet_act_fn",
    "transformer_layers_per_block",
    "num_attention_heads",
    "resnet_groups",
    "cross_attention_dim",
    "dual_cross_attention",
    "use_linear_projection",
    "only_cross_attention",
    "upcast_attention",
    "resnet_time_scale_shift",
    "attention_type",
    "resnet_skip_time_act",
    "resnet_out_scale_factor",
    "cross_attention_norm",
    "attention_head_dim",
    "upsample_type"
  ],
  "AutoencoderTinyBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "act_fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UNetMidBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "add_attention",
      "attention_head_dim",
      "output_scale_factor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "UNetMidBlock2DCrossAttn": {
    "__init__": [
      "self",
      "in_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "transformer_layers_per_block",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "num_attention_heads",
      "output_scale_factor",
      "cross_attention_dim",
      "dual_cross_attention",
      "use_linear_projection",
      "upcast_attention",
      "attention_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask"
    ]
  },
  "UNetMidBlock2DSimpleCrossAttn": {
    "__init__": [
      "self",
      "in_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "cross_attention_dim",
      "skip_time_act",
      "only_cross_attention",
      "cross_attention_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask"
    ]
  },
  "AttnDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "downsample_padding",
      "downsample_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "upsample_size"
    ]
  },
  "CrossAttnDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "transformer_layers_per_block",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "num_attention_heads",
      "cross_attention_dim",
      "output_scale_factor",
      "downsample_padding",
      "add_downsample",
      "dual_cross_attention",
      "use_linear_projection",
      "only_cross_attention",
      "upcast_attention",
      "attention_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask",
      "additional_residuals"
    ]
  },
  "DownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_downsample",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "DownEncoderBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_downsample",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AttnDownEncoderBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "add_downsample",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AttnSkipDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "add_downsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "skip_sample"
    ]
  },
  "SkipDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_downsample",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "skip_sample"
    ]
  },
  "ResnetDownsampleBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_downsample",
      "skip_time_act"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "SimpleCrossAttnDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "cross_attention_dim",
      "output_scale_factor",
      "add_downsample",
      "skip_time_act",
      "only_cross_attention",
      "cross_attention_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask"
    ]
  },
  "KDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_group_size",
      "add_downsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "KCrossAttnDownBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "cross_attention_dim",
      "dropout",
      "num_layers",
      "resnet_group_size",
      "add_downsample",
      "attention_head_dim",
      "add_self_attention",
      "resnet_eps",
      "resnet_act_fn"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb",
      "encoder_hidden_states",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask"
    ]
  },
  "AttnUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "prev_output_channel",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "upsample_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "upsample_size"
    ]
  },
  "CrossAttnUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "prev_output_channel",
      "temb_channels",
      "dropout",
      "num_layers",
      "transformer_layers_per_block",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "num_attention_heads",
      "cross_attention_dim",
      "output_scale_factor",
      "add_upsample",
      "dual_cross_attention",
      "use_linear_projection",
      "only_cross_attention",
      "upcast_attention",
      "attention_type",
      "use_pixelwise_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "encoder_hidden_states",
      "pixelwise_hidden_states",
      "cross_attention_kwargs",
      "upsample_size",
      "attention_mask",
      "encoder_attention_mask"
    ]
  },
  "UpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "prev_output_channel",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_upsample",
      "transformer_layers_per_block",
      "num_attention_heads",
      "use_linear_projection",
      "only_cross_attention",
      "upcast_attention",
      "use_pixelwise_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "upsample_size",
      "pixelwise_hidden_states",
      "cross_attention_kwargs"
    ]
  },
  "UpDecoderBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_upsample",
      "temb_channels"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "AttnUpDecoderBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "add_upsample",
      "temb_channels"
    ],
    "forward": [
      "self",
      "hidden_states",
      "temb"
    ]
  },
  "AttnSkipUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "prev_output_channel",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_pre_norm",
      "attention_head_dim",
      "output_scale_factor",
      "add_upsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "skip_sample"
    ]
  },
  "SkipUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "prev_output_channel",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_upsample",
      "upsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "skip_sample"
    ]
  },
  "ResnetUpsampleBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "prev_output_channel",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "output_scale_factor",
      "add_upsample",
      "skip_time_act"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "upsample_size"
    ]
  },
  "SimpleCrossAttnUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "prev_output_channel",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_time_scale_shift",
      "resnet_act_fn",
      "resnet_groups",
      "resnet_pre_norm",
      "attention_head_dim",
      "cross_attention_dim",
      "output_scale_factor",
      "add_upsample",
      "skip_time_act",
      "only_cross_attention",
      "cross_attention_norm"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "encoder_hidden_states",
      "upsample_size",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask"
    ]
  },
  "KUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_group_size",
      "add_upsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "upsample_size"
    ]
  },
  "KCrossAttnUpBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "temb_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_group_size",
      "attention_head_dim",
      "cross_attention_dim",
      "add_upsample",
      "upcast_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "res_hidden_states_tuple",
      "temb",
      "encoder_hidden_states",
      "cross_attention_kwargs",
      "upsample_size",
      "attention_mask",
      "encoder_attention_mask"
    ]
  },
  "KAttentionBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "dropout",
      "cross_attention_dim",
      "attention_bias",
      "upcast_attention",
      "temb_channels",
      "add_self_attention",
      "cross_attention_norm",
      "group_size"
    ],
    "_to_3d": [
      "self",
      "hidden_states",
      "height",
      "weight"
    ],
    "_to_4d": [
      "self",
      "hidden_states",
      "height",
      "weight"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "emb",
      "attention_mask",
      "cross_attention_kwargs",
      "encoder_attention_mask"
    ]
  },
  "UNet2DConditionOutput": {},
  "UNet2DConditionModel": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "sample_size",
      "in_channels",
      "out_channels",
      "center_input_sample",
      "flip_sin_to_cos",
      "freq_shift",
      "down_block_types",
      "mid_block_type",
      "up_block_types",
      "only_cross_attention",
      "block_out_channels",
      "layers_per_block",
      "downsample_padding",
      "mid_block_scale_factor",
      "act_fn",
      "norm_num_groups",
      "norm_eps",
      "cross_attention_dim",
      "transformer_layers_per_block",
      "encoder_hid_dim",
      "encoder_hid_dim_type",
      "attention_head_dim",
      "num_attention_heads",
      "dual_cross_attention",
      "use_linear_projection",
      "class_embed_type",
      "addition_embed_type",
      "addition_time_embed_dim",
      "num_class_embeds",
      "upcast_attention",
      "resnet_time_scale_shift",
      "resnet_skip_time_act",
      "resnet_out_scale_factor",
      "time_embedding_type",
      "time_embedding_dim",
      "time_embedding_act_fn",
      "timestep_post_act",
      "time_cond_proj_dim",
      "conv_in_kernel",
      "conv_out_kernel",
      "projection_class_embeddings_input_dim",
      "attention_type",
      "class_embeddings_concat",
      "mid_block_only_cross_attention",
      "cross_attention_norm",
      "addition_embed_type_num_heads"
    ],
    "attn_processors": [
      "self"
    ],
    "set_attn_processor": [
      "self",
      "processor"
    ],
    "set_default_attn_processor": [
      "self"
    ],
    "set_attention_slice": [
      "self",
      "slice_size"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "encoder_hidden_states",
      "class_labels",
      "timestep_cond",
      "attention_mask",
      "cross_attention_kwargs",
      "added_cond_kwargs",
      "down_block_additional_residuals",
      "mid_block_additional_residual",
      "encoder_attention_mask",
      "return_dict"
    ],
    "from_pretrained_orig": [
      "cls",
      "pretrained_model_path",
      "subfolder"
    ]
  },
  "ControlNetOutput": {},
  "ControlNetConditioningEmbedding": {
    "__init__": [
      "self",
      "conditioning_embedding_channels",
      "conditioning_channels",
      "block_out_channels",
      "return_rgbs",
      "use_rrdb"
    ],
    "forward": [
      "self",
      "conditioning"
    ]
  },
  "ControlNetModel": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "in_channels",
      "conditioning_channels",
      "flip_sin_to_cos",
      "freq_shift",
      "down_block_types",
      "only_cross_attention",
      "block_out_channels",
      "layers_per_block",
      "downsample_padding",
      "mid_block_scale_factor",
      "act_fn",
      "norm_num_groups",
      "norm_eps",
      "cross_attention_dim",
      "transformer_layers_per_block",
      "encoder_hid_dim",
      "encoder_hid_dim_type",
      "attention_head_dim",
      "num_attention_heads",
      "use_linear_projection",
      "class_embed_type",
      "addition_embed_type",
      "addition_time_embed_dim",
      "num_class_embeds",
      "upcast_attention",
      "resnet_time_scale_shift",
      "projection_class_embeddings_input_dim",
      "controlnet_conditioning_channel_order",
      "conditioning_embedding_out_channels",
      "global_pool_conditions",
      "addition_embed_type_num_heads",
      "return_rgbs",
      "use_rrdb"
    ],
    "from_unet": [
      "cls",
      "unet",
      "controlnet_conditioning_channel_order",
      "conditioning_embedding_out_channels",
      "load_weights_from_unet"
    ],
    "attn_processors": [
      "self"
    ],
    "set_attn_processor": [
      "self",
      "processor"
    ],
    "set_default_attn_processor": [
      "self"
    ],
    "set_attention_slice": [
      "self",
      "slice_size"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "encoder_hidden_states",
      "controlnet_cond",
      "fg_mask",
      "conditioning_scale_fg",
      "conditioning_scale_bg",
      "class_labels",
      "timestep_cond",
      "attention_mask",
      "added_cond_kwargs",
      "cross_attention_kwargs",
      "guess_mode",
      "return_dict"
    ]
  },
  "sample_pdf": [
    "bins",
    "weights",
    "n_samples",
    "det",
    "device"
  ],
  "load_K_Rt_from_P": [
    "filename",
    "P"
  ],
  "Dataset": {
    "__init__": [
      "self",
      "data_dir",
      "device"
    ],
    "gen_rays_at": [
      "self",
      "img_idx",
      "resolution_level"
    ],
    "gen_rays_o_at": [
      "self",
      "img_idx"
    ],
    "gen_rays_at_camera": [
      "self",
      "pose",
      "resolution_level"
    ],
    "gen_random_rays_at": [
      "self",
      "img_idx",
      "batch_size"
    ],
    "gen_random_rays_at_mask": [
      "self",
      "img_idx",
      "batch_size"
    ],
    "gen_rays_between": [
      "self",
      "idx_0",
      "idx_1",
      "ratio",
      "resolution_level"
    ],
    "gen_rays_across": [
      "self",
      "idx_0",
      "idx_1",
      "ratio",
      "resolution_level"
    ],
    "near_far_from_sphere": [
      "self",
      "rays_o",
      "rays_d"
    ],
    "image_at": [
      "self",
      "idx",
      "resolution_level"
    ]
  },
  "SurfaceRenderer": {
    "__init__": [
      "self",
      "conf",
      "device"
    ],
    "extract_geometry": [
      "self",
      "bound_min",
      "bound_max",
      "resolution",
      "threshold",
      "device"
    ],
    "render_core_outside": [
      "self",
      "rays_o",
      "rays_d",
      "z_vals",
      "sample_dist",
      "nerf",
      "background_rgb"
    ],
    "up_sample": [
      "self",
      "rays_o",
      "rays_d",
      "z_vals",
      "sdf",
      "n_importance",
      "inv_s"
    ],
    "cat_z_vals": [
      "self",
      "rays_o",
      "rays_d",
      "z_vals",
      "new_z_vals",
      "sdf",
      "last"
    ],
    "render_core": [
      "self",
      "rays_o",
      "rays_d",
      "z_vals",
      "sample_dist",
      "sdf_network",
      "deviation_network",
      "color_network",
      "light_network",
      "depth_z",
      "background_alpha",
      "bg_sampled_color",
      "background_rgb",
      "cos_anneal_ratio"
    ],
    "render": [
      "self",
      "rays_o",
      "rays_d",
      "near",
      "far",
      "depth_z",
      "perturb_overwrite",
      "background_rgb",
      "cos_anneal_ratio"
    ]
  },
  "SurfaceReconCommon": {
    "__init__": [
      "self",
      "model_dir",
      "network_cfg"
    ],
    "load_checkpoint": [
      "self",
      "ckpt_path"
    ],
    "surface_reconstruction": [
      "self",
      "data_dir",
      "save_dir",
      "color",
      "n_directions"
    ]
  },
  "SDFNetwork": {
    "__init__": [
      "self",
      "d_in",
      "d_out",
      "d_hidden",
      "n_layers",
      "skip_in",
      "multires",
      "bias",
      "scale",
      "geometric_init",
      "weight_norm",
      "inside_outside"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "sdf": [
      "self",
      "x"
    ],
    "sdf_hidden_appearance": [
      "self",
      "x"
    ],
    "gradient": [
      "self",
      "x"
    ]
  },
  "RenderingNetwork": {
    "__init__": [
      "self",
      "d_feature",
      "mode",
      "d_in",
      "d_out",
      "d_hidden",
      "n_layers",
      "weight_norm",
      "multires_view",
      "squeeze_out"
    ],
    "forward": [
      "self",
      "points",
      "normals",
      "view_dirs",
      "feature_vectors"
    ]
  },
  "NeRF": {
    "__init__": [
      "self",
      "D",
      "W",
      "d_in",
      "d_in_view",
      "multires",
      "multires_view",
      "output_ch",
      "skips",
      "use_viewdirs"
    ],
    "forward": [
      "self",
      "input_pts",
      "input_views"
    ]
  },
  "SingleVarianceNetwork": {
    "__init__": [
      "self",
      "init_val"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Mean": {
    "__init__": [
      "self",
      "dim",
      "keepdim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Discriminator": {
    "__init__": [
      "self",
      "channel",
      "patch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_embedder": [
    "multires",
    "input_dims"
  ],
  "re_attention": [],
  "parse_prompt_attention": [
    "text"
  ],
  "get_prompts_with_weights": [
    "pipe",
    "prompt",
    "max_length"
  ],
  "pad_tokens_and_weights": [
    "tokens",
    "weights",
    "max_length",
    "bos",
    "eos",
    "pad",
    "no_boseos_middle",
    "chunk_length"
  ],
  "get_unweighted_text_embeddings": [
    "pipe",
    "text_input",
    "chunk_length",
    "no_boseos_middle"
  ],
  "get_weighted_text_embeddings": [
    "pipe",
    "prompt",
    "uncond_prompt",
    "max_embeddings_multiples",
    "no_boseos_middle",
    "skip_parsing",
    "skip_weighting"
  ],
  "rescale_noise_cfg": [
    "noise_cfg",
    "noise_pred_text",
    "guidance_rescale"
  ],
  "StableDiffusionBlendExtendPipeline": {
    "_optional_components": [],
    "_encode_prompt": [
      "self",
      "prompt",
      "device",
      "num_images_per_prompt",
      "do_classifier_free_guidance",
      "negative_prompt",
      "max_embeddings_multiples",
      "prompt_embeds",
      "negative_prompt_embeds",
      "lora_scale"
    ],
    "blend_v": [
      "self",
      "a",
      "b",
      "blend_extent"
    ],
    "blend_h": [
      "self",
      "a",
      "b",
      "blend_extent"
    ],
    "__call__": [
      "self",
      "prompt",
      "height",
      "width",
      "num_inference_steps",
      "guidance_scale",
      "negative_prompt",
      "num_images_per_prompt",
      "eta",
      "generator",
      "latents",
      "prompt_embeds",
      "negative_prompt_embeds",
      "output_type",
      "return_dict",
      "callback",
      "callback_steps",
      "cross_attention_kwargs",
      "guidance_rescale"
    ]
  },
  "prepare_image": [
    "image"
  ],
  "StableDiffusionControlNetImg2ImgPanoPipeline": {
    "_optional_components": [],
    "check_inputs": [
      "self",
      "prompt",
      "image",
      "height",
      "width",
      "callback_steps",
      "negative_prompt",
      "prompt_embeds",
      "negative_prompt_embeds",
      "controlnet_conditioning_scale"
    ],
    "_default_height_width": [
      "self",
      "height",
      "width",
      "image"
    ],
    "_encode_prompt": [
      "self",
      "prompt",
      "device",
      "num_images_per_prompt",
      "do_classifier_free_guidance",
      "negative_prompt",
      "max_embeddings_multiples",
      "prompt_embeds",
      "negative_prompt_embeds",
      "lora_scale"
    ],
    "denoise_latents": [
      "self",
      "latents",
      "t",
      "prompt_embeds",
      "control_image",
      "controlnet_conditioning_scale",
      "guess_mode",
      "cross_attention_kwargs",
      "do_classifier_free_guidance",
      "guidance_scale",
      "extra_step_kwargs",
      "views_scheduler_status"
    ],
    "blend_v": [
      "self",
      "a",
      "b",
      "blend_extent"
    ],
    "blend_h": [
      "self",
      "a",
      "b",
      "blend_extent"
    ],
    "get_blocks": [
      "self",
      "latents",
      "control_image",
      "tile_latent_min_size",
      "overlap_size"
    ],
    "__call__": [
      "self",
      "prompt",
      "image",
      "control_image",
      "height",
      "width",
      "strength",
      "num_inference_steps",
      "guidance_scale",
      "negative_prompt",
      "num_images_per_prompt",
      "eta",
      "generator",
      "latents",
      "prompt_embeds",
      "negative_prompt_embeds",
      "output_type",
      "return_dict",
      "callback",
      "callback_steps",
      "cross_attention_kwargs",
      "controlnet_conditioning_scale",
      "guess_mode",
      "context_size"
    ]
  },
  "KeypointsTypes": {
    "POSES_CAMERA": []
  },
  "HDFormerDetector": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "load_model": [
      "self",
      "load_to_cpu"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "avg_flip": [
      "self",
      "pre",
      "pre_flip"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Skeleton": {
    "__init__": [
      "self",
      "parents",
      "joints_left",
      "joints_right"
    ],
    "num_joints": [
      "self"
    ],
    "parents": [
      "self"
    ],
    "has_children": [
      "self"
    ],
    "children": [
      "self"
    ],
    "remove_joints": [
      "self",
      "joints_to_remove"
    ],
    "joints_left": [
      "self"
    ],
    "joints_right": [
      "self"
    ],
    "_compute_metadata": [
      "self"
    ]
  },
  "get_skeleton": [],
  "edge2mat": [
    "link",
    "num_node"
  ],
  "normalize_incidence_matrix": [
    "im"
  ],
  "build_digraph_incidence_matrix": [
    "num_nodes",
    "edges"
  ],
  "DiGraph": {
    "__init__": [
      "self",
      "skeleton"
    ]
  },
  "Graph": {
    "__init__": [
      "self",
      "skeleton",
      "strategy",
      "max_hop",
      "dilation"
    ],
    "__str__": [
      "self"
    ],
    "get_edge": [
      "self",
      "skeleton"
    ],
    "get_adjacency": [
      "self",
      "strategy"
    ]
  },
  "get_hop_distance": [
    "num_node",
    "edge",
    "max_hop"
  ],
  "normalize_digraph": [
    "A"
  ],
  "normalize_undigraph": [
    "A"
  ],
  "HDFormerNet": {
    "__init__": [
      "self",
      "cfg"
    ],
    "get_edge_fea": [
      "self",
      "x_v"
    ],
    "forward": [
      "self",
      "x_v"
    ]
  },
  "HDFormer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "x_v",
      "mean_3d",
      "std_3d"
    ]
  },
  "import_class": [
    "name"
  ],
  "conv_branch_init": [
    "conv",
    "branches"
  ],
  "conv_init": [
    "conv"
  ],
  "bn_init": [
    "bn",
    "scale"
  ],
  "zero": [
    "x"
  ],
  "iden": [
    "x"
  ],
  "FirstOrderAttention": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "A",
      "t_kernel_size",
      "t_stride",
      "t_padding",
      "t_dilation",
      "adj_len",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HightOrderAttentionBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "A",
      "di_graph",
      "attention",
      "stride",
      "adj_len",
      "dropout",
      "residual",
      "norm_layer",
      "edge_importance",
      "graph",
      "conditional",
      "experts",
      "bias",
      "share_tcn",
      "max_hop"
    ],
    "forward": [
      "self",
      "fv",
      "fe"
    ]
  },
  "TemporalModelBase": {
    "__init__": [
      "self",
      "num_joints_in",
      "in_features",
      "num_joints_out",
      "filter_widths",
      "causal",
      "dropout",
      "channels"
    ],
    "set_bn_momentum": [
      "self",
      "momentum"
    ],
    "receptive_field": [
      "self"
    ],
    "total_causal_shift": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TemporalModel": {
    "__init__": [
      "self",
      "num_joints_in",
      "in_features",
      "num_joints_out",
      "filter_widths",
      "causal",
      "dropout",
      "channels",
      "dense"
    ],
    "_forward_blocks": [
      "self",
      "x"
    ]
  },
  "TransCan3Dkeys": {
    "__init__": [
      "self",
      "in_channels",
      "num_features",
      "out_channels",
      "time_window",
      "num_blocks"
    ],
    "_make_blocks": [
      "self"
    ],
    "set_bn_momentum": [
      "self",
      "momentum"
    ],
    "forward": [
      "self",
      "p2ds",
      "p3d"
    ]
  },
  "BodyKeypointsDetection3D": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_create_model": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "train": [
      "self"
    ],
    "to_device": [
      "self",
      "device"
    ],
    "load_pretrained": [
      "self"
    ],
    "preprocess": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "get_abs_2d_pts": [
      "self",
      "input_video_frame_num",
      "pose2d_rr",
      "pose2d_canonical"
    ],
    "canonicalize_2Ds": [
      "self",
      "pos2d",
      "f",
      "c"
    ],
    "normalize_screen_coordinates": [
      "self",
      "X",
      "w",
      "h"
    ]
  },
  "PixelNorm": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "make_kernel": [
    "k"
  ],
  "Blur": {
    "__init__": [
      "self",
      "kernel",
      "pad",
      "upsample_factor"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "EqualConv2d": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel",
      "kernel_size",
      "stride",
      "padding",
      "bias"
    ],
    "forward": [
      "self",
      "input"
    ],
    "__repr__": [
      "self"
    ]
  },
  "NoiseInjection": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "image",
      "noise"
    ]
  },
  "ConstantInput": {
    "__init__": [
      "self",
      "channel",
      "size"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "StyledConv": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel",
      "kernel_size",
      "style_dim",
      "upsample",
      "blur_kernel",
      "demodulate"
    ],
    "forward": [
      "self",
      "input",
      "style",
      "noise"
    ]
  },
  "ToRGB": {
    "__init__": [
      "self",
      "in_channel",
      "style_dim",
      "upsample",
      "blur_kernel"
    ],
    "forward": [
      "self",
      "input",
      "style",
      "skip"
    ]
  },
  "Generator": {
    "__init__": [
      "self",
      "size",
      "style_dim",
      "n_mlp",
      "channel_multiplier",
      "blur_kernel",
      "lr_mlp"
    ],
    "make_noise": [
      "self"
    ],
    "mean_latent": [
      "self",
      "n_latent"
    ],
    "get_latent": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "styles",
      "return_latents",
      "inject_index",
      "truncation",
      "truncation_latent",
      "input_is_latent",
      "noise",
      "randomize_noise"
    ]
  },
  "def_lib": [],
  "could_use_op": [
    "input"
  ],
  "ensure_tuple": [
    "xs",
    "ndim"
  ],
  "conv2d_gradfix_cache": [],
  "conv2d_gradfix": [
    "transpose",
    "weight_shape",
    "stride",
    "padding",
    "output_padding",
    "dilation",
    "groups"
  ],
  "SplAtConv2d": {
    "__init__": [
      "self",
      "in_channels",
      "channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "radix",
      "reduction_factor",
      "rectify",
      "rectify_avg",
      "norm_layer",
      "dropblock_prob"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "rSoftMax": {
    "__init__": [
      "self",
      "radix",
      "cardinality"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DropBlock2D": {
    "__init__": [
      "self"
    ]
  },
  "GlobalAvgPool2d": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "DepeDetect": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "img",
      "img_metas"
    ]
  },
  "check_point_in_img": [
    "points",
    "height",
    "width"
  ],
  "depth2color": [
    "depth"
  ],
  "lidar2img": [
    "points_lidar",
    "camrera_info"
  ],
  "get_lidar2global": [
    "infos"
  ],
  "plot_result": [
    "res_path",
    "vis_thred",
    "version",
    "draw_gt",
    "save_format"
  ],
  "CustomNuScenesDataset": {
    "__init__": [
      "self",
      "idx_range"
    ],
    "get_data_info": [
      "self",
      "index"
    ]
  },
  "LoadMultiViewImageFromMultiSweepsFiles": {
    "__init__": [
      "self",
      "sweeps_num",
      "to_float32",
      "file_client_args",
      "pad_empty_sweeps",
      "sweep_range",
      "sweeps_id",
      "color_type",
      "sensors",
      "test_mode",
      "prob"
    ],
    "__call__": [
      "self",
      "results"
    ],
    "__repr__": [
      "self"
    ]
  },
  "PadMultiViewImage": {
    "__init__": [
      "self",
      "size",
      "size_divisor",
      "pad_val"
    ],
    "_pad_img": [
      "self",
      "results"
    ],
    "__call__": [
      "self",
      "results"
    ],
    "__repr__": [
      "self"
    ]
  },
  "NormalizeMultiviewImage": {
    "__init__": [
      "self",
      "mean",
      "std",
      "to_rgb"
    ],
    "__call__": [
      "self",
      "results"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ResizeCropFlipImage": {
    "__init__": [
      "self",
      "data_aug_conf",
      "training",
      "diff_aug"
    ],
    "__call__": [
      "self",
      "results"
    ],
    "_get_rot": [
      "self",
      "h"
    ],
    "_img_transform": [
      "self",
      "img",
      "resize",
      "resize_dims",
      "crop",
      "flip",
      "rotate"
    ],
    "_sample_augmentation": [
      "self"
    ]
  },
  "Petr3D": {
    "__init__": [
      "self",
      "use_grid_mask",
      "pts_voxel_layer",
      "pts_voxel_encoder",
      "pts_middle_encoder",
      "pts_fusion_layer",
      "img_backbone",
      "pts_backbone",
      "img_neck",
      "pts_neck",
      "pts_bbox_head",
      "img_roi_head",
      "img_rpn_head",
      "train_cfg",
      "test_cfg",
      "pretrained"
    ],
    "extract_img_feat": [
      "self",
      "img",
      "img_metas"
    ],
    "extract_feat": [
      "self",
      "img",
      "img_metas"
    ],
    "forward_pts_train": [
      "self",
      "pts_feats",
      "gt_bboxes_3d",
      "gt_labels_3d",
      "img_metas",
      "gt_bboxes_ignore"
    ],
    "forward": [
      "self",
      "return_loss"
    ],
    "forward_train": [
      "self",
      "points",
      "img_metas",
      "gt_bboxes_3d",
      "gt_labels_3d",
      "gt_labels",
      "gt_bboxes",
      "img",
      "proposals",
      "gt_bboxes_ignore",
      "img_depth",
      "img_mask"
    ],
    "forward_test": [
      "self",
      "img_metas",
      "img"
    ],
    "simple_test_pts": [
      "self",
      "x",
      "img_metas",
      "rescale"
    ],
    "simple_test": [
      "self",
      "img_metas",
      "img",
      "rescale"
    ],
    "aug_test_pts": [
      "self",
      "feats",
      "img_metas",
      "rescale"
    ],
    "aug_test": [
      "self",
      "img_metas",
      "imgs",
      "rescale"
    ]
  },
  "VoVNet19_slim_dw_eSE": [],
  "VoVNet19_dw_eSE": [],
  "VoVNet19_slim_eSE": [],
  "VoVNet19_eSE": [],
  "VoVNet39_eSE": [],
  "VoVNet57_eSE": [],
  "VoVNet99_eSE": [],
  "_STAGE_SPECS": [],
  "dw_conv3x3": [
    "in_channels",
    "out_channels",
    "module_name",
    "postfix",
    "stride",
    "kernel_size",
    "padding"
  ],
  "Hsigmoid": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "eSEModule": {
    "__init__": [
      "self",
      "channel",
      "reduction"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_OSA_module": {
    "__init__": [
      "self",
      "in_ch",
      "stage_ch",
      "concat_ch",
      "layer_per_block",
      "module_name",
      "SE",
      "identity",
      "depthwise"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_OSA_stage": {
    "__init__": [
      "self",
      "in_ch",
      "stage_ch",
      "concat_ch",
      "block_per_stage",
      "layer_per_block",
      "stage_num",
      "SE",
      "depthwise"
    ]
  },
  "VoVNet": {
    "__init__": [
      "self",
      "spec_name",
      "input_ch",
      "out_features",
      "frozen_stages",
      "norm_eval",
      "pretrained",
      "init_cfg"
    ],
    "_initialize_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_freeze_stages": [
      "self"
    ],
    "train": [
      "self",
      "mode"
    ]
  },
  "SinePositionalEncoding3D": {
    "__init__": [
      "self",
      "num_feats",
      "temperature",
      "normalize",
      "scale",
      "eps",
      "offset",
      "init_cfg",
      "skip_n"
    ],
    "forward": [
      "self",
      "mask"
    ],
    "__repr__": [
      "self"
    ]
  },
  "PETRDNTransformer": {
    "__init__": [
      "self",
      "encoder",
      "decoder",
      "init_cfg",
      "cross"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "query_embed",
      "pos_embed",
      "attn_masks",
      "reg_branch"
    ]
  },
  "PETRTransformerDecoderLayer": {
    "__init__": [
      "self",
      "attn_cfgs",
      "feedforward_channels",
      "embed_dims",
      "ffn_dropout",
      "operation_order",
      "act_cfg",
      "norm_cfg",
      "ffn_num_fcs",
      "with_cp"
    ],
    "_forward": [
      "self",
      "query",
      "key",
      "value",
      "query_pos",
      "key_pos",
      "attn_masks",
      "query_key_padding_mask",
      "key_padding_mask"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "query_pos",
      "key_pos",
      "attn_masks",
      "query_key_padding_mask",
      "key_padding_mask"
    ]
  },
  "PETRMultiheadAttention": {
    "__init__": [
      "self",
      "embed_dims",
      "num_heads",
      "attn_drop",
      "proj_drop",
      "dropout_layer",
      "init_cfg",
      "batch_first"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "identity",
      "query_pos",
      "key_pos",
      "attn_mask",
      "key_padding_mask"
    ]
  },
  "PETRTransformerEncoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "PETRTransformerDecoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "query"
    ]
  },
  "_ASPPModule": {
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "kernel_size",
      "padding",
      "dilation",
      "BatchNorm"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_init_weight": [
      "self"
    ]
  },
  "DepthNet": {
    "__init__": [
      "self",
      "in_channels",
      "mid_channels",
      "context_channels",
      "depth_channels",
      "use_dcn",
      "use_aspp",
      "use_mlp"
    ],
    "forward": [
      "self",
      "x",
      "mlp_input"
    ]
  },
  "pos2posemb3d": [
    "pos",
    "num_pos_feats",
    "temperature"
  ],
  "RegLayer": {
    "__init__": [
      "self",
      "embed_dims",
      "shared_reg_fcs",
      "group_reg_dims",
      "act_layer",
      "drop"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PETRv2DEDNHead": {
    "__init__": [
      "self",
      "num_classes",
      "in_channels",
      "num_query",
      "num_reg_fcs",
      "transformer",
      "sync_cls_avg_factor",
      "positional_encoding",
      "code_weights",
      "bbox_coder",
      "loss_cls",
      "loss_bbox",
      "loss_iou",
      "train_cfg",
      "test_cfg",
      "with_position",
      "with_multiview",
      "depth_step",
      "depth_num",
      "LID",
      "depth_start",
      "position_level",
      "depth_level",
      "position_range",
      "group_reg_dims",
      "scalar",
      "noise_scale",
      "noise_trans",
      "dn_weight",
      "split",
      "init_cfg",
      "normedlinear",
      "with_fpe",
      "with_time",
      "with_multi"
    ],
    "_init_layers": [
      "self"
    ],
    "init_weights": [
      "self"
    ],
    "get_mlp_input": [
      "self",
      "img_metas"
    ],
    "position_embeding": [
      "self",
      "img_feats",
      "img_metas",
      "masks"
    ],
    "prepare_for_dn": [
      "self",
      "batch_size",
      "reference_points",
      "img_metas"
    ],
    "_load_from_state_dict": [
      "self",
      "state_dict",
      "prefix",
      "local_metadata",
      "strict",
      "missing_keys",
      "unexpected_keys",
      "error_msgs"
    ],
    "forward": [
      "self",
      "mlvl_feats",
      "img_metas"
    ],
    "get_downsampled_gt_depth": [
      "self",
      "gt_depths"
    ],
    "get_depth_loss": [
      "self",
      "gt_depth",
      "pred_depth"
    ],
    "prepare_for_loss": [
      "self",
      "mask_dict"
    ],
    "_get_target_single": [
      "self",
      "cls_score",
      "bbox_pred",
      "gt_labels",
      "gt_bboxes",
      "gt_bboxes_ignore"
    ],
    "get_targets": [
      "self",
      "cls_scores_list",
      "bbox_preds_list",
      "gt_bboxes_list",
      "gt_labels_list",
      "gt_bboxes_ignore_list"
    ],
    "loss_single": [
      "self",
      "cls_scores",
      "bbox_preds",
      "gt_bboxes_list",
      "gt_labels_list",
      "gt_bboxes_ignore_list"
    ],
    "dn_loss_single": [
      "self",
      "cls_scores",
      "bbox_preds",
      "known_bboxs",
      "known_labels",
      "num_total_pos"
    ],
    "loss": [
      "self",
      "gt_bboxes_list",
      "gt_labels_list",
      "preds_dicts",
      "gt_depth",
      "gt_bboxes_ignore"
    ],
    "get_bboxes": [
      "self",
      "preds_dicts",
      "img_metas",
      "rescale"
    ]
  },
  "CPFPN": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_outs",
      "start_level",
      "end_level",
      "add_extra_convs",
      "relu_before_extra_convs",
      "no_norm_on_lateral",
      "conv_cfg",
      "norm_cfg",
      "act_cfg",
      "upsample_cfg",
      "init_cfg"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "normalize_bbox": [
    "bboxes",
    "pc_range"
  ],
  "denormalize_bbox": [
    "normalized_bboxes",
    "pc_range"
  ],
  "BBox3DL1Cost": {
    "__init__": [
      "self",
      "weight"
    ],
    "__call__": [
      "self",
      "bbox_pred",
      "gt_bboxes"
    ]
  },
  "NMSFreeCoder": {
    "__init__": [
      "self",
      "pc_range",
      "voxel_size",
      "post_center_range",
      "max_num",
      "score_threshold",
      "num_classes"
    ],
    "encode": [
      "self"
    ],
    "decode_single": [
      "self",
      "cls_scores",
      "bbox_preds"
    ],
    "decode": [
      "self",
      "preds_dicts"
    ]
  },
  "HungarianAssigner3D": {
    "__init__": [
      "self",
      "cls_cost",
      "reg_cost",
      "iou_cost",
      "pc_range"
    ],
    "assign": [
      "self",
      "bbox_pred",
      "cls_pred",
      "gt_bboxes",
      "gt_labels",
      "gt_bboxes_ignore",
      "eps"
    ]
  },
  "lg_e_10": [],
  "log10": [
    "x"
  ],
  "Result": {
    "__init__": [
      "self"
    ],
    "set_to_worst": [
      "self"
    ],
    "update": [
      "self",
      "irmse",
      "imae",
      "mse",
      "rmse",
      "mae",
      "absrel",
      "squared_rel",
      "lg10",
      "delta1",
      "delta2",
      "delta3",
      "gpu_time",
      "data_time",
      "silog",
      "photometric"
    ],
    "evaluate": [
      "self",
      "output",
      "target",
      "photometric"
    ]
  },
  "loss_names": [],
  "MaskedMSELoss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "pred",
      "target"
    ]
  },
  "MaskedL1Loss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "pred",
      "target",
      "weight"
    ]
  },
  "PhotometricLoss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "target",
      "recon",
      "mask"
    ]
  },
  "SmoothnessLoss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "depth"
    ]
  },
  "m_logger": [],
  "ArgsList": {
    "__init__": [
      "self"
    ]
  },
  "SelfSupervisedDepthCompletion": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "iterate": [
      "self",
      "mode",
      "args",
      "loader",
      "model",
      "optimizer",
      "logger",
      "epoch"
    ],
    "forward": [
      "self",
      "source_dir"
    ]
  },
  "init_weights": [
    "m"
  ],
  "convt_bn_relu": [
    "in_channels",
    "out_channels",
    "kernel_size",
    "stride",
    "padding",
    "output_padding",
    "bn",
    "relu"
  ],
  "DepthCompletionNet": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "cmap": [],
  "depth_colorize": [
    "depth"
  ],
  "merge_into_row": [
    "ele",
    "pred"
  ],
  "add_row": [
    "img_merge",
    "row"
  ],
  "save_image": [
    "img_merge",
    "filename"
  ],
  "save_depth_as_uint16png": [
    "img",
    "filename"
  ],
  "display_warping": [
    "rgb_tgt",
    "pred_tgt",
    "warped"
  ],
  "Intrinsics": {
    "__init__": [
      "self",
      "width",
      "height",
      "fu",
      "fv",
      "cu",
      "cv"
    ],
    "cuda": [
      "self"
    ],
    "scale": [
      "self",
      "height",
      "width"
    ],
    "__print__": [
      "self"
    ]
  },
  "image_to_pointcloud": [
    "depth",
    "intrinsics"
  ],
  "pointcloud_to_image": [
    "pointcloud",
    "intrinsics"
  ],
  "batch_multiply": [
    "batch_scalar",
    "batch_matrix"
  ],
  "transform_curr_to_near": [
    "pointcloud_curr",
    "r_mat",
    "t_vec",
    "intrinsics"
  ],
  "homography_from": [
    "rgb_near",
    "depth_curr",
    "r_mat",
    "t_vec",
    "intrinsics"
  ],
  "fieldnames": [],
  "ignore_hidden": [],
  "backup_source_code": [
    "backup_directory"
  ],
  "adjust_learning_rate": [
    "lr_init",
    "optimizer",
    "epoch"
  ],
  "get_folder_name": [
    "args"
  ],
  "avgpool": [],
  "multiscale": [
    "img"
  ],
  "input_options": [],
  "load_calib": [
    "args"
  ],
  "get_paths_and_transform": [
    "split",
    "args"
  ],
  "rgb_read": [
    "filename"
  ],
  "depth_read": [
    "filename"
  ],
  "drop_depth_measurements": [
    "depth",
    "prob_keep"
  ],
  "train_transform": [
    "rgb",
    "sparse",
    "target",
    "rgb_near",
    "args"
  ],
  "val_transform": [
    "rgb",
    "sparse",
    "target",
    "rgb_near",
    "args"
  ],
  "no_transform": [
    "rgb",
    "sparse",
    "target",
    "rgb_near",
    "args"
  ],
  "to_float_tensor": [
    "x"
  ],
  "handle_gray": [
    "rgb",
    "args"
  ],
  "get_rgb_near": [
    "path",
    "args"
  ],
  "KittiDepth": {
    "__init__": [
      "self",
      "split",
      "args"
    ],
    "__getraw__": [
      "self",
      "index"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "_is_pil_image": [
    "img"
  ],
  "adjust_brightness": [
    "img",
    "brightness_factor"
  ],
  "adjust_contrast": [
    "img",
    "contrast_factor"
  ],
  "adjust_saturation": [
    "img",
    "saturation_factor"
  ],
  "adjust_hue": [
    "img",
    "hue_factor"
  ],
  "adjust_gamma": [
    "img",
    "gamma",
    "gain"
  ],
  "NormalizeNumpyArray": {
    "__init__": [
      "self",
      "mean",
      "std"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "NormalizeTensor": {
    "__init__": [
      "self",
      "mean",
      "std"
    ],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "Rotate": {
    "__init__": [
      "self",
      "angle"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "BottomCrop": {
    "__init__": [
      "self",
      "size"
    ],
    "get_params": [
      "img",
      "output_size"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "Crop": {
    "__init__": [
      "self",
      "crop"
    ],
    "get_params": [
      "img",
      "crop"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "Lambda": {
    "__init__": [
      "self",
      "lambd"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "HorizontalFlip": {
    "__init__": [
      "self",
      "do_flip"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "ColorJitter": {
    "__init__": [
      "self",
      "brightness",
      "contrast",
      "saturation",
      "hue"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "rgb2gray": [
    "rgb"
  ],
  "convert_2d_to_3d": [
    "u",
    "v",
    "z",
    "K"
  ],
  "feature_match": [
    "img1",
    "img2"
  ],
  "get_pose_pnp": [
    "rgb_curr",
    "rgb_near",
    "depth_curr",
    "K"
  ],
  "ControlledUnetModel": {
    "forward": [
      "self",
      "x",
      "timesteps",
      "context",
      "control",
      "only_mid_control"
    ]
  },
  "ControlLDM": {
    "__init__": [
      "self",
      "control_stage_config",
      "control_key",
      "only_mid_control"
    ],
    "get_input": [
      "self",
      "batch",
      "k",
      "bs"
    ],
    "apply_model": [
      "self",
      "x_noisy",
      "t",
      "cond"
    ],
    "get_unconditional_conditioning": [
      "self",
      "N"
    ],
    "log_images": [
      "self",
      "batch",
      "N",
      "n_row",
      "sample",
      "ddim_steps",
      "ddim_eta",
      "return_keys",
      "quantize_denoised",
      "inpaint",
      "plot_denoise_rows",
      "plot_progressive_rows",
      "plot_diffusion_rows",
      "unconditional_guidance_scale",
      "unconditional_guidance_label",
      "use_ema_scope"
    ],
    "sample_log": [
      "self",
      "cond",
      "batch_size",
      "ddim",
      "ddim_steps"
    ],
    "configure_optimizers": [
      "self"
    ],
    "low_vram_shift": [
      "self",
      "is_diffusing"
    ]
  },
  "mask_score": [
    "mask"
  ],
  "sobel": [
    "img",
    "mask",
    "thresh"
  ],
  "resize_and_pad": [
    "image",
    "box"
  ],
  "expand_image_mask": [
    "image",
    "mask",
    "ratio"
  ],
  "resize_box": [
    "yyxx",
    "H",
    "W",
    "h",
    "w"
  ],
  "get_bbox_from_mask": [
    "mask"
  ],
  "expand_bbox": [
    "mask",
    "yyxx",
    "ratio",
    "min_crop"
  ],
  "box2squre": [
    "image",
    "box"
  ],
  "pad_to_square": [
    "image",
    "pad_value",
    "random"
  ],
  "box_in_box": [
    "small_box",
    "big_box"
  ],
  "shuffle_image": [
    "image",
    "N"
  ],
  "get_mosaic_mask": [
    "image",
    "fg_mask",
    "N",
    "ratio"
  ],
  "extract_canny_noise": [
    "image",
    "mask",
    "dilate"
  ],
  "get_random_structure": [
    "size"
  ],
  "random_dilate": [
    "seg",
    "min",
    "max"
  ],
  "random_erode": [
    "seg",
    "min",
    "max"
  ],
  "select_max_region": [
    "mask"
  ],
  "perturb_mask": [
    "gt",
    "min_iou",
    "max_iou"
  ],
  "q_x": [
    "x_0",
    "t"
  ],
  "extract_target_boundary": [
    "img",
    "target_mask"
  ],
  "append_dims": [
    "x",
    "target_dims"
  ],
  "norm_thresholding": [
    "x0",
    "value"
  ],
  "spatial_norm_thresholding": [
    "x0",
    "value"
  ],
  "__conditioning_keys__": [],
  "uniform_on_device": [
    "r1",
    "r2",
    "shape",
    "device"
  ],
  "DDPM": {
    "__init__": [
      "self",
      "unet_config",
      "timesteps",
      "beta_schedule",
      "loss_type",
      "ckpt_path",
      "ignore_keys",
      "load_only_unet",
      "monitor",
      "use_ema",
      "first_stage_key",
      "image_size",
      "channels",
      "log_every_t",
      "clip_denoised",
      "linear_start",
      "linear_end",
      "cosine_s",
      "given_betas",
      "original_elbo_weight",
      "v_posterior",
      "l_simple_weight",
      "conditioning_key",
      "parameterization",
      "scheduler_config",
      "use_positional_encodings",
      "learn_logvar",
      "logvar_init",
      "make_it_fit",
      "ucg_training",
      "reset_ema",
      "reset_num_ema_updates"
    ],
    "register_schedule": [
      "self",
      "given_betas",
      "beta_schedule",
      "timesteps",
      "linear_start",
      "linear_end",
      "cosine_s"
    ],
    "ema_scope": [
      "self",
      "context"
    ],
    "init_from_ckpt": [
      "self",
      "path",
      "ignore_keys",
      "only_model"
    ],
    "q_mean_variance": [
      "self",
      "x_start",
      "t"
    ],
    "predict_start_from_noise": [
      "self",
      "x_t",
      "t",
      "noise"
    ],
    "predict_start_from_z_and_v": [
      "self",
      "x_t",
      "t",
      "v"
    ],
    "predict_eps_from_z_and_v": [
      "self",
      "x_t",
      "t",
      "v"
    ],
    "q_posterior": [
      "self",
      "x_start",
      "x_t",
      "t"
    ],
    "p_mean_variance": [
      "self",
      "x",
      "t",
      "clip_denoised"
    ],
    "p_sample": [
      "self",
      "x",
      "t",
      "clip_denoised",
      "repeat_noise"
    ],
    "p_sample_loop": [
      "self",
      "shape",
      "return_intermediates"
    ],
    "sample": [
      "self",
      "batch_size",
      "return_intermediates"
    ],
    "q_sample": [
      "self",
      "x_start",
      "t",
      "noise"
    ],
    "get_v": [
      "self",
      "x",
      "noise",
      "t"
    ],
    "get_loss": [
      "self",
      "pred",
      "target",
      "mean"
    ],
    "p_losses": [
      "self",
      "x_start",
      "t",
      "noise"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_input": [
      "self",
      "batch",
      "k"
    ],
    "shared_step": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_train_batch_end": [
      "self"
    ],
    "_get_rows_from_list": [
      "self",
      "samples"
    ],
    "log_images": [
      "self",
      "batch",
      "N",
      "n_row",
      "sample",
      "return_keys"
    ],
    "configure_optimizers": [
      "self"
    ]
  },
  "LatentDiffusion": {
    "__init__": [
      "self",
      "first_stage_config",
      "cond_stage_config",
      "num_timesteps_cond",
      "cond_stage_key",
      "cond_stage_trainable",
      "concat_mode",
      "cond_stage_forward",
      "conditioning_key",
      "scale_factor",
      "scale_by_std",
      "force_null_conditioning"
    ],
    "make_cond_schedule": [
      "self"
    ],
    "on_train_batch_start": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "register_schedule": [
      "self",
      "given_betas",
      "beta_schedule",
      "timesteps",
      "linear_start",
      "linear_end",
      "cosine_s"
    ],
    "instantiate_first_stage": [
      "self",
      "config"
    ],
    "instantiate_cond_stage": [
      "self",
      "config"
    ],
    "_get_denoise_row_from_list": [
      "self",
      "samples",
      "desc",
      "force_no_decoder_quantization"
    ],
    "get_first_stage_encoding": [
      "self",
      "encoder_posterior"
    ],
    "get_learned_conditioning": [
      "self",
      "c"
    ],
    "meshgrid": [
      "self",
      "h",
      "w"
    ],
    "delta_border": [
      "self",
      "h",
      "w"
    ],
    "get_weighting": [
      "self",
      "h",
      "w",
      "Ly",
      "Lx",
      "device"
    ],
    "get_fold_unfold": [
      "self",
      "x",
      "kernel_size",
      "stride",
      "uf",
      "df"
    ],
    "get_input": [
      "self",
      "batch",
      "k",
      "return_first_stage_outputs",
      "force_c_encode",
      "cond_key",
      "return_original_cond",
      "bs",
      "return_x"
    ],
    "decode_first_stage": [
      "self",
      "z",
      "predict_cids",
      "force_not_quantize"
    ],
    "encode_first_stage": [
      "self",
      "x"
    ],
    "shared_step": [
      "self",
      "batch"
    ],
    "forward": [
      "self",
      "x",
      "c"
    ],
    "apply_model": [
      "self",
      "x_noisy",
      "t",
      "cond",
      "return_ids"
    ],
    "_predict_eps_from_xstart": [
      "self",
      "x_t",
      "t",
      "pred_xstart"
    ],
    "_prior_bpd": [
      "self",
      "x_start"
    ],
    "p_losses": [
      "self",
      "x_start",
      "cond",
      "t",
      "noise"
    ],
    "p_mean_variance": [
      "self",
      "x",
      "c",
      "t",
      "clip_denoised",
      "return_codebook_ids",
      "quantize_denoised",
      "return_x0",
      "score_corrector",
      "corrector_kwargs"
    ],
    "p_sample": [
      "self",
      "x",
      "c",
      "t",
      "clip_denoised",
      "repeat_noise",
      "return_codebook_ids",
      "quantize_denoised",
      "return_x0",
      "temperature",
      "noise_dropout",
      "score_corrector",
      "corrector_kwargs"
    ],
    "progressive_denoising": [
      "self",
      "cond",
      "shape",
      "verbose",
      "callback",
      "quantize_denoised",
      "img_callback",
      "mask",
      "x0",
      "temperature",
      "noise_dropout",
      "score_corrector",
      "corrector_kwargs",
      "batch_size",
      "x_T",
      "start_T",
      "log_every_t"
    ],
    "p_sample_loop": [
      "self",
      "cond",
      "shape",
      "return_intermediates",
      "x_T",
      "verbose",
      "callback",
      "timesteps",
      "quantize_denoised",
      "mask",
      "x0",
      "img_callback",
      "start_T",
      "log_every_t"
    ],
    "sample": [
      "self",
      "cond",
      "batch_size",
      "return_intermediates",
      "x_T",
      "verbose",
      "timesteps",
      "quantize_denoised",
      "mask",
      "x0",
      "shape"
    ],
    "sample_log": [
      "self",
      "cond",
      "batch_size",
      "ddim",
      "ddim_steps"
    ],
    "get_unconditional_conditioning": [
      "self",
      "batch_size",
      "null_label"
    ],
    "log_images": [
      "self",
      "batch",
      "N",
      "n_row",
      "sample",
      "ddim_steps",
      "ddim_eta",
      "return_keys",
      "quantize_denoised",
      "inpaint",
      "plot_denoise_rows",
      "plot_progressive_rows",
      "plot_diffusion_rows",
      "unconditional_guidance_scale",
      "unconditional_guidance_label",
      "use_ema_scope"
    ],
    "configure_optimizers": [
      "self"
    ],
    "to_rgb": [
      "self",
      "x"
    ]
  },
  "DiffusionWrapper": {
    "__init__": [
      "self",
      "diff_model_config",
      "conditioning_key"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "c_concat",
      "c_crossattn",
      "c_adm"
    ]
  },
  "LatentUpscaleDiffusion": {
    "__init__": [
      "self"
    ],
    "instantiate_low_stage": [
      "self",
      "config"
    ],
    "get_input": [
      "self",
      "batch",
      "k",
      "cond_key",
      "bs",
      "log_mode"
    ],
    "log_images": [
      "self",
      "batch",
      "N",
      "n_row",
      "sample",
      "ddim_steps",
      "ddim_eta",
      "return_keys",
      "plot_denoise_rows",
      "plot_progressive_rows",
      "plot_diffusion_rows",
      "unconditional_guidance_scale",
      "unconditional_guidance_label",
      "use_ema_scope"
    ]
  },
  "LatentFinetuneDiffusion": {
    "__init__": [
      "self",
      "concat_keys",
      "finetune_keys",
      "keep_finetune_dims",
      "c_concat_log_start",
      "c_concat_log_end"
    ],
    "init_from_ckpt": [
      "self",
      "path",
      "ignore_keys",
      "only_model"
    ],
    "log_images": [
      "self",
      "batch",
      "N",
      "n_row",
      "sample",
      "ddim_steps",
      "ddim_eta",
      "return_keys",
      "quantize_denoised",
      "inpaint",
      "plot_denoise_rows",
      "plot_progressive_rows",
      "plot_diffusion_rows",
      "unconditional_guidance_scale",
      "unconditional_guidance_label",
      "use_ema_scope"
    ]
  },
  "LatentInpaintDiffusion": {
    "__init__": [
      "self",
      "concat_keys",
      "masked_image_key"
    ],
    "get_input": [
      "self",
      "batch",
      "k",
      "cond_key",
      "bs",
      "return_first_stage_outputs"
    ],
    "log_images": [
      "self"
    ]
  },
  "LatentDepth2ImageDiffusion": {
    "__init__": [
      "self",
      "depth_stage_config",
      "concat_keys"
    ],
    "get_input": [
      "self",
      "batch",
      "k",
      "cond_key",
      "bs",
      "return_first_stage_outputs"
    ],
    "log_images": [
      "self"
    ]
  },
  "LatentUpscaleFinetuneDiffusion": {
    "__init__": [
      "self",
      "concat_keys",
      "reshuffle_patch_size",
      "low_scale_config",
      "low_scale_key"
    ],
    "instantiate_low_stage": [
      "self",
      "config"
    ],
    "get_input": [
      "self",
      "batch",
      "k",
      "cond_key",
      "bs",
      "return_first_stage_outputs"
    ],
    "log_images": [
      "self"
    ]
  },
  "PLMSSampler": {
    "__init__": [
      "self",
      "model",
      "schedule"
    ],
    "register_buffer": [
      "self",
      "name",
      "attr"
    ],
    "make_schedule": [
      "self",
      "ddim_num_steps",
      "ddim_discretize",
      "ddim_eta",
      "verbose"
    ],
    "sample": [
      "self",
      "S",
      "batch_size",
      "shape",
      "conditioning",
      "callback",
      "normals_sequence",
      "img_callback",
      "quantize_x0",
      "eta",
      "mask",
      "x0",
      "temperature",
      "noise_dropout",
      "score_corrector",
      "corrector_kwargs",
      "verbose",
      "x_T",
      "log_every_t",
      "unconditional_guidance_scale",
      "unconditional_conditioning",
      "dynamic_threshold"
    ],
    "plms_sampling": [
      "self",
      "cond",
      "shape",
      "x_T",
      "ddim_use_original_steps",
      "callback",
      "timesteps",
      "quantize_denoised",
      "mask",
      "x0",
      "img_callback",
      "log_every_t",
      "temperature",
      "noise_dropout",
      "score_corrector",
      "corrector_kwargs",
      "unconditional_guidance_scale",
      "unconditional_conditioning",
      "dynamic_threshold"
    ],
    "p_sample_plms": [
      "self",
      "x",
      "c",
      "t",
      "index",
      "repeat_noise",
      "use_original_steps",
      "quantize_denoised",
      "temperature",
      "noise_dropout",
      "score_corrector",
      "corrector_kwargs",
      "unconditional_guidance_scale",
      "unconditional_conditioning",
      "old_eps",
      "t_next",
      "dynamic_threshold"
    ]
  },
  "DDIMSampler": {
    "__init__": [
      "self",
      "model",
      "schedule"
    ],
    "register_buffer": [
      "self",
      "name",
      "attr"
    ],
    "make_schedule": [
      "self",
      "ddim_num_steps",
      "ddim_discretize",
      "ddim_eta",
      "verbose"
    ],
    "sample": [
      "self",
      "S",
      "batch_size",
      "shape",
      "conditioning",
      "callback",
      "normals_sequence",
      "img_callback",
      "quantize_x0",
      "eta",
      "mask",
      "x0",
      "temperature",
      "noise_dropout",
      "score_corrector",
      "corrector_kwargs",
      "verbose",
      "x_T",
      "log_every_t",
      "unconditional_guidance_scale",
      "unconditional_conditioning",
      "dynamic_threshold",
      "ucg_schedule"
    ],
    "ddim_sampling": [
      "self",
      "cond",
      "shape",
      "x_T",
      "ddim_use_original_steps",
      "callback",
      "timesteps",
      "quantize_denoised",
      "mask",
      "x0",
      "img_callback",
      "log_every_t",
      "temperature",
      "noise_dropout",
      "score_corrector",
      "corrector_kwargs",
      "unconditional_guidance_scale",
      "unconditional_conditioning",
      "dynamic_threshold",
      "ucg_schedule"
    ],
    "p_sample_ddim": [
      "self",
      "x",
      "c",
      "t",
      "index",
      "repeat_noise",
      "use_original_steps",
      "quantize_denoised",
      "temperature",
      "noise_dropout",
      "score_corrector",
      "corrector_kwargs",
      "unconditional_guidance_scale",
      "unconditional_conditioning",
      "dynamic_threshold"
    ],
    "encode": [
      "self",
      "x0",
      "c",
      "t_enc",
      "use_original_steps",
      "return_intermediates",
      "unconditional_guidance_scale",
      "unconditional_conditioning",
      "callback"
    ],
    "stochastic_encode": [
      "self",
      "x0",
      "t",
      "use_original_steps",
      "noise"
    ],
    "decode": [
      "self",
      "x_latent",
      "cond",
      "t_start",
      "unconditional_guidance_scale",
      "unconditional_conditioning",
      "use_original_steps",
      "callback"
    ]
  },
  "_ATTN_PRECISION": [],
  "MemoryEfficientCrossAttention": {
    "__init__": [
      "self",
      "query_dim",
      "context_dim",
      "heads",
      "dim_head",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "context",
      "mask"
    ]
  },
  "LitEma": {
    "__init__": [
      "self",
      "model",
      "decay",
      "use_num_upates"
    ],
    "reset_num_updates": [
      "self"
    ],
    "forward": [
      "self",
      "model"
    ],
    "copy_to": [
      "self",
      "model"
    ],
    "store": [
      "self",
      "parameters"
    ],
    "restore": [
      "self",
      "parameters"
    ]
  },
  "LayerNormFp32": {
    "forward": [
      "self",
      "x"
    ]
  },
  "FrozenOpenCLIPEmbedder": {
    "LAYERS": [],
    "__init__": [
      "self",
      "arch",
      "version",
      "device",
      "max_length",
      "freeze",
      "layer"
    ],
    "freeze": [
      "self"
    ],
    "forward": [
      "self",
      "text"
    ],
    "encode_with_transformer": [
      "self",
      "text"
    ],
    "text_transformer_forward": [
      "self",
      "x",
      "attn_mask"
    ],
    "encode": [
      "self",
      "text"
    ]
  },
  "FrozenCLIPT5Encoder": {
    "__init__": [
      "self",
      "clip_version",
      "t5_version",
      "device",
      "clip_max_length",
      "t5_max_length"
    ],
    "encode": [
      "self",
      "text"
    ],
    "forward": [
      "self",
      "text"
    ]
  },
  "FrozenOpenCLIPImageEncoder": {
    "__init__": [
      "self",
      "arch",
      "version",
      "device",
      "freeze"
    ],
    "freeze": [
      "self"
    ],
    "forward": [
      "self",
      "image"
    ],
    "encode": [
      "self",
      "image"
    ]
  },
  "FrozenDinoV2Encoder": {
    "__init__": [
      "self",
      "model_path",
      "device",
      "freeze"
    ],
    "freeze": [
      "self"
    ],
    "forward": [
      "self",
      "image"
    ],
    "encode": [
      "self",
      "image"
    ]
  },
  "AbstractLowScaleModel": {
    "__init__": [
      "self",
      "noise_schedule_config"
    ],
    "register_schedule": [
      "self",
      "beta_schedule",
      "timesteps",
      "linear_start",
      "linear_end",
      "cosine_s"
    ],
    "q_sample": [
      "self",
      "x_start",
      "t",
      "noise"
    ],
    "forward": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "x"
    ]
  },
  "SimpleImageConcat": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ImageConcatWithNoiseAugmentation": {
    "__init__": [
      "self",
      "noise_schedule_config",
      "max_noise_level",
      "to_cuda"
    ],
    "forward": [
      "self",
      "x",
      "noise_level"
    ]
  },
  "MemoryEfficientAttnBlock": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MemoryEfficientCrossAttentionWrapper": {
    "forward": [
      "self",
      "x",
      "context",
      "mask"
    ]
  },
  "dependencies": [],
  "_DINOV2_BASE_URL": [],
  "_make_dinov2_model_name": [
    "arch_name",
    "patch_size"
  ],
  "_make_dinov2_model": [],
  "dinov2_vits14": [],
  "dinov2_vitb14": [],
  "dinov2_vitl14": [],
  "dinov2_vitg14": [],
  "_make_dinov2_linear_head": [],
  "_LinearClassifierWrapper": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_make_dinov2_linear_classifier": [],
  "dinov2_vits14_lc": [],
  "dinov2_vitb14_lc": [],
  "dinov2_vitl14_lc": [],
  "dinov2_vitg14_lc": [],
  "SwiGLUFFN": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "act_layer",
      "drop",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SwiGLUFFNFused": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "act_layer",
      "drop",
      "bias"
    ]
  },
  "MemEffAttention": {
    "forward": [
      "self",
      "x",
      "attn_bias"
    ]
  },
  "make_2tuple": [
    "x"
  ],
  "DINOHead": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "use_bn",
      "nlayers",
      "hidden_dim",
      "bottleneck_dim",
      "mlp_bias"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_build_mlp": [
    "nlayers",
    "in_dim",
    "bottleneck_dim",
    "hidden_dim",
    "use_bn",
    "bias"
  ],
  "drop_add_residual_stochastic_depth": [
    "x",
    "residual_func",
    "sample_drop_ratio"
  ],
  "get_branges_scales": [
    "x",
    "sample_drop_ratio"
  ],
  "add_residual": [
    "x",
    "brange",
    "residual",
    "residual_scale_factor",
    "scaling_vector"
  ],
  "get_attn_bias_and_cat": [
    "x_list",
    "branges"
  ],
  "drop_add_residual_stochastic_depth_list": [
    "x_list",
    "residual_func",
    "sample_drop_ratio",
    "scaling_vector"
  ],
  "NestedTensorBlock": {
    "forward_nested": [
      "self",
      "x_list"
    ],
    "forward": [
      "self",
      "x_or_x_list"
    ]
  },
  "BlockChunk": {
    "forward": [
      "self",
      "x"
    ]
  },
  "DinoVisionTransformer": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "in_chans",
      "embed_dim",
      "depth",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "ffn_bias",
      "proj_bias",
      "drop_path_rate",
      "drop_path_uniform",
      "init_values",
      "embed_layer",
      "act_layer",
      "block_fn",
      "ffn_layer",
      "block_chunks"
    ],
    "init_weights": [
      "self"
    ],
    "interpolate_pos_encoding": [
      "self",
      "x",
      "w",
      "h"
    ],
    "prepare_tokens_with_masks": [
      "self",
      "x",
      "masks"
    ],
    "forward_features_list": [
      "self",
      "x_list",
      "masks_list"
    ],
    "forward_features": [
      "self",
      "x",
      "masks"
    ],
    "_get_intermediate_layers_not_chunked": [
      "self",
      "x",
      "n"
    ],
    "_get_intermediate_layers_chunked": [
      "self",
      "x",
      "n"
    ],
    "get_intermediate_layers": [
      "self",
      "x",
      "n",
      "reshape",
      "return_class_token",
      "norm"
    ],
    "forward": [
      "self"
    ]
  },
  "vit_small": [
    "patch_size"
  ],
  "vit_base": [
    "patch_size"
  ],
  "vit_large": [
    "patch_size"
  ],
  "vit_giant2": [
    "patch_size"
  ],
  "build_model_from_cfg": [
    "cfg",
    "only_teacher"
  ],
  "get_shot_encoder": [
    "cfg"
  ],
  "get_contextual_relation_network": [
    "cfg"
  ],
  "MovieSceneSegmentationModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "inference": [
      "self",
      "batch"
    ],
    "shared_step": [
      "self",
      "inputs"
    ],
    "save_shot_feat": [
      "self",
      "_repr"
    ],
    "extract_shot_representation": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "get_batch_input": [
      "self",
      "shot_keyf_lst",
      "shot_start_idx",
      "shot_idx_lst"
    ],
    "preprocess": [
      "self",
      "inputs"
    ]
  },
  "get_pred_boundary": [
    "pred_dict",
    "threshold"
  ],
  "pred2scene": [
    "shot2keyf",
    "anno_dict"
  ],
  "scene2video": [
    "source_movie_fn",
    "scene_list",
    "thres"
  ],
  "get_demo_scene_list": [
    "shot2keyf",
    "anno_dict"
  ],
  "get_pair_list": [
    "anno_dict"
  ],
  "ShotEmbedding": {
    "__init__": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "shot_emb",
      "mask",
      "pos_ids"
    ]
  },
  "TransformerCRN": {
    "__init__": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "shot",
      "mask",
      "pos_ids",
      "pooling_method"
    ],
    "pooler": [
      "self",
      "sequence_output",
      "pooling_method"
    ],
    "_get_extended_attention_mask": [
      "self",
      "attention_mask"
    ]
  },
  "MlpHead": {
    "__init__": [
      "self",
      "input_dim",
      "hidden_dim",
      "output_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ProContEXT": {
    "__init__": [
      "self",
      "ckpt_path",
      "device",
      "cfg"
    ],
    "initialize": [
      "self",
      "image",
      "info"
    ],
    "track": [
      "self",
      "image",
      "info"
    ],
    "map_box_back": [
      "self",
      "pred_box",
      "resize_factor"
    ],
    "transform_bbox_to_crop": [
      "self",
      "box_in",
      "resize_factor",
      "device",
      "box_extract",
      "crop_type"
    ]
  },
  "OSTrack": {
    "__init__": [
      "self",
      "ckpt_path",
      "device"
    ],
    "initialize": [
      "self",
      "image",
      "info"
    ],
    "track": [
      "self",
      "image",
      "info"
    ],
    "map_box_back": [
      "self",
      "pred_box",
      "resize_factor"
    ],
    "transform_bbox_to_crop": [
      "self",
      "box_in",
      "resize_factor",
      "device",
      "box_extract",
      "crop_type"
    ]
  },
  "hann1d": [
    "sz",
    "centered"
  ],
  "hann2d": [
    "sz",
    "centered"
  ],
  "clip_box": [
    "box",
    "H",
    "W",
    "margin"
  ],
  "generate_mask_cond": [
    "cfg",
    "bs",
    "device",
    "gt_bbox"
  ],
  "sample_target": [
    "im",
    "target_bb",
    "search_area_factor",
    "output_sz",
    "mask"
  ],
  "transform_image_to_crop": [
    "box_in",
    "box_extract",
    "resize_factor",
    "crop_sz",
    "normalize"
  ],
  "check_box": [
    "box",
    "image_height",
    "image_width"
  ],
  "build_procontext": [
    "cfg"
  ],
  "VisionTransformerCE_ProContEXT": {
    "forward_features": [
      "self",
      "z",
      "x",
      "mask_x",
      "ce_template_mask",
      "ce_keep_rate"
    ],
    "forward": [
      "self",
      "z",
      "x",
      "ce_template_mask",
      "ce_keep_rate"
    ]
  },
  "_create_vision_transformer": [
    "pretrained"
  ],
  "vit_base_patch16_224_ce": [
    "pretrained"
  ],
  "combine_multi_tokens": [
    "template_tokens",
    "search_tokens",
    "mode"
  ],
  "candidate_elimination": [
    "attn",
    "tokens",
    "lens_t",
    "keep_ratio",
    "global_index",
    "box_mask_z"
  ],
  "CEBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "drop",
      "attn_drop",
      "drop_path",
      "act_layer",
      "norm_layer",
      "keep_ratio_search"
    ],
    "forward": [
      "self",
      "x",
      "global_index_template",
      "global_index_search",
      "mask",
      "ce_template_mask",
      "keep_ratio_search"
    ]
  },
  "CenterPredictor": {
    "__init__": [
      "self",
      "inplanes",
      "channel",
      "feat_sz",
      "stride"
    ],
    "forward": [
      "self",
      "x",
      "return_score"
    ],
    "cal_bbox": [
      "self",
      "score_map_ctr",
      "size_map",
      "offset_map",
      "return_score"
    ],
    "get_score_map": [
      "self",
      "x"
    ]
  },
  "build_box_head": [
    "cfg",
    "hidden_dim"
  ],
  "build_ostrack": [
    "cfg"
  ],
  "VisionTransformerCE": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "in_chans",
      "num_classes",
      "embed_dim",
      "depth",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "distilled",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "embed_layer",
      "norm_layer",
      "act_layer",
      "ce_loc",
      "ce_keep_ratio"
    ],
    "forward_features": [
      "self",
      "z",
      "x",
      "mask_x",
      "ce_template_mask",
      "ce_keep_rate"
    ],
    "forward": [
      "self",
      "z",
      "x",
      "ce_template_mask",
      "ce_keep_rate"
    ]
  },
  "combine_tokens": [
    "template_tokens",
    "search_tokens",
    "mode",
    "return_res"
  ],
  "recover_tokens": [
    "merged_tokens",
    "mode"
  ],
  "BaseBackbone": {
    "__init__": [
      "self"
    ],
    "finetune_track": [
      "self",
      "cfg",
      "patch_start_index"
    ]
  },
  "load_model_from_config": [
    "model",
    "config",
    "ckpt",
    "device",
    "verbose"
  ],
  "ImageViewTransform": {
    "__init__": [
      "self",
      "model_dir",
      "device"
    ],
    "forward": [
      "self",
      "model_path",
      "x",
      "y"
    ]
  },
  "sample_model": [
    "input_im",
    "model",
    "sampler",
    "precision",
    "h",
    "w",
    "ddim_steps",
    "n_samples",
    "scale",
    "ddim_eta",
    "x",
    "y",
    "z"
  ],
  "preprocess_image": [
    "models",
    "input_im",
    "preprocess",
    "carvekit_path"
  ],
  "main_run": [
    "models",
    "device",
    "return_what",
    "x",
    "y",
    "z",
    "raw_im",
    "carvekit_path",
    "preprocess",
    "scale",
    "n_samples",
    "ddim_steps",
    "ddim_eta",
    "precision",
    "h",
    "w"
  ],
  "_infer": [
    "genmodel",
    "model_path",
    "image_path",
    "target_view_path",
    "device"
  ],
  "renorm_thresholding": [
    "x0",
    "value"
  ],
  "Layout2ImgDiffusion": {
    "__init__": [
      "self",
      "cond_stage_key"
    ],
    "log_images": [
      "self",
      "batch",
      "N"
    ]
  },
  "SimpleUpscaleDiffusion": {
    "__init__": [
      "self"
    ],
    "get_input": [
      "self",
      "batch",
      "k",
      "cond_key",
      "bs",
      "log_mode"
    ],
    "log_images": [
      "self",
      "batch",
      "N",
      "n_row",
      "sample",
      "ddim_steps",
      "ddim_eta",
      "return_keys",
      "plot_denoise_rows",
      "plot_progressive_rows",
      "plot_diffusion_rows",
      "unconditional_guidance_scale",
      "unconditional_guidance_label",
      "use_ema_scope"
    ]
  },
  "MultiCatFrameDiffusion": {
    "__init__": [
      "self"
    ],
    "get_input": [
      "self",
      "batch",
      "k",
      "cond_key",
      "bs",
      "log_mode"
    ],
    "log_images": [
      "self",
      "batch",
      "N",
      "n_row",
      "sample",
      "ddim_steps",
      "ddim_eta",
      "return_keys",
      "plot_denoise_rows",
      "plot_progressive_rows",
      "plot_diffusion_rows",
      "unconditional_guidance_scale",
      "unconditional_guidance_label",
      "use_ema_scope"
    ]
  },
  "ResNet3d": {
    "__init__": [
      "self",
      "block",
      "layers",
      "num_classes",
      "zero_init_residual",
      "groups",
      "width_per_group",
      "replace_stride_with_dilation",
      "dropout",
      "inplanes",
      "first_stride",
      "norm_layer",
      "last_pool"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "blocks",
      "stride",
      "dilate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "resnet10_3d": [],
  "resnet26_3d": [],
  "resnet152_3d": [],
  "resnet200_3d": [],
  "C3D": {
    "__init__": [
      "self",
      "num_classes",
      "dropout",
      "inplanes",
      "norm_layer",
      "last_pool"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNet2p1d": {
    "__init__": [
      "self",
      "block",
      "layers",
      "num_classes",
      "zero_init_residual",
      "groups",
      "width_per_group",
      "replace_stride_with_dilation",
      "dropout",
      "inplanes",
      "first_stride",
      "norm_layer",
      "last_pool"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "blocks",
      "stride",
      "dilate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "resnet10_2p1d": [],
  "resnet18_2p1d": [],
  "resnet26_2p1d": [],
  "resnet34_2p1d": [],
  "resnet50_2p1d": [],
  "resnet101_2p1d": [],
  "resnet152_2p1d": [],
  "resnet200_2p1d": [],
  "RealBasicVSRNetForVideoSR": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_train_forward": [
      "self",
      "input",
      "target"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "_evaluate_postprocess": [
      "self",
      "input",
      "target"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "RealBasicVSRNet": {
    "__init__": [
      "self",
      "mid_channels",
      "num_propagation_blocks",
      "num_cleaning_blocks",
      "dynamic_refine_thres",
      "spynet_pretrained",
      "is_fix_cleaning",
      "is_sequential_cleaning"
    ],
    "forward": [
      "self",
      "lqs",
      "return_lqs"
    ]
  },
  "ResidualBlockNoBN": {
    "__init__": [
      "self",
      "mid_channels",
      "res_scale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PixelShufflePack": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "scale_factor",
      "upsample_kernel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "flow_warp": [
    "x",
    "flow",
    "interpolation",
    "padding_mode",
    "align_corners"
  ],
  "make_layer": [
    "block",
    "num_blocks"
  ],
  "charbonnier_loss": [
    "pred",
    "target",
    "eps"
  ],
  "MSRResNetLiteModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "ConvModule": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "act_cfg",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BasicVSRNet": {
    "__init__": [
      "self",
      "mid_channels",
      "num_blocks",
      "spynet_pretrained"
    ],
    "check_if_mirror_extended": [
      "self",
      "lrs"
    ],
    "compute_flow": [
      "self",
      "lrs"
    ],
    "forward": [
      "self",
      "lrs"
    ]
  },
  "ResidualBlocksWithInputConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_blocks"
    ],
    "forward": [
      "self",
      "feat"
    ]
  },
  "SPyNet": {
    "__init__": [
      "self",
      "pretrained"
    ],
    "compute_flow": [
      "self",
      "ref",
      "supp"
    ],
    "forward": [
      "self",
      "ref",
      "supp"
    ]
  },
  "SPyNetBasicModule": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "tensor_input"
    ]
  },
  "to8b": [
    "x"
  ],
  "NeRFRecon4K": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "load_existed_model": [
      "self"
    ],
    "nerf_reconstruction": [
      "self",
      "data_cfg",
      "render_dir"
    ],
    "render_viewpoints": [
      "self",
      "render_poses",
      "HW",
      "Ks",
      "render_kwargs",
      "gt_imgs",
      "savedir",
      "dump_images",
      "render_factor",
      "eval_ssim",
      "eval_lpips_alex",
      "eval_lpips_vgg"
    ]
  },
  "load_everything": [
    "cfg_data"
  ],
  "parent_dir": [],
  "parent_list": [],
  "render_utils_cuda": [],
  "DenseGrid": {
    "__init__": [
      "self",
      "channels",
      "world_size",
      "xyz_min",
      "xyz_max"
    ],
    "forward": [
      "self",
      "xyz"
    ],
    "scale_volume_grid": [
      "self",
      "new_world_size"
    ],
    "get_dense_grid": [
      "self"
    ],
    "__isub__": [
      "self",
      "val"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "MaskGrid": {
    "__init__": [
      "self",
      "path",
      "mask_cache_thres",
      "mask",
      "xyz_min",
      "xyz_max"
    ],
    "forward": [
      "self",
      "xyz"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "DirectVoxGO": {
    "__init__": [
      "self",
      "xyz_min",
      "xyz_max",
      "num_voxels",
      "num_voxels_base",
      "alpha_init",
      "mask_cache_path",
      "mask_cache_thres",
      "mask_cache_world_size",
      "fast_color_thres",
      "density_type",
      "k0_type",
      "density_config",
      "k0_config",
      "rgbnet_dim",
      "rgbnet_direct",
      "rgbnet_full_implicit",
      "rgbnet_depth",
      "rgbnet_width",
      "viewbase_pe"
    ],
    "_set_grid_resolution": [
      "self",
      "num_voxels"
    ],
    "get_kwargs": [
      "self"
    ],
    "maskout_near_cam_vox": [
      "self",
      "cam_o",
      "near_clip"
    ],
    "scale_volume_grid": [
      "self",
      "num_voxels"
    ],
    "update_occupancy_cache": [
      "self"
    ],
    "voxel_count_views": [
      "self",
      "rays_o_tr",
      "rays_d_tr",
      "imsz",
      "near",
      "far",
      "stepsize",
      "downrate",
      "irregular_shape"
    ],
    "activate_density": [
      "self",
      "density",
      "interval"
    ],
    "hit_coarse_geo": [
      "self",
      "rays_o",
      "rays_d",
      "near",
      "far",
      "stepsize"
    ],
    "sample_ray": [
      "self",
      "rays_o",
      "rays_d",
      "near",
      "far",
      "stepsize"
    ],
    "forward": [
      "self",
      "rays_o",
      "rays_d",
      "viewdirs",
      "global_step"
    ]
  },
  "DirectMPIGO": {
    "__init__": [
      "self",
      "xyz_min",
      "xyz_max",
      "num_voxels",
      "mpi_depth",
      "mask_cache_path",
      "mask_cache_thres",
      "mask_cache_world_size",
      "fast_color_thres",
      "density_type",
      "k0_type",
      "density_config",
      "k0_config",
      "rgbnet_dim",
      "rgbnet_depth",
      "rgbnet_width",
      "viewbase_pe",
      "spatial_pe"
    ],
    "_set_grid_resolution": [
      "self",
      "num_voxels",
      "mpi_depth"
    ],
    "get_kwargs": [
      "self"
    ],
    "scale_volume_grid": [
      "self",
      "num_voxels",
      "mpi_depth"
    ],
    "update_occupancy_cache": [
      "self"
    ],
    "update_occupancy_cache_lt_nviews": [
      "self",
      "rays_o_tr",
      "rays_d_tr",
      "imsz",
      "render_kwargs",
      "maskout_lt_nviews"
    ],
    "activate_density": [
      "self",
      "density",
      "interval"
    ],
    "sample_ray": [
      "self",
      "rays_o",
      "rays_d",
      "near",
      "far",
      "stepsize"
    ],
    "forward": [
      "self",
      "rays_o",
      "rays_d",
      "viewdirs",
      "global_step"
    ]
  },
  "create_full_step_id": [
    "shape"
  ],
  "Raw2Alpha": {
    "forward": [
      "ctx",
      "density",
      "shift",
      "interval"
    ],
    "backward": [
      "ctx",
      "grad_back"
    ]
  },
  "Raw2Alpha_nonuni": {
    "forward": [
      "ctx",
      "density",
      "shift",
      "interval"
    ],
    "backward": [
      "ctx",
      "grad_back"
    ]
  },
  "Alphas2Weights": {
    "forward": [
      "ctx",
      "alpha",
      "ray_id",
      "N"
    ],
    "backward": [
      "ctx",
      "grad_weights",
      "grad_last"
    ]
  },
  "get_rays_np": [
    "H",
    "W",
    "K",
    "c2w"
  ],
  "ndc_rays": [
    "H",
    "W",
    "focal",
    "near",
    "rays_o",
    "rays_d"
  ],
  "get_rays_of_a_view": [
    "H",
    "W",
    "K",
    "c2w",
    "ndc",
    "inverse_y",
    "flip_x",
    "flip_y",
    "mode"
  ],
  "get_training_rays": [
    "rgb_tr",
    "train_poses",
    "HW",
    "Ks",
    "ndc",
    "inverse_y",
    "flip_x",
    "flip_y"
  ],
  "get_training_rays_flatten": [
    "rgb_tr_ori",
    "train_poses",
    "HW",
    "Ks",
    "ndc",
    "inverse_y",
    "flip_x",
    "flip_y"
  ],
  "get_training_rays_in_maskcache_sampling": [
    "rgb_tr_ori",
    "train_poses",
    "HW",
    "Ks",
    "ndc",
    "inverse_y",
    "flip_x",
    "flip_y",
    "model",
    "render_kwargs"
  ],
  "get_training_rays_in_maskcache_sampling_sr": [
    "rgb_tr_ori",
    "train_poses",
    "HW",
    "Ks",
    "ndc",
    "inverse_y",
    "flip_x",
    "flip_y",
    "model",
    "render_kwargs",
    "cfgs"
  ],
  "batch_indices_generator": [
    "N",
    "BS"
  ],
  "batch_images_generator": [
    "N",
    "imsz",
    "BS"
  ],
  "simg_patch_indices_generator": [
    "imsz",
    "BS"
  ],
  "patch_gen": [
    "imsz",
    "num_im",
    "BS",
    "sz_patch"
  ],
  "mimg_patch_indices_generator": [
    "imsz",
    "num_im",
    "BS",
    "sz_patch",
    "sr_ratio"
  ],
  "SFTLayer": {
    "__init__": [
      "self",
      "num_feat",
      "num_grow_ch"
    ],
    "forward": [
      "self",
      "x",
      "cond"
    ]
  },
  "ResidualDenseBlock_SFT": {
    "__init__": [
      "self",
      "num_feat",
      "num_grow_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RRDB_SFT": {
    "__init__": [
      "self",
      "num_feat",
      "num_grow_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SFTNet": {
    "__init__": [
      "self",
      "n_in_colors",
      "scale",
      "num_feat",
      "num_block",
      "num_grow_ch",
      "num_cond",
      "dswise"
    ],
    "forward": [
      "self",
      "x",
      "cond",
      "fea"
    ],
    "tile_process": [
      "self",
      "img",
      "cond",
      "tile_size",
      "tile_pad"
    ],
    "load_network": [
      "self",
      "load_path",
      "device",
      "strict",
      "param_key"
    ],
    "_print_different_keys_loading": [
      "self",
      "load_net",
      "strict"
    ],
    "save_network": [
      "self",
      "save_root",
      "net_label",
      "current_iter",
      "param_key"
    ]
  },
  "load_tankstemple_data": [
    "basedir",
    "movie_render_kwargs"
  ],
  "trans_t": [
    "t"
  ],
  "rot_phi": [
    "phi"
  ],
  "rot_theta": [
    "th"
  ],
  "pose_spherical": [
    "theta",
    "phi",
    "radius"
  ],
  "load_blender_data": [
    "basedir",
    "half_res",
    "testskip"
  ],
  "inward_nearfar_heuristic": [
    "cam_o",
    "ratio"
  ],
  "imread": [
    "f"
  ],
  "depthread": [
    "path"
  ],
  "_minify": [
    "basedir",
    "factors",
    "resolutions"
  ],
  "_load_data": [
    "basedir",
    "factor",
    "width",
    "height",
    "load_imgs",
    "load_depths",
    "load_SR"
  ],
  "viewmatrix": [
    "z",
    "up",
    "pos"
  ],
  "ptstocam": [
    "pts",
    "c2w"
  ],
  "poses_avg": [
    "poses"
  ],
  "w2c_gen": [
    "poses"
  ],
  "render_path_spiral": [
    "c2w",
    "up",
    "rads",
    "focal",
    "zdelta",
    "zrate",
    "rots",
    "N"
  ],
  "recenter_poses": [
    "poses"
  ],
  "rerotate_poses": [
    "poses"
  ],
  "spherify_poses": [
    "poses",
    "bds",
    "depths"
  ],
  "load_llff_data": [
    "basedir",
    "factor",
    "width",
    "height",
    "recenter",
    "rerotate",
    "bd_factor",
    "spherify",
    "path_zflat",
    "load_depths",
    "load_SR",
    "movie_render_kwargs"
  ],
  "DenseOpticalFlowEstimation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "Inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "inference": [
      "self",
      "data"
    ]
  },
  "FlowDataset": {
    "__init__": [
      "self",
      "aug_params",
      "sparse"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__rmul__": [
      "self",
      "v"
    ],
    "__len__": [
      "self"
    ]
  },
  "MpiSintel": {
    "__init__": [
      "self",
      "aug_params",
      "split",
      "root",
      "dstype"
    ]
  },
  "FlyingChairs": {
    "__init__": [
      "self",
      "aug_params",
      "split",
      "root"
    ]
  },
  "FlyingThings3D": {
    "__init__": [
      "self",
      "aug_params",
      "root",
      "dstype"
    ]
  },
  "KITTI": {
    "__init__": [
      "self",
      "aug_params",
      "split",
      "root"
    ]
  },
  "HD1K": {
    "__init__": [
      "self",
      "aug_params",
      "root"
    ]
  },
  "fetch_dataloader": [
    "args",
    "TRAIN_DS"
  ],
  "FlowAugmentor": {
    "__init__": [
      "self",
      "crop_size",
      "min_scale",
      "max_scale",
      "do_flip"
    ],
    "color_transform": [
      "self",
      "img1",
      "img2"
    ],
    "eraser_transform": [
      "self",
      "img1",
      "img2",
      "bounds"
    ],
    "spatial_transform": [
      "self",
      "img1",
      "img2",
      "flow"
    ],
    "__call__": [
      "self",
      "img1",
      "img2",
      "flow"
    ]
  },
  "SparseFlowAugmentor": {
    "__init__": [
      "self",
      "crop_size",
      "min_scale",
      "max_scale",
      "do_flip"
    ],
    "color_transform": [
      "self",
      "img1",
      "img2"
    ],
    "eraser_transform": [
      "self",
      "img1",
      "img2"
    ],
    "resize_sparse_flow_map": [
      "self",
      "flow",
      "valid",
      "fx",
      "fy"
    ],
    "spatial_transform": [
      "self",
      "img1",
      "img2",
      "flow",
      "valid"
    ],
    "__call__": [
      "self",
      "img1",
      "img2",
      "flow",
      "valid"
    ]
  },
  "TAG_CHAR": [],
  "readFlow": [
    "fn"
  ],
  "readPFM": [
    "file"
  ],
  "writeFlow": [
    "filename",
    "uv",
    "v"
  ],
  "readFlowKITTI": [
    "filename"
  ],
  "readDispKITTI": [
    "filename"
  ],
  "writeFlowKITTI": [
    "filename",
    "uv"
  ],
  "read_gen": [
    "file_name",
    "pil"
  ],
  "ReferringVideoObjectSegmentation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "set_device": [
      "self",
      "device",
      "name"
    ],
    "set_postprocessor": [
      "self",
      "dataset_name"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "inference": [
      "self"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "set_criterion": [
      "self"
    ]
  },
  "PositionEmbeddingSine2D": {
    "__init__": [
      "self",
      "temperature",
      "normalize",
      "scale"
    ],
    "forward": [
      "self",
      "mask",
      "hidden_dim"
    ]
  },
  "get_window_size": [
    "x_size",
    "window_size",
    "shift_size"
  ],
  "WindowAttention3D": {
    "__init__": [
      "self",
      "dim",
      "window_size",
      "num_heads",
      "qkv_bias",
      "qk_scale",
      "attn_drop",
      "proj_drop"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "SwinTransformerBlock3D": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "window_size",
      "shift_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "drop_path",
      "act_layer",
      "norm_layer",
      "use_checkpoint"
    ],
    "forward_part1": [
      "self",
      "x",
      "mask_matrix"
    ],
    "forward_part2": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x",
      "mask_matrix"
    ]
  },
  "compute_mask": [
    "D",
    "H",
    "W",
    "window_size",
    "shift_size",
    "device"
  ],
  "PatchEmbed3D": {
    "__init__": [
      "self",
      "patch_size",
      "in_chans",
      "embed_dim",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SwinTransformer3D": {
    "__init__": [
      "self",
      "pretrained",
      "pretrained2d",
      "patch_size",
      "in_chans",
      "embed_dim",
      "depths",
      "num_heads",
      "window_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "norm_layer",
      "patch_norm",
      "frozen_stages",
      "use_checkpoint"
    ],
    "_freeze_stages": [
      "self"
    ],
    "inflate_weights": [
      "self",
      "logger"
    ],
    "forward": [
      "self",
      "x"
    ],
    "train": [
      "self",
      "mode"
    ]
  },
  "HungarianMatcher": {
    "__init__": [
      "self",
      "cost_is_referred",
      "cost_dice"
    ],
    "forward": [
      "self",
      "outputs",
      "targets"
    ]
  },
  "dice_coef": [
    "inputs",
    "targets",
    "smooth"
  ],
  "compute_is_referred_cost": [
    "outputs",
    "targets"
  ],
  "A2DSentencesPostProcess": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "outputs",
      "resized_padded_sample_size",
      "resized_sample_sizes",
      "orig_sample_sizes"
    ]
  },
  "ReferYoutubeVOSPostProcess": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "outputs",
      "videos_metadata",
      "samples_shape_with_padding"
    ]
  },
  "MultimodalTransformer": {
    "__init__": [
      "self",
      "num_encoder_layers",
      "num_decoder_layers",
      "text_encoder_type",
      "freeze_text_encoder",
      "transformer_cfg_dir"
    ],
    "_reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "vid_embeds",
      "vid_pad_mask",
      "text_queries",
      "obj_queries"
    ],
    "forward_text": [
      "self",
      "text_queries",
      "device"
    ],
    "num_parameters": [
      "self"
    ]
  },
  "TransformerEncoder": {
    "__init__": [
      "self",
      "encoder_layer",
      "num_layers",
      "norm"
    ],
    "forward": [
      "self",
      "src",
      "mask",
      "src_key_padding_mask",
      "pos"
    ]
  },
  "TransformerEncoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "nheads",
      "dim_feedforward",
      "dropout",
      "activation",
      "normalize_before"
    ],
    "with_pos_embed": [
      "self",
      "tensor",
      "pos"
    ],
    "forward_post": [
      "self",
      "src",
      "src_mask",
      "src_key_padding_mask",
      "pos"
    ],
    "forward_pre": [
      "self",
      "src",
      "src_mask",
      "src_key_padding_mask",
      "pos"
    ],
    "forward": [
      "self",
      "src",
      "src_mask",
      "src_key_padding_mask",
      "pos"
    ]
  },
  "TransformerDecoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "nheads",
      "dim_feedforward",
      "dropout",
      "activation",
      "normalize_before"
    ],
    "with_pos_embed": [
      "self",
      "tensor",
      "pos"
    ],
    "forward_post": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "tgt_key_padding_mask",
      "memory_key_padding_mask",
      "pos",
      "query_pos"
    ],
    "forward_pre": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "tgt_key_padding_mask",
      "memory_key_padding_mask",
      "pos",
      "query_pos"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "tgt_key_padding_mask",
      "memory_key_padding_mask",
      "pos",
      "query_pos"
    ]
  },
  "FeatureResizer": {
    "__init__": [
      "self",
      "input_feat_size",
      "output_feat_size",
      "dropout",
      "do_ln"
    ],
    "forward": [
      "self",
      "encoder_features"
    ]
  },
  "FPNSpatialDecoder": {
    "__init__": [
      "self",
      "context_dim",
      "fpn_dims",
      "mask_kernels_dim"
    ],
    "forward": [
      "self",
      "x",
      "layer_features"
    ],
    "num_parameters": [
      "self"
    ]
  },
  "dice_loss": [
    "inputs",
    "targets",
    "num_masks"
  ],
  "sigmoid_focal_loss": [
    "inputs",
    "targets",
    "num_masks",
    "alpha",
    "gamma"
  ],
  "SetCriterion": {
    "__init__": [
      "self",
      "matcher",
      "weight_dict",
      "eos_coef"
    ],
    "forward": [
      "self",
      "outputs",
      "targets"
    ],
    "compute_criterion": [
      "self",
      "outputs",
      "targets",
      "losses_to_compute"
    ],
    "loss_is_referred": [
      "self",
      "outputs",
      "targets",
      "indices"
    ],
    "loss_masks": [
      "self",
      "outputs",
      "targets",
      "indices",
      "num_masks"
    ],
    "_get_src_permutation_idx": [
      "indices"
    ],
    "_get_tgt_permutation_idx": [
      "indices"
    ],
    "_get_query_referred_indices": [
      "indices",
      "targets"
    ],
    "get_loss": [
      "self",
      "loss",
      "outputs",
      "targets",
      "indices"
    ]
  },
  "flatten_temporal_batch_dims": [
    "outputs",
    "targets"
  ],
  "reduce_dict": [
    "input_dict",
    "average"
  ],
  "nested_tensor_from_videos_list": [
    "videos_list"
  ],
  "setup_for_distributed": [
    "is_master"
  ],
  "is_dist_avail_and_initialized": [],
  "is_main_process": [],
  "save_on_master": [],
  "interpolate": [
    "input",
    "size",
    "scale_factor",
    "mode",
    "align_corners"
  ],
  "VideoSwinTransformerBackbone": {
    "__init__": [
      "self",
      "backbone_pretrained",
      "backbone_pretrained_path",
      "train_backbone",
      "running_mode"
    ],
    "forward": [
      "self",
      "samples"
    ],
    "num_parameters": [
      "self"
    ]
  },
  "FrozenBatchNorm2d": {
    "__init__": [
      "self",
      "n"
    ],
    "_load_from_state_dict": [
      "self",
      "state_dict",
      "prefix",
      "local_metadata",
      "strict",
      "missing_keys",
      "unexpected_keys",
      "error_msgs"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNetBackbone": {
    "__init__": [
      "self",
      "backbone_name",
      "train_backbone",
      "dilation"
    ],
    "forward": [
      "self",
      "tensor_list"
    ],
    "num_parameters": [
      "self"
    ]
  },
  "init_backbone": [
    "backbone_name"
  ],
  "MTTR": {
    "__init__": [
      "self",
      "num_queries",
      "mask_kernels_dim",
      "aux_loss",
      "transformer_cfg_dir"
    ],
    "forward": [
      "self",
      "samples",
      "valid_indices",
      "text_queries"
    ],
    "num_parameters": [
      "self"
    ]
  },
  "channel_shuffle": [
    "x",
    "groups"
  ],
  "ShuffleV2Block": {
    "__init__": [
      "self",
      "inp",
      "oup",
      "stride",
      "activation"
    ],
    "depthwise_conv": [
      "i",
      "o",
      "kernel_size",
      "stride",
      "padding",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ShuffleNetV2": {
    "__init__": [
      "self",
      "model_size",
      "out_stages",
      "with_last_conv",
      "kernal_size",
      "activation",
      "pretrain"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "hard_sigmoid": [
    "x",
    "inplace"
  ],
  "SqueezeExcite": {
    "__init__": [
      "self",
      "in_chs",
      "se_ratio",
      "reduced_base_chs",
      "activation",
      "gate_fn",
      "divisor"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GhostModule": {
    "__init__": [
      "self",
      "inp",
      "oup",
      "kernel_size",
      "ratio",
      "dw_size",
      "stride",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GhostBottleneck": {
    "__init__": [
      "self",
      "in_chs",
      "mid_chs",
      "out_chs",
      "dw_kernel_size",
      "stride",
      "activation",
      "se_ratio"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GhostBlocks": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "expand",
      "kernel_size",
      "num_blocks",
      "use_res",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GhostPAN": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "use_depthwise",
      "kernel_size",
      "expand",
      "num_blocks",
      "use_res",
      "num_extra_level",
      "upsample_cfg",
      "norm_cfg",
      "activation"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "act_layers": [
    "name"
  ],
  "norm_cfg": [],
  "build_norm_layer": [
    "cfg",
    "num_features",
    "postfix"
  ],
  "DepthwiseConvModule": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "norm_cfg",
      "activation",
      "inplace",
      "order"
    ],
    "forward": [
      "self",
      "x",
      "norm"
    ]
  },
  "OneStageDetector": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "inference": [
      "self",
      "meta"
    ]
  },
  "Integral": {
    "__init__": [
      "self",
      "reg_max"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "batched_nms": [
    "boxes",
    "scores",
    "idxs",
    "nms_cfg",
    "class_agnostic"
  ],
  "multiclass_nms": [
    "multi_bboxes",
    "multi_scores",
    "score_thr",
    "nms_cfg",
    "max_num",
    "score_factors"
  ],
  "distance2bbox": [
    "points",
    "distance",
    "max_shape"
  ],
  "warp_boxes": [
    "boxes",
    "M",
    "width",
    "height"
  ],
  "NanoDetPlusHead": {
    "__init__": [
      "self",
      "num_classes",
      "input_channel",
      "feat_channels",
      "stacked_convs",
      "kernel_size",
      "strides",
      "conv_type",
      "norm_cfg",
      "reg_max",
      "activation",
      "assigner_cfg"
    ],
    "_init_layers": [
      "self"
    ],
    "_buid_not_shared_head": [
      "self"
    ],
    "forward": [
      "self",
      "feats"
    ],
    "post_process": [
      "self",
      "preds",
      "meta"
    ],
    "get_bboxes": [
      "self",
      "cls_preds",
      "reg_preds",
      "img_metas"
    ],
    "get_single_level_center_priors": [
      "self",
      "batch_size",
      "featmap_size",
      "stride",
      "dtype",
      "device"
    ]
  },
  "load_model_weight": [
    "model_dir",
    "device"
  ],
  "NanoDetForFaceHumanHandDetection": {
    "__init__": [
      "self",
      "model_dir",
      "device_id"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "naive_collate": [
    "batch"
  ],
  "get_resize_matrix": [
    "raw_shape",
    "dst_shape"
  ],
  "color_aug_and_norm": [
    "meta",
    "mean",
    "std"
  ],
  "img_process": [
    "meta",
    "mean",
    "std"
  ],
  "overlay_bbox_cv": [
    "dets",
    "class_names",
    "score_thresh"
  ],
  "mean": [],
  "std": [],
  "class_names": [],
  "AbnormalDetectionModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "inference": [
      "self",
      "data"
    ],
    "preprocess": [
      "self",
      "image"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "MaskScoringNRoIHead": {
    "__init__": [
      "self",
      "mask_iou_head",
      "reg_roi_scale_factor"
    ],
    "_bbox_forward": [
      "self",
      "x",
      "rois"
    ],
    "_mask_forward_train": [
      "self",
      "x",
      "sampling_results",
      "bbox_feats",
      "gt_masks",
      "img_metas"
    ],
    "simple_test_mask": [
      "self",
      "x",
      "img_metas",
      "det_bboxes",
      "det_labels",
      "rescale"
    ]
  },
  "SingleRoINExtractor": {
    "__init__": [
      "self",
      "roi_layer",
      "out_channels",
      "featmap_strides",
      "finest_scale",
      "init_cfg",
      "gc_context",
      "offset_feature"
    ],
    "map_roi_levels": [
      "self",
      "rois",
      "num_levels"
    ],
    "forward": [
      "self",
      "feats",
      "rois",
      "roi_scale_factor"
    ]
  },
  "ImageFaceFusion": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "convert_state_dict": [
      "self",
      "state_dict"
    ],
    "image_transform": [
      "self",
      "image",
      "is_norm",
      "mean",
      "std"
    ],
    "extract_id": [
      "self",
      "np_source",
      "f5p"
    ],
    "detect_face": [
      "self",
      "img"
    ],
    "compute_3d_params": [
      "self",
      "Xs",
      "Xt"
    ],
    "process_enhance": [
      "self",
      "im",
      "f5p",
      "fh",
      "fw"
    ],
    "inference": [
      "self",
      "template_img",
      "user_img"
    ]
  },
  "_umeyama": [
    "src",
    "dst",
    "estimate_scale",
    "scale"
  ],
  "warp_and_crop_face_enhance": [
    "src_img",
    "facial_pts",
    "reference_pts",
    "crop_size",
    "align_type"
  ],
  "GPEN": {
    "__init__": [
      "self",
      "model_path",
      "size",
      "channel_multiplier",
      "device"
    ],
    "load_model": [
      "self",
      "channel_multiplier"
    ],
    "process": [
      "self",
      "im"
    ],
    "img2tensor": [
      "self",
      "img"
    ],
    "tensor2img": [
      "self",
      "image_tensor",
      "pmax",
      "imtype"
    ]
  },
  "isconcat": [],
  "ScaledLeakyReLU": {
    "__init__": [
      "self",
      "negative_slope"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "FullGenerator": {
    "__init__": [
      "self",
      "size",
      "style_dim",
      "n_mlp",
      "channel_multiplier",
      "blur_kernel",
      "lr_mlp",
      "narrow"
    ],
    "forward": [
      "self",
      "inputs",
      "return_latents",
      "inject_index",
      "truncation",
      "truncation_latent",
      "input_is_latent"
    ]
  },
  "FullGenerator_SR": {
    "__init__": [
      "self",
      "in_size",
      "out_size",
      "style_dim",
      "n_mlp",
      "channel_multiplier",
      "blur_kernel",
      "lr_mlp",
      "narrow"
    ],
    "forward": [
      "self",
      "inputs",
      "return_latents",
      "inject_index",
      "truncation",
      "truncation_latent",
      "input_is_latent"
    ]
  },
  "AADLayer": {
    "__init__": [
      "self",
      "c_x",
      "attr_c",
      "c_id"
    ],
    "forward": [
      "self",
      "h_in",
      "z_attr",
      "z_id"
    ]
  },
  "PositionalNorm2d": [
    "x",
    "epsilon"
  ],
  "AAD_ResBlk": {
    "__init__": [
      "self",
      "cin",
      "cout",
      "c_attr",
      "c_id"
    ],
    "forward": [
      "self",
      "h",
      "z_attr",
      "z_id"
    ]
  },
  "init_func": [
    "m",
    "init_type",
    "gain"
  ],
  "l2normalize": [
    "v",
    "eps"
  ],
  "SpectralNorm": {
    "__init__": [
      "self",
      "module",
      "name",
      "power_iterations"
    ],
    "_update_u_v": [
      "self"
    ],
    "_noupdate_u_v": [
      "self"
    ],
    "_make_params": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "convert_affinematrix_to_homography": [
    "A"
  ],
  "normal_transform_pixel": [
    "height",
    "width",
    "eps"
  ],
  "_torch_inverse_cast": [
    "input"
  ],
  "normalize_homography": [
    "dst_pix_trans_src_pix",
    "dsize_src",
    "dsize_dst"
  ],
  "warp_affine_torch": [
    "src",
    "M",
    "dsize",
    "mode",
    "padding_mode",
    "align_corners"
  ],
  "get_scheduler": [
    "optimizer",
    "opt"
  ],
  "Conv4x4": {
    "__init__": [
      "self",
      "in_c",
      "out_c"
    ],
    "forward": [
      "self",
      "feat"
    ]
  },
  "DeConv4x4": {
    "__init__": [
      "self",
      "in_c",
      "out_c"
    ],
    "forward": [
      "self",
      "input",
      "skip"
    ]
  },
  "MLAttrEncoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "Xt"
    ]
  },
  "AADGenerator": {
    "__init__": [
      "self",
      "c_id"
    ],
    "forward": [
      "self",
      "z_attr",
      "z_id",
      "deformation"
    ],
    "deform_input": [
      "self",
      "inp",
      "deformation"
    ]
  },
  "AEI_Net": {
    "__init__": [
      "self",
      "c_id",
      "num_kp",
      "device"
    ],
    "deform_input": [
      "self",
      "inp",
      "deformation"
    ],
    "flow_change": [
      "self",
      "x",
      "flow"
    ],
    "forward": [
      "self",
      "Xt",
      "z_id",
      "kp_fuse",
      "kp_t"
    ],
    "get_attr": [
      "self",
      "X"
    ]
  },
  "kp2gaussian": [
    "kp",
    "spatial_size",
    "kp_variance"
  ],
  "make_coordinate_grid": [
    "spatial_size",
    "type"
  ],
  "UpBlock2d": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "kernel_size",
      "padding",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DownBlock2d": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "kernel_size",
      "padding",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AntiAliasInterpolation2d": {
    "__init__": [
      "self",
      "channels",
      "scale"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "DenseMotionNetwork": {
    "__init__": [
      "self",
      "num_kp",
      "num_channels",
      "estimate_occlusion_map",
      "kp_variance"
    ],
    "create_heatmap_representations": [
      "self",
      "source_image",
      "kp_driving",
      "kp_source"
    ],
    "create_sparse_motions": [
      "self",
      "source_image",
      "kp_driving",
      "kp_source"
    ],
    "create_deformed_source_image": [
      "self",
      "source_image",
      "sparse_motions"
    ],
    "forward": [
      "self",
      "source_image",
      "kp_driving",
      "kp_source"
    ]
  },
  "BaseNetwork": {
    "__init__": [
      "self"
    ],
    "print_network": [
      "self"
    ],
    "init_weights": [
      "self",
      "init_type",
      "gain"
    ]
  },
  "VideoInpainting": {
    "__init__": [
      "self",
      "model_dir",
      "device_id"
    ]
  },
  "InpaintGenerator": {
    "__init__": [
      "self",
      "init_weights"
    ],
    "forward": [
      "self",
      "masked_frames",
      "masks"
    ],
    "infer": [
      "self",
      "feat",
      "masks"
    ]
  },
  "deconv": {
    "__init__": [
      "self",
      "input_channel",
      "output_channel",
      "kernel_size",
      "padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MultiHeadedAttention": {
    "__init__": [
      "self",
      "patchsize",
      "d_model"
    ],
    "forward": [
      "self",
      "x",
      "m",
      "b",
      "c"
    ]
  },
  "TransformerBlock": {
    "__init__": [
      "self",
      "patchsize",
      "hidden"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ref_length": [],
  "neighbor_stride": [],
  "default_fps": [],
  "MAX_frame": [],
  "video_process": [
    "video_input_path"
  ],
  "Stack": {
    "__init__": [
      "self",
      "roll"
    ],
    "__call__": [
      "self",
      "img_group"
    ]
  },
  "ToTorchFormatTensor": {
    "__init__": [
      "self",
      "div"
    ],
    "__call__": [
      "self",
      "pic"
    ]
  },
  "_to_tensors": [],
  "get_crop_mask_v1": [
    "mask"
  ],
  "get_ref_index": [
    "neighbor_ids",
    "length"
  ],
  "read_mask_oneImage": [
    "mpath"
  ],
  "check_size": [
    "h",
    "w"
  ],
  "get_mask_list": [
    "mask_path"
  ],
  "inpainting_by_model_balance": [
    "model",
    "video_inputPath",
    "mask_path",
    "video_savePath",
    "fps",
    "w_ori",
    "h_ori"
  ],
  "BaseVideoModel": {
    "__init__": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BaseHead": {
    "__init__": [
      "self",
      "cfg"
    ],
    "_construct_head": [
      "self",
      "dim",
      "num_classes",
      "dropout_rate",
      "activation_func"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AvgHead": {
    "__init__": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "normal_init": [
    "module",
    "mean",
    "std",
    "bias"
  ],
  "PatchShift": {
    "__init__": [
      "self",
      "inv",
      "ratio"
    ],
    "forward": [
      "self",
      "x",
      "batch_size",
      "frame_len"
    ],
    "shift": [
      "x",
      "inv",
      "ratio",
      "batch_size",
      "frame_len"
    ]
  },
  "TemporalShift": {
    "__init__": [
      "self",
      "n_div"
    ],
    "forward": [
      "self",
      "x",
      "batch_size",
      "frame_len"
    ],
    "shift": [
      "x",
      "fold_div",
      "batch_size",
      "frame_len"
    ]
  },
  "SwinTransformer2D_TPS": {
    "__init__": [
      "self",
      "pretrained",
      "pretrained2d",
      "patch_size",
      "in_chans",
      "embed_dim",
      "depths",
      "num_heads",
      "window_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "norm_layer",
      "patch_norm",
      "frozen_stages",
      "use_checkpoint"
    ],
    "_freeze_stages": [
      "self"
    ],
    "inflate_weights": [
      "self"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ],
    "forward": [
      "self",
      "x"
    ],
    "train": [
      "self",
      "mode"
    ]
  },
  "top_k_accuracy": [
    "scores",
    "labels",
    "topk"
  ],
  "I3DHead": {
    "__init__": [
      "self",
      "num_classes",
      "in_channels",
      "loss_cls",
      "spatial_type",
      "dropout_ratio",
      "init_std"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PatchShiftTransformer": {
    "__init__": [
      "self",
      "model_dir",
      "num_classes",
      "depths",
      "num_heads",
      "embed_dim",
      "in_channels",
      "pretrained"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InceptionBaseConv3D": {
    "__init__": [
      "self",
      "cfg",
      "in_planes",
      "out_planes",
      "kernel_size",
      "stride",
      "padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InceptionBlock3D": {
    "__init__": [
      "self",
      "cfg",
      "in_planes",
      "out_planes"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SelfGating": {
    "__init__": [
      "self",
      "input_dim"
    ],
    "forward": [
      "self",
      "input_tensor"
    ]
  },
  "STConv3d": {
    "__init__": [
      "self",
      "cfg",
      "in_planes",
      "out_planes",
      "kernel_size",
      "stride",
      "padding"
    ],
    "_construct_branch": [
      "self",
      "cfg",
      "in_planes",
      "out_planes",
      "kernel_size",
      "stride",
      "t_stride",
      "padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Inception3D": {
    "__init__": [
      "self",
      "cfg"
    ],
    "_construct_backbone": [
      "self",
      "cfg",
      "input_channel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TadaConvNeXt": {
    "__init__": [
      "self",
      "cfg"
    ],
    "forward_features": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_num_layers": [
      "self"
    ]
  },
  "ConvNeXtBlock": {
    "__init__": [
      "self",
      "cfg",
      "dim",
      "drop_path",
      "layer_scale_init_value"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TAdaConvNeXtBlock": {
    "__init__": [
      "self",
      "cfg",
      "dim",
      "drop_path",
      "layer_scale_init_value"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RouteFuncMLPLnGelu": {
    "__init__": [
      "self",
      "c_in",
      "ratio",
      "kernels",
      "with_bias_cal",
      "bn_eps",
      "bn_mmt"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TAdaConv2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "cal_dim"
    ],
    "forward": [
      "self",
      "x",
      "alpha"
    ],
    "__repr__": [
      "self"
    ]
  },
  "CLIPResNet": {
    "__init__": [
      "self",
      "layers",
      "output_dim",
      "input_resolution",
      "width",
      "pretrained"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ],
    "_make_layer": [
      "self",
      "planes",
      "blocks",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CLIPResNetWithAttention": {
    "__init__": [
      "self",
      "layers",
      "output_dim",
      "input_resolution",
      "width",
      "pretrained"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ],
    "_make_layer": [
      "self",
      "planes",
      "blocks",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CLIPVisionTransformer": {
    "__init__": [
      "self",
      "input_resolution",
      "patch_size",
      "width",
      "layers",
      "heads",
      "output_dim",
      "drop_path_rate",
      "out_indices",
      "pretrained",
      "get_embeddings"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CLIPTextEncoder": {
    "__init__": [
      "self",
      "context_length",
      "vocab_size",
      "transformer_width",
      "transformer_heads",
      "transformer_layers",
      "embed_dim",
      "out_dim",
      "pretrained"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ],
    "build_attention_mask": [
      "self"
    ],
    "forward": [
      "self",
      "text"
    ]
  },
  "CLIPTextContextEncoder": {
    "__init__": [
      "self",
      "context_length",
      "vocab_size",
      "transformer_width",
      "transformer_heads",
      "transformer_layers",
      "embed_dim",
      "out_dim",
      "pretrained"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ],
    "build_attention_mask": [
      "self"
    ],
    "forward": [
      "self",
      "text",
      "context"
    ]
  },
  "ContextDecoder": {
    "__init__": [
      "self",
      "transformer_width",
      "transformer_heads",
      "transformer_layers",
      "visual_dim",
      "dropout"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "forward": [
      "self",
      "text",
      "visual"
    ]
  },
  "FPNHead": {
    "__init__": [
      "self",
      "channels",
      "num_classes",
      "dropout_ratio",
      "feature_strides",
      "align_corners"
    ],
    "_transform_inputs": [
      "self",
      "inputs"
    ],
    "cls_seg": [
      "self",
      "feat"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "_init_weights": [
      "self",
      "m"
    ]
  },
  "ShopSegmentation": {
    "__init__": [
      "self",
      "model_dir",
      "device_id"
    ],
    "preprocess": [
      "self",
      "img",
      "size"
    ],
    "postprocess": [
      "self",
      "tensors",
      "crop_h",
      "crop_w",
      "ori_h",
      "ori_w"
    ],
    "forward": [
      "self",
      "image"
    ],
    "inference": [
      "self",
      "image"
    ]
  },
  "SHOPSEG": {
    "__init__": [
      "self",
      "model_dir",
      "context_length",
      "context_feature",
      "score_concat_index",
      "tau",
      "token_embed_dim",
      "text_dim"
    ],
    "encode_text": [
      "self",
      "text",
      "context_length"
    ],
    "extract_feat": [
      "self",
      "img"
    ],
    "after_extract_feat": [
      "self",
      "x",
      "name_list"
    ],
    "forward": [
      "self",
      "img",
      "text_list"
    ]
  },
  "RealtimeVideoDetector": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "inference": [
      "self",
      "img"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "preprocess": [
      "self",
      "img"
    ],
    "postprocess": [
      "self",
      "input"
    ],
    "inference_video": [
      "self",
      "v_path"
    ],
    "inference_video_iter": [
      "self",
      "v_path"
    ]
  },
  "_TORCH_VER": [],
  "meshgrid": [],
  "xyxy2xywh": [
    "bboxes"
  ],
  "xyxy2cxcywh": [
    "bboxes"
  ],
  "postprocess": [
    "prediction",
    "num_classes",
    "conf_thre",
    "nms_thre",
    "class_agnostic"
  ],
  "bboxes_iou": [
    "bboxes_a",
    "bboxes_b",
    "xyxy"
  ],
  "preproc": [
    "img",
    "input_size",
    "swap"
  ],
  "ValTransform": {
    "__init__": [
      "self",
      "swap",
      "legacy"
    ],
    "__call__": [
      "self",
      "img",
      "res",
      "input_size"
    ]
  },
  "Exp": {
    "__init__": [
      "self"
    ],
    "get_model": [
      "self"
    ]
  },
  "get_exp_by_name": [
    "exp_name"
  ],
  "BaseExp": {
    "get_model": [
      "self"
    ]
  },
  "StreamYoloExp": {
    "__init__": [
      "self"
    ],
    "get_model": [
      "self"
    ]
  },
  "TALHead": {
    "__init__": [
      "self",
      "num_classes",
      "width",
      "strides",
      "in_channels",
      "act",
      "depthwise",
      "gamma",
      "ignore_thr",
      "ignore_value"
    ],
    "forward": [
      "self",
      "xin",
      "labels",
      "imgs"
    ],
    "decode_outputs": [
      "self",
      "outputs",
      "dtype"
    ]
  },
  "Darknet": {
    "depth2blocks": [],
    "__init__": [
      "self",
      "depth",
      "in_channels",
      "stem_out_channels",
      "out_features"
    ],
    "make_group_layer": [
      "self",
      "in_channels",
      "num_blocks",
      "stride"
    ],
    "make_spp_block": [
      "self",
      "filters_list",
      "in_filters"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CSPDarknet": {
    "__init__": [
      "self",
      "dep_mul",
      "wid_mul",
      "out_features",
      "depthwise",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DFPPAFPN": {
    "__init__": [
      "self",
      "depth",
      "width",
      "in_features",
      "in_channels",
      "depthwise",
      "act"
    ],
    "off_forward": [
      "self",
      "input"
    ],
    "online_forward": [
      "self",
      "input",
      "buffer",
      "node"
    ],
    "forward": [
      "self",
      "input",
      "buffer",
      "mode"
    ]
  },
  "BaseConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "ksize",
      "stride",
      "groups",
      "bias",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ],
    "fuseforward": [
      "self",
      "x"
    ]
  },
  "DWConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "ksize",
      "stride",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResLayer": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SPPBottleneck": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_sizes",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CSPLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "n",
      "shortcut",
      "expansion",
      "depthwise",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Focus": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "ksize",
      "stride",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StreamYOLO": {
    "__init__": [
      "self",
      "backbone",
      "head"
    ],
    "forward": [
      "self",
      "x",
      "targets",
      "buffer",
      "mode"
    ]
  },
  "NAFNetForImageDenoise": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_train_forward": [
      "self",
      "input",
      "target"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "_evaluate_postprocess": [
      "self",
      "input",
      "target"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "SimpleGate": {
    "forward": [
      "self",
      "x"
    ]
  },
  "NAFBlock": {
    "__init__": [
      "self",
      "c",
      "DW_Expand",
      "FFN_Expand",
      "drop_out_rate"
    ],
    "forward": [
      "self",
      "inp"
    ]
  },
  "NAFNet": {
    "__init__": [
      "self",
      "img_channel",
      "width",
      "middle_blk_num",
      "enc_blk_nums",
      "dec_blk_nums"
    ],
    "forward": [
      "self",
      "inp"
    ],
    "check_image_size": [
      "self",
      "x"
    ]
  },
  "PSNRLoss": {
    "__init__": [
      "self",
      "loss_weight",
      "reduction",
      "toY"
    ],
    "forward": [
      "self",
      "pred",
      "target"
    ]
  },
  "LayerNormFunction": {
    "forward": [
      "ctx",
      "x",
      "weight",
      "bias",
      "eps"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "LayerNorm2d": {
    "__init__": [
      "self",
      "channels",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "sinusoidal_embedding": [
    "timesteps",
    "dim"
  ],
  "Resample": {
    "__init__": [
      "self",
      "scale_factor"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GLU": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "kl_divergence": [
    "mu1",
    "logvar1",
    "mu2",
    "logvar2"
  ],
  "standard_normal_cdf": [
    "x"
  ],
  "discretized_gaussian_log_likelihood": [
    "x0",
    "mean",
    "log_scale"
  ],
  "_i": [
    "tensor",
    "t",
    "x"
  ],
  "beta_schedule": [
    "schedule",
    "num_timesteps",
    "init_beta",
    "last_beta"
  ],
  "GaussianDiffusion": {
    "__init__": [
      "self",
      "betas",
      "mean_type",
      "var_type",
      "loss_type",
      "rescale_timesteps"
    ],
    "q_sample": [
      "self",
      "x0",
      "t",
      "noise"
    ],
    "q_mean_variance": [
      "self",
      "x0",
      "t"
    ],
    "q_posterior_mean_variance": [
      "self",
      "x0",
      "xt",
      "t"
    ],
    "p_sample": [
      "self",
      "xt",
      "t",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "condition_fn",
      "guide_scale"
    ],
    "p_sample_loop": [
      "self",
      "noise",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "condition_fn",
      "guide_scale"
    ],
    "p_mean_variance": [
      "self",
      "xt",
      "t",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "guide_scale"
    ],
    "ddim_sample": [
      "self",
      "xt",
      "t",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "condition_fn",
      "guide_scale",
      "ddim_timesteps",
      "eta"
    ],
    "ddim_sample_loop": [
      "self",
      "noise",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "condition_fn",
      "guide_scale",
      "ddim_timesteps",
      "eta"
    ],
    "ddim_reverse_sample": [
      "self",
      "xt",
      "t",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "guide_scale",
      "ddim_timesteps"
    ],
    "ddim_reverse_sample_loop": [
      "self",
      "x0",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "guide_scale",
      "ddim_timesteps"
    ],
    "plms_sample": [
      "self",
      "xt",
      "t",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "condition_fn",
      "guide_scale",
      "plms_timesteps"
    ],
    "plms_sample_loop": [
      "self",
      "noise",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "condition_fn",
      "guide_scale",
      "plms_timesteps"
    ],
    "loss": [
      "self",
      "x0",
      "t",
      "model",
      "model_kwargs",
      "noise"
    ],
    "variational_lower_bound": [
      "self",
      "x0",
      "xt",
      "t",
      "model",
      "model_kwargs",
      "clamp",
      "percentile"
    ],
    "variational_lower_bound_loop": [
      "self",
      "x0",
      "model",
      "model_kwargs",
      "clamp",
      "percentile"
    ],
    "_scale_timesteps": [
      "self",
      "t"
    ]
  },
  "PadToSquare": {
    "__init__": [
      "self",
      "fill"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "RandomScale": {
    "__init__": [
      "self",
      "min_scale",
      "max_scale",
      "min_ratio",
      "max_ratio"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "RandomRotate": {
    "__init__": [
      "self",
      "min_angle",
      "max_angle",
      "padding",
      "p"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "RandomGaussianBlur": {
    "__init__": [
      "self",
      "radius",
      "p"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "to_fp16": [
    "m"
  ],
  "SelfAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "attn_dropout",
      "proj_dropout"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "TextTransformer": {
    "__init__": [
      "self",
      "vocab_size",
      "text_len",
      "dim",
      "out_dim",
      "num_heads",
      "num_layers",
      "attn_dropout",
      "proj_dropout",
      "embedding_dropout"
    ],
    "forward": [
      "self",
      "x"
    ],
    "fp16": [
      "self"
    ]
  },
  "clip_vit_b_32": [],
  "clip_vit_b_16": [],
  "clip_vit_l_14": [],
  "clip_vit_l_14_336px": [],
  "clip_vit_h_16": [],
  "group_norm": [
    "dim"
  ],
  "VectorQuantizer": {
    "__init__": [
      "self",
      "codebook_size",
      "z_dim",
      "beta"
    ],
    "forward": [
      "self",
      "z"
    ]
  },
  "VQAutoencoder": {
    "__init__": [
      "self",
      "dim",
      "z_dim",
      "dim_mult",
      "num_res_blocks",
      "attn_scales",
      "dropout",
      "codebook_size",
      "beta"
    ],
    "forward": [
      "self",
      "x"
    ],
    "encode": [
      "self",
      "imgs"
    ],
    "decode": [
      "self",
      "z"
    ],
    "encode_to_tokens": [
      "self",
      "imgs"
    ],
    "decode_from_tokens": [
      "self",
      "tokens"
    ]
  },
  "KLAutoencoder": {
    "__init__": [
      "self",
      "dim",
      "z_dim",
      "dim_mult",
      "num_res_blocks",
      "attn_scales",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "z"
    ],
    "reparameterize": [
      "self",
      "mu",
      "log_var"
    ]
  },
  "PatchDiscriminator": {
    "__init__": [
      "self",
      "in_dim",
      "dim",
      "num_layers"
    ],
    "forward": [
      "self",
      "x"
    ],
    "init_weights": [
      "self",
      "m"
    ]
  },
  "depthwise_clipseg_conv": {
    "__init__": [
      "self"
    ],
    "depthwise_clipseg": [
      "self",
      "x",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "depthwise_conv": {
    "__init__": [
      "self",
      "kernel_size",
      "stride",
      "padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "depthwise_block": {
    "__init__": [
      "self",
      "kernel_size",
      "stride",
      "padding",
      "activation"
    ],
    "forward": [
      "self",
      "x",
      "act"
    ]
  },
  "bottleneck_block": {
    "__init__": [
      "self",
      "kernel_size",
      "stride",
      "padding",
      "activation"
    ],
    "forward": [
      "self",
      "x",
      "act"
    ]
  },
  "LSeg": {
    "__init__": [
      "self",
      "features",
      "backbone",
      "readout",
      "use_bn",
      "model_dir"
    ],
    "forward": [
      "self",
      "x",
      "labelset"
    ]
  },
  "get_attention": [
    "name"
  ],
  "get_mean_attention_map": [
    "attn",
    "token",
    "shape"
  ],
  "_make_pretrained_clip_vitl16_384": [
    "pretrained",
    "use_readout",
    "hooks",
    "enable_attention_hooks"
  ],
  "TextDrivenSeg": {
    "__init__": [
      "self",
      "model_dir",
      "device_id"
    ],
    "preprocess": [
      "self",
      "img",
      "size"
    ],
    "postprocess": [
      "self",
      "tensors",
      "crop_h",
      "crop_w",
      "ori_h",
      "ori_w"
    ],
    "forward": [
      "self",
      "image",
      "text"
    ],
    "inference": [
      "self",
      "image",
      "text"
    ]
  },
  "TextDrivenSegmentation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "img",
      "txt_list"
    ]
  },
  "OpenVocabularyDetectionViLD": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self"
    ],
    "forward": [
      "self",
      "img",
      "category_names"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "_build_text_embedings": [
      "self",
      "categories"
    ]
  },
  "multiple_templates": [],
  "ImagePortraitEnhancement": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "load_pretrained": [
      "self",
      "model_dir"
    ],
    "accumulate": [
      "self"
    ],
    "requires_grad": [
      "self",
      "model",
      "flag"
    ],
    "d_logistic_loss": [
      "self",
      "real_pred",
      "fake_pred"
    ],
    "d_r1_loss": [
      "self",
      "real_pred",
      "real_img"
    ],
    "g_nonsaturating_loss": [
      "self",
      "fake_pred",
      "fake_img",
      "real_img",
      "input_img"
    ],
    "g_path_regularize": [
      "self",
      "fake_img",
      "latents",
      "mean_path_length",
      "decay"
    ],
    "_evaluate_postprocess": [
      "self",
      "input",
      "target"
    ],
    "_train_forward_d": [
      "self",
      "input",
      "target"
    ],
    "_train_forward_d_r1": [
      "self",
      "input",
      "target"
    ],
    "_train_forward_g": [
      "self",
      "input",
      "target"
    ],
    "_train_forward_g_path": [
      "self",
      "input",
      "target"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "get_params": [
    "reference_pts",
    "facial_pts",
    "align_type"
  ],
  "L1Loss": {
    "__init__": [
      "self",
      "loss_weight",
      "reduction"
    ],
    "forward": [
      "self",
      "pred",
      "target",
      "weight"
    ]
  },
  "IDLoss": {
    "__init__": [
      "self",
      "model_path",
      "device",
      "ckpt_dict"
    ],
    "extract_feats": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "y_hat",
      "y",
      "x"
    ]
  },
  "PriorBox": {
    "__init__": [
      "self",
      "cfg",
      "image_size",
      "phase"
    ],
    "forward": [
      "self"
    ]
  },
  "py_cpu_nms": [
    "dets",
    "thresh"
  ],
  "cfg_re50": [],
  "RetinaFaceDetection": {
    "__init__": [
      "self",
      "model_path",
      "device"
    ],
    "check_keys": [
      "self",
      "pretrained_state_dict"
    ],
    "remove_prefix": [
      "self",
      "state_dict",
      "prefix"
    ],
    "load_model": [
      "self",
      "load_to_cpu"
    ],
    "detect": [
      "self",
      "img_raw",
      "resize",
      "confidence_threshold",
      "nms_threshold",
      "top_k",
      "keep_top_k",
      "save_image"
    ],
    "detect_tensor": [
      "self",
      "img",
      "resize",
      "confidence_threshold",
      "nms_threshold",
      "top_k",
      "keep_top_k",
      "save_image"
    ]
  },
  "MobileNetV1": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BottleNeck_IR": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel",
      "stride",
      "dim_match"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "channel_list": [],
  "get_layers": [
    "num_layers"
  ],
  "FaceQuality": {
    "__init__": [
      "self",
      "feature_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FQA": {
    "__init__": [
      "self",
      "backbone_path",
      "quality_path",
      "device",
      "size"
    ],
    "load_model": [
      "self",
      "backbone_path",
      "quality_path"
    ],
    "load_state_dict": [
      "self",
      "model",
      "state_dict"
    ],
    "get_face_quality": [
      "self",
      "img"
    ]
  },
  "FacialExpressionRecognition": {
    "__init__": [
      "self",
      "model_path",
      "device"
    ],
    "load_model": [
      "self",
      "load_to_cpu"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "five_crop": [
    "img",
    "size"
  ],
  "TenCrop": {
    "__init__": [
      "self",
      "size",
      "vertical_flip"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "VGG": {
    "__init__": [
      "self",
      "vgg_name",
      "cfg_path"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_make_layers": [
      "self",
      "cfg"
    ]
  },
  "VisionMiddlewareModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "inputs",
      "task_name"
    ],
    "forward": [
      "self",
      "inputs",
      "task_name"
    ],
    "postprocess": [
      "self",
      "outputs",
      "inputs",
      "task_name"
    ],
    "get_tasks": [
      "self"
    ]
  },
  "model_dict": [],
  "LinearClassifier": {
    "__init__": [
      "self",
      "in_channels",
      "num_classes"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BaseDecodeHead": {
    "__init__": [
      "self",
      "in_channels",
      "channels"
    ],
    "extra_repr": [
      "self"
    ],
    "_init_inputs": [
      "self",
      "in_channels",
      "in_index",
      "input_transform"
    ],
    "_transform_inputs": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "forward_train": [
      "self",
      "inputs",
      "img_metas",
      "gt_semantic_seg",
      "train_cfg"
    ],
    "forward_test": [
      "self",
      "inputs",
      "img_metas",
      "test_cfg"
    ],
    "cls_seg": [
      "self",
      "feat"
    ]
  },
  "FPNSegmentor": {
    "__init__": [
      "self",
      "fpn_layer_indices",
      "neck_cfg",
      "head_cfg"
    ],
    "show_result": [
      "self",
      "img",
      "result",
      "palette",
      "win_name",
      "show",
      "wait_time",
      "out_file",
      "opacity"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_agg_conv1d": [
    "weight_list",
    "bias_list",
    "agg",
    "x"
  ],
  "_agg_conv2d": [
    "weight_list",
    "bias_list",
    "agg",
    "x"
  ],
  "ViM": {
    "__init__": [
      "self"
    ],
    "register_ViM": [
      "self",
      "vim_list"
    ],
    "register_task": [
      "self",
      "task_name",
      "agg_weights",
      "agg_algo"
    ],
    "forward": [
      "self",
      "x",
      "task_name"
    ],
    "forward_ens_moe": [
      "self",
      "x",
      "agg"
    ]
  },
  "DUTRAFTStabilizer": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "Smoother": {
    "__init__": [
      "self",
      "inplanes",
      "embeddingSize",
      "hiddenSize",
      "kernel"
    ],
    "forward": [
      "self",
      "trajectory"
    ],
    "inference": [
      "self",
      "x_paths",
      "y_paths",
      "repeat"
    ],
    "KernelSmooth": [
      "self",
      "kernel",
      "path",
      "repeat"
    ]
  },
  "__C": [],
  "RFDetModule": {
    "__init__": [
      "self",
      "score_com_strength",
      "scale_com_strength",
      "nms_thresh",
      "nms_ksize",
      "topk",
      "gauss_ksize",
      "gauss_sigma",
      "ksize",
      "padding",
      "dilation",
      "scale_list"
    ],
    "forward": [
      "self"
    ],
    "process": [
      "self",
      "im1w_score"
    ],
    "weights_init": [
      "m"
    ]
  },
  "KeypointDetction": {
    "__init__": [
      "self",
      "RFDetPath",
      "topK",
      "detectorType"
    ],
    "forward": [
      "self",
      "im_data"
    ]
  },
  "RFDetection": {
    "__init__": [
      "self",
      "RFDetPath",
      "topK"
    ],
    "forward": [
      "self",
      "im_data",
      "batch",
      "allInfer"
    ],
    "reload": [
      "self",
      "RFDetPath"
    ]
  },
  "MotionEstimation": {
    "__init__": [
      "self",
      "args",
      "RAFTPath"
    ],
    "forward": [
      "self",
      "x",
      "x_RGB",
      "im_topk",
      "kpts"
    ],
    "reload": [
      "self",
      "RAFTPath"
    ]
  },
  "KLT": {
    "__init__": [
      "self",
      "RAFTPath"
    ],
    "forward": [
      "self",
      "x",
      "x_RGB",
      "im_topk",
      "kpts"
    ]
  },
  "motionPropagate": {
    "__init__": [
      "self",
      "inferenceMethod"
    ]
  },
  "JacobiSolver": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DUT": {
    "__init__": [
      "self",
      "SmootherPath",
      "RFDetPath",
      "RAFTPath",
      "MotionProPath",
      "homo",
      "args"
    ],
    "forward": [
      "self",
      "x",
      "x_RGB",
      "repeat"
    ],
    "inference": [
      "self",
      "x",
      "x_RGB",
      "repeat"
    ],
    "reload": [
      "self",
      "SmootherPath",
      "RFDetPath",
      "RAFTPath",
      "MotionProPath"
    ]
  },
  "RFDetSO": {
    "__init__": [
      "self",
      "score_com_strength",
      "scale_com_strength",
      "nms_thresh",
      "nms_ksize",
      "topk",
      "gauss_ksize",
      "gauss_sigma",
      "ksize",
      "padding",
      "dilation",
      "scale_list"
    ],
    "forward": [
      "self",
      "photos"
    ],
    "convO_init": [
      "m"
    ]
  },
  "MotionPro": {
    "__init__": [
      "self",
      "inplanes",
      "embeddingSize",
      "hiddenSize",
      "number_points",
      "kernel",
      "globalchoice"
    ],
    "forward": [
      "self",
      "motion"
    ],
    "inference": [
      "self",
      "x_flow",
      "y_flow",
      "kp"
    ]
  },
  "mesh_warp_frame": [
    "frame",
    "x_motion",
    "y_motion",
    "cap_width",
    "cap_height"
  ],
  "warpListImage": [
    "images",
    "x_motion",
    "y_motion",
    "cap_width",
    "cap_height"
  ],
  "gauss": [
    "t",
    "r",
    "window_size"
  ],
  "generateSmooth": [
    "originPath",
    "kernel",
    "repeat"
  ],
  "distance_matrix_vector": [
    "anchor",
    "positive"
  ],
  "pairwise_distances": [
    "x",
    "y"
  ],
  "ptCltoCr": [
    "leftC",
    "homolr",
    "right_imscale",
    "right_imorint",
    "clamp"
  ],
  "L2Norm": [
    "input",
    "dim"
  ],
  "MSD": [
    "x",
    "y"
  ],
  "MedianPool2d": {
    "__init__": [
      "self",
      "kernel_size",
      "stride",
      "padding",
      "same"
    ],
    "_padding": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SingleMotionPropagate": [
    "x_flow",
    "y_flow",
    "pts"
  ],
  "MultiMotionPropagate": [
    "x_flow",
    "y_flow",
    "pts"
  ],
  "HomoCalc": [
    "grids",
    "new_grids_loc"
  ],
  "HomoProj": [
    "homo",
    "pts"
  ],
  "multiHomoEstimate": [
    "motion",
    "kp"
  ],
  "singleHomoEstimate": [
    "motion",
    "kp"
  ],
  "f_rot": [
    "x"
  ],
  "MotionDistanceMeasure": [
    "motion1",
    "motion2"
  ],
  "clip_patch": [
    "kpts_byxc",
    "kpts_scale",
    "kpts_ori",
    "im_info",
    "images",
    "PSIZE"
  ],
  "filtbordmask": [
    "imscore",
    "radius"
  ],
  "filter_border": [
    "imscore",
    "radius"
  ],
  "topk_map": [
    "maps",
    "k"
  ],
  "get_gauss_filter_weight": [
    "ksize",
    "sig"
  ],
  "soft_nms_3d": [
    "scale_logits",
    "ksize",
    "com_strength"
  ],
  "soft_max_and_argmax_1d": [
    "input",
    "orint_maps",
    "scale_list",
    "com_strength1",
    "com_strength2",
    "dim",
    "keepdim"
  ],
  "im_rescale": [
    "im",
    "output_size"
  ],
  "SalientDetection": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "inference": [
      "self",
      "data"
    ],
    "preprocess": [
      "self",
      "image"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "CBAM": {
    "__init__": [
      "self",
      "inchs",
      "kernel_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SENet": {
    "__init__": [
      "self",
      "backbone_path",
      "pretrained"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "REBNCONV": {
    "__init__": [
      "self",
      "in_ch",
      "out_ch",
      "dirate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_upsample_like": [
    "src",
    "tar"
  ],
  "RSU7": {
    "__init__": [
      "self",
      "in_ch",
      "mid_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RSU6": {
    "__init__": [
      "self",
      "in_ch",
      "mid_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RSU5": {
    "__init__": [
      "self",
      "in_ch",
      "mid_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RSU4": {
    "__init__": [
      "self",
      "in_ch",
      "mid_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RSU4F": {
    "__init__": [
      "self",
      "in_ch",
      "mid_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "U2NET": {
    "__init__": [
      "self",
      "in_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AreaLayer": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel"
    ],
    "forward": [
      "self",
      "xl",
      "xh"
    ]
  },
  "EdgeLayer": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel"
    ],
    "forward": [
      "self",
      "xl",
      "xh"
    ]
  },
  "EBlock": {
    "__init__": [
      "self",
      "inchs",
      "outchs"
    ],
    "forward": [
      "self",
      "x",
      "edgeAtten"
    ]
  },
  "StructureE": {
    "__init__": [
      "self",
      "inchs",
      "outchs",
      "EM"
    ],
    "forward": [
      "self",
      "x",
      "edgeAtten"
    ]
  },
  "ABlock": {
    "__init__": [
      "self",
      "inchs",
      "outchs",
      "k"
    ],
    "forward": [
      "self",
      "x",
      "areaAtten"
    ]
  },
  "AMFusion": {
    "__init__": [
      "self",
      "inchs",
      "outchs",
      "AM"
    ],
    "forward": [
      "self",
      "xl",
      "xh",
      "xhm"
    ]
  },
  "Bottle2neck": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "baseWidth",
      "scale",
      "stype"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Res2Net": {
    "__init__": [
      "self",
      "block",
      "layers",
      "baseWidth",
      "scale",
      "num_classes"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "blocks",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "res2net50_v1b_26w_4s": [
    "backbone_path",
    "pretrained"
  ],
  "mse2psnr": [
    "x"
  ],
  "visualize_depth_numpy": [
    "depth",
    "minmax",
    "cmap"
  ],
  "init_log": [
    "log",
    "keys"
  ],
  "visualize_depth": [
    "depth",
    "minmax",
    "cmap"
  ],
  "N_to_reso": [
    "n_voxels",
    "bbox"
  ],
  "cal_n_samples": [
    "reso",
    "step_ratio"
  ],
  "__LPIPS__": [],
  "init_lpips": [
    "net_name",
    "device"
  ],
  "rgb_lpips": [
    "np_gt",
    "np_im",
    "net_name",
    "device"
  ],
  "findItem": [
    "items",
    "target"
  ],
  "rgb_ssim": [
    "img0",
    "img1",
    "max_val",
    "filter_size",
    "filter_sigma",
    "k1",
    "k2",
    "return_map"
  ],
  "convert_sdf_samples_to_ply": [
    "pytorch_3d_sdf_tensor",
    "ply_filename_out",
    "bbox",
    "level",
    "offset",
    "scale"
  ],
  "Timing": {
    "__init__": [
      "self",
      "name",
      "debug"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "type",
      "value",
      "traceback"
    ]
  },
  "NeRFReconVQCompression": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "evaluation": [
      "self",
      "render_dir",
      "N_vis"
    ],
    "render_path": [
      "self",
      "render_dir",
      "N_vis"
    ],
    "get_render_pose": [
      "self",
      "N_cameras"
    ]
  },
  "OctreeRender_trilinear_fast": [
    "rays",
    "tensorf",
    "chunk",
    "N_samples",
    "ndc_ray",
    "white_bg",
    "is_train",
    "device"
  ],
  "evaluation": [
    "test_dataset",
    "tensorf",
    "renderer",
    "savePath",
    "N_vis",
    "prtx",
    "N_samples",
    "white_bg",
    "ndc_ray",
    "compute_extra_metrics",
    "device",
    "im_save"
  ],
  "render_path": [
    "test_dataset",
    "tensorf",
    "c2ws",
    "renderer",
    "savePath",
    "prtx",
    "N_samples",
    "white_bg",
    "ndc_ray",
    "device"
  ],
  "TensorVM": {
    "__init__": [
      "self",
      "aabb",
      "gridSize",
      "device"
    ],
    "init_svd_volume": [
      "self",
      "res",
      "device"
    ],
    "get_optparam_groups": [
      "self",
      "lr_init_spatialxyz",
      "lr_init_network"
    ],
    "compute_features": [
      "self",
      "xyz_sampled"
    ],
    "compute_densityfeature": [
      "self",
      "xyz_sampled"
    ],
    "compute_appfeature": [
      "self",
      "xyz_sampled"
    ],
    "vectorDiffs": [
      "self",
      "vector_comps"
    ],
    "vector_comp_diffs": [
      "self"
    ],
    "up_sampling_VM": [
      "self",
      "plane_coef",
      "line_coef",
      "res_target"
    ],
    "upsample_volume_grid": [
      "self",
      "res_target"
    ]
  },
  "TensorVMSplit": {
    "__init__": [
      "self",
      "aabb",
      "gridSize",
      "device"
    ],
    "init_svd_volume": [
      "self",
      "res",
      "device"
    ],
    "init_one_svd": [
      "self",
      "n_component",
      "gridSize",
      "scale",
      "device"
    ],
    "get_optparam_groups": [
      "self",
      "lr_init_spatialxyz",
      "lr_init_network"
    ],
    "vectorDiffs": [
      "self",
      "vector_comps"
    ],
    "vector_comp_diffs": [
      "self"
    ],
    "density_L1": [
      "self"
    ],
    "TV_loss_density": [
      "self",
      "reg"
    ],
    "TV_loss_app": [
      "self",
      "reg"
    ],
    "compute_densityfeature": [
      "self",
      "xyz_sampled"
    ],
    "compute_appfeature": [
      "self",
      "xyz_sampled"
    ],
    "up_sampling_VM": [
      "self",
      "plane_coef",
      "line_coef",
      "res_target"
    ],
    "upsample_volume_grid": [
      "self",
      "res_target"
    ],
    "shrink": [
      "self",
      "new_aabb"
    ]
  },
  "TensorCP": {
    "__init__": [
      "self",
      "aabb",
      "gridSize",
      "device"
    ],
    "init_svd_volume": [
      "self",
      "res",
      "device"
    ],
    "init_one_svd": [
      "self",
      "n_component",
      "gridSize",
      "scale",
      "device"
    ],
    "get_optparam_groups": [
      "self",
      "lr_init_spatialxyz",
      "lr_init_network"
    ],
    "compute_densityfeature": [
      "self",
      "xyz_sampled"
    ],
    "compute_appfeature": [
      "self",
      "xyz_sampled"
    ],
    "up_sampling_Vector": [
      "self",
      "density_line_coef",
      "app_line_coef",
      "res_target"
    ],
    "upsample_volume_grid": [
      "self",
      "res_target"
    ],
    "shrink": [
      "self",
      "new_aabb"
    ],
    "density_L1": [
      "self"
    ],
    "TV_loss_density": [
      "self",
      "reg"
    ],
    "TV_loss_app": [
      "self",
      "reg"
    ]
  },
  "dec2bin": [
    "x",
    "bits"
  ],
  "bin2dec": [
    "b",
    "bits"
  ],
  "TensorVMSplitVQ": {
    "__init__": [
      "self",
      "aabb",
      "gridSize",
      "device"
    ],
    "extreme_load": [
      "self",
      "ckpt"
    ],
    "forward": [
      "self",
      "rays_chunk",
      "white_bg",
      "is_train",
      "ndc_ray",
      "N_samples",
      "isvq"
    ]
  },
  "getsize": [
    "compressed_file",
    "tag"
  ],
  "noop": [],
  "l2norm": [
    "t"
  ],
  "log": [
    "t",
    "eps"
  ],
  "uniform_init": [],
  "gumbel_noise": [
    "t"
  ],
  "gumbel_sample": [
    "t",
    "temperature",
    "dim"
  ],
  "ema_inplace": [
    "moving_avg",
    "new",
    "decay"
  ],
  "laplace_smoothing": [
    "x",
    "n_categories",
    "eps"
  ],
  "sample_vectors": [
    "samples",
    "num"
  ],
  "batched_sample_vectors": [
    "samples",
    "num"
  ],
  "pad_shape": [
    "shape",
    "size",
    "dim"
  ],
  "sample_multinomial": [
    "total_count",
    "probs"
  ],
  "all_gather_sizes": [
    "x",
    "dim"
  ],
  "all_gather_variably_sized": [
    "x",
    "sizes",
    "dim"
  ],
  "sample_vectors_distributed": [
    "local_samples",
    "num"
  ],
  "batched_bincount": [
    "x"
  ],
  "kmeans": [
    "samples",
    "num_clusters",
    "num_iters",
    "use_cosine_sim",
    "sample_fn",
    "all_reduce_fn"
  ],
  "batched_embedding": [
    "indices",
    "embeds"
  ],
  "orthogonal_loss_fn": [
    "t"
  ],
  "EuclideanCodebook": {
    "__init__": [
      "self",
      "dim",
      "codebook_size",
      "num_codebooks",
      "kmeans_init",
      "kmeans_iters",
      "decay",
      "eps",
      "threshold_ema_dead_code",
      "use_ddp",
      "learnable_codebook",
      "sample_codebook_temp"
    ],
    "init_embed_": [
      "self",
      "data"
    ],
    "replace": [
      "self",
      "batch_samples",
      "batch_mask"
    ],
    "expire_codes_": [
      "self",
      "batch_samples",
      "verbose"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "verbose"
    ]
  },
  "VectorQuantize": {
    "__init__": [
      "self",
      "dim",
      "codebook_size",
      "codebook_dim",
      "heads",
      "separate_codebook_per_head",
      "decay",
      "eps",
      "kmeans_init",
      "kmeans_iters",
      "use_cosine_sim",
      "threshold_ema_dead_code",
      "channel_last",
      "accept_image_fmap",
      "commitment_weight",
      "orthogonal_reg_weight",
      "orthogonal_reg_active_codes_only",
      "orthogonal_reg_max_codes",
      "sample_codebook_temp",
      "sync_codebook"
    ],
    "codebook": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "weight",
      "verbose"
    ]
  },
  "positional_encoding": [
    "positions",
    "freqs"
  ],
  "raw2alpha": [
    "sigma",
    "dist"
  ],
  "RGBRender": [
    "xyz_sampled",
    "viewdirs",
    "features"
  ],
  "AlphaGridMask": {
    "__init__": [
      "self",
      "device",
      "aabb",
      "alpha_volume"
    ],
    "sample_alpha": [
      "self",
      "xyz_sampled"
    ],
    "normalize_coord": [
      "self",
      "xyz_sampled"
    ]
  },
  "MLPRender_Fea": {
    "__init__": [
      "self",
      "inChanel",
      "viewpe",
      "feape",
      "featureC"
    ],
    "forward": [
      "self",
      "pts",
      "viewdirs",
      "features"
    ]
  },
  "MLPRender_PE": {
    "__init__": [
      "self",
      "inChanel",
      "viewpe",
      "pospe",
      "featureC"
    ],
    "forward": [
      "self",
      "pts",
      "viewdirs",
      "features"
    ]
  },
  "MLPRender": {
    "__init__": [
      "self",
      "inChanel",
      "viewpe",
      "featureC"
    ],
    "forward": [
      "self",
      "pts",
      "viewdirs",
      "features"
    ]
  },
  "TensorBase": {
    "__init__": [
      "self",
      "aabb",
      "gridSize",
      "device",
      "density_n_comp",
      "appearance_n_comp",
      "app_dim",
      "shadingMode",
      "alphaMask",
      "near_far",
      "density_shift",
      "alphaMask_thres",
      "distance_scale",
      "rayMarch_weight_thres",
      "pos_pe",
      "view_pe",
      "fea_pe",
      "featureC",
      "step_ratio",
      "fea2denseAct"
    ],
    "init_render_func": [
      "self",
      "shadingMode",
      "pos_pe",
      "view_pe",
      "fea_pe",
      "featureC",
      "device"
    ],
    "update_stepSize": [
      "self",
      "gridSize"
    ],
    "init_svd_volume": [
      "self",
      "res",
      "device"
    ],
    "compute_features": [
      "self",
      "xyz_sampled"
    ],
    "compute_densityfeature": [
      "self",
      "xyz_sampled"
    ],
    "compute_appfeature": [
      "self",
      "xyz_sampled"
    ],
    "normalize_coord": [
      "self",
      "xyz_sampled"
    ],
    "get_optparam_groups": [
      "self",
      "lr_init_spatial",
      "lr_init_network"
    ],
    "get_kwargs": [
      "self"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "ckpt"
    ],
    "sample_ray_ndc": [
      "self",
      "rays_o",
      "rays_d",
      "is_train",
      "N_samples"
    ],
    "sample_ray": [
      "self",
      "rays_o",
      "rays_d",
      "is_train",
      "N_samples"
    ],
    "shrink": [
      "self",
      "new_aabb",
      "voxel_size"
    ],
    "getDenseAlpha": [
      "self",
      "gridSize"
    ],
    "updateAlphaMask": [
      "self",
      "gridSize"
    ],
    "filtering_rays": [
      "self",
      "all_rays",
      "all_rgbs",
      "N_samples",
      "chunk",
      "bbox_only"
    ],
    "feature2density": [
      "self",
      "density_features"
    ],
    "compute_alpha": [
      "self",
      "xyz_locs",
      "length"
    ],
    "forward": [
      "self",
      "rays_chunk",
      "white_bg",
      "is_train",
      "ndc_ray",
      "N_samples"
    ]
  },
  "circle": [
    "radius",
    "h",
    "axis",
    "t0",
    "r"
  ],
  "cross": [
    "x",
    "y",
    "axis"
  ],
  "cat": [
    "x",
    "axis"
  ],
  "look_at_rotation": [
    "camera_position",
    "at",
    "up",
    "inverse",
    "cv"
  ],
  "gen_path": [
    "pos_gen",
    "at",
    "up",
    "frames"
  ],
  "TanksTempleDataset": {
    "__init__": [
      "self",
      "datadir",
      "split",
      "downsample",
      "wh",
      "is_stack"
    ],
    "bbox2corners": [
      "self"
    ],
    "read_meta": [
      "self"
    ],
    "define_transforms": [
      "self"
    ],
    "define_proj_mat": [
      "self"
    ],
    "world2ndc": [
      "self",
      "points"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "NSVF": {
    "__init__": [
      "self",
      "datadir",
      "split",
      "downsample",
      "wh",
      "is_stack"
    ],
    "bbox2corners": [
      "self"
    ],
    "read_meta": [
      "self"
    ],
    "define_transforms": [
      "self"
    ],
    "define_proj_mat": [
      "self"
    ],
    "world2ndc": [
      "self",
      "points"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "average_poses": [
    "poses"
  ],
  "center_poses": [
    "poses",
    "blender2opencv"
  ],
  "get_spiral": [
    "c2ws_all",
    "near_fars",
    "rads_scale",
    "N_views"
  ],
  "LLFFDataset": {
    "__init__": [
      "self",
      "datadir",
      "split",
      "downsample",
      "is_stack",
      "hold_every"
    ],
    "read_meta": [
      "self"
    ],
    "define_transforms": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "get_render_pose": [
      "self",
      "N_cameras"
    ]
  },
  "dataset_dict": [],
  "depth2dist": [
    "z_vals",
    "cos_angle"
  ],
  "ndc2dist": [
    "ndc_pts",
    "cos_angle"
  ],
  "get_ray_directions_blender": [
    "H",
    "W",
    "focal",
    "center"
  ],
  "ndc_rays_blender": [
    "H",
    "W",
    "focal",
    "near",
    "rays_o",
    "rays_d"
  ],
  "dda": [
    "rays_o",
    "rays_d",
    "bbox_3D"
  ],
  "ray_marcher": [
    "rays",
    "N_samples",
    "lindisp",
    "perturb",
    "bbox_3D"
  ],
  "ndc_bbox": [
    "all_rays"
  ],
  "map_idx": [],
  "img_size": [],
  "spatial_transform": [],
  "HandStatic": {
    "__init__": [
      "self",
      "model_dir",
      "device_id"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StaticGestureNet": {
    "__init__": [
      "self",
      "train"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "BottleneckIR": {
    "__init__": [
      "self",
      "in_channel",
      "depth",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BottleneckIRSE": {
    "__init__": [
      "self",
      "in_channel",
      "depth",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LinearBlock": {
    "__init__": [
      "self",
      "in_c",
      "out_c",
      "kernel",
      "stride",
      "padding",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DepthWise": {
    "__init__": [
      "self",
      "in_c",
      "out_c",
      "residual",
      "kernel",
      "stride",
      "padding",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MobileFaceNet": {
    "__init__": [
      "self",
      "embedding_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OmnidataNormalEstimation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "inference": [
      "self",
      "data"
    ]
  },
  "BasicConv": {
    "__init__": [
      "self",
      "in_planes",
      "out_planes",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ChannelGate": {
    "__init__": [
      "self",
      "gate_channels",
      "reduction_ratio",
      "pool_types"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ChannelPool": {
    "forward": [
      "self",
      "x"
    ]
  },
  "SpatialGate": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MemoryReader": {
    "__init__": [
      "self"
    ],
    "get_affinity": [
      "self",
      "mk",
      "qk"
    ],
    "readout": [
      "self",
      "affinity",
      "mv",
      "qv"
    ]
  },
  "RDE_VOS": {
    "__init__": [
      "self",
      "single_object",
      "repeat",
      "norm"
    ],
    "aggregate": [
      "self",
      "prob"
    ],
    "encode_key": [
      "self",
      "frame"
    ],
    "encode_value": [
      "self",
      "frame",
      "kf16",
      "mask",
      "other_mask"
    ],
    "segment": [
      "self",
      "qk16",
      "qv16",
      "qf8",
      "qf4",
      "mk16",
      "mv16",
      "selector"
    ],
    "memCrompress": [
      "self",
      "key",
      "value"
    ],
    "forward": [
      "self",
      "mode"
    ]
  },
  "VideoObjectSegmentation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "load_weights_sequential": [
    "target",
    "source_state",
    "extra_chan"
  ],
  "pad_divide_by": [
    "in_img",
    "d",
    "in_size"
  ],
  "InferenceCore": {
    "__init__": [
      "self",
      "prop_net",
      "is_cuda",
      "images",
      "num_objects",
      "top_k",
      "mem_every",
      "include_last"
    ],
    "encode_key": [
      "self",
      "idx"
    ],
    "do_pass": [
      "self",
      "first_k",
      "first_v",
      "idx",
      "end_idx"
    ],
    "interact": [
      "self",
      "mask",
      "frame_idx",
      "end_idx"
    ]
  },
  "aggregate": [
    "prob",
    "keep_bg"
  ],
  "softmax_w_top": [
    "x",
    "top"
  ],
  "make_gaussian": [
    "y_idx",
    "x_idx",
    "height",
    "width",
    "sigma"
  ],
  "kmn": [
    "x",
    "top",
    "gauss"
  ],
  "MemoryBank": {
    "__init__": [
      "self",
      "compress",
      "k",
      "top_k",
      "mode"
    ],
    "init_mode": [
      "self",
      "mode"
    ],
    "_global_matching": [
      "self",
      "mk",
      "qk",
      "H",
      "W"
    ],
    "_readout": [
      "self",
      "affinity",
      "mv"
    ],
    "match_memory": [
      "self",
      "qk"
    ],
    "add_memory": [
      "self",
      "key",
      "value",
      "is_temp"
    ]
  },
  "ValueEncoderSO": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "image",
      "key_f16",
      "mask"
    ]
  },
  "ValueEncoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "image",
      "key_f16",
      "mask",
      "other_masks"
    ]
  },
  "KeyEncoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "f"
    ]
  },
  "UpsampleBlock": {
    "__init__": [
      "self",
      "skip_c",
      "up_c",
      "out_c",
      "scale_factor"
    ],
    "forward": [
      "self",
      "skip_f",
      "up_f"
    ]
  },
  "KeyProjection": {
    "__init__": [
      "self",
      "indim",
      "keydim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_NonLocalBlockND": {
    "__init__": [
      "self",
      "in_channels",
      "inter_channels",
      "dimension",
      "sub_sample",
      "bn_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NONLocalBlock1D": {
    "__init__": [
      "self",
      "in_channels",
      "inter_channels",
      "sub_sample",
      "bn_layer"
    ]
  },
  "NONLocalBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "inter_channels",
      "sub_sample",
      "bn_layer"
    ]
  },
  "NONLocalBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "inter_channels",
      "sub_sample",
      "bn_layer"
    ]
  },
  "_ASPPModule3D": {
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "kernel_size",
      "padding",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ASPP3D": {
    "__init__": [
      "self",
      "in_plane",
      "out_plane",
      "reduction"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SELayerS": {
    "__init__": [
      "self",
      "channel",
      "reduction"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SEBasicBlock": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "reduction"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SAM": {
    "__init__": [
      "self",
      "indim",
      "outdim",
      "repeat",
      "norm"
    ],
    "seRepeat": [
      "self",
      "repeat"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MemCrompress": {
    "__init__": [
      "self",
      "repeat",
      "norm"
    ],
    "forward": [
      "self",
      "key",
      "value"
    ]
  },
  "ECBSRModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "SeqConv3x3": {
    "__init__": [
      "self",
      "seq_type",
      "inp_planes",
      "out_planes",
      "depth_multiplier"
    ],
    "forward": [
      "self",
      "x"
    ],
    "rep_params": [
      "self"
    ]
  },
  "ECB": {
    "__init__": [
      "self",
      "inp_planes",
      "out_planes",
      "depth_multiplier",
      "act_type",
      "with_idt"
    ],
    "forward": [
      "self",
      "x"
    ],
    "rep_params": [
      "self"
    ]
  },
  "default_init_weights": [
    "module_list",
    "scale",
    "bias_fill"
  ],
  "resize_flow": [
    "flow",
    "size_type",
    "sizes",
    "interp_mode",
    "align_corners"
  ],
  "pixel_unshuffle": [
    "x",
    "scale"
  ],
  "ResidualDenseBlock": {
    "__init__": [
      "self",
      "num_feat",
      "num_grow_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RRDB": {
    "__init__": [
      "self",
      "num_feat",
      "num_grow_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RRDBNet": {
    "__init__": [
      "self",
      "num_in_ch",
      "num_out_ch",
      "scale",
      "num_feat",
      "num_block",
      "num_grow_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "vip_seg_label": [],
  "vip_seg_label_to_id": [],
  "vip_seg_id_to_label": [],
  "city_labels": [],
  "sha256num": [
    "num"
  ],
  "id2rgb": [
    "id_map"
  ],
  "cityscapes_cat2rgb": [
    "cat_map"
  ],
  "trackmap2rgb": [
    "track_map"
  ],
  "draw_bbox_on_img": [
    "vis_img",
    "bboxes"
  ],
  "coords2bbox_all": [
    "coords"
  ],
  "tensor_mask2box": [
    "masks"
  ],
  "VideoKNet": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "extract_feat": [
      "self",
      "img"
    ],
    "init_tracker": [
      "self"
    ],
    "forward": [
      "self",
      "img",
      "img_metas",
      "rescale",
      "ref_img",
      "iid"
    ],
    "simple_test": [
      "self",
      "img",
      "img_metas",
      "rescale",
      "ref_img",
      "iid"
    ],
    "_track_forward": [
      "self",
      "track_feats",
      "x",
      "mask_pred"
    ],
    "get_things_id_for_tracking": [
      "self",
      "panoptic_seg",
      "seg_infos"
    ],
    "get_semantic_seg": [
      "self",
      "panoptic_seg",
      "segments_info"
    ],
    "generate_track_id_maps": [
      "self",
      "ids",
      "masks",
      "panopitc_seg_maps"
    ]
  },
  "SwinTransformerDIY": {
    "__init__": [
      "self",
      "pretrain_img_size",
      "patch_size",
      "in_chans",
      "embed_dims",
      "depths",
      "num_heads",
      "window_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "norm_layer",
      "use_abs_pos_embed",
      "patch_norm",
      "out_indices",
      "frozen_stages",
      "with_cp",
      "output_img",
      "pretrained"
    ],
    "_freeze_stages": [
      "self"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ],
    "forward": [
      "self",
      "x"
    ],
    "train": [
      "self",
      "mode"
    ]
  },
  "_process_mmcls_checkpoint": [
    "checkpoint"
  ],
  "_save_to_state_dict": [
    "module",
    "destination",
    "prefix",
    "keep_vars"
  ],
  "get_state_dict": [
    "module",
    "destination",
    "prefix",
    "keep_vars"
  ],
  "TRACKERS": [],
  "build_tracker": [
    "cfg"
  ],
  "QuasiDenseEmbedTracker": {
    "__init__": [
      "self",
      "init_score_thr",
      "obj_score_thr",
      "match_score_thr",
      "memo_tracklet_frames",
      "memo_backdrop_frames",
      "memo_momentum",
      "nms_conf_thr",
      "nms_backdrop_iou_thr",
      "nms_class_iou_thr",
      "with_cats",
      "match_metric"
    ],
    "empty": [
      "self"
    ],
    "update_memo": [
      "self",
      "ids",
      "bboxes",
      "embeds",
      "labels",
      "frame_id"
    ],
    "memo": [
      "self"
    ],
    "match": [
      "self",
      "bboxes",
      "labels",
      "track_feats",
      "frame_id",
      "asso_tau"
    ]
  },
  "coords2bbox": [
    "coords",
    "extend"
  ],
  "coords2bboxTensor": [
    "coords",
    "extend"
  ],
  "mask2box": [
    "masks"
  ],
  "batch_mask2boxlist": [
    "masks"
  ],
  "bboxlist2roi": [
    "bbox_list"
  ],
  "bbox2roi": [
    "bbox_list"
  ],
  "temp_interp_mask": [
    "maskseq",
    "T"
  ],
  "mask_seq_jac": [
    "sa",
    "sb"
  ],
  "skltn2mask": [
    "skltn",
    "size"
  ],
  "pts2array": [
    "pts"
  ],
  "SemanticFPNWrapper": {
    "__init__": [
      "self",
      "in_channels",
      "feat_channels",
      "out_channels",
      "start_level",
      "end_level",
      "cat_coors",
      "positional_encoding",
      "cat_coors_level",
      "fuse_by_cat",
      "return_list",
      "upsample_times",
      "with_pred",
      "num_aux_convs",
      "act_cfg",
      "out_act_cfg",
      "conv_cfg",
      "norm_cfg"
    ],
    "generate_coord": [
      "self",
      "input_feat"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "VideoKernelIterHead": {
    "__init__": [
      "self",
      "num_stages",
      "recursive",
      "assign_stages",
      "stage_loss_weights",
      "proposal_feature_channel",
      "merge_cls_scores",
      "do_panoptic",
      "post_assign",
      "hard_target",
      "merge_joint",
      "num_proposals",
      "num_thing_classes",
      "num_stuff_classes",
      "mask_assign_stride",
      "ignore_label",
      "thing_label_in_seg",
      "with_track",
      "mask_head",
      "mask_out_stride",
      "train_cfg",
      "test_cfg"
    ],
    "init_bbox_head": [
      "self",
      "mask_roi_extractor",
      "mask_head"
    ],
    "init_weights": [
      "self"
    ],
    "init_assigner_sampler": [
      "self"
    ],
    "forward_train": [
      "self",
      "x",
      "proposal_feats",
      "mask_preds",
      "cls_score",
      "img_metas",
      "gt_masks",
      "gt_labels",
      "gt_pids",
      "gt_bboxes_ignore",
      "imgs_whwh",
      "gt_bboxes",
      "gt_sem_seg",
      "gt_sem_cls"
    ],
    "init_mask_head": [
      "self",
      "mask_roi_extractor",
      "mask_head"
    ],
    "_mask_forward": [
      "self",
      "stage",
      "x",
      "object_feats",
      "mask_preds",
      "img_metas",
      "previous_obj_feats",
      "previous_mask_preds",
      "previous_x_feats"
    ],
    "simple_test": [
      "self",
      "x",
      "proposal_feats",
      "mask_preds",
      "cls_score",
      "img_metas"
    ],
    "simple_test_with_previous": [
      "self",
      "x",
      "proposal_feats",
      "mask_preds",
      "cls_score",
      "img_metas",
      "previous_obj_feats",
      "previous_mask_preds",
      "previous_x_feats",
      "is_first"
    ],
    "aug_test": [
      "self",
      "features",
      "proposal_list",
      "img_metas",
      "rescale"
    ],
    "forward_dummy": [
      "self",
      "x",
      "proposal_boxes",
      "proposal_feats",
      "img_metas"
    ],
    "get_panoptic": [
      "self",
      "cls_scores",
      "mask_preds",
      "test_cfg",
      "img_meta",
      "obj_feat"
    ],
    "merge_stuff_thing_thing_first": [
      "self",
      "thing_masks",
      "thing_labels",
      "thing_scores",
      "stuff_masks",
      "stuff_labels",
      "stuff_scores",
      "merge_cfg",
      "thing_obj_feat",
      "stuff_obj_feat"
    ],
    "merge_stuff_thing_stuff_joint": [
      "self",
      "thing_masks",
      "thing_labels",
      "thing_scores",
      "stuff_masks",
      "stuff_labels",
      "stuff_scores",
      "merge_cfg",
      "thing_obj",
      "stuff_obj"
    ]
  },
  "VideoKernelUpdateHead": {
    "__init__": [
      "self",
      "num_classes",
      "num_ffn_fcs",
      "num_heads",
      "num_cls_fcs",
      "num_mask_fcs",
      "feedforward_channels",
      "in_channels",
      "out_channels",
      "dropout",
      "mask_thr",
      "act_cfg",
      "ffn_act_cfg",
      "conv_kernel_size",
      "feat_transform_cfg",
      "hard_mask_thr",
      "kernel_init",
      "with_ffn",
      "mask_out_stride",
      "relative_coors",
      "relative_coors_off",
      "feat_gather_stride",
      "mask_transform_stride",
      "mask_upsample_stride",
      "num_thing_classes",
      "num_stuff_classes",
      "mask_assign_stride",
      "ignore_label",
      "thing_label_in_seg",
      "previous",
      "previous_x_feat",
      "previous_link",
      "previous_type",
      "previous_detach",
      "previous_detach_link",
      "previous_link_detach",
      "kernel_updator_cfg",
      "loss_rank",
      "loss_mask",
      "loss_dice",
      "loss_cls"
    ],
    "forward": [
      "self",
      "x",
      "proposal_feat",
      "mask_preds",
      "prev_cls_score",
      "mask_shape",
      "img_metas",
      "previous_obj_feats",
      "previous_mask_preds",
      "previous_x_feats"
    ],
    "_get_target_single": [
      "self",
      "pos_inds",
      "neg_inds",
      "pos_mask",
      "neg_mask",
      "pos_gt_mask",
      "pos_gt_labels",
      "gt_sem_seg",
      "gt_sem_cls",
      "cfg"
    ],
    "get_targets": [
      "self",
      "sampling_results",
      "gt_mask",
      "gt_labels",
      "rcnn_train_cfg",
      "concat",
      "gt_sem_seg",
      "gt_sem_cls"
    ],
    "rescale_masks": [
      "self",
      "masks_per_img",
      "img_meta"
    ],
    "get_seg_masks": [
      "self",
      "masks_per_img",
      "labels_per_img",
      "scores_per_img",
      "test_cfg",
      "img_meta"
    ],
    "segm2result": [
      "self",
      "mask_preds",
      "det_labels",
      "cls_scores"
    ]
  },
  "ConvKernelHead": {
    "__init__": [
      "self",
      "num_proposals",
      "in_channels",
      "out_channels",
      "num_heads",
      "num_cls_fcs",
      "num_seg_convs",
      "num_loc_convs",
      "att_dropout",
      "conv_kernel_size",
      "norm_cfg",
      "semantic_fpn",
      "train_cfg",
      "num_classes",
      "xavier_init_kernel",
      "kernel_init_std",
      "use_binary",
      "proposal_feats_with_obj",
      "feat_downsample_stride",
      "feat_refine_stride",
      "feat_refine",
      "with_embed",
      "feat_embed_only",
      "conv_normal_init",
      "mask_out_stride",
      "hard_target",
      "num_thing_classes",
      "num_stuff_classes",
      "mask_assign_stride",
      "ignore_label",
      "thing_label_in_seg",
      "cat_stuff_mask"
    ],
    "_init_layers": [
      "self"
    ],
    "_decode_init_proposals": [
      "self",
      "img",
      "img_metas"
    ],
    "simple_test_rpn": [
      "self",
      "img",
      "img_metas"
    ],
    "forward_dummy": [
      "self",
      "img",
      "img_metas"
    ]
  },
  "cal_similarity": [
    "key_embeds",
    "ref_embeds",
    "method",
    "temperature"
  ],
  "QuasiDenseMaskEmbedHeadGTMask": {
    "__init__": [
      "self",
      "num_convs",
      "num_fcs",
      "roi_feat_size",
      "in_channels",
      "conv_out_channels",
      "fc_out_channels",
      "embed_channels",
      "conv_cfg",
      "norm_cfg",
      "softmax_temp"
    ],
    "_add_conv_fc_branch": [
      "self",
      "num_convs",
      "num_fcs",
      "in_channels"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_track_targets": [
      "self",
      "gt_match_indices",
      "key_sampling_results",
      "ref_sampling_results"
    ],
    "match": [
      "self",
      "key_embeds",
      "ref_embeds",
      "key_sampling_results",
      "ref_sampling_results"
    ]
  },
  "MarigoldDepthOutput": {},
  "bs_search_table": [],
  "find_batch_size": [
    "ensemble_size",
    "input_res",
    "dtype"
  ],
  "inter_distances": [
    "tensors"
  ],
  "ensemble_depths": [
    "input_images",
    "regularizer_strength",
    "max_iter",
    "tol",
    "reduction",
    "max_res"
  ],
  "colorize_depth_maps": [
    "depth_map",
    "min_depth",
    "max_depth",
    "cmap",
    "valid_mask"
  ],
  "chw2hwc": [
    "chw"
  ],
  "resize_max_res": [
    "img",
    "max_edge_resolution"
  ],
  "GELU": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "approximate"
    ],
    "gelu": [
      "self",
      "gate"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ApproximateGELU": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AdaLayerNorm": {
    "__init__": [
      "self",
      "embedding_dim",
      "num_embeddings"
    ],
    "forward": [
      "self",
      "x",
      "timestep"
    ]
  },
  "AdaLayerNormZero": {
    "__init__": [
      "self",
      "embedding_dim",
      "num_embeddings"
    ],
    "forward": [
      "self",
      "x",
      "timestep",
      "class_labels",
      "hidden_dtype"
    ]
  },
  "AdaGroupNorm": {
    "__init__": [
      "self",
      "embedding_dim",
      "out_dim",
      "num_groups",
      "act_fn",
      "eps"
    ],
    "forward": [
      "self",
      "x",
      "emb"
    ]
  },
  "adain_color_fix": [
    "target",
    "source"
  ],
  "wavelet_color_fix": [
    "target",
    "source"
  ],
  "calc_mean_std": [
    "feat",
    "eps"
  ],
  "adaptive_instance_normalization": [
    "content_feat",
    "style_feat"
  ],
  "wavelet_blur": [
    "image",
    "radius"
  ],
  "wavelet_decomposition": [
    "image",
    "levels"
  ],
  "wavelet_reconstruction": [
    "content_feat",
    "style_feat"
  ],
  "load_dreambooth_lora": [
    "unet",
    "vae",
    "model_path",
    "model_base"
  ],
  "Transformer2DModelOutput": {},
  "Transformer2DModel": {
    "__init__": [
      "self",
      "num_attention_heads",
      "attention_head_dim",
      "in_channels",
      "out_channels",
      "num_layers",
      "dropout",
      "norm_num_groups",
      "cross_attention_dim",
      "pixelwise_cross_attention_dim",
      "attention_bias",
      "sample_size",
      "num_vector_embeds",
      "patch_size",
      "activation_fn",
      "num_embeds_ada_norm",
      "use_linear_projection",
      "only_cross_attention",
      "upcast_attention",
      "norm_type",
      "norm_elementwise_affine",
      "use_pixelwise_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "encoder_pixelwise_hidden_states",
      "timestep",
      "class_labels",
      "cross_attention_kwargs",
      "return_dict"
    ]
  },
  "save_pfm": [
    "filename",
    "image",
    "scale"
  ],
  "MVSDataset": {
    "__init__": [
      "self",
      "datapath",
      "listfile",
      "mode",
      "nviews",
      "ndepths",
      "interval_scale"
    ],
    "build_list": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "read_cam_file": [
      "self",
      "filename",
      "interval_scale"
    ],
    "read_img": [
      "self",
      "filename"
    ],
    "read_depth": [
      "self",
      "filename"
    ],
    "scale_mvs_input": [
      "self",
      "img",
      "intrinsics",
      "max_w",
      "max_h",
      "base"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "make_recursive_func": [
    "func"
  ],
  "tensor2numpy": [
    "vars"
  ],
  "numpy2torch": [
    "vars"
  ],
  "tocuda": [
    "vars"
  ],
  "generate_pointcloud": [
    "rgb",
    "depth",
    "ply_file",
    "intr",
    "scale"
  ],
  "write_cam": [
    "file",
    "cam"
  ],
  "read_points3d_binary": [
    "path_to_model_file"
  ],
  "rotmat2qvec": [
    "R"
  ],
  "calc_score": [
    "inputs",
    "images",
    "points3d",
    "extrinsic",
    "args"
  ],
  "processing_single_scene": [
    "args"
  ],
  "init_bn": [
    "module"
  ],
  "init_uniform": [
    "module",
    "init_method"
  ],
  "Deconv2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "relu",
      "bn",
      "bn_momentum",
      "init_method"
    ],
    "forward": [
      "self",
      "x"
    ],
    "init_weights": [
      "self",
      "init_method"
    ]
  },
  "Conv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "relu",
      "bn",
      "bn_momentum",
      "init_method"
    ],
    "forward": [
      "self",
      "x"
    ],
    "init_weights": [
      "self",
      "init_method"
    ]
  },
  "Deconv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "relu",
      "bn",
      "bn_momentum",
      "init_method"
    ],
    "forward": [
      "self",
      "x"
    ],
    "init_weights": [
      "self",
      "init_method"
    ]
  },
  "ConvBnReLU": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "pad"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvBn": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "pad"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "homo_warping": [
    "src_fea",
    "src_proj",
    "ref_proj",
    "depth_values"
  ],
  "DeConv2dFuse": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "relu",
      "bn",
      "bn_momentum"
    ],
    "forward": [
      "self",
      "x_pre",
      "x"
    ]
  },
  "FeatureNet": {
    "__init__": [
      "self",
      "base_channels",
      "num_stage",
      "stride",
      "arch_mode"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CostRegNet": {
    "__init__": [
      "self",
      "in_channels",
      "base_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RefineNet": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "img",
      "depth_init"
    ]
  },
  "depth_regression": [
    "p",
    "depth_values"
  ],
  "cas_mvsnet_loss": [
    "inputs",
    "depth_gt_ms",
    "mask_ms"
  ],
  "get_cur_depth_range_samples": [
    "cur_depth",
    "ndepth",
    "depth_inteval_pixel",
    "shape",
    "max_depth",
    "min_depth"
  ],
  "get_depth_range_samples": [
    "cur_depth",
    "ndepth",
    "depth_inteval_pixel",
    "device",
    "dtype",
    "shape",
    "max_depth",
    "min_depth"
  ],
  "ImageMultiViewDepthEstimation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "preprocess_make_pair": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "read_camera_parameters": [
    "filename"
  ],
  "read_img": [
    "filename"
  ],
  "read_mask": [
    "filename"
  ],
  "save_mask": [
    "filename",
    "mask"
  ],
  "read_pair_file": [
    "filename"
  ],
  "reproject_with_depth": [
    "depth_ref",
    "intrinsics_ref",
    "extrinsics_ref",
    "depth_src",
    "intrinsics_src",
    "extrinsics_src"
  ],
  "check_geometric_consistency": [
    "depth_ref",
    "intrinsics_ref",
    "extrinsics_ref",
    "depth_src",
    "intrinsics_src",
    "extrinsics_src"
  ],
  "filter_depth": [
    "pair_folder",
    "scan_folder",
    "out_folder",
    "thres_view"
  ],
  "pcd_depth_filter": [
    "scene",
    "test_dir",
    "save_dir",
    "thres_view"
  ],
  "Align_Corners_Range": [],
  "CascadeMVSNet": {
    "__init__": [
      "self",
      "refine",
      "ndepths",
      "depth_interals_ratio",
      "share_cr",
      "grad_method",
      "arch_mode",
      "cr_base_chs"
    ],
    "forward": [
      "self",
      "imgs",
      "proj_matrices",
      "depth_values"
    ]
  },
  "load_pretrained": [
    "model",
    "state_dict",
    "local_path",
    "map_location",
    "logger",
    "sub_level"
  ],
  "load_pretrained_dict": [
    "model",
    "state_dict",
    "logger",
    "sub_level"
  ],
  "_auto_drop_invalid": [
    "model",
    "state_dict",
    "logger"
  ],
  "StructuredProbingModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "x"
    ],
    "aggregate_token": [
      "self",
      "output",
      "target_size"
    ]
  },
  "VisualTransformer": {
    "__init__": [
      "self",
      "input_resolution",
      "patch_size",
      "width",
      "layers",
      "heads",
      "output_dim"
    ],
    "forward": [
      "self",
      "x",
      "return_all"
    ]
  },
  "CLIPNet": {
    "__init__": [
      "self",
      "arch_name",
      "pretrained"
    ],
    "forward": [
      "self",
      "input_data"
    ]
  },
  "ProbingModel": {
    "__init__": [
      "self",
      "feat_size",
      "num_classes"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ImageControl3dPortrait": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "convert_state_dict": [
      "self",
      "state_dict"
    ],
    "detect_face": [
      "self",
      "img"
    ],
    "get_f5p": [
      "self",
      "landmarks",
      "np_img"
    ],
    "find_pupil": [
      "self",
      "landmarks",
      "np_img"
    ],
    "load_lm3d": [
      "self",
      "similarity_mat_path"
    ],
    "POS": [
      "self",
      "xp",
      "x"
    ],
    "resize_n_crop_img": [
      "self",
      "img",
      "lm",
      "t",
      "s",
      "target_size",
      "mask"
    ],
    "align_img": [
      "self",
      "img",
      "lm",
      "lm3D",
      "mask",
      "target_size",
      "rescale_factor"
    ],
    "crop_image": [
      "self",
      "img",
      "lm"
    ],
    "create_samples": [
      "self",
      "N",
      "voxel_origin",
      "cube_length"
    ],
    "numpy_array_to_video": [
      "self",
      "numpy_list",
      "video_out_path"
    ],
    "inference": [
      "self",
      "image_path",
      "save_dir"
    ]
  },
  "TriPlaneGenerator": {
    "__init__": [
      "self",
      "z_dim",
      "c_dim",
      "w_dim",
      "img_resolution",
      "img_channels",
      "sr_num_fp16_res",
      "mapping_kwargs",
      "rendering_kwargs",
      "sr_kwargs"
    ],
    "mapping": [
      "self",
      "z",
      "c",
      "truncation_psi",
      "truncation_cutoff",
      "update_emas"
    ],
    "synthesis": [
      "self",
      "ws",
      "c",
      "neural_rendering_resolution",
      "update_emas",
      "cache_backbone",
      "use_cached_backbone"
    ],
    "sample": [
      "self",
      "coordinates",
      "directions",
      "z",
      "c",
      "truncation_psi",
      "truncation_cutoff",
      "update_emas"
    ],
    "sample_mixed": [
      "self",
      "coordinates",
      "directions",
      "ws",
      "truncation_psi",
      "truncation_cutoff",
      "update_emas"
    ],
    "forward": [
      "self",
      "z",
      "c",
      "truncation_psi",
      "truncation_cutoff",
      "neural_rendering_resolution",
      "update_emas",
      "cache_backbone",
      "use_cached_backbone"
    ]
  },
  "OSGDecoder": {
    "__init__": [
      "self",
      "n_features",
      "options"
    ],
    "forward": [
      "self",
      "sampled_features",
      "ray_directions"
    ]
  },
  "GaussianCameraPoseSampler": {
    "sample": [
      "horizontal_mean",
      "vertical_mean",
      "horizontal_stddev",
      "vertical_stddev",
      "radius",
      "batch_size",
      "device"
    ]
  },
  "LookAtPoseSampler": {
    "sample": [
      "horizontal_mean",
      "vertical_mean",
      "lookat_position",
      "horizontal_stddev",
      "vertical_stddev",
      "radius",
      "batch_size",
      "device"
    ]
  },
  "UniformCameraPoseSampler": {
    "sample": [
      "horizontal_mean",
      "vertical_mean",
      "horizontal_stddev",
      "vertical_stddev",
      "radius",
      "batch_size",
      "device"
    ]
  },
  "create_cam2world_matrix": [
    "forward_vector",
    "origin"
  ],
  "FOV_to_intrinsics": [
    "fov_degrees",
    "device"
  ],
  "normalize_2nd_moment": [
    "x",
    "dim",
    "eps"
  ],
  "modulated_conv2d": [
    "x",
    "weight",
    "styles",
    "noise",
    "up",
    "down",
    "padding",
    "resample_filter",
    "demodulate",
    "flip_weight",
    "fused_modconv"
  ],
  "FullyConnectedLayer": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "activation",
      "lr_multiplier",
      "bias_init"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "Conv2dLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "bias",
      "activation",
      "up",
      "down",
      "resample_filter",
      "conv_clamp",
      "channels_last",
      "trainable"
    ],
    "forward": [
      "self",
      "x",
      "gain"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "MappingNetwork": {
    "__init__": [
      "self",
      "z_dim",
      "c_dim",
      "w_dim",
      "num_ws",
      "num_layers",
      "embed_features",
      "layer_features",
      "activation",
      "lr_multiplier",
      "w_avg_beta"
    ],
    "forward": [
      "self",
      "z",
      "c",
      "truncation_psi",
      "truncation_cutoff",
      "update_emas"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "SynthesisLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "w_dim",
      "resolution",
      "kernel_size",
      "up",
      "use_noise",
      "activation",
      "resample_filter",
      "conv_clamp",
      "channels_last"
    ],
    "forward": [
      "self",
      "x",
      "w",
      "noise_mode",
      "fused_modconv",
      "gain"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "ToRGBLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "w_dim",
      "kernel_size",
      "conv_clamp",
      "channels_last"
    ],
    "forward": [
      "self",
      "x",
      "w",
      "fused_modconv"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "SynthesisBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "w_dim",
      "resolution",
      "img_channels",
      "is_last",
      "architecture",
      "resample_filter",
      "conv_clamp",
      "use_fp16",
      "fp16_channels_last",
      "fused_modconv_default"
    ],
    "forward": [
      "self",
      "x",
      "img",
      "ws",
      "force_fp32",
      "fused_modconv",
      "update_emas"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "SynthesisNetwork": {
    "__init__": [
      "self",
      "w_dim",
      "img_resolution",
      "img_channels",
      "channel_base",
      "channel_max",
      "num_fp16_res"
    ],
    "forward": [
      "self",
      "ws"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "DiscriminatorBlock": {
    "__init__": [
      "self",
      "in_channels",
      "tmp_channels",
      "out_channels",
      "resolution",
      "img_channels",
      "first_layer_idx",
      "architecture",
      "activation",
      "resample_filter",
      "conv_clamp",
      "use_fp16",
      "fp16_channels_last",
      "freeze_layers"
    ],
    "forward": [
      "self",
      "x",
      "img",
      "force_fp32"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "MinibatchStdLayer": {
    "__init__": [
      "self",
      "group_size",
      "num_channels"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "DiscriminatorEpilogue": {
    "__init__": [
      "self",
      "in_channels",
      "cmap_dim",
      "resolution",
      "img_channels",
      "architecture",
      "mbstd_group_size",
      "mbstd_num_channels",
      "activation",
      "conv_clamp"
    ],
    "forward": [
      "self",
      "x",
      "img",
      "cmap",
      "force_fp32"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "SuperresolutionHybrid8X": {
    "__init__": [
      "self",
      "channels",
      "img_resolution",
      "sr_num_fp16_res",
      "sr_antialias",
      "num_fp16_res",
      "conv_clamp",
      "channel_base",
      "channel_max"
    ],
    "forward": [
      "self",
      "rgb",
      "x",
      "ws"
    ]
  },
  "SuperresolutionHybrid4X": {
    "__init__": [
      "self",
      "channels",
      "img_resolution",
      "sr_num_fp16_res",
      "sr_antialias",
      "num_fp16_res",
      "conv_clamp",
      "channel_base",
      "channel_max"
    ],
    "forward": [
      "self",
      "rgb",
      "x",
      "ws"
    ]
  },
  "SuperresolutionHybrid2X": {
    "__init__": [
      "self",
      "channels",
      "img_resolution",
      "sr_num_fp16_res",
      "sr_antialias",
      "num_fp16_res",
      "conv_clamp",
      "channel_base",
      "channel_max"
    ],
    "forward": [
      "self",
      "rgb",
      "x",
      "ws"
    ]
  },
  "SuperresolutionHybridDeepfp32": {
    "__init__": [
      "self",
      "channels",
      "img_resolution",
      "sr_num_fp16_res",
      "num_fp16_res",
      "conv_clamp",
      "channel_base",
      "channel_max"
    ],
    "forward": [
      "self",
      "rgb",
      "x",
      "ws"
    ]
  },
  "SynthesisBlockNoUp": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "w_dim",
      "resolution",
      "img_channels",
      "is_last",
      "architecture",
      "resample_filter",
      "conv_clamp",
      "use_fp16",
      "fp16_channels_last",
      "fused_modconv_default"
    ],
    "forward": [
      "self",
      "x",
      "img",
      "ws",
      "force_fp32",
      "fused_modconv",
      "update_emas"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "SuperresolutionHybrid8XDC": {
    "__init__": [
      "self",
      "channels",
      "img_resolution",
      "sr_num_fp16_res",
      "sr_antialias",
      "num_fp16_res",
      "conv_clamp",
      "channel_base",
      "channel_max"
    ],
    "forward": [
      "self",
      "rgb",
      "x",
      "ws"
    ]
  },
  "OverlapPatchEmbed": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "stride",
      "in_chans",
      "embed_dim"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Encoder_low": {
    "__init__": [
      "self",
      "img_size",
      "depth",
      "in_chans",
      "embed_dims",
      "num_head",
      "mlp_ratio",
      "sr_ratio",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "norm_layer"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Encoder_high": {
    "__init__": [
      "self"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MixFeature": {
    "__init__": [
      "self",
      "img_size",
      "depth",
      "in_chans",
      "embed_dims",
      "num_head",
      "mlp_ratio",
      "sr_ratio",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "norm_layer"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "forward": [
      "self",
      "x_low",
      "x_high"
    ]
  },
  "TriplaneEncoder": {
    "__init__": [
      "self",
      "img_resolution",
      "sr_num_fp16_res",
      "rendering_kwargs",
      "sr_kwargs"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "gen_interfeats": [
      "self",
      "ws",
      "planes",
      "camera_params"
    ],
    "sample": [
      "self",
      "coordinates",
      "directions",
      "planes"
    ],
    "forward": [
      "self",
      "ws",
      "x",
      "camera_ref",
      "camera_mv"
    ]
  },
  "get_parameter_number": [
    "net"
  ],
  "MipRayMarcher2": {
    "__init__": [
      "self"
    ],
    "run_forward": [
      "self",
      "colors",
      "densities",
      "depths",
      "rendering_options"
    ],
    "forward": [
      "self",
      "colors",
      "densities",
      "depths",
      "rendering_options"
    ]
  },
  "generate_planes": [],
  "project_onto_planes": [
    "planes",
    "coordinates"
  ],
  "sample_from_planes": [
    "plane_axes",
    "plane_features",
    "coordinates",
    "mode",
    "padding_mode",
    "box_warp"
  ],
  "sample_from_3dgrid": [
    "grid",
    "coordinates"
  ],
  "ImportanceRenderer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "planes",
      "decoder",
      "ray_origins",
      "ray_directions",
      "rendering_options"
    ],
    "run_model": [
      "self",
      "planes",
      "decoder",
      "sample_coordinates",
      "sample_directions",
      "options"
    ],
    "sort_samples": [
      "self",
      "all_depths",
      "all_colors",
      "all_densities"
    ],
    "unify_samples": [
      "self",
      "depths1",
      "colors1",
      "densities1",
      "depths2",
      "colors2",
      "densities2"
    ],
    "sample_stratified": [
      "self",
      "ray_origins",
      "ray_start",
      "ray_end",
      "depth_resolution",
      "disparity_space_sampling"
    ],
    "sample_importance": [
      "self",
      "z_vals",
      "weights",
      "N_importance"
    ],
    "sample_pdf": [
      "self",
      "bins",
      "weights",
      "N_importance",
      "det",
      "eps"
    ]
  },
  "transform_vectors": [
    "matrix",
    "vectors4"
  ],
  "normalize_vecs": [
    "vectors"
  ],
  "torch_dot": [
    "x",
    "y"
  ],
  "get_ray_limits_box": [
    "rays_o",
    "rays_d",
    "box_side_length"
  ],
  "linspace": [
    "start",
    "stop",
    "num"
  ],
  "RaySampler": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "cam2world_matrix",
      "intrinsics",
      "resolution"
    ]
  },
  "init_transform_dict": [
    "input_res"
  ],
  "load_json": [
    "filename"
  ],
  "get_valid_frames": [
    "cap",
    "num_frames",
    "vlen",
    "sample"
  ],
  "load_frames_from_video": [
    "video_path",
    "num_frames",
    "sample"
  ],
  "LengthAdaptiveTokenizer": {
    "__init__": [
      "self",
      "config",
      "bpe_path"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "encode": [
      "self",
      "text"
    ],
    "__call__": [
      "self",
      "texts",
      "return_tensors",
      "padding",
      "truncation"
    ]
  },
  "VoP": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "get_video_features": [
      "self",
      "videos",
      "return_all_frames"
    ],
    "get_text_features": [
      "self",
      "text_data"
    ],
    "forward": [
      "self",
      "data",
      "return_all_frames"
    ]
  },
  "BaselinePooling": {
    "__init__": [
      "self",
      "pooling_type",
      "config"
    ],
    "_avg_pooling": [
      "self",
      "text_embeds",
      "video_embeds"
    ],
    "forward": [
      "self",
      "text_embeds",
      "video_embeds"
    ]
  },
  "VisualPromptLearner": {
    "__init__": [
      "self",
      "clip_model",
      "config"
    ],
    "forward": [
      "self"
    ]
  },
  "TextPromptLearner": {
    "__init__": [
      "self",
      "clip_model",
      "config"
    ],
    "forward": [
      "self"
    ]
  },
  "ImageEncoder": {
    "__init__": [
      "self",
      "clip_model",
      "config"
    ],
    "forward": [
      "self",
      "visual_prompts",
      "x"
    ]
  },
  "TextEncoder": {
    "__init__": [
      "self",
      "clip_model",
      "config"
    ],
    "forward": [
      "self",
      "text_prompts",
      "text"
    ]
  },
  "load_clip": [
    "name",
    "device",
    "jit"
  ],
  "VideoTextRetrievalModelSeries": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "get_video_features": [
      "self",
      "videos",
      "return_all_frames"
    ],
    "get_text_features": [
      "self",
      "text_data"
    ],
    "forward": [
      "self",
      "data",
      "return_all_frames"
    ]
  },
  "FPNFusionModule": {
    "__init__": [
      "self",
      "embed_dims",
      "fuse_dim",
      "n_block",
      "use_bn"
    ],
    "forward": [
      "self",
      "x_blocks"
    ]
  },
  "_make_multi_scale_layers": [
    "in_shape",
    "out_shape",
    "n_block",
    "groups",
    "use_bn"
  ],
  "DeformableTransformer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "num_decoder_layers",
      "dim_feedforward",
      "dropout",
      "activation",
      "return_intermediate_dec",
      "num_feature_levels",
      "dec_n_points",
      "drop_path",
      "token_label"
    ],
    "_reset_parameters": [
      "self"
    ],
    "get_proposal_pos_embed": [
      "self",
      "proposals"
    ],
    "gen_encoder_output_proposals": [
      "self",
      "memory",
      "memory_padding_mask",
      "spatial_shapes"
    ],
    "get_valid_ratio": [
      "self",
      "mask"
    ],
    "forward": [
      "self",
      "srcs",
      "masks",
      "tgt",
      "query_pos"
    ]
  },
  "DeformableTransformerDecoder": {
    "__init__": [
      "self",
      "decoder_layer",
      "num_layers",
      "return_intermediate"
    ],
    "forward": [
      "self",
      "tgt",
      "reference_points",
      "src",
      "src_spatial_shapes",
      "src_level_start_index",
      "src_valid_ratios",
      "query_pos",
      "src_padding_mask"
    ]
  },
  "ms_deform_attn_core_pytorch": [
    "value",
    "value_spatial_shapes",
    "sampling_locations",
    "attention_weights"
  ],
  "VidtModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "masked_sin_pos_encoding": [
    "x",
    "mask",
    "num_pos_feats",
    "temperature",
    "scale"
  ],
  "ReconfiguredAttentionModule": {
    "__init__": [
      "self",
      "dim",
      "window_size",
      "num_heads",
      "qkv_bias",
      "qk_scale",
      "attn_drop",
      "proj_drop"
    ],
    "forward": [
      "self",
      "x",
      "det",
      "mask",
      "cross_attn",
      "cross_attn_mask"
    ]
  },
  "Detector": {
    "__init__": [
      "self",
      "backbone",
      "transformer",
      "num_classes",
      "num_queries",
      "aux_loss",
      "with_box_refine",
      "epff",
      "with_vector",
      "processor_dct",
      "vector_hidden_dim",
      "iou_aware",
      "token_label",
      "distil"
    ],
    "forward": [
      "self",
      "features_0",
      "features_1",
      "features_2",
      "features_3",
      "det_tgt",
      "det_pos",
      "mask"
    ],
    "_set_aux_loss": [
      "self",
      "outputs_class",
      "outputs_coord",
      "outputs_vector"
    ]
  },
  "VideoMattingNetwork": {
    "__init__": [
      "self",
      "model_dir"
    ]
  },
  "preprocess": [
    "image"
  ],
  "DeepGuidedFilterRefiner": {
    "__init__": [
      "self",
      "hid_channels"
    ],
    "forward_single_frame": [
      "self",
      "fine_src",
      "base_src",
      "base_fgr",
      "base_pha",
      "base_hid"
    ],
    "forward_time_series": [
      "self",
      "fine_src",
      "base_src",
      "base_fgr",
      "base_pha",
      "base_hid"
    ],
    "forward": [
      "self",
      "fine_src",
      "base_src",
      "base_fgr",
      "base_pha",
      "base_hid"
    ]
  },
  "hswish": {
    "forward": [
      "self",
      "x"
    ]
  },
  "scSEblock": {
    "__init__": [
      "self",
      "out"
    ],
    "forward_single": [
      "self",
      "x"
    ],
    "forward_time": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RecurrentDecoder": {
    "__init__": [
      "self",
      "feature_channels",
      "decoder_channels"
    ],
    "forward": [
      "self",
      "s0",
      "f1",
      "f2",
      "f3",
      "f4",
      "r1",
      "r2",
      "r3",
      "r4"
    ]
  },
  "AvgPool": {
    "__init__": [
      "self"
    ],
    "forward_single_frame": [
      "self",
      "s0"
    ],
    "forward_time_series": [
      "self",
      "s0"
    ],
    "forward": [
      "self",
      "s0"
    ]
  },
  "crossfeature": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward_single_frame": [
      "self",
      "x1",
      "x2"
    ],
    "forward_time_series": [
      "self",
      "x1",
      "x2"
    ],
    "forward": [
      "self",
      "x1",
      "x2"
    ]
  },
  "UpsamplingBlock": {
    "__init__": [
      "self",
      "in_channels",
      "skip_channels",
      "src_channels",
      "out_channels"
    ],
    "forward_single_frame": [
      "self",
      "x",
      "f",
      "s",
      "r"
    ],
    "forward_time_series": [
      "self",
      "x",
      "f",
      "s",
      "r"
    ],
    "forward": [
      "self",
      "x",
      "f",
      "s",
      "r"
    ]
  },
  "OutputBlock": {
    "__init__": [
      "self",
      "in_channels",
      "src_channels",
      "out_channels"
    ],
    "forward_single_frame": [
      "self",
      "x",
      "s"
    ],
    "forward_time_series": [
      "self",
      "x",
      "s"
    ],
    "forward": [
      "self",
      "x",
      "s"
    ]
  },
  "Projection": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward_single_frame": [
      "self",
      "x"
    ],
    "forward_time_series": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GRU": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "padding"
    ],
    "forward_single_frame": [
      "self",
      "x",
      "pre_fea"
    ],
    "forward_time_series": [
      "self",
      "x",
      "pre_fea"
    ],
    "forward": [
      "self",
      "x",
      "pre_fea"
    ]
  },
  "Conv": {
    "__init__": [
      "self",
      "in_ch",
      "out_ch",
      "activation",
      "k",
      "s",
      "g"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SE": {
    "__init__": [
      "self",
      "ch",
      "r"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EfficientNet": {
    "__init__": [
      "self",
      "pretrained"
    ],
    "forward_single_frame": [
      "self",
      "x"
    ],
    "forward_time_series": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ],
    "export": [
      "self"
    ]
  },
  "MattingNetwork": {
    "__init__": [
      "self",
      "pretrained_backbone"
    ],
    "forward": [
      "self",
      "src",
      "r0",
      "r1",
      "r2",
      "r3",
      "downsample_ratio",
      "segmentation_pass"
    ],
    "_interpolate": [
      "self",
      "x",
      "scale_factor"
    ]
  },
  "ASP_OC_Module": {
    "__init__": [
      "self",
      "features",
      "out_features",
      "dilations"
    ],
    "_cat_each": [
      "self",
      "feat1",
      "feat2",
      "feat3",
      "feat4",
      "feat5"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LRASPP": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward_single_frame": [
      "self",
      "x"
    ],
    "forward_time_series": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_change_points": [
    "video_feat",
    "n_frame"
  ],
  "knap_sack": [
    "W",
    "wt",
    "val",
    "n"
  ],
  "generate_summary": [
    "all_shot_bound",
    "all_scores",
    "all_nframes",
    "all_positions"
  ],
  "transform_time": [
    "seconds"
  ],
  "summary_format": [
    "summary",
    "fps"
  ],
  "PGLVideoSummarization": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_train_forward": [
      "self",
      "input"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Inception": {
    "__init__": [
      "self",
      "in_channels",
      "ch1x1",
      "ch3x3red",
      "ch3x3",
      "ch5x5red",
      "ch5x5",
      "pool_proj"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GoogLeNet": {
    "__init__": [
      "self",
      "num_classes"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "bvlc_googlenet": {
    "__init__": [
      "self",
      "input_size"
    ],
    "forward": [
      "self",
      "frame"
    ]
  },
  "MultiAttention": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "freq",
      "pos_enc",
      "num_segments",
      "heads",
      "fusion"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PGL_SUM": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "freq",
      "pos_enc",
      "num_segments",
      "heads",
      "fusion"
    ],
    "forward": [
      "self",
      "frame_features"
    ]
  },
  "cpd_auto": [
    "K",
    "ncp",
    "vmax",
    "desc_rate"
  ],
  "calc_scatters": [
    "K"
  ],
  "cpd_nonlin": [
    "K",
    "ncp",
    "lmin",
    "lmax",
    "backtrack",
    "verbose",
    "out_scatters"
  ],
  "get_fid_net": [
    "resize_input",
    "normalize_input"
  ],
  "get_is_net": [
    "resize_input",
    "normalize_input"
  ],
  "compute_fid": [
    "real_feats",
    "fake_feats",
    "eps"
  ],
  "compute_prdc": [
    "real_feats",
    "fake_feats",
    "knn"
  ],
  "compute_is": [
    "logits",
    "num_splits"
  ],
  "make_irregular_mask": [
    "w",
    "h",
    "max_angle",
    "max_length",
    "max_width",
    "min_strokes",
    "max_strokes",
    "mode"
  ],
  "make_rectangle_mask": [
    "w",
    "h",
    "margin",
    "min_size",
    "max_size",
    "min_strokes",
    "max_strokes"
  ],
  "make_uncrop": [
    "w",
    "h"
  ],
  "TFS_CLIENT": [],
  "ceil_divide": [
    "a",
    "b"
  ],
  "rand_name": [
    "length",
    "suffix"
  ],
  "ema": [
    "net_ema",
    "net",
    "beta",
    "copy_buffer"
  ],
  "parallel": [
    "func",
    "args_list",
    "num_workers",
    "timeout"
  ],
  "unzip": [
    "filename",
    "dst_dir"
  ],
  "inverse_indices": [
    "indices"
  ],
  "detect_duplicates": [
    "feats",
    "thr"
  ],
  "md5": [
    "filename"
  ],
  "rope": [
    "x"
  ],
  "format_state": [
    "state",
    "filename"
  ],
  "breakup_grid": [
    "img",
    "grid_size"
  ],
  "viz_anno_geometry": [
    "item"
  ],
  "image_to_base64": [
    "img",
    "format"
  ],
  "COLORMAP": [],
  "RandomColor": {
    "__init__": [
      "self",
      "seed"
    ],
    "generate": [
      "self",
      "hue",
      "luminosity",
      "count",
      "format_"
    ],
    "pick_hue": [
      "self",
      "hue"
    ],
    "pick_saturation": [
      "self",
      "hue",
      "hue_name",
      "luminosity"
    ],
    "pick_brightness": [
      "self",
      "H",
      "S",
      "luminosity"
    ],
    "set_format": [
      "self",
      "hsv",
      "format_"
    ],
    "get_minimum_brightness": [
      "self",
      "H",
      "S"
    ],
    "get_hue_range": [
      "self",
      "color_input"
    ],
    "get_saturation_range": [
      "self",
      "hue"
    ],
    "get_color_info": [
      "self",
      "hue"
    ],
    "random_within": [
      "self",
      "r"
    ],
    "hsv_to_rgb": [
      "cls",
      "hsv"
    ]
  },
  "rand_color": [],
  "SVD": {
    "__init__": [
      "self",
      "h"
    ],
    "U": [
      "self",
      "x"
    ],
    "Ut": [
      "self",
      "x"
    ],
    "V": [
      "self",
      "x"
    ],
    "Vt": [
      "self",
      "x"
    ],
    "D": [
      "self"
    ],
    "H": [
      "self",
      "x"
    ],
    "Ht": [
      "self",
      "x"
    ],
    "Hinv": [
      "self",
      "x"
    ],
    "_pad": [
      "self",
      "x"
    ],
    "to": [
      "self"
    ]
  },
  "IdentitySVD": {
    "__init__": [
      "self",
      "c",
      "h",
      "w"
    ],
    "U": [
      "self",
      "x"
    ],
    "Ut": [
      "self",
      "x"
    ],
    "V": [
      "self",
      "x"
    ],
    "Vt": [
      "self",
      "x"
    ],
    "H": [
      "self",
      "x"
    ],
    "Ht": [
      "self",
      "x"
    ],
    "Hinv": [
      "self",
      "x"
    ],
    "_pad": [
      "self",
      "x"
    ]
  },
  "DenoiseSVD": {
    "__init__": [
      "self",
      "c",
      "h",
      "w"
    ],
    "U": [
      "self",
      "x"
    ],
    "Ut": [
      "self",
      "x"
    ],
    "V": [
      "self",
      "x"
    ],
    "Vt": [
      "self",
      "x"
    ],
    "_pad": [
      "self",
      "x"
    ]
  },
  "ColorizationSVD": {
    "__init__": [
      "self",
      "c",
      "h",
      "w"
    ],
    "U": [
      "self",
      "x"
    ],
    "Ut": [
      "self",
      "x"
    ],
    "V": [
      "self",
      "x"
    ],
    "Vt": [
      "self",
      "x"
    ],
    "D": [
      "self"
    ],
    "_pad": [
      "self",
      "x"
    ]
  },
  "imread_uint": [
    "path",
    "n_channels"
  ],
  "uint2single": [
    "img"
  ],
  "single2uint": [
    "img"
  ],
  "uint162single": [
    "img"
  ],
  "single2uint16": [
    "img"
  ],
  "rgb2ycbcr": [
    "img",
    "only_y"
  ],
  "ycbcr2rgb": [
    "img"
  ],
  "channel_convert": [
    "in_c",
    "tar_type",
    "img_list"
  ],
  "ssim": [
    "img1",
    "img2"
  ],
  "imresize_np": [
    "img",
    "scale",
    "antialiasing"
  ],
  "modcrop_np": [
    "img",
    "sf"
  ],
  "analytic_kernel": [
    "k"
  ],
  "anisotropic_Gaussian": [
    "ksize",
    "theta",
    "l1",
    "l2"
  ],
  "gm_blur_kernel": [
    "mean",
    "cov",
    "size"
  ],
  "shift_pixel": [
    "x",
    "sf",
    "upper_left"
  ],
  "blur": [
    "x",
    "k"
  ],
  "gen_kernel": [
    "k_size",
    "scale_factor",
    "min_var",
    "max_var",
    "noise_level"
  ],
  "fspecial_gaussian": [
    "hsize",
    "sigma"
  ],
  "fspecial_laplacian": [
    "alpha"
  ],
  "fspecial": [
    "filter_type"
  ],
  "bicubic_degradation": [
    "x",
    "sf"
  ],
  "srmd_degradation": [
    "x",
    "k",
    "sf"
  ],
  "dpsr_degradation": [
    "x",
    "k",
    "sf"
  ],
  "classical_degradation": [
    "x",
    "k",
    "sf"
  ],
  "add_sharpening": [
    "img",
    "weight",
    "radius",
    "threshold"
  ],
  "add_blur_1": [
    "img",
    "sf"
  ],
  "add_resize": [
    "img",
    "sf"
  ],
  "add_Gaussian_noise": [
    "img",
    "noise_level1",
    "noise_level2"
  ],
  "add_speckle_noise": [
    "img",
    "noise_level1",
    "noise_level2"
  ],
  "add_Poisson_noise": [
    "img"
  ],
  "add_JPEG_noise": [
    "img"
  ],
  "random_crop": [
    "lq",
    "hq",
    "sf",
    "lq_patchsize"
  ],
  "degradation_bsrgan_light": [
    "image",
    "sf",
    "isp_model"
  ],
  "add_blur_2": [
    "img",
    "sf"
  ],
  "degradation_bsrgan": [
    "image",
    "sf",
    "isp_model"
  ],
  "ImageFolder": {
    "__init__": [
      "self",
      "paths",
      "transforms"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "FeatureExtractor": {
    "__init__": [
      "self",
      "model",
      "checkpoint",
      "resolution",
      "mean",
      "std",
      "batch_size",
      "device"
    ],
    "__call__": [
      "self",
      "imgs",
      "num_workers"
    ],
    "batch_process": [
      "self",
      "paths"
    ]
  },
  "Classifier": {
    "__init__": [
      "self",
      "model",
      "checkpoint",
      "num_classes",
      "resolution",
      "mean",
      "std",
      "batch_size",
      "device"
    ],
    "__call__": [
      "self",
      "imgs",
      "num_workers"
    ]
  },
  "Text2Image": {
    "__init__": [
      "self",
      "vqgan_dim",
      "vqgan_z_dim",
      "vqgan_dim_mult",
      "vqgan_num_res_blocks",
      "vqgan_attn_scales",
      "vqgan_codebook_size",
      "vqgan_beta",
      "gpt_txt_vocab_size",
      "gpt_txt_seq_len",
      "gpt_img_seq_len",
      "gpt_dim",
      "gpt_num_heads",
      "gpt_num_layers",
      "vqgan_checkpoint",
      "gpt_checkpoint",
      "tokenizer",
      "batch_size",
      "device"
    ],
    "__call__": [
      "self",
      "txts",
      "top_k",
      "top_p",
      "temperature",
      "use_fp16"
    ],
    "_whiten_borders": [
      "self",
      "imgs"
    ]
  },
  "Sole2Shoe": {
    "__init__": [
      "self",
      "vqgan_dim",
      "vqgan_z_dim",
      "vqgan_dim_mult",
      "vqgan_num_res_blocks",
      "vqgan_attn_scales",
      "vqgan_codebook_size",
      "vqgan_beta",
      "src_resolution",
      "tar_resolution",
      "gpt_dim",
      "gpt_num_heads",
      "gpt_num_layers",
      "vqgan_checkpoint",
      "gpt_checkpoint",
      "batch_size",
      "device"
    ],
    "__call__": [
      "self",
      "sole_imgs",
      "top_k",
      "top_p",
      "temperature",
      "use_fp16",
      "num_workers"
    ],
    "_whiten_borders": [
      "self",
      "imgs"
    ]
  },
  "ImageParser": {
    "__init__": [
      "self",
      "model",
      "num_classes",
      "resolution",
      "mean",
      "std",
      "model_with_softmax",
      "checkpoint",
      "batch_size",
      "device"
    ],
    "__call__": [
      "self",
      "imgs",
      "num_workers"
    ]
  },
  "TextImageMatch": {
    "__init__": [
      "self",
      "embed_dim",
      "image_size",
      "patch_size",
      "vision_dim",
      "vision_heads",
      "vision_layers",
      "vocab_size",
      "text_len",
      "text_dim",
      "text_heads",
      "text_layers",
      "mean",
      "std",
      "checkpoint",
      "tokenizer",
      "batch_size",
      "device"
    ],
    "__call__": [
      "self",
      "imgs",
      "txts",
      "num_workers"
    ]
  },
  "taobao_feature_extractor": [
    "category"
  ],
  "singleton_classifier": [],
  "orientation_classifier": [],
  "fashion_text2image": [],
  "mindalle_text2image": [],
  "sole2shoe": [],
  "sole_parser": [],
  "sod_foreground_parser": [],
  "fashion_text_image_match": [],
  "normalize_fn": [
    "tensor",
    "mean",
    "std"
  ],
  "NormalizeByChannelMeanStd": {
    "__init__": [
      "self",
      "mean",
      "std"
    ],
    "forward": [
      "self",
      "tensor"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "EasyRobustModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "TinynasDetector": {
    "__init__": [
      "self",
      "model_dir"
    ]
  },
  "parse_config": [
    "filename"
  ],
  "DamoYolo": {
    "__init__": [
      "self",
      "model_dir"
    ]
  },
  "SingleStageDetector": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "load_pretrain_model": [
      "self",
      "pretrain_model"
    ],
    "init_bn": [
      "self",
      "M"
    ],
    "forward": [
      "self",
      "x"
    ],
    "postprocess": [
      "self",
      "preds"
    ]
  },
  "postprocess_gfocal": [
    "prediction",
    "num_classes",
    "conf_thre",
    "nms_thre"
  ],
  "build_local_model": [
    "config",
    "device"
  ],
  "build_ddp_model": [
    "model",
    "local_rank"
  ],
  "compute_on_dataset": [
    "model",
    "data_loader",
    "device",
    "timer",
    "tta"
  ],
  "_accumulate_predictions_from_multiple_gpus": [
    "predictions_per_gpu",
    "multi_gpu_infer"
  ],
  "mkdir": [
    "path"
  ],
  "Evaluater": {
    "__init__": [
      "self",
      "cfg"
    ],
    "get_data_loader": [
      "self",
      "cfg",
      "distributed"
    ],
    "evaluate": [
      "self"
    ]
  },
  "cosine_scheduler": {
    "__init__": [
      "self",
      "base_lr_per_img",
      "batch_size",
      "min_lr_ratio",
      "total_iters",
      "no_aug_iters",
      "warmup_iters",
      "warmup_start_lr"
    ],
    "get_lr": [
      "self",
      "iters"
    ]
  },
  "ema_scheduler": [
    "x",
    "ema_momentum"
  ],
  "ema_model": {
    "__init__": [
      "self",
      "student",
      "ema_momentum"
    ],
    "update": [
      "self",
      "iters",
      "student"
    ]
  },
  "get_latency": [
    "model",
    "inp",
    "iters",
    "warmup"
  ],
  "get_model_info": [
    "model",
    "tsize"
  ],
  "fuse_conv_and_bn": [
    "conv",
    "bn"
  ],
  "replace_module": [
    "module",
    "replaced_module_type",
    "new_module_type",
    "replace_func"
  ],
  "bbox_overlaps": [
    "bboxes1",
    "bboxes2",
    "mode",
    "is_aligned",
    "eps"
  ],
  "filter_box": [
    "output",
    "scale_range"
  ],
  "filter_results": [
    "boxlist",
    "num_classes",
    "nms_thre"
  ],
  "matrix_iou": [
    "a",
    "b"
  ],
  "adjust_box_anns": [
    "bbox",
    "scale_ratio",
    "padw",
    "padh",
    "w_max",
    "h_max"
  ],
  "remove_small_boxes": [
    "boxlist",
    "min_size"
  ],
  "boxlist_iou": [
    "boxlist1",
    "boxlist2"
  ],
  "_cat": [
    "tensors",
    "dim"
  ],
  "cat_boxlist": [
    "bboxes"
  ],
  "FLIP_LEFT_RIGHT": [],
  "FLIP_TOP_BOTTOM": [],
  "BoxList": {
    "__init__": [
      "self",
      "bbox",
      "image_size",
      "mode"
    ],
    "add_field": [
      "self",
      "field",
      "field_data"
    ],
    "get_field": [
      "self",
      "field"
    ],
    "has_field": [
      "self",
      "field"
    ],
    "fields": [
      "self"
    ],
    "_copy_extra_fields": [
      "self",
      "bbox"
    ],
    "convert": [
      "self",
      "mode"
    ],
    "_split_into_xyxy": [
      "self"
    ],
    "resize": [
      "self",
      "size"
    ],
    "transpose": [
      "self",
      "method"
    ],
    "crop": [
      "self",
      "box"
    ],
    "to": [
      "self",
      "device"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "__len__": [
      "self"
    ],
    "clip_to_image": [
      "self",
      "remove_empty"
    ],
    "area": [
      "self"
    ],
    "copy_with_fields": [
      "self",
      "fields",
      "skip_missing"
    ],
    "__repr__": [
      "self"
    ]
  },
  "to_image_list": [
    "tensors",
    "size_divisible",
    "max_size"
  ],
  "SA_Aug": {
    "__init__": [
      "self",
      "iters_per_epoch",
      "start_epoch",
      "total_epochs",
      "no_aug_epochs",
      "batch_size",
      "num_gpus",
      "num_workers",
      "sada_cfg"
    ],
    "__call__": [
      "self",
      "tensor",
      "target"
    ]
  },
  "_gaussian_map": [
    "img",
    "boxes",
    "scale_splits",
    "scale_ratios"
  ],
  "_merge_gaussian": [
    "img",
    "img_aug",
    "boxes",
    "scale_ratios",
    "scale_splits"
  ],
  "_box_sample_prob": [
    "bbox",
    "scale_ratios_splits",
    "box_prob"
  ],
  "_box_aug_per_img": [
    "img",
    "target",
    "aug_type",
    "scale_ratios",
    "scale_splits",
    "img_prob",
    "box_prob",
    "level"
  ],
  "Box_augs": {
    "__init__": [
      "self",
      "box_augs_dict",
      "max_iters",
      "scale_splits",
      "box_prob"
    ],
    "__call__": [
      "self",
      "tensor",
      "target",
      "iteration"
    ]
  },
  "_MAX_LEVEL": [],
  "pixel_mean": [],
  "scale_area": [
    "box",
    "height",
    "width",
    "scale_ratio"
  ],
  "_geometric_aug_func": [
    "x",
    "target",
    "angle",
    "translate",
    "scale",
    "shear",
    "hflip",
    "boxes_sample_prob",
    "scale_ratio"
  ],
  "geometric_aug_func": [],
  "solarize": [
    "image",
    "threshold"
  ],
  "solarize_add": [
    "image",
    "addition",
    "threshold"
  ],
  "color": [
    "img",
    "factor"
  ],
  "contrast": [
    "img",
    "factor"
  ],
  "brightness": [
    "image",
    "factor"
  ],
  "sharpness": [
    "image",
    "factor"
  ],
  "equalize": [
    "image"
  ],
  "autocontrast": [
    "image"
  ],
  "posterize": [
    "image",
    "bits"
  ],
  "_color_aug_func": [
    "img",
    "img_aug",
    "target",
    "scale_ratios_splits",
    "box_sample_probs"
  ],
  "color_aug_func": [],
  "ConvKXBN": {
    "__init__": [
      "self",
      "in_c",
      "out_c",
      "kernel_size",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ],
    "fuseforward": [
      "self",
      "x"
    ]
  },
  "ConvKXBNRELU": {
    "__init__": [
      "self",
      "in_c",
      "out_c",
      "kernel_size",
      "stride",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResConvBlock": {
    "__init__": [
      "self",
      "in_c",
      "out_c",
      "btn_c",
      "kernel_size",
      "stride",
      "act",
      "reparam",
      "block_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CSPStem": {
    "__init__": [
      "self",
      "in_c",
      "out_c",
      "btn_c",
      "stride",
      "kernel_size",
      "num_blocks",
      "act",
      "reparam",
      "block_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TinyNAS": {
    "__init__": [
      "self",
      "structure_info",
      "out_indices",
      "with_spp",
      "use_focus",
      "act",
      "reparam"
    ],
    "init_weights": [
      "self",
      "pretrain"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CSPWrapper": {
    "__init__": [
      "self",
      "convstem",
      "act",
      "reparam",
      "with_spp"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "load_tinynas_net": [
    "backbone_cfg"
  ],
  "SuperResStem": {
    "__init__": [
      "self",
      "in_c",
      "out_c",
      "btn_c",
      "kernel_size",
      "stride",
      "num_blocks",
      "with_spp",
      "act",
      "reparam",
      "block_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "reduce_loss": [
    "loss",
    "reduction"
  ],
  "weighted_loss": [
    "loss_func"
  ],
  "weight_reduce_loss": [
    "loss",
    "weight",
    "reduction",
    "avg_factor"
  ],
  "giou_loss": [
    "pred",
    "target",
    "eps"
  ],
  "GIoULoss": {
    "__init__": [
      "self",
      "eps",
      "reduction",
      "loss_weight"
    ],
    "forward": [
      "self",
      "pred",
      "target",
      "weight",
      "avg_factor",
      "reduction_override"
    ]
  },
  "distribution_focal_loss": [
    "pred",
    "label"
  ],
  "DistributionFocalLoss": {
    "__init__": [
      "self",
      "reduction",
      "loss_weight"
    ],
    "forward": [
      "self",
      "pred",
      "target",
      "weight",
      "avg_factor",
      "reduction_override"
    ]
  },
  "quality_focal_loss": [
    "pred",
    "target",
    "beta",
    "use_sigmoid"
  ],
  "QualityFocalLoss": {
    "__init__": [
      "self",
      "use_sigmoid",
      "beta",
      "reduction",
      "loss_weight"
    ],
    "forward": [
      "self",
      "pred",
      "target",
      "weight",
      "avg_factor",
      "reduction_override"
    ]
  },
  "FeatureLoss": {
    "__init__": [
      "self",
      "channels_s",
      "channels_t",
      "distiller",
      "loss_weight"
    ],
    "forward": [
      "self",
      "y_s",
      "y_t"
    ]
  },
  "MimicLoss": {
    "__init__": [
      "self",
      "channels_s",
      "channels_t"
    ],
    "forward": [
      "self",
      "y_s",
      "y_t"
    ]
  },
  "MGDLoss": {
    "__init__": [
      "self",
      "channels_s",
      "channels_t",
      "alpha_mgd",
      "lambda_mgd"
    ],
    "forward": [
      "self",
      "y_s",
      "y_t"
    ],
    "get_dis_loss": [
      "self",
      "preds_S",
      "preds_T",
      "idx"
    ]
  },
  "CWDLoss": {
    "__init__": [
      "self",
      "channels_s",
      "channels_t",
      "tau"
    ],
    "forward": [
      "self",
      "y_s",
      "y_t"
    ]
  },
  "GiraffeNeckV2": {
    "__init__": [
      "self",
      "depth",
      "hidden_ratio",
      "in_features",
      "in_channels",
      "out_channels",
      "act",
      "spp",
      "block_name"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "out_features"
    ]
  },
  "_ACT_LAYER": [],
  "SequentialList": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvBnAct2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "padding",
      "bias",
      "norm_layer",
      "act_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SeparableConv2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "padding",
      "bias",
      "channel_multiplier",
      "pw_kernel_size",
      "norm_layer",
      "act_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_init_weight": [
    "m",
    "n"
  ],
  "_init_weight_alt": [
    "m",
    "n"
  ],
  "Interpolate2d": {
    "__constants__": [],
    "__init__": [
      "self",
      "size",
      "scale_factor",
      "mode",
      "align_corners"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ResampleFeatureMap": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "reduction_ratio",
      "pad_type",
      "downsample",
      "upsample",
      "norm_layer",
      "apply_bn",
      "conv_after_downsample",
      "redundant_bias"
    ]
  },
  "GiraffeCombine": {
    "__init__": [
      "self",
      "feature_info",
      "fpn_config",
      "fpn_channels",
      "inputs_offsets",
      "target_reduction",
      "pad_type",
      "downsample",
      "upsample",
      "norm_layer",
      "apply_resample_bn",
      "conv_after_downsample",
      "redundant_bias",
      "weight_method"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GiraffeNode": {
    "__init__": [
      "self",
      "combine",
      "after_combine"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GiraffeLayer": {
    "__init__": [
      "self",
      "feature_info",
      "fpn_config",
      "inner_fpn_channels",
      "outer_fpn_channels",
      "num_levels",
      "pad_type",
      "downsample",
      "upsample",
      "norm_layer",
      "act_layer",
      "apply_resample_bn",
      "conv_after_downsample",
      "conv_bn_relu_pattern",
      "separable_conv",
      "redundant_bias",
      "merge_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GiraffeNeck": {
    "__init__": [
      "self",
      "min_level",
      "max_level",
      "num_levels",
      "norm_layer",
      "norm_kwargs",
      "act_type",
      "fpn_config",
      "fpn_name",
      "fpn_channels",
      "out_fpn_channels",
      "weight_method",
      "depth_multiplier",
      "width_multiplier",
      "with_backslash",
      "with_slash",
      "with_skip_connect",
      "skip_connect_type",
      "separable_conv",
      "feature_info",
      "merge_type",
      "pad_type",
      "downsample_type",
      "upsample_type",
      "apply_resample_bn",
      "conv_after_downsample",
      "redundant_bias",
      "conv_bn_relu_pattern",
      "alternate_init"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Node": [],
  "get_graph_info": [
    "graph"
  ],
  "nodeid_trans": [
    "id",
    "cur_level",
    "num_levels"
  ],
  "gen_log2n_graph_file": [
    "log2n_graph_file",
    "depth_multiplier"
  ],
  "get_log2n_graph": [
    "depth_multiplier"
  ],
  "get_dense_graph": [
    "depth_multiplier"
  ],
  "giraffeneck_config": [
    "min_level",
    "max_level",
    "weight_method",
    "depth_multiplier",
    "with_backslash",
    "with_slash",
    "with_skip_connect",
    "skip_connect_type"
  ],
  "get_graph_config": [
    "fpn_name",
    "min_level",
    "max_level",
    "weight_method",
    "depth_multiplier",
    "with_backslash",
    "with_slash",
    "with_skip_connect",
    "skip_connect_type"
  ],
  "bbox2distance": [
    "points",
    "bbox",
    "max_dis",
    "eps"
  ],
  "ZeroHead": {
    "__init__": [
      "self",
      "num_classes",
      "in_channels",
      "stacked_convs",
      "feat_channels",
      "reg_max",
      "strides",
      "norm",
      "act",
      "nms_conf_thre",
      "nms_iou_thre",
      "nms"
    ],
    "_build_not_shared_convs": [
      "self",
      "in_channel",
      "feat_channels"
    ],
    "_init_layers": [
      "self"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "xin",
      "labels",
      "imgs",
      "aux_targets"
    ],
    "forward_train": [
      "self",
      "xin",
      "labels",
      "imgs",
      "aux_targets"
    ],
    "forward_eval": [
      "self",
      "xin",
      "labels",
      "imgs"
    ],
    "forward_single": [
      "self",
      "x",
      "cls_convs",
      "reg_convs",
      "gfl_cls",
      "gfl_reg",
      "scale"
    ],
    "get_single_level_center_priors": [
      "self",
      "batch_size",
      "featmap_size",
      "stride",
      "dtype",
      "device"
    ],
    "loss": [
      "self",
      "cls_scores",
      "bbox_preds",
      "bbox_before_softmax",
      "gt_bboxes",
      "gt_labels",
      "mlvl_center_priors",
      "gt_bboxes_ignore"
    ],
    "get_targets": [
      "self",
      "cls_scores",
      "bbox_preds",
      "gt_bboxes_list",
      "mlvl_center_priors",
      "gt_labels_list",
      "unmap_outputs"
    ],
    "get_target_single": [
      "self",
      "center_priors",
      "cls_scores",
      "bbox_preds",
      "gt_bboxes",
      "gt_labels",
      "unmap_outputs",
      "gt_bboxes_ignore"
    ],
    "sample": [
      "self",
      "assign_result",
      "gt_bboxes"
    ]
  },
  "multi_apply": [
    "func"
  ],
  "xyxy2CxCywh": [
    "xyxy",
    "size"
  ],
  "GFocalHead_Tiny": {
    "__init__": [
      "self",
      "num_classes",
      "in_channels",
      "stacked_convs",
      "feat_channels",
      "reg_max",
      "reg_topk",
      "reg_channels",
      "strides",
      "add_mean",
      "norm",
      "act",
      "start_kernel_size",
      "conv_groups",
      "conv_type",
      "simOTA_cls_weight",
      "simOTA_iou_weight",
      "octbase",
      "simlqe",
      "use_lqe"
    ],
    "_build_not_shared_convs": [
      "self",
      "in_channel",
      "feat_channels"
    ],
    "_init_layers": [
      "self"
    ],
    "forward": [
      "self",
      "xin",
      "labels",
      "imgs",
      "conf_thre",
      "nms_thre"
    ],
    "forward_single": [
      "self",
      "x",
      "cls_convs",
      "reg_convs",
      "gfl_cls",
      "gfl_reg",
      "reg_conf",
      "scale"
    ],
    "get_single_level_center_priors": [
      "self",
      "batch_size",
      "featmap_size",
      "stride",
      "dtype",
      "device"
    ],
    "sample": [
      "self",
      "assign_result",
      "gt_bboxes"
    ],
    "get_bboxes": [
      "self",
      "cls_preds",
      "reg_preds",
      "mlvl_center_priors",
      "img_meta"
    ]
  },
  "BaseAssigner": {
    "assign": [
      "self",
      "bboxes",
      "gt_bboxes",
      "gt_bboxes_ignore",
      "gt_labels"
    ]
  },
  "AssignResult": {
    "__init__": [
      "self",
      "num_gts",
      "gt_inds",
      "max_overlaps",
      "labels"
    ],
    "num_preds": [
      "self"
    ],
    "set_extra_property": [
      "self",
      "key",
      "value"
    ],
    "get_extra_property": [
      "self",
      "key"
    ],
    "info": [
      "self"
    ],
    "random": [
      "cls"
    ],
    "add_gt_": [
      "self",
      "gt_labels"
    ]
  },
  "AlignOTAAssigner": {
    "__init__": [
      "self",
      "center_radius",
      "candidate_topk",
      "iou_weight",
      "cls_weight"
    ],
    "assign": [
      "self",
      "pred_scores",
      "priors",
      "decoded_bboxes",
      "gt_bboxes",
      "gt_labels",
      "gt_bboxes_ignore",
      "eps"
    ],
    "_assign": [
      "self",
      "pred_scores",
      "priors",
      "decoded_bboxes",
      "gt_bboxes",
      "gt_labels",
      "gt_bboxes_ignore",
      "eps"
    ],
    "get_in_gt_and_in_center_info": [
      "self",
      "priors",
      "gt_bboxes"
    ],
    "dynamic_k_matching": [
      "self",
      "cost",
      "pairwise_ious",
      "num_gt",
      "valid_mask"
    ]
  },
  "unmap": [
    "data",
    "count",
    "inds",
    "fill"
  ],
  "reduce_mean": [
    "tensor"
  ],
  "images_to_levels": [
    "target",
    "num_levels"
  ],
  "Swish": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvBNAct": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "ksize",
      "stride",
      "groups",
      "bias",
      "act",
      "norm",
      "reparam"
    ],
    "forward": [
      "self",
      "x"
    ],
    "fuseforward": [
      "self",
      "x"
    ]
  },
  "BasicBlock_3x3_Reverse": {
    "__init__": [
      "self",
      "ch_in",
      "ch_hidden_ratio",
      "ch_out",
      "act",
      "shortcut"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SPP": {
    "__init__": [
      "self",
      "ch_in",
      "ch_out",
      "k",
      "pool_size",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CSPStage": {
    "__init__": [
      "self",
      "block_fn",
      "ch_in",
      "ch_hidden_ratio",
      "ch_out",
      "n",
      "act",
      "spp"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RepConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "padding_mode",
      "deploy",
      "act",
      "norm"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "get_equivalent_kernel_bias": [
      "self"
    ],
    "_pad_1x1_to_3x3_tensor": [
      "self",
      "kernel1x1"
    ],
    "_fuse_bn_tensor": [
      "self",
      "branch"
    ],
    "switch_to_deploy": [
      "self"
    ]
  },
  "ConvBNLayer": {
    "__init__": [
      "self",
      "ch_in",
      "ch_out",
      "filter_size",
      "stride",
      "groups",
      "padding",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RepVGGBlock": {
    "__init__": [
      "self",
      "ch_in",
      "ch_out",
      "act",
      "deploy"
    ],
    "forward": [
      "self",
      "x"
    ],
    "switch_to_deploy": [
      "self"
    ],
    "get_equivalent_kernel_bias": [
      "self"
    ],
    "_pad_1x1_to_3x3_tensor": [
      "self",
      "kernel1x1"
    ],
    "_fuse_bn_tensor": [
      "self",
      "branch"
    ]
  },
  "BasicBlock_3x3": {
    "__init__": [
      "self",
      "ch_in",
      "ch_out",
      "act",
      "shortcut"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DepthWiseConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "ksize",
      "stride",
      "groups",
      "bias",
      "act",
      "norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "fast_Focus": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "ksize",
      "stride",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ],
    "focus_conv": [
      "self",
      "w1",
      "w2",
      "w3",
      "w4"
    ],
    "init_weights_constant": [
      "self",
      "w1",
      "w2",
      "w3",
      "w4"
    ]
  },
  "conv_1x1_bn": [
    "in_c",
    "out_c",
    "stride"
  ],
  "ShuffleBlock": {
    "__init__": [
      "self",
      "in_c",
      "out_c",
      "downsample"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ShuffleCSPLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "n",
      "shortcut",
      "expansion",
      "depthwise",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "bias_init_with_prob": [
    "prior_prob"
  ],
  "RepVggBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "padding_mode",
      "deploy",
      "use_se",
      "act",
      "norm"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "get_equivalent_kernel_bias": [
      "self"
    ],
    "_pad_1x1_to_3x3_tensor": [
      "self",
      "kernel1x1"
    ],
    "_fuse_bn_tensor": [
      "self",
      "branch"
    ],
    "switch_to_deploy": [
      "self"
    ]
  },
  "set_requires_grad": [
    "module",
    "value"
  ],
  "add_prefix_to_keys": [
    "dct",
    "prefix"
  ],
  "LadderRamp": {
    "__init__": [
      "self",
      "start_iters",
      "values"
    ],
    "__call__": [
      "self",
      "i"
    ]
  },
  "get_ramp": [
    "kind"
  ],
  "DefaultInpaintingTrainingModule": {
    "__init__": [
      "self",
      "model_dir",
      "predict_only",
      "concat_mask",
      "rescale_scheduler_kwargs",
      "image_to_discriminator",
      "add_noise_kwargs",
      "noise_fill_hole",
      "const_area_crop_kwargs",
      "distance_weighter_kwargs",
      "distance_weighted_mask_for_discr",
      "fake_fakes_proba",
      "fake_fakes_generator_kwargs"
    ],
    "forward": [
      "self",
      "batch"
    ],
    "generator_loss": [
      "self",
      "batch"
    ],
    "discriminator_loss": [
      "self",
      "batch"
    ],
    "_do_step": [
      "self",
      "batch",
      "optimizer_idx"
    ]
  },
  "BaseInpaintingTrainingModule": {
    "__init__": [
      "self",
      "model_dir",
      "use_ddp",
      "predict_only",
      "visualize_each_iters",
      "average_generator",
      "generator_avg_beta",
      "average_generator_start_step",
      "average_generator_period",
      "store_discr_outputs_for_vis"
    ],
    "forward": [
      "self",
      "batch"
    ],
    "generator_loss": [
      "self",
      "batch"
    ],
    "discriminator_loss": [
      "self",
      "batch"
    ]
  },
  "move_to_device": [
    "obj",
    "device"
  ],
  "ceil_modulo": [
    "x",
    "mod"
  ],
  "pad_tensor_to_modulo": [
    "img",
    "mod"
  ],
  "_pyrdown": [
    "im",
    "downsize"
  ],
  "_pyrdown_mask": [
    "mask",
    "downsize",
    "eps",
    "blur_mask",
    "round_up"
  ],
  "_erode_mask": [
    "mask",
    "ekernel",
    "eps"
  ],
  "_l1_loss": [
    "pred",
    "pred_downscaled",
    "ref",
    "mask",
    "mask_downscaled",
    "image",
    "on_pred"
  ],
  "_get_image_mask_pyramid": [
    "batch",
    "min_side",
    "max_scales",
    "px_budget"
  ],
  "refine_predict": [
    "batch",
    "inpainter",
    "gpu_ids",
    "modulo",
    "n_iters",
    "lr",
    "min_side",
    "max_scales",
    "px_budget"
  ],
  "FFTInpainting": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "NLayerDiscriminator": {
    "__init__": [
      "self",
      "input_nc",
      "ndf",
      "n_layers",
      "norm_layer"
    ],
    "get_all_activations": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FID_WEIGHTS_URL": [],
  "InceptionV3": {
    "DEFAULT_BLOCK_INDEX": [],
    "BLOCK_INDEX_BY_DIM": [],
    "__init__": [
      "self",
      "output_blocks",
      "resize_input",
      "normalize_input",
      "requires_grad",
      "use_fid_inception"
    ],
    "forward": [
      "self",
      "inp"
    ]
  },
  "fid_inception_v3": [],
  "FIDInceptionA": {
    "__init__": [
      "self",
      "in_channels",
      "pool_features"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FIDInceptionC": {
    "__init__": [
      "self",
      "in_channels",
      "channels_7x7"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FIDInceptionE_1": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FIDInceptionE_2": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "masked_l2_loss": [
    "pred",
    "target",
    "mask",
    "weight_known",
    "weight_missing"
  ],
  "masked_l1_loss": [
    "pred",
    "target",
    "mask",
    "weight_known",
    "weight_missing"
  ],
  "feature_matching_loss": [
    "fake_features",
    "target_features",
    "mask"
  ],
  "FourierUnit": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "groups",
      "spatial_scale_factor",
      "spatial_scale_mode",
      "spectral_pos_encoding",
      "use_se",
      "se_kwargs",
      "ffc3d",
      "fft_norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SpectralTransform": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "groups",
      "enable_lfu"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LearnableSpatialTransformWrapper": {
    "__init__": [
      "self",
      "impl",
      "pad_coef",
      "angle_init_range",
      "train_angle"
    ],
    "forward": [
      "self",
      "x"
    ],
    "transform": [
      "self",
      "x"
    ],
    "inverse_transform": [
      "self",
      "y_padded_rotated",
      "orig_x"
    ]
  },
  "FFC": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "ratio_gin",
      "ratio_gout",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "enable_lfu",
      "padding_type",
      "gated"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FFC_BN_ACT": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "ratio_gin",
      "ratio_gout",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "norm_layer",
      "activation_layer",
      "padding_type",
      "enable_lfu"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FFCResnetBlock": {
    "__init__": [
      "self",
      "dim",
      "padding_type",
      "norm_layer",
      "activation_layer",
      "dilation",
      "spatial_transform_kwargs",
      "inline"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConcatTupleLayer": {
    "forward": [
      "self",
      "x"
    ]
  },
  "FFCResNetGenerator": {
    "__init__": [
      "self",
      "input_nc",
      "output_nc",
      "ngf",
      "n_downsampling",
      "n_blocks",
      "norm_layer",
      "padding_type",
      "activation_layer",
      "up_norm_layer",
      "up_activation",
      "init_conv_kwargs",
      "downsample_conv_kwargs",
      "resnet_conv_kwargs",
      "spatial_transform_layers",
      "spatial_transform_kwargs",
      "add_out_act",
      "max_features",
      "out_ffc",
      "out_ffc_kwargs"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ResNetPL": {
    "__init__": [
      "self",
      "weight",
      "weights_path",
      "arch_encoder",
      "segmentation"
    ],
    "forward": [
      "self",
      "pred",
      "target"
    ]
  },
  "BaseAdversarialLoss": {
    "pre_generator_step": [
      "self",
      "real_batch",
      "fake_batch",
      "generator",
      "discriminator"
    ],
    "pre_discriminator_step": [
      "self",
      "real_batch",
      "fake_batch",
      "generator",
      "discriminator"
    ],
    "generator_loss": [
      "self",
      "real_batch",
      "fake_batch",
      "discr_real_pred",
      "discr_fake_pred",
      "mask"
    ],
    "discriminator_loss": [
      "self",
      "real_batch",
      "fake_batch",
      "discr_real_pred",
      "discr_fake_pred",
      "mask"
    ],
    "interpolate_mask": [
      "self",
      "mask",
      "shape"
    ]
  },
  "make_r1_gp": [
    "discr_real_pred",
    "real_batch"
  ],
  "NonSaturatingWithR1": {
    "__init__": [
      "self",
      "gp_coef",
      "weight",
      "mask_as_fake_target",
      "allow_scale_mask",
      "mask_scale_mode",
      "extra_mask_weight_for_gen",
      "use_unmasked_for_gen",
      "use_unmasked_for_discr"
    ],
    "generator_loss": [
      "self",
      "real_batch",
      "fake_batch",
      "discr_real_pred",
      "discr_fake_pred",
      "mask"
    ],
    "pre_discriminator_step": [
      "self",
      "real_batch",
      "fake_batch",
      "generator",
      "discriminator"
    ],
    "discriminator_loss": [
      "self",
      "real_batch",
      "fake_batch",
      "discr_real_pred",
      "discr_fake_pred",
      "mask"
    ]
  },
  "NUM_CLASS": [],
  "ModelBuilder": {
    "weights_init": [
      "m"
    ],
    "build_encoder": [
      "arch",
      "fc_dim",
      "weights",
      "model_dir"
    ],
    "build_decoder": [
      "arch",
      "fc_dim",
      "num_class",
      "weights",
      "use_softmax",
      "drop_last_conv"
    ],
    "get_decoder": [
      "weights_path",
      "arch_encoder",
      "arch_decoder",
      "fc_dim",
      "drop_last_conv"
    ],
    "get_encoder": [
      "weights_path",
      "arch_encoder",
      "arch_decoder",
      "fc_dim",
      "segmentation"
    ]
  },
  "conv3x3_bn_relu": [
    "in_planes",
    "out_planes",
    "stride"
  ],
  "PPMDeepsup": {
    "__init__": [
      "self",
      "num_class",
      "fc_dim",
      "use_softmax",
      "pool_scales",
      "drop_last_conv"
    ],
    "forward": [
      "self",
      "conv_out",
      "segSize"
    ]
  },
  "Resnet": {
    "__init__": [
      "self",
      "orig_resnet"
    ],
    "forward": [
      "self",
      "x",
      "return_feature_maps"
    ]
  },
  "ResnetDilated": {
    "__init__": [
      "self",
      "orig_resnet",
      "dilate_scale"
    ],
    "_nostride_dilate": [
      "self",
      "m",
      "dilate"
    ],
    "forward": [
      "self",
      "x",
      "return_feature_maps"
    ]
  },
  "C1DeepSup": {
    "__init__": [
      "self",
      "num_class",
      "fc_dim",
      "use_softmax",
      "drop_last_conv"
    ],
    "forward": [
      "self",
      "conv_out",
      "segSize"
    ]
  },
  "C1": {
    "__init__": [
      "self",
      "num_class",
      "fc_dim",
      "use_softmax"
    ],
    "forward": [
      "self",
      "conv_out",
      "segSize"
    ]
  },
  "DepthEstimationBtsModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "inference": [
      "self",
      "data"
    ]
  },
  "BtsModel": {
    "__init__": [
      "self",
      "focal"
    ],
    "forward": [
      "self",
      "x",
      "focal"
    ]
  },
  "activation_fn": [],
  "MAX_DEPTH": [],
  "UpscaleLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "UpscaleBlock": {
    "__init__": [
      "self",
      "in_channels",
      "skip_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "input_j"
    ]
  },
  "UpscaleNetwork": {
    "__init__": [
      "self",
      "filters"
    ],
    "forward": [
      "self",
      "raw_input"
    ]
  },
  "AtrousBlock": {
    "__init__": [
      "self",
      "input_filters",
      "filters",
      "dilation",
      "apply_initial_bn"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ASSPBlock": {
    "__init__": [
      "self",
      "input_filters",
      "cat_filters",
      "atrous_filters"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Reduction": {
    "__init__": [
      "self",
      "scale",
      "input_filters",
      "is_final"
    ],
    "forward": [
      "self",
      "ip"
    ]
  },
  "LPGBlock": {
    "__init__": [
      "self",
      "scale",
      "input_filters"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "SceneFlowEstimation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "Inputs"
    ],
    "postprocess": [
      "self",
      "Inputs"
    ],
    "inference": [
      "self",
      "data"
    ]
  },
  "RADIUS": [],
  "index_points_group": [
    "points",
    "knn_idx"
  ],
  "curvature": [
    "pc",
    "nsample",
    "radius"
  ],
  "PointNetSetAbstractionRatio": {
    "__init__": [
      "self",
      "ratio",
      "radius",
      "nsample",
      "in_channel",
      "mlp",
      "group_all",
      "return_fps",
      "use_xyz",
      "use_act",
      "act",
      "mean_aggr",
      "use_instance_norm"
    ],
    "forward": [
      "self",
      "xyz",
      "points",
      "fps_idx"
    ]
  },
  "PointNetSetAbstraction": {
    "__init__": [
      "self",
      "npoint",
      "radius",
      "nsample",
      "in_channel",
      "mlp",
      "group_all",
      "return_fps",
      "use_xyz",
      "use_act",
      "act",
      "mean_aggr",
      "use_instance_norm"
    ],
    "forward": [
      "self",
      "xyz",
      "points",
      "fps_idx"
    ]
  },
  "PointNetFeaturePropogation": {
    "__init__": [
      "self",
      "in_channel",
      "mlp",
      "learn_mask",
      "nsample"
    ],
    "forward": [
      "self",
      "pos1",
      "pos2",
      "feature1",
      "feature2",
      "hidden"
    ]
  },
  "Sinkhorn": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "corr",
      "epsilon",
      "gamma",
      "max_iter"
    ]
  },
  "PointWiseOptimLayer": {
    "__init__": [
      "self",
      "nsample",
      "radius",
      "in_channel",
      "mlp",
      "use_curvature"
    ],
    "forward": [
      "self",
      "pos1",
      "pos2",
      "feature1",
      "feature2",
      "nsample",
      "radius",
      "pos1_raw",
      "return_score"
    ]
  },
  "FeatureMatching": {
    "__init__": [
      "self",
      "npoint",
      "use_instance_norm",
      "supporth_th",
      "feature_norm",
      "max_iter"
    ],
    "upsample_flow": [
      "self",
      "pc1_l",
      "pc1_l_glob",
      "flow_inp"
    ],
    "calc_feats_corr": [
      "self",
      "pcloud1",
      "pcloud2",
      "feature1",
      "feature2",
      "norm"
    ],
    "calc_corr_mat": [
      "self",
      "pcloud1",
      "pcloud2",
      "feature1",
      "feature2"
    ],
    "get_flow_init": [
      "self",
      "pcloud1",
      "pcloud2",
      "feats1",
      "feats2"
    ],
    "forward": [
      "self",
      "pc1_l",
      "pc2_l",
      "feats1",
      "feats2"
    ]
  },
  "FlowRegressor": {
    "__init__": [
      "self",
      "npoint",
      "use_instance_norm",
      "input_dim",
      "nsample"
    ],
    "forward": [
      "self",
      "pc1_l",
      "feats"
    ]
  },
  "FeatureExtractionGlobal": {
    "__init__": [
      "self",
      "npoint",
      "use_instance_norm"
    ],
    "forward": [
      "self",
      "pc",
      "feature"
    ]
  },
  "FeatureExtraction": {
    "__init__": [
      "self",
      "npoint",
      "use_instance_norm"
    ],
    "forward": [
      "self",
      "pc",
      "feature",
      "fps_idx"
    ]
  },
  "HiddenInitNet": {
    "__init__": [
      "self",
      "npoint",
      "use_instance_norm"
    ],
    "forward": [
      "self",
      "pc",
      "feature"
    ]
  },
  "GRUReg": {
    "__init__": [
      "self",
      "npoint",
      "hidden_dim",
      "input_dim",
      "use_instance_norm"
    ],
    "gru": [
      "self",
      "h",
      "gru_inp",
      "pc"
    ],
    "get_gru_input": [
      "self",
      "feats1_new",
      "cost",
      "flow",
      "pc"
    ],
    "forward": [
      "self",
      "h",
      "feats1_new",
      "cost",
      "flow_lr",
      "pc1_l"
    ]
  },
  "SF_RCP": {
    "__init__": [
      "self",
      "npoint",
      "use_instance_norm"
    ],
    "initialization": [
      "self",
      "pc1_l",
      "pc2_l",
      "feats1",
      "feats2"
    ],
    "pointwise_optimization": [
      "self",
      "pc1_l_new",
      "pc2_l",
      "feats1_new",
      "feats2",
      "pc1_l",
      "flow_lr",
      "iter"
    ],
    "update_pos": [
      "self",
      "pc",
      "pc_lr",
      "flow",
      "flow_lr"
    ],
    "forward": [
      "self",
      "pc1",
      "pc2",
      "feature1",
      "feature2",
      "iters"
    ]
  },
  "FurthestPointSampling": {
    "forward": [
      "ctx",
      "xyz",
      "npoint"
    ],
    "backward": [
      "xyz",
      "a"
    ]
  },
  "furthest_point_sample": [],
  "GatherOperation": {
    "forward": [
      "ctx",
      "features",
      "idx"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "gather_operation": [],
  "KNN": {
    "forward": [
      "ctx",
      "k",
      "unknown",
      "known"
    ],
    "backward": [
      "ctx",
      "a",
      "b"
    ]
  },
  "knn": [],
  "ThreeNN": {
    "forward": [
      "ctx",
      "unknown",
      "known"
    ],
    "backward": [
      "ctx",
      "a",
      "b"
    ]
  },
  "three_nn": [],
  "ThreeInterpolate": {
    "forward": [
      "ctx",
      "features",
      "idx",
      "weight"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "three_interpolate": [],
  "GroupingOperation": {
    "forward": [
      "ctx",
      "features",
      "idx"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "grouping_operation": [],
  "BallQuery": {
    "forward": [
      "ctx",
      "radius",
      "nsample",
      "xyz",
      "new_xyz"
    ],
    "backward": [
      "ctx",
      "a"
    ]
  },
  "ball_query": [],
  "QueryAndGroup": {
    "__init__": [
      "self",
      "radius",
      "nsample",
      "use_xyz"
    ],
    "forward": [
      "self",
      "xyz",
      "new_xyz",
      "features"
    ]
  },
  "GroupAll": {
    "__init__": [
      "self",
      "use_xyz"
    ],
    "forward": [
      "self",
      "xyz",
      "new_xyz",
      "features"
    ]
  },
  "batch_mm": [
    "matrix",
    "matrix_batch"
  ],
  "aa2quat": [
    "rots",
    "form",
    "unified_orient"
  ],
  "quat2aa": [
    "quats"
  ],
  "quat2mat": [
    "quats"
  ],
  "quat2euler": [
    "q",
    "order",
    "degrees"
  ],
  "aa2mat": [
    "rots"
  ],
  "inv_affine": [
    "mat"
  ],
  "inv_rigid_affine": [
    "mat"
  ],
  "_sqrt_positive_part": [
    "x"
  ],
  "matrix_to_quaternion": [
    "matrix"
  ],
  "quaternion_to_axis_angle": [
    "quaternions"
  ],
  "mat2aa": [
    "matrix"
  ],
  "batch_rodrigues": [
    "rot_vecs",
    "epsilon"
  ],
  "write_bvh": [
    "parent",
    "offset",
    "rotation",
    "position",
    "names",
    "frametime",
    "order",
    "path",
    "endsite"
  ],
  "WriterWrapper": {
    "__init__": [
      "self",
      "parents"
    ],
    "axis2euler": [
      "self",
      "rot"
    ],
    "mapper_rot_mixamo": [
      "self",
      "rot",
      "n_bone"
    ],
    "transform_rot_with_restpose": [
      "self",
      "rot",
      "rest_pose",
      "node_list",
      "n_bone"
    ],
    "transform_rot_with_stdApose": [
      "self",
      "rot",
      "rest_pose"
    ],
    "write": [
      "self",
      "filename",
      "offset",
      "rot",
      "action_loc",
      "rest_pose",
      "correct_arm"
    ]
  },
  "read_obj": [
    "obj_path",
    "print_shape"
  ],
  "write_obj": [
    "save_path",
    "mesh"
  ],
  "projection": [
    "x",
    "n",
    "f"
  ],
  "translate": [
    "x",
    "y",
    "z"
  ],
  "rotate_x": [
    "a"
  ],
  "rotate_y": [
    "a"
  ],
  "length": [
    "x",
    "eps"
  ],
  "safe_normalize": [
    "x",
    "eps"
  ],
  "transform_pos": [
    "mtx",
    "pos"
  ],
  "_copysign": [
    "a",
    "b"
  ],
  "matrix_to_axis_angle": [
    "matrix"
  ],
  "load_smpl_params": [
    "pose_fname"
  ],
  "set_pose_param": [
    "pose",
    "start",
    "end"
  ],
  "load_test_anim": [
    "filename",
    "device",
    "mode"
  ],
  "load_syn_motion": [
    "filename",
    "device",
    "mode"
  ],
  "load_action": [
    "action_name",
    "model_dir",
    "action_dir",
    "mode",
    "device"
  ],
  "load_action_list": [
    "action",
    "model_dir",
    "action_dir",
    "mode",
    "device"
  ],
  "gen_skeleton_bvh": [
    "model_dir",
    "action_dir",
    "case_dir",
    "action",
    "mode"
  ],
  "DeFRCNForFewShot": {
    "__init__": [
      "self",
      "model_dir",
      "_cfg_dict"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "inference": [
      "self",
      "input"
    ],
    "get_model_cfg": [
      "self"
    ]
  },
  "PASCAL_VOC_ALL_CATEGORIES": [],
  "PASCAL_VOC_NOVEL_CATEGORIES": [],
  "PASCAL_VOC_BASE_CATEGORIES": [],
  "load_filtered_voc_instances": [
    "name",
    "root",
    "dirname",
    "split",
    "classnames"
  ],
  "register_meta_voc": [
    "name",
    "root",
    "dirname",
    "split",
    "year",
    "keepclasses",
    "sid"
  ],
  "register_all_voc": [
    "root"
  ],
  "DETECTRON2_REQUIRED_VERSION": [],
  "is_detectron2_version_available": [],
  "TORCH_REQUIRED_VERSION": [],
  "is_torch_version_available": [],
  "DETECTRON2_IMPORT_ERROR": [],
  "TORCH_VERSION_IMPORT_ERROR": [],
  "REQUIREMENTS_MAPPING_VERSION": [],
  "REQUIREMENTS": [],
  "requires_version": [],
  "COCO_CATEGORIES": [],
  "COCO_NOVEL_CATEGORIES": [],
  "_get_coco_fewshot_instances_meta": [],
  "load_coco_json": [
    "root",
    "json_file",
    "image_root",
    "metadata",
    "dataset_name"
  ],
  "register_meta_coco": [
    "name",
    "root",
    "metadata",
    "imgdir",
    "annofile"
  ],
  "register_all_coco": [
    "root"
  ],
  "COCO_NOVEL_CLASSES": [],
  "COCO_BASE_CLASSES": [],
  "COCO_ALL_CLASSES": [],
  "COCO_IDMAP": [],
  "surgery": [
    "data_type",
    "param_name",
    "is_weight",
    "tar_size",
    "ckpt"
  ],
  "model_surgery": [
    "src_path",
    "save_dir",
    "data_type",
    "method",
    "params_name"
  ],
  "detectron2_default_cfg": [],
  "CfgMapper": {
    "__init__": [
      "self",
      "cfg"
    ],
    "__call__": [
      "self"
    ]
  },
  "register_data": [
    "data_type",
    "data_dir"
  ],
  "COCOEvaluator": {
    "__init__": [
      "self",
      "dataset_name",
      "distributed",
      "output_dir"
    ],
    "reset": [
      "self"
    ],
    "process": [
      "self",
      "inputs",
      "outputs"
    ],
    "evaluate": [
      "self"
    ],
    "_eval_predictions": [
      "self"
    ],
    "_derive_coco_results": [
      "self",
      "coco_eval",
      "iou_type",
      "class_names"
    ]
  },
  "instances_to_coco_json": [
    "instances",
    "img_id"
  ],
  "_evaluate_predictions_on_coco": [
    "coco_gt",
    "coco_results",
    "iou_type",
    "catIds"
  ],
  "inference_on_dataset": [
    "model",
    "data_loader",
    "evaluator",
    "cfg"
  ],
  "PascalVOCEvaluator": {
    "__init__": [
      "self",
      "dataset_name"
    ],
    "evaluate": [
      "self"
    ]
  },
  "GradientDecoupleLayer": {
    "forward": [
      "ctx",
      "x",
      "_lambda"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "AffineLayer": {
    "__init__": [
      "self",
      "num_channels",
      "bias"
    ],
    "forward": [
      "self",
      "X"
    ]
  },
  "decouple_layer": [
    "x",
    "_lambda"
  ],
  "ResNetFeatures": {
    "__init__": [
      "self",
      "block",
      "layers",
      "num_classes",
      "zero_init_residual",
      "groups",
      "width_per_group",
      "replace_stride_with_dilation",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Res5ROIHeads": {
    "__init__": [
      "self",
      "cfg",
      "input_shape"
    ],
    "_build_res5_block": [
      "self",
      "cfg"
    ],
    "_shared_roi_transform": [
      "self",
      "features",
      "boxes"
    ],
    "forward": [
      "self",
      "images",
      "features",
      "proposals",
      "targets"
    ]
  },
  "fast_rcnn_inference": [
    "boxes",
    "scores",
    "image_shapes",
    "score_thresh",
    "nms_thresh",
    "topk_per_image"
  ],
  "FastRCNNOutputs": {
    "__init__": [
      "self",
      "box2box_transform",
      "pred_class_logits",
      "pred_proposal_deltas",
      "proposals",
      "smooth_l1_beta"
    ],
    "_log_accuracy": [
      "self"
    ],
    "softmax_cross_entropy_loss": [
      "self"
    ],
    "smooth_l1_loss": [
      "self"
    ],
    "losses": [
      "self"
    ],
    "predict_boxes": [
      "self"
    ],
    "predict_probs": [
      "self"
    ],
    "inference": [
      "self",
      "score_thresh",
      "nms_thresh",
      "topk_per_image"
    ]
  },
  "FastRCNNOutputLayers": {
    "__init__": [
      "self",
      "cfg",
      "input_size",
      "num_classes",
      "cls_agnostic_bbox_reg",
      "box_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DatasetMapperIns": {
    "__init__": [
      "self",
      "cfg",
      "is_train"
    ],
    "__call__": [
      "self",
      "dataset_dict"
    ]
  },
  "PrototypicalCalibrationBlock": {
    "__init__": [
      "self",
      "cfg"
    ],
    "build_model": [
      "self"
    ],
    "build_prototypes": [
      "self"
    ],
    "extract_roi_features": [
      "self",
      "img",
      "boxes"
    ],
    "execute_calibration": [
      "self",
      "inputs",
      "dts"
    ],
    "clsid_filter": [
      "self"
    ]
  },
  "concat_all_gather": [
    "tensor"
  ],
  "DeFRCN": {
    "__init__": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "batched_inputs"
    ],
    "inference": [
      "self",
      "batched_inputs"
    ],
    "_forward_once_": [
      "self",
      "batched_inputs",
      "gt_instances"
    ],
    "preprocess_image": [
      "self",
      "batched_inputs"
    ],
    "normalize_fn": [
      "self"
    ],
    "from_rpn_config": [
      "cls",
      "cfg",
      "input_shape"
    ]
  },
  "MutualSelfAttentionControl": {
    "__init__": [
      "self",
      "start_step",
      "start_layer",
      "layer_idx",
      "step_idx",
      "total_steps"
    ],
    "attn_batch": [
      "self",
      "q",
      "k",
      "v",
      "sim",
      "attn",
      "is_cross",
      "place_in_unet",
      "num_heads"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "sim",
      "attn",
      "is_cross",
      "place_in_unet",
      "num_heads"
    ]
  },
  "AttentionBase": {
    "__init__": [
      "self"
    ],
    "after_step": [
      "self"
    ],
    "__call__": [
      "self",
      "q",
      "k",
      "v",
      "sim",
      "attn",
      "is_cross",
      "place_in_unet",
      "num_heads"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "sim",
      "attn",
      "is_cross",
      "place_in_unet",
      "num_heads"
    ],
    "reset": [
      "self"
    ]
  },
  "register_attention_editor_diffusers": [
    "model",
    "editor"
  ],
  "TextToHeadModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "EfficientNetForFaceEmotion": {
    "__init__": [
      "self",
      "model_dir",
      "device_id"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FaceEmotionModel": {
    "__init__": [
      "self",
      "name",
      "num_embed",
      "num_au",
      "num_emotion"
    ],
    "feat_single_img": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "transform_PIL": [
    "img_pil"
  ],
  "index2AU": [],
  "emotion_list": [],
  "GlobalParams": [],
  "BlockArgs": [],
  "SwishImplementation": {
    "forward": [
      "ctx",
      "i"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "MemoryEfficientSwish": {
    "forward": [
      "self",
      "x"
    ]
  },
  "round_filters": [
    "filters",
    "global_params"
  ],
  "round_repeats": [
    "repeats",
    "global_params"
  ],
  "drop_connect": [
    "inputs",
    "p",
    "training"
  ],
  "get_width_and_height_from_size": [
    "x"
  ],
  "calculate_output_image_size": [
    "input_image_size",
    "stride"
  ],
  "get_same_padding_conv2d": [
    "image_size"
  ],
  "Conv2dDynamicSamePadding": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "groups",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv2dStaticSamePadding": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "image_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_same_padding_maxPool2d": [
    "image_size"
  ],
  "MaxPool2dDynamicSamePadding": {
    "__init__": [
      "self",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "return_indices",
      "ceil_mode"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MaxPool2dStaticSamePadding": {
    "__init__": [
      "self",
      "kernel_size",
      "stride",
      "image_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BlockDecoder": {
    "_decode_block_string": [
      "block_string"
    ],
    "_encode_block_string": [
      "block"
    ],
    "decode": [
      "string_list"
    ],
    "encode": [
      "blocks_args"
    ]
  },
  "efficientnet_params": [
    "model_name"
  ],
  "efficientnet": [
    "width_coefficient",
    "depth_coefficient",
    "image_size",
    "dropout_rate",
    "drop_connect_rate",
    "num_classes",
    "include_top"
  ],
  "get_model_params": [
    "model_name",
    "override_params"
  ],
  "load_pretrained_weights": [
    "model",
    "model_name",
    "weights_path",
    "load_fc",
    "advprop",
    "verbose"
  ],
  "VALID_MODELS": [],
  "MBConvBlock": {
    "__init__": [
      "self",
      "block_args",
      "global_params",
      "image_size"
    ],
    "forward": [
      "self",
      "inputs",
      "drop_connect_rate"
    ],
    "set_swish": [
      "self",
      "memory_efficient"
    ]
  },
  "adjust_bx_v2": [
    "box",
    "w",
    "h"
  ],
  "face_detection_PIL_v2": [
    "image",
    "face_model"
  ],
  "init": [
    "mod"
  ],
  "filter_bboxes_confs": [
    "shape",
    "imgsBboxes",
    "imgsConfs",
    "single",
    "thresh"
  ],
  "detect": [
    "im",
    "sess",
    "net"
  ],
  "FaceAttributeRecognition": {
    "__init__": [
      "self",
      "model_path",
      "device"
    ],
    "load_model": [
      "self",
      "load_to_cpu"
    ],
    "forward": [
      "self",
      "img"
    ]
  },
  "LongShortNet": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "input"
    ],
    "inference_video": [
      "self",
      "v_path"
    ]
  },
  "LongShortNetExp": {
    "__init__": [
      "self"
    ],
    "get_model": [
      "self"
    ]
  },
  "DFPPAFPNSHORT": {
    "__init__": [
      "self",
      "depth",
      "width",
      "in_features",
      "in_channels",
      "depthwise",
      "act",
      "frame_num",
      "with_short_cut",
      "out_channels"
    ],
    "off_forward": [
      "self",
      "input",
      "backbone_neck"
    ],
    "forward": [
      "self",
      "input",
      "buffer",
      "mode",
      "backbone_neck"
    ]
  },
  "BACKBONENECK": {
    "__init__": [
      "self",
      "depth",
      "width",
      "in_features",
      "in_channels",
      "depthwise",
      "act"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "DFPPAFPNLONG": {
    "__init__": [
      "self",
      "depth",
      "width",
      "in_features",
      "in_channels",
      "depthwise",
      "act",
      "frame_num",
      "with_short_cut",
      "merge_form",
      "out_channels"
    ],
    "off_forward": [
      "self",
      "input",
      "backbone_neck"
    ],
    "forward": [
      "self",
      "input",
      "buffer",
      "mode",
      "backbone_neck"
    ]
  },
  "LONGSHORT": {
    "__init__": [
      "self",
      "long_backbone",
      "short_backbone",
      "backbone_neck",
      "head",
      "merge_form",
      "in_channels",
      "width",
      "act",
      "with_short_cut",
      "long_cfg",
      "jian_ratio"
    ],
    "forward": [
      "self",
      "x",
      "targets",
      "buffer",
      "mode"
    ]
  },
  "SuperResIDWEXKX": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "kernel_size",
      "expension",
      "no_create",
      "no_reslink",
      "no_BN",
      "use_se"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "create_from_str": [
      "cls",
      "s"
    ]
  },
  "SuperResIDWE1K3": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResIDWE2K3": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResIDWE4K3": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResIDWE6K3": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResIDWE1K5": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResIDWE2K5": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResIDWE4K5": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResIDWE6K5": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResIDWE1K7": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResIDWE2K7": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResIDWE4K7": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResIDWE6K7": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "register_netblocks_dict": [
    "netblocks_dict"
  ],
  "SuperResKXKX": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "kernel_size",
      "no_create",
      "no_reslink",
      "no_BN",
      "use_se"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "create_from_str": [
      "cls",
      "s"
    ]
  },
  "SuperResK3K3": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResK5K5": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResK7K7": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "smart_round": [
    "x",
    "base"
  ],
  "get_right_parentheses_index": [
    "s"
  ],
  "create_netblock_list_from_str_inner": [
    "s",
    "no_create",
    "netblocks_dict"
  ],
  "create_netblock_list_from_str": [
    "s",
    "no_create",
    "netblocks_dict"
  ],
  "get_zennet": [],
  "SuperResK1KXK1": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "kernel_size",
      "no_create",
      "no_reslink",
      "no_BN",
      "use_se"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "create_from_str": [
      "cls",
      "s"
    ]
  },
  "SuperResK1K3K1": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResK1K5K1": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperResK1K7K1": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "bottleneck_channels",
      "sub_layers",
      "no_create"
    ]
  },
  "PlainNetSuperBlockClass": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "sub_layers",
      "no_create"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_output_resolution": [
      "self",
      "input_resolution"
    ],
    "create_from_str": [
      "cls",
      "s",
      "no_create"
    ]
  },
  "SuperConvKXBNRELU": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "sub_layers",
      "kernel_size",
      "no_create",
      "no_reslink",
      "no_BN"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SuperConvK1BNRELU": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperConvK3BNRELU": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperConvK5BNRELU": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "sub_layers",
      "no_create"
    ]
  },
  "SuperConvK7BNRELU": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "sub_layers",
      "no_create"
    ]
  },
  "PlainNet": {
    "__init__": [
      "self",
      "argv",
      "opt",
      "num_classes",
      "plainnet_struct",
      "no_create"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_all_netblocks_dict_": [],
  "PlainNetBasicBlockClass": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "no_create",
      "block_name"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_output_resolution": [
      "self",
      "input_resolution"
    ],
    "create_from_str": [
      "cls",
      "s",
      "no_create"
    ],
    "is_instance_from_str": [
      "cls",
      "s"
    ]
  },
  "AdaptiveAvgPool": {
    "__init__": [
      "self",
      "out_channels",
      "output_size",
      "no_create"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_output_resolution": [
      "self",
      "input_resolution"
    ],
    "create_from_str": [
      "cls",
      "s",
      "no_create"
    ]
  },
  "BN": {
    "__init__": [
      "self",
      "out_channels",
      "copy_from",
      "no_create"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_output_resolution": [
      "self",
      "input_resolution"
    ],
    "create_from_str": [
      "cls",
      "s",
      "no_create"
    ]
  },
  "ConvKX": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "groups",
      "copy_from",
      "no_create"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_output_resolution": [
      "self",
      "input_resolution"
    ],
    "create_from_str": [
      "cls",
      "s",
      "no_create"
    ]
  },
  "ConvDW": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "stride",
      "copy_from",
      "no_create"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_output_resolution": [
      "self",
      "input_resolution"
    ],
    "create_from_str": [
      "cls",
      "s",
      "no_create"
    ]
  },
  "ConvKXG2": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "copy_from",
      "no_create"
    ]
  },
  "ConvKXG4": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "copy_from",
      "no_create"
    ]
  },
  "ConvKXG8": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "copy_from",
      "no_create"
    ]
  },
  "ConvKXG16": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "copy_from",
      "no_create"
    ]
  },
  "ConvKXG32": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "copy_from",
      "no_create"
    ]
  },
  "Linear": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bias",
      "copy_from",
      "no_create"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_output_resolution": [
      "self",
      "input_resolution"
    ],
    "create_from_str": [
      "cls",
      "s",
      "no_create"
    ]
  },
  "MaxPool": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "stride",
      "no_create"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_output_resolution": [
      "self",
      "input_resolution"
    ],
    "create_from_str": [
      "cls",
      "s",
      "no_create"
    ]
  },
  "Sequential": {
    "__init__": [
      "self",
      "block_list",
      "no_create"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_output_resolution": [
      "self",
      "input_resolution"
    ],
    "create_from_str": [
      "cls",
      "s",
      "no_create"
    ]
  },
  "MultiSumBlock": {
    "__init__": [
      "self",
      "block_list",
      "no_create"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_output_resolution": [
      "self",
      "input_resolution"
    ],
    "create_from_str": [
      "cls",
      "s",
      "no_create"
    ]
  },
  "MultiCatBlock": {
    "__init__": [
      "self",
      "block_list",
      "no_create"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_output_resolution": [
      "self",
      "input_resolution"
    ],
    "create_from_str": [
      "cls",
      "s",
      "no_create"
    ]
  },
  "RELU": {
    "__init__": [
      "self",
      "out_channels",
      "no_create"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_output_resolution": [
      "self",
      "input_resolution"
    ],
    "create_from_str": [
      "cls",
      "s",
      "no_create"
    ]
  },
  "ResBlockProj": {
    "__init__": [
      "self",
      "block_list",
      "in_channels",
      "stride",
      "no_create"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_output_resolution": [
      "self",
      "input_resolution"
    ],
    "create_from_str": [
      "cls",
      "s",
      "no_create"
    ]
  },
  "bottom_basic_dict": [],
  "LightGlueImageMatching": {
    "__init__": [
      "self",
      "model_dir",
      "max_num_keypoints"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "inference": [
      "self",
      "data"
    ]
  },
  "get_patches": [
    "tensor",
    "required_corners",
    "ps"
  ],
  "simple_nms": [
    "scores",
    "nms_radius"
  ],
  "DKD": {
    "__init__": [
      "self",
      "radius",
      "top_k",
      "scores_th",
      "n_limit"
    ],
    "forward": [
      "self",
      "scores_map",
      "sub_pixel",
      "image_size"
    ]
  },
  "DeformableConv2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "bias",
      "mask"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_conv": [
    "inplanes",
    "planes",
    "kernel_size",
    "stride",
    "padding",
    "bias",
    "conv_type",
    "mask"
  ],
  "SDDH": {
    "__init__": [
      "self",
      "dims",
      "kernel_size",
      "n_pos",
      "gate",
      "conv2D",
      "mask"
    ],
    "forward": [
      "self",
      "x",
      "keypoints"
    ]
  },
  "ALIKED": {
    "default_conf": [],
    "checkpoint_url": [],
    "n_limit_max": [],
    "cfgs": [],
    "preprocess_conf": [],
    "required_data_keys": [],
    "__init__": [
      "self"
    ],
    "get_resblock": [
      "self",
      "c_in",
      "c_out",
      "conv_type",
      "mask"
    ],
    "extract_dense_map": [
      "self",
      "image"
    ],
    "forward": [
      "self",
      "data"
    ]
  },
  "DISK": {
    "default_conf": [],
    "preprocess_conf": [],
    "required_data_keys": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "data"
    ]
  },
  "ImagePreprocessor": {
    "default_conf": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "map_tensor": [
    "input_",
    "func"
  ],
  "rbd": [
    "data"
  ],
  "numpy_image_to_torch": [
    "image"
  ],
  "Extractor": {
    "__init__": [
      "self"
    ],
    "extract": [
      "self",
      "img"
    ]
  },
  "match_pair": [
    "extractor",
    "matcher",
    "image0",
    "image1",
    "device"
  ],
  "top_k_keypoints": [
    "keypoints",
    "scores",
    "k"
  ],
  "sample_descriptors": [
    "keypoints",
    "descriptors",
    "s"
  ],
  "SuperPoint": {
    "default_conf": [],
    "preprocess_conf": [],
    "required_data_keys": [],
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "data"
    ]
  },
  "filter_dog_point": [
    "points",
    "scales",
    "angles",
    "image_shape",
    "nms_radius",
    "scores"
  ],
  "sift_to_rootsift": [
    "x",
    "eps"
  ],
  "run_opencv_sift": [
    "features",
    "image"
  ],
  "SIFT": {
    "default_conf": [],
    "preprocess_conf": [],
    "required_data_keys": [],
    "__init__": [
      "self"
    ],
    "extract_single_image": [
      "self",
      "image"
    ],
    "forward": [
      "self",
      "data"
    ]
  },
  "cm_RdGn": [
    "x"
  ],
  "cm_BlRdGn": [
    "x_"
  ],
  "cm_prune": [
    "x_"
  ],
  "plot_images": [
    "imgs",
    "titles",
    "cmaps",
    "dpi",
    "pad",
    "adaptive"
  ],
  "plot_keypoints": [
    "kpts",
    "colors",
    "ps",
    "axes",
    "a"
  ],
  "plot_matches": [
    "kpts0",
    "kpts1",
    "color",
    "lw",
    "ps",
    "a",
    "labels",
    "axes"
  ],
  "add_text": [
    "idx",
    "text",
    "pos",
    "fs",
    "color",
    "lcolor",
    "lwidth",
    "ha",
    "va"
  ],
  "save_plot": [
    "path"
  ],
  "normalize_keypoints": [
    "kpts",
    "size"
  ],
  "pad_to_length": [
    "x",
    "length"
  ],
  "rotate_half": [
    "x"
  ],
  "apply_cached_rotary_emb": [
    "freqs",
    "t"
  ],
  "LearnableFourierPositionalEncoding": {
    "__init__": [
      "self",
      "M",
      "dim",
      "F_dim",
      "gamma"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TokenConfidence": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "desc0",
      "desc1"
    ]
  },
  "SelfBlock": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "flash",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "encoding",
      "mask"
    ]
  },
  "CrossBlock": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "flash",
      "bias"
    ],
    "map_": [
      "self",
      "func",
      "x0",
      "x1"
    ],
    "forward": [
      "self",
      "x0",
      "x1",
      "mask"
    ]
  },
  "TransformerLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "desc0",
      "desc1",
      "encoding0",
      "encoding1",
      "mask0",
      "mask1"
    ],
    "masked_forward": [
      "self",
      "desc0",
      "desc1",
      "encoding0",
      "encoding1",
      "mask0",
      "mask1"
    ]
  },
  "sigmoid_log_double_softmax": [
    "sim",
    "z0",
    "z1"
  ],
  "MatchAssignment": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "desc0",
      "desc1"
    ],
    "get_matchability": [
      "self",
      "desc"
    ]
  },
  "filter_matches": [
    "scores",
    "th"
  ],
  "LightGlue": {
    "pruning_keypoint_thresholds": [],
    "required_data_keys": [],
    "version": [],
    "weight_path": [],
    "features": [],
    "__init__": [
      "self",
      "model_dir",
      "default_conf"
    ],
    "compile": [
      "self",
      "mode",
      "static_lengths"
    ],
    "forward": [
      "self",
      "data"
    ],
    "_forward": [
      "self",
      "data"
    ],
    "confidence_threshold": [
      "self",
      "layer_index"
    ],
    "get_pruning_mask": [
      "self",
      "confidences",
      "scores",
      "layer_index"
    ],
    "check_if_stop": [
      "self",
      "confidences0",
      "confidences1",
      "layer_index",
      "num_points"
    ],
    "pruning_min_kpts": [
      "self",
      "device"
    ]
  },
  "lightglue_default_conf": [],
  "img_value_rescale": [
    "img",
    "old_range",
    "new_range"
  ],
  "get_mg_layer": [
    "src",
    "gt",
    "skin_mask"
  ],
  "spread_flow": [
    "length",
    "spread_ratio"
  ],
  "LoadExpBasis": [
    "bfm_folder"
  ],
  "transferBFM09": [
    "bfm_folder"
  ],
  "load_lm3d": [
    "bfm_folder"
  ],
  "mesh_to_string": [
    "mesh"
  ],
  "POS": [
    "xp",
    "x"
  ],
  "BBRegression": [
    "points",
    "params"
  ],
  "scale_trans": [
    "img",
    "lm",
    "t",
    "s"
  ],
  "align_for_lm": [
    "img",
    "five_points",
    "params"
  ],
  "resize_n_crop_img": [
    "img",
    "lm",
    "t",
    "s",
    "target_size",
    "mask"
  ],
  "extract_5p": [
    "lm"
  ],
  "align_img": [
    "img",
    "lm",
    "lm3D",
    "mask",
    "target_size",
    "rescale_factor"
  ],
  "normalize_v3": [
    "arr"
  ],
  "estimate_normals": [
    "vertices",
    "faces"
  ],
  "draw_landmarks": [
    "img",
    "landmark",
    "color",
    "step"
  ],
  "split_vis": [
    "img_path",
    "target_dir"
  ],
  "write_video": [
    "image_list",
    "save_path",
    "fps"
  ],
  "generate_triangles": [
    "h",
    "w",
    "margin_x",
    "margin_y",
    "mask"
  ],
  "face_vertices": [
    "vertices",
    "faces"
  ],
  "vertex_normals": [
    "vertices",
    "faces"
  ],
  "dict2obj": [
    "d"
  ],
  "DeRetouchingModule": {
    "__init__": [
      "self",
      "model_path"
    ],
    "run": [
      "self",
      "face_albedo_map",
      "texture_map"
    ]
  },
  "set_rasterizer": [],
  "Pytorch3dRasterizer": {
    "__init__": [
      "self",
      "image_size"
    ],
    "forward": [
      "self",
      "vertices",
      "faces",
      "attributes",
      "h",
      "w"
    ]
  },
  "SRenderY": {
    "__init__": [
      "self",
      "image_size",
      "obj_filename",
      "uvcoords_path",
      "uv_size"
    ],
    "forward": [
      "self",
      "vertices",
      "transformed_vertices",
      "albedos",
      "lights",
      "light_type"
    ],
    "add_SHlight": [
      "self",
      "normal_images",
      "gamma",
      "init_lit"
    ],
    "add_pointlight": [
      "self",
      "vertices",
      "normals",
      "lights"
    ],
    "add_directionlight": [
      "self",
      "normals",
      "lights"
    ],
    "world2uv": [
      "self",
      "vertices"
    ]
  },
  "FaceReconModel": {
    "__init__": [
      "self",
      "model_dir",
      "w_color",
      "tex_iters",
      "w_tex_smooth"
    ],
    "set_device": [
      "self",
      "device"
    ],
    "load_networks": [
      "self",
      "load_path"
    ],
    "setup": [
      "self",
      "checkpoint_path"
    ],
    "parallelize": [
      "self",
      "convert_sync_batchnorm"
    ],
    "eval": [
      "self"
    ],
    "set_render": [
      "self",
      "image_res"
    ],
    "set_input_base": [
      "self",
      "input"
    ],
    "set_input_hrn": [
      "self",
      "input"
    ],
    "predict_results_base": [
      "self"
    ],
    "forward": [
      "self",
      "visualize"
    ],
    "get_edge_points_horizontal": [
      "self"
    ],
    "smooth_valid_mask": [
      "self",
      "tex_valid_mask"
    ],
    "compute_visuals_hrn": [
      "self"
    ],
    "get_current_visuals": [
      "self"
    ],
    "save_results_hrn": [
      "self"
    ]
  },
  "Pix2PixModel": {
    "__init__": [
      "self",
      "opt"
    ],
    "set_input": [
      "self",
      "input"
    ],
    "forward": [
      "self"
    ],
    "backward_D": [
      "self"
    ],
    "backward_G": [
      "self"
    ],
    "optimize_parameters": [
      "self"
    ]
  },
  "init_net": [
    "net",
    "init_type",
    "init_gain",
    "gpu_ids"
  ],
  "define_D": [
    "input_nc",
    "ndf",
    "netD",
    "n_layers_D",
    "norm",
    "init_type",
    "init_gain",
    "gpu_ids"
  ],
  "cal_gradient_penalty": [
    "netD",
    "real_data",
    "fake_data",
    "device",
    "type",
    "constant",
    "lambda_gp"
  ],
  "ResnetGenerator": {
    "__init__": [
      "self",
      "input_nc",
      "output_nc",
      "ngf",
      "norm_layer",
      "use_dropout",
      "n_blocks",
      "padding_type"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "UnetGenerator": {
    "__init__": [
      "self",
      "input_nc",
      "output_nc",
      "num_downs",
      "ngf",
      "norm_layer",
      "use_dropout"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "UnetSkipConnectionBlock": {
    "__init__": [
      "self",
      "outer_nc",
      "inner_nc",
      "input_nc",
      "submodule",
      "outermost",
      "innermost",
      "norm_layer",
      "use_dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PixelDiscriminator": {
    "__init__": [
      "self",
      "input_nc",
      "ndf",
      "norm_layer"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Pix2PixOptions": {
    "__init__": [
      "self"
    ]
  },
  "BASE_LANDMARK_NUM": [],
  "INPUT_SIZE": [],
  "ENLARGE_RATIO": [],
  "LargeBaseLmkInfer": {
    "model_preload": [
      "model_path",
      "use_gpu"
    ],
    "process_img": [
      "model",
      "image",
      "use_gpu"
    ],
    "smooth": [
      "cur_lmks",
      "prev_lmks"
    ],
    "infer_img": [
      "img",
      "model",
      "use_gpu"
    ]
  },
  "kaiming_init": [
    "module",
    "a",
    "mode",
    "nonlinearity",
    "bias",
    "distribution"
  ],
  "SoftArgmax": {
    "__init__": [
      "self",
      "beta",
      "infer"
    ],
    "forward": [
      "self",
      "heatmap"
    ]
  },
  "LargeBaseLmksNet": {
    "__init__": [
      "self",
      "er",
      "infer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FACE_PART_SIZE": [],
  "conv_no_relu": [
    "inp",
    "oup",
    "kernel",
    "stride",
    "padding"
  ],
  "View": {
    "__init__": [
      "self",
      "shape"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Softmax": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LargeEyeballNet": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DROEstimation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "Inputs"
    ],
    "postprocess": [
      "self",
      "Inputs"
    ],
    "inference": [
      "self",
      "data"
    ],
    "infer_and_save_pose": [
      "self",
      "input_file_refs",
      "input_file",
      "model_wrapper",
      "image_shape",
      "data_type"
    ]
  },
  "mat2euler": [
    "mat"
  ],
  "euler2mat": [
    "angle"
  ],
  "pose_vec2mat": [
    "vec",
    "mode"
  ],
  "invert_pose": [
    "T"
  ],
  "invert_pose_numpy": [
    "T"
  ],
  "construct_K": [
    "fx",
    "fy",
    "cx",
    "cy",
    "dtype",
    "device"
  ],
  "scale_intrinsics": [
    "K",
    "x_scale",
    "y_scale"
  ],
  "view_synthesis": [
    "ref_image",
    "depth",
    "ref_cam",
    "cam",
    "mode",
    "padding_mode"
  ],
  "Pose": {
    "__init__": [
      "self",
      "mat"
    ],
    "__len__": [
      "self"
    ],
    "identity": [
      "cls",
      "N",
      "device",
      "dtype"
    ],
    "from_vec": [
      "cls",
      "vec",
      "mode"
    ],
    "shape": [
      "self"
    ],
    "item": [
      "self"
    ],
    "repeat": [
      "self"
    ],
    "inverse": [
      "self"
    ],
    "to": [
      "self"
    ],
    "transform_pose": [
      "self",
      "pose"
    ],
    "transform_points": [
      "self",
      "points"
    ],
    "__matmul__": [
      "self",
      "other"
    ]
  },
  "resize_sample_image_and_intrinsics": [
    "sample",
    "shape",
    "image_interpolation"
  ],
  "resize_sample": [
    "sample",
    "shape",
    "image_interpolation"
  ],
  "to_tensor_sample": [
    "sample",
    "tensor_type"
  ],
  "duplicate_sample": [
    "sample"
  ],
  "colorjitter_sample": [
    "sample",
    "parameters",
    "prob"
  ],
  "write_image": [
    "filename",
    "image"
  ],
  "flip_lr": [
    "image"
  ],
  "flip_lr_intr": [
    "intr",
    "width"
  ],
  "flip_model": [
    "model",
    "image",
    "flip"
  ],
  "flip_mf_model": [
    "model",
    "image",
    "ref_imgs",
    "intrinsics",
    "flip",
    "gt_depth",
    "gt_poses"
  ],
  "gradient_x": [
    "image"
  ],
  "gradient_y": [
    "image"
  ],
  "interpolate_image": [
    "image",
    "shape",
    "mode",
    "align_corners"
  ],
  "interpolate_scales": [
    "images",
    "shape",
    "mode",
    "align_corners"
  ],
  "match_scales": [
    "image",
    "targets",
    "num_scales",
    "mode",
    "align_corners"
  ],
  "image_grid": [
    "B",
    "H",
    "W",
    "dtype",
    "device",
    "normalized"
  ],
  "filter_args": [
    "func",
    "keys"
  ],
  "filter_args_create": [
    "func",
    "keys"
  ],
  "load_class": [
    "filename",
    "paths",
    "concat"
  ],
  "load_class_args_create": [
    "filename",
    "paths",
    "args",
    "concat"
  ],
  "load_network": [
    "network",
    "path",
    "prefixes"
  ],
  "backwards_state_dict": [
    "state_dict"
  ],
  "prep_dataset": [
    "config"
  ],
  "set_name": [
    "config"
  ],
  "prep_logger_and_checkpoint": [
    "model"
  ],
  "get_default_config": [
    "cfg_default"
  ],
  "merge_cfg_file": [
    "config",
    "cfg_file"
  ],
  "merge_cfgs": [
    "original",
    "override"
  ],
  "backwards_config": [
    "config"
  ],
  "parse_train_config": [
    "cfg_default",
    "cfg_file"
  ],
  "prepare_train_config": [
    "config"
  ],
  "parse_test_file": [
    "ckpt_file",
    "cfg_file"
  ],
  "parse_test_config": [
    "ckpt_file",
    "cfg_default",
    "cfg_file"
  ],
  "prepare_test_config": [
    "config"
  ],
  "load_depth": [
    "file"
  ],
  "viz_inv_depth": [
    "inv_depth",
    "normalizer",
    "percentile",
    "colormap",
    "filter_zeros"
  ],
  "inv2depth": [
    "inv_depth"
  ],
  "depth2inv": [
    "depth"
  ],
  "inv_depths_normalize": [
    "inv_depths"
  ],
  "calc_smoothness": [
    "inv_depths",
    "images",
    "num_scales"
  ],
  "fuse_inv_depth": [
    "inv_depth",
    "inv_depth_hat",
    "method"
  ],
  "post_process_inv_depth": [
    "inv_depth",
    "inv_depth_flipped",
    "method"
  ],
  "compute_depth_metrics": [
    "config",
    "gt",
    "pred",
    "use_gt_scale"
  ],
  "compute_depth_metrics_demon": [
    "config",
    "gt",
    "gt_pose",
    "pred",
    "use_gt_scale"
  ],
  "compute_pose_metrics": [
    "config",
    "gt",
    "pred"
  ],
  "is_numpy": [
    "data"
  ],
  "is_tuple": [
    "data"
  ],
  "is_list": [
    "data"
  ],
  "is_dict": [
    "data"
  ],
  "is_str": [
    "data"
  ],
  "is_int": [
    "data"
  ],
  "is_seq": [
    "data"
  ],
  "is_cfg": [
    "data"
  ],
  "parse_video": [
    "video_file",
    "save_root",
    "sample_rate"
  ],
  "get_intrinsics": [
    "image_shape_raw",
    "image_shape",
    "data_type"
  ],
  "filter_dict": [
    "dictionary",
    "keywords"
  ],
  "make_list": [
    "var",
    "n"
  ],
  "same_shape": [
    "shape1",
    "shape2"
  ],
  "pcolor": [
    "string",
    "color",
    "on_color",
    "attrs"
  ],
  "hvd_disable": [],
  "hvd_init": [],
  "on_rank_0": [
    "func"
  ],
  "rank": [],
  "world_size": [],
  "print0": [
    "string"
  ],
  "reduce_value": [
    "value",
    "average",
    "name"
  ],
  "get_cfg_defaults": [],
  "ResNetMultiImageInput": {
    "__init__": [
      "self",
      "block",
      "layers",
      "num_classes",
      "num_input_images"
    ]
  },
  "resnet_multiimage_input": [
    "num_layers",
    "pretrained",
    "num_input_images"
  ],
  "ResnetEncoder": {
    "__init__": [
      "self",
      "num_layers",
      "pretrained",
      "num_input_images"
    ],
    "forward": [
      "self",
      "input_image"
    ]
  },
  "PoseDecoder": {
    "__init__": [
      "self",
      "num_ch_enc",
      "num_input_features",
      "num_frames_to_predict_for",
      "stride"
    ],
    "forward": [
      "self",
      "input_features"
    ]
  },
  "disp_to_depth": [
    "disp",
    "min_depth",
    "max_depth"
  ],
  "DepthDecoder": {
    "__init__": [
      "self",
      "num_ch_enc",
      "scales",
      "num_output_channels",
      "use_skips"
    ],
    "forward": [
      "self",
      "input_features"
    ]
  },
  "DepthDecoderShare": {
    "__init__": [
      "self",
      "num_ch_enc",
      "scales",
      "num_output_channels",
      "stride",
      "use_skips",
      "num_ch_dec"
    ],
    "forward": [
      "self",
      "input_features"
    ]
  },
  "DepthDecoderShareFeat": {
    "__init__": [
      "self",
      "num_ch_enc",
      "scales",
      "num_output_channels",
      "stride",
      "use_skips",
      "num_ch_dec"
    ],
    "forward": [
      "self",
      "input_features"
    ]
  },
  "UnetDecoder": {
    "__init__": [
      "self",
      "num_ch_enc",
      "num_output_channels",
      "stride",
      "out_chs",
      "use_skips"
    ],
    "forward": [
      "self",
      "input_features"
    ]
  },
  "DepthHead": {
    "__init__": [
      "self",
      "input_dim",
      "hidden_dim",
      "scale"
    ],
    "forward": [
      "self",
      "x_d",
      "act_fn"
    ]
  },
  "PoseHead": {
    "__init__": [
      "self",
      "input_dim",
      "hidden_dim"
    ],
    "forward": [
      "self",
      "x_p"
    ]
  },
  "ProjectionInputDepth": {
    "__init__": [
      "self",
      "cost_dim",
      "hidden_dim",
      "out_chs"
    ],
    "forward": [
      "self",
      "depth",
      "cost"
    ]
  },
  "ProjectionInputPose": {
    "__init__": [
      "self",
      "cost_dim",
      "hidden_dim",
      "out_chs"
    ],
    "forward": [
      "self",
      "pose",
      "cost"
    ]
  },
  "UpMaskNet": {
    "__init__": [
      "self",
      "hidden_dim",
      "ratio"
    ],
    "forward": [
      "self",
      "feat"
    ]
  },
  "BasicUpdateBlockDepth": {
    "__init__": [
      "self",
      "hidden_dim",
      "cost_dim",
      "ratio",
      "context_dim"
    ],
    "forward": [
      "self",
      "net",
      "cost_func",
      "inv_depth",
      "context",
      "seq_len",
      "scale_func"
    ]
  },
  "BasicUpdateBlockPose": {
    "__init__": [
      "self",
      "hidden_dim",
      "cost_dim",
      "context_dim"
    ],
    "forward": [
      "self",
      "net",
      "cost_func",
      "pose",
      "inp",
      "seq_len"
    ]
  },
  "ResNetEncoder": {
    "__init__": [
      "self",
      "num_layers",
      "num_input_images",
      "pretrained",
      "out_chs",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNetEncoderV1": {
    "__init__": [
      "self",
      "num_layers",
      "num_input_images",
      "pretrained",
      "out_chs",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNetEncoderV2": {
    "__init__": [
      "self",
      "num_layers",
      "num_input_images",
      "pretrained",
      "out_chs",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FeatBlock": {
    "__init__": [
      "self",
      "planes",
      "out_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DepthPoseNet": {
    "__init__": [
      "self",
      "version",
      "min_depth",
      "max_depth"
    ],
    "upsample_depth": [
      "self",
      "depth",
      "mask",
      "ratio"
    ],
    "get_cost_each": [
      "self",
      "pose",
      "fmap",
      "fmap_ref",
      "depth",
      "K",
      "ref_K",
      "scale_factor"
    ],
    "depth_cost_calc": [
      "self",
      "inv_depth",
      "fmap",
      "fmaps_ref",
      "pose_list",
      "K",
      "ref_K",
      "scale_factor"
    ],
    "forward": [
      "self",
      "target_image",
      "ref_imgs",
      "intrinsics"
    ]
  },
  "stack_batch": [
    "batch"
  ],
  "SupModelMF": {
    "__init__": [
      "self"
    ],
    "logs": [
      "self"
    ],
    "supervised_loss": [
      "self",
      "image",
      "ref_images",
      "inv_depths",
      "gt_depth",
      "gt_poses",
      "poses",
      "intrinsics",
      "return_logs",
      "progress"
    ],
    "forward": [
      "self",
      "batch",
      "return_logs",
      "progress"
    ]
  },
  "save_code": [
    "filepath"
  ],
  "ModelCheckpoint": {
    "__init__": [
      "self",
      "filepath",
      "monitor",
      "save_top_k",
      "mode",
      "period",
      "s3_path",
      "s3_frequency"
    ],
    "_del_model": [
      "filepath"
    ],
    "_save_model": [
      "self",
      "filepath",
      "model"
    ],
    "check_monitor_top_k": [
      "self",
      "current"
    ],
    "format_checkpoint_name": [
      "self",
      "epoch",
      "metrics"
    ],
    "check_and_save": [
      "self",
      "model",
      "metrics"
    ],
    "_do_check_save": [
      "self",
      "filepath",
      "model",
      "current"
    ]
  },
  "SfmModelMF": {
    "__init__": [
      "self",
      "depth_net",
      "pose_net",
      "rotation_mode",
      "flip_lr_prob",
      "upsample_depth_maps",
      "min_depth",
      "max_depth"
    ],
    "logs": [
      "self"
    ],
    "losses": [
      "self"
    ],
    "add_loss": [
      "self",
      "key",
      "val"
    ],
    "network_requirements": [
      "self"
    ],
    "train_requirements": [
      "self"
    ],
    "add_depth_net": [
      "self",
      "depth_net"
    ],
    "add_pose_net": [
      "self",
      "pose_net"
    ],
    "compute_inv_depths": [
      "self",
      "image",
      "ref_imgs",
      "intrinsics"
    ],
    "compute_poses": [
      "self",
      "image",
      "contexts",
      "intrinsics",
      "depth"
    ],
    "forward": [
      "self",
      "batch",
      "return_logs"
    ]
  },
  "setup_depth_net": [
    "config",
    "prepared"
  ],
  "setup_pose_net": [
    "config",
    "prepared"
  ],
  "setup_percep_net": [
    "config",
    "prepared"
  ],
  "setup_model": [
    "config",
    "prepared"
  ],
  "NAFNetForImageDeblur": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "crop_process": [
      "self",
      "input"
    ],
    "_train_forward": [
      "self",
      "input",
      "target"
    ],
    "_inference_forward": [
      "self",
      "input"
    ],
    "_evaluate_postprocess": [
      "self",
      "input",
      "target"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "ImageColorEnhance": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_evaluate_postprocess": [
      "self",
      "src",
      "target"
    ],
    "_train_forward": [
      "self",
      "src",
      "target"
    ],
    "_inference_forward": [
      "self",
      "src"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Condition": {
    "__init__": [
      "self",
      "in_nc",
      "nf"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CSRNet": {
    "__init__": [
      "self",
      "in_nc",
      "out_nc",
      "base_nf",
      "cond_nf"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TPAMIBackbone": {
    "__init__": [
      "self",
      "pretrained",
      "input_resolution",
      "extra_pooling"
    ],
    "forward": [
      "self",
      "imgs"
    ]
  },
  "Res18Backbone": {
    "__init__": [
      "self",
      "pretrained",
      "input_resolution",
      "extra_pooling"
    ],
    "forward": [
      "self",
      "imgs"
    ]
  },
  "LUTGenerator": {
    "__init__": [
      "self",
      "n_colors",
      "n_vertices",
      "n_feats",
      "n_ranks"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "regularizations": [
      "self",
      "smoothness",
      "monotonicity"
    ]
  },
  "AdaInt": {
    "__init__": [
      "self",
      "n_colors",
      "n_vertices",
      "n_feats",
      "adaint_share"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AdaIntImageColorEnhance": {
    "__init__": [
      "self",
      "n_ranks",
      "n_vertices",
      "en_adaint",
      "en_adaint_share",
      "backbone",
      "pretrained",
      "n_colors"
    ],
    "init_weights": [
      "self"
    ],
    "__forward": [
      "self",
      "imgs"
    ],
    "_evaluate_postprocess": [
      "self",
      "src",
      "target"
    ],
    "_inference_forward": [
      "self",
      "src"
    ],
    "forward": [
      "self",
      "input"
    ],
    "regularizations": [
      "self",
      "smoothness",
      "monotonicity"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "DeepLPFImageColorEnhance": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_evaluate_postprocess": [
      "self",
      "src",
      "target"
    ],
    "_inference_forward": [
      "self",
      "src"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "BinaryLayer": {
    "forward": [
      "self",
      "input"
    ],
    "backward": [
      "self",
      "grad_output"
    ]
  },
  "CubicFilter": {
    "__init__": [
      "self",
      "num_in_channels",
      "num_out_channels",
      "batch_size"
    ],
    "get_cubic_mask": [
      "self",
      "feat",
      "img"
    ]
  },
  "GraduatedFilter": {
    "__init__": [
      "self",
      "num_in_channels",
      "num_out_channels"
    ],
    "tanh01": [
      "self",
      "x"
    ],
    "where": [
      "self",
      "cond",
      "x_1",
      "x_2"
    ],
    "get_inverted_mask": [
      "self",
      "factor",
      "invert",
      "d1",
      "d2",
      "max_scale",
      "top_line"
    ],
    "get_graduated_mask": [
      "self",
      "feat",
      "img"
    ]
  },
  "EllipticalFilter": {
    "__init__": [
      "self",
      "num_in_channels",
      "num_out_channels"
    ],
    "tanh01": [
      "self",
      "x"
    ],
    "where": [
      "self",
      "cond",
      "x_1",
      "x_2"
    ],
    "get_mask": [
      "self",
      "x_axis",
      "y_axis",
      "shift_x",
      "shift_y",
      "semi_axis_x",
      "semi_axis_y",
      "alpha",
      "scale_factor",
      "max_scale",
      "eps",
      "radius"
    ],
    "get_elliptical_mask": [
      "self",
      "feat",
      "img"
    ]
  },
  "MaxPoolBlock": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GlobalPoolingBlock": {
    "__init__": [
      "self",
      "receptive_field"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DeepLPFParameterPrediction": {
    "__init__": [
      "self",
      "num_in_channels",
      "num_out_channels",
      "batch_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LocalNet": {
    "forward": [
      "self",
      "x_in"
    ],
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ]
  },
  "DeepLPFNet": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "img"
    ]
  },
  "linear_assignment": [
    "cost_matrix",
    "thresh"
  ],
  "ious": [
    "atlbrs",
    "btlbrs"
  ],
  "iou_distance": [
    "atracks",
    "btracks"
  ],
  "embedding_distance": [
    "tracks",
    "detections",
    "metric"
  ],
  "fuse_motion": [
    "kf",
    "cost_matrix",
    "tracks",
    "detections",
    "only_position",
    "lambda_"
  ],
  "TrackState": {
    "New": [],
    "Tracked": [],
    "Lost": [],
    "Removed": []
  },
  "BaseTrack": {
    "_count": [],
    "track_id": [],
    "is_activated": [],
    "state": [],
    "history": [],
    "features": [],
    "curr_feature": [],
    "score": [],
    "start_frame": [],
    "frame_id": [],
    "time_since_update": [],
    "location": [],
    "end_frame": [
      "self"
    ],
    "next_id": [],
    "activate": [
      "self"
    ],
    "predict": [
      "self"
    ],
    "update": [
      "self"
    ],
    "mark_lost": [
      "self"
    ],
    "mark_removed": [
      "self"
    ]
  },
  "STrack": {
    "shared_kalman": [],
    "__init__": [
      "self",
      "tlwh",
      "score",
      "temp_feat",
      "buffer_size"
    ],
    "update_features": [
      "self",
      "feat"
    ],
    "predict": [
      "self"
    ],
    "multi_predict": [
      "stracks"
    ],
    "activate": [
      "self",
      "kalman_filter",
      "frame_id"
    ],
    "re_activate": [
      "self",
      "new_track",
      "frame_id",
      "new_id"
    ],
    "update": [
      "self",
      "new_track",
      "frame_id",
      "update_feature"
    ],
    "tlwh": [
      "self"
    ],
    "tlbr": [
      "self"
    ],
    "tlwh_to_xyah": [
      "tlwh"
    ],
    "to_xyah": [
      "self"
    ],
    "tlbr_to_tlwh": [
      "tlbr"
    ],
    "tlwh_to_tlbr": [
      "tlwh"
    ],
    "__repr__": [
      "self"
    ]
  },
  "JDETracker": {
    "__init__": [
      "self",
      "opt",
      "model_path",
      "device"
    ],
    "set_buffer_len": [
      "self",
      "frame_rate"
    ],
    "post_process": [
      "self",
      "dets",
      "meta"
    ],
    "merge_outputs": [
      "self",
      "detections"
    ],
    "update": [
      "self",
      "im_blob",
      "img0"
    ]
  },
  "joint_stracks": [
    "tlista",
    "tlistb"
  ],
  "sub_stracks": [
    "tlista",
    "tlistb"
  ],
  "remove_duplicate_stracks": [
    "stracksa",
    "stracksb"
  ],
  "get_color": [
    "idx"
  ],
  "plot_tracking": [
    "image",
    "tlwhs",
    "obj_ids",
    "scores",
    "frame_id",
    "fps",
    "ids2"
  ],
  "show_multi_object_tracking_result": [
    "video_in_path",
    "bboxes",
    "labels",
    "video_save_path"
  ],
  "chi2inv95": [],
  "KalmanFilter": {
    "__init__": [
      "self"
    ],
    "initiate": [
      "self",
      "measurement"
    ],
    "predict": [
      "self",
      "mean",
      "covariance"
    ],
    "project": [
      "self",
      "mean",
      "covariance"
    ],
    "multi_predict": [
      "self",
      "mean",
      "covariance"
    ],
    "update": [
      "self",
      "mean",
      "covariance",
      "measurement"
    ],
    "gating_distance": [
      "self",
      "mean",
      "covariance",
      "measurements",
      "only_position",
      "metric"
    ]
  },
  "LoadVideo": {
    "__init__": [
      "self",
      "path",
      "img_size"
    ],
    "get_size": [
      "self",
      "vw",
      "vh",
      "dw",
      "dh"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "letterbox": [
    "img",
    "new_shape",
    "color",
    "auto",
    "scaleFill",
    "scaleup"
  ],
  "cfg_opt": {
    "K": [],
    "arch": [],
    "conf_thres": [],
    "down_ratio": [],
    "head_conv": [],
    "heads": [],
    "img_size": [],
    "ltrb": [],
    "mean": [],
    "min_box_area": [],
    "num_classes": [],
    "reg_offset": [],
    "reid_dim": [],
    "std": [],
    "track_buffer": []
  },
  "ctdet_post_process": [
    "dets",
    "c",
    "s",
    "h",
    "w",
    "num_classes"
  ],
  "flip": [
    "img"
  ],
  "autopad": [
    "k",
    "p"
  ],
  "C3": {
    "__init__": [
      "self",
      "c1",
      "c2",
      "n",
      "shortcut",
      "g",
      "e"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "mot_decode": [
    "heat",
    "wh",
    "reg",
    "ltrb",
    "K"
  ],
  "backbone_param": [],
  "parse_model": [
    "d",
    "ch"
  ],
  "PoseYOLO": {
    "__init__": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_pose_net": [
    "num_layers",
    "heads",
    "head_conv"
  ],
  "make_divisible": [
    "x",
    "divisor"
  ],
  "_model_factory": [],
  "create_model": [
    "arch",
    "heads",
    "head_conv"
  ],
  "LayoutEstimation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "Inputs"
    ],
    "postprocess": [
      "self",
      "Inputs"
    ],
    "inference": [
      "self",
      "data"
    ]
  },
  "PanoVIT": {
    "__init__": [
      "self",
      "emb_dim",
      "input_hw",
      "input_norm",
      "pretrain",
      "backbone_config",
      "transformer_config",
      "modalities_config"
    ],
    "extract_feat": [
      "self",
      "x"
    ],
    "call_modality": [
      "self",
      "method"
    ],
    "forward": [
      "self",
      "x"
    ],
    "infer": [
      "self",
      "x"
    ],
    "postprocess": [
      "self",
      "image",
      "y_bon",
      "y_cor"
    ]
  },
  "StripPooling": {
    "__init__": [
      "self",
      "in_channels",
      "input_size",
      "pool_size",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "visualize_a_data": [
    "x",
    "y_bon",
    "y_cor"
  ],
  "ViTHorizonPryImage": {
    "__init__": [
      "self",
      "backbone",
      "fourier",
      "embedding"
    ],
    "forward": [
      "self",
      "img",
      "x"
    ]
  },
  "SPHead": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResnetDA": {
    "__init__": [
      "self",
      "backbone",
      "coco",
      "input_extra",
      "input_height"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "uv_meshgrid": [
    "w",
    "h"
  ],
  "_uv_tri": [
    "w",
    "h"
  ],
  "uv_tri": [
    "w",
    "h"
  ],
  "coorx2u": [
    "x",
    "w"
  ],
  "coory2v": [
    "y",
    "h"
  ],
  "u2coorx": [
    "u",
    "w"
  ],
  "v2coory": [
    "v",
    "h"
  ],
  "uv2xy": [
    "u",
    "v",
    "z"
  ],
  "pano_connect_points": [
    "p1",
    "p2",
    "z",
    "w",
    "h"
  ],
  "visualize_pano_stretch": [
    "stretched_img",
    "stretched_cor",
    "title"
  ],
  "PI": [],
  "sort_xy_filter_unique": [
    "xs",
    "ys",
    "y_small_first"
  ],
  "cor_2_1d": [
    "cor",
    "H",
    "W"
  ],
  "fuv2img": [
    "fuv",
    "coorW",
    "floorW",
    "floorH"
  ],
  "np_coorx2u": [
    "coorx",
    "coorW"
  ],
  "np_coory2v": [
    "coory",
    "coorH"
  ],
  "np_coor2xy": [
    "coor",
    "z",
    "coorW",
    "coorH",
    "floorW",
    "floorH"
  ],
  "np_x_u_solve_y": [
    "x",
    "u",
    "floorW",
    "floorH"
  ],
  "np_y_u_solve_x": [
    "y",
    "u",
    "floorW",
    "floorH"
  ],
  "np_xy2coor": [
    "xy",
    "z",
    "coorW",
    "coorH",
    "floorW",
    "floorH"
  ],
  "mean_percentile": [
    "vec",
    "p1",
    "p2"
  ],
  "vote": [
    "vec",
    "tol"
  ],
  "get_z1": [
    "coory0",
    "coory1",
    "z0",
    "coorH"
  ],
  "np_refine_by_fix_z": [
    "coory0",
    "coory1",
    "z0",
    "coorH"
  ],
  "infer_coory": [
    "coory0",
    "h",
    "z0",
    "coorH"
  ],
  "get_gpid": [
    "coorx",
    "coorW"
  ],
  "get_gpid_idx": [
    "gpid",
    "j"
  ],
  "gpid_two_split": [
    "xy",
    "tpid_a",
    "tpid_b"
  ],
  "_get_rot_rad": [
    "px",
    "py"
  ],
  "get_rot_rad": [
    "init_coorx",
    "coory",
    "z",
    "coorW",
    "coorH",
    "floorW",
    "floorH",
    "tol"
  ],
  "gen_ww_cuboid": [
    "xy",
    "gpid"
  ],
  "gen_ww_general": [
    "init_coorx",
    "xy",
    "gpid",
    "tol"
  ],
  "gen_ww": [
    "init_coorx",
    "coory",
    "z",
    "coorW",
    "coorH",
    "floorW",
    "floorH",
    "tol",
    "force_cuboid"
  ],
  "AL": [],
  "pas": [],
  "highpas": [],
  "gene_mask": [
    "f",
    "angle",
    "horizon"
  ],
  "normal": [
    "rgb_recons",
    "edge"
  ],
  "fourier_gray": [
    "img"
  ],
  "fourier": [
    "img"
  ],
  "LayoutEstimator": {
    "__init__": [
      "self",
      "emb_dim",
      "bon_weight",
      "cor_weight",
      "bon_loss",
      "cor_loss",
      "bon_scale",
      "init_weight",
      "dropout",
      "oneconv",
      "last_ks",
      "last_bias",
      "sigmod_normlize",
      "sample_weight",
      "H",
      "W",
      "post_force_cuboid"
    ],
    "forward": [
      "self",
      "x_emb"
    ],
    "infer": [
      "self",
      "x_emb"
    ]
  },
  "NormType": [],
  "is_listy": [
    "x"
  ],
  "_hook_inner": [
    "m",
    "i",
    "o"
  ],
  "hook_outputs": [
    "modules",
    "detach",
    "grad"
  ],
  "one_param": [
    "m"
  ],
  "dummy_batch": [
    "m",
    "size"
  ],
  "dummy_eval": [
    "m",
    "size"
  ],
  "model_sizes": [
    "m",
    "size"
  ],
  "PrePostInitMeta": {
    "__new__": [
      "cls",
      "name",
      "bases",
      "dct"
    ]
  },
  "Module": {
    "__pre_init__": [
      "self"
    ],
    "__init__": [
      "self"
    ]
  },
  "children": [
    "m"
  ],
  "num_children": [
    "m"
  ],
  "children_and_parameters": [
    "m"
  ],
  "flatten_model": [
    "m"
  ],
  "in_channels": [
    "m"
  ],
  "relu": [
    "inplace",
    "leaky"
  ],
  "conv_layer": [
    "ni",
    "nf",
    "ks",
    "stride",
    "padding",
    "bias",
    "is_1d",
    "norm_type",
    "use_activ",
    "leaky",
    "transpose",
    "init",
    "self_attention"
  ],
  "res_block": [
    "nf",
    "dense",
    "norm_type",
    "bottle"
  ],
  "conv1d": [
    "ni",
    "no",
    "ks",
    "stride",
    "padding",
    "bias"
  ],
  "sigmoid_range": [
    "x",
    "low",
    "high"
  ],
  "SigmoidRange": {
    "__init__": [
      "self",
      "low",
      "high"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SequentialEx": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "append": [
      "self",
      "layer"
    ],
    "extend": [
      "self",
      "layer"
    ],
    "insert": [
      "self",
      "i",
      "layer"
    ]
  },
  "MergeLayer": {
    "__init__": [
      "self",
      "dense"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PixelShuffle_ICNR": {
    "__init__": [
      "self",
      "ni",
      "nf",
      "scale",
      "blur",
      "norm_type",
      "leaky"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "custom_conv_layer": [
    "ni",
    "nf",
    "ks",
    "stride",
    "padding",
    "bias",
    "is_1d",
    "norm_type",
    "use_activ",
    "leaky",
    "transpose",
    "init",
    "self_attention",
    "extra_bn"
  ],
  "_get_sfs_idxs": [
    "sizes"
  ],
  "CustomPixelShuffle_ICNR": {
    "__init__": [
      "self",
      "ni",
      "nf",
      "scale",
      "blur",
      "leaky"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UnetBlockDeep": {
    "__init__": [
      "self",
      "up_in_c",
      "x_in_c",
      "hook",
      "final_div",
      "blur",
      "leaky",
      "self_attention",
      "nf_factor"
    ],
    "forward": [
      "self",
      "up_in"
    ]
  },
  "DynamicUnetDeep": {
    "__init__": [
      "self",
      "encoder",
      "n_classes",
      "blur",
      "blur_final",
      "self_attention",
      "y_range",
      "last_cross",
      "bottle",
      "norm_type",
      "nf_factor"
    ],
    "__del__": [
      "self"
    ]
  },
  "UnetBlockWide": {
    "__init__": [
      "self",
      "up_in_c",
      "x_in_c",
      "n_out",
      "hook",
      "final_div",
      "blur",
      "leaky",
      "self_attention"
    ],
    "forward": [
      "self",
      "up_in"
    ]
  },
  "DynamicUnetWide": {
    "__init__": [
      "self",
      "encoder",
      "n_classes",
      "blur",
      "blur_final",
      "self_attention",
      "y_range",
      "last_cross",
      "bottle",
      "norm_type",
      "nf_factor"
    ],
    "__del__": [
      "self"
    ]
  },
  "DDColor": {
    "__init__": [
      "self",
      "encoder_name",
      "input_size",
      "num_queries"
    ],
    "normalize": [
      "self",
      "img"
    ],
    "forward": [
      "self",
      "img"
    ]
  },
  "MultiScaleColorDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_dim",
      "num_queries",
      "nheads",
      "dim_feedforward",
      "dec_layers",
      "pre_norm",
      "color_embed_dim",
      "enforce_input_project",
      "num_scales"
    ],
    "forward": [
      "self",
      "feature_pyramid",
      "last_img_feature"
    ]
  },
  "l1_loss": [
    "pred",
    "target",
    "reduction"
  ],
  "tensor_lab2rgb": [
    "labs",
    "illuminant",
    "observer"
  ],
  "DDColorForImageColorization": {
    "__init__": [
      "self",
      "model_dir",
      "encoder_name",
      "input_size",
      "num_queries"
    ],
    "_load_pretrained": [
      "self",
      "net",
      "load_path",
      "strict",
      "param_key"
    ],
    "_train_forward": [
      "self",
      "input",
      "target"
    ],
    "_evaluate_postprocess": [
      "self",
      "input",
      "target",
      "img_l",
      "gt_rgb"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "batchnorm_2d": [
    "nf",
    "norm_type"
  ],
  "init_default": [
    "m",
    "func"
  ],
  "icnr": [
    "x",
    "scale",
    "init"
  ],
  "VGG_PRETRAIN_PATH": [],
  "NAMES": [],
  "insert_bn": [
    "names"
  ],
  "VGGFeatureExtractor": {
    "__init__": [
      "self",
      "layer_name_list",
      "vgg_type",
      "use_input_norm",
      "range_norm",
      "requires_grad",
      "remove_pooling",
      "pooling_stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SelfAttentionLayer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "dropout",
      "activation",
      "normalize_before"
    ],
    "_reset_parameters": [
      "self"
    ],
    "with_pos_embed": [
      "self",
      "tensor",
      "pos"
    ],
    "forward_post": [
      "self",
      "tgt",
      "tgt_mask",
      "tgt_key_padding_mask",
      "query_pos"
    ],
    "forward_pre": [
      "self",
      "tgt",
      "tgt_mask",
      "tgt_key_padding_mask",
      "query_pos"
    ],
    "forward": [
      "self",
      "tgt",
      "tgt_mask",
      "tgt_key_padding_mask",
      "query_pos"
    ]
  },
  "CrossAttentionLayer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "dropout",
      "activation",
      "normalize_before"
    ],
    "_reset_parameters": [
      "self"
    ],
    "with_pos_embed": [
      "self",
      "tensor",
      "pos"
    ],
    "forward_post": [
      "self",
      "tgt",
      "memory",
      "memory_mask",
      "memory_key_padding_mask",
      "pos",
      "query_pos"
    ],
    "forward_pre": [
      "self",
      "tgt",
      "memory",
      "memory_mask",
      "memory_key_padding_mask",
      "pos",
      "query_pos"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "memory_mask",
      "memory_key_padding_mask",
      "pos",
      "query_pos"
    ]
  },
  "FFNLayer": {
    "__init__": [
      "self",
      "d_model",
      "dim_feedforward",
      "dropout",
      "activation",
      "normalize_before"
    ],
    "_reset_parameters": [
      "self"
    ],
    "with_pos_embed": [
      "self",
      "tensor",
      "pos"
    ],
    "forward_post": [
      "self",
      "tgt"
    ],
    "forward_pre": [
      "self",
      "tgt"
    ],
    "forward": [
      "self",
      "tgt"
    ]
  },
  "QuadTreeAttentionForImageMatching": {
    "__init__": [
      "self",
      "model_dir",
      "model_type"
    ],
    "forward": [
      "self",
      "Inputs"
    ],
    "postprocess": [
      "self",
      "Inputs"
    ],
    "inference": [
      "self",
      "data"
    ]
  },
  "QuadtreeAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "topks",
      "value_branch",
      "act",
      "qkv_bias",
      "qk_scale",
      "attn_drop",
      "proj_drop",
      "scale",
      "attn_type"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "forward": [
      "self",
      "x",
      "target",
      "H",
      "W",
      "msg"
    ]
  },
  "QuadtreeBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "topks",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "drop_path",
      "act_layer",
      "norm_layer",
      "scale",
      "attn_type"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "forward": [
      "self",
      "x",
      "target",
      "H",
      "W"
    ]
  },
  "YOLOXONNX": {
    "__init__": [
      "self",
      "onnx_path",
      "multi_detect"
    ],
    "format_judge": [
      "self",
      "img"
    ],
    "preprocess": [
      "self",
      "image",
      "input_size",
      "swap"
    ],
    "cal_iou": [
      "self",
      "val1",
      "val2"
    ],
    "nms": [
      "self",
      "boxes",
      "scores",
      "nms_thr"
    ],
    "multiclass_nms": [
      "self",
      "boxes",
      "scores",
      "nms_thr",
      "score_thr"
    ],
    "postprocess": [
      "self",
      "outputs",
      "img_size",
      "p6"
    ],
    "get_new_box_order": [
      "self",
      "bboxes",
      "labels",
      "img_h",
      "img_w"
    ],
    "forward": [
      "self",
      "img_input",
      "cid",
      "sub_class"
    ]
  },
  "gn_init": [
    "m",
    "zero_init"
  ],
  "resnet50_embed": [],
  "ProductRetrievalEmbedding": {
    "__init__": [
      "self",
      "model_dir",
      "device"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "convert_to_square": [
    "bboxes"
  ],
  "calibrate_box": [
    "bboxes",
    "offsets"
  ],
  "get_image_boxes": [
    "bounding_boxes",
    "img",
    "size"
  ],
  "correct_bboxes": [
    "bboxes",
    "width",
    "height"
  ],
  "_preprocess": [
    "img"
  ],
  "PNet": {
    "__init__": [
      "self",
      "model_path"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RNet": {
    "__init__": [
      "self",
      "model_path"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ONet": {
    "__init__": [
      "self",
      "model_path"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MtcnnFaceDetector": {
    "__init__": [
      "self",
      "model_path",
      "device"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "run_first_stage": [
    "image",
    "net",
    "scale",
    "threshold",
    "device"
  ],
  "_generate_bboxes": [
    "probs",
    "offsets",
    "scale",
    "threshold"
  ],
  "DamoFdDetect": {
    "__init__": [
      "self",
      "model_dir"
    ]
  },
  "SCRFDPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "TinyMogDetect": {
    "__init__": [
      "self",
      "model_dir"
    ]
  },
  "ScrfdDetect": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "img",
      "img_metas"
    ],
    "postprocess": [
      "self",
      "detection_out"
    ]
  },
  "RetinaFaceDataset": {
    "CLASSES": [],
    "__init__": [
      "self",
      "min_size"
    ],
    "_parse_ann_line": [
      "self",
      "line"
    ],
    "load_annotations": [
      "self",
      "ann_file"
    ],
    "get_ann_info": [
      "self",
      "idx"
    ]
  },
  "LoadAnnotationsV2": {
    "__init__": [
      "self",
      "with_bbox",
      "with_label",
      "with_keypoints",
      "with_mask",
      "with_seg",
      "poly2mask",
      "file_client_args"
    ],
    "_load_bboxes": [
      "self",
      "results"
    ],
    "_load_keypoints": [
      "self",
      "results"
    ],
    "_load_labels": [
      "self",
      "results"
    ],
    "_poly2mask": [
      "self",
      "mask_ann",
      "img_h",
      "img_w"
    ],
    "process_polygons": [
      "self",
      "polygons"
    ],
    "_load_masks": [
      "self",
      "results"
    ],
    "_load_semantic_seg": [
      "self",
      "results"
    ],
    "__call__": [
      "self",
      "results"
    ],
    "__repr__": [
      "self"
    ]
  },
  "level_to_value": [
    "level",
    "max_value"
  ],
  "random_negative": [
    "value",
    "random_negative_prob"
  ],
  "bbox2fields": [],
  "RotateV2": {
    "__init__": [
      "self",
      "level",
      "scale",
      "center",
      "img_fill_val",
      "seg_ignore_label",
      "prob",
      "max_rotate_angle",
      "random_negative_prob"
    ],
    "_rotate_img": [
      "self",
      "results",
      "angle",
      "center",
      "scale"
    ],
    "_rotate_bboxes": [
      "self",
      "results",
      "rotate_matrix"
    ],
    "_rotate_keypoints90": [
      "self",
      "results",
      "angle"
    ],
    "_rotate_masks": [
      "self",
      "results",
      "angle",
      "center",
      "scale",
      "fill_val"
    ],
    "_rotate_seg": [
      "self",
      "results",
      "angle",
      "center",
      "scale",
      "fill_val"
    ],
    "_filter_invalid": [
      "self",
      "results",
      "min_bbox_size"
    ],
    "__call__": [
      "self",
      "results"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ResizeV2": {
    "__init__": [
      "self",
      "img_scale",
      "multiscale_mode",
      "ratio_range",
      "keep_ratio",
      "bbox_clip_border",
      "backend",
      "override"
    ],
    "random_select": [
      "img_scales"
    ],
    "random_sample": [
      "img_scales"
    ],
    "random_sample_ratio": [
      "img_scale",
      "ratio_range"
    ],
    "_random_scale": [
      "self",
      "results"
    ],
    "_resize_img": [
      "self",
      "results"
    ],
    "_resize_bboxes": [
      "self",
      "results"
    ],
    "_resize_keypoints": [
      "self",
      "results"
    ],
    "_resize_masks": [
      "self",
      "results"
    ],
    "_resize_seg": [
      "self",
      "results"
    ],
    "__call__": [
      "self",
      "results"
    ],
    "__repr__": [
      "self"
    ]
  },
  "RandomFlipV2": {
    "__init__": [
      "self",
      "flip_ratio",
      "direction"
    ],
    "bbox_flip": [
      "self",
      "bboxes",
      "img_shape",
      "direction"
    ],
    "keypoints_flip": [
      "self",
      "keypointss",
      "img_shape",
      "direction"
    ],
    "__call__": [
      "self",
      "results"
    ],
    "__repr__": [
      "self"
    ]
  },
  "RandomSquareCrop": {
    "__init__": [
      "self",
      "crop_ratio_range",
      "crop_choice",
      "bbox_clip_border",
      "big_face_ratio",
      "big_face_crop_choice"
    ],
    "__call__": [
      "self",
      "results"
    ],
    "__repr__": [
      "self"
    ]
  },
  "DefaultFormatBundleV2": {
    "__call__": [
      "self",
      "results"
    ],
    "_add_default_meta_keys": [
      "self",
      "results"
    ],
    "__repr__": [
      "self"
    ]
  },
  "BaseDetector": {
    "__init__": [
      "self"
    ],
    "with_neck": [
      "self"
    ],
    "with_shared_head": [
      "self"
    ],
    "with_bbox": [
      "self"
    ],
    "with_mask": [
      "self"
    ],
    "extract_feat": [
      "self",
      "imgs"
    ],
    "extract_feats": [
      "self",
      "imgs"
    ],
    "forward_train": [
      "self",
      "imgs",
      "img_metas"
    ],
    "async_simple_test": [
      "self",
      "img",
      "img_metas"
    ],
    "simple_test": [
      "self",
      "img",
      "img_metas"
    ],
    "aug_test": [
      "self",
      "imgs",
      "img_metas"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ],
    "aforward_test": [
      "self"
    ],
    "forward_test": [
      "self",
      "imgs",
      "img_metas"
    ],
    "forward": [
      "self",
      "img",
      "img_metas",
      "return_loss"
    ],
    "_parse_losses": [
      "self",
      "losses"
    ],
    "train_step": [
      "self",
      "data",
      "optimizer"
    ],
    "val_step": [
      "self",
      "data",
      "optimizer"
    ]
  },
  "SCRFD": {
    "__init__": [
      "self",
      "backbone",
      "neck",
      "bbox_head",
      "train_cfg",
      "test_cfg",
      "pretrained"
    ],
    "forward_train": [
      "self",
      "img",
      "img_metas",
      "gt_bboxes",
      "gt_labels",
      "gt_keypointss",
      "gt_bboxes_ignore"
    ],
    "simple_test": [
      "self",
      "img",
      "img_metas",
      "rescale",
      "repeat_head",
      "output_kps_var",
      "output_results"
    ],
    "feature_test": [
      "self",
      "img"
    ]
  },
  "TinyMog": {
    "__init__": [
      "self",
      "backbone",
      "neck",
      "bbox_head",
      "train_cfg",
      "test_cfg",
      "pretrained"
    ],
    "forward_train": [
      "self",
      "img",
      "img_metas",
      "gt_bboxes",
      "gt_labels",
      "gt_keypointss",
      "gt_bboxes_ignore"
    ],
    "simple_test": [
      "self",
      "img",
      "img_metas",
      "rescale",
      "repeat_head",
      "output_kps_var",
      "output_results"
    ],
    "feature_test": [
      "self",
      "img"
    ]
  },
  "CustomSingleStageDetector": {
    "__init__": [
      "self",
      "backbone",
      "neck",
      "bbox_head",
      "train_cfg",
      "test_cfg",
      "pretrained"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ],
    "extract_feat": [
      "self",
      "img"
    ],
    "forward_dummy": [
      "self",
      "img"
    ],
    "forward_train": [
      "self",
      "img",
      "img_metas",
      "gt_bboxes",
      "gt_labels",
      "gt_bboxes_ignore"
    ],
    "simple_test": [
      "self",
      "img",
      "img_metas",
      "rescale"
    ],
    "aug_test": [
      "self",
      "imgs",
      "img_metas",
      "rescale"
    ]
  },
  "ResNetV1e": {
    "__init__": [
      "self"
    ]
  },
  "MasterNet": {
    "__init__": [
      "self",
      "argv",
      "opt",
      "num_classes",
      "plainnet_struct",
      "no_create",
      "no_reslink",
      "no_BN",
      "use_se",
      "dropout"
    ],
    "extract_stage_features_and_logit": [
      "self",
      "x",
      "target_downsample_ratio"
    ],
    "forward": [
      "self",
      "x"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ]
  },
  "SCRFDHead": {
    "__init__": [
      "self",
      "num_classes",
      "in_channels",
      "stacked_convs",
      "feat_mults",
      "conv_cfg",
      "norm_cfg",
      "loss_dfl",
      "reg_max",
      "cls_reg_share",
      "strides_share",
      "scale_mode",
      "dw_conv",
      "use_kps",
      "num_kps",
      "loss_kps"
    ],
    "_get_conv_module": [
      "self",
      "in_channel",
      "out_channel"
    ],
    "_init_layers": [
      "self"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "feats"
    ],
    "forward_single": [
      "self",
      "x",
      "scale",
      "stride"
    ],
    "forward_train": [
      "self",
      "x",
      "img_metas",
      "gt_bboxes",
      "gt_labels",
      "gt_keypointss",
      "gt_bboxes_ignore",
      "proposal_cfg"
    ],
    "get_anchors": [
      "self",
      "featmap_sizes",
      "img_metas",
      "device"
    ],
    "anchor_center": [
      "self",
      "anchors"
    ],
    "loss_single": [
      "self",
      "anchors",
      "cls_score",
      "bbox_pred",
      "kps_pred",
      "labels",
      "label_weights",
      "bbox_targets",
      "kps_targets",
      "kps_weights",
      "stride",
      "num_total_samples"
    ],
    "loss": [
      "self",
      "cls_scores",
      "bbox_preds",
      "kps_preds",
      "gt_bboxes",
      "gt_labels",
      "gt_keypointss",
      "img_metas",
      "gt_bboxes_ignore"
    ],
    "get_bboxes": [
      "self",
      "cls_scores",
      "bbox_preds",
      "kps_preds",
      "img_metas",
      "cfg",
      "rescale",
      "with_nms"
    ],
    "_get_bboxes_single": [
      "self",
      "cls_scores",
      "bbox_preds",
      "kps_preds",
      "mlvl_anchors",
      "img_shape",
      "scale_factor",
      "cfg",
      "rescale",
      "with_nms"
    ],
    "get_targets": [
      "self",
      "anchor_list",
      "valid_flag_list",
      "gt_bboxes_list",
      "gt_keypointss_list",
      "img_metas",
      "gt_bboxes_ignore_list",
      "gt_labels_list",
      "label_channels",
      "unmap_outputs"
    ],
    "_get_target_single": [
      "self",
      "flat_anchors",
      "valid_flags",
      "num_level_anchors",
      "gt_bboxes",
      "gt_bboxes_ignore",
      "gt_labels",
      "gt_keypointss",
      "img_meta",
      "label_channels",
      "unmap_outputs"
    ],
    "get_num_level_anchors_inside": [
      "self",
      "num_level_anchors",
      "inside_flags"
    ],
    "aug_test": [
      "self",
      "feats",
      "img_metas",
      "rescale"
    ]
  },
  "bbox2result": [
    "bboxes",
    "labels",
    "num_classes",
    "kps",
    "num_kps"
  ],
  "distance2kps": [
    "points",
    "distance",
    "max_shape"
  ],
  "kps2distance": [
    "points",
    "kps",
    "max_dis",
    "eps"
  ],
  "MogFaceDetector": {
    "__init__": [
      "self",
      "model_path",
      "device"
    ],
    "load_model": [
      "self",
      "load_to_cpu"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "transform_anchor": [
    "anchors"
  ],
  "normalize_anchor": [
    "anchors"
  ],
  "MogPriorBox": {
    "__init__": [
      "self",
      "scale_list",
      "aspect_ratio_list",
      "stride_list",
      "anchor_size_list"
    ],
    "__call__": [
      "self",
      "img_height",
      "img_width"
    ]
  },
  "mogdecode": [
    "loc",
    "anchors"
  ],
  "MogFace": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LFPN": {
    "__init__": [
      "self",
      "c2_out_ch",
      "c3_out_ch",
      "c4_out_ch",
      "c5_out_ch",
      "c6_mid_ch",
      "c6_out_ch",
      "c7_mid_ch",
      "c7_out_ch",
      "out_dsfd_ft"
    ],
    "forward": [
      "self",
      "feature_list"
    ]
  },
  "SSHContext": {
    "__init__": [
      "self",
      "channels",
      "Xchannels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DeepHead": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel",
      "use_gn",
      "num_conv"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MogPredNet": {
    "__init__": [
      "self",
      "num_anchor_per_pixel",
      "num_classes",
      "input_ch_list",
      "use_deep_head",
      "deep_head_with_gn",
      "use_ssh",
      "deep_head_ch"
    ],
    "forward": [
      "self",
      "pyramid_feature_list",
      "dsfd_ft_list"
    ]
  },
  "UlfdFaceDetector": {
    "__init__": [
      "self",
      "model_path",
      "device"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "hard_nms": [
    "box_scores",
    "iou_threshold",
    "top_k",
    "candidate_size"
  ],
  "generate_priors": [
    "feature_map_list",
    "shrinkage_list",
    "image_size",
    "min_boxes",
    "clamp"
  ],
  "convert_locations_to_boxes": [
    "locations",
    "priors",
    "center_variance",
    "size_variance"
  ],
  "center_form_to_corner_form": [
    "locations"
  ],
  "iou_of": [
    "boxes0",
    "boxes1",
    "eps"
  ],
  "area_of": [
    "left_top",
    "right_bottom"
  ],
  "Mb_Tiny": {
    "__init__": [
      "self",
      "num_classes"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SubtractMeans": {
    "__init__": [
      "self",
      "mean"
    ],
    "__call__": [
      "self",
      "image",
      "boxes",
      "labels"
    ]
  },
  "SeperableConv2d": [
    "in_channels",
    "out_channels",
    "kernel_size",
    "stride",
    "padding"
  ],
  "create_mb_tiny_fd": [
    "num_classes",
    "is_test",
    "device"
  ],
  "create_mb_tiny_fd_predictor": [
    "net",
    "candidate_size",
    "nms_method",
    "sigma",
    "device"
  ],
  "PredictionTransform": {
    "__init__": [
      "self",
      "size",
      "mean",
      "std"
    ],
    "__call__": [
      "self",
      "image"
    ]
  },
  "Predictor": {
    "__init__": [
      "self",
      "net",
      "size",
      "mean",
      "std",
      "nms_method",
      "iou_threshold",
      "filter_threshold",
      "candidate_size",
      "sigma",
      "device"
    ],
    "predict": [
      "self",
      "image",
      "top_k",
      "prob_threshold"
    ]
  },
  "GraphPath": [],
  "SSD": {
    "__init__": [
      "self",
      "num_classes",
      "base_net",
      "source_layer_indexes",
      "extras",
      "classification_headers",
      "regression_headers",
      "is_test",
      "config",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ],
    "compute_header": [
      "self",
      "i",
      "x"
    ],
    "load": [
      "self",
      "model"
    ]
  },
  "image_mean_test": [],
  "image_mean": [],
  "image_std": [],
  "iou_threshold": [],
  "center_variance": [],
  "size_variance": [],
  "min_boxes": [],
  "shrinkage_list": [],
  "image_size": [],
  "feature_map_w_h_list": [],
  "priors": [],
  "define_img_size": [
    "size"
  ],
  "ImageRestorationModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "inference": [
      "self",
      "data"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "model_map": [],
  "my_model": {
    "__init__": [
      "self",
      "en_feature_num",
      "en_inter_num",
      "de_feature_num",
      "de_inter_num",
      "sam_number"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_initialize_weights": [
      "self"
    ]
  },
  "Encoder_Level": {
    "__init__": [
      "self",
      "feature_num",
      "inter_num",
      "level",
      "sam_number"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Decoder_Level": {
    "__init__": [
      "self",
      "feature_num",
      "inter_num",
      "sam_number"
    ],
    "forward": [
      "self",
      "x",
      "feat"
    ]
  },
  "DB": {
    "__init__": [
      "self",
      "in_channel",
      "d_list",
      "inter_num"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CSAF": {
    "__init__": [
      "self",
      "in_chnls",
      "ratio"
    ],
    "forward": [
      "self",
      "x0",
      "x2",
      "x4"
    ]
  },
  "RDB": {
    "__init__": [
      "self",
      "in_channel",
      "d_list",
      "inter_num"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DAWarp": [
    "feat",
    "offsets",
    "att_maps",
    "sample_k",
    "out_ch"
  ],
  "MFEBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "num_filters"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "DAFlowNet": {
    "__init__": [
      "self",
      "num_pyramid",
      "fpn_dim",
      "head_nums"
    ],
    "forward": [
      "self",
      "source_image",
      "reference_image",
      "source_feats",
      "reference_feats",
      "return_all",
      "warp_feature",
      "use_light_en_de"
    ]
  },
  "SDAFNet_Tryon": {
    "__init__": [
      "self",
      "ref_in_channel",
      "source_in_channel",
      "head_nums"
    ],
    "forward": [
      "self",
      "ref_input",
      "source_image",
      "ref_image",
      "use_light_en_de",
      "return_all",
      "warp_feature"
    ]
  },
  "align_face": [
    "image",
    "size",
    "lmks"
  ],
  "GetAffinePoints": [
    "pts_in",
    "trans"
  ],
  "RTSBackbone": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "img"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "initialize_weights": [
    "modules"
  ],
  "BasicBlockIR": {
    "__init__": [
      "self",
      "in_channel",
      "depth",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BasicBlockIRSE": {
    "__init__": [
      "self",
      "in_channel",
      "depth",
      "stride"
    ]
  },
  "IR_18": [
    "input_size"
  ],
  "IR_34": [
    "input_size"
  ],
  "IR_200": [
    "input_size"
  ],
  "IR_SE_200": [
    "input_size"
  ],
  "IResNet": {
    "__init__": [
      "self",
      "dropout",
      "num_features",
      "zero_init_residual",
      "groups",
      "width_per_group",
      "replace_stride_with_dilation",
      "fp16",
      "with_wcd",
      "wrs_M",
      "wrs_q"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "iresnet286": [
    "pretrained",
    "progress"
  ],
  "ResNet_50": [
    "input_size"
  ],
  "ResNet_101": [
    "input_size"
  ],
  "ResNet_152": [
    "input_size"
  ],
  "_model_dict": [],
  "get_model": [
    "key"
  ],
  "using_ckpt": [],
  "IBasicBlock": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "groups",
      "base_width",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_iresnet": [
    "arch",
    "layers"
  ],
  "FacialLandmarkConfidence": {
    "__init__": [
      "self",
      "model_path",
      "device"
    ],
    "load_model": [
      "self",
      "load_to_cpu"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "LandmarkConfidence": {
    "__init__": [
      "self",
      "landmark_count"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FC": {
    "__init__": [
      "self",
      "feat_dim",
      "num_class"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RespiratorNet": {
    "__init__": [
      "self"
    ],
    "train": [
      "self",
      "mode"
    ],
    "forward": [
      "self",
      "x",
      "y"
    ]
  },
  "ClassNet": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LandmarkNetD": {
    "__init__": [
      "self",
      "landmark_count"
    ],
    "_initialize_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DetectionModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "inference": [
      "self",
      "data"
    ],
    "preprocess": [
      "self",
      "image"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "calc_rel_pos_spatial": [
    "attn",
    "q",
    "q_shape",
    "k_shape",
    "rel_pos_h",
    "rel_pos_w"
  ],
  "HybridEmbed": {
    "__init__": [
      "self",
      "backbone",
      "img_size",
      "feature_size",
      "in_chans",
      "embed_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Norm2d": {
    "__init__": [
      "self",
      "embed_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ViT": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "in_chans",
      "num_classes",
      "embed_dim",
      "depth",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "hybrid_backbone",
      "norm_layer",
      "init_values",
      "use_checkpoint",
      "use_abs_pos_emb",
      "use_rel_pos_bias",
      "use_shared_rel_pos_bias",
      "out_indices",
      "interval",
      "pretrained"
    ],
    "fix_init_weight": [
      "self"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ],
    "get_num_layers": [
      "self"
    ],
    "no_weight_decay": [
      "self"
    ],
    "forward_features": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "load_pavimodel_dist": [
    "model_path",
    "map_location"
  ],
  "load_fileclient_dist": [
    "filename",
    "backend",
    "map_location"
  ],
  "get_external_models": [],
  "get_mmcls_models": [],
  "get_deprecated_model_names": [],
  "ConvModule_Norm": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel"
    ],
    "forward": [
      "self",
      "x",
      "activate",
      "norm"
    ]
  },
  "RPNNHead": {
    "__init__": [
      "self",
      "in_channels",
      "init_cfg",
      "num_convs"
    ],
    "_init_layers": [
      "self"
    ],
    "forward_single": [
      "self",
      "x"
    ],
    "loss": [
      "self",
      "cls_scores",
      "bbox_preds",
      "gt_bboxes",
      "img_metas",
      "gt_bboxes_ignore"
    ],
    "_get_bboxes_single": [
      "self",
      "cls_score_list",
      "bbox_pred_list",
      "score_factor_list",
      "mlvl_anchors",
      "img_meta",
      "cfg",
      "rescale",
      "with_nms"
    ],
    "_bbox_post_process": [
      "self",
      "mlvl_scores",
      "mlvl_bboxes",
      "mlvl_valid_anchors",
      "level_ids",
      "cfg",
      "img_shape"
    ],
    "onnx_export": [
      "self",
      "x",
      "img_metas"
    ]
  },
  "AnchorNHead": {
    "__init__": [
      "self",
      "num_classes",
      "in_channels",
      "feat_channels",
      "anchor_generator",
      "bbox_coder",
      "reg_decoded_bbox",
      "loss_cls",
      "loss_bbox",
      "train_cfg",
      "test_cfg",
      "norm_cfg",
      "init_cfg"
    ]
  },
  "BYTES_PER_FLOAT": [],
  "GPU_MEM_LIMIT": [],
  "FCNMaskNHead": {
    "__init__": [
      "self",
      "num_convs",
      "roi_feat_size",
      "in_channels",
      "conv_kernel_size",
      "conv_out_channels",
      "num_classes",
      "class_agnostic",
      "upsample_cfg",
      "conv_cfg",
      "norm_cfg",
      "predictor_cfg",
      "loss_mask",
      "init_cfg"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_targets": [
      "self",
      "sampling_results",
      "gt_masks",
      "rcnn_train_cfg"
    ],
    "loss": [
      "self",
      "mask_pred",
      "mask_targets",
      "labels"
    ],
    "get_seg_masks": [
      "self",
      "mask_pred",
      "det_bboxes",
      "det_labels",
      "rcnn_test_cfg",
      "ori_shape",
      "scale_factor",
      "rescale"
    ],
    "onnx_export": [
      "self",
      "mask_pred",
      "det_bboxes",
      "det_labels",
      "rcnn_test_cfg",
      "ori_shape"
    ]
  },
  "_do_paste_mask": [
    "masks",
    "boxes",
    "img_h",
    "img_w",
    "skip_empty"
  ],
  "ConvFCBBoxNHead": {
    "__init__": [
      "self",
      "num_shared_convs",
      "num_shared_fcs",
      "num_cls_convs",
      "num_cls_fcs",
      "num_reg_convs",
      "num_reg_fcs",
      "conv_out_channels",
      "fc_out_channels",
      "conv_cfg",
      "norm_cfg",
      "init_cfg"
    ],
    "_add_conv_fc_branch": [
      "self",
      "num_branch_convs",
      "num_branch_fcs",
      "in_channels",
      "is_shared"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Shared2FCBBoxNHead": {
    "__init__": [
      "self",
      "fc_out_channels"
    ]
  },
  "Shared4Conv1FCBBoxNHead": {
    "__init__": [
      "self",
      "fc_out_channels"
    ]
  },
  "FPNF": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_outs",
      "start_level",
      "end_level",
      "add_extra_convs",
      "relu_before_extra_convs",
      "no_norm_on_lateral",
      "conv_cfg",
      "norm_cfg",
      "act_cfg",
      "use_residual",
      "upsample_cfg",
      "init_cfg"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "SemanticSegmentation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "Inputs"
    ],
    "postprocess": [
      "self",
      "Inputs"
    ],
    "inference": [
      "self",
      "data"
    ]
  },
  "DDPMSegmentationModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "inference": [
      "self",
      "batch",
      "seed"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "create_feature_extractor": [
    "model_type"
  ],
  "save_tensors": [
    "module",
    "features",
    "name"
  ],
  "save_out_hook": [
    "self",
    "inp",
    "out"
  ],
  "save_input_hook": [
    "self",
    "inp",
    "out"
  ],
  "FeatureExtractorDDPM": {
    "__init__": [
      "self",
      "steps",
      "blocks"
    ],
    "_load_pretrained_model": [
      "self",
      "model_path"
    ],
    "forward": [
      "self",
      "x",
      "noise"
    ]
  },
  "collect_features": [
    "cfg",
    "activations",
    "sample_idx"
  ],
  "multi_acc": [
    "y_pred",
    "y_test"
  ],
  "oht_to_scalar": [
    "y_pred"
  ],
  "colorize_mask": [
    "mask",
    "palette"
  ],
  "to_labels": [
    "masks",
    "palette"
  ],
  "get_palette": [
    "category"
  ],
  "get_class_names": [
    "category"
  ],
  "bedroom_class": [],
  "ffhq_class": [],
  "cat_class": [],
  "horse_class": [],
  "celeba_class": [],
  "ade_bedroom_50_class": [],
  "ade_bedroom_40_class": [],
  "ade_bedroom_30_class": [],
  "ffhq_palette": [],
  "bedroom_palette": [],
  "cat_palette": [],
  "horse_palette": [],
  "celeba_palette": [],
  "ade_bedroom_50_palette": [],
  "ade_bedroom_40_palette": [],
  "ade_bedroom_30_palette": [],
  "pixel_classifier": {
    "__init__": [
      "self",
      "category",
      "dim"
    ],
    "init_weights": [
      "self",
      "init_type",
      "gain"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "predict_labels": [
    "models",
    "features",
    "size"
  ],
  "load_ensemble": [
    "model_num",
    "model_path",
    "device",
    "category",
    "dim"
  ],
  "save_predictions": [
    "preds",
    "category"
  ],
  "MaskFormerSemanticHead": {
    "__init__": [
      "self",
      "num_things_classes",
      "num_stuff_classes",
      "test_cfg",
      "loss_panoptic",
      "init_cfg"
    ],
    "forward_train": [
      "self"
    ],
    "simple_test": [
      "self",
      "mask_cls_results",
      "mask_pred_results",
      "img_metas",
      "rescale"
    ]
  },
  "BasePanopticFusionHead": {
    "__init__": [
      "self",
      "num_things_classes",
      "num_stuff_classes",
      "test_cfg",
      "loss_panoptic",
      "init_cfg"
    ],
    "with_loss": [
      "self"
    ],
    "forward_train": [
      "self",
      "gt_masks",
      "gt_semantic_seg"
    ],
    "simple_test": [
      "self",
      "img_metas",
      "det_labels",
      "mask_preds",
      "seg_preds",
      "det_bboxes",
      "cfg"
    ]
  },
  "seg_resize": [
    "input",
    "size",
    "scale_factor",
    "mode",
    "align_corners",
    "warning"
  ],
  "add_prefix": [
    "inputs",
    "prefix"
  ],
  "PIXEL_SAMPLERS": [],
  "build_pixel_sampler": [
    "cfg"
  ],
  "ResizeToMultiple": {
    "__init__": [
      "self",
      "size_divisor",
      "interpolation"
    ],
    "__call__": [
      "self",
      "results"
    ],
    "__repr__": [
      "self"
    ]
  },
  "BEiTAdapter": {
    "__init__": [
      "self",
      "pretrain_size",
      "conv_inplane",
      "n_points",
      "deform_num_heads",
      "init_values",
      "cffn_ratio",
      "deform_ratio",
      "with_cffn",
      "interaction_indexes",
      "add_vit_feature",
      "with_cp"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "_get_pos_embed": [
      "self",
      "pos_embed",
      "H",
      "W"
    ],
    "_init_deform_weights": [
      "self",
      "m"
    ],
    "_add_level_embed": [
      "self",
      "c2",
      "c3",
      "c4"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_reference_points": [
    "spatial_shapes",
    "device"
  ],
  "deform_inputs": [
    "x"
  ],
  "ConvFFN": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "act_layer",
      "drop"
    ],
    "forward": [
      "self",
      "x",
      "H",
      "W"
    ]
  },
  "Injector": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "n_points",
      "n_levels",
      "deform_ratio",
      "norm_layer",
      "init_values",
      "with_cp"
    ],
    "forward": [
      "self",
      "query",
      "reference_points",
      "feat",
      "spatial_shapes",
      "level_start_index"
    ]
  },
  "InteractionBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "n_points",
      "norm_layer",
      "drop",
      "drop_path",
      "with_cffn",
      "cffn_ratio",
      "init_values",
      "deform_ratio",
      "extra_extractor",
      "with_cp"
    ],
    "forward": [
      "self",
      "x",
      "c",
      "blocks",
      "deform_inputs1",
      "deform_inputs2",
      "H",
      "W"
    ]
  },
  "InteractionBlockWithCls": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "n_points",
      "norm_layer",
      "drop",
      "drop_path",
      "with_cffn",
      "cffn_ratio",
      "init_values",
      "deform_ratio",
      "extra_extractor",
      "with_cp"
    ],
    "forward": [
      "self",
      "x",
      "c",
      "cls",
      "blocks",
      "deform_inputs1",
      "deform_inputs2",
      "H",
      "W"
    ]
  },
  "SpatialPriorModule": {
    "__init__": [
      "self",
      "inplanes",
      "embed_dim",
      "with_cp"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BASEBEiT": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "in_chans",
      "num_classes",
      "embed_dim",
      "depth",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "hybrid_backbone",
      "norm_layer",
      "init_values",
      "use_checkpoint",
      "use_abs_pos_emb",
      "use_rel_pos_bias",
      "use_shared_rel_pos_bias",
      "pretrained",
      "with_cp"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ],
    "fix_init_weight": [
      "self"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "get_num_layers": [
      "self"
    ]
  },
  "Mask2FormerHeadFromMMSeg": {
    "__init__": [
      "self",
      "in_channels",
      "feat_channels",
      "out_channels",
      "num_things_classes",
      "num_stuff_classes",
      "num_queries",
      "num_transformer_feat_level",
      "pixel_decoder",
      "enforce_decoder_input_project",
      "transformer_decoder",
      "positional_encoding",
      "loss_cls",
      "loss_mask",
      "loss_dice",
      "train_cfg",
      "test_cfg",
      "init_cfg"
    ],
    "init_weights": [
      "self"
    ],
    "get_targets": [
      "self",
      "cls_scores_list",
      "mask_preds_list",
      "gt_labels_list",
      "gt_masks_list",
      "img_metas"
    ],
    "_get_target_single": [
      "self",
      "cls_score",
      "mask_pred",
      "gt_labels",
      "gt_masks",
      "img_metas"
    ],
    "loss_single": [
      "self",
      "cls_scores",
      "mask_preds",
      "gt_labels_list",
      "gt_masks_list",
      "img_metas"
    ],
    "loss": [
      "self",
      "all_cls_scores",
      "all_mask_preds",
      "gt_labels_list",
      "gt_masks_list",
      "img_metas"
    ],
    "forward_head": [
      "self",
      "decoder_out",
      "mask_feature",
      "attn_mask_target_size"
    ],
    "forward": [
      "self",
      "feats",
      "img_metas"
    ],
    "forward_train": [
      "self",
      "x",
      "img_metas",
      "gt_semantic_seg",
      "gt_labels",
      "gt_masks"
    ],
    "forward_test": [
      "self",
      "inputs",
      "img_metas",
      "test_cfg"
    ]
  },
  "EncoderDecoderMask2Former": {
    "__init__": [
      "self",
      "backbone",
      "decode_head",
      "neck",
      "auxiliary_head",
      "train_cfg",
      "test_cfg",
      "pretrained",
      "init_cfg"
    ],
    "_init_decode_head": [
      "self",
      "decode_head"
    ],
    "_init_auxiliary_head": [
      "self",
      "auxiliary_head"
    ],
    "extract_feat": [
      "self",
      "img"
    ],
    "encode_decode": [
      "self",
      "img",
      "img_metas"
    ],
    "_decode_head_forward_train": [
      "self",
      "x",
      "img_metas",
      "gt_semantic_seg"
    ],
    "_decode_head_forward_test": [
      "self",
      "x",
      "img_metas"
    ],
    "_auxiliary_head_forward_train": [
      "self",
      "x",
      "img_metas",
      "gt_semantic_seg"
    ],
    "forward_dummy": [
      "self",
      "img"
    ],
    "forward_train": [
      "self",
      "img",
      "img_metas",
      "gt_semantic_seg"
    ],
    "slide_inference": [
      "self",
      "img",
      "img_meta",
      "rescale"
    ],
    "whole_inference": [
      "self",
      "img",
      "img_meta",
      "rescale"
    ],
    "inference": [
      "self",
      "img",
      "img_meta",
      "rescale"
    ],
    "simple_test": [
      "self",
      "img",
      "img_meta",
      "rescale"
    ],
    "aug_test": [
      "self",
      "imgs",
      "img_metas",
      "rescale"
    ]
  },
  "BaseSegmentor": {
    "__init__": [
      "self",
      "init_cfg"
    ],
    "with_neck": [
      "self"
    ],
    "with_auxiliary_head": [
      "self"
    ],
    "with_decode_head": [
      "self"
    ],
    "extract_feat": [
      "self",
      "imgs"
    ],
    "encode_decode": [
      "self",
      "img",
      "img_metas"
    ],
    "forward_train": [
      "self",
      "imgs",
      "img_metas"
    ],
    "simple_test": [
      "self",
      "img",
      "img_meta"
    ],
    "aug_test": [
      "self",
      "imgs",
      "img_metas"
    ],
    "forward_test": [
      "self",
      "imgs",
      "img_metas"
    ],
    "forward": [
      "self",
      "img",
      "img_metas",
      "return_loss"
    ],
    "train_step": [
      "self",
      "data_batch",
      "optimizer"
    ],
    "val_step": [
      "self",
      "data_batch",
      "optimizer"
    ],
    "_parse_losses": [
      "losses"
    ],
    "show_result": [
      "self",
      "img",
      "result",
      "palette",
      "win_name",
      "show",
      "wait_time",
      "out_file",
      "opacity"
    ]
  },
  "DepthEstimation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "Inputs"
    ],
    "postprocess": [
      "self",
      "Inputs"
    ],
    "inference": [
      "self",
      "data"
    ]
  },
  "NewCRFDepth": {
    "__init__": [
      "self",
      "version",
      "inv_depth",
      "pretrained",
      "frozen_stages",
      "min_depth",
      "max_depth"
    ],
    "init_weights": [
      "self",
      "pretrained"
    ],
    "upsample_mask": [
      "self",
      "disp",
      "mask"
    ],
    "forward": [
      "self",
      "imgs"
    ]
  },
  "DispHead": {
    "__init__": [
      "self",
      "input_dim"
    ],
    "forward": [
      "self",
      "x",
      "scale"
    ]
  },
  "DispUnpack": {
    "__init__": [
      "self",
      "input_dim",
      "hidden_dim"
    ],
    "forward": [
      "self",
      "x",
      "output_size"
    ]
  },
  "CRFBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "v_dim",
      "window_size",
      "shift_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "drop_path",
      "act_layer",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x",
      "v",
      "mask_matrix"
    ]
  },
  "BasicCRFLayer": {
    "__init__": [
      "self",
      "dim",
      "depth",
      "num_heads",
      "v_dim",
      "window_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "drop_path",
      "norm_layer",
      "downsample",
      "use_checkpoint"
    ],
    "forward": [
      "self",
      "x",
      "v",
      "H",
      "W"
    ]
  },
  "NewCRF": {
    "__init__": [
      "self",
      "input_dim",
      "embed_dim",
      "v_dim",
      "window_size",
      "num_heads",
      "depth",
      "patch_size",
      "in_chans",
      "norm_layer",
      "patch_norm"
    ],
    "forward": [
      "self",
      "x",
      "v"
    ]
  },
  "PPM": {
    "__init__": [
      "self",
      "pool_scales",
      "in_channels",
      "channels",
      "conv_cfg",
      "norm_cfg",
      "act_cfg",
      "align_corners"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UPerHead": {
    "__init__": [
      "self",
      "pool_scales"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "PSP": {
    "__init__": [
      "self",
      "pool_scales"
    ],
    "psp_forward": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "StablediffusionPaintbyexample": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "load_model_wo_clip": [
    "model",
    "state_dict"
  ],
  "action2motion_joints": [],
  "JOINTSTYPE_ROOT": [],
  "JOINT_MAP": [],
  "JOINT_NAMES": [],
  "SMPL": {
    "__init__": [
      "self",
      "smpl_data_path"
    ],
    "forward": [
      "self"
    ]
  },
  "get_named_beta_schedule": [
    "schedule_name",
    "num_diffusion_timesteps",
    "scale_betas"
  ],
  "ModelMeanType": {
    "PREVIOUS_X": [],
    "START_X": [],
    "EPSILON": []
  },
  "ModelVarType": {
    "LEARNED": [],
    "FIXED_SMALL": [],
    "FIXED_LARGE": [],
    "LEARNED_RANGE": []
  },
  "LossType": {
    "MSE": [],
    "RESCALED_MSE": [],
    "KL": [],
    "RESCALED_KL": [],
    "is_vb": [
      "self"
    ]
  },
  "_extract_into_tensor": [
    "arr",
    "timesteps",
    "broadcast_shape"
  ],
  "JOINTSTYPES": [],
  "Rotation2xyz": {
    "__init__": [
      "self",
      "device",
      "smpl_data_path",
      "dataset"
    ],
    "__call__": [
      "self",
      "x",
      "mask",
      "pose_rep",
      "translation",
      "glob",
      "jointstype",
      "vertstrans",
      "betas",
      "beta",
      "glob_rot",
      "get_rotations_back"
    ]
  },
  "MDM": {
    "__init__": [
      "self",
      "modeltype",
      "njoints",
      "nfeats",
      "num_actions",
      "translation",
      "pose_rep",
      "glob",
      "glob_rot",
      "latent_dim",
      "ff_size",
      "num_layers",
      "num_heads",
      "dropout",
      "smpl_data_path",
      "ablation",
      "activation",
      "legacy",
      "data_rep",
      "dataset",
      "clip_dim",
      "arch",
      "emb_trans_dec",
      "clip_version"
    ],
    "parameters_wo_clip": [
      "self"
    ],
    "load_and_freeze_clip": [
      "self",
      "clip_version"
    ],
    "mask_cond": [
      "self",
      "cond",
      "force_mask"
    ],
    "encode_text": [
      "self",
      "raw_text"
    ],
    "forward": [
      "self",
      "x",
      "timesteps",
      "y"
    ],
    "_apply": [
      "self",
      "fn"
    ],
    "train": [
      "self"
    ]
  },
  "TimestepEmbedder": {
    "__init__": [
      "self",
      "latent_dim",
      "sequence_pos_encoder"
    ],
    "forward": [
      "self",
      "timesteps"
    ]
  },
  "InputProcess": {
    "__init__": [
      "self",
      "data_rep",
      "input_feats",
      "latent_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OutputProcess": {
    "__init__": [
      "self",
      "data_rep",
      "input_feats",
      "latent_dim",
      "njoints",
      "nfeats"
    ],
    "forward": [
      "self",
      "output"
    ]
  },
  "EmbedAction": {
    "__init__": [
      "self",
      "num_actions",
      "latent_dim"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ClassifierFreeSampleModel": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "x",
      "timesteps",
      "y"
    ]
  },
  "space_timesteps": [
    "num_timesteps",
    "section_counts"
  ],
  "SpacedDiffusion": {
    "__init__": [
      "self",
      "use_timesteps"
    ],
    "p_mean_variance": [
      "self",
      "model"
    ],
    "training_losses": [
      "self",
      "model"
    ],
    "condition_mean": [
      "self",
      "cond_fn"
    ],
    "condition_score": [
      "self",
      "cond_fn"
    ],
    "_wrap_model": [
      "self",
      "model"
    ],
    "_scale_timesteps": [
      "self",
      "t"
    ]
  },
  "_WrappedModel": {
    "__init__": [
      "self",
      "model",
      "timestep_map",
      "rescale_timesteps",
      "original_num_steps"
    ],
    "__call__": [
      "self",
      "x",
      "ts"
    ]
  },
  "OCRDetection": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "OCRDetectionPreprocessor": {
    "__init__": [
      "self",
      "model_dir",
      "mode"
    ],
    "__call__": [
      "self",
      "inputs"
    ]
  },
  "CompactDetBackbone": {
    "__init__": [
      "self",
      "width_stages",
      "input_channel",
      "bn_param"
    ]
  },
  "MHSA": {
    "__init__": [
      "self",
      "n_dims",
      "width",
      "height",
      "heads"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_flops": [
      "self",
      "x"
    ]
  },
  "MBInvertedMHSALayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "expand_ratio",
      "width",
      "height",
      "mid_channels"
    ],
    "forward": [
      "self",
      "x"
    ],
    "module_str": [
      "self"
    ],
    "config": [
      "self"
    ],
    "build_from_config": [
      "config"
    ],
    "is_zero_layer": [],
    "get_flops": [
      "self",
      "x"
    ]
  },
  "build_candidate_ops": [
    "candidate_ops",
    "in_channels",
    "out_channels",
    "stride",
    "ops_order",
    "spatio_size"
  ],
  "MixedEdge": {
    "MODE": [],
    "__init__": [
      "self",
      "candidate_ops"
    ],
    "n_choices": [
      "self"
    ],
    "probs_over_ops": [
      "self"
    ],
    "chosen_index": [
      "self"
    ],
    "chosen_op": [
      "self"
    ],
    "random_op": [
      "self"
    ],
    "entropy": [
      "self",
      "eps"
    ],
    "is_zero_layer": [
      "self"
    ],
    "active_op": [
      "self"
    ],
    "set_chosen_op_active": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "module_str": [
      "self"
    ],
    "config": [
      "self"
    ],
    "build_from_config": [
      "config"
    ],
    "get_flops": [
      "self",
      "x"
    ],
    "binarize": [
      "self"
    ],
    "set_arch_param_grad": [
      "self"
    ],
    "rescale_updated_arch_param": [
      "self"
    ]
  },
  "ArchGradientFunction": {
    "forward": [
      "ctx",
      "x",
      "binary_gates",
      "run_func",
      "backward_func"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "DwPwConv": {
    "__init__": [
      "self",
      "in_planes",
      "out_planes",
      "kernel_size",
      "stride",
      "padding",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DwPwConvTranspose": {
    "__init__": [
      "self",
      "in_planes",
      "out_planes",
      "kernel_size",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LightSegDetector": {
    "__init__": [
      "self",
      "in_channels",
      "inner_channels",
      "k",
      "bias",
      "adaptive",
      "smooth",
      "serial",
      "dw_kernel_size",
      "dw_padding"
    ],
    "_init_thresh": [
      "self",
      "inner_channels",
      "serial",
      "smooth",
      "bias"
    ],
    "_init_upsample": [
      "self",
      "in_channels",
      "out_channels",
      "smooth",
      "bias"
    ],
    "forward": [
      "self",
      "features",
      "gt",
      "masks",
      "training"
    ],
    "step_function": [
      "self",
      "x",
      "y"
    ]
  },
  "BasicModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "data"
    ]
  },
  "parallelize": [
    "model",
    "distributed",
    "local_rank"
  ],
  "DBNasModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DBModel_v2": {
    "__init__": [
      "self",
      "device",
      "distributed",
      "local_rank"
    ],
    "forward": [
      "self",
      "batch",
      "training"
    ]
  },
  "SegDetectorLossBuilder": {
    "__init__": [
      "self",
      "loss_class"
    ],
    "build": [
      "self"
    ]
  },
  "_neg_loss": [
    "pred",
    "gt"
  ],
  "FocalLoss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "out",
      "target"
    ]
  },
  "DiceLoss": {
    "__init__": [
      "self",
      "eps"
    ],
    "forward": [
      "self",
      "pred",
      "gt",
      "mask",
      "weights"
    ],
    "_compute": [
      "self",
      "pred",
      "gt",
      "mask",
      "weights"
    ]
  },
  "MaskL1Loss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "pred",
      "gt",
      "mask"
    ]
  },
  "MaskL2Loss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "pred",
      "gt",
      "mask"
    ]
  },
  "BalanceCrossEntropyLoss": {
    "__init__": [
      "self",
      "negative_ratio",
      "eps"
    ],
    "forward": [
      "self",
      "pred",
      "gt",
      "mask",
      "return_origin"
    ]
  },
  "L1BalanceCELoss": {
    "__init__": [
      "self",
      "eps",
      "l1_scale",
      "bce_scale",
      "hm_scale"
    ],
    "forward": [
      "self",
      "pred",
      "batch"
    ]
  },
  "GeoMVSNetDepthEstimation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "preprocess_make_pair": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "frequency_domain_filter": [
    "depth",
    "rho_ratio"
  ],
  "visual_fft_fig": [
    "fshift"
  ],
  "geomvsnet_loss": [
    "inputs",
    "depth_gt_ms",
    "mask_ms"
  ],
  "pixel_wise_loss": [
    "prob_volume",
    "depth_gt",
    "mask",
    "depth_value"
  ],
  "depth_distribution_similarity_loss": [
    "depth",
    "depth_gt",
    "mask",
    "depth_min",
    "depth_max"
  ],
  "cal_metrics": [
    "depth_pred",
    "depth_gt",
    "mask",
    "depth_min",
    "depth_max"
  ],
  "GeoMVSNet": {
    "__init__": [
      "self",
      "levels",
      "hypo_plane_num_stages",
      "depth_interal_ratio_stages",
      "feat_base_channel",
      "reg_base_channel",
      "group_cor_dim_stages"
    ],
    "forward": [
      "self",
      "imgs",
      "proj_matrices",
      "intrinsics_matrices",
      "depth_values",
      "filename"
    ]
  },
  "StageNet": {
    "__init__": [
      "self",
      "attn_temp"
    ],
    "forward": [
      "self",
      "stage_idx",
      "features",
      "proj_matrices",
      "depth_hypo",
      "regnet",
      "group_cor_dim",
      "depth_interal_ratio",
      "geo_reg_data"
    ]
  },
  "Reg2d": {
    "__init__": [
      "self",
      "input_channel",
      "base_channel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "init_inverse_range": [
    "cur_depth",
    "ndepths",
    "device",
    "dtype",
    "H",
    "W"
  ],
  "schedule_inverse_range": [
    "inverse_min_depth",
    "inverse_max_depth",
    "ndepths",
    "H",
    "W"
  ],
  "ConvBnReLU3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "pad"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GeoFeatureFusion": {
    "__init__": [
      "self",
      "convolutional_layer_encoding",
      "mask_type",
      "add_origin_feat_flag"
    ],
    "forward": [
      "self",
      "rgb",
      "depth",
      "confidence",
      "depth_values",
      "stage_idx",
      "origin_feat",
      "intrinsics_matrices_stage"
    ]
  },
  "GeoRegNet2d": {
    "__init__": [
      "self",
      "input_channel",
      "base_channel",
      "convolutional_layer_encoding"
    ],
    "forward": [
      "self",
      "x",
      "stage_idx",
      "geo_reg_data"
    ]
  },
  "BasicBlockGeo": {
    "expansion": [],
    "__constants__": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "groups",
      "base_width",
      "dilation",
      "norm_layer",
      "geoplanes"
    ],
    "forward": [
      "self",
      "x",
      "g1",
      "g2"
    ]
  },
  "GeometryFeature": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "z",
      "vnorm",
      "unorm",
      "h",
      "w",
      "ch",
      "cw",
      "fh",
      "fw"
    ]
  },
  "SparseDownSampleClose": {
    "__init__": [
      "self",
      "stride"
    ],
    "forward": [
      "self",
      "d",
      "mask"
    ]
  },
  "convbnrelu": [
    "in_channels",
    "out_channels",
    "kernel_size",
    "stride",
    "padding"
  ],
  "deconvbnrelu": [
    "in_channels",
    "out_channels",
    "kernel_size",
    "stride",
    "padding",
    "output_padding"
  ],
  "AddCoordsNp": {
    "__init__": [
      "self",
      "x_dim",
      "y_dim",
      "with_r"
    ],
    "call": [
      "self"
    ]
  },
  "Reg_BasicBlockGeo": {
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "kernel_size",
      "stride",
      "padding",
      "downsample",
      "groups",
      "base_width",
      "dilation",
      "norm_layer",
      "geoplanes"
    ],
    "forward": [
      "self",
      "x",
      "g1",
      "g2"
    ]
  },
  "regconv3D": [
    "in_planes",
    "out_planes",
    "kernel_size",
    "stride",
    "padding",
    "groups",
    "dilation",
    "bias"
  ],
  "regconv1x1": [
    "in_planes",
    "out_planes",
    "kernel_size",
    "stride",
    "padding",
    "groups",
    "bias"
  ],
  "reg_deconvbnrelu": [
    "in_channels",
    "out_channels",
    "kernel_size",
    "stride",
    "padding",
    "output_padding"
  ],
  "make_nograd_func": [
    "func"
  ],
  "tensor2float": [
    "vars"
  ],
  "tb_save_scalars": [
    "logger",
    "mode",
    "scalar_dict",
    "global_step"
  ],
  "tb_save_images": [
    "logger",
    "mode",
    "images_dict",
    "global_step"
  ],
  "DictAverageMeter": {
    "__init__": [
      "self"
    ],
    "update": [
      "self",
      "new_input"
    ],
    "mean": [
      "self"
    ]
  },
  "compute_metrics_for_each_image": [
    "metric_func"
  ],
  "Thres_metrics": [
    "depth_est",
    "depth_gt",
    "mask",
    "thres"
  ],
  "AbsDepthError_metrics": [
    "depth_est",
    "depth_gt",
    "mask",
    "thres"
  ],
  "reduce_scalar_outputs": [
    "scalar_outputs"
  ],
  "WarmupMultiStepLR": {
    "__init__": [
      "self",
      "optimizer",
      "milestones",
      "gamma",
      "warmup_factor",
      "warmup_iters",
      "warmup_method",
      "last_epoch"
    ],
    "get_lr": [
      "self"
    ]
  },
  "get_opts": [],
  "tv_version": [],
  "get_random_params": [
    "size",
    "scale_param",
    "use_flip"
  ],
  "__crop": [
    "img",
    "pos"
  ],
  "__flip": [
    "img"
  ],
  "FreqHPTForHumanImageGeneration": {
    "__init__": [
      "self",
      "model_dir",
      "device_id"
    ],
    "forward": [
      "self",
      "x",
      "y",
      "z"
    ]
  },
  "trans_keypoints": [
    "keypoints",
    "param",
    "img_size",
    "offset"
  ],
  "get_label_tensor": [
    "path",
    "img",
    "param"
  ],
  "get_image_tensor": [
    "path"
  ],
  "ExtractionOperation_flow": {
    "__init__": [
      "self",
      "in_channel",
      "num_label",
      "match_kernel"
    ],
    "forward": [
      "self",
      "value",
      "recoder"
    ],
    "feature_norm": [
      "self",
      "input_tensor"
    ]
  },
  "DistributionOperation_flow": {
    "__init__": [
      "self",
      "num_label",
      "input_dim",
      "match_kernel"
    ],
    "forward": [
      "self",
      "query",
      "extracted_feature",
      "recoder"
    ]
  },
  "EncoderLayer_flow": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel",
      "kernel_size",
      "downsample",
      "blur_kernel",
      "bias",
      "activate",
      "use_extraction",
      "num_label",
      "match_kernel",
      "num_extractions"
    ],
    "forward": [
      "self",
      "input",
      "recoder"
    ]
  },
  "DecoderLayer_flow_wavelet_fuse24": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel",
      "kernel_size",
      "upsample",
      "blur_kernel",
      "bias",
      "activate",
      "use_distribution",
      "num_label",
      "match_kernel",
      "wavelet_down_level",
      "window_size"
    ],
    "forward": [
      "self",
      "input",
      "neural_texture",
      "recoder",
      "warped_texture",
      "style_net",
      "gstyle"
    ]
  },
  "EqualTransposeConv2d": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel",
      "kernel_size",
      "stride",
      "padding",
      "bias"
    ],
    "forward": [
      "self",
      "input"
    ],
    "__repr__": [
      "self"
    ]
  },
  "GatedConv2dWithActivation": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "activation"
    ],
    "gated": [
      "self",
      "mask"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "SPDNorm": {
    "__init__": [
      "self",
      "norm_channel",
      "label_nc",
      "norm_type",
      "use_equal"
    ],
    "forward": [
      "self",
      "x",
      "prior_f",
      "weight"
    ]
  },
  "TPS": {
    "__init__": [
      "self",
      "mode"
    ],
    "trans": [
      "self",
      "kp_1"
    ],
    "transform_frame": [
      "self",
      "frame"
    ],
    "warp_coordinates": [
      "self",
      "coordinates"
    ],
    "preprocess_kp": [
      "self",
      "kp_1"
    ],
    "forward": [
      "self",
      "source_image",
      "kp_driving"
    ]
  },
  "MaskStyle": {
    "__init__": [
      "self",
      "channels",
      "log_size",
      "style_in",
      "channels_multiplier"
    ]
  },
  "StyleFlow": {
    "__init__": [
      "self",
      "channels",
      "log_size",
      "style_in"
    ]
  },
  "get_wav": [
    "in_channels",
    "pool"
  ],
  "WavePool": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_wav_two": [
    "in_channels",
    "out_channels",
    "pool"
  ],
  "WavePool2": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WaveUnpool": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "option_unpool"
    ],
    "forward": [
      "self",
      "LL",
      "LH",
      "HL",
      "HH",
      "original"
    ]
  },
  "Encoder_wiflow": {
    "__init__": [
      "self",
      "size",
      "input_dim",
      "channels",
      "num_labels",
      "match_kernels",
      "blur_kernel"
    ],
    "forward": [
      "self",
      "input",
      "recoder",
      "out_list"
    ]
  },
  "Decoder_wiflow_wavelet_fuse25": {
    "__init__": [
      "self",
      "size",
      "channels",
      "num_labels",
      "match_kernels",
      "blur_kernel",
      "wavelet_down_levels",
      "window_size"
    ],
    "forward": [
      "self",
      "input",
      "neural_textures",
      "skeleton_features",
      "source_features",
      "kp_skeleton",
      "recoder",
      "add_nted"
    ]
  },
  "SepConv": {
    "__init__": [
      "self",
      "in_channels",
      "filters",
      "out_channels",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "SelfAttLayer": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "lorder",
      "hidden_size"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TFFsmn": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "lorder",
      "hidden_size",
      "dilation",
      "layer_norm",
      "dropout",
      "skip_connect"
    ],
    "forward": [
      "self",
      "input"
    ],
    "compute1": [
      "self",
      "input"
    ]
  },
  "CNNFsmn": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "lorder",
      "hidden_size",
      "dilation",
      "layer_norm",
      "dropout",
      "skip_connect"
    ],
    "forward": [
      "self",
      "input"
    ],
    "compute1": [
      "self",
      "input"
    ],
    "compute2": [
      "self",
      "input"
    ]
  },
  "UniDeepFsmn": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "lorder",
      "hidden_size",
      "dilation",
      "layer_norm",
      "dropout",
      "skip_connect"
    ],
    "forward": [
      "self",
      "input"
    ],
    "compute1": [
      "self",
      "input"
    ],
    "compute2": [
      "self",
      "input"
    ],
    "compute3": [
      "self",
      "input"
    ],
    "to_kaldi_nnet": [
      "self"
    ],
    "to_raw_nnet": [
      "self",
      "fid"
    ],
    "load_kaldi_nnet": [
      "self",
      "instr"
    ]
  },
  "DeepFsmn": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "lorder",
      "rorder",
      "hidden_size",
      "layer_norm",
      "dropout"
    ],
    "forward": [
      "self",
      "input"
    ],
    "to_kaldi_nnet": [
      "self"
    ],
    "load_kaldi_nnet": [
      "self",
      "instr"
    ]
  },
  "RectifiedLinear": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim"
    ],
    "forward": [
      "self",
      "input"
    ],
    "to_kaldi_nnet": [
      "self"
    ],
    "load_kaldi_nnet": [
      "self",
      "instr"
    ]
  },
  "LogSoftmax": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim"
    ],
    "forward": [
      "self",
      "input"
    ],
    "to_kaldi_nnet": [
      "self"
    ],
    "load_kaldi_nnet": [
      "self",
      "instr"
    ]
  },
  "Sigmoid": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim"
    ],
    "forward": [
      "self",
      "input"
    ],
    "to_kaldi_nnet": [
      "self"
    ],
    "load_kaldi_nnet": [
      "self",
      "instr"
    ]
  },
  "to_kaldi_matrix": [
    "np_mat"
  ],
  "LayerBase": {
    "__init__": [
      "self"
    ],
    "to_kaldi_nnet": [
      "self"
    ]
  },
  "AffineTransform": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim"
    ],
    "forward": [
      "self",
      "input"
    ],
    "to_kaldi_nnet": [
      "self"
    ],
    "to_raw_nnet": [
      "self",
      "fid"
    ],
    "load_kaldi_nnet": [
      "self",
      "instr"
    ]
  },
  "EPS": [],
  "energy_vad": [
    "spec",
    "thdhigh",
    "thdlow",
    "int16"
  ],
  "modulation_loss_init": [
    "n_fft"
  ],
  "mask_loss_function": [
    "loss_func",
    "loss_type",
    "mask_type",
    "use_mod_loss",
    "use_wav2vec_loss",
    "n_fft",
    "hop_length",
    "EPS",
    "weight"
  ],
  "MaskNet": {
    "__init__": [
      "self",
      "indim",
      "outdim",
      "layers",
      "hidden_dim",
      "hidden_dim2",
      "lorder",
      "rorder",
      "dilation",
      "layer_norm",
      "dropout",
      "crm",
      "vad",
      "linearout"
    ],
    "forward": [
      "self",
      "feat",
      "ctl"
    ],
    "to_kaldi_nnet": [
      "self"
    ],
    "to_raw_nnet": [
      "self",
      "fid"
    ]
  },
  "BranchNet": {
    "__init__": [
      "self",
      "indim",
      "outdim",
      "layers",
      "hidden_dim",
      "lorder",
      "rorder",
      "dilation",
      "layer_norm",
      "dropout",
      "crm",
      "vad",
      "linearout"
    ],
    "forward": [
      "self",
      "x",
      "ctl"
    ],
    "forward_sepconv": [
      "self",
      "x"
    ],
    "forward_branch": [
      "self",
      "x"
    ]
  },
  "TACNet": {
    "__init__": [
      "self",
      "indim",
      "outdim",
      "layers",
      "hidden_dim",
      "lorder",
      "rorder",
      "crm",
      "vad",
      "linearout"
    ],
    "forward": [
      "self",
      "feat",
      "ctl"
    ],
    "to_kaldi_nnet": [
      "self"
    ]
  },
  "ModulationDomainLossModule": {
    "__init__": [
      "self",
      "modulation_kernels",
      "norm"
    ],
    "forward": [
      "self",
      "enhanced_spect",
      "clean_spect",
      "weight"
    ]
  },
  "ModulationDomainNCCLossModule": {
    "__init__": [
      "self",
      "modulation_kernels"
    ],
    "forward": [
      "self",
      "enhanced_spect",
      "clean_spect"
    ]
  },
  "GaborSTRFConv": {
    "__init__": [
      "self",
      "supn",
      "supk",
      "nkern",
      "rates",
      "scales",
      "norm_strf",
      "real_only"
    ],
    "strfs": [
      "self"
    ],
    "forward": [
      "self",
      "sigspec"
    ],
    "__repr__": [
      "self"
    ]
  },
  "HifiSSR": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "LRELU_SLOPE": [],
  "get_sinusoid_encoding_table": [
    "n_position",
    "d_hid",
    "padding_idx"
  ],
  "overlap_and_add": [
    "signal",
    "frame_step"
  ],
  "LastLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "nonlinear_activation",
      "nonlinear_activation_params",
      "pad",
      "kernel_size",
      "pad_params",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv1d1x1": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bias"
    ]
  },
  "LastLinear": {
    "__init__": [
      "self",
      "hidden_channel",
      "out_channel",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Stretch2d": {
    "__init__": [
      "self",
      "x_scale",
      "y_scale",
      "mode"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UpsampleLayer": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel",
      "upsample_rate",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_padding": [
    "kernel_size",
    "dilation"
  ],
  "ResBlock1": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "dilation",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResBlock2": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "dilation",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BasisSignalLayer": {
    "__init__": [
      "self",
      "basis_signal_weight",
      "L"
    ],
    "forward": [
      "self",
      "weight"
    ]
  },
  "CausalConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dilation",
      "bias",
      "pad",
      "pad_params"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CausalConvTranspose1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResidualStack": {
    "__init__": [
      "self",
      "kernel_size",
      "channels",
      "dilation",
      "bias",
      "nonlinear_activation",
      "nonlinear_activation_params",
      "pad",
      "pad_params",
      "use_causal_conv"
    ],
    "forward": [
      "self",
      "c"
    ]
  },
  "HiFiGANGenerator": {
    "__init__": [
      "self",
      "input_channels",
      "resblock_kernel_sizes",
      "upsample_rates",
      "upsample_initial_channel",
      "resblock_type",
      "upsample_kernel_sizes",
      "resblock_dilation_sizes",
      "transposedconv",
      "weight_norm",
      "bias"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "apply_weight_norm": [
      "self"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "inference": [
      "self",
      "x"
    ]
  },
  "ResBlk": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "actv",
      "normalize",
      "style_dim",
      "downsample"
    ],
    "_shortcut": [
      "self",
      "x"
    ],
    "_residual": [
      "self",
      "x",
      "s"
    ],
    "forward": [
      "self",
      "x",
      "s"
    ]
  },
  "ResBlk1D": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "actv",
      "normalize",
      "out_for_onnx",
      "downsample"
    ],
    "_shortcut": [
      "self",
      "x"
    ],
    "_residual": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AdaIN": {
    "__init__": [
      "self",
      "style_dim",
      "num_features"
    ],
    "forward": [
      "self",
      "x",
      "s"
    ]
  },
  "AdainResBlk": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "style_dim",
      "w_hpf",
      "actv",
      "upsample"
    ],
    "_shortcut": [
      "self",
      "x"
    ],
    "_residual": [
      "self",
      "x",
      "s"
    ],
    "forward": [
      "self",
      "x",
      "s"
    ]
  },
  "HighPass": {
    "__init__": [
      "self",
      "w_hpf"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UnetMapping": {
    "__init__": [
      "self",
      "dim_in",
      "style_dim",
      "max_conv_dim",
      "repeat_num"
    ],
    "forward": [
      "self",
      "x",
      "c"
    ]
  },
  "MaskMapping": {
    "__init__": [
      "self",
      "dim_in",
      "style_dim",
      "max_conv_dim",
      "repeat_num"
    ],
    "forward": [
      "self",
      "x",
      "c"
    ]
  },
  "StyleEncoder": {
    "__init__": [
      "self",
      "dim_in",
      "style_dim",
      "num_domains",
      "max_conv_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResidualCouplingLayer": {
    "__init__": [
      "self",
      "channels",
      "hidden_channels",
      "kernel_size",
      "dilation_rate",
      "n_layers",
      "p_dropout",
      "gin_channels",
      "mean_only"
    ],
    "forward": [
      "self",
      "x",
      "reverse"
    ]
  },
  "fused_add_tanh_sigmoid_multiply": [
    "input_a",
    "n_channels"
  ],
  "WN": {
    "__init__": [
      "self",
      "hidden_channels",
      "kernel_size",
      "dilation_rate",
      "n_layers",
      "gin_channels",
      "p_dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LinearNorm": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "bias",
      "w_init_gain"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Discriminator2d": {
    "__init__": [
      "self",
      "dim_in",
      "num_domains",
      "max_conv_dim",
      "repeat_num"
    ],
    "get_feature": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FlowBlocks": {
    "__init__": [
      "self",
      "channels",
      "hidden_channels",
      "kernel_size",
      "dilation_rate",
      "n_layers",
      "n_flows",
      "gin_channels"
    ],
    "forward": [
      "self",
      "x",
      "reverse"
    ]
  },
  "Flip": {
    "forward": [
      "self",
      "x"
    ]
  },
  "LauraCodecGenModel": {
    "__init__": [
      "self",
      "model_dir",
      "model_name",
      "model_config"
    ],
    "forward": [
      "self"
    ]
  },
  "denorm_f0": [
    "mel",
    "f0_threshold",
    "uv_threshold",
    "norm_type",
    "f0_feature"
  ],
  "binarize": [
    "mel",
    "threshold"
  ],
  "Voice": {
    "__init__": [
      "self",
      "voice_name",
      "voice_path",
      "custom_ckpt",
      "ignore_mask",
      "is_train"
    ],
    "scan_ckpt": [
      "self",
      "ckpt_path"
    ],
    "load_am": [
      "self"
    ],
    "load_vocoder": [
      "self"
    ],
    "am_forward": [
      "self",
      "symbol_seq"
    ],
    "vocoder_forward": [
      "self",
      "melspec"
    ],
    "train_sambert": [
      "self",
      "work_dir",
      "stage_dir",
      "data_dir",
      "config_path",
      "ignore_pretrain",
      "hparams"
    ],
    "train_hifigan": [
      "self",
      "work_dir",
      "stage_dir",
      "data_dir",
      "config_path",
      "ignore_pretrain",
      "hparams"
    ],
    "forward": [
      "self",
      "symbol_seq"
    ]
  },
  "SambertHifigan": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "build_voice_from_custom": [
      "self",
      "model_dir",
      "custom_ckpt"
    ],
    "load_voice": [
      "self",
      "model_dir",
      "custom_ckpt"
    ],
    "save_voices": [
      "self"
    ],
    "get_voices": [
      "self"
    ],
    "create_empty_voice": [
      "self",
      "voice_name",
      "audio_config",
      "am_config_path",
      "voc_config_path"
    ],
    "get_voice_audio_config_path": [
      "self",
      "voice"
    ],
    "get_voice_se_model_path": [
      "self",
      "voice"
    ],
    "get_voice_lang_path": [
      "self",
      "voice"
    ],
    "synthesis_one_sentences": [
      "self",
      "voice_name",
      "text"
    ],
    "train": [
      "self",
      "voice",
      "dirs",
      "train_type",
      "configs_path_dict",
      "ignore_pretrain",
      "create_if_not_exists",
      "hparam"
    ],
    "forward": [
      "self",
      "text",
      "voice_name"
    ]
  },
  "SpeakerVerificationResNet": {
    "__init__": [
      "self",
      "model_dir",
      "model_config"
    ],
    "forward": [
      "self",
      "audio"
    ],
    "__extract_feature": [
      "self",
      "audio"
    ],
    "__load_check_point": [
      "self",
      "pretrained_model_name",
      "device"
    ]
  },
  "Conv1d_O": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "input_shape",
      "in_channels",
      "stride",
      "dilation",
      "padding",
      "groups",
      "bias",
      "padding_mode",
      "skip_transpose"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_manage_padding": [
      "self",
      "x",
      "kernel_size",
      "dilation",
      "stride"
    ],
    "_check_input_shape": [
      "self",
      "shape"
    ]
  },
  "Conv1d": {
    "__init__": [
      "self"
    ]
  },
  "get_padding_elem": [
    "L_in",
    "stride",
    "kernel_size",
    "dilation"
  ],
  "BatchNorm1d_O": {
    "__init__": [
      "self",
      "input_shape",
      "input_size",
      "eps",
      "momentum",
      "affine",
      "track_running_stats",
      "combine_batch_time",
      "skip_transpose"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BatchNorm1d": {
    "__init__": [
      "self"
    ]
  },
  "Xvector": {
    "__init__": [
      "self",
      "device",
      "activation",
      "tdnn_blocks",
      "tdnn_channels",
      "tdnn_kernel_sizes",
      "tdnn_dilations",
      "lin_neurons",
      "in_channels"
    ],
    "forward": [
      "self",
      "x",
      "lens"
    ]
  },
  "SpectralCluster": {
    "__init__": [
      "self",
      "min_num_spks",
      "max_num_spks",
      "pval"
    ],
    "__call__": [
      "self",
      "X",
      "oracle_num"
    ],
    "get_sim_mat": [
      "self",
      "X"
    ],
    "p_pruning": [
      "self",
      "A"
    ],
    "get_laplacian": [
      "self",
      "M"
    ],
    "get_spec_embs": [
      "self",
      "L",
      "k_oracle"
    ],
    "cluster_embs": [
      "self",
      "emb",
      "k"
    ],
    "getEigenGaps": [
      "self",
      "eig_vals"
    ]
  },
  "UmapHdbscan": {
    "__init__": [
      "self",
      "n_neighbors",
      "n_components",
      "min_samples",
      "min_cluster_size",
      "metric"
    ],
    "__call__": [
      "self",
      "X"
    ]
  },
  "ClusterBackend": {
    "__init__": [
      "self",
      "model_dir",
      "model_config"
    ],
    "forward": [
      "self",
      "X"
    ],
    "merge_by_cos": [
      "self",
      "labels",
      "embs",
      "cos_thr"
    ]
  },
  "LanguageRecognitionERes2Net": {
    "__init__": [
      "self",
      "model_dir",
      "model_config"
    ],
    "forward": [
      "self",
      "audio"
    ],
    "_extract_feature": [
      "self",
      "audio"
    ],
    "_load_check_point": [
      "self",
      "pretrained_encoder",
      "pretrained_backend"
    ]
  },
  "length_to_mask": [
    "length",
    "max_len",
    "dtype",
    "device"
  ],
  "TDNNBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dilation",
      "activation",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Res2NetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "scale",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SEBlock": {
    "__init__": [
      "self",
      "in_channels",
      "se_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "AttentiveStatisticsPooling": {
    "__init__": [
      "self",
      "channels",
      "attention_channels",
      "global_context"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "SERes2NetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "res2net_scale",
      "se_channels",
      "kernel_size",
      "dilation",
      "activation",
      "groups"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "ECAPA_TDNN": {
    "__init__": [
      "self",
      "input_size",
      "device",
      "lin_neurons",
      "activation",
      "channels",
      "kernel_sizes",
      "dilations",
      "attention_channels",
      "res2net_scale",
      "se_channels",
      "global_context",
      "groups"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "SDPNHead": {
    "__init__": [
      "self",
      "in_dim",
      "use_bn",
      "nlayers",
      "hidden_dim",
      "bottleneck_dim"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Combiner": {
    "__init__": [
      "self",
      "backbone",
      "head"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SpeakerVerificationSDPN": {
    "__init__": [
      "self",
      "model_dir",
      "model_config"
    ],
    "forward": [
      "self",
      "audio"
    ],
    "__extract_feature": [
      "self",
      "audio"
    ],
    "__load_check_point": [
      "self",
      "pretrained_model_name",
      "device"
    ]
  },
  "TdnnLayer": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "context_size",
      "dilation",
      "padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "XVEC": {
    "__init__": [
      "self",
      "feat_dim",
      "hid_dim",
      "stats_dim",
      "embed_dim",
      "pooling_func"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SpeakerVerificationTDNN": {
    "__init__": [
      "self",
      "model_dir",
      "model_config"
    ],
    "forward": [
      "self",
      "audio"
    ],
    "__extract_feature": [
      "self",
      "audio"
    ],
    "__load_check_point": [
      "self",
      "pretrained_model_name"
    ]
  },
  "RDINOHead": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "use_bn",
      "norm_last_layer",
      "nlayers",
      "hidden_dim",
      "bottleneck_dim",
      "add_dim"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Combine": {
    "__init__": [
      "self",
      "backbone",
      "head"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SpeakerVerification_RDINO": {
    "__init__": [
      "self",
      "model_dir",
      "model_config"
    ],
    "forward": [
      "self",
      "audio"
    ],
    "__extract_feature": [
      "self",
      "audio"
    ],
    "__load_check_point": [
      "self",
      "pretrained_model_name",
      "device"
    ]
  },
  "TAP": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TSDP": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TSTP": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ASTP": {
    "__init__": [
      "self",
      "in_dim",
      "bottleneck_dim",
      "global_context_att"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TextClassificationHead": {
    "__init__": [
      "self",
      "hidden_size",
      "classifier_dropout",
      "num_labels"
    ],
    "forward": [
      "self",
      "inputs",
      "attention_mask",
      "labels"
    ],
    "compute_loss": [
      "self",
      "logits",
      "labels"
    ]
  },
  "ModelForTextClassification": {
    "task": [],
    "head_type": [],
    "__init__": [
      "self",
      "model_dir"
    ],
    "parse_head_cfg": [
      "self"
    ]
  },
  "BertForSequenceClassification": {
    "base_model_type": []
  },
  "ReLU": {
    "__init__": [
      "self",
      "inplace"
    ],
    "__repr__": [
      "self"
    ]
  },
  "BasicBlockERes2Net": {
    "expansion": [],
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride",
      "baseWidth",
      "scale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BasicBlockERes2Net_diff_AFF": {
    "expansion": [],
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride",
      "baseWidth",
      "scale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ERes2Net_aug": {
    "__init__": [
      "self",
      "block",
      "block_fuse",
      "num_blocks",
      "m_channels",
      "feat_dim",
      "embedding_size",
      "pooling_func",
      "two_emb_layer"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "num_blocks",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SpeakerVerificationERes2Net": {
    "__init__": [
      "self",
      "model_dir",
      "model_config"
    ],
    "forward": [
      "self",
      "audio"
    ],
    "__extract_feature": [
      "self",
      "audio"
    ],
    "__load_check_point": [
      "self",
      "pretrained_model_name",
      "device"
    ]
  },
  "MultiHeadSelfAttention": {
    "__init__": [
      "self",
      "n_units",
      "h",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "batch_size"
    ]
  },
  "PosEncoding": {
    "__init__": [
      "self",
      "max_seq_len",
      "d_word_vec"
    ],
    "forward": [
      "self",
      "input_len"
    ]
  },
  "TransformerEncoder_out": {
    "__init__": [
      "self",
      "idim",
      "n_units",
      "n_layers",
      "e_units",
      "h",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OutLayer": {
    "__init__": [
      "self",
      "n_units",
      "num_anchors"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TransformerDetector": {
    "__init__": [
      "self",
      "frame_dim",
      "anchor_dim",
      "hidden_dim",
      "max_seq_len"
    ],
    "forward": [
      "self",
      "feats",
      "anchors"
    ]
  },
  "SpeakerChangeLocatorTransformer": {
    "__init__": [
      "self",
      "model_dir",
      "model_config"
    ],
    "forward": [
      "self",
      "audio",
      "anchors"
    ],
    "__extract_feature": [
      "self",
      "audio"
    ],
    "__load_check_point": [
      "self",
      "pretrained_encoder",
      "pretrained_backend"
    ]
  },
  "BasicBlockERes2NetV2": {
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride",
      "baseWidth",
      "scale",
      "expansion"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BasicBlockERes2NetV2AFF": {
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride",
      "baseWidth",
      "scale",
      "expansion"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ERes2NetV2": {
    "__init__": [
      "self",
      "block",
      "block_fuse",
      "num_blocks",
      "m_channels",
      "feat_dim",
      "embed_dim",
      "baseWidth",
      "scale",
      "expansion",
      "pooling_func",
      "two_emb_layer"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "num_blocks",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SpeakerVerificationERes2NetV2": {
    "__init__": [
      "self",
      "model_dir",
      "model_config"
    ],
    "forward": [
      "self",
      "audio"
    ],
    "__extract_feature": [
      "self",
      "audio"
    ],
    "__load_check_point": [
      "self",
      "pretrained_model_name",
      "device"
    ]
  },
  "SpeakerVerificationECAPATDNN": {
    "__init__": [
      "self",
      "model_dir",
      "model_config"
    ],
    "forward": [
      "self",
      "audio"
    ],
    "__extract_feature": [
      "self",
      "audio"
    ],
    "__load_check_point": [
      "self",
      "pretrained_model_name"
    ]
  },
  "BasicBlockRes2Net": {
    "expansion": [],
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride",
      "baseWidth",
      "scale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LanguageRecognitionCAMPPlus": {
    "__init__": [
      "self",
      "model_dir",
      "model_config"
    ],
    "forward": [
      "self",
      "audio"
    ],
    "_extract_feature": [
      "self",
      "audio"
    ],
    "_load_check_point": [
      "self",
      "pretrained_encoder",
      "pretrained_backend"
    ]
  },
  "get_nonlinear": [
    "config_str",
    "channels"
  ],
  "statistics_pooling": [
    "x",
    "dim",
    "keepdim",
    "unbiased",
    "eps"
  ],
  "StatsPool": {
    "forward": [
      "self",
      "x"
    ]
  },
  "TDNNLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "config_str"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CAMLayer": {
    "__init__": [
      "self",
      "bn_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "reduction"
    ],
    "forward": [
      "self",
      "x"
    ],
    "seg_pooling": [
      "self",
      "x",
      "seg_len",
      "stype"
    ]
  },
  "CAMDenseTDNNLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bn_channels",
      "kernel_size",
      "stride",
      "dilation",
      "bias",
      "config_str",
      "memory_efficient"
    ],
    "bn_function": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CAMDenseTDNNBlock": {
    "__init__": [
      "self",
      "num_layers",
      "in_channels",
      "out_channels",
      "bn_channels",
      "kernel_size",
      "stride",
      "dilation",
      "bias",
      "config_str",
      "memory_efficient"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TransitLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bias",
      "config_str"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DenseLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bias",
      "config_str"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BasicResBlock": {
    "expansion": [],
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TokenClassificationHead": {
    "__init__": [
      "self",
      "hidden_size",
      "classifier_dropout",
      "num_labels"
    ],
    "forward": [
      "self",
      "inputs",
      "attention_mask",
      "labels"
    ],
    "compute_loss": [
      "self",
      "logits",
      "attention_mask",
      "labels"
    ]
  },
  "ModelForTokenClassification": {
    "task": [],
    "head_type": [],
    "base_model_prefix": [],
    "override_base_model_prefix": [],
    "__init__": [
      "self",
      "model_dir"
    ],
    "parse_head_cfg": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "offset_mapping",
      "label_mask"
    ]
  },
  "BertForTokenClassification": {
    "base_model_type": []
  },
  "AFF": {
    "__init__": [
      "self",
      "channels",
      "r"
    ],
    "forward": [
      "self",
      "x",
      "ds_y"
    ]
  },
  "FCM": {
    "__init__": [
      "self",
      "block",
      "num_blocks",
      "m_channels",
      "feat_dim"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "num_blocks",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CAMPPlus": {
    "__init__": [
      "self",
      "feat_dim",
      "embedding_size",
      "growth_rate",
      "bn_size",
      "init_channels",
      "config_str",
      "memory_efficient",
      "output_level"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SpeakerVerificationCAMPPlus": {
    "__init__": [
      "self",
      "model_dir",
      "model_config"
    ],
    "forward": [
      "self",
      "audio"
    ],
    "__extract_feature": [
      "self",
      "audio"
    ],
    "__load_check_point": [
      "self",
      "pretrained_model_name"
    ]
  },
  "BasicBlockERes2Net_AFF": {
    "expansion": [],
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride",
      "baseWidth",
      "scale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ERes2Net": {
    "__init__": [
      "self",
      "block",
      "block_fuse",
      "num_blocks",
      "m_channels",
      "feat_dim",
      "embed_dim",
      "pooling_func",
      "two_emb_layer"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "num_blocks",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GenericKeyWordSpotting": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self"
    ]
  },
  "toKaldiMatrix": [
    "np_mat"
  ],
  "printTensor": [
    "torch_tensor"
  ],
  "LinearTransform": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim"
    ],
    "forward": [
      "self",
      "input"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "fread"
    ]
  },
  "FSMNBlock": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "lorder",
      "rorder",
      "lstride",
      "rstride"
    ],
    "forward": [
      "self",
      "input"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "fread"
    ]
  },
  "_build_repeats": [
    "fsmn_layers",
    "linear_dim",
    "proj_dim",
    "lorder",
    "rorder",
    "lstride",
    "rstride"
  ],
  "FSMN": {
    "__init__": [
      "self",
      "input_dim",
      "input_affine_dim",
      "fsmn_layers",
      "linear_dim",
      "proj_dim",
      "lorder",
      "rorder",
      "lstride",
      "rstride",
      "output_affine_dim",
      "output_dim"
    ],
    "fuse_modules": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "in_cache"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "kaldi_file"
    ]
  },
  "FSMNDecorator": {
    "__init__": [
      "self",
      "model_dir",
      "cmvn_file",
      "backbone",
      "input_dim",
      "output_dim",
      "training"
    ],
    "__del__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "init_model": [
      "self",
      "cmvn_file",
      "backbone",
      "input_dim",
      "output_dim"
    ]
  },
  "KWSModel": {
    "__init__": [
      "self",
      "idim",
      "odim",
      "hdim",
      "global_cmvn",
      "preprocessing",
      "backbone",
      "classifier",
      "activation"
    ],
    "to_kaldi_net": [
      "self"
    ],
    "to_pytorch_net": [
      "self",
      "kaldi_file"
    ],
    "forward": [
      "self",
      "x",
      "in_cache"
    ],
    "fuse_modules": [
      "self"
    ]
  },
  "GlobalCMVN": {
    "__init__": [
      "self",
      "mean",
      "istd",
      "norm_var"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "load_kaldi_cmvn": [
    "cmvn_file"
  ],
  "DEBUG": [],
  "print_tensor": [
    "torch_tensor"
  ],
  "Fsmn": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "lorder",
      "rorder",
      "lstride",
      "rstride"
    ],
    "forward": [
      "self",
      "input"
    ],
    "print_model": [
      "self"
    ],
    "to_kaldi_nnet": [
      "self"
    ]
  },
  "FSMNNet": {
    "__init__": [
      "self",
      "input_dim",
      "linear_dim",
      "proj_dim",
      "lorder",
      "rorder",
      "num_syn",
      "fsmn_layers"
    ],
    "_build_repeats": [
      "linear_dim",
      "proj_dim",
      "lorder",
      "rorder",
      "fsmn_layers"
    ],
    "forward": [
      "self",
      "input"
    ],
    "print_model": [
      "self"
    ],
    "print_header": [
      "self"
    ],
    "to_kaldi_nnet": [
      "self"
    ]
  },
  "DFSMN": {
    "__init__": [
      "self",
      "dimproj",
      "dimlinear",
      "lorder",
      "rorder",
      "lstride",
      "rstride"
    ],
    "forward": [
      "self",
      "input"
    ],
    "print_model": [
      "self"
    ]
  },
  "build_dfsmn_repeats": [
    "linear_dim",
    "proj_dim",
    "lorder",
    "rorder",
    "fsmn_layers"
  ],
  "DFSMNUnit": {
    "__init__": [
      "self",
      "dimin",
      "dimexpand",
      "dimout",
      "lorder",
      "rorder"
    ],
    "forward": [
      "self",
      "input"
    ],
    "print_model": [
      "self"
    ],
    "to_kaldi_nnet": [
      "self"
    ]
  },
  "FSMNSeleNetV3": {
    "__init__": [
      "self",
      "input_dim",
      "linear_dim",
      "proj_dim",
      "lorder",
      "rorder",
      "num_syn",
      "fsmn_layers"
    ],
    "forward": [
      "self",
      "input"
    ],
    "print_model": [
      "self"
    ],
    "print_header": [
      "self"
    ],
    "to_kaldi_nnet": [
      "self"
    ]
  },
  "HEADER_BLOCK_SIZE": [],
  "LayerType": {
    "LAYER_DENSE": [],
    "LAYER_GRU": [],
    "LAYER_ATTENTION": [],
    "LAYER_FSMN": [],
    "LAYER_SEQUENTIAL_FSMN": [],
    "LAYER_FSMN_SELE": [],
    "LAYER_GRU_ATTENTION": [],
    "LAYER_DFSMN": []
  },
  "ActivationType": {
    "ACTIVATION_NONE": [],
    "ACTIVATION_RELU": [],
    "ACTIVATION_TANH": [],
    "ACTIVATION_SIGMOID": [],
    "ACTIVATION_SOFTMAX": [],
    "ACTIVATION_LOGSOFTMAX": []
  },
  "f32ToI32": [
    "f"
  ],
  "printNeonMatrix": [
    "w"
  ],
  "printNeonVector": [
    "b"
  ],
  "printDense": [
    "layer"
  ],
  "printGRU": [
    "layer"
  ],
  "FSMNSeleNetV2Decorator": {
    "MODEL_CLASS": [],
    "MODEL_TXT": [],
    "SC_CONFIG": [],
    "__init__": [
      "self",
      "model_dir",
      "training"
    ],
    "__del__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "forward_decode": [
      "self",
      "data"
    ]
  },
  "FSMNSeleNetV3Decorator": {
    "MODEL_CLASS": [],
    "__init__": [
      "self",
      "model_dir",
      "training"
    ]
  },
  "FSMNUnit": {
    "__init__": [
      "self",
      "dimlinear",
      "dimproj",
      "lorder",
      "rorder"
    ],
    "forward": [
      "self",
      "input"
    ],
    "print_model": [
      "self"
    ],
    "to_kaldi_nnet": [
      "self"
    ]
  },
  "FSMNSeleNetV2": {
    "__init__": [
      "self",
      "input_dim",
      "linear_dim",
      "proj_dim",
      "lorder",
      "rorder",
      "num_syn",
      "fsmn_layers",
      "sele_layer"
    ],
    "forward": [
      "self",
      "input"
    ],
    "print_model": [
      "self"
    ],
    "print_header": [
      "self"
    ],
    "to_kaldi_nnet": [
      "self"
    ]
  },
  "DfsmnAns": {
    "__init__": [
      "self",
      "model_dir",
      "fsmn_depth",
      "lorder"
    ],
    "forward": [
      "self",
      "input"
    ],
    "to_kaldi_nnet": [
      "self"
    ]
  },
  "ZipenhancerDecorator": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "ZipEnhancer": {
    "__init__": [
      "self",
      "h"
    ],
    "forward": [
      "self",
      "noisy_mag",
      "noisy_pha"
    ]
  },
  "AttrDict": {
    "__init__": [
      "self"
    ]
  },
  "mag_pha_stft": [
    "y",
    "n_fft",
    "hop_size",
    "win_size",
    "compress_factor",
    "center"
  ],
  "mag_pha_istft": [
    "mag",
    "pha",
    "n_fft",
    "hop_size",
    "win_size",
    "compress_factor",
    "center"
  ],
  "init_kernels": [
    "win_len",
    "win_inc",
    "fft_len",
    "win_type",
    "invers"
  ],
  "ConvSTFT": {
    "__init__": [
      "self",
      "win_len",
      "win_inc",
      "fft_len",
      "win_type",
      "feature_type",
      "fix"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "ConviSTFT": {
    "__init__": [
      "self",
      "win_len",
      "win_inc",
      "fft_len",
      "win_type",
      "feature_type",
      "fix"
    ],
    "forward": [
      "self",
      "inputs",
      "phase"
    ]
  },
  "FRCRNDecorator": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "FRCRN": {
    "__init__": [
      "self",
      "complex",
      "model_complexity",
      "model_depth",
      "log_amp",
      "padding_mode",
      "win_len",
      "win_inc",
      "fft_len",
      "win_type"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "apply_mask": [
      "self",
      "cmp_spec",
      "cmp_mask"
    ],
    "get_params": [
      "self",
      "weight_decay"
    ],
    "loss": [
      "self",
      "noisy",
      "labels",
      "out_list",
      "mode"
    ],
    "loss_1layer": [
      "self",
      "noisy",
      "est",
      "est_wav",
      "labels",
      "cmp_mask",
      "mode"
    ]
  },
  "si_snr": [
    "s1",
    "s2",
    "eps"
  ],
  "ComplexUniDeepFsmn": {
    "__init__": [
      "self",
      "nIn",
      "nHidden",
      "nOut"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ComplexUniDeepFsmn_L1": {
    "__init__": [
      "self",
      "nIn",
      "nHidden",
      "nOut"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ComplexConv2d": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ComplexConvTranspose2d": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel",
      "kernel_size",
      "stride",
      "padding",
      "output_padding",
      "dilation",
      "groups",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ComplexBatchNorm2d": {
    "__init__": [
      "self",
      "num_features",
      "eps",
      "momentum",
      "affine",
      "track_running_stats"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DualPathZipformer2Encoder": {
    "__init__": [
      "self",
      "encoder_layer",
      "num_layers",
      "pos_dim",
      "dropout",
      "warmup_begin",
      "warmup_end",
      "initial_layerdrop_rate",
      "final_layerdrop_rate",
      "bypass_layer"
    ],
    "forward": [
      "self",
      "src",
      "chunk_size",
      "feature_mask",
      "attn_mask",
      "src_key_padding_mask"
    ]
  },
  "DualPathDownsampledZipformer2Encoder": {
    "__init__": [
      "self",
      "encoder",
      "dim",
      "t_downsample",
      "f_downsample",
      "dropout"
    ],
    "forward": [
      "self",
      "src",
      "chunk_size",
      "feature_mask",
      "attn_mask",
      "src_key_padding_mask"
    ]
  },
  "Zipformer2DualPathEncoder": {
    "__init__": [
      "self",
      "output_downsampling_factor",
      "downsampling_factor",
      "f_downsampling_factor",
      "encoder_dim",
      "num_encoder_layers",
      "encoder_unmasked_dim",
      "query_head_dim",
      "pos_head_dim",
      "value_head_dim",
      "num_heads",
      "feedforward_dim",
      "cnn_module_kernel",
      "pos_dim",
      "dropout",
      "warmup_batches",
      "causal",
      "chunk_size",
      "left_context_frames"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "logaddexp_onnx": [
    "x",
    "y"
  ],
  "logaddexp": [
    "x",
    "y"
  ],
  "PiecewiseLinear": {
    "__init__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "__mul__": [
      "self",
      "alpha"
    ],
    "__add__": [
      "self",
      "x"
    ],
    "max": [
      "self",
      "x"
    ],
    "min": [
      "self",
      "x"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "get_common_basis": [
      "self",
      "p",
      "include_crossings"
    ]
  },
  "ScheduledFloat": {
    "__init__": [
      "self"
    ],
    "extra_repr": [
      "self"
    ],
    "__float__": [
      "self"
    ],
    "__add__": [
      "self",
      "x"
    ],
    "max": [
      "self",
      "x"
    ]
  },
  "FloatLike": [],
  "SoftmaxFunction": {
    "forward": [
      "ctx",
      "x",
      "dim"
    ],
    "backward": [
      "ctx",
      "ans_grad"
    ]
  },
  "inplace_softmax": [
    "tensor",
    "dim"
  ],
  "softmax": [
    "x",
    "dim"
  ],
  "BiasNormFunction": {
    "forward": [
      "ctx",
      "x",
      "bias",
      "log_scale",
      "channel_dim",
      "store_output_for_backprop"
    ],
    "backward": [
      "ctx",
      "ans_grad"
    ]
  },
  "BiasNorm": {
    "__init__": [
      "self",
      "num_channels",
      "channel_dim",
      "log_scale",
      "log_scale_min",
      "log_scale_max",
      "store_output_for_backprop"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ScaledLinear": [],
  "ChunkCausalDepthwiseConv1d": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "initial_scale",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "chunk_size"
    ],
    "_get_chunk_scale": [
      "self",
      "chunk_size"
    ],
    "streaming_forward": [
      "self",
      "x",
      "cache"
    ]
  },
  "penalize_abs_values_gt": [
    "x",
    "limit",
    "penalty",
    "name"
  ],
  "WithLoss": {
    "forward": [
      "ctx",
      "x",
      "y",
      "name"
    ],
    "backward": [
      "ctx",
      "ans_grad"
    ]
  },
  "with_loss": [
    "x",
    "y",
    "name"
  ],
  "LimitParamValue": {
    "forward": [
      "ctx",
      "x",
      "min",
      "max"
    ],
    "backward": [
      "ctx",
      "x_grad"
    ]
  },
  "limit_param_value": [
    "x",
    "min",
    "max",
    "prob",
    "training"
  ],
  "_no_op": [
    "x"
  ],
  "Dropout2": {
    "__init__": [
      "self",
      "p"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SwooshLFunction": {
    "forward": [
      "ctx",
      "x"
    ],
    "backward": [
      "ctx",
      "y_grad"
    ]
  },
  "SwooshL": {
    "forward": [
      "self",
      "x"
    ]
  },
  "SwooshLOnnx": {
    "forward": [
      "self",
      "x"
    ]
  },
  "SwooshRFunction": {
    "forward": [
      "ctx",
      "x"
    ],
    "backward": [
      "ctx",
      "y_grad"
    ]
  },
  "SwooshR": {
    "forward": [
      "self",
      "x"
    ]
  },
  "SwooshROnnx": {
    "forward": [
      "self",
      "x"
    ]
  },
  "SwooshLForward": [
    "x"
  ],
  "SwooshLForwardAndDeriv": [
    "x"
  ],
  "SwooshRForward": [
    "x"
  ],
  "SwooshRForwardAndDeriv": [
    "x"
  ],
  "ActivationDropoutAndLinear": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bias",
      "activation",
      "dropout_p",
      "dropout_shared_dim",
      "initial_scale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "convert_num_channels": [
    "x",
    "num_channels"
  ],
  "SubPixelConvTranspose2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DenseBlockV2": {
    "__init__": [
      "self",
      "h",
      "kernel_size",
      "depth"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DenseEncoder": {
    "__init__": [
      "self",
      "h",
      "in_channel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BaseDecoder": {
    "__init__": [
      "self",
      "h"
    ]
  },
  "MappingDecoder": {
    "__init__": [
      "self",
      "h",
      "out_channel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PhaseDecoder": {
    "__init__": [
      "self",
      "h",
      "out_channel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Zipformer2EncoderLayer": {
    "__init__": [
      "self",
      "embed_dim",
      "pos_dim",
      "num_heads",
      "query_head_dim",
      "pos_head_dim",
      "value_head_dim",
      "feedforward_dim",
      "dropout",
      "cnn_module_kernel",
      "causal",
      "attention_skip_rate",
      "conv_skip_rate",
      "const_attention_rate",
      "ff2_skip_rate",
      "ff3_skip_rate",
      "bypass_skip_rate"
    ],
    "get_sequence_dropout_mask": [
      "self",
      "x",
      "dropout_rate"
    ],
    "sequence_dropout": [
      "self",
      "x",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "src",
      "pos_emb",
      "chunk_size",
      "attn_mask",
      "src_key_padding_mask"
    ]
  },
  "BypassModule": {
    "__init__": [
      "self",
      "embed_dim",
      "skip_rate",
      "straight_through_rate",
      "scale_min",
      "scale_max"
    ],
    "_get_bypass_scale": [
      "self",
      "batch_size"
    ],
    "forward": [
      "self",
      "src_orig",
      "src"
    ]
  },
  "SimpleDownsample": {
    "__init__": [
      "self",
      "channels",
      "downsample",
      "dropout"
    ],
    "forward": [
      "self",
      "src"
    ]
  },
  "SimpleUpsample": {
    "__init__": [
      "self",
      "num_channels",
      "upsample"
    ],
    "forward": [
      "self",
      "src"
    ]
  },
  "CompactRelPositionalEncoding": {
    "__init__": [
      "self",
      "embed_dim",
      "dropout_rate",
      "max_len",
      "length_factor"
    ],
    "extend_pe": [
      "self",
      "x",
      "left_context_len"
    ],
    "forward": [
      "self",
      "x",
      "left_context_len"
    ]
  },
  "RelPositionMultiheadAttentionWeights": {
    "__init__": [
      "self",
      "embed_dim",
      "pos_dim",
      "num_heads",
      "query_head_dim",
      "pos_head_dim",
      "dropout",
      "pos_emb_skip_rate"
    ],
    "forward": [
      "self",
      "x",
      "pos_emb",
      "key_padding_mask",
      "attn_mask"
    ]
  },
  "FeedforwardModule": {
    "__init__": [
      "self",
      "embed_dim",
      "feedforward_dim",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NonlinAttention": {
    "__init__": [
      "self",
      "channels",
      "hidden_channels"
    ],
    "forward": [
      "self",
      "x",
      "attn_weights"
    ]
  },
  "ConvolutionModule": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "causal"
    ],
    "forward": [
      "self",
      "x",
      "src_key_padding_mask",
      "chunk_size"
    ]
  },
  "GenericFunASR": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self"
    ]
  },
  "UnetVC": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "Generator2": {
    "__init__": [
      "self",
      "dim_in",
      "style_dim",
      "max_conv_dim",
      "num_spk",
      "w_hpf",
      "F0_channel",
      "out_for_onnx"
    ],
    "forward": [
      "self",
      "x",
      "c"
    ]
  },
  "ConditionGenerator": {
    "__init__": [
      "self",
      "input_channels",
      "resblock_kernel_sizes",
      "upsample_rates",
      "upsample_initial_channel",
      "resblock_type",
      "upsample_kernel_sizes",
      "resblock_dilation_sizes",
      "transposedconv",
      "unet",
      "extra_info",
      "bias"
    ],
    "forward": [
      "self",
      "inp",
      "s",
      "extra_mc",
      "a",
      "b"
    ],
    "inference": [
      "self",
      "x"
    ]
  },
  "FeedForwardNet": {
    "__init__": [
      "self",
      "d_in",
      "d_hid",
      "d_out",
      "kernel_size",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MemoryBlockV2": {
    "__init__": [
      "self",
      "d",
      "filter_size",
      "shift",
      "dropout"
    ],
    "forward": [
      "self",
      "input",
      "mask"
    ]
  },
  "FsmnEncoderV2": {
    "__init__": [
      "self",
      "filter_size",
      "fsmn_num_layers",
      "input_dim",
      "num_memory_units",
      "ffn_inner_dim",
      "dropout",
      "spk_dim",
      "shift"
    ],
    "forward": [
      "self",
      "input",
      "mask"
    ]
  },
  "load_cmvn": [
    "cmvn_file"
  ],
  "apply_cmvn": [
    "inputs",
    "cmvn"
  ],
  "apply_lfr": [
    "inputs",
    "lfr_m",
    "lfr_n"
  ],
  "WavFrontend": {
    "__init__": [
      "self",
      "cmvn_file",
      "fs",
      "window",
      "n_mels",
      "frame_length",
      "frame_shift",
      "filter_length_min",
      "filter_length_max",
      "lfr_m",
      "lfr_n",
      "dither",
      "snip_edges",
      "upsacle_samples"
    ],
    "output_size": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_lengths"
    ],
    "forward_fbank": [
      "self",
      "input",
      "input_lengths"
    ],
    "forward_lfr_cmvn": [
      "self",
      "input",
      "input_lengths"
    ]
  },
  "make_pad_mask": [
    "lengths",
    "xs",
    "length_dim",
    "maxlen"
  ],
  "SpeakerVerificationCamplus": {
    "__init__": [
      "self",
      "pretrained_model_name",
      "device"
    ],
    "forward": [
      "self",
      "audio"
    ],
    "inference": [
      "self",
      "feature"
    ],
    "__extract_feature": [
      "self",
      "audio"
    ],
    "__load_check_point": [
      "self",
      "pretrained_model_name",
      "device"
    ]
  },
  "GenericInverseTextProcessing": {
    "__init__": [
      "self",
      "model_dir",
      "itn_model_name",
      "model_config"
    ],
    "forward": [
      "self"
    ]
  },
  "WeNetAutomaticSpeechRecognition": {
    "__init__": [
      "self",
      "model_dir",
      "am_model_name",
      "model_config"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "GenericAudioQuantization": {
    "__init__": [
      "self",
      "model_dir",
      "model_name",
      "model_config"
    ],
    "forward": [
      "self"
    ]
  },
  "GlobalLayerNorm": {
    "__init__": [
      "self",
      "dim",
      "shape",
      "eps",
      "elementwise_affine"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CumulativeLayerNorm": {
    "__init__": [
      "self",
      "dim",
      "elementwise_affine"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "select_norm": [
    "norm",
    "dim",
    "shape"
  ],
  "DepthwiseConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "bias"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "MossFormerConvModule": {
    "__init__": [
      "self",
      "in_channels",
      "kernel_size",
      "expansion_factor"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "CLayerNorm": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "sample"
    ]
  },
  "GLayerNorm": {
    "__init__": [
      "self",
      "channels",
      "eps"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "sample"
    ]
  },
  "MossFormer": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "load_check_point": [
      "self",
      "load_path",
      "device"
    ],
    "as_dict": [
      "self"
    ]
  },
  "IdentityBlock": {
    "_init__": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "MossFormerM": {
    "__init__": [
      "self",
      "num_blocks",
      "d_model",
      "attn_dropout",
      "group_size",
      "query_key_dim",
      "expansion_factor",
      "causal"
    ],
    "forward": [
      "self",
      "src"
    ]
  },
  "ComputeAttention": {
    "__init__": [
      "self",
      "att_mdl",
      "out_channels",
      "norm",
      "skip_connection"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MossFormerMaskNet": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "att_model",
      "norm",
      "num_spks",
      "skip_connection",
      "use_global_pos_enc"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "padding_to_multiple_of": [
    "n",
    "mult"
  ],
  "ScaledSinuEmbedding": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OffsetScale": {
    "__init__": [
      "self",
      "dim",
      "heads"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FFConvM": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "norm_klass",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MossFormerBlock": {
    "__init__": [
      "self",
      "dim",
      "group_size",
      "query_key_dim",
      "expansion_factor",
      "causal",
      "dropout",
      "rotary_pos_emb",
      "norm_klass",
      "shift_tokens"
    ],
    "forward": [
      "self",
      "x"
    ],
    "cal_attention": [
      "self",
      "x",
      "quad_q",
      "lin_q",
      "quad_k",
      "lin_k",
      "v",
      "u",
      "mask"
    ]
  },
  "MossFormerModule": {
    "__init__": [
      "self",
      "dim",
      "depth",
      "group_size",
      "query_key_dim",
      "expansion_factor",
      "causal",
      "attn_dropout",
      "norm_type",
      "shift_tokens"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DilatedDenseNet": {
    "__init__": [
      "self",
      "depth",
      "lorder",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FFConvMDilated": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "norm_klass",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UniDeepFsmnDual": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "lorder",
      "hidden_size"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "UniDeepFsmnDilated": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "lorder",
      "hidden_size",
      "depth"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ILayerNorm": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "sample"
    ]
  },
  "_LayerNorm": {
    "__init__": [
      "self",
      "channel_size"
    ],
    "apply_gain_and_bias": [
      "self",
      "normed_x"
    ]
  },
  "GlobLayerNorm": {
    "forward": [
      "self",
      "x"
    ]
  },
  "ComputationBlock": {
    "__init__": [
      "self",
      "num_blocks",
      "out_channels",
      "norm",
      "skip_around_intra"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MossFormer2": {
    "__init__": [
      "self",
      "model_dir",
      "in_channels",
      "out_channels",
      "num_blocks",
      "kernel_size",
      "norm",
      "num_spks",
      "skip_around_intra",
      "use_global_pos_enc",
      "max_length"
    ],
    "forward": [
      "self",
      "input"
    ],
    "load_check_point": [
      "self",
      "load_path",
      "device"
    ]
  },
  "identity": [
    "t"
  ],
  "GroupLinear": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "K"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FFM": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "norm_klass",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FLASH_ShareA_FFConvM": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "cal_attention": [
      "self",
      "x",
      "quad_q",
      "lin_q",
      "quad_k",
      "lin_k",
      "v",
      "u",
      "mask"
    ]
  },
  "GatedFSMNDilated": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "lorder",
      "hidden_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GatedFSMNDilatedDual": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "lorder",
      "hidden_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GatedFSMNBlockDilatedDual": {
    "__init__": [
      "self",
      "dim",
      "inner_channels"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "GatedFSMNBlockDilated": {
    "__init__": [
      "self",
      "dim",
      "inner_channels",
      "group_size",
      "norm_type"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "MossformerBlockGFSMN": {
    "__init__": [
      "self"
    ],
    "_build_repeats": [
      "self",
      "in_channels",
      "out_channels",
      "lorder",
      "hidden_size",
      "repeats"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MossformerBlock": {
    "__init__": [
      "self"
    ],
    "_build_repeats": [
      "self",
      "in_channels",
      "out_channels",
      "lorder",
      "hidden_size",
      "repeats"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Rotation": [],
  "Translation": [],
  "Operation": [],
  "NumpyExample": [],
  "TorchExample": [],
  "make_data_config": [
    "config",
    "mode",
    "num_res"
  ],
  "process_label": [
    "all_atom_positions",
    "operation"
  ],
  "load_single_feature": [
    "sequence_id",
    "monomer_feature_dir",
    "uniprot_msa_dir",
    "is_monomer"
  ],
  "load_single_label": [
    "label_id",
    "label_dir",
    "symmetry_operation"
  ],
  "process": [
    "config",
    "mode",
    "features",
    "labels",
    "seed",
    "batch_idx",
    "data_idx",
    "is_distillation"
  ],
  "load_and_process": [
    "config",
    "mode",
    "seed",
    "batch_idx",
    "data_idx",
    "is_distillation"
  ],
  "UnifoldDataset": {
    "__init__": [
      "self",
      "args",
      "seed",
      "config",
      "data_path",
      "mode",
      "max_step",
      "disable_sd",
      "json_prefix"
    ],
    "cal_sample_weight": [
      "self",
      "sample_weight"
    ],
    "sample_chain": [
      "self",
      "idx",
      "sample_by_seq"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "samples"
    ],
    "_inverse_map": [
      "mapping"
    ]
  },
  "UnifoldMultimerDataset": {
    "__init__": [
      "self",
      "args",
      "seed",
      "config",
      "data_path",
      "mode",
      "max_step",
      "disable_sd",
      "json_prefix"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "collater": [
      "samples"
    ],
    "get_pdb_name": [
      "chain"
    ],
    "get_chains": [
      "canon_chain_map"
    ],
    "filter_pdb_by_max_chains": [
      "pdb_chains",
      "pdb_assembly",
      "sample_weight",
      "max_chains"
    ]
  },
  "N_RES": [],
  "N_MSA": [],
  "N_EXTRA_MSA": [],
  "N_TPL": [],
  "d_pair": [],
  "d_msa": [],
  "d_template": [],
  "d_extra_msa": [],
  "d_single": [],
  "max_recycling_iters": [],
  "chunk_size": [],
  "aux_distogram_bins": [],
  "eps": [],
  "inf": [],
  "use_templates": [],
  "is_multimer": [],
  "base_config": [],
  "recursive_set": [
    "c",
    "key",
    "value",
    "ignore"
  ],
  "model_config": [
    "name",
    "train"
  ],
  "UnifoldForProteinStructrue": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self"
    ],
    "half": [
      "self"
    ],
    "bfloat16": [
      "self"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "forward": [
      "self",
      "batch"
    ]
  },
  "base_architecture": [
    "args"
  ],
  "ChainId": [],
  "PdbHeader": [],
  "PdbStructure": [],
  "SeqRes": [],
  "MmCIFDict": [],
  "Monomer": {},
  "AtomSite": {},
  "ResiduePosition": {},
  "ResidueAtPosition": {},
  "MmcifObject": {},
  "ParsingResult": {},
  "ParseError": {},
  "mmcif_loop_to_list": [
    "prefix",
    "parsed_info"
  ],
  "mmcif_loop_to_dict": [
    "prefix",
    "index",
    "parsed_info"
  ],
  "fast_parse": [],
  "parse": [],
  "_get_first_model": [
    "structure"
  ],
  "_MIN_LENGTH_OF_CHAIN_TO_BE_COUNTED_AS_PEPTIDE": [],
  "get_release_date": [
    "parsed_info"
  ],
  "_get_header": [
    "parsed_info"
  ],
  "_get_atom_site_list": [
    "parsed_info"
  ],
  "_get_protein_chains": [],
  "_is_set": [
    "data"
  ],
  "_UNIPROT_PATTERN": [],
  "Identifiers": {},
  "_parse_sequence_identifier": [
    "msa_sequence_identifier"
  ],
  "_extract_sequence_identifier": [
    "description"
  ],
  "get_identifiers": [
    "description"
  ],
  "get_chain_id_map": [
    "sequences",
    "descriptions"
  ],
  "divide_multi_chains": [
    "fasta_name",
    "output_dir_base",
    "sequences",
    "descriptions"
  ],
  "FeatureDict": [],
  "TemplateSearcher": [],
  "make_sequence_features": [
    "sequence",
    "description",
    "num_res"
  ],
  "make_msa_features": [
    "msas"
  ],
  "run_msa_tool": [
    "msa_runner",
    "input_fasta_path",
    "msa_out_path",
    "msa_format",
    "use_precomputed_msas"
  ],
  "DataPipeline": {
    "__init__": [
      "self",
      "jackhmmer_binary_path",
      "hhblits_binary_path",
      "uniref90_database_path",
      "mgnify_database_path",
      "bfd_database_path",
      "uniclust30_database_path",
      "small_bfd_database_path",
      "uniprot_database_path",
      "template_searcher",
      "template_featurizer",
      "use_small_bfd",
      "mgnify_max_hits",
      "uniref_max_hits",
      "use_precomputed_msas"
    ],
    "process": [
      "self",
      "input_fasta_path",
      "msa_output_dir"
    ],
    "process_uniprot": [
      "self",
      "input_fasta_path",
      "msa_output_dir"
    ]
  },
  "Error": {},
  "NoChainsError": {},
  "SequenceNotInTemplateError": {},
  "NoAtomDataInTemplateError": {},
  "TemplateAtomMaskAllZerosError": {},
  "QueryToTemplateAlignError": {},
  "CaDistanceError": {},
  "MultipleChainsError": {},
  "PrefilterError": {},
  "DateError": {},
  "AlignRatioError": {},
  "DuplicateError": {},
  "LengthError": {},
  "TEMPLATE_FEATURES": [],
  "_get_pdb_id_and_chain": [
    "hit"
  ],
  "_is_after_cutoff": [
    "pdb_id",
    "release_dates",
    "release_date_cutoff"
  ],
  "_parse_obsolete": [
    "obsolete_file_path"
  ],
  "_parse_release_dates": [
    "path"
  ],
  "_assess_hhsearch_hit": [
    "hit",
    "hit_pdb_code",
    "query_sequence",
    "release_dates",
    "release_date_cutoff",
    "max_subsequence_ratio",
    "min_align_ratio"
  ],
  "_find_template_in_pdb": [
    "template_chain_id",
    "template_sequence",
    "mmcif_object"
  ],
  "_realign_pdb_template_to_query": [
    "old_template_sequence",
    "template_chain_id",
    "mmcif_object",
    "old_mapping",
    "kalign_binary_path"
  ],
  "_check_residue_distances": [
    "all_positions",
    "all_positions_mask",
    "max_ca_ca_distance"
  ],
  "_get_atom_positions": [
    "mmcif_object",
    "auth_chain_id",
    "max_ca_ca_distance"
  ],
  "_extract_template_features": [
    "mmcif_object",
    "pdb_id",
    "mapping",
    "template_sequence",
    "query_sequence",
    "template_chain_id",
    "kalign_binary_path"
  ],
  "_build_query_to_hit_index_mapping": [
    "hit_query_sequence",
    "hit_sequence",
    "indices_hit",
    "indices_query",
    "original_query_sequence"
  ],
  "SingleHitResult": {},
  "_read_file": [
    "path"
  ],
  "_process_single_hit": [
    "query_sequence",
    "hit",
    "mmcif_dir",
    "max_template_date",
    "release_dates",
    "obsolete_pdbs",
    "kalign_binary_path",
    "strict_error_check"
  ],
  "TemplateSearchResult": {},
  "TemplateHitFeaturizer": {
    "__init__": [
      "self",
      "mmcif_dir",
      "max_template_date",
      "max_hits",
      "kalign_binary_path",
      "release_dates_path",
      "obsolete_pdbs_path",
      "strict_error_check"
    ],
    "get_templates": [
      "self",
      "query_sequence",
      "hits"
    ]
  },
  "HhsearchHitFeaturizer": {
    "get_templates": [
      "self",
      "query_sequence",
      "hits"
    ]
  },
  "HmmsearchHitFeaturizer": {
    "get_templates": [
      "self",
      "query_sequence",
      "hits"
    ]
  },
  "DeletionMatrix": [],
  "Msa": {
    "__post_init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "truncate": [
      "self",
      "max_seqs"
    ]
  },
  "TemplateHit": {},
  "parse_fasta": [
    "fasta_string"
  ],
  "parse_stockholm": [
    "stockholm_string"
  ],
  "parse_a3m": [
    "a3m_string"
  ],
  "_convert_sto_seq_to_a3m": [
    "query_non_gaps",
    "sto_seq"
  ],
  "convert_stockholm_to_a3m": [
    "stockholm_format",
    "max_sequences",
    "remove_first_row_gaps"
  ],
  "_keep_line": [
    "line",
    "seqnames"
  ],
  "truncate_stockholm_msa": [
    "stockholm_msa",
    "max_sequences"
  ],
  "remove_empty_columns_from_stockholm_msa": [
    "stockholm_msa"
  ],
  "deduplicate_stockholm_msa": [
    "stockholm_msa"
  ],
  "_get_hhr_line_regex_groups": [
    "regex_pattern",
    "line"
  ],
  "_update_hhr_residue_indices_list": [
    "sequence",
    "start_index",
    "indices_list"
  ],
  "_parse_hhr_hit": [
    "detailed_lines"
  ],
  "parse_hhr": [
    "hhr_string"
  ],
  "parse_e_values_from_tblout": [
    "tblout"
  ],
  "_get_indices": [
    "sequence",
    "start"
  ],
  "HitMetadata": {},
  "_parse_hmmsearch_description": [
    "description"
  ],
  "parse_hmmsearch_a3m": [
    "query_sequence",
    "a3m_string",
    "skip_first"
  ],
  "Hmmsearch": {
    "__init__": [
      "self"
    ],
    "output_format": [
      "self"
    ],
    "input_format": [
      "self"
    ],
    "query": [
      "self",
      "msa_sto"
    ],
    "query_with_hmm": [
      "self",
      "hmm"
    ],
    "get_template_hits": [
      "self",
      "output_string",
      "input_sequence"
    ]
  },
  "_to_a3m": [
    "sequences"
  ],
  "Kalign": {
    "__init__": [
      "self"
    ],
    "align": [
      "self",
      "sequences"
    ]
  },
  "_HHBLITS_DEFAULT_P": [],
  "_HHBLITS_DEFAULT_Z": [],
  "HHBlits": {
    "__init__": [
      "self"
    ],
    "query": [
      "self",
      "input_fasta_path"
    ]
  },
  "tmpdir_manager": [
    "base_dir"
  ],
  "timing": [
    "msg"
  ],
  "HHSearch": {
    "__init__": [
      "self"
    ],
    "output_format": [
      "self"
    ],
    "input_format": [
      "self"
    ],
    "query": [
      "self",
      "a3m"
    ],
    "get_template_hits": [
      "self",
      "output_string",
      "input_sequence"
    ]
  },
  "Jackhmmer": {
    "__init__": [
      "self"
    ],
    "_query_chunk": [
      "self",
      "input_fasta_path",
      "database_path"
    ],
    "query": [
      "self",
      "input_fasta_path"
    ]
  },
  "Hmmbuild": {
    "__init__": [
      "self"
    ],
    "build_profile_from_sto": [
      "self",
      "sto",
      "model_construction"
    ],
    "build_profile_from_a3m": [
      "self",
      "a3m"
    ],
    "_build_profile": [
      "self",
      "msa",
      "model_construction"
    ]
  },
  "nonensembled_fns": [
    "common_cfg",
    "mode_cfg"
  ],
  "crop_and_fix_size_fns": [
    "common_cfg",
    "mode_cfg",
    "crop_and_fix_size_seed"
  ],
  "ensembled_fns": [
    "common_cfg",
    "mode_cfg"
  ],
  "process_features": [
    "tensors",
    "common_cfg",
    "mode_cfg"
  ],
  "compose": [
    "x",
    "fs"
  ],
  "pad_then_stack": [
    "values"
  ],
  "map_fn": [
    "fun",
    "x"
  ],
  "process_single_label": [
    "label",
    "num_ensemble"
  ],
  "process_labels": [
    "labels_list",
    "num_ensemble"
  ],
  "label_transform_fn": [],
  "lru_cache": [
    "maxsize",
    "typed",
    "copy",
    "deepcopy"
  ],
  "load_pickle_safe": [
    "path"
  ],
  "load_pickle": [
    "path"
  ],
  "correct_template_restypes": [
    "feature"
  ],
  "convert_all_seq_feature": [
    "feature"
  ],
  "to_dense_matrix": [
    "spmat_dict"
  ],
  "FEATS_DTYPE": [],
  "uncompress_features": [
    "feats"
  ],
  "compress_features": [
    "features"
  ],
  "ModelOutput": [],
  "PDB_CHAIN_IDS": [],
  "PDB_MAX_CHAINS": [],
  "Protein": {
    "__post_init__": [
      "self"
    ]
  },
  "from_pdb_string": [
    "pdb_str",
    "chain_id"
  ],
  "_chain_end": [
    "atom_index",
    "end_resname",
    "chain_name",
    "residue_index"
  ],
  "to_pdb": [
    "prot"
  ],
  "ideal_atom_mask": [
    "prot"
  ],
  "from_prediction": [
    "features",
    "result",
    "b_factors"
  ],
  "from_feature": [
    "features",
    "b_factors"
  ],
  "REQUIRED_FEATURES": [],
  "MAX_TEMPLATES": [],
  "MSA_CROP_SIZE": [],
  "_is_homomer_or_monomer": [
    "chains"
  ],
  "pair_and_merge": [
    "all_chain_features"
  ],
  "crop_chains": [
    "chains_list",
    "msa_crop_size",
    "pair_msa_sequences",
    "max_templates"
  ],
  "_crop_single_chain": [
    "chain",
    "msa_crop_size",
    "pair_msa_sequences",
    "max_templates"
  ],
  "process_final": [
    "np_example"
  ],
  "_make_seq_mask": [
    "np_example"
  ],
  "_make_msa_mask": [
    "np_example"
  ],
  "_filter_features": [
    "np_example"
  ],
  "process_unmerged_features": [
    "all_chain_features"
  ],
  "empty_template_feats": [
    "n_res"
  ],
  "convert_monomer_features": [
    "monomer_features"
  ],
  "int_id_to_str_id": [
    "num"
  ],
  "add_assembly_features": [
    "all_chain_features"
  ],
  "pad_msa": [
    "np_example",
    "min_num_seq"
  ],
  "merge_msas": [
    "msa",
    "del_mat",
    "new_msa",
    "new_del_mat"
  ],
  "ca_ca": [],
  "chi_angles_atoms": [],
  "chi_angles_mask": [],
  "chi_pi_periodic": [],
  "rigid_group_atom_positions": [],
  "residue_atoms": [],
  "residue_atom_renaming_swaps": [],
  "van_der_waals_radius": [],
  "Bond": [],
  "BondAngle": [],
  "load_stereo_chemical_props": [],
  "between_res_bond_length_c_n": [],
  "between_res_bond_length_stddev_c_n": [],
  "between_res_cos_angles_c_n_ca": [],
  "between_res_cos_angles_ca_c_n": [],
  "atom_types": [],
  "atom_order": [],
  "atom_type_num": [],
  "restype_name_to_atom14_names": [],
  "restypes": [],
  "restype_order": [],
  "restype_num": [],
  "unk_restype_index": [],
  "restypes_with_x": [],
  "restype_order_with_x": [],
  "sequence_to_onehot": [
    "sequence",
    "mapping",
    "map_unknown_to_x"
  ],
  "restype_1to3": [],
  "restype_3to1": [],
  "unk_restype": [],
  "resnames": [],
  "resname_to_idx": [],
  "HHBLITS_AA_TO_ID": [],
  "ID_TO_HHBLITS_AA": [],
  "restypes_with_x_and_gap": [],
  "MAP_HHBLITS_AATYPE_TO_OUR_AATYPE": [],
  "_make_standard_atom_mask": [],
  "STANDARD_ATOM_MASK": [],
  "chi_angle_atom": [
    "atom_index"
  ],
  "chi_atom_1_one_hot": [],
  "chi_atom_2_one_hot": [],
  "chi_angles_atom_indices": [],
  "chi_groups_for_atom": [],
  "_make_rigid_transformation_4x4": [
    "ex",
    "ey",
    "translation"
  ],
  "restype_atom37_to_rigid_group": [],
  "restype_atom37_mask": [],
  "restype_atom37_rigid_group_positions": [],
  "restype_atom14_to_rigid_group": [],
  "restype_atom14_mask": [],
  "restype_atom14_rigid_group_positions": [],
  "restype_rigid_group_default_frame": [],
  "_make_rigid_group_constants": [],
  "make_atom14_dists_bounds": [
    "overlap_tolerance",
    "bond_length_tolerance_factor"
  ],
  "_make_atom14_and_atom37_constants": [],
  "_make_renaming_matrices": [],
  "renaming_matrices": [],
  "_make_atom14_is_ambiguous": [],
  "restype_atom14_is_ambiguous": [],
  "get_chi_atom_indices": [],
  "chi_atom_indices": [],
  "NumpyDict": [],
  "TorchDict": [],
  "MSA_FEATURE_NAMES": [],
  "cast_to_64bit_ints": [
    "protein"
  ],
  "make_seq_mask": [
    "protein"
  ],
  "make_template_mask": [
    "protein"
  ],
  "curry1": [
    "f"
  ],
  "correct_msa_restypes": [
    "protein"
  ],
  "squeeze_features": [
    "protein"
  ],
  "randomly_replace_msa_with_unknown": [
    "protein",
    "replace_proportion"
  ],
  "gumbel_max_sample": [
    "logits"
  ],
  "gumbel_argsort_sample_idx": [
    "logits"
  ],
  "uniform_permutation": [
    "num_seq"
  ],
  "gumbel_permutation": [
    "msa_mask",
    "msa_chains"
  ],
  "sample_msa": [
    "protein",
    "max_seq",
    "keep_extra",
    "gumbel_sample",
    "biased_msa_by_chain"
  ],
  "sample_msa_distillation": [
    "protein",
    "max_seq"
  ],
  "random_delete_msa": [
    "protein",
    "config"
  ],
  "crop_extra_msa": [
    "protein",
    "max_extra_msa"
  ],
  "delete_extra_msa": [
    "protein"
  ],
  "block_delete_msa": [
    "protein",
    "config"
  ],
  "nearest_neighbor_clusters": [
    "protein",
    "gap_agreement_weight"
  ],
  "unsorted_segment_sum": [
    "data",
    "segment_ids",
    "num_segments"
  ],
  "summarize_clusters": [
    "protein"
  ],
  "nearest_neighbor_clusters_v2": [
    "batch",
    "gap_agreement_weight"
  ],
  "make_msa_mask": [
    "protein"
  ],
  "pseudo_beta_fn": [
    "aatype",
    "all_atom_positions",
    "all_atom_mask"
  ],
  "make_pseudo_beta": [
    "protein",
    "prefix"
  ],
  "add_constant_field": [
    "protein",
    "key",
    "value"
  ],
  "shaped_categorical": [
    "probs",
    "epsilon"
  ],
  "make_hhblits_profile": [
    "protein"
  ],
  "make_msa_profile": [
    "batch"
  ],
  "make_hhblits_profile_v2": [
    "protein"
  ],
  "share_mask_by_entity": [
    "mask_position",
    "protein"
  ],
  "make_masked_msa": [
    "protein",
    "config",
    "replace_fraction",
    "gumbel_sample",
    "share_mask"
  ],
  "make_fixed_size": [
    "protein",
    "shape_schema",
    "msa_cluster_size",
    "extra_msa_size",
    "num_res",
    "num_templates"
  ],
  "make_target_feat": [
    "protein"
  ],
  "make_msa_feat": [
    "protein"
  ],
  "make_msa_feat_v2": [
    "batch"
  ],
  "make_extra_msa_feat": [
    "batch",
    "num_extra_msa"
  ],
  "select_feat": [
    "protein",
    "feature_list"
  ],
  "make_atom14_masks": [
    "protein"
  ],
  "make_atom14_masks_np": [
    "batch"
  ],
  "make_atom14_positions": [
    "protein"
  ],
  "atom37_to_frames": [
    "protein",
    "eps"
  ],
  "atom37_to_torsion_angles": [
    "protein",
    "prefix"
  ],
  "get_backbone_frames": [
    "protein"
  ],
  "get_chi_angles": [
    "protein"
  ],
  "crop_templates": [
    "protein",
    "max_templates",
    "subsample_templates"
  ],
  "crop_to_size_single": [
    "protein",
    "crop_size",
    "shape_schema",
    "seed"
  ],
  "crop_to_size_multimer": [
    "protein",
    "crop_size",
    "shape_schema",
    "seed",
    "spatial_crop_prob",
    "ca_ca_threshold"
  ],
  "get_single_crop_idx": [
    "num_res",
    "crop_size",
    "random_seed"
  ],
  "get_crop_sizes_each_chain": [
    "asym_len",
    "crop_size",
    "random_seed",
    "use_multinomial"
  ],
  "get_contiguous_crop_idx": [
    "protein",
    "crop_size",
    "random_seed",
    "use_multinomial"
  ],
  "get_spatial_crop_idx": [
    "protein",
    "crop_size",
    "random_seed",
    "ca_ca_threshold",
    "inf"
  ],
  "get_pairwise_distances": [
    "coords"
  ],
  "get_interface_candidates": [
    "ca_distances",
    "asym_id",
    "pair_mask",
    "ca_ca_threshold"
  ],
  "apply_crop_idx": [
    "protein",
    "shape_schema",
    "crop_idx"
  ],
  "MSA_GAP_IDX": [],
  "SEQUENCE_GAP_CUTOFF": [],
  "SEQUENCE_SIMILARITY_CUTOFF": [],
  "MSA_PAD_VALUES": [],
  "MSA_FEATURES": [],
  "SEQ_FEATURES": [],
  "CHAIN_FEATURES": [],
  "create_paired_features": [
    "chains"
  ],
  "pad_features": [
    "feature",
    "feature_name"
  ],
  "_make_msa_df": [
    "chain_features"
  ],
  "_create_species_dict": [
    "msa_df"
  ],
  "_match_rows_by_sequence_similarity": [
    "this_species_msa_dfs"
  ],
  "pair_sequences": [
    "examples"
  ],
  "reorder_paired_rows": [
    "all_paired_msa_rows_dict"
  ],
  "block_diag": [],
  "_correct_post_merged_feats": [
    "np_example",
    "np_chains_list",
    "pair_msa_sequences"
  ],
  "_pad_templates": [
    "chains",
    "max_templates"
  ],
  "_merge_features_from_multiple_chains": [
    "chains",
    "pair_msa_sequences"
  ],
  "_merge_homomers_dense_msa": [
    "chains"
  ],
  "_concatenate_paired_and_unpaired_features": [
    "example"
  ],
  "merge_chain_features": [
    "np_chains_list",
    "pair_msa_sequences",
    "max_templates"
  ],
  "deduplicate_unpaired_sequences": [
    "np_chains"
  ],
  "atom14_to_atom37": [
    "atom14",
    "batch"
  ],
  "build_template_angle_feat": [
    "template_feats",
    "v2_feature"
  ],
  "build_template_pair_feat": [
    "batch",
    "min_bin",
    "max_bin",
    "num_bins",
    "eps",
    "inf"
  ],
  "build_template_pair_feat_v2": [
    "batch",
    "min_bin",
    "max_bin",
    "num_bins",
    "multichain_mask_2d",
    "eps",
    "inf"
  ],
  "build_extra_msa_feat": [
    "batch"
  ],
  "predicted_lddt": [
    "plddt_logits"
  ],
  "compute_bin_values": [
    "breaks"
  ],
  "compute_predicted_aligned_error": [
    "bin_edges",
    "bin_probs"
  ],
  "predicted_aligned_error": [
    "pae_logits",
    "max_bin",
    "num_bins"
  ],
  "predicted_tm_score": [
    "pae_logits",
    "residue_weights",
    "max_bin",
    "num_bins",
    "eps",
    "asym_id",
    "interface"
  ],
  "Transition": {
    "__init__": [
      "self",
      "d_in",
      "n"
    ],
    "_transition": [
      "self",
      "x"
    ],
    "_chunk": [
      "self",
      "x",
      "chunk_size"
    ],
    "forward": [
      "self",
      "x",
      "chunk_size"
    ]
  },
  "OuterProductMean": {
    "__init__": [
      "self",
      "d_msa",
      "d_pair",
      "d_hid",
      "eps"
    ],
    "_opm": [
      "self",
      "a",
      "b"
    ],
    "_chunk": [
      "self",
      "a",
      "b",
      "chunk_size"
    ],
    "apply_alphafold_original_mode": [
      "self"
    ],
    "forward": [
      "self",
      "m",
      "mask",
      "chunk_size"
    ]
  },
  "residual": [
    "residual",
    "x",
    "training"
  ],
  "fused_bias_dropout_add": [
    "x",
    "bias",
    "residual",
    "dropmask",
    "prob"
  ],
  "fused_bias_dropout_add_inference": [
    "x",
    "bias",
    "residual"
  ],
  "bias_dropout_residual": [
    "module",
    "residual",
    "x",
    "dropout_shared_dim",
    "prob",
    "training"
  ],
  "fused_bias_gated_dropout_add": [
    "x",
    "bias",
    "g",
    "g_bias",
    "residual",
    "dropout_mask",
    "prob"
  ],
  "tri_mul_residual": [
    "module",
    "residual",
    "outputs",
    "dropout_shared_dim",
    "prob",
    "training",
    "block_size"
  ],
  "SimpleModuleList": {
    "__repr__": [
      "self"
    ]
  },
  "chunk_layer": [
    "layer",
    "inputs",
    "chunk_size",
    "num_batch_dims"
  ],
  "gen_attn_mask": [
    "mask",
    "neg_inf"
  ],
  "GlobalAttention": {
    "__init__": [
      "self",
      "input_dim",
      "head_dim",
      "num_heads",
      "inf",
      "eps"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "gen_msa_attn_mask": [
    "mask",
    "inf",
    "gen_col_mask"
  ],
  "MSAAttention": {
    "__init__": [
      "self",
      "d_in",
      "d_hid",
      "num_heads",
      "pair_bias",
      "d_pair"
    ],
    "_chunk": [
      "self",
      "m",
      "mask",
      "bias",
      "chunk_size"
    ],
    "_attn_chunk_forward": [
      "self",
      "m",
      "mask",
      "bias",
      "chunk_size"
    ],
    "_attn_forward": [
      "self",
      "m",
      "mask",
      "bias"
    ],
    "forward": [
      "self",
      "m",
      "z",
      "attn_mask",
      "chunk_size"
    ],
    "get_output_bias": [
      "self"
    ]
  },
  "MSARowAttentionWithPairBias": {
    "__init__": [
      "self",
      "d_msa",
      "d_pair",
      "d_hid",
      "num_heads"
    ]
  },
  "MSAColumnAttention": {
    "__init__": [
      "self",
      "d_msa",
      "d_hid",
      "num_heads"
    ],
    "forward": [
      "self",
      "m",
      "attn_mask",
      "chunk_size"
    ]
  },
  "MSAColumnGlobalAttention": {
    "__init__": [
      "self",
      "d_in",
      "d_hid",
      "num_heads",
      "inf",
      "eps"
    ],
    "_chunk": [
      "self",
      "m",
      "mask",
      "chunk_size"
    ],
    "_attn_forward": [
      "self",
      "m",
      "mask"
    ],
    "forward": [
      "self",
      "m",
      "mask",
      "chunk_size"
    ]
  },
  "gen_tri_attn_mask": [
    "mask",
    "inf"
  ],
  "TriangleAttention": {
    "__init__": [
      "self",
      "d_in",
      "d_hid",
      "num_heads",
      "starting"
    ],
    "_chunk": [
      "self",
      "x",
      "mask",
      "bias",
      "chunk_size"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask",
      "chunk_size"
    ],
    "get_output_bias": [
      "self"
    ]
  },
  "TriangleAttentionStarting": {
    "__init__": []
  },
  "TriangleAttentionEnding": {
    "__init__": []
  },
  "InputEmbedder": {
    "__init__": [
      "self",
      "tf_dim",
      "msa_dim",
      "d_pair",
      "d_msa",
      "relpos_k",
      "use_chain_relative",
      "max_relative_chain"
    ],
    "_relpos_indices": [
      "self",
      "res_id",
      "sym_id",
      "asym_id",
      "entity_id"
    ],
    "relpos_emb": [
      "self",
      "res_id",
      "sym_id",
      "asym_id",
      "entity_id",
      "num_sym"
    ],
    "forward": [
      "self",
      "tf",
      "msa"
    ]
  },
  "RecyclingEmbedder": {
    "__init__": [
      "self",
      "d_msa",
      "d_pair",
      "min_bin",
      "max_bin",
      "num_bins",
      "inf"
    ],
    "forward": [
      "self",
      "m",
      "z"
    ],
    "recyle_pos": [
      "self",
      "x"
    ]
  },
  "TemplateAngleEmbedder": {
    "__init__": [
      "self",
      "d_in",
      "d_out"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TemplatePairEmbedder": {
    "__init__": [
      "self",
      "d_in",
      "v2_d_in",
      "d_out",
      "d_pair",
      "v2_feature"
    ],
    "forward": [
      "self",
      "x",
      "z"
    ]
  },
  "ExtraMSAEmbedder": {
    "__init__": [
      "self",
      "d_in",
      "d_out"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ipa_point_weights_init_": [
    "weights"
  ],
  "torsion_angles_to_frames": [
    "frame",
    "alpha",
    "aatype",
    "default_frames"
  ],
  "frames_and_literature_positions_to_atom14_pos": [
    "frame",
    "aatype",
    "default_frames",
    "group_idx",
    "atom_mask",
    "lit_positions"
  ],
  "SideChainAngleResnetIteration": {
    "__init__": [
      "self",
      "d_hid"
    ],
    "forward": [
      "self",
      "s"
    ]
  },
  "SidechainAngleResnet": {
    "__init__": [
      "self",
      "d_in",
      "d_hid",
      "num_blocks",
      "num_angles"
    ],
    "forward": [
      "self",
      "s",
      "initial_s"
    ]
  },
  "InvariantPointAttention": {
    "__init__": [
      "self",
      "d_single",
      "d_pair",
      "d_hid",
      "num_heads",
      "num_qk_points",
      "num_v_points",
      "separate_kv",
      "bias",
      "eps"
    ],
    "forward": [
      "self",
      "s",
      "z",
      "f",
      "square_mask"
    ]
  },
  "BackboneUpdate": {
    "__init__": [
      "self",
      "d_single"
    ],
    "forward": [
      "self",
      "s"
    ]
  },
  "StructureModuleTransitionLayer": {
    "__init__": [
      "self",
      "c"
    ],
    "forward": [
      "self",
      "s"
    ]
  },
  "StructureModuleTransition": {
    "__init__": [
      "self",
      "c",
      "num_layers",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "s"
    ]
  },
  "StructureModule": {
    "__init__": [
      "self",
      "d_single",
      "d_pair",
      "d_ipa",
      "d_angle",
      "num_heads_ipa",
      "num_qk_points",
      "num_v_points",
      "dropout_rate",
      "num_blocks",
      "no_transition_layers",
      "num_resnet_blocks",
      "num_angles",
      "trans_scale_factor",
      "separate_kv",
      "ipa_bias",
      "epsilon",
      "inf"
    ],
    "forward": [
      "self",
      "s",
      "z",
      "aatype",
      "mask"
    ],
    "_init_residue_constants": [
      "self",
      "float_dtype",
      "device"
    ],
    "torsion_angles_to_frames": [
      "self",
      "frame",
      "alpha",
      "aatype"
    ],
    "frames_and_literature_positions_to_atom14_pos": [
      "self",
      "frame",
      "aatype"
    ]
  },
  "zero_translation": [
    "batch_dims",
    "dtype",
    "device",
    "requires_grad"
  ],
  "_QUAT_TO_ROT": [],
  "_QUAT_TO_ROT_tensor": [],
  "_QUAT_MULTIPLY": [],
  "_QUAT_MULTIPLY_BY_VEC": [],
  "_QUAT_MULTIPLY_BY_VEC_tensor": [],
  "Frame": {
    "__init__": [
      "self",
      "rotation",
      "translation"
    ],
    "identity": [
      "shape",
      "dtype",
      "device",
      "requires_grad"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__mul__": [
      "self",
      "right"
    ],
    "__rmul__": [
      "self",
      "left"
    ],
    "shape": [
      "self"
    ],
    "device": [
      "self"
    ],
    "get_rots": [
      "self"
    ],
    "get_trans": [
      "self"
    ],
    "compose": [
      "self",
      "other"
    ],
    "apply": [
      "self",
      "pts"
    ],
    "invert_apply": [
      "self",
      "pts"
    ],
    "invert": [
      "self"
    ],
    "map_tensor_fn": [
      "self",
      "fn"
    ],
    "to_tensor_4x4": [
      "self"
    ],
    "from_tensor_4x4": [
      "t"
    ],
    "from_3_points": [
      "p_neg_x_axis",
      "origin",
      "p_xy_plane",
      "eps"
    ],
    "unsqueeze": [
      "self",
      "dim"
    ],
    "cat": [
      "Ts",
      "dim"
    ],
    "apply_rot_fn": [
      "self",
      "fn"
    ],
    "apply_trans_fn": [
      "self",
      "fn"
    ],
    "scale_translation": [
      "self",
      "trans_scale_factor"
    ],
    "stop_rot_gradient": [
      "self"
    ],
    "make_transform_from_reference": [
      "n_xyz",
      "ca_xyz",
      "c_xyz",
      "eps"
    ],
    "cuda": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "type": [
      "self",
      "dtype"
    ]
  },
  "Quaternion": {
    "__init__": [
      "self",
      "quaternion",
      "translation"
    ],
    "identity": [
      "shape",
      "dtype",
      "device",
      "requires_grad"
    ],
    "get_quats": [
      "self"
    ],
    "get_trans": [
      "self"
    ],
    "get_rot_mats": [
      "self"
    ],
    "quat_to_rot": [
      "normalized_quat"
    ],
    "normalize_quat": [
      "quats"
    ],
    "quat_multiply_by_vec": [
      "quat",
      "vec"
    ],
    "compose_q_update_vec": [
      "self",
      "q_update_vec",
      "normalize_quats"
    ],
    "compose_update_vec": [
      "self",
      "update_vec",
      "pre_rot_mat"
    ],
    "stop_rot_gradient": [
      "self"
    ]
  },
  "TriangleMultiplication": {
    "__init__": [
      "self",
      "d_pair",
      "d_hid",
      "outgoing"
    ],
    "_chunk_2d": [
      "self",
      "z",
      "mask",
      "block_size"
    ],
    "forward": [
      "self",
      "z",
      "mask",
      "block_size"
    ],
    "get_output_bias": [
      "self"
    ]
  },
  "TriangleMultiplicationOutgoing": {
    "__init__": []
  },
  "TriangleMultiplicationIncoming": {
    "__init__": []
  },
  "EvoformerIteration": {
    "__init__": [
      "self",
      "d_msa",
      "d_pair",
      "d_hid_msa_att",
      "d_hid_opm",
      "d_hid_mul",
      "d_hid_pair_att",
      "num_heads_msa",
      "num_heads_pair",
      "transition_n",
      "msa_dropout",
      "pair_dropout",
      "outer_product_mean_first",
      "inf",
      "eps",
      "_is_extra_msa_stack"
    ],
    "forward": [
      "self",
      "m",
      "z",
      "msa_mask",
      "pair_mask",
      "msa_row_attn_mask",
      "msa_col_attn_mask",
      "tri_start_attn_mask",
      "tri_end_attn_mask",
      "chunk_size",
      "block_size"
    ]
  },
  "EvoformerStack": {
    "__init__": [
      "self",
      "d_msa",
      "d_pair",
      "d_hid_msa_att",
      "d_hid_opm",
      "d_hid_mul",
      "d_hid_pair_att",
      "d_single",
      "num_heads_msa",
      "num_heads_pair",
      "num_blocks",
      "transition_n",
      "msa_dropout",
      "pair_dropout",
      "outer_product_mean_first",
      "inf",
      "eps",
      "_is_extra_msa_stack"
    ],
    "forward": [
      "self",
      "m",
      "z",
      "msa_mask",
      "pair_mask",
      "msa_row_attn_mask",
      "msa_col_attn_mask",
      "tri_start_attn_mask",
      "tri_end_attn_mask",
      "chunk_size",
      "block_size"
    ]
  },
  "ExtraMSAStack": {
    "__init__": [
      "self",
      "d_msa",
      "d_pair",
      "d_hid_msa_att",
      "d_hid_opm",
      "d_hid_mul",
      "d_hid_pair_att",
      "num_heads_msa",
      "num_heads_pair",
      "num_blocks",
      "transition_n",
      "msa_dropout",
      "pair_dropout",
      "outer_product_mean_first",
      "inf",
      "eps"
    ],
    "forward": [
      "self",
      "m",
      "z",
      "msa_mask",
      "pair_mask",
      "msa_row_attn_mask",
      "msa_col_attn_mask",
      "tri_start_attn_mask",
      "tri_end_attn_mask",
      "chunk_size",
      "block_size"
    ]
  },
  "TemplatePointwiseAttention": {
    "__init__": [
      "self",
      "d_template",
      "d_pair",
      "d_hid",
      "num_heads",
      "inf"
    ],
    "_chunk": [
      "self",
      "z",
      "t",
      "mask",
      "chunk_size"
    ],
    "forward": [
      "self",
      "t",
      "z",
      "template_mask",
      "chunk_size"
    ]
  },
  "TemplateProjection": {
    "__init__": [
      "self",
      "d_template",
      "d_pair"
    ],
    "forward": [
      "self",
      "t",
      "z"
    ]
  },
  "TemplatePairStackBlock": {
    "__init__": [
      "self",
      "d_template",
      "d_hid_tri_att",
      "d_hid_tri_mul",
      "num_heads",
      "pair_transition_n",
      "dropout_rate",
      "tri_attn_first",
      "inf"
    ],
    "forward": [
      "self",
      "s",
      "mask",
      "tri_start_attn_mask",
      "tri_end_attn_mask",
      "chunk_size",
      "block_size"
    ]
  },
  "TemplatePairStack": {
    "__init__": [
      "self",
      "d_template",
      "d_hid_tri_att",
      "d_hid_tri_mul",
      "num_blocks",
      "num_heads",
      "pair_transition_n",
      "dropout_rate",
      "tri_attn_first",
      "inf"
    ],
    "forward": [
      "self",
      "single_templates",
      "mask",
      "tri_start_attn_mask",
      "tri_end_attn_mask",
      "templ_dim",
      "chunk_size",
      "block_size",
      "return_mean"
    ]
  },
  "AuxiliaryHeads": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "outputs"
    ]
  },
  "PredictedLDDTHead": {
    "__init__": [
      "self",
      "num_bins",
      "d_in",
      "d_hid"
    ],
    "forward": [
      "self",
      "s"
    ]
  },
  "EnhancedHeadBase": {
    "__init__": [
      "self",
      "d_in",
      "d_out",
      "disable_enhance_head"
    ],
    "apply_alphafold_original_mode": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DistogramHead": {
    "__init__": [
      "self",
      "d_pair",
      "num_bins",
      "disable_enhance_head"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PredictedAlignedErrorHead": {
    "__init__": [
      "self",
      "d_pair",
      "num_bins",
      "disable_enhance_head"
    ]
  },
  "MaskedMSAHead": {
    "__init__": [
      "self",
      "d_msa",
      "d_out",
      "disable_enhance_head"
    ]
  },
  "ExperimentallyResolvedHead": {
    "__init__": [
      "self",
      "d_single",
      "d_out",
      "disable_enhance_head"
    ]
  },
  "AlphaFold": {
    "__init__": [
      "self",
      "config"
    ],
    "__make_input_float__": [
      "self"
    ],
    "half": [
      "self"
    ],
    "bfloat16": [
      "self"
    ],
    "alphafold_original_mode": [
      "self"
    ],
    "inference_mode": [
      "self"
    ],
    "__convert_input_dtype__": [
      "self",
      "batch"
    ],
    "embed_templates_pair_core": [
      "self",
      "batch",
      "z",
      "pair_mask",
      "tri_start_attn_mask",
      "tri_end_attn_mask",
      "templ_dim",
      "multichain_mask_2d"
    ],
    "embed_templates_pair": [
      "self",
      "batch",
      "z",
      "pair_mask",
      "tri_start_attn_mask",
      "tri_end_attn_mask",
      "templ_dim"
    ],
    "embed_templates_angle": [
      "self",
      "batch"
    ],
    "iteration_evoformer": [
      "self",
      "feats",
      "m_1_prev",
      "z_prev",
      "x_prev"
    ],
    "iteration_evoformer_structure_module": [
      "self",
      "batch",
      "m_1_prev",
      "z_prev",
      "x_prev",
      "cycle_no",
      "num_recycling",
      "num_ensembles"
    ],
    "forward": [
      "self",
      "batch"
    ]
  },
  "custom_to_pil": [
    "x"
  ],
  "load_vqgan": [
    "config",
    "ckpt_path",
    "is_gumbel"
  ],
  "build_clip_model": [
    "model_path"
  ],
  "build_clip_transform": [
    "n_px"
  ],
  "OfaForTextToImageSynthesis": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "clip_tokenize": [
      "self",
      "texts",
      "context_length",
      "truncate"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "NoiseScheduleVP": {
    "__init__": [
      "self",
      "schedule",
      "betas",
      "alphas_cumprod",
      "continuous_beta_0",
      "continuous_beta_1"
    ],
    "marginal_log_mean_coeff": [
      "self",
      "t"
    ],
    "marginal_alpha": [
      "self",
      "t"
    ],
    "marginal_std": [
      "self",
      "t"
    ],
    "marginal_lambda": [
      "self",
      "t"
    ],
    "inverse_lambda": [
      "self",
      "lamb"
    ]
  },
  "model_wrapper": [
    "model",
    "noise_schedule",
    "model_type",
    "model_kwargs",
    "guidance_type",
    "condition",
    "unconditional_condition",
    "guidance_scale",
    "classifier_fn",
    "classifier_kwargs"
  ],
  "model_wrapper_guided_diffusion": [
    "model",
    "noise_schedule",
    "var_type",
    "mean_type",
    "model_kwargs",
    "clamp",
    "percentile",
    "rescale_timesteps",
    "num_timesteps",
    "guide_scale",
    "condition_fn"
  ],
  "DPM_Solver": {
    "__init__": [
      "self",
      "model_fn",
      "noise_schedule",
      "predict_x0",
      "thresholding",
      "max_val"
    ],
    "noise_prediction_fn": [
      "self",
      "x",
      "t"
    ],
    "data_prediction_fn": [
      "self",
      "x",
      "t"
    ],
    "model_fn": [
      "self",
      "x",
      "t"
    ],
    "get_time_steps": [
      "self",
      "skip_type",
      "t_T",
      "t_0",
      "N",
      "device"
    ],
    "get_orders_and_timesteps_for_singlestep_solver": [
      "self",
      "steps",
      "order",
      "skip_type",
      "t_T",
      "t_0",
      "device"
    ],
    "denoise_to_zero_fn": [
      "self",
      "x",
      "s"
    ],
    "dpm_solver_first_update": [
      "self",
      "x",
      "s",
      "t",
      "model_s",
      "return_intermediate"
    ],
    "singlestep_dpm_solver_second_update": [
      "self",
      "x",
      "s",
      "t",
      "r1",
      "model_s",
      "return_intermediate",
      "solver_type"
    ],
    "singlestep_dpm_solver_third_update": [
      "self",
      "x",
      "s",
      "t",
      "r1",
      "r2",
      "model_s",
      "model_s1",
      "return_intermediate",
      "solver_type"
    ],
    "multistep_dpm_solver_second_update": [
      "self",
      "x",
      "model_prev_list",
      "t_prev_list",
      "t",
      "solver_type"
    ],
    "multistep_dpm_solver_third_update": [
      "self",
      "x",
      "model_prev_list",
      "t_prev_list",
      "t",
      "solver_type"
    ],
    "singlestep_dpm_solver_update": [
      "self",
      "x",
      "s",
      "t",
      "order",
      "return_intermediate",
      "solver_type",
      "r1",
      "r2"
    ],
    "multistep_dpm_solver_update": [
      "self",
      "x",
      "model_prev_list",
      "t_prev_list",
      "t",
      "order",
      "solver_type"
    ],
    "dpm_solver_adaptive": [
      "self",
      "x",
      "order",
      "t_T",
      "t_0",
      "h_init",
      "atol",
      "rtol",
      "theta",
      "t_err",
      "solver_type"
    ],
    "sample": [
      "self",
      "x",
      "steps",
      "t_start",
      "t_end",
      "order",
      "skip_type",
      "method",
      "lower_order_final",
      "denoise_to_zero",
      "solver_type",
      "atol",
      "rtol"
    ]
  },
  "interpolate_fn": [
    "x",
    "xp",
    "yp"
  ],
  "expand_dims": [
    "v",
    "dims"
  ],
  "OfaForAllTasks": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "inference": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "input"
    ],
    "_text_gen_inference": [
      "self",
      "input"
    ],
    "_visual_grounding_inference": [
      "self",
      "input"
    ],
    "_traverse_inference": [
      "self",
      "input"
    ],
    "build_trie": [
      "self"
    ],
    "load_ans2label": [
      "self"
    ],
    "save_pretrained": [
      "self",
      "target_folder",
      "save_checkpoint_names",
      "save_function",
      "config"
    ],
    "detokenizer": [
      "self",
      "text"
    ]
  },
  "MPlugForAllTasks": {
    "__init__": [
      "self",
      "model_dir",
      "task"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "HiTeAForAllTasks": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "clip_tokenize": [
    "tokenizer",
    "texts",
    "context_length",
    "truncate"
  ],
  "GEMMForMultiModalEmbedding": {
    "__init__": [
      "self",
      "model_dir",
      "device_id"
    ],
    "parse_image": [
      "self",
      "input_img"
    ],
    "parse_text": [
      "self",
      "text_str"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "GEVL": {
    "__init__": [
      "self",
      "embed_dim",
      "image_resolution",
      "vision_layers",
      "vision_width",
      "vision_patch_size",
      "context_length",
      "vocab_size",
      "transformer_width",
      "transformer_heads",
      "transformer_layers",
      "use_gc",
      "tokenizer"
    ],
    "build_attention_mask": [
      "self",
      "seq_length",
      "prefix_length"
    ],
    "dtype": [
      "self"
    ],
    "encode_image": [
      "self",
      "image",
      "return_tokens"
    ],
    "encode_text": [
      "self",
      "text",
      "return_tokens"
    ],
    "image_to_text": [
      "self",
      "image"
    ]
  },
  "GEMMModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "tokenize": [
      "self",
      "text_str"
    ],
    "parse_feat": [
      "self",
      "feat"
    ],
    "forward": [
      "self",
      "image",
      "text",
      "captioning"
    ]
  },
  "MMSpeechConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "max_position_embeddings",
      "encoder_layers",
      "encoder_ffn_dim",
      "encoder_attention_heads",
      "decoder_layers",
      "decoder_ffn_dim",
      "decoder_attention_heads",
      "encoder_layerdrop",
      "decoder_layerdrop",
      "use_cache",
      "is_encoder_decoder",
      "activation_function",
      "d_model",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "init_std",
      "classifier_dropout",
      "scale_embedding",
      "pad_token_id",
      "bos_token_id",
      "decoder_start_token_id",
      "eos_token_id",
      "forced_eos_token_id",
      "encoder_normalize_before",
      "decoder_normalize_before",
      "normformer",
      "encoder_drop_path_rate",
      "decoder_drop_path_rate",
      "layernorm_embedding",
      "patch_layernorm_embedding",
      "resnet_type",
      "resnet_model_path",
      "resnet_drop_path_rate",
      "token_bucket_size",
      "image_bucket_size",
      "add_type_embedding",
      "share_decoder_input_output_embed",
      "attn_scale_factor",
      "code_layernorm_embedding",
      "code_image_size",
      "entangle_position_embedding",
      "interpolate_position",
      "orig_patch_image_size",
      "share_attn_bias",
      "use_image_feature",
      "disable_entangle",
      "use_ofasys",
      "vit_type",
      "vit_drop_path_rate",
      "use_gamma_feature",
      "gamma",
      "exclude_mlp",
      "temperature_init_value",
      "remove_decoder_type_embedding",
      "mlp_dim",
      "required_seq_len_multiple",
      "encoder_pos_conv_depth",
      "encoder_conv_pos",
      "encoder_conv_pos_groups",
      "encoder_max_positions",
      "phone_vocab_size",
      "audio_mask_prob",
      "audio_mask_selection",
      "audio_mask_other",
      "audio_mask_length",
      "audio_no_mask_overlap",
      "audio_mask_min_space",
      "audio_mask_channel_prob",
      "audio_mask_channel_before",
      "audio_mask_channel_selection",
      "audio_mask_channel_other",
      "audio_mask_channel_length",
      "audio_no_mask_channel_overlap",
      "audio_mask_channel_min_space",
      "encoder_dropout_input",
      "encoder_dropout_features",
      "phone_dict_size"
    ]
  },
  "_CHECKPOINT_FOR_DOC": [],
  "_CONFIG_FOR_DOC": [],
  "_TOKENIZER_FOR_DOC": [],
  "TORCH_MESH_GRID_WARNING_VERSION": [],
  "DEFAULT_MAX_SOURCE_POSITIONS": [],
  "DEFAULT_MAX_TARGET_POSITIONS": [],
  "DEFAULT_MIN_PARAMS_TO_WRAP": [],
  "OFA_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "MMSpeechPreTrainedModel": {
    "config_class": [],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ]
  },
  "MMSpeechEncoderOutput": {},
  "MMSpeechModelOutput": {},
  "MMSPEECH_START_DOCSTRING": [],
  "MMSPEECH_GENERATION_EXAMPLE": [],
  "MMSPEECH_INPUTS_DOCSTRING": [],
  "Conv2dSubsampling4": {
    "__init__": [
      "self",
      "idim",
      "odim"
    ],
    "get_out_seq_lens_tensor": [
      "self",
      "in_seq_lens_tensor"
    ],
    "forward": [
      "self",
      "x",
      "x_length"
    ]
  },
  "MMSpeechEncoder": {
    "__init__": [
      "self",
      "cfg",
      "embed_tokens"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "apply_mask": [
      "self",
      "x",
      "padding_mask",
      "mask_indices",
      "mask_channel_indices",
      "mask_prob"
    ],
    "_get_feat_extract_output_lengths": [
      "self",
      "input_lengths"
    ],
    "forward": [
      "self",
      "fbank",
      "fbank_length",
      "fbank_masks",
      "phone_items",
      "phone_masks",
      "features_only",
      "mask",
      "mask_prob",
      "layer",
      "output_hidden_states"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ],
    "compute_var": [
      "y"
    ]
  },
  "MMSpeechModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_encoder_normalized_probs": [
      "self",
      "net_output",
      "log_probs"
    ],
    "forward": [
      "self",
      "input_ids",
      "patch_images",
      "patch_images_2",
      "patch_masks",
      "token_embeddings",
      "sample_patch_num",
      "fbank",
      "fbank_length",
      "fbank_masks",
      "phone_items",
      "phone_masks",
      "features_only",
      "mask",
      "mask_prob",
      "layer",
      "decoder_input_ids",
      "code_masks",
      "attention_mask",
      "encoder_outputs",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ]
  },
  "VOCAB_FILES_NAMES": [],
  "PRETRAINED_VOCAB_FILES_MAP": [],
  "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES": [],
  "VOCAB_FILES_NAMES_ZH": [],
  "PRETRAINED_VOCAB_FILES_MAP_ZH": [],
  "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES_ZH": [],
  "PRETRAINED_INIT_CONFIGURATION_ZH": [],
  "OFATokenizer": {
    "vocab_files_names": [],
    "pretrained_vocab_files_map": [],
    "max_model_input_sizes": []
  },
  "OFATokenizerZH": {
    "vocab_files_names": [],
    "pretrained_vocab_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "do_basic_tokenize",
      "never_split",
      "bos_token",
      "eos_token",
      "sep_token",
      "cls_token",
      "unk_token",
      "pad_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "do_lower_case": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ]
  },
  "make_token_bucket_position": [
    "bucket_size",
    "max_position"
  ],
  "make_image_bucket_position": [
    "bucket_size",
    "num_relative_distance"
  ],
  "new_arange": [
    "x"
  ],
  "shift_tokens_right": [
    "input_ids",
    "pad_token_id",
    "decoder_start_token_id"
  ],
  "_make_causal_mask": [
    "input_ids_shape",
    "dtype",
    "past_key_values_length"
  ],
  "_expand_mask": [
    "mask",
    "dtype",
    "tgt_len"
  ],
  "LayerDropModuleList": {
    "__init__": [
      "self",
      "p",
      "modules"
    ],
    "__iter__": [
      "self"
    ]
  },
  "OFAAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "dropout",
      "is_decoder",
      "bias",
      "scale_heads",
      "scale_factor"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states",
      "key_value_states",
      "past_key_value",
      "attention_mask",
      "output_attentions",
      "attn_bias"
    ]
  },
  "OFAEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "drop_path_rate"
    ],
    "residual_connection": [
      "self",
      "x",
      "residual"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions",
      "attn_bias"
    ]
  },
  "OFADecoderLayer": {
    "__init__": [
      "self",
      "config",
      "drop_path_rate"
    ],
    "residual_connection": [
      "self",
      "x",
      "residual"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "use_cache",
      "self_attn_bias",
      "cross_attn_bias"
    ]
  },
  "OFAPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ]
  },
  "OFAEncoderOutput": {},
  "OFA_START_DOCSTRING": [],
  "OFA_GENERATION_EXAMPLE": [],
  "OFA_INPUTS_DOCSTRING": [],
  "OFAEncoder": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_rel_pos_bias": [
      "self",
      "x",
      "idx"
    ],
    "get_image_rel_pos_bias": [
      "self",
      "image_position_ids",
      "idx"
    ],
    "get_patch_images_info": [
      "self",
      "patch_images",
      "sample_patch_num",
      "device"
    ],
    "forward_embedding": [
      "self",
      "input_ids",
      "image_embed",
      "image_embed_2",
      "token_embedding",
      "pos_embed",
      "image_pos_embed",
      "image_pos_embed_2"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ],
    "forward": [
      "self",
      "input_ids",
      "patch_images",
      "patch_images_2",
      "patch_masks",
      "output_attentions",
      "output_hidden_states",
      "token_embeddings",
      "sample_patch_num"
    ]
  },
  "OFADecoder": {
    "__init__": [
      "self",
      "config",
      "embed_tokens",
      "output_projection"
    ],
    "build_output_projection": [
      "self",
      "config"
    ],
    "get_rel_pos_bias": [
      "self",
      "x",
      "idx"
    ],
    "get_image_rel_pos_bias": [
      "self",
      "x",
      "idx"
    ],
    "get_pos_info": [
      "self",
      "tgt_pos_embed",
      "src_pos_embed",
      "use_image"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prepare_decoder_attention_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "dtype",
      "past_key_values_length"
    ],
    "max_positions": [
      "self"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "get_normalized_probs_scriptable": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "reorder_incremental_state_scripting": [
      "self",
      "past_key_values",
      "new_order"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "code_masks",
      "src_pos_embed",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states"
    ]
  },
  "OFAModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "max_decoder_positions": [
      "self"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "get_normalized_probs_scriptable": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "forward": [
      "self",
      "input_ids",
      "patch_images",
      "patch_images_2",
      "patch_masks",
      "token_embeddings",
      "sample_patch_num",
      "decoder_input_ids",
      "code_masks",
      "attention_mask",
      "encoder_outputs",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "decoder_input_ids",
      "past",
      "attention_mask",
      "code_masks",
      "use_cache",
      "encoder_outputs"
    ],
    "prepare_decoder_input_ids_from_labels": [
      "self",
      "labels"
    ],
    "_prepare_encoder_decoder_kwargs_for_generation": [
      "self",
      "inputs_tensor",
      "model_kwargs",
      "model_input_name"
    ],
    "_reorder_cache": [
      "past",
      "beam_idx"
    ],
    "_expand_inputs_for_generation": [
      "input_ids",
      "expand_size",
      "is_encoder_decoder",
      "attention_mask",
      "encoder_outputs"
    ]
  },
  "OFATokenizerFast": {
    "vocab_files_names": [],
    "pretrained_vocab_files_map": [],
    "max_model_input_sizes": [],
    "slow_tokenizer_class": []
  },
  "OFATokenizerZHFast": {
    "vocab_files_names": [],
    "pretrained_vocab_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "slow_tokenizer_class": [],
    "__init__": [
      "self",
      "vocab_file",
      "tokenizer_file",
      "do_lower_case",
      "bos_token",
      "eos_token",
      "sep_token",
      "cls_token",
      "unk_token",
      "pad_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ]
  },
  "OFA_PRETRAINED_CONFIG_ARCHIVE_MAP": [],
  "OFAConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "max_position_embeddings",
      "encoder_layers",
      "encoder_ffn_dim",
      "encoder_attention_heads",
      "decoder_layers",
      "decoder_ffn_dim",
      "decoder_attention_heads",
      "encoder_layerdrop",
      "decoder_layerdrop",
      "use_cache",
      "is_encoder_decoder",
      "activation_function",
      "d_model",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "init_std",
      "classifier_dropout",
      "scale_embedding",
      "pad_token_id",
      "bos_token_id",
      "decoder_start_token_id",
      "eos_token_id",
      "forced_eos_token_id",
      "encoder_normalize_before",
      "decoder_normalize_before",
      "normformer",
      "encoder_drop_path_rate",
      "decoder_drop_path_rate",
      "layernorm_embedding",
      "patch_layernorm_embedding",
      "resnet_type",
      "resnet_model_path",
      "resnet_drop_path_rate",
      "token_bucket_size",
      "image_bucket_size",
      "add_type_embedding",
      "share_decoder_input_output_embed",
      "attn_scale_factor",
      "code_layernorm_embedding",
      "code_image_size",
      "entangle_position_embedding",
      "interpolate_position",
      "orig_patch_image_size",
      "share_attn_bias",
      "use_image_feature",
      "disable_entangle",
      "use_ofasys",
      "vit_type",
      "vit_drop_path_rate",
      "use_gamma_feature",
      "gamma",
      "exclude_mlp",
      "temperature_init_value",
      "remove_decoder_type_embedding",
      "mlp_dim"
    ]
  },
  "vit_large_336": [
    "drop_path_rate"
  ],
  "vit_huge": [
    "drop_path_rate"
  ],
  "expand_mask": [
    "mask",
    "dtype",
    "tgt_len"
  ],
  "SequenceGenerator": {
    "__init__": [
      "self",
      "tokenizer",
      "beam_size",
      "max_len_a",
      "max_len_b",
      "max_len",
      "min_len",
      "normalize_scores",
      "len_penalty",
      "unk_penalty",
      "temperature",
      "match_source_len",
      "no_repeat_ngram_size",
      "search_strategy",
      "eos",
      "symbols_to_strip_from_output",
      "lm_model",
      "lm_weight",
      "constraint_trie",
      "constraint_range",
      "gen_code",
      "gen_box",
      "ignore_eos",
      "zero_shot"
    ],
    "forward": [
      "self",
      "sample",
      "prefix_tokens",
      "bos_token"
    ],
    "generate": [
      "self",
      "models",
      "sample"
    ],
    "_generate": [
      "self",
      "models",
      "sample",
      "prefix_tokens",
      "constraints",
      "bos_token"
    ],
    "_prefix_tokens": [
      "self",
      "step",
      "lprobs",
      "scores",
      "tokens",
      "prefix_tokens",
      "beam_size"
    ],
    "replicate_first_beam": [
      "self",
      "tensor",
      "mask",
      "beam_size"
    ],
    "finalize_hypos": [
      "self",
      "step",
      "bbsz_idx",
      "eos_scores",
      "tokens",
      "scores",
      "finalized",
      "finished",
      "beam_size",
      "attn",
      "src_lengths",
      "max_len"
    ],
    "is_finished": [
      "self",
      "step",
      "unfin_idx",
      "max_len",
      "finalized_sent_len",
      "beam_size"
    ]
  },
  "EnsembleModel": {
    "__init__": [
      "self",
      "models"
    ],
    "forward": [
      "self"
    ],
    "has_encoder": [
      "self"
    ],
    "has_incremental_states": [
      "self"
    ],
    "max_decoder_positions": [
      "self"
    ],
    "forward_encoder": [
      "self",
      "net_input"
    ],
    "forward_decoder": [
      "self",
      "tokens",
      "encoder_outs",
      "incremental_states",
      "temperature",
      "constraint_trie",
      "constraint_start",
      "constraint_end",
      "gen_code",
      "zero_shot",
      "prefix_tokens"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_outs",
      "new_order"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_states",
      "new_order"
    ]
  },
  "Search": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ],
    "set_src_lengths": [
      "self",
      "src_lengths"
    ],
    "init_constraints": [
      "self",
      "batch_constraints",
      "beam_size"
    ],
    "prune_sentences": [
      "self",
      "batch_idxs"
    ],
    "update_constraints": [
      "self",
      "active_hypos"
    ]
  },
  "BeamSearch": {
    "__init__": [
      "self",
      "tgt_dict"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ]
  },
  "PrefixConstrainedBeamSearch": {
    "__init__": [
      "self",
      "tgt_dict",
      "prefix_allowed_tokens_fn"
    ],
    "apply_mask": [
      "self",
      "x",
      "prev_output_tokens",
      "original_batch_idxs"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ]
  },
  "LexicallyConstrainedBeamSearch": {
    "__init__": [
      "self",
      "tokenizer",
      "representation"
    ],
    "init_constraints": [
      "self",
      "batch_constraints",
      "beam_size"
    ],
    "prune_sentences": [
      "self",
      "batch_idxs"
    ],
    "update_constraints": [
      "self",
      "active_hypos"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ],
    "step_sentence": [
      "self",
      "step",
      "sentno",
      "lprobs",
      "constraint_states",
      "beams_buf",
      "indices_buf",
      "scores_buf"
    ]
  },
  "LengthConstrainedBeamSearch": {
    "__init__": [
      "self",
      "tgt_dict",
      "min_len_a",
      "min_len_b",
      "max_len_a",
      "max_len_b"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ]
  },
  "DiverseBeamSearch": {
    "__init__": [
      "self",
      "tgt_dict",
      "num_groups",
      "diversity_strength"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ]
  },
  "Sampling": {
    "__init__": [
      "self",
      "tgt_dict",
      "sampling_topk",
      "sampling_topp"
    ],
    "_sample_topp": [
      "self",
      "lprobs"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ]
  },
  "DiverseSiblingsSearch": {
    "__init__": [
      "self",
      "tgt_dict",
      "diversity_rate"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ]
  },
  "MANIFOLD_PATH_SEP": [],
  "apply_to_sample": [
    "f",
    "sample"
  ],
  "strip_pad": [
    "tensor",
    "pad"
  ],
  "get_token_to_word_mapping": [
    "tokens",
    "exclude_list"
  ],
  "extract_hard_alignment": [
    "attn",
    "src_sent",
    "tgt_sent",
    "pad",
    "eos"
  ],
  "log_softmax": [
    "x",
    "dim",
    "onnx_trace"
  ],
  "extract_soft_alignment": [
    "attn",
    "src_sent",
    "tgt_sent",
    "pad",
    "eos"
  ],
  "FairseqIncrementalState": {
    "__init__": [
      "self"
    ],
    "init_incremental_state": [
      "self"
    ],
    "_get_full_incremental_state_key": [
      "self",
      "key"
    ],
    "get_incremental_state": [
      "self",
      "incremental_state",
      "key"
    ],
    "set_incremental_state": [
      "self",
      "incremental_state",
      "key",
      "value"
    ]
  },
  "with_incremental_state": [
    "cls"
  ],
  "ConstraintState": {
    "__init__": [
      "self"
    ]
  },
  "pack_constraints": [
    "batch_constraints"
  ],
  "unpack_constraints": [
    "constraint_tensor"
  ],
  "ConstraintNode": {
    "__init__": [
      "self",
      "token",
      "parent"
    ],
    "id": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "next_tokens": [
      "self"
    ],
    "create": [
      "constraints"
    ],
    "print_graph": [
      "node"
    ],
    "token_counts": [
      "self"
    ],
    "tokens": [
      "self"
    ],
    "add_sequence": [
      "self",
      "sequence"
    ]
  },
  "UnorderedConstraintState": {
    "__init__": [
      "self",
      "node",
      "copy_from"
    ],
    "create": [
      "constraint_tensor"
    ],
    "__str__": [
      "self"
    ],
    "__copy__": [
      "self"
    ],
    "copy": [
      "self"
    ],
    "name": [
      "self"
    ],
    "is_root": [
      "self"
    ],
    "bank": [
      "self"
    ],
    "num_completed": [
      "self"
    ],
    "finished": [
      "self"
    ],
    "token_counts": [
      "self"
    ],
    "tokens": [
      "self"
    ],
    "num_constraint_tokens": [
      "self"
    ],
    "next_tokens": [
      "self"
    ],
    "advance": [
      "self",
      "token"
    ]
  },
  "ConstraintSequence": {
    "__init__": [
      "self",
      "sequences"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__len__": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "OrderedConstraintState": {
    "__init__": [
      "self",
      "sequence",
      "state"
    ],
    "create": [
      "constraint_tensor"
    ],
    "__str__": [
      "self"
    ],
    "__copy__": [
      "self"
    ],
    "copy": [
      "self"
    ],
    "num_completed": [
      "self"
    ],
    "is_root": [
      "self"
    ],
    "name": [
      "self"
    ],
    "bank": [
      "self"
    ],
    "finished": [
      "self"
    ],
    "token_counts": [
      "self"
    ],
    "tokens": [
      "self"
    ],
    "num_constraint_tokens": [
      "self"
    ],
    "next_tokens": [
      "self"
    ],
    "advance": [
      "self",
      "token"
    ]
  },
  "is_cuda_extension_usable": [],
  "NGramRepeatBlock": {
    "__init__": [
      "self",
      "no_repeat_ngram_size",
      "use_extension"
    ],
    "reset_parameters": [
      "self"
    ],
    "call_cuda_extension": [
      "self",
      "tokens",
      "lprobs",
      "bsz",
      "beam_size",
      "step"
    ],
    "forward": [
      "self",
      "tokens",
      "lprobs",
      "bsz",
      "beam_size",
      "step"
    ],
    "_no_repeat_ngram": [
      "self",
      "tokens",
      "lprobs",
      "bsz",
      "beam_size",
      "step"
    ],
    "calculate_banned_tokens": [
      "tokens",
      "step",
      "gen_ngrams",
      "no_repeat_ngram_size",
      "bbsz_idx"
    ],
    "transpose_list": [
      "l"
    ]
  },
  "MultiheadAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "kdim",
      "vdim",
      "dropout",
      "bias",
      "add_bias_kv",
      "add_zero_attn",
      "self_attention",
      "encoder_decoder_attention",
      "q_noise",
      "qn_block_size"
    ],
    "prepare_for_onnx_export_": [
      "self"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask",
      "incremental_state",
      "need_weights",
      "static_kv",
      "attn_mask",
      "before_softmax",
      "need_head_weights"
    ],
    "_append_prev_key_padding_mask": [
      "key_padding_mask",
      "prev_key_padding_mask",
      "batch_size",
      "src_len",
      "static_kv"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "_get_input_buffer": [
      "self",
      "incremental_state"
    ],
    "_set_input_buffer": [
      "self",
      "incremental_state",
      "buffer"
    ],
    "apply_sparse_mask": [
      "self",
      "attn_weights",
      "tgt_len",
      "src_len",
      "bsz"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "CLIPTokenizer": {
    "__init__": [
      "self",
      "bpe_path",
      "length"
    ],
    "__call__": [
      "self",
      "sequence"
    ],
    "_tokenizer": [
      "self",
      "text"
    ]
  },
  "XGLMTokenizer": {
    "__init__": [
      "self",
      "model_dir",
      "length"
    ],
    "__call__": [
      "self",
      "sequence"
    ]
  },
  "make_diffusion": [
    "schedule",
    "num_timesteps",
    "init_beta",
    "last_beta",
    "mean_type",
    "var_type"
  ],
  "UnCLIP": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self"
    ],
    "synthesis": [
      "self",
      "text",
      "tokenizer",
      "batch_size",
      "timesteps_prior",
      "timesteps_64",
      "timesteps_256",
      "timesteps_1024",
      "guide_prior",
      "guide_64",
      "guide_256",
      "guide_1024",
      "eta_prior",
      "eta_64",
      "eta_256",
      "eta_1024",
      "solver"
    ]
  },
  "MultiStageDiffusionForTextToImageSynthesis": {
    "__init__": [
      "self",
      "model_dir",
      "device"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Upsampler256": {
    "__init__": [
      "self",
      "in_dim",
      "dim",
      "y_dim",
      "context_dim",
      "out_dim",
      "dim_mult",
      "num_heads",
      "head_dim",
      "num_res_blocks",
      "attn_scales",
      "resblock_resample",
      "use_scale_shift_norm",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "y",
      "concat"
    ],
    "_forward_single": [
      "self",
      "module",
      "x",
      "e",
      "context"
    ]
  },
  "Upsampler1024": {
    "__init__": [
      "self",
      "in_dim",
      "dim",
      "y_dim",
      "out_dim",
      "dim_mult",
      "num_res_blocks",
      "resblock_resample",
      "use_scale_shift_norm",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "y",
      "concat"
    ],
    "_forward_single": [
      "self",
      "module",
      "x",
      "e"
    ]
  },
  "Prior": {
    "__init__": [
      "self",
      "dim",
      "clip_dim",
      "num_heads",
      "num_layers"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "y"
    ],
    "init_weights": [
      "self"
    ],
    "param_groups": [
      "self"
    ]
  },
  "SinusoidalEmbedding": {
    "__init__": [
      "self",
      "seq_len",
      "dim",
      "pad_token"
    ],
    "forward": [
      "self",
      "tokens"
    ]
  },
  "XGLM": {
    "__init__": [
      "self",
      "vocab_size",
      "max_seq_len",
      "dim",
      "ffn_dim",
      "ffn_act",
      "embed_dim",
      "num_heads",
      "num_layers",
      "pad_token",
      "dropout"
    ],
    "forward": [
      "self",
      "tokens",
      "mask"
    ],
    "init_weights": [
      "self",
      "m"
    ]
  },
  "SuperResUNet256": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "dim",
      "text_dim",
      "context_dim",
      "dim_mult",
      "num_heads",
      "head_dim",
      "num_res_blocks",
      "attn_scales",
      "resblock_resample",
      "use_conv",
      "use_scale_shift_norm",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "lx",
      "lt",
      "y",
      "context",
      "mask"
    ],
    "_forward_single": [
      "self",
      "module",
      "x",
      "t",
      "context",
      "mask"
    ]
  },
  "printable_text": [
    "text"
  ],
  "convert_tokens_to_ids": [
    "vocab",
    "tokens"
  ],
  "FullTokenizer": {
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids"
    ]
  },
  "SuperResUNet1024": {
    "__init__": [
      "self",
      "in_dim",
      "dim",
      "out_dim",
      "dim_mult",
      "num_res_blocks",
      "resblock_resample",
      "use_scale_shift_norm",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "concat"
    ],
    "_forward_single": [
      "self",
      "module",
      "x",
      "e"
    ]
  },
  "DiffusionModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "noise",
      "timesteps",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ]
  },
  "DiffusionForTextToImageSynthesis": {
    "__init__": [
      "self",
      "model_dir",
      "device"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "generate": [
      "self",
      "input"
    ]
  },
  "cosine_fn": [
    "u"
  ],
  "gelu": [
    "x"
  ],
  "BertConfig": {
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "emb_size",
      "num_hidden_layers",
      "transformer_type",
      "transition_function",
      "weighted_transformer",
      "num_rolled_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "attention_type",
      "rezero",
      "pre_ln",
      "squeeze_excitation",
      "transfer_matrix",
      "dim_dropout",
      "roberta_style",
      "set_mask_zero",
      "init_scale",
      "safer_fp16",
      "grad_checkpoint"
    ],
    "from_dict": [
      "cls",
      "json_object"
    ],
    "from_json_file": [
      "cls",
      "json_file"
    ],
    "to_dict": [
      "self"
    ],
    "to_json_string": [
      "self"
    ]
  },
  "BERTLayerNorm": {
    "__init__": [
      "self",
      "config",
      "variance_epsilon",
      "special_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BERTEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "adv_embedding"
    ]
  },
  "BERTFactorizedAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "dim_dropout": [
    "x",
    "p",
    "dim",
    "training"
  ],
  "BERTSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask"
    ]
  },
  "BERTSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "BERTAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_tensor",
      "attention_mask",
      "head_mask"
    ]
  },
  "DepthwiseSeparableConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BERTIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SqueezeExcitationBlock": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BERTOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "BERTLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask"
    ]
  },
  "BERTWeightedLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "BERTEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "epoch_id",
      "head_masks"
    ]
  },
  "BERTEncoderRolled": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "epoch_id",
      "head_masks"
    ]
  },
  "BERTEncoderACT": {
    "__init__": [
      "self",
      "config"
    ],
    "should_continue": [
      "self",
      "halting_probability",
      "n_updates"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "BERTPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "epoch_id",
      "head_masks",
      "adv_embedding"
    ]
  },
  "BertForSequenceClassificationMultiTask": {
    "__init__": [
      "self",
      "config",
      "label_list",
      "core_encoder"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "labels",
      "labels_index",
      "epoch_id",
      "head_masks",
      "adv_embedding",
      "return_embedding",
      "loss_weight"
    ]
  },
  "DiffusionGenerator": {
    "__init__": [
      "self",
      "in_dim",
      "dim",
      "text_dim",
      "context_dim",
      "out_dim",
      "dim_mult",
      "num_heads",
      "head_dim",
      "num_res_blocks",
      "attn_scales",
      "resblock_resample",
      "use_scale_shift_norm",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "y",
      "context",
      "mask"
    ],
    "_forward_single": [
      "self",
      "module",
      "x",
      "e",
      "context",
      "mask"
    ]
  },
  "TextToVideoSynthesis": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "UNetSD": {
    "__init__": [
      "self",
      "in_dim",
      "dim",
      "y_dim",
      "context_dim",
      "out_dim",
      "dim_mult",
      "num_heads",
      "head_dim",
      "num_res_blocks",
      "attn_scales",
      "use_scale_shift_norm",
      "dropout",
      "temporal_attn_times",
      "temporal_attention",
      "use_checkpoint",
      "use_image_dataset",
      "use_fps_condition",
      "use_sim_mask"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "y",
      "fps",
      "video_mask",
      "focus_present_mask",
      "prob_focus_present",
      "mask_last_frame_num"
    ],
    "_forward_single": [
      "self",
      "module",
      "x",
      "e",
      "context",
      "time_rel_pos_bias",
      "focus_present_mask",
      "video_mask",
      "reference"
    ]
  },
  "TemporalTransformer": {
    "__init__": [
      "self",
      "in_channels",
      "n_heads",
      "d_head",
      "depth",
      "dropout",
      "context_dim",
      "disable_self_attn",
      "use_linear",
      "use_checkpoint",
      "only_self_att",
      "multiply_zero"
    ],
    "forward": [
      "self",
      "x",
      "context"
    ]
  },
  "TemporalConvBlock_v2": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "dropout",
      "use_image_dataset"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "prob_mask_like": [
    "shape",
    "prob",
    "device"
  ],
  "CAPTION_MODELS": [],
  "Interrogator": {
    "__init__": [
      "self",
      "config"
    ],
    "load_caption_model": [
      "self"
    ],
    "load_clip_model": [
      "self"
    ],
    "chain": [
      "self",
      "image_features",
      "phrases",
      "best_prompt",
      "best_sim",
      "min_count",
      "max_count",
      "desc",
      "reverse"
    ],
    "generate_caption": [
      "self",
      "pil_image"
    ],
    "image_to_features": [
      "self",
      "image"
    ],
    "interrogate_classic": [
      "self",
      "image",
      "max_flavors",
      "caption"
    ],
    "interrogate_fast": [
      "self",
      "image",
      "max_flavors",
      "caption"
    ],
    "interrogate_negative": [
      "self",
      "image",
      "max_flavors"
    ],
    "interrogate": [
      "self",
      "image",
      "min_flavors",
      "max_flavors",
      "caption"
    ],
    "rank_top": [
      "self",
      "image_features",
      "text_array",
      "reverse"
    ],
    "similarity": [
      "self",
      "image_features",
      "text"
    ],
    "similarities": [
      "self",
      "image_features",
      "text_array"
    ],
    "_prepare_caption": [
      "self"
    ],
    "_prepare_clip": [
      "self"
    ]
  },
  "LabelTable": {
    "__init__": [
      "self",
      "labels",
      "desc",
      "ci"
    ],
    "_load_cached": [
      "self",
      "desc",
      "hash",
      "sanitized_name"
    ],
    "_rank": [
      "self",
      "image_features",
      "text_embeds",
      "top_count",
      "reverse"
    ],
    "rank": [
      "self",
      "image_features",
      "top_count",
      "reverse"
    ]
  },
  "_download_file": [
    "url",
    "filepath",
    "chunk_size",
    "quiet"
  ],
  "_merge_tables": [
    "tables",
    "ci"
  ],
  "_prompt_at_max_len": [
    "text",
    "tokenize"
  ],
  "_truncate_to_fit": [
    "text",
    "tokenize"
  ],
  "list_caption_models": [],
  "list_clip_models": [],
  "load_list": [
    "data_path",
    "filename"
  ],
  "CLIP_Interrogator": {
    "__init__": [
      "self",
      "model_dir",
      "device",
      "device_id"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "RawVideoExtractorCV2": {
    "__init__": [
      "self",
      "centercrop",
      "size",
      "frame_rate"
    ],
    "_transform": [
      "self",
      "n_px"
    ],
    "video_to_tensor": [
      "self",
      "video_file",
      "preprocess",
      "sample_fp",
      "start_time",
      "end_time"
    ],
    "get_video_data": [
      "self",
      "video_path",
      "start_time",
      "end_time"
    ],
    "process_raw_data": [
      "self",
      "raw_video_data"
    ]
  },
  "RawVideoExtractor": [],
  "VideoCLIPForMultiModalEmbedding": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_get_text": [
      "self",
      "caption",
      "tokenizer",
      "enable_zh"
    ],
    "_get_rawvideo_dec": [
      "self",
      "video_path",
      "rawVideoExtractor",
      "local_transform",
      "s",
      "e"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "get_retrieved_videos": [
    "sims",
    "k"
  ],
  "get_index_to_normalize": [
    "sims",
    "videos"
  ],
  "qb_norm": [
    "train_test",
    "test_test",
    "args"
  ],
  "CrossEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "concat_embeddings",
      "concat_type"
    ]
  },
  "CrossPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "hidden_mask"
    ]
  },
  "swish": [
    "x"
  ],
  "ACT2FN": [],
  "CrossEn": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sim_matrix"
    ]
  },
  "AllGather": {
    "forward": [
      "ctx",
      "tensor",
      "args"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "AllGather2": {
    "forward": [
      "ctx",
      "tensor",
      "args"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "allgather": [],
  "CLIP4Clip": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "video",
      "video_mask"
    ],
    "get_sequence_output": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "shaped"
    ],
    "get_visual_output": [
      "self",
      "video",
      "video_mask",
      "shaped"
    ],
    "get_sequence_visual_output": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "video",
      "video_mask",
      "shaped"
    ],
    "agg_video_feat": [
      "self",
      "visual_output",
      "video_mask",
      "sim_header"
    ],
    "wti_interaction": [
      "self",
      "text_feat",
      "video_feat",
      "text_mask",
      "video_mask"
    ],
    "_loose_similarity": [
      "self",
      "sequence_output",
      "visual_output",
      "attention_mask",
      "video_mask",
      "sim_header"
    ],
    "get_similarity_logits": [
      "self",
      "sequence_output",
      "visual_output",
      "attention_mask",
      "video_mask",
      "shaped",
      "loose_type"
    ],
    "dtype": [
      "self"
    ],
    "init_weights": [
      "self",
      "module"
    ]
  },
  "_PT_NAME": [],
  "ControlLoRAOutput": {},
  "ControlLoRATuner": {
    "tune": [
      "model",
      "tuner_config",
      "pretrained_tuner"
    ],
    "set_tune_layers": [
      "self",
      "unet",
      "tune_layers_list"
    ],
    "__init__": [
      "self",
      "in_channels",
      "down_block_types",
      "block_out_channels",
      "layers_per_block",
      "act_fn",
      "norm_num_groups",
      "lora_pre_down_block_types",
      "lora_pre_down_layers_per_block",
      "lora_pre_conv_skipped",
      "lora_pre_conv_types",
      "lora_pre_conv_layers_per_block",
      "lora_pre_conv_layers_kernel_size",
      "lora_block_in_channels",
      "lora_block_out_channels",
      "lora_cross_attention_dims",
      "lora_rank",
      "lora_control_rank",
      "lora_post_add",
      "lora_concat_hidden",
      "lora_control_channels",
      "lora_control_self_add",
      "lora_key_states_skipped",
      "lora_value_states_skipped",
      "lora_output_states_skipped",
      "lora_control_version"
    ],
    "forward": [
      "self",
      "x",
      "return_dict"
    ]
  },
  "ControlLoRACrossAttnProcessor": {
    "__init__": [
      "self",
      "hidden_size",
      "cross_attention_dim",
      "rank",
      "control_rank",
      "post_add",
      "concat_hidden",
      "control_channels",
      "control_self_add",
      "key_states_skipped",
      "value_states_skipped",
      "output_states_skipped"
    ],
    "inject_pre_lora": [
      "self",
      "lora_layer"
    ],
    "inject_post_lora": [
      "self",
      "lora_layer"
    ],
    "inject_control_states": [
      "self",
      "control_states"
    ],
    "process_control_states": [
      "self",
      "hidden_states",
      "scale"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "scale"
    ]
  },
  "ControlLoRACrossAttnProcessorV2": {
    "__init__": [
      "self",
      "hidden_size",
      "cross_attention_dim",
      "rank",
      "control_rank",
      "control_channels"
    ],
    "inject_pre_lora": [
      "self",
      "lora_layer"
    ],
    "inject_post_lora": [
      "self",
      "lora_layer"
    ],
    "inject_control_states": [
      "self",
      "control_states"
    ],
    "process_control_states": [
      "self",
      "hidden_states",
      "scale",
      "is_out"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "scale"
    ]
  },
  "ConvBlock2D": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_tensor",
      "temb"
    ]
  },
  "SimpleDownEncoderBlock2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "convnet_eps",
      "convnet_time_scale_shift",
      "convnet_act_fn",
      "convnet_groups",
      "convnet_pre_norm",
      "convnet_kernel_size",
      "output_scale_factor",
      "add_downsample",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "TunerOutput": {},
  "LoRACrossAttnProcessor": {
    "__init__": [
      "self",
      "hidden_size",
      "cross_attention_dim",
      "rank",
      "post_add",
      "key_states_skipped",
      "value_states_skipped",
      "output_states_skipped"
    ],
    "skip_key_states": [
      "self",
      "is_skipped"
    ],
    "skip_value_states": [
      "self",
      "is_skipped"
    ],
    "skip_output_states": [
      "self",
      "is_skipped"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "scale"
    ]
  },
  "LoRATuner": {
    "tune": [
      "model",
      "tuner_config",
      "pretrained_tuner"
    ],
    "set_tune_layers": [
      "self",
      "unet",
      "tune_layers_list"
    ],
    "__init__": [
      "self",
      "lora_block_out_channels",
      "lora_cross_attention_dims",
      "lora_rank",
      "lora_post_add",
      "lora_key_states_skipped",
      "lora_value_states_skipped",
      "lora_output_states_skipped"
    ],
    "forward": [
      "self"
    ]
  },
  "__tuner_MAP__": [],
  "EfficientStableDiffusion": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "train": [
      "self",
      "mode"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "state_dict": [
      "self"
    ],
    "tokenize_caption": [
      "self",
      "captions"
    ],
    "forward": [
      "self",
      "prompt",
      "cond",
      "target"
    ],
    "parameters": [
      "self",
      "recurse"
    ],
    "save_pretrained": [
      "self",
      "target_folder",
      "save_checkpoint_names",
      "save_function",
      "config",
      "save_config_function"
    ],
    "_instantiate": [
      "cls",
      "model_dir"
    ]
  },
  "MPlugConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "task",
      "bert_config",
      "image_res",
      "batch_size_train",
      "vision_width",
      "distill",
      "clip_name",
      "batch_size_test",
      "k_test",
      "alpha",
      "warm_up",
      "eos",
      "optimizer",
      "schedular",
      "min_length",
      "max_length",
      "beam_size",
      "add_ocr",
      "add_object",
      "text_encoder",
      "text_decoder",
      "clip_embed_dim",
      "clip_image_resolution",
      "clip_vision_layers",
      "clip_vision_width",
      "clip_vision_patch_size",
      "clip_context_length",
      "clip_vocab_size",
      "clip_transformer_width",
      "clip_transformer_heads",
      "clip_transformer_layers",
      "queue_size",
      "embed_dim",
      "temp"
    ],
    "from_yaml_file": [
      "cls",
      "yaml_file"
    ]
  },
  "HiTeAConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "task",
      "bert_config",
      "image_res",
      "num_frames",
      "batch_size_train",
      "vision_width",
      "distill",
      "batch_size_test",
      "k_test",
      "alpha",
      "warm_up",
      "eos",
      "optimizer",
      "schedular",
      "min_length",
      "max_length",
      "beam_size",
      "text_encoder",
      "text_decoder",
      "queue_size",
      "embed_dim",
      "temp"
    ],
    "from_yaml_file": [
      "cls",
      "yaml_file"
    ]
  },
  "CONFIG_NAME": [],
  "load_tf_weights_in_bert": [
    "model",
    "config",
    "tf_checkpoint_path"
  ],
  "clamp_inf": [
    "tensor"
  ],
  "BertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ]
  },
  "BertSelfAttention": {
    "__init__": [
      "self",
      "config",
      "is_cross_attention"
    ],
    "save_attn_gradients": [
      "self",
      "attn_gradients"
    ],
    "get_attn_gradients": [
      "self"
    ],
    "save_attention_map": [
      "self",
      "attention_map"
    ],
    "get_attention_map": [
      "self"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "BertSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "BertAttention": {
    "__init__": [
      "self",
      "config",
      "is_cross_attention"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "BertIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "FusionLayer": {
    "__init__": [
      "self",
      "config",
      "layer_num"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "layer_nums",
      "past_key_value",
      "output_attentions"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ]
  },
  "BertLayer": {
    "__init__": [
      "self",
      "config",
      "layer_num"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ]
  },
  "FusionEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BertEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BertPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertPredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertLMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertOnlyMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output"
    ]
  },
  "BertOnlyNSPHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pooled_output"
    ]
  },
  "BertPreTrainingHeads": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output",
      "pooled_output"
    ]
  },
  "BertPreTrainedModel": {
    "config_class": [],
    "load_tf_weights": [],
    "base_model_prefix": [],
    "_keys_to_ignore_on_load_missing": [],
    "_init_weights": [
      "self",
      "module"
    ]
  },
  "BERT_START_DOCSTRING": [],
  "BERT_INPUTS_DOCSTRING": [],
  "FusionModel": {
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "get_extended_attention_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "device",
      "is_decoder"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "is_decoder"
    ]
  },
  "BertLMHeadModel": {
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "labels",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "is_decoder",
      "reduction",
      "soft_labels",
      "alpha",
      "return_logits"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past",
      "attention_mask"
    ],
    "_reorder_cache": [
      "self",
      "past",
      "beam_idx"
    ]
  },
  "BertPrefixModel": {
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "labels",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "is_decoder",
      "reduction",
      "soft_labels",
      "alpha",
      "return_logits"
    ]
  },
  "MPlug": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "from_pretrained": [
      "cls",
      "model_dir",
      "task",
      "load_checkpoint"
    ],
    "_initialize_clip": [
      "config",
      "num_patches"
    ],
    "init_distill": [
      "self",
      "config"
    ],
    "forward": [
      "self"
    ],
    "module_setting": [
      "self",
      "config"
    ],
    "copy_params": [
      "self"
    ],
    "_momentum_update": [
      "self"
    ],
    "generation": [
      "self",
      "question_states",
      "question_atts",
      "out_size"
    ],
    "_tile": [
      "x",
      "dim",
      "n_tile"
    ]
  },
  "MPlugForVisualQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "image",
      "question",
      "answer",
      "alpha",
      "k",
      "weights",
      "train"
    ]
  },
  "MPlugForImageCaption": {
    "__init__": [
      "self",
      "config"
    ],
    "beam_search": [
      "self",
      "image",
      "question",
      "answer",
      "train",
      "out_size"
    ],
    "forward": [
      "self",
      "image",
      "question",
      "answer",
      "train",
      "out_size",
      "scst"
    ]
  },
  "MPlugForImageTextRetrieval": {
    "__init__": [
      "self",
      "config"
    ],
    "init_distill": [
      "self",
      "config"
    ],
    "_dequeue_and_enqueue": [
      "self",
      "image_feat",
      "text_feat",
      "idx"
    ],
    "forward": [
      "self",
      "image",
      "text",
      "idx",
      "train"
    ]
  },
  "HiTeA": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "from_pretrained": [
      "cls",
      "model_dir",
      "load_checkpoint"
    ],
    "init_distill": [
      "self",
      "config"
    ],
    "forward": [
      "self"
    ],
    "module_setting": [
      "self",
      "config"
    ],
    "copy_params": [
      "self"
    ],
    "_momentum_update": [
      "self"
    ],
    "generation": [
      "self",
      "question_states",
      "question_atts",
      "out_size"
    ],
    "_tile": [
      "x",
      "dim",
      "n_tile"
    ]
  },
  "HiTeAForVideoQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "video",
      "question",
      "answer",
      "alpha",
      "k",
      "weights",
      "train"
    ]
  },
  "HiTeAForVideoCaption": {
    "__init__": [
      "self",
      "config"
    ],
    "beam_search": [
      "self",
      "video",
      "question",
      "answer",
      "train",
      "out_size"
    ],
    "forward": [
      "self",
      "video",
      "question",
      "answer",
      "train",
      "out_size",
      "scst"
    ]
  },
  "build_predictor": [
    "args",
    "tokenizer",
    "symbols",
    "model",
    "logger"
  ],
  "TextGenerator": {
    "__init__": [
      "self",
      "args",
      "model",
      "vocab",
      "symbols",
      "global_scorer",
      "logger",
      "dump_beam"
    ],
    "_build_target_tokens": [
      "self",
      "pred"
    ],
    "translate_batch": [
      "self",
      "encoder_inputs",
      "do_sample",
      "out_size"
    ],
    "translate_batch_scst": [
      "self",
      "encoder_inputs",
      "do_sample",
      "out_size"
    ],
    "_fast_translate_batch": [
      "self",
      "encoder_inputs",
      "max_length",
      "min_length",
      "do_sample",
      "out_size"
    ],
    "_generate_no_beam_search": [
      "self",
      "input_ids",
      "cur_len",
      "max_length",
      "do_sample",
      "temperature",
      "top_k",
      "top_p",
      "repetition_penalty",
      "pad_token_id",
      "eos_token_ids",
      "batch_size"
    ]
  },
  "top_k_top_p_filtering": [
    "logits",
    "top_k",
    "top_p",
    "filter_value",
    "min_tokens_to_keep"
  ],
  "tile": [
    "x",
    "count",
    "dim"
  ],
  "MViTv2_Base_config": [],
  "interpolate_rel_pos_embed": [
    "state_dict_origin",
    "state_dict_model",
    "temporal",
    "verbose"
  ],
  "_prepare_mvit_configs": [
    "cfg"
  ],
  "Permute": {
    "__init__": [
      "self",
      "dims"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "round_width": [
    "width",
    "multiplier",
    "min_width",
    "divisor",
    "verbose"
  ],
  "attention_pool": [
    "tensor",
    "pool",
    "thw_shape",
    "has_cls_embed",
    "norm"
  ],
  "get_rel_pos": [
    "rel_pos",
    "d"
  ],
  "cal_rel_pos_spatial": [
    "attn",
    "q",
    "k",
    "has_cls_embed",
    "q_shape",
    "k_shape",
    "rel_pos_h",
    "rel_pos_w"
  ],
  "cal_rel_pos_temporal": [
    "attn",
    "q",
    "has_cls_embed",
    "q_shape",
    "k_shape",
    "rel_pos_t"
  ],
  "MultiScaleAttention": {
    "__init__": [
      "self",
      "dim",
      "dim_out",
      "input_size",
      "num_heads",
      "qkv_bias",
      "drop_rate",
      "kernel_q",
      "kernel_kv",
      "stride_q",
      "stride_kv",
      "norm_layer",
      "has_cls_embed",
      "mode",
      "pool_first",
      "rel_pos_spatial",
      "rel_pos_temporal",
      "rel_pos_zero_init",
      "residual_pooling",
      "separate_qkv"
    ],
    "forward": [
      "self",
      "x",
      "thw_shape"
    ]
  },
  "MultiScaleBlock": {
    "__init__": [
      "self",
      "dim",
      "dim_out",
      "num_heads",
      "input_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "drop_path",
      "act_layer",
      "norm_layer",
      "up_rate",
      "kernel_q",
      "kernel_kv",
      "stride_q",
      "stride_kv",
      "mode",
      "has_cls_embed",
      "pool_first",
      "rel_pos_spatial",
      "rel_pos_temporal",
      "rel_pos_zero_init",
      "residual_pooling",
      "dim_mul_in_att",
      "separate_qkv",
      "use_grad_checkpoint"
    ],
    "forward": [
      "self",
      "x",
      "thw_shape"
    ]
  },
  "MViTv2": {
    "__init__": [
      "self",
      "img_size",
      "embed_dim",
      "num_classes",
      "num_frames",
      "num_heads",
      "depth",
      "patch_kernel",
      "patch_stride",
      "patch_padding",
      "config",
      "dropout_rate",
      "drop_path_rate",
      "mlp_ratio",
      "qkv_bias",
      "mode",
      "cls_embed_on",
      "use_abs_pos",
      "rel_pos_spatial",
      "rel_pos_temporal",
      "rel_pos_zero_init",
      "residual_pooling",
      "dim_mul_in_att",
      "pool_first",
      "zero_decay_pos_cls",
      "separate_qkv",
      "norm_stem",
      "sep_pos_embed",
      "use_grad_checkpoint"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "no_weight_decay": [
      "self"
    ],
    "_get_pos_embed": [
      "self",
      "pos_embed",
      "bcthw"
    ],
    "forward_features": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "load_from_config": [
    "config"
  ],
  "gelu_new": [
    "x"
  ],
  "BertLayerNorm": [],
  "convert_models_to_fp32": [
    "model"
  ],
  "CLIPForMultiModalEmbedding": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ],
    "temperature": [
      "self"
    ]
  },
  "validate_case_matches_checkpoint": [
    "do_lower_case",
    "init_checkpoint"
  ],
  "convert_by_vocab": [
    "vocab",
    "items"
  ],
  "convert_ids_to_tokens": [
    "inv_vocab",
    "ids"
  ],
  "MGeoForTextRanking": {
    "__init__": [
      "self",
      "config",
      "finetune_mode",
      "gis_num"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "gis_list",
      "gis_tp"
    ]
  },
  "MGeoForTokenClassification": {
    "_keys_to_ignore_on_load_unexpected": [],
    "__init__": [
      "self",
      "config",
      "finetune_mode"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "offset_mapping",
      "label_mask",
      "gis_list",
      "gis_tp"
    ]
  },
  "MGeoForSequenceClassification": {
    "__init__": [
      "self",
      "config",
      "finetune_mode"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "gis_list",
      "gis_tp"
    ]
  },
  "GisEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length",
      "rel_type_ids",
      "absolute_position_ids",
      "relative_position_ids",
      "prov_ids",
      "city_ids",
      "dist_ids"
    ]
  },
  "BertForPreTrainingOutput": {},
  "BertForPreTraining": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "next_sentence_label",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "GisBertLMPredictionHead": {
    "__init__": [
      "self",
      "config",
      "vocab_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertForGisMaskedLM": {
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "is_decoder",
      "mode",
      "soft_labels",
      "alpha",
      "return_logits",
      "rel_type_ids",
      "absolute_position_ids",
      "relative_position_ids",
      "token_type_ids_label",
      "rel_type_ids_label",
      "absolute_position_ids_label",
      "relative_position_ids_label"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "BertForMaskedLM": {
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "is_decoder",
      "mode",
      "soft_labels",
      "alpha",
      "return_logits",
      "rel_type_ids",
      "absolute_position_ids",
      "relative_position_ids"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "BertForNextSentencePrediction": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BertForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BertForQuestionAnswering": {
    "_keys_to_ignore_on_load_unexpected": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MGeoPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "MGeo": {
    "__init__": [
      "self",
      "config",
      "finetune_mode",
      "gis_num",
      "add_pooling_layer"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "is_decoder",
      "mode",
      "gis_list",
      "gis_tp",
      "use_token_type"
    ],
    "extract_sequence_outputs": [
      "self",
      "outputs"
    ],
    "extract_pooled_outputs": [
      "self",
      "outputs"
    ]
  },
  "FlashAttentionBlock": {
    "__init__": [
      "self",
      "dim",
      "context_dim",
      "num_heads",
      "head_dim",
      "batch_size"
    ],
    "_init_weight": [
      "self",
      "module"
    ],
    "forward": [
      "self",
      "x",
      "context"
    ]
  },
  "FrozenOpenCLIPVisualEmbedder": {
    "LAYERS": [],
    "__init__": [
      "self",
      "arch",
      "pretrained",
      "device",
      "max_length",
      "freeze",
      "layer",
      "input_shape"
    ],
    "freeze": [
      "self"
    ],
    "forward": [
      "self",
      "image"
    ],
    "encode_with_transformer": [
      "self",
      "text"
    ],
    "text_transformer_forward": [
      "self",
      "x",
      "attn_mask"
    ],
    "encode": [
      "self",
      "text"
    ]
  },
  "pmi_world_size": [],
  "gpus_per_machine": [],
  "composition_strings": [],
  "VideoComposer": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "load_stable_diffusion_pretrained": [
    "state_dict",
    "temporal_attention"
  ],
  "AddGaussianNoise": {
    "__init__": [
      "self",
      "mean",
      "std"
    ],
    "__call__": [
      "self",
      "img"
    ],
    "__repr__": [
      "self"
    ]
  },
  "GaussianDiffusion_style": {
    "__init__": [
      "self",
      "betas",
      "mean_type",
      "var_type",
      "loss_type",
      "rescale_timesteps"
    ],
    "q_sample": [
      "self",
      "x0",
      "t",
      "noise"
    ],
    "q_mean_variance": [
      "self",
      "x0",
      "t"
    ],
    "q_posterior_mean_variance": [
      "self",
      "x0",
      "xt",
      "t"
    ],
    "p_sample": [
      "self",
      "xt",
      "t",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "condition_fn",
      "guide_scale"
    ],
    "p_sample_loop": [
      "self",
      "noise",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "condition_fn",
      "guide_scale"
    ],
    "p_mean_variance": [
      "self",
      "xt",
      "t",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "guide_scale"
    ],
    "ddim_sample": [
      "self",
      "xt",
      "t",
      "t_prev",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "condition_fn",
      "guide_scale",
      "ddim_timesteps",
      "eta"
    ],
    "ddim_sample_loop": [
      "self",
      "noise",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "condition_fn",
      "guide_scale",
      "ddim_timesteps",
      "eta"
    ],
    "ddim_reverse_sample": [
      "self",
      "xt",
      "t",
      "t_next",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "guide_scale",
      "ddim_timesteps"
    ],
    "ddim_reverse_sample_loop": [
      "self",
      "x0",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "guide_scale",
      "ddim_timesteps"
    ],
    "plms_sample": [
      "self",
      "xt",
      "t",
      "t_prev",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "condition_fn",
      "guide_scale",
      "plms_timesteps"
    ],
    "plms_sample_loop": [
      "self",
      "noise",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "condition_fn",
      "guide_scale",
      "plms_timesteps"
    ],
    "dpm_solver_sample_loop": [
      "self",
      "noise",
      "model",
      "model_kwargs",
      "order",
      "skip_type",
      "method",
      "clamp",
      "percentile",
      "condition_fn",
      "guide_scale",
      "dpm_solver_timesteps",
      "algorithm_type",
      "t_start",
      "t_end",
      "lower_order_final",
      "denoise_to_zero",
      "solver_type"
    ],
    "inpaint_p_sample": [
      "self",
      "xt",
      "t",
      "y",
      "mask",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "guide_scale"
    ],
    "inpaint_p_sample_loop": [
      "self",
      "noise",
      "y",
      "mask",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "guide_scale"
    ],
    "inpaint_mcg_p_sample": [
      "self",
      "xt",
      "t",
      "y",
      "mask",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "guide_scale",
      "mcg_scale"
    ],
    "inpaint_mcg_p_sample_loop": [
      "self",
      "noise",
      "y",
      "mask",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "guide_scale",
      "mcg_scale"
    ],
    "loss": [
      "self",
      "x0",
      "t",
      "model",
      "model_kwargs",
      "noise",
      "input_x0",
      "reduction"
    ],
    "variational_lower_bound": [
      "self",
      "x0",
      "xt",
      "t",
      "model",
      "model_kwargs",
      "clamp",
      "percentile",
      "reduction"
    ],
    "variational_lower_bound_loop": [
      "self",
      "x0",
      "model",
      "model_kwargs",
      "clamp",
      "percentile"
    ],
    "_scale_timesteps": [
      "self",
      "t"
    ]
  },
  "USE_TEMPORAL_TRANSFORMER": [],
  "load_Block": [
    "state",
    "prefix",
    "new_prefix"
  ],
  "load_2d_pretrained_state_dict": [
    "state",
    "cfg"
  ],
  "TemporalAttentionBlock": {
    "__init__": [
      "self",
      "dim",
      "heads",
      "dim_head",
      "rotary_emb",
      "use_image_dataset",
      "use_sim_mask"
    ],
    "forward": [
      "self",
      "x",
      "pos_bias",
      "focus_present_mask",
      "video_mask"
    ]
  },
  "TemporalAttentionMultiBlock": {
    "__init__": [
      "self",
      "dim",
      "heads",
      "dim_head",
      "rotary_emb",
      "use_image_dataset",
      "use_sim_mask",
      "temporal_attn_times"
    ],
    "forward": [
      "self",
      "x",
      "pos_bias",
      "focus_present_mask",
      "video_mask"
    ]
  },
  "InitTemporalConvBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "dropout",
      "use_image_dataset"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TemporalConvBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "dropout",
      "use_image_dataset"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UNetSD_temporal": {
    "__init__": [
      "self",
      "cfg",
      "in_dim",
      "dim",
      "y_dim",
      "context_dim",
      "hist_dim",
      "concat_dim",
      "out_dim",
      "dim_mult",
      "num_heads",
      "head_dim",
      "num_res_blocks",
      "attn_scales",
      "use_scale_shift_norm",
      "dropout",
      "temporal_attn_times",
      "temporal_attention",
      "use_checkpoint",
      "use_image_dataset",
      "use_fps_condition",
      "use_sim_mask",
      "misc_dropout",
      "training",
      "inpainting",
      "video_compositions",
      "p_all_zero",
      "p_all_keep",
      "zero_y",
      "black_image_feature"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "y",
      "depth",
      "image",
      "motion",
      "local_image",
      "single_sketch",
      "masked",
      "canny",
      "sketch",
      "histogram",
      "fps",
      "video_mask",
      "focus_present_mask",
      "prob_focus_present",
      "mask_last_frame_num"
    ],
    "_forward_single": [
      "self",
      "module",
      "x",
      "e",
      "context",
      "time_rel_pos_bias",
      "focus_present_mask",
      "video_mask",
      "reference"
    ]
  },
  "PreNormattention": {
    "__init__": [
      "self",
      "dim",
      "fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PreNormattention_qkv": {
    "__init__": [
      "self",
      "dim",
      "fn"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v"
    ]
  },
  "Attention_qkv": {
    "__init__": [
      "self",
      "dim",
      "heads",
      "dim_head",
      "dropout"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v"
    ]
  },
  "PostNormattention": {
    "__init__": [
      "self",
      "dim",
      "fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Transformer_v2": {
    "__init__": [
      "self",
      "heads",
      "dim",
      "dim_head_k",
      "dim_head_v",
      "dropout_atte",
      "mlp_dim",
      "dropout_ffn",
      "depth"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "is_dist_initialized": [],
  "new_group": [
    "ranks"
  ],
  "destroy_process_group": [],
  "barrier": [
    "group"
  ],
  "all_reduce": [
    "tensor",
    "op",
    "group"
  ],
  "reduce": [
    "tensor",
    "dst",
    "op",
    "group"
  ],
  "gather": [
    "tensor",
    "dst",
    "group"
  ],
  "get_global_gloo_group": [],
  "generalized_all_gather": [
    "data",
    "group"
  ],
  "generalized_gather": [
    "data",
    "dst",
    "group"
  ],
  "scatter": [
    "data",
    "scatter_list",
    "src",
    "group"
  ],
  "reduce_scatter": [
    "output",
    "input_list",
    "op",
    "group"
  ],
  "send": [
    "tensor",
    "dst",
    "group"
  ],
  "recv": [
    "tensor",
    "src",
    "group"
  ],
  "isend": [
    "tensor",
    "dst",
    "group"
  ],
  "irecv": [
    "tensor",
    "src",
    "group"
  ],
  "shared_random_seed": [
    "group"
  ],
  "_all_gather": [
    "x"
  ],
  "_all_reduce": [
    "x"
  ],
  "_split": [
    "x"
  ],
  "DiffAllGather": {
    "symbolic": [
      "graph",
      "input"
    ],
    "forward": [
      "ctx",
      "input"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "DiffAllReduce": {
    "symbolic": [
      "graph",
      "input"
    ],
    "forward": [
      "ctx",
      "input"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "DiffScatter": {
    "symbolic": [
      "ctx",
      "input"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "DiffCopy": {
    "symbolic": [
      "graph",
      "input"
    ],
    "forward": [
      "ctx",
      "input"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "diff_all_gather": [],
  "diff_all_reduce": [],
  "diff_scatter": [],
  "diff_copy": [],
  "spherical_kmeans": [
    "feats",
    "num_clusters",
    "num_iters"
  ],
  "sinkhorn": [
    "Q",
    "eps",
    "num_iters"
  ],
  "save_with_model_kwargs": [
    "model_kwargs",
    "video_data",
    "autoencoder",
    "ori_video",
    "viz_num",
    "step",
    "caps",
    "palette",
    "cfg",
    "duration"
  ],
  "prepare_model_kwargs": [
    "partial_keys",
    "full_model_kwargs",
    "use_fps_condition"
  ],
  "get_first_stage_encoding": [
    "encoder_posterior"
  ],
  "make_masked_images": [
    "imgs",
    "masks"
  ],
  "DOWNLOAD_TO_CACHE": [
    "oss_key",
    "file_or_dirname",
    "cache_dir"
  ],
  "parse_oss_url": [
    "path"
  ],
  "parse_bucket": [
    "url"
  ],
  "read": [
    "filename",
    "mode",
    "retry"
  ],
  "download_video_to_file": [
    "filename",
    "local_file",
    "retry"
  ],
  "read_gzip": [
    "filename",
    "retry"
  ],
  "put_object": [
    "bucket",
    "oss_key",
    "data",
    "retry"
  ],
  "put_torch_object": [
    "bucket",
    "oss_key",
    "data",
    "retry"
  ],
  "put_object_from_file": [
    "bucket",
    "oss_key",
    "filename",
    "retry"
  ],
  "get_object": [
    "bucket",
    "oss_key",
    "retry"
  ],
  "get_object_to_file": [
    "bucket",
    "oss_key",
    "filename",
    "retry"
  ],
  "video_tensor_to_gif": [
    "tensor",
    "path",
    "duration",
    "loop",
    "optimize"
  ],
  "save_video": [
    "bucket",
    "oss_key",
    "tensor",
    "mean",
    "std",
    "nrow",
    "retry"
  ],
  "save_video_multiple_conditions": [
    "oss_key",
    "video_tensor",
    "model_kwargs",
    "source_imgs",
    "palette",
    "mean",
    "std",
    "nrow",
    "retry",
    "save_origin_video",
    "bucket",
    "duration"
  ],
  "save_video_multiple_conditions_with_data": [
    "bucket",
    "video_save_key",
    "gt_video_save_key",
    "vis_oss_key",
    "video_tensor",
    "model_kwargs",
    "source_imgs",
    "palette",
    "mean",
    "std",
    "nrow",
    "retry"
  ],
  "save_video_vs_conditions": [
    "bucket",
    "oss_key",
    "video_tensor",
    "conditions",
    "source_imgs",
    "mean",
    "std",
    "nrow",
    "retry"
  ],
  "save_video_grid_mp4": [
    "bucket",
    "oss_key",
    "tensor",
    "mean",
    "std",
    "nrow",
    "fps",
    "retry"
  ],
  "save_text": [
    "bucket",
    "oss_key",
    "tensor",
    "nrow",
    "retry"
  ],
  "save_caps": [
    "bucket",
    "oss_key",
    "caps",
    "retry"
  ],
  "download": [
    "url",
    "filename",
    "replace",
    "quiet"
  ],
  "TFSClient": {
    "__init__": [
      "self",
      "host",
      "app_key"
    ],
    "server": [
      "self"
    ],
    "read": [
      "self",
      "tfs"
    ]
  },
  "read_tfs": [
    "tfs",
    "retry"
  ],
  "huggingface_tokenizer": [
    "name"
  ],
  "huggingface_model": [
    "name",
    "model_type"
  ],
  "_LOCAL_PROCESS_GROUP": [],
  "init_process_group": [
    "local_rank",
    "local_world_size",
    "shard_id",
    "num_shards",
    "init_method",
    "dist_backend"
  ],
  "is_master_proc": [
    "num_gpus"
  ],
  "all_gather_unaligned": [
    "data",
    "group"
  ],
  "init_distributed_training": [
    "cfg"
  ],
  "get_local_size": [],
  "find_free_port": [],
  "random_resize": [
    "img",
    "size"
  ],
  "CenterCropV3": {
    "__init__": [
      "self",
      "size"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "Rescale": {
    "__init__": [
      "self",
      "size",
      "interpolation"
    ],
    "__call__": [
      "self",
      "rgb"
    ]
  },
  "ResizeRandomCrop": {
    "__init__": [
      "self",
      "size",
      "size_short"
    ],
    "__call__": [
      "self",
      "rgb"
    ]
  },
  "ExtractResizeRandomCrop": {
    "__init__": [
      "self",
      "size",
      "size_short"
    ],
    "__call__": [
      "self",
      "rgb"
    ]
  },
  "ExtractResizeAssignCrop": {
    "__init__": [
      "self",
      "size",
      "size_short"
    ],
    "__call__": [
      "self",
      "rgb",
      "wh"
    ]
  },
  "CenterCropV2": {
    "__init__": [
      "self",
      "size"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "RandomCropV2": {
    "__init__": [
      "self",
      "size",
      "min_area",
      "ratio"
    ],
    "_get_params": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "rgb"
    ]
  },
  "RandomHFlip": {
    "__init__": [
      "self",
      "p"
    ],
    "__call__": [
      "self",
      "rgb"
    ]
  },
  "GaussianBlur": {
    "__init__": [
      "self",
      "sigmas",
      "p"
    ],
    "__call__": [
      "self",
      "rgb"
    ]
  },
  "RandomGray": {
    "__init__": [
      "self",
      "p"
    ],
    "__call__": [
      "self",
      "rgb"
    ]
  },
  "BatchSampler": {
    "__init__": [
      "self",
      "dataset_size",
      "batch_size",
      "num_replicas",
      "rank",
      "shuffle",
      "seed"
    ],
    "__iter__": [
      "self"
    ]
  },
  "GroupSampler": {
    "__init__": [
      "self",
      "group_file",
      "batch_size",
      "alpha",
      "update_interval",
      "seed"
    ],
    "__iter__": [
      "self"
    ],
    "update_groups": [
      "self"
    ],
    "sample": [
      "self"
    ]
  },
  "ImgGroupSampler": {
    "__init__": [
      "self",
      "group_file",
      "batch_size",
      "alpha",
      "update_interval",
      "seed"
    ],
    "__iter__": [
      "self"
    ],
    "update_groups": [
      "self"
    ],
    "sample": [
      "self"
    ]
  },
  "annotator_ckpts_path": [],
  "rgb2hex": [
    "rgb"
  ],
  "hex2rgb": [
    "hex"
  ],
  "Palette": {
    "__init__": [
      "self",
      "num_hues",
      "num_sat",
      "num_light"
    ],
    "histogram": [
      "self",
      "rgb_img",
      "sigma"
    ],
    "get_palette_image": [
      "self",
      "hist",
      "percentile",
      "width",
      "height"
    ],
    "quantize_image": [
      "self",
      "rgb_img"
    ],
    "export": [
      "self",
      "dirname"
    ]
  },
  "SketchSimplification": {
    "__init__": [
      "self",
      "mean",
      "std"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "sketch_simplification_gan": [
    "model_dir",
    "pretrained"
  ],
  "sketch_simplification_mse": [
    "pretrained"
  ],
  "sketch_to_pencil_v1": [
    "pretrained"
  ],
  "sketch_to_pencil_v2": [
    "pretrained"
  ],
  "CONFIGS": [],
  "create_conv_func": [
    "op_type"
  ],
  "config_model": [
    "model"
  ],
  "config_model_converted": [
    "model"
  ],
  "convert_pdc": [
    "op",
    "weight"
  ],
  "convert_pidinet": [
    "state_dict",
    "config"
  ],
  "CSAM": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CDCM": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MapReduce": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PDCBlock": {
    "__init__": [
      "self",
      "pdc",
      "inplane",
      "ouplane",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PDCBlock_converted": {
    "__init__": [
      "self",
      "pdc",
      "inplane",
      "ouplane",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PiDiNet": {
    "__init__": [
      "self",
      "inplane",
      "pdcs",
      "dil",
      "sa",
      "convert"
    ],
    "get_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "pidinet_bsd_tiny": [
    "pretrained",
    "vanilla_cnn"
  ],
  "pidinet_bsd_small": [
    "pretrained",
    "vanilla_cnn"
  ],
  "pidinet_bsd": [
    "model_dir",
    "pretrained",
    "vanilla_cnn"
  ],
  "pidinet_nyud": [
    "pretrained",
    "vanilla_cnn"
  ],
  "pidinet_multicue": [
    "pretrained",
    "vanilla_cnn"
  ],
  "_clip": [
    "name",
    "pretrained"
  ],
  "FusionBlock": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self"
    ]
  },
  "MiDaS": {
    "__init__": [
      "self",
      "image_size",
      "patch_size",
      "dim",
      "neck_dims",
      "fusion_dim",
      "num_heads",
      "num_layers"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "midas_v3": [
    "model_dir",
    "pretrained"
  ],
  "CLIPVisionWrapper": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BertWrapper": {
    "__init__": [
      "self",
      "config_json",
      "feat_dim",
      "token_dim"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "CrossLayer": {
    "__init__": [
      "self",
      "feat_dim",
      "mlp_ratio"
    ],
    "forward": [
      "self",
      "text_tensors",
      "text_masks",
      "image_tensors",
      "retrieved_tensors"
    ]
  },
  "TEAM": {
    "__init__": [
      "self",
      "text_model",
      "image_model",
      "pretrained"
    ],
    "get_feature": [
      "self",
      "text_data",
      "text_mask",
      "img_tensor"
    ],
    "get_cross_score": [
      "self",
      "text_tensors",
      "text_mask",
      "image_tensors"
    ]
  },
  "TEAMForMultiModalSimilarity": {
    "__init__": [
      "self",
      "model_dir",
      "device_id"
    ],
    "tokenize_text": [
      "self",
      "text_str"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "create_diffusion": [
    "diffusion_config"
  ],
  "GroupNorm": {
    "forward": [
      "self",
      "x"
    ]
  },
  "SuperResModel": {
    "__init__": [
      "self",
      "image_size",
      "in_channels"
    ],
    "forward": [
      "self",
      "x",
      "timesteps",
      "low_res"
    ]
  },
  "UNetConfig": {
    "__init__": [
      "self",
      "image_size",
      "in_channels",
      "model_channels",
      "out_channels",
      "num_res_blocks",
      "attention_resolutions",
      "dropout",
      "channel_mult",
      "num_classes",
      "use_checkpoint",
      "use_fp16",
      "num_heads",
      "num_head_channels",
      "num_heads_upsample",
      "use_scale_shift_norm",
      "resblock_updown",
      "use_new_attention_order"
    ]
  },
  "HFUNetModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x",
      "timesteps",
      "y"
    ],
    "convert_to_fp16": [
      "self"
    ]
  },
  "VideoToVideo": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "CenterCropWide": {
    "__init__": [
      "self",
      "size"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "get_ancestral_step": [
    "sigma_from",
    "sigma_to",
    "eta"
  ],
  "get_scalings": [
    "sigma"
  ],
  "sample_heun": [
    "noise",
    "model",
    "sigmas",
    "s_churn",
    "s_tmin",
    "s_tmax",
    "s_noise",
    "show_progress"
  ],
  "BatchedBrownianTree": {
    "__init__": [
      "self",
      "x",
      "t0",
      "t1",
      "seed"
    ],
    "sort": [
      "a",
      "b"
    ],
    "__call__": [
      "self",
      "t0",
      "t1"
    ]
  },
  "BrownianTreeNoiseSampler": {
    "__init__": [
      "self",
      "x",
      "sigma_min",
      "sigma_max",
      "seed",
      "transform"
    ],
    "__call__": [
      "self",
      "sigma",
      "sigma_next"
    ]
  },
  "sample_dpmpp_2m_sde": [
    "noise",
    "model",
    "sigmas",
    "eta",
    "s_noise",
    "solver_type",
    "show_progress"
  ],
  "GaussianDiffusion_SDEdit": {
    "__init__": [
      "self",
      "sigmas",
      "prediction_type"
    ],
    "diffuse": [
      "self",
      "x0",
      "t",
      "noise"
    ],
    "denoise": [
      "self",
      "xt",
      "t",
      "s",
      "model",
      "model_kwargs",
      "guide_scale",
      "guide_rescale",
      "clamp",
      "percentile"
    ],
    "sample": [
      "self",
      "noise",
      "model",
      "model_kwargs",
      "condition_fn",
      "guide_scale",
      "guide_rescale",
      "clamp",
      "percentile",
      "solver",
      "steps",
      "t_max",
      "t_min",
      "discretization",
      "discard_penultimate_step",
      "return_intermediate",
      "show_progress",
      "seed"
    ],
    "_sigma_to_t": [
      "self",
      "sigma"
    ],
    "_t_to_sigma": [
      "self",
      "t"
    ]
  },
  "betas_to_sigmas": [
    "betas"
  ],
  "sigmas_to_betas": [
    "sigmas"
  ],
  "logsnrs_to_sigmas": [
    "logsnrs"
  ],
  "sigmas_to_logsnrs": [
    "sigmas"
  ],
  "_logsnr_cosine": [
    "n",
    "logsnr_min",
    "logsnr_max"
  ],
  "_logsnr_cosine_shifted": [
    "n",
    "logsnr_min",
    "logsnr_max",
    "scale"
  ],
  "_logsnr_cosine_interp": [
    "n",
    "logsnr_min",
    "logsnr_max",
    "scale_min",
    "scale_max"
  ],
  "karras_schedule": [
    "n",
    "sigma_min",
    "sigma_max",
    "rho"
  ],
  "logsnr_cosine_interp_schedule": [
    "n",
    "logsnr_min",
    "logsnr_max",
    "scale_min",
    "scale_max"
  ],
  "noise_schedule": [
    "schedule",
    "n",
    "zero_terminal_snr"
  ],
  "Vid2VidSDUNet": {
    "__init__": [
      "self",
      "in_dim",
      "dim",
      "y_dim",
      "context_dim",
      "out_dim",
      "dim_mult",
      "num_heads",
      "head_dim",
      "num_res_blocks",
      "attn_scales",
      "use_scale_shift_norm",
      "dropout",
      "temporal_attn_times",
      "temporal_attention",
      "use_checkpoint",
      "use_image_dataset",
      "use_fps_condition",
      "use_sim_mask",
      "training",
      "inpainting"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "y",
      "x_lr",
      "fps",
      "video_mask",
      "focus_present_mask",
      "prob_focus_present",
      "mask_last_frame_num"
    ],
    "_forward_single": [
      "self",
      "module",
      "x",
      "e",
      "context",
      "time_rel_pos_bias",
      "focus_present_mask",
      "video_mask",
      "reference"
    ]
  },
  "RLEGForMultiModalEmbedding": {
    "__init__": [
      "self",
      "model_dir",
      "device_id"
    ],
    "parse_image": [
      "self",
      "input_img"
    ],
    "parse_text": [
      "self",
      "text_str"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "RLEGModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "tokenize": [
      "self",
      "text_str"
    ],
    "encode_text": [
      "self",
      "text"
    ],
    "encode_image": [
      "self",
      "image"
    ],
    "parse_feat": [
      "self",
      "feat"
    ],
    "forward": [
      "self",
      "image",
      "text"
    ]
  },
  "isinstance_str": [
    "x",
    "cls_name"
  ],
  "Fourier_filter": [
    "x",
    "threshold",
    "scale"
  ],
  "register_upblock2d": [
    "model"
  ],
  "register_free_upblock2d": [
    "model",
    "b1",
    "b2",
    "s1",
    "s2"
  ],
  "register_crossattn_upblock2d": [
    "model"
  ],
  "register_free_crossattn_upblock2d": [
    "model",
    "b1",
    "b2",
    "s1",
    "s2"
  ],
  "MplugOwlVisionConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "projection_dim",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "hidden_act",
      "layer_norm_eps",
      "attention_dropout",
      "initializer_range",
      "initializer_factor",
      "use_flash_attn",
      "use_fp32_layernorm"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "MplugOwlVisualAbstractorConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "attention_probs_dropout_prob",
      "initializer_range",
      "layer_norm_eps",
      "encoder_hidden_size",
      "use_fp32_layernorm"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "MplugOwlConfig": {
    "model_type": [],
    "is_composition": [],
    "__init__": [
      "self",
      "task",
      "vision_config",
      "visual_abstractor_config",
      "text_config",
      "num_query_tokens"
    ],
    "from_vision_abstractor_text_configs": [
      "cls",
      "vision_config",
      "visual_abstractor_config",
      "text_config"
    ],
    "to_dict": [
      "self"
    ]
  },
  "MplugOwlForConditionalGenerationModelOutput": {
    "to_tuple": [
      "self"
    ]
  },
  "bloom_forward": [
    "self",
    "input_ids",
    "past_key_values",
    "attention_mask",
    "head_mask",
    "inputs_embeds",
    "use_cache",
    "output_attentions",
    "output_hidden_states",
    "return_dict"
  ],
  "get_ltor_masks_and_position_ids_from_embeddings": [
    "data"
  ],
  "MplugOwlVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "MplugOwlVisionAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states",
      "head_mask",
      "output_attentions"
    ]
  },
  "MplugOwlMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MplugOwlVisionEncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions"
    ]
  },
  "MplugOwlPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "_no_split_modules": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ]
  },
  "MPLUG_OWL_START_DOCSTRING": [],
  "MPLUG_OWL_VISION_INPUTS_DOCSTRING": [],
  "MPLUG_OWL_TEXT_INPUTS_DOCSTRING": [],
  "MPLUG_OWL_INPUTS_DOCSTRING": [],
  "MplugOwlVisionEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MplugOwlVisionModel": {
    "main_input_name": [],
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "MplugOwlVisualAbstractorMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MplugOwlVisualAbstractorMultiHeadAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "save_attn_gradients": [
      "self",
      "attn_gradients"
    ],
    "get_attn_gradients": [
      "self"
    ],
    "save_attention_map": [
      "self",
      "attention_map"
    ],
    "get_attention_map": [
      "self"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "MplugOwlVisualAbstractorCrossOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "MplugOwlVisualAbstractorAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "MplugOwlVisualAbstractorLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "output_attentions"
    ]
  },
  "MplugOwlVisualAbstractorEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MplugOwlVisualAbstractorModel": {
    "__init__": [
      "self",
      "config",
      "language_hidden_size"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "get_extended_attention_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "device"
    ],
    "forward": [
      "self",
      "query_embeds",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MplugOwlModel": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "_tie_weights": [
      "self"
    ],
    "get_text_features": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "get_media_indices": [
    "my_list"
  ],
  "MplugOwlForConditionalGenerationHF": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "_tie_weights": [
      "self"
    ],
    "_preprocess_accelerate": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "input_ids",
      "num_images",
      "non_padding_mask",
      "non_media_mask",
      "prompt_mask",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "output_attentions",
      "output_hidden_states",
      "labels",
      "return_dict"
    ],
    "generate": [
      "self",
      "pixel_values",
      "input_ids",
      "attention_mask"
    ]
  },
  "MplugOwlForConditionalGeneration": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Q2VRankerStage1": {
    "__init__": [
      "self",
      "nscales",
      "hidden_dim"
    ],
    "forward": [
      "self",
      "ctx_feats",
      "qfeat"
    ]
  },
  "V2QRankerStage1": {
    "__init__": [
      "self",
      "nscales",
      "hidden_dim"
    ],
    "forward": [
      "self",
      "ctx_feats",
      "qfeat"
    ]
  },
  "Q2VRankerStage2": {
    "__init__": [
      "self",
      "nscales",
      "hidden_dim",
      "snippet_length"
    ],
    "forward": [
      "self",
      "vfeats",
      "qfeat",
      "hit_indices",
      "qv_ctx_scores"
    ]
  },
  "V2QRankerStage2": {
    "__init__": [
      "self",
      "nscales",
      "hidden_dim"
    ],
    "forward": [
      "self",
      "ctn_feats",
      "qfeat"
    ]
  },
  "V2VAttention": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "video_feats",
      "video_masks"
    ]
  },
  "BboxRegressor": {
    "__init__": [
      "self",
      "hidden_dim",
      "enable_stage2"
    ],
    "forward": [
      "self",
      "ctx_feats",
      "ctn_feats",
      "qfeat"
    ]
  },
  "PositionEncoding": {
    "__init__": [
      "self",
      "max_len",
      "dim",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "mask_logits": [
    "inputs",
    "mask",
    "mask_value"
  ],
  "WindowAttention_1D": {
    "__init__": [
      "self",
      "dim",
      "window_size",
      "num_heads",
      "qkv_bias",
      "attn_drop",
      "proj_drop",
      "pretrained_window_size"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "SwinTransformerBlock_1D": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "window_size",
      "shift_size",
      "mlp_ratio",
      "qkv_bias",
      "drop",
      "attn_drop",
      "drop_path",
      "act_layer",
      "norm_layer",
      "pretrained_window_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PatchEmbed1D": {
    "__init__": [
      "self",
      "patch_size",
      "in_chans",
      "embed_dim",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SwinTransformerV2_1D": {
    "__init__": [
      "self",
      "patch_size",
      "in_chans",
      "embed_dim",
      "depths",
      "num_heads",
      "window_size",
      "mlp_ratio",
      "qkv_bias",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "norm_layer",
      "patch_norm",
      "use_checkpoint",
      "pretrained_window_sizes"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "no_weight_decay": [
      "self"
    ],
    "no_weight_decay_keywords": [
      "self"
    ],
    "forward_features": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "decode_video": [
    "video_path",
    "target_fps"
  ],
  "SOONet": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self"
    ],
    "forward_train": [
      "self"
    ],
    "forward_test": [
      "self",
      "query_feats",
      "video_feats",
      "start_ts",
      "end_ts",
      "scale_boundaries"
    ]
  },
  "StableDiffusionXL": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "tokenize_caption": [
      "self",
      "tokenizer",
      "captions"
    ],
    "compute_time_ids": [
      "self",
      "original_size",
      "crops_coords_top_left"
    ],
    "encode_prompt": [
      "self",
      "text_encoders",
      "tokenizers",
      "prompt",
      "text_input_ids_list"
    ],
    "preprocessing_data": [
      "self",
      "text",
      "target"
    ],
    "forward": [
      "self",
      "text",
      "target"
    ],
    "save_pretrained": [
      "self",
      "target_folder",
      "save_checkpoint_names",
      "save_function",
      "config",
      "save_config_function"
    ]
  },
  "StableDiffusion": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "tokenize_caption": [
      "self",
      "captions"
    ],
    "forward": [
      "self",
      "text",
      "target"
    ],
    "save_pretrained": [
      "self",
      "target_folder",
      "save_checkpoint_names",
      "save_function",
      "config",
      "save_config_function"
    ]
  },
  "ImageToVideo": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "build_noise": [
      "self"
    ]
  },
  "fn": [
    "u"
  ],
  "Img2VidSDUNet": {
    "__init__": [
      "self",
      "in_dim",
      "dim",
      "y_dim",
      "num_tokens",
      "context_dim",
      "out_dim",
      "dim_mult",
      "num_heads",
      "head_dim",
      "num_res_blocks",
      "attn_scales",
      "use_scale_shift_norm",
      "dropout",
      "default_fps",
      "temporal_attn_times",
      "temporal_attention",
      "use_checkpoint",
      "use_image_dataset",
      "use_sim_mask",
      "training",
      "inpainting"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "y",
      "fps",
      "video_mask",
      "focus_present_mask",
      "prob_focus_present",
      "mask_last_frame_num"
    ],
    "_forward_single": [
      "self",
      "module",
      "x",
      "e",
      "context",
      "time_rel_pos_bias",
      "focus_present_mask",
      "video_mask",
      "reference"
    ]
  },
  "CrossConfig": {
    "__init__": [
      "self",
      "vocab_size_or_config_json_file",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range"
    ]
  },
  "CrossModel": {
    "initialize_parameters": [
      "self"
    ],
    "__init__": [
      "self",
      "config"
    ],
    "build_attention_mask": [
      "self",
      "attention_mask"
    ],
    "forward": [
      "self",
      "concat_input",
      "concat_type",
      "attention_mask",
      "output_all_encoded_layers"
    ]
  },
  "PreTrainedModel": {
    "__init__": [
      "self",
      "config"
    ],
    "init_weights": [
      "self",
      "module"
    ],
    "resize_token_embeddings": [
      "self",
      "new_num_tokens"
    ],
    "init_preweight": [
      "cls",
      "model",
      "state_dict",
      "prefix",
      "task_config"
    ],
    "dtype": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "config",
      "state_dict"
    ]
  },
  "PatchShiftModule": {
    "__init__": [
      "self",
      "net",
      "video_frame",
      "n_div"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask",
      "need_weights",
      "attn_mask"
    ]
  },
  "make_patch_shift": [
    "net",
    "video_frame",
    "shift_layers",
    "n_div"
  ],
  "Event_Layer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "dim_feedforward",
      "dropout",
      "activation",
      "normalize_before",
      "is_weights"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "pos",
      "query_pos"
    ]
  },
  "adaptive_mask": [
    "aa",
    "bb",
    "ada_para"
  ],
  "Frame_Layer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "dim_feedforward",
      "para",
      "dropout",
      "activation",
      "normalize_before",
      "is_weights"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "pos",
      "query_pos"
    ]
  },
  "TransDecoder": {
    "__init__": [
      "self",
      "decoder_layer",
      "num_layers",
      "norm",
      "return_intermediate"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "pos",
      "query_pos"
    ]
  },
  "Event_decoder": {
    "__init__": [
      "self",
      "num_attris",
      "layers",
      "heads",
      "dim_ftr",
      "pos_emb",
      "length",
      "dim_feedforward",
      "without_init"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "Frame_decoder": {
    "__init__": [
      "self",
      "num_attris",
      "layers",
      "heads",
      "dim_ftr",
      "pos_emb",
      "length",
      "dim_feedforward",
      "without_init"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "MyObject": {
    "__init__": [
      "self"
    ]
  },
  "CLIP4ClipPreTrainedModel": {
    "__init__": [
      "self",
      "cross_config"
    ],
    "from_pretrained": [
      "cls",
      "cross_config",
      "state_dict",
      "cache_dir",
      "type_vocab_size"
    ]
  },
  "show_log": [
    "task_config",
    "info"
  ],
  "update_attr": [
    "target_name",
    "target_config",
    "target_attr_name",
    "source_config",
    "source_attr_name",
    "default_value"
  ],
  "check_attr": [
    "target_name",
    "task_config"
  ],
  "PreCrossConfig": {
    "from_dict": [
      "cls",
      "json_object"
    ],
    "from_json_file": [
      "cls",
      "json_file"
    ],
    "__repr__": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "to_json_string": [
      "self"
    ]
  },
  "ProSTForTVRetrieval": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "_get_text": [
      "self",
      "caption",
      "tokenizer",
      "enable_zh"
    ],
    "_get_rawvideo_dec": [
      "self",
      "video_path",
      "rawVideoExtractor",
      "local_transform",
      "s",
      "e"
    ],
    "forward": [
      "self",
      "input"
    ],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "logging": [],
  "drop_grid": [
    "grid_map",
    "drop_range",
    "training"
  ],
  "GumbelSample": {
    "__init__": [
      "self",
      "in_dim",
      "num_keep"
    ],
    "forward": [
      "self",
      "x",
      "tau"
    ],
    "sample": [
      "self",
      "x",
      "topk_mask",
      "gumbel_hard"
    ],
    "random_sample": [
      "self",
      "x"
    ],
    "restore": [
      "self",
      "x",
      "topk_mask",
      "src"
    ]
  },
  "FPNTrans": {
    "__init__": [
      "self",
      "trans_layers",
      "inner_channels",
      "img_size",
      "inner_vit",
      "out_sampling"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "custom_tokenize": [
    "tokenizer",
    "text"
  ],
  "ImageProcessor": {
    "__init__": [
      "self",
      "do_preprocess",
      "do_resize",
      "image_size",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "apply_ocr"
    ],
    "preprocess": [
      "self",
      "image"
    ],
    "__call__": [
      "self",
      "images"
    ]
  },
  "OCRUtils": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "ocr_infos"
    ]
  },
  "bound_box": [
    "box",
    "height",
    "width"
  ],
  "bbox2pto4p": [
    "box2p"
  ],
  "bbox4pto2p": [
    "box4p"
  ],
  "stack_tensor_dict": [
    "tensor_dicts"
  ],
  "TextLayoutSerializer": {
    "__init__": [
      "self",
      "max_seq_length",
      "max_block_num",
      "tokenizer",
      "width",
      "height",
      "use_roberta_tokenizer",
      "ocr_utils"
    ],
    "label2seq": [
      "self",
      "ocr_info",
      "label_info"
    ],
    "serialize_single": [
      "self",
      "ocr_info",
      "input_ids",
      "bbox_line",
      "bbox_word",
      "width",
      "height"
    ],
    "ocr_info2seq": [
      "self",
      "ocr_info",
      "width",
      "height"
    ],
    "halfseq2seq": [
      "self",
      "input_ids",
      "bbox_line",
      "bbox_word",
      "width",
      "height"
    ],
    "__call__": [
      "self",
      "ocr_infos",
      "input_ids",
      "bboxes_line",
      "bboxes_word",
      "sizes_raw"
    ]
  },
  "GeoVLDocModelOutputs": {
    "__init__": [
      "self",
      "text_features",
      "text_mm_features",
      "block_vis_features",
      "block_vis_mm_features",
      "image_mm_features"
    ]
  },
  "GeoVLDocModel": {
    "__init__": [
      "self",
      "config",
      "hard_negtive_sampling"
    ],
    "from_pretrained": [
      "self",
      "ckpt_path"
    ],
    "forward": [
      "self",
      "input_ids",
      "image",
      "bbox",
      "bbox_4p_normalized",
      "attention_mask",
      "first_token_idxes",
      "first_token_idxes_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "VLDocForDocVLEmbedding": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input_ids",
      "image",
      "bbox",
      "bbox_4p_normalized",
      "attention_mask",
      "first_token_idxes",
      "first_token_idxes_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "init_pretrained_weight": [
    "model",
    "pretrained_model_path",
    "state_dict",
    "cache_dir",
    "init_backbone"
  ],
  "LayoutRobertaConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "bbox_scale",
      "pe_type",
      "position_embedding_type",
      "use_cache",
      "classifier_dropout"
    ]
  },
  "PositionalEmbedding1D": {
    "__init__": [
      "self",
      "demb"
    ],
    "forward": [
      "self",
      "pos_seq",
      "bsz"
    ]
  },
  "PositionalEmbedding2D": {
    "__init__": [
      "self",
      "demb",
      "dim_bbox"
    ],
    "forward": [
      "self",
      "bbox"
    ]
  },
  "LayoutRobertaEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "_cal_spatial_position_embeddings": [
      "self",
      "bbox"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ],
    "calc_bbox_pos_emb": [
      "self",
      "bbox",
      "pe_type"
    ],
    "create_position_ids_from_inputs_embeds": [
      "self",
      "inputs_embeds"
    ]
  },
  "LayoutRobertaSelfAttention": {
    "__init__": [
      "self",
      "config",
      "position_embedding_type"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "bbox_pos_emb",
      "bbox_pos_mask"
    ]
  },
  "LayoutRobertaSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "LayoutRobertaAttention": {
    "__init__": [
      "self",
      "config",
      "position_embedding_type"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "bbox_pos_emb",
      "bbox_pos_mask"
    ]
  },
  "LayoutRobertaIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LayoutRobertaOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "LayoutRobertaLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "bbox_pos_emb",
      "bbox_pos_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ]
  },
  "LayoutRobertaEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "bbox_pos_emb",
      "bbox_pos_mask"
    ]
  },
  "LayoutRobertaPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LayoutRobertaPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "update_keys_to_ignore": [
      "self",
      "config",
      "del_keys_to_ignore"
    ]
  },
  "LayoutRobertaModel": {
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "bbox_mask",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "create_position_ids_from_input_ids": [
    "input_ids",
    "padding_idx",
    "past_key_values_length"
  ],
  "SPIECE_UNDERLINE": [],
  "VLDocXLMTokenizer": {
    "model_input_names": []
  },
  "WEIGHTS_NAME": [],
  "BertSelfAttentionWithRelationsRAT": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "relation"
    ]
  },
  "BertSelfAttentionWithRelationsTableformer": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "relation"
    ]
  },
  "SqlBertEncoder": {
    "__init__": [
      "self",
      "layers",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_all_encoded_layers"
    ]
  },
  "PreTrainedBertModel": {
    "__init__": [
      "self",
      "config"
    ],
    "init_bert_weights": [
      "self",
      "module"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name",
      "state_dict",
      "cache_dir"
    ]
  },
  "SpaceTCnModel": {
    "__init__": [
      "self",
      "config",
      "schema_link_module"
    ],
    "forward": [
      "self",
      "input_ids",
      "header_ids",
      "token_order_ids",
      "token_type_ids",
      "attention_mask",
      "match_type_ids",
      "l_hs",
      "header_len",
      "type_ids",
      "col_dict_list",
      "ids",
      "header_flatten_tokens",
      "header_flatten_index",
      "header_flatten_output",
      "token_column_id",
      "token_column_mask",
      "column_start_index",
      "headers_length",
      "all_schema_link_matrix",
      "all_schema_link_mask",
      "output_all_encoded_layers"
    ]
  },
  "Seq2SQL": {
    "__init__": [
      "self",
      "iS",
      "hS",
      "lS",
      "dr",
      "n_cond_ops",
      "n_agg_ops",
      "n_action_ops",
      "max_select_num",
      "max_where_num",
      "device"
    ],
    "set_device": [
      "self",
      "device"
    ],
    "forward": [
      "self",
      "wemb_layer",
      "l_n",
      "l_hs",
      "start_index",
      "column_index",
      "tokens",
      "ids"
    ]
  },
  "SpaceTCnConfig": {
    "__init__": [
      "self",
      "vocab_size_or_config_json_file",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range"
    ],
    "from_dict": [
      "cls",
      "json_object"
    ],
    "from_json_file": [
      "cls",
      "json_file"
    ],
    "__repr__": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "to_json_string": [
      "self"
    ]
  },
  "TableQuestionAnswering": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "to": [
      "self",
      "device"
    ],
    "convert_string": [
      "self",
      "pr_wvi",
      "nlu",
      "nlu_tt"
    ],
    "get_fields_info": [
      "self",
      "t1s",
      "tables",
      "train"
    ],
    "get_history_select_where": [
      "self",
      "his_sql",
      "header_len"
    ],
    "get_types_ids": [
      "self",
      "col_type"
    ],
    "generate_inputs": [
      "self",
      "nlu1_tok",
      "hs_t_1",
      "type_t",
      "unit_t",
      "his_sql",
      "q_know",
      "t_know",
      "s_link"
    ],
    "gen_l_hpu": [
      "self",
      "i_hds"
    ],
    "get_bert_output": [
      "self",
      "model_bert",
      "tokenizer",
      "nlu_t",
      "hs_t",
      "col_types",
      "units",
      "his_sql",
      "q_know",
      "t_know",
      "schema_link"
    ],
    "predict": [
      "self",
      "queries"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "_symmetric_kl_div": [
    "logits1",
    "logits2",
    "attention_mask"
  ],
  "compute_adv_loss": [
    "embedding",
    "model",
    "ori_logits",
    "ori_loss",
    "adv_grad_factor",
    "adv_bound",
    "sigma"
  ],
  "compute_adv_loss_pair": [
    "embedding",
    "model",
    "start_logits",
    "end_logits",
    "ori_loss",
    "adv_grad_factor",
    "adv_bound",
    "sigma"
  ],
  "PlugMentalForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "_forward_call": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "compute_loss": [
      "self",
      "outputs",
      "labels"
    ]
  },
  "SbertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length",
      "return_inputs_embeds"
    ]
  },
  "SbertSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "SbertSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "SbertAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "SbertIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SbertOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "SbertLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ]
  },
  "SbertEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "SbertPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AdapterModel": {
    "__init__": [
      "self",
      "args",
      "pretrained_model_config"
    ],
    "forward": [
      "self",
      "pretrained_model_outputs"
    ]
  },
  "PlugMentalPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "AttentionBackboneModelOutputWithEmbedding": {},
  "PlugMentalModel": {
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "PlugMentalConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "position_embedding_type",
      "use_cache",
      "classifier_dropout",
      "adapter_size",
      "adapter_transformer_layers",
      "adapter_list"
    ]
  },
  "T5Chat": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "generate": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "decoder_input_ids"
    ]
  },
  "EncoderWrapper": {
    "__init__": [
      "self",
      "encoder"
    ],
    "set_n_passages": [
      "self",
      "n_passages"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "FIDT5Chat": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "wrap_encoder": [
      "self"
    ],
    "unwrap_encoder": [
      "self"
    ],
    "load": [
      "self",
      "pretrained_model_path",
      "from_tf"
    ],
    "generate": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "input_ids",
      "decoder_input_ids"
    ]
  },
  "GPT2Model": {
    "__init__": [
      "self"
    ]
  },
  "PoNetPredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "PoNetLMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "PoNetOnlyMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output"
    ]
  },
  "PoNetForMaskedLM": {
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "segment_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "PoNetForDocumentSegmentation": {
    "_keys_to_ignore_on_load_unexpected": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "segment_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_instantiate": [
      "cls",
      "model_dir",
      "model_config"
    ]
  },
  "is_pytorch_12plus": [],
  "CLS_ID": [],
  "EOS_ID": [],
  "segment_max": [
    "src",
    "index",
    "dim"
  ],
  "get_segment_index": [
    "input_ids",
    "cls_id",
    "eos_id"
  ],
  "get_token_type_mask": [
    "input_ids",
    "cls_id",
    "eos_id"
  ],
  "get_win_max": [
    "hidden_states",
    "kernel_size"
  ],
  "PoNetEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ]
  },
  "PoNetSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "segment_index",
      "token_type_mask",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "PoNetSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "PoNetIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "PoNetOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "PoNetAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "segment_index",
      "token_type_mask",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "PoNetLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "segment_index",
      "token_type_mask",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ]
  },
  "PoNetEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "segment_index",
      "token_type_mask",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "PoNetPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "PoNetPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "PoNetModel": {
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "segment_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "PoNetConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "position_embedding_type",
      "use_cache",
      "classifier_dropout",
      "clsgsepg"
    ]
  },
  "PRETRAINED_INIT_CONFIGURATION": [],
  "PoNetTokenizer": {
    "vocab_files_names": [],
    "pretrained_vocab_files_map": [],
    "max_model_input_sizes": [],
    "pretrained_init_configuration": [],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ]
  },
  "BertForTextRanking": {
    "base_model_type": []
  },
  "BertForDocumentSegmentation": {
    "_keys_to_ignore_on_load_unexpected": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "sentence_attention_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_instantiate": [
      "cls",
      "model_dir",
      "model_config"
    ]
  },
  "MBertForWordAlignment": {
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "src_input_ids",
      "src_attention_mask",
      "src_b2w_map",
      "tgt_input_ids",
      "tgt_attention_mask",
      "tgt_b2w_map",
      "threshold",
      "bpe_level"
    ]
  },
  "SiameseUieModel": {
    "__init__": [
      "self",
      "config"
    ],
    "set_crossattention_layer": [
      "self",
      "num_hidden_layers"
    ],
    "circle_loss": [
      "self",
      "y_pred",
      "y_true"
    ],
    "get_cross_attention_output": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask"
    ],
    "get_plm_sequence_output": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "is_hint"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_masks",
      "hint_ids",
      "cross_attention_masks",
      "head_labels",
      "tail_labels"
    ],
    "fast_inference": [
      "self",
      "sequence_output",
      "attention_masks",
      "hint_ids",
      "cross_attention_masks"
    ]
  },
  "Pooler": {
    "__init__": [
      "self",
      "pooler_type"
    ],
    "forward": [
      "self",
      "outputs",
      "attention_mask"
    ]
  },
  "BertForSentenceEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "query",
      "docs",
      "labels"
    ],
    "encode": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "BertOnnxConfig": {
    "inputs": [
      "self"
    ]
  },
  "JiebaBPETokenizer": {
    "__init__": [
      "self",
      "tokenizer_json_file"
    ],
    "vocab_size": [
      "self"
    ],
    "vocab": [
      "self"
    ],
    "inv_vocab": [
      "self"
    ],
    "tokenize": [
      "self",
      "text",
      "is_code"
    ],
    "detokenize": [
      "self",
      "token_ids"
    ],
    "eod": [
      "self"
    ]
  },
  "GPTMoEParallelMLP": {
    "__init__": [
      "self",
      "config",
      "init_method",
      "output_layer_init_method",
      "moe",
      "enable_expert_tensor_parallelism"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPTMoEEmbedding": {
    "__init__": [
      "self",
      "config",
      "init_method"
    ],
    "zero_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ]
  },
  "NoopTransformerLayer": {
    "__init__": [
      "self",
      "layer_number"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_output",
      "enc_dec_attn_mask",
      "inference_params"
    ]
  },
  "attention_mask_func": [
    "attention_scores",
    "attention_mask"
  ],
  "GPTMoECoreAttention": {
    "__init__": [
      "self",
      "config",
      "layer_number",
      "attn_mask_type"
    ],
    "forward": [
      "self",
      "query_layer",
      "key_layer",
      "value_layer",
      "attention_mask"
    ]
  },
  "GPTMoEParallelAttention": {
    "__init__": [
      "self",
      "config",
      "init_method",
      "output_layer_init_method",
      "layer_number"
    ],
    "_allocate_memory": [
      "self",
      "inference_max_sequence_len",
      "batch_size"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "inference_params"
    ]
  },
  "nullcontext": {
    "__init__": [
      "self",
      "enter_result"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "bias_dropout_add": [
    "x",
    "bias",
    "residual",
    "prob",
    "training"
  ],
  "get_bias_dropout_add": [
    "training"
  ],
  "bias_dropout_add_fused_train": [
    "x",
    "bias",
    "residual",
    "prob"
  ],
  "bias_dropout_add_fused_inference": [
    "x",
    "bias",
    "residual",
    "prob"
  ],
  "GPTMoEParallelTransformerLayer": {
    "__init__": [
      "self",
      "config",
      "init_method",
      "output_layer_init_method",
      "layer_number",
      "num_experts"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "inference_params"
    ]
  },
  "GPTMoEParallelTransformer": {
    "__init__": [
      "self",
      "config",
      "init_method",
      "output_layer_init_method",
      "post_layer_norm",
      "pre_process",
      "post_process",
      "num_experts"
    ],
    "_get_layer": [
      "self",
      "layer_number"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "inference_params"
    ]
  },
  "GPTMoETransformerLanguageModel": {
    "__init__": [
      "self",
      "config",
      "init_method",
      "output_layer_init_method",
      "num_experts"
    ],
    "forward": [
      "self",
      "enc_input_ids",
      "enc_position_ids",
      "enc_attn_mask",
      "inference_params",
      "enc_hidden_states"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ]
  },
  "init_method_normal": [
    "sigma"
  ],
  "scaled_init_method_normal": [
    "sigma",
    "num_layers"
  ],
  "GPTMoEModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config",
      "parallel_output"
    ],
    "word_embeddings_weight": [
      "self"
    ],
    "build_attention_mask_and_position_ids": [
      "tokens"
    ],
    "post_language_model_processing": [
      "input_",
      "labels",
      "word_embeddings_weight",
      "sequence_parallel"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "inference_params",
      "labels"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ]
  },
  "modify_logits_for_top_k_filtering": [
    "logits",
    "top_k"
  ],
  "modify_logits_for_top_p_filtering": [
    "logits",
    "top_p"
  ],
  "sample": [
    "logits",
    "top_k",
    "top_p",
    "temperature",
    "vocab_size"
  ],
  "InferenceParams": {
    "__init__": [
      "self",
      "max_batch_size",
      "max_sequence_len"
    ],
    "swap_key_value_dict": [
      "self",
      "batch_idx"
    ]
  },
  "DistributedGPTMoE": {
    "__init__": [
      "self",
      "model_dir",
      "rank",
      "path_load_tag"
    ],
    "train": [
      "self",
      "mode"
    ],
    "forward": [
      "self",
      "tokens",
      "attention_mask",
      "position_ids",
      "labels",
      "prompt_length",
      "is_pair"
    ],
    "generate": [
      "self",
      "tokens",
      "temperature",
      "use_eod_token_for_early_termination",
      "stop_on_double_eol",
      "stop_on_eol"
    ]
  },
  "GPTMoEForTextGeneration": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "generate": [
      "self",
      "input"
    ]
  },
  "GPTMoESelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "_transpose_for_scores": [
      "self",
      "tensor"
    ],
    "_split_tensor_along_last_dim": [
      "self",
      "tensor",
      "num_partitions",
      "contiguous_split_chunks"
    ],
    "forward": [
      "self",
      "hidden_states",
      "ltor_mask",
      "is_infer"
    ]
  },
  "GPTMoEMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPTMoETransformerLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "ltor_mask"
    ]
  },
  "GPTMoETransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "_get_layer": [
      "self",
      "layer_number"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "GPTMoEConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "ffn_hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "layernorm_epsilon",
      "bias_gelu_fusion",
      "fp32_residual_connection",
      "sequence_parallel",
      "fp16",
      "bf16",
      "apply_query_key_layer_scaling",
      "attention_softmax_in_fp32",
      "kv_channels",
      "masked_softmax_fusion",
      "attention_dropout",
      "bias_dropout_fusion",
      "apply_residual_connection_post_layernorm",
      "hidden_dropout",
      "init_method_std",
      "eod_id",
      "tokens_to_generate",
      "top_k",
      "top_p",
      "num_experts",
      "use_tutel",
      "top_k_linear_strategy",
      "use_expert_residual_network",
      "load_ds_ckpts",
      "model_dir"
    ],
    "params_dtype": [
      "self"
    ]
  },
  "get_checkpoint_names": [
    "checkpoints_path",
    "path_load_tag",
    "num_experts",
    "tensor_rank",
    "expp_rank"
  ],
  "_get_expert_ckpt_name": [
    "checkpoints_path",
    "layer_id",
    "expert_id"
  ],
  "_load_base_checkpoint": [
    "load_dir",
    "path_load_tag",
    "num_experts"
  ],
  "load_moe_checkpoint": [
    "model",
    "state_dict",
    "load_dir"
  ],
  "multiplicative_jitter": [
    "x",
    "device",
    "epsilon"
  ],
  "gumbel_rsample": [
    "shape",
    "device"
  ],
  "_AllToAll": {
    "forward": [
      "ctx",
      "group",
      "input"
    ],
    "backward": [
      "ctx"
    ]
  },
  "USE_EINSUM": [],
  "einsum": [
    "rule",
    "a",
    "b"
  ],
  "_capacity": [
    "gates",
    "capacity_factor",
    "min_capacity"
  ],
  "_top_idx": [
    "source",
    "k"
  ],
  "_one_hot_to_float": [
    "x",
    "num_classes"
  ],
  "top1gating": [
    "logits",
    "capacity_factor",
    "min_capacity",
    "used_token",
    "noisy_gate_policy",
    "drop_tokens",
    "use_rts",
    "use_tutel"
  ],
  "TopKGate": {
    "__init__": [
      "self",
      "model_dim",
      "num_experts",
      "k",
      "capacity_factor",
      "eval_capacity_factor",
      "min_capacity",
      "noisy_gate_policy",
      "drop_tokens",
      "use_rts",
      "top_k_linear_strategy"
    ],
    "forward": [
      "self",
      "input",
      "used_token",
      "use_tutel"
    ]
  },
  "MOELayer": {
    "__init__": [
      "self",
      "gate",
      "experts",
      "ep_group_name",
      "ep_size",
      "num_local_experts",
      "use_tutel",
      "use_expert_residual_network"
    ],
    "_set_ep_group": [
      "self",
      "ep_group"
    ],
    "forward": [
      "self"
    ]
  },
  "LSoftmaxLinearLayer": {
    "__init__": [
      "self",
      "input_features",
      "output_features",
      "margin"
    ],
    "calculate_cos_m_theta": [
      "self",
      "cos_theta",
      "device"
    ],
    "reset_parameters": [
      "self"
    ],
    "find_k": [
      "self",
      "cos"
    ],
    "forward": [
      "self",
      "input",
      "device",
      "training"
    ]
  },
  "ExpertResidualLayer": {
    "__init__": [
      "self",
      "embed_dim"
    ],
    "forward": [
      "self",
      "xs"
    ]
  },
  "_gather_tokens": [
    "input_",
    "dim"
  ],
  "_drop_tokens": [
    "input_",
    "dim"
  ],
  "_GatherTokens": {
    "symbolic": [
      "graph",
      "input_",
      "dim"
    ],
    "forward": [
      "ctx",
      "input_",
      "dim"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "_DropTokens": {
    "symbolic": [
      "graph",
      "input_",
      "dim"
    ],
    "forward": [
      "ctx",
      "input_",
      "dim"
    ],
    "backward": [
      "ctx",
      "input_"
    ]
  },
  "gather_tokens": [
    "input_",
    "dim"
  ],
  "drop_tokens": [
    "input_",
    "dim"
  ],
  "has_moe_layers": [
    "m"
  ],
  "is_moe_param": [
    "param"
  ],
  "split_params_into_shared_and_expert_params": [
    "params"
  ],
  "split_params_grads_into_shared_and_expert_params": [
    "group"
  ],
  "split_params_into_different_moe_groups_for_optimizer": [
    "param_groups"
  ],
  "MoE": {
    "__init__": [
      "self",
      "hidden_size",
      "expert",
      "num_experts",
      "ep_size",
      "k",
      "capacity_factor",
      "eval_capacity_factor",
      "min_capacity",
      "use_residual",
      "noisy_gate_policy",
      "drop_tokens",
      "use_rts",
      "use_tutel",
      "top_k_linear_strategy",
      "use_expert_residual_network"
    ],
    "forward": [
      "self",
      "hidden_states",
      "used_token"
    ]
  },
  "Experts": {
    "__init__": [
      "self",
      "expert",
      "num_local_experts",
      "expert_group_name"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "XLMRobertaEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ],
    "create_position_ids_from_inputs_embeds": [
      "self",
      "inputs_embeds"
    ]
  },
  "XLMRobertaSelfAttention": {
    "__init__": [
      "self",
      "config",
      "position_embedding_type"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "XLMRobertaSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "XLMRobertaAttention": {
    "__init__": [
      "self",
      "config",
      "position_embedding_type"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "XLMRobertaIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "XLMRobertaOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "XLMRobertaLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ]
  },
  "XLMRobertaEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "XLMRobertaPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "XLMRobertaPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "update_keys_to_ignore": [
      "self",
      "config",
      "del_keys_to_ignore"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "XLMRobertaModel": {
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "XLMRobertaConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "position_embedding_type",
      "use_cache",
      "classifier_dropout"
    ]
  },
  "XLMRobertaOnnxConfig": {
    "inputs": [
      "self"
    ]
  },
  "add_model_config_args": [
    "parser"
  ],
  "add_fp16_config_args": [
    "parser"
  ],
  "add_training_args": [
    "parser"
  ],
  "add_evaluation_args": [
    "parser"
  ],
  "add_text_generate_args": [
    "parser"
  ],
  "add_data_args": [
    "parser"
  ],
  "add_finetune_config_args": [
    "parser"
  ],
  "mpi_define_env": [
    "args"
  ],
  "setup_args": [
    "args"
  ],
  "get_masks_and_position_ids": [
    "data",
    "eod_token",
    "reset_position_ids",
    "reset_attention_mask",
    "loss_mask",
    "attention_mask",
    "set_loss_mask",
    "mem_length"
  ],
  "get_batch": [
    "context_tokens",
    "device",
    "args"
  ],
  "top_k_logits": [
    "logits",
    "top_k",
    "top_p",
    "filter_value"
  ],
  "sample_sequence": [
    "model",
    "tokenizer",
    "context_tokens",
    "context_length",
    "args",
    "device",
    "mems",
    "end_tokens"
  ],
  "read_context": [
    "tokenizer",
    "args",
    "context"
  ],
  "MGLMForTextSummarization": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "generate": [
      "self",
      "input"
    ]
  },
  "SUMMARY_WRITER_DIR_NAME": [],
  "get_log_dir": [
    "name",
    "base"
  ],
  "get_hostname": [],
  "get_spare_port": [
    "args"
  ],
  "print_and_save_args": [
    "args",
    "verbose",
    "log_dir"
  ],
  "print_params_min_max_norm": [
    "optimizer",
    "iteration"
  ],
  "Timers": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "name"
    ],
    "log": [
      "self",
      "names",
      "normalizer",
      "reset"
    ]
  },
  "report_memory": [
    "name"
  ],
  "get_checkpoint_name": [
    "checkpoints_path",
    "iteration",
    "release",
    "zero"
  ],
  "ensure_directory_exists": [
    "filename"
  ],
  "get_checkpoint_tracker_filename": [
    "checkpoints_path"
  ],
  "save_zero_checkpoint": [
    "args",
    "iteration",
    "optimizer"
  ],
  "save_ds_checkpoint": [
    "iteration",
    "model",
    "lr_scheduler",
    "args",
    "tag"
  ],
  "get_checkpoint_iteration": [
    "load_path"
  ],
  "load_weights": [
    "src",
    "dst",
    "dst2src"
  ],
  "load_mlp": [
    "our",
    "oai",
    "dst2src"
  ],
  "load_attention": [
    "our",
    "oai",
    "dst2src"
  ],
  "load_transformer_layer": [
    "our",
    "oai",
    "dst2src"
  ],
  "move_weights": [
    "our",
    "oai",
    "dst2src"
  ],
  "debug_finetune_data": [
    "local_vars",
    "batch_id",
    "tokenizer"
  ],
  "get_optimizer_param_groups": [
    "model"
  ],
  "get_learning_rate_scheduler": [
    "optimizer",
    "args"
  ],
  "setup_model_and_optimizer": [
    "args",
    "model_type",
    "multi_token",
    "num_labels",
    "spell_length"
  ],
  "backward_step": [
    "optimizer",
    "model",
    "lm_loss",
    "args",
    "timers"
  ],
  "see_memory_usage": [
    "message",
    "force"
  ],
  "train_step": [
    "data_iterator",
    "model",
    "optimizer",
    "lr_scheduler",
    "args",
    "timers",
    "forward_step_func",
    "mems",
    "single_step"
  ],
  "MultiTaskDataset": {
    "__init__": [
      "self",
      "tasks",
      "datasets",
      "reweight",
      "temperature",
      "max_limit"
    ],
    "__len__": [
      "self"
    ],
    "pet_wrapper": [
      "data"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "DataConfig": {
    "__init__": [
      "self",
      "defaults"
    ],
    "apply": [
      "self",
      "args",
      "tokenizer"
    ],
    "set_defaults": [
      "self"
    ],
    "apply_defaults": [
      "self",
      "args"
    ]
  },
  "prepare_tokenizer": [
    "args"
  ],
  "make_data_loader": [
    "dataset",
    "tokenizer",
    "batch_size",
    "num_iters",
    "args",
    "shuffle",
    "block_collate"
  ],
  "make_tfrecord_loaders": [
    "args"
  ],
  "make_loaders": [
    "args",
    "tokenizer"
  ],
  "build_multi_task_dataset": [
    "args",
    "tokenizer"
  ],
  "get_split": [
    "args"
  ],
  "configure_data": [],
  "PROCESS_INPUTS_DOCSTRING": [],
  "FINALIZE_INPUTS_DOCSTRING": [],
  "BeamScorer": {
    "process": [
      "self",
      "input_ids",
      "next_scores",
      "next_tokens",
      "next_indices"
    ],
    "finalize": [
      "self",
      "input_ids",
      "next_scores",
      "next_tokens",
      "next_indices"
    ]
  },
  "BeamSearchScorer": {
    "__init__": [
      "self",
      "batch_size",
      "max_length",
      "num_beams",
      "device",
      "length_penalty",
      "do_early_stopping",
      "num_beam_hyps_to_keep"
    ],
    "is_done": [
      "self"
    ],
    "process": [
      "self",
      "input_ids",
      "next_scores",
      "next_tokens",
      "next_indices",
      "pad_token_id",
      "eos_token_id",
      "mems"
    ],
    "finalize": [
      "self",
      "input_ids",
      "final_beam_scores",
      "final_beam_tokens",
      "final_beam_indices",
      "pad_token_id",
      "eos_token_id",
      "mems"
    ]
  },
  "BeamHypotheses": {
    "__init__": [
      "self",
      "num_beams",
      "max_length",
      "length_penalty",
      "early_stopping"
    ],
    "__len__": [
      "self"
    ],
    "add": [
      "self",
      "hyp",
      "sum_logprobs",
      "mems"
    ],
    "is_done": [
      "self",
      "best_sum_logprobs",
      "cur_len"
    ]
  },
  "LogitsProcessor": {
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "LogitsProcessorList": {
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "MinLengthLogitsProcessor": {
    "__init__": [
      "self",
      "min_length",
      "eos_token_id"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "NoRepeatNGramLogitsProcessor": {
    "__init__": [
      "self",
      "ngram_size"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ],
    "_calc_banned_ngram_tokens": [
      "self",
      "prev_input_ids",
      "num_hypos",
      "cur_len"
    ]
  },
  "path_pattern": [],
  "target_type": [],
  "mean_result": [],
  "rindex": [
    "lst",
    "val",
    "start"
  ],
  "index_in_list": [
    "lst",
    "val",
    "start"
  ],
  "ConstructBlockStrategy": {
    "__init__": [
      "self",
      "args",
      "tokenizer",
      "max_seq_length",
      "bert_prob",
      "gap_sentence_prob",
      "gpt_infill_prob",
      "gpt_min_ratio",
      "bert_ratio",
      "gap_sentence_ratio",
      "average_block_length",
      "max_block_length",
      "block_mask_prob",
      "context_mask_ratio",
      "context_mask_range",
      "short_seq_prob",
      "single_span_prob",
      "block_position_encoding",
      "encoder_decoder",
      "shuffle_blocks",
      "sentinel_token",
      "task_mask",
      "random_position",
      "masked_lm"
    ],
    "contains_sentence_end": [
      "self",
      "tok"
    ],
    "sample_spans": [
      "span_lengths",
      "total_length",
      "rng",
      "offset"
    ],
    "sample_span_in_document": [
      "self",
      "tokens",
      "masked_lengths",
      "rng"
    ],
    "make_masked_data": [
      "self",
      "tokens",
      "loss_masks",
      "attention_mask",
      "block_spans",
      "rng",
      "task"
    ],
    "make_block_data": [
      "self",
      "tokens",
      "loss_masks",
      "attention_mask",
      "block_spans",
      "rng",
      "task"
    ],
    "generate_blank_data": [
      "self",
      "sample",
      "masked_lengths",
      "attention_mask",
      "rng",
      "task"
    ],
    "split_samples": [
      "self",
      "samples",
      "rng"
    ],
    "construct_blocks": [
      "self",
      "samples"
    ],
    "pad_batch": [
      "token_batch",
      "target_batch",
      "loss_mask_batch",
      "position_id_batch"
    ]
  },
  "main": [],
  "NLTKSegmenter": {
    "__init": [
      "self"
    ],
    "segment_string": [
      "article"
    ]
  },
  "download_nltk": [],
  "url_to_filename": [
    "url",
    "etag"
  ],
  "filename_to_url": [
    "filename",
    "cache_dir"
  ],
  "cached_path": [
    "url_or_filename",
    "cache_dir"
  ],
  "split_s3_path": [
    "url"
  ],
  "s3_request": [
    "func"
  ],
  "s3_etag": [
    "url"
  ],
  "s3_get": [
    "url",
    "temp_file"
  ],
  "http_get": [
    "url",
    "temp_file"
  ],
  "get_from_cache": [
    "url",
    "cache_dir"
  ],
  "read_set_from_file": [
    "filename"
  ],
  "get_file_extension": [
    "path",
    "dot",
    "lower"
  ],
  "Encoder_SP": {
    "__init__": [
      "self",
      "model_path"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "tokens"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "convert_token_to_id": [
      "self",
      "token"
    ],
    "convert_id_to_token": [
      "self",
      "idx"
    ]
  },
  "from_pretrained": [
    "model_path"
  ],
  "TRAIN_DATA": [],
  "VAL_DATA": [],
  "TEST_DATA": [],
  "should_split": [
    "split"
  ],
  "get_ext": [
    "path"
  ],
  "get_dataset": [
    "name",
    "tokenizer",
    "pre_tokenize",
    "data_parallel_rank",
    "loader_scatter",
    "no_lazy_loader",
    "half_lazy_loader"
  ],
  "supported_corpus": [
    "corpus_name"
  ],
  "make_dataset": [
    "path",
    "seq_length",
    "mem_length",
    "shuffle",
    "split",
    "tokenizer",
    "sample_one_document",
    "pre_tokenize",
    "ds_type",
    "save_splits",
    "load_splits",
    "save_test_data",
    "no_lazy_loader",
    "loader_scatter",
    "data_parallel_rank",
    "filter_english",
    "non_sentence_start",
    "half_lazy_loader"
  ],
  "ShuffleDataset": {
    "__init__": [
      "self",
      "ds"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ]
  },
  "ConcatDataset": {
    "cumsum": [
      "sequence"
    ],
    "__init__": [
      "self",
      "datasets"
    ],
    "get_text_len": [
      "self",
      "idx"
    ],
    "SetTokenizer": [
      "self",
      "tokenizer"
    ],
    "GetTokenizer": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "lens": [
      "self"
    ],
    "X": [
      "self"
    ],
    "Y": [
      "self"
    ]
  },
  "SplitDataset": {
    "__init__": [
      "self",
      "ds",
      "split_inds"
    ],
    "__len__": [
      "self"
    ],
    "get_text_len": [
      "self",
      "idx"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "SetTokenizer": [
      "self",
      "tokenizer"
    ],
    "GetTokenizer": [
      "self"
    ],
    "X": [
      "self"
    ],
    "Y": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "split_ds": [
    "ds",
    "split",
    "shuffle",
    "save_splits",
    "load_splits"
  ],
  "csv_dataset": {
    "__init__": [
      "self",
      "path",
      "tokenizer",
      "preprocess_fn",
      "delim",
      "binarize_sent",
      "drop_unlabeled",
      "text_key",
      "label_key"
    ],
    "SetTokenizer": [
      "self",
      "tokenizer"
    ],
    "GetTokenizer": [
      "self"
    ],
    "tokenizer": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "write": [
      "self",
      "writer_gen",
      "path",
      "skip_header"
    ]
  },
  "json_dataset": {
    "__init__": [
      "self",
      "path",
      "tokenizer",
      "preprocess_fn",
      "binarize_sent",
      "text_key",
      "label_key",
      "loose_json"
    ],
    "SetTokenizer": [
      "self",
      "tokenizer"
    ],
    "GetTokenizer": [
      "self"
    ],
    "tokenizer": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "write": [
      "self",
      "writer_gen",
      "path",
      "skip_header"
    ],
    "save_json_stream": [
      "self",
      "save_path",
      "json_stream"
    ],
    "load_json_stream": [
      "self",
      "load_path"
    ]
  },
  "XLDataset": {
    "__init__": [
      "self",
      "ds",
      "tokenizer",
      "max_seq_len",
      "mem_len",
      "sample_across_doc"
    ],
    "init_indices": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "getidx": [
      "self",
      "idx"
    ],
    "pad_seq": [
      "self",
      "seq",
      "pad_id"
    ]
  },
  "BlockDataset": {
    "__init__": [
      "self",
      "ds",
      "tokenizer",
      "max_seq_len",
      "sample_across_doc",
      "non_sentence_start",
      "filter_english"
    ],
    "init_weighting": [
      "self"
    ],
    "get_weighted_samples": [
      "self",
      "np_rng"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "right_strip_seq": [
      "self",
      "tokens",
      "loss_mask",
      "seq_length"
    ],
    "getidx": [
      "self",
      "data_idx"
    ],
    "pad_seq": [
      "self",
      "seq",
      "pad_id"
    ],
    "contains_sentence_end": [
      "self",
      "tok"
    ]
  },
  "GPT2Dataset": {
    "__init__": [
      "self",
      "ds",
      "tokenizer",
      "max_seq_len",
      "num_samples",
      "weighted",
      "sample_across_doc",
      "random_across_doc_sampling",
      "sentence_start"
    ],
    "init_weighting": [
      "self"
    ],
    "get_weighted_samples": [
      "self",
      "np_rng"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "getidx": [
      "self",
      "data_idx"
    ],
    "pad_seq": [
      "self",
      "seq",
      "pad_id"
    ],
    "contains_sentence_end": [
      "self",
      "tok"
    ]
  },
  "BertSentencepairDataset": {
    "__init__": [
      "self",
      "ds",
      "max_seq_len",
      "mask_lm_prob",
      "max_preds_per_seq",
      "short_seq_prob",
      "dataset_size",
      "presplit_sentences",
      "weighted"
    ],
    "get_weighting": [
      "self"
    ],
    "get_weighted_samples": [
      "self",
      "np_rng"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "sentence_split": [
      "self",
      "document"
    ],
    "sentence_tokenize": [
      "self",
      "sent",
      "sentence_num",
      "beginning",
      "ending"
    ],
    "get_doc": [
      "self",
      "idx"
    ],
    "create_random_sentencepair": [
      "self",
      "target_seq_length",
      "rng",
      "np_rng"
    ],
    "truncate_seq_pair": [
      "self",
      "a",
      "b",
      "max_seq_len",
      "rng"
    ],
    "mask_token": [
      "self",
      "idx",
      "tokens",
      "types",
      "vocab_words",
      "rng"
    ],
    "pad_seq": [
      "self",
      "seq"
    ],
    "create_masked_lm_predictions": [
      "self",
      "a",
      "b",
      "mask_lm_prob",
      "max_preds_per_seq",
      "vocab_words",
      "rng"
    ]
  },
  "NUM_PROCESSES": [],
  "punctuation_standardization": [
    "string"
  ],
  "KeyDataset": {
    "__init__": [
      "self",
      "text_loader",
      "mask_loader"
    ],
    "get_text_len": [
      "self",
      "idx"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "DataReader": {
    "PATH": [],
    "assert_str": [],
    "reserve_punct": [],
    "split_row": [],
    "TASK_QUEUE_LIMIT": [],
    "DONE_QUEUE_LIMIT": [],
    "tokenize_worker": [
      "self",
      "input",
      "output",
      "info",
      "tokenizer",
      "tokenize"
    ],
    "print_info": [
      "self",
      "info"
    ],
    "__init__": [
      "self",
      "writers",
      "tokenizer",
      "tokenize"
    ],
    "process": [
      "self"
    ],
    "write_result": [
      "data",
      "writers"
    ],
    "get_token_count": [
      "contents"
    ],
    "process_sample": [
      "cls",
      "text",
      "tokenizer",
      "tokenize"
    ],
    "trim_field": [
      "content",
      "max_length"
    ],
    "process_line": [
      "self",
      "data",
      "tokenizer",
      "tokenize"
    ]
  },
  "PromptReader": {
    "is_json": [],
    "tokenize_worker": [
      "self",
      "input",
      "output",
      "info",
      "tokenizer",
      "tokenize"
    ],
    "write_result": [
      "data",
      "writers"
    ]
  },
  "KeyReader": {
    "PATH": [],
    "assert_str": [],
    "process_line": [
      "self",
      "data",
      "tokenizer",
      "tokenize"
    ],
    "tokenize_worker": [
      "self",
      "input",
      "output",
      "info",
      "tokenizer",
      "tokenize"
    ],
    "write_result": [
      "data",
      "writers"
    ]
  },
  "zhihu": {
    "PATH": [],
    "reserve_punct": [],
    "assert_str": [],
    "qtitle_prefix": [],
    "qcontent_prefix": [],
    "user_prefix": [],
    "answer_prefix": [],
    "process_line": [
      "self",
      "data",
      "tokenizer",
      "tokenize"
    ]
  },
  "zhidao": {
    "PATH": [],
    "reserve_punct": [],
    "assert_str": [],
    "qtitle_prefix": [],
    "qcontent_prefix": [],
    "answer_prefix": [],
    "process_line": [
      "self",
      "data",
      "tokenizer",
      "tokenize"
    ]
  },
  "baike": {
    "PATH": [],
    "reserve_punct": [],
    "assert_str": [],
    "process_line": [
      "self",
      "data",
      "tokenizer",
      "tokenize"
    ]
  },
  "wikipedia": {
    "PATH": [],
    "assert_str": [],
    "process_line": [
      "self",
      "data",
      "tokenizer",
      "tokenize"
    ]
  },
  "TestDataset": {
    "PATH": [],
    "assert_str": [],
    "process_line": [
      "self",
      "data",
      "tokenizer",
      "tokenize"
    ]
  },
  "OpenWebText": {
    "PATH": [],
    "assert_str": [],
    "__init__": [
      "self"
    ],
    "process_line": [
      "self",
      "data",
      "tokenizer",
      "tokenize"
    ]
  },
  "CCNews": {
    "PATH": [],
    "assert_str": [],
    "process_line": [
      "self",
      "data",
      "tokenizer",
      "tokenize"
    ]
  },
  "BertData": {
    "is_json": [],
    "PATH": [],
    "process_line": [
      "self",
      "data",
      "tokenizer",
      "tokenize"
    ]
  },
  "Pile": {
    "is_json": [],
    "PATH": [],
    "filtered_sources": [],
    "downsample_sources": [],
    "print_info": [
      "self",
      "info"
    ],
    "tokenize_worker": [
      "self",
      "input",
      "output",
      "info",
      "tokenizer",
      "tokenize"
    ],
    "process_line": [
      "self",
      "data",
      "tokenizer",
      "tokenize"
    ]
  },
  "Stories": {
    "is_json": [],
    "PATH": [],
    "process_line": [
      "self",
      "data",
      "tokenizer",
      "tokenize"
    ]
  },
  "BertBaseData": {
    "PATH": []
  },
  "BertLargeData": {
    "PATH": []
  },
  "WuDaoCorpus": {
    "PATH": [],
    "is_json": [],
    "reserve_punct": [],
    "split_row": [],
    "process_line": [
      "self",
      "item",
      "tokenizer",
      "tokenize"
    ]
  },
  "NAMED_CORPORA": [],
  "PRETRAINED_VOCAB_ARCHIVE_MAP": [],
  "PRETRAINED_MERGES_ARCHIVE_MAP": [],
  "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP": [],
  "VOCAB_NAME": [],
  "MERGES_NAME": [],
  "SPECIAL_TOKENS_NAME": [],
  "get_lazy_path": [
    "path"
  ],
  "exists_lazy": [
    "path",
    "data_type"
  ],
  "get_scatter_path": [
    "path",
    "scatter_rank"
  ],
  "exists_scatter": [
    "path",
    "scatter_num",
    "data_type"
  ],
  "LazyWriter": {
    "__init__": [
      "self",
      "path",
      "data_type",
      "is_array",
      "array_data_type"
    ],
    "get_len_path": [
      "path",
      "data_type"
    ],
    "write": [
      "self",
      "s"
    ],
    "close": [
      "self"
    ]
  },
  "split_strings": [
    "strings",
    "start",
    "chr_lens"
  ],
  "ProcessorTokenizer": {
    "__init__": [
      "self",
      "tokenizer",
      "process_fn"
    ],
    "__call__": [
      "self",
      "string"
    ]
  },
  "LazyLoader": {
    "__init__": [
      "self",
      "path",
      "data_type",
      "mem_map",
      "map_fn",
      "is_array",
      "array_data_type",
      "load_memory",
      "half_load"
    ],
    "SetTokenizer": [
      "self",
      "tokenizer"
    ],
    "GetTokenizer": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "file_read": [
      "self",
      "start",
      "end"
    ]
  },
  "DistributedSequentialSampler": {
    "__init__": [
      "self",
      "num_samples",
      "train_iters",
      "batch_size",
      "rank",
      "world_size"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "_batch": [
      "self",
      "batch"
    ]
  },
  "DistributedBatchSampler": {
    "__init__": [
      "self",
      "sampler",
      "batch_size",
      "drop_last",
      "rank",
      "world_size",
      "wrap_last",
      "gradient_accumulation_steps"
    ],
    "__iter__": [
      "self"
    ],
    "data_iterator": [
      "self",
      "_iter",
      "wrap_around"
    ],
    "_batch": [
      "self",
      "batch"
    ]
  },
  "make_tokenizer": [
    "tokenizer_type",
    "corpus",
    "model_path",
    "vocab_size",
    "model_type",
    "pad_token",
    "character_coverage",
    "command_tokens",
    "type_tokens"
  ],
  "Tokenization": {
    "__init__": [
      "self",
      "tokenization",
      "text",
      "original_text",
      "command_tokens",
      "asIds"
    ],
    "set_command_tokens": [
      "self",
      "command_tokens"
    ],
    "parse_command_tokens": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "insert": [
      "self",
      "idx",
      "other"
    ],
    "append": [
      "self",
      "other"
    ],
    "extend": [
      "self",
      "other"
    ]
  },
  "token_format": [],
  "COMMAND_TUPLE": [],
  "prep_command_tokens": [
    "tokenlist",
    "token_format"
  ],
  "CommandToken": {
    "__init__": [
      "self",
      "name",
      "token",
      "Id",
      "lstrip",
      "rstrip"
    ],
    "__str__": [
      "self"
    ]
  },
  "DEFAULT_COMMAND_TOKENS": [],
  "TYPE_TUPLE": [],
  "prep_type_tokens": [
    "tokenlist",
    "token_format"
  ],
  "TypeToken": {
    "__init__": [
      "self",
      "name",
      "token",
      "Id"
    ],
    "__str__": [
      "self"
    ]
  },
  "DEFAULT_TYPE_TOKENS": [],
  "TextTokenizer": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "text",
      "process_fn"
    ],
    "__len__": [
      "self"
    ],
    "tokens": [
      "self"
    ],
    "vocab": [
      "self"
    ],
    "exists": [
      "model_path"
    ],
    "Train": [
      "self",
      "corpus"
    ],
    "EncodeAsIds": [
      "self",
      "text",
      "process_fn"
    ],
    "EncodeAsTokens": [
      "self",
      "text",
      "process_fn"
    ],
    "IdToToken": [
      "self",
      "Id"
    ],
    "TokenToId": [
      "self",
      "token"
    ],
    "DecodeIds": [
      "self",
      "Ids"
    ],
    "DecodeTokens": [
      "self",
      "Tokens"
    ]
  },
  "CharacterLevelTokenizer": {
    "__init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "exists": [
      "model_path"
    ],
    "Train": [
      "self",
      "corpus"
    ],
    "tokens": [
      "self"
    ],
    "vocab": [
      "self"
    ],
    "EncodeAsIds": [
      "self",
      "text",
      "process_fn"
    ],
    "EncodeAsTokens": [
      "self",
      "text",
      "process_fn"
    ],
    "IdToToken": [
      "self",
      "Id"
    ],
    "TokenToId": [
      "self",
      "token"
    ],
    "DecodeIds": [
      "self",
      "Ids"
    ],
    "DecodeTokens": [
      "self",
      "Tokens"
    ]
  },
  "MAX_SENTENCEPIECE_SENTENCES": [],
  "get_corpus_freq": [
    "dataset",
    "filepath",
    "filetype"
  ],
  "SentencePieceTokenizer": {
    "__init__": [
      "self",
      "model_type",
      "vocab_size",
      "corpus",
      "model_path",
      "character_coverage"
    ],
    "__len__": [
      "self"
    ],
    "tokens": [
      "self"
    ],
    "vocab": [
      "self"
    ],
    "exists": [
      "model_path"
    ],
    "load_spm_model": [
      "self"
    ],
    "Train": [
      "self",
      "corpus",
      "num_text_tokens"
    ],
    "EncodeAsIds": [
      "self",
      "text",
      "process_fn"
    ],
    "EncodeAsTokens": [
      "self",
      "text",
      "process_fn"
    ],
    "IdToToken": [
      "self",
      "Id"
    ],
    "TokenToId": [
      "self",
      "token"
    ],
    "DecodeIds": [
      "self",
      "Ids"
    ],
    "DecodeTokens": [
      "self",
      "Tokens"
    ]
  },
  "BertWordPieceTokenizer": {
    "__init__": [
      "self",
      "tokenizer_model_type",
      "cache_dir",
      "add_block_symbols",
      "add_sentinel_token",
      "add_task_mask",
      "add_decoder_mask"
    ],
    "_encode": [
      "self",
      "text"
    ],
    "EncodeAsTokens": [
      "self",
      "text",
      "process_fn"
    ],
    "IdToToken": [
      "self",
      "Id",
      "type_token"
    ],
    "TokenToId": [
      "self",
      "token",
      "type_token"
    ],
    "DecodeIds": [
      "self",
      "Ids",
      "type_token"
    ],
    "DecodeTokens": [
      "self",
      "Tokens",
      "type_token"
    ]
  },
  "GPT2BPETokenizer": {
    "__init__": [
      "self",
      "model_type_or_path",
      "cache_dir",
      "add_block_symbols",
      "add_task_mask",
      "add_decoder_mask"
    ],
    "EncodeAsIds": [
      "self",
      "text",
      "process_fn"
    ],
    "_encode": [
      "self",
      "text"
    ],
    "EncodeAsTokens": [
      "self",
      "text",
      "process_fn"
    ],
    "DecodeAsTokens": [
      "self",
      "Ids"
    ],
    "IdToToken": [
      "self",
      "Id",
      "type_token"
    ],
    "TokenToId": [
      "self",
      "token",
      "type_token"
    ],
    "DecodeIds": [
      "self",
      "Ids",
      "type_token"
    ],
    "DecodeTokens": [
      "self",
      "Tokens",
      "type_token"
    ]
  },
  "ChineseSPTokenizer": {
    "__init__": [
      "self",
      "model_path",
      "add_block_symbols",
      "add_task_mask",
      "add_decoder_mask"
    ],
    "_encode": [
      "self",
      "text"
    ],
    "EncodeAsTokens": [
      "self",
      "text",
      "process_fn"
    ],
    "IdToToken": [
      "self",
      "Id",
      "type_token"
    ],
    "TokenToId": [
      "self",
      "token",
      "type_token"
    ],
    "DecodeIds": [
      "self",
      "Ids",
      "type_token"
    ],
    "DecodeTokens": [
      "self",
      "Tokens",
      "type_token"
    ]
  },
  "accuracy_metric": [
    "predictions",
    "labels",
    "examples"
  ],
  "f1_metric": [
    "predictions",
    "labels",
    "examples"
  ],
  "f1_macro_metric": [
    "predictions",
    "labels",
    "examples"
  ],
  "global_tokenizer": [],
  "accuracy_func_provider": [
    "single_dataset_provider",
    "metric_dict",
    "args",
    "is_test",
    "eval_func",
    "output_func",
    "only_rank0",
    "tokenizer"
  ],
  "segment_length": [],
  "multichoice_evaluate": [
    "model",
    "dataloader",
    "example_dict",
    "args"
  ],
  "InputExample": {
    "__init__": [
      "self",
      "guid",
      "text_a",
      "text_b",
      "label",
      "logits",
      "meta",
      "idx",
      "num_choices"
    ],
    "__repr__": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "to_json_string": [
      "self"
    ],
    "load_examples": [
      "path"
    ],
    "save_examples": [
      "examples",
      "path"
    ]
  },
  "num_special_tokens_to_add": [
    "text_a_ids",
    "text_b_ids",
    "answer_ids",
    "add_cls",
    "add_sep",
    "add_piece",
    "add_eos"
  ],
  "build_input_from_ids": [
    "text_a_ids",
    "text_b_ids",
    "answer_ids",
    "max_seq_length",
    "tokenizer",
    "args",
    "add_cls",
    "add_sep",
    "add_piece",
    "add_eos",
    "mask_id"
  ],
  "build_decoder_input": [
    "enc_ids",
    "answer_ids",
    "max_seq_length",
    "max_dec_seq_length",
    "tokenizer"
  ],
  "build_sample": [
    "ids",
    "types",
    "paddings",
    "positions",
    "masks",
    "label",
    "unique_id",
    "target",
    "logit_mask",
    "segment_ids",
    "prompt_ids"
  ],
  "build_decoder_sample": [
    "sample",
    "dec_ids",
    "dec_position",
    "dec_masks",
    "dec_target",
    "dec_logit_mask"
  ],
  "my_collate": [
    "batch"
  ],
  "FakeDataloader": {
    "__init__": [
      "self",
      "num_iters"
    ],
    "__iter__": [
      "self"
    ]
  },
  "build_data_loader": [
    "dataset",
    "batch_size",
    "num_workers",
    "drop_last",
    "shuffle",
    "only_rank0"
  ],
  "FilledPattern": [],
  "PVP": {
    "__init__": [
      "self",
      "args",
      "tokenizer",
      "label_list",
      "max_seq_length",
      "pattern_id",
      "verbalizer_file",
      "seed",
      "is_multi_token",
      "max_segment_length",
      "fast_decode",
      "split",
      "num_prompt_tokens"
    ],
    "is_multi_token": [
      "self"
    ],
    "spell_length": [
      "self"
    ],
    "mask": [
      "self"
    ],
    "mask_id": [
      "self"
    ],
    "max_num_verbalizers": [
      "self"
    ],
    "shortenable": [
      "s"
    ],
    "remove_final_punc": [
      "s"
    ],
    "lowercase_first": [
      "s"
    ],
    "uppercase_first": [
      "s"
    ],
    "available_patterns": [],
    "replace_prompt_tokens": [
      "self",
      "parts_a",
      "parts_b"
    ],
    "encode": [
      "self",
      "example",
      "priming",
      "labeled"
    ],
    "_seq_length": [
      "parts",
      "only_shortenable"
    ],
    "_remove_last": [
      "parts"
    ],
    "truncate": [
      "self",
      "parts_a",
      "parts_b",
      "answer",
      "max_length"
    ],
    "get_parts": [
      "self",
      "example"
    ],
    "get_answers": [
      "self",
      "example"
    ],
    "get_verbalizer_ids": [
      "self"
    ],
    "verbalize": [
      "self",
      "label"
    ],
    "get_mask_positions": [
      "self",
      "input_ids"
    ],
    "_load_verbalizer_from_file": [
      "path",
      "pattern_id"
    ]
  },
  "CopaPVP": {
    "available_patterns": [],
    "is_multi_token": [
      "self"
    ],
    "spell_length": [
      "self"
    ],
    "mask": [
      "self"
    ],
    "mask_id": [
      "self"
    ],
    "get_answers": [
      "self",
      "example"
    ],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ],
    "encode": [
      "self",
      "example",
      "priming",
      "labeled"
    ]
  },
  "WscPVP": {
    "available_patterns": [],
    "is_multi_token": [
      "self"
    ],
    "spell_length": [
      "self"
    ],
    "get_answers": [
      "self",
      "example"
    ],
    "get_parts": [
      "self",
      "example"
    ],
    "encode": [
      "self",
      "example",
      "priming",
      "labeled"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "RecordPVP": {
    "is_multi_token": [
      "self"
    ],
    "get_answers": [
      "self",
      "example"
    ],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "RacePVP": {
    "is_multi_token": [
      "self"
    ],
    "available_patterns": [],
    "get_answers": [
      "self",
      "example"
    ],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "RtePVP": {
    "VERBALIZER": [],
    "available_patterns": [],
    "spell_length": [
      "self"
    ],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "CbPVP": {
    "VERBALIZER": [],
    "available_patterns": [],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "BoolQPVP": {
    "VERBALIZER_A": [],
    "VERBALIZER_B": [],
    "available_patterns": [],
    "spell_length": [
      "self"
    ],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "MultiRcPVP": {
    "VERBALIZER": [],
    "available_patterns": [],
    "spell_length": [
      "self"
    ],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "WicPVP": {
    "VERBALIZER_A": [],
    "VERBALIZER_B": [],
    "available_patterns": [],
    "spell_length": [
      "self"
    ],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "AgnewsPVP": {
    "VERBALIZER": [],
    "available_patterns": [],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "YahooPVP": {
    "VERBALIZER": [],
    "available_patterns": [],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "MnliPVP": {
    "VERBALIZER_A": [],
    "VERBALIZER_B": [],
    "available_patterns": [],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "YelpPolarityPVP": {
    "VERBALIZER": [],
    "available_patterns": [],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "YelpFullPVP": {
    "VERBALIZER": [],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "XStancePVP": {
    "VERBALIZERS": [],
    "available_patterns": [],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "Sst2PVP": {
    "VERBALIZER_A": [],
    "VERBALIZER_B": [],
    "available_patterns": [],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "ColaPVP": {
    "VERBALIZER": [],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "MrpcPVP": {
    "VERBALIZER": [],
    "available_patterns": [],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "QqpPVP": {
    "VERBALIZER": [],
    "available_patterns": [],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "QnliPVP": {
    "VERBALIZER": [],
    "available_patterns": [],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "SquadPVP": {
    "is_multi_token": [
      "self"
    ],
    "get_answers": [
      "self",
      "example"
    ],
    "get_parts": [
      "self",
      "example"
    ],
    "verbalize": [
      "self",
      "label"
    ]
  },
  "get_verbalization_ids": [
    "word",
    "tokenizer",
    "force_single_token"
  ],
  "PVPS": [],
  "TRAIN_SET": [],
  "DEV_SET": [],
  "TEST_SET": [],
  "TRUE_DEV_SET": [],
  "UNLABELED_SET": [],
  "SPLIT_TYPES": [],
  "get_output_func": [
    "task_name",
    "args"
  ],
  "read_tsv": [
    "path"
  ],
  "SuperGlueDataset": {
    "__init__": [
      "self",
      "args",
      "task_name",
      "data_dir",
      "seq_length",
      "split",
      "tokenizer",
      "for_train",
      "pattern_ensemble",
      "pattern_text"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "DataProcessor": {
    "__init__": [
      "self",
      "args"
    ],
    "output_prediction": [
      "self",
      "predictions",
      "examples",
      "output_file"
    ],
    "variable_num_choices": [
      "self"
    ],
    "get_train_examples": [
      "self",
      "data_dir"
    ],
    "get_dev_examples": [
      "self",
      "data_dir",
      "for_train"
    ],
    "get_test_examples": [
      "self",
      "data_dir"
    ],
    "get_unlabeled_examples": [
      "self",
      "data_dir"
    ],
    "get_labels": [
      "self"
    ],
    "get_classifier_input": [
      "self",
      "example",
      "tokenizer"
    ],
    "encode": [
      "self",
      "example",
      "tokenizer",
      "seq_length",
      "args"
    ]
  },
  "SuperGLUEProcessor": {
    "__init__": [
      "self",
      "args"
    ],
    "get_train_examples": [
      "self",
      "data_dir"
    ],
    "get_dev_examples": [
      "self",
      "data_dir",
      "for_train"
    ],
    "get_test_examples": [
      "self",
      "data_dir"
    ],
    "get_unlabeled_examples": [
      "self",
      "data_dir"
    ],
    "_create_examples": [
      "self"
    ]
  },
  "RteProcessor": {
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "self",
      "path",
      "set_type",
      "hypothesis_name",
      "premise_name"
    ]
  },
  "AxGProcessor": {
    "get_train_examples": [
      "self",
      "data_dir"
    ],
    "get_test_examples": [
      "self",
      "data_dir"
    ]
  },
  "AxBProcessor": {
    "get_train_examples": [
      "self",
      "data_dir"
    ],
    "get_test_examples": [
      "self",
      "data_dir"
    ],
    "_create_examples": [
      "self",
      "path",
      "set_type",
      "hypothesis_name",
      "premise_name"
    ]
  },
  "CbProcessor": {
    "get_labels": [
      "self"
    ]
  },
  "WicProcessor": {
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ],
    "get_classifier_input": [
      "self",
      "example",
      "tokenizer"
    ]
  },
  "WscProcessor": {
    "variable_num_choices": [
      "self"
    ],
    "get_train_examples": [
      "self",
      "data_dir",
      "cloze_eval"
    ],
    "get_labels": [
      "self"
    ],
    "get_classifier_input": [
      "self",
      "example",
      "tokenizer"
    ],
    "_create_examples": [
      "self",
      "path",
      "set_type",
      "cloze_eval"
    ]
  },
  "BoolQProcessor": {
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ]
  },
  "CopaProcessor": {
    "get_labels": [
      "self"
    ],
    "encode": [
      "self",
      "example",
      "tokenizer",
      "seq_length",
      "args"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ]
  },
  "MultiRcProcessor": {
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ],
    "output_prediction": [
      "self",
      "predictions",
      "examples",
      "output_file"
    ],
    "get_classifier_input": [
      "self",
      "example",
      "tokenizer"
    ]
  },
  "RaceProcessor": {
    "variable_num_choices": [
      "self"
    ],
    "get_labels": [
      "self"
    ],
    "get_train_examples": [
      "self",
      "data_dir"
    ],
    "get_dev_examples": [
      "self",
      "data_dir",
      "for_train"
    ],
    "get_test_examples": [
      "self",
      "data_dir"
    ],
    "_create_examples": [
      "path",
      "set_type",
      "for_train"
    ]
  },
  "RecordProcessor": {
    "get_dev_examples": [
      "self",
      "data_dir",
      "for_train"
    ],
    "variable_num_choices": [
      "self"
    ],
    "get_labels": [
      "self"
    ],
    "output_prediction": [
      "self",
      "predictions",
      "examples",
      "output_file"
    ],
    "encode": [
      "self",
      "example",
      "tokenizer",
      "seq_length",
      "args"
    ],
    "_create_examples": [
      "path",
      "set_type",
      "seed",
      "max_train_candidates_per_question",
      "for_train"
    ]
  },
  "MnliProcessor": {
    "get_train_examples": [
      "self",
      "data_dir"
    ],
    "get_dev_examples": [
      "self",
      "data_dir",
      "for_train"
    ],
    "get_test_examples": [
      "self",
      "data_dir"
    ],
    "get_unlabeled_examples": [
      "self",
      "data_dir"
    ],
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ]
  },
  "MnliMismatchedProcessor": {
    "get_dev_examples": [
      "self",
      "data_dir",
      "for_train"
    ],
    "get_test_examples": [
      "self",
      "data_dir"
    ]
  },
  "AgnewsProcessor": {
    "get_train_examples": [
      "self",
      "data_dir"
    ],
    "get_dev_examples": [
      "self",
      "data_dir",
      "for_train"
    ],
    "get_test_examples": [
      "self",
      "data_dir"
    ],
    "get_unlabeled_examples": [
      "self",
      "data_dir"
    ],
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ]
  },
  "YahooAnswersProcessor": {
    "get_train_examples": [
      "self",
      "data_dir"
    ],
    "get_dev_examples": [
      "self",
      "data_dir",
      "for_train"
    ],
    "get_test_examples": [
      "self",
      "data_dir"
    ],
    "get_unlabeled_examples": [
      "self",
      "data_dir"
    ],
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ]
  },
  "YelpPolarityProcessor": {
    "get_train_examples": [
      "self",
      "data_dir"
    ],
    "get_dev_examples": [
      "self",
      "data_dir",
      "for_train"
    ],
    "get_test_examples": [
      "self",
      "data_dir"
    ],
    "get_unlabeled_examples": [
      "self",
      "data_dir"
    ],
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ]
  },
  "YelpFullProcessor": {
    "get_test_examples": [
      "self",
      "data_dir"
    ],
    "get_labels": [
      "self"
    ]
  },
  "XStanceProcessor": {
    "__init__": [
      "self",
      "args",
      "language"
    ],
    "get_train_examples": [
      "self",
      "data_dir"
    ],
    "get_dev_examples": [
      "self",
      "data_dir",
      "for_train"
    ],
    "get_test_examples": [
      "self",
      "data_dir"
    ],
    "get_unlabeled_examples": [
      "self",
      "data_dir"
    ],
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "self",
      "path"
    ]
  },
  "Sst2Processor": {
    "get_train_examples": [
      "self",
      "data_dir"
    ],
    "get_dev_examples": [
      "self",
      "data_dir",
      "for_train"
    ],
    "get_test_examples": [
      "self",
      "data_dir"
    ],
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ]
  },
  "ColaProcessor": {
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ]
  },
  "MrpcProcessor": {
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ]
  },
  "QqpProcessor": {
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ]
  },
  "QnliProcessor": {
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ]
  },
  "SquadProcessor": {
    "get_train_examples": [
      "self",
      "data_dir"
    ],
    "get_dev_examples": [
      "self",
      "data_dir",
      "for_train"
    ],
    "get_labels": [
      "self"
    ],
    "_create_examples": [
      "path",
      "set_type"
    ]
  },
  "CLASSIFICATION_DATASETS": [],
  "MULTI_CHOICE_DATASETS": [],
  "PROCESSORS": [],
  "DEFAULT_METRICS": [],
  "train_valid_datasets_provider": [
    "args",
    "tokenizer",
    "pattern_text"
  ],
  "metrics_func_provider": [
    "args",
    "tokenizer",
    "is_test"
  ],
  "qa_evaluate": [
    "predictions",
    "labels",
    "examples",
    "metric"
  ],
  "multirc_em": [
    "predictions",
    "labels",
    "examples"
  ],
  "qa_exact_match": [],
  "qa_f1": [],
  "gigaword_detokenize": [
    "string",
    "is_target"
  ],
  "cnndm_detokenize": [
    "string",
    "is_target"
  ],
  "blanklm_detokenize": [
    "string",
    "is_target"
  ],
  "SummmaryProcessor": {
    "__init__": [
      "self",
      "task",
      "data_dir",
      "tokenizer"
    ],
    "create_examples": [
      "self",
      "split"
    ]
  },
  "SQuADProcessor": {
    "__init__": [
      "self",
      "data_dir",
      "tokenizer"
    ],
    "create_examples": [
      "self",
      "split"
    ]
  },
  "XSumProcessor": {
    "__init__": [
      "self",
      "data_dir",
      "tokenizer"
    ],
    "create_examples": [
      "self",
      "split"
    ]
  },
  "Seq2SeqDataset": {
    "__init__": [
      "self",
      "args",
      "split",
      "tokenizer"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "ExtractionDataset": {
    "__init__": [
      "self",
      "args",
      "split",
      "tokenizer"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "BlankLMDataset": {
    "__init__": [
      "self",
      "args",
      "split",
      "tokenizer"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "mask_text": [
      "self",
      "text"
    ]
  },
  "seq2seq_forward_step": [
    "data",
    "model",
    "args",
    "timers",
    "mems"
  ],
  "_is_digit": [
    "w"
  ],
  "gigaword_tok_dict": [],
  "cnndm_tok_dict": [],
  "fix_tokenization": [
    "text",
    "dataset"
  ],
  "count_tokens": [
    "tokens"
  ],
  "get_f1": [
    "text_a",
    "text_b"
  ],
  "remove_duplicate": [
    "l_list",
    "duplicate_rate"
  ],
  "rouge_metric": [
    "predictions",
    "labels",
    "examples",
    "metric",
    "duplicate_rate",
    "dataset"
  ],
  "process_batch": [
    "batch",
    "args"
  ],
  "DecoderEvaluater": {
    "__init__": [
      "self",
      "args",
      "tokenizer"
    ],
    "evaluate": [
      "self",
      "model",
      "dataloader",
      "example_dict",
      "args"
    ]
  },
  "blanklm_fix_tokenization": [
    "text"
  ],
  "BlankLMEvaluater": {
    "evaluate": [
      "self",
      "model",
      "dataloader",
      "example_dict",
      "args"
    ]
  },
  "LMDataset": {
    "__init__": [
      "self",
      "args",
      "documents",
      "tokenizer",
      "num_original_tokens",
      "num_tokenized_tokens"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "LambadaDataset": {
    "__init__": [
      "self",
      "args",
      "tokenizer",
      "strict"
    ],
    "get_tokens": [
      "self",
      "text"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "build_lambada_dataset": [
    "tokenizer",
    "args"
  ],
  "build_lm_dataset": [
    "tokenizer",
    "args"
  ],
  "build_wikitext103_dataset": [
    "tokenizer",
    "args"
  ],
  "lm_forward_step": [
    "data",
    "model",
    "args",
    "timers",
    "mems",
    "eval_metric"
  ],
  "classify_evaluate": [
    "model",
    "dataloader",
    "example_dict",
    "args"
  ],
  "evaluate_and_print_results": [
    "data_loader",
    "model",
    "eval_metric",
    "args"
  ],
  "ptb_detokenizer": [
    "string"
  ],
  "wikitext_detokenizer": [
    "string"
  ],
  "lambada_detokenizer": [
    "string"
  ],
  "get_detokenizer": [
    "dataset"
  ],
  "DETOKENIZERS": [],
  "PyTorchDistributedDataParallel": {
    "named_parameters": [
      "self",
      "prefix",
      "recurse"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ]
  },
  "PositionalEmbedding": {
    "__init__": [
      "self",
      "hidden_size"
    ],
    "forward": [
      "self",
      "pos_seq",
      "bsz"
    ]
  },
  "ParallelCrossAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "attention_dropout_prob",
      "output_dropout_prob",
      "init_method",
      "output_layer_init_method"
    ],
    "_transpose_for_scores": [
      "self",
      "tensor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_states",
      "cross_mask"
    ]
  },
  "ParallelSelfAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "attention_dropout_prob",
      "output_dropout_prob",
      "init_method",
      "output_layer_init_method",
      "relative_encoding",
      "performer",
      "attention_scale"
    ],
    "_transpose_for_scores": [
      "self",
      "tensor"
    ],
    "_rel_shift": [
      "x",
      "zero_triu"
    ],
    "forward": [
      "self",
      "hidden_states",
      "ltor_mask",
      "position_embeddings",
      "r_w_bias",
      "r_r_bias",
      "mem"
    ]
  },
  "gelu_impl": [
    "x"
  ],
  "ParallelMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "output_dropout_prob",
      "init_method",
      "output_layer_init_method"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ParallelDecoderLayer": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "attention_dropout_prob",
      "output_dropout_prob",
      "layernorm_epsilon",
      "init_method",
      "output_layer_init_method"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_states",
      "ltor_mask",
      "cross_mask"
    ]
  },
  "ParallelTransformerLayer": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "attention_dropout_prob",
      "output_dropout_prob",
      "layernorm_epsilon",
      "init_method",
      "output_layer_init_method",
      "relative_encoding",
      "performer",
      "attention_scale"
    ],
    "forward": [
      "self",
      "hidden_states",
      "ltor_mask",
      "position_embeddings",
      "r_w_bias",
      "r_r_bias",
      "mem"
    ]
  },
  "unscaled_init_method": [
    "sigma"
  ],
  "GPT2ParallelTransformer": {
    "__init__": [
      "self",
      "num_layers",
      "hidden_size",
      "num_attention_heads",
      "max_sequence_length",
      "max_memory_length",
      "embedding_dropout_prob",
      "attention_dropout_prob",
      "output_dropout_prob",
      "checkpoint_activations",
      "checkpoint_num_layers",
      "layernorm_epsilon",
      "init_method_std",
      "use_scaled_init_for_output_weights",
      "relative_encoding",
      "block_position_encoding",
      "performer",
      "use_decoder_layer",
      "attention_scale"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "attention_mask",
      "memory_states",
      "encoder_states",
      "return_memory",
      "detach_memory"
    ],
    "update_mems": [
      "self",
      "hiddens",
      "mems",
      "return_memory"
    ]
  },
  "BertParallelSelfAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "dropout_prob",
      "output_parallel",
      "init_method"
    ],
    "_transpose_for_scores": [
      "self",
      "tensor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "BertParallelTransformerOutput": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "dropout_prob",
      "layernorm_epsilon",
      "input_is_parallel",
      "init_method"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "BertParallelTransformerLayer": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "num_attention_heads",
      "attention_dropout_prob",
      "output_dropout_prob",
      "intermediate_activation_fn",
      "layernorm_epsilon",
      "init_method"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "bert_extended_attention_mask": [
    "attention_mask"
  ],
  "PRETRAINED_MODEL_ARCHIVE_MAP": [],
  "TF_WEIGHTS_NAME": [],
  "GLMModel": {
    "__init__": [
      "self",
      "num_layers",
      "vocab_size",
      "hidden_size",
      "num_attention_heads",
      "embedding_dropout_prob",
      "attention_dropout_prob",
      "output_dropout_prob",
      "max_sequence_length",
      "max_memory_length",
      "checkpoint_activations",
      "checkpoint_num_layers",
      "parallel_output",
      "relative_encoding",
      "block_position_encoding",
      "output_predict",
      "spell_length",
      "spell_func",
      "attention_scale"
    ],
    "freeze_transformer": [
      "self",
      "tune_prefix_layers"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "EncoderDecoder": {
    "__init__": [
      "self",
      "num_layers",
      "vocab_size",
      "hidden_size",
      "num_attention_heads",
      "embedding_dropout_prob",
      "attention_dropout_prob",
      "output_dropout_prob",
      "max_sequence_length",
      "max_memory_length",
      "checkpoint_activations",
      "checkpoint_num_layers",
      "parallel_output",
      "output_predict"
    ],
    "forward": [
      "self",
      "source_ids",
      "target_ids",
      "source_position_ids",
      "target_position_ids",
      "source_mask",
      "target_mask"
    ]
  },
  "glm_get_params_for_weight_decay_optimization": [
    "module"
  ],
  "PromptSpell": {
    "__init__": [
      "self",
      "spell_length",
      "hidden_size",
      "spell_func"
    ],
    "init_embedding": [
      "self",
      "word_embeddings",
      "task_tokens"
    ],
    "forward": [
      "self"
    ]
  },
  "GLMForMultiTokenCloze": {
    "__init__": [
      "self",
      "language_model",
      "take_softmax",
      "length_penalty"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "named_parameters": [
      "self",
      "prefix",
      "recurse"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "target_ids",
      "logit_mask",
      "prompt_pos"
    ]
  },
  "GLMForMultiTokenClozeFast": {
    "__init__": [
      "self",
      "language_model",
      "take_softmax",
      "length_penalty"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "dec_input_ids",
      "dec_position_ids",
      "dec_attention_mask",
      "dec_target_ids",
      "dec_logit_mask"
    ]
  },
  "GLMForSingleTokenCloze": {
    "__init__": [
      "self",
      "language_model",
      "take_softmax"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "named_parameters": [
      "self",
      "prefix",
      "recurse"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "target_ids",
      "logit_mask",
      "prompt_pos"
    ]
  },
  "GLMForSequenceClassification": {
    "__init__": [
      "self",
      "language_model",
      "hidden_size",
      "hidden_dropout",
      "pool_token",
      "num_class"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "GPTNeoModel": {
    "__init__": [
      "self"
    ]
  },
  "DocumentGroundedDialogRetrievalModel": {
    "_backbone_prefix": [],
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input",
      "gck_segment"
    ],
    "encode_query": [
      "self",
      "input"
    ],
    "encode_context": [
      "self",
      "input"
    ]
  },
  "DocumentGroundedDialogRerankModel": {
    "_backbone_prefix": [],
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "resize_token_embeddings": [
      "self",
      "size"
    ],
    "save_pretrained": [
      "self",
      "addr"
    ]
  },
  "DocumentGroundedDialogGenerateModel": {
    "_backbone_prefix": [],
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "generate": [
      "self",
      "input"
    ]
  },
  "Wrapper": {
    "__init__": [
      "self",
      "encoder"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "dummy_tensor"
    ]
  },
  "DPRModel": {
    "__init__": [
      "self",
      "model_dir",
      "config"
    ],
    "encode": [
      "model",
      "input_ids",
      "attention_mask",
      "gck_segment"
    ],
    "forward": [
      "self",
      "query_input_ids",
      "query_attention_mask",
      "context_input_ids",
      "context_attention_mask",
      "labels",
      "gck_segment"
    ]
  },
  "ClassifyRerank": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "Rerank": {
    "__init__": [
      "self",
      "encoder",
      "top_k"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "Re2GModel": {
    "__init__": [
      "self",
      "model_dir",
      "config"
    ],
    "forward": [
      "self",
      "rerank_input_ids",
      "input_ids",
      "attention_mask",
      "label_ids"
    ],
    "generate": [
      "self",
      "rerank_input_ids",
      "input_ids",
      "attention_mask"
    ]
  },
  "SPACE_START_DOCSTRING": [],
  "SpaceModel": {
    "config_class": []
  },
  "SpacePreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "SpaceForDST": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input"
    ],
    "_forward": [
      "self",
      "input_ids",
      "input_mask",
      "segment_ids",
      "position_ids",
      "head_mask",
      "start_pos",
      "end_pos",
      "inform_slot_id",
      "refer_id",
      "class_label_id",
      "diag_state"
    ]
  },
  "SpaceForDialogModeling": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "SpaceForDialogIntent": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "SpaceConfig": {
    "model_type": []
  },
  "unsqueeze": [
    "input",
    "dims"
  ],
  "gumbel_softmax": [
    "input",
    "tau",
    "eps"
  ],
  "equal": [
    "x",
    "y",
    "dtype"
  ],
  "not_equal": [
    "x",
    "y",
    "dtype"
  ],
  "repeat": [
    "var",
    "times"
  ],
  "SpaceGenerator": {
    "_registry": [],
    "register": [
      "cls",
      "name"
    ],
    "by_name": [
      "name"
    ],
    "create": [
      "config"
    ],
    "__init__": [
      "self",
      "config",
      "reader"
    ],
    "__call__": [
      "self",
      "step_fn",
      "state"
    ]
  },
  "SpaceTokenizer": {},
  "UnifiedTransformer": {
    "__init__": [
      "self",
      "model_dir",
      "config",
      "reader",
      "generator",
      "dtype"
    ],
    "_create_parameters": [
      "self"
    ],
    "_create_mask": [
      "self",
      "input_mask",
      "append_head",
      "auto_regressive"
    ],
    "_join_mask": [
      "self",
      "mask1",
      "mask2"
    ],
    "_mlm_head": [
      "self",
      "mlm_embed"
    ],
    "_dec_head": [
      "self",
      "dec_embed"
    ],
    "_refactor_feature": [
      "self",
      "features"
    ],
    "_encoder_network": [
      "self",
      "input_token",
      "input_mask",
      "input_pos",
      "input_type",
      "input_turn"
    ],
    "_encoder_decoder_network": [
      "self",
      "src_token",
      "src_mask",
      "tgt_token",
      "tgt_mask",
      "src_pos",
      "src_type",
      "src_turn",
      "tgt_pos",
      "tgt_type",
      "tgt_turn"
    ],
    "_encoder_prompt_decoder_network": [
      "self",
      "src_token",
      "src_mask",
      "tgt_token",
      "tgt_mask",
      "prompt_token",
      "prompt_mask",
      "src_pos",
      "src_type",
      "src_turn",
      "tgt_pos",
      "tgt_type",
      "tgt_turn",
      "prompt_pos",
      "prompt_type",
      "prompt_turn"
    ],
    "_optimize": [
      "self",
      "loss",
      "optimizer",
      "lr_scheduler"
    ],
    "_infer": [
      "self",
      "inputs",
      "start_id",
      "eos_id",
      "max_gen_len",
      "prev_input"
    ]
  },
  "GenUnifiedTransformer": {
    "__init__": [
      "self",
      "model_dir",
      "config",
      "reader",
      "generator"
    ],
    "_forward": [
      "self",
      "inputs",
      "is_training",
      "with_label"
    ],
    "_collect_metrics": [
      "self",
      "inputs",
      "outputs",
      "with_label",
      "data_file"
    ],
    "_optimize": [
      "self",
      "loss",
      "do_update",
      "optimizer"
    ],
    "_init_state": [
      "self",
      "src_token",
      "src_mask",
      "src_pos",
      "src_type",
      "src_turn"
    ],
    "_init_prompt_state": [
      "self",
      "src_token",
      "src_mask",
      "prompt_token",
      "prompt_mask",
      "src_pos",
      "src_type",
      "src_turn",
      "prompt_pos",
      "prompt_type",
      "prompt_turn"
    ],
    "_decode": [
      "self",
      "state"
    ],
    "_infer": [
      "self",
      "inputs",
      "start_id",
      "eos_id",
      "max_gen_len",
      "prev_input"
    ]
  },
  "SpaceModelBase": {
    "_registry": [],
    "register": [
      "cls",
      "name"
    ],
    "by_name": [
      "name"
    ],
    "create": [
      "model_dir",
      "config"
    ],
    "__init__": [
      "self",
      "model_dir",
      "config"
    ],
    "_create_parameters": [
      "self"
    ],
    "_forward": [
      "self",
      "inputs",
      "is_training",
      "with_label"
    ],
    "_collect_metrics": [
      "self",
      "inputs",
      "outputs",
      "with_label",
      "data_file"
    ],
    "_optimize": [
      "self",
      "loss",
      "optimizer",
      "lr_scheduler"
    ],
    "_infer": [
      "self",
      "inputs",
      "start_id",
      "eos_id",
      "max_gen_len",
      "prev_input"
    ],
    "forward": [
      "self",
      "inputs",
      "is_training",
      "with_label",
      "data_file"
    ],
    "infer": [
      "self",
      "inputs",
      "start_id",
      "eos_id",
      "max_gen_len",
      "prev_input"
    ]
  },
  "IntentUnifiedTransformer": {
    "__init__": [
      "self",
      "model_dir",
      "config",
      "reader",
      "generator"
    ],
    "_forward": [
      "self",
      "inputs",
      "is_training",
      "with_label"
    ],
    "_collect_metrics": [
      "self",
      "inputs",
      "outputs",
      "with_label",
      "data_file"
    ],
    "_infer": [
      "self",
      "inputs",
      "start_id",
      "eos_id",
      "max_gen_len",
      "prev_input"
    ]
  },
  "QWenForTextGeneration": {
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past_key_values",
      "inputs_embeds"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_reorder_cache": [
      "past_key_values",
      "beam_idx"
    ],
    "chat": [
      "self",
      "tokenizer",
      "query",
      "history",
      "system",
      "append_history"
    ],
    "generate": [
      "self",
      "inputs",
      "generation_config",
      "logits_processor",
      "stopping_criteria",
      "prefix_allowed_tokens_fn",
      "synced_gpus",
      "streamer"
    ]
  },
  "HistoryType": [],
  "TokensType": [],
  "BatchTokensType": [],
  "pad_batch": [
    "batch",
    "pad_id",
    "seq_length"
  ],
  "get_ltor_masks_and_position_ids": [
    "data",
    "eod_token",
    "reset_position_ids",
    "reset_attention_mask",
    "eod_mask_loss"
  ],
  "get_stop_words_ids": [
    "chat_format",
    "tokenizer"
  ],
  "make_context": [
    "tokenizer",
    "query",
    "history",
    "system",
    "max_window_size",
    "chat_format"
  ],
  "_decode_default": [
    "tokens"
  ],
  "_decode_chatml": [
    "tokens"
  ],
  "decode_tokens": [
    "tokens",
    "tokenizer",
    "raw_text_len",
    "context_length",
    "chat_format",
    "verbose",
    "return_end_reason"
  ],
  "StopWordsLogitsProcessor": {
    "__init__": [
      "self",
      "stop_words_ids",
      "eos_token_id"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ],
    "_tokens_match": [
      "self",
      "prev_tokens",
      "tokens"
    ],
    "_calc_stopped_samples": [
      "self",
      "prev_input_ids"
    ]
  },
  "switch": [
    "val1",
    "val2",
    "boolean"
  ],
  "QWen_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "FlashSelfAttention": {
    "__init__": [
      "self",
      "causal",
      "softmax_scale",
      "attention_dropout"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v"
    ]
  },
  "QWenAttention": {
    "__init__": [
      "self",
      "config",
      "layer_number"
    ],
    "_attn": [
      "self",
      "query",
      "key",
      "value",
      "attention_mask",
      "head_mask"
    ],
    "_upcast_and_reordered_attn": [
      "self",
      "query",
      "key",
      "value",
      "attention_mask",
      "head_mask"
    ],
    "_split_heads": [
      "self",
      "tensor",
      "num_heads",
      "attn_head_size"
    ],
    "_merge_heads": [
      "self",
      "tensor",
      "num_heads",
      "attn_head_size"
    ],
    "forward": [
      "self",
      "hidden_states",
      "layer_past",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "output_attentions",
      "use_cache"
    ]
  },
  "QWenMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "QWenBlock": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "num_expert"
    ],
    "forward": [
      "self",
      "hidden_states",
      "layer_past",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "use_cache",
      "output_attentions"
    ]
  },
  "QWenPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "is_parallelizable": [],
    "supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "QWenModel": {
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "RotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "base"
    ],
    "update_rotary_pos_emb_cache": [
      "self",
      "max_seq_len",
      "offset",
      "ntk_alpha"
    ],
    "forward": [
      "self",
      "max_seq_len",
      "offset",
      "ntk_alpha"
    ]
  },
  "_rotate_half": [
    "x"
  ],
  "apply_rotary_pos_emb": [
    "t",
    "freqs",
    "use_flash_rotary"
  ],
  "QWEN_PRETRAINED_CONFIG_ARCHIVE_MAP": [],
  "QWenConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "n_embd",
      "n_layer",
      "n_head",
      "n_inner",
      "embd_pdrop",
      "attn_pdrop",
      "layer_norm_epsilon",
      "initializer_range",
      "scale_attn_weights",
      "use_cache",
      "eos_token_id",
      "apply_residual_connection_post_layernorm",
      "bf16",
      "kv_channels",
      "rotary_pct",
      "rotary_emb_base",
      "use_dynamic_ntk",
      "use_logn_attn",
      "use_flash_attn",
      "ffn_hidden_size",
      "no_bias",
      "tie_word_embeddings"
    ]
  },
  "QWenTokenizer": {
    "vocab_files_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "errors",
      "max_len",
      "unk_token",
      "bos_token",
      "eos_token",
      "pad_token",
      "add_prefix_space",
      "add_bos_token",
      "add_more_sp_tokens"
    ],
    "__len__": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "vocab_size": [
      "self"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "all_special_tokens": [
      "self"
    ],
    "all_special_ids": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_decode": [
      "self",
      "token_ids",
      "skip_special_tokens"
    ]
  },
  "batch_filling_sequence": [
    "model",
    "seqs",
    "context_lengths",
    "strategy",
    "max_memory_length",
    "get_masks_and_position_ids",
    "mems"
  ],
  "add_generation_specific_args": [
    "parser"
  ],
  "isEnglish": [
    "s"
  ],
  "fill_blanks": [
    "args",
    "raw_text",
    "model",
    "tokenizer",
    "strategy"
  ],
  "GLM130bForTextGeneration": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "func": [
      "self",
      "raw_text"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "add_bminf_args": [
    "parser"
  ],
  "add_quantization_args": [
    "parser"
  ],
  "add_initialization_args": [
    "parser"
  ],
  "set_up_model_args": [
    "args"
  ],
  "initialize": [
    "extra_args_provider"
  ],
  "initialize_model_and_tokenizer": [
    "args"
  ],
  "RESOURCE_PACKAGE_NAME": [],
  "Kernel": {
    "__init__": [
      "self",
      "filename",
      "function_names"
    ]
  },
  "kernels": [],
  "compress_int4_weight": [
    "weight"
  ],
  "extract_weight_to_half": [
    "weight",
    "scale_list",
    "source_bit_width"
  ],
  "BaseStrategy": {
    "__init__": [
      "self",
      "batch_size",
      "invalid_slices",
      "temperature",
      "top_k",
      "eps",
      "top_p",
      "end_tokens"
    ],
    "is_done": [
      "self"
    ],
    "forward": [
      "self",
      "logits",
      "tokens",
      "mems",
      "temperature"
    ],
    "finalize": [
      "self",
      "tokens",
      "mems"
    ]
  },
  "BeamSearchStrategy": {
    "__init__": [
      "self",
      "batch_size",
      "num_beams",
      "length_penalty",
      "consider_end",
      "end_tokens",
      "invalid_slices",
      "no_repeat_ngram_size",
      "min_gen_length",
      "deterministic"
    ],
    "_init_cache": [
      "self"
    ],
    "_add_end_beams": [
      "self",
      "score",
      "beam",
      "batch_idx"
    ],
    "is_done": [
      "self"
    ],
    "forward": [
      "self",
      "logits",
      "tokens",
      "mems"
    ],
    "finalize": [
      "self",
      "tokens",
      "mems"
    ]
  },
  "quantize": [
    "model",
    "weight_bit_width"
  ],
  "QuantizedColumnParallelLinear": {
    "__init__": [
      "self",
      "weight_bit_width",
      "weight"
    ],
    "forward": [
      "self",
      "input_"
    ]
  },
  "QuantizedRowParallelLinear": {
    "__init__": [
      "self",
      "weight_bit_width",
      "weight"
    ],
    "forward": [
      "self",
      "input_"
    ]
  },
  "W8A16Linear": {
    "forward": [
      "ctx",
      "inp",
      "quant_w",
      "scale_w",
      "weight_bit_width"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "QuantizedLinear": {
    "__init__": [
      "self",
      "weight_bit_width",
      "weight_tensor",
      "bias_tensor",
      "empty_init"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "CHATGLM_6B_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "InvalidScoreLogitsProcessor": {
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "load_tf_weights_in_chatglm_6b": [
    "model",
    "config",
    "tf_checkpoint_path"
  ],
  "PrefixEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "prefix"
    ]
  },
  "apply_rotary_pos_emb_index": [
    "q",
    "k",
    "cos",
    "sin",
    "position_id"
  ],
  "attention_fn": [
    "self",
    "query_layer",
    "key_layer",
    "value_layer",
    "attention_mask",
    "hidden_size_per_partition",
    "layer_id",
    "layer_past",
    "scaling_attention_score",
    "use_cache"
  ],
  "GLMBlock": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "layernorm_epsilon",
      "layer_id",
      "inner_hidden_size",
      "hidden_size_per_attention_head",
      "layernorm",
      "use_bias",
      "params_dtype",
      "num_layers",
      "position_encoding_2d"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "attention_mask",
      "layer_id",
      "layer_past",
      "use_cache",
      "output_attentions"
    ]
  },
  "ChatGLMPreTrainedModel": {
    "is_parallelizable": [],
    "supports_gradient_checkpointing": [],
    "config_class": [],
    "base_model_prefix": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "get_masks": [
      "self",
      "input_ids",
      "device"
    ],
    "get_position_ids": [
      "self",
      "input_ids",
      "mask_positions",
      "device",
      "gmask"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "CHATGLM_6B_START_DOCSTRING": [],
  "CHATGLM_6B_INPUTS_DOCSTRING": [],
  "ChatGLMModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_prompt": [
      "self",
      "batch_size",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ChatGLMForConditionalGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "_update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder",
      "standardize_cache_format"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past",
      "past_key_values",
      "attention_mask",
      "position_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_reorder_cache": [
      "past",
      "beam_idx"
    ],
    "process_response": [
      "self",
      "response"
    ],
    "_chat": [
      "self",
      "tokenizer",
      "query",
      "history",
      "max_length",
      "num_beams",
      "do_sample",
      "top_p",
      "temperature",
      "logits_processor"
    ],
    "stream_chat": [
      "self",
      "tokenizer",
      "query",
      "history",
      "max_length",
      "do_sample",
      "top_p",
      "temperature",
      "logits_processor"
    ],
    "stream_generate": [
      "self",
      "input_ids",
      "generation_config",
      "logits_processor",
      "stopping_criteria",
      "prefix_allowed_tokens_fn"
    ],
    "quantize": [
      "self",
      "bits",
      "empty_init"
    ],
    "chat": [
      "self",
      "input"
    ]
  },
  "ChatGLMConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_layers",
      "num_attention_heads",
      "layernorm_epsilon",
      "use_cache",
      "bos_token_id",
      "eos_token_id",
      "mask_token_id",
      "gmask_token_id",
      "pad_token_id",
      "max_sequence_length",
      "inner_hidden_size",
      "position_encoding_2d",
      "quantization_bit",
      "pre_seq_len",
      "prefix_projection"
    ]
  },
  "SPTokenizer": {
    "__init__": [
      "self",
      "vocab_file",
      "num_image_tokens",
      "max_blank_length",
      "byte_fallback"
    ],
    "_get_text_tokenizer": [
      "self"
    ],
    "get_blank_token": [
      "length"
    ],
    "get_tab_token": [],
    "num_text_tokens": [
      "self"
    ],
    "num_tokens": [
      "self"
    ],
    "_encode_whitespaces": [
      "text",
      "max_len"
    ],
    "_preprocess": [
      "self",
      "text",
      "linebreak",
      "whitespaces"
    ],
    "encode": [
      "self",
      "text",
      "linebreak",
      "whitespaces",
      "add_dummy_prefix"
    ],
    "decode": [
      "self",
      "text_ids"
    ],
    "tokenize": [
      "self",
      "text",
      "linebreak",
      "whitespaces",
      "add_dummy_prefix"
    ],
    "__getitem__": [
      "self",
      "x"
    ]
  },
  "ChatGLMTokenizer": {
    "vocab_files_names": [],
    "max_model_input_sizes": [],
    "model_input_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "remove_space",
      "bos_token",
      "eos_token",
      "end_token",
      "mask_token",
      "gmask_token",
      "padding_side",
      "num_image_tokens"
    ],
    "gmask_token_id": [
      "self"
    ],
    "end_token_id": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "preprocess_text": [
      "self",
      "inputs"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ]
  },
  "SbertPredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SbertLMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SbertOnlyMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output"
    ]
  },
  "SbertPreTrainingHeads": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output",
      "pooled_output"
    ]
  },
  "SbertForMaskedLM": {
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "SbertForTokenClassification": {
    "_keys_to_ignore_on_load_unexpected": [],
    "__init__": [
      "self",
      "config"
    ],
    "_forward_call": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "offset_mapping",
      "label_mask"
    ]
  },
  "SbertForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "_forward_call": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "compute_loss": [
      "self",
      "outputs",
      "labels"
    ]
  },
  "SbertPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "SbertModel": {
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "SbertConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "position_embedding_type",
      "use_cache",
      "classifier_dropout"
    ]
  },
  "activation_coeffs": [],
  "LinearProjection": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "activation",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RelationModule": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "query",
      "protos"
    ]
  },
  "MetricsLayer": {
    "__init__": [
      "self",
      "args"
    ],
    "name": [
      "self"
    ],
    "forward": [
      "self",
      "query",
      "protos"
    ],
    "cosine_similarity": [
      "self",
      "x",
      "y"
    ]
  },
  "AveragePooling": {
    "forward": [
      "self",
      "x",
      "mask",
      "dim"
    ]
  },
  "AttnPooling": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "output_size"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "PoolingLayer": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "_create_args": [
    "model_config",
    "hidden_size"
  ],
  "SbertForFaqQuestionAnswering": {
    "_backbone_prefix": [],
    "PROTO_NET": [],
    "MGIMN_NET": [],
    "_instantiate": [
      "cls"
    ],
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "_compute_loss": [
      "self",
      "logits",
      "target",
      "num_cls"
    ],
    "forward_sentence_embedding": [
      "self",
      "inputs"
    ],
    "load_checkpoint": [
      "self",
      "model_local_dir",
      "default_dtype",
      "load_state_fn"
    ]
  },
  "get_onehot_labels": [
    "target",
    "num_cls"
  ],
  "ProtoNet": {
    "__init__": [
      "self",
      "backbone_config",
      "model_config"
    ],
    "__call__": [
      "self",
      "query",
      "support",
      "query_mask",
      "support_mask",
      "support_labels"
    ],
    "sentence_embedding": [
      "self",
      "inputs"
    ]
  },
  "MGIMNNet": {
    "INSTANCE_LEVEL_INTERACTION": [],
    "EPISODE_LEVEL_INTERACTION": [],
    "__init__": [
      "self",
      "backbone_config",
      "model_config"
    ],
    "__call__": [
      "self",
      "query",
      "support",
      "query_mask",
      "support_mask",
      "support_labels"
    ],
    "_instance_compare": [
      "self",
      "Q",
      "S",
      "n_query",
      "n_cls",
      "k_shot"
    ],
    "_instance_level_interaction": [
      "self",
      "z_query",
      "query_mask",
      "z_support",
      "support_mask"
    ],
    "_class_level_interaction": [
      "self",
      "z_query",
      "query_mask",
      "z_support",
      "support_mask",
      "n_cls"
    ],
    "_episode_level_interaction": [
      "self",
      "z_query",
      "query_mask",
      "z_support",
      "support_mask"
    ],
    "_fuse_query": [
      "self",
      "x",
      "n_cls",
      "k_shot",
      "ins_z_query",
      "cls_z_query",
      "eps_z_query"
    ],
    "_fuse_support": [
      "self",
      "x",
      "n_query",
      "ins_z_support",
      "cls_z_support",
      "eps_z_support"
    ],
    "context_embedding": [
      "self",
      "query",
      "support",
      "query_mask",
      "support_mask"
    ],
    "sentence_embedding": [
      "self",
      "inputs"
    ],
    "safe_get": [
      "self",
      "k",
      "default"
    ]
  },
  "DecoderPooler": {
    "__init__": [
      "self",
      "pooler_type"
    ],
    "forward": [
      "self",
      "outputs",
      "attention_mask"
    ]
  },
  "BloomForSentenceEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "query",
      "docs",
      "labels"
    ],
    "encode": [
      "self",
      "input_ids",
      "attention_mask"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "BloomForTextGeneration": {},
  "MsModelMixin": {
    "_instantiate": [
      "cls"
    ]
  },
  "BloomModel": {},
  "DebertaV2ForMaskedLM": {
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DebertaV2PredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DebertaV2LMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DebertaV2OnlyMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output"
    ]
  },
  "ContextPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "output_dim": [
      "self"
    ]
  },
  "XSoftmax": {
    "forward": [
      "self",
      "input",
      "mask",
      "dim"
    ],
    "backward": [
      "self",
      "grad_output"
    ],
    "symbolic": [
      "g",
      "self",
      "mask",
      "dim"
    ]
  },
  "DropoutContext": {
    "__init__": [
      "self"
    ]
  },
  "get_mask": [
    "input",
    "local_context"
  ],
  "XDropout": {
    "forward": [
      "ctx",
      "input",
      "local_ctx"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ],
    "symbolic": [
      "g",
      "input",
      "local_ctx"
    ]
  },
  "StableDropout": {
    "__init__": [
      "self",
      "drop_prob"
    ],
    "forward": [
      "self",
      "x"
    ],
    "clear_context": [
      "self"
    ],
    "init_context": [
      "self",
      "reuse_mask",
      "scale"
    ],
    "get_context": [
      "self"
    ]
  },
  "DebertaV2SelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "DebertaV2Attention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions",
      "query_states",
      "relative_pos",
      "rel_embeddings"
    ]
  },
  "DebertaV2Intermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DebertaV2Output": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "DebertaV2Layer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "query_states",
      "relative_pos",
      "rel_embeddings",
      "output_attentions"
    ]
  },
  "DebertaV2Encoder": {
    "__init__": [
      "self",
      "config"
    ],
    "get_rel_embedding": [
      "self"
    ],
    "get_attention_mask": [
      "self",
      "attention_mask"
    ],
    "get_rel_pos": [
      "self",
      "hidden_states",
      "query_states",
      "relative_pos"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_hidden_states",
      "output_attentions",
      "query_states",
      "relative_pos",
      "return_dict"
    ]
  },
  "make_log_bucket_position": [
    "relative_pos",
    "bucket_size",
    "max_position"
  ],
  "build_relative_position": [
    "query_size",
    "key_size",
    "bucket_size",
    "max_position"
  ],
  "c2p_dynamic_expand": [
    "c2p_pos",
    "query_layer",
    "relative_pos"
  ],
  "p2c_dynamic_expand": [
    "c2p_pos",
    "query_layer",
    "key_layer"
  ],
  "pos_dynamic_expand": [
    "pos_index",
    "p2c_att",
    "key_layer"
  ],
  "DisentangledSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x",
      "attention_heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions",
      "query_states",
      "relative_pos",
      "rel_embeddings"
    ],
    "disentangled_attention_bias": [
      "self",
      "query_layer",
      "key_layer",
      "relative_pos",
      "rel_embeddings",
      "scale_factor"
    ]
  },
  "DebertaV2Embeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "mask",
      "inputs_embeds"
    ]
  },
  "DebertaV2PreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "config"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "DebertaV2Model": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DebertaV2Config": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "relative_attention",
      "max_relative_positions",
      "pad_token_id",
      "position_biased_input",
      "pos_att_type",
      "pooler_dropout",
      "pooler_hidden_act"
    ]
  },
  "DebertaV2TokenizerFast": {
    "vocab_files_names": [],
    "pretrained_vocab_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "slow_tokenizer_class": [],
    "__init__": [
      "self",
      "vocab_file",
      "tokenizer_file",
      "do_lower_case",
      "split_by_punct",
      "split_chinese",
      "bos_token",
      "eos_token",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ]
  },
  "DebertaV2Tokenizer": {
    "vocab_files_names": [],
    "pretrained_vocab_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "split_by_punct",
      "split_chinese",
      "bos_token",
      "eos_token",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "sp_model_kwargs"
    ],
    "vocab_size": [
      "self"
    ],
    "vocab": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "prepare_for_tokenization": [
      "self",
      "text",
      "is_split_into_words"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ]
  },
  "SPMTokenizer": {
    "__init__": [
      "self",
      "vocab_file",
      "split_by_punct",
      "sp_model_kwargs"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "d"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids"
    ],
    "decode": [
      "self",
      "tokens",
      "start",
      "end",
      "raw_text"
    ],
    "add_special_token": [
      "self",
      "token"
    ],
    "part_of_whole_word": [
      "self",
      "token",
      "is_bos"
    ],
    "pad": [
      "self"
    ],
    "bos": [
      "self"
    ],
    "eos": [
      "self"
    ],
    "unk": [
      "self"
    ],
    "mask": [
      "self"
    ],
    "sym": [
      "self",
      "id"
    ],
    "id": [
      "self",
      "sym"
    ],
    "_encode_as_pieces": [
      "self",
      "text"
    ],
    "split_to_words": [
      "self",
      "text"
    ],
    "_run_strip_accents": [
      "self",
      "text"
    ],
    "_run_split_on_punc": [
      "self",
      "text"
    ],
    "save_pretrained": [
      "self",
      "path",
      "filename_prefix"
    ]
  },
  "PlugV2Chat": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "generate": [
      "self",
      "input_ids",
      "token_type_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "decoder_input_ids",
      "token_type_ids"
    ]
  },
  "PlugV2EncoderWrapper": {
    "__init__": [
      "self",
      "bert"
    ],
    "set_n_passages": [
      "self",
      "n_passages"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids"
    ]
  },
  "PlugV2FidChat": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "wrap_encoder": [
      "self"
    ],
    "unwrap_encoder": [
      "self"
    ],
    "load": [
      "self",
      "pretrained_model_path",
      "from_tf"
    ],
    "generate": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "input_ids",
      "decoder_input_ids",
      "token_type_ids"
    ]
  },
  "TransformerDecoderState": {
    "__init__": [
      "self",
      "src",
      "cache_num_layers"
    ],
    "update_state": [
      "self",
      "new_input",
      "previous_layer_inputs"
    ],
    "_init_cache": [
      "self",
      "num_layers"
    ],
    "map_batch_fn": [
      "self",
      "fn"
    ]
  },
  "PlugPointerGenerator": {
    "__init__": [
      "self",
      "hidden_size",
      "vocab_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PlugPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "PlugModel": {
    "__init__": [
      "self",
      "config",
      "checkpoint"
    ],
    "forward": [
      "self",
      "src",
      "tgt",
      "mask_src",
      "token_type_ids"
    ]
  },
  "LabelSmoothingLoss": {
    "__init__": [
      "self",
      "label_smoothing",
      "tgt_vocab_size",
      "ignore_index"
    ],
    "forward": [
      "self",
      "output",
      "target"
    ]
  },
  "NMTLossCompute": {
    "__init__": [
      "self",
      "generator",
      "symbols",
      "vocab_size",
      "label_smoothing"
    ],
    "_bottle": [
      "self",
      "_v"
    ],
    "_unbottle": [
      "self",
      "_v",
      "batch_size"
    ],
    "forward": [
      "self",
      "tgt",
      "output"
    ]
  },
  "PlugForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "checkpoint",
      "dataset"
    ],
    "forward": [
      "self",
      "src",
      "tgt",
      "mask_src",
      "token_type_ids"
    ],
    "translate_batch": [
      "self",
      "batch",
      "fast"
    ],
    "_tile": [
      "self",
      "x",
      "count",
      "dim"
    ],
    "_top_k_top_p_filtering": [
      "self",
      "logits",
      "top_k",
      "top_p",
      "filter_value",
      "min_tokens_to_keep"
    ],
    "_fast_translate_batch": [
      "self",
      "batch",
      "max_length",
      "min_length",
      "bad_words_ids",
      "early_stopping",
      "num_beams",
      "length_penalty",
      "repetition_penalty",
      "no_repeat_ngram_size",
      "do_sample",
      "temperature",
      "top_k",
      "top_p"
    ],
    "calc_banned_tokens": [
      "self",
      "prev_input_ids",
      "num_hypos",
      "no_repeat_ngram_size",
      "cur_len"
    ],
    "translate": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids"
    ]
  },
  "PlugConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "encoder",
      "encoder_pth",
      "max_pos",
      "share_emb",
      "dec_layers",
      "dec_hidden_size",
      "dec_heads",
      "dec_ff_size",
      "dec_dropout",
      "use_bert_emb",
      "label_smoothing",
      "block_trigram"
    ]
  },
  "AnnealingLR": {
    "DECAY_STYLES": [],
    "__init__": [
      "self",
      "optimizer",
      "start_lr",
      "warmup_iter",
      "num_iters",
      "decay_style",
      "last_iter"
    ],
    "get_lr": [
      "self"
    ],
    "step": [
      "self",
      "step_num"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "sd"
    ]
  },
  "DecodeLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "enc_hidden_states",
      "enc_attn_mask",
      "dec_attn_mask",
      "is_infer"
    ]
  },
  "BertDecoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "enc_hidden_states",
      "enc_attn_mask",
      "dec_attn_mask",
      "checkpoint_activations",
      "output_all_encoded_layers",
      "is_infer"
    ]
  },
  "DecodeModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "embeddings",
      "sequence_output",
      "decode_input_ids",
      "position_ids",
      "enc_attn_mask",
      "dec_attn_mask",
      "checkpoint_activations",
      "is_infer"
    ]
  },
  "PalmForPreTraining": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "decode_input_ids",
      "position_ids",
      "decode_attention_mask",
      "lm_labels",
      "checkpoint_activations",
      "is_infer",
      "sequence_output",
      "parallel_output"
    ]
  },
  "PlugNLUConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "original_vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "lr_decay_style",
      "weight_decay",
      "clip_grad",
      "warmup",
      "pre_ln",
      "fp16",
      "fp32_layernorm",
      "fp32_embedding",
      "fp32_tokentypes",
      "layernorm_epsilon",
      "dec_hidden_layers",
      "attn_separate"
    ],
    "from_dict": [
      "cls",
      "json_object"
    ],
    "from_json_file": [
      "cls",
      "json_file"
    ],
    "merge_args": [
      "self",
      "args"
    ],
    "__repr__": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "to_json_string": [
      "self"
    ]
  },
  "PlugNLGConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "original_vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "dec_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "lr_decay_style",
      "weight_decay",
      "clip_grad",
      "warmup",
      "pre_ln",
      "fp16",
      "fp32_layernorm",
      "fp32_embedding",
      "fp32_tokentypes",
      "layernorm_epsilon",
      "attn_separate"
    ]
  },
  "DistributedPlug": {
    "__init__": [
      "self",
      "model_dir",
      "rank"
    ],
    "initialize_model": [
      "self",
      "path_load_tag"
    ],
    "top_k_logits": [
      "logits",
      "top_k",
      "top_p",
      "filter_value"
    ],
    "forward": [
      "self",
      "input_tokens",
      "token_type_ids",
      "attention_mask",
      "target_tokens",
      "position_ids",
      "decode_attention_mask",
      "checkpoint_activations",
      "is_infer",
      "sequence_output",
      "parallel_output"
    ],
    "generate": [
      "self",
      "input",
      "out_length"
    ]
  },
  "GPT3ForTextGeneration": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "generate": [
      "self",
      "inputs"
    ],
    "_get_length": [
      "attention_mask"
    ],
    "save_pretrained": [
      "self"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "stream_generate": [
      "self",
      "inputs"
    ]
  },
  "GPT3ParallelMLP": {
    "__init__": [
      "self",
      "config",
      "init_method",
      "output_layer_init_method"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPT3Embedding": {
    "__init__": [
      "self",
      "config",
      "init_method"
    ],
    "zero_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids"
    ]
  },
  "GPT3CoreAttention": {
    "__init__": [
      "self",
      "config",
      "layer_number",
      "attn_mask_type"
    ],
    "forward": [
      "self",
      "query_layer",
      "key_layer",
      "value_layer",
      "attention_mask"
    ]
  },
  "GPT3ParallelAttention": {
    "__init__": [
      "self",
      "config",
      "init_method",
      "output_layer_init_method",
      "layer_number"
    ],
    "_allocate_memory": [
      "self",
      "inference_max_sequence_len",
      "batch_size"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "inference_params"
    ]
  },
  "GPT3ParallelTransformerLayer": {
    "__init__": [
      "self",
      "config",
      "init_method",
      "output_layer_init_method",
      "layer_number"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "inference_params"
    ]
  },
  "GPT3ParallelTransformer": {
    "__init__": [
      "self",
      "config",
      "init_method",
      "output_layer_init_method",
      "post_layer_norm",
      "pre_process",
      "post_process"
    ],
    "_get_layer": [
      "self",
      "layer_number"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "inference_params"
    ]
  },
  "GPT3TransformerLanguageModel": {
    "__init__": [
      "self",
      "config",
      "init_method",
      "output_layer_init_method"
    ],
    "forward": [
      "self",
      "enc_input_ids",
      "enc_position_ids",
      "enc_attn_mask",
      "inference_params",
      "enc_hidden_states"
    ]
  },
  "GPT3Model": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "word_embeddings_weight": [
      "self"
    ],
    "build_attention_mask_and_position_ids": [
      "tokens"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "inference_params",
      "labels"
    ]
  },
  "split_into_partitions": [
    "tensor",
    "num_partitions",
    "partition_dim",
    "stride"
  ],
  "split_state_dict": [
    "state_dict",
    "model",
    "partitions"
  ],
  "DistributedGPT3": {
    "__init__": [
      "self",
      "model_dir",
      "rank",
      "path_load_tag"
    ],
    "train": [
      "self",
      "mode"
    ],
    "forward": [
      "self",
      "tokens",
      "attention_mask",
      "position_ids",
      "labels",
      "prompts_len",
      "inputs_len"
    ],
    "sample": [
      "self",
      "tokens",
      "prompts_len",
      "use_eod_token_for_early_termination",
      "stop_on_double_eol",
      "stop_on_eol"
    ],
    "beam_search": [
      "self",
      "tokens",
      "beam_size",
      "num_return_gen"
    ],
    "generate": [
      "self",
      "tokens",
      "do_sample"
    ],
    "stream_generate": [
      "self",
      "tokens"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "save_pretrained": [
      "self",
      "target_folder",
      "save_checkpoint_names",
      "save_function",
      "config"
    ]
  },
  "GPT3SelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "_transpose_for_scores": [
      "self",
      "tensor"
    ],
    "_split_tensor_along_last_dim": [
      "self",
      "tensor",
      "num_partitions",
      "contiguous_split_chunks"
    ],
    "forward": [
      "self",
      "hidden_states",
      "ltor_mask",
      "is_infer"
    ]
  },
  "GPT3MLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPT3TransformerLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "ltor_mask"
    ]
  },
  "GPT3Transformer": {
    "__init__": [
      "self",
      "config"
    ],
    "_get_layer": [
      "self",
      "layer_number"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "GPT3Config": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "ffn_hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "layernorm_epsilon",
      "bias_gelu_fusion",
      "fp32_residual_connection",
      "sequence_parallel",
      "fp16",
      "bf16",
      "apply_query_key_layer_scaling",
      "attention_softmax_in_fp32",
      "kv_channels",
      "masked_softmax_fusion",
      "attention_dropout",
      "bias_dropout_fusion",
      "apply_residual_connection_post_layernorm",
      "hidden_dropout",
      "init_method_std",
      "eod_id",
      "tokens_to_generate",
      "top_k",
      "top_p",
      "temperature"
    ],
    "params_dtype": [
      "self"
    ]
  },
  "BartForTextErrorCorrection": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "_layer_norm_all": [
    "tensor",
    "mask_float"
  ],
  "LayerwiseAttention": {
    "__init__": [
      "self",
      "num_layers",
      "model_dim",
      "dropout"
    ],
    "forward": [
      "self",
      "tensors",
      "mask"
    ]
  },
  "UniTEForTranslationEvaluation": {
    "__init__": [
      "self",
      "attention_probs_dropout_prob",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "hidden_act",
      "hidden_dropout_prob",
      "hidden_size",
      "initializer_range",
      "intermediate_size",
      "layer_norm_eps",
      "max_position_embeddings",
      "num_attention_heads",
      "num_hidden_layers",
      "type_vocab_size",
      "use_cache",
      "vocab_size",
      "mlp_hidden_sizes",
      "mlp_act",
      "mlp_final_act",
      "mlp_dropout"
    ],
    "forward": [
      "self",
      "input_ids",
      "input_format",
      "score"
    ],
    "load_checkpoint": [
      "self",
      "path",
      "device",
      "plm_only"
    ]
  },
  "combine_input_sentences": [
    "all_input_concat",
    "maximum_length",
    "pad_idx",
    "eos_idx"
  ],
  "cut_long_sequences2": [
    "all_input_concat",
    "maximum_length",
    "pad_idx"
  ],
  "cut_long_sequences3": [
    "all_input_concat",
    "maximum_length",
    "pad_idx"
  ],
  "InputFormat": {
    "SRC": [],
    "REF": [],
    "SRC_REF": []
  },
  "UniTEConfig": {
    "__init__": [
      "self"
    ]
  },
  "_get_model_class": [
    "config",
    "model_mapping"
  ],
  "TransformersModel": {
    "_instantiate": [
      "cls",
      "model_dir"
    ]
  },
  "CsanmtForTranslation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self",
      "input",
      "label",
      "prefix",
      "prefix_hit"
    ],
    "forward": [
      "self",
      "input"
    ],
    "encoding_graph": [
      "self",
      "features",
      "params"
    ],
    "semantic_encoding_graph": [
      "self",
      "features",
      "params",
      "name"
    ],
    "build_contrastive_training_graph": [
      "self",
      "features",
      "labels",
      "params"
    ],
    "MGMC_sampling": [
      "self",
      "x_embedding",
      "y_embedding",
      "params",
      "epsilon"
    ],
    "decoding_graph": [
      "self",
      "encoder_output",
      "encoder_self_attention_bias",
      "labels",
      "params",
      "embedding_augmentation"
    ],
    "build_training_graph": [
      "self",
      "features",
      "labels",
      "params",
      "feature_embedding",
      "label_embedding"
    ],
    "transformer_model_train_fn": [
      "self",
      "features",
      "labels"
    ],
    "prediction": [
      "self",
      "decoder_output",
      "params"
    ],
    "inference_func": [
      "self",
      "encoder_output",
      "feature_output",
      "encoder_self_attention_bias",
      "trg_seq",
      "states_key",
      "states_val",
      "params",
      "is_prefix"
    ],
    "beam_search": [
      "self",
      "features",
      "params"
    ]
  },
  "BeamSearchState": {},
  "tile_to_beam_size": [
    "tensor",
    "beam_size"
  ],
  "infer_shape": [
    "x"
  ],
  "split_first_two_dims": [
    "tensor",
    "dim_0",
    "dim_1"
  ],
  "merge_first_two_dims": [
    "tensor"
  ],
  "gather_2d": [
    "params",
    "indices",
    "name"
  ],
  "layer_norm": [
    "inputs",
    "epsilon",
    "name",
    "reuse"
  ],
  "_layer_process": [
    "x",
    "mode"
  ],
  "_residual_fn": [
    "x",
    "y",
    "keep_prob"
  ],
  "embedding_augmentation_layer": [
    "x",
    "embedding_augmentation",
    "params",
    "name"
  ],
  "transformer_ffn_layer": [
    "x",
    "params",
    "name"
  ],
  "transformer_encoder": [
    "encoder_input",
    "encoder_self_attention_bias",
    "mask",
    "params",
    "name"
  ],
  "transformer_semantic_encoder": [
    "encoder_input",
    "encoder_self_attention_bias",
    "mask",
    "params",
    "name"
  ],
  "transformer_decoder": [
    "decoder_input",
    "encoder_output",
    "decoder_self_attention_bias",
    "encoder_decoder_attention_bias",
    "states_key",
    "states_val",
    "embedding_augmentation",
    "params",
    "name"
  ],
  "add_timing_signal": [
    "x",
    "min_timescale",
    "max_timescale"
  ],
  "attention_bias": [
    "inputs",
    "mode",
    "inf",
    "dtype"
  ],
  "split_heads": [
    "x",
    "num_heads"
  ],
  "dot_product_attention": [
    "q",
    "k",
    "v",
    "bias",
    "dropout_rate",
    "name",
    "rpr"
  ],
  "combine_heads": [
    "x"
  ],
  "create_rpr": [
    "orginal_var",
    "length_q",
    "length_kv",
    "max_relative_dis",
    "name"
  ],
  "multihead_attention": [
    "queries",
    "memories",
    "bias",
    "key_depth",
    "value_depth",
    "output_depth",
    "num_heads",
    "dropout_rate",
    "states_key",
    "states_val",
    "layer",
    "max_relative_dis",
    "name"
  ],
  "get_initializer": [
    "params"
  ],
  "get_learning_rate_decay": [
    "learning_rate",
    "global_step",
    "params"
  ],
  "average_gradients": [
    "tower_grads"
  ],
  "_ENGINE": [],
  "MultiStepOptimizer": {
    "__init__": [
      "self",
      "optimizer",
      "step",
      "use_locking",
      "name"
    ],
    "_all_reduce": [
      "self",
      "tensor"
    ],
    "compute_gradients": [
      "self",
      "loss",
      "var_list",
      "gate_gradients",
      "aggregation_method",
      "colocate_gradients_with_ops",
      "grad_loss"
    ],
    "apply_gradients": [
      "self",
      "grads_and_vars",
      "global_step",
      "name"
    ]
  },
  "shard_features": [
    "x",
    "num_datashards"
  ],
  "UserSatisfactionEstimation": {
    "__init__": [
      "self",
      "model_dir",
      "bert_name",
      "device"
    ],
    "init_model": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "init_params": [
    "model"
  ],
  "universal_sentence_embedding": [
    "sentences",
    "mask",
    "sqrt"
  ],
  "BERTBackbone": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "USE": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "PolyLMForTextGeneration": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ],
    "generate": [
      "self",
      "input"
    ]
  },
  "EMPTY": [],
  "YESNO_LABELS": [],
  "my_lcs": [
    "string",
    "sub"
  ],
  "Bleu": {
    "__init__": [
      "self",
      "n"
    ],
    "compute_score": [
      "self",
      "gts",
      "res"
    ],
    "method": [
      "self"
    ]
  },
  "BleuScorer": {
    "__slots__": [],
    "copy": [
      "self"
    ],
    "__init__": [
      "self",
      "test",
      "refs",
      "n",
      "special_reflen"
    ],
    "cook_append": [
      "self",
      "test",
      "refs"
    ],
    "ratio": [
      "self",
      "option"
    ],
    "score_ratio": [
      "self",
      "option"
    ],
    "score_ratio_str": [
      "self",
      "option"
    ],
    "reflen": [
      "self",
      "option"
    ],
    "testlen": [
      "self",
      "option"
    ],
    "retest": [
      "self",
      "new_test"
    ],
    "rescore": [
      "self",
      "new_test"
    ],
    "size": [
      "self"
    ],
    "__iadd__": [
      "self",
      "other"
    ],
    "compatible": [
      "self",
      "other"
    ],
    "single_reflen": [
      "self",
      "option"
    ],
    "_single_reflen": [
      "self",
      "reflens",
      "option",
      "testlen"
    ],
    "recompute_score": [
      "self",
      "option",
      "verbose"
    ],
    "compute_score": [
      "self",
      "option",
      "verbose"
    ]
  },
  "data_check": [
    "obj",
    "task"
  ],
  "compute_bleu_rouge": [
    "pred_dict",
    "ref_dict",
    "bleu_order"
  ],
  "local_prf": [
    "pred_list",
    "ref_list"
  ],
  "compute_prf": [
    "pred_dict",
    "ref_dict"
  ],
  "prepare_prf": [
    "pred_dict",
    "ref_dict"
  ],
  "get_metrics": [
    "pred_result",
    "ref_result",
    "task",
    "source"
  ],
  "prepare_bleu": [
    "pred_result",
    "ref_result",
    "task"
  ],
  "get_main_result": [
    "qid",
    "pred_result",
    "ref_result"
  ],
  "get_entity_result": [
    "qid",
    "pred_result",
    "ref_result"
  ],
  "get_desc_result": [
    "qid",
    "pred_result",
    "ref_result"
  ],
  "get_yesno_result": [
    "qid",
    "pred_result",
    "ref_result"
  ],
  "get_all_result": [
    "qid",
    "pred_result",
    "ref_result"
  ],
  "format_metrics": [
    "metrics",
    "task",
    "err_msg"
  ],
  "PalmPointerGenerator": {
    "__init__": [
      "self",
      "hidden_size",
      "vocab_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PalmPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "__init__": [
      "self",
      "config"
    ],
    "_from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "AbsSummarizer": {
    "__init__": [
      "self",
      "config",
      "checkpoint"
    ],
    "_unwrap_checkpoint": [
      "checkpoint"
    ],
    "forward": [
      "self",
      "src",
      "tgt",
      "mask_src"
    ]
  },
  "Translator": {
    "__init__": [
      "self",
      "model",
      "dataset"
    ],
    "from_batch": [
      "self",
      "translation_batch"
    ],
    "translate": [
      "self",
      "data_iter",
      "step"
    ],
    "translate_batch": [
      "self",
      "batch",
      "fast"
    ],
    "_tile": [
      "self",
      "x",
      "count",
      "dim"
    ],
    "_top_k_top_p_filtering": [
      "self",
      "logits",
      "top_k",
      "top_p",
      "filter_value",
      "min_tokens_to_keep"
    ],
    "_fast_translate_batch": [
      "self",
      "batch"
    ],
    "__call__": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "PalmForTextGeneration": {
    "__init__": [
      "self",
      "config",
      "checkpoint"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "labels"
    ],
    "generate": [
      "self",
      "input"
    ]
  },
  "PalmConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "encoder",
      "encoder_pth",
      "max_pos",
      "share_emb",
      "dec_layers",
      "dec_hidden_size",
      "dec_heads",
      "dec_ff_size",
      "dec_dropout",
      "use_bert_emb",
      "label_smoothing",
      "alpha",
      "beam_size",
      "min_length",
      "max_length",
      "sample_topk",
      "block_trigram"
    ]
  },
  "BertFillMaskHead": {
    "__init__": [
      "self",
      "hidden_size",
      "hidden_act",
      "layer_norm_eps",
      "vocab_size"
    ],
    "forward": [
      "self",
      "inputs",
      "attention_mask",
      "labels"
    ],
    "compute_loss": [
      "self",
      "logits",
      "labels"
    ]
  },
  "XlmRobertaMaskHead": {
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "hidden_size",
      "hidden_act",
      "layer_norm_eps",
      "vocab_size"
    ],
    "forward": [
      "self",
      "inputs",
      "attention_mask",
      "labels"
    ],
    "compute_loss": [
      "self",
      "logits",
      "labels"
    ],
    "get_output_embeddings": [
      "self"
    ]
  },
  "XLMRobertaLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "features"
    ],
    "_tie_weights": [
      "self"
    ]
  },
  "TextRankingHead": {
    "__init__": [
      "self",
      "hidden_size",
      "classifier_dropout",
      "num_labels",
      "neg_sample"
    ],
    "forward": [
      "self",
      "inputs",
      "attention_mask",
      "labels"
    ],
    "compute_loss": [
      "self",
      "logits"
    ]
  },
  "TextGenerationHead": {
    "__init__": [
      "self"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "compute_loss": [
      "self",
      "logits",
      "labels"
    ]
  },
  "BertMLMHead": {
    "compute_loss": [
      "self",
      "outputs",
      "labels"
    ]
  },
  "RobertaMLMHead": {
    "compute_loss": [
      "self",
      "outputs",
      "labels"
    ]
  },
  "LSTMCRFHead": {
    "__init__": [
      "self",
      "hidden_size",
      "num_labels"
    ],
    "forward": [
      "self",
      "inputs",
      "attention_mask",
      "label",
      "label_mask",
      "offset_mapping"
    ],
    "decode": [
      "self",
      "logits",
      "label_mask"
    ]
  },
  "TransformersCRFHead": {
    "__init__": [
      "self",
      "hidden_size",
      "num_labels"
    ],
    "forward": [
      "self",
      "inputs",
      "attention_mask",
      "label",
      "label_mask",
      "offset_mapping"
    ],
    "decode": [
      "self",
      "logits",
      "label_mask"
    ]
  },
  "CRF": {
    "__init__": [
      "self",
      "num_tags",
      "batch_first"
    ],
    "reset_parameters": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "forward": [
      "self",
      "emissions",
      "tags",
      "mask",
      "reduction"
    ],
    "decode": [
      "self",
      "emissions",
      "mask",
      "nbest",
      "pad_tag"
    ],
    "_validate": [
      "self",
      "emissions",
      "tags",
      "mask"
    ],
    "_compute_score": [
      "self",
      "emissions",
      "tags",
      "mask"
    ],
    "_compute_normalizer": [
      "self",
      "emissions",
      "mask"
    ],
    "_viterbi_decode": [
      "self",
      "emissions",
      "mask",
      "pad_tag"
    ],
    "_viterbi_decode_nbest": [
      "self",
      "emissions",
      "mask",
      "nbest",
      "pad_tag"
    ]
  },
  "InformationExtractionHead": {
    "__init__": [
      "self",
      "hidden_size",
      "labels"
    ],
    "forward": [
      "self",
      "inputs",
      "attention_mask",
      "labels",
      "text",
      "offsets",
      "threshold"
    ],
    "_get_masks_and_mentions": [
      "self",
      "text",
      "offsets",
      "heads",
      "tails",
      "init_mask",
      "threshold"
    ]
  },
  "LSTMForTokenClassificationWithCRF": {
    "override_base_model_type": [],
    "base_model_type": [],
    "head_type": [],
    "parse_head_cfg": [
      "self"
    ]
  },
  "LSTMModel": {
    "__init__": [
      "self",
      "vocab_size",
      "embed_width",
      "hidden_size"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "MegatronBertPredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MegatronBertLMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MegatronBertOnlyMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output"
    ]
  },
  "MegatronBertOnlyNSPHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pooled_output"
    ]
  },
  "MegatronBertPreTrainingHeads": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output",
      "pooled_output"
    ]
  },
  "MegatronBertForMaskedLM": {
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "MegatronBertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ]
  },
  "MegatronBertSelfAttention": {
    "__init__": [
      "self",
      "config",
      "position_embedding_type"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "MegatronBertSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "MegatronBertAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "MegatronBertIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MegatronBertOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "MegatronBertLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ]
  },
  "MegatronBertEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MegatronBertPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MegatronBertPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "MegatronBertModel": {
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MegatronBertConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "position_embedding_type",
      "use_cache"
    ]
  },
  "fast_gelu": [
    "x"
  ],
  "TopQuerySelfAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "layer_number",
      "fp16",
      "attention_softmax_in_fp32"
    ],
    "forward": [
      "self",
      "hidden_states",
      "query_hidden_state",
      "attention_mask",
      "layer_past",
      "get_key_value",
      "prompt_length",
      "context_length"
    ]
  },
  "TopQueryLayer": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "layer_number",
      "layernorm_epsilon"
    ],
    "forward": [
      "self",
      "hidden_states",
      "query_hidden_state",
      "attention_mask",
      "layer_past",
      "get_key_value",
      "prompt_length",
      "context_length"
    ]
  },
  "QueryEmbedding": {
    "__init__": [
      "self",
      "hidden_size",
      "vocab_size",
      "max_sequence_length"
    ],
    "forward": [
      "self",
      "position_ids"
    ],
    "state_dict_for_save_checkpoint": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ]
  },
  "TransformerLanguageModel": {
    "__init__": [
      "self",
      "hidden_size",
      "num_layers",
      "num_attention_heads",
      "padded_vocab_size",
      "max_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "layer_past",
      "get_key_value",
      "prompt_length",
      "context_length"
    ],
    "state_dict_for_save_checkpoint": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ]
  },
  "CodeGeeXModel": {
    "__init__": [
      "self",
      "hidden_size",
      "num_layers",
      "num_attention_heads",
      "padded_vocab_size",
      "max_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "layer_past",
      "get_key_value",
      "prompt_length",
      "context_length"
    ],
    "state_dict_for_save_checkpoint": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ]
  },
  "model_provider": [],
  "CodeGeeXForCodeTranslation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "encode_whitespaces": [
    "text",
    "start_extra_id",
    "max_len"
  ],
  "decode_whitespaces": [
    "text",
    "start_extra_id",
    "max_len"
  ],
  "Code13BDictionary": {
    "__init__": [
      "self",
      "dict_file",
      "extra_token_ids",
      "pad_to_vocab_size"
    ],
    "_pad_to_vocab_size": [
      "self",
      "vocab_size"
    ],
    "_load_dict": [
      "self",
      "dict_file"
    ],
    "_add_symbol": [
      "self",
      "sym",
      "count"
    ],
    "__len__": [
      "self"
    ],
    "index": [
      "self",
      "sym"
    ],
    "string": [
      "self",
      "idx"
    ],
    "map_token": [
      "self",
      "token"
    ],
    "map_tokens": [
      "self",
      "tokens"
    ],
    "decode_tokens": [
      "self",
      "tokens"
    ]
  },
  "CodeGeeXTokenizer": {
    "__init__": [
      "self",
      "tokenizer",
      "tokenizer_path",
      "start_extra_id",
      "max_len",
      "mode",
      "dict_file"
    ],
    "encode_code": [
      "self",
      "code"
    ],
    "decode_code": [
      "self",
      "input_ids"
    ]
  },
  "CodeGeeXForCodeGeneration": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "get_token_stream": [
    "model",
    "tokenizer",
    "seq_length",
    "out_seq_length",
    "context_tokens",
    "return_scores",
    "prompt_length",
    "micro_batch_size",
    "bad_ids",
    "temperature",
    "topp",
    "topk",
    "greedy"
  ],
  "sample_sequence_batch": [
    "model",
    "tokenizer",
    "context_tokens",
    "context_lengths",
    "attention_mask",
    "position_ids",
    "seq_length",
    "out_seq_length",
    "maxlen",
    "return_scores",
    "prompt_length",
    "bad_ids",
    "temperature",
    "topp",
    "topk",
    "recompute",
    "greedy"
  ],
  "_repr": [
    "modules",
    "depth"
  ],
  "BaseTaskModel": {
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "_backbone_prefix": [],
    "__init__": [
      "self",
      "model_dir"
    ],
    "__repr__": [
      "self"
    ],
    "_instantiate": [
      "cls"
    ],
    "forward": [
      "self",
      "input"
    ],
    "load_checkpoint": [
      "self",
      "model_local_dir",
      "default_dtype",
      "load_state_fn"
    ],
    "_load_checkpoint": [
      "self",
      "state_dict",
      "load_state_fn",
      "ignore_mismatched_sizes",
      "_fast_init"
    ],
    "retrieve_modules_from_names": [
      "self",
      "names",
      "prefix",
      "add_prefix",
      "remove_prefix"
    ]
  },
  "SingleBackboneTaskModelBase": {
    "_backbone_prefix": [],
    "_head_prefix": [],
    "__init__": [
      "self",
      "model_dir"
    ],
    "build_backbone": [
      "self",
      "cfg"
    ],
    "build_head": [
      "self",
      "cfg"
    ],
    "backbone": [
      "self"
    ],
    "head": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "compute_loss": [
      "self",
      "outputs",
      "labels"
    ],
    "extract_backbone_outputs": [
      "self",
      "outputs"
    ]
  },
  "EncoderModel": {
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "base_model_prefix": [],
    "base_model_type": [],
    "head_prefix": [],
    "head_type": [],
    "override_base_model_prefix": [],
    "override_base_model_type": [],
    "__init__": [
      "self",
      "model_dir"
    ],
    "post_init": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_get_transformer_config": [
      "self"
    ],
    "_use_transformer_config": [
      "self",
      "cfg"
    ],
    "parse_encoder_cfg": [
      "self"
    ],
    "parse_head_cfg": [
      "self"
    ],
    "build_encoder": [
      "self",
      "cfg"
    ],
    "build_head": [
      "self",
      "cfg"
    ],
    "encoder": [
      "self"
    ],
    "head": [
      "self"
    ],
    "extract_feature": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_instantiate": [
      "cls"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "revision",
      "cfg_dict",
      "device"
    ]
  },
  "ModelForTextRanking": {
    "task": [],
    "head_type": [],
    "__init__": [
      "self",
      "model_dir"
    ],
    "parse_encoder_cfg": [
      "self"
    ],
    "parse_head_cfg": [
      "self"
    ]
  },
  "ModelForFillMask": {
    "task": [],
    "head_type": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_load_missing": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "ModelForInformationExtraction": {
    "task": [],
    "head_type": []
  },
  "ModelForMachineReadingComprehension": {
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "label_mask",
      "match_labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MultiNonLinearProjection": {
    "__init__": [
      "self",
      "hidden_size",
      "num_label",
      "dropout_rate",
      "act_func",
      "intermediate_hidden_size"
    ],
    "forward": [
      "self",
      "input_features"
    ]
  },
  "ModelForTokenClassificationWithCRF": {
    "head_type": [],
    "base_model_prefix": [],
    "postprocess": [
      "self",
      "inputs"
    ]
  },
  "ModelForTextGeneration": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past"
    ],
    "generate": [
      "self",
      "inputs",
      "temperature"
    ]
  },
  "ModelForFeatureExtraction": {
    "task": [],
    "head_type": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "INTERMEDIATE_SIZE_MAP": [],
  "NUM_SHARDS": [],
  "compute_intermediate_size": [
    "n"
  ],
  "read_json": [
    "path"
  ],
  "write_json": [
    "text",
    "path"
  ],
  "write_tokenizer": [
    "tokenizer_path",
    "input_tokenizer_path"
  ],
  "get_chat_prompt": [
    "system",
    "text",
    "history",
    "max_length",
    "tokenizer"
  ],
  "LlamaForTextGeneration": {
    "chat": [
      "self",
      "input",
      "tokenizer"
    ]
  },
  "LlamaPreTrainedModel": {},
  "LlamaModel": {},
  "VecoForMaskedLM": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "VecoForTokenClassification": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "VecoForSequenceClassification": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "VECO_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "VecoModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "VecoConfig": {
    "model_type": []
  },
  "PeerForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "side_info_sets",
      "return_dict"
    ]
  },
  "PEER_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "PeerEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length",
      "side_info_sets"
    ]
  },
  "PeerSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "side_info_sets"
    ]
  },
  "PeerSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "PeerAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "side_info_sets"
    ]
  },
  "PeerIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "PeerOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "PeerLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "side_info_sets"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ]
  },
  "PeerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "get_position_attention_score": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "side_info_sets",
      "return_dict"
    ]
  },
  "PeerDiscriminatorPredictions": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "discriminator_hidden_states"
    ]
  },
  "PeerGeneratorPredictions": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "generator_hidden_states"
    ]
  },
  "PeerPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "PeerForRTDOutput": {},
  "PeerForPreTrainingOutput": {},
  "PEER_START_DOCSTRING": [],
  "PEER_INPUTS_DOCSTRING": [],
  "PeerModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "update_seq_side_info": [
      "self",
      "side_info_sets",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "side_info_sets",
      "return_dict"
    ]
  },
  "PeerTopModel": {
    "__init__": [
      "self",
      "config"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "update_seq_side_info": [
      "self",
      "side_info_sets",
      "input_ids"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "side_info_sets",
      "return_dict"
    ]
  },
  "PeerClassificationHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "PeerConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "embedding_size",
      "hidden_size",
      "num_hidden_layers",
      "num_hidden_layers_shared",
      "num_hidden_layers_gen",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "summary_type",
      "summary_use_proj",
      "summary_activation",
      "summary_last_dropout",
      "pad_token_id",
      "position_embedding_type",
      "gen_weight",
      "dis_weight",
      "dis_weight_scheduler",
      "augmentation_copies",
      "augmentation_temperature",
      "absolute_position_embedding",
      "relative_position_embedding",
      "seq_side_info_embeddings",
      "cold_start_epochs",
      "debug_config",
      "rtd_levels",
      "rtd_level_thresholds",
      "ranking_start_epoch",
      "real_token_rank_for_good_estimate",
      "rank_sampl_prop",
      "rank_sampl_range",
      "rank_delta_factor",
      "rank_level_compare_method",
      "weight_loss_low_levels",
      "weight_loss_low_levels_setting",
      "weight_loss_low_levels_scheduler",
      "weight_loss_level_compos",
      "mask_da",
      "mask_da_start_epoch",
      "mask_da_mlm_topk_val",
      "mask_ratio_setting",
      "mask_ratio_scheduler",
      "mask_ratio_stage1_epochs"
    ]
  },
  "get_random_states": [
    "device"
  ],
  "set_random_states": [
    "random_states",
    "device"
  ],
  "check_nan_inf": [
    "data"
  ],
  "SequenceSideInfo": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "getSenTokIdx": [
      "self",
      "sentence_position_embedding",
      "inputs_str",
      "seq_len_total"
    ],
    "generate_seq_side_info": [
      "self",
      "sentence_position_embedding",
      "inputs_id"
    ]
  },
  "__HEAD_MASK_WARNING_MSG": [],
  "T5ForConditionalGeneration": {
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "__init__": [
      "self",
      "config",
      "device_map"
    ],
    "parallelize": [
      "self",
      "device_map"
    ],
    "deparallelize": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "head_mask",
      "decoder_head_mask",
      "cross_attn_head_mask",
      "encoder_outputs",
      "past_key_values",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past",
      "attention_mask",
      "head_mask",
      "decoder_head_mask",
      "cross_attn_head_mask",
      "use_cache",
      "encoder_outputs"
    ],
    "prepare_decoder_input_ids_from_labels": [
      "self",
      "labels"
    ],
    "generate": [
      "self"
    ],
    "_reorder_cache": [
      "self",
      "past",
      "beam_idx"
    ]
  },
  "load_tf_weights_in_t5": [
    "model",
    "config",
    "tf_checkpoint_path"
  ],
  "T5LayerNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5DenseReluDense": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5DenseGatedGeluDense": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5LayerFF": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5Attention": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "_relative_position_bucket": [
      "relative_position",
      "bidirectional",
      "num_buckets",
      "max_distance"
    ],
    "compute_bias": [
      "self",
      "query_length",
      "key_length"
    ],
    "forward": [
      "self",
      "hidden_states",
      "mask",
      "key_value_states",
      "position_bias",
      "past_key_value",
      "layer_head_mask",
      "query_length",
      "use_cache",
      "output_attentions"
    ]
  },
  "T5LayerSelfAttention": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias",
      "layer_head_mask",
      "past_key_value",
      "use_cache",
      "output_attentions"
    ]
  },
  "T5LayerCrossAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "key_value_states",
      "attention_mask",
      "position_bias",
      "layer_head_mask",
      "past_key_value",
      "use_cache",
      "query_length",
      "output_attentions"
    ]
  },
  "T5Block": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "encoder_decoder_position_bias",
      "layer_head_mask",
      "cross_attn_layer_head_mask",
      "past_key_value",
      "use_cache",
      "output_attentions",
      "return_dict"
    ]
  },
  "T5PreTrainedModel": {
    "config_class": [],
    "load_tf_weights": [],
    "base_model_prefix": [],
    "is_parallelizable": [],
    "supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "config"
    ],
    "dummy_inputs": [
      "self"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "_shift_right": [
      "self",
      "input_ids"
    ],
    "_instantiate": [
      "cls"
    ]
  },
  "T5Stack": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "parallelize": [
      "self",
      "device_map"
    ],
    "deparallelize": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "inputs_embeds",
      "head_mask",
      "cross_attn_head_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "T5Model": {
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "__init__": [
      "self",
      "config"
    ],
    "parallelize": [
      "self",
      "device_map"
    ],
    "deparallelize": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "head_mask",
      "decoder_head_mask",
      "cross_attn_head_mask",
      "encoder_outputs",
      "past_key_values",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "T5Config": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "d_model",
      "d_kv",
      "d_ff",
      "num_layers",
      "num_decoder_layers",
      "num_heads",
      "relative_attention_num_buckets",
      "relative_attention_max_distance",
      "dropout_rate",
      "layer_norm_epsilon",
      "initializer_factor",
      "feed_forward_proj",
      "is_encoder_decoder",
      "use_cache",
      "pad_token_id",
      "eos_token_id"
    ]
  },
  "T5OnnxConfig": {
    "inputs": [
      "self"
    ],
    "default_onnx_opset": [
      "self"
    ]
  },
  "CanmtForTranslation": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "build_model": [
      "self",
      "model_dir"
    ],
    "build_generator": [
      "cls",
      "model",
      "vocab_tgt",
      "args"
    ],
    "load_checkpoint": [
      "self",
      "path",
      "device"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "CanmtModel": {
    "__init__": [
      "self",
      "args",
      "encoder",
      "decoder",
      "second_decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "build_embedding": [
      "cls",
      "args",
      "dictionary",
      "embed_dim",
      "path"
    ],
    "build_encoder": [
      "cls",
      "args",
      "src_dict",
      "embed_tokens"
    ],
    "build_decoder": [
      "cls",
      "args",
      "tgt_dict",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "prev_src_tokens",
      "return_all_hiddens",
      "features_only",
      "alignment_layer",
      "alignment_heads"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "forward_decoder": [
      "self",
      "tokens",
      "encoder_outs",
      "incremental_states",
      "temperature"
    ],
    "forward_decoder_src": [
      "self",
      "tokens",
      "encoder_outs",
      "incremental_states",
      "temperature"
    ],
    "forward_encoder": [
      "self",
      "net_input"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_outs",
      "new_order"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_states",
      "new_order"
    ]
  },
  "transformer_deep": [
    "args"
  ],
  "StarForTextToSql": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "default_init": [
    "cls"
  ],
  "split_tensor_along_last_dim": [
    "tensor",
    "num_partitions",
    "contiguous_split_chunks"
  ],
  "CoreAttention": {
    "__init__": [
      "self",
      "config",
      "layer_number"
    ],
    "forward": [
      "self",
      "query_layer",
      "key_layer",
      "value_layer",
      "attention_mask"
    ]
  },
  "_config_to_kwargs": [
    "args"
  ],
  "GLMTransformer": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "_get_layer": [
      "self",
      "layer_number"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "rotary_pos_emb",
      "kv_caches",
      "use_cache",
      "output_hidden_states"
    ]
  },
  "ChatGLM2ForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "empty_init",
      "device"
    ],
    "_update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder",
      "standardize_cache_format"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "position_ids",
      "is_first_forward"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "return_last_logit"
    ],
    "_reorder_cache": [
      "past",
      "beam_idx"
    ],
    "process_response": [
      "self",
      "response"
    ],
    "build_inputs": [
      "self",
      "tokenizer",
      "query",
      "history"
    ],
    "build_stream_inputs": [
      "self",
      "tokenizer",
      "query",
      "history"
    ],
    "_chat": [
      "self",
      "tokenizer",
      "query",
      "history",
      "max_length",
      "num_beams",
      "do_sample",
      "top_p",
      "temperature",
      "logits_processor"
    ],
    "stream_chat": [
      "self",
      "tokenizer",
      "query",
      "history",
      "past_key_values",
      "max_length",
      "do_sample",
      "top_p",
      "temperature",
      "logits_processor",
      "return_past_key_values"
    ],
    "stream_generate": [
      "self",
      "input_ids",
      "generation_config",
      "logits_processor",
      "stopping_criteria",
      "prefix_allowed_tokens_fn",
      "return_past_key_values"
    ],
    "quantize": [
      "self",
      "bits",
      "empty_init",
      "device"
    ],
    "chat": [
      "self",
      "input",
      "tokenizer"
    ]
  },
  "ChatGLM2Config": {
    "model_type": [],
    "__init__": [
      "self",
      "num_layers",
      "padded_vocab_size",
      "hidden_size",
      "ffn_hidden_size",
      "kv_channels",
      "num_attention_heads",
      "seq_length",
      "hidden_dropout",
      "attention_dropout",
      "layernorm_epsilon",
      "rmsnorm",
      "apply_residual_connection_post_layernorm",
      "post_layer_norm",
      "add_bias_linear",
      "add_qkv_bias",
      "bias_dropout_fusion",
      "multi_query_attention",
      "multi_query_group_num",
      "apply_query_key_layer_scaling",
      "attention_softmax_in_fp32",
      "fp32_residual_connection",
      "quantization_bit",
      "pre_seq_len",
      "prefix_projection",
      "rope_ratio"
    ]
  },
  "ChatGLM2Tokenizer": {
    "vocab_files_names": [],
    "model_input_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "padding_side"
    ],
    "get_command": [
      "self",
      "token"
    ],
    "pad_token": [
      "self"
    ],
    "pad_token_id": [
      "self"
    ],
    "eos_token": [
      "self"
    ],
    "eos_token_id": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "get_prefix_tokens": [
      "self"
    ],
    "build_prompt": [
      "self",
      "query",
      "history"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ]
  },
  "Head": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "compute_loss": [
      "self"
    ]
  },
  "TorchHead": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "compute_loss": [
      "self"
    ]
  },
  "TorchModel": {
    "__init__": [
      "self",
      "model_dir"
    ],
    "__call__": [
      "self"
    ],
    "_load_pretrained": [
      "self",
      "net",
      "load_path",
      "strict",
      "param_key"
    ],
    "forward": [
      "self"
    ],
    "post_init": [
      "self"
    ],
    "init_weights": [
      "self"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "save_pretrained": [
      "self",
      "target_folder",
      "save_checkpoint_names",
      "save_function",
      "config",
      "save_config_function"
    ],
    "compile": [
      "self"
    ]
  },
  "DEFAULT_RESOURCE_MODEL_ID": [],
  "run_auto_label": [
    "input_wav",
    "work_dir",
    "para_ids",
    "resource_model_id",
    "resource_revision",
    "gender",
    "stage",
    "process_num",
    "develop_mode",
    "has_para",
    "enable_enh"
  ]
}