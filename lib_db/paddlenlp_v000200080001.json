{
  "PADDLENLP_STABLE_VERSION": [],
  "__version__": [],
  "__all__": [],
  "einsum": [
    "equation"
  ],
  "LOADED_EXT": [],
  "file_lock": [
    "lock_file_path"
  ],
  "_get_files": [
    "path"
  ],
  "newer_group": [
    "sources",
    "target",
    "missing"
  ],
  "CMakeExtension": {
    "__init__": [
      "self",
      "name",
      "source_dir"
    ],
    "build_with_command": [
      "self",
      "ext_builder"
    ],
    "get_target_filename": [
      "self"
    ],
    "get_output_filename": [
      "self"
    ]
  },
  "FasterTransformerExtension": {
    "__init__": [
      "self",
      "name",
      "source_dir",
      "need_parallel"
    ],
    "build_with_command": [
      "self",
      "ext_builder"
    ],
    "get_target_filename": [
      "self"
    ],
    "get_output_filename": [
      "self"
    ]
  },
  "BuildExtension": {
    "build_extensions": [
      "self"
    ]
  },
  "EXTENSIONS": [],
  "get_extension_maker": [
    "name"
  ],
  "_write_setup_file": [
    "name",
    "file_path",
    "build_dir"
  ],
  "load": [
    "name",
    "build_dir",
    "force",
    "verbose"
  ],
  "layerwise_lr_decay": [
    "decay_rate",
    "name_dict",
    "n_layers",
    "param"
  ],
  "AdamWDL": {
    "__init__": [
      "self",
      "learning_rate",
      "beta1",
      "beta2",
      "epsilon",
      "parameters",
      "weight_decay",
      "apply_decay_param_fun",
      "grad_clip",
      "lazy_mode",
      "multi_precision",
      "layerwise_decay",
      "n_layers",
      "set_param_lr_fun",
      "name_dict",
      "name"
    ],
    "_set_auxiliary_var": [
      "self",
      "key",
      "val"
    ],
    "_get_auxiliary_var": [
      "self",
      "key"
    ],
    "_append_optimize_op": [
      "self",
      "block",
      "param_and_grad"
    ],
    "_append_decoupled_weight_decay": [
      "self",
      "block",
      "param_and_grad"
    ],
    "_create_optimization_pass": [
      "self",
      "parameters_and_grads"
    ],
    "__str__": [
      "self"
    ],
    "_update_param_group": [
      "self",
      "parameters"
    ]
  },
  "InverseSquareRootSchedule": {
    "__init__": [
      "self",
      "warmup_steps",
      "learning_rate",
      "last_epoch",
      "verbose"
    ],
    "get_lr": [
      "self"
    ]
  },
  "ExponentialMovingAverage": {
    "__init__": [
      "self",
      "model",
      "decay"
    ],
    "register": [
      "self"
    ],
    "update": [
      "self"
    ],
    "apply_shadow": [
      "self"
    ],
    "restore": [
      "self"
    ]
  },
  "guard": [
    "device"
  ],
  "ParallelEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "rank",
      "world_size",
      "weight_attr",
      "name"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ColumnParallelLiner": {
    "__init__": [
      "self",
      "size",
      "num_partitions",
      "gather_out",
      "param_attr",
      "bias_attr",
      "name"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RowParallelLiner": {
    "__init__": [
      "self",
      "size",
      "num_partitions",
      "input_is_parallel",
      "param_attr",
      "bias_attr",
      "name"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GroupInfo": [],
  "Topology": {
    "__init__": [
      "self",
      "device_rank",
      "world_size",
      "dp_degree",
      "pp_degree",
      "sharding_degree",
      "mp_degree",
      "sep_degree",
      "order"
    ],
    "__repr__": [
      "self"
    ]
  },
  "MODEL_PARALLEL_RNG": [],
  "RNGStatesTracker": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "name",
      "seed"
    ],
    "rng_state": [
      "self",
      "name"
    ]
  },
  "RNG_STATE_TRACKER": [],
  "get_rng_state_tracker": [],
  "setup_args": [],
  "postprocess_response": [
    "tokenizer",
    "seq",
    "bos_idx",
    "eos_idx"
  ],
  "infer": [
    "args"
  ],
  "postprocess_seq": [
    "seq",
    "bos_idx",
    "eos_idx",
    "output_bos",
    "output_eos"
  ],
  "prepare_input": [
    "tokenizer",
    "sentences"
  ],
  "parse_args": [],
  "do_predict": [
    "args"
  ],
  "get_op_cache_config": [
    "use_batch_major_op_cache",
    "size_per_head",
    "is_fp16"
  ],
  "MODEL_CLASSES": [],
  "generate_src_word": [
    "batch_size",
    "vocab_size",
    "max_length",
    "eos_idx",
    "pad_idx"
  ],
  "post_process_seq": [
    "seq",
    "bos_idx",
    "eos_idx",
    "output_bos",
    "output_eos"
  ],
  "FasterTransformer": {
    "__init__": [
      "self",
      "src_vocab_size",
      "trg_vocab_size",
      "max_length",
      "num_encoder_layers",
      "num_decoder_layers",
      "n_head",
      "d_model",
      "d_inner_hid",
      "dropout",
      "weight_sharing",
      "attn_dropout",
      "act_dropout",
      "bos_id",
      "eos_id",
      "pad_id",
      "decoding_strategy",
      "beam_size",
      "topk",
      "topp",
      "max_out_len",
      "diversity_rate",
      "decoding_lib",
      "use_fp16_decoding",
      "enable_fast_encoder",
      "use_fp16_encoder",
      "rel_len",
      "alpha"
    ],
    "forward": [
      "self",
      "src_word",
      "trg_word"
    ],
    "load": [
      "self",
      "init_from_params",
      "state_dict"
    ],
    "export_params": [
      "self",
      "init_from_params",
      "place"
    ]
  },
  "TransformerGenerator": {
    "__init__": [
      "self",
      "src_vocab_size",
      "trg_vocab_size",
      "max_length",
      "num_encoder_layers",
      "num_decoder_layers",
      "n_head",
      "d_model",
      "d_inner_hid",
      "dropout",
      "weight_sharing",
      "bos_id",
      "eos_id",
      "pad_id",
      "beam_size",
      "max_out_len",
      "activation",
      "normalize_before"
    ],
    "forward": [
      "self",
      "src_word",
      "trg_word"
    ],
    "load": [
      "self",
      "path",
      "state_dict"
    ]
  },
  "FasterOPT": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding"
    ],
    "forward": [
      "self",
      "input_ids",
      "seq_len",
      "attention_mask",
      "top_k",
      "top_p",
      "max_length",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "forced_eos_token_id",
      "temperature",
      "decode_strategy",
      "num_return_sequences"
    ],
    "export_params": [
      "self",
      "state_to_load",
      "place"
    ],
    "save_resources": [
      "self",
      "tokenizer",
      "path"
    ],
    "generate": []
  },
  "FasterGPT": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding"
    ],
    "forward": [
      "self",
      "input_ids",
      "seq_len",
      "attention_mask",
      "top_k",
      "top_p",
      "max_length",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "forced_eos_token_id",
      "temperature",
      "decode_strategy",
      "num_return_sequences"
    ],
    "export_params": [
      "self",
      "state_to_load",
      "place"
    ],
    "save_resources": [
      "self",
      "tokenizer",
      "path"
    ],
    "generate": []
  },
  "FasterUnifiedTransformer": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "seq_len",
      "position_ids",
      "role_ids"
    ],
    "generate_logits_mask": [
      "self",
      "use_fp16_decoding"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "seq_len",
      "role_ids",
      "position_ids",
      "max_length",
      "min_length",
      "top_k",
      "top_p",
      "decode_strategy",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "num_beams",
      "diversity_rate",
      "temperature",
      "num_return_sequences",
      "length_penalty",
      "early_stopping",
      "forced_eos_token_id"
    ],
    "generate": []
  },
  "FasterUNIMOText": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ],
    "generate_logits_mask": [
      "self",
      "use_fp16_decoding"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "seq_len",
      "max_length",
      "min_length",
      "top_k",
      "top_p",
      "num_beams",
      "decode_strategy",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "diversity_rate",
      "temperature",
      "num_return_sequences",
      "length_penalty",
      "early_stopping",
      "forced_eos_token_id",
      "position_ids"
    ],
    "generate": []
  },
  "FasterMIRO": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ],
    "generate_logits_mask": [
      "self",
      "use_fp16_decoding"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "seq_len",
      "max_length",
      "min_length",
      "top_k",
      "top_p",
      "num_beams",
      "decode_strategy",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "diversity_rate",
      "temperature",
      "num_return_sequences",
      "length_penalty",
      "early_stopping",
      "forced_eos_token_id",
      "position_ids"
    ],
    "generate": []
  },
  "FasterBART": {
    "enable_faster_encoder_func": [],
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding",
      "enable_fast_encoder"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "encoder_output",
      "seq_len",
      "num_beams",
      "top_k",
      "top_p",
      "temperature",
      "decode_strategy",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "decoder_start_token_id",
      "min_length",
      "max_length",
      "diversity_rate",
      "length_penalty",
      "num_return_sequences",
      "early_stopping",
      "forced_eos_token_id"
    ],
    "generate": []
  },
  "FasterMBART": {
    "enable_faster_encoder_func": [],
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding",
      "enable_fast_encoder"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "encoder_output",
      "seq_len",
      "forced_bos_token_id",
      "num_beams",
      "top_k",
      "top_p",
      "decode_strategy",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "decoder_start_token_id",
      "max_length",
      "diversity_rate",
      "length_penalty",
      "temperature",
      "num_return_sequences",
      "early_stopping",
      "forced_eos_token_id"
    ],
    "generate": []
  },
  "FasterGPTJ": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding"
    ],
    "forward": [
      "self",
      "input_ids",
      "seq_len",
      "attention_mask",
      "top_k",
      "top_p",
      "min_length",
      "max_length",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "forced_eos_token_id",
      "temperature",
      "repetition_penalty",
      "decode_strategy",
      "num_return_sequences"
    ],
    "generate": []
  },
  "FasterCodeGen": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding"
    ],
    "forward": [
      "self",
      "input_ids",
      "seq_len",
      "attention_mask",
      "top_k",
      "top_p",
      "min_length",
      "max_length",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "forced_eos_token_id",
      "temperature",
      "repetition_penalty",
      "decode_strategy",
      "num_return_sequences"
    ],
    "generate": []
  },
  "FasterPegasus": {
    "enable_faster_encoder_func": [],
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding",
      "enable_fast_encoder"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "encoder_output",
      "seq_len",
      "min_length",
      "max_length",
      "num_beams",
      "decode_strategy",
      "decoder_start_token_id",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "diversity_rate",
      "length_penalty",
      "top_k",
      "top_p",
      "temperature",
      "num_return_sequences",
      "early_stopping",
      "forced_bos_token_id",
      "forced_eos_token_id"
    ],
    "generate": []
  },
  "FasterT5": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "encoder_output",
      "seq_len",
      "max_length",
      "min_length",
      "top_k",
      "top_p",
      "num_beams",
      "decode_strategy",
      "decoder_start_token_id",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "diversity_rate",
      "temperature",
      "num_return_sequences",
      "length_penalty",
      "early_stopping",
      "forced_eos_token_id"
    ],
    "generate": []
  },
  "infer_transformer_decoder": [
    "from_tensor",
    "memory_tensor",
    "mem_seq_len",
    "self_ln_weight",
    "self_ln_bias",
    "self_q_weight",
    "self_q_bias",
    "self_k_weight",
    "self_k_bias",
    "self_v_weight",
    "self_v_bias",
    "self_out_weight",
    "self_out_bias",
    "cross_ln_weight",
    "cross_ln_bias",
    "cross_q_weight",
    "cross_q_bias",
    "cross_k_weight",
    "cross_k_bias",
    "cross_v_weight",
    "cross_v_bias",
    "cross_out_weight",
    "cross_out_bias",
    "ffn_ln_weight",
    "ffn_ln_bias",
    "ffn_inter_weight",
    "ffn_inter_bias",
    "ffn_out_weight",
    "ffn_out_bias",
    "old_self_cache_key",
    "old_self_cache_value",
    "old_mem_cache",
    "step",
    "n_head",
    "size_per_head",
    "memory_hidden_dim",
    "is_fuse_qkv"
  ],
  "InferTransformerDecoder": {
    "__init__": [
      "self",
      "decoder",
      "n_head",
      "size_per_head",
      "decoder_lib",
      "use_fp16_decoder",
      "use_batch_major_op_cache"
    ],
    "forward": [
      "self",
      "from_tensor",
      "memory_tensor",
      "mem_seq_len",
      "self_cache_key",
      "self_cache_value",
      "mem_cache",
      "step",
      "memory_hidden_dim",
      "is_fuse_qkv"
    ]
  },
  "FasterDecoder": {
    "__init__": [
      "self",
      "src_vocab_size",
      "trg_vocab_size",
      "max_length",
      "num_encoder_layers",
      "num_decoder_layers",
      "n_head",
      "d_model",
      "d_inner_hid",
      "dropout",
      "weight_sharing",
      "bos_id",
      "eos_id",
      "max_out_len",
      "decoder_lib",
      "use_fp16_decoder",
      "use_batch_major_op_cache"
    ],
    "forward": [
      "self",
      "src_word"
    ],
    "load": [
      "self",
      "init_from_params"
    ]
  },
  "run_custom": [
    "op_name",
    "inputs_names",
    "inputs_var",
    "attrs_names",
    "attrs_val",
    "outputs_names",
    "outputs_dtype"
  ],
  "infer_transformer_decoding": [
    "enc_output",
    "memory_seq_lens",
    "word_emb",
    "slf_ln_weight",
    "slf_ln_bias",
    "slf_q_weight",
    "slf_q_bias",
    "slf_k_weight",
    "slf_k_bias",
    "slf_v_weight",
    "slf_v_bias",
    "slf_out_weight",
    "slf_out_bias",
    "cross_ln_weight",
    "cross_ln_bias",
    "cross_q_weight",
    "cross_q_bias",
    "cross_k_weight",
    "cross_k_bias",
    "cross_v_weight",
    "cross_v_bias",
    "cross_out_weight",
    "cross_out_bias",
    "ffn_ln_weight",
    "ffn_ln_bias",
    "ffn_inter_weight",
    "ffn_inter_bias",
    "ffn_out_weight",
    "ffn_out_bias",
    "decoder_ln_weight",
    "decoder_ln_bias",
    "linear_weight",
    "linear_bias",
    "pos_emb",
    "_decoding_strategy",
    "_beam_size",
    "_topk",
    "_topp",
    "_n_head",
    "_size_per_head",
    "_n_layer",
    "_bos_id",
    "_eos_id",
    "_max_out_len",
    "_diversity_rate",
    "_rel_len",
    "_alpha"
  ],
  "infer_force_decoding": [
    "enc_output",
    "memory_seq_lens",
    "word_emb",
    "slf_ln_weight",
    "slf_ln_bias",
    "slf_q_weight",
    "slf_q_bias",
    "slf_k_weight",
    "slf_k_bias",
    "slf_v_weight",
    "slf_v_bias",
    "slf_out_weight",
    "slf_out_bias",
    "cross_ln_weight",
    "cross_ln_bias",
    "cross_q_weight",
    "cross_q_bias",
    "cross_k_weight",
    "cross_k_bias",
    "cross_v_weight",
    "cross_v_bias",
    "cross_out_weight",
    "cross_out_bias",
    "ffn_ln_weight",
    "ffn_ln_bias",
    "ffn_inter_weight",
    "ffn_inter_bias",
    "ffn_out_weight",
    "ffn_out_bias",
    "decoder_ln_weight",
    "decoder_ln_bias",
    "linear_weight",
    "linear_bias",
    "pos_emb",
    "trg_word",
    "_decoding_strategy",
    "_beam_size",
    "_topk",
    "_topp",
    "_n_head",
    "_size_per_head",
    "_n_layer",
    "_bos_id",
    "_eos_id",
    "_max_out_len",
    "_diversity_rate",
    "_rel_len",
    "_alpha"
  ],
  "infer_opt_decoding": [
    "input",
    "attn_mask",
    "mem_seq_len",
    "word_emb",
    "slf_ln_weight",
    "slf_ln_bias",
    "slf_q_weight",
    "slf_q_bias",
    "slf_k_weight",
    "slf_k_bias",
    "slf_v_weight",
    "slf_v_bias",
    "slf_out_weight",
    "slf_out_bias",
    "ffn_ln_weight",
    "ffn_ln_bias",
    "ffn_inter_weight",
    "ffn_inter_bias",
    "ffn_out_weight",
    "ffn_out_bias",
    "decoder_ln_weight",
    "decoder_ln_bias",
    "pos_emb",
    "linear_weight",
    "normalize_before",
    "topk",
    "topp",
    "max_out_len",
    "head_num",
    "size_per_head",
    "num_layer",
    "bos_id",
    "eos_id",
    "temperature",
    "use_fp16_decoding"
  ],
  "infer_gpt_decoding": [
    "input",
    "attn_mask",
    "mem_seq_len",
    "word_emb",
    "slf_ln_weight",
    "slf_ln_bias",
    "slf_q_weight",
    "slf_q_bias",
    "slf_k_weight",
    "slf_k_bias",
    "slf_v_weight",
    "slf_v_bias",
    "slf_out_weight",
    "slf_out_bias",
    "ffn_ln_weight",
    "ffn_ln_bias",
    "ffn_inter_weight",
    "ffn_inter_bias",
    "ffn_out_weight",
    "ffn_out_bias",
    "decoder_ln_weight",
    "decoder_ln_bias",
    "pos_emb",
    "linear_weight",
    "topk",
    "topp",
    "max_out_len",
    "head_num",
    "size_per_head",
    "num_layer",
    "bos_id",
    "eos_id",
    "temperature",
    "use_fp16_decoding"
  ],
  "infer_unified_decoding": [
    "input_ids",
    "attn_mask",
    "memory_seq_lens",
    "type_id",
    "decoder_type_id",
    "logits_mask",
    "word_emb",
    "slf_ln_weight",
    "slf_ln_bias",
    "slf_q_weight",
    "slf_q_bias",
    "slf_k_weight",
    "slf_k_bias",
    "slf_v_weight",
    "slf_v_bias",
    "slf_out_weight",
    "slf_out_bias",
    "ffn_ln_weight",
    "ffn_ln_bias",
    "ffn_inter_weight",
    "ffn_inter_bias",
    "ffn_out_weight",
    "ffn_out_bias",
    "decoder_ln_weight",
    "decoder_ln_bias",
    "trans_weight",
    "trans_bias",
    "lm_ln_weight",
    "lm_ln_bias",
    "linear_weight",
    "linear_bias",
    "pos_emb",
    "type_emb",
    "role_id",
    "decoder_role_id",
    "role_emb",
    "position_id",
    "decoder_position_id",
    "_decoding_strategy",
    "_beam_size",
    "_topk",
    "_topp",
    "_n_head",
    "_size_per_head",
    "_n_layer",
    "_bos_id",
    "_eos_id",
    "_max_out_len",
    "_diversity_rate",
    "_unk_id",
    "_mask_id",
    "_temperature",
    "_len_penalty",
    "_normalize_before",
    "_pos_bias",
    "_hidden_act",
    "_rel_len",
    "_early_stopping",
    "_min_length"
  ],
  "infer_miro_decoding": [
    "input_ids",
    "attn_mask",
    "memory_seq_lens",
    "type_id",
    "decoder_type_id",
    "logits_mask",
    "word_emb",
    "pre_decoder_ln_weight",
    "pre_decoder_ln_bias",
    "slf_ln_weight",
    "slf_ln_bias",
    "slf_q_weight",
    "slf_q_bias",
    "slf_k_weight",
    "slf_k_bias",
    "slf_v_weight",
    "slf_v_bias",
    "slf_out_weight",
    "slf_out_bias",
    "ffn_ln_weight",
    "ffn_ln_bias",
    "ffn_inter_weight",
    "ffn_inter_bias",
    "ffn_out_weight",
    "ffn_out_bias",
    "decoder_ln_weight",
    "decoder_ln_bias",
    "trans_weight",
    "trans_bias",
    "lm_ln_weight",
    "lm_ln_bias",
    "linear_weight",
    "linear_bias",
    "pos_emb",
    "type_emb",
    "role_id",
    "decoder_role_id",
    "role_emb",
    "position_id",
    "decoder_position_id",
    "_decoding_strategy",
    "_beam_size",
    "_topk",
    "_topp",
    "_n_head",
    "_size_per_head",
    "_n_layer",
    "_bos_id",
    "_eos_id",
    "_max_out_len",
    "_diversity_rate",
    "_unk_id",
    "_mask_id",
    "_temperature",
    "_len_penalty",
    "_normalize_before",
    "_pos_bias",
    "_hidden_act",
    "_rel_len",
    "_early_stopping",
    "_min_length"
  ],
  "infer_bart_decoding": [
    "enc_output",
    "memory_seq_lens",
    "word_emb",
    "slf_ln_weight",
    "slf_ln_bias",
    "slf_q_weight",
    "slf_q_bias",
    "slf_k_weight",
    "slf_k_bias",
    "slf_v_weight",
    "slf_v_bias",
    "slf_out_weight",
    "slf_out_bias",
    "cross_ln_weight",
    "cross_ln_bias",
    "cross_q_weight",
    "cross_q_bias",
    "cross_k_weight",
    "cross_k_bias",
    "cross_v_weight",
    "cross_v_bias",
    "cross_out_weight",
    "cross_out_bias",
    "ffn_ln_weight",
    "ffn_ln_bias",
    "ffn_inter_weight",
    "ffn_inter_bias",
    "ffn_out_weight",
    "ffn_out_bias",
    "decoder_ln_weight",
    "decoder_ln_bias",
    "linear_weight",
    "linear_bias",
    "pos_emb",
    "_decoding_strategy",
    "_beam_size",
    "_topk",
    "_topp",
    "_temperature",
    "_n_head",
    "_size_per_head",
    "_n_layer",
    "_bos_id",
    "_eos_id",
    "_max_out_len",
    "_min_out_len",
    "_diversity_rate",
    "_rel_len",
    "_alpha",
    "_early_stopping"
  ],
  "infer_mbart_decoding": [
    "enc_output",
    "memory_seq_lens",
    "word_emb",
    "slf_ln_weight",
    "slf_ln_bias",
    "slf_q_weight",
    "slf_q_bias",
    "slf_k_weight",
    "slf_k_bias",
    "slf_v_weight",
    "slf_v_bias",
    "slf_out_weight",
    "slf_out_bias",
    "cross_ln_weight",
    "cross_ln_bias",
    "cross_q_weight",
    "cross_q_bias",
    "cross_k_weight",
    "cross_k_bias",
    "cross_v_weight",
    "cross_v_bias",
    "cross_out_weight",
    "cross_out_bias",
    "ffn_ln_weight",
    "ffn_ln_bias",
    "ffn_inter_weight",
    "ffn_inter_bias",
    "ffn_out_weight",
    "ffn_out_bias",
    "decoder_ln_weight",
    "decoder_ln_bias",
    "mbart_ln_weight",
    "mbart_ln_bias",
    "linear_weight",
    "linear_bias",
    "pos_emb",
    "trg_word",
    "_decoding_strategy",
    "_beam_size",
    "_topk",
    "_topp",
    "_n_head",
    "_size_per_head",
    "_n_layer",
    "_bos_id",
    "_eos_id",
    "_max_out_len",
    "_diversity_rate",
    "_rel_len",
    "_alpha",
    "_temperature",
    "_early_stopping",
    "_hidden_act"
  ],
  "infer_gptj_decoding": [
    "input",
    "attn_mask",
    "mem_seq_len",
    "word_emb",
    "slf_ln_weight",
    "slf_ln_bias",
    "slf_q_weight",
    "slf_out_weight",
    "ffn_inter_weight",
    "ffn_inter_bias",
    "ffn_out_weight",
    "ffn_out_bias",
    "decoder_ln_weight",
    "decoder_ln_bias",
    "linear_weight",
    "linear_bias",
    "topk",
    "topp",
    "max_out_len",
    "head_num",
    "size_per_head",
    "num_layer",
    "bos_id",
    "eos_id",
    "temperature",
    "rotary_embedding_dim",
    "repetition_penalty",
    "min_length",
    "use_fp16_decoding"
  ],
  "infer_pegasus_decoding": [
    "enc_output",
    "memory_seq_lens",
    "word_emb",
    "slf_ln_weight",
    "slf_ln_bias",
    "slf_q_weight",
    "slf_q_bias",
    "slf_k_weight",
    "slf_k_bias",
    "slf_v_weight",
    "slf_v_bias",
    "slf_out_weight",
    "slf_out_bias",
    "cross_ln_weight",
    "cross_ln_bias",
    "cross_q_weight",
    "cross_q_bias",
    "cross_k_weight",
    "cross_k_bias",
    "cross_v_weight",
    "cross_v_bias",
    "cross_out_weight",
    "cross_out_bias",
    "ffn_ln_weight",
    "ffn_ln_bias",
    "ffn_inter_weight",
    "ffn_inter_bias",
    "ffn_out_weight",
    "ffn_out_bias",
    "decoder_ln_weight",
    "decoder_ln_bias",
    "linear_weight",
    "linear_bias",
    "pos_emb",
    "_decoding_strategy",
    "_beam_size",
    "_topk",
    "_topp",
    "_n_head",
    "_size_per_head",
    "_n_layer",
    "_bos_id",
    "_eos_id",
    "_max_out_len",
    "_min_out_len",
    "_diversity_rate",
    "_rel_len",
    "_alpha",
    "_temperature",
    "_early_stopping",
    "_hidden_act"
  ],
  "infer_t5_decoding": [
    "enc_output",
    "memory_seq_lens",
    "word_emb",
    "slf_ln_weight",
    "slf_ln_bias",
    "slf_q_weight",
    "slf_q_bias",
    "slf_k_weight",
    "slf_k_bias",
    "slf_v_weight",
    "slf_v_bias",
    "slf_out_weight",
    "slf_out_bias",
    "cross_ln_weight",
    "cross_ln_bias",
    "cross_q_weight",
    "cross_q_bias",
    "cross_k_weight",
    "cross_k_bias",
    "cross_v_weight",
    "cross_v_bias",
    "cross_out_weight",
    "cross_out_bias",
    "ffn_ln_weight",
    "ffn_ln_bias",
    "ffn_inter_weight_0",
    "ffn_inter_bias_0",
    "ffn_inter_weight_1",
    "ffn_inter_bias_1",
    "ffn_out_weight",
    "ffn_out_bias",
    "relative_attention_bias_weight",
    "decoder_ln_weight",
    "decoder_ln_bias",
    "linear_weight",
    "linear_bias",
    "decoding_strategy",
    "beam_size",
    "top_k",
    "top_p",
    "head_num",
    "size_per_head",
    "num_decoder_layers",
    "start_id",
    "end_id",
    "max_out_len",
    "diversity_rate",
    "rel_len",
    "alpha",
    "temperature",
    "early_stopping",
    "max_distance",
    "relative_attention_num_buckets",
    "tie_word_embeddings",
    "act"
  ],
  "finalize": [
    "beam_size",
    "output_ids",
    "parent_ids",
    "out_seq_lens",
    "forced_eos_token_id",
    "max_seq_len",
    "decoding_strategy"
  ],
  "transfer_param": [
    "p",
    "is_bias",
    "dtype",
    "restore_data"
  ],
  "_convert_qkv": [
    "q_proj",
    "k_proj",
    "v_proj",
    "attr",
    "use_numpy",
    "del_param",
    "dummy_tensor"
  ],
  "convert_params": [
    "fast_model",
    "model",
    "fuse_qkv",
    "use_fp16",
    "restore_data"
  ],
  "InferBase": {
    "__init__": [
      "self",
      "use_fp16_decoding"
    ],
    "default_bias": [
      "self",
      "weight",
      "index",
      "is_null"
    ]
  },
  "InferTransformerDecoding": {
    "__init__": [
      "self",
      "decoder",
      "word_embedding",
      "positional_embedding",
      "linear",
      "num_decoder_layers",
      "n_head",
      "d_model",
      "bos_id",
      "eos_id",
      "decoding_strategy",
      "beam_size",
      "topk",
      "topp",
      "max_out_len",
      "diversity_rate",
      "decoding_lib",
      "use_fp16_decoding",
      "rel_len",
      "alpha"
    ],
    "forward": [
      "self",
      "enc_output",
      "memory_seq_lens",
      "trg_word"
    ]
  },
  "FTParaConf": {
    "__init__": [
      "self",
      "tensor_para_size",
      "layer_para_size",
      "layer_para_batch_size"
    ],
    "_env2int": [
      "env_list",
      "default"
    ],
    "is_last_group": [
      "self"
    ],
    "is_load": [
      "self",
      "i",
      "num_layer"
    ],
    "slice_weight": [
      "self",
      "weight",
      "axis",
      "phase",
      "out_param"
    ],
    "set_partial_model": [
      "self",
      "is_partial_model"
    ],
    "fit_partial_model": [
      "self",
      "model",
      "state_to_load"
    ]
  },
  "_ft_para_conf": [],
  "get_ft_para_conf": [],
  "enable_ft_para": [
    "tensor_para_size",
    "layer_para_size",
    "layer_para_batch_size"
  ],
  "InferOptDecoding": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding"
    ],
    "forward": [
      "self",
      "input_ids",
      "mem_seq_len",
      "attention_mask",
      "topk",
      "topp",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "forced_eos_token_id",
      "max_out_len",
      "temperature"
    ]
  },
  "InferGptDecoding": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding"
    ],
    "forward": [
      "self",
      "input_ids",
      "mem_seq_len",
      "attention_mask",
      "topk",
      "topp",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "forced_eos_token_id",
      "max_out_len",
      "temperature"
    ]
  },
  "InferUnifiedDecoding": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding",
      "logits_mask",
      "n_head",
      "hidden_dims",
      "size_per_head",
      "n_layer",
      "unk_id",
      "mask_id",
      "normalize_before",
      "hidden_act"
    ],
    "forward": [
      "self",
      "input_ids",
      "attn_mask",
      "memory_seq_lens",
      "type_id",
      "decoder_type_id",
      "role_id",
      "decoder_role_id",
      "position_id",
      "decoder_position_id",
      "beam_size",
      "topk",
      "topp",
      "decoding_strategy",
      "max_out_len",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "forced_eos_token_id",
      "temperature",
      "length_penalty",
      "diversity_rate",
      "pos_bias",
      "rel_len",
      "early_stopping",
      "min_length"
    ]
  },
  "InferMIRODecoding": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding",
      "logits_mask",
      "n_head",
      "hidden_dims",
      "size_per_head",
      "n_layer",
      "unk_id",
      "mask_id",
      "normalize_before",
      "hidden_act"
    ],
    "forward": [
      "self",
      "input_ids",
      "attn_mask",
      "memory_seq_lens",
      "type_id",
      "decoder_type_id",
      "role_id",
      "decoder_role_id",
      "position_id",
      "decoder_position_id",
      "beam_size",
      "topk",
      "topp",
      "decoding_strategy",
      "max_out_len",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "forced_eos_token_id",
      "temperature",
      "length_penalty",
      "diversity_rate",
      "pos_bias",
      "rel_len",
      "early_stopping",
      "min_length"
    ]
  },
  "InferBartDecoding": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding"
    ],
    "forward": [
      "self",
      "enc_output",
      "memory_seq_lens",
      "beam_size",
      "top_k",
      "top_p",
      "temperature",
      "decoding_strategy",
      "max_out_len",
      "min_out_len",
      "diversity_rate",
      "rel_len",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "forced_eos_token_id",
      "alpha",
      "early_stopping"
    ]
  },
  "InferMBartDecoding": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding",
      "hidden_act"
    ],
    "forward": [
      "self",
      "enc_output",
      "memory_seq_lens",
      "trg_word",
      "beam_size",
      "top_k",
      "top_p",
      "decoding_strategy",
      "max_out_len",
      "diversity_rate",
      "rel_len",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "alpha",
      "temperature",
      "early_stopping"
    ]
  },
  "convert_gptj_params": [
    "fast_model",
    "model",
    "fuse_qkv",
    "use_fp16",
    "restore_data",
    "permutation"
  ],
  "InferGptJDecoding": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding",
      "transpose_qkv"
    ],
    "forward": [
      "self",
      "input_ids",
      "mem_seq_len",
      "attention_mask",
      "topk",
      "topp",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "forced_eos_token_id",
      "max_out_len",
      "temperature",
      "repetition_penalty",
      "min_length"
    ]
  },
  "InferPegasusDecoding": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding",
      "hidden_act"
    ],
    "forward": [
      "self",
      "enc_output",
      "memory_seq_lens",
      "beam_size",
      "top_k",
      "top_p",
      "decoding_strategy",
      "max_out_len",
      "min_out_len",
      "diversity_rate",
      "rel_len",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "alpha",
      "temperature",
      "early_stopping",
      "forced_eos_token_id"
    ]
  },
  "InferT5Decoding": {
    "__init__": [
      "self",
      "model",
      "decoding_lib",
      "use_fp16_decoding"
    ],
    "forward": [
      "self",
      "enc_output",
      "memory_seq_lens",
      "beam_size",
      "top_k",
      "top_p",
      "decoding_strategy",
      "max_out_len",
      "diversity_rate",
      "rel_len",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "alpha",
      "temperature",
      "early_stopping"
    ]
  },
  "infer_transformer_encoder": [
    "input",
    "attn_mask",
    "q_weight",
    "q_bias",
    "k_weight",
    "k_bias",
    "v_weight",
    "v_bias",
    "attn_out_weight",
    "attn_out_bias",
    "norm1_weight",
    "norm1_bias",
    "norm2_weight",
    "norm2_bias",
    "ffn_inter_weight",
    "ffn_inter_bias",
    "ffn_out_weight",
    "ffn_out_bias",
    "n_head",
    "size_per_head",
    "n_layer",
    "use_gelu",
    "remove_padding",
    "int8_mode",
    "layer_idx",
    "allow_gemm_test",
    "use_trt_kernel",
    "normalize_before"
  ],
  "encoder_layer_forward": [
    "self",
    "src",
    "src_mask",
    "cache",
    "sequence_id_offset",
    "trt_seq_len"
  ],
  "encoder_forward": [
    "self",
    "src",
    "src_mask",
    "cache"
  ],
  "enable_fast_encoder": [
    "self",
    "use_fp16",
    "encoder_lib"
  ],
  "disable_fast_encoder": [
    "self"
  ],
  "convert_to_fp16": [
    "transformer_encoder"
  ],
  "tuple_output": [
    "outputs",
    "loss"
  ],
  "convert_encoder_output": [
    "encoder_output"
  ],
  "layer_init_wrapper": [
    "func"
  ],
  "_transformer_encoder_layer_fwd": [
    "self",
    "src",
    "src_mask",
    "cache",
    "output_attentions"
  ],
  "_transformer_decoder_layer_fwd": [
    "self",
    "tgt",
    "memory",
    "tgt_mask",
    "memory_mask",
    "cache",
    "output_attentions"
  ],
  "_transformer_decoder_fwd": [
    "self",
    "tgt",
    "memory",
    "tgt_mask",
    "memory_mask",
    "cache",
    "output_attentions",
    "output_hidden_states",
    "return_dict"
  ],
  "_transformer_encoder_fwd": [
    "self",
    "src",
    "src_mask",
    "cache",
    "output_attentions",
    "output_hidden_states",
    "return_dict"
  ],
  "_encoder_init": [],
  "_decoder_init": [],
  "_get_wrap_setattr": [
    "cls"
  ],
  "is_tensor": [
    "x"
  ],
  "ModelOutput": {
    "__post_init__": [
      "self"
    ],
    "__delitem__": [
      "self"
    ],
    "setdefault": [
      "self"
    ],
    "pop": [
      "self"
    ],
    "update": [
      "self"
    ],
    "__getitem__": [
      "self",
      "k"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "to_tuple": [
      "self"
    ]
  },
  "BaseModelOutput": {},
  "BaseModelOutputWithNoAttention": {},
  "BaseModelOutputWithPooling": {},
  "BaseModelOutputWithPast": {},
  "BaseModelOutputWithPastAndCrossAttentions": {},
  "BaseModelOutputWithPoolingAndCrossAttentions": {},
  "SequenceClassifierOutput": {},
  "TokenClassifierOutput": {},
  "QuestionAnsweringModelOutput": {},
  "MultipleChoiceModelOutput": {},
  "MaskedLMOutput": {},
  "CausalLMOutputWithPast": {},
  "CausalLMOutputWithCrossAttentions": {},
  "Seq2SeqModelOutput": {},
  "Seq2SeqLMOutput": {},
  "Seq2SeqQuestionAnsweringModelOutput": {},
  "Seq2SeqSequenceClassifierOutput": {},
  "SequenceClassifierOutputWithPast": {},
  "BackboneOutput": {},
  "BaseModelOutputWithPoolingAndNoAttention": {},
  "ImageClassifierOutputWithNoAttention": {},
  "DepthEstimatorOutput": {},
  "SemanticSegmenterOutput": {},
  "Seq2SeqSpectrogramOutput": {},
  "MoEModelOutputWithPast": {},
  "MoECausalLMOutputWithPast": {},
  "convert_to_unicode": [
    "text"
  ],
  "whitespace_tokenize": [
    "text"
  ],
  "_is_whitespace": [
    "char"
  ],
  "_is_control": [
    "char"
  ],
  "_is_punctuation": [
    "char"
  ],
  "_is_end_of_word": [
    "text"
  ],
  "_is_start_of_word": [
    "text"
  ],
  "_insert_one_token_to_ordered_list": [
    "token_list",
    "new_token"
  ],
  "is_chinese_char": [
    "cp"
  ],
  "_is_nonnormalized_char": [
    "char"
  ],
  "_is_nonnormalized_numeric": [
    "char"
  ],
  "normalize_chars": [
    "text"
  ],
  "_is_symbol": [
    "char"
  ],
  "tokenize_special_chars": [
    "text"
  ],
  "Trie": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "word"
    ],
    "split": [
      "self",
      "text"
    ],
    "cut_text": [
      "self",
      "text",
      "offsets"
    ]
  },
  "tokenize_chinese_chars": [
    "text"
  ],
  "ChatTemplate": {
    "_compile_jinja_template": [
      "chat_template"
    ],
    "render_conversation": [
      "self",
      "conversation_data",
      "index",
      "context_data"
    ],
    "render_query": [
      "self",
      "query",
      "index",
      "context_data"
    ],
    "_init_context_data": [
      "self",
      "context_data"
    ],
    "render_system": [
      "self",
      "context_data"
    ],
    "__call__": [
      "self",
      "conversations",
      "context_data"
    ],
    "from_dict": [
      "cls",
      "config"
    ],
    "from_file": [
      "cls",
      "file"
    ]
  },
  "ChatTemplateMixin": {
    "apply_chat_template": [
      "self",
      "conversation",
      "tokenize",
      "context_data"
    ],
    "encode_chat_inputs": [
      "self",
      "conversations",
      "context_data"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "init_chat_template": [
      "self",
      "chat_template"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ]
  },
  "PretrainedTokenizer": {
    "tokens_trie": [],
    "_decode_use_source_tokenizer": [],
    "_pre_init": [
      "self",
      "original_init"
    ],
    "_build_special_tokens_map_extended": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "is_fast": [
      "self"
    ],
    "get_added_vocab": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "_add_tokens": [
      "self",
      "new_tokens",
      "special_tokens"
    ],
    "_create_trie": [
      "self",
      "unique_no_split_tokens"
    ],
    "prepare_for_tokenization": [
      "self",
      "text",
      "is_split_into_words"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "_convert_token_to_id_with_added_voc": [
      "self",
      "token"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "load_vocabulary": [
      "filepath",
      "unk_token",
      "pad_token",
      "bos_token",
      "eos_token"
    ],
    "save_vocabulary": [
      "filepath",
      "vocab"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "_encode_plus": [
      "self",
      "text",
      "text_pair",
      "add_special_tokens",
      "padding_strategy",
      "truncation_strategy",
      "max_length",
      "stride",
      "is_split_into_words",
      "pad_to_multiple_of",
      "return_tensors",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "_batch_encode_plus": [
      "self",
      "batch_text_or_text_pairs",
      "add_special_tokens",
      "padding_strategy",
      "truncation_strategy",
      "max_length",
      "stride",
      "is_split_into_words",
      "pad_to_multiple_of",
      "return_position_ids",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "_batch_prepare_for_model": [
      "self",
      "batch_ids_pairs",
      "add_special_tokens",
      "padding_strategy",
      "truncation_strategy",
      "max_length",
      "stride",
      "pad_to_multiple_of",
      "return_position_ids",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "_get_bert_like_offset_mapping": [
      "self",
      "text"
    ],
    "get_offset_mapping": [
      "self",
      "text",
      "split_tokens"
    ],
    "_decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces",
      "spaces_between_special_tokens"
    ],
    "decode_token": [
      "self",
      "all_input_ids",
      "prefix_offset",
      "read_offset"
    ]
  },
  "BPETokenizer": {
    "__init__": [
      "self",
      "vocab_file",
      "encoder_json_path",
      "vocab_bpe_path",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "_tokenize": [
      "self",
      "text",
      "is_sentencepiece"
    ],
    "_get_encoder": [
      "self",
      "encoder_json_path",
      "vocab_bpe_path"
    ]
  },
  "SequenceFeatureExtractor": {
    "__init__": [
      "self",
      "feature_size",
      "sampling_rate",
      "padding_value"
    ],
    "pad": [
      "self",
      "processed_features",
      "padding",
      "max_length",
      "truncation",
      "pad_to_multiple_of",
      "return_attention_mask",
      "return_tensors"
    ],
    "_pad": [
      "self",
      "processed_features",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ],
    "_truncate": [
      "self",
      "processed_features",
      "max_length",
      "pad_to_multiple_of",
      "truncation"
    ],
    "_get_padding_strategies": [
      "self",
      "padding",
      "max_length"
    ]
  },
  "export_model": [
    "model",
    "input_spec",
    "path",
    "model_format"
  ],
  "ProcessorMixin": {
    "attributes": [],
    "feature_extractor_class": [],
    "tokenizer_class": [],
    "_auto_class": [],
    "__init__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "save_pretrained": [
      "self",
      "save_directory"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "_get_arguments_from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "model_input_names": [
      "self"
    ]
  },
  "__all_gather_recomputation__": [],
  "is_mc2_valid": [],
  "is_paddle_tensor": [
    "tensor"
  ],
  "to_channel_dimension_format": [
    "image",
    "channel_dim",
    "input_channel_dim"
  ],
  "rescale": [
    "image",
    "scale",
    "data_format",
    "dtype"
  ],
  "to_pil_image": [
    "image",
    "do_rescale"
  ],
  "get_resize_output_image_size": [
    "input_image",
    "size",
    "default_to_square",
    "max_size"
  ],
  "resize": [
    "image",
    "size",
    "resample",
    "reducing_gap",
    "data_format",
    "return_numpy"
  ],
  "normalize": [
    "image",
    "mean",
    "std",
    "data_format"
  ],
  "center_crop": [
    "image",
    "size",
    "data_format",
    "return_numpy"
  ],
  "_center_to_corners_format_paddle": [
    "bboxes_center"
  ],
  "_center_to_corners_format_numpy": [
    "bboxes_center"
  ],
  "center_to_corners_format": [
    "bboxes_center"
  ],
  "_corners_to_center_format_paddle": [
    "bboxes_corners"
  ],
  "_corners_to_center_format_numpy": [
    "bboxes_corners"
  ],
  "corners_to_center_format": [
    "bboxes_corners"
  ],
  "rgb_to_id": [
    "color"
  ],
  "id_to_rgb": [
    "id_map"
  ],
  "PaddingMode": {
    "CONSTANT": [],
    "REFLECT": [],
    "REPLICATE": [],
    "SYMMETRIC": []
  },
  "pad": [
    "image",
    "padding",
    "mode",
    "constant_values",
    "data_format",
    "input_data_format"
  ],
  "convert_to_rgb": [
    "image"
  ],
  "Module": [],
  "PytorchTensor": [],
  "tensor_summary": [
    "tensor"
  ],
  "compare_model_weights": [
    "first_state_dict",
    "second_state_dict"
  ],
  "state_dict_contains_prefix": [
    "state_dict",
    "prefix"
  ],
  "init_name_mappings": [
    "mappings"
  ],
  "StateDictKeysChecker": {
    "__init__": [
      "self",
      "model_or_state_dict",
      "loaded_state_dict",
      "check_shape",
      "base_model_prefix",
      "ignore_keys"
    ],
    "change_base_downstream_mismatched_keys": [
      "self"
    ],
    "change_downstream_base_mismatched_keys": [
      "self"
    ],
    "change_diff_keys": [
      "self"
    ],
    "get_unexpected_keys": [
      "self"
    ],
    "get_mismatched_keys": [
      "self"
    ],
    "get_diff_keys": [
      "self",
      "return_all_diff"
    ]
  },
  "naive_fuse_merge_tp": [
    "weight_list",
    "is_column",
    "fuse_tensor_parts"
  ],
  "naive_fuse_split_tp": [
    "weight",
    "tensor_parallel_degree",
    "tensor_parallel_rank",
    "is_column",
    "fuse_tensor_parts"
  ],
  "normal_fuse_merge_tp": [
    "weight_list",
    "is_column"
  ],
  "normal_fuse_split_tp": [
    "weight",
    "tensor_parallel_degree",
    "tensor_parallel_rank",
    "is_column"
  ],
  "tensor_parallel_qkv_to_naive_merged_qkv": [
    "weight",
    "num_attention_heads"
  ],
  "naive_merged_qkv_to_tensor_parallel_qkv": [
    "weight",
    "num_attention_heads"
  ],
  "splited_qkv_to_tensor_parallel_qkv": [
    "weight_list",
    "num_attention_heads"
  ],
  "fuse_param_func": [],
  "split_param_func": [],
  "split_or_fuse_func": [
    "is_fuse"
  ],
  "get_tensor_parallel_merge_func": [
    "tensor_parallel_degree",
    "tensor_parallel_rank",
    "num_attention_heads"
  ],
  "get_tensor_parallel_split_func": [
    "tensor_parallel_degree",
    "tensor_parallel_rank",
    "num_attention_heads"
  ],
  "split_or_merge_func": [
    "is_split",
    "tensor_parallel_degree",
    "tensor_parallel_rank",
    "num_attention_heads"
  ],
  "StateDictNameMapping": {
    "__post_init__": [
      "self"
    ],
    "should_transpose": [
      "self"
    ],
    "should_merge_last_two_dim": [
      "self"
    ],
    "run": [
      "self",
      "state_dict",
      "name"
    ],
    "matched": [
      "self",
      "text"
    ]
  },
  "TensorInfoSaver": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "state_dict_key",
      "key",
      "values"
    ],
    "summary": [
      "self",
      "output_path"
    ],
    "summary_to_excel": [
      "self",
      "file"
    ],
    "summary_to_terminal": [
      "self"
    ],
    "clear": [
      "self"
    ]
  },
  "LogitHooker": {
    "__init__": [
      "self",
      "mappings",
      "tensor_info_saver"
    ],
    "_paddle_hooks": [
      "self",
      "layer",
      "inputs",
      "outputs"
    ],
    "_pytorch_hooks": [
      "self",
      "layer",
      "inputs",
      "outputs"
    ],
    "register_paddle_model_hooks": [
      "self",
      "model"
    ],
    "register_pytorch_model_hooks": [
      "self",
      "model"
    ],
    "summary": [
      "self"
    ]
  },
  "LogitComparer": {
    "_ignore_state_dict_keys": [],
    "num_layer_regex": [],
    "__init__": [
      "self",
      "input_dir"
    ],
    "get_paddle_pytorch_model_classes": [
      "self"
    ],
    "get_inputs": [
      "self"
    ],
    "resolve_paddle_output_logits": [
      "self",
      "paddle_outputs"
    ],
    "resolve_pytorch_output_logits": [
      "self",
      "pytorch_outputs"
    ],
    "get_model_state_dict": [
      "model",
      "copy"
    ],
    "compare_model_state_dicts": [
      "self",
      "paddle_model",
      "pytorch_model",
      "name_mappings"
    ],
    "compare_logits": [
      "self"
    ],
    "on_converted": [
      "self"
    ]
  },
  "ConversionMixin": {
    "support_conversion": [
      "cls",
      "config"
    ],
    "convert": [
      "cls",
      "weight_file",
      "config",
      "cache_dir"
    ],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "get_tensor_parallel_convert_actions": [
      "cls",
      "config",
      "loaded_state_dict_keys",
      "is_split",
      "ignore_error"
    ],
    "convert_tensor_parallel": [
      "cls",
      "weight_file",
      "config",
      "state_dict",
      "ignore_error"
    ],
    "merge_tensor_parallel": [
      "cls",
      "state_dict",
      "config"
    ],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ],
    "_resolve_prefix_keys": [
      "state_keys_base",
      "state_keys_real",
      "ignore_error"
    ],
    "convert_fuse_and_split": [
      "cls",
      "config",
      "state_dict",
      "tp_actions"
    ],
    "get_fuse_or_split_param_convert_actions": [
      "cls",
      "config",
      "loaded_state_dict_keys",
      "is_fuse",
      "ignore_error"
    ],
    "_get_fuse_or_split_param_mappings": [
      "cls",
      "config",
      "is_fuse"
    ],
    "_resolve_prefix_keys_for_fuse_and_split": [
      "state_keys_base",
      "state_keys_real",
      "ignore_error",
      "is_fuse"
    ]
  },
  "Converter": {
    "__init__": [
      "self"
    ],
    "resolve_num_layer": [
      "cls",
      "config_or_num_layers"
    ],
    "convert": [
      "self",
      "input_dir"
    ]
  },
  "IMAGE_PROCESSOR_NAME": [],
  "BatchFeature": {},
  "ImageProcessingMixin": {
    "pretrained_init_configuration": [],
    "_auto_class": [],
    "__init__": [
      "self"
    ],
    "_set_processor_class": [
      "self",
      "processor_class"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "save_pretrained": [
      "self",
      "save_directory"
    ],
    "save_to_hf_hub": [
      "self",
      "repo_id",
      "private",
      "subfolder",
      "commit_message",
      "revision",
      "create_pr"
    ],
    "save_to_aistudio": [
      "self",
      "repo_id",
      "private",
      "license",
      "exist_ok",
      "subfolder"
    ],
    "get_image_processor_dict": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "from_dict": [
      "cls",
      "image_processor_dict"
    ],
    "to_dict": [
      "self"
    ],
    "from_json_file": [
      "cls",
      "json_file"
    ],
    "to_json_string": [
      "self"
    ],
    "to_json_file": [
      "self",
      "json_file_path"
    ],
    "__repr__": [
      "self"
    ]
  },
  "BaseImageProcessor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "images"
    ],
    "preprocess": [
      "self",
      "images"
    ]
  },
  "VALID_SIZE_DICT_KEYS": [],
  "is_valid_size_dict": [
    "size_dict"
  ],
  "convert_to_size_dict": [
    "size",
    "max_size",
    "default_to_square",
    "height_width_order"
  ],
  "get_size_dict": [
    "size",
    "max_size",
    "height_width_order",
    "default_to_square",
    "param_name"
  ],
  "_sym_db": [],
  "DESCRIPTOR": [],
  "_TRAINERSPEC_MODELTYPE": [],
  "_MODELPROTO_SENTENCEPIECE_TYPE": [],
  "_TRAINERSPEC": [],
  "_NORMALIZERSPEC": [],
  "_SELFTESTDATA_SAMPLE": [],
  "_SELFTESTDATA": [],
  "_MODELPROTO_SENTENCEPIECE": [],
  "_MODELPROTO": [],
  "TrainerSpec": [],
  "NormalizerSpec": [],
  "SelfTestData": [],
  "ModelProto": [],
  "NewGELUActivation": {
    "forward": [
      "self",
      "input"
    ]
  },
  "GELUActivation": {
    "__init__": [
      "self",
      "use_gelu_python"
    ],
    "_gelu_python": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "FastGELUActivation": {
    "forward": [
      "self",
      "input"
    ]
  },
  "QuickGELUActivation": {
    "forward": [
      "self",
      "input"
    ]
  },
  "ClippedGELUActivation": {
    "__init__": [
      "self",
      "min",
      "max"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SiLUActivation": {
    "forward": [
      "self",
      "input"
    ]
  },
  "MishActivation": {
    "forward": [
      "self",
      "input"
    ]
  },
  "LinearActivation": {
    "forward": [
      "self",
      "input"
    ]
  },
  "ClassInstantier": {
    "__getitem__": [
      "self",
      "key"
    ]
  },
  "ACT2CLS": [],
  "ACT2FN": [],
  "get_activation": [
    "activation_string"
  ],
  "gelu_python": [],
  "gelu_new": [],
  "gelu": [],
  "gelu_fast": [],
  "quick_gelu": [],
  "silu": [],
  "mish": [],
  "linear_act": [],
  "Linear": [],
  "ColumnParallelLinear": [],
  "RowParallelLinear": [],
  "dy2st_nocheck_guard_context": [],
  "unwrap_optimizer": [
    "optimizer",
    "optimizer_instances"
  ],
  "prune_linear_layer": [
    "layer",
    "index",
    "dim"
  ],
  "find_pruneable_heads_and_indices": [
    "heads",
    "n_heads",
    "head_size",
    "already_pruned_heads"
  ],
  "apply_chunking_to_forward": [
    "forward_fn",
    "chunk_size",
    "chunk_dim"
  ],
  "unwrap_model": [
    "model"
  ],
  "_add_variant": [
    "weights_name",
    "variant"
  ],
  "dtype_guard": [
    "dtype"
  ],
  "_init_weights": [],
  "no_init_weights": [
    "_enable"
  ],
  "get_parameter_dtype": [
    "parameter"
  ],
  "load_state_dict": [
    "checkpoint_file",
    "tensor_parallel_split_mapping",
    "fliter_dict_keys",
    "device"
  ],
  "resolve_weight_file_from_hf_hub": [
    "repo_id",
    "cache_dir",
    "convert_from_torch",
    "subfolder",
    "use_safetensors"
  ],
  "register_base_model": [
    "cls"
  ],
  "BackboneMixin": {
    "forward_with_filtered_kwargs": [
      "self"
    ]
  },
  "_re_layer_prefix": [],
  "_partion_for_pipeline_mode": [
    "keys"
  ],
  "shard_checkpoint": [
    "state_dict",
    "max_shard_size",
    "weights_name",
    "shard_format"
  ],
  "load_sharded_checkpoint": [
    "model",
    "folder",
    "variant",
    "strict",
    "prefer_safe"
  ],
  "faster_set_state_dict": [
    "model",
    "state_dict",
    "strict_dtype"
  ],
  "_load_state_dict_into_model": [
    "model_to_load",
    "state_dict",
    "start_prefix"
  ],
  "_convert_state_dict_dtype_and_shape": [
    "state_dict",
    "model_to_load"
  ],
  "_load_state_dict_into_meta_model": [
    "model",
    "state_dict",
    "loaded_state_dict_keys",
    "start_prefix",
    "expected_keys",
    "dtype",
    "is_safetensors",
    "keep_in_fp32_modules"
  ],
  "PretrainedModel": {
    "model_config_file": [],
    "pretrained_init_configuration": [],
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "main_input_name": [],
    "config_class": [],
    "_keep_in_fp32_modules": [],
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_save": [],
    "_tied_weights_keys": [],
    "__init__": [
      "self"
    ],
    "_post_init": [
      "self",
      "original_init"
    ],
    "_init_weights": [
      "self",
      "layer"
    ],
    "_initialize_weights": [
      "self",
      "layer"
    ],
    "init_weights": [
      "self"
    ],
    "_from_config": [
      "cls",
      "config"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "base_model": [
      "self"
    ],
    "model_name_list": [
      "self"
    ],
    "can_generate": [
      "self"
    ],
    "recompute_enable": [
      "self"
    ],
    "recompute_disable": [
      "self"
    ],
    "get_memory_footprint": [
      "self",
      "return_buffers"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "tie_weights": [
      "self"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "constructed_from_pretrained_config": [
      "cls",
      "init_func"
    ],
    "save_model_config": [
      "self",
      "save_dir"
    ],
    "save_to_hf_hub": [
      "self",
      "repo_id",
      "private",
      "subfolder",
      "commit_message",
      "revision",
      "create_pr"
    ],
    "save_to_aistudio": [
      "self",
      "repo_id",
      "private",
      "license",
      "exist_ok",
      "safe_serialization",
      "subfolder",
      "merge_tensor_parallel"
    ],
    "resize_token_embeddings": [
      "self",
      "new_num_tokens"
    ],
    "_update_init_config": [
      "self",
      "init_config",
      "key",
      "value"
    ],
    "_get_resized_embeddings": [
      "self",
      "old_embeddings",
      "new_num_tokens"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "_resolve_model_file_path": [
      "cls",
      "pretrained_model_name_or_path",
      "from_hf_hub",
      "from_aistudio",
      "cache_dir",
      "subfolder",
      "config",
      "convert_from_torch",
      "use_safetensors",
      "variant"
    ],
    "_load_pretrained_model": [
      "cls",
      "model",
      "state_dict",
      "loaded_keys",
      "resolved_archive_file",
      "pretrained_model_name_or_path",
      "config",
      "ignore_mismatched_sizes",
      "low_cpu_mem_usage",
      "dtype",
      "keep_in_fp32_modules",
      "quantization_linear_list"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "save_pretrained": [
      "self",
      "save_dir",
      "is_main_process",
      "state_dict",
      "save_function",
      "max_shard_size",
      "safe_serialization",
      "variant"
    ]
  },
  "PipelinePretrainedModel": {
    "__init_hook__": [
      "self"
    ],
    "__init__": [
      "self",
      "config"
    ],
    "add_sequential_layer": [
      "self",
      "layer_desc",
      "name_prefix"
    ],
    "get_sequential_layers": [
      "self"
    ],
    "get_sequential_name_prefixes": [
      "self"
    ],
    "_set_pipeline_name_mapping": [
      "self",
      "mappings"
    ],
    "get_shardlayer_prefix": [
      "self",
      "name_splited"
    ],
    "state_dict": [
      "self"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "HUGGINGFACE_CO_RESOLVE_ENDPOINT": [],
  "convert_ndarray_dtype": [
    "np_array",
    "target_dtype"
  ],
  "get_scale_by_dtype": [
    "dtype",
    "return_positive"
  ],
  "fn_args_to_dict": [
    "func"
  ],
  "adapt_stale_fwd_patch": [
    "self",
    "name",
    "value"
  ],
  "InitTrackerMeta": {
    "__init__": [
      "cls",
      "name",
      "bases",
      "attrs"
    ],
    "init_and_track_conf": [
      "init_func",
      "pre_init_func",
      "post_init_func"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ]
  },
  "param_in_func": [
    "func",
    "param_field"
  ],
  "resolve_cache_dir": [
    "from_hf_hub",
    "from_aistudio",
    "cache_dir"
  ],
  "find_transformer_model_type": [
    "model_class"
  ],
  "find_transformer_model_class_by_name": [
    "model_name"
  ],
  "convert_file_size_to_int": [
    "size"
  ],
  "paddlenlp_hub_download": [
    "repo_id",
    "filename"
  ],
  "_CACHED_NO_EXIST": [],
  "cached_file": [
    "path_or_repo_id",
    "filename",
    "cache_dir",
    "subfolder",
    "from_aistudio",
    "_raise_exceptions_for_missing_entries",
    "_raise_exceptions_for_connection_errors",
    "pretrained_model_name_or_path"
  ],
  "cached_file_for_hf_hub": [
    "path_or_repo_id",
    "filename",
    "cache_dir",
    "subfolder",
    "_raise_exceptions_for_missing_entries"
  ],
  "get_checkpoint_shard_files": [
    "pretrained_model_name_or_path",
    "index_filename",
    "cache_dir",
    "subfolder",
    "from_aistudio",
    "from_hf_hub"
  ],
  "is_safetensors_available": [],
  "device_guard": [
    "device",
    "dev_id"
  ],
  "paddlenlp_load": [
    "path",
    "map_location"
  ],
  "is_paddle_support_lazy_init": [],
  "ContextManagers": {
    "__init__": [
      "self",
      "context_managers"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "use_hybrid_parallel": [],
  "optimizer_name_suffix": [],
  "weight_name_suffix": [],
  "dtype_byte_size": [
    "dtype"
  ],
  "apply_print_resets": [
    "buf"
  ],
  "CaptureStd": {
    "__init__": [
      "self",
      "out",
      "err",
      "replay"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Registry": {
    "__init__": [
      "self"
    ],
    "register": [
      "self",
      "name"
    ]
  },
  "AttentionRegistry": [],
  "create_bigbird_rand_mask_idx": [
    "num_layers",
    "query_length",
    "key_length",
    "num_heads",
    "block_size",
    "window_size",
    "num_global_blocks",
    "num_rand_blocks",
    "seed"
  ],
  "create_bigbird_rand_mask_idx_list": [
    "num_layers",
    "query_length",
    "key_length",
    "num_heads",
    "block_size",
    "window_size",
    "num_global_blocks",
    "num_rand_blocks",
    "seed"
  ],
  "_convert_param_attr_to_list": [
    "param_attr",
    "n"
  ],
  "Linear3D": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "size_per_head",
      "weight_attr",
      "bias_attr"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Attention": {
    "__init__": [
      "self",
      "num_heads",
      "block_size",
      "window_size",
      "num_global_blocks",
      "num_rand_blocks",
      "seed"
    ],
    "forward": [
      "self",
      "query_matrix",
      "key_matrix",
      "value_matrix",
      "d_head",
      "attn_mask",
      "rand_mask_idx",
      "query_mask",
      "key_mask",
      "dropout"
    ]
  },
  "DefaultAttention": {
    "forward": [
      "self",
      "query_matrix",
      "key_matrix",
      "value_matrix",
      "d_head",
      "attn_mask",
      "rand_mask_idx",
      "query_mask",
      "key_mask",
      "dropout"
    ]
  },
  "BigBirdSparseAttention": {
    "__init__": [
      "self",
      "num_heads",
      "block_size",
      "window_size",
      "num_global_blocks",
      "num_rand_blocks",
      "seed"
    ],
    "_get_band_mask": [
      "self",
      "blocked_query_mask",
      "blocked_key_mask",
      "batch_size",
      "sequence_length"
    ],
    "_get_band_matrix": [
      "self",
      "blocked_matrix",
      "B",
      "T"
    ],
    "_get_rand_mask": [
      "self",
      "blocked_query_mask",
      "blocked_key_mask",
      "rand_mask_idx",
      "batch_size",
      "sequence_length"
    ],
    "_gather_random_key_value": [
      "self",
      "blocked_matrix",
      "rand_mask_idx",
      "B",
      "T"
    ],
    "_get_global_out": [
      "self",
      "query_matrix",
      "key_matrix",
      "value_matrix",
      "key_mask",
      "d_head",
      "dropout",
      "is_front"
    ],
    "_get_splited_matrix": [
      "self",
      "matrix"
    ],
    "forward": [
      "self",
      "query_matrix",
      "key_matrix",
      "value_matrix",
      "d_head",
      "attn_mask",
      "rand_mask_idx",
      "query_mask",
      "key_mask",
      "dropout"
    ]
  },
  "MultiHeadAttention": {
    "Cache": [],
    "StaticCache": [],
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "dropout",
      "kdim",
      "vdim",
      "weight_attr",
      "bias_attr",
      "block_size",
      "window_size",
      "num_global_blocks",
      "num_rand_blocks",
      "seed",
      "attention_type"
    ],
    "_prepare_qkv": [
      "self",
      "query",
      "key",
      "value",
      "cache"
    ],
    "compute_kv": [
      "self",
      "key",
      "value"
    ],
    "gen_cache": [
      "self",
      "key",
      "value",
      "type"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attn_mask",
      "rand_mask_idx",
      "query_mask",
      "key_mask",
      "cache"
    ]
  },
  "SentencePieceExtractor": {
    "__init__": [
      "self",
      "model"
    ],
    "extract": [
      "self"
    ]
  },
  "check_number_comma": [
    "piece"
  ],
  "BertConverter": {
    "converted": [
      "self"
    ]
  },
  "ErnieConverter": {},
  "TinyBertConverter": {},
  "NystromformerConverter": {},
  "SpmConverter": {
    "__init__": [
      "self"
    ],
    "vocab": [
      "self",
      "proto"
    ],
    "unk_id": [
      "self",
      "proto"
    ],
    "tokenizer": [
      "self",
      "proto"
    ],
    "normalizer": [
      "self",
      "proto"
    ],
    "pretokenizer": [
      "self",
      "replacement",
      "add_prefix_space"
    ],
    "postprocessor": [
      "self"
    ],
    "replacement": [
      "self"
    ],
    "add_prefix_space": [
      "self"
    ],
    "set_model": [
      "self",
      "tokenizer"
    ],
    "converted": [
      "self"
    ]
  },
  "ErnieMConverter": {
    "set_model": [
      "self",
      "tokenizer"
    ],
    "normalizer": [
      "self",
      "proto"
    ],
    "vocab": [
      "self",
      "proto"
    ],
    "unk_id": [
      "self",
      "proto"
    ],
    "pretokenizer": [
      "self",
      "replacement",
      "add_prefix_space"
    ],
    "postprocessor": [
      "self"
    ]
  },
  "SLOW_TO_FAST_CONVERTERS": [],
  "convert_slow_tokenizer": [
    "transformer_tokenizer"
  ],
  "hertz_to_mel": [
    "freq",
    "mel_scale"
  ],
  "mel_to_hertz": [
    "mels",
    "mel_scale"
  ],
  "_create_triangular_filter_bank": [
    "fft_freqs",
    "filter_freqs"
  ],
  "mel_filter_bank": [
    "num_frequency_bins",
    "num_mel_filters",
    "min_frequency",
    "max_frequency",
    "sampling_rate",
    "norm",
    "mel_scale"
  ],
  "optimal_fft_length": [
    "window_length"
  ],
  "window_function": [
    "window_length",
    "name",
    "periodic",
    "frame_length",
    "center"
  ],
  "spectrogram": [
    "waveform",
    "window",
    "frame_length",
    "hop_length",
    "fft_length",
    "power",
    "center",
    "pad_mode",
    "onesided",
    "preemphasis",
    "mel_filters",
    "mel_floor",
    "log_mel",
    "reference",
    "min_value",
    "db_range",
    "dtype"
  ],
  "power_to_db": [
    "spectrogram",
    "reference",
    "min_value",
    "db_range"
  ],
  "amplitude_to_db": [
    "spectrogram",
    "reference",
    "min_value",
    "db_range"
  ],
  "get_mel_filter_banks": [
    "nb_frequency_bins",
    "nb_mel_filters",
    "frequency_min",
    "frequency_max",
    "sample_rate",
    "norm",
    "mel_scale"
  ],
  "fram_wave": [
    "waveform",
    "hop_length",
    "fft_window_size",
    "center"
  ],
  "stft": [
    "frames",
    "windowing_function",
    "fft_window_size"
  ],
  "is_integer": [
    "number"
  ],
  "CosineAnnealingWithWarmupDecay": {
    "__init__": [
      "self",
      "max_lr",
      "min_lr",
      "warmup_step",
      "decay_step",
      "last_epoch",
      "verbose"
    ],
    "get_lr": [
      "self"
    ]
  },
  "LinearAnnealingWithWarmupDecay": {
    "__init__": [
      "self",
      "max_lr",
      "min_lr",
      "warmup_step",
      "decay_step",
      "last_epoch",
      "verbose"
    ],
    "get_lr": [
      "self"
    ]
  },
  "LinearDecayWithWarmup": {
    "__init__": [
      "self",
      "learning_rate",
      "total_steps",
      "warmup",
      "last_epoch",
      "verbose"
    ]
  },
  "ConstScheduleWithWarmup": {
    "__init__": [
      "self",
      "learning_rate",
      "warmup",
      "total_steps",
      "last_epoch",
      "verbose"
    ]
  },
  "CosineDecayWithWarmup": {
    "__init__": [
      "self",
      "learning_rate",
      "total_steps",
      "warmup",
      "with_hard_restarts",
      "num_cycles",
      "last_epoch",
      "verbose"
    ]
  },
  "PolyDecayWithWarmup": {
    "__init__": [
      "self",
      "learning_rate",
      "total_steps",
      "warmup",
      "lr_end",
      "power",
      "last_epoch",
      "verbose"
    ]
  },
  "FEATURE_EXTRACTOR_NAME": [],
  "FeatureExtractionMixin": {
    "pretrained_init_configuration": [],
    "pretrained_feature_extractor_file": [],
    "_auto_class": [],
    "__init__": [
      "self"
    ],
    "_set_processor_class": [
      "self",
      "processor_class"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "save_pretrained": [
      "self",
      "save_directory"
    ],
    "get_feature_extractor_dict": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "from_dict": [
      "cls",
      "feature_extractor_dict"
    ],
    "to_dict": [
      "self"
    ],
    "from_json_file": [
      "cls",
      "json_file"
    ],
    "to_json_string": [
      "self"
    ],
    "to_json_file": [
      "self",
      "json_file_path"
    ],
    "__repr__": [
      "self"
    ]
  },
  "prepare_qkv_ofa": [
    "self",
    "query",
    "key",
    "value",
    "cache"
  ],
  "mha_ofa_forward": [
    "self",
    "query",
    "key",
    "value",
    "attn_mask",
    "cache"
  ],
  "encoder_ofa_forward": [
    "self",
    "src",
    "src_mask",
    "cache",
    "output_attentions",
    "output_hidden_states",
    "return_dict"
  ],
  "encoder_layer_ofa_forward": [
    "self",
    "src",
    "src_mask",
    "cache",
    "output_attentions"
  ],
  "reorder_head": [
    "layer",
    "index"
  ],
  "reorder_neuron": [
    "layer",
    "index",
    "dim"
  ],
  "reorder_neuron_head": [
    "model",
    "head_importance",
    "neuron_importance"
  ],
  "compute_neuron_head_importance": [
    "model",
    "data_loader",
    "num_layers",
    "num_heads",
    "loss_fct",
    "intermediate_name",
    "output_name",
    "label_names"
  ],
  "_re_configuration_file": [],
  "custom_object_save": [
    "obj",
    "folder",
    "config"
  ],
  "attribute_map": [
    "config",
    "kwargs"
  ],
  "convert_to_legacy_config": [
    "attribute_map",
    "config"
  ],
  "flatten_model_config": [
    "config"
  ],
  "is_standard_config": [
    "config"
  ],
  "resolve_hf_config_path": [
    "repo_id",
    "cache_dir",
    "subfolder"
  ],
  "PretrainedConfig": {
    "pretrained_init_configuration": [],
    "__setattr__": [
      "self",
      "key",
      "value"
    ],
    "__getattribute__": [
      "self",
      "key"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "__init__": [
      "self"
    ],
    "name_or_path": [
      "self",
      "value"
    ],
    "use_return_dict": [
      "self"
    ],
    "num_labels": [
      "self",
      "num_labels"
    ],
    "save_pretrained": [
      "self",
      "save_directory"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "get_config_dict": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "_get_config_dict": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "from_dict": [
      "cls",
      "config_dict"
    ],
    "from_json_file": [
      "cls",
      "json_file"
    ],
    "_dict_from_json_file": [
      "cls",
      "json_file"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__repr__": [
      "self"
    ],
    "to_diff_dict": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "to_json_string": [
      "self",
      "use_diff"
    ],
    "to_json_file": [
      "self",
      "json_file_path",
      "use_diff"
    ],
    "update": [
      "self",
      "config_dict"
    ],
    "update_from_string": [
      "self",
      "update_str"
    ],
    "register_for_auto_class": [
      "cls",
      "auto_class"
    ],
    "get": [
      "self",
      "key",
      "default"
    ]
  },
  "get_configuration_file": [
    "configuration_files"
  ],
  "UnauthorizedError": {},
  "EntryNotFoundError": {},
  "_add_subfolder": [
    "weights_name",
    "subfolder"
  ],
  "aistudio_download": [
    "repo_id",
    "filename",
    "cache_dir",
    "subfolder",
    "revision"
  ],
  "AddedToken": {
    "__getstate__": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "FastEncoding": {},
  "ExplicitEnum": {
    "_missing_": [
      "cls",
      "value"
    ]
  },
  "PaddingStrategy": {
    "LONGEST": [],
    "MAX_LENGTH": [],
    "DO_NOT_PAD": []
  },
  "TensorType": {
    "PADDLE": [],
    "NUMPY": []
  },
  "VERY_LARGE_INTEGER": [],
  "LARGE_INTEGER": [],
  "TextInput": [],
  "PreTokenizedInput": [],
  "EncodedInput": [],
  "TextInputPair": [],
  "PreTokenizedInputPair": [],
  "EncodedInputPair": [],
  "SPECIAL_TOKENS_MAP_FILE": [],
  "ADDED_TOKENS_FILE": [],
  "TOKENIZER_CONFIG_FILE": [],
  "to_py_obj": [
    "obj"
  ],
  "_is_numpy": [
    "x"
  ],
  "TruncationStrategy": {
    "ONLY_FIRST": [],
    "ONLY_SECOND": [],
    "LONGEST_FIRST": [],
    "DO_NOT_TRUNCATE": []
  },
  "CharSpan": {},
  "TokenSpan": {},
  "BatchEncoding": {
    "__init__": [
      "self",
      "data",
      "encoding",
      "tensor_type",
      "prepend_batch_axis",
      "n_sequences"
    ],
    "n_sequences": [
      "self"
    ],
    "is_fast": [
      "self"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "__getattr__": [
      "self",
      "item"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "keys": [
      "self"
    ],
    "values": [
      "self"
    ],
    "items": [
      "self"
    ],
    "encodings": [
      "self"
    ],
    "tokens": [
      "self",
      "batch_index"
    ],
    "sequence_ids": [
      "self",
      "batch_index"
    ],
    "words": [
      "self",
      "batch_index"
    ],
    "word_ids": [
      "self",
      "batch_index"
    ],
    "token_to_sequence": [
      "self",
      "batch_or_token_index",
      "token_index"
    ],
    "token_to_word": [
      "self",
      "batch_or_token_index",
      "token_index"
    ],
    "word_to_tokens": [
      "self",
      "batch_or_word_index",
      "word_index",
      "sequence_index"
    ],
    "token_to_chars": [
      "self",
      "batch_or_token_index",
      "token_index"
    ],
    "char_to_token": [
      "self",
      "batch_or_char_index",
      "char_index",
      "sequence_index"
    ],
    "word_to_chars": [
      "self",
      "batch_or_word_index",
      "word_index",
      "sequence_index"
    ],
    "char_to_word": [
      "self",
      "batch_or_char_index",
      "char_index",
      "sequence_index"
    ],
    "convert_to_tensors": [
      "self",
      "tensor_type",
      "prepend_batch_axis"
    ]
  },
  "SpecialTokensMixin": {
    "SPECIAL_TOKENS_ATTRIBUTES": [],
    "__init__": [
      "self",
      "verbose"
    ],
    "sanitize_special_tokens": [
      "self"
    ],
    "add_special_tokens": [
      "self",
      "special_tokens_dict"
    ],
    "add_tokens": [
      "self",
      "new_tokens",
      "special_tokens"
    ],
    "_add_tokens": [
      "self",
      "new_tokens",
      "special_tokens"
    ],
    "bos_token": [
      "self",
      "value"
    ],
    "eos_token": [
      "self",
      "value"
    ],
    "unk_token": [
      "self",
      "value"
    ],
    "sep_token": [
      "self",
      "value"
    ],
    "pad_token": [
      "self",
      "value"
    ],
    "cls_token": [
      "self",
      "value"
    ],
    "mask_token": [
      "self",
      "value"
    ],
    "additional_special_tokens": [
      "self",
      "value"
    ],
    "bos_token_id": [
      "self",
      "value"
    ],
    "eos_token_id": [
      "self",
      "value"
    ],
    "unk_token_id": [
      "self",
      "value"
    ],
    "sep_token_id": [
      "self",
      "value"
    ],
    "pad_token_id": [
      "self",
      "value"
    ],
    "pad_token_type_id": [
      "self"
    ],
    "cls_token_id": [
      "self",
      "value"
    ],
    "mask_token_id": [
      "self",
      "value"
    ],
    "additional_special_tokens_ids": [
      "self",
      "values"
    ],
    "special_tokens_map": [
      "self"
    ],
    "special_tokens_map_extended": [
      "self"
    ],
    "all_special_tokens": [
      "self"
    ],
    "all_special_tokens_extended": [
      "self"
    ],
    "all_special_ids": [
      "self"
    ]
  },
  "PretrainedTokenizerBase": {
    "tokenizer_config_file": [],
    "slow_tokenizer_class": [],
    "__init__": [
      "self"
    ],
    "max_len_single_sentence": [
      "self",
      "value"
    ],
    "max_len_sentences_pair": [
      "self",
      "value"
    ],
    "_switch_to_input_mode": [
      "self"
    ],
    "_set_processor_class": [
      "self",
      "processor_class"
    ],
    "__repr__": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "save_pretrained": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "_save_pretrained": [
      "self",
      "save_directory",
      "file_names",
      "filename_prefix"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ],
    "save_to_hf_hub": [
      "self",
      "repo_id",
      "private",
      "subfolder",
      "commit_message",
      "revision",
      "create_pr"
    ],
    "save_to_aistudio": [
      "self",
      "repo_id",
      "private",
      "license",
      "exist_ok",
      "subfolder"
    ],
    "tokenize": [
      "self",
      "text",
      "pair",
      "add_special_tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "_get_padding_truncation_strategies": [
      "self",
      "padding",
      "truncation",
      "max_length",
      "pad_to_multiple_of",
      "verbose"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "max_length",
      "stride",
      "is_split_into_words",
      "padding",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "add_special_tokens",
      "pad_to_multiple_of",
      "return_tensors",
      "verbose"
    ],
    "encode": [
      "self",
      "text",
      "text_pair",
      "add_special_tokens",
      "padding",
      "truncation",
      "max_length",
      "stride",
      "is_split_into_words",
      "pad_to_multiple_of",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_offsets_mapping",
      "return_length",
      "verbose",
      "return_position_ids"
    ],
    "encode_plus": [
      "self",
      "text",
      "text_pair",
      "add_special_tokens",
      "padding",
      "truncation",
      "max_length",
      "stride",
      "is_split_into_words",
      "pad_to_multiple_of",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "_encode_plus": [
      "self",
      "text",
      "text_pair",
      "add_special_tokens",
      "padding_strategy",
      "truncation_strategy",
      "max_length",
      "stride",
      "is_split_into_words",
      "pad_to_multiple_of",
      "return_position_ids",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "batch_encode": [
      "self",
      "batch_text_or_text_pairs",
      "max_length",
      "stride",
      "is_split_into_words",
      "padding",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "add_special_tokens",
      "pad_to_multiple_of",
      "return_tensors",
      "verbose"
    ],
    "_batch_encode_plus": [
      "self",
      "batch_text_or_text_pairs",
      "add_special_tokens",
      "padding_strategy",
      "truncation_strategy",
      "max_length",
      "stride",
      "is_split_into_words",
      "pad_to_multiple_of",
      "return_position_ids",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "pad": [
      "self",
      "encoded_inputs",
      "padding",
      "max_length",
      "pad_to_multiple_of",
      "return_attention_mask",
      "return_tensors",
      "verbose"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "prepare_for_model": [
      "self",
      "ids",
      "pair_ids",
      "padding",
      "truncation",
      "max_length",
      "stride",
      "pad_to_multiple_of",
      "return_tensors",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_offsets_mapping",
      "add_special_tokens",
      "verbose",
      "prepend_batch_axis"
    ],
    "truncate_sequences": [
      "self",
      "ids",
      "pair_ids",
      "num_tokens_to_remove",
      "truncation_strategy",
      "stride"
    ],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "batch_decode": [
      "self",
      "sequences",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ],
    "decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ],
    "_decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "clean_up_tokenization": [
      "out_string"
    ],
    "_eventual_warn_about_too_long_sequence": [
      "self",
      "ids",
      "max_length",
      "verbose"
    ]
  },
  "TOKENIZER_FILE": [],
  "VOCAB_FILES_NAMES": [],
  "PretrainedFastTokenizer": {
    "resource_files_names": [],
    "__init__": [
      "self"
    ],
    "is_fast": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "vocab": [
      "self"
    ],
    "get_added_vocab": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "backend_tokenizer": [
      "self"
    ],
    "_convert_encoding": [
      "self",
      "encoding",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_offsets_mapping",
      "return_length",
      "return_position_ids",
      "verbose"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "_convert_token_to_id_with_added_voc": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "_add_tokens": [
      "self",
      "new_tokens",
      "special_tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "tokenize": [
      "self",
      "text",
      "pair",
      "add_special_tokens"
    ],
    "set_truncation_and_padding": [
      "self",
      "padding_strategy",
      "truncation_strategy",
      "max_length",
      "stride",
      "pad_to_multiple_of"
    ],
    "_batch_encode_plus": [
      "self",
      "batch_text_or_text_pairs",
      "add_special_tokens",
      "padding_strategy",
      "truncation_strategy",
      "max_length",
      "stride",
      "is_split_into_words",
      "pad_to_multiple_of",
      "return_position_ids",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "_encode_plus": [
      "self",
      "text",
      "text_pair",
      "add_special_tokens",
      "padding_strategy",
      "truncation_strategy",
      "max_length",
      "stride",
      "is_split_into_words",
      "pad_to_multiple_of",
      "return_position_ids",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "_save_pretrained": [
      "self",
      "save_directory",
      "file_names",
      "legacy_format",
      "filename_prefix"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "_decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ]
  },
  "calc_multi_relation_loss": [
    "loss_fct",
    "s",
    "t",
    "attn_mask",
    "num_relation_heads",
    "alpha",
    "beta"
  ],
  "calc_minilm_loss": [
    "loss_fct",
    "s",
    "t",
    "attn_mask",
    "num_relation_heads"
  ],
  "to_distill": [
    "self",
    "return_qkv",
    "return_attentions",
    "return_layer_outputs",
    "layer_index"
  ],
  "_convert_attention_mask": [
    "attn_mask",
    "dtype"
  ],
  "attention_forward": [
    "self",
    "query",
    "key",
    "value",
    "attn_mask",
    "cache"
  ],
  "transformer_encoder_layer_forward": [
    "self",
    "src",
    "src_mask",
    "cache"
  ],
  "transformer_encoder_forward": [
    "self",
    "src",
    "src_mask",
    "cache"
  ],
  "minilm_pretraining_forward": [
    "self",
    "input_ids",
    "token_type_ids",
    "attention_mask"
  ],
  "tinybert_forward": [
    "self",
    "input_ids",
    "token_type_ids",
    "attention_mask"
  ],
  "bert_forward": [
    "self",
    "input_ids",
    "token_type_ids",
    "attention_mask"
  ],
  "IMAGENET_DEFAULT_MEAN": [],
  "IMAGENET_DEFAULT_STD": [],
  "IMAGENET_STANDARD_MEAN": [],
  "IMAGENET_STANDARD_STD": [],
  "to_numpy": [
    "obj"
  ],
  "ImageInput": [],
  "ChannelDimension": {
    "FIRST": [],
    "LAST": []
  },
  "is_valid_image": [
    "img"
  ],
  "valid_images": [
    "imgs"
  ],
  "is_batched": [
    "img"
  ],
  "make_list_of_images": [
    "images",
    "expected_ndims"
  ],
  "to_numpy_array": [
    "img"
  ],
  "infer_channel_dimension_format": [
    "image"
  ],
  "get_channel_dimension_axis": [
    "image"
  ],
  "get_image_size": [
    "image",
    "channel_dim"
  ],
  "is_valid_annotation_coco_detection": [
    "annotation"
  ],
  "is_valid_annotation_coco_panoptic": [
    "annotation"
  ],
  "valid_coco_detection_annotations": [
    "annotations"
  ],
  "valid_coco_panoptic_annotations": [
    "annotations"
  ],
  "load_image": [
    "image"
  ],
  "ImageFeatureExtractionMixin": {
    "_ensure_format_supported": [
      "self",
      "image"
    ],
    "to_pil_image": [
      "self",
      "image",
      "rescale"
    ],
    "convert_rgb": [
      "self",
      "image"
    ],
    "rescale": [
      "self",
      "image",
      "scale"
    ],
    "to_numpy_array": [
      "self",
      "image",
      "rescale",
      "channel_first"
    ],
    "expand_dims": [
      "self",
      "image"
    ],
    "normalize": [
      "self",
      "image",
      "mean",
      "std",
      "rescale"
    ],
    "resize": [
      "self",
      "image",
      "size",
      "resample",
      "default_to_square",
      "max_size"
    ],
    "center_crop": [
      "self",
      "image",
      "size"
    ],
    "flip_channel_order": [
      "self",
      "image"
    ],
    "rotate": [
      "self",
      "image",
      "angle",
      "resample",
      "expand",
      "center",
      "translate",
      "fillcolor"
    ]
  },
  "split_inputs_sequence_dim": [
    "inputs",
    "sep_rank",
    "sep_degree"
  ],
  "_reshard_qkv": [
    "x",
    "group",
    "split_axis",
    "concat_axis"
  ],
  "ReshardQKV": {
    "forward": [
      "ctx",
      "x",
      "group",
      "split_axis",
      "concat_axis"
    ],
    "backward": [
      "ctx",
      "dy"
    ]
  },
  "ReshardLayer": {
    "__init__": [
      "self",
      "sep_group"
    ],
    "forward": [
      "self",
      "x",
      "split_axis",
      "concat_axis"
    ]
  },
  "ElectraConverter": {
    "_ignore_state_dict_keys": [],
    "get_paddle_pytorch_model_classes": [
      "self"
    ],
    "get_name_mapping": [
      "self",
      "config_or_num_layers"
    ]
  },
  "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES": [],
  "ElectraTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "do_basic_tokenize",
      "never_split",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ]
  },
  "ElectraEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ]
  },
  "ElectraDiscriminatorPredictions": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "discriminator_hidden_states"
    ]
  },
  "ElectraGeneratorPredictions": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "generator_hidden_states"
    ]
  },
  "ElectraPretrainedModel": {
    "base_model_prefix": [],
    "gen_weight": [],
    "disc_weight": [],
    "tie_word_embeddings": [],
    "untied_generator_embeddings": [],
    "use_softmax_sample": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "config_class": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "ElectraModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ElectraDiscriminator": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds"
    ]
  },
  "ElectraGenerator": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ElectraClassificationHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "ErnieHealthDiscriminator": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "candidate_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "ElectraForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ElectraForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ElectraForTotalPretraining": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "get_discriminator_inputs": [
      "self",
      "inputs",
      "raw_inputs",
      "generator_logits",
      "generator_labels",
      "use_softmax_sample"
    ],
    "sample_from_softmax": [
      "self",
      "logits",
      "use_softmax_sample"
    ],
    "update_inputs": [
      "self",
      "sequence",
      "updates",
      "positions"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "raw_input_ids",
      "generator_labels"
    ]
  },
  "ElectraPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErnieHealthForPreTrainingOutput": {},
  "ErnieHealthForTotalPretraining": {
    "__init__": [
      "self",
      "config"
    ],
    "get_discriminator_inputs_ernie_health": [
      "self",
      "inputs",
      "raw_inputs",
      "generator_logits",
      "generator_labels",
      "use_softmax_sample"
    ],
    "sample_negatives_from_softmax": [
      "self",
      "logits",
      "raw_inputs",
      "use_softmax_sample"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "raw_input_ids",
      "generator_labels",
      "return_dict"
    ]
  },
  "ElectraForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ElectraPretrainingCriterion": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "generator_prediction_scores",
      "discriminator_prediction_scores",
      "generator_labels",
      "discriminator_labels",
      "attention_mask"
    ]
  },
  "ErnieHealthPretrainingCriterion": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "generator_logits",
      "generator_labels",
      "logits_rtd",
      "logits_mts",
      "logits_csp",
      "discriminator_labels",
      "attention_mask"
    ]
  },
  "ElectraForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ElectraForMaskedLM": [],
  "ElectraForPretraining": [],
  "ELECTRA_PRETRAINED_INIT_CONFIGURATION": [],
  "ELECTRA_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ElectraConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "embedding_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id",
      "layer_norm_eps",
      "num_choices",
      "gen_weight",
      "disc_weight"
    ]
  },
  "MiniGPT4Processor": {
    "attributes": [],
    "image_processor_class": [],
    "tokenizer_class": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer"
    ],
    "process_images": [
      "self",
      "images",
      "return_tensors"
    ],
    "process_texts": [
      "self",
      "texts",
      "prompts",
      "return_tensors"
    ],
    "__call__": [
      "self",
      "images",
      "text",
      "prompt",
      "return_tensors"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "model_input_names": [
      "self"
    ]
  },
  "MiniGPT4ImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb"
    ],
    "resize": [
      "self",
      "image",
      "size",
      "resample",
      "data_format"
    ],
    "rescale": [
      "self",
      "image",
      "scale",
      "data_format"
    ],
    "normalize": [
      "self",
      "image",
      "mean",
      "std",
      "data_format"
    ],
    "preprocess": [
      "self",
      "images",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "return_tensors",
      "do_convert_rgb",
      "data_format"
    ]
  },
  "MiniGPT4_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "Parameter": [
    "tensor"
  ],
  "convert_weights_to_dtype": [
    "model",
    "dtype"
  ],
  "MiniGPT4ForConditionalGenerationModelOutput": {
    "to_tuple": [
      "self"
    ]
  },
  "MiniGPT4PretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "MiniGPT4VisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "MiniGPT4Attention": {
    "__init__": [
      "self",
      "config"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states",
      "head_mask",
      "output_attentions"
    ]
  },
  "MiniGPT4MLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MiniGPT4EncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions"
    ]
  },
  "MiniGPT4Encoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MiniGPT4VisionModel": {
    "main_input_name": [],
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "MiniGPT4QFormerMultiHeadAttention": {
    "__init__": [
      "self",
      "config",
      "is_cross_attention"
    ],
    "save_attn_gradients": [
      "self",
      "attn_gradients"
    ],
    "get_attn_gradients": [
      "self"
    ],
    "save_attention_map": [
      "self",
      "attention_map"
    ],
    "get_attention_map": [
      "self"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "MiniGPT4QFormerSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "MiniGPT4QFormerAttention": {
    "__init__": [
      "self",
      "config",
      "is_cross_attention"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "MiniGPT4QFormerIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MiniGPT4QFormerOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "MiniGPT4QFormerLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "query_length"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ],
    "feed_forward_chunk_query": [
      "self",
      "attention_output"
    ]
  },
  "MiniGPT4QFormerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "query_length"
    ]
  },
  "MiniGPT4QFormerModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "get_extended_attention_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "has_query"
    ],
    "invert_attention_mask": [
      "self",
      "encoder_attention_mask"
    ],
    "get_head_mask": [
      "self",
      "head_mask",
      "num_hidden_layers",
      "is_attention_chunked"
    ],
    "_convert_head_mask_to_5d": [
      "self",
      "head_mask",
      "num_hidden_layers"
    ],
    "forward": [
      "self",
      "query_embeds",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MiniGPT4Model": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_text_features": [
      "self",
      "input_ids",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_qformer_features": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "forward": [
      "self",
      "pixel_values",
      "first_input_ids",
      "second_input_ids",
      "first_attention_mask",
      "second_attention_mask",
      "output_attentions",
      "output_hidden_states",
      "labels",
      "return_dict"
    ]
  },
  "MiniGPT4ForConditionalGeneration": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "first_input_ids",
      "second_input_ids",
      "first_attention_mask",
      "second_attention_mask",
      "output_attentions",
      "output_hidden_states",
      "labels",
      "return_dict"
    ],
    "generate": [
      "self",
      "pixel_values",
      "first_input_ids",
      "second_input_ids",
      "first_attention_mask",
      "second_attention_mask"
    ],
    "encode_images": [
      "self",
      "pixel_values"
    ],
    "generate_with_image_features": [
      "self",
      "image_features",
      "first_input_ids",
      "second_input_ids",
      "image_attention_mask",
      "first_attention_mask",
      "second_attention_mask"
    ]
  },
  "MiniGPT4VisionConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "projection_dim",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "hidden_act",
      "layer_norm_eps",
      "dropout",
      "attention_dropout",
      "initializer_range",
      "initializer_factor",
      "qkv_bias"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "MiniGPT4QFormerConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "position_embedding_type",
      "classifier_dropout",
      "cross_attention_frequency",
      "encoder_hidden_size"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "MiniGPT4Config": {
    "model_type": [],
    "is_composition": [],
    "__init__": [
      "self",
      "vision_config",
      "qformer_config",
      "text_config",
      "num_query_tokens"
    ],
    "from_vision_qformer_text_configs": [
      "cls",
      "vision_config",
      "qformer_config",
      "text_config"
    ],
    "to_dict": [
      "self"
    ]
  },
  "sd": [],
  "layers": [],
  "SPTokenizer": {
    "__init__": [
      "self",
      "model_path"
    ],
    "tokenize": [
      "self",
      "s",
      "encode_special_tokens"
    ],
    "encode": [
      "self",
      "s",
      "bos",
      "eos"
    ],
    "decode": [
      "self",
      "t"
    ],
    "decode_tokens": [
      "self",
      "tokens"
    ],
    "convert_token_to_id": [
      "self",
      "token"
    ],
    "convert_id_to_token": [
      "self",
      "index"
    ]
  },
  "ChatGLMv2Tokenizer": {
    "resource_files_names": [],
    "model_input_names": [],
    "pretrained_resource_files_map": [],
    "__init__": [
      "self",
      "vocab_file",
      "padding_side",
      "encode_special_tokens"
    ],
    "get_command": [
      "self",
      "token"
    ],
    "pad_token": [
      "self"
    ],
    "pad_token_id": [
      "self"
    ],
    "eos_token": [
      "self"
    ],
    "eos_token_id": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "get_prefix_tokens": [
      "self"
    ],
    "build_prompt": [
      "self",
      "query",
      "history"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ],
    "encode_chat_inputs": [
      "self",
      "conversations",
      "context_data"
    ]
  },
  "RotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "original_impl"
    ],
    "forward_impl": [
      "self",
      "seq_len",
      "n_elem",
      "base"
    ],
    "forward": [
      "self",
      "max_seq_len",
      "offset"
    ]
  },
  "apply_rotary_pos_emb": [
    "x",
    "rope_cache"
  ],
  "RMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "epsilon"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CoreAttention": {
    "__init__": [
      "self",
      "config",
      "layer_number"
    ],
    "forward": [
      "self",
      "query_layer",
      "key_layer",
      "value_layer",
      "attention_mask"
    ]
  },
  "SelfAttention": {
    "__init__": [
      "self",
      "config",
      "layer_number",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "rotary_pos_emb",
      "kv_cache",
      "use_cache"
    ]
  },
  "MLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GLMBlock": {
    "__init__": [
      "self",
      "config",
      "layer_number"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "rotary_pos_emb",
      "kv_cache",
      "use_cache"
    ]
  },
  "GLMTransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "_get_layer": [
      "self",
      "layer_number"
    ],
    "recompute_training": [
      "self",
      "layer_module",
      "hidden_states",
      "attention_mask",
      "rotary_embeds",
      "kv_cache",
      "use_cache"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "rotary_pos_emb",
      "kv_caches",
      "use_cache",
      "output_hidden_states"
    ]
  },
  "ChatGLMv2PretrainedModel": {
    "config_class": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "get_masks": [
      "self",
      "input_ids",
      "past_key_values",
      "padding_mask"
    ],
    "get_position_ids": [
      "self",
      "input_ids"
    ],
    "_get_name_mappings": [
      "cls",
      "config"
    ]
  },
  "Embedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "ChatGLMv2Model": {
    "__init__": [
      "self",
      "config",
      "empty_init"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "full_attention_mask",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ChatGLMv2ForCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "reorder_cache": [
      "self",
      "cache",
      "beam_idx"
    ],
    "update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder",
      "standardize_cache_format"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "position_ids",
      "is_first_forward"
    ],
    "_get_model_inputs_spec": [
      "self",
      "dtype"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_hidden_states",
      "return_dict",
      "return_last_logit"
    ]
  },
  "CHATGLM_V2_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ChatGLMv2Config": {
    "model_type": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "num_hidden_layers",
      "vocab_size",
      "hidden_size",
      "ffn_hidden_size",
      "kv_channels",
      "num_attention_heads",
      "max_sequence_length",
      "hidden_dropout",
      "attention_dropout",
      "layernorm_epsilon",
      "use_cache",
      "rmsnorm",
      "apply_residual_connection_post_layernorm",
      "post_layer_norm",
      "add_bias_linear",
      "add_qkv_bias",
      "interleaved_qkv",
      "bias_dropout_fusion",
      "multi_query_group_num",
      "apply_query_key_layer_scaling",
      "attention_softmax_in_fp32",
      "fp32_residual_connection",
      "eos_token_id",
      "pad_token_id",
      "use_flash_attention",
      "long_sequence_strategy_type",
      "long_sequence_strategy_name",
      "long_sequence_init_args",
      "use_long_sequence_strategies"
    ]
  },
  "BitImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "size",
      "resample",
      "do_center_crop",
      "crop_size",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb"
    ],
    "resize": [
      "self",
      "image",
      "size",
      "resample",
      "data_format"
    ],
    "center_crop": [
      "self",
      "image",
      "size",
      "data_format"
    ],
    "rescale": [
      "self",
      "image",
      "scale",
      "data_format"
    ],
    "normalize": [
      "self",
      "image",
      "mean",
      "std",
      "data_format"
    ],
    "preprocess": [
      "self",
      "images",
      "do_resize",
      "size",
      "resample",
      "do_center_crop",
      "crop_size",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "return_tensors",
      "data_format"
    ]
  },
  "get_padding_value": [
    "padding",
    "kernel_size",
    "stride",
    "dilation"
  ],
  "WeightStandardizedConv2D": {
    "__init__": [
      "self",
      "in_channel",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "epsilon"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "BitGroupNormActivation": {
    "__init__": [
      "self",
      "config",
      "num_channels",
      "epsilon",
      "apply_activation"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "DynamicPad2d": {
    "__init__": [
      "self",
      "kernel_size",
      "stride",
      "dilation",
      "value"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "BitMaxPool2D": {
    "__init__": [
      "self",
      "kernel_size",
      "stride",
      "dilation",
      "ceil_mode",
      "padding",
      "padding_value",
      "use_dynamic_padding"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BitEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "drop_path": [
    "input",
    "drop_prob",
    "training"
  ],
  "BitDropPath": {
    "__init__": [
      "self",
      "drop_prob"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "make_div": [
    "value",
    "divisor"
  ],
  "BitPreActivationBottleneckLayer": {
    "__init__": [
      "self",
      "config",
      "in_channels",
      "out_channels",
      "bottle_ratio",
      "stride",
      "dilation",
      "first_dilation",
      "groups",
      "drop_path_rate",
      "is_first_layer"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BitBottleneckLayer": {
    "__init__": [
      "self",
      "config",
      "in_channels",
      "out_channels",
      "bottle_ratio",
      "stride",
      "dilation",
      "first_dilation",
      "groups",
      "drop_path_rate",
      "is_first_layer"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BitDownsampleConv": {
    "__init__": [
      "self",
      "config",
      "in_channels",
      "out_channels",
      "stride",
      "preact"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BitStage": {
    "__init__": [
      "self",
      "config",
      "in_channels",
      "out_channels",
      "stride",
      "dilation",
      "depth",
      "bottle_ratio",
      "layer_dropout"
    ],
    "_get_updated_hyperparameters": [
      "self",
      "layer_idx",
      "stride",
      "layer_dropout"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "BitEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "_get_updated_hyperparameters": [
      "self",
      "stage_idx",
      "current_stride",
      "current_hidden_size",
      "dilation",
      "config"
    ],
    "forward": [
      "self",
      "hidden_state",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BitPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "main_input_name": [],
    "_init_weights": [
      "self",
      "module"
    ]
  },
  "BitModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BitForImageClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "labels",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BitBackbone": {
    "__init__": [
      "self",
      "config"
    ],
    "channels": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BitConfig": {
    "model_type": [],
    "layer_types": [],
    "supported_padding": [],
    "__init__": [
      "self",
      "num_channels",
      "embedding_size",
      "hidden_sizes",
      "depths",
      "layer_type",
      "hidden_act",
      "global_padding",
      "num_groups",
      "drop_path_rate",
      "embedding_dynamic_padding",
      "output_stride",
      "width_factor",
      "out_features"
    ]
  },
  "SPIECE_UNDERLINE": [],
  "ErnieMTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "sentencepiece_model_file",
      "do_lower_case",
      "encoding",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "get_offset_mapping": [
      "self",
      "text"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "clean_text": [
      "self",
      "text"
    ],
    "_tokenize": [
      "self",
      "text",
      "sample"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "convert_ids_to_string": [
      "self",
      "ids"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "is_ch_char": [
      "self",
      "char"
    ],
    "is_alpha": [
      "self",
      "char"
    ],
    "is_punct": [
      "self",
      "char"
    ],
    "is_whitespace": [
      "self",
      "char"
    ]
  },
  "ErnieMEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ]
  },
  "ErnieMPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErnieMPretrainedModel": {
    "model_config_file": [],
    "config_class": [],
    "resource_files_names": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "ErnieMModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "past_key_values",
      "use_cache",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieMForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "labels",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieMForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "start_positions",
      "end_positions",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieMForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "labels",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieMForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "labels",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "UIEM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "ErnieMFastTokenizer": {
    "resource_files_names": [],
    "slow_tokenizer_class": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_file",
      "sentencepiece_model_file",
      "tokenizer_file",
      "do_lower_case",
      "encoding",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "max_length",
      "stride",
      "is_split_into_words",
      "padding",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "add_special_tokens",
      "pad_to_multiple_of",
      "return_tensors",
      "verbose"
    ]
  },
  "ERNIE_M_PRETRAINED_INIT_CONFIGURATION": [],
  "ERNIE_M_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ErnieMConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id"
    ]
  },
  "ErnieViLProcessor": {
    "attributes": [],
    "image_processor_class": [],
    "tokenizer_class": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "return_tensors"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "model_input_names": [
      "self"
    ],
    "feature_extractor_class": [
      "self"
    ],
    "feature_extractor": [
      "self"
    ]
  },
  "ErnieViLImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "size",
      "resample",
      "do_center_crop",
      "crop_size",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb"
    ],
    "resize": [
      "self",
      "image",
      "size",
      "resample",
      "data_format"
    ],
    "center_crop": [
      "self",
      "image",
      "size",
      "data_format"
    ],
    "rescale": [
      "self",
      "image",
      "scale",
      "data_format"
    ],
    "normalize": [
      "self",
      "image",
      "mean",
      "std",
      "data_format"
    ],
    "preprocess": [
      "self",
      "images",
      "do_resize",
      "size",
      "resample",
      "do_center_crop",
      "crop_size",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "return_tensors",
      "data_format"
    ]
  },
  "ErnieViLTokenizer": {
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "model_input_names": []
  },
  "ERNIE_VIL_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "ErnieViLOutput": {
    "to_tuple": [
      "self"
    ]
  },
  "ErnieViLPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "gradient_checkpointing_enable": [
      "self"
    ],
    "gradient_checkpointing_disable": [
      "self"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "ErnieViLModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_text_features": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "token_type_ids",
      "task_type_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "attention_mask",
      "position_ids",
      "token_type_ids",
      "task_type_ids",
      "return_loss",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ErnieViLTextModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "token_type_ids",
      "task_type_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ErnieViLVisionModel": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ErnieViLFeatureExtractor": {
    "__init__": [
      "self"
    ]
  },
  "ErnieViLTextConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "task_type_vocab_size",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id",
      "layer_norm_eps",
      "task_id",
      "use_task_id",
      "fuse",
      "use_cache"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "ErnieViLVisionConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "hidden_act",
      "layer_norm_eps",
      "dropout",
      "attention_dropout",
      "initializer_range",
      "initializer_factor"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "ErnieViLConfig": {
    "model_type": [],
    "is_composition": [],
    "__init__": [
      "self",
      "text_config",
      "vision_config",
      "logit_scale_init_value"
    ],
    "from_text_vision_configs": [
      "cls",
      "text_config",
      "vision_config"
    ],
    "to_dict": [
      "self"
    ]
  },
  "CLIPSegProcessor": {
    "attributes": [],
    "image_processor_class": [],
    "tokenizer_class": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "visual_prompt",
      "return_tensors"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "feature_extractor_class": [
      "self"
    ],
    "feature_extractor": [
      "self"
    ]
  },
  "ViTImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std"
    ],
    "resize": [
      "self",
      "image",
      "size",
      "resample",
      "data_format"
    ],
    "rescale": [
      "self",
      "image",
      "scale",
      "data_format"
    ],
    "normalize": [
      "self",
      "image",
      "mean",
      "std",
      "data_format"
    ],
    "preprocess": [
      "self",
      "images",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "return_tensors",
      "data_format"
    ]
  },
  "_CHECKPOINT_FOR_DOC": [],
  "CLIPSEG_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "_expand_mask": [
    "mask",
    "tgt_len"
  ],
  "contrastive_loss": [
    "logits"
  ],
  "clipseg_loss": [
    "similarity"
  ],
  "CLIPSegOutput": {
    "to_tuple": [
      "self"
    ]
  },
  "CLIPSegDecoderOutput": {},
  "CLIPSegImageSegmentationOutput": {
    "to_tuple": [
      "self"
    ]
  },
  "CLIPSegVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "interpolate_position_embeddings": [
      "self",
      "new_size"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "CLIPSegTextEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "CLIPSegAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "causal_attention_mask",
      "output_attentions"
    ]
  },
  "CLIPSegMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CLIPSegEncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "causal_attention_mask",
      "output_attentions"
    ]
  },
  "CLIPSegPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ]
  },
  "CLIPSegEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "causal_attention_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CLIPSegTextTransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_build_causal_attention_mask": [
      "self",
      "bsz",
      "seq_len",
      "dtype"
    ]
  },
  "CLIPSegTextModel": {
    "config_class": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CLIPSegVisionTransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CLIPSegVisionModel": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CLIPSegModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_text_features": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "attention_mask",
      "position_ids",
      "return_loss",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CLIPSegDecoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "causal_attention_mask",
      "output_attentions"
    ]
  },
  "CLIPSegDecoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "conditional_embeddings",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CLIPSegForImageSegmentation": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_conditional_embeddings": [
      "self",
      "batch_size",
      "input_ids",
      "attention_mask",
      "position_ids",
      "conditional_pixel_values"
    ],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "conditional_pixel_values",
      "conditional_embeddings",
      "attention_mask",
      "position_ids",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CLIPSEG_PRETRAINED_CONFIG_ARCHIVE_MAP": [],
  "CLIPSegTextConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "max_position_embeddings",
      "hidden_act",
      "layer_norm_eps",
      "attention_dropout",
      "initializer_range",
      "initializer_factor",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "CLIPSegVisionConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "hidden_act",
      "layer_norm_eps",
      "attention_dropout",
      "initializer_range",
      "initializer_factor"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "CLIPSegConfig": {
    "model_type": [],
    "is_composition": [],
    "__init__": [
      "self",
      "text_config",
      "vision_config",
      "projection_dim",
      "logit_scale_init_value",
      "extract_layers",
      "reduce_dim",
      "decoder_num_attention_heads",
      "decoder_attention_dropout",
      "decoder_hidden_act",
      "decoder_intermediate_size",
      "conditional_layer",
      "use_complex_transposed_convolution"
    ],
    "from_text_vision_configs": [
      "cls",
      "text_config",
      "vision_config"
    ],
    "to_dict": [
      "self"
    ]
  },
  "BasicTokenizer": {
    "__init__": [
      "self",
      "do_lower_case",
      "never_split",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "tokenize": [
      "self",
      "text",
      "never_split"
    ],
    "_run_strip_accents": [
      "self",
      "text"
    ],
    "_run_split_on_punc": [
      "self",
      "text",
      "never_split"
    ],
    "_tokenize_chinese_chars": [
      "self",
      "text"
    ],
    "_is_chinese_char": [
      "self",
      "cp"
    ],
    "_clean_text": [
      "self",
      "text"
    ]
  },
  "WordpieceTokenizer": {
    "__init__": [
      "self",
      "vocab",
      "unk_token",
      "max_input_chars_per_word"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "BertTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "do_basic_tokenize",
      "never_split",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ]
  },
  "BertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "past_key_values_length"
    ]
  },
  "BertPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertPretrainedModel": {
    "model_config_file": [],
    "config_class": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "BertModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "past_key_values",
      "use_cache",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "BertForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "start_positions",
      "end_positions",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "BertForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "BertForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "BertLMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "masked_positions"
    ]
  },
  "BertPretrainingHeads": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output",
      "pooled_output",
      "masked_positions"
    ]
  },
  "BertForPreTrainingOutput": {},
  "BertForPretraining": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "masked_positions",
      "labels",
      "next_sentence_label",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "BertPretrainingCriterion": {
    "__init__": [
      "self",
      "vocab_size"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "seq_relationship_score",
      "masked_lm_labels",
      "next_sentence_labels",
      "masked_lm_scale"
    ]
  },
  "BertForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "BertOnlyMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output",
      "masked_positions"
    ]
  },
  "BertForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "masked_positions",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "BertFastTokenizer": {
    "resource_files_names": [],
    "slow_tokenizer_class": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "tokenizer_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ]
  },
  "BERT_PRETRAINED_INIT_CONFIGURATION": [],
  "BERT_PRETRAINED_RESOURCE_FILES_MAP": [],
  "BertConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id",
      "pool_act",
      "fuse",
      "layer_norm_eps",
      "use_cache"
    ]
  },
  "SpeechT5Processor": {
    "feature_extractor_class": [],
    "tokenizer_class": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "feature_extractor",
      "tokenizer"
    ],
    "__call__": [
      "self"
    ],
    "pad": [
      "self"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ]
  },
  "PRETRAINED_VOCAB_FILES_MAP": [],
  "SpeechT5Tokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "max_model_input_sizes": [],
    "model_input_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "bos_token",
      "eos_token",
      "unk_token",
      "pad_token",
      "sp_model_kwargs"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "d"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ]
  },
  "_HIDDEN_STATES_START_POSITION": [],
  "_CONFIG_FOR_DOC": [],
  "SPEECHT5_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "masked_fill": [
    "x",
    "mask",
    "value"
  ],
  "finfo": [
    "dtype"
  ],
  "shift_tokens_right": [
    "input_ids",
    "pad_token_id",
    "decoder_start_token_id"
  ],
  "shift_spectrograms_right": [
    "input_values",
    "reduction_factor"
  ],
  "_make_causal_mask": [
    "input_ids_shape",
    "dtype",
    "past_key_values_length"
  ],
  "_compute_mask_indices": [
    "shape",
    "mask_prob",
    "mask_length",
    "attention_mask",
    "min_masks"
  ],
  "SpeechT5NoLayerNormConvLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SpeechT5LayerNormConvLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SpeechT5GroupNormConvLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SpeechT5SinusoidalPositionalEmbedding": {
    "__init__": [
      "self",
      "num_positions",
      "embedding_dim",
      "padding_idx"
    ],
    "make_weights": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "padding_idx"
    ],
    "get_embedding": [
      "num_embeddings",
      "embedding_dim",
      "padding_idx"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values_length"
    ],
    "create_position_ids_from_input_ids": [
      "self",
      "input_ids",
      "padding_idx",
      "past_key_values_length"
    ]
  },
  "SpeechT5PositionalConvEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SpeechT5ScaledPositionalEncoding": {
    "__init__": [
      "self",
      "dropout",
      "dim",
      "max_len"
    ],
    "forward": [
      "self",
      "emb"
    ]
  },
  "SpeechT5RelativePositionalEncoding": {
    "__init__": [
      "self",
      "dim",
      "max_length"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SpeechT5SamePadLayer": {
    "__init__": [
      "self",
      "num_conv_pos_embeddings"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SpeechT5FeatureEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "_freeze_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "input_values"
    ]
  },
  "SpeechT5FeatureProjection": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SpeechT5SpeechEncoderPrenet": {
    "__init__": [
      "self",
      "config"
    ],
    "freeze_feature_encoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_values",
      "attention_mask",
      "mask_time_indices"
    ],
    "_get_feature_vector_attention_mask": [
      "self",
      "feature_vector_length",
      "attention_mask"
    ],
    "_get_feat_extract_output_lengths": [
      "self",
      "input_lengths"
    ],
    "_mask_hidden_states": [
      "self",
      "hidden_states",
      "mask_time_indices",
      "attention_mask"
    ]
  },
  "SpeechT5SpeechDecoderPrenet": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_values",
      "speaker_embeddings"
    ]
  },
  "SpeechT5BatchNormConvLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SpeechT5SpeechDecoderPostnet": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "postnet": [
      "self",
      "hidden_states"
    ]
  },
  "SpeechT5TextEncoderPrenet": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "SpeechT5TextDecoderPrenet": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "past_key_values"
    ]
  },
  "SpeechT5TextDecoderPostnet": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ]
  },
  "SpeechT5Attention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "dropout",
      "is_decoder",
      "bias"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states",
      "key_value_states",
      "past_key_value",
      "attention_mask",
      "layer_head_mask",
      "position_bias",
      "output_attentions"
    ]
  },
  "SpeechT5FeedForward": {
    "__init__": [
      "self",
      "config",
      "intermediate_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SpeechT5EncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "layer_head_mask",
      "position_bias",
      "output_attentions"
    ]
  },
  "SpeechT5DecoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "layer_head_mask",
      "cross_attn_layer_head_mask",
      "past_key_value",
      "output_attentions",
      "use_cache"
    ]
  },
  "SpeechT5PretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "main_input_name": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ]
  },
  "SpeechT5Encoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "SpeechT5EncoderWithSpeechPrenet": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_values",
      "attention_mask",
      "head_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "SpeechT5EncoderWithTextPrenet": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_values",
      "attention_mask",
      "head_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "SpeechT5EncoderWithoutPrenet": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_values",
      "attention_mask",
      "head_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "SpeechT5Decoder": {
    "__init__": [
      "self",
      "config"
    ],
    "_prepare_decoder_attention_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "inputs_embeds",
      "past_key_values_length"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "head_mask",
      "cross_attn_head_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "SpeechT5DecoderWithSpeechPrenet": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_values",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "speaker_embeddings",
      "head_mask",
      "cross_attn_head_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "SpeechT5DecoderWithTextPrenet": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_values",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "head_mask",
      "cross_attn_head_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "SpeechT5DecoderWithoutPrenet": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_values",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "head_mask",
      "cross_attn_head_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "SpeechT5GuidedMultiheadAttentionLoss": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "attentions",
      "input_masks",
      "output_masks"
    ],
    "_make_guided_attention_masks": [
      "self",
      "input_masks",
      "output_masks"
    ],
    "_make_guided_attention_mask": [
      "input_length",
      "output_length",
      "sigma"
    ]
  },
  "SpeechT5SpectrogramLoss": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "attention_mask",
      "outputs_before_postnet",
      "outputs_after_postnet",
      "logits",
      "labels",
      "cross_attentions"
    ]
  },
  "SpeechT5Model": {
    "__init__": [
      "self",
      "config",
      "encoder",
      "decoder"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "freeze_feature_encoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_values",
      "attention_mask",
      "decoder_input_values",
      "decoder_attention_mask",
      "head_mask",
      "decoder_head_mask",
      "cross_attn_head_mask",
      "encoder_outputs",
      "past_key_values",
      "use_cache",
      "speaker_embeddings",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "SpeechT5ForSpeechToText": {
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_save": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "freeze_feature_encoder": [
      "self"
    ],
    "resize_token_embeddings": [
      "self",
      "new_num_tokens"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_values",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "head_mask",
      "decoder_head_mask",
      "cross_attn_head_mask",
      "encoder_outputs",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "labels"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "decoder_input_ids",
      "past_key_values",
      "attention_mask",
      "head_mask",
      "decoder_head_mask",
      "cross_attn_head_mask",
      "use_cache",
      "encoder_outputs"
    ],
    "_reorder_cache": [
      "past_key_values",
      "beam_idx"
    ]
  },
  "_generate_speech": [
    "model",
    "input_values",
    "speaker_embeddings",
    "threshold",
    "minlenratio",
    "maxlenratio",
    "vocoder",
    "output_cross_attentions"
  ],
  "SpeechT5ForTextToSpeech": {
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_save": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_values",
      "decoder_attention_mask",
      "head_mask",
      "decoder_head_mask",
      "cross_attn_head_mask",
      "encoder_outputs",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "speaker_embeddings",
      "labels",
      "stop_labels"
    ],
    "generate_speech": [
      "self",
      "input_ids",
      "speaker_embeddings",
      "threshold",
      "minlenratio",
      "maxlenratio",
      "vocoder",
      "output_cross_attentions"
    ]
  },
  "SpeechT5ForSpeechToSpeech": {
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_save": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "freeze_feature_encoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_values",
      "attention_mask",
      "decoder_input_values",
      "decoder_attention_mask",
      "head_mask",
      "decoder_head_mask",
      "cross_attn_head_mask",
      "encoder_outputs",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "speaker_embeddings",
      "labels",
      "stop_labels"
    ],
    "generate_speech": [
      "self",
      "input_values",
      "speaker_embeddings",
      "threshold",
      "minlenratio",
      "maxlenratio",
      "vocoder",
      "output_cross_attentions"
    ]
  },
  "HifiGanResidualBlock": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "dilation",
      "leaky_relu_slope"
    ],
    "get_padding": [
      "self",
      "kernel_size",
      "dilation"
    ],
    "apply_weight_norm": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SpeechT5HifiGan": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "apply_weight_norm": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "spectrogram"
    ]
  },
  "SpeechT5FeatureExtractor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "feature_size",
      "sampling_rate",
      "padding_value",
      "do_normalize",
      "num_mel_bins",
      "hop_length",
      "win_length",
      "win_function",
      "frame_signal_scale",
      "fmin",
      "fmax",
      "mel_floor",
      "reduction_factor",
      "return_attention_mask"
    ],
    "zero_mean_unit_var_norm": [
      "input_values",
      "attention_mask",
      "padding_value"
    ],
    "_extract_mel_features": [
      "self",
      "one_waveform"
    ],
    "__call__": [
      "self",
      "audio",
      "audio_target",
      "padding",
      "max_length",
      "truncation",
      "pad_to_multiple_of",
      "return_attention_mask",
      "return_tensors",
      "sampling_rate"
    ],
    "_process_audio": [
      "self",
      "speech",
      "is_target",
      "padding",
      "max_length",
      "truncation",
      "pad_to_multiple_of",
      "return_attention_mask",
      "return_tensors"
    ],
    "to_dict": [
      "self"
    ]
  },
  "SpeechT5Config": {
    "model_type": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "encoder_layers",
      "encoder_attention_heads",
      "encoder_ffn_dim",
      "encoder_layerdrop",
      "decoder_layers",
      "decoder_ffn_dim",
      "decoder_attention_heads",
      "decoder_layerdrop",
      "hidden_act",
      "positional_dropout",
      "hidden_dropout",
      "attention_dropout",
      "activation_dropout",
      "initializer_range",
      "layer_norm_eps",
      "scale_embedding",
      "feat_extract_norm",
      "feat_proj_dropout",
      "feat_extract_activation",
      "conv_dim",
      "conv_stride",
      "conv_kernel",
      "conv_bias",
      "num_conv_pos_embeddings",
      "num_conv_pos_embedding_groups",
      "apply_spec_augment",
      "mask_time_prob",
      "mask_time_length",
      "mask_time_min_masks",
      "mask_feature_prob",
      "mask_feature_length",
      "mask_feature_min_masks",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "decoder_start_token_id",
      "num_mel_bins",
      "speech_decoder_prenet_layers",
      "speech_decoder_prenet_units",
      "speech_decoder_prenet_dropout",
      "speaker_embedding_dim",
      "speech_decoder_postnet_layers",
      "speech_decoder_postnet_units",
      "speech_decoder_postnet_kernel",
      "speech_decoder_postnet_dropout",
      "reduction_factor",
      "max_speech_positions",
      "max_text_positions",
      "encoder_max_relative_position",
      "use_guided_attention_loss",
      "guided_attention_loss_num_heads",
      "guided_attention_loss_sigma",
      "guided_attention_loss_scale",
      "use_cache",
      "is_encoder_decoder"
    ],
    "inputs_to_logits_ratio": [
      "self"
    ]
  },
  "SpeechT5HifiGanConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "model_in_dim",
      "sampling_rate",
      "upsample_initial_channel",
      "upsample_rates",
      "upsample_kernel_sizes",
      "resblock_kernel_sizes",
      "resblock_dilation_sizes",
      "initializer_range",
      "leaky_relu_slope",
      "normalize_before"
    ]
  },
  "formate_dict": [],
  "clean_up_codem_spaces": [
    "s"
  ],
  "ErnieCodeTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "sentencepiece_model_file",
      "do_lower_case",
      "remove_space",
      "keep_accents",
      "eos_token",
      "unk_token",
      "pad_token",
      "extra_ids",
      "additional_special_tokens",
      "sp_model_kwargs"
    ],
    "preprocess_text": [
      "self",
      "inputs"
    ],
    "decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ]
  },
  "ERNIECODE_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "DATA_TYPE_MAP": [],
  "data_type_converter": [
    "tensor"
  ],
  "ErnieCodeLayerNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErnieCodeDenseReluDense": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErnieCodeDenseGatedGeluDense": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErnieCodeDenseGatedSiluDense": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErnieCodeLayerFF": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErnieCodeAttention": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "_relative_position_bucket": [
      "relative_position",
      "bidirectional",
      "num_buckets",
      "max_distance"
    ],
    "compute_bias": [
      "self",
      "query_length",
      "key_length"
    ],
    "forward": [
      "self",
      "hidden_states",
      "mask",
      "key_value_states",
      "position_bias",
      "cache",
      "query_length",
      "use_cache",
      "output_attentions"
    ]
  },
  "ErnieCodeLayerSelfAttention": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias",
      "cache",
      "use_cache",
      "output_attentions"
    ]
  },
  "ErnieCodeLayerCrossAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "key_value_states",
      "attention_mask",
      "position_bias",
      "cache",
      "use_cache",
      "query_length",
      "output_attentions"
    ]
  },
  "ErnieCodeBlock": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "encoder_decoder_position_bias",
      "cache",
      "use_cache",
      "output_attentions"
    ]
  },
  "ErnieCodePretrainedModel": {
    "base_model_prefix": [],
    "config_class": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "dummy_inputs": [
      "self"
    ],
    "_init_weights": [
      "self",
      "layer"
    ],
    "_shift_right": [
      "self",
      "input_ids"
    ]
  },
  "ErnieCodeStack": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "dtype": [
      "self"
    ],
    "recompute_training": [
      "self",
      "layer_module",
      "hidden_states",
      "extended_attention_mask",
      "position_bias",
      "encoder_hidden_states",
      "encoder_extended_attention_mask",
      "encoder_decoder_position_bias",
      "use_cache",
      "output_attentions"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "inputs_embeds",
      "cache",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_extended_attention_mask": [
      "self",
      "attention_mask",
      "input_shape"
    ],
    "invert_attention_mask": [
      "self",
      "encoder_attention_mask"
    ]
  },
  "ErnieCodeModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "cache",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ErnieCodeForConditionalGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "cache",
      "labels",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_input_ids_for_generation": [
      "bos_token_id",
      "encoder_output"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "cache",
      "attention_mask",
      "use_cache",
      "encoder_output"
    ],
    "prepare_decoder_input_ids_from_labels": [
      "self",
      "labels"
    ],
    "expand_inputs_for_generation": [
      "input_ids",
      "expand_size",
      "attention_mask"
    ],
    "prepare_attention_mask_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "ErnieCodeEncoderModel": {
    "base_model_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "ErnieCode": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_encoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "cache",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ERNIECODE_PRETRAINED_INIT_CONFIGURATION": [],
  "ERNIECODE_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ErnieCodeConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "d_model",
      "d_kv",
      "d_ff",
      "num_layers",
      "num_decoder_layers",
      "num_heads",
      "relative_attention_num_buckets",
      "relative_attention_max_distance",
      "dropout_rate",
      "layer_norm_epsilon",
      "initializer_factor",
      "feed_forward_proj",
      "is_encoder_decoder",
      "use_cache",
      "bos_token_id",
      "pad_token_id",
      "eos_token_id",
      "enable_recompute"
    ]
  },
  "CodeGenTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "max_len",
      "pad_token",
      "eos_token",
      "unk_token",
      "eol_token"
    ],
    "decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces",
      "truncate_before_pattern"
    ],
    "truncate": [
      "self",
      "completion",
      "truncate_before_pattern"
    ]
  },
  "CODEGEN_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "fixed_pos_embedding": [
    "x",
    "seq_dim",
    "seq_len"
  ],
  "rotate_every_two": [
    "x"
  ],
  "duplicate_interleave": [
    "m"
  ],
  "CodeGenAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "_split_heads": [
      "self",
      "x",
      "n_head",
      "dim_head",
      "mp_num"
    ],
    "_merge_heads": [
      "self",
      "tensor",
      "num_attention_heads",
      "attn_head_size"
    ],
    "_attn": [
      "self",
      "query",
      "key",
      "value",
      "attention_mask"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "use_cache",
      "cache",
      "output_attentions"
    ]
  },
  "CodeGenMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CodeGenBlock": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "use_cache",
      "cache",
      "output_attentions"
    ]
  },
  "CodeGenPreTrainedModel": {
    "model_config_file": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "config_class": [],
    "base_model_prefix": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "CodeGenModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "use_cache",
      "cache",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CodeGenForCausalLM": {
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "prepare_fast_entry": [
      "self",
      "kwargs"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "cache"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "use_cache",
      "cache",
      "labels",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "CODEGEN_PRETRAINED_INIT_CONFIGURATION": [],
  "CODEGEN_PRETRAINED_RESOURCE_FILES_MAP": [],
  "CodeGenConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "n_embd",
      "n_layer",
      "n_head",
      "n_ctx",
      "n_positions",
      "attn_pdrop",
      "resid_pdrop",
      "embd_pdrop",
      "rotary_dim",
      "activation_function",
      "layer_norm_epsilon",
      "initializer_range",
      "n_inner",
      "tie_word_embeddings"
    ]
  },
  "SqueezeBertTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ]
  },
  "SqueezeBertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids"
    ]
  },
  "MatMulWrapper": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "mat1",
      "mat2"
    ]
  },
  "SqueezeBertLayerNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "epsilon"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvDropoutLayerNorm": {
    "__init__": [
      "self",
      "cin",
      "cout",
      "groups",
      "dropout_prob"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "ConvActivation": {
    "__init__": [
      "self",
      "cin",
      "cout",
      "groups",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SqueezeBertSelfAttention": {
    "__init__": [
      "self",
      "config",
      "cin",
      "q_groups",
      "k_groups",
      "v_groups"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "transpose_key_for_scores": [
      "self",
      "x"
    ],
    "transpose_output": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions"
    ]
  },
  "SqueezeBertLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions"
    ]
  },
  "SqueezeBertEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions",
      "output_hidden_states"
    ]
  },
  "SqueezeBertPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SqueezeBertPredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SqueezeBertLMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SqueezeBertPreTrainingHeads": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output",
      "pooled_output"
    ]
  },
  "SqueezeBertPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "SqueezeBertModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "output_attentions",
      "output_hidden_states"
    ]
  },
  "SqueezeBertForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "SqueezeBertForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids"
    ]
  },
  "SqueezeBertForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "SQUEEZEBERT_PRETRAINED_INIT_CONFIGURATION": [],
  "SQUEEZEBERT_PRETRAINED_RESOURCE_FILES_MAP": [],
  "SqueezeBertConfig": {
    "pretrained_init_configuration": [],
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "embedding_size",
      "q_groups",
      "k_groups",
      "v_groups",
      "post_attention_groups",
      "intermediate_groups",
      "output_groups"
    ]
  },
  "LayoutLMTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": []
  },
  "LayoutLMPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LayoutLMEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "token_type_ids",
      "position_ids"
    ]
  },
  "LayoutLMPretrainedModel": {
    "config_class": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "LayoutLMModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "output_hidden_states"
    ]
  },
  "LayoutLMForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "output_hidden_states"
    ]
  },
  "LayoutLMForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "output_hidden_states"
    ]
  },
  "LayoutLMLMPredictionHead": {
    "__init__": [
      "self",
      "config",
      "weight_attr"
    ],
    "forward": [
      "self",
      "hidden_states",
      "masked_positions"
    ]
  },
  "LayoutLMOnlyMLMHead": {
    "__init__": [
      "self",
      "config",
      "weight_attr"
    ],
    "forward": [
      "self",
      "sequence_output",
      "masked_positions"
    ]
  },
  "LayoutLMForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "LAYOUTLM_PRETRAINED_INIT_CONFIGURATION": [],
  "LAYOUTLM_PRETRAINED_RESOURCE_FILES_MAP": [],
  "LayoutLMConfig": {
    "pretrained_init_configuration": [],
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "max_2d_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "classifier_dropout",
      "pad_token_id",
      "pool_act"
    ]
  },
  "ErnieCtmTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "do_basic_tokenize",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token_template",
      "cls_num",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "_tokenize": [
      "self",
      "text"
    ]
  },
  "ErnieCtmModelOutput": {},
  "ErnieCtmEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "ErnieCtmPooler": {
    "__init__": [
      "self",
      "hidden_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErnieCtmPretrainedModel": {
    "model_config_file": [],
    "config_class": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "ErnieCtmModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "content_clone",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieCtmWordtagModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "lengths",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "tag_labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieCtmMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErnieCtmNptagModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieCtmForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ERNIE_CTM_CONFIG": [],
  "ERNIE_CTM_PRETRAINED_INIT_CONFIGURATION": [],
  "ERNIE_CTM_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ErnieCtmConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "embedding_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "layer_norm_eps",
      "type_vocab_size",
      "initializer_range",
      "use_content_summary",
      "content_summary_index",
      "cls_num",
      "pad_token_id",
      "num_prompt_placeholders",
      "prompt_vocab_ids"
    ]
  },
  "JiebaBasicTokenizer": {
    "__init__": [
      "self",
      "vocab",
      "do_lower_case",
      "never_split",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "_tokenize_chinese_chars": [
      "self",
      "text"
    ]
  },
  "RoFormerTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "max_model_input_sizes": [],
    "pretrained_init_configuration": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "use_jieba",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "get_vocab": [
      "self"
    ]
  },
  "RoFormerEmbeddings": {
    "__init__": [
      "self",
      "vocab_size",
      "embedding_size",
      "hidden_dropout_prob",
      "type_vocab_size"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "inputs_embeds"
    ]
  },
  "RotaryPositionEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings"
    ],
    "forward": [
      "self",
      "x",
      "offset"
    ]
  },
  "MultiHeadAttentionWithRotary": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "dropout",
      "kdim",
      "vdim",
      "need_weights",
      "rotary_value",
      "max_position_embeddings"
    ],
    "_prepare_qkv": [
      "self",
      "query",
      "key",
      "value",
      "cache"
    ]
  },
  "TransformerEncoderLayerWithRotary": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "dim_feedforward",
      "dropout",
      "activation",
      "attn_dropout",
      "act_dropout",
      "normalize_before",
      "rotary_value",
      "max_position_embeddings"
    ]
  },
  "RoFormerPooler": {
    "__init__": [
      "self",
      "hidden_size",
      "pool_act"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "RoFormerLMPredictionHead": {
    "__init__": [
      "self",
      "embedding_size",
      "hidden_size",
      "vocab_size",
      "activation",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "RoFormerOnlyMLMHead": {
    "__init__": [
      "self",
      "embedding_size",
      "hidden_size",
      "vocab_size",
      "activation",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "sequence_output"
    ]
  },
  "RoFormerPretrainedModel": {
    "config_class": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "RoFormerModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "inputs_embeds",
      "past_key_values",
      "use_cache",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "RoFormerForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "RoFormerForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "RoFormerForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "RoFormerForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "RoFormerForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "RoFormerForCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "use_cache",
      "cache"
    ],
    "update_model_kwargs_for_generation": [
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ]
  },
  "ROFORMER_PRETRAINED_INIT_CONFIGURATION": [],
  "ROFORMER_PRETRAINED_RESOURCE_FILES_MAP": [],
  "RoFormerConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "embedding_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id",
      "pool_act",
      "layer_norm_eps",
      "rotary_value",
      "eos_token_id",
      "use_cache"
    ]
  },
  "AlbertTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "sentencepiece_model_file",
      "do_lower_case",
      "remove_space",
      "keep_accents",
      "bos_token",
      "eos_token",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ]
  },
  "AlbertEnglishTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "sentencepiece_model_file",
      "do_lower_case",
      "remove_space",
      "keep_accents",
      "bos_token",
      "eos_token",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "sp_model_kwargs"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "d"
    ],
    "preprocess_text": [
      "self",
      "inputs"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ]
  },
  "AlbertChineseTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "do_basic_tokenize",
      "never_split",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ]
  },
  "dtype_float": [],
  "AlbertForPreTrainingOutput": {},
  "AlbertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ]
  },
  "AlbertAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "output_attentions"
    ]
  },
  "AlbertLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "output_attentions"
    ]
  },
  "AlbertLayerGroup": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "output_attentions",
      "output_hidden_states"
    ]
  },
  "AlbertTransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "AlbertPretrainedModel": {
    "model_config_file": [],
    "config_class": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "AlbertModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_convert_head_mask_to_5d": [
      "self",
      "head_mask",
      "num_hidden_layers"
    ],
    "get_head_mask": [
      "self",
      "head_mask",
      "num_hidden_layers",
      "is_attention_chunked"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "AlbertForPretraining": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "sentence_order_label",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "AlbertMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AlbertSOPHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pooled_output"
    ]
  },
  "AlbertForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "AlbertForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "AlbertForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "AlbertForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "AlbertForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ALBERT_PRETRAINED_INIT_CONFIGURATION": [],
  "ALBERT_PRETRAINED_RESOURCE_FILES_MAP": [],
  "AlbertConfig": {
    "pretrained_init_configuration": [],
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "embedding_size",
      "hidden_size",
      "num_hidden_layers",
      "num_hidden_groups",
      "num_attention_heads",
      "intermediate_size",
      "inner_group_num",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "add_pooling_layer",
      "classifier_dropout_prob"
    ]
  },
  "T5Tokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "sentencepiece_model_file",
      "do_lower_case",
      "remove_space",
      "keep_accents",
      "eos_token",
      "unk_token",
      "pad_token",
      "extra_ids",
      "additional_special_tokens",
      "sp_model_kwargs"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "max_length",
      "stride",
      "is_split_into_words",
      "padding",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask"
    ],
    "vocab_size": [
      "self"
    ],
    "_add_eos_if_not_present": [
      "self",
      "token_ids"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "batch_decode": [
      "self",
      "sequences",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ],
    "clean_up_tokenization": [
      "out_string"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "d"
    ]
  },
  "T5_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "T5LayerNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5DenseReluDense": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5DenseGatedGeluDense": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5DenseGatedSiluDense": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5LayerFF": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5Attention": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "_relative_position_bucket": [
      "relative_position",
      "bidirectional",
      "num_buckets",
      "max_distance"
    ],
    "compute_bias": [
      "self",
      "query_length",
      "key_length"
    ],
    "forward": [
      "self",
      "hidden_states",
      "mask",
      "key_value_states",
      "position_bias",
      "cache",
      "query_length",
      "use_cache",
      "output_attentions"
    ]
  },
  "T5LayerSelfAttention": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias",
      "cache",
      "use_cache",
      "output_attentions"
    ]
  },
  "T5LayerCrossAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "key_value_states",
      "attention_mask",
      "position_bias",
      "cache",
      "use_cache",
      "query_length",
      "output_attentions"
    ]
  },
  "T5Block": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "encoder_decoder_position_bias",
      "cache",
      "use_cache",
      "output_attentions"
    ]
  },
  "T5PretrainedModel": {
    "base_model_prefix": [],
    "config_class": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "dummy_inputs": [
      "self"
    ],
    "_init_weights": [
      "self",
      "layer"
    ],
    "_shift_right": [
      "self",
      "input_ids"
    ]
  },
  "T5Stack": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "dtype": [
      "self"
    ],
    "recompute_training": [
      "self",
      "layer_module",
      "hidden_states",
      "extended_attention_mask",
      "position_bias",
      "encoder_hidden_states",
      "encoder_extended_attention_mask",
      "encoder_decoder_position_bias",
      "use_cache",
      "output_attentions"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "inputs_embeds",
      "cache",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_extended_attention_mask": [
      "self",
      "attention_mask",
      "input_shape"
    ],
    "invert_attention_mask": [
      "self",
      "encoder_attention_mask"
    ]
  },
  "T5Model": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "cache",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "T5ForConditionalGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "cache",
      "labels",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_fast_entry": [
      "self",
      "kwargs"
    ],
    "prepare_input_ids_for_generation": [
      "bos_token_id",
      "encoder_output"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "cache",
      "attention_mask",
      "use_cache",
      "encoder_output"
    ],
    "prepare_decoder_input_ids_from_labels": [
      "self",
      "labels"
    ],
    "expand_inputs_for_generation": [
      "input_ids",
      "expand_size",
      "attention_mask"
    ],
    "prepare_attention_mask_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "T5EncoderModel": {
    "base_model_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_encoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "cache",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "T5_PRETRAINED_INIT_CONFIGURATION": [],
  "T5_PRETRAINED_RESOURCE_FILES_MAP": [],
  "T5Config": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "d_model",
      "d_kv",
      "d_ff",
      "num_layers",
      "num_decoder_layers",
      "num_heads",
      "relative_attention_num_buckets",
      "relative_attention_max_distance",
      "dropout_rate",
      "layer_norm_epsilon",
      "initializer_factor",
      "feed_forward_proj",
      "is_encoder_decoder",
      "use_cache",
      "pad_token_id",
      "eos_token_id"
    ]
  },
  "ArtistTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "image_vocab_size",
      "do_basic_tokenize",
      "never_split",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "_convert_token_to_id_with_added_voc": [
      "self",
      "token"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "max_length",
      "stride",
      "is_split_into_words",
      "padding",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "add_special_tokens",
      "pad_to_multiple_of",
      "return_tensors",
      "verbose"
    ]
  },
  "ArtistModel": {
    "config_class": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": []
  },
  "ArtistForConditionalGeneration": {
    "config_class": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "__init__": [
      "self",
      "config"
    ],
    "prepare_attention_mask_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ]
  },
  "ARTIST_PRETRAINED_INIT_CONFIGURATION": [],
  "ARTIST_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ArtistConfig": {
    "pretrained_init_configuration": []
  },
  "FNetTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "model_input_names": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "sentencepiece_model_file",
      "do_lower_case",
      "remove_space",
      "keep_accents",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "sp_model_kwargs"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ]
  },
  "FNetBasicOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "FNetOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "FNetIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "FNetLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "FNetEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FNetPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "FNetEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "FNetBasicFourierTransform": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "FNetFourierTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "FNetPredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "FNetLMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "FNetOnlyMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output"
    ]
  },
  "FNetOnlyNSPHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pooled_output"
    ]
  },
  "FNetPreTrainingHeads": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output",
      "pooled_output"
    ]
  },
  "FNetPretrainedModel": {
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "FNetModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FNetForSequenceClassification": {
    "__init__": [
      "self",
      "config",
      "num_classes"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FNetForPreTraining": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "next_sentence_label",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FNetForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "next_sentence_label",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FNetForNextSentencePrediction": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "next_sentence_label",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FNetForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FNetForTokenClassification": {
    "__init__": [
      "self",
      "config",
      "num_classes"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FNetForQuestionAnswering": {
    "__init__": [
      "self",
      "config",
      "num_labels"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FNET_PRETRAINED_INIT_CONFIGURATION": [],
  "FNET_PRETRAINED_RESOURCE_FILES_MAP": [],
  "FNetConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "add_pooling_layer"
    ]
  },
  "ReformerTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "sentencepiece_model_file",
      "do_lower_case",
      "remove_space",
      "keep_accents",
      "eos_token",
      "unk_token",
      "pad_token",
      "extra_ids",
      "additional_special_tokens",
      "sp_model_kwargs"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "max_length",
      "stride",
      "is_split_into_words",
      "padding",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask"
    ],
    "vocab_size": [
      "self"
    ],
    "_add_eos_if_not_present": [
      "self",
      "token_ids"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ]
  },
  "REFORMER_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "_logsumexp": [
    "x",
    "axis",
    "keepdim"
  ],
  "_stable_argsort": [
    "vector",
    "axis"
  ],
  "_apply_chunking_to_forward": [
    "forward_fn",
    "chunk_size",
    "chunk_dim"
  ],
  "_get_least_common_mult_chunk_len": [
    "attn_layers",
    "lsh_attn_chunk_length",
    "local_attn_chunk_length"
  ],
  "_get_min_chunk_len": [
    "attn_layers",
    "lsh_attn_chunk_length",
    "local_attn_chunk_length"
  ],
  "ReverseSort": {
    "forward": [
      "ctx",
      "out_vectors",
      "logits",
      "sorted_bucket_idx",
      "undo_sorted_bucket_idx"
    ],
    "backward": [
      "ctx",
      "grad_out_vectors",
      "grad_logits"
    ]
  },
  "_ReversibleFunction": {
    "forward": [
      "ctx",
      "hidden_states",
      "layers",
      "attention_mask",
      "num_hashes",
      "all_hidden_states",
      "all_attentions",
      "cache",
      "use_cache",
      "orig_sequence_length",
      "output_hidden_states",
      "output_attentions"
    ],
    "backward": [
      "ctx",
      "grad_hidden_states"
    ]
  },
  "AxialPositionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "position_ids"
    ]
  },
  "PositionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "position_ids"
    ]
  },
  "ReformerEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "start_idx_pos_encodings",
      "inputs_embeds"
    ]
  },
  "EfficientAttentionMixin": {
    "_look_adjacent": [
      "self",
      "vectors",
      "num_chunks_before",
      "num_chunks_after"
    ],
    "_split_hidden_size_dim": [
      "self",
      "x",
      "num_attn_heads",
      "attn_head_size"
    ],
    "_merge_hidden_size_dims": [
      "self",
      "x",
      "num_attn_heads",
      "attn_head_size"
    ],
    "_split_seq_length_dim_to": [
      "self",
      "vectors",
      "dim_factor_1",
      "dim_factor_2",
      "num_attn_heads",
      "attn_head_size"
    ]
  },
  "LSHSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "num_hashes",
      "buckets",
      "cache",
      "use_cache",
      "output_attentions"
    ],
    "_query_per_attn_head": [
      "self",
      "hidden_states"
    ],
    "_value_per_attn_head": [
      "self",
      "hidden_states"
    ],
    "_hash_vectors": [
      "self",
      "vectors",
      "num_hashes",
      "attention_mask",
      "increase_num_buckets"
    ],
    "_get_sorted_bucket_idx_and_undo_sorted_bucket_idx": [
      "self",
      "buckets"
    ],
    "_set_num_buckets": [
      "self",
      "sequence_length"
    ],
    "_attend": [
      "self",
      "query_vectors",
      "key_vectors",
      "value_vectors",
      "sorted_bucket_idx_per_hash",
      "attention_mask",
      "do_standard_self_attention",
      "do_cached_attention"
    ],
    "_compute_attn_mask": [
      "self",
      "query_indices",
      "key_indices",
      "attention_mask",
      "query_key_dot_shape",
      "do_standard_self_attention"
    ],
    "_get_relevant_hid_states_and_buckets": [
      "self",
      "query_vectors",
      "attention_mask",
      "num_hashes",
      "hidden_states",
      "past_states",
      "past_buckets"
    ],
    "_expand_to_indices_in_relevant_chunk": [
      "self",
      "indices",
      "sequence_length"
    ],
    "_len_and_dim_norm": [
      "self",
      "vectors"
    ],
    "_len_norm": [
      "self",
      "x",
      "epsilon"
    ],
    "_gather_by_expansion": [
      "self",
      "vectors",
      "idxs",
      "num_hashes"
    ]
  },
  "LocalSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "cache",
      "use_cache",
      "output_attentions"
    ],
    "_compute_attn_mask": [
      "self",
      "query_indices",
      "key_indices",
      "attention_mask",
      "query_key_dots_shape",
      "do_standard_self_attention"
    ],
    "_retrieve_relevant_hidden_states": [
      "previous_hidden_states",
      "chunk_length",
      "num_chunks_before"
    ]
  },
  "ReformerSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ReformerAttention": {
    "__init__": [
      "self",
      "config",
      "layer_id"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "num_hashes",
      "cache",
      "use_cache",
      "orig_sequence_length",
      "output_attentions",
      "buckets"
    ]
  },
  "ReformerFeedForwardDense": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ReformerFeedForwardOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ChunkReformerFeedForward": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "attention_output"
    ],
    "forward_chunk": [
      "self",
      "hidden_states"
    ]
  },
  "ReformerLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id"
    ],
    "_init_attention_seed": [
      "self"
    ],
    "_init_feed_forward_seed": [
      "self"
    ],
    "forward": [
      "self",
      "prev_attn_output",
      "hidden_states",
      "attention_mask",
      "num_hashes",
      "cache",
      "use_cache",
      "orig_sequence_length",
      "output_attentions"
    ],
    "backward_pass": [
      "self",
      "next_attn_output",
      "hidden_states",
      "grad_attn_output",
      "grad_hidden_states",
      "attention_mask",
      "buckets"
    ]
  },
  "ReformerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "num_hashes",
      "cache",
      "use_cache",
      "orig_sequence_length",
      "output_hidden_states",
      "output_attentions"
    ]
  },
  "ReformerOnlyLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "forward_chunk": [
      "self",
      "hidden_states"
    ]
  },
  "ReformerClassificationHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LSHSelfAttentionOutput": {},
  "LocalSelfAttentionOutput": {},
  "AttentionOutput": {},
  "ReformerOutput": {},
  "ReformerBackwardOutput": {},
  "ReformerEncoderOutput": {},
  "ReformerPretrainedModel": {
    "base_model_prefix": [],
    "config_class": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "ReformerModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "num_hashes",
      "cache",
      "use_cache",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ],
    "_pad_to_mult_of_chunk_length": [
      "self",
      "input_ids",
      "inputs_embeds",
      "attention_mask",
      "position_ids",
      "input_shape",
      "padding_length",
      "padded_seq_length"
    ]
  },
  "ReformerModelWithLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "num_hashes",
      "cache",
      "use_cache",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "cache",
      "use_cache",
      "num_hashes"
    ]
  },
  "ReformerForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "num_hashes",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ReformerForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "num_hashes",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ReformerForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "num_hashes",
      "start_positions",
      "end_positions",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "REFORMER_PRETRAINED_INIT_CONFIGURATION": [],
  "REFORMER_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ReformerConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "axial_pos_shape",
      "axial_pos_embds_dim",
      "hidden_dropout_prob",
      "attn_layers",
      "lsh_attn_chunk_length",
      "local_attn_chunk_length",
      "hidden_size",
      "max_position_embeddings",
      "axial_pos_embds",
      "vocab_size",
      "num_hashes",
      "num_buckets",
      "lsh_num_chunks_before",
      "lsh_num_chunks_after",
      "hash_seed",
      "is_decoder",
      "lsh_attention_probs_dropout_prob",
      "num_attention_heads",
      "attention_head_size",
      "local_num_chunks_before",
      "local_num_chunks_after",
      "pad_token_id",
      "local_attention_probs_dropout_prob",
      "layer_norm_eps",
      "hidden_act",
      "feed_forward_size",
      "chunk_size_feed_forward",
      "chunk_size_lm_head",
      "tie_word_embeddings",
      "initializer_range",
      "axial_norm_std",
      "use_cache",
      "classifier_dropout",
      "num_hidden_layers"
    ]
  },
  "DPTImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "size",
      "resample",
      "keep_aspect_ratio",
      "ensure_multiple_of",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std"
    ],
    "resize": [
      "self",
      "image",
      "size",
      "keep_aspect_ratio",
      "ensure_multiple_of",
      "resample",
      "data_format"
    ],
    "rescale": [
      "self",
      "image",
      "scale",
      "data_format"
    ],
    "normalize": [
      "self",
      "image",
      "mean",
      "std",
      "data_format"
    ],
    "preprocess": [
      "self",
      "images",
      "do_resize",
      "size",
      "keep_aspect_ratio",
      "ensure_multiple_of",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "return_tensors",
      "data_format"
    ],
    "post_process_semantic_segmentation": [
      "self",
      "outputs",
      "target_sizes"
    ]
  },
  "BaseModelOutputWithIntermediateActivations": {},
  "BaseModelOutputWithPoolingAndIntermediateActivations": {},
  "DPTViTHybridEmbeddings": {
    "__init__": [
      "self",
      "config",
      "feature_size"
    ],
    "_resize_pos_embed": [
      "self",
      "posemb",
      "grid_size_height",
      "grid_size_width",
      "start_index"
    ],
    "forward": [
      "self",
      "pixel_values",
      "interpolate_pos_encoding",
      "return_dict"
    ]
  },
  "DPTViTEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "_resize_pos_embed": [
      "self",
      "posemb",
      "grid_size_height",
      "grid_size_width",
      "start_index"
    ],
    "forward": [
      "self",
      "pixel_values",
      "return_dict"
    ]
  },
  "DPTViTPatchEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "DPTViTSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "output_attentions"
    ]
  },
  "DPTViTSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "DPTViTAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "output_attentions"
    ]
  },
  "DPTViTIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DPTViTOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "DPTViTLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "output_attentions"
    ]
  },
  "DPTViTEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DPTReassembleStage": {
    "__init__": [
      "self",
      "config"
    ],
    "_init_reassemble_dpt_hybrid": [
      "self",
      "config"
    ],
    "_init_reassemble_dpt": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DPTReassembleLayer": {
    "__init__": [
      "self",
      "config",
      "channels",
      "factor"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "DPTFeatureFusionStage": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DPTPreActResidualLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "DPTFeatureFusionLayer": {
    "__init__": [
      "self",
      "config",
      "align_corners"
    ],
    "forward": [
      "self",
      "hidden_state",
      "residual"
    ]
  },
  "DPTPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "main_input_name": [],
    "supports_gradient_checkpointing": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "gradient_checkpointing_enable": [
      "self"
    ],
    "gradient_checkpointing_disable": [
      "self"
    ]
  },
  "DPTModel": {
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DPTViTPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DPTNeck": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DPTDepthEstimationHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DPTForDepthEstimation": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DPTSemanticSegmentationHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DPTAuxiliaryHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DPTForSemanticSegmentation": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DPTConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "initializer_range",
      "layer_norm_eps",
      "image_size",
      "patch_size",
      "num_channels",
      "is_hybrid",
      "qkv_bias",
      "backbone_out_indices",
      "readout_type",
      "reassemble_factors",
      "neck_hidden_sizes",
      "fusion_hidden_size",
      "head_in_index",
      "use_batch_norm_in_fusion_residual",
      "use_auxiliary_head",
      "auxiliary_loss_weight",
      "semantic_loss_ignore_index",
      "semantic_classifier_dropout",
      "backbone_featmap_shape",
      "neck_ignore_stages",
      "backbone_config"
    ],
    "to_dict": [
      "self"
    ]
  },
  "bytes_to_unicode": [],
  "get_pairs": [
    "word"
  ],
  "DebertaTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "max_len",
      "bos_token",
      "eos_token",
      "sep_token",
      "cls_token",
      "unk_token",
      "pad_token",
      "mask_token",
      "add_prefix_space",
      "add_bos_token"
    ],
    "vocab_size": [
      "self"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_ids_to_string": [
      "self",
      "ids"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "get_vocab": [
      "self"
    ],
    "prepare_for_tokenization": [
      "self",
      "text",
      "is_split_into_words"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ]
  },
  "DropoutContext": {
    "__init__": [
      "self"
    ]
  },
  "get_mask": [
    "input",
    "local_context"
  ],
  "XDropout": {
    "forward": [
      "ctx",
      "input",
      "local_ctx"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "StableDropout": {
    "__init__": [
      "self",
      "drop_prob"
    ],
    "forward": [
      "self",
      "x"
    ],
    "clear_context": [
      "self"
    ],
    "init_context": [
      "self",
      "reuse_mask",
      "scale"
    ],
    "get_context": [
      "self"
    ]
  },
  "create_position_ids_from_input_ids": [
    "input_ids",
    "padding_idx",
    "past_key_values_length"
  ],
  "softmax_with_mask": [
    "x",
    "mask",
    "axis"
  ],
  "DebertaEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "mask",
      "inputs_embeds"
    ]
  },
  "DebertaLayerNorm": {
    "__init__": [
      "self",
      "size",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DebertaSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "build_relative_position": [
    "query_size",
    "key_size"
  ],
  "c2p_dynamic_expand": [
    "c2p_pos",
    "query_layer",
    "relative_pos"
  ],
  "p2c_dynamic_expand": [
    "c2p_pos",
    "query_layer",
    "key_layer"
  ],
  "pos_dynamic_expand": [
    "pos_index",
    "p2c_att",
    "key_layer"
  ],
  "DisentangledSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions",
      "query_states",
      "relative_pos",
      "rel_embeddings"
    ],
    "disentangled_att_bias": [
      "self",
      "query_layer",
      "key_layer",
      "relative_pos",
      "rel_embeddings",
      "scale_factor"
    ]
  },
  "DebertaAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions",
      "query_states",
      "relative_pos",
      "rel_embeddings"
    ]
  },
  "DebertaIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DebertaOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "DebertaLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "query_states",
      "relative_pos",
      "rel_embeddings",
      "output_attentions"
    ]
  },
  "DebertaEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "get_rel_embedding": [
      "self"
    ],
    "get_attention_mask": [
      "self",
      "attention_mask"
    ],
    "get_rel_pos": [
      "self",
      "hidden_states",
      "query_states",
      "relative_pos"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_hidden_states",
      "output_attentions",
      "query_states",
      "relative_pos",
      "return_dict"
    ]
  },
  "DebertaPreTrainedModel": {
    "model_config_file": [],
    "config_class": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "init_weights": [
      "self",
      "layer"
    ]
  },
  "DebertaModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DebertaPredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DebertaLMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DebertaOnlyMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output"
    ]
  },
  "DebertaForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ContextPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "output_dim": [
      "self"
    ]
  },
  "DebertaForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DebertaForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DebertaForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DebertaForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "DEBERTA_PRETRAINED_INIT_CONFIGURATION": [],
  "DEBERTA_PRETRAINED_RESOURCE_FILES_MAP": [],
  "DebertaConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "position_biased_input",
      "pos_att_type",
      "output_attentions",
      "output_hidden_states",
      "relative_attention"
    ]
  },
  "return_args": [
    "hidden_states",
    "attention_mask",
    "position_ids"
  ],
  "QWenEmbeddingPipe": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "args"
    ]
  },
  "QWenBlockPipe": {
    "forward": [
      "self",
      "args"
    ]
  },
  "QWenRMSNormPipe": {
    "forward": [
      "self",
      "args"
    ]
  },
  "QWenForCausalLMPipe": {
    "config_class": [],
    "_get_tensor_parallel_mappings": [],
    "_init_weights": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "PAT_STR": [],
  "ENDOFTEXT": [],
  "IMSTART": [],
  "IMEND": [],
  "EXTRAS": [],
  "SPECIAL_TOKENS": [],
  "tiktoken": [],
  "_load_tiktoken_bpe": [
    "tiktoken_bpe_file"
  ],
  "QWenTokenizer": {
    "model_input_names": [],
    "resource_files_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "errors",
      "padding_side"
    ],
    "__len__": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "_add_tokens": [
      "self",
      "new_tokens",
      "special_tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory"
    ],
    "tokenize": [
      "self",
      "text",
      "allowed_special",
      "disallowed_special"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "vocab_size": [
      "self"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "errors"
    ],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ]
  },
  "MAX_NTK_SEQ_LENGTH": [],
  "parallel_matmul": [
    "x",
    "y",
    "tensor_parallel_output"
  ],
  "get_triangle_upper_mask": [
    "x",
    "mask"
  ],
  "QWenAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "_attn": [
      "self",
      "query",
      "key",
      "value",
      "attention_mask"
    ],
    "_split_heads": [
      "self",
      "tensor",
      "num_heads",
      "attn_head_size"
    ],
    "_merge_heads": [
      "self",
      "tensor",
      "num_heads",
      "attn_head_size"
    ],
    "forward": [
      "self",
      "hidden_states",
      "layer_past",
      "attention_mask",
      "position_ids",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "output_attentions",
      "use_cache"
    ]
  },
  "QWenMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "QWenBlock": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "layer_past",
      "attention_mask",
      "position_ids",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "use_cache",
      "output_attentions"
    ]
  },
  "QWenPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "__init__": [
      "self"
    ],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_init_weights": [
      "self",
      "module"
    ]
  },
  "QWenModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "recompute_training": [
      "self",
      "block",
      "hidden_states",
      "layer_past",
      "attention_mask",
      "position_ids",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "use_cache",
      "output_attentions"
    ],
    "get_masks": [
      "self",
      "batch_size",
      "seq_length",
      "past_length",
      "padding_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "position_ids",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "QWenLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "tensor_parallel_output"
    ]
  },
  "QWenPretrainingCriterion": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "masked_lm_labels"
    ]
  },
  "QWenForCausalLM": {
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "update_model_kwargs_for_generation": [
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past_key_values",
      "inputs_embeds"
    ],
    "prepare_attention_mask_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "position_ids",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "rotate_half": [
    "x"
  ],
  "rms_norm_fused": [
    "x_in",
    "w",
    "eps"
  ],
  "QWenRMSNorm": {
    "__init__": [
      "self",
      "config"
    ],
    "_norm": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QWenLMHeadModel": [],
  "QWenConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "emb_dropout_prob",
      "attn_dropout_prob",
      "layer_norm_epsilon",
      "initializer_range",
      "max_position_embeddings",
      "scale_attn_weights",
      "use_cache",
      "recompute_granularity",
      "kv_channels",
      "rotary_pct",
      "rotary_emb_base",
      "use_dynamic_ntk",
      "use_logn_attn",
      "use_flash_attention",
      "use_fused_rms_norm",
      "use_fused_rope",
      "intermediate_size",
      "tensor_parallel_output",
      "no_bias",
      "tie_word_embeddings",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "long_sequence_strategy_type",
      "long_sequence_strategy_name",
      "long_sequence_init_args",
      "use_long_sequence_strategies"
    ]
  },
  "BlipProcessor": {
    "attributes": [],
    "image_processor_class": [],
    "tokenizer_class": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "return_tensors"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "model_input_names": [
      "self"
    ]
  },
  "BlipImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb"
    ],
    "resize": [
      "self",
      "image",
      "size",
      "resample",
      "data_format"
    ],
    "rescale": [
      "self",
      "image",
      "scale",
      "data_format"
    ],
    "normalize": [
      "self",
      "image",
      "mean",
      "std",
      "data_format"
    ],
    "preprocess": [
      "self",
      "images",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "return_tensors",
      "do_convert_rgb",
      "data_format"
    ]
  },
  "BlipTextEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ]
  },
  "BlipTextSelfAttention": {
    "__init__": [
      "self",
      "config",
      "is_cross_attention"
    ],
    "save_attn_gradients": [
      "self",
      "attn_gradients"
    ],
    "get_attn_gradients": [
      "self"
    ],
    "save_attention_map": [
      "self",
      "attention_map"
    ],
    "get_attention_map": [
      "self"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "BlipTextSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "BlipTextAttention": {
    "__init__": [
      "self",
      "config",
      "is_cross_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "BlipTextIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BlipTextOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "BlipTextLayer": {
    "__init__": [
      "self",
      "config",
      "layer_num"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ]
  },
  "BlipTextEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BlipTextPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BlipTextPredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BlipTextLMPredictionHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BlipTextOnlyMLMHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "sequence_output"
    ]
  },
  "BlipTextPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "_keys_to_ignore_on_load_missing": [],
    "supports_gradient_checkpointing": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "gradient_checkpointing_enable": [
      "self"
    ],
    "gradient_checkpointing_disable": [
      "self"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ]
  },
  "BlipTextModel": {
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "dtype": [
      "self"
    ],
    "get_extended_attention_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "is_decoder"
    ],
    "invert_attention_mask": [
      "self",
      "encoder_attention_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "inputs_embeds",
      "encoder_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "is_decoder"
    ]
  },
  "BlipTextLMHeadModel": {
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "labels",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "return_logits",
      "is_decoder",
      "reduction"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask"
    ],
    "prepare_attention_mask_for_generation": [
      "self",
      "inputs",
      "pad_token_id",
      "eos_token_id"
    ]
  },
  "BLIP_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "blip_loss": [
    "similarity"
  ],
  "BlipForConditionalGenerationModelOutput": {},
  "BlipTextVisionModelOutput": {},
  "BlipImageTextMatchingModelOutput": {},
  "BlipOutput": {
    "to_tuple": [
      "self"
    ]
  },
  "BlipVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "BlipAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions"
    ]
  },
  "BlipMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BlipEncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions"
    ]
  },
  "BlipPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "init_weights": [
      "self"
    ],
    "gradient_checkpointing_enable": [
      "self"
    ],
    "gradient_checkpointing_disable": [
      "self"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ]
  },
  "BlipEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BlipVisionModel": {
    "main_input_name": [],
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BlipModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_text_features": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "attention_mask",
      "position_ids",
      "return_loss",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BlipForConditionalGeneration": {
    "config_class": [],
    "_keys_to_ignore_on_load_missing": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "input_ids",
      "position_ids",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "labels",
      "return_dict"
    ],
    "generate": [
      "self",
      "pixel_values",
      "input_ids",
      "attention_mask"
    ]
  },
  "BlipForQuestionAnswering": {
    "config_class": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "decoder_input_ids",
      "decoder_attention_mask",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "labels",
      "return_dict"
    ],
    "generate": [
      "self",
      "input_ids",
      "pixel_values",
      "attention_mask"
    ]
  },
  "BlipForImageTextRetrieval": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "use_itm_head",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BlipTextConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "encoder_hidden_size",
      "intermediate_size",
      "projection_dim",
      "num_hidden_layers",
      "num_attention_heads",
      "max_position_embeddings",
      "hidden_act",
      "layer_norm_eps",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "initializer_range",
      "initializer_factor",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "sep_token_id",
      "is_decoder",
      "use_cache"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "BlipVisionConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "projection_dim",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "hidden_act",
      "layer_norm_eps",
      "dropout",
      "attention_dropout",
      "initializer_range",
      "initializer_factor"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "BlipConfig": {
    "model_type": [],
    "is_composition": [],
    "__init__": [
      "self",
      "text_config",
      "vision_config",
      "projection_dim",
      "logit_scale_init_value",
      "image_text_hidden_size"
    ],
    "from_text_vision_configs": [
      "cls",
      "text_config",
      "vision_config"
    ],
    "to_dict": [
      "self"
    ]
  },
  "MPNetTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "bos_token",
      "eos_token",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "max_length",
      "stride",
      "padding",
      "is_split_into_words",
      "pad_to_max_seq_len",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "add_special_tokens",
      "pad_to_multiple_of",
      "return_offsets_mapping"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ]
  },
  "MPNetEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids"
    ]
  },
  "MPNetAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias"
    ]
  },
  "MPNetLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias"
    ]
  },
  "MPNetEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ],
    "compute_position_bias": [
      "self",
      "x",
      "position_ids",
      "num_buckets"
    ],
    "relative_position_bucket": [
      "relative_position",
      "num_buckets",
      "max_distance"
    ]
  },
  "MPNetPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MPNetPretrainedModel": {
    "base_model_prefix": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "MPNetModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ]
  },
  "MPNetLMHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MPNetForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "labels"
    ]
  },
  "MPNetForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "MPNetForMultipleChoice": {
    "__init__": [
      "self",
      "config",
      "num_choices"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "MPNetForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "MPNetForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "MPNET_PRETRAINED_INIT_CONFIGURATION": [],
  "MPNetConfig": {
    "model_type": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "initializer_range",
      "layer_norm_eps",
      "relative_attention_num_buckets",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id"
    ]
  },
  "get_hcg": [],
  "get_attr": [
    "layer",
    "name"
  ],
  "GPTEmbeddingPipe": {
    "__init__": [
      "self",
      "config"
    ],
    "embedding_weight": [
      "self"
    ],
    "forward": [
      "self",
      "args"
    ]
  },
  "GPTDecoderLayerPipe": {
    "forward": [
      "self",
      "args"
    ]
  },
  "LayerNormPipe": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "args"
    ]
  },
  "GPTLMHeadPipe": {
    "__init__": [
      "self",
      "config"
    ],
    "embedding_weight": [
      "self"
    ]
  },
  "GPTForCausalLMPipe": {
    "config_class": [],
    "_get_tensor_parallel_mappings": [],
    "_get_fuse_or_split_param_mappings": [],
    "_init_weights": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "__init__": [
      "self",
      "config",
      "pp_recompute_interval"
    ]
  },
  "get_mesh": [
    "pp_idx"
  ],
  "seed_guard_context": [
    "name"
  ],
  "_expand_2d_mask": [
    "mask",
    "dtype",
    "tgt_length"
  ],
  "MultiHeadAttentionAuto": {
    "Cache": [],
    "__init__": [
      "self",
      "config",
      "ipp"
    ],
    "_fuse_prepare_qkv": [
      "self",
      "query",
      "use_cache",
      "past_key_value"
    ],
    "_prepare_qkv": [
      "self",
      "query",
      "key",
      "value",
      "use_cache",
      "past_key_value"
    ],
    "_flash_attention": [
      "self",
      "q",
      "k",
      "v",
      "attention_mask",
      "output_attentions"
    ],
    "_core_attention": [
      "self",
      "q",
      "k",
      "v",
      "attention_mask",
      "output_attentions"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attention_mask",
      "use_cache",
      "past_key_value",
      "output_attentions"
    ]
  },
  "TransformerDecoder": {
    "__init__": [
      "self",
      "config",
      "decoder_layers",
      "norm",
      "hidden_size"
    ],
    "recompute_training": [
      "self",
      "layer_module",
      "hidden_states",
      "past_key_value",
      "attention_mask",
      "use_cache",
      "output_attentions"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "use_cache",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "GPTDecoderLayerAuto": {
    "__init__": [
      "self",
      "config",
      "ipp"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "use_cache",
      "past_key_value",
      "output_attentions"
    ]
  },
  "GPTEmbeddingsAuto": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeddings"
    ]
  },
  "GPTPretrainedModelAuto": {
    "model_config_file": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "config_class": [],
    "pretrained_init_configuration": [],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ],
    "_get_name_mappings": [
      "cls",
      "config"
    ]
  },
  "GPTModelAuto": {
    "__init__": [
      "self",
      "config"
    ],
    "get_layer_ipp": [
      "self",
      "layer_index"
    ],
    "get_last_layer_ipp": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prepare_decoder_attention_mask": [
      "attention_mask",
      "input_shape",
      "past_key_values_length",
      "dtype"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "GPTPretrainingCriterionAuto": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "masked_lm_labels",
      "loss_mask"
    ]
  },
  "GPTLMHeadAuto": {
    "__init__": [
      "self",
      "config",
      "embedding_weights",
      "ipp"
    ],
    "forward": [
      "self",
      "hidden_states",
      "tensor_parallel_output"
    ]
  },
  "GPTForCausalLMAuto": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "past_key_values",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_fast_entry": [
      "self",
      "kwargs"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "use_cache",
      "past_key_values"
    ],
    "prepare_attention_mask_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ]
  },
  "GPTLMHeadModelAuto": [],
  "GPTChineseTokenizer": {
    "resource_files_names": [],
    "cpm_model_link": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "model_file",
      "max_len",
      "unk_token",
      "bos_token",
      "eos_token",
      "eol_token"
    ],
    "eol_token_id": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "convert_ids_to_string": [
      "self",
      "ids"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ]
  },
  "GPTTokenizer": {
    "resource_files_names": [],
    "gpt_vocab_link": [],
    "gpt_merges_link": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "max_len",
      "pad_token",
      "eos_token",
      "unk_token",
      "eol_token",
      "add_prefix_space",
      "add_bos_token"
    ],
    "vocab_size": [
      "self"
    ],
    "eol_token_id": [
      "self"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_ids_to_string": [
      "self",
      "ids"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "get_vocab": [
      "self"
    ],
    "prepare_for_tokenization": [
      "self",
      "text",
      "is_split_into_words"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ]
  },
  "OriginLayerNorm": [],
  "fast_layer_norm": [
    "input",
    "weight",
    "bias",
    "eps"
  ],
  "_check_normalized_shape": [
    "normalized_shape"
  ],
  "GPTDecoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "use_cache",
      "past_key_value",
      "output_attentions"
    ]
  },
  "GPTEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeddings"
    ]
  },
  "GPTLayerNorm": {
    "__init__": [
      "self",
      "config",
      "normalized_shape",
      "epsilon",
      "weight_attr",
      "bias_attr",
      "name"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "GPTPretrainedModel": {
    "model_config_file": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "config_class": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ],
    "_get_fuse_or_split_param_mappings": [
      "cls",
      "config",
      "is_fuse"
    ],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "GPTModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prepare_decoder_attention_mask": [
      "attention_mask",
      "input_shape",
      "past_key_values_length",
      "dtype"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "GPTPretrainingCriterion": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "masked_lm_labels",
      "loss_mask"
    ]
  },
  "GPTForGreedyGeneration": {
    "__init__": [
      "self",
      "config",
      "max_predict_len"
    ],
    "model": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "masked_positions",
      "use_cache",
      "past_key_values"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "GPTLMHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states",
      "tensor_parallel_output"
    ]
  },
  "GPTForCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "past_key_values",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_fast_entry": [
      "self",
      "kwargs"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "use_cache",
      "past_key_values"
    ],
    "prepare_attention_mask_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ]
  },
  "GPTForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "GPTForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "GPTLMHeadModel": [],
  "GPT_PRETRAINED_INIT_CONFIGURATION": [],
  "GPT_PRETRAINED_RESOURCE_FILES_MAP": [],
  "GPTConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "seq_length",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_activation",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "eos_token_id",
      "bos_token_id",
      "eol_token_id",
      "num_partitions",
      "normalize_before",
      "recompute_granularity",
      "scale_qk_coeff",
      "tensor_parallel_degree",
      "tensor_parallel_output",
      "output_attentions",
      "ignore_index",
      "use_flash_attention",
      "use_fused_dropout_add",
      "use_fast_layer_norm",
      "use_fused_linear",
      "fuse_attention_qkv",
      "fuse_attention_ffn",
      "fused_softmax_with_triangular",
      "virtual_pp_degree",
      "sequence_parallel",
      "fuse_sequence_parallel_allreduce"
    ]
  },
  "_add_prefix_space": [],
  "LukeTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "entity_file",
      "merges_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "sep_token_id": [
      "self"
    ],
    "cls_token_id": [
      "self"
    ],
    "pad_token_id": [
      "self"
    ],
    "unk_token_id": [
      "self"
    ],
    "get_entity_vocab": [
      "self"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "_tokenize": [
      "self",
      "text",
      "add_prefix_space"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "entity_spans",
      "entity_spans_pair",
      "entities",
      "entities_pair",
      "max_mention_length",
      "max_length",
      "stride",
      "add_prefix_space",
      "is_split_into_words",
      "padding",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask"
    ],
    "tokenize": [
      "self",
      "text",
      "add_prefix_space"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "_convert_token_to_id_with_added_voc": [
      "self",
      "token"
    ],
    "add_special_tokens": [
      "self",
      "token_list"
    ],
    "convert_entity_to_id": [
      "self",
      "entity"
    ],
    "entity_encode": [
      "self",
      "text",
      "entities",
      "max_mention_length",
      "entity_spans",
      "ent_sep",
      "offset_a"
    ],
    "_convert_entity_pos": [
      "self",
      "text",
      "entity_span"
    ],
    "get_offset_mapping": [
      "self",
      "text"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ]
  },
  "paddle_gather": [
    "x",
    "dim",
    "index"
  ],
  "layer_norm_eps": [],
  "LukePretrainedModel": {
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "LukeSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "LukeIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LukeOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "LukeEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids"
    ]
  },
  "LukePooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EntityEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "entity_ids",
      "position_ids",
      "token_type_ids"
    ]
  },
  "LukeSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "word_hidden_states",
      "entity_hidden_states",
      "attention_mask"
    ]
  },
  "LukeAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "word_hidden_states",
      "entity_hidden_states",
      "attention_mask"
    ]
  },
  "LukeLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "word_hidden_states",
      "entity_hidden_states",
      "attention_mask"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ]
  },
  "LukeEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "word_hidden_states",
      "entity_hidden_states",
      "attention_mask"
    ]
  },
  "LukeModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "entity_ids",
      "entity_position_ids",
      "entity_token_type_ids",
      "entity_attention_mask"
    ]
  },
  "LukeLMHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "EntityPredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EntityPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LukeForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "entity_ids",
      "entity_position_ids",
      "entity_token_type_ids",
      "entity_attention_mask"
    ]
  },
  "LukeForEntityClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "entity_ids",
      "entity_position_ids",
      "entity_token_type_ids",
      "entity_attention_mask"
    ]
  },
  "LukeForEntityPairClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "entity_ids",
      "entity_position_ids",
      "entity_token_type_ids",
      "entity_attention_mask"
    ]
  },
  "LukeForEntitySpanClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "entity_start_positions",
      "entity_end_positions",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "entity_ids",
      "entity_position_ids",
      "entity_token_type_ids",
      "entity_attention_mask"
    ]
  },
  "LukeForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "entity_ids",
      "entity_position_ids",
      "entity_token_type_ids",
      "entity_attention_mask"
    ]
  },
  "LUKE_PRETRAINED_INIT_CONFIGURATION": [],
  "LUKE_PRETRAINED_RESOURCE_FILES_MAP": [],
  "LukeConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "entity_vocab_size",
      "entity_emb_size",
      "initializer_range",
      "pad_token_id",
      "entity_pad_token_id",
      "cls_token_id"
    ]
  },
  "ErnieDocTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ]
  },
  "ErnieDocBPETokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_file",
      "encoder_json_path",
      "vocab_bpe_path",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ]
  },
  "PointwiseFFN": {
    "__init__": [
      "self",
      "d_inner_hid",
      "d_hid",
      "dropout_rate",
      "hidden_act",
      "weight_attr",
      "bias_attr"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ErnieDocEncoderLayer": {
    "__init__": [
      "self",
      "n_head",
      "d_key",
      "d_value",
      "d_model",
      "d_inner_hid",
      "prepostprocess_dropout",
      "attention_dropout",
      "relu_dropout",
      "hidden_act",
      "normalize_before",
      "epsilon",
      "rel_pos_params_sharing",
      "r_w_bias",
      "r_r_bias",
      "r_t_bias",
      "weight_attr",
      "bias_attr"
    ],
    "forward": [
      "self",
      "enc_input",
      "memory",
      "rel_pos",
      "rel_task",
      "attn_mask"
    ]
  },
  "ErnieDocEncoder": {
    "__init__": [
      "self",
      "num_layers",
      "encoder_layer",
      "mem_len"
    ],
    "_cache_mem": [
      "self",
      "curr_out",
      "prev_mem"
    ],
    "forward": [
      "self",
      "enc_input",
      "memories",
      "rel_pos",
      "rel_task",
      "attn_mask"
    ]
  },
  "ErnieDocPretrainedModel": {
    "base_model_prefix": [],
    "config_class": [],
    "resource_files_names": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "ErnieDocEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids"
    ]
  },
  "ErnieDocPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErnieDocModel": {
    "__init__": [
      "self",
      "config"
    ],
    "_create_n_head_attn_mask": [
      "self",
      "attn_mask",
      "batch_size"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "memories",
      "token_type_ids",
      "position_ids",
      "attn_mask"
    ]
  },
  "ErnieDocForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "memories",
      "token_type_ids",
      "position_ids",
      "attn_mask"
    ]
  },
  "ErnieDocForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "memories",
      "token_type_ids",
      "position_ids",
      "attn_mask"
    ]
  },
  "ErnieDocForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "memories",
      "token_type_ids",
      "position_ids",
      "attn_mask"
    ]
  },
  "ERNIE_DOC_PRETRAINED_INIT_CONFIGURATION": [],
  "ERNIE_DOC_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ErnieDocConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "num_hidden_layers",
      "num_attention_heads",
      "hidden_size",
      "hidden_dropout_prob",
      "attention_dropout_prob",
      "relu_dropout",
      "hidden_act",
      "memory_len",
      "vocab_size",
      "max_position_embeddings",
      "task_type_vocab_size",
      "normalize_before",
      "epsilon",
      "rel_pos_params_sharing",
      "initializer_range",
      "pad_token_id",
      "cls_token_idx"
    ]
  },
  "ChineseBertTokenizer": {
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "padding_side": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "pinyin_map",
      "id2pinyin",
      "pinyin2tensor",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "encode": [
      "self",
      "text",
      "text_pair",
      "max_seq_len",
      "pad_to_max_seq_len",
      "truncation_strategy",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask"
    ],
    "batch_encode": [
      "self",
      "batch_text_or_text_pairs",
      "max_seq_len",
      "pad_to_max_seq_len",
      "stride",
      "is_split_into_words",
      "truncation_strategy",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask"
    ],
    "truncate_sequences": [
      "self",
      "ids",
      "pair_ids",
      "token_offset_mapping",
      "token_pair_offset_mapping",
      "num_tokens_to_remove",
      "truncation_strategy",
      "stride"
    ],
    "pinyin_locs_map": [
      "self",
      "text"
    ],
    "get_pinyin_ids": [
      "self",
      "text",
      "text_pair",
      "offset_mapping"
    ]
  },
  "PinyinEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pinyin_ids"
    ]
  },
  "GlyphEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "FusionBertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "pinyin_ids",
      "token_type_ids",
      "position_ids"
    ]
  },
  "ChineseBertLMPredictionHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states",
      "masked_positions"
    ]
  },
  "ChineseBertPretrainingHeads": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "sequence_output",
      "pooled_output",
      "masked_positions"
    ]
  },
  "ChineseBertPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ChineseBertPretrainedModel": {
    "base_model_prefix": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "ChineseBertModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "pinyin_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "output_hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ]
  },
  "ChineseBertForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "pinyin_ids",
      "token_type_ids",
      "attention_mask"
    ]
  },
  "ChineseBertForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "pinyin_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "ChineseBertForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "pinyin_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "ChineseBertForPretraining": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "pinyin_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "masked_positions"
    ]
  },
  "ChineseBertPretrainingCriterion": {
    "__init__": [
      "self",
      "vocab_size"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "seq_relationship_score",
      "masked_lm_labels",
      "next_sentence_labels",
      "masked_lm_scale"
    ]
  },
  "CHINESEBERT_PRETRAINED_INIT_CONFIGURATION": [],
  "CHINESEBERT_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ChineseBertConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id",
      "pool_act",
      "layer_norm_eps",
      "glyph_embedding_dim",
      "pinyin_embedding_size",
      "pinyin_map_len"
    ]
  },
  "dont_transpose": [],
  "convert_pytorch_checkpoint_to_paddle": [
    "pytorch_checkpoint_path",
    "paddle_dump_path"
  ],
  "MT5_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "MT5LayerNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MT5DenseReluDense": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MT5DenseGatedGeluDense": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MT5DenseGatedSiluDense": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MT5LayerFF": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MT5Attention": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "_relative_position_bucket": [
      "relative_position",
      "bidirectional",
      "num_buckets",
      "max_distance"
    ],
    "compute_bias": [
      "self",
      "query_length",
      "key_length"
    ],
    "forward": [
      "self",
      "hidden_states",
      "mask",
      "key_value_states",
      "position_bias",
      "cache",
      "query_length",
      "use_cache",
      "output_attentions"
    ]
  },
  "MT5LayerSelfAttention": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias",
      "cache",
      "use_cache",
      "output_attentions"
    ]
  },
  "MT5LayerCrossAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "key_value_states",
      "attention_mask",
      "position_bias",
      "cache",
      "use_cache",
      "query_length",
      "output_attentions"
    ]
  },
  "MT5Block": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "encoder_decoder_position_bias",
      "cache",
      "use_cache",
      "output_attentions"
    ]
  },
  "MT5PretrainedModel": {
    "base_model_prefix": [],
    "config_class": [],
    "pretrained_init_configuration": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "dummy_inputs": [
      "self"
    ],
    "_init_weights": [
      "self",
      "layer"
    ],
    "_shift_right": [
      "self",
      "input_ids"
    ]
  },
  "MT5Stack": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "dtype": [
      "self"
    ],
    "recompute_training": [
      "self",
      "layer_module",
      "hidden_states",
      "extended_attention_mask",
      "position_bias",
      "encoder_hidden_states",
      "encoder_extended_attention_mask",
      "encoder_decoder_position_bias",
      "use_cache",
      "output_attentions"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "inputs_embeds",
      "cache",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_extended_attention_mask": [
      "self",
      "attention_mask",
      "input_shape"
    ],
    "invert_attention_mask": [
      "self",
      "encoder_attention_mask"
    ]
  },
  "MT5Model": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "cache",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MT5ForConditionalGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "cache",
      "labels",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_input_ids_for_generation": [
      "bos_token_id",
      "encoder_output"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "cache",
      "attention_mask",
      "use_cache",
      "encoder_output"
    ],
    "prepare_decoder_input_ids_from_labels": [
      "self",
      "labels"
    ],
    "expand_inputs_for_generation": [
      "input_ids",
      "expand_size",
      "attention_mask"
    ],
    "prepare_attention_mask_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "MT5EncoderModel": {
    "base_model_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "get_encoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "cache",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MT5_PRETRAINED_INIT_CONFIGURATION": [],
  "MT5Config": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "d_model",
      "d_kv",
      "d_ff",
      "num_layers",
      "num_decoder_layers",
      "num_heads",
      "relative_attention_num_buckets",
      "relative_attention_max_distance",
      "dropout_rate",
      "layer_norm_epsilon",
      "initializer_factor",
      "feed_forward_proj",
      "is_encoder_decoder",
      "use_cache",
      "bos_token_id",
      "pad_token_id",
      "eos_token_id"
    ]
  },
  "load_vocab": [
    "vocab_file"
  ],
  "_is_chinese_char": [
    "cp"
  ],
  "PegasusChineseTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "model_input_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "do_basic_tokenize",
      "never_split",
      "pad_token",
      "eos_token",
      "unk_token",
      "mask_token",
      "mask_token_sent",
      "additional_special_tokens",
      "sep_token",
      "cls_token",
      "tokenize_chinese_chars",
      "strip_accents",
      "offset"
    ],
    "do_lower_case": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "_cjk_punctuation": [],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "_special_token_mask": [
      "self",
      "seq"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ]
  },
  "PEGASUS_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "Cache": [],
  "StaticCache": [],
  "PegasusPretrainedModel": {
    "model_config_file": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "PegasusSinusoidalPositionalEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim"
    ],
    "_init_weight": [
      "out"
    ],
    "forward": [
      "self",
      "input_ids_shape",
      "past_key_values_length"
    ]
  },
  "PegasusEncoder": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "PegasusDecoder": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "memory_mask",
      "cache",
      "x",
      "mix_ratio"
    ]
  },
  "PegasusModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "use_cache",
      "cache"
    ]
  },
  "PegasusForConditionalGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "prepare_fast_entry": [
      "self",
      "kwargs"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "use_cache",
      "cache",
      "labels"
    ],
    "prepare_decoder_input_ids_from_labels": [
      "self",
      "labels"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "decoder_input_ids",
      "attention_mask",
      "decoder_attention_mask",
      "cache",
      "use_cache",
      "encoder_output"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "PEGASUS_PRETRAINED_INIT_CONFIGURATION": [],
  "PegasusConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "attribute_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "max_position_embeddings",
      "encoder_layers",
      "encoder_ffn_dim",
      "encoder_attention_heads",
      "decoder_layers",
      "decoder_ffn_dim",
      "decoder_attention_heads",
      "activation_function",
      "d_model",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "init_std",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "is_encoder_decoder",
      "decoder_start_token_id",
      "forced_eos_token_id",
      "scale_embedding",
      "use_cache",
      "encoder_layerdrop",
      "decoder_layerdrop"
    ]
  },
  "DistilBertTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "max_seq_len",
      "stride",
      "is_split_into_words",
      "pad_to_max_seq_len",
      "truncation_strategy",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask"
    ]
  },
  "DistilBertPretrainedModel": {
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "model_config_file": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "DistilBertModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "DistilBertForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "DistilBertForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "DistilBertForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "DistilBertForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "DISTILBERT_PRETRAINED_INIT_CONFIGURATION": [],
  "DISTILBERT_PRETRAINED_RESOURCE_FILES_MAP": [],
  "DistilBertConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "initializer_range",
      "pad_token_id",
      "pool_act",
      "fuse",
      "layer_norm_eps",
      "use_cache"
    ]
  },
  "GLMTokenizerMixin": {
    "sop_token": [
      "self"
    ],
    "sop_token_id": [
      "self"
    ],
    "eop_token": [
      "self"
    ],
    "eop_token_id": [
      "self"
    ],
    "gmask_token_id": [
      "self"
    ],
    "smask_token_id": [
      "self"
    ],
    "mask_token_ids": [
      "self"
    ],
    "_build_input_for_multiple_choice": [
      "self",
      "context",
      "choices"
    ],
    "_pad_batch": [
      "self",
      "tokens",
      "position_ids",
      "attention_mask",
      "max_seq_length"
    ],
    "_collate": [
      "self",
      "samples"
    ],
    "build_inputs_for_multiple_choice": [
      "self",
      "model_input",
      "choices",
      "max_length"
    ],
    "build_inputs_for_generation": [
      "self",
      "model_input",
      "max_gen_length",
      "targets",
      "padding",
      "is_train"
    ]
  },
  "GLMChineseTokenizer": {
    "model_input_names": [],
    "resource_files_names": [],
    "pretrained_init_configuration": [],
    "cog_model_link": [],
    "pretrained_resource_files_map": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "model_file",
      "cls_token",
      "sep_token",
      "unk_token",
      "mask_token",
      "pad_token",
      "eos_token",
      "additional_special_tokens"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ]
  },
  "GLMGPT2Tokenizer": {
    "model_input_names": [],
    "pretrained_init_configuration": [],
    "added_tokens_link": [],
    "pretrained_resource_files_map": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "cls_token",
      "sep_token",
      "unk_token",
      "mask_token",
      "pad_token",
      "eos_token"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ]
  },
  "GLMBertTokenizer": {
    "model_input_names": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "max_model_input_sizes": []
  },
  "GLMTokenizer": {
    "bert_model_names": [],
    "chinese_model_names": [],
    "gpt2_model_names": [],
    "tokenizer_config_file": [],
    "__init__": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "GLMAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "_transpose_for_scores": [
      "self",
      "inputs"
    ],
    "_core_attention": [
      "self",
      "hidden_states",
      "cache"
    ],
    "_core_parallel_attention": [
      "self",
      "hidden_states",
      "cache"
    ],
    "forward": [
      "self",
      "hidden_states",
      "ltor_mask",
      "cache"
    ]
  },
  "GPT2MLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GLMStack": {
    "__init__": [
      "self",
      "config"
    ],
    "recompute_training": [
      "self",
      "layer_module",
      "hidden_states",
      "ltor_mask",
      "cache"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "attention_mask",
      "cache",
      "return_dict"
    ],
    "update_memories": [
      "self",
      "hiddens",
      "cache"
    ]
  },
  "GLMPretrainedModel": {
    "base_model_prefix": [],
    "config_class": [],
    "model_config_file": [],
    "resource_files_names": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "GLMModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "cache",
      "return_dict"
    ]
  },
  "GLMForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "choice_ids",
      "choice_indices",
      "labels",
      "return_dict"
    ]
  },
  "GLMForConditionalGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "_reorder_cache": [
      "self",
      "cache",
      "beam_index"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "cache"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "labels",
      "cache",
      "return_dict",
      "loss_mask",
      "use_cache"
    ]
  },
  "GLM_PRETRAINED_INIT_CONFIGURATION": [],
  "GLM_PRETRAINED_RESOURCE_FILES_MAP": [],
  "GLMConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "num_layers",
      "vocab_size",
      "hidden_size",
      "num_attention_heads",
      "embedding_dropout_prob",
      "attention_dropout_prob",
      "output_dropout_prob",
      "max_sequence_length",
      "checkpoint_num_layers",
      "parallel_output",
      "relative_encoding",
      "block_position_encoding",
      "output_predict",
      "spell_length",
      "spell_func",
      "attention_scale",
      "initializer_range",
      "pool_token",
      "layernorm_epsilon",
      "use_scaled_init_for_output_weights"
    ]
  },
  "ChineseCLIPProcessor": {
    "attributes": [],
    "image_processor_class": [],
    "tokenizer_class": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "return_tensors"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "model_input_names": [
      "self"
    ],
    "feature_extractor_class": [
      "self"
    ],
    "feature_extractor": [
      "self"
    ]
  },
  "ChineseCLIPImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "size",
      "resample",
      "do_center_crop",
      "crop_size",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb"
    ],
    "resize": [
      "self",
      "image",
      "size",
      "resample",
      "data_format"
    ],
    "center_crop": [
      "self",
      "image",
      "size",
      "data_format"
    ],
    "rescale": [
      "self",
      "image",
      "scale",
      "data_format"
    ],
    "normalize": [
      "self",
      "image",
      "mean",
      "std",
      "data_format"
    ],
    "preprocess": [
      "self",
      "images",
      "do_resize",
      "size",
      "resample",
      "do_center_crop",
      "crop_size",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "return_tensors",
      "data_format"
    ]
  },
  "ChineseCLIPConverter": {
    "num_layer_key": [],
    "_ignore_state_dict_keys": [],
    "resolve_num_layer": [
      "self",
      "config_or_num_layers"
    ],
    "load_torch_weight_file": [
      "self",
      "model_file"
    ],
    "get_paddle_pytorch_model_classes": [
      "self"
    ],
    "get_name_mapping": [
      "self",
      "config_or_num_layers"
    ],
    "convert": [
      "self",
      "input_dir",
      "output_dir"
    ]
  },
  "ChineseCLIPTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "model_input_names": []
  },
  "CHINESE_CLIP_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "chinese_clip_loss": [
    "similarity"
  ],
  "ChineseCLIPVisionModelOutput": {},
  "ChineseCLIPTextModelOutput": {},
  "ChineseCLIPOutput": {
    "to_tuple": [
      "self"
    ]
  },
  "ChineseCLIPPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "gradient_checkpointing_enable": [
      "self"
    ],
    "gradient_checkpointing_disable": [
      "self"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "FirstTokenPooler": {
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ChineseCLIPTextModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ChineseCLIPVisionModel": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ChineseCLIPModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_text_features": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "return_loss",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ChineseCLIPTextModelWithProjection": {
    "config_class": [],
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ChineseCLIPVisionModelWithProjection": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ChineseCLIPFeatureExtractor": {
    "__init__": [
      "self"
    ]
  },
  "ChineseCLIPTextConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "projection_dim",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "initializer_factor",
      "layer_norm_eps",
      "pad_token_id",
      "pool_act",
      "fuse",
      "position_embedding_type",
      "use_cache"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "ChineseCLIPVisionConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "projection_dim",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "hidden_act",
      "layer_norm_eps",
      "dropout",
      "attention_dropout",
      "initializer_range",
      "initializer_factor"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "ChineseCLIPConfig": {
    "model_type": [],
    "is_composition": [],
    "__init__": [
      "self",
      "text_config",
      "vision_config",
      "projection_dim",
      "logit_scale_init_value"
    ],
    "from_text_vision_configs": [
      "cls",
      "text_config",
      "vision_config"
    ],
    "to_dict": [
      "self"
    ]
  },
  "ConvBertTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": []
  },
  "GroupedLinear": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "num_groups"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SeparableConv1D": {
    "__init__": [
      "self",
      "input_filters",
      "output_filters",
      "kernel_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MultiHeadAttentionWithConv": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "dropout",
      "kdim",
      "vdim",
      "need_weights",
      "conv_kernel_size",
      "head_ratio"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attn_mask",
      "cache"
    ]
  },
  "TransformerEncoderLayerWithConv": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "dim_feedforward",
      "dropout",
      "activation",
      "attn_dropout",
      "act_dropout",
      "normalize_before",
      "conv_kernel_size",
      "head_ratio",
      "num_groups"
    ]
  },
  "ConvBertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "ConvBertDiscriminatorPredictions": {
    "__init__": [
      "self",
      "hidden_size",
      "hidden_act"
    ],
    "forward": [
      "self",
      "discriminator_hidden_states"
    ]
  },
  "ConvBertGeneratorPredictions": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "generator_hidden_states"
    ]
  },
  "ConvBertPretrainedModel": {
    "base_model_prefix": [],
    "gen_weight": [],
    "disc_weight": [],
    "tie_word_embeddings": [],
    "untied_generator_embeddings": [],
    "use_softmax_sample": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "config_class": [],
    "tie_weights": [
      "self"
    ],
    "_init_weights": [
      "self",
      "layer"
    ],
    "_tie_or_clone_weights": [
      "self",
      "output_embeddings",
      "input_embeddings"
    ]
  },
  "ConvBertModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ConvBertDiscriminator": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds"
    ]
  },
  "ConvBertGenerator": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ConvBertClassificationHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "ConvBertForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ConvBertForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ConvBertForTotalPretraining": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "get_discriminator_inputs": [
      "self",
      "inputs",
      "raw_inputs",
      "generator_logits",
      "generator_labels",
      "use_softmax_sample"
    ],
    "sample_from_softmax": [
      "self",
      "logits",
      "use_softmax_sample"
    ],
    "update_inputs": [
      "self",
      "sequence",
      "updates",
      "positions"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "raw_input_ids",
      "generator_labels"
    ]
  },
  "ConvBertPretrainingCriterion": {
    "__init__": [
      "self",
      "vocab_size",
      "gen_weight",
      "disc_weight"
    ],
    "forward": [
      "self",
      "generator_prediction_scores",
      "discriminator_prediction_scores",
      "generator_labels",
      "discriminator_labels",
      "attention_mask"
    ]
  },
  "ConvBertPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ConvBertForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ConvBertForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ConvBertForMaskedLM": [],
  "ConvBertForPretraining": [],
  "CONVBERT_PRETRAINED_INIT_CONFIGURATION": [],
  "CONVBERT_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ConvBertConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "pool_act",
      "embedding_size",
      "conv_kernel_size",
      "head_ratio",
      "num_groups"
    ]
  },
  "CLIPProcessor": {
    "attributes": [],
    "image_processor_class": [],
    "tokenizer_class": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "return_tensors"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "model_input_names": [
      "self"
    ],
    "feature_extractor_class": [
      "self"
    ],
    "feature_extractor": [
      "self"
    ]
  },
  "CLIPImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "size",
      "resample",
      "do_center_crop",
      "crop_size",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb"
    ],
    "resize": [
      "self",
      "image",
      "size",
      "resample",
      "data_format"
    ],
    "center_crop": [
      "self",
      "image",
      "size",
      "data_format"
    ],
    "rescale": [
      "self",
      "image",
      "scale",
      "data_format"
    ],
    "normalize": [
      "self",
      "image",
      "mean",
      "std",
      "data_format"
    ],
    "preprocess": [
      "self",
      "images",
      "do_resize",
      "size",
      "resample",
      "do_center_crop",
      "crop_size",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "return_tensors",
      "data_format"
    ]
  },
  "whitespace_clean": [
    "text",
    "re"
  ],
  "CLIPTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "model_input_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "max_len",
      "bos_token",
      "eos_token",
      "unk_token",
      "pad_token"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ]
  },
  "CLIP_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "NEG_INF": [],
  "clip_loss": [
    "similarity"
  ],
  "CLIPVisionModelOutput": {},
  "CLIPTextModelOutput": {},
  "CLIPOutput": {
    "to_tuple": [
      "self"
    ]
  },
  "ModifiedResNet": {
    "__init__": [
      "self",
      "layers",
      "output_dim",
      "heads",
      "input_resolution",
      "width"
    ],
    "_make_layer": [
      "self",
      "planes",
      "blocks",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "multi_head_attention_forward": [
    "x",
    "num_heads",
    "q_proj",
    "k_proj",
    "v_proj",
    "c_proj",
    "attn_mask"
  ],
  "Identity": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Bottleneck": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AttentionPool2d": {
    "__init__": [
      "self",
      "spacial_dim",
      "embed_dim",
      "num_heads",
      "output_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CLIPPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "gradient_checkpointing_enable": [
      "self"
    ],
    "gradient_checkpointing_disable": [
      "self"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "CLIPTextTransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CLIPTextModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CLIPVisionTransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "forward_pre": [
      "self",
      "x"
    ],
    "forward_post": [
      "self",
      "x"
    ]
  },
  "CLIPVisionModel": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CLIPModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_text_features": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "attention_mask",
      "position_ids",
      "return_loss",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CLIPTextModelWithProjection": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CLIPVisionModelWithProjection": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CLIPFeatureExtractor": {
    "__init__": [
      "self"
    ]
  },
  "Old2NewPretrainedConfig": {
    "old_config_dict": [],
    "text_name_mapping": [],
    "vision_name_mapping": [],
    "from_dict": [
      "cls",
      "config_dict"
    ]
  },
  "CLIPTextConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "projection_dim",
      "num_hidden_layers",
      "num_attention_heads",
      "max_position_embeddings",
      "hidden_act",
      "layer_norm_eps",
      "dropout",
      "attention_dropout",
      "initializer_range",
      "initializer_factor",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "CLIPVisionConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "projection_dim",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "hidden_act",
      "layer_norm_eps",
      "dropout",
      "attention_dropout",
      "initializer_range",
      "initializer_factor"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "CLIPConfig": {
    "model_type": [],
    "is_composition": [],
    "__init__": [
      "self",
      "text_config",
      "vision_config",
      "projection_dim",
      "logit_scale_init_value"
    ],
    "from_text_vision_configs": [
      "cls",
      "text_config",
      "vision_config"
    ],
    "to_dict": [
      "self"
    ]
  },
  "RobertaConverter": {
    "_ignore_state_dict_keys": [],
    "get_paddle_pytorch_model_classes": [
      "self"
    ],
    "get_name_mapping": [
      "self",
      "config_or_num_layers"
    ]
  },
  "RobertaChineseTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "do_basic_tokenize",
      "never_split",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ]
  },
  "RobertaBPETokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "bos_token",
      "eos_token",
      "sep_token",
      "cls_token",
      "unk_token",
      "pad_token",
      "mask_token",
      "add_prefix_space"
    ],
    "get_vocab": [
      "self"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_offset_mapping": [
      "self",
      "text"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "prepare_for_tokenization": [
      "self",
      "text",
      "is_split_into_words"
    ]
  },
  "RobertaTokenizer": {
    "chinese_model_names": [],
    "english_model_names": [],
    "tokenizer_config_file": [],
    "__init__": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "RobertaEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ],
    "create_position_ids_from_inputs_embeds": [
      "self",
      "inputs_embeds"
    ]
  },
  "RobertaPooler": {
    "__init__": [
      "self",
      "hidden_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "RobertaPretrainedModel": {
    "pretrained_init_configuration": [],
    "config_class": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "RobertaModel": {
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "RobertaForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "RobertaClassificationHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "RobertaForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "RobertaForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "RobertaForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "RobertaForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "RobertaLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "RobertaForCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "past_key_values",
      "use_cache",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past",
      "attention_mask"
    ],
    "_reorder_cache": [
      "self",
      "past",
      "beam_idx"
    ]
  },
  "PRETRAINED_INIT_CONFIGURATION": [],
  "RobertaConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id",
      "layer_norm_eps",
      "cls_token_id"
    ]
  },
  "BpeEncoder": {
    "__init__": [
      "self",
      "encoder_json_file",
      "vocab_bpe_file",
      "errors",
      "unk_token"
    ],
    "__get_encoder": [
      "self",
      "encoder_json_file"
    ],
    "__get_bpe_ranks": [
      "self",
      "vocab_bpe_file"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "tokens"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ]
  },
  "SkepTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "max_model_input_sizes": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_file",
      "bpe_vocab_file",
      "bpe_json_file",
      "do_lower_case",
      "use_bpe_encoder",
      "need_token_type_id",
      "add_two_sep_token_inter",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "get_vocab": [
      "self"
    ]
  },
  "SkepEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ]
  },
  "SkepPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SkepPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "SkepModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "past_key_values",
      "use_cache",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "embedding"
    ]
  },
  "SkepForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "labels",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "SkepForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "labels",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "SkepCrfForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "seq_lens",
      "labels",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "SKEP_PRETRAINED_INIT_CONFIGURATION": [],
  "SKEP_PRETRAINED_RESOURCE_FILES_MAP": [],
  "SkepConfig": {
    "pretrained_init_configuration": [],
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id"
    ]
  },
  "ChatGLMTokenizer": {
    "resource_files_names": [],
    "max_model_input_sizes": [],
    "model_input_names": [],
    "pretrained_resource_files_map": [],
    "__init__": [
      "self",
      "vocab_file",
      "unk_token",
      "bos_token",
      "eos_token",
      "end_token",
      "mask_token",
      "gmask_token",
      "pad_token",
      "padding_side",
      "do_lower_case",
      "num_image_tokens"
    ],
    "gmask_token_id": [
      "self"
    ],
    "end_token_id": [
      "self"
    ],
    "tab_token": [
      "self"
    ],
    "get_blank_token": [
      "length"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "prepare_for_tokenization": [
      "self",
      "text",
      "is_split_into_words"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces",
      "spaces_between_special_tokens"
    ],
    "postprocess": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ]
  },
  "PrefixEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "prefix"
    ]
  },
  "RotaryEmbeddings": {
    "__init__": [
      "self",
      "hidden_size",
      "base",
      "position_encoding_2d"
    ],
    "get_rotary_embeds": [
      "self",
      "cos",
      "sin",
      "position_ids"
    ],
    "forward": [
      "self",
      "position_ids"
    ]
  },
  "ChatGLMAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "_rotate_half": [
      "self",
      "x"
    ],
    "_apply_rotary_position_embed_index": [
      "self",
      "q",
      "k",
      "cos",
      "sin"
    ],
    "_core_attention": [
      "self",
      "q_layer",
      "k_layer",
      "position_ids",
      "rotary_embeds"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "use_cache",
      "cache",
      "layer_id",
      "rotary_embeds"
    ]
  },
  "ChatGLMBlock": {
    "__init__": [
      "self",
      "config",
      "layer_id"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "use_cache",
      "cache",
      "rotary_embeds"
    ]
  },
  "ChatGLMMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "geglu": [
      "self",
      "x"
    ],
    "gelu": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ChatGLMStack": {
    "__init__": [
      "self",
      "config"
    ],
    "get_prompt": [
      "self",
      "batch_size",
      "dtype"
    ],
    "recompute_training": [
      "self",
      "layer_module",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "use_cache",
      "cache",
      "rotary_embeds"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "cache",
      "use_cache"
    ]
  },
  "ChatGLMPretrainedModel": {
    "base_model_prefix": [],
    "config_class": [],
    "model_config_file": [],
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "init_weights": [
      "self",
      "layer"
    ],
    "get_position_ids": [
      "self",
      "input_ids",
      "mask_positions",
      "use_gmasks"
    ],
    "_get_model_inputs_spec": [
      "self",
      "dtype"
    ],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ]
  },
  "ChatGLMModel": {
    "_keys_to_ignore_on_load_unexpected": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "cache",
      "inputs_embeds",
      "use_cache",
      "return_dict"
    ]
  },
  "ChatGLMHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ChatGLMForCausalLM": {
    "_keys_to_ignore_on_save": [],
    "_tied_weights_keys": [],
    "__init__": [
      "self",
      "config"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "past_key_values",
      "cache"
    ],
    "reorder_cache": [
      "self",
      "cache",
      "beam_idx"
    ],
    "update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder",
      "standardize_cache_format"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "cache",
      "inputs_embeds",
      "labels",
      "use_cache",
      "return_dict"
    ],
    "_reorder_cache": [
      "cache",
      "beam_idx"
    ],
    "process_response": [
      "response"
    ]
  },
  "CHATGLM_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ChatGLMConfig": {
    "model_type": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "layernorm_epsilon",
      "use_cache",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "mask_token_id",
      "gmask_token_id",
      "max_sequence_length",
      "inner_hidden_size",
      "position_encoding_2d",
      "quantization_bit",
      "pre_seq_len",
      "prefix_projection",
      "output_predict",
      "attention_scale",
      "activation",
      "num_image_tokens",
      "use_flash_attention",
      "long_sequence_strategy_type",
      "long_sequence_strategy_name",
      "long_sequence_init_args",
      "use_long_sequence_strategies"
    ]
  },
  "FunnelTokenizer": {
    "cls_token_type_id": [],
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "bos_token",
      "eos_token",
      "do_basic_tokenize",
      "never_split",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ]
  },
  "FUNNEL_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "INF": [],
  "expand": [
    "self"
  ],
  "repeat_interleave": [
    "x",
    "repeats",
    "dim"
  ],
  "gather": [
    "x",
    "dim",
    "index"
  ],
  "split": [
    "x",
    "batch_size",
    "dim"
  ],
  "normal_": [
    "x",
    "m",
    "std"
  ],
  "uniform_": [
    "x",
    "a",
    "b"
  ],
  "constant_": [
    "x",
    "val"
  ],
  "FunnelEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds"
    ]
  },
  "FunnelAttentionStructure": {
    "__init__": [
      "self",
      "config"
    ],
    "init_attention_inputs": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "token_type_ids"
    ],
    "token_type_ids_to_mat": [
      "self",
      "token_type_ids"
    ],
    "get_position_embeds": [
      "self",
      "seq_len",
      "dtype"
    ],
    "stride_pool_pos": [
      "self",
      "pos_id",
      "block_index"
    ],
    "relative_pos": [
      "self",
      "pos",
      "stride",
      "pooled_pos",
      "shift"
    ],
    "stride_pool": [
      "self",
      "tensor",
      "axis"
    ],
    "pool_tensor": [
      "self",
      "tensor",
      "mode",
      "stride"
    ],
    "pre_attention_pooling": [
      "self",
      "output",
      "attention_inputs"
    ],
    "post_attention_pooling": [
      "self",
      "attention_inputs"
    ]
  },
  "_relative_shift_gather": [
    "positional_attn",
    "context_len",
    "shift"
  ],
  "FunnelRelMultiheadAttention": {
    "__init__": [
      "self",
      "config",
      "block_index"
    ],
    "relative_positional_attention": [
      "self",
      "position_embeds",
      "q_head",
      "context_len",
      "cls_mask"
    ],
    "relative_token_type_attention": [
      "self",
      "token_type_mat",
      "q_head",
      "cls_mask"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attention_inputs",
      "output_attentions"
    ]
  },
  "FunnelPositionwiseFFN": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden"
    ]
  },
  "FunnelLayer": {
    "__init__": [
      "self",
      "config",
      "block_index"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attention_inputs",
      "output_attentions"
    ]
  },
  "FunnelEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "token_type_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "upsample": [
    "x",
    "stride",
    "target_len",
    "separate_cls",
    "truncate_seq"
  ],
  "FunnelDecoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "final_hidden",
      "first_block_hidden",
      "attention_mask",
      "token_type_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FunnelDiscriminatorPredictions": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "discriminator_hidden_states"
    ]
  },
  "FunnelPreTrainedModel": {
    "pretrained_init_configuration": [],
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "config_class": [],
    "base_model_prefix": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "init_weights": [
      "self"
    ],
    "prune_heads": [
      "self",
      "heads_to_prune"
    ]
  },
  "FunnelClassificationHead": {
    "__init__": [
      "self",
      "config",
      "n_labels"
    ],
    "forward": [
      "self",
      "hidden"
    ]
  },
  "FunnelBaseModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FunnelModel": {
    "base_model_prefix": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FunnelForPreTraining": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FunnelForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FunnelForSequenceClassification": {
    "base_model_class": [],
    "__init__": [
      "self",
      "config",
      "num_classes"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FunnelForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FunnelForTokenClassification": {
    "__init__": [
      "self",
      "config",
      "num_classes"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FunnelForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "FunnelForPreTrainingOutput": {
    "loss": [],
    "logits": [],
    "hidden_states": [],
    "attentions": [],
    "__init__": [
      "self"
    ]
  },
  "FUNNEL_PRETRAINED_INIT_CONFIGURATION": [],
  "FUNNEL_PRETRAINED_RESOURCE_FILES_MAP": [],
  "FUNNEL_RESOURCE_FILES_NAMES": [],
  "FunnelConfig": {
    "model_type": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "block_sizes",
      "block_repeats",
      "num_decoder_layers",
      "d_model",
      "n_head",
      "d_head",
      "d_inner",
      "hidden_act",
      "hidden_dropout",
      "attention_dropout",
      "activation_dropout",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "initializer_std",
      "layer_norm_eps",
      "pooling_type",
      "attention_type",
      "separate_cls",
      "truncate_seq",
      "pool_q_only"
    ],
    "num_hidden_layers": [
      "self"
    ],
    "num_blocks": [
      "self"
    ]
  },
  "PRETRAINED_RESOURCE_FILES_MAP": [],
  "split_tokenizer_json_file": [
    "tokenizer_file"
  ],
  "BloomTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "max_model_input_sizes": [],
    "padding_side": [],
    "model_input_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "max_len",
      "unk_token",
      "bos_token",
      "eos_token",
      "pad_token",
      "eol_token",
      "add_prefix_space",
      "add_bos_token"
    ],
    "vocab_size": [
      "self"
    ],
    "eol_token_id": [
      "self"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_ids_to_string": [
      "self",
      "ids"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "get_vocab": [
      "self"
    ],
    "prepare_for_tokenization": [
      "self",
      "text",
      "is_split_into_words"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ]
  },
  "LogitsProcessorList": {
    "__call__": [
      "self",
      "input_ids",
      "logits"
    ]
  },
  "LogitsProcessor": {
    "__call__": [
      "self",
      "input_ids",
      "logits"
    ]
  },
  "MinLengthLogitsProcessor": {
    "__init__": [
      "self",
      "min_length",
      "eos_token_id"
    ],
    "__call__": [
      "self",
      "input_ids",
      "logits"
    ]
  },
  "RepetitionPenaltyLogitsProcessor": {
    "__init__": [
      "self",
      "penalty"
    ],
    "__call__": [
      "self",
      "input_ids",
      "logits"
    ]
  },
  "HammingDiversityLogitsProcessor": {
    "__init__": [
      "self",
      "diversity_rate",
      "num_beams",
      "num_beam_groups"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores",
      "current_tokens",
      "beam_group_idx"
    ]
  },
  "ForcedBOSTokenLogitsProcessor": {
    "__init__": [
      "self",
      "forced_bos_token_id"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "ForcedEOSTokenLogitsProcessor": {
    "__init__": [
      "self",
      "max_length",
      "forced_eos_token_id"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "split_tensor_along_last_dim": [
    "tensor",
    "num_partitions",
    "contiguous_split_chunks"
  ],
  "build_alibi_tensor": [
    "attention_mask",
    "num_heads",
    "dtype"
  ],
  "dropout_add": [
    "x",
    "residual",
    "prob",
    "training"
  ],
  "pre_process_alibi_for_pad": [
    "alibi",
    "attention_mask",
    "num_heads"
  ],
  "bloom_gelu_forward": [
    "x"
  ],
  "bloom_gelu_back": [
    "g",
    "x"
  ],
  "baddbmm": [
    "input",
    "batch1",
    "batch2",
    "beta",
    "alpha"
  ],
  "GeLUFunction": {
    "forward": [
      "ctx",
      "input"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "BloomGelu": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BloomAttention": {
    "__init__": [
      "self",
      "config",
      "layer_number"
    ],
    "_split_heads": [
      "self",
      "fused_qkv"
    ],
    "_merge_heads": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual",
      "alibi",
      "attention_mask",
      "layer_past",
      "head_mask",
      "use_cache",
      "output_attentions"
    ]
  },
  "BloomMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "BloomBlock": {
    "__init__": [
      "self",
      "config",
      "layer_number"
    ],
    "forward": [
      "self",
      "hidden_states",
      "layer_past",
      "attention_mask",
      "head_mask",
      "use_cache",
      "output_attentions",
      "alibi"
    ]
  },
  "BloomPreTrainedModel": {
    "_keys_to_ignore_on_load_missing": [],
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ],
    "_init_weights": [
      "self",
      "layer"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "_convert_to_bloom_cache": [
      "past_key_value"
    ],
    "_convert_to_standard_cache": [
      "past_key_value",
      "batch_size"
    ],
    "_convert_head_mask_to_5d": [
      "self",
      "head_mask",
      "num_hidden_layers"
    ],
    "get_head_mask": [
      "self",
      "head_mask",
      "num_hidden_layers",
      "is_attention_chunked"
    ],
    "_get_name_mappings": [
      "cls",
      "config"
    ]
  },
  "BloomModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "_prepare_attn_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "past_key_values_length",
      "num_heads"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "recompute_training": [
      "self",
      "block",
      "hidden_states",
      "layer_past",
      "attention_mask",
      "head_mask",
      "use_cache",
      "output_attentions",
      "alibi"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BloomLMHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states",
      "parallel_output"
    ]
  },
  "BloomPretrainingCriterion": {
    "__init__": [
      "self",
      "ignore_index",
      "tensor_parallel_degree",
      "tensor_parallel_output"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "masked_lm_labels",
      "loss_mask"
    ]
  },
  "BloomForPretraining": {
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "labels",
      "loss_mask",
      "attention_mask",
      "use_cache",
      "cache"
    ]
  },
  "BloomForCausalLM": {
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_save": [],
    "_tied_weights_keys": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "update_model_kwargs_for_generation": [
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "use_cache",
      "cache"
    ],
    "prepare_attention_mask_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "forward": [
      "self",
      "input_ids",
      "cache",
      "attention_mask",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_reorder_cache": [
      "past",
      "beam_idx"
    ]
  },
  "BloomForSequenceClassification": {
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BloomForTokenClassification": {
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BloomForGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "prepare_input_ids_for_generation": [
      "self",
      "bos_token_id",
      "encoder_output"
    ],
    "prepare_attention_mask_for_generation": [
      "self",
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "update_scores_for_generation": [
      "self",
      "scores",
      "next_scores",
      "length",
      "unfinished_flag"
    ],
    "get_logits_processor": [
      "self",
      "min_length",
      "max_length",
      "eos_token_id",
      "forced_bos_token_id",
      "forced_eos_token_id",
      "num_beams",
      "num_beam_groups",
      "diversity_rate",
      "repetition_penalty"
    ],
    "expand_inputs_for_generation": [
      "self",
      "input_ids",
      "expand_size",
      "attention_mask"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "use_cache",
      "cache"
    ],
    "update_model_kwargs_for_generation": [
      "self",
      "next_tokens",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "sample": [
      "self",
      "input_ids",
      "logits_processors",
      "max_length",
      "pad_token_id",
      "eos_token_id",
      "top_k",
      "top_p",
      "temperature",
      "min_tokens_to_keep"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "_construct_resource_file_url": [
    "model_names",
    "file_name"
  ],
  "BLOOM_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "BLOOM_PRETRAINED_INIT_CONFIGURATION": [],
  "BLOOM_PRETRAINED_RESOURCE_FILES_MAP": [],
  "BloomConfig": {
    "model_type": [],
    "attribute_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "n_layer",
      "n_head",
      "masked_softmax_fusion",
      "layer_norm_epsilon",
      "initializer_range",
      "use_cache",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "apply_residual_connection_post_layernorm",
      "hidden_dropout",
      "attention_dropout",
      "attention_softmax_in_fp32",
      "pretraining_tp",
      "slow_but_exact",
      "use_recompute",
      "use_pure_fp16",
      "use_flash_attention",
      "long_sequence_strategy_type",
      "long_sequence_strategy_name",
      "long_sequence_init_args",
      "use_long_sequence_strategies"
    ]
  },
  "ErnieTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ],
    "extend_chinese_char": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ]
  },
  "ErnieTinyTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_file",
      "sentencepiece_model_file",
      "word_dict",
      "do_lower_case",
      "encoding",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ],
    "cut": [
      "self",
      "chars"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "get_vocab": [
      "self"
    ]
  },
  "ErnieEmbeddings": {
    "__init__": [
      "self",
      "config",
      "weight_attr"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "task_type_ids",
      "inputs_embeds",
      "past_key_values_length"
    ]
  },
  "ErniePooler": {
    "__init__": [
      "self",
      "config",
      "weight_attr"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErniePretrainedModel": {
    "model_config_file": [],
    "config_class": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "ErnieModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "task_type_ids",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieLMPredictionHead": {
    "__init__": [
      "self",
      "config",
      "weight_attr"
    ],
    "forward": [
      "self",
      "hidden_states",
      "masked_positions"
    ]
  },
  "ErniePretrainingHeads": {
    "__init__": [
      "self",
      "config",
      "weight_attr"
    ],
    "forward": [
      "self",
      "sequence_output",
      "pooled_output",
      "masked_positions"
    ]
  },
  "ErnieForPreTrainingOutput": {},
  "ErnieForPretraining": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "masked_positions",
      "inputs_embeds",
      "labels",
      "next_sentence_label",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErniePretrainingCriterion": {
    "__init__": [
      "self",
      "with_nsp_loss"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "seq_relationship_score",
      "masked_lm_labels",
      "next_sentence_labels"
    ]
  },
  "ErnieOnlyMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output",
      "masked_positions"
    ]
  },
  "ErnieForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "masked_positions",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "UIE": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "return_dict"
    ]
  },
  "UTC": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "omask_positions",
      "cls_positions",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieFastTokenizer": {
    "resource_files_names": [],
    "slow_tokenizer_class": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "tokenizer_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ]
  },
  "ERNIE_PRETRAINED_INIT_CONFIGURATION": [],
  "ERNIE_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ErnieConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "task_id",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "task_type_vocab_size",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id",
      "pool_act",
      "fuse",
      "layer_norm_eps",
      "use_cache",
      "use_task_id"
    ]
  },
  "RWTokenizer": {
    "resource_files_names": [],
    "model_input_names": [],
    "pretrained_resource_files_map": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file"
    ],
    "decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ]
  },
  "DecoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "alibi",
      "attention_mask",
      "layer_past",
      "head_mask",
      "use_cache",
      "output_attentions",
      "i"
    ]
  },
  "RWPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "__init__": [
      "self"
    ],
    "_init_weights": [
      "self",
      "layer"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "_convert_to_standard_cache": [
      "past_key_value",
      "batch_size"
    ],
    "_convert_to_rw_cache": [
      "past_key_value"
    ]
  },
  "RWModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "_prepare_attn_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "past_key_values_length"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "_convert_head_mask_to_5d": [
      "self",
      "head_mask",
      "num_hidden_layers"
    ],
    "get_head_mask": [
      "self",
      "head_mask",
      "num_hidden_layers",
      "is_attention_chunked"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "head_mask",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "CausalLMHead": {
    "forward": [
      "self",
      "input"
    ]
  },
  "RWForCausalLM": {
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "prepare_attention_mask_for_generation": [
      "self",
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past",
      "attention_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "head_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_reorder_cache": [
      "past",
      "beam_idx"
    ]
  },
  "RW_PRETRAINED_INIT_CONFIGURATION": [],
  "RWConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "attribute_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "n_layer",
      "n_head",
      "layer_norm_epsilon",
      "initializer_range",
      "bos_token_id",
      "eos_token_id",
      "apply_residual_connection_post_layernorm",
      "hidden_dropout",
      "attention_dropout",
      "multi_query",
      "n_head_kv",
      "bias",
      "alibi",
      "parallel_attn"
    ],
    "head_dim": [
      "self"
    ],
    "rotary": [
      "self"
    ]
  },
  "BigBirdTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "sentencepiece_model_file",
      "do_lower_case",
      "remove_space",
      "keep_accents",
      "eos_token",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "extra_ids",
      "additional_special_tokens",
      "sp_model_kwargs",
      "encoding"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "max_length",
      "stride",
      "is_split_into_words",
      "padding",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask"
    ],
    "vocab_size": [
      "self"
    ],
    "_add_eos_if_not_present": [
      "self",
      "token_ids"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "_encode": [
      "self",
      "text",
      "max_seq_len",
      "max_pred_len",
      "masked_lm_prob"
    ]
  },
  "BIG_BIRD_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "BigBirdEncoderLayerOutput": {},
  "TransformerEncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "src",
      "src_mask",
      "rand_mask_idx",
      "query_mask",
      "key_mask"
    ]
  },
  "BigBirdEncoderOutput": {},
  "TransformerEncoder": {
    "__init__": [
      "self",
      "encoder_layer",
      "num_layers"
    ],
    "forward": [
      "self",
      "src",
      "src_mask_list",
      "rand_mask_idx_list",
      "query_mask",
      "key_mask",
      "output_hidden_states",
      "output_attentions"
    ]
  },
  "BigBirdPooler": {
    "__init__": [
      "self",
      "hidden_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BigBirdEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "BigBirdPretrainedModel": {
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "model_config_file": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "BigBirdModel": {
    "__init__": [
      "self",
      "config"
    ],
    "_process_mask": [
      "self",
      "input_ids",
      "inputs_embeds",
      "attention_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "rand_mask_idx_list",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ]
  },
  "BigBirdForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "rand_mask_idx_list",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "BigBirdLMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "masked_positions"
    ]
  },
  "BigBirdPretrainingHeads": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output",
      "pooled_output",
      "masked_positions"
    ]
  },
  "BigBirdForPreTrainingOutput": {},
  "BigBirdForPretraining": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "rand_mask_idx_list",
      "masked_positions",
      "attention_mask",
      "rand_mask",
      "inputs_embeds",
      "labels",
      "next_sentence_label",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "BigBirdPretrainingCriterion": {
    "__init__": [
      "self",
      "config",
      "use_nsp",
      "ignore_index"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "seq_relationship_score",
      "masked_lm_labels",
      "next_sentence_labels",
      "masked_lm_scale",
      "masked_lm_weights"
    ]
  },
  "BigBirdIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BigBirdOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "BigBirdForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "start_positions",
      "end_positions",
      "rand_mask_idx_list",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ],
    "prepare_question_mask": [
      "q_lengths",
      "maxlen"
    ]
  },
  "BigBirdForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "rand_mask_idx_list",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "BigBirdForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "rand_mask_idx_list",
      "token_type_ids",
      "labels",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "BigBirdForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "rand_mask_idx_list",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "BigBirdForCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "rand_mask_idx_list",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "BIGBIRD_PRETRAINED_INIT_CONFIGURATION": [],
  "BIGBIRD_PRETRAINED_RESOURCE_FILES_MAP": [],
  "BigBirdConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "sep_token_id",
      "attention_type",
      "use_bias",
      "rescale_embeddings",
      "block_size",
      "num_random_blocks",
      "dropout",
      "padding_idx",
      "attn_dropout",
      "act_dropout",
      "normalize_before",
      "weight_attr",
      "bias_attr",
      "window_size",
      "num_global_blocks",
      "num_rand_blocks",
      "seed",
      "activation",
      "embedding_weights"
    ]
  },
  "NystromformerTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "do_basic_tokenize",
      "never_split",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ]
  },
  "NystromformerEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "NystromformerSelfAttention": {
    "__init__": [
      "self",
      "config",
      "position_embedding_type"
    ],
    "iterative_inv": [
      "self",
      "mat",
      "n_iter"
    ],
    "transpose_for_scores": [
      "self",
      "layer"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions"
    ]
  },
  "NystromformerSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "NystromformerAttention": {
    "__init__": [
      "self",
      "config",
      "position_embedding_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions"
    ]
  },
  "NystromformerIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "NystromformerOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "NystromformerLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "apply_chunking_to_forward": [
      "self",
      "forward_fn",
      "chunk_size",
      "chunk_dim"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions"
    ]
  },
  "NystromformerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "NystromformerPredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "NystromformerLMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "NystromformerOnlyMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output"
    ]
  },
  "NystromformerPretrainedModel": {
    "model_config_file": [],
    "config_class": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "support_recompute": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_init_weights": [
      "self",
      "layer"
    ],
    "_set_recompute": [
      "self",
      "module",
      "value"
    ]
  },
  "NystromformerModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_extended_attention_mask": [
      "self",
      "attention_mask",
      "input_shape"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "NystromformerForMaskedLM": {
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "NystromformerClassificationHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "NystromformerForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "NystromformerForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "NystromformerForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "NystromformerForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "NystromformerFastTokenizer": {
    "resource_files_names": [],
    "slow_tokenizer_class": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "tokenizer_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ]
  },
  "NYSTROMFORMER_PRETRAINED_INIT_CONFIGURATION": [],
  "NYSTROMFORMER_PRETRAINED_RESOURCE_FILES_MAP": [],
  "NystromformerConfig": {
    "pretrained_init_configuration": [],
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "segment_means_seq_len",
      "num_landmarks",
      "conv_kernel_size",
      "inv_coeff_init_option",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id"
    ]
  },
  "create_trie": [
    "unique_no_split_tokens"
  ],
  "ProphetNetTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "do_basic_tokenize",
      "unk_token",
      "sep_token",
      "bos_token",
      "eos_token",
      "cls_token",
      "x_sep_token",
      "pad_token",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_tokenize_function": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "convert_ids_to_string": [
      "self",
      "ids"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "save_vocabulary": [
      "self",
      "save_directory"
    ]
  },
  "ngram_attention_bias": [
    "sequence_length",
    "ngram",
    "dtype"
  ],
  "compute_relative_buckets": [
    "num_buckets",
    "max_distance",
    "relative_positions",
    "is_bidirectional"
  ],
  "compute_all_stream_relative_buckets": [
    "num_buckets",
    "max_distance",
    "position_ids"
  ],
  "ProphetNetPretrainedModel": {
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ],
    "_shift_right": [
      "self",
      "input_ids"
    ]
  },
  "ProphetNetPositionalEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "inputs_shape",
      "attention_mask",
      "past_key_values",
      "position_ids"
    ],
    "_forward": [
      "self",
      "position_ids"
    ]
  },
  "ProphetNetAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "attention_dropout",
      "dropout",
      "num_attn_heads"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states",
      "key_value_states",
      "attention_mask",
      "past_key_value"
    ]
  },
  "ProphetNetFeedForward": {
    "__init__": [
      "self",
      "hidden_size",
      "activation_function",
      "activation_dropout",
      "dropout",
      "ffn_dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ProphetNetNgramSelfAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_buckets",
      "relative_max_distance",
      "num_decoder_attention_heads",
      "dropout",
      "attention_dropout",
      "ngram"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "batch_size"
    ],
    "forward": [
      "self",
      "hidden_states",
      "past_key_value",
      "attention_mask",
      "extended_predict_attention_mask",
      "main_relative_position_buckets",
      "predict_relative_position_buckets",
      "position_ids"
    ],
    "get_main_relative_pos_embeddings": [
      "self",
      "hidden_states",
      "attn_weights",
      "position_ids",
      "main_relative_position_buckets"
    ],
    "get_predict_relative_pos_embeddings": [
      "self",
      "hidden_states",
      "attn_weights",
      "position_ids",
      "predict_relative_position_buckets"
    ]
  },
  "ProphetNetEncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "ProphetNetDecoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attn_mask",
      "extended_predict_attention_mask",
      "main_relative_position_buckets",
      "predict_relative_position_buckets",
      "position_ids",
      "past_key_value",
      "use_cache"
    ]
  },
  "ProphetNetEncoder": {
    "__init__": [
      "self",
      "word_embeddings",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "ProphetNetDecoder": {
    "__init__": [
      "self",
      "word_embeddings",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache"
    ],
    "compute_buffered_relative_buckets": [
      "self",
      "position_ids"
    ],
    "prepare_attention_mask": [
      "self",
      "hidden_states",
      "attention_mask"
    ],
    "prepare_predict_attention_mask": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "ProphetNetModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "use_cache",
      "past_key_values"
    ]
  },
  "Linear_wo_bias": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "weight_attr",
      "name"
    ],
    "forward": [
      "self",
      "input"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "ProphetNetForConditionalGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "labels",
      "use_cache",
      "past_key_values"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "decoder_input_ids",
      "attention_mask",
      "decoder_attention_mask",
      "cache",
      "use_cache",
      "encoder_output"
    ],
    "prepare_decoder_input_ids_from_labels": [
      "self",
      "labels"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "PROPHETNET_PRETRAINED_INIT_CONFIGURATION": [],
  "PROPHETNET_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ProphetNetConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "bos_token_id",
      "pad_token_id",
      "eos_token_id",
      "hidden_size",
      "decoder_start_token_id",
      "max_position_embeddings",
      "activation_function",
      "activation_dropout",
      "dropout",
      "relative_max_distance",
      "ngram",
      "num_buckets",
      "encoder_ffn_dim",
      "num_encoder_attention_heads",
      "num_encoder_layers",
      "decoder_ffn_dim",
      "num_decoder_attention_heads",
      "num_decoder_layers",
      "attention_dropout",
      "init_std",
      "eps",
      "add_cross_attention",
      "disable_ngram_loss"
    ]
  },
  "MBART_PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES": [],
  "MBART50_PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES": [],
  "MBartTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "model_input_names": [],
    "FAIRSEQ_LANGUAGE_CODES": [],
    "__init__": [
      "self",
      "vocab_file",
      "src_lang",
      "tgt_lang",
      "bos_token",
      "eos_token",
      "sep_token",
      "cls_token",
      "unk_token",
      "pad_token",
      "mask_token",
      "sp_model_kwargs",
      "additional_special_tokens"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "max_length",
      "stride",
      "is_split_into_words",
      "padding",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "d"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "convert_ids_to_string": [
      "self",
      "ids"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "set_src_lang_special_tokens": [
      "self",
      "src_lang"
    ],
    "set_tgt_lang_special_tokens": [
      "self",
      "tgt_lang"
    ]
  },
  "MBart50Tokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "model_input_names": [],
    "FAIRSEQ_LANGUAGE_CODES": [],
    "__init__": [
      "self",
      "vocab_file",
      "src_lang",
      "tgt_lang",
      "bos_token",
      "eos_token",
      "sep_token",
      "cls_token",
      "unk_token",
      "pad_token",
      "mask_token",
      "sp_model_kwargs",
      "additional_special_tokens"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "max_length",
      "stride",
      "is_split_into_words",
      "padding",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "d"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "vocab_size": [
      "self"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "convert_ids_to_string": [
      "self",
      "ids"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "set_src_lang_special_tokens": [
      "self",
      "src_lang"
    ],
    "set_tgt_lang_special_tokens": [
      "self",
      "tgt_lang"
    ],
    "_build_translation_inputs": [
      "self",
      "raw_inputs",
      "return_tensors",
      "src_lang",
      "tgt_lang"
    ]
  },
  "MBartPretrainedModel": {
    "model_config_file": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "MBartLearnedPositionalEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim"
    ],
    "forward": [
      "self",
      "input_ids_shape",
      "past_key_values_length"
    ]
  },
  "MBartEncoder": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MBartDecoder": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "memory_mask",
      "cache",
      "decoder_inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MBartModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "use_cache",
      "cache",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MBartClassificationHead": {
    "__init__": [
      "self",
      "input_dim",
      "inner_dim",
      "num_classes",
      "pooler_dropout"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MBartForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "use_cache",
      "cache",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MBartForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "use_cache",
      "cache",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "start_positions",
      "end_positions",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MBartForConditionalGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "prepare_fast_entry": [
      "self",
      "kwargs"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "use_cache",
      "cache",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "decoder_input_ids",
      "attention_mask",
      "decoder_attention_mask",
      "cache",
      "use_cache",
      "encoder_output"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "MBART_PRETRAINED_INIT_CONFIGURATION": [],
  "MBART_PRETRAINED_RESOURCE_FILES_MAP": [],
  "MBartConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "bos_token_id",
      "pad_token_id",
      "eos_token_id",
      "forced_eos_token_id",
      "d_model",
      "encoder_layers",
      "decoder_layers",
      "encoder_attention_heads",
      "decoder_attention_heads",
      "encoder_ffn_dim",
      "decoder_ffn_dim",
      "dropout",
      "activation_function",
      "attention_dropout",
      "activation_dropout",
      "max_position_embeddings",
      "init_std",
      "is_encoder_decoder",
      "scale_embedding"
    ]
  },
  "DebertaV2Tokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "sentencepiece_model_file",
      "vocab_file",
      "do_lower_case",
      "split_by_punct",
      "bos_token",
      "eos_token",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "sp_model_kwargs"
    ],
    "vocab_size": [
      "self"
    ],
    "vocab": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "prepare_for_tokenization": [
      "self",
      "text",
      "is_split_into_words"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ]
  },
  "SPMTokenizer": {
    "__init__": [
      "self",
      "vocab_file",
      "special_tokens",
      "split_by_punct",
      "sp_model_kwargs"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "d"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids"
    ],
    "decode": [
      "self",
      "tokens",
      "start",
      "end",
      "raw_text"
    ],
    "add_special_token": [
      "self",
      "token"
    ],
    "part_of_whole_word": [
      "self",
      "token",
      "is_bos"
    ],
    "pad": [
      "self"
    ],
    "bos": [
      "self"
    ],
    "eos": [
      "self"
    ],
    "unk": [
      "self"
    ],
    "mask": [
      "self"
    ],
    "sym": [
      "self",
      "id"
    ],
    "id": [
      "self",
      "sym"
    ],
    "_encode_as_pieces": [
      "self",
      "text"
    ],
    "split_to_words": [
      "self",
      "text"
    ],
    "_run_strip_accents": [
      "self",
      "text"
    ],
    "_run_split_on_punc": [
      "self",
      "text"
    ]
  },
  "DebertaV2Embeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "mask",
      "inputs_embeds"
    ]
  },
  "DebertaV2SelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "DebertaV2Attention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions",
      "query_states",
      "relative_pos",
      "rel_embeddings"
    ]
  },
  "DebertaV2Intermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DebertaV2Output": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "DebertaV2Layer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "query_states",
      "relative_pos",
      "rel_embeddings",
      "output_attentions"
    ]
  },
  "ConvLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual_states",
      "input_mask"
    ]
  },
  "make_log_bucket_position": [
    "relative_pos",
    "bucket_size",
    "max_position"
  ],
  "DebertaV2Encoder": {
    "__init__": [
      "self",
      "config"
    ],
    "get_rel_embedding": [
      "self"
    ],
    "get_attention_mask": [
      "self",
      "attention_mask"
    ],
    "get_rel_pos": [
      "self",
      "hidden_states",
      "query_states",
      "relative_pos"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_hidden_states",
      "output_attentions",
      "query_states",
      "relative_pos",
      "return_dict"
    ]
  },
  "DebertaV2PreTrainedModel": {
    "model_config_file": [],
    "config_class": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "init_weights": [
      "self",
      "layer"
    ]
  },
  "DebertaV2Model": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DebertaV2PredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DebertaV2LMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DebertaV2OnlyMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output"
    ]
  },
  "DebertaV2ForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DebertaV2ForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DebertaV2ForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DebertaV2ForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DebertaV2ForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "DEBERTA_V2_PRETRAINED_INIT_CONFIGURATION": [],
  "DEBERTA_V2_PRETRAINED_RESOURCE_FILES_MAP": [],
  "DebertaV2Config": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "relative_attention",
      "max_relative_positions",
      "pad_token_id",
      "position_biased_input",
      "pos_att_type",
      "pooler_dropout",
      "pooler_hidden_act",
      "share_attn_key",
      "output_hidden_states",
      "output_attentions"
    ]
  },
  "MobileBertTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "batch_encode": [
      "self",
      "batch_text_or_text_pairs",
      "max_length",
      "padding",
      "truncation",
      "stride",
      "is_split_into_words",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "pad_to_multiple_of",
      "return_tensors",
      "verbose"
    ]
  },
  "NoNorm": {
    "__init__": [
      "self",
      "feat_size",
      "eps"
    ],
    "forward": [
      "self",
      "input_tensor"
    ]
  },
  "NORM2FN": [],
  "MobileBertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "MobileBertAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "query_tensor",
      "key_tensor",
      "value_tensor",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "output_attentions"
    ]
  },
  "MobileBertIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "OutputBottleneck": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual_tensor"
    ]
  },
  "MobileBertOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "intermediate_states",
      "residual_tensor_1",
      "residual_tensor_2"
    ]
  },
  "BottleneckLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "FFNOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual_tensor"
    ]
  },
  "FFNLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MobileBertLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "output_attentions"
    ]
  },
  "MobileBertEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MobileBertPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MobileBertPredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MobileBertLMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MobileBertOnlyMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output"
    ]
  },
  "MobileBertPreTrainingHeads": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output",
      "pooled_output"
    ]
  },
  "MobileBertPretrainedModel": {
    "model_config_file": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "MobileBertForPreTrainingOutput": {},
  "MobileBertForPreTraining": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddigs"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MobileBertModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_head_mask": [
      "self",
      "head_mask",
      "num_hidden_layers",
      "is_attention_chunked"
    ],
    "_convert_head_mask_to_5d": [
      "self",
      "head_mask",
      "num_hidden_layers"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "MobileBertForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MobileBertForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MOBILEBERT_PRETRAINED_INIT_CONFIGURATION": [],
  "MOBILEBERT_PRETRAINED_RESOURCE_FILES_MAP": [],
  "MobileBertConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "embedding_size",
      "true_hidden_size",
      "normalization_type",
      "use_bottleneck",
      "use_bottleneck_attention",
      "intra_bottleneck_size",
      "key_query_shared_bottleneck",
      "num_feedforward_networks",
      "trigram_input",
      "classifier_activation",
      "classifier_dropout",
      "add_pooling_layer"
    ]
  },
  "GAUAlphaTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "padding_side": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "get_vocab": [
      "self"
    ]
  },
  "Norm": {
    "__init__": [
      "self",
      "epsilon"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "attention_normalize": [
    "a",
    "mask",
    "axis",
    "method"
  ],
  "ScaleOffset": {
    "__init__": [
      "self",
      "hidden_size",
      "scale",
      "offset"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "GatedAttentionUnit": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "GAULayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "initializer": [
    "tensor",
    "num_hidden_layers",
    "order",
    "gain"
  ],
  "GAUAlphaPretrainedModel": {
    "model_config_file": [],
    "config_class": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "GAUAlphaModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids"
    ]
  },
  "GAUAlphaEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids"
    ]
  },
  "GAUAlphaEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "GAUAlphaForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ]
  },
  "GAUAlphaForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ]
  },
  "GAUAlphaForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ]
  },
  "GAUAlphaForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ]
  },
  "GAUAlphaLMPredictionHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GAUAlphaForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ]
  },
  "GAUAlPHA_PRETRAINED_INIT_CONFIGURATION": [],
  "GAUAlPHA_PRETRAINED_RESOURCE_FILES_MAP": [],
  "GAUAlphaConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "task_id",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "task_type_vocab_size",
      "type_vocab_size",
      "attention_key_size",
      "initializer_range",
      "pad_token_id",
      "pool_act",
      "activation",
      "normalization",
      "fuse",
      "layer_norm_eps",
      "norm_eps",
      "use_cache",
      "use_task_id",
      "use_bias",
      "attention_scale"
    ]
  },
  "BertJapaneseTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "do_word_tokenize",
      "do_subword_tokenize",
      "word_tokenizer_type",
      "subword_tokenizer_type",
      "never_split",
      "mecab_kwargs",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "do_lower_case": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "_tokenize": [
      "self",
      "text"
    ]
  },
  "MecabTokenizer": {
    "__init__": [
      "self",
      "do_lower_case",
      "never_split",
      "normalize_text",
      "mecab_dic",
      "mecab_option"
    ],
    "tokenize": [
      "self",
      "text",
      "never_split"
    ]
  },
  "CharacterTokenizer": {
    "__init__": [
      "self",
      "vocab",
      "unk_token",
      "normalize_text"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "ClapProcessor": {
    "feature_extractor_class": [],
    "tokenizer_class": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "feature_extractor",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "text",
      "audios",
      "return_tensors"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "model_input_names": [
      "self"
    ]
  },
  "CLAP_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "interpolate": [
    "hidden_states",
    "ratio"
  ],
  "window_partition": [
    "hidden_states",
    "window_size"
  ],
  "window_reverse": [
    "windows",
    "window_size",
    "height",
    "width"
  ],
  "ClapTextModelOutput": {},
  "ClapAudioModelOutput": {},
  "ClapOutput": {
    "to_tuple": [
      "self"
    ]
  },
  "ClapDropPath": {
    "__init__": [
      "self",
      "drop_prob"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ClapAudioAFFBlock": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "ClapAudioPatchEmbed": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "is_longer_idx"
    ]
  },
  "ClapAudioSelfAttention": {
    "__init__": [
      "self",
      "config",
      "dim",
      "num_heads",
      "window_size"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "output_attentions"
    ]
  },
  "ClapAudioSelfOutput": {
    "__init__": [
      "self",
      "config",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "ClapAudioAttention": {
    "__init__": [
      "self",
      "config",
      "dim",
      "num_heads",
      "window_size"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "output_attentions"
    ]
  },
  "ClapAudioIntermediate": {
    "__init__": [
      "self",
      "config",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ClapAudioOutput": {
    "__init__": [
      "self",
      "config",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ClapAudioLayer": {
    "__init__": [
      "self",
      "config",
      "dim",
      "input_resolution",
      "num_heads",
      "shift_size"
    ],
    "set_shift_and_window_size": [
      "self",
      "input_resolution"
    ],
    "get_attn_mask": [
      "self",
      "height",
      "width",
      "dtype"
    ],
    "maybe_pad": [
      "self",
      "hidden_states",
      "height",
      "width"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_dimensions",
      "head_mask",
      "output_attentions",
      "always_partition"
    ]
  },
  "ClapAudioStage": {
    "__init__": [
      "self",
      "config",
      "dim",
      "input_resolution",
      "depth",
      "num_heads",
      "drop_path",
      "downsample"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_dimensions",
      "head_mask",
      "output_attentions",
      "always_partition"
    ]
  },
  "ClapAudioPatchMerging": {
    "__init__": [
      "self",
      "input_resolution",
      "dim",
      "norm_layer"
    ],
    "maybe_pad": [
      "self",
      "input_feature",
      "height",
      "width"
    ],
    "forward": [
      "self",
      "input_feature",
      "input_dimensions"
    ]
  },
  "ClapAudioEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "reshape_mel2img": [
      "self",
      "normalized_input_features"
    ],
    "forward": [
      "self",
      "input_features",
      "is_longer",
      "head_mask",
      "output_attentions",
      "output_hidden_states",
      "output_hidden_states_before_downsampling",
      "always_partition",
      "return_dict"
    ]
  },
  "ClapProjectionLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ClapTextEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ],
    "create_position_ids_from_inputs_embeds": [
      "self",
      "inputs_embeds"
    ]
  },
  "ClapTextSelfAttention": {
    "__init__": [
      "self",
      "config",
      "position_embedding_type"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "ClapTextSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "ClapTextAttention": {
    "__init__": [
      "self",
      "config",
      "position_embedding_type"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "ClapTextIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ClapTextOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "ClapTextLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ]
  },
  "ClapTextEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ClapTextPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ClapPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ],
    "get_extended_attention_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "has_query"
    ],
    "get_head_mask": [
      "self",
      "head_mask",
      "num_hidden_layers",
      "is_attention_chunked"
    ],
    "_convert_head_mask_to_5d": [
      "self",
      "head_mask",
      "num_hidden_layers"
    ]
  },
  "ClapAudioModel": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_features",
      "is_longer",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ClapTextModel": {
    "config_class": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ClapModel": {
    "config_class": [],
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_text_features": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_audio_features": [
      "self",
      "input_features",
      "is_longer",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "forward": [
      "self",
      "input_ids",
      "input_features",
      "is_longer",
      "attention_mask",
      "position_ids",
      "return_loss",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ClapTextModelWithProjection": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ClapAudioModelWithProjection": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_features",
      "is_longer",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ClapFeatureExtractor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "feature_size",
      "sampling_rate",
      "hop_length",
      "max_length_s",
      "fft_window_size",
      "padding_value",
      "return_attention_mask",
      "frequency_min",
      "frequency_max",
      "top_db",
      "truncation",
      "padding"
    ],
    "to_dict": [
      "self"
    ],
    "_np_extract_fbank_features": [
      "self",
      "waveform",
      "mel_filters"
    ],
    "_random_mel_fusion": [
      "self",
      "mel",
      "total_frames",
      "chunk_frames"
    ],
    "_get_input_mel": [
      "self",
      "waveform",
      "max_length",
      "truncation",
      "padding"
    ],
    "__call__": [
      "self",
      "raw_speech",
      "truncation",
      "padding",
      "max_length",
      "sampling_rate",
      "return_tensors"
    ]
  },
  "ClapTextConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "initializer_factor",
      "layer_norm_eps",
      "projection_dim",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "position_embedding_type",
      "use_cache",
      "classifier_dropout",
      "projection_hidden_act"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "ClapAudioConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "window_size",
      "num_mel_bins",
      "spec_size",
      "hidden_act",
      "patch_size",
      "patch_stride",
      "num_classes",
      "hidden_size",
      "projection_dim",
      "depths",
      "num_attention_heads",
      "enable_fusion",
      "hidden_dropout_prob",
      "fusion_type",
      "patch_embed_input_channels",
      "flatten_patch_embeds",
      "patch_embeds_hidden_size",
      "enable_patch_layer_norm",
      "drop_path_rate",
      "attention_probs_dropout_prob",
      "qkv_bias",
      "mlp_ratio",
      "aff_block_r",
      "num_hidden_layers",
      "projection_hidden_act",
      "layer_norm_eps",
      "initializer_factor"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "ClapConfig": {
    "model_type": [],
    "is_composition": [],
    "__init__": [
      "self",
      "text_config",
      "audio_config",
      "logit_scale_init_value",
      "projection_dim",
      "projection_hidden_act",
      "initializer_factor"
    ],
    "from_text_audio_configs": [
      "cls",
      "text_config",
      "audio_config"
    ],
    "to_dict": [
      "self"
    ]
  },
  "LayoutXLMTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "model_input_names": [],
    "SPECIAL_TOKENS_ATTRIBUTES": [],
    "__init__": [
      "self",
      "vocab_file",
      "bos_token",
      "eos_token",
      "sep_token",
      "cls_token",
      "unk_token",
      "pad_token",
      "mask_token"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ]
  },
  "relative_position_bucket": [
    "relative_position",
    "bidirectional",
    "num_buckets",
    "max_distance"
  ],
  "token_featue_to_sequence_feature": [
    "input_ids",
    "seq_length",
    "sequence_output"
  ],
  "LayoutXLMPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LayoutXLMEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "_cal_spatial_position_embeddings": [
      "self",
      "bbox"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "token_type_ids",
      "position_ids"
    ]
  },
  "LayoutXLMPretrainedModel": {
    "config_class": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "LayoutXLMSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "LayoutXLMSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "compute_qkv": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "rel_pos",
      "rel_2d_pos"
    ]
  },
  "LayoutXLMAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "rel_pos",
      "rel_2d_pos"
    ]
  },
  "LayoutXLMEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "_cal_1d_pos_emb": [
      "self",
      "hidden_states",
      "position_ids"
    ],
    "_cal_2d_pos_emb": [
      "self",
      "hidden_states",
      "bbox"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "bbox",
      "position_ids"
    ]
  },
  "LayoutXLMIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LayoutXLMOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "LayoutXLMLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "rel_pos",
      "rel_2d_pos"
    ]
  },
  "VisualBackbone": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "images"
    ]
  },
  "LayoutXLMModel": {
    "__init__": [
      "self",
      "config"
    ],
    "_calc_text_embeddings": [
      "self",
      "input_ids",
      "bbox",
      "position_ids",
      "token_type_ids"
    ],
    "_calc_visual_bbox": [
      "self",
      "image_feature_pool_shape",
      "bbox",
      "visual_shape"
    ],
    "_calc_img_embeddings": [
      "self",
      "image",
      "bbox",
      "position_ids"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "head_mask",
      "output_hidden_states",
      "output_attentions"
    ]
  },
  "LayoutXLMForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "labels"
    ]
  },
  "LayoutXLMForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "labels"
    ]
  },
  "LayoutXLMPredictionHead": {
    "__init__": [
      "self",
      "hidden_size",
      "vocab_size",
      "activation",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states",
      "masked_positions"
    ]
  },
  "LayoutXLMPretrainingHeads": {
    "__init__": [
      "self",
      "hidden_size",
      "vocab_size",
      "activation",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "sequence_output",
      "masked_positions"
    ]
  },
  "LayoutXLMForPretraining": {
    "__init__": [
      "self",
      "config"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "masked_positions"
    ]
  },
  "BiaffineAttention": {
    "__init__": [
      "self",
      "in_features",
      "out_features"
    ],
    "forward": [
      "self",
      "x_1",
      "x_2"
    ]
  },
  "REDecoder": {
    "__init__": [
      "self",
      "hidden_size",
      "hidden_dropout_prob"
    ],
    "build_relation": [
      "self",
      "relations",
      "entities"
    ],
    "get_predicted_relations": [
      "self",
      "logits",
      "relations",
      "entities"
    ],
    "forward": [
      "self",
      "hidden_states",
      "entities",
      "relations"
    ]
  },
  "LayoutXLMForRelationExtraction": {
    "__init__": [
      "self",
      "config"
    ],
    "_init_weights": [
      "self",
      "layer"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "attention_mask",
      "entities",
      "relations",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "labels"
    ]
  },
  "LayoutXLMForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "start_positions",
      "end_positions"
    ]
  },
  "read_config": [
    "fp"
  ],
  "Conv2d": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CNNBlockBase": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride"
    ],
    "freeze": [
      "self"
    ]
  },
  "ResNetBlockBase": [],
  "ShapeSpec": {
    "__new__": [
      "cls",
      "channels",
      "height",
      "width",
      "stride"
    ]
  },
  "get_norm": [
    "norm",
    "out_channels"
  ],
  "FrozenBatchNorm": {
    "__init__": [
      "self",
      "num_channels"
    ]
  },
  "Backbone": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "size_divisibility": [
      "self"
    ],
    "output_shape": [
      "self"
    ]
  },
  "BasicBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ]
  },
  "BottleneckBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DeformBottleneckBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ]
  },
  "BasicStem": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNet": {
    "__init__": [
      "self",
      "stem",
      "stages",
      "num_classes",
      "out_features",
      "freeze_at"
    ],
    "forward": [
      "self",
      "x"
    ],
    "output_shape": [
      "self"
    ],
    "make_stage": [
      "block_class",
      "num_blocks"
    ],
    "make_default_stages": [
      "depth",
      "block_class"
    ],
    "freeze": [
      "self",
      "freeze_at"
    ]
  },
  "LastLevelMaxPool": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_assert_strides_are_log2_contiguous": [
    "strides"
  ],
  "FPN": {
    "__init__": [
      "self",
      "bottom_up",
      "in_features",
      "out_channels",
      "norm",
      "top_block",
      "fuse_type"
    ],
    "size_divisibility": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "output_shape": [
      "self"
    ]
  },
  "make_stage": [],
  "build_resnet_backbone": [
    "cfg",
    "input_shape"
  ],
  "build_resnet_fpn_backbone": [
    "cfg",
    "input_shape"
  ],
  "LAYOUTXLM_PRETRAINED_INIT_CONFIGURATION": [],
  "LAYOUTXLM_PRETRAINED_RESOURCE_FILES_MAP": [],
  "LayoutXLMConfig": {
    "pretrained_init_configuration": [],
    "model_type": [],
    "__init__": [
      "self",
      "attention_probs_dropout_prob",
      "bos_token_id",
      "coordinate_size",
      "eos_token_id",
      "fast_qkv",
      "gradient_checkpointing",
      "has_relative_attention_bias",
      "has_spatial_attention_bias",
      "has_visual_segment_embedding",
      "hidden_act",
      "hidden_dropout_prob",
      "hidden_size",
      "image_feature_pool_shape",
      "initializer_range",
      "intermediate_size",
      "layer_norm_eps",
      "max_2d_position_embeddings",
      "max_position_embeddings",
      "max_rel_2d_pos",
      "max_rel_pos",
      "model_type",
      "num_attention_heads",
      "num_hidden_layers",
      "output_past",
      "pad_token_id",
      "shape_size",
      "rel_2d_pos_bins",
      "rel_pos_bins",
      "type_vocab_size",
      "vocab_size",
      "with_pool",
      "use_visual_backbone"
    ]
  },
  "GPTJTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "max_len",
      "pad_token",
      "eos_token",
      "unk_token",
      "eol_token"
    ]
  },
  "GPTJAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "_split_heads": [
      "self",
      "tensor",
      "num_attention_heads",
      "attn_head_size",
      "rotary"
    ],
    "_merge_heads": [
      "self",
      "tensor",
      "num_attention_heads",
      "attn_head_size"
    ],
    "_attn": [
      "self",
      "query",
      "key",
      "value",
      "attention_mask"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "layer_past",
      "use_cache",
      "output_attentions"
    ]
  },
  "GPTJMLP": {
    "__init__": [
      "self",
      "intermediate_size",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPTJBlock": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "layer_past",
      "attention_mask",
      "use_cache",
      "output_attentions"
    ]
  },
  "GPTJPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "is_parallelizable": [],
    "supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "GPTJModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "GPTJForCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "prepare_fast_entry": [
      "self",
      "kwargs"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past_key_values"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_reorder_cache": [
      "past",
      "beam_idx"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "GPTJForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "GPTJForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "GPTJ_PRETRAINED_INIT_CONFIGURATION": [],
  "GPTJ_PRETRAINED_RESOURCE_FILES_MAP": [],
  "GPTJConfig": {
    "model_type": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "n_positions",
      "n_embd",
      "n_layer",
      "n_head",
      "rotary_dim",
      "n_inner",
      "activation_function",
      "resid_pdrop",
      "embd_pdrop",
      "attn_pdrop",
      "layer_norm_epsilon",
      "initializer_range",
      "use_cache",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings"
    ]
  },
  "match_embedding_param": [
    "convert_parameter_name_dict"
  ],
  "match_encoder_param": [
    "convert_parameter_name_dict",
    "layer_num"
  ],
  "match_pooler_parameter": [
    "convert_parameter_name_dict"
  ],
  "match_mlm_parameter": [
    "convert_parameter_name_dict"
  ],
  "write_vocab": [
    "vocab_file"
  ],
  "ErnieGramTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ]
  },
  "ErnieGramEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ]
  },
  "ErnieGramPooler": {
    "__init__": [
      "self",
      "config",
      "weight_attr"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErnieGramPretrainedModel": {
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "model_config_file": [],
    "resource_files_names": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "ErnieGramModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "past_key_values",
      "use_cache",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieGramForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieGramForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ErnieGramForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "ERNIE_GRAM_PRETRAINED_INIT_CONFIGURATION": [],
  "ERNIE_GRAM_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ErnieGramConfig": {
    "pretrained_init_configuration": [],
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "embedding_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id",
      "rel_pos_size"
    ]
  },
  "all_strategy_types": [],
  "LongSequenceStrategies": {
    "build_long_sequence_strategy": [
      "cls",
      "strategy_type",
      "stratety_name"
    ]
  },
  "AttentionWithLinearBias": {
    "__init__": [
      "self"
    ],
    "_get_interleave": [
      "self",
      "n"
    ],
    "forward": [
      "self",
      "bool_attention_mask",
      "num_heads",
      "dtype"
    ]
  },
  "LinearScalingRotaryEmbedding": {
    "__init__": [
      "self"
    ],
    "_set_cos_sin_cache": [
      "self",
      "seq_len"
    ]
  },
  "NTKScalingRotaryEmbedding": {
    "__init__": [
      "self"
    ]
  },
  "DynamicNTKScalingRotaryEmbedding": {
    "__init__": [
      "self"
    ],
    "_scale_cos_sin": [
      "self",
      "seq_len",
      "ntk_alpha"
    ],
    "forward": [
      "self",
      "seq_len",
      "ntk_alpha"
    ]
  },
  "RemBertTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "remove_space",
      "keep_accents",
      "cls_token",
      "unk_token",
      "sep_token",
      "pad_token",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "d"
    ],
    "_tokenize": [
      "self",
      "text",
      "sample"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ]
  },
  "RemBertPretrainedModel": {
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "RemBertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids"
    ]
  },
  "RemBertPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "RemBertSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "RemBertSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "RemBertAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "RemBertIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "RemBertOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "RemBertLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ]
  },
  "RemBertEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "RemBertModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "RemBertForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "RemBertForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "RemBertLMPredictionHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states",
      "masked_positions"
    ]
  },
  "RemBertOnlyMLMHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "sequence_output",
      "masked_positions"
    ]
  },
  "RemBertForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "RemBertForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "RemBertForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "REMBERT_PRETRAINED_INIT_CONFIGURATION": [],
  "REMBERT_PRETRAINED_RESOURCE_FILES_MAP": [],
  "RemBertConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "input_embedding_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id",
      "layer_norm_eps"
    ]
  },
  "BartTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "bos_token",
      "eos_token",
      "cls_token",
      "sep_token",
      "unk_token",
      "pad_token",
      "mask_token"
    ],
    "_bpe_encode": [
      "self",
      "text"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_vocab": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "eol_token_id": [
      "self"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_ids_to_string": [
      "self",
      "ids"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ]
  },
  "BartPretrainedModel": {
    "model_config_file": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "BartLearnedPositionalEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim"
    ],
    "forward": [
      "self",
      "input_ids_shape",
      "past_key_values_length"
    ]
  },
  "BartEncoder": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BartDecoder": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "memory_mask",
      "decoder_inputs_embeds",
      "cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BartModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "use_cache",
      "cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BartClassificationHead": {
    "__init__": [
      "self",
      "input_dim",
      "inner_dim",
      "num_classes",
      "pooler_dropout"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BartForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "use_cache",
      "cache",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BartForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "use_cache",
      "cache",
      "start_positions",
      "end_positions",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BartForConditionalGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "prepare_fast_entry": [
      "self",
      "kwargs"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "inputs_embeds",
      "decoder_inputs_embeds",
      "use_cache",
      "cache",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_decoder_input_ids_from_labels": [
      "self",
      "labels"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "decoder_input_ids",
      "attention_mask",
      "decoder_attention_mask",
      "cache",
      "use_cache",
      "encoder_output"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "BART_PRETRAINED_INIT_CONFIGURATION": [],
  "BART_PRETRAINED_RESOURCE_FILES_MAP": [],
  "BartConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "max_position_embeddings",
      "encoder_layers",
      "encoder_ffn_dim",
      "encoder_attention_heads",
      "decoder_layers",
      "decoder_ffn_dim",
      "decoder_attention_heads",
      "activation_function",
      "d_model",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "init_std",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "is_encoder_decoder",
      "decoder_start_token_id",
      "forced_eos_token_id",
      "scale_embedding"
    ]
  },
  "UnifiedTransformerTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "TASK_TO_SPECIAL_TOKEN": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "sentencepiece_model_file",
      "do_lower_case",
      "unk_token",
      "pad_token",
      "cls_token",
      "sep_token",
      "mask_token",
      "special_tokens_file"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "preprocess_text": [
      "self",
      "inputs",
      "remove_space",
      "lower",
      "is_split_into_words"
    ],
    "clean_text": [
      "self",
      "text"
    ],
    "encode_pieces": [
      "self",
      "spm_model",
      "text",
      "return_unicode",
      "sample"
    ],
    "_tokenize": [
      "self",
      "text",
      "is_split_into_words"
    ],
    "merge_subword": [
      "self",
      "tokens"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens",
      "keep_space"
    ],
    "convert_ids_to_string": [
      "self",
      "ids",
      "keep_space"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ],
    "read_file": [
      "filepath"
    ],
    "load_vocabulary": [
      "filepath",
      "unk_token",
      "pad_token",
      "bos_token",
      "eos_token"
    ],
    "dialogue_encode": [
      "self",
      "history",
      "response",
      "knowledge",
      "task_type",
      "max_seq_len",
      "max_response_len",
      "max_knowledge_len",
      "return_position_ids",
      "return_token_type_ids",
      "return_role_ids",
      "return_attention_mask",
      "return_length",
      "add_start_token_as_response",
      "pad_to_max_seq_len",
      "return_tensors",
      "is_split_into_words",
      "position_style"
    ]
  },
  "convert": [
    "args"
  ],
  "UnifiedTransformerPretrainedModel": {
    "model_config_file": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "config_class": [],
    "base_model_prefix": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "UnifiedTransformerEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "role_ids",
      "input_embeddings"
    ]
  },
  "UnifiedTransformerModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "use_cache",
      "cache",
      "role_ids",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "UnifiedTransformerLMHead": {
    "__init__": [
      "self",
      "hidden_size",
      "vocab_size",
      "activation",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states",
      "masked_positions"
    ]
  },
  "UnifiedTransformerLMHeadModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "masked_positions",
      "use_cache",
      "cache",
      "role_ids",
      "labels",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_fast_entry": [
      "self",
      "kwargs"
    ],
    "adjust_logits_during_generation": [
      "self",
      "logits"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "use_cache",
      "cache"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "UnifiedTransformerForMaskedLM": [],
  "UNIFIED_TRANSFORMER_PRETRAINED_INIT_CONFIGURATION": [],
  "UNIFIED_TRANSFORMER_PRETRAINED_RESOURCE_FILES_MAP": [],
  "UnifiedTransformerConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "normalize_before",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "unk_token_id",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "mask_token_id",
      "role_type_size"
    ]
  },
  "ErnieLayoutTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "pretrained_positional_embedding_sizes": [],
    "max_model_input_sizes": [],
    "SPECIAL_TOKENS_ATTRIBUTES": [],
    "__init__": [
      "self",
      "vocab_file",
      "sentencepiece_model_file",
      "do_tokenize_postprocess",
      "sep_token",
      "cls_token",
      "unk_token",
      "pad_token",
      "mask_token"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_offset_mapping": [
      "self",
      "text"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "is_ch_char": [
      "self",
      "char"
    ],
    "is_alpha": [
      "self",
      "char"
    ],
    "is_punct": [
      "self",
      "char"
    ],
    "is_whitespace": [
      "self",
      "char"
    ]
  },
  "ErnieLayoutPooler": {
    "__init__": [
      "self",
      "hidden_size",
      "with_pool"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErnieLayoutEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "_cal_spatial_position_embeddings": [
      "self",
      "bbox"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "token_type_ids",
      "position_ids"
    ]
  },
  "ErnieLayoutPretrainedModel": {
    "model_config_file": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "ErnieLayoutSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "ErnieLayoutSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "compute_qkv": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "output_attentions",
      "rel_pos",
      "rel_2d_pos"
    ]
  },
  "ErnieLayoutAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "output_attentions",
      "rel_pos",
      "rel_2d_pos"
    ]
  },
  "ErnieLayoutEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "_cal_1d_pos_emb": [
      "self",
      "hidden_states",
      "position_ids"
    ],
    "_cal_2d_pos_emb": [
      "self",
      "hidden_states",
      "bbox"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "bbox",
      "position_ids"
    ]
  },
  "ErnieLayoutIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ErnieLayoutOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "ErnieLayoutLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "output_attentions",
      "rel_pos",
      "rel_2d_pos"
    ]
  },
  "ErnieLayoutModel": {
    "__init__": [
      "self",
      "config"
    ],
    "_calc_text_embeddings": [
      "self",
      "input_ids",
      "bbox",
      "position_ids",
      "token_type_ids"
    ],
    "_calc_img_embeddings": [
      "self",
      "image",
      "bbox",
      "position_ids"
    ],
    "_calc_visual_bbox": [
      "self",
      "image_feature_pool_shape",
      "bbox",
      "visual_shape"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "output_hidden_states",
      "output_attentions"
    ]
  },
  "ErnieLayoutForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "labels"
    ]
  },
  "ErnieLayoutPredictionHead": {
    "__init__": [
      "self",
      "hidden_size",
      "vocab_size",
      "activation",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states",
      "masked_positions"
    ]
  },
  "ErnieLayoutPretrainingHeads": {
    "__init__": [
      "self",
      "hidden_size",
      "vocab_size",
      "activation",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "sequence_output",
      "masked_positions"
    ]
  },
  "ErnieLayoutForPretraining": {
    "__init__": [
      "self",
      "config"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "masked_positions"
    ]
  },
  "ErnieLayoutForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "labels"
    ]
  },
  "ErnieLayoutForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "start_positions",
      "end_positions"
    ]
  },
  "UIEX": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "bbox",
      "image"
    ]
  },
  "ConvBNLayer": {
    "__init__": [
      "self",
      "num_channels",
      "num_filters",
      "filter_size",
      "stride",
      "groups",
      "act",
      "name",
      "data_format"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "ERNIE_LAYOUT_PRETRAINED_INIT_CONFIGURATION": [],
  "ERNIE_LAYOUT_PRETRAINED_RESOURCE_FILES_MAP": [],
  "ErnieLayoutConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "task_id",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "max_2d_position_embeddings",
      "task_type_vocab_size",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id",
      "pool_act",
      "fuse",
      "image_feature_pool_shape",
      "layer_norm_eps",
      "use_cache",
      "use_task_id",
      "classifier_dropout",
      "has_visual_segment_embedding"
    ]
  },
  "_build_linear": [
    "n_in",
    "n_out",
    "name",
    "init"
  ],
  "_build_ln": [
    "n_in",
    "name"
  ],
  "append_name": [
    "name",
    "postfix"
  ],
  "AttentionLayer": {
    "__init__": [
      "self",
      "cfg",
      "name"
    ],
    "forward": [
      "self",
      "queries",
      "keys",
      "values",
      "attn_bias",
      "past_cache"
    ]
  },
  "PositionwiseFeedForwardLayer": {
    "__init__": [
      "self",
      "cfg",
      "name"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "ErnieEncoderLayer": {
    "__init__": [
      "self",
      "cfg",
      "name"
    ],
    "forward": [
      "self",
      "inputs",
      "attn_bias",
      "past_cache"
    ]
  },
  "ErnieEncoderStack": {
    "__init__": [
      "self",
      "cfg",
      "name"
    ],
    "forward": [
      "self",
      "inputs",
      "attn_bias",
      "past_cache"
    ]
  },
  "ErnieGenPretrainedModel": {
    "ernie_gen_pretrained_init_configuration": [],
    "ernie_gen_pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "_post_init": [
      "self",
      "original_init"
    ]
  },
  "ErnieForGeneration": {
    "__init__": [
      "self",
      "cfg",
      "name"
    ],
    "forward": [
      "self"
    ]
  },
  "ErnieGenModel": [],
  "CONTROL_CODES": [],
  "CTRLTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "CONTROL_CODES": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "max_len",
      "unk_token"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ]
  },
  "SinusoidalPositionalEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim"
    ],
    "_init_weight": [
      "out"
    ],
    "forward": [
      "self",
      "position_ids"
    ]
  },
  "scaled_dot_product_attention": [
    "q",
    "k",
    "v",
    "mask",
    "attention_mask"
  ],
  "EncoderLayer": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "intermediate_size",
      "rate",
      "epsilon"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "layer_past",
      "attention_mask",
      "use_cache",
      "output_attentions"
    ]
  },
  "CTRLPreTrainedModel": {
    "base_model_prefix": [],
    "model_config_file": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "CTRLModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "cache",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "use_cache",
      "output_attentions",
      "output_hidden_states"
    ]
  },
  "CTRLLMHeadModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "use_cache",
      "cache"
    ],
    "forward": [
      "self",
      "input_ids",
      "cache",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states"
    ]
  },
  "CTRLForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "cache",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states"
    ]
  },
  "CTRLForCausalLM": [],
  "CTRL_PRETRAINED_INIT_CONFIGURATION": [],
  "CTRL_PRETRAINED_RESOURCE_FILES_MAP": [],
  "CTRLConfig": {
    "pretrained_init_configuration": [],
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "n_positions",
      "n_embd",
      "dff",
      "n_layer",
      "n_head",
      "resid_pdrop",
      "embd_pdrop",
      "layer_norm_epsilon",
      "initializer_range",
      "use_cache"
    ]
  },
  "ErnieEncoder": {
    "__init__": [
      "self",
      "config",
      "output_emb_size"
    ],
    "_init_weights": [
      "self",
      "layer"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "ErnieDualEncoder": {
    "__init__": [
      "self",
      "query_model_name_or_path",
      "title_model_name_or_path",
      "share_parameters",
      "output_emb_size",
      "dropout",
      "reinitialize",
      "use_cross_batch"
    ],
    "init_epsilon_weights": [
      "self",
      "layer"
    ],
    "get_semantic_embedding": [
      "self",
      "data_loader"
    ],
    "get_pooled_embedding": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "is_query"
    ],
    "cosine_sim": [
      "self",
      "query_input_ids",
      "title_input_ids",
      "query_token_type_ids",
      "query_position_ids",
      "query_attention_mask",
      "title_token_type_ids",
      "title_position_ids",
      "title_attention_mask"
    ],
    "forward": [
      "self",
      "query_input_ids",
      "pos_title_input_ids",
      "neg_title_input_ids",
      "is_prediction",
      "query_token_type_ids",
      "query_position_ids",
      "query_attention_mask",
      "pos_title_token_type_ids",
      "pos_title_position_ids",
      "pos_title_attention_mask",
      "neg_title_token_type_ids",
      "neg_title_position_ids",
      "neg_title_attention_mask"
    ]
  },
  "ErnieCrossEncoder": {
    "__init__": [
      "self",
      "pretrain_model_name_or_path",
      "num_classes",
      "reinitialize",
      "dropout"
    ],
    "init_epsilon_weights": [
      "self",
      "layer"
    ],
    "matching": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "return_prob_distributation"
    ],
    "matching_v2": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ],
    "matching_v3": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "labels"
    ]
  },
  "PROCESSOR_MAPPING_NAMES": [],
  "get_configurations": [],
  "AutoProcessor": {
    "MAPPING_NAMES": [],
    "_processor_mapping": [],
    "_name_mapping": [],
    "processor_config_file": [],
    "__init__": [
      "self"
    ],
    "_get_processor_class_from_config": [
      "cls",
      "pretrained_model_name_or_path",
      "config_file_path"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "IMAGE_PROCESSOR_MAPPING_NAMES": [],
  "AutoImageProcessor": {
    "MAPPING_NAMES": [],
    "_processor_mapping": [],
    "_name_mapping": [],
    "image_processor_config_file": [],
    "__init__": [
      "self"
    ],
    "_get_image_processor_class_from_config": [
      "cls",
      "pretrained_model_name_or_path",
      "config_file_path"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "TOKENIZER_MAPPING_NAMES": [],
  "FAST_TOKENIZER_MAPPING_NAMES": [],
  "AutoTokenizer": {
    "MAPPING_NAMES": [],
    "_tokenizer_mapping": [],
    "_name_mapping": [],
    "_fast_name_mapping": [],
    "tokenizer_config_file": [],
    "__init__": [
      "self"
    ],
    "_get_fast_tokenizer_class": [
      "cls",
      "init_class",
      "class_name"
    ],
    "_get_tokenizer_class_from_config": [
      "cls",
      "pretrained_model_name_or_path",
      "config_file_path",
      "use_fast"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "MAPPING_NAMES": [],
  "MAPPING_TASKS": [],
  "MODEL_FOR_CAUSAL_LM_MAPPING_NAMES": [],
  "get_name_mapping": [
    "task"
  ],
  "get_task_name": [
    "model_class"
  ],
  "get_init_configurations": [],
  "_BaseAutoModelClass": {
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "_task_choice": [],
    "model_config_file": [],
    "legacy_model_config_file": [],
    "__init__": [
      "self"
    ],
    "_get_model_class_from_config": [
      "cls",
      "pretrained_model_name_or_path",
      "config_file_path",
      "config"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "_from_pretrained": [
      "cls",
      "pretrained_model_name_or_path",
      "task"
    ]
  },
  "AutoBackbone": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoModel": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "_task_choice": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path",
      "task"
    ]
  },
  "AutoModelForPretraining": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoModelForSequenceClassification": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoModelForTokenClassification": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoModelForQuestionAnswering": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoModelForMultipleChoice": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoModelForMaskedLM": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoModelForCausalLM": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoModelForCausalLMPipe": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoEncoder": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoDecoder": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoGenerator": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoDiscriminator": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoModelForConditionalGeneration": {
    "CONFIGURATION_MODEL_MAPPING": [],
    "_pretrained_model_dict": [],
    "_name_mapping": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "AutoConfig": {
    "name2class": [],
    "config_file": [],
    "legacy_config_file": [],
    "_get_config_class_from_config": [
      "cls",
      "pretrained_model_name_or_path",
      "config_file_path"
    ],
    "from_file": [
      "cls",
      "config_file"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "MegatronBertTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ]
  },
  "MegatronBertPretrainedModel": {
    "model_config_file": [],
    "resource_files_names": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "MegatronBertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "past_key_values_length"
    ]
  },
  "MegatronBertSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "MegatronBertSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "MegatronBertAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "MegatronBertIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MegatronBertOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "MegatronBertLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ]
  },
  "MegatronBertEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "MegatronBertPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MegatronBertModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "MegatronBertForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "MegatronBertForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "MegatronBertPredictionHeadTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MegatronBertLMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MegatronBertOnlyMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output"
    ]
  },
  "MegatronBertOnlyNSPHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pooled_output"
    ]
  },
  "MegatronBertPreTrainingHeads": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "sequence_output",
      "pooled_output"
    ]
  },
  "MegatronBertForPreTraining": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "MegatronBertForCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "MegatronBertForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids"
    ]
  },
  "MegatronBertForNextSentencePrediction": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "MegatronBertForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "MegatronBertForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids"
    ]
  },
  "MegatronBert_PRETRAINED_INIT_CONFIGURATION": [],
  "MegatronBert_PRETRAINED_RESOURCE_FILES_MAP": [],
  "MegatronBertConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "position_embedding_type"
    ]
  },
  "XLNetConverter": {
    "_ignore_state_dict_keys": [],
    "num_layer_key": [],
    "get_paddle_pytorch_model_classes": [
      "self"
    ],
    "get_name_mapping": [
      "self",
      "config_or_num_layers"
    ]
  },
  "SENTENCEPIECE_UNDERLINE": [],
  "SEG_ID_A": [],
  "SEG_ID_B": [],
  "SEG_ID_CLS": [],
  "SEG_ID_SEP": [],
  "SEG_ID_PAD": [],
  "XLNetTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "pretrained_positional_embedding_sizes": [],
    "max_model_input_sizes": [],
    "padding_side": [],
    "pad_token_type_id": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "remove_space",
      "keep_accents",
      "bos_token",
      "eos_token",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "additional_special_tokens",
      "sp_model_kwargs"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "d"
    ],
    "preprocess_text": [
      "self",
      "inputs"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ]
  },
  "XLNetRelativeAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "rel_shift_bnij": [
      "x",
      "klen"
    ],
    "rel_attn_core": [
      "self",
      "q_head",
      "k_head_h",
      "v_head_h",
      "k_head_r",
      "seg_mat",
      "attn_mask",
      "head_mask",
      "output_attentions"
    ],
    "post_attention": [
      "self",
      "h",
      "attn_vec",
      "residual"
    ],
    "forward": [
      "self",
      "h",
      "g",
      "attn_mask_h",
      "attn_mask_g",
      "r",
      "seg_mat",
      "mems",
      "target_mapping",
      "head_mask",
      "output_attentions"
    ]
  },
  "XLNetFeedForward": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "inp"
    ]
  },
  "XLNetLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "output_h",
      "output_g",
      "attn_mask_h",
      "attn_mask_g",
      "r",
      "seg_mat",
      "mems",
      "target_mapping",
      "head_mask",
      "output_attentions"
    ]
  },
  "XLNetPretrainedModel": {
    "pretrained_init_configuration": [],
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "model_config_file": [],
    "config_class": [],
    "base_model_prefix": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "XLNetModelOutput": {},
  "XLNetLMHeadModelOutput": {},
  "XLNetForSequenceClassificationOutput": {},
  "XLNetForTokenClassificationOutput": {},
  "XLNetForMultipleChoiceOutput": {},
  "XLNetForQuestionAnsweringSimpleOutput": {},
  "XLNetForQuestionAnsweringOutput": {},
  "XLNetModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "create_mask": [
      "self",
      "qlen",
      "mlen"
    ],
    "cache_mem": [
      "self",
      "curr_out",
      "prev_mem"
    ],
    "positional_embedding": [
      "pos_seq",
      "inv_freq",
      "bsz"
    ],
    "relative_positional_encoding": [
      "self",
      "qlen",
      "klen",
      "bsz"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "mems",
      "perm_mask",
      "target_mapping",
      "input_mask",
      "head_mask",
      "inputs_embeds",
      "use_mems_train",
      "use_mems_eval",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "XLNetClassificationHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "XLNetForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "mems",
      "perm_mask",
      "target_mapping",
      "input_mask",
      "head_mask",
      "inputs_embeds",
      "labels",
      "use_mems_train",
      "use_mems_eval",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "problem_type"
    ]
  },
  "XLNetForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "mems",
      "perm_mask",
      "target_mapping",
      "input_mask",
      "head_mask",
      "inputs_embeds",
      "labels",
      "use_mems_train",
      "use_mems_eval",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "XLNetLMHeadModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "mems",
      "perm_mask",
      "target_mapping",
      "input_mask",
      "head_mask",
      "inputs_embeds",
      "labels",
      "use_mems_train",
      "use_mems_eval",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "XLNetForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "mems",
      "perm_mask",
      "target_mapping",
      "input_mask",
      "head_mask",
      "inputs_embeds",
      "labels",
      "use_mems_train",
      "use_mems_eval",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "XLNetForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "mems",
      "perm_mask",
      "target_mapping",
      "start_positions",
      "end_positions",
      "input_mask",
      "head_mask",
      "inputs_embeds",
      "use_mems_train",
      "use_mems_eval",
      "return_dict"
    ]
  },
  "XLNetForCausalLM": [],
  "logger": [],
  "XLNET_PRETRAINED_RESOURCE_FILES_MAP": [],
  "XLNET_PRETRAINED_INIT_CONFIGURATION": [],
  "XLNetConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "d_model",
      "n_layer",
      "n_head",
      "d_inner",
      "ff_activation",
      "untie_r",
      "attn_type",
      "initializer_range",
      "layer_norm_eps",
      "dropout",
      "classfier_dropout",
      "mem_len",
      "reuse_len",
      "use_mems_eval",
      "use_mems_train",
      "bi_data",
      "clamp_len",
      "same_length",
      "summary_type",
      "summary_use_proj",
      "summary_activation",
      "summary_last_dropout",
      "start_n_top",
      "end_n_top",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id"
    ],
    "max_position_embeddings": [
      "self",
      "value"
    ]
  },
  "position_encoding_init": [
    "n_position",
    "d_pos_vec",
    "dtype"
  ],
  "WordEmbedding": {
    "__init__": [
      "self",
      "vocab_size",
      "emb_dim",
      "bos_id"
    ],
    "forward": [
      "self",
      "word"
    ]
  },
  "PositionalEmbedding": {
    "__init__": [
      "self",
      "emb_dim",
      "max_length"
    ],
    "forward": [
      "self",
      "pos"
    ]
  },
  "CrossEntropyCriterion": {
    "__init__": [
      "self",
      "label_smooth_eps",
      "pad_idx"
    ],
    "forward": [
      "self",
      "predict",
      "label"
    ]
  },
  "label_smoothed_nll_loss": [
    "lprobs",
    "target",
    "epsilon",
    "ignore_index",
    "reduce"
  ],
  "LabelSmoothedCrossEntropyCriterion": {
    "__init__": [
      "self",
      "label_smoothing",
      "padding_idx"
    ],
    "forward": [
      "self",
      "predict",
      "label",
      "reduce"
    ],
    "get_lprobs_and_target": [
      "self",
      "predict",
      "label"
    ],
    "compute_loss": [
      "self",
      "predict",
      "label",
      "reduce"
    ]
  },
  "TransformerDecodeCell": {
    "__init__": [
      "self",
      "decoder",
      "word_embedding",
      "pos_embedding",
      "linear",
      "dropout"
    ],
    "forward": [
      "self",
      "inputs",
      "states",
      "static_cache",
      "trg_src_attn_bias",
      "memory"
    ]
  },
  "TransformerBeamSearchDecoder": {
    "__init__": [
      "self",
      "cell",
      "start_token",
      "end_token",
      "beam_size",
      "var_dim_in_state"
    ],
    "_merge_batch_beams_with_var_dim": [
      "self",
      "c"
    ],
    "_split_batch_beams_with_var_dim": [
      "self",
      "c"
    ],
    "tile_beam_merge_with_batch": [
      "t",
      "beam_size"
    ],
    "step": [
      "self",
      "time",
      "inputs",
      "states"
    ],
    "force_decoding": [
      "self",
      "beam_search_output",
      "beam_search_state",
      "trg_word",
      "trg_length",
      "time"
    ]
  },
  "TransformerModel": {
    "__init__": [
      "self",
      "src_vocab_size",
      "trg_vocab_size",
      "max_length",
      "num_encoder_layers",
      "num_decoder_layers",
      "n_head",
      "d_model",
      "d_inner_hid",
      "dropout",
      "weight_sharing",
      "attn_dropout",
      "act_dropout",
      "bos_id",
      "eos_id",
      "pad_id",
      "activation",
      "normalize_before"
    ],
    "forward": [
      "self",
      "src_word",
      "trg_word"
    ]
  },
  "InferTransformerModel": {
    "__init__": [
      "self",
      "src_vocab_size",
      "trg_vocab_size",
      "max_length",
      "num_encoder_layers",
      "num_decoder_layers",
      "n_head",
      "d_model",
      "d_inner_hid",
      "dropout",
      "weight_sharing",
      "attn_dropout",
      "act_dropout",
      "bos_id",
      "eos_id",
      "pad_id",
      "beam_size",
      "max_out_len",
      "output_time_major",
      "beam_search_version",
      "activation",
      "normalize_before"
    ],
    "forward": [
      "self",
      "src_word",
      "trg_word"
    ],
    "beam_search_v2": [
      "self",
      "src_word",
      "beam_size",
      "max_len",
      "alpha",
      "trg_word",
      "trg_length"
    ]
  },
  "TransformerDecoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "use_cache",
      "cache",
      "output_attentions"
    ],
    "gen_cache": [
      "self",
      "memory"
    ]
  },
  "OPTLearnedPositionEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "initializer_range"
    ],
    "forward": [
      "self",
      "attention_mask",
      "past_key_values_length"
    ]
  },
  "OPTEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "input_embeddings",
      "past_key_values_length"
    ]
  },
  "OPTPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ],
    "_get_fuse_or_split_param_mappings": [
      "cls",
      "config",
      "is_fuse"
    ],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "OPTModel": {
    "__init__": [
      "self",
      "config"
    ],
    "_prepare_decoder_attention_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "past_key_values_length"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "embedding"
    ]
  },
  "OPTLMHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "OPTForCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "_get_model_inputs_spec": [
      "self",
      "dtype"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_fast_entry": [
      "self",
      "kwargs"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "use_cache",
      "cache",
      "attention_mask",
      "inputs_embeds"
    ],
    "prepare_attention_mask_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "OPTForConditionalGeneration": [],
  "convert_configs": [
    "model_dir",
    "output_dir"
  ],
  "convert_weights": [
    "model_dir",
    "output_dir"
  ],
  "OPT_PRETRAINED_INIT_CONFIGURATION": [],
  "OPT_PRETRAINED_RESOURCE_FILES_MAP": [],
  "OPTConfig": {
    "pretrained_init_configuration": [],
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "intermediate_size",
      "num_attention_heads",
      "hidden_act",
      "max_position_embeddings",
      "normalize_before",
      "word_embed_proj_dim",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "initializer_range",
      "type_vocab_size",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "enable_bias",
      "mp_degree",
      "fuse_attention_qkv",
      "fuse_attention_ffn"
    ]
  },
  "Blip2Processor": {
    "attributes": [],
    "image_processor_class": [],
    "tokenizer_class": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "images",
      "text",
      "return_tensors"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "model_input_names": [
      "self"
    ]
  },
  "BLIP_2_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "Blip2ForConditionalGenerationModelOutput": {
    "to_tuple": [
      "self"
    ]
  },
  "Blip2VisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "Blip2Attention": {
    "__init__": [
      "self",
      "config"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states",
      "head_mask",
      "output_attentions"
    ]
  },
  "Blip2MLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Blip2EncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions"
    ]
  },
  "Blip2PretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "_no_split_modules": [],
    "_keep_in_fp32_modules": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ]
  },
  "Blip2Encoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "Blip2VisionModel": {
    "main_input_name": [],
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "Blip2QFormerMultiHeadAttention": {
    "__init__": [
      "self",
      "config",
      "is_cross_attention"
    ],
    "save_attn_gradients": [
      "self",
      "attn_gradients"
    ],
    "get_attn_gradients": [
      "self"
    ],
    "save_attention_map": [
      "self",
      "attention_map"
    ],
    "get_attention_map": [
      "self"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "Blip2QFormerSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "Blip2QFormerAttention": {
    "__init__": [
      "self",
      "config",
      "is_cross_attention"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "Blip2QFormerIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Blip2QFormerOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "Blip2QFormerLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "query_length"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ],
    "feed_forward_chunk_query": [
      "self",
      "attention_output"
    ]
  },
  "Blip2QFormerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "query_length"
    ]
  },
  "Blip2QFormerModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "get_extended_attention_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "has_query"
    ],
    "invert_attention_mask": [
      "self",
      "encoder_attention_mask"
    ],
    "get_head_mask": [
      "self",
      "head_mask",
      "num_hidden_layers",
      "is_attention_chunked"
    ],
    "_convert_head_mask_to_5d": [
      "self",
      "head_mask",
      "num_hidden_layers"
    ],
    "forward": [
      "self",
      "query_embeds",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "Blip2Model": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_text_features": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_qformer_features": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "forward": [
      "self",
      "pixel_values",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "output_attentions",
      "output_hidden_states",
      "labels",
      "return_dict"
    ]
  },
  "Blip2ForConditionalGeneration": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "output_attentions",
      "output_hidden_states",
      "labels",
      "return_dict"
    ],
    "generate": [
      "self",
      "pixel_values",
      "input_ids",
      "attention_mask"
    ]
  },
  "Blip2VisionConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "projection_dim",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "hidden_act",
      "layer_norm_eps",
      "dropout",
      "attention_dropout",
      "initializer_range",
      "initializer_factor",
      "qkv_bias"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "Blip2QFormerConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "position_embedding_type",
      "classifier_dropout",
      "cross_attention_frequency",
      "encoder_hidden_size"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "Blip2Config": {
    "model_type": [],
    "is_composition": [],
    "__init__": [
      "self",
      "vision_config",
      "qformer_config",
      "text_config",
      "num_query_tokens"
    ],
    "from_vision_qformer_text_configs": [
      "cls",
      "vision_config",
      "qformer_config",
      "text_config"
    ],
    "to_dict": [
      "self"
    ]
  },
  "load_balancing_loss_func": [
    "gate_logits",
    "num_experts",
    "top_k",
    "attention_mask"
  ],
  "assign_kv_heads": [
    "num_kv_heads",
    "num_gpus"
  ],
  "is_casual_mask": [
    "attention_mask"
  ],
  "MixtralRMSNorm": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "repeat_kv": [
    "hidden_states",
    "n_rep"
  ],
  "MixtralRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "base"
    ],
    "_set_cos_sin_cache": [
      "self",
      "seq_len"
    ],
    "forward": [
      "self",
      "x",
      "seq_len"
    ]
  },
  "MixtralMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MixtralSparseMoeBlock": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MixtralAttention": {
    "__init__": [
      "self",
      "config",
      "layerwise_recompute"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "past_key_value",
      "attention_mask",
      "output_attentions",
      "use_cache"
    ]
  },
  "MixtralDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layerwise_recompute"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "attention_mask",
      "output_attentions",
      "output_router_logits",
      "past_key_value",
      "use_cache"
    ]
  },
  "MixtralPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "MixtralModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prepare_decoder_attention_mask": [
      "attention_mask",
      "input_shape",
      "past_key_values_length",
      "dtype"
    ],
    "recompute_training_full": [
      "self",
      "layer_module",
      "hidden_states",
      "position_ids",
      "attention_mask",
      "output_attentions",
      "output_router_logits",
      "past_key_value",
      "use_cache"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "output_router_logits",
      "return_dict"
    ]
  },
  "MixtralPretrainingCriterion": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "masked_lm_labels"
    ]
  },
  "MixtralLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "tensor_parallel_output"
    ]
  },
  "MixtralForCausalLM": {
    "enable_to_static_method": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "use_cache",
      "past_key_values",
      "inputs_embeds",
      "output_router_logits"
    ],
    "_get_model_inputs_spec": [
      "self",
      "dtype"
    ],
    "update_model_kwargs_for_generation": [
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "output_router_logits",
      "return_dict"
    ]
  },
  "MixtralConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "max_position_embeddings",
      "seq_length",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "use_recompute",
      "recompute_granularity",
      "no_recompute_layers",
      "use_flash_attention",
      "attention_dropout",
      "use_fused_rope",
      "rope_theta",
      "tensor_parallel_output",
      "sequence_parallel",
      "fuse_sequence_parallel_allreduce",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings",
      "num_experts_per_tok",
      "num_local_experts",
      "router_aux_loss_coef",
      "output_router_logits",
      "sliding_window"
    ]
  },
  "lowercase_and_remove_accent": [
    "text"
  ],
  "replace_unicode_punct": [
    "text"
  ],
  "remove_non_printing_char": [
    "text"
  ],
  "romanian_preprocessing": [
    "text"
  ],
  "XLMTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "unk_token",
      "bos_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "additional_special_tokens",
      "lang2id",
      "id2lang",
      "do_lowercase_and_remove_accent"
    ],
    "do_lower_case": [
      "self"
    ],
    "moses_punct_norm": [
      "self",
      "text",
      "lang"
    ],
    "moses_tokenize": [
      "self",
      "text",
      "lang"
    ],
    "moses_pipeline": [
      "self",
      "text",
      "lang"
    ],
    "ja_tokenize": [
      "self",
      "text"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "_tokenize": [
      "self",
      "text",
      "lang",
      "bypass_tokenizer"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ]
  },
  "get_masks": [
    "seqlen",
    "lengths",
    "causal",
    "padding_mask"
  ],
  "TransformerFFN": {
    "__init__": [
      "self",
      "in_dim",
      "dim_hidden",
      "out_dim",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "XLMPretrainedModel": {
    "pretrained_init_configuration": [],
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "model_config_file": [],
    "config_class": [],
    "base_model_prefix": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "XLMModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "langs",
      "attention_mask",
      "position_ids",
      "lengths",
      "cache",
      "output_attentions",
      "output_hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ]
  },
  "XLMPredLayer": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "x",
      "y"
    ]
  },
  "XLMWithLMHeadModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "langs",
      "attention_mask",
      "position_ids",
      "lengths",
      "cache",
      "labels"
    ]
  },
  "XLMForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "langs",
      "attention_mask",
      "position_ids",
      "lengths"
    ]
  },
  "XLMForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "langs",
      "attention_mask",
      "position_ids",
      "lengths"
    ]
  },
  "XLMForQuestionAnsweringSimple": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "langs",
      "attention_mask",
      "position_ids",
      "lengths"
    ]
  },
  "XLMForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "langs",
      "attention_mask",
      "position_ids",
      "lengths"
    ]
  },
  "XLM_PRETRAINED_INIT_CONFIGURATION": [],
  "XLM_PRETRAINED_RESOURCE_FILES_MAP": [],
  "XLMConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "emb_dim",
      "n_layers",
      "n_heads",
      "dropout",
      "attention_dropout",
      "gelu_activation",
      "hidden_act",
      "sinusoidal_embeddings",
      "causal",
      "asm",
      "n_langs",
      "use_lang_emb",
      "max_position_embeddings",
      "embed_init_std",
      "layer_norm_eps",
      "init_std",
      "bos_index",
      "eos_index",
      "pad_index",
      "unk_index",
      "mask_index",
      "is_encoder",
      "summary_type",
      "summary_use_proj",
      "summary_activation",
      "summary_proj_to_labels",
      "summary_first_dropout",
      "start_n_top",
      "end_n_top",
      "mask_token_id",
      "lang_id",
      "pad_token_id",
      "bos_token_id"
    ]
  },
  "LayoutLMv2Tokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": []
  },
  "LayoutLMv2Pooler": {
    "__init__": [
      "self",
      "hidden_size",
      "with_pool"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LayoutLMv2Embeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "_cal_spatial_position_embeddings": [
      "self",
      "bbox"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "token_type_ids",
      "position_ids"
    ]
  },
  "LayoutLMv2PretrainedModel": {
    "model_config_file": [],
    "config_class": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "LayoutLMv2SelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "LayoutLMv2SelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "compute_qkv": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "rel_pos",
      "rel_2d_pos"
    ]
  },
  "LayoutLMv2Attention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "rel_pos",
      "rel_2d_pos"
    ]
  },
  "LayoutLMv2Encoder": {
    "__init__": [
      "self",
      "config"
    ],
    "_cal_1d_pos_emb": [
      "self",
      "hidden_states",
      "position_ids"
    ],
    "_cal_2d_pos_emb": [
      "self",
      "hidden_states",
      "bbox"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "bbox",
      "position_ids"
    ]
  },
  "LayoutLMv2Intermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LayoutLMv2Output": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "LayoutLMv2Layer": {
    "__init__": [
      "self",
      "config"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "rel_pos",
      "rel_2d_pos"
    ]
  },
  "LayoutLMv2Model": {
    "__init__": [
      "self",
      "config"
    ],
    "_calc_text_embeddings": [
      "self",
      "input_ids",
      "bbox",
      "position_ids",
      "token_type_ids"
    ],
    "_calc_img_embeddings": [
      "self",
      "image",
      "bbox",
      "position_ids"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "head_mask",
      "output_hidden_states",
      "output_attentions"
    ]
  },
  "LayoutLMv2ForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "labels"
    ]
  },
  "LayoutLMv2PredictionHead": {
    "__init__": [
      "self",
      "hidden_size",
      "vocab_size",
      "activation",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states",
      "masked_positions"
    ]
  },
  "LayoutLMv2PretrainingHeads": {
    "__init__": [
      "self",
      "hidden_size",
      "vocab_size",
      "activation",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "sequence_output",
      "masked_positions"
    ]
  },
  "LayoutLMv2ForPretraining": {
    "__init__": [
      "self",
      "config"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "image",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "masked_positions"
    ]
  },
  "LayoutLMv2ForRelationExtraction": {
    "__init__": [
      "self",
      "config"
    ],
    "_init_weights": [
      "self",
      "layer"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "bbox",
      "labels",
      "image",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "entities",
      "relations"
    ]
  },
  "LAYOUTLMV2_PRETRAINED_INIT_CONFIGURATION": [],
  "LAYOUTLMV2_PRETRAINED_RESOURCE_FILES_MAP": [],
  "LayoutLMv2Config": {
    "pretrained_init_configuration": [],
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "max_2d_position_embeddings",
      "max_rel_pos",
      "max_rel_2d_pos",
      "rel_pos_bins",
      "rel_2d_pos_bins",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "coordinate_size",
      "shape_size",
      "image_feature_pool_shape",
      "fast_qkv",
      "has_relative_attention_bias",
      "has_spatial_attention_bias",
      "has_visual_segment_embedding",
      "output_past",
      "gradient_checkpointing",
      "classifier_dropout",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "use_cache",
      "with_pool",
      "use_visual_backbone"
    ]
  },
  "person_token": [],
  "temp_token": [],
  "HashtagProcessor": {
    "__init__": [
      "self",
      "wiki_word_frequency"
    ],
    "__call__": [
      "self",
      "s"
    ],
    "_split": [
      "self",
      "s"
    ]
  },
  "replace_person_token": [
    "t"
  ],
  "fix_html": [
    "t"
  ],
  "replace_punctuation_with_commas": [
    "t"
  ],
  "simplify_quotes": [
    "t"
  ],
  "merge_quotes": [
    "t"
  ],
  "remove_comma_numbers": [
    "t"
  ],
  "pre_process_dot_numbers": [
    "t"
  ],
  "post_process_dot_numbers": [
    "t"
  ],
  "pre_process_quotes": [
    "t"
  ],
  "post_process_quotes": [
    "t"
  ],
  "pre_process_dates": [
    "t"
  ],
  "post_process_dates": [
    "t"
  ],
  "merge_commas": [
    "t"
  ],
  "add_space_after_commas": [
    "t"
  ],
  "handle_special_chars": [
    "t"
  ],
  "expand_hashtags": [
    "t",
    "hashtag_processor"
  ],
  "_re_ignore_chars": [],
  "ignore_chars": [
    "t"
  ],
  "remove_extra_spaces": [
    "t"
  ],
  "remove_repeating_chars": [
    "t"
  ],
  "remove_urls": [
    "t"
  ],
  "remove_html_tags": [
    "t"
  ],
  "remove_first_last_commas": [
    "t"
  ],
  "remove_wiki_ref": [
    "t"
  ],
  "TextNormalizer": {
    "__init__": [
      "self",
      "wiki_word_frequency_file"
    ],
    "__call__": [
      "self",
      "t"
    ]
  },
  "DalleBartTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "wiki_word_frequency_file",
      "normalize_text",
      "errors",
      "max_len",
      "bos_token",
      "eos_token",
      "cls_token",
      "sep_token",
      "unk_token",
      "pad_token",
      "mask_token"
    ],
    "_bpe_encode": [
      "self",
      "text"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "max_length",
      "stride",
      "is_split_into_words",
      "padding",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "add_special_tokens",
      "pad_to_multiple_of",
      "return_tensors",
      "verbose"
    ]
  },
  "DalleBartPretrainedModel": {
    "base_model_prefix": [],
    "model_config_file": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "DalleBartLearnedPositionalEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim"
    ],
    "forward": [
      "self",
      "input_ids_shape",
      "past_key_values_length"
    ]
  },
  "GLU": {
    "__init__": [
      "self",
      "count_in_out",
      "count_middle",
      "activation_dropout",
      "dropout",
      "activation_function",
      "use_bias"
    ],
    "forward": [
      "self",
      "z"
    ]
  },
  "DalleBartEncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "src",
      "src_mask"
    ]
  },
  "DalleBartEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "DalleBartDecoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "cache"
    ],
    "gen_cache": [
      "self",
      "memory"
    ]
  },
  "DalleBartDecoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "memory_mask",
      "cache"
    ],
    "gen_cache": [
      "self",
      "memory",
      "do_zip"
    ]
  },
  "DalleBartModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "use_cache",
      "cache"
    ]
  },
  "DalleBartForConditionalGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "use_cache",
      "cache"
    ],
    "prepare_decoder_input_ids_from_labels": [
      "self",
      "labels"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "decoder_input_ids",
      "attention_mask",
      "decoder_attention_mask",
      "cache",
      "use_cache",
      "encoder_output"
    ],
    "sample": [
      "self",
      "input_ids",
      "logits_processors",
      "max_length",
      "pad_token_id",
      "eos_token_id",
      "top_k",
      "top_p",
      "temperature",
      "min_tokens_to_keep",
      "condition_scale",
      "model_kwargs_uncond"
    ],
    "generate": [
      "self",
      "input_ids",
      "max_length",
      "min_length",
      "decode_strategy",
      "temperature",
      "top_k",
      "top_p",
      "repetition_penalty",
      "num_beams",
      "num_beam_groups",
      "length_penalty",
      "early_stopping",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "text_pad_token_id",
      "decoder_start_token_id",
      "forced_bos_token_id",
      "forced_eos_token_id",
      "num_return_sequences",
      "diversity_rate",
      "use_cache",
      "use_fast",
      "use_fp16_decoding",
      "condition_scale"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "ResnetBlock": {
    "__init__": [
      "self",
      "log2_count_in",
      "log2_count_out"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AttentionBlock": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MiddleLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "h"
    ]
  },
  "Upsample": {
    "__init__": [
      "self",
      "log2_count"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UpsampleBlock": {
    "__init__": [
      "self",
      "log2_count_in",
      "log2_count_out",
      "has_attention",
      "has_upsample"
    ],
    "forward": [
      "self",
      "h"
    ]
  },
  "Decoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "z"
    ]
  },
  "DALLEBART_PRETRAINED_RESOURCE_FILES_MAP": [],
  "DALLEBART_PRETRAINED_INIT_CONFIGURATION": [],
  "DalleBartConfig": {
    "pretrained_init_configuration": [],
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "image_vocab_size",
      "bos_token_id",
      "pad_token_id",
      "eos_token_id",
      "max_text_length",
      "max_image_length",
      "decoder_start_token_id",
      "d_model",
      "num_encoder_layers",
      "num_decoder_layers",
      "encoder_attention_heads",
      "decoder_attention_heads",
      "encoder_ffn_dim",
      "decoder_ffn_dim",
      "dropout",
      "activation_function",
      "attention_dropout",
      "activation_dropout",
      "use_bias",
      "init_std"
    ]
  },
  "__repr__": [
    "self"
  ],
  "LlamaEmbeddingPipe": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "args"
    ]
  },
  "LlamaDecoderLayerPipe": {
    "forward": [
      "self",
      "args"
    ]
  },
  "LlamaRMSNormPipe": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "args"
    ]
  },
  "LlamaForCausalLMPipe": {
    "config_class": [],
    "_get_tensor_parallel_mappings": [],
    "_get_fuse_or_split_param_mappings": [],
    "_init_weights": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "is_pp_enable": [],
  "global_mesh_starts_with_pp": [],
  "LlamaRMSNormAuto": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LlamaMLPAuto": {
    "__init__": [
      "self",
      "config",
      "ipp"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LlamaAttentionAuto": {
    "__init__": [
      "self",
      "config",
      "layerwise_recompute",
      "ipp"
    ],
    "_init_rope": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "past_key_value",
      "attention_mask",
      "output_attentions",
      "use_cache",
      "alibi"
    ]
  },
  "LlamaDecoderLayerAuto": {
    "__init__": [
      "self",
      "config",
      "layerwise_recompute",
      "ipp"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "attention_mask",
      "output_attentions",
      "past_key_value",
      "use_cache",
      "alibi"
    ]
  },
  "LlamaPretrainedModelAuto": {
    "config_class": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ]
  },
  "LlamaModelAuto": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prepare_decoder_attention_mask": [
      "attention_mask",
      "input_shape",
      "past_key_values_length",
      "dtype"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "LlamaPretrainingCriterion3DAuto": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "masked_lm_labels"
    ]
  },
  "LlamaLMHeadAuto": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "tensor_parallel_output"
    ]
  },
  "LlamaForCausalLM3DAuto": {
    "enable_to_static_method": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "use_cache",
      "past_key_values",
      "inputs_embeds"
    ],
    "_get_model_inputs_spec": [
      "self",
      "dtype"
    ],
    "update_model_kwargs_for_generation": [
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "forward": [
      "self",
      "input_ids",
      "labels",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "LlamaTokenizer": {
    "model_input_names": [],
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "unk_token",
      "bos_token",
      "eos_token",
      "add_bos_token",
      "add_eos_token",
      "sp_model_kwargs",
      "decode_with_prefix_space"
    ],
    "vocab_size": [
      "self"
    ],
    "bos_token_id": [
      "self"
    ],
    "eos_token_id": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ]
  },
  "BEGINOFTEXT": [],
  "EOTID": [],
  "Llama3Tokenizer": {
    "model_input_names": [],
    "resource_files_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "errors",
      "padding_side"
    ],
    "__len__": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "_add_tokens": [
      "self",
      "new_tokens",
      "special_tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory"
    ],
    "tokenize": [
      "self",
      "text",
      "allowed_special",
      "disallowed_special"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "vocab_size": [
      "self"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "errors"
    ],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ]
  },
  "_get_interleave": [
    "n"
  ],
  "LlamaRMSNorm": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LlamaRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "base"
    ],
    "_set_cos_sin_cache": [
      "self",
      "seq_len"
    ],
    "forward": [
      "self",
      "x",
      "seq_len"
    ]
  },
  "LlamaLinearScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "base",
      "scaling_factor"
    ],
    "_set_cos_sin_cache": [
      "self",
      "seq_len"
    ]
  },
  "LlamaNTKScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "base",
      "scaling_factor"
    ]
  },
  "LlamaDynamicNTKScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "base",
      "scaling_factor"
    ],
    "_scale_cos_sin": [
      "self",
      "seq_len"
    ],
    "forward": [
      "self",
      "x",
      "seq_len"
    ]
  },
  "LlamaMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LlamaAttention": {
    "__init__": [
      "self",
      "config",
      "layerwise_recompute"
    ],
    "_init_rope": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "past_key_value",
      "attention_mask",
      "output_attentions",
      "use_cache",
      "alibi",
      "npu_is_casual"
    ]
  },
  "LlamaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layerwise_recompute"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "attention_mask",
      "output_attentions",
      "past_key_value",
      "use_cache",
      "alibi",
      "npu_is_casual"
    ]
  },
  "LlamaPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ],
    "_get_fuse_or_split_param_mappings": [
      "cls",
      "config",
      "is_fuse"
    ],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "LlamaModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prepare_decoder_attention_mask": [
      "attention_mask",
      "input_shape",
      "past_key_values_length",
      "dtype"
    ],
    "recompute_training_full": [
      "self",
      "layer_module",
      "hidden_states",
      "position_ids",
      "attention_mask",
      "output_attentions",
      "past_key_value",
      "use_cache",
      "alibi"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "LlamaPretrainingCriterion": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "masked_lm_labels"
    ]
  },
  "ConcatSePMaskedLoss": {
    "forward": [
      "ctx",
      "inp",
      "axis",
      "group"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "LlamaLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "tensor_parallel_output"
    ]
  },
  "LlamaForCausalLM": {
    "enable_to_static_method": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "use_cache",
      "past_key_values",
      "inputs_embeds"
    ],
    "_get_model_inputs_spec": [
      "self",
      "dtype"
    ],
    "update_model_kwargs_for_generation": [
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "get_dist_attr": [
    "shard_specs",
    "pp_idx"
  ],
  "LlamaPretrainingCriterionAuto": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "masked_lm_labels"
    ]
  },
  "LlamaForCausalLMAuto": {
    "enable_to_static_method": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "use_cache",
      "past_key_values",
      "inputs_embeds"
    ],
    "_get_model_inputs_spec": [
      "self",
      "dtype"
    ],
    "update_model_kwargs_for_generation": [
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "forward": [
      "self",
      "input_ids",
      "labels",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "LLAMA_PRETRAINED_INIT_CONFIGURATION": [],
  "LLAMA_PRETRAINED_RESOURCE_FILES_MAP": [],
  "LlamaConfig": {
    "model_type": [],
    "attribute_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "max_position_embeddings",
      "seq_length",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "initializer_range",
      "rms_norm_eps",
      "rope_theta",
      "use_cache",
      "use_recompute",
      "recompute_granularity",
      "pp_recompute_interval",
      "no_recompute_layers",
      "fuse_attention_qkv",
      "fuse_attention_ffn",
      "use_flash_attention",
      "use_fused_rms_norm",
      "use_fused_rope",
      "tensor_parallel_output",
      "sequence_parallel",
      "fuse_sequence_parallel_allreduce",
      "virtual_pp_degree",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings",
      "alibi",
      "rope_scaling_factor",
      "rope_scaling_type",
      "long_sequence_strategy_type",
      "long_sequence_strategy_name",
      "long_sequence_init_args",
      "use_long_sequence_strategies"
    ],
    "rope": [
      "self"
    ]
  },
  "NeZhaTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "padding_side": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "get_vocab": [
      "self"
    ]
  },
  "NeZhaAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "generate_relative_positions_embeddings": [
      "self",
      "length",
      "depth",
      "max_relative_position"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "NeZhaLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "NeZhaEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "NeZhaEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "inputs_embeds"
    ]
  },
  "NeZhaPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "NeZhaPretrainedModel": {
    "model_config_file": [],
    "config_class": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "NeZhaModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ]
  },
  "NeZhaLMPredictionHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "NeZhaPretrainingHeads": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "sequence_output",
      "pooled_output"
    ]
  },
  "NeZhaForPreTrainingOutput": {},
  "NeZhaForPretraining": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "inputs_embeds",
      "masked_lm_labels",
      "next_sentence_label",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "NeZhaForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "NeZhaForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "NeZhaForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "NeZhaForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "NEZHA_PRETRAINED_INIT_CONFIGURATION": [],
  "NEZHA_PRETRAINED_RESOURCE_FILES_MAP": [],
  "NeZhaConfig": {
    "pretrained_init_configuration": [],
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "embedding_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "max_relative_position",
      "type_vocab_size",
      "initializer_range",
      "layer_norm_eps",
      "classifier_dropout",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "use_cache"
    ]
  },
  "BlenderbotSmallTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "max_len",
      "special_tokens",
      "bos_token",
      "eos_token",
      "unk_token",
      "pad_token",
      "eol_token"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "convert_ids_to_string": [
      "self",
      "ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ]
  },
  "BlenderbotSmallLearnedPositionalEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids_shape",
      "past_key_values_length"
    ]
  },
  "BlenderbotSmallPretrainedModel": {
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "BlenderbotSmallDecoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "dim_feedforward",
      "dropout",
      "activation",
      "attn_dropout",
      "act_dropout",
      "normalize_before",
      "weight_attr",
      "bias_attr"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "cache"
    ]
  },
  "BlenderbotSmallEncoder": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "BlenderbotSmallDecoder": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "memory_mask",
      "use_cache",
      "cache"
    ]
  },
  "BlenderbotSmallModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "use_cache",
      "cache"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_encoder": [
      "self"
    ]
  },
  "BlenderbotSmallForConditionalGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "use_cache",
      "cache"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "decoder_input_ids",
      "attention_mask",
      "encoder_output",
      "use_cache",
      "cache"
    ],
    "get_encoder": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "BlenderbotSmallForCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "use_cache",
      "cache"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "attention_mask",
      "use_cache",
      "cache"
    ]
  },
  "BLENDERBOTSMALL_PRETRAINED_INIT_CONFIGURATION": [],
  "BLENDERBOTSMALL_PRETRAINED_RESOURCE_FILES_MAP": [],
  "BlenderbotSmallConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "bos_token_id",
      "pad_token_id",
      "eos_token_id",
      "decoder_start_token_id",
      "d_model",
      "num_encoder_layers",
      "num_decoder_layers",
      "encoder_attention_heads",
      "decoder_attention_heads",
      "encoder_ffn_dim",
      "decoder_ffn_dim",
      "dropout",
      "activation_function",
      "attention_dropout",
      "activation_dropout",
      "max_position_embeddings",
      "init_std",
      "scale_embedding",
      "normalize_before"
    ]
  },
  "TinyBertTokenizer": {
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": []
  },
  "TinyBertPretrainedModel": {
    "model_config_file": [],
    "config_class": [],
    "resource_files_names": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "TinyBertModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "embedding"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "past_key_values",
      "use_cache",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "TinyBertForPretraining": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "TinyBertForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "labels",
      "inputs_embeds",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "TinyBertForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "start_positions",
      "end_positions",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "TinyBertForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "output_hidden_states",
      "output_attentions",
      "return_dict"
    ]
  },
  "TinyBertFastTokenizer": {
    "resource_files_names": [],
    "slow_tokenizer_class": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "tokenizer_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ]
  },
  "TINYBERT_PRETRAINED_INIT_CONFIGURATION": [],
  "TINYBERT_PRETRAINED_RESOURCE_FILES_MAP": [],
  "TinyBertConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "pool_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "layer_norm_eps",
      "initializer_range",
      "pad_token_id",
      "fit_size"
    ]
  },
  "VisualGLMProcessor": {
    "attributes": [],
    "image_processor_class": [],
    "tokenizer_class": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer"
    ],
    "process_images": [
      "self",
      "images",
      "return_tensors"
    ],
    "process_texts": [
      "self",
      "texts",
      "return_tensors"
    ],
    "build_inputs_with_image": [
      "self",
      "image",
      "query",
      "history"
    ],
    "__call__": [
      "self",
      "image",
      "query",
      "history"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "process_response": [
      "self",
      "response"
    ],
    "get_responses": [
      "self"
    ],
    "model_input_names": [
      "self"
    ]
  },
  "VisualGLMImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb"
    ],
    "resize": [
      "self",
      "image",
      "size",
      "resample",
      "data_format"
    ],
    "rescale": [
      "self",
      "image",
      "scale",
      "data_format"
    ],
    "normalize": [
      "self",
      "image",
      "mean",
      "std",
      "data_format"
    ],
    "preprocess": [
      "self",
      "images",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "return_tensors",
      "do_convert_rgb",
      "data_format"
    ]
  },
  "VisualGLM_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "VisualGLMForConditionalGenerationModelOutput": {
    "to_tuple": [
      "self"
    ]
  },
  "VisualGLMPretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_keys_to_ignore_on_load_missing": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "_set_gradient_checkpointing": [
      "self",
      "module",
      "value"
    ]
  },
  "VisualGLMVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "VisualGLMAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states",
      "head_mask",
      "output_attentions"
    ]
  },
  "VisualGLMMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "VisualGLMEncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions"
    ]
  },
  "VisualGLMEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "VisualGLMVisionModel": {
    "main_input_name": [],
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "VisualGLMQFormerMultiHeadAttention": {
    "__init__": [
      "self",
      "config",
      "is_cross_attention"
    ],
    "save_attn_gradients": [
      "self",
      "attn_gradients"
    ],
    "get_attn_gradients": [
      "self"
    ],
    "save_attention_map": [
      "self",
      "attention_map"
    ],
    "get_attention_map": [
      "self"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "VisualGLMQFormerSelfOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "VisualGLMQFormerAttention": {
    "__init__": [
      "self",
      "config",
      "is_cross_attention"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions"
    ]
  },
  "VisualGLMQFormerIntermediate": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "VisualGLMQFormerOutput": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "VisualGLMQFormerLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "query_length"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ],
    "feed_forward_chunk_query": [
      "self",
      "attention_output"
    ]
  },
  "VisualGLMQFormerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "query_length"
    ]
  },
  "VisualGLMQFormerModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "get_extended_attention_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "has_query"
    ],
    "invert_attention_mask": [
      "self",
      "encoder_attention_mask"
    ],
    "get_head_mask": [
      "self",
      "head_mask",
      "num_hidden_layers",
      "is_attention_chunked"
    ],
    "_convert_head_mask_to_5d": [
      "self",
      "head_mask",
      "num_hidden_layers"
    ],
    "forward": [
      "self",
      "query_embeds",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "VisualGLMModel": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_text_features": [
      "self",
      "input_ids",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "get_qformer_features": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "forward": [
      "self",
      "pixel_values",
      "first_input_ids",
      "second_input_ids",
      "first_attention_mask",
      "second_attention_mask",
      "output_attentions",
      "output_hidden_states",
      "labels",
      "return_dict"
    ]
  },
  "ChatGLMForConditionalGenerationWithImage": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "image_features",
      "input_ids",
      "position_ids",
      "attention_mask",
      "pre_image_length",
      "cache",
      "inputs_embeds",
      "labels",
      "use_cache",
      "return_dict"
    ]
  },
  "VisualGLMForConditionalGeneration": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "encode_images": [
      "self",
      "pixel_values"
    ],
    "generate": [
      "self",
      "pixel_values",
      "input_ids",
      "pre_image_length",
      "attention_mask"
    ]
  },
  "VisualGLMVisionConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "hidden_act",
      "layer_norm_eps",
      "dropout",
      "attention_dropout",
      "initializer_range",
      "initializer_factor",
      "qkv_bias"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "VisualGLMQFormerConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "initializer_range",
      "layer_norm_eps",
      "pad_token_id",
      "position_embedding_type",
      "classifier_dropout",
      "cross_attention_frequency",
      "encoder_hidden_size"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "VisualGLMConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vision_config",
      "qformer_config",
      "text_config",
      "num_query_tokens"
    ],
    "from_vision_qformer_text_configs": [
      "cls",
      "vision_config",
      "qformer_config",
      "text_config"
    ],
    "to_dict": [
      "self"
    ]
  },
  "BlenderbotTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "max_len",
      "special_tokens",
      "bos_token",
      "eos_token",
      "cls_token",
      "sep_token",
      "pad_token",
      "unk_token",
      "mask_token",
      "eol_token",
      "add_prefix"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "prepare_for_tokenization": [
      "self",
      "text",
      "is_split_into_words"
    ]
  },
  "BlenderbotPretrainedModel": {
    "base_model_prefix": [],
    "config_class": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "BlenderbotLearnedPositionalEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids_shape",
      "past_key_values_length"
    ]
  },
  "BlenderbotEncoder": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "BlenderbotDecoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "dim_feedforward",
      "dropout",
      "activation",
      "attn_dropout",
      "act_dropout",
      "normalize_before",
      "weight_attr",
      "bias_attr"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "cache"
    ]
  },
  "BlenderbotDecoder": {
    "__init__": [
      "self",
      "config",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "memory_mask",
      "use_cache",
      "cache"
    ]
  },
  "BlenderbotModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "use_cache",
      "cache"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_encoder": [
      "self"
    ]
  },
  "BlenderbotForConditionalGeneration": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_output",
      "use_cache",
      "cache"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "decoder_input_ids",
      "attention_mask",
      "encoder_output",
      "use_cache",
      "cache"
    ],
    "get_encoder": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "BlenderbotForCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "use_cache",
      "cache"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "attention_mask",
      "use_cache",
      "cache"
    ]
  },
  "BLENDERBOT_PRETRAINED_INIT_CONFIGURATION": [],
  "BLENDERBOT_PRETRAINED_RESOURCE_FILES_MAP": [],
  "BlenderbotConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "bos_token_id",
      "pad_token_id",
      "eos_token_id",
      "decoder_start_token_id",
      "d_model",
      "num_encoder_layers",
      "num_decoder_layers",
      "encoder_attention_heads",
      "decoder_attention_heads",
      "encoder_ffn_dim",
      "decoder_ffn_dim",
      "dropout",
      "activation_function",
      "attention_dropout",
      "activation_dropout",
      "max_position_embeddings",
      "init_std",
      "scale_embedding",
      "normalize_before"
    ]
  },
  "RoFormerv2Tokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "get_vocab": [
      "self"
    ]
  },
  "RoFormerv2Embeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids"
    ]
  },
  "RoFormerv2PretrainedModel": {
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "RoFormerv2Model": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "output_hidden_states"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "embedding"
    ]
  },
  "RoFormerv2ForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ]
  },
  "RoFormerv2ForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ]
  },
  "RoFormerv2ForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ]
  },
  "RoFormerv2ForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ]
  },
  "RoFormerv2LMPredictionHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "RoFormerv2ForMaskedLM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ]
  },
  "ROFORMERV2_PRETRAINED_INIT_CONFIGURATION": [],
  "ROFORMERV2_PRETRAINED_RESOURCE_FILES_MAP": [],
  "RoFormerv2Config": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "act_dropout",
      "max_position_embeddings",
      "type_vocab_size",
      "pad_token_id",
      "rotary_value",
      "use_bias",
      "epsilon",
      "normalize_before",
      "num_choices"
    ]
  },
  "UNIMOTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token"
    ],
    "vocab_size": [
      "self"
    ],
    "load_vocabulary": [
      "filepath",
      "unk_token",
      "pad_token",
      "bos_token",
      "eos_token"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "merge_subword": [
      "self",
      "tokens"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "gen_encode": [
      "self",
      "source",
      "title",
      "target",
      "max_seq_len",
      "max_title_len",
      "max_target_len",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "add_start_token_for_decoding",
      "pad_to_max_seq_len",
      "return_tensors",
      "is_split_into_words",
      "continuous_position"
    ]
  },
  "UNIMOPretrainedModel": {
    "model_config_file": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "config_class": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "UNIMOEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "input_embeddings"
    ]
  },
  "UNIMOModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "use_cache",
      "cache",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "UNIMOLMHead": {
    "__init__": [
      "self",
      "hidden_size",
      "vocab_size",
      "activation",
      "embedding_weights"
    ],
    "forward": [
      "self",
      "hidden_states",
      "masked_positions"
    ]
  },
  "UNIMOLMHeadModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "masked_positions",
      "use_cache",
      "cache",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_fast_entry": [
      "self",
      "kwargs"
    ],
    "adjust_logits_during_generation": [
      "self",
      "logits"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "use_cache",
      "cache"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "UNIMOForMaskedLM": [],
  "UNIMOForConditionalGeneration": [],
  "UNIMO_PRETRAINED_INIT_CONFIGURATION": [],
  "UNIMO_PRETRAINED_RESOURCE_FILES_MAP": [],
  "UNIMOConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "normalize_before",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "unk_token_id",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "mask_token_id"
    ]
  },
  "PPMiniLMTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "do_basic_tokenize",
      "never_split",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ]
  },
  "PPMiniLMEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids"
    ]
  },
  "PPMiniLMPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "PPMiniLMPretrainedModel": {
    "model_config_file": [],
    "config_class": [],
    "resource_files_names": [],
    "base_model_prefix": [],
    "pretrained_init_configuration": [],
    "pretrained_resource_files_map": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "PPMiniLMModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "PPMiniLMForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "PPMiniLMForQuestionAnswering": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "PPMiniLMForMultipleChoice": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "PPMINILM_PRETRAINED_INIT_CONFIGURATION": [],
  "PPMINILM_PRETRAINED_RESOURCE_FILES_MAP": [],
  "PPMiniLMConfig": {
    "model_type": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id",
      "do_lower_case",
      "is_split_into_words",
      "max_seq_len",
      "pad_to_max_seq_len",
      "layer_norm_eps"
    ]
  },
  "bos_config": [],
  "bos_host": [],
  "bos_bucket": [],
  "access_key_id": [],
  "secret_access_key": [],
  "upload_to_bos_from_raw": [
    "raw",
    "name",
    "category"
  ],
  "multi_upload_to_bos": [
    "filename",
    "name",
    "category"
  ],
  "load_all_models": [
    "include_community"
  ],
  "app": [],
  "download": [
    "model_name",
    "cache_dir",
    "force_download"
  ],
  "search": [
    "query",
    "include_community"
  ],
  "server": [
    "app",
    "host",
    "port",
    "app_dir",
    "workers",
    "log_level",
    "limit_concurrency",
    "limit_max_requests",
    "timeout_keep_alive",
    "reload"
  ],
  "install": [
    "package"
  ],
  "main": [],
  "PACKAGE_SERVER_HOME": [],
  "install_package_from_bos": [
    "package_name",
    "tag"
  ],
  "start_backend": [
    "app"
  ],
  "COMMUNITY_MODEL_CONFIG_FILE_NAME": [],
  "load_community_models": [],
  "_get_highlighter": [
    "word"
  ],
  "print_example_code": [],
  "tabulate": [
    "tables",
    "headers",
    "highlight_word"
  ],
  "get_unfinished_flag": [
    "input_ids",
    "unfinished_flag",
    "eos_token_id"
  ],
  "BeamHypotheses": {
    "__init__": [
      "self",
      "num_beams",
      "length_penalty",
      "early_stopping"
    ],
    "__len__": [
      "self"
    ],
    "add": [
      "self",
      "hyp",
      "sum_logprobs",
      "origin_len"
    ],
    "is_done": [
      "self",
      "best_sum_logprobs",
      "cur_len",
      "origin_len"
    ]
  },
  "BeamSearchScorer": {
    "__init__": [
      "self",
      "batch_size",
      "max_length",
      "num_beams",
      "length_penalty",
      "do_early_stopping",
      "num_beam_hyps_to_keep",
      "num_beam_groups"
    ],
    "is_done": [
      "self"
    ],
    "process": [
      "self",
      "input_ids",
      "next_scores",
      "next_tokens",
      "next_indices",
      "origin_len",
      "pad_token_id",
      "eos_token_id"
    ],
    "finalize": [
      "self",
      "input_ids",
      "final_beam_scores",
      "final_beam_tokens",
      "final_beam_indices",
      "origin_len",
      "pad_token_id",
      "eos_token_id"
    ]
  },
  "GenerationMixin": {
    "enable_to_static_method": [],
    "prepare_input_ids_for_generation": [
      "bos_token_id",
      "encoder_output"
    ],
    "prepare_attention_mask_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "prepare_seq_len_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "get_logits_processor": [
      "self",
      "min_length",
      "max_length",
      "eos_token_id",
      "forced_bos_token_id",
      "forced_eos_token_id",
      "num_beams",
      "num_beam_groups",
      "diversity_rate",
      "repetition_penalty",
      "no_repeat_ngram_size",
      "logits_processors"
    ],
    "expand_inputs_for_generation": [
      "input_ids",
      "expand_size",
      "attention_mask"
    ],
    "update_model_kwargs_for_generation": [
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "update_scores_for_generation": [
      "scores",
      "next_scores",
      "length",
      "unfinished_flag"
    ],
    "prepare_encoder_decoder_kwargs_for_generation": [
      "self",
      "input_ids",
      "model_kwargs"
    ],
    "prepare_decoder_input_ids_for_generation": [
      "self",
      "input_ids",
      "decoder_start_token_id",
      "bos_token_id"
    ],
    "get_decoder_start_token_id": [
      "self",
      "decoder_start_token_id",
      "bos_token_id"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids"
    ],
    "adjust_logits_during_generation": [
      "self",
      "logits"
    ],
    "prepare_fast_entry": [
      "self",
      "kwargs"
    ],
    "_convert_to_fast": [
      "self",
      "kwargs"
    ],
    "_build_fast": [
      "self",
      "kwargs"
    ],
    "generate": [
      "self",
      "input_ids",
      "generation_config",
      "stopping_criteria",
      "streamer",
      "synced_gpus"
    ],
    "greedy_search": [
      "self",
      "input_ids",
      "logits_processors",
      "max_length",
      "pad_token_id",
      "eos_token_id",
      "stopping_criteria",
      "streamer",
      "fast_ptq_sampling",
      "trunc_input",
      "synced_gpus"
    ],
    "sample": [
      "self",
      "input_ids",
      "logits_processors",
      "max_length",
      "pad_token_id",
      "eos_token_id",
      "top_k",
      "top_p",
      "temperature",
      "min_tokens_to_keep",
      "stopping_criteria",
      "streamer",
      "fast_ptq_sampling",
      "trunc_input",
      "synced_gpus"
    ],
    "_get_model_inputs_spec": [
      "self",
      "dtype"
    ],
    "to_static": [
      "self",
      "path",
      "config"
    ],
    "sample_d2s": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "logits_processors",
      "max_new_tokens",
      "pad_token_id",
      "eos_token_id",
      "top_k",
      "top_p",
      "temperature",
      "min_tokens_to_keep"
    ],
    "reorder_cache": [
      "self",
      "cache",
      "beam_idx"
    ],
    "beam_search": [
      "self",
      "input_ids",
      "beam_scorer",
      "logits_processors",
      "max_length",
      "diversity_rate",
      "pad_token_id",
      "eos_token_id",
      "stopping_criteria",
      "fast_ptq_sampling",
      "trunc_input",
      "synced_gpus"
    ],
    "group_beam_search": [
      "self",
      "input_ids",
      "beam_scorer",
      "logits_processors",
      "max_length",
      "pad_token_id",
      "eos_token_id",
      "stopping_criteria",
      "fast_ptq_sampling",
      "trunc_input",
      "synced_gpus"
    ]
  },
  "BaseStreamer": {
    "put": [
      "self",
      "value"
    ],
    "end": [
      "self"
    ]
  },
  "TextStreamer": {
    "__init__": [
      "self",
      "tokenizer",
      "skip_prompt"
    ],
    "put": [
      "self",
      "value"
    ],
    "end": [
      "self"
    ],
    "on_finalized_text": [
      "self",
      "text",
      "stream_end"
    ],
    "_is_chinese_char": [
      "self",
      "cp"
    ]
  },
  "TextIteratorStreamer": {
    "__init__": [
      "self",
      "tokenizer",
      "skip_prompt",
      "timeout"
    ],
    "on_finalized_text": [
      "self",
      "text",
      "stream_end"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ]
  },
  "DEFAULT_MAX_NEW_TOKENS": [],
  "resolve_hf_generation_config_path": [
    "repo_id",
    "cache_dir",
    "subfolder"
  ],
  "GenerationConfig": {
    "_get_generation_mode": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__repr__": [
      "self"
    ],
    "validate": [
      "self",
      "is_init"
    ],
    "save_pretrained": [
      "self",
      "save_directory",
      "config_file_name"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path",
      "from_hf_hub",
      "from_aistudio",
      "config_file_name",
      "cache_dir",
      "force_download"
    ],
    "_dict_from_json_file": [
      "cls",
      "json_file"
    ],
    "dict_paddle_dtype_to_str": [
      "self",
      "d"
    ],
    "from_dict": [
      "cls",
      "config_dict"
    ],
    "to_diff_dict": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "to_json_string": [
      "self",
      "use_diff"
    ],
    "to_json_file": [
      "self",
      "json_file_path",
      "use_diff"
    ],
    "from_model_config": [
      "cls",
      "model_config"
    ],
    "update": [
      "self"
    ]
  },
  "_get_ngrams": [
    "ngram_size",
    "prev_input_ids",
    "num_hypos"
  ],
  "_get_generated_ngrams": [
    "banned_ngrams",
    "prev_input_ids",
    "ngram_size",
    "cur_len"
  ],
  "_calc_banned_ngram_tokens": [
    "ngram_size",
    "prev_input_ids",
    "num_hypos",
    "cur_len"
  ],
  "NoRepeatNGramLogitsProcessor": {
    "__init__": [
      "self",
      "ngram_size"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "TopKProcess": [
    "probs",
    "top_k",
    "min_tokens_to_keep"
  ],
  "TopPProcess": [
    "probs",
    "top_p",
    "min_tokens_to_keep"
  ],
  "LogitsWarper": {
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "TemperatureLogitsWarper": {
    "__init__": [
      "self",
      "temperature"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "SequenceBiasLogitsProcessor": {
    "__init__": [
      "self",
      "sequence_bias"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ],
    "_prepare_bias_variables": [
      "self",
      "scores"
    ],
    "_validate_arguments": [
      "self"
    ]
  },
  "NoBadWordsLogitsProcessor": {
    "__init__": [
      "self",
      "bad_words_ids",
      "eos_token_id"
    ],
    "_validate_arguments": [
      "self"
    ]
  },
  "PrefixConstrainedLogitsProcessor": {
    "__init__": [
      "self",
      "prefix_allowed_tokens_fn",
      "num_beams"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "StoppingCriteria": {
    "__call__": [
      "self",
      "input_ids",
      "logits"
    ]
  },
  "MaxTimeCriteria": {
    "__init__": [
      "self",
      "max_time",
      "initial_timestamp"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "MaxLengthCriteria": {
    "__init__": [
      "self",
      "max_length"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "StoppingCriteriaList": {
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ],
    "max_length": [
      "self"
    ]
  },
  "validate_stopping_criteria": [
    "stopping_criteria",
    "max_length"
  ],
  "RDropLoss": {
    "__init__": [
      "self",
      "reduction"
    ],
    "forward": [
      "self",
      "p",
      "q",
      "pad_mask"
    ]
  },
  "RougeN": {
    "__init__": [
      "self",
      "n"
    ],
    "_get_ngrams": [
      "self",
      "words"
    ],
    "score": [
      "self",
      "evaluated_sentences_ids",
      "reference_sentences_ids"
    ],
    "compute": [
      "self",
      "evaluated_sentences_ids",
      "reference_sentences_ids"
    ],
    "accumulate": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "name": [
      "self"
    ],
    "update": [
      "self",
      "overlapping_count",
      "reference_count"
    ]
  },
  "Rouge1": {
    "__init__": [
      "self"
    ]
  },
  "Rouge2": {
    "__init__": [
      "self"
    ]
  },
  "RougeL": {
    "__init__": [
      "self",
      "trans_func",
      "vocab",
      "gamma",
      "name"
    ],
    "lcs": [
      "self",
      "string",
      "sub"
    ],
    "add_inst": [
      "self",
      "cand",
      "ref_list"
    ],
    "update": [
      "self",
      "output",
      "label",
      "seq_mask"
    ],
    "accumulate": [
      "self"
    ],
    "score": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "name": [
      "self"
    ]
  },
  "RougeLForDuReader": {
    "__init__": [
      "self",
      "alpha",
      "beta",
      "gamma"
    ],
    "add_inst": [
      "self",
      "cand",
      "ref_list",
      "yn_label",
      "yn_ref",
      "entity_ref"
    ],
    "add_yn_bonus": [
      "self",
      "cand",
      "ref",
      "yn_label",
      "yn_ref"
    ],
    "add_entity_bonus": [
      "self",
      "cand",
      "entity_ref"
    ]
  },
  "AccuracyAndF1": {
    "__init__": [
      "self",
      "topk",
      "pos_label",
      "name"
    ],
    "compute": [
      "self",
      "pred",
      "label"
    ],
    "update": [
      "self",
      "correct"
    ],
    "accumulate": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "name": [
      "self"
    ]
  },
  "Mcc": {
    "__init__": [
      "self",
      "name"
    ],
    "compute": [
      "self",
      "pred",
      "label"
    ],
    "update": [
      "self",
      "preds_and_labels"
    ],
    "accumulate": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "name": [
      "self"
    ]
  },
  "PearsonAndSpearman": {
    "__init__": [
      "self",
      "name"
    ],
    "update": [
      "self",
      "preds_and_labels"
    ],
    "accumulate": [
      "self"
    ],
    "pearson": [
      "self",
      "preds",
      "labels"
    ],
    "spearman": [
      "self",
      "preds",
      "labels"
    ],
    "get_rank": [
      "self",
      "raw_list"
    ],
    "reset": [
      "self"
    ],
    "name": [
      "self"
    ]
  },
  "MultiLabelsMetric": {
    "__init__": [
      "self",
      "num_labels",
      "name"
    ],
    "update": [
      "self",
      "args"
    ],
    "accumulate": [
      "self",
      "average",
      "pos_label"
    ],
    "compute": [
      "self",
      "pred",
      "label"
    ],
    "_multi_labels_confusion_matrix": [
      "self",
      "pred",
      "label"
    ],
    "reset": [
      "self"
    ],
    "name": [
      "self"
    ]
  },
  "Distinct": {
    "__init__": [
      "self",
      "n_size",
      "trans_func",
      "name"
    ],
    "update": [
      "self",
      "output"
    ],
    "add_inst": [
      "self",
      "cand"
    ],
    "reset": [
      "self"
    ],
    "accumulate": [
      "self"
    ],
    "score": [
      "self"
    ],
    "name": [
      "self"
    ]
  },
  "DetectionF1": {
    "__init__": [
      "self",
      "pos_label",
      "name"
    ],
    "update": [
      "self",
      "preds",
      "labels",
      "length"
    ],
    "reset": [
      "self"
    ],
    "accumulate": [
      "self"
    ],
    "name": [
      "self"
    ]
  },
  "CorrectionF1": {
    "__init__": [
      "self",
      "pos_label",
      "name"
    ],
    "update": [
      "self",
      "det_preds",
      "det_labels",
      "corr_preds",
      "corr_labels",
      "length"
    ]
  },
  "default_trans_func": [
    "output",
    "label",
    "seq_mask",
    "vocab"
  ],
  "get_match_size": [
    "cand_ngram",
    "refs_ngram"
  ],
  "get_ngram": [
    "sent",
    "n_size",
    "label"
  ],
  "BLEU": {
    "__init__": [
      "self",
      "trans_func",
      "vocab",
      "n_size",
      "weights",
      "name"
    ],
    "update": [
      "self",
      "output",
      "label",
      "seq_mask"
    ],
    "add_inst": [
      "self",
      "cand",
      "ref_list"
    ],
    "count_ngram": [
      "self",
      "cand",
      "ref_list",
      "n_size"
    ],
    "count_bp": [
      "self",
      "cand",
      "ref_list"
    ],
    "reset": [
      "self"
    ],
    "accumulate": [
      "self"
    ],
    "score": [
      "self"
    ],
    "name": [
      "self"
    ]
  },
  "BLEUForDuReader": {
    "__init__": [
      "self",
      "n_size",
      "alpha",
      "beta"
    ],
    "add_inst": [
      "self",
      "cand",
      "ref_list",
      "yn_label",
      "yn_ref",
      "entity_ref"
    ],
    "add_yn_bonus": [
      "self",
      "cand",
      "ref_list",
      "yn_label",
      "yn_ref"
    ],
    "add_entity_bonus": [
      "self",
      "cand",
      "entity_ref"
    ]
  },
  "extract_tp_actual_correct": [
    "y_true",
    "y_pred",
    "suffix"
  ],
  "ChunkEvaluator": {
    "__init__": [
      "self",
      "label_list",
      "suffix"
    ],
    "compute": [
      "self",
      "lengths",
      "predictions",
      "labels",
      "dummy"
    ],
    "_is_number_or_matrix": [
      "self",
      "var"
    ],
    "update": [
      "self",
      "num_infer_chunks",
      "num_label_chunks",
      "num_correct_chunks"
    ],
    "accumulate": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "name": [
      "self"
    ]
  },
  "MRR": {
    "__init__": [
      "self",
      "distance"
    ],
    "reset_distance": [
      "self",
      "distance"
    ],
    "compute_matrix_mrr": [
      "self",
      "labels",
      "embeddings"
    ]
  },
  "compute_prediction": [
    "examples",
    "features",
    "predictions",
    "version_2_with_negative",
    "n_best_size",
    "max_answer_length",
    "null_score_diff_threshold"
  ],
  "make_qid_to_has_ans": [
    "examples"
  ],
  "remove_punctuation": [
    "in_str"
  ],
  "normalize_answer": [
    "s"
  ],
  "compute_exact": [
    "a_gold",
    "a_pred"
  ],
  "compute_f1": [
    "a_gold",
    "a_pred",
    "is_whitespace_splited"
  ],
  "get_raw_scores": [
    "examples",
    "preds",
    "is_whitespace_splited"
  ],
  "apply_no_ans_threshold": [
    "scores",
    "na_probs",
    "qid_to_has_ans",
    "na_prob_thresh"
  ],
  "make_eval_dict": [
    "exact_scores",
    "f1_scores",
    "qid_list"
  ],
  "merge_eval": [
    "main_eval",
    "new_eval",
    "prefix"
  ],
  "find_best_thresh": [
    "preds",
    "scores",
    "na_probs",
    "qid_to_has_ans"
  ],
  "find_all_best_thresh": [
    "main_eval",
    "preds",
    "exact_raw",
    "f1_raw",
    "na_probs",
    "qid_to_has_ans"
  ],
  "squad_evaluate": [
    "examples",
    "preds",
    "na_probs",
    "na_prob_thresh",
    "is_whitespace_splited"
  ],
  "compute_predictions": [
    "all_examples",
    "all_features",
    "all_results",
    "n_best_size",
    "max_answer_length",
    "do_lower_case",
    "verbose",
    "tokenizer"
  ],
  "get_final_text": [
    "pred_text",
    "orig_text",
    "tokenizer",
    "verbose"
  ],
  "_compute_softmax": [
    "scores"
  ],
  "_get_best_indexes": [
    "logits",
    "n_best_size"
  ],
  "dureader_evaluate": [
    "examples",
    "preds"
  ],
  "Perplexity": {
    "__init__": [
      "self",
      "name"
    ],
    "compute": [
      "self",
      "pred",
      "label",
      "seq_mask"
    ],
    "update": [
      "self",
      "ce",
      "word_num"
    ],
    "reset": [
      "self"
    ],
    "accumulate": [
      "self"
    ],
    "name": [
      "self"
    ]
  },
  "SpanEvaluator": {
    "__init__": [
      "self",
      "limit"
    ],
    "compute": [
      "self",
      "start_probs",
      "end_probs",
      "gold_start_ids",
      "gold_end_ids"
    ],
    "update": [
      "self",
      "num_correct_spans",
      "num_infer_spans",
      "num_label_spans"
    ],
    "eval_span": [
      "self",
      "predict_start_ids",
      "predict_end_ids",
      "label_start_ids",
      "label_end_ids"
    ],
    "accumulate": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "name": [
      "self"
    ]
  },
  "FasterErniePretrainedModel": {
    "model_config_file": [],
    "pretrained_init_configuration": [],
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "init_weights": [
      "self",
      "layer"
    ]
  },
  "FasterErnieModel": {
    "__init__": [
      "self",
      "vocab_size",
      "vocab_file",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "intermediate_size",
      "hidden_act",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "max_position_embeddings",
      "type_vocab_size",
      "initializer_range",
      "pad_token_id",
      "do_lower_case",
      "is_split_into_words",
      "max_seq_len"
    ],
    "forward": [
      "self",
      "text",
      "text_pair"
    ]
  },
  "FasterErnieForSequenceClassification": {
    "__init__": [
      "self",
      "ernie",
      "num_classes",
      "dropout"
    ],
    "forward": [
      "self",
      "text",
      "text_pair"
    ]
  },
  "FasterErnieForTokenClassification": {
    "__init__": [
      "self",
      "ernie",
      "num_classes",
      "dropout"
    ],
    "forward": [
      "self",
      "text",
      "text_pair"
    ]
  },
  "load_vocabulary": [
    "filepath"
  ],
  "FasterPretrainedModel": {
    "to_static": [
      "self",
      "output_path"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "load_vocabulary": [
      "filepath"
    ],
    "save_pretrained": [
      "self",
      "save_dir"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ]
  },
  "ActScalesLoader": {
    "__init__": [
      "self",
      "scale_json_file_path",
      "key_map_dict",
      "num_of_layers"
    ]
  },
  "WeightScalesLoader": {
    "__init__": [
      "self",
      "scale_json_file_path",
      "key_map_dict",
      "num_of_layers",
      "concat_qkv",
      "concat_ffn1"
    ]
  },
  "CacheScaleLoader": {
    "__init__": [
      "self",
      "scale_json_file_path",
      "key_map_dict",
      "num_of_layers",
      "num_heads"
    ]
  },
  "to_tensor": [
    "string_values",
    "name"
  ],
  "to_vocab_buffer": [
    "vocab_dict",
    "name"
  ],
  "FasterTokenizer": {
    "name_map": [],
    "__init__": [
      "self",
      "vocab",
      "do_lower_case",
      "is_split_into_words"
    ],
    "forward": [
      "self",
      "text",
      "text_pair",
      "max_seq_len",
      "pad_to_max_seq_len"
    ],
    "from_pretrained": [
      "cls",
      "name"
    ]
  },
  "AutoTrainerBase": {
    "training_path": [],
    "save_path": [],
    "export_path": [],
    "compress_path": [],
    "results_filename": [],
    "experiment_path": [],
    "visualdl_path": [],
    "__init__": [
      "self",
      "train_dataset",
      "eval_dataset",
      "metric_for_best_model",
      "greater_is_better",
      "language",
      "output_dir",
      "verbosity"
    ],
    "supported_languages": [
      "self"
    ],
    "_default_training_argument": [
      "self"
    ],
    "_model_candidates": [
      "self"
    ],
    "_data_checks_and_inference": [
      "self",
      "dataset_list"
    ],
    "_construct_trainable": [
      "self"
    ],
    "_compute_metrics": [
      "self",
      "eval_preds"
    ],
    "_preprocess_fn": [
      "self",
      "example",
      "tokenizer",
      "max_seq_length",
      "is_test"
    ],
    "export": [
      "self",
      "export_path",
      "trial_id"
    ],
    "to_taskflow": [
      "self",
      "trial_id"
    ],
    "evaluate": [
      "self",
      "eval_dataset",
      "trial_id"
    ],
    "predict": [
      "self",
      "test_dataset",
      "trial_id"
    ],
    "_override_hp": [
      "self",
      "config",
      "default_hp"
    ],
    "_filter_model_candidates": [
      "self",
      "language",
      "preset",
      "custom_model_candidates"
    ],
    "_get_model_result": [
      "self",
      "trial_id"
    ],
    "show_training_results": [
      "self"
    ],
    "load": [
      "self",
      "path"
    ],
    "train": [
      "self",
      "num_models",
      "preset",
      "num_gpus",
      "num_cpus",
      "max_concurrent_trials",
      "time_budget_s",
      "experiment_name",
      "hp_overrides",
      "custom_model_candidates"
    ],
    "visualdl": [
      "self",
      "trial_id"
    ]
  },
  "UTCLoss": {
    "__call__": [
      "self",
      "logit",
      "label"
    ],
    "forward": [
      "self",
      "logit",
      "label"
    ]
  },
  "AutoTrainerForTextClassification": {
    "__init__": [
      "self",
      "text_column",
      "label_column",
      "train_dataset",
      "eval_dataset",
      "metric_for_best_model",
      "greater_is_better",
      "problem_type"
    ],
    "supported_languages": [
      "self"
    ],
    "_default_training_argument": [
      "self"
    ],
    "_default_prompt_tuning_arguments": [
      "self"
    ],
    "_model_candidates": [
      "self"
    ],
    "_data_checks_and_inference": [
      "self",
      "dataset_list"
    ],
    "_construct_trainer": [
      "self",
      "model_config"
    ],
    "evaluate": [
      "self",
      "eval_dataset",
      "trial_id"
    ],
    "predict": [
      "self",
      "test_dataset",
      "trial_id"
    ],
    "_compute_metrics": [
      "self",
      "eval_preds"
    ],
    "_compute_multi_class_metrics": [
      "self",
      "eval_preds"
    ],
    "_compute_multi_label_metrics": [
      "self",
      "eval_preds"
    ],
    "_preprocess_labels": [
      "self",
      "example",
      "is_test",
      "is_utc"
    ],
    "_preprocess_fn": [
      "self",
      "example",
      "tokenizer",
      "max_length",
      "is_test"
    ],
    "_preprocess_dataset": [
      "self",
      "dataset",
      "max_length",
      "tokenizer",
      "is_test",
      "is_utc"
    ],
    "to_taskflow": [
      "self",
      "trial_id",
      "batch_size",
      "precision",
      "compress"
    ],
    "export": [
      "self",
      "export_path",
      "trial_id",
      "compress"
    ],
    "_get_input_spec": [
      "self",
      "model_config"
    ],
    "compress": [
      "self",
      "compress_path",
      "trial_id"
    ],
    "_ptq_strategy": [
      "self",
      "compress_path",
      "trial_id",
      "algo",
      "batch_size",
      "batch_nums"
    ]
  },
  "_set_var_distributed": [
    "var"
  ],
  "fused_act_bias_wrapper": [
    "x",
    "bias",
    "dequant_scales",
    "shift",
    "smooth",
    "act_method",
    "compute_dtype",
    "quant_scale",
    "quant_round_type",
    "quant_max_bound",
    "quant_min_bound"
  ],
  "FusedMultiTransformerConfig": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "dim_feedforward",
      "weight_only_quant_bits",
      "dropout_rate",
      "activation",
      "norm_type",
      "use_neox_rotary_style",
      "normalize_before",
      "ln_scale_attrs",
      "ln_bias_attrs",
      "qkv_weight_attrs",
      "qkv_weight_scale_attrs",
      "qkv_bias_attrs",
      "linear_weight_attrs",
      "linear_weight_scale_attrs",
      "linear_bias_attrs",
      "ffn_ln_scale_attrs",
      "ffn_ln_bias_attrs",
      "ffn1_weight_attrs",
      "ffn1_weight_scale_attrs",
      "ffn1_bias_attrs",
      "ffn2_weight_attrs",
      "ffn2_weight_scale_attrs",
      "ffn2_bias_attrs",
      "qkv_out_scale_attrs",
      "linear_out_scale_attrs",
      "ffn1_out_scale_attrs",
      "ffn2_out_scale_attrs",
      "linear_shift_attrs",
      "linear_smooth_attrs",
      "ffn2_shift_attrs",
      "ffn2_smooth_attrs",
      "cache_k_scale_attrs",
      "cache_v_scale_attrs",
      "cache_k_out_scale_attrs",
      "cache_v_out_scale_attrs",
      "quant_round_type",
      "quant_max_bound",
      "quant_min_bound",
      "epsilon",
      "residual_alpha",
      "num_layers",
      "nranks",
      "trans_qkvw",
      "ring_id",
      "kv_num_heads",
      "use_dynamic_cachekv_quant",
      "rank_id"
    ]
  },
  "FusedMultiTransformerBase": {
    "__init__": [
      "self",
      "config"
    ],
    "get_attr": [
      "self",
      "attrs",
      "idx"
    ],
    "_add_parameter": [
      "self",
      "param"
    ],
    "init_weight_shape": [
      "self",
      "config"
    ],
    "get_weight_create_dype": [
      "self"
    ],
    "compute_layernorm_before_qkv": [
      "self",
      "src",
      "i"
    ],
    "compute_qkv_linear": [
      "self",
      "ln_out",
      "i"
    ],
    "compute_qkv": [
      "self",
      "src",
      "residual_input",
      "i"
    ],
    "compute_fmha": [
      "self",
      "qkv_out",
      "padding_offset",
      "seq_lens",
      "input_ids",
      "rotary_embs",
      "rotary_emb_dims",
      "caches",
      "pre_caches",
      "pre_caches_length",
      "attn_mask",
      "i"
    ],
    "compute_mmha": [
      "self",
      "qkv_out",
      "caches",
      "attn_mask",
      "seq_lens",
      "rotary_embs",
      "rotary_emb_dims",
      "i"
    ],
    "compute_out_linear": [
      "self",
      "fmha_out",
      "i"
    ],
    "compute_attn": [
      "self",
      "time_step",
      "qkv_out",
      "padding_offset",
      "seq_lens",
      "input_ids",
      "rotary_embs",
      "rotary_emb_dims",
      "caches",
      "pre_caches",
      "pre_caches_length",
      "attn_mask",
      "i"
    ],
    "compute_ffn_layernorm": [
      "self",
      "out_linear_out",
      "residual_input",
      "i"
    ],
    "compute_activation": [
      "self",
      "ffn1_out",
      "i"
    ],
    "compute_ffn1": [
      "self",
      "tmp_out",
      "i"
    ],
    "compute_ffn2": [
      "self",
      "ffn1_out",
      "i"
    ],
    "compute_bias_residual_layernorm": [
      "self",
      "ffn2_out",
      "residual_input",
      "i",
      "num_layers"
    ],
    "pre_process": [
      "self"
    ],
    "post_process": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "src",
      "cum_offsets",
      "padding_offset",
      "attn_mask",
      "caches",
      "pre_caches",
      "pre_caches_length",
      "rotary_embs",
      "rotary_emb_dims",
      "seq_lens",
      "time_step"
    ]
  },
  "FusedMultiTransformerPostLayernorm": {
    "__init__": [
      "self",
      "config"
    ],
    "compute_qkv": [
      "self",
      "src",
      "residual_input",
      "i"
    ],
    "compute_ffn_layernorm": [
      "self",
      "out_linear_out",
      "residual_input",
      "i"
    ],
    "compute_bias_residual_layernorm": [
      "self",
      "ffn2_out",
      "residual_input",
      "i",
      "num_layers"
    ]
  },
  "FusedMultiTransformerWeightOnly": {
    "__init__": [
      "self",
      "config"
    ],
    "get_weight_create_dype": [
      "self"
    ],
    "init_weight_shape": [
      "self",
      "config"
    ],
    "compute_qkv_linear": [
      "self",
      "ln_out",
      "i"
    ],
    "compute_out_linear": [
      "self",
      "fmha_out",
      "i"
    ],
    "compute_ffn1": [
      "self",
      "tmp_out",
      "i"
    ],
    "compute_ffn2": [
      "self",
      "ffn1_out",
      "i"
    ]
  },
  "FusedMultiTransformerWeightOnlyPostLayernorm": {
    "__init__": [
      "self",
      "config"
    ]
  },
  "FusedMultiTransformerA8W8": {
    "__init__": [
      "self",
      "config"
    ],
    "get_weight_create_dype": [
      "self"
    ],
    "init_weight_shape": [
      "self",
      "config"
    ],
    "compute_layernorm_before_qkv": [
      "self",
      "src",
      "i"
    ],
    "compute_qkv_linear": [
      "self",
      "ln_out",
      "i"
    ],
    "compute_fmha": [
      "self",
      "qkv_out",
      "padding_offset",
      "seq_lens",
      "input_ids",
      "rotary_embs",
      "rotary_emb_dims",
      "caches",
      "pre_caches",
      "pre_caches_length",
      "attn_mask",
      "i"
    ],
    "compute_mmha": [
      "self",
      "qkv_out",
      "caches",
      "attn_mask",
      "seq_lens",
      "rotary_embs",
      "rotary_emb_dims",
      "i"
    ],
    "compute_out_linear": [
      "self",
      "fmha_out",
      "i"
    ],
    "compute_ffn_layernorm": [
      "self",
      "out_linear_out",
      "residual_input",
      "i"
    ],
    "compute_activation": [
      "self",
      "ffn1_out",
      "i"
    ],
    "compute_ffn1": [
      "self",
      "tmp_out",
      "i"
    ],
    "compute_ffn2": [
      "self",
      "ffn1_out",
      "i"
    ],
    "compute_bias_residual_layernorm": [
      "self",
      "ffn2_out",
      "residual_input",
      "i",
      "num_layers"
    ]
  },
  "FusedBlockMultiTransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "compute_attn": [
      "self",
      "time_step",
      "qkv_out",
      "padding_offset",
      "seq_lens",
      "input_ids",
      "rotary_embs",
      "rotary_emb_dims",
      "caches",
      "pre_caches",
      "pre_caches_length",
      "attn_mask",
      "i"
    ],
    "post_process": [
      "self"
    ]
  },
  "FusedBlockMultiTransformerWeightOnly": {
    "__init__": [
      "self",
      "config"
    ]
  },
  "FusedBlockMultiTransformerA8W8": {
    "__init__": [
      "self",
      "config"
    ],
    "compute_attn": [
      "self",
      "time_step",
      "qkv_out",
      "padding_offset",
      "seq_lens",
      "input_ids",
      "rotary_embs",
      "rotary_emb_dims",
      "caches",
      "pre_caches",
      "pre_caches_length",
      "attn_mask",
      "i"
    ]
  },
  "ForcedDecodingEOSTokenLogitsProcessor": {
    "__init__": [
      "self",
      "max_decoding_step",
      "forced_eos_token_id"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores",
      "decoding_step"
    ]
  },
  "GenerationInferenceModel": {
    "get_cache_kvs_shape": [
      "cls",
      "max_batch_size",
      "max_length"
    ],
    "to_static": [
      "self",
      "output_path",
      "config"
    ],
    "prepare_input_ids_for_generation": [
      "bos_token_id",
      "encoder_output"
    ],
    "generate": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "penalty_score",
      "frequency_score",
      "presence_score",
      "min_length",
      "max_length",
      "temperature",
      "top_p",
      "eos_token_id",
      "seq_len_encoder",
      "seq_len_decoder",
      "step_idx",
      "stop_flags",
      "tgt_ids",
      "tgt_pos",
      "tgt_generation_mask",
      "pre_ids",
      "stop_nums",
      "cache_kvs",
      "inputs_embeds",
      "logits_processors",
      "pre_caches"
    ],
    "update_model_kwargs_for_generation": [
      "self",
      "cache",
      "just_decoder",
      "next_tokens",
      "eos_token_id",
      "model_kwargs"
    ],
    "sample": [
      "self",
      "input_ids",
      "eos_token_id",
      "cache_kvs",
      "top_p",
      "temperature",
      "inputs_embeds"
    ]
  },
  "GenerationBlockInferenceModel": {
    "get_cache_kvs_shape": [
      "cls",
      "max_batch_size",
      "max_length"
    ],
    "to_static": [
      "self",
      "output_path",
      "config"
    ],
    "prepare_input_ids_for_generation": [
      "bos_token_id",
      "encoder_output"
    ],
    "generate": [
      "self",
      "input_ids",
      "temperature",
      "top_p",
      "eos_token_id",
      "src_mask",
      "penalty_score",
      "frequency_score",
      "presence_score",
      "next_tokens",
      "is_block_step",
      "seq_lens_this_time",
      "seq_lens_encoder",
      "seq_lens_decoder",
      "step_idx",
      "stop_flags",
      "rope_emb",
      "min_length",
      "max_length",
      "stop_nums",
      "bad_tokens",
      "not_need_stop",
      "block_tables",
      "pre_ids",
      "pre_caches",
      "cache_kvs",
      "k_quant_scales",
      "v_quant_scales",
      "k_dequant_scales",
      "v_dequant_scales",
      "tgt_mask"
    ],
    "sample": [
      "self",
      "eos_token_id",
      "top_k",
      "top_p",
      "penalty_score",
      "frequency_score",
      "presence_score",
      "temperature",
      "min_tokens_to_keep"
    ]
  },
  "ChatGLMv2InferenceModel": {
    "__init__": [
      "self",
      "config",
      "empty_init"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "remove_padding": [
      "self",
      "input_ids",
      "seq_lens_this_time"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "cache_kvs",
      "seq_len_encoder",
      "seq_len_decoder",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "ChatGLMv2ForCausalLMInferenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_cache_kvs_shape": [
      "cls",
      "config",
      "max_batch_size",
      "max_length"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "cache_kvs",
      "seq_len_encoder",
      "seq_len_decoder",
      "tgt_ids",
      "tgt_pos",
      "tgt_generation_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "cache",
      "cache_kvs",
      "pre_caches",
      "seq_len_encoder",
      "seq_len_decoder",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "FusedQWenRMSNorm": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QWenInferenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ],
    "remove_padding": [
      "self",
      "input_ids",
      "seq_lens_this_time"
    ],
    "prepare_input_ids_for_generation": [
      "bos_token_id",
      "encoder_output"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "cache_kvs",
      "pre_caches",
      "seq_len_encoder",
      "seq_len_decoder",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "QWenForCausalLMInferenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path",
      "from_hf_hub",
      "subfolder"
    ],
    "get_cache_kvs_shape": [
      "cls",
      "config",
      "max_batch_size",
      "max_length"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "cache_kvs",
      "seq_len_encoder",
      "seq_len_decoder",
      "tgt_ids",
      "tgt_pos",
      "tgt_generation_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "cache",
      "cache_kvs",
      "pre_caches",
      "seq_len_encoder",
      "seq_len_decoder",
      "past_key_values",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "QWenForQWenVLInferenceModel": {
    "generate_text_with_image_features": [
      "self",
      "input_ids",
      "image_features",
      "img_pos",
      "attention_mask",
      "position_ids",
      "penalty_score",
      "frequency_score",
      "presence_score",
      "min_length",
      "max_length",
      "temperature",
      "top_p",
      "eos_token_id",
      "seq_len_encoder",
      "seq_len_decoder",
      "step_idx",
      "stop_flags",
      "tgt_ids",
      "tgt_pos",
      "tgt_generation_mask",
      "pre_ids",
      "stop_nums",
      "cache_kvs",
      "inputs_embeds"
    ],
    "to_static": [
      "self",
      "output_path",
      "config"
    ]
  },
  "GPTInferenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "remove_padding": [
      "self",
      "input_ids",
      "seq_lens_this_time"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "cache",
      "cache_kvs",
      "seq_len_encoder",
      "seq_len_decoder",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "GPTForCausalLMInferenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "get_cache_kvs_shape": [
      "cls",
      "config",
      "max_batch_size",
      "max_length"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "cache_kvs",
      "seq_len_encoder",
      "seq_len_decoder",
      "tgt_ids",
      "tgt_pos",
      "tgt_generation_mask"
    ],
    "prepare_attention_mask_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "cache",
      "cache_kvs",
      "seq_len_encoder",
      "seq_len_decoder",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "RotaryEmbeddingsDybatch": {
    "__init__": [
      "self",
      "hidden_size",
      "base",
      "learnable"
    ],
    "forward": [
      "self",
      "seq_dim",
      "seq_len"
    ]
  },
  "ChatGLMStackDyBatch": {
    "__init__": [
      "self",
      "config"
    ],
    "remove_padding": [
      "self",
      "input_ids",
      "seq_lens_this_time"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "cache",
      "cache_kvs",
      "pre_caches",
      "seq_len_encoder",
      "seq_len_decoder",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "time_step"
    ],
    "set_state_dict": [
      "self",
      "state_dict",
      "use_structured_name"
    ]
  },
  "ChatGLMModelDyBatch": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "cache",
      "inputs_embeds",
      "use_cache",
      "cache_kvs",
      "pre_caches",
      "seq_len_encoder",
      "seq_len_decoder",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "time_step"
    ]
  },
  "ChatGLMForCausalLMInferenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "get_cache_kvs_shape": [
      "cls",
      "config",
      "max_batch_size",
      "max_length"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "cache_kvs",
      "seq_len_encoder",
      "seq_len_decoder",
      "tgt_ids",
      "tgt_pos",
      "tgt_generation_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "cache",
      "cache_kvs",
      "pre_caches",
      "seq_len_encoder",
      "seq_len_decoder",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "time_step"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "BloomModelInferenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "set_transformer_block": [
      "self",
      "transformer_config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "remove_padding": [
      "self",
      "input_ids",
      "seq_lens_this_time"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "inputs_embeds",
      "cache",
      "cache_kvs",
      "pre_caches",
      "seq_len_encoder",
      "seq_len_decoder",
      "return_dict"
    ],
    "set_state_dict": [
      "self",
      "state_dict",
      "use_structured_name"
    ]
  },
  "BloomForCausalLMInferenceModel": {
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_cache_kvs_shape": [
      "cls",
      "config",
      "max_batch_size",
      "max_length"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "cache_kvs",
      "tgt_ids",
      "tgt_generation_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "cache",
      "attention_mask",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "cache_kvs",
      "pre_caches",
      "output_attentions",
      "output_hidden_states",
      "seq_len_encoder",
      "seq_len_decoder",
      "return_dict"
    ],
    "set_state_dict": [
      "self",
      "state_dict",
      "use_structured_name"
    ],
    "_reorder_cache": [
      "past",
      "beam_idx"
    ]
  },
  "BloomBlockInferenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "set_transformer_block": [
      "self",
      "transformer_config"
    ],
    "remove_padding": [
      "self",
      "input_ids",
      "seq_lens_this_time"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "inputs_embeds",
      "caches",
      "pre_caches",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BlommForCausalBlockLMInferenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_cache_kvs_shape": [
      "cls",
      "config",
      "max_batch_size",
      "max_length"
    ],
    "prepare_inputs_for_generation": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "src_mask",
      "tgt_mask",
      "pre_caches",
      "caches",
      "seq_lens_this_time",
      "seq_lens_encoder",
      "seq_lens_decoder",
      "rope_emb",
      "block_tables",
      "k_quant_scales",
      "v_quant_scales",
      "k_dequant_scales",
      "v_dequant_scales"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "OPTInferenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "remove_padding": [
      "self",
      "input_ids",
      "seq_lens_this_time"
    ],
    "prepare_input_ids_for_generation": [
      "bos_token_id",
      "encoder_output"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "cache_kvs",
      "seq_len_encoder",
      "seq_len_decoder",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "OPTForCausalLMInferenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "get_cache_kvs_shape": [
      "cls",
      "config",
      "max_batch_size",
      "max_length"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "cache_kvs",
      "seq_len_encoder",
      "seq_len_decoder",
      "tgt_ids",
      "tgt_pos",
      "tgt_generation_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "cache",
      "cache_kvs",
      "seq_len_encoder",
      "seq_len_decoder",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "OPTForBlip2InferenceModel": {
    "generate_text_with_image_features": [
      "self",
      "image_features",
      "second_input_ids",
      "attention_mask",
      "position_ids",
      "penalty_score",
      "frequency_score",
      "presence_score",
      "min_length",
      "max_length",
      "temperature",
      "top_p",
      "eos_token_id",
      "seq_len_encoder",
      "seq_len_decoder",
      "step_idx",
      "stop_flags",
      "tgt_ids",
      "tgt_pos",
      "tgt_generation_mask",
      "pre_ids",
      "stop_nums",
      "cache_kvs",
      "inputs_embeds"
    ],
    "to_static": [
      "self",
      "output_path",
      "config"
    ]
  },
  "FusedLlamaRMSNorm": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LlamaInferenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "set_transformer_block": [
      "self",
      "transformer_config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "remove_padding": [
      "self",
      "input_ids",
      "seq_lens_this_time"
    ],
    "prepare_input_ids_for_generation": [
      "bos_token_id",
      "encoder_output"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "cache_kvs",
      "pre_caches",
      "seq_len_encoder",
      "seq_len_decoder",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "LlamaBlockInferenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "set_transformer_block": [
      "self",
      "transformer_config"
    ],
    "remove_padding": [
      "self",
      "input_ids",
      "seq_lens_this_time"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "inputs_embeds",
      "caches",
      "pre_caches",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "LlamaForCausalLMInferenceModel": {
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "get_cache_kvs_shape": [
      "cls",
      "config",
      "max_batch_size",
      "max_length"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "cache_kvs",
      "seq_len_encoder",
      "seq_len_decoder",
      "tgt_ids",
      "tgt_pos",
      "tgt_generation_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "cache",
      "cache_kvs",
      "pre_caches",
      "seq_len_encoder",
      "seq_len_decoder",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "LlamaForCausalLMBlockInferenceModel": {
    "_keys_to_ignore_on_load_missing": [],
    "__init__": [
      "self",
      "config"
    ],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "get_cache_kvs_shape": [
      "cls",
      "config",
      "max_batch_size",
      "max_length"
    ],
    "prepare_inputs_for_generation": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "src_mask",
      "pre_caches",
      "caches",
      "seq_lens_this_time",
      "seq_lens_encoder",
      "seq_lens_decoder",
      "rope_emb",
      "block_tables",
      "k_quant_scales",
      "v_quant_scales",
      "k_dequant_scales",
      "v_dequant_scales"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "LlamaForMiniGPT4InferenceModel": {
    "generate_text_with_image_features": [
      "self",
      "image_features",
      "first_input_ids",
      "second_input_ids",
      "attention_mask",
      "position_ids",
      "penalty_score",
      "frequency_score",
      "presence_score",
      "min_length",
      "max_length",
      "temperature",
      "top_p",
      "eos_token_id",
      "seq_len_encoder",
      "seq_len_decoder",
      "step_idx",
      "stop_flags",
      "tgt_ids",
      "tgt_pos",
      "tgt_generation_mask",
      "pre_ids",
      "stop_nums",
      "cache_kvs",
      "inputs_embeds"
    ],
    "to_static": [
      "self",
      "output_path",
      "config"
    ]
  },
  "DuReaderQG": {
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "BSTC": {
    "lazy": [],
    "BUILDER_CONFIGS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "data_dir",
      "split"
    ]
  },
  "Glue": {
    "BUILDER_CONFIGS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "Cote": {
    "BUILDER_CONFIGS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "ALL_LANGUAGES": [],
  "XNLI": {
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "ChnSentiCorpV2": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "PAWSX": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_labels": [
      "self"
    ]
  },
  "WMT14ende": {
    "URL": [],
    "META_INFO": [],
    "SPLITS": [],
    "VOCAB_INFO": [],
    "UNK_TOKEN": [],
    "BOS_TOKEN": [],
    "EOS_TOKEN": [],
    "MD5": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_vocab": [
      "self"
    ]
  },
  "DuConv": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "DuReaderChecklist": {
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "Couplet": {
    "URL": [],
    "META_INFO": [],
    "MD5": [],
    "SPLITS": [],
    "VOCAB_INFO": [],
    "UNK_TOKEN": [],
    "BOS_TOKEN": [],
    "EOS_TOKEN": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_vocab": [
      "self"
    ]
  },
  "CBLUE": {
    "BUILDER_CONFIGS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_search_entity_index": [
      "self",
      "tokens",
      "entity_tokens",
      "skip_idx"
    ],
    "_search_spo_index": [
      "self",
      "tokens",
      "subjects",
      "objects"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "NLPCC13EVSAM05HIT": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ]
  },
  "THUCNews": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "LABEL_PATH": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "BelleGroup": {
    "BUILDER_CONFIGS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "CnnDailymail": {
    "lazy": [],
    "META_INFO": [],
    "SPLITS": [],
    "cnn_dailymail": [],
    "_read_text_file": [
      "self",
      "text_file"
    ],
    "_get_url_hashes": [
      "self",
      "path"
    ],
    "_get_hash_from_path": [
      "self",
      "p"
    ],
    "_find_files": [
      "self",
      "dl_paths",
      "publisher",
      "url_dict"
    ],
    "_subset_filenames": [
      "self",
      "dl_paths",
      "split"
    ],
    "_get_art_abs": [
      "self",
      "story_file",
      "version"
    ],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "dl_paths",
      "split"
    ]
  },
  "Conll2002": {
    "META_INFO": [],
    "BASE_URL": [],
    "BUILDER_CONFIGS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_labels": [
      "self"
    ]
  },
  "C3": {
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "data_files"
    ],
    "get_labels": [
      "self"
    ]
  },
  "NLPCC_DBQA": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "InTokens": {
    "required_input_keys": [],
    "required_output_keys": [],
    "supported_input_keys": [],
    "_pad_batch_records": [
      "cls",
      "batch_records"
    ]
  },
  "InTokensMapDataset": {
    "__init__": [
      "self",
      "data",
      "tokenizer",
      "max_length"
    ],
    "_create_intokens_data": [
      "self",
      "data"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ]
  },
  "InTokensIterableDataset": {
    "__init__": [
      "self",
      "data",
      "tokenizer",
      "max_length"
    ],
    "__iter__": [
      "self"
    ]
  },
  "TriviaQA": {
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "Poetry": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "DATASETS_MODULE_PATH": [],
  "load_from_ppnlp": [
    "path"
  ],
  "DatasetTuple": {
    "__init__": [
      "self",
      "splits"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "_gen_identifier_map": [
      "self",
      "splits"
    ],
    "__len__": [
      "self"
    ]
  },
  "import_main_class": [
    "module_path"
  ],
  "load_from_hf": [
    "path",
    "name",
    "splits"
  ],
  "load_dataset": [
    "path_or_read_func",
    "name",
    "data_files",
    "splits",
    "lazy"
  ],
  "MapDataset": {
    "__init__": [
      "self",
      "data"
    ],
    "_transform": [
      "self",
      "data"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "filter": [
      "self",
      "fn",
      "num_workers"
    ],
    "_filter": [
      "self",
      "fn"
    ],
    "shard": [
      "self",
      "num_shards",
      "index",
      "contiguous"
    ],
    "_shard": [
      "self",
      "num_shards",
      "index",
      "contiguous"
    ],
    "map": [
      "self",
      "fn",
      "lazy",
      "batched",
      "num_workers"
    ],
    "_map": [
      "self",
      "fn",
      "lazy",
      "batched"
    ]
  },
  "IterDataset": {
    "__init__": [
      "self",
      "data"
    ],
    "_transform": [
      "self",
      "data"
    ],
    "_shard_filter": [
      "self",
      "num_samples"
    ],
    "_filter": [
      "self",
      "data"
    ],
    "__iter__": [
      "self"
    ],
    "skip": [
      "self",
      "n"
    ],
    "filter": [
      "self",
      "fn"
    ],
    "shard": [
      "self",
      "num_shards",
      "index"
    ],
    "map": [
      "self",
      "fn"
    ]
  },
  "DatasetBuilder": {
    "lazy": [],
    "__init__": [
      "self",
      "lazy",
      "name"
    ],
    "read_datasets": [
      "self",
      "splits",
      "data_files"
    ],
    "read": [
      "self",
      "filename",
      "split"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "_get_data": [
      "self",
      "mode"
    ],
    "get_labels": [
      "self"
    ],
    "get_vocab": [
      "self"
    ]
  },
  "SimpleBuilder": {
    "__init__": [
      "self",
      "lazy",
      "read_func"
    ],
    "read": [
      "self"
    ]
  },
  "FewCLUE": {
    "BUILDER_CONFIGS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "CMRC2018": {
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "XNLI_CN": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "PTB": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "DRCD_CN": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "LCQMC": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_labels": [
      "self"
    ]
  },
  "MsraNer": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_labels": [
      "self"
    ]
  },
  "SQuAD": {
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "PeoplesDailyNER": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_labels": [
      "self"
    ]
  },
  "IWSLT15": {
    "URL": [],
    "META_INFO": [],
    "MD5": [],
    "SPLITS": [],
    "VOCAB_INFO": [],
    "UNK_TOKEN": [],
    "BOS_TOKEN": [],
    "EOS_TOKEN": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_vocab": [
      "self"
    ]
  },
  "BQCorpus": {
    "lazy": [],
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_labels": [
      "self"
    ]
  },
  "DRCD": {
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "CAIL2018Small": {
    "lazy": [],
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_labels": [
      "self"
    ]
  },
  "NLPCC14SC": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "LCQMC_V2": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_labels": [
      "self"
    ]
  },
  "SeAbsa16": {
    "BUILDER_CONFIGS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "CAIL2019_SCM": {
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_labels": [
      "self"
    ]
  },
  "WOS": {
    "lazy": [],
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_labels": [
      "self"
    ]
  },
  "DuReaderYesNo": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_labels": [
      "self"
    ]
  },
  "NLPCC13EVSAM05THU": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ]
  },
  "Clue": {
    "BUILDER_CONFIGS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "YahooAnswer100K": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "VOCAB_INFO": [],
    "UNK_TOKEN": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ],
    "get_vocab": [
      "self"
    ]
  },
  "Imdb": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "data_dir"
    ],
    "get_labels": [
      "self"
    ]
  },
  "HYP": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "LCSTSNew": {
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "DuReaderRobust": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "ChnSentiCorp": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename",
      "split"
    ],
    "get_labels": [
      "self"
    ]
  },
  "AdvertiseGen": {
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "SIGHAN_CN": {
    "URL": [],
    "MD5": [],
    "META_INFO": [],
    "SPLITS": [],
    "_get_data": [
      "self",
      "mode"
    ],
    "_read": [
      "self",
      "filename"
    ]
  },
  "_DESCRIPTION": [],
  "_URL": [],
  "LanguagePairConfig": {
    "__init__": [
      "self"
    ]
  },
  "LanguagePairDataset": {
    "BUILDER_CONFIGS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "source_filepath",
      "target_filepath"
    ]
  },
  "_GLUE_CITATION": [],
  "_GLUE_DESCRIPTION": [],
  "_MRPC_DEV_IDS": [],
  "_MRPC_TRAIN": [],
  "_MRPC_TEST": [],
  "_MNLI_BASE_KWARGS": [],
  "GlueConfig": {
    "__init__": [
      "self",
      "text_features",
      "label_column",
      "data_url",
      "data_dir",
      "citation",
      "url",
      "label_classes",
      "process_label"
    ]
  },
  "_mnli_split_generator": [
    "name",
    "data_dir",
    "split",
    "matched"
  ],
  "_CITATION": [],
  "_COTE_URLs": [],
  "COTEConfig": {
    "__init__": [
      "self",
      "data_url",
      "data_dir"
    ]
  },
  "COTE": {
    "BUILDER_CONFIGS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "filepath",
      "split"
    ]
  },
  "_TRAIN_DATA_URL": [],
  "_TESTVAL_DATA_URL": [],
  "_LANGUAGES": [],
  "XnliConfig": {
    "__init__": [
      "self",
      "language",
      "languages"
    ]
  },
  "Xnli": {
    "VERSION": [],
    "BUILDER_CONFIG_CLASS": [],
    "BUILDER_CONFIGS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "data_format",
      "filepaths"
    ]
  },
  "DuconvConfig": {
    "__init__": [
      "self"
    ]
  },
  "Duconv": {
    "BUILDER_CONFIGS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "filepath"
    ]
  },
  "_URLS": [],
  "SquadV2Config": {
    "__init__": [
      "self"
    ]
  },
  "SquadV2": {
    "BUILDER_CONFIGS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "filepath"
    ]
  },
  "_get_md5": [
    "string"
  ],
  "FUNSDConfig": {
    "__init__": [
      "self"
    ]
  },
  "FUNSD": {
    "BUILDER_CONFIGS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "filepath"
    ]
  },
  "_DATA_URL": [],
  "TranslateData": [],
  "MT_Eng_ViConfig": {
    "__init__": [
      "self",
      "language_pair"
    ]
  },
  "MTEngVietnamese": {
    "BUILDER_CONFIGS": [],
    "BUILDER_CONFIG_CLASS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "source_file",
      "target_file"
    ]
  },
  "_DL_URLS": [],
  "_HIGHLIGHTS": [],
  "_ARTICLE": [],
  "_SUPPORTED_VERSIONS": [],
  "_DEFAULT_VERSION": [],
  "CnnDailymailConfig": {
    "__init__": [
      "self"
    ]
  },
  "_get_url_hashes": [
    "path"
  ],
  "_get_hash_from_path": [
    "p"
  ],
  "_find_files": [
    "dl_paths",
    "publisher",
    "url_dict"
  ],
  "_subset_filenames": [
    "dl_paths",
    "split"
  ],
  "DM_SINGLE_CLOSE_QUOTE": [],
  "DM_DOUBLE_CLOSE_QUOTE": [],
  "END_TOKENS": [],
  "_read_text_file": [
    "text_file"
  ],
  "_get_art_abs": [
    "story_file",
    "tfds_version"
  ],
  "_LICENSE": [],
  "RVLCDIPSampledConfig": {
    "__init__": [
      "self"
    ]
  },
  "RVLCDIPSampled": {
    "BUILDER_CONFIGS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "filepath"
    ]
  },
  "_HOMEPAGE": [],
  "_TRAINING_FILE": [],
  "_DEV_FILE": [],
  "_TEST_FILE": [],
  "PtbTextOnlyConfig": {
    "__init__": [
      "self"
    ]
  },
  "PtbTextOnly": {
    "VERSION": [],
    "BUILDER_CONFIGS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "filepath"
    ]
  },
  "_TRAIN_FILE": [],
  "Cmrc2018": {
    "VERSION": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "filepath"
    ]
  },
  "MsraNerConfig": {
    "__init__": [
      "self"
    ]
  },
  "SquadConfig": {
    "__init__": [
      "self"
    ]
  },
  "Squad": {
    "BUILDER_CONFIGS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "filepath"
    ]
  },
  "XFUNDZhConfig": {
    "__init__": [
      "self"
    ]
  },
  "XFUNDZh": {
    "BUILDER_CONFIGS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "filepath"
    ]
  },
  "_SEABSA16_URLs": [],
  "SEABSA16Config": {
    "__init__": [
      "self",
      "data_url",
      "data_dir"
    ]
  },
  "SEABSA16": {
    "BUILDER_CONFIGS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "filepath",
      "split"
    ]
  },
  "_CLUE_CITATION": [],
  "_CLUE_DESCRIPTION": [],
  "ClueConfig": {
    "__init__": [
      "self",
      "data_url",
      "text_features",
      "label_column",
      "data_dir",
      "citation",
      "url",
      "label_classes",
      "process_label"
    ]
  },
  "_DOWNLOAD_URL": [],
  "IMDBReviewsConfig": {
    "__init__": [
      "self"
    ]
  },
  "DureaderRobustConfig": {
    "__init__": [
      "self"
    ]
  },
  "DureaderRobust": {
    "BUILDER_CONFIGS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "filepath"
    ]
  },
  "ChnSentiCorpConfig": {
    "__init__": [
      "self"
    ]
  },
  "DocVQAZhConfig": {
    "__init__": [
      "self"
    ]
  },
  "DocVQAZh": {
    "BUILDER_CONFIGS": [],
    "_info": [
      "self"
    ],
    "_split_generators": [
      "self",
      "dl_manager"
    ],
    "_generate_examples": [
      "self",
      "filepath"
    ]
  },
  "SentenceGenerate": {
    "__init__": [
      "self",
      "model_name",
      "create_n",
      "generate_n",
      "max_length",
      "top_p"
    ],
    "augment": [
      "self",
      "sequences"
    ],
    "_generate_similar_sentence": [
      "self",
      "sequence",
      "model",
      "tokenizer"
    ]
  },
  "SentenceSummarize": {
    "__init__": [
      "self",
      "create_n",
      "max_length",
      "batch_size",
      "top_k",
      "top_p",
      "temperature",
      "use_fp16_decoding"
    ],
    "augment": [
      "self",
      "sequences"
    ]
  },
  "SentenceBackTranslate": {
    "__init__": [
      "self",
      "src_lang",
      "tgt_lang",
      "max_length",
      "batch_size",
      "num_beams",
      "use_faster",
      "decode_strategy",
      "from_model_name",
      "to_model_name"
    ],
    "augment": [
      "self",
      "sequences"
    ],
    "_translate": [
      "self",
      "model",
      "tokenizer",
      "sequences",
      "lang"
    ]
  },
  "SentenceBackTranslateAPI": {
    "__init__": [
      "self",
      "src_lang",
      "tgt_lang",
      "appid",
      "secretKey",
      "qps"
    ],
    "augment": [
      "self",
      "sequences"
    ],
    "_back_translate_hub": [
      "self",
      "sequences"
    ],
    "_back_translate_api": [
      "self",
      "sequences"
    ],
    "_translate_api": [
      "self",
      "query",
      "from_lang",
      "to_lang"
    ]
  },
  "SentenceContinue": {
    "__init__": [
      "self",
      "model_name",
      "max_length",
      "decode_strategy",
      "use_faster",
      "create_n",
      "top_k",
      "temperature",
      "top_p",
      "batch_size"
    ],
    "augment": [
      "self",
      "sequences"
    ],
    "_generate_continue": [
      "self",
      "sequences",
      "model",
      "tokenizer"
    ]
  },
  "BaseAugment": {
    "__init__": [
      "self",
      "create_n",
      "aug_n",
      "aug_percent",
      "aug_min",
      "aug_max",
      "vocab"
    ],
    "clean": [
      "cls",
      "sequences"
    ],
    "_load_file": [
      "self",
      "mode"
    ],
    "_get_data": [
      "self",
      "mode"
    ],
    "_get_aug_n": [
      "self",
      "size",
      "size_a"
    ],
    "_skip_stop_word_tokens": [
      "self",
      "seq_tokens"
    ],
    "augment": [
      "self",
      "sequences",
      "num_thread"
    ],
    "_augment": [
      "self",
      "sequence"
    ]
  },
  "FileAugment": {
    "__init__": [
      "self",
      "strategies"
    ],
    "augment": [
      "self",
      "input_file",
      "output_file",
      "separator",
      "separator_id"
    ],
    "file_read": [
      "self",
      "input_file"
    ],
    "file_write": [
      "self",
      "output_sequences",
      "output_file"
    ]
  },
  "CharSubstitute": {
    "__init__": [
      "self",
      "aug_type",
      "custom_file_path",
      "delete_file_path",
      "create_n",
      "aug_n",
      "aug_percent",
      "aug_min",
      "aug_max",
      "model_name",
      "vocab"
    ],
    "_load_substitue_dict": [
      "self",
      "source_type"
    ],
    "_generate_sequence": [
      "self",
      "output_seq_tokens",
      "aug_tokens"
    ],
    "_augment": [
      "self",
      "sequence"
    ],
    "_augment_mlm": [
      "self",
      "sequence",
      "seq_tokens",
      "aug_indexes",
      "p"
    ],
    "_augment_multi": [
      "self",
      "seq_tokens",
      "aug_n",
      "aug_indexes",
      "p"
    ],
    "_augment_single": [
      "self",
      "seq_tokens",
      "aug_indexes",
      "p"
    ]
  },
  "CharInsert": {
    "__init__": [
      "self",
      "aug_type",
      "custom_file_path",
      "delete_file_path",
      "create_n",
      "aug_n",
      "aug_percent",
      "aug_min",
      "aug_max",
      "model_name",
      "vocab"
    ],
    "_load_insert_dict": [
      "self",
      "source_type"
    ],
    "_augment": [
      "self",
      "sequence"
    ],
    "_augment_mlm": [
      "self",
      "sequence",
      "seq_tokens",
      "aug_indexes"
    ],
    "_augment_multi": [
      "self",
      "seq_tokens",
      "aug_n",
      "aug_indexes"
    ],
    "_augment_single": [
      "self",
      "seq_tokens",
      "aug_indexes"
    ],
    "_generate_sequence": [
      "self",
      "output_seq_tokens",
      "aug_tokens",
      "p"
    ]
  },
  "CharSwap": {
    "__init__": [
      "self",
      "create_n",
      "aug_n",
      "aug_percent",
      "aug_min",
      "aug_max",
      "vocab"
    ],
    "_augment": [
      "self",
      "sequence"
    ],
    "_skip_chars": [
      "self",
      "seq_tokens"
    ]
  },
  "CharDelete": {
    "__init__": [
      "self",
      "create_n",
      "aug_n",
      "aug_percent",
      "aug_min",
      "aug_max",
      "vocab"
    ],
    "_augment": [
      "self",
      "sequence"
    ],
    "_skip_chars": [
      "self",
      "seq_tokens"
    ]
  },
  "WordSubstitute": {
    "__init__": [
      "self",
      "aug_type",
      "custom_file_path",
      "delete_file_path",
      "create_n",
      "aug_n",
      "aug_percent",
      "aug_min",
      "aug_max",
      "tf_idf",
      "tf_idf_file",
      "model_name",
      "vocab"
    ],
    "_count_idf": [
      "self",
      "tf_idf_file"
    ],
    "_calculate_tfidf": [
      "self",
      "sequence",
      "seq_tokens",
      "aug_indexes"
    ],
    "_load_substitue_dict": [
      "self",
      "source_type"
    ],
    "_generate_sequence": [
      "self",
      "output_seq_tokens",
      "aug_tokens"
    ],
    "_augment": [
      "self",
      "sequence"
    ],
    "_augment_mlm": [
      "self",
      "sequence",
      "seq_tokens",
      "aug_indexes",
      "p"
    ],
    "_augment_multi": [
      "self",
      "seq_tokens",
      "aug_n",
      "aug_indexes",
      "p"
    ],
    "_augment_single": [
      "self",
      "seq_tokens",
      "aug_indexes",
      "p"
    ]
  },
  "WordInsert": {
    "__init__": [
      "self",
      "aug_type",
      "custom_file_path",
      "delete_file_path",
      "create_n",
      "aug_n",
      "aug_percent",
      "aug_min",
      "aug_max",
      "model_name",
      "vocab"
    ],
    "_load_insert_dict": [
      "self",
      "source_type"
    ],
    "_augment": [
      "self",
      "sequence"
    ],
    "_augment_mlm": [
      "self",
      "sequence",
      "seq_tokens",
      "aug_indexes"
    ],
    "_augment_multi": [
      "self",
      "seq_tokens",
      "aug_n",
      "aug_indexes"
    ],
    "_augment_single": [
      "self",
      "seq_tokens",
      "aug_indexes"
    ],
    "_generate_sequence": [
      "self",
      "output_seq_tokens",
      "aug_tokens",
      "p"
    ]
  },
  "WordSwap": {
    "__init__": [
      "self",
      "create_n",
      "aug_n",
      "aug_percent",
      "aug_min",
      "aug_max",
      "vocab"
    ],
    "_augment": [
      "self",
      "sequence"
    ],
    "_skip_words": [
      "self",
      "seq_tokens"
    ]
  },
  "WordDelete": {
    "__init__": [
      "self",
      "create_n",
      "aug_n",
      "aug_percent",
      "aug_min",
      "aug_max",
      "vocab"
    ],
    "_augment": [
      "self",
      "sequence"
    ],
    "_skip_words": [
      "self",
      "seq_tokens"
    ]
  },
  "PrefixConfig": {
    "__dict__": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "save_pretrained": [
      "self",
      "save_directory"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "from_json_file": [
      "cls",
      "path_json_file"
    ]
  },
  "bloom_postprocess_past_key_value": [
    "past_key_values"
  ],
  "chatglm_postprocess_past_key_value": [
    "past_key_values"
  ],
  "llama_postprocess_past_key_value": [
    "past_key_values"
  ],
  "qwen_postprocess_past_key_value": [
    "past_key_values"
  ],
  "PrefixModelForCausalLM": {
    "__init__": [
      "self",
      "model",
      "prefix_config",
      "postprocess_past_key_value",
      "pad_attention_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ],
    "generate": [
      "self"
    ],
    "_prepare_inputs_for_generation": [
      "self"
    ],
    "mark_only_prefix_as_trainable": [
      "self"
    ],
    "_create_prefix_encoder": [
      "self"
    ],
    "_get_past_key_values": [
      "self",
      "batch_size"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "print_trainable_parameters": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "model",
      "prefix_path",
      "postprocess_past_key_value",
      "pad_attention_mask"
    ],
    "save_pretrained": [
      "self",
      "save_directory",
      "merge_tensor_parallel"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ],
    "_get_tensor_parallel_convert_actions": [
      "self",
      "loaded_keys",
      "is_split",
      "ignore_error"
    ],
    "_merge_trainable_tensor_parallel": [
      "self",
      "trainable_state_dict"
    ],
    "_convert_tensor_parallel": [
      "self",
      "prefix_state_dict"
    ],
    "save_to_aistudio": [
      "self",
      "repo_id",
      "private",
      "license",
      "exist_ok",
      "subfolder",
      "merge_tensor_parallel"
    ]
  },
  "is_fused_matmul_bias_supported": [],
  "quick_lora": [
    "input",
    "lora_A",
    "lora_B",
    "weight",
    "bias",
    "scaling",
    "is_column",
    "is_row",
    "group",
    "world_size"
  ],
  "QuickLora": {
    "forward": [
      "ctx",
      "input",
      "lora_A",
      "lora_B",
      "weight",
      "bias",
      "scaling",
      "input_stop_gradient"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "ColumnQuickLora": {
    "forward": [
      "ctx",
      "input",
      "lora_A",
      "lora_B",
      "weight",
      "bias",
      "scaling",
      "group",
      "input_stop_gradient"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "RowQuickLora": {
    "forward": [
      "ctx",
      "input",
      "lora_A",
      "lora_B",
      "weight",
      "bias",
      "scaling",
      "group",
      "world_size",
      "input_stop_gradient"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "QuantizationLoRALinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "quant_algo",
      "dtype",
      "weight_attr",
      "scale_attr",
      "bias_attr",
      "block_size",
      "double_quant_block_size",
      "double_quant",
      "qquant_scale_attr",
      "double_quant_scale_attr",
      "quant_sacle_offset_attr",
      "quant_scale_attr",
      "llm_int8_threshold",
      "r",
      "lora_alpha",
      "lora_dropout",
      "merge_weights"
    ],
    "init_float_weight": [
      "self"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ColumnParallelQuantizationLoRALinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "quant_algo",
      "dtype",
      "weight_attr",
      "scale_attr",
      "bias_attr",
      "gather_output",
      "mp_group",
      "r",
      "lora_alpha",
      "lora_dropout",
      "lora_A_weight_attr"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RowParallelQuantizationLoRALinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "quant_algo",
      "dtype",
      "weight_attr",
      "scale_attr",
      "bias_attr",
      "input_is_parallel",
      "mp_group",
      "r",
      "lora_alpha",
      "lora_dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LoRALinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "r",
      "lora_alpha",
      "lora_dropout",
      "merge_weights",
      "use_quick_lora",
      "rslora",
      "lora_plus_scale",
      "pissa"
    ],
    "use_quick_lora": [
      "self"
    ],
    "pissa_init": [
      "self",
      "rank"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "RowParallelLoRALinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "r",
      "lora_alpha",
      "lora_dropout",
      "rslora",
      "lora_plus_scale",
      "merge_weights",
      "use_quick_lora",
      "pissa"
    ],
    "use_quick_lora": [
      "self"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "RowSequenceParallelLoRALinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "r",
      "lora_alpha",
      "lora_dropout",
      "rslora",
      "lora_plus_scale",
      "merge_weights",
      "use_quick_lora"
    ],
    "use_quick_lora": [
      "self"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "ColumnParallelLoRALinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "r",
      "lora_alpha",
      "lora_dropout",
      "rslora",
      "lora_plus_scale",
      "merge_weights",
      "lora_A_weight_attr",
      "use_quick_lora",
      "pissa"
    ],
    "use_quick_lora": [
      "self"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "ColumnSequenceParallelLoRALinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "r",
      "lora_alpha",
      "lora_dropout",
      "rslora",
      "lora_plus_scale",
      "merge_weights",
      "lora_A_weight_attr",
      "use_quick_lora"
    ],
    "use_quick_lora": [
      "self"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "LoRAMergedLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "head_dim",
      "r",
      "lora_alpha",
      "lora_dropout",
      "merge_weights",
      "enable_lora"
    ],
    "zero_pad_and_reshape": [
      "self",
      "x"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "ColumnParallelLoRAMergedLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "head_dim",
      "r",
      "lora_alpha",
      "lora_dropout",
      "merge_weights",
      "enable_lora",
      "lora_A_weight_attr"
    ],
    "zero_pad_and_reshape": [
      "self",
      "x"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "LoRAConv2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "r",
      "lora_alpha",
      "lora_dropout",
      "merge_weights"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "LoRAModel": {
    "__init__": [
      "self",
      "model",
      "lora_config"
    ],
    "add_lora_split_mapping": [
      "self",
      "module_name",
      "is_column"
    ],
    "_get_tensor_parallel_mappings": [
      "self",
      "config",
      "is_split"
    ],
    "from_pretrained": [
      "cls",
      "model",
      "lora_path"
    ],
    "set_state_dict": [
      "self",
      "state_dict"
    ],
    "_merge_trainable_tensor_parallel": [
      "self",
      "trainable_state_dict"
    ],
    "_get_tensor_parallel_convert_actions": [
      "self",
      "loaded_keys",
      "is_split",
      "ignore_error",
      "config"
    ],
    "_convert_tensor_parallel": [
      "self",
      "lora_state_dict"
    ],
    "save_pretrained": [
      "self",
      "save_directory",
      "merge_tensor_parallel"
    ],
    "_find_and_replace_module": [
      "self",
      "model",
      "module_name",
      "lora_config",
      "enable_lora"
    ],
    "_find_and_restore_module": [
      "self",
      "module_name"
    ],
    "get_trainable_state_dict": [
      "self"
    ],
    "print_trainable_parameters": [
      "self"
    ],
    "mark_only_lora_as_trainable": [
      "self"
    ],
    "get_lora_model": [
      "self",
      "model",
      "lora_config"
    ],
    "restore_original_model": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "save_to_aistudio": [
      "self",
      "repo_id",
      "private",
      "license",
      "exist_ok",
      "subfolder",
      "merge_tensor_parallel"
    ]
  },
  "LoRAConfig": {
    "__post_init__": [
      "self"
    ],
    "scaling": [
      "self"
    ],
    "__dict__": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "save_pretrained": [
      "self",
      "save_directory"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "from_json_file": [
      "cls",
      "path_json_file"
    ]
  },
  "QuantedLoRALinear": {
    "__init__": [
      "self",
      "layer",
      "q_config"
    ],
    "forward": [
      "self",
      "input"
    ],
    "_linear_forward": [
      "self",
      "input",
      "weight"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "weights_to_quanters": [
      "self"
    ],
    "activation_quanters": [
      "self"
    ]
  },
  "ColumnParallelQuantedLoRALinear": {
    "__init__": [
      "self",
      "layer",
      "q_config"
    ],
    "forward": [
      "self",
      "input"
    ],
    "_linear_forward": [
      "self",
      "input",
      "weight"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "weights_to_quanters": [
      "self"
    ],
    "activation_quanters": [
      "self"
    ]
  },
  "RowParallelQuantedLoRALinear": {
    "__init__": [
      "self",
      "layer",
      "q_config"
    ],
    "forward": [
      "self",
      "input"
    ],
    "_linear_forward": [
      "self",
      "input",
      "weight"
    ],
    "train": [
      "self"
    ],
    "eval": [
      "self"
    ],
    "weights_to_quanters": [
      "self"
    ],
    "activation_quanters": [
      "self"
    ]
  },
  "EMBEDDING_HOME": [],
  "list_embedding_name": [],
  "TokenEmbedding": {
    "__init__": [
      "self",
      "embedding_name",
      "unknown_token",
      "unknown_token_vector",
      "extended_vocab_path",
      "trainable",
      "keep_extended_vocab_only"
    ],
    "_init_without_extend_vocab": [
      "self",
      "vector_np",
      "pad_vector",
      "unk_vector"
    ],
    "_read_vocab_list_from_file": [
      "self",
      "extended_vocab_path"
    ],
    "_extend_vocab": [
      "self",
      "extended_vocab_path",
      "vector_np",
      "pad_vector",
      "unk_vector",
      "keep_extended_vocab_only"
    ],
    "set_trainable": [
      "self",
      "trainable"
    ],
    "search": [
      "self",
      "words"
    ],
    "get_idx_from_word": [
      "self",
      "word"
    ],
    "get_idx_list_from_words": [
      "self",
      "words"
    ],
    "_dot_np": [
      "self",
      "array_a",
      "array_b"
    ],
    "_calc_word": [
      "self",
      "word_a",
      "word_b",
      "calc_kernel"
    ],
    "dot": [
      "self",
      "word_a",
      "word_b"
    ],
    "cosine_sim": [
      "self",
      "word_a",
      "word_b"
    ],
    "_construct_word_to_idx": [
      "self",
      "idx_to_word"
    ],
    "__repr__": [
      "self"
    ]
  },
  "URL_ROOT": [],
  "EMBEDDING_URL_ROOT": [],
  "PAD_TOKEN": [],
  "UNK_TOKEN": [],
  "EMBEDDING_NAME_LIST": [],
  "DEFAULT_CALLBACKS": [],
  "DEFAULT_PROGRESS_CALLBACK": [],
  "TRAINING_ARGS_NAME": [],
  "TRAINER_STATE_NAME": [],
  "OPTIMIZER_NAME": [],
  "SCHEDULER_NAME": [],
  "SCALER_NAME": [],
  "Trainer": {
    "__init__": [
      "self",
      "model",
      "criterion",
      "args",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "tokenizer",
      "compute_metrics",
      "callbacks",
      "optimizers",
      "preprocess_logits_for_metrics"
    ],
    "_wrap_amp_model": [
      "self",
      "args",
      "model"
    ],
    "add_callback": [
      "self",
      "callback"
    ],
    "pop_callback": [
      "self",
      "callback"
    ],
    "remove_callback": [
      "self",
      "callback"
    ],
    "_load_from_peft_checkpoint": [
      "self",
      "resume_from_checkpoint"
    ],
    "_load_from_checkpoint": [
      "self",
      "resume_from_checkpoint"
    ],
    "_wrap_model_and_load_sharded_checkpoint": [
      "self",
      "resume_from_checkpoint"
    ],
    "train": [
      "self",
      "resume_from_checkpoint",
      "ignore_keys_for_eval"
    ],
    "_inner_training_loop": [
      "self",
      "args",
      "model",
      "train_dataloader",
      "len_dataloader",
      "max_steps",
      "num_train_epochs",
      "num_update_steps_per_epoch",
      "num_train_samples",
      "resume_from_checkpoint",
      "ignore_keys_for_eval"
    ],
    "_load_best_model_from_peft_checkpoint": [
      "self"
    ],
    "_get_train_sampler": [
      "self"
    ],
    "_set_state_dict_in_model": [
      "self",
      "state_dict"
    ],
    "_print_timer": [
      "self"
    ],
    "_get_item_from_loss": [
      "self",
      "loss"
    ],
    "_maybe_log_save_evaluate": [
      "self",
      "tr_loss",
      "model",
      "epoch",
      "ignore_keys_for_eval"
    ],
    "_get_learning_rate": [
      "self"
    ],
    "get_train_dataloader": [
      "self"
    ],
    "_get_eval_sampler": [
      "self",
      "eval_dataset"
    ],
    "get_eval_dataloader": [
      "self",
      "eval_dataset"
    ],
    "get_test_dataloader": [
      "self",
      "test_dataset"
    ],
    "create_optimizer_and_scheduler": [
      "self",
      "num_training_steps"
    ],
    "create_optimizer": [
      "self",
      "lr_scheduler"
    ],
    "_load_rng_state": [
      "self",
      "checkpoint"
    ],
    "get_optimizer_cls_and_kwargs": [
      "args"
    ],
    "create_scheduler": [
      "self",
      "num_training_steps"
    ],
    "num_examples": [
      "self",
      "dataloader"
    ],
    "_wrap_model": [
      "self",
      "model",
      "training"
    ],
    "_prepare_input": [
      "self",
      "data"
    ],
    "_prepare_inputs": [
      "self",
      "inputs"
    ],
    "autocast_smart_context_manager": [
      "self"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs",
      "return_outputs"
    ],
    "_enable_delay_scale_loss": [
      "self"
    ],
    "training_step": [
      "self",
      "model",
      "inputs"
    ],
    "training_pipeline_step": [
      "self",
      "model",
      "inputs"
    ],
    "save_model": [
      "self",
      "output_dir",
      "merge_tensor_parallel"
    ],
    "_filter_moe_no_sync_optimizer_params": [
      "self"
    ],
    "_save_checkpoint": [
      "self",
      "model",
      "metrics"
    ],
    "set_optimizer_grouped_parameters": [
      "self",
      "optimizer_grouped_parameters"
    ],
    "disable_autocast_context_manager": [
      "self"
    ],
    "_sorted_checkpoints": [
      "self",
      "output_dir",
      "checkpoint_prefix",
      "use_mtime"
    ],
    "_rotate_checkpoints": [
      "self",
      "use_mtime",
      "output_dir"
    ],
    "_save": [
      "self",
      "output_dir",
      "state_dict",
      "merge_tensor_parallel"
    ],
    "_load_optimizer_and_scheduler": [
      "self",
      "checkpoint"
    ],
    "log": [
      "self",
      "logs"
    ],
    "evaluate": [
      "self",
      "eval_dataset",
      "ignore_keys",
      "metric_key_prefix"
    ],
    "evaluation_loop": [
      "self",
      "dataloader",
      "description",
      "prediction_loss_only",
      "ignore_keys",
      "metric_key_prefix",
      "max_eval_iters"
    ],
    "predict": [
      "self",
      "test_dataset",
      "ignore_keys",
      "metric_key_prefix"
    ],
    "prediction_pipeline_step": [
      "self",
      "model",
      "inputs",
      "prediction_loss_only",
      "ignore_keys"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs",
      "prediction_loss_only",
      "ignore_keys"
    ],
    "is_local_process_zero": [
      "self"
    ],
    "is_world_process_zero": [
      "self"
    ],
    "_nested_gather": [
      "self",
      "tensors"
    ],
    "_pad_across_processes": [
      "self",
      "tensor",
      "pad_index"
    ],
    "_set_signature_columns_if_needed": [
      "self"
    ],
    "_remove_unused_columns": [
      "self",
      "dataset",
      "description"
    ],
    "_get_collator_with_removed_columns": [
      "self",
      "data_collator",
      "description"
    ],
    "_is_iterable_dataset": [
      "self",
      "dataset"
    ],
    "print_config": [
      "self",
      "args",
      "key"
    ],
    "is_unified_checkpoint": [
      "self",
      "resume_from_checkpoint",
      "safe_serialization"
    ]
  },
  "DataClass": [],
  "DataClassType": [],
  "strtobool": [
    "v"
  ],
  "PdArgumentParser": {
    "__init__": [
      "self",
      "dataclass_types"
    ],
    "_parse_dataclass_field": [
      "parser",
      "field"
    ],
    "_add_dataclass_arguments": [
      "self",
      "dtype"
    ],
    "parse_args_into_dataclasses": [
      "self",
      "args",
      "return_remaining_strings",
      "look_for_args_file",
      "args_filename"
    ],
    "common_parse": [
      "self",
      "args",
      "return_remaining_strings"
    ],
    "read_json": [
      "self",
      "json_file"
    ],
    "parse_json_file": [
      "self",
      "json_file",
      "return_remaining_strings"
    ],
    "parse_json_file_and_cmd_lines": [
      "self",
      "return_remaining_strings"
    ],
    "parse_dict": [
      "self",
      "args"
    ]
  },
  "global_try_import_slim": [],
  "compress": [
    "self",
    "custom_evaluate"
  ],
  "quant": [
    "self",
    "model_dir",
    "strategy"
  ],
  "generate_input_spec": [
    "model",
    "dataset",
    "input_dtype"
  ],
  "_dynabert": [
    "self",
    "model"
  ],
  "_replace_transformer_func": [
    "self"
  ],
  "_recover_transformer_func": [
    "self",
    "all_recover"
  ],
  "_replace_auto_model_forward": [
    "self"
  ],
  "_replace_auto_model_qat_forward": [
    "self"
  ],
  "_recover_auto_model_forward": [
    "self"
  ],
  "_dynabert_init": [
    "self",
    "model",
    "eval_dataloader"
  ],
  "check_dynabert_config": [
    "net_config",
    "width_mult"
  ],
  "evaluate": [
    "self",
    "model",
    "data_loader"
  ],
  "evaluate_qa": [
    "self",
    "model",
    "data_loader"
  ],
  "evaluate_seq_cls": [
    "self",
    "model",
    "data_loader"
  ],
  "evaluate_token_cls": [
    "self",
    "model",
    "data_loader"
  ],
  "_dynabert_training": [
    "self",
    "ofa_model",
    "model",
    "teacher_model",
    "train_dataloader",
    "eval_dataloader",
    "num_train_epochs"
  ],
  "_get_dynabert_model": [
    "model",
    "width_mult"
  ],
  "_load_parameters": [
    "dynabert_model",
    "ori_state_dict"
  ],
  "_export_dynamic_dynabert_model": [
    "self",
    "width_mult"
  ],
  "_dynabert_export": [
    "self"
  ],
  "_post_training_quantization_grid_search": [
    "self",
    "model_dir"
  ],
  "_quant_aware_training_dynamic": [
    "self",
    "input_dir"
  ],
  "_quant_embeddings": [
    "self",
    "input_prefix"
  ],
  "auto_model_dynabert_forward": [
    "self",
    "input_ids",
    "token_type_ids",
    "position_ids",
    "attention_mask",
    "task_type_ids",
    "past_key_values",
    "inputs_embeds",
    "use_cache",
    "output_hidden_states",
    "output_attentions",
    "return_dict"
  ],
  "auto_model_forward": [
    "self",
    "input_ids",
    "token_type_ids",
    "position_ids",
    "attention_mask",
    "task_type_ids",
    "past_key_values",
    "inputs_embeds",
    "use_cache",
    "output_hidden_states",
    "output_attentions",
    "return_dict"
  ],
  "soft_cross_entropy": [
    "inp",
    "target"
  ],
  "reset_optimizer_and_scheduler": [
    "self"
  ],
  "cut_embeddings": [
    "model",
    "tokenizer",
    "config",
    "word_emb_index",
    "max_seq_length",
    "max_vocab_size",
    "output_dir"
  ],
  "TrainerState": {
    "__post_init__": [
      "self"
    ],
    "save_to_json": [
      "self",
      "json_path"
    ],
    "load_from_json": [
      "cls",
      "json_path"
    ]
  },
  "TrainerControl": {
    "_new_training": [
      "self"
    ],
    "_new_epoch": [
      "self"
    ],
    "_new_step": [
      "self"
    ]
  },
  "TrainerCallback": {
    "on_init_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_train_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_train_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_epoch_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_epoch_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_step_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_load_data_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_optimizer_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_optimizer_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_substep_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_step_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_evaluate": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_save": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_log": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_prediction_step": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "CallbackHandler": {
    "__init__": [
      "self",
      "callbacks",
      "model",
      "tokenizer",
      "optimizer",
      "lr_scheduler"
    ],
    "add_callback": [
      "self",
      "callback"
    ],
    "pop_callback": [
      "self",
      "callback"
    ],
    "remove_callback": [
      "self",
      "callback"
    ],
    "callback_list": [
      "self"
    ],
    "on_init_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_train_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_train_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_epoch_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_epoch_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_step_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_load_data_end": [
      "self",
      "args",
      "state",
      "control",
      "inputs"
    ],
    "on_optimizer_begin": [
      "self",
      "args",
      "state",
      "control",
      "scaler"
    ],
    "on_optimizer_end": [
      "self",
      "args",
      "state",
      "control",
      "scaler"
    ],
    "on_substep_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_step_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_evaluate": [
      "self",
      "args",
      "state",
      "control",
      "metrics"
    ],
    "on_save": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_log": [
      "self",
      "args",
      "state",
      "control",
      "logs"
    ],
    "on_prediction_step": [
      "self",
      "args",
      "state",
      "control"
    ],
    "call_event": [
      "self",
      "event",
      "args",
      "state",
      "control"
    ]
  },
  "DefaultFlowCallback": {
    "on_step_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_epoch_end": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "ProgressCallback": {
    "__init__": [
      "self"
    ],
    "on_train_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_step_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_prediction_step": [
      "self",
      "args",
      "state",
      "control",
      "eval_dataloader"
    ],
    "on_evaluate": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_log": [
      "self",
      "args",
      "state",
      "control",
      "logs"
    ],
    "on_train_end": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "PrinterCallback": {
    "on_log": [
      "self",
      "args",
      "state",
      "control",
      "logs"
    ]
  },
  "EarlyStoppingCallback": {
    "__init__": [
      "self",
      "early_stopping_patience",
      "early_stopping_threshold"
    ],
    "check_metric_value": [
      "self",
      "args",
      "state",
      "control",
      "metric_value"
    ],
    "on_train_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_evaluate": [
      "self",
      "args",
      "state",
      "control",
      "metrics"
    ]
  },
  "is_visualdl_available": [],
  "is_tensorboard_available": [],
  "is_wandb_available": [],
  "is_ray_available": [],
  "get_available_reporting_integrations": [],
  "rewrite_logs": [
    "d"
  ],
  "VisualDLCallback": {
    "__init__": [
      "self",
      "vdl_writer"
    ],
    "_init_summary_writer": [
      "self",
      "args",
      "log_dir"
    ],
    "on_train_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_log": [
      "self",
      "args",
      "state",
      "control",
      "logs"
    ],
    "on_train_end": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "TensorBoardCallback": {
    "__init__": [
      "self",
      "tb_writer"
    ],
    "_init_summary_writer": [
      "self",
      "args",
      "log_dir"
    ],
    "on_train_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_log": [
      "self",
      "args",
      "state",
      "control",
      "logs"
    ],
    "on_train_end": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "WandbCallback": {
    "__init__": [
      "self"
    ],
    "setup": [
      "self",
      "args",
      "state",
      "model"
    ],
    "on_train_begin": [
      "self",
      "args",
      "state",
      "control",
      "model"
    ],
    "on_train_end": [
      "self",
      "args",
      "state",
      "control",
      "model",
      "tokenizer"
    ],
    "on_log": [
      "self",
      "args",
      "state",
      "control",
      "model",
      "logs"
    ],
    "on_save": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "AutoNLPCallback": {
    "__init__": [
      "self"
    ],
    "on_evaluate": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "INTEGRATION_TO_CALLBACK": [],
  "get_reporting_integration_callbacks": [
    "report_to"
  ],
  "MODEL_NAME": [],
  "DIST_CKPT_PATH": [],
  "AutoTrainer": {
    "__init__": [
      "self"
    ],
    "_nested_gather": [
      "self",
      "tensors"
    ],
    "_wrap_model": [
      "self",
      "model",
      "training"
    ],
    "_get_meshes_for_loader": [
      "self"
    ],
    "_wrap_for_dist_loader": [
      "self",
      "train_dataloader"
    ],
    "_wrap_for_auto": [
      "self",
      "model",
      "train_dataloader"
    ],
    "_wrap_amp_model": [
      "self",
      "args",
      "model"
    ],
    "_get_item_from_loss": [
      "self",
      "loss"
    ],
    "_split_batches_for_accumulation": [
      "self",
      "inputs"
    ],
    "_inner_training_loop": [
      "self",
      "args",
      "model",
      "train_dataloader",
      "len_dataloader",
      "max_steps",
      "num_train_epochs",
      "num_update_steps_per_epoch",
      "num_train_samples",
      "resume_from_checkpoint",
      "ignore_keys_for_eval"
    ],
    "_get_train_sampler": [
      "self"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs",
      "return_outputs"
    ],
    "dynamic_traning": [
      "self",
      "model",
      "inputs"
    ],
    "static_traning": [
      "self",
      "model",
      "inputs"
    ],
    "training_step": [
      "self",
      "model",
      "inputs"
    ],
    "optimizer_step": [
      "self"
    ],
    "_maybe_log_save_evaluate": [
      "self",
      "tr_loss",
      "model",
      "epoch",
      "ignore_keys_for_eval"
    ],
    "_save_checkpoint": [
      "self",
      "model",
      "metrics"
    ],
    "_save": [
      "self",
      "output_dir",
      "state_dict",
      "merge_tensor_parallel"
    ],
    "_load_from_checkpoint": [
      "self",
      "resume_from_checkpoint"
    ]
  },
  "default_logdir": [],
  "TrainingArguments": {
    "__post_init__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [],
    "train_batch_size": [
      "self"
    ],
    "eval_batch_size": [
      "self"
    ],
    "current_device": [
      "self"
    ],
    "world_size": [
      "self"
    ],
    "data_parallel_rank": [
      "self"
    ],
    "dataset_rank": [
      "self"
    ],
    "dataset_world_size": [
      "self"
    ],
    "sharding_parallel_rank": [
      "self"
    ],
    "tensor_parallel_rank": [
      "self"
    ],
    "pipeline_parallel_rank": [
      "self"
    ],
    "optimizer_name_suffix": [
      "self"
    ],
    "weight_name_suffix": [
      "self"
    ],
    "sharded_name_suffix": [
      "self",
      "shard_id",
      "pp_id",
      "moe_id"
    ],
    "process_index": [
      "self"
    ],
    "logical_process_index": [
      "self"
    ],
    "local_process_index": [
      "self"
    ],
    "should_log": [
      "self"
    ],
    "should_save": [
      "self"
    ],
    "should_save_model_state": [
      "self"
    ],
    "_no_sync_in_gradient_accumulation": [
      "self"
    ],
    "should_save_sharding_stage1_model": [
      "self"
    ],
    "should_load_sharding_stage1_model": [
      "self"
    ],
    "should_load_dataset": [
      "self"
    ],
    "main_process_first": [
      "self",
      "local",
      "desc"
    ],
    "get_warmup_steps": [
      "self",
      "num_training_steps"
    ],
    "to_dict": [
      "self"
    ],
    "to_json_string": [
      "self"
    ],
    "to_sanitized_dict": [
      "self"
    ],
    "print_config": [
      "self",
      "args",
      "key"
    ]
  },
  "Seq2SeqTrainingArguments": {},
  "CompressionArguments": {
    "print_config": [
      "self",
      "args",
      "key"
    ]
  },
  "_get_distributed_seeds": [
    "seed",
    "topo"
  ],
  "set_seed": [
    "seed",
    "topo"
  ],
  "_switch_mode": [
    "mode"
  ],
  "_exec_mode_guard": [
    "mode"
  ],
  "EvalPrediction": {},
  "EvalLoopOutput": {},
  "PredictionOutput": {},
  "TrainOutput": {},
  "PREFIX_CHECKPOINT_DIR": [],
  "_re_checkpoint": [],
  "get_last_checkpoint": [
    "folder"
  ],
  "IntervalStrategy": {
    "NO": [],
    "STEPS": [],
    "EPOCH": []
  },
  "EvaluationStrategy": {
    "NO": [],
    "STEPS": [],
    "EPOCH": []
  },
  "OptimizerNames": {
    "ADAMW": [],
    "ADAFACTOR": []
  },
  "ShardingOption": {
    "SHARD_OP": [],
    "SHARD_GRAD_OP": [],
    "FULL_SHARD": [],
    "OFFLOAD": []
  },
  "is_main_process": [
    "local_rank"
  ],
  "total_processes_number": [
    "local_rank"
  ],
  "speed_metrics": [
    "split",
    "start_time",
    "num_samples",
    "num_steps",
    "seq_length"
  ],
  "SchedulerType": {
    "LINEAR": [],
    "COSINE": [],
    "CONSTANT": [],
    "CONSTANT_WITH_WARMUP": [],
    "POLYNOMIAL": []
  },
  "get_constant_schedule": [
    "learning_rate",
    "last_epoch"
  ],
  "get_constant_schedule_with_warmup": [
    "learning_rate",
    "num_warmup_steps",
    "last_epoch"
  ],
  "get_linear_schedule_with_warmup": [
    "learning_rate",
    "num_warmup_steps",
    "num_training_steps",
    "last_epoch"
  ],
  "get_cosine_schedule_with_warmup": [
    "learning_rate",
    "num_warmup_steps",
    "num_training_steps",
    "num_cycles",
    "last_epoch"
  ],
  "get_polynomial_decay_schedule_with_warmup": [
    "learning_rate",
    "num_warmup_steps",
    "num_training_steps",
    "lr_end",
    "power",
    "last_epoch"
  ],
  "TYPE_TO_SCHEDULER_FUNCTION": [],
  "get_scheduler": [
    "name",
    "learning_rate",
    "num_warmup_steps",
    "num_training_steps",
    "num_cycles",
    "lr_end",
    "power"
  ],
  "_secs2timedelta": [
    "secs"
  ],
  "metrics_format": [
    "self",
    "metrics"
  ],
  "log_metrics": [
    "self",
    "split",
    "metrics"
  ],
  "save_metrics": [
    "self",
    "split",
    "metrics",
    "combined"
  ],
  "save_state": [
    "self"
  ],
  "has_length": [
    "dataset"
  ],
  "TrainerMemoryTracker": {
    "stages": [],
    "__init__": [
      "self",
      "skip_memory_metrics"
    ],
    "derive_stage": [
      "self"
    ],
    "cpu_mem_used": [
      "self"
    ],
    "peak_monitor_func": [
      "self"
    ],
    "start": [
      "self"
    ],
    "stop": [
      "self",
      "stage"
    ],
    "update_metrics": [
      "self",
      "stage",
      "metrics"
    ],
    "stop_and_update_metrics": [
      "self",
      "metrics"
    ]
  },
  "IterableDatasetShard": {
    "__init__": [
      "self",
      "dataset",
      "batch_size",
      "drop_last",
      "num_processes",
      "process_index",
      "seed"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "find_batch_size": [
    "tensors"
  ],
  "RemoveColumnsCollator": {
    "__init__": [
      "self",
      "data_collator",
      "signature_columns",
      "logger",
      "model_name",
      "description"
    ],
    "_remove_columns": [
      "self",
      "feature"
    ],
    "__call__": [
      "self",
      "features"
    ]
  },
  "set_hyrbid_parallel_seed": [
    "basic_seed",
    "dataset_rank",
    "tp_rank",
    "pp_rank"
  ],
  "Seq2SeqTrainer": {
    "evaluate": [
      "self",
      "eval_dataset",
      "ignore_keys",
      "metric_key_prefix"
    ],
    "predict": [
      "self",
      "test_dataset",
      "ignore_keys",
      "metric_key_prefix"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs",
      "prediction_loss_only",
      "ignore_keys"
    ],
    "_pad_tensors_to_max_len": [
      "self",
      "tensor",
      "max_length"
    ]
  },
  "distributed_concat": [
    "tensor",
    "num_total_examples"
  ],
  "paddle_pad_and_concatenate": [
    "tensor1",
    "tensor2",
    "padding_index"
  ],
  "numpy_pad_and_concatenate": [
    "array1",
    "array2",
    "padding_index"
  ],
  "nested_concat": [
    "tensors",
    "new_tensors",
    "padding_index"
  ],
  "nested_detach": [
    "tensors"
  ],
  "nested_numpify": [
    "tensors"
  ],
  "nested_truncate": [
    "tensors",
    "limit"
  ],
  "distributed_isfile": [
    "filename"
  ],
  "distributed_file": [
    "filename"
  ],
  "broadcast_dp_optimizer": [
    "state_dict"
  ],
  "broadcast_moe_optimizer": [
    "state_dict",
    "broadcast_dp"
  ],
  "add_start_docstrings": [],
  "add_start_docstrings_to_model_forward": [],
  "add_end_docstrings": [],
  "MODEL_META_NAME": [],
  "SHARDING_META_NAME": [],
  "filter_sharded_params": [
    "state_dict",
    "optimizer",
    "sharding_group"
  ],
  "exclude_paramters_in_state_dict": [
    "model_state_dict",
    "param_names_in_master_weights",
    "sharding_group",
    "should_save_sharding_stage1_model"
  ],
  "ShardingIO": {
    "__init__": [
      "self",
      "args",
      "model",
      "optimizer",
      "hcg"
    ],
    "set_optimizer": [
      "self",
      "optimizer"
    ],
    "load_state_dict_from_checkpoint_with_reshard": [
      "self",
      "checkpoint",
      "base_weight_name",
      "model_wrapped"
    ],
    "_load_one_state_dict_from_checkpoint": [
      "self",
      "resume_from_checkpoint",
      "base_weight_name",
      "weight_name_suffix"
    ],
    "_load_optimizer_state_of_one_shard": [
      "self",
      "checkpoint",
      "base_opt_name",
      "optimizer_name_suffix"
    ],
    "_need_reshard": [
      "self",
      "checkpoint"
    ],
    "_need_reshard_pp": [
      "self",
      "checkpoint"
    ],
    "load_optimizer_state_with_reshard": [
      "self",
      "checkpoint",
      "base_opt_name",
      "model_wrapped"
    ],
    "manipulate_state_dict_and_config": [
      "self",
      "model_to_save",
      "merge_tensor_parallel"
    ],
    "save_distributed_model_meta": [
      "self",
      "dir"
    ],
    "_get_distributed_strategy": [
      "self"
    ],
    "_recover_params_from_master_weights": [
      "self",
      "state_dict"
    ],
    "_all_gather_simple_object": [
      "self",
      "obj",
      "group"
    ],
    "_load_model_meta": [
      "self",
      "dir"
    ],
    "_load_distributed_strategy": [
      "self",
      "dir"
    ],
    "_load_sharding_meta": [
      "self",
      "dir",
      "pp_rank"
    ],
    "_map_optimizer_state_to_param": [
      "self",
      "optimizer_state_names"
    ],
    "_gather_sharding_metas": [
      "self"
    ]
  },
  "SHARDING_STRATEGY_V1": [],
  "SHARDING_STRATEGY_V2": [],
  "is_sharding_opt": [
    "optimizer"
  ],
  "get_sharding_strategy": [
    "optimizer"
  ],
  "NodeModelState": {
    "__init__": [
      "self",
      "mp_rank",
      "sharding_rank",
      "pp_rank"
    ],
    "set_node_rank": [
      "self",
      "mp_rank",
      "sharding_rank",
      "pp_rank"
    ],
    "_add_kv": [
      "self",
      "d",
      "k",
      "v"
    ],
    "model_weights": [
      "self"
    ],
    "add_weight": [
      "self",
      "k",
      "v"
    ],
    "add_weights": [
      "self",
      "model_state_dict",
      "rank"
    ],
    "set_weights": [
      "self",
      "model_state_dict"
    ],
    "set_opt_state": [
      "self",
      "opt_state_dict"
    ],
    "set_master_weights": [
      "self",
      "master_weights"
    ],
    "opt_state": [
      "self"
    ],
    "add_opt": [
      "self",
      "k",
      "v"
    ],
    "add_opts": [
      "self",
      "opts",
      "rank"
    ],
    "master_weights": [
      "self"
    ],
    "add_master_weight": [
      "self",
      "k",
      "v"
    ],
    "add_master_weights": [
      "self",
      "master",
      "rank"
    ],
    "lr_scheduler": [
      "self"
    ],
    "set_lr_scheduler": [
      "self",
      "lr_scheduler"
    ],
    "map_names": [
      "self",
      "map_func"
    ],
    "drop_rank": [
      "self"
    ],
    "collapse_key": [
      "self"
    ],
    "flatten_key": [
      "self"
    ],
    "pack_keys": [
      "self",
      "structure_name_mapping"
    ],
    "unpack_keys": [
      "self"
    ],
    "split_state": [
      "self",
      "split_func"
    ],
    "even_distribute": [
      "self",
      "group"
    ],
    "reshard": [
      "self",
      "group",
      "filter_func"
    ],
    "split_items": [
      "self",
      "split_func"
    ],
    "merge_items": [
      "self",
      "merge_func"
    ],
    "merge_from": [
      "self",
      "other",
      "rank"
    ],
    "get_opt_state_dict": [
      "self"
    ]
  },
  "all_gather_simple_object": [
    "obj",
    "group"
  ],
  "all_gather_state_dict": [
    "state_dict",
    "filter_func",
    "group"
  ],
  "_all_gather_state_dict": [
    "state_dict",
    "filter_func",
    "group"
  ],
  "shard": [
    "node_model_state",
    "model",
    "optimizer",
    "hcg"
  ],
  "restore": [
    "node_model_state",
    "model",
    "optimizer",
    "hcg"
  ],
  "merge_tensors": [
    "k",
    "tensor_list",
    "shape"
  ],
  "pad_tensor": [
    "k",
    "tensor",
    "padded_size"
  ],
  "slice_tensor": [
    "tensor",
    "begin",
    "end"
  ],
  "collect_split_info": [
    "optimizer",
    "model"
  ],
  "is_bata": [
    "name"
  ],
  "_GLOBAL_EXTRACT_LAYER_NAME_FUNC": [],
  "regitser_extract_layer_name_func": [
    "func"
  ],
  "get_extract_layer_name_func": [],
  "_GLOBAL_INDEX_LAYER_FUNC": [],
  "register_index_layer_func": [
    "func"
  ],
  "get_index_layer_func": [],
  "LayerNameScope": {
    "registered_layers": [],
    "__init__": [
      "self",
      "prefix",
      "template"
    ],
    "get_layer_prefix": [
      "cls",
      "old_layer_name"
    ],
    "register_layer_prefix": [
      "cls",
      "prefix"
    ],
    "get_next_scope": [
      "self",
      "layer_id",
      "old_layer_name"
    ],
    "get_layer_name": [
      "self"
    ],
    "get_sub_scope": [
      "self",
      "sub_layer_name"
    ]
  },
  "register_layername_prefix": [
    "layer_name"
  ],
  "extract_param_names_groupby_layer": [
    "meta",
    "mp_rank"
  ],
  "build_pipeline_context": [
    "meta",
    "pp_model"
  ],
  "LayerReNamingManager": {
    "__init__": [
      "self"
    ],
    "get_new_layer_name": [
      "self",
      "layer_id",
      "old_name"
    ],
    "get_new_param_name": [
      "self",
      "layer_id",
      "old_name"
    ]
  },
  "PipeLinelayer": {
    "__init__": [
      "self",
      "layer_name",
      "param_names"
    ],
    "params": [
      "self"
    ],
    "name": [
      "self"
    ]
  },
  "PipeLineSegment": {
    "__init__": [
      "self",
      "start_index",
      "end_index"
    ],
    "add_layer": [
      "self",
      "layer_name",
      "param_names"
    ],
    "layers": [
      "self"
    ]
  },
  "PipeLineStage": {
    "__init__": [
      "self"
    ],
    "add_segment": [
      "self",
      "start_index",
      "end_index"
    ],
    "add_layer": [
      "self",
      "layer_index",
      "layer_name",
      "param_names"
    ],
    "build_name_mapping": [
      "self"
    ],
    "map_name": [
      "self",
      "param_name",
      "t_name"
    ],
    "print_name_mapping": [
      "self"
    ]
  },
  "PipeLineSegmentContext": {
    "__init__": [
      "self",
      "pp_model",
      "param_names_by_layer"
    ],
    "_index_layers": [
      "self"
    ],
    "_segment": [
      "self"
    ],
    "map_name": [
      "self",
      "param_name",
      "t_name"
    ],
    "map_name_to_stage": [
      "self",
      "name"
    ],
    "print_name_mapping": [
      "self"
    ]
  },
  "reshard": [
    "node_model_state",
    "reshard_context",
    "hcg"
  ],
  "npu_accelerate_plugin": [
    "optimizer"
  ],
  "_optimizer_step_with_flatten_param_grads": [
    "optimizer"
  ],
  "_flatten_param_grads": [
    "optimizer",
    "params_grads"
  ],
  "FP32_MASTER": [],
  "optimizer_scalar_name": [],
  "optimizer_non_scaler_name": [],
  "async_save_queue": [],
  "DEST_PLACE": [],
  "UnifiedCheckpointOption": {
    "SKIP_SAVE_MODEL_WEIGHT": [],
    "MASTER_WEIGHT_COMPATIBLE": [],
    "ASYNC_SAVE": []
  },
  "save_unified_checkpoint": [
    "args",
    "model",
    "optimizer",
    "output_dir",
    "safe_serialization"
  ],
  "load_unified_checkpoint": [
    "args",
    "model",
    "optimizer",
    "resume_from_checkpoint",
    "safe_serialization"
  ],
  "load_unified_checkpoint_locally": [
    "args",
    "model",
    "resume_from_checkpoint",
    "safe_serialization"
  ],
  "save_config": [
    "model_to_save"
  ],
  "unified_checkpoint_into_shards": [
    "args",
    "model_to_save",
    "safe_serialization"
  ],
  "save_unified_optimizer": [
    "args",
    "model",
    "optimizer",
    "output_dir",
    "safe_serialization"
  ],
  "load_unified_optimizer": [
    "args",
    "model",
    "optimizer",
    "resume_from_checkpoint",
    "safe_serialization"
  ],
  "load_unified_optimizer_locally": [
    "args",
    "model",
    "optimizer",
    "resume_from_checkpoint",
    "safe_serialization"
  ],
  "unified_optimizer_into_shards": [
    "args",
    "model",
    "optimizer",
    "safe_serialization"
  ],
  "check_unified_checkpoint": [
    "args",
    "model",
    "resume_from_checkpoint",
    "safe_serialization"
  ],
  "check_unified_optimizer": [
    "args",
    "model",
    "optimizer",
    "resume_from_checkpoint",
    "safe_serialization"
  ],
  "save_single_card_checkpoint": [
    "args",
    "model_to_save",
    "output_dir"
  ],
  "save_single_card_optimizer": [
    "args",
    "model",
    "optimizer",
    "output_dir"
  ],
  "save_prefix_past_key_value": [
    "model_to_save",
    "save_directory"
  ],
  "get_expected_state_dict": [
    "model_to_save"
  ],
  "create_dispatch_table": [
    "args",
    "model",
    "file_keyname_mappings",
    "file_machine_mappings",
    "resume_from_checkpoint"
  ],
  "create_optimizer_dispatch_table": [
    "args",
    "model",
    "optimizer",
    "file_keyname_mappings",
    "file_machine_mappings",
    "resume_from_checkpoint",
    "struct2static_name_mappings",
    "is_master_weights",
    "typename_set"
  ],
  "load_unified_checkpoint_dynamically": [
    "args",
    "model",
    "optimizer",
    "resume_from_checkpoint",
    "safe_serialization"
  ],
  "load_unified_optimizer_dynamically": [
    "args",
    "model",
    "optimizer",
    "resume_from_checkpoint",
    "safe_serialization"
  ],
  "load_single_card_checkpoint": [
    "args",
    "model",
    "resume_from_checkpoint"
  ],
  "load_single_card_optimizer": [
    "args",
    "model",
    "optimizer",
    "resume_from_checkpoint"
  ],
  "get_file_mappings": [
    "index",
    "resume_from_checkpoint"
  ],
  "create_send_table": [
    "file_keyname_mappings",
    "file_machine_mappings"
  ],
  "distributed_send_recv": [
    "config",
    "state_dict",
    "tp_actions",
    "send_table",
    "recv_table",
    "resume_from_checkpoint",
    "file_keyname_mappings",
    "file_machine_mappings"
  ],
  "get_sharded_file_name": [
    "args",
    "file_name",
    "is_optimizer"
  ],
  "get_sharded_index": [
    "index_file_list",
    "total_size_list"
  ],
  "reduce_master_weights_status": [
    "has_master_weights"
  ],
  "gather_sharded_object": [
    "index_file",
    "total_size",
    "is_optimizer"
  ],
  "generate_base_static_name": [
    "vname"
  ],
  "filter_params": [
    "model_to_save",
    "state_dict",
    "is_optimizer"
  ],
  "merge_tensor_parallel_with_shard": [
    "state_dict",
    "tp_actions",
    "all_filter_keys"
  ],
  "merge_tensor_parallel_for_optimizer": [
    "state_dict",
    "tp_actions",
    "all_filter_keys"
  ],
  "get_optimizer_shard_files": [
    "optimizer_path",
    "index_filename"
  ],
  "get_expected_keys": [
    "sharded_metadata",
    "model",
    "optimizer"
  ],
  "mapping_optimizer_tp_actions": [
    "tp_actions",
    "optimizer_loaded_keys"
  ],
  "flatten_list": [
    "nested_list"
  ],
  "check_exitcode": [
    "task"
  ],
  "clear_async_save_task_queue": [],
  "file_save_async_or_sync": [
    "state_dict",
    "path",
    "safe_serialization",
    "is_sync"
  ],
  "select_model_weight_index": [
    "args",
    "model",
    "resume_from_checkpoint",
    "safe_serialization",
    "local"
  ],
  "update_master_weight_status": [
    "args",
    "optimizer",
    "has_master_weight",
    "safe_serialization"
  ],
  "is_need_master_weight": [
    "optimizer",
    "is_fp16_or_bp16"
  ],
  "_Timer": {
    "__init__": [
      "self",
      "name"
    ],
    "start": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "elapsed": [
      "self",
      "reset"
    ]
  },
  "RuntimeTimer": {
    "__init__": [
      "self",
      "name"
    ],
    "start": [
      "self",
      "name"
    ],
    "stop": [
      "self"
    ],
    "log": [
      "self"
    ]
  },
  "Timers": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "name"
    ],
    "write": [
      "self",
      "names",
      "writer",
      "iteration",
      "normalizer",
      "reset"
    ],
    "log": [
      "self",
      "names",
      "normalizer",
      "reset"
    ]
  },
  "_GLOBAL_TIMERS": [],
  "get_timers": [],
  "set_timers": [],
  "disable_timers": [],
  "MLMPromptTokenizer": {
    "omask_token": [],
    "__init__": [
      "self",
      "tokenizer",
      "max_length"
    ],
    "__call__": [
      "self",
      "inputs"
    ],
    "_create_position_ids_from_part": [
      "self",
      "input_ids",
      "part",
      "last_position"
    ],
    "_create_max_lengths_from_do_truncate": [
      "self",
      "part_text",
      "part_do_truncate"
    ],
    "_create_attention_mask": [
      "self",
      "input_ids",
      "option_length"
    ],
    "_create_masked_positions": [
      "self",
      "input_ids",
      "soft_token_ids"
    ],
    "add_special_tokens": [
      "self",
      "input_dict"
    ],
    "join": [
      "input_dict"
    ]
  },
  "VERBALIZER_CONFIG_FILE": [],
  "VERBALIZER_PARAMETER_FILE": [],
  "Verbalizer": {
    "__init__": [
      "self",
      "label_words",
      "tokenizer"
    ],
    "labels": [
      "self",
      "labels"
    ],
    "label_words": [
      "self",
      "label_words"
    ],
    "create_parameters": [
      "self"
    ],
    "preprocess_label_words": [
      "self"
    ],
    "convert_labels_to_ids": [
      "self",
      "label"
    ],
    "convert_ids_to_labels": [
      "self",
      "index"
    ],
    "project": [
      "self",
      "outputs"
    ],
    "process_outputs": [
      "self",
      "outputs",
      "masked_positions"
    ],
    "aggregate": [
      "self",
      "outputs",
      "mask",
      "atype"
    ],
    "normalize": [
      "self",
      "outputs"
    ],
    "calibrate": [
      "self",
      "label_word_outputs"
    ],
    "save": [
      "self",
      "save_path"
    ],
    "load_from": [
      "cls",
      "data_path",
      "tokenizer"
    ]
  },
  "ManualVerbalizer": {
    "__init__": [
      "self",
      "label_words",
      "tokenizer"
    ],
    "create_parameters": [
      "self"
    ],
    "aggregate_multiple_mask": [
      "self",
      "outputs",
      "atype"
    ],
    "process_outputs": [
      "self",
      "outputs",
      "masked_positions"
    ]
  },
  "MaskedLMIdentity": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "sequence_output",
      "masked_positions"
    ]
  },
  "SoftVerbalizer": {
    "__init__": [
      "self",
      "label_words",
      "tokenizer",
      "model"
    ],
    "create_parameters": [
      "self"
    ],
    "process_outputs": [
      "self",
      "outputs",
      "masked_positions"
    ],
    "head_parameters": [
      "self"
    ],
    "non_head_parameters": [
      "self"
    ],
    "_extract_head": [
      "self",
      "model"
    ],
    "_create_init_weight": [
      "self",
      "weight",
      "is_bias"
    ]
  },
  "MaskedLMVerbalizer": {
    "__init__": [
      "self",
      "label_words",
      "tokenizer"
    ],
    "create_parameters": [
      "self"
    ],
    "check_label_words_constraint": [
      "self",
      "label_words"
    ],
    "aggregate_multiple_mask": [
      "self",
      "outputs",
      "atype"
    ]
  },
  "PromptTuningArguments": {
    "__post_init__": [
      "self"
    ]
  },
  "PromptModelForSequenceClassification": {
    "__init__": [
      "self",
      "model",
      "template",
      "verbalizer",
      "freeze_plm",
      "freeze_dropout"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask",
      "masked_positions",
      "soft_token_ids",
      "encoder_ids",
      "labels",
      "return_dict"
    ],
    "prompt_parameters": [
      "self"
    ],
    "get_input_spec": [
      "self"
    ]
  },
  "TEMPLATE_CONFIG_FILE": [],
  "TEMPLATE_PARAMETER_FILE": [],
  "DEFAULT_MAX_OPTIONS": [],
  "Template": {
    "template_special_tokens": [],
    "template_attributes": [],
    "input_feature_names": [],
    "opt_token": [],
    "omask_token": [],
    "__init__": [
      "self",
      "prompt",
      "tokenizer",
      "max_length"
    ],
    "prompt": [
      "self",
      "prompt"
    ],
    "set_prompt": [
      "self",
      "prompt"
    ],
    "create_prompt_parameters": [
      "self"
    ],
    "_check_template_special_tokens": [
      "self"
    ],
    "_check_example_name": [
      "self",
      "name",
      "example"
    ],
    "_check_omask_token": [
      "self"
    ],
    "build_inputs_with_prompt": [
      "self",
      "example",
      "prompt"
    ],
    "create_token_type_sequence_from_prompt": [
      "self",
      "prompt"
    ],
    "create_position_sequence_from_prompt": [
      "self",
      "prompt"
    ],
    "create_truncation_sequence_from_prompt": [
      "self",
      "prompt"
    ],
    "create_example_keys_from_prompt": [
      "self"
    ],
    "encode": [
      "self",
      "example"
    ],
    "__call__": [
      "self",
      "example"
    ],
    "process_batch": [
      "self",
      "input_dict"
    ],
    "save": [
      "self",
      "save_path"
    ],
    "extract_template_keywords": [
      "prompt"
    ],
    "parse_template_string": [
      "prompt",
      "left_token",
      "right_token"
    ]
  },
  "ManualTemplate": {
    "template_special_tokens": [],
    "template_attributes": [],
    "__init__": [
      "self",
      "prompt",
      "tokenizer",
      "max_length"
    ],
    "create_prompt_parameters": [
      "self"
    ],
    "process_batch": [
      "self",
      "input_dict"
    ]
  },
  "SoftLSTM": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "output_size",
      "activation"
    ],
    "forward": [
      "self",
      "embeds"
    ]
  },
  "SoftTemplate": {
    "template_special_tokens": [],
    "input_feature_names": [],
    "__init__": [
      "self",
      "prompt",
      "tokenizer",
      "max_length",
      "word_embeddings",
      "soft_embeddings"
    ],
    "named_parameters": [
      "self"
    ],
    "parameters": [
      "self"
    ],
    "create_prompt_parameters": [
      "self"
    ],
    "process_batch": [
      "self",
      "input_dict"
    ],
    "parse_soft_prompt": [
      "self"
    ],
    "_init_soft_parameters": [
      "self",
      "soft2word"
    ],
    "_create_soft_encoders": [
      "self",
      "output_size",
      "activation"
    ],
    "build_inputs_with_prompt": [
      "self",
      "example",
      "prompt"
    ],
    "save": [
      "self",
      "save_path"
    ]
  },
  "PrefixTemplate": {
    "template_special_tokens": [],
    "input_feature_names": [],
    "__init__": [
      "self",
      "prompt",
      "tokenizer",
      "max_length",
      "model",
      "prefix_dropout"
    ],
    "_get_config": [
      "model"
    ],
    "parse_soft_prompt": [
      "self"
    ],
    "process_model": [
      "self",
      "model"
    ],
    "process_batch": [
      "self",
      "input_dict"
    ],
    "_create_soft_encoders": [
      "self"
    ]
  },
  "AutoTemplate": {
    "default_text_keyword": [],
    "__init__": [
      "self"
    ],
    "create_from": [
      "cls",
      "prompt",
      "tokenizer",
      "max_length",
      "model",
      "soft_embeddings",
      "prefix_dropout",
      "template_class"
    ],
    "load_from": [
      "cls",
      "data_path",
      "tokenizer",
      "max_length",
      "model"
    ]
  },
  "UTCTemplate": {
    "template_special_tokens": [],
    "__init__": [
      "self",
      "tokenizer",
      "max_length",
      "prompt"
    ],
    "_has_options": [
      "self"
    ],
    "build_inputs_with_prompt": [
      "self",
      "example",
      "prompt"
    ],
    "encode": [
      "self",
      "example",
      "use_mask"
    ],
    "create_prompt_parameters": [
      "self"
    ],
    "process_batch": [
      "self",
      "input_dict"
    ]
  },
  "signature": [
    "function"
  ],
  "PromptDataCollatorWithPadding": {
    "_convert_to_tensors": [
      "self",
      "data"
    ],
    "__call__": [
      "self",
      "features"
    ]
  },
  "sequence_classification_forward_with_past_key_values": [
    "self",
    "input_ids",
    "token_type_ids",
    "position_ids",
    "attention_mask",
    "inputs_embeds",
    "labels",
    "output_hidden_states",
    "output_attentions",
    "return_dict",
    "past_key_values"
  ],
  "masked_lm_forward_with_past_key_values": [
    "self",
    "input_ids",
    "token_type_ids",
    "position_ids",
    "attention_mask",
    "masked_positions",
    "inputs_embeds",
    "labels",
    "output_hidden_states",
    "output_attentions",
    "return_dict",
    "past_key_values"
  ],
  "PromptTrainer": {
    "__init__": [
      "self",
      "model",
      "tokenizer",
      "criterion",
      "args",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "compute_metrics",
      "callbacks",
      "optimizers"
    ],
    "_get_model": [
      "self"
    ],
    "template": [
      "self",
      "template"
    ],
    "verbalizer": [
      "self",
      "verbalizer"
    ],
    "pretrained_model": [
      "self",
      "model"
    ],
    "_map_dataset": [
      "self",
      "dataset"
    ],
    "_prepare_input": [
      "self",
      "inputs"
    ],
    "_save": [
      "self",
      "output_dir",
      "state_dict",
      "merge_tensor_parallel"
    ],
    "_load_from_checkpoint": [
      "self",
      "resume_from_checkpoint"
    ],
    "get_test_dataloader": [
      "self",
      "test_dataset"
    ],
    "get_eval_dataloader": [
      "self",
      "eval_dataset"
    ],
    "create_optimizer": [
      "self",
      "lr_scheduler"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs",
      "return_outputs"
    ],
    "_compute_rdrop_loss": [
      "self",
      "model",
      "input_dict",
      "labels",
      "outputs",
      "loss"
    ],
    "_compute_rgl_loss": [
      "self",
      "embeddings",
      "labels",
      "equal_type"
    ],
    "export_model": [
      "self",
      "export_path",
      "input_spec",
      "export_type"
    ]
  },
  "TensorHolder": [],
  "nested_reduce_tensor": [
    "tensor"
  ],
  "nested_empty_tensor": [
    "tensor"
  ],
  "nested_broadcast_tensor": [
    "tensor",
    "src",
    "group"
  ],
  "nested_copy": [
    "inputs"
  ],
  "nested_copy_place": [
    "inputs",
    "place",
    "blocking"
  ],
  "loggers": [],
  "log_config": [],
  "Logger": {
    "__init__": [
      "self",
      "name"
    ],
    "disable": [
      "self"
    ],
    "enable": [
      "self"
    ],
    "set_level": [
      "self",
      "log_level"
    ],
    "is_enable": [
      "self"
    ],
    "__call__": [
      "self",
      "log_level",
      "msg"
    ],
    "use_terminator": [
      "self",
      "terminator"
    ],
    "processing": [
      "self",
      "msg",
      "interval"
    ]
  },
  "_no_grad_uniform_": [
    "tensor",
    "a",
    "b"
  ],
  "_no_grad_normal_": [
    "tensor",
    "mean",
    "std"
  ],
  "_no_grad_fill_": [
    "tensor",
    "value"
  ],
  "ones_": [
    "tensor"
  ],
  "zeros_": [
    "tensor"
  ],
  "vector_": [
    "tensor",
    "vector"
  ],
  "_calculate_fan_in_and_fan_out": [
    "tensor",
    "reverse"
  ],
  "xavier_uniform_": [
    "tensor",
    "gain",
    "reverse"
  ],
  "xavier_normal_": [
    "tensor",
    "gain",
    "reverse"
  ],
  "_calculate_correct_fan": [
    "tensor",
    "mode",
    "reverse"
  ],
  "_calculate_gain": [
    "nonlinearity",
    "param"
  ],
  "kaiming_uniform_": [
    "tensor",
    "a",
    "mode",
    "nonlinearity",
    "reverse"
  ],
  "kaiming_normal_": [
    "tensor",
    "a",
    "mode",
    "nonlinearity",
    "reverse"
  ],
  "linear_init_": [
    "module"
  ],
  "conv_init_": [
    "module"
  ],
  "bias_init_with_prob": [
    "prior_prob"
  ],
  "reset_initialized_parameter": [
    "model",
    "include_self"
  ],
  "to": [
    "self",
    "device",
    "dtype",
    "blocking",
    "floating_only"
  ],
  "DocParser": {
    "__init__": [
      "self",
      "ocr_lang",
      "layout_analysis",
      "pdf_parser_config",
      "use_gpu",
      "device_id"
    ],
    "parse": [
      "self",
      "doc",
      "expand_to_a4_size",
      "do_ocr"
    ],
    "__call__": [
      "self"
    ],
    "ocr": [
      "self",
      "image",
      "det",
      "rec",
      "cls"
    ],
    "_get_buffer": [
      "self",
      "data",
      "file_like"
    ],
    "read_image": [
      "self",
      "image"
    ],
    "read_pdf": [
      "self",
      "pdf",
      "password"
    ],
    "get_page_image": [
      "self",
      "page",
      "matrix"
    ],
    "init_ocr_inference": [
      "self"
    ],
    "_normalize_box": [
      "self",
      "box",
      "old_size",
      "new_size",
      "offset_x",
      "offset_y"
    ],
    "expand_image_to_a4_size": [
      "self",
      "image",
      "center"
    ],
    "write_image_with_results": [
      "self",
      "image",
      "layout",
      "result",
      "save_path",
      "return_image",
      "format",
      "max_size"
    ]
  },
  "world_size": [],
  "reduce_tensor": [
    "tensor",
    "buffer_size"
  ],
  "distributed_gather": [
    "tensor",
    "dst",
    "group",
    "offload"
  ],
  "distributed_allgather": [
    "tensor",
    "group",
    "offload"
  ],
  "DistributedBatchSampler": {
    "__init__": [
      "self",
      "dataset",
      "batch_size",
      "num_replicas",
      "rank",
      "shuffle",
      "drop_last",
      "consumed_samples"
    ],
    "get_start_end_idx": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch",
      "consumed_samples"
    ]
  },
  "is_datasets_available": [],
  "is_paddle_cuda_available": [],
  "is_paddle_available": [],
  "is_psutil_available": [],
  "is_tiktoken_available": [],
  "is_torch_available": [],
  "is_package_available": [
    "package_name"
  ],
  "is_fast_tokenizer_available": [],
  "is_paddlenlp_ops_available": [],
  "is_transformers_available": [],
  "install_package": [
    "package_name",
    "version",
    "module_name",
    "cache_dir"
  ],
  "uninstall_package": [
    "package_name",
    "module_name"
  ],
  "import_module": [
    "module_name"
  ],
  "resize_func": [],
  "norm_func": [],
  "permute_func": [],
  "map_offset": [
    "ori_offset",
    "offset_mapping"
  ],
  "pad_image_data": [
    "image_data"
  ],
  "unify_prompt_name": [
    "prompt"
  ],
  "get_relation_type_dict": [
    "relation_data",
    "schema_lang"
  ],
  "uie_loss_func": [
    "outputs",
    "labels"
  ],
  "compute_metrics": [
    "p"
  ],
  "_get_user_home": [],
  "_get_ppnlp_home": [],
  "_get_sub_home": [
    "directory",
    "parent_home"
  ],
  "_get_bool_env": [
    "env_key",
    "default_value"
  ],
  "USER_HOME": [],
  "PPNLP_HOME": [],
  "MODEL_HOME": [],
  "HF_CACHE_HOME": [],
  "DATA_HOME": [],
  "PACKAGE_HOME": [],
  "DOWNLOAD_SERVER": [],
  "FAILED_STATUS": [],
  "SUCCESS_STATUS": [],
  "LEGACY_CONFIG_NAME": [],
  "CONFIG_NAME": [],
  "TOKENIZER_CONFIG_NAME": [],
  "CHAT_TEMPLATE_CONFIG_NAME": [],
  "GENERATION_CONFIG_NAME": [],
  "LORA_CONFIG_NAME": [],
  "LORA_WEIGHTS_NAME": [],
  "PREFIX_CONFIG_NAME": [],
  "PREFIX_WEIGHTS_NAME": [],
  "PADDLE_PEFT_WEIGHTS_INDEX_NAME": [],
  "PAST_KEY_VALUES_FILE_NAME": [],
  "PADDLE_WEIGHTS_NAME": [],
  "PADDLE_WEIGHTS_INDEX_NAME": [],
  "PYTORCH_WEIGHTS_NAME": [],
  "PYTORCH_WEIGHTS_INDEX_NAME": [],
  "SAFE_WEIGHTS_NAME": [],
  "SAFE_WEIGHTS_INDEX_NAME": [],
  "PADDLE_OPTIMIZER_NAME": [],
  "PADDLE_OPTIMIZER_INDEX_NAME": [],
  "SAFE_OPTIMIZER_NAME": [],
  "SAFE_OPTIMIZER_INDEX_NAME": [],
  "PADDLE_MASTER_WEIGHTS_NAME": [],
  "PADDLE_MASTER_WEIGHTS_INDEX_NAME": [],
  "SAFE_MASTER_WEIGHTS_NAME": [],
  "SAFE_MASTER_WEIGHTS_INDEX_NAME": [],
  "SAFE_PEFT_WEIGHTS_NAME": [],
  "SAFE_PEFT_WEIGHTS_INDEX_NAME": [],
  "COMMUNITY_MODEL_PREFIX": [],
  "WEIGHTS_HOME": [],
  "DOWNLOAD_RETRY_LIMIT": [],
  "DOWNLOAD_CHECK": [],
  "nlp_models": [],
  "is_url": [
    "path"
  ],
  "get_weights_path_from_url": [
    "url",
    "md5sum"
  ],
  "_map_path": [
    "url",
    "root_dir"
  ],
  "get_path_from_url": [
    "url",
    "root_dir",
    "md5sum",
    "check_exist"
  ],
  "get_path_from_url_with_filelock": [
    "url",
    "root_dir",
    "md5sum",
    "check_exist",
    "timeout"
  ],
  "_download": [
    "url",
    "path",
    "md5sum"
  ],
  "_md5check": [
    "fullname",
    "md5sum"
  ],
  "_md5": [
    "text"
  ],
  "_decompress": [
    "fname"
  ],
  "_uncompress_file_zip": [
    "filepath"
  ],
  "_uncompress_file_tar": [
    "filepath",
    "mode"
  ],
  "_is_a_single_file": [
    "file_list"
  ],
  "_is_a_single_dir": [
    "file_list"
  ],
  "DownloaderCheck": {
    "__init__": [
      "self",
      "task",
      "command",
      "addition"
    ],
    "uri_path": [
      "self",
      "server_url",
      "api"
    ],
    "_initialize": [
      "self"
    ],
    "request_check": [
      "self",
      "task",
      "command",
      "addition"
    ],
    "run": [
      "self"
    ]
  },
  "download_check": [
    "model_id",
    "model_class",
    "addition"
  ],
  "url_file_exists": [
    "url"
  ],
  "hf_file_exists": [
    "repo_id",
    "filename",
    "token",
    "subfolder"
  ],
  "MAX_HEADER_SIZE": [],
  "dtype_size": [],
  "numpy_dtype": [],
  "getSize": [
    "fileobject"
  ],
  "metadata_validate": [
    "metadata"
  ],
  "read_metadata": [
    "buffer"
  ],
  "readinto_numpy": [
    "meta",
    "buffer",
    "base_ptr"
  ],
  "PySafeSlice": {
    "__init__": [
      "self",
      "info",
      "bufferfile",
      "base_ptr",
      "buffermmap"
    ],
    "ndim": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "get": [
      "self"
    ],
    "start_offset": [
      "self"
    ],
    "get_shape": [
      "self"
    ],
    "shape": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "nelements": [
      "self"
    ],
    "bits": [
      "self"
    ],
    "nbytes": [
      "self"
    ]
  },
  "fast_safe_open": {
    "__init__": [
      "self",
      "filename",
      "framework",
      "device"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "metadata": [
      "self"
    ],
    "keys": [
      "self"
    ],
    "get_tensor": [
      "self",
      "name"
    ],
    "get_slice": [
      "self",
      "name"
    ]
  },
  "fast_load_file": [
    "filename"
  ],
  "static_params_to_dygraph": [
    "model",
    "static_tensor_dict"
  ],
  "dygraph_params_to_static": [
    "model",
    "dygraph_tensor_dict",
    "topo"
  ],
  "TimeCostAverage": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "record": [
      "self",
      "usetime"
    ],
    "get_average": [
      "self"
    ]
  },
  "get_env_device": [],
  "compare_version": [
    "version",
    "pair_version"
  ],
  "get_bool_ids_greater_than": [
    "probs",
    "limit",
    "return_prob"
  ],
  "get_span": [
    "start_ids",
    "end_ids",
    "with_prob"
  ],
  "DataConverter": {
    "__init__": [
      "self",
      "label_studio_file",
      "negative_ratio",
      "prompt_prefix",
      "options",
      "separator",
      "layout_analysis",
      "expand_to_a4_size",
      "schema_lang",
      "ocr_lang",
      "anno_type"
    ],
    "process_text_tag": [
      "self",
      "line",
      "task_type"
    ],
    "process_image_tag": [
      "self",
      "line",
      "task_type"
    ],
    "convert_cls_examples": [
      "self",
      "raw_examples"
    ],
    "convert_ext_examples": [
      "self",
      "raw_examples",
      "is_train"
    ],
    "generate_cls_example": [
      "self",
      "text",
      "labels",
      "prompt_prefix",
      "options",
      "image",
      "bbox"
    ],
    "add_full_negative_example": [
      "self",
      "examples",
      "texts",
      "relation_prompt_list",
      "predicate_set",
      "subject_golden_list",
      "images",
      "bbox_list"
    ],
    "add_entity_negative_example": [
      "self",
      "examples",
      "texts",
      "prompts",
      "label_set",
      "images",
      "bbox_list"
    ],
    "add_relation_negative_example": [
      "self",
      "redundants",
      "text",
      "num_positive",
      "ratio",
      "image",
      "bbox"
    ]
  },
  "MZ_ZIP_LOCAL_DIR_HEADER_SIZE": [],
  "_TYPES": [],
  "SerializationError": {},
  "seek_by_string": [
    "file_handler",
    "string",
    "file_size"
  ],
  "read_prefix_key": [
    "path"
  ],
  "_maybe_decode_ascii": [
    "bytes_str"
  ],
  "_storage_type_to_dtype_to_map": [],
  "StorageType": {
    "__init__": [
      "self",
      "name"
    ],
    "__str__": [
      "self"
    ]
  },
  "_element_size": [
    "dtype"
  ],
  "UnpicklerWrapperStage": {
    "find_class": [
      "self",
      "mod_name",
      "name"
    ]
  },
  "_rebuild_tensor_stage": [
    "storage",
    "storage_offset",
    "size",
    "stride",
    "requires_grad",
    "backward_hooks"
  ],
  "_rebuild_parameter": [
    "data",
    "requires_grad",
    "backward_hooks"
  ],
  "_rebuild_parameter_with_state": [
    "data",
    "requires_grad",
    "backward_hooks",
    "state"
  ],
  "dumpy": [],
  "load_torch": [
    "path"
  ],
  "BaseOperator": {
    "__init__": [
      "self",
      "name"
    ],
    "__call__": [
      "self",
      "sample",
      "context"
    ],
    "__str__": [
      "self"
    ]
  },
  "DecodeImage": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "sample",
      "context"
    ]
  },
  "ResizeImage": {
    "__init__": [
      "self",
      "target_size",
      "interp"
    ],
    "__call__": [
      "self",
      "sample",
      "context",
      "save_real_img"
    ]
  },
  "Permute": {
    "__init__": [
      "self",
      "to_bgr"
    ],
    "__call__": [
      "self",
      "sample",
      "context"
    ]
  },
  "NormalizeImage": {
    "__init__": [
      "self",
      "mean",
      "std",
      "is_channel_first",
      "is_scale"
    ],
    "__call__": [
      "self",
      "sample",
      "context"
    ]
  },
  "PadBatch": {
    "__init__": [
      "self",
      "pad_to_stride",
      "use_padded_im_info"
    ],
    "__call__": [
      "self",
      "samples",
      "context"
    ]
  },
  "check": [
    "s"
  ],
  "img2base64": [
    "img_path"
  ],
  "np2base64": [
    "image_np"
  ],
  "pil2base64": [
    "image",
    "image_type",
    "size"
  ],
  "Bbox": {
    "__slots__": [],
    "__init__": [
      "self",
      "left",
      "top",
      "width",
      "height"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "tuple": [
      "self",
      "precision"
    ],
    "list_int": [
      "self"
    ],
    "points_tuple": [
      "self",
      "precision"
    ],
    "left": [
      "self",
      "left"
    ],
    "right": [
      "self",
      "right"
    ],
    "top": [
      "self",
      "top"
    ],
    "bottom": [
      "self",
      "bottom"
    ],
    "width": [
      "self",
      "width"
    ],
    "height": [
      "self",
      "height"
    ],
    "is_cross_boundary": [
      "self",
      "width",
      "height",
      "top",
      "left"
    ],
    "is_vertical": [
      "self"
    ],
    "is_horizontal": [
      "self"
    ],
    "is_square": [
      "self"
    ],
    "center": [
      "self"
    ],
    "points": [
      "self"
    ],
    "contain": [
      "self",
      "box"
    ],
    "overlap_vertically": [
      "self",
      "box"
    ],
    "overlap_horizontally": [
      "self",
      "box"
    ],
    "overlap": [
      "self",
      "box"
    ],
    "hoverlap": [
      "self",
      "box"
    ],
    "voverlap": [
      "self",
      "box"
    ],
    "hdistance": [
      "self",
      "box"
    ],
    "vdistance": [
      "self",
      "box"
    ],
    "area": [
      "self"
    ],
    "translate": [
      "self",
      "vector"
    ],
    "union": [],
    "adjacency": [
      "boxa",
      "boxb"
    ],
    "intersection": [],
    "iou": [
      "boxa",
      "boxb"
    ],
    "from_points": [
      "p0",
      "p1"
    ]
  },
  "two_dimension_sort_box": [
    "box1",
    "box2",
    "vratio"
  ],
  "two_dimension_sort_layout": [
    "layout1",
    "layout2",
    "vratio"
  ],
  "ppocr2example": [
    "ocr_res",
    "img_path"
  ],
  "_profiler_step_id": [],
  "_profiler_options": [],
  "_prof": [],
  "ProfilerOptions": {
    "__init__": [
      "self",
      "options_str"
    ],
    "_parse_from_string": [
      "self",
      "options_str"
    ],
    "__getitem__": [
      "self",
      "name"
    ]
  },
  "add_profiler_step": [
    "options_str"
  ],
  "ENV_VARS_TRUE_VALUES": [],
  "_is_true": [
    "value"
  ],
  "_as_int": [
    "value"
  ],
  "DISABLE_SYMLINKS_WARNING": [],
  "HEADER_FILENAME_PATTERN": [],
  "DOWNLOAD_CHUNK_SIZE": [],
  "REPO_ID_SEPARATOR": [],
  "DEFAULT_DOWNLOAD_TIMEOUT": [],
  "DEFAULT_REQUEST_TIMEOUT": [],
  "DEFAULT_ETAG_TIMEOUT": [],
  "OFFLINE": [],
  "_cache_commit_hash_for_specific_revision": [
    "storage_folder",
    "revision",
    "commit_hash"
  ],
  "_check_disk_space": [
    "expected_size",
    "target_dir"
  ],
  "http_get": [
    "url",
    "temp_file"
  ],
  "_chmod_and_replace": [
    "src",
    "dst"
  ],
  "repo_folder_name": [],
  "OfflineModeIsEnabled": {},
  "OfflineAdapter": {
    "send": [
      "self",
      "request"
    ]
  },
  "BACKEND_FACTORY_T": [],
  "_default_backend_factory": [],
  "HTTP_METHOD_T": [],
  "_get_session_from_cache": [
    "process_id",
    "thread_id"
  ],
  "reset_sessions": [],
  "get_session": [],
  "_request_wrapper": [
    "method",
    "url"
  ],
  "_get_pointer_path": [
    "storage_folder",
    "revision",
    "relative_filename"
  ],
  "_create_symlink": [
    "src",
    "dst",
    "new_blob"
  ],
  "_set_write_permission_and_retry": [
    "func",
    "path",
    "excinfo"
  ],
  "SoftTemporaryDirectory": [
    "suffix",
    "prefix",
    "dir"
  ],
  "_to_local_dir": [
    "path",
    "local_dir",
    "relative_filename",
    "use_symlinks"
  ],
  "_normalize_etag": [
    "etag"
  ],
  "AistudioBosFileMetadata": {},
  "raise_for_status": [
    "response",
    "endpoint_name"
  ],
  "are_symlinks_supported": [
    "cache_dir"
  ],
  "ENDPOINT": [],
  "ENDPOINT_v2": [],
  "BOS_URL_TEMPLATE": [],
  "BOS_URL_TEMPLATE_WITHOUT_REVISION": [],
  "REGEX_COMMIT_HASH": [],
  "REPO_TYPE": [],
  "get_bos_file_metadata": [
    "url",
    "token",
    "proxies",
    "timeout",
    "library_name",
    "library_version",
    "user_agent"
  ],
  "bos_url": [
    "repo_id",
    "filename"
  ],
  "bos_download": [
    "repo_id",
    "filename",
    "subfolder",
    "repo_type",
    "revision",
    "library_name",
    "library_version",
    "cache_dir",
    "local_dir",
    "local_dir_use_symlinks",
    "user_agent",
    "force_download",
    "proxies",
    "etag_timeout",
    "resume_download",
    "token",
    "local_files_only",
    "endpoint",
    "url"
  ],
  "bos_file_exists": [
    "repo_id",
    "filename"
  ],
  "bos_try_to_load_from_cache": [
    "repo_id",
    "filename",
    "cache_dir",
    "revision",
    "repo_type"
  ],
  "VERSION": [],
  "AISTUDIO_URL_TEMPLATE": [],
  "default_home": [],
  "AISTUDIO_HOME": [],
  "default_cache_path": [],
  "AISTUDIO_HUB_CACHE": [],
  "DEFAULT_REVISION": [],
  "REPO_TYPE_MODEL": [],
  "REPO_TYPES": [],
  "AISTUDIO_TOKEN_PATH": [],
  "LocalTokenNotFoundError": {},
  "_clean_token": [
    "token"
  ],
  "_get_token_from_environment": [],
  "_get_token_from_file": [],
  "get_token": [],
  "get_token_to_send": [
    "token"
  ],
  "_validate_token_to_send": [
    "token",
    "is_write_action"
  ],
  "build_aistudio_headers": [],
  "get_aistudio_file_metadata": [
    "url",
    "token",
    "proxies",
    "timeout",
    "library_name",
    "library_version",
    "user_agent"
  ],
  "aistudio_hub_url": [
    "repo_id",
    "filename"
  ],
  "aistudio_hub_download": [
    "repo_id",
    "filename",
    "subfolder",
    "repo_type",
    "revision",
    "library_name",
    "library_version",
    "cache_dir",
    "local_dir",
    "local_dir_use_symlinks",
    "user_agent",
    "force_download",
    "proxies",
    "etag_timeout",
    "resume_download",
    "token",
    "local_files_only",
    "endpoint"
  ],
  "aistudio_hub_file_exists": [
    "repo_id",
    "filename"
  ],
  "aistudio_hub_try_to_load_from_cache": [
    "repo_id",
    "filename",
    "cache_dir",
    "revision",
    "repo_type"
  ],
  "resolve_file_path": [
    "repo_id",
    "filenames",
    "subfolder",
    "repo_type",
    "revision",
    "library_name",
    "library_version",
    "cache_dir",
    "local_dir",
    "local_dir_use_symlinks",
    "user_agent",
    "force_download",
    "proxies",
    "etag_timeout",
    "resume_download",
    "token",
    "local_files_only",
    "endpoint",
    "url",
    "from_aistudio",
    "from_hf_hub",
    "from_bos"
  ],
  "bos_aistudio_hf_file_exist": [
    "repo_id",
    "filename"
  ],
  "bos_aistudio_hf_try_to_load_from_cache": [
    "repo_id",
    "filename",
    "cache_dir",
    "subfolder",
    "revision",
    "repo_type",
    "from_bos",
    "from_aistudio",
    "from_hf_hub"
  ],
  "GlobalPointer": {
    "__init__": [
      "self",
      "hidden_size",
      "heads",
      "head_size",
      "RoPE",
      "tril_mask",
      "max_length"
    ],
    "forward": [
      "self",
      "inputs",
      "attention_mask"
    ]
  },
  "GlobalPointerForEntityExtraction": {
    "__init__": [
      "self",
      "encoder",
      "label_maps",
      "head_size"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "GPLinkerForRelationExtraction": {
    "__init__": [
      "self",
      "encoder",
      "label_maps",
      "head_size"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "GPLinkerForEventExtraction": {
    "__init__": [
      "self",
      "encoder",
      "label_maps",
      "head_size"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "sequence_mask": [
    "seq_ids",
    "valid_lengths"
  ],
  "log_sum_exp": [
    "vec",
    "dim"
  ],
  "LinearChainCrf": {
    "__init__": [
      "self",
      "num_labels",
      "crf_lr",
      "with_start_stop_tag"
    ],
    "_initialize_alpha": [
      "self",
      "batch_size"
    ],
    "forward": [
      "self",
      "inputs",
      "lengths"
    ],
    "gold_score": [
      "self",
      "inputs",
      "labels",
      "lengths"
    ],
    "_point_score": [
      "self",
      "inputs",
      "labels",
      "lengths"
    ],
    "_trans_score": [
      "self",
      "labels",
      "lengths"
    ],
    "_get_start_stop_tensor": [
      "self",
      "batch_size"
    ],
    "_get_batch_index": [
      "self",
      "batch_size"
    ],
    "_get_seq_index": [
      "self",
      "length"
    ],
    "_get_batch_seq_index": [
      "self",
      "batch_size",
      "length"
    ]
  },
  "LinearChainCrfLoss": {
    "__init__": [
      "self",
      "crf"
    ],
    "forward": [
      "self",
      "inputs",
      "lengths",
      "labels",
      "old_version_labels"
    ]
  },
  "ViterbiDecoder": {
    "__init__": [
      "self",
      "transitions",
      "with_start_stop_tag"
    ],
    "_initialize_alpha": [
      "self",
      "batch_size"
    ],
    "forward": [
      "self",
      "inputs",
      "lengths"
    ],
    "_get_batch_index": [
      "self",
      "batch_size"
    ]
  },
  "Chomp1d": {
    "__init__": [
      "self",
      "chomp_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TemporalBlock": {
    "__init__": [
      "self",
      "n_inputs",
      "n_outputs",
      "kernel_size",
      "stride",
      "dilation",
      "padding",
      "dropout"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TCN": {
    "__init__": [
      "self",
      "input_channel",
      "num_channels",
      "kernel_size",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ModelManager": {
    "__init__": [
      "self",
      "task_name",
      "model_path",
      "tokenizer_name",
      "model_handler",
      "post_handler",
      "precision",
      "device_id"
    ],
    "_register": [
      "self"
    ],
    "_get_tokenizer": [
      "self"
    ],
    "_get_predict_id": [
      "self"
    ],
    "predict": [
      "self",
      "data",
      "parameters"
    ]
  },
  "lock_predictor": [
    "lock"
  ],
  "TaskflowManager": {
    "__init__": [
      "self",
      "task",
      "taskflow_handler"
    ],
    "predict": [
      "self",
      "data",
      "parameters"
    ]
  },
  "SimpleServer": {
    "__init__": [
      "self"
    ],
    "register": [
      "self",
      "task_name",
      "model_path",
      "tokenizer_name",
      "model_handler",
      "post_handler",
      "precision",
      "device_id"
    ],
    "register_taskflow": [
      "self",
      "task_name",
      "task",
      "taskflow_handler"
    ]
  },
  "Predictor": {
    "__init__": [
      "self",
      "model_path",
      "precision",
      "device"
    ],
    "_get_default_static_model_path": [
      "self"
    ],
    "_is_int8_model": [
      "self",
      "model_path"
    ],
    "_create_predictor": [
      "self"
    ],
    "_check_predictor_type": [
      "self"
    ],
    "_prepare_paddle_mode": [
      "self",
      "static_model_path"
    ],
    "_prepare_onnx_mode": [
      "self",
      "static_model_path"
    ],
    "_convert_dygraph_to_static": [
      "self",
      "model_instance",
      "input_spec"
    ]
  },
  "BaseRouterManager": {
    "_app": [],
    "__init__": [
      "self",
      "app"
    ],
    "register_models_router": [
      "self"
    ],
    "register_taskflow_router": [
      "self"
    ]
  },
  "TokenClsModelHandler": {
    "__init__": [
      "self"
    ],
    "process": [
      "cls",
      "predictor",
      "tokenizer",
      "data",
      "parameters"
    ]
  },
  "BaseModelHandler": {
    "__init__": [
      "self"
    ],
    "process": [
      "cls",
      "predictor",
      "tokenizer",
      "data",
      "parameters"
    ]
  },
  "BasePostHandler": {
    "__init__": [
      "self"
    ],
    "process": [
      "cls",
      "data",
      "parameters"
    ]
  },
  "BaseTaskflowHandler": {
    "__init__": [
      "self"
    ],
    "process": [
      "cls",
      "data",
      "parameters"
    ]
  },
  "QAModelHandler": {
    "__init__": [
      "self"
    ],
    "process": [
      "cls",
      "predictor",
      "tokenizer",
      "data",
      "parameters"
    ]
  },
  "TaskflowHandler": {
    "__init__": [
      "self"
    ],
    "process": [
      "cls",
      "predictor",
      "data",
      "parameters"
    ]
  },
  "MultiClassificationPostHandler": {
    "__init__": [
      "self"
    ],
    "process": [
      "cls",
      "data",
      "parameters"
    ]
  },
  "MultiLabelClassificationPostHandler": {
    "__init__": [
      "self"
    ],
    "process": [
      "cls",
      "data",
      "parameters"
    ]
  },
  "CustomModelHandler": {
    "__init__": [
      "self"
    ],
    "process": [
      "cls",
      "predictor",
      "tokenizer",
      "data",
      "parameters"
    ]
  },
  "ERNIEMHandler": {
    "__init__": [
      "self"
    ],
    "process": [
      "cls",
      "predictor",
      "tokenizer",
      "data",
      "parameters"
    ]
  },
  "ResponseBase": {},
  "RequestBase": {},
  "HttpRouterManager": {
    "register_models_router": [
      "self",
      "task_name"
    ],
    "register_taskflow_router": [
      "self",
      "task_name"
    ]
  },
  "Stack": {
    "__init__": [
      "self",
      "axis",
      "dtype"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "Pad": {
    "__init__": [
      "self",
      "pad_val",
      "axis",
      "ret_length",
      "dtype",
      "pad_right"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "Tuple": {
    "__init__": [
      "self",
      "fn"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "Dict": {
    "__init__": [
      "self",
      "fn"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "DummyDataset": {
    "__len__": [
      "self"
    ]
  },
  "DistDataLoader": {
    "__init__": [
      "self",
      "dataset",
      "feed_list",
      "places",
      "return_list",
      "batch_sampler",
      "batch_size",
      "shuffle",
      "drop_last",
      "collate_fn",
      "num_workers",
      "use_buffer_reader",
      "prefetch_factor",
      "use_shared_memory",
      "timeout",
      "worker_init_fn",
      "persistent_workers",
      "eval"
    ],
    "_dataloader_iter": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "_init_dataloader_comm_group": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "_broadcast_data": [
      "self",
      "data"
    ],
    "__next__": [
      "self"
    ]
  },
  "get_idx_from_word": [
    "word",
    "word_to_idx",
    "unk_word"
  ],
  "BaseTokenizer": {
    "__init__": [
      "self",
      "vocab"
    ],
    "get_tokenizer": [
      "self"
    ],
    "cut": [
      "self",
      "sentence"
    ],
    "encode": [
      "self",
      "sentence"
    ]
  },
  "JiebaTokenizer": {
    "__init__": [
      "self",
      "vocab"
    ],
    "cut": [
      "self",
      "sentence",
      "cut_all",
      "use_hmm"
    ],
    "encode": [
      "self",
      "sentence",
      "cut_all",
      "use_hmm"
    ]
  },
  "Vocab": {
    "__init__": [
      "self",
      "counter",
      "max_size",
      "min_freq",
      "token_to_idx",
      "unk_token",
      "pad_token",
      "bos_token",
      "eos_token"
    ],
    "_index_counter_keys": [
      "self",
      "counter",
      "special_tokens",
      "max_size",
      "min_freq"
    ],
    "_sort_index_according_to_user_specification": [
      "self",
      "token_to_idx"
    ],
    "to_tokens": [
      "self",
      "indices"
    ],
    "to_indices": [
      "self",
      "tokens"
    ],
    "__getitem__": [
      "self",
      "tokens"
    ],
    "__len__": [
      "self"
    ],
    "__contains__": [
      "self",
      "token"
    ],
    "__call__": [
      "self",
      "tokens"
    ],
    "idx_to_token": [
      "self"
    ],
    "token_to_idx": [
      "self"
    ],
    "to_json": [
      "self",
      "path"
    ],
    "from_json": [
      "cls",
      "json_str"
    ],
    "from_dict": [
      "cls",
      "token_to_idx",
      "unk_token",
      "pad_token",
      "bos_token",
      "eos_token"
    ],
    "build_vocab": [
      "iterator",
      "max_size",
      "min_freq",
      "token_to_idx",
      "unk_token",
      "pad_token",
      "bos_token",
      "eos_token"
    ],
    "load_vocabulary": [
      "filepath",
      "unk_token",
      "pad_token",
      "bos_token",
      "eos_token"
    ],
    "save_vocabulary": [
      "self",
      "filepath"
    ],
    "get_unk_token_id": [
      "self"
    ],
    "get_bos_token_id": [
      "self"
    ],
    "get_eos_token_id": [
      "self"
    ],
    "get_pad_token_id": [
      "self"
    ]
  },
  "local_rank": [],
  "check_data_split": [
    "splits_string",
    "do_train",
    "do_eval",
    "do_predict"
  ],
  "get_train_valid_test_split_": [
    "splits_string",
    "size"
  ],
  "get_datasets_weights_and_num_samples": [
    "data_prefix",
    "train_val_test_num_samples"
  ],
  "print_rank_0": [],
  "build_train_valid_test_datasets": [
    "data_prefix",
    "data_impl",
    "splits_string",
    "train_val_test_num_samples",
    "seq_length",
    "seed",
    "skip_warmup",
    "train_data_prefix",
    "valid_data_prefix",
    "test_data_prefix",
    "return_doc_ids",
    "share_folder"
  ],
  "_build_train_valid_test_datasets": [
    "data_prefix",
    "data_impl",
    "splits_string",
    "train_val_test_num_samples",
    "seq_length",
    "seed",
    "skip_warmup",
    "return_doc_ids",
    "share_folder"
  ],
  "get_indexed_dataset_": [
    "data_prefix",
    "data_impl",
    "skip_warmup"
  ],
  "GPTDataset": {
    "__init__": [
      "self",
      "name",
      "data_prefix",
      "documents",
      "indexed_dataset",
      "splits_string",
      "num_samples",
      "seq_length",
      "seed",
      "return_doc_ids",
      "share_folder"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "_build_index_mappings": [
    "name",
    "data_prefix",
    "documents",
    "sizes",
    "splits_string",
    "num_samples",
    "seq_length",
    "seed",
    "share_folder"
  ],
  "_num_tokens": [
    "documents",
    "sizes"
  ],
  "_num_epochs": [
    "tokens_per_epoch",
    "seq_length",
    "num_samples"
  ],
  "_build_doc_idx": [
    "documents",
    "num_epochs",
    "np_rng",
    "separate_last_epoch"
  ],
  "_build_sample_idx": [
    "sizes",
    "doc_idx",
    "seq_length",
    "num_epochs",
    "tokens_per_epoch"
  ],
  "_build_shuffle_idx": [
    "num_samples",
    "total_size",
    "np_rng"
  ],
  "InputDataClass": [],
  "DataCollator": [],
  "DataCollatorMixin": {
    "__call__": [
      "self",
      "features",
      "return_tensors"
    ]
  },
  "default_data_collator": [
    "features",
    "return_tensors"
  ],
  "paddle_default_data_collator": [
    "features"
  ],
  "numpy_default_data_collator": [
    "features"
  ],
  "DefaultDataCollator": {
    "__call__": [
      "self",
      "features",
      "return_tensors"
    ]
  },
  "DataCollatorWithPadding": {
    "__call__": [
      "self",
      "features"
    ]
  },
  "DataCollatorForTokenClassification": {
    "paddle_call": [
      "self",
      "features"
    ],
    "numpy_call": [
      "self",
      "features"
    ]
  },
  "DataCollatorForSeq2Seq": {
    "__call__": [
      "self",
      "features",
      "return_tensors"
    ]
  },
  "_paddle_collate_batch": [
    "examples",
    "tokenizer",
    "pad_to_multiple_of"
  ],
  "_numpy_collate_batch": [
    "examples",
    "tokenizer",
    "pad_to_multiple_of"
  ],
  "tolist": [
    "x"
  ],
  "DataCollatorForLanguageModeling": {
    "paddle_call": [
      "self",
      "examples"
    ],
    "paddle_mask_tokens": [
      "self",
      "inputs",
      "special_tokens_mask"
    ],
    "numpy_call": [
      "self",
      "examples"
    ],
    "numpy_mask_tokens": [
      "self",
      "inputs",
      "special_tokens_mask"
    ]
  },
  "DataCollatorForWholeWordMask": {
    "paddle_call": [
      "self",
      "examples"
    ],
    "numpy_call": [
      "self",
      "examples"
    ],
    "_whole_word_mask": [
      "self",
      "input_tokens",
      "max_predictions"
    ],
    "paddle_mask_tokens": [
      "self",
      "inputs",
      "mask_labels"
    ],
    "numpy_mask_tokens": [
      "self",
      "inputs",
      "mask_labels"
    ]
  },
  "SamplerHelper": {
    "__init__": [
      "self",
      "dataset",
      "iterable"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "length": [
      "self",
      "length"
    ],
    "apply": [
      "self",
      "fn"
    ],
    "shuffle": [
      "self",
      "buffer_size",
      "seed"
    ],
    "sort": [
      "self",
      "cmp",
      "key",
      "reverse",
      "buffer_size"
    ],
    "batch": [
      "self",
      "batch_size",
      "drop_last",
      "batch_size_fn",
      "key"
    ],
    "shard": [
      "self",
      "num_replicas",
      "rank"
    ],
    "list": [
      "self"
    ]
  },
  "__best_fitting_dtype": [
    "vocab_size"
  ],
  "get_available_dataset_impl": [],
  "make_dataset": [
    "path",
    "impl",
    "skip_warmup"
  ],
  "dataset_exists": [
    "path",
    "impl"
  ],
  "read_longs": [
    "f",
    "n"
  ],
  "write_longs": [
    "f",
    "a"
  ],
  "read_shorts": [
    "f",
    "n"
  ],
  "write_shorts": [
    "f",
    "a"
  ],
  "dtypes": [],
  "code": [
    "dtype"
  ],
  "index_file_path": [
    "prefix_path"
  ],
  "data_file_path": [
    "prefix_path"
  ],
  "loss_mask_file_path": [
    "prefix_path"
  ],
  "create_doc_idx": [
    "sizes"
  ],
  "IndexedDataset": {
    "_HDR_MAGIC": [],
    "__init__": [
      "self",
      "path"
    ],
    "read_index": [
      "self",
      "path"
    ],
    "read_data": [
      "self",
      "path"
    ],
    "check_index": [
      "self",
      "i"
    ],
    "__del__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "get": [
      "self",
      "idx",
      "offset",
      "length"
    ],
    "__len__": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "exists": [
      "path"
    ],
    "supports_prefetch": [
      "self"
    ],
    "doc_idx": [
      "self"
    ],
    "get_doc_idx": [
      "self"
    ],
    "set_doc_idx": [
      "self",
      "doc_idx_"
    ]
  },
  "IndexedDatasetBuilder": {
    "element_sizes": [],
    "__init__": [
      "self",
      "out_file",
      "dtype"
    ],
    "add_item": [
      "self",
      "tensor"
    ],
    "end_document": [
      "self"
    ],
    "merge_file_": [
      "self",
      "another_file"
    ],
    "finalize": [
      "self",
      "index_file"
    ]
  },
  "_warmup_mmap_file": [
    "path"
  ],
  "MMapIndexedDataset": {
    "__init__": [
      "self",
      "path",
      "skip_warmup"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "_do_init": [
      "self",
      "path",
      "skip_warmup"
    ],
    "__del__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "get": [
      "self",
      "idx",
      "offset",
      "length"
    ],
    "sizes": [
      "self"
    ],
    "doc_idx": [
      "self"
    ],
    "get_doc_idx": [
      "self"
    ],
    "set_doc_idx": [
      "self",
      "doc_idx_"
    ],
    "supports_prefetch": [
      "self"
    ],
    "exists": [
      "path"
    ]
  },
  "make_builder": [
    "out_file",
    "impl",
    "save_dtype",
    "loss_mask_file"
  ],
  "MMapIndexedDatasetBuilder": {
    "__init__": [
      "self",
      "out_file",
      "dtype",
      "loss_mask_file"
    ],
    "flush_loss_mask_item": [
      "self",
      "loss_mask_lst"
    ],
    "add_item": [
      "self",
      "tensor"
    ],
    "add_doc": [
      "self",
      "tensor",
      "sizes"
    ],
    "end_document": [
      "self"
    ],
    "merge_file_": [
      "self",
      "another_file"
    ],
    "finalize": [
      "self",
      "index_file"
    ]
  },
  "CompatibleIndexedDataset": {
    "__init__": [
      "self",
      "path"
    ],
    "__getstate__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "get": [
      "self",
      "idx",
      "offset",
      "length"
    ],
    "sizes": [
      "self"
    ],
    "doc_idx": [
      "self"
    ],
    "get_doc_idx": [
      "self"
    ],
    "set_doc_idx": [
      "self",
      "doc_idx_"
    ],
    "exists": [
      "path"
    ]
  },
  "BlendableDataset": {
    "__init__": [
      "self",
      "datasets",
      "weights",
      "size",
      "share_folder"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "BoWEncoder": {
    "__init__": [
      "self",
      "emb_dim"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "mask"
    ]
  },
  "CNNEncoder": {
    "__init__": [
      "self",
      "emb_dim",
      "num_filter",
      "ngram_filter_sizes",
      "conv_layer_activation",
      "output_dim"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "mask"
    ]
  },
  "GRUEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "direction",
      "dropout",
      "pooling_type"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "sequence_length"
    ]
  },
  "LSTMEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "direction",
      "dropout",
      "pooling_type"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "sequence_length"
    ]
  },
  "RNNEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "direction",
      "dropout",
      "pooling_type"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "sequence_length"
    ]
  },
  "TCNEncoder": {
    "__init__": [
      "self",
      "input_size",
      "num_channels",
      "kernel_size",
      "dropout"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "ChatGLMTask": {
    "__init__": [
      "self",
      "task",
      "model"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_batchify": [
      "self",
      "data",
      "batch_size"
    ],
    "_preprocess": [
      "self",
      "inputs",
      "padding",
      "add_special_tokens"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "set_argument": [
      "self",
      "argument"
    ],
    "_convert_dygraph_to_static": [
      "self"
    ]
  },
  "usage": [],
  "DialogueTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "task",
      "model",
      "batch_size",
      "max_seq_len"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_batchify_fn": [
      "self",
      "batch_examples"
    ],
    "_check_input_text": [
      "self",
      "inputs"
    ],
    "_batchify": [
      "self",
      "data",
      "max_seq_len",
      "batch_size"
    ],
    "_convert_text_to_input": [
      "self",
      "texts",
      "max_seq_len"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_post_process_response": [
      "self",
      "token_ids",
      "tokenizer"
    ],
    "interactive_mode": [
      "self",
      "max_turn"
    ],
    "_get_in_turn_repetition": [
      "self",
      "pred",
      "is_cn"
    ],
    "_select_response": [
      "self",
      "ids",
      "scores",
      "tokenizer",
      "max_dec_len",
      "num_return_sequences",
      "keep_space"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "Task": {
    "__init__": [
      "self",
      "model",
      "task",
      "priority_path"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_preprocess": [
      "self",
      "inputs",
      "padding",
      "add_special_tokens"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_get_static_model_name": [
      "self"
    ],
    "_check_task_files": [
      "self"
    ],
    "_check_predictor_type": [
      "self"
    ],
    "_construct_ocr_engine": [
      "self",
      "lang",
      "use_angle_cls"
    ],
    "_construce_layout_analysis_engine": [
      "self"
    ],
    "_prepare_static_mode": [
      "self"
    ],
    "_prepare_onnx_mode": [
      "self"
    ],
    "_get_inference_model": [
      "self"
    ],
    "_convert_dygraph_to_static": [
      "self"
    ],
    "_check_input_text": [
      "self",
      "inputs"
    ],
    "_auto_splitter": [
      "self",
      "input_texts",
      "max_text_len",
      "bbox_list",
      "split_sentence"
    ],
    "_auto_joiner": [
      "self",
      "short_results",
      "input_mapping",
      "is_dict"
    ],
    "paddle_quantize_model": [
      "self",
      "model_path"
    ],
    "help": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "FillMaskTask": {
    "__init__": [
      "self",
      "task",
      "model",
      "top_k"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "get_masked_index": [
      "self",
      "input_ids"
    ],
    "ensure_exactly_one_mask_token": [
      "self",
      "input_ids"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "MODEL_MAP": [],
  "get_dynamic_max_length": [
    "examples",
    "default_max_length",
    "dynamic_max_length"
  ],
  "UIETask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "task",
      "model",
      "schema"
    ],
    "set_argument": [
      "self",
      "argument"
    ],
    "set_schema": [
      "self",
      "schema"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_check_input_text": [
      "self",
      "inputs"
    ],
    "_single_stage_predict": [
      "self",
      "inputs"
    ],
    "_auto_joiner": [
      "self",
      "short_results",
      "short_inputs",
      "input_mapping"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_parse_inputs": [
      "self",
      "inputs"
    ],
    "_multi_stage_predict": [
      "self",
      "data"
    ],
    "_add_bbox_info": [
      "self",
      "results",
      "data"
    ],
    "_convert_ids_to_results": [
      "self",
      "examples",
      "sentence_ids",
      "probs"
    ],
    "_build_tree": [
      "cls",
      "schema",
      "name"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "GPTask": {
    "resource_files_names": [],
    "__init__": [
      "self",
      "task",
      "model"
    ],
    "_load_config": [
      "self"
    ],
    "_set_schema": [
      "self",
      "schema"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_build_tree": [
      "cls",
      "schema",
      "name"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "_postprocess_opinion_extraction": [
      "self",
      "inputs"
    ],
    "_postprocess_relation_extraction": [
      "self",
      "inputs"
    ],
    "_postprocess_entity_extraction": [
      "self",
      "inputs"
    ]
  },
  "ZeroShotTextClassificationTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "task",
      "model",
      "schema"
    ],
    "_set_utc_schema": [
      "self",
      "schema"
    ],
    "set_schema": [
      "self",
      "schema"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self"
    ],
    "_check_input_text": [
      "self",
      "inputs"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "DDParserTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "task",
      "model",
      "tree",
      "prob",
      "use_pos",
      "use_cuda",
      "batch_size",
      "return_visual"
    ],
    "_check_segmented_words": [
      "self",
      "inputs"
    ],
    "from_segments": [
      "self",
      "segmented_words"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_vocabs": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_preprocess_words": [
      "self",
      "inputs"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "_visualize": [
      "self",
      "data"
    ]
  },
  "pad_sequence": [
    "sequences",
    "padding_value",
    "fix_len"
  ],
  "convert_example": [
    "example",
    "vocabs",
    "fix_len"
  ],
  "flat_words": [
    "words",
    "pad_index"
  ],
  "probability": [
    "s_arc",
    "arc_preds"
  ],
  "decode": [
    "arc_preds",
    "rel_preds",
    "s_arc",
    "mask",
    "tree"
  ],
  "eisner": [
    "scores",
    "mask"
  ],
  "fill_diagonal": [
    "x",
    "value",
    "offset",
    "dim1",
    "dim2"
  ],
  "backtrack": [
    "p_i",
    "p_c",
    "heads",
    "i",
    "j",
    "complete"
  ],
  "stripe": [
    "x",
    "n",
    "w",
    "offset",
    "dim"
  ],
  "Node": {
    "__init__": [
      "self",
      "id",
      "parent"
    ]
  },
  "DepTree": {
    "__init__": [
      "self",
      "sentence"
    ],
    "build_tree": [
      "self"
    ],
    "add": [
      "self",
      "parent",
      "child"
    ],
    "judge_legal": [
      "self"
    ],
    "inorder_traversal": [
      "self",
      "node"
    ]
  },
  "istree": [
    "sequence"
  ],
  "DOC_FORMAT": [],
  "download_file": [
    "save_dir",
    "filename",
    "url",
    "md5"
  ],
  "add_docstrings": [],
  "static_mode_guard": [],
  "dygraph_mode_guard": [],
  "cut_chinese_sent": [
    "para"
  ],
  "TermTreeNode": {
    "__init__": [
      "self",
      "sid",
      "term",
      "base",
      "node_type",
      "term_type",
      "hyper",
      "level",
      "alias",
      "alias_ext",
      "sub_type",
      "sub_term",
      "data"
    ],
    "__str__": [
      "self"
    ],
    "sid": [
      "self"
    ],
    "term": [
      "self"
    ],
    "base": [
      "self"
    ],
    "alias": [
      "self"
    ],
    "alias_ext": [
      "self"
    ],
    "termtype": [
      "self"
    ],
    "subtype": [
      "self"
    ],
    "subterm": [
      "self"
    ],
    "hyper": [
      "self"
    ],
    "level": [
      "self"
    ],
    "sons": [
      "self"
    ],
    "node_type": [
      "self"
    ],
    "add_son": [
      "self",
      "son_name"
    ],
    "from_dict": [
      "cls",
      "data"
    ],
    "from_json": [
      "cls",
      "json_str"
    ]
  },
  "TermTree": {
    "__init__": [
      "self"
    ],
    "__build_sons": [
      "self"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "__contains__": [
      "self",
      "item"
    ],
    "__iter__": [
      "self"
    ],
    "root": [
      "self"
    ],
    "__load_type": [
      "self",
      "file_path"
    ],
    "__judge_term_node": [
      "self",
      "node"
    ],
    "add_term": [
      "self",
      "term",
      "base",
      "term_type",
      "sub_type",
      "sub_term",
      "alias",
      "alias_ext",
      "data"
    ],
    "add_type": [
      "self",
      "type_name",
      "hyper_type"
    ],
    "__load_file": [
      "self",
      "file_path"
    ],
    "__build_son": [
      "self",
      "node"
    ],
    "build_son": [
      "self",
      "node"
    ],
    "__build_index": [
      "self",
      "node"
    ],
    "__judge_hyper": [
      "self",
      "source_id",
      "target_id"
    ],
    "find_term": [
      "self",
      "term",
      "term_type"
    ],
    "build_from_dir": [
      "self",
      "term_schema_path",
      "term_data_path",
      "linking"
    ],
    "from_dir": [
      "cls",
      "term_schema_path",
      "term_data_path",
      "linking"
    ],
    "__dfs": [
      "self",
      "cur_id",
      "depth",
      "path",
      "writer"
    ],
    "save": [
      "self",
      "save_dir"
    ]
  },
  "levenstein_distance": [
    "s1",
    "s2"
  ],
  "BurkhardKellerNode": {
    "__init__": [
      "self",
      "word"
    ]
  },
  "BurkhardKellerTree": {
    "__init__": [
      "self"
    ],
    "__add": [
      "self",
      "cur_node",
      "word"
    ],
    "add": [
      "self",
      "word"
    ],
    "__search_similar_word": [
      "self",
      "cur_node",
      "s",
      "threshold"
    ],
    "search_similar_word": [
      "self",
      "word"
    ]
  },
  "TriedTree": {
    "__init__": [
      "self"
    ],
    "add_word": [
      "self",
      "word"
    ],
    "search": [
      "self",
      "content"
    ]
  },
  "Customization": {
    "__init__": [
      "self"
    ],
    "load_customization": [
      "self",
      "filename",
      "sep"
    ],
    "parse_customization": [
      "self",
      "query",
      "lac_tags",
      "prefix"
    ]
  },
  "SchemaTree": {
    "__init__": [
      "self",
      "name",
      "children"
    ],
    "__repr__": [
      "self"
    ],
    "add_child": [
      "self",
      "node"
    ]
  },
  "get_id_and_prob": [
    "span_set",
    "offset_mapping"
  ],
  "dbc2sbc": [
    "s"
  ],
  "WordTagRelationExtractor": {
    "_chain_items": [],
    "_all_items": [],
    "_jux_buf": [],
    "__init__": [
      "self",
      "schema"
    ],
    "schema": [
      "self"
    ],
    "from_dict": [
      "cls",
      "config_dict"
    ],
    "from_json": [
      "cls",
      "json_str"
    ],
    "from_pkl": [
      "cls",
      "pkl_path"
    ],
    "from_config": [
      "cls",
      "config_path"
    ],
    "add_schema_from_dict": [
      "self",
      "config_dict"
    ],
    "_judge_jux": [
      "self",
      "wordtag_item"
    ],
    "_search_jux": [
      "self",
      "cur_item",
      "cur_pos",
      "jux_type",
      "jux_word",
      "status_flag",
      "search_list"
    ],
    "_match_item": [
      "item",
      "type_can"
    ],
    "_trig_handler": [
      "self",
      "cur_item",
      "head_conf"
    ],
    "_find_tail": [
      "self",
      "search_range",
      "sg_conf",
      "head_hype"
    ],
    "_find_supp": [
      "self",
      "search_range",
      "search_type"
    ],
    "_make_output": [
      "self",
      "head_item",
      "tail_item",
      "group",
      "source",
      "support",
      "trig_word"
    ],
    "_reverse": [
      "self",
      "res",
      "group_name"
    ],
    "extract_spo": [
      "self",
      "all_items"
    ]
  },
  "DataCollatorGP": {
    "__call__": [
      "self",
      "features"
    ]
  },
  "DataCollatorForErnieCtm": {
    "__call__": [
      "self",
      "features"
    ]
  },
  "gp_decode": [
    "batch_outputs",
    "offset_mappings",
    "texts",
    "label_maps",
    "task_type"
  ],
  "DocSpan": [],
  "Example": [],
  "Feature": [],
  "Compose": {
    "__init__": [
      "self",
      "transforms",
      "ctx"
    ],
    "__call__": [
      "self",
      "data"
    ]
  },
  "batch_arrange": [
    "batch_samples",
    "fields"
  ],
  "ProcessReader": {
    "__init__": [
      "self",
      "dataset",
      "sample_transforms",
      "batch_transforms",
      "batch_size",
      "shuffle",
      "drop_last",
      "drop_empty",
      "mixup_epoch",
      "cutmix_epoch",
      "class_aware_sampling",
      "use_process",
      "use_fine_grained_loss",
      "num_classes",
      "bufsize",
      "memsize",
      "inputs_def",
      "devices_num",
      "num_trainers"
    ],
    "process": [
      "self",
      "dataset"
    ],
    "_load_batch": [
      "self",
      "dataset"
    ],
    "worker": [
      "self",
      "drop_empty",
      "batch_samples"
    ]
  },
  "pad_batch_data": [
    "insts",
    "pad_idx",
    "max_seq_len",
    "return_pos",
    "return_input_mask",
    "return_max_len",
    "return_num_token",
    "return_seq_lens",
    "pad_2d_pos_ids",
    "pad_segment_id",
    "select",
    "extract"
  ],
  "ImageReader": {
    "__init__": [
      "self",
      "super_rel_pos",
      "tokenizer",
      "max_key_len",
      "max_seq_len",
      "image_size",
      "block_w",
      "block_h",
      "im_npos"
    ],
    "ppocr2example": [
      "self",
      "ocr_res",
      "img_path",
      "querys"
    ],
    "box2example": [
      "self",
      "ocr_res",
      "img_path",
      "querys"
    ],
    "example2feature": [
      "self",
      "example",
      "tokenizer",
      "max_line_id"
    ],
    "_pad_batch_records": [
      "self",
      "batch_records",
      "max_line_id",
      "phase"
    ],
    "data_generator": [
      "self",
      "ocr_res",
      "img_path",
      "querys",
      "batch_size",
      "ocr_type",
      "phase"
    ],
    "_prepare_batch_data": [
      "self",
      "features",
      "batch_size",
      "phase"
    ],
    "_build_input_mask": [
      "self",
      "padded_token_ids"
    ],
    "_build_rel_pos": [
      "self",
      "padded_token_ids"
    ],
    "generate_coco_data": [
      "self",
      "batch_image_path",
      "batch_image_base64",
      "batch_scaled_width",
      "batch_scaled_height",
      "batch_rois"
    ],
    "im_make_batch": [
      "self",
      "dataset",
      "image_boxes_nums",
      "bsize"
    ],
    "BIO2SPAN": [
      "self",
      "BIO"
    ],
    "_check_is_max_context": [
      "self",
      "doc_spans",
      "cur_span_index",
      "position"
    ]
  },
  "get_doc_pred": [
    "result",
    "ans_pos",
    "example",
    "tokenizer",
    "feature",
    "do_lower_case",
    "all_key_probs",
    "example_index"
  ],
  "find_bio_pos": [
    "label"
  ],
  "viterbi_decode": [
    "logits"
  ],
  "find_answer_pos": [
    "logits",
    "feature"
  ],
  "calEuclidean": [
    "x_list",
    "y_list"
  ],
  "longestCommonSequence": [
    "question_tokens",
    "context_tokens"
  ],
  "sort_res": [
    "prompt",
    "ans_list",
    "context",
    "boxes",
    "lang"
  ],
  "TASKS": [],
  "support_schema_list": [],
  "support_argument_list": [],
  "Taskflow": {
    "__init__": [
      "self",
      "task",
      "model",
      "mode",
      "device_id",
      "from_hf_hub"
    ],
    "__call__": [
      "self"
    ],
    "help": [
      "self"
    ],
    "task_path": [
      "self"
    ],
    "tasks": [],
    "from_segments": [
      "self"
    ],
    "interactive_mode": [
      "self",
      "max_turn"
    ],
    "set_schema": [
      "self",
      "schema"
    ],
    "set_argument": [
      "self",
      "argument"
    ]
  },
  "MATCH_TYPE": [],
  "TextSimilarityTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "task",
      "model",
      "batch_size",
      "max_length"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_check_input_text": [
      "self",
      "inputs"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "_convert_dygraph_to_static": [
      "self"
    ]
  },
  "SegJiebaTask": {
    "__init__": [
      "self",
      "task",
      "model",
      "user_dict"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ]
  },
  "SegLACTask": {
    "__init__": [
      "self",
      "task",
      "model"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "SegWordTagTask": {
    "__init__": [
      "self",
      "model",
      "task"
    ],
    "_simplify_result": [
      "self",
      "results"
    ]
  },
  "LacTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "task",
      "model",
      "user_dict"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_vocabs": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_preprocess": [
      "self",
      "inputs",
      "padding",
      "add_special_tokens"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "MultimodalFeatureExtractionTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "task",
      "model",
      "batch_size",
      "is_static_model",
      "max_length",
      "return_tensors"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self"
    ],
    "_batchify": [
      "self",
      "data",
      "batch_size"
    ],
    "_check_input_text": [
      "self",
      "inputs"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_convert_dygraph_to_static": [
      "self"
    ],
    "_get_inference_model": [
      "self"
    ]
  },
  "LABEL_TO_SCHEMA": [],
  "WordTagTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "model",
      "task",
      "tag_path",
      "term_schema_path",
      "term_data_path",
      "user_dict",
      "linking",
      "spo_config_path",
      "with_ie"
    ],
    "summary_num": [
      "self"
    ],
    "linking": [
      "self"
    ],
    "_load_labels": [
      "tag_path"
    ],
    "_load_task_resources": [
      "self"
    ],
    "_preprocess_text": [
      "self",
      "input_texts"
    ],
    "_reset_offset": [
      "self",
      "pred_words"
    ],
    "_decode": [
      "self",
      "batch_texts",
      "batch_pred_tags"
    ],
    "_term_linking": [
      "self",
      "wordtag_res"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_preprocess": [
      "self",
      "inputs",
      "padding",
      "add_special_tokens"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "set_schema": [
      "self",
      "schema"
    ]
  },
  "NPTagTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "task",
      "model",
      "batch_size",
      "max_seq_len",
      "linking"
    ],
    "summary_num": [
      "self"
    ],
    "_construct_dict_map": [
      "self"
    ],
    "_decode": [
      "self",
      "pred_ids"
    ],
    "_search": [
      "self",
      "scores_can",
      "pred_ids_can",
      "depth",
      "path",
      "score"
    ],
    "_find_topk": [
      "self",
      "a",
      "k",
      "axis",
      "largest",
      "sorted"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "URLS": [],
  "PoetryGenerationTask": {
    "__init__": [
      "self",
      "task",
      "model"
    ]
  },
  "ENCODER_TYPE": [],
  "TextFeatureExtractionTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "task",
      "model",
      "batch_size",
      "max_seq_len",
      "_static_mode",
      "return_tensors",
      "reinitialize",
      "share_parameters",
      "is_paragraph",
      "output_emb_size"
    ],
    "_check_para_encoder": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_batchify": [
      "self",
      "data",
      "batch_size"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "_convert_dygraph_to_static": [
      "self"
    ]
  },
  "text_length": [
    "text"
  ],
  "SentenceFeatureExtractionTask": {
    "resource_files_names": [],
    "__init__": [
      "self",
      "task",
      "model",
      "batch_size",
      "max_seq_len",
      "_static_mode",
      "return_tensors",
      "pooling_mode"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_batchify": [
      "self",
      "data",
      "batch_size"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "_convert_dygraph_to_static": [
      "self"
    ]
  },
  "QuestionGenerationTask": {
    "__init__": [
      "self",
      "task",
      "model"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_batchify": [
      "self",
      "data",
      "batch_size"
    ],
    "_check_input_text": [
      "self",
      "inputs"
    ],
    "_convert_example": [
      "self",
      "example",
      "max_seq_len",
      "return_length",
      "template"
    ],
    "_parse_batch": [
      "self",
      "batch_examples",
      "pad_val",
      "pad_right"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "out_run_model": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "_return_num_return_sequences": [
      "self",
      "ids",
      "scores",
      "max_dec_len",
      "num_return_sequences"
    ],
    "_select_from_num_return_sequences": [
      "self",
      "ids",
      "scores",
      "max_dec_len",
      "num_return_sequences"
    ],
    "_post_process_decoded_sequence": [
      "self",
      "token_ids"
    ],
    "_remove_template": [
      "self",
      "instr"
    ],
    "_construct_input_spec": [
      "self"
    ]
  },
  "TASK_MODEL_MAP": [],
  "CSCTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "task",
      "model"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_vocabs": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_preprocess": [
      "self",
      "inputs",
      "padding",
      "add_special_tokens"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "_convert_example": [
      "self",
      "example"
    ],
    "_parse_decode": [
      "self",
      "words",
      "corr_preds",
      "det_preds",
      "lengths"
    ]
  },
  "CodeGenerationTask": {
    "__init__": [
      "self",
      "task",
      "model"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_batchify": [
      "self",
      "data",
      "batch_size"
    ],
    "_convert_text_to_input": [
      "self",
      "texts"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "_construct_input_spec": [
      "self"
    ]
  },
  "TextGenerationTask": {
    "__init__": [
      "self",
      "task",
      "model"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_preprocess": [
      "self",
      "inputs",
      "padding",
      "add_special_tokens"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "POS_LABEL_WORDTAG": [],
  "POS_LABEL_LAC": [],
  "NERWordTagTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "model",
      "task",
      "entity_only"
    ],
    "_decode": [
      "self",
      "batch_texts",
      "batch_pred_tags"
    ],
    "_simplify_result": [
      "self",
      "results"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "NERLACTask": {
    "__init__": [
      "self",
      "model",
      "task",
      "entity_only"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "softmax": [
    "x",
    "axis"
  ],
  "TextClassificationTask": {
    "__init__": [
      "self",
      "task",
      "model"
    ],
    "_initialize_prompt": [
      "self"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self"
    ],
    "_construct_id2label": [
      "self"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "QuestionAnsweringTask": {
    "__init__": [
      "self",
      "task",
      "model"
    ]
  },
  "POSTaggingTask": {
    "__init__": [
      "self",
      "task",
      "model"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "SentaTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "task",
      "model"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_preprocess": [
      "self",
      "inputs",
      "padding",
      "add_special_tokens"
    ],
    "_batchify_fn": [
      "self",
      "samples"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "SkepTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "task",
      "model"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_preprocess": [
      "self",
      "inputs",
      "padding",
      "add_special_tokens"
    ],
    "_batchify_fn": [
      "self",
      "samples"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "UIESentaTask": {
    "resource_files_names": [],
    "resource_files_urls": [],
    "__init__": [
      "self",
      "task",
      "model",
      "schema",
      "aspects"
    ],
    "set_schema": [
      "self",
      "schema"
    ],
    "_check_aspects": [
      "self",
      "aspects"
    ],
    "_construct_input_spec": [
      "self"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_single_stage_predict": [
      "self",
      "inputs"
    ],
    "_auto_joiner": [
      "self",
      "short_results",
      "short_inputs",
      "input_mapping"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_multi_stage_predict": [
      "self",
      "data"
    ],
    "_convert_ids_to_results": [
      "self",
      "examples",
      "sentence_ids",
      "probs"
    ],
    "_build_tree": [
      "cls",
      "schema",
      "name"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ]
  },
  "DocPromptTask": {
    "__init__": [
      "self",
      "task",
      "model"
    ],
    "_construct_tokenizer": [
      "self"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "_check_input_text": [
      "self",
      "inputs"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_input_spec": [
      "self"
    ]
  },
  "TextSummarizationTask": {
    "__init__": [
      "self",
      "task",
      "model"
    ],
    "_construct_model": [
      "self",
      "model"
    ],
    "_construct_tokenizer": [
      "self",
      "model"
    ],
    "_preprocess": [
      "self",
      "inputs"
    ],
    "_batchify": [
      "self",
      "data",
      "batch_size"
    ],
    "_convert_example": [
      "self",
      "example",
      "max_seq_len",
      "return_length"
    ],
    "_parse_batch": [
      "self",
      "batch_examples",
      "pad_val",
      "pad_right"
    ],
    "_run_model": [
      "self",
      "inputs"
    ],
    "_postprocess": [
      "self",
      "inputs"
    ],
    "_select_from_num_return_sequences": [
      "self",
      "ids",
      "scores",
      "max_dec_len",
      "num_return_sequences"
    ],
    "_post_process_decoded_sequence": [
      "self",
      "token_ids"
    ],
    "_construct_input_spec": [
      "self"
    ]
  },
  "BoWModel": {
    "__init__": [
      "self",
      "vocab_size",
      "num_classes",
      "emb_dim",
      "padding_idx",
      "hidden_size",
      "fc_hidden_size"
    ],
    "forward": [
      "self",
      "text",
      "seq_len"
    ]
  },
  "LSTMModel": {
    "__init__": [
      "self",
      "vocab_size",
      "num_classes",
      "emb_dim",
      "padding_idx",
      "lstm_hidden_size",
      "direction",
      "lstm_layers",
      "dropout_rate",
      "pooling_type",
      "fc_hidden_size"
    ],
    "forward": [
      "self",
      "text",
      "seq_len"
    ]
  },
  "SkepSequenceModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "BiAffineParser": {
    "__init__": [
      "self",
      "encoding_model",
      "n_rels",
      "n_words",
      "pad_index",
      "bos_index",
      "eos_index",
      "n_mlp_arc",
      "n_mlp_rel"
    ],
    "forward": [
      "self",
      "words",
      "wp"
    ]
  },
  "BiAffine": {
    "__init__": [
      "self",
      "n_in",
      "n_out",
      "bias_x",
      "bias_y"
    ],
    "forward": [
      "self",
      "x",
      "y"
    ]
  },
  "LSTMByWPEncoder": {
    "__init__": [
      "self",
      "n_words",
      "pad_index",
      "lstm_by_wp_embed_size",
      "n_embed",
      "n_lstm_hidden",
      "n_lstm_layers"
    ],
    "forward": [
      "self",
      "words",
      "wp"
    ]
  },
  "index_sample": [
    "x",
    "index"
  ],
  "BiGruCrf": {
    "__init__": [
      "self",
      "word_emb_dim",
      "hidden_size",
      "vocab_size",
      "num_labels",
      "emb_lr",
      "crf_lr",
      "with_start_stop_tag"
    ],
    "forward": [
      "self",
      "inputs",
      "lengths",
      "labels"
    ]
  },
  "ErnieForCSC": {
    "__init__": [
      "self",
      "ernie",
      "pinyin_vocab_size",
      "pad_pinyin_id"
    ],
    "forward": [
      "self",
      "input_ids",
      "pinyin_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ]
  },
  "quant_inference_mapping": [],
  "QuantizationConfig": {
    "__init__": [
      "self",
      "weight_quantize_algo",
      "quant_type",
      "shift",
      "smooth",
      "shift_smooth_all_linears",
      "quant_round_type",
      "llm_int8_threshold",
      "weight_double_quant",
      "weight_blocksize",
      "weight_double_quant_block_size",
      "weight_quant_method",
      "act_quant_method"
    ],
    "is_weight_quantize": [
      "self"
    ],
    "is_support_merge_tensor_parallel": [
      "self"
    ],
    "from_dict": [
      "cls",
      "config_dict",
      "return_unused_kwargs"
    ],
    "to_json_file": [
      "self",
      "json_file_path"
    ],
    "to_dict": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "to_json_string": [
      "self",
      "use_diff"
    ],
    "to_diff_dict": [
      "self"
    ]
  },
  "qlora_weight_quantize": [
    "weight",
    "quant_algo",
    "double_quant",
    "block_size",
    "double_quant_block_size",
    "linear_name",
    "return_dict"
  ],
  "qlora_weight_dequantize": [
    "quant_weight",
    "quant_algo",
    "state",
    "double_quant",
    "block_size",
    "double_quant_block_size"
  ],
  "qlora_weight_quantize_dequantize": [
    "weight",
    "quant_algo",
    "double_quant",
    "block_size",
    "double_quant_block_size"
  ],
  "qlora_weight_linear": [
    "x",
    "quant_weight",
    "dtype",
    "state",
    "quant_algo",
    "double_quant",
    "block_size",
    "double_quant_block_size",
    "bias"
  ],
  "QuantMapping": [],
  "QuantizationLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "quant_algo",
      "dtype",
      "weight_attr",
      "scale_attr",
      "bias_attr",
      "block_size",
      "double_quant_block_size",
      "double_quant",
      "qquant_scale_attr",
      "double_quant_scale_attr",
      "quant_scale_offset_attr",
      "quant_scale_attr",
      "llm_int8_threshold"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ColumnParallelQuantizationLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "quant_algo",
      "dtype",
      "weight_attr",
      "scale_attr",
      "bias_attr",
      "gather_output",
      "mp_group",
      "llm_int8_threshold"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RowParallelQuantizationLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "quant_algo",
      "dtype",
      "weight_attr",
      "scale_attr",
      "bias_attr",
      "input_is_parallel",
      "mp_group",
      "llm_int8_threshold"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "replace_with_quantization_linear": [
    "model",
    "quantization_config",
    "name_prefix",
    "llm_int8_threshold"
  ],
  "convert_to_quantize_state_dict_with_check": [
    "state_dict",
    "quantization_linear_list",
    "quant_algo",
    "dtype"
  ],
  "convert_to_quantize_state_dict_without_check": [
    "state_dict",
    "quantization_linear_list",
    "quantization_config",
    "dtype"
  ],
  "convert_to_quantize_state_dict": [
    "state_dict",
    "quantization_linear_list",
    "quantization_config",
    "dtype"
  ],
  "update_loaded_state_dict_keys": [
    "state_dict",
    "quantization_linear_list",
    "quantization_config"
  ],
  "is_git_repo": [
    "dir"
  ],
  "have_git": [],
  "git_revision": [
    "dir"
  ],
  "is_dirty": [
    "dir"
  ],
  "commit": [],
  "show": []
}