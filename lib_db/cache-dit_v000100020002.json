{
  "main": [],
  "_FORMAT": [],
  "_DATE_FORMAT": [],
  "_LOG_LEVEL": [],
  "_LOG_DIR": [],
  "NewLineFormatter": {
    "__init__": [
      "self",
      "fmt",
      "datefmt"
    ],
    "format": [
      "self",
      "record"
    ]
  },
  "_root_logger": [],
  "_default_handler": [],
  "_default_file_handler": [],
  "_inference_log_file_handler": [],
  "_setup_logger": [],
  "init_logger": [
    "name"
  ],
  "logging_rank_0": [
    "logger",
    "message",
    "level"
  ],
  "ENV": {},
  "logger": [],
  "dummy_print": [],
  "disable_print": [],
  "is_diffusers_at_least_0_3_5": [],
  "maybe_empty_cache": [],
  "print_tensor": [
    "x",
    "name",
    "dim",
    "no_dist_shape",
    "disable"
  ],
  "NONE": [],
  "DBCache": [],
  "DBPrune": [],
  "Pattern_0": [],
  "Pattern_1": [],
  "Pattern_2": [],
  "Pattern_3": [],
  "Pattern_4": [],
  "Pattern_5": [],
  "CacheStats": {},
  "summary": [
    "adapter_or_others",
    "details",
    "logging"
  ],
  "strify": [
    "adapter_or_others"
  ],
  "_summary": [
    "pipe_or_module",
    "details",
    "logging"
  ],
  "supported_matrix": [],
  "__all__": [],
  "TYPE_CHECKING": [],
  "__version__": [],
  "version": [],
  "__version_tuple__": [],
  "version_tuple": [],
  "__commit_id__": [],
  "commit_id": [],
  "PROFILER_DIR": [],
  "ProfilerContext": {
    "__init__": [
      "self",
      "enabled",
      "activities",
      "output_dir",
      "profile_name",
      "with_stack",
      "record_shapes"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "profile_function": [
    "enabled",
    "activities",
    "output_dir",
    "profile_name",
    "with_stack",
    "record_shapes"
  ],
  "create_profiler_context": [
    "enabled",
    "activities",
    "output_dir",
    "profile_name"
  ],
  "get_profiler_output_dir": [],
  "set_profiler_output_dir": [
    "path"
  ],
  "_per_token_quant_8bit": [
    "y_ptr",
    "x_ptr",
    "H",
    "eps",
    "bit8_min",
    "bit8_max",
    "BLOCK"
  ],
  "_per_token_dequant_8bit": [
    "y_ptr",
    "x_ptr",
    "H",
    "BLOCK"
  ],
  "per_token_quant_fp8": [
    "x"
  ],
  "per_token_dequant_fp8": [
    "x"
  ],
  "_qkv_permute_quant": [
    "quant_x_ptr",
    "x_ptr",
    "qx_stride_b",
    "qx_stride_n",
    "x_stride_b",
    "x_stride_s",
    "x_stride_p",
    "B",
    "S",
    "N",
    "D",
    "EPS",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_D"
  ],
  "_qkv_dequant_permute": [
    "x_ptr",
    "quant_x_ptr",
    "x_stride_s",
    "qx_stride_s",
    "qx_stride_b",
    "qx_stride_n",
    "B",
    "S",
    "N",
    "D",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_D"
  ],
  "qkv_permute_quant_fp8": [
    "x",
    "eps"
  ],
  "qkv_dequant_permute_fp8": [
    "quant_x",
    "dtype"
  ],
  "fused_merge_attn_states": [
    "prev_out",
    "prev_lse",
    "suff_out",
    "suff_lse"
  ],
  "_fused_merge_attn_states_kernel": [
    "out_ptr",
    "lse_ptr",
    "prev_out_ptr",
    "prev_lse_ptr",
    "suff_out_ptr",
    "suff_lse_ptr",
    "HEAD_SIZE",
    "PADDED_HEAD_SIZE"
  ],
  "normalize_quantize_type": [
    "quantize_type"
  ],
  "quantize": [
    "module",
    "quant_type",
    "backend",
    "per_row",
    "exclude_layers",
    "filter_fn"
  ],
  "quantize_ao": [
    "module",
    "quant_type",
    "per_row",
    "exclude_layers",
    "filter_fn"
  ],
  "lpips_loss_fn_vgg": [],
  "lpips_loss_fn_alex": [],
  "compute_lpips_img": [
    "img0",
    "img1",
    "net"
  ],
  "DISABLE_VERBOSE": [],
  "PSNR_TYPE": [],
  "compute_lpips_file": [
    "image_true",
    "image_test"
  ],
  "set_psnr_type": [
    "psnr_type"
  ],
  "get_psnr_type": [],
  "calculate_psnr": [
    "image_true",
    "image_test"
  ],
  "compute_psnr_file": [
    "image_true",
    "image_test"
  ],
  "compute_mse_file": [
    "image_true",
    "image_test"
  ],
  "compute_ssim_file": [
    "image_true",
    "image_test"
  ],
  "compute_dir_metric": [
    "image_true_dir",
    "image_test_dir",
    "compute_file_func"
  ],
  "_fetch_video_frames": [
    "video_true",
    "video_test"
  ],
  "compute_video_metric": [
    "video_true",
    "video_test",
    "compute_frame_func"
  ],
  "METRICS_CHOICES": [],
  "get_args": [],
  "entrypoint": [],
  "ImagePathDataset": {
    "__init__": [
      "self",
      "files_or_imgs",
      "transforms"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ]
  },
  "get_activations": [
    "files_or_imgs",
    "model",
    "batch_size",
    "dims",
    "device",
    "num_workers",
    "disable_tqdm"
  ],
  "calculate_frechet_distance": [
    "mu1",
    "sigma1",
    "mu2",
    "sigma2",
    "eps"
  ],
  "calculate_activation_statistics": [
    "files_or_imgs",
    "model",
    "batch_size",
    "dims",
    "device",
    "num_workers",
    "disable_tqdm"
  ],
  "FrechetInceptionDistance": {
    "__init__": [
      "self",
      "device",
      "dims",
      "num_workers",
      "batch_size",
      "disable_tqdm"
    ],
    "compute_fid": [
      "self",
      "image_true",
      "image_test"
    ],
    "compute_video_fid": [
      "self",
      "video_true",
      "video_test"
    ],
    "_fetch_video_frames": [
      "self",
      "video_true",
      "video_test"
    ]
  },
  "compute_fid": [
    "image_true",
    "image_test"
  ],
  "compute_video_fid": [
    "video_true",
    "video_test"
  ],
  "FID_WEIGHTS_URL": [],
  "InceptionV3": {
    "DEFAULT_BLOCK_INDEX": [],
    "BLOCK_INDEX_BY_DIM": [],
    "__init__": [
      "self",
      "output_blocks",
      "resize_input",
      "normalize_input",
      "requires_grad",
      "use_fid_inception"
    ],
    "forward": [
      "self",
      "inp"
    ]
  },
  "_inception_v3": [],
  "fid_inception_v3": [],
  "FIDInceptionA": {
    "__init__": [
      "self",
      "in_channels",
      "pool_features"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FIDInceptionC": {
    "__init__": [
      "self",
      "in_channels",
      "channels_7x7"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FIDInceptionE_1": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FIDInceptionE_2": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ImageRewardScore": {
    "__init__": [
      "self",
      "device",
      "imagereward_model_path"
    ],
    "compute_reward_score": [
      "self",
      "img",
      "prompt"
    ]
  },
  "compute_reward_score_img": [
    "img",
    "prompt",
    "imagereward_model_path"
  ],
  "compute_reward_score": [
    "img_dir",
    "prompts",
    "imagereward_model_path"
  ],
  "_metrics_progress_verbose": [],
  "set_metrics_verbose": [
    "verbose"
  ],
  "get_metrics_verbose": [],
  "_IMAGE_EXTENSIONS": [],
  "_VIDEO_EXTENSIONS": [],
  "CLIPScore": {
    "__init__": [
      "self",
      "device",
      "clip_model_path"
    ],
    "compute_clip_score": [
      "self",
      "img",
      "prompt"
    ]
  },
  "compute_clip_score_img": [
    "img",
    "prompt",
    "clip_model_path"
  ],
  "compute_clip_score": [
    "img_dir",
    "prompts",
    "clip_model_path"
  ],
  "ParamsModifier": {
    "__init__": [
      "self",
      "cache_config",
      "calibrator_config"
    ]
  },
  "enable_cache": [
    "pipe_or_adapter",
    "cache_config",
    "calibrator_config",
    "params_modifiers",
    "parallelism_config",
    "attention_backend"
  ],
  "_has_controlnet": [
    "pipe_or_adapter"
  ],
  "_parse_text_encoder": [
    "pipe"
  ],
  "_parse_extra_parallel_modules": [
    "pipe_or_adapter",
    "extra_parallel_module"
  ],
  "set_attn_backend": [
    "pipe_or_adapter",
    "attention_backend"
  ],
  "refresh_context": [
    "transformer"
  ],
  "disable_cache": [
    "pipe_or_adapter"
  ],
  "supported_pipelines": [],
  "get_adapter": [
    "pipe"
  ],
  "_steps_mask": [
    "compute_bins",
    "cache_bins",
    "total_steps"
  ],
  "steps_mask": [
    "compute_bins",
    "cache_bins",
    "total_steps",
    "mask_policy"
  ],
  "load_cache_options_from_dict": [
    "cache_kwargs",
    "reset"
  ],
  "load_cache_options_from_yaml": [
    "yaml_file_path",
    "reset"
  ],
  "load_options": [
    "path_or_dict",
    "reset"
  ],
  "load_cache_config": [
    "path_or_dict"
  ],
  "load_parallelism_config": [
    "path_or_dict"
  ],
  "load_attn_backend_config": [
    "path_or_dict"
  ],
  "load_configs": [
    "path_or_dict",
    "return_dict"
  ],
  "ForwardPattern": {
    "__init__": [
      "self",
      "Return_H_First",
      "Return_H_Only",
      "Forward_H_only",
      "In",
      "Out",
      "Supported"
    ],
    "Pattern_0": [],
    "Pattern_1": [],
    "Pattern_2": [],
    "Pattern_3": [],
    "Pattern_4": [],
    "Pattern_5": [],
    "supported_patterns": []
  },
  "CacheType": {
    "NONE": [],
    "DBCache": [],
    "DBPrune": [],
    "type": [
      "type_hint"
    ],
    "__str__": [
      "self"
    ]
  },
  "cache_type": [
    "type_hint"
  ],
  "block_range": [
    "start",
    "end",
    "step"
  ],
  "_relaxed_assert": [
    "transformer",
    "allow_classes"
  ],
  "flux_adapter": [
    "pipe"
  ],
  "mochi_adapter": [
    "pipe"
  ],
  "cogvideox_adapter": [
    "pipe"
  ],
  "wan_adapter": [
    "pipe"
  ],
  "hunyuanvideo_adapter": [
    "pipe"
  ],
  "qwenimage_adapter": [
    "pipe"
  ],
  "ltxvideo_adapter": [
    "pipe"
  ],
  "allegro_adapter": [
    "pipe"
  ],
  "cogview3plus_adapter": [
    "pipe"
  ],
  "cogview4_adapter": [
    "pipe"
  ],
  "cosmos_adapter": [
    "pipe"
  ],
  "easyanimate_adapter": [
    "pipe"
  ],
  "skyreelsv2_adapter": [
    "pipe"
  ],
  "sd3_adapter": [
    "pipe"
  ],
  "consisid_adapter": [
    "pipe"
  ],
  "dit_adapter": [
    "pipe"
  ],
  "amused_adapter": [
    "pipe"
  ],
  "bria_adapter": [
    "pipe"
  ],
  "lumina2_adapter": [
    "pipe"
  ],
  "omnigen_adapter": [
    "pipe"
  ],
  "pixart_adapter": [
    "pipe"
  ],
  "sana_adapter": [
    "pipe"
  ],
  "stabledudio_adapter": [
    "pipe"
  ],
  "visualcloze_adapter": [
    "pipe"
  ],
  "auraflow_adapter": [
    "pipe"
  ],
  "chroma_adapter": [
    "pipe"
  ],
  "shape_adapter": [
    "pipe"
  ],
  "hidream_adapter": [
    "pipe"
  ],
  "hunyuandit_adapter": [
    "pipe"
  ],
  "hunyuanditpag_adapter": [
    "pipe"
  ],
  "kandinsky5_adapter": [
    "pipe"
  ],
  "prx_adapter": [
    "pipe"
  ],
  "hunyuan_image_adapter": [
    "pipe"
  ],
  "chronoedit_adapter": [
    "pipe"
  ],
  "zimage_adapter": [
    "pipe"
  ],
  "ovis_image_adapter": [
    "pipe"
  ],
  "longcat_image_adapter": [
    "pipe"
  ],
  "glm_image_adapter": [
    "pipe"
  ],
  "import_error_adapter": [],
  "_safe_import": [
    "module_name",
    "func_name"
  ],
  "BlockAdapterRegister": {
    "register": [
      "cls",
      "name",
      "supported"
    ],
    "get_adapter": [
      "cls",
      "pipe_or_module"
    ],
    "has_separate_cfg": [
      "cls",
      "pipe_or_adapter_or_module"
    ],
    "is_supported": [
      "cls",
      "pipe_or_module"
    ],
    "supported_pipelines": [
      "cls"
    ]
  },
  "FakeDiffusionPipeline": {
    "__init__": [
      "self",
      "transformer"
    ]
  },
  "BlockAdapter": {
    "__post_init__": [
      "self"
    ],
    "maybe_fake_pipe": [
      "self"
    ],
    "maybe_skip_checks": [
      "self"
    ],
    "maybe_fill_attrs": [
      "self"
    ],
    "maybe_patchify": [
      "self"
    ],
    "auto_block_adapter": [
      "adapter"
    ],
    "check_block_adapter": [
      "adapter"
    ],
    "find_match_blocks": [
      "transformer",
      "allow_prefixes",
      "allow_suffixes",
      "check_prefixes",
      "check_suffixes"
    ],
    "find_blocks": [
      "transformer"
    ],
    "match_block_pattern": [
      "block",
      "forward_pattern"
    ],
    "match_blocks_pattern": [
      "transformer_blocks",
      "forward_pattern",
      "logging"
    ],
    "normalize": [
      "adapter",
      "unique"
    ],
    "unique": [
      "cls",
      "adapter"
    ],
    "assert_normalized": [
      "cls",
      "adapter"
    ],
    "is_normalized": [
      "cls",
      "adapter"
    ],
    "is_cached": [
      "cls",
      "adapter"
    ],
    "is_parallelized": [
      "cls",
      "adapter"
    ],
    "nested_depth": [
      "cls",
      "obj"
    ],
    "flatten": [
      "cls",
      "attr"
    ]
  },
  "CachedAdapter": {
    "__call__": [
      "self"
    ],
    "apply": [
      "cls",
      "pipe_or_adapter"
    ],
    "cachify": [
      "cls",
      "block_adapter"
    ],
    "check_context_kwargs": [
      "cls",
      "block_adapter"
    ],
    "create_context": [
      "cls",
      "block_adapter"
    ],
    "modify_context_params": [
      "cls",
      "block_adapter"
    ],
    "_modify_context_params": [
      "cls",
      "new_context_kwargs",
      "old_context_kwargs"
    ],
    "_config_messages": [
      "cls",
      "logging"
    ],
    "mock_blocks": [
      "cls",
      "block_adapter",
      "contexts_kwargs"
    ],
    "mock_transformer": [
      "cls",
      "unified_blocks",
      "transformer",
      "blocks_name",
      "unique_blocks_name",
      "dummy_blocks_names",
      "block_adapter"
    ],
    "collect_unified_blocks": [
      "cls",
      "block_adapter",
      "contexts_kwargs"
    ],
    "apply_params_hooks": [
      "cls",
      "block_adapter",
      "contexts_kwargs"
    ],
    "apply_stats_hooks": [
      "cls",
      "block_adapter"
    ],
    "maybe_release_hooks": [
      "cls",
      "pipe_or_adapter"
    ],
    "release_hooks": [
      "cls",
      "pipe_or_adapter",
      "_release_blocks",
      "_release_transformer",
      "_release_pipeline"
    ],
    "maybe_refresh_context": [
      "cls",
      "transformer"
    ]
  },
  "LTX2PatchFunctor": {
    "_apply": [
      "self",
      "transformer"
    ]
  },
  "__patch_transformer_forward__": [
    "self",
    "hidden_states",
    "audio_hidden_states",
    "encoder_hidden_states",
    "audio_encoder_hidden_states",
    "timestep",
    "audio_timestep",
    "encoder_attention_mask",
    "audio_encoder_attention_mask",
    "num_frames",
    "height",
    "width",
    "fps",
    "audio_num_frames",
    "video_coords",
    "audio_coords",
    "attention_kwargs",
    "return_dict"
  ],
  "HunyuanDiTPatchFunctor": {
    "_apply": [
      "self",
      "transformer"
    ]
  },
  "__patch_block_forward__": [
    "self",
    "hidden_states",
    "encoder_hidden_states",
    "temb",
    "image_rotary_emb",
    "controlnet_block_samples",
    "skips"
  ],
  "WanVACEPatchFunctor": {
    "_apply": [
      "self",
      "transformer"
    ]
  },
  "DiTPatchFunctor": {
    "_apply": [
      "self",
      "transformer"
    ]
  },
  "GlmImagePatchFunctor": {
    "_apply": [
      "self",
      "transformer",
      "blocks"
    ]
  },
  "HiDreamPatchFunctor": {
    "_apply": [
      "self",
      "transformer"
    ]
  },
  "__patch_double_forward__": [
    "self",
    "hidden_states",
    "encoder_hidden_states",
    "hidden_states_masks",
    "temb",
    "image_rotary_emb",
    "llama31_encoder_hidden_states"
  ],
  "__patch_single_forward__": [
    "self",
    "hidden_states",
    "hidden_states_masks",
    "temb",
    "image_rotary_emb",
    "llama31_encoder_hidden_states"
  ],
  "ZImageControlNetPatchFunctor": {
    "_apply": [
      "self",
      "transformer"
    ]
  },
  "ImportErrorPatchFunctor": {
    "_apply": [
      "self",
      "transformer"
    ]
  },
  "FluxPatchFunctor": [],
  "ChromaPatchFunctor": [],
  "QwenImageControlNetPatchFunctor": [],
  "PatchFunctor": {
    "apply": [
      "self",
      "transformer"
    ],
    "_apply": [
      "self",
      "transformer"
    ],
    "is_from_diffusers": [
      "cls",
      "transformer"
    ]
  },
  "PrunedContext": {
    "__post_init__": [
      "self"
    ],
    "get_residual_diff_threshold": [
      "self"
    ],
    "mark_step_begin": [
      "self"
    ],
    "add_residual_diff": [
      "self",
      "diff"
    ],
    "add_pruned_step": [
      "self"
    ],
    "add_pruned_block": [
      "self",
      "num_blocks"
    ],
    "add_actual_block": [
      "self",
      "num_blocks"
    ],
    "get_pruned_blocks": [
      "self"
    ],
    "get_cfg_pruned_blocks": [
      "self"
    ],
    "get_actual_blocks": [
      "self"
    ],
    "get_cfg_actual_blocks": [
      "self"
    ],
    "get_pruned_steps": [
      "self"
    ],
    "get_cfg_pruned_steps": [
      "self"
    ]
  },
  "ContextNotExistError": {},
  "CachedContextManager": {
    "__init__": [
      "self",
      "name",
      "persistent_context"
    ],
    "persistent_context": [
      "self"
    ],
    "current_context": [
      "self"
    ],
    "current_step_refreshed": [
      "self"
    ],
    "is_pre_refreshed": [
      "self"
    ],
    "new_context": [
      "self"
    ],
    "maybe_refresh": [
      "self",
      "cached_context"
    ],
    "set_context": [
      "self",
      "cached_context"
    ],
    "get_context": [
      "self",
      "name"
    ],
    "reset_context": [
      "self",
      "cached_context"
    ],
    "remove_context": [
      "self",
      "cached_context"
    ],
    "clear_contexts": [
      "self"
    ],
    "enter_context": [
      "self",
      "cached_context"
    ],
    "get_residual_diff_threshold": [
      "self"
    ],
    "get_buffer": [
      "self",
      "name"
    ],
    "set_buffer": [
      "self",
      "name",
      "buffer"
    ],
    "remove_buffer": [
      "self",
      "name"
    ],
    "mark_step_begin": [
      "self"
    ],
    "get_current_step": [
      "self"
    ],
    "get_current_step_residual_diff": [
      "self"
    ],
    "get_current_step_cfg_residual_diff": [
      "self"
    ],
    "get_current_transformer_step": [
      "self"
    ],
    "get_force_refresh_step_hint": [
      "self"
    ],
    "get_cached_steps": [
      "self"
    ],
    "get_cfg_cached_steps": [
      "self"
    ],
    "get_max_cached_steps": [
      "self"
    ],
    "get_max_continuous_cached_steps": [
      "self"
    ],
    "get_continuous_cached_steps": [
      "self"
    ],
    "get_cfg_continuous_cached_steps": [
      "self"
    ],
    "add_cached_step": [
      "self"
    ],
    "add_residual_diff": [
      "self",
      "diff"
    ],
    "get_residual_diffs": [
      "self"
    ],
    "get_cfg_residual_diffs": [
      "self"
    ],
    "get_accumulated_residual_diff": [
      "self"
    ],
    "get_cfg_accumulated_residual_diff": [
      "self"
    ],
    "max_accumulated_residual_diff_threshold": [
      "self"
    ],
    "is_calibrator_enabled": [
      "self"
    ],
    "is_encoder_calibrator_enabled": [
      "self"
    ],
    "get_calibrator": [
      "self"
    ],
    "get_cfg_calibrator": [
      "self"
    ],
    "is_calibrator_cache_residual": [
      "self"
    ],
    "is_cache_residual": [
      "self"
    ],
    "is_encoder_cache_residual": [
      "self"
    ],
    "is_in_warmup": [
      "self"
    ],
    "is_in_full_compute_steps": [
      "self"
    ],
    "is_steps_computation_mask_enabled": [
      "self"
    ],
    "get_steps_computation_policy": [
      "self"
    ],
    "is_l1_diff_enabled": [
      "self"
    ],
    "get_important_condition_threshold": [
      "self"
    ],
    "Fn_compute_blocks": [
      "self"
    ],
    "Bn_compute_blocks": [
      "self"
    ],
    "enable_separate_cfg": [
      "self"
    ],
    "is_separate_cfg_step": [
      "self"
    ],
    "cfg_diff_compute_separate": [
      "self"
    ],
    "similarity": [
      "self",
      "t1",
      "t2"
    ],
    "_debugging_set_buffer": [
      "self",
      "prefix"
    ],
    "_debugging_get_buffer": [
      "self",
      "prefix"
    ],
    "set_Fn_buffer": [
      "self",
      "buffer",
      "prefix"
    ],
    "get_Fn_buffer": [
      "self",
      "prefix"
    ],
    "set_Fn_encoder_buffer": [
      "self",
      "buffer",
      "prefix"
    ],
    "get_Fn_encoder_buffer": [
      "self",
      "prefix"
    ],
    "set_Bn_buffer": [
      "self",
      "buffer",
      "prefix"
    ],
    "get_Bn_buffer": [
      "self",
      "prefix"
    ],
    "set_Bn_encoder_buffer": [
      "self",
      "buffer",
      "prefix"
    ],
    "get_Bn_encoder_buffer": [
      "self",
      "prefix"
    ],
    "apply_cache": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "prefix",
      "encoder_prefix"
    ],
    "get_downsample_factor": [
      "self"
    ],
    "can_cache": [
      "self",
      "states_tensor",
      "parallelized",
      "threshold",
      "prefix"
    ]
  },
  "PrunedContextManager": {
    "__init__": [
      "self",
      "name"
    ],
    "new_context": [
      "self"
    ],
    "set_context": [
      "self",
      "cached_context"
    ],
    "get_context": [
      "self",
      "name"
    ],
    "reset_context": [
      "self",
      "cached_context"
    ],
    "add_pruned_step": [
      "self"
    ],
    "add_pruned_block": [
      "self",
      "num_blocks"
    ],
    "add_actual_block": [
      "self",
      "num_blocks"
    ],
    "get_pruned_steps": [
      "self"
    ],
    "get_cfg_pruned_steps": [
      "self"
    ],
    "get_pruned_blocks": [
      "self"
    ],
    "get_actual_blocks": [
      "self"
    ],
    "get_cfg_pruned_blocks": [
      "self"
    ],
    "get_cfg_actual_blocks": [
      "self"
    ],
    "get_non_prune_blocks_ids": [
      "self",
      "num_blocks"
    ],
    "can_prune": [
      "self"
    ],
    "apply_prune": [
      "self"
    ]
  },
  "DBPruneConfig": {
    "strify": [
      "self"
    ]
  },
  "BasicCacheConfig": {
    "update": [
      "self"
    ],
    "empty": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "as_dict": [
      "self"
    ],
    "strify": [
      "self"
    ]
  },
  "ExtraCacheConfig": {},
  "DBCacheConfig": {},
  "ContextManager": {
    "_supported_managers": [],
    "__new__": [
      "cls",
      "cache_type",
      "name",
      "persistent_context"
    ]
  },
  "CachedContext": {
    "__post_init__": [
      "self"
    ],
    "enable_calibrator": [
      "self"
    ],
    "enable_encoder_calibrator": [
      "self"
    ],
    "calibrator_cache_type": [
      "self"
    ],
    "has_calibrators": [
      "self"
    ],
    "get_residual_diff_threshold": [
      "self"
    ],
    "get_buffer": [
      "self",
      "name"
    ],
    "set_buffer": [
      "self",
      "name",
      "buffer"
    ],
    "remove_buffer": [
      "self",
      "name"
    ],
    "clear_buffers": [
      "self"
    ],
    "mark_step_begin": [
      "self"
    ],
    "get_calibrators": [
      "self"
    ],
    "get_cfg_calibrators": [
      "self"
    ],
    "add_residual_diff": [
      "self",
      "diff"
    ],
    "get_residual_diffs": [
      "self"
    ],
    "get_cfg_residual_diffs": [
      "self"
    ],
    "get_accumulated_residual_diff": [
      "self"
    ],
    "get_cfg_accumulated_residual_diff": [
      "self"
    ],
    "add_cached_step": [
      "self"
    ],
    "get_cached_steps": [
      "self"
    ],
    "get_cfg_cached_steps": [
      "self"
    ],
    "get_current_step": [
      "self"
    ],
    "get_current_transformer_step": [
      "self"
    ],
    "get_force_refresh_step_hint": [
      "self"
    ],
    "is_separate_cfg_step": [
      "self"
    ],
    "warmup_steps": [
      "self"
    ],
    "is_in_warmup": [
      "self"
    ],
    "is_in_full_compute_steps": [
      "self"
    ],
    "get_steps_computation_policy": [
      "self"
    ]
  },
  "CalibratorBase": {
    "reset_cache": [
      "self"
    ],
    "approximate": [
      "self"
    ],
    "mark_step_begin": [
      "self"
    ],
    "update": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "CalibratorConfig": {
    "strify": [
      "self"
    ],
    "to_kwargs": [
      "self"
    ],
    "as_dict": [
      "self"
    ],
    "update": [
      "self"
    ],
    "empty": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "TaylorSeerCalibratorConfig": {
    "strify": [
      "self"
    ],
    "to_kwargs": [
      "self"
    ]
  },
  "FoCaCalibratorConfig": {
    "strify": [
      "self"
    ]
  },
  "Calibrator": {
    "_supported_calibrators": [],
    "__new__": [
      "cls",
      "calibrator_config"
    ]
  },
  "FoCaCalibrator": {
    "__init__": [
      "self"
    ],
    "reset_cache": [
      "self"
    ],
    "approximate": [
      "self"
    ],
    "mark_step_begin": [
      "self"
    ],
    "update": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "TaylorSeerState": {
    "__init__": [
      "self",
      "n_derivatives",
      "max_warmup_steps",
      "skip_interval_steps"
    ],
    "reset": [
      "self"
    ],
    "mark_step_begin": [
      "self"
    ],
    "should_compute": [
      "self",
      "step"
    ],
    "derivative": [
      "self",
      "Y"
    ],
    "approximate": [
      "self"
    ],
    "update": [
      "self",
      "Y"
    ],
    "step": [
      "self",
      "Y"
    ]
  },
  "TaylorSeerCalibrator": {
    "__init__": [
      "self",
      "n_derivatives",
      "max_warmup_steps",
      "skip_interval_steps"
    ],
    "reset_cache": [
      "self"
    ],
    "maybe_init_state": [
      "self",
      "name"
    ],
    "mark_step_begin": [
      "self"
    ],
    "derivative": [
      "self",
      "Y",
      "name"
    ],
    "approximate": [
      "self",
      "name"
    ],
    "update": [
      "self",
      "Y",
      "name"
    ],
    "step": [
      "self",
      "Y",
      "name"
    ],
    "__repr__": [
      "self"
    ]
  },
  "CachedBlocks_Pattern_0_1_2": {
    "_supported_patterns": []
  },
  "PrunedBlocks_Pattern_0_1_2": {
    "_supported_patterns": []
  },
  "UnifiedBlocks": {
    "__new__": [
      "cls",
      "transformer_blocks",
      "transformer",
      "forward_pattern",
      "check_forward_pattern",
      "check_num_outputs",
      "cache_prefix",
      "cache_context",
      "context_manager",
      "cache_type"
    ]
  },
  "CachedBlocks": {
    "__new__": [
      "cls",
      "transformer_blocks",
      "transformer",
      "forward_pattern",
      "check_forward_pattern",
      "check_num_outputs",
      "cache_prefix",
      "cache_context",
      "context_manager",
      "cache_type"
    ]
  },
  "PrunedBlocks": {
    "__new__": [
      "cls",
      "transformer_blocks",
      "transformer",
      "forward_pattern",
      "check_forward_pattern",
      "check_num_outputs",
      "cache_prefix",
      "cache_context",
      "context_manager",
      "cache_type"
    ]
  },
  "apply_stats": [
    "module",
    "cache_context",
    "context_manager"
  ],
  "remove_stats": [
    "module"
  ],
  "CachedBlocks_Pattern_3_4_5": {
    "_supported_patterns": [],
    "call_blocks": [
      "self",
      "hidden_states"
    ],
    "_process_block_outputs": [
      "self",
      "hidden_states"
    ],
    "_process_forward_outputs": [
      "self",
      "hidden_states",
      "new_encoder_hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "call_Fn_blocks": [
      "self",
      "hidden_states"
    ],
    "call_Mn_blocks": [
      "self",
      "hidden_states"
    ],
    "call_Bn_blocks": [
      "self",
      "hidden_states"
    ]
  },
  "PrunedBlocks_Pattern_3_4_5": {
    "_supported_patterns": [],
    "__init__": [
      "self",
      "transformer_blocks",
      "transformer",
      "forward_pattern",
      "check_forward_pattern",
      "check_num_outputs",
      "cache_prefix",
      "cache_context",
      "context_manager",
      "cache_type"
    ],
    "_check_cache_type": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "num_blocks": [
      "self"
    ],
    "_skip_prune": [
      "self",
      "block_id"
    ],
    "_maybe_prune": [
      "self",
      "block_id",
      "hidden_states",
      "prefix"
    ],
    "compute_or_prune": [
      "self",
      "block_id",
      "block",
      "hidden_states",
      "new_encoder_hidden_states"
    ]
  },
  "maybe_onload": [
    "block",
    "reference_tensor",
    "pending_tasks"
  ],
  "get_event_loop": [],
  "maybe_offload": [
    "pending_tasks"
  ],
  "CachedBlocks_Pattern_Base": {
    "_supported_patterns": [],
    "__init__": [
      "self",
      "transformer_blocks",
      "transformer",
      "forward_pattern",
      "check_forward_pattern",
      "check_num_outputs",
      "cache_prefix",
      "cache_context",
      "context_manager",
      "cache_type"
    ],
    "_check_forward_pattern": [
      "self"
    ],
    "_check_cache_type": [
      "self"
    ],
    "_check_cache_params": [
      "self"
    ],
    "call_blocks": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ],
    "_process_block_outputs": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ],
    "_process_forward_outputs": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ],
    "_check_if_context_parallel_enabled": [
      "self",
      "module"
    ],
    "_get_Fn_residual": [
      "self",
      "original_hidden_states",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ],
    "_is_parallelized": [
      "self"
    ],
    "_is_in_cache_step": [
      "self"
    ],
    "_Fn_blocks": [
      "self"
    ],
    "_Mn_blocks": [
      "self"
    ],
    "_Bn_blocks": [
      "self"
    ],
    "call_Fn_blocks": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ],
    "call_Mn_blocks": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ],
    "call_Bn_blocks": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ]
  },
  "PrunedBlocks_Pattern_Base": {
    "__init__": [
      "self",
      "transformer_blocks",
      "transformer",
      "forward_pattern",
      "check_forward_pattern",
      "check_num_outputs",
      "cache_prefix",
      "cache_context",
      "context_manager",
      "cache_type"
    ],
    "_check_cache_type": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ],
    "num_blocks": [
      "self"
    ],
    "_skip_prune": [
      "self",
      "block_id"
    ],
    "_maybe_prune": [
      "self",
      "block_id",
      "hidden_states",
      "prefix"
    ],
    "compute_or_prune": [
      "self",
      "block_id",
      "block",
      "hidden_states",
      "encoder_hidden_states"
    ]
  },
  "_check_diffusers_cp_support": [],
  "ParallelismBackend": {
    "AUTO": [],
    "NATIVE_DIFFUSER": [],
    "NATIVE_PYTORCH": [],
    "NATIVE_HYBRID": [],
    "NONE": [],
    "is_supported": [
      "cls",
      "backend"
    ],
    "from_str": [
      "cls",
      "backend_str"
    ],
    "__str__": [
      "self"
    ]
  },
  "ParallelismConfig": {
    "__post_init__": [
      "self"
    ],
    "_maybe_init_hybrid_meshes": [
      "self"
    ],
    "enabled": [
      "self"
    ],
    "cp_enabled": [
      "self"
    ],
    "tp_enabled": [
      "self"
    ],
    "usp_enabled": [
      "self"
    ],
    "hybrid_enabled": [
      "self"
    ],
    "strify": [
      "self",
      "details",
      "text_encoder",
      "vae",
      "controlnet"
    ],
    "_get_world_size": [
      "self"
    ],
    "text_encoder_world_size": [
      "self"
    ],
    "auto_encoder_world_size": [
      "self"
    ],
    "vae_world_size": [
      "self"
    ],
    "controlnet_world_size": [
      "self"
    ]
  },
  "enable_parallelism": [
    "transformer",
    "parallelism_config"
  ],
  "remove_parallelism_stats": [
    "module"
  ],
  "_maybe_set_module_attention_backend": [
    "module",
    "parallelism_config"
  ],
  "_is_text_encoder": [
    "module"
  ],
  "_is_controlnet": [
    "module"
  ],
  "_is_auto_encoder": [
    "module"
  ],
  "_is_parallelized": [
    "module"
  ],
  "maybe_enable_parallelism_for_transformer": [
    "transformer",
    "parallelism_config"
  ],
  "maybe_enable_hybrid_parallelism_for_transformer": [
    "transformer",
    "parallelism_config"
  ],
  "maybe_enable_context_parallelism_for_transformer": [
    "transformer",
    "parallelism_config"
  ],
  "maybe_enable_tensor_parallelism_for_transformer": [
    "transformer",
    "parallelism_config"
  ],
  "PixArtContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "__patch_Attention_prepare_attention_mask__": [
    "self",
    "attention_mask",
    "target_length",
    "batch_size",
    "out_dim",
    "head_size"
  ],
  "__patch_AttnProcessor2_0__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "temb"
  ],
  "DiTContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "HunyuanImageContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "__patch__HunyuanImageTransformer2DModel_forward__": [
    "self",
    "hidden_states",
    "timestep",
    "encoder_hidden_states",
    "encoder_attention_mask",
    "timestep_r",
    "encoder_hidden_states_2",
    "encoder_attention_mask_2",
    "guidance",
    "attention_kwargs",
    "return_dict"
  ],
  "HunyuanVideoContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "__patch__HunyuanVideoTransformer3DModel_forward__": [
    "self",
    "hidden_states",
    "timestep",
    "encoder_hidden_states",
    "encoder_attention_mask",
    "pooled_projections",
    "guidance",
    "attention_kwargs",
    "return_dict"
  ],
  "__patch_HunyuanVideoAttnProcessor2_0__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "image_rotary_emb"
  ],
  "LongCatImageContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "LTXVideoContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "__patch__LTXAttention_prepare_attention_mask__": [
    "self",
    "attention_mask",
    "target_length",
    "batch_size",
    "out_dim",
    "head_size"
  ],
  "__patch__LTXVideoAttnProcessor__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "image_rotary_emb"
  ],
  "ZImageContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "_ulysses_attn_with_async_qkv_proj_zimage": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "freqs_cis"
  ],
  "ZSingleStreamAttnProcessor_original__call__": [],
  "__patch_ZSingleStreamAttnProcessor_ulysses_async__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "freqs_cis"
  ],
  "ChromaContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "Kandinsky5ContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "Flux2ContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "SkyReelsV2ContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "LTX2ContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "__patch__LTX2Attention_prepare_attention_mask__": [
    "self",
    "attention_mask",
    "target_length",
    "batch_size",
    "out_dim",
    "head_size"
  ],
  "__patch__LTX2AudioVideoAttnProcessor__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "query_rotary_emb",
    "key_rotary_emb"
  ],
  "CogVideoXContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "__patch_CogVideoXAttnProcessor2_0__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "image_rotary_emb"
  ],
  "ImportErrorContextParallelismPlanner": {
    "plan": [
      "self",
      "transformer"
    ]
  },
  "_activate_cp_planners": [],
  "CogView3PlusContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "CogView4ContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "__patch_CogView4AttnProcessor__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "image_rotary_emb"
  ],
  "maybe_enable_context_parallelism": [
    "transformer",
    "parallelism_config"
  ],
  "_maybe_patch_native_parallel_config": [
    "transformer"
  ],
  "FluxContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "_ulysses_attn_with_async_qkv_proj_flux": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "image_rotary_emb"
  ],
  "FluxAttnProcessor_original__call__": [],
  "__patch_FluxAttnProcessor_ulysses_async__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "image_rotary_emb"
  ],
  "__patch_FluxSingleTransformerBlock_ulysses_async_forward__": [
    "self",
    "hidden_states",
    "encoder_hidden_states",
    "temb",
    "image_rotary_emb",
    "joint_attention_kwargs"
  ],
  "CosisIDContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "NunchakuFluxContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "__patch_NunchakuFluxFA2Processor__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "image_rotary_emb"
  ],
  "NunchakuQwenImageContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "__patch_NunchakuQwenImageNaiveFA2Processor__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "encoder_hidden_states_mask",
    "attention_mask",
    "image_rotary_emb"
  ],
  "NunchakuZImageContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "ChronoEditContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "__patch_ChronoEditWanAttnProcessor__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "rotary_emb"
  ],
  "QwenImageContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "_ulysses_attn_with_async_qkv_proj_qwen_image": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "encoder_hidden_states_mask",
    "attention_mask",
    "image_rotary_emb"
  ],
  "QwenDoubleStreamAttnProcessor2_0_original__call__": [],
  "__patch_QwenDoubleStreamAttnProcessor2_0_ulysses_async__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "encoder_hidden_states_mask",
    "attention_mask",
    "image_rotary_emb"
  ],
  "ContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "ContextParallelismPlannerRegister": {
    "register": [
      "cls",
      "name"
    ],
    "get_planner": [
      "cls",
      "transformer"
    ],
    "supported_planners": [
      "cls"
    ]
  },
  "OvisImageContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "_ulysses_attn_with_async_qkv_proj_ovis_image": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "image_rotary_emb"
  ],
  "OvisImageAttnProcessor_original__call__": [],
  "__patch_OvisImageAttnProcessor_ulysses_async__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "image_rotary_emb"
  ],
  "__patch_OvisImageSingleTransformerBlock_ulysses_async_forward__": [
    "self",
    "hidden_states",
    "encoder_hidden_states",
    "temb",
    "image_rotary_emb",
    "joint_attention_kwargs"
  ],
  "WanContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "__patch_WanAttnProcessor__call__": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "rotary_emb"
  ],
  "WanVACEContextParallelismPlanner": {
    "apply": [
      "self",
      "transformer"
    ]
  },
  "TensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "mesh": [
      "self",
      "parallelism_config"
    ]
  },
  "TensorParallelismPlannerRegister": {
    "register": [
      "cls",
      "name"
    ],
    "get_planner": [
      "cls",
      "transformer"
    ],
    "supported_planners": [
      "cls"
    ]
  },
  "QwenImageTensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "Flux2TensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "rerangege_swiglu_weight": [
      "cls",
      "weight",
      "tp_size"
    ],
    "rearrange_feedforward_weight": [
      "cls",
      "block",
      "tp_size"
    ],
    "rearrange_singleblock_weight": [
      "cls",
      "block",
      "tp_size"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "Kandinsky5TensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "SplitFreqsProcessor": {
    "__init__": [
      "self",
      "processor",
      "tp_size",
      "tp_rank"
    ],
    "from_mochi_processor": [
      "cls",
      "processor",
      "tp_size",
      "tp_rank"
    ],
    "__call__": [
      "self"
    ]
  },
  "MochiTensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "rearrange_feedforward_weight": [
      "block",
      "tp_size"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "LongCatImageTensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "CogViewTensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "ZImageTensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "_divisors": [
    "n"
  ],
  "shard_divisible_attr": [
    "obj",
    "attr",
    "tp_size"
  ],
  "FluxTensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "maybe_enable_tensor_parallelism": [
    "transformer",
    "parallelism_config"
  ],
  "DistributedRMSNorm": {
    "__init__": [
      "self",
      "tp_mesh",
      "normalized_shape",
      "eps",
      "elementwise_affine",
      "weight"
    ],
    "from_rmsnorm": [
      "cls",
      "tp_mesh",
      "rmsnorm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanTensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "GlmImageTensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "ShardRotaryEmbProcessor": {
    "__init__": [
      "self",
      "processor",
      "tp_size",
      "tp_rank"
    ],
    "from_attn_processor": [
      "cls",
      "processor",
      "tp_size",
      "tp_rank"
    ],
    "_shard_rope": [
      "self",
      "emb"
    ],
    "__call__": [
      "self",
      "attn",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "query_rotary_emb",
      "key_rotary_emb"
    ]
  },
  "LTX2VideoTensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "PixArtTensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "HunyuanDiTTensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "SkyReelsV2TensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "OvisImageTensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "rearrange_proj_out_weight": [
    "single_block",
    "tp_group_size"
  ],
  "rearrange_proj_mlp_weight": [
    "single_block",
    "tp_group_size"
  ],
  "rearrange_ffn_0_swiglu_proj_weight": [
    "proj",
    "tp_group_size"
  ],
  "ImportErrorTensorParallelismPlanner": {
    "plan": [
      "self",
      "transformer"
    ]
  },
  "_activate_tp_planners": [],
  "LTXVideoTensorParallelismPlanner": {
    "apply": [
      "self",
      "transformer",
      "parallelism_config"
    ],
    "parallelize_transformer": [
      "self",
      "transformer",
      "tp_mesh"
    ]
  },
  "maybe_enable_parallelism_for_auto_encoder": [
    "auto_encoder",
    "parallelism_config"
  ],
  "AutoEncoderDataParallelismPlanner": {
    "apply": [
      "self",
      "auto_encoder",
      "parallelism_config"
    ],
    "mesh": [
      "self",
      "parallelism_config"
    ]
  },
  "AutoEncoderDataParallelismPlannerRegister": {
    "register": [
      "cls",
      "name"
    ],
    "get_planner": [
      "cls",
      "auto_encoder"
    ],
    "supported_planners": [
      "cls"
    ]
  },
  "AutoencoderKLQwenImageDataParallelismPlanner": {
    "apply": [
      "self",
      "auto_encoder",
      "parallelism_config"
    ],
    "parallelize_tiling": [
      "self",
      "auto_encoder",
      "dp_mesh"
    ]
  },
  "AutoencoderKLHunyuanVideoDataParallelismPlanner": {
    "apply": [
      "self",
      "auto_encoder",
      "parallelism_config"
    ],
    "parallelize_tiling": [
      "self",
      "auto_encoder",
      "dp_mesh"
    ]
  },
  "TileBatchedP2PComm": {
    "__init__": [
      "self"
    ],
    "set_dims": [
      "self",
      "dims"
    ],
    "set_shape": [
      "self",
      "shape"
    ],
    "clear_dims": [
      "self"
    ],
    "clear_shape": [
      "self"
    ],
    "send_shape": [
      "self",
      "tensor",
      "dst",
      "group"
    ],
    "recv_shape": [
      "self",
      "src",
      "group"
    ],
    "send_tensor": [
      "self",
      "tensor",
      "dst",
      "group"
    ],
    "recv_tensor": [
      "self",
      "src",
      "group",
      "device",
      "dtype"
    ],
    "commit": [
      "self"
    ],
    "wait": [
      "self"
    ],
    "sync": [
      "self"
    ]
  },
  "AutoencoderKLWanDataParallelismPlanner": {
    "apply": [
      "self",
      "auto_encoder",
      "parallelism_config"
    ],
    "parallelize_tiling": [
      "self",
      "auto_encoder",
      "dp_mesh"
    ]
  },
  "maybe_enable_data_parallelism": [
    "auto_encoder",
    "parallelism_config"
  ],
  "AutoencoderKLFlux2DataParallelismPlanner": {
    "apply": [
      "self",
      "auto_encoder",
      "parallelism_config"
    ],
    "parallelize_tiling": [
      "self",
      "auto_encoder",
      "dp_mesh"
    ]
  },
  "ImportErrorAutoEncoderDataParallelismPlanner": {
    "plan": [
      "self",
      "auto_encoder"
    ]
  },
  "_activate_auto_encoder_dp_planners": [],
  "AutoencoderKLDataParallelismPlanner": {
    "apply": [
      "self",
      "auto_encoder",
      "parallelism_config"
    ],
    "parallelize_tiling": [
      "self",
      "auto_encoder",
      "dp_mesh"
    ]
  },
  "AutoencoderKLLTX2VideoDataParallelismPlanner": {
    "apply": [
      "self",
      "auto_encoder",
      "parallelism_config"
    ],
    "parallelize_tiling": [
      "self",
      "auto_encoder",
      "dp_mesh"
    ]
  },
  "maybe_enable_parallelism_for_text_encoder": [
    "text_encoder",
    "parallelism_config"
  ],
  "_supported_gemma_classes": [],
  "GemmaTensorParallelismPlanner": {
    "apply": [
      "self",
      "text_encoder",
      "parallelism_config"
    ],
    "parallelize_text_encoder": [
      "self",
      "text_encoder",
      "tp_mesh"
    ]
  },
  "TextEncoderTensorParallelismPlanner": {
    "apply": [
      "self",
      "text_encoder",
      "parallelism_config"
    ],
    "mesh": [
      "self",
      "parallelism_config"
    ]
  },
  "TextEncoderTensorParallelismPlannerRegister": {
    "register": [
      "cls",
      "name"
    ],
    "get_planner": [
      "cls",
      "text_encoder"
    ],
    "supported_planners": [
      "cls"
    ]
  },
  "T5EncoderTensorParallelismPlanner": {
    "apply": [
      "self",
      "text_encoder",
      "parallelism_config"
    ],
    "parallelize_text_encoder": [
      "self",
      "text_encoder",
      "tp_mesh"
    ]
  },
  "_supported_mistral_classes": [],
  "MistralTensorParallelismPlanner": {
    "apply": [
      "self",
      "text_encoder",
      "parallelism_config"
    ],
    "parallelize_text_encoder": [
      "self",
      "text_encoder",
      "tp_mesh"
    ]
  },
  "LlamaTensorParallelismPlanner": {
    "apply": [
      "self",
      "text_encoder",
      "parallelism_config"
    ],
    "parallelize_text_encoder": [
      "self",
      "text_encoder",
      "tp_mesh"
    ]
  },
  "_supported_glm_classes": [],
  "GlmTensorParallelismPlanner": {
    "apply": [
      "self",
      "text_encoder",
      "parallelism_config"
    ],
    "parallelize_text_encoder": [
      "self",
      "text_encoder",
      "tp_mesh"
    ]
  },
  "UMT5EncoderTensorParallelismPlanner": {
    "apply": [
      "self",
      "text_encoder",
      "parallelism_config"
    ],
    "parallelize_text_encoder": [
      "self",
      "text_encoder",
      "tp_mesh"
    ]
  },
  "Qwen3TensorParallelismPlanner": {
    "apply": [
      "self",
      "text_encoder",
      "parallelism_config"
    ],
    "parallelize_text_encoder": [
      "self",
      "text_encoder",
      "tp_mesh"
    ]
  },
  "ImportErrorTextEncoderTensorParallelismPlanner": {
    "plan": [
      "self",
      "text_encoder"
    ]
  },
  "_activate_text_encoder_tp_planners": [],
  "Qwen2_5_VLTensorParallelismPlanner": {
    "apply": [
      "self",
      "text_encoder",
      "parallelism_config"
    ],
    "parallelize_text_encoder": [
      "self",
      "text_encoder",
      "tp_mesh"
    ]
  },
  "MAX_TOKEN": [],
  "_registry_pop_attn_backend": [
    "attn_backend"
  ],
  "_set_new_attn_backend": [
    "member",
    "value"
  ],
  "_wait_tensor": [
    "tensor"
  ],
  "_get_rank_world_size": [
    "group"
  ],
  "_gather_size_by_comm": [
    "size",
    "group"
  ],
  "_split_head_sizes": [
    "H",
    "group"
  ],
  "_maybe_pad_qkv_head": [
    "x",
    "H",
    "group"
  ],
  "_maybe_unpad_qkv_head": [
    "x",
    "H_PAD",
    "group"
  ],
  "_maybe_pad_o_head": [
    "x",
    "H",
    "group"
  ],
  "_maybe_unpad_o_head": [
    "x",
    "H_PAD",
    "group"
  ],
  "_prepare_ulysses_comm_metadata": [
    "query"
  ],
  "_all_to_all_single_qkv_async": [
    "x",
    "group"
  ],
  "_all_to_all_single_o_async": [
    "x",
    "group"
  ],
  "_all_to_all_single_qkv_uneven_heads_async": [
    "x",
    "group"
  ],
  "_all_to_all_single_o_uneven_heads_async": [
    "x",
    "group"
  ],
  "_all_to_all_single_qkv_fp8_async": [
    "x",
    "group"
  ],
  "_all_to_all_single_o_fp8_async": [
    "x",
    "group"
  ],
  "_all_to_all_single_any_qkv_async": [
    "x",
    "group"
  ],
  "_all_to_all_single_any_o_async": [
    "x",
    "group"
  ],
  "_all_to_all_single_any_qkv_fp8_async": [
    "x",
    "group"
  ],
  "_all_to_all_single_any_o_fp8_async": [
    "x",
    "group"
  ],
  "_unified_all_to_all_qkv_async_fn": [
    "fp8"
  ],
  "_unified_all_to_all_o_async_fn": [
    "fp8"
  ],
  "_ExtendedContextParallelConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "_enable_context_parallelism_ext": [
    "model"
  ],
  "UnifiedTemplatedUSPAttention": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "enable_gqa",
      "return_lse",
      "forward_op",
      "backward_op",
      "_parallel_config"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "_TemplatedUSPAttention": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "enable_gqa",
      "return_lse",
      "forward_op",
      "backward_op",
      "_parallel_config"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "_TemplatedUSPAttentionFloat8": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "enable_gqa",
      "return_lse",
      "forward_op",
      "backward_op",
      "_parallel_config"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "_maybe_register_custom_attn_backends": [],
  "UnifiedTemplatedRingAttention": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "enable_gqa",
      "return_lse",
      "forward_op",
      "backward_op",
      "_parallel_config"
    ]
  },
  "_TemplatedRingAllGatherAttention": {},
  "_RingBatchedP2PComm": {
    "__init__": [
      "self",
      "process_group"
    ],
    "send_recv": [
      "self",
      "to_send",
      "recv_tensor"
    ],
    "commit": [
      "self"
    ],
    "wait": [
      "self"
    ],
    "send_recv_kv": [
      "self",
      "k",
      "v",
      "k_buffer",
      "v_buffer"
    ],
    "batch_send_recv_kv": [
      "self",
      "k",
      "v",
      "kv_buffer"
    ]
  },
  "_TemplatedRingBatchedP2PAttention": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "enable_gqa",
      "return_lse",
      "forward_op",
      "backward_op",
      "_parallel_config"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "UnifiedTemplatedUlyssesAttention": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "enable_gqa",
      "return_lse",
      "forward_op",
      "backward_op",
      "_parallel_config"
    ]
  },
  "_TemplatedUlyssesAttention": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "enable_gqa",
      "return_lse",
      "forward_op",
      "backward_op",
      "_parallel_config"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "_TemplatedUlyssesAttentionUnEvenHeads": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "enable_gqa",
      "return_lse",
      "forward_op",
      "backward_op",
      "_parallel_config"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "_TemplatedUlyssesAttentionFloat8": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "enable_gqa",
      "return_lse",
      "forward_op",
      "backward_op",
      "_parallel_config"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "_TemplatedUlyssesAnythingAttention": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "enable_gqa",
      "return_lse",
      "forward_op",
      "backward_op",
      "_parallel_config"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "_TemplatedUlyssesAnythingAttentionFloat8": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "enable_gqa",
      "return_lse",
      "forward_op",
      "backward_op",
      "_parallel_config"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "_fill_gather_shapes": [
    "shape",
    "gather_dims",
    "dim",
    "world_size"
  ],
  "_all_gather_anything": [
    "tensor",
    "dim",
    "group"
  ],
  "AllGatherAnythingFunction": {
    "forward": [
      "ctx",
      "tensor",
      "dim",
      "group"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "shard_anything": [
    "cls",
    "tensor",
    "dim",
    "mesh"
  ],
  "unshard_anything": [
    "cls",
    "tensor",
    "dim",
    "mesh"
  ],
  "is_ulysses_heads_no_padding": [],
  "enable_ulysses_anything": [],
  "is_ulysses_anything_enabled": [],
  "disable_ulysses_anything": [],
  "_enable_ulysses_anything_float8": [],
  "_is_ulysses_anything_float8_enabled": [],
  "_disable_ulysses_anything_float8": [],
  "enable_ulysses_float8": [],
  "is_ulysses_float8_enabled": [],
  "disable_ulysses_float8": [],
  "maybe_enable_parallelism_for_controlnet": [
    "controlnet",
    "parallelism_config"
  ],
  "ZImageControlNetContextParallelismPlanner": {
    "apply": [
      "self",
      "controlnet"
    ]
  },
  "_ulysses_attn_with_async_qkv_proj_zimage_controlnet": [
    "self",
    "attn",
    "hidden_states",
    "encoder_hidden_states",
    "attention_mask",
    "freqs_cis"
  ],
  "_activate_controlnet_cp_planners": [],
  "ControlNetContextParallelismPlanner": {
    "apply": [
      "self",
      "controlnet"
    ]
  },
  "ControlNetContextParallelismPlannerRegister": {
    "register": [
      "cls",
      "name"
    ],
    "get_planner": [
      "cls",
      "controlnet"
    ],
    "supported_planners": [
      "cls"
    ]
  },
  "set_compile_configs": [
    "descent_tuning",
    "cuda_graphs",
    "force_disable_compile_caches",
    "fx_graph_cache",
    "fx_graph_remote_cache",
    "autotune_local_cache",
    "use_fast_math",
    "compute_comm_overlap",
    "capture_scalar_outputs",
    "capture_dynamic_output_shape_ops"
  ],
  "resolve_obj_by_qualname": [
    "qualname"
  ],
  "resolve_current_platform_cls_qualname": [],
  "__getattr__": [
    "name"
  ],
  "__setattr__": [
    "name",
    "value"
  ],
  "BasePlatform": {
    "empty_cache": [],
    "ipc_collect": [],
    "get_device_name": [],
    "device_ctx": [],
    "default_device": [],
    "synchronize": [],
    "device_count": [],
    "is_accelerator_available": [],
    "current_device": [],
    "reset_peak_memory_stats": [],
    "max_memory_allocated": [],
    "get_device_properties": [],
    "set_device": [],
    "get_device_capability": []
  },
  "CpuPlatform": {
    "device_control_env_var": [],
    "default_device": [],
    "get_device_name": [],
    "is_accelerator_available": []
  },
  "CudaPlatform": {
    "empty_cache": [],
    "ipc_collect": [],
    "get_device_name": [],
    "device_ctx": [
      "device"
    ],
    "default_device": [],
    "synchronize": [
      "device"
    ],
    "device_count": [],
    "is_accelerator_available": [],
    "current_device": [],
    "reset_peak_memory_stats": [
      "device"
    ],
    "max_memory_allocated": [
      "device"
    ],
    "get_device_properties": [
      "device"
    ],
    "set_device": [
      "device"
    ],
    "get_device_capability": [
      "device"
    ]
  },
  "NPUPlatform": {
    "empty_cache": [],
    "ipc_collect": [],
    "get_device_name": [],
    "device_ctx": [
      "device"
    ],
    "default_device": [],
    "synchronize": [
      "device"
    ],
    "device_count": [],
    "is_accelerator_available": [],
    "current_device": [],
    "reset_peak_memory_stats": [
      "device"
    ],
    "max_memory_allocated": [
      "device"
    ],
    "get_device_properties": [
      "device"
    ],
    "set_device": [
      "device"
    ]
  },
  "get_example_args": [],
  "_env_path_mapping": [],
  "_path_env_mapping": [],
  "_path": [
    "default",
    "args",
    "ENV",
    "lora",
    "controlnet",
    "transformer"
  ],
  "flux_example": [
    "args"
  ],
  "flux_fill_example": [
    "args"
  ],
  "_flux2_params_modifiers": [
    "args"
  ],
  "flux2_example": [
    "args"
  ],
  "flux2_klein_example": [
    "args"
  ],
  "flux2_klein_edit_example": [
    "args"
  ],
  "_qwen_light_scheduler": [],
  "_qwen_light_cache_config": [
    "args"
  ],
  "qwen_image_example": [
    "args"
  ],
  "qwen_image_edit_example": [
    "args"
  ],
  "qwen_image_controlnet_example": [
    "args"
  ],
  "qwen_image_layered_example": [
    "args"
  ],
  "skyreels_v2_example": [
    "args"
  ],
  "ltx2_t2v_example": [
    "args"
  ],
  "ltx2_i2v_example": [
    "args"
  ],
  "_wan_2_2_params_modifiers": [
    "args"
  ],
  "wan_example": [
    "args"
  ],
  "wan_i2v_example": [
    "args"
  ],
  "wan_vace_example": [
    "args"
  ],
  "ovis_image_example": [
    "args"
  ],
  "_zimage_turbo_steps_mask": [
    "args"
  ],
  "zimage_example": [
    "args"
  ],
  "zimage_controlnet_example": [
    "args"
  ],
  "longcat_image_example": [
    "args"
  ],
  "longcat_image_edit_example": [
    "args"
  ],
  "glm_image_example": [
    "args"
  ],
  "glm_image_edit_example": [
    "args"
  ],
  "ExampleType": {
    "T2V": [],
    "I2V": [],
    "T2I": [],
    "IE2I": [],
    "FLF2V": [],
    "VACE": []
  },
  "ExampleInputData": {
    "data": [
      "self",
      "args"
    ],
    "new_generator": [
      "self",
      "args"
    ],
    "summary": [
      "self",
      "args"
    ]
  },
  "ExampleOutputData": {
    "save": [
      "self",
      "args"
    ],
    "_default_save_path": [
      "self"
    ],
    "summary": [
      "self",
      "args"
    ]
  },
  "ExampleInitConfig": {
    "__post_init__": [
      "self"
    ],
    "get_pipe": [
      "self",
      "args"
    ],
    "summary": [
      "self",
      "args"
    ],
    "_custom_components_kwargs": [
      "self"
    ],
    "has_lora": [
      "self"
    ],
    "_pipeline_quantization_config": [
      "self",
      "args"
    ]
  },
  "_is_function_or_method": [
    "component"
  ],
  "Example": {
    "__init__": [
      "self",
      "args",
      "init_config",
      "input_data"
    ],
    "check_valid": [
      "self"
    ],
    "prepare_input_data": [
      "self"
    ],
    "run": [
      "self"
    ],
    "new_generator": [
      "self",
      "input_kwargs",
      "args"
    ]
  },
  "ExampleRegister": {
    "register": [
      "cls",
      "name",
      "default"
    ],
    "get_example": [
      "cls",
      "args",
      "name"
    ],
    "list_examples": [
      "cls"
    ],
    "get_default": [
      "cls",
      "name"
    ]
  },
  "MemoryTracker": {
    "__init__": [
      "self",
      "device"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "get_peak_memory_gb": [
      "self"
    ],
    "report": [
      "self"
    ]
  },
  "GiB": [],
  "get_base_args": [
    "parse"
  ],
  "maybe_postprocess_args": [
    "args"
  ],
  "get_text_encoder_from_pipe": [
    "pipe"
  ],
  "prepare_extra_parallel_modules": [
    "args",
    "pipe_or_adapter",
    "custom_extra_modules"
  ],
  "maybe_compile_text_encoder": [
    "args",
    "pipe_or_adapter"
  ],
  "maybe_compile_controlnet": [
    "args",
    "pipe_or_adapter"
  ],
  "maybe_compile_vae": [
    "args",
    "pipe_or_adapter"
  ],
  "maybe_compile_transformer": [
    "args",
    "pipe_or_adapter"
  ],
  "maybe_quantize_transformer": [
    "args",
    "pipe_or_adapter"
  ],
  "maybe_quantize_text_encoder": [
    "args",
    "pipe_or_adapter"
  ],
  "maybe_quantize_controlnet": [
    "args",
    "pipe_or_adapter"
  ],
  "pipe_quant_bnb_4bit_config": [
    "args",
    "components_to_quantize"
  ],
  "maybe_vae_tiling_or_slicing": [
    "args",
    "pipe_or_adapter"
  ],
  "maybe_cpu_offload": [
    "args",
    "pipe_or_adapter"
  ],
  "maybe_apply_optimization": [
    "args",
    "pipe_or_adapter"
  ],
  "get_rank_device": [],
  "maybe_init_distributed": [
    "args"
  ],
  "maybe_destroy_distributed": [],
  "create_profiler_from_args": [
    "args",
    "profile_name"
  ],
  "import_error_example": [],
  "load_pipeline_quant_config": [
    "pipeline_quant_config_path"
  ],
  "GenerateRequest": {
    "__repr__": [
      "self"
    ]
  },
  "GenerateResponse": {},
  "ModelManager": {
    "__init__": [
      "self",
      "model_path",
      "device",
      "generator_device",
      "torch_dtype",
      "enable_cache",
      "cache_config",
      "enable_cpu_offload",
      "device_map",
      "enable_compile",
      "parallel_type",
      "parallel_args",
      "attn_backend",
      "quantize",
      "quantize_type",
      "pipeline_quant_config_path",
      "lora_path",
      "lora_name",
      "fuse_lora"
    ],
    "startup_warmup": [
      "self",
      "resolutions",
      "prompt"
    ],
    "load_model": [
      "self"
    ],
    "_warmup_if_needed": [
      "self",
      "width",
      "height",
      "prompt"
    ],
    "_load_images_from_urls": [
      "self",
      "image_urls"
    ],
    "_resolve_output_dir": [
      "self",
      "output_dir"
    ],
    "_save_image_to_dir": [
      "self",
      "image",
      "output_dir",
      "name"
    ],
    "_save_video_to_dir": [
      "self",
      "video_frames",
      "output_dir",
      "name",
      "fps"
    ],
    "generate": [
      "self",
      "request"
    ],
    "get_model_info": [
      "self"
    ]
  },
  "get_default_params_modifiers": [],
  "align_cache_config": [],
  "GenerateRequestAPI": {},
  "GenerateResponseAPI": {},
  "create_app": [
    "model_manager"
  ],
  "HEARTBEAT_INTERVAL": [],
  "HEARTBEAT_SIZE": [],
  "TPCoordinator": {
    "__init__": [
      "self",
      "model_manager",
      "rank",
      "world_size"
    ],
    "pipe": [
      "self"
    ],
    "get_model_info": [
      "self"
    ],
    "_start_heartbeat": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "generate": [
      "self",
      "request"
    ]
  },
  "run_tp_worker": [
    "model_manager",
    "rank"
  ],
  "parse_args": [],
  "launch_server": [
    "args"
  ]
}