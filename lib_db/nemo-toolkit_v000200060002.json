{
  "EXCLUSIONS": [],
  "get_top_comments": [
    "_data"
  ],
  "main": [],
  "__TEST_DATA_FILENAME": [],
  "__TEST_DATA_URL": [],
  "__TEST_DATA_SUBDIR": [],
  "pytest_addoption": [
    "parser"
  ],
  "device": [
    "request"
  ],
  "run_only_on_device_fixture": [
    "request",
    "device"
  ],
  "downloads_weights": [
    "request",
    "device"
  ],
  "run_nightly_test_for_qa": [
    "request",
    "device"
  ],
  "cleanup_local_folder": [],
  "reset_singletons": [],
  "reset_env_vars": [],
  "test_data_dir": [],
  "extract_data_from_tar": [
    "test_dir",
    "test_data_archive",
    "url",
    "local_data"
  ],
  "k2_is_appropriate": [],
  "k2_cuda_is_enabled": [
    "k2_is_appropriate"
  ],
  "pytest_configure": [
    "config"
  ],
  "testclass_downloads": [
    "cls",
    "refresh_cache",
    "model_names"
  ],
  "TestDataDir": {
    "test_test_data_dir": [
      "self",
      "test_data_dir"
    ]
  },
  "test_resolve_trainer_cfg_strategy": [],
  "TestEnvironmentVariableParsing": {
    "test_get_envint_returns_int_value": [
      "self"
    ],
    "test_get_envint_with_default": [
      "self"
    ],
    "test_get_envint_required_missing": [
      "self"
    ],
    "test_get_envint_coercion_error": [
      "self"
    ],
    "test_get_envint_negative_value": [
      "self"
    ],
    "test_get_envfloat_returns_float_value": [
      "self"
    ],
    "test_get_envfloat_with_integer_string": [
      "self"
    ],
    "test_get_envfloat_with_default": [
      "self"
    ],
    "test_get_envfloat_required_missing": [
      "self"
    ],
    "test_get_envfloat_coercion_error": [
      "self"
    ],
    "test_get_envfloat_scientific_notation": [
      "self"
    ],
    "test_get_envfloat_negative_value": [
      "self"
    ],
    "test_get_envbool_true_values": [
      "self"
    ],
    "test_get_envbool_false_values": [
      "self"
    ],
    "test_get_envbool_with_default": [
      "self"
    ],
    "test_get_envbool_required_missing": [
      "self"
    ],
    "test_get_envbool_non_boolean_value": [
      "self"
    ],
    "test_get_envdecimal_returns_decimal_value": [
      "self"
    ],
    "test_get_envdecimal_with_integer_string": [
      "self"
    ],
    "test_get_envdecimal_with_default": [
      "self"
    ],
    "test_get_envdecimal_required_missing": [
      "self"
    ],
    "test_get_envdecimal_coercion_error": [
      "self"
    ],
    "test_get_envdecimal_negative_value": [
      "self"
    ],
    "test_get_envdecimal_high_precision": [
      "self"
    ],
    "test_get_envdate_returns_date_value": [
      "self"
    ],
    "test_get_envdate_with_different_formats": [
      "self"
    ],
    "test_get_envdate_with_default": [
      "self"
    ],
    "test_get_envdate_required_missing": [
      "self"
    ],
    "test_get_envdate_coercion_error": [
      "self"
    ],
    "test_get_envdatetime_returns_datetime_value": [
      "self"
    ],
    "test_get_envdatetime_with_different_formats": [
      "self"
    ],
    "test_get_envdatetime_with_default": [
      "self"
    ],
    "test_get_envdatetime_required_missing": [
      "self"
    ],
    "test_get_envdatetime_coercion_error": [
      "self"
    ],
    "test_get_envdatetime_with_timezone": [
      "self"
    ],
    "test_get_envlist_returns_list_value": [
      "self"
    ],
    "test_get_envlist_with_custom_separator": [
      "self"
    ],
    "test_get_envlist_with_default": [
      "self"
    ],
    "test_get_envlist_required_missing": [
      "self"
    ],
    "test_get_envlist_empty_string": [
      "self"
    ],
    "test_get_envlist_multiple_words": [
      "self"
    ],
    "test_get_envdict_returns_dict_value": [
      "self"
    ],
    "test_get_envdict_with_default": [
      "self"
    ],
    "test_get_envdict_required_missing": [
      "self"
    ],
    "test_get_envdict_coercion_error": [
      "self"
    ],
    "test_get_envdict_complex_dict": [
      "self"
    ]
  },
  "test_is_multistorageclient_url_with_msc_not_installed": [],
  "test_is_multistorageclient_url_with_msc_installed": [],
  "TestDataUtils": {
    "test_resolve_cache_dir": [
      "self"
    ],
    "test_is_datastore_path": [
      "self"
    ],
    "test_bucket_and_object_from_uri": [
      "self"
    ],
    "test_ais_endpoint_to_dir": [
      "self"
    ],
    "test_ais_binary": [
      "self"
    ]
  },
  "ASRModelType": {
    "CTC": [],
    "RNNT": []
  },
  "TestPrettyStrEnum": {
    "test_incorrect_value": [
      "self"
    ],
    "test_correct_value": [
      "self"
    ],
    "test_str": [
      "self"
    ]
  },
  "flops_config": [],
  "test_gpt3": [
    "flops_config"
  ],
  "test_llama2": [
    "flops_config"
  ],
  "test_llama3": [
    "flops_config"
  ],
  "test_nemotron": [
    "flops_config"
  ],
  "test_mixtral": [
    "flops_config"
  ],
  "test_bert": [
    "flops_config"
  ],
  "test_hyena": [
    "flops_config"
  ],
  "test_transformer": [
    "flops_config"
  ],
  "test_transformer_no_moe": [
    "flops_config"
  ],
  "TestIsGlobalRankZero": {
    "setup_method": [
      "self"
    ],
    "test_default_behavior": [
      "self"
    ],
    "test_with_pytorch_rank_0": [
      "self"
    ],
    "test_with_pytorch_rank_nonzero": [
      "self"
    ],
    "test_with_slurm_rank_0": [
      "self"
    ],
    "test_with_slurm_rank_nonzero": [
      "self"
    ],
    "test_with_mpi_rank_0": [
      "self"
    ],
    "test_with_mpi_rank_nonzero": [
      "self"
    ],
    "test_with_node_rank_0_local_rank_0": [
      "self"
    ],
    "test_with_node_rank_0_local_rank_nonzero": [
      "self"
    ],
    "test_with_node_rank_nonzero": [
      "self"
    ],
    "test_with_group_rank_fallback": [
      "self"
    ],
    "test_env_var_precedence": [
      "self"
    ]
  },
  "TestGetRank": {
    "setup_method": [
      "self"
    ],
    "test_not_distributed": [
      "self",
      "mock_is_initialized"
    ],
    "test_distributed_not_global_rank_zero": [
      "self",
      "mock_dist_get_rank",
      "mock_is_initialized"
    ],
    "test_distributed_global_rank_zero": [
      "self",
      "mock_dist_get_rank",
      "mock_is_initialized"
    ]
  },
  "TestGetLastRank": {
    "test_not_distributed": [
      "self",
      "mock_is_initialized"
    ],
    "test_distributed": [
      "self",
      "mock_get_world_size",
      "mock_is_initialized"
    ]
  },
  "TestUnavailableMeta": {
    "test_metaclass_creation": [
      "self"
    ],
    "test_custom_error_message": [
      "self"
    ],
    "test_call_raises_error": [
      "self"
    ],
    "test_attribute_access_raises_error": [
      "self"
    ],
    "test_arithmetic_operations_raise_error": [
      "self"
    ],
    "test_comparison_operations_raise_error": [
      "self"
    ],
    "test_container_operations_raise_error": [
      "self"
    ],
    "test_descriptor_operations_raise_error": [
      "self"
    ]
  },
  "TestSafeImport": {
    "test_successful_import": [
      "self"
    ],
    "test_failed_import": [
      "self"
    ],
    "test_import_with_custom_message": [
      "self"
    ],
    "test_import_with_alternative": [
      "self"
    ],
    "test_unavailable_module_raises_error_when_used": [
      "self"
    ]
  },
  "TestSafeImportFrom": {
    "test_successful_import_from": [
      "self"
    ],
    "test_failed_import_from_nonexistent_module": [
      "self"
    ],
    "test_failed_import_from_nonexistent_symbol": [
      "self"
    ],
    "test_import_from_with_custom_message": [
      "self"
    ],
    "test_import_from_with_alternative": [
      "self"
    ],
    "test_fallback_module": [
      "self"
    ],
    "test_fallback_module_both_fail": [
      "self"
    ]
  },
  "TestRobustCopy": {
    "test_robust_copy_success": [
      "self",
      "tmp_path"
    ],
    "test_robust_copy_fallback": [
      "self",
      "tmp_path"
    ]
  },
  "parser": [],
  "args": [],
  "get_hf_model_class": [
    "hf_config"
  ],
  "create_hf_model": [
    "model_name_or_path",
    "output_dir",
    "config_updates",
    "overwrite"
  ],
  "Identity": {
    "__init__": [
      "self"
    ]
  },
  "WithCopy": {
    "copy": [
      "self"
    ]
  },
  "Optimizer": {
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "param_groups": [
      "self"
    ]
  },
  "OptimizerWrapper": {
    "__init_": [
      "self",
      "optimizer"
    ]
  },
  "DummyOptimizer": {
    "__init__": [
      "self"
    ],
    "unscale_grads": [
      "self"
    ],
    "step": [
      "self"
    ]
  },
  "Model": {
    "__init__": [
      "self",
      "prefix",
      "metadata"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "metadata"
    ]
  },
  "make_optimizer_state": [],
  "test_set_model_parallel_attributes": [],
  "test_init_parallel_ranks": [],
  "test_init_model_parallel": [
    "mock_mpu"
  ],
  "test_init_model_parallel_with_tp_pp_dp": [
    "mock_mpu"
  ],
  "test_optimizer_sharded_state_dict": [],
  "test_grad_scaler": [
    "mock_mpu"
  ],
  "_mpu_tp_2": [
    "mock_mpu"
  ],
  "DummyTokenizer": {
    "__init__": [
      "self"
    ]
  },
  "TestMegatronMixedPrecision": {
    "test_precision_plugin_fp8_passed": [
      "self"
    ],
    "test_precision_plugin_precision_params_override": [
      "self"
    ]
  },
  "TestMegatronParallel": {
    "mock_pipeline": [
      "self",
      "mocker"
    ],
    "mock_precision_plugin": [
      "self",
      "mocker"
    ],
    "mock_callbacks": [
      "self",
      "mocker"
    ],
    "mock_data_step": [
      "self",
      "mocker"
    ],
    "mock_forward_step": [
      "self",
      "mocker"
    ],
    "mock_loss_reduction": [
      "self",
      "mocker"
    ],
    "test_init_with_defaults": [
      "self",
      "mocker",
      "mock_pipeline"
    ],
    "test_init_with_custom_parameters": [
      "self",
      "mocker",
      "mock_pipeline",
      "mock_precision_plugin",
      "mock_callbacks",
      "mock_data_step",
      "mock_forward_step",
      "mock_loss_reduction"
    ]
  },
  "TestCallbackConnector": {
    "test_add_callbacks": [
      "self"
    ],
    "test_event": [
      "self"
    ],
    "test_add_connector": [
      "self"
    ],
    "test_contains": [
      "self"
    ],
    "test_add_count_callback": [
      "self"
    ],
    "test_event_trigger_with_count_callback": [
      "self"
    ]
  },
  "TestCallback": {
    "on_megatron_step_start": [
      "self"
    ],
    "on_megatron_microbatch_start": [
      "self"
    ]
  },
  "CountCallback": {
    "__init__": [
      "self"
    ],
    "on_megatron_step_start": [
      "self"
    ],
    "on_megatron_microbatch_start": [
      "self"
    ],
    "on_megatron_microbatch_callback": [
      "self"
    ],
    "on_megatron_microbatch_end": [
      "self"
    ],
    "on_megatron_reduce_microbatches_start": [
      "self"
    ],
    "on_megatron_reduce_microbatches_end": [
      "self"
    ],
    "on_megatron_log_step_end": [
      "self"
    ],
    "on_megatron_step_end": [
      "self"
    ]
  },
  "reconfigure_num_microbatches_calculator_manager": [],
  "VOCAB_PATH": [],
  "MERGES_PATH": [],
  "DATA_PATH": [],
  "EXP_DIR": [],
  "teardown": [
    "exp_dir"
  ],
  "ValidateOptStateRestoration": {
    "on_fit_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_load_checkpoint": [
      "self",
      "trainer",
      "pl_module",
      "checkpoint"
    ]
  },
  "ValidateOptStateScratchInit": {
    "on_fit_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "ValidateModelScratchInit": {
    "on_fit_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "ValidateModelRestoration": {
    "on_fit_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_load_checkpoint": [
      "self",
      "trainer",
      "pl_module",
      "checkpoint"
    ],
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "setup_data": [
    "mbs",
    "gbs",
    "seq_length"
  ],
  "make_model_optim": [
    "tokenizer",
    "mbs",
    "gbs",
    "seq_length"
  ],
  "run_train_from_scratch": [
    "mbs",
    "gbs",
    "num_dev"
  ],
  "run_resume_train": [
    "mbs",
    "gbs",
    "num_dev"
  ],
  "test_optim_state_restoration": [],
  "set_env": [],
  "load_dcp": [
    "ckpt_dir",
    "torch_tensor"
  ],
  "compare_ckpts": [
    "a",
    "b",
    "path"
  ],
  "setup_model_optim": [
    "log_dir",
    "n_steps",
    "tokenizer",
    "gbs",
    "mbs"
  ],
  "setup_trainer_and_logger": [
    "log_dir"
  ],
  "replace_first": [
    "x",
    "old",
    "new"
  ],
  "extract_model_keys": [
    "ckpt_keys"
  ],
  "prepend_exp_avg": [
    "model_keys"
  ],
  "prepend_exp_avg_sq": [
    "model_keys"
  ],
  "has_all_keys": [
    "ckpt_keys",
    "keys"
  ],
  "TestCkptStateRestoration": {
    "test_resume_optim_state": [
      "self",
      "tmp_path"
    ]
  },
  "trainer": [],
  "test_finetuning_module": [
    "mock_gpt_sft_dataset",
    "trainer"
  ],
  "test_dolly_module": [
    "mock_gpt_sft_dataset",
    "trainer"
  ],
  "test_squad_module": [
    "mock_gpt_sft_dataset",
    "trainer"
  ],
  "BASE_CHECKPOINT_DIR": [],
  "MockContext": {
    "__init__": [
      "self",
      "config"
    ],
    "run": [
      "self",
      "command"
    ]
  },
  "test_recipes_with_nemo_run": [
    "module",
    "recipe",
    "name",
    "tmpdir",
    "monkeypatch"
  ],
  "_get_strategy": [],
  "_get_last_checkpoint_dir": [
    "model",
    "suffix"
  ],
  "get_model_and_data": [
    "mbs",
    "gbs"
  ],
  "TestDistCkptIO": {
    "test_dist_ckpt_io_called_for_mcore_models": [
      "self",
      "tmp_path"
    ],
    "test_async_save_produces_same_checkpoints_as_sync": [
      "self",
      "tmp_path"
    ],
    "test_sharded_strategies": [
      "self"
    ]
  },
  "TestOneLoggerNeMoCallback": {
    "test_inheritance": [
      "self"
    ],
    "test_init_configures_provider": [
      "self",
      "mock_ptl_callback_init",
      "mock_on_app_start",
      "mock_config_class",
      "mock_get_config",
      "mock_provider"
    ]
  },
  "TestOneLoggerCallback": {
    "test_get_one_logger_init_config": [
      "self"
    ],
    "test_get_one_logger_init_config_no_slurm": [
      "self"
    ],
    "test_get_base_callback_config": [
      "self"
    ],
    "test_get_base_callback_config_with_checkpoint_callback": [
      "self"
    ],
    "test_get_base_callback_config_async_save": [
      "self"
    ],
    "test_get_base_callback_config_dict_strategy": [
      "self"
    ],
    "test_get_nemo_v1_callback_config": [
      "self"
    ],
    "test_get_nemo_v1_callback_config_bucket_batch_size": [
      "self"
    ],
    "test_get_nemo_v1_callback_config_fallback": [
      "self"
    ],
    "test_get_nemo_v2_callback_config": [
      "self"
    ],
    "test_get_nemo_v2_callback_config_uses_micro_when_global_missing": [
      "self"
    ],
    "test_get_nemo_v2_callback_config_no_data": [
      "self"
    ],
    "test_should_enable_for_current_rank_single_process": [
      "self"
    ],
    "test_should_enable_for_current_rank_distributed_rank0": [
      "self"
    ],
    "test_should_enable_for_current_rank_distributed_middle_rank": [
      "self"
    ],
    "test_update_config_v1": [
      "self",
      "mock_ptl_callback",
      "mock_on_app_start",
      "mock_config_class",
      "mock_get_config",
      "mock_telemetry_config_class",
      "mock_get_v1_config",
      "mock_provider"
    ],
    "test_update_config_v2": [
      "self",
      "mock_ptl_callback",
      "mock_on_app_start",
      "mock_config_class",
      "mock_get_config",
      "mock_telemetry_config_class",
      "mock_get_v2_config",
      "mock_provider"
    ],
    "test_update_config_unknown_version_defaults_to_v1": [
      "self",
      "mock_ptl_callback",
      "mock_on_app_start",
      "mock_config_class",
      "mock_get_config",
      "mock_telemetry_config_class",
      "mock_get_v1_config",
      "mock_provider"
    ],
    "test_update_config_v2_without_data": [
      "self",
      "mock_ptl_callback",
      "mock_on_app_start",
      "mock_config_class",
      "mock_get_config",
      "mock_telemetry_config_class",
      "mock_get_v2_config",
      "mock_provider"
    ],
    "test_update_config_v2_with_extra_kwargs": [
      "self",
      "mock_ptl_callback",
      "mock_on_app_start",
      "mock_config_class",
      "mock_get_config",
      "mock_telemetry_config_class",
      "mock_get_v2_config",
      "mock_provider"
    ],
    "test_export_all_symbols": [
      "self"
    ],
    "test_init_with_environment_variables": [
      "self",
      "mock_ptl_callback",
      "mock_on_app_start",
      "mock_config_class",
      "mock_get_config",
      "mock_provider"
    ],
    "test_update_config_with_empty_config": [
      "self",
      "mock_ptl_callback",
      "mock_on_app_start",
      "mock_config_class",
      "mock_get_config",
      "mock_telemetry_config_class",
      "mock_get_v1_config",
      "mock_provider"
    ],
    "test_callback_instantiation_without_mocks_raises_import_error": [
      "self"
    ],
    "test_init_provider_chain_calls": [
      "self",
      "mock_ptl_callback_init",
      "mock_on_app_start",
      "mock_config_class",
      "mock_get_config",
      "mock_provider"
    ]
  },
  "test_idempotent_path_append_path_no_suffix": [
    "base_dir"
  ],
  "test_ckpt_to_context_subdir": [
    "filepath"
  ],
  "test_ckpt_to_dir": [
    "filepath"
  ],
  "test_ckpt_to_weights_subdir": [
    "filepath"
  ],
  "TestNeMoLogger": {
    "trainer": [
      "self"
    ],
    "test_loggers": [
      "self"
    ],
    "test_explicit_log_dir": [
      "self",
      "trainer"
    ],
    "test_default_log_dir": [
      "self",
      "trainer"
    ],
    "test_custom_version": [
      "self",
      "trainer"
    ],
    "test_file_logging_setup": [
      "self",
      "trainer"
    ],
    "test_model_checkpoint_setup": [
      "self",
      "trainer"
    ],
    "test_resume": [
      "self",
      "trainer",
      "tmp_path"
    ]
  },
  "_fresh_group_module": [],
  "test_base_callback_noops_do_not_raise": [],
  "test_base_callback_is_ptl_callback": [],
  "test_callback_group_singleton_identity": [],
  "test_callback_group_update_config_fanout_and_attach": [
    "monkeypatch"
  ],
  "test_callback_group_dynamic_dispatch_calls_when_present": [],
  "test_callback_group_dynamic_dispatch_ignores_missing_methods": [],
  "test_hook_class_init_with_callbacks_wraps_and_emits": [
    "monkeypatch"
  ],
  "test_hook_class_init_with_callbacks_idempotent": [],
  "test_on_app_end_is_idempotent": [
    "monkeypatch"
  ],
  "test_auto_resume_get_weights_path": [],
  "test_auto_resume_get_context_path": [],
  "test_auto_resume_get_trainer_ckpt_path": [],
  "make_parser": [],
  "wrap_config": [
    "config",
    "trainer"
  ],
  "make_byzantine_model_wrapper": [
    "model",
    "trainer"
  ],
  "test_failing": [
    "trainer",
    "ddp_parity",
    "optim",
    "data",
    "tokenizer"
  ],
  "test_working": [
    "trainer",
    "ddp_parity",
    "optim",
    "data",
    "tokenizer"
  ],
  "make_trainer_optim": [
    "args"
  ],
  "TestConversion": {
    "test_ddp_strategy_conversion": [
      "self"
    ],
    "test_fsdp_strategy_conversion": [
      "self"
    ],
    "test_mixed_precision_plugin_conversion": [
      "self"
    ],
    "test_fsdp_precision_plugin_conversion": [
      "self"
    ],
    "test_unsupported_object_conversion": [
      "self"
    ],
    "test_megatron_strategy_conversion": [
      "self"
    ],
    "test_megatron_precision_conversion": [
      "self"
    ]
  },
  "DummyClass": {
    "__init__": [
      "self",
      "a",
      "b"
    ]
  },
  "TestIOMixin": {
    "test_reinit": [
      "self"
    ],
    "test_init": [
      "self"
    ]
  },
  "TestStateDictTransform": {
    "mock_ctx": [
      "self"
    ],
    "mock_multi_target_ctx": [
      "self"
    ],
    "test_transform_with_single_source_single_target": [
      "self",
      "mock_ctx"
    ],
    "test_transform_with_multiple_sources": [
      "self",
      "mock_ctx"
    ],
    "test_transform_with_multiple_mapped_sources": [
      "self",
      "mock_ctx"
    ],
    "test_transform_with_variable_arguments": [
      "self",
      "mock_ctx"
    ],
    "test_transform_with_no_matching_source": [
      "self",
      "mock_ctx"
    ],
    "test_transform_with_multiple_targets": [
      "self",
      "mock_multi_target_ctx"
    ],
    "test_transform_with_multiple_sources_multiple_wildcards": [
      "self",
      "mock_ctx"
    ],
    "test_transform_with_multiple_targets_multiple_wildcards": [
      "self",
      "mock_multi_target_ctx"
    ],
    "test_transform_with_no_matching_target": [
      "self",
      "mock_ctx"
    ],
    "test_transform_with_invalid_transform_function": [
      "self",
      "mock_ctx"
    ]
  },
  "TestStateTransformDecorator": {
    "mock_ctx": [
      "self"
    ],
    "test_single_transform": [
      "self",
      "mock_ctx"
    ],
    "test_multiple_outputs_transform": [
      "self",
      "mock_ctx"
    ]
  },
  "single_transform": [
    "ctx",
    "x"
  ],
  "multiple_outputs_transform": [
    "ctx"
  ],
  "ARTIFACTS_DIR": [],
  "dummy_extra": [
    "a",
    "b",
    "c"
  ],
  "partial_function_with_pos_and_key_args": [],
  "TestLoad": {
    "test_reload_ckpt": [
      "self",
      "mock_update_one_logger",
      "tmpdir",
      "partial_function_with_pos_and_key_args"
    ]
  },
  "mock_model": [],
  "checkpoint_io": [
    "mock_model",
    "tmp_path"
  ],
  "adapter_checkpoint_io": [
    "mock_model",
    "tmp_path"
  ],
  "save_and_load_checkpoint": [
    "checkpoint_io",
    "checkpoint",
    "path",
    "adapter_only"
  ],
  "test_save_and_load_checkpoint": [
    "checkpoint_io",
    "tmp_path"
  ],
  "test_save_and_load_checkpoint_adapter_only": [
    "adapter_checkpoint_io",
    "tmp_path"
  ],
  "test_remove_checkpoint": [
    "checkpoint_io",
    "tmp_path"
  ],
  "DummyModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "dummy_model": [],
  "optimizer_fn": [],
  "lr_scheduler": [],
  "optimizer_module": [
    "optimizer_fn",
    "lr_scheduler"
  ],
  "test_optimizer_module_initialization": [
    "optimizer_module",
    "optimizer_fn",
    "lr_scheduler"
  ],
  "test_optimizer_creation": [
    "dummy_model",
    "optimizer_module"
  ],
  "test_connect_method": [
    "dummy_model",
    "optimizer_module"
  ],
  "TestFabricConversion": {
    "test_simple_conversion": [
      "self"
    ]
  },
  "get_metadata": [
    "ckpt_save_pre_mcore_014",
    "ckpt_parallel_save_optim",
    "ckpt_optim_fully_reshardable"
  ],
  "TestMegatronStrategy": {
    "test_checkpoint_io": [
      "self",
      "mock_create_checkpoint_io"
    ],
    "test_ckpt_load_main_params_and_ckpt_load_optimizer_both_true": [
      "self"
    ],
    "test_ckpt_load_main_params_with_state_dict": [
      "self"
    ],
    "test_ckpt_load_main_params_without_state_dict": [
      "self"
    ],
    "test_sharded_state_dict_metadata": [
      "self"
    ],
    "test_init_errors": [
      "self"
    ],
    "test_process_dataloader": [
      "self"
    ],
    "test_on_test_end": [
      "self"
    ],
    "test_update_step_kwargs": [
      "self"
    ]
  },
  "mock_transformer_layer": [],
  "mock_lightning_module": [],
  "mock_trainer": [],
  "mock_checkpoint_io": [],
  "strategy": [
    "mock_transformer_layer"
  ],
  "TestFSDPStrategy": {
    "test_init": [
      "self",
      "mock_transformer_layer"
    ],
    "test_training_step": [
      "self",
      "strategy"
    ],
    "test_validation_step": [
      "self",
      "strategy"
    ],
    "test_test_step": [
      "self",
      "strategy"
    ],
    "test_predict_step": [
      "self",
      "strategy"
    ],
    "test_process_dataloader": [
      "self",
      "strategy"
    ],
    "test_checkpoint_io": [
      "self",
      "mock_create_checkpoint_io"
    ],
    "test_current_epoch_step": [
      "self",
      "strategy",
      "mock_trainer"
    ],
    "test_remove_checkpoint": [
      "self",
      "strategy"
    ],
    "test_save_checkpoint": [
      "self",
      "strategy"
    ]
  },
  "mock_mixed_precision_policy": [],
  "mock_device_mesh": [],
  "TestFSDP2Strategy": {
    "test_init": [
      "self"
    ],
    "test_lightning_restore_optimizer": [
      "self",
      "strategy"
    ],
    "test_load_optimizer_state_dict": [
      "self",
      "strategy"
    ],
    "test_setup": [
      "self",
      "strategy",
      "mock_trainer"
    ],
    "test_parallelize": [
      "self",
      "strategy"
    ],
    "test_checkpoint_io": [
      "self",
      "mock_create_checkpoint_io"
    ],
    "test_remove_checkpoint": [
      "self",
      "strategy"
    ],
    "test_save_checkpoint": [
      "self",
      "strategy"
    ],
    "test_load_checkpoint": [
      "self",
      "strategy"
    ],
    "test_validation_step": [
      "self",
      "strategy"
    ],
    "test_test_step": [
      "self",
      "strategy"
    ],
    "test_predict_step": [
      "self",
      "strategy"
    ]
  },
  "_reset_megatron_parallel_state": [],
  "reset_megatron_parallel_state": [],
  "RandomDataset": {
    "__init__": [
      "self",
      "size",
      "length"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ]
  },
  "PassThroughLossReduction": {
    "forward": [
      "self",
      "batch",
      "forward_out"
    ],
    "reduce": [
      "self",
      "losses_reduced_per_micro_batch"
    ]
  },
  "ExampleModel": {
    "__init__": [
      "self"
    ],
    "configure_model": [
      "self"
    ],
    "forward": [
      "self",
      "batch"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "training_step": [
      "self",
      "batch"
    ],
    "validation_step": [
      "self",
      "batch"
    ],
    "test_step": [
      "self",
      "batch"
    ],
    "configure_optimizers": [
      "self"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "setup_test": [
    "path",
    "async_save",
    "max_epochs"
  ],
  "get_final_checkpoint": [
    "checkpoint_dir"
  ],
  "TestLinkCheckpoint": {
    "test_link_ckpt": [
      "self",
      "tmpdir"
    ],
    "test_link_ckpt_async": [
      "self",
      "tmpdir"
    ],
    "test_restore_async": [
      "self",
      "tmpdir"
    ]
  },
  "TestModelTransformCallback": {
    "callback": [
      "self"
    ],
    "pl_module": [
      "self"
    ],
    "trainer": [
      "self"
    ],
    "test_setup_stores_transform": [
      "self",
      "callback",
      "pl_module",
      "trainer",
      "caplog"
    ]
  },
  "MockModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MockLightningModule": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TestPEFT": {
    "test_peft_call": [
      "self"
    ],
    "test_linear_adapter": [
      "self"
    ],
    "test_linear_adapter_monkey_patch": [
      "self"
    ],
    "test_peft_setup": [
      "self"
    ],
    "test_peft_on_train_epoch_start_with_adapter": [
      "self",
      "mock_logging"
    ],
    "test_params_to_save": [
      "self"
    ],
    "test_params_to_save_batchnorm": [
      "self"
    ]
  },
  "test_runtime_estimator": [],
  "MockDataModule": {
    "__init__": [
      "self",
      "global_batch_size",
      "vocab_size"
    ]
  },
  "test_flops_measurement_callback_bert": [],
  "test_extract_module_attr_name_with_module": [],
  "test_extract_module_attr_name_with_model": [],
  "test_extract_module_attr_name_raises": [],
  "test_listify_non_list": [],
  "test_listify_list": [],
  "test_get_modules_from_selector_none_selector": [],
  "test_get_modules_from_selector_empty_string": [],
  "test_get_modules_from_selector_star": [],
  "test_get_modules_from_selector_exact_path": [],
  "test_get_modules_from_selector_non_existent_attr": [],
  "test_get_modules_from_selector_attr_is_not_module": [],
  "test_get_modules_from_selector_wildcard_children": [],
  "test_jit_config_assertion": [],
  "test_compile_module_torch": [],
  "test_compile_module_none": [],
  "test_jit_transform_no_config": [],
  "test_jit_transform_already_compiled": [],
  "test_jit_transform_compile_once": [],
  "TestPreemptionCallback": {
    "callback": [
      "self"
    ],
    "mock_trainer": [
      "self"
    ],
    "test_init": [
      "self",
      "callback"
    ],
    "test_custom_signal": [
      "self"
    ],
    "test_on_train_batch_start_distributed_init": [
      "self",
      "callback",
      "mock_trainer",
      "initially_supported",
      "becomes_supported"
    ],
    "test_interrupted_property": [
      "self",
      "callback",
      "is_supported",
      "interrupted",
      "expected"
    ],
    "test_on_train_start": [
      "self",
      "callback",
      "mock_trainer"
    ],
    "test_on_train_end": [
      "self",
      "callback",
      "mock_trainer"
    ],
    "test_on_train_batch_end": [
      "self",
      "callback",
      "mock_trainer",
      "interrupted"
    ]
  },
  "TestNsysCallback": {
    "setup_mocks": [
      "self"
    ],
    "mock_trainer": [
      "self"
    ],
    "mock_pl_module": [
      "self"
    ],
    "test_init_valid_params": [
      "self"
    ],
    "test_init_invalid_params": [
      "self"
    ],
    "test_on_train_batch_start_profiling": [
      "self",
      "mock_emit_nvtx",
      "mock_get_rank",
      "mock_trainer",
      "mock_pl_module"
    ],
    "test_on_train_batch_start_no_profiling": [
      "self",
      "mock_get_rank",
      "mock_trainer",
      "mock_pl_module"
    ],
    "test_on_train_batch_end_profiling": [
      "self",
      "mock_emit_nvtx",
      "mock_get_rank",
      "mock_trainer",
      "mock_pl_module"
    ],
    "test_on_train_batch_end_no_profiling": [
      "self",
      "mock_emit_nvtx",
      "mock_get_rank",
      "mock_trainer",
      "mock_pl_module"
    ],
    "test_non_cuda_device": [
      "self",
      "mock_trainer",
      "mock_pl_module"
    ],
    "test_rank_not_in_profile_ranks": [
      "self",
      "mock_get_rank",
      "mock_trainer",
      "mock_pl_module"
    ],
    "test_profiling_range": [
      "self",
      "mock_emit_nvtx",
      "mock_get_rank",
      "start_step",
      "end_step",
      "batch_idx",
      "expected_call",
      "mock_trainer",
      "mock_pl_module"
    ],
    "test_single_profile_range": [
      "self",
      "mock_get_rank",
      "mock_trainer",
      "mock_pl_module"
    ]
  },
  "test_speed_monitor": [],
  "TestHydraRunner": {
    "test_no_config": [
      "self"
    ],
    "test_config1": [
      "self"
    ],
    "test_config1_invalid": [
      "self"
    ],
    "test_config2": [
      "self"
    ],
    "test_config2_invalid": [
      "self"
    ],
    "test_config2_filepath_schema": [
      "self"
    ]
  },
  "DefaultConfig": {},
  "my_app": [
    "cfg"
  ],
  "DOMAINS": [],
  "process_args": [],
  "_build_import_path": [
    "domain",
    "subdomains",
    "imp"
  ],
  "_get_class_from_path": [
    "domain",
    "subdomains",
    "imp"
  ],
  "_test_domain_module_imports": [
    "module",
    "domain",
    "subdomains"
  ],
  "test_domain_asr": [
    "args"
  ],
  "test_domain_tts": [
    "args"
  ],
  "test_domain_lightning": [
    "args"
  ],
  "test_domain_core": [
    "args"
  ],
  "test_domain": [
    "args"
  ],
  "run_checks": [],
  "load_model": [],
  "load_model_from_unpacked_hf_dir": [
    "repo_id"
  ],
  "upload_model_as_single_nemo_file": [
    "model",
    "repo_id",
    "token"
  ],
  "upload_model_as_unpacked_files": [
    "model",
    "repo_id",
    "token"
  ],
  "check_repo_exists": [
    "repo_id",
    "token"
  ],
  "cleanup": [
    "repo_id",
    "token"
  ],
  "OnesDataset": {
    "__init__": [
      "self",
      "dataset_len"
    ],
    "__getitem__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "TestStatelessTimer": {
    "setup_model": [
      "self"
    ],
    "cleanup": [
      "self"
    ],
    "test_stateless_timer": [
      "self"
    ]
  },
  "instantiate_multinode_ddp_if_possible": [],
  "setup_model": [
    "trainer"
  ],
  "get_rank_info": [
    "texts",
    "rank_key"
  ],
  "check_model_ranks": [
    "model"
  ],
  "cutset_path": [
    "tmp_path_factory"
  ],
  "cutset_shar_path": [
    "cutset_path"
  ],
  "cutset_shar_path_other": [
    "cutset_path"
  ],
  "nemo_manifest_path": [
    "cutset_path"
  ],
  "nemo_manifest_with_skipme_path": [
    "nemo_manifest_path"
  ],
  "mc_cutset_path": [
    "tmp_path_factory"
  ],
  "nemo_tarred_manifest_path": [
    "nemo_manifest_path"
  ],
  "nemo_tarred_manifest_with_skipme_path": [
    "nemo_tarred_manifest_path"
  ],
  "nemo_tarred_manifest_path_multi": [
    "nemo_tarred_manifest_path"
  ],
  "nemo_tarred_manifest_subset_path": [
    "nemo_tarred_manifest_path"
  ],
  "UnsupervisedAudioDataset": {
    "__getitem__": [
      "self",
      "cuts"
    ]
  },
  "test_dataloader_from_lhotse_cuts": [
    "cutset_path"
  ],
  "test_dataloader_from_lhotse_cuts_truncate": [
    "cutset_path"
  ],
  "test_dataloader_from_lhotse_cuts_cut_into_windows": [
    "cutset_path"
  ],
  "test_dataloader_from_lhotse_cuts_pad_min_duration": [
    "cutset_path"
  ],
  "test_dataloader_from_lhotse_cuts_channel_selector": [
    "mc_cutset_path"
  ],
  "test_dataloader_from_lhotse_shar_cuts": [
    "cutset_shar_path"
  ],
  "test_dataloader_from_lhotse_shar_cuts_via_fields": [
    "cutset_shar_path"
  ],
  "test_dataloader_from_lhotse_shar_cuts_add_new_field": [
    "tmp_path_factory",
    "cutset_shar_path"
  ],
  "test_dataloader_from_nemo_manifest": [
    "nemo_manifest_path"
  ],
  "_Identity": {
    "__getitem__": [
      "self",
      "cuts"
    ]
  },
  "test_dataloader_from_nemo_manifest_has_custom_fields": [
    "nemo_manifest_path"
  ],
  "test_dataloader_from_tarred_nemo_manifest": [
    "nemo_tarred_manifest_path"
  ],
  "test_dataloader_from_tarred_nemo_manifest_weighted_combination": [
    "nemo_tarred_manifest_path"
  ],
  "test_dataloader_from_tarred_nemo_manifest_multi": [
    "nemo_tarred_manifest_path_multi"
  ],
  "test_dataloader_from_tarred_nemo_manifest_multi_max_open_streams": [
    "nemo_tarred_manifest_path_multi"
  ],
  "test_dataloader_from_tarred_nemo_manifest_concat": [
    "nemo_tarred_manifest_path"
  ],
  "test_dataloader_from_lhotse_shar_cuts_combine_datasets_unweighted": [
    "cutset_shar_path",
    "cutset_shar_path_other"
  ],
  "test_dataloader_from_lhotse_shar_cuts_combine_datasets_weighted": [
    "cutset_shar_path",
    "cutset_shar_path_other"
  ],
  "TextDataset": {
    "__getitem__": [
      "self",
      "cuts"
    ]
  },
  "test_dataloader_from_nemo_manifest_with_text_field": [
    "nemo_manifest_path",
    "text_field",
    "text_value"
  ],
  "LangDataset": {
    "__getitem__": [
      "self",
      "cuts"
    ]
  },
  "test_dataloader_from_nemo_manifest_with_lang_field": [
    "nemo_manifest_path",
    "lang_field",
    "lang_value"
  ],
  "test_lazy_nemo_iterator_with_offset_field": [
    "tmp_path"
  ],
  "test_lazy_nemo_iterator_with_relative_paths": [
    "tmp_path"
  ],
  "test_lhotse_cuts_resolve_relative_paths": [
    "tmp_path"
  ],
  "test_extended_data_input_cfg": [
    "cutset_shar_path",
    "nemo_tarred_manifest_path_multi"
  ],
  "test_extended_data_input_cfg_subgroup": [
    "cutset_shar_path",
    "nemo_tarred_manifest_path_multi"
  ],
  "test_extended_data_input_cfg_yaml_path": [
    "tmp_path",
    "cutset_shar_path",
    "nemo_tarred_manifest_path_multi"
  ],
  "txt_en_path": [
    "tmp_path_factory"
  ],
  "txt_es_path": [
    "tmp_path_factory"
  ],
  "questions_path": [
    "tmp_path_factory"
  ],
  "test_text_file_input": [
    "txt_en_path",
    "txt_es_path"
  ],
  "test_text_file_pairs_input": [
    "txt_en_path",
    "txt_es_path",
    "questions_path"
  ],
  "txt_pair_paths_shards": [
    "tmp_path_factory",
    "txt_en_path",
    "txt_es_path"
  ],
  "test_text_file_pairs_shards_input": [
    "txt_pair_paths_shards",
    "questions_path"
  ],
  "en_es_tokenizer": [
    "tmp_path_factory",
    "txt_en_path",
    "txt_es_path"
  ],
  "test_multimodal_text_audio_dataloading": [
    "txt_pair_paths_shards",
    "nemo_tarred_manifest_path_multi",
    "en_es_tokenizer",
    "questions_path"
  ],
  "test_multimodal_text_audio_dataloading_zip_strategy": [
    "txt_pair_paths_shards",
    "nemo_tarred_manifest_path_multi",
    "en_es_tokenizer",
    "questions_path"
  ],
  "test_multimodal_text_audio_dataloading_round_robin_strategy": [
    "txt_pair_paths_shards",
    "nemo_tarred_manifest_path_multi",
    "en_es_tokenizer",
    "questions_path"
  ],
  "test_multimodal_text_audio_dataloading_randomized_round_robin_strategy": [
    "deterministic_rng",
    "txt_pair_paths_shards",
    "nemo_tarred_manifest_path_multi",
    "en_es_tokenizer",
    "questions_path"
  ],
  "test_dataloader_with_noise_nemo_json": [
    "cutset_path",
    "nemo_manifest_path"
  ],
  "test_dataloader_with_noise_lhotse_jsonl": [
    "cutset_path"
  ],
  "test_dataloader_with_noise_nemo_tar": [
    "cutset_path",
    "nemo_tarred_manifest_path_multi"
  ],
  "test_dataloader_with_synth_rir": [
    "cutset_path"
  ],
  "test_dataloader_bucket_batch_size": [
    "nemo_tarred_manifest_path_multi"
  ],
  "test_dataloader_2d_bucketing": [
    "nemo_tarred_manifest_path_multi",
    "en_es_tokenizer"
  ],
  "test_dataloader_from_nemo_nontarred_manifest_with_extra_questions_field_iter": [
    "nemo_manifest_path",
    "questions_path"
  ],
  "test_dataloader_from_nemo_manifest_with_extra_questions_field_iter": [
    "nemo_tarred_manifest_path",
    "questions_path"
  ],
  "test_dataloader_from_nemo_manifest_with_extra_questions_field_sample": [
    "nemo_tarred_manifest_path",
    "questions_path"
  ],
  "nemo_tarred_manifest_path_with_offset": [
    "tmp_path_factory"
  ],
  "test_dataloader_from_tarred_nemo_manifest_with_offset": [
    "nemo_tarred_manifest_path_with_offset"
  ],
  "test_force_iterable_dataset": [
    "cutset_path"
  ],
  "test_force_map_dataset": [
    "cutset_shar_path"
  ],
  "test_dataloader_from_tarred_nemo_subset_manifest": [
    "nemo_tarred_manifest_subset_path"
  ],
  "test_dataloader_from_nemo_manifest_with_skipme": [
    "nemo_manifest_with_skipme_path"
  ],
  "test_dataloader_from_tarred_nemo_manifest_with_skipme": [
    "nemo_tarred_manifest_with_skipme_path"
  ],
  "test_dataloader_from_data_input_cfg_yaml_path_with_skipme": [
    "cutset_shar_path",
    "nemo_tarred_manifest_with_skipme_path"
  ],
  "test_dataloader_lhotse_shar_nemo_tarred_slice_length": [
    "nemo_tarred_manifest_path_multi",
    "cutset_shar_path"
  ],
  "test_dataloader_lhotse_shar_slice_length_multi_epoch_different_sample": [
    "cutset_shar_path"
  ],
  "test_dataloader_nemo_tarred_slice_length_multi_epoch_different_sample": [
    "nemo_tarred_manifest_path_multi"
  ],
  "nemo_manifest_path_multichannel": [
    "tmp_path_factory"
  ],
  "test_lazy_nemo_iterator": [
    "nemo_manifest_path"
  ],
  "test_lazy_nemo_iterator_multichannel": [
    "nemo_manifest_path_multichannel"
  ],
  "nemo_offset_manifest_path": [
    "tmp_path_factory"
  ],
  "test_lazy_nemo_iterator_with_offset": [
    "nemo_offset_manifest_path"
  ],
  "test_lazy_nemo_iterator_with_offset_metadata_only": [
    "nemo_offset_manifest_path"
  ],
  "MockClassWithCudaGraphs": {
    "__init__": [
      "self"
    ],
    "disable_cuda_graphs": [
      "self"
    ],
    "maybe_enable_cuda_graphs": [
      "self"
    ]
  },
  "MockModuleWithCudaGraphs": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MockModuleWithCudaGraphsByPath": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TestWithOptionalCudaGraphs": {
    "test_module_toggle_cuda_graphs": [
      "self"
    ],
    "test_module_toggle_cuda_graphs_by_path": [
      "self"
    ]
  },
  "multimodal_conversations_path": [
    "tmp_path_factory"
  ],
  "tarred_multimodal_conversations_path": [
    "multimodal_conversations_path",
    "tmp_path_factory"
  ],
  "test_multimodal_conversation_input": [
    "multimodal_conversations_path"
  ],
  "sharegpt_conversations_path": [
    "tmp_path_factory"
  ],
  "test_multimodal_conversation_input_sharegpt": [
    "sharegpt_conversations_path"
  ],
  "tokenizer": [
    "tmp_path_factory",
    "multimodal_conversations_path"
  ],
  "test_multimodal_conversation_input_with_prompt": [
    "multimodal_conversations_path",
    "tokenizer"
  ],
  "test_text_only_conversation_length_measurement": [
    "tokenizer"
  ],
  "test_audio_only_conversation_length_measurement": [
    "tokenizer",
    "tmp_path_factory"
  ],
  "test_multimodal_conversation_length_measurement": [
    "tokenizer",
    "tmp_path_factory"
  ],
  "test_multimodal_conversation_tarred_format": [
    "multimodal_conversations_path",
    "tmp_path_factory"
  ],
  "test_multimodal_conversation_tarred_format_sharding_works": [
    "multimodal_conversations_path",
    "tmp_path_factory"
  ],
  "test_multimodal_conversation_duration_filter": [],
  "test_cut_to_conversation_conversion": [
    "cutset_path",
    "tokenizer"
  ],
  "s2s_cutset_path": [
    "tmp_path_factory"
  ],
  "test_s2s_cut_to_conversation_conversion": [
    "s2s_cutset_path",
    "tokenizer"
  ],
  "test_dataloader_multimodal_conversation_tarred_slice_length_multi_epoch_different_sample": [
    "tarred_multimodal_conversations_path"
  ],
  "multiple_multimodal_conversations_path": [
    "multimodal_conversations_path",
    "tmp_path_factory"
  ],
  "test_dataloader_multimodal_conversation_nontarred_slice_length_ignored": [
    "multiple_multimodal_conversations_path"
  ],
  "TestCommonMetrics": {
    "top_k_logits": [],
    "test_top_1_accuracy": [
      "self"
    ],
    "test_top_1_2_accuracy": [
      "self"
    ],
    "test_top_1_accuracy_distributed": [
      "self"
    ],
    "test_top_1_accuracy_distributed_uneven_batch": [
      "self"
    ]
  },
  "TestPerplexity": {
    "test_perplexity": [
      "self",
      "ddp",
      "dist_sync_on_step",
      "probs",
      "logits"
    ]
  },
  "TestLoss": {
    "test_loss": [
      "self",
      "ddp",
      "dist_sync_on_step",
      "loss_sum_or_avg",
      "num_measurements",
      "take_avg_loss"
    ]
  },
  "TestPunctuationErrorRate": {
    "reference": [],
    "hypothesis": [],
    "punctuation_marks": [],
    "operation_amounts": [],
    "substitution_amounts": [],
    "correct_rate": [],
    "deletions_rate": [],
    "insertions_rate": [],
    "substitutions_rate": [],
    "punct_er": [],
    "operation_rates": [],
    "substitution_rates": [],
    "test_punctuation_error_rate": [
      "self"
    ],
    "test_OccurancePunctuationErrorRate": [
      "self"
    ],
    "test_DatasetPunctuationErrorRate": [
      "self"
    ]
  },
  "test_dataloader_multiple_ranks_deterministic_rng": [
    "nemo_tarred_manifest_path"
  ],
  "test_dataloader_multiple_ranks_trng": [
    "nemo_tarred_manifest_path"
  ],
  "test_chat_template": [],
  "test_throws_chat_template": [],
  "DummyDataset": {
    "__getitem__": [
      "self",
      "item"
    ]
  },
  "test_fallback_dataset": [],
  "make_cut": [
    "id_",
    "duration",
    "num_tokens"
  ],
  "cuts": [],
  "test_2d_bucketing_expected_bucket_allocation": [
    "cuts"
  ],
  "test_2d_bucketing_filter_lenient": [
    "duration",
    "num_tokens",
    "should_keep",
    "bucket_idx"
  ],
  "test_2d_bucketing_filter_strict": [
    "duration",
    "num_tokens",
    "should_keep",
    "bucket_idx"
  ],
  "test_2d_bucketing_filter_strict_max_ratio": [],
  "test_2d_bucketing_strict_mode_flag_works": [
    "deterministic_rng",
    "tmp_path"
  ],
  "TestListUtils": {
    "test_flatten": [
      "self"
    ]
  },
  "TestMaskSequenceTensor": {
    "test_mask_sequence_tensor": [
      "self",
      "ndim"
    ]
  },
  "TestPreprocessingUtils": {
    "test_get_full_path_local": [
      "self",
      "tmpdir"
    ],
    "test_get_full_path_ais": [
      "self",
      "tmpdir"
    ],
    "test_get_full_path_ais_no_cache": [
      "self"
    ],
    "test_get_full_path_audio_file_len_limit": [
      "self"
    ],
    "test_get_full_path_invalid_type": [
      "self"
    ],
    "test_get_full_path_invalid_relative_path": [
      "self"
    ],
    "test_is_tarred_dataset": [
      "self"
    ]
  },
  "LossInput": {},
  "NO_ZERO_NUM_MEASUREMENTS": [],
  "SOME_NUM_MEASUREMENTS_ARE_ZERO": [],
  "ALL_NUM_MEASUREMENTS_ARE_ZERO": [],
  "DEVICE_CAPABILITY": [],
  "_mock_onelogger_update_config": [],
  "extract_ema_weights": [
    "pl_module",
    "trainer"
  ],
  "extract_weights": [
    "pl_module"
  ],
  "TestEMAConfig": {
    "test_ema_value": [
      "self"
    ],
    "test_ema_saved_state": [
      "self",
      "tmpdir",
      "caplog"
    ],
    "test_exp_manager_ema_weights": [
      "self",
      "tmpdir"
    ],
    "test_exp_manager_ema_weights_topk": [
      "self",
      "tmpdir"
    ],
    "test_exp_manager_ema_weights_topk_resume": [
      "self",
      "tmpdir"
    ]
  },
  "TestEMATrain": {
    "test_ema_run_cuda": [
      "self",
      "test_data_dir",
      "precision",
      "accumulate_grad_batches",
      "validate_original_weights",
      "tmpdir"
    ],
    "test_ema_run_cpu": [
      "self",
      "test_data_dir",
      "accumulate_grad_batches",
      "validate_original_weights",
      "tmpdir"
    ],
    "run_training_test": [
      "self",
      "accumulate_grad_batches",
      "validate_original_weights",
      "accelerator",
      "precision",
      "tmpdir"
    ],
    "test_ema_run_with_save_best_model": [
      "self",
      "tmpdir"
    ]
  },
  "EMAAssertCallback": {
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ]
  },
  "EMAValidationAssertCallback": {
    "on_validation_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_validation_end": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "LLAMA2_CFG_STR": [],
  "NEMOTRON_CFG_STR": [],
  "UNSUPPORTED_MODEL_CFG_STR": [],
  "NULL_MODEL_CFG_STR": [],
  "model_config": [
    "cfg"
  ],
  "test_eval_tflops_per_sec_per_gpu": [
    "model_config",
    "model_name",
    "train_step_time",
    "expected_value"
  ],
  "cut": [],
  "test_cut_duration_filter": [
    "cut"
  ],
  "test_cut_token_per_second_filter": [
    "cut"
  ],
  "test_cut_passes_by_token_count_and_tpt_filter": [
    "cut"
  ],
  "src_tgt_example": [],
  "test_src_tgt_token_filter_requires_prompt_formatting": [
    "src_tgt_example"
  ],
  "test_src_tgt_passes_by_duration_filter": [
    "src_tgt_example"
  ],
  "test_src_tgt_token_filter": [
    "src_tgt_example"
  ],
  "nemo_sft_example": [],
  "test_nemo_sft_token_filter_requires_prompt_formatting": [
    "nemo_sft_example"
  ],
  "test_nemo_sft_passes_by_duration_filter": [
    "nemo_sft_example"
  ],
  "test_nemo_sft_token_filter": [
    "nemo_sft_example"
  ],
  "MODEL_SPECIAL_TOKENS": [],
  "TestSentencePieceTokenizerLegacy": {
    "model_name": [],
    "test_add_special_tokens": [
      "self",
      "test_data_dir"
    ],
    "test_text_to_tokens": [
      "self",
      "test_data_dir"
    ],
    "test_tokens_to_text": [
      "self",
      "test_data_dir"
    ],
    "test_text_to_ids": [
      "self",
      "test_data_dir"
    ],
    "test_ids_to_text": [
      "self",
      "test_data_dir"
    ],
    "test_tokens_to_ids": [
      "self",
      "test_data_dir"
    ],
    "test_ids_to_tokens": [
      "self",
      "test_data_dir"
    ]
  },
  "TestSentencePieceTokenizer": {
    "model_name": [],
    "test_text_to_tokens": [
      "self",
      "test_data_dir"
    ],
    "test_tokens_to_text": [
      "self",
      "test_data_dir"
    ],
    "test_text_to_ids": [
      "self",
      "test_data_dir"
    ],
    "test_ids_to_text": [
      "self",
      "test_data_dir"
    ],
    "test_tokens_to_ids": [
      "self",
      "test_data_dir"
    ],
    "test_ids_to_tokens": [
      "self",
      "test_data_dir"
    ]
  },
  "Input": [],
  "ONLY_PROBS": [],
  "ONLY_LOGITS1": [],
  "ONLY_LOGITS100": [],
  "PROBS_AND_LOGITS": [],
  "NO_PROBS_NO_LOGITS": [],
  "NUM_PROCESSES": [],
  "NUM_BATCHES": [],
  "BATCH_SIZE": [],
  "NUM_CLASSES": [],
  "EXTRA_DIM": [],
  "THRESHOLD": [],
  "setup_ddp": [
    "rank",
    "world_size"
  ],
  "_class_test": [
    "rank",
    "worldsize",
    "preds",
    "target",
    "metric_class",
    "sk_metric",
    "dist_sync_on_step",
    "metric_args",
    "check_dist_sync_on_step",
    "check_batch",
    "atol"
  ],
  "_functional_test": [
    "preds",
    "target",
    "metric_functional",
    "sk_metric",
    "metric_args",
    "atol"
  ],
  "MetricTester": {
    "atol": [],
    "setup_class": [
      "self"
    ],
    "teardown_class": [
      "self"
    ],
    "run_functional_metric_test": [
      "self",
      "preds",
      "target",
      "metric_functional",
      "sk_metric",
      "metric_args"
    ],
    "run_class_metric_test": [
      "self",
      "ddp",
      "preds",
      "target",
      "metric_class",
      "sk_metric",
      "dist_sync_on_step",
      "metric_args",
      "check_dist_sync_on_step",
      "check_batch"
    ]
  },
  "reference_perplexity_func": [
    "probs"
  ],
  "_perplexity_class_test": [
    "rank",
    "worldsize",
    "probs",
    "logits",
    "dist_sync_on_step",
    "metric_args",
    "check_dist_sync_on_step",
    "check_batch",
    "atol"
  ],
  "PerplexityTester": {
    "run_class_perplexity_test": [
      "self",
      "ddp",
      "probs",
      "logits",
      "dist_sync_on_step",
      "metric_args",
      "check_dist_sync_on_step",
      "check_batch"
    ]
  },
  "reference_loss_func": [
    "loss_sum_or_avg",
    "num_measurements",
    "take_avg_loss"
  ],
  "_loss_class_test": [
    "rank",
    "worldsize",
    "loss_sum_or_avg",
    "num_measurements",
    "dist_sync_on_step",
    "take_avg_loss",
    "check_dist_sync_on_step",
    "check_batch",
    "atol"
  ],
  "LossTester": {
    "run_class_loss_test": [
      "self",
      "ddp",
      "loss_sum_or_avg",
      "num_measurements",
      "dist_sync_on_step",
      "take_avg_loss",
      "check_dist_sync_on_step",
      "check_batch"
    ]
  },
  "_Batch": {},
  "test_move_data_to_device": [
    "batch"
  ],
  "cuts_path": [
    "tmp_path_factory"
  ],
  "multi_speaker_simulator_example": [
    "tmp_path_factory"
  ],
  "test_prompt_format_cut": [
    "cuts_path",
    "tokenizer"
  ],
  "test_prompt_format_cut_filtered_out": [
    "cuts_path",
    "tokenizer"
  ],
  "test_prompt_format_cut_max_tokens_has_no_filtering_effect": [
    "cuts_path",
    "tokenizer"
  ],
  "test_prompt_format_src_tgt": [
    "src_tgt_example",
    "tokenizer"
  ],
  "test_prompt_format_src_tgt_filtered_out": [
    "src_tgt_example",
    "tokenizer"
  ],
  "test_prompt_format_src_tgt_2d": [
    "src_tgt_example",
    "tokenizer"
  ],
  "test_prompt_format_nemo_sft": [
    "nemo_sft_example",
    "tokenizer"
  ],
  "test_prompt_format_nemo_sft_filtered_out": [
    "nemo_sft_example",
    "tokenizer"
  ],
  "test_prompt_format_multi_speaker_simulator": [
    "multi_speaker_simulator_example",
    "tokenizer"
  ],
  "TestTTSTokenizers": {
    "PHONEME_DICT_DE": [],
    "PHONEME_DICT_EN": [],
    "PHONEME_DICT_ES": [],
    "PHONEME_DICT_IT": [],
    "PHONEME_DICT_FR": [],
    "PHONEME_DICT_JA": [],
    "_parse_text": [
      "tokenizer",
      "text"
    ],
    "test_english_chars_tokenizer": [
      "self"
    ],
    "test_english_chars_tokenizer_unknown_token": [
      "self"
    ],
    "test_english_chars_tokenizer_accented_character": [
      "self"
    ],
    "test_german_chars_tokenizer": [
      "self"
    ],
    "test_italian_chars_tokenizer": [
      "self"
    ],
    "test_spanish_chars_tokenizer": [
      "self"
    ],
    "test_vietnamese_chars_tokenizer": [
      "self"
    ],
    "test_french_chars_tokenizer": [
      "self"
    ],
    "test_ipa_tokenizer": [
      "self"
    ],
    "test_ipa_tokenizer_unsupported_locale": [
      "self"
    ],
    "test_ipa_tokenizer_de_de": [
      "self"
    ],
    "test_ipa_tokenizer_it_it": [
      "self"
    ],
    "test_ipa_tokenizer_en_us": [
      "self"
    ],
    "test_ipa_tokenizer_es_es": [
      "self"
    ],
    "test_ipa_tokenizer_fr_fr": [
      "self"
    ],
    "test_ipa_tokenizer_fixed_vocab": [
      "self"
    ],
    "test_japanese_phoneme_tokenizer": [
      "self"
    ]
  },
  "TestTokenizerUtils": {
    "_create_expected_output": [
      "words"
    ],
    "test_english_word_tokenize": [
      "self"
    ],
    "test_english_word_tokenize_with_punctuation": [
      "self"
    ],
    "test_english_word_tokenize_with_contractions": [
      "self"
    ],
    "test_english_word_tokenize_with_compound_words": [
      "self"
    ],
    "test_english_word_tokenize_with_escaped": [
      "self"
    ],
    "test_any_locale_word_tokenize": [
      "self"
    ],
    "test_any_locale_word_tokenize_with_accents": [
      "self"
    ],
    "test_any_locale_word_tokenize_with_numbers": [
      "self"
    ],
    "test_any_locale_word_tokenize_fr": [
      "self"
    ],
    "test_any_locale_word_tokenize_with_accents_fr": [
      "self"
    ]
  },
  "MockLinearAdapter1": {},
  "MockLinearAdapter2": {},
  "CommonModule": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "num_params": [
      "self"
    ]
  },
  "CommonModuleAdapter": {
    "forward": [
      "self",
      "x"
    ],
    "get_accepted_adapter_types": [
      "self"
    ]
  },
  "get_adapter_cfg": [
    "in_features",
    "dim",
    "norm_pos"
  ],
  "get_classpath": [
    "cls"
  ],
  "TestCommonAdapterModuleMixin": {
    "test_get_accepted_adapter_types": [
      "self"
    ],
    "test_set_accepted_adapter_types_reset_types": [
      "self"
    ],
    "test_set_accepted_adapter_types_invalid_class": [
      "self"
    ]
  },
  "TestAdapterModules": {
    "test_linear_adapter_config": [
      "self"
    ],
    "test_linear_adapter_init": [
      "self"
    ],
    "test_linear_adapter_dropout": [
      "self"
    ],
    "test_linear_adapter_norm_position": [
      "self",
      "norm_position"
    ],
    "test_linear_adapter_strategy": [
      "self"
    ]
  },
  "test_nemotronh_prompt_formatter_training": [
    "bpe_tokenizer"
  ],
  "test_nemotronh_prompt_formatter_inference": [
    "bpe_tokenizer"
  ],
  "test_nemotronh_prompt_formatter_training_with_system": [
    "bpe_tokenizer"
  ],
  "test_nemotronh_prompt_formatter_inference_with_system": [
    "bpe_tokenizer"
  ],
  "TOKENIZER_TRAIN_TEXT": [],
  "bpe_tokenizer": [
    "tmp_path_factory"
  ],
  "canary_tokenizer": [
    "bpe_tokenizer",
    "tmp_path_factory"
  ],
  "test_gemma_prompt_formatter_training": [
    "bpe_tokenizer"
  ],
  "test_gemma_prompt_formatter_inference": [
    "bpe_tokenizer"
  ],
  "test_gemma_prompt_formatter_training_bos_eos_inserted_only_once_in_multiturn": [
    "bpe_tokenizer"
  ],
  "test_qwen_prompt_formatter_training": [
    "bpe_tokenizer"
  ],
  "test_qwen_prompt_formatter_inference": [
    "bpe_tokenizer"
  ],
  "test_mistral_prompt_formatter_training": [
    "bpe_tokenizer"
  ],
  "test_mistral_prompt_formatter_inference": [
    "bpe_tokenizer"
  ],
  "test_canary_prompt_formatter_training": [
    "canary_tokenizer"
  ],
  "test_canary_prompt_formatter_inference": [
    "canary_tokenizer"
  ],
  "test_llama2_prompt_formatter_training": [
    "bpe_tokenizer"
  ],
  "test_llama2_prompt_formatter_inference": [
    "bpe_tokenizer"
  ],
  "test_llama2_prompt_formatter_training_with_system": [
    "bpe_tokenizer"
  ],
  "test_llama2_prompt_formatter_inference_with_system": [
    "bpe_tokenizer"
  ],
  "_DummyPromptFormatter": {
    "NAME": [],
    "TEMPLATE": [],
    "OUTPUT_ROLE": []
  },
  "test_prompt_formatter_empty_dialog_exception": [
    "bpe_tokenizer"
  ],
  "test_prompt_formatter_inference": [
    "bpe_tokenizer"
  ],
  "test_prompt_formatter_inference_using_content": [
    "bpe_tokenizer"
  ],
  "test_prompt_formatter_training": [
    "bpe_tokenizer"
  ],
  "test_prompt_formatter_training_using_content": [
    "bpe_tokenizer"
  ],
  "test_prompt_formatter_missing_role": [
    "bpe_tokenizer"
  ],
  "test_prompt_formatter_missing_slots": [
    "bpe_tokenizer"
  ],
  "test_prompt_formatter_aggregate_tokenizer": [
    "canary_tokenizer"
  ],
  "test_prompt_formatter_aggregate_tokenizer_missing_prompt_language": [
    "canary_tokenizer"
  ],
  "_DummyPreamblePromptFormatter": {
    "NAME": [],
    "TEMPLATE": [],
    "OUTPUT_ROLE": []
  },
  "test_prompt_formatter_preamble_inference": [
    "bpe_tokenizer"
  ],
  "test_prompt_formatter_premble_training": [
    "bpe_tokenizer"
  ],
  "test_prompt_formatter_explicit_preamble": [
    "bpe_tokenizer"
  ],
  "test_prompt_formatter_wrong_preamble_excpetions": [
    "bpe_tokenizer"
  ],
  "fastpitch_model": [],
  "hifigan_model": [],
  "radtts_model": [],
  "TestExportable": {
    "test_FastPitchModel_export_to_onnx": [
      "self",
      "fastpitch_model"
    ],
    "test_HifiGanModel_export_to_onnx": [
      "self",
      "hifigan_model"
    ],
    "test_RadTTSModel_export_to_torchscript": [
      "self",
      "radtts_model"
    ],
    "test_RadTTSModel_export_to_onnx": [
      "self",
      "radtts_model"
    ]
  },
  "set_device": [],
  "language_specific_text_example": [],
  "supported_languages": [
    "language_specific_text_example"
  ],
  "get_language_id_from_pretrained_model_name": [
    "supported_languages"
  ],
  "mel_spec_example": [
    "set_device"
  ],
  "audio_text_pair_example_english": [
    "test_data_dir",
    "set_device"
  ],
  "TestTTSDataset": {
    "test_dataset": [
      "self",
      "test_data_dir"
    ],
    "test_raise_exception_on_not_supported_sup_data_types": [
      "self",
      "test_data_dir"
    ],
    "test_raise_exception_on_not_supported_window": [
      "self",
      "test_data_dir"
    ],
    "test_raise_exception_on_missing_pitch_sup_data_type_if_use_voiced": [
      "self",
      "test_data_dir",
      "sup_data_type"
    ],
    "test_save_voiced_items_if_pt_file_not_exist": [
      "self",
      "test_data_dir",
      "sup_data_types",
      "output_indices",
      "tmp_path"
    ]
  },
  "enhancer_config": [],
  "enhancer": [
    "enhancer_config"
  ],
  "enhancer_with_fastpitch": [
    "enhancer_config_with_fastpitch"
  ],
  "sample_input": [
    "batch_size",
    "max_length"
  ],
  "test_pad_spectrograms": [
    "enhancer",
    "sample_input"
  ],
  "test_spectrogram_norm_unnorm": [
    "enhancer",
    "sample_input"
  ],
  "test_spectrogram_unnorm_norm": [
    "enhancer",
    "sample_input"
  ],
  "test_spectrogram_norm_unnorm_dont_look_at_padding": [
    "enhancer",
    "sample_input"
  ],
  "test_spectrogram_unnorm_norm_dont_look_at_padding": [
    "enhancer",
    "sample_input"
  ],
  "test_generator_pass_keeps_size": [
    "enhancer",
    "sample_input"
  ],
  "test_discriminator_pass": [
    "enhancer",
    "sample_input"
  ],
  "test_nemo_save_load": [
    "enhancer",
    "tmp_path"
  ],
  "mcfg": [],
  "pcfg": [],
  "wcfg": [],
  "input_example": [
    "sz"
  ],
  "taco2wg": [
    "spec",
    "z"
  ],
  "forward_wrapper": [
    "self",
    "spec",
    "z"
  ],
  "TestWaveGlow": {
    "test_export_to_onnx": [
      "self"
    ]
  },
  "sample_duration_input": [
    "max_length",
    "group_size",
    "batch_size"
  ],
  "test_sort_unsort": [],
  "test_regulate_len": [],
  "TestIpaG2p": {
    "PHONEME_DICT_DIR": [],
    "PHONEME_DICT_PATH_DE": [],
    "PHONEME_DICT_PATH_EN": [],
    "PHONEME_DICT_PATH_ES": [],
    "GRAPHEME_PREFIX": [],
    "_create_g2p": [
      "phoneme_dict",
      "locale",
      "apply_to_oov_word",
      "use_chars",
      "phoneme_probability",
      "grapheme_case",
      "grapheme_prefix"
    ],
    "test_normalize_dict_with_phonemes": [
      "self"
    ],
    "test_normalize_dict_with_graphemes_and_phonemes": [
      "self"
    ],
    "test_replace_symbols": [
      "self"
    ],
    "test_forward_call": [
      "self"
    ],
    "test_forward_call_with_file_or_object_dict_type": [
      "self"
    ],
    "test_forward_call_with_oov_word": [
      "self"
    ],
    "test_forward_call_with_oov_func": [
      "self"
    ],
    "test_forward_call_with_uppercase_grapheme_only": [
      "self"
    ],
    "test_forward_call_with_lowercase_grapheme_only": [
      "self"
    ],
    "test_forward_call_with_mixed_case_grapheme_only": [
      "self"
    ],
    "test_forward_call_with_uppercase_grapheme_and_get_phoneme_only": [
      "self"
    ],
    "test_forward_call_with_lowercase_grapheme_and_get_phoneme_only": [
      "self"
    ],
    "test_forward_call_with_mixed_case_grapheme_and_get_phoneme_only": [
      "self"
    ],
    "test_forward_call_with_escaped_characters": [
      "self"
    ],
    "test_instantiate_unsupported_locale": [
      "self"
    ],
    "test_forward_call_de_de": [
      "self"
    ],
    "test_forward_call_en_us": [
      "self"
    ],
    "test_forward_call_es_es": [
      "self"
    ]
  },
  "TestAudioCodecLoss": {
    "test_masked_loss_l1": [
      "self"
    ],
    "test_masked_loss_l2": [
      "self"
    ],
    "test_si_sdr_loss": [
      "self"
    ],
    "test_si_sdr_loss_batch": [
      "self"
    ]
  },
  "TestTTSDatasetUtils": {
    "test_get_abs_rel_paths_input_abs": [
      "self"
    ],
    "test_get_abs_rel_paths_input_rel": [
      "self"
    ],
    "test_get_audio_paths": [
      "self"
    ],
    "test_load_audio": [
      "self",
      "test_data_dir"
    ],
    "test_load_audio_with_offset": [
      "self",
      "test_data_dir"
    ],
    "test_normalize_volume": [
      "self"
    ],
    "test_normalize_volume_negative_peak": [
      "self"
    ],
    "test_normalize_volume_zero": [
      "self"
    ],
    "test_normalize_volume_max": [
      "self"
    ],
    "test_normalize_volume_zeros": [
      "self"
    ],
    "test_normalize_volume_empty": [
      "self"
    ],
    "test_normalize_volume_out_of_range": [
      "self"
    ],
    "test_stack_tensors": [
      "self"
    ],
    "test_stack_tensors_3d": [
      "self"
    ],
    "test_filter_dataset_by_duration": [
      "self"
    ]
  },
  "TestTTSFeatureProcessors": {
    "_write_test_dict": [
      "self",
      "test_dict",
      "filename"
    ],
    "test_feature_scalar": [
      "self"
    ],
    "test_log_compression": [
      "self"
    ],
    "test_log_compression_clamp": [
      "self"
    ],
    "test_mean_variance_normalization": [
      "self"
    ],
    "test_mean_variance_normalization_masked": [
      "self"
    ],
    "test_mean_variance_speaker_normalization": [
      "self"
    ],
    "test_mean_variance_speaker_normalization_masked": [
      "self"
    ]
  },
  "TestTTSFeatures": {
    "setup_class": [
      "self"
    ],
    "_compute_start_end_frames": [
      "self",
      "offset",
      "duration"
    ],
    "_create_test_dir": [
      "self"
    ],
    "test_compute_mel_spectrogram": [
      "self"
    ],
    "test_save_and_load_mel_spectrogram": [
      "self"
    ],
    "test_compute_pitch": [
      "self"
    ],
    "test_compute_pitch_batched": [
      "self",
      "test_data_dir"
    ],
    "test_save_and_load_pitch": [
      "self"
    ],
    "test_save_and_load_pitch_segments": [
      "self",
      "test_data_dir"
    ],
    "test_compute_energy": [
      "self"
    ],
    "test_save_and_load_energy": [
      "self"
    ],
    "test_save_and_load_energy_segments": [
      "self",
      "test_data_dir"
    ]
  },
  "TestAudioTrimming": {
    "test_get_start_and_end_of_speech_frames_frames": [
      "self"
    ],
    "test_get_start_and_end_of_speech_frames_not_frames_found": [
      "self"
    ],
    "test_pad_sample_indices": [
      "self"
    ],
    "test_pad_sample_indices_boundaries": [
      "self"
    ]
  },
  "available_models": [],
  "pretrained_model": [
    "request",
    "get_language_id_from_pretrained_model_name"
  ],
  "test_inference": [
    "pretrained_model",
    "language_specific_text_example"
  ],
  "test_conditional_layer_norm": [],
  "TestAudioCodecModules": {
    "setup_class": [
      "self"
    ],
    "test_conv1d": [
      "self"
    ],
    "test_conv1d_downsample": [
      "self"
    ],
    "test_conv1d_transpose_upsample": [
      "self"
    ],
    "test_residual_block": [
      "self"
    ],
    "test_hifigan_decoder": [
      "self"
    ],
    "test_resnet_encoder": [
      "self"
    ],
    "test_multiband_mel_encoder": [
      "self"
    ]
  },
  "TestResidualVectorQuantizer": {
    "setup_class": [
      "self"
    ],
    "test_rvq_eval": [
      "self",
      "num_codebooks"
    ],
    "test_group_rvq_eval": [
      "self",
      "num_groups",
      "num_codebooks"
    ]
  },
  "TestCodecActivation": {
    "setup_class": [
      "self"
    ],
    "test_snake": [
      "self"
    ]
  },
  "TestFiniteScalarQuantizer": {
    "setup_class": [
      "self"
    ],
    "test_fsq_eval": [
      "self",
      "num_levels"
    ],
    "test_fsq_output": [
      "self"
    ],
    "test_group_fsq_eval": [
      "self",
      "num_groups",
      "num_levels_per_group"
    ]
  },
  "set_seed": [
    "seed"
  ],
  "TestConvolutionLayer": {
    "setup_class": [
      "cls"
    ],
    "test_non_causal_forward": [
      "self"
    ],
    "test_causal_forward": [
      "self"
    ]
  },
  "TestPositionwiseConvFF": {
    "setup_class": [
      "cls"
    ],
    "test_causal_forward": [
      "self"
    ],
    "test_non_causal_forward": [
      "self"
    ]
  },
  "TestSelfAttention": {
    "setup_class": [
      "cls"
    ],
    "test_causal_forward": [
      "self"
    ],
    "test_non_causal_forward": [
      "self"
    ]
  },
  "TestCrossAttention": {
    "setup_class": [
      "cls"
    ],
    "test_forward": [
      "self"
    ]
  },
  "TestTransformerLayer": {
    "setup_class": [
      "cls"
    ],
    "test_forward_causal_self_attn_and_has_xattn": [
      "self"
    ]
  },
  "TestTransformer": {
    "setup_class": [
      "cls"
    ],
    "test_forward_causal_self_attn_and_no_xattn": [
      "self"
    ],
    "test_forward_causal_self_attn_and_has_xattn": [
      "self"
    ]
  },
  "test_freezing_params": [],
  "test_keeping_unfrozen_params": [],
  "test_configure_optimizers": [],
  "test_configure_optimizers_with_lr_scheduler": [],
  "test_bleu": [],
  "test_wer": [],
  "resolve_pretrained_models": [],
  "model": [],
  "dataset": [
    "model"
  ],
  "training_cutset_batch": [],
  "test_s2s_speech_decoder_training_step": [
    "model",
    "dataset",
    "training_cutset_batch"
  ],
  "test_s2s_speech_decoder_validation_step": [
    "model",
    "dataset",
    "training_cutset_batch"
  ],
  "test_s2s_speech_decoder_offline_generation": [
    "model"
  ],
  "data_config": [
    "tmp_path"
  ],
  "test_datamodule_train_dataloader": [
    "data_config",
    "tokenizer"
  ],
  "test_datamodule_validation_dataloader": [
    "data_config",
    "tokenizer"
  ],
  "test_s2s_dataset": [
    "dataset",
    "training_cutset_batch"
  ],
  "test_s2s_training_step": [
    "model",
    "dataset",
    "training_cutset_batch"
  ],
  "test_s2s_validation_step": [
    "model",
    "dataset",
    "training_cutset_batch"
  ],
  "test_s2s_offline_generation": [
    "model"
  ],
  "test_replace_placeholders": [],
  "test_replace_placeholders_removes_excessive_left_padding": [],
  "AUDIO_LOCATOR_TAG": [],
  "PROMPT": [],
  "prompt_formatter": [
    "model"
  ],
  "test_salm_dataset": [
    "dataset",
    "prompt_formatter",
    "training_cutset_batch"
  ],
  "test_salm_training_step": [
    "model",
    "dataset",
    "prompt_formatter",
    "training_cutset_batch"
  ],
  "test_salm_validation_step": [
    "model",
    "dataset",
    "prompt_formatter",
    "training_cutset_batch"
  ],
  "test_salm_generation": [
    "model"
  ],
  "test_salm_generation_audios_via_prompt": [
    "model",
    "tmp_path"
  ],
  "test_salm_generation_prompts_as_tensor": [
    "model"
  ],
  "TestLlavaNextSimilarityInterleavedSampleEncoder": {
    "setUpClass": [
      "cls"
    ],
    "setUp": [
      "self"
    ],
    "test_process_image": [
      "self"
    ],
    "test_encode_image_following_text": [
      "self"
    ],
    "test_encode_image_before_text": [
      "self"
    ]
  },
  "TestLlavaNextTaskEncoder": {
    "setUpClass": [
      "cls"
    ],
    "setUp": [
      "self"
    ],
    "test_batch": [
      "self"
    ],
    "test_select_samples_to_pack": [
      "self",
      "mock_predict_seq_len_with_padding",
      "mock_greedy_knapsack"
    ],
    "test_pack_selected_samples": [
      "self",
      "mock_convert_to_packed"
    ]
  },
  "TestLlavaNextSampleEncoder": {
    "setUpClass": [
      "cls"
    ],
    "setUp": [
      "self"
    ],
    "test_process_image": [
      "self"
    ],
    "test_encode": [
      "self"
    ]
  },
  "get_args": [],
  "get_parser": [],
  "compare_parameters": [
    "model1",
    "model2",
    "label1",
    "label2"
  ],
  "compare_model_outputs": [
    "original_model",
    "exported_model",
    "tokenizer"
  ],
  "run_conversion_pipeline": [
    "args"
  ],
  "sample_image": [],
  "basic_conversation": [],
  "test_conversation_initialization": [],
  "test_get_prompt_single_style": [
    "basic_conversation"
  ],
  "test_get_prompt_two_style": [],
  "test_get_prompt_mistral_vila": [],
  "test_get_prompt_nvgpt": [],
  "test_get_prompt_plain": [],
  "test_get_prompt_v0": [],
  "test_get_prompt_v1": [],
  "test_get_prompt_mistral_orca": [],
  "test_get_prompt_mistral_zephyr": [],
  "test_get_prompt_mistral_direct": [],
  "test_get_prompt_chatml_direct": [],
  "test_get_prompt_mpt": [],
  "test_get_prompt_qwen": [],
  "test_get_prompt_gemma": [],
  "test_get_prompt_nv_dpo": [],
  "test_process_image_pad": [
    "sample_image"
  ],
  "test_process_image_resize": [
    "sample_image"
  ],
  "test_process_image_default": [
    "sample_image"
  ],
  "test_process_image_base64": [
    "sample_image"
  ],
  "test_get_images": [
    "basic_conversation",
    "sample_image"
  ],
  "test_get_images_return_path": [
    "basic_conversation",
    "sample_image"
  ],
  "test_to_gradio_chatbot": [
    "basic_conversation",
    "sample_image"
  ],
  "test_copy": [],
  "test_dict": [],
  "test_dict_with_images": [
    "basic_conversation",
    "sample_image"
  ],
  "test_process_chat_template": [],
  "test_invalid_sep_style": [],
  "test_invalid_image_process_mode": [],
  "TestMLlama11B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_peft_none": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus"
    ]
  },
  "TestGemma3VL4B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_peft_lora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_different_configurations": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlava15_13B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_peft_none": [
      "self",
      "recipe_module"
    ],
    "test_parameterized_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus"
    ]
  },
  "TestMLLama90B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_peft_lora": [
      "self",
      "recipe_module"
    ],
    "test_invalid_peft_scheme": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus"
    ]
  },
  "TestLlava15_7B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_peft_lora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus"
    ]
  },
  "TestLlavaNext7B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_peft_lora": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_recipe_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus"
    ]
  },
  "TestGemma3VL27B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_peft_lora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_different_configurations": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama4OmniE16": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_performance_mode": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_peft_none": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_peft_lora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus"
    ],
    "test_finetune_recipe_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama4OmniE128": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_performance_mode": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_peft_none": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_peft_lora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus"
    ],
    "test_finetune_recipe_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestClipB32": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus"
    ]
  },
  "TestGemma3VL12B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_peft_lora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_different_configurations": [
      "self",
      "recipe_module"
    ]
  },
  "TestNevaLlama38B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer_config": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_default": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_performance_mode": [
      "self",
      "recipe_module"
    ],
    "test_recipe_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus"
    ]
  },
  "test_siglip_config_error": [],
  "test_downsample_block_basic": [],
  "TestQwenVLInferenceWrapper": {
    "setup_method": [
      "self"
    ],
    "test_init": [
      "self"
    ],
    "test_prep_inference_input_with_image": [
      "self"
    ],
    "test_prep_inference_input_empty_image_dict": [
      "self"
    ],
    "test_prep_inference_input_missing_image_keys": [
      "self"
    ],
    "test_get_batch_for_context_window": [
      "self"
    ],
    "test_get_batch_for_context_window_edge_cases": [
      "self"
    ],
    "test_forward_pass_without_pipeline_parallel": [
      "self"
    ],
    "test_forward_pass_without_pipeline_parallel_empty_input": [
      "self"
    ],
    "test_forward_pass_without_pipeline_parallel_model_error": [
      "self"
    ],
    "test_integration_prep_and_forward": [
      "self"
    ],
    "test_tensor_dimensions_validation": [
      "self"
    ],
    "test_cuda_non_blocking_flag": [
      "self"
    ]
  },
  "TestTokenizerWrapper": {
    "setup_method": [
      "self"
    ],
    "test_init": [
      "self"
    ],
    "test_detokenize": [
      "self"
    ],
    "test_tokenize": [
      "self"
    ]
  },
  "TestVLMTextGenerationController": {
    "setup_method": [
      "self"
    ],
    "test_init": [
      "self"
    ],
    "test_tokenize_prompt_with_no_image": [
      "self"
    ],
    "test_tokenize_prompt_with_image": [
      "self"
    ],
    "test_prep_inference_input": [
      "self"
    ]
  },
  "TestQwenVLTextGenerationController": {
    "setup_method": [
      "self"
    ],
    "test_init": [
      "self"
    ],
    "test_qwenvl_tokenizer_detokenize": [
      "self"
    ],
    "test_tokenize_prompt": [
      "self"
    ]
  },
  "TestIntegration": {
    "test_vlm_controller_inheritance": [
      "self"
    ],
    "test_qwenvl_controller_inheritance": [
      "self"
    ],
    "test_tokenizer_wrapper_interface": [
      "self"
    ]
  },
  "TestSetupTrainerAndRestoreModel": {
    "test_setup_trainer_and_restore_model": [
      "self",
      "mock_set_modelopt"
    ]
  },
  "TestSetupInferenceWrapper": {
    "setup_method": [
      "self"
    ],
    "test_setup_inference_wrapper_mllama": [
      "self",
      "mock_config_cls",
      "mock_wrapper_cls"
    ],
    "test_setup_inference_wrapper_llava": [
      "self",
      "mock_config_cls",
      "mock_wrapper_cls"
    ],
    "test_setup_inference_wrapper_qwenvl": [
      "self",
      "mock_config_cls",
      "mock_wrapper_cls"
    ],
    "test_setup_inference_wrapper_unknown_config": [
      "self"
    ]
  },
  "TestSetupModelAndTokenizer": {
    "setup_method": [
      "self"
    ],
    "test_setup_model_and_tokenizer_mllama": [
      "self",
      "mock_setup_wrapper",
      "mock_setup_trainer",
      "mock_model_cls",
      "mock_processor_cls",
      "mock_load_context"
    ],
    "test_setup_model_and_tokenizer_llava": [
      "self",
      "mock_setup_wrapper",
      "mock_setup_trainer",
      "mock_model_cls",
      "mock_processor_cls",
      "mock_load_context"
    ],
    "test_setup_model_and_tokenizer_qwenvl_3b": [
      "self",
      "mock_setup_wrapper",
      "mock_setup_trainer",
      "mock_model_cls",
      "mock_processor_cls",
      "mock_load_context"
    ],
    "test_setup_model_and_tokenizer_qwenvl_invalid_projector": [
      "self",
      "mock_load_context"
    ],
    "test_setup_model_and_tokenizer_qwenvl_unknown_size": [
      "self",
      "mock_load_context"
    ],
    "test_setup_model_and_tokenizer_unknown_config": [
      "self",
      "mock_load_context"
    ],
    "test_setup_model_and_tokenizer_no_trainer": [
      "self",
      "mock_setup_wrapper",
      "mock_setup_trainer",
      "mock_trainer_cls",
      "mock_strategy_cls",
      "mock_model_cls",
      "mock_processor_cls",
      "mock_load_context"
    ]
  },
  "TestGenerate": {
    "setup_method": [
      "self"
    ],
    "test_generate_qwenvl": [
      "self",
      "mock_common_params_cls",
      "mock_engine_cls",
      "mock_controller_cls"
    ],
    "test_generate_other_model": [
      "self",
      "mock_common_params_cls",
      "mock_engine_cls",
      "mock_controller_cls"
    ],
    "test_generate_with_defaults": [
      "self",
      "mock_common_params_cls",
      "mock_engine_cls",
      "mock_controller_cls"
    ]
  },
  "TestChannelAugment": {
    "test_channel_selection": [
      "self",
      "num_channels"
    ]
  },
  "TestTAC": {
    "test_average": [
      "self",
      "num_channels"
    ],
    "test_attend": [
      "self",
      "num_channels"
    ]
  },
  "TestChannelPool": {
    "test_average": [
      "self",
      "num_channels"
    ],
    "test_attention": [
      "self",
      "num_channels"
    ]
  },
  "TestAudioSpectrogram": {
    "test_audio_to_spec": [
      "self",
      "fft_length",
      "num_channels"
    ],
    "test_spec_to_audio": [
      "self",
      "fft_length",
      "num_channels"
    ],
    "test_audio_to_spectrogram_reconstruction": [
      "self",
      "fft_length",
      "num_channels",
      "magnitude_power",
      "scale"
    ],
    "test_match_reference_implementation": [
      "self",
      "fft_length",
      "num_channels",
      "magnitude_power",
      "scale"
    ],
    "test_invalid_length": [
      "self",
      "fft_length"
    ],
    "test_invalid_compression": [
      "self",
      "fft_length"
    ],
    "test_invalid_spec_to_audio_input": [
      "self",
      "fft_length"
    ],
    "test_streaming_istft_matches_offline_rectangular_center_false": [
      "self",
      "fft_length",
      "hop_div",
      "batch_size",
      "num_channels",
      "magnitude_power",
      "scale",
      "chunk_size",
      "window_type"
    ]
  },
  "TestMixtureConsistencyProjection": {
    "test_mixture_consistency": [
      "self",
      "weighting",
      "num_sources"
    ],
    "test_unsupported_weighting": [
      "self"
    ],
    "test_unsupported_inputs": [
      "self"
    ]
  },
  "mock_dataset_config": [
    "tmp_path",
    "request"
  ],
  "mask_model_rnn_params": [],
  "mask_model_rnn": [
    "mask_model_rnn_params"
  ],
  "mask_model_rnn_with_trainer_and_mock_dataset": [
    "mask_model_rnn_params",
    "mock_dataset_config"
  ],
  "mask_model_flexarray": [],
  "bf_model_flexarray": [
    "mask_model_flexarray"
  ],
  "TestMaskModelRNN": {
    "test_constructor": [
      "self",
      "mask_model_rnn"
    ],
    "test_forward_infer": [
      "self",
      "mask_model_rnn",
      "batch_size",
      "sample_len"
    ],
    "test_training_step": [
      "self",
      "mask_model_rnn_with_trainer_and_mock_dataset"
    ],
    "test_model_training": [
      "self",
      "mask_model_rnn_with_trainer_and_mock_dataset"
    ]
  },
  "TestMaskModelFlexArray": {
    "test_constructor": [
      "self",
      "mask_model_flexarray"
    ],
    "test_forward_infer": [
      "self",
      "mask_model_flexarray",
      "batch_size",
      "num_channels",
      "sample_len"
    ]
  },
  "TestBFModelFlexArray": {
    "test_constructor": [
      "self",
      "bf_model_flexarray"
    ],
    "test_forward_infer": [
      "self",
      "bf_model_flexarray",
      "batch_size",
      "num_channels",
      "sample_len"
    ]
  },
  "convert_to_dictconfig": [
    "d"
  ],
  "score_based_base_config": [],
  "test_score_based_model_init": [
    "score_based_base_config"
  ],
  "score_based_model": [
    "score_based_base_config"
  ],
  "score_based_model_with_trainer_and_mock_dataset": [
    "score_based_base_config",
    "mock_dataset_config"
  ],
  "test_score_based_model_forward": [
    "score_based_model",
    "batch_size",
    "sample_len"
  ],
  "test_score_based_model_step": [
    "score_based_model_with_trainer_and_mock_dataset"
  ],
  "test_score_based_model_training": [
    "score_based_model_with_trainer_and_mock_dataset"
  ],
  "maxine_model_fixture": [],
  "TestBNR2Model": {
    "test_constructor": [
      "self",
      "maxine_model_fixture"
    ],
    "test_forward_infer": [
      "self",
      "maxine_model_fixture",
      "batch_size",
      "sample_len"
    ]
  },
  "ncsnpp": [
    "request"
  ],
  "transformerunet": [
    "request"
  ],
  "spectrogram_ncsnpp": [
    "request"
  ],
  "spectrogram_transformerunet": [
    "request"
  ],
  "spectrogram_conformer": [],
  "mock_input_3d": [],
  "mock_input_4d": [],
  "test_ncsnpp_forward": [
    "ncsnpp",
    "mock_input_4d"
  ],
  "test_transformerunet_forward": [
    "transformerunet",
    "mock_input_3d"
  ],
  "test_spectrogram_ncsnpp_forward": [
    "spectrogram_ncsnpp",
    "mock_input_4d"
  ],
  "test_spectrogram_transformerunet_forward": [
    "spectrogram_transformerunet",
    "mock_input_4d"
  ],
  "test_spectrogram_conformer_forward": [
    "spectrogram_conformer",
    "mock_input_4d"
  ],
  "TestAudioMetricWrapper": {
    "test_metric_full_batch": [
      "self"
    ],
    "test_input_length": [
      "self"
    ],
    "test_channel": [
      "self",
      "channel"
    ]
  },
  "TestSquimMetrics": {
    "test_squim_mos": [
      "self",
      "fs"
    ],
    "test_squim_objective": [
      "self",
      "metric",
      "fs"
    ]
  },
  "TestAudioDatasets": {
    "test_list_to_multichannel": [
      "self",
      "num_channels",
      "num_targets"
    ],
    "test_processor_process_audio": [
      "self",
      "num_channels"
    ],
    "test_audio_collate_fn": [
      "self"
    ],
    "test_audio_to_target_dataset": [
      "self"
    ],
    "test_audio_to_target_dataset_with_target_list": [
      "self"
    ],
    "test_audio_to_target_dataset_for_inference": [
      "self"
    ],
    "test_audio_to_target_with_reference_dataset": [
      "self"
    ],
    "test_audio_to_target_with_embedding_dataset": [
      "self"
    ]
  },
  "TestSpectrogramToMultichannelFeatures": {
    "test_magnitude": [
      "self",
      "fft_length",
      "num_channels",
      "mag_reduction",
      "mag_power",
      "mag_normalization"
    ],
    "test_ipd": [
      "self",
      "fft_length",
      "num_channels",
      "ipd_normalization",
      "use_input_length"
    ],
    "test_num_channels": [
      "self",
      "use_ipd"
    ],
    "test_num_features": [
      "self",
      "use_ipd"
    ],
    "test_unsupported_norm": [
      "self"
    ]
  },
  "TestMaskBasedProcessor": {
    "test_mask_reference_channel": [
      "self",
      "fft_length",
      "num_channels",
      "num_masks"
    ]
  },
  "TestMaskBasedDereverb": {
    "test_wpe_convtensor": [
      "self",
      "num_channels",
      "filter_length",
      "delay"
    ],
    "test_wpe_filter": [
      "self",
      "num_channels",
      "filter_length",
      "delay"
    ],
    "test_mask_based_dereverb_init": [
      "self",
      "num_channels",
      "filter_length",
      "delay"
    ]
  },
  "TestMaskEstimator": {
    "test_flex_channels": [
      "self",
      "channel_reduction_position",
      "channel_reduction_type",
      "channel_block_type"
    ],
    "test_gss": [
      "self",
      "num_channels",
      "num_subbands",
      "num_outputs",
      "batch_size"
    ]
  },
  "TestSSLPretrainMaskingWithPatch": {
    "test_masking": [
      "self",
      "patch_size",
      "mask_fraction",
      "training"
    ],
    "test_unsupported_initialization": [
      "self"
    ]
  },
  "NUM_STEPS": [],
  "test_sb_sampler_nfe": [
    "num_steps",
    "process",
    "noise_schedule_type"
  ],
  "flow_matching_base_config_params": [],
  "flow_matching_base_config_ids": [],
  "flow_matching_base_config": [
    "request"
  ],
  "test_flow_matching_model_init": [
    "flow_matching_base_config"
  ],
  "flow_matching_model": [
    "flow_matching_base_config",
    "request"
  ],
  "flow_matching_model_with_trainer_and_mock_dataset": [
    "flow_matching_base_config",
    "mock_dataset_config"
  ],
  "test_flow_matching_model_forward": [
    "flow_matching_model",
    "batch_size",
    "sample_len",
    "eval",
    "p_cond"
  ],
  "test_flow_matching_model_step": [
    "flow_matching_model_with_trainer_and_mock_dataset"
  ],
  "test_flow_matching_model_training": [
    "flow_matching_model_with_trainer_and_mock_dataset"
  ],
  "predictive_model_ncsn": [],
  "predictive_model_conformer": [],
  "predictive_model_streaming_conformer": [],
  "predictive_model_transformer_unet_params_base": [],
  "predictive_model_conformer_unet": [],
  "predictive_model_streaming_conformer_unet": [],
  "predictive_model_transformer_unet_params": [
    "predictive_model_transformer_unet_params_base",
    "request"
  ],
  "predictive_model_transformer_unet": [
    "predictive_model_transformer_unet_params"
  ],
  "predictive_model_transformer_unet_with_trainer_and_mock_dataset": [
    "predictive_model_transformer_unet_params",
    "mock_dataset_config"
  ],
  "TestPredictiveModelNCSN": {
    "test_constructor": [
      "self",
      "predictive_model_ncsn"
    ],
    "test_forward_infer": [
      "self",
      "predictive_model_ncsn",
      "batch_size",
      "sample_len"
    ]
  },
  "TestPredictiveModelConformer": {
    "test_constructor": [
      "self",
      "predictive_model_conformer"
    ],
    "test_forward_infer": [
      "self",
      "predictive_model_conformer",
      "batch_size",
      "sample_len"
    ]
  },
  "TestPredictiveModelStreamingConformer": {
    "test_constructor": [
      "self",
      "predictive_model_streaming_conformer"
    ],
    "test_forward_infer": [
      "self",
      "predictive_model_streaming_conformer",
      "batch_size",
      "sample_len"
    ]
  },
  "TestPredictiveModelTransformerUNet": {
    "test_constructor": [
      "self",
      "predictive_model_transformer_unet"
    ],
    "test_forward_infer": [
      "self",
      "predictive_model_transformer_unet",
      "batch_size",
      "sample_len"
    ],
    "test_adaptive_rms_ebabled_fails": [
      "self",
      "predictive_model_transformer_unet",
      "batch_size",
      "sample_len"
    ],
    "test_training_step": [
      "self",
      "predictive_model_transformer_unet_with_trainer_and_mock_dataset"
    ],
    "test_model_training": [
      "self",
      "predictive_model_transformer_unet_with_trainer_and_mock_dataset"
    ]
  },
  "TestPredictiveModelConformerUNet": {
    "test_constructor": [
      "self",
      "predictive_model_conformer_unet"
    ],
    "test_forward_infer": [
      "self",
      "predictive_model_conformer_unet",
      "batch_size",
      "sample_len"
    ]
  },
  "TestPredictiveModelStreamingConformerUNet": {
    "test_constructor": [
      "self",
      "predictive_model_streaming_conformer_unet"
    ],
    "test_forward_infer": [
      "self",
      "predictive_model_streaming_conformer_unet",
      "batch_size",
      "sample_len"
    ]
  },
  "TestDataSimulationUtils": {
    "test_check_angle": [
      "self"
    ],
    "test_wrap_to_180": [
      "self"
    ],
    "test_placement_range": [
      "self"
    ],
    "test_convert_rir_to_mc": [
      "self",
      "num_mics",
      "num_sources"
    ]
  },
  "TestArrayGeometry": {
    "test_array_geometry": [
      "self",
      "mic_spacing",
      "num_mics",
      "axis"
    ]
  },
  "TestRoomSimulation": {
    "max_diff_tol": [],
    "test_simulate_room_mix": [
      "self",
      "test_data_dir"
    ]
  },
  "schroedinger_bridge_model_ncsn_params": [],
  "schroedinger_bridge_model_ncsn": [
    "schroedinger_bridge_model_ncsn_params"
  ],
  "schroedinger_bridge_model_ncsn_with_trainer_and_mock_dataset": [
    "schroedinger_bridge_model_ncsn_params",
    "mock_dataset_config"
  ],
  "TestSchroedingerBridgeModelNCSN": {
    "test_constructor": [
      "self",
      "schroedinger_bridge_model_ncsn"
    ],
    "test_forward_infer": [
      "self",
      "schroedinger_bridge_model_ncsn",
      "batch_size",
      "sample_len"
    ],
    "test_training_step": [
      "self",
      "schroedinger_bridge_model_ncsn_with_trainer_and_mock_dataset"
    ],
    "test_model_training": [
      "self",
      "schroedinger_bridge_model_ncsn_with_trainer_and_mock_dataset"
    ]
  },
  "TestAudioLosses": {
    "test_calculate_mean": [
      "self",
      "num_channels",
      "use_mask",
      "use_input_length"
    ],
    "test_calculate_sdr_scale_and_convolution_invariant": [
      "self"
    ],
    "test_calculate_mse_input_and_mask": [
      "self"
    ],
    "test_calculate_mse_invalid_dimensions": [
      "self"
    ],
    "test_calculate_mae_input_and_mask": [
      "self"
    ],
    "test_calculate_mae_invalid_dimensions": [
      "self"
    ],
    "test_sdr": [
      "self",
      "num_channels"
    ],
    "test_sdr_weighted": [
      "self",
      "num_channels"
    ],
    "test_sdr_input_length": [
      "self",
      "num_channels"
    ],
    "test_sdr_scale_invariant": [
      "self",
      "num_channels"
    ],
    "test_sdr_binary_mask": [
      "self",
      "num_channels"
    ],
    "test_sdr_max": [
      "self",
      "num_channels",
      "sdr_max"
    ],
    "test_target_calculation": [
      "self",
      "num_channels",
      "filter_length",
      "use_mask",
      "use_input_length"
    ],
    "test_sdr_convolution_invariant": [
      "self",
      "num_channels",
      "filter_length"
    ],
    "test_sdr_scale_and_convolution_invariant": [
      "self"
    ],
    "test_sdr_length_and_mask": [
      "self"
    ],
    "test_sdr_invalid_weight": [
      "self"
    ],
    "test_sdr_invalid_reduction": [
      "self"
    ],
    "test_mse": [
      "self",
      "num_channels",
      "ndim"
    ],
    "test_mse_weighted": [
      "self",
      "num_channels",
      "ndim"
    ],
    "test_mse_input_length": [
      "self",
      "num_channels",
      "ndim"
    ],
    "test_mse_invalid_weight": [
      "self"
    ],
    "test_mse_invalid_reduction": [
      "self"
    ],
    "test_mse_invalid_ndim": [
      "self"
    ],
    "test_mae": [
      "self",
      "num_channels",
      "ndim"
    ],
    "test_mae_weighted": [
      "self",
      "num_channels",
      "ndim"
    ],
    "test_mae_input_length": [
      "self",
      "num_channels",
      "ndim"
    ],
    "test_mae_invalid_weight": [
      "self"
    ],
    "test_mae_invalid_reduction": [
      "self"
    ],
    "test_mae_invalid_ndim": [
      "self"
    ],
    "test_maxine_combined_loss": [
      "self",
      "test_data_dir"
    ]
  },
  "TIMES_MIN": [],
  "TIMES_MAX": [],
  "test_euler_sampler_nfe": [
    "num_steps",
    "estimator_target"
  ],
  "test_time_generation_bounds_optimal_transport": [
    "time_min",
    "time_max"
  ],
  "test_time_generation_bounds_optimal_transport_negative_examples": [
    "time_min",
    "time_max"
  ],
  "TestGenerateApproximateNoiseField": {
    "test_theoretical_coherence_matrix": [
      "self",
      "num_mics",
      "mic_spacing",
      "fft_length",
      "sample_rate",
      "field"
    ],
    "test_generate_approximate_noise_field": [
      "self",
      "num_mics",
      "mic_spacing",
      "fft_length",
      "sample_rate",
      "field",
      "save_figures"
    ]
  },
  "TestAudioUtilsElements": {
    "test_rms": [
      "self"
    ],
    "test_db_conversion": [
      "self"
    ],
    "test_get_segment_start": [
      "self"
    ],
    "test_calculate_sdr_numpy": [
      "self"
    ],
    "test_calculate_sdr_numpy_scale_invariant": [
      "self"
    ],
    "test_convmtx_mc": [
      "self",
      "num_channels",
      "filter_length",
      "delay"
    ],
    "test_toeplitz": [
      "self",
      "num_channels",
      "filter_length",
      "num_samples"
    ]
  },
  "TestCovarianceMatrix": {
    "test_calculate_covariance_matrix_vs_psd": [
      "self",
      "num_channels",
      "num_freq",
      "use_mask",
      "normalize_mask",
      "mask_type"
    ],
    "test_calculate_covariance_matrix": [
      "self",
      "num_channels",
      "num_freq",
      "use_mask",
      "normalize_mask",
      "mask_type"
    ],
    "test_mismatch_dimensions": [
      "self",
      "num_channels",
      "num_freq"
    ]
  },
  "ModularAudioGPTModel": {
    "log": [
      "self"
    ]
  },
  "setup_module": [],
  "llm_model_config": [],
  "trainer_config": [],
  "perception_model_config": [],
  "test_batch": [],
  "TestModularAudioGPTModel": {
    "test_init_and_train": [
      "self",
      "llm_model_config",
      "perception_model_config",
      "trainer_config"
    ],
    "test_prepare_llm_input": [
      "self",
      "llm_model_config",
      "perception_model_config",
      "trainer_config",
      "test_batch"
    ],
    "test_training_step": [
      "self",
      "llm_model_config",
      "perception_model_config",
      "trainer_config",
      "test_batch"
    ],
    "test_validation_step": [
      "self",
      "llm_model_config",
      "perception_model_config",
      "trainer_config",
      "test_batch"
    ],
    "test_predict_step": [
      "self",
      "llm_model_config",
      "perception_model_config",
      "trainer_config",
      "test_batch"
    ],
    "test_concat_multi_features": [
      "self",
      "llm_model_config",
      "perception_model_config",
      "trainer_config"
    ],
    "test_shift_tokens_by_multi_audios": [
      "self"
    ]
  },
  "test_speechllm_dataset": [
    "tokenizer",
    "cuts"
  ],
  "llama_tokenizer": [
    "capsys",
    "tmp_path_factory"
  ],
  "test_speechllm_dataset_prompt_template": [
    "llama_tokenizer",
    "cuts"
  ],
  "test_speechllm_dataset_tokens_to_generate_increases_seq_len": [
    "llama_tokenizer",
    "cuts"
  ],
  "test_audio_example_with_prompt_emmett_t5": [
    "cuts_path",
    "tokenizer"
  ],
  "nmt_paths": [
    "tmp_path_factory"
  ],
  "test_text_example_with_prompt_emmett_t5": [
    "nmt_paths",
    "tokenizer"
  ],
  "CrashCallback": {
    "__init__": [
      "self",
      "crash_step"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ]
  },
  "train_data": [
    "data_path",
    "tokenizer_path",
    "index_mapping_dir",
    "seq_length"
  ],
  "small_llama_cfg": [
    "seq_length"
  ],
  "StopBeforeEnd": {
    "__init__": [
      "self",
      "stop_on_step"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ]
  },
  "AssertOptimizerParamGroupsHaveAtLeastTwoWeightDecays": {
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "MCoreModelAttributeValidator": {
    "__init__": [
      "self",
      "attr_dict"
    ],
    "_check_attrs": [
      "self",
      "target"
    ],
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "MiscAttributeValidator": {
    "__init__": [
      "self",
      "attr_dict"
    ],
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_end": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "verify_distcp_dir": [
    "ckpt_path"
  ],
  "verify_ckpt_dir": [
    "model_ckpt",
    "max_steps",
    "val_check_interval",
    "exp_dir",
    "dist_ckpts"
  ],
  "create_verify_precision": [
    "precision"
  ],
  "Llama3ConfigCI": {},
  "logger": [],
  "Llama3Config145M": {},
  "CrashException": {},
  "CheckResumeStepCallback": {
    "__init__": [
      "self",
      "expected_resume_step"
    ],
    "on_train_start": [
      "self",
      "trainer"
    ]
  },
  "get_trainer": [
    "args",
    "callbacks",
    "plugins",
    "strategy"
  ],
  "get_megatron_strategy": [
    "args",
    "async_save"
  ],
  "get_optimizer": [
    "bf16_enabled"
  ],
  "get_my_local_ckpt_node_dir": [
    "log_dir",
    "rank"
  ],
  "find_latest_local_ckpt_step": [
    "local_ckpt_node_dir",
    "global_rank"
  ],
  "run_test": [
    "args_dict"
  ],
  "OrdTokenizer": {
    "__init__": [
      "self",
      "vocab_size",
      "num_reserved_tokens",
      "special_token_names"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "text_to_ids": [
      "self",
      "text"
    ]
  },
  "squad": [
    "mbs",
    "gbs"
  ],
  "get_mistral_expected_ckpt": [],
  "get_mixtral_expected_ckpt": [],
  "mixtral_8x7b": [],
  "mistral_7b": [],
  "make_lora": [
    "use_exclude"
  ],
  "parse_args": [],
  "TokenizerType": [],
  "T": [],
  "ExampleConfig": {
    "configure_model": [
      "self"
    ]
  },
  "MSELossReduction": {
    "forward": [
      "self",
      "batch",
      "forward_out"
    ],
    "reduce": [
      "self",
      "losses_reduced_per_micro_batch"
    ]
  },
  "some_first": [
    "seq"
  ],
  "get_dtype_device": [
    "torch_object"
  ],
  "batch_collator": [
    "batches"
  ],
  "PassthroughLossReduction": {
    "forward": [
      "self",
      "batch",
      "forward_out"
    ],
    "reduce": [
      "self",
      "forward_out"
    ]
  },
  "LitAutoEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "batch",
      "batch_idx"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ],
    "test_loss_reduction": [
      "self"
    ],
    "predict_loss_reduction": [
      "self"
    ],
    "configure_model": [
      "self"
    ]
  },
  "MnistItem": {},
  "MNISTCustom": {
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "LossLoggingCallback": {
    "__init__": [
      "self"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ],
    "on_test_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "on_validation_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "on_validation_epoch_end": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_test_epoch_end": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "MNISTDataModule": {
    "__init__": [
      "self",
      "data_dir",
      "batch_size"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ]
  },
  "test_train_mnist_litautoencoder_with_megatron_strategy_single_gpu": [],
  "run_train_mnist_litautoencoder_with_megatron_strategy_single_gpu": [],
  "make_squad_hf_dataset": [
    "data_path",
    "tokenizer"
  ],
  "align_labels": [
    "logits",
    "labels"
  ],
  "DummyJitModel": {
    "__init__": [
      "self",
      "tokenizer",
      "has_jit"
    ],
    "configure_model": [
      "self"
    ],
    "forward": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch"
    ]
  },
  "TestValidateConfig": {
    "reset_configs": [
      "self"
    ],
    "test_model_validation": [
      "self"
    ],
    "test_data_validation": [
      "self"
    ],
    "test_trainer_validatiopn": [
      "self"
    ]
  },
  "TestImportCkpt": {
    "test_output_path_exists_no_overwrite": [
      "self"
    ]
  },
  "TestExportCkpt": {
    "test_output_path_exists_no_overwrite": [
      "self"
    ]
  },
  "TorchAdam": {
    "__init__": [
      "self",
      "config",
      "lr_scheduler"
    ],
    "optimizers": [
      "self",
      "model"
    ]
  },
  "test_train_mnist_litautoencoder_with_fsdp_strategy_single_gpu": [],
  "run_train_mnist_litautoencoder_with_fsdp_strategy_single_gpu": [],
  "remove_module_from_key": [
    "x"
  ],
  "remove_module_from_dict_keys": [
    "d"
  ],
  "mock_average_losses": [
    "losses"
  ],
  "mock_distributed": [
    "mocker"
  ],
  "test_hard_negative_ranking_loss": [],
  "test_average_losses_mock": [],
  "test_bert_in_batch_negatives_loss": [],
  "test_bert_loss_with_sop": [],
  "test_bert_loss_forward_with_sop": [
    "mocker"
  ],
  "test_bert_in_batch_negatives_init": [],
  "test_bert_in_batch_forward_validation": [],
  "test_sentence_order_prediction": [
    "tensor_input",
    "expected"
  ],
  "test_huggingface_bert_base_config": [],
  "test_huggingface_bert_large_config": [],
  "test_megatron_bert_base_config": [],
  "test_megatron_bert_large_config": [],
  "MockConfig": {},
  "TestBertTransforms": {
    "mock_ctx": [
      "self"
    ]
  },
  "TestBertBase": {
    "sample_batch": [
      "self"
    ],
    "sample_packed_batch": [
      "self"
    ],
    "basic_config": [
      "self"
    ],
    "test_get_batch_on_this_cp_rank_no_cp": [
      "self",
      "sample_batch"
    ],
    "test_get_packed_seq_params": [
      "self",
      "sample_packed_batch"
    ],
    "test_bert_config_initialization": [
      "self",
      "basic_config"
    ],
    "test_bert_model_initialization": [
      "self",
      "basic_config"
    ],
    "test_bert_forward_step": [
      "self",
      "basic_config",
      "sample_batch"
    ],
    "test_bert_forward_step_with_tokentypes": [
      "self",
      "basic_config",
      "sample_batch"
    ],
    "test_bert_forward_step_with_packed_seqs": [
      "self",
      "basic_config",
      "sample_batch"
    ],
    "test_bert_model_training_step": [
      "self",
      "basic_config"
    ],
    "test_bert_model_validation_step": [
      "self",
      "basic_config"
    ],
    "test_get_batch_with_context_parallel": [
      "self",
      "sample_batch"
    ]
  },
  "TestBertEmbeddingHead": {
    "embedding_head": [
      "self"
    ],
    "test_embedding_head_forward": [
      "self",
      "embedding_head"
    ],
    "test_embedding_head_masked_tokens": [
      "self",
      "embedding_head"
    ]
  },
  "TestBertEmbeddingConfig": {
    "test_large_config": [
      "self"
    ],
    "test_mini_config": [
      "self"
    ]
  },
  "TestBertEmbeddingModel": {
    "mock_tokenizer": [
      "self"
    ],
    "model_config": [
      "self"
    ],
    "model": [
      "self",
      "model_config",
      "mock_tokenizer"
    ]
  },
  "test_bert_embedding_data_step": [],
  "test_bert_embedding_data_step_tuple_input": [],
  "test_bert_embedding_forward_step": [],
  "test_training_loss_reduction_initialization": [],
  "test_validation_loss_reduction_initialization": [],
  "TestBertSpec": {
    "setup_parallel_state": [
      "self"
    ],
    "mock_config": [
      "self"
    ],
    "mock_submodules_config": [
      "self"
    ]
  },
  "test_llama31_nemotron_nano_8b_config": [],
  "test_llama31_nemotron_70b_config": [],
  "test_llama33_nemotron_super_49b_config": [],
  "test_llama33_nemotron_ultra_253b_config": [],
  "test_mixtral_config": [],
  "test_mixtral_config_8x3b": [],
  "test_mixtral_config_8x7b": [],
  "test_mixtral_config_8x22b": [],
  "test_chatglm_config": [],
  "test_chatglm2_config_6b": [],
  "test_chatglm3_config_6b": [],
  "skip_if_no_gpu": [],
  "init_distributed_parallel_state": [
    "world_size",
    "rank",
    "tensor_model_parallel_size",
    "context_parallel_size",
    "pipeline_model_parallel_size"
  ],
  "dtype": [
    "request"
  ],
  "config_type": [
    "request"
  ],
  "test_config": [
    "dtype",
    "config_type"
  ],
  "hyena_config": [],
  "operator_type": [
    "request"
  ],
  "hyena_mixer": [
    "test_config",
    "hyena_config",
    "operator_type"
  ],
  "test_mixer_initialization": [
    "hyena_mixer",
    "test_config",
    "hyena_config",
    "operator_type"
  ],
  "test_mixer_forward_pass": [
    "hyena_mixer"
  ],
  "test_mixer_dtypes": [
    "hyena_mixer",
    "dtype"
  ],
  "test_mixer_state_dict": [
    "hyena_mixer",
    "operator_type"
  ],
  "test_qwen2_config": [],
  "test_qwen2_config_500m": [],
  "test_qwen2_config_1p5b": [],
  "test_qwen25_config_3B": [],
  "test_qwen2_config_7b": [],
  "test_qwen2_config_72b": [],
  "test_mistral_config7b": [],
  "test_mistral_nemo_config_12b": [],
  "test_mistral_nemo_config_123b": [],
  "test_mistral_small3_config_24b": [],
  "test_gemma3_1b_config": [],
  "test_gemma3_4b_config": [],
  "test_gemma3_12b_config": [],
  "test_gemma3_27b_config": [],
  "test_llama_config": [],
  "test_llama3_config": [],
  "test_llama2_config_7b": [],
  "test_llama2_config_13b": [],
  "test_llama2_config_70b": [],
  "test_llama3_config_8b": [],
  "test_llama3_config_70b": [],
  "test_llama31_config": [],
  "test_llama31_config_8b": [],
  "test_llama31_config_70b": [],
  "test_llama31_config_405b": [],
  "test_codellama_config_7b": [],
  "test_codellama_config_13b": [],
  "test_codellama_config_34b": [],
  "test_codellama_config_70b": [],
  "test_Phi3_config": [],
  "test_phi3configmini": [],
  "test_hyena_base_config": [],
  "test_hyena_7b_config": [],
  "test_hyena_nv_7b_config": [],
  "test_hyena_1b_config": [],
  "test_hyena_nv_1b_config": [],
  "test_hyena_40b_config": [],
  "test_hyena_nv_40b_config": [],
  "test_hyena_7b_arc_long_context_config": [],
  "test_hyena_40b_arc_long_context_config": [],
  "test_hyena_test_config": [],
  "test_hyena_nv_test_config": [],
  "test_convert_hyena": [],
  "sample_hidden_states": [],
  "sample_attention_mask": [],
  "test_pool_avg": [
    "sample_hidden_states",
    "sample_attention_mask"
  ],
  "test_pool_cls": [
    "sample_hidden_states",
    "sample_attention_mask"
  ],
  "test_pool_last": [
    "sample_hidden_states",
    "sample_attention_mask"
  ],
  "test_pool_invalid": [],
  "TestPoolingModule": {
    "test_pooling_avg": [
      "self",
      "sample_hidden_states",
      "sample_attention_mask"
    ],
    "test_pooling_cls": [
      "self",
      "sample_hidden_states",
      "sample_attention_mask"
    ],
    "test_batch_size_one": [
      "self",
      "pool_type"
    ]
  },
  "TestLlamaBidirectionalHFAdapter": {
    "mock_model": [
      "self"
    ],
    "adapter": [
      "self",
      "mock_model"
    ],
    "test_forward": [
      "self",
      "adapter",
      "sample_hidden_states",
      "sample_attention_mask"
    ]
  },
  "test_get_llama_bidirectional_hf_model": [
    "mock_tokenizer_cls",
    "mock_model_cls"
  ],
  "TestLlamaBidirectionalForSequenceClassification": {
    "config": [
      "self"
    ],
    "model": [
      "self",
      "config"
    ],
    "test_model_initialization": [
      "self",
      "model",
      "config"
    ],
    "test_forward_classification": [
      "self",
      "model"
    ],
    "test_forward_regression": [
      "self"
    ],
    "test_forward_multi_label": [
      "self"
    ],
    "test_different_pooling_types": [
      "self",
      "config"
    ],
    "test_forward_without_labels": [
      "self",
      "model"
    ],
    "test_temperature_scaling": [
      "self",
      "config"
    ],
    "test_return_dict_option": [
      "self",
      "model",
      "return_dict"
    ]
  },
  "config_name_to_hf_id": [],
  "strip_digits_from_end": [
    "s"
  ],
  "get_modulename_from_config_name": [
    "config_name"
  ],
  "generate_twolayer_checkpoints": [
    "config_name",
    "hf_id"
  ],
  "import_from_hf": [
    "config_name",
    "hf_path"
  ],
  "init_parallel_state": [
    "tensor_model_parallel_size",
    "pipeline_model_parallel_size",
    "context_parallel_size"
  ],
  "zigzag_split_across_group_ranks": [
    "data",
    "group",
    "seq_dim"
  ],
  "zigzag_gather_from_group_ranks": [
    "data",
    "group",
    "seq_dim"
  ],
  "MixerModuleWrapper": {
    "__init__": [
      "self",
      "seq_len",
      "operator_type",
      "use_subquadratic_ops"
    ],
    "forward": [
      "self",
      "x",
      "_use_cp"
    ]
  },
  "MockProjConv": {
    "__init__": [
      "self",
      "kernel_size"
    ]
  },
  "MockMixer": {
    "__init__": [
      "self",
      "kernel_size",
      "use_conv_bias"
    ]
  },
  "mock_b2b_causal_conv1d": [
    "x",
    "weight_proj",
    "weight_mixer",
    "skip_bias"
  ],
  "test_b2b_causal_conv1d_module_initialization": [
    "operator_type"
  ],
  "test_b2b_causal_conv1d_module_weight_extraction": [
    "operator_type"
  ],
  "test_b2b_causal_conv1d_module_bias_handling": [
    "use_conv_bias",
    "operator_type"
  ],
  "test_b2b_causal_conv1d_module_invalid_operator": [],
  "test_b2b_causal_conv1d_module_different_shapes": [
    "batch_size",
    "seq_len"
  ],
  "test_b2b_causal_conv1d_module_different_kernel_sizes": [
    "kernel_size"
  ],
  "test_b2b_causal_conv1d_module_invalid_input": [],
  "test_b2b_causal_conv1d_module_dtype_handling": [],
  "test_b2b_causal_conv1d_module_device_handling": [],
  "test_b2b_causal_conv1d_effective_padding_size": [],
  "test_zigzag_get_overlapping_patches": [],
  "test_exchange_overlapping_regions_causal_forward": [
    "monkeypatch"
  ],
  "test_zigzag_indices": [],
  "test_ensure_divisibility": [],
  "test_get_groups_and_group_sizes": [],
  "test_init_methods": [],
  "test_fftconv_func": [],
  "test_fftconv_func_high_dimensional_input": [],
  "test_fftconv_func_use_subquadratic_ops_success": [
    "mock_fft_causal_conv1d",
    "mock_is_fused_supported"
  ],
  "test_fftconv_func_use_subquadratic_ops_not_supported": [
    "mock_is_fused_supported"
  ],
  "TestFallbackFunctions": {
    "test_causal_conv1d_fallback": [
      "self",
      "mock_causal_conv1d"
    ],
    "test_b2b_causal_conv1d_fallback": [
      "self",
      "mock_b2b_causal_conv1d"
    ],
    "test_fft_causal_conv1d_fallback": [
      "self",
      "mock_fft_causal_conv1d"
    ],
    "test_is_fused_supported_fallback": [
      "self",
      "mock_is_fused_supported"
    ],
    "test_fallback_functions_import_error_messages": [
      "self"
    ],
    "test_einops_import_error": [
      "self"
    ]
  },
  "_munge_key_megatron_to_nemo2": [
    "k"
  ],
  "_munge_sharded_tensor_key_megatron_to_nemo2": [
    "v"
  ],
  "_key_in_filter": [
    "k",
    "filter"
  ],
  "MegatronModelType": [],
  "_reset_microbatch_calculator": [],
  "_dummy": [],
  "_teardown_apex_megatron_cuda": [],
  "_initialize_distributed_parallel_state": [
    "devices",
    "tensor_model_parallel_size",
    "pipeline_model_parallel_size",
    "pipeline_model_parallel_split_rank",
    "context_parallel_size",
    "interactive"
  ],
  "distributed_model_parallel_state": [
    "seed",
    "devices",
    "tensor_model_parallel_size",
    "pipeline_model_parallel_size",
    "pipeline_model_parallel_split_rank",
    "context_parallel_size",
    "interactive"
  ],
  "load_weights_sharded_inplace_nemo2_to_mcore": [
    "model",
    "distributed_checkpoint_dir",
    "skip_keys_with_these_prefixes",
    "ckpt_format"
  ],
  "test_golden_values": [
    "use_te"
  ],
  "mixer": [
    "test_config",
    "hyena_config",
    "operator_type"
  ],
  "mixer_kernel": [
    "test_config",
    "hyena_config",
    "operator_type"
  ],
  "mixer_kernel_hyena_only": [
    "test_config",
    "hyena_config"
  ],
  "test_implicit_filter": [
    "mixer_kernel_hyena_only"
  ],
  "test_subquadratic_ops_kernel": [
    "mixer",
    "mixer_kernel",
    "config_type",
    "operator_type"
  ],
  "test_gemma_config": [],
  "test_gemma_config_2b": [],
  "test_gemma_config_7b": [],
  "test_code_gemma_config_2b": [],
  "test_code_gemma_config_7b": [],
  "test_ssm_config": [],
  "test_base_mamba_config_130m": [],
  "test_base_mamba_config_370m": [],
  "test_base_mamba_config_780m": [],
  "test_base_mamba_config_1_3b": [],
  "test_base_mamba_config_2_7b": [],
  "test_nvidia_mamba_config_8b": [],
  "test_nvidia_mamba_hybrid_config_8b": [],
  "test_nemotronh_config_4b": [],
  "test_nemotronh_config_8b": [],
  "test_nemotronh_config_47b": [],
  "test_nemotronh_config_56b": [],
  "test_nemotron_nano_9b_v2": [],
  "test_nemotron_nano_12b_v2": [],
  "simple_parallel_state": [],
  "TestParallelHyenaOperator": {
    "operator": [
      "self",
      "test_config",
      "hyena_config"
    ],
    "test_initialization": [
      "self",
      "operator"
    ],
    "test_gpu_forward": [
      "self",
      "operator",
      "test_config"
    ]
  },
  "TestParallelShortHyenaOperator": {
    "operator": [
      "self",
      "test_config",
      "hyena_config"
    ],
    "test_initialization": [
      "self",
      "operator"
    ],
    "test_gpu_forward": [
      "self",
      "operator",
      "test_config"
    ],
    "test_fast_causal_conv_short_conv_len_validation": [
      "self",
      "test_config",
      "hyena_config"
    ]
  },
  "TestParallelShortHyenaOperatorWithConvBias": {
    "operator": [
      "self",
      "test_config",
      "hyena_config"
    ],
    "test_initialization": [
      "self",
      "operator"
    ],
    "test_gpu_forward": [
      "self",
      "operator",
      "test_config"
    ]
  },
  "TestParallelCausalDepthwiseConv1d": {
    "operator": [
      "self",
      "test_config",
      "hyena_config"
    ],
    "test_initialization": [
      "self",
      "operator"
    ],
    "test_gpu_forward": [
      "self",
      "operator",
      "test_config"
    ]
  },
  "setup_tensors": [],
  "test_adjust_filter_shape_for_broadcast": [],
  "test_parallel_fir_short_filter": [
    "setup_tensors"
  ],
  "test_parallel_fir_long_filter": [
    "setup_tensors"
  ],
  "test_parallel_fir_gated_bias": [
    "setup_tensors"
  ],
  "test_parallel_iir": [],
  "test_step_fir": [],
  "test_step_fir_flip_filter": [],
  "test_step_iir": [],
  "test_prefill_via_modal_fft": [],
  "add_test_args": [
    "parser"
  ],
  "megatron_model_provider": [
    "pre_process",
    "post_process"
  ],
  "test_starcoder_config": [],
  "test_starcoder_config_15b": [],
  "test_starcoder2_config": [],
  "test_starcoder2_config_3b": [],
  "test_starcoder2_config_7b": [],
  "test_starcoder2_config_15b": [],
  "test_baichuan2_config": [],
  "test_baichuan2_config_7b": [],
  "test_nemotron_config": [],
  "test_nemotron3_config_4b": [],
  "test_nemotron3_config_8b": [],
  "test_nemotron3_config_22b": [],
  "test_nemotron4_config_15b": [],
  "test_nemotron4_config_340b": [],
  "test_gpt_config_126m": [],
  "test_gpt_config_5b": [],
  "test_gpt_config_7b": [],
  "test_gpt_config_20b": [],
  "test_gpt_config_40b": [],
  "test_gpt_config_175b": [],
  "test_reranker_base_config": [],
  "test_llama32_reranker_1b_config": [],
  "test_llama32_reranker_500m_config": [],
  "test_reranker_loss": [
    "mock_cp_size",
    "mock_dp_group",
    "mock_world_size",
    "mock_all_reduce"
  ],
  "test_reranker_model_pooling": [],
  "MockModule": {
    "__init__": [
      "self"
    ]
  },
  "TestFNMixin": {
    "setup_method": [
      "self"
    ],
    "test_forall_true": [
      "self"
    ],
    "test_forall_false": [
      "self"
    ],
    "test_map": [
      "self"
    ],
    "test_walk": [
      "self"
    ],
    "test_freeze": [
      "self"
    ],
    "test_unfreeze": [
      "self"
    ]
  },
  "TestActivationFunctions": {
    "input_tensor": [
      "self"
    ],
    "larger_input_tensor": [
      "self"
    ],
    "test_openai_gelu": [
      "self",
      "input_tensor"
    ],
    "test_quick_gelu": [
      "self",
      "input_tensor"
    ],
    "test_squared_relu": [
      "self",
      "input_tensor"
    ],
    "test_activation_shapes": [
      "self",
      "larger_input_tensor"
    ],
    "test_gelu_implementation_equivalence": [
      "self"
    ],
    "test_squared_relu_0": [
      "self"
    ],
    "test_gradient_flow": [
      "self"
    ]
  },
  "CustomMLP": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SharedMLP": {
    "__init__": [
      "self",
      "shared"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "add_relu": [
    "x"
  ],
  "add_relu_named": [
    "x",
    "name",
    "to_replace"
  ],
  "add_relu_first": [
    "x",
    "i"
  ],
  "TestWalkModule": {
    "test_map_identity": [
      "self"
    ],
    "test_map_transform": [
      "self"
    ],
    "test_walk_custom_module": [
      "self"
    ],
    "test_walk_shared_module": [
      "self"
    ],
    "test_leaf_only": [
      "self"
    ]
  },
  "TestWalkListModule": {
    "test_walk_module_container": [
      "self",
      "module_container"
    ],
    "test_walk_module_container_with_kwargs": [
      "self",
      "module_container"
    ],
    "test_walk_module_container_with_recursion": [
      "self",
      "module_container"
    ]
  },
  "TestWalkDictModule": {
    "test_walk_module_dict_identity": [
      "self"
    ],
    "test_walk_module_dict_transform": [
      "self"
    ]
  },
  "count_parameters": [
    "model",
    "ignore_keys"
  ],
  "TestNemotron3_22B_16K": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_valid_trainer_parallelism": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen25_500M": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestNemotron3_8B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ]
  },
  "TestNemotronNano9Bv2": {
    "recipe": [
      "self"
    ],
    "test_model_config": [
      "self",
      "recipe"
    ],
    "test_model": [
      "self",
      "recipe"
    ],
    "test_trainer": [
      "self",
      "recipe"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestMamba2_370M": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestLlama3_70B_16k": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_valid_trainer_parallelism": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestChatGLM3_6B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestMamba2_8B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestLlama3_8B_16k": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_valid_trainer_parallelism": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestNemotronH56B": {
    "recipe": [
      "self"
    ],
    "test_model_config": [
      "self",
      "recipe"
    ],
    "test_model": [
      "self",
      "recipe"
    ],
    "test_trainer": [
      "self",
      "recipe"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestMamba2Hybrid8B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestMamba2_130M": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestGPT3_175B": {
    "test_model": [
      "self"
    ],
    "test_trainer_default_settings": [
      "self"
    ],
    "test_trainer_custom_settings": [
      "self"
    ],
    "test_trainer_with_callbacks": [
      "self"
    ],
    "test_pretrain_recipe_default_settings": [
      "self"
    ],
    "test_pretrain_recipe_custom_settings": [
      "self"
    ],
    "test_pretrain_performance_optimizations": [
      "self"
    ],
    "test_pretrain_recipe_with_performance_mode": [
      "self"
    ]
  },
  "TestLlama31NemotronNano8B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_finetune_sequence_length_settings": [
      "self",
      "recipe_module"
    ],
    "test_invalid_peft_scheme": [
      "self",
      "recipe_module"
    ],
    "test_valid_peft_schemes": [
      "self",
      "recipe_module",
      "peft_scheme"
    ]
  },
  "TestLlamaEmbedding_1B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_packed_sequence": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations_without_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen3_8B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestBERT_110M": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ]
  },
  "TestNemotronH8B": {
    "recipe": [
      "self"
    ],
    "test_model_config": [
      "self",
      "recipe"
    ],
    "test_model": [
      "self",
      "recipe"
    ],
    "test_trainer": [
      "self",
      "recipe"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestBERT_340M": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ]
  },
  "TestStarcoder2_15B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_packed_sequence": [
      "self",
      "recipe_module"
    ]
  },
  "test_torchrun_with_explicit_devices": [
    "mock_device_count",
    "mock_cuda_available"
  ],
  "test_torchrun_raises_error_without_cuda": [
    "mock_cuda_available"
  ],
  "TestNemotron4_15B_64K": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_valid_trainer_parallelism": [
      "self",
      "recipe_module"
    ]
  },
  "TestStarcoder2_3B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_packed_sequence": [
      "self",
      "recipe_module"
    ]
  },
  "TestMistral": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestMixtral8x7B_64k": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_valid_trainer_parallelism": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestMixtral8x22B_64k": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_valid_trainer_parallelism": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama2_7B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_packed_sequence": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations_with_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen3_600M": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestT5_3B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama33NemotronSuper49B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_no_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_lora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_invalid_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestMamba2_2_7B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestLlama32_1B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_packed_sequence": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen2_500M": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestDeepSeekV3": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestBaichuan2_7B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen3_235B_A22B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestHyena1B": {
    "test_tokenizer": [
      "self"
    ],
    "test_model_default": [
      "self"
    ],
    "test_model_with_parameters": [
      "self",
      "tp_comm_overlap",
      "seq_length"
    ],
    "test_pretrain_recipe_default": [
      "self"
    ],
    "test_pretrain_recipe_with_parameters": [
      "self",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_finetune_recipe_with_parameters": [
      "self"
    ],
    "test_tokenizer_docstring": [
      "self"
    ],
    "test_model_docstring": [
      "self"
    ],
    "test_pretrain_recipe_docstring": [
      "self"
    ],
    "test_finetune_recipe_docstring": [
      "self"
    ]
  },
  "TestHyenaBase": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_tokenizer_recipe": [
      "self",
      "recipe_module"
    ],
    "test_invalid_model_size": [
      "self",
      "recipe_module"
    ],
    "test_wandb_logger": [
      "self",
      "recipe_module"
    ],
    "test_callbacks": [
      "self",
      "recipe_module"
    ],
    "test_nsys_profiling": [
      "self",
      "recipe_module"
    ]
  },
  "TestGemma2_2B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen2_72B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestNemotronNano12Bv2": {
    "recipe": [
      "self"
    ],
    "test_model_config": [
      "self",
      "recipe"
    ],
    "test_model": [
      "self",
      "recipe"
    ],
    "test_trainer": [
      "self",
      "recipe"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestGemma2_9B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama31NemotronUltra253B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_no_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_lora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_invalid_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestLlama4_E128": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_finetune_peft_options": [
      "self",
      "recipe_module"
    ],
    "test_packed_sequence_options": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama31Nemotron70B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_model_types": [
      "self",
      "recipe_module",
      "model_type"
    ],
    "test_invalid_model_type": [
      "self",
      "recipe_module"
    ],
    "test_invalid_peft_scheme": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations": [
      "self",
      "recipe_module"
    ]
  },
  "TestBertEmbedding": {
    "test_bert_embedding_model_110m": [
      "self"
    ],
    "test_bert_embedding_model_340m": [
      "self"
    ],
    "test_bert_embedding_model_invalid_version": [
      "self"
    ],
    "test_bert_trainer_default_settings": [
      "self"
    ],
    "test_bert_trainer_custom_settings": [
      "self"
    ],
    "test_bert_trainer_with_callbacks": [
      "self"
    ],
    "test_bert_trainer_ddp_settings": [
      "self"
    ]
  },
  "TestNemotron3_22B_64K": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_valid_trainer_parallelism": [
      "self",
      "recipe_module"
    ]
  },
  "TestHyena7B": {
    "test_tokenizer": [
      "self"
    ],
    "test_model_default": [
      "self"
    ],
    "test_model_with_parameters": [
      "self",
      "tp_comm_overlap",
      "seq_length"
    ],
    "test_pretrain_recipe_default": [
      "self"
    ],
    "test_pretrain_recipe_with_parameters": [
      "self",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_finetune_recipe_with_parameters": [
      "self"
    ],
    "test_tokenizer_docstring": [
      "self"
    ],
    "test_model_docstring": [
      "self"
    ],
    "test_pretrain_recipe_docstring": [
      "self"
    ],
    "test_finetune_recipe_docstring": [
      "self"
    ]
  },
  "TestLlama3_8B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestE5_340M": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_custom_values": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_finetune_recipe_with_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestStarcoder_15B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama32_3B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_packed_sequence": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestNemotron4_340B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ]
  },
  "TestMixtral8x7B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestNemotron3_4B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestDeepSeekV2Lite": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen3_1P7B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen2_7B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestNemotronH47B": {
    "recipe": [
      "self"
    ],
    "test_model_config": [
      "self",
      "recipe"
    ],
    "test_model": [
      "self",
      "recipe"
    ],
    "test_trainer": [
      "self",
      "recipe"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestStarcoder2_7B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_packed_sequence": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama3_8B_64k": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_valid_trainer_parallelism": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen25_7B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama31_70B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_packed_sequence": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations_with_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestGemma2B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestMamba2_1_3B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestQwen3_30B_A3B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama4_E16": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_finetune_peft_options": [
      "self",
      "recipe_module"
    ],
    "test_packed_sequence_options": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama3_70B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestNemotron3_22B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestNemotronH4B": {
    "recipe": [
      "self"
    ],
    "test_model_config": [
      "self",
      "recipe"
    ],
    "test_model": [
      "self",
      "recipe"
    ],
    "test_trainer": [
      "self",
      "recipe"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestQwen3_32B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestHyena40B": {
    "test_tokenizer": [
      "self"
    ],
    "test_model_default": [
      "self"
    ],
    "test_model_with_parameters": [
      "self",
      "tp_comm_overlap",
      "seq_length"
    ],
    "test_pretrain_recipe_default": [
      "self"
    ],
    "test_pretrain_recipe_with_parameters": [
      "self",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_finetune_recipe_with_parameters": [
      "self"
    ],
    "test_tokenizer_docstring": [
      "self"
    ],
    "test_model_docstring": [
      "self"
    ],
    "test_pretrain_recipe_docstring": [
      "self"
    ],
    "test_finetune_recipe_docstring": [
      "self"
    ]
  },
  "TestGemma2_27B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen2_1p5B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestMamba2_780M": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestLlama3_70B_64k": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_valid_trainer_parallelism": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestMistralSmall3_24B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestNemotron4_15B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ]
  },
  "TestGemma7B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestDeepSeekV2": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama31_8B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_packed_sequence": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen25_72B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_insufficient_nodes": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestNemotron": {
    "recipe_module": [
      "self"
    ],
    "test_nemotron_model": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ],
    "test_nemotron_trainer": [
      "self",
      "recipe_module"
    ],
    "test_trainer_with_different_gpu_configs": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_trainer_with_different_parallelism_options": [
      "self",
      "recipe_module",
      "tensor_model_parallel_size",
      "pipeline_model_parallel_size",
      "context_parallel_size",
      "sequence_parallel"
    ]
  },
  "TestT5_220M": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen25_32B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "test_bf16_mixed_config": [],
  "test_fp16_mixed_config": [],
  "test_bf16_with_fp8_mixed_config": [],
  "test_fp16_with_fp8_mixed_config": [],
  "test_bf16_with_mxfp8_mixed_config": [],
  "test_fp16_with_mxfp8_mixed_config": [],
  "test_bf16_with_fp8_current_scaling_mixed_config": [],
  "test_fp16_with_fp8_current_scaling_mixed_config": [],
  "test_bf16_with_fp8_subchannel_scaling_mixed_config": [],
  "test_fp16_with_fp8_subchannel_scaling_mixed_config": [],
  "TestQwen25_1p5B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestMixtral8x7B_16k": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_valid_trainer_parallelism": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen3_14B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama3_8B_128k": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_valid_trainer_parallelism": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestGemma3_1B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_packed_sequence": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen3_4B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestNemotron4_15B_16K": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_valid_trainer_parallelism": [
      "self",
      "recipe_module"
    ]
  },
  "TestQwen25_14B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestPhi3Mini4kInstruct": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer_default_settings": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_dora": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_invalid_peft": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_with_packed_sequence": [
      "self",
      "recipe_module"
    ]
  },
  "TestMixtral8x22B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestT5_11B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe_with_different_configurations": [
      "self",
      "recipe_module",
      "num_nodes",
      "num_gpus_per_node"
    ],
    "test_trainer_parallelism_options": [
      "self",
      "recipe_module"
    ],
    "test_model_config_parameters": [
      "self",
      "recipe_module"
    ]
  },
  "TestLlama31_405B": {
    "recipe_module": [
      "self"
    ],
    "test_model": [
      "self",
      "recipe_module"
    ],
    "test_trainer": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe": [
      "self",
      "recipe_module"
    ],
    "test_finetune_recipe_without_peft": [
      "self",
      "recipe_module"
    ],
    "test_pretrain_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations": [
      "self",
      "recipe_module"
    ],
    "test_finetune_performance_optimizations_with_peft": [
      "self",
      "recipe_module"
    ]
  },
  "TestDropUnexpectedParams": {
    "setup_method": [
      "self"
    ],
    "test_valid_config_stays_same": [
      "self"
    ],
    "test_config_updates": [
      "self"
    ],
    "test_nested_config_updates": [
      "self"
    ]
  },
  "GPT_PARAMS": [],
  "GPT_PARALLELISM": [],
  "BERT_PARAMS": [],
  "T5_PARAMS": [],
  "TestUtils": {
    "test_calculate_model_size": [
      "self"
    ],
    "test_calculate_train_time": [
      "self"
    ],
    "test_modify_cfg": [
      "self"
    ],
    "test_calculate_model_size_utils": [
      "self"
    ],
    "test_model_size_params": [
      "self"
    ],
    "test_gpt_grid_search": [
      "self"
    ],
    "test_bert_grid_search": [
      "self"
    ],
    "test_t5_grid_search": [
      "self"
    ]
  },
  "get_auto_configs": [
    "configs"
  ],
  "TestGenerateConfgis": {
    "test_llama_model": [
      "self"
    ],
    "test_mistral_model": [
      "self"
    ],
    "test_mixtral_model": [
      "self"
    ],
    "test_gemma_model": [
      "self"
    ],
    "test_nemotron_model": [
      "self"
    ],
    "test_finetune_lora": [
      "self"
    ],
    "test_finetune_dora": [
      "self"
    ],
    "test_finetune": [
      "self"
    ]
  },
  "NUMBA_RNNT_LOSS_AVAILABLE": [],
  "hybrid_asr_model_with_prompt": [
    "test_data_dir"
  ],
  "TestEncDecHybridRNNTCTCBPEModelWithPrompt": {
    "test_constructor": [
      "self",
      "hybrid_asr_model_with_prompt"
    ],
    "test_forward": [
      "self",
      "hybrid_asr_model_with_prompt"
    ],
    "test_predict_step": [
      "self",
      "hybrid_asr_model_with_prompt"
    ],
    "test_save_restore_artifact": [
      "self",
      "hybrid_asr_model_with_prompt"
    ],
    "test_save_restore_artifact_spe": [
      "self",
      "hybrid_asr_model_with_prompt",
      "test_data_dir"
    ],
    "test_save_restore_artifact_agg": [
      "self",
      "hybrid_asr_model_with_prompt",
      "test_data_dir"
    ],
    "test_vocab_change": [
      "self",
      "test_data_dir",
      "hybrid_asr_model_with_prompt"
    ],
    "test_decoding_change": [
      "self",
      "hybrid_asr_model_with_prompt"
    ],
    "test_decoding_type_change": [
      "self",
      "hybrid_asr_model_with_prompt"
    ],
    "test_input_output_types_with_prompt": [
      "self",
      "hybrid_asr_model_with_prompt"
    ],
    "test_prompt_feature_initialization": [
      "self",
      "hybrid_asr_model_with_prompt"
    ],
    "test_prompt_truncation": [
      "self",
      "hybrid_asr_model_with_prompt"
    ]
  },
  "conformer_ctc_bpe_model": [],
  "TestContextGraphCTC": {
    "test_graph_building": [
      "self"
    ]
  },
  "TestCTCWordSpotter": {
    "test_run_word_spotter": [
      "self",
      "test_data_dir",
      "conformer_ctc_bpe_model"
    ]
  },
  "TestContextBiasingUtils": {
    "test_merge_alignment_with_ws_hyps": [
      "self",
      "conformer_ctc_bpe_model"
    ],
    "test_compute_fscore": [
      "self"
    ]
  },
  "getattr2": [
    "object",
    "attr"
  ],
  "TestASRLocalAttention": {
    "test_forward": [
      "self"
    ],
    "test_change_save_restore": [
      "self"
    ],
    "test_train": [
      "self",
      "global_tokens",
      "global_tokens_spacing"
    ]
  },
  "ssl_model": [],
  "denoise_mlm_ssl_model": [],
  "TestSSLModel": {
    "test_constructor": [
      "self",
      "ssl_model"
    ],
    "test_contr_nonquant": [
      "self",
      "ssl_model"
    ],
    "test_contr_mlm": [
      "self",
      "ssl_model"
    ],
    "test_contr_mlm_multi": [
      "self",
      "ssl_model"
    ]
  },
  "TestDenoiseMLMSSLModel": {
    "test_forward": [
      "self",
      "denoise_mlm_ssl_model"
    ],
    "test_forward_masked": [
      "self",
      "denoise_mlm_ssl_model"
    ]
  },
  "asr_model": [
    "test_data_dir"
  ],
  "TestEncDecCTCModel": {
    "test_constructor": [
      "self",
      "asr_model"
    ],
    "test_forward": [
      "self",
      "asr_model"
    ],
    "test_predict_step": [
      "self",
      "asr_model"
    ],
    "test_save_restore_artifact": [
      "self",
      "asr_model"
    ],
    "test_save_restore_artifact_spe": [
      "self",
      "asr_model",
      "test_data_dir"
    ],
    "test_save_restore_artifact_agg": [
      "self",
      "asr_model",
      "test_data_dir"
    ],
    "test_vocab_change": [
      "self",
      "test_data_dir",
      "asr_model"
    ],
    "test_decoding_change": [
      "self",
      "asr_model"
    ],
    "test_ASRDatasetConfig_for_AudioToBPEDataset": [
      "self"
    ],
    "test_ASRDatasetConfig_for_TarredAudioToBPEDataset": [
      "self"
    ]
  },
  "TestASRSamplers": {
    "labels": [],
    "test_ssb_sampler": [
      "self"
    ]
  },
  "max_symbols_setup": [],
  "TestEncDecRNNTModel": {
    "test_constructor": [
      "self",
      "asr_model"
    ],
    "test_forward": [
      "self",
      "asr_model"
    ],
    "test_predict_step": [
      "self",
      "asr_model"
    ],
    "test_vocab_change": [
      "self",
      "asr_model"
    ],
    "test_change_conv_asr_se_context_window": [
      "self",
      "asr_model"
    ],
    "test_change_conv_asr_se_context_window_no_config_update": [
      "self",
      "asr_model"
    ],
    "test_decoding_change": [
      "self",
      "asr_model"
    ],
    "test_GreedyRNNTInferConfig": [
      "self"
    ],
    "test_GreedyBatchedRNNTInferConfig": [
      "self"
    ],
    "test_BeamRNNTInferConfig": [
      "self"
    ],
    "test_greedy_decoding": [
      "self",
      "greedy_class",
      "loop_labels"
    ],
    "test_multiblank_rnnt_greedy_decoding": [
      "self",
      "greedy_class"
    ],
    "test_greedy_multi_decoding": [
      "self",
      "greedy_class"
    ],
    "test_greedy_decoding_stateless_decoder": [
      "self",
      "greedy_class",
      "loop_labels",
      "context_size"
    ],
    "test_greedy_multi_decoding_stateless_decoder": [
      "self",
      "greedy_class"
    ],
    "test_greedy_decoding_preserve_alignment": [
      "self",
      "greedy_class",
      "loop_labels"
    ],
    "test_greedy_decoding_preserve_frame_confidence": [
      "self",
      "greedy_class",
      "loop_labels"
    ],
    "test_greedy_decoding_max_symbols_alignment": [
      "self",
      "max_symbols_setup",
      "greedy_class",
      "max_symbols_per_step",
      "loop_labels"
    ],
    "test_greedy_decoding_max_symbols_confidence_incorrect_max_symbols": [
      "self",
      "max_symbols_setup",
      "greedy_class",
      "max_symbols_per_step",
      "loop_labels"
    ],
    "test_greedy_decoding_max_symbols_confidence": [
      "self",
      "max_symbols_setup",
      "greedy_class",
      "max_symbols_per_step",
      "loop_labels"
    ],
    "test_beam_decoding": [
      "self",
      "beam_config"
    ],
    "test_beam_decoding_preserve_alignments": [
      "self",
      "beam_config"
    ],
    "test_greedy_decoding_SampledRNNTJoint": [
      "self",
      "greedy_class",
      "loop_labels"
    ],
    "test_beam_decoding_SampledRNNTJoint": [
      "self",
      "beam_config"
    ]
  },
  "RNNTTestHelper": {
    "wrap_and_call": [
      "fn",
      "acts",
      "labels",
      "device",
      "input_lengths",
      "target_lengths"
    ]
  },
  "RnntLossSampleData": {
    "get_sample_small": [
      "cls"
    ],
    "get_sample_small_blank_last": [
      "cls"
    ],
    "get_sample_medium": [
      "cls"
    ],
    "get_sample_small_random": [
      "cls",
      "blank_first",
      "device"
    ],
    "get_sample_medium_random_var_size": [
      "cls",
      "blank_first",
      "device"
    ]
  },
  "rnnt_test_helper": [],
  "rnn_loss_sample_data": [],
  "fast_conformer_transducer_model": [],
  "fast_conformer_ctc_model": [],
  "fast_conformer_hybrid_model": [],
  "canary_1b_flash": [],
  "canary_1b_v2": [],
  "hybrid_rnnt_ctc_bpe_model_with_prompt": [],
  "speech_classification_model": [],
  "speaker_label_model": [],
  "citrinet_model": [],
  "citrinet_rnnt_model": [],
  "conformer_model": [],
  "squeezeformer_model": [],
  "TestEncDecMultiTaskModel": {
    "test_constructor": [
      "self",
      "asr_model"
    ],
    "test_forward": [
      "self",
      "asr_model"
    ],
    "test_training_step": [
      "self",
      "deterministic_rng",
      "asr_model"
    ],
    "test_validation_step": [
      "self",
      "deterministic_rng",
      "asr_model"
    ],
    "test_save_restore_artifact": [
      "self",
      "asr_model"
    ],
    "test_restore_with_timestamps_asr_model": [
      "self",
      "canary_1b_v2"
    ],
    "test_decoding_change": [
      "self",
      "asr_model"
    ],
    "test_prompt_change": [
      "self",
      "asr_model"
    ],
    "test_prompt_change_subclass": [
      "self",
      "asr_model"
    ],
    "test_transcribe_single_file": [
      "self",
      "asr_model",
      "test_data_dir"
    ],
    "test_transcribe_single_file_translation": [
      "self",
      "asr_model",
      "test_data_dir"
    ],
    "test_transcribe_return_hypothesis": [
      "self",
      "asr_model",
      "test_data_dir"
    ],
    "test_transcribe_tensor": [
      "self",
      "asr_model",
      "test_data_dir"
    ],
    "test_build_tokenizer": [
      "self",
      "asr_model",
      "test_data_dir"
    ],
    "test_predict_step": [
      "self",
      "asr_model",
      "test_data_dir"
    ],
    "test_FrameBatchMultiTaskAED": [
      "self",
      "asr_model",
      "test_data_dir"
    ],
    "test_FrameBatchMultiTaskAED_with_timestamps": [
      "self",
      "canary_1b_flash"
    ]
  },
  "test_prompted_dataset": [
    "asr_model"
  ],
  "canary2_tokenizer": [
    "asr_model",
    "tmp_path"
  ],
  "test_prompted_dataset_canary2": [
    "canary2_tokenizer"
  ],
  "test_aed_timestamp_processing": [],
  "test_aed_forced_aligned_timestamps": [
    "canary_1b_v2"
  ],
  "test_aed_parallel_chunking": [
    "canary_1b_v2"
  ],
  "hybrid_asr_model": [
    "test_data_dir"
  ],
  "TestEncDecHybridRNNTCTCBPEModel": {
    "test_constructor": [
      "self",
      "hybrid_asr_model"
    ],
    "test_forward": [
      "self",
      "hybrid_asr_model"
    ],
    "test_predict_step": [
      "self",
      "hybrid_asr_model"
    ],
    "test_save_restore_artifact": [
      "self",
      "hybrid_asr_model"
    ],
    "test_save_restore_artifact_spe": [
      "self",
      "hybrid_asr_model",
      "test_data_dir"
    ],
    "test_save_restore_artifact_agg": [
      "self",
      "hybrid_asr_model",
      "test_data_dir"
    ],
    "test_vocab_change": [
      "self",
      "test_data_dir",
      "hybrid_asr_model"
    ],
    "test_decoding_change": [
      "self",
      "hybrid_asr_model"
    ],
    "test_decoding_type_change": [
      "self",
      "hybrid_asr_model"
    ]
  },
  "TestJasperBlock": {
    "jasper_base_config": [],
    "check_module_exists": [
      "self",
      "module",
      "cls"
    ],
    "test_basic_block": [
      "self"
    ],
    "test_residual_block": [
      "self"
    ],
    "test_basic_block_repeat": [
      "self"
    ],
    "test_basic_block_repeat_stride": [
      "self"
    ],
    "test_basic_block_repeat_stride_last": [
      "self"
    ],
    "test_basic_block_repeat_separable": [
      "self"
    ],
    "test_basic_block_stride": [
      "self"
    ],
    "test_residual_block_stride": [
      "self"
    ],
    "test_residual_block_activations": [
      "self"
    ],
    "test_residual_block_normalizations": [
      "self"
    ],
    "test_residual_block_se": [
      "self"
    ],
    "test_residual_block_asymmetric_pad_future_contexts": [
      "self"
    ],
    "test_residual_block_asymmetric_pad_future_context_fallback": [
      "self"
    ],
    "test_padding_size_conv1d": [
      "self"
    ]
  },
  "TestParallelBlock": {
    "contrust_jasper_block": [],
    "test_blocks_with_same_input_output_channels_sum_residual": [
      "self"
    ],
    "test_blocks_with_different_input_output_channels_sum_residual": [
      "self"
    ],
    "test_blocks_with_same_input_output_channels_conv_residual": [
      "self"
    ],
    "test_blocks_with_different_input_output_channels_conv_residual": [
      "self"
    ],
    "test_single_block": [
      "self"
    ],
    "test_tower_dropout": [
      "self"
    ]
  },
  "TestSelectChannels": {
    "num_samples": [],
    "max_diff_tol": [],
    "test_single_channel_input": [
      "self",
      "channel_selector"
    ],
    "test_multi_channel_input": [
      "self",
      "num_channels",
      "channel_selector"
    ],
    "test_select_more_channels_than_available": [
      "self",
      "num_channels",
      "channel_selector"
    ]
  },
  "TestAudioSegment": {
    "sample_rate": [],
    "signal_duration_sec": [],
    "max_diff_tol": [],
    "num_samples": [
      "self"
    ],
    "test_init_single_channel": [
      "self",
      "num_channels",
      "channel_selector"
    ],
    "test_from_file": [
      "self",
      "num_channels",
      "channel_selector"
    ],
    "test_noise_perturb_channels": [
      "self",
      "data_channels",
      "noise_channels"
    ],
    "test_silence_perturb": [
      "self"
    ],
    "test_audio_segment_from_file": [
      "self",
      "tmpdir",
      "num_channels",
      "channel_selectors",
      "sample_rate"
    ],
    "test_audio_segment_multichannel_with_list": [
      "self",
      "tmpdir",
      "num_channels",
      "channel_selectors",
      "offset",
      "duration"
    ],
    "test_audio_segment_trim_match": [
      "self",
      "tmpdir",
      "target_sr"
    ]
  },
  "TestFusedBatchNorm1d": {
    "test_constructor": [
      "self"
    ],
    "test_from_batchnorm": [
      "self"
    ]
  },
  "TestReplaceBNWithFusedBN": {
    "test_replace_bn_with_fused_bn": [
      "self"
    ],
    "test_replace_bn_with_fused_bn_all": [
      "self"
    ]
  },
  "TestEncDecMultiTalkerRNNTBPEModel": {
    "test_constructor": [
      "self",
      "asr_model"
    ],
    "test_forward": [
      "self",
      "asr_model"
    ],
    "test_speaker_target_setting": [
      "self",
      "asr_model"
    ]
  },
  "NestedRNNTModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "setup_training_data": [],
    "setup_validation_data": [],
    "transcribe": []
  },
  "TestEncDecRNNTBPEModel": {
    "test_constructor": [
      "self",
      "asr_model"
    ],
    "test_forward": [
      "self",
      "asr_model"
    ],
    "test_predict_step": [
      "self",
      "asr_model"
    ],
    "test_save_restore_artifact": [
      "self",
      "asr_model"
    ],
    "test_save_restore_artifact_spe": [
      "self",
      "asr_model",
      "test_data_dir"
    ],
    "test_save_restore_artifact_agg": [
      "self",
      "asr_model",
      "test_data_dir"
    ],
    "test_vocab_change": [
      "self",
      "test_data_dir",
      "asr_model"
    ],
    "test_decoding_change": [
      "self",
      "asr_model"
    ],
    "test_save_restore_nested_model": [
      "self"
    ]
  },
  "DEVICES": [],
  "n_gpu_lm": [
    "test_data_dir"
  ],
  "kenlm_wrapper": [
    "test_data_dir"
  ],
  "TestNGramGPULanguageModel": {
    "test_load": [
      "self",
      "test_data_dir"
    ],
    "test_initial_states": [
      "self",
      "n_gpu_lm",
      "kenlm_wrapper",
      "bos",
      "batch_size",
      "device"
    ],
    "test_triton_vs_pytorch_random_states": [
      "self",
      "n_gpu_lm",
      "batch_size",
      "num_iterations"
    ],
    "test_final": [
      "self",
      "n_gpu_lm",
      "kenlm_wrapper",
      "bos",
      "device"
    ],
    "test_sentences": [
      "self",
      "n_gpu_lm",
      "kenlm_wrapper",
      "bos",
      "eos",
      "device"
    ],
    "test_save_load_nemo": [
      "self",
      "tmp_path",
      "test_data_dir"
    ],
    "test_save_load_from_file": [
      "self",
      "tmp_path",
      "test_data_dir"
    ]
  },
  "test_lhotse_asr_dataset": [
    "tokenizer"
  ],
  "test_lhotse_asr_dataset_metadata": [
    "tokenizer"
  ],
  "test_context_graph": [],
  "test_boosting_tree": [
    "test_context_graph"
  ],
  "TestGPUBoostingTreeModel": {
    "test_building_context_graph": [
      "self",
      "test_context_graph"
    ],
    "test_advance_method": [
      "self",
      "test_boosting_tree",
      "device",
      "batch_size"
    ],
    "test_get_final_method": [
      "self",
      "test_boosting_tree",
      "device"
    ],
    "test_boosting_tree_inference": [
      "self",
      "test_boosting_tree",
      "device"
    ],
    "test_triton_vs_pytorch_consistency": [
      "self",
      "test_context_graph"
    ],
    "test_eos_handling": [
      "self",
      "test_context_graph"
    ],
    "test_boosting_tree_model_from_config": [
      "self",
      "conformer_ctc_bpe_model",
      "tmp_path"
    ]
  },
  "decode_chars": [
    "tokens",
    "token_length",
    "mapping"
  ],
  "decode_subwords": [
    "tokens",
    "token_length",
    "tokenizer"
  ],
  "TestASRDatasets": {
    "labels": [],
    "test_tarred_dataset": [
      "self",
      "test_data_dir"
    ],
    "test_tarred_dataset_filter": [
      "self",
      "test_data_dir"
    ],
    "test_mismatch_in_model_dataloader_config": [
      "self",
      "caplog"
    ],
    "test_tarred_bpe_dataset": [
      "self",
      "test_data_dir"
    ],
    "test_dali_char_dataset": [
      "self",
      "test_data_dir"
    ],
    "test_dali_bpe_dataset": [
      "self",
      "test_data_dir"
    ],
    "test_dali_char_vs_ref_dataset": [
      "self",
      "test_data_dir"
    ],
    "test_tarred_dali_char_dataset": [
      "self",
      "test_data_dir"
    ],
    "test_dali_tarred_char_vs_ref_dataset": [
      "self",
      "test_data_dir"
    ],
    "test_feature_to_text_char_dataset": [
      "self"
    ],
    "test_feature_to_text_bpe_dataset": [
      "self",
      "test_data_dir"
    ],
    "test_feature_with_rttm_to_text_char_dataset": [
      "self"
    ],
    "test_feature_with_rttm_to_text_bpe_dataset": [
      "self",
      "test_data_dir"
    ]
  },
  "TestUtilityFunctions": {
    "test_cache_datastore_manifests": [
      "self",
      "cache_audio"
    ]
  },
  "TestStochasticDepth": {
    "test_stochastic_depth_model_creation": [
      "self"
    ],
    "test_stochastic_depth_forward": [
      "self"
    ]
  },
  "TestBypassPreEncode": {
    "test_bypass_pre_encode_forward": [
      "self"
    ],
    "test_error_shape_invalid_bypass_pre_encode_forward": [
      "self"
    ]
  },
  "test_preprocessor_invariant_to_padding": [
    "deterministic_rng",
    "length"
  ],
  "test_canary_encoder_invariant_to_padding": [
    "deterministic_rng",
    "length"
  ],
  "test_conformer_inference_invariant_to_batch_size": [
    "deterministic_rng"
  ],
  "special_tokenizer_path": [
    "tmp_path_factory"
  ],
  "lang_tokenizer_path": [
    "tmp_path_factory"
  ],
  "test_canary_tokenizer_build_special_tokenizer": [
    "tmp_path"
  ],
  "test_canary_tokenizer_init_from_cfg": [
    "special_tokenizer_path",
    "lang_tokenizer_path"
  ],
  "jasper_encoder_config": [
    "num_layers"
  ],
  "conformer_encoder_config": [],
  "squeezeformer_encoder_config": [],
  "TestInterCTCLoss": {
    "test_forward": [
      "self",
      "model_class",
      "encoder_config",
      "apply_at_layers",
      "loss_weights"
    ]
  },
  "TestASRSubsamplingConvChunking": {
    "test_forward": [
      "self"
    ]
  },
  "TestEncDecHybridRNNTCTCModel": {
    "test_constructor": [
      "self",
      "hybrid_asr_model"
    ],
    "test_forward": [
      "self",
      "hybrid_asr_model"
    ],
    "test_predict_step": [
      "self",
      "hybrid_asr_model"
    ],
    "test_vocab_change": [
      "self",
      "hybrid_asr_model"
    ],
    "test_decoding_change": [
      "self",
      "hybrid_asr_model"
    ],
    "test_decoding_type_change": [
      "self",
      "hybrid_asr_model"
    ],
    "test_GreedyRNNTInferConfig": [
      "self"
    ],
    "test_GreedyBatchedRNNTInferConfig": [
      "self"
    ],
    "test_BeamRNNTInferConfig": [
      "self"
    ],
    "test_greedy_decoding": [
      "self",
      "greedy_class",
      "loop_labels"
    ],
    "test_greedy_multi_decoding": [
      "self",
      "greedy_class"
    ],
    "test_greedy_decoding_stateless_decoder": [
      "self",
      "greedy_class",
      "loop_labels",
      "context_size"
    ],
    "test_greedy_multi_decoding_stateless_decoder": [
      "self",
      "greedy_class"
    ],
    "test_greedy_decoding_preserve_alignment": [
      "self",
      "greedy_class",
      "loop_labels"
    ],
    "test_beam_decoding": [
      "self",
      "beam_config"
    ],
    "test_beam_decoding_preserve_alignments": [
      "self",
      "beam_config"
    ],
    "test_greedy_decoding_SampledRNNTJoint": [
      "self",
      "greedy_class",
      "loop_labels"
    ],
    "test_beam_decoding_SampledRNNTJoint": [
      "self",
      "beam_config"
    ]
  },
  "TestASRModulesBasicTests": {
    "test_AudioToMelSpectrogramPreprocessor_config": [
      "self"
    ],
    "test_AudioToMelSpectrogramPreprocessor_batch": [
      "self"
    ],
    "test_AudioToMelSpectrogramPreprocessor_gpu": [
      "self"
    ],
    "test_SpectrogramAugmentationr_legacy": [
      "self"
    ],
    "test_SpectrogramAugmentationr_vectorized": [
      "self"
    ],
    "test_SpectrogramAugmentationr_numba_kernel": [
      "self",
      "caplog"
    ],
    "test_SpectrogramAugmentationr_config": [
      "self"
    ],
    "test_CropOrPadSpectrogramAugmentation": [
      "self"
    ],
    "test_CropOrPadSpectrogramAugmentation_config": [
      "self"
    ],
    "test_MaskedPatchAugmentation": [
      "self"
    ],
    "test_MaskedPatchAugmentation_config": [
      "self"
    ],
    "test_RNNTDecoder": [
      "self"
    ],
    "test_RNNTJoint": [
      "self"
    ],
    "test_HATJoint": [
      "self"
    ]
  },
  "fastpitch_model_path": [
    "fastpitch_model",
    "tmp_path_factory"
  ],
  "conformer_ctc_bpe_bn_model": [],
  "conformer_ctc_bpe_bn_model_path": [
    "conformer_ctc_bpe_bn_model",
    "tmp_path_factory"
  ],
  "conformer_rnnt_bpe_bn_model": [],
  "conformer_rnnt_bpe_bn_model_path": [
    "conformer_rnnt_bpe_bn_model",
    "tmp_path_factory"
  ],
  "asr_model_ctc_bpe_config": [
    "test_data_dir"
  ],
  "asr_tts_ctc_bpe_model": [
    "asr_model_ctc_bpe_config",
    "fastpitch_model_path"
  ],
  "TestASRWithTTSModel": {
    "test_from_pretrained_ctc_model": [
      "self",
      "fastpitch_model_path",
      "conformer_ctc_bpe_bn_model_path"
    ],
    "test_from_pretrained_rnnt_model": [
      "self",
      "fastpitch_model_path",
      "conformer_rnnt_bpe_bn_model_path"
    ],
    "test_from_asr_config": [
      "self",
      "asr_model_ctc_bpe_config",
      "fastpitch_model_path"
    ],
    "test_save_restore": [
      "self",
      "asr_tts_ctc_bpe_model"
    ],
    "test_save_restore_asr": [
      "self",
      "asr_tts_ctc_bpe_model"
    ],
    "test_from_pretrained_ctc_model_fused_bn": [
      "self",
      "fastpitch_model_path",
      "conformer_ctc_bpe_bn_model_path"
    ]
  },
  "TestFilterbankFeatures": {
    "test_seq_len": [
      "self"
    ],
    "test_random_stft_sizes": [
      "self"
    ],
    "test_random_stft_sizes_exact_pad": [
      "self"
    ]
  },
  "frame_classification_model": [],
  "TestEncDecClassificationModel": {
    "test_constructor": [
      "self",
      "speech_classification_model"
    ],
    "test_forward": [
      "self",
      "speech_classification_model"
    ],
    "test_vocab_change": [
      "self",
      "speech_classification_model"
    ],
    "test_transcription": [
      "self",
      "speech_classification_model",
      "test_data_dir"
    ],
    "test_EncDecClassificationDatasetConfig_for_AudioToSpeechLabelDataset": [
      "self"
    ]
  },
  "TestEncDecFrameClassificationModel": {
    "test_reshape_labels": [
      "self",
      "frame_classification_model",
      "logits_len",
      "labels_len"
    ],
    "test_EncDecClassificationDatasetConfig_for_AudioToMultiSpeechLabelDataset": [
      "self"
    ],
    "test_frame_classification_model": [
      "self",
      "frame_classification_model"
    ]
  },
  "build_char_tokenizer_with_vocabulary": [
    "vocabulary"
  ],
  "TestWordErrorRate": {
    "vocabulary": [],
    "char_tokenizer": [],
    "__string_to_ctc_tensor": [
      "self",
      "txt",
      "use_tokenizer",
      "as_logprobs"
    ],
    "__reference_string_to_tensor": [
      "self",
      "txt",
      "use_tokenizer"
    ],
    "get_wer": [
      "self",
      "wer",
      "prediction",
      "reference",
      "use_tokenizer"
    ],
    "test_wer_function": [
      "self"
    ],
    "test_wer_metric_simple": [
      "self",
      "batch_dim_index",
      "test_wer_bpe"
    ],
    "test_wer_metric_randomized": [
      "self",
      "test_wer_bpe"
    ],
    "test_wer_metric_decode": [
      "self",
      "test_wer_bpe"
    ],
    "test_wer_metric_return_hypothesis": [
      "self",
      "batch_dim_index",
      "test_wer_bpe"
    ],
    "test_wer_metric_subword_return_hypothesis": [
      "self",
      "batch_dim_index",
      "test_wer_bpe"
    ],
    "get_wer_ctc": [
      "self",
      "prediction",
      "reference",
      "test_wer_bpe"
    ],
    "decode_token_to_str_with_vocabulary_mock": [
      "self",
      "ids"
    ],
    "get_wer_rnnt": [
      "self",
      "prediction",
      "reference",
      "batch_dim_index",
      "test_wer_bpe"
    ],
    "test_rnnt_wer_metric_simple": [
      "self",
      "batch_dim_index",
      "test_wer_bpe"
    ],
    "test_rnnt_wer_metric_randomized": [
      "self",
      "test_wer_bpe"
    ],
    "test_char_decoding_logprobs": [
      "self"
    ],
    "test_subword_decoding_logprobs": [
      "self"
    ],
    "test_char_decoding_labels": [
      "self"
    ],
    "test_subword_decoding_labels": [
      "self"
    ]
  },
  "TestBLEUHelperFunctions": {
    "test_get_bleu_tokenizers_from_cuts_missing_tokenizer": [
      "self"
    ],
    "test_move_dimension_to_the_front": [
      "self"
    ]
  },
  "TestBLEUMetric": {
    "vocabulary": [],
    "char_tokenizer": [],
    "create_mock_decoding": [
      "self",
      "decode_type"
    ],
    "__reference_string_to_tensor": [
      "self",
      "txt"
    ],
    "test_bleu_initialization": [
      "self",
      "batch_dim_index",
      "decode_type"
    ],
    "test_bleu_update_basic": [
      "self"
    ],
    "test_bleu_update_empty_predictions": [
      "self"
    ],
    "test_bleu_update_different_batch_dims": [
      "self",
      "batch_dim_index"
    ],
    "test_bleu_with_cuts_tokenizers": [
      "self"
    ],
    "test_bleu_cuts_length_mismatch": [
      "self"
    ],
    "test_bleu_perfect_match": [
      "self"
    ],
    "test_bleu_no_match": [
      "self"
    ],
    "test_bleu_partial_match": [
      "self",
      "n_gram"
    ],
    "test_bleu_empty_prediction": [
      "self"
    ],
    "test_bleu_empty_reference": [
      "self"
    ],
    "test_bleu_multiple_samples": [
      "self"
    ],
    "test_bleu_different_ngram_calculations": [
      "self",
      "n_gram"
    ],
    "test_bleu_multi_tokenization": [
      "self"
    ]
  },
  "TestBLEUEdgeCases": {
    "vocabulary": [],
    "create_mock_decoding": [
      "self"
    ],
    "test_bleu_empty_hypotheses": [
      "self"
    ],
    "test_bleu_zero_length_targets": [
      "self"
    ]
  },
  "TestMultiTaskMetricConstraintFunctions": {
    "setUp": [
      "self"
    ],
    "test_static_constraint_equality": [
      "self"
    ],
    "test_static_constraint_inequality": [
      "self"
    ],
    "test_compare_constraint": [
      "self"
    ],
    "test_logical_operations": [
      "self"
    ]
  },
  "TestMultiTaskMetricConstraintParsing": {
    "setUp": [
      "self"
    ],
    "test_simple_equality_constraint": [
      "self"
    ],
    "test_simple_inequality_constraint": [
      "self"
    ],
    "test_property_comparison_constraint": [
      "self"
    ],
    "test_and_constraint": [
      "self"
    ],
    "test_or_constraint": [
      "self"
    ],
    "test_not_constraint": [
      "self"
    ],
    "test_complex_constraint": [
      "self"
    ],
    "test_parentheses_constraint": [
      "self"
    ],
    "test_nested_parentheses_constraint": [
      "self"
    ],
    "test_parentheses_with_not_constraint": [
      "self"
    ],
    "test_complex_parentheses_constraint": [
      "self"
    ],
    "test_invalid_constraint": [
      "self"
    ]
  },
  "TestMultiTaskMetricCutSplitting": {
    "create_mock_cut": [
      "self",
      "custom_data"
    ],
    "test_split_cuts_simple": [
      "self"
    ],
    "test_split_cuts_no_matches": [
      "self"
    ],
    "test_split_cuts_empty_input": [
      "self"
    ]
  },
  "TestMultiTaskMetricUpdate": {
    "mock_multitask_metric": [
      "self"
    ],
    "test_update_with_matching_cuts": [
      "self",
      "mock_multitask_metric"
    ],
    "test_update_with_empty_indices": [
      "self",
      "mock_multitask_metric"
    ]
  },
  "TestMultiTaskMetricCompute": {
    "test_compute_wer_metric": [
      "self"
    ],
    "test_compute_bleu_metric": [
      "self"
    ],
    "test_reset_metrics": [
      "self"
    ]
  },
  "TestMultiTaskMetricEdgeCases": {
    "test_missing_custom_attribute": [
      "self"
    ],
    "test_complex_constraint_edge_cases": [
      "self"
    ],
    "test_operators_coverage": [
      "self"
    ]
  },
  "BASE_DIR": [],
  "set_multiprocessing_method": [],
  "speakers_path": [
    "tmp_path_factory"
  ],
  "textonly_manifest_path": [
    "tmp_path_factory"
  ],
  "textonly_unnormalized_manifest_path": [
    "tmp_path_factory"
  ],
  "tts_normalizer": [],
  "asr_tokenizer": [
    "test_data_dir"
  ],
  "tts_tokenizer": [],
  "TestTextToTextDataset": {
    "test_text_to_text_dataset": [
      "self",
      "textonly_manifest_path",
      "tokenizer_workers",
      "speakers_path",
      "asr_tokenizer",
      "tts_tokenizer",
      "tts_normalizer",
      "set_multiprocessing_method"
    ],
    "test_text_to_text_dataset_unnormalized": [
      "self",
      "textonly_unnormalized_manifest_path",
      "speakers_path",
      "asr_tokenizer",
      "tts_tokenizer",
      "tts_normalizer"
    ],
    "test_text_to_text_iterable_dataset": [
      "self",
      "textonly_manifest_path",
      "tokenizer_workers",
      "speakers_path",
      "asr_tokenizer",
      "tts_tokenizer",
      "tts_normalizer",
      "set_multiprocessing_method"
    ]
  },
  "test_lhotse_asr_speaker_dataset": [
    "tokenizer"
  ],
  "speech_regression_model": [],
  "TestEncDecRegressionModel": {
    "test_constructor": [
      "self",
      "speech_regression_model"
    ],
    "test_transcription": [
      "self",
      "speech_regression_model",
      "test_data_dir"
    ]
  },
  "get_batch_encoder_outputs_from_records": [
    "records",
    "model",
    "device"
  ],
  "test_multi_task_streaming_decoding": [
    "tmp_path_factory",
    "an4_val_manifest_corrected",
    "canary_180m_flash",
    "device",
    "use_cuda_graph_decoder",
    "decoding_policy",
    "chunk_size",
    "batch_size"
  ],
  "stt_en_conformer_transducer_small_model": [],
  "get_rnnt_alignments": [
    "strategy",
    "manifest_path",
    "model",
    "loop_labels",
    "use_cuda_graph_decoder",
    "device"
  ],
  "test_rnnt_alignments": [
    "loop_labels",
    "use_cuda_graph_decoder",
    "device",
    "an4_val_manifest_corrected",
    "stt_en_conformer_transducer_small_model"
  ],
  "get_model_encoder_output": [
    "test_audio_filenames",
    "num_samples",
    "model",
    "device",
    "dtype"
  ],
  "test_label_looping_streaming_batched_state": [
    "tmp_path_factory",
    "an4_val_manifest_corrected",
    "stt_en_fastconformer_transducer_large",
    "stt_en_fastconformer_tdt_large",
    "device",
    "use_cuda_graph_decoder",
    "is_tdt",
    "chunk_size",
    "batch_size",
    "max_symbols"
  ],
  "test_label_looping_streaming_partial_hypotheses": [
    "tmp_path_factory",
    "an4_val_manifest_corrected",
    "stt_en_fastconformer_transducer_large",
    "stt_en_fastconformer_tdt_large",
    "device",
    "use_cuda_graph_decoder",
    "is_tdt",
    "chunk_size",
    "batch_size",
    "max_symbols"
  ],
  "test_label_looping_continuous_streaming_batched_state": [
    "tmp_path_factory",
    "an4_val_manifest_corrected",
    "stt_en_fastconformer_transducer_large",
    "stt_en_fastconformer_tdt_large",
    "device",
    "use_cuda_graph_decoder",
    "is_tdt",
    "chunk_size",
    "batch_size",
    "max_symbols"
  ],
  "test_label_looping_continuous_streaming_partial_hypotheses": [
    "tmp_path_factory",
    "an4_val_manifest_corrected",
    "stt_en_fastconformer_transducer_large",
    "stt_en_fastconformer_tdt_large",
    "device",
    "use_cuda_graph_decoder",
    "is_tdt",
    "chunk_size",
    "batch_size",
    "max_symbols"
  ],
  "test_context_size_total_and_subsample": [],
  "test_context_size_batch_total_and_subsample": [
    "device"
  ],
  "_create_audio_batch": [
    "batch_size",
    "length",
    "device",
    "dtype"
  ],
  "test_streaming_batched_audio_buffer": [
    "device"
  ],
  "test_streaming_batched_audio_buffer_raises_on_too_long_chunk": [
    "device"
  ],
  "CHECKPOINTS_PATH": [],
  "an4_val_manifest_corrected": [
    "tmp_path_factory",
    "test_data_dir"
  ],
  "an4_train_manifest_corrected": [
    "tmp_path_factory",
    "test_data_dir"
  ],
  "_stt_en_conformer_transducer_small_raw": [],
  "_stt_en_fastconformer_transducer_large_raw": [],
  "_stt_en_fastconformer_tdt_large_raw": [],
  "_canary_180m_flash_raw": [],
  "stt_en_conformer_transducer_small": [
    "_stt_en_conformer_transducer_small_raw"
  ],
  "stt_en_fastconformer_transducer_large": [
    "_stt_en_fastconformer_transducer_large_raw"
  ],
  "stt_en_fastconformer_tdt_large": [
    "_stt_en_fastconformer_tdt_large_raw"
  ],
  "canary_180m_flash": [
    "_canary_180m_flash_raw"
  ],
  "preserve_decoding_cfg_and_cpu_device": [
    "model"
  ],
  "load_audio": [
    "file_path",
    "target_sr"
  ],
  "avoid_sync_operations": [
    "device"
  ],
  "make_preprocessor_deterministic": [
    "model"
  ],
  "test_cuda_graph_rnnt_greedy_decoder": [
    "model_name",
    "batch_size",
    "enable_bfloat16",
    "loop_labels",
    "request"
  ],
  "test_loop_labels_cuda_graph_rnnt_greedy_decoder_forced_mode": [
    "stt_en_fastconformer_transducer_large",
    "force_mode",
    "enable_bfloat16"
  ],
  "test_loop_labels_cuda_graph_ddp_mixed_precision": [
    "tmp_path_factory",
    "an4_train_manifest_corrected",
    "stt_en_fastconformer_transducer_large",
    "stt_en_fastconformer_tdt_large",
    "is_tdt"
  ],
  "test_change_devices": [
    "loop_labels",
    "stt_en_fastconformer_transducer_large"
  ],
  "TestBatchedHyps": {
    "test_instantiate": [
      "self",
      "device"
    ],
    "test_instantiate_incorrect_batch_size": [
      "self",
      "batch_size"
    ],
    "test_instantiate_incorrect_init_length": [
      "self",
      "init_length"
    ],
    "test_add_results": [
      "self",
      "device"
    ],
    "test_add_multiple_results": [
      "self",
      "device"
    ],
    "test_add_results_masked": [
      "self",
      "device"
    ],
    "test_add_results_masked_no_checks": [
      "self",
      "device"
    ],
    "test_add_multiple_results_masked": [
      "self",
      "device"
    ]
  },
  "TestBatchedAlignments": {
    "test_instantiate": [
      "self",
      "device"
    ],
    "test_instantiate_incorrect_batch_size": [
      "self",
      "batch_size"
    ],
    "test_instantiate_incorrect_init_length": [
      "self",
      "init_length"
    ],
    "test_add_results": [
      "self",
      "device"
    ],
    "test_add_multiple_results": [
      "self",
      "device"
    ],
    "test_add_results_masked": [
      "self",
      "device"
    ],
    "test_add_results_masked_no_checks": [
      "self",
      "device"
    ],
    "test_add_multiple_results_masked": [
      "self",
      "device"
    ]
  },
  "TestConvertToHypotheses": {
    "test_convert_to_hypotheses": [
      "self",
      "device"
    ],
    "test_convert_to_hypotheses_with_alignments": [
      "self",
      "device"
    ]
  },
  "BaseTimestampsTest": {
    "bpe_tokenizer": [
      "self"
    ],
    "char_offsets_chars": [
      "self"
    ],
    "word_offsets_chars_expected_output": [
      "self"
    ],
    "word_offsets_chars_expected_output_other_delimiter": [
      "self"
    ],
    "segment_offsets_expected_output": [
      "self"
    ],
    "segment_offsets_expected_output_gap": [
      "self"
    ],
    "char_offsets_wpe": [
      "self"
    ],
    "word_offsets_wpe_expected_output": [
      "self"
    ],
    "word_offsets_wpe_expected_output_other_delimiter": [
      "self"
    ],
    "char_offsets_bpe": [
      "self"
    ],
    "encoded_char_offsets_bpe": [
      "self"
    ],
    "word_offsets_bpe_expected_output": [
      "self"
    ],
    "word_offsets_bpe_expected_output_other_delimiter": [
      "self"
    ],
    "check_char_timestamps": [
      "hyp",
      "decoding"
    ],
    "check_subword_timestamps": [
      "hyp",
      "decoding"
    ],
    "test_word_offsets_chars": [
      "self"
    ],
    "test_word_offsets_char_other_delimiter": [
      "self"
    ],
    "test_word_offsets_subword_wpe": [
      "self"
    ],
    "test_word_offsets_subword_wpe_other_delimiter": [
      "self"
    ],
    "test_word_offsets_subword_bpe": [
      "self"
    ],
    "test_word_offsets_subword_bpe_other_delimiter": [
      "self"
    ],
    "test_segment_offsets_delimiter": [
      "self"
    ],
    "test_segment_offsets_gap": [
      "self"
    ]
  },
  "RNNT_MODEL": [],
  "CTC_MODEL": [],
  "TDT_MODEL": [],
  "MAX_SAMPLES": [],
  "test_audio_filenames": [
    "test_data_dir"
  ],
  "rnnt_model": [],
  "tdt_model": [],
  "ctc_model": [],
  "get_rnnt_encoder_output": [
    "rnnt_model",
    "test_audio_filenames"
  ],
  "get_tdt_encoder_output": [
    "tdt_model",
    "test_audio_filenames"
  ],
  "get_ctc_output": [
    "ctc_model",
    "test_audio_filenames"
  ],
  "kenlm_model_path": [
    "tmp_path_factory",
    "test_data_dir"
  ],
  "get_transducer_model_encoder_output": [
    "test_audio_filenames",
    "num_samples",
    "model",
    "device",
    "dtype"
  ],
  "get_ctc_model_output": [
    "test_audio_filenames",
    "num_samples",
    "model",
    "device",
    "dtype"
  ],
  "print_unit_test_info": [
    "strategy",
    "batch_size",
    "beam_size",
    "allow_cuda_graphs",
    "device"
  ],
  "check_res_best_hyps": [
    "num_samples",
    "hyps"
  ],
  "print_res_best_hyps": [
    "hyps"
  ],
  "check_res_nbest_hyps": [
    "num_samples",
    "batch_nbest_hyps"
  ],
  "print_res_nbest_hyps": [
    "batch_nbest_hyps"
  ],
  "decode_text_from_hypotheses": [
    "hyps",
    "model"
  ],
  "decode_text_from_nbest_hypotheses": [
    "hyps",
    "model"
  ],
  "TestRNNTDecoding": {
    "test_rnnt_beam_decoding_return_best_hypothesis": [
      "self",
      "test_audio_filenames",
      "rnnt_model",
      "get_rnnt_encoder_output",
      "beam_config",
      "device",
      "batch_size",
      "beam_size"
    ],
    "test_rnnt_beam_decoding_return_nbest": [
      "self",
      "test_audio_filenames",
      "rnnt_model",
      "get_rnnt_encoder_output",
      "beam_config",
      "device",
      "beam_size",
      "batch_size"
    ],
    "test_rnnt_beam_decoding_kenlm": [
      "self",
      "kenlm_model_path",
      "test_audio_filenames",
      "rnnt_model",
      "get_rnnt_encoder_output",
      "beam_config",
      "device",
      "batch_size",
      "beam_size",
      "pruning_mode",
      "blank_lm_score_mode"
    ]
  },
  "TestTDTDecoding": {
    "test_tdt_beam_decoding_return_best_hypothesis": [
      "self",
      "test_audio_filenames",
      "tdt_model",
      "get_tdt_encoder_output",
      "beam_config",
      "device",
      "batch_size",
      "beam_size"
    ],
    "test_tdt_beam_decoding_return_nbest": [
      "self",
      "test_audio_filenames",
      "tdt_model",
      "get_tdt_encoder_output",
      "beam_config",
      "device",
      "beam_size",
      "batch_size"
    ],
    "test_tdt_beam_decoding_kenlm": [
      "self",
      "kenlm_model_path",
      "test_audio_filenames",
      "tdt_model",
      "get_tdt_encoder_output",
      "beam_config",
      "device",
      "batch_size",
      "beam_size",
      "pruning_mode",
      "blank_lm_score_mode"
    ]
  },
  "TestTransducerCudaGraphBeamDecoding": {
    "test_stated_stateless": [
      "self",
      "test_audio_filenames",
      "rnnt_model",
      "tdt_model",
      "model_type",
      "force_mode"
    ],
    "test_stated_stateless_bf16": [
      "self",
      "test_audio_filenames",
      "rnnt_model",
      "tdt_model",
      "model_type"
    ]
  },
  "TestCTCDecoding": {
    "test_ctc_beam_decoding_return_best_hypothesis": [
      "self",
      "test_audio_filenames",
      "ctc_model",
      "get_ctc_output",
      "beam_config",
      "device",
      "batch_size",
      "beam_size"
    ],
    "test_ctc_beam_decoding_return_nbest": [
      "self",
      "test_audio_filenames",
      "ctc_model",
      "get_ctc_output",
      "beam_config",
      "device",
      "beam_size",
      "batch_size"
    ],
    "test_ctc_beam_decoding_kenlm": [
      "self",
      "kenlm_model_path",
      "test_audio_filenames",
      "ctc_model",
      "get_ctc_output",
      "beam_config",
      "device",
      "batch_size",
      "beam_size"
    ]
  },
  "audio_file": [
    "test_data_dir"
  ],
  "char_vocabulary": [],
  "tmp_tokenizer": [
    "test_data_dir"
  ],
  "TestCTCTimestamps": {
    "decoding_char": [
      "self"
    ],
    "decoding_subword_wpe": [
      "self"
    ],
    "decoding_subword_bpe": [
      "self"
    ],
    "test_word_offsets_subword_wpe": [
      "self",
      "tmp_tokenizer"
    ],
    "test_word_offsets_subword_wpe_other_delimiter": [
      "self",
      "tmp_tokenizer"
    ]
  },
  "TestCTCGreedyDecodingWithNGPU_LM": {
    "test_ctc_decoding_gpulm": [
      "self",
      "audio_file",
      "kenlm_model_path",
      "ctc_model"
    ]
  },
  "TestCTCGreedyDecodingCudaGrpahs": {
    "test_stated_stateless": [
      "self",
      "audio_file",
      "kenlm_model_path",
      "ctc_model",
      "force_mode"
    ]
  },
  "NestedFloatList": [],
  "assert_nested_lists_approx": [
    "actual",
    "expected",
    "rel_tol",
    "abs_tol"
  ],
  "assert_hyps_sequence_equal": [
    "actual",
    "expected",
    "rel_tol",
    "abs_tol"
  ],
  "assert_hyps_timestamps_equal": [
    "actual",
    "expected",
    "rel_tol",
    "abs_tol"
  ],
  "TestBatchedBeamHyps": {
    "test_rnnt_instantiate": [
      "self",
      "device"
    ],
    "test_rnnt_instantiate_incorrect_batch_size": [
      "self",
      "batch_size"
    ],
    "test_rnnt_instantiate_incorrect_beam_size": [
      "self",
      "beam_size"
    ],
    "test_rnnt_instantiate_incorrect_init_length": [
      "self",
      "init_length"
    ],
    "test_rnnt_add_results": [
      "self",
      "device"
    ],
    "test_rnnt_add_multiple_results": [
      "self",
      "device"
    ],
    "test_rnnt_add_with_invalid_results": [
      "self",
      "device"
    ],
    "test_tdt_instantiate": [
      "self",
      "device"
    ],
    "test_tdt_instantiate_incorrect_batch_size": [
      "self",
      "batch_size"
    ],
    "test_tdt_instantiate_incorrect_beam_size": [
      "self",
      "beam_size"
    ],
    "test_tdt_instantiate_incorrect_init_length": [
      "self",
      "init_length"
    ],
    "test_tdt_add_results": [
      "self",
      "device"
    ],
    "test_tdt_add_multiple_results": [
      "self",
      "device"
    ],
    "test_tdt_add_with_invalid_results": [
      "self",
      "device"
    ],
    "test_ctc_instantiate": [
      "self",
      "device"
    ],
    "test_ctc_instantiate_incorrect_batch_size": [
      "self",
      "batch_size"
    ],
    "test_ctc_instantiate_incorrect_beam_size": [
      "self",
      "beam_size"
    ],
    "test_ctc_instantiate_incorrect_init_length": [
      "self",
      "init_length"
    ],
    "test_ctc_create_fold_consecutive_mask": [
      "self",
      "y"
    ],
    "test_ctc_add_results": [
      "self",
      "device"
    ]
  },
  "deterministic_rng": [],
  "decoder_nm": [
    "deterministic_rng"
  ],
  "nnet": [
    "decoder_nm"
  ],
  "inputs": [],
  "test_greedy_decoding": [
    "inputs",
    "nnet",
    "deterministic_rng",
    "with_confidence"
  ],
  "test_temperature_sampling_decoding": [
    "inputs",
    "nnet"
  ],
  "test_beam_decoding_beam_scores_false": [
    "inputs",
    "nnet"
  ],
  "test_beam_decoding_beam_scores_true": [
    "inputs",
    "nnet"
  ],
  "test_beam_decoding_beam_scores_true_with_fusion_models": [
    "inputs",
    "nnet"
  ],
  "prompted_inputs": [],
  "test_transformer_aed_beam_infer_strips_prompt": [
    "prompted_inputs",
    "decoder_nm",
    "nnet",
    "tokenizer"
  ],
  "test_transformer_aed_greedy_infer_strips_prompt": [
    "prompted_inputs",
    "decoder_nm",
    "nnet",
    "tokenizer"
  ],
  "get_rnnt_decoder": [
    "vocab_size",
    "decoder_output_size"
  ],
  "get_rnnt_joint": [
    "vocab_size",
    "vocabulary",
    "encoder_output_size",
    "decoder_output_size",
    "joint_output_shape"
  ],
  "decode_text_from_greedy_hypotheses": [
    "hyps",
    "decoding"
  ],
  "check_beam_decoding": [
    "test_data_dir",
    "beam_config"
  ],
  "check_tdt_greedy_decoding": [
    "test_data_dir",
    "use_cuda_graph_decoder",
    "lm_path",
    "boosting_tree"
  ],
  "TestRNNTTimestamps": {
    "_convert_offsets": [
      "self",
      "offsets"
    ],
    "char_offsets_chars": [
      "self"
    ],
    "char_offsets_wpe": [
      "self"
    ],
    "char_offsets_bpe": [
      "self"
    ],
    "encoded_char_offsets_bpe": [
      "self"
    ],
    "decoding_char": [
      "self"
    ],
    "decoding_subword_wpe": [
      "self"
    ],
    "decoding_subword_bpe": [
      "self"
    ],
    "test_word_offsets_subword_wpe": [
      "self",
      "tmp_tokenizer"
    ],
    "test_word_offsets_subword_wpe_other_delimiter": [
      "self",
      "tmp_tokenizer"
    ]
  },
  "ECE_VALUES": [],
  "TOL_DEGREE": [],
  "TOL": [],
  "conformer_rnnt_bpe_model": [],
  "audio_and_texts": [
    "test_data_dir"
  ],
  "TestASRConfidenceBenchmark": {
    "test_run_confidence_benchmark": [
      "self",
      "model_name",
      "target_level",
      "audio_and_texts",
      "conformer_ctc_bpe_model",
      "conformer_rnnt_bpe_model"
    ],
    "test_deprecated_config_args": [
      "self",
      "model_name",
      "conformer_ctc_bpe_model",
      "conformer_rnnt_bpe_model"
    ]
  },
  "VOCAB_SIZES": [],
  "AGGREGATION_VEC_SIMPLE": [],
  "get_measure_parametrize_ranges": [],
  "get_aggregation_parametrize_ranges": [],
  "TestConfidenceMeasureBank": {
    "test_measure_bank": [
      "self"
    ],
    "test_confidence_measures_one": [
      "self",
      "measure_name",
      "alpha",
      "vocab_size"
    ],
    "test_confidence_measures_zero": [
      "self",
      "measure_name",
      "alpha",
      "vocab_size"
    ],
    "test_confidence_measures_partial_order": [
      "self",
      "measure_name",
      "alpha",
      "vocab_size"
    ]
  },
  "TestConfidenceAggregationBank": {
    "test_aggregation_bank": [
      "self"
    ],
    "test_confidence_agregation_simple": [
      "self",
      "aggregation_name"
    ]
  },
  "name2metric": [],
  "name2metric_all_correct": [],
  "name2metric_all_incorrect": [],
  "Y_TRUE": [],
  "Y_TRUE_ALL_CORRECT": [],
  "Y_TRUE_ALL_INCORRECT": [],
  "Y_SCORE": [],
  "Y_TRUE_RANDOM": [],
  "Y_SCORE_RANDOM": [],
  "TestConfidenceMetrics": {
    "test_metric_main": [
      "self",
      "metric_name"
    ],
    "test_metric_all_correct": [
      "self",
      "metric_name"
    ],
    "test_metric_all_incorrect": [
      "self",
      "metric_name"
    ],
    "test_metric_auc_yc_aux": [
      "self"
    ]
  },
  "TestSaveConfidencePlot": {
    "test_save_confidence_hist": [
      "self"
    ],
    "test_save_simple_confidence_curve": [
      "self",
      "plot_func"
    ],
    "test_save_custom_confidence_curve": [
      "self"
    ]
  },
  "wrap_and_call": [
    "fn",
    "acts",
    "labels",
    "device"
  ],
  "init_k2_rnnt": [],
  "skip_test_if_unsupported": [
    "device",
    "k2_is_appropriate",
    "k2_cuda_is_enabled"
  ],
  "TestRNNTLossK2": {
    "test_case_small": [
      "self",
      "device",
      "k2_is_appropriate",
      "k2_cuda_is_enabled"
    ],
    "test_case_small_blank_last": [
      "self",
      "device",
      "k2_is_appropriate",
      "k2_cuda_is_enabled"
    ],
    "test_case_small_random": [
      "self",
      "device",
      "k2_is_appropriate",
      "k2_cuda_is_enabled"
    ],
    "test_case_big_tensor": [
      "self",
      "device",
      "k2_is_appropriate",
      "k2_cuda_is_enabled"
    ],
    "test_case_large_random": [
      "self",
      "device",
      "k2_is_appropriate",
      "k2_cuda_is_enabled"
    ]
  },
  "EPS_SM_INPUT": [],
  "EPS_L_INPUT": [],
  "TestGraphRnnt": {
    "test_temporal_schema": [
      "self",
      "device",
      "blank_first",
      "num_frames",
      "vocab_size"
    ],
    "test_unit_schema": [
      "self",
      "device",
      "blank_first"
    ],
    "test_grid_schema": [
      "self",
      "device",
      "blank_first"
    ],
    "test_small_compose_transducer": [
      "self",
      "device",
      "connect_composed",
      "blank_first",
      "rnnt_test_helper",
      "rnn_loss_sample_data"
    ],
    "test_small_grid_transducer": [
      "self",
      "device",
      "rnnt_test_helper",
      "rnn_loss_sample_data"
    ],
    "test_medium_grid_transducer": [
      "self",
      "device",
      "use_triton",
      "rnnt_test_helper",
      "rnn_loss_sample_data"
    ],
    "test_medium_random_var_size": [
      "self",
      "device",
      "use_triton",
      "rnnt_test_helper",
      "rnn_loss_sample_data"
    ],
    "test_small_random_grid_compose_equivalent": [
      "self",
      "device",
      "blank_first",
      "rnn_loss_sample_data"
    ]
  },
  "TestRnntLogProbs": {
    "test_rnnt_logprobs_random": [
      "self",
      "batch_size",
      "num_frames",
      "num_text_units",
      "vocab_size",
      "float_dtype"
    ]
  },
  "init_k2_ctc": [],
  "TestCTCLossK2": {
    "test_case_small": [
      "self",
      "device",
      "k2_is_appropriate",
      "k2_cuda_is_enabled"
    ],
    "test_case_small_blank_last": [
      "self",
      "device",
      "k2_is_appropriate",
      "k2_cuda_is_enabled"
    ],
    "test_case_small_random": [
      "self",
      "device",
      "k2_is_appropriate",
      "k2_cuda_is_enabled"
    ],
    "test_case_big_tensor": [
      "self",
      "device",
      "k2_is_appropriate",
      "k2_cuda_is_enabled"
    ],
    "test_case_large_random": [
      "self",
      "device",
      "k2_is_appropriate",
      "k2_cuda_is_enabled"
    ]
  },
  "TestGraphWTransducerLoss": {
    "test_temporal_schema": [
      "self",
      "device",
      "blank_first",
      "num_frames",
      "vocab_size",
      "last_blank_mode"
    ],
    "test_unit_schema": [
      "self",
      "device",
      "blank_first"
    ],
    "test_grid_schema": [
      "self",
      "device",
      "blank_first",
      "last_blank_mode"
    ],
    "test_small_random_grid_compose_equivalent": [
      "self",
      "device",
      "blank_first",
      "last_blank_mode",
      "rnn_loss_sample_data"
    ],
    "test_small_grid_transducer_inf_penalty": [
      "self",
      "device",
      "last_blank_mode",
      "use_grid_implementation",
      "rnnt_test_helper",
      "rnn_loss_sample_data"
    ]
  },
  "get_simple_rttm_without_overlap": [
    "rttm_file"
  ],
  "get_simple_rttm_with_overlap": [
    "rttm_file"
  ],
  "get_simple_rttm_with_silence": [
    "rttm_file"
  ],
  "TestVADUtils": {
    "test_align_label_logits": [
      "self",
      "logits_len",
      "labels_len"
    ],
    "test_load_speech_segments_from_rttm": [
      "self",
      "test_data_dir"
    ],
    "test_load_speech_overlap_segments_from_rttm": [
      "self",
      "test_data_dir"
    ],
    "test_get_nonspeech_segments": [
      "self",
      "test_data_dir"
    ],
    "test_get_frame_labels": [
      "self",
      "test_data_dir"
    ],
    "test_convert_labels_to_speech_segments": [
      "self",
      "test_data_dir"
    ],
    "test_read_rttm_as_pyannote_object": [
      "self",
      "test_data_dir"
    ],
    "test_frame_vad_construct_pyannote_object_per_file": [
      "self",
      "test_data_dir"
    ]
  },
  "annotator": [],
  "sampler": [],
  "get_data_simulation_configs": [],
  "generate_words_and_alignments": [
    "sample_index"
  ],
  "TestGetCtmLine": {
    "test_wrong_type_conf_values": [
      "self",
      "conf"
    ],
    "test_valid_conf_values": [
      "self",
      "conf"
    ],
    "test_invalid_conf_ranges": [
      "self",
      "conf"
    ],
    "test_valid_start_time_duration_with_precision": [
      "self",
      "start_time",
      "duration",
      "output_precision"
    ],
    "test_valid_input": [
      "self"
    ],
    "test_invalid_types_for_time_duration": [
      "self",
      "start_time",
      "duration"
    ],
    "test_invalid_conf_values": [
      "self",
      "conf"
    ],
    "test_default_values": [
      "self"
    ]
  },
  "TestDataSimulatorUtils": {
    "test_binary_search_alignments": [
      "self",
      "max_audio_read_sec",
      "min_alignment_count"
    ],
    "test_normalize_audio": [
      "self",
      "sample_len",
      "gain"
    ],
    "test_get_cleaned_base_path": [
      "self",
      "output_dir"
    ],
    "test_get_split_points_in_alignments": [
      "self",
      "words",
      "alignments",
      "sr",
      "new_start",
      "split_buffer",
      "answers"
    ],
    "test_add_silence_to_alignments": [
      "self",
      "alignments",
      "words"
    ]
  },
  "TestDataAnnotator": {
    "test_init": [
      "self",
      "annotator"
    ],
    "test_create_new_rttm_entry": [
      "self",
      "annotator"
    ],
    "test_create_new_json_entry": [
      "self",
      "annotator"
    ],
    "test_create_new_ctm_entry": [
      "self",
      "annotator"
    ]
  },
  "TestSpeechSampler": {
    "test_init": [
      "self",
      "sampler"
    ],
    "test_init_overlap_params": [
      "self",
      "sampler"
    ],
    "test_init_silence_params": [
      "self",
      "sampler"
    ],
    "test_get_session_silence_mean_pass": [
      "self",
      "sampler",
      "mean",
      "var"
    ],
    "test_get_session_silence_mean_fail": [
      "self",
      "sampler",
      "mean",
      "var"
    ],
    "test_get_session_overlap_mean_pass": [
      "self",
      "sampler",
      "mean",
      "var"
    ],
    "test_get_session_overlap_mean_fail": [
      "self",
      "sampler",
      "mean",
      "var"
    ],
    "test_sample_from_overlap_model": [
      "self",
      "sampler",
      "non_silence_len_samples",
      "running_overlap_len_samples"
    ],
    "test_sample_from_silence_model": [
      "self",
      "sampler",
      "running_len_samples",
      "running_overlap_len_samples"
    ],
    "test_sample_noise_manifest": [
      "self",
      "sampler",
      "num_noise_files",
      "test_data_dir"
    ],
    "test_silence_vs_overlap_selector": [
      "self",
      "sampler",
      "running_overlap_len_samples",
      "running_speech_len_samples",
      "running_len_samples",
      "non_silence_len_samples"
    ]
  },
  "_make_char": [
    "char",
    "token_id",
    "start_off",
    "end_off",
    "token"
  ],
  "test_join_char_level_timestamps_without_filter": [],
  "test_join_char_level_timestamps_with_filter": [],
  "test_merge_hypotheses_of_same_audio": [],
  "test_merge_all_hypotheses": [],
  "DummyDatasetAudioOnly": {
    "__init__": [
      "self",
      "audio_files",
      "config"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "audio_files": [
    "test_data_dir"
  ],
  "TranscribableDummy": {
    "_transcribe_on_begin": [
      "self",
      "audio",
      "trcfg"
    ],
    "_transcribe_input_manifest_processing": [
      "self",
      "audio_files",
      "temp_dir",
      "trcfg"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "_transcribe_forward": [
      "self",
      "batch",
      "trcfg"
    ],
    "_transcribe_output_processing": [
      "self",
      "outputs",
      "trcfg"
    ],
    "_transcribe_on_end": [
      "self",
      "trcfg"
    ]
  },
  "TestTranscriptionMixin": {
    "test_constructor_non_instance": [
      "self"
    ],
    "test_transcribe": [
      "self",
      "dummy_model"
    ],
    "test_transcribe_generator": [
      "self",
      "dummy_model"
    ],
    "test_transcribe_generator_explicit_stop_check": [
      "self",
      "dummy_model"
    ],
    "test_transcribe_check_flags": [
      "self",
      "dummy_model"
    ],
    "test_transribe_override_config_incorrect": [
      "self",
      "dummy_model"
    ],
    "test_transribe_override_config_correct": [
      "self",
      "dummy_model"
    ],
    "test_transcribe_return_hypothesis": [
      "self",
      "test_data_dir",
      "fast_conformer_ctc_model"
    ],
    "test_transcribe_tensor": [
      "self",
      "audio_files",
      "fast_conformer_ctc_model"
    ],
    "test_transcribe_multiple_tensor": [
      "self",
      "audio_files",
      "fast_conformer_ctc_model"
    ],
    "test_transcribe_dataloader": [
      "self",
      "audio_files",
      "fast_conformer_ctc_model"
    ],
    "test_transcribe_return_nbest_rnnt": [
      "self",
      "audio_files",
      "fast_conformer_transducer_model"
    ],
    "test_transcribe_return_nbest_canary": [
      "self",
      "audio_files",
      "canary_1b_flash"
    ],
    "test_timestamps_with_transcribe": [
      "self",
      "audio_files",
      "fast_conformer_ctc_model"
    ],
    "test_timestamps_with_transcribe_hybrid": [
      "self",
      "audio_files",
      "fast_conformer_hybrid_model"
    ],
    "test_timestamps_with_transcribe_hybrid_ctc_head": [
      "self",
      "audio_files",
      "fast_conformer_hybrid_model"
    ],
    "test_timestamps_with_transcribe_canary_flash": [
      "self",
      "audio_files",
      "canary_1b_flash"
    ],
    "test_transcribe_return_nbest_hybrid_rnnt_ctc_prompt": [
      "self",
      "audio_files",
      "hybrid_rnnt_ctc_bpe_model_with_prompt"
    ],
    "test_timestamps_with_transcribe_hybrid_prompt": [
      "self",
      "audio_files",
      "hybrid_rnnt_ctc_bpe_model_with_prompt"
    ]
  },
  "_create_masks": [
    "att_mask",
    "max_audio_length",
    "padding_length"
  ],
  "get_mask": [
    "lengths"
  ],
  "TestASRAdapterModules": {
    "test_mha_adapter_config": [
      "self"
    ],
    "test_relpos_mha_adapter_config": [
      "self"
    ],
    "test_abs_pos_encoding_adapter_config": [
      "self"
    ],
    "test_rel_pos_encoding_adapter_config": [
      "self"
    ],
    "test_transformer_mha_adapter_config": [
      "self"
    ],
    "test_mha_adapter_init": [
      "self",
      "n_head",
      "proj_dim"
    ],
    "test_relmha_adapter_init": [
      "self",
      "n_head",
      "proj_dim"
    ],
    "test_relmha_adapter_with_torch_sdpa": [
      "self"
    ],
    "test_mha_adapter_with_torch_sdpa": [
      "self"
    ],
    "test_abspos_encoding_init": [
      "self"
    ],
    "test_relpos_encoding_init": [
      "self"
    ],
    "test_transformer_mha_adapter_init": [
      "self",
      "n_head",
      "proj_dim"
    ],
    "test_mha_adapter_strategy": [
      "self"
    ],
    "test_relpos_mha_adapter_strategy": [
      "self"
    ],
    "test_abspos_encoding_adapter_strategy": [
      "self"
    ],
    "test_relpos_encoding_adapter_strategy": [
      "self"
    ],
    "test_transformer_mha_adapter_strategy": [
      "self"
    ]
  },
  "conformer_ctc_adapter": [],
  "squeezeformer_ctc_adapter": [],
  "multitask_model": [
    "test_data_dir"
  ],
  "TestASRAdapterMixin": {
    "test_class_paths_are_correct": [
      "self"
    ],
    "test_asr_model_constructor": [
      "self",
      "model"
    ],
    "test_asr_model_constructor_mha_adapter": [
      "self",
      "model"
    ],
    "test_conformer_constructor_mha_adapter": [
      "self",
      "conformer_ctc_adapter"
    ],
    "test_squeezeformer_constructor_mha_adapter": [
      "self",
      "squeezeformer_ctc_adapter"
    ],
    "test_asr_model_constructor_encoder_module": [
      "self",
      "model"
    ],
    "test_asr_model_constructor_decoder_module": [
      "self",
      "model"
    ],
    "test_asr_model_constructor_joint_module_ctc_skip": [
      "self",
      "model"
    ],
    "test_asr_model_constructor_joint_module_rnnt": [
      "self",
      "rnnt_model"
    ],
    "test_asr_multiple_adapter": [
      "self",
      "model"
    ],
    "test_asr_forward_linear_pre": [
      "self",
      "model",
      "name"
    ],
    "test_asr_forward_linear_post": [
      "self",
      "model",
      "name"
    ],
    "test_conformer_forward_mha": [
      "self",
      "conformer_ctc_adapter",
      "name"
    ],
    "test_squeezeformer_forward_mha": [
      "self",
      "squeezeformer_ctc_adapter",
      "name"
    ],
    "test_canary_forward_mha": [
      "self",
      "multitask_model",
      "name",
      "adapter_type"
    ],
    "test_canary_forward_mha_decoder_fails_without_support": [
      "self",
      "multitask_model",
      "name"
    ],
    "test_asr_multi_adapter_forward": [
      "self",
      "rnnt_model",
      "name1",
      "name2"
    ],
    "test_asr_multi_adapter_partial_forward": [
      "self",
      "model",
      "name1",
      "name2"
    ],
    "test_asr_forward_unfrozen_adapters": [
      "self",
      "model",
      "name"
    ],
    "test_constructor_pretrained": [
      "self"
    ],
    "test_constructor_pretrained_rnnt": [
      "self"
    ],
    "test_asr_model_adapter_loss": [
      "self",
      "model"
    ]
  },
  "CUDA_ONLY_DEVICE": [],
  "DTYPES": [],
  "TestRNNTLossPytorch": {
    "test_case_small": [
      "self",
      "device",
      "dtype"
    ],
    "test_case_small_random": [
      "self",
      "device",
      "dtype"
    ],
    "test_case_small_random_fastemit_reg": [
      "self",
      "device",
      "dtype",
      "fastemit_lambda"
    ],
    "test_case_big_tensor": [
      "self",
      "device",
      "dtype"
    ],
    "test_case_large_random": [
      "self",
      "device",
      "dtype"
    ],
    "test_case_small_clamp": [
      "self",
      "device",
      "dtype"
    ],
    "test_case_small_fastemit_clamp": [
      "self",
      "device",
      "dtype",
      "fastemit_lambda"
    ],
    "test_case_small_random_accumulated": [
      "self",
      "device"
    ]
  },
  "TestMultiblankRNNTLoss": {
    "test_case_randomized_act_label": [
      "self",
      "device"
    ]
  },
  "TestTDTLoss": {
    "test_case_randomized_act_label": [
      "self",
      "device"
    ],
    "test_case_randomized_act_label_no_0_duration": [
      "self",
      "device"
    ],
    "test_case_fixed_case_act_label": [
      "self",
      "device"
    ]
  },
  "TestRNNTCUDAReductions": {
    "test_reduce_max": [
      "self",
      "dtype"
    ],
    "test_reduce_exp": [
      "self",
      "dtype"
    ]
  },
  "TestRNNTHelper": {
    "test_log_sum_exp": [
      "self",
      "dtype"
    ],
    "test_log_sum_exp_neg_inf": [
      "self",
      "dtype"
    ],
    "test_div_up": [
      "self",
      "dtype"
    ],
    "test_add": [
      "self",
      "dtype"
    ],
    "test_maximum": [
      "self",
      "dtype"
    ],
    "test_identity": [
      "self",
      "dtype"
    ],
    "test_negate": [
      "self",
      "dtype"
    ],
    "test_exponential": [
      "self",
      "dtype"
    ],
    "test_log_plus": [
      "self",
      "dtype"
    ],
    "test_compute_costs_data": [
      "self",
      "batch_size",
      "fastemit_lambda",
      "dtype"
    ]
  },
  "log_softmax": [
    "x",
    "axis"
  ],
  "log_softmax_grad": [
    "x",
    "axis"
  ],
  "TestRNNTCUDAKernels": {
    "test_compute_alphas_kernel": [
      "self",
      "dtype"
    ],
    "test_compute_betas_kernel": [
      "self",
      "dtype"
    ],
    "test_compute_grads_kernel": [
      "self",
      "dtype"
    ],
    "test_compute_grads_kernel_fastemit": [
      "self",
      "dtype"
    ],
    "test_compute_grads_kernel_clamp": [
      "self",
      "dtype"
    ]
  },
  "TestTDTCUDAKernels": {
    "test_compute_alphas_kernel": [
      "self"
    ]
  },
  "TestMultiblankRNNTCUDAKernels": {
    "test_compute_alphas_kernel": [
      "self"
    ]
  },
  "get_cfg": [
    "seed",
    "dtype"
  ],
  "prepare_data": [
    "b",
    "f",
    "t",
    "device",
    "freq_masks",
    "time_masks",
    "freq_width",
    "time_width",
    "seed",
    "dtype"
  ],
  "launch_kernel": [
    "data",
    "cfg"
  ],
  "freq_mask_check": [
    "x",
    "x_len",
    "f_start",
    "f_len",
    "mask_value",
    "bidx"
  ],
  "time_mask_check": [
    "x",
    "x_len",
    "t_start",
    "t_len",
    "mask_value",
    "bidx"
  ],
  "TestSpecAugmentNumba": {
    "test_spec_aug_kernel": [
      "self",
      "dtype"
    ],
    "test_spec_aug_kernel_large_batch": [
      "self",
      "dtype"
    ],
    "test_spec_aug_kernel_mask_value": [
      "self"
    ],
    "test_spec_aug_kernel_grad": [
      "self"
    ],
    "test_spec_aug_kernel_no_freq_mask": [
      "self"
    ],
    "test_spec_aug_kernel_no_time_mask": [
      "self"
    ],
    "test_spec_aug_kernel_no_freq_time_mask": [
      "self"
    ]
  },
  "TestSortformerModules_CheckStreamingParameters": {
    "test_valid_parameters": [
      "self",
      "n_spk",
      "spkcache_len",
      "fifo_len",
      "chunk_len",
      "lc",
      "rc",
      "spkcache_update_period",
      "spkcache_sil_frames_per_spk"
    ],
    "test_invalid_parameters": [
      "self",
      "param_name",
      "param_value",
      "expected_min"
    ],
    "test_invalid_float_parameters": [
      "self",
      "param_name",
      "param_value"
    ],
    "test_invalid_spkcache_len": [
      "self",
      "spkcache_len",
      "n_spk",
      "spkcache_sil_frames_per_spk"
    ]
  },
  "TestSortformerModules_GeneralUtils": {
    "test_length_to_mask": [
      "self",
      "batch_size",
      "max_length",
      "lengths"
    ],
    "test_forward_speaker_sigmoids": [
      "self",
      "batch_size",
      "n_frames",
      "num_spks"
    ],
    "test_apply_mask_to_preds": [
      "self",
      "batch_size",
      "n_frames",
      "n_spk",
      "encoder_lengths"
    ]
  },
  "TestSortformerModules_StreamingUtils": {
    "test_streaming_feat_loader": [
      "self",
      "batch_size",
      "feat_dim",
      "feat_len",
      "chunk_len",
      "subsampling_factor",
      "chunk_left_context",
      "chunk_right_context"
    ],
    "test_concat_and_pad": [
      "self",
      "batch_size",
      "emb_dim",
      "n_frames",
      "num_tensors"
    ],
    "test_concat_embs": [
      "self",
      "tensor_shapes",
      "dim",
      "return_lengths",
      "device"
    ],
    "test_init_streaming_state": [
      "self",
      "batch_size",
      "async_streaming",
      "device"
    ]
  },
  "TestSortformerModules_StreamingScoreComputations": {
    "test_boost_topk_scores": [
      "self",
      "batch_size",
      "n_frames",
      "n_spk",
      "n_boost_per_spk",
      "scale_factor",
      "offset"
    ],
    "test_get_silence_profile": [
      "self",
      "batch_size",
      "n_frames",
      "emb_dim",
      "n_spk",
      "sil_threshold"
    ],
    "test_get_log_pred_scores": [
      "self",
      "batch_size",
      "n_frames",
      "n_spk",
      "pred_score_threshold"
    ],
    "test_get_topk_indices": [
      "self",
      "batch_size",
      "n_frames",
      "n_spk",
      "spkcache_len",
      "spkcache_sil_frames_per_spk"
    ],
    "test_gather_spkcache_and_preds": [
      "self",
      "batch_size",
      "n_frames",
      "n_spk",
      "spkcache_len"
    ],
    "test_get_max_perm_index": [
      "self",
      "batch_size",
      "n_frames",
      "n_spk"
    ],
    "test_disable_low_scores": [
      "self",
      "batch_size",
      "n_frames",
      "n_spk",
      "min_pos_scores_per_spk"
    ],
    "test_permute_speakers": [
      "self",
      "batch_size",
      "n_frames",
      "n_spk"
    ],
    "test_compress_spkcache": [
      "self",
      "batch_size",
      "n_frames",
      "n_spk",
      "spkcache_len"
    ]
  },
  "TestSortformerModules_StreamingUpdate": {
    "test_fifo_not_full": [
      "self",
      "batch_size",
      "emb_dim",
      "n_spk",
      "spkcache_len",
      "cur_spkcache_len",
      "fifo_len",
      "cur_fifo_len",
      "chunk_len",
      "lc",
      "rc"
    ],
    "test_fifo_full_no_compression": [
      "self",
      "batch_size",
      "emb_dim",
      "n_spk",
      "spkcache_len",
      "cur_spkcache_len",
      "fifo_len",
      "cur_fifo_len",
      "chunk_len",
      "spkcache_update_period",
      "lc",
      "rc"
    ],
    "test_fifo_full_with_compression": [
      "self",
      "batch_size",
      "emb_dim",
      "n_spk",
      "spkcache_len",
      "cur_spkcache_len",
      "fifo_len",
      "cur_fifo_len",
      "chunk_len",
      "spkcache_update_period",
      "lc",
      "rc"
    ],
    "test_training_mode_with_permutation": [
      "self",
      "batch_size",
      "emb_dim",
      "n_spk",
      "spkcache_len",
      "cur_spkcache_len",
      "fifo_len",
      "cur_fifo_len",
      "chunk_len",
      "spkcache_update_period",
      "lc",
      "rc"
    ]
  },
  "TestSortformerModules_StreamingUpdateAsync": {
    "_assert_async_batch_item_state": [
      "self",
      "chunk_preds",
      "expected_chunk_preds",
      "fifo_len",
      "expected_fifo_len",
      "fifo",
      "expected_fifo_embs",
      "fifo_preds",
      "expected_fifo_preds",
      "spkcache_len",
      "expected_spkcache_len",
      "spkcache",
      "expected_spkcache_embs",
      "spkcache_preds",
      "expected_spkcache_preds"
    ],
    "test_streaming_update_async": [
      "self",
      "batch_size",
      "emb_dim",
      "n_spk",
      "max_spkcache_len",
      "spkcache_lengths",
      "max_fifo_len",
      "fifo_lengths",
      "max_chunk_len",
      "chunk_lengths",
      "spkcache_update_period",
      "lc",
      "rc"
    ]
  },
  "msdd_model": [],
  "TestEncDecDiarLabelModel": {
    "test_constructor": [
      "self",
      "msdd_model"
    ],
    "test_forward_infer": [
      "self",
      "msdd_model"
    ]
  },
  "TestBCELoss": {
    "test_loss": [
      "self",
      "probs",
      "labels",
      "target_lens",
      "reduction",
      "expected_output"
    ]
  },
  "word_count": [
    "spk_transcript"
  ],
  "calculate_wer_count": [
    "_ins",
    "_del",
    "_sub",
    "ref_word_count"
  ],
  "permuted_input_test": [
    "hyp",
    "ref",
    "calculated"
  ],
  "TestConcatMinPermWordErrorRate": {
    "test_cpwer_oneword": [
      "self"
    ],
    "test_cpwer_perfect": [
      "self"
    ],
    "test_cpwer_spk_counfusion_and_asr_error": [
      "self"
    ],
    "test_cpwer_undercount": [
      "self"
    ],
    "test_cpwer_overcount": [
      "self"
    ],
    "test_get_partial_ref_labels": [
      "self",
      "pred_labels",
      "ref_labels",
      "expected_output"
    ],
    "test_get_online_DER_stats": [
      "self",
      "DER",
      "CER",
      "FA",
      "MISS",
      "diar_eval_count",
      "der_stat_dict",
      "deci",
      "expected_der_dict",
      "expected_der_stat_dict"
    ]
  },
  "get_train_ds_config": [
    "manifest_filepath",
    "batch_size",
    "num_workers"
  ],
  "get_validation_ds_config": [
    "manifest_filepath",
    "batch_size",
    "num_workers"
  ],
  "get_test_ds_config": [
    "manifest_filepath",
    "batch_size",
    "num_workers"
  ],
  "TestLhotseAudioToSpeechE2ESpkDiarDataset": {
    "test_e2e_speaker_diar_lhotse_dataset": [
      "self",
      "test_data_dir",
      "batch_size",
      "num_workers",
      "split"
    ]
  },
  "TestNeuralDiarizerInference": {
    "test_msdd_diar_inference": [
      "self",
      "tmpdir",
      "test_data_dir",
      "device",
      "num_speakers",
      "max_num_speakers"
    ]
  },
  "is_rttm_length_too_long": [
    "rttm_file_path",
    "wav_len_in_sec"
  ],
  "TestAudioToSpeechE2ESpkDiarDataset": {
    "test_e2e_speaker_diar_dataset": [
      "self",
      "test_data_dir"
    ]
  },
  "EncDecSpeechLabelModelTest": {
    "test_constructor": [
      "self"
    ],
    "test_ecapa_enc_dec": [
      "self"
    ],
    "test_titanet_enc_dec": [
      "self"
    ]
  },
  "TestEncDecSpeechLabelModel": {
    "test_pretrained_titanet_embeddings": [
      "self",
      "test_data_dir"
    ],
    "test_pretrained_ambernet_logits": [
      "self",
      "test_data_dir"
    ],
    "test_pretrained_ambernet_logits_batched": [
      "self",
      "test_data_dir"
    ]
  },
  "sortformer_model": [],
  "TestSortformerEncLabelModelOffline": {
    "test_constructor": [
      "self",
      "sortformer_model"
    ],
    "test_forward_infer": [
      "self",
      "sortformer_model",
      "batch_size",
      "sample_len"
    ]
  },
  "TestSortformerEncLabelModelStreaming": {
    "test_constructor": [
      "self",
      "sortformer_model"
    ],
    "test_forward_infer": [
      "self",
      "sortformer_model",
      "batch_size",
      "sample_len"
    ]
  },
  "check_range_values": [
    "target",
    "source"
  ],
  "check_labels": [
    "target",
    "source"
  ],
  "matrix": [
    "mat",
    "use_tensor",
    "dtype"
  ],
  "generate_orthogonal_embs": [
    "total_spks",
    "perturb_sigma",
    "emb_dim"
  ],
  "generate_toy_data": [
    "n_spks",
    "spk_dur",
    "emb_dim",
    "perturb_sigma",
    "ms_window",
    "ms_shift",
    "torch_seed"
  ],
  "TestDiarizationSequneceUtilFunctions": {
    "test_minimal_index_ex2": [
      "self",
      "Y",
      "target",
      "offset"
    ],
    "test_minimal_index_same": [
      "self",
      "N"
    ],
    "test_stitch_cluster_labels_label_switch": [
      "self",
      "N"
    ],
    "test_stitch_cluster_labels_label_many_to_one": [
      "self",
      "N"
    ],
    "test_stitch_cluster_labels_label_one_to_many": [
      "self",
      "N"
    ],
    "test_stitch_cluster_labels_one_label_replaced": [
      "self",
      "N"
    ],
    "test_stitch_cluster_labels_confusion_error": [
      "self",
      "N"
    ],
    "test_stitch_cluster_labels_speaker_more_speakers": [
      "self",
      "N"
    ],
    "test_stitch_cluster_labels_speaker_longer_sequence": [
      "self",
      "N"
    ],
    "test_embedding_merger": [
      "self",
      "n_spks",
      "merge_quantity"
    ],
    "test_cosine_affinity_calculation": [
      "self",
      "n_spks",
      "spk_dur"
    ],
    "test_cosine_affinity_calculation_scale_interpol": [
      "self",
      "n_spks",
      "spk_dur"
    ],
    "test_embedding_reducer": [
      "self",
      "n_spks",
      "target_speaker_index",
      "merge_quantity"
    ],
    "test_merge_scheduler_2clus": [
      "self",
      "ntbr",
      "pcl",
      "mspb"
    ],
    "test_merge_scheduler_3clus": [
      "self",
      "ntbr",
      "pcl",
      "mspb"
    ],
    "test_merge_scheduler_4clus_shuff": [
      "self",
      "ntbr",
      "pcl",
      "mspb"
    ],
    "test_merge_scheduler_3clus_repeat": [
      "self",
      "ntbr",
      "pcl",
      "mspb"
    ]
  },
  "TestClassExport": {
    "test_online_segmentor_class_export": [
      "self"
    ],
    "test_online_segmentor_instance_export": [
      "self"
    ],
    "test_online_speaker_clustering_instance_export": [
      "self"
    ]
  },
  "TestGetSubsegments": {
    "test_get_subsegments": [
      "self",
      "offset",
      "window",
      "shift",
      "duration",
      "min_subsegment_duration",
      "decimals",
      "use_asr_style_frame_count",
      "sample_rate",
      "feat_per_sec",
      "expected"
    ],
    "test_min_subsegment_duration_filtering": [
      "self"
    ],
    "test_zero_duration": [
      "self"
    ],
    "test_edge_case_short_slice": [
      "self"
    ]
  },
  "TestDiarizationSegmentationUtils": {
    "test_merge_int_intervals_ex1": [
      "self",
      "intervals",
      "target"
    ],
    "test_merge_int_intervals_ex2": [
      "self",
      "intervals",
      "target"
    ],
    "test_merge_int_intervals_edge_test": [
      "self",
      "intervals",
      "target"
    ],
    "test_is_overlap_true": [
      "self",
      "rangeA",
      "rangeB"
    ],
    "test_is_overlap_false": [
      "self",
      "rangeA",
      "rangeB"
    ],
    "test_fl2int": [
      "self",
      "x",
      "decimals"
    ],
    "test_int2fl": [
      "self",
      "x",
      "decimals"
    ],
    "test_merge_float_intervals_edge_margin_test": [
      "self"
    ],
    "test_merge_float_overlaps": [
      "self",
      "intervals",
      "target"
    ],
    "test_get_speech_labels_for_update": [
      "self"
    ],
    "test_get_online_subsegments_from_buffer": [
      "self"
    ],
    "test_get_new_cursor_for_update_mulsegs_ex1": [
      "self",
      "frame_start",
      "segment_range_ts",
      "gt_cursor_for_old_segments",
      "gt_cursor_index"
    ],
    "get_sub_range_list": [
      "self",
      "target_range",
      "source_range_list"
    ],
    "test_tensor_to_list": [
      "self",
      "source_range_list"
    ],
    "test_get_online_segments_from_slices": [
      "self",
      "buffer_start",
      "buffer_end",
      "subsegments",
      "ind_offset",
      "window",
      "sample_rate"
    ]
  },
  "TestClusteringUtilFunctions": {
    "test_get_k_neighbors_connections": [
      "self",
      "p_value",
      "N",
      "mask_method",
      "seed"
    ],
    "test_unpack_labels": [
      "self",
      "Y_aggr",
      "window_range_list",
      "absolute_merge_mapping",
      "chunk_cluster_count",
      "embeddings_per_chunk",
      "org_len"
    ]
  },
  "TestSpeakerClustering": {
    "test_offline_clus_script_save_load": [
      "self",
      "cuda"
    ],
    "test_online_clus_script_save_load": [
      "self",
      "cuda"
    ],
    "test_offline_speaker_clustering": [
      "self",
      "n_spks",
      "total_sec",
      "SSV",
      "perturb_sigma",
      "seed",
      "jit_script",
      "cuda"
    ],
    "test_offline_speaker_clustering_cpu": [
      "self",
      "n_spks",
      "total_sec",
      "SSV",
      "perturb_sigma",
      "seed",
      "jit_script",
      "cuda"
    ],
    "test_offline_speaker_clustering_very_short_cpu": [
      "self",
      "n_spks",
      "spk_dur",
      "SSV",
      "enhanced_count_thres",
      "min_samples_for_nmesc",
      "seed"
    ],
    "test_offline_speaker_clustering_very_short_gpu": [
      "self",
      "n_spks",
      "spk_dur",
      "SSV",
      "enhanced_count_thres",
      "min_samples_for_nmesc",
      "seed"
    ],
    "test_longform_speaker_clustering_cpu": [
      "self",
      "n_spks",
      "spk_dur",
      "SSV",
      "enhanced_count_thres",
      "min_samples_for_nmesc",
      "chunk_cluster_count",
      "embeddings_per_chunk",
      "jit_script",
      "seed"
    ],
    "test_longform_speaker_clustering_gpu": [
      "self",
      "n_spks",
      "spk_dur",
      "SSV",
      "enhanced_count_thres",
      "min_samples_for_nmesc",
      "chunk_cluster_count",
      "embeddings_per_chunk",
      "jit_script",
      "seed"
    ],
    "test_online_speaker_clustering": [
      "self",
      "n_spks",
      "total_sec",
      "buffer_size",
      "sigma",
      "seed",
      "jit_script",
      "cuda"
    ],
    "test_online_speaker_clustering_cpu": [
      "self",
      "n_spks",
      "total_sec",
      "buffer_size",
      "sigma",
      "seed",
      "jit_script",
      "cuda"
    ]
  },
  "TestLinearSumAssignmentAlgorithm": {
    "test_lsa_solver_export_test": [
      "self"
    ],
    "test_linear_sum_assignment_algorithm_cost_matrix": [
      "self",
      "cost_matrix"
    ],
    "test_linear_sum_assignment_algorithm_random_matrix": [
      "self",
      "seed",
      "mat_size"
    ]
  },
  "TestMultiTalkerInstanceManagerMethods": {
    "test_reset_active_speaker_buffers": [
      "self",
      "asr_model",
      "diar_model"
    ],
    "test_reset_with_new_params": [
      "self",
      "asr_model",
      "diar_model"
    ],
    "test_add_speaker": [
      "self",
      "asr_model",
      "diar_model"
    ],
    "test_update_diar_state": [
      "self",
      "asr_model",
      "diar_model"
    ],
    "test_update_asr_state": [
      "self",
      "asr_model",
      "diar_model"
    ],
    "test_get_active_speakers_info": [
      "self",
      "asr_model",
      "diar_model"
    ],
    "test_update_seglsts": [
      "self",
      "asr_model",
      "diar_model"
    ]
  },
  "TestGetNewSentenceDict": {
    "test_get_new_sentence_dict": [
      "self",
      "speaker",
      "start_time",
      "end_time",
      "text",
      "session_id"
    ]
  },
  "TestFixFrameTimeStep": {
    "test_fix_frame_time_step_shapes": [
      "self",
      "new_tokens",
      "new_words",
      "frame_inds_seq",
      "expected"
    ]
  },
  "TestGetSimulatedSoftmax": {
    "test_invalid_dims": [
      "self"
    ],
    "test_invalid_length_vs_maxspks": [
      "self"
    ],
    "test_valid_softmax_behavior": [
      "self",
      "vec",
      "min_sigmoid_val",
      "max_num_of_spks",
      "expected_prefix"
    ]
  },
  "TestWordDictContentOffline": {
    "test_get_word_dict_content_offline": [
      "self",
      "frame_stt",
      "frame_end",
      "expected_end"
    ]
  },
  "TestWordDictContentOnline": {
    "test_get_word_dict_content_online": [
      "self",
      "token_group",
      "frame_inds_seq",
      "time_step_local_offset",
      "expected_stt",
      "expected_end"
    ]
  },
  "TestGetMultitokenWords": {
    "test_get_multitoken_words_replaces_shorter_saved": [
      "self",
      "verbose"
    ]
  },
  "TestAppendWordAndTsSeq": {
    "test_append_and_fifo_pop": [
      "self"
    ]
  },
  "TestGetDiarPredOutStream": {
    "test_get_diar_pred_out_stream": [
      "self",
      "diar_model",
      "step_num",
      "nframes"
    ]
  },
  "TestWriteSeglst": {
    "test_write_and_read": [
      "self",
      "tmp_path"
    ]
  },
  "TestGetMultiTalkerSamplesFromManifest": {
    "test_missing_audio_filepath": [
      "self",
      "tmp_path"
    ],
    "test_rttm_missing_file": [
      "self",
      "tmp_path"
    ]
  },
  "TestSpeakerTaggedASRInit": {
    "test_init_default_config_values": [
      "self",
      "asr_model",
      "diar_model",
      "tmp_path"
    ],
    "test_init_instance_manager_creation": [
      "self",
      "asr_model",
      "diar_model",
      "tmp_path"
    ]
  },
  "TestSpeakerTaggedASRMethods": {
    "test_get_offset_sentence": [
      "self",
      "asr_model",
      "diar_model",
      "tmp_path"
    ],
    "test_find_active_speakers_valid": [
      "self",
      "asr_model",
      "diar_model",
      "tmp_path"
    ],
    "test_mask_features_valid": [
      "self",
      "asr_model",
      "diar_model",
      "tmp_path"
    ]
  },
  "reconstruct_labels_forloop": [
    "labels",
    "batch_perm_inds"
  ],
  "TestSortingUtils": {
    "test_find_first_nonzero": [
      "self",
      "mat",
      "max_cap_val",
      "thres",
      "expected"
    ],
    "test_find_best_permutation": [
      "self",
      "match_score",
      "speaker_permutations",
      "expected"
    ],
    "test_reconstruct_labels_with_forloop_ver": [
      "self",
      "batch_size",
      "num_frames",
      "num_speakers"
    ],
    "test_reconstruct_labels": [
      "self",
      "labels",
      "batch_perm_inds",
      "expected_output"
    ]
  },
  "TestTargetGenerators": {
    "test_get_ats_targets": [
      "self",
      "labels",
      "preds",
      "num_speakers",
      "expected_output"
    ],
    "test_get_pil_targets": [
      "self",
      "labels",
      "preds",
      "num_speakers",
      "expected_output"
    ]
  },
  "TestGetHiddenLengthFromSampleLength": {
    "test_various_cases": [
      "self",
      "num_samples",
      "num_sample_per_mel_frame",
      "num_mel_frame_per_asr_frame",
      "expected_hidden_length"
    ],
    "test_default_parameters": [
      "self"
    ],
    "test_edge_cases": [
      "self"
    ],
    "test_real_life_examples": [
      "self"
    ]
  },
  "DiarizableDummy": {
    "_diarize_on_begin": [
      "self",
      "audio",
      "diarcfg"
    ],
    "_diarize_input_manifest_processing": [
      "self",
      "audio_files",
      "temp_dir",
      "diarcfg"
    ],
    "_setup_diarize_dataloader": [
      "self",
      "config"
    ],
    "_diarize_forward": [
      "self",
      "batch"
    ],
    "_diarize_output_processing": [
      "self",
      "outputs",
      "uniq_ids",
      "diarcfg"
    ]
  },
  "TestSpkDiarizationMixin": {
    "test_constructor_non_instance": [
      "self"
    ],
    "test_diarize": [
      "self",
      "dummy_model"
    ],
    "test_diarize_generator": [
      "self",
      "dummy_model"
    ],
    "test_diarize_generator_explicit_stop_check": [
      "self",
      "dummy_model"
    ],
    "test_diarize_check_flags": [
      "self",
      "dummy_model"
    ],
    "test_transribe_override_config_incorrect": [
      "self",
      "dummy_model"
    ],
    "test_transribe_override_config_correct": [
      "self",
      "dummy_model"
    ]
  },
  "MyTestOptimizer": {
    "__init__": [
      "self",
      "params"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "DoNothingOptimizer": {
    "__init__": [
      "self",
      "params"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "ExampleMCoreModel": {
    "sharded_state_dict": [
      "self"
    ]
  },
  "DoNothingModel": {
    "configure_optimizers": [
      "self"
    ]
  },
  "TestExpManager": {
    "_mock_onelogger_update_config": [
      "self"
    ],
    "test_omegaconf": [
      "self"
    ],
    "test_trainer_loggers": [
      "self",
      "tmp_path"
    ],
    "test_trainer_neptune_logger": [
      "self",
      "tmp_path"
    ],
    "test_checkpoint_configurations": [
      "self"
    ],
    "test_default_log_dir": [
      "self"
    ],
    "test_log_dir_overrides": [
      "self",
      "monkeypatch",
      "tmp_path"
    ],
    "test_resume": [
      "self",
      "tmp_path"
    ],
    "test_nemo_checkpoint_save_best_model_1": [
      "self",
      "tmp_path"
    ],
    "test_nemo_checkpoint_save_best_model_2": [
      "self",
      "tmp_path"
    ],
    "test_nemo_checkpoint_always_save_nemo": [
      "self",
      "tmp_path"
    ],
    "test_nemo_checkpoint_doesnt_produce_too_many_nemo_ckpts": [
      "self",
      "tmp_path"
    ],
    "test_nemo_checkpoint_make_checkpoint_dir": [
      "self",
      "tmp_path"
    ],
    "test_nemo_checkpoint_restore_model": [
      "self",
      "tmp_path"
    ],
    "test_base_checkpoints_are_not_overwritten": [
      "self",
      "tmp_path",
      "test_dist_ckpt"
    ],
    "test_last_checkpoint_saved": [
      "self",
      "tmp_path"
    ],
    "test_resume_checkpoint_skip_validation": [
      "self",
      "tmp_path"
    ],
    "test_warning_validation_skipping_when_custom_epoch_loop": [
      "self",
      "tmp_path"
    ],
    "_write_fake_checkpoint": [
      "self",
      "path",
      "isdir",
      "add_unfinished_marker"
    ],
    "test_skipped_unfinished_checkpoints_when_restoring": [
      "self",
      "tmp_path"
    ],
    "test_skipped_unfinished_dist_checkpoints_when_restoring": [
      "self",
      "tmp_path"
    ],
    "test_incomplete_checkpoints_cleanup": [
      "self",
      "tmp_path"
    ],
    "test_incomplete_dist_checkpoints_cleanup": [
      "self",
      "tmp_path"
    ],
    "_chkpt_path_and_marker_path_pairs": [],
    "test_incomplete_checkpoints_marker_path": [
      "self",
      "chkpt_path",
      "expected_marker_path"
    ],
    "test_invalid_checkpoints_removed_from_topk": [
      "self",
      "tmp_path"
    ],
    "test_doesnt_silently_start_from_scratch": [
      "self",
      "tmp_path"
    ],
    "test_doesnt_silently_start_from_scratch_dist": [
      "self",
      "tmp_path"
    ],
    "test_save_nemo_not_comp_with_model_parallel": [
      "self",
      "tmp_path"
    ]
  },
  "cls": [],
  "TestConfigUtils": {
    "test_all_args_exist": [
      "self",
      "cls"
    ],
    "test_all_args_dont_exist": [
      "self",
      "cls"
    ],
    "test_extra_args_exist": [
      "self",
      "cls"
    ],
    "test_extra_args_exist_but_is_ignored": [
      "self",
      "cls"
    ],
    "test_args_exist_but_is_remapped": [
      "self",
      "cls"
    ],
    "test_ptl_config": [
      "self"
    ],
    "test_early_stopping_config": [
      "self"
    ]
  },
  "TestNeuralTypeSystem": {
    "test_short_vs_long_version": [
      "self"
    ],
    "test_parameterized_type_audio_sampling_frequency": [
      "self"
    ],
    "test_transpose_same_1": [
      "self"
    ],
    "test_transpose_same_2": [
      "self"
    ],
    "test_inheritance_spec_augment_example": [
      "self"
    ],
    "test_singletone": [
      "self"
    ],
    "test_list_of_lists": [
      "self"
    ],
    "test_void": [
      "self"
    ],
    "test_big_void": [
      "self"
    ],
    "test_unspecified_dimensions": [
      "self"
    ],
    "test_any_axis": [
      "self"
    ],
    "test_struct": [
      "self"
    ]
  },
  "get_all_neural_types": [],
  "SimpleLinear": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SimpleLinearExportable": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SimpleLinearWithAdapterMixin": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SimpleLinearWithTypes": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DummyModuleWithIOTypes": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TestTorchJitCompatibility": {
    "test_simple_linear": [
      "self"
    ],
    "test_simple_linear_exportable": [
      "self"
    ],
    "test_simple_linear_with_adapter_mixin": [
      "self"
    ],
    "test_simple_linear_with_types": [
      "self"
    ],
    "test_element_compilable": [
      "self",
      "neural_type"
    ],
    "test_dummy_module_with_io_types": [
      "self"
    ],
    "test_chain_with_types": [
      "self"
    ]
  },
  "get_class_path": [
    "cls"
  ],
  "MockSerializationImpl": {
    "__init__": [
      "self",
      "cfg"
    ]
  },
  "MockSerializationImplV2": {},
  "TestSerialization": {
    "test_from_config_dict_with_cls": [
      "self"
    ],
    "test_from_config_dict_without_cls": [
      "self"
    ],
    "test_config_updated": [
      "self"
    ],
    "test_base_class_instantiation": [
      "self"
    ],
    "test_self_class_instantiation": [
      "self"
    ],
    "test_sub_class_instantiation": [
      "self"
    ]
  },
  "classpath": [
    "cls"
  ],
  "get_dir_size": [
    "path"
  ],
  "get_size": [
    "path"
  ],
  "_is_json_serializable": [
    "value"
  ],
  "MockModelWithChildren": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ]
  },
  "MockModelWithChildEncDecCTCBPE": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ]
  },
  "MockModelWithChildCustomConfigPath": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ]
  },
  "MockModelIncorrectWithNemoArtifact": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ]
  },
  "_mock_model_config": [],
  "_mock_model_with_children_config": [
    "child1_model_path",
    "child2_model_path",
    "child2_model_cfg"
  ],
  "_mock_model_with_child_encdecctcbpe_config": [
    "pretrained_model_name"
  ],
  "_mock_model_with_child_custom_config_path_config": [],
  "_mock_model_incorrect_with_nemo_artifact_config": [
    "child_model_path"
  ],
  "TestSaveRestore": {
    "__test_restore_elsewhere": [
      "self",
      "model",
      "attr_for_eq_check",
      "override_config_path",
      "map_location",
      "strict",
      "return_config"
    ],
    "test_EncDecCTCModel": [
      "self"
    ],
    "test_EncDecCTCModelBPE": [
      "self"
    ],
    "test_EncDecCTCModelBPE_v2": [
      "self"
    ],
    "test_EncDecCTCModelBPE_v3": [
      "self"
    ],
    "test_EncDecCTCModelBPE_HF": [
      "self"
    ],
    "test_mock_save_to_restore_from": [
      "self"
    ],
    "test_mock_restore_from_config_only": [
      "self"
    ],
    "test_mock_restore_from_config_override_with_OmegaConf": [
      "self"
    ],
    "test_mock_restore_from_config_override_with_yaml": [
      "self"
    ],
    "test_mock_save_to_restore_from_with_target_class": [
      "self"
    ],
    "test_mock_save_to_restore_from_multiple_models": [
      "self"
    ],
    "test_mock_save_to_restore_from_multiple_models_inverted_order": [
      "self"
    ],
    "test_mock_save_to_restore_chained": [
      "self"
    ],
    "test_mock_save_to_multiple_times": [
      "self"
    ],
    "test_multiple_model_save_restore_connector": [
      "self"
    ],
    "test_restore_from_save_restore_connector": [
      "self"
    ],
    "test_restore_from_save_restore_connector_return_config": [
      "self"
    ],
    "test_restore_from_save_restore_connector_return_config_partial_tar_extraction": [
      "self"
    ],
    "test_restore_from_save_restore_connector_unpacked_file": [
      "self"
    ],
    "test_mock_model_model_collision": [
      "self"
    ],
    "test_mock_model_nested": [
      "self",
      "change_child_number",
      "child2_model_from_path"
    ],
    "test_mock_model_nested_with_resources": [
      "self",
      "change_child_resource",
      "child2_model_from_path"
    ],
    "test_mock_model_nested_with_resources_multiple_passes": [
      "self"
    ],
    "test_mock_model_nested_double_with_resources": [
      "self"
    ],
    "test_mock_model_nested_child_from_pretrained": [
      "self"
    ],
    "test_mock_model_nested_custom_config_field": [
      "self"
    ],
    "test_using_nemo_checkpoint_as_artifact_disallowed": [
      "self"
    ],
    "test_restore_from_save_restore_connector_extracted_dir": [
      "self"
    ],
    "test_hf_model_filter": [
      "self"
    ],
    "test_hf_model_info": [
      "self"
    ],
    "test_hf_model_info_with_card_data": [
      "self"
    ],
    "test_hf_model_info_with_limited_results": [
      "self"
    ],
    "test_filtering_methods": [
      "self",
      "filter_method",
      "tar_input"
    ]
  },
  "MockDistributedCheckpointIO": {
    "__init__": [
      "self",
      "save_ckpt_format"
    ],
    "save_checkpoint": [
      "self"
    ]
  },
  "MockTorchCheckpointIO": {
    "__init__": [
      "self"
    ],
    "save_checkpoint": [
      "self"
    ]
  },
  "_get_nlp_strategy_without_optimizer_state": [],
  "TestAsyncSave": {
    "test_async_save_produces_same_checkpoints_as_sync": [
      "self",
      "tmp_path"
    ]
  },
  "TestFaultTolerance": {
    "test_fault_tol_callback_not_created_by_default": [
      "self"
    ],
    "test_fault_tol_callback_created": [
      "self"
    ]
  },
  "requires_eff": [],
  "TestFileIO": {
    "test_to_from_config_file": [
      "self",
      "asr_model"
    ],
    "test_save_restore_from_nemo_file": [
      "self",
      "asr_model"
    ],
    "test_eff_save_restore_from_nemo_file_encrypted": [
      "self",
      "asr_model"
    ],
    "test_save_restore_from_nemo_file_with_override": [
      "self",
      "asr_model",
      "tmpdir"
    ],
    "test_save_model_level_pt_ckpt": [
      "self",
      "asr_model"
    ],
    "test_save_module_level_pt_ckpt": [
      "self",
      "asr_model"
    ]
  },
  "TestStragglerDetection": {
    "test_prints_perf_scores": [
      "self",
      "tmp_path"
    ]
  },
  "TempModule": {
    "__init__": [
      "self"
    ]
  },
  "TestNeuralModule": {
    "test_num_weights": [
      "self"
    ],
    "test_freeze": [
      "self"
    ],
    "test_unfreeze": [
      "self"
    ],
    "test_as_frozen": [
      "self"
    ],
    "test_partial_unfreeze": [
      "self"
    ]
  },
  "recursive_assert_shape": [
    "x",
    "shape"
  ],
  "recursive_assert_homogeneous_type": [
    "x",
    "type_val"
  ],
  "TestNeuralTypeCheckSystem": {
    "test_no_types_passthrough": [
      "self"
    ],
    "test_input_output_types": [
      "self"
    ],
    "test_input_types_only": [
      "self"
    ],
    "test_multiple_input_types_only": [
      "self"
    ],
    "test_output_types_only": [
      "self"
    ],
    "test_multiple_output_types_only": [
      "self"
    ],
    "test_multiple_output_types_only_namedtuple": [
      "self"
    ],
    "test_multiple_mixed_output_types_only": [
      "self"
    ],
    "test_multiple_mixed_output_types_only_namedtuple": [
      "self"
    ],
    "test_multiple_mixed_output_types_only_mismatched": [
      "self"
    ],
    "test_multiple_mixed_output_types_only_namedtuple_mismatched": [
      "self"
    ],
    "test_incorrect_inheritance": [
      "self"
    ],
    "test_port_definition_rejection": [
      "self"
    ],
    "test_port_shape_rejection": [
      "self"
    ],
    "test_positional_args": [
      "self"
    ],
    "test_optional_types": [
      "self"
    ],
    "test_input_output_neural_types": [
      "self"
    ],
    "test_nested_input_output_neural_types": [
      "self"
    ],
    "test_nested_input_output_neural_types_ignore_collections": [
      "self"
    ],
    "test_nested_mixed_input_output_neural_types": [
      "self"
    ],
    "test_multi_forward_type": [
      "self"
    ],
    "test_input_type_override": [
      "self"
    ],
    "test_output_type_override": [
      "self"
    ],
    "test_multi_type_override": [
      "self"
    ],
    "test_disable_typecheck": [
      "self"
    ],
    "test_nested_shape_mismatch": [
      "self"
    ],
    "test_nested_mixed_shape_mismatch": [
      "self"
    ],
    "test_input_container_neural_types": [
      "self"
    ],
    "test_input_container_neural_types_incorrect": [
      "self"
    ],
    "test_output_container_neural_types_incorrect": [
      "self"
    ],
    "test_output_container_neural_types_no_tuple_wrap": [
      "self"
    ],
    "test_output_container_neural_types_explicit_tuple_wrap": [
      "self"
    ],
    "test_disable_semantic_types_input_output": [
      "self"
    ]
  },
  "TempModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OptCounter": {
    "__init__": [
      "self"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "Callback": {
    "on_train_end": [
      "self",
      "trainer",
      "module"
    ],
    "assert_counts": [
      "self",
      "trainer",
      "module",
      "count"
    ]
  },
  "SchedulerNoOpCallback": {
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ],
    "assert_counts": [
      "self",
      "trainer",
      "module",
      "count"
    ]
  },
  "TestOptimizersSchedulers": {
    "INITIAL_LR": [],
    "MIN_LR": [],
    "MAX_STEPS": [],
    "D_MODEL": [],
    "test_get_optimizer": [
      "self"
    ],
    "test_register_optimizer": [
      "self"
    ],
    "test_optim_config_parse_bypass": [
      "self"
    ],
    "test_optim_config_parse_arg_by_name": [
      "self"
    ],
    "test_optim_config_parse_arg_by_target": [
      "self"
    ],
    "test_get_scheduler": [
      "self"
    ],
    "test_register_scheduler": [
      "self"
    ],
    "test_sched_config_parse_simple": [
      "self"
    ],
    "test_sched_config_parse_from_cls": [
      "self"
    ],
    "test_sched_config_parse_reduce_on_plateau": [
      "self"
    ],
    "test_WarmupPolicy": [
      "self"
    ],
    "test_WarmupHoldPolicy": [
      "self"
    ],
    "test_WarmupAnnealing": [
      "self"
    ],
    "test_SquareAnnealing": [
      "self"
    ],
    "test_SquareRootAnnealing": [
      "self"
    ],
    "test_CosineAnnealing": [
      "self"
    ],
    "test_NoamAnnealing": [
      "self"
    ],
    "test_PolynomialDecayAnnealing": [
      "self"
    ],
    "test_PolynomialHoldDecayAnnealing": [
      "self"
    ],
    "test_InverseSquareRootAnnealing": [
      "self"
    ]
  },
  "TestWarmupHoldAnnealSchedulers": {
    "INITIAL_LR": [],
    "MIN_LR": [],
    "MAX_STEPS": [],
    "test_WarmupHoldAnnealOneMinusSquareRoot": [
      "self"
    ],
    "test_WarmupHoldAnnealLinear": [
      "self"
    ],
    "test_CosineAnnealing_with_noop_steps": [
      "self"
    ],
    "test_max_step_computation": [
      "self"
    ],
    "test_max_step_computation_with_sched_no_ops": [
      "self"
    ]
  },
  "DefaultModule": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "num_params": [
      "self"
    ]
  },
  "DefaultModuleAdapter": {
    "forward": [
      "self",
      "x"
    ]
  },
  "DefaultModelAdapterMixin": {
    "setup_adapters": [
      "self"
    ],
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "is_adapter_available": [
      "self"
    ],
    "check_valid_model_with_adapter_support_": [
      "self"
    ],
    "resolve_adapter_module_name_": [
      "self",
      "name"
    ],
    "_get_global_cfg": [
      "self"
    ],
    "adapter_module_names": [
      "self"
    ],
    "default_adapter_module_name": [
      "self"
    ]
  },
  "DefaultAdapterModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "forward": [
      "self",
      "x"
    ],
    "list_available_models": [
      "cls"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ]
  },
  "get_model_config": [
    "in_features",
    "update_adapter_cfg"
  ],
  "update_adapter_global_cfg": [
    "cfg",
    "encoder_adapter",
    "decoder_adapter"
  ],
  "TestAdapterModelMixin": {
    "test_base_model_no_support_for_adapters": [
      "self",
      "caplog"
    ],
    "test_base_model_replace_adapter_compatible_modules": [
      "self",
      "caplog"
    ],
    "test_single_adapter": [
      "self"
    ],
    "test_single_encoder_module_adapter": [
      "self"
    ],
    "test_single_decoder_module_adapter": [
      "self"
    ],
    "test_single_adapter_default_metaconfig": [
      "self"
    ],
    "test_all_disabled_adapters": [
      "self"
    ],
    "test_set_enabled_all_adapters_with_no_name": [
      "self"
    ],
    "test_set_enabled_all_adapters_with_no_name_only_decoder": [
      "self"
    ],
    "test_enc_dec_enabled_adapters": [
      "self"
    ],
    "test_multiple_adapter": [
      "self",
      "enc",
      "dec"
    ],
    "test_multiple_adapter_non_unique_adapter_name": [
      "self"
    ],
    "test_forward_linear_pre": [
      "self",
      "enc",
      "dec"
    ],
    "test_forward_linear_post": [
      "self",
      "enc",
      "dec"
    ],
    "test_multi_adapter_forward": [
      "self",
      "enc",
      "dec"
    ],
    "test_multi_adapter_partial_forward_global_module_different": [
      "self",
      "enc",
      "dec"
    ],
    "test_multi_adapter_partial_forward_global_module_same_output": [
      "self",
      "name1",
      "name2"
    ],
    "test_forward_unfrozen_adapters": [
      "self",
      "enc",
      "dec"
    ],
    "test_forward_linear_no_strategy": [
      "self"
    ],
    "test_forward_linear_replaced_strategy": [
      "self"
    ],
    "test_save_adapter_with_no_adapters_added": [
      "self"
    ],
    "test_single_decoder_save_load_adapter_only_exact_name": [
      "self"
    ],
    "test_single_decoder_save_load_adapter_only_global_name": [
      "self",
      "restore_name"
    ],
    "test_multiple_decoder_save_load_adapter_only_exact_name": [
      "self"
    ],
    "test_multiple_save_load_adapter_with_multiple_load": [
      "self",
      "decoder",
      "encoder"
    ],
    "test_multiple_decoder_save_load_adapter_dual_name": [
      "self"
    ],
    "test_single_decoder_save_load_adapter_only_partial_name": [
      "self"
    ]
  },
  "TestAdapterStrategy": {
    "test_ResidualAddAdapterStrategyConfig": [
      "self"
    ],
    "test_strategy_default": [
      "self"
    ],
    "test_strategy_stochasic_depth": [
      "self",
      "stochastic_depth"
    ],
    "test_strategy_l2_lambda": [
      "self"
    ]
  },
  "TestAdapterMixin": {
    "test_module_registered_adapter_by_class_path": [
      "self"
    ],
    "test_module_registered_adapter_by_class": [
      "self"
    ],
    "test_module_registered_adapter_by_adapter_class": [
      "self"
    ],
    "test_single_adapter": [
      "self"
    ],
    "test_multiple_adapter": [
      "self"
    ],
    "test_forward_linear_pre": [
      "self"
    ],
    "test_forward_linear_post": [
      "self"
    ],
    "test_multi_adapter_forward": [
      "self"
    ],
    "test_multi_adapter_partial_forward": [
      "self"
    ],
    "test_forward_unfrozen_adapters": [
      "self"
    ],
    "test_forward_linear_no_strategy": [
      "self"
    ],
    "test_forward_linear_replaced_strategy": [
      "self"
    ]
  },
  "construct_negatives": [
    "input_file",
    "output_file",
    "num_passages",
    "num_negatives"
  ],
  "DEFAULT_NEMO_HOME": [],
  "hf_tokenizer": [
    "model_name"
  ],
  "import_ckpt_experiment": [
    "executor",
    "model",
    "source"
  ],
  "get_nemo_home": [
    "nemo_home"
  ],
  "prepare_squad_dataset": [
    "model_name",
    "seq_length",
    "nemo_home"
  ],
  "prepare_squad_dataset_experiment": [
    "executor",
    "model_name",
    "seq_length",
    "nemo_home"
  ],
  "isfile_train_pack_metadata": [
    "hf_model_uri",
    "data_config"
  ],
  "get_comm_overlap_callback_idx": [
    "callbacks"
  ],
  "dump_config_diff_from_base_recipe": [
    "base_recipe",
    "new_recipe",
    "output_dir",
    "file_name"
  ],
  "get_csv_configs": [
    "gpu",
    "task",
    "model_name",
    "model_size",
    "args"
  ],
  "get_user_configs": [
    "gpu",
    "task",
    "model_name",
    "model_size",
    "args"
  ],
  "set_mcore_fsdp_configs": [
    "recipe",
    "comm_overlap_callback_idx",
    "tp_size"
  ],
  "set_precision_configs": [
    "recipe",
    "compute_dtype",
    "fp8_recipe"
  ],
  "set_recompute_configs": [
    "recipe",
    "recompute_layers",
    "activation_offload_layers",
    "recompute_modules"
  ],
  "set_cuda_graph_configs": [
    "recipe",
    "enable_cuda_graphs",
    "task"
  ],
  "set_full_iteration_cuda_graph_configs": [
    "recipe",
    "pp_size",
    "vp_size"
  ],
  "set_perf_optimization_configs": [
    "recipe",
    "use_mcore_fsdp",
    "enable_cuda_graphs",
    "task",
    "tp_size",
    "pp_size",
    "vp_size",
    "compute_dtype",
    "fp8_recipe",
    "recompute_layers",
    "activation_offload_layers",
    "recompute_modules",
    "use_fsdp_double_buffer",
    "use_user_buffer_registration",
    "use_sharp",
    "keep_fsdp_fp8_transpose_cache"
  ],
  "set_primary_perf_configs": [
    "recipe",
    "task",
    "num_nodes",
    "num_gpus_per_node",
    "mbs",
    "gbs",
    "max_steps",
    "tp_size",
    "pp_size",
    "cp_size",
    "vp_size",
    "ep_size",
    "etp_size",
    "enable_cuda_graphs",
    "use_mcore_fsdp",
    "use_fsdp_double_buffer",
    "use_user_buffer_registration",
    "use_sharp",
    "recompute_layers",
    "activation_offload_layers",
    "compute_dtype",
    "fp8_recipe",
    "recompute_modules",
    "nccl_communicator_config_path",
    "keep_fsdp_fp8_transpose_cache",
    "use_te_op_fuser",
    "use_te_act_func",
    "act_func_fp8_input_store"
  ],
  "set_exp_logging_configs": [
    "recipe",
    "task",
    "domain",
    "model_name",
    "enable_tb",
    "enable_wd",
    "wandb_prj_name",
    "wandb_job_name"
  ],
  "args_sanity_check": [
    "args"
  ],
  "build_perf_env_plugin": [
    "args",
    "pp_size",
    "user_buffer_registration"
  ],
  "INLINE_TEMPLATE": [],
  "slurm_executor": [
    "gpu",
    "account",
    "partition",
    "log_dir",
    "nodes",
    "num_gpus_per_node",
    "time_limit",
    "container_image",
    "custom_mounts",
    "custom_env_vars",
    "custom_srun_args",
    "hf_token",
    "nemo_home",
    "wandb_key",
    "network",
    "custom_bash_cmds",
    "optional_gpus_per_node",
    "additional_slurm_params"
  ],
  "parse_cli_args": [],
  "parse_additional_slurm_params": [
    "params_str"
  ],
  "HF_MODEL_URI": [],
  "SKIP_IMPORT": [],
  "SKIP_DATASET_DOWNLOAD": [],
  "override_recipe_configs": [
    "args",
    "num_nodes",
    "mbs",
    "gbs",
    "tp_size",
    "pp_size",
    "cp_size",
    "vp_size",
    "ep_size",
    "enable_cuda_graphs",
    "use_mcore_fsdp",
    "recompute_layers",
    "activation_offload_layers"
  ],
  "USE_TOKEN_DROP": [],
  "NUM_NODES": [],
  "NUM_GPUS_PER_NODE": [],
  "MICRO_BATCH_SIZE": [],
  "GLOBAL_BATCH_SIZE": [],
  "TP_SIZE": [],
  "PP_SIZE": [],
  "CP_SIZE": [],
  "MAX_STEPS": [],
  "SEQ_LENGTH": [],
  "mlperf_lora_llama2_70b_recipe": [
    "num_nodes",
    "num_gpus_per_node",
    "mbs",
    "gbs",
    "tp_size",
    "pp_size",
    "cp_size",
    "max_steps"
  ],
  "MAJOR": [],
  "MINOR": [],
  "PATCH": [],
  "PRE_RELEASE": [],
  "VERSION": [],
  "__shortversion__": [],
  "__version__": [],
  "__package_name__": [],
  "__contact_names__": [],
  "__contact_emails__": [],
  "__homepage__": [],
  "__repository_url__": [],
  "__download_url__": [],
  "__description__": [],
  "__license__": [],
  "__keywords__": [],
  "NEMO_ENV_VARNAME_ENABLE_COLORING": [],
  "NEMO_ENV_VARNAME_REDIRECT_LOGS_TO_STDERR": [],
  "NEMO_ENV_VARNAME_TESTING": [],
  "NEMO_ENV_VARNAME_VERSION": [],
  "NEMO_ENV_CACHE_DIR": [],
  "NEMO_ENV_DATA_STORE_CACHE_DIR": [],
  "NEMO_ENV_DATA_STORE_CACHE_SHARED": [],
  "use_deploy": [],
  "noop_decorator": [
    "func"
  ],
  "use_pytriton": [],
  "batch": [],
  "LOGGER": [],
  "TensorRTMMExporter": {
    "__init__": [
      "self",
      "model_dir",
      "load_model",
      "modality"
    ],
    "export": [
      "self",
      "visual_checkpoint_path",
      "llm_checkpoint_path",
      "model_type",
      "llm_model_type",
      "tensor_parallel_size",
      "max_input_len",
      "max_output_len",
      "max_batch_size",
      "vision_max_batch_size",
      "max_multimodal_len",
      "dtype",
      "delete_existing_files",
      "load_model",
      "use_lora_plugin",
      "lora_target_modules",
      "lora_checkpoint_path",
      "max_lora_rank"
    ],
    "forward": [
      "self",
      "input_text",
      "input_media",
      "batch_size",
      "max_output_len",
      "top_k",
      "top_p",
      "temperature",
      "repetition_penalty",
      "num_beams",
      "lora_uids"
    ],
    "get_input_media_tensors": [
      "self"
    ],
    "get_triton_input": [
      "self"
    ],
    "get_triton_output": [
      "self"
    ],
    "triton_infer_fn": [
      "self"
    ],
    "_load": [
      "self"
    ]
  },
  "use_onnxruntime": [],
  "use_trt": [],
  "OnnxLLMExporter": {
    "__init__": [
      "self",
      "onnx_model_dir",
      "model",
      "tokenizer",
      "model_name_or_path",
      "load_runtime"
    ],
    "_load_runtime": [
      "self"
    ],
    "_load_hf_model": [
      "self"
    ],
    "export": [
      "self",
      "input_names",
      "output_names",
      "example_inputs",
      "opset",
      "dynamic_axes_input",
      "dynamic_axes_output",
      "export_dtype",
      "verbose"
    ],
    "_export_to_onnx": [
      "self",
      "input_names",
      "output_names",
      "example_inputs",
      "opset",
      "dynamic_axes_input",
      "dynamic_axes_output",
      "export_dtype",
      "verbose"
    ],
    "export_onnx_to_trt": [
      "self",
      "trt_model_dir",
      "profiles",
      "override_layernorm_precision_to_fp32",
      "override_layers_to_fp32",
      "trt_dtype",
      "profiling_verbosity",
      "trt_builder_flags"
    ],
    "_override_layer_precision_to_fp32": [
      "self",
      "layer"
    ],
    "_override_layers_to_fp32": [
      "self",
      "network",
      "fp32_layer_patterns"
    ],
    "_override_layernorm_precision_to_fp32": [
      "self",
      "network"
    ],
    "forward": [
      "self",
      "inputs",
      "dimensions"
    ],
    "get_model": [
      "self"
    ],
    "get_tokenizer": [
      "self"
    ],
    "get_model_input_names": [
      "self"
    ],
    "get_triton_input": [
      "self"
    ],
    "get_triton_output": [
      "self"
    ],
    "triton_infer_fn": [
      "self"
    ]
  },
  "TarPath": {
    "__init__": [
      "self",
      "tar"
    ],
    "__del__": [
      "self"
    ],
    "__truediv__": [
      "self",
      "key"
    ],
    "__str__": [
      "self"
    ],
    "tarobject": [
      "self"
    ],
    "relpath": [
      "self"
    ],
    "name": [
      "self"
    ],
    "suffix": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "exists": [
      "self"
    ],
    "is_file": [
      "self"
    ],
    "is_dir": [
      "self"
    ],
    "open": [
      "self",
      "mode"
    ],
    "glob": [
      "self",
      "pattern"
    ],
    "rglob": [
      "self",
      "pattern"
    ],
    "iterdir": [
      "self"
    ]
  },
  "ZarrPathStore": {
    "__init__": [
      "self",
      "tarpath"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "__delitem__": [
      "self",
      "key"
    ],
    "keys": [
      "self"
    ]
  },
  "vLLMHFExporter": {
    "__init__": [
      "self"
    ],
    "export": [
      "self",
      "model",
      "enable_lora"
    ],
    "add_lora_models": [
      "self",
      "lora_model_name",
      "lora_model"
    ],
    "get_triton_input": [
      "self"
    ],
    "get_triton_output": [
      "self"
    ],
    "triton_infer_fn": [
      "self"
    ],
    "forward": [
      "self",
      "input_texts",
      "max_output_len",
      "top_k",
      "top_p",
      "temperature",
      "lora_model_name"
    ]
  },
  "PATTERN_TIKTOKEN": [],
  "DEFAULT_TIKTOKEN_MAX_VOCAB": [],
  "SPECIAL_TOKENS": [],
  "SPECIAL_TOKEN_TEMPLATE": [],
  "reload_mergeable_ranks": [
    "path",
    "max_vocab"
  ],
  "TiktokenTokenizer": {
    "__init__": [
      "self",
      "vocab_file"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "tokens"
    ],
    "batch_decode": [
      "self",
      "ids"
    ],
    "pad_id": [
      "self"
    ],
    "bos_token_id": [
      "self"
    ],
    "eos_token_id": [
      "self"
    ]
  },
  "TensorRTLLM": {
    "__init__": [
      "self",
      "model_dir",
      "lora_ckpt_list",
      "load_model",
      "use_python_runtime",
      "enable_chunked_context",
      "max_tokens_in_paged_kv_cache",
      "multi_block_mode"
    ],
    "export": [
      "self",
      "nemo_checkpoint_path",
      "model_type",
      "delete_existing_files",
      "tensor_parallelism_size",
      "pipeline_parallelism_size",
      "gpus_per_node",
      "max_input_len",
      "max_output_len",
      "max_batch_size",
      "max_prompt_embedding_table_size",
      "use_parallel_embedding",
      "use_embedding_sharing",
      "paged_kv_cache",
      "remove_input_padding",
      "paged_context_fmha",
      "dtype",
      "load_model",
      "use_lora_plugin",
      "lora_target_modules",
      "max_lora_rank",
      "max_num_tokens",
      "opt_num_tokens",
      "max_seq_len",
      "multiple_profiles",
      "gpt_attention_plugin",
      "gemm_plugin",
      "use_mcore_path",
      "reduce_fusion",
      "fp8_quantized",
      "fp8_kvcache",
      "gather_context_logits",
      "gather_generation_logits",
      "build_rank"
    ],
    "export_hf_model": [
      "self",
      "hf_model_path",
      "max_batch_size",
      "tensor_parallelism_size",
      "max_input_len",
      "max_output_len",
      "max_num_tokens",
      "opt_num_tokens",
      "dtype",
      "max_seq_len",
      "gemm_plugin",
      "remove_input_padding",
      "paged_context_fmha",
      "paged_kv_cache",
      "tokens_per_block",
      "multiple_profiles",
      "reduce_fusion",
      "max_beam_width",
      "use_refit",
      "model_type",
      "delete_existing_files"
    ],
    "get_hf_model_dtype": [
      "self",
      "model_dir"
    ],
    "_export_to_nim_format": [
      "self",
      "model_config",
      "model_type"
    ],
    "get_transformer_config": [
      "self",
      "nemo_model_config"
    ],
    "convert_to_safe_tensors": [
      "self",
      "nemo_checkpoint_path",
      "model_type",
      "delete_existing_files",
      "tensor_parallelism_size",
      "pipeline_parallelism_size",
      "gpus_per_node",
      "use_parallel_embedding",
      "use_embedding_sharing",
      "dtype"
    ],
    "gather_and_reshard_model": [
      "self",
      "model_config",
      "model",
      "storage_dtype"
    ],
    "get_input_dtype": [
      "self",
      "storage_dtype"
    ],
    "get_nemo_to_trtllm_conversion_dict": [
      "model_state_dict"
    ],
    "build": [
      "self",
      "model",
      "model_config",
      "model_type",
      "gpus_per_node",
      "tokenizer",
      "max_input_len",
      "max_output_len",
      "max_batch_size",
      "use_refit",
      "reshard_model",
      "use_mcore_path"
    ],
    "refit": [
      "self",
      "model",
      "model_config",
      "use_mcore_path"
    ],
    "forward": [
      "self",
      "input_texts",
      "max_output_len",
      "top_k",
      "top_p",
      "temperature",
      "stop_words_list",
      "bad_words_list",
      "no_repeat_ngram_size",
      "task_ids",
      "lora_uids",
      "prompt_embeddings_table",
      "prompt_embeddings_checkpoint_path",
      "streaming",
      "output_log_probs",
      "output_context_logits",
      "output_generation_logits"
    ],
    "add_prompt_table": [
      "self",
      "task_name",
      "prompt_embeddings_checkpoint_path"
    ],
    "remove_prompt_table": [
      "self",
      "task_name"
    ],
    "_pad_logits": [
      "self",
      "logits_tensor"
    ],
    "get_supported_models_list": [
      "self"
    ],
    "get_supported_hf_model_mapping": [
      "self"
    ],
    "get_hidden_size": [
      "self"
    ],
    "get_triton_input": [
      "self"
    ],
    "get_triton_output": [
      "self"
    ],
    "triton_infer_fn": [
      "self"
    ],
    "triton_infer_fn_streaming": [
      "self"
    ],
    "_prep_ptuning_table": [
      "self"
    ],
    "_load_prompt_tables": [
      "self"
    ],
    "_get_prompt_embedding_table_ckpt": [
      "self",
      "prompt_embeddings_checkpoint_path"
    ],
    "_get_prompt_embedding_table": [
      "self",
      "prompt_embeddings_table",
      "prompt_embeddings_checkpoint_path"
    ],
    "_load_config_file": [
      "self"
    ],
    "_load": [
      "self"
    ],
    "unload_engine": [
      "self"
    ]
  },
  "vLLMExporter": {
    "__init__": [
      "self"
    ],
    "export": [
      "self",
      "nemo_checkpoint",
      "model_dir",
      "model_type",
      "device",
      "tensor_parallel_size",
      "pipeline_parallel_size",
      "max_model_len",
      "lora_checkpoints",
      "dtype",
      "seed",
      "log_stats",
      "weight_storage",
      "gpu_memory_utilization",
      "quantization",
      "delete_existing_files"
    ],
    "_prepare_lora_checkpoints": [
      "self",
      "model_dir",
      "lora_checkpoints",
      "dtype"
    ],
    "_add_request_to_engine": [
      "self",
      "prompt",
      "max_output_len",
      "temperature",
      "top_k",
      "top_p",
      "lora_uid"
    ],
    "_forward_regular": [
      "self",
      "request_ids"
    ],
    "_forward_streaming": [
      "self",
      "request_ids"
    ],
    "_add_triton_request_to_engine": [
      "self",
      "inputs",
      "index"
    ],
    "get_triton_input": [
      "self"
    ],
    "get_triton_output": [
      "self"
    ],
    "triton_infer_fn": [
      "self"
    ],
    "triton_infer_fn_streaming": [
      "self"
    ],
    "forward": [
      "self",
      "input_texts",
      "max_output_len",
      "top_k",
      "top_p",
      "temperature",
      "stop_words_list",
      "bad_words_list",
      "no_repeat_ngram_size",
      "task_ids",
      "lora_uids",
      "prompt_embeddings_table",
      "prompt_embeddings_checkpoint_path",
      "streaming",
      "output_log_probs",
      "output_generation_logits",
      "output_context_logits"
    ]
  },
  "lock_sm": [],
  "trt_to_torch_dtype_dict": [],
  "get_profile_shapes": [
    "input_shape",
    "dynamic_batchsize"
  ],
  "get_dynamic_axes": [
    "profiles"
  ],
  "cuassert": [
    "cuda_ret"
  ],
  "ShapeError": {},
  "TRTEngine": {
    "__init__": [
      "self",
      "plan_path",
      "logger"
    ],
    "allocate_buffers": [
      "self",
      "device"
    ],
    "set_inputs": [
      "self",
      "feed_dict",
      "stream"
    ],
    "infer": [
      "self",
      "stream",
      "use_cuda_graph"
    ]
  },
  "make_tensor": [
    "d"
  ],
  "unroll_input": [
    "input_names",
    "input_example"
  ],
  "parse_groups": [
    "ret",
    "output_lists"
  ],
  "TrtCompiler": {
    "__init__": [
      "self",
      "model",
      "plan_path",
      "precision",
      "method",
      "input_names",
      "output_names",
      "output_lists",
      "export_args",
      "build_args",
      "input_profiles",
      "dynamic_batchsize",
      "use_cuda_graph",
      "timestamp",
      "fallback",
      "forward_override",
      "logger"
    ],
    "_inputs_to_dict": [
      "self",
      "input_example"
    ],
    "_load_engine": [
      "self"
    ],
    "forward": [
      "self",
      "model",
      "argv",
      "kwargs"
    ],
    "_onnx_to_trt": [
      "self",
      "onnx_path"
    ],
    "_build_and_save": [
      "self",
      "model",
      "input_example"
    ]
  },
  "trt_forward": [
    "self"
  ],
  "trt_compile": [
    "model",
    "base_path",
    "args",
    "submodule",
    "logger"
  ],
  "SentencePieceTokenizer": {
    "__init__": [
      "self",
      "model_path",
      "special_tokens",
      "legacy",
      "tokenizer"
    ],
    "text_to_tokens": [
      "self",
      "text"
    ],
    "encode": [
      "self",
      "text"
    ],
    "tokens_to_text": [
      "self",
      "tokens"
    ],
    "batch_decode": [
      "self",
      "ids"
    ],
    "token_to_id": [
      "self",
      "token"
    ],
    "ids_to_tokens": [
      "self",
      "ids"
    ],
    "tokens_to_ids": [
      "self",
      "tokens"
    ],
    "add_special_tokens": [
      "self",
      "special_tokens"
    ],
    "pad_id": [
      "self"
    ],
    "bos_token_id": [
      "self"
    ],
    "eos_token_id": [
      "self"
    ],
    "sep_id": [
      "self"
    ],
    "cls_id": [
      "self"
    ],
    "mask_id": [
      "self"
    ],
    "unk_id": [
      "self"
    ],
    "additional_special_tokens_ids": [
      "self"
    ],
    "vocab": [
      "self"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "__len__": [
      "self"
    ],
    "is_fast": [
      "self"
    ],
    "get_added_vocab": [
      "self"
    ]
  },
  "SUPPORTED_DTYPE": [],
  "torch_dtype_from_precision": [
    "precision",
    "megatron_amp_O2"
  ],
  "Quantizer": {
    "__init__": [
      "self",
      "quantization_config",
      "export_config"
    ],
    "_setup": [
      "model"
    ],
    "modify_model_config": [
      "model_cfg"
    ],
    "_sample_output": [
      "model"
    ],
    "quantize": [
      "self",
      "model",
      "forward_loop"
    ],
    "export": [
      "self",
      "model"
    ]
  },
  "is_nemo2_checkpoint": [
    "checkpoint_path"
  ],
  "prepare_directory_for_export": [
    "model_dir",
    "delete_existing_files",
    "subdir"
  ],
  "is_nemo_tarfile": [
    "path"
  ],
  "get_model_device_type": [
    "module"
  ],
  "get_example_inputs": [
    "tokenizer"
  ],
  "validate_fp8_network": [
    "network"
  ],
  "__all__": [],
  "nemo_to_path": [
    "nemo_checkpoint"
  ],
  "TarFileSystemReader": {
    "__init__": [
      "self",
      "path"
    ]
  },
  "load_sharded_metadata_torch_dist": [
    "checkpoint_dir",
    "load_extra_states"
  ],
  "load_sharded_pickle_extra_state_scale": [
    "dir"
  ],
  "contains_extra_states": [
    "subdir"
  ],
  "load_sharded_metadata_zarr": [
    "checkpoint_dir",
    "load_extra_states"
  ],
  "nemo_weights_directory": [
    "nemo_path"
  ],
  "load_model_weights": [
    "checkpoint_path",
    "load_extra_states"
  ],
  "TRTLLM_ENGINE_DIR": [],
  "_mock_import": [
    "module"
  ],
  "replace_number_add_offset": [
    "key",
    "offset_value"
  ],
  "rename_qkv_keys": [
    "key"
  ],
  "reformat_module_names_to_hf": [
    "tensors"
  ],
  "convert_lora_weights_to_canonical": [
    "config",
    "lora_weights"
  ],
  "convert_lora_nemo_to_canonical": [
    "lora_nemo",
    "save_path",
    "hf_format",
    "donor_hf_config"
  ],
  "MODEL_NAME": [],
  "build_and_save_engine": [
    "max_input_len",
    "max_output_len",
    "max_batch_size",
    "model_dir",
    "model_weights",
    "model_config",
    "model_type",
    "lora_ckpt_list",
    "use_lora_plugin",
    "max_lora_rank",
    "lora_target_modules",
    "max_prompt_embedding_table_size",
    "paged_kv_cache",
    "remove_input_padding",
    "paged_context_fmha",
    "use_refit",
    "max_num_tokens",
    "max_seq_len",
    "opt_num_tokens",
    "max_beam_width",
    "tokens_per_block",
    "multiple_profiles",
    "gpt_attention_plugin",
    "gemm_plugin",
    "reduce_fusion",
    "gather_context_logits",
    "gather_generation_logits"
  ],
  "is_rank": [
    "rank"
  ],
  "use_trtllm_bindings": [],
  "TRTLLM_SUPPORTS_DEVICE_DISABLE": [],
  "TensorrtLLMHostContext": {},
  "TensorrtLLMWorkerContext": {},
  "tensorrt_llm_worker_context": [],
  "_read_config": [
    "config_path"
  ],
  "_load": [
    "tokenizer",
    "engine_dir",
    "lora_ckpt_list",
    "num_beams",
    "use_python_runtime",
    "enable_chunked_context",
    "max_tokens_in_paged_kv_cache",
    "multi_block_mode"
  ],
  "_forward": [
    "input_tensors",
    "max_output_len",
    "top_k",
    "top_p",
    "temperature",
    "prompt_table",
    "task_vocab_size",
    "task_ids",
    "lora_uids",
    "stop_words_list",
    "bad_words_list",
    "no_repeat_ngram_size",
    "streaming",
    "multiprocessed_env"
  ],
  "load": [
    "tokenizer",
    "engine_dir",
    "lora_ckpt_list",
    "num_beams",
    "use_python_runtime",
    "enable_chunked_context",
    "max_tokens_in_paged_kv_cache",
    "multi_block_mode"
  ],
  "forward": [
    "input_tensors",
    "max_output_len",
    "host_context",
    "top_k",
    "top_p",
    "temperature",
    "prompt_table",
    "task_vocab_size",
    "task_ids",
    "lora_uids",
    "stop_words_list",
    "bad_words_list",
    "no_repeat_ngram_size",
    "streaming",
    "multiprocessed_env"
  ],
  "load_distributed": [
    "engine_dir",
    "model_parallel_rank",
    "gpus_per_node"
  ],
  "maybe_cast_to_trt_dtype": [
    "dtype"
  ],
  "refit": [
    "weights_dict"
  ],
  "unload_engine": [],
  "prepare_input_tensors": [
    "input_texts",
    "host_context",
    "prompt_table",
    "task_vtoken_counts",
    "task_ids"
  ],
  "generate": [
    "input_texts",
    "max_output_len",
    "host_context",
    "top_k",
    "top_p",
    "temperature",
    "prompt_table",
    "task_vocab_size",
    "task_vtoken_counts",
    "task_ids",
    "lora_uids",
    "stop_words_list",
    "bad_words_list",
    "no_repeat_ngram_size",
    "streaming",
    "output_log_probs",
    "multiprocessed_env",
    "output_context_logits",
    "output_generation_logits"
  ],
  "generate_streaming": [
    "input_texts",
    "max_output_len",
    "host_context",
    "top_k",
    "top_p",
    "temperature",
    "prompt_table",
    "task_vocab_size",
    "task_vtoken_counts",
    "task_ids",
    "lora_uids",
    "stop_words_list",
    "bad_words_list",
    "no_repeat_ngram_size"
  ],
  "unload": [
    "host_context"
  ],
  "to_word_list_format": [
    "word_dict",
    "tokenizer",
    "ref_str"
  ],
  "EXTRA_STATE": [],
  "load_extra_state_from_bytes": [
    "val"
  ],
  "preprocess_scaling_factors_for_local_export": [
    "state_dict"
  ],
  "rename_extra_states": [
    "state_dict"
  ],
  "torch_to_numpy_state_dict": [
    "state_dict"
  ],
  "update_tokenizer_paths": [
    "tokenizer_config",
    "unpacked_checkpoints_dir"
  ],
  "copy_tokenizer_files": [
    "config",
    "out_dir"
  ],
  "get_tokenizer_from_nemo2_context": [
    "model_context_dir"
  ],
  "get_tokenizer": [
    "tokenizer_dir_or_path"
  ],
  "build_tokenizer": [
    "tokenizer"
  ],
  "load_nemo_config": [
    "nemo_ckpt"
  ],
  "get_model_type": [
    "nemo_ckpt"
  ],
  "get_weights_dtype": [
    "nemo_ckpt"
  ],
  "load_distributed_model_weights": [
    "nemo_checkpoint",
    "mcore_scales_format",
    "torch_tensor"
  ],
  "load_nemo_model": [
    "nemo_ckpt",
    "nemo_export_dir",
    "mcore_scales_format"
  ],
  "cpu_map_location": [
    "storage",
    "loc"
  ],
  "gpu_map_location": [
    "storage",
    "loc"
  ],
  "UnpackedNemoCheckpointDir": {
    "__init__": [
      "self",
      "checkpoints_dir",
      "load_checkpoints_to_cpu"
    ],
    "model_config": [
      "self"
    ],
    "checkpoints_dir": [
      "self"
    ],
    "get_checkpoints_paths": [
      "self",
      "tensor_model_parallel_size",
      "pipeline_model_parallel_size"
    ],
    "checkpoint_name": [
      "self"
    ],
    "get_tokenizer_file_path": [
      "self",
      "tokenizer_key",
      "file_key",
      "default_filename_pattern"
    ]
  },
  "TOKENIZER_CONFIG_FILE": [],
  "TOKENIZER_DIR": [],
  "get_nmt_tokenizer": [
    "nemo_checkpoint_path"
  ],
  "CONFIG_NAME": [],
  "WEIGHTS_NAME": [],
  "is_qnemo_checkpoint": [
    "path"
  ],
  "qnemo_to_tensorrt_llm": [
    "nemo_checkpoint_path",
    "engine_dir",
    "max_input_len",
    "max_seq_len",
    "max_batch_size",
    "max_prompt_embedding_table_size",
    "tensor_parallel_size",
    "pipeline_parallel_size",
    "use_parallel_embedding",
    "paged_kv_cache",
    "paged_context_fmha",
    "remove_input_padding",
    "use_lora_plugin",
    "lora_target_modules",
    "max_lora_rank",
    "max_num_tokens",
    "opt_num_tokens",
    "max_beam_width",
    "multiple_profiles",
    "reduce_fusion"
  ],
  "weights_dict": [],
  "DECODER_MODEL_TYPE": [],
  "post_layernorm_keys": [],
  "mlp_proj_bias_keys": [],
  "attention_dense_bias_keys": [],
  "input_layernorm_keys": [],
  "pre_layernorm_keys": [],
  "attention_dense_weight_keys": [],
  "mlp_proj_weight_keys": [],
  "mlp_fc_keys": [],
  "attention_qkv_bias_keys": [],
  "attention_qkv_weight_keys": [],
  "mlp_router_keys": [],
  "mlp_fc_expert_keys": [],
  "mlp_proj_experts_keys": [],
  "final_layernorm_keys": [],
  "mlp_dense_2_keys": [],
  "attention_not_mapped_keys": [],
  "weight_scaling_suffix": [],
  "activation_scaling_suffix": [],
  "save_val": [
    "val",
    "dir",
    "key",
    "tp_num"
  ],
  "save_split": [
    "split_vals",
    "dir",
    "key",
    "i",
    "split_factor"
  ],
  "save_expert_split": [
    "split_vals",
    "dir",
    "key",
    "i",
    "split_factor"
  ],
  "generate_int8": [
    "weights",
    "act_range",
    "is_qkv",
    "multi_query_mode"
  ],
  "write_int8": [
    "vals",
    "dir",
    "base_key",
    "split_dim",
    "tp_rank",
    "split_factor",
    "kv_cache_only"
  ],
  "get_suffix": [
    "key"
  ],
  "get_trt_llm_prefix": [
    "key"
  ],
  "any_word_in_key": [
    "key",
    "words"
  ],
  "sequential_key_map": [
    "key",
    "mapping"
  ],
  "get_trt_llm_infix": [
    "key"
  ],
  "get_trt_llm_keyname": [
    "key"
  ],
  "is_scaling_factor": [
    "key"
  ],
  "get_scaling_factor_keys": [
    "key"
  ],
  "save_scaling_factor": [
    "scaling_factors",
    "key",
    "val",
    "config"
  ],
  "cast_val_datatype": [
    "vals",
    "trt_llm_key",
    "storage_type",
    "is_fp8_model",
    "scaling_factors"
  ],
  "split_val_gate": [
    "vals",
    "convert_on_device"
  ],
  "split_and_save_weight": [
    "tp_rank",
    "saved_dir",
    "split_factor",
    "key",
    "vals",
    "storage_type",
    "act_range",
    "config",
    "scaling_factors"
  ],
  "split": [
    "v",
    "tp_size",
    "idx",
    "dim"
  ],
  "init_model_parallel_from_nemo": [
    "reshard_model"
  ],
  "get_config": [
    "decoder_type",
    "config"
  ],
  "prompt_convert": [
    "prompt_config",
    "prompt_weights"
  ],
  "determine_quantization_settings": [
    "nemo_model_config",
    "fp8_quantized",
    "fp8_kvcache"
  ],
  "model_to_trtllm_ckpt": [
    "model",
    "nemo_model_config",
    "nemo_export_dir",
    "decoder_type",
    "dtype",
    "tensor_parallel_size",
    "pipeline_parallel_size",
    "gpus_per_node",
    "use_parallel_embedding",
    "use_embedding_sharing",
    "use_distributed_convert",
    "model_parallel_rank",
    "vocab_size",
    "fp8_quantized",
    "fp8_kvcache"
  ],
  "layer_names": [],
  "extract_layers_with_prefix": [
    "model_",
    "prefix"
  ],
  "get_layer_name": [
    "layer_type",
    "prefix"
  ],
  "get_layer_prefix": [
    "layer_names",
    "is_mcore"
  ],
  "rename_key": [
    "new_key"
  ],
  "rename_key_dist_ckpt": [
    "old_key",
    "layer"
  ],
  "load_scaling_factors": [
    "model",
    "num_layers",
    "export_config"
  ],
  "convert_model_to_trt_llm_ckpt": [
    "nemo_model_config",
    "model",
    "nemo_export_dir",
    "storage_type",
    "inference_tp_size",
    "decoder_type",
    "use_parallel_embedding",
    "processes",
    "fp8_quantized",
    "fp8_kvcache"
  ],
  "_get_layer_index": [
    "split_key"
  ],
  "rename_layer_num": [
    "param_name",
    "layer_num"
  ],
  "get_layer_num": [
    "param_name"
  ],
  "dist_model_to_trt_llm_ckpt": [
    "model",
    "nemo_model_config",
    "inference_tp_size",
    "inference_pp_size",
    "tokenizer_vocab_size",
    "fp8_quantized",
    "fp8_kvcache"
  ],
  "create_export_dir": [
    "nemo_export_dir"
  ],
  "split_qkv_weight": [
    "qkv_weight",
    "model_config"
  ],
  "split_kv_weight": [
    "kv_weight",
    "model_config"
  ],
  "split_gate_weight": [
    "gate_weight"
  ],
  "convert_mllama_config": [
    "source_vision",
    "source_text"
  ],
  "convert_mllama_nemo_to_hf": [
    "checkpoint_path",
    "processor_name"
  ],
  "build_trtllm_engine": [
    "model_dir",
    "visual_checkpoint_path",
    "llm_checkpoint_path",
    "model_type",
    "llm_model_type",
    "tensor_parallelism_size",
    "max_input_len",
    "max_output_len",
    "max_batch_size",
    "max_multimodal_len",
    "dtype",
    "use_lora_plugin",
    "lora_target_modules",
    "max_lora_rank",
    "lora_ckpt_list"
  ],
  "build_mllama_trtllm_engine": [
    "model_dir",
    "hf_model_path",
    "tensor_parallelism_size",
    "max_input_len",
    "max_output_len",
    "max_batch_size",
    "max_multimodal_len",
    "dtype",
    "use_lora_plugin",
    "lora_target_modules",
    "max_lora_rank",
    "lora_ckpt_list"
  ],
  "export_visual_wrapper_onnx": [
    "visual_wrapper",
    "input",
    "output_dir",
    "input_names",
    "dynamic_axes"
  ],
  "export_perception_wrapper_onnx": [
    "perception_wrapper",
    "input",
    "output_dir",
    "input_names",
    "output_names",
    "dynamic_axes"
  ],
  "build_trt_engine": [
    "model_type",
    "input_sizes",
    "output_dir",
    "vision_max_batch_size",
    "dtype",
    "image_size",
    "num_frames",
    "nemo_config",
    "part_name"
  ],
  "build_neva_engine": [
    "model_type",
    "model_dir",
    "visual_checkpoint_path",
    "vision_max_batch_size"
  ],
  "build_video_neva_engine": [
    "model_dir",
    "visual_checkpoint_path",
    "vision_max_batch_size"
  ],
  "build_perception_engine": [
    "model_dir",
    "perception_checkpoint_path",
    "model_type",
    "max_batch_size"
  ],
  "build_mllama_visual_engine": [
    "model_dir",
    "hf_model_path",
    "processor_name",
    "vision_max_batch_size"
  ],
  "build_visual_engine": [
    "model_dir",
    "visual_checkpoint_path",
    "model_type",
    "vision_max_batch_size"
  ],
  "extract_lora_ckpt": [
    "lora_ckpt",
    "output_dir"
  ],
  "build_mllama_engine": [
    "model_dir",
    "checkpoint_path",
    "processor_name",
    "vision_max_batch_size",
    "tensor_parallelism_size",
    "max_input_len",
    "max_output_len",
    "max_batch_size",
    "max_multimodal_len",
    "dtype",
    "use_lora_plugin",
    "lora_target_modules",
    "max_lora_rank",
    "lora_ckpt_list"
  ],
  "trt_dtype_to_torch": [
    "dtype"
  ],
  "MultimodalModelRunner": {
    "__init__": [
      "self",
      "visual_engine_dir",
      "llm_engine_dir",
      "modality"
    ],
    "init_tokenizer": [
      "self",
      "llm_engine_dir"
    ],
    "init_image_encoder": [
      "self",
      "visual_engine_dir"
    ],
    "init_vision_preprocessor": [
      "self",
      "visual_encoder_dir"
    ],
    "init_llm": [
      "self",
      "llm_engine_dir"
    ],
    "video_preprocess": [
      "self",
      "video_path"
    ],
    "insert_tokens_by_index": [
      "self",
      "input_ids",
      "num_frames"
    ],
    "preprocess": [
      "self",
      "warmup",
      "pre_prompt",
      "post_prompt",
      "image",
      "attention_mask",
      "batch_size"
    ],
    "tokenizer_image_token": [
      "batch_size",
      "prompt",
      "tokenizer",
      "image_token_index"
    ],
    "split_prompt_by_images": [
      "self",
      "tensor"
    ],
    "generate": [
      "self",
      "pre_prompt",
      "post_prompt",
      "image",
      "decoder_input_ids",
      "max_new_tokens",
      "attention_mask",
      "warmup",
      "batch_size",
      "top_k",
      "top_p",
      "temperature",
      "repetition_penalty",
      "num_beams",
      "lora_uids"
    ],
    "get_visual_features": [
      "self",
      "image",
      "attention_mask"
    ],
    "setup_fake_prompts": [
      "self",
      "visual_features",
      "pre_input_ids",
      "post_input_ids",
      "input_lengths"
    ],
    "setup_fake_prompts_vila": [
      "self",
      "batch_size",
      "visual_features",
      "split_input_ids",
      "input_lengths"
    ],
    "preprocess_lita_visual": [
      "self",
      "visual_features",
      "config"
    ],
    "ptuning_setup": [
      "self",
      "prompt_table",
      "input_ids",
      "input_lengths"
    ],
    "expand2square_pt": [
      "self",
      "images",
      "background_color"
    ],
    "load_video": [
      "self",
      "config",
      "video_path",
      "processor",
      "num_frames"
    ],
    "preprocess_frames": [
      "self",
      "frames",
      "config",
      "processor"
    ],
    "get_num_sample_frames": [
      "self",
      "config",
      "vid_len"
    ],
    "process_lita_video": [
      "self",
      "nemo_config",
      "video_path",
      "image_processor"
    ],
    "process_image": [
      "self",
      "image_file",
      "image_processor",
      "nemo_config",
      "image_folder"
    ],
    "process_vila_img": [
      "self",
      "images"
    ],
    "setup_inputs": [
      "self",
      "input_text",
      "raw_image",
      "batch_size"
    ],
    "run": [
      "self",
      "input_text",
      "input_image",
      "max_new_tokens",
      "batch_size",
      "top_k",
      "top_p",
      "temperature",
      "repetition_penalty",
      "num_beams",
      "lora_uids",
      "run_profiling",
      "check_accuracy"
    ],
    "print_result": [
      "self",
      "input_text",
      "output_text",
      "batch_size",
      "num_beams",
      "run_profiling",
      "check_accuracy"
    ],
    "load_test_media": [
      "self",
      "input_media"
    ]
  },
  "SpeechllmModelRunner": {
    "__init__": [
      "self",
      "perception_engine_dir",
      "llm_engine_dir",
      "modality"
    ],
    "init_modality_encoder": [
      "self",
      "engine_dir"
    ],
    "init_speech_preprocessor": [
      "self",
      "feature_extractor_path"
    ],
    "process_audio": [
      "self",
      "input_signal",
      "input_signal_length"
    ],
    "setup_inputs": [
      "self",
      "input_text",
      "input_media",
      "batch_size"
    ],
    "load_test_media": [
      "self",
      "input_media_path"
    ],
    "get_modality_encoder_features": [
      "self",
      "modality_features",
      "attention_mask"
    ],
    "preprocess": [
      "self",
      "warmup",
      "pre_prompt",
      "post_prompt",
      "processed_features",
      "attention_mask",
      "batch_size"
    ],
    "run": [
      "self",
      "input_text",
      "input_media",
      "max_new_tokens",
      "batch_size",
      "top_k",
      "top_p",
      "temperature",
      "repetition_penalty",
      "num_beams",
      "run_profiling",
      "check_accuracy",
      "input_signal",
      "input_signal_length",
      "lora_uids"
    ]
  },
  "NemoModelLoader": {
    "_load_nemo_checkpoint_state": [
      "nemo_file"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "load_model": [
      "self"
    ],
    "convert_and_store_nemo_weights": [
      "model_config",
      "safetensors_file"
    ],
    "_standardize_nemo2_naming": [
      "state_dict"
    ]
  },
  "NemoModelConfig": {
    "__init__": [
      "self",
      "nemo_checkpoint",
      "model_dir",
      "model_type",
      "tokenizer_mode",
      "dtype",
      "seed",
      "revision",
      "override_neuron_config",
      "code_revision",
      "rope_scaling",
      "rope_theta",
      "tokenizer_revision",
      "max_model_len",
      "quantization",
      "quantization_param_path",
      "enforce_eager",
      "max_seq_len_to_capture",
      "max_logprobs",
      "disable_sliding_window",
      "disable_cascade_attn",
      "use_async_output_proc",
      "disable_mm_preprocessor_cache",
      "logits_processor_pattern",
      "override_pooler_config",
      "override_generation_config",
      "enable_sleep_mode",
      "model_impl"
    ],
    "_change_paths_to_absolute_paths": [
      "tokenizer_config",
      "nemo_checkpoint"
    ],
    "_load_hf_arguments": [
      "self",
      "nemo_config"
    ],
    "try_get_generation_config": [
      "self"
    ]
  },
  "ModelConverter": {
    "__init__": [
      "self",
      "model_type"
    ],
    "get_architecture": [
      "self"
    ],
    "convert_config": [
      "self",
      "nemo_model_config",
      "hf_config"
    ],
    "convert_weights": [
      "self",
      "nemo_model_config",
      "state_dict"
    ],
    "requires_bos_token": [
      "self"
    ]
  },
  "LlamaConverter": {
    "get_architecture": [
      "self"
    ],
    "convert_weights": [
      "self",
      "nemo_model_config",
      "state_dict"
    ],
    "requires_bos_token": [
      "self"
    ]
  },
  "MixtralConverter": {
    "get_architecture": [
      "self"
    ],
    "convert_weights": [
      "self",
      "nemo_model_config",
      "state_dict"
    ],
    "requires_bos_token": [
      "self"
    ]
  },
  "GemmaConverter": {
    "get_architecture": [
      "self"
    ],
    "convert_weights": [
      "self",
      "nemo_model_config",
      "state_dict"
    ],
    "requires_bos_token": [
      "self"
    ]
  },
  "Starcoder2Converter": {
    "get_architecture": [
      "self"
    ],
    "convert_config": [
      "self",
      "nemo_model_config",
      "hf_config"
    ],
    "convert_weights": [
      "self",
      "nemo_model_config",
      "state_dict"
    ]
  },
  "_MODEL_CONVERTERS": [],
  "register_model_converter": [
    "model_type",
    "cls"
  ],
  "get_model_converter": [
    "model_type"
  ],
  "HANDLERS": [],
  "PATCHED": [],
  "add_memory_handlers_to_pl_logger": [],
  "add_filehandlers_to_pl_logger": [
    "all_log_file",
    "err_log_file"
  ],
  "S3_PATH_PREFIX": [],
  "build_s3_url": [
    "bucket",
    "key"
  ],
  "is_s3_url": [
    "path"
  ],
  "NotFoundError": {},
  "LoggerMisconfigurationError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "CheckpointMisconfigurationError": {},
  "EarlyStoppingParams": {},
  "IPLEpochStopperParams": {},
  "CallbackParams": {},
  "StepTimingParams": {},
  "EMAParams": {},
  "StragglerDetectionParams": {},
  "FaultToleranceParams": {},
  "ExpManagerConfig": {},
  "TimingCallback": {
    "__init__": [
      "self",
      "log_tokens_per_sec",
      "timer_kwargs"
    ],
    "_on_batch_start": [
      "self",
      "name"
    ],
    "_on_batch_end": [
      "self",
      "name",
      "pl_module"
    ],
    "on_train_batch_start": [
      "self",
      "trainer",
      "pl_module",
      "batch",
      "batch_idx"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ],
    "on_validation_batch_start": [
      "self",
      "trainer",
      "pl_module",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "on_validation_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "on_test_batch_start": [
      "self",
      "trainer",
      "pl_module",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "on_test_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "on_before_backward": [
      "self",
      "trainer",
      "pl_module",
      "loss"
    ],
    "on_after_backward": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "DeltaTimingCallback": {
    "__init__": [
      "self",
      "timer_kwargs"
    ],
    "_on_epoch_start": [
      "self",
      "name",
      "trainer",
      "pl_module"
    ],
    "_on_batch_end": [
      "self",
      "name",
      "trainer",
      "pl_module"
    ],
    "on_train_epoch_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_validation_epoch_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ],
    "on_validation_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ]
  },
  "exp_manager": [
    "trainer",
    "cfg"
  ],
  "error_checks": [
    "trainer",
    "cfg"
  ],
  "_filter_out_unfinished_checkpoints": [
    "checkpoint_paths"
  ],
  "check_resume": [
    "trainer",
    "log_dir",
    "resume_if_exists",
    "resume_past_end",
    "resume_ignore_no_checkpoint",
    "dirpath",
    "resume_from_checkpoint"
  ],
  "check_explicit_log_dir": [
    "trainer",
    "explicit_log_dir",
    "exp_dir",
    "name",
    "version"
  ],
  "get_log_dir": [
    "trainer",
    "exp_dir",
    "name",
    "version",
    "explicit_log_dir",
    "use_datetime_version",
    "resume_if_exists"
  ],
  "get_git_hash": [],
  "get_git_diff": [],
  "configure_loggers": [
    "trainer",
    "exp_dir",
    "log_dir",
    "name",
    "version",
    "checkpoint_callback_params",
    "create_tensorboard_logger",
    "summary_writer_kwargs",
    "create_wandb_logger",
    "wandb_kwargs",
    "create_mlflow_logger",
    "mlflow_kwargs",
    "create_dllogger_logger",
    "dllogger_kwargs",
    "create_clearml_logger",
    "clearml_kwargs",
    "create_neptune_logger",
    "neptune_kwargs"
  ],
  "NeMoCheckpointConnector": {
    "resume_start": [
      "self",
      "checkpoint_path"
    ]
  },
  "configure_checkpointing": [
    "trainer",
    "log_dir",
    "name",
    "resume",
    "params",
    "create_preemption_callback"
  ],
  "check_slurm": [
    "trainer"
  ],
  "StatelessTimer": {
    "__init__": [
      "self",
      "duration",
      "interval",
      "verbose"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "_check_time_remaining": [
      "self",
      "trainer"
    ]
  },
  "configure_no_restart_validation_training_loop": [
    "trainer"
  ],
  "SkipResumeTrainingValidationLoop": {
    "_should_check_val_fx": [
      "self",
      "data_fetcher"
    ]
  },
  "clean_exp_ckpt": [
    "exp_log_dir",
    "remove_ckpt",
    "remove_nemo"
  ],
  "is_float8tensor": [
    "tensor"
  ],
  "is_mxfp8tensor": [
    "tensor"
  ],
  "te_version": [],
  "robust_copy": [
    "src",
    "dst"
  ],
  "maybe_download_from_cloud": [
    "url",
    "filename",
    "subfolder",
    "cache_dir",
    "refresh_cache"
  ],
  "SageMakerDDPStrategy": {
    "cluster_environment": [
      "self",
      "env"
    ]
  },
  "initialize_sagemaker": [],
  "initialize_distributed": [
    "args",
    "backend"
  ],
  "gather_objects": [
    "partial_results_list",
    "main_rank"
  ],
  "temporary_directory": [],
  "webdataset_split_by_workers": [
    "src"
  ],
  "avoid_bfloat16_autocast_context": [],
  "avoid_float16_autocast_context": [],
  "cast_tensor": [
    "x",
    "from_dtype",
    "to_dtype"
  ],
  "cast_all": [
    "x",
    "from_dtype",
    "to_dtype"
  ],
  "CastToFloat": {
    "__init__": [
      "self",
      "mod"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CastToFloatAll": {
    "__init__": [
      "self",
      "mod"
    ],
    "forward": [
      "self"
    ]
  },
  "monkeypatched": [
    "object",
    "name",
    "patch"
  ],
  "maybe_cast_to_type": [
    "x",
    "type_"
  ],
  "hyena": [
    "config"
  ],
  "add_optimizer_args": [
    "parent_parser",
    "optimizer",
    "default_lr",
    "default_opt_args"
  ],
  "add_scheduler_args": [
    "parent_parser"
  ],
  "add_asr_args": [
    "parent_parser"
  ],
  "add_nlp_args": [
    "parent_parser"
  ],
  "ModelMetadataRegistry": {},
  "AppState": {
    "__init__": [
      "self"
    ],
    "device_id": [
      "self",
      "id"
    ],
    "world_size": [
      "self",
      "size"
    ],
    "model_parallel_size": [
      "self",
      "size"
    ],
    "tensor_model_parallel_size": [
      "self",
      "size"
    ],
    "expert_model_parallel_rank": [
      "self",
      "rank"
    ],
    "expert_model_parallel_size": [
      "self",
      "size"
    ],
    "expert_tensor_parallel_size": [
      "self",
      "size"
    ],
    "expert_tensor_parallel_rank": [
      "self",
      "rank"
    ],
    "pipeline_model_parallel_size": [
      "self",
      "size"
    ],
    "pipeline_model_parallel_comm_backend": [
      "self",
      "backend"
    ],
    "encoder_tensor_model_parallel_size": [
      "self",
      "size"
    ],
    "encoder_pipeline_model_parallel_size": [
      "self",
      "size"
    ],
    "use_tp_pp_dp_mapping": [
      "self",
      "use_new_mapping"
    ],
    "num_distributed_optimizer_instances": [
      "self",
      "shard_factor"
    ],
    "virtual_pipeline_model_parallel_size": [
      "self",
      "size"
    ],
    "data_parallel_size": [
      "self",
      "size"
    ],
    "local_rank": [
      "self",
      "rank"
    ],
    "global_rank": [
      "self",
      "rank"
    ],
    "tensor_model_parallel_rank": [
      "self",
      "rank"
    ],
    "tensor_model_parallel_group": [
      "self",
      "group"
    ],
    "pipeline_model_parallel_rank": [
      "self",
      "rank"
    ],
    "virtual_pipeline_model_parallel_rank": [
      "self",
      "rank"
    ],
    "encoder_tensor_model_parallel_rank": [
      "self",
      "rank"
    ],
    "encoder_pipeline_model_parallel_rank": [
      "self",
      "rank"
    ],
    "pipeline_model_parallel_split_rank": [
      "self",
      "rank"
    ],
    "pipeline_model_parallel_group": [
      "self",
      "group"
    ],
    "data_parallel_rank": [
      "self",
      "rank"
    ],
    "data_parallel_group": [
      "self",
      "group"
    ],
    "use_fp8": [
      "self",
      "use_fp8"
    ],
    "use_sharp": [
      "self",
      "use_sharp"
    ],
    "use_gloo_process_groups": [
      "self",
      "use_gloo_process_groups"
    ],
    "context_parallel_size": [
      "self",
      "size"
    ],
    "init_mpi_proc_group": [
      "self",
      "init_mpi_proc_group"
    ],
    "nccl_communicator_config_path": [
      "self",
      "path"
    ],
    "random_seed": [
      "self",
      "seed"
    ],
    "log_dir": [
      "self",
      "dir"
    ],
    "exp_dir": [
      "self",
      "dir"
    ],
    "name": [
      "self",
      "name"
    ],
    "checkpoint_name": [
      "self",
      "name"
    ],
    "version": [
      "self",
      "version"
    ],
    "create_checkpoint_callback": [
      "self",
      "create_checkpoint_callback"
    ],
    "checkpoint_callback_params": [
      "self",
      "params"
    ],
    "files_to_move": [
      "self",
      "files"
    ],
    "files_to_copy": [
      "self",
      "files"
    ],
    "cmd_args": [
      "self",
      "args"
    ],
    "model_restore_path": [
      "self",
      "path"
    ],
    "register_model_guid": [
      "self",
      "guid",
      "restoration_path"
    ],
    "reset_model_guid_registry": [
      "self"
    ],
    "get_model_metadata_from_guid": [
      "self",
      "guid"
    ],
    "is_model_being_restored": [
      "self",
      "is_restored"
    ],
    "nemo_file_folder": [
      "self",
      "path"
    ],
    "restore": [
      "self",
      "restore"
    ]
  },
  "_HAS_HYDRA": [],
  "update_model_config": [
    "model_cls",
    "update_cfg",
    "drop_missing_subconfigs"
  ],
  "_update_subconfig": [
    "model_cfg",
    "update_cfg",
    "subconfig_key",
    "drop_missing_subconfigs"
  ],
  "_add_subconfig_keys": [
    "model_cfg",
    "update_cfg",
    "subconfig_key"
  ],
  "assert_dataclass_signature_match": [
    "cls",
    "datacls",
    "ignore_args",
    "remap_args"
  ],
  "CoercionError": {
    "__init__": [
      "self",
      "key",
      "value",
      "func"
    ]
  },
  "RequiredSettingMissingError": {
    "__init__": [
      "self",
      "key"
    ]
  },
  "_get_env": [
    "key",
    "default",
    "coerce",
    "required"
  ],
  "_bool": [
    "value"
  ],
  "_int": [
    "value"
  ],
  "_float": [
    "value"
  ],
  "_decimal": [
    "value"
  ],
  "_dict": [
    "value"
  ],
  "_datetime": [
    "value"
  ],
  "_date": [
    "value"
  ],
  "get_env": [
    "key"
  ],
  "get_envbool": [
    "key"
  ],
  "get_envint": [
    "key"
  ],
  "get_envfloat": [
    "key"
  ],
  "get_envdecimal": [
    "key"
  ],
  "get_envdate": [
    "key"
  ],
  "get_envdatetime": [
    "key"
  ],
  "get_envlist": [
    "key"
  ],
  "get_envdict": [
    "key"
  ],
  "ExportFormat": {
    "ONNX": [],
    "TORCHSCRIPT": []
  },
  "_EXT_DICT": [],
  "TorchRMSNorm": {
    "__init__": [
      "self",
      "weight",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LinearWithBiasSkip": {
    "__init__": [
      "self",
      "weight",
      "bias",
      "skip_bias_add"
    ],
    "forward": [
      "self",
      "x",
      "weight"
    ]
  },
  "get_export_format": [
    "filename"
  ],
  "augment_filename": [
    "output",
    "prepend"
  ],
  "forward_method": [
    "self"
  ],
  "wrap_forward_method": [
    "self"
  ],
  "parse_input_example": [
    "input_example"
  ],
  "to_onnxrt_input": [
    "ort_input_names",
    "input_names",
    "input_dict",
    "input_list"
  ],
  "verify_torchscript": [
    "model",
    "output",
    "input_examples",
    "check_tolerance"
  ],
  "verify_runtime": [
    "model",
    "output",
    "input_examples",
    "input_names",
    "check_tolerance"
  ],
  "run_ts_and_compare": [
    "ts_model",
    "ts_input_list",
    "ts_input_dict",
    "output_example",
    "check_tolerance"
  ],
  "run_ort_and_compare": [
    "sess",
    "ort_input",
    "output_example",
    "check_tolerance"
  ],
  "apex_available": [],
  "simple_replace": [
    "BaseT",
    "DestT"
  ],
  "replace_MatchedScaleMaskSoftmax": [
    "n"
  ],
  "wrap_module": [
    "BaseT",
    "DestT"
  ],
  "swap_modules": [
    "model",
    "mapping"
  ],
  "replace_modules": [
    "model",
    "expansions"
  ],
  "script_module": [
    "m"
  ],
  "script_replacements": [],
  "replace_for_export": [
    "model"
  ],
  "add_casts_around_norms": [
    "model"
  ],
  "rename_onnx_io": [
    "output",
    "input_names",
    "output_names"
  ],
  "MODEL_CONFIG": [],
  "_VAL_TEST_FASTPATH_KEY": [],
  "ArtifactPathType": {
    "LOCAL_PATH": [],
    "TAR_PATH": []
  },
  "ArtifactItem": {},
  "detect_prefix": [
    "names"
  ],
  "load_config": [
    "model_file"
  ],
  "unwrap_model": [
    "model",
    "module_instances"
  ],
  "param_is_not_shared": [
    "param"
  ],
  "resolve_dataset_name_from_cfg": [
    "cfg"
  ],
  "parse_dataset_as_name": [
    "name"
  ],
  "unique_names_check": [
    "name_list"
  ],
  "resolve_validation_dataloaders": [
    "model"
  ],
  "resolve_test_dataloaders": [
    "model"
  ],
  "wrap_training_step": [
    "wrapped",
    "instance",
    "args",
    "kwargs"
  ],
  "convert_model_config_to_dict_config": [
    "cfg"
  ],
  "_convert_config": [
    "cfg"
  ],
  "maybe_update_config_version": [
    "cfg"
  ],
  "import_class_by_path": [
    "path"
  ],
  "resolve_subclass_pretrained_model_info": [
    "base_class"
  ],
  "check_lib_version": [
    "lib_name",
    "checked_version",
    "operator"
  ],
  "uninject_model_parallel_rank": [
    "filepath"
  ],
  "inject_model_parallel_rank": [
    "filepath",
    "fsdp_sharded_ckpt"
  ],
  "ckpt_to_dir": [
    "filepath"
  ],
  "save_artifacts": [
    "model",
    "output_dir",
    "use_abspath"
  ],
  "ApproxGELUActivation": [
    "input"
  ],
  "ApexGuardDefaults": {
    "__init__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "item"
    ]
  },
  "init_method_kaiming_uniform": [
    "val"
  ],
  "init_method_const": [
    "val"
  ],
  "init_method_normal": [
    "sigma"
  ],
  "average_losses_across_data_parallel_group": [
    "losses"
  ],
  "get_ltor_masks_and_position_ids": [
    "data",
    "eod_token",
    "reset_position_ids",
    "reset_attention_mask",
    "eod_mask_loss",
    "compute_attention_mask"
  ],
  "build_position_ids": [
    "token_ids"
  ],
  "make_attention_mask_3d": [
    "source_mask",
    "target_mask"
  ],
  "make_inference_attention_mask_3d": [
    "source_block",
    "target_block",
    "pad_id"
  ],
  "make_inference_history_mask_3d": [
    "block"
  ],
  "build_attention_mask_3d_padding": [
    "source_mask",
    "target_mask"
  ],
  "build_attention_mask_3d_causal": [
    "source_mask",
    "target_mask"
  ],
  "build_attention_mask_3d": [
    "source_mask",
    "target_mask",
    "attn_mask_type"
  ],
  "split_list": [
    "inputs",
    "num_chunks",
    "enforce_divisible_batch"
  ],
  "get_iterator_k_split": [
    "batch",
    "num_microbatches",
    "enforce_divisible_batch"
  ],
  "build_manifest": [
    "transcripts_path",
    "manifest_path",
    "data_dir",
    "mount_dir",
    "wav_path"
  ],
  "download_an4": [
    "data_dir",
    "train_mount_dir",
    "test_mount_dir"
  ],
  "logging": [],
  "MSC_PROTOCOL": [],
  "is_multistorageclient_url": [
    "path"
  ],
  "import_multistorageclient": [],
  "build_engine": [
    "onnx_path",
    "output_path",
    "fp16",
    "input_profile",
    "enable_refit",
    "enable_preview",
    "timing_cache",
    "workspace_size",
    "int8",
    "builder_optimization_level"
  ],
  "str_to_dtype": [
    "dtype"
  ],
  "GPU_INSTALL_STRING": [],
  "UnavailableError": {},
  "null_decorator": [],
  "UnavailableMeta": {
    "__new__": [
      "meta",
      "name",
      "bases",
      "dct"
    ],
    "__call__": [
      "cls"
    ],
    "__getattr__": [
      "cls",
      "name"
    ],
    "__eq__": [
      "cls",
      "other"
    ],
    "__lt__": [
      "cls",
      "other"
    ],
    "__gt__": [
      "cls",
      "other"
    ],
    "__le__": [
      "cls",
      "other"
    ],
    "__ge__": [
      "cls",
      "other"
    ],
    "__ne__": [
      "cls",
      "other"
    ],
    "__abs__": [
      "cls"
    ],
    "__add__": [
      "cls",
      "other"
    ],
    "__radd__": [
      "cls",
      "other"
    ],
    "__iadd__": [
      "cls",
      "other"
    ],
    "__floordiv__": [
      "cls",
      "other"
    ],
    "__rfloordiv__": [
      "cls",
      "other"
    ],
    "__ifloordiv__": [
      "cls",
      "other"
    ],
    "__lshift__": [
      "cls",
      "other"
    ],
    "__rlshift__": [
      "cls",
      "other"
    ],
    "__mul__": [
      "cls",
      "other"
    ],
    "__rmul__": [
      "cls",
      "other"
    ],
    "__imul__": [
      "cls",
      "other"
    ],
    "__ilshift__": [
      "cls",
      "other"
    ],
    "__pow__": [
      "cls",
      "other"
    ],
    "__rpow__": [
      "cls",
      "other"
    ],
    "__ipow__": [
      "cls",
      "other"
    ],
    "__rshift__": [
      "cls",
      "other"
    ],
    "__rrshift__": [
      "cls",
      "other"
    ],
    "__irshift__": [
      "cls",
      "other"
    ],
    "__sub__": [
      "cls",
      "other"
    ],
    "__rsub__": [
      "cls",
      "other"
    ],
    "__isub__": [
      "cls",
      "other"
    ],
    "__truediv__": [
      "cls",
      "other"
    ],
    "__rtruediv__": [
      "cls",
      "other"
    ],
    "__itruediv__": [
      "cls",
      "other"
    ],
    "__divmod__": [
      "cls",
      "other"
    ],
    "__rdivmod__": [
      "cls",
      "other"
    ],
    "__neg__": [
      "cls"
    ],
    "__invert__": [
      "cls"
    ],
    "__hash__": [
      "cls"
    ],
    "__index__": [
      "cls"
    ],
    "__iter__": [
      "cls"
    ],
    "__delitem__": [
      "cls",
      "name"
    ],
    "__setitem__": [
      "cls",
      "name",
      "value"
    ],
    "__enter__": [
      "cls"
    ],
    "__get__": [
      "cls"
    ],
    "__delete__": [
      "cls"
    ],
    "__len__": [
      "cls"
    ]
  },
  "is_unavailable": [
    "obj"
  ],
  "UnavailableNullContext": {
    "__init__": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "safe_import": [
    "module"
  ],
  "safe_import_from": [
    "module",
    "symbol"
  ],
  "gpu_only_import": [
    "module"
  ],
  "gpu_only_import_from": [
    "module",
    "symbol"
  ],
  "get_forward_hook": [
    "name",
    "trainer",
    "rank",
    "logger",
    "dump_to_file"
  ],
  "get_backward_hook": [
    "name",
    "trainer",
    "rank",
    "logger",
    "dump_to_file"
  ],
  "get_tensor_hook": [
    "module",
    "name",
    "trainer",
    "rank",
    "logger",
    "dump_to_file"
  ],
  "register_debug_hooks": [
    "module",
    "trainer",
    "logger",
    "dump_to_file"
  ],
  "MB": [],
  "GB": [],
  "SHARED_MEM_DIR": [],
  "DEFAULT_CHUNK_SIZE_MB": [],
  "DEFAULT_MAX_READ_CONCURRENCY": [],
  "DEFAULT_MAX_WRITE_CONCURRENCY": [],
  "S3Utils": {
    "s3_path_exists": [
      "s3_path",
      "match_directory"
    ],
    "remove_object": [
      "s3_path"
    ],
    "download_s3_file_to_stream": [
      "s3_path",
      "chunk_size_MB",
      "max_concurrency"
    ],
    "download_s3_file_to_path": [
      "s3_path",
      "file_path",
      "chunk_size_MB",
      "max_concurrency"
    ],
    "upload_file_stream_to_s3": [
      "bytes_buffer",
      "s3_path",
      "chunk_size_MB",
      "max_concurrency"
    ],
    "upload_file": [
      "file_path",
      "s3_path",
      "chunk_size_MB",
      "max_concurrency",
      "remove_file"
    ],
    "find_files_with_suffix": [
      "base_path",
      "suffix",
      "return_key_only",
      "profile",
      "creds"
    ],
    "_get_s3_resource": [
      "profile",
      "creds",
      "get_client",
      "session",
      "config"
    ],
    "parse_s3_url": [
      "s3_url"
    ],
    "build_s3_url": [
      "bucket",
      "key"
    ],
    "is_s3_url": [
      "path"
    ],
    "parse_prefix_with_step": [
      "path"
    ]
  },
  "_scan_objects_with_retry": [
    "s3_bucket",
    "s3_prefix"
  ],
  "is_slow_down_error": [
    "exception"
  ],
  "_download_fileobj_with_retry": [
    "s3_client",
    "bucket",
    "key",
    "bytes_buffer",
    "config"
  ],
  "_download_file_with_retry": [
    "s3_client",
    "bucket",
    "key",
    "file_path",
    "config"
  ],
  "_upload_fileobj_with_retry": [
    "s3_client",
    "bytes_buffer",
    "bucket",
    "key",
    "config"
  ],
  "_upload_file_with_retry": [
    "s3_client",
    "file_path",
    "bucket",
    "key",
    "config"
  ],
  "PACKING_ALGOS": [],
  "find_first_bin_that_fits": [
    "bins",
    "s",
    "bin_size"
  ],
  "first_fit": [
    "seqlens",
    "pack_size"
  ],
  "first_fit_decreasing": [
    "seqlens",
    "pack_size"
  ],
  "first_fit_shuffle": [
    "seqlens",
    "pack_size"
  ],
  "create_hist": [
    "dataset",
    "truncate_seq_len"
  ],
  "create_packing_strategy": [
    "histogram",
    "pack_size",
    "packing_algorithm"
  ],
  "fill_packing_strategy": [
    "assignments",
    "sequences",
    "pack_size",
    "pad_id"
  ],
  "_nvtx_enabled": [],
  "nvtx_range_push": [
    "msg"
  ],
  "nvtx_range_pop": [
    "msg"
  ],
  "NeMoBaseException": {},
  "LightningNotInstalledException": {
    "__init__": [
      "self",
      "obj"
    ]
  },
  "CheckInstall": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "__getattr__": [
      "self"
    ]
  },
  "NamedTimer": {
    "_REDUCTION_TYPE": [],
    "__init__": [
      "self",
      "reduction",
      "sync_cuda",
      "buffer_size"
    ],
    "__getitem__": [
      "self",
      "k"
    ],
    "buffer_size": [
      "self"
    ],
    "_reduction_fn": [
      "self"
    ],
    "reset": [
      "self",
      "name"
    ],
    "start": [
      "self",
      "name"
    ],
    "stop": [
      "self",
      "name"
    ],
    "is_active": [
      "self",
      "name"
    ],
    "active_timers": [
      "self"
    ],
    "get": [
      "self",
      "name"
    ],
    "export": [
      "self"
    ]
  },
  "SimpleTimer": {
    "__init__": [
      "self",
      "sync_cuda"
    ],
    "reset": [
      "self"
    ],
    "start": [
      "self",
      "device"
    ],
    "stop": [
      "self",
      "device"
    ],
    "total_sec": [
      "self"
    ]
  },
  "PrettyStrEnum": {
    "__str__": [
      "self"
    ],
    "_missing_": [
      "cls",
      "value"
    ]
  },
  "LogMode": {
    "EACH": [],
    "ONCE": []
  },
  "Logger": {
    "NOTSET": [],
    "DEBUG": [],
    "INFO": [],
    "WARNING": [],
    "ERROR": [],
    "CRITICAL": [],
    "_level_names": [],
    "__init__": [
      "self",
      "capture_warnings"
    ],
    "_define_logger": [
      "self",
      "capture_warnings"
    ],
    "remove_stream_handlers": [
      "self"
    ],
    "add_stream_handlers": [
      "self",
      "formatter"
    ],
    "reset_stream_handler": [
      "self",
      "formatter"
    ],
    "add_file_handler": [
      "self",
      "log_file"
    ],
    "add_err_file_handler": [
      "self",
      "log_file"
    ],
    "getEffectiveLevel": [
      "self"
    ],
    "get_verbosity": [
      "self"
    ],
    "setLevel": [
      "self",
      "verbosity_level"
    ],
    "set_verbosity": [
      "self",
      "verbosity_level"
    ],
    "patch_stderr_handler": [
      "self",
      "stream"
    ],
    "patch_stdout_handler": [
      "self",
      "stream"
    ],
    "temp_verbosity": [
      "self",
      "verbosity_level"
    ],
    "captureWarnings": [
      "self",
      "capture"
    ],
    "_warning_is_ignored": [
      "self",
      "category"
    ],
    "_showwarning": [
      "self",
      "message",
      "category",
      "filename",
      "lineno",
      "file",
      "line"
    ],
    "_logged_once": [
      "self",
      "msg",
      "mode"
    ],
    "debug": [
      "self",
      "msg"
    ],
    "info": [
      "self",
      "msg"
    ],
    "warning": [
      "self",
      "msg"
    ],
    "error": [
      "self",
      "msg"
    ],
    "critical": [
      "self",
      "msg"
    ]
  },
  "add_handlers_to_mcore_logger": [],
  "resolve_trainer_cfg": [
    "trainer_cfg"
  ],
  "HalfPrecisionForAudio": {
    "convert_input": [
      "self",
      "data"
    ]
  },
  "Singleton": {
    "__instances": [],
    "__lock": [],
    "__call__": [
      "cls"
    ]
  },
  "is_global_rank_zero": [],
  "get_rank": [],
  "get_last_rank": [],
  "FLOPSConfig": {},
  "gpt3": [
    "config"
  ],
  "llama2": [
    "config"
  ],
  "llama3": [
    "config"
  ],
  "nemotron": [
    "config"
  ],
  "mixtral": [
    "config"
  ],
  "qwen3": [
    "config"
  ],
  "bert": [
    "config"
  ],
  "transformer": [
    "config"
  ],
  "clip_vit_l": [
    "config"
  ],
  "neva_projection": [
    "config"
  ],
  "flux": [
    "config"
  ],
  "deepseekv3": [
    "config"
  ],
  "_nemotronh_mlp_layer_flops": [
    "config"
  ],
  "_non_mla_attn_layer_flops": [
    "config"
  ],
  "_mamba_layer_flops": [
    "config"
  ],
  "_hybrid_model_flops": [
    "config"
  ],
  "nemotronh": [
    "config"
  ],
  "attention_flops_calculator": [
    "seqlen",
    "hidden_size",
    "num_attention_heads",
    "num_query_groups",
    "kv_channels",
    "is_swa",
    "swa_window_size"
  ],
  "moe_mlp_flops_calculator": [
    "seqlen",
    "hidden_size",
    "moe_ffn_hidden_size",
    "moe_router_topk",
    "gated_linear_unit"
  ],
  "loss_flops_calculator": [
    "seqlen",
    "hidden_size",
    "vocab_size"
  ],
  "gpt_oss_flops_calculator": [
    "gbs",
    "num_layers",
    "seqlen",
    "hidden_size",
    "num_attention_heads",
    "num_query_groups",
    "moe_ffn_hidden_size",
    "moe_router_topk",
    "vocab_size",
    "kv_channels",
    "swa_window_size",
    "window_attn_skip_freq"
  ],
  "gpt_oss": [
    "config"
  ],
  "resolve_cache_dir": [],
  "is_datastore_path": [
    "path"
  ],
  "is_tarred_path": [
    "path"
  ],
  "is_datastore_cache_shared": [],
  "ais_cache_base": [],
  "ais_endpoint": [],
  "bucket_and_object_from_uri": [
    "uri"
  ],
  "ais_endpoint_to_dir": [
    "endpoint"
  ],
  "ais_binary": [],
  "datastore_path_to_local_path": [
    "store_path"
  ],
  "open_datastore_object_with_binary": [
    "path",
    "num_retries"
  ],
  "open_best": [
    "path",
    "mode"
  ],
  "get_datastore_object": [
    "path",
    "force",
    "num_retries"
  ],
  "DataStoreObject": {
    "__init__": [
      "self",
      "store_path",
      "local_path",
      "get"
    ],
    "store_path": [
      "self"
    ],
    "local_path": [
      "self"
    ],
    "get": [
      "self",
      "force"
    ],
    "put": [
      "self",
      "force"
    ],
    "__str__": [
      "self"
    ]
  },
  "datastore_object_get": [
    "store_object"
  ],
  "wds_url_opener": [
    "data",
    "handler"
  ],
  "S3CheckpointIO": {
    "__init__": [
      "self",
      "dirpath",
      "chunk_size_MB",
      "max_read_concurrency",
      "max_write_concurrency",
      "async_checkpointing"
    ],
    "async_checkpointing": [
      "self"
    ],
    "_serialize_checkpoint_to_shm": [
      "self",
      "checkpoint",
      "path"
    ],
    "_serialize_checkpoint_to_bytes": [
      "self",
      "checkpoint",
      "path"
    ],
    "_check_uploading_results_so_far": [
      "self"
    ],
    "save_checkpoint": [
      "self",
      "checkpoint",
      "path",
      "storage_options"
    ],
    "load_checkpoint": [
      "self",
      "path",
      "map_location"
    ],
    "remove_checkpoint": [
      "self",
      "path"
    ],
    "teardown": [
      "self"
    ]
  },
  "_clean_up_conflicting_checkpoint": [
    "filepath"
  ],
  "_upload_file_to_s3": [
    "localfile",
    "path",
    "chunk_size_MB",
    "max_write_concurrency",
    "remove_file"
  ],
  "_upload_bytes_to_s3": [
    "bytes",
    "path",
    "chunk_size_MB",
    "max_write_concurrency"
  ],
  "dummy_func": [],
  "_debug_time": [
    "name"
  ],
  "AsyncCompatibleCheckpointIO": {
    "save_checkpoint": [
      "self",
      "checkpoint",
      "path",
      "storage_options"
    ]
  },
  "AsyncFinalizableCheckpointIO": {
    "__init__": [
      "self",
      "checkpoint_io"
    ],
    "save_checkpoint": [
      "self",
      "checkpoint",
      "path",
      "storage_options"
    ],
    "maybe_finalize_save_checkpoint": [
      "self",
      "blocking"
    ],
    "teardown": [
      "self"
    ]
  },
  "AsyncFinalizerCallback": {
    "on_train_batch_end": [
      "self",
      "trainer"
    ],
    "on_train_epoch_end": [
      "self",
      "trainer"
    ],
    "on_train_end": [
      "self",
      "trainer"
    ],
    "_get_checkpoint_io": [
      "self",
      "trainer"
    ]
  },
  "DistributedCheckpointIO": {
    "__init__": [
      "self",
      "save_ckpt_format",
      "load_directly_on_device",
      "load_strictness",
      "async_save",
      "torch_dist_multiproc",
      "assume_constant_structure",
      "parallel_save",
      "parallel_save_within_dp",
      "parallel_load"
    ],
    "from_config": [
      "cls",
      "model_cfg",
      "async_save"
    ],
    "save_checkpoint": [
      "self",
      "checkpoint",
      "path",
      "storage_options"
    ],
    "load_checkpoint": [
      "self",
      "path",
      "map_location",
      "sharded_state_dict",
      "strict",
      "validate_access_integrity"
    ],
    "adjust_non_strict_load": [
      "self",
      "path",
      "sharded_state_dict"
    ],
    "remove_checkpoint": [
      "self",
      "path"
    ],
    "save_sharded_strategy": [
      "self"
    ],
    "_determine_dist_ckpt_save_strategy": [
      "self"
    ]
  },
  "_get_iteration_from_checkpoint": [
    "checkpoint"
  ],
  "NeMoModelCheckpoint": {
    "UNFINISHED_CHECKPOINT_SUFFIX": [],
    "__init__": [
      "self",
      "always_save_nemo",
      "save_nemo_on_train_end",
      "save_best_model",
      "postfix",
      "n_resume",
      "model_parallel_size",
      "async_save",
      "save_last_n_optim_states"
    ],
    "nemo_topk_check_previous_run": [
      "self"
    ],
    "_remove_invalid_entries_from_topk": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "setup": [
      "self",
      "trainer",
      "pl_module",
      "stage"
    ],
    "on_save_checkpoint": [
      "self",
      "trainer",
      "pl_module",
      "checkpoint"
    ],
    "on_train_end": [
      "self",
      "trainer",
      "pl_module"
    ],
    "_backup_existing_nemo_ckpt": [
      "self",
      "trainer"
    ],
    "_format_nemo_checkpoint_name": [
      "self",
      "ver"
    ],
    "_del_model_without_trainer": [
      "self",
      "filepath"
    ],
    "_ema_callback": [
      "self",
      "trainer"
    ],
    "_drop_optimizer_states": [
      "self",
      "trainer",
      "filepath",
      "storage_options"
    ],
    "_get_checkpoints_list": [
      "self",
      "filepath"
    ],
    "_load_current_state_dict": [
      "self",
      "trainer",
      "checkpoint"
    ],
    "format_checkpoint_unfinished_marker_path": [
      "checkpoint_path"
    ],
    "is_checkpoint_unfinished": [
      "checkpoint_path"
    ],
    "set_checkpoint_unfinished_marker": [
      "checkpoint_path",
      "barrier_after"
    ],
    "remove_checkpoint_unfinished_marker": [
      "checkpoint_path",
      "barrier_before"
    ],
    "file_exists": [
      "self",
      "filepath",
      "trainer",
      "check_dist_ckpt"
    ],
    "_save_checkpoint": [
      "self",
      "trainer",
      "filepath"
    ],
    "_get_finalize_save_checkpoint_callback": [
      "self",
      "trainer",
      "filepath",
      "global_step"
    ],
    "_remove_checkpoint": [
      "self",
      "trainer",
      "filepath",
      "override_async"
    ],
    "_ema_format_filepath": [
      "self",
      "filepath"
    ],
    "_has_ema_ckpts": [
      "self",
      "checkpoints"
    ],
    "_is_ema_filepath": [
      "self",
      "filepath"
    ],
    "_saved_checkpoint_paths": [
      "self"
    ],
    "_remove_unfinished_checkpoints": [
      "checkpoint_dir"
    ],
    "_should_remove_checkpoint": [
      "self",
      "trainer",
      "previous",
      "current"
    ]
  },
  "PreemptionCallback": {
    "__init__": [
      "self",
      "checkpoint_callback",
      "sig"
    ],
    "interrupted": [
      "self"
    ],
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_end": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ],
    "release": [
      "self"
    ]
  },
  "struct_copy_one": [
    "src"
  ],
  "struct_copy_two": [
    "tgt",
    "src"
  ],
  "StaticBufferLoader": {
    "__init__": [
      "self",
      "loader"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "get_lr": [
    "lr_scheduler"
  ],
  "zero_grad": [
    "optimizer"
  ],
  "to_tensor": [
    "self",
    "value",
    "name"
  ],
  "get_optimizer_step": [
    "state"
  ],
  "get_training_step": [
    "state"
  ],
  "get_amp_autocast_init": [
    "state"
  ],
  "get_ddp_init": [
    "state"
  ],
  "CUDAGraphState": {},
  "CUDAGraphCallback": {
    "__init__": [
      "self",
      "capture_iteration"
    ],
    "setup": [
      "self",
      "trainer",
      "pl_module",
      "stage"
    ],
    "teardown": [
      "self",
      "trainer",
      "pl_module",
      "stage"
    ],
    "on_fit_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_fit_end": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_end": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_epoch_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_epoch_end": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_batch_start": [
      "self",
      "trainer",
      "pl_module",
      "batch",
      "batch_idx"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ],
    "on_save_checkpoint": [
      "self",
      "trainer",
      "pl_module",
      "checkpoint"
    ]
  },
  "_PRINTED_WARNING": [],
  "deprecated": [
    "wrapped",
    "version",
    "explanation",
    "wait_seconds"
  ],
  "deprecated_warning": [
    "old_method",
    "new_method",
    "wait_seconds"
  ],
  "experimental": [
    "wrapped",
    "instance",
    "args",
    "kwargs"
  ],
  "_normalize_docstring": [
    "docstring"
  ],
  "add_port_docs": [
    "wrapped",
    "instance",
    "value"
  ],
  "MLFlowParams": {},
  "ClearMLParams": {},
  "ClearMLLogger": {
    "name": [
      "self"
    ],
    "version": [
      "self"
    ],
    "__init__": [
      "self",
      "clearml_cfg",
      "log_dir",
      "prefix",
      "save_best_model",
      "postfix"
    ],
    "log_hyperparams": [
      "self",
      "params"
    ],
    "log_metrics": [
      "self",
      "metrics",
      "step"
    ],
    "log_table": [
      "self",
      "key",
      "columns",
      "data",
      "dataframe",
      "step"
    ],
    "after_save_checkpoint": [
      "self",
      "checkpoint_callback"
    ],
    "finalize": [
      "self",
      "status"
    ],
    "_log_model": [
      "self",
      "save_path"
    ]
  },
  "DLLoggerParams": {},
  "DLLogger": {
    "name": [
      "self"
    ],
    "version": [
      "self"
    ],
    "__init__": [
      "self",
      "stdout",
      "verbose",
      "json_file"
    ],
    "log_hyperparams": [
      "self",
      "params"
    ],
    "log_metrics": [
      "self",
      "metrics",
      "step"
    ],
    "save": [
      "self"
    ]
  },
  "BaseFormatter": {
    "DEFAULT_FORMAT": [],
    "DEFAULT_DATE_FORMAT": [],
    "DEFAULT_COLORS": [],
    "__init__": [
      "self",
      "color",
      "fmt",
      "datefmt",
      "colors"
    ],
    "format": [
      "self",
      "record"
    ]
  },
  "BaseNeMoFormatter": {
    "DEFAULT_FORMAT": []
  },
  "DebugNeMoFormatter": {
    "DEFAULT_FORMAT": []
  },
  "check_color_support": [],
  "to_unicode": [
    "value"
  ],
  "CSI": [],
  "OSC": [],
  "BEL": [],
  "code_to_chars": [
    "code"
  ],
  "set_title": [
    "title"
  ],
  "clear_screen": [
    "mode"
  ],
  "clear_line": [
    "mode"
  ],
  "AnsiCodes": {
    "__init__": [
      "self"
    ]
  },
  "AnsiCursor": {
    "UP": [
      "self",
      "n"
    ],
    "DOWN": [
      "self",
      "n"
    ],
    "FORWARD": [
      "self",
      "n"
    ],
    "BACK": [
      "self",
      "n"
    ],
    "POS": [
      "self",
      "x",
      "y"
    ]
  },
  "AnsiFore": {
    "BLACK": [],
    "RED": [],
    "GREEN": [],
    "YELLOW": [],
    "BLUE": [],
    "MAGENTA": [],
    "CYAN": [],
    "WHITE": [],
    "RESET": [],
    "LIGHTBLACK_EX": [],
    "LIGHTRED_EX": [],
    "LIGHTGREEN_EX": [],
    "LIGHTYELLOW_EX": [],
    "LIGHTBLUE_EX": [],
    "LIGHTMAGENTA_EX": [],
    "LIGHTCYAN_EX": [],
    "LIGHTWHITE_EX": []
  },
  "AnsiBack": {
    "BLACK": [],
    "RED": [],
    "GREEN": [],
    "YELLOW": [],
    "BLUE": [],
    "MAGENTA": [],
    "CYAN": [],
    "WHITE": [],
    "RESET": [],
    "LIGHTBLACK_EX": [],
    "LIGHTRED_EX": [],
    "LIGHTGREEN_EX": [],
    "LIGHTYELLOW_EX": [],
    "LIGHTBLUE_EX": [],
    "LIGHTMAGENTA_EX": [],
    "LIGHTCYAN_EX": [],
    "LIGHTWHITE_EX": []
  },
  "AnsiStyle": {
    "BRIGHT": [],
    "DIM": [],
    "NORMAL": [],
    "RESET_ALL": []
  },
  "Fore": [],
  "Back": [],
  "Style": [],
  "Cursor": [],
  "initialize_model_parallel_for_nemo": [
    "world_size",
    "global_rank",
    "local_rank",
    "tensor_model_parallel_size",
    "expert_model_parallel_size",
    "expert_tensor_parallel_size",
    "pipeline_model_parallel_size",
    "virtual_pipeline_model_parallel_size",
    "pipeline_model_parallel_split_rank",
    "pipeline_model_parallel_comm_backend",
    "context_parallel_size",
    "encoder_tensor_model_parallel_size",
    "encoder_pipeline_model_parallel_size",
    "micro_batch_size",
    "global_batch_size",
    "rampup_batch_size",
    "use_fp8",
    "init_mpi_proc_group",
    "seed",
    "apex_transformer_log_level",
    "use_tp_pp_dp_mapping",
    "use_te_rng_tracker",
    "num_distributed_optimizer_instances",
    "nccl_communicator_config_path",
    "use_sharp",
    "use_gloo_process_groups"
  ],
  "_set_random_seed": [
    "seed_"
  ],
  "set_jit_fusion_options": [],
  "fake_initialize_model_parallel": [
    "world_size",
    "rank",
    "tensor_model_parallel_size_",
    "pipeline_model_parallel_size_",
    "pipeline_model_parallel_split_rank_",
    "virtual_pipeline_model_parallel_size_",
    "expert_model_parallel_size_",
    "expert_tensor_parallel_size_",
    "context_parallel_size_",
    "encoder_tensor_model_parallel_size_",
    "encoder_pipeline_model_parallel_size_",
    "use_tp_pp_dp_mapping"
  ],
  "_try_restore_tokenizer": [
    "model",
    "ckpt_path"
  ],
  "AutoResume": {
    "WEIGHTS_PATH": [],
    "get_weights_path": [
      "self",
      "path"
    ],
    "setup": [
      "self",
      "trainer",
      "model"
    ],
    "_extract_path": [
      "self",
      "path"
    ],
    "_get_base_model_path_for_adapter": [
      "self",
      "adapter_meta_path",
      "model"
    ],
    "_find_trainer_ckpt_path": [
      "self"
    ],
    "get_context_path": [
      "self",
      "model"
    ],
    "get_trainer_ckpt_path": [
      "self",
      "model"
    ]
  },
  "AdapterPath": {
    "__new__": [
      "cls"
    ],
    "__repr__": [
      "self"
    ]
  },
  "NEMO_MEGATRON_MODEL_PARALLEL_APPSTATE_OVERRIDE": [],
  "SharedStateDictProtocol": {
    "sharded_state_dict": [
      "self",
      "prefix",
      "metadata"
    ]
  },
  "init_parallel_ranks": [
    "world_size",
    "global_rank",
    "local_rank",
    "parallel_config",
    "seed",
    "fp8"
  ],
  "init_model_parallel": [
    "model"
  ],
  "set_model_parallel_attributes": [
    "model",
    "parallelism"
  ],
  "megatron_lazy_init_context": [
    "config"
  ],
  "megatron_cpu_init_context": [
    "config"
  ],
  "ModelT": [],
  "GradScaler": {
    "__init__": [
      "self",
      "init_scale",
      "growth_factor",
      "backoff_factor",
      "growth_interval",
      "enabled",
      "hysteresis"
    ],
    "_unscale_grads_": [
      "self",
      "optimizer"
    ],
    "_maybe_opt_step": [
      "self",
      "optimizer",
      "optimizer_state"
    ],
    "update": [
      "self",
      "new_scale"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "enable_nvidia_optimizations": [],
  "optimizer_sharded_state_dict": [
    "model",
    "optimizer",
    "is_loading",
    "sharding_type",
    "metadata"
  ],
  "load_model_state_dict": [
    "megatron_parallel",
    "checkpoint",
    "strict"
  ],
  "_sync_from_last_pipeline_stage": [
    "value",
    "broadcast"
  ],
  "setup_megatron_optimizer": [
    "model",
    "config",
    "no_weight_decay_cond",
    "scale_lr_cond",
    "lr_mult"
  ],
  "DEFAULT_NEMO_CACHE_HOME": [],
  "NEMO_CACHE_HOME": [],
  "DEFAULT_NEMO_DATASETS_CACHE": [],
  "NEMO_DATASETS_CACHE": [],
  "DEFAULT_NEMO_MODELS_CACHE": [],
  "NEMO_MODELS_CACHE": [],
  "get_vocab_size": [
    "config",
    "vocab_size",
    "make_vocab_size_divisible_by"
  ],
  "ADAPTER_META_FILENAME": [],
  "HF_ADAPTER_CONFIG_FILENAME": [],
  "idempotent_path_append": [
    "base_dir",
    "suffix"
  ],
  "ckpt_to_context_subdir": [
    "filepath"
  ],
  "NeMoLogger": {
    "__post_init__": [
      "self"
    ],
    "setup": [
      "self",
      "trainer",
      "resume_if_exists",
      "task_config"
    ],
    "_setup_trainer_loggers": [
      "self",
      "trainer",
      "dir",
      "version"
    ],
    "_setup_trainer_model_checkpoint": [
      "self",
      "trainer",
      "log_dir",
      "ckpt"
    ],
    "_handle_task_config": [
      "self",
      "task_config",
      "log_dir"
    ],
    "_setup_file_logging": [
      "self",
      "log_dir"
    ],
    "_setup_files_to_move": [
      "self",
      "log_dir",
      "app_state"
    ]
  },
  "DataT": [],
  "STEP_OUTPUT": [],
  "PrecisionPluginProtocol": {
    "convert_input": [
      "self",
      "data"
    ],
    "convert_output": [
      "self",
      "output"
    ]
  },
  "default_data_step": [
    "dataloader_iter"
  ],
  "default_forward_step": [
    "model",
    "batch"
  ],
  "extract_ddp_funcs": [
    "ddp_config",
    "pipeline"
  ],
  "MegatronParallel": {
    "__init__": [
      "self",
      "pipeline",
      "precision_plugin",
      "callbacks",
      "data_step",
      "forward_step",
      "loss_reduction",
      "vp_size",
      "ddp_config",
      "fsdp",
      "cpu",
      "convert_module_fn"
    ],
    "forward": [
      "self",
      "data",
      "forward_only",
      "data_step",
      "forward_step",
      "loss_reduction",
      "seq_length",
      "micro_batch_size",
      "num_microbatches",
      "step_i",
      "wrap_forward_step"
    ],
    "training_step": [
      "self",
      "data",
      "data_step",
      "forward_step",
      "loss_reduction",
      "seq_length",
      "micro_batch_size",
      "num_microbatches"
    ],
    "validation_step": [
      "self",
      "data",
      "data_step",
      "forward_step",
      "loss_reduction",
      "seq_length",
      "micro_batch_size",
      "num_microbatches",
      "step_i"
    ],
    "test_step": [
      "self",
      "data",
      "data_step",
      "forward_step",
      "loss_reduction",
      "seq_length",
      "micro_batch_size",
      "num_microbatches",
      "step_i"
    ],
    "predict_step": [
      "self",
      "data",
      "data_step",
      "forward_step",
      "loss_reduction",
      "seq_length",
      "micro_batch_size",
      "num_microbatches",
      "step_i"
    ],
    "_step": [
      "self",
      "step_type",
      "data",
      "data_step",
      "forward_step",
      "loss_reduction",
      "seq_length",
      "micro_batch_size",
      "num_microbatches",
      "forward_only",
      "step_i"
    ],
    "wrapped_forward_step": [
      "self",
      "forward_step",
      "loss_reduction",
      "data_step",
      "context"
    ],
    "init_model_parallel": [
      "self"
    ],
    "apply_convert_module_fn": [
      "self"
    ],
    "init_ddp": [
      "self"
    ],
    "teardown_ddp": [
      "self"
    ],
    "_setup_module": [
      "self",
      "function"
    ],
    "_call_module": [
      "self",
      "function"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "metadata"
    ],
    "_module_sharded_state_dict": [
      "self",
      "module"
    ],
    "enable_forward_pre_hook": [
      "self"
    ],
    "disable_forward_pre_hook": [
      "self"
    ],
    "force_param_sync": [
      "self"
    ],
    "pipeline": [
      "self"
    ],
    "module": [
      "self"
    ],
    "__getattr__": [
      "self",
      "item"
    ]
  },
  "_ModuleStepFunction": {
    "__init__": [
      "self",
      "name",
      "is_property",
      "includes_self"
    ],
    "from_data_step": [
      "cls",
      "module",
      "step_type"
    ],
    "from_forward_step": [
      "cls",
      "module",
      "step_type"
    ],
    "from_loss_reduction": [
      "cls",
      "module",
      "step_type"
    ],
    "__call__": [
      "self",
      "module"
    ]
  },
  "getattr_proxy": [
    "self",
    "item"
  ],
  "DDP": {
    "__init__": [
      "self",
      "config",
      "ddp_config",
      "module",
      "disable_bucketing"
    ],
    "state_dict": [
      "self",
      "prefix",
      "keep_vars"
    ],
    "__getattr__": [
      "self",
      "item"
    ]
  },
  "CallbackConnector": {
    "__init__": [
      "self",
      "callbacks"
    ],
    "add": [
      "self"
    ],
    "event": [
      "self",
      "name"
    ],
    "transform_event": [
      "self",
      "name",
      "obj"
    ],
    "__add__": [
      "self",
      "other"
    ],
    "__iadd__": [
      "self",
      "other"
    ],
    "__contains__": [
      "self",
      "callback_object"
    ]
  },
  "MegatronStep": {
    "infer": [
      "cls",
      "pipeline",
      "data",
      "forward_step_func",
      "forward_only",
      "micro_batch_size",
      "seq_length",
      "num_microbatches",
      "step_i"
    ],
    "__call__": [
      "self"
    ],
    "to_data_iterator_list": [
      "self",
      "data"
    ],
    "infer_micro_batch_size": [
      "cls",
      "data"
    ],
    "infer_seq_length": [
      "cls",
      "data"
    ],
    "infer_num_microbatches": [
      "cls",
      "data"
    ],
    "model": [
      "self"
    ],
    "pl_module": [
      "self"
    ],
    "trainer": [
      "self"
    ],
    "forward_backward_func": [
      "self"
    ],
    "adjust_tensor_shapes_fn": [
      "self"
    ],
    "get_data_iterator_and_seq_length": [
      "self"
    ],
    "has_global_batch_sampler": [
      "self"
    ]
  },
  "CallbackMethods": {
    "on_megatron_step_start": [
      "self",
      "step"
    ],
    "on_megatron_microbatches_start": [
      "self",
      "step"
    ],
    "on_megatron_microbatch_start": [
      "self",
      "step",
      "batch",
      "forward_callback"
    ],
    "on_megatron_microbatch_end": [
      "self",
      "step",
      "batch",
      "forward_callback",
      "output"
    ],
    "on_megatron_microbatches_end": [
      "self",
      "step",
      "microbatch_outputs"
    ],
    "on_megatron_reduce_microbatches_start": [
      "self",
      "step",
      "microbatch_outputs"
    ],
    "on_megatron_reduce_microbatches_end": [
      "self",
      "step",
      "microbatch_outputs",
      "loss_reduction",
      "reduced"
    ],
    "on_megatron_step_end": [
      "self",
      "step",
      "microbatch_outputs",
      "reduced"
    ]
  },
  "ReductionT": [],
  "MegatronLossReduction": {
    "__init__": [
      "self"
    ],
    "setup": [
      "self",
      "batch"
    ],
    "_pre_forward_hook": [
      "self",
      "module",
      "x"
    ],
    "forward": [
      "self",
      "batch",
      "forward_out"
    ],
    "reduce": [
      "self",
      "losses_reduced_per_micro_batch"
    ]
  },
  "MegatronCallbackProtocol": {
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "MegatronStepProtocol": {
    "__call__": [
      "self"
    ]
  },
  "_calc_number_of_params": [
    "model"
  ],
  "_calc_number_of_trainable_params": [
    "model"
  ],
  "is_list_of_iterators": [
    "var"
  ],
  "_make_data_iterator_list": [
    "model",
    "data_iterator"
  ],
  "MaskedTokenLossReduction": {
    "__init__": [
      "self",
      "validation_step",
      "val_drop_last"
    ],
    "forward": [
      "self",
      "batch",
      "forward_out"
    ],
    "reduce": [
      "self",
      "losses_reduced_per_micro_batch"
    ]
  },
  "MaskedTokenLossReductionWithLossMask": {
    "forward": [
      "self",
      "batch",
      "forward_out"
    ]
  },
  "masked_token_loss": [
    "tensor",
    "mask"
  ],
  "moe_loss_tracker_ctx": [],
  "aggregate_moe_loss_stats": [
    "loss_scale"
  ],
  "_is_slurm_interactive_mode": [],
  "get_one_logger_init_config": [],
  "_get_base_callback_config": [
    "trainer",
    "global_batch_size",
    "seq_length"
  ],
  "get_nemo_v1_callback_config": [
    "trainer"
  ],
  "get_nemo_v2_callback_config": [
    "trainer",
    "data"
  ],
  "_should_enable_for_current_rank": [],
  "OneLoggerNeMoCallback": {
    "_instance": [],
    "__new__": [
      "cls"
    ],
    "__init__": [
      "self"
    ],
    "update_config": [
      "self",
      "nemo_version",
      "trainer"
    ]
  },
  "CallbackGroup": {
    "get_instance": [
      "cls"
    ],
    "__init__": [
      "self"
    ],
    "register": [
      "self",
      "callback"
    ],
    "update_config": [
      "self",
      "nemo_version",
      "trainer"
    ],
    "callbacks": [
      "self"
    ],
    "__getattr__": [
      "self",
      "method_name"
    ],
    "on_app_end": [
      "self"
    ]
  },
  "hook_class_init_with_callbacks": [
    "cls",
    "start_callback",
    "end_callback"
  ],
  "create_dataloader": [
    "dataset",
    "drop_last",
    "pad_samples_to_global_batch_size"
  ],
  "setup_microbatch_calculator": [
    "global_rank",
    "micro_batch_size",
    "global_batch_size",
    "rampup_batch_size"
  ],
  "add_megatron_sampler": [
    "dataloader",
    "micro_batch_size",
    "global_batch_size",
    "rampup_batch_size",
    "consumed_samples",
    "dataloader_type",
    "drop_last",
    "pad_samples_to_global_batch_size",
    "dataloader_mode",
    "rank",
    "world_size"
  ],
  "WrappedDataLoader": {
    "__init__": [
      "self",
      "mode"
    ]
  },
  "BaseMegatronSampler": {
    "__init__": [
      "self",
      "total_samples",
      "consumed_samples",
      "micro_batch_size",
      "data_parallel_rank",
      "data_parallel_size",
      "drop_last",
      "global_batch_size",
      "rampup_batch_size",
      "pad_samples_to_global_batch_size"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "MegatronPretrainingSampler": {
    "__init__": [
      "self",
      "total_samples",
      "consumed_samples",
      "micro_batch_size",
      "data_parallel_rank",
      "data_parallel_size",
      "drop_last",
      "global_batch_size",
      "rampup_batch_size",
      "pad_samples_to_global_batch_size"
    ],
    "get_start_end_idx": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "MegatronPretrainingRandomSampler": {
    "__init__": [
      "self",
      "total_samples",
      "consumed_samples",
      "micro_batch_size",
      "data_parallel_rank",
      "data_parallel_size",
      "drop_last",
      "global_batch_size",
      "pad_samples_to_global_batch_size",
      "seed"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "BaseCallback": {
    "on_app_start": [
      "self"
    ],
    "on_app_end": [
      "self"
    ],
    "on_model_init_start": [
      "self"
    ],
    "on_model_init_end": [
      "self"
    ],
    "on_dataloader_init_start": [
      "self"
    ],
    "on_dataloader_init_end": [
      "self"
    ],
    "on_optimizer_init_start": [
      "self"
    ],
    "on_optimizer_init_end": [
      "self"
    ],
    "on_load_checkpoint_start": [
      "self"
    ],
    "on_load_checkpoint_end": [
      "self"
    ],
    "on_save_checkpoint_start": [
      "self"
    ],
    "on_save_checkpoint_end": [
      "self"
    ],
    "on_save_checkpoint_success": [
      "self"
    ],
    "update_config": [
      "self"
    ]
  },
  "AnyT": [],
  "ConfigT": [],
  "FabricMegatronMixedPrecision": {
    "__init__": [
      "self",
      "precision",
      "params_dtype",
      "pipeline_dtype",
      "autocast_dtype",
      "autocast_enabled",
      "grad_reduce_in_fp32",
      "fp8",
      "fp8_recipe",
      "first_last_layers_bf16",
      "num_layers_at_start_in_bf16",
      "num_layers_at_end_in_bf16",
      "reuse_grad_buf_for_mxfp8_param_ag",
      "fp8_margin",
      "fp8_amax_history_len",
      "fp8_amax_compute_algo",
      "fp8_wgrad",
      "fp8_dot_product_attention",
      "fp8_multi_head_attention",
      "fp8_params",
      "fp8_param_gather",
      "fp16_loss_scale",
      "fp16_initial_loss_scale",
      "fp16_min_loss_scale",
      "fp16_loss_scale_window",
      "fp16_hysteresis"
    ],
    "convert_input": [
      "self",
      "data"
    ],
    "convert_output": [
      "self",
      "data"
    ],
    "convert_config": [
      "self",
      "config"
    ],
    "convert_module": [
      "self",
      "module"
    ],
    "convert_optimizer": [
      "self",
      "optimizer"
    ],
    "forward_context": [
      "self"
    ]
  },
  "_convert_megatron_mixed_precision": [
    "plugin"
  ],
  "FabricT": [],
  "to_fabric": [
    "obj"
  ],
  "_ddp_converter": [
    "strategy"
  ],
  "_fsdp_converter": [
    "strategy"
  ],
  "_mixed_precision_converter": [
    "plugin"
  ],
  "_fsdp_precision_converter": [
    "plugin"
  ],
  "DDPLiteral": [],
  "FabricMegatronStrategy": {
    "__init__": [
      "self",
      "tensor_model_parallel_size",
      "pipeline_model_parallel_size",
      "virtual_pipeline_model_parallel_size",
      "pipeline_model_parallel_comm_backend",
      "microbatch_group_size_per_vp_stage",
      "context_parallel_size",
      "sequence_parallel",
      "expert_model_parallel_size",
      "moe_extended_tp",
      "expert_tensor_parallel_size",
      "encoder_tensor_model_parallel_size",
      "encoder_pipeline_model_parallel_size",
      "data_sampler",
      "accelerator",
      "parallel_devices",
      "cluster_environment",
      "checkpoint_io",
      "precision",
      "megatron_callbacks",
      "ddp",
      "process_group_backend",
      "timeout",
      "start_method",
      "no_ddp_communication_hook",
      "output_data_idx",
      "pipeline_dtype",
      "init_model_parallel",
      "use_tp_pp_dp_mapping",
      "num_distributed_optimizer_instances",
      "nccl_communicator_config_path"
    ],
    "_setup_distributed": [
      "self"
    ],
    "process_datamodule": [
      "self",
      "datamodule"
    ],
    "process_dataloader": [
      "self",
      "dataloader"
    ],
    "setup_megatron_optimizer": [
      "self",
      "model",
      "optimizer_config",
      "no_weight_decay_cond",
      "scale_lr_cond",
      "lr_mult"
    ],
    "setup_optimizer": [
      "self",
      "optimizer"
    ],
    "setup_module": [
      "self",
      "module"
    ],
    "module_init_context": [
      "self",
      "empty_init"
    ],
    "module_to_device": [
      "self",
      "module"
    ],
    "save_checkpoint": [
      "self",
      "path",
      "state",
      "storage_options",
      "filter_dict"
    ],
    "load_checkpoint": [
      "self",
      "path",
      "state",
      "strict"
    ],
    "load_module_state_dict": [
      "self",
      "module",
      "state_dict",
      "strict"
    ],
    "sharded_state_dict_metadata": [
      "self"
    ],
    "megatron_context": [
      "self"
    ],
    "checkpoint_io": [
      "self"
    ],
    "unwrapped_checkpoint_io": [
      "self"
    ],
    "parallelism": [
      "self"
    ]
  },
  "_MegatronDataLoaderIterDataFetcher": {
    "__init__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "_DataFetcherWrapper": {
    "__init__": [
      "self",
      "data_fetcher",
      "output_data_idx"
    ],
    "done": [
      "self"
    ],
    "fetched": [
      "self"
    ],
    "length": [
      "self"
    ],
    "data_config": [
      "self"
    ],
    "__next__": [
      "self"
    ]
  },
  "convert_megatron_strategy": [
    "strategy"
  ],
  "Fabric": {
    "io_init": [
      "self"
    ],
    "load_model": [
      "self",
      "path",
      "model"
    ],
    "import_model": [
      "self",
      "path",
      "model_type"
    ],
    "setup_module": [
      "self",
      "module",
      "move_to_device",
      "_reapply_compile"
    ],
    "setup_datamodule": [
      "self",
      "datamodule",
      "stage"
    ]
  },
  "DistributedModel": {},
  "NoValOnRestartTrainingLoop": {
    "_should_check_val_fx": [
      "self",
      "data_fetcher"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "prefix"
    ],
    "advance": [
      "self",
      "data_fetcher"
    ]
  },
  "Trainer": {
    "add_io": [
      "self",
      "obj"
    ],
    "io_init": [
      "self"
    ],
    "to_fabric": [
      "self",
      "callbacks",
      "loggers"
    ]
  },
  "extract_dtypes": [
    "ckpt"
  ],
  "dtype_from_str": [
    "dtype"
  ],
  "dtype_from_hf": [
    "config"
  ],
  "is_trainer_attached": [
    "model"
  ],
  "get_automodel_from_trainer": [
    "trainer"
  ],
  "MCoreHierarchicalCheckpointIO": {
    "__init__": [
      "self",
      "wrapped_checkpoint_io",
      "local_ckpt_manager",
      "get_global_ckpt_iteration_fn",
      "async_save",
      "local_ckpt_algo",
      "parallelization_group",
      "allow_cache"
    ],
    "to_tensor_aware_state_dict": [
      "self",
      "checkpoint"
    ],
    "from_tensor_aware_state_dict": [
      "self",
      "tensor_aware_checkpoint",
      "sharded_state_dict",
      "strict"
    ]
  },
  "update_trainer_local_checkpoint_io": [
    "trainer",
    "local_checkpoint_base_dir",
    "get_global_ckpt_iteration_fn"
  ],
  "_logger": [],
  "FSDP2Strategy": {
    "__init__": [
      "self",
      "data_parallel_size",
      "tensor_parallel_size",
      "context_parallel_size",
      "sequence_parallel",
      "offload_policy",
      "data_sampler",
      "checkpoint_io",
      "mp_policy",
      "parallelize_fn",
      "use_hf_tp_plan",
      "custom_tp_plan"
    ],
    "lightning_restore_optimizer": [
      "self"
    ],
    "load_optimizer_state_dict": [
      "self",
      "checkpoint"
    ],
    "_load_optimizer_state_dict": [
      "self"
    ],
    "setup_environment": [
      "self"
    ],
    "setup": [
      "self",
      "trainer"
    ],
    "parallelize": [
      "self"
    ],
    "_setup_distributed": [
      "self"
    ],
    "_get_loss_reduction": [
      "self",
      "step_type"
    ],
    "_step_proxy": [
      "self",
      "step_type",
      "batch",
      "batch_idx"
    ],
    "optimizer_state": [
      "self",
      "optimizer"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "tensor_init_context": [
      "self",
      "empty_init"
    ],
    "checkpoint_io": [
      "self",
      "io"
    ],
    "current_epoch_step": [
      "self"
    ],
    "remove_checkpoint": [
      "self",
      "filepath"
    ],
    "lightning_module_state_dict": [
      "self"
    ],
    "save_checkpoint": [
      "self",
      "checkpoint",
      "filepath",
      "storage_options"
    ],
    "load_checkpoint": [
      "self",
      "checkpoint_path"
    ],
    "load_model_state_dict": [
      "self",
      "ckpt",
      "strict"
    ]
  },
  "RestoreConfig": {},
  "setup_parallel_ranks": [
    "strategy"
  ],
  "setup_data_sampler": [
    "trainer"
  ],
  "fix_progress_bar": [
    "trainer",
    "replace_progress_bar",
    "progress_interval"
  ],
  "create_checkpoint_io": [
    "wrapping_ckpt_io"
  ],
  "mcore_to_pyt_sharded_state_dict": [
    "checkpoint",
    "sharded_state_dict",
    "dtensor",
    "device_mesh"
  ],
  "pyt_to_mcore_state_dict": [
    "state_dict",
    "prefix",
    "device_mesh"
  ],
  "fsdp2_strategy_parallelize": [
    "model",
    "device_mesh",
    "mp_policy",
    "use_hf_tp_plan",
    "tp_shard_plan",
    "offload_policy"
  ],
  "get_hf_tp_shard_plan": [
    "model"
  ],
  "translate_to_torch_parallel_style": [
    "style"
  ],
  "to_cpu": [
    "v"
  ],
  "_destroy_dist_connection": [],
  "create_context_parallel_ctx": [
    "cp_mesh",
    "cp_buffers",
    "cp_seq_dims",
    "cp_no_restore_buffers",
    "cp_rotate_method"
  ],
  "get_train_context": [
    "enable_loss_parallel",
    "enable_compiled_autograd"
  ],
  "FSDPLiteral": [],
  "URL": [],
  "LOAD_ERROR": [],
  "RESHARDING_LOAD_ERROR": [],
  "ParallelismConfig": {},
  "MegatronStrategy": {
    "__init__": [
      "self",
      "tensor_model_parallel_size",
      "pipeline_model_parallel_size",
      "pipeline_model_parallel_comm_backend",
      "num_layers_in_first_pipeline_stage",
      "num_layers_in_last_pipeline_stage",
      "virtual_pipeline_model_parallel_size",
      "microbatch_group_size_per_vp_stage",
      "context_parallel_size",
      "sequence_parallel",
      "expert_model_parallel_size",
      "moe_extended_tp",
      "expert_tensor_parallel_size",
      "encoder_tensor_model_parallel_size",
      "encoder_pipeline_model_parallel_size",
      "account_for_embedding_in_pipeline_split",
      "account_for_loss_in_pipeline_split",
      "data_sampler",
      "parallel_devices",
      "cluster_environment",
      "checkpoint_io",
      "find_unused_parameters",
      "ckpt_load_optimizer",
      "ckpt_save_optimizer",
      "ckpt_load_main_params",
      "ddp",
      "fsdp",
      "lazy_init",
      "pipeline_dtype",
      "use_te_rng_tracker",
      "use_sharp",
      "save_ckpt_format",
      "ckpt_async_save",
      "ckpt_torch_dist_multiproc",
      "ckpt_assume_constant_structure",
      "ckpt_parallel_save",
      "ckpt_parallel_save_within_dp",
      "ckpt_parallel_load",
      "ckpt_parallel_save_optim",
      "ckpt_load_directly_on_device",
      "ckpt_load_strictness",
      "ckpt_save_pre_mcore_014",
      "ckpt_optim_fully_reshardable",
      "distrib_optim_fully_reshardable_mem_efficient",
      "setup_optimizers",
      "init_model_parallel",
      "replace_progress_bar",
      "progress_interval",
      "restore_config",
      "megatron_log_level",
      "use_tp_pp_dp_mapping",
      "num_distributed_optimizer_instances",
      "nccl_communicator_config_path",
      "pipeline_model_parallel_layout",
      "use_gloo_process_groups"
    ],
    "pipeline_dtype": [
      "self",
      "value"
    ],
    "connect": [
      "self",
      "model"
    ],
    "setup": [
      "self",
      "trainer"
    ],
    "setup_distributed": [
      "self"
    ],
    "process_dataloader": [
      "self",
      "dataloader"
    ],
    "setup_megatron_parallel": [
      "self",
      "trainer"
    ],
    "init_model_parallel": [
      "self"
    ],
    "configure_ddp": [
      "self"
    ],
    "_setup_model": [
      "self",
      "model"
    ],
    "setup_optimizers": [
      "self",
      "trainer"
    ],
    "on_validation_end": [
      "self"
    ],
    "on_test_end": [
      "self"
    ],
    "training_step": [
      "self",
      "dataloader_iter"
    ],
    "optimizer_step": [
      "self",
      "optimizer",
      "closure",
      "model"
    ],
    "validation_step": [
      "self",
      "dataloader_iter"
    ],
    "test_step": [
      "self",
      "dataloader_iter"
    ],
    "predict_step": [
      "self",
      "dataloader_iter"
    ],
    "teardown": [
      "self"
    ],
    "model_sharded_context": [
      "self"
    ],
    "_update_step_kwargs": [
      "self",
      "dataloader_iter",
      "kwargs",
      "step_name"
    ],
    "optimizer_sharded_state_dict": [
      "self",
      "is_loading",
      "metadata"
    ],
    "_get_fsdp_dtensor_state_dict": [
      "self",
      "raw_state_dict",
      "model_key",
      "optimizer_key"
    ],
    "_save_fsdp_dtensor_checkpoint": [
      "self",
      "checkpoint",
      "path",
      "storage_options"
    ],
    "save_checkpoint": [
      "self",
      "checkpoint",
      "filepath",
      "storage_options"
    ],
    "should_restore_optimizer_states": [
      "self",
      "selective_restore"
    ],
    "_save_fsdp_dtensor_common_state": [
      "self",
      "state_dict",
      "ckpt_dir"
    ],
    "_load_fsdp_dtensor_common_state": [
      "self",
      "ckpt_dir"
    ],
    "_load_fsdp_dtensor_checkpoint": [
      "self",
      "path",
      "sharded_state_dict",
      "strict"
    ],
    "load_checkpoint": [
      "self",
      "checkpoint_path",
      "selective_restore"
    ],
    "sharded_state_dict_metadata": [
      "self"
    ],
    "selective_restore": [
      "self"
    ],
    "load_optimizer_state_dict": [
      "self",
      "checkpoint",
      "selective_restore"
    ],
    "remove_checkpoint": [
      "self",
      "filepath"
    ],
    "load_model_state_dict": [
      "self",
      "checkpoint",
      "strict"
    ],
    "checkpoint_io": [
      "self",
      "io"
    ],
    "unwrapped_checkpoint_io": [
      "self"
    ],
    "current_epoch_step": [
      "self"
    ],
    "distributed_sampler_kwargs": [
      "self"
    ],
    "restore_checkpoint_after_setup": [
      "self"
    ],
    "parallelism": [
      "self"
    ],
    "tensor_init_context": [
      "self",
      "empty_init"
    ]
  },
  "_data_fetcher_wrapper": [
    "fn"
  ],
  "_MegatronAutomaticOptimization": {
    "__init__": [
      "self",
      "trainer"
    ]
  },
  "FSDPStrategy": {
    "__init__": [
      "self",
      "auto_wrap_policy",
      "state_dict_type",
      "ckpt_load_optimizer",
      "ckpt_save_optimizer",
      "data_sampler"
    ],
    "setup_environment": [
      "self"
    ],
    "setup": [
      "self",
      "trainer"
    ],
    "_get_loss_reduction": [
      "self",
      "step_type"
    ],
    "_step_proxy": [
      "self",
      "step_type",
      "batch",
      "batch_idx"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "process_dataloader": [
      "self",
      "dataloader"
    ],
    "checkpoint_io": [
      "self",
      "io"
    ],
    "current_epoch_step": [
      "self"
    ],
    "remove_checkpoint": [
      "self",
      "filepath"
    ],
    "save_checkpoint": [
      "self",
      "checkpoint",
      "filepath",
      "storage_options"
    ],
    "load_checkpoint": [
      "self",
      "checkpoint_path"
    ]
  },
  "_CommOverlapConfig": {},
  "MegatronCommOverlapCallback": {
    "__init__": [
      "self",
      "tp_comm_overlap",
      "tp_comm_overlap_cfg",
      "tp_comm_bootstrap_backend",
      "overlap_p2p_comm",
      "batch_p2p_comm",
      "overlap_grad_reduce",
      "overlap_param_gather",
      "overlap_param_gather_with_optimizer_step",
      "align_param_gather",
      "bucket_size",
      "defer_embedding_wgrad_compute",
      "wgrad_deferral_limit"
    ],
    "_get_model_comm_overlap_cfgs": [
      "self",
      "parallelism_cfg"
    ],
    "_get_optimizer_overlap_cfgs": [
      "self",
      "parallelism_cfg"
    ],
    "_apply_cfgs": [
      "self",
      "src_cfg",
      "dest_cfg"
    ],
    "_override_user_cfgs": [
      "self",
      "comm_overlap_cfg"
    ],
    "_check_num_cuda_device_max_connections": [
      "self"
    ],
    "setup": [
      "self",
      "trainer",
      "pl_module",
      "stage"
    ],
    "_init_te_userbuffers": [
      "self",
      "model_parallel_cfg"
    ],
    "on_fit_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_validation_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_test_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_predict_start": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "OptimizerMonitor": {
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ]
  },
  "ModelTransform": {
    "__init__": [
      "self"
    ],
    "setup": [
      "self",
      "trainer",
      "pl_module",
      "stage"
    ],
    "on_train_epoch_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_validation_epoch_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "_maybe_apply_transform": [
      "self",
      "trainer"
    ],
    "apply_transform": [
      "self",
      "trainer"
    ],
    "_needs_to_call": [
      "self"
    ]
  },
  "_call_counter": [
    "func"
  ],
  "MegatronProgressBar": {
    "init_train_tqdm": [
      "self"
    ],
    "on_train_epoch_start": [
      "self",
      "trainer"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "calculate_data_parallel_groups": [],
  "get_current_epoch_step": [
    "trainer"
  ],
  "NsysCallback": {
    "__init__": [
      "self",
      "start_step",
      "end_step",
      "ranks",
      "gen_shape",
      "nvtx_ranges"
    ],
    "_rank_is_active": [
      "self",
      "trainer"
    ],
    "on_train_batch_start": [
      "self",
      "trainer",
      "pl_module",
      "batch",
      "batch_idx"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ]
  },
  "DeepEPCallback": {
    "setup": [
      "self",
      "trainer",
      "pl_module",
      "stage"
    ],
    "_apply_deepep_cfgs": [
      "self",
      "dest_cfg"
    ]
  },
  "trace_handler": [
    "prof",
    "chakra_device_trace_path"
  ],
  "PytorchProfilerCallback": {
    "__init__": [
      "self",
      "start_step",
      "end_step",
      "warmup_steps",
      "active_steps",
      "trace_dir",
      "profiler_kwargs"
    ],
    "on_train_batch_start": [
      "self",
      "trainer",
      "pl_module",
      "batch",
      "batch_idx"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ],
    "_stop_profiler": [
      "self"
    ]
  },
  "ProgressPrinter": {
    "__init__": [
      "self",
      "log_interval",
      "skip_accumulate_metrics",
      "exclude_metrics"
    ],
    "format_string": [
      "self",
      "prefix",
      "metrics"
    ],
    "disable": [
      "self"
    ],
    "enable": [
      "self"
    ],
    "is_disabled": [
      "self"
    ],
    "average_metrics_dict": [
      "self"
    ],
    "train_description": [
      "self"
    ],
    "validation_description": [
      "self"
    ],
    "test_description": [
      "self"
    ],
    "log_interval": [
      "self",
      "val"
    ],
    "on_sanity_check_start": [
      "self"
    ],
    "on_sanity_check_end": [
      "self"
    ],
    "on_train_start": [
      "self",
      "trainer"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_validation_batch_start": [
      "self",
      "trainer",
      "pl_module",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "on_validation_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "on_test_batch_start": [
      "self",
      "trainer",
      "pl_module",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "on_test_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "should_log": [
      "self",
      "n"
    ],
    "log_megatron_timers": [
      "self",
      "timers"
    ]
  },
  "pl_has_dist_opt_with_ovelap": [
    "trainer"
  ],
  "pl_check_param_hashes_across_dp_replicas": [
    "trainer"
  ],
  "DdpParityChecker": {
    "__init__": [
      "self",
      "interval"
    ],
    "on_train_batch_start": [
      "self",
      "trainer",
      "pl_module",
      "batch",
      "batch_idx",
      "unused"
    ],
    "on_train_end": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "MegatronTokenDropCallback": {
    "__init__": [
      "self",
      "moe_expert_capacity_factor",
      "moe_pad_expert_input_to_capacity"
    ],
    "_set_cfgs": [
      "self",
      "cfg"
    ],
    "setup": [
      "self",
      "trainer",
      "pl_module",
      "stage"
    ]
  },
  "_model_flops_map": [],
  "FLOPsMeasurementCallback": {
    "higher_is_better": [],
    "__init__": [
      "self",
      "model_config",
      "data_config",
      "model_name"
    ],
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ],
    "eval_tflops_per_sec_per_gpu": [
      "self",
      "train_step_time"
    ],
    "eval_model_flops": [
      "self"
    ]
  },
  "MM_FLOPsMeasurementCallback": {
    "higher_is_better": [],
    "__init__": [
      "self",
      "model_name_config_dict",
      "data_config"
    ],
    "eval_model_flops": [
      "self"
    ]
  },
  "ScheduleValue": [],
  "_resolve_attr": [
    "root",
    "path"
  ],
  "make_start_end": [
    "name",
    "spec"
  ],
  "LayerFreezer": {
    "__init__": [
      "self",
      "schedule"
    ],
    "_resolve_attr": [
      "root",
      "path"
    ],
    "_apply_freeze": [
      "self",
      "module",
      "freeze"
    ],
    "on_train_batch_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "RuntimeEstimator": {
    "__init__": [
      "self",
      "time_unit"
    ],
    "_get_elapsed_duration": [
      "self",
      "trainer"
    ],
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_batch_start": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ]
  },
  "SpeedMonitor": {
    "__init__": [
      "self",
      "window_size",
      "time_unit"
    ],
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ]
  },
  "MemoryProfileCallback": {
    "__init__": [
      "self",
      "dir",
      "warn_cycles",
      "ranks"
    ],
    "enable_on_rank": [
      "self"
    ],
    "setup": [
      "self",
      "trainer",
      "pl_module",
      "stage"
    ],
    "on_train_end": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "ModelCheckpoint": {
    "UNFINISHED_CHECKPOINT_SUFFIX": [],
    "__init__": [
      "self",
      "monitor",
      "verbose",
      "save_last",
      "save_top_k",
      "save_weights_only",
      "mode",
      "every_n_epochs",
      "every_n_train_steps",
      "train_time_interval",
      "save_on_train_epoch_end",
      "save_optim_on_train_end",
      "always_save_context",
      "save_context_on_train_end"
    ],
    "on_train_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "nemo_topk_check_previous_run": [
      "self"
    ],
    "_remove_invalid_entries_from_topk": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "setup": [
      "self",
      "trainer"
    ],
    "on_train_end": [
      "self",
      "trainer",
      "pl_module"
    ],
    "_del_model_without_trainer": [
      "self",
      "filepath"
    ],
    "_ema_callback": [
      "self",
      "trainer"
    ],
    "format_checkpoint_unfinished_marker_path": [
      "checkpoint_path"
    ],
    "is_checkpoint_unfinished": [
      "checkpoint_path"
    ],
    "set_checkpoint_unfinished_marker": [
      "checkpoint_path",
      "barrier_after"
    ],
    "remove_checkpoint_unfinished_marker": [
      "checkpoint_path",
      "barrier_before"
    ],
    "file_exists": [
      "self",
      "filepath",
      "trainer",
      "check_dist_ckpt"
    ],
    "_monitor_candidates": [
      "self",
      "trainer"
    ],
    "_link_checkpoint": [
      "self",
      "trainer",
      "filepath",
      "linkpath",
      "override_async"
    ],
    "_save_checkpoint": [
      "self",
      "trainer",
      "filepath"
    ],
    "_get_finalize_save_checkpoint_callback": [
      "self",
      "trainer",
      "filepath",
      "global_step"
    ],
    "_remove_checkpoint": [
      "self",
      "trainer",
      "filepath",
      "override_async"
    ],
    "_ema_format_filepath": [
      "self",
      "filepath"
    ],
    "_has_ema_ckpts": [
      "self",
      "checkpoints"
    ],
    "_is_ema_filepath": [
      "self",
      "filepath"
    ],
    "_saved_checkpoint_paths": [
      "self"
    ],
    "_remove_unfinished_checkpoints": [
      "checkpoint_dir"
    ],
    "_should_remove_checkpoint": [
      "self",
      "trainer",
      "previous",
      "current"
    ]
  },
  "collect_precision": [
    "tensor"
  ],
  "collect_precision_and_shape": [
    "tensor"
  ],
  "ParameterDebugger": {
    "__init__": [
      "self",
      "param_fn",
      "grad_fn",
      "log_on_hooks"
    ],
    "_apply_user_funcs": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "ModelTrainingStateCallback": {
    "__init__": [
      "self",
      "val_check_interval",
      "strict"
    ],
    "_get_training_state": [
      "self",
      "trainer"
    ],
    "on_train_batch_start": [
      "self",
      "trainer",
      "pl_module",
      "batch",
      "batch_idx"
    ]
  },
  "MegatronEnableExperimentalCallback": {
    "__init__": [
      "self"
    ],
    "setup": [
      "self"
    ]
  },
  "reduce_value": [
    "value",
    "reduce_op"
  ],
  "MemoryMonitor": {
    "__init__": [
      "self",
      "memory_keys",
      "dist_aggregate_batch_interval"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ]
  },
  "_MEMORY_KEYS": [],
  "_get_memory_report": [
    "memory_keys"
  ],
  "PEFT": {
    "transform": [
      "self",
      "module",
      "name",
      "prefix"
    ],
    "__call__": [
      "self",
      "model"
    ],
    "freeze_model": [
      "self",
      "model"
    ],
    "get_wrappped_io": [
      "self"
    ],
    "setup": [
      "self",
      "trainer",
      "pl_module",
      "stage"
    ],
    "set_params_to_save": [
      "self",
      "trainer"
    ],
    "apply_transform": [
      "self",
      "trainer"
    ],
    "restore_automodel": [
      "self",
      "trainer",
      "path"
    ],
    "adapter_key_filter": [
      "self",
      "key"
    ]
  },
  "AdapterWrapper": {
    "__init__": [
      "self",
      "to_wrap",
      "adapter"
    ],
    "base_linear_forward": [
      "self",
      "x"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "WrappedAdapterIO": {
    "__init__": [
      "self",
      "checkpoint_io",
      "peft"
    ],
    "save_checkpoint": [
      "self",
      "checkpoint",
      "path",
      "storage_options"
    ],
    "_create_lora_hf_config": [
      "self",
      "ckpt_keys"
    ],
    "load_checkpoint": [
      "self",
      "path",
      "sharded_state_dict",
      "map_location",
      "strict"
    ]
  },
  "extract_module_attr_name": [
    "pl_module"
  ],
  "listify": [
    "x"
  ],
  "get_modules_from_selector": [
    "model",
    "module_selector"
  ],
  "compile_module": [
    "config",
    "module"
  ],
  "JitConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "JitTransform": {
    "__init__": [
      "self",
      "config"
    ],
    "on_train_epoch_start": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "ModelCallback": {
    "TRAINER_PARAMS": [],
    "MODEL_PARAMS": [],
    "__init__": [
      "self",
      "setup",
      "teardown",
      "on_fit_start",
      "on_fit_end",
      "on_sanity_check_start",
      "on_sanity_check_end",
      "on_train_batch_start",
      "on_train_batch_end",
      "on_train_epoch_start",
      "on_train_epoch_end",
      "on_validation_epoch_start",
      "on_validation_epoch_end",
      "on_test_epoch_start",
      "on_test_epoch_end",
      "on_validation_batch_start",
      "on_validation_batch_end",
      "on_test_batch_start",
      "on_test_batch_end",
      "on_train_start",
      "on_train_end",
      "on_validation_start",
      "on_validation_end",
      "on_test_start",
      "on_test_end",
      "on_exception",
      "on_save_checkpoint",
      "on_load_checkpoint",
      "on_before_backward",
      "on_after_backward",
      "on_before_optimizer_step",
      "on_before_zero_grad",
      "on_predict_start",
      "on_predict_end",
      "on_predict_batch_start",
      "on_predict_batch_end",
      "on_predict_epoch_start",
      "on_predict_epoch_end"
    ],
    "_get_param_type": [
      "self",
      "param_name"
    ],
    "_wrap_func": [
      "self",
      "func"
    ]
  },
  "GarbageCollectionCallback": {
    "__init__": [
      "self",
      "gc_interval_train",
      "gc_interval_val"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ],
    "on_validation_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ]
  },
  "MegatronOptimizerModule": {
    "__init__": [
      "self",
      "config",
      "lr_scheduler",
      "no_weight_decay_cond",
      "scale_lr_cond",
      "lr_mult"
    ],
    "on_fit_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "optimizers": [
      "self",
      "model"
    ],
    "finalize_model_grads": [
      "self"
    ]
  },
  "LRSchedulerModule": {
    "connect": [
      "self",
      "model",
      "optimizer"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizers"
    ],
    "__call__": [
      "self",
      "model",
      "optimizers"
    ]
  },
  "OptimizerModule": {
    "__init__": [
      "self",
      "lr_scheduler"
    ],
    "connect": [
      "self",
      "model"
    ],
    "optimizers": [
      "self",
      "model"
    ],
    "on_train_batch_start": [
      "self",
      "trainer",
      "pl_module",
      "batch",
      "batch_idx"
    ],
    "__call__": [
      "self",
      "model",
      "megatron_parallel"
    ]
  },
  "WarmupPolicyScheduler": {
    "__init__": [
      "self",
      "warmup_steps",
      "warmup_ratio",
      "max_steps",
      "min_lr",
      "interval",
      "frequency",
      "monitor"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizer"
    ]
  },
  "WarmupHoldPolicyScheduler": {
    "__init__": [
      "self",
      "warmup_steps",
      "warmup_ratio",
      "hold_steps",
      "hold_ratio",
      "max_steps",
      "min_lr",
      "interval",
      "frequency",
      "monitor"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizer"
    ]
  },
  "SquareAnnealingScheduler": {
    "__init__": [
      "self",
      "max_steps",
      "min_lr",
      "interval",
      "frequency",
      "monitor"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizer"
    ]
  },
  "SquareRootAnnealingScheduler": {
    "__init__": [
      "self",
      "max_steps",
      "min_lr",
      "interval",
      "frequency",
      "monitor"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizer"
    ]
  },
  "NoamAnnealingScheduler": {
    "__init__": [
      "self",
      "d_model",
      "warmup_steps",
      "warmup_ratio",
      "max_steps",
      "min_lr",
      "interval",
      "frequency",
      "monitor"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizer"
    ]
  },
  "NoamHoldAnnealingScheduler": {
    "__init__": [
      "self",
      "max_steps",
      "decay_rate",
      "min_lr",
      "interval",
      "frequency",
      "monitor"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizer"
    ]
  },
  "WarmupAnnealingScheduler": {
    "__init__": [
      "self",
      "warmup_steps",
      "warmup_ratio",
      "max_steps",
      "min_lr",
      "interval",
      "frequency",
      "monitor"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizer"
    ]
  },
  "InverseSquareRootAnnealingScheduler": {
    "__init__": [
      "self",
      "max_steps",
      "min_lr",
      "interval",
      "frequency",
      "monitor"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizer"
    ]
  },
  "T5InverseSquareRootAnnealingScheduler": {
    "__init__": [
      "self",
      "max_steps",
      "min_lr",
      "interval",
      "frequency",
      "monitor"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizer"
    ]
  },
  "PolynomialDecayAnnealingScheduler": {
    "__init__": [
      "self",
      "max_steps",
      "min_lr",
      "power",
      "cycle",
      "interval",
      "frequency",
      "monitor"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizer"
    ]
  },
  "PolynomialHoldDecayAnnealingScheduler": {
    "__init__": [
      "self",
      "max_steps",
      "min_lr",
      "power",
      "cycle",
      "interval",
      "frequency",
      "monitor"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizer"
    ]
  },
  "CosineAnnealingScheduler": {
    "__init__": [
      "self",
      "max_steps",
      "warmup_steps",
      "constant_steps",
      "min_lr",
      "interval",
      "frequency",
      "monitor"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizer"
    ]
  },
  "WarmupHoldAnnealScheduler": {
    "__init__": [
      "self",
      "warmup_ratio",
      "hold_ratio",
      "max_steps",
      "decay_schedule",
      "min_lr",
      "interval",
      "frequency",
      "monitor"
    ],
    "scheduler": [
      "self",
      "model",
      "optimizer"
    ]
  },
  "_param_does_not_have_wd": [
    "param_name",
    "param"
  ],
  "_extract_model_params_for_optim": [
    "model",
    "weight_decay",
    "no_weight_decay_cond"
  ],
  "PytorchOptimizerModule": {
    "__init__": [
      "self",
      "optimizer_fn",
      "lr_scheduler",
      "no_weight_decay_cond",
      "scale_lr_cond",
      "lr_mult"
    ],
    "on_fit_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "optimizers": [
      "self",
      "model"
    ],
    "connect": [
      "self",
      "model"
    ]
  },
  "DataSampler": {
    "connect": [
      "self",
      "trainer"
    ],
    "setup": [
      "self",
      "global_rank"
    ],
    "transform_dataloader": [
      "self",
      "dataloader",
      "consumed_samples"
    ]
  },
  "MegatronDataSampler": {
    "__init__": [
      "self",
      "seq_len",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "dataloader_type",
      "init_consumed_samples",
      "init_global_step",
      "output_log",
      "decoder_seq_len"
    ],
    "setup": [
      "self",
      "global_rank"
    ],
    "transform_dataloader": [
      "self",
      "dataloader",
      "consumed_samples"
    ],
    "compute_consumed_samples": [
      "self",
      "steps_since_resume"
    ],
    "on_megatron_step_start": [
      "self",
      "step"
    ],
    "on_megatron_microbatches_start": [
      "self",
      "step"
    ],
    "on_megatron_step_end": [
      "self",
      "step"
    ],
    "num_microbatches": [
      "self"
    ],
    "current_global_batch_size": [
      "self"
    ]
  },
  "get_optim_config": [
    "optimizer"
  ],
  "DtypeConfig": {},
  "MegatronMixedPrecision": {
    "__init__": [
      "self",
      "precision",
      "params_dtype",
      "pipeline_dtype",
      "autocast_dtype",
      "autocast_enabled",
      "grad_reduce_in_fp32",
      "fp8",
      "fp8_recipe",
      "first_last_layers_bf16",
      "fp8_margin",
      "fp8_amax_history_len",
      "fp8_amax_compute_algo",
      "fp8_wgrad",
      "fp8_dot_product_attention",
      "fp8_multi_head_attention",
      "fp8_params",
      "fp8_param_gather",
      "fp4",
      "fp4_recipe",
      "fp16_loss_scale",
      "fp16_initial_loss_scale",
      "fp16_min_loss_scale",
      "fp16_loss_scale_window",
      "fp16_hysteresis",
      "num_layers_at_start_in_bf16",
      "num_layers_at_end_in_bf16",
      "reuse_grad_buf_for_mxfp8_param_ag"
    ],
    "convert_module": [
      "self",
      "module"
    ],
    "convert_optimizer": [
      "self",
      "optimizer"
    ],
    "convert_input": [
      "self",
      "data"
    ],
    "convert_output": [
      "self",
      "data"
    ],
    "forward_context": [
      "self"
    ],
    "clip_gradients": [
      "self",
      "optimizer",
      "clip_val",
      "gradient_clip_algorithm"
    ],
    "clip_grad_by_value": [
      "self",
      "optimizer",
      "clip_val"
    ],
    "clip_grad_by_norm": [
      "self",
      "optimizer",
      "clip_val"
    ]
  },
  "update_config_with_dtype_overrides": [
    "dtype_config",
    "config"
  ],
  "TEConfig": {},
  "te_accelerate": [
    "model",
    "fp8_autocast"
  ],
  "_apply_basic_module_replacement": [
    "model"
  ],
  "is_te_accelerated": [
    "model"
  ],
  "apply_fp8_autocast": [
    "model",
    "fp8_recipe_handler"
  ],
  "_contextual_fp8_autocast": [
    "model_forward",
    "fp8_recipe",
    "use_during_eval"
  ],
  "PredicateDispatch": {
    "__init__": [
      "self"
    ],
    "register": [
      "self",
      "predicate"
    ],
    "__call__": [
      "self",
      "value"
    ],
    "register_class": [
      "self",
      "cls"
    ]
  },
  "to_config": [],
  "handle_partial": [
    "value"
  ],
  "SourceT": [],
  "TargetT": [],
  "Connector": {
    "default_path": [],
    "LOCK_TIMEOUT": [],
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "__new__": [
      "cls"
    ],
    "__call__": [
      "self",
      "output_path",
      "overwrite"
    ],
    "local_path": [
      "self",
      "base_path"
    ],
    "is_in_cache": [
      "self",
      "base_path"
    ]
  },
  "ModelConnector": {
    "nemo_setup": [
      "self",
      "model",
      "trainer"
    ],
    "nemo_save": [
      "self",
      "output_path",
      "trainer",
      "dump_io"
    ],
    "nemo_load": [
      "self",
      "path",
      "trainer",
      "cpu"
    ],
    "local_path": [
      "self",
      "base_path"
    ],
    "on_import_ckpt": [
      "self",
      "model"
    ],
    "save_hf_tokenizer_assets": [
      "self",
      "tokenizer_name_or_path",
      "save_path"
    ]
  },
  "SourceModuleT": [],
  "TargetModuleT": [],
  "F": [],
  "TransformCTX": {},
  "_ModelState": {
    "__init__": [
      "self",
      "state_dict",
      "config"
    ],
    "state_dict": [
      "self"
    ],
    "to": [
      "self",
      "dtype"
    ]
  },
  "apply_transforms": [
    "source",
    "target",
    "mapping",
    "transforms",
    "state_dict_ignored_entries",
    "cast_dtype"
  ],
  "_default_transform": [
    "inp"
  ],
  "StateDictTransform": {
    "__init__": [
      "self",
      "source_key",
      "target_key",
      "transform"
    ],
    "__call__": [
      "self",
      "ctx"
    ],
    "call_transform": [
      "self",
      "ctx"
    ]
  },
  "_match_keys": [
    "keys",
    "pattern"
  ],
  "state_transform": [
    "source_key",
    "target_key",
    "fn"
  ],
  "TransformFns": {
    "split_qkv": [
      "ctx",
      "linear_qkv"
    ],
    "split_qkv_bias": [
      "ctx",
      "qkv_bias"
    ],
    "merge_qkv_concat": [
      "ctx",
      "qkv"
    ],
    "merge_qkv": [
      "ctx",
      "q",
      "k",
      "v"
    ],
    "merge_qkv_bias_concat": [
      "ctx",
      "qkv_bias"
    ],
    "merge_qkv_bias": [
      "ctx",
      "qb",
      "kb",
      "vb"
    ],
    "merge_fc1": [
      "gate",
      "up"
    ],
    "split_fc1": [
      "linear_fc1"
    ],
    "duplicate2": [
      "param"
    ],
    "duplicate3": [
      "param"
    ],
    "prune_padding": [
      "ctx",
      "embedding"
    ]
  },
  "load_context": [
    "path",
    "subpath",
    "build"
  ],
  "model_importer": [
    "target",
    "ext"
  ],
  "model_exporter": [
    "target",
    "ext"
  ],
  "import_ckpt": [
    "model",
    "source",
    "output_path",
    "overwrite"
  ],
  "load_connector_from_trainer_ckpt": [
    "path",
    "target"
  ],
  "_verify_peft_export": [
    "path",
    "target"
  ],
  "export_ckpt": [
    "path",
    "target",
    "output_path",
    "overwrite",
    "load_connector",
    "modelopt_export_kwargs"
  ],
  "log": [],
  "LightningModuleT": [],
  "ModuleT": [],
  "is_rank_0": [],
  "HFAdapterKeyRenamer": {
    "nemo_to_hf": [
      "x"
    ],
    "hf_to_nemo": [
      "x"
    ]
  },
  "HFCheckpointIO": {
    "__init__": [
      "self",
      "model",
      "adapter_only"
    ],
    "save_checkpoint": [
      "self",
      "checkpoint",
      "path",
      "storage_options"
    ],
    "_save_adapter_weights_only": [
      "self",
      "state_dict",
      "path",
      "storage_options"
    ],
    "_load_adapter_weights_only": [
      "path"
    ],
    "load_checkpoint": [
      "self",
      "path",
      "sharded_state_dict",
      "map_location",
      "strict"
    ],
    "remove_checkpoint": [
      "self",
      "path"
    ]
  },
  "ConnT": [],
  "CkptType": [],
  "_thread_local": [],
  "_is_default_factory": [
    "arg"
  ],
  "_ordered_arguments_with_default": [
    "data"
  ],
  "_config_representer_with_defaults": [
    "dumper",
    "data",
    "type_name"
  ],
  "_partial_representer_with_defaults": [
    "dumper",
    "data"
  ],
  "_safe_object_representer": [
    "dumper",
    "data"
  ],
  "IOMixin": {
    "__new__": [
      "cls"
    ],
    "__init_subclass__": [
      "cls"
    ],
    "io_transform_args": [
      "self",
      "init_fn"
    ],
    "io_init": [
      "self"
    ],
    "io_artifacts": [
      "cls"
    ],
    "io_dump": [
      "self",
      "output",
      "yaml_attrs"
    ],
    "_io_dump_yaml": [
      "self",
      "io",
      "attrs"
    ]
  },
  "ConnectorMixin": {
    "import_from": [
      "cls",
      "path"
    ],
    "register_importer": [
      "cls",
      "ext",
      "default_path"
    ],
    "register_exporter": [
      "cls",
      "ext",
      "default_path"
    ],
    "importer": [
      "cls",
      "path"
    ],
    "exporter": [
      "cls",
      "ext",
      "path"
    ],
    "import_ckpt": [
      "self",
      "path",
      "overwrite",
      "base_path"
    ],
    "_get_connector": [
      "cls",
      "ext",
      "path",
      "importer"
    ]
  },
  "track_io": [
    "target",
    "artifacts"
  ],
  "_io_transform_args": [
    "self",
    "init_fn"
  ],
  "_io_init": [
    "self"
  ],
  "_io_wrap_init": [
    "cls"
  ],
  "_io_register_serialization": [
    "cls"
  ],
  "_io_flatten_object": [
    "instance"
  ],
  "_io_unflatten_object": [
    "values",
    "metadata"
  ],
  "_io_path_elements_fn": [
    "x"
  ],
  "_artifact_transform_save": [
    "instance",
    "cfg",
    "output_path",
    "relative_dir"
  ],
  "_artifact_transform_load": [
    "cfg",
    "path"
  ],
  "drop_unexpected_params": [
    "config"
  ],
  "capture": [
    "to_capture"
  ],
  "SelfT": [],
  "IOProtocol": {
    "__io__": [
      "self"
    ]
  },
  "ReInitProtocol": {
    "reinit": [
      "self"
    ]
  },
  "reinit": [
    "configurable"
  ],
  "type_cache": [],
  "type_factory": [
    "original_type",
    "base_value"
  ],
  "_make_torch_importable": [
    "name"
  ],
  "_torch_type_importables": [],
  "_torch_initializers": [],
  "_import_aliases": [],
  "_make_torch_nn_importable": [
    "name"
  ],
  "_nn_type_importables": [],
  "is_torch_tensor": [
    "value"
  ],
  "convert_torch_tensor_to_cst": [
    "value",
    "convert_child"
  ],
  "enable": [],
  "TrainerContext": {
    "from_trainer": [
      "cls",
      "trainer"
    ],
    "construct_extra": [
      "cls",
      "trainer"
    ]
  },
  "ckpt_to_weights_subdir": [
    "filepath",
    "is_saving"
  ],
  "MegatronCheckpointIO": {
    "__init__": [
      "self",
      "save_ckpt_format",
      "load_directly_on_device",
      "async_save",
      "torch_dist_multiproc",
      "assume_constant_structure",
      "parallel_save",
      "parallel_save_within_dp",
      "parallel_load"
    ],
    "save_checkpoint": [
      "self",
      "checkpoint",
      "path",
      "storage_options"
    ],
    "load_checkpoint": [
      "self",
      "path",
      "sharded_state_dict",
      "map_location",
      "strict"
    ],
    "remove_checkpoint": [
      "self",
      "path"
    ],
    "_determine_dist_ckpt_save_strategy": [
      "self"
    ],
    "save_sharded_strategy": [
      "self"
    ],
    "_preprocess_checkpoint_load_path": [
      "path"
    ],
    "load_content_metadata": [
      "path",
      "preloaded_state_dict"
    ],
    "adjust_non_strict_load": [
      "self",
      "path",
      "sharded_state_dict"
    ]
  },
  "_fix_tensors_device": [
    "ckpt"
  ],
  "is_distributed_ckpt": [
    "path"
  ],
  "_local": [],
  "HFAutoArtifact": {
    "dump": [
      "self",
      "instance",
      "value",
      "absolute_dir",
      "relative_dir"
    ],
    "load": [
      "self",
      "path"
    ]
  },
  "from_pretrained_kwargs": [],
  "from_pretrained": [
    "auto_cls",
    "pretrained_model_name_or_path"
  ],
  "handle_hf_pretrained": [
    "value"
  ],
  "ValueT": [],
  "Artifact": {
    "__init__": [
      "self",
      "attr",
      "required",
      "skip"
    ],
    "dump": [
      "self",
      "instance",
      "value",
      "absolute_dir",
      "relative_dir"
    ],
    "load": [
      "self",
      "path"
    ],
    "__repr__": [
      "self"
    ]
  },
  "PickleArtifact": {
    "dump": [
      "self",
      "instance",
      "absolute_dir",
      "relative_dir"
    ],
    "load": [
      "self",
      "path"
    ],
    "file_path": [
      "self",
      "path"
    ]
  },
  "PathArtifact": {
    "dump": [
      "self",
      "instance",
      "value",
      "absolute_dir",
      "relative_dir"
    ],
    "load": [
      "self",
      "path"
    ]
  },
  "FileArtifact": {
    "dump": [
      "self",
      "instance",
      "value",
      "absolute_dir",
      "relative_dir"
    ],
    "load": [
      "self",
      "path"
    ]
  },
  "pathize": [
    "s"
  ],
  "copy_file": [
    "src",
    "path",
    "relative_dst"
  ],
  "DirArtifact": {
    "dump": [
      "self",
      "instance",
      "value",
      "absolute_dir",
      "relative_dir"
    ],
    "load": [
      "self",
      "path"
    ]
  },
  "DirOrStringArtifact": {
    "dump": [
      "self",
      "instance",
      "value",
      "absolute_dir",
      "relative_dir"
    ],
    "load": [
      "self",
      "path"
    ]
  },
  "_merge_callbacks": [
    "partial",
    "callbacks"
  ],
  "PreemptionPlugin": {
    "setup": [
      "self",
      "task",
      "executor"
    ]
  },
  "FaultTolerancePlugin": {
    "setup": [
      "self",
      "task",
      "executor"
    ]
  },
  "NsysPlugin": {
    "setup": [
      "self",
      "task",
      "executor"
    ]
  },
  "MemoryProfilePlugin": {
    "setup": [
      "self",
      "task",
      "executor"
    ]
  },
  "WandbPlugin": {
    "setup": [
      "self",
      "task",
      "executor"
    ]
  },
  "ConfigValidationPlugin": {
    "setup": [
      "self",
      "task",
      "executor"
    ]
  },
  "PerfEnvPlugin": {
    "get_vboost_srun_cmd": [
      "self",
      "nodes",
      "job_dir"
    ],
    "setup": [
      "self",
      "task",
      "executor"
    ]
  },
  "TritonCacheSetup": {},
  "ConfigManager": {
    "__init__": [
      "self",
      "server_base_path",
      "server_config_path"
    ],
    "_load_model_registry": [
      "self"
    ],
    "_load_server_config": [
      "self"
    ],
    "_initialize_config_parameters": [
      "self"
    ],
    "_configure_stt": [
      "self"
    ],
    "_configure_diarization": [
      "self"
    ],
    "_configure_turn_taking": [
      "self"
    ],
    "_configure_llm": [
      "self"
    ],
    "_configure_tts": [
      "self"
    ],
    "get_server_config": [
      "self"
    ],
    "get_model_registry": [
      "self"
    ],
    "get_vad_params": [
      "self"
    ],
    "get_stt_params": [
      "self"
    ],
    "get_diar_params": [
      "self"
    ]
  },
  "BaseInputTransport": {
    "_handle_vad": [
      "self",
      "audio_frame",
      "vad_state"
    ]
  },
  "TransportParams": {},
  "WebsocketServerParams": {},
  "WebsocketServerInputTransport": {
    "__init__": [
      "self",
      "transport",
      "host",
      "port",
      "params",
      "callbacks"
    ],
    "start": [
      "self",
      "frame"
    ],
    "stop": [
      "self",
      "frame"
    ],
    "cancel": [
      "self",
      "frame"
    ],
    "cleanup": [
      "self"
    ],
    "_server_task_handler": [
      "self"
    ],
    "_client_handler": [
      "self",
      "websocket",
      "path"
    ],
    "_monitor_websocket": [
      "self",
      "websocket",
      "session_timeout"
    ]
  },
  "WebsocketServerTransport": {
    "__init__": [
      "self",
      "params",
      "host",
      "port",
      "input_name",
      "output_name"
    ],
    "input": [
      "self"
    ],
    "output": [
      "self"
    ],
    "_on_client_connected": [
      "self",
      "websocket"
    ],
    "_on_client_disconnected": [
      "self",
      "websocket"
    ],
    "_on_session_timeout": [
      "self",
      "websocket"
    ],
    "_on_websocket_ready": [
      "self"
    ]
  },
  "DiarizationConfig": {},
  "NeMoLegacyDiarService": {
    "__init__": [
      "self",
      "cfg",
      "model",
      "frame_len_in_secs",
      "sample_rate",
      "left_offset",
      "right_offset",
      "use_amp",
      "compute_dtype"
    ],
    "build_diarizer": [
      "self"
    ],
    "print_diar_result": [
      "self",
      "diar_result"
    ],
    "diarize": [
      "self",
      "audio",
      "stream_id"
    ],
    "reset_state": [
      "self",
      "stream_id"
    ],
    "init_streaming_state": [
      "self",
      "batch_size"
    ],
    "stream_step": [
      "self",
      "processed_signal",
      "processed_signal_length",
      "streaming_state",
      "total_preds",
      "left_offset",
      "right_offset"
    ]
  },
  "NemoLegacyASRService": {
    "__init__": [
      "self",
      "model",
      "att_context_size",
      "device",
      "eou_string",
      "eob_string",
      "decoder_type",
      "chunk_size",
      "shift_size",
      "left_chunks",
      "sample_rate",
      "frame_len_in_secs",
      "use_amp",
      "chunk_size_in_secs"
    ],
    "_reset_cache": [
      "self"
    ],
    "_get_blank_hypothesis": [
      "self"
    ],
    "drop_extra_pre_encoded": [
      "self"
    ],
    "get_blank_id": [
      "self"
    ],
    "get_text_from_tokens": [
      "self",
      "tokens"
    ],
    "_load_model": [
      "self",
      "model"
    ],
    "_get_best_hypothesis": [
      "self",
      "encoded",
      "encoded_len",
      "partial_hypotheses"
    ],
    "_get_tokens_from_alignments": [
      "self",
      "alignments"
    ],
    "transcribe": [
      "self",
      "audio",
      "stream_id"
    ],
    "reset_state": [
      "self",
      "stream_id"
    ]
  },
  "BaseNemoTTSService": {
    "__init__": [
      "self"
    ],
    "_setup_model": [
      "self"
    ],
    "_generate_audio": [
      "self",
      "text"
    ],
    "can_generate_metrics": [
      "self"
    ],
    "start": [
      "self",
      "frame"
    ],
    "stop": [
      "self",
      "frame"
    ],
    "cancel": [
      "self",
      "frame"
    ],
    "_stop_tasks": [
      "self"
    ],
    "_tts_processor": [
      "self"
    ],
    "_get_response_queue": [
      "self",
      "request_id"
    ],
    "_processing_task_handler": [
      "self"
    ],
    "_handle_think_tokens": [
      "self",
      "text"
    ],
    "run_tts": [
      "self",
      "text"
    ],
    "_convert_to_bytes": [
      "self",
      "audio_data"
    ]
  },
  "NeMoFastPitchHiFiGANTTSService": {
    "__init__": [
      "self",
      "fastpitch_model",
      "hifigan_model",
      "device"
    ],
    "_setup_model": [
      "self"
    ],
    "_setup_fastpitch_model": [
      "self",
      "model_name"
    ],
    "_setup_hifigan_model": [
      "self",
      "model_name"
    ],
    "_generate_audio": [
      "self",
      "text"
    ]
  },
  "KokoroTTSService": {
    "__init__": [
      "self",
      "lang_code",
      "voice",
      "device",
      "sample_rate",
      "speed"
    ],
    "_setup_model": [
      "self"
    ],
    "_generate_audio": [
      "self",
      "text"
    ]
  },
  "LOG_MEL_ZERO": [],
  "AudioBufferer": {
    "__init__": [
      "self",
      "sample_rate",
      "buffer_size_in_secs"
    ],
    "reset": [
      "self"
    ],
    "update": [
      "self",
      "audio"
    ],
    "get_buffer": [
      "self"
    ],
    "is_buffer_empty": [
      "self"
    ]
  },
  "CacheFeatureBufferer": {
    "__init__": [
      "self",
      "sample_rate",
      "buffer_size_in_secs",
      "chunk_size_in_secs",
      "preprocessor_cfg",
      "device",
      "fill_value"
    ],
    "is_buffer_empty": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "_update_feature_buffer": [
      "self",
      "feat_chunk"
    ],
    "preprocess": [
      "self",
      "audio_signal"
    ],
    "update": [
      "self",
      "audio"
    ],
    "get_buffer": [
      "self"
    ],
    "get_feature_buffer": [
      "self"
    ]
  },
  "NeMoTurnTakingService": {
    "__init__": [
      "self",
      "backchannel_phrases",
      "eou_string",
      "eob_string",
      "language",
      "use_vad",
      "use_diar",
      "max_buffer_size",
      "bot_stop_delay"
    ],
    "_load_backchannel_phrases": [
      "self",
      "backchannel_phrases"
    ],
    "clean_text": [
      "self",
      "text"
    ],
    "is_backchannel": [
      "self",
      "text"
    ],
    "process_frame": [
      "self",
      "frame",
      "direction"
    ],
    "_handle_transcription": [
      "self",
      "frame",
      "direction"
    ],
    "_handle_completed_text": [
      "self",
      "completed_text",
      "direction",
      "is_final"
    ],
    "_handle_user_started_speaking": [
      "self",
      "frame",
      "direction"
    ],
    "_contains_only_speaker_tags": [
      "self",
      "text"
    ],
    "_handle_user_stopped_speaking": [
      "self",
      "frame",
      "direction"
    ],
    "_handle_user_interruption": [
      "self",
      "frame"
    ],
    "_handle_diar_result": [
      "self",
      "frame",
      "direction"
    ]
  },
  "NeMoDiarInputParams": {},
  "NemoDiarService": {
    "__init__": [
      "self"
    ],
    "_load_model": [
      "self"
    ],
    "can_generate_metrics": [
      "self"
    ],
    "start": [
      "self",
      "frame"
    ],
    "stop": [
      "self",
      "frame"
    ],
    "cancel": [
      "self",
      "frame"
    ],
    "_stop_tasks": [
      "self"
    ],
    "_diarization_processor": [
      "self"
    ],
    "_processing_task_handler": [
      "self"
    ],
    "_handle_diarization_result": [
      "self",
      "diar_result"
    ],
    "_response_task_handler": [
      "self"
    ],
    "run_stt": [
      "self",
      "audio"
    ],
    "_handle_transcription": [
      "self",
      "transcript",
      "is_final",
      "language"
    ],
    "set_language": [
      "self",
      "language"
    ],
    "set_model": [
      "self",
      "model"
    ],
    "process_frame": [
      "self",
      "frame",
      "direction"
    ],
    "reset": [
      "self"
    ],
    "_get_dominant_speaker_id": [
      "self",
      "spk_pred"
    ]
  },
  "DEFAULT_GENERATION_KWARGS": [],
  "LLMUtilsMixin": {
    "_maybe_add_user_message": [
      "self",
      "messages"
    ],
    "_maybe_merge_consecutive_turns": [
      "self",
      "messages"
    ]
  },
  "HuggingFaceLLMLocalService": {
    "__init__": [
      "self",
      "model",
      "device",
      "dtype",
      "thinking_budget",
      "generation_kwargs",
      "apply_chat_template_kwargs"
    ],
    "_apply_chat_template": [
      "self",
      "messages"
    ],
    "_get_prompt_from_messages": [
      "self",
      "messages"
    ],
    "generate_stream": [
      "self",
      "messages"
    ]
  },
  "HuggingFaceLLMService": {
    "__init__": [
      "self"
    ],
    "create_client": [
      "self",
      "api_key",
      "base_url"
    ],
    "_process_context": [
      "self",
      "context"
    ],
    "get_chat_completions": [
      "self",
      "params_from_context"
    ]
  },
  "VLLMService": {
    "__init__": [
      "self"
    ],
    "_start_vllm_server": [
      "self",
      "model",
      "vllm_server_params",
      "base_url"
    ],
    "_stop_vllm_server": [
      "self"
    ],
    "stop": [
      "self",
      "frame"
    ],
    "cancel": [
      "self",
      "frame"
    ],
    "get_chat_completions": [
      "self",
      "params_from_context"
    ],
    "_get_response_from_client": [
      "self",
      "messages",
      "params"
    ]
  },
  "get_llm_service_from_config": [
    "config"
  ],
  "NeMoSTTInputParams": {},
  "NemoSTTService": {
    "__init__": [
      "self"
    ],
    "_load_model": [
      "self"
    ],
    "can_generate_metrics": [
      "self"
    ],
    "start": [
      "self",
      "frame"
    ],
    "stop": [
      "self",
      "frame"
    ],
    "cancel": [
      "self",
      "frame"
    ],
    "run_stt": [
      "self",
      "audio"
    ],
    "_handle_transcription": [
      "self",
      "transcript",
      "is_final",
      "language"
    ],
    "set_language": [
      "self",
      "language"
    ],
    "set_model": [
      "self",
      "model"
    ],
    "process_frame": [
      "self",
      "frame",
      "direction"
    ]
  },
  "SimpleSegmentedTextAggregator": {
    "__init__": [
      "self",
      "punctuation_marks"
    ],
    "_find_segment_end": [
      "self",
      "text"
    ],
    "aggregate": [
      "self",
      "text"
    ]
  },
  "DiarResultFrame": {},
  "__version": [],
  "__author__": [],
  "ITN_TRUE": [],
  "ITN_FALSE": [],
  "TIMESTAMP_TRUE": [],
  "TIMESTAMP_FALSE": [],
  "DIARIZE_TRUE": [],
  "DIARIZE_FALSE": [],
  "Canary2PromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "TEMPLATE": [],
    "encode_turn": [
      "self",
      "prompt_template",
      "expected_slots",
      "slot_values"
    ]
  },
  "map_manifest_values_to_special_tokens": [
    "slot_values"
  ],
  "canary2": [
    "cut",
    "prompt"
  ],
  "MISTRAL_BOS": [],
  "MISTRAL_PROMPT_BEGIN": [],
  "MISTRAL_PROMPT_END": [],
  "MISTRAL_END_OF_TURN": [],
  "MISTRAL_NL": [],
  "MistralPromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "TEMPLATE": []
  },
  "GEMMA_BOS": [],
  "GEMMA_END_OF_TURN": [],
  "GEMMA_NL": [],
  "GemmaPromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "INSERT_BOS": [],
    "INSERT_EOS": [],
    "TEMPLATE": []
  },
  "gemma1": [
    "cut",
    "prompt"
  ],
  "BOOL_TRUE": [],
  "BOOL_FALSE": [],
  "PNC_TRUE": [],
  "PNC_FALSE": [],
  "TASK_TRANSCRIBE": [],
  "TASK_TRANSLATE": [],
  "CanaryPromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "TEMPLATE": [],
    "_validate_slot_values": [
      "self",
      "expected",
      "received"
    ],
    "encode_turn": [
      "self",
      "prompt_template",
      "expected_slots",
      "slot_values"
    ]
  },
  "canary": [
    "cut",
    "prompt"
  ],
  "SYSTEM_BOS": [],
  "TURN_BOS": [],
  "NemotronHPromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "INFERENCE_PREFIX": [],
    "TEMPLATE": []
  },
  "nemotron_h": [
    "cut",
    "prompt"
  ],
  "T5NMTPromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "TEMPLATE": [],
    "encode_turn": [
      "self",
      "prompt_template",
      "expected_slots",
      "slot_values"
    ]
  },
  "t5nmt": [
    "cut",
    "prompt"
  ],
  "t5nmt_src_tgt_text_example": [
    "example",
    "prompt"
  ],
  "QWEN_BOT": [],
  "QWEN_EOT": [],
  "QwenPromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "INFERENCE_PREFIX": [],
    "TEMPLATE": []
  },
  "ExamplePromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "TEMPLATE": []
  },
  "PREAMBLE_ROLE": [],
  "BOS_SLOT": [],
  "EOS_SLOT": [],
  "BaseModalityType": {
    "matches": [
      "value"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Text": {
    "matches": [
      "value"
    ]
  },
  "TextLiteral": {
    "__init__": [
      "self"
    ],
    "matches": [
      "self",
      "value"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Modality": {
    "Text": [],
    "TextLiteral": []
  },
  "PromptFormatter": {
    "PROMPT_LANGUAGE_SLOT": [],
    "NAME": [],
    "TEMPLATE": [],
    "OUTPUT_ROLE": [],
    "INFERENCE_PREFIX": [],
    "INSERT_BOS": [],
    "INSERT_EOS": [],
    "_REGISTERED_FORMATTERS": [],
    "__init__": [
      "self",
      "tokenizer",
      "defaults"
    ],
    "__init_subclass__": [
      "cls"
    ],
    "resolve": [
      "cls",
      "name"
    ],
    "get_roles": [
      "cls"
    ],
    "get_slots": [
      "cls",
      "role"
    ],
    "get_template": [
      "cls",
      "role"
    ],
    "get_default_dialog_slots": [
      "self"
    ],
    "encode_turn": [
      "self",
      "prompt_template",
      "expected_slots",
      "slot_values"
    ],
    "encode_dialog": [
      "self",
      "turns"
    ],
    "_apply_tokenizer": [
      "self",
      "text",
      "lang"
    ],
    "_validate_slot_values": [
      "self",
      "expected",
      "received"
    ],
    "_validate_defaults": [
      "self"
    ]
  },
  "_mangled": [
    "slot"
  ],
  "_unmangled": [
    "slot"
  ],
  "Phi2QAPromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "TEMPLATE": []
  },
  "Phi2ChatPromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "TEMPLATE": []
  },
  "Phi2CodePromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "TEMPLATE": []
  },
  "PlainPromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "TEMPLATE": []
  },
  "plain": [
    "cut",
    "prompt"
  ],
  "Llama2PromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "TEMPLATE": []
  },
  "llama2_src_tgt_text_example": [
    "example",
    "prompt"
  ],
  "llama2_sft_text_example": [
    "example",
    "prompt"
  ],
  "LLAMA3_BOS": [],
  "LLAMA3_HEADER_BEGIN": [],
  "LLAMA3_HEADER_END": [],
  "LLAMA3_END_OF_TURN": [],
  "LLAMA3_NL": [],
  "Llama3PromptFormatter": {
    "NAME": [],
    "OUTPUT_ROLE": [],
    "INFERENCE_PREFIX": [],
    "TEMPLATE": []
  },
  "_UINT8_MAX_F": [],
  "_SPATIAL_ALIGN": [],
  "_TEMPORAL_ALIGN": [],
  "load_jit_model": [
    "jit_filepath",
    "device"
  ],
  "save_jit_model": [
    "model",
    "jit_filepath"
  ],
  "get_filepaths": [
    "input_pattern"
  ],
  "get_output_filepath": [
    "filepath",
    "output_dir"
  ],
  "read_image": [
    "filepath"
  ],
  "read_video": [
    "filepath"
  ],
  "resize_image": [
    "image",
    "short_size"
  ],
  "resize_video": [
    "video",
    "short_size"
  ],
  "write_image": [
    "filepath",
    "image"
  ],
  "write_video": [
    "filepath",
    "video",
    "fps"
  ],
  "numpy2tensor": [
    "input_image",
    "dtype",
    "device",
    "range_min"
  ],
  "tensor2numpy": [
    "input_tensor",
    "range_min"
  ],
  "pad_image_batch": [
    "batch",
    "spatial_align"
  ],
  "pad_video_batch": [
    "batch",
    "temporal_align",
    "spatial_align"
  ],
  "unpad_video_batch": [
    "batch",
    "crop_region"
  ],
  "unpad_image_batch": [
    "batch",
    "crop_region"
  ],
  "get_pytorch_model": [
    "jit_filepath",
    "tokenizer_config"
  ],
  "load_pytorch_model": [
    "jit_filepath",
    "tokenizer_config",
    "model_type",
    "device"
  ],
  "get_tokenizer_config": [
    "tokenizer_type"
  ],
  "CausalVideoTokenizer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "from_pretrained": [
      "cls",
      "tokenizer_type",
      "load_encoder",
      "load_decoder",
      "load_full_model",
      "use_pytorch",
      "dtype"
    ],
    "autoencode": [
      "self",
      "input_tensor"
    ],
    "encode": [
      "self",
      "input_tensor"
    ],
    "decode": [
      "self",
      "input_latent"
    ],
    "forward": [
      "self",
      "video",
      "temporal_window"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "continuous_image": [],
  "discrete_image": [],
  "continuous_video": [],
  "discrete_video": [],
  "NetworkEval": [],
  "ContinuousImageTokenizer": {
    "__init__": [
      "self",
      "z_channels",
      "z_factor",
      "latent_channels"
    ],
    "encoder_jit": [
      "self"
    ],
    "decoder_jit": [
      "self"
    ],
    "last_decoder_layer": [
      "self"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "z"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "CausalContinuousVideoTokenizer": {
    "__init__": [
      "self",
      "z_channels",
      "z_factor",
      "latent_channels"
    ],
    "encoder_jit": [
      "self"
    ],
    "decoder_jit": [
      "self"
    ],
    "last_decoder_layer": [
      "self"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "z"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TokenizerConfigs": {
    "CI": [],
    "DI": [],
    "CV": [],
    "DV": []
  },
  "TokenizerModels": {
    "CI": [],
    "DI": [],
    "CausalCV": [],
    "CausalDV": []
  },
  "DiscreteImageTokenizer": {
    "__init__": [
      "self",
      "z_channels",
      "embedding_dim"
    ],
    "to": [
      "self"
    ],
    "encoder_jit": [
      "self"
    ],
    "decoder_jit": [
      "self"
    ],
    "last_decoder_layer": [
      "self"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "quant"
    ],
    "decode_code": [
      "self",
      "code_b"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "CausalDiscreteVideoTokenizer": {
    "__init__": [
      "self",
      "z_channels",
      "z_factor",
      "embedding_dim"
    ],
    "to": [
      "self"
    ],
    "encoder_jit": [
      "self"
    ],
    "decoder_jit": [
      "self"
    ],
    "last_decoder_layer": [
      "self"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "quant"
    ],
    "decode_code": [
      "self",
      "code_b"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "_LEGACY_NUM_GROUPS": [],
  "CausalConv3d": {
    "__init__": [
      "self",
      "chan_in",
      "chan_out",
      "kernel_size",
      "pad_mode"
    ],
    "_replication_pad": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CausalUpsample3d": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CausalDownsample3d": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CausalHybridUpsample3d": {
    "__init__": [
      "self",
      "in_channels",
      "spatial_up",
      "temporal_up"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CausalHybridDownsample3d": {
    "__init__": [
      "self",
      "in_channels",
      "spatial_down",
      "temporal_down"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CausalResnetBlock3d": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CausalResnetBlockFactorized3d": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CausalAttnBlock": {
    "__init__": [
      "self",
      "in_channels",
      "num_groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CausalTemporalAttnBlock": {
    "__init__": [
      "self",
      "in_channels",
      "num_groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EncoderBase": {
    "__init__": [
      "self",
      "in_channels",
      "channels",
      "channels_mult",
      "num_res_blocks",
      "attn_resolutions",
      "dropout",
      "resolution",
      "z_channels"
    ],
    "patcher3d": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DecoderBase": {
    "__init__": [
      "self",
      "out_channels",
      "channels",
      "channels_mult",
      "num_res_blocks",
      "attn_resolutions",
      "dropout",
      "resolution",
      "z_channels"
    ],
    "unpatcher3d": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "z"
    ]
  },
  "EncoderFactorized": {
    "__init__": [
      "self",
      "in_channels",
      "channels",
      "channels_mult",
      "num_res_blocks",
      "attn_resolutions",
      "dropout",
      "resolution",
      "z_channels",
      "spatial_compression",
      "temporal_compression"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DecoderFactorized": {
    "__init__": [
      "self",
      "out_channels",
      "channels",
      "channels_mult",
      "num_res_blocks",
      "attn_resolutions",
      "dropout",
      "resolution",
      "z_channels",
      "spatial_compression",
      "temporal_compression"
    ],
    "forward": [
      "self",
      "z"
    ]
  },
  "IdentityDistribution": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "parameters"
    ]
  },
  "GaussianDistribution": {
    "__init__": [
      "self",
      "min_logvar",
      "max_logvar"
    ],
    "sample": [
      "self",
      "mean",
      "logvar"
    ],
    "forward": [
      "self",
      "parameters"
    ]
  },
  "time2batch": [
    "x"
  ],
  "batch2time": [
    "x",
    "batch_size"
  ],
  "space2batch": [
    "x"
  ],
  "batch2space": [
    "x",
    "batch_size",
    "height"
  ],
  "cast_tuple": [
    "t",
    "length"
  ],
  "replication_pad": [
    "x"
  ],
  "divisible_by": [
    "num",
    "den"
  ],
  "is_odd": [
    "n"
  ],
  "nonlinearity": [
    "x"
  ],
  "Normalize": [
    "in_channels",
    "num_groups"
  ],
  "CausalNormalize": {
    "__init__": [
      "self",
      "in_channels",
      "num_groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "exists": [
    "v"
  ],
  "default": [],
  "pack_one": [
    "t",
    "pattern"
  ],
  "unpack_one": [
    "t",
    "ps",
    "pattern"
  ],
  "round_ste": [
    "z"
  ],
  "entropy": [
    "prob"
  ],
  "EncoderType": {
    "Default": []
  },
  "DecoderType": {
    "Default": []
  },
  "Encoder3DType": {
    "BASE": [],
    "FACTORIZED": []
  },
  "Decoder3DType": {
    "BASE": [],
    "FACTORIZED": []
  },
  "ContinuousFormulation": {
    "VAE": [],
    "AE": []
  },
  "DiscreteQuantizer": {
    "VQ": [],
    "LFQ": [],
    "FSQ": [],
    "RESFSQ": []
  },
  "Upsample": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Downsample": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResnetBlock": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AttnBlock": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Encoder": {
    "__init__": [
      "self",
      "in_channels",
      "channels",
      "channels_mult",
      "num_res_blocks",
      "attn_resolutions",
      "dropout",
      "resolution",
      "z_channels",
      "spatial_compression"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Decoder": {
    "__init__": [
      "self",
      "out_channels",
      "channels",
      "channels_mult",
      "num_res_blocks",
      "attn_resolutions",
      "dropout",
      "resolution",
      "z_channels",
      "spatial_compression"
    ],
    "forward": [
      "self",
      "z"
    ]
  },
  "_WAVELETS": [],
  "_PERSISTENT": [],
  "Patcher": {
    "__init__": [
      "self",
      "patch_size",
      "patch_method"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_dwt": [
      "self",
      "x",
      "mode",
      "rescale"
    ],
    "_haar": [
      "self",
      "x"
    ],
    "_arrange": [
      "self",
      "x"
    ]
  },
  "Patcher3D": {
    "__init__": [
      "self",
      "patch_size",
      "patch_method"
    ],
    "_dwt": [
      "self",
      "x",
      "wavelet",
      "mode",
      "rescale"
    ],
    "_haar": [
      "self",
      "x"
    ],
    "_arrange": [
      "self",
      "x"
    ]
  },
  "UnPatcher": {
    "__init__": [
      "self",
      "patch_size",
      "patch_method"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_idwt": [
      "self",
      "x",
      "wavelet",
      "mode",
      "rescale"
    ],
    "_ihaar": [
      "self",
      "x"
    ],
    "_iarrange": [
      "self",
      "x"
    ]
  },
  "UnPatcher3D": {
    "__init__": [
      "self",
      "patch_size",
      "patch_method"
    ],
    "_idwt": [
      "self",
      "x",
      "wavelet",
      "mode",
      "rescale"
    ],
    "_ihaar": [
      "self",
      "x"
    ],
    "_iarrange": [
      "self",
      "x"
    ]
  },
  "ResidualFSQuantizer": {
    "__init__": [
      "self",
      "levels",
      "num_quantizers"
    ],
    "forward": [
      "self",
      "x"
    ],
    "indices_to_codes": [
      "self",
      "indices_stack"
    ]
  },
  "FSQuantizer": {
    "__init__": [
      "self",
      "levels",
      "dim",
      "num_codebooks",
      "keep_num_codebooks_dim",
      "scale"
    ],
    "bound": [
      "self",
      "z",
      "eps"
    ],
    "quantize": [
      "self",
      "z"
    ],
    "_scale_and_shift": [
      "self",
      "zhat_normalized"
    ],
    "_scale_and_shift_inverse": [
      "self",
      "zhat"
    ],
    "codes_to_indices": [
      "self",
      "zhat"
    ],
    "indices_to_codes": [
      "self",
      "indices",
      "project_out"
    ],
    "forward": [
      "self",
      "z"
    ]
  },
  "VectorQuantizer": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "beta",
      "remap",
      "unknown_index",
      "sane_index_shape",
      "legacy",
      "use_norm"
    ],
    "remap_to_used": [
      "self",
      "inds"
    ],
    "unmap_to_all": [
      "self",
      "inds"
    ],
    "forward": [
      "self",
      "z",
      "temp",
      "rescale_logits",
      "return_logits"
    ],
    "get_codebook_entry": [
      "self",
      "indices",
      "shape"
    ]
  },
  "LFQuantizer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "z",
      "temp"
    ]
  },
  "InvQuantizerJit": {
    "__init__": [
      "self",
      "quantizer"
    ],
    "forward": [
      "self",
      "indices"
    ]
  },
  "CrossEntropyLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "logits_ndim",
      "weight",
      "reduction",
      "ignore_index"
    ],
    "forward": [
      "self",
      "logits",
      "labels",
      "loss_mask"
    ]
  },
  "NLLLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "log_probs_ndim",
      "weight",
      "reduction",
      "ignore_index"
    ],
    "forward": [
      "self",
      "log_probs",
      "labels",
      "loss_mask"
    ]
  },
  "MultiSimilarityLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "scale_pos",
      "scale_neg",
      "offset",
      "margin"
    ],
    "forward": [
      "self",
      "logits",
      "labels"
    ]
  },
  "BCEWithLogitsLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "logits_ndim",
      "weight",
      "reduction",
      "pos_weight"
    ],
    "forward": [
      "self",
      "logits",
      "labels",
      "loss_mask"
    ]
  },
  "SmoothedCrossEntropyLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "pad_id",
      "label_smoothing",
      "predict_last_k",
      "eps",
      "per_token_reduction"
    ],
    "forward": [
      "self",
      "log_probs",
      "labels",
      "output_mask"
    ]
  },
  "SmoothedNLLLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "reduction",
      "label_smoothing",
      "eps"
    ],
    "forward": [
      "self",
      "log_probs",
      "labels",
      "output_mask",
      "lengths"
    ]
  },
  "SpanningLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "logits",
      "start_positions",
      "end_positions"
    ]
  },
  "AggregatorLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "num_inputs",
      "weights"
    ],
    "forward": [
      "self"
    ]
  },
  "MSELoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "reduction"
    ],
    "forward": [
      "self",
      "preds",
      "labels"
    ]
  },
  "GlobalAverageLossMetric": {
    "full_state_update": [],
    "__init__": [
      "self",
      "dist_sync_on_step",
      "process_group",
      "take_avg_loss"
    ],
    "update": [
      "self",
      "loss",
      "num_measurements"
    ],
    "compute": [
      "self"
    ]
  },
  "MetricStringToTorchMetric": [],
  "TextMetricsSet": [],
  "ClassificationMetricsSet": [],
  "punctuation_error_rate": [
    "references",
    "hypotheses",
    "punctuation_marks",
    "punctuation_mask"
  ],
  "OccurancePunctuationErrorRate": {
    "__init__": [
      "self",
      "punctuation_marks",
      "punctuation_mask"
    ],
    "compute_rates": [
      "self",
      "operation_amounts",
      "substitution_amounts"
    ],
    "compute_operation_amounts": [
      "self",
      "reference",
      "hypothesis"
    ],
    "compute": [
      "self",
      "reference",
      "hypothesis"
    ]
  },
  "DatasetPunctuationErrorRate": {
    "__init__": [
      "self",
      "references",
      "hypotheses",
      "punctuation_marks",
      "punctuation_mask"
    ],
    "compute": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "print": [
      "self"
    ]
  },
  "TopKClassificationAccuracy": {
    "full_state_update": [],
    "__init__": [
      "self",
      "top_k",
      "dist_sync_on_step"
    ],
    "top_k_predicted_labels": [
      "self",
      "logits"
    ],
    "update": [
      "self",
      "logits",
      "labels"
    ],
    "compute": [
      "self"
    ],
    "top_k": [
      "self",
      "value"
    ]
  },
  "compute_topk_accuracy": [
    "correct_counts_k",
    "total_counts_k"
  ],
  "ExactStringPerCategoryMatchMetric": {
    "__init__": [
      "self",
      "categories",
      "dist_sync_on_step"
    ],
    "update": [
      "self",
      "pred",
      "target",
      "category"
    ],
    "compute": [
      "self"
    ]
  },
  "ExactStringMatchMetric": {
    "__init__": [
      "self",
      "dist_sync_on_step"
    ],
    "update": [
      "self",
      "pred",
      "target"
    ],
    "compute": [
      "self"
    ]
  },
  "TokenF1Score": {
    "__init__": [
      "self",
      "dist_sync_on_step"
    ],
    "update": [
      "self",
      "pred",
      "target"
    ],
    "compute": [
      "self"
    ],
    "f1_score": [
      "self",
      "prediction",
      "ground_truth"
    ],
    "normalize": [
      "self",
      "s"
    ]
  },
  "Perplexity": {
    "full_state_update": [],
    "__init__": [
      "self",
      "dist_sync_on_step",
      "process_group",
      "validate_args"
    ],
    "update": [
      "self",
      "probs",
      "logits"
    ],
    "compute": [
      "self"
    ]
  },
  "megatron_tokenizer_model_map": [],
  "TokenizerConfig": {},
  "EnJaProcessor": {
    "__init__": [
      "self",
      "lang_id"
    ],
    "detokenize": [
      "self",
      "tokens"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "normalize": [
      "self",
      "text"
    ]
  },
  "JaMecabProcessor": {
    "__init__": [
      "self"
    ],
    "detokenize": [
      "self",
      "text"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "normalize": [
      "self",
      "text"
    ]
  },
  "CANARY_BOS": [],
  "CANARY_EOS": [],
  "CANARY_PAD": [],
  "CANARY_NOSPEECH": [],
  "CANARY_PNC": [],
  "CANARY_NOPNC": [],
  "CANARY2_BOCTX": [],
  "DEFAULT_TOKENS": [],
  "CANARY_SPECIAL_TOKENIZER": [],
  "CanaryTokenizer": {
    "__init__": [
      "self",
      "tokenizers"
    ],
    "eos_id": [
      "self"
    ],
    "bos_id": [
      "self"
    ],
    "nospeech_id": [
      "self"
    ],
    "pad_id": [
      "self"
    ],
    "_text_with_timestamps_to_ids": [
      "self",
      "text_without_timestamps",
      "time_text",
      "lang_id"
    ],
    "_text_to_ids_maybe_with_timestamps": [
      "self",
      "text_no_eos",
      "lang_id"
    ],
    "text_to_ids": [
      "self",
      "text",
      "lang_id"
    ],
    "_tokenize_special_prompt": [
      "self",
      "text"
    ],
    "spl_token_to_id": [
      "self",
      "token"
    ],
    "build_special_tokenizer": [
      "tokens",
      "model_dir",
      "force_rebuild"
    ]
  },
  "CanaryBPETokenizer": {
    "eos_id": [
      "self"
    ],
    "bos_id": [
      "self"
    ],
    "nospeech_id": [
      "self"
    ],
    "pad_id": [
      "self"
    ]
  },
  "_map_canary1_to_canary2_lang": [
    "lang",
    "available_langs"
  ],
  "MosesProcessor": {
    "__init__": [
      "self",
      "lang_id"
    ],
    "detokenize": [
      "self",
      "tokens"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "normalize": [
      "self",
      "text"
    ]
  },
  "IndicProcessor": {
    "__init__": [
      "self",
      "lang_id"
    ],
    "detokenize": [
      "self",
      "tokens"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "normalize": [
      "self",
      "text"
    ]
  },
  "ByteLevelProcessor": {
    "detokenize": [
      "self",
      "tokens"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "normalize": [
      "self",
      "text"
    ]
  },
  "ByteLevelTokenizer": {
    "__init__": [
      "self",
      "special_tokens",
      "vocab_size",
      "_eos_id",
      "_pad_id",
      "_bos_id"
    ],
    "text_to_tokens": [
      "self",
      "text"
    ],
    "tokens_to_text": [
      "self",
      "tokens"
    ],
    "text_to_ids": [
      "self",
      "text"
    ],
    "ids_to_text": [
      "self",
      "ids"
    ],
    "tokens_to_ids": [
      "self",
      "tokens"
    ],
    "ids_to_tokens": [
      "self",
      "ids"
    ],
    "token_to_id": [
      "self",
      "token"
    ],
    "id_to_token": [
      "self",
      "id"
    ],
    "pad_id": [
      "self"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "unk_id": [
      "self"
    ]
  },
  "torch_home": [],
  "MEGATRON_CACHE": [],
  "CONFIGS": [],
  "MEGATRON_CONFIG_MAP": [],
  "list_available_models": [],
  "get_megatron_lm_models_list": [],
  "_check_megatron_name": [
    "pretrained_model_name"
  ],
  "get_megatron_vocab_file": [
    "pretrained_model_name"
  ],
  "get_megatron_merges_file": [
    "pretrained_model_name"
  ],
  "_download": [
    "path",
    "url"
  ],
  "get_megatron_tokenizer": [
    "pretrained_model_name"
  ],
  "NUMBER_OF_CHARACTERS_READ_BUFFER_SIZE": [],
  "SpecialTokenString": {
    "MASK": [],
    "BOS": [],
    "EOS": [],
    "PAD": [],
    "SEP": [],
    "CLS": [],
    "UNK": [],
    "has_value": [
      "cls",
      "value"
    ]
  },
  "SpecialTokenStringType": [],
  "CharTokenizer": {
    "__init__": [
      "self",
      "vocab_file",
      "mask_token",
      "bos_token",
      "eos_token",
      "pad_token",
      "sep_token",
      "cls_token",
      "unk_token",
      "special_token_to_prepend",
      "special_token_to_append",
      "special_tokens_to_remove_while_decoding"
    ],
    "check_special_tokens_dict_from_file": [
      "cls",
      "special_tokens_dict",
      "vocab_file"
    ],
    "check_special_tokens_dict_for_duplicate_values": [
      "special_tokens_dict",
      "err_msg_prefix"
    ],
    "update_special_tokens_dict": [
      "cls",
      "init_special_tokens_dict",
      "mask_token",
      "bos_token",
      "eos_token",
      "pad_token",
      "sep_token",
      "cls_token",
      "unk_token"
    ],
    "check_token_from_file": [
      "token",
      "vocab_file",
      "line_i"
    ],
    "check_special_token_name": [
      "parameter_name",
      "value",
      "special_tokens_dict"
    ],
    "check_special_tokens_to_remove_while_decoding": [
      "special_tokens_to_remove_while_decoding",
      "special_tokens_dict"
    ],
    "text_to_tokens": [
      "self",
      "text"
    ],
    "tokens_to_text": [
      "self",
      "tokens"
    ],
    "text_to_ids": [
      "self",
      "text"
    ],
    "ids_to_text": [
      "self",
      "ids"
    ],
    "tokens_to_ids": [
      "self",
      "tokens"
    ],
    "token_to_id": [
      "self",
      "token"
    ],
    "ids_to_tokens": [
      "self",
      "ids"
    ],
    "check_special_token_id_getting": [
      "special_token",
      "id_name"
    ],
    "pad_id": [
      "self"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "unk_id": [
      "self"
    ],
    "mask_id": [
      "self"
    ],
    "sep_id": [
      "self"
    ],
    "cls_id": [
      "self"
    ],
    "create_special_tokens_dict": [
      "mask_token",
      "bos_token",
      "eos_token",
      "pad_token",
      "sep_token",
      "cls_token",
      "unk_token"
    ],
    "check_characters_to_exclude_from_vocabulary": [
      "characters_to_exclude_from_vocabulary"
    ],
    "check_text_and_text_file_name": [
      "text",
      "text_file_name"
    ],
    "build_vocab": [
      "cls",
      "save_path",
      "text",
      "text_file_name",
      "characters_to_exclude",
      "vocab_size",
      "mask_token",
      "bos_token",
      "eos_token",
      "pad_token",
      "sep_token",
      "cls_token",
      "unk_token"
    ]
  },
  "DEFAULT_MASK_TOKEN": [],
  "DEFAULT_BOS_TOKEN": [],
  "DEFAULT_EOS_TOKEN": [],
  "DEFAULT_PAD_TOKEN": [],
  "DEFAULT_SEP_TOKEN": [],
  "DEFAULT_UNK_TOKEN": [],
  "RegExTokenizer": {
    "__init__": [
      "self",
      "regex",
      "mask_token",
      "bos_token",
      "eos_token",
      "pad_token",
      "sep_token",
      "unk_token"
    ],
    "_update_cache": [
      "self"
    ],
    "_compile_regex": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "text_to_tokens": [
      "self",
      "text"
    ],
    "tokens_to_text": [
      "self",
      "tokens"
    ],
    "token_to_ids": [
      "self",
      "tokens"
    ],
    "tokens_to_ids": [
      "self",
      "token_data"
    ],
    "ids_to_tokens": [
      "self",
      "ids_list"
    ],
    "text_to_ids": [
      "self",
      "text"
    ],
    "ids_to_text": [
      "self",
      "ids"
    ],
    "pad_id": [
      "self"
    ],
    "unk_id": [
      "self"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "mask_id": [
      "self"
    ],
    "sep_id": [
      "self"
    ],
    "_get_regex_vocab_files": [
      "self",
      "regex_file",
      "vocab_file"
    ],
    "save_tokenizer": [
      "self",
      "regex_file",
      "vocab_file"
    ],
    "load_tokenizer": [
      "self",
      "regex_file",
      "vocab_file"
    ],
    "build_vocab_from_csv": [
      "self",
      "data_csv_file",
      "col"
    ],
    "build_vocab_from_text": [
      "self",
      "data_text_file"
    ]
  },
  "NullTokenizer": {
    "__init__": [
      "self",
      "vocab_size"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "detokenize": [
      "self",
      "ids"
    ],
    "offsets": [
      "self",
      "ids",
      "text"
    ],
    "vocab_size": [
      "self"
    ],
    "vocab": [
      "self"
    ],
    "inv_vocab": [
      "self"
    ],
    "cls": [
      "self"
    ],
    "sep": [
      "self"
    ],
    "mask": [
      "self"
    ],
    "eod": [
      "self"
    ],
    "additional_special_tokens_ids": [
      "self"
    ]
  },
  "WordTokenizer": {
    "__init__": [
      "self",
      "vocab_file",
      "mask_token",
      "bos_token",
      "eos_token",
      "pad_token",
      "sep_token",
      "cls_token",
      "unk_token"
    ],
    "text_to_tokens": [
      "self",
      "text"
    ],
    "ids_to_text": [
      "self",
      "ids"
    ]
  },
  "get_unicode_categories": [],
  "NUMERICS": [],
  "tokenize_en": [
    "line"
  ],
  "ChineseProcessor": {
    "__init__": [
      "self"
    ],
    "normalize": [
      "self",
      "text"
    ],
    "detokenize": [
      "self",
      "text"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "TokenizerSpec": {
    "text_to_tokens": [
      "self",
      "text"
    ],
    "tokens_to_text": [
      "self",
      "tokens"
    ],
    "tokens_to_ids": [
      "self",
      "tokens"
    ],
    "ids_to_tokens": [
      "self",
      "ids"
    ],
    "text_to_ids": [
      "self",
      "text"
    ],
    "ids_to_text": [
      "self",
      "ids"
    ],
    "add_special_tokens": [
      "self",
      "special_tokens"
    ],
    "apply_chat_template": [
      "self"
    ],
    "name": [
      "self"
    ],
    "unique_identifiers": [
      "self"
    ],
    "cls": [
      "self"
    ],
    "sep": [
      "self"
    ],
    "pad": [
      "self"
    ],
    "eod": [
      "self"
    ],
    "bos": [
      "self"
    ],
    "eos": [
      "self"
    ],
    "mask": [
      "self"
    ]
  },
  "END_OF_TEXT": [],
  "NEW_LINE": [],
  "find_index_of": [
    "list_input",
    "item"
  ],
  "TabularTokenizer": {
    "__init__": [
      "self",
      "coder",
      "special_tokens",
      "delimiter"
    ],
    "__len__": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "text_to_ids": [
      "self",
      "text"
    ],
    "ids_to_text": [
      "self",
      "token_ids"
    ],
    "eod": [
      "self"
    ],
    "eor": [
      "self"
    ],
    "add_special_tokens": [
      "self",
      "special_tokens"
    ],
    "text_to_tokens": [
      "self",
      "text"
    ],
    "tokens_to_ids": [
      "self",
      "tokens"
    ],
    "ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "token_ids"
    ],
    "tokens_to_text": [
      "self",
      "tokens"
    ]
  },
  "Code": {
    "compute_code": [
      "self",
      "data_series"
    ],
    "__init__": [
      "self",
      "col_name",
      "code_len",
      "start_id",
      "fillall",
      "hasnan"
    ],
    "encode": [
      "self",
      "item"
    ],
    "decode": [
      "self",
      "ids"
    ],
    "code_range": [
      "self"
    ]
  },
  "IntCode": {
    "__init__": [
      "self",
      "col_name",
      "code_len",
      "start_id",
      "fillall",
      "base",
      "hasnan"
    ],
    "compute_code": [
      "self",
      "data_series"
    ],
    "array_convert_to_int": [
      "self",
      "val"
    ],
    "convert_to_int": [
      "self",
      "val"
    ],
    "reverse_convert_to_int": [
      "self",
      "val"
    ],
    "code_range": [
      "self"
    ],
    "encode": [
      "self",
      "item"
    ],
    "decode": [
      "self",
      "ids"
    ]
  },
  "FloatCode": {
    "__init__": [
      "self",
      "col_name",
      "code_len",
      "start_id",
      "fillall",
      "base",
      "hasnan",
      "transform"
    ],
    "convert_to_int": [
      "self",
      "val"
    ],
    "array_convert_to_int": [
      "self",
      "val"
    ],
    "reverse_convert_to_int": [
      "self",
      "val"
    ],
    "decode": [
      "self",
      "ids"
    ]
  },
  "CategoryCode": {
    "__init__": [
      "self",
      "col_name",
      "start_id"
    ],
    "compute_code": [
      "self",
      "data_series"
    ],
    "encode": [
      "self",
      "item"
    ],
    "decode": [
      "self",
      "ids"
    ]
  },
  "column_map": [],
  "ColumnCodes": {
    "__init__": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "register": [
      "self",
      "name",
      "ccode"
    ],
    "encode": [
      "self",
      "col",
      "item"
    ],
    "decode": [
      "self",
      "col",
      "ids"
    ],
    "get_range": [
      "self",
      "column_id"
    ],
    "get_column_codes": [
      "cls",
      "column_configs",
      "example_arrays"
    ]
  },
  "AggregateTokenizer": {
    "__init__": [
      "self",
      "tokenizers"
    ],
    "_calculate_offsets": [
      "self"
    ],
    "text_to_tokens": [
      "self",
      "text",
      "lang_id"
    ],
    "text_to_ids": [
      "self",
      "text",
      "lang_id"
    ],
    "tokens_to_text": [
      "self",
      "tokens",
      "lang_id"
    ],
    "ids_to_text": [
      "self",
      "ids"
    ],
    "token_to_id": [
      "self",
      "token",
      "lang_id"
    ],
    "ids_to_tokens": [
      "self",
      "ids"
    ],
    "ids_to_text_and_langs": [
      "self",
      "ids"
    ],
    "ids_to_words_and_langs": [
      "self",
      "ids"
    ],
    "ids_to_lang": [
      "self",
      "ids"
    ],
    "tokens_to_ids": [
      "self",
      "tokens",
      "langs"
    ],
    "get_bos": [
      "self",
      "lang_id"
    ],
    "get_eos": [
      "self",
      "lang_id"
    ],
    "vocab": [
      "self"
    ],
    "langs": [
      "self"
    ]
  },
  "TokenizerWrapper": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "text",
      "lang"
    ],
    "_call_agg_tokenizer": [
      "self",
      "text",
      "lang"
    ],
    "_call_tokenizer": [
      "self",
      "text",
      "lang"
    ],
    "_call_parser": [
      "self",
      "text",
      "lang"
    ]
  },
  "create_spt_model": [
    "data_file",
    "vocab_size",
    "sample_size",
    "do_lower_case",
    "tokenizer_type",
    "output_dir",
    "character_coverage",
    "train_extremely_large_corpus",
    "max_sentencepiece_length",
    "bos",
    "eos",
    "pad",
    "control_symbols",
    "user_defined_symbols",
    "byte_fallback",
    "split_digits",
    "split_by_whitespace",
    "split_by_unicode_script",
    "remove_extra_whitespaces"
  ],
  "TEMPLATE_VAR_VALIDATION_PAT": [],
  "TEMPLATE_VAR_SEARCH_PAT": [],
  "ChatTemplateMixin": {
    "apply_chat_template": [
      "self",
      "messages"
    ],
    "has_chat_template": [
      "self"
    ]
  },
  "is_template_var": [
    "s"
  ],
  "extract_template_parts": [
    "template",
    "skip_empty"
  ],
  "strip_template_wrap": [
    "s"
  ],
  "render_chat_turn": [
    "message",
    "template"
  ],
  "encode_string_with_special_token": [
    "tokenizer",
    "inputs",
    "special_token"
  ],
  "tokenize_with_chat_template": [
    "tokenizer",
    "messages",
    "template"
  ],
  "extract_turns": [
    "messages",
    "axis"
  ],
  "explode_chat_template_input": [
    "messages"
  ],
  "is_chat_input": [
    "messages"
  ],
  "YouTokenToMeTokenizer": {
    "__init__": [
      "self",
      "model_path",
      "bpe_dropout",
      "legacy",
      "r2l"
    ],
    "text_to_tokens": [
      "self",
      "text"
    ],
    "tokens_to_text": [
      "self",
      "tokens"
    ],
    "text_to_ids": [
      "self",
      "text"
    ],
    "ids_to_text": [
      "self",
      "ids"
    ],
    "tokens_to_ids": [
      "self",
      "tokens"
    ],
    "ids_to_tokens": [
      "self",
      "ids"
    ],
    "pad_id": [
      "self"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "unk_id": [
      "self"
    ]
  },
  "_synoglyphs": [],
  "SYNOGLYPH2ASCII": [],
  "LATIN_ALPHABET_BASIC": [],
  "ACCENTED_CHARS": [],
  "LATIN_CHARS_ALL": [],
  "_WORDS_RE_EN": [],
  "_WORDS_RE_ANY_LOCALE": [],
  "english_text_preprocessing": [
    "text",
    "lower"
  ],
  "any_locale_text_preprocessing": [
    "text"
  ],
  "normalize_unicode_text": [
    "text"
  ],
  "_word_tokenize": [
    "words",
    "is_lower"
  ],
  "english_word_tokenize": [
    "text"
  ],
  "any_locale_word_tokenize": [
    "text"
  ],
  "spanish_text_preprocessing": [
    "text"
  ],
  "italian_text_preprocessing": [
    "text"
  ],
  "chinese_text_preprocessing": [
    "text"
  ],
  "french_text_preprocessing": [
    "text"
  ],
  "vietnamese_text_preprocessing": [
    "text"
  ],
  "japanese_text_preprocessing": [
    "text"
  ],
  "TextToSpeechTokenizer": {
    "__init__": [
      "self",
      "phoneme_dict",
      "heteronyms"
    ],
    "text_to_ids": [
      "self",
      "text"
    ],
    "text_to_tokens": [
      "self",
      "text"
    ],
    "tokens_to_text": [
      "self",
      "tokens"
    ],
    "tokens_to_ids": [
      "self",
      "tokens"
    ],
    "ids_to_tokens": [
      "self",
      "ids"
    ],
    "ids_to_text": [
      "self",
      "ids"
    ],
    "pad_id": [
      "self"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ]
  },
  "SUPPORTED_LOCALES": [],
  "DEFAULT_PUNCTUATION": [],
  "VITS_PUNCTUATION": [],
  "GRAPHEME_CHARACTER_SETS": [],
  "IPA_CHARACTER_SETS": [],
  "GRAPHEME_CHARACTER_CASES": [],
  "validate_locale": [
    "locale"
  ],
  "get_grapheme_character_set": [
    "locale",
    "case"
  ],
  "get_ipa_character_set": [
    "locale"
  ],
  "get_ipa_punctuation_list": [
    "locale"
  ],
  "BaseTokenizer": {
    "__init__": [
      "self",
      "tokens"
    ],
    "__call__": [
      "self",
      "text"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "tokens"
    ]
  },
  "BaseCharsTokenizer": {
    "PUNCT_LIST": [],
    "__init__": [
      "self",
      "chars",
      "punct",
      "apostrophe",
      "add_blank_at",
      "pad_with_space",
      "non_default_punct_list",
      "text_preprocessing_func"
    ],
    "encode": [
      "self",
      "text"
    ]
  },
  "EnglishCharsTokenizer": {
    "__init__": [
      "self",
      "punct",
      "apostrophe",
      "add_blank_at",
      "pad_with_space",
      "non_default_punct_list",
      "text_preprocessing_func"
    ]
  },
  "VietnameseCharsTokenizer": {
    "_LOCALE": [],
    "_CHARSET_STR": [],
    "__init__": [
      "self",
      "chars",
      "punct",
      "apostrophe",
      "add_blank_at",
      "pad_with_space",
      "non_default_punct_list",
      "text_preprocessing_func"
    ]
  },
  "GermanCharsTokenizer": {
    "_LOCALE": [],
    "_PUNCT_LIST": [],
    "_CHARSET_STR": [],
    "__init__": [
      "self",
      "chars",
      "punct",
      "apostrophe",
      "add_blank_at",
      "pad_with_space",
      "non_default_punct_list",
      "text_preprocessing_func"
    ]
  },
  "SpanishCharsTokenizer": {
    "PUNCT_LIST": [],
    "__init__": [
      "self",
      "punct",
      "apostrophe",
      "add_blank_at",
      "pad_with_space",
      "non_default_punct_list"
    ]
  },
  "FrenchCharsTokenizer": {
    "PUNCT_LIST": [],
    "__init__": [
      "self",
      "punct",
      "apostrophe",
      "add_blank_at",
      "pad_with_space",
      "non_default_punct_list"
    ]
  },
  "ItalianCharsTokenizer": {
    "PUNCT_LIST": [],
    "__init__": [
      "self",
      "punct",
      "apostrophe",
      "add_blank_at",
      "pad_with_space",
      "non_default_punct_list"
    ]
  },
  "GermanPhonemesTokenizer": {
    "PUNCT_LIST": [],
    "__init__": [
      "self",
      "punct",
      "apostrophe",
      "add_blank_at",
      "pad_with_space",
      "non_default_punct_list",
      "text_preprocessing_func"
    ],
    "encode": [
      "self",
      "text"
    ]
  },
  "ItalianPhonemesTokenizer": {
    "PUNCT_LIST": [],
    "__init__": [
      "self",
      "punct",
      "apostrophe",
      "add_blank_at",
      "pad_with_space",
      "non_default_punct_list",
      "text_preprocessing_func"
    ],
    "encode": [
      "self",
      "text"
    ]
  },
  "EnglishPhonemesTokenizer": {
    "PUNCT_LIST": [],
    "VOWELS": [],
    "CONSONANTS": [],
    "__init__": [
      "self",
      "g2p",
      "punct",
      "non_default_punct_list",
      "stresses",
      "chars"
    ],
    "encode": [
      "self",
      "text"
    ],
    "encode_from_g2p": [
      "self",
      "g2p_text",
      "raw_text"
    ],
    "set_phone_prob": [
      "self",
      "prob"
    ]
  },
  "IPATokenizer": {
    "__init__": [
      "self",
      "g2p",
      "locale",
      "punct",
      "non_default_punct_list",
      "fixed_vocab"
    ],
    "encode": [
      "self",
      "text"
    ],
    "encode_from_g2p": [
      "self",
      "g2p_text",
      "raw_text"
    ],
    "set_phone_prob": [
      "self",
      "prob"
    ]
  },
  "ChinesePhonemesTokenizer": {
    "PUNCT_LIST": [],
    "ZH_PUNCT_LIST": [],
    "__init__": [
      "self",
      "g2p",
      "punct",
      "non_default_punct_list"
    ],
    "encode": [
      "self",
      "text"
    ],
    "encode_from_g2p": [
      "self",
      "g2p_text",
      "raw_text"
    ]
  },
  "JapanesePhonemeTokenizer": {
    "JA_PUNCT_LIST": [],
    "__init__": [
      "self",
      "g2p",
      "punct",
      "non_default_punct_list"
    ],
    "encode": [
      "self",
      "text"
    ],
    "encode_from_g2p": [
      "self",
      "g2p_text",
      "raw_text"
    ]
  },
  "AggregatedTTSTokenizer": {
    "__init__": [
      "self",
      "tokenizers",
      "tokenizer_names"
    ],
    "encode": [
      "self",
      "text",
      "tokenizer_name"
    ],
    "decode": [
      "self",
      "tokens",
      "tokenizer_name"
    ]
  },
  "AutoTokenizer": {
    "__init__": [
      "self",
      "pretrained_model_name",
      "vocab_file",
      "merges_file",
      "mask_token",
      "bos_token",
      "eos_token",
      "pad_token",
      "sep_token",
      "cls_token",
      "unk_token",
      "additional_special_tokens",
      "use_fast",
      "trust_remote_code",
      "include_special_tokens",
      "chat_template"
    ],
    "_initialize_tokenizer": [
      "self",
      "pretrained_model_name",
      "vocab_file",
      "merges_file",
      "use_fast",
      "trust_remote_code",
      "chat_template"
    ],
    "vocab_size": [
      "self"
    ],
    "add_special_tokens": [
      "self",
      "special_tokens_dict"
    ],
    "additional_special_tokens_ids": [
      "self"
    ],
    "text_to_tokens": [
      "self",
      "text"
    ],
    "tokens_to_text": [
      "self",
      "tokens"
    ],
    "token_to_id": [
      "self",
      "token"
    ],
    "tokens_to_ids": [
      "self",
      "tokens"
    ],
    "ids_to_tokens": [
      "self",
      "ids"
    ],
    "text_to_ids": [
      "self",
      "text"
    ],
    "apply_chat_template": [
      "self"
    ],
    "ids_to_text": [
      "self",
      "ids",
      "remove_special_tokens"
    ],
    "vocab": [
      "self"
    ],
    "inv_vocab": [
      "self"
    ],
    "pad_id": [
      "self"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "eod": [
      "self"
    ],
    "sep_id": [
      "self"
    ],
    "cls_id": [
      "self"
    ],
    "unk_id": [
      "self"
    ],
    "mask_id": [
      "self"
    ],
    "name": [
      "self"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "save_pretrained": [
      "self",
      "save_directory"
    ]
  },
  "LogEpochTimeCallback": {
    "on_train_epoch_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_train_epoch_end": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "EMA": {
    "__init__": [
      "self",
      "decay",
      "validate_original_weights",
      "every_n_steps",
      "cpu_offload"
    ],
    "on_fit_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_validation_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_validation_end": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_test_start": [
      "self",
      "trainer",
      "pl_module"
    ],
    "on_test_end": [
      "self",
      "trainer",
      "pl_module"
    ],
    "_should_validate_ema_weights": [
      "self",
      "trainer"
    ],
    "_ema_initialized": [
      "self",
      "trainer"
    ],
    "swap_model_weights": [
      "self",
      "trainer",
      "saving_ema_model"
    ],
    "save_ema_model": [
      "self",
      "trainer"
    ],
    "save_original_optimizer_state": [
      "self",
      "trainer"
    ],
    "on_load_checkpoint": [
      "self",
      "trainer",
      "pl_module",
      "checkpoint"
    ]
  },
  "ema_update": [
    "ema_model_tuple",
    "current_model_tuple",
    "decay"
  ],
  "run_ema_update_cpu": [
    "ema_model_tuple",
    "current_model_tuple",
    "decay",
    "pre_sync_stream"
  ],
  "EMAOptimizer": {
    "__init__": [
      "self",
      "optimizer",
      "device",
      "decay",
      "every_n_steps",
      "current_step"
    ],
    "all_parameters": [
      "self"
    ],
    "step": [
      "self",
      "closure",
      "grad_scaler"
    ],
    "_should_update_at_step": [
      "self"
    ],
    "update": [
      "self"
    ],
    "swap_tensors": [
      "self",
      "tensor1",
      "tensor2"
    ],
    "switch_main_parameter_weights": [
      "self",
      "saving_ema_model"
    ],
    "swap_ema_weights": [
      "self",
      "enabled"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "join": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "add_param_group": [
      "self",
      "param_group"
    ]
  },
  "IPLEpochStopper": {
    "__init__": [
      "self",
      "enable_stop",
      "stop_every_n_epochs"
    ],
    "on_train_epoch_end": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "PromptFormatFnReturnType": [],
  "PromptFormatSignature": [],
  "registered_prompt_format_fn": [
    "example_type",
    "formatter_type"
  ],
  "get_prompt_format_fn": [
    "example",
    "prompt"
  ],
  "apply_prompt_format_fn": [
    "example",
    "prompt"
  ],
  "move_data_to_device": [
    "inputs",
    "device",
    "non_blocking"
  ],
  "ConcatDataset": {
    "__init__": [
      "self",
      "datasets",
      "shuffle",
      "sampling_technique",
      "sampling_temperature",
      "sampling_scale",
      "sampling_probabilities",
      "seed",
      "global_rank",
      "world_size"
    ],
    "get_iterable": [
      "self",
      "dataset"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "temperature_generator": [
      "datasets"
    ],
    "round_robin_generator": [
      "datasets"
    ],
    "random_generator": [
      "datasets"
    ]
  },
  "ConcatMapDataset": {
    "__init__": [
      "self",
      "datasets",
      "sampling_technique",
      "sampling_temperature",
      "sampling_probabilities",
      "seed"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "CodeSwitchedDataset": {
    "__init__": [
      "self",
      "datasets",
      "lang_probs",
      "shuffle",
      "min_duration",
      "max_duration",
      "min_monolingual",
      "db_norm",
      "pause_start",
      "pause_join",
      "pause_end",
      "sampling_scales",
      "seed",
      "global_rank",
      "world_size",
      "pure_random",
      "force_monochannel",
      "infinity_mode",
      "sample_rate",
      "augmentor"
    ],
    "get_iterable_by_lang": [
      "self",
      "lang"
    ],
    "build_single_CS_sample": [
      "self"
    ],
    "prep_underlying_datasets": [
      "self"
    ],
    "get_sample_from_language": [
      "self",
      "lang"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "MegatronCorePretrainingSampler": {
    "_get_padding_indices": [
      "self",
      "pad_samples_num"
    ]
  },
  "BaseMegatronBatchSampler": {
    "__init__": [
      "self",
      "total_samples",
      "consumed_samples",
      "micro_batch_size",
      "global_batch_size",
      "data_parallel_rank",
      "data_parallel_size",
      "drop_last",
      "pad_samples_to_global_batch_size"
    ],
    "update_global_batch_size": [
      "self",
      "new_global_batch_size"
    ],
    "global_batch_size": [
      "self",
      "new_global_batch_size"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "MegatronPretrainingBatchSampler": {
    "get_start_end_idx": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "MegatronPretrainingRandomBatchSampler": {
    "__init__": [
      "self",
      "total_samples",
      "consumed_samples",
      "micro_batch_size",
      "global_batch_size",
      "data_parallel_rank",
      "data_parallel_size",
      "drop_last",
      "pad_samples_to_global_batch_size",
      "seed"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "FallbackDataset": {
    "__init__": [
      "self",
      "dataset"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "__len__": [
      "self"
    ]
  },
  "BlendableDataset": {
    "__init__": [
      "self",
      "datasets",
      "weights",
      "size"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "create_data_mmap": [
      "self"
    ]
  },
  "MemoryEfficientBlendableDataset": {
    "__init__": [
      "self",
      "datasets",
      "weights",
      "size",
      "weight_bins"
    ],
    "get_ds_sample_idx": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "test_index_blending": [
      "cls"
    ]
  },
  "compile_helper": [],
  "MultimodalSamplingConstraint": {
    "_internal": [],
    "__post_init__": [
      "self"
    ],
    "add": [
      "self",
      "example"
    ],
    "exceeded": [
      "self"
    ],
    "close_to_exceeding": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "measure_length": [
      "self",
      "example"
    ]
  },
  "FixedBucketBatchSizeConstraint2D": {
    "__post_init__": [
      "self"
    ],
    "bucketing_2d_enabled": [
      "self"
    ],
    "measure_length": [
      "self",
      "example"
    ],
    "select_bucket": [
      "self",
      "buckets",
      "example",
      "example_len"
    ]
  },
  "find_smallest_bucket": [
    "buckets",
    "example_lens",
    "strict",
    "max_ratio"
  ],
  "MultimodalFixedBucketBatchSizeConstraint2D": {
    "measure_length": [
      "self",
      "example"
    ]
  },
  "DurationFilter": {
    "__init__": [
      "self",
      "d_min",
      "d_max"
    ],
    "__call__": [
      "self",
      "example"
    ]
  },
  "TokenCountFilter": {
    "__init__": [
      "self",
      "t_min",
      "t_max",
      "measure_total_length"
    ],
    "__call__": [
      "self",
      "example"
    ]
  },
  "TokenPerSecondFilter": {
    "__init__": [
      "self",
      "tps_min",
      "tps_max"
    ],
    "__call__": [
      "self",
      "example"
    ]
  },
  "TokenPerTokenFilter": {
    "__init__": [
      "self",
      "tpt_min",
      "tpt_max"
    ],
    "__call__": [
      "self",
      "example"
    ]
  },
  "BucketingFilter": {
    "__init__": [
      "self",
      "sampling_constraint"
    ],
    "__call__": [
      "self",
      "example"
    ]
  },
  "_measure_tokens": [
    "cut"
  ],
  "_measure_tps": [
    "cut"
  ],
  "read_cutset_from_config": [
    "config"
  ],
  "IncompleteConfigError": {},
  "KNOWN_DATA_CONFIG_TYPES": [],
  "get_known_config_data_types": [],
  "get_parser_fn": [
    "data_type_name"
  ],
  "data_type_parser": [
    "name"
  ],
  "read_dataset_config": [
    "config"
  ],
  "parse_group": [
    "grp_cfg",
    "propagate_attrs"
  ],
  "read_txt_paths": [
    "config"
  ],
  "read_txt_pair_paths": [
    "config"
  ],
  "read_nemo_sft_jsonl": [
    "config"
  ],
  "read_multimodal_conversation_jsonl": [
    "config"
  ],
  "read_share_gpt_as_conversation": [
    "config"
  ],
  "_resolve_shar_inputs": [
    "path",
    "only_metadata"
  ],
  "attach_tags": [
    "cut",
    "tags"
  ],
  "parse_and_combine_datasets": [
    "config_list",
    "propagate_attrs"
  ],
  "read_lhotse_manifest": [
    "config"
  ],
  "cut_to_conversation": [
    "cut",
    "audio_locator_tag",
    "token_equivalent_duration"
  ],
  "read_lhotse_as_conversation": [
    "config"
  ],
  "_strip_timestamps": [
    "text",
    "_TIMESTAMP_PATTERN",
    "_SPACE_PATTERN"
  ],
  "FailedConversion": {},
  "s2s_cut_to_conversation": [
    "cut",
    "audio_locator_tag",
    "token_equivalent_duration",
    "input_roles",
    "output_roles",
    "strip_timestamp_tokens"
  ],
  "read_s2s_as_conversation": [
    "config"
  ],
  "resolve_relative_paths": [
    "cut",
    "manifest_path"
  ],
  "read_nemo_manifest": [
    "config"
  ],
  "read_multi_speaker_simulator": [
    "config"
  ],
  "mux": [],
  "guess_parse_cutset": [
    "inp"
  ],
  "LazyNeMoIterator": {
    "__init__": [
      "self",
      "path",
      "text_field",
      "lang_field",
      "metadata_only",
      "shuffle_shards",
      "shard_seed",
      "extra_fields"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__add__": [
      "self",
      "other"
    ],
    "_create_cut": [
      "self",
      "audio_path",
      "offset",
      "duration",
      "sampling_rate"
    ],
    "_create_recording": [
      "self",
      "audio_path",
      "duration",
      "sampling_rate"
    ]
  },
  "LazyNeMoTarredIterator": {
    "__init__": [
      "self",
      "manifest_path",
      "tar_paths",
      "shuffle_shards",
      "shard_seed",
      "text_field",
      "lang_field",
      "skip_missing_manifest_entries",
      "extra_fields",
      "slice_length"
    ],
    "to_shards": [
      "self"
    ],
    "_validate": [
      "self"
    ],
    "_get_seed": [
      "self"
    ],
    "shard_ids": [
      "self"
    ],
    "_iter_sequential": [
      "self",
      "tar_path",
      "shard_manifest",
      "manifest_path",
      "rng"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__add__": [
      "self",
      "other"
    ]
  },
  "make_cut_with_subset_inmemory_recording": [
    "recording",
    "offset",
    "duration"
  ],
  "ExtraField": {
    "TYPE": [],
    "SUPPORTED_TYPES": [],
    "attach_to": [
      "self",
      "cut"
    ],
    "__init_subclass__": [
      "cls"
    ],
    "from_dict": [
      "data"
    ],
    "is_supported": [
      "cls",
      "field_type"
    ],
    "supported_types": [
      "cls"
    ]
  },
  "TextIteratorExtraField": {
    "TYPE": [],
    "__init__": [
      "self",
      "name",
      "path",
      "seed"
    ],
    "_maybe_init": [
      "self"
    ],
    "attach_to": [
      "self",
      "cut"
    ]
  },
  "TextSampleExtraField": {
    "TYPE": [],
    "__init__": [
      "self",
      "name",
      "path",
      "seed"
    ],
    "_maybe_init": [
      "self"
    ],
    "attach_to": [
      "self",
      "cut"
    ]
  },
  "validate_extra_fields": [
    "extra_fields"
  ],
  "expand_sharded_filepaths": [
    "paths"
  ],
  "_to_custom_attr_dict": [
    "d",
    "_excluded_fields"
  ],
  "Formattable": {
    "__init__": [
      "self"
    ],
    "input_length": [
      "self"
    ],
    "output_length": [
      "self"
    ],
    "total_length": [
      "self"
    ],
    "apply_prompt_format": [
      "self",
      "prompt"
    ]
  },
  "TextExample": {
    "tokenize": [
      "self",
      "tokenizer"
    ]
  },
  "LhotseTextAdapter": {
    "__post_init__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "default_text_example_prompt_format_fn": [
    "example",
    "prompt"
  ],
  "SourceTargetTextExample": {
    "tokenize": [
      "self",
      "tokenizer"
    ]
  },
  "LhotseTextPairAdapter": {
    "__post_init__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "default_src_tgt_prompt_format_fn": [
    "example",
    "prompt"
  ],
  "NeMoSFTExample": {},
  "default_sft_prompt_format_fn": [
    "example",
    "prompt"
  ],
  "NeMoSFTJsonlAdapter": {
    "__post_init__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "TextTurn": {
    "to_dict": [
      "self"
    ]
  },
  "AudioTurn": {
    "to_dict": [
      "self"
    ]
  },
  "NeMoMultimodalConversation": {
    "input_length": [
      "self"
    ],
    "output_length": [
      "self"
    ],
    "total_length": [
      "self"
    ],
    "has_audio_turns": [
      "self"
    ],
    "has_text_turns": [
      "self"
    ],
    "is_text_only": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "list_cuts": [
      "self"
    ]
  },
  "collate_conversation_audio_fault_tolerant": [
    "conversations"
  ],
  "_compute_num_audio_tokens": [
    "example",
    "mode"
  ],
  "default_multimodal_conversation_prompt_format_fn": [
    "example",
    "prompt"
  ],
  "NeMoMultimodalConversationJsonlAdapter": {
    "__post_init__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "_should_skip": [
      "self",
      "example"
    ],
    "_get_rng": [
      "self"
    ],
    "_iter_tar": [
      "self"
    ],
    "_iter_jsonl": [
      "self"
    ]
  },
  "NeMoMultimodalConversationShareGPTJsonlAdapter": {
    "__post_init__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "_get_rng": [
      "self"
    ],
    "_iter_tar": [
      "self"
    ],
    "_iter_jsonl": [
      "self"
    ],
    "_transform_sharegpt_conversations": [
      "self",
      "data"
    ],
    "_create_turns": [
      "self",
      "conversations",
      "cuts",
      "manifest_path"
    ]
  },
  "TarIterator": {
    "__init__": [
      "self",
      "source"
    ],
    "__iter__": [
      "self"
    ]
  },
  "_iterate_tarfile_pairwise": [
    "tar_file"
  ],
  "NeMoMultimodalConversationTarWriter": {
    "__init__": [
      "self",
      "output_dir",
      "shard_size"
    ],
    "write": [
      "self",
      "example"
    ],
    "close": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "_maybe_increment_shard": [
      "self"
    ],
    "_reset": [
      "self"
    ],
    "_setup_writers": [
      "self"
    ]
  },
  "LhotseDataLoadingConfig": {},
  "determine_use_iterable_dataset": [
    "use_iterable_dataset",
    "config"
  ],
  "get_lhotse_dataloader_from_config": [
    "config",
    "global_rank",
    "world_size",
    "dataset",
    "tokenizer"
  ],
  "get_lhotse_dataloader_from_single_config": [
    "config",
    "global_rank",
    "world_size",
    "dataset",
    "tokenizer"
  ],
  "get_lhotse_dataloader_from_multi_config": [
    "top_level_config",
    "global_rank",
    "world_size",
    "dataset",
    "tokenizer"
  ],
  "get_lhotse_sampler_from_config": [
    "config",
    "global_rank",
    "world_size",
    "tokenizer"
  ],
  "determine_sampling_constraint": [
    "cuts",
    "bucket_duration_bins",
    "config"
  ],
  "determine_bucket_duration_bins": [
    "config"
  ],
  "make_structured_with_schema_warnings": [
    "config"
  ],
  "tokenize": [
    "example",
    "tokenizer"
  ],
  "tokenize_with_prompt": [
    "example",
    "tokenizer",
    "prompt_format"
  ],
  "_normalize_loudness": [
    "cuts",
    "db_norm"
  ],
  "_merge_supervisions": [
    "cuts"
  ],
  "_flatten_alt_text": [
    "cut"
  ],
  "maybe_set_cuda_expandable_segments": [
    "enabled"
  ],
  "resample": [
    "example",
    "sampling_rate"
  ],
  "_select_channel": [
    "cut",
    "channel_selector"
  ],
  "LLM_VOCAB_SIZE_MAP": [],
  "read_tb_log": [
    "path",
    "summary_name"
  ],
  "activation_registry": [],
  "if_exist": [
    "outfold",
    "files"
  ],
  "_compute_softmax": [
    "scores"
  ],
  "flatten_iterable": [
    "iter"
  ],
  "flatten": [
    "list_in"
  ],
  "extend_instance": [
    "obj",
    "mixin"
  ],
  "apply_rope_scaling": [
    "freqs",
    "scale_factor",
    "low_freq_factor",
    "high_freq_factor",
    "old_context_len"
  ],
  "mask_sequence_tensor": [
    "tensor",
    "lengths"
  ],
  "ClampActivation": {
    "__init__": [
      "self",
      "min_value",
      "max_value"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "snake": [
    "x",
    "alpha",
    "eps"
  ],
  "Snake": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HalfSnake": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MegatronTrainerBuilder": {
    "__init__": [
      "self",
      "cfg"
    ],
    "_training_strategy": [
      "self"
    ],
    "_grad_scaler": [
      "self"
    ],
    "_plugins": [
      "self"
    ],
    "_callbacks": [
      "self",
      "callbacks"
    ],
    "create_trainer": [
      "self",
      "callbacks"
    ]
  },
  "MegatronLMPPTrainerBuilder": {
    "_grad_scaler": [
      "self"
    ]
  },
  "AdapterModuleUtil": {
    "setup_adapter_strategy": [
      "self",
      "adapter_strategy"
    ],
    "get_default_strategy_config": [
      "self"
    ],
    "adapter_unfreeze": [
      "self"
    ]
  },
  "LinearAdapter": {
    "__init__": [
      "self",
      "in_features",
      "dim",
      "activation",
      "norm_position",
      "dropout",
      "adapter_strategy"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LinearAdapterConfig": {},
  "WithOptionalCudaGraphs": {
    "disable_cuda_graphs_recursive": [
      "cls",
      "module",
      "attribute_path"
    ],
    "enable_cuda_graphs_recursive": [
      "cls",
      "module",
      "attribute_path"
    ],
    "disable_cuda_graphs": [
      "self"
    ],
    "maybe_enable_cuda_graphs": [
      "self"
    ]
  },
  "NEG_INF": [],
  "form_attention_mask": [
    "input_mask",
    "diagonal"
  ],
  "transformer_weights_init": [
    "module",
    "std_init_range",
    "xavier"
  ],
  "mask_padded_tokens": [
    "tokens",
    "pad_id"
  ],
  "MLMScorer": {
    "__init__": [
      "self",
      "model_name",
      "device"
    ],
    "score_sentences": [
      "self",
      "sentences"
    ],
    "score_sentence": [
      "self",
      "sentence"
    ],
    "__mask_text__": [
      "self",
      "idx",
      "tokens"
    ]
  },
  "rnn": [
    "input_size",
    "hidden_size",
    "num_layers",
    "norm",
    "forget_gate_bias",
    "dropout",
    "norm_first_rnn",
    "t_max",
    "weights_init_scale",
    "hidden_hidden_bias_scale",
    "proj_size"
  ],
  "OverLastDim": {
    "__init__": [
      "self",
      "module"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LSTMDropout": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "dropout",
      "forget_gate_bias",
      "t_max",
      "weights_init_scale",
      "hidden_hidden_bias_scale",
      "proj_size"
    ],
    "forward": [
      "self",
      "x",
      "h"
    ]
  },
  "RNNLayer": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "rnn_type",
      "batch_norm",
      "forget_gate_bias",
      "t_max",
      "weights_init_scale",
      "hidden_hidden_bias_scale",
      "proj_size"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_flatten_parameters": [
      "self"
    ]
  },
  "BNRNNSum": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "rnn_type",
      "rnn_layers",
      "batch_norm",
      "dropout",
      "forget_gate_bias",
      "norm_first_rnn",
      "t_max",
      "weights_init_scale",
      "hidden_hidden_bias_scale",
      "proj_size"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_parse_hidden_state": [
      "self",
      "hx"
    ],
    "_flatten_parameters": [
      "self"
    ]
  },
  "StackTime": {
    "__init__": [
      "self",
      "factor"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ln_lstm": [
    "input_size",
    "hidden_size",
    "num_layers",
    "dropout",
    "forget_gate_bias",
    "t_max",
    "weights_init_scale",
    "hidden_hidden_bias_scale"
  ],
  "LSTMLayer": {
    "__init__": [
      "self",
      "cell"
    ],
    "forward": [
      "self",
      "input",
      "state"
    ]
  },
  "LayerNormLSTMCell": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "forget_gate_bias"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "state"
    ]
  },
  "init_stacked_lstm": [
    "num_layers",
    "layer",
    "first_layer_args",
    "other_layer_args"
  ],
  "StackedLSTM": {
    "__init__": [
      "self",
      "num_layers",
      "layer",
      "first_layer_args",
      "other_layer_args"
    ],
    "forward": [
      "self",
      "input",
      "states"
    ]
  },
  "label_collate": [
    "labels",
    "device"
  ],
  "NLPDDPStrategy": {
    "__init__": [
      "self",
      "parallel_devices",
      "cluster_environment",
      "checkpoint_io",
      "no_ddp_communication_hook",
      "nccl_communicator_config_path",
      "sharp",
      "dist_ckpt_parallel_save"
    ],
    "setup": [
      "self",
      "trainer"
    ],
    "setup_distributed": [
      "self",
      "global_rank",
      "world_size"
    ],
    "configure_ddp": [
      "self"
    ],
    "optimizer_sharded_state_dict": [
      "self",
      "unsharded_optim_state",
      "is_loading"
    ],
    "save_checkpoint": [
      "self",
      "checkpoint",
      "filepath",
      "storage_options"
    ],
    "load_model_state_dict": [
      "self",
      "checkpoint",
      "strict"
    ],
    "_fix_tensors_device": [
      "self",
      "ckpt"
    ],
    "_get_param_group": [
      "self",
      "state_dict"
    ],
    "_check_param_groups_mismatch": [
      "self",
      "checkpoint_path",
      "sharded_state_dict"
    ],
    "_fix_param_groups": [
      "self",
      "checkpoint_path",
      "sharded_state_dict"
    ],
    "load_checkpoint": [
      "self",
      "checkpoint_path",
      "load_optimizer_states"
    ],
    "_integrate_original_checkpoint_data": [
      "self",
      "checkpoint"
    ],
    "remove_checkpoint": [
      "self",
      "filepath"
    ],
    "use_distributed_checkpointing": [
      "self"
    ],
    "distributed_sampler_kwargs": [
      "self"
    ],
    "restore_checkpoint_after_setup": [
      "self"
    ],
    "unwrapped_checkpoint_io": [
      "self"
    ]
  },
  "NLPDDPStrategyNotebook": {
    "_configure_launcher": [
      "self"
    ]
  },
  "_get_sharded_state_dict_context": [
    "module",
    "rank0_only"
  ],
  "_get_full_state_dict_context": [
    "module",
    "rank0_only"
  ],
  "NLPFSDPStrategy": {
    "__init__": [
      "self",
      "sharding_strategy",
      "grad_reduce_dtype",
      "sharded_checkpoint",
      "precision",
      "nccl_communicator_config_path",
      "sharp",
      "set_buffer_dtype",
      "extra_fsdp_wrap_module"
    ],
    "_set_mixed_precision_recipe": [
      "self",
      "precision",
      "grad_reduce_dtype",
      "set_buffer_dtype"
    ],
    "setup_environment": [
      "self"
    ],
    "lightning_module_state_dict": [
      "self"
    ],
    "optimizer_state": [
      "self",
      "optimizer"
    ],
    "load_model_state_dict": [
      "self",
      "checkpoint",
      "strict"
    ],
    "load_optimizer_state_dict": [
      "self",
      "checkpoint"
    ],
    "save_checkpoint": [
      "self",
      "checkpoint",
      "filepath",
      "storage_options"
    ],
    "load_checkpoint": [
      "self",
      "checkpoint_path"
    ],
    "remove_checkpoint": [
      "self",
      "filepath"
    ],
    "restore_checkpoint_after_setup": [
      "self"
    ]
  },
  "NLPSaveRestoreConnector": {
    "__init__": [
      "self"
    ],
    "save_to": [
      "self",
      "model",
      "save_path"
    ],
    "modify_state_dict": [
      "self",
      "conf",
      "state_dict"
    ],
    "_load_state_dict_from_disk": [
      "self",
      "model_weights",
      "map_location"
    ],
    "restore_from": [
      "self",
      "calling_cls",
      "restore_path",
      "override_config_path",
      "map_location",
      "strict",
      "return_config",
      "trainer",
      "validate_access_integrity",
      "replace_sharded_tensor_key"
    ]
  },
  "PipelineMixedPrecisionPlugin": {
    "__init__": [
      "self",
      "precision",
      "device",
      "scaler"
    ],
    "forward_context": [
      "self"
    ]
  },
  "FSDPMixedPrecisionPlugin": {
    "__init__": [
      "self",
      "precision",
      "scaler"
    ],
    "forward_context": [
      "self"
    ]
  },
  "MegatronHalfPrecisionPlugin": {
    "__init__": [
      "self",
      "precision",
      "device",
      "scaler"
    ],
    "optimizer_step": [
      "self",
      "optimizer",
      "model",
      "closure"
    ],
    "forward_context": [
      "self"
    ]
  },
  "GlobalBatchDataFetcher": {
    "__init__": [
      "self",
      "prefetch_batches",
      "store_on_device"
    ],
    "_fetch_next_batch": [
      "self",
      "iterator"
    ]
  },
  "CustomProgressBar": {
    "get_current_epoch_step": [
      "self",
      "trainer"
    ],
    "init_train_tqdm": [
      "self"
    ],
    "on_train_epoch_start": [
      "self",
      "trainer"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module"
    ]
  },
  "MultiLayerPerceptron": {
    "__init__": [
      "self",
      "hidden_size",
      "num_classes",
      "num_layers",
      "activation",
      "log_softmax",
      "channel_idx"
    ],
    "last_linear_layer": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "TORCH_VERSION": [],
  "TORCH_VERSION_MIN": [],
  "NeMoMixedPrecisionPlugin": {
    "__init__": [
      "self",
      "init_scale",
      "growth_interval"
    ]
  },
  "LOG": [],
  "REUSE_CODE_EXP": [],
  "RepoMetadata": {
    "__post_init__": [
      "self"
    ]
  },
  "EXTERNAL_REPOS": [],
  "register_external_repo": [
    "metadata"
  ],
  "get_registered_external_repo": [
    "name"
  ],
  "check_if_mounted": [
    "cluster_config",
    "path_to_check"
  ],
  "get_unmounted_path": [
    "cluster_config",
    "path"
  ],
  "get_exp_handles": [
    "expname",
    "ignore_finished",
    "ignore_exp_not_exists"
  ],
  "get_timeout": [
    "cluster_config",
    "partition"
  ],
  "get_free_port": [
    "exclude",
    "strategy"
  ],
  "get_generation_command": [
    "server_address",
    "generation_commands"
  ],
  "get_reward_server_command": [
    "server_type",
    "num_gpus",
    "num_nodes",
    "model_path",
    "cluster_config",
    "server_port",
    "server_args"
  ],
  "get_ray_server_cmd": [
    "start_cmd"
  ],
  "get_server_command": [
    "server_type",
    "num_gpus",
    "num_nodes",
    "model_path",
    "cluster_config",
    "server_port",
    "server_args"
  ],
  "get_sandox_command": [],
  "CustomJobDetails": {
    "stdout": [
      "self"
    ],
    "srun_stdout": [
      "self"
    ],
    "stderr": [
      "self"
    ],
    "srun_stderr": [
      "self"
    ],
    "ls_term": [
      "self"
    ]
  },
  "read_config": [
    "config_file"
  ],
  "get_cluster_config": [
    "cluster",
    "config_dir"
  ],
  "_get_tunnel_cached": [
    "job_dir",
    "host",
    "user",
    "identity",
    "shell",
    "pre_command"
  ],
  "tunnel_hash": [
    "tunnel"
  ],
  "get_tunnel": [
    "cluster_config"
  ],
  "OutputWatcher": {
    "submit": [
      "self",
      "stream"
    ]
  },
  "progress_callback": [
    "transferred",
    "total"
  ],
  "cluster_download": [
    "tunnel",
    "remote_dir",
    "local_dir",
    "remote_tar_dir",
    "verbose"
  ],
  "cluster_upload": [
    "tunnel",
    "local_file",
    "remote_dir",
    "verbose"
  ],
  "get_git_repo_path": [
    "path"
  ],
  "get_packager": [
    "extra_package_dirs"
  ],
  "get_env_variables": [
    "cluster_config"
  ],
  "get_mounts_from_config": [
    "cluster_config"
  ],
  "get_executor": [
    "cluster_config",
    "container",
    "num_nodes",
    "tasks_per_node",
    "gpus_per_node",
    "job_name",
    "log_dir",
    "log_prefix",
    "mounts",
    "partition",
    "time_min",
    "dependencies",
    "extra_package_dirs",
    "heterogeneous",
    "het_group",
    "total_het_groups",
    "slurm_kwargs"
  ],
  "temporary_env_update": [
    "cluster_config",
    "updates"
  ],
  "add_task": [
    "exp",
    "cmd",
    "task_name",
    "cluster_config",
    "container",
    "num_tasks",
    "num_gpus",
    "num_nodes",
    "log_dir",
    "partition",
    "time_min",
    "with_sandbox",
    "sandbox_port",
    "server_config",
    "reuse_code_exp",
    "reuse_code",
    "task_dependencies",
    "run_after",
    "get_server_command",
    "extra_package_dirs",
    "slurm_kwargs",
    "heterogeneous"
  ],
  "run_exp": [
    "exp",
    "cluster_config",
    "sequential"
  ],
  "add_mount_path": [
    "mount_source",
    "mount_dest",
    "cluster_config"
  ],
  "create_remote_directory": [
    "directory",
    "cluster_config"
  ],
  "create_remote_config": [
    "config",
    "config_name",
    "config_directory",
    "cluster_config"
  ],
  "check_remote_mount_directories": [
    "directories",
    "cluster_config",
    "exit_on_failure"
  ],
  "get_unmounted_filepath": [
    "cluster_config",
    "filepath"
  ],
  "get_mounted_filepath": [
    "cluster_config",
    "filepath"
  ],
  "NUM_CHECK": [],
  "TIME_CHECK": [],
  "CURRENCY_CHECK": [],
  "ORD_CHECK": [],
  "THREE_CHECK": [],
  "DECIMAL_CHECK": [],
  "ABBREVIATIONS_COMMON": [],
  "ABBREVIATIONS_EXPANDED": [],
  "ABBREVIATIONS_TTS_FASTPITCH": [],
  "inflect_engine": [],
  "clean_text": [
    "string",
    "table",
    "punctuation_to_replace",
    "abbreviation_version"
  ],
  "warn_common_chars": [
    "string"
  ],
  "clean_numbers": [
    "string"
  ],
  "clean_abbreviations": [
    "string",
    "version"
  ],
  "clean_punctuations": [
    "string",
    "table",
    "punctuation_to_replace"
  ],
  "NumberCleaner": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "format_final_number": [
      "self",
      "whole_num",
      "decimal"
    ],
    "clean": [
      "self",
      "match"
    ]
  },
  "_Collection": {
    "OUTPUT_TYPE": []
  },
  "FromFileText": {
    "__init__": [
      "self",
      "file",
      "parser"
    ],
    "__parse_texts": [
      "file"
    ]
  },
  "AudioText": {
    "OUTPUT_TYPE": [],
    "__init__": [
      "self",
      "ids",
      "audio_files",
      "durations",
      "texts",
      "offsets",
      "speakers",
      "orig_sampling_rates",
      "token_labels",
      "langs",
      "parser",
      "min_duration",
      "max_duration",
      "max_number",
      "do_sort_by_duration",
      "index_by_file_id"
    ]
  },
  "VideoText": {
    "OUTPUT_TYPE": [],
    "__init__": [
      "self",
      "ids",
      "video_files",
      "durations",
      "texts",
      "offsets",
      "speakers",
      "orig_sampling_rates",
      "token_labels",
      "langs",
      "parser",
      "min_duration",
      "max_duration",
      "max_number",
      "do_sort_by_duration",
      "index_by_file_id"
    ]
  },
  "ASRAudioText": {
    "__init__": [
      "self",
      "manifests_files",
      "parse_func"
    ]
  },
  "SpeechLLMAudioTextEntity": {
    "__init__": [
      "self",
      "sid",
      "audio_file",
      "duration",
      "context",
      "answer",
      "offset",
      "speaker",
      "orig_sr",
      "lang"
    ]
  },
  "ASRVideoText": {
    "__init__": [
      "self",
      "manifests_files"
    ]
  },
  "SpeechLLMAudioText": {
    "__init__": [
      "self",
      "ids",
      "audio_files",
      "durations",
      "context_list",
      "answers",
      "offsets",
      "speakers",
      "orig_sampling_rates",
      "langs",
      "min_duration",
      "max_duration",
      "max_number",
      "do_sort_by_duration",
      "index_by_file_id",
      "max_num_samples"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ]
  },
  "SpeechLLMAudioTextCollection": {
    "__init__": [
      "self",
      "manifests_files",
      "context_file",
      "context_key",
      "answer_key"
    ],
    "__parse_item": [
      "self",
      "line",
      "manifest_file"
    ]
  },
  "SpeechLabel": {
    "OUTPUT_TYPE": [],
    "__init__": [
      "self",
      "audio_files",
      "durations",
      "labels",
      "offsets",
      "min_duration",
      "max_duration",
      "max_number",
      "do_sort_by_duration",
      "index_by_file_id"
    ]
  },
  "ASRSpeechLabel": {
    "__init__": [
      "self",
      "manifests_files",
      "is_regression_task",
      "cal_labels_occurrence",
      "delimiter"
    ],
    "__parse_item": [
      "self",
      "line",
      "manifest_file"
    ]
  },
  "FeatureSequenceLabel": {
    "OUTPUT_TYPE": [],
    "__init__": [
      "self",
      "feature_files",
      "seq_labels",
      "max_number",
      "index_by_file_id"
    ],
    "relative_speaker_parser": [
      "self",
      "seq_label"
    ]
  },
  "ASRFeatureSequenceLabel": {
    "__init__": [
      "self",
      "manifests_files",
      "max_number",
      "index_by_file_id"
    ],
    "_parse_item": [
      "self",
      "line",
      "manifest_file"
    ]
  },
  "DiarizationLabel": {
    "OUTPUT_TYPE": [],
    "__init__": [
      "self",
      "audio_files",
      "durations",
      "rttm_files",
      "offsets",
      "target_spks_list",
      "sess_spk_dicts",
      "clus_spk_list",
      "rttm_spk_list",
      "max_number",
      "do_sort_by_duration",
      "index_by_file_id"
    ]
  },
  "DiarizationSpeechLabel": {
    "__init__": [
      "self",
      "manifests_files",
      "emb_dict",
      "clus_label_dict",
      "round_digits",
      "seq_eval_mode",
      "pairwise_infer"
    ],
    "split_rttm_line": [
      "self",
      "rttm_line",
      "decimals"
    ],
    "__parse_item_rttm": [
      "self",
      "line",
      "manifest_file"
    ]
  },
  "EndtoEndDiarizationLabel": {
    "OUTPUT_TYPE": [],
    "__init__": [
      "self",
      "audio_files",
      "uniq_ids",
      "durations",
      "rttm_files",
      "offsets",
      "max_number",
      "do_sort_by_duration",
      "index_by_file_id"
    ]
  },
  "EndtoEndDiarizationSpeechLabel": {
    "__init__": [
      "self",
      "manifests_files",
      "round_digits"
    ],
    "__parse_item_rttm": [
      "self",
      "line",
      "manifest_file"
    ]
  },
  "Audio": {
    "OUTPUT_TYPE": [],
    "__init__": [
      "self",
      "audio_files_list",
      "duration_list",
      "offset_list",
      "text_list",
      "min_duration",
      "max_duration",
      "max_number",
      "do_sort_by_duration"
    ]
  },
  "AudioCollection": {
    "__init__": [
      "self",
      "manifest_files",
      "audio_to_manifest_key"
    ],
    "__parse_item": [
      "self",
      "line",
      "manifest_file"
    ]
  },
  "FeatureLabel": {
    "OUTPUT_TYPE": [],
    "__init__": [
      "self",
      "feature_files",
      "labels",
      "durations",
      "min_duration",
      "max_duration",
      "max_number",
      "do_sort_by_duration",
      "index_by_file_id"
    ]
  },
  "ASRFeatureLabel": {
    "__init__": [
      "self",
      "manifests_files",
      "is_regression_task",
      "cal_labels_occurrence",
      "delimiter"
    ],
    "_parse_item": [
      "self",
      "line",
      "manifest_file"
    ]
  },
  "FeatureText": {
    "OUTPUT_TYPE": [],
    "__init__": [
      "self",
      "ids",
      "feature_files",
      "rttm_files",
      "durations",
      "texts",
      "offsets",
      "speakers",
      "orig_sampling_rates",
      "token_labels",
      "langs",
      "parser",
      "min_duration",
      "max_duration",
      "max_number",
      "do_sort_by_duration",
      "index_by_file_id"
    ]
  },
  "ASRFeatureText": {
    "__init__": [
      "self",
      "manifests_files"
    ]
  },
  "ManifestBase": {
    "__init__": [
      "self"
    ]
  },
  "ManifestEN": {
    "__init__": [
      "self"
    ]
  },
  "item_iter": [
    "manifests_files",
    "parse_func"
  ],
  "__parse_item": [
    "line",
    "manifest_file"
  ],
  "is_tarred_dataset": [
    "audio_file",
    "manifest_file"
  ],
  "get_full_path": [
    "audio_file",
    "manifest_file",
    "data_dir",
    "audio_file_len_limit",
    "force_cache"
  ],
  "CharParser": {
    "__init__": [
      "self",
      "labels"
    ],
    "__call__": [
      "self",
      "text"
    ],
    "_normalize": [
      "self",
      "text"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "str_input"
    ]
  },
  "ENCharParser": {
    "PUNCTUATION_TO_REPLACE": [],
    "__init__": [
      "self",
      "abbreviation_version",
      "make_table"
    ],
    "__make_trans_table": [
      "self"
    ],
    "_normalize": [
      "self",
      "text"
    ]
  },
  "RUCharParser": {
    "PUNCTUATION_TO_REPLACE": [],
    "__init__": [
      "self"
    ],
    "__make_trans_table": [
      "self"
    ],
    "_normalize": [
      "self",
      "text"
    ]
  },
  "NAME_TO_PARSER": [],
  "_FLOAT_TYPES": [],
  "_HALF_TYPES": [],
  "_BF16_TYPES": [],
  "MegatronModule": {
    "__init__": [
      "self",
      "config",
      "share_token_embeddings"
    ],
    "word_embeddings_weight": [
      "self"
    ],
    "position_embeddings_weight": [
      "self"
    ],
    "encoder_relative_position_embeddings_weight": [
      "self"
    ],
    "decoder_relative_position_embeddings_weight": [
      "self"
    ],
    "decoder_cross_attention_relative_position_embeddings_weight": [
      "self"
    ],
    "initialize_word_embeddings": [
      "self",
      "init_method",
      "vocab_size",
      "hidden_size"
    ],
    "sync_initial_word_embeddings": [
      "self"
    ],
    "sync_initial_position_embeddings": [
      "self"
    ],
    "state_dict_for_save_checkpoint": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "sync_initial_encoder_relative_position_embeddings": [
      "self"
    ],
    "sync_initial_decoder_relative_position_embeddings": [
      "self"
    ],
    "sync_initial_decoder_cross_attention_relative_position_embeddings": [
      "self"
    ]
  },
  "conversion_helper": [
    "val",
    "conversion"
  ],
  "fp32_to_float16": [
    "val",
    "float16_converter"
  ],
  "float16_to_fp32": [
    "val"
  ],
  "Float16Module": {
    "__init__": [
      "self",
      "config",
      "module",
      "precision",
      "share_token_embeddings"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ],
    "forward": [
      "self"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "state_dict_for_save_checkpoint": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "word_embeddings_weight": [
      "self"
    ],
    "position_embeddings_weight": [
      "self"
    ],
    "encoder_relative_position_embeddings_weight": [
      "self"
    ],
    "decoder_relative_position_embeddings_weight": [
      "self"
    ],
    "decoder_cross_attention_relative_position_embeddings_weight": [
      "self"
    ]
  },
  "NF4Weight": {
    "__new__": [
      "cls",
      "data",
      "is_nf4_quantized",
      "block_size",
      "scale_block_size"
    ],
    "quantize": [
      "self",
      "device"
    ],
    "dequantize": [
      "self"
    ],
    "cuda": [
      "self",
      "device",
      "non_blocking"
    ],
    "to": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_LinearNF4": {
    "forward": [
      "ctx",
      "input",
      "weight"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "nf4_quantize": [
    "x"
  ],
  "NF4LinearWrapper": {
    "__init__": [
      "self",
      "bf16_linear_weight"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NF4LayerNormLinearWrapper": {
    "__init__": [
      "self",
      "bf16_linear_weight",
      "layer_norm_weight",
      "layer_norm_bias",
      "normalization",
      "zero_centered_gamma"
    ],
    "_create_layer_norm_fn": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "qlora_load_model": [
    "model",
    "model_cfg",
    "checkpoint"
  ],
  "bias_gelu": [
    "bias",
    "y"
  ],
  "bias_gelu_back": [
    "g",
    "bias",
    "y"
  ],
  "GeLUFunction": {
    "forward": [
      "ctx",
      "input",
      "bias"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ],
    "symbolic": [
      "g",
      "input",
      "bias"
    ]
  },
  "fused_bias_gelu": [
    "input",
    "bias"
  ],
  "swap_mcore_mixin": [
    "module",
    "mcore_mixin"
  ],
  "MCoreAdapterModuleMixin": {
    "mcore_register_adapters": [
      "self"
    ]
  },
  "MCoreTransformerBlockMixin": {
    "mcore_register_adapters": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "rotary_pos_cos",
      "rotary_pos_sin",
      "attention_bias",
      "inference_params",
      "packed_seq_params",
      "sequence_len_offset"
    ]
  },
  "MCoreSelfAttentionMixin": {
    "mcore_register_adapters": [
      "self"
    ],
    "get_query_key_value_tensors": [
      "self",
      "hidden_states",
      "key_value_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "key_value_states",
      "inference_params",
      "rotary_pos_emb",
      "packed_seq_params",
      "rotary_pos_cos",
      "rotary_pos_sin",
      "attention_bias",
      "sequence_len_offset"
    ]
  },
  "MCoreMLPMixin": {
    "mcore_register_adapters": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "expert_idx"
    ]
  },
  "MCoreSequentialMLPMixin": {
    "mcore_register_adapters": [
      "self"
    ],
    "forward": [
      "self",
      "permuted_local_hidden_states",
      "tokens_per_expert"
    ]
  },
  "MCoreGPTEmbeddingMixin": {
    "mcore_register_adapters": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids"
    ]
  },
  "MCoreTransformerLayerMixin": {
    "mcore_register_adapters": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "inference_params",
      "packed_seq_params"
    ]
  },
  "AdapterName": {
    "MLP_INFUSED": [],
    "KEY_INFUSED": [],
    "VALUE_INFUSED": [],
    "PRE_ATTN_ADAPTER": [],
    "POST_ATTN_ADAPTER": [],
    "PTUNING_ADAPTER": [],
    "LORA_KQV_ADAPTER": [],
    "LORA_UNFUSED_KQV_ADAPTER": [],
    "MLP_HEAD_ADAPTER": [],
    "LORA_KV_ADAPTER": [],
    "LORA_Q_ADAPTER": [],
    "MM_LINEAR_ADAPTER": [],
    "LORA_DENSE_ATTENTION_ADAPTER": [],
    "LORA_Hto4H_ADAPTER": [],
    "LORA_UNFUSED_Hto4H_ADAPTER": [],
    "LORA_4HtoH_ADAPTER": [],
    "LORA_MOE_Hto4H_ADAPTER": [],
    "LORA_MOE_4HtoH_ADAPTER": [],
    "MULTIMODAL_PROJECTOR_ADAPTER": [],
    "PARALLEL_LINEAR_ADAPTER": []
  },
  "InfusedAdapter": {
    "__init__": [
      "self",
      "in_features",
      "model_parallel_config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MLPInfusedAdapter": {},
  "InfusedAdapterConfig": {},
  "MLPInfusedAdapterConfig": {},
  "pad_seq_to_mult": [
    "x",
    "mult"
  ],
  "unpad_seq_to_mult": [
    "x",
    "pad_len"
  ],
  "ParallelLinearAdapter": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "dim",
      "activation",
      "norm_position",
      "norm_type",
      "column_init_method",
      "row_init_method",
      "gather_output",
      "input_is_parallel",
      "dropout",
      "model_parallel_config",
      "alpha",
      "dropout_position",
      "a2a_experimental",
      "is_expert"
    ],
    "_get_init_fn": [
      "self",
      "init_method"
    ],
    "adapter_unfreeze": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "_All2AllHp2Sp": {
    "forward": [
      "ctx",
      "input_"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "all2all_hp2sp": [
    "input_"
  ],
  "ParallelLinearAdapterConfig": {},
  "MLPHeadAdapter": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "input_is_parallel",
      "model_parallel_config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MLPHeadAdapterConfig": {},
  "LoraKQVAdapter": {},
  "LoraKVAdapter": {},
  "LoraQAdapter": {},
  "LoraDenseAttentionAdapter": {},
  "LoraHto4HAdapter": {},
  "Lora4HtoHAdapter": {},
  "LoraKQVAdapterConfig": {},
  "LoraQAdapterConfig": {},
  "LoraKVAdapterConfig": {},
  "LoraDenseAttentionAdapterConfig": {},
  "LoraHto4HAdapterConfig": {},
  "Lora4HtoHAdapterConfig": {},
  "LoraUnfusedHto4HAdapter": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "dim",
      "activation",
      "norm_position",
      "norm_type",
      "column_init_method",
      "row_init_method",
      "gather_output",
      "input_is_parallel",
      "dropout",
      "model_parallel_config",
      "alpha",
      "dropout_position",
      "a2a_experimental"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LoraUnfusedHto4HAdapterConfig": {},
  "LoraUnfusedKQVAdapter": {
    "__init__": [
      "self",
      "in_features",
      "dim",
      "num_query_groups",
      "kv_channels",
      "activation",
      "norm_position",
      "norm_type",
      "column_init_method",
      "row_init_method",
      "gather_output",
      "input_is_parallel",
      "dropout",
      "model_parallel_config",
      "alpha",
      "dropout_position",
      "a2a_experimental"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LoraUnfusedKQVAdapterConfig": {},
  "LoraMoeAdapter": {
    "__init__": [
      "self",
      "num_moe_experts",
      "in_features",
      "out_features",
      "dim",
      "activation",
      "norm_position",
      "norm_type",
      "column_init_method",
      "row_init_method",
      "gather_output",
      "input_is_parallel",
      "dropout",
      "model_parallel_config",
      "alpha",
      "dropout_position",
      "a2a_experimental"
    ],
    "forward": [
      "self",
      "x",
      "expert_idx"
    ]
  },
  "LoraMoeHto4HAdapterConfig": {},
  "LoraMoe4HtoHAdapterConfig": {},
  "PromptEncoderAdapter": {
    "__init__": [
      "self",
      "virtual_tokens",
      "bottleneck_dim",
      "embedding_dim",
      "init_std",
      "output_dim",
      "model_parallel_config"
    ],
    "set_inference_table": [
      "self",
      "prompt_representation"
    ],
    "clear_inference_table": [
      "self"
    ],
    "get_inference_table": [
      "self"
    ],
    "inner_forward": [
      "self"
    ],
    "forward": [
      "self",
      "batch_size",
      "use_cached_reps"
    ]
  },
  "PromptEncoderAdapterConfig": {},
  "ParallelLinearAdapterWeightTying": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "dim",
      "activation",
      "norm_position",
      "norm_type",
      "column_init_method",
      "row_init_method",
      "gather_output",
      "dropout",
      "num_position_embeddings",
      "dim_position_embeddings",
      "position_embedding_strategy",
      "model_parallel_config"
    ],
    "set_position": [
      "self",
      "position_id"
    ],
    "tie_weights": [
      "self",
      "position_id",
      "adapter"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ParallelLinearAdapterWeightTyingConfig": {},
  "LoraKQVAdapterWeightTying": {},
  "LoraKQVAdapterWeightTyingConfig": {},
  "DownSampleBlock": {
    "forward": [
      "self",
      "x"
    ],
    "flat_square": [
      "self",
      "x"
    ]
  },
  "MultimodalProjectorAdapter": {
    "__init__": [
      "self",
      "adapter_type",
      "in_features",
      "out_features",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MultimodalProjectorAdapterConfig": {},
  "AbstractEmbModel": {
    "__init__": [
      "self",
      "enable_lora_finetune",
      "target_block",
      "target_module"
    ],
    "is_trainable": [
      "self"
    ],
    "ucg_rate": [
      "self"
    ],
    "input_key": [
      "self"
    ],
    "encode": [
      "self"
    ],
    "_enable_lora": [
      "self",
      "lora_model"
    ]
  },
  "FrozenCLIPEmbedder": {
    "LAYERS": [],
    "__init__": [
      "self",
      "version",
      "device",
      "max_length",
      "enable_lora_finetune",
      "layer",
      "layer_idx",
      "always_return_pooled",
      "dtype"
    ],
    "freeze": [
      "self"
    ],
    "forward": [
      "self",
      "text",
      "max_sequence_length"
    ],
    "encode": [
      "self",
      "text"
    ]
  },
  "FrozenT5Embedder": {
    "__init__": [
      "self",
      "version",
      "max_length",
      "device",
      "dtype",
      "load_config_only"
    ],
    "freeze": [
      "self"
    ],
    "forward": [
      "self",
      "text",
      "max_sequence_length"
    ]
  },
  "configs": [],
  "_import_qkv_bias": [
    "transformer_config",
    "qb",
    "kb",
    "vb"
  ],
  "_import_qkv": [
    "transformer_config",
    "q",
    "k",
    "v"
  ],
  "flux_key_mapping": [],
  "flux_transformer_converter": [
    "ckpt_path",
    "transformer_config"
  ],
  "Utils": {
    "world_size": [],
    "rank": [],
    "initialize_distributed": [
      "tensor_model_parallel_size",
      "pipeline_model_parallel_size",
      "context_parallel_size"
    ],
    "set_world_size": [
      "world_size",
      "rank"
    ],
    "destroy_model_parallel": [],
    "initialize_model_parallel": [
      "tensor_model_parallel_size",
      "pipeline_model_parallel_size",
      "virtual_pipeline_model_parallel_size",
      "pipeline_model_parallel_split_rank"
    ]
  },
  "NAME": [],
  "flux_mock_datamodule": [],
  "pretrain_recipe": [
    "dir",
    "name",
    "num_nodes",
    "num_gpus_per_node",
    "fn"
  ],
  "DummyModelParams": {
    "__post_init__": [
      "self"
    ]
  },
  "unit_test_recipe": [
    "name",
    "dir",
    "num_nodes",
    "num_gpus_per_node"
  ],
  "common_broadcast": [
    "x",
    "y"
  ],
  "batch_add": [
    "x",
    "y"
  ],
  "batch_mul": [
    "x",
    "y"
  ],
  "batch_sub": [
    "x",
    "y"
  ],
  "batch_div": [
    "x",
    "y"
  ],
  "cat_outputs_cp": [
    "x",
    "seq_dim",
    "cp_group"
  ],
  "EDMScaling": {
    "__init__": [
      "self",
      "sigma_data"
    ],
    "__call__": [
      "self",
      "sigma"
    ]
  },
  "EDMSDE": {
    "__init__": [
      "self",
      "p_mean",
      "p_std",
      "sigma_max",
      "sigma_min"
    ],
    "sample_t": [
      "self",
      "batch_size"
    ],
    "marginal_prob": [
      "self",
      "x0",
      "sigma"
    ]
  },
  "EDMSampler": {
    "forward": [
      "self",
      "x0_fn",
      "x_sigma_max",
      "num_steps",
      "sigma_min",
      "sigma_max",
      "rho",
      "S_churn",
      "S_min",
      "S_max",
      "S_noise"
    ]
  },
  "EDMPipeline": {
    "__init__": [
      "self",
      "net",
      "vae",
      "p_mean",
      "p_std",
      "sigma_max",
      "sigma_min",
      "sigma_data",
      "seed"
    ],
    "noise_level_generator": [
      "self"
    ],
    "_initialize_generators": [
      "self"
    ],
    "training_step": [
      "self",
      "data_batch",
      "iteration"
    ],
    "denoise": [
      "self",
      "xt",
      "sigma",
      "condition"
    ],
    "compute_loss_with_epsilon_and_sigma": [
      "self",
      "data_batch",
      "x0_from_data_batch",
      "x0",
      "condition",
      "epsilon",
      "sigma"
    ],
    "get_per_sigma_loss_weights": [
      "self",
      "sigma"
    ],
    "get_condition_uncondition": [
      "self",
      "data_batch"
    ],
    "get_x0_fn_from_batch": [
      "self",
      "data_batch",
      "guidance",
      "is_negative_prompt"
    ],
    "generate_samples_from_batch": [
      "self",
      "data_batch",
      "guidance",
      "state_shape",
      "is_negative_prompt",
      "num_steps"
    ],
    "draw_training_sigma_and_epsilon": [
      "self",
      "x0_size",
      "condition"
    ],
    "random_dropout_input": [
      "self",
      "in_tensor",
      "dropout_rate"
    ],
    "get_data_and_condition": [
      "self",
      "data_batch",
      "dropout_rate"
    ]
  },
  "FlowMatchEulerDiscreteScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "shift",
      "use_dynamic_shifting",
      "base_shift",
      "max_shift",
      "base_image_seq_len",
      "max_image_seq_len"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "scale_noise": [
      "self",
      "sample",
      "timestep",
      "noise"
    ],
    "_sigma_to_t": [
      "self",
      "sigma"
    ],
    "time_shift": [
      "self",
      "mu",
      "sigma",
      "t"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "sigmas",
      "mu"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "s_churn",
      "s_tmin",
      "s_tmax",
      "s_noise",
      "generator"
    ],
    "__len__": [
      "self"
    ]
  },
  "LinearAttention": {
    "__init__": [
      "self",
      "dim",
      "heads",
      "dim_head"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LinAttnBlock": {
    "__init__": [
      "self",
      "in_channels"
    ]
  },
  "make_attn": [
    "in_channels",
    "attn_type"
  ],
  "validate_vae": [],
  "AutoencoderKLVAE": {
    "__init__": [
      "self",
      "path"
    ],
    "decode": [
      "self",
      "x"
    ]
  },
  "TestVAEGenerator": {
    "setUp": [
      "self"
    ],
    "test_initialization_valid": [
      "self"
    ],
    "test_initialization_invalid": [
      "self"
    ],
    "test_generate_input": [
      "self"
    ],
    "test_count_parameters": [
      "self"
    ],
    "test_load_base_json_skeleton": [
      "self"
    ],
    "test_generate_all_combinations": [
      "self"
    ],
    "test_assign_attributes": [
      "self"
    ],
    "test_search_space_16x1024": [
      "self"
    ],
    "test_sort_data_in_place": [
      "self"
    ],
    "test_search_for_target_vae_invalid": [
      "self"
    ]
  },
  "LPIPSWithDiscriminator": {
    "__init__": [
      "self",
      "disc_start",
      "logvar_init",
      "kl_weight",
      "pixelloss_weight",
      "disc_num_layers",
      "disc_in_channels",
      "disc_factor",
      "disc_weight",
      "perceptual_weight",
      "use_actnorm",
      "disc_conditional",
      "disc_loss"
    ],
    "calculate_adaptive_weight": [
      "self",
      "nll_loss",
      "g_loss",
      "last_layer"
    ],
    "forward": [
      "self",
      "inputs",
      "reconstructions",
      "posteriors",
      "optimizer_idx",
      "global_step",
      "last_layer",
      "cond",
      "weights"
    ]
  },
  "VAEGenerator": {
    "__init__": [
      "self",
      "input_resolution",
      "compression_ratio"
    ],
    "_generate_input": [
      "self"
    ],
    "_count_parameters": [
      "self",
      "model"
    ],
    "_load_base_json_skeleton": [
      "self"
    ],
    "_generate_all_combinations": [
      "self",
      "attr"
    ],
    "_assign_attributes": [
      "self",
      "choice"
    ],
    "_search_space_16x1024": [
      "self"
    ],
    "_search_space_8x1024": [
      "self"
    ],
    "_sort_data_in_place": [
      "self",
      "data",
      "mode"
    ],
    "_print_table": [
      "self",
      "data",
      "headers",
      "col_widths"
    ],
    "search_for_target_vae": [
      "self",
      "parameters_budget",
      "cuda_max_mem"
    ],
    "input_resolution": [
      "self"
    ],
    "compression_ratio": [
      "self"
    ]
  },
  "AutoEncoderConfig": {},
  "DiagonalGaussian": {
    "__init__": [
      "self",
      "sample",
      "chunk_dim"
    ],
    "forward": [
      "self",
      "z"
    ]
  },
  "AutoEncoder": {
    "__init__": [
      "self",
      "params"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "z"
    ],
    "forward": [
      "self",
      "x"
    ],
    "load_from_checkpoint": [
      "self",
      "ckpt_path"
    ]
  },
  "AvgLossReduction": {
    "forward": [
      "self",
      "batch",
      "forward_out"
    ],
    "reduce": [
      "self",
      "losses_reduced_per_micro_batch"
    ]
  },
  "VAE": {
    "__init__": [
      "self",
      "config",
      "pretrained_model_name_or_path",
      "search_vae"
    ],
    "forward": [
      "self",
      "target",
      "global_step"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ]
  },
  "VAEModel": {
    "__init__": [
      "self",
      "pretrained_model_name_or_path",
      "optim",
      "model_transform"
    ],
    "configure_model": [
      "self"
    ],
    "data_step": [
      "self",
      "dataloader_iter"
    ],
    "forward": [
      "self"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ],
    "on_validation_model_zero_grad": [
      "self"
    ]
  },
  "crop_image": [
    "img",
    "divisor"
  ],
  "ImageTaskEncoder": {
    "encode_sample": [
      "self",
      "sample"
    ]
  },
  "train_vae": [],
  "initialize_text_encoder": [
    "t5_cache_dir"
  ],
  "df": [],
  "autoencoder": [],
  "t5_cache_dir": [],
  "EncodedSample": {
    "__init__": [
      "self",
      "encoded_text",
      "length",
      "attn_mask",
      "offset_mappings"
    ],
    "truncate": [
      "self"
    ]
  },
  "encode_for_batch": [
    "tokenizer",
    "encoder",
    "prompts",
    "truncate",
    "max_length",
    "output_mapping"
  ],
  "generate_t5_embed": [
    "tokenizer",
    "text_encoder",
    "prompt",
    "t5_embeding_max_length"
  ],
  "get_start_end_idx_for_this_rank": [
    "dataset_size",
    "rank",
    "world_size"
  ],
  "butterfly_process_func": [
    "index"
  ],
  "prepare": [
    "process_func",
    "output_dir"
  ],
  "prepare_butterfly_dataset": [],
  "DiffusionSample": {
    "to_dict": [
      "self"
    ],
    "__add__": [
      "self",
      "other"
    ],
    "__radd__": [
      "self",
      "other"
    ],
    "__lt__": [
      "self",
      "other"
    ]
  },
  "cook": [
    "sample"
  ],
  "BasicDiffusionTaskEncoder": {
    "cookers": [],
    "__init__": [
      "self"
    ],
    "encode_sample": [
      "self",
      "sample"
    ],
    "select_samples_to_pack": [
      "self",
      "samples"
    ],
    "pack_selected_samples": [
      "self",
      "samples"
    ],
    "batch": [
      "self",
      "samples"
    ]
  },
  "PosID3D": {
    "__init__": [
      "self"
    ],
    "generate_pos_id": [
      "self"
    ],
    "get_pos_id_3d": [
      "self"
    ]
  },
  "pad_divisible": [
    "x",
    "padding_value"
  ],
  "concat_pad": [
    "tensor_list",
    "max_seq_length"
  ],
  "pos_id_3d": [],
  "cook_raw_images": [
    "sample"
  ],
  "RawImageDiffusionTaskEncoder": {
    "cookers": []
  },
  "DiffusionDataModule": {
    "__init__": [
      "self",
      "path",
      "seq_length",
      "micro_batch_size",
      "global_batch_size",
      "num_workers",
      "pin_memory",
      "task_encoder",
      "use_train_split_for_val",
      "virtual_epoch_length",
      "packing_buffer_size",
      "max_samples_per_sequence"
    ],
    "datasets_provider": [
      "self",
      "worker_config",
      "split"
    ],
    "val_dataloader": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "PosEmb3D": {
    "__init__": [
      "self"
    ],
    "generate_pos_id": [
      "self"
    ],
    "get_pos_id_3d": [
      "self"
    ]
  },
  "DiTVideoLatentFakeDataset": {
    "__init__": [
      "self",
      "n_frames",
      "max_h",
      "max_w",
      "patch_size",
      "in_channels",
      "crossattn_emb_size",
      "max_text_seqlen",
      "seq_length"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "VideoLatentFakeDataModule": {
    "__init__": [
      "self",
      "model_config",
      "seq_length",
      "micro_batch_size",
      "global_batch_size",
      "num_workers",
      "pin_memory",
      "task_encoder",
      "use_train_split_for_val"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "_create_dataloader": [
      "self",
      "dataset"
    ]
  },
  "_MockT2IDataset": {
    "__init__": [
      "self",
      "image_H",
      "image_W",
      "length",
      "image_key",
      "txt_key",
      "hint_key",
      "image_precached",
      "text_precached",
      "prompt_seq_len",
      "pooled_prompt_dim",
      "context_dim",
      "vae_scale_factor",
      "vae_channels"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "dit_forward_step": [
    "model",
    "batch"
  ],
  "dit_data_step": [
    "module",
    "dataloader_iter"
  ],
  "get_batch_on_this_cp_rank": [
    "data"
  ],
  "DiTConfig": {
    "layernorm_epsilon": [],
    "normalization": [],
    "add_bias_linear": [],
    "qk_layernorm_per_head": [],
    "layernorm_zero_centered_gamma": [],
    "data_step_fn": [],
    "forward_step_fn": [],
    "replicated_t_embedder": [],
    "configure_model": [
      "self",
      "tokenizer",
      "vp_stage"
    ],
    "configure_vae": [
      "self"
    ]
  },
  "DiTBConfig": {},
  "DiTLConfig": {},
  "DiTXLConfig": {},
  "DiT7BConfig": {},
  "DiTLlama30BConfig": {},
  "DiTLlama5BConfig": {},
  "DiTLlama1BConfig": {},
  "ECDiTLlama1BConfig": {},
  "DiTModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "model_transform",
      "tokenizer"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "data_step": [
      "self",
      "dataloader_iter"
    ],
    "forward": [
      "self"
    ],
    "forward_step": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_validation_start": [
      "self"
    ],
    "on_validation_end": [
      "self"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ],
    "on_validation_model_zero_grad": [
      "self"
    ]
  },
  "DummyLossReduction": {
    "__init__": [
      "self",
      "validation_step",
      "val_drop_last"
    ],
    "forward": [
      "self",
      "batch",
      "forward_out"
    ],
    "reduce": [
      "self",
      "losses_reduced_per_micro_batch"
    ]
  },
  "dynamic_import": [
    "full_path"
  ],
  "DiTLlamaModel": {
    "__init__": [
      "self",
      "config",
      "pre_process",
      "post_process",
      "fp16_lm_cross_entropy",
      "parallel_output",
      "position_embedding_type",
      "max_img_h",
      "max_img_w",
      "max_frames",
      "patch_spatial",
      "patch_temporal",
      "in_channels",
      "out_channels",
      "vp_stage"
    ]
  },
  "MoviegGenLayer": {
    "__init__": [
      "self",
      "config",
      "submodules",
      "layer_number",
      "hidden_dropout",
      "position_embedding_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "inference_params",
      "packed_seq_params"
    ]
  },
  "_get_mlp_module_spec": [
    "use_te",
    "num_experts",
    "moe_grouped_gemm",
    "fp8"
  ],
  "get_dit_llama_spec": [
    "num_experts",
    "attn_mask_type"
  ],
  "DiTWithAdaLNSubmodules": {},
  "STDiTWithAdaLNSubmodules": {},
  "RMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "config",
      "eps"
    ],
    "_norm": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AdaLN": {
    "__init__": [
      "self",
      "config",
      "n_adaln_chunks",
      "norm",
      "modulation_bias",
      "use_second_norm"
    ],
    "forward": [
      "self",
      "timestep_emb"
    ],
    "modulate": [
      "self",
      "x",
      "shift",
      "scale"
    ],
    "scale_add": [
      "self",
      "residual",
      "x",
      "gate"
    ],
    "modulated_layernorm": [
      "self",
      "x",
      "shift",
      "scale",
      "layernorm_idx"
    ],
    "scaled_modulated_layernorm": [
      "self",
      "residual",
      "x",
      "gate",
      "shift",
      "scale",
      "layernorm_idx"
    ]
  },
  "AdaLNContinuous": {
    "__init__": [
      "self",
      "config",
      "conditioning_embedding_dim",
      "modulation_bias",
      "norm_type"
    ],
    "forward": [
      "self",
      "x",
      "conditioning_embedding"
    ]
  },
  "STDiTLayerWithAdaLN": {
    "__init__": [
      "self",
      "config",
      "submodules",
      "layer_number",
      "hidden_dropout",
      "position_embedding_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "inference_params",
      "packed_seq_params"
    ]
  },
  "DiTLayerWithAdaLN": {
    "__init__": [
      "self",
      "config",
      "submodules",
      "layer_number",
      "hidden_dropout",
      "position_embedding_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "inference_params",
      "packed_seq_params"
    ]
  },
  "DiTLayer": {
    "__init__": [
      "self",
      "config",
      "submodules",
      "layer_number",
      "mlp_ratio",
      "n_adaln_chunks",
      "modulation_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "inference_params",
      "packed_seq_params"
    ]
  },
  "MMDiTLayer": {
    "__init__": [
      "self",
      "config",
      "submodules",
      "layer_number",
      "context_pre_only"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "inference_params",
      "packed_seq_params",
      "emb"
    ],
    "__call__": [
      "self"
    ]
  },
  "FluxSingleTransformerBlock": {
    "__init__": [
      "self",
      "config",
      "submodules",
      "layer_number",
      "mlp_ratio",
      "n_adaln_chunks",
      "modulation_bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "inference_params",
      "packed_seq_params",
      "emb"
    ],
    "__call__": [
      "self"
    ]
  },
  "get_stdit_adaln_block_with_transformer_engine_spec": [],
  "get_dit_adaln_block_with_transformer_engine_spec": [
    "attn_mask_type"
  ],
  "get_official_dit_adaln_block_with_transformer_engine_spec": [],
  "get_mm_dit_block_with_transformer_engine_spec": [],
  "get_flux_single_transformer_engine_spec": [],
  "get_flux_double_transformer_engine_spec": [],
  "modulate": [
    "x",
    "shift",
    "scale"
  ],
  "FinalLayer": {
    "__init__": [
      "self",
      "hidden_size",
      "spatial_patch_size",
      "temporal_patch_size",
      "out_channels"
    ],
    "forward": [
      "self",
      "x_BT_HW_D",
      "emb_B_D"
    ]
  },
  "DiTCrossAttentionModel": {
    "__init__": [
      "self",
      "config",
      "pre_process",
      "post_process",
      "fp16_lm_cross_entropy",
      "parallel_output",
      "position_embedding_type",
      "max_img_h",
      "max_img_w",
      "max_frames",
      "patch_spatial",
      "patch_temporal",
      "in_channels",
      "out_channels",
      "transformer_decoder_layer_spec",
      "pos_embedder",
      "vp_stage"
    ],
    "forward": [
      "self",
      "x",
      "timesteps",
      "crossattn_emb",
      "packed_seq_params",
      "pos_ids"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ],
    "_set_embedder_weights_replica_id": [
      "self",
      "tensor",
      "sharded_state_dict",
      "embedder_weight_key"
    ]
  },
  "JointSelfAttentionSubmodules": {},
  "JointSelfAttention": {
    "__init__": [
      "self",
      "config",
      "submodules",
      "layer_number",
      "attn_mask_type",
      "context_pre_only"
    ],
    "_split_qkv": [
      "self",
      "mixed_qkv"
    ],
    "get_query_key_value_tensors": [
      "self",
      "hidden_states",
      "key_value_states"
    ],
    "get_added_query_key_value_tensors": [
      "self",
      "added_hidden_states",
      "key_value_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "key_value_states",
      "inference_params",
      "rotary_pos_emb",
      "packed_seq_params",
      "additional_hidden_states"
    ]
  },
  "FluxSingleAttention": {
    "__init__": [
      "self",
      "config",
      "submodules",
      "layer_number",
      "attn_mask_type",
      "cp_comm_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "key_value_states",
      "inference_params",
      "rotary_pos_emb",
      "packed_seq_params"
    ]
  },
  "ParallelTimestepEmbedding": {
    "__init__": [
      "self",
      "in_channels",
      "time_embed_dim",
      "seed"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_pos_emb_on_this_cp_rank": [
    "pos_emb",
    "seq_dim"
  ],
  "SinCosPosEmb3D": {
    "__init__": [
      "self",
      "config",
      "h",
      "w",
      "t",
      "spatial_interpolation_scale",
      "temporal_interpolation_scale"
    ],
    "forward": [
      "self",
      "pos_ids"
    ]
  },
  "FactorizedLearnable3DEmbedding": {
    "__init__": [
      "self",
      "config",
      "t",
      "h",
      "w"
    ],
    "customize_init_param": [
      "self"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "pos_ids"
    ]
  },
  "FluxInferencePipeline": {
    "__init__": [
      "self",
      "params",
      "flux",
      "vae",
      "t5",
      "clip",
      "scheduler_steps"
    ],
    "load_from_pretrained": [
      "self",
      "ckpt_path",
      "do_convert_from_hf",
      "save_converted_model_to"
    ],
    "encoder_prompt": [
      "self",
      "prompt",
      "num_images_per_prompt",
      "prompt_embeds",
      "pooled_prompt_embeds",
      "max_sequence_length",
      "device",
      "dtype"
    ],
    "_prepare_latent_image_ids": [
      "batch_size",
      "height",
      "width",
      "device",
      "dtype"
    ],
    "_pack_latents": [
      "latents",
      "batch_size",
      "num_channels_latents",
      "height",
      "width"
    ],
    "_unpack_latents": [
      "latents",
      "height",
      "width",
      "vae_scale_factor"
    ],
    "_calculate_shift": [
      "image_seq_len",
      "base_seq_len",
      "max_seq_len",
      "base_shift",
      "max_shift"
    ],
    "prepare_latents": [
      "self",
      "batch_size",
      "num_channels_latents",
      "height",
      "width",
      "dtype",
      "device",
      "generator",
      "latents"
    ],
    "_generate_rand_latents": [
      "shape",
      "generator",
      "device",
      "dtype",
      "batch_size"
    ],
    "numpy_to_pil": [
      "images"
    ],
    "torch_to_numpy": [
      "images"
    ],
    "denormalize": [
      "image"
    ],
    "__call__": [
      "self",
      "prompt",
      "height",
      "width",
      "num_inference_steps",
      "timesteps",
      "guidance_scale",
      "num_images_per_prompt",
      "generator",
      "latents",
      "prompt_embeds",
      "pooled_prompt_embeds",
      "output_type",
      "max_sequence_length",
      "device",
      "dtype",
      "save_to_disk",
      "offload",
      "output_path"
    ]
  },
  "FluxControlNetInferencePipeline": {
    "__init__": [
      "self",
      "params",
      "contorlnet_config",
      "flux",
      "vae",
      "t5",
      "clip",
      "scheduler_steps",
      "flux_controlnet"
    ],
    "load_from_pretrained": [
      "self",
      "flux_ckpt_path",
      "controlnet_ckpt_path",
      "do_convert_from_hf",
      "save_converted_model_to"
    ],
    "pil_to_numpy": [
      "self",
      "images"
    ],
    "numpy_to_pt": [
      "self",
      "images"
    ],
    "prepare_image": [
      "self",
      "images",
      "height",
      "width",
      "batch_size",
      "num_images_per_prompt",
      "device",
      "dtype"
    ],
    "__call__": [
      "self",
      "prompt",
      "height",
      "width",
      "num_inference_steps",
      "timesteps",
      "guidance_scale",
      "num_images_per_prompt",
      "generator",
      "latents",
      "prompt_embeds",
      "pooled_prompt_embeds",
      "output_type",
      "max_sequence_length",
      "device",
      "dtype",
      "save_to_disk",
      "offload",
      "control_guidance_start",
      "control_guidance_end",
      "control_image",
      "controlnet_conditioning_scale",
      "output_path"
    ]
  },
  "flux_data_step": [
    "dataloader_iter"
  ],
  "FluxConfig": {
    "save_converted_model_to": [],
    "configure_model": [
      "self"
    ]
  },
  "T5Config": {},
  "ClipConfig": {},
  "FluxModelParams": {},
  "Flux": {
    "__init__": [
      "self",
      "config"
    ],
    "get_fp8_context": [
      "self"
    ],
    "forward": [
      "self",
      "img",
      "txt",
      "y",
      "timesteps",
      "img_ids",
      "txt_ids",
      "guidance",
      "controlnet_double_block_samples",
      "controlnet_single_block_samples"
    ],
    "load_from_pretrained": [
      "self",
      "ckpt_path",
      "do_convert_from_hf",
      "save_converted_model_to",
      "load_dist_ckpt"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "MegatronFluxModel": {
    "__init__": [
      "self",
      "flux_params",
      "optim",
      "seed"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "configure_model": [
      "self"
    ],
    "configure_scheduler": [
      "self"
    ],
    "configure_vae": [
      "self",
      "vae"
    ],
    "configure_text_encoders": [
      "self",
      "clip",
      "t5"
    ],
    "data_step": [
      "self",
      "dataloader_iter"
    ],
    "forward": [
      "self"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "forward_step": [
      "self",
      "batch"
    ],
    "encode_prompt": [
      "self",
      "prompt",
      "device",
      "dtype"
    ],
    "compute_density_for_timestep_sampling": [
      "self",
      "weighting_scheme",
      "batch_size",
      "logit_mean",
      "logit_std",
      "mode_scale"
    ],
    "prepare_image_latent": [
      "self",
      "latents"
    ],
    "_unpack_latents": [
      "self",
      "latents",
      "height",
      "width"
    ],
    "_prepare_latent_image_ids": [
      "self",
      "batch_size",
      "height",
      "width",
      "device",
      "dtype"
    ],
    "_pack_latents": [
      "self",
      "latents",
      "batch_size",
      "num_channels_latents",
      "height",
      "width"
    ],
    "set_input_tensor": [
      "self",
      "tensor"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "HFFluxImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "config": [
      "self"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ]
  },
  "import_double_block_qkv": [
    "ctx",
    "q",
    "k",
    "v"
  ],
  "import_double_block_qkv_bias": [
    "ctx",
    "qb",
    "kb",
    "vb"
  ],
  "import_added_qkv": [
    "ctx",
    "q",
    "k",
    "v"
  ],
  "import_added_qkv_bias": [
    "ctx",
    "qb",
    "kb",
    "vb"
  ],
  "import_single_block_qkv": [
    "ctx",
    "q",
    "k",
    "v"
  ],
  "import_single_block_qkv_bias": [
    "ctx",
    "qb",
    "kb",
    "vb"
  ],
  "transform_single_proj_out": [
    "proj_weight"
  ],
  "rope": [
    "pos",
    "dim",
    "theta"
  ],
  "EmbedND": {
    "__init__": [
      "self",
      "dim",
      "theta",
      "axes_dim"
    ],
    "forward": [
      "self",
      "ids"
    ]
  },
  "MLPEmbedder": {
    "__init__": [
      "self",
      "in_dim",
      "hidden_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_timestep_embedding": [
    "timesteps",
    "embedding_dim",
    "flip_sin_to_cos",
    "downscale_freq_shift",
    "scale",
    "max_period"
  ],
  "Timesteps": {
    "__init__": [
      "self",
      "embedding_dim",
      "flip_sin_to_cos",
      "downscale_freq_shift",
      "scale",
      "max_period"
    ],
    "forward": [
      "self",
      "timesteps"
    ]
  },
  "TimeStepEmbedder": {
    "__init__": [
      "self",
      "embedding_dim",
      "hidden_dim",
      "flip_sin_to_cos",
      "downscale_freq_shift",
      "scale",
      "max_period"
    ],
    "forward": [
      "self",
      "timesteps"
    ]
  },
  "zero_module": [
    "module"
  ],
  "flux_controlnet_data_step": [
    "dataloader_iter"
  ],
  "FluxControlNetConfig": {},
  "FluxControlNet": {
    "__init__": [
      "self",
      "config"
    ],
    "load_from_flux_transformer": [
      "self",
      "flux"
    ],
    "get_fp8_context": [
      "self"
    ],
    "forward": [
      "self",
      "img",
      "controlnet_cond",
      "txt",
      "y",
      "timesteps",
      "img_ids",
      "txt_ids",
      "guidance",
      "conditioning_scale"
    ]
  },
  "FluxControlnetForwardWrapper": {
    "__init__": [
      "self",
      "flux_config",
      "flux_controlnet_config"
    ],
    "forward": [
      "self",
      "packed_noisy_model_input",
      "control_image",
      "prompt_embeds",
      "pooled_prompt_embeds",
      "timesteps",
      "latent_image_ids",
      "text_ids",
      "guidance_vec"
    ]
  },
  "MegatronFluxControlNetModel": {
    "__init__": [
      "self",
      "flux_params",
      "flux_controlnet_config",
      "seed"
    ],
    "configure_model": [
      "self"
    ],
    "data_step": [
      "self",
      "dataloader_iter"
    ],
    "forward": [
      "self"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "forward_step": [
      "self",
      "batch"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ]
  },
  "ControlNetConditioningEmbedding": {
    "__init__": [
      "self",
      "conditioning_embedding_channels",
      "conditioning_channels",
      "block_out_channels"
    ],
    "forward": [
      "self",
      "conditioning"
    ]
  },
  "create_image_processor": [],
  "finetune_recipe": [
    "checkpoint_path",
    "dir",
    "name",
    "num_nodes",
    "num_gpus_per_node",
    "peft_scheme",
    "freeze_modules"
  ],
  "_MockAVLMDataset": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "audio_processor",
      "image_embedding_tokens",
      "audio_embedding_tokens",
      "name",
      "num_samples",
      "seq_length",
      "seed"
    ],
    "__len__": [
      "self"
    ],
    "_get_text": [
      "self",
      "idx"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "calculate_encoded_audio_seq_length": [
    "model_type",
    "audio_length",
    "fixed_max_audio_length",
    "sample_rate",
    "window_stride",
    "encoder_down_sampling",
    "num_mel_bins",
    "patch_size",
    "time_stride",
    "frequency_stride",
    "max_spectrogram_length"
  ],
  "calculate_encoded_image_seq_length": [
    "num_one_image_tiles",
    "model_type",
    "img_width",
    "img_height",
    "patch_size",
    "projection_downsample_factor"
  ],
  "AVLMSampleEncoder": {
    "__init__": [
      "self",
      "tokenizer",
      "audio_processor",
      "image_processor",
      "multimodal_sample_config"
    ],
    "build_tokenizer": [
      "self"
    ],
    "build_audio_processor": [
      "self"
    ],
    "build_image_processor": [
      "self"
    ],
    "_process_audio_from_decoded": [
      "self",
      "audio",
      "sample_rate"
    ],
    "process_audio": [
      "self",
      "audio",
      "mode"
    ],
    "process_video": [
      "self",
      "video"
    ],
    "process_image": [
      "self",
      "image"
    ]
  },
  "AVLMSampleEncoderQA": {
    "__init__": [
      "self",
      "tokenizer",
      "audio_processor",
      "image_processor",
      "multimodal_sample_config"
    ],
    "tokenize": [
      "self",
      "prompt",
      "input_sample"
    ],
    "encode": [
      "self",
      "input_sample",
      "output_sample"
    ]
  },
  "AVLMTaskEncoder": {
    "__init__": [
      "self",
      "tokenizer",
      "audio_processor",
      "image_processor",
      "multimodal_sample_config",
      "packed_sequence",
      "packed_sequence_size"
    ],
    "encode_sample": [
      "self",
      "sample"
    ],
    "batch": [
      "self",
      "samples"
    ],
    "encode_batch": [
      "self",
      "batch_data"
    ],
    "select_samples_to_pack": [
      "self",
      "samples"
    ],
    "pack_selected_samples": [
      "self",
      "samples"
    ]
  },
  "flatten_if_nested": [
    "lst"
  ],
  "AVLMDataModule": {
    "__init__": [
      "self",
      "path",
      "tokenizer",
      "audio_processor",
      "image_processor",
      "seq_length",
      "micro_batch_size",
      "global_batch_size",
      "num_workers",
      "num_val_workers",
      "pin_memory",
      "shuffle_buffer_size",
      "max_samples_per_sequence",
      "multimodal_sample_config",
      "task_encoder",
      "decoder_seq_length",
      "packing_buffer_size",
      "validation_task_encoder"
    ]
  },
  "AudioSize": {},
  "VideoSize": {},
  "ImageSize": {},
  "MediaDict": {},
  "AVLMEnergonInterleavedSample": {},
  "AVLMEnergonQASample": {},
  "AVLMSample": {},
  "PackedAVLMSample": {},
  "AVLMRawBatch": {},
  "PackedAVLMRawBatch": {},
  "AVLMSampleConfig": {},
  "AVLMConfig8B": {},
  "MODEL_CONFIG_ATTR": [],
  "restore_model_weights": [
    "model",
    "checkpoint_path",
    "strict"
  ],
  "avlm_data_step": [
    "dataloader_iter"
  ],
  "avlm_forward_step": [
    "model",
    "batch"
  ],
  "AVLMConfig": {
    "__post_init__": [
      "self"
    ],
    "configure_model": [
      "self",
      "tokenizer"
    ]
  },
  "MCoreAVLMModel": {
    "__init__": [
      "self",
      "config",
      "tokenizer",
      "pre_process",
      "post_process",
      "add_encoder",
      "add_decoder",
      "drop_vision_class_token"
    ],
    "combine_embeddings": [
      "self",
      "input_ids",
      "image_embeddings",
      "audio_embeddings",
      "language_embeddings",
      "image_token_index",
      "audio_token_index",
      "use_inference_kv_cache",
      "packed_seq_params"
    ],
    "pad_sequence": [
      "self",
      "combined_embeddings",
      "labels",
      "loss_mask",
      "packed_seq_params"
    ],
    "truncate_sequence": [
      "self",
      "combined_embeddings",
      "labels",
      "loss_mask",
      "packed_seq_params"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "loss_mask",
      "attention_mask",
      "labels",
      "images",
      "num_image_tiles",
      "image_token_index",
      "audios",
      "audio_lengths",
      "audio_token_index",
      "inference_params",
      "runtime_gather_output",
      "packed_seq_params"
    ],
    "freeze": [
      "self",
      "freeze_language_model",
      "freeze_vision_model",
      "freeze_vision_projection",
      "freeze_audio_model",
      "freeze_audio_projection"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ],
    "_get_shard_factor": [
      "self",
      "packed_seq_params"
    ],
    "_process_embedding_token_parallel": [
      "self",
      "combined_embeddings",
      "new_labels",
      "new_loss_mask",
      "packed_seq_params"
    ]
  },
  "AVLMModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "configure_model": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "loss_mask",
      "attention_mask",
      "labels",
      "images",
      "num_image_tiles",
      "image_token_index",
      "audios",
      "audio_lengths",
      "audio_token_index",
      "inference_params",
      "runtime_gather_output",
      "packed_seq_params"
    ],
    "data_step": [
      "self",
      "dataloader_iter"
    ],
    "forward_step": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "temporary_model_parallel_size": [
    "app_state",
    "temp_value"
  ],
  "GRAPHEME_CASE_UPPER": [],
  "GRAPHEME_CASE_LOWER": [],
  "GRAPHEME_CASE_MIXED": [],
  "read_wordids": [
    "wordid_map"
  ],
  "get_wordid_to_phonemes": [
    "wordid_to_phonemes_file",
    "to_lower"
  ],
  "remove_punctuation": [
    "text",
    "remove_spaces",
    "do_lower",
    "exclude"
  ],
  "get_heteronym_spans": [
    "sentences",
    "supported_heteronyms"
  ],
  "set_grapheme_case": [
    "text",
    "case"
  ],
  "HeteronymClassificationDataset": {
    "__init__": [
      "self",
      "manifest",
      "tokenizer",
      "heteronym_dict",
      "wordid_to_idx",
      "max_seq_len",
      "grapheme_field",
      "with_labels"
    ],
    "_prepare_sample": [
      "self",
      "sentence",
      "start_end",
      "heteronyms",
      "word_ids"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "T5G2PDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "tokenizer",
      "max_source_len",
      "max_target_len",
      "do_lower",
      "grapheme_field",
      "phoneme_field",
      "with_labels"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "CTCG2PBPEDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "tokenizer_graphemes",
      "tokenizer_phonemes",
      "do_lower",
      "labels",
      "max_source_len",
      "phoneme_field",
      "grapheme_field",
      "with_labels"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "map": [
      "self",
      "text"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "BaseG2p": {
    "__init__": [
      "self",
      "phoneme_dict",
      "word_tokenize_func",
      "apply_to_oov_word",
      "mapping_file"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "EnglishG2p": {
    "__init__": [
      "self",
      "phoneme_dict",
      "word_tokenize_func",
      "apply_to_oov_word",
      "ignore_ambiguous_words",
      "heteronyms",
      "encoding",
      "phoneme_probability",
      "mapping_file"
    ],
    "_parse_as_cmu_dict": [
      "phoneme_dict_path",
      "encoding"
    ],
    "_parse_file_by_lines": [
      "p",
      "encoding"
    ],
    "is_unique_in_phoneme_dict": [
      "self",
      "word"
    ],
    "parse_one_word": [
      "self",
      "word"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "Classifier": {
    "input_types": [
      "self"
    ],
    "__init__": [
      "self",
      "hidden_size",
      "dropout"
    ],
    "post_init": [
      "self",
      "use_transformer_init"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "save_to": [
      "self",
      "save_path"
    ],
    "restore_from": [
      "cls",
      "restore_path"
    ]
  },
  "TokenClassifier": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "hidden_size",
      "num_classes",
      "num_layers",
      "activation",
      "log_softmax",
      "dropout",
      "use_transformer_init"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ChineseG2p": {
    "__init__": [
      "self",
      "phoneme_dict",
      "phoneme_prefix",
      "phoneme_case",
      "tone_prefix",
      "ascii_letter_prefix",
      "ascii_letter_case",
      "word_tokenize_func",
      "apply_to_oov_word",
      "mapping_file",
      "word_segmenter"
    ],
    "_parse_as_pinyin_dict": [
      "phoneme_dict_path",
      "phoneme_prefix",
      "phoneme_case"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "IpaG2p": {
    "STRESS_SYMBOLS": [],
    "CHAR_REGEX": [],
    "PUNCT_REGEX": [],
    "__init__": [
      "self",
      "phoneme_dict",
      "locale",
      "apply_to_oov_word",
      "ignore_ambiguous_words",
      "heteronyms",
      "use_chars",
      "phoneme_probability",
      "use_stresses",
      "grapheme_case",
      "grapheme_prefix",
      "mapping_file"
    ],
    "_parse_phoneme_dict": [
      "phoneme_dict"
    ],
    "replace_dict": [
      "self",
      "phoneme_dict"
    ],
    "_parse_file_by_lines": [
      "p"
    ],
    "_prepend_prefix_for_one_word": [
      "self",
      "word"
    ],
    "_normalize_dict": [
      "self",
      "phoneme_dict_obj"
    ],
    "replace_symbols": [
      "self",
      "symbols",
      "keep_alternate"
    ],
    "is_unique_in_phoneme_dict": [
      "self",
      "word"
    ],
    "parse_one_word": [
      "self",
      "word"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "T5G2PConfig": {},
  "T5G2PModel": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "labels"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_train_epoch_end": [
      "self"
    ],
    "_setup_infer_dataloader": [
      "self",
      "cfg"
    ],
    "_infer": [
      "self",
      "config"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "split"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx",
      "split"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "_generate_predictions": [
      "self",
      "input_ids",
      "model_max_target_len"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "cfg",
      "name"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "setup_test_data": [
      "self",
      "cfg"
    ],
    "setup_multiple_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_multiple_test_data": [
      "self",
      "test_data_config"
    ],
    "list_available_models": [
      "cls"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "_export_teardown": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "forward_for_export": [
      "self",
      "input_ids"
    ]
  },
  "CTCG2PConfig": {},
  "CTCG2PModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "setup_grapheme_tokenizer": [
      "self",
      "cfg"
    ],
    "_setup_encoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "input_len"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_train_epoch_end": [
      "self"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "split"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx",
      "split"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "_setup_infer_dataloader": [
      "self",
      "cfg"
    ],
    "_infer": [
      "self",
      "config"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "cfg",
      "name"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_multiple_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_multiple_test_data": [
      "self",
      "test_data_config"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "setup_test_data": [
      "self",
      "cfg"
    ],
    "list_available_models": [
      "cls"
    ],
    "wer": [
      "self",
      "wer"
    ],
    "per": [
      "self",
      "per"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "_export_teardown": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "forward_for_export": [
      "self",
      "input_ids",
      "input_len"
    ]
  },
  "JapaneseG2p": {
    "__init__": [
      "self",
      "phoneme_dict",
      "phoneme_prefix",
      "ascii_letter_prefix",
      "ascii_letter_case",
      "word_tokenize_func",
      "apply_to_oov_word",
      "mapping_file",
      "word_segmenter"
    ],
    "_parse_ja_phoneme_dict": [
      "phoneme_dict_path",
      "phoneme_prefix"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "Tacotron2Loss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "ForwardSumLoss": {
    "__init__": [
      "self",
      "blank_logprob",
      "loss_scale"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "attn_logprob",
      "in_lens",
      "out_lens"
    ]
  },
  "BinLoss": {
    "__init__": [
      "self",
      "loss_scale"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "hard_attention",
      "soft_attention"
    ]
  },
  "compute_flow_loss": [
    "z",
    "log_det_W_list",
    "log_s_list",
    "n_elements",
    "n_dims",
    "mask",
    "sigma"
  ],
  "compute_regression_loss": [
    "x_hat",
    "x",
    "mask",
    "name"
  ],
  "AttributePredictionLoss": {
    "__init__": [
      "self",
      "name",
      "model_config",
      "loss_weight",
      "sigma"
    ],
    "forward": [
      "self",
      "model_output",
      "lens"
    ]
  },
  "AttentionBinarizationLoss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hard_attention",
      "soft_attention"
    ]
  },
  "RADTTSLoss": {
    "__init__": [
      "self",
      "sigma",
      "n_group_size",
      "dur_model_config",
      "f0_model_config",
      "energy_model_config",
      "vpred_model_config",
      "loss_weights"
    ],
    "forward": [
      "self",
      "model_output",
      "in_lens",
      "out_lens"
    ]
  },
  "MaskedLoss": {
    "__init__": [
      "self",
      "loss_fn",
      "loss_scale"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "predicted",
      "target",
      "target_len"
    ]
  },
  "MaskedMAELoss": {
    "__init__": [
      "self",
      "loss_scale"
    ]
  },
  "MaskedMSELoss": {
    "__init__": [
      "self",
      "loss_scale"
    ]
  },
  "TimeDomainLoss": {
    "__init__": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio_real",
      "audio_gen",
      "audio_len"
    ]
  },
  "MultiResolutionMelLoss": {
    "__init__": [
      "self",
      "sample_rate",
      "resolutions",
      "mel_dims",
      "log_guard"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio_real",
      "audio_gen",
      "audio_len"
    ]
  },
  "STFTLoss": {
    "__init__": [
      "self",
      "resolution",
      "log_guard",
      "sqrt_guard"
    ],
    "_compute_spectrogram": [
      "self",
      "audio",
      "spec_len"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio_real",
      "audio_gen",
      "audio_len"
    ]
  },
  "MultiResolutionSTFTLoss": {
    "__init__": [
      "self",
      "resolutions",
      "log_guard",
      "sqrt_guard"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio_real",
      "audio_gen",
      "audio_len"
    ]
  },
  "SISDRLoss": {
    "__init__": [
      "self",
      "epsilon"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio_real",
      "audio_gen",
      "audio_len"
    ]
  },
  "FeatureMatchingLoss": {
    "__init__": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "fmaps_real",
      "fmaps_gen"
    ]
  },
  "RelativeFeatureMatchingLoss": {
    "__init__": [
      "self",
      "div_guard"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "fmaps_real",
      "fmaps_gen"
    ]
  },
  "GeneratorHingedLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "disc_scores_gen"
    ]
  },
  "GeneratorSquaredLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "disc_scores_gen"
    ]
  },
  "DiscriminatorHingedLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "disc_scores_real",
      "disc_scores_gen"
    ]
  },
  "DiscriminatorSquaredLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "disc_scores_real",
      "disc_scores_gen"
    ]
  },
  "WaveGlowLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "GradientPenaltyLoss": {
    "__init__": [
      "self",
      "weight"
    ],
    "__call__": [
      "self",
      "images",
      "output"
    ]
  },
  "GeneratorLoss": {
    "__call__": [
      "self",
      "fake_logits"
    ]
  },
  "HingeLoss": {
    "__call__": [
      "self",
      "real_logits",
      "fake_logits"
    ]
  },
  "ConsistencyLoss": {
    "__init__": [
      "self",
      "weight"
    ],
    "__call__": [
      "self",
      "condition",
      "output",
      "lengths"
    ]
  },
  "DiscriminatorLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "disc_real_outputs",
      "disc_generated_outputs"
    ]
  },
  "stft": [
    "x",
    "fft_size",
    "hop_size",
    "win_length",
    "window"
  ],
  "SpectralConvergenceLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "LogSTFTMagnitudeLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "KlLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "z_p",
      "logs_q",
      "m_p",
      "logs_p",
      "z_mask"
    ]
  },
  "DurationLoss": {
    "__init__": [
      "self",
      "loss_scale"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "log_durs_predicted",
      "durs_tgt",
      "len"
    ]
  },
  "PitchLoss": {
    "__init__": [
      "self",
      "loss_scale"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "pitch_predicted",
      "pitch_tgt",
      "len"
    ]
  },
  "EnergyLoss": {
    "__init__": [
      "self",
      "loss_scale"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "energy_predicted",
      "energy_tgt",
      "length"
    ]
  },
  "MelLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "spect_predicted",
      "spect_tgt"
    ]
  },
  "ClassificationReport": {
    "full_state_update": [],
    "__init__": [
      "self",
      "num_classes",
      "label_ids",
      "mode",
      "dist_sync_on_step",
      "process_group"
    ],
    "update": [
      "self",
      "predictions",
      "labels"
    ],
    "compute": [
      "self"
    ]
  },
  "ValMetric": {
    "get_score": [
      "self",
      "ground_truth",
      "predicted_text"
    ]
  },
  "AccuracyScore": {
    "get_score": [
      "self",
      "ground_truth",
      "predicted_text"
    ]
  },
  "BLEUScore": {
    "__init__": [
      "self"
    ],
    "get_score": [
      "self",
      "ground_truth",
      "predicted_text"
    ]
  },
  "ROUGEScores": {
    "__init__": [
      "self"
    ],
    "get_score": [
      "self",
      "ground_truth",
      "predicted_text"
    ]
  },
  "VALID_FILE_FORMATS": [],
  "DatasetMeta": {},
  "DatasetSample": {},
  "audio_collate_fn": [
    "batch"
  ],
  "preprocess_manifest": [
    "dataset_name",
    "dataset",
    "min_duration",
    "max_duration"
  ],
  "VocoderDataset": {
    "__init__": [
      "self",
      "dataset_meta",
      "sample_rate",
      "n_samples",
      "weighted_sampling_steps_per_epoch",
      "feature_processors",
      "min_duration",
      "max_duration",
      "trunc_duration",
      "volume_norm"
    ],
    "get_sampler": [
      "self",
      "batch_size",
      "world_size"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "TarredVocoderDataset": {
    "__init__": [
      "self",
      "dataset_meta",
      "sample_rate",
      "n_samples",
      "shuffle_n",
      "min_duration",
      "max_duration",
      "trunc_duration",
      "feature_processors",
      "shard_strategy",
      "global_rank",
      "world_size"
    ],
    "_filter": [
      "self",
      "iterator"
    ],
    "_build_sample": [
      "self",
      "tup"
    ],
    "get_sampler": [
      "self",
      "batch_size",
      "world_size"
    ],
    "collate_fn": [
      "self",
      "batch"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "EPSILON": [],
  "WINDOW_FN_SUPPORTED": [],
  "TTSDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "sample_rate",
      "text_tokenizer",
      "tokens",
      "text_normalizer",
      "text_normalizer_call_kwargs",
      "text_tokenizer_pad_id",
      "sup_data_types",
      "sup_data_path",
      "max_duration",
      "min_duration",
      "ignore_file",
      "trim",
      "trim_ref",
      "trim_top_db",
      "trim_frame_length",
      "trim_hop_length",
      "n_fft",
      "win_length",
      "hop_length",
      "window",
      "n_mels",
      "lowfreq",
      "highfreq",
      "segment_max_duration",
      "pitch_augment",
      "cache_pitch_augment",
      "pad_multiple"
    ],
    "filter_files": [
      "data",
      "ignore_file",
      "min_duration",
      "max_duration",
      "total_duration"
    ],
    "add_log_mel": [
      "self"
    ],
    "add_durations": [
      "self"
    ],
    "add_align_prior_matrix": [
      "self"
    ],
    "add_pitch": [
      "self"
    ],
    "add_voiced_mask": [
      "self"
    ],
    "add_p_voiced": [
      "self"
    ],
    "add_energy": [
      "self"
    ],
    "add_speaker_id": [
      "self"
    ],
    "add_reference_audio": [
      "self"
    ],
    "get_spec": [
      "self",
      "audio"
    ],
    "get_log_mel": [
      "self",
      "audio"
    ],
    "pitch_shift": [
      "self",
      "audio",
      "sr",
      "rel_audio_path_as_text_id"
    ],
    "_pad_wav_to_multiple": [
      "self",
      "wav"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "join_data": [
      "self",
      "data_dict"
    ],
    "general_collate_fn": [
      "self",
      "batch"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "MixerTTSXDataset": {
    "__init__": [
      "self"
    ],
    "_albert": [
      "self"
    ],
    "add_lm_tokens": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "PairedRealFakeSpectrogramsDataset": {
    "__init__": [
      "self",
      "manifest_filepath"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "FastPitchSSLDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "sample_rate",
      "ssl_content_emb_type",
      "pad_multiple",
      "max_duration",
      "min_duration",
      "ignore_file",
      "trim",
      "pitch_conditioning",
      "pitch_mean",
      "pitch_std",
      "pitch_normalization",
      "sup_data_dir",
      "speaker_stats_pitch_fp",
      "speaker_conditioning_type"
    ],
    "_get_wav_from_filepath": [
      "self",
      "audio_filepath"
    ],
    "get_ssl_features": [
      "self",
      "wav_text_id"
    ],
    "get_pitch_contour": [
      "self",
      "wav_text_id"
    ],
    "get_mel_spectrogram": [
      "self",
      "wav_text_id"
    ],
    "pad_collate_fn": [
      "self",
      "batch"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "DistributedBucketSampler": {
    "__init__": [
      "self",
      "dataset",
      "batch_size",
      "boundaries",
      "num_replicas",
      "rank",
      "shuffle"
    ],
    "_create_buckets": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "_bisect": [
      "self",
      "x",
      "lo",
      "hi"
    ],
    "__len__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "TextToSpeechDataset": {
    "__init__": [
      "self",
      "dataset_meta",
      "sample_rate",
      "text_tokenizer",
      "weighted_sampling_steps_per_epoch",
      "speaker_path",
      "featurizers",
      "feature_processors",
      "align_prior_hop_length",
      "min_duration",
      "max_duration",
      "volume_norm"
    ],
    "get_sampler": [
      "self",
      "batch_size",
      "world_size"
    ],
    "_preprocess_manifest": [
      "self",
      "dataset_name",
      "dataset",
      "min_duration",
      "max_duration",
      "speaker_index_map"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "MagpieTTSDataset": {
    "__init__": [
      "self",
      "dataset_meta",
      "sample_rate",
      "weighted_sampling_steps_per_epoch",
      "min_duration",
      "max_duration",
      "volume_norm",
      "codec_model_downsample_factor",
      "bos_id",
      "eos_id",
      "audio_bos_id",
      "audio_eos_id",
      "context_audio_bos_id",
      "context_audio_eos_id",
      "num_audio_codebooks",
      "prior_scaling_factor",
      "load_cached_codes_if_available",
      "dataset_type",
      "tokenizer_config",
      "load_16khz_audio",
      "use_text_conditioning_tokenizer",
      "pad_context_text_to_max_duration",
      "context_duration_min",
      "context_duration_max"
    ],
    "get_num_audio_samples_to_slice": [
      "self",
      "duration",
      "sample_rate"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "MagpieTTSDatasetDPO": {
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "TTSDataType": {
    "name": []
  },
  "WithLens": {},
  "LogMel": {
    "name": []
  },
  "Durations": {
    "name": []
  },
  "AlignPriorMatrix": {
    "name": []
  },
  "Pitch": {
    "name": []
  },
  "Energy": {
    "name": []
  },
  "SpeakerID": {
    "name": []
  },
  "Voiced_mask": {
    "name": []
  },
  "P_voiced": {
    "name": []
  },
  "LMTokens": {
    "name": []
  },
  "ReferenceAudio": {
    "name": []
  },
  "MAIN_DATA_TYPES": [],
  "VALID_SUPPLEMENTARY_DATA_TYPES": [],
  "DATA_STR2DATA_CLASS": [],
  "HAVE_WANDB": [],
  "_get_logger": [
    "loggers",
    "logger_type"
  ],
  "_load_vocoder": [
    "model_name",
    "checkpoint_path",
    "type"
  ],
  "AudioArtifact": {},
  "ImageArtifact": {},
  "LogAudioParams": {},
  "create_id": [
    "filepath"
  ],
  "ArtifactGenerator": {
    "generate_artifacts": [
      "self",
      "model",
      "batch_dict",
      "initial_log"
    ]
  },
  "LoggingCallback": {
    "__init__": [
      "self",
      "generators",
      "data_loader",
      "log_epochs",
      "epoch_frequency",
      "output_dir",
      "loggers",
      "log_tensorboard",
      "log_wandb"
    ],
    "_log_audio": [
      "self",
      "audio",
      "log_dir",
      "step"
    ],
    "_log_image": [
      "self",
      "image",
      "log_dir",
      "step"
    ],
    "_log_artifacts": [
      "self",
      "audio_list",
      "image_list",
      "log_dir",
      "global_step"
    ],
    "on_fit_start": [
      "self",
      "trainer",
      "model"
    ],
    "on_train_epoch_end": [
      "self",
      "trainer",
      "model"
    ]
  },
  "VocoderArtifactGenerator": {
    "generate_artifacts": [
      "self",
      "model",
      "batch_dict",
      "initial_log"
    ]
  },
  "AudioCodecArtifactGenerator": {
    "__init__": [
      "self",
      "log_audio",
      "log_encoding",
      "log_dequantized"
    ],
    "_generate_audio": [
      "self",
      "model",
      "dataset_names",
      "audio_ids",
      "audio",
      "audio_len",
      "save_input"
    ],
    "_generate_images": [
      "self",
      "model",
      "dataset_names",
      "audio_ids",
      "audio",
      "audio_len"
    ],
    "generate_artifacts": [
      "self",
      "model",
      "batch_dict",
      "initial_log"
    ]
  },
  "FastPitchArtifactGenerator": {
    "__init__": [
      "self",
      "log_spectrogram",
      "log_alignment",
      "audio_params"
    ],
    "_create_ground_truth_artifacts": [
      "self",
      "model",
      "dataset_names",
      "audio_ids",
      "batch_dict"
    ],
    "_generate_audio": [
      "self",
      "mels",
      "mels_len",
      "hop_length"
    ],
    "_generate_predictions": [
      "self",
      "model",
      "dataset_names",
      "audio_ids",
      "batch_dict"
    ],
    "_generate_gta_predictions": [
      "self",
      "model",
      "dataset_names",
      "audio_ids",
      "batch_dict"
    ],
    "generate_artifacts": [
      "self",
      "model",
      "batch_dict",
      "initial_log"
    ]
  },
  "_is_distributed": [],
  "_is_complex_or_float": [
    "tensor"
  ],
  "broadcast_tensors": [
    "tensors",
    "src"
  ],
  "OperationMode": {
    "training": [],
    "validation": [],
    "infer": []
  },
  "get_batch_size": [
    "train_dataloader"
  ],
  "get_num_workers": [
    "trainer"
  ],
  "binarize_attention": [
    "attn",
    "in_len",
    "out_len"
  ],
  "binarize_attention_parallel": [
    "attn",
    "in_lens",
    "out_lens"
  ],
  "get_mask_from_lengths": [
    "lengths",
    "x"
  ],
  "sort_tensor": [
    "context",
    "lens",
    "dim",
    "descending"
  ],
  "unsort_tensor": [
    "ordered",
    "indices",
    "dim"
  ],
  "mas": [
    "attn_map",
    "width"
  ],
  "mas_width1": [
    "log_attn_map"
  ],
  "b_mas": [
    "b_log_attn_map",
    "in_lens",
    "out_lens",
    "width"
  ],
  "griffin_lim": [
    "magnitudes",
    "n_iters",
    "n_fft"
  ],
  "log_audio_to_tb": [
    "swriter",
    "spect",
    "name",
    "step",
    "griffin_lim_mag_scale",
    "griffin_lim_power",
    "sr",
    "n_fft",
    "n_mels",
    "fmax"
  ],
  "tacotron2_log_to_tb_func": [
    "swriter",
    "tensors",
    "step",
    "tag",
    "log_images",
    "log_images_freq",
    "add_audio",
    "griffin_lim_mag_scale",
    "griffin_lim_power",
    "sr",
    "n_fft",
    "n_mels",
    "fmax"
  ],
  "tacotron2_log_to_wandb_func": [
    "swriter",
    "tensors",
    "step",
    "tag",
    "log_images",
    "log_images_freq",
    "add_audio",
    "griffin_lim_mag_scale",
    "griffin_lim_power",
    "sr",
    "n_fft",
    "n_mels",
    "fmax"
  ],
  "plot_alignment_to_numpy": [
    "alignment",
    "title",
    "info",
    "phoneme_seq",
    "vmin",
    "vmax"
  ],
  "plot_alignment_to_numpy_for_speechllm": [
    "alignment",
    "title",
    "info",
    "phoneme_seq",
    "vmin",
    "vmax",
    "phoneme_ver",
    "phone_offset",
    "h_offset"
  ],
  "plot_pitch_to_numpy": [
    "pitch",
    "ylim_range"
  ],
  "plot_multipitch_to_numpy": [
    "pitch_gt",
    "pitch_pred",
    "ylim_range"
  ],
  "plot_spectrogram_to_numpy": [
    "spectrogram"
  ],
  "create_plot": [
    "data",
    "x_axis",
    "y_axis",
    "output_filepath"
  ],
  "plot_gate_outputs_to_numpy": [
    "gate_targets",
    "gate_outputs"
  ],
  "save_figure_to_numpy": [
    "fig"
  ],
  "waveglow_log_to_tb_func": [
    "swriter",
    "tensors",
    "step",
    "tag",
    "n_fft",
    "hop_length",
    "window",
    "mel_fb"
  ],
  "remove": [
    "conv_list"
  ],
  "regulate_len": [
    "durations",
    "enc_out",
    "pace",
    "mel_max_len",
    "group_size",
    "dur_lens"
  ],
  "split_view": [
    "tensor",
    "split_size",
    "dim"
  ],
  "slice_segments": [
    "x",
    "ids_str",
    "segment_size"
  ],
  "rand_slice_segments": [
    "x",
    "x_lengths",
    "segment_size"
  ],
  "clip_grad_value_": [
    "parameters",
    "clip_value",
    "norm_type"
  ],
  "convert_pad_shape": [
    "pad_shape"
  ],
  "generate_path": [
    "duration",
    "mask"
  ],
  "process_batch": [
    "batch_data",
    "sup_data_types_set"
  ],
  "to_device_recursive": [
    "e",
    "device"
  ],
  "batch_from_ragged": [
    "text",
    "pitch",
    "pace",
    "batch_lengths",
    "padding_idx",
    "volume"
  ],
  "sample_tts_input": [
    "export_config",
    "device",
    "max_batch",
    "max_dim"
  ],
  "g2p_backward_compatible_support": [
    "g2p_target"
  ],
  "get_abs_rel_paths": [
    "input_path",
    "base_path"
  ],
  "get_audio_filepaths": [
    "manifest_entry",
    "audio_dir"
  ],
  "normalize_volume": [
    "audio",
    "volume_level"
  ],
  "BetaBinomialInterpolator": {
    "__init__": [
      "self",
      "round_mel_len_to",
      "round_text_len_to",
      "cache_size",
      "scaling_factor"
    ],
    "round": [
      "val",
      "to"
    ],
    "__call__": [
      "self",
      "w",
      "h"
    ]
  },
  "general_padding": [
    "item",
    "item_len",
    "max_len",
    "pad_value"
  ],
  "stack_tensors": [
    "tensors",
    "max_lens",
    "pad_value"
  ],
  "logbeta": [
    "x",
    "y"
  ],
  "logcombinations": [
    "n",
    "k"
  ],
  "logbetabinom": [
    "n",
    "a",
    "b",
    "x"
  ],
  "beta_binomial_prior_distribution": [
    "phoneme_count",
    "mel_count",
    "scaling_factor"
  ],
  "get_base_dir": [
    "paths"
  ],
  "filter_dataset_by_duration": [
    "entries",
    "min_duration",
    "max_duration"
  ],
  "get_weighted_sampler": [
    "sample_weights",
    "batch_size",
    "world_size",
    "num_steps"
  ],
  "_read_audio": [
    "audio_filepath",
    "sample_rate",
    "offset",
    "duration",
    "n_retries"
  ],
  "_segment_audio": [
    "audio_filepath",
    "sample_rate",
    "offset",
    "n_samples",
    "max_offset",
    "n_retries"
  ],
  "sample_audio": [
    "manifest_entry",
    "audio_dir",
    "sample_rate",
    "n_samples",
    "volume_norm"
  ],
  "piecewise_linear_transform": [
    "x",
    "q_tilde",
    "compute_jacobian",
    "outlier_passthru"
  ],
  "piecewise_linear_inverse_transform": [
    "y",
    "q_tilde",
    "compute_jacobian",
    "outlier_passthru"
  ],
  "unbounded_piecewise_quadratic_transform": [
    "x",
    "w_tilde",
    "v_tilde",
    "upper",
    "lower",
    "inverse"
  ],
  "weighted_softmax": [
    "v",
    "w"
  ],
  "piecewise_quadratic_transform": [
    "x",
    "w_tilde",
    "v_tilde",
    "inverse"
  ],
  "piecewise_rational_quadratic_transform": [
    "inputs",
    "unnormalized_widths",
    "unnormalized_heights",
    "unnormalized_derivatives",
    "inverse",
    "tails",
    "tail_bound",
    "min_bin_width",
    "min_bin_height",
    "min_derivative"
  ],
  "searchsorted": [
    "bin_locations",
    "inputs",
    "eps"
  ],
  "unconstrained_rational_quadratic_spline": [
    "inputs",
    "unnormalized_widths",
    "unnormalized_heights",
    "unnormalized_derivatives",
    "inverse",
    "tails",
    "tail_bound",
    "min_bin_width",
    "min_bin_height",
    "min_derivative"
  ],
  "rational_quadratic_spline": [
    "inputs",
    "unnormalized_widths",
    "unnormalized_heights",
    "unnormalized_derivatives",
    "inverse",
    "left",
    "right",
    "bottom",
    "top",
    "min_bin_width",
    "min_bin_height",
    "min_derivative"
  ],
  "FastPitchAdapterModelMixin": {
    "setup_adapters": [
      "self"
    ],
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "is_adapter_available": [
      "self"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "check_valid_model_with_adapter_support_": [
      "self"
    ],
    "resolve_adapter_module_name_": [
      "self",
      "name"
    ],
    "_get_global_cfg": [
      "self"
    ],
    "adapter_module_names": [
      "self"
    ]
  },
  "FeatureProcessor": {
    "process": [
      "self",
      "training_example"
    ]
  },
  "FeatureScaler": {
    "__init__": [
      "self",
      "field",
      "add_value",
      "div_value"
    ],
    "process": [
      "self",
      "training_example"
    ]
  },
  "LogCompression": {
    "__init__": [
      "self",
      "field",
      "log_zero_guard_type",
      "log_zero_guard_value"
    ],
    "_add_guard": [
      "self",
      "feature"
    ],
    "_clamp_guard": [
      "self",
      "feature"
    ],
    "process": [
      "self",
      "training_example"
    ]
  },
  "MeanVarianceNormalization": {
    "__init__": [
      "self",
      "field",
      "stats_path",
      "mask_field"
    ],
    "process": [
      "self",
      "training_example"
    ]
  },
  "MeanVarianceSpeakerNormalization": {
    "__init__": [
      "self",
      "field",
      "stats_path",
      "speaker_field",
      "mask_field",
      "fallback_to_default"
    ],
    "process": [
      "self",
      "training_example"
    ]
  },
  "Featurizer": {
    "save": [
      "self",
      "manifest_entry",
      "audio_dir",
      "feature_dir",
      "overwrite"
    ],
    "load": [
      "self",
      "manifest_entry",
      "audio_dir",
      "feature_dir"
    ],
    "collate_fn": [
      "self",
      "train_batch"
    ]
  },
  "_get_feature_filepath": [
    "manifest_entry",
    "audio_dir",
    "feature_dir",
    "feature_name"
  ],
  "_features_exists": [
    "feature_names",
    "manifest_entry",
    "audio_dir",
    "feature_dir"
  ],
  "_save_feature": [
    "feature_name",
    "features",
    "manifest_entry",
    "audio_dir",
    "feature_dir"
  ],
  "_load_feature": [
    "feature_dict",
    "feature_name",
    "manifest_entry",
    "audio_dir",
    "feature_dir",
    "indices"
  ],
  "_get_frame_indices": [
    "manifest_entry",
    "sample_rate",
    "hop_length"
  ],
  "_collate_feature": [
    "feature_dict",
    "feature_name",
    "train_batch"
  ],
  "MelSpectrogramFeaturizer": {
    "__init__": [
      "self",
      "feature_name",
      "sample_rate",
      "mel_dim",
      "win_length",
      "hop_length",
      "lowfreq",
      "highfreq",
      "log",
      "log_zero_guard_type",
      "log_zero_guard_value",
      "mel_norm",
      "volume_norm"
    ],
    "compute_mel_spec": [
      "self",
      "manifest_entry",
      "audio_dir"
    ],
    "save": [
      "self",
      "manifest_entry",
      "audio_dir",
      "feature_dir",
      "overwrite"
    ],
    "load": [
      "self",
      "manifest_entry",
      "audio_dir",
      "feature_dir"
    ],
    "collate_fn": [
      "self",
      "train_batch"
    ]
  },
  "EnergyFeaturizer": {
    "__init__": [
      "self",
      "spec_featurizer",
      "feature_name"
    ],
    "compute_energy": [
      "self",
      "manifest_entry",
      "audio_dir"
    ],
    "save": [
      "self",
      "manifest_entry",
      "audio_dir",
      "feature_dir",
      "overwrite"
    ],
    "load": [
      "self",
      "manifest_entry",
      "audio_dir",
      "feature_dir"
    ],
    "collate_fn": [
      "self",
      "train_batch"
    ]
  },
  "PitchFeaturizer": {
    "__init__": [
      "self",
      "pitch_name",
      "voiced_mask_name",
      "voiced_prob_name",
      "sample_rate",
      "win_length",
      "hop_length",
      "pitch_fmin",
      "pitch_fmax",
      "volume_norm",
      "batch_seconds",
      "batch_padding"
    ],
    "compute_pitch": [
      "self",
      "manifest_entry",
      "audio_dir"
    ],
    "save": [
      "self",
      "manifest_entry",
      "audio_dir",
      "feature_dir",
      "overwrite"
    ],
    "load": [
      "self",
      "manifest_entry",
      "audio_dir",
      "feature_dir"
    ],
    "collate_fn": [
      "self",
      "train_batch"
    ]
  },
  "AudioTrimmer": {
    "trim_audio": [
      "self",
      "audio",
      "sample_rate",
      "audio_id"
    ]
  },
  "EnergyAudioTrimmer": {
    "__init__": [
      "self",
      "db_threshold",
      "ref_amplitude",
      "speech_frame_threshold",
      "trim_win_length",
      "trim_hop_length",
      "pad_seconds",
      "volume_norm"
    ],
    "trim_audio": [
      "self",
      "audio",
      "sample_rate",
      "audio_id"
    ]
  },
  "VadAudioTrimmer": {
    "__init__": [
      "self",
      "model_name",
      "vad_sample_rate",
      "vad_threshold",
      "device",
      "speech_frame_threshold",
      "trim_win_length",
      "trim_hop_length",
      "pad_seconds",
      "volume_norm"
    ],
    "_detect_speech": [
      "self",
      "audio"
    ],
    "_scale_sample_indices": [
      "self",
      "start_sample",
      "end_sample",
      "sample_rate"
    ],
    "trim_audio": [
      "self",
      "audio",
      "sample_rate",
      "audio_id"
    ]
  },
  "get_start_and_end_of_speech_frames": [
    "is_speech",
    "speech_frame_threshold",
    "audio_id"
  ],
  "pad_sample_indices": [
    "start_sample",
    "end_sample",
    "max_sample",
    "sample_rate",
    "pad_seconds"
  ],
  "MelPsuedoInverseModel": {
    "__init__": [
      "self",
      "cfg"
    ],
    "convert_mel_spectrogram_to_linear": [
      "self",
      "mel"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "cuda": [
      "self"
    ]
  },
  "GriffinLimModel": {
    "__init__": [
      "self",
      "cfg"
    ],
    "convert_spectrogram_to_audio": [
      "self",
      "spec",
      "Ts"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "cuda": [
      "self"
    ]
  },
  "TwoStagesConfig": {},
  "TwoStagesModel": {
    "__init__": [
      "self",
      "cfg"
    ],
    "set_mel_to_spec_model": [
      "self",
      "mel2spec"
    ],
    "set_linear_vocoder": [
      "self",
      "linvocoder"
    ],
    "cuda": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "convert_spectrogram_to_audio": [
      "self",
      "spec"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_validation_epoch_end": [
      "self",
      "outputs"
    ],
    "__setup_dataloader_from_config": [
      "self",
      "cfg",
      "shuffle_should_be",
      "name"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "MixerTTSModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_setup_tokenizer": [
      "self",
      "cfg"
    ],
    "_get_lm_model_tokenizer": [
      "self",
      "lm_model"
    ],
    "_get_lm_embeddings": [
      "self",
      "lm_model"
    ],
    "_get_lm_padding_value": [
      "self",
      "lm_model"
    ],
    "_metrics": [
      "self",
      "true_durs",
      "true_text_len",
      "pred_durs",
      "true_pitch",
      "pred_pitch",
      "true_spect",
      "pred_spect",
      "true_spect_len",
      "attn_logprob",
      "attn_soft",
      "attn_hard",
      "attn_hard_dur"
    ],
    "run_aligner": [
      "self",
      "text",
      "text_len",
      "text_mask",
      "spect",
      "spect_len",
      "attn_prior"
    ],
    "forward": [
      "self",
      "text",
      "text_len",
      "pitch",
      "spect",
      "spect_len",
      "attn_prior",
      "lm_tokens"
    ],
    "infer": [
      "self",
      "text",
      "text_len",
      "text_mask",
      "spect",
      "spect_len",
      "attn_prior",
      "use_gt_durs",
      "lm_tokens",
      "pitch"
    ],
    "on_train_epoch_start": [
      "self"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "generate_spectrogram": [
      "self",
      "tokens",
      "tokens_len",
      "lm_tokens",
      "raw_texts",
      "norm_text_for_lm_model",
      "lm_model"
    ],
    "parse": [
      "self",
      "text",
      "normalize"
    ],
    "_loader": [
      "self",
      "cfg"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "setup_test_data": [
      "self",
      "cfg"
    ],
    "list_available_models": [
      "cls"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "input_example": [
      "self",
      "max_text_len",
      "max_lm_tokens_len"
    ],
    "forward_for_export": [
      "self",
      "text",
      "lm_tokens"
    ]
  },
  "SSLDisentangler": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "list_available_models": [
      "cls"
    ],
    "tb_logger": [
      "self"
    ],
    "__setup_dataloader_from_config": [
      "self",
      "data_config"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "configure_optimizers": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "normalize_content"
    ],
    "forward_for_export": [
      "self",
      "input_signal",
      "input_signal_length",
      "normalize_content"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_validation_epoch_end": [
      "self",
      "outputs"
    ]
  },
  "UnivNetModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_get_max_steps": [
      "self"
    ],
    "get_warmup_steps": [
      "max_steps",
      "warmup_steps",
      "warmup_ratio"
    ],
    "configure_optimizers": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "convert_spectrogram_to_audio": [
      "self",
      "spec"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "_bias_denoise": [
      "self",
      "audio",
      "mel"
    ],
    "__setup_dataloader_from_config": [
      "self",
      "cfg",
      "shuffle_should_be",
      "name"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "setup_test_data": [
      "self",
      "cfg"
    ],
    "list_available_models": [
      "cls"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "forward_for_export": [
      "self",
      "spec"
    ]
  },
  "setup_tokenizers": [
    "all_tokenizers_config",
    "use_text_conditioning_tokenizer",
    "mode"
  ],
  "worker_init_fn": [
    "worker_id"
  ],
  "MagpieTTS_Model": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "freeze_model": [
      "self",
      "model"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "_setup_tokenizers": [
      "self",
      "cfg",
      "mode"
    ],
    "tb_logger": [
      "self"
    ],
    "audio_to_codes": [
      "self",
      "audio",
      "audio_len",
      "audio_type"
    ],
    "codes_to_audio": [
      "self",
      "codes",
      "codes_len"
    ],
    "embed_audio_tokens": [
      "self",
      "audio_tokens"
    ],
    "get_speaker_embeddings": [
      "self",
      "audio_16khz",
      "audio_len_16khz"
    ],
    "compute_loss": [
      "self",
      "logits",
      "audio_codes",
      "audio_codes_lens"
    ],
    "forward": [
      "self",
      "dec_input_embedded",
      "dec_input_mask",
      "cond",
      "cond_mask",
      "attn_prior",
      "multi_encoder_mapping"
    ],
    "logits_to_audio_codes": [
      "self",
      "all_code_logits",
      "audio_codes_lens"
    ],
    "sample_codes_from_logits": [
      "self",
      "all_code_logits_t",
      "temperature",
      "topk"
    ],
    "log_attention_probs": [
      "self",
      "attention_prob_matrix",
      "audio_codes_lens",
      "text_lens",
      "prefix",
      "dec_context_size"
    ],
    "log_train_val_example": [
      "self",
      "logits",
      "target_audio_codes",
      "audio_codes_lens_target",
      "context_audio_codes",
      "context_audio_codes_lens"
    ],
    "scale_prior": [
      "self",
      "prior",
      "global_step"
    ],
    "compute_alignment_loss": [
      "self",
      "attention_scores",
      "text_lens",
      "audio_lens",
      "dec_context_size"
    ],
    "prepare_context_tensors": [
      "self",
      "batch"
    ],
    "prepare_dummy_cond_for_cfg": [
      "self",
      "cond",
      "cond_mask",
      "additional_decoder_input",
      "additional_dec_mask"
    ],
    "process_batch": [
      "self",
      "batch",
      "mode"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "infer_batch": [
      "self",
      "batch",
      "max_decoder_steps",
      "temperature",
      "topk",
      "use_cfg",
      "cfg_scale"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "get_dataset": [
      "self",
      "cfg",
      "dataset_type"
    ],
    "_setup_train_dataloader": [
      "self",
      "cfg"
    ],
    "_setup_test_dataloader": [
      "self",
      "cfg"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "setup_test_data": [
      "self",
      "cfg"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "MagpieTTS_ModelInference": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "transcribe_with_whisper": [
      "self",
      "audio_filepath",
      "language"
    ],
    "process_text": [
      "self",
      "input_text"
    ],
    "get_speaker_embeddings_from_filepaths": [
      "self",
      "filepaths"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx"
    ]
  },
  "MagpieTTS_ModelDPO": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "_get_batch_logps": [
      "self",
      "logits",
      "labels",
      "loss_mask",
      "average_log_prob"
    ],
    "preference_loss": [
      "self",
      "policy_chosen_logps",
      "policy_rejected_logps",
      "reference_chosen_logps",
      "reference_rejected_logps",
      "chosen_gt_rewards",
      "rejected_gt_rewards",
      "beta",
      "gt_reward_scale",
      "label_smoothing",
      "loss_type",
      "reference_free"
    ],
    "process_batch_dpo": [
      "self",
      "batch_chosen_rejected"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_validation_epoch_end": [
      "self"
    ]
  },
  "PYNINI_AVAILABLE": [],
  "NeedsNormalizer": {
    "_setup_normalizer": [
      "self",
      "cfg"
    ]
  },
  "SpectrogramGenerator": {
    "parse": [
      "self",
      "str_input"
    ],
    "generate_spectrogram": [
      "self",
      "tokens"
    ],
    "list_available_models": [
      "cls"
    ],
    "set_export_config": [
      "self",
      "args"
    ]
  },
  "Vocoder": {
    "convert_spectrogram_to_audio": [
      "self",
      "spec"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "GlowVocoder": {
    "__init__": [
      "self"
    ],
    "mode": [
      "self"
    ],
    "temp_mode": [
      "self",
      "mode"
    ],
    "nemo_infer": [
      "self"
    ],
    "check_children_attributes": [
      "self"
    ],
    "update_bias_spect": [
      "self"
    ],
    "denoise": [
      "self",
      "audio",
      "strength"
    ]
  },
  "MelToSpec": {
    "convert_mel_spectrogram_to_linear": [
      "self",
      "mel"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "TextToWaveform": {
    "parse": [
      "self",
      "str_input"
    ],
    "convert_text_to_waveform": [
      "self"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "G2PModel": {
    "convert_graphemes_to_phonemes": [
      "self",
      "manifest_filepath",
      "output_manifest_filepath",
      "grapheme_field",
      "batch_size",
      "num_workers",
      "pred_field"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "FastPitchModel_SSL": {
    "__init__": [
      "self",
      "cfg",
      "trainer",
      "vocoder"
    ],
    "vocode_spectrogram": [
      "self",
      "spectrogram"
    ],
    "tb_logger": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "compute_encoding": [
      "self",
      "content_embedding",
      "speaker_embedding",
      "dataset_id"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_validation_epoch_end": [
      "self",
      "outputs"
    ],
    "generate_wav": [
      "self",
      "content_embedding",
      "speaker_embedding",
      "encoded_len",
      "pitch_contour",
      "compute_pitch",
      "compute_duration",
      "durs_gt",
      "dataset_id"
    ],
    "__setup_dataloader_from_config": [
      "self",
      "cfg"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "setup_test_data": [
      "self",
      "cfg"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "HifiGanModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "max_steps": [
      "self"
    ],
    "get_warmup_steps": [
      "max_steps",
      "warmup_steps",
      "warmup_ratio"
    ],
    "configure_optimizers": [
      "self"
    ],
    "update_lr": [
      "self",
      "interval"
    ],
    "forward": [
      "self"
    ],
    "convert_spectrogram_to_audio": [
      "self",
      "spec"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_train_epoch_end": [
      "self"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "_process_batch": [
      "self",
      "batch"
    ],
    "_bias_denoise": [
      "self",
      "audio",
      "mel"
    ],
    "_setup_train_dataloader": [
      "self",
      "cfg"
    ],
    "_setup_test_dataloader": [
      "self",
      "cfg"
    ],
    "__setup_dataloader_from_config": [
      "self",
      "cfg",
      "shuffle_should_be",
      "name"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "setup_test_data": [
      "self",
      "cfg"
    ],
    "configure_callbacks": [
      "self"
    ],
    "list_available_models": [
      "cls"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "forward_for_export": [
      "self",
      "spec"
    ]
  },
  "G2PConfig": {},
  "TextTokenizer": {},
  "TextTokenizerConfig": {},
  "FastPitchModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_get_default_text_tokenizer_conf": [
      "self"
    ],
    "_setup_tokenizer": [
      "self",
      "cfg"
    ],
    "tb_logger": [
      "self"
    ],
    "parser": [
      "self"
    ],
    "parse": [
      "self",
      "str_input",
      "normalize"
    ],
    "forward": [
      "self"
    ],
    "generate_spectrogram": [
      "self",
      "tokens",
      "speaker",
      "pace",
      "reference_spec",
      "reference_spec_lens"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "_setup_train_dataloader": [
      "self",
      "cfg"
    ],
    "_setup_test_dataloader": [
      "self",
      "cfg"
    ],
    "__setup_dataloader_from_config": [
      "self",
      "cfg",
      "shuffle_should_be",
      "name"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "setup_test_data": [
      "self",
      "cfg"
    ],
    "configure_callbacks": [
      "self"
    ],
    "list_available_models": [
      "cls"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "_export_teardown": [
      "self"
    ],
    "disabled_deployment_input_names": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "forward_for_export": [
      "self",
      "text",
      "pitch",
      "pace",
      "volume",
      "batch_lengths",
      "speaker"
    ],
    "interpolate_speaker": [
      "self",
      "original_speaker_1",
      "original_speaker_2",
      "weight_speaker_1",
      "weight_speaker_2",
      "new_speaker_id"
    ]
  },
  "SpectrogramEnhancerModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "move_to_correct_device": [
      "self",
      "e"
    ],
    "normalize_spectrograms": [
      "self",
      "spectrogram",
      "lengths"
    ],
    "unnormalize_spectrograms": [
      "self",
      "spectrogram",
      "lengths"
    ],
    "generate_zs": [
      "self",
      "batch_size",
      "mixing"
    ],
    "generate_noise": [
      "self",
      "batch_size"
    ],
    "pad_spectrograms": [
      "self",
      "spectrograms"
    ],
    "forward": [
      "self"
    ],
    "forward_with_custom_noise": [
      "self",
      "input_spectrograms",
      "lengths",
      "zs",
      "ws",
      "noise",
      "mixing",
      "normalize"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx",
      "optimizer_idx"
    ],
    "configure_optimizers": [
      "self"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "list_available_models": [
      "cls"
    ],
    "log_illustration": [
      "self",
      "target_spectrograms",
      "input_spectrograms",
      "enhanced_spectrograms",
      "lengths"
    ]
  },
  "Preprocessor": {},
  "Tacotron2Config": {},
  "Tacotron2Model": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "parser": [
      "self"
    ],
    "parse": [
      "self",
      "text",
      "normalize"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "generate_spectrogram": [
      "self"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "_setup_tokenizer": [
      "self",
      "cfg"
    ],
    "__setup_dataloader_from_config": [
      "self",
      "cfg",
      "shuffle_should_be",
      "name"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "AudioCodecModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "get_speaker_embedding": [
      "self",
      "audio",
      "requires_grad"
    ],
    "encode_audio": [
      "self",
      "audio",
      "audio_len"
    ],
    "decode_audio": [
      "self",
      "inputs",
      "input_len"
    ],
    "quantize": [
      "self",
      "encoded",
      "encoded_len"
    ],
    "dequantize": [
      "self",
      "tokens",
      "tokens_len"
    ],
    "encode": [
      "self",
      "audio",
      "audio_len"
    ],
    "decode": [
      "self",
      "tokens",
      "tokens_len"
    ],
    "forward": [
      "self",
      "audio",
      "audio_len"
    ],
    "pad_audio": [
      "self",
      "audio",
      "audio_len"
    ],
    "_process_batch": [
      "self",
      "batch"
    ],
    "disc_update_prob": [
      "self"
    ],
    "should_update_disc": [
      "self",
      "batch_idx"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_train_epoch_end": [
      "self"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "get_dataset": [
      "self",
      "cfg"
    ],
    "_setup_train_dataloader": [
      "self",
      "cfg"
    ],
    "_setup_test_dataloader": [
      "self",
      "cfg"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "setup_test_data": [
      "self",
      "cfg"
    ],
    "max_steps": [
      "self"
    ],
    "configure_optimizers": [
      "self"
    ],
    "update_lr": [
      "self",
      "interval"
    ],
    "configure_callbacks": [
      "self"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "RadTTSModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "batch_dict": [
      "self",
      "batch_data"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "configure_optimizers": [
      "self"
    ],
    "_loader": [
      "self",
      "cfg"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "setup_test_data": [
      "self",
      "cfg"
    ],
    "generate_spectrogram": [
      "self",
      "tokens",
      "speaker",
      "sigma"
    ],
    "parser": [
      "self"
    ],
    "_setup_tokenizer": [
      "self",
      "cfg"
    ],
    "parse": [
      "self",
      "text",
      "normalize"
    ],
    "tb_logger": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "forward_for_export": [
      "self",
      "text",
      "batch_lengths",
      "speaker_id",
      "speaker_id_text",
      "speaker_id_attributes",
      "pitch",
      "pace",
      "volume"
    ]
  },
  "AlignerModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_setup_tokenizer": [
      "self",
      "cfg"
    ],
    "forward": [
      "self"
    ],
    "_metrics": [
      "self",
      "attn_soft",
      "attn_logprob",
      "spec_len",
      "text_len"
    ],
    "on_train_epoch_start": [
      "self"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "_loader": [
      "self",
      "cfg"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "setup_test_data": [
      "self",
      "cfg"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "WaveGlowModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "mode": [
      "self",
      "new_mode"
    ],
    "forward": [
      "self"
    ],
    "convert_spectrogram_to_audio": [
      "self",
      "spec",
      "sigma",
      "denoise",
      "denoiser_strength"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "__setup_dataloader_from_config": [
      "self",
      "cfg",
      "shuffle_should_be",
      "name"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "list_available_models": [
      "cls"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "input_module": [
      "self"
    ],
    "output_module": [
      "self"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward_for_export": [
      "self",
      "spec",
      "z"
    ]
  },
  "VitsModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_setup_tokenizer": [
      "self",
      "cfg"
    ],
    "parse": [
      "self",
      "text",
      "normalize"
    ],
    "configure_optimizers": [
      "self"
    ],
    "forward": [
      "self",
      "tokens",
      "speakers",
      "noise_scale",
      "length_scale",
      "noise_scale_w",
      "max_len"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "_loader": [
      "self",
      "cfg"
    ],
    "train_dataloader": [
      "self"
    ],
    "setup_training_data": [
      "self",
      "cfg"
    ],
    "setup_validation_data": [
      "self",
      "cfg"
    ],
    "setup_test_data": [
      "self",
      "cfg"
    ],
    "list_available_models": [
      "cls"
    ],
    "convert_text_to_waveform": [
      "self"
    ]
  },
  "FFTransformerDecoderAdapter": {
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "is_adapter_available": [
      "self"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "_update_adapter_cfg_input_dim": [
      "self",
      "cfg"
    ]
  },
  "FFTransformerEncoderAdapter": {},
  "AlignmentEncoderAdapter": {
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "is_adapter_available": [
      "self"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "_update_adapter_cfg_input_dim": [
      "self",
      "cfg",
      "module_dim"
    ]
  },
  "TemporalPredictorAdapter": {
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "is_adapter_available": [
      "self"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "_update_adapter_cfg_input_dim": [
      "self",
      "cfg"
    ]
  },
  "fused_add_tanh_sigmoid_multiply": [
    "input_a",
    "input_b"
  ],
  "ExponentialClass": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DenseLayer": {
    "__init__": [
      "self",
      "in_dim",
      "sizes"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BiLSTM": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "lstm_norm_fn",
      "max_batch_size"
    ],
    "lstm_sorted": [
      "self",
      "context",
      "lens",
      "hx"
    ],
    "lstm": [
      "self",
      "context",
      "lens",
      "hx"
    ],
    "lstm_nocast": [
      "self",
      "context",
      "lens"
    ],
    "forward": [
      "self",
      "context",
      "lens"
    ]
  },
  "ConvLSTMLinear": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "n_layers",
      "n_channels",
      "kernel_size",
      "p_dropout",
      "use_partial_padding",
      "norm_fn"
    ],
    "forward": [
      "self",
      "context",
      "lens"
    ]
  },
  "get_radtts_encoder": [
    "encoder_n_convolutions",
    "encoder_embedding_dim",
    "encoder_kernel_size",
    "norm_fn"
  ],
  "Invertible1x1ConvLUS": {
    "__init__": [
      "self",
      "c"
    ],
    "forward": [
      "self",
      "z",
      "inverse"
    ]
  },
  "Invertible1x1Conv": {
    "__init__": [
      "self",
      "c"
    ],
    "forward": [
      "self",
      "z",
      "inverse"
    ]
  },
  "SimpleConvNet": {
    "__init__": [
      "self",
      "n_mel_channels",
      "n_context_dim",
      "final_out_channels",
      "n_layers",
      "kernel_size",
      "with_dilation",
      "max_channels",
      "zero_init",
      "use_partial_padding"
    ],
    "forward": [
      "self",
      "z_w_context",
      "seq_lens"
    ]
  },
  "WN": {
    "__init__": [
      "self",
      "n_in_channels",
      "n_context_dim",
      "n_layers",
      "n_channels",
      "kernel_size",
      "affine_activation",
      "use_partial_padding"
    ],
    "forward": [
      "self",
      "forward_input",
      "seq_lens"
    ]
  },
  "SplineTransformationLayerAR": {
    "__init__": [
      "self",
      "n_in_channels",
      "n_context_dim",
      "n_layers",
      "affine_model",
      "kernel_size",
      "scaling_fn",
      "affine_activation",
      "n_channels",
      "n_bins",
      "left",
      "right",
      "bottom",
      "top",
      "use_quadratic"
    ],
    "normalize": [
      "self",
      "z",
      "inverse"
    ],
    "denormalize": [
      "self",
      "z",
      "inverse"
    ],
    "forward": [
      "self",
      "z",
      "context",
      "inverse"
    ]
  },
  "SplineTransformationLayer": {
    "__init__": [
      "self",
      "n_mel_channels",
      "n_context_dim",
      "n_layers",
      "with_dilation",
      "kernel_size",
      "scaling_fn",
      "affine_activation",
      "n_channels",
      "n_bins",
      "left",
      "right",
      "bottom",
      "top",
      "use_quadratic"
    ],
    "forward": [
      "self",
      "z",
      "context",
      "inverse",
      "seq_lens"
    ]
  },
  "AffineTransformationLayer": {
    "__init__": [
      "self",
      "n_mel_channels",
      "n_context_dim",
      "n_layers",
      "affine_model",
      "with_dilation",
      "kernel_size",
      "scaling_fn",
      "affine_activation",
      "n_channels",
      "use_partial_padding"
    ],
    "get_scaling_and_logs": [
      "self",
      "scale_unconstrained"
    ],
    "forward": [
      "self",
      "z",
      "context",
      "inverse",
      "seq_lens"
    ]
  },
  "ConvAttention": {
    "__init__": [
      "self",
      "n_mel_channels",
      "n_speaker_dim",
      "n_text_channels",
      "n_att_channels",
      "temperature"
    ],
    "forward": [
      "self",
      "queries",
      "keys",
      "query_lens",
      "mask",
      "key_lens",
      "attn_prior"
    ]
  },
  "GaussianDropout": {
    "__init__": [
      "self",
      "stdev"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "get_same_padding": [
    "kernel_size",
    "stride",
    "dilation"
  ],
  "SameLensMaskedConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "padding",
      "groups"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "SameLensMaskedLinear": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "create_channel_mix_layer": [
    "in_feat",
    "out_feat"
  ],
  "create_time_mix_layer": [
    "in_feat",
    "out_feat",
    "kernel_size",
    "stride",
    "conv_type",
    "dilation"
  ],
  "Mix": {
    "__init__": [
      "self",
      "first_mix_layer",
      "second_mix_layer",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "PreNormResidual": {
    "__init__": [
      "self",
      "fn",
      "feature_dim"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "MixerTTSBlock": {
    "__init__": [
      "self",
      "in_feat",
      "expansion_factor",
      "kernel_size",
      "conv_type",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "MixerTTSModule": {
    "__init__": [
      "self",
      "num_tokens",
      "feature_dim",
      "num_layers",
      "kernel_sizes",
      "padding_idx",
      "conv_type",
      "expansion_factor",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "conditioning"
    ]
  },
  "SelfAttentionModule": {
    "__init__": [
      "self",
      "n_text_channels",
      "n_lm_tokens_channels"
    ],
    "forward": [
      "self",
      "queries",
      "keys",
      "values",
      "q_mask",
      "kv_mask"
    ]
  },
  "GreedyCTCDecoder": {
    "__init__": [
      "self",
      "labels",
      "blank"
    ],
    "forward": [
      "self",
      "emission"
    ]
  },
  "ConvolutionLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "is_causal"
    ],
    "forward": [
      "self",
      "signal"
    ]
  },
  "PositionwiseConvFF": {
    "__init__": [
      "self",
      "d_model",
      "d_ffn",
      "p_dropout",
      "kernel_size",
      "bias",
      "is_causal",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Attention": {
    "__init__": [
      "self",
      "n_heads",
      "d_model",
      "p_dropout",
      "is_causal"
    ],
    "compute_qkv_and_mask": [
      "self",
      "query",
      "query_mask",
      "memory",
      "memory_mask"
    ],
    "_init_cache": [],
    "reset_cache": [
      "self",
      "use_cache"
    ],
    "attn_naive": [
      "self",
      "query",
      "query_mask",
      "memory",
      "memory_mask",
      "attn_prior"
    ],
    "forward": [
      "self",
      "query",
      "query_mask",
      "memory",
      "memory_mask",
      "attn_prior"
    ]
  },
  "SelfAttention": {
    "__init__": [
      "self",
      "n_heads",
      "d_model",
      "p_dropout",
      "is_causal",
      "max_length_causal_mask"
    ],
    "compute_qkv_and_mask": [
      "self",
      "query",
      "query_mask",
      "memory",
      "memory_mask"
    ]
  },
  "CrossAttention": {
    "__init__": [
      "self",
      "n_heads",
      "d_model",
      "d_memory",
      "p_dropout"
    ],
    "compute_qkv_and_mask": [
      "self",
      "query",
      "query_mask",
      "memory",
      "memory_mask"
    ]
  },
  "TransformerLayer": {
    "__init__": [
      "self",
      "d_model",
      "d_ffn",
      "sa_n_heads",
      "kernel_size",
      "p_dropout",
      "has_xattn",
      "xa_d_memory",
      "xa_n_heads",
      "is_causal",
      "apply_norm_to_cond",
      "max_length_causal_mask",
      "conv_non_linearity"
    ],
    "_init_cache": [],
    "reset_cache": [
      "self",
      "use_cache"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "cond",
      "cond_mask",
      "attn_prior"
    ]
  },
  "Transformer": {
    "__init__": [
      "self",
      "n_layers",
      "d_model",
      "d_ffn",
      "sa_n_heads",
      "kernel_size",
      "p_dropout",
      "p_dropout_out",
      "has_xattn",
      "xa_d_memory",
      "xa_n_heads",
      "is_causal",
      "apply_norm_to_cond",
      "apply_norm_out",
      "max_length_causal_mask",
      "use_learnable_pos_emb",
      "conv_non_linearity"
    ],
    "reset_cache": [
      "self",
      "use_cache"
    ],
    "_init_weights_gpt2": [
      "module"
    ],
    "_get_layer_inputs": [
      "idx",
      "cond",
      "cond_mask",
      "attn_prior",
      "multi_encoder_mapping"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "cond",
      "cond_mask",
      "attn_prior",
      "multi_encoder_mapping"
    ]
  },
  "get_padding": [
    "kernel_size",
    "dilation"
  ],
  "get_padding_2d": [
    "kernel_size",
    "dilation"
  ],
  "get_down_sample_padding": [
    "kernel_size",
    "stride"
  ],
  "get_up_sample_padding": [
    "kernel_size",
    "stride"
  ],
  "SSLModel": {
    "__init__": [
      "self",
      "slm_model_name"
    ],
    "forward": [
      "self"
    ]
  },
  "SLMDiscriminator": {
    "__init__": [
      "self",
      "slm_model_name",
      "slm_sr",
      "input_sr",
      "slm_hidden",
      "slm_layers",
      "initial_channel",
      "use_spectral_norm"
    ],
    "_forward": [
      "self",
      "x"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio_real",
      "audio_gen"
    ]
  },
  "zero_mean_unit_var_norm": [
    "input_values"
  ],
  "load_fsspec": [
    "path",
    "map_location"
  ],
  "PreEmphasis": {
    "__init__": [
      "self",
      "coefficient"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SELayer": {
    "__init__": [
      "self",
      "channel",
      "reduction"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SEBasicBlock": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "reduction"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNetSpeakerEncoder": {
    "__init__": [
      "self",
      "input_dim",
      "proj_dim",
      "layers",
      "num_filters",
      "encoder_type",
      "log_input",
      "use_torch_spec",
      "audio_config"
    ],
    "_init_layers": [
      "self"
    ],
    "create_layer": [
      "self",
      "block",
      "planes",
      "blocks",
      "stride"
    ],
    "new_parameter": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "l2_norm"
    ],
    "get_torch_mel_spectrogram_class": [
      "self",
      "audio_config"
    ],
    "load_checkpoint": [
      "self",
      "checkpoint_path",
      "strict"
    ]
  },
  "CodecActivation": {
    "__init__": [
      "self",
      "activation",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CausalConvTranspose1dNorm": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "groups",
      "trim_right_ratio",
      "bias"
    ],
    "apply_weight_norm": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ]
  },
  "CausalConv1dNorm": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "groups",
      "pad_mode",
      "extra_pad_mode",
      "bias"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "_get_extra_padding_for_conv1d": [
      "self",
      "hidden_states"
    ],
    "_pad1d": [
      "hidden_states",
      "paddings",
      "mode",
      "value"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ]
  },
  "Conv1dNorm": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "padding",
      "pad_mode"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ]
  },
  "ConvTranspose1dNorm": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "groups"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ]
  },
  "Conv2dNorm": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "PeriodDiscriminator": {
    "__init__": [
      "self",
      "period",
      "lrelu_slope"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio"
    ]
  },
  "MultiPeriodDiscriminator": {
    "__init__": [
      "self",
      "periods",
      "lrelu_slope"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio_real",
      "audio_gen"
    ]
  },
  "DiscriminatorSTFT": {
    "__init__": [
      "self",
      "filters",
      "lrelu_slope"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "spec"
    ]
  },
  "MultiBandDiscriminatorSTFT": {
    "__init__": [
      "self",
      "resolution",
      "stft_bands"
    ],
    "compute_stft": [
      "self",
      "audio"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio"
    ]
  },
  "MultiResolutionDiscriminatorSTFT": {
    "__init__": [
      "self",
      "resolutions",
      "stft_bands"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio_real",
      "audio_gen"
    ]
  },
  "Discriminator": {
    "__init__": [
      "self",
      "discriminators"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio_real",
      "audio_gen"
    ]
  },
  "VectorQuantizerBase": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ],
    "encode": [
      "self",
      "inputs",
      "input_len"
    ],
    "decode": [
      "self",
      "indices",
      "input_len"
    ]
  },
  "FiniteScalarQuantizer": {
    "__init__": [
      "self",
      "num_levels",
      "eps"
    ],
    "codebook_size": [
      "self"
    ],
    "dim": [
      "self"
    ],
    "codebook_dim": [
      "self"
    ],
    "codes": [
      "self"
    ],
    "codebook": [
      "self"
    ],
    "round": [
      "inputs",
      "input_len"
    ],
    "compress": [
      "self",
      "inputs",
      "input_len"
    ],
    "inputs_to_codes": [
      "self",
      "inputs",
      "input_len"
    ],
    "codes_to_nonnegative": [
      "self",
      "codes"
    ],
    "nonnegative_to_codes": [
      "self",
      "codes_nonnegative"
    ],
    "codes_to_indices": [
      "self",
      "codes"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ],
    "encode": [
      "self",
      "inputs",
      "input_len"
    ],
    "decode": [
      "self",
      "indices",
      "input_len"
    ]
  },
  "GroupFiniteScalarQuantizer": {
    "__init__": [
      "self",
      "num_groups",
      "num_levels_per_group"
    ],
    "codebook_dim": [
      "self"
    ],
    "codebook_size_per_group": [
      "self"
    ],
    "codebook_size": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ],
    "encode": [
      "self",
      "inputs",
      "input_len"
    ],
    "decode": [
      "self",
      "indices",
      "input_len"
    ]
  },
  "ResidualBlock": {
    "__init__": [
      "self",
      "channels",
      "filters",
      "kernel_size",
      "dilation",
      "dropout_rate",
      "activation",
      "is_causal",
      "pad_mode"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ]
  },
  "HiFiGANResBlock": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "dilations",
      "activation",
      "is_causal",
      "pad_mode"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ]
  },
  "HiFiGANResLayer": {
    "__init__": [
      "self",
      "channels",
      "kernel_sizes",
      "dilations",
      "activation",
      "is_causal",
      "pad_mode"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ]
  },
  "CausalHiFiGANEncoder": {
    "__init__": [
      "self",
      "encoded_dim",
      "down_sample_rates",
      "base_channels",
      "in_kernel_size",
      "out_kernel_size",
      "resblock_kernel_sizes",
      "resblock_dilation_sizes",
      "activation",
      "pad_mode"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "audio",
      "audio_len"
    ]
  },
  "HiFiGANEncoder": {
    "__init__": [
      "self",
      "encoded_dim",
      "down_sample_rates",
      "base_channels",
      "in_kernel_size",
      "out_kernel_size",
      "resblock_kernel_sizes",
      "resblock_dilation_sizes",
      "activation",
      "pad_mode"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "audio",
      "audio_len"
    ]
  },
  "CausalHiFiGANDecoder": {
    "__init__": [
      "self",
      "input_dim",
      "up_sample_rates",
      "base_channels",
      "in_kernel_size",
      "out_kernel_size",
      "resblock_kernel_sizes",
      "resblock_dilation_sizes",
      "activation",
      "output_activation",
      "pad_mode",
      "n_groups_equal_to_out_channels"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ]
  },
  "HiFiGANDecoder": {
    "__init__": [
      "self",
      "input_dim",
      "up_sample_rates",
      "base_channels",
      "in_kernel_size",
      "out_kernel_size",
      "resblock_kernel_sizes",
      "resblock_dilation_sizes",
      "activation",
      "output_activation",
      "pad_mode",
      "n_groups_equal_to_out_channels"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ]
  },
  "MelSpectrogramProcessor": {
    "__init__": [
      "self",
      "sample_rate",
      "win_length",
      "hop_length",
      "mel_dim",
      "log_guard"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio",
      "audio_len"
    ]
  },
  "ResNetEncoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_layers",
      "hidden_channels",
      "filters",
      "kernel_size",
      "dropout_rate",
      "activation",
      "pad_mode"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ]
  },
  "FullBandMelEncoder": {
    "__init__": [
      "self",
      "mel_processor",
      "encoder"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio",
      "audio_len"
    ]
  },
  "MultiBandMelEncoder": {
    "__init__": [
      "self",
      "mel_bands",
      "mel_processor"
    ],
    "validate_mel_bands": [
      "mel_dim",
      "mel_bands"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio",
      "audio_len"
    ]
  },
  "mask_from_lens": [
    "lens",
    "max_len"
  ],
  "PositionalEmbedding": {
    "__init__": [
      "self",
      "demb"
    ],
    "forward": [
      "self",
      "pos_seq",
      "bsz"
    ]
  },
  "MultiHeadAttn": {
    "__init__": [
      "self",
      "n_head",
      "d_model",
      "d_head",
      "dropout",
      "dropatt",
      "pre_lnorm",
      "condition_types"
    ],
    "forward": [
      "self",
      "inp",
      "attn_mask",
      "conditioning"
    ],
    "_forward": [
      "self",
      "inp",
      "attn_mask",
      "conditioning"
    ]
  },
  "FFTransformerDecoder": {
    "__init__": [
      "self",
      "n_layer",
      "n_head",
      "d_model",
      "d_head",
      "d_inner",
      "kernel_size",
      "dropout",
      "dropatt",
      "dropemb",
      "pre_lnorm",
      "condition_types"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "seq_lens",
      "conditioning"
    ],
    "_forward": [
      "self",
      "inp",
      "mask",
      "conditioning"
    ]
  },
  "FFTransformerEncoder": {
    "__init__": [
      "self",
      "n_layer",
      "n_head",
      "d_model",
      "d_head",
      "d_inner",
      "kernel_size",
      "dropout",
      "dropatt",
      "dropemb",
      "pre_lnorm",
      "n_embed",
      "d_embed",
      "padding_idx",
      "condition_types"
    ],
    "input_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "conditioning"
    ]
  },
  "FFTransformer": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "n_layers",
      "n_head",
      "d_head",
      "d_inner",
      "kernel_size",
      "dropout",
      "dropatt",
      "dropemb"
    ],
    "forward": [
      "self",
      "dec_inp",
      "in_lens"
    ]
  },
  "SUPPORTED_CONDITION_TYPES": [],
  "check_support_condition_types": [
    "condition_types"
  ],
  "masked_instance_norm": [
    "input",
    "mask",
    "weight",
    "bias",
    "momentum",
    "eps"
  ],
  "MaskedInstanceNorm1d": {
    "__init__": [
      "self",
      "num_features",
      "eps",
      "momentum",
      "affine",
      "track_running_stats"
    ],
    "forward": [
      "self",
      "input",
      "mask"
    ]
  },
  "PartialConv1d": {
    "__constants__": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "mask_in"
    ]
  },
  "LinearNorm": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "bias",
      "w_init_gain"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvNorm": {
    "__constants__": [],
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "w_init_gain",
      "use_partial_padding",
      "use_weight_norm",
      "norm_fn"
    ],
    "forward": [
      "self",
      "signal",
      "mask"
    ]
  },
  "LocationLayer": {
    "__init__": [
      "self",
      "attention_n_filters",
      "attention_kernel_size",
      "attention_dim"
    ],
    "forward": [
      "self",
      "attention_weights_cat"
    ]
  },
  "Prenet": {
    "__init__": [
      "self",
      "in_dim",
      "sizes",
      "p_dropout"
    ],
    "forward": [
      "self",
      "x",
      "inference"
    ]
  },
  "WaveNet": {
    "__init__": [
      "self",
      "n_in_channels",
      "n_mel_channels",
      "n_layers",
      "n_channels",
      "kernel_size"
    ],
    "forward": [
      "self",
      "forward_input"
    ]
  },
  "ConditionalLayerNorm": {
    "__init__": [
      "self",
      "hidden_dim",
      "condition_dim",
      "condition_types"
    ],
    "init_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "conditioning"
    ]
  },
  "ConditionalInput": {
    "__init__": [
      "self",
      "hidden_dim",
      "condition_dim",
      "condition_types"
    ],
    "forward": [
      "self",
      "inputs",
      "conditioning"
    ]
  },
  "StyleAttention": {
    "__init__": [
      "self",
      "gst_size",
      "n_style_token",
      "n_style_attn_head"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "Conv2DReLUNorm": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "bias",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "ReferenceEncoder": {
    "__init__": [
      "self",
      "n_mels",
      "cnn_filters",
      "dropout",
      "gru_hidden",
      "kernel_size",
      "stride",
      "padding",
      "bias"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "inputs_lengths"
    ],
    "calculate_post_conv_lengths": [
      "lengths",
      "n_convs",
      "kernel_size",
      "stride",
      "pad"
    ],
    "lengths_to_masks": [
      "lengths"
    ]
  },
  "GlobalStyleToken": {
    "__init__": [
      "self",
      "reference_encoder",
      "gst_size",
      "n_style_token",
      "n_style_attn_head"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "inp",
      "inp_lengths"
    ]
  },
  "SpeakerLookupTable": {
    "__init__": [
      "self",
      "n_speakers",
      "embedding_dim"
    ],
    "forward": [
      "self",
      "speaker"
    ]
  },
  "SpeakerEncoder": {
    "__init__": [
      "self",
      "lookup_module",
      "gst_module",
      "precomputed_embedding_dim"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "overwrite_precomputed_emb": [
      "self",
      "emb"
    ],
    "forward": [
      "self",
      "batch_size",
      "speaker",
      "reference_spec",
      "reference_spec_lens"
    ]
  },
  "LRELU_SLOPE": [],
  "LayerNorm": {
    "__init__": [
      "self",
      "channels",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvReluNorm": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_channels",
      "out_channels",
      "kernel_size",
      "n_layers",
      "p_dropout"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "DDSConv": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "n_layers",
      "p_dropout"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g"
    ]
  },
  "Log": {
    "forward": [
      "self",
      "x",
      "x_mask",
      "reverse"
    ]
  },
  "Flip": {
    "forward": [
      "self",
      "x"
    ]
  },
  "ElementwiseAffine": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "reverse"
    ]
  },
  "ResidualCouplingLayer": {
    "__init__": [
      "self",
      "channels",
      "hidden_channels",
      "kernel_size",
      "dilation_rate",
      "n_layers",
      "p_dropout",
      "gin_channels",
      "mean_only"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g",
      "reverse"
    ]
  },
  "ConvFlow": {
    "__init__": [
      "self",
      "in_channels",
      "filter_channels",
      "kernel_size",
      "n_layers",
      "num_bins",
      "tail_bound"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g",
      "reverse"
    ]
  },
  "StochasticDurationPredictor": {
    "__init__": [
      "self",
      "in_channels",
      "filter_channels",
      "kernel_size",
      "p_dropout",
      "n_flows",
      "gin_channels"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "w",
      "g",
      "reverse",
      "noise_scale"
    ]
  },
  "DurationPredictor": {
    "__init__": [
      "self",
      "in_channels",
      "filter_channels",
      "kernel_size",
      "p_dropout",
      "gin_channels"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g"
    ]
  },
  "TextEncoder": {
    "__init__": [
      "self",
      "n_vocab",
      "out_channels",
      "hidden_channels",
      "filter_channels",
      "n_heads",
      "n_layers",
      "kernel_size",
      "p_dropout",
      "padding_idx"
    ],
    "forward": [
      "self",
      "x",
      "x_lengths"
    ]
  },
  "ResidualCouplingBlock": {
    "__init__": [
      "self",
      "channels",
      "hidden_channels",
      "kernel_size",
      "dilation_rate",
      "n_layers",
      "n_flows",
      "gin_channels"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g",
      "reverse"
    ]
  },
  "PosteriorEncoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "hidden_channels",
      "kernel_size",
      "dilation_rate",
      "n_layers",
      "gin_channels"
    ],
    "forward": [
      "self",
      "x",
      "x_lengths",
      "g"
    ]
  },
  "Generator": {
    "__init__": [
      "self",
      "initial_channel",
      "resblock",
      "resblock_kernel_sizes",
      "resblock_dilation_sizes",
      "upsample_rates",
      "upsample_initial_channel",
      "upsample_kernel_sizes",
      "gin_channels"
    ],
    "forward": [
      "self",
      "x",
      "g"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "DiscriminatorP": {
    "__init__": [
      "self",
      "period",
      "kernel_size",
      "stride",
      "use_spectral_norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DiscriminatorS": {
    "__init__": [
      "self",
      "use_spectral_norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SynthesizerTrn": {
    "__init__": [
      "self",
      "n_vocab",
      "spec_channels",
      "segment_size",
      "inter_channels",
      "hidden_channels",
      "filter_channels",
      "n_heads",
      "n_layers",
      "kernel_size",
      "p_dropout",
      "padding_idx",
      "resblock",
      "resblock_kernel_sizes",
      "resblock_dilation_sizes",
      "upsample_rates",
      "upsample_initial_channel",
      "upsample_kernel_sizes",
      "n_speakers",
      "gin_channels",
      "use_sdp"
    ],
    "forward": [
      "self",
      "text",
      "text_len",
      "spec",
      "spec_len",
      "speakers"
    ],
    "infer": [
      "self",
      "text",
      "text_len",
      "speakers",
      "noise_scale",
      "length_scale",
      "noise_scale_w",
      "max_len"
    ],
    "voice_conversion": [
      "self",
      "y",
      "y_lengths",
      "speaker_src",
      "speaker_tgt"
    ]
  },
  "AttentionEncoder": {
    "__init__": [
      "self",
      "hidden_channels",
      "filter_channels",
      "n_heads",
      "n_layers",
      "kernel_size",
      "p_dropout",
      "window_size"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "MultiHeadAttention": {
    "__init__": [
      "self",
      "channels",
      "out_channels",
      "n_heads",
      "p_dropout",
      "window_size",
      "heads_share",
      "block_length",
      "proximal_bias",
      "proximal_init"
    ],
    "forward": [
      "self",
      "x",
      "c",
      "attn_mask"
    ],
    "attention": [
      "self",
      "query",
      "key",
      "value",
      "mask"
    ],
    "_matmul_with_relative_values": [
      "self",
      "x",
      "y"
    ],
    "_matmul_with_relative_keys": [
      "self",
      "x",
      "y"
    ],
    "_get_relative_embeddings": [
      "self",
      "relative_embeddings",
      "length"
    ],
    "_relative_position_to_absolute_position": [
      "self",
      "x"
    ],
    "_absolute_position_to_relative_position": [
      "self",
      "x"
    ],
    "_attention_bias_proximal": [
      "self",
      "length"
    ]
  },
  "FFN": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "filter_channels",
      "kernel_size",
      "p_dropout",
      "activation",
      "causal"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ],
    "_causal_padding": [
      "self",
      "x"
    ],
    "_same_padding": [
      "self",
      "x"
    ]
  },
  "KernelPredictor": {
    "__init__": [
      "self",
      "cond_channels",
      "conv_in_channels",
      "conv_out_channels",
      "conv_layers",
      "conv_kernel_size",
      "kpnet_hidden_channels",
      "kpnet_conv_size",
      "kpnet_dropout",
      "kpnet_nonlinear_activation",
      "kpnet_nonlinear_activation_params"
    ],
    "forward": [
      "self",
      "c"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "LVCBlock": {
    "__init__": [
      "self",
      "in_channels",
      "cond_channels",
      "stride",
      "dilations",
      "lReLU_slope",
      "conv_kernel_size",
      "cond_hop_length",
      "kpnet_hidden_channels",
      "kpnet_conv_size",
      "kpnet_dropout"
    ],
    "forward": [
      "self",
      "x",
      "c"
    ],
    "location_variable_convolution": [
      "self",
      "x",
      "kernel",
      "bias",
      "dilation",
      "hop_size"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "DiscriminatorR": {
    "__init__": [
      "self",
      "cfg",
      "resolution"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "spectrogram": [
      "self",
      "x"
    ]
  },
  "MultiResolutionDiscriminator": {
    "__init__": [
      "self",
      "cfg",
      "debug"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "y",
      "y_hat"
    ]
  },
  "average_features": [
    "pitch",
    "durs"
  ],
  "log_to_duration": [
    "log_dur",
    "min_dur",
    "max_dur",
    "mask"
  ],
  "ConvReLUNorm": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dropout",
      "condition_dim",
      "condition_types"
    ],
    "forward": [
      "self",
      "signal",
      "conditioning"
    ]
  },
  "TemporalPredictor": {
    "__init__": [
      "self",
      "input_size",
      "filter_size",
      "kernel_size",
      "dropout",
      "n_layers",
      "condition_types"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "enc",
      "enc_mask",
      "conditioning"
    ]
  },
  "FastPitchModule": {
    "__init__": [
      "self",
      "encoder_module",
      "decoder_module",
      "duration_predictor",
      "pitch_predictor",
      "energy_predictor",
      "aligner",
      "speaker_encoder",
      "n_speakers",
      "symbols_embedding_dim",
      "pitch_embedding_kernel_size",
      "energy_embedding_kernel_size",
      "n_mel_channels",
      "min_token_duration",
      "max_token_duration",
      "use_log_energy"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "get_speaker_embedding": [
      "self",
      "batch_size",
      "speaker",
      "reference_spec",
      "reference_spec_lens"
    ],
    "forward": [
      "self"
    ],
    "infer": [
      "self"
    ]
  },
  "FastPitchSSLModule": {
    "__init__": [
      "self",
      "encoder_module",
      "decoder_module",
      "duration_predictor",
      "pitch_predictor",
      "symbols_embedding_dim",
      "pitch_embedding_kernel_size",
      "n_mel_channels",
      "min_token_duration",
      "max_token_duration"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "SEANetResnetBlock": {
    "__init__": [
      "self",
      "channels",
      "activation"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ]
  },
  "SEANetRNN": {
    "__init__": [
      "self",
      "dim",
      "num_layers",
      "rnn_type",
      "use_skip"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ]
  },
  "SEANetEncoder": {
    "__init__": [
      "self",
      "down_sample_rates",
      "base_channels",
      "in_kernel_size",
      "out_kernel_size",
      "encoded_dim",
      "activation",
      "rnn_layers",
      "rnn_type",
      "rnn_skip"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "audio",
      "audio_len"
    ]
  },
  "SEANetDecoder": {
    "__init__": [
      "self",
      "up_sample_rates",
      "base_channels",
      "in_kernel_size",
      "out_kernel_size",
      "encoded_dim",
      "activation",
      "rnn_layers",
      "rnn_type",
      "rnn_skip"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ]
  },
  "_ema_inplace": [
    "moving_avg",
    "new",
    "decay"
  ],
  "_laplace_smoothing": [
    "inputs",
    "n_categories",
    "epsilon"
  ],
  "_compute_distances": [
    "input1",
    "input2"
  ],
  "_sample_vectors": [
    "samples",
    "num_sample"
  ],
  "_k_means": [
    "samples",
    "num_clusters",
    "num_iters"
  ],
  "_mask_3d": [
    "tensor",
    "lengths"
  ],
  "EuclideanCodebook": {
    "__init__": [
      "self",
      "codebook_size",
      "codebook_dim",
      "decay",
      "threshold_ema_dead_code",
      "kmeans_iters"
    ],
    "_init_codes": [
      "self",
      "data"
    ],
    "_expire_codes": [
      "self",
      "inputs"
    ],
    "_update_codes": [
      "self",
      "inputs",
      "indices"
    ],
    "_quantize": [
      "self",
      "inputs"
    ],
    "_dequantize": [
      "self",
      "indices"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ],
    "encode": [
      "self",
      "inputs",
      "input_len"
    ],
    "decode": [
      "self",
      "indices",
      "input_len"
    ]
  },
  "ResidualVectorQuantizer": {
    "__init__": [
      "self",
      "num_codebooks",
      "codebook_size",
      "codebook_dim",
      "decay",
      "threshold_ema_dead_code",
      "kmeans_iters"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ],
    "encode": [
      "self",
      "inputs",
      "input_len"
    ],
    "decode": [
      "self",
      "indices",
      "input_len"
    ]
  },
  "GroupResidualVectorQuantizer": {
    "__init__": [
      "self",
      "num_codebooks",
      "num_groups",
      "codebook_dim"
    ],
    "num_codebooks_per_group": [
      "self"
    ],
    "codebook_dim_per_group": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "input_len"
    ],
    "encode": [
      "self",
      "inputs",
      "input_len"
    ],
    "decode": [
      "self",
      "indices",
      "input_len"
    ]
  },
  "Blur": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EqualLinear": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "lr_mul",
      "bias"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "StyleMapping": {
    "__init__": [
      "self",
      "emb",
      "depth",
      "lr_mul"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RGBBlock": {
    "__init__": [
      "self",
      "latent_dim",
      "input_channel",
      "upsample",
      "channels"
    ],
    "forward": [
      "self",
      "x",
      "prev_rgb",
      "istyle"
    ]
  },
  "Conv2DModulated": {
    "__init__": [
      "self",
      "in_chan",
      "out_chan",
      "kernel",
      "demod",
      "stride",
      "dilation",
      "eps"
    ],
    "_get_same_padding": [
      "self",
      "size",
      "kernel",
      "dilation",
      "stride"
    ],
    "forward": [
      "self",
      "x",
      "y"
    ]
  },
  "GeneratorBlock": {
    "__init__": [
      "self",
      "latent_dim",
      "input_channels",
      "filters",
      "upsample",
      "upsample_rgb",
      "channels"
    ],
    "forward": [
      "self",
      "x",
      "prev_rgb",
      "istyle",
      "inoise"
    ]
  },
  "DiscriminatorBlock": {
    "__init__": [
      "self",
      "input_channels",
      "filters",
      "downsample"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Postnet": {
    "__init__": [
      "self",
      "n_mel_channels",
      "postnet_embedding_dim",
      "postnet_kernel_size",
      "postnet_n_convolutions",
      "p_dropout"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "pad_dur": [
    "dur",
    "txt_enc"
  ],
  "pad_energy_avg_and_f0": [
    "energy_avg",
    "f0",
    "max_out_len"
  ],
  "adjust_f0": [
    "f0",
    "f0_mean",
    "f0_std",
    "vmask_bool",
    "musical_scaling"
  ],
  "FlowStep": {
    "__init__": [
      "self",
      "n_mel_channels",
      "n_context_dim",
      "n_layers",
      "affine_model",
      "scaling_fn",
      "matrix_decomposition",
      "affine_activation",
      "use_partial_padding"
    ],
    "forward": [
      "self",
      "z",
      "context",
      "inverse",
      "seq_lens"
    ]
  },
  "RadTTSModule": {
    "__init__": [
      "self",
      "n_speakers",
      "n_speaker_dim",
      "n_text",
      "n_text_dim",
      "n_flows",
      "n_conv_layers_per_step",
      "n_mel_channels",
      "dummy_speaker_embedding",
      "n_early_size",
      "n_early_every",
      "n_group_size",
      "affine_model",
      "dur_model_config",
      "f0_model_config",
      "energy_model_config",
      "v_model_config",
      "include_modules",
      "scaling_fn",
      "matrix_decomposition",
      "learn_alignments",
      "affine_activation",
      "attn_use_CTC",
      "use_context_lstm",
      "context_lstm_norm",
      "n_f0_dims",
      "n_energy_avg_dims",
      "context_lstm_w_f0_and_energy",
      "use_first_order_features",
      "unvoiced_bias_activation",
      "ap_pred_log_f0"
    ],
    "encode_speaker": [
      "self",
      "spk_ids"
    ],
    "encode_text": [
      "self",
      "text",
      "in_lens"
    ],
    "preprocess_context": [
      "self",
      "context",
      "speaker_vecs",
      "out_lens",
      "f0",
      "energy_avg",
      "assume_padded"
    ],
    "fold": [
      "self",
      "mel"
    ],
    "unfold": [
      "self",
      "mel",
      "assume_padded"
    ],
    "binarize_attention": [
      "self",
      "attn",
      "in_lens",
      "out_lens"
    ],
    "get_first_order_features": [
      "self",
      "feats",
      "dilation"
    ],
    "apply_voice_mask_to_text": [
      "self",
      "text_enc",
      "voiced_mask"
    ],
    "forward": [
      "self",
      "mel",
      "speaker_ids",
      "text",
      "in_lens",
      "out_lens",
      "binarize_attention",
      "attn_prior",
      "f0",
      "energy_avg",
      "voiced_mask"
    ],
    "infer": [
      "self",
      "speaker_id",
      "text",
      "sigma",
      "speaker_id_text",
      "speaker_id_attributes",
      "pace",
      "token_duration_max",
      "in_lens",
      "dur",
      "f0",
      "f0_mean",
      "f0_std",
      "energy_avg",
      "voiced_mask",
      "pitch_shift"
    ],
    "infer_f0": [
      "self",
      "txt_enc_time_expanded",
      "spk_vec",
      "voiced_mask",
      "lens"
    ],
    "infer_energy": [
      "self",
      "txt_enc_time_expanded",
      "spk_vec",
      "lens"
    ],
    "remove_norms": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ]
  },
  "AlignmentEncoder": {
    "__init__": [
      "self",
      "n_mel_channels",
      "n_text_channels",
      "n_att_channels",
      "temperature",
      "condition_types",
      "dist_type"
    ],
    "_apply_mask": [
      "inputs",
      "mask",
      "mask_value"
    ],
    "get_dist": [
      "self",
      "keys",
      "queries",
      "mask"
    ],
    "get_euclidean_dist": [
      "queries_enc",
      "keys_enc"
    ],
    "get_cosine_dist": [
      "queries_enc",
      "keys_enc"
    ],
    "get_durations": [
      "attn_soft",
      "text_len",
      "spect_len"
    ],
    "get_mean_dist_by_durations": [
      "dist",
      "durations",
      "mask"
    ],
    "get_mean_distance_for_word": [
      "l2_dists",
      "durs",
      "start_token",
      "num_tokens"
    ],
    "forward": [
      "self",
      "queries",
      "keys",
      "mask",
      "attn_prior",
      "conditioning"
    ]
  },
  "WaveGlowModule": {
    "__init__": [
      "self",
      "n_mel_channels",
      "n_flows",
      "n_group",
      "n_early_every",
      "n_early_size",
      "n_wn_channels",
      "n_wn_layers",
      "wn_kernel_size"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "forward": [
      "self",
      "spec",
      "z",
      "audio",
      "run_inverse",
      "sigma"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "audio_to_normal_dist": [
      "self"
    ],
    "norm_dist_to_audio": [
      "self"
    ],
    "remove_weightnorm": [
      "self"
    ]
  },
  "init_weights": [
    "m",
    "mean",
    "std"
  ],
  "ResBlock1": {
    "__constants__": [],
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "ResBlock2": {
    "__constants__": [],
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "MultiScaleDiscriminator": {
    "__init__": [
      "self",
      "debug"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "y",
      "y_hat"
    ]
  },
  "get_attribute_prediction_model": [
    "config"
  ],
  "AttributeProcessing": {
    "__init__": [
      "self",
      "take_log_of_input"
    ],
    "normalize": [
      "self",
      "x"
    ],
    "denormalize": [
      "self",
      "x"
    ]
  },
  "BottleneckLayerLayer": {
    "__init__": [
      "self",
      "in_dim",
      "reduction_factor",
      "norm",
      "non_linearity",
      "use_pconv"
    ],
    "forward": [
      "self",
      "x",
      "lens"
    ]
  },
  "DAP": {
    "__init__": [
      "self",
      "n_speaker_dim",
      "bottleneck_hparams",
      "take_log_of_input",
      "arch_hparams",
      "use_transformer"
    ],
    "forward": [
      "self",
      "txt_enc",
      "spk_emb",
      "x",
      "lens"
    ],
    "infer": [
      "self",
      "txt_enc",
      "spk_emb",
      "lens"
    ]
  },
  "maximum_path": [
    "neg_cent",
    "mask"
  ],
  "maximum_path_each": [
    "path",
    "value",
    "t_y",
    "t_x",
    "max_neg_val"
  ],
  "maximum_path_c": [
    "paths",
    "values",
    "t_ys",
    "t_xs"
  ],
  "get_pad_id": [
    "tokenizer"
  ],
  "DuplexS2SDataset": {
    "__init__": [
      "self",
      "tokenizer",
      "frame_length",
      "source_sample_rate",
      "target_sample_rate",
      "input_roles",
      "output_roles"
    ],
    "__getitem__": [
      "self",
      "cuts"
    ]
  },
  "collate_token_channel": [
    "cuts",
    "tokenizer",
    "frame_length",
    "roles"
  ],
  "build_token_channel": [
    "cut",
    "tokenizer",
    "frame_length",
    "roles",
    "pad_id"
  ],
  "SALMDataset": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "__getitem__": [
      "self",
      "conversations"
    ]
  },
  "left_collate_vectors": [
    "tensors",
    "padding_value"
  ],
  "drop_in_memory_data": [
    "conversations"
  ],
  "DataModule": {
    "__init__": [
      "self",
      "cfg",
      "tokenizer",
      "dataset"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "_build_test_dataloader": [
      "self",
      "cfg"
    ],
    "_get_dp_rank": [
      "self"
    ],
    "_get_world_size": [
      "self"
    ]
  },
  "maybe_install_lora": [
    "model"
  ],
  "fp32_precision": [],
  "NsightProfiling": {
    "__init__": [
      "self",
      "begin_step",
      "end_step",
      "gen_shape",
      "nvtx_ranges"
    ],
    "on_train_batch_start": [
      "self",
      "trainer",
      "pl_module",
      "batch",
      "batch_idx"
    ],
    "on_train_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "outputs",
      "batch",
      "batch_idx"
    ]
  },
  "configure_optimizers": [
    "model"
  ],
  "freeze_and_subset": [
    "named_parameters",
    "exclude_patterns",
    "keep_patterns"
  ],
  "is_frozen": [
    "module"
  ],
  "load_pretrained_nemo": [
    "cls",
    "model_path_or_name"
  ],
  "load_pretrained_hf": [
    "model_path_or_name",
    "pretrained_weights",
    "dtype"
  ],
  "move_embedding": [
    "model"
  ],
  "setup_audio_codec": [
    "model"
  ],
  "setup_speech_encoder": [
    "model",
    "pretrained_weights"
  ],
  "HFHubMixin": {
    "_from_pretrained": [
      "cls"
    ],
    "save_pretrained": [
      "self",
      "save_directory"
    ]
  },
  "BLEU": {
    "__init__": [
      "self",
      "normalize",
      "normalizer",
      "verbose"
    ],
    "reset": [
      "self"
    ],
    "update": [
      "self",
      "name",
      "refs",
      "hyps"
    ],
    "compute": [
      "self"
    ]
  },
  "_identity": [
    "x"
  ],
  "ASRBLEU": {
    "__init__": [
      "self",
      "pretrained_asr",
      "normalize",
      "normalizer",
      "verbose"
    ],
    "reset": [
      "self"
    ],
    "update": [
      "self",
      "name",
      "refs",
      "pred_audio",
      "pred_audio_lens"
    ],
    "compute": [
      "self"
    ]
  },
  "WER": {
    "__init__": [
      "self",
      "normalize",
      "normalizer",
      "verbose"
    ],
    "reset": [
      "self"
    ],
    "update": [
      "self",
      "name",
      "refs",
      "hyps"
    ],
    "compute": [
      "self"
    ]
  },
  "SALM": {
    "__init__": [
      "self",
      "cfg"
    ],
    "text_vocab_size": [
      "self"
    ],
    "text_bos_id": [
      "self"
    ],
    "text_eos_id": [
      "self"
    ],
    "text_pad_id": [
      "self"
    ],
    "audio_locator_tag_id": [
      "self"
    ],
    "token_equivalent_duration": [
      "self"
    ],
    "sampling_rate": [
      "self"
    ],
    "forward": [
      "self",
      "input_embeds",
      "attention_mask",
      "cache"
    ],
    "prepare_inputs": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_validation_epoch_start": [
      "self"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_test_epoch_start": [
      "self"
    ],
    "on_test_epoch_end": [
      "self"
    ],
    "test_step": [
      "self"
    ],
    "backward": [
      "self"
    ],
    "generate": [
      "self",
      "prompts",
      "audios",
      "audio_lens",
      "generation_config"
    ],
    "configure_optimizers": [
      "self"
    ],
    "configure_model": [
      "self"
    ],
    "oomptimizer_schema": [
      "self"
    ]
  },
  "replace_placeholders_and_build_targets": [
    "input_ids",
    "embeds",
    "padding_id",
    "placeholder_id",
    "replacements",
    "target_ids"
  ],
  "_unpad_inputs": [
    "input_ids",
    "embeds",
    "target_ids",
    "padding_id"
  ],
  "_resolve_audios_in_prompt": [
    "prompts",
    "sampling_rate",
    "device"
  ],
  "DuplexS2SModel": {
    "__init__": [
      "self",
      "cfg"
    ],
    "speech_vocab_size": [
      "self"
    ],
    "speech_bos_id": [
      "self"
    ],
    "speech_eos_id": [
      "self"
    ],
    "speech_delay_id": [
      "self"
    ],
    "text_vocab_size": [
      "self"
    ],
    "text_bos_id": [
      "self"
    ],
    "text_eos_id": [
      "self"
    ],
    "text_pad_id": [
      "self"
    ],
    "forward": [
      "self",
      "input_embeds",
      "cache"
    ],
    "prepare_inputs": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_train_epoch_start": [
      "self"
    ],
    "on_validation_epoch_start": [
      "self"
    ],
    "on_validation_epoch_end": [
      "self",
      "prefix"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_test_epoch_start": [
      "self"
    ],
    "on_test_epoch_end": [
      "self"
    ],
    "test_step": [
      "self"
    ],
    "_get_bos_embedding": [
      "self"
    ],
    "offline_inference": [
      "self",
      "input_signal",
      "input_signal_lens",
      "decode_audio"
    ],
    "backward": [
      "self"
    ],
    "configure_optimizers": [
      "self"
    ],
    "oomptimizer_schema": [
      "self"
    ],
    "configure_model": [
      "self"
    ]
  },
  "replace_control_speech_codes": [
    "speech_codes",
    "control_codes"
  ],
  "tokens_to_str": [
    "tokens",
    "lengths",
    "tokenizer",
    "pad_id"
  ],
  "DuplexS2SSpeechDecoderModel": {
    "__init__": [
      "self",
      "cfg"
    ],
    "speech_vocab_size": [
      "self"
    ],
    "speech_bos_id": [
      "self"
    ],
    "speech_eos_id": [
      "self"
    ],
    "speech_delay_id": [
      "self"
    ],
    "text_vocab_size": [
      "self"
    ],
    "text_bos_id": [
      "self"
    ],
    "text_eos_id": [
      "self"
    ],
    "text_pad_id": [
      "self"
    ],
    "forward": [
      "self",
      "input_embeds",
      "cache",
      "input_audio_tokens",
      "loss_mask"
    ],
    "prepare_inputs": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_train_epoch_start": [
      "self"
    ],
    "on_validation_epoch_start": [
      "self"
    ],
    "on_validation_epoch_end": [
      "self",
      "prefix"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_test_epoch_start": [
      "self"
    ],
    "on_test_epoch_end": [
      "self"
    ],
    "test_step": [
      "self"
    ],
    "_get_bos_embedding": [
      "self"
    ],
    "offline_inference": [
      "self",
      "input_signal",
      "input_signal_lens",
      "decode_audio"
    ],
    "backward": [
      "self"
    ],
    "configure_optimizers": [
      "self"
    ],
    "oomptimizer_schema": [
      "self"
    ],
    "configure_model": [
      "self"
    ]
  },
  "AudioPerceptionModule": {
    "input_example": [
      "self",
      "max_batch",
      "max_dim",
      "min_length"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "token_equivalent_duration": [
      "self"
    ],
    "__init__": [
      "self",
      "cfg"
    ],
    "maybe_preprocess_audio": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ]
  },
  "IdentityConnector": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "audio_signal",
      "length"
    ]
  },
  "TransformerARSpeechDecoder": {
    "__init__": [
      "self",
      "speech_decoder_parms",
      "lantent_dim",
      "num_audio_codebooks",
      "num_audio_tokens_per_codebook"
    ],
    "forward": [
      "self",
      "hidden_states",
      "speech_mask",
      "input_audio_tokens",
      "return_raw_logits"
    ],
    "sample_codes_from_logits": [
      "self",
      "all_code_logits_t",
      "temperature",
      "topk"
    ],
    "all_logits_to_each_codebooks_logits": [
      "self",
      "logits"
    ],
    "embed_audio_tokens": [
      "self",
      "audio_tokens"
    ],
    "reset_input_and_kv_cache": [
      "self",
      "use_cache"
    ],
    "_init_cache": []
  },
  "get_layer_spec": [
    "is_vit",
    "normalization"
  ],
  "get_layer_spec_te": [
    "is_vit"
  ],
  "get_mlp_module_spec": [
    "use_te"
  ],
  "get_norm_mlp_module_spec_te": [],
  "ptq": [
    "model_path",
    "export_config",
    "calibration_tp",
    "calibration_pp",
    "num_layers_in_first_pipeline_stage",
    "num_layers_in_last_pipeline_stage",
    "devices",
    "num_nodes",
    "quantization_config",
    "forward_loop",
    "legacy_ckpt",
    "trust_remote_code"
  ],
  "MLlamaDataset": {
    "__init__": [
      "self",
      "data_path",
      "data_config",
      "tokenizer",
      "image_processor",
      "sequence_length"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "_process_images": [
      "self",
      "source"
    ],
    "collate_fn": [
      "self",
      "instances"
    ]
  },
  "MLlamaPreloadedDataModule": {
    "__init__": [
      "self",
      "paths",
      "weights",
      "data_config",
      "seq_length",
      "decoder_seq_length",
      "tokenizer",
      "image_processor",
      "micro_batch_size",
      "global_batch_size",
      "num_train_samples",
      "num_val_samples",
      "num_test_samples",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "use_packed_sequence",
      "seed"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "_create_dataloader": [
      "self",
      "dataset"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "LlamaImageTextSample": {},
  "Llama3SampleEncoder": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "multimodal_sample_config"
    ],
    "process_image": [
      "self",
      "image"
    ],
    "apply_prompt_template": [
      "self",
      "input_text",
      "use_plain"
    ],
    "tokenize": [
      "self",
      "prompt"
    ],
    "encode": [
      "self",
      "input_sample",
      "output_sample"
    ],
    "process_answer_str": [
      "self",
      "answer",
      "stop_str"
    ]
  },
  "pad_or_truncate": [
    "sequence_batch",
    "seq_length",
    "padding_value"
  ],
  "LlamaImageTextRawBatch": {},
  "LlamaTaskEncoder": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "multimodal_sample_config",
      "seq_length"
    ],
    "batch": [
      "self",
      "samples"
    ]
  },
  "_MockMLlamaDataset": {
    "__init__": [
      "self",
      "vocab_size",
      "crop_size",
      "name",
      "num_samples",
      "seq_length",
      "seed"
    ],
    "__len__": [
      "self"
    ],
    "_get_text": [
      "self",
      "idx"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "MLlamaConfig11B": {},
  "MLlamaConfig11BInstruct": {},
  "MLlamaConfig90B": {},
  "MLlamaConfig90BInstruct": {},
  "HFMLlamaImporter": {
    "init": [
      "self"
    ],
    "local_path": [
      "self",
      "base_path"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ],
    "_language_model_config": [
      "self",
      "source"
    ],
    "_vision_model_config": [
      "self",
      "source"
    ]
  },
  "HFMLlamaExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target",
      "source_config"
    ],
    "tokenizer": [
      "self"
    ],
    "ckpt_load": [
      "self",
      "path"
    ],
    "_modify_mllama_source_state": [
      "self",
      "state_dict",
      "source_config"
    ],
    "config": [
      "self"
    ]
  },
  "_rename_xattn_layer_nums_hf": [
    "source"
  ],
  "_import_embedding_hf": [
    "a"
  ],
  "_import_patch_embedding_hf": [
    "a"
  ],
  "_import_gate": [
    "gate"
  ],
  "_import_vision_qkv": [
    "ctx",
    "q",
    "k",
    "v"
  ],
  "_import_text_qkv": [
    "ctx",
    "q",
    "k",
    "v"
  ],
  "_import_text_kv": [
    "ctx",
    "k",
    "v"
  ],
  "_import_simple_concat": [
    "a",
    "b"
  ],
  "_merge_kv": [
    "k",
    "v",
    "head_num",
    "num_query_groups",
    "head_size",
    "hidden_size"
  ],
  "_merge_qkv": [
    "q",
    "k",
    "v",
    "head_num",
    "num_query_groups",
    "head_size",
    "hidden_size"
  ],
  "_split_kv": [
    "kv",
    "head_num",
    "num_query_groups",
    "head_size",
    "hidden_size"
  ],
  "_split_qkv": [
    "qkv",
    "head_num",
    "num_query_groups",
    "head_size",
    "hidden_size"
  ],
  "_export_gate": [
    "gate"
  ],
  "_export_patch_embedding_hf": [
    "a"
  ],
  "_export_vision_qkv": [
    "ctx",
    "qkv"
  ],
  "_export_text_kv": [
    "ctx",
    "kv"
  ],
  "_export_text_qkv": [
    "ctx",
    "qkv"
  ],
  "_export_simple_split": [
    "linear_fc1"
  ],
  "_export_embedding_hf": [
    "word_embeddings",
    "learnable_embedding"
  ],
  "mllama_data_step": [
    "dataloader_iter"
  ],
  "mllama_forward_step": [
    "model",
    "batch"
  ],
  "set_input_tensor": [
    "self",
    "tensor"
  ],
  "CrossAttentionVisionConfig": {
    "max_aspect_ratio_id": [
      "self"
    ],
    "configure_model": [
      "self"
    ]
  },
  "CrossAttentionTextConfig": {
    "_init_fusion_schedule": [
      "self",
      "num_layers"
    ],
    "configure_model": [
      "self",
      "tokenizer",
      "pre_process",
      "post_process",
      "vp_stage"
    ]
  },
  "MLlamaModelConfig": {
    "__post_init__": [
      "self"
    ],
    "configure_model": [
      "self",
      "tokenizer",
      "vp_stage"
    ]
  },
  "CrossAttentionVisionModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "images",
      "aspect_ratio_ids"
    ],
    "set_input_tensor": [
      "self",
      "tensor"
    ]
  },
  "MLlamaBaseModel": {
    "__init__": [
      "self",
      "config",
      "tokenizer",
      "pre_process",
      "post_process",
      "add_encoder",
      "add_decoder",
      "vp_stage"
    ],
    "compute_xattn_caches_masks": [
      "self",
      "vision_tokens",
      "vision_orig_shape",
      "batch_masks",
      "num_chunks",
      "total_len"
    ],
    "forward": [
      "self",
      "position_ids",
      "tokens",
      "labels",
      "batch_images",
      "batch_masks",
      "num_chunks",
      "aspect_ratio_ids",
      "cross_attention_masks",
      "full_text_row_masked_out_mask",
      "xattn_caches",
      "inference_params"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ]
  },
  "MLlamaModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "configure_model": [
      "self",
      "vp_stage"
    ],
    "forward": [
      "self",
      "batch_images",
      "tokens",
      "position_ids",
      "batch_masks",
      "num_chunks",
      "aspect_ratio_ids",
      "labels",
      "cross_attention_masks",
      "full_text_row_masked_out_mask",
      "xattn_caches"
    ],
    "data_step": [
      "self",
      "dataloader_iter"
    ],
    "forward_step": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "_pad_attention_masks": [
    "masks",
    "num_chunks",
    "total_length",
    "max_chunks",
    "device",
    "dtype"
  ],
  "_get_full_row_masked_out_mask": [
    "attention_bias",
    "mask_value"
  ],
  "_generate_cross_attention_mask": [
    "text_token_count",
    "text_device",
    "text_dtype",
    "vision_tokens",
    "cross_attention_masks"
  ],
  "create_vision_mask_tensor": [
    "tokens",
    "vision_token_id"
  ],
  "to_2tuple": [
    "x"
  ],
  "build_encoder_attention_mask": [
    "x",
    "ar_ids",
    "ntok",
    "num_chunks",
    "supported_aspect_ratios"
  ],
  "get_image_transformer_layer_spec": [],
  "forward_with_return_intermediate": [
    "self",
    "hidden_states",
    "attention_mask",
    "context",
    "context_mask",
    "rotary_pos_emb",
    "attention_bias",
    "inference_params",
    "packed_seq_params",
    "return_intermediate"
  ],
  "ColumnParallelConv2dPatch": {
    "__init__": [
      "self",
      "config",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PrecomputedTilePositionEmbedding": {
    "__init__": [
      "self",
      "config",
      "gated"
    ],
    "forward": [
      "self",
      "hidden_states",
      "aspect_ratio_ids"
    ]
  },
  "SelfAttentionNoBias": {
    "__init__": [
      "self",
      "config",
      "submodules",
      "layer_number",
      "attn_mask_type"
    ]
  },
  "ImageTransformerLayer": {
    "__init__": [
      "self",
      "config",
      "submodules",
      "layer_number",
      "hidden_dropout"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "rotary_pos_emb",
      "attention_bias",
      "inference_params",
      "packed_seq_params"
    ]
  },
  "VisionEncoder": {
    "__init__": [
      "self",
      "config",
      "image_size",
      "patch_size",
      "in_channels",
      "pre_process",
      "post_process",
      "return_intermediate"
    ],
    "apply_positional_embedding": [
      "self",
      "x",
      "aspect_ratio_ids"
    ],
    "apply_class_embedding": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "images",
      "ar_ids"
    ]
  },
  "MLlamaCrossAttentionSubmodules": {},
  "CrossAttentionTextModel": {
    "__init__": [
      "self",
      "config",
      "transformer_layer_spec",
      "vocab_size",
      "max_sequence_length",
      "pre_process",
      "post_process",
      "fp16_lm_cross_entropy",
      "parallel_output",
      "share_embeddings_and_output_weights",
      "position_embedding_type",
      "rotary_percent",
      "rotary_base",
      "seq_len_interpolation_factor",
      "vp_stage"
    ],
    "get_partially_trainable_embedding": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "decoder_input",
      "cross_attention_masks",
      "full_text_row_masked_out_mask",
      "xattn_caches",
      "labels",
      "inference_params",
      "packed_seq_params",
      "extra_block_kwargs"
    ]
  },
  "CrossAttentionTransformerBlock": {
    "__init__": [
      "self"
    ],
    "_get_layer_offset": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "xattn_caches",
      "cross_attention_masks",
      "full_text_row_masked_out_mask",
      "rotary_pos_emb",
      "attention_bias",
      "cross_attention_bias",
      "inference_params",
      "packed_seq_params"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "CrossAttentionTransformerLayer": {
    "__init__": [
      "self",
      "config",
      "submodules",
      "layer_number",
      "hidden_dropout"
    ],
    "compute_xattn_kv_cache": [
      "self",
      "xattn_tokens"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cross_attention_masks",
      "xattn_cache",
      "full_text_row_masked_out_mask",
      "rotary_pos_emb",
      "cross_attention_bias",
      "inference_params",
      "packed_seq_params"
    ]
  },
  "DummyCrossAttentionTransformerLayer": {
    "__call__": [
      "self",
      "hidden_states"
    ],
    "compute_xattn_kv_cache": [
      "self",
      "xattn_tokens"
    ]
  },
  "MLlamaCrossAttention": {
    "__init__": [
      "self",
      "config",
      "submodules",
      "layer_number",
      "attn_mask_type"
    ],
    "get_key_value_tensors": [
      "self",
      "key_value_states"
    ],
    "get_query_tensor": [
      "self",
      "hidden_states"
    ],
    "get_query_key_value_tensors": [
      "self",
      "hidden_states",
      "key_value_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cross_attention_masks",
      "xattn_cache",
      "full_text_row_masked_out_mask",
      "inference_params",
      "rotary_pos_emb",
      "rotary_pos_cos",
      "rotary_pos_sin",
      "cross_attention_bias",
      "packed_seq_params"
    ],
    "_compute_xattn_kv_cache": [
      "self",
      "xattn_tokens"
    ]
  },
  "set_modelopt_spec_if_exists_in_ckpt": [
    "model",
    "path"
  ],
  "_set_llama4_modelopt_spec": [
    "model_cfg"
  ],
  "_get_llama4_modelopt_spec": [
    "config",
    "local_core_attention",
    "remap_te_layernorm",
    "real_quant_cfg",
    "qk_l2_norm"
  ],
  "setup_trainer_and_restore_model_with_modelopt_spec": [
    "model_path",
    "tensor_model_parallel_size",
    "pipeline_model_parallel_size",
    "num_layers_in_first_pipeline_stage",
    "num_layers_in_last_pipeline_stage",
    "expert_model_parallel_size",
    "devices",
    "num_nodes",
    "inference_only",
    "legacy_ckpt",
    "strategy_kwargs",
    "trainer_kwargs",
    "model_config_overrides"
  ],
  "LlavaNextSampleEncoder": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "multimodal_sample_config"
    ],
    "process_image": [
      "self",
      "image"
    ],
    "encode": [
      "self",
      "input_sample",
      "output_sample"
    ]
  },
  "convert_to_packed_llava_next": [
    "tokens",
    "labels",
    "ignore_index",
    "pad_to_multiple_of",
    "final_padding_to"
  ],
  "LlavaNextSimilarityInterleavedSampleEncoder": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "multimodal_sample_config"
    ],
    "process_image": [
      "self",
      "image"
    ],
    "encode": [
      "self",
      "input_sample",
      "output_sample"
    ]
  },
  "image_size_to_num_patches": [
    "image_size",
    "grid_pinpoints",
    "patch_size"
  ],
  "select_best_resolution": [
    "original_size",
    "possible_resolutions"
  ],
  "LlavaNextTaskEncoder": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "multimodal_sample_config",
      "packed_sequence",
      "packed_sequence_size",
      "num_image_embeddings_per_tile"
    ],
    "batch": [
      "self",
      "samples"
    ],
    "select_samples_to_pack": [
      "self",
      "samples"
    ],
    "pack_selected_samples": [
      "self",
      "samples"
    ]
  },
  "_MockLlavaNextDataset": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "name",
      "num_samples",
      "seq_length",
      "seed"
    ],
    "__len__": [
      "self"
    ],
    "_get_text": [
      "self",
      "idx"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "LlavaNextTextSample": {},
  "PackedLlavaNextTextSample": {},
  "LlavaNextTextRawBatch": {},
  "PackedLlavaNextTextRawBatch": {},
  "llava_next_data_step": [
    "dataloader_iter"
  ],
  "llava_next_forward_step": [
    "model",
    "batch"
  ],
  "LlavaNextConfig": {
    "configure_model": [
      "self",
      "tokenizer",
      "vp_stage"
    ]
  },
  "MCoreLlavaNextModel": {
    "__init__": [
      "self",
      "config",
      "tokenizer",
      "pre_process",
      "post_process",
      "add_encoder",
      "add_decoder",
      "drop_vision_class_token",
      "vp_stage"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "image_sizes",
      "loss_mask",
      "attention_mask",
      "media",
      "labels",
      "inference_params",
      "num_media_tiles",
      "media_token_index",
      "runtime_gather_output",
      "packed_seq_params"
    ]
  },
  "LlavaNextConfig7B": {},
  "LlavaNextConfig13B": {},
  "LlavaNextModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "configure_model": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "image_sizes",
      "loss_mask",
      "attention_mask",
      "media",
      "labels",
      "inference_params",
      "num_media_tiles",
      "packed_seq_params"
    ]
  },
  "HFLlavaNextImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "config": [
      "self"
    ]
  },
  "HFLlavaNextExporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "_export_language_qkv": [
    "ctx",
    "linear_qkv"
  ],
  "_export_vision_qkv_bias": [
    "ctx",
    "linear_qkv_bias"
  ],
  "_export_cls_token": [
    "ctx",
    "class_token"
  ],
  "_export_language_linear_fc1": [
    "ctx",
    "linear_fc1"
  ],
  "_export_embedding": [
    "ctx",
    "embedding"
  ],
  "_export_language_head": [
    "ctx",
    "output_weight"
  ],
  "get_image_sequence_length": [
    "img_h",
    "img_w",
    "patch_dim",
    "add_class_token",
    "class_token_len"
  ],
  "unpad_image": [
    "tensor",
    "original_size"
  ],
  "get_anyres_image_grid_shape": [
    "image_size",
    "grid_pinpoints",
    "patch_size"
  ],
  "pack_image_features": [
    "image_features",
    "image_sizes",
    "vision_feature_select_strategy",
    "image_newline"
  ],
  "get_number_of_features": [
    "orig_height",
    "orig_width",
    "height",
    "width",
    "image_grid_pinpoints",
    "patch_size"
  ],
  "get_unpadded_features": [
    "height",
    "width",
    "patches_height",
    "patches_width",
    "scale_height",
    "scale_width"
  ],
  "LoRA": {
    "freeze_model": [
      "self",
      "model"
    ]
  },
  "search_for_fit": [
    "numbers",
    "capacity"
  ],
  "greedy_knapsack": [
    "item_sizes",
    "samples",
    "max_capacity"
  ],
  "predict_seq_len": [
    "instance_tokens",
    "num_image_embeddings_per_tile",
    "media_token_index"
  ],
  "predict_seq_len_with_padding": [
    "instance_tokens",
    "pad_to_multiple_of"
  ],
  "convert_to_packed": [
    "tokens",
    "labels",
    "num_image_embeddings_per_tile",
    "media_token_index",
    "ignore_index",
    "pad_to_multiple_of"
  ],
  "TarOrFolderImageLoader": {
    "__init__": [
      "self",
      "image_folder"
    ],
    "build_index": [
      "self"
    ],
    "open_image": [
      "self",
      "file_name"
    ]
  },
  "TarOrFolderVideoLoader": {
    "__init__": [
      "self",
      "video_folder",
      "data_config"
    ],
    "build_index": [
      "self"
    ],
    "open_video": [
      "self",
      "file_name"
    ],
    "flatten_frames": [
      "self",
      "cap"
    ]
  },
  "process_image": [
    "processor",
    "image",
    "image_process_mode"
  ],
  "tokenize_special_token": [
    "prompt",
    "tokenizer",
    "special_token_map"
  ],
  "find_pattern_indices": [
    "template",
    "pattern",
    "search_start_index",
    "allow_first_token_mismatch"
  ],
  "LazySupervisedDataset": {
    "__init__": [
      "self",
      "data_path",
      "data_config",
      "tokenizer",
      "image_processor"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "_process_images": [
      "self",
      "source"
    ],
    "_apply_prompt_templates": [
      "self",
      "source",
      "use_plain"
    ],
    "_tokenize_and_label": [
      "self",
      "conversations"
    ],
    "_get_crop_size": [
      "self"
    ]
  },
  "NevaDataset": {
    "__init__": [
      "self",
      "data_path",
      "data_config",
      "tokenizer",
      "image_processor",
      "packed_sequence",
      "num_image_embeddings_per_tile"
    ],
    "collate_fn": [
      "self",
      "instances"
    ]
  },
  "NevaPreloadedDataModule": {
    "__init__": [
      "self",
      "paths",
      "weights",
      "data_config",
      "seq_length",
      "decoder_seq_length",
      "tokenizer",
      "image_processor",
      "micro_batch_size",
      "global_batch_size",
      "num_train_samples",
      "num_val_samples",
      "num_test_samples",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "packed_sequence",
      "num_image_embeddings_per_tile",
      "seed"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "_create_dataloader": [
      "self",
      "dataset"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "MultiModalToken": {},
  "ImageToken": {},
  "VideoToken": {},
  "IGNORE_INDEX": [],
  "IMAGE_TOKEN_INDEX": [],
  "VIDEO_TOKEN_INDEX": [],
  "SPECIAL_TOKEN_MAP": [],
  "DataConfig": {},
  "ImageDataConfig": {},
  "VideoDataConfig": {},
  "_MockNevaDataset": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "name",
      "num_samples",
      "seq_length",
      "seed",
      "packed_sequence",
      "num_image_embeddings_per_tile"
    ],
    "__len__": [
      "self"
    ],
    "_get_text": [
      "self",
      "idx"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "SeparatorStyle": {
    "SINGLE": [],
    "TWO": [],
    "MPT": [],
    "PLAIN": [],
    "CHATML": [],
    "LLAMA_2": [],
    "LLAMA_3": [],
    "MLLAMA": [],
    "MISTRAL": [],
    "NVGPT": [],
    "QWEN": [],
    "GEMMA": []
  },
  "Conversation": {
    "process_prompt_with_images": [
      "self",
      "messages"
    ],
    "process_chat_template": [
      "self",
      "tokenizer_name_or_path",
      "messages"
    ],
    "get_prompt": [
      "self"
    ],
    "append_message": [
      "self",
      "role",
      "message"
    ],
    "process_image": [
      "self",
      "image",
      "image_process_mode",
      "return_pil",
      "image_format"
    ],
    "get_images": [
      "self",
      "return_pil",
      "return_path"
    ],
    "to_gradio_chatbot": [
      "self"
    ],
    "copy": [
      "self"
    ],
    "dict": [
      "self"
    ]
  },
  "conv_nvgpt": [],
  "conv_nv_dpo": [],
  "conv_vicuna_v0": [],
  "conv_vicuna_v1": [],
  "conv_llama_2": [],
  "conv_llava_llama_2": [],
  "conv_llava_llama_3": [],
  "conv_mllama": [],
  "conv_mistral_instruct": [],
  "conv_llava_llama_2_simple": [],
  "conv_llava_llama_2_mmtag": [],
  "conv_mpt": [],
  "conv_qwen": [],
  "conv_gemma_instruct": [],
  "conv_llava_plain": [],
  "conv_llava_v0": [],
  "conv_llava_v0_mmtag": [],
  "conv_llava_v1": [],
  "conv_llava_v1_mmtag": [],
  "conv_mistral_vila": [],
  "conv_mistral_orca": [],
  "conv_mistral_zephyr": [],
  "conv_mistral_direct": [],
  "conv_chatml_direct": [],
  "default_conversation": [],
  "conv_templates": [],
  "neva_data_step": [
    "dataloader_iter"
  ],
  "neva_forward_step": [
    "model",
    "batch"
  ],
  "NevaConfig": {
    "__post_init__": [
      "self"
    ],
    "configure_model": [
      "self",
      "tokenizer",
      "vp_stage"
    ]
  },
  "MCoreNevaModel": {
    "__init__": [
      "self",
      "config",
      "tokenizer",
      "pre_process",
      "post_process",
      "add_encoder",
      "add_decoder",
      "drop_vision_class_token",
      "vp_stage"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "loss_mask",
      "attention_mask",
      "images",
      "labels",
      "inference_params",
      "num_image_tiles",
      "image_token_index",
      "runtime_gather_output",
      "image_token_mask",
      "packed_seq_params"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ],
    "_preprocess_data": [
      "self",
      "image_embeddings",
      "language_embeddings",
      "input_ids",
      "loss_mask",
      "labels",
      "use_inference_kv_cache",
      "image_token_index",
      "num_image_tiles",
      "attention_mask",
      "packed_seq_params"
    ],
    "_get_shard_factor": [
      "self",
      "packed_seq_params"
    ],
    "_process_embedding_token_parallel": [
      "self",
      "combined_embeddings",
      "new_labels",
      "new_loss_mask",
      "packed_seq_params"
    ]
  },
  "NevaModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "configure_model": [
      "self",
      "vp_stage"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "loss_mask",
      "attention_mask",
      "images",
      "labels",
      "inference_params",
      "num_image_tiles",
      "image_token_index",
      "runtime_gather_output",
      "image_token_mask",
      "packed_seq_params"
    ],
    "data_step": [
      "self",
      "dataloader_iter"
    ],
    "forward_step": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "LlavaConfig": {},
  "Llava15Config7B": {},
  "Llava15Config13B": {},
  "LlavaModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFLlavaImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target",
      "image_newline"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "import_qkv": [
    "q",
    "k",
    "v",
    "head_num",
    "num_query_groups",
    "heads_per_group",
    "hidden_size",
    "head_size"
  ],
  "export_qkv": [
    "linear_qkv",
    "head_num",
    "num_query_groups",
    "heads_per_group",
    "hidden_size",
    "head_size"
  ],
  "export_qkv_bias": [
    "qkv_bias",
    "head_num",
    "num_query_groups",
    "heads_per_group",
    "head_size"
  ],
  "_import_language_qkv": [
    "ctx",
    "q",
    "k",
    "v"
  ],
  "_import_vision_qkv_bias": [
    "ctx",
    "q_bias",
    "k_bias",
    "v_bias"
  ],
  "_import_cls_token": [
    "ctx",
    "cls_token"
  ],
  "_import_linear_fc1": [
    "down",
    "gate"
  ],
  "gather_features": [
    "image_features",
    "text_features",
    "local_loss",
    "gather_with_grad"
  ],
  "ClipMegatronLoss": {
    "__init__": [
      "self",
      "local_loss",
      "gather_with_grad",
      "cache_labels"
    ],
    "forward": [
      "self",
      "batch",
      "forward_out"
    ],
    "reduce": [
      "self",
      "losses_reduced_per_micro_batch"
    ]
  },
  "cook_raw_iamges": [
    "sample"
  ],
  "ClipTaskEncoder": {
    "cookers": [],
    "__init__": [
      "self",
      "img_h",
      "img_w",
      "img_mean",
      "img_std",
      "max_length",
      "tokenizer",
      "image_processor",
      "is_train"
    ],
    "encode_sample": [
      "self",
      "sample"
    ]
  },
  "_MockClipDataset": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "name",
      "num_samples",
      "seq_length",
      "seed",
      "task_encoder"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "clip_forward_step": [
    "model",
    "batch"
  ],
  "clip_data_step": [
    "dataloader_iter"
  ],
  "CLIPViTConfig": {
    "configure_model": [
      "self"
    ]
  },
  "CLIPViTModel": {
    "__init__": [
      "self",
      "transformer_config",
      "transformer_layer_spec",
      "add_class_token",
      "class_token_len",
      "patch_dim",
      "img_h",
      "img_w",
      "model_subtype",
      "output_dim"
    ],
    "set_input_tensor": [
      "self",
      "tensor"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CLIPTextModelConfig": {
    "configure_model": [
      "self",
      "tokenizer",
      "pre_process",
      "post_process"
    ]
  },
  "CLIPTextModel": {
    "__init__": [
      "self",
      "transformer_config",
      "transformer_layer_spec",
      "vocab_size",
      "max_sequence_length",
      "output_dim",
      "share_embeddings_and_output_weights"
    ],
    "forward": [
      "self",
      "input_ids"
    ],
    "set_input_tensor": [
      "self",
      "tensor"
    ]
  },
  "CLIPConfig": {
    "configure_model": [
      "self",
      "tokenizer",
      "pre_process",
      "post_process"
    ]
  },
  "MCoreClipModel": {
    "__init__": [
      "self",
      "config",
      "tokenizer",
      "pre_process",
      "post_process"
    ],
    "forward": [
      "self",
      "images",
      "captions"
    ],
    "set_input_tensor": [
      "self",
      "tensor"
    ]
  },
  "CLIPModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "imagenet_val",
      "mbs",
      "gbs",
      "max_workers"
    ],
    "on_fit_start": [
      "self"
    ],
    "configure_model": [
      "self"
    ],
    "forward": [
      "self",
      "images",
      "captions"
    ],
    "data_step": [
      "self",
      "dataloader_iter"
    ],
    "forward_step": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "zero_shot_classifier": [
      "self"
    ],
    "zero_shot_eval": [
      "self"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "CLIPViTL_14_224_Config": {},
  "CLIPViTB_32_224_Config": {},
  "CLIPTextModelB_32_224_Config": {},
  "CLIPTextModelL_14_224_Config": {},
  "CLIPConfigL14": {},
  "CLIPConfigB32": {},
  "HFClipImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target",
      "image_newline"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "_import_language_qkv_bias": [
    "ctx",
    "q_bias",
    "k_bias",
    "v_bias"
  ],
  "TaskEncoderConfig": {},
  "TaskEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "encode_batch": [
      "self",
      "batch_data"
    ],
    "encode_vqa_sample": [
      "self",
      "input_sample"
    ]
  },
  "MockLlama4Dataset": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "name",
      "num_samples",
      "seq_length",
      "seed",
      "packed_sequence",
      "pixel_shuffle_ratio",
      "num_image_embeddings_per_tile",
      "num_tiles_per_image"
    ],
    "__len__": [
      "self"
    ],
    "_get_text": [
      "self",
      "idx"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "llama4_data_step": [
    "dataloader_iter"
  ],
  "llama4_forward_step": [
    "model",
    "batch"
  ],
  "Llama4OmniConfig": {
    "__post_init__": [
      "self"
    ],
    "configure_model": [
      "self",
      "tokenizer",
      "vp_stage"
    ]
  },
  "Llama4OmniBaseModel": {
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "loss_mask",
      "attention_mask",
      "images",
      "labels",
      "inference_params",
      "runtime_gather_output",
      "packed_seq_params"
    ]
  },
  "Llama4OmniModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "Llama4ScoutExperts16Config": {},
  "Llama4MaverickExperts128Config": {},
  "HFLlama4OmniImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "_modify_llama4_source_state": [
      "self",
      "source"
    ],
    "config": [
      "self"
    ]
  },
  "HFLlama4OmniExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "config": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target",
      "source_config"
    ],
    "tokenizer": [
      "self"
    ],
    "ckpt_load": [
      "self",
      "path"
    ],
    "_modify_llama4_source_state": [
      "self",
      "state_dict",
      "source_config"
    ]
  },
  "Llama4VisionConfig": {
    "configure_model": [
      "self"
    ]
  },
  "PackingIndex": {
    "Z": [],
    "Y": [],
    "X": [],
    "TIME": [],
    "HEIGHT": [],
    "WIDTH": [],
    "IDX": [],
    "BATCH_IDX": [],
    "NUM_METADATA": [],
    "ID_CLS_TOKEN": [],
    "ID_PAD_TOKEN": []
  },
  "PixelShuffle": {
    "__init__": [
      "self",
      "ps_ratio"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "pixel_shuffle_op": [
    "input_x",
    "ps_ratio"
  ],
  "PixelShuffleMLP": {
    "__init__": [
      "self",
      "config",
      "ps_ratio",
      "input_dim",
      "output_dim",
      "add_fc"
    ],
    "forward": [
      "self",
      "encoded_patches"
    ]
  },
  "Llama4ViTModel": {
    "__init__": [
      "self",
      "transformer_config",
      "transformer_layer_spec",
      "ln_pre_impl",
      "ln_post_impl",
      "add_class_token",
      "class_token_len",
      "patch_dim",
      "img_h",
      "img_w",
      "model_subtype"
    ],
    "get_rope_emb": [
      "self"
    ],
    "get_rope_freqs": [
      "self",
      "dim",
      "theta"
    ],
    "compute_rope_freqs": [
      "self",
      "freqs",
      "t"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ],
    "_encode": [
      "self",
      "x",
      "attention_mask"
    ],
    "forward": [
      "self",
      "images"
    ]
  },
  "clean_split": [
    "name"
  ],
  "make_dataset_splits": [
    "dataset",
    "split",
    "split_aliases"
  ],
  "has_dist_env_init_or_rank_env_var": [],
  "batchify": [
    "tensor"
  ],
  "extract_key_from_dicts": [
    "batch",
    "key"
  ],
  "pad_within_micro": [
    "batch",
    "pad_token_id"
  ],
  "HFDatasetDataModule": {
    "__init__": [
      "self",
      "path_or_dataset",
      "split",
      "collate_fn",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "seq_length",
      "micro_batch_size",
      "global_batch_size",
      "pad_token_id",
      "use_dist_sampler",
      "train_aliases",
      "test_aliases",
      "val_aliases"
    ],
    "from_dict": [
      "dataset_dict",
      "split"
    ],
    "collate_fn": [
      "batch",
      "pad_token_id"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "get_data_sampler": [
      "self",
      "dataset"
    ],
    "_make_dataloader": [
      "self",
      "dataset",
      "collate_fn"
    ],
    "train": [
      "self"
    ],
    "val": [
      "self"
    ],
    "test": [
      "self"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "map": [
      "self",
      "function",
      "split_names"
    ]
  },
  "pretrain_performance_optimizations": [
    "recipe"
  ],
  "NevaConfig8B": {},
  "finetune_performance_optimizations": [
    "recipe"
  ],
  "HF_MODEL_NAME": [],
  "process_vision": [
    "processor",
    "images",
    "videos",
    "fps",
    "model_version"
  ],
  "infer_seqlen": [
    "source_len",
    "target_len",
    "cutoff_len"
  ],
  "extract_dialogue_pairs": [
    "tokens",
    "decoded_tokens"
  ],
  "truncate_tokens": [
    "tokens",
    "labels",
    "max_sequence_length",
    "tokenizer"
  ],
  "PreloadedSupervisedDataset": {
    "__init__": [
      "self",
      "data_path",
      "data_config",
      "tokenizer",
      "image_processor",
      "model_version",
      "sequence_length"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "_normalize_vision_paths": [
      "self",
      "source",
      "image_folder",
      "video_folder"
    ],
    "_fetch_vision_content": [
      "self",
      "images",
      "videos"
    ],
    "_process_vision": [
      "self",
      "source",
      "image_folder",
      "video_folder",
      "model_version"
    ],
    "_apply_prompt_templates": [
      "self",
      "conv",
      "source",
      "use_plain"
    ],
    "_tokenize_and_label": [
      "self",
      "conv",
      "chatml",
      "vision_tensors"
    ],
    "_get_crop_size": [
      "self"
    ]
  },
  "Qwen2VLDataset": {
    "__init__": [
      "self",
      "data_path",
      "data_config",
      "tokenizer",
      "image_processor",
      "model_version",
      "sequence_length"
    ],
    "collate_fn": [
      "self",
      "instances"
    ]
  },
  "Qwen2VLPreloadedDataModule": {
    "__init__": [
      "self",
      "model_version",
      "paths",
      "weights",
      "data_config",
      "seq_length",
      "decoder_seq_length",
      "tokenizer",
      "image_processor",
      "micro_batch_size",
      "global_batch_size",
      "num_train_samples",
      "num_val_samples",
      "num_test_samples",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "use_packed_sequence",
      "seed"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "_create_dataloader": [
      "self",
      "dataset"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "Qwen2VLImageToken": {},
  "Qwen2VLVideoToken": {},
  "OBJECT_REF_START_TOKEN_INDEX": [],
  "OBJECT_REF_END_TOKEN_INDEX": [],
  "BOX_START_TOKEN_INDEX": [],
  "BOX_END_TOKEN_INDEX": [],
  "QUAD_START_TOKEN_INDEX": [],
  "QUAD_END_TOKEN_INDEX": [],
  "VISION_START_TOKEN_INDEX": [],
  "VISION_END_TOKEN_INDEX": [],
  "PAD_TOKEN_INDEX": [],
  "HF_IMAGE_TOKEN_INDEX": [],
  "HF_VIDEO_TOKEN_INDEX": [],
  "Qwen2VLDataConfig": {},
  "ChatMLSample": {},
  "Qwen2VLTaskSample": {},
  "Qwen2VLTaskBatch": {},
  "convert_to_qwen2vl_content": [
    "user_input",
    "image_pattern",
    "video_pattern"
  ],
  "cook_chatml_sample": [
    "sample"
  ],
  "Qwen2VLTaskEncoder": {
    "cookers": [],
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "temporal_patch_size",
      "spatial_merge_size",
      "patch_size",
      "max_padding_length"
    ],
    "encode_sample": [
      "self",
      "sample"
    ],
    "batch": [
      "self",
      "samples"
    ],
    "encode_batch": [
      "self",
      "batch"
    ]
  },
  "Qwen2VLMockDataModule": {
    "__init__": [
      "self",
      "seq_length",
      "tokenizer",
      "image_processor",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "num_train_samples",
      "num_val_samples",
      "num_test_samples",
      "num_workers",
      "pin_memory",
      "persistent_workers"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "_create_dataloader": [
      "self",
      "dataset"
    ]
  },
  "prepare_image_inputs": [
    "num_channels",
    "width",
    "height"
  ],
  "_Qwen2VLMockDataset": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "name",
      "num_samples",
      "seq_length",
      "seed"
    ],
    "__len__": [
      "self"
    ],
    "_get_text": [
      "self",
      "idx"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "conv_qwen2vl": [],
  "qwen2vl_data_step": [
    "dataloader_iter",
    "model_version"
  ],
  "qwen2vl_forward_step": [
    "model",
    "batch"
  ],
  "Qwen2VLVisionConfig": {
    "configure_model": [
      "self"
    ]
  },
  "Qwen25VLVisionConfig": {
    "configure_model": [
      "self"
    ]
  },
  "Qwen2VLConfig": {
    "__post_init__": [
      "self"
    ],
    "configure_model": [
      "self",
      "tokenizer",
      "vp_stage"
    ]
  },
  "MCoreQwen2VLModel": {
    "__init__": [
      "self",
      "config",
      "tokenizer",
      "pre_process",
      "post_process",
      "add_encoder",
      "add_decoder",
      "drop_vision_class_token",
      "vp_stage"
    ],
    "get_rope_index": [
      "self",
      "input_ids",
      "image_grid_thw",
      "video_grid_thw",
      "second_per_grid_ts",
      "attention_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "loss_mask",
      "labels",
      "inference_params",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "runtime_gather_output",
      "second_per_grid_ts"
    ],
    "_preprocess_data": [
      "self",
      "input_ids",
      "loss_mask",
      "labels",
      "language_embeddings",
      "image_embeddings",
      "video_embeddings",
      "position_ids",
      "use_inference_kv_cache",
      "attention_mask"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ]
  },
  "Qwen2VLModel": {
    "__init__": [
      "self",
      "config",
      "model_version",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "configure_model": [
      "self",
      "vp_stage"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "loss_mask",
      "labels",
      "inference_params",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "second_per_grid_ts"
    ],
    "data_step": [
      "self",
      "dataloader_iter"
    ],
    "forward_step": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "qwen2vl_2b": [],
  "qwen2vl_7b": [],
  "qwen2vl_72b": [],
  "qwen25vl_3b": [],
  "qwen25vl_7b": [],
  "qwen25vl_32b": [],
  "qwen25vl_72b": [],
  "Qwen25VLVisionTransformerBlock": {
    "__init__": [
      "self",
      "config",
      "spec",
      "post_layer_norm",
      "pre_process",
      "post_process",
      "pg_collection",
      "vp_stage"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "rotary_pos_cos",
      "rotary_pos_sin",
      "attention_bias",
      "inference_context",
      "packed_seq_params",
      "sequence_len_offset",
      "packed_seq_params_full"
    ],
    "_checkpointed_forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "attention_bias",
      "packed_seq_params",
      "use_inner_fp8_context",
      "packed_seq_params_full"
    ]
  },
  "VisionRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "Qwen2VisionModel": {
    "__init__": [
      "self",
      "transformer_config",
      "transformer_layer_spec",
      "add_class_token",
      "class_token_len",
      "patch_dim",
      "temporal_patch_size",
      "spatial_merge_size",
      "spatial_patch_size",
      "img_h",
      "img_w"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "get_packed_seq_params": [
      "self",
      "grid_thw"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw",
      "attention_mask"
    ]
  },
  "Qwen25VisionModel": {
    "__init__": [
      "self",
      "transformer_config",
      "transformer_layer_spec",
      "add_class_token",
      "class_token_len",
      "patch_dim",
      "temporal_patch_size",
      "spatial_merge_size",
      "spatial_patch_size",
      "img_h",
      "img_w",
      "window_size"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "get_packed_seq_params": [
      "self",
      "grid_thw",
      "cu_seqlens"
    ],
    "get_window_index": [
      "self",
      "grid_thw"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw",
      "attention_mask"
    ]
  },
  "Qwen2VLConfig2B": {},
  "Qwen2VLConfig7B": {},
  "Qwen2VLConfig72B": {},
  "Qwen25VLConfig3B": {},
  "Qwen25VLConfig7B": {},
  "Qwen25VLConfig32B": {},
  "Qwen25VLConfig72B": {},
  "HFQwen2VLImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFQwen2VLExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target",
      "source_config"
    ],
    "tokenizer": [
      "self"
    ],
    "ckpt_load": [
      "self",
      "path"
    ],
    "config": [
      "self"
    ]
  },
  "_import_vision_linear_fc1_weight": [
    "down",
    "gate"
  ],
  "_import_vision_linear_fc1_bias": [
    "down",
    "gate"
  ],
  "_export_language_qkv_bias": [
    "ctx",
    "qkv_bias"
  ],
  "_export_linear_fc1": [
    "linear_fc1"
  ],
  "_export_vision_linear_fc1_weight": [
    "vision_fc1_weight"
  ],
  "_export_vision_linear_fc1_bias": [
    "vision_fc1_bias"
  ],
  "Gemma3DataSample": {},
  "IMAGE_SIZE": [],
  "IMAGE_TOKENS": [],
  "Gemma3VLMockDataModule": {
    "__init__": [
      "self",
      "tokenizer",
      "seq_length",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "num_train_samples",
      "num_val_samples",
      "num_test_samples",
      "num_workers",
      "pin_memory",
      "persistent_workers"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "_create_dataloader": [
      "self",
      "dataset"
    ]
  },
  "HAVE_TEX": [],
  "gemma3vl_data_step": [
    "dataloader_iter"
  ],
  "gemma3vl_forward_step": [
    "model",
    "batch"
  ],
  "Gemma3VLConfig": {
    "__post_init__": [
      "self"
    ],
    "configure_model": [
      "self",
      "tokenizer",
      "vp_stage"
    ]
  },
  "MCoreGemma3VLModel": {
    "__init__": [
      "self",
      "config",
      "tokenizer",
      "pre_process",
      "post_process",
      "add_encoder",
      "add_decoder"
    ],
    "shared_embedding_or_output_weight": [
      "self"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ],
    "freeze": [
      "self",
      "freeze_language_model",
      "freeze_vision_model",
      "freeze_vision_projection"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "pixel_values",
      "labels",
      "loss_mask",
      "inference_context",
      "runtime_gather_output",
      "packed_seq_params"
    ],
    "_preprocess_data": [
      "self",
      "input_ids",
      "image_embedding",
      "language_embedding",
      "use_inference_kv_cache"
    ],
    "_process_sequence_parallel": [
      "self",
      "combined_embedding",
      "labels",
      "loss_mask",
      "packed_seq_params"
    ],
    "_compute_attention_mask": [
      "self",
      "input_ids"
    ]
  },
  "Gemma3VLModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "pixel_values",
      "loss_mask",
      "labels",
      "inference_params"
    ]
  },
  "Gemma3VLVisionConfig": {},
  "Gemma3VLMultimodalProjectorConfig": {
    "configure_model": [
      "self"
    ]
  },
  "Gemma3VLMultimodalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Gemma3VLConfig4B": {},
  "Gemma3VLConfig12B": {},
  "Gemma3VLConfig27B": {},
  "Gemma3VLImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "Gemma3VLExporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "_vision_projector_permute": [
    "ctx",
    "x"
  ],
  "EnergonDataModule": {
    "__init__": [
      "self",
      "path",
      "train_encoder",
      "seq_length",
      "micro_batch_size",
      "global_batch_size",
      "num_workers",
      "num_val_workers",
      "pin_memory",
      "shuffle_buffer_size",
      "max_samples_per_sequence",
      "decoder_seq_length",
      "packing_buffer_size",
      "validation_encoder"
    ],
    "io_init": [
      "self"
    ],
    "datasets_provider": [
      "self",
      "worker_config",
      "split"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "_find_pattern_indices": [
    "template",
    "pattern",
    "search_start_index",
    "allow_first_token_mismatch"
  ],
  "DataSample": {},
  "DataBatch": {},
  "MultimodalProjectorConfig": {
    "configure_model": [
      "self"
    ]
  },
  "HFCLIPVisionConfig": {
    "__post_init__": [
      "self"
    ],
    "configure_model": [
      "self"
    ]
  },
  "BaseCLIPViTModel": {
    "forward": [
      "self",
      "x",
      "attention_mask",
      "num_unused_layers"
    ]
  },
  "SigLIPViT400M_14_384_Config": {},
  "SigLIPViTModel": {
    "__init__": [
      "self",
      "config"
    ],
    "configure_model": [
      "self"
    ]
  },
  "SigLIPViTImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "config": [
      "self"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ]
  },
  "CLIPViTL_14_336_Config": {},
  "CLIPViTImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "config": [
      "self"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ]
  },
  "InternViTRMSNorm": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "eps",
      "sequence_parallel",
      "compute_var"
    ],
    "_norm": [
      "self",
      "x",
      "var"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_gather_var": [
      "self",
      "input_",
      "max_dim",
      "valid_heads",
      "total_heads"
    ]
  },
  "_bias_dropout_add_func_internvit": [
    "ls",
    "x_with_bias",
    "residual",
    "prob",
    "training"
  ],
  "bias_dropout_add_unfused_internvit": [
    "ls",
    "training"
  ],
  "get_bias_dropout_add_internvit": [
    "ls",
    "training",
    "fused"
  ],
  "InternViTTransformerLayer": {
    "__init__": [
      "self"
    ]
  },
  "InternViTSelfAttention": {
    "__init__": [
      "self",
      "config",
      "submodules"
    ]
  },
  "InternViTTEDotProductAttention": {
    "forward": [
      "self"
    ]
  },
  "get_internvit_layer_spec": [
    "use_te",
    "add_qk_norm",
    "norm_type"
  ],
  "InternViTConfig": {},
  "InternViT_6B_448px_Config": {},
  "InternViT_300M_448px_Config": {},
  "InternViTModel": {
    "__init__": [
      "self",
      "config"
    ],
    "configure_model": [
      "self"
    ]
  },
  "HFInternViTImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "config": [
      "self"
    ]
  },
  "_import_position_embedding": [
    "ctx",
    "pos_emb"
  ],
  "MllamaInferenceWrapper": {
    "__init__": [
      "self",
      "model",
      "inference_wrapper_config"
    ],
    "prep_inference_input": [
      "self",
      "prompts_tokens",
      "image_dict"
    ],
    "get_batch_for_context_window": [
      "self",
      "inference_input",
      "context_start_position",
      "context_end_position"
    ],
    "forward_pass_without_pipeline_parallel": [
      "self",
      "inference_input"
    ]
  },
  "_setup_trainer_and_restore_model": [
    "path",
    "trainer",
    "model"
  ],
  "setup_inference_wrapper": [
    "model",
    "tokenizer",
    "params_dtype",
    "inference_batch_times_seqlen_threshold"
  ],
  "setup_model_and_tokenizer": [
    "path",
    "trainer",
    "tp_size",
    "pp_size",
    "params_dtype",
    "inference_batch_times_seqlen_threshold"
  ],
  "LlavaInferenceWrapper": {
    "__init__": [
      "self",
      "model",
      "inference_wrapper_config"
    ],
    "prep_inference_input": [
      "self",
      "prompts_tokens",
      "image_dict"
    ],
    "get_batch_for_context_window": [
      "self",
      "inference_input",
      "context_start_position",
      "context_end_position"
    ],
    "forward_pass_without_pipeline_parallel": [
      "self",
      "inference_input"
    ]
  },
  "VLMTextGenerationController": {
    "__init__": [
      "self",
      "inference_wrapped_model",
      "tokenizer",
      "image_processor"
    ],
    "tokenize_prompt": [
      "self",
      "prompt",
      "image"
    ],
    "prep_inference_input": [
      "self",
      "prompts_tokens",
      "active_requests",
      "use_attention_mask"
    ]
  },
  "QwenVLTextGenerationController": {
    "__init__": [
      "self",
      "inference_wrapped_model",
      "tokenizer",
      "image_processor",
      "processor"
    ],
    "tokenize_prompt": [
      "self",
      "prompt",
      "image"
    ]
  },
  "VLMEngine": {
    "generate": [
      "self",
      "prompts",
      "images",
      "common_inference_params"
    ]
  },
  "QwenVLInferenceWrapper": {
    "__init__": [
      "self",
      "model",
      "inference_wrapper_config"
    ],
    "prep_inference_input": [
      "self",
      "prompts_tokens",
      "image_dict"
    ],
    "get_batch_for_context_window": [
      "self",
      "inference_input",
      "context_start_position",
      "context_end_position"
    ],
    "forward_pass_without_pipeline_parallel": [
      "self",
      "inference_input"
    ]
  },
  "train": [
    "model",
    "data",
    "trainer",
    "log",
    "resume",
    "optim",
    "tokenizer",
    "model_transform"
  ],
  "pretrain": [
    "model",
    "data",
    "trainer",
    "log",
    "resume",
    "optim"
  ],
  "finetune": [
    "model",
    "data",
    "trainer",
    "log",
    "resume",
    "optim",
    "peft"
  ],
  "validate": [
    "model",
    "data",
    "trainer",
    "log",
    "resume",
    "optim",
    "tokenizer",
    "model_transform"
  ],
  "evaluate": [],
  "_use_tokenizer": [
    "model",
    "data",
    "tokenizer"
  ],
  "_setup": [
    "model",
    "data",
    "trainer",
    "log",
    "resume",
    "optim",
    "tokenizer",
    "model_transform"
  ],
  "_set_with_io": [
    "obj",
    "attr",
    "value"
  ],
  "_validate_config": [
    "model",
    "data",
    "trainer",
    "log",
    "resume",
    "optim",
    "tokenizer",
    "model_transform"
  ],
  "SpeechLMMegatronStrategy": {
    "load_model_state_dict": [
      "self",
      "checkpoint",
      "strict"
    ]
  },
  "SPEECHLM_PEFT_RESUME": [],
  "SpeechToTextLLMPEFT": {
    "__init__": [
      "self",
      "peft"
    ],
    "get_wrappped_io": [
      "self"
    ],
    "__call__": [
      "self",
      "model"
    ],
    "_transform_module": [
      "self",
      "module"
    ],
    "transform": [
      "self",
      "module",
      "name",
      "prefix"
    ],
    "set_params_to_save": [
      "self",
      "trainer"
    ]
  },
  "SpeechLMWrappedAdapterIO": {
    "load_checkpoint": [
      "self",
      "path",
      "sharded_state_dict",
      "map_location",
      "strict"
    ],
    "_load_checkpoint": [
      "self",
      "path",
      "sharded_state_dict",
      "map_location",
      "load_base",
      "strict"
    ]
  },
  "SpeechLMAutoResume": {
    "_maybe_get_adapter_path": [
      "self",
      "checkpoint"
    ],
    "get_trainer_ckpt_path": [
      "self",
      "model"
    ]
  },
  "load_distributed_ckpt": [
    "ckpt_dir"
  ],
  "get_nested_attr": [
    "obj",
    "attr"
  ],
  "prepare_pretrained_llm_dist_ckpt": [
    "model_config"
  ],
  "get_object_list_from_config": [
    "cfg"
  ],
  "to_dict_config": [
    "cfg"
  ],
  "END_OF_SEQ": [],
  "pad_batch": [
    "batch",
    "pad_id",
    "max_len"
  ],
  "switch": [
    "val1",
    "val2",
    "boolean"
  ],
  "TextGenerationStrategy": {
    "__init__": [
      "self",
      "model"
    ],
    "forward_step": [
      "self",
      "batch"
    ],
    "tokenize_batch": [
      "self",
      "sentences",
      "max_len",
      "add_BOS"
    ],
    "clip_max_len": [
      "self",
      "maxlen"
    ],
    "init_batch": [
      "self",
      "context_tokens",
      "context_length",
      "compute_attention_mask"
    ],
    "prepare_batch_at_step": [
      "self",
      "tokens",
      "maxlen",
      "micro_batch_size",
      "step",
      "context_length"
    ],
    "post_process": [
      "self",
      "tokens",
      "new_tokens",
      "context_length"
    ],
    "end_of_generation_condition": [
      "self",
      "tokens",
      "prev",
      "eod_id",
      "end_strings"
    ],
    "post_generation_process": [
      "self",
      "output"
    ],
    "_get_end_of_generation_tokens_and_strings": [
      "self",
      "eod_id",
      "end_strings"
    ]
  },
  "SpeechToTextGenerationStrategy": {
    "__init__": [
      "self",
      "model",
      "max_depth"
    ],
    "init_batch": [
      "self",
      "context_tokens",
      "context_lengths",
      "audio_signal",
      "audio_length",
      "compute_attention_mask",
      "num_audios",
      "context_start_idx"
    ],
    "clip_max_len": [
      "self",
      "maxlen"
    ],
    "prepare_batch_at_step": [
      "self",
      "tokens",
      "input_embeddings",
      "maxlen",
      "micro_batch_size",
      "step",
      "context_lengths",
      "curr_context_length",
      "compute_attention_mask"
    ],
    "post_process": [
      "self",
      "tokens",
      "new_tokens",
      "context_length"
    ],
    "end_of_generation_condition": [
      "self",
      "tokens",
      "prev",
      "eod_id",
      "end_strings"
    ]
  },
  "model_inference_strategy_dispatcher": [
    "model"
  ],
  "default_inference_config": [],
  "OutputType": {},
  "clean_end_string": [
    "text",
    "tokenizer",
    "end_string"
  ],
  "get_computeprob_response": [
    "tokenizer",
    "response",
    "inputs"
  ],
  "send_generate_info": [
    "context_tokens_tensor",
    "context_length_tensor",
    "audio_signal",
    "audio_signal_length",
    "tokens_to_generate",
    "all_probs",
    "compute_logprob",
    "temperature",
    "top_k",
    "top_p",
    "greedy",
    "repetition_penalty",
    "min_tokens_to_generate",
    "end_strings",
    "num_audios",
    "context_start_idx"
  ],
  "receive_generate_info": [
    "has_multi_audios"
  ],
  "synced_generate": [
    "model",
    "inference_strategy",
    "context_tokens_tensor",
    "context_length_tensor",
    "audio_signal",
    "audio_signal_length",
    "tokens_to_generate",
    "all_probs",
    "temperature",
    "top_k",
    "top_p",
    "greedy",
    "compute_attention_mask",
    "compute_logprob",
    "repetition_penalty",
    "end_strings",
    "min_tokens_to_generate",
    "num_audios",
    "context_start_idx"
  ],
  "sample_sequence_batch": [
    "model",
    "inference_strategy",
    "context_tokens",
    "context_lengths",
    "audio_signal",
    "audio_signal_length",
    "tokens_to_generate",
    "all_probs",
    "compute_attention_mask",
    "compute_logprob",
    "type_ids",
    "temperature",
    "end_strings",
    "extra",
    "num_audios",
    "context_start_idx"
  ],
  "PipelineComponents": {},
  "dump_config": [
    "cfg",
    "logger"
  ],
  "build_components": [
    "cfg",
    "tokenizer"
  ],
  "speech_to_text_llm_train": [
    "cfg",
    "tokenizer"
  ],
  "speech_to_text_llm_validate": [
    "cfg",
    "tokenizer"
  ],
  "speech_to_text_llm_generate": [
    "cfg",
    "tokenizer"
  ],
  "pytorch_adam_with_flat_lr": [
    "lr"
  ],
  "AudioToTextDataModule": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "global_batch_size": [
      "self"
    ],
    "micro_batch_size": [
      "self"
    ],
    "seq_length": [
      "self"
    ],
    "data_cfg": [
      "self"
    ],
    "get_text_processor": [
      "self"
    ],
    "prepare_data": [
      "self"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "_create_dataset": [
      "self",
      "mode"
    ],
    "_create_nemo_dataloader": [
      "self",
      "dataset",
      "mode"
    ],
    "_parse_lhotse_data_name": [
      "self",
      "mode"
    ],
    "_create_lhotse_dataloader": [
      "self",
      "dataset",
      "mode"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "predict_dataloader": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "TextProcessorOutput": {},
  "MultimodalConversationTextProcessor": {
    "__init__": [
      "self",
      "tokenizer",
      "prompt_format",
      "max_seq_length",
      "add_boa_eoa",
      "boa_string",
      "eoa_string"
    ],
    "__call__": [
      "self",
      "lhotse_input"
    ],
    "process_sample": [
      "self",
      "lhotse_input"
    ]
  },
  "SpeechLMDataSampler": {
    "transform_dataloader": [
      "self",
      "dataloader",
      "consumed_samples"
    ]
  },
  "collate_vectors": [
    "items",
    "max_length",
    "padding_value"
  ],
  "MultimodalConversationDataset": {
    "__init__": [
      "self",
      "text_processor",
      "tokens_to_generate",
      "pad_to_max_length",
      "max_seq_length",
      "default_context",
      "context_key",
      "default_context_key",
      "answer_key",
      "answer_only_loss",
      "is_train"
    ],
    "__getitem__": [
      "self",
      "all_cuts"
    ],
    "_get_metadata": [
      "self",
      "all_cuts"
    ],
    "_process_sample": [
      "self",
      "sample"
    ],
    "_convert_cut_sample": [
      "self",
      "cut"
    ],
    "_process_cut": [
      "self",
      "cut"
    ],
    "_process_multimodal_conversation": [
      "self",
      "sample"
    ]
  },
  "collate_audio_data": [
    "samples",
    "pad_val"
  ],
  "collate_text_data": [
    "samples",
    "tokens_to_generate",
    "pad_to_max_length",
    "max_seq_length",
    "pad_id",
    "answer_only_loss"
  ],
  "_audio_collate_fn": [
    "audio_signals",
    "audio_lengths"
  ],
  "_collate_item": [
    "item",
    "max_length",
    "pad_id"
  ],
  "_speechllm_audio_text_collate_fn": [
    "batch",
    "tokens_to_generate",
    "pad_to_max_length",
    "max_seq_length",
    "text_pad_id"
  ],
  "_speechllm_multi_audio_text_collate_fn": [
    "batch",
    "tokens_to_generate",
    "pad_to_max_length",
    "max_seq_length",
    "text_pad_id"
  ],
  "AudioTextDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "text_processor",
      "sample_rate",
      "int_values",
      "augmentor",
      "max_duration",
      "min_duration",
      "max_utts",
      "trim",
      "channel_selector",
      "max_seq_length",
      "min_seq_length",
      "tokens_to_generate",
      "pad_to_max_length",
      "max_num_samples",
      "index_by_file_id",
      "context_key",
      "answer_key",
      "context_file"
    ],
    "get_manifest_sample": [
      "self",
      "sample_id"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "MultiAudioTextDataset": {
    "__init__": [
      "self"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "TarredAudioFilter": {
    "__init__": [
      "self",
      "collection",
      "iterator"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ]
  },
  "TarredAudioLoopOffsets": {
    "__init__": [
      "self",
      "collection",
      "iterator"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ]
  },
  "TarredAudioTextDataset": {
    "__init__": [
      "self",
      "audio_tar_filepaths",
      "manifest_filepath",
      "text_processor",
      "sample_rate",
      "int_values",
      "augmentor",
      "shuffle_n",
      "min_duration",
      "max_duration",
      "trim",
      "shard_strategy",
      "shard_manifests",
      "global_rank",
      "world_size",
      "max_seq_length",
      "min_seq_length",
      "tokens_to_generate",
      "pad_to_max_length",
      "context_key",
      "answer_key",
      "context_file"
    ],
    "_filter": [
      "self",
      "iterator"
    ],
    "_loop_offsets": [
      "self",
      "iterator"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ],
    "_build_sample": [
      "self",
      "tup"
    ],
    "get_manifest_sample": [
      "self",
      "sample_id"
    ],
    "__iter__": [
      "self"
    ],
    "_compute_len": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "get_tarred_audio_text_dataset": [
    "config",
    "text_processor",
    "augmentor",
    "global_rank",
    "world_size",
    "shuffle_n"
  ],
  "get_concat_tarred_audio_text_dataset": [
    "config",
    "text_processor",
    "augmentor",
    "global_rank",
    "world_size",
    "shuffle_n"
  ],
  "get_tarred_audio_text_dataset_from_config": [
    "config",
    "text_processor",
    "augmentor",
    "global_rank",
    "world_size"
  ],
  "get_audio_text_dataset_from_config": [
    "manifest_filepath",
    "config",
    "text_processor",
    "augmentor",
    "is_train"
  ],
  "get_datasets_weights_and_num_samples": [
    "data_prefix",
    "num_samples"
  ],
  "build_loss_mask": [
    "input_ids",
    "answer_start_idx",
    "answer_only_loss"
  ],
  "ceil_to_nearest": [
    "n",
    "m"
  ],
  "pad_or_trim_to_max_length": [
    "inputs",
    "max_length",
    "pad_value",
    "ceil_to",
    "seq_dim"
  ],
  "estimate_encoded_max_length": [
    "audio_signal",
    "sample_rate",
    "frame_length"
  ],
  "SpeechLanguageModel": {
    "__init__": [
      "self"
    ],
    "cfg": [
      "self",
      "cfg"
    ],
    "summarize": [
      "self",
      "max_depth"
    ],
    "freeze_module": [
      "self",
      "module"
    ],
    "unfreeze_module": [
      "self",
      "module"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "_set_model_guid": [
      "self"
    ],
    "propagate_model_guid": [
      "self"
    ],
    "setup_multi_validation_data": [
      "self"
    ],
    "setup_multi_test_data": [
      "self"
    ],
    "validation_step_outputs": [
      "self",
      "value"
    ],
    "test_step_outputs": [
      "self",
      "value"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "on_test_epoch_end": [
      "self"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "get_validation_dataloader_prefix": [
      "self",
      "dataloader_idx"
    ],
    "get_test_dataloader_prefix": [
      "self",
      "dataloader_idx"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "speech_to_text_llm_data_step": [
    "dataloader_iter"
  ],
  "speech_to_text_llm_forward_step": [
    "model",
    "batch"
  ],
  "SpeechToTextLLMConfig": {
    "_freeze_module": [
      "self",
      "module"
    ],
    "_maybe_load_pretrained_llm": [
      "self",
      "model",
      "strict"
    ],
    "_maybe_load_asr_and_modality_adapter": [
      "self",
      "asr_model",
      "modality_adapter"
    ],
    "_propagate_model_configs": [
      "self"
    ],
    "configure_model": [
      "self",
      "tokenizer",
      "speech_model"
    ]
  },
  "MCoreSpeechToTextLLM": {
    "__init__": [
      "self",
      "config",
      "language_model",
      "speech_model",
      "modality_adapter",
      "tokenizer"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ],
    "_create_attention_mask": [
      "self",
      "encoder_input"
    ],
    "_concat_features": [
      "self",
      "embs1",
      "emb1_lens",
      "embs2",
      "emb2_lens"
    ],
    "_concat_multi_features": [
      "self",
      "encoded",
      "encoded_len",
      "input_embeds",
      "input_length",
      "context_start_idx"
    ],
    "inject_perception_input": [
      "self",
      "encoded",
      "encoded_len",
      "input_ids",
      "input_length",
      "context_start_idx"
    ],
    "_shift_labels_by_emb_len": [
      "self",
      "labels",
      "label_lens",
      "emb_lens",
      "max_len",
      "pad_token"
    ],
    "_get_text_embeddings": [
      "self",
      "text_tokens",
      "position_ids"
    ],
    "_get_llm_input_for_context_parallel": [
      "self",
      "attention_mask",
      "decoder_input",
      "labels",
      "loss_masks",
      "max_length"
    ],
    "perception": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ],
    "forward": [
      "self",
      "input_ids",
      "input_length",
      "loss_mask",
      "attention_mask",
      "audio_signal",
      "audio_signal_length",
      "processed_signal",
      "processed_signal_length",
      "labels",
      "num_audios",
      "context_start_idx",
      "inference_params",
      "packed_seq_params"
    ]
  },
  "SpeechToTextLLM": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "configure_model": [
      "self"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "forward": [
      "self",
      "input_ids",
      "input_length",
      "loss_mask",
      "attention_mask",
      "audio_signal",
      "audio_signal_length",
      "processed_signal",
      "processed_signal_length",
      "labels",
      "num_audios",
      "context_start_idx",
      "inference_params"
    ],
    "freeze_llm": [
      "self"
    ],
    "freeze_speech": [
      "self"
    ],
    "freeze_modality_adapter": [
      "self"
    ],
    "unfreeze_llm": [
      "self"
    ],
    "unfreeze_speech": [
      "self"
    ],
    "unfreeze_modality_adapter": [
      "self"
    ],
    "trainable_parameters": [
      "self"
    ],
    "data_step": [
      "self",
      "dataloader_iter"
    ],
    "forward_step": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "_metrics_require_string2category_map": [
      "self"
    ],
    "setup_metric": [
      "self",
      "data_cfg"
    ],
    "inference_step": [
      "self",
      "batch",
      "mode"
    ],
    "get_inference_strategy": [
      "self"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "_determine_log_key": [
      "self",
      "dataloader_idx",
      "metric_name",
      "mode"
    ],
    "inference_epoch_end": [
      "self",
      "outputs",
      "mode",
      "data_cfg"
    ],
    "gather_and_maybe_write_predictions": [
      "self",
      "data_cfg",
      "output",
      "averaged_metric",
      "mode",
      "dataloader_idx"
    ],
    "write_predictions_to_file": [
      "self",
      "outputs",
      "output_file_path_prefix",
      "output_dir"
    ],
    "_reconfigure_and_process_inference_batch": [
      "self",
      "batch",
      "data_cfg"
    ],
    "set_inference_config": [
      "self",
      "inference_config"
    ],
    "get_inference_config": [
      "self"
    ],
    "on_validation_epoch_start": [
      "self"
    ],
    "on_test_epoch_start": [
      "self"
    ],
    "on_predict_epoch_start": [
      "self"
    ],
    "on_test_epoch_end": [
      "self"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "on_train_epoch_start": [
      "self"
    ]
  },
  "MCoreASRModule": {
    "__init__": [
      "self",
      "encoder",
      "preprocessor",
      "spec_augment"
    ],
    "maybe_preprocess_audio": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ]
  },
  "HFWrappedPreprocessor": {
    "__init__": [
      "self",
      "preprocessor",
      "sample_rate"
    ],
    "forward": [
      "self",
      "input_signal",
      "length"
    ],
    "__call__": [
      "self"
    ]
  },
  "HFWrappedEncoder": {
    "__init__": [
      "self",
      "encoder"
    ],
    "forward": [
      "self",
      "audio_signal",
      "length"
    ],
    "__call__": [
      "self"
    ]
  },
  "ASRModuleConfig": {
    "configure_nemo_asr_model": [
      "self"
    ],
    "configure_hf_auto_model": [
      "self"
    ],
    "configure_model": [
      "self"
    ]
  },
  "MCoreModalityAdapterModule": {
    "__init__": [
      "self",
      "module"
    ],
    "forward": [
      "self",
      "encoded",
      "encoded_len"
    ]
  },
  "ModalityAdapterConfig": {
    "configure_model": [
      "self"
    ]
  },
  "calculate_mean": [
    "input",
    "input_length",
    "mask",
    "dim",
    "keepdim",
    "eps"
  ],
  "scale_invariant_target": [
    "estimate",
    "target",
    "input_length",
    "mask",
    "eps"
  ],
  "convolution_invariant_target": [
    "estimate",
    "target",
    "input_length",
    "mask",
    "filter_length",
    "diag_reg",
    "eps"
  ],
  "calculate_sdr_batch": [
    "estimate",
    "target",
    "input_length",
    "mask",
    "scale_invariant",
    "convolution_invariant",
    "convolution_filter_length",
    "remove_mean",
    "sdr_max",
    "eps"
  ],
  "SDRLoss": {
    "__init__": [
      "self",
      "weight",
      "reduction",
      "scale_invariant",
      "convolution_invariant",
      "convolution_filter_length",
      "remove_mean",
      "sdr_max",
      "eps"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "estimate",
      "target",
      "input_length",
      "mask"
    ]
  },
  "calculate_mse_batch": [
    "estimate",
    "target",
    "input_length",
    "mask"
  ],
  "calculate_mae_batch": [
    "estimate",
    "target",
    "input_length",
    "mask"
  ],
  "MAELoss": {
    "__init__": [
      "self",
      "weight",
      "reduction",
      "ndim"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "estimate",
      "target",
      "input_length",
      "mask"
    ]
  },
  "EPS": [],
  "sisnr_loss": [
    "source",
    "estimate_source",
    "source_lengths"
  ],
  "cal_si_snr_with_pit": [
    "source",
    "estimate_source",
    "source_lengths"
  ],
  "reorder_source": [
    "source",
    "perms",
    "max_snr_idx"
  ],
  "STT_EN_CONFORMER_CTC_SMALL_v1_6_0": [],
  "restore_asr_model_from_cloud": [
    "location",
    "refresh_cache"
  ],
  "CombinedLoss": {
    "__init__": [
      "self",
      "sample_rate",
      "hop_length",
      "num_mels",
      "fft_length",
      "sisnr_loss_weight",
      "spectral_loss_weight",
      "asr_loss_weight",
      "use_asr_loss",
      "use_mel_spec",
      "conformer_model",
      "epsilon"
    ],
    "spectral_loss": [
      "self",
      "predicted_audio",
      "primary_audio"
    ],
    "asr_loss": [
      "self",
      "predicted_audio",
      "primary_audio"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "estimate",
      "target",
      "input_length"
    ]
  },
  "__VERIFIED_METRICS__": [],
  "AudioMetricWrapper": {
    "__init__": [
      "self",
      "metric",
      "channel",
      "metric_using_batch_averaging"
    ],
    "_select_channel": [
      "self",
      "preds",
      "target"
    ],
    "_trim_inputs": [
      "preds",
      "target",
      "input_length"
    ],
    "_batch_reduction": [
      "batch_values"
    ],
    "update": [
      "self",
      "preds",
      "target",
      "input_length"
    ],
    "compute": [
      "self"
    ],
    "forward": [
      "self",
      "preds",
      "target",
      "input_length"
    ],
    "reset": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_wrap_compute": [
      "self",
      "compute"
    ]
  },
  "SquimMOSMetric": {
    "__init__": [
      "self",
      "fs"
    ],
    "update": [
      "self",
      "preds",
      "target"
    ],
    "compute": [
      "self"
    ],
    "state_dict": [
      "self"
    ]
  },
  "SquimObjectiveMetric": {
    "__init__": [
      "self",
      "fs",
      "metric"
    ],
    "update": [
      "self",
      "preds",
      "target"
    ],
    "compute": [
      "self"
    ],
    "state_dict": [
      "self"
    ]
  },
  "INPUT_CHANNEL_SELECTOR": [],
  "TARGET_CHANNEL_SELECTOR": [],
  "REFERENCE_CHANNEL_SELECTOR": [],
  "LHOTSE_TARGET_CHANNEL_SELECTOR": [],
  "LHOTSE_REFERENCE_CHANNEL_SELECTOR": [],
  "LhotseAudioToTargetDataset": {
    "TARGET_KEY": [],
    "REFERENCE_KEY": [],
    "EMBEDDING_KEY": [],
    "__getitem__": [
      "self",
      "cuts"
    ]
  },
  "_key_available": [
    "cuts",
    "key"
  ],
  "create_recording": [
    "path_or_paths"
  ],
  "create_array": [
    "path"
  ],
  "convert_manifest_nemo_to_lhotse": [
    "input_manifest",
    "output_manifest",
    "input_key",
    "target_key",
    "reference_key",
    "embedding_key",
    "force_absolute_paths"
  ],
  "_as_relative": [
    "recording",
    "paths",
    "enabled"
  ],
  "SignalSetup": {},
  "ASRAudioProcessor": {
    "__init__": [
      "self",
      "sample_rate",
      "random_offset",
      "normalization_signal",
      "eps"
    ],
    "sample_rate": [
      "self",
      "value"
    ],
    "random_offset": [
      "self",
      "value"
    ],
    "sync_setup": [
      "self",
      "value"
    ],
    "async_setup": [
      "self",
      "value"
    ],
    "embedding_setup": [
      "self",
      "value"
    ],
    "process": [
      "self",
      "example"
    ],
    "load_audio": [
      "self",
      "example"
    ],
    "process_audio": [
      "self",
      "audio"
    ],
    "load_sync_signals": [
      "self",
      "example"
    ],
    "load_async_signals": [
      "self",
      "example"
    ],
    "get_samples": [
      "cls",
      "audio_file",
      "sample_rate",
      "duration",
      "channel_selector",
      "fixed_offset",
      "random_offset"
    ],
    "get_samples_synchronized": [
      "cls",
      "audio_files",
      "sample_rate",
      "duration",
      "channel_selectors",
      "fixed_offset",
      "random_offset"
    ],
    "get_samples_from_file": [
      "cls",
      "audio_file",
      "sample_rate",
      "offset",
      "num_samples",
      "channel_selector"
    ],
    "get_segment_from_file": [
      "audio_file",
      "sample_rate",
      "offset",
      "num_samples",
      "channel_selector"
    ],
    "list_to_multichannel": [
      "signal"
    ],
    "get_duration": [
      "audio_files"
    ],
    "load_embedding": [
      "self",
      "example"
    ],
    "load_embedding_vector": [
      "filepath"
    ]
  },
  "BaseAudioDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "collection",
      "audio_processor",
      "output_type"
    ],
    "num_channels": [
      "self",
      "signal_key"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "AudioToTargetExample": [],
  "AudioToTargetDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "sample_rate",
      "input_key",
      "target_key",
      "audio_duration",
      "random_offset",
      "max_duration",
      "min_duration",
      "max_utts",
      "input_channel_selector",
      "target_channel_selector",
      "normalization_signal"
    ],
    "output_types": [
      "self"
    ]
  },
  "AudioToTargetWithReferenceExample": [],
  "AudioToTargetWithReferenceDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "sample_rate",
      "input_key",
      "target_key",
      "reference_key",
      "audio_duration",
      "random_offset",
      "max_duration",
      "min_duration",
      "max_utts",
      "input_channel_selector",
      "target_channel_selector",
      "reference_channel_selector",
      "reference_is_synchronized",
      "reference_duration",
      "normalization_signal"
    ],
    "output_types": [
      "self"
    ]
  },
  "AudioToTargetWithEmbeddingExample": [],
  "AudioToTargetWithEmbeddingDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "sample_rate",
      "input_key",
      "target_key",
      "embedding_key",
      "audio_duration",
      "random_offset",
      "max_duration",
      "min_duration",
      "max_utts",
      "input_channel_selector",
      "target_channel_selector",
      "normalization_signal"
    ],
    "output_types": [
      "self"
    ]
  },
  "check_angle": [
    "key",
    "val"
  ],
  "wrap_to_180": [
    "angle"
  ],
  "ArrayGeometry": {
    "__init__": [
      "self",
      "mic_positions",
      "center",
      "internal_cs"
    ],
    "num_mics": [
      "self"
    ],
    "positions": [
      "self"
    ],
    "internal_positions": [
      "self"
    ],
    "radius": [
      "self"
    ],
    "get_rotation": [
      "yaw",
      "pitch",
      "roll"
    ],
    "translate": [
      "self",
      "to"
    ],
    "rotate": [
      "self",
      "yaw",
      "pitch",
      "roll"
    ],
    "new_rotated_array": [
      "self",
      "yaw",
      "pitch",
      "roll"
    ],
    "spherical_relative_to_array": [
      "self",
      "point",
      "use_internal_cs"
    ],
    "__str__": [
      "self"
    ],
    "plot": [
      "self",
      "elev",
      "azim",
      "mic_size"
    ]
  },
  "convert_placement_to_range": [
    "placement",
    "room_dim",
    "object_radius"
  ],
  "RIRCorpusGenerator": {
    "__init__": [
      "self",
      "cfg"
    ],
    "cfg": [
      "self",
      "cfg"
    ],
    "sample_rate": [
      "self"
    ],
    "check_cfg": [
      "self"
    ],
    "generate_room_params": [
      "self"
    ],
    "generate_array": [
      "self",
      "room_dim"
    ],
    "generate_source_position": [
      "self",
      "room_dim"
    ],
    "generate": [
      "self"
    ]
  },
  "simulate_room_kwargs": [
    "kwargs"
  ],
  "simulate_room": [
    "room_params",
    "mic_array",
    "source_position",
    "room_filepath"
  ],
  "save_rir_simulation": [
    "filepath",
    "rir_dataset",
    "metadata"
  ],
  "load_rir_simulation": [
    "filepath",
    "source",
    "rir_key"
  ],
  "convert_numpy_to_serializable": [
    "data"
  ],
  "convert_rir_to_multichannel": [
    "rir"
  ],
  "plot_rir_manifest_info": [
    "filepath",
    "plot_filepath"
  ],
  "RIRMixGenerator": {
    "__init__": [
      "self",
      "cfg"
    ],
    "cfg": [
      "self",
      "cfg"
    ],
    "sample_rate": [
      "self"
    ],
    "check_cfg": [
      "self"
    ],
    "generate_target": [
      "self",
      "subset"
    ],
    "generate_interference": [
      "self",
      "subset",
      "target_cfg"
    ],
    "generate_mix": [
      "self",
      "subset",
      "target_cfg"
    ],
    "generate": [
      "self"
    ]
  },
  "convolve_rir": [
    "signal",
    "rir"
  ],
  "calculate_drr": [
    "rir",
    "sample_rate",
    "n_direct",
    "n_0_ms"
  ],
  "normalize_max": [
    "x",
    "max_db",
    "eps"
  ],
  "simultaneously_active_rms": [
    "x",
    "y",
    "sample_rate",
    "rms_threshold_db",
    "window_len_ms",
    "min_active_duration"
  ],
  "scaled_disturbance": [
    "signal",
    "disturbance",
    "sdr",
    "sample_rate",
    "ref_channel",
    "eps"
  ],
  "prepare_source_signal": [
    "signal_type",
    "sample_rate",
    "audio_data",
    "audio_dir",
    "min_duration",
    "ref_signal",
    "mic_positions",
    "num_retries"
  ],
  "check_min_sample_rate": [
    "filepath",
    "sample_rate"
  ],
  "simulate_room_mix": [
    "sample_rate",
    "target_cfg",
    "interference_cfg",
    "mix_cfg",
    "audio_metadata",
    "base_output_filepath",
    "max_amplitude",
    "eps"
  ],
  "simulate_room_mix_helper": [
    "example_and_audio_metadata"
  ],
  "plot_mix_manifest_info": [
    "filepath",
    "plot_filepath"
  ],
  "get_audio_to_target_dataset": [
    "config"
  ],
  "get_audio_to_target_with_reference_dataset": [
    "config"
  ],
  "get_audio_to_target_with_embedding_dataset": [
    "config"
  ],
  "SpectrogramConformer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "context_size": [
      "self",
      "value"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_length",
      "cache_last_channel",
      "cache_last_time",
      "cache_last_channel_len"
    ]
  },
  "ConformerEncoderUNet": {
    "__init__": [
      "self"
    ],
    "forward_internal": [
      "self",
      "audio_signal",
      "length",
      "cache_last_channel",
      "cache_last_time",
      "cache_last_channel_len",
      "bypass_pre_encode"
    ]
  },
  "SpectrogramConformerUNet": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "context_size": [
      "self",
      "value"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_length",
      "cache_last_channel",
      "cache_last_time",
      "cache_last_channel_len"
    ]
  },
  "SpectrogramNoiseConditionalScoreNetworkPlusPlus": {
    "__init__": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_length",
      "condition"
    ]
  },
  "NoiseConditionalScoreNetworkPlusPlus": {
    "__init__": [
      "self",
      "nonlinearity",
      "in_channels",
      "out_channels",
      "channels",
      "num_res_blocks",
      "num_resolutions",
      "init_scale",
      "conditioned_on_time",
      "fourier_embedding_scale",
      "dropout_rate",
      "pad_time_to",
      "pad_dimension_to"
    ],
    "init_weights_": [
      "self"
    ],
    "pad_input": [
      "self",
      "input"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "GaussianFourierProjection": {
    "__init__": [
      "self",
      "embedding_size",
      "scale"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ResnetBlockBigGANPlusPlus": {
    "__init__": [
      "self",
      "activation",
      "in_ch",
      "out_ch",
      "diffusion_step_embedding_dim",
      "init_scale",
      "dropout_rate",
      "in_num_groups",
      "out_num_groups",
      "eps"
    ],
    "init_weights_": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "diffusion_time_embedding"
    ]
  },
  "ChannelAugment": {
    "__init__": [
      "self",
      "permute_channels",
      "num_channels_min",
      "num_channels_max",
      "rng",
      "seed"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TransformAverageConcatenate": {
    "__init__": [
      "self",
      "in_features",
      "out_features"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TransformAttendConcatenate": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "n_head",
      "dropout_rate"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ChannelAveragePool": {
    "__init__": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ChannelAttentionPool": {
    "__init__": [
      "self",
      "in_features",
      "n_head",
      "dropout_rate"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ParametricMultichannelWienerFilter": {
    "__init__": [
      "self",
      "beta",
      "rank",
      "postfilter",
      "ref_channel",
      "ref_hard",
      "ref_hard_use_grad",
      "ref_subband_weighting",
      "num_subbands",
      "diag_reg",
      "eps"
    ],
    "trace": [
      "x",
      "keepdim"
    ],
    "apply_diag_reg": [
      "self",
      "psd"
    ],
    "apply_filter": [
      "self",
      "input",
      "filter"
    ],
    "apply_ban": [
      "self",
      "input",
      "filter",
      "psd_n"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "mask_s",
      "mask_n"
    ]
  },
  "ReferenceChannelEstimatorSNR": {
    "__init__": [
      "self",
      "hard",
      "hard_use_grad",
      "subband_weighting",
      "num_subbands",
      "eps"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "W",
      "psd_s",
      "psd_n"
    ]
  },
  "WPEFilter": {
    "__init__": [
      "self",
      "filter_length",
      "prediction_delay",
      "diag_reg",
      "eps"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "power",
      "input_length"
    ],
    "convtensor": [
      "cls",
      "x",
      "filter_length",
      "delay",
      "n_steps"
    ],
    "permute_convtensor": [
      "cls",
      "x"
    ],
    "estimate_correlations": [
      "self",
      "input",
      "weight",
      "tilde_input",
      "input_length"
    ],
    "estimate_filter": [
      "self",
      "Q",
      "R"
    ],
    "apply_filter": [
      "self",
      "filter",
      "input",
      "tilde_input"
    ]
  },
  "StochasticDifferentialEquation": {
    "__init__": [
      "self",
      "time_min",
      "time_max",
      "num_steps"
    ],
    "dt": [
      "self"
    ],
    "time_delta": [
      "self"
    ],
    "generate_time": [
      "self",
      "size",
      "device"
    ],
    "coefficients": [
      "self",
      "state",
      "time"
    ],
    "prior_sampling": [
      "self",
      "prior_mean"
    ],
    "discretize": [
      "self"
    ],
    "copy": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "OrnsteinUhlenbeckVarianceExplodingSDE": {
    "__init__": [
      "self",
      "stiffness",
      "std_min",
      "std_max",
      "num_steps",
      "time_min",
      "time_max",
      "eps"
    ],
    "std_ratio": [
      "self"
    ],
    "log_std_ratio": [
      "self"
    ],
    "perturb_kernel_mean": [
      "self",
      "state",
      "prior_mean",
      "time"
    ],
    "perturb_kernel_std": [
      "self",
      "time"
    ],
    "perturb_kernel_params": [
      "self",
      "state",
      "prior_mean",
      "time"
    ],
    "coefficients": [
      "self",
      "state",
      "time",
      "prior_mean",
      "state_length"
    ],
    "prior_sampling": [
      "self",
      "prior_mean"
    ],
    "copy": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ReverseStochasticDifferentialEquation": {
    "__init__": [
      "self"
    ],
    "coefficients": [
      "self",
      "state",
      "time",
      "score_condition",
      "state_length"
    ],
    "prior_sampling": [
      "self",
      "shape",
      "device"
    ],
    "discretize": [
      "self"
    ],
    "copy": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "PredictorCorrectorSampler": {
    "__init__": [
      "self",
      "sde",
      "score_estimator",
      "predictor",
      "corrector",
      "num_steps",
      "num_corrector_steps",
      "time_max",
      "time_min",
      "snr",
      "output_type"
    ],
    "forward": [
      "self",
      "prior_mean",
      "score_condition",
      "state_length"
    ]
  },
  "Predictor": {
    "__init__": [
      "self",
      "sde",
      "score_estimator"
    ],
    "forward": [
      "self"
    ]
  },
  "ReverseDiffusionPredictor": {
    "__init__": [
      "self",
      "sde",
      "score_estimator"
    ],
    "forward": [
      "self"
    ]
  },
  "Corrector": {
    "__init__": [
      "self",
      "sde",
      "score_estimator",
      "snr",
      "num_steps"
    ],
    "forward": [
      "self",
      "state",
      "time",
      "score_condition",
      "state_length"
    ]
  },
  "AnnealedLangevinDynamics": {
    "__init__": [
      "self",
      "sde"
    ],
    "forward": [
      "self",
      "state",
      "time",
      "score_condition",
      "state_length"
    ]
  },
  "SBNoiseSchedule": {
    "__init__": [
      "self",
      "time_min",
      "time_max",
      "num_steps",
      "eps"
    ],
    "dt": [
      "self"
    ],
    "time_delta": [
      "self"
    ],
    "generate_time": [
      "self",
      "size",
      "device"
    ],
    "alpha_t_max": [
      "self"
    ],
    "sigma_t_max": [
      "self"
    ],
    "f": [
      "self",
      "time"
    ],
    "g": [
      "self",
      "time"
    ],
    "alpha": [
      "self",
      "time"
    ],
    "alpha_bar_from_alpha": [
      "self",
      "alpha"
    ],
    "get_alphas": [
      "self",
      "time"
    ],
    "sigma": [
      "self",
      "time"
    ],
    "sigma_bar_from_sigma": [
      "self",
      "sigma"
    ],
    "get_sigmas": [
      "self",
      "time"
    ],
    "copy": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SBNoiseScheduleVE": {
    "__init__": [
      "self",
      "k",
      "c",
      "time_min",
      "time_max",
      "num_steps",
      "eps"
    ],
    "f": [
      "self",
      "time"
    ],
    "g": [
      "self",
      "time"
    ],
    "alpha": [
      "self",
      "time"
    ],
    "sigma": [
      "self",
      "time"
    ],
    "copy": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SBNoiseScheduleVP": {
    "__init__": [
      "self",
      "beta_0",
      "beta_1",
      "c",
      "time_min",
      "time_max",
      "num_steps",
      "eps"
    ],
    "f": [
      "self",
      "time"
    ],
    "g": [
      "self",
      "time"
    ],
    "alpha": [
      "self",
      "time"
    ],
    "sigma": [
      "self",
      "time"
    ],
    "copy": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SBSampler": {
    "__init__": [
      "self",
      "noise_schedule",
      "estimator",
      "estimator_output",
      "estimator_time",
      "process",
      "time_max",
      "time_min",
      "num_steps",
      "eps"
    ],
    "time_max": [
      "self",
      "value"
    ],
    "time_min": [
      "self",
      "value"
    ],
    "num_steps": [
      "self",
      "value"
    ],
    "process": [
      "self",
      "value"
    ],
    "estimator_time": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "prior_mean",
      "estimator_condition",
      "state_length"
    ]
  },
  "ESTIMATOR_TARGET": [],
  "ConditionalFlow": {
    "__init__": [
      "self",
      "time_min",
      "time_max"
    ],
    "mean": [
      "self"
    ],
    "std": [
      "self"
    ],
    "vector_field": [
      "self"
    ],
    "_broadcast_time": [
      "time",
      "n_dim"
    ],
    "generate_time": [
      "self",
      "batch_size",
      "rng"
    ],
    "sample": [
      "self"
    ],
    "flow": [
      "self"
    ]
  },
  "OptimalTransportFlow": {
    "__init__": [
      "self",
      "time_min",
      "time_max",
      "sigma_start",
      "sigma_end"
    ],
    "mean": [
      "self"
    ],
    "std": [
      "self"
    ],
    "vector_field": [
      "self"
    ]
  },
  "ConditionalFlowMatchingSampler": {
    "__init__": [
      "self",
      "estimator",
      "num_steps",
      "time_min",
      "time_max"
    ],
    "time_step": [
      "self"
    ],
    "forward": [
      "self",
      "state",
      "estimator_condition",
      "state_length"
    ]
  },
  "ConditionalFlowMatchingEulerSampler": {
    "__init__": [
      "self",
      "estimator",
      "num_steps",
      "time_min",
      "time_max",
      "estimator_target",
      "flow"
    ],
    "__call__": [
      "self"
    ],
    "forward": [
      "self",
      "state",
      "estimator_condition",
      "state_length"
    ]
  },
  "LearnedSinusoidalPosEmb": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "t"
    ]
  },
  "ConvPositionEmbed": {
    "__init__": [
      "self",
      "dim",
      "kernel_size",
      "groups"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "AdaptiveRMSNorm": {
    "__init__": [
      "self",
      "dim",
      "cond_dim"
    ],
    "forward": [
      "self",
      "x",
      "cond"
    ]
  },
  "GEGLU": {
    "forward": [
      "self",
      "x"
    ]
  },
  "get_feedforward_layer": [
    "dim",
    "mult",
    "dropout"
  ],
  "TransformerUNet": {
    "__init__": [
      "self",
      "dim",
      "depth",
      "heads",
      "ff_mult",
      "attn_dropout",
      "ff_dropout",
      "max_positions",
      "adaptive_rmsnorm",
      "adaptive_rmsnorm_cond_dim_in",
      "use_unet_skip_connection",
      "skip_connect_scale"
    ],
    "init_alibi": [
      "self",
      "max_positions",
      "heads"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "key_padding_mask",
      "adaptive_rmsnorm_cond"
    ],
    "get_alibi_bias": [
      "self",
      "batch_size",
      "seq_len"
    ]
  },
  "SpectrogramTransformerUNet": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "freq_dim",
      "dim",
      "depth",
      "heads",
      "ff_mult",
      "ff_dropout",
      "attn_dropout",
      "max_positions",
      "time_hidden_dim",
      "conv_pos_embed_kernel_size",
      "conv_pos_embed_groups",
      "adaptive_rmsnorm"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "_get_key_padding_mask": [
      "input_length",
      "max_length"
    ],
    "forward": [
      "self",
      "input",
      "input_length",
      "condition"
    ]
  },
  "SpeechEnhancementLoggingCallback": {
    "__init__": [
      "self",
      "data_loader",
      "data_loader_idx",
      "loggers",
      "log_tensorboard",
      "log_wandb",
      "sample_rate",
      "max_utts"
    ],
    "_log_audio": [
      "self",
      "audios",
      "lengths",
      "step",
      "label"
    ],
    "on_validation_epoch_end": [
      "self",
      "trainer",
      "model"
    ]
  },
  "SOUND_VELOCITY": [],
  "sinc_unnormalized": [
    "x"
  ],
  "theoretical_coherence": [
    "mic_positions",
    "sample_rate",
    "field",
    "fft_length",
    "sound_velocity"
  ],
  "estimated_coherence": [
    "S",
    "eps"
  ],
  "generate_approximate_noise_field": [
    "mic_positions",
    "noise_signal",
    "sample_rate",
    "field",
    "fft_length",
    "method",
    "sound_velocity"
  ],
  "transform_to_match_coherence": [
    "signal",
    "desired_coherence",
    "method",
    "ref_channel",
    "corrcoef_threshold"
  ],
  "rms": [
    "x"
  ],
  "mag2db": [
    "mag",
    "eps"
  ],
  "db2mag": [
    "db"
  ],
  "pow2db": [
    "power",
    "eps"
  ],
  "get_segment_start": [
    "signal",
    "segment"
  ],
  "calculate_sdr_numpy": [
    "estimate",
    "target",
    "scale_invariant",
    "convolution_invariant",
    "convolution_filter_length",
    "remove_mean",
    "sdr_max",
    "eps"
  ],
  "wrap_to_pi": [
    "x"
  ],
  "convmtx_numpy": [
    "x",
    "filter_length",
    "delay",
    "n_steps"
  ],
  "convmtx_mc_numpy": [
    "x",
    "filter_length",
    "delay",
    "n_steps"
  ],
  "scale_invariant_target_numpy": [
    "estimate",
    "target",
    "eps"
  ],
  "convolution_invariant_target_numpy": [
    "estimate",
    "target",
    "filter_length",
    "diag_reg",
    "eps"
  ],
  "toeplitz": [
    "x"
  ],
  "covariance_matrix": [
    "x",
    "mask",
    "normalize_mask",
    "eps"
  ],
  "Resample": {
    "__init__": [
      "self",
      "orig_freq",
      "new_freq",
      "resampling_method",
      "lowpass_filter_width",
      "rolloff",
      "beta"
    ],
    "forward": [
      "self",
      "waveform"
    ]
  },
  "_get_sinc_resample_kernel": [
    "orig_freq",
    "new_freq",
    "gcd",
    "lowpass_filter_width",
    "rolloff",
    "resampling_method",
    "beta",
    "device",
    "dtype"
  ],
  "_apply_sinc_resample_kernel": [
    "waveform",
    "orig_freq",
    "new_freq",
    "gcd",
    "kernel",
    "width"
  ],
  "apply_weight_norm_lstm": [
    "lstm_module"
  ],
  "remove_weight_norm_lstm": [
    "lstm_module"
  ],
  "AudioToAudioModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_setup_loss": [
      "self"
    ],
    "_get_num_dataloaders": [
      "self",
      "tag"
    ],
    "_setup_metrics": [
      "self",
      "tag"
    ],
    "evaluation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "tag"
    ],
    "on_validation_start": [
      "self"
    ],
    "on_test_start": [
      "self"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_evaluation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx",
      "tag"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "_setup_process_dataloader": [
      "self",
      "config"
    ],
    "match_batch_length": [
      "input",
      "batch_length"
    ],
    "process": [
      "self",
      "paths2audio_files",
      "output_dir",
      "batch_size",
      "num_workers",
      "input_channel_selector",
      "input_dir"
    ],
    "list_available_models": [
      "cls"
    ],
    "setup_optimization_flags": [
      "self"
    ],
    "on_after_backward": [
      "self"
    ],
    "configure_callbacks": [
      "self"
    ]
  },
  "EncMaskDecAudioToAudioModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "evaluation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "tag"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "PredictiveAudioToAudioModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "evaluation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "tag"
    ]
  },
  "ScoreBasedGenerativeAudioToAudioModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_length"
    ],
    "_step": [
      "self",
      "target_signal",
      "input_signal",
      "input_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "evaluation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "tag"
    ]
  },
  "FlowMatchingAudioToAudioModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_length"
    ],
    "forward_eval": [
      "self",
      "input_signal",
      "input_length"
    ],
    "forward_internal": [
      "self",
      "input_signal",
      "input_length",
      "enable_ssl_masking"
    ],
    "_step": [
      "self",
      "target_signal",
      "input_signal",
      "input_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "evaluation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "tag"
    ]
  },
  "SchroedingerBridgeAudioToAudioModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_length"
    ],
    "_step": [
      "self",
      "target_signal",
      "input_signal",
      "input_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "evaluation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "tag"
    ]
  },
  "SUPPORTED_SAMPLE_RATE": [],
  "SUPPORTED_INPUT_ALIGN_MS": [],
  "SUPPORTED_INPUT_ALIGN_SAMPLES": [],
  "_Seasr": {
    "__init__": [
      "self",
      "sample_rate",
      "hidden_nodes",
      "streaming",
      "kernel_size",
      "f1",
      "f2",
      "stride",
      "dropout"
    ],
    "forward": [
      "self"
    ],
    "apply_weight_norm": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "BNR2": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "evaluation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "tag"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "AudioToSpectrogram": {
    "__init__": [
      "self",
      "fft_length",
      "hop_length",
      "magnitude_power",
      "scale",
      "center"
    ],
    "win_length": [
      "self"
    ],
    "stft": [
      "self",
      "x"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_length"
    ],
    "get_output_length": [
      "self",
      "input_length"
    ]
  },
  "SpectrogramToAudio": {
    "__init__": [
      "self",
      "fft_length",
      "hop_length",
      "magnitude_power",
      "scale",
      "center"
    ],
    "win_length": [
      "self"
    ],
    "istft": [
      "self",
      "x_spec"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_length"
    ],
    "get_output_length": [
      "self",
      "input_length"
    ],
    "_stream_initialized": [
      "self"
    ],
    "_eps": [
      "self"
    ],
    "_init_stream_buffers": [
      "self",
      "shape_like"
    ],
    "reset_streaming": [
      "self"
    ],
    "_shift_left_inplace": [
      "self",
      "buffer"
    ],
    "stream_update": [
      "self",
      "input"
    ],
    "stream_finalize": [
      "self"
    ]
  },
  "MaskEstimatorRNN": {
    "__init__": [
      "self",
      "num_outputs",
      "num_subbands",
      "num_features",
      "num_layers",
      "num_hidden_features",
      "num_input_channels",
      "dropout",
      "bidirectional",
      "rnn_type",
      "mag_reduction",
      "use_ipd"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_length"
    ]
  },
  "MaskEstimatorFlexChannels": {
    "__init__": [
      "self",
      "num_outputs",
      "num_subbands",
      "num_blocks",
      "channel_reduction_position",
      "channel_reduction_type",
      "channel_block_type",
      "temporal_block_type",
      "temporal_block_num_layers",
      "temporal_block_num_heads",
      "temporal_block_dimension",
      "temporal_block_self_attention_model",
      "temporal_block_att_context_size",
      "num_input_channels",
      "mag_reduction",
      "mag_power",
      "use_ipd",
      "mag_normalization",
      "ipd_normalization"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_length"
    ]
  },
  "MaskEstimatorGSS": {
    "__init__": [
      "self",
      "num_iterations",
      "eps",
      "dtype"
    ],
    "normalize": [
      "self",
      "x",
      "dim"
    ],
    "update_masks": [
      "self",
      "alpha",
      "activity",
      "log_pdf"
    ],
    "update_weights": [
      "self",
      "gamma"
    ],
    "update_pdf": [
      "self",
      "z",
      "gamma",
      "zH_invBM_z"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "activity"
    ]
  },
  "MaskReferenceChannel": {
    "__init__": [
      "self",
      "ref_channel",
      "mask_min_db",
      "mask_max_db"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_length",
      "mask"
    ]
  },
  "MaskBasedBeamformer": {
    "__init__": [
      "self",
      "filter_type",
      "filter_beta",
      "filter_rank",
      "filter_postfilter",
      "ref_channel",
      "ref_hard",
      "ref_hard_use_grad",
      "ref_subband_weighting",
      "num_subbands",
      "mask_min_db",
      "mask_max_db",
      "postmask_min_db",
      "postmask_max_db",
      "diag_reg",
      "eps"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "mask",
      "mask_undesired",
      "input_length"
    ]
  },
  "MaskBasedDereverbWPE": {
    "__init__": [
      "self",
      "filter_length",
      "prediction_delay",
      "num_iterations",
      "mask_min_db",
      "mask_max_db",
      "diag_reg",
      "eps",
      "dtype"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_length",
      "mask"
    ]
  },
  "SpectrogramToMultichannelFeatures": {
    "__init__": [
      "self",
      "num_subbands",
      "num_input_channels",
      "mag_reduction",
      "mag_power",
      "use_ipd",
      "mag_normalization",
      "ipd_normalization",
      "eps"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "num_features": [
      "self"
    ],
    "num_channels": [
      "self"
    ],
    "get_mean_time_channel": [
      "input",
      "input_length"
    ],
    "get_mean_std_time_channel": [
      "cls",
      "input",
      "input_length",
      "eps"
    ],
    "normalize_mean": [
      "self",
      "input",
      "input_length"
    ],
    "normalize_mean_var": [
      "self",
      "input",
      "input_length"
    ],
    "forward": [
      "self",
      "input",
      "input_length"
    ]
  },
  "SSLPretrainWithMaskedPatch": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "patch_size",
      "mask_fraction"
    ],
    "forward": [
      "self",
      "input_spec",
      "length"
    ]
  },
  "MixtureConsistencyProjection": {
    "__init__": [
      "self",
      "weighting",
      "eps"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "mixture",
      "estimate"
    ]
  },
  "EMU_HUB": [],
  "VQ_HUB": [],
  "smart_resize": [
    "image",
    "factor",
    "min_pixels",
    "max_pixels"
  ],
  "to_imgstr": [
    "image_tokens",
    "tokenizer"
  ],
  "VOCAB_FILES_NAMES": [],
  "PAT_STR": [],
  "ENDOFTEXT": [],
  "IMSTART": [],
  "IMEND": [],
  "EXTRAS": [],
  "SPECIAL_START_ID": [],
  "_load_tiktoken_bpe": [
    "tiktoken_bpe_file"
  ],
  "CosmosMultiModalTokenizer": {
    "vocab_files_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "special_tokens_file",
      "errors",
      "bos_token",
      "eos_token",
      "pad_token",
      "img_token",
      "boi_token",
      "eoi_token",
      "eol_token",
      "eof_token"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "__len__": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "_add_tokens": [
      "self",
      "new_tokens",
      "special_tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory"
    ],
    "tokenize": [
      "self",
      "text",
      "allowed_special",
      "disallowed_special"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "vocab_size": [
      "self"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "errors"
    ]
  },
  "_NUM_OBJECT_STORE_READ_ATTEMPTS": [],
  "get_collate_fn": [
    "first_stage_key",
    "cond_stage_key"
  ],
  "_IMG_EXTENSIONS": [],
  "pil_loader": [
    "key",
    "data"
  ],
  "get_world_size": [],
  "WebDatasetCommon": {
    "__init__": [
      "self",
      "dataset_cfg",
      "map_fn",
      "compose_fn",
      "consumed_samples",
      "filter_fn",
      "gen_cfg",
      "decode_fn",
      "is_train"
    ],
    "_get_webdataset_and_epoch": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "SharedEpoch": {
    "__init__": [
      "self",
      "epoch"
    ],
    "set_value": [
      "self",
      "epoch"
    ],
    "get_value": [
      "self"
    ]
  },
  "WDSUrlsRandomSampler": {
    "__init__": [
      "self",
      "urls",
      "total_urls",
      "chunk_size",
      "consumed_samples",
      "data_parallel_rank",
      "data_parallel_size",
      "num_workers",
      "drop_last",
      "data_sharding"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "imagenet_classnames": [],
  "openai_imagenet_template": [],
  "get_preprocess_fns_params": [
    "img_h",
    "img_w",
    "img_mean",
    "img_std",
    "is_train",
    "max_position_embedding",
    "tokenizer"
  ],
  "get_preprocess_fns": [
    "model_cfg",
    "tokenizer",
    "is_train"
  ],
  "tuple_to_dict": [
    "inp"
  ],
  "transform_fn": [
    "sample",
    "img_transform",
    "text_transform"
  ],
  "build_train_valid_datasets": [
    "model_cfg",
    "consumed_samples",
    "tokenizer"
  ],
  "custom_collate": [
    "batch"
  ],
  "build_imagenet_validation_dataloader_params": [
    "imagenet_val",
    "img_h",
    "img_w",
    "mbs",
    "gbs",
    "num_workers",
    "pin_memory",
    "img_mean",
    "img_std",
    "is_train",
    "max_position_embedding",
    "tokenizer"
  ],
  "build_imagenet_validation_dataloader": [
    "model_cfg",
    "tokenizer"
  ],
  "ImagenetClassnameDataset": {
    "__init__": [
      "self",
      "classnames",
      "templates",
      "text_transform"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "OPENAI_DATASET_MEAN": [],
  "OPENAI_DATASET_STD": [],
  "AugmentationCfg": {},
  "ResizeMaxSize": {
    "__init__": [
      "self",
      "max_size",
      "interpolation",
      "fn",
      "fill"
    ],
    "forward": [
      "self",
      "img"
    ]
  },
  "_convert_to_rgb": [
    "image"
  ],
  "image_transform": [
    "image_size",
    "is_train",
    "mean",
    "std",
    "resize_longest_max",
    "fill_color",
    "aug_cfg"
  ],
  "EnergonMultiModalDataModule": {
    "__init__": [
      "self",
      "path",
      "tokenizer",
      "image_processor",
      "seq_length",
      "micro_batch_size",
      "global_batch_size",
      "num_workers",
      "num_val_workers",
      "pin_memory",
      "shuffle_buffer_size",
      "max_samples_per_sequence",
      "multimodal_sample_config",
      "task_encoder",
      "decoder_seq_length",
      "packing_buffer_size",
      "validation_task_encoder"
    ],
    "io_init": [
      "self"
    ],
    "datasets_provider": [
      "self",
      "worker_config",
      "split"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "SequentialMegatronSampler": {
    "__init__": [
      "self",
      "seq_len",
      "micro_batch_size",
      "global_batch_size",
      "init_consumed_samples",
      "decoder_seq_len",
      "init_global_step"
    ],
    "transform_dataloader": [
      "self",
      "dataloader"
    ],
    "megatron_data_kwargs": [
      "self"
    ]
  },
  "SampleEncoder": {
    "__init__": [
      "self"
    ],
    "encode": [
      "self",
      "input_sample",
      "output_sample"
    ]
  },
  "BaseSampleEncoder": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "multimodal_sample_config",
      "image_tag_type"
    ],
    "process_image": [
      "self",
      "image"
    ],
    "compute_loss_mask": [
      "self",
      "labels"
    ],
    "encode": [
      "self",
      "input_sample",
      "output_sample"
    ]
  },
  "VQASampleEncoder": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "multimodal_sample_config",
      "image_tag_type"
    ],
    "apply_prompt_template": [
      "self",
      "input_text",
      "use_plain"
    ],
    "tokenize": [
      "self",
      "prompt"
    ],
    "compute_labels": [
      "self",
      "tokens",
      "sample"
    ],
    "encode": [
      "self",
      "input_sample",
      "output_sample"
    ],
    "process_answer_str": [
      "self",
      "answer",
      "stop_str"
    ]
  },
  "InterleavedSampleEncoder": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "multimodal_sample_config",
      "image_tag_type"
    ],
    "tokenize": [
      "self",
      "sample"
    ],
    "compute_labels": [
      "self",
      "tokens"
    ],
    "encode": [
      "self",
      "input_sample",
      "output_sample"
    ]
  },
  "SimilarityInterleavedEncoder": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "multimodal_sample_config",
      "image_tag_type"
    ],
    "tokenize": [
      "self",
      "sample"
    ]
  },
  "AudioToken": {},
  "ImageTextSample": {},
  "PackedImageTextSample": {},
  "ImageTextRawBatch": {},
  "PackedImageTextRawBatch": {},
  "MultiModalSampleConfig": {},
  "MultiModalTaskEncoder": {
    "__init__": [
      "self",
      "tokenizer",
      "image_processor",
      "multimodal_sample_config",
      "packed_sequence",
      "packed_sequence_size",
      "num_image_embeddings_per_tile",
      "image_tag_type"
    ],
    "register_encoder": [
      "self",
      "sample_type",
      "encoder"
    ],
    "encode_sample": [
      "self",
      "sample"
    ],
    "batch": [
      "self",
      "samples"
    ],
    "encode_batch": [
      "self",
      "batch_data"
    ],
    "select_samples_to_pack": [
      "self",
      "samples"
    ],
    "pack_selected_samples": [
      "self",
      "samples"
    ]
  },
  "BaseConversationTemplateConfig": {
    "chat_template": []
  },
  "LLaVATemplateConfig": {},
  "MLlamaTemplateConfig": {},
  "LhotseAudioQuestionAnswerDataset": {
    "__init__": [
      "self",
      "text_processor",
      "default_context",
      "tokens_to_generate",
      "pad_to_max_length",
      "max_seq_length",
      "context_key",
      "default_context_key"
    ],
    "__getitem__": [
      "self",
      "all_cuts"
    ]
  },
  "as_dict": [
    "arg"
  ],
  "build_speechllm_dataset": [
    "model_instance",
    "data_cfg",
    "is_train"
  ],
  "build_speechllm_dataloader": [
    "dataset",
    "data_cfg",
    "consumed_samples",
    "is_predict",
    "is_eval"
  ],
  "PEFT_MODULE_MAP": [],
  "LORA_CONFIG_TO_MCORE_MAP": [],
  "get_target_modules": [
    "lora_cfg",
    "default"
  ],
  "PEFTConfig": {
    "__init__": [
      "self",
      "peft_cfg",
      "name_key_to_cfg"
    ],
    "get_config_dict": [
      "self"
    ],
    "_calculate_kv_channels": [
      "self",
      "cfg"
    ]
  },
  "SelectivePEFTConfig": {
    "__init__": [
      "self",
      "cfg"
    ]
  },
  "MLPHeadPEFTConfig": {
    "__init__": [
      "self",
      "cfg"
    ]
  },
  "LoraPEFTConfig": {
    "__init__": [
      "self",
      "cfg"
    ],
    "_create_lora_config": [
      "self",
      "cfg",
      "lora_cfg",
      "in_features",
      "out_features",
      "adapter_cfg_cls",
      "num_query_groups",
      "kv_channels"
    ]
  },
  "QLoraPEFTConfig": {},
  "IA3PEFTConfig": {
    "__init__": [
      "self",
      "cfg"
    ]
  },
  "PtuningPEFTConfig": {
    "__init__": [
      "self",
      "cfg"
    ]
  },
  "CanonicalAdaptersPEFTConfig": {
    "__init__": [
      "self",
      "cfg"
    ]
  },
  "SDLoraPEFTConfig": {
    "__init__": [
      "self",
      "cfg"
    ]
  },
  "PEFT_CONFIG_MAP": [],
  "maybe_cast_to_list": [
    "x"
  ],
  "get_num_samples_from_files": [
    "file_list"
  ],
  "shift_tokens_by_multi_audios": [
    "context_tokens",
    "context_lengths",
    "audio_feat_lens",
    "context_start_idx",
    "encoder_max_length"
  ],
  "get_nested_dict_value": [
    "d",
    "key",
    "sep"
  ],
  "align_feat_seq_list": [
    "seq_list",
    "seq_len_list",
    "mode",
    "pooling",
    "target_len"
  ],
  "TextProcessing": {
    "__init__": [
      "self",
      "tokenizer",
      "max_seq_length",
      "min_seq_length",
      "add_bos",
      "add_eos",
      "add_sep",
      "sep_id",
      "seed",
      "separate_prompt_and_response_with_newline",
      "answer_only_loss",
      "truncation_field",
      "pad_to_max_length",
      "prompt_template",
      "virtual_tokens",
      "tokens_to_generate",
      "context_key",
      "answer_key",
      "end_string",
      "audio_locator",
      "add_boa_eoa",
      "boa_string",
      "eoa_string"
    ],
    "__call__": [
      "self"
    ],
    "_process_example": [
      "self",
      "context",
      "output"
    ]
  },
  "get_text_processor_from_cfg": [
    "cfg",
    "tokenizer"
  ],
  "PromptFormatterTextProcessing": {
    "__init__": [
      "self",
      "tokenizer",
      "prompt_format",
      "audio_locator",
      "max_seq_length"
    ],
    "_process_example": [
      "self",
      "cut"
    ]
  },
  "_find_substring_indices": [
    "string",
    "substring"
  ],
  "SpeechLLMAdapterMixin": {
    "load_adapters": [
      "self",
      "filepath",
      "peft_cfgs",
      "map_location"
    ],
    "get_peft_state_dict": [
      "self"
    ]
  },
  "ModularizedAudioT5Model": {
    "setup_perception_modules": [
      "self",
      "cfg"
    ],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "load_frozen_model": [
      "self",
      "cfg",
      "trainer"
    ],
    "init_model": [
      "self",
      "cfg",
      "trainer"
    ],
    "parameters": [
      "self"
    ],
    "setup_optimizer_param_groups": [
      "self"
    ],
    "inject_perception_input": [
      "self",
      "encoded",
      "encoded_len",
      "input_ids",
      "input_length"
    ],
    "_shift_labels_by_emb_len": [
      "self",
      "labels",
      "label_lens",
      "emb_lens",
      "max_len",
      "pad_token"
    ],
    "_get_text_embeddings": [
      "self",
      "text_tokens",
      "position_ids"
    ],
    "prepare_llm_input": [
      "self",
      "audio_batch"
    ],
    "forward": [
      "self",
      "batch",
      "checkpoint_activations_all_layers"
    ],
    "get_forward_output_only_func": [
      "self"
    ],
    "get_forward_output_and_loss_func": [
      "self",
      "validation_step"
    ],
    "on_train_epoch_start": [
      "self"
    ],
    "_build_dataset": [
      "self",
      "data_cfg",
      "is_train"
    ],
    "build_data_loader": [
      "self",
      "dataset",
      "data_cfg",
      "consumed_samples",
      "is_eval"
    ],
    "_modify_config": [
      "cls",
      "gpt_cfg",
      "cfg",
      "audio_cfg",
      "add_cfg_to_tree"
    ],
    "load_audio_model": [
      "cls",
      "pretrained_audio_model"
    ],
    "restore_from_pretrained_models": [
      "cls",
      "cfg",
      "trainer"
    ],
    "_build_vocab": [
      "self"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "build_train_valid_test_datasets": [
      "self",
      "stage"
    ],
    "setup_training_data": [
      "self",
      "training_data_config"
    ],
    "setup_validation_data": [
      "self",
      "validation_data_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "setup_training_dataloader": [
      "self"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "_metrics_require_string2category_map": [
      "self"
    ],
    "setup_metric": [
      "self",
      "data_cfg"
    ],
    "_reconfigure_and_process_inference_batch": [
      "self",
      "batch",
      "data_cfg"
    ],
    "validation_step": [
      "self",
      "dataloader_iter",
      "inference"
    ],
    "_validation_step_internal": [
      "self",
      "dataloader_iter",
      "batch_idx",
      "dataloader_idx",
      "inference",
      "result_mode"
    ],
    "inference_step": [
      "self",
      "dataloader_iter",
      "mode",
      "dataloader_idx"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "on_test_epoch_end": [
      "self"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "inference_epoch_end": [
      "self",
      "outputs",
      "mode",
      "data_cfg"
    ],
    "write_predictions_to_file": [
      "self",
      "outputs",
      "output_file_path_prefix",
      "output_dir"
    ],
    "setup_eval_dataloader": [
      "self",
      "datasets",
      "data_cfg"
    ],
    "fwd_bwd_step": [
      "self",
      "dataloader_iter",
      "batch_idx",
      "forward_only"
    ],
    "loss_func": [
      "self",
      "loss_mask",
      "output_tensor"
    ],
    "_determine_log_key": [
      "self",
      "data_config",
      "dataloader_idx",
      "metric_name",
      "mode"
    ],
    "test_step": [
      "self",
      "dataloader_iter",
      "dataloader_idx"
    ],
    "training_step": [
      "self",
      "dataloader_iter"
    ],
    "setup_mcore_distributed_parallel": [
      "self"
    ],
    "oomptimizer_schema": [
      "self",
      "schema"
    ]
  },
  "DecoderTextPromptModularizedAudioT5Model": {
    "prepare_llm_input": [
      "self",
      "audio_batch"
    ],
    "forward": [
      "self",
      "audio_batch",
      "checkpoint_activations_all_layers"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "_build_dataset": [
      "self",
      "data_cfg",
      "is_train"
    ]
  },
  "CrossAttendModularAudioGPTModel": {
    "prepare_llm_input": [
      "self",
      "audio_batch"
    ],
    "setup_perception_modules": [
      "self",
      "cfg"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "configure_sharded_model": [
      "self"
    ]
  },
  "ConcatPooling": {
    "__init__": [
      "self",
      "pooling_factor"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PoolingMLPConnectors": {
    "__init__": [
      "self",
      "input_dim",
      "hidden_dim",
      "output_dim",
      "num_layers",
      "activation",
      "pooling",
      "pooling_factor"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio_signal",
      "length"
    ]
  },
  "IdentityConnectors": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "audio_signal",
      "length"
    ]
  },
  "MultiFeatureAggregator": {
    "__init__": [
      "self",
      "cfg",
      "channel_dim"
    ],
    "_have_same_length": [
      "self",
      "encoded_len"
    ],
    "forward": [
      "self",
      "encoded",
      "encoded_len",
      "ref_idx"
    ]
  },
  "MultiAudioPerceptionModule": {
    "__init__": [
      "self",
      "cfg"
    ],
    "maybe_preprocess_audio": [
      "self",
      "preprocessor",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ],
    "forward_speaker": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ]
  },
  "lens_to_mask": [
    "lens",
    "max_length"
  ],
  "TransformerCrossAttention": {
    "__init__": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "encoder_states",
      "encoded_len",
      "input_embeds",
      "input_lengths",
      "decoder_mems_list",
      "return_mems"
    ]
  },
  "TransformerDecoderBlock": {
    "__init__": [
      "self",
      "hidden_size",
      "inner_size",
      "num_attention_heads",
      "attn_score_dropout",
      "attn_layer_dropout",
      "ffn_dropout",
      "hidden_act",
      "pre_ln"
    ],
    "forward_preln": [
      "self",
      "decoder_query",
      "decoder_mask",
      "decoder_keys",
      "encoder_states",
      "encoder_mask"
    ],
    "forward_postln": [
      "self",
      "decoder_query",
      "decoder_mask",
      "decoder_keys",
      "encoder_states",
      "encoder_mask"
    ],
    "forward": [
      "self",
      "decoder_query",
      "decoder_mask",
      "decoder_keys",
      "encoder_states",
      "encoder_mask"
    ]
  },
  "TransformerDecoder": {
    "__init__": [
      "self",
      "num_layers",
      "hidden_size",
      "inner_size",
      "num_attention_heads",
      "attn_score_dropout",
      "attn_layer_dropout",
      "ffn_dropout",
      "hidden_act",
      "pre_ln",
      "pre_ln_final_layer_norm"
    ],
    "_get_memory_states": [
      "self",
      "decoder_states",
      "decoder_mems_list",
      "i"
    ],
    "forward": [
      "self",
      "decoder_states",
      "decoder_mask",
      "encoder_states",
      "encoder_mask",
      "decoder_mems_list",
      "return_mems",
      "return_mems_as_list"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ]
  },
  "PositionWiseFF": {
    "__init__": [
      "self",
      "hidden_size",
      "inner_size",
      "ffn_dropout",
      "hidden_act"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AudioToTextGenerationStrategy": {
    "init_batch": [
      "self",
      "context_tokens",
      "context_lengths",
      "audio_signal",
      "audio_length",
      "compute_attention_mask",
      "num_audios",
      "context_start_idx"
    ],
    "clip_max_len": [
      "self",
      "maxlen"
    ],
    "prepare_batch_at_step": [
      "self",
      "tokens",
      "input_embeddings",
      "maxlen",
      "micro_batch_size",
      "step",
      "context_lengths",
      "curr_context_length",
      "compute_attention_mask"
    ],
    "post_process": [
      "self",
      "tokens",
      "new_tokens",
      "context_length"
    ],
    "end_of_generation_condition": [
      "self",
      "tokens",
      "prev",
      "eod_id",
      "end_strings"
    ]
  },
  "CrossAttendAudioToTextGenerationStrategy": {
    "init_batch": [
      "self",
      "context_tokens",
      "context_lengths",
      "audio_signal",
      "audio_length",
      "compute_attention_mask",
      "num_audios",
      "context_start_idx"
    ],
    "prepare_batch_at_step": [
      "self",
      "tokens",
      "input_embeddings",
      "maxlen",
      "micro_batch_size",
      "step",
      "context_lengths",
      "curr_context_length",
      "compute_attention_mask"
    ]
  },
  "GPTModelTextGenerationStrategy": {
    "__init__": [
      "self",
      "model"
    ],
    "clip_max_len": [
      "self",
      "maxlen"
    ],
    "init_batch": [
      "self",
      "context_tokens",
      "context_length",
      "compute_attention_mask"
    ],
    "prepare_batch_at_step": [
      "self",
      "tokens",
      "maxlen",
      "micro_batch_size",
      "step",
      "context_length",
      "compute_attention_mask"
    ]
  },
  "GriffinModelTextGenerationStrategy": {
    "__init__": [
      "self",
      "model"
    ],
    "clip_max_len": [
      "self",
      "maxlen"
    ],
    "init_batch": [
      "self",
      "context_tokens",
      "context_length",
      "compute_attention_mask"
    ],
    "prepare_batch_at_step": [
      "self",
      "tokens",
      "maxlen",
      "micro_batch_size",
      "step",
      "context_length",
      "compute_attention_mask"
    ],
    "forward_step": [
      "self",
      "batch",
      "tensor_shape_and_context_length"
    ]
  },
  "neva_process_prompts": [
    "prompt",
    "tokenizer",
    "multimodal_cfg",
    "num_media_latents",
    "conv_template"
  ],
  "NevaModelTextGenerationStrategy": {
    "__init__": [
      "self",
      "model"
    ],
    "clip_max_len": [
      "self",
      "maxlen"
    ],
    "init_batch": [
      "self",
      "context_tokens",
      "context_length",
      "compute_attention_mask"
    ],
    "tokenize_batch": [
      "self",
      "prompt",
      "max_len",
      "add_BOS"
    ],
    "prepare_batch_at_step": [
      "self",
      "tokens",
      "maxlen",
      "micro_batch_size",
      "step",
      "context_length",
      "compute_attention_mask",
      "media"
    ]
  },
  "PromptLearningModelTextGenerationStrategy": {
    "__init__": [
      "self",
      "model",
      "task_ids"
    ],
    "init_batch": [
      "self",
      "context_tokens",
      "context_length",
      "compute_attention_mask"
    ],
    "clip_max_len": [
      "self",
      "maxlen"
    ],
    "prepare_batch_at_step": [
      "self",
      "tokens",
      "maxlen",
      "micro_batch_size",
      "step",
      "context_length",
      "compute_attention_mask"
    ],
    "post_process": [
      "self",
      "tokens",
      "new_tokens",
      "context_length"
    ]
  },
  "McoreRetroModelTextGenerationStrategy": {
    "__init__": [
      "self",
      "model"
    ],
    "clip_max_len": [
      "self",
      "maxlen"
    ],
    "tokenize_batch": [
      "self",
      "sentences",
      "max_len",
      "add_BOS"
    ],
    "tokenize_neighbors_batch": [
      "self",
      "neighbors",
      "retro_args"
    ],
    "init_batch": [
      "self",
      "context_tokens",
      "context_length",
      "compute_attention_mask"
    ],
    "prepare_batch_at_step": [
      "self",
      "tokens",
      "maxlen",
      "micro_batch_size",
      "step",
      "context_length",
      "compute_attention_mask"
    ]
  },
  "get_model_parallel_src_rank": [],
  "repetition_penalty": [
    "logits",
    "repetition_penalty",
    "used_tokens"
  ],
  "top_k_logits": [
    "logits",
    "top_k",
    "top_p",
    "filter_value",
    "started"
  ],
  "_video_speech_collate_fn": [
    "batch",
    "pad_id"
  ],
  "_VideoTextDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "manifest_filepath",
      "parser",
      "int_values",
      "max_duration",
      "min_duration",
      "max_utts",
      "trim",
      "bos_id",
      "eos_id",
      "pad_id",
      "return_sample_id",
      "channel_selector"
    ],
    "get_manifest_sample": [
      "self",
      "sample_id"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "VSRManifestProcessor": {
    "__init__": [
      "self",
      "manifest_filepath",
      "parser",
      "max_duration",
      "min_duration",
      "max_utts",
      "bos_id",
      "eos_id",
      "pad_id",
      "index_by_file_id"
    ],
    "process_text_by_id": [
      "self",
      "index"
    ],
    "process_text_by_file_id": [
      "self",
      "file_id"
    ],
    "process_text_by_sample": [
      "self",
      "sample"
    ]
  },
  "VideoToBPEDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "manifest_filepath",
      "tokenizer",
      "int_values",
      "max_duration",
      "min_duration",
      "max_utts",
      "trim",
      "use_start_end_token",
      "return_sample_id",
      "channel_selector"
    ]
  },
  "VideoToCharDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "manifest_filepath",
      "labels",
      "int_values",
      "max_duration",
      "min_duration",
      "max_utts",
      "blank_index",
      "unk_index",
      "normalize",
      "trim",
      "bos_id",
      "eos_id",
      "pad_id",
      "parser",
      "return_sample_id",
      "channel_selector"
    ]
  },
  "_TarredVideoToTextDataset": {
    "__init__": [
      "self",
      "audio_tar_filepaths",
      "manifest_filepath",
      "parser",
      "int_values",
      "shuffle_n",
      "min_duration",
      "max_duration",
      "trim",
      "bos_id",
      "eos_id",
      "pad_id",
      "shard_strategy",
      "global_rank",
      "world_size",
      "return_sample_id"
    ],
    "_filter": [
      "self",
      "iterator"
    ],
    "_loop_offsets": [
      "self",
      "iterator"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "_build_sample": [
      "self",
      "tup"
    ],
    "get_manifest_sample": [
      "self",
      "sample_id"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "TarredVideoToBPEDataset": {
    "__init__": [
      "self",
      "audio_tar_filepaths",
      "manifest_filepath",
      "tokenizer",
      "int_values",
      "shuffle_n",
      "min_duration",
      "max_duration",
      "trim",
      "use_start_end_token",
      "shard_strategy",
      "global_rank",
      "world_size",
      "return_sample_id"
    ]
  },
  "get_video_to_text_bpe_dataset_from_config": [
    "config",
    "local_rank",
    "global_rank",
    "world_size",
    "tokenizer",
    "preprocessor_cfg"
  ],
  "get_video_to_text_char_dataset_from_config": [
    "config",
    "local_rank",
    "global_rank",
    "world_size",
    "preprocessor_cfg"
  ],
  "get_bpe_dataset": [
    "config",
    "tokenizer"
  ],
  "get_char_dataset": [
    "config"
  ],
  "get_tarred_dataset": [
    "config",
    "shuffle_n",
    "global_rank",
    "world_size",
    "tokenizer"
  ],
  "Permute": {
    "__init__": [
      "self",
      "dims",
      "make_contiguous"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNetBlock": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "kernel_size",
      "stride",
      "weight_init",
      "bias_init"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GlobalAvgPool2d": {
    "__init__": [
      "self",
      "dim",
      "keepdim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNet": {
    "__init__": [
      "self",
      "dim_input",
      "dim_output",
      "model",
      "include_stem",
      "include_head"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNetBottleneckBlock": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bottleneck_ratio",
      "kernel_size",
      "stride",
      "weight_init",
      "bias_init"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "padding_mode",
      "device",
      "dtype",
      "weight_init",
      "bias_init"
    ]
  },
  "VideoFeaturizer": {
    "__init__": [
      "self"
    ],
    "process": [
      "self",
      "video_file",
      "offset",
      "duration"
    ],
    "from_file": [
      "self",
      "video_file",
      "offset",
      "duration"
    ]
  },
  "VisualEncDecCTCModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "transcribe": [
      "self",
      "paths2video_files",
      "batch_size",
      "logprobs",
      "return_hypotheses",
      "num_workers",
      "channel_selector",
      "augmentor"
    ],
    "change_vocabulary": [
      "self",
      "new_vocabulary",
      "decoding_cfg"
    ],
    "change_decoding_strategy": [
      "self",
      "decoding_cfg"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_video_signal",
      "input_video_signal_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_nb"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_dataloader": [
      "self"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "list_available_models": [
      "cls"
    ],
    "wer": [
      "self",
      "wer"
    ]
  },
  "VisualEncDecHybridRNNTCTCBPEModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "change_vocabulary": [
      "self",
      "new_tokenizer_dir",
      "new_tokenizer_type",
      "decoding_cfg",
      "ctc_decoding_cfg"
    ],
    "change_decoding_strategy": [
      "self",
      "decoding_cfg",
      "decoder_type"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "VisualEncDecCTCModelBPE": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "change_vocabulary": [
      "self",
      "new_tokenizer_dir",
      "new_tokenizer_type",
      "decoding_cfg"
    ],
    "change_decoding_strategy": [
      "self",
      "decoding_cfg"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "VisualEncDecHybridRNNTCTCModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "transcribe": [
      "self",
      "paths2video_files",
      "batch_size",
      "return_hypotheses",
      "partial_hypothesis",
      "num_workers",
      "channel_selector"
    ],
    "change_vocabulary": [
      "self",
      "new_vocabulary",
      "decoding_cfg",
      "ctc_decoding_cfg"
    ],
    "change_decoding_strategy": [
      "self",
      "decoding_cfg",
      "decoder_type"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_nb"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "VisualEncDecRNNTModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "setup_optim_normalization": [
      "self"
    ],
    "extract_rnnt_loss_cfg": [
      "self",
      "cfg"
    ],
    "transcribe": [
      "self",
      "paths2video_files",
      "batch_size",
      "return_hypotheses",
      "partial_hypothesis",
      "num_workers",
      "channel_selector",
      "augmentor"
    ],
    "change_vocabulary": [
      "self",
      "new_vocabulary",
      "decoding_cfg"
    ],
    "change_decoding_strategy": [
      "self",
      "decoding_cfg"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_nb"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "on_after_backward": [
      "self"
    ],
    "list_export_subnets": [
      "self"
    ],
    "decoder_joint": [
      "self"
    ],
    "list_available_models": [
      "cls"
    ],
    "wer": [
      "self",
      "wer"
    ]
  },
  "VisualEncDecRNNTBPEModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "change_vocabulary": [
      "self",
      "new_tokenizer_dir",
      "new_tokenizer_type",
      "decoding_cfg"
    ],
    "change_decoding_strategy": [
      "self",
      "decoding_cfg"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "VideoPreprocessor": {
    "__init__": [
      "self",
      "grayscale",
      "normalize",
      "resize",
      "resize_size",
      "norm_mean",
      "norm_std"
    ],
    "forward": [
      "self",
      "input_signal",
      "length"
    ]
  },
  "NormalizeVideo": {
    "__init__": [
      "self",
      "mean",
      "std"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResizeVideo": {
    "__init__": [
      "self",
      "size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LinearProjectionVideoFrontEnd": {
    "__init__": [
      "self",
      "in_channels",
      "in_height",
      "in_width",
      "dim_output",
      "out_channels_first",
      "circle_crop",
      "circle_radius"
    ],
    "input_types": [
      "self"
    ],
    "input_types_for_export": [
      "self"
    ],
    "get_circle_indices": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "length"
    ]
  },
  "VideoAugmentation": {
    "__init__": [
      "self",
      "random_crop",
      "crop_size",
      "horizontal_flip",
      "time_masking",
      "num_mask_second",
      "spatial_masking",
      "mean_frame"
    ],
    "input_types": [
      "self"
    ],
    "input_types_for_export": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "length"
    ]
  },
  "SpatialVideoMasking": {
    "__init__": [
      "self",
      "num_horizontal_masks",
      "num_vertical_masks",
      "max_h",
      "max_v",
      "mean_frame"
    ],
    "forward": [
      "self",
      "input_signal",
      "length"
    ]
  },
  "VideoFrameMasking": {
    "__init__": [
      "self",
      "T_second",
      "num_mask_second",
      "fps",
      "mean_frame"
    ],
    "forward": [
      "self",
      "input_signal",
      "length"
    ]
  },
  "ResNetVideoFrontEnd": {
    "__init__": [
      "self",
      "in_channels",
      "model",
      "dim_output",
      "out_channels_first"
    ],
    "input_types": [
      "self"
    ],
    "input_types_for_export": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "length"
    ]
  },
  "SAFE_REPOS": [],
  "task": [],
  "factory": [],
  "barrier": [],
  "is_safe_repo": [
    "hf_path",
    "trust_remote_code"
  ],
  "AnyPath": [],
  "prune": [
    "nemo_checkpoint",
    "save_path",
    "pruning_config",
    "devices",
    "num_nodes",
    "tp_size",
    "pp_size",
    "num_layers_in_first_pipeline_stage",
    "num_layers_in_last_pipeline_stage",
    "num_train_samples",
    "data",
    "tokenizer_path",
    "legacy_ckpt"
  ],
  "distill": [
    "student_model_path",
    "teacher_model_path",
    "data",
    "trainer",
    "distillation_config_path",
    "log",
    "resume",
    "optim",
    "tokenizer",
    "model_transform"
  ],
  "_build_directory_tree": [
    "path",
    "tree",
    "root_name"
  ],
  "_load_model_from_path": [
    "model"
  ],
  "BERTLossReduction": {
    "__init__": [
      "self",
      "validation_step",
      "val_drop_last",
      "add_sop_loss"
    ],
    "forward": [
      "self",
      "batch",
      "forward_out"
    ],
    "reduce": [
      "self",
      "losses_reduced_per_micro_batch"
    ]
  },
  "HardNegativeRankingLoss": {
    "__init__": [
      "self",
      "validation_step",
      "val_drop_last",
      "num_hard_negatives",
      "scale",
      "label_smoothing"
    ],
    "forward": [
      "self",
      "batch",
      "forward_out"
    ],
    "reduce": [
      "self",
      "losses_reduced_per_micro_batch"
    ]
  },
  "BERTInBatchExclusiveHardNegativesRankingLoss": {
    "__init__": [
      "self",
      "validation_step",
      "val_drop_last",
      "num_hard_negatives",
      "scale",
      "label_smoothing",
      "global_in_batch_negatives",
      "backprop_type"
    ],
    "_gather_global_in_batch_representations": [
      "self",
      "local_tensor"
    ],
    "forward": [
      "self",
      "batch",
      "forward_out"
    ],
    "reduce": [
      "self",
      "losses_reduced_per_micro_batch"
    ]
  },
  "masked_token_with_zero": [
    "tensor",
    "mask"
  ],
  "sentence_order_prediction_loss": [
    "tensor",
    "sentence_order"
  ],
  "BERTPreTrainingDataModule": {
    "__init__": [
      "self",
      "paths",
      "seq_length",
      "tokenizer",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "reset_position_ids",
      "reset_attention_mask",
      "eod_mask_loss",
      "seed",
      "split",
      "index_mapping_dir"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "_create_dataloader": [
      "self",
      "dataset",
      "mode"
    ],
    "bert_dataset_config": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "reconfigure_limit_batches": [
      "self"
    ],
    "_reconfigure_limit_batches": [
      "self",
      "limit_batches",
      "dataloader",
      "mode"
    ]
  },
  "get_dataset_root": [
    "name"
  ],
  "create_sft_dataset": [
    "path",
    "tokenizer",
    "seq_length",
    "add_bos",
    "add_eos",
    "seed",
    "index_mapping_dir",
    "truncation_method",
    "memmap_workers",
    "data_type",
    "num_hard_negatives"
  ],
  "BertEmbeddingDataset": {
    "__init__": [
      "self",
      "file_path",
      "tokenizer",
      "max_seq_length",
      "min_seq_length",
      "add_bos",
      "add_eos",
      "max_num_samples",
      "seed",
      "index_mapping_dir",
      "virtual_tokens",
      "memmap_workers",
      "truncation_method",
      "special_tokens",
      "data_type",
      "num_hard_negatives",
      "negative_sample_strategy"
    ],
    "_build_samples_mapping": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_process_example": [
      "self",
      "example"
    ],
    "_maybe_cast_to_list": [
      "self",
      "x"
    ],
    "_ceil_to_nearest": [
      "self",
      "n",
      "m"
    ],
    "_collate_item": [
      "self",
      "item",
      "max_length"
    ],
    "_create_attention_mask2": [
      "self",
      "max_length",
      "item_length"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "FineTuningDataModule": {
    "__init__": [
      "self",
      "dataset_root",
      "seq_length",
      "tokenizer",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "seed",
      "memmap_workers",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "dataset_kwargs"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "_create_dataset": [
      "self",
      "path"
    ],
    "_create_dataloader": [
      "self",
      "dataset",
      "mode"
    ],
    "train_path": [
      "self"
    ],
    "validation_path": [
      "self"
    ],
    "test_path": [
      "self"
    ],
    "_extract_tokenizer_model_name": [
      "self"
    ]
  },
  "SpecterDataModule": {
    "__init__": [
      "self",
      "dataset_root",
      "seq_length",
      "tokenizer",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "force_redownload",
      "delete_raw",
      "seed",
      "memmap_workers",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "dataset_kwargs"
    ],
    "prepare_data": [
      "self"
    ],
    "_download_data": [
      "self"
    ],
    "_preprocess_and_split_data": [
      "self",
      "dset",
      "train_ratio",
      "val_ratio"
    ],
    "reconfigure_limit_batches": [
      "self"
    ]
  },
  "BERTMockDataModule": {
    "__init__": [
      "self",
      "seq_length",
      "tokenizer",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "num_train_samples",
      "num_val_samples",
      "num_test_samples",
      "num_workers",
      "pin_memory",
      "persistent_workers"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "_create_dataloader": [
      "self",
      "dataset"
    ],
    "reconfigure_limit_batches": [
      "self"
    ]
  },
  "_MockBERTDataset": {
    "__init__": [
      "self",
      "tokenizer",
      "name",
      "num_samples",
      "seq_length",
      "seed"
    ],
    "__len__": [
      "self"
    ],
    "_get_text": [
      "self",
      "idx"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "HAVE_TE": [],
  "bert_data_step": [
    "dataloder_iter"
  ],
  "bert_forward_step": [
    "model",
    "batch"
  ],
  "default_layer_spec": [
    "config"
  ],
  "BertConfig": {
    "deallocate_pipeline_outputs": [],
    "configure_model": [
      "self",
      "tokenizer",
      "vp_stage"
    ]
  },
  "MCoreBertModelWrapperWithPostLNSupport": {
    "__init__": [
      "self",
      "bert_type",
      "add_pooler",
      "tokenizer"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "tokentype_ids",
      "lm_labels",
      "loss_mask",
      "inference_params",
      "hidden_states_only"
    ]
  },
  "TransformerLayerSubmodulesWithPostLNSupport": {
    "__init__": [
      "self",
      "post_att_layernorm",
      "post_mlp_layernorm"
    ]
  },
  "TransformerLayerWithPostLNSupport": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "inference_params",
      "packed_seq_params"
    ]
  },
  "TransformerBlockWithPostLNSupport": {
    "__init__": [
      "self",
      "bert_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "inference_params",
      "packed_seq_params"
    ]
  },
  "BertModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "configure_model": [
      "self",
      "vp_stage"
    ],
    "forward": [
      "self"
    ],
    "data_step": [
      "self",
      "dataloader_iter"
    ],
    "forward_step": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "get_packed_seq_params": [
    "batch"
  ],
  "bert_embedding_data_step": [
    "dataloder_iter"
  ],
  "bert_embedding_forward_step": [
    "model",
    "batch"
  ],
  "BertEmbeddingConfig": {},
  "BertEmbeddingLargeConfig": {},
  "BertEmbeddingMiniConfig": {},
  "BertEmbeddingHead": {
    "__init__": [
      "self",
      "word_embedding_dimension",
      "pooling_mode_mean_tokens"
    ],
    "forward": [
      "self",
      "token_embeddings",
      "attention_mask"
    ]
  },
  "BertEmbeddingModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "configure_model": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "BertEmbeddingImporter": {
    "__init__": [
      "self"
    ],
    "init": [
      "self"
    ]
  },
  "get_bert_layer_with_transformer_engine_spec_postln": [],
  "get_bert_layer_local_spec_postln": [],
  "MegatronBertConfig": {},
  "MegatronBertLargeConfig": {},
  "MegatronBertBaseConfig": {},
  "HuggingFaceBertConfig": {},
  "HuggingFaceBertBaseConfig": {},
  "HuggingFaceBertLargeConfig": {},
  "HuggingFaceBertModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HuggingFaceBertImporter": {
    "__init__": [
      "self"
    ],
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HuggingFaceBertExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "tokenizer": [
      "self"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "config": [
      "self"
    ]
  },
  "_import_embedding": [
    "ctx",
    "embedding"
  ],
  "_import_output_bias": [
    "ctx",
    "bias"
  ],
  "_import_qkv_2": [
    "ctx",
    "q",
    "k",
    "v"
  ],
  "_import_qkv_bias_2": [
    "ctx",
    "qb",
    "kb",
    "vb"
  ],
  "_import_embedding_2": [
    "ctx",
    "embedding"
  ],
  "_export_qkv": [
    "ctx",
    "linear_qkv"
  ],
  "_export_qkv_bias": [
    "ctx",
    "qkv_bias"
  ],
  "_set_gpt_mamba_modelopt_spec": [
    "model_cfg"
  ],
  "restore_modelopt_state": [
    "model",
    "path",
    "trainer"
  ],
  "save_modelopt_state": [
    "model",
    "path",
    "checkpoint_io"
  ],
  "ALGORITHMS": [],
  "apply_speculative_decoding": [
    "model",
    "algorithm"
  ],
  "_has_same_speculative_decoding_state": [
    "model",
    "mode"
  ],
  "BaseLoss": {
    "__init__": [
      "self",
      "model_config",
      "projection_layer"
    ],
    "pre_forward": [
      "self",
      "predictions",
      "targets"
    ],
    "post_forward": [
      "self",
      "loss",
      "tp_reduce",
      "is_sequence_parallel"
    ]
  },
  "HiddenStateCosineLoss": {
    "__init__": [
      "self",
      "model_config",
      "projection_layer"
    ],
    "forward": [
      "self",
      "predictions",
      "targets"
    ]
  },
  "LogitsKLLoss": {
    "__init__": [
      "self",
      "model_config",
      "temperature",
      "reverse"
    ],
    "forward": [
      "self",
      "predictions",
      "targets"
    ]
  },
  "LogitsAndIntermediatesLossBalancer": {
    "__init__": [
      "self",
      "kd_loss_scale",
      "skip_original_loss"
    ],
    "forward": [
      "self",
      "loss_dict"
    ]
  },
  "ProjectionLayer": {
    "__init__": [
      "self",
      "student_config",
      "teacher_config"
    ],
    "forward": [
      "self",
      "student_tensor"
    ],
    "_init_weights": [
      "self",
      "module"
    ]
  },
  "_AllReduce": {
    "forward": [
      "ctx",
      "op",
      "group",
      "tensor"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "all_reduce_autograd": [
    "tensor",
    "op",
    "group"
  ],
  "DistillationConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "load_distillation_config": [
    "config_path",
    "student_cfg",
    "teacher_cfg"
  ],
  "_adjust_layer_index_for_pp": [
    "submodule_name",
    "model_cfg"
  ],
  "teacher_provider": [
    "config",
    "ckpt_path",
    "tokenizer",
    "trainer"
  ],
  "adjust_distillation_model_for_mcore": [
    "model",
    "distill_cfg"
  ],
  "get_tensor_shapes_adjust_fn_for_distillation": [
    "model",
    "seq_length",
    "micro_batch_size",
    "decoder_seq_length",
    "forward_only"
  ],
  "_DistillationLossReduction": {
    "__init__": [
      "self",
      "distillation_loss_fn"
    ],
    "forward": [
      "self",
      "batch",
      "forward_out"
    ],
    "_masked_token_loss": [
      "self",
      "loss_output",
      "mask"
    ]
  },
  "DistillationGPTModel": {
    "__init__": [
      "self",
      "config",
      "teacher_config",
      "teacher_ckpt_path",
      "distillation_config_path",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "configure_model": [
      "self"
    ],
    "get_inference_wrapper": [
      "self"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "core_module": [
      "self"
    ],
    "train": [
      "self",
      "mode"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ]
  },
  "prune_recipe": [
    "nemo_checkpoint",
    "save_path"
  ],
  "distillation_recipe": [
    "student_model_path",
    "teacher_model_path",
    "distillation_config_path",
    "dir",
    "name",
    "num_nodes",
    "num_gpus_per_node"
  ],
  "SUPPORTED_PRUNING_HPARAMS": [],
  "PruningConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "prune_language_model": [
    "model",
    "pruning_config",
    "data_module",
    "trainer"
  ],
  "save_pruned_model": [
    "trainer",
    "save_path"
  ],
  "get_quant_cfg_choices": [],
  "standardize_json_config": [
    "quant_cfg"
  ],
  "load_quant_cfg": [
    "cfg_path"
  ],
  "QUANT_CFG_CHOICES": [],
  "SUPPORTED_EXPORT_FMT": [],
  "KV_QUANT_CFG_CHOICES": [],
  "QuantizationConfig": {},
  "ExportConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "export_hf_checkpoint": [
    "model_dir",
    "export_dir",
    "model"
  ],
  "unwrap_for_modelopt_operations": [
    "model"
  ],
  "get_calib_data_iter": [
    "data",
    "batch_size",
    "calib_size",
    "max_sequence_length"
  ],
  "create_data_iterator_getter": [
    "model",
    "dataset",
    "seq_len",
    "batch_size",
    "calibration_size"
  ],
  "gpt_model_type": [],
  "get_modelopt_decoder_type": [
    "model"
  ],
  "PreTrainingDataModule": {
    "__init__": [
      "self",
      "paths",
      "seq_length",
      "seq_length_dec",
      "tokenizer",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "masking_probability",
      "short_sequence_probability",
      "masking_max_ngram",
      "masking_do_full_word",
      "masking_do_permutation",
      "masking_use_longer_ngrams",
      "masking_use_geometric_distribution",
      "seed",
      "split",
      "index_mapping_dir"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "_create_dataloader": [
      "self",
      "dataset",
      "mode"
    ],
    "t5_dataset_config": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "reconfigure_limit_batches": [
      "self"
    ],
    "_reconfigure_limit_batches": [
      "self",
      "limit_batches",
      "dataloader",
      "mode"
    ]
  },
  "T5SFTDataset": {
    "__init__": [
      "self",
      "file_path",
      "src_tokenizer",
      "tgt_tokenizer",
      "max_src_seq_length",
      "max_tgt_seq_length",
      "add_bos_to_input",
      "add_eos_to_input",
      "replace_bos_with_pad",
      "index_mapping_dir",
      "memmap_workers",
      "hf_dataset"
    ],
    "_process_src": [
      "self",
      "src"
    ],
    "_process_tgt": [
      "self",
      "tgt"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "SquadDataModule": {
    "__init__": [
      "self",
      "dataset_root",
      "seq_length",
      "seq_length_dec",
      "tokenizer",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "force_redownload",
      "delete_raw",
      "seed",
      "memmap_workers",
      "num_workers",
      "pin_memory",
      "persistent_workers"
    ],
    "prepare_data": [
      "self"
    ],
    "_download_data": [
      "self"
    ],
    "_preprocess_and_split_data": [
      "self",
      "dset",
      "split_val_from_train",
      "val_proportion"
    ],
    "reconfigure_limit_batches": [
      "self"
    ]
  },
  "_MockT5Dataset": {
    "__init__": [
      "self",
      "tokenizer",
      "name",
      "num_samples",
      "seq_length",
      "seq_length_dec",
      "seed",
      "create_attention_mask"
    ],
    "__len__": [
      "self"
    ],
    "_get_text": [
      "self",
      "idx"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "t5_data_step": [
    "dataloader_iter"
  ],
  "t5_forward_step": [
    "model",
    "batch"
  ],
  "transformer_engine_layer_spec": [
    "encoder_config",
    "decoder_config"
  ],
  "local_layer_spec": [
    "encoder_config",
    "decoder_config"
  ],
  "T5Config220M": {},
  "T5Config3B": {},
  "T5Config11B": {},
  "T5Model": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "configure_model": [
      "self"
    ],
    "forward": [
      "self",
      "encoder_input_ids",
      "decoder_input_ids",
      "encoder_attn_mask",
      "decoder_attn_mask",
      "encoder_decoder_attn_mask",
      "lm_labels",
      "inference_params"
    ],
    "data_step": [
      "self",
      "dataloader_iter"
    ],
    "forward_step": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "get_inference_wrapper": [
      "self",
      "params_dtype",
      "inference_batch_times_seqlen_threshold"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "HFT5Importer": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "_import_encoder_qkv": [
    "ctx",
    "q",
    "k",
    "v"
  ],
  "_import_decoder_qkv": [
    "ctx",
    "q",
    "k",
    "v"
  ],
  "_import_decoder_kv": [
    "ctx",
    "k",
    "v"
  ],
  "_import_encoder_linear_fc1": [
    "down",
    "gate"
  ],
  "_import_decoder_linear_fc1": [
    "down",
    "gate"
  ],
  "HFT5Exporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "_export_encoder_qkv": [
    "ctx",
    "linear_qkv"
  ],
  "_export_decoder_qkv": [
    "ctx",
    "linear_qkv"
  ],
  "_export_decoder_kv": [
    "ctx",
    "linear_kv"
  ],
  "_export_encoder_linear_fc1": [
    "linear_fc1"
  ],
  "_export_decoder_linear_fc1": [
    "linear_fc1"
  ],
  "create_reranker_dataset": [
    "path",
    "tokenizer",
    "seq_length",
    "add_bos",
    "add_eos",
    "seed",
    "index_mapping_dir",
    "truncation_method",
    "memmap_workers",
    "data_type",
    "num_hard_negatives",
    "negative_sample_strategy",
    "question_key",
    "pos_key",
    "neg_key"
  ],
  "ReRankerDataset": {
    "__init__": [
      "self",
      "file_path",
      "tokenizer",
      "max_seq_length",
      "min_seq_length",
      "add_bos",
      "add_eos",
      "max_num_samples",
      "seed",
      "index_mapping_dir",
      "virtual_tokens",
      "memmap_workers",
      "truncation_method",
      "special_tokens",
      "data_type",
      "num_hard_negatives",
      "negative_sample_strategy",
      "question_key",
      "pos_key",
      "neg_key"
    ],
    "_build_samples_mapping": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_process_example": [
      "self",
      "example"
    ],
    "_maybe_cast_to_list": [
      "self",
      "x"
    ],
    "_ceil_to_nearest": [
      "self",
      "n",
      "m"
    ],
    "_collate_item": [
      "self",
      "item",
      "max_length"
    ],
    "_create_attention_mask2": [
      "self",
      "max_length",
      "item_length"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "CustomReRankerDataModule": {
    "__init__": [
      "self",
      "data_root",
      "val_root",
      "test_root",
      "val_ratio",
      "test_ratio",
      "dataset_identifier",
      "seq_length",
      "tokenizer",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "force_redownload",
      "delete_raw",
      "seed",
      "memmap_workers",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "packed_sequence_specs",
      "query_key",
      "pos_doc_key",
      "neg_doc_key",
      "dataset_kwargs"
    ],
    "_create_dataset": [
      "self",
      "path"
    ]
  },
  "SpecterReRankerDataModule": {
    "__init__": [
      "self",
      "dataset_root",
      "seq_length",
      "tokenizer",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "force_redownload",
      "delete_raw",
      "seed",
      "memmap_workers",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "dataset_kwargs"
    ],
    "prepare_data": [
      "self"
    ],
    "_download_data": [
      "self"
    ],
    "_preprocess_and_split_data": [
      "self",
      "dset",
      "train_ratio",
      "val_ratio"
    ],
    "reconfigure_limit_batches": [
      "self"
    ],
    "_create_dataset": [
      "self",
      "path"
    ]
  },
  "is_number_tryexcept": [
    "s"
  ],
  "is_zipped_list": [
    "paths"
  ],
  "validate_dataset_asset_accessibility": [
    "paths"
  ],
  "build_pretraining_datamodule": [
    "datamodule",
    "trainer_max_steps",
    "trainer_val_check_interval",
    "trainer_limit_val_batches",
    "trainer_limit_test_batches"
  ],
  "MLPerfGovReportDataModule": {
    "__init__": [
      "self",
      "seq_length",
      "tokenizer",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "force_redownload",
      "delete_raw",
      "seed",
      "memmap_workers",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "packed_sequence_specs",
      "dataset_kwargs"
    ],
    "prepare_data": [
      "self"
    ],
    "_download_data": [
      "self"
    ],
    "_preprocess_and_split_data": [
      "self",
      "dset",
      "split_val_from_train",
      "val_proportion"
    ],
    "train_path": [
      "self"
    ],
    "validation_path": [
      "self"
    ],
    "test_path": [
      "self"
    ],
    "default_pack_path": [
      "self"
    ],
    "pack_metadata": [
      "self"
    ],
    "train_path_packed": [
      "self"
    ],
    "validation_path_packed": [
      "self"
    ]
  },
  "PREFIX_STR": [],
  "__idx_version__": [],
  "__idx_suffix__": [],
  "GPTSFTDataset": {
    "__init__": [
      "self",
      "file_path",
      "tokenizer",
      "max_seq_length",
      "min_seq_length",
      "pad_seq_length_to_mult",
      "add_bos",
      "add_eos",
      "add_sep",
      "sep_id",
      "max_num_samples",
      "seed",
      "label_key",
      "answer_only_loss",
      "truncation_field",
      "pad_to_max_length",
      "index_mapping_dir",
      "prompt_template",
      "virtual_tokens",
      "tokens_to_generate",
      "memmap_workers",
      "hf_dataset",
      "global_sample_mapping",
      "truncation_method",
      "special_tokens",
      "is_test",
      "output_original_text",
      "ceil_to_power_2",
      "get_attention_mask_from_fusion",
      "sanity_check_dist_workers"
    ],
    "_load_dataset": [
      "self"
    ],
    "_maybe_validate_prompt_template": [
      "self"
    ],
    "_build_samples_mapping": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_separate_template": [
      "self",
      "prompt_template_values"
    ],
    "_multiple_truncation": [
      "self",
      "template_ids",
      "template_ids_keys"
    ],
    "_truncation": [
      "self",
      "ids",
      "expect_length"
    ],
    "_process_example": [
      "self",
      "example"
    ],
    "_maybe_cast_to_list": [
      "self",
      "x"
    ],
    "_ceil_to_nearest": [
      "self",
      "n",
      "m"
    ],
    "_collate_item": [
      "self",
      "item",
      "max_length",
      "pad_id"
    ],
    "_build_loss_mask": [
      "self",
      "processed_example"
    ],
    "_create_attention_mask": [
      "self",
      "max_length"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "GPTSFTPackedDataset": {
    "__init__": [
      "self",
      "file_path",
      "tokenizer",
      "return_cu_seqlen",
      "pad_cu_seqlens",
      "pack_metadata_file_path"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_load_dataset": [
      "self"
    ],
    "_build_samples_mapping": [
      "self"
    ],
    "_build_loss_mask": [
      "self",
      "processed_example"
    ],
    "_maybe_cast_to_list": [
      "self",
      "x"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "GPTSFTChatDataset": {
    "__init__": [
      "self",
      "file_path",
      "tokenizer",
      "max_seq_length",
      "min_seq_length",
      "pad_seq_length_to_mult",
      "add_bos",
      "add_eos",
      "add_sep",
      "sep_id",
      "max_num_samples",
      "seed",
      "label_key",
      "answer_only_loss",
      "truncation_field",
      "pad_to_max_length",
      "index_mapping_dir",
      "prompt_template",
      "virtual_tokens",
      "tokens_to_generate",
      "memmap_workers",
      "hf_dataset",
      "global_sample_mapping",
      "truncation_method",
      "special_tokens",
      "is_test",
      "output_original_text",
      "ceil_to_power_2",
      "get_attention_mask_from_fusion",
      "sanity_check_dist_workers",
      "use_hf_tokenizer_chat_template",
      "tool_schemas"
    ],
    "_maybe_validate_prompt_template": [
      "self"
    ],
    "_build_samples_mapping": [
      "self"
    ],
    "_process_example": [
      "self",
      "example"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "AlpacaDataModule": {
    "__init__": [
      "self",
      "seq_length",
      "tokenizer",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "force_redownload",
      "delete_raw",
      "seed",
      "memmap_workers",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "packed_sequence_specs",
      "dataset_kwargs"
    ],
    "prepare_data": [
      "self"
    ],
    "_download_data": [
      "self"
    ],
    "_preprocess_and_split_data": [
      "self",
      "dset",
      "train_ratio",
      "val_ratio"
    ]
  },
  "DollyDataModule": {
    "__init__": [
      "self",
      "seq_length",
      "tokenizer",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "force_redownload",
      "delete_raw",
      "seed",
      "memmap_workers",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "packed_sequence_specs",
      "dataset_kwargs"
    ],
    "prepare_data": [
      "self"
    ],
    "_download_data": [
      "self"
    ],
    "_preprocess_and_split_data": [
      "self",
      "dset",
      "train_ratio",
      "val_ratio"
    ]
  },
  "SYSTEM_TOKEN": [],
  "TYPE_INSTRUCTION": [],
  "GENERATION_REGEX": [],
  "build_index_from_memdata": [
    "fn",
    "newline_int"
  ],
  "safe_map": [
    "fn",
    "iterable",
    "workers",
    "ctx"
  ],
  "_TextMemMapDataset": {
    "__init__": [
      "self",
      "dataset_paths",
      "newline_int",
      "header_lines",
      "workers",
      "tokenizer",
      "build_index_fn",
      "sort_dataset_paths",
      "index_mapping_dir"
    ],
    "__del__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_fetch_sample_from_memmap": [
      "self",
      "mdata",
      "i",
      "j"
    ],
    "_build_data_from_text": [
      "self",
      "text"
    ],
    "load_file": [
      "self",
      "fn",
      "index_mapping_dir"
    ]
  },
  "_JSONLMemMapDataset": {
    "__init__": [
      "self",
      "dataset_paths",
      "newline_int",
      "header_lines",
      "workers",
      "tokenizer",
      "sort_dataset_paths",
      "index_mapping_dir"
    ],
    "_build_data_from_text": [
      "self",
      "text"
    ]
  },
  "_OnlineSampleMapping": {
    "__init__": [
      "self",
      "dataset_size",
      "num_samples",
      "block_size",
      "cache_maxsize",
      "seed",
      "shuffle",
      "truncate_to_block_boundary"
    ],
    "__str__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "__reduce__": [
      "self"
    ],
    "__reduce_ex__": [
      "self",
      "protocol"
    ],
    "get_sample_block": [
      "self",
      "block_idx"
    ]
  },
  "build_index_files": [
    "dataset_paths",
    "newline_int",
    "workers",
    "build_index_fn",
    "index_mapping_dir"
  ],
  "handle_index": [
    "dataset",
    "idx"
  ],
  "lightning_prepare_data": [],
  "_get_samples_mapping": [
    "indexed_dataset",
    "data_prefix",
    "num_epochs",
    "max_num_samples",
    "max_seq_length",
    "short_seq_prob",
    "seed",
    "name",
    "binary_head",
    "index_mapping_dir",
    "samples_mapping",
    "sanity_check_dist_workers"
  ],
  "_make_indexed_dataset_compatibility": [
    "dataset"
  ],
  "_preprocess": [
    "source",
    "tokenizer",
    "name_end_token_ids",
    "label_start_ids",
    "special_tokens",
    "num_turn_start_tokens"
  ],
  "_convert_to_openai_messages": [
    "source"
  ],
  "_chat_preprocess": [
    "source",
    "tokenizer",
    "tool_schemas"
  ],
  "_mask_targets": [
    "target",
    "tokenized_lens",
    "speakers",
    "header_len",
    "s_ids",
    "tokenizer",
    "mask_role",
    "gtype",
    "name_end_token_ids",
    "special_tokens",
    "label_start_ids",
    "num_turn_start_tokens"
  ],
  "_get_header_conversation_type_mask_role": [
    "source",
    "special_tokens"
  ],
  "_add_speaker_and_signal": [
    "header",
    "source",
    "mask_role",
    "gtype",
    "special_tokens"
  ],
  "_response_value_formater": [
    "label",
    "label_start",
    "end_signal"
  ],
  "_identify_start_index_of_subsequence": [
    "subsequence",
    "sequence"
  ],
  "_build_memmap_index_files": [
    "newline_int",
    "build_index_fn",
    "fn",
    "index_mapping_dir"
  ],
  "_index_fn": [
    "fn",
    "index_mapping_dir"
  ],
  "_index_file_exists": [
    "idx_fn"
  ],
  "_deallocate_indexed_dataset_memory": [
    "indexed_dataset"
  ],
  "_reconfigure_limit_batches": [
    "limit_batches",
    "dataloader"
  ],
  "mock": [],
  "dolly": [],
  "hf_dataset": [
    "path"
  ],
  "CustomRetrievalDataModule": {
    "__init__": [
      "self",
      "data_root",
      "val_root",
      "test_root",
      "val_ratio",
      "test_ratio",
      "dataset_identifier",
      "seq_length",
      "tokenizer",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "force_redownload",
      "delete_raw",
      "seed",
      "memmap_workers",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "packed_sequence_specs",
      "query_key",
      "pos_doc_key",
      "neg_doc_key",
      "dataset_kwargs"
    ],
    "prepare_data": [
      "self"
    ],
    "_preprocess_and_split_data": [
      "self"
    ]
  },
  "HFDatasetDataModulePacked": {
    "__init__": [
      "self",
      "path_or_dataset",
      "packed_sequence_size",
      "split_across_pack",
      "max_packs"
    ],
    "collate_fn": [
      "self",
      "batch",
      "pad_token_id",
      "pad_seq_len_divisible"
    ],
    "_make_dataloader": [
      "self",
      "dataset",
      "split",
      "collate_fn"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ]
  },
  "HellaSwagHFDataModule": {
    "__init__": [
      "self",
      "tokenizer",
      "dataset_name"
    ],
    "preprocess": [
      "text"
    ],
    "process_doc": [
      "doc"
    ],
    "preprocess_dataset": [
      "tokenizer",
      "max_length",
      "dataset",
      "seed"
    ]
  },
  "SquadHFDataModule": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "formatting_prompts_func": [
      "self",
      "example"
    ],
    "setup": [
      "self",
      "stage"
    ]
  },
  "HFMockDataModule": {
    "__init__": [
      "self",
      "seq_length",
      "vocab_size",
      "micro_batch_size",
      "rampup_batch_size",
      "num_train_samples",
      "num_val_samples",
      "num_test_samples",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "create_attention_mask",
      "vocab_file",
      "merges_file",
      "pad_seq_len_divisible"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "_create_dataloader": [
      "self",
      "dataset"
    ],
    "collate_fn": [
      "batch",
      "pad_token_id",
      "pad_seq_len_divisible"
    ]
  },
  "_MockGPTDataset": {
    "__init__": [
      "self",
      "vocab_size",
      "name",
      "num_samples",
      "seq_length",
      "create_attention_mask",
      "seed"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "tokenize_dataset": [
    "path",
    "tokenizer",
    "max_seq_length",
    "seed",
    "dataset_kwargs"
  ],
  "prepare_packed_sequence_data": [
    "input_path",
    "output_path",
    "output_metadata_path",
    "packed_sequence_size",
    "tokenizer",
    "max_seq_length",
    "seed",
    "packing_algorithm",
    "dataset_kwargs"
  ],
  "PackedSequenceSpecs": {
    "__post_init__": [
      "self"
    ]
  },
  "CROSS_ENTROPY_IGNORE_IDX": [],
  "PACK_TYPE": [],
  "HFDatasetPackedSequenceHelper": {
    "__init__": [
      "self",
      "dataset",
      "split"
    ],
    "pack": [
      "self",
      "packed_sequence_size",
      "split_across_pack",
      "max_packs"
    ],
    "_should_stop_packing": [
      "self"
    ],
    "_split_and_add_pack": [
      "self",
      "current_pack"
    ],
    "_add_pack": [
      "self",
      "pack"
    ],
    "_convert_to_tensors": [
      "self",
      "pack"
    ],
    "_pad_pack": [
      "self",
      "pack",
      "padding_idx"
    ]
  },
  "create_block_causal_mask": [
    "seq_lens"
  ],
  "packed_block_causal_mask": [
    "seq_lens"
  ],
  "ChatDataModule": {
    "__init__": [
      "self",
      "dataset_root",
      "seq_length",
      "tokenizer",
      "micro_batch_size",
      "global_batch_size",
      "rampup_batch_size",
      "seed",
      "memmap_workers",
      "num_workers",
      "pin_memory",
      "persistent_workers",
      "packed_sequence_specs",
      "dataset_kwargs",
      "use_hf_tokenizer_chat_template"
    ],
    "_create_dataset": [
      "self",
      "path",
      "pack_metadata_path",
      "is_test"
    ]
  },
  "infer_global_batch_size": [
    "micro_batch_size",
    "num_nodes",
    "devices",
    "accumulate_grad_batches",
    "tensor_model_parallel_size",
    "pipeline_model_parallel_size",
    "context_model_parallel_size"
  ],
  "Evo2BlendedDatasetConfig": {
    "validate_dataset_prefix": [
      "cls",
      "values"
    ]
  },
  "parse_dataset_config": [
    "dataset_config_path",
    "dataset_path"
  ],
  "Evo2Dataset": {
    "TAG_BOUNDS": [],
    "DEFAULT_EOD": [],
    "MAX_TAG_LEN": [],
    "_get_gpt_batch": [
      "self",
      "idx"
    ],
    "_modify_gpt_batch": [
      "self",
      "databatch"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "mask_phylogenetic_tags": [
      "tokenized_sequence",
      "terminal_tag_char",
      "other_tag_chars",
      "eod_token_id",
      "max_tag_len"
    ]
  },
  "Evo2DatasetPadEodLossMask": {},
  "Qwen2Config": {},
  "Qwen2Config500M": {},
  "Qwen25Config500M": {},
  "Qwen2Config1P5B": {},
  "Qwen25Config3B": {},
  "Qwen25Config1P5B": {},
  "Qwen2Config7B": {},
  "Qwen25Config7B": {},
  "Qwen25Config14B": {},
  "Qwen25Config32B": {},
  "Qwen2Config72B": {},
  "Qwen25Config72B": {},
  "Qwen2Model": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFQwen2Importer": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFQwen2Exporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "MistralConfig7B": {},
  "MistralNeMoConfig12B": {},
  "MistralNeMoConfig123B": {},
  "MistralSmall3Config24B": {},
  "MistralModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFMistralImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFMistralExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "reranker_data_step": [
    "dataloder_iter"
  ],
  "reranker_forward_step": [
    "model",
    "batch"
  ],
  "ReRankerBaseConfig": {},
  "Llama32Reranker1BConfig": {
    "configure_model": [
      "self",
      "tokenizer",
      "pre_process",
      "post_process",
      "vp_stage"
    ]
  },
  "Llama32Reranker500MConfig": {},
  "ReRankerModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "dataset_kwargs": [
      "self"
    ],
    "configure_model": [
      "self",
      "vp_stage"
    ],
    "pool": [
      "self",
      "last_hidden_states",
      "attention_mask"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "decoder_input"
    ],
    "score": [
      "self"
    ],
    "has_float16_module_wrapper": [
      "self"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "ReRankerImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "config": [
      "self"
    ],
    "tokenizer": [
      "self"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ]
  },
  "ReRankerExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "config": [
      "self"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ]
  },
  "ReRankerLoss": {
    "__init__": [
      "self",
      "validation_step",
      "val_drop_last",
      "num_hard_negatives",
      "label_smoothing"
    ],
    "forward": [
      "self",
      "batch",
      "forward_out"
    ],
    "reduce": [
      "self",
      "losses_reduced_per_micro_batch"
    ]
  },
  "NemotronConfig": {},
  "Nemotron3Config4B": {},
  "Nemotron3Config8B": {},
  "Nemotron3Config22B": {},
  "Nemotron4Config15B": {},
  "Nemotron4Config340B": {},
  "NemotronModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFNemotronImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFNemotronExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "GemmaConfig": {},
  "GemmaConfig2B": {},
  "GemmaConfig7B": {},
  "CodeGemmaConfig2B": {},
  "CodeGemmaConfig7B": {},
  "GemmaModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "configure_model": [
      "self",
      "vp_stage"
    ]
  },
  "HFGemmaImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFGemmaExporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "pool": [
    "last_hidden_states",
    "attention_mask",
    "pool_type"
  ],
  "LlamaBidirectionalConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "pooling",
      "temperature"
    ]
  },
  "LlamaBidirectionalModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "_update_causal_mask": [
      "self",
      "attention_mask",
      "input_tensor",
      "cache_position",
      "past_key_values",
      "output_attentions"
    ]
  },
  "LlamaBidirectionalForSequenceClassification": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "LlamaBidirectionalHFAdapter": {
    "__init__": [
      "self",
      "model",
      "normalize",
      "pooling_module"
    ],
    "device": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "dimensions"
    ]
  },
  "Pooling": {
    "__init__": [
      "self",
      "pooling_mode"
    ],
    "forward": [
      "self",
      "last_hidden_states",
      "attention_mask"
    ]
  },
  "get_llama_bidirectional_hf_model": [
    "model_name_or_path",
    "normalize",
    "pooling_mode",
    "torch_dtype",
    "trust_remote_code"
  ],
  "_grad_accum_fusion_available": [],
  "gpt_data_step": [
    "dataloader_iter",
    "use_mtp"
  ],
  "gpt_forward_step": [
    "model",
    "batch"
  ],
  "transformer_engine_full_layer_spec": [
    "config",
    "vp_stage"
  ],
  "mtp_block_spec": [
    "config",
    "vp_stage"
  ],
  "torch_dtype_from_mcore_config": [
    "config"
  ],
  "torch_dtype_from_dict_config": [
    "config"
  ],
  "GPTConfig": {
    "configure_model": [
      "self",
      "tokenizer",
      "pre_process",
      "post_process",
      "vp_stage"
    ]
  },
  "GPTConfig126M": {},
  "GPTConfig5B": {},
  "GPTConfig7B": {},
  "GPTConfig20B": {},
  "GPTConfig40B": {},
  "GPTConfig175B": {},
  "GPTModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform",
      "model_context_managers"
    ],
    "configure_model": [
      "self",
      "vp_stage"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "labels",
      "decoder_input",
      "inference_context",
      "packed_seq_params"
    ],
    "data_step": [
      "self",
      "dataloader_iter"
    ],
    "forward_step": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "get_inference_wrapper": [
      "self",
      "params_dtype",
      "inference_batch_times_seqlen_threshold",
      "inference_max_seq_length"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "Baichuan2Config": {},
  "Baichuan2Config7B": {},
  "Baichuan2Model": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFBaichuan2Importer": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFBaichuan2Exporter": {
    "init": [
      "self",
      "dtype",
      "model_name"
    ],
    "apply": [
      "self",
      "output_path",
      "target_model_name",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ]
  },
  "Phi3Config": {},
  "Phi3ConfigMini": {},
  "Phi3Model": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFPhi3Importer": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFPhi3Exporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "DeepSeekConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "DeepSeekV2Config": {},
  "DeepSeekV2LiteConfig": {},
  "DeepSeekV3Config": {},
  "DeepSeekModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFDeepSeekImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path",
      "convert_mtp",
      "trust_remote_code"
    ],
    "_verify_source": [
      "self"
    ],
    "_modify_source_state": [
      "self",
      "source"
    ],
    "_add_mtp_to_source": [
      "self",
      "source"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFDeepSeekExporter": {
    "init": [
      "self",
      "dtype",
      "model_name"
    ],
    "_detect_hf_deepseek_version": [
      "self",
      "source_config"
    ],
    "ckpt_load": [
      "self",
      "path"
    ],
    "apply": [
      "self",
      "output_path",
      "target_model_name",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target",
      "source_config"
    ],
    "_modify_source_state": [
      "self",
      "source",
      "source_config"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "ssm_forward_step": [
    "model",
    "batch"
  ],
  "dist_ckpt_handler": [
    "checkpoint_dir"
  ],
  "SSMConfig": {
    "configure_model": [
      "self",
      "tokenizer",
      "pre_process",
      "post_process",
      "vp_stage"
    ]
  },
  "MambaModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "get_inference_wrapper": [
      "self",
      "params_dtype",
      "inference_batch_times_seqlen_threshold",
      "inference_max_seq_length"
    ]
  },
  "PyTorchSSMImporter": {
    "__new__": [
      "cls",
      "path",
      "model_config"
    ],
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path",
      "source_dist_ckpt",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFNemotronHImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFNemotronHExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "_export_head": [
    "ctx",
    "embedding"
  ],
  "BaseMambaConfig130M": {},
  "BaseMambaConfig370M": {},
  "BaseMambaConfig780M": {},
  "BaseMambaConfig1_3B": {},
  "BaseMambaConfig2_7B": {},
  "NVIDIAMambaConfig8B": {},
  "NVIDIAMambaHybridConfig8B": {},
  "NemotronHConfigBase": {},
  "NemotronHConfig4B": {},
  "NemotronHConfig8B": {},
  "NemotronHConfig47B": {},
  "NemotronHConfig56B": {},
  "NemotronNano9Bv2": {},
  "NemotronNano12Bv2": {},
  "MixtralConfig": {},
  "MixtralConfig8x3B": {},
  "MixtralConfig8x7B": {},
  "MixtralConfig8x22B": {},
  "MixtralModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFMixtralImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "_import_lm_head": [
    "ctx",
    "embedding"
  ],
  "HFMixtralExporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "gemma2_layer_spec": [
    "config"
  ],
  "Gemma2Config": {},
  "Gemma2Config2B": {},
  "Gemma2Config9B": {},
  "Gemma2Config27B": {},
  "Gemma2Model": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "configure_model": [
      "self"
    ]
  },
  "Gemma2DotProductAttention": {
    "__init__": [
      "self",
      "config",
      "layer_number",
      "attn_mask_type",
      "attention_type",
      "attention_dropout"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attention_mask",
      "attn_mask_type",
      "packed_seq_params"
    ]
  },
  "TERowParallelLinearLayerNorm": {
    "__init__": [
      "self",
      "input_size",
      "output_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Gemma2OutputLayer": {
    "forward": [
      "self"
    ]
  },
  "EmbeddingScalingMixin": {
    "forward": [
      "self"
    ]
  },
  "logit_softcapping": [
    "logits",
    "scale"
  ],
  "get_swa": [
    "seq_q",
    "seq_kv",
    "w"
  ],
  "gemma3_layer_spec": [
    "config"
  ],
  "Gemma3Config": {
    "configure_model": [
      "self",
      "tokenizer",
      "pre_process",
      "post_process",
      "vp_stage"
    ]
  },
  "Gemma3Config1B": {},
  "Gemma3Config4B": {},
  "Gemma3Config12B": {},
  "Gemma3Config27B": {},
  "Gemma3Model": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform",
      "model_context_managers"
    ]
  },
  "Gemma3LanguageModelEmbedding": {
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "tokentype_ids"
    ]
  },
  "Gemma3RotaryEmbedding": {
    "__init__": [
      "self",
      "rope_scaling",
      "rope_scaling_factor",
      "rotary_base",
      "rotary_base_local"
    ],
    "forward": [
      "self",
      "max_seq_len",
      "offset",
      "packed_seq"
    ]
  },
  "_is_local_attn_layer": [
    "layer_number",
    "layer_pattern"
  ],
  "Gemma3SelfAttention": {
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "key_value_states",
      "inference_context",
      "rotary_pos_emb",
      "rotary_pos_cos",
      "rotary_pos_sin",
      "attention_bias",
      "packed_seq_params",
      "sequence_len_offset"
    ]
  },
  "Gemma3TEDotProductAttention": {
    "__init__": [
      "self",
      "config",
      "layer_number",
      "attn_mask_type",
      "attention_type",
      "attention_dropout"
    ]
  },
  "HFGemma3Importer": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFGemma3Exporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "StarcoderConfig": {},
  "StarcoderConfig15B": {},
  "StarcoderModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFStarcoderImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFStarcoderExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "LlamaConfig": {},
  "Llama2Config7B": {},
  "Llama2Config13B": {},
  "Llama2Config70B": {},
  "Llama3Config": {},
  "Llama31Config": {
    "configure_model": [
      "self",
      "tokenizer",
      "pre_process",
      "post_process",
      "vp_stage"
    ]
  },
  "Llama3Config8B": {},
  "Llama3Config70B": {},
  "Llama31Config8B": {},
  "Llama31Config70B": {},
  "Llama31Config405B": {},
  "Llama32Config1B": {},
  "Llama32Config3B": {},
  "CodeLlamaConfig7B": {},
  "CodeLlamaConfig13B": {},
  "CodeLlamaConfig34B": {},
  "CodeLlamaConfig70B": {},
  "Llama4Config": {},
  "Llama4Experts16Config": {},
  "Llama4Experts128Config": {},
  "LlamaModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform",
      "model_context_managers"
    ]
  },
  "MLPerfLoRALlamaModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFLlamaImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "_modify_llama4_source_state": [
      "self",
      "source"
    ],
    "config": [
      "self"
    ]
  },
  "HFLlamaExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target",
      "source_config"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ],
    "is_llama4": [
      "self"
    ],
    "create_llama4_config": [
      "self",
      "source"
    ],
    "ckpt_load": [
      "self",
      "path"
    ],
    "_modify_llama4_source_state": [
      "self",
      "state_dict",
      "source_config"
    ]
  },
  "HFLlamaPEFTExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "peft_config": [
      "self"
    ]
  },
  "split_moe": [
    "ctx",
    "tensor"
  ],
  "LLAMA_33_NEMOTRON_SUPER_49B_HETEROGENEOUS_CONFIG": [],
  "LLAMA_31_NEMOTRON_ULTRA_253B_HETEROGENEOUS_CONFIG": [],
  "HyenaInferenceContext": {
    "reset": [
      "self"
    ]
  },
  "HyenaModel": {
    "get_inference_wrapper": [
      "self",
      "params_dtype",
      "inference_batch_times_seqlen_threshold",
      "inference_max_seq_length"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "labels",
      "decoder_input",
      "loss_mask",
      "inference_context",
      "packed_seq_params"
    ]
  },
  "hyena_forward_step": [
    "model",
    "batch"
  ],
  "HyenaConfig": {
    "__post_init__": [
      "self"
    ],
    "configure_model": [
      "self",
      "tokenizer",
      "vp_stage"
    ]
  },
  "HyenaTestConfig": {},
  "HyenaNVTestConfig": {},
  "Hyena1bConfig": {},
  "HyenaNV1bConfig": {},
  "Hyena7bConfig": {},
  "HyenaNV7bConfig": {},
  "Hyena40bConfig": {},
  "HyenaNV40bConfig": {},
  "Hyena7bARCLongContextConfig": {},
  "Hyena40bARCLongContextConfig": {},
  "PyTorchHyenaImporter": {
    "__new__": [
      "cls",
      "path",
      "model_config"
    ],
    "init": [
      "self"
    ],
    "get_source_model": [
      "self"
    ],
    "apply": [
      "self",
      "output_path",
      "checkpoint_format"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HuggingFaceSavannaHyenaImporter": {
    "get_source_model": [
      "self"
    ]
  },
  "Llama31NemotronNano8BConfig": {},
  "Llama31Nemotron70BConfig": {},
  "heterogeneous_layer_spec": [
    "config"
  ],
  "Llama33NemotronSuper49BConfig": {},
  "Llama31NemotronUltra253BConfig": {},
  "LlamaNemotronModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFLlamaNemotronImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFLlamaNemotronExporter": {
    "init": [
      "self",
      "dtype",
      "from_config",
      "model_name"
    ],
    "apply": [
      "self",
      "output_path",
      "target_model_name",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFLlamaNemotronPEFTExporter": {
    "init": [
      "self",
      "dtype",
      "from_config",
      "model_name"
    ],
    "apply": [
      "self",
      "output_path",
      "target_model_name"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "peft_config": [
      "self"
    ]
  },
  "Qwen3Config": {},
  "Qwen3MoEConfig": {},
  "Qwen3Config600M": {},
  "Qwen3Config1P7B": {},
  "Qwen3Config4B": {},
  "Qwen3Config8B": {},
  "Qwen3Config14B": {},
  "Qwen3Config32B": {},
  "Qwen3Config30B_A3B": {},
  "Qwen3Config235B_A22B": {},
  "Qwen3Model": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFQwen3Importer": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFQwen3Exporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "_local_layer_spec": [
    "config"
  ],
  "_transformer_engine_layer_spec": [
    "config"
  ],
  "get_nv_embedding_layer_spec": [
    "config"
  ],
  "nv_embedding_data_step": [
    "dataloder_iter"
  ],
  "nv_embedding_forward_step": [
    "model",
    "batch"
  ],
  "Llama32EmbeddingConfig1B": {
    "configure_model": [
      "self",
      "tokenizer",
      "pre_process",
      "post_process",
      "vp_stage"
    ]
  },
  "Llama32EmbeddingConfig3B": {
    "configure_model": [
      "self",
      "tokenizer",
      "pre_process",
      "post_process",
      "vp_stage"
    ]
  },
  "_average_pool": [
    "last_hidden_states",
    "attention_mask"
  ],
  "LlamaEmbeddingModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ],
    "dataset_kwargs": [
      "self"
    ],
    "encode": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "decoder_input"
    ],
    "training_loss_reduction": [
      "self"
    ],
    "validation_loss_reduction": [
      "self"
    ]
  },
  "LlamaEmbeddingImporter": {
    "init": [
      "self"
    ],
    "config": [
      "self"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ]
  },
  "LlamaEmbeddingExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "config": [
      "self"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ]
  },
  "GPTOSSConfig": {},
  "GPTOSSConfig120B": {},
  "GPTOSSConfig20B": {},
  "GPTOSSModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "_BaseGPTOSSImporter": {
    "init": [
      "self"
    ],
    "hf_ckpt_load": [
      "self"
    ],
    "_dequantize_mxfp4": [
      "self",
      "blocks",
      "scales"
    ]
  },
  "HFGPTOSSImporter": {
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "OpenAIGPTOSSImporter": {
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "_interleave": [
    "elem"
  ],
  "_uninterleave": [
    "elem"
  ],
  "HFGPTOSSExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFGPTOSSPEFTExporter": {
    "init": [
      "self",
      "dtype"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "peft_config": [
      "self"
    ]
  },
  "ChatGLMConfig": {},
  "ChatGLM2Config6B": {},
  "ChatGLM3Config6B": {},
  "ChatGLMModel": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFChatGLMImporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFChatGLMExporter": {
    "init": [
      "self",
      "dtype",
      "model_name"
    ],
    "apply": [
      "self",
      "output_path",
      "target_model_name",
      "trust_remote_code"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ]
  },
  "_import_qkv_weight": [
    "ctx",
    "hf_qkv_weights"
  ],
  "_export_qkv_weight": [
    "ctx",
    "qkv_weights"
  ],
  "Starcoder2Config": {},
  "Starcoder2Config3B": {},
  "Starcoder2Config7B": {},
  "Starcoder2Config15B": {},
  "Starcoder2Model": {
    "__init__": [
      "self",
      "config",
      "optim",
      "tokenizer",
      "model_transform"
    ]
  },
  "HFStarcoder2Importer": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "HFStarcoder2Exporter": {
    "init": [
      "self"
    ],
    "apply": [
      "self",
      "output_path"
    ],
    "convert_state": [
      "self",
      "source",
      "target"
    ],
    "tokenizer": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "chunkify_cu_seqlens": [
    "cu_seqlens",
    "cu_seqlens_padded",
    "attention_chunk_size"
  ],
  "chunkify": [
    "x",
    "attention_chunk_size"
  ],
  "get_llama4_layer_spec": [
    "config",
    "vp_stage",
    "gpt_decoder_block_spec"
  ],
  "Llama4SelfAttention": {
    "__init__": [
      "self",
      "is_nope_layer",
      "attention_chunk_size"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "key_value_states",
      "inference_context",
      "rotary_pos_emb",
      "rotary_pos_cos",
      "rotary_pos_sin",
      "attention_bias",
      "packed_seq_params",
      "sequence_len_offset"
    ]
  },
  "_get_zigzag_indices": [
    "N",
    "device"
  ],
  "_get_inverse_zigzag_indices": [
    "N",
    "device"
  ],
  "all_to_all_single_fn": [
    "group",
    "type",
    "input",
    "with_zigzag_splitting"
  ],
  "AllToAllSingleFunction": {
    "forward": [
      "ctx",
      "input_tensor",
      "group",
      "type",
      "with_zigzag_splitting"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "zigzag_get_overlapping_patches": [
    "data",
    "seq_dim",
    "overlap_size"
  ],
  "ExchangeOverlappingRegionsCausal": {
    "forward": [
      "ctx",
      "chunk_a",
      "chunk_b",
      "group",
      "group_rank"
    ],
    "backward": [
      "ctx",
      "grad_chunk_a",
      "grad_chunk_b"
    ]
  },
  "hyena_no_weight_decay_cond": [
    "name",
    "param"
  ],
  "fftconv_func": [
    "u",
    "k",
    "D",
    "dropout_mask",
    "gelu",
    "k_rev",
    "bidirectional",
    "use_subquadratic_ops"
  ],
  "ImplicitModalFilter": {
    "__init__": [
      "self",
      "d_model",
      "order",
      "L_cache",
      "gamma_min",
      "gamma_max",
      "lr",
      "device",
      "use_subquadratic_ops"
    ],
    "get_t": [
      "self",
      "L"
    ],
    "get_logp": [
      "self"
    ],
    "compute_filter": [
      "self",
      "L",
      "t"
    ],
    "filter": [
      "self",
      "L"
    ],
    "forward": [
      "self",
      "L"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "ExplicitSingleDecayFilter": {
    "__init__": [
      "self",
      "d_model",
      "L_cache",
      "log_r_min",
      "log_r_max",
      "unit_passthrough",
      "decay_preset",
      "small_init",
      "num_decay_repeats",
      "device"
    ],
    "forward": [
      "self",
      "L"
    ],
    "filter": [
      "self",
      "L"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "small_init_init_method": [
    "dim"
  ],
  "wang_init_method": [
    "n_layers",
    "dim"
  ],
  "get_init_method": [
    "init_method_name",
    "num_layers",
    "hidden_size"
  ],
  "ensure_divisibility": [
    "numerator",
    "denominator"
  ],
  "divide": [
    "numerator",
    "denominator"
  ],
  "initialize_affine_weight_gpu": [
    "weight",
    "init_method",
    "partition_dim",
    "stride"
  ],
  "get_groups_and_group_sizes": [
    "hidden_size",
    "num_groups",
    "world_size",
    "expand_factor"
  ],
  "ParallelHyenaOperator": {
    "__init__": [
      "self",
      "hidden_size",
      "transformer_config",
      "hyena_config",
      "init_method",
      "operator_type",
      "max_sequence_length",
      "zigzag"
    ],
    "forward_long": [
      "self"
    ],
    "forward_medium": [
      "self"
    ],
    "forward": [
      "self",
      "x1",
      "x2",
      "v",
      "_hyena_use_cp",
      "inference_context"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "ParallelShortHyenaOperator": {
    "__init__": [
      "self",
      "hidden_size",
      "transformer_config",
      "hyena_config",
      "init_method",
      "short_conv_class",
      "use_fast_causal_conv",
      "local_init",
      "use_conv_bias"
    ],
    "forward": [
      "self",
      "x1",
      "x2",
      "v",
      "inference_context",
      "_hyena_use_cp"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "ParallelCausalDepthwiseConv1d": {
    "__init__": [
      "self",
      "d_model",
      "transformer_config",
      "hyena_config",
      "kernel_size",
      "init_method",
      "bias",
      "use_fast_causal_conv",
      "num_groups",
      "repeat_h_dg",
      "local_init"
    ],
    "forward": [
      "self",
      "x",
      "inference_context",
      "_use_cp"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "B2BCausalConv1dModule": {
    "__init__": [
      "self",
      "proj_conv_module",
      "mixer_module",
      "operator_type",
      "b2b_causal_conv1d"
    ],
    "forward": [
      "self",
      "x",
      "_use_cp"
    ]
  },
  "ParallelCausalDepthwiseConv1dWithState": {
    "forward": [
      "self",
      "x",
      "inference_context",
      "_use_cp"
    ]
  },
  "make_upper_case": [
    "tokens",
    "lowercase_start",
    "lowercase_end",
    "case_diff"
  ],
  "reweighted_cross_entropy": [
    "loss",
    "labels",
    "lowercase_weight",
    "normalize_per_batch"
  ],
  "HyenaLayerSubmodules": {},
  "HyenaLayer": {
    "__init__": [
      "self",
      "transformer_config",
      "hyena_config",
      "operator_type",
      "max_sequence_length",
      "submodules",
      "layer_number",
      "residual_in_fp32",
      "pg_collection"
    ],
    "bias_dropout_add_exec_handler": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "rotary_pos_cos",
      "rotary_pos_sin",
      "attention_bias",
      "inference_context",
      "packed_seq_params",
      "sequence_len_offset"
    ]
  },
  "Symbols": {
    "HYENA_SHORT": [],
    "HYENA_MEDIUM": [],
    "HYENA": [],
    "ATTENTION": [],
    "VALID": []
  },
  "_allocate_override": [
    "total_layers_count",
    "override_pattern"
  ],
  "allocate_layers": [
    "total_layers_count",
    "override_pattern"
  ],
  "adjust_filter_shape_for_broadcast": [
    "u",
    "h"
  ],
  "parallel_fir": [],
  "parallel_iir": [],
  "step_fir": [],
  "step_iir": [],
  "prefill_via_modal_fft": [],
  "get_hyena_stack_spec": [
    "use_te",
    "vortex_style_fp8",
    "unfused_rmsnorm",
    "plain_row_linear"
  ],
  "hyena_stack_spec_no_te": [],
  "get_pad_tensor": [],
  "pad_to_multiple": [
    "x",
    "multiple"
  ],
  "set_format_recipe": [],
  "fp8_padded_forward": [
    "cls",
    "self",
    "x"
  ],
  "rmsnorm": [
    "self",
    "x"
  ],
  "NoTP": {
    "__init__": [
      "self"
    ]
  },
  "Linear": {
    "forward": [
      "self",
      "x"
    ]
  },
  "RMSNormLinear": {
    "forward": [
      "self",
      "x"
    ]
  },
  "TELinearFp8": {
    "forward": [
      "self",
      "x"
    ]
  },
  "TELayerNormColumnParallelLinearFp8": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RMSNormTELinearFp8": {
    "__init__": [
      "self",
      "input_size",
      "output_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HYENA_LAYER_MAP": [],
  "HyenaStackSubmodules": {},
  "HyenaStack": {
    "__init__": [
      "self",
      "transformer_config",
      "hyena_config",
      "hybrid_override_pattern",
      "max_sequence_length",
      "submodules",
      "pre_process",
      "post_process",
      "post_layer_norm",
      "pg_collection"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ],
    "_select_layers_for_pipeline_parallel": [
      "self",
      "layer_type_list"
    ],
    "_get_layer": [
      "self",
      "layer_number"
    ],
    "_checkpointed_forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "attention_bias",
      "packed_seq_params"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "context",
      "context_mask",
      "rotary_pos_emb",
      "rotary_pos_cos",
      "rotary_pos_sin",
      "attention_bias",
      "inference_context",
      "packed_seq_params",
      "sequence_len_offset"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "HyenaMixerSubmodules": {},
  "HyenaMixer": {
    "__init__": [
      "self",
      "transformer_config",
      "hyena_config",
      "max_sequence_length",
      "submodules",
      "layer_number",
      "operator_type"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ],
    "forward": [
      "self",
      "x",
      "layer_past",
      "inference_context",
      "_hyena_use_cp"
    ]
  },
  "LoRALinear": {
    "forward": [
      "self",
      "x"
    ]
  },
  "patch_linear_module": [
    "orig_linear",
    "dim",
    "alpha",
    "dropout",
    "dropout_position",
    "lora_A_init_method",
    "lora_dtype"
  ],
  "LoRAMerge": {
    "transform": [
      "self",
      "m",
      "name",
      "prefix"
    ]
  },
  "ParallelLinearDoRAAdapter": {
    "init_weight_magnitude": [
      "self",
      "value"
    ],
    "get_weight_magnitude": [
      "self"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "DoRALinear": {
    "__init__": [
      "self",
      "to_wrap",
      "adapter"
    ],
    "_get_weight_norm": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DoRA": {
    "__post_init__": [
      "self"
    ],
    "transform": [
      "self",
      "m",
      "name",
      "prefix"
    ]
  },
  "TECL": [],
  "TERL": [],
  "get_adapter_attributes_from_linear": [
    "m"
  ],
  "is_expert_linear": [
    "fqn"
  ],
  "wildcard_match": [
    "pattern",
    "key"
  ],
  "gpt_lora": [],
  "export_lora": [
    "lora_checkpoint_path",
    "output_path"
  ],
  "merge_lora": [
    "lora_checkpoint_path",
    "output_path",
    "legacy_ckpt",
    "trust_remote_code"
  ],
  "_load_base_model_and_lora": [
    "lora_checkpoint_path"
  ],
  "_setup_trainer_and_restore_model_and_adapter": [
    "lora_checkpoint_path",
    "trainer",
    "model",
    "lora"
  ],
  "_save_merged_weight": [
    "output_path",
    "merged_weights",
    "model",
    "trainer",
    "trust_remote_code"
  ],
  "PEFT_STR2CLS": [],
  "ModuleMatcher": {
    "match": [
      "self",
      "m",
      "name",
      "prefix"
    ]
  },
  "ModuleDict": {
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "LoRALinearSplitQKV": {
    "forward": [
      "self",
      "x"
    ]
  },
  "LoRALinearSplitFC1UpGate": {
    "forward": [
      "self",
      "x"
    ]
  },
  "CanonicalLoRA": {
    "__post_init__": [
      "self"
    ],
    "transform": [
      "self",
      "m",
      "name",
      "prefix"
    ]
  },
  "HasBool": {
    "__bool__": [
      "self"
    ]
  },
  "_TModule": [],
  "ModuleFunc": [],
  "ModulePredicate": [],
  "map": [
    "module",
    "func",
    "leaf_only"
  ],
  "walk": [
    "module",
    "func",
    "leaf_only"
  ],
  "forall": [
    "module",
    "func",
    "recurse"
  ],
  "_map_module": [
    "module",
    "func",
    "recurse",
    "leaf_only",
    "transformed_modules"
  ],
  "_map_module_list": [
    "module_list",
    "func",
    "recurse",
    "leaf_only",
    "transformed_modules"
  ],
  "_map_module_dict": [
    "module_dict",
    "func",
    "recurse",
    "leaf_only",
    "transformed_modules"
  ],
  "_create_list_wrapper": [
    "module_list",
    "to_add"
  ],
  "_get_func_kwargs": [
    "func"
  ],
  "gelu_impl": [
    "x"
  ],
  "openai_gelu": [
    "x"
  ],
  "quick_gelu": [
    "x"
  ],
  "squared_relu": [
    "x"
  ],
  "FNMixin": {
    "__init_subclass__": [
      "cls"
    ],
    "forall": [
      "self",
      "func",
      "recurse"
    ],
    "map": [
      "self",
      "func",
      "leaf_only"
    ],
    "walk": [
      "self",
      "func",
      "leaf_only"
    ],
    "freeze": [
      "self"
    ],
    "unfreeze": [
      "self"
    ]
  },
  "qwen2_model": [
    "version"
  ],
  "qwen2_trainer": [
    "tensor_parallelism",
    "pipeline_parallelism",
    "pipeline_parallelism_type",
    "virtual_pipeline_parallelism",
    "context_parallelism",
    "sequence_parallelism",
    "num_nodes",
    "num_gpus_per_node",
    "max_steps",
    "precision",
    "accumulate_grad_batches",
    "limit_test_batches",
    "limit_val_batches",
    "log_every_n_steps",
    "val_check_interval",
    "callbacks"
  ],
  "pretrain_recipe_performance": [
    "dir",
    "name",
    "num_nodes",
    "num_gpus_per_node",
    "fn"
  ],
  "nemotron_model": [
    "version"
  ],
  "nemotron_trainer": [
    "tensor_parallelism",
    "pipeline_parallelism",
    "pipeline_parallelism_type",
    "virtual_pipeline_parallelism",
    "context_parallelism",
    "sequence_parallelism",
    "num_nodes",
    "num_gpus_per_node",
    "max_steps",
    "precision",
    "accumulate_grad_batches",
    "limit_test_batches",
    "limit_val_batches",
    "log_every_n_steps",
    "val_check_interval",
    "callbacks"
  ],
  "performance_optimizations": [
    "recipe"
  ],
  "bert_embedding_model": [
    "version"
  ],
  "bert_trainer": [
    "tensor_parallelism",
    "pipeline_parallelism",
    "pipeline_parallelism_type",
    "virtual_pipeline_parallelism",
    "context_parallelism",
    "sequence_parallelism",
    "num_nodes",
    "num_gpus_per_node",
    "max_steps",
    "precision",
    "accumulate_grad_batches",
    "limit_test_batches",
    "limit_val_batches",
    "log_every_n_steps",
    "val_check_interval",
    "callbacks"
  ],
  "tokenizer_recipe": [],
  "model_recipe": [
    "model_size",
    "tp_comm_overlap",
    "seq_length"
  ],
  "trainer_recipe": [
    "tensor_parallelism",
    "pipeline_parallelism",
    "pipeline_parallelism_type",
    "virtual_pipeline_parallelism",
    "context_parallelism",
    "sequence_parallelism",
    "num_nodes",
    "num_gpus_per_node",
    "max_steps",
    "val_check_interval",
    "limit_test_batches",
    "limit_val_batches",
    "log_every_n_steps",
    "callbacks",
    "fp8",
    "grad_reduce_in_fp32",
    "align_param_gather",
    "no_aligned_megatron_ddp",
    "ckpt_async_save",
    "save_ckpt_format"
  ],
  "blended_dataset_config_recipe": [
    "config_path"
  ],
  "pretrain_recipe_creater": [
    "dataset_config",
    "global_batch_size",
    "micro_batch_size",
    "num_nodes",
    "num_gpus_per_node",
    "grad_acc_batches",
    "tensor_parallel_size",
    "pipeline_model_parallel_size",
    "context_parallel_size",
    "seq_length",
    "seed",
    "model_size",
    "use_megatron_comm_overlap_llama3_8k",
    "workers",
    "val_check_interval",
    "dir",
    "enable_preemption",
    "align_param_gather",
    "tflops_callback",
    "gc_interval",
    "nsys_profiling",
    "max_steps",
    "nsys_start_step",
    "nsys_end_step",
    "nsys_ranks",
    "no_aligned_megatron_ddp",
    "grad_reduce_in_fp32",
    "fp8",
    "ckpt_async_save",
    "sequence_parallel",
    "ckpt_format",
    "limit_val_batches",
    "restore_optimizer_from_ckpt",
    "resume_path",
    "wandb_project",
    "wandb_name",
    "name",
    "fn"
  ],
  "bert_model": [
    "version",
    "bert_type"
  ],
  "gemma2_model": [
    "version"
  ],
  "gemma2_trainer": [
    "tensor_parallelism",
    "pipeline_parallelism",
    "pipeline_parallelism_type",
    "virtual_pipeline_parallelism",
    "context_parallelism",
    "sequence_parallelism",
    "num_nodes",
    "num_gpus_per_node",
    "max_steps",
    "precision",
    "accumulate_grad_batches",
    "limit_test_batches",
    "limit_val_batches",
    "log_every_n_steps",
    "val_check_interval",
    "callbacks"
  ],
  "nemo_resume": [],
  "default_finetune_recipe": [
    "model",
    "resume_path",
    "dir",
    "name",
    "num_nodes",
    "num_gpus_per_node",
    "packed_sequence",
    "tokenizer"
  ],
  "default_finetune_trainer": [
    "tensor_parallelism",
    "pipeline_parallelism",
    "pipeline_parallelism_type",
    "virtual_pipeline_parallelism",
    "context_parallelism",
    "sequence_parallelism",
    "num_nodes",
    "num_gpus_per_node",
    "max_steps",
    "limit_test_batches",
    "limit_val_batches",
    "val_check_interval"
  ],
  "default_finetune_log": [
    "dir",
    "name",
    "tensorboard_logger",
    "wandb_logger"
  ],
  "lora": [],
  "dora": [],
  "starcoder_trainer": [
    "tensor_parallelism",
    "pipeline_parallelism",
    "pipeline_parallelism_type",
    "virtual_pipeline_parallelism",
    "context_parallelism",
    "sequence_parallelism",
    "num_nodes",
    "num_gpus_per_node",
    "max_steps",
    "precision",
    "accumulate_grad_batches",
    "limit_test_batches",
    "limit_val_batches",
    "log_every_n_steps",
    "val_check_interval",
    "callbacks"
  ],
  "qwen3_model": [
    "version"
  ],
  "qwen3_trainer": [
    "tensor_parallelism",
    "pipeline_parallelism",
    "pipeline_parallelism_type",
    "virtual_pipeline_parallelism",
    "context_parallelism",
    "sequence_parallelism",
    "expert_parallelism",
    "account_for_embedding_in_pipeline_split",
    "account_for_loss_in_pipeline_split",
    "num_nodes",
    "num_gpus_per_node",
    "max_steps",
    "precision",
    "accumulate_grad_batches",
    "limit_test_batches",
    "limit_val_batches",
    "log_every_n_steps",
    "val_check_interval",
    "callbacks"
  ],
  "starcoder2_model": [
    "version"
  ],
  "starcoder2_trainer": [
    "tensor_parallelism",
    "pipeline_parallelism",
    "pipeline_parallelism_type",
    "virtual_pipeline_parallelism",
    "context_parallelism",
    "sequence_parallelism",
    "num_nodes",
    "num_gpus_per_node",
    "max_steps",
    "precision",
    "accumulate_grad_batches",
    "limit_test_batches",
    "limit_val_batches",
    "log_every_n_steps",
    "val_check_interval",
    "callbacks"
  ],
  "gemma3_trainer": [
    "tensor_parallelism",
    "pipeline_parallelism",
    "pipeline_parallelism_type",
    "virtual_pipeline_parallelism",
    "context_parallelism",
    "sequence_parallelism",
    "num_nodes",
    "num_gpus_per_node",
    "max_steps",
    "callbacks"
  ],
  "TPOverlapCfg": {},
  "PipelineOverlapCfg": {},
  "RingExchangeOverlapCfg": {},
  "BulkOverlapCfg": {},
  "TransformerLayerTPOverlapCfg": {},
  "userbuffers_bf16_h100_h8192_tp4_mbs1_seqlen8192": [],
  "userbuffers_fp8_h100_h8192_tp4_mbs1_seqlen8192": [],
  "userbuffers_bf16_b200_h8192_tp2_mbs1_seqlen8192": [],
  "userbuffers_fp8_b200_h8192_tp2_mbs1_seqlen8192": [],
  "userbuffers_bf16_h100_h16384_tp8_cp2_mbs1_seqlen8192": [],
  "userbuffers_fp8_h100_h16384_tp8_cp2_mbs1_seqlen8192": [],
  "userbuffers_bf16_b200_h16384_tp4_cp2_mbs1_seqlen8192": [],
  "userbuffers_fp8_b200_h16384_tp4_cp2_mbs1_seqlen8192": [],
  "userbuffers_fp8_h100_h8192_tp2_mbs1_seqlen4096_lora": [],
  "userbuffers_fp8_h100_h16384_tp4_mbs1_seqlen2048_lora": [],
  "userbuffers_bf16_h100_h6144_tp2_mbs2_seqlen2048": [],
  "userbuffers_fp8_h100_h6144_tp2_mbs2_seqlen2048": [],
  "userbuffers_bf16_h100_h12288_tp4_mbs1_seqlen2048": [],
  "userbuffers_fp8_h100_h12288_tp4_mbs1_seqlen2048": [],
  "userbuffers_bf16_b200_h12288_tp4_mbs1_seqlen2048": [],
  "userbuffers_fp8_b200_h12288_tp4_mbs1_seqlen2048": [],
  "userbuffers_bf16_b200_h6144_tp2_mbs1_seqlen4096": [],
  "userbuffers_bf16_b200_h18432_tp8_mbs1_seqlen4096": [],
  "userbuffers_fp8_b200_h18432_tp8_mbs1_seqlen4096": [],
  "straggler_det_callback": [
    "straggler_report_time_interval",
    "stop_if_detected_straggler",
    "gpu_relative_perf_threshold",
    "gpu_individual_perf_threshold"
  ],
  "bf16_mixed": [],
  "fp16_mixed": [],
  "bf16_with_fp8_mixed": [],
  "fp16_with_fp8_mixed": [],
  "bf16_with_mxfp8_mixed": [],
  "fp16_with_mxfp8_mixed": [],
  "bf16_with_fp8_current_scaling_mixed": [],
  "nemotron_h_bf16_with_fp8_current_scaling_mixed": [],
  "nanov2_bf16_with_fp8_current_scaling_mixed": [],
  "fp16_with_fp8_current_scaling_mixed": [],
  "bf16_with_fp8_subchannel_scaling_mixed": [],
  "fp16_with_fp8_subchannel_scaling_mixed": [],
  "distributed_fused_adam_with_cosine_annealing": [
    "precision",
    "warmup_steps",
    "constant_steps",
    "adam_beta1",
    "adam_beta2",
    "max_lr",
    "min_lr",
    "clip_grad"
  ],
  "pytorch_adam_with_cosine_annealing": [
    "warmup_steps",
    "constant_steps",
    "max_lr",
    "min_lr",
    "weight_decay",
    "foreach"
  ],
  "te_adam_with_cosine_annealing": [
    "warmup_steps",
    "constant_steps",
    "max_lr",
    "min_lr",
    "weight_decay"
  ],
  "te_adam_with_flat_lr": [
    "lr",
    "weight_decay"
  ],
  "pytorch_sgd_with_cosine_annealing": [
    "warmup_steps",
    "constant_steps",
    "max_lr",
    "min_lr",
    "wd"
  ],
  "pytorch_sgd_with_flat_lr": [
    "lr",
    "wd"
  ],
  "tensorboard_logger": [
    "name",
    "save_dir"
  ],
  "wandb_logger": [
    "project",
    "name",
    "entity"
  ],
  "default_log": [
    "dir",
    "name",
    "tensorboard_logger",
    "wandb_logger"
  ],
  "default_resume": [
    "resume_if_exists",
    "resume_ignore_no_checkpoint"
  ],
  "get_global_step_from_global_checkpoint_path": [
    "path"
  ],
  "torchrun": [
    "devices"
  ],
  "MCoreTokenizerWrappper": {
    "__init__": [
      "self",
      "tokenizer",
      "vocab_size"
    ],
    "detokenize": [
      "self",
      "tokens",
      "remove_special_tokens"
    ],
    "tokenize": [
      "self",
      "prompt"
    ],
    "additional_special_tokens_ids": [
      "self"
    ],
    "bos": [
      "self"
    ],
    "pad": [
      "self"
    ]
  },
  "setup_mcore_engine": [
    "path",
    "trainer",
    "params_dtype",
    "inference_batch_times_seqlen_threshold",
    "inference_max_seq_length",
    "enable_flash_decode",
    "max_batch_size",
    "random_seed"
  ],
  "SUPPORTED_MODELS": [],
  "AutoConfigurator": {
    "__init__": [
      "self",
      "recipe",
      "path_to_logs",
      "mode",
      "gpu_memory_gb",
      "tensor_parallel_sizes",
      "pipeline_parallel_sizes",
      "micro_batch_sizes",
      "context_parallel_sizes",
      "expert_parallel_sizes",
      "min_model_parallel_size",
      "max_model_parallel_size",
      "num_tokens_in_b",
      "tflops_per_gpu",
      "max_minutes_per_run",
      "max_training_days",
      "max_steps_per_run",
      "vocab_size",
      "calculate_model_size"
    ],
    "_get_message": [
      "self",
      "config"
    ],
    "_get_model_type": [
      "self",
      "model"
    ],
    "_get_model_size": [
      "self",
      "model",
      "model_type",
      "vocab_size",
      "calculate_model_size"
    ]
  },
  "generate_configs": [
    "runner_config"
  ],
  "GPT_BASED_MODELS": [],
  "ModelSizeParams": {
    "init_params": [
      "self"
    ]
  },
  "_calculate_model_size": [
    "vocab_size",
    "seq_length",
    "hidden_size",
    "num_layers",
    "ffn_size",
    "kv_channels",
    "att_heads",
    "model_name"
  ],
  "generic_base_config": [
    "config"
  ],
  "modify_cfg": [
    "base_cfg",
    "act",
    "num_mbs_act",
    "act_per_pipe",
    "tp",
    "pp",
    "cp",
    "ep",
    "virtual_pipelines",
    "mbs",
    "max_steps",
    "num_nodes",
    "model_name",
    "path_to_logs",
    "model_size"
  ],
  "generate_grid_search_configs": [
    "base_cfg",
    "train_cfg"
  ],
  "_set_activations_checkpoint_params": [
    "tp",
    "pp",
    "cp",
    "ep",
    "num_layers",
    "act_method",
    "multiplier",
    "model_size_in_b",
    "model_name"
  ],
  "GPT3GridSearch": {
    "tp": [],
    "pp": [],
    "cp": [],
    "ep": [],
    "mbs": [],
    "init_params": [
      "self"
    ]
  },
  "T5GridSearch": {
    "tp": [],
    "pp": [],
    "cp": [],
    "ep": [],
    "mbs": [],
    "init_params": [
      "self"
    ]
  },
  "BertGridSearch": {
    "tp": [],
    "pp": [],
    "cp": [],
    "ep": [],
    "mbs": [],
    "init_params": [
      "self"
    ]
  },
  "_calculate_tp_pp_mbs_grid": [
    "model_size_in_b",
    "num_layers",
    "model_name",
    "seq_length",
    "train_cfg"
  ],
  "get_results": [
    "base_config",
    "train_config",
    "path_to_save",
    "output_top_n",
    "log_file_prefix"
  ],
  "calculate_tflops": [
    "model_name",
    "gbs",
    "enc_seq_len",
    "dec_seq_len",
    "hs",
    "ffn_hs",
    "layers",
    "vocab",
    "nodes",
    "gpus_per_node",
    "time_per_step"
  ],
  "find_error": [
    "error_file",
    "errors"
  ],
  "find_tb_logs": [
    "logs_dir",
    "tb_prefix"
  ],
  "calculate_model_size": [
    "gpu_count",
    "max_training_days",
    "model_size_in_b",
    "tflops_per_gpu",
    "num_tokens_in_b",
    "model_name"
  ],
  "_estimate_model_size": [
    "max_training_days",
    "gpu_count",
    "tflops_per_gpu",
    "num_tokens_in_b",
    "model_name"
  ],
  "_estimate_training_time": [
    "model_size_in_b",
    "gpu_count",
    "tflops_per_gpu",
    "num_tokens_in_b",
    "model_name"
  ],
  "_MAX_LEVEL": [],
  "ImageNetPolicy": {
    "__init__": [
      "self",
      "fillcolor"
    ],
    "__call__": [
      "self",
      "img"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SubPolicy": {
    "__init__": [
      "self",
      "operation1",
      "probability1",
      "magnitude_idx1",
      "operation2",
      "probability2",
      "magnitude_idx2",
      "fillcolor"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "has_file_allowed_extension": [
    "filename",
    "extensions"
  ],
  "is_image_file": [
    "filename"
  ],
  "make_dataset": [
    "directory",
    "class_to_idx",
    "data_per_class_fraction",
    "extensions",
    "is_valid_file"
  ],
  "IMG_EXTENSIONS": [],
  "accimage_loader": [
    "path"
  ],
  "default_loader": [
    "path"
  ],
  "ImageFolder": {
    "__init__": [
      "self",
      "root",
      "transform",
      "target_transform",
      "classes_fraction",
      "data_per_class_fraction",
      "loader",
      "is_valid_file"
    ]
  },
  "MegatronVisionPretrainingRandomSampler": {
    "__init__": [
      "self",
      "dataset",
      "total_samples",
      "consumed_samples",
      "micro_batch_size",
      "data_parallel_rank",
      "data_parallel_size",
      "data_sharding",
      "drop_last",
      "global_batch_size",
      "pad_samples_to_global_batch_size"
    ],
    "__iter__": [
      "self"
    ]
  },
  "_to_torch_data_type": [
    "precision"
  ],
  "RandomSeedDataset": {
    "__init__": [
      "self",
      "dataset",
      "seed"
    ],
    "__len__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "GaussianBlur": {
    "__init__": [
      "self",
      "p",
      "radius_min",
      "radius_max"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "Solarization": {
    "__init__": [
      "self",
      "p"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "ClassificationTransform": {
    "__init__": [
      "self",
      "model_cfg",
      "image_size",
      "train"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "InpaintingTransform": {
    "__init__": [
      "self",
      "model_cfg",
      "image_size",
      "train"
    ],
    "gen_mask": [
      "self",
      "image_size",
      "mask_size",
      "mask_type",
      "patch_size"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "DinoTransform": {
    "__init__": [
      "self",
      "model_cfg",
      "image_size",
      "train"
    ],
    "__call__": [
      "self",
      "image"
    ]
  },
  "RNNTLossPytorch": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "blank",
      "reduction"
    ],
    "forward": [
      "self",
      "acts",
      "labels",
      "act_lens",
      "label_lens"
    ],
    "compute_forward_prob": [
      "self",
      "acts",
      "labels",
      "act_lens",
      "label_lens"
    ]
  },
  "TDTLossPytorch": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "blank",
      "durations",
      "reduction",
      "sigma"
    ],
    "forward": [
      "self",
      "acts",
      "labels",
      "act_lens",
      "label_lens"
    ],
    "logsumexp": [
      "self",
      "a",
      "b"
    ],
    "compute_forward_prob": [
      "self",
      "acts",
      "duration_acts",
      "labels",
      "act_lens",
      "label_lens"
    ]
  },
  "MultiblankRNNTLossPytorch": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "blank",
      "big_blank_durations",
      "reduction",
      "sigma"
    ],
    "forward": [
      "self",
      "acts",
      "labels",
      "act_lens",
      "label_lens"
    ],
    "compute_forward_prob": [
      "self",
      "acts",
      "labels",
      "act_lens",
      "label_lens"
    ]
  },
  "LatticeLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "num_classes",
      "reduction",
      "backend",
      "criterion_type",
      "loss_type",
      "split_batch_size",
      "graph_module_cfg"
    ],
    "update_graph": [
      "self",
      "graph"
    ],
    "forward": [
      "self",
      "log_probs",
      "targets",
      "input_lengths",
      "target_lengths"
    ]
  },
  "WARP_RNNT_INSTALLATION_MESSAGE": [],
  "RNNTLossConfig": {},
  "RNNT_LOSS_RESOLVER": [],
  "_warn_unused_additional_kwargs": [
    "loss_name",
    "kwargs"
  ],
  "_clean_kwargs": [
    "loss_name",
    "kwargs",
    "init_method",
    "ignore_params"
  ],
  "resolve_rnnt_default_loss_name": [],
  "resolve_rnnt_loss": [
    "loss_name",
    "blank_idx",
    "loss_kwargs"
  ],
  "RNNTLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "num_classes",
      "reduction",
      "loss_name",
      "loss_kwargs"
    ],
    "reduce": [
      "self",
      "losses",
      "target_lengths"
    ],
    "forward": [
      "self",
      "log_probs",
      "targets",
      "input_lengths",
      "target_lengths"
    ]
  },
  "BCELoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "reduction",
      "alpha",
      "weight",
      "sorted_preds",
      "sorted_loss",
      "class_normalization"
    ],
    "forward": [
      "self",
      "probs",
      "labels",
      "target_lens",
      "enable_autocast"
    ]
  },
  "CTCLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "num_classes",
      "zero_infinity",
      "reduction"
    ],
    "reduce": [
      "self",
      "losses",
      "target_lengths"
    ],
    "forward": [
      "self",
      "log_probs",
      "targets",
      "input_lengths",
      "target_lengths"
    ]
  },
  "AngularSoftmaxLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "scale",
      "margin"
    ],
    "forward": [
      "self",
      "logits",
      "labels"
    ]
  },
  "RNNTLossForSSL": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "needs_labels": [
      "self"
    ],
    "__init__": [
      "self",
      "num_classes"
    ],
    "forward": [
      "self",
      "spec_masks",
      "decoder_outputs",
      "targets",
      "decoder_lengths",
      "target_lengths"
    ]
  },
  "MLMLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "needs_labels": [
      "self"
    ],
    "__init__": [
      "self",
      "combine_time_steps",
      "mask_threshold"
    ],
    "forward": [
      "self",
      "decoder_outputs",
      "targets",
      "decoder_lengths",
      "target_lengths",
      "spec_masks",
      "masks"
    ]
  },
  "MultiMLMLoss": {
    "input_types": [
      "self"
    ],
    "__init__": [
      "self",
      "combine_time_steps",
      "mask_threshold",
      "num_decoders",
      "squeeze_single"
    ],
    "forward": [
      "self",
      "masks",
      "decoder_outputs",
      "targets",
      "decoder_lengths",
      "target_lengths"
    ]
  },
  "ContrastiveLoss": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "needs_labels": [
      "self"
    ],
    "__init__": [
      "self",
      "in_dim",
      "proj_dim",
      "combine_time_steps",
      "num_negatives",
      "quantized_targets",
      "codebook_size",
      "prob_ppl_weight",
      "logit_temp",
      "reduce",
      "sample_from_same_utterance_only",
      "sample_from_non_masked",
      "sample_from_codebook",
      "group_loss",
      "num_groups",
      "quantizer_temp_start",
      "quantizer_temp_min",
      "quantizer_temp_decay",
      "mask_threshold",
      "store_ids",
      "reduce_ids",
      "multiplier"
    ],
    "sample_negatives": [
      "self",
      "y",
      "num"
    ],
    "forward": [
      "self",
      "spectrograms",
      "spec_masks",
      "decoder_outputs",
      "decoder_lengths"
    ],
    "_calculate_similarity": [
      "self",
      "logits",
      "negatives",
      "targets"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ]
  },
  "CTCLossForSSL": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "needs_labels": [
      "self"
    ],
    "__init__": [
      "self",
      "num_classes",
      "zero_infinity",
      "reduction"
    ],
    "forward": [
      "self",
      "spec_masks",
      "decoder_outputs",
      "targets",
      "decoder_lengths",
      "target_lengths"
    ]
  },
  "BLEU_TOKENIZER": [],
  "_get_bleu_tokenizers_from_cuts": [
    "cuts"
  ],
  "_move_dimension_to_the_front": [
    "tensor",
    "dim_index"
  ],
  "MultiBinaryAccuracy": {
    "full_state_update": [],
    "__init__": [
      "self",
      "dist_sync_on_step"
    ],
    "update": [
      "self",
      "preds",
      "targets",
      "signal_lengths",
      "cumulative"
    ],
    "compute": [
      "self"
    ]
  },
  "ConstraintParser": {
    "_primitives": [],
    "_booleans": [],
    "parse_constraint": [
      "self",
      "constraint"
    ],
    "primitives": [
      "self"
    ],
    "booleans": [
      "self"
    ],
    "_logical_not": [
      "expr",
      "properties"
    ],
    "_logical_and": [
      "l_expr",
      "r_expr",
      "properties"
    ],
    "_logical_or": [
      "l_expr",
      "r_expr",
      "properties"
    ],
    "_logical_xor": [
      "l_expr",
      "r_expr",
      "properties"
    ],
    "_no_constraint": [
      "properties"
    ],
    "_static_constraint": [
      "fnc",
      "key",
      "val",
      "properties"
    ],
    "_compare_constraint": [
      "fnc",
      "key1",
      "key2",
      "properties"
    ],
    "_resolve_primitives": [
      "self",
      "constraint"
    ],
    "_resolve_bools": [
      "self",
      "constraint"
    ]
  },
  "MultiTaskMetric": {
    "__init__": [
      "self",
      "model",
      "cfg"
    ],
    "eval": [
      "self",
      "batch",
      "predictions",
      "predictions_lengths",
      "predictions_mask",
      "return_all_metrics",
      "prefix"
    ],
    "update": [
      "self",
      "predictions",
      "predictions_lengths",
      "predictions_mask",
      "targets",
      "targets_lengths",
      "input_ids",
      "cuts"
    ],
    "compute": [
      "self",
      "return_all_metrics",
      "prefix"
    ],
    "reset": [
      "self"
    ],
    "_split_cuts": [
      "self",
      "cuts"
    ]
  },
  "move_dimension_to_the_front": [
    "tensor",
    "dim_index"
  ],
  "word_error_rate": [
    "hypotheses",
    "references",
    "use_cer"
  ],
  "word_error_rate_detail": [
    "hypotheses",
    "references",
    "use_cer"
  ],
  "word_error_rate_per_utt": [
    "hypotheses",
    "references",
    "use_cer"
  ],
  "get_partial_ref_labels": [
    "pred_labels",
    "ref_labels"
  ],
  "get_online_DER_stats": [
    "DER",
    "CER",
    "FA",
    "MISS",
    "diar_eval_count",
    "der_stat_dict",
    "deci"
  ],
  "uem_timeline_from_file": [
    "uem_file",
    "uniq_name"
  ],
  "score_labels": [
    "AUDIO_RTTM_MAP",
    "all_reference",
    "all_hypothesis",
    "all_uem",
    "collar",
    "ignore_overlap",
    "verbose"
  ],
  "evaluate_der": [
    "audio_rttm_map_dict",
    "all_reference",
    "all_hypothesis",
    "diar_eval_mode"
  ],
  "calculate_session_cpWER_bruteforce": [
    "spk_hypothesis",
    "spk_reference"
  ],
  "calculate_session_cpWER": [
    "spk_hypothesis",
    "spk_reference",
    "use_lsa_only"
  ],
  "concat_perm_word_error_rate": [
    "spk_hypotheses",
    "spk_references"
  ],
  "get_feature_seq_speakerlabel_dataset": [
    "feature_loader",
    "config"
  ],
  "get_feature_label_dataset": [
    "config",
    "augmentor"
  ],
  "get_feature_multi_label_dataset": [
    "config",
    "augmentor"
  ],
  "_feature_collate_fn": [
    "batch"
  ],
  "_audio_feature_collate_fn": [
    "batch",
    "feat_pad_val",
    "label_pad_id"
  ],
  "_vad_feature_segment_collate_fn": [
    "batch",
    "window_length_in_sec",
    "shift_length_in_sec",
    "frame_unit_in_sec"
  ],
  "_FeatureSeqSpeakerLabelDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "FeatureToSeqSpeakerLabelDataset": {
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "FeatureToLabelDataset": {
    "ZERO_LEVEL_SPEC_DB_VAL": [],
    "FRAME_UNIT_TIME_SECS": [],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "_vad_segment_collate_fn": [
      "self",
      "batch"
    ]
  },
  "FeatureToMultiLabelDataset": {
    "ZERO_LEVEL_SPEC_DB_VAL": [],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "_get_label_set": [
      "self"
    ],
    "_label_str_to_tensor": [
      "self",
      "label_str"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "MultiSpeakerSimulator": {
    "__init__": [
      "self",
      "cfg"
    ],
    "_init_speaker_permutations": [
      "self",
      "num_sess",
      "num_speakers",
      "all_speaker_ids",
      "random_seed"
    ],
    "_init_chunk_count": [
      "self"
    ],
    "_check_args": [
      "self"
    ],
    "clean_up": [
      "self"
    ],
    "_get_speaker_dominance": [
      "self"
    ],
    "_increase_speaker_dominance": [
      "self",
      "base_speaker_dominance",
      "factor"
    ],
    "_set_speaker_volume": [
      "self"
    ],
    "_get_next_speaker": [
      "self",
      "prev_speaker",
      "dominance"
    ],
    "_get_window": [
      "self",
      "window_amount",
      "start"
    ],
    "_get_start_buffer_and_window": [
      "self",
      "first_alignment"
    ],
    "_get_end_buffer_and_window": [
      "self",
      "current_sample_cursor",
      "remaining_dur_samples",
      "remaining_len_audio_file"
    ],
    "_check_missing_speakers": [
      "self",
      "num_missing"
    ],
    "_add_file": [
      "self",
      "audio_manifest",
      "audio_file",
      "sentence_word_count",
      "max_word_count_in_sentence",
      "max_samples_in_sentence",
      "random_offset"
    ],
    "_build_sentence": [
      "self",
      "speaker_turn",
      "speaker_ids",
      "speaker_wav_align_map",
      "max_samples_in_sentence"
    ],
    "_add_silence_or_overlap": [
      "self",
      "speaker_turn",
      "prev_speaker",
      "start",
      "length",
      "session_len_samples",
      "prev_len_samples",
      "enforce"
    ],
    "_get_session_meta_data": [
      "self",
      "array",
      "snr"
    ],
    "_get_session_silence_from_rttm": [
      "self",
      "rttm_list",
      "running_len_samples"
    ],
    "_add_sentence_to_array": [
      "self",
      "start",
      "length",
      "array",
      "is_speech"
    ],
    "_generate_session": [
      "self",
      "idx",
      "basepath",
      "filename",
      "speaker_ids",
      "speaker_wav_align_map",
      "noise_samples",
      "device",
      "enforce_counter"
    ],
    "generate_sessions": [
      "self",
      "random_seed"
    ]
  },
  "RIRMultiSpeakerSimulator": {
    "__init__": [
      "self",
      "cfg"
    ],
    "_check_args_rir": [
      "self"
    ],
    "_generate_rir_gpuRIR": [
      "self"
    ],
    "_generate_rir_pyroomacoustics": [
      "self"
    ],
    "_convolve_rir": [
      "self",
      "input",
      "speaker_turn",
      "RIR"
    ],
    "_generate_session": [
      "self",
      "idx",
      "basepath",
      "filename",
      "speaker_ids",
      "speaker_wav_align_map",
      "noise_samples",
      "device",
      "enforce_counter"
    ]
  },
  "ASRFeatureManifestProcessor": {
    "__init__": [
      "self",
      "manifest_filepath",
      "parser",
      "max_duration",
      "min_duration",
      "max_utts",
      "bos_id",
      "eos_id",
      "pad_id",
      "index_by_file_id"
    ],
    "process_text_by_id": [
      "self",
      "index"
    ],
    "process_text_by_file_id": [
      "self",
      "file_id"
    ],
    "process_text_by_sample": [
      "self",
      "sample"
    ]
  },
  "_FeatureTextDataset": {
    "ZERO_LEVEL_SPEC_DB_VAL": [],
    "NORM_MODES": [],
    "RTTM_MODES": [],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "manifest_filepath",
      "parser",
      "normalize",
      "normalize_type",
      "use_rttm",
      "rttm_mode",
      "feat_min_len",
      "feat_mask_val",
      "frame_unit_time_secs",
      "sample_rate",
      "augmentor",
      "max_duration",
      "min_duration",
      "max_utts",
      "trim",
      "bos_id",
      "eos_id",
      "pad_id",
      "return_sample_id",
      "channel_selector"
    ],
    "get_manifest_sample": [
      "self",
      "sample_id"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "process_features_with_rttm": [
      "self",
      "features",
      "offset",
      "rttm_file",
      "mask_val"
    ],
    "__len__": [
      "self"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "normalize_feature": [
      "self",
      "feat"
    ]
  },
  "FeatureToCharDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "labels",
      "normalize",
      "normalize_type",
      "use_rttm",
      "rttm_mode",
      "feat_min_len",
      "feat_mask_val",
      "frame_unit_time_secs",
      "sample_rate",
      "augmentor",
      "max_duration",
      "min_duration",
      "max_utts",
      "blank_index",
      "unk_index",
      "trim",
      "bos_id",
      "eos_id",
      "pad_id",
      "parser",
      "return_sample_id",
      "channel_selector"
    ]
  },
  "FeatureToBPEDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "tokenizer",
      "normalize",
      "normalize_type",
      "use_rttm",
      "rttm_mode",
      "feat_min_len",
      "feat_mask_val",
      "frame_unit_time_secs",
      "sample_rate",
      "augmentor",
      "max_duration",
      "min_duration",
      "max_utts",
      "use_start_end_token",
      "trim",
      "return_sample_id",
      "channel_selector"
    ]
  },
  "_speech_collate_fn": [
    "batch",
    "pad_id"
  ],
  "ASRManifestProcessor": {
    "__init__": [
      "self",
      "manifest_filepath",
      "parser",
      "max_duration",
      "min_duration",
      "max_utts",
      "bos_id",
      "eos_id",
      "pad_id",
      "index_by_file_id",
      "manifest_parse_func"
    ],
    "process_text_by_id": [
      "self",
      "index"
    ],
    "process_text_by_file_id": [
      "self",
      "file_id"
    ],
    "process_text_by_sample": [
      "self",
      "sample"
    ]
  },
  "cache_datastore_manifests": [
    "manifest_filepaths",
    "cache_audio",
    "shared_cache",
    "num_workers",
    "max_num_workers"
  ],
  "shard_manifests_if_needed": [
    "manifest_filepaths",
    "shard_strategy",
    "shard_manifests",
    "global_rank",
    "world_size"
  ],
  "_AudioTextDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "manifest_filepath",
      "parser",
      "sample_rate",
      "int_values",
      "augmentor",
      "max_duration",
      "min_duration",
      "max_utts",
      "trim",
      "bos_id",
      "eos_id",
      "pad_id",
      "return_sample_id",
      "channel_selector",
      "manifest_parse_func"
    ],
    "get_manifest_sample": [
      "self",
      "sample_id"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_process_sample": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "AudioToCharDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "manifest_filepath",
      "labels",
      "sample_rate",
      "int_values",
      "augmentor",
      "max_duration",
      "min_duration",
      "max_utts",
      "blank_index",
      "unk_index",
      "normalize",
      "trim",
      "bos_id",
      "eos_id",
      "pad_id",
      "parser",
      "return_sample_id",
      "channel_selector",
      "manifest_parse_func"
    ]
  },
  "AudioToBPEDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "manifest_filepath",
      "tokenizer",
      "sample_rate",
      "int_values",
      "augmentor",
      "max_duration",
      "min_duration",
      "max_utts",
      "trim",
      "use_start_end_token",
      "return_sample_id",
      "channel_selector",
      "manifest_parse_func"
    ]
  },
  "_TarredAudioToTextDataset": {
    "__init__": [
      "self",
      "audio_tar_filepaths",
      "manifest_filepath",
      "parser",
      "sample_rate",
      "int_values",
      "augmentor",
      "shuffle_n",
      "min_duration",
      "max_duration",
      "trim",
      "bos_id",
      "eos_id",
      "pad_id",
      "shard_strategy",
      "shard_manifests",
      "global_rank",
      "world_size",
      "return_sample_id",
      "manifest_parse_func"
    ],
    "_filter": [
      "self",
      "iterator"
    ],
    "_loop_offsets": [
      "self",
      "iterator"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "_build_sample": [
      "self",
      "tup"
    ],
    "get_manifest_sample": [
      "self",
      "sample_id"
    ],
    "__iter__": [
      "self"
    ],
    "_compute_len": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "TarredAudioToCharDataset": {
    "__init__": [
      "self",
      "audio_tar_filepaths",
      "manifest_filepath",
      "labels",
      "sample_rate",
      "int_values",
      "augmentor",
      "shuffle_n",
      "min_duration",
      "max_duration",
      "blank_index",
      "unk_index",
      "normalize",
      "trim",
      "bos_id",
      "eos_id",
      "parser",
      "pad_id",
      "shard_strategy",
      "shard_manifests",
      "global_rank",
      "world_size",
      "return_sample_id",
      "manifest_parse_func"
    ]
  },
  "TarredAudioToBPEDataset": {
    "__init__": [
      "self",
      "audio_tar_filepaths",
      "manifest_filepath",
      "tokenizer",
      "sample_rate",
      "int_values",
      "augmentor",
      "shuffle_n",
      "min_duration",
      "max_duration",
      "trim",
      "use_start_end_token",
      "shard_strategy",
      "shard_manifests",
      "global_rank",
      "world_size",
      "return_sample_id",
      "manifest_parse_func"
    ]
  },
  "BucketingDataset": {
    "__init__": [
      "self",
      "dataset",
      "bucketing_batch_size"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "BucketingIterator": {
    "__init__": [
      "self",
      "wrapped_ds",
      "bucketing_batch_size"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ]
  },
  "RandomizedChainDataset": {
    "__init__": [
      "self",
      "datasets",
      "rnd_seed"
    ],
    "__iter__": [
      "self"
    ]
  },
  "LhotseAudioToSpeechE2ESpkDiarDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "cfg"
    ],
    "__getitem__": [
      "self",
      "cuts"
    ]
  },
  "LhotseSpeechToTextBpeDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "tokenizer",
      "return_cuts"
    ],
    "__getitem__": [
      "self",
      "cuts"
    ]
  },
  "LhotseSpeechToTextSpkBpeDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "cfg",
      "tokenizer"
    ],
    "__getitem__": [
      "self",
      "cuts"
    ]
  },
  "TextToTextItem": {},
  "TextToTextBatch": {
    "collate_fn": [
      "batch",
      "asr_pad_id",
      "tts_text_pad_id"
    ]
  },
  "TextOrAudioToTextBatch": {
    "collate_fn": [
      "batch",
      "tts_text_pad_id",
      "asr_pad_id"
    ]
  },
  "_asr_text_to_tokens": [
    "text"
  ],
  "_tts_text_to_tokens": [
    "text"
  ],
  "_iterate_manifest": [
    "filepath"
  ],
  "TextToTextDatasetBase": {
    "__init__": [
      "self",
      "manifest_filepath",
      "speakers_filepath",
      "asr_tokenizer",
      "asr_use_start_end_token",
      "tts_parser",
      "tts_text_pad_id",
      "tts_text_normalizer",
      "tts_text_normalizer_call_kwargs",
      "min_words",
      "max_words",
      "tokenizer_workers",
      "num_parts",
      "current_part_index"
    ],
    "_asr_text_to_tokens": [
      "self",
      "text"
    ],
    "_tts_text_to_tokens": [
      "self",
      "text",
      "normalize"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "TextToTextDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "speakers_filepath",
      "asr_tokenizer",
      "asr_use_start_end_token",
      "tts_parser",
      "tts_text_pad_id",
      "tts_text_normalizer",
      "tts_text_normalizer_call_kwargs",
      "min_words",
      "max_words",
      "tokenizer_workers"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "TextToTextIterableDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "speakers_filepath",
      "asr_tokenizer",
      "asr_use_start_end_token",
      "tts_parser",
      "tts_text_pad_id",
      "tts_text_normalizer",
      "tts_text_normalizer_call_kwargs",
      "min_words",
      "max_words",
      "tokenizer_workers",
      "num_parts",
      "current_part_index"
    ],
    "__iter__": [
      "self"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "__DALI_MINIMUM_VERSION__": [],
  "DALI_INSTALLATION_MESSAGE": [],
  "is_dali_supported": [
    "min_version",
    "verbose"
  ],
  "DALIOutputs": {
    "__init__": [
      "self",
      "out_dict"
    ],
    "has_processed_signal": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__len__": [
      "self"
    ]
  },
  "_AudioTextDALIDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "device",
      "batch_size",
      "parser",
      "audio_tar_filepaths",
      "audio_tar_index_filepaths",
      "sample_rate",
      "num_threads",
      "max_duration",
      "min_duration",
      "bos_id",
      "eos_id",
      "pad_id",
      "trim",
      "shuffle",
      "drop_last",
      "shard_strategy",
      "device_id",
      "global_rank",
      "world_size",
      "preprocessor_cfg",
      "return_sample_id"
    ],
    "reset": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "next": [
      "self"
    ],
    "size": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__next__": [
      "self"
    ]
  },
  "AudioToCharDALIDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "device",
      "batch_size",
      "labels",
      "sample_rate",
      "audio_tar_filepaths",
      "audio_tar_index_filepaths",
      "num_threads",
      "max_duration",
      "min_duration",
      "blank_index",
      "unk_index",
      "normalize",
      "bos_id",
      "eos_id",
      "pad_id",
      "trim",
      "shuffle",
      "drop_last",
      "parser",
      "shard_strategy",
      "device_id",
      "global_rank",
      "world_size",
      "preprocessor_cfg",
      "return_sample_id"
    ]
  },
  "AudioToBPEDALIDataset": {
    "__init__": [
      "self",
      "manifest_filepath",
      "tokenizer",
      "device",
      "batch_size",
      "sample_rate",
      "audio_tar_filepaths",
      "audio_tar_index_filepaths",
      "num_threads",
      "max_duration",
      "min_duration",
      "trim",
      "shuffle",
      "drop_last",
      "shard_strategy",
      "device_id",
      "global_rank",
      "world_size",
      "preprocessor_cfg",
      "use_start_end_token",
      "return_sample_id"
    ]
  },
  "inject_dataloader_value_from_model_config": [
    "model_cfg",
    "dataloader_cfg",
    "key"
  ],
  "get_concat_char_dataset": [
    "config",
    "global_rank",
    "world_size",
    "augmentor"
  ],
  "get_concat_bpe_dataset": [
    "config",
    "tokenizer",
    "global_rank",
    "world_size",
    "augmentor"
  ],
  "get_concat_tarred_dataset": [
    "config",
    "shuffle_n",
    "global_rank",
    "world_size",
    "tokenizer",
    "augmentor"
  ],
  "get_code_switched_dataset": [
    "config",
    "shuffle_n",
    "global_rank",
    "world_size",
    "tokenizer",
    "augmentor"
  ],
  "get_dali_char_dataset": [
    "config",
    "shuffle",
    "device_id",
    "global_rank",
    "world_size",
    "preprocessor_cfg"
  ],
  "get_dali_bpe_dataset": [
    "config",
    "tokenizer",
    "shuffle",
    "device_id",
    "global_rank",
    "world_size",
    "preprocessor_cfg"
  ],
  "get_audio_to_text_char_dataset_from_config": [
    "config",
    "local_rank",
    "global_rank",
    "world_size",
    "preprocessor_cfg"
  ],
  "get_audio_to_text_bpe_dataset_from_config": [
    "config",
    "local_rank",
    "global_rank",
    "world_size",
    "tokenizer",
    "preprocessor_cfg"
  ],
  "ASRPredictionWriter": {
    "__init__": [
      "self",
      "dataset",
      "output_file"
    ],
    "write_on_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "prediction",
      "batch_indices",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "close_output_file": [
      "self"
    ]
  },
  "convert_to_config_list": [
    "initial_list"
  ],
  "get_chain_dataset": [
    "datasets",
    "ds_config",
    "rank"
  ],
  "calc_bucketing_batch_sizes": [
    "ds_config",
    "datasets_len"
  ],
  "get_classification_label_dataset": [
    "featurizer",
    "config"
  ],
  "get_speech_label_dataset": [
    "featurizer",
    "config"
  ],
  "get_tarred_classification_label_dataset": [
    "featurizer",
    "config",
    "shuffle_n",
    "global_rank",
    "world_size"
  ],
  "get_concat_tarred_speech_label_dataset": [
    "featurizer",
    "config",
    "shuffle_n",
    "global_rank",
    "world_size"
  ],
  "get_tarred_speech_label_dataset": [
    "featurizer",
    "config",
    "shuffle_n",
    "global_rank",
    "world_size"
  ],
  "get_audio_multi_label_dataset": [
    "cfg"
  ],
  "get_tarred_audio_multi_label_dataset": [
    "cfg",
    "shuffle_n",
    "global_rank",
    "world_size"
  ],
  "get_scale_mapping_list": [
    "uniq_timestamps"
  ],
  "extract_seg_info_from_rttm": [
    "rttm_lines",
    "mapping_dict",
    "target_spks"
  ],
  "assign_frame_level_spk_vector": [
    "rttm_timestamps",
    "round_digits",
    "frame_per_sec",
    "target_spks",
    "min_spks"
  ],
  "get_subsegments_to_timestamps": [
    "subsegments",
    "feat_per_sec",
    "max_end_ts",
    "decimals"
  ],
  "extract_frame_info_from_rttm": [
    "offset",
    "duration",
    "rttm_lines",
    "round_digits"
  ],
  "get_frame_targets_from_rttm": [
    "rttm_timestamps",
    "offset",
    "duration",
    "round_digits",
    "feat_per_sec",
    "max_spks"
  ],
  "_AudioMSDDTrainDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "assign_labels_to_longer_segs": [
      "self",
      "uniq_id",
      "base_scale_clus_label"
    ],
    "get_diar_target_labels": [
      "self",
      "uniq_id",
      "sample",
      "fr_level_target"
    ],
    "parse_rttm_for_ms_targets": [
      "self",
      "sample"
    ],
    "get_uniq_id_with_range": [
      "self",
      "sample",
      "deci"
    ],
    "get_ms_seg_timestamps": [
      "self",
      "sample"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "_AudioMSDDInferDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "parse_rttm_multiscale": [
      "self",
      "sample"
    ],
    "get_diar_target_labels_from_fr_target": [
      "self",
      "uniq_id",
      "fr_level_target"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "_msdd_train_collate_fn": [
    "self",
    "batch"
  ],
  "_msdd_infer_collate_fn": [
    "self",
    "batch"
  ],
  "AudioToSpeechMSDDTrainDataset": {
    "__init__": [
      "self"
    ],
    "msdd_train_collate_fn": [
      "self",
      "batch"
    ]
  },
  "AudioToSpeechMSDDInferDataset": {
    "__init__": [
      "self"
    ],
    "msdd_infer_collate_fn": [
      "self",
      "batch"
    ]
  },
  "_AudioToSpeechE2ESpkDiarDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "get_frame_count_from_time_series_length": [
      "self",
      "seq_len"
    ],
    "get_uniq_id_with_range": [
      "self",
      "sample",
      "deci"
    ],
    "parse_rttm_for_targets_and_lens": [
      "self",
      "rttm_file",
      "offset",
      "duration",
      "target_len"
    ],
    "get_soft_targets_seg": [
      "self",
      "feat_level_target",
      "target_len"
    ],
    "get_segment_timestamps": [
      "self",
      "duration",
      "offset",
      "sample_rate"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "_eesd_train_collate_fn": [
    "self",
    "batch"
  ],
  "AudioToSpeechE2ESpkDiarDataset": {
    "__init__": [
      "self"
    ],
    "eesd_train_collate_fn": [
      "self",
      "batch"
    ]
  },
  "AudioNoiseItem": {},
  "AudioNoiseBatch": {},
  "_parse_manifest_item": [
    "line",
    "manifest_file"
  ],
  "_audio_noise_collate_fn": [
    "batch",
    "batch_augmentor"
  ],
  "load_noise_manifest": [
    "noise_manifest"
  ],
  "load_noise_audio": [
    "sample",
    "sample_rate",
    "max_audio_len",
    "pad_to_max",
    "min_white_noise_db",
    "max_white_noise_db",
    "max_trial"
  ],
  "sample_noise": [
    "noise_data",
    "sample_rate",
    "max_audio_len",
    "max_trial"
  ],
  "pad_audio": [
    "audio",
    "min_len",
    "pad_audio_mode"
  ],
  "AudioNoiseDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "noise_manifest",
      "batch_augmentor",
      "min_audio_len_secs",
      "pad_audio_mode"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "TarredAudioNoiseDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "noise_manifest",
      "batch_augmentor",
      "min_audio_len_secs",
      "pad_audio_mode"
    ],
    "_build_sample": [
      "self",
      "tup"
    ],
    "_pad_audio": [
      "self",
      "audio"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "LhotseAudioNoiseDataset": {
    "__init__": [
      "self",
      "noise_manifest",
      "batch_augmentor_cfg"
    ],
    "__getitem__": [
      "self",
      "cuts"
    ]
  },
  "get_audio_noise_dataset": [
    "config",
    "augmentor",
    "batch_augmentor"
  ],
  "get_concat_audio_noise_dataset": [
    "config",
    "global_rank",
    "world_size",
    "augmentor",
    "batch_augmentor"
  ],
  "get_tarred_audio_noise_dataset": [
    "config",
    "shuffle_n",
    "global_rank",
    "world_size",
    "augmentor",
    "batch_augmentor"
  ],
  "get_concat_tarred_audio_noise_dataset": [
    "config",
    "shuffle_n",
    "global_rank",
    "world_size",
    "augmentor",
    "batch_augmentor"
  ],
  "get_audio_noise_dataset_from_config": [
    "config",
    "global_rank",
    "world_size"
  ],
  "repeat_signal": [
    "signal",
    "sig_len",
    "required_length"
  ],
  "normalize": [
    "signal"
  ],
  "count_occurence": [
    "manifest_file_id"
  ],
  "_fixed_seq_collate_fn": [
    "self",
    "batch"
  ],
  "_vad_frame_seq_collate_fn": [
    "self",
    "batch"
  ],
  "_AudioLabelDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "AudioToClassificationLabelDataset": {
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "AudioToSpeechLabelDataset": {
    "__init__": [
      "self"
    ],
    "fixed_seq_collate_fn": [
      "self",
      "batch"
    ],
    "vad_frame_seq_collate_fn": [
      "self",
      "batch"
    ]
  },
  "_TarredAudioLabelDataset": {
    "__init__": [
      "self"
    ],
    "_filter": [
      "self",
      "iterator"
    ],
    "_build_sample": [
      "self",
      "tup"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "TarredAudioToClassificationLabelDataset": {
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "TarredAudioToSpeechLabelDataset": {
    "__init__": [
      "self"
    ],
    "fixed_seq_collate_fn": [
      "self",
      "batch"
    ],
    "sliced_seq_collate_fn": [
      "self",
      "batch"
    ],
    "vad_frame_seq_collate_fn": [
      "self",
      "batch"
    ]
  },
  "AudioToMultiLabelDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "_get_label_set": [
      "self"
    ],
    "_label_str_to_tensor": [
      "self",
      "label_str"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "TarredAudioToMultiLabelDataset": {
    "__init__": [
      "self"
    ],
    "_get_label_set": [
      "self"
    ],
    "_label_str_to_tensor": [
      "self",
      "label_str"
    ],
    "_filter": [
      "self",
      "iterator"
    ],
    "_build_sample": [
      "self",
      "tup"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "AudioPairToLabelDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "fixed_seq_collate_fn": [
      "self",
      "batch"
    ]
  },
  "PromptedAudioToTextMiniBatch": {
    "get_decoder_inputs_outputs": [
      "self"
    ]
  },
  "PromptedAudioToTextLhotseDataset": {
    "__init__": [
      "self",
      "tokenizer",
      "prompt",
      "enable_chunking"
    ],
    "__getitem__": [
      "self",
      "cuts"
    ],
    "_collate_tokens": [
      "self",
      "tokens"
    ],
    "_find_optimal_chunk_size": [
      "self",
      "total_len",
      "min_sec",
      "max_sec",
      "sample_rate",
      "overlap_sec"
    ],
    "_chunk_waveform": [
      "self",
      "waveform",
      "chunk_size",
      "overlap_sec",
      "sample_rate"
    ]
  },
  "ProbablyIncorrectLanguageKeyError": {},
  "_drop_in_memory_data": [
    "cuts",
    "_fields"
  ],
  "FrameCtmUnit": {
    "__repr__": [
      "self"
    ],
    "end_frame": [
      "self"
    ],
    "to_ctm_str": [
      "self",
      "time_per_frame"
    ]
  },
  "ASRCTMPredictionWriter": {
    "__init__": [
      "self",
      "dataset",
      "output_file",
      "output_ctm_dir",
      "time_per_frame"
    ],
    "write_ctm": [
      "self",
      "name",
      "filepath",
      "frameCtmUnits"
    ],
    "write_on_batch_end": [
      "self",
      "trainer",
      "pl_module",
      "prediction",
      "batch_indices",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ]
  },
  "LhotseSpeechToTextBpeDatasetWithPrompt": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "tokenizer",
      "cfg"
    ],
    "_get_prompt_index": [
      "self",
      "prompt_key"
    ],
    "prompt_to_target": [
      "self",
      "cut",
      "num_prompts",
      "window_stride",
      "subsampling_factor"
    ],
    "get_hidden_length_from_sample_length": [
      "self",
      "num_samples"
    ],
    "__getitem__": [
      "self",
      "cuts"
    ]
  },
  "get_hf_audio_to_text_bpe_dataset": [
    "config",
    "global_rank",
    "world_size",
    "tokenizer",
    "augmentor"
  ],
  "get_hf_audio_to_text_char_dataset": [
    "config",
    "global_rank",
    "world_size",
    "augmentor"
  ],
  "HFTextProcessor": {
    "__init__": [
      "self",
      "parser",
      "bos_id",
      "eos_id",
      "pad_id",
      "normalize_text",
      "symbols_to_keep"
    ],
    "process_text": [
      "self",
      "text",
      "lang"
    ]
  },
  "_HFAudioTextDataset": {
    "__init__": [
      "self",
      "audio_key",
      "text_key",
      "sample_rate_key",
      "hf_data_cfg",
      "parser",
      "sample_rate",
      "augmentor",
      "trim",
      "bos_id",
      "eos_id",
      "pad_id",
      "return_sample_id",
      "channel_selector",
      "normalize_db",
      "ref_channel",
      "id_key",
      "normalize_text",
      "symbols_to_keep"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ]
  },
  "HFAudioToCharDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "audio_key",
      "text_key",
      "sample_rate_key",
      "hf_data_cfg",
      "labels",
      "sample_rate",
      "augmentor",
      "trim",
      "bos_id",
      "eos_id",
      "pad_id",
      "return_sample_id",
      "channel_selector",
      "normalize_db",
      "ref_channel",
      "parser",
      "blank_index",
      "unk_index",
      "normalize",
      "id_key",
      "normalize_text",
      "symbols_to_keep"
    ]
  },
  "HFAudioToBPEDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "audio_key",
      "text_key",
      "sample_rate_key",
      "hf_data_cfg",
      "tokenizer",
      "sample_rate",
      "augmentor",
      "trim",
      "return_sample_id",
      "channel_selector",
      "normalize_db",
      "ref_channel",
      "use_start_end_token",
      "id_key",
      "normalize_text",
      "symbols_to_keep"
    ]
  },
  "_HFIterableAudioTextDataset": {
    "__init__": [
      "self",
      "audio_key",
      "text_key",
      "sample_rate_key",
      "hf_data_cfg",
      "parser",
      "sample_rate",
      "augmentor",
      "trim",
      "bos_id",
      "eos_id",
      "pad_id",
      "return_sample_id",
      "channel_selector",
      "normalize_db",
      "ref_channel",
      "id_key",
      "global_rank",
      "world_size",
      "shuffle_n",
      "shuffle_seed",
      "normalize_text",
      "symbols_to_keep"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "_collate_fn": [
      "self",
      "batch"
    ],
    "_build_sample": [
      "self",
      "sample"
    ]
  },
  "HFIterableAudioToCharDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "labels",
      "audio_key",
      "text_key",
      "sample_rate_key",
      "hf_data_cfg",
      "sample_rate",
      "augmentor",
      "trim",
      "bos_id",
      "eos_id",
      "pad_id",
      "return_sample_id",
      "id_key",
      "channel_selector",
      "normalize_db",
      "ref_channel",
      "global_rank",
      "world_size",
      "shuffle_n",
      "shuffle_seed",
      "parser",
      "blank_index",
      "unk_index",
      "normalize",
      "normalize_text",
      "symbols_to_keep"
    ]
  },
  "HFIterableAudioToBPEDataset": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "audio_key",
      "text_key",
      "sample_rate_key",
      "hf_data_cfg",
      "tokenizer",
      "sample_rate",
      "augmentor",
      "trim",
      "return_sample_id",
      "id_key",
      "channel_selector",
      "normalize_db",
      "ref_channel",
      "global_rank",
      "world_size",
      "shuffle_n",
      "shuffle_seed",
      "use_start_end_token",
      "normalize_text",
      "symbols_to_keep"
    ]
  },
  "CtcTopologyCompiler": {
    "__init__": [
      "self",
      "num_classes",
      "blank",
      "topo_type",
      "topo_with_self_loops",
      "device"
    ],
    "to": [
      "self",
      "device"
    ],
    "compile": [
      "self",
      "targets",
      "target_lengths"
    ]
  },
  "CtcNumGraphCompiler": {
    "__init__": [
      "self",
      "num_classes",
      "blank",
      "topo_type",
      "topo_with_self_loops",
      "device",
      "aux_graph"
    ],
    "compile": [
      "self",
      "targets",
      "target_lengths",
      "aux_graph"
    ]
  },
  "MmiGraphCompiler": {
    "__init__": [
      "self",
      "num_classes",
      "blank",
      "topo_type",
      "topo_with_self_loops",
      "device",
      "aux_graph"
    ],
    "to": [
      "self",
      "device"
    ],
    "compile": [
      "self",
      "targets",
      "target_lengths",
      "aux_graph"
    ]
  },
  "RnntTopologyCompiler": {
    "__init__": [
      "self",
      "num_classes",
      "blank",
      "topo_type",
      "topo_with_self_loops",
      "device",
      "max_adapter_length"
    ],
    "compile": [
      "self",
      "targets",
      "target_lengths"
    ]
  },
  "force_float32_context": [],
  "GraphTransducerLossBase": {
    "__init__": [
      "self",
      "use_grid_implementation",
      "connect_composed",
      "double_scores",
      "cast_to_float32"
    ],
    "get_unit_schema": [
      "self",
      "units_tensor",
      "vocab_size"
    ],
    "get_temporal_schema": [
      "self",
      "num_frames",
      "vocab_size",
      "device"
    ],
    "get_grid": [
      "self",
      "units_tensor",
      "num_frames",
      "vocab_size"
    ],
    "get_composed_lattice": [
      "self",
      "units_tensor",
      "num_frames",
      "vocab_size"
    ],
    "get_graphs_batched": [
      "self",
      "source_lengths",
      "targets",
      "target_lengths",
      "vocab_size"
    ],
    "get_batch_indices": [
      "self",
      "target_fsas_vec"
    ],
    "get_logits_indices": [
      "self",
      "target_fsas_vec",
      "logits_shape"
    ]
  },
  "GraphRnntLoss": {
    "__init__": [
      "self",
      "blank",
      "use_grid_implementation",
      "connect_composed",
      "double_scores",
      "cast_to_float32",
      "return_graph",
      "use_triton"
    ],
    "get_unit_schema": [
      "self",
      "units_tensor",
      "vocab_size"
    ],
    "get_temporal_schema": [
      "self",
      "num_frames",
      "vocab_size",
      "device"
    ],
    "relabel_states": [
      "states",
      "n",
      "m"
    ],
    "get_grid": [
      "self",
      "units_tensor",
      "num_frames",
      "vocab_size"
    ],
    "get_weighted_graphs": [
      "self",
      "logits",
      "targets",
      "source_lengths",
      "target_lengths",
      "use_graph_weight"
    ],
    "forward": [
      "self",
      "acts",
      "labels",
      "act_lens",
      "label_lens"
    ]
  },
  "GraphIntersectDenseConfig": {},
  "GraphModuleConfig": {},
  "ASRK2Mixin": {
    "_init_k2": [
      "self"
    ],
    "update_k2_modules": [
      "self",
      "input_cfg"
    ],
    "_forward_k2_post_processing": [
      "self",
      "log_probs",
      "encoded_length",
      "greedy_predictions"
    ]
  },
  "MAPLoss": {
    "__init__": [
      "self",
      "num_classes",
      "blank",
      "reduction",
      "cfg",
      "topo_type",
      "topo_with_self_loops",
      "token_lm",
      "intersect_pruned",
      "intersect_conf",
      "boost_coeff"
    ],
    "update_graph": [
      "self",
      "graph"
    ],
    "_intersect_calc_scores_impl_exact_opt": [
      "self",
      "dense_fsa_vec",
      "num_graphs",
      "den_graph",
      "return_lats"
    ],
    "_intersect_calc_scores_impl_pruned": [
      "self",
      "dense_fsa_vec",
      "num_graphs",
      "den_graph",
      "return_lats"
    ],
    "_intersect_calc_scores": [
      "self",
      "emissions_graphs",
      "supervision_graphs",
      "supervisions"
    ]
  },
  "CtcMmiLoss": {
    "__init__": [
      "self",
      "num_classes",
      "blank",
      "reduction",
      "cfg",
      "topo_type",
      "topo_with_self_loops",
      "token_lm",
      "intersect_pruned",
      "intersect_conf",
      "boost_coeff"
    ],
    "update_graph": [
      "self",
      "graph"
    ]
  },
  "MLLoss": {
    "__init__": [
      "self",
      "num_classes",
      "blank",
      "reduction",
      "cfg",
      "topo_type",
      "topo_with_self_loops"
    ],
    "_prepare_graphs_for_intersection": [
      "self",
      "log_probs",
      "targets",
      "input_lengths",
      "target_lengths"
    ],
    "_intersect_calc_scores": [
      "self",
      "emissions_graphs",
      "supervision_graphs",
      "supervisions"
    ],
    "forward": [
      "self",
      "log_probs",
      "targets",
      "input_lengths",
      "target_lengths"
    ]
  },
  "CtcLoss": {
    "__init__": [
      "self",
      "num_classes",
      "blank",
      "reduction",
      "cfg",
      "topo_type",
      "topo_with_self_loops"
    ]
  },
  "RnntLoss": {
    "__init__": [
      "self",
      "num_classes",
      "blank",
      "reduction",
      "cfg",
      "topo_type",
      "topo_with_self_loops",
      "predictor_window_size",
      "predictor_step_size"
    ],
    "forward": [
      "self",
      "log_probs",
      "targets",
      "input_lengths",
      "target_lengths"
    ]
  },
  "GradExpNormalize": {
    "forward": [
      "ctx",
      "log_probs",
      "input_lengths",
      "reduction"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "GradInsert": {
    "forward": [
      "ctx",
      "input_tensor",
      "output_tensor",
      "grad",
      "mask"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "PartialGrad": {
    "__init__": [
      "self",
      "func"
    ],
    "forward": [
      "self",
      "input_tensor",
      "targets",
      "input_lengths",
      "target_lengths"
    ]
  },
  "BaseDecoder": {
    "__init__": [
      "self",
      "num_classes",
      "blank",
      "cfg",
      "intersect_pruned",
      "intersect_conf",
      "topo_type",
      "topo_with_self_loops",
      "device"
    ],
    "to": [
      "self",
      "device"
    ],
    "update_graph": [
      "self",
      "graph"
    ],
    "_decode_impl": [
      "self",
      "log_probs",
      "supervisions",
      "return_lattices",
      "return_ilabels",
      "output_aligned"
    ],
    "decode": [
      "self",
      "log_probs",
      "log_probs_length",
      "return_lattices",
      "return_ilabels",
      "output_aligned"
    ],
    "align": [
      "self",
      "log_probs",
      "log_probs_length",
      "targets",
      "target_lengths",
      "return_lattices",
      "return_ilabels",
      "output_aligned"
    ]
  },
  "CtcDecoder": {
    "__init__": [
      "self",
      "num_classes",
      "blank",
      "cfg",
      "intersect_pruned",
      "intersect_conf",
      "topo_type",
      "topo_with_self_loops",
      "device"
    ]
  },
  "RnntAligner": {
    "__init__": [
      "self",
      "num_classes",
      "blank",
      "cfg",
      "intersect_pruned",
      "intersect_conf",
      "topo_type",
      "topo_with_self_loops",
      "predictor_window_size",
      "predictor_step_size",
      "device"
    ],
    "decode": [
      "self",
      "log_probs",
      "log_probs_length",
      "return_lattices",
      "return_ilabels",
      "output_aligned"
    ],
    "align": [
      "self",
      "log_probs",
      "log_probs_length",
      "targets",
      "target_lengths",
      "return_lattices",
      "return_ilabels",
      "output_aligned"
    ]
  },
  "TokenLMDecoder": {
    "__init__": [
      "self",
      "num_classes",
      "blank",
      "cfg",
      "token_lm",
      "intersect_pruned",
      "intersect_conf",
      "topo_type",
      "topo_with_self_loops",
      "device"
    ],
    "update_graph": [
      "self",
      "graph"
    ]
  },
  "K2WfstDecoder": {
    "__init__": [
      "self",
      "lm_fst",
      "decoding_mode",
      "beam_size",
      "config",
      "tokenword_disambig_id",
      "lm_weight",
      "nbest_size",
      "device"
    ],
    "_set_decoder_config": [
      "self",
      "config"
    ],
    "_set_decoding_mode": [
      "self",
      "decoding_mode"
    ],
    "_init_decoder": [
      "self"
    ],
    "_beam_size_setter": [
      "self",
      "value"
    ],
    "_lm_weight_setter": [
      "self",
      "value"
    ],
    "nbest_size": [
      "self",
      "value"
    ],
    "_nbest_size_setter": [
      "self",
      "value"
    ],
    "_decoding_mode_setter": [
      "self",
      "value"
    ],
    "_decode_lattice": [
      "self",
      "emissions_fsas",
      "order"
    ],
    "decode": [
      "self",
      "log_probs",
      "log_probs_length"
    ],
    "_post_decode": [
      "self",
      "hypotheses"
    ],
    "calibrate_lm_weight": [
      "self",
      "log_probs",
      "log_probs_length",
      "reference_texts"
    ],
    "calculate_oracle_wer": [
      "self",
      "log_probs",
      "log_probs_length",
      "reference_texts"
    ]
  },
  "create_supervision": [
    "input_lengths"
  ],
  "invert_permutation": [
    "indices"
  ],
  "make_non_pad_mask": [
    "input_lengths",
    "seq_len"
  ],
  "make_non_pad_mask_3d": [
    "lengths_x",
    "lengths_y",
    "max_length_x",
    "max_length_y"
  ],
  "ragged_to_tensor_2axes_simple": [
    "rt"
  ],
  "load_graph": [
    "graph_path"
  ],
  "intersect_with_self_loops": [
    "base_graph",
    "aux_graph"
  ],
  "compose_with_self_loops": [
    "base_graph",
    "aux_graph"
  ],
  "create_sparse_wrapped": [
    "indices",
    "values",
    "size",
    "min_col_index"
  ],
  "prep_padded_densefsavec": [
    "log_softmax",
    "supervisions"
  ],
  "shift_labels_inpl": [
    "lattices",
    "shift"
  ],
  "reset_properties_fsa": [
    "graph"
  ],
  "add_self_loops": [
    "graph",
    "label",
    "mode"
  ],
  "get_arc_weights": [
    "graph"
  ],
  "get_tot_objf_and_finite_mask": [
    "tot_scores",
    "reduction"
  ],
  "get_uniform_rnnt_prune_ranges": [
    "encoded_lengths",
    "target_lengths",
    "window_size_with_blank",
    "step",
    "max_seq_len",
    "begin_only"
  ],
  "apply_rnnt_prune_ranges": [
    "encoder_outputs",
    "decoder_outputs",
    "ranges"
  ],
  "levenshtein_graph_k2": [
    "fsa",
    "ins_del_score"
  ],
  "CtcK2Mixin": {
    "_prepare_log_probs_and_targets": [
      "self",
      "log_probs",
      "input_lengths",
      "targets",
      "target_lengths"
    ],
    "_prepare_emissions_graphs": [
      "self",
      "log_probs",
      "supervisions"
    ],
    "_maybe_normalize_gradients": [
      "self",
      "log_probs",
      "input_lengths"
    ],
    "_extract_labels_and_probabilities": [
      "self",
      "shortest_path_fsas",
      "return_ilabels",
      "output_aligned"
    ]
  },
  "RnntK2Mixin": {
    "_prepare_log_probs_and_targets": [
      "self",
      "log_probs",
      "input_lengths",
      "targets",
      "target_lengths"
    ],
    "_prepare_emissions_graphs": [
      "self",
      "log_probs",
      "supervisions"
    ],
    "_maybe_normalize_gradients": [
      "self",
      "log_probs",
      "input_lengths"
    ]
  },
  "rnnt_logprobs_torch": [
    "logits",
    "targets",
    "blank_id"
  ],
  "GraphWTransducerLoss": {
    "__init__": [
      "self",
      "blank",
      "eps_weight",
      "last_blank_mode",
      "use_grid_implementation",
      "connect_composed",
      "double_scores",
      "cast_to_float32"
    ],
    "get_unit_schema": [
      "self",
      "units_tensor",
      "vocab_size"
    ],
    "get_temporal_schema": [
      "self",
      "num_frames",
      "vocab_size",
      "device"
    ],
    "get_grid": [
      "self",
      "units_tensor",
      "num_frames",
      "vocab_size"
    ],
    "forward": [
      "self",
      "acts",
      "labels",
      "act_lens",
      "label_lens"
    ]
  },
  "_rnnt_logprobs_fwd_kernel": [
    "logits_ptr",
    "targets_ptr",
    "source_lengths_ptr",
    "target_lengths_ptr",
    "max_source_len",
    "max_target_len_plus_1",
    "num_labels",
    "blank_id",
    "target_scores_ptr",
    "blank_scores_ptr",
    "BLOCK_SIZE"
  ],
  "_rnnt_logprobs_bwd_kernel": [
    "logits_ptr",
    "grad_logits_ptr",
    "targets_ptr",
    "source_lengths_ptr",
    "target_lengths_ptr",
    "max_source_len",
    "max_target_len_plus_1",
    "num_labels",
    "blank_id",
    "grad_target_scores_ptr",
    "grad_blank_scores_ptr",
    "BLOCK_SIZE"
  ],
  "RnntLogProbs": {
    "forward": [
      "ctx",
      "logits",
      "targets",
      "blank_id",
      "source_lengths",
      "target_lengths"
    ],
    "backward": [
      "ctx",
      "grad_target_scores",
      "grad_blank_scores"
    ]
  },
  "rnnt_logprobs_triton": [
    "logits",
    "targets",
    "blank_id",
    "source_lengths",
    "target_lengths"
  ],
  "build_topo": [
    "name",
    "tokens",
    "blank_num",
    "with_self_loops"
  ],
  "build_default_topo": [
    "tokens",
    "with_self_loops"
  ],
  "build_compact_topo": [
    "tokens",
    "with_self_loops"
  ],
  "build_shared_blank_topo": [
    "tokens",
    "with_self_loops"
  ],
  "build_minimal_topo": [
    "tokens"
  ],
  "RnntEmissionAdapterBuilder": {
    "__init__": [
      "self",
      "tokens",
      "blank_num",
      "eps_num"
    ],
    "__call__": [
      "self",
      "adapter_lengths"
    ],
    "_build_single_adapter": [
      "self",
      "adapter_length"
    ]
  },
  "ContextState": {
    "__init__": [
      "self",
      "id",
      "token",
      "token_score",
      "node_score",
      "output_score",
      "is_end",
      "level",
      "phrase",
      "ac_threshold"
    ]
  },
  "ContextGraph": {
    "__init__": [
      "self",
      "context_score",
      "depth_scaling",
      "ac_threshold"
    ],
    "_fill_fail_output": [
      "self"
    ],
    "build": [
      "self",
      "token_ids",
      "phrases",
      "scores",
      "ac_thresholds",
      "uniform_weights"
    ],
    "draw": [
      "self",
      "title",
      "filename",
      "symbol_table"
    ]
  },
  "Token": {},
  "WSHyp": {},
  "beam_pruning": [
    "next_tokens",
    "beam_threshold"
  ],
  "state_pruning": [
    "next_tokens"
  ],
  "find_best_hyps": [
    "spotted_words",
    "intersection_threshold"
  ],
  "get_ctc_word_alignment": [
    "logprob",
    "asr_model",
    "token_weight",
    "blank_idx"
  ],
  "filter_wb_hyps": [
    "best_hyp_list",
    "word_alignment"
  ],
  "run_word_spotter": [
    "logprobs",
    "context_graph",
    "asr_model",
    "blank_idx",
    "beam_threshold",
    "cb_weight",
    "ctc_ali_token_weight",
    "keyword_threshold",
    "blank_threshold",
    "non_blank_threshold"
  ],
  "BoostingTreeModelConfig": {
    "is_empty": [
      "cfg"
    ]
  },
  "TBranch": {},
  "BoostingTreeStorage": {
    "__post_init__": [
      "self",
      "num_states_max",
      "num_arcs_max"
    ],
    "_add_tbranches_first_order": [
      "self",
      "tbranches"
    ],
    "_add_tbranches_next_order": [
      "self",
      "tbranches"
    ],
    "_start_adding_tbranches_for_order": [
      "self",
      "order"
    ],
    "_end_adding_tbranches_for_order": [
      "self",
      "order"
    ],
    "sanity_check": [
      "self"
    ]
  },
  "BoostingTreeConfig": {},
  "GPUBoostingTreeModel": {
    "START_STATE": [],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_read_context_graph": [
      "cls",
      "context_graph"
    ],
    "from_context_graph": [
      "cls",
      "context_graph",
      "vocab_size",
      "unk_score",
      "final_eos_score",
      "use_triton",
      "uniform_weights"
    ],
    "from_boosting_tree_np": [
      "cls",
      "boosting_tree_np",
      "use_triton"
    ],
    "advance": [
      "self",
      "states",
      "eos_id"
    ],
    "get_final": [
      "self",
      "states"
    ],
    "dummy_boosting_tree": [
      "cls",
      "vocab_size",
      "use_triton"
    ],
    "get_alternative_transcripts": [
      "cls",
      "cfg",
      "tokenizer",
      "phrase",
      "is_aggregate_tokenizer"
    ],
    "from_config": [
      "cls",
      "cfg",
      "tokenizer"
    ]
  },
  "merge_alignment_with_ws_hyps": [
    "candidate",
    "asr_model",
    "cb_results",
    "decoder_type",
    "intersection_threshold",
    "blank_idx",
    "print_stats",
    "bow"
  ],
  "compute_fscore": [
    "recognition_results_manifest",
    "key_words_list",
    "eps",
    "print_stats"
  ],
  "ContextGraphCTC": {
    "__init__": [
      "self",
      "blank_id"
    ],
    "add_to_graph": [
      "self",
      "word_items"
    ],
    "draw": [
      "self",
      "title",
      "symbol_table"
    ]
  },
  "FusedBatchNorm1d": {
    "__init__": [
      "self",
      "num_features"
    ],
    "from_batchnorm": [
      "cls",
      "bn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_get_module_by_name": [
    "module",
    "full_layer_name"
  ],
  "replace_bn_with_fused_bn": [
    "module",
    "full_layer_name"
  ],
  "replace_bn_with_fused_bn_all": [
    "model"
  ],
  "NON_EXISTENT_LABEL_VALUE": [],
  "INACTIVE_SCORE": [],
  "BacthedBeamCTCState": {
    "__init__": [
      "self",
      "batch_size",
      "beam_size",
      "max_time",
      "vocab_size",
      "device",
      "float_dtype",
      "blank_index"
    ],
    "need_reinit": [
      "self",
      "encoder_output_projected"
    ]
  },
  "SeparateGraphsBatchedBeamCTC": {},
  "BatchedBeamCTCComputer": {
    "INITIAL_MAX_TIME": [],
    "CUDA_PROGRAM_NAME": [],
    "__init__": [
      "self",
      "blank_index",
      "beam_size",
      "return_best_hypothesis",
      "preserve_alignments",
      "compute_timestamps",
      "fusion_models",
      "fusion_models_alpha",
      "beam_beta",
      "beam_threshold",
      "allow_cuda_graphs"
    ],
    "force_cuda_graphs_mode": [
      "self",
      "mode"
    ],
    "maybe_enable_cuda_graphs": [
      "self"
    ],
    "disable_cuda_graphs": [
      "self"
    ],
    "reset_cuda_graphs_state": [
      "self"
    ],
    "batched_beam_search_torch": [
      "self",
      "decoder_outputs",
      "decoder_output_lengths"
    ],
    "batched_beam_search_cuda_graphs": [
      "self",
      "decoder_outputs",
      "decoder_output_lengths"
    ],
    "_create_process_batch_kernel": [
      "cls"
    ],
    "_graph_reinitialize": [
      "self",
      "decoder_outputs",
      "decoder_output_lengths"
    ],
    "_partial_graphs_compile": [
      "self"
    ],
    "_full_graph_compile": [
      "self"
    ],
    "_before_process_batch": [
      "self"
    ],
    "_process_batch": [
      "self"
    ],
    "_after_process_batch": [
      "self"
    ],
    "__call__": [
      "self",
      "x",
      "out_len"
    ]
  },
  "StackingSubsampling": {
    "__init__": [
      "self",
      "subsampling_factor",
      "feat_in",
      "feat_out",
      "norm"
    ],
    "get_sampling_frames": [
      "self"
    ],
    "get_streaming_cache_size": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "ConvSubsampling": {
    "__init__": [
      "self",
      "subsampling",
      "subsampling_factor",
      "feat_in",
      "feat_out",
      "conv_channels",
      "subsampling_conv_chunking_factor",
      "activation",
      "is_causal"
    ],
    "get_sampling_frames": [
      "self"
    ],
    "get_streaming_cache_size": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ],
    "reset_parameters": [
      "self"
    ],
    "conv_split_by_batch": [
      "self",
      "x",
      "lengths"
    ],
    "conv_split_by_channel": [
      "self",
      "x"
    ],
    "channel_chunked_conv": [
      "self",
      "conv",
      "chunk_size",
      "x"
    ],
    "change_subsampling_conv_chunking_factor": [
      "self",
      "subsampling_conv_chunking_factor"
    ]
  },
  "calc_length": [
    "lengths",
    "all_paddings",
    "kernel_size",
    "stride",
    "ceil_mode",
    "repeat_num"
  ],
  "TimeReductionModule": {
    "__init__": [
      "self",
      "d_model",
      "out_dim",
      "kernel_size",
      "stride"
    ],
    "forward": [
      "self",
      "x",
      "att_mask",
      "pad_mask"
    ],
    "reset_parameters": [
      "self"
    ]
  },
  "SubsamplingReductionModule": {
    "__init__": [
      "self",
      "reduction",
      "d_model",
      "reduction_factor"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "apply_channel_mask": [
    "tensor",
    "mask"
  ],
  "calculate_conv_output_size": [
    "input_size",
    "kernel_size",
    "stride",
    "padding"
  ],
  "MaskedConvSequential": {
    "forward": [
      "self",
      "x",
      "lengths"
    ],
    "_create_mask": [
      "self",
      "tensor",
      "lengths"
    ]
  },
  "AbstractCTCDecoding": {
    "__init__": [
      "self",
      "decoding_cfg",
      "blank_id",
      "supported_punctuation"
    ],
    "tokenizer_type": [
      "self"
    ],
    "ctc_decoder_predictions_tensor": [
      "self",
      "decoder_outputs",
      "decoder_lengths",
      "fold_consecutive",
      "return_hypotheses"
    ],
    "decode_hypothesis": [
      "self",
      "hypotheses_list",
      "fold_consecutive"
    ],
    "compute_confidence": [
      "self",
      "hypotheses_list"
    ],
    "decode_tokens_to_str": [
      "self",
      "tokens"
    ],
    "decode_ids_to_tokens": [
      "self",
      "tokens"
    ],
    "decode_ids_to_str": [
      "self",
      "tokens"
    ],
    "decode_tokens_to_str_with_strip_punctuation": [
      "self",
      "tokens"
    ],
    "compute_ctc_timestamps": [
      "self",
      "hypothesis",
      "timestamp_type"
    ],
    "_compute_offsets": [
      "hypothesis",
      "token_lengths",
      "ctc_token"
    ],
    "_refine_timestamps": [
      "encoded_char_offsets",
      "char_offsets",
      "supported_punctuation"
    ],
    "preserve_alignments": [
      "self",
      "value"
    ],
    "compute_timestamps": [
      "self",
      "value"
    ],
    "preserve_frame_confidence": [
      "self",
      "value"
    ]
  },
  "CTCDecoding": {
    "__init__": [
      "self",
      "decoding_cfg",
      "vocabulary"
    ],
    "tokenizer_type": [
      "self"
    ],
    "_aggregate_token_confidence": [
      "self",
      "hypothesis"
    ],
    "decode_tokens_to_str": [
      "self",
      "tokens"
    ],
    "decode_ids_to_tokens": [
      "self",
      "tokens"
    ]
  },
  "CTCBPEDecoding": {
    "__init__": [
      "self",
      "decoding_cfg",
      "tokenizer"
    ],
    "tokenizer_type": [
      "self"
    ],
    "_aggregate_token_confidence": [
      "self",
      "hypothesis"
    ],
    "decode_tokens_to_str": [
      "self",
      "tokens"
    ],
    "decode_ids_to_tokens": [
      "self",
      "tokens"
    ]
  },
  "CTCDecodingConfig": {},
  "CTCBPEDecodingConfig": {},
  "pack_hypotheses": [
    "hypotheses",
    "beam_hypotheses",
    "scores"
  ],
  "_states_to_device": [
    "dec_state",
    "device"
  ],
  "AEDBeamInfer": {
    "__init__": [
      "self",
      "transformer_decoder",
      "log_softmax_module",
      "tokenizer",
      "search_type",
      "return_best_hypothesis",
      "preserve_alignments"
    ],
    "__call__": [
      "self"
    ],
    "forward": [
      "self",
      "encoder_hidden_states",
      "encoder_input_mask",
      "decoder_input_ids",
      "partial_hypotheses"
    ],
    "set_decoding_type": [
      "self",
      "decoding_type"
    ]
  },
  "TransformerAEDBeamInfer": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "transformer_decoder",
      "log_softmax_module",
      "tokenizer",
      "search_type",
      "beam_size",
      "length_penalty",
      "max_generation_delta",
      "return_best_hypothesis",
      "preserve_alignments",
      "ngram_lm_model",
      "ngram_lm_alpha",
      "boosting_tree",
      "boosting_tree_alpha"
    ],
    "forward": [
      "self",
      "encoder_hidden_states",
      "encoder_input_mask",
      "decoder_input_ids",
      "partial_hypotheses"
    ],
    "format_hypotheses": [
      "self",
      "packed_result",
      "decoder_input_ids"
    ]
  },
  "AEDBeamInferConfig": {},
  "INF_VAL": [],
  "RelPositionMultiHeadAttention": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "dropout_rate",
      "pos_bias_u",
      "pos_bias_v",
      "max_cache_len",
      "use_bias",
      "use_pytorch_sdpa",
      "use_pytorch_sdpa_backends"
    ],
    "rel_shift": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask",
      "pos_emb",
      "cache"
    ]
  },
  "RelPositionMultiHeadAttentionLongformer": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "dropout_rate",
      "pos_bias_u",
      "pos_bias_v",
      "att_context_size",
      "max_cache_len",
      "global_tokens",
      "global_tokens_spacing",
      "global_attn_separate",
      "use_bias",
      "use_pytorch_sdpa",
      "use_pytorch_sdpa_backends"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "pad_mask",
      "pos_emb",
      "cache"
    ],
    "_get_global_attn_indices": [
      "self",
      "is_index_global_attn"
    ],
    "_compute_global_key_attn": [
      "self",
      "key",
      "query",
      "max_num_global_attn_indices",
      "is_index_global_attn_nonzero",
      "is_local_index_global_attn_nonzero",
      "is_local_index_no_global_attn_nonzero"
    ],
    "_compute_attn_output_with_global_indices": [
      "self",
      "value",
      "attn_probs",
      "max_num_global_attn_indices",
      "is_index_global_attn_nonzero",
      "is_local_index_global_attn_nonzero",
      "w"
    ],
    "_compute_out_global_to_all": [
      "self",
      "query",
      "key",
      "value",
      "max_num_global_attn_indices",
      "is_local_index_global_attn_nonzero",
      "is_index_global_attn_nonzero",
      "is_local_index_no_global_attn_nonzero",
      "is_index_masked"
    ],
    "_skew": [
      "self",
      "x",
      "direction",
      "padding_value"
    ],
    "_skew2": [
      "self",
      "x",
      "padding_value"
    ],
    "_chunk_overlap": [
      "self",
      "x",
      "w"
    ],
    "_get_invalid_locations_mask": [
      "self",
      "w",
      "device"
    ],
    "mask_invalid_locations": [
      "self",
      "input_tensor",
      "w"
    ],
    "sliding_chunks_matmul_qk": [
      "self",
      "q",
      "k",
      "w",
      "padding_value"
    ],
    "sliding_chunks_matmul_pv": [
      "self",
      "prob",
      "v",
      "w"
    ]
  },
  "PositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate",
      "max_len",
      "xscale",
      "dropout_rate_emb"
    ],
    "create_pe": [
      "self",
      "positions",
      "dtype"
    ],
    "extend_pe": [
      "self",
      "length",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "x",
      "cache_len"
    ]
  },
  "RelPositionalEncoding": {
    "extend_pe": [
      "self",
      "length",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "x",
      "cache_len"
    ]
  },
  "LocalAttRelPositionalEncoding": {
    "__init__": [
      "self",
      "att_context_size"
    ],
    "extend_pe": [
      "self",
      "length",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "x",
      "cache_len"
    ]
  },
  "SpecAugment": {
    "FREQ_AXIS": [],
    "TIME_AXIS": [],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "freq_masks",
      "time_masks",
      "freq_width",
      "time_width",
      "rng",
      "mask_value",
      "use_vectorized_code"
    ],
    "forward": [
      "self",
      "input_spec",
      "length"
    ],
    "_forward_legacy": [
      "self",
      "input_spec",
      "length"
    ],
    "_forward_vectorized": [
      "self",
      "input_spec",
      "length"
    ],
    "_apply_masks": [
      "self",
      "input_spec",
      "num_masks",
      "length",
      "width",
      "mask_value",
      "axis"
    ]
  },
  "SpecCutout": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "rect_masks",
      "rect_time",
      "rect_freq",
      "rng"
    ],
    "forward": [
      "self",
      "input_spec"
    ]
  },
  "CausalConv2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "padding_mode",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CausalConv1D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "padding_mode",
      "device",
      "dtype"
    ],
    "update_cache": [
      "self",
      "x",
      "cache"
    ],
    "forward": [
      "self",
      "x",
      "cache"
    ]
  },
  "AbstractMultiTaskDecoding": {
    "__init__": [
      "self",
      "decoding_cfg",
      "transformer_decoder",
      "log_softmax_module",
      "tokenizer"
    ],
    "change_strategy": [
      "self",
      "strategy"
    ],
    "decode_predictions_tensor": [
      "self",
      "encoder_hidden_states",
      "encoder_input_mask",
      "decoder_input_ids",
      "return_hypotheses",
      "partial_hypotheses"
    ],
    "decode_hypothesis": [
      "self",
      "hypotheses_list"
    ],
    "compute_confidence": [
      "self",
      "hypotheses_list"
    ],
    "_aggregate_token_confidence": [
      "self",
      "hypothesis"
    ],
    "decode_tokens_to_str": [
      "self",
      "tokens"
    ],
    "decode_ids_to_tokens": [
      "self",
      "tokens"
    ],
    "decode_tokens_to_lang": [
      "self",
      "tokens"
    ],
    "decode_ids_to_langs": [
      "self",
      "tokens"
    ]
  },
  "MultiTaskDecoding": {
    "__init__": [
      "self",
      "decoding_cfg",
      "transformer_decoder",
      "log_softmax_module",
      "tokenizer"
    ],
    "decode_tokens_to_str": [
      "self",
      "tokens",
      "lang"
    ],
    "decode_ids_to_str": [
      "self",
      "tokens"
    ],
    "decode_ids_to_tokens": [
      "self",
      "tokens"
    ],
    "decode_tokens_to_lang": [
      "self",
      "tokens"
    ],
    "decode_ids_to_langs": [
      "self",
      "tokens"
    ],
    "decode_hypothesis": [
      "self",
      "hypotheses_list"
    ]
  },
  "AEDStreamingDecodingConfig": {},
  "MultiTaskDecodingConfig": {},
  "_CUDA_PROGRAM_NAME": [],
  "create_outer_for_loop_kernel": [],
  "create_inner_while_loop_kernel": [],
  "RNNTGreedyDecodeCudaGraph": {
    "__init__": [
      "self",
      "max_symbols",
      "caller"
    ],
    "_reinitialize": [
      "self",
      "max_time",
      "batch_size",
      "encoder_output",
      "encoder_output_length"
    ],
    "__call__": [
      "self",
      "x",
      "out_len",
      "device",
      "partial_hypotheses"
    ]
  },
  "pack_wfst_hypotheses": [
    "hypotheses",
    "logits",
    "logitlen"
  ],
  "AbstractBeamCTCInfer": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "blank_id",
      "beam_size"
    ],
    "set_vocabulary": [
      "self",
      "vocab"
    ],
    "set_decoding_type": [
      "self",
      "decoding_type"
    ],
    "set_tokenizer": [
      "self",
      "tokenizer"
    ],
    "forward": [
      "self",
      "decoder_output",
      "decoder_lengths"
    ],
    "__call__": [
      "self"
    ]
  },
  "BeamCTCInfer": {
    "__init__": [
      "self",
      "blank_id",
      "beam_size",
      "search_type",
      "return_best_hypothesis",
      "preserve_alignments",
      "compute_timestamps",
      "ngram_lm_alpha",
      "beam_beta",
      "ngram_lm_model",
      "flashlight_cfg",
      "pyctcdecode_cfg"
    ],
    "forward": [
      "self",
      "decoder_output",
      "decoder_lengths"
    ],
    "default_beam_search": [
      "self",
      "x",
      "out_len"
    ],
    "_pyctcdecode_beam_search": [
      "self",
      "x",
      "out_len"
    ],
    "flashlight_beam_search": [
      "self",
      "x",
      "out_len"
    ],
    "set_decoding_type": [
      "self",
      "decoding_type"
    ]
  },
  "WfstCTCInfer": {
    "__init__": [
      "self",
      "blank_id",
      "beam_size",
      "search_type",
      "return_best_hypothesis",
      "preserve_alignments",
      "compute_timestamps",
      "decoding_mode",
      "open_vocabulary_decoding",
      "beam_width",
      "lm_weight",
      "device",
      "arpa_lm_path",
      "wfst_lm_path",
      "riva_decoding_cfg",
      "k2_decoding_cfg"
    ],
    "forward": [
      "self",
      "decoder_output",
      "decoder_lengths"
    ],
    "_prepare_decoding_lm_wfst": [
      "self"
    ],
    "_riva_decoding": [
      "self",
      "x",
      "out_len"
    ],
    "_k2_decoding": [
      "self",
      "x",
      "out_len"
    ]
  },
  "BeamBatchedCTCInfer": {
    "__init__": [
      "self",
      "blank_index",
      "beam_size",
      "return_best_hypothesis",
      "preserve_alignments",
      "compute_timestamps",
      "ngram_lm_alpha",
      "beam_beta",
      "beam_threshold",
      "ngram_lm_model",
      "boosting_tree",
      "boosting_tree_alpha",
      "allow_cuda_graphs",
      "tokenizer"
    ],
    "disable_cuda_graphs": [
      "self"
    ],
    "maybe_enable_cuda_graphs": [
      "self"
    ],
    "forward": [
      "self",
      "decoder_output",
      "decoder_lengths"
    ]
  },
  "PyCTCDecodeConfig": {},
  "FlashlightConfig": {},
  "BeamCTCInferConfig": {},
  "WfstCTCInferConfig": {},
  "_GreedyRNNTInfer": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "decoder_model",
      "joint_model",
      "blank_index",
      "max_symbols_per_step",
      "preserve_alignments",
      "preserve_frame_confidence",
      "confidence_method_cfg"
    ],
    "__call__": [
      "self"
    ],
    "_pred_step": [
      "self",
      "label",
      "hidden",
      "add_sos",
      "batch_size"
    ],
    "_joint_step": [
      "self",
      "enc",
      "pred",
      "log_normalize"
    ],
    "_joint_step_after_projection": [
      "self",
      "enc",
      "pred",
      "log_normalize"
    ]
  },
  "GreedyRNNTInfer": {
    "__init__": [
      "self",
      "decoder_model",
      "joint_model",
      "blank_index",
      "max_symbols_per_step",
      "preserve_alignments",
      "preserve_frame_confidence",
      "confidence_method_cfg"
    ],
    "forward": [
      "self",
      "encoder_output",
      "encoded_lengths",
      "partial_hypotheses"
    ],
    "_greedy_decode": [
      "self",
      "x",
      "out_len",
      "partial_hypotheses"
    ]
  },
  "GreedyBatchedRNNTInfer": {
    "__init__": [
      "self",
      "decoder_model",
      "joint_model",
      "blank_index",
      "max_symbols_per_step",
      "preserve_alignments",
      "preserve_frame_confidence",
      "confidence_method_cfg",
      "loop_labels",
      "use_cuda_graph_decoder",
      "fusion_models",
      "fusion_models_alpha"
    ],
    "disable_cuda_graphs": [
      "self"
    ],
    "maybe_enable_cuda_graphs": [
      "self"
    ],
    "forward": [
      "self",
      "encoder_output",
      "encoded_lengths",
      "partial_hypotheses"
    ],
    "_greedy_decode_blank_as_pad_loop_labels": [
      "self",
      "x",
      "out_len",
      "device",
      "partial_hypotheses"
    ],
    "_greedy_decode_blank_as_pad_loop_frames": [
      "self",
      "x",
      "out_len",
      "device",
      "partial_hypotheses"
    ],
    "_greedy_decode_masked": [
      "self",
      "x",
      "out_len",
      "device",
      "partial_hypotheses"
    ]
  },
  "ExportedModelGreedyBatchedRNNTInfer": {
    "__init__": [
      "self",
      "encoder_model",
      "decoder_joint_model",
      "max_symbols_per_step"
    ],
    "__call__": [
      "self",
      "audio_signal",
      "length"
    ],
    "_greedy_decode": [
      "self",
      "x",
      "out_len"
    ],
    "_setup_blank_index": [
      "self"
    ],
    "run_encoder": [
      "self",
      "audio_signal",
      "length"
    ],
    "run_decoder_joint": [
      "self",
      "enc_logits",
      "targets",
      "target_length"
    ],
    "_get_initial_states": [
      "self",
      "batchsize"
    ]
  },
  "ONNXGreedyBatchedRNNTInfer": {
    "__init__": [
      "self",
      "encoder_model",
      "decoder_joint_model",
      "max_symbols_per_step"
    ],
    "_setup_encoder_input_output_keys": [
      "self"
    ],
    "_setup_decoder_joint_input_output_keys": [
      "self"
    ],
    "_setup_blank_index": [
      "self"
    ],
    "run_encoder": [
      "self",
      "audio_signal",
      "length"
    ],
    "run_decoder_joint": [
      "self",
      "enc_logits",
      "targets",
      "target_length"
    ],
    "_get_initial_states": [
      "self",
      "batchsize"
    ]
  },
  "TorchscriptGreedyBatchedRNNTInfer": {
    "__init__": [
      "self",
      "encoder_model",
      "decoder_joint_model",
      "cfg",
      "device",
      "max_symbols_per_step"
    ],
    "_setup_encoder_input_keys": [
      "self"
    ],
    "_setup_decoder_joint_input_keys": [
      "self"
    ],
    "_setup_blank_index": [
      "self"
    ],
    "run_encoder": [
      "self",
      "audio_signal",
      "length"
    ],
    "run_decoder_joint": [
      "self",
      "enc_logits",
      "targets",
      "target_length"
    ],
    "_get_initial_states": [
      "self",
      "batchsize"
    ]
  },
  "GreedyMultiblankRNNTInfer": {
    "__init__": [
      "self",
      "decoder_model",
      "joint_model",
      "blank_index",
      "big_blank_durations",
      "max_symbols_per_step",
      "preserve_alignments",
      "preserve_frame_confidence",
      "confidence_method_cfg"
    ],
    "_greedy_decode": [
      "self",
      "x",
      "out_len",
      "partial_hypotheses"
    ]
  },
  "GreedyBatchedMultiblankRNNTInfer": {
    "__init__": [
      "self",
      "decoder_model",
      "joint_model",
      "blank_index",
      "big_blank_durations",
      "max_symbols_per_step",
      "preserve_alignments",
      "preserve_frame_confidence",
      "confidence_method_cfg"
    ],
    "_greedy_decode_blank_as_pad": [
      "self",
      "x",
      "out_len",
      "device",
      "partial_hypotheses"
    ],
    "_greedy_decode_masked": [
      "self",
      "x",
      "out_len",
      "device",
      "partial_hypotheses"
    ]
  },
  "GreedyRNNTInferConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "GreedyBatchedRNNTInferConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "GreedyTDTInfer": {
    "__init__": [
      "self",
      "decoder_model",
      "joint_model",
      "blank_index",
      "durations",
      "max_symbols_per_step",
      "preserve_alignments",
      "preserve_frame_confidence",
      "include_duration",
      "include_duration_confidence",
      "confidence_method_cfg"
    ],
    "forward": [
      "self",
      "encoder_output",
      "encoded_lengths",
      "partial_hypotheses"
    ],
    "_greedy_decode": [
      "self",
      "x",
      "out_len",
      "partial_hypotheses"
    ]
  },
  "GreedyBatchedTDTInfer": {
    "__init__": [
      "self",
      "decoder_model",
      "joint_model",
      "blank_index",
      "durations",
      "max_symbols_per_step",
      "preserve_alignments",
      "preserve_frame_confidence",
      "include_duration",
      "include_duration_confidence",
      "confidence_method_cfg",
      "use_cuda_graph_decoder",
      "fusion_models",
      "fusion_models_alpha"
    ],
    "forward": [
      "self",
      "encoder_output",
      "encoded_lengths",
      "partial_hypotheses"
    ],
    "_greedy_decode_masked": [
      "self",
      "x",
      "out_len",
      "device",
      "partial_hypotheses"
    ],
    "_greedy_decode_blank_as_pad_loop_labels": [
      "self",
      "x",
      "out_len",
      "device",
      "partial_hypotheses"
    ],
    "disable_cuda_graphs": [
      "self"
    ],
    "maybe_enable_cuda_graphs": [
      "self"
    ]
  },
  "BeamTDTInfer": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "decoder_model",
      "joint_model",
      "durations",
      "beam_size",
      "search_type",
      "score_norm",
      "return_best_hypothesis",
      "maes_num_steps",
      "maes_prefix_alpha",
      "maes_expansion_gamma",
      "maes_expansion_beta",
      "softmax_temperature",
      "preserve_alignments",
      "ngram_lm_model",
      "ngram_lm_alpha",
      "max_symbols_per_step",
      "blank_lm_score_mode",
      "pruning_mode",
      "allow_cuda_graphs"
    ],
    "__call__": [
      "self",
      "encoder_output",
      "encoded_lengths",
      "partial_hypotheses"
    ],
    "default_beam_search": [
      "self",
      "encoder_outputs",
      "encoded_lengths",
      "partial_hypotheses"
    ],
    "modified_adaptive_expansion_search": [
      "self",
      "encoder_outputs",
      "encoded_lengths",
      "partial_hypotheses"
    ],
    "merge_duplicate_hypotheses": [
      "self",
      "hypotheses"
    ],
    "set_decoding_type": [
      "self",
      "decoding_type"
    ],
    "prefix_search": [
      "self",
      "hypotheses",
      "encoder_output",
      "prefix_alpha"
    ],
    "compute_ngram_score": [
      "self",
      "current_lm_state",
      "label"
    ],
    "sort_nbest": [
      "self",
      "hyps"
    ]
  },
  "BeamBatchedTDTInfer": {
    "input_types": [
      "self"
    ],
    "__init__": [
      "self",
      "decoder_model",
      "joint_model",
      "durations",
      "blank_index",
      "beam_size",
      "search_type",
      "score_norm",
      "max_symbols_per_step",
      "preserve_alignments",
      "fusion_models",
      "fusion_models_alpha",
      "blank_lm_score_mode",
      "pruning_mode",
      "allow_cuda_graphs",
      "return_best_hypothesis"
    ],
    "disable_cuda_graphs": [
      "self"
    ],
    "maybe_enable_cuda_graphs": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "forward": [
      "self",
      "encoder_output",
      "encoded_lengths",
      "partial_hypotheses"
    ]
  },
  "AEDGreedyInfer": {
    "__init__": [
      "self",
      "transformer_decoder",
      "log_softmax_module",
      "tokenizer",
      "search_type",
      "preserve_alignments"
    ],
    "__call__": [
      "self"
    ],
    "forward": [
      "self",
      "encoder_hidden_states",
      "encoder_input_mask",
      "decoder_input_ids",
      "partial_hypotheses"
    ],
    "set_decoding_type": [
      "self",
      "decoding_type"
    ]
  },
  "TransformerAEDGreedyInfer": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "transformer_decoder",
      "log_softmax_module",
      "tokenizer",
      "temperature",
      "max_generation_delta",
      "preserve_alignments",
      "preserve_token_confidence",
      "confidence_method_cfg",
      "n_samples"
    ],
    "forward": [
      "self",
      "encoder_hidden_states",
      "encoder_input_mask",
      "decoder_input_ids",
      "partial_hypotheses"
    ],
    "format_hypotheses": [
      "self",
      "packed_result",
      "decoder_input_ids"
    ]
  },
  "AEDGreedyInferConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "MALSDState": {
    "__init__": [
      "self",
      "durations",
      "batch_size",
      "beam_size",
      "max_time",
      "encoder_dim",
      "max_symbols",
      "device",
      "float_dtype",
      "blank_index"
    ],
    "need_reinit": [
      "self",
      "encoder_output_projected"
    ]
  },
  "SeparateGraphsMALSD": {},
  "ModifiedALSDBatchedTDTComputer": {
    "INITIAL_MAX_TIME": [],
    "CUDA_PROGRAM_NAME": [],
    "__init__": [
      "self",
      "decoder",
      "joint",
      "durations",
      "blank_index",
      "beam_size",
      "max_symbols_per_step",
      "preserve_alignments",
      "fusion_models",
      "fusion_models_alpha",
      "blank_lm_score_mode",
      "pruning_mode",
      "allow_cuda_graphs"
    ],
    "force_cuda_graphs_mode": [
      "self",
      "mode"
    ],
    "maybe_enable_cuda_graphs": [
      "self"
    ],
    "disable_cuda_graphs": [
      "self"
    ],
    "reset_cuda_graphs_state": [
      "self"
    ],
    "modified_alsd_torch": [
      "self",
      "encoder_output",
      "encoder_output_length"
    ],
    "topk_fusion_model": [
      "self",
      "fusion_scores_list",
      "log_probs",
      "duration_log_probs",
      "eps"
    ],
    "modified_alsd_cuda_graphs": [
      "self",
      "encoder_output",
      "encoder_output_length"
    ],
    "_create_loop_body_kernel": [
      "cls"
    ],
    "_graph_reinitialize": [
      "self",
      "encoder_output_projected",
      "encoder_output_length"
    ],
    "_partial_graphs_compile": [
      "self"
    ],
    "_full_graph_compile": [
      "self"
    ],
    "_before_loop": [
      "self"
    ],
    "_loop_body": [
      "self"
    ],
    "_loop_update_decoder": [
      "self"
    ],
    "__call__": [
      "self",
      "x",
      "out_len"
    ]
  },
  "ModifiedAESBatchedRNNTComputer": {
    "__init__": [
      "self",
      "decoder",
      "joint",
      "blank_index",
      "beam_size",
      "maes_num_steps",
      "maes_expansion_beta",
      "maes_expansion_gamma",
      "preserve_alignments",
      "ngram_lm_model",
      "ngram_lm_alpha",
      "blank_lm_score_mode",
      "pruning_mode",
      "allow_cuda_graphs"
    ],
    "batched_modified_adaptive_expansion_search_torch": [
      "self",
      "encoder_output",
      "encoder_output_length"
    ],
    "combine_scores": [
      "self",
      "log_probs",
      "lm_scores"
    ],
    "topk_lm": [
      "self",
      "batched_hyps",
      "lm_scores",
      "log_probs"
    ],
    "__call__": [
      "self",
      "x",
      "out_len"
    ]
  },
  "ACT2FN": [],
  "TokenClassifierConfig": {},
  "BertPretrainingTokenClassifier": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "hidden_size",
      "num_classes",
      "num_layers",
      "activation",
      "log_softmax",
      "dropout",
      "use_transformer_init"
    ],
    "log_softmax": [
      "self"
    ],
    "with_log_softmax_enabled": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "TransducerModelType": {
    "RNNT": [],
    "TDT": [],
    "MULTI_BLANK": []
  },
  "TransducerDecodingStrategyType": {
    "GREEDY": [],
    "GREEDY_BATCH": [],
    "BEAM": [],
    "TSD": [],
    "MAES": [],
    "ALSD": [],
    "MALSD_BATCH": [],
    "MAES_BATCH": []
  },
  "AbstractRNNTDecoding": {
    "__init__": [
      "self",
      "decoding_cfg",
      "decoder",
      "joint",
      "blank_id",
      "supported_punctuation"
    ],
    "tokenizer_type": [
      "self"
    ],
    "rnnt_decoder_predictions_tensor": [
      "self",
      "encoder_output",
      "encoded_lengths",
      "return_hypotheses",
      "partial_hypotheses"
    ],
    "decode_hypothesis": [
      "self",
      "hypotheses_list"
    ],
    "compute_confidence": [
      "self",
      "hypotheses_list"
    ],
    "decode_tokens_to_str": [
      "self",
      "tokens"
    ],
    "decode_ids_to_tokens": [
      "self",
      "tokens"
    ],
    "decode_tokens_to_lang": [
      "self",
      "tokens"
    ],
    "decode_ids_to_langs": [
      "self",
      "tokens"
    ],
    "decode_ids_to_str": [
      "self",
      "tokens"
    ],
    "decode_tokens_to_str_with_strip_punctuation": [
      "self",
      "tokens"
    ],
    "update_joint_fused_batch_size": [
      "self"
    ],
    "compute_rnnt_timestamps": [
      "self",
      "hypothesis",
      "timestamp_type"
    ],
    "_compute_offsets": [
      "hypothesis",
      "blank_id"
    ],
    "_compute_offsets_tdt": [
      "hypothesis",
      "blank_id"
    ],
    "_refine_timestamps": [
      "encoded_char_offsets",
      "char_offsets",
      "supported_punctuation"
    ],
    "_refine_timestamps_tdt": [
      "encoded_char_offsets",
      "char_offsets",
      "supported_punctuation"
    ],
    "_load_kenlm_model": [
      "ngram_lm_model"
    ]
  },
  "RNNTDecoding": {
    "__init__": [
      "self",
      "decoding_cfg",
      "decoder",
      "joint",
      "vocabulary"
    ],
    "tokenizer_type": [
      "self"
    ],
    "_aggregate_token_confidence": [
      "self",
      "hypothesis"
    ],
    "decode_tokens_to_str": [
      "self",
      "tokens"
    ],
    "decode_ids_to_tokens": [
      "self",
      "tokens"
    ],
    "decode_tokens_to_lang": [
      "self",
      "tokens"
    ],
    "decode_ids_to_langs": [
      "self",
      "tokens"
    ]
  },
  "RNNTBPEDecoding": {
    "__init__": [
      "self",
      "decoding_cfg",
      "decoder",
      "joint",
      "tokenizer"
    ],
    "tokenizer_type": [
      "self"
    ],
    "_aggregate_token_confidence": [
      "self",
      "hypothesis"
    ],
    "decode_tokens_to_str": [
      "self",
      "tokens"
    ],
    "decode_ids_to_tokens": [
      "self",
      "tokens"
    ],
    "decode_tokens_to_lang": [
      "self",
      "tokens"
    ],
    "decode_ids_to_langs": [
      "self",
      "tokens"
    ],
    "decode_hypothesis": [
      "self",
      "hypotheses_list"
    ]
  },
  "RNNTDecodingConfig": {},
  "RNNTBPEDecodingConfig": {},
  "GumbelVectorQuantizer": {
    "__init__": [
      "self",
      "dim",
      "num_vars",
      "temp",
      "groups",
      "combine_groups",
      "vq_dim",
      "time_first",
      "activation",
      "weight_proj_depth",
      "weight_proj_factor"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "get_codebook_indices": [
      "self"
    ],
    "sample_from_codebook": [
      "self",
      "b",
      "n"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "return_ids"
    ]
  },
  "CTCDecoderCudaGraphsState": {
    "full_graph": [],
    "__init__": [
      "self",
      "batch_size",
      "max_time",
      "vocab_dim",
      "device",
      "float_dtype"
    ],
    "need_reinit": [
      "self",
      "logits"
    ]
  },
  "_DECODER_LENGTHS_NONE_WARNING": [],
  "GreedyCTCInfer": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "blank_id",
      "preserve_alignments",
      "compute_timestamps",
      "preserve_frame_confidence",
      "confidence_method_cfg"
    ],
    "forward": [
      "self",
      "decoder_output",
      "decoder_lengths"
    ],
    "_greedy_decode_logprobs": [
      "self",
      "x",
      "out_len"
    ],
    "_greedy_decode_labels": [
      "self",
      "x",
      "out_len"
    ],
    "__call__": [
      "self"
    ]
  },
  "GreedyBatchedCTCInfer": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "blank_id",
      "preserve_alignments",
      "compute_timestamps",
      "preserve_frame_confidence",
      "confidence_method_cfg",
      "ngram_lm_model",
      "ngram_lm_alpha",
      "boosting_tree",
      "boosting_tree_alpha",
      "allow_cuda_graphs",
      "tokenizer"
    ],
    "forward": [
      "self",
      "decoder_output",
      "decoder_lengths"
    ],
    "_greedy_decode_logprobs_batched": [
      "self",
      "x",
      "out_len"
    ],
    "_greedy_decode_labels_batched": [
      "self",
      "x",
      "out_len"
    ],
    "_greedy_decode_logprobs_batched_fusion_models_torch": [
      "self",
      "logits",
      "out_len"
    ],
    "_before_loop": [
      "self"
    ],
    "_inner_loop": [
      "self"
    ],
    "_create_while_loop_kernel": [
      "cls"
    ],
    "_graph_reinitialize": [
      "self",
      "logits",
      "logits_len"
    ],
    "_greedy_decode_logprobs_batched_fusion_models_cuda_graphs": [
      "self",
      "logits",
      "out_len"
    ],
    "force_cuda_graphs_mode": [
      "self",
      "mode"
    ],
    "maybe_enable_cuda_graphs": [
      "self"
    ],
    "disable_cuda_graphs": [
      "self"
    ],
    "reset_cuda_graphs_state": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "GreedyCTCInferConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "RIVA_DECODER_INSTALLATION_MESSAGE": [],
  "riva_decoder_importer": [],
  "_riva_config_to_dict": [
    "conf"
  ],
  "_fill_inner_riva_config_": [
    "riva_conf",
    "nemo_conf"
  ],
  "RivaDecoderConfig": {
    "__init__": [
      "self"
    ]
  },
  "WfstNbestUnit": {},
  "WfstNbestHypothesis": {
    "__init__": [
      "self",
      "raw_hypotheses"
    ],
    "__iter__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "replace_unit_": [
      "self",
      "index",
      "new_unit"
    ],
    "shape0": [
      "self"
    ],
    "shape1": [
      "self"
    ],
    "has_timesteps": [
      "self"
    ],
    "has_alignment": [
      "self"
    ]
  },
  "collapse_tokenword_hypotheses": [
    "hypotheses",
    "tokenword_disambig_str"
  ],
  "AbstractWFSTDecoder": {
    "__init__": [
      "self",
      "lm_fst",
      "decoding_mode",
      "beam_size",
      "config",
      "tokenword_disambig_id",
      "lm_weight"
    ],
    "_set_decoder_config": [
      "self",
      "config"
    ],
    "_set_decoding_mode": [
      "self",
      "decoding_mode"
    ],
    "_init_decoder": [
      "self"
    ],
    "decoding_mode": [
      "self",
      "value"
    ],
    "_decoding_mode_setter": [
      "self",
      "value"
    ],
    "beam_size": [
      "self",
      "value"
    ],
    "_beam_size_setter": [
      "self",
      "value"
    ],
    "lm_weight": [
      "self",
      "value"
    ],
    "_lm_weight_setter": [
      "self",
      "value"
    ],
    "tokenword_disambig_id": [
      "self"
    ],
    "open_vocabulary_decoding": [
      "self"
    ],
    "decode": [
      "self",
      "log_probs",
      "log_probs_length"
    ],
    "_post_decode": [
      "self",
      "hypotheses"
    ],
    "calibrate_lm_weight": [
      "self",
      "log_probs",
      "log_probs_length",
      "reference_texts"
    ],
    "calculate_oracle_wer": [
      "self",
      "log_probs",
      "log_probs_length",
      "reference_texts"
    ]
  },
  "RivaGpuWfstDecoder": {
    "__init__": [
      "self",
      "lm_fst",
      "decoding_mode",
      "beam_size",
      "config",
      "tokenword_disambig_id",
      "lm_weight",
      "nbest_size"
    ],
    "_set_decoder_config": [
      "self",
      "config"
    ],
    "_init_decoder": [
      "self"
    ],
    "_set_decoding_mode": [
      "self",
      "decoding_mode"
    ],
    "_beam_size_setter": [
      "self",
      "value"
    ],
    "_lm_weight_setter": [
      "self",
      "value"
    ],
    "_decoding_mode_setter": [
      "self",
      "value"
    ],
    "nbest_size": [
      "self",
      "value"
    ],
    "_nbest_size_setter": [
      "self",
      "value"
    ],
    "_decode_nbest": [
      "self",
      "log_probs",
      "log_probs_length"
    ],
    "_decode_mbr": [
      "self",
      "log_probs",
      "log_probs_length"
    ],
    "_decode_lattice": [
      "self",
      "log_probs",
      "log_probs_length"
    ],
    "decode": [
      "self",
      "log_probs",
      "log_probs_length"
    ],
    "_post_decode": [
      "self",
      "hypotheses"
    ],
    "calibrate_lm_weight": [
      "self",
      "log_probs",
      "log_probs_length",
      "reference_texts"
    ],
    "calculate_oracle_wer": [
      "self",
      "log_probs",
      "log_probs_length",
      "reference_texts"
    ],
    "_release_gpu_memory": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "StatsPoolLayer": {
    "__init__": [
      "self",
      "feat_in",
      "pool_mode",
      "eps",
      "unbiased"
    ],
    "forward": [
      "self",
      "encoder_output",
      "length"
    ]
  },
  "make_seq_mask_like": [
    "like",
    "lengths",
    "valid_ones",
    "time_dim"
  ],
  "get_statistics_with_mask": [
    "x",
    "m",
    "dim",
    "eps"
  ],
  "TDNNModule": {
    "__init__": [
      "self",
      "inp_filters",
      "out_filters",
      "kernel_size",
      "dilation",
      "stride",
      "padding"
    ],
    "forward": [
      "self",
      "x",
      "length"
    ]
  },
  "MaskedSEModule": {
    "__init__": [
      "self",
      "inp_filters",
      "se_filters",
      "out_filters",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "input",
      "length"
    ]
  },
  "TDNNSEModule": {
    "__init__": [
      "self",
      "inp_filters",
      "out_filters",
      "group_scale",
      "se_channels",
      "kernel_size",
      "dilation",
      "init_mode"
    ],
    "forward": [
      "self",
      "input",
      "length"
    ]
  },
  "AttentivePoolLayer": {
    "__init__": [
      "self",
      "inp_filters",
      "attention_channels",
      "kernel_size",
      "dilation",
      "eps"
    ],
    "forward": [
      "self",
      "x",
      "length"
    ]
  },
  "ConformerLayer": {
    "__init__": [
      "self",
      "d_model",
      "d_ff",
      "self_attention_model",
      "global_tokens",
      "global_tokens_spacing",
      "global_attn_separate",
      "n_heads",
      "conv_kernel_size",
      "conv_norm_type",
      "conv_context_size",
      "dropout",
      "dropout_att",
      "pos_bias_u",
      "pos_bias_v",
      "att_context_size",
      "use_bias",
      "use_pytorch_sdpa",
      "use_pytorch_sdpa_backends"
    ],
    "forward": [
      "self",
      "x",
      "att_mask",
      "pos_emb",
      "pad_mask",
      "cache_last_channel",
      "cache_last_time"
    ]
  },
  "ConformerConvolution": {
    "__init__": [
      "self",
      "d_model",
      "kernel_size",
      "norm_type",
      "conv_context_size",
      "pointwise_activation",
      "use_bias"
    ],
    "forward": [
      "self",
      "x",
      "pad_mask",
      "cache"
    ],
    "reset_parameters_conv": [
      "self"
    ]
  },
  "ConformerFeedForward": {
    "__init__": [
      "self",
      "d_model",
      "d_ff",
      "dropout",
      "activation",
      "use_bias"
    ],
    "forward": [
      "self",
      "x"
    ],
    "reset_parameters_ff": [
      "self"
    ]
  },
  "jasper_activations": [],
  "tds_uniform_": [
    "tensor",
    "mode"
  ],
  "tds_normal_": [
    "tensor",
    "mode"
  ],
  "compute_new_kernel_size": [
    "kernel_size",
    "kernel_width"
  ],
  "get_asymtric_padding": [
    "kernel_size",
    "stride",
    "dilation",
    "future_context"
  ],
  "_se_pool_step_script_infer": [
    "x",
    "context_window",
    "mask"
  ],
  "_se_pool_step_script_train": [
    "x",
    "context_window",
    "mask"
  ],
  "_masked_conv_init_lens": [
    "lens",
    "current_maxlen",
    "original_maxlen"
  ],
  "MaskedConv1d": {
    "__constants__": [],
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "heads",
      "bias",
      "use_mask",
      "quantize"
    ],
    "get_seq_len": [
      "self",
      "lens"
    ],
    "forward": [
      "self",
      "x",
      "lens"
    ],
    "update_masked_length": [
      "self",
      "max_len",
      "seq_range",
      "device"
    ],
    "mask_input": [
      "self",
      "x",
      "lens"
    ]
  },
  "GroupShuffle": {
    "__init__": [
      "self",
      "groups",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SqueezeExcite": {
    "__init__": [
      "self",
      "channels",
      "reduction_ratio",
      "context_window",
      "interpolation_mode",
      "activation",
      "quantize"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ],
    "forward_for_export": [
      "self",
      "x",
      "lengths"
    ],
    "_se_pool_step": [
      "self",
      "x",
      "mask"
    ],
    "set_max_len": [
      "self",
      "max_len",
      "seq_range"
    ],
    "make_pad_mask": [
      "self",
      "seq_lens",
      "max_audio_length",
      "device"
    ],
    "change_context_window": [
      "self",
      "context_window"
    ]
  },
  "JasperBlock": {
    "__constants__": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "repeat",
      "kernel_size",
      "kernel_size_factor",
      "stride",
      "dilation",
      "padding",
      "dropout",
      "activation",
      "residual",
      "groups",
      "separable",
      "heads",
      "normalization",
      "norm_groups",
      "residual_mode",
      "residual_panes",
      "conv_mask",
      "se",
      "se_reduction_ratio",
      "se_context_window",
      "se_interpolation_mode",
      "stride_last",
      "future_context",
      "quantize",
      "layer_idx"
    ],
    "_get_conv": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "padding",
      "bias",
      "groups",
      "heads",
      "separable",
      "quantize"
    ],
    "_get_conv_bn_layer": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "padding",
      "bias",
      "groups",
      "heads",
      "separable",
      "normalization",
      "norm_groups",
      "quantize"
    ],
    "_get_act_dropout_layer": [
      "self",
      "drop_prob",
      "activation"
    ],
    "forward": [
      "self",
      "input_"
    ]
  },
  "ParallelBlock": {
    "__init__": [
      "self",
      "blocks",
      "aggregation_mode",
      "block_dropout_prob",
      "residual_mode",
      "in_filters",
      "out_filters"
    ],
    "get_dropout_mask": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ScaleBiasLayer": {
    "__init__": [
      "self",
      "d_model",
      "adaptive_scale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SqueezeformerLayer": {
    "__init__": [
      "self",
      "d_model",
      "d_ff",
      "self_attention_model",
      "n_heads",
      "conv_kernel_size",
      "conv_norm_type",
      "dropout",
      "dropout_att",
      "pos_bias_u",
      "pos_bias_v",
      "adaptive_scale"
    ],
    "forward": [
      "self",
      "x",
      "att_mask",
      "pos_emb",
      "pad_mask"
    ],
    "reset_parameters": [
      "self"
    ]
  },
  "StatelessNet": {
    "__init__": [
      "self",
      "context_size",
      "vocab_size",
      "emb_dim",
      "blank_idx",
      "normalization_mode",
      "dropout"
    ],
    "forward": [
      "self",
      "y",
      "state"
    ]
  },
  "BeamRNNTInfer": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "decoder_model",
      "joint_model",
      "beam_size",
      "search_type",
      "score_norm",
      "return_best_hypothesis",
      "tsd_max_sym_exp_per_step",
      "alsd_max_target_len",
      "nsc_max_timesteps_expansion",
      "nsc_prefix_alpha",
      "maes_num_steps",
      "maes_prefix_alpha",
      "maes_expansion_gamma",
      "maes_expansion_beta",
      "language_model",
      "softmax_temperature",
      "preserve_alignments",
      "ngram_lm_model",
      "ngram_lm_alpha",
      "hat_subtract_ilm",
      "hat_ilm_weight",
      "max_symbols_per_step",
      "blank_lm_score_mode",
      "pruning_mode",
      "allow_cuda_graphs"
    ],
    "__call__": [
      "self",
      "encoder_output",
      "encoded_lengths",
      "partial_hypotheses"
    ],
    "sort_nbest": [
      "self",
      "hyps"
    ],
    "greedy_search": [
      "self",
      "h",
      "encoded_lengths",
      "partial_hypotheses"
    ],
    "default_beam_search": [
      "self",
      "h",
      "encoded_lengths",
      "partial_hypotheses"
    ],
    "time_sync_decoding": [
      "self",
      "h",
      "encoded_lengths",
      "partial_hypotheses"
    ],
    "align_length_sync_decoding": [
      "self",
      "h",
      "encoded_lengths",
      "partial_hypotheses"
    ],
    "modified_adaptive_expansion_search": [
      "self",
      "h",
      "encoded_lengths",
      "partial_hypotheses"
    ],
    "recombine_hypotheses": [
      "self",
      "hypotheses"
    ],
    "resolve_joint_output": [
      "self",
      "enc_out",
      "dec_out"
    ],
    "prefix_search": [
      "self",
      "hypotheses",
      "enc_out",
      "prefix_alpha"
    ],
    "compute_ngram_score": [
      "self",
      "current_lm_state",
      "label"
    ],
    "set_decoding_type": [
      "self",
      "decoding_type"
    ]
  },
  "BeamBatchedRNNTInfer": {
    "input_types": [
      "self"
    ],
    "__init__": [
      "self",
      "decoder_model",
      "joint_model",
      "blank_index",
      "beam_size",
      "search_type",
      "score_norm",
      "maes_num_steps",
      "maes_expansion_gamma",
      "maes_expansion_beta",
      "max_symbols_per_step",
      "preserve_alignments",
      "fusion_models",
      "fusion_models_alpha",
      "blank_lm_score_mode",
      "pruning_mode",
      "allow_cuda_graphs",
      "return_best_hypothesis"
    ],
    "disable_cuda_graphs": [
      "self"
    ],
    "maybe_enable_cuda_graphs": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "forward": [
      "self",
      "encoder_output",
      "encoded_lengths",
      "partial_hypotheses"
    ]
  },
  "BeamRNNTInferConfig": {},
  "ModifiedALSDBatchedRNNTComputer": {
    "INITIAL_MAX_TIME": [],
    "CUDA_PROGRAM_NAME": [],
    "__init__": [
      "self",
      "decoder",
      "joint",
      "blank_index",
      "beam_size",
      "max_symbols_per_step",
      "preserve_alignments",
      "fusion_models",
      "fusion_models_alpha",
      "blank_lm_score_mode",
      "pruning_mode",
      "allow_cuda_graphs"
    ],
    "force_cuda_graphs_mode": [
      "self",
      "mode"
    ],
    "maybe_enable_cuda_graphs": [
      "self"
    ],
    "disable_cuda_graphs": [
      "self"
    ],
    "reset_cuda_graphs_state": [
      "self"
    ],
    "modified_alsd_torch": [
      "self",
      "encoder_output",
      "encoder_output_length"
    ],
    "topk_fusion_model": [
      "self",
      "fusion_scores_list",
      "log_probs",
      "eps"
    ],
    "modified_alsd_cuda_graphs": [
      "self",
      "encoder_output",
      "encoder_output_length"
    ],
    "_create_loop_body_kernel": [
      "cls"
    ],
    "_graph_reinitialize": [
      "self",
      "encoder_output_projected",
      "encoder_output_length"
    ],
    "_partial_graphs_compile": [
      "self"
    ],
    "_full_graph_compile": [
      "self"
    ],
    "_before_loop": [
      "self"
    ],
    "_loop_body": [
      "self"
    ],
    "_loop_update_decoder": [
      "self"
    ],
    "__call__": [
      "self",
      "x",
      "out_len"
    ]
  },
  "LabelLoopingState": {
    "__init__": [
      "self",
      "batch_size",
      "max_time",
      "encoder_dim",
      "max_symbols",
      "device",
      "float_dtype",
      "logits_dim",
      "preserve_alignments",
      "preserve_frame_confidence"
    ],
    "need_reinit": [
      "self",
      "encoder_output_projected"
    ]
  },
  "GreedyBatchedRNNTLabelLoopingComputer": {
    "INITIAL_MAX_TIME": [],
    "CUDA_PROGRAM_NAME": [],
    "__init__": [
      "self",
      "decoder",
      "joint",
      "blank_index",
      "max_symbols_per_step",
      "preserve_alignments",
      "preserve_frame_confidence",
      "confidence_method_cfg",
      "allow_cuda_graphs",
      "fusion_models",
      "fusion_models_alpha"
    ],
    "reset_cuda_graphs_state": [
      "self"
    ],
    "_get_frame_confidence": [
      "self",
      "logits"
    ],
    "torch_impl": [
      "self",
      "encoder_output",
      "encoder_output_length",
      "prev_batched_state"
    ],
    "_get_decoding_state_item_after_sos": [
      "self",
      "device"
    ],
    "_get_batched_decoding_state_after_sos": [
      "self",
      "device",
      "batch_size"
    ],
    "reset_state_by_mask": [
      "self",
      "state",
      "mask"
    ],
    "split_batched_state": [
      "self",
      "state"
    ],
    "merge_to_batched_state": [
      "self",
      "state_items"
    ],
    "cuda_graphs_impl": [
      "self",
      "encoder_output",
      "encoder_output_length",
      "prev_batched_state"
    ],
    "_create_outer_while_loop_kernel": [
      "cls"
    ],
    "_create_inner_while_loop_kernel": [
      "cls"
    ],
    "_graph_reinitialize": [
      "self",
      "encoder_output_projected",
      "encoder_output_length"
    ],
    "_warmup_for_cuda_graphs": [
      "self"
    ],
    "_partial_graphs_compile": [
      "self"
    ],
    "_full_graph_compile": [
      "self"
    ],
    "_init_decoding_state": [
      "self",
      "current_batch_size",
      "prev_batched_state"
    ],
    "_before_outer_loop": [
      "self"
    ],
    "_before_inner_loop_get_joint_output": [
      "self"
    ],
    "_inner_loop_step_find_next_non_blank": [
      "self"
    ],
    "_after_inner_loop_step": [
      "self"
    ],
    "_after_inner_loop_store_labels": [
      "self"
    ],
    "_after_inner_loop_select_fusion_states": [
      "self"
    ],
    "_after_inner_loop_get_decoder_output": [
      "self"
    ],
    "_after_inner_loop_force_max_symbols": [
      "self"
    ],
    "_fix_timestamps_for_iterative_decoding": [
      "self",
      "current_batch_size",
      "prev_batched_state"
    ]
  },
  "SeparateGraphsLabelLooping": {},
  "BatchedLabelLoopingState": {},
  "LabelLoopingStateItem": {},
  "GreedyBatchedLabelLoopingComputerBase": {
    "force_cuda_graphs_mode": [
      "self",
      "mode"
    ],
    "maybe_enable_cuda_graphs": [
      "self"
    ],
    "disable_cuda_graphs": [
      "self"
    ],
    "torch_impl": [
      "self",
      "encoder_output",
      "encoder_output_length",
      "prev_batched_state"
    ],
    "cuda_graphs_impl": [
      "self",
      "encoder_output",
      "encoder_output_length",
      "prev_batched_state"
    ],
    "reset_cuda_graphs_state": [
      "self"
    ],
    "split_batched_state": [
      "self",
      "state"
    ],
    "merge_to_batched_state": [
      "self",
      "state_items"
    ],
    "reset_state_by_mask": [
      "self",
      "state",
      "mask"
    ],
    "__call__": [
      "self",
      "x",
      "out_len",
      "prev_batched_state"
    ]
  },
  "GreedyBatchedTDTLabelLoopingComputer": {
    "INITIAL_MAX_TIME": [],
    "CUDA_PROGRAM_NAME": [],
    "__init__": [
      "self",
      "decoder",
      "joint",
      "blank_index",
      "durations",
      "max_symbols_per_step",
      "preserve_alignments",
      "preserve_frame_confidence",
      "include_duration",
      "include_duration_confidence",
      "confidence_method_cfg",
      "allow_cuda_graphs",
      "fusion_models",
      "fusion_models_alpha"
    ],
    "reset_cuda_graphs_state": [
      "self"
    ],
    "_get_frame_confidence": [
      "self",
      "logits",
      "num_durations"
    ],
    "torch_impl": [
      "self",
      "encoder_output",
      "encoder_output_length",
      "prev_batched_state"
    ],
    "_get_decoding_state_item_after_sos": [
      "self",
      "device"
    ],
    "_get_batched_decoding_state_after_sos": [
      "self",
      "device",
      "batch_size"
    ],
    "reset_state_by_mask": [
      "self",
      "state",
      "mask"
    ],
    "split_batched_state": [
      "self",
      "state"
    ],
    "merge_to_batched_state": [
      "self",
      "state_items"
    ],
    "cuda_graphs_impl": [
      "self",
      "encoder_output",
      "encoder_output_length",
      "prev_batched_state"
    ],
    "_create_outer_while_loop_kernel": [
      "cls"
    ],
    "_create_inner_while_loop_kernel": [
      "cls"
    ],
    "_graph_reinitialize": [
      "self",
      "encoder_output_projected",
      "encoder_output_length"
    ],
    "_warmup_for_cuda_graphs": [
      "self"
    ],
    "_partial_graphs_compile": [
      "self"
    ],
    "_full_graph_compile": [
      "self"
    ],
    "_init_decoding_state": [
      "self",
      "current_batch_size",
      "prev_batched_state"
    ],
    "_before_outer_loop": [
      "self"
    ],
    "_before_inner_loop_get_joint_output": [
      "self"
    ],
    "_inner_loop_step_find_next_non_blank": [
      "self"
    ],
    "_after_inner_loop_step": [
      "self"
    ],
    "_after_inner_loop_store_labels": [
      "self"
    ],
    "_after_inner_loop_select_fusion_states": [
      "self"
    ],
    "_after_inner_loop_get_decoder_output": [
      "self"
    ],
    "_after_inner_loop_force_max_symbols": [
      "self"
    ],
    "_fix_timestamps_for_iterative_decoding": [
      "self",
      "current_batch_size",
      "prev_batched_state"
    ]
  },
  "AEDStreamingState": {},
  "GreedyBatchedStreamingAEDComputer": {
    "__init__": [
      "self",
      "asr_model",
      "frame_chunk_size",
      "decoding_cfg"
    ],
    "__call__": [
      "self",
      "encoder_output",
      "encoder_output_len",
      "encoder_input_mask",
      "prev_batched_state"
    ],
    "run_waitk_decoding_step": [
      "self",
      "encoded_speech",
      "encoder_input_mask"
    ],
    "run_alignatt_decoding_step": [
      "self",
      "encoded_speech",
      "encoder_input_mask"
    ],
    "detect_hallucinations": [
      "self",
      "pred_tokens_ids",
      "batch_idxs",
      "current_context_lengths"
    ],
    "compute_laal": [
      "self",
      "delays",
      "source_length",
      "target_length"
    ],
    "compute_alignatt_lagging": [
      "self",
      "records",
      "predicted_token_ids",
      "tokens_frame_alignment",
      "context_encoder_frames",
      "audio_encoder_fs",
      "BOW_PREFIX"
    ],
    "compute_waitk_lagging": [
      "self",
      "records",
      "predicted_token_ids",
      "context_encoder_frames",
      "audio_encoder_fs",
      "BOW_PREFIX"
    ],
    "initialize_aed_model_state": [
      "cls",
      "asr_model",
      "decoder_input_ids",
      "batch_size",
      "context_encoder_frames",
      "chunk_secs",
      "right_context_secs"
    ]
  },
  "return_decoder_input_ids": [
    "decoding_config",
    "asr_model"
  ],
  "TransformerMultiHeadAttentionAdapter": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "attn_score_dropout",
      "attn_layer_dropout",
      "proj_dim",
      "adapter_strategy"
    ],
    "forward": [
      "self",
      "queries",
      "keys",
      "values",
      "attention_mask"
    ],
    "reset_parameters": [
      "self"
    ],
    "get_default_strategy_config": [
      "self"
    ]
  },
  "TransformerMultiHeadAttentionAdapterConfig": {},
  "AttentionAdapterModuleMixin": {
    "forward_single_enabled_adapter_": [
      "self",
      "input",
      "adapter_module"
    ]
  },
  "MHAResidualAddAdapterStrategy": {
    "forward": [
      "self",
      "input",
      "adapter"
    ],
    "compute_output": [
      "self",
      "input",
      "adapter"
    ]
  },
  "MHAResidualAddAdapterStrategyConfig": {},
  "MultiHeadAttentionAdapter": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "dropout_rate",
      "proj_dim",
      "adapter_strategy",
      "use_pytorch_sdpa",
      "use_pytorch_sdpa_backends"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask",
      "pos_emb",
      "cache"
    ],
    "reset_parameters": [
      "self"
    ],
    "get_default_strategy_config": [
      "self"
    ]
  },
  "MultiHeadAttentionAdapterConfig": {},
  "RelPositionMultiHeadAttentionAdapter": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "dropout_rate",
      "proj_dim",
      "adapter_strategy",
      "use_pytorch_sdpa",
      "use_pytorch_sdpa_backends"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask",
      "pos_emb",
      "cache"
    ],
    "reset_parameters": [
      "self"
    ],
    "get_default_strategy_config": [
      "self"
    ]
  },
  "RelPositionMultiHeadAttentionAdapterConfig": {},
  "PositionalEncodingAdapter": {
    "__init__": [
      "self",
      "d_model",
      "max_len",
      "xscale",
      "adapter_strategy"
    ],
    "get_default_strategy_config": [
      "self"
    ]
  },
  "PositionalEncodingAdapterConfig": {},
  "RelPositionalEncodingAdapter": {
    "__init__": [
      "self",
      "d_model",
      "max_len",
      "xscale",
      "adapter_strategy"
    ],
    "get_default_strategy_config": [
      "self"
    ]
  },
  "RelPositionalEncodingAdapterConfig": {},
  "ngram_advance_triton_kernel": [
    "vocab_size",
    "states_ptr",
    "new_states_ptr",
    "scores_ptr",
    "start_state",
    "to_states_ptr",
    "ilabels_ptr",
    "arcs_weights_ptr",
    "start_end_arcs_ptr",
    "backoff_to_states_ptr",
    "backoff_weights_ptr",
    "BLOCK_SIZE"
  ],
  "_BOS_ID": [],
  "_EOS_ID": [],
  "_UNK_ID": [],
  "_SPECIAL_SYMBOLS_MAP": [],
  "_log_10_to_e": [
    "score"
  ],
  "KenLMBatchedWrapper": {
    "__init__": [
      "self",
      "lm_path",
      "vocab_size",
      "token_offset"
    ],
    "from_file": [
      "cls",
      "lm_path",
      "vocab_size",
      "token_offset"
    ],
    "get_init_state": [
      "self",
      "bos"
    ],
    "get_init_states": [
      "self",
      "batch_size",
      "bos"
    ],
    "advance": [
      "self",
      "states"
    ],
    "advance_single": [
      "self",
      "state",
      "label"
    ],
    "score_sentence": [
      "self",
      "sentence",
      "bos",
      "eos"
    ],
    "score_sentences": [
      "self",
      "sentences",
      "bos",
      "eos"
    ],
    "get_final_single": [
      "self",
      "state"
    ],
    "get_final": [
      "self",
      "states"
    ]
  },
  "NGram": {},
  "Arc": {},
  "SuffixTreeStorage": {
    "__post_init__": [
      "self",
      "num_states_max",
      "num_arcs_max",
      "separate_bos_state"
    ],
    "_add_unigrams": [
      "self",
      "ngrams",
      "bos_id",
      "unk_id"
    ],
    "_find_state": [
      "self",
      "symbols",
      "bos_id"
    ],
    "_add_ngrams_next_order": [
      "self",
      "ngrams",
      "bos_id"
    ],
    "_start_adding_ngrams_for_order": [
      "self",
      "order",
      "max_ngrams"
    ],
    "_add_ngram": [
      "self",
      "ngram",
      "bos_id"
    ],
    "_end_adding_ngrams_for_order": [
      "self",
      "order",
      "bos_id",
      "unk_id"
    ],
    "_add_ngram_max_order": [
      "self",
      "ngram",
      "bos_id"
    ],
    "_end_adding_ngrams_max_order": [
      "self"
    ],
    "sanity_check": [
      "self"
    ]
  },
  "NGramLMConfig": {},
  "NGramGPULanguageModel": {
    "START_STATE": [],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "list_available_models": [
      "cls"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "from_nemo": [
      "cls",
      "lm_path",
      "vocab_size",
      "use_triton"
    ],
    "from_file": [
      "cls",
      "lm_path",
      "vocab_size",
      "normalize_unk",
      "use_triton",
      "token_offset"
    ],
    "from_arpa": [
      "cls",
      "lm_path",
      "vocab_size",
      "normalize_unk",
      "use_triton",
      "token_offset"
    ],
    "dummy_unigram_lm": [
      "cls",
      "vocab_size",
      "use_triton"
    ],
    "from_suffix_tree": [
      "cls",
      "suffix_tree_np",
      "use_triton"
    ],
    "_read_header": [
      "cls",
      "f"
    ],
    "_read_ngrams": [
      "cls",
      "f",
      "token_offset"
    ],
    "_line_to_ngram": [
      "line",
      "pattern",
      "token_offset"
    ],
    "_init_from_suffix_tree_np": [
      "self",
      "suffix_tree_np"
    ],
    "get_init_states": [
      "self",
      "batch_size",
      "bos"
    ],
    "forward": [
      "self",
      "labels",
      "labels_lengths",
      "bos",
      "eos"
    ],
    "score_sentences": [
      "self",
      "labels",
      "labels_lengths",
      "bos",
      "eos"
    ],
    "advance": [
      "self",
      "states",
      "eos_id"
    ],
    "_advance_pytorch": [
      "self",
      "states"
    ],
    "_advance_triton": [
      "self",
      "states"
    ],
    "get_final": [
      "self",
      "states"
    ],
    "_resolve_final": [
      "self"
    ],
    "_get_final_pytorch": [
      "self",
      "states"
    ]
  },
  "CHUNK_SIZE": [],
  "CHUNK_BUFFER_SIZE": [],
  "softmax": [
    "x"
  ],
  "get_train_list": [
    "args_train_path"
  ],
  "setup_tokenizer": [
    "nemo_model_file"
  ],
  "iter_files": [
    "source_path",
    "dest_path",
    "tokenizer",
    "encoding_level",
    "is_aggregate_tokenizer",
    "verbose"
  ],
  "read_train_file": [
    "path",
    "is_aggregate_tokenizer",
    "verbose"
  ],
  "tokenize_str": [
    "texts",
    "tokenizer"
  ],
  "tokenize_text": [
    "data",
    "tokenizer",
    "path",
    "chunk_size",
    "buffer_size"
  ],
  "write_dataset": [
    "chunks",
    "path"
  ],
  "DEFAULT_TOKEN_OFFSET": [],
  "TW_BREAK": [],
  "KALDIFST_INSTALLATION_MESSAGE": [],
  "GRAPHVIZ_INSTALLATION_MESSAGE": [],
  "KALDILM_INSTALLATION_MESSAGE": [],
  "_kaldifst_maybe_raise": [],
  "kaldifst_importer": [],
  "_graphviz_maybe_raise": [],
  "graphviz_importer": [],
  "_kaldilm_maybe_raise": [],
  "kaldilm_importer": [],
  "LexiconUnit": {},
  "Lexicon": {
    "__init__": [
      "self",
      "wordid2tokenid",
      "id2word",
      "id2token",
      "disambig_pattern"
    ],
    "__iter__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "token_ids": [
      "self"
    ]
  },
  "arpa2fst": [
    "lm_path",
    "attach_symbol_table"
  ],
  "add_tokenwords_": [
    "g_fst",
    "tokens",
    "word_weight",
    "token_unigram_weight",
    "token_oov"
  ],
  "generate_lexicon_sentencepiece": [
    "tokenizer",
    "id2word",
    "oov",
    "add_epsilon",
    "first_tokenword_id",
    "disambig_pattern"
  ],
  "add_disambig_symbols": [
    "lexicon"
  ],
  "make_lexicon_fst_no_silence": [
    "lexicon",
    "attach_symbol_table"
  ],
  "mkgraph_ctc_ov": [
    "tokenizer",
    "lm_path",
    "topology_name",
    "write_tlg_path",
    "open_vocabulary",
    "open_vocabulary_weights",
    "target"
  ],
  "KaldiFstMask": {
    "Acceptor": [],
    "Error": [],
    "TopSorted": [],
    "Acyclic": [],
    "IlabelSorted": [],
    "OlabelSorted": [],
    "IlabelDeterministic": [],
    "OlabelDeterministic": [],
    "HasEpsilons": [],
    "HasIEpsilons": [],
    "Accessible": [],
    "Coaccessible": [],
    "Weighted": []
  },
  "LatticeProperties": {},
  "AbstractLattice": {
    "__init__": [
      "self",
      "lattice"
    ],
    "as_tensor": [
      "self"
    ],
    "draw": [
      "self",
      "filename",
      "title",
      "zoom"
    ],
    "edit_distance": [
      "self",
      "reference_sequence"
    ],
    "lattice": [
      "self"
    ],
    "properties": [
      "self"
    ],
    "symbol_table": [
      "self"
    ],
    "auxiliary_tables": [
      "self"
    ]
  },
  "KaldiWordLattice": {
    "__init__": [
      "self",
      "lattice",
      "symbol_table",
      "auxiliary_tables"
    ],
    "properties": [
      "self"
    ],
    "symbol_table": [
      "self"
    ],
    "auxiliary_tables": [
      "self"
    ],
    "as_tensor": [
      "self"
    ],
    "edit_distance": [
      "self",
      "reference_sequence"
    ],
    "draw": [
      "self",
      "filename",
      "title",
      "zoom"
    ]
  },
  "_is_notebook": [],
  "_svg_srcdoc_resize": [
    "filename",
    "zoom"
  ],
  "levenshtein_graph_kaldi": [
    "fst",
    "ins_del_score"
  ],
  "load_word_lattice": [
    "lat_filename",
    "id2word",
    "id2token"
  ],
  "extract_punctuation_from_vocab": [
    "vocab"
  ],
  "extract_capitalized_tokens_from_vocab": [
    "vocab"
  ],
  "define_spe_tokenizer_type": [
    "vocabulary"
  ],
  "cos_similarity": [
    "emb_a",
    "emb_b",
    "eps"
  ],
  "ScalerMinMax": [
    "X"
  ],
  "getEuclideanDistance": [
    "specEmbA",
    "specEmbB",
    "device"
  ],
  "kmeans_plusplus_torch": [
    "X",
    "n_clusters",
    "random_state",
    "n_local_trials",
    "device"
  ],
  "kmeans_torch": [
    "X",
    "num_clusters",
    "threshold",
    "iter_limit",
    "random_state",
    "device"
  ],
  "getTheLargestComponent": [
    "affinity_mat",
    "seg_index",
    "device"
  ],
  "isGraphFullyConnected": [
    "affinity_mat",
    "device"
  ],
  "getKneighborsConnections": [
    "affinity_mat",
    "p_value",
    "mask_method"
  ],
  "getAffinityGraphMat": [
    "affinity_mat_raw",
    "p_value"
  ],
  "getMinimumConnection": [
    "mat",
    "max_N",
    "n_list",
    "device"
  ],
  "getRepeatedList": [
    "mapping_argmat",
    "score_mat_size"
  ],
  "get_argmin_mat": [
    "timestamps_in_scales"
  ],
  "getCosAffinityMatrix": [
    "emb"
  ],
  "get_scale_interpolated_embs": [
    "multiscale_weights",
    "embeddings_in_scales",
    "timestamps_in_scales",
    "device"
  ],
  "getMultiScaleCosAffinityMatrix": [
    "multiscale_weights",
    "embeddings_in_scales",
    "timestamps_in_scales",
    "device"
  ],
  "getLaplacian": [
    "X"
  ],
  "eigDecompose": [
    "laplacian",
    "cuda",
    "device"
  ],
  "eigValueSh": [
    "laplacian",
    "cuda",
    "device"
  ],
  "getLamdaGaplist": [
    "lambdas"
  ],
  "addAnchorEmb": [
    "emb",
    "anchor_sample_n",
    "anchor_spk_n",
    "sigma"
  ],
  "getEnhancedSpeakerCount": [
    "emb",
    "random_test_count",
    "anchor_spk_n",
    "anchor_sample_n",
    "sigma",
    "cuda"
  ],
  "split_input_data": [
    "embeddings_in_scales",
    "timestamps_in_scales",
    "multiscale_segment_counts"
  ],
  "estimateNumofSpeakers": [
    "affinity_mat",
    "max_num_speakers",
    "cuda"
  ],
  "SpectralClustering": {
    "__init__": [
      "self",
      "n_clusters",
      "random_state",
      "n_random_trials",
      "cuda",
      "device"
    ],
    "forward": [
      "self",
      "X"
    ],
    "clusterSpectralEmbeddings": [
      "self",
      "affinity",
      "cuda",
      "device"
    ],
    "getSpectralEmbeddings": [
      "self",
      "affinity_mat",
      "n_spks",
      "cuda"
    ]
  },
  "NMESC": {
    "__init__": [
      "self",
      "mat",
      "max_num_speakers",
      "max_rp_threshold",
      "sparse_search",
      "sparse_search_volume",
      "nme_mat_size",
      "use_subsampling_for_nme",
      "fixed_thres",
      "maj_vote_spk_count",
      "parallelism",
      "cuda",
      "device"
    ],
    "forward": [
      "self"
    ],
    "subsampleAffinityMat": [
      "self",
      "nme_mat_size"
    ],
    "getEigRatio": [
      "self",
      "p_neighbors"
    ],
    "getPvalueList": [
      "self"
    ]
  },
  "SpeakerClustering": {
    "__init__": [
      "self",
      "min_samples_for_nmesc",
      "nme_mat_size",
      "sparse_search",
      "maj_vote_spk_count",
      "parallelism",
      "cuda"
    ],
    "forward_unit_infer": [
      "self",
      "mat",
      "oracle_num_speakers",
      "max_num_speakers",
      "max_rp_threshold",
      "sparse_search_volume",
      "est_num_of_spk_enhanced",
      "fixed_thres",
      "kmeans_random_trials"
    ],
    "forward": [
      "self",
      "param_dict"
    ],
    "forward_infer": [
      "self",
      "embeddings_in_scales",
      "timestamps_in_scales",
      "multiscale_segment_counts",
      "multiscale_weights",
      "oracle_num_speakers",
      "max_num_speakers",
      "max_rp_threshold",
      "enhanced_count_thres",
      "sparse_search_volume",
      "fixed_thres",
      "kmeans_random_trials"
    ]
  },
  "LINEAR_ADAPTER_CLASSPATH": [],
  "MHA_ADAPTER_CLASSPATH": [],
  "RELMHA_ADAPTER_CLASSPATH": [],
  "POS_ENCODING_ADAPTER_CLASSPATH": [],
  "REL_POS_ENCODING_ADAPTER_CLASSPATH": [],
  "TRANSFORMER_MHA_ADAPTER_CLASSPATH": [],
  "convert_adapter_cfg_to_dict_config": [
    "cfg"
  ],
  "update_adapter_cfg_input_dim": [
    "module",
    "cfg"
  ],
  "get_correct_marks": [
    "r",
    "h"
  ],
  "get_token_targets_with_confidence": [
    "hyp"
  ],
  "get_word_targets_with_confidence": [
    "hyp"
  ],
  "run_confidence_benchmark": [
    "model",
    "target_level",
    "filepaths",
    "reference_texts",
    "batch_size",
    "num_workers",
    "plot_dir",
    "use_amp"
  ],
  "apply_confidence_parameters": [
    "decoding_cfg",
    "hp"
  ],
  "LongFormSpeakerClustering": {
    "__init__": [
      "self",
      "cuda"
    ],
    "check_input": [
      "self",
      "embeddings_per_chunk",
      "chunk_cluster_count",
      "max_num_speakers"
    ],
    "unpack_labels": [
      "self",
      "Y_aggr",
      "window_range_list",
      "absolute_merge_mapping",
      "org_len"
    ],
    "split_embs_to_windows": [
      "self",
      "index",
      "emb",
      "embeddings_per_chunk"
    ],
    "forward": [
      "self",
      "param_dict"
    ],
    "get_div_ceil_count": [
      "self",
      "numer",
      "denomin"
    ],
    "long_forward_infer": [
      "self",
      "embeddings_in_scales",
      "timestamps_in_scales",
      "multiscale_segment_counts",
      "multiscale_weights",
      "oracle_num_speakers",
      "max_rp_threshold",
      "max_num_speakers",
      "sparse_search_volume",
      "fixed_thres",
      "chunk_cluster_count",
      "embeddings_per_chunk"
    ],
    "forward_infer": [
      "self",
      "embeddings_in_scales",
      "timestamps_in_scales",
      "multiscale_segment_counts",
      "multiscale_weights",
      "oracle_num_speakers",
      "max_rp_threshold",
      "max_num_speakers",
      "enhanced_count_thres",
      "sparse_search_volume",
      "fixed_thres",
      "chunk_cluster_count",
      "embeddings_per_chunk"
    ]
  },
  "flatten_char_offsets": [
    "char_offsets"
  ],
  "get_words_offsets": [
    "char_offsets",
    "encoded_char_offsets",
    "decode_tokens_to_str",
    "word_delimiter_char",
    "tokenizer_type",
    "supported_punctuation"
  ],
  "get_segment_offsets": [
    "word_offsets",
    "segment_delimiter_tokens",
    "supported_punctuation",
    "segment_gap_threshold"
  ],
  "process_aed_timestamp_outputs": [
    "outputs",
    "subsampling_factor",
    "window_stride"
  ],
  "process_timestamp_outputs": [
    "outputs",
    "subsampling_factor",
    "window_stride"
  ],
  "get_forced_aligned_timestamps_with_external_model": [
    "audio",
    "external_ctc_model",
    "main_model_predictions",
    "batch_size",
    "viterbi_device",
    "segment_separators",
    "word_separator",
    "supported_punctuation",
    "timestamp_type",
    "has_hypotheses"
  ],
  "merge_parallel_chunks": [
    "hypotheses",
    "encoded_len",
    "model",
    "timestamps",
    "subsampling_factor",
    "window_stride",
    "decoding"
  ],
  "join_y_sequence": [
    "merged_hypothesis",
    "hypotheses"
  ],
  "join_timestamp_and_add_word_and_segment_level_timestamps": [
    "merged_hypotheses",
    "hypotheses",
    "chunk_offsets",
    "subsampling_factor",
    "window_stride",
    "decoding",
    "merged_tokens"
  ],
  "join_char_level_timestamps": [
    "hypotheses",
    "chunk_offsets",
    "subsampling_factor",
    "window_stride",
    "merged_tokens"
  ],
  "merge_all_hypotheses": [
    "hypotheses_list",
    "timestamps",
    "subsampling_factor",
    "chunk_duration_seconds"
  ],
  "merge_hypotheses_of_same_audio": [
    "hypotheses_list",
    "timestamps",
    "subsampling_factor",
    "chunk_duration_seconds"
  ],
  "TEXT_METRICS_MAPPING": [],
  "flatten_dict_config": [
    "config",
    "parent_key",
    "sep",
    "join"
  ],
  "get_hydra_override_from_config": [
    "config",
    "exclude_keys"
  ],
  "strip_spaces_before_punctuations": [
    "text"
  ],
  "remove_punctuations": [
    "text",
    "punctuations"
  ],
  "clean_label": [
    "_str",
    "num_to_words",
    "langid"
  ],
  "convert_num_to_words": [
    "_str",
    "langid"
  ],
  "cal_write_wer": [
    "pred_manifest",
    "gt_text_attr_name",
    "pred_text_attr_name",
    "clean_groundtruth_text",
    "langid",
    "use_cer",
    "output_filename",
    "ignore_capitalization",
    "ignore_punctuation",
    "punctuations",
    "strip_punc_space"
  ],
  "cal_write_text_metric": [
    "pred_manifest",
    "gt_text_attr_name",
    "pred_text_attr_name",
    "output_filename",
    "ignore_capitalization",
    "ignore_punctuation",
    "punctuations",
    "metric",
    "metric_args",
    "strip_punc_space"
  ],
  "Swish": {},
  "MULTIPLIER": [],
  "INCREMENT": [],
  "MODULUS": [],
  "INIT_POINTER_VALUE": [],
  "INIT_HASH_VALUE": [],
  "INIT_PREFIX_HASH_VALUE": [],
  "hash_text": [
    "prev_hash",
    "add_labels"
  ],
  "BlankLMScoreMode": {
    "NO_SCORE": [],
    "LM_WEIGHTED_FULL": []
  },
  "PruningMode": {
    "EARLY": [],
    "LATE": []
  },
  "ASRModelTypeEnum": {
    "RNNT": [],
    "TDT": [],
    "CTC": []
  },
  "BatchedBeamHyps": {
    "__init__": [
      "self",
      "batch_size",
      "beam_size",
      "init_length",
      "blank_index",
      "device",
      "float_dtype",
      "store_prefix_hashes",
      "model_type"
    ],
    "clear_": [
      "self"
    ],
    "_allocate_more": [
      "self"
    ],
    "add_results_": [
      "self",
      "next_indices",
      "next_labels",
      "next_hyps_prob",
      "next_label_durations"
    ],
    "add_results_no_checks_": [
      "self",
      "next_indices",
      "next_labels",
      "next_hyps_prob",
      "next_label_durations"
    ],
    "recombine_hyps_": [
      "self"
    ],
    "remove_duplicates": [
      "self",
      "labels",
      "total_logps"
    ],
    "recombine_prefixes": [
      "self",
      "label_logps",
      "active_mask"
    ],
    "to_hyps_list": [
      "self",
      "score_norm"
    ],
    "to_nbest_hyps_list": [
      "self",
      "score_norm"
    ],
    "flatten_sort_": [
      "self",
      "score_norm"
    ],
    "_create_fold_consecutive_mask": [
      "self",
      "transcript"
    ],
    "_create_timestamps_tensor": [
      "self",
      "max_time"
    ],
    "_create_transcripts_mask": [
      "self",
      "transcripts"
    ]
  },
  "MIN_MERGE_SUBSEQUENCE_LEN": [],
  "print_alignment": [
    "alignment"
  ],
  "write_lcs_alignment_to_pickle": [
    "alignment",
    "filepath",
    "extras"
  ],
  "longest_common_subsequence_merge": [
    "X",
    "Y",
    "filepath"
  ],
  "lcs_alignment_merge_buffer": [
    "buffer",
    "data",
    "delay",
    "model",
    "max_steps_per_timestep",
    "filepath",
    "min_lcs_length",
    "parallel_chunking"
  ],
  "inplace_buffer_merge": [
    "buffer",
    "data",
    "timesteps",
    "model"
  ],
  "StreamingFeatureBufferer": {
    "__init__": [
      "self",
      "asr_model",
      "chunk_size",
      "buffer_size"
    ],
    "reset": [
      "self"
    ],
    "_add_chunk_to_buffer": [
      "self",
      "chunk"
    ],
    "_update_feature_buffer": [
      "self",
      "feat_chunk"
    ],
    "get_raw_feature_buffer": [
      "self"
    ],
    "get_normalized_feature_buffer": [
      "self"
    ],
    "_convert_buffer_to_features": [
      "self"
    ],
    "update_feature_buffer": [
      "self",
      "chunk"
    ]
  },
  "AudioFeatureIterator": {
    "__init__": [
      "self",
      "samples",
      "frame_len",
      "preprocessor",
      "device",
      "pad_to_frame_len"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ]
  },
  "speech_collate_fn": [
    "batch"
  ],
  "AudioBuffersDataLayer": {
    "output_types": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "set_signal": [
      "self",
      "signals"
    ],
    "__len__": [
      "self"
    ]
  },
  "FeatureFrameBufferer": {
    "__init__": [
      "self",
      "asr_model",
      "frame_len",
      "batch_size",
      "total_buffer",
      "pad_to_buffer_len"
    ],
    "reset": [
      "self"
    ],
    "get_batch_frames": [
      "self"
    ],
    "get_frame_buffers": [
      "self",
      "frames"
    ],
    "set_frame_reader": [
      "self",
      "frame_reader"
    ],
    "_update_feature_buffer": [
      "self",
      "feat_frame"
    ],
    "get_norm_consts_per_frame": [
      "self",
      "batch_frames"
    ],
    "normalize_frame_buffers": [
      "self",
      "frame_buffers",
      "norm_consts"
    ],
    "get_buffers_batch": [
      "self"
    ]
  },
  "FrameBatchASR": {
    "__init__": [
      "self",
      "asr_model",
      "frame_len",
      "total_buffer",
      "batch_size",
      "pad_to_buffer_len"
    ],
    "reset": [
      "self"
    ],
    "read_audio_file": [
      "self",
      "audio_filepath",
      "delay",
      "model_stride_in_secs"
    ],
    "set_frame_reader": [
      "self",
      "frame_reader"
    ],
    "infer_logits": [
      "self",
      "keep_logits"
    ],
    "_get_batch_preds": [
      "self",
      "keep_logits"
    ],
    "transcribe": [
      "self",
      "tokens_per_chunk",
      "delay",
      "keep_logits"
    ],
    "greedy_merge": [
      "self",
      "preds"
    ]
  },
  "BatchedFeatureFrameBufferer": {
    "__init__": [
      "self",
      "asr_model",
      "frame_len",
      "batch_size",
      "total_buffer"
    ],
    "reset": [
      "self"
    ],
    "get_batch_frames": [
      "self"
    ],
    "get_frame_buffers": [
      "self",
      "frames"
    ],
    "set_frame_reader": [
      "self",
      "frame_reader",
      "idx"
    ],
    "_update_feature_buffer": [
      "self",
      "feat_frame",
      "idx"
    ],
    "get_norm_consts_per_frame": [
      "self",
      "batch_frames"
    ],
    "normalize_frame_buffers": [
      "self",
      "frame_buffers",
      "norm_consts"
    ],
    "get_buffers_batch": [
      "self"
    ]
  },
  "BatchedFrameASRRNNT": {
    "__init__": [
      "self",
      "asr_model",
      "frame_len",
      "total_buffer",
      "batch_size",
      "max_steps_per_timestep",
      "stateful_decoding",
      "target_lang_id"
    ],
    "set_target_lang_id": [
      "self",
      "target_lang_id"
    ],
    "reset": [
      "self"
    ],
    "read_audio_file": [
      "self",
      "audio_filepath",
      "delay",
      "model_stride_in_secs"
    ],
    "set_frame_reader": [
      "self",
      "frame_reader",
      "idx"
    ],
    "infer_logits": [
      "self"
    ],
    "_get_batch_preds": [
      "self"
    ],
    "transcribe": [
      "self",
      "tokens_per_chunk",
      "delay"
    ],
    "_alignment_decoder": [
      "self",
      "alignments",
      "tokenizer",
      "blank_id"
    ],
    "greedy_merge": [
      "self",
      "preds"
    ]
  },
  "BatchedFrameASRTDT": {
    "__init__": [
      "self",
      "asr_model",
      "frame_len",
      "total_buffer",
      "batch_size",
      "max_steps_per_timestep",
      "stateful_decoding",
      "tdt_search_boundary"
    ],
    "transcribe": [
      "self",
      "tokens_per_chunk",
      "delay"
    ]
  },
  "LongestCommonSubsequenceBatchedFrameASRRNNT": {
    "__init__": [
      "self",
      "asr_model",
      "frame_len",
      "total_buffer",
      "batch_size",
      "max_steps_per_timestep",
      "stateful_decoding",
      "alignment_basepath"
    ],
    "transcribe": [
      "self",
      "tokens_per_chunk",
      "delay"
    ]
  },
  "CacheAwareStreamingAudioBuffer": {
    "__init__": [
      "self",
      "model",
      "online_normalization",
      "pad_and_drop_preencoded"
    ],
    "__iter__": [
      "self"
    ],
    "is_buffer_empty": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "reset_buffer": [
      "self"
    ],
    "reset_buffer_pointer": [
      "self"
    ],
    "extract_preprocessor": [
      "self"
    ],
    "append_audio_file": [
      "self",
      "audio_filepath",
      "stream_id"
    ],
    "append_audio": [
      "self",
      "audio",
      "stream_id"
    ],
    "append_processed_signal": [
      "self",
      "processed_signal",
      "stream_id"
    ],
    "get_model_device": [
      "self"
    ],
    "preprocess_audio": [
      "self",
      "audio",
      "device"
    ],
    "get_all_audios": [
      "self"
    ]
  },
  "FrameBatchMultiTaskAED": {
    "__init__": [
      "self",
      "asr_model",
      "frame_len",
      "total_buffer",
      "batch_size"
    ],
    "reset": [
      "self"
    ],
    "infer_logits": [
      "self",
      "keep_logits",
      "timestamps"
    ],
    "get_input_tokens": [
      "self",
      "sample"
    ],
    "read_audio_file": [
      "self",
      "audio_filepath",
      "delay",
      "model_stride_in_secs",
      "meta_data"
    ],
    "_get_batch_preds": [
      "self",
      "keep_logits",
      "timestamps"
    ],
    "transcribe": [
      "self",
      "tokens_per_chunk",
      "delay",
      "keep_logits",
      "timestamps"
    ],
    "_join_hypotheses": [
      "self",
      "hypotheses",
      "timestamps"
    ],
    "_join_text": [
      "self",
      "merged_hypothesis",
      "hypotheses"
    ],
    "_join_y_sequence": [
      "self",
      "merged_hypothesis",
      "hypotheses"
    ],
    "_join_timestamp": [
      "self",
      "merged_hypothesis",
      "hypotheses"
    ]
  },
  "FrameBatchChunkedRNNT": {
    "__init__": [
      "self",
      "asr_model",
      "frame_len",
      "total_buffer",
      "batch_size"
    ],
    "read_audio_file": [
      "self",
      "audio_filepath",
      "delay",
      "model_stride_in_secs"
    ],
    "_get_batch_preds": [
      "self",
      "keep_logits"
    ],
    "transcribe": [
      "self",
      "tokens_per_chunk",
      "delay",
      "keep_logits"
    ]
  },
  "FrameBatchChunkedCTC": {
    "__init__": [
      "self",
      "asr_model",
      "frame_len",
      "total_buffer",
      "batch_size"
    ],
    "read_audio_file": [
      "self",
      "audio_filepath",
      "delay",
      "model_stride_in_secs"
    ],
    "_get_batch_preds": [
      "self",
      "keep_logits"
    ],
    "transcribe": [
      "self",
      "tokens_per_chunk",
      "delay",
      "keep_logits"
    ]
  },
  "ContextSize": {
    "total": [
      "self"
    ],
    "subsample": [
      "self",
      "factor"
    ],
    "add_frames_get_removed_": [
      "self",
      "num_frames",
      "is_last_chunk",
      "expected_context"
    ],
    "__str__": [
      "self"
    ]
  },
  "ContextSizeBatch": {
    "total": [
      "self"
    ],
    "subsample": [
      "self",
      "factor"
    ],
    "add_frames_": [
      "self",
      "num_frames_batch",
      "is_last_chunk_batch",
      "expected_context"
    ]
  },
  "StreamingBatchedAudioBuffer": {
    "__init__": [
      "self",
      "batch_size",
      "context_samples",
      "dtype",
      "device"
    ],
    "add_audio_batch_": [
      "self",
      "audio_batch",
      "audio_lengths",
      "is_last_chunk",
      "is_last_chunk_batch"
    ]
  },
  "AudioBatch": {
    "collate_fn": [
      "audio_batch"
    ]
  },
  "SimpleAudioDataset": {
    "__init__": [
      "self",
      "audio_filenames",
      "sample_rate"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "__len__": [
      "self"
    ]
  },
  "get_rounded_str_float": [
    "num",
    "output_precision",
    "min_precision",
    "max_precision"
  ],
  "get_ctm_line": [
    "source",
    "channel",
    "start_time",
    "duration",
    "token",
    "conf",
    "type_of_token",
    "speaker",
    "NA_token",
    "UNK",
    "default_channel",
    "output_precision"
  ],
  "rreplace": [
    "s",
    "old",
    "new"
  ],
  "get_uniq_id_with_period": [
    "path"
  ],
  "get_subsegment_dict": [
    "subsegments_manifest_file",
    "window",
    "shift",
    "deci"
  ],
  "get_input_manifest_dict": [
    "input_manifest_path"
  ],
  "write_truncated_subsegments": [
    "input_manifest_dict",
    "_subsegment_dict",
    "output_manifest_path",
    "step_count",
    "deci"
  ],
  "write_file": [
    "name",
    "lines",
    "idx"
  ],
  "read_file": [
    "pathlist"
  ],
  "get_dict_from_wavlist": [
    "pathlist"
  ],
  "get_dict_from_list": [
    "data_pathlist",
    "uniqids"
  ],
  "get_path_dict": [
    "data_path",
    "uniqids",
    "len_wavs"
  ],
  "create_segment_manifest": [
    "input_manifest_path",
    "output_manifest_path",
    "window",
    "shift",
    "step_count",
    "deci"
  ],
  "create_manifest": [
    "wav_path",
    "manifest_filepath",
    "text_path",
    "rttm_path",
    "uem_path",
    "ctm_path",
    "add_duration"
  ],
  "read_manifest": [
    "manifest"
  ],
  "write_manifest": [
    "output_path",
    "target_manifest",
    "ensure_ascii"
  ],
  "write_ctm": [
    "output_path",
    "target_ctm"
  ],
  "write_text": [
    "output_path",
    "target_ctm"
  ],
  "filepath_to_absolute": [
    "filepath",
    "base_path"
  ],
  "_MPS_WARNING_TEXT": [],
  "get_auto_inference_device": [
    "allow_mps"
  ],
  "get_inference_device": [
    "cuda",
    "allow_mps"
  ],
  "get_auto_inference_dtype": [
    "device"
  ],
  "get_inference_dtype": [
    "compute_dtype",
    "device"
  ],
  "get_buffered_pred_feat_rnnt": [
    "asr",
    "tokens_per_chunk",
    "delay",
    "model_stride_in_secs",
    "batch_size",
    "manifest",
    "filepaths",
    "target_lang_id",
    "accelerator"
  ],
  "get_buffered_pred_feat": [
    "asr",
    "frame_len",
    "tokens_per_chunk",
    "delay",
    "preprocessor_cfg",
    "model_stride_in_secs",
    "device",
    "manifest",
    "filepaths"
  ],
  "get_buffered_pred_feat_multitaskAED": [
    "asr",
    "preprocessor_cfg",
    "model_stride_in_secs",
    "device",
    "manifest",
    "filepaths",
    "delay",
    "timestamps"
  ],
  "wrap_transcription": [
    "hyps"
  ],
  "prepare_audio_data": [
    "cfg"
  ],
  "read_and_maybe_sort_manifest": [
    "path",
    "try_sort"
  ],
  "restore_transcription_order": [
    "manifest_path",
    "transcriptions"
  ],
  "compute_output_filename": [
    "cfg",
    "model_name"
  ],
  "normalize_timestamp_output": [
    "timestamps"
  ],
  "write_transcription": [
    "transcriptions",
    "cfg",
    "model_name",
    "filepaths",
    "compute_langs",
    "timestamps"
  ],
  "compute_metrics_per_sample": [
    "manifest_path",
    "reference_field",
    "hypothesis_field",
    "metrics",
    "punctuation_marks",
    "output_manifest_path"
  ],
  "PunctuationCapitalization": {
    "__init__": [
      "self",
      "punctuation_marks"
    ],
    "separate_punctuation": [
      "self",
      "lines"
    ],
    "do_lowercase": [
      "self",
      "lines"
    ],
    "rm_punctuation": [
      "self",
      "lines"
    ]
  },
  "TextProcessingConfig": {},
  "phase_vocoder": [
    "D",
    "rate",
    "phi_advance",
    "scale_buffer"
  ],
  "_phase_vocoder_kernel": [
    "D",
    "time_steps",
    "phi_advance",
    "d_stretch",
    "phase_acc",
    "scale_buffer"
  ],
  "SequenceGeneratorConfig": {},
  "SequenceGenerator": {
    "TYPE_GREEDY": [],
    "TYPE_TOPK": [],
    "TYPE_BEAM": [],
    "SEARCHER_TYPES": [],
    "__init__": [
      "self",
      "cfg",
      "embedding",
      "decoder",
      "log_softmax",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "encoder_states",
      "encoder_input_mask",
      "return_beam_scores",
      "pad_max_len",
      "return_length"
    ],
    "get_seq_length": [
      "self",
      "seq"
    ],
    "decode_semantics_from_tokens": [
      "self",
      "seq_tokens"
    ]
  },
  "get_seq_length": [
    "seq",
    "eos_id"
  ],
  "pad_sequence": [
    "seq",
    "max_len",
    "pad_token"
  ],
  "get_seq_mask": [
    "seq",
    "seq_lens"
  ],
  "get_color_palette": [],
  "dump_json_to_file": [
    "file_path",
    "session_trans_dict"
  ],
  "write_txt": [
    "w_path",
    "val"
  ],
  "init_session_trans_dict": [
    "uniq_id",
    "n_spk"
  ],
  "init_session_gecko_dict": [],
  "convert_ctm_to_text": [
    "ctm_file_path"
  ],
  "convert_word_dict_seq_to_text": [
    "word_dict_seq_list"
  ],
  "convert_word_dict_seq_to_ctm": [
    "word_dict_seq_list",
    "uniq_id",
    "decimals"
  ],
  "get_total_result_dict": [
    "der_results",
    "wer_results",
    "csv_columns"
  ],
  "get_audacity_label": [
    "word",
    "stt_sec",
    "end_sec",
    "speaker"
  ],
  "get_num_of_spk_from_labels": [
    "labels"
  ],
  "convert_seglst": [
    "seglst",
    "all_speakers"
  ],
  "get_session_trans_dict": [
    "uniq_id",
    "word_dict_seq_list",
    "diar_labels"
  ],
  "print_sentences": [
    "sentences",
    "color_palette",
    "params"
  ],
  "read_seglst": [
    "seglst_filepath",
    "round_digits",
    "return_rttm",
    "sort_by_start_time",
    "sort_by_end_time"
  ],
  "chunk_seglst": [
    "seglst",
    "chunk_size"
  ],
  "OnlineEvaluation": {
    "__init__": [
      "self",
      "ref_seglst",
      "ref_rttm_labels",
      "hyp_seglst",
      "collar",
      "ignore_overlap",
      "verbose"
    ],
    "evaluate_inloop": [
      "self",
      "hyp_seglst",
      "end_step_time"
    ],
    "evaluate_outofloop": [
      "self",
      "chunk_size"
    ],
    "evaluate": [
      "self",
      "ref_seglst",
      "hyp_seglst",
      "chunk_size",
      "verbose"
    ]
  },
  "OfflineDiarWithASR": {
    "__init__": [
      "self",
      "cfg_diarizer"
    ],
    "get_csv_columns": [],
    "make_file_lists": [
      "self"
    ],
    "_load_realigning_LM": [
      "self"
    ],
    "_save_VAD_labels_list": [
      "self",
      "word_ts_dict"
    ],
    "get_speech_labels_from_decoded_prediction": [
      "input_word_ts",
      "nonspeech_threshold"
    ],
    "run_diarization": [
      "self",
      "diar_model_config",
      "word_timestamps"
    ],
    "_get_frame_level_VAD": [
      "self",
      "vad_processing_dir",
      "smoothing_type"
    ],
    "gather_eval_results": [
      "diar_score",
      "audio_rttm_map_dict",
      "trans_info_dict",
      "root_path",
      "decimals"
    ],
    "_get_the_closest_silence_start": [
      "self",
      "vad_index_word_end",
      "vad_frames",
      "offset"
    ],
    "_compensate_word_ts_list": [
      "self",
      "audio_file_list",
      "word_ts_dict"
    ],
    "get_transcript_with_speaker_labels": [
      "self",
      "diar_hyp",
      "word_hyp",
      "word_ts_hyp"
    ],
    "get_word_level_json_list": [
      "self",
      "words",
      "diar_labels",
      "word_ts",
      "word_rfnd_ts",
      "decimals"
    ],
    "_make_json_output": [
      "self",
      "uniq_id",
      "diar_labels",
      "word_dict_seq_list"
    ],
    "_get_realignment_ranges": [
      "self",
      "k",
      "word_seq_len"
    ],
    "_get_word_timestamp_anchor": [
      "self",
      "word_ts_stt_end"
    ],
    "realign_words_with_lm": [
      "self",
      "word_dict_seq_list"
    ],
    "evaluate": [
      "audio_file_list",
      "hyp_trans_info_dict",
      "hyp_ctm_file_list",
      "ref_ctm_file_list"
    ],
    "get_str_speech_labels": [
      "speech_labels_float"
    ],
    "write_session_level_result_in_csv": [
      "der_results",
      "wer_results",
      "root_path",
      "csv_columns",
      "csv_file_name"
    ],
    "_write_and_log": [
      "self",
      "uniq_id",
      "session_trans_dict",
      "audacity_label_words",
      "gecko_dict",
      "sentences"
    ],
    "break_transcript_lines": [
      "self",
      "string_out",
      "params",
      "max_chars_in_line"
    ],
    "print_errors": [
      "der_results",
      "wer_results"
    ]
  },
  "if_none_get_default": [
    "param",
    "default_value"
  ],
  "WERBPE_TS": {
    "__init__": [
      "self",
      "tokenizer",
      "batch_dim_index",
      "use_cer",
      "ctc_decode",
      "log_prediction",
      "dist_sync_on_step"
    ],
    "ctc_decoder_predictions_tensor_with_ts": [
      "self",
      "time_stride",
      "predictions",
      "predictions_len"
    ],
    "decode_tokens_to_str_with_ts": [
      "self",
      "tokens"
    ],
    "decode_ids_to_tokens_with_ts": [
      "self",
      "tokens"
    ],
    "get_ts_from_decoded_prediction": [
      "self",
      "decoded_prediction",
      "hypothesis",
      "char_ts"
    ]
  },
  "WER_TS": {
    "__init__": [
      "self",
      "vocabulary",
      "batch_dim_index",
      "use_cer",
      "ctc_decode",
      "log_prediction",
      "dist_sync_on_step"
    ],
    "decode_tokens_to_str_with_ts": [
      "self",
      "tokens",
      "timestamps"
    ],
    "decode_ids_to_tokens_with_ts": [
      "self",
      "tokens",
      "timestamps"
    ],
    "ctc_decoder_predictions_tensor_with_ts": [
      "self",
      "predictions",
      "predictions_len"
    ]
  },
  "get_wer_feat_logit": [
    "audio_file_path",
    "asr",
    "frame_len",
    "tokens_per_chunk",
    "delay",
    "model_stride_in_secs"
  ],
  "FrameBatchASRLogits": {
    "__init__": [
      "self",
      "asr_model",
      "frame_len",
      "total_buffer",
      "batch_size"
    ],
    "clear_buffer": [
      "self"
    ],
    "read_audio_file_and_return": [
      "self",
      "audio_filepath",
      "delay",
      "model_stride_in_secs"
    ],
    "_get_batch_preds": [
      "self",
      "keep_logits"
    ],
    "transcribe_with_ts": [
      "self",
      "tokens_per_chunk",
      "delay"
    ]
  },
  "ASRDecoderTimeStamps": {
    "__init__": [
      "self",
      "cfg_diarizer"
    ],
    "set_asr_model": [
      "self"
    ],
    "load_LM_for_CTC_decoder": [
      "self",
      "asr_model"
    ],
    "run_ASR_QuartzNet_CTC": [
      "self",
      "asr_model"
    ],
    "clean_trans_and_TS": [
      "trans",
      "char_ts"
    ],
    "_get_spaces": [
      "self",
      "trans",
      "char_ts",
      "time_stride"
    ],
    "run_ASR_CitriNet_CTC": [
      "self",
      "asr_model"
    ],
    "set_buffered_infer_params": [
      "self",
      "asr_model"
    ],
    "run_ASR_BPE_CTC": [
      "self",
      "asr_model"
    ],
    "get_word_ts_from_spaces": [
      "self",
      "char_ts",
      "spaces_in_sec",
      "end_stamp"
    ],
    "run_pyctcdecode": [
      "self",
      "logprob",
      "onset_delay_in_sec",
      "beam_width"
    ],
    "get_word_ts_from_wordframes": [
      "idx",
      "word_frames",
      "frame_duration",
      "onset_delay",
      "word_block_delay"
    ],
    "align_decoder_delay": [
      "word_ts",
      "decoder_delay_in_sec"
    ]
  },
  "Hypothesis": {
    "non_blank_frame_confidence": [
      "self"
    ],
    "words": [
      "self"
    ],
    "merge_": [
      "self",
      "other"
    ],
    "clean_decoding_state_": [
      "self"
    ]
  },
  "NBestHypotheses": {},
  "HATJointOutput": {},
  "is_prefix": [
    "x",
    "pref"
  ],
  "select_k_expansions": [
    "hyps",
    "topk_idxs",
    "topk_logps",
    "gamma",
    "beta"
  ],
  "BatchedHyps": {
    "__init__": [
      "self",
      "batch_size",
      "init_length",
      "device",
      "float_dtype",
      "is_with_durations"
    ],
    "clear_": [
      "self"
    ],
    "_allocate_more": [
      "self"
    ],
    "add_results_": [
      "self",
      "active_indices",
      "labels",
      "time_indices",
      "scores",
      "token_durations"
    ],
    "add_results_no_checks_": [
      "self",
      "active_indices",
      "labels",
      "time_indices",
      "scores",
      "token_durations"
    ],
    "add_results_masked_": [
      "self",
      "active_mask",
      "labels",
      "time_indices",
      "scores",
      "token_durations"
    ],
    "add_results_masked_no_checks_": [
      "self",
      "active_mask",
      "labels",
      "time_indices",
      "scores",
      "token_durations"
    ],
    "get_last_labels": [
      "self",
      "pad_id"
    ],
    "clone": [
      "self"
    ],
    "merge_": [
      "self",
      "other"
    ]
  },
  "BatchedAlignments": {
    "__init__": [
      "self",
      "batch_size",
      "logits_dim",
      "init_length",
      "device",
      "float_dtype",
      "store_alignments",
      "store_frame_confidence",
      "with_duration_confidence"
    ],
    "clear_": [
      "self"
    ],
    "_allocate_more": [
      "self"
    ],
    "add_results_": [
      "self",
      "active_indices",
      "time_indices",
      "logits",
      "labels",
      "confidence"
    ],
    "add_results_masked_": [
      "self",
      "active_mask",
      "time_indices",
      "logits",
      "labels",
      "confidence"
    ],
    "add_results_masked_no_checks_": [
      "self",
      "active_mask",
      "time_indices",
      "logits",
      "labels",
      "confidence"
    ],
    "clone": [
      "self"
    ]
  },
  "batched_hyps_to_hypotheses": [
    "batched_hyps",
    "alignments",
    "batch_size"
  ],
  "PostProcessingParams": {},
  "load_postprocessing_from_yaml": [
    "postprocessing_yaml"
  ],
  "prepare_manifest": [
    "config"
  ],
  "write_vad_infer_manifest_star": [
    "args"
  ],
  "write_vad_infer_manifest": [
    "file",
    "args_func"
  ],
  "get_vad_stream_status": [
    "data"
  ],
  "load_tensor_from_file": [
    "filepath"
  ],
  "generate_overlap_vad_seq": [
    "frame_pred_dir",
    "smoothing_method",
    "overlap",
    "window_length_in_sec",
    "shift_length_in_sec",
    "num_workers",
    "out_dir"
  ],
  "generate_overlap_vad_seq_per_file_star": [
    "args"
  ],
  "generate_overlap_vad_seq_per_tensor": [
    "frame",
    "per_args",
    "smoothing_method"
  ],
  "generate_overlap_vad_seq_per_file": [
    "frame_filepath",
    "per_args"
  ],
  "merge_overlap_segment": [
    "segments"
  ],
  "filter_short_segments": [
    "segments",
    "threshold"
  ],
  "percentile": [
    "data",
    "perc"
  ],
  "cal_vad_onset_offset": [
    "scale",
    "onset",
    "offset",
    "sequence"
  ],
  "binarization": [
    "sequence",
    "per_args"
  ],
  "remove_segments": [
    "original_segments",
    "to_be_removed_segments"
  ],
  "get_gap_segments": [
    "segments"
  ],
  "filtering": [
    "speech_segments",
    "per_args"
  ],
  "prepare_gen_segment_table": [
    "sequence",
    "per_args"
  ],
  "generate_vad_segment_table_per_tensor": [
    "sequence",
    "per_args"
  ],
  "generate_vad_segment_table_per_file": [
    "pred_filepath",
    "per_args"
  ],
  "generate_vad_segment_table": [
    "vad_pred_dir",
    "postprocessing_params",
    "frame_length_in_sec",
    "num_workers",
    "out_dir",
    "use_rttm"
  ],
  "generate_vad_segment_table_per_file_star": [
    "args"
  ],
  "vad_construct_pyannote_object_per_file": [
    "vad_table_filepath",
    "groundtruth_RTTM_file"
  ],
  "get_parameter_grid": [
    "params"
  ],
  "vad_tune_threshold_on_dev": [
    "params",
    "vad_pred",
    "groundtruth_RTTM",
    "result_file",
    "vad_pred_method",
    "focus_metric",
    "frame_length_in_sec",
    "num_workers"
  ],
  "check_if_param_valid": [
    "params"
  ],
  "pred_rttm_map": [
    "vad_pred",
    "groundtruth_RTTM",
    "vad_pred_method"
  ],
  "plot": [
    "path2audio_file",
    "path2_vad_pred",
    "path2groundtruth_rttm",
    "groundtruth_labels",
    "sample_rate",
    "offset",
    "duration",
    "threshold",
    "per_args",
    "unit_frame_len",
    "label_repeat",
    "xticks_step"
  ],
  "gen_pred_from_speech_segments": [
    "speech_segments",
    "prob",
    "shift_length_in_sec"
  ],
  "extract_labels": [
    "path2ground_truth_label",
    "time"
  ],
  "generate_vad_frame_pred": [
    "vad_model",
    "window_length_in_sec",
    "shift_length_in_sec",
    "manifest_vad_input",
    "out_dir",
    "use_feat"
  ],
  "init_vad_model": [
    "model_path"
  ],
  "init_frame_vad_model": [
    "model_path"
  ],
  "stitch_segmented_asr_output": [
    "segmented_output_manifest",
    "speech_segments_tensor_dir",
    "stitched_output_manifest"
  ],
  "construct_manifest_eval": [
    "input_manifest",
    "stitched_output_manifest",
    "aligned_vad_asr_output_manifest"
  ],
  "load_rttm_file": [
    "filepath"
  ],
  "merge_intervals": [
    "intervals"
  ],
  "load_speech_segments_from_rttm": [
    "rttm_file"
  ],
  "load_speech_overlap_segments_from_rttm": [
    "rttm_file"
  ],
  "get_nonspeech_segments": [
    "speech_segments",
    "max_duration"
  ],
  "get_frame_labels": [
    "segments",
    "frame_length",
    "offset",
    "duration",
    "as_str"
  ],
  "plot_sample_from_rttm": [
    "audio_file",
    "rttm_file",
    "max_duration",
    "save_path",
    "show",
    "offset",
    "unit_frame_len"
  ],
  "align_labels_to_frames": [
    "probs",
    "labels",
    "threshold"
  ],
  "read_rttm_as_pyannote_object": [
    "rttm_file",
    "speaker_override"
  ],
  "convert_labels_to_speech_segments": [
    "labels",
    "frame_length_in_sec"
  ],
  "frame_vad_construct_pyannote_object_per_file": [
    "prediction",
    "groundtruth",
    "frame_length_in_sec"
  ],
  "frame_vad_infer_load_manifest": [
    "cfg"
  ],
  "frame_vad_eval_detection_error": [
    "pred_dir",
    "key_labels_map",
    "key_rttm_map",
    "key_pred_rttm_map",
    "frame_length_in_sec"
  ],
  "ts_vad_post_processing": [
    "ts_vad_binary_vec",
    "cfg_vad_params",
    "unit_10ms_frame_count",
    "bypass_postprocessing"
  ],
  "predlist_to_timestamps": [
    "batch_preds_list",
    "audio_rttm_map_dict",
    "cfg_vad_params",
    "unit_10ms_frame_count",
    "bypass_postprocessing",
    "precision"
  ],
  "get_lsa_speaker_mapping": [
    "U_set",
    "cmm_P",
    "cmm_Q",
    "PandQ"
  ],
  "get_minimal_indices": [
    "Y_new"
  ],
  "stitch_cluster_labels": [
    "Y_old",
    "Y_new"
  ],
  "calculate_removable_counts": [
    "removable_counts_mat",
    "remain_count",
    "num_clus"
  ],
  "get_merge_quantity": [
    "num_to_be_removed",
    "pre_clus_labels",
    "min_count_per_cluster"
  ],
  "merge_vectors": [
    "selected_inds",
    "emb_ndx",
    "pre_cluster_labels"
  ],
  "get_closest_embeddings": [
    "affinity_mat",
    "n_closest"
  ],
  "run_reducer": [
    "pre_embs",
    "target_spk_idx",
    "merge_quantity",
    "pre_clus_labels"
  ],
  "get_first_arg_index": [
    "mat",
    "label"
  ],
  "OnlineSpeakerClustering": {
    "__init__": [
      "self",
      "max_num_speakers",
      "max_rp_threshold",
      "enhanced_count_thres",
      "fixed_thres",
      "sparse_search_volume",
      "history_buffer_size",
      "current_buffer_size",
      "min_spk_counting_buffer_size",
      "min_frame_per_spk",
      "p_update_freq",
      "p_value_skip_frame_thres",
      "p_value_queue_size",
      "use_temporal_label_major_vote",
      "temporal_label_major_vote_buffer_size",
      "cuda"
    ],
    "onlineNMEanalysis": [
      "self",
      "mat_in",
      "frame_index"
    ],
    "speaker_counter_buffer": [
      "self",
      "est_num_of_spk"
    ],
    "limit_frames_per_speaker": [
      "self",
      "frame_index",
      "est_num_of_spk"
    ],
    "online_spk_num_estimation": [
      "self",
      "mat_in",
      "frame_index"
    ],
    "prepare_embedding_update": [
      "self",
      "emb_in",
      "segment_indexes_matrix"
    ],
    "make_constant_length_emb": [
      "self",
      "emb_in",
      "base_segment_indexes"
    ],
    "update_speaker_history_buffer": [
      "self",
      "emb_in",
      "base_segment_indexes"
    ],
    "get_reduced_mat": [
      "self",
      "emb_in",
      "base_segment_indexes"
    ],
    "match_labels": [
      "self",
      "Y_merged",
      "add_new"
    ],
    "forward": [
      "self",
      "curr_emb",
      "base_segment_indexes",
      "max_num_speakers",
      "max_rp_threshold",
      "enhanced_count_thres",
      "sparse_search_volume",
      "frame_index",
      "cuda"
    ],
    "forward_infer": [
      "self",
      "curr_emb",
      "base_segment_indexes",
      "max_num_speakers",
      "max_rp_threshold",
      "enhanced_count_thres",
      "sparse_search_volume",
      "fixed_thres",
      "frame_index",
      "cuda"
    ]
  },
  "measure_eta": [
    "func"
  ],
  "format_time": [
    "seconds"
  ],
  "add_delay_for_real_time": [
    "cfg",
    "chunk_audio",
    "session_start_time",
    "feat_frame_count",
    "loop_end_time",
    "loop_start_time"
  ],
  "write_seglst_file": [
    "seglst_dict_list",
    "output_path"
  ],
  "get_multi_talker_samples_from_manifest": [
    "cfg",
    "manifest_file",
    "feat_per_sec",
    "max_spks"
  ],
  "setup_diarization_model": [
    "cfg",
    "map_location"
  ],
  "write_seglst": [
    "output_filepath",
    "seglst_list"
  ],
  "get_new_sentence_dict": [
    "speaker",
    "start_time",
    "end_time",
    "text",
    "session_id"
  ],
  "fix_frame_time_step": [
    "cfg",
    "new_tokens",
    "new_words",
    "frame_inds_seq"
  ],
  "get_simulated_softmax": [
    "cfg",
    "speaker_sigmoid"
  ],
  "get_word_dict_content_offline": [
    "cfg",
    "word",
    "word_index",
    "diar_pred_out",
    "time_stt_end_tuple",
    "frame_len"
  ],
  "get_word_dict_content_online": [
    "cfg",
    "word",
    "word_index",
    "diar_pred_out_stream",
    "token_group",
    "frame_inds_seq",
    "time_step_local_offset",
    "frame_len"
  ],
  "get_multitoken_words": [
    "cfg",
    "word_and_ts_seq",
    "word_seq",
    "new_words",
    "fix_prev_words_count"
  ],
  "append_word_and_ts_seq": [
    "cfg",
    "word_idx_offset",
    "word_and_ts_seq",
    "word_dict"
  ],
  "SpeakerTaggedASR": {
    "__init__": [
      "self",
      "cfg",
      "asr_model",
      "diar_model"
    ],
    "_init_evaluator": [
      "self"
    ],
    "_get_offset_sentence": [
      "self",
      "session_trans_dict",
      "offset"
    ],
    "_get_sentence": [
      "self",
      "word_dict"
    ],
    "get_sentences_values": [
      "self",
      "session_trans_dict",
      "sentence_render_length"
    ],
    "merge_transcript_and_speakers": [
      "self",
      "test_manifest_dict",
      "asr_hypotheses",
      "diar_pred_out"
    ],
    "get_frame_and_words_offline": [
      "self",
      "uniq_id",
      "diar_pred_out",
      "asr_hypothesis",
      "word_and_ts_seq"
    ],
    "get_frame_and_words_online": [
      "self",
      "uniq_id",
      "step_num",
      "diar_pred_out_stream",
      "previous_hypothesis",
      "word_and_ts_seq"
    ],
    "_add_speaker_transcriptions": [
      "self",
      "transcriptions",
      "speaker_transcriptions",
      "word_and_ts_seq",
      "test_manifest_dict"
    ],
    "perform_offline_stt_spk": [
      "self",
      "override_cfg"
    ],
    "generate_seglst_dicts_from_serial_streaming": [
      "self",
      "samples"
    ],
    "generate_seglst_dicts_from_parallel_streaming": [
      "self",
      "samples"
    ],
    "_find_active_speakers": [
      "self",
      "diar_preds",
      "n_active_speakers_per_stream"
    ],
    "forward_pre_encoded": [
      "self",
      "audio_signal",
      "length",
      "drop_extra_pre_encoded"
    ],
    "mask_features": [
      "self",
      "chunk_audio",
      "mask",
      "threshold",
      "mask_value"
    ],
    "mask_preencode": [
      "self",
      "chunk_audio",
      "mask",
      "threshold"
    ],
    "get_diar_pred_out_stream": [
      "self",
      "step_num"
    ],
    "perform_serial_streaming_stt_spk": [
      "self",
      "step_num",
      "chunk_audio",
      "chunk_lengths",
      "is_buffer_empty",
      "drop_extra_pre_encoded"
    ],
    "perform_parallel_streaming_stt_spk": [
      "self",
      "step_num",
      "chunk_audio",
      "chunk_lengths",
      "is_buffer_empty",
      "drop_extra_pre_encoded"
    ]
  },
  "MultiTalkerInstanceManager": {
    "__init__": [
      "self",
      "asr_model",
      "diar_model",
      "batch_size",
      "max_num_of_spks",
      "sent_break_sec"
    ],
    "_reset_active_speaker_buffers": [
      "self"
    ],
    "reset": [
      "self",
      "batch_size",
      "max_num_of_spks"
    ],
    "add_speaker": [
      "self",
      "batch_idx",
      "speaker_id"
    ],
    "get_speakers": [
      "self",
      "batch_idx"
    ],
    "to": [
      "self",
      "device"
    ],
    "update_diar_state": [
      "self",
      "diar_pred_out_stream",
      "previous_chunk_preds",
      "diar_streaming_state"
    ],
    "update_asr_state": [
      "self",
      "batch_idx",
      "speaker_id",
      "cache_last_channel",
      "cache_last_time",
      "cache_last_channel_len",
      "previous_hypotheses",
      "previous_pred_out"
    ],
    "get_active_speakers_info": [
      "self",
      "active_speakers",
      "chunk_audio",
      "chunk_lengths"
    ],
    "update_seglsts": [
      "self",
      "offset"
    ]
  },
  "get_cleaned_base_path": [
    "output_dir",
    "overwrite_output"
  ],
  "binary_search_alignments": [
    "inds",
    "max_audio_read_sec",
    "min_alignment_count",
    "alignments"
  ],
  "get_subset_of_audio_manifest": [
    "audio_manifest",
    "offset_index",
    "max_audio_read_sec",
    "min_alignment_count"
  ],
  "read_audio_from_buffer": [
    "audio_manifest",
    "buffer_dict",
    "offset_index",
    "device",
    "max_audio_read_sec",
    "min_alignment_count",
    "read_subset"
  ],
  "perturb_audio": [
    "audio",
    "sr",
    "augmentor",
    "device"
  ],
  "normalize_audio": [
    "array"
  ],
  "get_power_of_audio_file": [
    "audio_file",
    "end_audio_file",
    "running_len_samples",
    "device"
  ],
  "get_scaled_audio_signal": [
    "audio_file",
    "end_audio_file",
    "running_len_samples",
    "desired_avg_power_noise",
    "device"
  ],
  "get_desired_avg_power_noise": [
    "power_array",
    "snr_min",
    "snr_max",
    "background_noise_snr"
  ],
  "get_background_noise": [
    "len_array",
    "power_array",
    "noise_samples",
    "audio_read_buffer_dict",
    "snr_min",
    "snr_max",
    "background_noise_snr",
    "seed",
    "device",
    "sr"
  ],
  "get_random_offset_index": [
    "audio_manifest",
    "audio_read_buffer_dict",
    "offset_min",
    "max_audio_read_sec",
    "min_alignment_count"
  ],
  "get_speaker_ids": [
    "sess_idx",
    "speaker_samples",
    "permutated_speaker_inds"
  ],
  "build_speaker_samples_map": [
    "manifest",
    "tqdm_bar"
  ],
  "read_noise_manifest": [
    "add_bg",
    "background_manifest"
  ],
  "read_rir_manifest": [
    "rir_manifest"
  ],
  "get_speaker_samples": [
    "speaker_ids",
    "speaker_samples"
  ],
  "add_silence_to_alignments": [
    "audio_manifest"
  ],
  "load_speaker_sample": [
    "speaker_wav_align_map",
    "speaker_ids",
    "speaker_turn",
    "min_alignment_count"
  ],
  "get_split_points_in_alignments": [
    "words",
    "alignments",
    "split_buffer",
    "sr",
    "sentence_audio_len",
    "new_start"
  ],
  "per_speaker_normalize": [
    "sentence_audio",
    "splits",
    "speaker_turn",
    "volume",
    "device"
  ],
  "DataAnnotator": {
    "__init__": [
      "self",
      "cfg"
    ],
    "_init_file_write": [
      "self"
    ],
    "_init_filelist_lists": [
      "self"
    ],
    "init_annotation_lists": [
      "self"
    ],
    "create_new_rttm_entry": [
      "self",
      "words",
      "alignments",
      "start",
      "end",
      "speaker_id",
      "add_split_buffer"
    ],
    "create_new_json_entry": [
      "self",
      "text",
      "wav_filename",
      "start",
      "length",
      "speaker_id",
      "rttm_filepath",
      "ctm_filepath"
    ],
    "create_ctm_entry_from_segment_list": [
      "self",
      "source_segment_list",
      "session_name",
      "speaker_id",
      "start"
    ],
    "create_new_ctm_entry": [
      "self",
      "words",
      "alignments",
      "session_name",
      "speaker_id",
      "start"
    ],
    "add_to_filename_lists": [
      "self",
      "basepath",
      "filename"
    ],
    "write_filelist_files": [
      "self",
      "basepath"
    ],
    "write_annotation_files": [
      "self",
      "basepath",
      "filename",
      "meta_data"
    ],
    "write_annotation_rttm_and_ctm": [
      "self",
      "basepath",
      "filename"
    ]
  },
  "SpeechSampler": {
    "__init__": [
      "self",
      "cfg"
    ],
    "_mean_var_to_a_and_b": [
      "self",
      "mean",
      "var"
    ],
    "_init_silence_params": [
      "self"
    ],
    "_init_overlap_params": [
      "self"
    ],
    "silence_vs_overlap_selector": [
      "self",
      "running_len_samples",
      "non_silence_len_samples"
    ],
    "get_session_silence_mean": [
      "self"
    ],
    "get_session_overlap_mean": [
      "self"
    ],
    "sample_from_silence_model": [
      "self",
      "running_len_samples"
    ],
    "sample_from_overlap_model": [
      "self",
      "non_silence_len_samples"
    ],
    "sample_noise_manifest": [
      "self",
      "noise_manifest"
    ]
  },
  "ConfidenceMethodConstants": {
    "NAMES": [],
    "ENTROPY_TYPES": [],
    "ENTROPY_NORMS": [],
    "print": [
      "cls"
    ]
  },
  "ConfidenceConstants": {
    "AGGREGATIONS": [],
    "print": [
      "cls"
    ]
  },
  "ConfidenceMethodConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "ConfidenceConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "get_confidence_measure_bank": [],
  "get_confidence_aggregation_bank": [],
  "ConfidenceMethodMixin": {
    "_init_confidence_method": [
      "self",
      "confidence_method_cfg"
    ],
    "_get_confidence": [
      "self",
      "x"
    ],
    "_get_confidence_tensor": [
      "self",
      "x"
    ]
  },
  "ConfidenceMixin": {
    "_init_confidence": [
      "self",
      "confidence_cfg"
    ],
    "compute_confidence": [
      "self",
      "hypotheses_list"
    ],
    "_aggregate_token_confidence": [
      "self",
      "hypothesis"
    ],
    "_aggregate_token_confidence_chars": [
      "self",
      "words",
      "token_confidence"
    ],
    "_aggregate_token_confidence_subwords_sentencepiece": [
      "self",
      "words",
      "token_confidence",
      "token_ids"
    ]
  },
  "BLANK_TOKEN": [],
  "SPACE_TOKEN": [],
  "Word": {},
  "Segment": {},
  "Utterance": {},
  "is_sub_or_superscript_pair": [
    "ref_text",
    "text"
  ],
  "restore_token_case": [
    "word",
    "word_tokens"
  ],
  "get_char_tokens": [
    "text",
    "model"
  ],
  "_get_utt_id": [
    "audio_filepath",
    "audio_filepath_parts_in_utt_id"
  ],
  "get_utt_obj": [
    "text",
    "T",
    "model",
    "segment_separators",
    "word_separator",
    "audio_filepath",
    "utt_id"
  ],
  "add_t_start_end_to_utt_obj": [
    "utt_obj",
    "alignment_utt",
    "output_timestep_duration"
  ],
  "viterbi_decoding": [
    "log_probs_batch",
    "y_batch",
    "T_batch",
    "U_batch",
    "viterbi_device",
    "padding_value"
  ],
  "get_batch_variables": [
    "audio",
    "model",
    "segment_separators",
    "word_separator",
    "align_using_pred_text",
    "audio_filepath_parts_in_utt_id",
    "gt_text_batch",
    "output_timestep_duration",
    "simulate_cache_aware_streaming",
    "use_buffered_chunked_streaming",
    "buffered_chunk_params",
    "padding_value",
    "has_hypotheses"
  ],
  "compute_stochastic_depth_drop_probs": [
    "num_layers",
    "stochastic_depth_drop_prob",
    "stochastic_depth_mode",
    "stochastic_depth_start_layer"
  ],
  "get_uniqname_from_filepath": [
    "filepath"
  ],
  "get_uniq_id_from_manifest_line": [
    "line"
  ],
  "get_uniq_id_with_dur": [
    "meta",
    "decimals"
  ],
  "audio_rttm_map": [
    "manifest",
    "attach_dur"
  ],
  "parse_scale_configs": [
    "window_lengths_in_sec",
    "shift_lengths_in_sec",
    "multiscale_weights"
  ],
  "get_embs_and_timestamps": [
    "multiscale_embeddings_and_timestamps",
    "multiscale_args_dict"
  ],
  "get_timestamps": [
    "multiscale_timestamps",
    "multiscale_args_dict"
  ],
  "get_contiguous_stamps": [
    "stamps"
  ],
  "merge_stamps": [
    "lines"
  ],
  "labels_to_pyannote_object": [
    "labels",
    "uniq_name"
  ],
  "labels_to_rttmfile": [
    "labels",
    "uniq_id",
    "out_rttm_dir"
  ],
  "string_to_float": [
    "x",
    "round_digits"
  ],
  "convert_rttm_line": [
    "rttm_line",
    "round_digits"
  ],
  "rttm_to_labels": [
    "rttm_filename"
  ],
  "write_cluster_labels": [
    "base_scale_idx",
    "lines_cluster_labels",
    "out_rttm_dir"
  ],
  "generate_cluster_labels": [
    "segment_ranges",
    "cluster_labels"
  ],
  "perform_clustering": [
    "embs_and_timestamps",
    "AUDIO_RTTM_MAP",
    "out_rttm_dir",
    "clustering_params",
    "device",
    "verbose"
  ],
  "get_vad_out_from_rttm_line": [
    "rttm_line"
  ],
  "get_offset_and_duration": [
    "AUDIO_RTTM_MAP",
    "uniq_id",
    "decimals"
  ],
  "write_overlap_segments": [
    "outfile",
    "AUDIO_RTTM_MAP",
    "uniq_id",
    "overlap_range_list",
    "decimals"
  ],
  "read_rttm_lines": [
    "rttm_file_path"
  ],
  "validate_vad_manifest": [
    "AUDIO_RTTM_MAP",
    "vad_manifest"
  ],
  "is_overlap": [
    "rangeA",
    "rangeB"
  ],
  "get_overlap_range": [
    "rangeA",
    "rangeB"
  ],
  "merge_int_intervals": [
    "intervals_in"
  ],
  "fl2int": [
    "x",
    "decimals"
  ],
  "int2fl": [
    "x",
    "decimals"
  ],
  "merge_float_intervals": [
    "ranges",
    "decimals",
    "margin"
  ],
  "get_sub_range_list": [
    "target_range",
    "source_range_list"
  ],
  "write_rttm2manifest": [
    "AUDIO_RTTM_MAP",
    "manifest_file",
    "include_uniq_id",
    "decimals"
  ],
  "segments_manifest_to_subsegments_manifest": [
    "segments_manifest_file",
    "subsegments_manifest_file",
    "window",
    "shift",
    "min_subsegment_duration",
    "include_uniq_id"
  ],
  "get_subsegments": [
    "offset",
    "window",
    "shift",
    "duration",
    "min_subsegment_duration",
    "decimals",
    "use_asr_style_frame_count",
    "sample_rate",
    "feat_per_sec"
  ],
  "get_subsegments_scriptable": [
    "offset",
    "window",
    "shift",
    "duration"
  ],
  "get_target_sig": [
    "sig",
    "start_sec",
    "end_sec",
    "slice_length",
    "sample_rate"
  ],
  "check_ranges": [
    "range_tensor"
  ],
  "tensor_to_list": [
    "range_tensor"
  ],
  "generate_diarization_output_lines": [
    "speaker_timestamps",
    "model_spk_num"
  ],
  "get_speech_labels_for_update": [
    "frame_start",
    "buffer_end",
    "vad_timestamps",
    "cumulative_speech_labels",
    "cursor_for_old_segments"
  ],
  "get_new_cursor_for_update": [
    "frame_start",
    "segment_range_ts"
  ],
  "get_online_segments_from_slices": [
    "sig",
    "buffer_start",
    "buffer_end",
    "subsegments",
    "ind_offset",
    "window",
    "sample_rate"
  ],
  "get_online_subsegments_from_buffer": [
    "buffer_start",
    "buffer_end",
    "sample_rate",
    "speech_labels_for_update",
    "audio_buffer",
    "segment_indexes",
    "window",
    "shift"
  ],
  "get_scale_mapping_argmat": [
    "uniq_embs_and_timestamps"
  ],
  "get_overlap_stamps": [
    "cont_stamps",
    "ovl_spk_idx"
  ],
  "get_adaptive_threshold": [
    "estimated_num_of_spks",
    "min_threshold",
    "overlap_infer_spk_limit"
  ],
  "generate_speaker_timestamps": [
    "clus_labels",
    "msdd_preds"
  ],
  "get_uniq_id_list_from_manifest": [
    "manifest_file"
  ],
  "get_id_tup_dict": [
    "uniq_id_list",
    "test_data_collection",
    "preds_list"
  ],
  "prepare_split_data": [
    "manifest_filepath",
    "_out_dir",
    "multiscale_args_dict",
    "global_rank"
  ],
  "extract_timestamps": [
    "manifest_file"
  ],
  "make_rttm_with_overlap": [
    "manifest_file_path",
    "clus_label_dict",
    "msdd_preds"
  ],
  "timestamps_to_pyannote_object": [
    "speaker_timestamps",
    "uniq_id",
    "audio_rttm_values",
    "all_hypothesis",
    "all_reference",
    "all_uems",
    "out_rttm_dir"
  ],
  "get_uem_object": [
    "uem_lines",
    "uniq_id"
  ],
  "embedding_normalize": [
    "embs",
    "use_std",
    "eps"
  ],
  "OnlineSegmentor": {
    "__init__": [
      "self",
      "sample_rate"
    ],
    "run_online_segmentation": [
      "self",
      "audio_buffer",
      "vad_timestamps",
      "segment_raw_audio",
      "segment_range_ts",
      "segment_indexes",
      "window",
      "shift"
    ]
  },
  "find_first_nonzero": [
    "mat",
    "max_cap_val",
    "thres"
  ],
  "find_best_permutation": [
    "match_score",
    "speaker_permutations"
  ],
  "reconstruct_labels": [
    "labels",
    "batch_perm_inds"
  ],
  "get_ats_targets": [
    "labels",
    "preds",
    "speaker_permutations",
    "thres",
    "tolerance"
  ],
  "get_pil_targets": [
    "labels",
    "preds",
    "speaker_permutations"
  ],
  "find_segments_from_rttm": [
    "recording_id",
    "rttms",
    "start_after",
    "end_before",
    "adjust_offset",
    "tolerance"
  ],
  "get_mask_from_segments": [
    "segments",
    "a_cut",
    "speaker_to_idx_map",
    "num_speakers",
    "feat_per_sec"
  ],
  "get_soft_mask": [
    "feat_level_target",
    "num_frames",
    "stride"
  ],
  "get_hidden_length_from_sample_length": [
    "num_samples",
    "num_sample_per_mel_frame",
    "num_mel_frame_per_asr_frame"
  ],
  "speaker_to_target": [
    "a_cut",
    "num_sample_per_mel_frame",
    "num_mel_frame_per_asr_frame",
    "boundary_segments",
    "soft_label",
    "soft_thres",
    "return_text"
  ],
  "MultiSpeakerMixtureGenerator": {
    "__init__": [
      "self",
      "manifest_filepath",
      "sample_rate",
      "simulator_type",
      "min_duration",
      "max_duration",
      "min_delay",
      "random_seed",
      "num_speakers",
      "global_rank",
      "world_size"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "LibriSpeechMixSimulator": [
      "self"
    ],
    "MultiSpeakerMixtureLoader": [
      "self"
    ],
    "_get_offset_and_duration": [
      "self",
      "supervisions"
    ],
    "_get_non_overlap_supervisions_indices": [
      "self",
      "supervisions"
    ],
    "_json_to_cut": [
      "self",
      "json_dict"
    ],
    "_create_cut": [
      "self",
      "audio_path",
      "offset",
      "duration",
      "sampling_rate",
      "channel"
    ],
    "_create_recording": [
      "self",
      "audio_path",
      "duration",
      "sampling_rate"
    ]
  },
  "unravel_index": [
    "index",
    "shape"
  ],
  "LinearSumAssignmentSolver": {
    "__init__": [
      "self",
      "cost_matrix"
    ],
    "_reset_uncovered_mat": [
      "self"
    ],
    "_step1": [
      "self"
    ],
    "_step2": [
      "self"
    ],
    "_step3": [
      "self"
    ],
    "_step4": [
      "self",
      "bypass"
    ],
    "_step5": [
      "self"
    ],
    "_step6": [
      "self"
    ]
  },
  "linear_sum_assignment": [
    "cost_matrix",
    "max_size"
  ],
  "auc_roc": [
    "y_true",
    "y_score"
  ],
  "auc_pr": [
    "y_true",
    "y_score"
  ],
  "auc_nt": [
    "y_true",
    "y_score"
  ],
  "nce": [
    "y_true",
    "y_score"
  ],
  "ece": [
    "y_true",
    "y_score",
    "n_bins",
    "return_curve"
  ],
  "auc_yc": [
    "y_true",
    "y_score",
    "n_bins",
    "return_std_maximum",
    "return_curve"
  ],
  "save_confidence_hist": [
    "y_score",
    "plot_dir",
    "name"
  ],
  "save_roc_curve": [
    "y_true",
    "y_score",
    "plot_dir",
    "name"
  ],
  "save_pr_curve": [
    "y_true",
    "y_score",
    "plot_dir",
    "name"
  ],
  "save_nt_curve": [
    "y_true",
    "y_score",
    "plot_dir",
    "name"
  ],
  "save_custom_confidence_curve": [
    "thresholds",
    "values",
    "plot_dir",
    "name",
    "xlabel",
    "ylabel"
  ],
  "change_conv_asr_se_context_window": [
    "model",
    "context_window",
    "update_config"
  ],
  "_update_se_context_window": [
    "model",
    "context_window",
    "cfg"
  ],
  "SemiSortBatchSampler": {
    "__init__": [
      "self",
      "global_rank",
      "world_size",
      "durations",
      "batch_size",
      "batch_shuffle",
      "drop_last",
      "randomization_factor",
      "seed"
    ],
    "_calculate_local_num_batches": [
      "self"
    ],
    "_make_batches": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "get_semi_sorted_batch_sampler": [
    "model",
    "dataset",
    "config"
  ],
  "TranscriptionReturnType": [],
  "GenericTranscriptionType": [],
  "InternalTranscribeConfig": {},
  "TranscribeConfig": {},
  "get_value_from_transcription_config": [
    "trcfg",
    "key",
    "default"
  ],
  "TranscriptionTensorDataset": {
    "__init__": [
      "self",
      "config"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "get_item": [
      "self",
      "index"
    ]
  },
  "TranscriptionMixin": {
    "transcribe": [
      "self",
      "audio",
      "batch_size",
      "return_hypotheses",
      "num_workers",
      "channel_selector",
      "augmentor",
      "verbose",
      "timestamps",
      "override_config"
    ],
    "transcribe_generator": [
      "self",
      "audio",
      "override_config"
    ],
    "_transcribe_on_begin": [
      "self",
      "audio",
      "trcfg"
    ],
    "_transcribe_input_processing": [
      "self",
      "audio",
      "trcfg"
    ],
    "_transcribe_input_tensor_processing": [
      "self",
      "audio_tensors",
      "temp_dir",
      "trcfg"
    ],
    "_transcribe_input_manifest_processing": [
      "self",
      "audio_files",
      "temp_dir",
      "trcfg"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "_transcribe_forward": [
      "self",
      "batch",
      "trcfg"
    ],
    "_transcribe_output_processing": [
      "self",
      "outputs",
      "trcfg"
    ],
    "_transcribe_on_end": [
      "self",
      "trcfg"
    ],
    "_setup_transcribe_tensor_dataloader": [
      "self",
      "config",
      "trcfg"
    ]
  },
  "ASRTranscriptionMixin": {
    "_transcribe_input_manifest_processing": [
      "self",
      "audio_files",
      "temp_dir",
      "trcfg"
    ],
    "_transcribe_on_begin": [
      "self",
      "audio",
      "trcfg"
    ],
    "_transcribe_on_end": [
      "self",
      "trcfg"
    ],
    "get_transcribe_config": [
      "cls"
    ]
  },
  "get_spk_kernel_class": [
    "spk_kernel_type",
    "input_size",
    "d_model",
    "dropout"
  ],
  "SpeakerKernelMixin": {
    "_init_speaker_kernel_config": [
      "self",
      "cfg"
    ],
    "_init_spk_kernel": [
      "self"
    ],
    "_attach_spk_kernel_hooks": [
      "self"
    ],
    "_get_spk_kernel_hook_pre_layer": [
      "self",
      "layer_idx"
    ],
    "_get_spk_kernel_hook_post_layer": [
      "self",
      "layer_idx"
    ],
    "_cleanup_speaker_kernel_hooks": [
      "self"
    ],
    "set_speaker_targets": [
      "self",
      "spk_targets",
      "bg_spk_targets"
    ],
    "clear_speaker_targets": [
      "self"
    ],
    "solve_length_mismatch": [
      "self",
      "x",
      "mask",
      "default_value"
    ],
    "mask_with_speaker_targets": [
      "self",
      "x",
      "spk_targets",
      "default_value"
    ],
    "concat_with_speaker_targets": [
      "self",
      "x",
      "spk_targets"
    ]
  },
  "ASRAdapterModelMixin": {
    "setup_adapters": [
      "self"
    ],
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "is_adapter_available": [
      "self"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "check_valid_model_with_adapter_support_": [
      "self"
    ],
    "resolve_adapter_module_name_": [
      "self",
      "name"
    ],
    "_get_global_cfg": [
      "self"
    ],
    "adapter_module_names": [
      "self"
    ],
    "default_adapter_module_name": [
      "self"
    ]
  },
  "GenericDiarizationType": [],
  "InternalDiarizeConfig": {},
  "DiarizeConfig": {},
  "get_value_from_diarization_config": [
    "diarcfg",
    "key",
    "default"
  ],
  "SpkDiarizationMixin": {
    "__init__": [
      "self"
    ],
    "diarize": [
      "self",
      "audio",
      "batch_size",
      "include_tensor_outputs",
      "postprocessing_yaml",
      "num_workers",
      "verbose",
      "override_config"
    ],
    "diarize_generator": [
      "self",
      "audio",
      "override_config"
    ],
    "_input_audio_to_rttm_processing": [
      "self",
      "audio_files"
    ],
    "_diarize_on_begin": [
      "self",
      "audio",
      "diarcfg"
    ],
    "_diarize_input_processing": [
      "self",
      "audio",
      "diarcfg"
    ],
    "_diarize_input_manifest_processing": [
      "self",
      "audio_files",
      "temp_dir",
      "diarcfg"
    ],
    "_setup_diarize_dataloader": [
      "self",
      "config"
    ],
    "_diarize_forward": [
      "self",
      "batch"
    ],
    "_diarize_output_processing": [
      "self",
      "outputs",
      "uniq_ids",
      "diarcfg"
    ],
    "_diarize_on_end": [
      "self",
      "diarcfg"
    ]
  },
  "StreamingEncoder": {
    "setup_streaming_params": [
      "self",
      "max_look_ahead"
    ],
    "get_initial_cache_state": [
      "self",
      "batch_size",
      "dtype",
      "device",
      "max_dim"
    ],
    "to_numpy": [
      "tensor"
    ],
    "cache_aware_stream_step": [
      "self",
      "processed_signal",
      "processed_signal_length",
      "cache_last_channel",
      "cache_last_time",
      "cache_last_channel_len",
      "keep_all_outputs",
      "drop_extra_pre_encoded",
      "bypass_pre_encode"
    ]
  },
  "InterCTCMixin": {
    "_process_config_values": [
      "self",
      "loss_weights",
      "apply_at_layers"
    ],
    "setup_interctc": [
      "self",
      "decoder_name",
      "loss_name",
      "wer_name"
    ],
    "get_interctc_param": [
      "self",
      "param_name"
    ],
    "set_interctc_param": [
      "self",
      "param_name",
      "param_value"
    ],
    "_verify_setup_was_called": [
      "self"
    ],
    "is_interctc_enabled": [
      "self"
    ],
    "set_interctc_enabled": [
      "self",
      "enabled"
    ],
    "finalize_interctc_metrics": [
      "self",
      "metrics",
      "outputs",
      "prefix"
    ],
    "get_captured_interctc_tensors": [
      "self"
    ],
    "add_interctc_losses": [
      "self",
      "loss_value",
      "transcript",
      "transcript_len",
      "compute_wer",
      "compute_loss",
      "log_wer_num_denom",
      "log_prefix"
    ]
  },
  "ASRBPEMixin": {
    "AGGREGATE_TOKENIZERS_DICT_PREFIX": [],
    "_setup_tokenizer": [
      "self",
      "tokenizer_cfg"
    ],
    "_setup_monolingual_tokenizer": [
      "self",
      "tokenizer_cfg"
    ],
    "_setup_aggregate_tokenizer": [
      "self",
      "tokenizer_cfg"
    ],
    "_make_tokenizer": [
      "self",
      "tokenizer_cfg",
      "lang"
    ],
    "_cleanup_monolingual_and_aggregate_config_and_artifacts_if_needed": [
      "self"
    ],
    "_cleanup_aggregate_config_and_artifacts_if_needed": [
      "self"
    ],
    "save_tokenizers": [
      "self",
      "directory"
    ],
    "_extract_tokenizer_from_config": [
      "self",
      "tokenizer_cfg",
      "dir"
    ],
    "_derive_tokenizer_properties": [
      "self"
    ]
  },
  "ASRModuleMixin": {
    "change_conv_asr_se_context_window": [
      "self",
      "context_window",
      "update_config"
    ],
    "change_attention_model": [
      "self",
      "self_attention_model",
      "att_context_size",
      "update_config"
    ],
    "change_subsampling_conv_chunking_factor": [
      "self",
      "subsampling_conv_chunking_factor",
      "update_config"
    ],
    "conformer_stream_step": [
      "self",
      "processed_signal",
      "processed_signal_length",
      "cache_last_channel",
      "cache_last_time",
      "cache_last_channel_len",
      "keep_all_outputs",
      "previous_hypotheses",
      "previous_pred_out",
      "drop_extra_pre_encoded",
      "return_transcription",
      "return_log_probs",
      "bypass_pre_encode"
    ],
    "transcribe_simulate_cache_aware_streaming": [
      "self",
      "paths2audio_files",
      "batch_size",
      "logprobs",
      "return_hypotheses",
      "online_normalization"
    ],
    "_setup_streaming_transcribe_dataloader": [
      "self",
      "paths2audio_files",
      "batch_size",
      "online_normalization"
    ]
  },
  "VerificationMixin": {
    "path2audio_files_to_manifest": [
      "paths2audio_files",
      "manifest_filepath"
    ]
  },
  "DiarizationMixin": {
    "diarize": [
      "self",
      "paths2audio_files",
      "batch_size"
    ]
  },
  "check_type": [
    "var",
    "t",
    "name"
  ],
  "check_contiguous": [
    "var",
    "name"
  ],
  "check_dim": [
    "var",
    "dim",
    "name"
  ],
  "certify_inputs": [
    "log_probs",
    "labels",
    "lengths",
    "label_lengths"
  ],
  "_assert_no_grad": [
    "tensor"
  ],
  "LogSoftmaxGradModification": {
    "forward": [
      "ctx",
      "acts",
      "clamp"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "forward_pass": [
    "log_probs",
    "labels",
    "blank"
  ],
  "backward_pass": [
    "log_probs",
    "labels",
    "blank"
  ],
  "compute_gradient": [
    "log_probs",
    "alphas",
    "betas",
    "labels",
    "blank",
    "fastemit_lambda"
  ],
  "fastemit_regularization": [
    "log_probs",
    "labels",
    "alphas",
    "betas",
    "blank",
    "fastemit_lambda"
  ],
  "transduce": [
    "log_probs",
    "labels",
    "blank",
    "fastemit_lambda"
  ],
  "transduce_batch": [
    "log_probs",
    "labels",
    "flen",
    "glen",
    "blank",
    "fastemit_lambda"
  ],
  "_RNNT": {
    "forward": [
      "ctx",
      "acts",
      "labels",
      "act_lens",
      "label_lens",
      "blank",
      "fastemit_lambda"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "_RNNTNumba": {
    "forward": [
      "ctx",
      "acts",
      "labels",
      "act_lens",
      "label_lens",
      "blank",
      "reduction",
      "fastemit_lambda",
      "clamp"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "_TDTNumba": {
    "forward": [
      "ctx",
      "label_acts",
      "duration_acts",
      "labels",
      "act_lens",
      "label_lens",
      "blank",
      "durations",
      "reduction",
      "fastemit_lambda",
      "clamp",
      "sigma",
      "omega"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "_MultiblankRNNTNumba": {
    "forward": [
      "ctx",
      "acts",
      "labels",
      "act_lens",
      "label_lens",
      "blank",
      "big_blank_durations",
      "reduction",
      "fastemit_lambda",
      "clamp",
      "sigma"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "rnnt_loss": [
    "acts",
    "labels",
    "act_lens",
    "label_lens",
    "blank",
    "reduction",
    "fastemit_lambda",
    "clamp"
  ],
  "multiblank_rnnt_loss": [
    "acts",
    "labels",
    "act_lens",
    "label_lens",
    "blank",
    "big_blank_durations",
    "reduction",
    "fastemit_lambda",
    "clamp"
  ],
  "tdt_loss": [
    "acts",
    "labels",
    "act_lens",
    "label_lens",
    "blank",
    "durations",
    "reduction",
    "fastemit_lambda",
    "clamp"
  ],
  "RNNTLossNumba": {
    "__init__": [
      "self",
      "blank",
      "reduction",
      "fastemit_lambda",
      "clamp"
    ],
    "forward": [
      "self",
      "acts",
      "labels",
      "act_lens",
      "label_lens"
    ]
  },
  "MultiblankRNNTLossNumba": {
    "__init__": [
      "self",
      "blank",
      "big_blank_durations",
      "reduction",
      "fastemit_lambda",
      "clamp",
      "sigma"
    ],
    "forward": [
      "self",
      "acts",
      "labels",
      "act_lens",
      "label_lens"
    ]
  },
  "TDTLossNumba": {
    "__init__": [
      "self",
      "blank",
      "durations",
      "reduction",
      "fastemit_lambda",
      "clamp",
      "sigma",
      "omega"
    ],
    "forward": [
      "self",
      "acts",
      "labels",
      "act_lens",
      "label_lens"
    ]
  },
  "rnnt_loss_cpu": [
    "acts",
    "labels",
    "input_lengths",
    "label_lengths",
    "costs",
    "grads",
    "blank_label",
    "fastemit_lambda",
    "clamp",
    "num_threads"
  ],
  "rnnt_loss_gpu": [
    "acts",
    "labels",
    "input_lengths",
    "label_lengths",
    "costs",
    "grads",
    "blank_label",
    "fastemit_lambda",
    "clamp",
    "num_threads"
  ],
  "tdt_loss_gpu": [
    "label_acts",
    "duration_acts",
    "labels",
    "input_lengths",
    "label_lengths",
    "costs",
    "label_grads",
    "duration_grads",
    "blank_label",
    "durations",
    "fastemit_lambda",
    "clamp",
    "num_threads",
    "sigma",
    "omega"
  ],
  "multiblank_rnnt_loss_gpu": [
    "acts",
    "labels",
    "input_lengths",
    "label_lengths",
    "costs",
    "grads",
    "blank_label",
    "big_blank_durations",
    "fastemit_lambda",
    "clamp",
    "num_threads",
    "sigma"
  ],
  "_THREADS_PER_BLOCK": [],
  "_WARP_SIZE": [],
  "_DTYPE": [],
  "FP32_INF": [],
  "FP32_NEG_INF": [],
  "threads_per_block": [],
  "warp_size": [],
  "RNNTStatus": {
    "RNNT_STATUS_SUCCESS": [],
    "RNNT_STATUS_INVALID_VALUE": []
  },
  "threshold": [],
  "log_sum_exp": [
    "a",
    "b"
  ],
  "div_up": [
    "x",
    "y"
  ],
  "maximum": [
    "x",
    "y"
  ],
  "add": [
    "x",
    "y"
  ],
  "identity": [
    "x"
  ],
  "negate": [
    "x"
  ],
  "exponential": [
    "x"
  ],
  "log_plus": [
    "p1",
    "p2"
  ],
  "copy_data_1d": [
    "source",
    "dest",
    "idx"
  ],
  "compute_costs_data": [
    "source",
    "dest",
    "fastemit_lambda"
  ],
  "get_workspace_size": [
    "maxT",
    "maxU",
    "minibatch",
    "gpu"
  ],
  "flatten_tensor": [
    "x"
  ],
  "CpuRNNT_index": {
    "__init__": [
      "self",
      "U",
      "maxU",
      "minibatch",
      "alphabet_size",
      "batch_first"
    ],
    "__call__": [
      "self",
      "t",
      "u",
      "v"
    ]
  },
  "CpuRNNT_metadata": {
    "__init__": [
      "self",
      "T",
      "U",
      "workspace",
      "bytes_used",
      "blank",
      "labels",
      "log_probs",
      "idx"
    ],
    "setup_probs": [
      "self",
      "T",
      "U",
      "labels",
      "blank",
      "log_probs",
      "idx"
    ]
  },
  "CPURNNT": {
    "__init__": [
      "self",
      "minibatch",
      "maxT",
      "maxU",
      "alphabet_size",
      "workspace",
      "blank",
      "fastemit_lambda",
      "clamp",
      "num_threads",
      "batch_first"
    ],
    "cost_and_grad_kernel": [
      "self",
      "log_probs",
      "grad",
      "labels",
      "mb",
      "T",
      "U",
      "bytes_used"
    ],
    "compute_alphas": [
      "self",
      "log_probs",
      "T",
      "U",
      "alphas"
    ],
    "compute_betas_and_grads": [
      "self",
      "grad",
      "log_probs",
      "T",
      "U",
      "alphas",
      "betas",
      "labels",
      "logll"
    ],
    "cost_and_grad": [
      "self",
      "log_probs",
      "grads",
      "costs",
      "flat_labels",
      "label_lengths",
      "input_lengths"
    ],
    "score_forward": [
      "self",
      "log_probs",
      "costs",
      "flat_labels",
      "label_lengths",
      "input_lengths"
    ]
  },
  "CTA_REDUCE_SIZE": [],
  "I_Op": {
    "EXPONENTIAL": [],
    "IDENTITY": []
  },
  "R_Op": {
    "ADD": [],
    "MAXIMUM": []
  },
  "CTAReduce": [
    "tid",
    "x",
    "storage",
    "count",
    "R_opid"
  ],
  "_reduce_rows": [
    "I_opid",
    "R_opid",
    "acts",
    "output",
    "num_rows"
  ],
  "_reduce_minus": [
    "I_opid",
    "R_opid",
    "acts",
    "output",
    "num_rows"
  ],
  "ReduceHelper": [
    "I_opid",
    "R_opid",
    "acts",
    "output",
    "num_rows",
    "num_cols",
    "minus",
    "stream"
  ],
  "reduce_exp": [
    "acts",
    "denom",
    "rows",
    "cols",
    "minus",
    "stream"
  ],
  "reduce_max": [
    "acts",
    "denom",
    "rows",
    "cols",
    "minus",
    "stream"
  ],
  "GPURNNT": {
    "__init__": [
      "self",
      "minibatch",
      "maxT",
      "maxU",
      "alphabet_size",
      "workspace",
      "blank",
      "fastemit_lambda",
      "clamp",
      "num_threads",
      "stream"
    ],
    "log_softmax": [
      "self",
      "acts",
      "denom"
    ],
    "compute_cost_and_score": [
      "self",
      "acts",
      "grads",
      "costs",
      "labels",
      "label_lengths",
      "input_lengths"
    ],
    "cost_and_grad": [
      "self",
      "acts",
      "grads",
      "costs",
      "pad_labels",
      "label_lengths",
      "input_lengths"
    ],
    "score_forward": [
      "self",
      "acts",
      "costs",
      "pad_labels",
      "label_lengths",
      "input_lengths"
    ],
    "_prepare_workspace": [
      "self"
    ]
  },
  "MultiblankGPURNNT": {
    "__init__": [
      "self",
      "sigma",
      "num_big_blanks",
      "minibatch",
      "maxT",
      "maxU",
      "alphabet_size",
      "workspace",
      "big_blank_workspace",
      "blank",
      "fastemit_lambda",
      "clamp",
      "num_threads",
      "stream"
    ],
    "compute_cost_and_score": [
      "self",
      "acts",
      "grads",
      "costs",
      "labels",
      "label_lengths",
      "input_lengths"
    ],
    "cost_and_grad": [
      "self",
      "acts",
      "grads",
      "costs",
      "pad_labels",
      "label_lengths",
      "input_lengths"
    ],
    "score_forward": [
      "self",
      "acts",
      "costs",
      "pad_labels",
      "label_lengths",
      "input_lengths"
    ],
    "_prepare_workspace": [
      "self"
    ]
  },
  "GPUTDT": {
    "__init__": [
      "self",
      "sigma",
      "omega",
      "num_durations",
      "minibatch",
      "maxT",
      "maxU",
      "alphabet_size",
      "workspace",
      "tdt_workspace",
      "blank",
      "fastemit_lambda",
      "clamp",
      "num_threads",
      "stream"
    ],
    "compute_cost_and_score": [
      "self",
      "label_acts",
      "duration_acts",
      "label_grads",
      "duration_grads",
      "costs",
      "labels",
      "label_lengths",
      "input_lengths"
    ],
    "cost_and_grad": [
      "self",
      "label_acts",
      "duration_acts",
      "label_grads",
      "duration_grads",
      "costs",
      "pad_labels",
      "label_lengths",
      "input_lengths"
    ],
    "score_forward": [
      "self",
      "label_acts",
      "duration_acts",
      "costs",
      "pad_labels",
      "label_lengths",
      "input_lengths"
    ],
    "_prepare_workspace": [
      "self"
    ]
  },
  "GPU_RNNT_THREAD_SIZE": [],
  "INF": [],
  "logp": [
    "denom",
    "acts",
    "maxT",
    "maxU",
    "alphabet_size",
    "mb",
    "t",
    "u",
    "v"
  ],
  "logp_duration": [
    "acts",
    "maxT",
    "maxU",
    "num_durations",
    "mb",
    "t",
    "u",
    "v"
  ],
  "compute_alphas_kernel": [
    "acts",
    "denom",
    "alphas",
    "llForward",
    "xlen",
    "ylen",
    "mlabels",
    "minibatch",
    "maxT",
    "maxU",
    "alphabet_size",
    "blank_"
  ],
  "compute_betas_kernel": [
    "acts",
    "denom",
    "betas",
    "llBackward",
    "xlen",
    "ylen",
    "mlabels",
    "minibatch",
    "maxT",
    "maxU",
    "alphabet_size",
    "blank_"
  ],
  "compute_grad_kernel": [
    "grads",
    "acts",
    "denom",
    "alphas",
    "betas",
    "logll",
    "xlen",
    "ylen",
    "mlabels",
    "minibatch",
    "maxT",
    "maxU",
    "alphabet_size",
    "blank_",
    "fastemit_lambda",
    "clamp"
  ],
  "compute_multiblank_alphas_kernel": [
    "acts",
    "denom",
    "sigma",
    "alphas",
    "llForward",
    "xlen",
    "ylen",
    "mlabels",
    "minibatch",
    "maxT",
    "maxU",
    "alphabet_size",
    "blank_",
    "big_blank_duration",
    "num_big_blanks"
  ],
  "compute_multiblank_betas_kernel": [
    "acts",
    "denom",
    "sigma",
    "betas",
    "llBackward",
    "xlen",
    "ylen",
    "mlabels",
    "minibatch",
    "maxT",
    "maxU",
    "alphabet_size",
    "blank_",
    "big_blank_duration",
    "num_big_blanks"
  ],
  "compute_multiblank_grad_kernel": [
    "grads",
    "acts",
    "denom",
    "sigma",
    "alphas",
    "betas",
    "logll",
    "xlen",
    "ylen",
    "mlabels",
    "minibatch",
    "maxT",
    "maxU",
    "alphabet_size",
    "blank_",
    "big_blank_duration",
    "num_big_blanks",
    "fastemit_lambda",
    "clamp"
  ],
  "compute_tdt_alphas_kernel": [
    "acts",
    "duration_acts",
    "denom",
    "sigma",
    "alphas",
    "llForward",
    "xlen",
    "ylen",
    "mlabels",
    "minibatch",
    "maxT",
    "maxU",
    "alphabet_size",
    "blank_",
    "durations",
    "num_durations"
  ],
  "compute_tdt_betas_kernel": [
    "acts",
    "duration_acts",
    "denom",
    "sigma",
    "betas",
    "llBackward",
    "xlen",
    "ylen",
    "mlabels",
    "minibatch",
    "maxT",
    "maxU",
    "alphabet_size",
    "blank_",
    "durations",
    "num_durations"
  ],
  "compute_tdt_grad_kernel": [
    "label_grads",
    "duration_grads",
    "acts",
    "duration_acts",
    "denom",
    "sigma",
    "alphas",
    "betas",
    "logll",
    "xlen",
    "ylen",
    "mlabels",
    "minibatch",
    "maxT",
    "maxU",
    "alphabet_size",
    "blank_",
    "durations",
    "num_durations",
    "fastemit_lambda",
    "clamp"
  ],
  "MAX_THREAD_BUFFER": [],
  "spec_augment_kernel": [
    "x",
    "x_len",
    "freq_starts",
    "freq_widths",
    "time_starts",
    "time_widths",
    "mask_value"
  ],
  "spec_augment_launch_heuristics": [
    "x",
    "length"
  ],
  "launch_spec_augment_kernel": [
    "x",
    "x_len",
    "freq_starts",
    "freq_lengths",
    "time_starts",
    "time_lengths",
    "freq_masks",
    "time_masks",
    "mask_value"
  ],
  "SpecAugmentNumba": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "freq_masks",
      "time_masks",
      "freq_width",
      "time_width",
      "rng",
      "mask_value"
    ],
    "forward": [
      "self",
      "input_spec",
      "length"
    ]
  },
  "ExternalFeatureLoader": {
    "__init__": [
      "self",
      "augmentor"
    ],
    "load_feature_from_file": [
      "self",
      "file_path"
    ],
    "_convert_samples_to_float32": [
      "samples"
    ],
    "process": [
      "self",
      "file_path"
    ],
    "process_segment": [
      "self",
      "feature_segment"
    ]
  },
  "CONSTANT": [],
  "normalize_batch": [
    "x",
    "seq_len",
    "normalize_type"
  ],
  "clean_spectrogram_batch": [
    "spectrogram",
    "spectrogram_len",
    "fill_value"
  ],
  "splice_frames": [
    "x",
    "frame_splicing"
  ],
  "WaveformFeaturizer": {
    "__init__": [
      "self",
      "sample_rate",
      "int_values",
      "augmentor"
    ],
    "max_augmentation_length": [
      "self",
      "length"
    ],
    "process": [
      "self",
      "file_path",
      "offset",
      "duration",
      "trim",
      "trim_ref",
      "trim_top_db",
      "trim_frame_length",
      "trim_hop_length",
      "orig_sr",
      "channel_selector",
      "normalize_db"
    ],
    "process_segment": [
      "self",
      "audio_segment"
    ],
    "from_config": [
      "cls",
      "input_config",
      "perturbation_configs"
    ]
  },
  "FeaturizerFactory": {
    "__init__": [
      "self"
    ],
    "from_config": [
      "cls",
      "input_cfg",
      "perturbation_configs"
    ]
  },
  "FilterbankFeatures": {
    "__init__": [
      "self",
      "sample_rate",
      "n_window_size",
      "n_window_stride",
      "window",
      "normalize",
      "n_fft",
      "preemph",
      "nfilt",
      "lowfreq",
      "highfreq",
      "log",
      "log_zero_guard_type",
      "log_zero_guard_value",
      "dither",
      "pad_to",
      "max_duration",
      "frame_splicing",
      "exact_pad",
      "pad_value",
      "mag_power",
      "use_grads",
      "rng",
      "nb_augmentation_prob",
      "nb_max_freq",
      "mel_norm",
      "stft_exact_pad",
      "stft_conv"
    ],
    "stft": [
      "self",
      "x"
    ],
    "log_zero_guard_value_fn": [
      "self",
      "x"
    ],
    "get_seq_len": [
      "self",
      "seq_len"
    ],
    "filter_banks": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "seq_len",
      "linear_spec"
    ]
  },
  "FilterbankFeaturesTA": {
    "__init__": [
      "self",
      "sample_rate",
      "n_window_size",
      "n_window_stride",
      "normalize",
      "nfilt",
      "n_fft",
      "preemph",
      "lowfreq",
      "highfreq",
      "log",
      "log_zero_guard_type",
      "log_zero_guard_value",
      "dither",
      "window",
      "pad_to",
      "pad_value",
      "mel_norm",
      "use_grads",
      "max_duration",
      "frame_splicing",
      "exact_pad",
      "nb_augmentation_prob",
      "nb_max_freq",
      "mag_power",
      "rng",
      "stft_exact_pad",
      "stft_conv"
    ],
    "filter_banks": [
      "self"
    ],
    "_resolve_log_zero_guard_value": [
      "self",
      "dtype"
    ],
    "_apply_dithering": [
      "self",
      "signals"
    ],
    "_apply_preemphasis": [
      "self",
      "signals"
    ],
    "_compute_output_lengths": [
      "self",
      "input_lengths"
    ],
    "_apply_pad_to": [
      "self",
      "features"
    ],
    "_apply_log": [
      "self",
      "features"
    ],
    "_extract_spectrograms": [
      "self",
      "signals"
    ],
    "_apply_normalization": [
      "self",
      "features",
      "lengths",
      "eps"
    ],
    "forward": [
      "self",
      "input_signal",
      "length"
    ]
  },
  "HAVE_OMEGACONG_WEBDATASET": [],
  "read_one_audiosegment": [
    "manifest",
    "target_sr",
    "tarred_audio",
    "audio_dataset"
  ],
  "Perturbation": {
    "max_augmentation_length": [
      "self",
      "length"
    ],
    "perturb": [
      "self",
      "data"
    ]
  },
  "SpeedPerturbation": {
    "__init__": [
      "self",
      "sr",
      "resample_type",
      "min_speed_rate",
      "max_speed_rate",
      "num_rates",
      "rng"
    ],
    "max_augmentation_length": [
      "self",
      "length"
    ],
    "perturb": [
      "self",
      "data"
    ]
  },
  "TimeStretchPerturbation": {
    "__init__": [
      "self",
      "min_speed_rate",
      "max_speed_rate",
      "num_rates",
      "n_fft",
      "rng"
    ],
    "max_augmentation_length": [
      "self",
      "length"
    ],
    "perturb": [
      "self",
      "data"
    ]
  },
  "SilencePerturbation": {
    "__init__": [
      "self",
      "min_start_silence_secs",
      "max_start_silence_secs",
      "min_end_silence_secs",
      "max_end_silence_secs",
      "rng",
      "value"
    ],
    "perturb": [
      "self",
      "data"
    ]
  },
  "GainPerturbation": {
    "__init__": [
      "self",
      "min_gain_dbfs",
      "max_gain_dbfs",
      "rng"
    ],
    "perturb": [
      "self",
      "data"
    ]
  },
  "ImpulsePerturbation": {
    "__init__": [
      "self",
      "manifest_path",
      "audio_tar_filepaths",
      "shuffle_n",
      "normalize_impulse",
      "shift_impulse",
      "rng"
    ],
    "perturb": [
      "self",
      "data"
    ]
  },
  "ShiftPerturbation": {
    "__init__": [
      "self",
      "min_shift_ms",
      "max_shift_ms",
      "rng"
    ],
    "perturb": [
      "self",
      "data"
    ]
  },
  "NoisePerturbation": {
    "__init__": [
      "self",
      "manifest_path",
      "min_snr_db",
      "max_snr_db",
      "max_gain_db",
      "rng",
      "audio_tar_filepaths",
      "shuffle_n",
      "orig_sr"
    ],
    "orig_sr": [
      "self"
    ],
    "get_one_noise_sample": [
      "self",
      "target_sr"
    ],
    "perturb": [
      "self",
      "data",
      "ref_mic"
    ],
    "perturb_with_input_noise": [
      "self",
      "data",
      "noise",
      "data_rms",
      "ref_mic"
    ],
    "perturb_with_foreground_noise": [
      "self",
      "data",
      "noise",
      "data_rms",
      "max_noise_dur",
      "max_additions",
      "ref_mic"
    ]
  },
  "NoisePerturbationWithNormalization": {
    "__init__": [
      "self",
      "manifest_path",
      "min_snr_db",
      "max_snr_db",
      "snr_samples",
      "norm_to_db",
      "rng",
      "audio_tar_filepaths",
      "shuffle_n",
      "orig_sr",
      "global_rank",
      "world_size",
      "shard_strategy",
      "epsilon"
    ],
    "orig_sr": [
      "self"
    ],
    "read_one_audiosegment": [
      "self",
      "target_sr"
    ],
    "perturb": [
      "self",
      "data",
      "ref_mic"
    ],
    "snr_mixer": [
      "self",
      "clean",
      "noise",
      "snr",
      "norm_to_db"
    ],
    "norm_audio_to_db": [
      "self",
      "x",
      "norm_to_db"
    ],
    "concatenate_noise_sample": [
      "self",
      "clean",
      "noise",
      "fs",
      "silence_length"
    ],
    "perturb_with_input_noise": [
      "self",
      "data",
      "noise",
      "data_rms",
      "ref_mic",
      "norm_to_db"
    ]
  },
  "WhiteNoisePerturbation": {
    "__init__": [
      "self",
      "min_level",
      "max_level",
      "rng"
    ],
    "perturb": [
      "self",
      "data"
    ]
  },
  "RirAndNoisePerturbation": {
    "__init__": [
      "self",
      "rir_manifest_path",
      "rir_prob",
      "noise_manifest_paths",
      "noise_prob",
      "min_snr_db",
      "max_snr_db",
      "rir_tar_filepaths",
      "rir_shuffle_n",
      "noise_tar_filepaths",
      "apply_noise_rir",
      "orig_sample_rate",
      "max_additions",
      "max_duration",
      "bg_noise_manifest_paths",
      "bg_noise_prob",
      "bg_min_snr_db",
      "bg_max_snr_db",
      "bg_noise_tar_filepaths",
      "bg_orig_sample_rate",
      "rng"
    ],
    "perturb": [
      "self",
      "data"
    ]
  },
  "TranscodePerturbation": {
    "__init__": [
      "self",
      "codecs",
      "rng"
    ],
    "perturb": [
      "self",
      "data"
    ]
  },
  "RandomSegmentPerturbation": {
    "__init__": [
      "self",
      "duration_sec",
      "pad_to_duration",
      "rng",
      "min_rms_db",
      "max_trials",
      "verbose"
    ],
    "perturb": [
      "self",
      "data"
    ]
  },
  "perturbation_types": [],
  "register_perturbation": [
    "name",
    "perturbation"
  ],
  "AudioAugmentor": {
    "__init__": [
      "self",
      "perturbations",
      "rng"
    ],
    "perturb": [
      "self",
      "segment"
    ],
    "max_augmentation_length": [
      "self",
      "length"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "process_augmentations": [
    "augmenter",
    "global_rank",
    "world_size"
  ],
  "AugmentationDataset": {
    "__init__": [
      "self",
      "manifest_path",
      "tar_filepaths",
      "shuffle_n",
      "rank",
      "world_size",
      "shard_strategy"
    ],
    "__len__": [
      "self"
    ],
    "_loop_offsets": [
      "self",
      "iterator"
    ],
    "__iter__": [
      "self"
    ]
  },
  "HAVE_PYDUB": [],
  "available_formats": [],
  "sf_supported_formats": [],
  "ChannelSelectorType": [],
  "select_channels": [
    "signal",
    "channel_selector"
  ],
  "get_samples": [
    "audio_file",
    "target_sr",
    "dtype"
  ],
  "AudioSegment": {
    "__init__": [
      "self",
      "samples",
      "sample_rate",
      "target_sr",
      "trim",
      "trim_ref",
      "trim_top_db",
      "trim_frame_length",
      "trim_hop_length",
      "orig_sr",
      "channel_selector",
      "normalize_db",
      "ref_channel",
      "audio_file",
      "offset",
      "duration"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__ne__": [
      "self",
      "other"
    ],
    "__str__": [
      "self"
    ],
    "_convert_samples_to_float32": [
      "samples"
    ],
    "from_file": [
      "cls",
      "audio_file",
      "target_sr",
      "int_values",
      "offset",
      "duration",
      "trim",
      "trim_ref",
      "trim_top_db",
      "trim_frame_length",
      "trim_hop_length",
      "orig_sr",
      "channel_selector",
      "normalize_db",
      "ref_channel"
    ],
    "from_file_list": [
      "cls",
      "audio_file_list",
      "target_sr",
      "int_values",
      "offset",
      "duration",
      "trim",
      "channel_selector"
    ],
    "segment_from_file": [
      "cls",
      "audio_file",
      "target_sr",
      "n_segments",
      "trim",
      "orig_sr",
      "channel_selector",
      "offset",
      "dtype"
    ],
    "samples": [
      "self"
    ],
    "sample_rate": [
      "self"
    ],
    "num_channels": [
      "self"
    ],
    "num_samples": [
      "self"
    ],
    "duration": [
      "self"
    ],
    "rms_db": [
      "self"
    ],
    "orig_sr": [
      "self"
    ],
    "offset": [
      "self"
    ],
    "audio_file": [
      "self"
    ],
    "is_empty": [
      "self"
    ],
    "gain_db": [
      "self",
      "gain"
    ],
    "normalize_db": [
      "self",
      "target_db",
      "ref_channel"
    ],
    "pad": [
      "self",
      "pad_size",
      "symmetric"
    ],
    "subsegment": [
      "self",
      "start_time",
      "end_time"
    ]
  },
  "SLUIntentSlotBPEModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "set_decoding_strategy": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "target_semantics",
      "target_semantics_length",
      "processed_signal",
      "processed_signal_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_nb"
    ],
    "predict": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length",
      "dataloader_idx"
    ],
    "validation_pass": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_dataloader": [
      "self"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "transcribe": [
      "self",
      "audio",
      "batch_size",
      "return_hypotheses",
      "num_workers",
      "verbose"
    ],
    "_transcribe_forward": [
      "self",
      "batch",
      "trcfg"
    ],
    "_transcribe_output_processing": [
      "self",
      "outputs",
      "trcfg"
    ],
    "list_available_models": [
      "cls"
    ],
    "wer": [
      "self",
      "wer"
    ]
  },
  "HybridRNNTCTCPromptTranscribeConfig": {},
  "EncDecHybridRNNTCTCBPEModelWithPrompt": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "initialize_prompt_feature": [
      "self"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "_transcribe_forward": [
      "self",
      "batch",
      "trcfg"
    ],
    "transcribe": [
      "self",
      "audio",
      "batch_size",
      "return_hypotheses",
      "partial_hypothesis",
      "num_workers",
      "channel_selector",
      "augmentor",
      "verbose",
      "timestamps",
      "override_config"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length",
      "prompt"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_nb"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "validation_pass": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "bleu": [
      "self",
      "bleu"
    ],
    "get_transcribe_config": [
      "cls"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "EncDecSpeakerLabelModel": {
    "list_available_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "extract_labels": [
      "data_layer_config"
    ],
    "__setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "setup_training_data": [
      "self",
      "train_data_layer_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_layer_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_layer_params"
    ],
    "test_dataloader": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward_for_export": [
      "self",
      "audio_signal",
      "length"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "evaluation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "tag"
    ],
    "pair_evaluation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "tag"
    ],
    "pair_multi_eval_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx",
      "tag"
    ],
    "multi_evaluation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx",
      "tag"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "infer_file": [
      "self",
      "path2audio_file"
    ],
    "infer_segment": [
      "self",
      "segment"
    ],
    "get_label": [
      "self",
      "path2audio_file",
      "segment_duration",
      "num_segments",
      "random_seed"
    ],
    "get_embedding": [
      "self",
      "path2audio_file"
    ],
    "verify_speakers": [
      "self",
      "path2audio_file1",
      "path2audio_file2",
      "threshold"
    ],
    "verify_speakers_batch": [
      "self",
      "audio_files_pairs",
      "threshold",
      "batch_size",
      "sample_rate",
      "device"
    ],
    "batch_inference": [
      "self",
      "manifest_filepath",
      "batch_size",
      "sample_rate",
      "device"
    ]
  },
  "EncDecDiarLabelModel": {
    "list_available_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "add_speaker_model_config": [
      "self",
      "cfg"
    ],
    "_init_segmentation_info": [
      "self"
    ],
    "_init_speaker_model": [
      "self"
    ],
    "__setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "__setup_dataloader_from_config_infer": [
      "self",
      "config",
      "emb_dict",
      "emb_seq",
      "clus_label_dict",
      "pairwise_infer"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_layer_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "setup_multiple_test_data": [
      "self",
      "test_data_config"
    ],
    "test_dataloader": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "get_ms_emb_seq": [
      "self",
      "embs",
      "scale_mapping",
      "ms_seg_counts"
    ],
    "get_cluster_avg_embs_model": [
      "self",
      "embs",
      "clus_label_index",
      "ms_seg_counts",
      "scale_mapping"
    ],
    "get_ms_mel_feat": [
      "self",
      "processed_signal",
      "processed_signal_len",
      "ms_seg_timestamps",
      "ms_seg_counts"
    ],
    "forward_infer": [
      "self",
      "input_signal",
      "input_signal_length",
      "emb_vectors",
      "targets"
    ],
    "forward": [
      "self",
      "features",
      "feature_length",
      "ms_seg_timestamps",
      "ms_seg_counts",
      "clus_label_index",
      "scale_mapping",
      "targets"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "compute_accuracies": [
      "self"
    ]
  },
  "ClusterEmbedding": {
    "__init__": [
      "self",
      "cfg_diar_infer",
      "cfg_msdd_model",
      "speaker_model"
    ],
    "prepare_cluster_embs_infer": [
      "self"
    ],
    "assign_labels_to_longer_segs": [
      "self",
      "base_clus_label_dict",
      "session_scale_mapping_dict"
    ],
    "get_base_clus_label_dict": [
      "self",
      "clus_labels",
      "emb_scale_seq_dict"
    ],
    "get_cluster_avg_embs": [
      "self",
      "emb_scale_seq_dict",
      "clus_labels",
      "speaker_mapping_dict",
      "session_scale_mapping_dict"
    ],
    "run_clustering_diarizer": [
      "self",
      "manifest_filepath",
      "emb_dir"
    ],
    "get_scale_map": [
      "self",
      "embs_and_timestamps"
    ],
    "check_clustering_labels": [
      "self",
      "out_dir"
    ],
    "load_clustering_labels": [
      "self",
      "out_dir"
    ],
    "load_emb_scale_seq_dict": [
      "self",
      "out_dir"
    ]
  },
  "NeuralDiarizer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "transfer_diar_params_to_model_params": [
      "self",
      "msdd_model",
      "cfg"
    ],
    "save_to": [
      "self",
      "save_path"
    ],
    "extract_standalone_speaker_model": [
      "self",
      "prefix"
    ],
    "_init_msdd_model": [
      "self",
      "cfg"
    ],
    "get_pred_mat": [
      "self",
      "data_list"
    ],
    "get_integrated_preds_list": [
      "self",
      "uniq_id_list",
      "test_data_collection",
      "preds_list"
    ],
    "get_emb_clus_infer": [
      "self",
      "cluster_embeddings"
    ],
    "diarize": [
      "self"
    ],
    "get_range_average": [
      "self",
      "signals",
      "emb_vectors",
      "diar_window_index",
      "test_data_collection"
    ],
    "get_range_clus_avg_emb": [
      "self",
      "test_batch",
      "_test_data_collection",
      "device"
    ],
    "diar_infer": [
      "self",
      "test_batch",
      "test_data_collection"
    ],
    "run_pairwise_diarization": [
      "self"
    ],
    "run_overlap_aware_eval": [
      "self",
      "preds_list",
      "threshold"
    ],
    "from_pretrained": [
      "cls",
      "model_name",
      "vad_model_name",
      "map_location",
      "verbose"
    ],
    "__call__": [
      "self",
      "audio_filepath",
      "batch_size",
      "num_workers",
      "max_speakers",
      "num_speakers",
      "out_dir",
      "verbose"
    ],
    "_initialize_configs": [
      "self",
      "manifest_path",
      "max_speakers",
      "num_speakers",
      "tmpdir",
      "batch_size",
      "num_workers",
      "verbose"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "EncDecCTCModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "transcribe": [
      "self",
      "audio",
      "batch_size",
      "return_hypotheses",
      "num_workers",
      "channel_selector",
      "augmentor",
      "verbose",
      "timestamps",
      "override_config"
    ],
    "change_vocabulary": [
      "self",
      "new_vocabulary",
      "decoding_cfg"
    ],
    "change_decoding_strategy": [
      "self",
      "decoding_cfg",
      "verbose"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_nb"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "validation_pass": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_dataloader": [
      "self"
    ],
    "_transcribe_forward": [
      "self",
      "batch",
      "trcfg"
    ],
    "_transcribe_output_processing": [
      "self",
      "outputs",
      "trcfg"
    ],
    "get_best_hyptheses": [
      "self",
      "all_hypothesis"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "list_available_models": [
      "cls"
    ],
    "adapter_module_names": [
      "self"
    ],
    "wer": [
      "self",
      "wer"
    ]
  },
  "timeit": [
    "method"
  ],
  "OnlineClusteringDiarizer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "_init_online_clustering_module": [
      "self",
      "clustering_params"
    ],
    "_init_online_segmentor_module": [
      "self",
      "sample_rate"
    ],
    "_init_memory_buffer": [
      "self"
    ],
    "_init_temporal_major_voting_module": [
      "self",
      "clustering_params"
    ],
    "_init_segment_variables": [
      "self"
    ],
    "_init_buffer_frame_timestamps": [
      "self"
    ],
    "_transfer_timestamps_to_segmentor": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "_clear_memory": [
      "self",
      "scale_idx"
    ],
    "_temporal_label_major_vote": [
      "self"
    ],
    "save_history_data": [
      "self",
      "scale_idx",
      "total_cluster_labels",
      "is_online"
    ],
    "_run_embedding_extractor": [
      "self",
      "audio_signal"
    ],
    "_extract_online_embeddings": [
      "self",
      "audio_signal",
      "segment_ranges",
      "embeddings"
    ],
    "_perform_online_clustering": [
      "self",
      "uniq_embs_and_timestamps",
      "cuda"
    ],
    "_get_interim_output": [
      "self"
    ],
    "diarize_step": [
      "self",
      "audio_buffer",
      "vad_timestamps"
    ]
  },
  "ASRModel": {
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "list_available_models": [
      "cls"
    ],
    "add_auxiliary_losses": [
      "self",
      "loss",
      "reset_registry"
    ],
    "setup_optimization_flags": [
      "self"
    ],
    "on_after_backward": [
      "self"
    ],
    "maybe_enable_cuda_graphs": [
      "self",
      "force_reinit"
    ],
    "disable_cuda_graphs": [
      "self"
    ],
    "on_train_epoch_start": [
      "self"
    ],
    "on_train_epoch_end": [
      "self"
    ],
    "on_validation_epoch_start": [
      "self"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "on_test_epoch_start": [
      "self"
    ],
    "on_predict_epoch_start": [
      "self"
    ],
    "oomptimizer_schema": [
      "self"
    ]
  },
  "ExportableEncDecModel": {
    "input_module": [
      "self"
    ],
    "output_module": [
      "self"
    ],
    "output_names": [
      "self"
    ],
    "forward_for_export": [
      "self",
      "audio_signal",
      "length",
      "cache_last_channel",
      "cache_last_time",
      "cache_last_channel_len"
    ],
    "disabled_deployment_input_names": [
      "self"
    ],
    "disabled_deployment_output_names": [
      "self"
    ],
    "set_export_config": [
      "self",
      "args"
    ]
  },
  "EncDecMultiTalkerRNNTBPEModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "list_available_models": [
      "cls"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_nb"
    ],
    "validation_pass": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "_transcribe_forward": [
      "self",
      "batch",
      "trcfg"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ]
  },
  "ConfidenceSpec": {
    "to_confidence_config": [
      "self"
    ]
  },
  "get_filtered_logprobs": [
    "hypothesis",
    "exclude_blank"
  ],
  "compute_confidence": [
    "hypothesis",
    "confidence_cfg"
  ],
  "safe_joblib_load": [
    "file_path"
  ],
  "SecurityError": {},
  "EncDecRNNTModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "setup_optim_normalization": [
      "self"
    ],
    "extract_rnnt_loss_cfg": [
      "self",
      "cfg"
    ],
    "set_decoding_type_according_to_loss": [
      "self",
      "decoding_cfg"
    ],
    "transcribe": [
      "self",
      "audio",
      "batch_size",
      "return_hypotheses",
      "partial_hypothesis",
      "num_workers",
      "channel_selector",
      "augmentor",
      "verbose",
      "timestamps",
      "override_config"
    ],
    "change_vocabulary": [
      "self",
      "new_vocabulary",
      "decoding_cfg"
    ],
    "change_decoding_strategy": [
      "self",
      "decoding_cfg",
      "verbose"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_nb"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "validation_pass": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "_transcribe_forward": [
      "self",
      "batch",
      "trcfg"
    ],
    "_transcribe_output_processing": [
      "self",
      "outputs",
      "trcfg"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "on_after_backward": [
      "self"
    ],
    "list_export_subnets": [
      "self"
    ],
    "decoder_joint": [
      "self"
    ],
    "set_export_config": [
      "self",
      "args"
    ],
    "list_available_models": [
      "cls"
    ],
    "wer": [
      "self",
      "wer"
    ]
  },
  "EncDecHybridRNNTCTCModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "transcribe": [
      "self",
      "audio",
      "batch_size",
      "return_hypotheses",
      "partial_hypothesis",
      "num_workers",
      "channel_selector",
      "augmentor",
      "verbose",
      "timestamps",
      "override_config"
    ],
    "_transcribe_on_begin": [
      "self",
      "audio",
      "trcfg"
    ],
    "_transcribe_on_end": [
      "self",
      "trcfg"
    ],
    "_transcribe_forward": [
      "self",
      "batch",
      "trcfg"
    ],
    "_transcribe_output_processing": [
      "self",
      "outputs",
      "trcfg"
    ],
    "change_vocabulary": [
      "self",
      "new_vocabulary",
      "decoding_cfg",
      "ctc_decoding_cfg"
    ],
    "change_decoding_strategy": [
      "self",
      "decoding_cfg",
      "decoder_type",
      "verbose"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_nb"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "validation_pass": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "list_export_subnets": [
      "self"
    ],
    "output_module": [
      "self"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "EncDecK2SeqModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "list_available_models": [
      "cls"
    ],
    "change_vocabulary": [
      "self",
      "new_vocabulary"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ]
  },
  "EncDecK2SeqModelBPE": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "list_available_models": [
      "cls"
    ],
    "change_vocabulary": [
      "self",
      "new_tokenizer_dir",
      "new_tokenizer_type"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ]
  },
  "EncDecK2RnntSeqModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "list_available_models": [
      "cls"
    ],
    "change_vocabulary": [
      "self",
      "new_vocabulary"
    ]
  },
  "EncDecK2RnntSeqModelBPE": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "list_available_models": [
      "cls"
    ],
    "change_vocabulary": [
      "self",
      "new_tokenizer_dir",
      "new_tokenizer_type"
    ]
  },
  "EncDecRNNTBPEModel": {
    "list_available_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "change_vocabulary": [
      "self",
      "new_tokenizer_dir",
      "new_tokenizer_type",
      "decoding_cfg"
    ],
    "change_decoding_strategy": [
      "self",
      "decoding_cfg",
      "verbose"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ]
  },
  "_MODEL_CONFIG_YAML": [],
  "_VAD_MODEL": [],
  "_SPEAKER_MODEL": [],
  "get_available_model_names": [
    "class_name"
  ],
  "ClusteringDiarizer": {
    "__init__": [
      "self",
      "cfg",
      "speaker_model"
    ],
    "list_available_models": [
      "cls"
    ],
    "_init_vad_model": [
      "self"
    ],
    "_init_speaker_model": [
      "self",
      "speaker_model"
    ],
    "_setup_vad_test_data": [
      "self",
      "manifest_vad_input"
    ],
    "_setup_spkr_test_data": [
      "self",
      "manifest_file"
    ],
    "_run_vad": [
      "self",
      "manifest_file"
    ],
    "_run_segmentation": [
      "self",
      "window",
      "shift",
      "scale_tag"
    ],
    "_perform_speech_activity_detection": [
      "self"
    ],
    "_extract_embeddings": [
      "self",
      "manifest_file",
      "scale_idx",
      "num_scales"
    ],
    "diarize": [
      "self",
      "paths2audio_files",
      "batch_size"
    ],
    "save_to": [
      "self",
      "save_path"
    ],
    "restore_from": [
      "cls",
      "restore_path",
      "override_config_path",
      "map_location"
    ],
    "verbose": [
      "self"
    ]
  },
  "EncDecCTCModelBPE": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "change_vocabulary": [
      "self",
      "new_tokenizer_dir",
      "new_tokenizer_type",
      "decoding_cfg"
    ],
    "change_decoding_strategy": [
      "self",
      "decoding_cfg",
      "verbose"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "_fuse_bn_in_conformer": [
    "asr_model"
  ],
  "TextDataConfig": {},
  "ASRWithTTSModel": {
    "list_available_models": [
      "cls"
    ],
    "_check_config": [
      "cls",
      "cfg"
    ],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "from_asr_config": [
      "cls",
      "asr_cfg",
      "asr_model_type",
      "tts_model_path",
      "enhancer_model_path",
      "trainer"
    ],
    "from_pretrained_models": [
      "cls",
      "asr_model_path",
      "tts_model_path",
      "enhancer_model_path",
      "asr_model_fuse_bn",
      "cfg",
      "trainer"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "setup_optimization": [
      "self",
      "optim_config",
      "optim_kwargs"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "transcribe": [
      "self",
      "audio",
      "batch_size",
      "verbose"
    ],
    "setup_multiple_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "setup_multiple_test_data": [
      "self",
      "test_data_config"
    ],
    "save_asr_model_to": [
      "self",
      "save_path"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "on_test_epoch_end": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "unfreeze": [
      "self"
    ],
    "on_fit_start": [
      "self"
    ],
    "train": [
      "self",
      "mode"
    ],
    "_get_tts_spectrogram": [
      "self",
      "tts_texts",
      "speakers"
    ],
    "_get_batch_spect": [
      "self",
      "batch"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "_setup_text_dataset_from_config": [
      "self",
      "train_data_config",
      "iterable"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_nb"
    ]
  },
  "SpeechEncDecSelfSupervisedModel": {
    "list_available_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ],
    "decoder_loss_step": [
      "self",
      "spectrograms",
      "spec_masks",
      "encoded",
      "encoded_len",
      "targets",
      "target_lengths"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_nb"
    ],
    "validation_pass": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ]
  },
  "EncDecMaskedTokenPredModel": {
    "transfer_batch_to_device": [
      "self",
      "batch",
      "device",
      "dataloader_idx"
    ],
    "list_available_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "oomptimizer_schema": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length",
      "apply_mask"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "inference_pass": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "mode",
      "apply_mask"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ]
  },
  "EncDecDenoiseMaskedTokenPredModel": {
    "oomptimizer_schema": [
      "self"
    ],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length",
      "noise_signal",
      "noise_signal_length",
      "processed_noise_signal",
      "processed_noise_signal_length",
      "noisy_input_signal",
      "noisy_input_signal_length",
      "processed_noisy_input_signal",
      "processed_noisy_input_signal_length",
      "apply_mask"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "inference_pass": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "mode",
      "apply_mask"
    ]
  },
  "AlignerWrapperModel": {
    "__init__": [
      "self",
      "model",
      "cfg"
    ],
    "_init_ctc_alignment_specific": [
      "self",
      "cfg"
    ],
    "_init_rnnt_alignment_specific": [
      "self",
      "cfg"
    ],
    "_init_model_specific": [
      "self",
      "cfg"
    ],
    "_rnnt_joint_pruned": [
      "self",
      "encoder_outputs",
      "encoded_len",
      "decoder_outputs",
      "transcript_len"
    ],
    "_apply_prob_suppress": [
      "self",
      "log_probs"
    ],
    "_prepare_ctc_argmax_predictions": [
      "self",
      "log_probs",
      "encoded_len"
    ],
    "_predict_impl_rnnt_argmax": [
      "self",
      "encoded",
      "encoded_len",
      "transcript",
      "transcript_len",
      "sample_id"
    ],
    "_process_tokens_to_words": [
      "self",
      "tokens",
      "token_begin",
      "token_len",
      "token_prob",
      "words"
    ],
    "_process_char_with_space_to_words": [
      "self",
      "tokens",
      "token_begin",
      "token_len",
      "token_prob",
      "words"
    ],
    "_results_to_ctmUnits": [
      "self",
      "s_id",
      "pred",
      "prob"
    ],
    "_predict_impl_ctc": [
      "self",
      "encoded",
      "encoded_len",
      "transcript",
      "transcript_len",
      "sample_id"
    ],
    "_predict_impl_rnnt": [
      "self",
      "encoded",
      "encoded_len",
      "transcript",
      "transcript_len",
      "sample_id"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "transcribe": [
      "self",
      "manifest",
      "batch_size",
      "num_workers",
      "verbose"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_test_data": [
      "self",
      "val_data_config"
    ]
  },
  "EncDecTransfModelBPE": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "transcribe": [
      "self",
      "audio",
      "batch_size",
      "return_hypotheses",
      "num_workers",
      "channel_selector",
      "augmentor",
      "verbose"
    ],
    "_update_default_values": [
      "self",
      "config"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length",
      "transcript",
      "transcript_length"
    ],
    "compute_audio_loss": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_nb"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "eval_mode"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx",
      "eval_mode"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "test_dataloader": [
      "self"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "_transcribe_on_begin": [
      "self",
      "audio",
      "trcfg"
    ],
    "_transcribe_forward": [
      "self",
      "batch",
      "trcfg"
    ],
    "_transcribe_output_processing": [
      "self",
      "outputs",
      "trcfg"
    ],
    "_transcribe_on_end": [
      "self",
      "trcfg"
    ]
  },
  "EncDecHybridRNNTCTCBPEModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "change_vocabulary": [
      "self",
      "new_tokenizer_dir",
      "new_tokenizer_type",
      "decoding_cfg",
      "ctc_decoding_cfg"
    ],
    "change_decoding_strategy": [
      "self",
      "decoding_cfg",
      "decoder_type",
      "verbose"
    ],
    "list_available_models": [
      "cls"
    ]
  },
  "SortformerEncLabelModel": {
    "list_available_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "add_rttms_mask_mats": [
      "self",
      "rttms_mask_mats",
      "device"
    ],
    "_init_loss_weights": [
      "self"
    ],
    "_init_eval_metrics": [
      "self"
    ],
    "_reset_train_metrics": [
      "self"
    ],
    "_reset_valid_metrics": [
      "self"
    ],
    "__setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_layer_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "test_dataloader": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "frontend_encoder": [
      "self",
      "processed_signal",
      "processed_signal_length",
      "bypass_pre_encode"
    ],
    "forward_infer": [
      "self",
      "emb_seq",
      "emb_seq_length"
    ],
    "_diarize_forward": [
      "self",
      "batch"
    ],
    "_diarize_output_processing": [
      "self",
      "outputs",
      "uniq_ids",
      "diarcfg"
    ],
    "_setup_diarize_dataloader": [
      "self",
      "config"
    ],
    "oom_safe_feature_extraction": [
      "self",
      "input_signal",
      "input_signal_length"
    ],
    "process_signal": [
      "self",
      "audio_signal",
      "audio_signal_length"
    ],
    "forward": [
      "self",
      "audio_signal",
      "audio_signal_length"
    ],
    "input_names": [
      "self"
    ],
    "output_names": [
      "self"
    ],
    "streaming_input_examples": [
      "self"
    ],
    "streaming_export": [
      "self",
      "output"
    ],
    "forward_for_export": [
      "self",
      "chunk",
      "chunk_lengths",
      "spkcache",
      "spkcache_lengths",
      "fifo",
      "fifo_lengths"
    ],
    "forward_streaming": [
      "self",
      "processed_signal",
      "processed_signal_length"
    ],
    "forward_streaming_step": [
      "self",
      "processed_signal",
      "processed_signal_length",
      "streaming_state",
      "total_preds",
      "drop_extra_pre_encoded",
      "left_offset",
      "right_offset"
    ],
    "_get_aux_train_evaluations": [
      "self",
      "preds",
      "targets",
      "target_lens"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "_get_aux_validation_evaluations": [
      "self",
      "preds",
      "targets",
      "target_lens"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "_get_aux_test_batch_evaluations": [
      "self",
      "batch_idx",
      "preds",
      "targets",
      "target_lens"
    ],
    "test_batch": [
      "self"
    ],
    "on_validation_epoch_end": [
      "self"
    ],
    "diarize": [
      "self",
      "audio",
      "batch_size",
      "include_tensor_outputs",
      "postprocessing_yaml",
      "num_workers",
      "verbose",
      "override_config"
    ]
  },
  "_config_check": [
    "cfg"
  ],
  "MultiTaskTranscriptionInternalConfig": {},
  "MultiTaskTranscriptionConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "EncDecMultiTaskModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "change_decoding_strategy": [
      "self",
      "decoding_cfg"
    ],
    "change_vocabulary": [
      "self",
      "new_tokenizer_dir",
      "new_tokenizer_type",
      "decoding_cfg",
      "prompt_format"
    ],
    "change_prompt": [
      "self",
      "prompt_format",
      "prompt_defaults"
    ],
    "transcribe": [
      "self",
      "audio",
      "batch_size",
      "return_hypotheses",
      "num_workers",
      "channel_selector",
      "augmentor",
      "verbose",
      "timestamps",
      "override_config"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length",
      "transcript",
      "transcript_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_nb"
    ],
    "validation_pass": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "eval_mode"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_dataloader": [
      "self"
    ],
    "_transcribe_on_begin": [
      "self",
      "audio",
      "trcfg"
    ],
    "_transcribe_input_manifest_processing": [
      "self",
      "audio_files",
      "temp_dir",
      "trcfg"
    ],
    "_transcribe_forward": [
      "self",
      "batch",
      "trcfg"
    ],
    "_transcribe_output_processing": [
      "self",
      "outputs",
      "trcfg"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "_transcribe_on_end": [
      "self",
      "trcfg"
    ],
    "_may_be_make_dict_and_fix_paths": [
      "self",
      "json_items",
      "manifest_path",
      "trcfg"
    ],
    "get_transcribe_config": [
      "cls"
    ],
    "predict_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "has_processed_signal",
      "timestamps"
    ],
    "adapter_module_names": [
      "self"
    ],
    "oomptimizer_schema": [
      "self"
    ],
    "__restore_timestamps_asr_model": [
      "self"
    ]
  },
  "parse_multitask_prompt": [
    "prompt"
  ],
  "ClassificationInferConfig": {},
  "RegressionInferConfig": {},
  "_EncDecBaseModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_setup_preprocessor": [
      "self"
    ],
    "_setup_encoder": [
      "self"
    ],
    "_setup_decoder": [
      "self"
    ],
    "_setup_loss": [
      "self"
    ],
    "_setup_metrics": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config",
      "use_feat"
    ],
    "test_dataloader": [
      "self"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "_setup_feature_label_dataloader": [
      "self",
      "config"
    ],
    "transcribe": [
      "self",
      "audio",
      "batch_size",
      "logprobs",
      "override_config"
    ],
    "_transcribe_input_manifest_processing": [
      "self",
      "audio_files",
      "temp_dir",
      "trcfg"
    ],
    "_transcribe_forward": [
      "self",
      "batch",
      "trcfg"
    ],
    "_transcribe_output_processing": [
      "self",
      "outputs",
      "trcfg"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "_update_decoder_config": [
      "self",
      "labels",
      "cfg"
    ],
    "get_transcribe_config": [
      "cls"
    ]
  },
  "EncDecClassificationModel": {
    "setup_test_data": [
      "self",
      "test_data_config",
      "use_feat"
    ],
    "_setup_feature_label_dataloader": [
      "self",
      "config"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "forward_for_export": [
      "self",
      "audio_signal",
      "length"
    ],
    "_update_decoder_config": [
      "self",
      "labels",
      "cfg"
    ],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "change_labels": [
      "self",
      "new_labels"
    ],
    "list_available_models": [
      "cls"
    ],
    "_setup_transcribe_dataloader": [
      "self",
      "config"
    ],
    "transcribe": [
      "self",
      "audio",
      "batch_size",
      "logprobs",
      "override_config"
    ],
    "_transcribe_input_manifest_processing": [
      "self",
      "audio_files",
      "temp_dir",
      "trcfg"
    ],
    "_transcribe_forward": [
      "self",
      "batch",
      "trcfg"
    ],
    "_transcribe_output_processing": [
      "self",
      "outputs",
      "trcfg"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length"
    ]
  },
  "EncDecRegressionModel": {
    "list_available_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "_setup_preprocessor": [
      "self"
    ],
    "_setup_encoder": [
      "self"
    ],
    "_setup_decoder": [
      "self"
    ],
    "_setup_loss": [
      "self"
    ],
    "_setup_metrics": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "transcribe": [
      "self",
      "audio",
      "batch_size",
      "override_config"
    ],
    "_update_decoder_config": [
      "self",
      "labels",
      "cfg"
    ]
  },
  "EncDecFrameClassificationModel": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "output_types": [
      "self"
    ],
    "list_available_models": [
      "cls"
    ],
    "_setup_preprocessor": [
      "self"
    ],
    "_setup_encoder": [
      "self"
    ],
    "_setup_decoder": [
      "self"
    ],
    "_update_decoder_config": [
      "self",
      "labels",
      "cfg"
    ],
    "_setup_metrics": [
      "self"
    ],
    "_setup_loss": [
      "self"
    ],
    "_setup_dataloader_from_config": [
      "self",
      "config"
    ],
    "_setup_feature_label_dataloader": [
      "self",
      "config"
    ],
    "get_label_masks": [
      "self",
      "labels",
      "labels_len"
    ],
    "forward": [
      "self",
      "input_signal",
      "input_signal_length",
      "processed_signal",
      "processed_signal_length"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx",
      "tag"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx",
      "tag"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "reshape_labels": [
      "self",
      "logits",
      "labels",
      "logits_len",
      "labels_len"
    ],
    "get_metric_logits_labels": [
      "self",
      "logits",
      "labels",
      "masks"
    ],
    "forward_for_export": [
      "self",
      "input",
      "length",
      "cache_last_channel",
      "cache_last_time",
      "cache_last_channel_len"
    ]
  },
  "AlignerCTCConfig": {},
  "AlignerRNNTConfig": {},
  "AlignerWrapperModelConfig": {},
  "K2AlignerWrapperModelConfig": {},
  "qn_15x5": [],
  "jasper_10x5_dr": [],
  "JasperModelConfig": {},
  "QuartzNetModelConfig": {},
  "EncDecCTCModelConfigBuilder": {
    "VALID_CONFIGS": [],
    "__init__": [
      "self",
      "name",
      "encoder_cfg_func"
    ],
    "set_labels": [
      "self",
      "labels"
    ],
    "set_separable": [
      "self",
      "separable"
    ],
    "set_repeat": [
      "self",
      "repeat"
    ],
    "set_sample_rate": [
      "self",
      "sample_rate"
    ],
    "set_dropout": [
      "self",
      "dropout"
    ],
    "set_dataset_normalize": [
      "self",
      "normalize"
    ],
    "_finalize_cfg": [
      "self"
    ],
    "build": [
      "self"
    ]
  },
  "EncDecK2SeqConfig": {},
  "EncDecK2SeqModelConfig": {},
  "matchboxnet_3x1x64": [],
  "matchboxnet_3x1x64_vad": [],
  "MatchboxNetModelConfig": {},
  "MatchboxNetVADModelConfig": {},
  "EncDecClassificationModelConfigBuilder": {
    "VALID_CONFIGS": [],
    "__init__": [
      "self",
      "name",
      "encoder_cfg_func"
    ],
    "set_labels": [
      "self",
      "labels"
    ],
    "set_separable": [
      "self",
      "separable"
    ],
    "set_repeat": [
      "self",
      "repeat"
    ],
    "set_sample_rate": [
      "self",
      "sample_rate"
    ],
    "set_dropout": [
      "self",
      "dropout"
    ],
    "set_timesteps": [
      "self",
      "timesteps"
    ],
    "set_is_regression_task": [
      "self",
      "is_regression_task"
    ],
    "_finalize_cfg": [
      "self"
    ],
    "build": [
      "self"
    ]
  },
  "EncDecClassificationDatasetConfig": {},
  "EncDecClassificationConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "EncDecClassificationModelConfig": {},
  "DiarizerComponentConfig": {
    "get": [
      "self",
      "name",
      "default"
    ],
    "__iter__": [
      "self"
    ],
    "dict": [
      "self"
    ]
  },
  "ASRDiarizerCTCDecoderParams": {},
  "ASRRealigningLMParams": {},
  "ASRDiarizerParams": {},
  "ASRDiarizerConfig": {},
  "VADParams": {},
  "VADConfig": {},
  "SpeakerEmbeddingsParams": {},
  "SpeakerEmbeddingsConfig": {},
  "ClusteringParams": {},
  "ClusteringConfig": {},
  "MSDDParams": {},
  "MSDDConfig": {},
  "DiarizerConfig": {},
  "NeuralDiarizerInferenceConfig": {
    "init_config": [
      "cls",
      "diar_model_path",
      "vad_model_path",
      "map_location",
      "verbose"
    ]
  },
  "ASRDatasetConfig": {},
  "EncDecCTCConfig": {},
  "EncDecCTCModelConfig": {},
  "CacheAwareStreamingConfig": {},
  "LSTMDecoder": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "feat_in",
      "num_classes",
      "lstm_hidden_size",
      "vocabulary",
      "bidirectional",
      "num_layers"
    ],
    "forward": [
      "self",
      "encoder_output"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "vocabulary": [
      "self"
    ],
    "num_classes_with_blank": [
      "self"
    ]
  },
  "ConvLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride"
    ],
    "forward": [
      "self",
      "feature"
    ]
  },
  "MSDD_module": {
    "output_types": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "init_weights": [
      "self",
      "m"
    ],
    "__init__": [
      "self",
      "num_spks",
      "hidden_size",
      "num_lstm_layers",
      "dropout_rate",
      "cnn_output_ch",
      "emb_dim",
      "scale_n",
      "clamp_max",
      "conv_repeat",
      "weighting_scheme",
      "context_vector_type"
    ],
    "core_model": [
      "self",
      "ms_emb_seq",
      "length",
      "ms_avg_embs",
      "targets"
    ],
    "element_wise_product": [
      "self",
      "scale_weights",
      "ms_avg_embs",
      "ms_emb_seq"
    ],
    "cosine_similarity": [
      "self",
      "scale_weights",
      "ms_avg_embs",
      "_ms_emb_seq"
    ],
    "attention_scale_weights": [
      "self",
      "ms_avg_embs_perm",
      "ms_emb_seq"
    ],
    "conv_scale_weights": [
      "self",
      "ms_avg_embs_perm",
      "ms_emb_seq_single"
    ],
    "conv_forward": [
      "self",
      "conv_input",
      "conv_module",
      "bn_module",
      "first_layer"
    ],
    "forward": [
      "self",
      "ms_emb_seq",
      "length",
      "ms_avg_embs",
      "targets"
    ],
    "input_example": [
      "self"
    ]
  },
  "_TokensWrapper": {
    "__init__": [
      "self",
      "vocabulary",
      "tokenizer"
    ],
    "blank": [
      "self"
    ],
    "unk_id": [
      "self"
    ],
    "vocab": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "token_to_id": [
      "self",
      "token"
    ],
    "text_to_tokens": [
      "self",
      "text"
    ]
  },
  "FlashLightKenLMBeamSearchDecoder": {
    "__init__": [
      "self",
      "lm_path",
      "vocabulary",
      "tokenizer",
      "lexicon_path",
      "boost_path",
      "beam_size",
      "beam_size_token",
      "beam_threshold",
      "lm_weight",
      "word_score",
      "unk_weight",
      "sil_weight"
    ],
    "_get_tokens": [
      "self",
      "idxs"
    ],
    "_get_timesteps": [
      "self",
      "token_idxs"
    ],
    "forward": [
      "self",
      "log_probs"
    ]
  },
  "AbstractRNNTJoint": {
    "joint_after_projection": [
      "self",
      "f",
      "g"
    ],
    "project_encoder": [
      "self",
      "encoder_output"
    ],
    "project_prednet": [
      "self",
      "prednet_output"
    ],
    "joint": [
      "self",
      "f",
      "g"
    ],
    "num_classes_with_blank": [
      "self"
    ],
    "num_extra_outputs": [
      "self"
    ]
  },
  "AbstractRNNTDecoder": {
    "__init__": [
      "self",
      "vocab_size",
      "blank_idx",
      "blank_as_pad"
    ],
    "predict": [
      "self",
      "y",
      "state",
      "add_sos",
      "batch_size"
    ],
    "initialize_state": [
      "self",
      "y"
    ],
    "score_hypothesis": [
      "self",
      "hypothesis",
      "cache"
    ],
    "batch_score_hypothesis": [
      "self",
      "hypotheses",
      "cache"
    ],
    "batch_initialize_states": [
      "self",
      "decoder_states"
    ],
    "batch_select_state": [
      "self",
      "batch_states",
      "idx"
    ],
    "batch_aggregate_states_beam": [
      "cls",
      "src_states",
      "batch_size",
      "beam_size",
      "indices",
      "dst_states"
    ],
    "batch_replace_states_mask": [
      "cls",
      "src_states",
      "dst_states",
      "mask",
      "other_src_states"
    ],
    "batch_replace_states_all": [
      "cls",
      "src_states",
      "dst_states",
      "batch_size"
    ],
    "clone_state": [
      "cls",
      "states"
    ],
    "batch_split_states": [
      "cls",
      "batch_states"
    ],
    "batch_unsplit_states": [
      "cls",
      "batch_states",
      "device",
      "dtype"
    ],
    "batch_concat_states": [
      "self",
      "batch_states"
    ],
    "batch_copy_states": [
      "self",
      "old_states",
      "new_states",
      "ids",
      "value"
    ],
    "mask_select_states": [
      "self",
      "states",
      "mask"
    ]
  },
  "HATJoint": {
    "__init__": [
      "self",
      "jointnet",
      "num_classes",
      "num_extra_outputs",
      "vocabulary",
      "log_softmax",
      "preserve_memory",
      "fuse_loss_wer",
      "fused_batch_size",
      "experimental_fuse_loss_wer"
    ],
    "return_hat_ilm": [
      "self",
      "hat_subtract_ilm"
    ],
    "joint_after_projection": [
      "self",
      "f",
      "g"
    ],
    "_joint_hat_net_modules": [
      "self",
      "num_classes",
      "pred_n_hidden",
      "enc_n_hidden",
      "joint_n_hidden",
      "activation",
      "dropout"
    ]
  },
  "ConformerEncoder": {
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "input_types": [
      "self"
    ],
    "input_types_for_export": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "output_types_for_export": [
      "self"
    ],
    "disabled_deployment_input_names": [
      "self"
    ],
    "disabled_deployment_output_names": [
      "self"
    ],
    "__init__": [
      "self",
      "feat_in",
      "n_layers",
      "d_model",
      "feat_out",
      "causal_downsampling",
      "subsampling",
      "subsampling_factor",
      "subsampling_conv_chunking_factor",
      "subsampling_conv_channels",
      "reduction",
      "reduction_position",
      "reduction_factor",
      "ff_expansion_factor",
      "self_attention_model",
      "n_heads",
      "att_context_size",
      "att_context_probs",
      "att_context_style",
      "xscaling",
      "untie_biases",
      "pos_emb_max_len",
      "conv_kernel_size",
      "conv_norm_type",
      "conv_context_size",
      "use_bias",
      "dropout",
      "dropout_pre_encoder",
      "dropout_emb",
      "dropout_att",
      "stochastic_depth_drop_prob",
      "stochastic_depth_mode",
      "stochastic_depth_start_layer",
      "global_tokens",
      "global_tokens_spacing",
      "global_attn_separate",
      "use_pytorch_sdpa",
      "use_pytorch_sdpa_backends",
      "sync_max_audio_length"
    ],
    "forward_for_export": [
      "self",
      "audio_signal",
      "length",
      "cache_last_channel",
      "cache_last_time",
      "cache_last_channel_len"
    ],
    "streaming_post_process": [
      "self",
      "rets",
      "keep_all_outputs"
    ],
    "forward": [
      "self",
      "audio_signal",
      "length",
      "cache_last_channel",
      "cache_last_time",
      "cache_last_channel_len",
      "bypass_pre_encode"
    ],
    "forward_internal": [
      "self",
      "audio_signal",
      "length",
      "cache_last_channel",
      "cache_last_time",
      "cache_last_channel_len",
      "bypass_pre_encode"
    ],
    "update_max_seq_length": [
      "self",
      "seq_length",
      "device"
    ],
    "set_max_audio_length": [
      "self",
      "max_audio_length"
    ],
    "_create_masks": [
      "self",
      "att_context_size",
      "padding_length",
      "max_audio_length",
      "offset",
      "device"
    ],
    "enable_pad_mask": [
      "self",
      "on"
    ],
    "_calc_context_sizes": [
      "self",
      "att_context_size",
      "att_context_probs",
      "att_context_style",
      "conv_context_size",
      "conv_kernel_size"
    ],
    "set_default_att_context_size": [
      "self",
      "att_context_size"
    ],
    "setup_streaming_params": [
      "self",
      "chunk_size",
      "shift_size",
      "left_chunks",
      "att_context_size",
      "max_context"
    ],
    "get_initial_cache_state": [
      "self",
      "batch_size",
      "dtype",
      "device",
      "max_dim"
    ],
    "change_attention_model": [
      "self",
      "self_attention_model",
      "att_context_size",
      "update_config",
      "device"
    ],
    "change_subsampling_conv_chunking_factor": [
      "self",
      "subsampling_conv_chunking_factor"
    ]
  },
  "ConformerEncoderAdapter": {
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "is_adapter_available": [
      "self"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "_update_adapter_cfg_input_dim": [
      "self",
      "cfg"
    ],
    "get_accepted_adapter_types": [
      "self"
    ]
  },
  "ConformerMultiLayerFeatureExtractor": {
    "__init__": [
      "self",
      "encoder",
      "layer_idx_list",
      "aggregator",
      "detach",
      "convert_to_cpu"
    ],
    "forward": [
      "self",
      "audio_signal",
      "length",
      "cache_last_channel",
      "cache_last_time",
      "cache_last_channel_len"
    ]
  },
  "ConformerChangeConfig": {},
  "ViterbiDecoderWithGraph": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "num_classes",
      "backend",
      "dec_type",
      "return_type",
      "return_ilabels",
      "output_aligned",
      "split_batch_size",
      "graph_module_cfg"
    ],
    "update_graph": [
      "self",
      "graph"
    ],
    "_forward_impl": [
      "self",
      "log_probs",
      "log_probs_length",
      "targets",
      "target_length"
    ],
    "forward": [
      "self",
      "log_probs",
      "log_probs_length"
    ],
    "align": [
      "self",
      "log_probs",
      "log_probs_length",
      "targets",
      "target_length"
    ]
  },
  "TransposeLast": {
    "forward": [
      "self",
      "x"
    ]
  },
  "SamePad": {
    "__init__": [
      "self",
      "kernel_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvFeatureEncoder": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "conv_layers",
      "extractor_mode",
      "conv_bias",
      "feature_grad_mult",
      "normalize_audio",
      "embedding_dim"
    ],
    "apply_layers": [
      "self",
      "x"
    ],
    "normalize": [
      "self",
      "source",
      "lengths"
    ],
    "forward": [
      "self",
      "input_signal",
      "length"
    ],
    "get_lengths": [
      "self",
      "audio_lengths"
    ]
  },
  "Wav2VecTransformerEncoder": {
    "__init__": [
      "self",
      "pos_embed",
      "transformer",
      "layer_drop"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "audio_signal",
      "length"
    ],
    "apply_transformer": [
      "self",
      "x",
      "padding_mask"
    ],
    "create_padding_mask": [
      "self",
      "length"
    ]
  },
  "GradMultiply": {
    "forward": [
      "ctx",
      "x",
      "scale"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "StreamingSortformerState": {
    "spkcache": [],
    "spkcache_lengths": [],
    "spkcache_preds": [],
    "fifo": [],
    "fifo_lengths": [],
    "fifo_preds": [],
    "spk_perm": [],
    "mean_sil_emb": [],
    "n_sil_frames": [],
    "to": [
      "self",
      "device"
    ]
  },
  "SortformerModules": {
    "init_weights": [
      "self",
      "m"
    ],
    "__init__": [
      "self",
      "num_spks",
      "dropout_rate",
      "fc_d_model",
      "tf_d_model",
      "subsampling_factor",
      "spkcache_len",
      "fifo_len",
      "chunk_len",
      "spkcache_update_period",
      "chunk_left_context",
      "chunk_right_context",
      "spkcache_sil_frames_per_spk",
      "causal_attn_rate",
      "causal_attn_rc",
      "scores_add_rnd",
      "pred_score_threshold",
      "max_index",
      "scores_boost_latest",
      "sil_threshold",
      "strong_boost_rate",
      "weak_boost_rate",
      "min_pos_scores_rate"
    ],
    "_check_streaming_parameters": [
      "self"
    ],
    "length_to_mask": [
      "lengths",
      "max_length"
    ],
    "streaming_feat_loader": [
      "self",
      "feat_seq",
      "feat_seq_length",
      "feat_seq_offset"
    ],
    "forward_speaker_sigmoids": [
      "self",
      "hidden_out"
    ],
    "concat_embs": [
      "list_of_tensors",
      "return_lengths",
      "dim",
      "device"
    ],
    "concat_and_pad": [
      "embs",
      "lengths"
    ],
    "init_streaming_state": [
      "self",
      "batch_size",
      "async_streaming",
      "device"
    ],
    "apply_mask_to_preds": [
      "spkcache_fifo_chunk_preds",
      "spkcache_fifo_chunk_fc_encoder_lengths"
    ],
    "streaming_update_async": [
      "self",
      "streaming_state",
      "chunk",
      "chunk_lengths",
      "preds",
      "lc",
      "rc"
    ],
    "streaming_update": [
      "self",
      "streaming_state",
      "chunk",
      "preds",
      "lc",
      "rc"
    ],
    "_boost_topk_scores": [
      "self",
      "scores",
      "n_boost_per_spk",
      "scale_factor",
      "offset"
    ],
    "_get_silence_profile": [
      "self",
      "mean_sil_emb",
      "n_sil_frames",
      "emb_seq",
      "preds"
    ],
    "_get_log_pred_scores": [
      "self",
      "preds"
    ],
    "_get_topk_indices": [
      "self",
      "scores"
    ],
    "_gather_spkcache_and_preds": [
      "self",
      "emb_seq",
      "preds",
      "topk_indices",
      "is_disabled",
      "mean_sil_emb"
    ],
    "_get_max_perm_index": [
      "self",
      "scores"
    ],
    "_disable_low_scores": [
      "self",
      "preds",
      "scores",
      "min_pos_scores_per_spk"
    ],
    "_permute_speakers": [
      "self",
      "scores",
      "max_perm_index"
    ],
    "_compress_spkcache": [
      "self",
      "emb_seq",
      "preds",
      "mean_sil_emb",
      "permute_spk"
    ]
  },
  "StatelessTransducerDecoder": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "__init__": [
      "self",
      "prednet",
      "vocab_size",
      "context_size",
      "normalization_mode"
    ],
    "forward": [
      "self",
      "targets",
      "target_length",
      "states"
    ],
    "predict": [
      "self",
      "y",
      "state",
      "add_sos",
      "batch_size"
    ],
    "_predict_modules": [
      "self"
    ],
    "score_hypothesis": [
      "self",
      "hypothesis",
      "cache"
    ],
    "initialize_state": [
      "self",
      "y"
    ],
    "batch_initialize_states": [
      "self",
      "decoder_states"
    ],
    "batch_select_state": [
      "self",
      "batch_states",
      "idx"
    ],
    "batch_concat_states": [
      "self",
      "batch_states"
    ],
    "batch_replace_states_mask": [
      "cls",
      "src_states",
      "dst_states",
      "mask",
      "other_src_states"
    ],
    "batch_replace_states_all": [
      "cls",
      "src_states",
      "dst_states",
      "batch_size"
    ],
    "clone_state": [
      "cls",
      "state"
    ],
    "batch_split_states": [
      "cls",
      "batch_states"
    ],
    "batch_unsplit_states": [
      "cls",
      "batch_states",
      "device",
      "dtype"
    ],
    "batch_copy_states": [
      "self",
      "old_states",
      "new_states",
      "ids",
      "value"
    ],
    "mask_select_states": [
      "self",
      "states",
      "mask"
    ],
    "batch_score_hypothesis": [
      "self",
      "hypotheses",
      "cache"
    ]
  },
  "RNNTDecoder": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "__init__": [
      "self",
      "prednet",
      "vocab_size",
      "normalization_mode",
      "random_state_sampling",
      "blank_as_pad"
    ],
    "forward": [
      "self",
      "targets",
      "target_length",
      "states"
    ],
    "predict": [
      "self",
      "y",
      "state",
      "add_sos",
      "batch_size"
    ],
    "_predict_modules": [
      "self",
      "vocab_size",
      "pred_n_hidden",
      "pred_rnn_layers",
      "forget_gate_bias",
      "t_max",
      "norm",
      "weights_init_scale",
      "hidden_hidden_bias_scale",
      "dropout",
      "rnn_hidden_size"
    ],
    "initialize_state": [
      "self",
      "y"
    ],
    "score_hypothesis": [
      "self",
      "hypothesis",
      "cache"
    ],
    "batch_score_hypothesis": [
      "self",
      "hypotheses",
      "cache"
    ],
    "batch_initialize_states": [
      "self",
      "decoder_states"
    ],
    "batch_select_state": [
      "self",
      "batch_states",
      "idx"
    ],
    "batch_aggregate_states_beam": [
      "cls",
      "src_states",
      "batch_size",
      "beam_size",
      "indices",
      "dst_states"
    ],
    "batch_concat_states": [
      "self",
      "batch_states"
    ],
    "batch_replace_states_mask": [
      "cls",
      "src_states",
      "dst_states",
      "mask",
      "other_src_states"
    ],
    "batch_replace_states_all": [
      "cls",
      "src_states",
      "dst_states",
      "batch_size"
    ],
    "clone_state": [
      "cls",
      "state"
    ],
    "batch_split_states": [
      "cls",
      "batch_states"
    ],
    "batch_unsplit_states": [
      "cls",
      "batch_states",
      "device",
      "dtype"
    ],
    "batch_copy_states": [
      "self",
      "old_states",
      "new_states",
      "ids",
      "value"
    ],
    "mask_select_states": [
      "self",
      "states",
      "mask"
    ],
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "_update_adapter_cfg_input_dim": [
      "self",
      "cfg"
    ]
  },
  "RNNTJoint": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "disabled_deployment_input_names": [
      "self"
    ],
    "__init__": [
      "self",
      "jointnet",
      "num_classes",
      "num_extra_outputs",
      "vocabulary",
      "log_softmax",
      "preserve_memory",
      "fuse_loss_wer",
      "fused_batch_size",
      "experimental_fuse_loss_wer",
      "masking_prob"
    ],
    "forward": [
      "self",
      "encoder_outputs",
      "decoder_outputs",
      "encoder_lengths",
      "transcripts",
      "transcript_lengths",
      "compute_wer"
    ],
    "project_encoder": [
      "self",
      "encoder_output"
    ],
    "project_prednet": [
      "self",
      "prednet_output"
    ],
    "joint_after_projection": [
      "self",
      "f",
      "g"
    ],
    "_joint_net_modules": [
      "self",
      "num_classes",
      "pred_n_hidden",
      "enc_n_hidden",
      "joint_n_hidden",
      "activation",
      "dropout"
    ],
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "_update_adapter_cfg_input_dim": [
      "self",
      "cfg"
    ],
    "num_classes_with_blank": [
      "self"
    ],
    "num_extra_outputs": [
      "self"
    ],
    "loss": [
      "self"
    ],
    "set_loss": [
      "self",
      "loss"
    ],
    "wer": [
      "self"
    ],
    "set_wer": [
      "self",
      "wer"
    ],
    "fuse_loss_wer": [
      "self"
    ],
    "set_fuse_loss_wer": [
      "self",
      "fuse_loss_wer",
      "loss",
      "metric"
    ],
    "fused_batch_size": [
      "self"
    ],
    "set_fused_batch_size": [
      "self",
      "fused_batch_size"
    ]
  },
  "RNNTDecoderJoint": {
    "__init__": [
      "self",
      "decoder",
      "joint"
    ],
    "input_types": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "encoder_outputs",
      "targets",
      "target_length",
      "input_states_1",
      "input_states_2"
    ]
  },
  "RNNTDecoderJointSSL": {
    "__init__": [
      "self",
      "decoder",
      "joint"
    ],
    "needs_labels": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "encoder_output",
      "targets",
      "target_lengths"
    ]
  },
  "SampledRNNTJoint": {
    "__init__": [
      "self",
      "jointnet",
      "num_classes",
      "n_samples",
      "vocabulary",
      "log_softmax",
      "preserve_memory",
      "fuse_loss_wer",
      "fused_batch_size"
    ],
    "forward": [
      "self",
      "encoder_outputs",
      "decoder_outputs",
      "encoder_lengths",
      "transcripts",
      "transcript_lengths",
      "compute_wer"
    ],
    "sampled_joint": [
      "self",
      "f",
      "g",
      "transcript",
      "transcript_lengths"
    ]
  },
  "AudioPreprocessor": {
    "__init__": [
      "self",
      "win_length",
      "hop_length"
    ],
    "forward": [
      "self",
      "input_signal",
      "length"
    ],
    "get_features": [
      "self",
      "input_signal",
      "length"
    ]
  },
  "AudioToMelSpectrogramPreprocessor": {
    "save_to": [
      "self",
      "save_path"
    ],
    "restore_from": [
      "cls",
      "restore_path"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "sample_rate",
      "window_size",
      "window_stride",
      "n_window_size",
      "n_window_stride",
      "window",
      "normalize",
      "n_fft",
      "preemph",
      "features",
      "lowfreq",
      "highfreq",
      "log",
      "log_zero_guard_type",
      "log_zero_guard_value",
      "dither",
      "pad_to",
      "frame_splicing",
      "exact_pad",
      "pad_value",
      "mag_power",
      "rng",
      "nb_augmentation_prob",
      "nb_max_freq",
      "use_torchaudio",
      "mel_norm",
      "stft_exact_pad",
      "stft_conv"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim",
      "min_length"
    ],
    "get_features": [
      "self",
      "input_signal",
      "length"
    ],
    "filter_banks": [
      "self"
    ]
  },
  "AudioToMFCCPreprocessor": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "save_to": [
      "self",
      "save_path"
    ],
    "restore_from": [
      "cls",
      "restore_path"
    ],
    "__init__": [
      "self",
      "sample_rate",
      "window_size",
      "window_stride",
      "n_window_size",
      "n_window_stride",
      "window",
      "n_fft",
      "lowfreq",
      "highfreq",
      "n_mels",
      "n_mfcc",
      "dct_type",
      "norm",
      "log"
    ],
    "get_features": [
      "self",
      "input_signal",
      "length"
    ]
  },
  "SpectrogramAugmentation": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "freq_masks",
      "time_masks",
      "freq_width",
      "time_width",
      "rect_masks",
      "rect_time",
      "rect_freq",
      "rng",
      "mask_value",
      "use_vectorized_spec_augment",
      "use_numba_spec_augment"
    ],
    "forward": [
      "self",
      "input_spec",
      "length"
    ]
  },
  "MaskedPatchAugmentation": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "patch_size",
      "mask_patches",
      "freq_masks",
      "freq_width"
    ],
    "forward": [
      "self",
      "input_spec",
      "length"
    ]
  },
  "CropOrPadSpectrogramAugmentation": {
    "__init__": [
      "self",
      "audio_length"
    ],
    "forward": [
      "self",
      "input_signal",
      "length"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "save_to": [
      "self",
      "save_path"
    ],
    "restore_from": [
      "cls",
      "restore_path"
    ]
  },
  "AudioToMelSpectrogramPreprocessorConfig": {},
  "AudioToMFCCPreprocessorConfig": {},
  "SpectrogramAugmentationConfig": {},
  "CropOrPadSpectrogramAugmentationConfig": {},
  "MaskedPatchAugmentationConfig": {},
  "SqueezeformerEncoder": {
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "feat_in",
      "n_layers",
      "d_model",
      "feat_out",
      "subsampling",
      "subsampling_factor",
      "subsampling_conv_channels",
      "ff_expansion_factor",
      "self_attention_model",
      "n_heads",
      "att_context_size",
      "xscaling",
      "untie_biases",
      "pos_emb_max_len",
      "conv_kernel_size",
      "conv_norm_type",
      "dropout",
      "dropout_emb",
      "dropout_att",
      "adaptive_scale",
      "time_reduce_idx",
      "time_recovery_idx"
    ],
    "set_max_audio_length": [
      "self",
      "max_audio_length"
    ],
    "forward": [
      "self",
      "audio_signal",
      "length"
    ],
    "forward_for_export": [
      "self",
      "audio_signal",
      "length"
    ],
    "update_max_seq_length": [
      "self",
      "seq_length",
      "device"
    ],
    "make_pad_mask": [
      "self",
      "max_audio_length",
      "seq_lens"
    ],
    "enable_pad_mask": [
      "self",
      "on"
    ]
  },
  "SqueezeformerEncoderAdapter": {
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "is_adapter_available": [
      "self"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "_update_adapter_cfg_input_dim": [
      "self",
      "cfg"
    ],
    "get_accepted_adapter_types": [
      "self"
    ]
  },
  "BeamSearchDecoderWithLM": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "vocab",
      "beam_width",
      "alpha",
      "beta",
      "lm_path",
      "num_cpus",
      "cutoff_prob",
      "cutoff_top_n",
      "input_tensor"
    ],
    "forward": [
      "self",
      "log_probs",
      "log_probs_length"
    ]
  },
  "ConvASREncoder": {
    "_prepare_for_export": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "jasper",
      "activation",
      "feat_in",
      "normalization_mode",
      "residual_mode",
      "norm_groups",
      "conv_mask",
      "frame_splicing",
      "init_mode",
      "quantize"
    ],
    "forward": [
      "self",
      "audio_signal",
      "length"
    ],
    "update_max_sequence_length": [
      "self",
      "seq_length",
      "device"
    ],
    "subsampling_factor": [
      "self"
    ]
  },
  "ParallelConvASREncoder": {
    "_prepare_for_export": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "disabled_deployment_input_names": [
      "self"
    ],
    "disabled_deployment_output_names": [
      "self"
    ],
    "save_to": [
      "self",
      "save_path"
    ],
    "restore_from": [
      "cls",
      "restore_path"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "jasper",
      "activation",
      "feat_in",
      "normalization_mode",
      "residual_mode",
      "norm_groups",
      "conv_mask",
      "frame_splicing",
      "init_mode",
      "aggregation_mode",
      "quantize"
    ],
    "forward": [
      "self",
      "audio_signal",
      "length"
    ]
  },
  "ConvASRDecoder": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "feat_in",
      "num_classes",
      "init_mode",
      "vocabulary",
      "add_blank"
    ],
    "forward": [
      "self",
      "encoder_output"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "_update_adapter_cfg_input_dim": [
      "self",
      "cfg"
    ],
    "vocabulary": [
      "self"
    ],
    "num_classes_with_blank": [
      "self"
    ]
  },
  "ConvASRDecoderReconstruction": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "feat_in",
      "feat_out",
      "feat_hidden",
      "stride_layers",
      "non_stride_layers",
      "kernel_size",
      "init_mode",
      "activation",
      "stride_transpose",
      "apply_softmax"
    ],
    "forward": [
      "self",
      "encoder_output"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "_prepare_for_export": [
      "self"
    ]
  },
  "ConvASRDecoderClassification": {
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "feat_in",
      "num_classes",
      "init_mode",
      "return_logits",
      "pooling_type"
    ],
    "forward": [
      "self",
      "encoder_output"
    ],
    "num_classes": [
      "self"
    ]
  },
  "ECAPAEncoder": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "feat_in",
      "filters",
      "kernel_sizes",
      "dilations",
      "scale",
      "init_mode"
    ],
    "forward": [
      "self",
      "audio_signal",
      "length"
    ]
  },
  "SpeakerDecoder": {
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "feat_in",
      "num_classes",
      "emb_sizes",
      "pool_mode",
      "angular",
      "attention_channels",
      "init_mode"
    ],
    "affine_layer": [
      "self",
      "inp_shape",
      "out_shape",
      "learn_mean",
      "affine_type"
    ],
    "forward": [
      "self",
      "encoder_output",
      "length"
    ]
  },
  "ConvASREncoderAdapter": {
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "is_adapter_available": [
      "self"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "_update_adapter_cfg_input_dim": [
      "self",
      "block",
      "cfg"
    ],
    "get_accepted_adapter_types": [
      "self"
    ]
  },
  "JasperEncoderConfig": {},
  "ConvASREncoderConfig": {},
  "ConvASRDecoderConfig": {},
  "ConvASRDecoderClassificationConfig": {},
  "RNNEncoder": {
    "input_example": [
      "self"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "feat_in",
      "n_layers",
      "d_model",
      "proj_size",
      "rnn_type",
      "bidirectional",
      "subsampling",
      "subsampling_factor",
      "subsampling_conv_channels",
      "dropout"
    ],
    "forward": [
      "self",
      "audio_signal",
      "length"
    ]
  },
  "SpeakerNoiseAugmentation": {
    "__init__": [
      "self",
      "prob",
      "noise_ratio",
      "min_r_speech",
      "max_r_speech",
      "min_r_noise",
      "max_r_noise",
      "min_mix_rate",
      "max_mix_rate"
    ],
    "repeat_noise": [
      "self",
      "noise",
      "noise_len",
      "max_audio_len"
    ],
    "pad_or_trim_noise": [
      "self",
      "noise",
      "max_audio_len",
      "value"
    ],
    "__call__": [
      "self",
      "batch"
    ]
  },
  "MultiSpeakerNoiseAugmentation": {
    "__init__": [
      "self",
      "prob",
      "noise_ratio",
      "min_r_speech",
      "max_r_speech",
      "min_r_noise",
      "max_r_noise",
      "min_mix_rate",
      "max_mix_rate",
      "min_num_segments",
      "max_num_segments",
      "min_num_speakers",
      "max_num_speakers"
    ],
    "__call__": [
      "self",
      "batch"
    ],
    "get_noise_segments": [
      "self",
      "batch_idx",
      "batch",
      "segment_lens",
      "num_speakers",
      "mode"
    ]
  },
  "RandomBlockMasking": {
    "__init__": [
      "self",
      "feat_in",
      "mask_prob",
      "block_size",
      "mask_value",
      "freeze",
      "allow_overlap",
      "max_mask_ratio"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_feats",
      "input_lengths"
    ],
    "forward_without_overlap": [
      "self",
      "input_feats",
      "input_lengths"
    ],
    "forward_with_overlap": [
      "self",
      "input_feats",
      "input_lengths"
    ]
  },
  "ConvFeatureMaksingWrapper": {
    "__init__": [
      "self",
      "pre_encode_module",
      "masking_module"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ],
    "set_masking_enabled": [
      "self",
      "apply_mask"
    ],
    "get_current_mask": [
      "self"
    ],
    "get_current_feat": [
      "self"
    ]
  },
  "MultiSoftmaxDecoder": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "__init__": [
      "self",
      "feat_in",
      "num_classes",
      "num_decoders",
      "init_mode",
      "use_bias",
      "squeeze_single"
    ],
    "forward": [
      "self",
      "encoder_output"
    ]
  },
  "Aggregator": {
    "AVAILABLE_POOLING": [],
    "__init__": [
      "self",
      "mode",
      "weights",
      "layer_idx_list",
      "channel_idx"
    ],
    "_forward_for_weighted_sum": [
      "self",
      "encoded",
      "encoded_len"
    ],
    "forward": [
      "self",
      "encoded",
      "encoded_len"
    ]
  },
  "ConformerMultiLayerFeaturePreprocessor": {
    "__init__": [
      "self",
      "aggregator",
      "preprocessor",
      "encoder",
      "spec_augment",
      "layer_idx_list",
      "freeze_encoder"
    ],
    "forward": [
      "self",
      "input_signal",
      "length"
    ]
  },
  "RandomProjectionVectorQuantizer": {
    "DIST_FN_LIST": [],
    "__init__": [
      "self",
      "feat_in",
      "code_dim",
      "num_classes",
      "num_books",
      "dist_fn",
      "time_ahead",
      "freeze",
      "squeeze_single",
      "combine_time_steps"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "forward": [
      "self",
      "input_signal"
    ]
  },
  "PoolingEncoder": {
    "_SUPPORTED_ARCH": [],
    "__init__": [
      "self",
      "num_layers",
      "hidden_size",
      "inner_size",
      "mask_future",
      "num_attention_heads",
      "attn_score_dropout",
      "attn_layer_dropout",
      "ffn_dropout",
      "hidden_act",
      "pre_ln",
      "pre_ln_final_layer_norm",
      "hidden_steps",
      "hidden_init_method",
      "hidden_blocks",
      "pooling_type"
    ],
    "_build_pooling_module": [
      "self"
    ],
    "supported_arch": [
      "self"
    ],
    "supported_init_methods": [
      "self"
    ],
    "hidden_steps": [
      "self"
    ],
    "hidden_blocks": [
      "self"
    ],
    "hidden_init_method": [
      "self"
    ],
    "forward": [
      "self",
      "encoder_states",
      "encoder_mask"
    ]
  },
  "NeMoTransformerBottleneckConfig": {},
  "NeMoTransformerBottleneckEncoderConfig": {},
  "NeMoTransformerBottleneckDecoderConfig": {},
  "TransformerBottleneckEncoderNM": {
    "_SUPPORTED_ARCH": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_layers",
      "inner_size",
      "num_attention_heads",
      "max_sequence_length",
      "num_token_types",
      "embedding_dropout",
      "learn_positional_encodings",
      "ffn_dropout",
      "attn_score_dropout",
      "attn_layer_dropout",
      "hidden_act",
      "mask_future",
      "pre_ln",
      "pre_ln_final_layer_norm",
      "arch",
      "hidden_steps",
      "hidden_blocks",
      "hidden_init_method",
      "return_mask"
    ],
    "_build_encoder": [
      "self",
      "arch"
    ],
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "supported_arch": [
      "self"
    ],
    "arch": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "encoder_mask",
      "return_mask"
    ]
  },
  "TransformerBottleneckDecoderNM": {
    "_SUPPORTED_ARCH": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_layers",
      "inner_size",
      "num_attention_heads",
      "max_sequence_length",
      "num_token_types",
      "embedding_dropout",
      "learn_positional_encodings",
      "ffn_dropout",
      "attn_score_dropout",
      "attn_layer_dropout",
      "hidden_act",
      "pre_ln",
      "pre_ln_final_layer_norm",
      "arch"
    ],
    "_build_decoder": [
      "self",
      "arch"
    ],
    "supported_arch": [
      "self"
    ],
    "arch": [
      "self"
    ]
  },
  "GreedySequenceGenerator": {
    "__init__": [
      "self",
      "embedding",
      "decoder",
      "classifier",
      "pad",
      "bos",
      "eos",
      "max_sequence_length",
      "max_delta_length",
      "batch_size",
      "n_samples",
      "temperature",
      "preserve_step_confidence",
      "confidence_method_cfg"
    ],
    "_one_step_forward": [
      "self",
      "decoder_input_ids",
      "encoder_hidden_states",
      "encoder_input_mask",
      "decoder_mems_list",
      "pos",
      "return_scores"
    ],
    "_prepare_for_search": [
      "self",
      "decoder_input_ids",
      "encoder_hidden_states"
    ],
    "_forward": [
      "self",
      "decoder_input_ids",
      "encoder_hidden_states",
      "encoder_input_mask",
      "return_beam_scores"
    ],
    "__call__": [
      "self",
      "decoder_input_ids",
      "encoder_hidden_states",
      "encoder_input_mask",
      "return_beam_scores"
    ],
    "freeze": [
      "self"
    ],
    "unfreeze": [
      "self"
    ],
    "as_frozen": [
      "self"
    ]
  },
  "TopKSequenceGenerator": {
    "__init__": [
      "self",
      "embedding",
      "decoder",
      "log_softmax",
      "beam_size",
      "temperature"
    ],
    "_one_step_forward": [
      "self",
      "decoder_input_ids",
      "encoder_hidden_states",
      "encoder_input_mask",
      "decoder_mems_list",
      "pos",
      "return_scores"
    ]
  },
  "BeamSearchSequenceGenerator": {
    "__init__": [
      "self",
      "embedding",
      "decoder",
      "log_softmax",
      "beam_size",
      "len_pen"
    ],
    "compute_len_penalty": [
      "lengths",
      "alpha"
    ],
    "_forward": [
      "self",
      "decoder_input_ids",
      "encoder_hidden_states",
      "encoder_input_mask",
      "return_beam_scores"
    ]
  },
  "BeamSearchSequenceGeneratorWithFusionModels": {
    "__init__": [
      "self",
      "embedding",
      "decoder",
      "log_softmax",
      "fusion_models",
      "fusion_models_alpha",
      "beam_size",
      "len_pen"
    ],
    "_forward": [
      "self",
      "decoder_input_ids",
      "encoder_hidden_states",
      "encoder_input_mask",
      "return_beam_scores"
    ]
  },
  "EnsembleBeamSearchSequenceGenerator": {
    "__init__": [
      "self",
      "encoders",
      "embeddings",
      "decoders",
      "log_softmaxes",
      "beam_size",
      "len_pen",
      "pad",
      "bos",
      "eos",
      "max_sequence_length",
      "max_delta_length",
      "batch_size",
      "language_model",
      "fusion_coef"
    ],
    "compute_len_penalty": [
      "lengths",
      "alpha"
    ],
    "_one_step_forward_lm": [
      "self",
      "decoder_input_ids",
      "lm_mems_list",
      "pos"
    ],
    "_one_step_forward": [
      "self",
      "ensemble_index",
      "decoder_input_ids",
      "encoder_hidden_states",
      "encoder_input_mask",
      "decoder_mems_list",
      "pos"
    ],
    "_prepare_for_search": [
      "self",
      "decoder_input_ids",
      "encoder_hidden_states"
    ],
    "_get_encoder_hidden_states": [
      "self",
      "src_ids",
      "encoder_input_mask",
      "ensemble_index"
    ],
    "_average_probs": [
      "self",
      "probs_list"
    ],
    "_forward": [
      "self",
      "src_ids",
      "encoder_input_mask",
      "decoder_input_ids",
      "return_beam_scores"
    ],
    "__call__": [
      "self",
      "src_ids",
      "encoder_input_mask",
      "decoder_input_ids",
      "return_beam_scores"
    ],
    "freeze": [
      "self"
    ],
    "unfreeze": [
      "self"
    ],
    "as_frozen": [
      "self"
    ]
  },
  "BeamSearchSequenceGeneratorWithLanguageModel": {
    "__init__": [
      "self",
      "embedding",
      "decoder",
      "log_softmax",
      "language_model",
      "beam_size",
      "len_pen",
      "fusion_coef"
    ],
    "_one_step_forward": [
      "self",
      "decoder_input_ids",
      "encoder_hidden_states",
      "encoder_input_mask",
      "decoder_mems_list",
      "lm_mems_list",
      "pos"
    ],
    "compute_len_penalty": [
      "lengths",
      "alpha"
    ],
    "_forward": [
      "self",
      "decoder_input_ids",
      "encoder_hidden_states",
      "encoder_input_mask",
      "return_beam_scores"
    ]
  },
  "DecoderModule": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "hidden_size": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "embedding": [
      "self"
    ],
    "decoder": [
      "self"
    ],
    "max_sequence_length": [
      "self"
    ]
  },
  "TransformerDecoderAdapter": {
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "is_adapter_available": [
      "self"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "_update_adapter_cfg_input_dim": [
      "self",
      "cfg"
    ]
  },
  "FixedPositionalEncoding": {
    "__init__": [
      "self",
      "hidden_size",
      "max_sequence_length"
    ],
    "_build_pos_enc": [
      "self",
      "hidden_size",
      "max_sequence_length",
      "device"
    ],
    "forward": [
      "self",
      "position_ids"
    ]
  },
  "TransformerEmbedding": {
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "max_sequence_length",
      "num_token_types",
      "embedding_dropout",
      "learn_positional_encodings"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "start_pos"
    ]
  },
  "AttentionBridge": {
    "__init__": [
      "self",
      "hidden_size",
      "k",
      "bridge_size"
    ],
    "forward": [
      "self",
      "hidden",
      "hidden_mask",
      "return_ortho_loss"
    ]
  },
  "BridgeEncoder": {
    "__init__": [
      "self",
      "num_layers",
      "hidden_size",
      "inner_size",
      "mask_future",
      "num_attention_heads",
      "attn_score_dropout",
      "attn_layer_dropout",
      "ffn_dropout",
      "hidden_act",
      "pre_ln",
      "pre_ln_final_layer_norm",
      "hidden_steps",
      "hidden_init_method",
      "hidden_blocks"
    ],
    "supported_init_methods": [
      "self"
    ],
    "hidden_steps": [
      "self"
    ],
    "hidden_blocks": [
      "self"
    ],
    "hidden_init_method": [
      "self"
    ],
    "forward": [
      "self",
      "encoder_states",
      "encoder_mask"
    ]
  },
  "NeMoTransformerConfig": {},
  "NeMoTransformerEncoderConfig": {},
  "NeMoTransformerDecoderConfig": {},
  "TransformerEncoderNM": {
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_layers",
      "inner_size",
      "num_attention_heads",
      "max_sequence_length",
      "num_token_types",
      "embedding_dropout",
      "learn_positional_encodings",
      "ffn_dropout",
      "attn_score_dropout",
      "attn_layer_dropout",
      "hidden_act",
      "mask_future",
      "pre_ln",
      "pre_ln_final_layer_norm"
    ],
    "forward": [
      "self",
      "input_ids",
      "encoder_mask"
    ],
    "hidden_size": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "max_sequence_length": [
      "self"
    ],
    "embedding": [
      "self"
    ],
    "encoder": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ]
  },
  "TransformerDecoderNM": {
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "num_layers",
      "inner_size",
      "num_attention_heads",
      "max_sequence_length",
      "num_token_types",
      "embedding_dropout",
      "learn_positional_encodings",
      "ffn_dropout",
      "attn_score_dropout",
      "attn_layer_dropout",
      "hidden_act",
      "pre_ln",
      "pre_ln_final_layer_norm"
    ],
    "forward": [
      "self",
      "input_ids",
      "decoder_mask",
      "encoder_embeddings",
      "encoder_mask",
      "decoder_mems"
    ],
    "hidden_size": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "max_sequence_length": [
      "self"
    ],
    "embedding": [
      "self"
    ],
    "decoder": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "output_types": [
      "self"
    ]
  },
  "TransformerDecoderNMAdapter": {
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "is_adapter_available": [
      "self"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "_update_adapter_cfg_input_dim": [
      "self",
      "cfg"
    ]
  },
  "get_nemo_transformer": [
    "model_name",
    "pretrained",
    "config_dict",
    "encoder",
    "pre_ln_final_layer_norm"
  ],
  "PerceiverEncoder": {
    "__init__": [
      "self",
      "num_layers",
      "hidden_size",
      "inner_size",
      "mask_future",
      "num_attention_heads",
      "attn_score_dropout",
      "attn_layer_dropout",
      "ffn_dropout",
      "hidden_act",
      "pre_ln",
      "pre_ln_final_layer_norm",
      "hidden_steps",
      "hidden_init_method",
      "hidden_blocks"
    ],
    "supported_init_methods": [
      "self"
    ],
    "hidden_steps": [
      "self"
    ],
    "hidden_blocks": [
      "self"
    ],
    "hidden_init_method": [
      "self"
    ],
    "forward": [
      "self",
      "encoder_states",
      "encoder_mask"
    ]
  },
  "TransformerEncoderBlock": {
    "__init__": [
      "self",
      "hidden_size",
      "inner_size",
      "num_attention_heads",
      "attn_score_dropout",
      "attn_layer_dropout",
      "ffn_dropout",
      "hidden_act",
      "pre_ln"
    ],
    "forward_preln": [
      "self",
      "encoder_query",
      "encoder_mask",
      "encoder_keys"
    ],
    "forward_postln": [
      "self",
      "encoder_query",
      "encoder_mask",
      "encoder_keys"
    ],
    "forward": [
      "self",
      "encoder_query",
      "encoder_mask",
      "encoder_keys"
    ],
    "get_accepted_adapter_types": [
      "self"
    ]
  },
  "TransformerEncoder": {
    "__init__": [
      "self",
      "num_layers",
      "hidden_size",
      "inner_size",
      "mask_future",
      "num_attention_heads",
      "attn_score_dropout",
      "attn_layer_dropout",
      "ffn_dropout",
      "hidden_act",
      "pre_ln",
      "pre_ln_final_layer_norm"
    ],
    "_get_memory_states": [
      "self",
      "encoder_states",
      "encoder_mems_list",
      "i"
    ],
    "forward": [
      "self",
      "encoder_states",
      "encoder_mask",
      "encoder_mems_list",
      "return_mems"
    ]
  },
  "TransformerEncoderAdapter": {
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "is_adapter_available": [
      "self"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "_update_adapter_cfg_input_dim": [
      "self",
      "cfg"
    ]
  },
  "LengthParam": {},
  "SamplingParam": {},
  "TextGeneration": {
    "generate": [
      "self",
      "inputs",
      "length_params",
      "sampling_params"
    ]
  },
  "EncoderModule": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "hidden_size": [
      "self"
    ]
  },
  "AxisKindAbstract": {},
  "AxisKind": {
    "Batch": [],
    "Time": [],
    "Dimension": [],
    "Channel": [],
    "Width": [],
    "Height": [],
    "Any": [],
    "Sequence": [],
    "FlowGroup": [],
    "Singleton": [],
    "__repr__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "t_with_string": [
      "self",
      "text"
    ],
    "from_str": [
      "label"
    ]
  },
  "AxisType": {
    "__init__": [
      "self",
      "kind",
      "size",
      "is_list"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ElementType": {
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "type_parameters": [
      "self"
    ],
    "fields": [
      "self"
    ],
    "compare": [
      "self",
      "second"
    ]
  },
  "VoidType": {
    "__init__": [
      "self"
    ],
    "compare": [
      "self",
      "second"
    ]
  },
  "ChannelType": {
    "__init__": [
      "self"
    ]
  },
  "EmbeddedTextType": {
    "__init__": [
      "self"
    ]
  },
  "LogitsType": {
    "__init__": [
      "self"
    ]
  },
  "ProbsType": {
    "__init__": [
      "self"
    ]
  },
  "LogprobsType": {
    "__init__": [
      "self"
    ]
  },
  "LabelsType": {
    "__init__": [
      "self"
    ]
  },
  "HypothesisType": {
    "__init__": [
      "self"
    ]
  },
  "LengthsType": {
    "__init__": [
      "self"
    ]
  },
  "LossType": {
    "__init__": [
      "self"
    ]
  },
  "EncodedRepresentation": {
    "__init__": [
      "self"
    ]
  },
  "AcousticEncodedRepresentation": {
    "__init__": [
      "self"
    ]
  },
  "AudioSignal": {
    "__init__": [
      "self",
      "freq"
    ],
    "type_parameters": [
      "self"
    ]
  },
  "VideoSignal": {
    "__init__": [
      "self",
      "fps"
    ],
    "type_parameters": [
      "self"
    ]
  },
  "SpectrogramType": {
    "__init__": [
      "self"
    ]
  },
  "MelSpectrogramType": {
    "__init__": [
      "self"
    ]
  },
  "MFCCSpectrogramType": {
    "__init__": [
      "self"
    ]
  },
  "PredictionsType": {
    "__init__": [
      "self"
    ]
  },
  "RegressionValuesType": {
    "__init__": [
      "self"
    ]
  },
  "CategoricalValuesType": {
    "__init__": [
      "self"
    ]
  },
  "MaskType": {
    "__init__": [
      "self"
    ]
  },
  "Index": {
    "__init__": [
      "self"
    ]
  },
  "Target": {
    "__init__": [
      "self"
    ]
  },
  "ClassificationTarget": {
    "__init__": [
      "self"
    ]
  },
  "ImageValue": {
    "__init__": [
      "self"
    ]
  },
  "NormalizedImageValue": {
    "__init__": [
      "self"
    ]
  },
  "ImageFeatureValue": {
    "__init__": [
      "self"
    ]
  },
  "StringType": {
    "__init__": [
      "self"
    ]
  },
  "StringLabel": {
    "__init__": [
      "self"
    ]
  },
  "BoolType": {
    "__init__": [
      "self"
    ]
  },
  "IntType": {
    "__init__": [
      "self"
    ]
  },
  "FloatType": {
    "__init__": [
      "self"
    ]
  },
  "TokenIndex": {
    "__init__": [
      "self"
    ]
  },
  "Length": {
    "__init__": [
      "self"
    ]
  },
  "ProbabilityDistributionSamplesType": {
    "__init__": [
      "self"
    ]
  },
  "NormalDistributionSamplesType": {
    "__init__": [
      "self"
    ]
  },
  "SequenceToSequenceAlignmentType": {
    "__init__": [
      "self"
    ]
  },
  "NormalDistributionMeanType": {
    "__init__": [
      "self"
    ]
  },
  "NormalDistributionLogVarianceType": {
    "__init__": [
      "self"
    ]
  },
  "TokenDurationType": {
    "__init__": [
      "self"
    ]
  },
  "TokenLogDurationType": {
    "__init__": [
      "self"
    ]
  },
  "LogDeterminantType": {
    "__init__": [
      "self"
    ]
  },
  "NeuralTypeComparisonResult": {
    "SAME": [],
    "LESS": [],
    "GREATER": [],
    "DIM_INCOMPATIBLE": [],
    "TRANSPOSE_SAME": [],
    "CONTAINER_SIZE_MISMATCH": [],
    "INCOMPATIBLE": [],
    "SAME_TYPE_INCOMPATIBLE_PARAMS": [],
    "UNCHECKED": []
  },
  "NeuralType": {
    "__str__": [
      "self"
    ],
    "__init__": [
      "self",
      "axes",
      "elements_type",
      "optional"
    ],
    "_init_internal": [
      "self",
      "axes",
      "elements_type",
      "optional"
    ],
    "compare": [
      "self",
      "second"
    ],
    "compare_and_raise_error": [
      "self",
      "parent_type_name",
      "port_name",
      "second_object"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__check_sanity": [
      "axes"
    ],
    "__compare_axes": [
      "axes_a",
      "axes_b"
    ],
    "__repr__": [
      "self"
    ]
  },
  "NeuralTypeError": {},
  "NeuralPortNameMismatchError": {
    "__init__": [
      "self",
      "input_port_name"
    ]
  },
  "NeuralPortNmTensorMismatchError": {
    "__init__": [
      "self",
      "class_name",
      "port_name",
      "first_type",
      "second_type",
      "type_comatibility"
    ]
  },
  "OptimizerParams": {},
  "SGDParams": {},
  "AdamParams": {},
  "AdamWParams": {},
  "AdadeltaParams": {},
  "AdamaxParams": {},
  "AdagradParams": {},
  "RMSpropParams": {},
  "RpropParams": {},
  "NovogradParams": {},
  "AdafactorParams": {},
  "register_optimizer_params": [
    "name",
    "optimizer_params"
  ],
  "get_optimizer_config": [
    "name"
  ],
  "AVAILABLE_OPTIMIZER_PARAMS": [],
  "SchedConfig": {},
  "OptimConfig": {},
  "ModelConfig": {},
  "HydraConfig": {},
  "NemoConfig": {},
  "ModelConfigBuilder": {
    "__init__": [
      "self",
      "model_cfg"
    ],
    "set_train_ds": [
      "self",
      "cfg"
    ],
    "set_validation_ds": [
      "self",
      "cfg"
    ],
    "set_test_ds": [
      "self",
      "cfg"
    ],
    "set_optim": [
      "self",
      "cfg",
      "sched_cfg"
    ],
    "_finalize_cfg": [
      "self"
    ],
    "build": [
      "self"
    ]
  },
  "cs": [],
  "TrainerConfig": {},
  "Config": {},
  "_get_gpu_name": [],
  "hydra_runner": [
    "config_path",
    "config_name",
    "schema"
  ],
  "SchedulerParams": {},
  "SquareRootConstantSchedulerParams": {},
  "WarmupSchedulerParams": {},
  "WarmupHoldSchedulerParams": {},
  "WarmupAnnealingHoldSchedulerParams": {},
  "SquareAnnealingParams": {},
  "SquareRootAnnealingParams": {},
  "CosineAnnealingParams": {},
  "NoamAnnealingParams": {},
  "NoamHoldAnnealingParams": {},
  "WarmupAnnealingParams": {},
  "InverseSquareRootAnnealingParams": {},
  "PolynomialDecayAnnealingParams": {},
  "PolynomialHoldDecayAnnealingParams": {},
  "StepLRParams": {},
  "ExponentialLRParams": {},
  "ReduceLROnPlateauParams": {},
  "CyclicLRParams": {},
  "register_scheduler_params": [
    "name",
    "scheduler_params"
  ],
  "get_scheduler_config": [
    "name"
  ],
  "AVAILABLE_SCHEDULER_PARAMS": [],
  "DataLoaderConfig": {},
  "NEMO_DEFAULT_MODEL_CARD_TEMPLATE": [],
  "__K2_MINIMUM_MAJOR_VERSION": [],
  "__K2_MINIMUM_MINOR_VERSION": [],
  "__K2_MINIMUM_VERSION": [],
  "K2_INSTALLATION_MESSAGE": [],
  "get_io_names": [
    "types",
    "disabled_names"
  ],
  "extract_dynamic_axes": [
    "name",
    "ntype"
  ],
  "__CUDA_PYTHON_MINIMUM_VERSION_CUDA_GRAPH_CONDITIONAL_NODES_SUPPORTED__": [],
  "check_cuda_python_cuda_graphs_conditional_nodes_supported": [],
  "skip_cuda_python_test_if_cuda_graphs_conditional_nodes_not_supported": [],
  "assert_drv": [
    "err"
  ],
  "cu_call": [
    "f_call_out"
  ],
  "with_conditional_node": [
    "while_loop_kernel",
    "while_loop_args",
    "while_loop_conditional_handle",
    "device"
  ],
  "run_nvrtc": [
    "kernel_string",
    "kernel_name",
    "program_name"
  ],
  "cuda_logger": [],
  "__NUMBA_DEFAULT_MINIMUM_VERSION__": [],
  "__NUMBA_MINIMUM_VERSION__": [],
  "__NUMBA_MINIMUM_VERSION_FP16_SUPPORTED__": [],
  "NUMBA_INSTALLATION_MESSAGE": [],
  "STRICT_NUMBA_COMPAT_CHECK": [],
  "is_numba_compat_strict": [],
  "set_numba_compat_strictness": [
    "strict"
  ],
  "with_numba_compat_strictness": [
    "strict"
  ],
  "numba_cpu_is_supported": [
    "min_version"
  ],
  "numba_cuda_is_supported": [
    "min_version"
  ],
  "is_numba_cuda_fp16_supported": [
    "return_reason"
  ],
  "skip_numba_cuda_test_if_unsupported": [
    "min_version"
  ],
  "is_lib_available": [
    "name"
  ],
  "KENLM_AVAILABLE": [],
  "KENLM_INSTALLATION_MESSAGE": [],
  "TRITON_AVAILABLE": [],
  "TRITON_INSTALLATION_MESSAGE": [],
  "identity_decorator": [
    "f"
  ],
  "_lib_required": [
    "is_available",
    "name",
    "message"
  ],
  "kenlm_required": [],
  "triton_required": [],
  "k2_required": [],
  "is_in_toplevel_plugins_module": [],
  "ProcessLauncherConfig": {},
  "execute_job": [
    "idx",
    "overrides",
    "hydra_context",
    "config",
    "singleton_state",
    "gpu_idx"
  ],
  "launch": [
    "launcher",
    "job_overrides",
    "initial_job_idx"
  ],
  "ProcessLauncher": {
    "__init__": [
      "self"
    ],
    "setup": [
      "self"
    ],
    "launch": [
      "self",
      "job_overrides",
      "initial_job_idx"
    ]
  },
  "AVAILABLE_OPTIMIZERS": [],
  "HAVE_APEX_DISTRIBUTED_ADAM": [],
  "parse_optimizer_args": [
    "optimizer_name",
    "optimizer_kwargs"
  ],
  "register_optimizer": [
    "name",
    "optimizer",
    "optimizer_params"
  ],
  "init_optimizer_states": [
    "optimizer"
  ],
  "WarmupPolicy": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "get_lr": [
      "self"
    ],
    "_get_warmup_lr": [
      "self",
      "step"
    ],
    "_get_lr": [
      "self",
      "step"
    ]
  },
  "SquareRootConstantPolicy": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "get_lr": [
      "self"
    ],
    "_get_lr": [
      "self",
      "step"
    ]
  },
  "WarmupHoldPolicy": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "get_lr": [
      "self"
    ]
  },
  "WarmupHoldAnnealOneMinusSquareRoot": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "_get_lr": [
      "self",
      "step"
    ]
  },
  "WarmupHoldAnnealLinear": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "_get_lr": [
      "self",
      "step"
    ]
  },
  "WarmupAnnealHoldPolicy": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "get_lr": [
      "self"
    ],
    "_get_warmup_lr": [
      "self",
      "step"
    ],
    "_get_constant_lr": [
      "self",
      "step"
    ],
    "_get_lr": [
      "self",
      "step"
    ]
  },
  "_squareroot_annealing": [
    "initial_lr",
    "step",
    "max_steps",
    "min_lr"
  ],
  "_square_annealing": [
    "initial_lr",
    "step",
    "max_steps",
    "min_lr"
  ],
  "_cosine_annealing": [
    "initial_lr",
    "step",
    "max_steps",
    "min_lr"
  ],
  "_linear_warmup_with_cosine_annealing": [
    "max_lr",
    "warmup_steps",
    "step",
    "decay_steps",
    "min_lr"
  ],
  "_poly_decay": [
    "initial_lr",
    "step",
    "decay_steps",
    "power",
    "min_lr",
    "cycle"
  ],
  "_noam_hold_annealing": [
    "initial_lr",
    "step",
    "warmup_steps",
    "hold_steps",
    "decay_rate",
    "min_lr"
  ],
  "SquareAnnealing": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "_get_lr": [
      "self",
      "step"
    ]
  },
  "SquareRootAnnealing": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "_get_lr": [
      "self",
      "step"
    ]
  },
  "CosineAnnealing": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "_get_lr": [
      "self",
      "step"
    ],
    "_get_warmup_lr": [
      "self",
      "step"
    ],
    "_get_constant_lr": [
      "self",
      "step"
    ],
    "_get_linear_warmup_with_cosine_annealing_lr": [
      "self",
      "step"
    ]
  },
  "NoamAnnealing": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "get_lr": [
      "self"
    ],
    "_noam_annealing": [
      "self",
      "initial_lr",
      "step"
    ]
  },
  "NoamHoldAnnealing": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "_get_lr": [
      "self",
      "step"
    ]
  },
  "WarmupAnnealing": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "_get_lr": [
      "self",
      "step"
    ]
  },
  "InverseSquareRootAnnealing": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "_get_lr": [
      "self",
      "step"
    ]
  },
  "T5InverseSquareRootAnnealing": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "_get_lr": [
      "self",
      "step"
    ]
  },
  "PolynomialDecayAnnealing": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "_get_lr": [
      "self",
      "step"
    ]
  },
  "PolynomialHoldDecayAnnealing": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "_get_lr": [
      "self",
      "step"
    ]
  },
  "register_scheduler": [
    "name",
    "scheduler",
    "scheduler_params"
  ],
  "get_scheduler": [
    "name"
  ],
  "prepare_lr_scheduler": [
    "optimizer",
    "scheduler_config",
    "train_dataloader"
  ],
  "compute_max_steps": [
    "max_epochs",
    "accumulate_grad_batches",
    "limit_train_batches",
    "num_workers",
    "num_samples",
    "batch_size",
    "drop_last"
  ],
  "AVAILABLE_SCHEDULERS": [],
  "EPOCH_SCHEDULERS": [],
  "Adafactor": {
    "__init__": [
      "self",
      "params",
      "lr",
      "eps",
      "clip_threshold",
      "decay_rate",
      "beta1",
      "weight_decay",
      "scale_parameter",
      "relative_step",
      "warmup_init",
      "min_step"
    ],
    "supports_memory_efficient_fp16": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ],
    "_get_lr": [
      "self",
      "param_group",
      "param_state"
    ],
    "_get_options": [
      "self",
      "param_group",
      "param_shape"
    ],
    "_rms": [
      "self",
      "tensor"
    ],
    "_approx_sq_grad": [
      "self",
      "exp_avg_sq_row",
      "exp_avg_sq_col"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "_zero_grad_group_helper": [
    "group",
    "set_to_none"
  ],
  "_multi_tensor_copy_this_to_that": [
    "this",
    "that",
    "overflow_buf"
  ],
  "_get_grad_data_group": [
    "is_expert_group"
  ],
  "GradBucket": {
    "__init__": [
      "self",
      "numel",
      "chunk_size_mb",
      "data_group"
    ],
    "zero": [
      "self"
    ],
    "allreduce_buffer": [
      "self"
    ],
    "get": [
      "self",
      "shape",
      "start_index"
    ],
    "update_chunk_info": [
      "self",
      "grad_chunk_info"
    ],
    "get_allreduce_tensor": [
      "self"
    ]
  },
  "MainParamsOptimizerWrapper": {
    "__init__": [
      "self",
      "optimizer",
      "fp32_grad_accum",
      "contiguous_grad_bucket",
      "async_grad_allreduce",
      "grad_div_ar_fusion",
      "grad_allreduce_chunk_size_mb"
    ],
    "_make_param_hook": [
      "self",
      "param",
      "main_param",
      "i",
      "grad_chunk_info",
      "is_expert_group"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ],
    "copy_model_grads_to_main_grads": [
      "self"
    ],
    "_get_model_and_main_params_data_float16": [
      "self"
    ],
    "_set_overflow_buffer": [
      "self",
      "half_dtype"
    ],
    "_copy_main_params_to_model_params": [
      "self"
    ],
    "_copy_model_params_to_main_params": [
      "self"
    ],
    "reload_model_params": [
      "self"
    ],
    "step": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "allreduce_main_grads": [
      "self"
    ],
    "no_sync": [
      "self"
    ],
    "async_master_grads_allreudce": [
      "self"
    ],
    "fp32_grad_accumulation": [
      "self"
    ],
    "get_parameters_with_grad": [
      "self"
    ],
    "_get_state": [
      "self"
    ],
    "_set_state": [
      "self",
      "value"
    ],
    "state": [],
    "_get_param_groups": [
      "self"
    ],
    "_set_param_groups": [
      "self",
      "value"
    ],
    "param_groups": [],
    "_get_defaults": [
      "self"
    ],
    "_set_defaults": [
      "self",
      "value"
    ],
    "defaults": []
  },
  "_check_valid_opt_params": [
    "lr",
    "eps",
    "betas"
  ],
  "Novograd": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "grad_averaging",
      "amsgrad",
      "luc",
      "luc_trust",
      "luc_eps"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "MultiTensorApply": {
    "available": [],
    "warned": [],
    "__init__": [
      "self",
      "chunk_size"
    ],
    "__call__": [
      "self",
      "op",
      "noop_flag_buffer",
      "tensor_lists"
    ]
  },
  "Adan": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "max_grad_norm",
      "no_prox",
      "foreach",
      "fused"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "restart_opt": [
      "self"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "_single_tensor_adan": [
    "params",
    "grads",
    "exp_avgs",
    "exp_avg_sqs",
    "exp_avg_diffs",
    "neg_pre_grads"
  ],
  "_multi_tensor_adan": [
    "params",
    "grads",
    "exp_avgs",
    "exp_avg_sqs",
    "exp_avg_diffs",
    "neg_pre_grads"
  ],
  "_fused_adan_multi_tensor": [
    "params",
    "grads",
    "exp_avgs",
    "exp_avg_sqs",
    "exp_avg_diffs",
    "neg_pre_grads"
  ],
  "_fused_adan_single_tensor": [
    "params",
    "grads",
    "exp_avgs",
    "exp_avg_sqs",
    "exp_avg_diffs",
    "neg_pre_grads"
  ],
  "_filter_empty_common_step": [
    "state_dict"
  ],
  "McoreDistributedOptimizer": {
    "NVTX_LABEL": [],
    "__init__": [
      "self",
      "optim"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ],
    "reload_model_params": [
      "self",
      "state_dict"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "sharded_state_dict": [
      "self",
      "model_sharded_state_dict",
      "optimizer_state_dict",
      "is_loading",
      "dist_ckpt_parallel_save"
    ],
    "step": [
      "self",
      "closure"
    ],
    "_get_state": [
      "self"
    ],
    "_set_state": [
      "self",
      "value"
    ],
    "state": [],
    "save_parameter_state": [
      "self",
      "filename"
    ],
    "load_parameter_state": [
      "self",
      "filename"
    ],
    "_get_param_groups": [
      "self"
    ],
    "_set_param_groups": [
      "self",
      "value"
    ],
    "param_groups": [],
    "disable_pre_hook": [
      "self"
    ],
    "enable_pre_hook": [
      "self"
    ]
  },
  "MegatronFusedAdam": {
    "__init__": [
      "self"
    ],
    "step": [
      "self",
      "closure",
      "grad_scaler"
    ]
  },
  "quantize_param_fragment": [
    "input_"
  ],
  "get_fp8_scale_and_amax": [
    "tensor"
  ],
  "_distributed_pgs": [],
  "create_distributed_pgs": [],
  "create_distribute_within_nodes_pgs": [],
  "MegatronDistributedFusedAdam": {
    "__init__": [
      "self",
      "params",
      "disable_distributed_parameters",
      "distribute_within_nodes",
      "distributed_size",
      "lock_timeout"
    ],
    "_broadcast_params": [
      "self"
    ],
    "_make_post_backward_hook": [
      "self",
      "param",
      "param_group_id",
      "param_id"
    ],
    "init_params": [
      "self",
      "params",
      "param_sync_dtype"
    ],
    "init_params_bucket": [
      "self",
      "params",
      "grad_sync_dtype",
      "param_sync_dtype"
    ],
    "_init_param_state": [
      "self",
      "param",
      "param_group_id",
      "param_id",
      "param_sync_dtype"
    ],
    "init_param_buffer": [
      "self"
    ],
    "try_grad_sync": [
      "self",
      "params"
    ],
    "zero_grad": [
      "self"
    ],
    "grad_norm": [
      "self",
      "parameters",
      "norm_type",
      "force"
    ],
    "_param_copy_fragments": [
      "self",
      "fragments"
    ],
    "_check_params_shard_dtypes": [
      "self",
      "params_buckets"
    ],
    "sharded_state_dict": [
      "self",
      "model_sharded_state_dict",
      "optimizer_state_dict"
    ]
  },
  "RAdam": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "_TYPECHECK_ENABLED": [],
  "_TYPECHECK_SEMANTIC_CHECK_ENABLED": [],
  "ALLOWED_TARGET_PREFIXES": [],
  "ALLOWED_NEMO_SUBMODULE_PREFIXES": [],
  "_is_target_allowed": [
    "target"
  ],
  "_validate_config_targets_recursive": [
    "config_node"
  ],
  "safe_instantiate": [
    "config"
  ],
  "is_typecheck_enabled": [],
  "is_semantic_typecheck_enabled": [],
  "TypecheckMetadata": {
    "__post_init__": [
      "self"
    ]
  },
  "Typing": {
    "input_types": [
      "self"
    ],
    "output_types": [
      "self"
    ],
    "_validate_input_types": [
      "self",
      "input_types",
      "ignore_collections"
    ],
    "_attach_and_validate_output_types": [
      "self",
      "out_objects",
      "ignore_collections",
      "output_types"
    ],
    "__check_neural_type": [
      "self",
      "obj",
      "metadata",
      "depth",
      "name"
    ],
    "__attach_neural_type": [
      "self",
      "obj",
      "metadata",
      "depth",
      "name"
    ]
  },
  "Serialization": {
    "from_config_dict": [
      "cls",
      "config",
      "trainer"
    ],
    "to_config_dict": [
      "self"
    ],
    "_inspect_signature_for_trainer": [
      "cls",
      "check_cls"
    ]
  },
  "FileIO": {
    "save_to": [
      "self",
      "save_path"
    ],
    "restore_from": [
      "cls",
      "restore_path",
      "override_config_path",
      "map_location",
      "strict",
      "return_config",
      "trainer",
      "save_restore_connector"
    ],
    "from_config_file": [
      "cls",
      "path2yaml_file"
    ],
    "to_config_file": [
      "self",
      "path2yaml_file"
    ]
  },
  "PretrainedModelInfo": {
    "__repr__": [
      "self"
    ],
    "__hash__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__lt__": [
      "self",
      "other"
    ]
  },
  "typecheck": {
    "__init__": [
      "self",
      "input_types",
      "output_types",
      "ignore_collections"
    ],
    "__call__": [
      "self",
      "wrapped"
    ],
    "unwrapped_call": [
      "self",
      "wrapped"
    ],
    "wrapped_call": [
      "self",
      "wrapped",
      "instance",
      "args",
      "kwargs"
    ],
    "set_typecheck_enabled": [
      "enabled"
    ],
    "disable_checks": [],
    "set_semantic_check_enabled": [
      "enabled"
    ],
    "disable_semantic_checks": [],
    "enable_wrapping": [
      "enabled"
    ]
  },
  "Loss": {
    "__init__": [
      "self"
    ]
  },
  "ModelPT": {
    "__init__": [
      "self",
      "cfg",
      "trainer"
    ],
    "__init_subclass__": [
      "cls"
    ],
    "on_fit_start": [
      "self"
    ],
    "register_artifact": [
      "self",
      "config_path",
      "src",
      "verify_src_exists"
    ],
    "has_artifacts": [
      "self"
    ],
    "has_native_or_submodules_artifacts": [
      "self"
    ],
    "has_nemo_submodules": [
      "self"
    ],
    "register_nemo_submodule": [
      "self",
      "name",
      "config_field",
      "model"
    ],
    "named_nemo_modules": [
      "self",
      "prefix_name",
      "prefix_config"
    ],
    "save_to": [
      "self",
      "save_path"
    ],
    "restore_from": [
      "cls",
      "restore_path",
      "override_config_path",
      "map_location",
      "strict",
      "return_config",
      "save_restore_connector",
      "trainer",
      "validate_access_integrity"
    ],
    "load_from_checkpoint": [
      "cls",
      "checkpoint_path"
    ],
    "setup_training_data": [
      "self",
      "train_data_config"
    ],
    "setup_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_test_data": [
      "self",
      "test_data_config"
    ],
    "setup_multiple_validation_data": [
      "self",
      "val_data_config"
    ],
    "setup_multiple_test_data": [
      "self",
      "test_data_config"
    ],
    "setup_megatron_optimization": [
      "self",
      "optim_config"
    ],
    "setup_optimization": [
      "self",
      "optim_config",
      "optim_kwargs"
    ],
    "setup_optimizer_param_groups": [
      "self"
    ],
    "configure_optimizers": [
      "self"
    ],
    "propagate_model_guid": [
      "self"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "on_validation_epoch_end": [
      "self",
      "sync_metrics"
    ],
    "on_test_epoch_end": [
      "self"
    ],
    "multi_validation_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "multi_test_epoch_end": [
      "self",
      "outputs",
      "dataloader_idx"
    ],
    "get_validation_dataloader_prefix": [
      "self",
      "dataloader_idx"
    ],
    "get_test_dataloader_prefix": [
      "self",
      "dataloader_idx"
    ],
    "load_part_of_state_dict": [
      "self",
      "state_dict",
      "include",
      "exclude",
      "load_from_string"
    ],
    "maybe_init_from_pretrained_checkpoint": [
      "self",
      "cfg",
      "map_location"
    ],
    "teardown": [
      "self",
      "stage"
    ],
    "extract_state_dict_from": [
      "cls",
      "restore_path",
      "save_dir",
      "split_by_module",
      "save_restore_connector"
    ],
    "prepare_test": [
      "self",
      "trainer"
    ],
    "set_trainer": [
      "self",
      "trainer"
    ],
    "set_world_size": [
      "self",
      "trainer"
    ],
    "summarize": [
      "self",
      "max_depth"
    ],
    "_update_dataset_config": [
      "self",
      "dataset_name",
      "config"
    ],
    "num_weights": [
      "self"
    ],
    "cfg": [
      "self",
      "cfg"
    ],
    "trainer": [
      "self"
    ],
    "hparams": [
      "self"
    ],
    "validation_step_outputs": [
      "self",
      "value"
    ],
    "test_step_outputs": [
      "self",
      "value"
    ],
    "_is_model_being_restored": [],
    "_set_model_restore_state": [
      "is_being_restored",
      "folder"
    ],
    "_set_model_guid": [
      "self"
    ],
    "update_save_restore_connector": [
      "cls",
      "save_restore_connector"
    ],
    "_setup_chakra_profiling": [
      "self"
    ],
    "_setup_profiling": [
      "self"
    ],
    "on_train_start": [
      "self"
    ],
    "on_train_batch_start": [
      "self",
      "batch",
      "batch_idx",
      "unused"
    ],
    "on_train_batch_end": [
      "self",
      "outputs",
      "batch",
      "batch_idx",
      "unused"
    ],
    "_cleanup_on_execution_end": [
      "self"
    ],
    "on_train_end": [
      "self"
    ],
    "on_test_end": [
      "self"
    ],
    "on_predict_end": [
      "self"
    ],
    "_optim_config_copy": [
      "self",
      "optim_config"
    ]
  },
  "NeuralModule": {
    "num_weights": [
      "self"
    ],
    "_num_weights": [
      "self"
    ],
    "input_example": [
      "self",
      "max_batch",
      "max_dim"
    ],
    "freeze": [
      "self"
    ],
    "unfreeze": [
      "self",
      "partial"
    ],
    "as_frozen": [
      "self"
    ]
  },
  "Dataset": {
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "IterableDataset": {
    "_collate_fn": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "DatasetConfig": {},
  "Exportable": {
    "input_module": [
      "self"
    ],
    "output_module": [
      "self"
    ],
    "export": [
      "self",
      "output",
      "input_example",
      "verbose",
      "do_constant_folding",
      "onnx_opset_version",
      "check_trace",
      "dynamic_axes",
      "check_tolerance",
      "export_modules_as_functions",
      "keep_initializers_as_inputs",
      "use_dynamo"
    ],
    "_export": [
      "self",
      "output",
      "input_example",
      "verbose",
      "do_constant_folding",
      "onnx_opset_version",
      "check_trace",
      "dynamic_axes",
      "check_tolerance",
      "export_modules_as_functions",
      "keep_initializers_as_inputs",
      "use_dynamo"
    ],
    "disabled_deployment_input_names": [
      "self"
    ],
    "disabled_deployment_output_names": [
      "self"
    ],
    "supported_export_formats": [
      "self"
    ],
    "_prepare_for_export": [
      "self"
    ],
    "_export_teardown": [
      "self"
    ],
    "input_names": [
      "self"
    ],
    "output_names": [
      "self"
    ],
    "input_types_for_export": [
      "self"
    ],
    "output_types_for_export": [
      "self"
    ],
    "dynamic_shapes_for_export": [
      "self",
      "use_dynamo"
    ],
    "get_export_subnet": [
      "self",
      "subnet"
    ],
    "list_export_subnets": [
      "self"
    ],
    "get_export_config": [
      "self"
    ],
    "set_export_config": [
      "self",
      "args"
    ]
  },
  "ADAPTER_REGISTRY": [],
  "AdapterRegistryInfo": {
    "__post_init__": [
      "self"
    ]
  },
  "AdapterConfig": {},
  "register_adapter": [
    "base_class",
    "adapter_class"
  ],
  "get_registered_adapter": [
    "cls"
  ],
  "_prepare_default_adapter_config": [],
  "update_module_class_with_adapter_class": [
    "module",
    "cfg",
    "update_config",
    "verbose"
  ],
  "AdapterModuleMixin": {
    "adapter_global_cfg_key": [],
    "adapter_metadata_cfg_key": [],
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "is_adapter_available": [
      "self"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "get_adapter_module": [
      "self",
      "name"
    ],
    "get_adapter_cfg": [
      "self",
      "name"
    ],
    "set_accepted_adapter_types": [
      "self",
      "adapter_types"
    ],
    "get_accepted_adapter_types": [
      "self"
    ],
    "unfreeze_enabled_adapters": [
      "self",
      "freeze_batchnorm"
    ],
    "forward_enabled_adapters": [
      "self",
      "input"
    ],
    "resolve_adapter_module_name_": [
      "self",
      "name"
    ],
    "forward_single_enabled_adapter_": [
      "self",
      "input",
      "adapter_module"
    ],
    "check_supported_adapter_type_": [
      "self",
      "adapter_cfg",
      "supported_adapter_types"
    ]
  },
  "AdapterModelPTMixin": {
    "setup_adapters": [
      "self"
    ],
    "add_adapter": [
      "self",
      "name",
      "cfg"
    ],
    "is_adapter_available": [
      "self"
    ],
    "set_enabled_adapters": [
      "self",
      "name",
      "enabled"
    ],
    "get_enabled_adapters": [
      "self"
    ],
    "check_valid_model_with_adapter_support_": [
      "self"
    ],
    "save_adapters": [
      "self",
      "filepath",
      "name"
    ],
    "load_adapters": [
      "self",
      "filepath",
      "name",
      "map_location",
      "strict"
    ],
    "update_adapter_cfg": [
      "self",
      "cfg"
    ],
    "replace_adapter_compatible_modules": [
      "self",
      "update_config",
      "verbose"
    ],
    "adapter_module_names": [
      "self"
    ],
    "default_adapter_module_name": [
      "self"
    ]
  },
  "AbstractAdapterStrategy": {
    "forward": [
      "self",
      "input",
      "adapter"
    ],
    "__call__": [
      "self"
    ]
  },
  "ReturnResultAdapterStrategy": {
    "forward": [
      "self",
      "input",
      "adapter"
    ],
    "compute_output": [
      "self",
      "input",
      "adapter"
    ]
  },
  "ReturnResultAdapterStrategyConfig": {},
  "ResidualAddAdapterStrategy": {
    "__init__": [
      "self",
      "stochastic_depth",
      "l2_lambda"
    ],
    "forward": [
      "self",
      "input",
      "adapter"
    ],
    "compute_output": [
      "self",
      "input",
      "adapter"
    ],
    "apply_stochastic_depth": [
      "self",
      "output",
      "input",
      "adapter"
    ],
    "compute_auxiliary_losses": [
      "self",
      "output",
      "input",
      "adapter"
    ]
  },
  "ResidualAddAdapterStrategyConfig": {},
  "HuggingFaceFileIO": {
    "get_hf_model_filter": [
      "cls"
    ],
    "search_huggingface_models": [
      "cls",
      "model_filter"
    ],
    "push_to_hf_hub": [
      "self",
      "repo_id"
    ],
    "_get_hf_model_card": [
      "self",
      "template",
      "template_kwargs"
    ]
  },
  "_DEFAULT_ACCESS_GUID": [],
  "_ACCESS_CFG": [],
  "_ACCESS_ENABLED": [],
  "set_access_cfg": [
    "cfg",
    "guid"
  ],
  "AccessMixin": {
    "__init__": [
      "self"
    ],
    "register_accessible_tensor": [
      "self",
      "name",
      "tensor"
    ],
    "get_module_registry": [
      "cls",
      "module"
    ],
    "reset_registry": [
      "self",
      "registry_key"
    ],
    "access_cfg": [
      "self"
    ],
    "update_access_cfg": [
      "cls",
      "cfg",
      "guid"
    ],
    "is_access_enabled": [
      "cls",
      "guid"
    ],
    "set_access_enabled": [
      "cls",
      "access_enabled",
      "guid"
    ]
  },
  "SaveRestoreConnector": {
    "__init__": [
      "self"
    ],
    "save_to": [
      "self",
      "model",
      "save_path"
    ],
    "load_config_and_state_dict": [
      "self",
      "calling_cls",
      "restore_path",
      "override_config_path",
      "map_location",
      "strict",
      "return_config",
      "trainer",
      "validate_access_integrity"
    ],
    "modify_state_dict": [
      "self",
      "conf",
      "state_dict"
    ],
    "load_instance_with_state_dict": [
      "self",
      "instance",
      "state_dict",
      "strict"
    ],
    "restore_from": [
      "self",
      "calling_cls",
      "restore_path",
      "override_config_path",
      "map_location",
      "strict",
      "return_config",
      "trainer",
      "validate_access_integrity"
    ],
    "extract_state_dict_from": [
      "self",
      "restore_path",
      "save_dir",
      "split_by_module"
    ],
    "register_artifact": [
      "self",
      "model",
      "config_path",
      "src",
      "verify_src_exists"
    ],
    "_handle_artifacts": [
      "self",
      "model",
      "nemo_file_folder"
    ],
    "_update_subconfigs": [
      "model",
      "path2yaml_file"
    ],
    "_update_artifact_paths": [
      "self",
      "model",
      "path2yaml_file"
    ],
    "_inject_model_parallel_rank_for_ckpt": [
      "self",
      "dirname",
      "basename"
    ],
    "_make_nemo_file_from_folder": [
      "filename",
      "source_dir"
    ],
    "_make_nemo_file_from_folder_with_multistorageclient": [
      "filename",
      "source_dir"
    ],
    "_is_safe_path": [
      "member",
      "extract_to"
    ],
    "_safe_extract": [
      "tar",
      "out_folder",
      "members"
    ],
    "_filtered_tar_info": [
      "tar_path",
      "filter_fn"
    ],
    "_filtered_recursive_walk": [
      "path",
      "filter_fn"
    ],
    "_tar_open": [
      "path2file"
    ],
    "_unpack_nemo_file": [
      "path2file",
      "out_folder",
      "members"
    ],
    "_unpack_nemo_file_with_multistorageclient": [
      "path2file",
      "out_folder",
      "members"
    ],
    "_save_state_dict_to_disk": [
      "state_dict",
      "filepath"
    ],
    "_load_state_dict_from_disk": [
      "model_weights",
      "map_location"
    ],
    "model_config_yaml": [
      "self",
      "path"
    ],
    "model_weights_ckpt": [
      "self",
      "path"
    ],
    "model_extracted_dir": [
      "self",
      "path"
    ],
    "pack_nemo_file": [
      "self",
      "save_nemo_file"
    ]
  }
}