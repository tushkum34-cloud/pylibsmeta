{
  "ValidationError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "GenerationError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "OverloadedError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "IncompleteGenerationError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "BadRequestError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "ShardNotReadyError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "ShardTimeoutError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "NotFoundError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "RateLimitExceededError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "NotSupportedError": {
    "__init__": [
      "self",
      "model_id"
    ]
  },
  "UnknownError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "parse_error": [
    "status_code",
    "payload"
  ],
  "__version__": [],
  "INFERENCE_ENDPOINT": [],
  "deployed_models": [
    "headers"
  ],
  "check_model_support": [
    "repo_id",
    "headers"
  ],
  "InferenceAPIClient": {
    "__init__": [
      "self",
      "repo_id",
      "token",
      "timeout"
    ]
  },
  "InferenceAPIAsyncClient": {
    "__init__": [
      "self",
      "repo_id",
      "token",
      "timeout"
    ]
  },
  "Client": {
    "__init__": [
      "self",
      "base_url",
      "headers",
      "cookies",
      "timeout"
    ],
    "chat": [
      "self",
      "messages",
      "repetition_penalty",
      "frequency_penalty",
      "logit_bias",
      "logprobs",
      "top_logprobs",
      "max_tokens",
      "n",
      "presence_penalty",
      "stream",
      "seed",
      "temperature",
      "top_p",
      "tools",
      "tool_choice"
    ],
    "_chat_stream_response": [
      "self",
      "request"
    ],
    "generate": [
      "self",
      "prompt",
      "do_sample",
      "max_new_tokens",
      "best_of",
      "repetition_penalty",
      "frequency_penalty",
      "return_full_text",
      "seed",
      "stop_sequences",
      "temperature",
      "top_k",
      "top_p",
      "truncate",
      "typical_p",
      "watermark",
      "decoder_input_details",
      "top_n_tokens",
      "grammar"
    ],
    "generate_stream": [
      "self",
      "prompt",
      "do_sample",
      "max_new_tokens",
      "repetition_penalty",
      "frequency_penalty",
      "return_full_text",
      "seed",
      "stop_sequences",
      "temperature",
      "top_k",
      "top_p",
      "truncate",
      "typical_p",
      "watermark",
      "top_n_tokens",
      "grammar"
    ]
  },
  "AsyncClient": {
    "__init__": [
      "self",
      "base_url",
      "headers",
      "cookies",
      "timeout"
    ],
    "chat": [
      "self",
      "messages",
      "repetition_penalty",
      "frequency_penalty",
      "logit_bias",
      "logprobs",
      "top_logprobs",
      "max_tokens",
      "n",
      "presence_penalty",
      "stream",
      "seed",
      "temperature",
      "top_p",
      "tools",
      "tool_choice"
    ],
    "_chat_single_response": [
      "self",
      "request"
    ],
    "_chat_stream_response": [
      "self",
      "request"
    ],
    "generate": [
      "self",
      "prompt",
      "do_sample",
      "max_new_tokens",
      "best_of",
      "repetition_penalty",
      "frequency_penalty",
      "return_full_text",
      "seed",
      "stop_sequences",
      "temperature",
      "top_k",
      "top_p",
      "truncate",
      "typical_p",
      "watermark",
      "decoder_input_details",
      "top_n_tokens",
      "grammar"
    ],
    "generate_stream": [
      "self",
      "prompt",
      "do_sample",
      "max_new_tokens",
      "repetition_penalty",
      "frequency_penalty",
      "return_full_text",
      "seed",
      "stop_sequences",
      "temperature",
      "top_k",
      "top_p",
      "truncate",
      "typical_p",
      "watermark",
      "top_n_tokens",
      "grammar"
    ]
  },
  "GrammarType": {
    "Json": [],
    "Regex": []
  },
  "Grammar": {},
  "ToolCall": {},
  "Message": {},
  "Tool": {},
  "ChatCompletionComplete": {},
  "Function": {},
  "ChoiceDeltaToolCall": {},
  "ChoiceDelta": {},
  "Choice": {},
  "ChatCompletionChunk": {},
  "ChatComplete": {},
  "ChatRequest": {},
  "Parameters": {
    "valid_best_of": [
      "cls",
      "field_value",
      "values"
    ],
    "valid_repetition_penalty": [
      "cls",
      "v"
    ],
    "valid_frequency_penalty": [
      "cls",
      "v"
    ],
    "valid_seed": [
      "cls",
      "v"
    ],
    "valid_temp": [
      "cls",
      "v"
    ],
    "valid_top_k": [
      "cls",
      "v"
    ],
    "valid_top_p": [
      "cls",
      "v"
    ],
    "valid_truncate": [
      "cls",
      "v"
    ],
    "valid_typical_p": [
      "cls",
      "v"
    ],
    "valid_top_n_tokens": [
      "cls",
      "v"
    ],
    "valid_grammar": [
      "cls",
      "v"
    ]
  },
  "Request": {
    "valid_input": [
      "cls",
      "v"
    ],
    "valid_best_of_stream": [
      "cls",
      "field_value",
      "values"
    ]
  },
  "InputToken": {},
  "Token": {},
  "FinishReason": {
    "Length": [],
    "EndOfSequenceToken": [],
    "StopSequence": []
  },
  "BestOfSequence": {},
  "Details": {},
  "Response": {},
  "StreamDetails": {},
  "StreamResponse": {},
  "DeployedModel": {}
}