{
  "__path__": [],
  "logger": [],
  "APPLICATION_X_NPY": [],
  "InvokeEndpointOutput": {
    "__init__": [
      "self",
      "body",
      "content_type"
    ]
  },
  "LocalEndpoint": {
    "__init__": [
      "self",
      "endpoint_name",
      "endpoint_config_name",
      "local_session",
      "local_model",
      "in_process_mode",
      "local_container_mode_obj",
      "in_process_mode_obj",
      "model_server",
      "secret_key",
      "serializer",
      "deserializer",
      "container_config"
    ],
    "endpoint_status": [
      "self"
    ],
    "_universal_deep_ping": [
      "self"
    ],
    "invoke": [
      "self",
      "body",
      "content_type",
      "accept"
    ],
    "create": [
      "cls",
      "endpoint_name",
      "endpoint_config_name",
      "local_model",
      "local_session",
      "in_process_mode",
      "local_container_mode_obj",
      "in_process_mode_obj",
      "model_server",
      "secret_key",
      "serializer",
      "deserializer",
      "container_config"
    ],
    "get": [
      "cls",
      "endpoint_name",
      "local_session"
    ],
    "refresh": [
      "self"
    ],
    "delete": [
      "self"
    ],
    "update": [
      "self",
      "endpoint_config_name"
    ]
  },
  "LocalEndpointConfig": {
    "__init__": [
      "self",
      "endpoint_config_name",
      "production_variants",
      "local_session"
    ],
    "create": [
      "cls",
      "endpoint_config_name",
      "production_variants",
      "local_session"
    ],
    "delete": [
      "self"
    ]
  },
  "_get_container_config": [
    "config"
  ],
  "EndpointDeploymentProgress": {
    "__init__": [
      "self",
      "endpoint_name"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "log": [
      "self",
      "message"
    ],
    "update_status": [
      "self",
      "status"
    ]
  },
  "_deploy_done_with_progress": [
    "sagemaker_client",
    "endpoint_name",
    "progress_tracker"
  ],
  "_live_logging_deploy_done_with_progress": [
    "sagemaker_client",
    "endpoint_name",
    "paginator",
    "paginator_config",
    "poll",
    "progress_tracker"
  ],
  "Network": {},
  "Compute": {},
  "__all__": [],
  "BedrockModelBuilder": {
    "__init__": [
      "self",
      "model"
    ],
    "_get_bedrock_client": [
      "self"
    ],
    "_get_sagemaker_client": [
      "self"
    ],
    "deploy": [
      "self",
      "job_name",
      "imported_model_name",
      "custom_model_name",
      "role_arn",
      "job_tags",
      "imported_model_tags",
      "model_tags",
      "client_request_token",
      "imported_model_kms_key_id"
    ],
    "_fetch_model_package": [
      "self"
    ],
    "_get_s3_artifacts": [
      "self"
    ],
    "_get_checkpoint_uri_from_manifest": [
      "self"
    ]
  },
  "INFERENCE_RECOMMENDER_FRAMEWORK_MAPPING": [],
  "LOGGER": [],
  "Phase": {
    "__init__": [
      "self",
      "duration_in_seconds",
      "initial_number_of_users",
      "spawn_rate"
    ]
  },
  "ModelLatencyThreshold": {
    "__init__": [
      "self",
      "percentile",
      "value_in_milliseconds"
    ]
  },
  "_InferenceRecommenderMixin": {
    "right_size": [
      "self",
      "sample_payload_url",
      "supported_content_types",
      "supported_instance_types",
      "job_name",
      "framework",
      "framework_version",
      "job_duration_in_seconds",
      "hyperparameter_ranges",
      "phases",
      "traffic_type",
      "max_invocations",
      "model_latency_thresholds",
      "max_tests",
      "max_parallel_tests",
      "log_level"
    ],
    "_update_params": [
      "self"
    ],
    "_update_params_for_right_size": [
      "self",
      "instance_type",
      "initial_instance_count",
      "accelerator_type",
      "serverless_inference_config",
      "async_inference_config",
      "explainer_config"
    ],
    "_update_params_for_recommendation_id": [
      "self",
      "instance_type",
      "initial_instance_count",
      "accelerator_type",
      "async_inference_config",
      "serverless_inference_config",
      "inference_recommendation_id",
      "explainer_config"
    ],
    "_convert_to_endpoint_configurations_json": [
      "self",
      "hyperparameter_ranges"
    ],
    "_convert_to_traffic_pattern_json": [
      "self",
      "traffic_type",
      "phases"
    ],
    "_convert_to_resource_limit_json": [
      "self",
      "max_tests",
      "max_parallel_tests"
    ],
    "_convert_to_stopping_conditions_json": [
      "self",
      "max_invocations",
      "model_latency_thresholds"
    ],
    "_get_recommendation": [
      "self",
      "sage_client",
      "job_or_model_name",
      "inference_recommendation_id"
    ],
    "_get_right_size_recommendation": [
      "self",
      "sage_client",
      "job_or_model_name",
      "inference_recommendation_id"
    ],
    "_get_model_recommendation": [
      "self",
      "sage_client",
      "job_or_model_name",
      "inference_recommendation_id"
    ],
    "_search_recommendation": [
      "self",
      "recommendation_list",
      "inference_recommendation_id"
    ],
    "_filter_recommendations_for_realtime": [
      "self"
    ]
  },
  "SPECULATIVE_DRAFT_MODEL": [],
  "_DJL_MODEL_BUILDER_ENTRY_POINT": [],
  "_NO_JS_MODEL_EX": [],
  "_JS_SCOPE": [],
  "_CODE_FOLDER": [],
  "_JS_MINIMUM_VERSION_IMAGE": [],
  "_INVALID_DJL_SAMPLE_DATA_EX": [],
  "_INVALID_TGI_SAMPLE_DATA_EX": [],
  "SUPPORTED_TRITON_MODE": [],
  "SUPPORTED_TRITON_FRAMEWORK": [],
  "INPUT_NAME": [],
  "OUTPUT_NAME": [],
  "TRITON_IMAGE_ACCOUNT_ID_MAP": [],
  "GPU_INSTANCE_FAMILIES": [],
  "TRITON_IMAGE_BASE": [],
  "LATEST_VERSION": [],
  "VERSION_FOR_TF1": [],
  "TritonSerializer": {
    "__init__": [
      "self",
      "input_serializer",
      "dtype",
      "content_type"
    ],
    "serialize": [
      "self",
      "data"
    ]
  },
  "_ModelBuilderUtils": {
    "_init_sagemaker_session_if_does_not_exist": [
      "self",
      "instance_type"
    ],
    "_get_jumpstart_recommended_instance_type": [
      "self"
    ],
    "_get_default_instance_type": [
      "self"
    ],
    "_auto_detect_container_default": [
      "self"
    ],
    "_get_smd_image_uri": [
      "self",
      "processing_unit"
    ],
    "_is_huggingface_model": [
      "self"
    ],
    "_get_supported_version": [
      "self",
      "hf_config",
      "hugging_face_version",
      "base_fw"
    ],
    "_get_hf_framework_versions": [
      "self",
      "model_id",
      "hf_token"
    ],
    "_detect_jumpstart_image": [
      "self"
    ],
    "_detect_huggingface_image": [
      "self"
    ],
    "_detect_model_object_image": [
      "self"
    ],
    "_auto_detect_image_uri": [
      "self"
    ],
    "_use_jumpstart_equivalent": [
      "self"
    ],
    "_hf_schema_builder_init": [
      "self",
      "model_task"
    ],
    "_retrieve_hugging_face_model_mapping": [
      "self"
    ],
    "_prepare_hf_model_for_upload": [
      "self"
    ],
    "_get_processing_unit": [
      "self"
    ],
    "_get_inference_component_resource_requirements": [
      "self",
      "mb"
    ],
    "_can_fit_on_single_gpu": [
      "self"
    ],
    "_extract_framework_from_image_uri": [
      "self"
    ],
    "_fetch_serializer_and_deserializer_for_framework": [
      "self",
      "framework"
    ],
    "_normalize_framework_to_enum": [
      "self",
      "framework"
    ],
    "_handle_mlflow_input": [
      "self"
    ],
    "_has_mlflow_arguments": [
      "self"
    ],
    "_get_artifact_path": [
      "self",
      "mlflow_model_path"
    ],
    "_mlflow_metadata_exists": [
      "self",
      "path"
    ],
    "_initialize_for_mlflow": [
      "self",
      "artifact_path"
    ],
    "_is_inferentia_or_trainium": [
      "self",
      "instance_type"
    ],
    "_is_image_compatible_with_optimization_job": [
      "self",
      "image_uri"
    ],
    "_deployment_config_contains_draft_model": [
      "self",
      "deployment_config"
    ],
    "_is_draft_model_jumpstart_provided": [
      "self",
      "deployment_config"
    ],
    "_generate_optimized_model": [
      "self",
      "optimization_response"
    ],
    "_is_optimized": [
      "self"
    ],
    "_generate_model_source": [
      "self",
      "model_data",
      "accept_eula"
    ],
    "_update_environment_variables": [
      "self",
      "env",
      "new_env"
    ],
    "_extract_speculative_draft_model_provider": [
      "self",
      "speculative_decoding_config"
    ],
    "_extract_additional_model_data_source_s3_uri": [
      "self",
      "additional_model_data_source"
    ],
    "_extract_deployment_config_additional_model_data_source_s3_uri": [
      "self",
      "additional_model_data_source"
    ],
    "_is_draft_model_gated": [
      "self",
      "draft_model_config"
    ],
    "_extracts_and_validates_speculative_model_source": [
      "self",
      "speculative_decoding_config"
    ],
    "_generate_channel_name": [
      "self",
      "additional_model_data_sources"
    ],
    "_generate_additional_model_data_sources": [
      "self",
      "model_source",
      "channel_name",
      "accept_eula",
      "s3_data_type",
      "compression_type"
    ],
    "_is_s3_uri": [
      "self",
      "s3_uri"
    ],
    "_extract_optimization_config_and_env": [
      "self",
      "quantization_config",
      "compilation_config",
      "sharding_config"
    ],
    "_custom_speculative_decoding": [
      "self",
      "speculative_decoding_config",
      "accept_eula"
    ],
    "_get_cached_model_specs": [
      "self",
      "model_id",
      "version",
      "region",
      "sagemaker_session"
    ],
    "_jumpstart_speculative_decoding": [
      "self",
      "speculative_decoding_config",
      "sagemaker_session"
    ],
    "_optimize_for_hf": [
      "self",
      "output_path",
      "tags",
      "job_name",
      "quantization_config",
      "compilation_config",
      "speculative_decoding_config",
      "sharding_config",
      "env_vars",
      "vpc_config",
      "kms_key",
      "max_runtime_in_sec"
    ],
    "_optimize_prepare_for_hf": [
      "self"
    ],
    "_is_gated_model": [
      "self"
    ],
    "set_js_deployment_config": [
      "self",
      "config_name",
      "instance_type"
    ],
    "_set_additional_model_source": [
      "self",
      "speculative_decoding_config"
    ],
    "_find_compatible_deployment_config": [
      "self",
      "speculative_decoding_config"
    ],
    "_get_neuron_model_env_vars": [
      "self",
      "instance_type"
    ],
    "_set_optimization_image_default": [
      "self",
      "create_optimization_job_args"
    ],
    "_get_default_vllm_image": [
      "self",
      "image"
    ],
    "_get_latest_lmi_version_from_list": [
      "self",
      "version",
      "version_to_compare"
    ],
    "_parse_lmi_version": [
      "self",
      "image"
    ],
    "_optimize_for_jumpstart": [
      "self",
      "output_path",
      "instance_type",
      "tags",
      "job_name",
      "accept_eula",
      "quantization_config",
      "compilation_config",
      "speculative_decoding_config",
      "sharding_config",
      "env_vars",
      "vpc_config",
      "kms_key",
      "max_runtime_in_sec"
    ],
    "_generate_optimized_core_model": [
      "self",
      "optimization_response"
    ],
    "deployment_config_response_data": [
      "self",
      "deployment_configs"
    ],
    "_get_deployment_configs_benchmarks_data": [
      "self"
    ],
    "_get_deployment_configs": [
      "self",
      "selected_config_name",
      "selected_instance_type"
    ],
    "add_tags": [
      "self",
      "tags"
    ],
    "remove_tag_with_key": [
      "self",
      "key"
    ],
    "_get_model_uri": [
      "self"
    ],
    "_ensure_base_name_if_needed": [
      "self",
      "image_uri",
      "script_uri",
      "model_uri"
    ],
    "_ensure_metadata_configs": [
      "self"
    ],
    "_user_agent_decorator": [
      "self",
      "func"
    ],
    "_get_serve_setting": [
      "self"
    ],
    "_is_jumpstart_model_id": [
      "self"
    ],
    "_has_nvidia_gpu": [
      "self"
    ],
    "_is_gpu_instance": [
      "self",
      "instance_type"
    ],
    "_save_inference_spec": [
      "self"
    ],
    "_hmac_signing": [
      "self"
    ],
    "_generate_config_pbtxt": [
      "self",
      "pkl_path"
    ],
    "_pack_conda_env": [
      "self",
      "pkl_path"
    ],
    "_export_tf_to_onnx": [
      "self",
      "export_path",
      "model",
      "schema_builder"
    ],
    "_export_pytorch_to_onnx": [
      "self",
      "model",
      "export_path",
      "schema_builder"
    ],
    "_validate_for_triton": [
      "self"
    ],
    "_prepare_for_triton": [
      "self"
    ],
    "_auto_detect_image_for_triton": [
      "self"
    ],
    "_validate_djl_serving_sample_data": [
      "self"
    ],
    "_validate_tgi_serving_sample_data": [
      "self"
    ],
    "_create_conda_env": [
      "self"
    ],
    "_extract_framework_from_model_trainer": [
      "self",
      "model_trainer"
    ],
    "_infer_model_server_from_training": [
      "self",
      "model_trainer"
    ],
    "_extract_inference_spec_from_training_code": [
      "self",
      "model_trainer"
    ],
    "_inherit_training_environment": [
      "self",
      "model_trainer"
    ],
    "_extract_version_from_training_image": [
      "self",
      "training_image"
    ],
    "_detect_inference_image_from_training": [
      "self"
    ],
    "get_huggingface_model_metadata": [
      "self",
      "model_id",
      "hf_hub_token"
    ],
    "download_huggingface_model_metadata": [
      "self",
      "model_id",
      "model_local_path",
      "hf_hub_token"
    ]
  },
  "Framework": {
    "XGBOOST": [],
    "LDA": [],
    "PYTORCH": [],
    "TENSORFLOW": [],
    "MXNET": [],
    "CHAINER": [],
    "SKLEARN": [],
    "HUGGINGFACE": [],
    "DJL": [],
    "SPARKML": [],
    "NTM": [],
    "SMD": []
  },
  "AsyncPredictor": {
    "__init__": [
      "self",
      "predictor",
      "name"
    ],
    "predict": [
      "self",
      "data",
      "input_path",
      "initial_args",
      "inference_id",
      "waiter_config"
    ],
    "predict_async": [
      "self",
      "data",
      "input_path",
      "initial_args",
      "inference_id"
    ],
    "_upload_data_to_s3": [
      "self",
      "data",
      "input_path"
    ],
    "_create_request_args": [
      "self",
      "input_path",
      "initial_args",
      "inference_id"
    ],
    "_submit_async_request": [
      "self",
      "input_path",
      "initial_args",
      "inference_id"
    ],
    "_wait_for_output": [
      "self",
      "output_path",
      "failure_path",
      "waiter_config"
    ],
    "_check_output_path": [
      "self",
      "output_path",
      "waiter_config"
    ],
    "_check_output_and_failure_paths": [
      "self",
      "output_path",
      "failure_path",
      "waiter_config"
    ],
    "update_endpoint": [
      "self",
      "initial_instance_count",
      "instance_type",
      "accelerator_type",
      "model_name",
      "tags",
      "kms_key",
      "data_capture_config_dict",
      "wait"
    ],
    "delete_endpoint": [
      "self",
      "delete_endpoint_config"
    ],
    "delete_model": [
      "self"
    ],
    "enable_data_capture": [
      "self"
    ],
    "disable_data_capture": [
      "self"
    ],
    "update_data_capture_config": [
      "self",
      "data_capture_config"
    ],
    "list_monitors": [
      "self"
    ],
    "endpoint_context": [
      "self"
    ]
  },
  "SCRIPT_PARAM_NAME": [],
  "DIR_PARAM_NAME": [],
  "CONTAINER_LOG_LEVEL_PARAM_NAME": [],
  "JOB_NAME_PARAM_NAME": [],
  "MODEL_SERVER_WORKERS_PARAM_NAME": [],
  "SAGEMAKER_REGION_PARAM_NAME": [],
  "SAGEMAKER_OUTPUT_LOCATION": [],
  "_ModelBuilderServers": {
    "_build_for_model_server": [
      "self"
    ],
    "_build_for_torchserve": [
      "self"
    ],
    "_build_for_tgi": [
      "self"
    ],
    "_build_for_djl": [
      "self"
    ],
    "_build_for_triton": [
      "self"
    ],
    "_build_for_tensorflow_serving": [
      "self"
    ],
    "_build_for_tei": [
      "self"
    ],
    "_build_for_smd": [
      "self"
    ],
    "_build_for_transformers": [
      "self"
    ],
    "_build_for_djl_jumpstart": [
      "self",
      "init_kwargs"
    ],
    "_build_for_tgi_jumpstart": [
      "self",
      "init_kwargs"
    ],
    "_build_for_mms_jumpstart": [
      "self",
      "init_kwargs"
    ],
    "_build_for_jumpstart": [
      "self"
    ],
    "_djl_model_builder_deploy_wrapper": [
      "self"
    ],
    "_tgi_model_builder_deploy_wrapper": [
      "self"
    ],
    "_tei_model_builder_deploy_wrapper": [
      "self"
    ],
    "_js_builder_deploy_wrapper": [
      "self"
    ],
    "_transformers_model_builder_deploy_wrapper": [
      "self"
    ]
  },
  "_LOWEST_MMS_VERSION": [],
  "ModelBuilder": {
    "_create_session_with_region": [
      "self"
    ],
    "__post_init__": [
      "self"
    ],
    "_warn_about_deprecated_parameters": [
      "self",
      "warnings"
    ],
    "_initialize_compute_config": [
      "self"
    ],
    "_initialize_network_config": [
      "self"
    ],
    "_initialize_defaults": [
      "self"
    ],
    "_fetch_default_instance_type_for_custom_model": [
      "self"
    ],
    "_fetch_hub_document_for_custom_model": [
      "self"
    ],
    "_fetch_hosting_configs_for_custom_model": [
      "self"
    ],
    "_get_instance_resources": [
      "self",
      "instance_type"
    ],
    "_fetch_and_cache_recipe_config": [
      "self"
    ],
    "_initialize_jumpstart_config": [
      "self"
    ],
    "_initialize_script_mode_variables": [
      "self"
    ],
    "_get_client_translators": [
      "self"
    ],
    "_save_model_inference_spec": [
      "self"
    ],
    "_prepare_for_mode": [
      "self",
      "model_path",
      "should_upload_artifacts"
    ],
    "_build_validations": [
      "self"
    ],
    "_build_for_passthrough": [
      "self"
    ],
    "_build_default_async_inference_config": [
      "self",
      "async_inference_config"
    ],
    "enable_network_isolation": [
      "self"
    ],
    "_is_model_customization": [
      "self"
    ],
    "_fetch_model_package_arn": [
      "self"
    ],
    "_fetch_model_package": [
      "self"
    ],
    "_convert_model_data_source_to_local": [
      "self",
      "model_data_source"
    ],
    "_convert_additional_sources_to_local": [
      "self",
      "additional_sources"
    ],
    "_get_source_code_env_vars": [
      "self"
    ],
    "to_string": [
      "self",
      "obj"
    ],
    "is_repack": [
      "self"
    ],
    "_upload_code": [
      "self",
      "key_prefix",
      "repack"
    ],
    "_script_mode_env_vars": [
      "self"
    ],
    "_is_mms_version": [
      "self"
    ],
    "_get_container_env": [
      "self"
    ],
    "_prepare_container_def_base": [
      "self"
    ],
    "_handle_tf_repack": [
      "self",
      "deploy_key_prefix",
      "instance_type",
      "serverless_inference_config"
    ],
    "_prepare_container_def": [
      "self"
    ],
    "_prepare_pipeline_container_defs": [
      "self"
    ],
    "_core_container_to_dict": [
      "self",
      "container"
    ],
    "_create_sagemaker_model": [
      "self"
    ],
    "_create_model": [
      "self"
    ],
    "fetch_endpoint_names_for_base_model": [
      "self"
    ],
    "_build_single_modelbuilder": [
      "self",
      "mode",
      "role_arn",
      "sagemaker_session"
    ],
    "_extract_and_extend_tags_from_model_trainer": [
      "self"
    ],
    "_deploy_local_endpoint": [
      "self"
    ],
    "_wait_for_endpoint": [
      "self",
      "endpoint",
      "poll",
      "live_logging",
      "show_progress",
      "wait"
    ],
    "_deploy_core_endpoint": [
      "self"
    ],
    "_deploy": [
      "self"
    ],
    "_get_deploy_wrapper": [
      "self"
    ],
    "_does_ic_exist": [
      "self",
      "ic_name"
    ],
    "_update_inference_component": [
      "self",
      "ic_name",
      "resource_requirements"
    ],
    "_deploy_for_ic": [
      "self",
      "ic_data",
      "endpoint_name"
    ],
    "_reset_build_state": [
      "self"
    ],
    "build": [
      "self",
      "model_name",
      "mode",
      "role_arn",
      "sagemaker_session",
      "region"
    ],
    "configure_for_torchserve": [
      "self",
      "shared_libs",
      "dependencies",
      "image_config"
    ],
    "from_jumpstart_config": [
      "cls",
      "jumpstart_config",
      "role_arn",
      "compute",
      "network",
      "image_uri",
      "env_vars",
      "model_kms_key",
      "resource_requirements",
      "tolerate_vulnerable_model",
      "tolerate_deprecated_model",
      "sagemaker_session",
      "schema_builder"
    ],
    "transformer": [
      "self",
      "instance_count",
      "instance_type",
      "strategy",
      "assemble_with",
      "output_path",
      "output_kms_key",
      "accept",
      "env",
      "max_concurrent_transforms",
      "max_payload",
      "tags",
      "volume_kms_key"
    ],
    "display_benchmark_metrics": [
      "self"
    ],
    "set_deployment_config": [
      "self",
      "config_name",
      "instance_type"
    ],
    "get_deployment_config": [
      "self"
    ],
    "list_deployment_configs": [
      "self"
    ],
    "optimize": [
      "self",
      "model_name",
      "output_path",
      "instance_type",
      "role_arn",
      "sagemaker_session",
      "region",
      "tags",
      "job_name",
      "accept_eula",
      "quantization_config",
      "compilation_config",
      "speculative_decoding_config",
      "sharding_config",
      "env_vars",
      "vpc_config",
      "kms_key",
      "image_uri",
      "max_runtime_in_sec"
    ],
    "_model_builder_optimize_wrapper": [
      "self",
      "output_path",
      "instance_type",
      "role_arn",
      "region",
      "tags",
      "job_name",
      "accept_eula",
      "quantization_config",
      "compilation_config",
      "speculative_decoding_config",
      "sharding_config",
      "env_vars",
      "vpc_config",
      "kms_key",
      "image_uri",
      "max_runtime_in_sec",
      "sagemaker_session"
    ],
    "deploy": [
      "self",
      "endpoint_name",
      "initial_instance_count",
      "instance_type",
      "wait",
      "update_endpoint",
      "container_timeout_in_seconds",
      "inference_config",
      "custom_orchestrator_instance_type",
      "custom_orchestrator_initial_instance_count"
    ],
    "_deploy_model_customization": [
      "self",
      "endpoint_name",
      "initial_instance_count",
      "inference_component_name"
    ],
    "_fetch_peft": [
      "self"
    ],
    "_does_endpoint_exist": [
      "self",
      "endpoint_name"
    ],
    "deploy_local": [
      "self",
      "endpoint_name",
      "container_timeout_in_seconds"
    ],
    "register": [
      "self",
      "model_package_name",
      "model_package_group_name",
      "content_types",
      "response_types",
      "inference_instances",
      "transform_instances",
      "model_metrics",
      "metadata_properties",
      "marketplace_cert",
      "approval_status",
      "description",
      "drift_check_baselines",
      "customer_metadata_properties",
      "validation_specification",
      "domain",
      "task",
      "sample_payload_url",
      "nearest_model_name",
      "data_input_configuration",
      "skip_model_validation",
      "source_uri",
      "model_card",
      "model_life_cycle",
      "accept_eula",
      "model_type"
    ]
  },
  "PKL_FILE_NAME": [],
  "Mode": {
    "__str__": [
      "self"
    ],
    "IN_PROCESS": [],
    "LOCAL_CONTAINER": [],
    "SAGEMAKER_ENDPOINT": []
  },
  "_PING_HEALTH_CHECK_INTERVAL_SEC": [],
  "_PING_HEALTH_CHECK_FAIL_MSG": [],
  "LocalContainerMode": {
    "__init__": [
      "self",
      "model_server",
      "inference_spec",
      "schema_builder",
      "session",
      "model_path",
      "env_vars"
    ],
    "load": [
      "self",
      "model_path"
    ],
    "prepare": [
      "self"
    ],
    "create_server": [
      "self",
      "image",
      "container_timeout_seconds",
      "secret_key",
      "container_config",
      "ping_fn",
      "env_vars",
      "model_path",
      "jumpstart"
    ],
    "destroy_server": [
      "self"
    ],
    "_pull_image": [
      "self",
      "image"
    ],
    "_is_ecr_image": [
      "self",
      "image"
    ]
  },
  "InProcessMode": {
    "__init__": [
      "self",
      "model",
      "inference_spec",
      "schema_builder",
      "session",
      "model_path",
      "env_vars"
    ],
    "load": [
      "self",
      "model_path"
    ],
    "prepare": [
      "self"
    ],
    "create_server": [
      "self",
      "ping_fn"
    ],
    "destroy_server": [
      "self"
    ]
  },
  "SageMakerEndpointMode": {
    "__init__": [
      "self",
      "inference_spec",
      "model_server"
    ],
    "load": [
      "self",
      "model_path"
    ],
    "prepare": [
      "self",
      "model_path",
      "secret_key",
      "s3_model_data_url",
      "sagemaker_session",
      "image",
      "jumpstart",
      "should_upload_artifacts"
    ]
  },
  "_get_default_model_server_for_mlflow": [
    "deployment_flavor"
  ],
  "_get_default_image_for_mlflow": [
    "python_version",
    "region",
    "instance_type"
  ],
  "_generate_mlflow_artifact_path": [
    "src_folder",
    "artifact_name"
  ],
  "_get_all_flavor_metadata": [
    "mlmodel_path"
  ],
  "_get_framework_version_from_requirements": [
    "flavor",
    "requirements_path"
  ],
  "_get_deployment_flavor": [
    "flavor_metadata"
  ],
  "_get_python_version_from_parsed_mlflow_model_file": [
    "parsed_metadata"
  ],
  "_download_s3_artifacts": [
    "s3_path",
    "dst_path",
    "session"
  ],
  "_copy_directory_contents": [
    "src_dir",
    "dest_dir"
  ],
  "_select_container_for_mlflow_model": [
    "mlflow_model_src_path",
    "deployment_flavor",
    "region",
    "instance_type"
  ],
  "_validate_input_for_mlflow": [
    "model_server",
    "deployment_flavor"
  ],
  "_get_saved_model_path_for_tensorflow_and_keras_flavor": [
    "model_path"
  ],
  "_move_contents": [
    "src_dir",
    "dest_dir"
  ],
  "DEFAULT_FW_USED_FOR_DEFAULT_IMAGE": [],
  "DEFAULT_PYTORCH_VERSION": [],
  "MODEL_PACKAGE_ARN_REGEX": [],
  "MLFLOW_RUN_ID_REGEX": [],
  "MLFLOW_REGISTRY_PATH_REGEX": [],
  "S3_PATH_REGEX": [],
  "MLFLOW_TRACKING_ARN": [],
  "MLFLOW_MODEL_PATH": [],
  "MLFLOW_METADATA_FILE": [],
  "MLFLOW_PIP_DEPENDENCY_FILE": [],
  "MLFLOW_PYFUNC": [],
  "MLFLOW_FLAVOR_TO_PYTHON_PACKAGE_MAP": [],
  "TENSORFLOW_SAVED_MODEL_NAME": [],
  "FLAVORS_WITH_FRAMEWORK_SPECIFIC_DLC_SUPPORT": [],
  "FLAVORS_DEFAULT_WITH_TF_SERVING": [],
  "CONTENT_TYPE": [],
  "ACCEPT_TYPE": [],
  "CustomPayloadTranslator": {
    "__init__": [
      "self",
      "content_type",
      "accept_type"
    ],
    "serialize_payload_to_bytes": [
      "self",
      "payload"
    ],
    "deserialize_payload_from_stream": [
      "self",
      "stream"
    ],
    "serialize": [
      "self",
      "payload",
      "content_type"
    ],
    "deserialize": [
      "self",
      "stream",
      "content_type"
    ],
    "CONTENT_TYPE": [
      "self"
    ],
    "ACCEPT": [
      "self"
    ]
  },
  "TorchTensorTranslator": {
    "__init__": [
      "self"
    ],
    "serialize": [
      "self",
      "data",
      "content_type"
    ],
    "deserialize": [
      "self",
      "data",
      "content_type"
    ],
    "_deserializer": [
      "self"
    ]
  },
  "TensorflowTensorTranslator": {
    "__init__": [
      "self"
    ],
    "serialize": [
      "self",
      "data",
      "content_type"
    ],
    "deserialize": [
      "self",
      "data",
      "content_type"
    ],
    "_deserializer": [
      "self"
    ]
  },
  "NumpyTranslator": {
    "__init__": [
      "self"
    ],
    "serialize": [
      "self",
      "data",
      "content_type"
    ],
    "deserialize": [
      "self",
      "data",
      "content_type"
    ],
    "_deserializer": [
      "self"
    ]
  },
  "ListTranslator": {
    "__init__": [
      "self"
    ],
    "serialize": [
      "self",
      "data",
      "content_type"
    ],
    "deserialize": [
      "self",
      "data",
      "content_type"
    ],
    "_deserializer": [
      "self"
    ]
  },
  "TORCH_TENSOR": [],
  "TF_TENSOR": [],
  "NUMPY_ARRAY": [],
  "PYTHON_LIST": [],
  "SUPPORTED_TYPES": [],
  "CLASS_TO_TRANSLATOR_MAP": [],
  "PYTORCH_TENSOR_TO_TRITON_DTYPE_MAP": [],
  "TENSORFLOW_TO_TRITON_DTYPE_MAP": [],
  "NUMPY_ARRAY_TRITON_DTYPE_MAP": [],
  "DEFAULT_DTYPE": [],
  "TritonSchemaBuilder": {
    "__init__": [
      "self"
    ],
    "_update_serializer_deserializer_for_triton": [
      "self"
    ],
    "_detect_class_of_sample_input_and_output": [
      "self"
    ],
    "_detect_dtype_for_triton": [
      "self"
    ],
    "_detect_dtype_for_pytorch_tensor": [
      "self",
      "data"
    ],
    "_detect_dtype_for_numpy": [
      "self",
      "data"
    ],
    "_detect_dtype_for_tensorflow": [
      "self",
      "data"
    ]
  },
  "RequirementsManager": {
    "capture_and_install_dependencies": [
      "self",
      "dependencies"
    ],
    "_install_requirements_txt": [
      "self"
    ],
    "_update_conda_env_in_path": [
      "self"
    ],
    "_get_active_conda_env_name": [
      "self"
    ],
    "_get_active_conda_env_prefix": [
      "self"
    ],
    "_detect_conda_env_and_local_dependencies": [
      "self"
    ]
  },
  "JSONSerializerWrapper": {
    "serialize": [
      "self",
      "data"
    ]
  },
  "CSVSerializerWrapper": {
    "serialize": [
      "self",
      "data"
    ]
  },
  "translation_mapping": [],
  "DeserializerWrapper": {
    "__init__": [
      "self",
      "deserializer",
      "accept"
    ],
    "deserialize": [
      "self",
      "stream",
      "content_type"
    ],
    "ACCEPT": [
      "self"
    ]
  },
  "SchemaBuilder": {
    "__init__": [
      "self",
      "sample_input",
      "sample_output",
      "input_translator",
      "output_translator"
    ],
    "_get_serializer": [
      "self",
      "obj"
    ],
    "_get_deserializer": [
      "self",
      "obj"
    ],
    "_get_inverse": [
      "self",
      "obj"
    ],
    "__repr__": [
      "self"
    ],
    "generate_marshalling_map": [
      "self"
    ],
    "get_input_sample": [
      "self"
    ]
  },
  "_is_torch_tensor": [
    "data"
  ],
  "_is_jsonable": [
    "data"
  ],
  "_is_path_to_file": [
    "data"
  ],
  "_validate_translations": [
    "payload",
    "serialize_callable",
    "deserialize_callable"
  ],
  "_ServeSettings": {
    "__init__": [
      "self",
      "role_arn",
      "s3_model_data_url",
      "instance_type",
      "env_vars",
      "sagemaker_session"
    ]
  },
  "_get_logs": [
    "generator",
    "logs",
    "until"
  ],
  "pull_logs": [
    "generator",
    "stop",
    "until",
    "final_pull"
  ],
  "retrieve_local_schemas": [
    "task"
  ],
  "MIB_CONVERSION_FACTOR": [],
  "MEMORY_BUFFER_MULTIPLIER": [],
  "_get_gpu_info": [
    "instance_type",
    "session"
  ],
  "_get_gpu_info_fallback": [
    "instance_type",
    "region"
  ],
  "_format_instance_type": [
    "instance_type"
  ],
  "_total_inference_model_size_mib": [
    "model",
    "dtype"
  ],
  "TELEMETRY_OPT_OUT_MESSAGING": [],
  "MODE_TO_CODE": [],
  "MODEL_SERVER_TO_CODE": [],
  "MLFLOW_MODEL_PATH_CODE": [],
  "MODEL_HUB_TO_CODE": [],
  "SD_DRAFT_MODEL_SOURCE_TO_CODE": [],
  "_capture_telemetry": [
    "func_name"
  ],
  "_send_telemetry": [
    "status",
    "mode",
    "session",
    "failure_reason",
    "failure_type",
    "extra_info"
  ],
  "_construct_url": [
    "accountId",
    "mode",
    "status",
    "failure_reason",
    "failure_type",
    "extra_info",
    "region"
  ],
  "_requests_helper": [
    "url",
    "timeout"
  ],
  "_get_accountId": [
    "session"
  ],
  "_get_region_or_default": [
    "session"
  ],
  "_get_image_uri_option": [
    "image_uri",
    "is_custom_image"
  ],
  "LINEAGE_POLLER_INTERVAL_SECS": [],
  "LINEAGE_POLLER_MAX_TIMEOUT_SECS": [],
  "TRACKING_SERVER_ARN_REGEX": [],
  "TRACKING_SERVER_CREATION_TIME_FORMAT": [],
  "MODEL_BUILDER_MLFLOW_MODEL_PATH_LINEAGE_ARTIFACT_TYPE": [],
  "MLFLOW_S3_PATH": [],
  "MLFLOW_MODEL_PACKAGE_PATH": [],
  "MLFLOW_RUN_ID": [],
  "MLFLOW_LOCAL_PATH": [],
  "MLFLOW_REGISTRY_PATH": [],
  "ERROR": [],
  "CODE": [],
  "CONTRIBUTED_TO": [],
  "VALIDATION_EXCEPTION": [],
  "hardware_lookup": [],
  "fallback_gpu_resource_mapping": [],
  "_get_available_gpus": [
    "log"
  ],
  "_get_nb_instance": [],
  "_get_ram_usage_mb": [],
  "_check_disk_space": [
    "model_path"
  ],
  "_check_docker_disk_usage": [],
  "BUF_SIZE": [],
  "_get_dir_size": [
    "path"
  ],
  "Uploader": {
    "__init__": [
      "self"
    ],
    "observe": [
      "self",
      "bytes_amount"
    ],
    "upload": [
      "self",
      "model_dir",
      "total_size",
      "credentials",
      "region_name",
      "bucket",
      "key"
    ],
    "upload_uncompressed": [
      "self",
      "model_dir",
      "sagemaker_session",
      "bucket",
      "key_prefix",
      "total_size"
    ]
  },
  "upload": [
    "sagemaker_session",
    "model_dir",
    "bucket",
    "key_prefix"
  ],
  "upload_uncompressed": [
    "sagemaker_session",
    "model_dir",
    "bucket",
    "key_prefix"
  ],
  "ModelBuilderException": {
    "fmt": [],
    "__init__": [
      "self"
    ]
  },
  "LocalDeepPingException": {
    "fmt": [],
    "model_builder_error_code": [],
    "__init__": [
      "self",
      "message"
    ]
  },
  "InProcessDeepPingException": {
    "fmt": [],
    "model_builder_error_code": [],
    "__init__": [
      "self",
      "message"
    ]
  },
  "LocalModelOutOfMemoryException": {
    "fmt": [],
    "model_builder_error_code": [],
    "__init__": [
      "self",
      "message"
    ]
  },
  "LocalModelLoadException": {
    "fmt": [],
    "model_builder_error_code": [],
    "__init__": [
      "self",
      "message"
    ]
  },
  "LocalModelInvocationException": {
    "fmt": [],
    "model_builder_error_code": [],
    "__init__": [
      "self",
      "message"
    ]
  },
  "SkipTuningComboException": {
    "fmt": [],
    "__init__": [
      "self",
      "message"
    ]
  },
  "TaskNotFoundException": {
    "fmt": [],
    "__init__": [
      "self",
      "message"
    ]
  },
  "ModelServer": {
    "__str__": [
      "self"
    ],
    "TORCHSERVE": [],
    "MMS": [],
    "TENSORFLOW_SERVING": [],
    "DJL_SERVING": [],
    "TRITON": [],
    "TGI": [],
    "TEI": [],
    "SMD": []
  },
  "HardwareType": {
    "__str__": [
      "self"
    ],
    "CPU": [],
    "GPU": [],
    "INFERENTIA_1": [],
    "INFERENTIA_2": [],
    "GRAVITON": []
  },
  "ImageUriOption": {
    "__str__": [
      "self"
    ],
    "CUSTOM_IMAGE": [],
    "CUSTOM_1P_IMAGE": [],
    "DEFAULT_IMAGE": []
  },
  "ModelHub": {
    "__str__": [
      "self"
    ],
    "JUMPSTART": [],
    "HUGGINGFACE": []
  },
  "SpeculativeDecodingDraftModelSource": {
    "__str__": [
      "self"
    ],
    "SAGEMAKER": [],
    "CUSTOM": []
  },
  "_load_artifact_by_source_uri": [
    "source_uri",
    "sagemaker_session",
    "source_types_to_match",
    "artifact_type"
  ],
  "_poll_lineage_artifact": [
    "s3_uri",
    "artifact_type",
    "sagemaker_session"
  ],
  "_get_mlflow_model_path_type": [
    "mlflow_model_path"
  ],
  "_create_mlflow_model_path_lineage_artifact": [
    "mlflow_model_path",
    "sagemaker_session",
    "source_types_to_match"
  ],
  "_retrieve_and_create_if_not_exist_mlflow_model_path_lineage_artifact": [
    "mlflow_model_path",
    "sagemaker_session",
    "tracking_server_arn"
  ],
  "_add_association_between_artifacts": [
    "mlflow_model_path_artifact_arn",
    "autogenerated_model_data_artifact_arn",
    "sagemaker_session"
  ],
  "_maintain_lineage_tracking_for_mlflow_model": [
    "mlflow_model_path",
    "s3_upload_path",
    "sagemaker_session",
    "tracking_server_arn"
  ],
  "package_inference_code": [],
  "_get_model_config_properties_from_hf": [
    "model_id",
    "hf_hub_token"
  ],
  "AsyncInferenceResponse": {
    "__init__": [
      "self",
      "predictor_async",
      "output_path",
      "failure_path"
    ],
    "get_result": [
      "self",
      "waiter_config"
    ],
    "_get_result_from_s3": [
      "self",
      "output_path",
      "failure_path"
    ],
    "_get_result_from_s3_output_path": [
      "self",
      "output_path"
    ],
    "_get_result_from_s3_output_failure_paths": [
      "self",
      "output_path",
      "failure_path"
    ]
  },
  "WaiterConfig": {
    "__init__": [
      "self",
      "max_attempts",
      "delay"
    ],
    "_to_request_dict": [
      "self"
    ]
  },
  "_VERSION_DETECTION_ERROR": [],
  "_CASTING_WARNING": [],
  "auto_detect_container": [
    "model",
    "region",
    "instance_type"
  ],
  "_cast_to_compatible_version": [
    "framework",
    "fw_version"
  ],
  "_process_version": [
    "ver"
  ],
  "_later_version": [
    "current",
    "found"
  ],
  "_find_compatible_vs": [
    "split_vs",
    "supported_vs"
  ],
  "_detect_framework_and_version": [
    "model_base"
  ],
  "_get_model_base": [
    "model"
  ],
  "pipcmd": [],
  "get_all_files_for_installed_packages_pip": [
    "packages"
  ],
  "get_all_files_for_installed_packages": [
    "packages"
  ],
  "batched": [
    "iterable",
    "n"
  ],
  "get_all_installed_packages": [],
  "map_package_names_to_files": [
    "package_names"
  ],
  "get_currently_used_packages": [],
  "get_requirements_for_pkl_file": [
    "pkl_path",
    "dest"
  ],
  "get_all_requirements": [
    "dest"
  ],
  "save_pkl": [
    "save_path",
    "obj"
  ],
  "save_xgboost": [
    "save_path",
    "xgb_model"
  ],
  "save_sklearn": [
    "model_path",
    "model"
  ],
  "load_xgboost_from_json": [
    "model_save_path",
    "class_name"
  ],
  "_get_class_from_name": [
    "class_name"
  ],
  "_SUPPORTED_SUFFIXES": [],
  "capture_dependencies": [
    "dependencies",
    "work_dir",
    "capture_all"
  ],
  "_process_custom_dependencies": [
    "custom_dependencies",
    "module_version_dict"
  ],
  "_process_customer_provided_requirements": [
    "requirements_file",
    "module_version_dict"
  ],
  "_is_valid_requirement_file": [
    "path"
  ],
  "_parse_dependency_list": [
    "depedency_list"
  ],
  "TRITON_MODEL_DIR": [],
  "TritonPythonModel": {
    "auto_complete_config": [
      "auto_complete_model_config"
    ],
    "initialize": [
      "self",
      "args"
    ],
    "execute": [
      "self",
      "requests"
    ]
  },
  "_run_preflight_diagnostics": [],
  "_py_vs_parity_check": [],
  "_pickle_file_integrity_check": [],
  "_SHM_SIZE": [],
  "LocalTritonServer": {
    "__init__": [
      "self"
    ],
    "_start_triton_server": [
      "self",
      "docker_client",
      "model_path",
      "secret_key",
      "image_uri",
      "env_vars"
    ],
    "_invoke_triton_server": [
      "self",
      "payload"
    ]
  },
  "SageMakerTritonServer": {
    "__init__": [
      "self"
    ],
    "_upload_triton_artifacts": [
      "self",
      "model_path",
      "sagemaker_session",
      "secret_key",
      "s3_model_data_url",
      "image",
      "should_upload_artifacts"
    ]
  },
  "CONFIG_TEMPLATE": [],
  "_get_default_dtype": [],
  "_get_default_tgi_configurations": [
    "model_id",
    "hf_model_config",
    "schema_builder"
  ],
  "_get_admissible_dtypes": [],
  "MODE_DIR_BINDING": [],
  "_DEFAULT_ENV_VARS": [],
  "LocalTgiServing": {
    "_start_tgi_serving": [
      "self",
      "client",
      "image",
      "model_path",
      "secret_key",
      "env_vars",
      "jumpstart"
    ],
    "_invoke_tgi_serving": [
      "self",
      "request",
      "content_type",
      "accept"
    ]
  },
  "SageMakerTgiServing": {
    "_upload_tgi_artifacts": [
      "self",
      "model_path",
      "sagemaker_session",
      "jumpstart",
      "s3_model_data_url",
      "image",
      "env_vars",
      "should_upload_artifacts"
    ]
  },
  "_update_env_vars": [
    "env_vars"
  ],
  "_extract_js_resource": [
    "js_model_dir",
    "code_dir",
    "js_id"
  ],
  "_copy_jumpstart_artifacts": [
    "model_data",
    "js_id",
    "code_dir"
  ],
  "_create_dir_structure": [
    "model_path"
  ],
  "prepare_tgi_js_resources": [
    "model_path",
    "js_id",
    "shared_libs",
    "dependencies",
    "model_data"
  ],
  "ATTENTION_HEAD_NAME_VARIENTS": [],
  "CHARS_PER_TOKEN": [],
  "TOKENS_PER_WORD": [],
  "_get_default_tensor_parallel_degree": [
    "hf_model_config",
    "gpu_count"
  ],
  "_get_default_data_type": [],
  "_get_default_batch_size": [],
  "_set_tokens_to_tokens_threshold": [
    "tokens"
  ],
  "_tokens_from_chars": [
    "text"
  ],
  "_tokens_from_words": [
    "text"
  ],
  "_get_default_max_tokens": [
    "sample_input",
    "sample_output"
  ],
  "_get_default_djl_configurations": [
    "model_id",
    "hf_model_config",
    "schema_builder"
  ],
  "_get_admissible_tensor_parallel_degrees": [
    "hf_model_config"
  ],
  "LocalDJLServing": {
    "_start_djl_serving": [
      "self",
      "client",
      "image",
      "model_path",
      "secret_key",
      "env_vars"
    ],
    "_invoke_djl_serving": [
      "self",
      "request",
      "content_type",
      "accept"
    ]
  },
  "SageMakerDjlServing": {
    "_upload_djl_artifacts": [
      "self",
      "model_path",
      "sagemaker_session",
      "s3_model_data_url",
      "image",
      "env_vars",
      "should_upload_artifacts"
    ]
  },
  "_SETTING_PROPERTY_STMT": [],
  "prepare_djl_js_resources": [
    "model_path",
    "js_id",
    "shared_libs",
    "dependencies",
    "model_data"
  ],
  "inference_spec": [],
  "native_model": [],
  "schema_builder": [],
  "model_fn": [
    "model_dir"
  ],
  "input_fn": [
    "input_data",
    "content_type"
  ],
  "predict_fn": [
    "input_data",
    "predict_callable"
  ],
  "output_fn": [
    "predictions",
    "accept_type"
  ],
  "install_package": [
    "package_name",
    "version"
  ],
  "_get_mlflow_flavor": [],
  "_load_mlflow_model": [
    "deployment_flavor",
    "model_dir"
  ],
  "LocalTorchServe": {
    "_start_torch_serve": [
      "self",
      "client",
      "image",
      "model_path",
      "secret_key",
      "env_vars"
    ],
    "_invoke_torch_serve": [
      "self",
      "request",
      "content_type",
      "accept"
    ]
  },
  "SageMakerTorchServe": {
    "_upload_torchserve_artifacts": [
      "self",
      "model_path",
      "sagemaker_session",
      "secret_key",
      "s3_model_data_url",
      "image",
      "should_upload_artifacts"
    ]
  },
  "prepare_for_torchserve": [
    "model_path",
    "shared_libs",
    "dependencies",
    "session",
    "image_uri",
    "inference_spec"
  ],
  "LocalTensorflowServing": {
    "_start_tensorflow_serving": [
      "self",
      "client",
      "image",
      "model_path",
      "secret_key",
      "env_vars"
    ],
    "_invoke_tensorflow_serving": [
      "self",
      "request",
      "content_type",
      "accept"
    ]
  },
  "SageMakerTensorflowServing": {
    "_upload_tensorflow_serving_artifacts": [
      "self",
      "model_path",
      "sagemaker_session",
      "secret_key",
      "s3_model_data_url",
      "image",
      "should_upload_artifacts"
    ]
  },
  "prepare_for_tf_serving": [
    "model_path",
    "shared_libs",
    "dependencies"
  ],
  "SHARED_LIBS_DIR": [],
  "SERVE_PATH": [],
  "METADATA_PATH": [],
  "input_handler": [
    "data",
    "context"
  ],
  "output_handler": [
    "data",
    "context"
  ],
  "_set_up_schema_builder": [],
  "_set_up_shared_libs": [],
  "_convert_for_serialization": [
    "deserialized_data"
  ],
  "InProcessServing": {
    "_start_serving": [
      "self"
    ],
    "_stop_serving": [
      "self"
    ],
    "_invoke_serving": [
      "self",
      "request",
      "content_type",
      "accept"
    ]
  },
  "InProcessServer": {
    "__init__": [
      "self",
      "model",
      "inference_spec",
      "schema_builder",
      "task"
    ],
    "_create_server": [
      "self"
    ],
    "start_server": [
      "self"
    ],
    "stop_server": [
      "self"
    ],
    "_start_run_async_in_thread": [
      "self"
    ],
    "_serve": [
      "self"
    ]
  },
  "initialize_custom_orchestrator": [],
  "handler": [
    "request"
  ],
  "SageMakerSmdServer": {
    "_upload_smd_artifacts": [
      "self",
      "model_path",
      "sagemaker_session",
      "secret_key",
      "s3_model_data_url",
      "image",
      "should_upload_artifacts"
    ]
  },
  "prepare_for_smd": [
    "model_path",
    "shared_libs",
    "dependencies",
    "inference_spec"
  ],
  "LocalMultiModelServer": {
    "_start_serving": [
      "self",
      "client",
      "image",
      "model_path",
      "secret_key",
      "env_vars"
    ],
    "_invoke_multi_model_server_serving": [
      "self",
      "request",
      "content_type",
      "accept"
    ]
  },
  "SageMakerMultiModelServer": {
    "_upload_server_artifacts": [
      "self",
      "model_path",
      "secret_key",
      "sagemaker_session",
      "s3_model_data_url",
      "image",
      "env_vars",
      "should_upload_artifacts"
    ]
  },
  "prepare_mms_js_resources": [
    "model_path",
    "js_id",
    "shared_libs",
    "dependencies",
    "model_data"
  ],
  "prepare_for_mms": [
    "model_path",
    "shared_libs",
    "dependencies",
    "session",
    "image_uri",
    "inference_spec"
  ],
  "LocalTeiServing": {
    "_start_tei_serving": [
      "self",
      "client",
      "image",
      "model_path",
      "secret_key",
      "env_vars"
    ],
    "_invoke_tei_serving": [
      "self",
      "request",
      "content_type",
      "accept"
    ]
  },
  "SageMakerTeiServing": {
    "_upload_tei_artifacts": [
      "self",
      "model_path",
      "sagemaker_session",
      "s3_model_data_url",
      "image",
      "env_vars",
      "should_upload_artifacts"
    ]
  },
  "BatchTransformInferenceConfig": {},
  "all_accounts": [],
  "is_1p_image_uri": [
    "image_uri"
  ],
  "generate_secret_key": [
    "nbytes"
  ],
  "compute_hash": [
    "buffer",
    "secret_key"
  ],
  "perform_integrity_check": [
    "buffer",
    "metadata_path"
  ],
  "_OptimizationContainer": {
    "TRT": [],
    "VLLM": [],
    "NEURON": []
  },
  "_OptimizationCombination": {
    "validate_against": [
      "self",
      "optimization_combination",
      "rule_set"
    ]
  },
  "TRUTHY_SET": [],
  "FALSY_SET": [],
  "TRT_CONFIGURATION": [],
  "VLLM_CONFIGURATION": [],
  "NEURON_CONFIGURATION": [],
  "_validate_optimization_configuration": [
    "is_jumpstart",
    "instance_type",
    "quantization_config",
    "compilation_config",
    "sharding_config",
    "speculative_decoding_config"
  ],
  "INF1_INSTANCE_FAMILIES": [],
  "INF2_INSTANCE_FAMILIES": [],
  "GRAVITON_INSTANCE_FAMILIES": [],
  "validate_image_uri_and_hardware": [
    "image_uri",
    "instance_type",
    "model_server"
  ],
  "detect_hardware_type_of_instance": [
    "instance_type"
  ],
  "detect_triton_image_hardware_type": [
    "image_uri"
  ],
  "detect_torchserve_image_hardware_type": [
    "image_uri"
  ],
  "image_uri_config_dir_path": [],
  "account_ids": [],
  "extract_account_ids": [
    "json_obj"
  ],
  "LambdaModel": {},
  "CustomOrchestrator": {
    "__init__": [
      "self"
    ],
    "client": [
      "self"
    ],
    "handle": [
      "self",
      "data",
      "context"
    ]
  },
  "AsyncCustomOrchestrator": {
    "handle": [
      "self",
      "data",
      "context"
    ]
  },
  "InferenceSpec": {
    "load": [
      "self",
      "model_dir"
    ],
    "invoke": [
      "self",
      "input_object",
      "model"
    ],
    "preprocess": [
      "self",
      "input_data"
    ],
    "postprocess": [
      "self",
      "predictions"
    ],
    "prepare": [
      "self"
    ],
    "get_model": [
      "self"
    ]
  }
}