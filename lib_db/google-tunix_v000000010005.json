{
  "GrpoPipeline": {
    "create_rollout_config": [
      "self"
    ],
    "create_role_to_mesh": [
      "self"
    ],
    "create_cluster_config": [
      "self"
    ],
    "create_rl_training_config": [
      "self"
    ],
    "create_rl_cluster": [
      "self"
    ],
    "run_grpo_trainer": [
      "self"
    ]
  },
  "main": [
    "argv"
  ],
  "PeftPipeline": {
    "run_peft_trainer": [
      "self"
    ]
  },
  "_TUNIX_PREFIX": [],
  "yaml_key_to_env_key": [
    "s"
  ],
  "string_to_bool": [
    "s"
  ],
  "_yaml_types_to_parser": [],
  "HyperParameters": {
    "__init__": [
      "self",
      "argv"
    ],
    "_validate_tokenizer": [
      "self"
    ],
    "clear_directory_contents": [
      "self"
    ],
    "_validate_model_source": [
      "self",
      "raw_keys"
    ],
    "check_supported_workflow": [
      "self"
    ],
    "_get_nested_config": [
      "self",
      "keys"
    ],
    "_extract_kwargs": [
      "self",
      "func",
      "config",
      "config_path_info",
      "learning_rate"
    ],
    "_get_schedule_fn": [
      "self",
      "schedule_type",
      "config_path_info"
    ],
    "_create_learning_rate": [
      "self",
      "optimizer_config",
      "config_path_info"
    ],
    "create_optimizer": [
      "self"
    ],
    "create_mesh": [
      "self",
      "model_key"
    ],
    "obtain_training_config_dict": [
      "self",
      "key"
    ],
    "_update_from_env_and_command_line": [
      "self",
      "raw_keys",
      "raw_data_from_yaml",
      "argv"
    ],
    "update_dict": [
      "self",
      "schema",
      "source"
    ],
    "_validate_env_variable": [
      "self",
      "raw_data_from_yaml"
    ],
    "_load_config_from_yaml": [
      "self",
      "config_name"
    ],
    "obtain_reward_fn": [
      "self"
    ],
    "_get_function_from_path": [
      "self",
      "path_str"
    ]
  },
  "initialize": [
    "argv"
  ],
  "CONFIG_MAP": [],
  "_BASE_MODULE_PATH": [],
  "get_model_module": [
    "model_name"
  ],
  "create_model_dynamically": [
    "model_name",
    "file_dir",
    "model_config",
    "mesh"
  ],
  "_get_version": [
    "model_name",
    "matched_prefix"
  ],
  "obtain_model_params": [
    "model_name"
  ],
  "_get_base_model": [
    "model_config",
    "mesh"
  ],
  "apply_lora_to_model": [
    "base_model",
    "mesh",
    "lora_config"
  ],
  "_gemma_conversion": [
    "model_config",
    "gemma",
    "params",
    "mesh"
  ],
  "_get_model_version_suffix": [
    "model_name"
  ],
  "create_tokenizer": [
    "tokenizer_config",
    "tokenizer_path"
  ],
  "create_model": [
    "model_config",
    "tokenizer_config",
    "mesh"
  ],
  "ExpectedSignature": [],
  "reasoning_start": [],
  "reasoning_end": [],
  "solution_start": [],
  "solution_end": [],
  "match_format": [],
  "match_format_exactly": [
    "prompts",
    "completions"
  ],
  "match_format_approximately": [
    "prompts",
    "completions"
  ],
  "check_answer": [
    "prompts",
    "completions",
    "answer"
  ],
  "check_numbers": [
    "prompts",
    "completions",
    "answer"
  ],
  "_SOLUTION_CLIP_CHARS": [],
  "extract_solution": [
    "solution_str",
    "method"
  ],
  "compute_score": [
    "solution_str",
    "ground_truth",
    "method",
    "format_score",
    "score"
  ],
  "ModelOrPath": [],
  "MetricsT": [],
  "MetricsBuffer": [],
  "Mode": {
    "TRAIN": [],
    "EVAL": [],
    "__str__": [
      "self"
    ]
  },
  "Role": {
    "ACTOR": [],
    "CRITIC": [],
    "REFERENCE": [],
    "REWARD": [],
    "ROLLOUT": []
  },
  "RLTrainingConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "ClusterConfig": {},
  "RLCluster": {
    "__init__": [
      "self"
    ],
    "_init_backbone_sharing_map": [
      "self",
      "actor",
      "reference"
    ],
    "_load_model": [
      "self",
      "model_or_path",
      "mesh",
      "data_type"
    ],
    "_init_cluster": [
      "self"
    ],
    "_propagate_backbone_sharing_map": [
      "self"
    ],
    "_put_model_on_memory_kind": [
      "self",
      "model",
      "memory_kind"
    ],
    "_update_models_sharing_weights": [
      "self",
      "params",
      "role"
    ],
    "_maybe_load_model_from_cpu": [
      "self",
      "model",
      "role"
    ],
    "_maybe_offload_model_to_cpu": [
      "self",
      "model",
      "role"
    ],
    "rollout": [
      "self"
    ],
    "inference_worker": [
      "self"
    ],
    "actor_trainer": [
      "self"
    ],
    "critic_trainer": [
      "self"
    ],
    "perf": [
      "self"
    ],
    "close": [
      "self"
    ],
    "_log_metrics": [
      "self",
      "metrics_buffer"
    ],
    "with_external_metrics_logger": [
      "self",
      "external_metrics_logger"
    ],
    "buffer_metrics": [
      "self",
      "metrics",
      "mode"
    ],
    "update_actor": [
      "self",
      "train_ds",
      "eval_ds",
      "skip_jit"
    ],
    "update_critic": [
      "self",
      "train_ds",
      "eval_ds",
      "skip_jit"
    ],
    "generate": [
      "self",
      "prompts",
      "apply_chat_template",
      "mode",
      "micro_batch_size"
    ],
    "get_ref_per_token_logps": [
      "self",
      "prompt_tokens",
      "completion_tokens",
      "pad_id",
      "eos_id",
      "micro_batch_size",
      "completion_mask"
    ],
    "get_old_per_token_logps": [
      "self",
      "prompt_tokens",
      "completion_tokens",
      "micro_batch_size",
      "completion_mask"
    ],
    "sync_weights": [
      "self"
    ],
    "get_values": [
      "self",
      "prompt_tokens",
      "completion_tokens",
      "pad_id",
      "eos_id",
      "completion_mask"
    ],
    "get_rewards": [
      "self",
      "prompt_tokens",
      "completion_tokens",
      "pad_id",
      "eos_id"
    ]
  },
  "make_causal_attn_mask": [],
  "build_positions_from_mask": [],
  "RepeatIterable": {
    "__init__": [
      "self",
      "data",
      "repeat",
      "mini_batch_size",
      "shuffle",
      "key"
    ],
    "_shuffle_and_slice_one_batch": [
      "self",
      "rollout_batch"
    ],
    "__iter__": [
      "self"
    ]
  },
  "TrainExample": {},
  "compute_kl_divergence": [
    "per_token_logps",
    "ref_per_token_logps",
    "method"
  ],
  "selective_log_softmax": [
    "logits",
    "input_ids"
  ],
  "get_per_token_logps": [
    "model",
    "input_tokens",
    "positions",
    "attn_mask",
    "logits_to_keep"
  ],
  "process_ids": [
    "prompt_tokens",
    "completion_tokens",
    "pad_id",
    "eos_id",
    "completion_mask"
  ],
  "compute_per_token_logps": [
    "model",
    "prompt_tokens",
    "completion_tokens",
    "pad_id",
    "eos_id",
    "completion_mask",
    "stop_gradient",
    "return_logits"
  ],
  "make_completion_mask": [
    "completion_ids",
    "eos_tok"
  ],
  "pad_to_length": [
    "x",
    "target_length",
    "pad_value",
    "left",
    "axis"
  ],
  "aggregate_loss": [
    "per_token_loss",
    "completion_mask",
    "loss_agg_mode"
  ],
  "ABC": [],
  "abstractmethod": [],
  "TrainingInputT": [],
  "RewardFn": [],
  "MetricFn": [],
  "TConfig": [],
  "RLLearner": {
    "__init__": [
      "self",
      "rl_cluster",
      "algo_config",
      "reward_fns",
      "metric_fns",
      "data_shuffle_seed"
    ],
    "_generate_and_compute_advantage": [
      "self",
      "training_input",
      "mode"
    ],
    "_compute_trajectory_ids": [
      "self",
      "example",
      "steps"
    ],
    "_num_iterations": [
      "self"
    ],
    "_num_generations": [
      "self"
    ],
    "_compute_rewards": [
      "self",
      "prompts",
      "completions",
      "mode"
    ],
    "_process_accumulated_batches": [
      "self",
      "micro_batches",
      "micro_batch_sizes",
      "mode"
    ],
    "_prepare_data": [
      "self",
      "iterator",
      "proceed_num_steps",
      "sample_repeat",
      "batch_repeat",
      "service_target_batch_size",
      "data_queue",
      "async_loading",
      "mode"
    ],
    "_create_micro_batch_iterator": [
      "self",
      "full_batch_iterator",
      "micro_batch_size"
    ],
    "train": [
      "self",
      "train_ds",
      "eval_ds",
      "skip_jit"
    ],
    "_run_global_step": [
      "self",
      "full_batch_size",
      "mini_batch_size",
      "service_target_batch_size",
      "grad_acc_steps",
      "train_iterator",
      "eval_ds",
      "skip_jit"
    ],
    "_run_mini_batch_step": [
      "self",
      "initial_steps",
      "service_target_batch_size",
      "grad_acc_steps",
      "train_iterator",
      "eval_ds",
      "skip_jit"
    ],
    "_run_all_micro_batch_steps": [
      "self",
      "initial_steps",
      "service_target_batch_size",
      "grad_acc_steps",
      "train_iterator",
      "eval_ds",
      "skip_jit"
    ]
  },
  "Trainer": {
    "__init__": [
      "self",
      "model",
      "optimizer",
      "training_config",
      "custom_checkpoint_metadata_fn",
      "metrics_logger"
    ],
    "with_rl_metrics_to_log": [
      "self",
      "rl_metrics_to_log"
    ],
    "with_tqdm_metrics_to_display": [
      "self",
      "tqdm_metrics_to_display"
    ],
    "custom_checkpoint_metadata": [
      "self"
    ],
    "restored_global_step": [
      "self"
    ],
    "_post_process_train_step": [
      "self",
      "aux"
    ],
    "_post_process_eval_step": [
      "self",
      "aux"
    ],
    "_get_additional_tqdm_metrics": [
      "self"
    ],
    "_tqdm_train_metrics": [
      "self"
    ]
  },
  "Mesh": [],
  "NamedSharding": [],
  "check_positive": [
    "value",
    "name"
  ],
  "check_divisibility": [
    "small_size",
    "big_size",
    "small_size_name",
    "big_size_name"
  ],
  "to_flat_dict": [
    "tree"
  ],
  "get_pytree_mesh_info": [
    "tree"
  ],
  "_is_same_state": [
    "s1",
    "s2"
  ],
  "is_sharing_weights": [
    "m1",
    "m2"
  ],
  "is_sharing_backbone": [
    "m1",
    "m2"
  ],
  "chunk_slices_by_size": [
    "stop",
    "step"
  ],
  "get_batch_slice": [
    "tree",
    "batch_slice"
  ],
  "merge_micro_batches": [
    "batches"
  ],
  "put_params_on_memory_kind": [
    "params",
    "memory_kind"
  ],
  "create_critic_model": [
    "actor_model",
    "seed",
    "lm_head_to_replace"
  ],
  "get_partition_spec": [
    "sharding"
  ],
  "maybe_move": [
    "arr",
    "mesh"
  ],
  "_POLICY_LOSS_FN_CATEGORY": [],
  "_ADVANTAGE_ESTIMATOR_CATEGORY": [],
  "FunctionRegistry": {
    "__init__": [
      "self",
      "allowed_categories"
    ],
    "_validate_category": [
      "self",
      "category"
    ],
    "register": [
      "self",
      "category",
      "name"
    ],
    "get": [
      "self",
      "category",
      "name"
    ],
    "list_categories": [
      "self"
    ],
    "list_functions": [
      "self",
      "category"
    ]
  },
  "default_registry": [],
  "get_policy_loss_fn": [
    "name"
  ],
  "register_policy_loss_fn": [
    "name"
  ],
  "get_advantage_estimator": [
    "name"
  ],
  "register_advantage_estimator": [
    "name"
  ],
  "AlgorithmConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "callback_on_ready": [
    "x",
    "success",
    "failure"
  ],
  "_identity": [
    "x"
  ],
  "INTERMEDIATE_SPLIT_SUFFIX": [],
  "INTERMEDIATE_REPLICA_SUFFIX": [],
  "_maybe_find_intermediate_sharding": [
    "source_sharding",
    "target_sharding"
  ],
  "_experimental_pre_reshard": [
    "splitfn",
    "src_pytree",
    "target_shardings"
  ],
  "_get_reshard_fn_pathwaysutils": [],
  "_get_reshard_fn_jax_device_put": [],
  "_get_reshard_fn": [
    "cache_resharding_plans",
    "donate",
    "use_experimental_pre_reshard",
    "get_reshard_fns"
  ],
  "reshard_pytree": [
    "source",
    "target",
    "cache_plan",
    "donate_input",
    "use_experimental_pre_reshard"
  ],
  "reshard_model_to_mesh": [
    "model",
    "mesh"
  ],
  "_T": [],
  "AbstractDataQueue": {
    "put": [
      "self",
      "item"
    ],
    "get": [
      "self",
      "block",
      "timeout"
    ],
    "qsize": [
      "self"
    ],
    "close": [
      "self"
    ]
  },
  "SimpleDataQueue": {
    "__init__": [
      "self",
      "maxsize"
    ],
    "put": [
      "self",
      "item"
    ],
    "get": [
      "self",
      "block",
      "timeout"
    ],
    "qsize": [
      "self"
    ],
    "close": [
      "self"
    ]
  },
  "GRPOConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "TGrpoConfig": [],
  "GRPOLearner": {
    "__init__": [
      "self",
      "rl_cluster",
      "algo_config",
      "reward_fns",
      "metric_fns",
      "data_shuffle_seed"
    ],
    "_generate_and_compute_advantage": [
      "self",
      "training_input",
      "mode"
    ],
    "_compute_trajectory_ids": [
      "self",
      "example",
      "steps"
    ],
    "_num_iterations": [
      "self"
    ],
    "_num_generations": [
      "self"
    ],
    "train": [
      "self",
      "train_ds",
      "eval_ds",
      "skip_jit"
    ]
  },
  "grpo_loss_fn": [
    "model",
    "train_example",
    "algo_config",
    "pad_id",
    "eos_id"
  ],
  "compute_advantages": [
    "rewards",
    "num_generations"
  ],
  "GrpoConfig": [],
  "GrpoLearner": [],
  "DAPOConfig": {},
  "DAPOLearner": {
    "__init__": [
      "self",
      "rl_cluster",
      "algo_config",
      "reward_fns",
      "metric_fns",
      "data_shuffle_seed"
    ]
  },
  "VanillaRollout": {
    "__init__": [
      "self",
      "model",
      "tokenizer",
      "cache_config_or_size"
    ],
    "generate": [
      "self",
      "prompts",
      "rollout_config"
    ],
    "get_per_token_logps": [
      "self",
      "prompt_tokens",
      "completion_tokens",
      "completion_mask"
    ],
    "update_params": [
      "self",
      "params",
      "filter_types"
    ],
    "pad_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "model": [
      "self"
    ]
  },
  "VllmRollout": {
    "__init__": [
      "self",
      "model",
      "tokenizer",
      "cache_config_or_size",
      "mesh",
      "rollout_config"
    ],
    "generate": [
      "self",
      "prompts",
      "rollout_config"
    ],
    "get_per_token_logps": [
      "self",
      "prompt_tokens",
      "completion_tokens"
    ],
    "update_params": [
      "self",
      "params",
      "filter_types"
    ],
    "pad_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "model": [
      "self"
    ]
  },
  "CacheConfig": {},
  "RolloutOutput": {},
  "RolloutConfig": {},
  "BaseRollout": {
    "__init__": [
      "self"
    ],
    "generate": [
      "self",
      "prompts",
      "rollout_config"
    ],
    "get_per_token_logps": [
      "self",
      "prompt_tokens",
      "completion_tokens",
      "completion_mask"
    ],
    "update_params": [
      "self",
      "params",
      "filter_types"
    ],
    "pad_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "model": [
      "self"
    ]
  },
  "SglangJaxRollout": {
    "__init__": [
      "self",
      "model",
      "tokenizer",
      "mesh",
      "rollout_config"
    ],
    "generate": [
      "self",
      "prompts",
      "rollout_config"
    ],
    "get_per_token_logps": [
      "self",
      "prompt_tokens",
      "completion_tokens",
      "completion_mask"
    ],
    "update_params": [
      "self",
      "params",
      "filter_types"
    ],
    "pad_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "model": [
      "self"
    ]
  },
  "registry": [],
  "compute_gae_advantages": [
    "rewards",
    "values",
    "completion_mask",
    "gamma",
    "gae_lambda"
  ],
  "masked_whiten": [
    "x",
    "completion_mask"
  ],
  "masked_mean": [
    "x",
    "mask",
    "axis"
  ],
  "masked_var": [
    "x",
    "mask",
    "mean"
  ],
  "compute_entropy_from_logits": [
    "logits"
  ],
  "PPOConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "PPOLearner": {
    "__init__": [
      "self",
      "rl_cluster",
      "ppo_config",
      "reward_fns",
      "metric_fns",
      "data_shuffle_seed"
    ],
    "_generate_and_compute_advantage": [
      "self",
      "training_input",
      "mode"
    ],
    "_compute_trajectory_ids": [
      "self",
      "example",
      "steps"
    ],
    "_num_iterations": [
      "self"
    ],
    "_num_generations": [
      "self"
    ],
    "train": [
      "self",
      "train_ds",
      "eval_ds",
      "skip_jit"
    ]
  },
  "ppo_value_loss_fn": [
    "model",
    "train_example",
    "clip_range_value",
    "pad_id",
    "eos_id"
  ],
  "ppo_policy_loss_fn": [
    "model",
    "train_example",
    "epsilon_low",
    "epsilon_high",
    "epsilon_c",
    "entropy_coef",
    "pad_id",
    "eos_id"
  ],
  "PpoConfig": [],
  "PpoLearner": [],
  "pad_prompt_and_completion": [
    "prompt_tokens",
    "completion_tokens",
    "max_prompt_length",
    "max_generation_steps",
    "pad_id"
  ],
  "get_recent_assistant_user_messages": [
    "chat_completions_messages"
  ],
  "convert_single_message": [
    "msg",
    "tokenizer",
    "parser",
    "is_first",
    "is_generation"
  ],
  "tokenize_and_generate_masks": [
    "messages",
    "tokenizer",
    "parser",
    "contains_first_msg",
    "contains_generation_msg"
  ],
  "BaseTool": [],
  "ToolCall": [],
  "ToolParser": [],
  "GeminiToolParser": {
    "parse": [
      "self",
      "model_response"
    ],
    "get_tool_prompt": [
      "self",
      "tools"
    ]
  },
  "QwenToolParser": [],
  "_PARSER_REGISTRY": [],
  "get_tool_parser": [
    "parser_name"
  ],
  "dataclass": [],
  "TokenConfig": {},
  "BaseChatTemplateParser": {
    "__init__": [
      "self",
      "tokenizer",
      "disable_thinking"
    ],
    "_init_tokens": [
      "self"
    ],
    "_init_generation_prompt": [
      "self"
    ],
    "parse": [
      "self",
      "messages",
      "add_generation_prompt",
      "is_first_msg"
    ],
    "_handle_first_message": [
      "self",
      "messages"
    ],
    "_parse_message": [
      "self",
      "message"
    ],
    "_parse_system": [
      "self",
      "message"
    ],
    "_parse_user": [
      "self",
      "message"
    ],
    "_parse_assistant": [
      "self",
      "message"
    ],
    "_parse_tool": [
      "self",
      "message"
    ]
  },
  "DefaultChatTemplateParser": {
    "_init_tokens": [
      "self"
    ],
    "_init_generation_prompt": [
      "self"
    ],
    "parse": [
      "self",
      "messages",
      "add_generation_prompt",
      "is_first_msg"
    ]
  },
  "QwenChatTemplateParser": {
    "_init_tokens": [
      "self"
    ],
    "_get_assistant_token": [
      "self"
    ],
    "_init_generation_prompt": [
      "self"
    ],
    "_handle_first_message": [
      "self",
      "messages"
    ]
  },
  "LlamaChatTemplateParser": {
    "_init_tokens": [
      "self"
    ],
    "_init_generation_prompt": [
      "self"
    ]
  },
  "GemmaChatTemplateParser": {
    "_init_tokens": [
      "self"
    ],
    "_parse_assistant": [
      "self",
      "message"
    ],
    "_parse_system": [
      "self",
      "message"
    ],
    "preprocess_messages": [
      "self",
      "messages"
    ],
    "parse": [
      "self",
      "messages",
      "add_generation_prompt",
      "is_first_msg"
    ],
    "_init_generation_prompt": [
      "self"
    ]
  },
  "Trajectory": [],
  "TrajectoryItem": [],
  "field": [],
  "GroupQueueManager": {
    "__init__": [
      "self"
    ],
    "put_exception": [
      "self",
      "exc"
    ],
    "prepare_clear": [
      "self"
    ],
    "clear": [
      "self"
    ],
    "put": [
      "self",
      "item"
    ],
    "_get_one_ready_group": [
      "self"
    ],
    "get_batch": [
      "self",
      "batch_size"
    ],
    "_open_bucket_count": [
      "self"
    ]
  },
  "BaseEnv": [],
  "LLMBaseAgent": [],
  "logger": [],
  "TrajectoryCollectEngine": {
    "__init__": [
      "self",
      "agent",
      "env"
    ],
    "collect": [
      "self",
      "mode"
    ],
    "collect_multiple": [
      "pairs"
    ],
    "_reset": [
      "self"
    ],
    "_one_step": [
      "self"
    ],
    "_append_final_reward": [
      "self"
    ],
    "compute_trajectory_reward": [
      "self"
    ],
    "compute_mc_reward": [
      "self"
    ],
    "_close": [
      "self"
    ]
  },
  "Step": [],
  "Action": [],
  "ConversationAgentBase": [],
  "ModelAgent": {
    "__init__": [
      "self",
      "system_prompt"
    ],
    "update_from_model": [
      "self",
      "response"
    ]
  },
  "ToolManager": [],
  "ToolAgent": {
    "__init__": [
      "self",
      "system_prompt",
      "tool_parser_name",
      "tool_map"
    ],
    "_init_messages": [
      "self",
      "system_prompt"
    ],
    "_observation_to_messages": [
      "self",
      "observation"
    ],
    "update_from_model": [
      "self",
      "response"
    ]
  },
  "asdict": [],
  "EnvStepResult": {},
  "BaseTaskEnv": {
    "__init__": [
      "self",
      "task"
    ],
    "_initial_observation": [
      "self"
    ],
    "_step_impl": [
      "self",
      "action"
    ],
    "reset": [
      "self"
    ],
    "step": [
      "self",
      "action"
    ],
    "from_dict": [
      "cls",
      "env_args"
    ]
  },
  "dummy_reward": [],
  "ToolEnvironment": {
    "__init__": [
      "self",
      "task"
    ],
    "_initial_observation": [
      "self"
    ],
    "_step_impl": [
      "self",
      "action"
    ],
    "_extract_llm_answer": [
      "action"
    ],
    "_execute_tool_calls": [
      "self",
      "tool_calls"
    ],
    "from_dict": [
      "cls",
      "env_args"
    ]
  },
  "TaskEnvironment": {
    "__init__": [
      "self",
      "task"
    ],
    "_initial_observation": [
      "self"
    ],
    "_step_impl": [
      "self",
      "action"
    ],
    "from_dict": [
      "cls",
      "env_args"
    ]
  },
  "RewardOutput": {},
  "register": [
    "name"
  ],
  "unregister": [
    "name"
  ],
  "get_reward_fn": [
    "name"
  ],
  "exact_match": [
    "task",
    "action"
  ],
  "combine_rewards": [
    "weights"
  ],
  "is_two_reward": [
    "task",
    "action"
  ],
  "calculate_reward": [
    "task",
    "action"
  ],
  "RolloutOrchestrator": {
    "__init__": [
      "self"
    ],
    "_collect_trajectory": [
      "self",
      "agent",
      "env",
      "mode"
    ],
    "_runner": [
      "self",
      "i",
      "agent",
      "env",
      "manager",
      "group_key",
      "episodes_per_pair",
      "start_step_fn",
      "collect_mode"
    ],
    "run_producers_from_stream": [
      "self",
      "pairs_stream"
    ],
    "yield_batches": [
      "self",
      "batch_size"
    ],
    "run_and_yield_batches": [
      "self",
      "pairs"
    ]
  },
  "ToolOutput": [],
  "CalculatorTool": {
    "get_json_schema": [
      "self"
    ],
    "apply": [
      "self"
    ]
  },
  "as_completed": [],
  "ThreadPoolExecutor": [],
  "InferenceWorker": {
    "__init__": [
      "self",
      "models"
    ],
    "get_rewards": [
      "self",
      "prompt_tokens",
      "completion_tokens",
      "pad_id",
      "eos_id"
    ],
    "get_ref_per_token_logps": [
      "self",
      "prompt_tokens",
      "completion_tokens",
      "pad_id",
      "eos_id",
      "completion_mask"
    ],
    "get_values": [
      "self",
      "prompt_tokens",
      "completion_tokens",
      "pad_id",
      "eos_id",
      "completion_mask"
    ],
    "get_model": [
      "self",
      "role"
    ],
    "update_model": [
      "self",
      "role",
      "params"
    ]
  },
  "_convert_to_nparray": [
    "arr"
  ],
  "assert_equal": [
    "path",
    "x",
    "y"
  ],
  "assert_not_equal": [
    "path",
    "x",
    "y"
  ],
  "assert_close": [
    "path",
    "x",
    "y",
    "atol",
    "rtol"
  ],
  "Decoder": {
    "__init__": [
      "self",
      "rngs"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "ModelConfig": {},
  "ToyTransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x",
      "positions",
      "cache",
      "attention_mask",
      "output_hidden_states"
    ],
    "num_embed": [
      "self"
    ]
  },
  "get_dummy_inputs_for_lora_toy_transformer_tests": [],
  "get_lora_model": [
    "model",
    "module_path",
    "mesh",
    "rank",
    "alpha"
  ],
  "MockVocab": {
    "__init__": [
      "self"
    ],
    "pad_id": [
      "self"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "GetPieceSize": [
      "self"
    ],
    "DecodeIds": [
      "self",
      "ids"
    ],
    "EncodeAsIds": [
      "self",
      "text"
    ]
  },
  "MockTransformerWithScoreHead": {
    "__init__": [
      "self",
      "transformer",
      "rngs"
    ],
    "__call__": [
      "self"
    ]
  },
  "download_from_huggingface": [
    "repo_id",
    "model_path"
  ],
  "batch_templatize": [
    "prompts",
    "tokenizer"
  ],
  "validate_llm_outputs": [
    "expected_output_pattern",
    "serving_outputs"
  ],
  "delete_directory": [
    "path"
  ],
  "clear_jax_arrays": [],
  "is_running_in_colab": [],
  "partial": [],
  "PerfSpanQuery": [],
  "Span": [],
  "SpanGroup": [],
  "MetricsExportFn": [],
  "PerfMetricsExport": {
    "from_role_to_devices": [
      "role_to_devices"
    ],
    "from_cluster_config": [
      "cluster_config"
    ],
    "create_metrics_export_fn": [
      "cluster_config"
    ],
    "_grpo_metrics_colocated": [
      "role_to_devices",
      "query"
    ],
    "_grpo_metrics_rollout_1_actor_2_reference_2": [
      "role_to_devices",
      "query"
    ],
    "_grpo_metrics_fully_disaggregated": [
      "role_to_devices",
      "query"
    ],
    "_grpo_extract_spans_and_groups": [
      "role_to_devices",
      "query"
    ]
  },
  "ArrayLike": [],
  "Timeline": [],
  "PerfMetricsConfig": {},
  "JaxDevice": [],
  "span_group_tostring": [
    "group",
    "born"
  ],
  "span_group_print": [
    "group",
    "born"
  ],
  "span_group_stack_clone": [
    "stack"
  ],
  "span_group_batch_query_first": [
    "batch",
    "name"
  ],
  "span_group_batch_query_last": [
    "batch",
    "name"
  ],
  "span_group_batch_query_nth": [
    "batch",
    "name",
    "index"
  ],
  "span_group_batch_query_all": [
    "batch",
    "name"
  ],
  "create_thread_timeline_id": [],
  "create_device_timeline_id": [
    "id"
  ],
  "create_device_timeline_ids": [
    "devices"
  ],
  "NoopTracer": {
    "synchronize": [
      "self"
    ],
    "print": [
      "self"
    ],
    "export": [
      "self"
    ],
    "all_devices": [
      "self"
    ],
    "span_group": [
      "self",
      "name"
    ],
    "span": [
      "self",
      "name",
      "devices"
    ]
  },
  "PerfTracer": {
    "__init__": [
      "self",
      "devices",
      "export_fn"
    ],
    "_get_timelines": [
      "self"
    ],
    "_get_or_create_thread_timeline": [
      "self",
      "id"
    ],
    "_get_or_create_device_timeline": [
      "self",
      "id"
    ],
    "_get_or_create_device_timelines": [
      "self",
      "ids"
    ],
    "synchronize": [
      "self"
    ],
    "print": [
      "self"
    ],
    "export": [
      "self"
    ],
    "all_devices": [
      "self"
    ],
    "span_group": [
      "self",
      "name"
    ],
    "span": [
      "self",
      "name",
      "devices"
    ]
  },
  "Tracer": [],
  "ThreadTimeline": {
    "span_begin": [
      "self",
      "name",
      "begin"
    ],
    "span_end": [
      "self",
      "end"
    ]
  },
  "DeviceTimeline": {
    "__init__": [
      "self",
      "id",
      "born"
    ],
    "span": [
      "self",
      "name",
      "thread_span_begin",
      "waitlist"
    ],
    "wait_pending_spans": [
      "self"
    ]
  },
  "BatchDeviceTimeline": {
    "__init__": [
      "self",
      "timelines"
    ],
    "span": [
      "self",
      "name",
      "thread_span_begin",
      "waitlist"
    ]
  },
  "_DeviceWaitlist": {
    "__init__": [
      "self"
    ],
    "device_end": [
      "self",
      "waitlist"
    ]
  },
  "_async_wait": [
    "waitlist",
    "success",
    "failure"
  ],
  "_synchronize_devices": [],
  "ModuleList": [],
  "mathd_normalize_answer": [
    "answer"
  ],
  "_strip_string": [
    "string"
  ],
  "BAD_SUBSTRINGS": [],
  "BAD_REGEXES": [],
  "TUPLE_CHARS": [],
  "_sympy_parse": [
    "expr"
  ],
  "_parse_latex": [
    "expr"
  ],
  "_is_float": [
    "num"
  ],
  "_is_int": [
    "x"
  ],
  "_is_frac": [
    "expr"
  ],
  "_str_is_int": [
    "x"
  ],
  "_str_to_int": [
    "x"
  ],
  "_inject_implicit_mixed_number": [
    "step"
  ],
  "_strip_properly_formatted_commas": [
    "expr"
  ],
  "_normalize": [
    "expr"
  ],
  "count_unknown_letters_in_expr": [
    "expr"
  ],
  "should_allow_eval": [
    "expr"
  ],
  "are_equal_under_sympy": [
    "ground_truth_normalized",
    "given_normalized"
  ],
  "split_tuple": [
    "expr"
  ],
  "last_boxed_only_string": [
    "string"
  ],
  "remove_boxed": [
    "s"
  ],
  "extract_boxed_answer": [
    "solution"
  ],
  "grade_answer_sympy": [
    "given_answer",
    "ground_truth"
  ],
  "grade_answer_mathd": [
    "given_answer",
    "ground_truth"
  ],
  "extract_answer": [
    "passage"
  ],
  "THOUGHT_DELIMITER_END": [],
  "math_reward": [
    "prompts",
    "completions",
    "answer"
  ],
  "get_dataset": [
    "path",
    "split",
    "seed",
    "system_prompt"
  ],
  "get_train_and_eval_datasets": [
    "data_path",
    "split",
    "seed",
    "system_prompt",
    "batch_size",
    "num_batches",
    "train_fraction",
    "num_epochs"
  ],
  "profile_and_capture_log": {
    "__init__": [
      "self",
      "tag",
      "enable_profile",
      "device_name",
      "host_trace_level"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "pathways_available": [],
  "load_file_from_gcs": [
    "file_dir",
    "target_dir"
  ],
  "kaggle_pipeline": [
    "model_config"
  ],
  "hf_pipeline": [
    "model_config"
  ],
  "TrainingConfig": {},
  "TrainingInput": {},
  "DistillationTrainer": {
    "__init__": [
      "self",
      "student_model",
      "teacher_model",
      "strategy",
      "optimizer",
      "training_config"
    ],
    "with_gen_model_input_fn": [
      "self",
      "gen_model_input_fn"
    ],
    "with_loss_fn": [
      "self",
      "loss_fn",
      "has_aux"
    ],
    "_prepare_inputs": [
      "self",
      "input_data"
    ],
    "get_train_loss": [
      "self",
      "model",
      "teacher_output",
      "inputs"
    ],
    "get_eval_loss": [
      "self",
      "model",
      "teacher_output",
      "inputs"
    ],
    "close": [
      "self"
    ]
  },
  "ModelForwardCallable": [],
  "FeaturePoolingStrategy": {
    "__init__": [
      "self",
      "student_forward_fn",
      "teacher_forward_fn",
      "labels_fn",
      "feature_layer",
      "alpha",
      "feature_loss_fn",
      "cosine_distance_axis"
    ],
    "pre_process_models": [
      "self",
      "student_model",
      "teacher_model"
    ],
    "post_process_models": [
      "self",
      "student_model",
      "teacher_model"
    ],
    "get_teacher_outputs": [
      "self",
      "teacher_model",
      "inputs"
    ],
    "get_student_outputs": [
      "self",
      "student_model",
      "inputs"
    ],
    "compute_eval_loss": [
      "self",
      "student_output",
      "labels"
    ],
    "compute_loss": [
      "self",
      "student_output",
      "teacher_output",
      "labels"
    ]
  },
  "AttentionTransferStrategy": {
    "__init__": [
      "self",
      "student_forward_fn",
      "teacher_forward_fn",
      "labels_fn",
      "attention_layer",
      "alpha",
      "attention_loss_fn"
    ]
  },
  "AttentionProjectionStrategy": {
    "__init__": [
      "self",
      "student_forward_fn",
      "teacher_forward_fn",
      "labels_fn",
      "attention_layer",
      "dummy_input",
      "rngs",
      "alpha",
      "attention_loss_fn"
    ]
  },
  "FeatureProjectionStrategy": {
    "__init__": [
      "self",
      "student_forward_fn",
      "teacher_forward_fn",
      "labels_fn",
      "feature_layer",
      "dummy_input",
      "rngs",
      "alpha",
      "feature_loss_fn"
    ],
    "pre_process_models": [
      "self",
      "student_model",
      "teacher_model"
    ],
    "post_process_models": [
      "self",
      "student_model",
      "teacher_model"
    ],
    "get_teacher_outputs": [
      "self",
      "teacher_model",
      "inputs"
    ],
    "get_student_outputs": [
      "self",
      "student_model",
      "inputs"
    ],
    "compute_eval_loss": [
      "self",
      "student_output",
      "labels"
    ],
    "compute_loss": [
      "self",
      "student_output",
      "teacher_output",
      "labels"
    ]
  },
  "LogitStrategy": {
    "__init__": [
      "self",
      "student_forward_fn",
      "teacher_forward_fn",
      "labels_fn",
      "temperature",
      "alpha"
    ],
    "compute_eval_loss": [
      "self",
      "student_output",
      "labels"
    ],
    "compute_loss": [
      "self",
      "student_output",
      "teacher_output",
      "labels"
    ]
  },
  "R": [],
  "BaseStrategy": {
    "__init__": [
      "self",
      "student_forward_fn",
      "teacher_forward_fn",
      "labels_fn"
    ],
    "compute_loss": [
      "self",
      "student_output",
      "teacher_output",
      "labels"
    ],
    "compute_eval_loss": [
      "self",
      "student_output",
      "labels"
    ],
    "pre_process_models": [
      "self",
      "student_model",
      "teacher_model"
    ],
    "post_process_models": [
      "self",
      "student_model",
      "teacher_model"
    ],
    "get_teacher_outputs": [
      "self",
      "teacher_model",
      "inputs"
    ],
    "get_student_outputs": [
      "self",
      "student_model",
      "inputs"
    ],
    "get_train_loss": [
      "self",
      "student_model",
      "teacher_output",
      "inputs"
    ],
    "get_eval_loss": [
      "self",
      "student_model",
      "inputs"
    ]
  },
  "ModelWithFeatureProjection": {
    "__init__": [
      "self",
      "model",
      "feature_shape",
      "feature_target_shape"
    ],
    "__call__": [
      "self"
    ]
  },
  "setup_models_with_feature_projection": [
    "student_model",
    "teacher_model",
    "student_layer_to_capture",
    "teacher_layer_to_capture",
    "dummy_student_input",
    "dummy_teacher_input"
  ],
  "remove_feature_projection_from_models": [
    "student_model",
    "teacher_model"
  ],
  "PaddingMode": {
    "VALID": [],
    "SAME": []
  },
  "avg_pool_array_to_target_shape": [
    "input_array",
    "target_shape",
    "padding_mode",
    "count_include_pad_for_same_padding"
  ],
  "SowedModule": {
    "_SOW_TAG": [],
    "__init__": [
      "self",
      "model_to_wrap"
    ],
    "__call__": [
      "self"
    ]
  },
  "pop_sowed_intermediate_outputs": [
    "model"
  ],
  "wrap_model_with_sowed_modules": [
    "model",
    "modules_to_capture"
  ],
  "unwrap_sowed_modules": [
    "model"
  ],
  "TokenizerType": {},
  "TokenizerAdapter": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "ids"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "pad_id": [
      "self"
    ],
    "_missing_methods": [
      "self"
    ],
    "_is_hf_tokenizer": [
      "self"
    ],
    "tokenizer": [
      "self"
    ],
    "apply_chat_template": [
      "self",
      "messages",
      "add_generation_prompt",
      "tokenize"
    ],
    "_apply_gemma_chat_template": [
      "self",
      "messages",
      "add_generation_prompt",
      "tokenize"
    ]
  },
  "Tokenizer": {
    "__init__": [
      "self",
      "tokenizer_type",
      "tokenizer_path",
      "add_bos",
      "add_eos",
      "hf_access_token"
    ],
    "tokenize": [
      "self",
      "example",
      "prefix",
      "suffix",
      "add_eos"
    ]
  },
  "SamplerOutput": {},
  "BaseSampler": {
    "transformer": [
      "self"
    ],
    "transformer_state": [
      "self"
    ],
    "__call__": [
      "self",
      "input_strings",
      "max_generation_steps",
      "max_prompt_length",
      "temperature",
      "top_p",
      "top_k",
      "beam_size",
      "seed",
      "multi_sampling",
      "return_logits",
      "echo",
      "pad_output"
    ],
    "tokenize": [
      "self",
      "input_string"
    ]
  },
  "BackendMappingMixin": {
    "DEFAULT_BACKEND": [],
    "_backend_registry": [
      "cls"
    ],
    "mapping_for": [
      "cls",
      "backend"
    ],
    "to_hf_mappings": [
      "cls",
      "backend"
    ],
    "lora_to_hf_mappings": [
      "cls",
      "backend"
    ],
    "to_hf_transpose_keys": [
      "cls",
      "backend"
    ],
    "to_hf_hook_fns": [
      "cls",
      "backend"
    ]
  },
  "MappingConfig": {
    "build": [
      "cls",
      "mapping_obj",
      "model",
      "backend"
    ],
    "from_model": [
      "cls",
      "model",
      "backend"
    ]
  },
  "StreamCallback": [],
  "RequestFuture": [],
  "VLLMInProcessDriver": {
    "__init__": [
      "self",
      "llm_engine"
    ],
    "from_engine_args": [
      "cls",
      "engine_args"
    ],
    "submit_request": [
      "self",
      "request_id",
      "prompt",
      "params"
    ],
    "start": [
      "self"
    ],
    "cancel": [
      "self",
      "request_id"
    ],
    "shutdown": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "pause": [
      "self"
    ],
    "resume": [
      "self"
    ],
    "_loop": [
      "self"
    ],
    "_wait_for_work": [
      "self"
    ],
    "_step_engine": [
      "self"
    ],
    "_handle_output": [
      "self",
      "output"
    ],
    "_record_error": [
      "self",
      "exc"
    ],
    "llm_engine": [
      "self"
    ],
    "last_error": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc",
      "tb"
    ]
  },
  "compute_attention_masks": [
    "time_step",
    "seq_len",
    "input_mask"
  ],
  "next_power_of_2": [
    "x"
  ],
  "find_first_non_pad_idx": [
    "ids",
    "pad_id"
  ],
  "find_first_eos_idx": [
    "ids",
    "eos_id"
  ],
  "find_last_non_pad_idx": [
    "ids",
    "pad_id"
  ],
  "padded_fill_tokens_and_logits": [
    "token_buffers",
    "logits_buffers",
    "return_logits",
    "echo",
    "pad_value",
    "eos_value",
    "max_prompt_length",
    "max_total_length"
  ],
  "single_padded_fill_tokens_and_logits": [
    "token_buffer",
    "logits_buffer",
    "return_logits",
    "echo",
    "pad_value",
    "eos_value",
    "max_prompt_length",
    "max_total_length"
  ],
  "check_sampling_mode_conflict": [
    "original_sampling_mode",
    "new_sampling_mode"
  ],
  "get_logprobs_from_vllm_output": [
    "token_ids",
    "logprobs"
  ],
  "build_flat_dict": [
    "flat_state",
    "mappings"
  ],
  "ShapeMismatchError": {},
  "MappingError": {},
  "_get_layer_axis_from_sharding_spec": [
    "sharding_spec"
  ],
  "_unroll_scanned_layers": [
    "src_state",
    "src_to_tgt_map"
  ],
  "_apply_transpose": [
    "val",
    "src_key",
    "transpose_keys"
  ],
  "_reshape_attention": [
    "val",
    "tgt_shape",
    "src_key"
  ],
  "_align_shape": [
    "val",
    "tgt_shape",
    "src_key"
  ],
  "_apply_dtype_cast": [
    "val",
    "tgt_dtype",
    "src_key"
  ],
  "transfer_state_with_mappings": [
    "src_state",
    "dst_state",
    "key_mappings",
    "key_mapping_hook_fns",
    "transpose_keys",
    "reshard_fn"
  ],
  "verify_state_closeness": [
    "golden_state",
    "state",
    "atol"
  ],
  "SglangJaxConfig": {},
  "SglangJaxSampler": {
    "__init__": [
      "self",
      "tokenizer",
      "config"
    ],
    "update_params": [
      "self",
      "updated_weights",
      "filter_types"
    ],
    "load_checkpoint": [
      "self",
      "path_or_weights"
    ],
    "_find_tp_size": [
      "self",
      "mesh"
    ],
    "_sglang_jax_config": [
      "self",
      "config"
    ],
    "_model_runner": [
      "self"
    ],
    "transformer": [
      "self"
    ],
    "transformer_state": [
      "self"
    ],
    "tokenize": [
      "self",
      "input_string"
    ],
    "__call__": [
      "self",
      "input_strings",
      "max_generation_steps",
      "max_prompt_length",
      "temperature",
      "top_p",
      "top_k",
      "beam_size",
      "seed",
      "multi_sampling",
      "return_logits",
      "echo",
      "pad_output"
    ]
  },
  "VllmConfig": {},
  "VllmSampler": {
    "__init__": [
      "self",
      "tokenizer",
      "config"
    ],
    "update_params": [
      "self",
      "updated_weights",
      "filter_types"
    ],
    "load_checkpoint": [
      "self",
      "path_or_weights"
    ],
    "_find_total_size": [
      "self",
      "mesh"
    ],
    "_vllm_config": [
      "self",
      "config"
    ],
    "_build_engine_args": [
      "self"
    ],
    "_create_driver": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "_model_runner": [
      "self"
    ],
    "transformer": [
      "self"
    ],
    "transformer_state": [
      "self"
    ],
    "tokenize": [
      "self",
      "input_string"
    ],
    "detokenize": [
      "self",
      "input_strings",
      "request_outputs"
    ],
    "_generate_server_mode": [
      "self",
      "prompts",
      "sampling_params"
    ],
    "__call__": [
      "self",
      "input_strings",
      "max_generation_steps",
      "max_prompt_length",
      "temperature",
      "top_p",
      "top_k",
      "beam_size",
      "seed",
      "multi_sampling",
      "return_logits",
      "echo",
      "pad_output"
    ]
  },
  "_BeamSearchSamplingState": {},
  "init_batched_beam_state": [
    "logits",
    "input_token_buffer",
    "initial_cache",
    "done",
    "positions",
    "logits_buffer",
    "beam_size"
  ],
  "beam_search_step": [
    "logits",
    "done",
    "token_buffer",
    "cache",
    "logits_buffer",
    "state",
    "pad_token_id",
    "decoding_step"
  ],
  "finalize_beam_search_state": [
    "beam_search_state",
    "token_buffer",
    "logits_buffer"
  ],
  "LayerCache": [],
  "Cache": [],
  "_SamplingState": {},
  "_sample_top_p": [
    "probs",
    "p",
    "key",
    "k"
  ],
  "sample_top_p": [
    "logits",
    "key",
    "temperature",
    "top_p",
    "top_k"
  ],
  "sample_best": [
    "logits"
  ],
  "_init_cache": [
    "n_layers",
    "cache_size",
    "batch_size",
    "num_kv_heads",
    "head_dim",
    "dtype"
  ],
  "Sampler": {
    "__init__": [
      "self",
      "transformer",
      "tokenizer",
      "cache_config"
    ],
    "transformer": [
      "self"
    ],
    "transformer_state": [
      "self",
      "state"
    ],
    "dtype": [
      "self"
    ],
    "init_sample_state": [
      "self",
      "all_input_ids",
      "total_sampling_steps",
      "include_logits",
      "forbidden_token_ids",
      "temperature",
      "top_p",
      "top_k",
      "seed",
      "beam_size"
    ],
    "tokenize": [
      "self",
      "input_string"
    ],
    "_sample": [
      "self",
      "logits",
      "eos",
      "cache",
      "sampler_state"
    ],
    "_prefill_fn": [
      "self",
      "params",
      "sampler_state"
    ],
    "_decode_fn": [
      "self",
      "params",
      "sampling_state"
    ],
    "_sample_step": [
      "self",
      "params",
      "sampler_state"
    ],
    "__call__": [
      "self",
      "input_strings",
      "max_generation_steps",
      "max_prompt_length",
      "echo",
      "return_logits",
      "eos_tokens",
      "forbidden_tokens",
      "temperature",
      "top_p",
      "top_k",
      "beam_size",
      "seed",
      "pad_output"
    ]
  },
  "PeftTrainer": [],
  "TrainingHooks": {
    "on_train_start": [
      "self",
      "train_ctx"
    ],
    "on_train_end": [
      "self",
      "train_ctx"
    ],
    "on_train_step_start": [
      "self",
      "train_ctx"
    ],
    "on_train_step_end": [
      "self",
      "train_ctx",
      "train_step",
      "train_loss",
      "step_time"
    ],
    "on_eval_step_start": [
      "self",
      "train_ctx"
    ],
    "on_eval_step_end": [
      "self",
      "train_ctx",
      "eval_loss"
    ]
  },
  "DataHooks": {
    "load_next_train_batch": [
      "self",
      "train_ctx"
    ],
    "load_next_eval_batch": [
      "self",
      "train_ctx"
    ]
  },
  "tqdm": [],
  "ProgressBar": {
    "__init__": [
      "self",
      "metrics_prefix",
      "metrics_logger",
      "initial_steps",
      "max_steps",
      "description"
    ],
    "_update_metric": [
      "self",
      "metric_name",
      "mode",
      "ndigits"
    ],
    "update_metrics": [
      "self",
      "metric_names",
      "mode",
      "ndigits"
    ],
    "_sort_metrics": [
      "self"
    ],
    "update": [
      "self",
      "n"
    ],
    "close": [
      "self"
    ]
  },
  "measure_tflops_per_step": [
    "train_step_fn",
    "model",
    "optimizer",
    "train_example"
  ],
  "approximate_tflops_per_second": [
    "total_model_params",
    "global_batch_size",
    "step_time_delta"
  ],
  "is_lora_enabled": [
    "model"
  ],
  "time_measure": [
    "context",
    "suppress_logging"
  ],
  "_pathways_hbm_usage_gb": [
    "devices"
  ],
  "_jax_hbm_usage_gb": [
    "devices"
  ],
  "show_hbm_usage": [
    "title"
  ],
  "LoggingBackend": [],
  "TensorboardBackend": [],
  "WandbBackend": [],
  "BackendFactory": [],
  "MetricsLoggerOptions": {
    "create_backends": [
      "self"
    ]
  },
  "_calculate_geometric_mean": [
    "x"
  ],
  "MetricsLogger": {
    "__init__": [
      "self",
      "metrics_logger_options"
    ],
    "log": [
      "self",
      "metrics_prefix",
      "metric_name",
      "scalar_value",
      "mode",
      "step"
    ],
    "metric_exists": [
      "self",
      "metrics_prefix",
      "metric_name",
      "mode"
    ],
    "get_metric": [
      "self",
      "metrics_prefix",
      "metric_name",
      "mode"
    ],
    "get_metric_history": [
      "self",
      "metrics_prefix",
      "metric_name",
      "mode"
    ],
    "close": [
      "self"
    ]
  },
  "get_sharding": [
    "x",
    "mesh",
    "pspec"
  ],
  "_ModelInputT": [],
  "P": [],
  "_calculate_global_batch_size": [
    "train_example"
  ],
  "_default_loss_fn": [
    "model",
    "input_tokens",
    "input_mask",
    "positions",
    "attention_mask"
  ],
  "_DEFAULT_CHECKPOINTING_OPTIONS": [],
  "CheckpointManager": {
    "__init__": [
      "self",
      "root_directory",
      "options"
    ],
    "latest_step": [
      "self"
    ],
    "save": [
      "self",
      "step",
      "model",
      "save_only_lora_params",
      "force",
      "custom_metadata"
    ],
    "maybe_restore": [
      "self",
      "model",
      "step",
      "restore_only_lora_params"
    ],
    "close": [
      "self"
    ]
  },
  "InflightThrottler": {
    "__init__": [
      "self",
      "max_inflight"
    ],
    "add_computation": [
      "self",
      "computation"
    ],
    "wait_for_next": [
      "self"
    ],
    "wait_for_all": [
      "self"
    ]
  },
  "ProfilerOptions": {},
  "Profiler": {
    "_lock": [],
    "__init__": [
      "self",
      "initial_step",
      "max_step",
      "profiler_options"
    ],
    "maybe_activate": [
      "self",
      "step"
    ],
    "maybe_deactivate": [
      "self",
      "step"
    ],
    "_set_last_profile_step": [
      "self",
      "profiler_steps",
      "max_step"
    ]
  },
  "DataInput": {},
  "DPOTrainingConfig": {},
  "compute_logps": [
    "model",
    "input_ids",
    "positions",
    "attention_mask",
    "logits_to_keep",
    "completion_mask"
  ],
  "DPOTrainer": {
    "__init__": [
      "self",
      "model",
      "ref_model",
      "optimizer",
      "training_config",
      "tokenizer"
    ],
    "_prepare_inputs": [
      "self",
      "training_input"
    ],
    "_post_process_train_step": [
      "self",
      "aux"
    ],
    "_post_process_eval_step": [
      "self",
      "aux"
    ]
  },
  "dpo_loss_fn": [
    "model",
    "train_example",
    "algorithm",
    "beta",
    "lambda_orpo",
    "label_smoothing"
  ],
  "_generate_ids_and_masks": [
    "input_strings",
    "tokenizer",
    "max_length",
    "left_pad"
  ],
  "_tokenize": [
    "input_string",
    "tokenizer"
  ],
  "_preprocess_dict": [
    "training_input"
  ],
  "process_dpo_record": [
    "record",
    "tokenizer",
    "max_prompt_length",
    "max_response_length"
  ],
  "DpoTrainingConfig": [],
  "DpoTrainer": [],
  "ORPOTrainingConfig": [],
  "ORPOTrainer": [],
  "OrpoTrainingConfig": [],
  "OrpoTrainer": [],
  "create_dummy_model": [
    "model_class",
    "config",
    "mesh",
    "dtype",
    "random_seed",
    "scale"
  ],
  "torch_key_to_jax_key": [
    "mapping",
    "source_key"
  ],
  "stoi": [
    "s"
  ],
  "path_to_key": [
    "path"
  ],
  "load_and_create_model": [
    "file_dir",
    "model_class",
    "config",
    "key_mapping",
    "mesh",
    "preprocess_fn",
    "dtype"
  ],
  "_ModelFamilyInfo": {},
  "_MODEL_FAMILY_INFO_MAPPING": [],
  "split": [
    "model_name"
  ],
  "_standardize_model_version": [
    "raw_model_version"
  ],
  "get_model_family_and_version": [
    "model_name"
  ],
  "get_model_config_category": [
    "model_name"
  ],
  "get_model_config_id": [
    "model_name"
  ],
  "get_model_name_from_model_id": [
    "model_id"
  ],
  "GEMMA3_270M_PT": [],
  "GEMMA3_1B_PT": [],
  "GEMMA3_4B_PT": [],
  "GEMMA3_12B_PT": [],
  "GEMMA3_27B_PT": [],
  "GEMMA3_270M_IT": [],
  "GEMMA3_1B_IT": [],
  "GEMMA3_4B_IT": [],
  "GEMMA3_12B_IT": [],
  "GEMMA3_27B_IT": [],
  "GEMMA3_TOKENIZER": [],
  "create_model_from_checkpoint": [
    "checkpoint_path",
    "model_config",
    "mesh",
    "dtype"
  ],
  "PROMPT_TEMPLATE": [],
  "map_from_upstream_checkpoint": [
    "params",
    "model_type"
  ],
  "_get_key_and_transform_mapping": [
    "cfg"
  ],
  "_make_preprocess_fn": [
    "cfg"
  ],
  "create_model_from_safe_tensors": [
    "file_dir",
    "config",
    "mesh",
    "dtype"
  ],
  "RematConfig": {
    "NONE": [],
    "BLOCK": []
  },
  "ShardingConfig": {
    "get_default_sharding": [
      "is_sampling"
    ]
  },
  "QueryPreAttentionNormalisation": {
    "BY_ONE_OVER_SQRT_HEAD_DIM": [],
    "BY_ONE_OVER_SQRT_EMBED_DIM_DIV_NUM_HEADS": []
  },
  "shard": [
    "x",
    "s"
  ],
  "Embedder": {
    "__init__": [
      "self",
      "vocab_size",
      "embed_dim"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "x"
    ],
    "embed_dim": [
      "self"
    ],
    "num_embed": [
      "self"
    ]
  },
  "Einsum": {
    "__init__": [
      "self",
      "einsum_str",
      "shape"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "apply_rope": [
    "inputs",
    "positions"
  ],
  "K_MASK": [],
  "AttentionType": {
    "GLOBAL": [],
    "LOCAL_SLIDING": []
  },
  "GEMMA3_ATTENTION_PATTERN": [],
  "find_last_one_index": [
    "attn_mask"
  ],
  "create_sliding_window_mask": [
    "attn_mask",
    "sliding_window_size"
  ],
  "Attention": {
    "__init__": [
      "self"
    ],
    "block": [
      "self",
      "x",
      "segment_pos",
      "cache",
      "attn_mask"
    ],
    "__call__": [
      "self",
      "x",
      "segment_pos",
      "cache",
      "attn_mask"
    ],
    "head_dim": [
      "self"
    ],
    "features": [
      "self"
    ],
    "query_pre_attn_scalar": [
      "self"
    ],
    "num_heads": [
      "self"
    ],
    "num_kv_heads": [
      "self"
    ],
    "use_qkv_einsum": [
      "self"
    ],
    "use_gqa": [
      "self"
    ]
  },
  "FeedForward": {
    "__init__": [
      "self",
      "features",
      "hidden_dim"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Block": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "x",
      "segment_pos",
      "cache",
      "attn_mask"
    ]
  },
  "RMSNorm": {
    "__init__": [
      "self",
      "dim"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Gemma3": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "last_tokens",
      "positions",
      "cache",
      "attention_mask",
      "output_hidden_states"
    ],
    "get_model_input": [
      "self"
    ],
    "embed_dim": [
      "self"
    ],
    "num_embed": [
      "self"
    ],
    "num_layers": [
      "self"
    ]
  },
  "Params": [],
  "load_and_format_params": [
    "path"
  ],
  "load_metadata": [
    "path"
  ],
  "_load_params": [
    "path"
  ],
  "_param_remapper": [
    "orig_params"
  ],
  "_unflatten_params": [
    "params"
  ],
  "_peek_vocab_size_from_safetensors": [
    "file_dir"
  ],
  "_create_sliding_mask": [
    "segment_pos",
    "cache_len",
    "sliding_window_size"
  ],
  "_flatten_path": [
    "path"
  ],
  "module_from_linen_variables": [
    "module_factory",
    "variables",
    "map_key_fn",
    "assign_val_fn"
  ],
  "_map_linen_var_names": [
    "key"
  ],
  "_assign_linen_params_to_nnx_state": [
    "state",
    "mapped_path",
    "val"
  ],
  "Transformer": {
    "from_params": [
      "cls",
      "params",
      "version"
    ],
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "last_tokens",
      "positions",
      "cache",
      "attention_mask",
      "output_hidden_states"
    ],
    "embed_dim": [
      "self"
    ],
    "num_embed": [
      "self"
    ],
    "num_layers": [
      "self"
    ],
    "init_cache": [
      "self",
      "batch_size",
      "cache_size",
      "dtype"
    ],
    "get_model_input": [
      "self"
    ]
  },
  "TransformerWithScoreHead": {
    "__init__": [
      "self",
      "transformer",
      "rngs"
    ],
    "__call__": [
      "self"
    ]
  },
  "_compute_attention_masks": [
    "time_step",
    "seq_len",
    "input_mask"
  ],
  "_stack_experts": [
    "params"
  ],
  "MoELayer": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "MLP": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "DecoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "x",
      "segment_pos",
      "cache",
      "attn_mask"
    ]
  },
  "Qwen3": {
    "__init__": [
      "self",
      "config"
    ],
    "init_cache": [
      "self",
      "batch_size",
      "cache_size",
      "dtype"
    ],
    "__call__": [
      "self",
      "input_tokens",
      "positions",
      "cache",
      "attention_mask",
      "output_hidden_states"
    ],
    "get_model_input": [
      "self"
    ]
  },
  "BACKEND_MAPPINGS": [],
  "__all__": [],
  "Sharding": [],
  "MappingEntry": [],
  "_to_sglang_jax_mappings": [],
  "_lora_to_sglang_jax_mappings": [],
  "_to_sglang_jax_transpose_keys": [],
  "_to_sglang_jax_hook_fns": [],
  "_generate_pos_embeddings": [
    "positions",
    "features",
    "rope_theta"
  ],
  "apply_rotary_embedding": [
    "x",
    "sin",
    "cos"
  ],
  "Qwen2": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "input_tokens",
      "positions",
      "cache",
      "attention_mask",
      "output_hidden_states"
    ],
    "get_model_input": [
      "self"
    ]
  },
  "Llama3": {
    "__init__": [
      "self",
      "config"
    ],
    "get_model_input": [
      "self"
    ],
    "__call__": [
      "self",
      "input_tokens",
      "positions",
      "cache",
      "attention_mask"
    ],
    "num_embed": [
      "self"
    ]
  },
  "_to_hf_mappings": [],
  "_lora_to_hf_mappings": [],
  "_to_hf_transpose_keys": [],
  "_to_hf_hook_fns": [],
  "SYSTEM_PROMPT": [],
  "TEMPLATE": [],
  "extract_hash_answer": [
    "text"
  ],
  "get_dataset_from_parquet": [
    "parquet_path",
    "tokenizer"
  ],
  "create_dataset": [
    "dataset_name",
    "batch_size",
    "num_batches"
  ],
  "INPUT_TEMPLATE": [],
  "INPUT_TEMPLATE_IT": [],
  "create_datasets": [
    "dataset_name",
    "global_batch_size",
    "max_target_length",
    "num_train_epochs",
    "tokenizer",
    "instruct_tuned",
    "input_template"
  ],
  "_build_data_loader": [],
  "_Tokenize": {
    "__init__": [
      "self",
      "tokenizer",
      "input_template"
    ],
    "map": [
      "self",
      "element"
    ]
  },
  "_BuildTrainInput": {
    "__init__": [
      "self",
      "max_seq_len",
      "pad_value"
    ],
    "map": [
      "self",
      "tokens"
    ],
    "_pad_up_to_max_len": [
      "self",
      "input_tensor",
      "pad_value"
    ]
  },
  "_FilterOverlength": {
    "__init__": [
      "self",
      "max_seq_len"
    ],
    "filter": [
      "self",
      "element"
    ]
  }
}