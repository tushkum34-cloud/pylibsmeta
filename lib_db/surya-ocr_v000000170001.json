{
  "Settings": {
    "TORCH_DEVICE_MODEL": [
      "self"
    ],
    "DETECTOR_STATIC_CACHE": [
      "self"
    ],
    "LAYOUT_STATIC_CACHE": [
      "self"
    ],
    "FOUNDATION_XLA": [
      "self"
    ],
    "FOUNDATION_STATIC_CACHE": [
      "self"
    ],
    "TABLE_REC_STATIC_CACHE": [
      "self"
    ],
    "OCR_ERROR_STATIC_CACHE": [
      "self"
    ],
    "MODEL_DTYPE": [
      "self"
    ],
    "MODEL_DTYPE_BFLOAT": [
      "self"
    ],
    "INFERENCE_MODE": [
      "self"
    ]
  },
  "settings": [],
  "load_predictors": [
    "device",
    "dtype"
  ],
  "configure_logging": [],
  "get_logger": [],
  "logger": [],
  "LOCK_EXPIRATION": [],
  "join_urls": [
    "url1",
    "url2"
  ],
  "get_model_name": [
    "pretrained_model_name_or_path"
  ],
  "download_file": [
    "remote_path",
    "local_path",
    "chunk_size"
  ],
  "check_manifest": [
    "local_dir"
  ],
  "download_directory": [
    "remote_path",
    "local_dir"
  ],
  "S3DownloaderMixin": {
    "s3_prefix": [],
    "get_local_path": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "get_nearest_pad": [
    "length",
    "pad_multiple"
  ],
  "get_compile_args": [
    "device"
  ],
  "mark_step": [],
  "ModelLoader": {
    "__init__": [
      "self",
      "checkpoint"
    ],
    "model": [
      "self",
      "device",
      "dtype",
      "attention_implementation"
    ],
    "processor": [
      "self",
      "device",
      "dtype"
    ]
  },
  "clean_boxes": [
    "boxes"
  ],
  "rescale_bbox": [
    "bbox",
    "processor_size",
    "image_size"
  ],
  "expand_bbox": [
    "bbox",
    "expansion_factor"
  ],
  "SCRIPT_TOKEN_MAPPING": [],
  "script_ranges": [],
  "get_top_scripts": [
    "text",
    "max_scripts"
  ],
  "is_flash_attn_2_supported": [
    "device"
  ],
  "pad_to_batch_size_repeat": [
    "tensor",
    "batch_size"
  ],
  "pad_to_batch_size": [
    "tensor",
    "batch_size"
  ],
  "PolygonBox": {
    "convert_bbox_to_polygon": [
      "cls",
      "value"
    ],
    "height": [
      "self"
    ],
    "width": [
      "self"
    ],
    "area": [
      "self"
    ],
    "bbox": [
      "self"
    ],
    "rescale": [
      "self",
      "processor_size",
      "image_size"
    ],
    "round": [
      "self",
      "divisor"
    ],
    "fit_to_bounds": [
      "self",
      "bounds"
    ],
    "merge": [
      "self",
      "other"
    ],
    "merge_left": [
      "self",
      "other"
    ],
    "merge_right": [
      "self",
      "other"
    ],
    "expand": [
      "self",
      "x_margin",
      "y_margin"
    ],
    "intersection_polygon": [
      "self",
      "other"
    ],
    "intersection_area": [
      "self",
      "other",
      "x_margin",
      "y_margin"
    ],
    "x_overlap": [
      "self",
      "other",
      "x_margin"
    ],
    "y_overlap": [
      "self",
      "other",
      "y_margin"
    ],
    "intersection_pct": [
      "self",
      "other",
      "x_margin",
      "y_margin"
    ],
    "shift": [
      "self",
      "x_shift",
      "y_shift"
    ],
    "clamp": [
      "self",
      "bbox"
    ],
    "center": [
      "self"
    ],
    "distance": [
      "self",
      "other"
    ],
    "__hash__": [
      "self"
    ]
  },
  "BasePredictor": {
    "model_loader_cls": [],
    "default_batch_sizes": [],
    "torch_dtype": [],
    "disable_tqdm": [
      "self",
      "value"
    ],
    "__init__": [
      "self",
      "checkpoint",
      "device",
      "dtype",
      "attention_implementation"
    ],
    "to": [
      "self",
      "device_dtype"
    ],
    "get_batch_size": [
      "self"
    ],
    "pad_to_batch_size": [
      "tensor",
      "batch_size"
    ],
    "__call__": [
      "self"
    ]
  },
  "SuryaPreTrainedModel": {
    "_check_and_adjust_attn_implementation": [
      "self",
      "attn_implementation"
    ]
  },
  "TaskNames": {
    "block_without_boxes": [],
    "ocr_with_boxes": [],
    "ocr_without_boxes": [],
    "layout": [],
    "table_structure": []
  },
  "TASK_NAMES": [],
  "SuryaModelOutput": {},
  "FlashAttentionKwargs": {},
  "KwargsForCausalLM": {},
  "DistanceProjection": {
    "__init__": [
      "self",
      "in_features",
      "out_features"
    ],
    "forward": [
      "self",
      "x"
    ],
    "init_weights": [
      "self"
    ]
  },
  "BboxHead": {
    "__init__": [
      "self",
      "in_features",
      "out_features"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SuryaModel": {
    "config_class": [],
    "supports_gradient_checkpointing": [],
    "_skip_keys_device_placement": [],
    "_supports_flash_attn_2": [],
    "_supports_sdpa": [],
    "_supports_flex_attn": [],
    "_supports_cache_class": [],
    "_supports_quantized_cache": [],
    "_supports_static_cache": [],
    "_supports_attention_backend": [],
    "main_input_name": [],
    "_tied_weights_keys": [],
    "__init__": [
      "self",
      "config",
      "embedder",
      "vision_encoder",
      "decoder"
    ],
    "tie_weights": [
      "self"
    ],
    "_tie_weights": [
      "self"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "maybe_static_pad_image_inputs": [
      "self",
      "chunk_pixels",
      "chunk_grid_thw",
      "actual_chunk_len",
      "encoder_chunk_size"
    ],
    "get_image_embeddings": [
      "self",
      "pixel_values",
      "grid_thw",
      "encoder_chunk_size",
      "valid_batch_size",
      "max_batch_size"
    ],
    "embed_ids_boxes_images": [
      "self",
      "input_ids",
      "image_embeddings",
      "encoder_chunk_size",
      "valid_batch_size",
      "input_boxes",
      "embed_boxes"
    ],
    "get_2d_learned_embeddings": [
      "self",
      "grid_thw",
      "device",
      "bbox_size"
    ],
    "get_logits": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "input_ids",
      "image_embeddings",
      "labels",
      "image_tiles",
      "grid_thw",
      "inputs_embeds",
      "attention_mask",
      "position_ids",
      "cache_position",
      "past_key_values",
      "output_hidden_states",
      "output_attentions",
      "use_cache",
      "encoder_chunk_size",
      "cache_idxs",
      "num_valid_tokens",
      "prefill",
      "text_lengths",
      "valid_batch_size",
      "input_boxes",
      "embed_boxes",
      "logits_to_keep"
    ],
    "_update_causal_mask": [
      "self",
      "attention_mask",
      "input_tensor",
      "cache_position",
      "past_key_values",
      "output_attentions"
    ],
    "_prepare_4d_causal_attention_mask_with_cache_position": [
      "attention_mask",
      "sequence_length",
      "target_length",
      "dtype",
      "device",
      "cache_position",
      "batch_size",
      "config",
      "past_key_values"
    ]
  },
  "SuryaXLAModel": {
    "get_image_embeddings": [
      "self",
      "pixel_values",
      "grid_thw",
      "encoder_chunk_size",
      "valid_batch_size",
      "max_batch_size"
    ],
    "embed_ids_boxes_images": [
      "self",
      "input_ids",
      "image_embeddings",
      "encoder_chunk_size",
      "valid_batch_size",
      "input_boxes",
      "embed_boxes"
    ],
    "get_2d_learned_embeddings": [
      "self",
      "grid_thw",
      "bbox_size"
    ]
  },
  "SuryaModelConfig": {
    "model_type": [],
    "is_composition": [],
    "__init__": [
      "self",
      "vocab_size",
      "bbox_size",
      "blank_bbox_token_id",
      "bos_token_id",
      "eos_token_id",
      "pad_token_id",
      "image_token_id",
      "register_token_ids",
      "eoi_token_id",
      "beacon_token_id",
      "special_token_count",
      "max_sequence_length",
      "special_ocr_tokens",
      "vision_encoder",
      "decoder",
      "tasks",
      "bbox_embed_size",
      "num_register_tokens",
      "image_embed_encoding_size",
      "image_embed_encoding_multiplier",
      "num_beacon_tokens",
      "beacon_token_interval",
      "sliding_window",
      "multi_output_distance",
      "max_multi_out"
    ]
  },
  "_get_unpad_data": [
    "attention_mask"
  ],
  "_upad_input": [
    "query_layer",
    "key_layer",
    "value_layer",
    "query_length",
    "indices_k",
    "cu_seqlens_k",
    "max_seqlen_in_batch_k"
  ],
  "flash_attn_prefill": [
    "module",
    "query_states",
    "key_states",
    "value_states",
    "attention_mask",
    "dropout",
    "scaling",
    "query_length",
    "batch_size",
    "indices_k",
    "cu_seqlens_k",
    "max_seqlen_in_batch_k"
  ],
  "flash_attn_decode": [
    "module",
    "query_states",
    "key_states",
    "value_states",
    "attention_mask",
    "scaling"
  ],
  "Qwen2MLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "rotate_half": [
    "x"
  ],
  "apply_rotary_pos_emb": [
    "q",
    "k",
    "cos",
    "sin",
    "position_ids",
    "unsqueeze_dim"
  ],
  "repeat_kv": [
    "hidden_states",
    "n_rep"
  ],
  "eager_attention_forward": [
    "module",
    "query",
    "key",
    "value",
    "attention_mask",
    "scaling",
    "dropout"
  ],
  "Qwen2Attention": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_embeddings",
      "attention_mask",
      "past_key_value",
      "cache_position",
      "cache_idxs",
      "num_valid_tokens",
      "text_lengths",
      "prefill"
    ]
  },
  "Qwen2RMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "Qwen2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_value",
      "output_attentions",
      "use_cache",
      "cache_position",
      "cache_idxs",
      "num_valid_tokens",
      "text_lengths",
      "prefill",
      "position_embeddings"
    ]
  },
  "Qwen2RotaryEmbedding": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "_dynamic_frequency_update": [
      "self",
      "position_ids",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "Qwen2PreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "_skip_keys_device_placement": [],
    "_supports_flash_attn_2": [],
    "_supports_sdpa": [],
    "_supports_flex_attn": [],
    "_supports_cache_class": [],
    "_supports_quantized_cache": [],
    "_supports_static_cache": [],
    "_supports_attention_backend": [],
    "_init_weights": [
      "self",
      "module"
    ]
  },
  "SuryaDecoderModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "cache_position",
      "cache_idxs",
      "num_valid_tokens",
      "text_lengths",
      "prefill"
    ]
  },
  "SuryaDecoderConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "base_model_tp_plan": [],
    "base_model_pp_plan": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_theta",
      "rope_scaling",
      "use_sliding_window",
      "sliding_window",
      "max_window_layers",
      "attention_dropout"
    ]
  },
  "SimpleTokenEmbedder": {
    "__init__": [
      "self",
      "config"
    ],
    "embed": [
      "self",
      "input_tokens",
      "input_boxes",
      "embed_boxes"
    ]
  },
  "TaskDict": {},
  "TasksDict": {},
  "ProcessorInput": {},
  "ImageInput": {},
  "TextInput": {},
  "ProcessorOutput": {},
  "create_token_regex": [
    "tokens"
  ],
  "Qwen2Tokenizer": {},
  "GreedyMathUTF16Tokenizer": {
    "vocab_files_names": [],
    "model_input_names": [],
    "is_fast": [],
    "_to_utf16_units": [
      "s"
    ],
    "_from_utf16_units": [
      "units"
    ],
    "_build_trie": [
      "cls",
      "token_to_id"
    ],
    "_build_escape_patterns": [
      "self",
      "math_token_to_rawid"
    ],
    "_encode_math_greedy": [
      "cls",
      "s",
      "trie",
      "math_base",
      "debug"
    ],
    "__init__": [
      "self",
      "vocab_file",
      "specials_file",
      "specials_dict_file"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "_encode_core": [
      "self",
      "text"
    ],
    "_fix_latex_escapes": [
      "self",
      "text"
    ],
    "_decode_core": [
      "self",
      "ids"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "decode": [
      "self",
      "token_ids",
      "skip_special_tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ]
  },
  "SuryaOCRTokenizer": {
    "__init__": [
      "self",
      "special_tokens",
      "model_checkpoint"
    ],
    "get_vocab": [
      "self"
    ],
    "_add_tokens": [
      "self",
      "new_tokens",
      "special_tokens"
    ],
    "vocab_size": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "__call__": [
      "self",
      "texts",
      "tasks"
    ],
    "decode": [
      "self",
      "token_ids"
    ]
  },
  "EOS_TOKEN": [],
  "EOI_TOKEN": [],
  "IMAGE_TOKEN": [],
  "PAD_TOKEN": [],
  "NO_OUTPUT_TOKEN": [],
  "IMAGE_ROTATED_TOKEN": [],
  "REGISTER_TOKENS": [],
  "BEACON_TOKEN": [],
  "NOMATH_TOKEN": [],
  "OCR_WITH_BOXES_BOS_TOKEN": [],
  "OCR_WITHOUT_BOXES_BOS_TOKEN": [],
  "BLOCK_WITHOUT_BOXES_TOKEN": [],
  "LAYOUT_BOS_TOKEN": [],
  "TABLE_STRUCTURE_BOS_TOKEN": [],
  "SuryaOCRProcessor": {
    "attributes": [],
    "image_processor_class": [],
    "ocr_tokenizer_class": [],
    "rescale_factor": [],
    "image_mean": [],
    "image_std": [],
    "__init__": [
      "self",
      "ocr_tokenizer",
      "blank_bbox_token_id",
      "num_register_tokens",
      "patch_size",
      "merge_size",
      "num_beacon_tokens",
      "beacon_token_interval",
      "model_device"
    ],
    "vocab_size": [
      "self"
    ],
    "image_processor": [
      "self",
      "image"
    ],
    "scale_to_fit": [
      "img",
      "max_size",
      "min_size"
    ],
    "_image_processor": [
      "self",
      "image"
    ],
    "_process_and_tile": [
      "self",
      "image"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_process_text_input": [
      "self",
      "text_input",
      "task"
    ],
    "_process_input": [
      "self",
      "input_dict",
      "task"
    ],
    "_process_ocr_with_boxes": [
      "self",
      "mixed_input",
      "bos_token_id",
      "task"
    ],
    "_process_layout": [
      "self",
      "mixed_input",
      "bos_token_id"
    ],
    "_process_table_structure": [
      "self",
      "mixed_input",
      "bos_token_id"
    ],
    "_process_ocr_without_boxes": [
      "self",
      "mixed_input",
      "bos_token_id",
      "task"
    ],
    "_process_block_without_boxes": [
      "self",
      "mixed_input",
      "bos_token_id",
      "task"
    ],
    "align_long_axis": [
      "self",
      "image"
    ],
    "__call__": [
      "self",
      "mixed_batch",
      "padding_side",
      "device",
      "pad_to_multiple"
    ],
    "decode": [
      "self",
      "tokens",
      "task"
    ]
  },
  "Qwen2_5_VLMLP": {
    "__init__": [
      "self",
      "config",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "Qwen2_5_VisionPatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "temporal_patch_size",
      "in_channels",
      "embed_dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen2_5_VisionRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "Qwen2_5_VLPatchMerger": {
    "__init__": [
      "self",
      "dim",
      "context_dim",
      "spatial_merge_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "apply_rotary_pos_emb_flashatt": [
    "q",
    "k",
    "cos",
    "sin"
  ],
  "Qwen2_5_VLVisionXLASdpaAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb",
      "position_embeddings"
    ]
  },
  "Qwen2_5_VLVisionXLAFlashAttention2": {
    "__init__": [
      "self",
      "dim",
      "num_heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb",
      "position_embeddings"
    ]
  },
  "Qwen2_5_VLVisionFlashAttention2": {
    "__init__": [
      "self",
      "dim",
      "num_heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb",
      "position_embeddings"
    ]
  },
  "apply_rotary_pos_emb_vision": [
    "q",
    "k",
    "cos",
    "sin"
  ],
  "Qwen2_5_VLVisionAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb",
      "position_embeddings"
    ]
  },
  "Qwen2_5_VLVisionSdpaAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads"
    ],
    "unpack_qkv_with_mask": [
      "self",
      "q",
      "k",
      "v",
      "cu_seqlens"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb",
      "position_embeddings"
    ]
  },
  "QWEN2_5_VL_VISION_ATTENTION_CLASSES": [],
  "Qwen2_5_VLVisionBlock": {
    "__init__": [
      "self",
      "config",
      "attn_implementation"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb",
      "position_embeddings"
    ]
  },
  "Qwen2_5_VL_START_DOCSTRING": [],
  "Qwen2_5_VLPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "_skip_keys_device_placement": [],
    "_supports_flash_attn_2": [],
    "_supports_sdpa": [],
    "_supports_cache_class": [],
    "_supports_static_cache": [],
    "_init_weights": [
      "self",
      "module"
    ]
  },
  "Qwen2_5_VisionTransformerPretrainedModel": {
    "config_class": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "forward": [
      "self",
      "hidden_states",
      "grid_thw"
    ]
  },
  "SuryaEncoderModel": {
    "image_size": [
      "self"
    ],
    "hidden_size": [
      "self"
    ],
    "embed_images": [
      "self",
      "image_batch",
      "grid_thw"
    ]
  },
  "SuryaEncoderConfig": {
    "model_type": [],
    "base_config_key": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "depth",
      "hidden_size",
      "hidden_act",
      "intermediate_size",
      "num_heads",
      "in_channels",
      "patch_size",
      "spatial_merge_size",
      "spatial_patch_size",
      "temporal_patch_size",
      "tokens_per_second",
      "window_size",
      "out_hidden_size",
      "fullatt_block_indexes",
      "initializer_range",
      "image_size"
    ]
  },
  "SuryaEncoderImageProcessor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "images"
    ],
    "numpy_resize": [
      "cls",
      "image",
      "size",
      "interpolation"
    ],
    "process_inner": [
      "self",
      "images"
    ],
    "preprocess": [
      "self",
      "images",
      "return_tensors"
    ],
    "pad_image": [
      "cls",
      "image",
      "size",
      "data_format",
      "input_data_format",
      "pad_value"
    ],
    "align_long_axis": [
      "cls",
      "image",
      "size"
    ],
    "normalize": [
      "cls",
      "image",
      "mean",
      "std",
      "data_format",
      "input_data_format"
    ]
  },
  "_EXPECTED_OUTPUT_SHAPE": [],
  "DonutSwinEncoderOutput": {},
  "DonutSwinModelOutput": {},
  "window_partition": [
    "input_feature",
    "window_size"
  ],
  "window_reverse": [
    "windows",
    "window_size",
    "height",
    "width"
  ],
  "DonutSwinEmbeddings": {
    "__init__": [
      "self",
      "config",
      "use_mask_token"
    ],
    "interpolate_pos_encoding": [
      "self",
      "embeddings",
      "height",
      "width"
    ],
    "forward": [
      "self",
      "pixel_values",
      "bool_masked_pos",
      "interpolate_pos_encoding"
    ]
  },
  "DonutSwinPatchEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "maybe_pad": [
      "self",
      "pixel_values",
      "height",
      "width"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "DonutSwinPatchMerging": {
    "__init__": [
      "self",
      "input_resolution",
      "dim",
      "norm_layer"
    ],
    "maybe_pad": [
      "self",
      "input_feature",
      "height",
      "width"
    ],
    "forward": [
      "self",
      "input_feature",
      "input_dimensions"
    ]
  },
  "DonutSwinSelfAttention": {
    "__init__": [
      "self",
      "config",
      "dim",
      "num_heads",
      "num_kv_heads",
      "window_size"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "transpose_kv_for_scores": [
      "self",
      "x",
      "repeats"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "output_attentions"
    ]
  },
  "DonutSwinSelfOutput": {
    "__init__": [
      "self",
      "config",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "DonutSwinAttention": {
    "__init__": [
      "self",
      "config",
      "dim",
      "num_heads",
      "num_kv_heads",
      "window_size"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "output_attentions"
    ]
  },
  "DonutSwinIntermediate": {
    "__init__": [
      "self",
      "config",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DonutSwinOutput": {
    "__init__": [
      "self",
      "config",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DonutSwinLayer": {
    "__init__": [
      "self",
      "config",
      "dim",
      "input_resolution",
      "num_heads",
      "num_kv_heads",
      "shift_size"
    ],
    "set_shift_and_window_size": [
      "self",
      "input_resolution"
    ],
    "get_attn_mask": [
      "self",
      "height",
      "width",
      "dtype",
      "device"
    ],
    "maybe_pad": [
      "self",
      "hidden_states",
      "height",
      "width"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_dimensions",
      "head_mask",
      "output_attentions",
      "always_partition"
    ]
  },
  "DonutSwinStage": {
    "__init__": [
      "self",
      "config",
      "layer_num",
      "dim",
      "input_resolution",
      "depth",
      "num_heads",
      "num_kv_heads",
      "downsample"
    ],
    "build_2d_sincos_position_embedding": [
      "width",
      "height",
      "embed_dim",
      "temperature",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_dimensions",
      "head_mask",
      "output_attentions",
      "always_partition"
    ]
  },
  "DonutSwinEncoder": {
    "__init__": [
      "self",
      "config",
      "grid_size"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_dimensions",
      "head_mask",
      "output_attentions",
      "output_hidden_states",
      "output_hidden_states_before_downsampling",
      "always_partition",
      "return_dict"
    ]
  },
  "DonutSwinPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "main_input_name": [],
    "supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "_init_weights": [
      "self",
      "module"
    ]
  },
  "_MAX_SQRT_GRADIENT": [],
  "WrappedEmbedding": {
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "SuryaADETRDecoderRMSNorm": {
    "__init__": [
      "self",
      "dim",
      "eps"
    ],
    "_norm": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "SuryaADETRDecoderRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "base",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "position_ids",
      "seq_len"
    ]
  },
  "SuryaADETRDecoderSdpaCrossAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "encoder_attention_mask",
      "use_cache"
    ],
    "_clear_cache": [
      "self"
    ],
    "_setup_cache": [
      "self",
      "batch_size",
      "device",
      "dtype"
    ],
    "_update_cache": [
      "self",
      "key_states",
      "value_states"
    ]
  },
  "SuryaADETRDecoderSdpaAttention": {
    "__init__": [
      "self",
      "config",
      "static_cache",
      "max_boxes"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "attention_mask",
      "cache_position",
      "use_cache",
      "window_attn"
    ],
    "_setup_cache": [
      "self",
      "batch_size",
      "device",
      "dtype"
    ],
    "_clear_cache": [
      "self"
    ],
    "_update_static_cache": [
      "self",
      "key_states",
      "value_states"
    ],
    "_update_dynamic_cache": [
      "self",
      "key_states",
      "value_states"
    ],
    "_update_cache": [
      "self",
      "key_states",
      "value_states"
    ]
  },
  "SuryaADETRDecoderMlp": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SuryaADETRDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "static_cache",
      "max_boxes"
    ],
    "forward": [
      "self",
      "activations",
      "position_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "cache_position",
      "use_cache"
    ],
    "double_res_forward": [
      "self",
      "activations",
      "position_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "cache_position",
      "use_cache"
    ]
  },
  "SuryaADETRDecoderPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "_skip_keys_device_placement": [],
    "_supports_flash_attn_2": [],
    "_supports_sdpa": [],
    "_supports_cache_class": [],
    "_supports_quantized_cache": [],
    "_init_weights": [
      "self",
      "module"
    ],
    "_setup_cache": [
      "self",
      "config",
      "batch",
      "device",
      "dtype"
    ],
    "_clear_cache": [
      "self"
    ],
    "reset_cache": [
      "self",
      "batch",
      "device",
      "dtype"
    ],
    "_tie_weights": [
      "self"
    ],
    "tie_weights": [
      "self"
    ]
  },
  "SuryaADETRDecoderModel": {
    "__init__": [
      "self",
      "config",
      "embedder",
      "max_boxes",
      "static_cache"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "input_boxes_counts",
      "inputs_embeds",
      "position_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "cache_position",
      "use_cache",
      "output_hidden_states",
      "return_dict",
      "prefill"
    ],
    "_update_causal_mask": [
      "self",
      "attention_mask",
      "input_tensor",
      "cache_position"
    ]
  },
  "convert_if_not_rgb": [
    "images"
  ],
  "open_pdf": [
    "pdf_filepath"
  ],
  "get_page_images": [
    "doc",
    "indices",
    "dpi"
  ],
  "slice_bboxes_from_image": [
    "image",
    "bboxes"
  ],
  "slice_polys_from_image": [
    "image",
    "polys"
  ],
  "slice_and_pad_poly": [
    "image_array",
    "coordinates"
  ],
  "get_name_from_path": [
    "path"
  ],
  "load_pdf": [
    "pdf_path",
    "page_range",
    "dpi"
  ],
  "load_image": [
    "image_path"
  ],
  "load_from_file": [
    "input_path",
    "page_range",
    "dpi"
  ],
  "load_from_folder": [
    "folder_path",
    "page_range",
    "dpi"
  ],
  "load_lang_file": [
    "lang_path",
    "names"
  ],
  "OCRErrorDetectionResult": {},
  "OCRErrorModelLoader": {
    "__init__": [
      "self",
      "checkpoint"
    ],
    "model": [
      "self",
      "device",
      "dtype",
      "attention_implementation"
    ],
    "processor": [
      "self",
      "device",
      "dtype"
    ]
  },
  "VOCAB_FILES_NAMES": [],
  "load_vocab": [
    "vocab_file"
  ],
  "whitespace_tokenize": [
    "text"
  ],
  "DistilBertTokenizer": {
    "vocab_files_names": [],
    "model_input_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "do_basic_tokenize",
      "never_split",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "do_lower_case": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text",
      "split_special_tokens"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ]
  },
  "BasicTokenizer": {
    "__init__": [
      "self",
      "do_lower_case",
      "never_split",
      "tokenize_chinese_chars",
      "strip_accents",
      "do_split_on_punc"
    ],
    "tokenize": [
      "self",
      "text",
      "never_split"
    ],
    "_run_strip_accents": [
      "self",
      "text"
    ],
    "_run_split_on_punc": [
      "self",
      "text",
      "never_split"
    ],
    "_tokenize_chinese_chars": [
      "self",
      "text"
    ],
    "_is_chinese_char": [
      "self",
      "cp"
    ],
    "_clean_text": [
      "self",
      "text"
    ]
  },
  "WordpieceTokenizer": {
    "__init__": [
      "self",
      "vocab",
      "unk_token",
      "max_input_chars_per_word"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "OCRErrorPredictor": {
    "model_loader_cls": [],
    "batch_size": [],
    "default_batch_sizes": [],
    "__call__": [
      "self",
      "texts",
      "batch_size"
    ],
    "batch_ocr_error_detection": [
      "self",
      "texts",
      "batch_size"
    ]
  },
  "ID2LABEL": [],
  "DistilBertConfig": {
    "model_type": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "max_position_embeddings",
      "sinusoidal_pos_embds",
      "n_layers",
      "n_heads",
      "dim",
      "hidden_dim",
      "dropout",
      "attention_dropout",
      "activation",
      "initializer_range",
      "qa_dropout",
      "seq_classif_dropout",
      "pad_token_id"
    ]
  },
  "DistilBertOnnxConfig": {
    "inputs": [
      "self"
    ]
  },
  "create_sinusoidal_embeddings": [
    "n_pos",
    "dim",
    "out"
  ],
  "Embeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "input_embeds"
    ]
  },
  "MultiHeadSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "prune_heads": [
      "self",
      "heads"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask",
      "head_mask",
      "output_attentions"
    ]
  },
  "DistilBertFlashAttention2": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask",
      "head_mask",
      "output_attentions"
    ],
    "_flash_attention_forward": [
      "self",
      "query_states",
      "key_states",
      "value_states",
      "attention_mask",
      "query_length",
      "dropout",
      "softmax_scale"
    ],
    "_upad_input": [
      "self",
      "query_layer",
      "key_layer",
      "value_layer",
      "attention_mask",
      "query_length"
    ]
  },
  "FFN": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input"
    ],
    "ff_chunk": [
      "self",
      "input"
    ]
  },
  "DISTILBERT_ATTENTION_CLASSES": [],
  "TransformerBlock": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask",
      "head_mask",
      "output_attentions"
    ]
  },
  "Transformer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask",
      "head_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DistilBertPreTrainedModel": {
    "config_class": [],
    "load_tf_weights": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_supports_flash_attn_2": [],
    "_init_weights": [
      "self",
      "module"
    ]
  },
  "DistilBertModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_position_embeddings": [
      "self"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "new_embeddings"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "head_mask",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "DistilBertForSequenceClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "get_position_embeddings": [
      "self"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "head_mask",
      "inputs_embeds",
      "labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "draw_bboxes_on_image": [
    "bboxes",
    "image",
    "labels",
    "label_font_size",
    "color"
  ],
  "draw_polys_on_image": [
    "corners",
    "image",
    "labels",
    "box_padding",
    "label_offset",
    "label_font_size",
    "color"
  ],
  "filepath": [],
  "render_text_as_html": [
    "bboxes",
    "texts",
    "image_size",
    "base_font_size",
    "scaler"
  ],
  "get_font_path": [
    "langs"
  ],
  "strip_html_tags": [
    "html_text"
  ],
  "get_text_size": [
    "text",
    "font"
  ],
  "render_text": [
    "draw",
    "text",
    "s_bbox",
    "bbox_width",
    "bbox_height",
    "font_path",
    "box_font_size"
  ],
  "draw_text_with_playwright": [
    "bboxes",
    "texts",
    "image_size"
  ],
  "draw_text_on_image": [
    "bboxes",
    "texts",
    "image_size",
    "font_path",
    "max_font_size",
    "res_upscale"
  ],
  "LayoutBox": {},
  "LayoutResult": {},
  "LayoutPredictor": {
    "batch_size": [],
    "default_batch_sizes": [],
    "__init__": [
      "self",
      "foundation_predictor"
    ],
    "disable_tqdm": [
      "self",
      "value"
    ],
    "__call__": [
      "self",
      "images",
      "batch_size",
      "top_k"
    ]
  },
  "LAYOUT_PRED_RELABEL": [],
  "FoundationModelLoader": {
    "__init__": [
      "self",
      "checkpoint"
    ],
    "model": [
      "self",
      "device",
      "dtype",
      "attention_implementation"
    ],
    "processor": [
      "self",
      "device",
      "dtype"
    ]
  },
  "ContinuousBatchInput": {},
  "ContinuousBatchOutput": {},
  "FoundationPrompt": {},
  "FoundationPredictor": {
    "model_loader_cls": [],
    "batch_size": [],
    "torch_dtype": [],
    "default_batch_sizes": [],
    "encoder_chunk_sizes": [],
    "extra_token_count": [],
    "tasks": [],
    "__init__": [
      "self",
      "checkpoint",
      "device",
      "dtype",
      "attention_implementation"
    ],
    "to": [
      "self",
      "device_dtype"
    ],
    "get_encoder_chunk_size": [
      "self"
    ],
    "setup_cache": [
      "self",
      "batch_size",
      "max_cache_len",
      "max_sliding_window"
    ],
    "num_empty_slots": [
      "self"
    ],
    "num_active_slots": [
      "self"
    ],
    "prepare_input": [
      "self",
      "task_names",
      "images",
      "input_text",
      "math_modes"
    ],
    "process_outputs": [
      "self",
      "outputs",
      "max_lookahead_tokens"
    ],
    "maybe_insert_beacon_tokens": [
      "self",
      "input_ids",
      "input_boxes",
      "num_predicted_tokens",
      "num_new_tokens"
    ],
    "decode": [
      "self",
      "current_inputs",
      "max_lookahead_tokens"
    ],
    "pad_and_shift_input_ids_position_ids": [
      "self",
      "input_ids",
      "bbox_preds",
      "position_ids",
      "new_seq_len"
    ],
    "get_cache_position": [
      "self",
      "seq_len",
      "attention_mask",
      "prefill"
    ],
    "prefill": [
      "self",
      "current_inputs",
      "max_lookahead_tokens"
    ],
    "get_max_image_token_count": [
      "self",
      "images",
      "tasks"
    ],
    "prediction_loop": [
      "self",
      "images",
      "input_texts",
      "task_names",
      "batch_size",
      "max_tokens",
      "max_sliding_window",
      "math_mode",
      "drop_repeated_tokens",
      "max_lookahead_tokens",
      "top_k",
      "tqdm_desc"
    ]
  },
  "detect_repeat_token": [
    "predicted_tokens",
    "max_repeats"
  ],
  "prediction_to_polygon_batch": [
    "pred",
    "img_sizes",
    "bbox_scaler",
    "skew_scaler",
    "skew_min"
  ],
  "StaticOpsCache": {
    "__init__": [
      "self",
      "config",
      "batch_size",
      "max_cache_len",
      "text_sliding_window",
      "device",
      "dtype"
    ],
    "update": [
      "self",
      "key_states",
      "value_states",
      "layer_idx",
      "cache_kwargs"
    ],
    "_prefill_update": [
      "self",
      "key_cache",
      "value_cache",
      "key_states",
      "value_states",
      "text_token_counts",
      "cache_kwargs"
    ],
    "decode_attention_mask_update": [
      "self",
      "num_valid_tokens",
      "cache_idxs"
    ],
    "prefill_attention_mask_update": [
      "self",
      "attention_mask",
      "merge_idxs",
      "valid_batch_size",
      "text_lengths"
    ],
    "_decode_update": [
      "self",
      "key_cache",
      "value_cache",
      "key_states",
      "value_states",
      "text_token_counts",
      "cache_kwargs"
    ],
    "get_seq_length": [
      "self",
      "layer_idx"
    ]
  },
  "DynamicOpsCache": {
    "__init__": [
      "self",
      "config",
      "batch_size",
      "max_cache_len",
      "text_sliding_window",
      "device",
      "dtype"
    ],
    "update": [
      "self",
      "key_states",
      "value_states",
      "layer_idx",
      "cache_kwargs"
    ],
    "update_text_counts": [
      "self",
      "merge_idxs",
      "valid_batch_size",
      "new_text_lens"
    ],
    "prefill_attention_mask_update": [
      "self",
      "prefill_attention_mask",
      "merge_idxs",
      "valid_batch_mask",
      "text_lengths"
    ],
    "_prefill_update": [
      "self",
      "key_cache",
      "value_cache",
      "key_states",
      "value_states",
      "text_token_counts",
      "cache_kwargs"
    ],
    "decode_attention_mask_update": [
      "self",
      "num_valid_tokens",
      "cache_idxs"
    ],
    "_decode_update": [
      "self",
      "key_cache",
      "value_cache",
      "key_states",
      "value_states",
      "text_token_counts",
      "cache_kwargs"
    ],
    "get_seq_length": [
      "self",
      "layer_idx"
    ]
  },
  "BaseChar": {
    "validate_confidence": [
      "cls",
      "v"
    ]
  },
  "TextChar": {},
  "TextWord": {},
  "TextLine": {},
  "OCRResult": {},
  "RecognitionPredictor": {
    "batch_size": [],
    "default_batch_sizes": [],
    "__init__": [
      "self",
      "foundation_predictor"
    ],
    "disable_tqdm": [
      "self",
      "value"
    ],
    "detect_and_slice_bboxes": [
      "self",
      "images",
      "task_names",
      "det_predictor",
      "detection_batch_size",
      "highres_images"
    ],
    "slice_bboxes": [
      "self",
      "images",
      "task_names",
      "bboxes",
      "polygons",
      "input_text"
    ],
    "get_bboxes_text": [
      "self",
      "flat",
      "predicted_tokens",
      "scores",
      "predicted_polygons",
      "drop_repeated_text"
    ],
    "__call__": [
      "self",
      "images",
      "task_names",
      "det_predictor",
      "detection_batch_size",
      "recognition_batch_size",
      "highres_images",
      "bboxes",
      "polygons",
      "input_text",
      "sort_lines",
      "math_mode",
      "return_words",
      "drop_repeated_text",
      "max_sliding_window",
      "max_tokens",
      "filter_tag_list"
    ]
  },
  "MATH_SYMBOLS": [],
  "unwrap_math": [
    "text"
  ],
  "MATH_BLOCK": [],
  "STRIP_TAGS": [],
  "DEFAULT_TAGS_TO_FILTER": [],
  "filter_blacklist_tags": [
    "text_chars",
    "tags_to_filter"
  ],
  "clean_math_tags": [
    "html"
  ],
  "sort_text_lines": [
    "lines",
    "tolerance"
  ],
  "clean_close_polygons": [
    "bboxes",
    "thresh"
  ],
  "words_from_chars": [
    "chars",
    "line_box"
  ],
  "truncate_repetitions": [
    "text",
    "min_len"
  ],
  "extract_tags": [
    "proposed_tags"
  ],
  "tag_pattern": [],
  "cleanup_math": [
    "line"
  ],
  "fix_unbalanced_tags": [
    "text_chars",
    "special_tokens"
  ],
  "CODE_TO_LANGUAGE": [],
  "LANGUAGE_TO_CODE": [],
  "TableCell": {
    "label": [
      "self"
    ]
  },
  "TableRow": {
    "label": [
      "self"
    ]
  },
  "TableCol": {
    "label": [
      "self"
    ]
  },
  "TableResult": {},
  "LabelShaper": {
    "__init__": [
      "self"
    ],
    "dict_to_labels": [
      "self",
      "label_components"
    ],
    "component_idx": [
      "self",
      "key"
    ],
    "get_box_property": [
      "self",
      "key",
      "add_special_tokens"
    ],
    "component_idx_dict": [
      "self"
    ],
    "convert_polygons_to_bboxes": [
      "self",
      "label_components"
    ],
    "convert_bbox_to_polygon": [
      "self",
      "box",
      "skew_scaler",
      "skew_min"
    ]
  },
  "TableRecModelLoader": {
    "__init__": [
      "self",
      "checkpoint"
    ],
    "model": [
      "self",
      "device",
      "dtype",
      "attention_implementation"
    ],
    "processor": [
      "self",
      "device",
      "dtype"
    ]
  },
  "TableRecPredictor": {
    "model_loader_cls": [],
    "batch_size": [],
    "default_batch_sizes": [],
    "__call__": [
      "self",
      "images",
      "batch_size"
    ],
    "inference_loop": [
      "self",
      "encoder_hidden_states",
      "batch_input_ids",
      "current_batch_size",
      "batch_size"
    ],
    "batch_table_recognition": [
      "self",
      "images",
      "batch_size"
    ],
    "decode_batch_predictions": [
      "self",
      "rowcol_predictions",
      "cell_predictions",
      "orig_sizes",
      "idx_map",
      "shaper"
    ]
  },
  "SuryaTableRecProcessor": {
    "attributes": [],
    "image_processor_class": [],
    "__init__": [
      "self",
      "checkpoint"
    ],
    "resize_polygon": [
      "self",
      "polygon",
      "orig_size",
      "new_size"
    ],
    "__call__": [
      "self",
      "images",
      "query_items",
      "columns",
      "convert_images"
    ]
  },
  "LabelEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "boxes"
    ]
  },
  "SuryaTableRecDecoder": {
    "_tied_weights_keys": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "cache_position",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "use_cache",
      "prefill"
    ]
  },
  "BOX_DIM": [],
  "SPECIAL_TOKENS": [],
  "MAX_BOXES": [],
  "MERGE_KEYS": [],
  "MERGE_VALUES": [],
  "ID_TO_CATEGORY": [],
  "CATEGORY_TO_ID": [],
  "ID_TO_HEADER": [],
  "HEADER_TO_ID": [],
  "BOX_PROPERTIES": [],
  "TableRecModelOutput": {},
  "SuryaTableRecConfig": {
    "model_type": [],
    "is_composition": [],
    "__init__": [
      "self"
    ]
  },
  "DonutSwinTableRecConfig": {
    "model_type": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "image_size",
      "patch_size",
      "num_channels",
      "embed_dim",
      "depths",
      "num_heads",
      "num_kv_heads",
      "window_size",
      "mlp_ratio",
      "qkv_bias",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "drop_path_rate",
      "hidden_act",
      "use_absolute_embeddings",
      "initializer_range",
      "layer_norm_eps",
      "encoder_length",
      "use_positional_embeddings"
    ]
  },
  "SuryaTableRecDecoderConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "num_hidden_layers",
      "vocab_size",
      "bbox_size",
      "hidden_size",
      "property_embed_size",
      "box_embed_size",
      "intermediate_size",
      "encoder_hidden_size",
      "num_attention_heads",
      "lru_width",
      "attention_window_size",
      "conv1d_width",
      "logits_soft_cap",
      "rms_norm_eps",
      "use_cache",
      "pad_token_id",
      "eos_token_id",
      "bos_token_id",
      "pause_token_id",
      "query_end_token_id",
      "hidden_activation",
      "rope_theta",
      "block_types",
      "cross_attn_layers",
      "encoder_cross_attn_layers",
      "self_attn_layers",
      "global_attn_layers",
      "attention_dropout",
      "num_key_value_heads",
      "attention_bias",
      "w_init_variance_scale",
      "init_std",
      "tie_word_embeddings",
      "aux_heads",
      "causal",
      "layer_norm_eps",
      "dropout",
      "special_token_count"
    ],
    "layers_block_type": [
      "self"
    ]
  },
  "DonutSwinModel": {
    "__init__": [
      "self",
      "config",
      "add_pooling_layer",
      "use_mask_token"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "_prune_heads": [
      "self",
      "heads_to_prune"
    ],
    "forward": [
      "self",
      "pixel_values",
      "bool_masked_pos",
      "head_mask",
      "output_attentions",
      "output_hidden_states",
      "interpolate_pos_encoding",
      "return_dict"
    ]
  },
  "TableRecOutput": {},
  "TableRecEncoderDecoderModel": {
    "config_class": [],
    "base_model_prefix": [],
    "main_input_name": [],
    "supports_gradient_checkpointing": [],
    "_supports_param_buffer_assignment": [],
    "__init__": [
      "self",
      "config",
      "encoder",
      "decoder"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "forward": [
      "self",
      "decoder_input_ids",
      "decoder_cache_position",
      "decoder_attention_mask",
      "encoder_outputs",
      "use_cache",
      "return_dict"
    ],
    "resize_token_embeddings": [
      "self"
    ],
    "_reorder_cache": [
      "self",
      "past_key_values",
      "beam_idx"
    ]
  },
  "streamlit_app_cli": [],
  "detect_text_cli": [
    "input_path"
  ],
  "load_predictors_cached": [],
  "ocr_errors": [
    "pdf_file",
    "page_count",
    "sample_len",
    "max_samples",
    "max_pages"
  ],
  "text_detection": [
    "img"
  ],
  "layout_detection": [
    "img"
  ],
  "table_recognition": [
    "img",
    "highres_img",
    "skip_table_detection"
  ],
  "ocr": [
    "img",
    "highres_img",
    "skip_text_detection",
    "recognize_math",
    "with_bboxes"
  ],
  "get_page_image": [
    "pdf_file",
    "page_num",
    "dpi"
  ],
  "page_counter": [
    "pdf_file"
  ],
  "predictors": [],
  "in_file": [],
  "filetype": [],
  "page_count": [],
  "run_text_det": [],
  "run_text_rec": [],
  "run_layout_det": [],
  "run_table_rec": [],
  "run_ocr_errors": [],
  "use_pdf_boxes": [],
  "skip_table_detection": [],
  "skip_text_detection": [],
  "recognize_math": [],
  "ocr_with_boxes": [],
  "OCR_TASK_NAME": [],
  "OCR_MAX_IMAGE_SIZE": [],
  "SuryaOCRDataset": {
    "__init__": [
      "self",
      "processor",
      "data_args"
    ],
    "__len__": [
      "self"
    ],
    "get_script_text": [
      "self",
      "text"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "SuryaOCRDataCollator": {
    "__init__": [
      "self",
      "processor",
      "data_args"
    ],
    "__call__": [
      "self",
      "inputs"
    ]
  },
  "load_model_and_processor": [
    "checkpoint_path"
  ],
  "SuryaOCRModelArguments": {},
  "SuryaOCRDataArguments": {},
  "SuryaOCRTrainingArguments": {},
  "main": [],
  "CLILoader": {
    "__init__": [
      "self",
      "filepath",
      "cli_options",
      "highres"
    ],
    "common_options": [
      "fn"
    ],
    "load": [
      "self",
      "highres"
    ],
    "parse_range_str": [
      "range_str"
    ]
  },
  "table_recognition_cli": [
    "input_path",
    "skip_table_detection"
  ],
  "ocr_text_cli": [
    "input_path",
    "task_name",
    "disable_math"
  ],
  "detect_layout_cli": [
    "input_path"
  ],
  "MAX_WIDTH": [],
  "MAX_HEIGHT": [],
  "replace_fences": [
    "text"
  ],
  "load_predictor": [],
  "inference": [
    "pil_image",
    "bbox"
  ],
  "resize_image": [
    "pil_image"
  ],
  "get_canvas_hash": [
    "pil_image"
  ],
  "top_message": [],
  "predictor": [],
  "canvas_hash": [],
  "objects": [],
  "bbox_list": [],
  "ocr_latex_cli": [
    "input_path"
  ],
  "texify_app_cli": [],
  "S3_API_URL": [],
  "TextDetectionResult": {},
  "get_dynamic_thresholds": [
    "linemap",
    "text_threshold",
    "low_text",
    "typical_top10_avg"
  ],
  "detect_boxes": [
    "linemap",
    "text_threshold",
    "low_text"
  ],
  "get_detected_boxes": [
    "textmap",
    "text_threshold",
    "low_text"
  ],
  "get_and_clean_boxes": [
    "textmap",
    "processor_size",
    "image_size",
    "text_threshold",
    "low_text"
  ],
  "parallel_get_boxes": [
    "preds",
    "orig_sizes",
    "include_maps"
  ],
  "DetectionModelLoader": {
    "__init__": [
      "self",
      "checkpoint"
    ],
    "model": [
      "self",
      "device",
      "dtype",
      "attention_implementation"
    ],
    "processor": [
      "self",
      "device",
      "dtype"
    ]
  },
  "DetectionPredictor": {
    "model_loader_cls": [],
    "batch_size": [],
    "default_batch_sizes": [],
    "__call__": [
      "self",
      "images",
      "batch_size",
      "include_maps"
    ],
    "prepare_image": [
      "self",
      "img"
    ],
    "batch_detection": [
      "self",
      "images",
      "batch_size",
      "static_cache"
    ]
  },
  "SegformerImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_reduce_labels"
    ],
    "from_dict": [
      "cls",
      "image_processor_dict"
    ],
    "_preprocess": [
      "self",
      "image",
      "do_resize",
      "do_rescale",
      "do_normalize",
      "size",
      "resample",
      "rescale_factor",
      "image_mean",
      "image_std",
      "input_data_format"
    ],
    "_preprocess_image": [
      "self",
      "image",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "data_format",
      "input_data_format"
    ],
    "__call__": [
      "self",
      "images",
      "segmentation_maps"
    ],
    "preprocess": [
      "self",
      "images",
      "segmentation_maps",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_reduce_labels",
      "return_tensors",
      "data_format",
      "input_data_format"
    ]
  },
  "get_total_splits": [
    "image_size",
    "height"
  ],
  "split_image": [
    "img",
    "height"
  ],
  "FakeFuture": {
    "__init__": [
      "self",
      "func"
    ],
    "result": [
      "self"
    ]
  },
  "FakeExecutor": {
    "__init__": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "submit": [
      "self",
      "fn"
    ]
  },
  "EfficientViTConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "num_classes",
      "num_channels",
      "widths",
      "head_dim",
      "num_stages",
      "depths",
      "strides",
      "hidden_sizes",
      "patch_size",
      "hidden_dropout_prob",
      "attention_probs_dropout_prob",
      "classifier_dropout_prob",
      "layer_norm_eps",
      "decoder_layer_hidden_size",
      "decoder_hidden_size",
      "semantic_loss_ignore_index",
      "initializer_range"
    ]
  },
  "val2list": [
    "x",
    "repeat_time"
  ],
  "val2tuple": [
    "x",
    "min_len",
    "idx_repeat"
  ],
  "get_same_padding": [
    "kernel_size"
  ],
  "get_padding": [
    "kernel_size",
    "stride",
    "dilation"
  ],
  "ConvNormAct": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "dilation",
      "groups",
      "bias",
      "dropout",
      "norm_layer",
      "act_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DSConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "use_bias",
      "norm_layer",
      "act_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "mid_channels",
      "expand_ratio",
      "use_bias",
      "norm_layer",
      "act_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MBConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "mid_channels",
      "expand_ratio",
      "use_bias",
      "norm_layer",
      "act_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FusedMBConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "mid_channels",
      "expand_ratio",
      "groups",
      "use_bias",
      "norm_layer",
      "act_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LiteMLA": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "heads",
      "heads_ratio",
      "dim",
      "use_bias",
      "norm_layer",
      "act_layer",
      "kernel_func",
      "scales",
      "eps"
    ],
    "_attn": [
      "self",
      "q",
      "k",
      "v"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EfficientVitBlock": {
    "__init__": [
      "self",
      "in_channels",
      "heads_ratio",
      "head_dim",
      "expand_ratio",
      "norm_layer",
      "act_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResidualBlock": {
    "__init__": [
      "self",
      "main",
      "shortcut",
      "pre_norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "build_local_block": [
    "in_channels",
    "out_channels",
    "stride",
    "kernel_size",
    "expand_ratio",
    "norm_layer",
    "act_layer",
    "fewer_norm",
    "block_type"
  ],
  "Stem": {
    "__init__": [
      "self",
      "in_chs",
      "out_chs",
      "depth",
      "stride",
      "norm_layer",
      "act_layer",
      "block_type"
    ]
  },
  "EfficientVitLargeStage": {
    "__init__": [
      "self",
      "in_chs",
      "out_chs",
      "depth",
      "stride",
      "norm_layer",
      "act_layer",
      "head_dim",
      "vit_stage",
      "fewer_norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EfficientVitLarge": {
    "__init__": [
      "self",
      "config",
      "norm_layer",
      "act_layer"
    ],
    "set_grad_checkpointing": [
      "self",
      "enable"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EfficientViTPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "main_input_name": [],
    "_init_weights": [
      "self",
      "module"
    ]
  },
  "DecodeMLP": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DecodeHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "encoder_hidden_states"
    ]
  },
  "EfficientViTForSemanticSegmentation": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "EfficientViTForSemanticLayoutSegmentation": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  }
}