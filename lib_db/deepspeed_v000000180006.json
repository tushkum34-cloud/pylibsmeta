{
  "torch_available": [],
  "is_rocm_pytorch": [],
  "rocm_version": [],
  "RED_START": [],
  "RED_END": [],
  "ERROR": [],
  "abort": [
    "msg"
  ],
  "fetch_requirements": [
    "path"
  ],
  "is_env_set": [
    "key"
  ],
  "get_env_if_set": [
    "key",
    "default"
  ],
  "install_requires": [],
  "extras_require": [],
  "all_extras": [],
  "cmdclass": [],
  "ext_modules": [],
  "BUILD_OP_PLATFORM": [],
  "BUILD_OP_DEFAULT": [],
  "command_exists": [
    "cmd"
  ],
  "op_envvar": [
    "op_name"
  ],
  "op_enabled": [
    "op_name"
  ],
  "install_ops": [],
  "version_str": [],
  "torch_version": [],
  "bf16_support": [],
  "cuda_version": [],
  "nccl_version": [],
  "hip_version": [],
  "torch_info": [],
  "thisdir": [],
  "start_time": [],
  "end_time": [],
  "StochasticTransformerBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self"
    ],
    "absolute_name": [
      "self"
    ],
    "nvcc_args": [
      "self"
    ]
  },
  "RandomLTDBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "include_paths": [
      "self"
    ]
  },
  "RaggedOpsBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ],
    "filter_ccs": [
      "self",
      "ccs"
    ],
    "get_prefix": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "include_paths": [
      "self"
    ]
  },
  "FusedAdamBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "include_paths": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "nvcc_args": [
      "self"
    ]
  },
  "InferenceCoreBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ],
    "filter_ccs": [
      "self",
      "ccs"
    ],
    "get_prefix": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "include_paths": [
      "self"
    ]
  },
  "op_builder_dir": [],
  "op_builder_module": [],
  "__op_builders__": [],
  "ALL_OPS": [],
  "accelerator_name": [],
  "RaggedUtilsBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ],
    "filter_ccs": [
      "self",
      "ccs"
    ],
    "get_prefix": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "include_paths": [
      "self"
    ]
  },
  "SparseAttnBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ]
  },
  "CPUAdagradBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "libraries_args": [
      "self"
    ],
    "include_paths": [
      "self"
    ]
  },
  "UtilsBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ]
  },
  "QuantizerBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "include_paths": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ]
  },
  "__deepspeed__": [],
  "this_module": [],
  "builder_closure": [
    "member_name"
  ],
  "TransformerBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "include_paths": [
      "self"
    ]
  },
  "CPUAdamBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "libraries_args": [
      "self"
    ],
    "include_paths": [
      "self"
    ]
  },
  "FusedLionBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "include_paths": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "nvcc_args": [
      "self"
    ]
  },
  "YELLOW": [],
  "END": [],
  "WARNING": [],
  "DEFAULT_TORCH_EXTENSION_PATH": [],
  "DEFAULT_COMPUTE_CAPABILITIES": [],
  "MissingCUDAException": {},
  "CUDAMismatchException": {},
  "installed_cuda_version": [
    "name"
  ],
  "get_default_compute_capabilities": [],
  "cuda_minor_mismatch_ok": [],
  "assert_no_cuda_mismatch": [
    "name"
  ],
  "OpBuilder": {
    "_rocm_version": [],
    "_rocm_gpu_arch": [],
    "_rocm_wavefront_size": [],
    "_is_rocm_pytorch": [],
    "_is_sycl_enabled": [],
    "_loaded_ops": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "hipify_extension": [
      "self"
    ],
    "sycl_extension": [
      "self"
    ],
    "validate_torch_version": [
      "torch_info"
    ],
    "validate_torch_op_version": [
      "torch_info"
    ],
    "is_rocm_pytorch": [],
    "is_sycl_enabled": [],
    "installed_rocm_version": [],
    "get_rocm_gpu_arch": [],
    "get_rocm_wavefront_size": [],
    "include_paths": [
      "self"
    ],
    "nvcc_args": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ],
    "extra_ldflags": [
      "self"
    ],
    "has_function": [
      "self",
      "funcname",
      "libraries",
      "library_dirs",
      "verbose"
    ],
    "strip_empty_entries": [
      "self",
      "args"
    ],
    "cpu_arch": [
      "self"
    ],
    "get_cuda_compile_flag": [
      "self"
    ],
    "_backup_cpuinfo": [
      "self"
    ],
    "simd_width": [
      "self"
    ],
    "command_exists": [
      "self",
      "cmd"
    ],
    "warning": [
      "self",
      "msg"
    ],
    "deepspeed_src_path": [
      "self",
      "code_path"
    ],
    "builder": [
      "self"
    ],
    "load": [
      "self",
      "verbose"
    ],
    "jit_load": [
      "self",
      "verbose"
    ]
  },
  "CUDAOpBuilder": {
    "compute_capability_args": [
      "self",
      "cross_compile_archs"
    ],
    "filter_ccs": [
      "self",
      "ccs"
    ],
    "version_dependent_macros": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ],
    "builder": [
      "self"
    ],
    "hipify_extension": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "nvcc_args": [
      "self"
    ],
    "libraries_args": [
      "self"
    ]
  },
  "TorchCPUOpBuilder": {
    "get_cuda_lib64_path": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "cxx_args": [
      "self"
    ]
  },
  "InferenceBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ],
    "filter_ccs": [
      "self",
      "ccs"
    ],
    "sources": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "include_paths": [
      "self"
    ],
    "nvcc_args": [
      "self"
    ]
  },
  "DeepCompileBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "libraries_args": [
      "self"
    ],
    "include_paths": [
      "self"
    ]
  },
  "FPQuantizerBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ],
    "filter_ccs": [
      "self",
      "ccs"
    ],
    "sources": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "include_paths": [
      "self"
    ],
    "get_default_quant_dtype": [],
    "get_quant_range": [
      "q_bits"
    ]
  },
  "SpatialInferenceBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ],
    "sources": [
      "self"
    ],
    "include_paths": [
      "self"
    ]
  },
  "InferenceCutlassBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ],
    "filter_ccs": [
      "self",
      "ccs"
    ],
    "get_prefix": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "include_paths": [
      "self"
    ]
  },
  "AsyncIOBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self"
    ],
    "absolute_name": [
      "self"
    ],
    "lib_sources": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "include_paths": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "check_for_libaio_pkg": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ]
  },
  "GDSBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self"
    ],
    "absolute_name": [
      "self"
    ],
    "lib_sources": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "include_paths": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ]
  },
  "FusedLambBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "include_paths": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "nvcc_args": [
      "self"
    ]
  },
  "CPULionBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "libraries_args": [
      "self"
    ],
    "include_paths": [
      "self"
    ]
  },
  "EvoformerAttnBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "nvcc_args": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ],
    "include_paths": [
      "self"
    ]
  },
  "NPUFusedAdam": {
    "multi_tensor_adam": [
      "chunk_size",
      "noop_flag_buffer",
      "tensor_lists",
      "lr",
      "beta1",
      "beta2",
      "epsilon",
      "step",
      "adam_w_mode",
      "bias_correction",
      "weight_decay"
    ]
  },
  "NPUOpBuilder": {
    "_ascend_path": [],
    "_torch_npu_path": [],
    "_cann_version": [],
    "__init__": [
      "self",
      "name"
    ],
    "cann_defs": [
      "self"
    ],
    "installed_cann_path": [
      "self"
    ],
    "installed_cann_version": [
      "self",
      "name"
    ],
    "include_paths": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ]
  },
  "NotImplementedBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "load": [
      "self",
      "verbose"
    ],
    "sources": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "include_paths": [
      "self"
    ]
  },
  "ActivationFuncType": {
    "UNKNOWN": [],
    "GELU": [],
    "ReLU": [],
    "GATED_GELU": [],
    "GATED_SILU": []
  },
  "InferenceContext": {
    "_workspace": [],
    "_seed": [],
    "_curr_offset": [],
    "_stream": [],
    "_free_memory_size": [],
    "_num_tokens": [],
    "_attention_unfused_workspace_offset": [],
    "_workSpaceSize": [],
    "workSpaceSize": [],
    "kv_caches": [],
    "reset_tokens": [
      "initial_tokens"
    ],
    "current_tokens": [],
    "GetWorkSpace": []
  },
  "NPUInference": {
    "layer_norm": [
      "inputs",
      "gamma",
      "beta",
      "epsilon"
    ],
    "_qkv_gemm": [
      "inputs",
      "weight",
      "q_scale",
      "bias",
      "gamma",
      "beta",
      "eps",
      "add_bias",
      "q_int8",
      "transpose"
    ],
    "qkv_gemm_fp16": [
      "inputs",
      "weight",
      "q_scale",
      "bias",
      "gamma",
      "beta",
      "eps",
      "add_bias",
      "q_int8",
      "transpose"
    ],
    "qkv_gemm_bf16": [
      "inputs",
      "weight",
      "q_scale",
      "bias",
      "gamma",
      "beta",
      "eps",
      "add_bias",
      "q_int8",
      "transpose"
    ],
    "qkv_gemm_fp32": [
      "inputs",
      "weight",
      "q_scale",
      "bias",
      "gamma",
      "beta",
      "eps",
      "add_bias",
      "q_int8",
      "transpose"
    ],
    "_bias_add_transform_0213": [
      "vals",
      "bias",
      "hidden_dim",
      "seq_length",
      "seq_offset",
      "heads",
      "num_kv",
      "rotary_dim",
      "rotate_half",
      "rotate_every_two",
      "rope_theta"
    ],
    "_softmax_context": [
      "query_key_value",
      "attn_mask",
      "rotary_dim",
      "rotate_half",
      "rotate_every_two",
      "heads",
      "num_kv",
      "norm_factor",
      "triangular_masking",
      "local_attention",
      "window_size",
      "no_masking",
      "layer_id",
      "num_layers",
      "alibi",
      "rope_theta"
    ],
    "softmax_context_fp16": [
      "query_key_value",
      "attn_mask",
      "rotary_dim",
      "rotate_half",
      "rotate_every_two",
      "heads",
      "num_kv",
      "norm_factor",
      "triangular_masking",
      "local_attention",
      "window_size",
      "no_masking",
      "layer_id",
      "num_layers",
      "alibi",
      "rope_theta"
    ],
    "softmax_context_bf16": [
      "query_key_value",
      "attn_mask",
      "rotary_dim",
      "rotate_half",
      "rotate_every_two",
      "heads",
      "num_kv",
      "norm_factor",
      "triangular_masking",
      "local_attention",
      "window_size",
      "no_masking",
      "layer_id",
      "num_layers",
      "alibi",
      "rope_theta"
    ],
    "softmax_context_fp32": [
      "query_key_value",
      "attn_mask",
      "rotary_dim",
      "rotate_half",
      "rotate_every_two",
      "heads",
      "num_kv",
      "norm_factor",
      "triangular_masking",
      "local_attention",
      "window_size",
      "no_masking",
      "layer_id",
      "num_layers",
      "alibi",
      "rope_theta"
    ],
    "_vector_matmul": [
      "input",
      "weight",
      "async_op",
      "q_scale",
      "q_int8",
      "transposed_mode"
    ],
    "vector_matmul_fp16": [
      "input",
      "weight",
      "async_op",
      "q_scale",
      "q_int8",
      "transposed_mode"
    ],
    "vector_matmul_bf16": [
      "input",
      "weight",
      "async_op",
      "q_scale",
      "q_int8",
      "transposed_mode"
    ],
    "vector_matmul_fp32": [
      "input",
      "weight",
      "async_op",
      "q_scale",
      "q_int8",
      "transposed_mode"
    ],
    "_mlp_gemm": [
      "input",
      "residual",
      "input_bias",
      "weight_interm",
      "weight_out",
      "bias",
      "gamma",
      "beta",
      "eps",
      "pre_layer_norm",
      "mlp_after_attn",
      "interm_scale",
      "out_scale",
      "dtype",
      "mlp_act_func_type",
      "transpose"
    ],
    "mlp_gemm_fp16": [
      "input",
      "residual",
      "input_bias",
      "weight_interm",
      "weight_out",
      "bias",
      "gamma",
      "beta",
      "eps",
      "pre_layer_norm",
      "mlp_after_attn",
      "interm_scale",
      "out_scale",
      "dtype",
      "mlp_act_func_type",
      "transpose"
    ],
    "mlp_gemm_bf16": [
      "input",
      "residual",
      "input_bias",
      "weight_interm",
      "weight_out",
      "bias",
      "gamma",
      "beta",
      "eps",
      "pre_layer_norm",
      "mlp_after_attn",
      "interm_scale",
      "out_scale",
      "dtype",
      "mlp_act_func_type",
      "transpose"
    ],
    "mlp_gemm_fp32": [
      "input",
      "residual",
      "input_bias",
      "weight_interm",
      "weight_out",
      "bias",
      "gamma",
      "beta",
      "eps",
      "pre_layer_norm",
      "mlp_after_attn",
      "interm_scale",
      "out_scale",
      "dtype",
      "mlp_act_func_type",
      "transpose"
    ],
    "_residual_add_bias": [
      "hidden_state",
      "residual",
      "attention_output",
      "attention_bias",
      "final_bias",
      "mp_size",
      "mlp_after_attn",
      "add_bias",
      "pre_layer_norm"
    ],
    "residual_add_bias_fp16": [
      "hidden_state",
      "residual",
      "attention_output",
      "attention_bias",
      "final_bias",
      "mp_size",
      "mlp_after_attn",
      "add_bias",
      "pre_layer_norm"
    ],
    "residual_add_bias_bf16": [
      "hidden_state",
      "residual",
      "attention_output",
      "attention_bias",
      "final_bias",
      "mp_size",
      "mlp_after_attn",
      "add_bias",
      "pre_layer_norm"
    ],
    "residual_add_bias_fp32": [
      "hidden_state",
      "residual",
      "attention_output",
      "attention_bias",
      "final_bias",
      "mp_size",
      "mlp_after_attn",
      "add_bias",
      "pre_layer_norm"
    ]
  },
  "MLUFusedAdam": {
    "multi_tensor_adam": [
      "chunk_size",
      "noop_flag_buffer",
      "tensor_lists",
      "lr",
      "beta1",
      "beta2",
      "epsilon",
      "step",
      "adam_w_mode",
      "bias_correction",
      "weight_decay"
    ]
  },
  "MLUOpBuilder": {
    "builder": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "libraries_args": [
      "self"
    ]
  },
  "HPUFusedAdam": {
    "htcore": [],
    "is_lazy_mode": [],
    "multi_tensor_adam": [
      "chunk_size",
      "noop_flag_buffer",
      "tensor_lists",
      "lr",
      "beta1",
      "beta2",
      "epsilon",
      "step",
      "adam_w_mode",
      "bias_correction",
      "weight_decay"
    ]
  },
  "CPUOpBuilder": {
    "builder": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "libraries_args": [
      "self"
    ]
  },
  "FPQuantizer": {
    "CUDA_IMPL": [],
    "selective_dequantize": [
      "cls",
      "val_q",
      "scales",
      "indexes",
      "group_size",
      "q_mantisa_bits",
      "q_exponent_bits"
    ],
    "dequantize": [
      "cls",
      "fp_out",
      "input_q",
      "scale",
      "group_size",
      "q_mantisa_bits",
      "q_exponent_bits"
    ],
    "quantize": [
      "cls",
      "out",
      "val",
      "scale",
      "group_size",
      "stochastic_rounding",
      "q_bits",
      "q_mantisa_bits"
    ],
    "get_scales": [
      "cls",
      "out",
      "num_groups"
    ]
  },
  "PackbitsBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "include_paths": [
      "self"
    ],
    "cxx_args": [
      "self"
    ]
  },
  "FlashAttentionBuilderObject": {
    "__init__": [
      "self"
    ],
    "flash_attn_func_v2": [
      "self",
      "q",
      "k",
      "v",
      "dropout_p",
      "softmax_scale",
      "is_causal"
    ]
  },
  "FlashAttentionBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "include_paths": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "load": [
      "self"
    ]
  },
  "SYCLOpBuilder": {
    "builder": [
      "self"
    ],
    "version_dependent_macros": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "extra_ldflags": [
      "self"
    ],
    "fixed_aotflags": [
      "self"
    ],
    "load": [
      "self",
      "verbose"
    ],
    "jit_load": [
      "self",
      "verbose"
    ]
  },
  "SDAAFusedAdam": {
    "multi_tensor_adam": [
      "chunk_size",
      "noop_flag_buffer",
      "tensor_lists",
      "lr",
      "beta1",
      "beta2",
      "epsilon",
      "step",
      "adam_w_mode",
      "bias_correction",
      "weight_decay"
    ]
  },
  "SDAAOpBuilder": {
    "builder": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "libraries_args": [
      "self"
    ]
  },
  "CCLCommBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "include_paths": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ],
    "extra_ldflags": [
      "self"
    ]
  },
  "ShareMemCommBuilder": {
    "BUILD_VAR": [],
    "NAME": [],
    "__init__": [
      "self",
      "name"
    ],
    "absolute_name": [
      "self"
    ],
    "sources": [
      "self"
    ],
    "include_paths": [
      "self"
    ],
    "cxx_args": [
      "self"
    ],
    "is_compatible": [
      "self",
      "verbose"
    ]
  },
  "GREEN": [],
  "RED": [],
  "SUCCESS": [],
  "OKAY": [],
  "FAIL": [],
  "INFO": [],
  "color_len": [],
  "okay": [],
  "warning": [],
  "op_report": [
    "verbose"
  ],
  "nvcc_version": [],
  "installed_cann_path": [],
  "installed_cann_version": [],
  "get_shm_size": [],
  "human_readable_size": [
    "size"
  ],
  "debug_report": [],
  "parse_arguments": [],
  "main": [
    "hide_operator_status",
    "hide_errors_and_warnings"
  ],
  "cli_main": [],
  "get_annotations_from_namespace": [
    "namespace"
  ],
  "get_annotations": [
    "obj"
  ],
  "_parse_version": [
    "version_str"
  ],
  "__version__": [],
  "__git_hash__": [],
  "__git_branch__": [],
  "dist": [],
  "set_optimizer_flags": [
    "config_class",
    "model"
  ],
  "initialize": [
    "args",
    "model",
    "optimizer",
    "model_parameters",
    "training_data",
    "lr_scheduler",
    "distributed_port",
    "mpu",
    "dist_init_required",
    "collate_fn",
    "config",
    "mesh_param",
    "config_params"
  ],
  "_add_core_arguments": [
    "parser"
  ],
  "add_config_arguments": [
    "parser"
  ],
  "default_inference_config": [],
  "init_inference": [
    "model",
    "config"
  ],
  "tp_model_init": [
    "model",
    "tp_size",
    "dtype",
    "config"
  ],
  "version": [],
  "git_hash": [],
  "git_branch": [],
  "installed_ops": [],
  "compatible_ops": [],
  "TORCH_DISTRIBUTED_DEFAULT_PORT": [],
  "default_pg_timeout": [],
  "INFERENCE_GENERIC_MODE": [],
  "INFERENCE_SPECIALIZED_MODE": [],
  "CROSS_RANK": [],
  "CROSS_SIZE": [],
  "LOCAL_RANK": [],
  "Backend": {
    "__init__": [
      "self",
      "name",
      "rank",
      "size"
    ],
    "is_initialized": [
      "self"
    ],
    "new_group": [
      "self"
    ],
    "init_process_group": [
      "self"
    ]
  },
  "DS_COMM_ALL_GATHER_OFF": [],
  "DS_COMM_REDUCE_SCATTER_OFF": [],
  "DS_COMM_BROADCAST_OFF": [],
  "DS_COMM_ALL_REDUCE_OFF": [],
  "DS_COMM_REDUCE_OFF": [],
  "disable_compiler_collective": [
    "func"
  ],
  "build_shm_op": [],
  "has_coalescing_manager": [],
  "has_all_reduce_coalesced": [],
  "get_coalescing_manager": [
    "group",
    "device",
    "reqs",
    "async_op"
  ],
  "all_gather_comm_off": [
    "flag"
  ],
  "reduce_scatter_comm_off": [
    "flag"
  ],
  "broadcast_comm_off": [
    "flag"
  ],
  "all_reduce_comm_off": [
    "flag"
  ],
  "reduce_comm_off": [
    "flag"
  ],
  "backward_comm_off": [
    "flag"
  ],
  "Noop": {
    "wait": [
      "self"
    ]
  },
  "TorchBackend": {
    "__init__": [
      "self",
      "backend",
      "timeout",
      "init_method",
      "rank",
      "world_size",
      "name"
    ],
    "get_all_gather_function": [
      "self"
    ],
    "get_reduce_scatter_function": [
      "self"
    ],
    "has_all_gather_into_tensor": [
      "self"
    ],
    "has_reduce_scatter_tensor": [
      "self"
    ],
    "init_process_group": [
      "self",
      "backend",
      "timeout",
      "init_method",
      "rank",
      "world_size"
    ],
    "all_reduce": [
      "self",
      "tensor",
      "op",
      "group",
      "async_op"
    ],
    "inference_all_reduce": [
      "self",
      "tensor",
      "op",
      "group"
    ],
    "all_reduce_coalesced": [
      "self",
      "tensors",
      "op",
      "group",
      "async_op"
    ],
    "reduce": [
      "self",
      "tensor",
      "dst",
      "op",
      "group",
      "async_op"
    ],
    "reduce_scatter": [
      "self",
      "output",
      "input_list",
      "op",
      "group",
      "async_op"
    ],
    "broadcast": [
      "self",
      "tensor",
      "src",
      "group",
      "async_op"
    ],
    "broadcast_object_list": [
      "self",
      "object_list",
      "src",
      "group",
      "device"
    ],
    "all_gather": [
      "self",
      "tensor_list",
      "tensor",
      "group",
      "async_op"
    ],
    "all_gather_into_tensor": [
      "self",
      "output_tensor",
      "input_tensor",
      "group",
      "async_op"
    ],
    "all_gather_base": [
      "self",
      "output_tensor",
      "input_tensor",
      "group",
      "async_op"
    ],
    "all_gather_coalesced": [
      "self",
      "output_tensors",
      "input_tensors",
      "group",
      "async_op"
    ],
    "all_gather_object": [
      "self",
      "object_list",
      "obj",
      "group"
    ],
    "reduce_scatter_tensor": [
      "self",
      "output_tensor",
      "input_tensor",
      "op",
      "group",
      "async_op"
    ],
    "all_to_all_single": [
      "self",
      "output",
      "input",
      "output_split_sizes",
      "input_split_sizes",
      "group",
      "async_op"
    ],
    "all_to_all": [
      "self",
      "output_tensor_list",
      "input_tensor_list",
      "group",
      "async_op"
    ],
    "send": [
      "self",
      "tensor",
      "dst",
      "group",
      "tag"
    ],
    "recv": [
      "self",
      "tensor",
      "src",
      "group",
      "tag"
    ],
    "isend": [
      "self",
      "tensor",
      "dst",
      "group",
      "tag"
    ],
    "irecv": [
      "self",
      "tensor",
      "src",
      "group",
      "tag"
    ],
    "gather": [
      "self",
      "tensor",
      "gather_list",
      "dst",
      "group",
      "async_op"
    ],
    "scatter": [
      "self",
      "tensor",
      "scatter_list",
      "src",
      "group",
      "async_op"
    ],
    "barrier": [
      "self",
      "group",
      "async_op",
      "device_ids"
    ],
    "monitored_barrier": [
      "self",
      "group",
      "timeout",
      "wait_all_ranks"
    ],
    "get_rank": [
      "self",
      "group"
    ],
    "get_world_size": [
      "self",
      "group"
    ],
    "is_initialized": [
      "self"
    ],
    "get_backend": [
      "self",
      "group"
    ],
    "new_group": [
      "self",
      "ranks"
    ],
    "get_global_rank": [
      "self",
      "group",
      "group_rank"
    ],
    "get_world_group": [
      "self"
    ],
    "destroy_process_group": [
      "self",
      "group"
    ],
    "_reduce_op": [
      "self",
      "op"
    ],
    "init_device_mesh": [
      "self",
      "mesh_shape",
      "mesh_dim_names"
    ],
    "enable_symm_mem_for_group": [
      "self",
      "group_name"
    ]
  },
  "cdb": [],
  "timers": [],
  "timer_summary": [],
  "comms_logger": [],
  "nccl_backend": [],
  "mpi_backend": [],
  "ccl_backend": [],
  "hccl_backend": [],
  "ProcessGroup": {
    "__init__": [
      "self",
      "comm_id",
      "ranks"
    ]
  },
  "_configure_using_config_file": [
    "config"
  ],
  "configure": [
    "deepspeed_config",
    "enabled",
    "prof_all",
    "prof_ops",
    "verbose",
    "debug"
  ],
  "timed_op": [
    "func"
  ],
  "init_deepspeed_backend": [
    "ds_backend",
    "timeout",
    "init_method"
  ],
  "is_initialized": [],
  "destroy_process_group": [
    "group"
  ],
  "new_group": [
    "ranks"
  ],
  "is_available": [],
  "set_backend": [],
  "broadcast": [
    "tensor",
    "src",
    "group",
    "async_op",
    "prof",
    "log_name",
    "debug"
  ],
  "broadcast_object_list": [
    "object_list",
    "src",
    "group",
    "device"
  ],
  "all_gather": [
    "tensor_list",
    "tensor",
    "group",
    "async_op",
    "prof",
    "log_name",
    "debug"
  ],
  "all_gather_object": [
    "object_list",
    "obj",
    "group",
    "prof",
    "log_name",
    "debug"
  ],
  "has_reduce_scatter_tensor": [],
  "reduce_scatter_fn": [
    "output_tensor",
    "tensor",
    "op",
    "group",
    "async_op",
    "prof",
    "debug"
  ],
  "reduce_scatter_tensor": [
    "output_tensor",
    "tensor",
    "op",
    "group",
    "async_op",
    "prof",
    "log_name",
    "debug"
  ],
  "all_gather_into_tensor": [
    "output_tensor",
    "tensor",
    "group",
    "async_op",
    "prof",
    "log_name",
    "debug"
  ],
  "has_all_gather_into_tensor": [],
  "allgather_fn": [
    "output_tensor",
    "input_tensor",
    "group",
    "async_op",
    "debug"
  ],
  "all_to_all_single": [
    "output",
    "tensor",
    "output_split_sizes",
    "input_split_sizes",
    "group",
    "async_op",
    "prof",
    "log_name",
    "debug"
  ],
  "all_to_all": [
    "output_tensor_list",
    "input_tensor_list",
    "group",
    "async_op"
  ],
  "send": [
    "tensor",
    "dst",
    "group",
    "tag",
    "prof",
    "log_name",
    "debug"
  ],
  "recv": [
    "tensor",
    "src",
    "group",
    "tag",
    "prof",
    "log_name",
    "debug"
  ],
  "isend": [
    "tensor",
    "dst",
    "group",
    "tag",
    "prof",
    "log_name",
    "debug"
  ],
  "irecv": [
    "tensor",
    "src",
    "group",
    "tag",
    "prof",
    "log_name",
    "debug"
  ],
  "gather": [
    "tensor",
    "gather_list",
    "dst",
    "group",
    "async_op",
    "prof",
    "log_name",
    "debug"
  ],
  "scatter": [
    "tensor",
    "scatter_list",
    "src",
    "group",
    "async_op",
    "prof",
    "log_name",
    "debug"
  ],
  "barrier": [
    "group",
    "async_op",
    "device_ids",
    "prof",
    "log_name",
    "debug"
  ],
  "monitored_barrier": [
    "group",
    "timeout",
    "wait_all_ranks",
    "prof",
    "log_name",
    "debug"
  ],
  "log_summary": [
    "show_straggler",
    "return_dict"
  ],
  "reset_log": [],
  "has_comm_data": [],
  "get_comm_operation_count": [],
  "get_logged_comm_ops": [],
  "reduce": [
    "tensor",
    "dst",
    "op",
    "group",
    "async_op",
    "prof",
    "log_name",
    "debug"
  ],
  "reduce_scatter": [
    "output",
    "input_list",
    "op",
    "group",
    "async_op",
    "prof",
    "log_name",
    "debug"
  ],
  "all_gather_coalesced": [
    "output_tensors",
    "input_tensors",
    "group",
    "async_op"
  ],
  "all_reduce": [
    "tensor",
    "op",
    "group",
    "async_op",
    "prof",
    "log_name",
    "debug"
  ],
  "inference_all_reduce": [
    "tensor",
    "op",
    "group",
    "async_op",
    "prof",
    "log_name",
    "debug"
  ],
  "all_reduce_coalesced": [
    "tensors",
    "op",
    "group",
    "async_op",
    "prof",
    "log_name",
    "debug"
  ],
  "get_world_group": [],
  "get_world_size": [
    "group"
  ],
  "get_rank": [
    "group"
  ],
  "get_local_rank": [],
  "get_global_rank": [
    "group",
    "group_rank"
  ],
  "get_all_ranks_from_group": [
    "group"
  ],
  "initialize_mesh_device": [
    "mesh_shape",
    "mesh_dim_names"
  ],
  "enable_symm_mem_for_group": [
    "group_name"
  ],
  "init_distributed": [
    "dist_backend",
    "auto_mpi_discovery",
    "distributed_port",
    "verbose",
    "timeout",
    "init_method",
    "dist_init_required",
    "config",
    "rank",
    "world_size"
  ],
  "mpi_discovery": [
    "distributed_port",
    "verbose"
  ],
  "in_aml": [],
  "in_aws_sm": [],
  "in_dlts": [],
  "patch_aml_env_for_torch_nccl_backend": [
    "master_port",
    "verbose"
  ],
  "patch_aws_sm_env_for_torch_nccl_backend": [
    "verbose"
  ],
  "build_ccl_op": [],
  "CCLHandler": {
    "__init__": [
      "self",
      "ccl_comm_op"
    ],
    "wait": [
      "self"
    ]
  },
  "CCLBackend": {
    "__init__": [
      "self",
      "name",
      "rank",
      "world_size",
      "mpu",
      "timeout",
      "init_method"
    ],
    "is_initialized": [
      "self"
    ],
    "run_collective": [
      "self",
      "name"
    ],
    "all_reduce": [
      "self",
      "tensor",
      "op",
      "group",
      "async_op"
    ],
    "inference_all_reduce": [
      "self",
      "tensor",
      "op",
      "group"
    ],
    "broadcast": [
      "self",
      "tensor",
      "src",
      "group",
      "async_op"
    ],
    "all_gather": [
      "self",
      "tensor_list",
      "tensor",
      "group",
      "async_op"
    ],
    "reduce_scatter_tensor": [
      "self",
      "output_tensor",
      "input_tensor",
      "op",
      "group",
      "async_op"
    ],
    "all_gather_into_tensor": [
      "self",
      "output_tensor",
      "input_tensor",
      "group",
      "async_op"
    ],
    "all_to_all_single": [
      "self",
      "output",
      "input",
      "output_split_sizes",
      "input_split_sizes",
      "group",
      "async_op"
    ],
    "send": [
      "self",
      "tensor",
      "dst",
      "group",
      "tag"
    ],
    "recv": [
      "self",
      "tensor",
      "src",
      "group",
      "tag"
    ],
    "gather": [
      "self",
      "tensor",
      "gather_list",
      "dst",
      "group",
      "async_op"
    ],
    "scatter": [
      "self",
      "tensor",
      "gather_list",
      "dst",
      "group",
      "async_op"
    ],
    "barrier": [
      "self",
      "group",
      "async_op"
    ],
    "monitored_barrier": [
      "self",
      "group",
      "timeout",
      "wait_all_ranks"
    ],
    "reduce_scatter": [
      "self",
      "output",
      "input_list",
      "op",
      "group",
      "async_op"
    ],
    "reduce": [
      "self",
      "tensor",
      "dst",
      "op",
      "group",
      "async_op"
    ],
    "new_group": [
      "self",
      "ranks"
    ],
    "_new_group": [
      "self",
      "ranks",
      "group"
    ],
    "get_all_ranks_from_group": [
      "self",
      "group"
    ]
  },
  "get_local_rank_from_launcher": [],
  "get_world_rank_from_launcher": [],
  "get_world_size_from_launcher": [],
  "get_default_args": [
    "func"
  ],
  "get_tensor_position": [
    "func"
  ],
  "get_tensor_kwarg": [
    "func",
    "kwargs"
  ],
  "get_msg_size_from_args": [
    "func"
  ],
  "get_debug_log_name": [
    "func_args",
    "debug"
  ],
  "CommsLoggerConfig": {},
  "DeepSpeedCommsConfig": {
    "__init__": [
      "self",
      "ds_config"
    ]
  },
  "ReduceOp": {
    "SUM": [],
    "PRODUCT": [],
    "MIN": [],
    "MAX": [],
    "BAND": [],
    "BOR": [],
    "BXOR": [],
    "AVG": [],
    "UNUSED": []
  },
  "NCCL_BACKEND": [],
  "CCL_BACKEND": [],
  "MPI_BACKEND": [],
  "GLOO_BACKEND": [],
  "SCCL_BACKEND": [],
  "HCCL_BACKEND": [],
  "DEFAULT_AML_MASTER_PORT": [],
  "DEFAULT_AML_NCCL_SOCKET_IFNAME": [],
  "COMMS_LOGGER_FORMAT": [],
  "COMMS_LOGGER": [],
  "COMMS_LOGGER_ENABLED": [],
  "COMMS_LOGGER_ENABLED_DEFAULT": [],
  "COMMS_LOGGER_VERBOSE": [],
  "COMMS_LOGGER_VERBOSE_DEFAULT": [],
  "COMMS_LOGGER_PROF_ALL": [],
  "COMMS_LOGGER_PROF_ALL_DEFAULT": [],
  "COMMS_LOGGER_DEBUG": [],
  "COMMS_LOGGER_DEBUG_DEFAULT": [],
  "COMMS_LOGGER_PROF_OPS": [],
  "COMMS_LOGGER_PROF_OPS_DEFAULT": [],
  "random_ltd_module": [],
  "gpt_sample_tokens": [
    "reserved_length",
    "seq_length",
    "batch_size",
    "layers",
    "device",
    "attn_mask"
  ],
  "bert_sample_tokens": [
    "reserved_length",
    "seq_length",
    "batch_size",
    "layers",
    "device",
    "attn_mask"
  ],
  "GatherTokens": {
    "forward": [
      "ctx",
      "activations",
      "sorted_indices",
      "batch_first"
    ],
    "backward": [
      "ctx",
      "a_gradients",
      "g_gradients"
    ]
  },
  "ScatterTokens": {
    "forward": [
      "ctx",
      "all_activations",
      "layer_activations",
      "sorted_indices",
      "batch_first"
    ],
    "backward": [
      "ctx",
      "out_gradients"
    ]
  },
  "kernel_": [],
  "_attention": [
    "Q",
    "K",
    "V",
    "bias1",
    "bias2"
  ],
  "attention_bwd": [
    "dO",
    "Q",
    "K",
    "V",
    "O",
    "lse",
    "bias1",
    "bias2",
    "bias1_grad",
    "bias2_grad"
  ],
  "EvoformerFusedAttention": {
    "forward": [
      "ctx",
      "q",
      "k",
      "v",
      "bias1",
      "bias2"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "DS4Sci_EvoformerAttention": [
    "Q",
    "K",
    "V",
    "biases"
  ],
  "fp_quant_module": [],
  "Quantizer": {
    "__init__": [
      "self",
      "group_size"
    ],
    "quantize": [
      "self",
      "input",
      "q_bits",
      "q_mantisa_bits",
      "stochastic_mode",
      "return_meta_tensor"
    ],
    "dequantize": [
      "self",
      "input_q",
      "fp_out",
      "q_bits",
      "q_mantisa_bits",
      "scale"
    ]
  },
  "FP_Quantize": {
    "__init__": [
      "self",
      "quantization_config"
    ],
    "quantize": [
      "self",
      "input",
      "q_bits",
      "q_mantisa_bits",
      "stochastic_mode",
      "return_meta_tensor"
    ],
    "to": [
      "self"
    ],
    "get_scales": [
      "self"
    ],
    "dequantize": [
      "self",
      "input_q",
      "fp_out",
      "q_bits",
      "q_mantisa_bits",
      "scale"
    ],
    "selective_dequantize": [
      "self",
      "input_q",
      "indexes",
      "fp_out",
      "q_bits",
      "q_mantisa_bits",
      "scale"
    ]
  },
  "matmul_fp8": [
    "inp",
    "weight",
    "scale",
    "quantization_group_size",
    "quantizer"
  ],
  "matmul_fp8_fallback": [
    "inp",
    "weight",
    "scale",
    "quantization_group_size",
    "quantizer"
  ],
  "matmul_kernel_fp8_bf16": [
    "inp_ptr",
    "weight_ptr",
    "out_ptr",
    "scale_ptr",
    "M",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "quantization_group_size"
  ],
  "matmul_kernel_fp8_fp16": [
    "inp_ptr",
    "weight_ptr",
    "out_ptr",
    "scale_ptr",
    "M",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "quantization_group_size"
  ],
  "matmul_fp8_triton": [
    "inp",
    "weight",
    "scale",
    "quantization_group_size"
  ],
  "DeepSpeedCPUAdagrad": {
    "optimizer_id": [],
    "__init__": [
      "self",
      "model_params",
      "lr",
      "eps",
      "weight_decay",
      "amsgrad",
      "fp32_optimizer_states"
    ],
    "__del__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "_kernel": [
    "A",
    "B",
    "C",
    "stride_za",
    "stride_ha",
    "stride_ma",
    "stride_ka",
    "stride_zb",
    "stride_hb",
    "stride_kb",
    "stride_nb",
    "stride_zc",
    "stride_hc",
    "stride_mc",
    "stride_nc",
    "DS0",
    "DS1",
    "SDD_K",
    "SDD_off_width",
    "lut",
    "locks",
    "nlocks"
  ],
  "_sparse_matmul": {
    "sdd_cache": [],
    "dsd_cache": [],
    "dds_cache": [],
    "locks": [],
    "load_balance": [
      "sizes",
      "block"
    ],
    "get_locks": [
      "size",
      "dev"
    ],
    "make_sdd_lut": [
      "layout",
      "block",
      "dtype",
      "device"
    ],
    "_sdd_matmul": [
      "a",
      "b",
      "trans_a",
      "trans_b",
      "trans_c",
      "spdims",
      "block",
      "luts",
      "num_locks",
      "widths",
      "packs",
      "bench",
      "time"
    ],
    "make_dxx_lut": [
      "layout",
      "block",
      "step",
      "trans",
      "device",
      "transform"
    ],
    "_dds_matmul": [
      "a",
      "b",
      "trans_a",
      "trans_b",
      "trans_c",
      "spdims",
      "block",
      "lut",
      "num_locks",
      "width",
      "packs",
      "bench",
      "time"
    ],
    "_dsd_matmul": [
      "a",
      "b",
      "trans_a",
      "trans_b",
      "trans_c",
      "spdims",
      "block",
      "lut",
      "num_locks",
      "width",
      "packs",
      "bench",
      "time"
    ],
    "fn": [],
    "forward": [
      "ctx",
      "a",
      "b",
      "trans_a",
      "trans_b",
      "trans_c",
      "mode",
      "spdims",
      "block",
      "c_lut",
      "c_num_locks",
      "c_width",
      "c_packs",
      "c_bench",
      "c_time",
      "da_lut",
      "da_num_locks",
      "da_width",
      "da_packs",
      "da_bench",
      "da_time",
      "db_lut",
      "db_num_locks",
      "db_width",
      "db_packs",
      "db_bench",
      "db_time"
    ],
    "backward": [
      "ctx",
      "dc"
    ]
  },
  "MatMul": {
    "make_lut": [
      "self",
      "dtype",
      "device"
    ],
    "__init__": [
      "self",
      "layout",
      "block",
      "mode",
      "trans_a",
      "trans_b",
      "bench"
    ],
    "_pad_shape": [
      "x",
      "is_sparse"
    ],
    "__call__": [
      "self",
      "a",
      "b"
    ],
    "_validate_inputs": [
      "self",
      "a",
      "b"
    ]
  },
  "SparseSelfAttention": {
    "__init__": [
      "self",
      "sparsity_config",
      "key_padding_mask_mode",
      "attn_mask_mode",
      "max_seq_length"
    ],
    "ops": [],
    "get_layout": [
      "self",
      "L"
    ],
    "get_ops": [
      "self",
      "H",
      "L"
    ],
    "transpose_key_for_scores": [
      "self",
      "x",
      "L"
    ],
    "transpose_mask_for_sparse": [
      "self",
      "qtype",
      "x",
      "is_key_padding_mask"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "rpe",
      "key_padding_mask",
      "attn_mask"
    ]
  },
  "SparseAttentionUtils": {
    "extend_position_embedding": [
      "model",
      "max_position"
    ],
    "update_tokenizer_model_max_length": [
      "tokenizer",
      "max_position"
    ],
    "replace_model_self_attention_with_sparse_self_attention": [
      "model",
      "max_position",
      "sparsity_config"
    ],
    "replace_self_attention_layer_with_sparse_self_attention_layer": [
      "config",
      "layers",
      "sparsity_config"
    ],
    "pad_to_block_size": [
      "block_size",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "inputs_embeds",
      "pad_token_id",
      "model_embeddings"
    ],
    "unpad_sequence_output": [
      "pad_len",
      "sequence_output"
    ]
  },
  "next_power_of_2": [
    "n"
  ],
  "num_warps": [
    "n"
  ],
  "_forward": [
    "X",
    "scale",
    "LUT",
    "RPE",
    "KP_M",
    "ATTN_M",
    "sizemax",
    "stride_zx",
    "stride_zrpe",
    "stride_hrpe",
    "stride_srpe",
    "stride_zkpm",
    "stride_zattnm"
  ],
  "_backward": [
    "X",
    "scale",
    "DX",
    "LUT",
    "sizemax",
    "stride_zx",
    "stride_zdx"
  ],
  "_sparse_softmax": {
    "bwd_kernels": [],
    "make_lut": [
      "layout",
      "block",
      "device"
    ],
    "forward": [
      "ctx",
      "x",
      "scale",
      "rpe",
      "key_padding_mask",
      "attn_mask",
      "kp_mask_mode",
      "attn_mask_mode",
      "spdims",
      "block",
      "lut",
      "num_blocks",
      "maxlut",
      "bench",
      "time"
    ],
    "backward": [
      "ctx",
      "dx"
    ]
  },
  "Softmax": {
    "sparse_softmax": [],
    "make_lut": [
      "self",
      "device"
    ],
    "__init__": [
      "self",
      "layout",
      "block",
      "bench"
    ],
    "__call__": [
      "self",
      "x",
      "scale",
      "rpe",
      "key_padding_mask",
      "attn_mask",
      "key_padding_mask_mode",
      "attn_mask_mode"
    ]
  },
  "SparsityConfig": {
    "__init__": [
      "self",
      "num_heads",
      "block",
      "different_layout_per_head"
    ],
    "setup_layout": [
      "self",
      "seq_len"
    ],
    "check_and_propagate_first_head_layout": [
      "self",
      "layout"
    ]
  },
  "DenseSparsityConfig": {
    "__init__": [
      "self",
      "num_heads",
      "block",
      "different_layout_per_head"
    ],
    "make_layout": [
      "self",
      "seq_len"
    ]
  },
  "FixedSparsityConfig": {
    "__init__": [
      "self",
      "num_heads",
      "block",
      "different_layout_per_head",
      "num_local_blocks",
      "num_global_blocks",
      "attention",
      "horizontal_global_attention",
      "num_different_global_patterns"
    ],
    "set_local_layout": [
      "self",
      "h",
      "layout"
    ],
    "set_global_layout": [
      "self",
      "h",
      "layout"
    ],
    "make_layout": [
      "self",
      "seq_len"
    ]
  },
  "VariableSparsityConfig": {
    "__init__": [
      "self",
      "num_heads",
      "block",
      "different_layout_per_head",
      "num_random_blocks",
      "local_window_blocks",
      "global_block_indices",
      "global_block_end_indices",
      "attention",
      "horizontal_global_attention"
    ],
    "set_random_layout": [
      "self",
      "h",
      "layout"
    ],
    "set_local_layout": [
      "self",
      "h",
      "layout"
    ],
    "set_global_layout": [
      "self",
      "h",
      "layout"
    ],
    "make_layout": [
      "self",
      "seq_len"
    ]
  },
  "BigBirdSparsityConfig": {
    "__init__": [
      "self",
      "num_heads",
      "block",
      "different_layout_per_head",
      "num_random_blocks",
      "num_sliding_window_blocks",
      "num_global_blocks",
      "attention"
    ],
    "set_random_layout": [
      "self",
      "h",
      "layout"
    ],
    "set_sliding_window_layout": [
      "self",
      "h",
      "layout"
    ],
    "set_global_layout_itc": [
      "self",
      "h",
      "layout"
    ],
    "make_layout": [
      "self",
      "seq_len"
    ]
  },
  "BSLongformerSparsityConfig": {
    "__init__": [
      "self",
      "num_heads",
      "block",
      "different_layout_per_head",
      "num_sliding_window_blocks",
      "global_block_indices",
      "global_block_end_indices",
      "attention"
    ],
    "set_sliding_window_layout": [
      "self",
      "h",
      "layout"
    ],
    "set_global_layout": [
      "self",
      "h",
      "layout"
    ],
    "make_layout": [
      "self",
      "seq_len"
    ]
  },
  "LocalSlidingWindowSparsityConfig": {
    "__init__": [
      "self",
      "num_heads",
      "block",
      "num_sliding_window_blocks",
      "attention"
    ],
    "set_sliding_window_layout": [
      "self",
      "h",
      "layout"
    ],
    "make_layout": [
      "self",
      "seq_len"
    ]
  },
  "BertSparseSelfAttention": {
    "__init__": [
      "self",
      "config",
      "sparsity_config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "_build_file_index": [
    "directory",
    "suffix"
  ],
  "_module": [],
  "_directory": [],
  "FusedLamb": {
    "__init__": [
      "self",
      "params",
      "lr",
      "bias_correction",
      "betas",
      "eps",
      "eps_inside_sqrt",
      "weight_decay",
      "max_grad_norm",
      "max_coeff",
      "min_coeff",
      "amsgrad"
    ],
    "step": [
      "self",
      "closure",
      "grads",
      "output_params",
      "scale",
      "grad_norms"
    ],
    "get_lamb_coeffs": [
      "self"
    ]
  },
  "quantizer_cuda_module": [],
  "ds_quantizer": [
    "input",
    "groups",
    "bit_num",
    "sr",
    "asym"
  ],
  "transformer_cuda_module": [],
  "stochastic_transformer_cuda_module": [],
  "TransformerConfig": {
    "__init__": [
      "self",
      "batch_size",
      "hidden_size",
      "intermediate_size",
      "heads",
      "attn_dropout_ratio",
      "hidden_dropout_ratio",
      "num_hidden_layers",
      "initializer_range"
    ]
  },
  "DeepSpeedTransformerConfig": {
    "__init__": [
      "self",
      "batch_size",
      "hidden_size",
      "intermediate_size",
      "heads",
      "attn_dropout_ratio",
      "hidden_dropout_ratio",
      "num_hidden_layers",
      "initializer_range",
      "layer_norm_eps",
      "local_rank",
      "seed",
      "fp16",
      "pre_layer_norm",
      "normalize_invertible",
      "gelu_checkpoint",
      "adjust_init_range",
      "attn_dropout_checkpoint",
      "stochastic_mode",
      "return_tuple",
      "training"
    ],
    "from_dict": [
      "cls",
      "json_object"
    ],
    "from_json_file": [
      "cls",
      "json_file"
    ]
  },
  "DeepSpeedTransformerFunction": {
    "forward": [
      "ctx",
      "input",
      "input_mask",
      "self",
      "grads",
      "layer_id",
      "attn_qkvw",
      "attn_qkvb",
      "attn_ow",
      "attn_ob",
      "attn_nw",
      "attn_nb",
      "inter_w",
      "inter_b",
      "output_w",
      "output_b",
      "norm_w",
      "norm_b",
      "config"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "DeepSpeedTransformerLayer": {
    "layer_id": [],
    "__init__": [
      "self",
      "config",
      "initial_weights",
      "initial_biases"
    ],
    "init_transformer_weights": [
      "self",
      "adjust_init_range"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "layer_head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_value",
      "output_attentions",
      "grads"
    ]
  },
  "Diffusers2DTransformerConfig": {
    "__init__": [
      "self",
      "int8_quantization"
    ]
  },
  "minus_inf": [],
  "triton_flash_attn": [],
  "load_triton_flash_attn": [],
  "DeepSpeedDiffusersAttentionFunction": {
    "forward": [
      "ctx",
      "input",
      "context",
      "input_mask",
      "config",
      "attn_qkvw",
      "attn_qw",
      "attn_kw",
      "attn_vw",
      "attn_qkvb",
      "num_attention_heads_per_partition",
      "norm_factor",
      "hidden_size_per_partition",
      "attn_ow",
      "attn_ob",
      "do_out_bias",
      "score_context_func",
      "linear_func",
      "pad_transform_func",
      "triton_flash_attn_kernel",
      "rope_theta"
    ],
    "backward": [
      "ctx",
      "grad_output",
      "grad_output1",
      "grad_output2",
      "grad_output3"
    ]
  },
  "DeepSpeedDiffusersAttention": {
    "layer_id": [],
    "__init__": [
      "self",
      "config"
    ],
    "allocate_workspace": [
      "self",
      "size"
    ],
    "forward": [
      "self",
      "input",
      "context",
      "input_mask"
    ]
  },
  "DeepSpeedMoEInferenceConfig": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "heads",
      "num_hidden_layers",
      "layer_norm_eps",
      "local_rank",
      "mp_size",
      "fp16",
      "bf16",
      "q_int8",
      "pre_layer_norm",
      "stochastic_mode",
      "scale_attention",
      "triangular_masking",
      "local_attention",
      "window_size",
      "return_tuple",
      "moe_experts",
      "global_experts",
      "k",
      "capacity_factor",
      "eval_capacity_factor",
      "min_capacity",
      "noisy_gate_policy",
      "drop_tokens",
      "use_rts",
      "mlp_type",
      "scale_attn_by_inverse_layer_idx"
    ],
    "from_dict": [
      "cls",
      "json_object"
    ],
    "from_json_file": [
      "cls",
      "json_file"
    ]
  },
  "DeepSpeedMLPFunction": {
    "forward": [
      "ctx",
      "input",
      "inter_w",
      "inter_b",
      "config",
      "output_b",
      "output_w",
      "q_scales",
      "q_groups",
      "merge_count",
      "mp_group",
      "async_op",
      "gelu_gemm_func",
      "vector_matmul_func"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "DeepSpeedMoEMLP": {
    "__init__": [
      "self",
      "config",
      "q_scales",
      "q_groups",
      "merge_count",
      "mlp_extra_grouping",
      "mp_group"
    ],
    "forward": [
      "self",
      "input",
      "async_op"
    ]
  },
  "DeepSpeedMoEInference": {
    "layer_id": [],
    "__init__": [
      "self",
      "config",
      "mp_group",
      "ep_group",
      "expert_mp_group",
      "quantize_scales",
      "quantize_groups",
      "merge_count",
      "mlp_extra_grouping"
    ],
    "res_coef_func": [
      "self",
      "inp",
      "async_op"
    ],
    "moe_gate_einsum": [
      "self",
      "attention_output"
    ],
    "expert_exec": [
      "self",
      "dispatched_input"
    ],
    "_alltoall": [
      "self",
      "dispatched_attention"
    ],
    "scale_expert_output": [
      "self",
      "attention_output",
      "expert_output",
      "combined_weights"
    ],
    "forward": [
      "self",
      "input",
      "input_mask",
      "attention_mask",
      "head_mask",
      "layer_past",
      "get_key_value",
      "get_present",
      "encoder_output",
      "enc_dec_attn_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "use_cache",
      "output_attentions"
    ]
  },
  "DeepSpeedDiffusersTransformerBlock": {
    "__init__": [
      "self",
      "equivalent_module",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "context",
      "timestep"
    ]
  },
  "DeepSpeedInferenceConfig": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "heads",
      "num_hidden_layers",
      "layer_norm_eps",
      "local_rank",
      "mp_size",
      "dtype",
      "pre_layer_norm",
      "norm_type",
      "stochastic_mode",
      "scale_attention",
      "triangular_masking",
      "local_attention",
      "window_size",
      "rotary_dim",
      "rotate_half",
      "rotate_every_two",
      "return_tuple",
      "mlp_after_attn",
      "mlp_act_func_type",
      "training_mp_size",
      "bigscience_bloom",
      "max_out_tokens",
      "min_out_tokens",
      "enable_qkv_quantization",
      "use_mup",
      "scale_attn_by_inverse_layer_idx",
      "return_single_tuple",
      "set_empty_params",
      "transposed_mode",
      "use_triton",
      "triton_autotune",
      "num_kv",
      "rope_theta",
      "invert_mask"
    ],
    "from_dict": [
      "cls",
      "json_object"
    ],
    "from_json_file": [
      "cls",
      "json_file"
    ]
  },
  "DeepSpeedSelfAttention": {
    "num_layers": [],
    "_qkv_buffers": [],
    "__init__": [
      "self",
      "config",
      "mp_group",
      "q_scales",
      "q_groups",
      "merge_count"
    ],
    "compute_attention": [
      "self",
      "qkv_out",
      "input_mask",
      "layer_past",
      "alibi",
      "is_prompt",
      "token_idx",
      "position_ids"
    ],
    "_merge_qkv": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "input_mask",
      "head_mask",
      "layer_past",
      "get_present",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "output_attentions",
      "norm_w",
      "norm_b",
      "alibi"
    ]
  },
  "BloomSelfAttention": {
    "__init__": [
      "self"
    ],
    "_transpose_for_context": [
      "self",
      "x"
    ],
    "_split_tensor_along_last_dim": [
      "self",
      "tensor",
      "num_partitions",
      "contiguous_split_chunks"
    ],
    "compute_attention": [
      "self",
      "qkv_out",
      "input_mask",
      "layer_past",
      "alibi",
      "is_prompt",
      "token_idx",
      "position_ids"
    ]
  },
  "_fwd_kernel": [
    "Q",
    "K",
    "V",
    "sm_scale",
    "Out",
    "stride_qz",
    "stride_qh",
    "stride_qm",
    "stride_qk",
    "stride_kz",
    "stride_kh",
    "stride_kn",
    "stride_kk",
    "stride_vz",
    "stride_vh",
    "stride_vk",
    "stride_vn",
    "stride_oz",
    "stride_oh",
    "stride_om",
    "stride_on",
    "Z",
    "H",
    "N_CTX",
    "BLOCK_M",
    "BLOCK_DMODEL",
    "BLOCK_N"
  ],
  "spatial_cuda_module": [],
  "nhwc_bias_add": [
    "activation",
    "bias",
    "other",
    "other_bias"
  ],
  "DeepSpeedMLP": {
    "_inter_w_buffers": [],
    "__init__": [
      "self",
      "config",
      "mp_group",
      "q_scales",
      "q_groups",
      "merge_count",
      "mlp_extra_grouping"
    ],
    "_merge_inter_w": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "residual",
      "residual_norm",
      "bias"
    ]
  },
  "PadTransformOp": {
    "__init__": [
      "self",
      "config"
    ],
    "pad_transform_fallback": [
      "query",
      "key",
      "value",
      "heads",
      "do_flash_attn"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "heads",
      "do_flash_attn"
    ]
  },
  "GELUGemmOp": {
    "__init__": [
      "self",
      "config"
    ],
    "gelu_gemm_fallback": [
      "self",
      "input",
      "weight",
      "scale",
      "bias",
      "out",
      "out_scale",
      "dtype",
      "transpose"
    ],
    "forward": [
      "self",
      "input",
      "weight",
      "bias",
      "weight_out"
    ]
  },
  "BaseOp": {
    "inference_module": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "VectorAddOp": {
    "__init__": [
      "self",
      "config"
    ],
    "vector_add_fallback": [
      "cls",
      "a",
      "b",
      "gamma"
    ],
    "forward": [
      "self",
      "a",
      "b",
      "gamma"
    ]
  },
  "GatedActivationOp": {
    "__init__": [
      "self",
      "config"
    ],
    "gated_activation_fallback": [
      "cls",
      "activation",
      "bias",
      "activation_func_type"
    ],
    "forward": [
      "self",
      "activation",
      "bias",
      "activation_func_type"
    ]
  },
  "LayerNormOp": {
    "__init__": [
      "self",
      "config"
    ],
    "layer_norm_residual": [
      "cls",
      "vals",
      "bias",
      "res",
      "gamma",
      "beta",
      "epsilon"
    ],
    "layer_norm_residual_store_pre_ln_res": [
      "cls",
      "vals",
      "bias",
      "res",
      "gamma",
      "beta",
      "epsilon"
    ],
    "layer_norm_fallback": [
      "cls",
      "vals",
      "gamma",
      "beta",
      "epsilon"
    ],
    "forward": [
      "self",
      "vals",
      "gamma",
      "beta",
      "epsilon"
    ]
  },
  "SoftmaxContextOp": {
    "__init__": [
      "self",
      "config"
    ],
    "transform4d_0213": [
      "x",
      "seq_length"
    ],
    "repeat_kv": [
      "hidden_states",
      "n_rep"
    ],
    "bias_add_transform_0213": [
      "input",
      "bias",
      "num_heads",
      "trans_count",
      "perform_bias"
    ],
    "softmax_context_fallback": [
      "self",
      "query_key_value",
      "attn_mask",
      "rotary_dim",
      "rotate_half",
      "rotate_every_two",
      "heads",
      "num_kv",
      "norm_factor",
      "triangular_masking",
      "local_attention",
      "window_size",
      "no_masking",
      "layer_id",
      "num_layers",
      "alibi",
      "rope_theta",
      "is_prompt",
      "token_idx",
      "position_ids"
    ],
    "forward": [
      "self",
      "query_key_value",
      "attn_mask",
      "heads",
      "num_kv",
      "norm_factor",
      "no_masking",
      "layer_id",
      "num_layers",
      "alibi",
      "is_prompt",
      "token_idx",
      "position_ids"
    ]
  },
  "BiasResidualOp": {
    "__init__": [
      "self",
      "config"
    ],
    "bias_residual_fallback": [
      "cls",
      "output",
      "residual",
      "bias"
    ],
    "forward": [
      "self",
      "output",
      "residual",
      "bias"
    ]
  },
  "ResidualAddOp": {
    "__init__": [
      "self",
      "config"
    ],
    "res_add_bias": [
      "hidden_state",
      "residual",
      "attn_output",
      "attn_bias",
      "final_bias",
      "add_attn_bias",
      "mp_size"
    ],
    "residual_add_fallback": [
      "hidden_state",
      "residual",
      "attention_output",
      "attention_bias",
      "final_bias",
      "mp_size",
      "mlp_after_attn",
      "add_bias",
      "pre_layer_norm"
    ],
    "forward": [
      "self",
      "hidden_state",
      "residual",
      "add_bias",
      "attention_output",
      "residual_add",
      "attention_bias",
      "final_bias"
    ]
  },
  "EinsumSecSmEcmOp": {
    "__init__": [
      "self",
      "config"
    ],
    "einsum_sec_sm_ecm_fallback": [
      "cls",
      "Q",
      "W"
    ],
    "forward": [
      "self",
      "Q",
      "W"
    ]
  },
  "RMSNormOp": {
    "__init__": [
      "self",
      "config"
    ],
    "rms_norm_fallback": [
      "vals",
      "gamma",
      "epsilon"
    ],
    "forward": [
      "self",
      "vals",
      "gamma",
      "epsilon"
    ]
  },
  "SoftmaxOp": {
    "__init__": [
      "self",
      "config"
    ],
    "softmax_fallback": [
      "attn_scores",
      "attn_mask",
      "alibi",
      "triangular",
      "recompute",
      "local_attention",
      "window_size",
      "async_op",
      "layer_scale",
      "head_offset",
      "mp_size"
    ],
    "forward": [
      "self",
      "attn_scores",
      "attn_mask",
      "alibi",
      "triangular",
      "recompute",
      "local_attention",
      "window_size",
      "async_op",
      "layer_scale",
      "head_offset"
    ]
  },
  "BiasReluOp": {
    "__init__": [
      "self",
      "config"
    ],
    "bias_relu_fallback": [
      "cls",
      "activations",
      "bias"
    ],
    "forward": [
      "self",
      "activation",
      "bias"
    ]
  },
  "LinearOp": {
    "__init__": [
      "self",
      "config"
    ],
    "linear_fallback": [
      "self",
      "input",
      "weight",
      "bias",
      "add_bias",
      "do_flash_attn",
      "num_heads",
      "transpose",
      "rope_theta"
    ],
    "forward": [
      "self",
      "input",
      "weight",
      "bias",
      "add_bias",
      "do_flash_attn",
      "num_heads",
      "external_cache",
      "num_layers"
    ],
    "_triton_autotune": [
      "min_seqlen",
      "max_seqlen",
      "hidden_size",
      "dtype"
    ]
  },
  "PreRMSNormOp": {
    "__init__": [
      "self",
      "config"
    ],
    "pre_rms_norm_fallback": [
      "vals",
      "residual",
      "gamma",
      "epsilon"
    ],
    "forward": [
      "self",
      "vals",
      "residual",
      "gamma",
      "epsilon"
    ]
  },
  "BiasGeluOp": {
    "__init__": [
      "self",
      "config"
    ],
    "bias_gelu_fallback": [
      "cls",
      "activations",
      "bias"
    ],
    "forward": [
      "self",
      "activation",
      "bias"
    ]
  },
  "VectorMatMulOp": {
    "__init__": [
      "self",
      "config"
    ],
    "vector_matmul_fallback": [
      "self",
      "input",
      "weight",
      "async_op",
      "q_scale",
      "q_int8",
      "transpose"
    ],
    "forward": [
      "self",
      "input",
      "weight",
      "async_op"
    ],
    "_triton_autotune": [
      "min_seqlen",
      "max_seqlen",
      "hidden_size",
      "dtype"
    ]
  },
  "BiasAddOp": {
    "__init__": [
      "self",
      "config"
    ],
    "bias_add_fallback": [
      "cls",
      "input",
      "bias"
    ],
    "forward": [
      "self",
      "activation",
      "bias"
    ]
  },
  "MoEResMatmulOp": {
    "__init__": [
      "self",
      "config"
    ],
    "moe_res_matmul_fallback": [
      "cls",
      "residual",
      "coef",
      "output"
    ],
    "forward": [
      "self",
      "residual",
      "coef",
      "output"
    ]
  },
  "key_idx": [],
  "value_idx": [],
  "WorkspaceOp": {
    "__init__": [
      "self",
      "config"
    ],
    "allocate_workspace": [
      "self"
    ],
    "release_workspace": [
      "self"
    ],
    "reset_cache": [
      "self"
    ],
    "retake_workspace": [
      "self"
    ],
    "allocate_workspace_fp32_fallback": [
      "self",
      "hidden_dim",
      "num_heads",
      "prompt_length",
      "batch_size",
      "num_layers",
      "mp_size",
      "external_cache",
      "rank",
      "max_out_tokens",
      "min_out_tokens"
    ],
    "allocate_workspace_bf16_fallback": [
      "self",
      "hidden_dim",
      "num_heads",
      "prompt_length",
      "batch_size",
      "num_layers",
      "mp_size",
      "external_cache",
      "rank",
      "max_out_tokens",
      "min_out_tokens"
    ],
    "allocate_workspace_fp16_fallback": [
      "self",
      "hidden_dim",
      "num_heads",
      "prompt_length",
      "batch_size",
      "num_layers",
      "mp_size",
      "external_cache",
      "rank",
      "max_out_tokens",
      "min_out_tokens"
    ],
    "reset_cache_fallback": [
      "self"
    ],
    "release_workspace_fallback": [
      "self"
    ],
    "retake_workspace_fallback": [
      "self"
    ],
    "is_allocated": [
      "self"
    ]
  },
  "QKVGemmOp": {
    "__init__": [
      "self",
      "config"
    ],
    "_triton_autotune": [
      "min_seqlen",
      "max_seqlen",
      "hidden_size",
      "dtype"
    ],
    "qkv_gemm_fallback": [
      "input",
      "weight",
      "q_scale",
      "bias",
      "gamma",
      "beta",
      "eps",
      "add_bias",
      "q_int8",
      "transpose"
    ],
    "rms_qkv_gemm_fallback": [
      "input",
      "weight",
      "q_scale",
      "gamma",
      "eps",
      "q_int8",
      "transpose"
    ],
    "forward": [
      "self",
      "input",
      "weight",
      "bias",
      "gamma",
      "beta"
    ]
  },
  "MLPGemmOp": {
    "__init__": [
      "self",
      "config"
    ],
    "mlp_gemm_fallback": [
      "self",
      "input",
      "residual",
      "input_bias",
      "weight_interm",
      "weight_out",
      "bias",
      "gamma",
      "beta",
      "eps",
      "pre_layer_norm",
      "mlp_after_attn",
      "interm_scale",
      "out_scale",
      "dtype",
      "mlp_act_func_type",
      "transpose"
    ],
    "rms_mlp_gemm_fallback": [
      "self",
      "input",
      "residual",
      "weight_interm",
      "weight_out",
      "gamma",
      "eps",
      "interm_scale",
      "out_scale",
      "dtype",
      "mlp_act_func_type",
      "transpose"
    ],
    "forward": [
      "self",
      "input",
      "residual",
      "weight_interm",
      "weight_out",
      "input_bias",
      "bias",
      "gamma",
      "beta"
    ]
  },
  "is_nfs_path": [
    "path"
  ],
  "TritonCacheDir": {
    "_warning_printed": [],
    "warn_if_nfs": [
      "cache_dir"
    ],
    "default_cache_dir": []
  },
  "bias_add_activation": [
    "C",
    "bias",
    "activation"
  ],
  "AutotuneCacheManager": {
    "__init__": [
      "self",
      "key"
    ],
    "has_file": [
      "self"
    ],
    "put": [
      "self",
      "table"
    ],
    "load": [
      "self"
    ]
  },
  "MatmulExt": {
    "forward": [
      "A",
      "B",
      "bias",
      "activation",
      "use_triton",
      "update_autotune_table"
    ]
  },
  "TritonMatmul": {
    "__init__": [
      "self"
    ],
    "_ref_forward": [
      "A",
      "B",
      "ref_dtype"
    ],
    "_read_autotune_table": [
      "cache_key",
      "triton_kernel"
    ],
    "_write_autotune_table": [
      "cache_key",
      "triton_kernel"
    ],
    "_update_autotune_table": [
      "cache_key",
      "triton_kernel"
    ],
    "forward": [
      "A",
      "B",
      "ref_dtype",
      "bias",
      "activation"
    ]
  },
  "Fp16Matmul": {
    "_2d_kernel": [],
    "_4d_kernel": [],
    "_cache_stride": [],
    "__init__": [
      "self",
      "read_cache"
    ],
    "skip_autotune": [
      "self"
    ],
    "forward": [
      "A",
      "B",
      "use_triton",
      "bias",
      "activation"
    ],
    "_matmul_4d": [
      "a",
      "b"
    ],
    "_score_4d_matmul": [
      "input",
      "head_size",
      "input_mask",
      "scale"
    ],
    "_context_4d_matmul": [
      "prob",
      "input",
      "head_size"
    ],
    "_ref_forward": [
      "A",
      "B",
      "ref_dtype",
      "bias",
      "activation"
    ],
    "_check_parity": [
      "A",
      "B",
      "output_dtype",
      "SA",
      "SB",
      "qblock_size",
      "ref_dtype",
      "tol",
      "use_triton",
      "bias",
      "activation"
    ],
    "_read_autotune_table": [],
    "_write_autotune_table": [],
    "_update_autotune_table": []
  },
  "matmul_ext_update_autotune_table": [],
  "gelu_functor": [
    "x"
  ],
  "gelu_kernel": [
    "x_ptr",
    "output_ptr",
    "n_elements",
    "BLOCK_SIZE"
  ],
  "gelu": [
    "activations"
  ],
  "TritonMLP": {
    "__init__": [
      "self",
      "config",
      "mp_group",
      "q_scales",
      "q_groups",
      "merge_count",
      "mlp_extra_grouping"
    ],
    "forward": [
      "self",
      "input",
      "residual",
      "residual_norm",
      "bias"
    ]
  },
  "layer_norm_kernel": [
    "Out",
    "A",
    "Weight",
    "Bias",
    "stride",
    "N",
    "eps",
    "BLOCK_SIZE"
  ],
  "layer_norm_residual_kernel": [
    "Out",
    "A",
    "Residual",
    "ln_input",
    "Weight",
    "Bias",
    "stride",
    "N",
    "eps",
    "BLOCK_SIZE"
  ],
  "layer_norm_residual_bias_kernel": [
    "Out",
    "A",
    "Residual",
    "InputBias",
    "ln_input",
    "Weight",
    "Bias",
    "stride",
    "N",
    "eps",
    "BLOCK_SIZE"
  ],
  "layer_norm": [
    "a",
    "weight",
    "bias",
    "eps"
  ],
  "layer_norm_residual": [
    "a",
    "input_bias",
    "residual",
    "weight",
    "bias",
    "eps"
  ],
  "TritonSelfAttention": {
    "num_layers": [],
    "__init__": [
      "self",
      "config",
      "mp_group",
      "q_scales",
      "q_groups",
      "merge_count",
      "qkv_merging"
    ],
    "_triton_autotune": [
      "min_seqlen",
      "max_seqlen",
      "head_size",
      "hidden_size",
      "triangular_masking",
      "scale",
      "dtype"
    ],
    "ds_compute_attention": [
      "self",
      "qkv_out",
      "input_mask",
      "layer_past",
      "alibi",
      "is_prompt",
      "token_idx",
      "position_ids"
    ],
    "forward": [
      "self",
      "input",
      "input_mask",
      "head_mask",
      "layer_past",
      "get_present",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "triangularutput_attentions",
      "norm_w",
      "norm_b",
      "alibi",
      "use_triton_attention"
    ]
  },
  "_triton_attention": [
    "qkv",
    "input_mask",
    "layer_past",
    "alibi",
    "scale",
    "head_size",
    "triangular",
    "use_cuda_flash",
    "use_triton_flash",
    "use_ds_attention"
  ],
  "_flash_packed_kernel": [
    "QKV",
    "mask",
    "ADD_MASK",
    "IS_CAUSAL",
    "sm_scale",
    "Out",
    "stride_qz",
    "stride_qn",
    "stride_qm",
    "stride_mz",
    "stride_oz",
    "stride_on",
    "Z",
    "H",
    "N_CTX",
    "P_SEQ",
    "hidden_size",
    "BLOCK_M",
    "BLOCK_DMODEL",
    "BLOCK_N"
  ],
  "_triton_packed_flash": [
    "qkv",
    "head_size",
    "mask",
    "sm_scale",
    "causal",
    "add_mask"
  ],
  "residual_add_bias_kernel": [
    "hidden_state_ptr",
    "residual_ptr",
    "attn_output_ptr",
    "hidden_state_size",
    "attn_bias_ptr",
    "final_bias_ptr",
    "bias_size",
    "output_ptr",
    "mp_size",
    "mlp_after_attn",
    "pre_attn_norm",
    "add_attn_bias",
    "BLOCK_SIZE"
  ],
  "residual_add_bias": [
    "hidden_state",
    "residual",
    "attn_output",
    "attn_bias",
    "final_bias",
    "mp_size",
    "mlp_after_attn",
    "add_attn_bias",
    "pre_attn_norm"
  ],
  "vector_matmul_func": [
    "input",
    "weight",
    "async_op",
    "q_scale",
    "q_int8",
    "transposed_mode"
  ],
  "fused_gemm_gelu": [
    "input",
    "weight",
    "weight_scale",
    "bias",
    "weight_out",
    "weight_out_scale",
    "epsilon",
    "pre_layer_norm",
    "q_int8",
    "async_op",
    "transposed_mode",
    "use_triton_ln"
  ],
  "linear_func": [
    "input",
    "weight",
    "bias",
    "add_bias",
    "do_flash_attn",
    "num_heads",
    "transposed_mode"
  ],
  "mlp_gemm_func": [
    "input",
    "residual",
    "input_bias",
    "weight_interm",
    "weight_out",
    "bias",
    "gamma",
    "beta",
    "epsilon",
    "pre_layer_norm",
    "mlp_after_attn",
    "weight_interm_scale",
    "weight_out_scale",
    "q_int8",
    "mlp_act_func_type",
    "transposed_mode",
    "use_triton_ln"
  ],
  "qkv_gemm_func": [
    "input",
    "weight",
    "q_scale",
    "bias",
    "gamma",
    "beta",
    "epsilon",
    "add_bias",
    "q_int8",
    "transposed_mode",
    "use_triton_ln"
  ],
  "softmax_kernel": [
    "output_ptr",
    "input_ptr",
    "stride",
    "n_cols",
    "BLOCK_SIZE"
  ],
  "masked_softmax_kernel": [
    "output_ptr",
    "input_ptr",
    "stride",
    "mask_ptr",
    "mask_stride",
    "n_cols",
    "BLOCK_SIZE"
  ],
  "softmax": [
    "input",
    "mask",
    "dim"
  ],
  "AUTOTUNE_TOP_K": [],
  "SKIP_AUTOTUNE": [],
  "_triton_ops_matmul_early_config_prune": [
    "configs",
    "named_args"
  ],
  "_fp16_matmul_prune_config": [
    "configs",
    "named_args",
    "skip_autotune"
  ],
  "_fp_matmul": [
    "A",
    "B",
    "C",
    "M",
    "N",
    "K",
    "bias",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "CACHE_M",
    "CACHE_N",
    "CACHE_K",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "GROUP_M",
    "SPLIT_K",
    "EVEN_K",
    "ACC_TYPE",
    "BIAS_ADD",
    "ACTIVATION"
  ],
  "matmul_4d_prune_config": [
    "configs",
    "named_args",
    "skip_autotune"
  ],
  "matmul_4d_kernel": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "M",
    "N",
    "K",
    "CACHE_M",
    "CACHE_N",
    "CACHE_K",
    "stride_ab",
    "stride_ah",
    "stride_am",
    "stride_ak",
    "stride_bb",
    "stride_bh",
    "stride_bk",
    "stride_bn",
    "stride_cb",
    "stride_ch",
    "stride_cm",
    "stride_cn",
    "scale",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "MASK"
  ],
  "multi_tensor_applier": [],
  "FusedLion": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "weight_decay",
      "set_grad_none"
    ],
    "zero_grad": [
      "self"
    ],
    "step": [
      "self",
      "closure",
      "grads",
      "output_params",
      "scale",
      "grad_norms",
      "grad_scaler"
    ]
  },
  "MultiTensorApply": {
    "__init__": [
      "self",
      "chunk_size"
    ],
    "__call__": [
      "self",
      "op",
      "noop_flag_buffer",
      "tensor_lists"
    ]
  },
  "DeepSpeedCPULion": {
    "optimizer_id": [],
    "__init__": [
      "self",
      "model_params",
      "lr",
      "betas",
      "weight_decay",
      "fp32_optimizer_states"
    ],
    "__del__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "_ZENFLOW_AVAILABLE": [],
  "ZenFlowSelectiveAdamW": {
    "__init__": [
      "self"
    ],
    "temp_copy_param": [
      "self",
      "group_to_paramlist"
    ],
    "copy_mv_from_cpu": [
      "self",
      "params"
    ],
    "copy_mv_to_cpu": [
      "self",
      "params"
    ],
    "clear_selected_mv": [
      "self"
    ],
    "_step_without_offload": [
      "self"
    ],
    "_step_with_offload": [
      "self"
    ],
    "group_step": [
      "self",
      "group_to_paramlist"
    ]
  },
  "ZenFlowSelectiveAdamW_stage3": {
    "__init__": [
      "self"
    ],
    "temp_copy_param": [
      "self",
      "paramlist"
    ],
    "clear_selected_mv": [
      "self"
    ],
    "_step_without_offload": [
      "self"
    ],
    "copy_mv_from_cpu": [
      "self",
      "params"
    ],
    "copy_mv_to_cpu": [
      "self",
      "params"
    ],
    "group_step": [
      "self",
      "paramlist"
    ],
    "_step_with_offload": [
      "self"
    ]
  },
  "_single_tensor_adamw": [
    "params",
    "grads",
    "exp_avgs",
    "exp_avg_sqs",
    "max_exp_avg_sqs",
    "state_steps",
    "grad_scale",
    "found_inf"
  ],
  "_multi_tensor_adamw": [
    "params",
    "grads",
    "exp_avgs",
    "exp_avg_sqs",
    "max_exp_avg_sqs",
    "state_steps",
    "grad_scale",
    "found_inf"
  ],
  "_fused_adamw": [
    "params",
    "grads",
    "exp_avgs",
    "exp_avg_sqs",
    "max_exp_avg_sqs",
    "state_steps",
    "grad_scale",
    "found_inf"
  ],
  "adamw": [
    "params",
    "grads",
    "exp_avgs",
    "exp_avg_sqs",
    "max_exp_avg_sqs",
    "state_steps",
    "foreach",
    "capturable",
    "differentiable",
    "fused",
    "grad_scale",
    "found_inf",
    "has_complex"
  ],
  "FusedAdam": {
    "__init__": [
      "self",
      "params",
      "lr",
      "bias_correction",
      "betas",
      "eps",
      "adam_w_mode",
      "weight_decay",
      "amsgrad",
      "set_grad_none"
    ],
    "zero_grad": [
      "self"
    ],
    "step": [
      "self",
      "closure",
      "grads",
      "output_params",
      "scale",
      "grad_norms",
      "grad_scaler"
    ]
  },
  "ZenFlowCPUAdam": {
    "__init__": [
      "self"
    ],
    "_sequential_step": [
      "self",
      "step_id",
      "closure"
    ],
    "_parallel_step": [
      "self",
      "step_id",
      "now_state",
      "group_info",
      "closure"
    ]
  },
  "DeepSpeedCPUAdam": {
    "optimizer_id": [],
    "__init__": [
      "self",
      "model_params",
      "lr",
      "bias_correction",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "adamw_mode",
      "fp32_optimizer_states"
    ],
    "__del__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "step": [
      "self",
      "closure"
    ],
    "step_subgroup": [
      "self",
      "subgroup_id",
      "closure"
    ],
    "rollback_subgroup": [
      "self",
      "sub_group_id",
      "closure"
    ]
  },
  "TIMEOUT": [],
  "ResourceManager": {
    "__init__": [
      "self",
      "args",
      "hosts",
      "num_gpus_per_node",
      "results_dir",
      "exps_dir",
      "arg_mappings"
    ],
    "schedule_experiments": [
      "self",
      "exp_paths"
    ],
    "run_job": [
      "self",
      "exp",
      "reservations"
    ],
    "experiment_check": [
      "self",
      "pbar"
    ],
    "resource_request": [
      "self",
      "exp"
    ],
    "status": [
      "self"
    ],
    "run": [
      "self"
    ],
    "save_exp_results_to_database": [
      "self",
      "message",
      "ranks",
      "path"
    ],
    "parse_results": [
      "self",
      "metric"
    ],
    "clear": [
      "self"
    ]
  },
  "Node": {
    "__init__": [
      "self",
      "host",
      "max_slots"
    ],
    "reserve_slots": [
      "self",
      "slot_request"
    ],
    "restore_slots": [
      "self",
      "slots"
    ]
  },
  "Reservation": {
    "__init__": [
      "self",
      "node",
      "slots"
    ],
    "restore_slots": [
      "self"
    ],
    "desc": [
      "self"
    ]
  },
  "get_job_id": [],
  "get_user": [],
  "run_experiment": [
    "exp",
    "reservations",
    "user_script",
    "user_args"
  ],
  "PDSH_MAX_FAN_OUT": [],
  "clean_up": [
    "exp",
    "reservations"
  ],
  "search_error": [
    "filename"
  ],
  "was_interrupted": [
    "filename"
  ],
  "find_replace_str": [
    "value",
    "replace_dict"
  ],
  "find_replace": [
    "target",
    "replace_dict"
  ],
  "get_list": [
    "val"
  ],
  "combine_dict": [
    "d",
    "u"
  ],
  "del_if_exists": [
    "t",
    "d"
  ],
  "replace_dict": [
    "d",
    "u",
    "ignored_keys"
  ],
  "get_val_by_key": [
    "d",
    "k"
  ],
  "set_val_by_key": [
    "d",
    "k",
    "vv"
  ],
  "fetch_hostfile": [
    "hostfile_path"
  ],
  "validate_ds_config": [
    "config"
  ],
  "remove_dupe_dicts": [
    "l"
  ],
  "prune_config": [
    "config",
    "ignored_keys"
  ],
  "prune_configs": [
    "configs",
    "ignored_keys"
  ],
  "get_tuning_keys": [
    "tuning_space"
  ],
  "get_all_configs": [
    "tuning_space",
    "ignore_keys"
  ],
  "canonical_name": [
    "config",
    "tuning_keys",
    "prefix",
    "omit_val"
  ],
  "get_first_config": [
    "config"
  ],
  "write_experiments": [
    "exps",
    "exps_dir"
  ],
  "memory_to_string": [
    "n",
    "postfix",
    "units",
    "precision"
  ],
  "number_to_string": [
    "n",
    "postfix",
    "units",
    "precision"
  ],
  "DeepSpeedAutotuningConfig": {
    "__init__": [
      "self",
      "param_dict"
    ],
    "_initialize": [
      "self",
      "autotuning_dict"
    ]
  },
  "get_model_info_config": [
    "param_dict"
  ],
  "get_default_model_info_config": [],
  "ZERO_OPTIMIZATION_STAGE": [],
  "OFFLOAD_OPTIMIZER": [],
  "OFFLOAD_PARAM": [],
  "ZERO_OPTIMIZATION_STAGE_DEFAULT": [],
  "Autotuner": {
    "__init__": [
      "self",
      "args",
      "active_resources"
    ],
    "print_tuning_results": [
      "self"
    ],
    "_get_user_config": [
      "self",
      "user_args"
    ],
    "_get_resource_manager": [
      "self",
      "active_resources"
    ],
    "_get_exp_resources": [
      "self",
      "args"
    ],
    "metric": [
      "self"
    ],
    "fast_enabled": [
      "self"
    ],
    "max_train_batch_size": [
      "self"
    ],
    "mp_size": [
      "self"
    ],
    "max_train_micro_batch_size_per_gpu": [
      "self"
    ],
    "min_train_micro_batch_size_per_gpu": [
      "self"
    ],
    "num_tuning_micro_batch_sizes": [
      "self"
    ],
    "fp16_enabled": [
      "self"
    ],
    "get_gpu_memory_info": [
      "self"
    ],
    "get_activation_memory_per_gpu": [
      "self"
    ],
    "get_instantiation_memory_required_per_gpu": [
      "self",
      "zero_stage"
    ],
    "_generate_experiments": [
      "self",
      "tuning_space",
      "max_train_batch_size_per_gpu"
    ],
    "tune": [
      "self"
    ],
    "tune_space": [
      "self",
      "tuning_space",
      "prev_max_mbs",
      "prev_best_mbs",
      "prev_best_metric_val"
    ],
    "get_plateau_mbs": [
      "self",
      "tuning_space_name"
    ],
    "get_model_num_params": [
      "self"
    ],
    "model_info_profile_run": [
      "self"
    ],
    "update_records": [
      "self",
      "space_name",
      "exp",
      "metric_val",
      "num_exps"
    ],
    "get_best_space_record": [
      "self",
      "space_name"
    ],
    "get_best_space_records": [
      "self"
    ],
    "run_tuning_micro_batch_sizes": [
      "self",
      "tuning_micro_batch_sizes",
      "max_train_batch_size_per_gpu",
      "min_micro_batch_size",
      "stage",
      "tuning_micro_batch_sizes_overwritten"
    ],
    "get_min_max_micro_batch_size": [
      "self",
      "stage",
      "min_micro_batch_size",
      "calculated_max_micro_batch_size"
    ],
    "get_gas_from_user_config": [
      "self"
    ],
    "get_val_from_user_args": [
      "self",
      "ds_name"
    ],
    "get_tuning_micro_batch_size_list": [
      "self",
      "min_micro_batch_size",
      "max_micro_batch_size",
      "num_tuning_micro_batch_sizes"
    ],
    "run_ds_config": [
      "self",
      "ds_config",
      "exp_name"
    ],
    "write_optimal_config": [
      "self"
    ],
    "run_after_tuning": [
      "self"
    ]
  },
  "DEFAULT_TEMPLATE_PATH_ZERO_0": [],
  "DEFAULT_TEMPLATE_PATH_ZERO_1": [],
  "DEFAULT_TEMPLATE_PATH_ZERO_2": [],
  "DEFAULT_TEMPLATE_PATH_ZERO_3": [],
  "METRIC_PERCENT_DIFF_CONST": [],
  "DS_CONFIG": [],
  "BUFSIZE": [],
  "AUTOTUNING_FORMAT": [],
  "AUTOTUNING": [],
  "AUTOTUNING_ENABLED": [],
  "AUTOTUNING_ENABLED_DEFAULT": [],
  "AUTOTUNING_FAST": [],
  "AUTOTUNING_FAST_DEFAULT": [],
  "AUTOTUNING_RESULTS_DIR": [],
  "AUTOTUNING_RESULTS_DIR_DEFAULT": [],
  "AUTOTUNING_EXPS_DIR": [],
  "AUTOTUNING_EXPS_DIR_DEFAULT": [],
  "AUTOTUNING_OVERWRITE": [],
  "AUTOTUNING_OVERWRITE_DEFAULT": [],
  "AUTOTUNING_START_PROFILE_STEP": [],
  "AUTOTUNING_START_PROFILE_STEP_DEFAULT": [],
  "AUTOTUNING_END_PROFILE_STEP": [],
  "AUTOTUNING_END_PROFILE_STEP_DEFAULT": [],
  "AUTOTUNING_METRIC_PATH": [],
  "AUTOTUNING_METRIC_PATH_DEFAULT": [],
  "AUTOTUNING_TUNER_TYPE": [],
  "AUTOTUNING_TUNER_GRIDSEARCH": [],
  "AUTOTUNING_TUNER_RANDOM": [],
  "AUTOTUNING_TUNER_MODELBASED": [],
  "AUTOTUNING_TUNER_TYPE_DEFAULT": [],
  "AUTOTUNING_TUNER_EARLY_STOPPING": [],
  "AUTOTUNING_TUNER_EARLY_STOPPING_DEFAULT": [],
  "AUTOTUNING_TUNER_NUM_TRIALS": [],
  "AUTOTUNING_TUNER_NUM_TRIALS_DEFAULT": [],
  "AUTOTUNING_ARG_MAPPINGS": [],
  "AUTOTUNING_ARG_MAPPINGS_DEFAULT": [],
  "AUTOTUNING_MAX_TRAIN_BATCH_SIZE": [],
  "AUTOTUNING_MAX_TRAIN_BATCH_SIZE_DEFAULT": [],
  "AUTOTUNING_MIN_TRAIN_BATCH_SIZE": [],
  "AUTOTUNING_MIN_TRAIN_BATCH_SIZE_DEFAULT": [],
  "AUTOTUNING_MAX_TRAIN_MICRO_BATCH_SIZE_PER_GPU": [],
  "AUTOTUNING_MAX_TRAIN_MICRO_BATCH_SIZE_PER_GPU_DEFAULT": [],
  "AUTOTUNING_MIN_TRAIN_MICRO_BATCH_SIZE_PER_GPU": [],
  "AUTOTUNING_MIN_TRAIN_MICRO_BATCH_SIZE_PER_GPU_DEFAULT": [],
  "AUTOTUNING_NUM_TUNING_MICRO_BATCH_SIZES": [],
  "AUTOTUNING_NUM_TUNING_MICRO_BATCH_SIZES_DEFAULT": [],
  "AUTOTUNING_MP_SIZE": [],
  "AUTOTUNING_MP_SIZE_DEFAULT": [],
  "AUTOTUNING_METRIC": [],
  "AUTOTUNING_METRIC_LATENCY": [],
  "AUTOTUNING_METRIC_THROUGHPUT": [],
  "AUTOTUNING_METRIC_FLOPS": [],
  "AUTOTUNING_METRIC_FORWARD": [],
  "AUTOTUNING_METRIC_BACKWRAD": [],
  "AUTOTUNING_METRIC_STEPS": [],
  "AUTOTUNING_METRIC_DEFAULT": [],
  "AUTOTUNING_MODEL_INFO_PATH": [],
  "AUTOTUNING_MODEL_INFO_PATH_DEFAULT": [],
  "MODEL_INFO_FORMAT": [],
  "MODEL_INFO": [],
  "MODEL_INFO_PROFILE": [],
  "MODEL_INFO_PROFILE_DEFAULT": [],
  "MODEL_INFO_NUM_PARAMS": [],
  "MODEL_INFO_NUM_PARAMS_DEFAULT": [],
  "MODEL_INFO_HIDDEN_SIZE": [],
  "MODEL_INFO_HIDDEN_SIZE_DEFAULT": [],
  "MODEL_INFO_NUM_LAYERS": [],
  "MODEL_INFO_NUM_LAYERS_DEFAULT": [],
  "MODEL_INFO_KEY_DEFAULT_DICT": [],
  "DEFAULT_HF_CONFIG": [],
  "DEFAULT_MIN_MEM_CONFIG": [],
  "DEFAULT_TUNING_SPACE_ZERO_0": [],
  "DEFAULT_TUNING_SPACE_ZERO_1": [],
  "DEFAULT_TUNING_SPACE_ZERO_2": [],
  "DEFAULT_TUNING_SPACE_ZERO_3": [],
  "GLOBAL_TUNING_SPACE": [],
  "TUNING_MICRO_BATCH_SIZE_PREFIX": [],
  "index_to_feature": [
    "p",
    "dims"
  ],
  "feature_to_index": [
    "feature",
    "dims"
  ],
  "dict_to_dims": [
    "tuning_space"
  ],
  "gen_combinations": [
    "d"
  ],
  "flatten": [
    "d",
    "parent_key",
    "sep"
  ],
  "dict_to_feature": [
    "feature_dict",
    "keys",
    "max_value"
  ],
  "XGBoostCostModel": {
    "__init__": [
      "self",
      "loss_type",
      "num_threads",
      "log_interval",
      "upper_model"
    ],
    "fit": [
      "self",
      "xs",
      "ys"
    ],
    "predict": [
      "self",
      "xs"
    ]
  },
  "BaseTuner": {
    "__init__": [
      "self",
      "exps",
      "resource_manager",
      "metric"
    ],
    "has_next": [
      "self"
    ],
    "next_batch": [
      "self",
      "sample_size"
    ],
    "update": [
      "self"
    ],
    "tune": [
      "self",
      "sample_size",
      "n_trials",
      "early_stopping"
    ]
  },
  "INIT_NUM": [],
  "ModelBasedTuner": {
    "__init__": [
      "self",
      "exps",
      "resource_manager",
      "metric",
      "tuning_space"
    ],
    "find_estimated_top_configs": [
      "self"
    ],
    "next_batch": [
      "self",
      "sample_size"
    ],
    "has_next": [
      "self"
    ],
    "update": [
      "self"
    ]
  },
  "RandomTuner": {
    "__init__": [
      "self",
      "exps",
      "resource_manager",
      "metric"
    ],
    "next_batch": [
      "self",
      "sample_size"
    ]
  },
  "GridSearchTuner": {
    "__init__": [
      "self",
      "exps",
      "resource_manager",
      "metric"
    ],
    "next_batch": [
      "self",
      "sample_size"
    ]
  },
  "AIOBasic_Engine": {
    "__init__": [
      "self",
      "args",
      "tid",
      "read_op"
    ],
    "fini": [
      "self"
    ],
    "read": [
      "self",
      "args",
      "tid",
      "loop_id"
    ],
    "write": [
      "self",
      "args",
      "tid",
      "loop_id"
    ],
    "_create_context": [
      "self",
      "args",
      "tid",
      "read_op"
    ]
  },
  "ds_io_main": [],
  "OTHER_OPTIONS": [],
  "PERF_SCRIPT": [],
  "DEFAULT_SWEEP_CONFIG": [],
  "SweepConfig": {
    "__init__": [
      "self",
      "args"
    ]
  },
  "validate_arguments": [
    "args"
  ],
  "parse_sweep_arguments": [],
  "dump_cmd_lines": [
    "cmd_lines"
  ],
  "get_ftd_map": [
    "nvme_dir_list"
  ],
  "get_sweep_config_dict": [
    "sweep_config_json"
  ],
  "get_sweep_cmd_lines": [
    "sweep_config_dict"
  ],
  "launch_sweep": [
    "sweep_jobs",
    "sync_job",
    "flush_cache_job",
    "verbose"
  ],
  "create_cmd_tags": [
    "cmd_line"
  ],
  "get_log_file": [
    "io_op_desc",
    "cmd_line"
  ],
  "create_perf_jobs": [
    "io_op_desc",
    "log_dir",
    "cmd_lines"
  ],
  "script_path": [],
  "async_io_setup": [],
  "gds_io_setup": [],
  "remove_folder": [
    "folder"
  ],
  "run_read_sweep": [
    "sweep_config",
    "flush_cache_job",
    "sync_job",
    "cmd_lines"
  ],
  "run_write_sweep": [
    "sweep_config",
    "flush_cache_job",
    "sync_job",
    "cmd_lines"
  ],
  "sweep_main": [
    "args"
  ],
  "Job": {
    "__init__": [
      "self",
      "cmd_line",
      "output_file",
      "work_dir"
    ],
    "cmd": [
      "self"
    ],
    "get_stdout": [
      "self"
    ],
    "get_stderr": [
      "self"
    ],
    "get_cwd": [
      "self"
    ],
    "open_output_file": [
      "self"
    ],
    "close_output_file": [
      "self"
    ]
  },
  "run_job": [
    "job",
    "verbose"
  ],
  "AIO_HANDLE": [],
  "AIO_BASIC": [],
  "TORCH_IO": [],
  "TORCH_FAST_IO": [],
  "VALID_ENGINES": [],
  "BUFFER": [],
  "BOUNCE_BUFFER": [],
  "NUM_BYTES": [],
  "FILE": [],
  "HANDLE": [],
  "ELAPSED_SEC": [],
  "FAST_IO_BUFFER": [],
  "USE_CPU_LOCKED_TENSOR": [],
  "USE_GDS": [],
  "validate_args": [
    "args"
  ],
  "convert_to_param": [
    "key"
  ],
  "generate_aio_param": [
    "read_log_dir",
    "write_log_dir"
  ],
  "generate_main": [
    "log_dir"
  ],
  "READ_SPEED": [],
  "WRITE_SPEED": [],
  "PERF_METRICS": [],
  "METRIC_SEARCH": [],
  "extract_value": [
    "key",
    "file"
  ],
  "get_file_key": [
    "file"
  ],
  "get_thread_count": [
    "file"
  ],
  "get_metric": [
    "file",
    "metric"
  ],
  "get_results": [
    "log_files",
    "metric"
  ],
  "get_sorted_results": [
    "log_dir",
    "metric"
  ],
  "BYTES_PER_GB": [],
  "BYTES_PER_MB": [],
  "BYTES_PER_KB": [],
  "LOG_TIDS": [],
  "task_log": [
    "tid",
    "msg",
    "force"
  ],
  "task_barrier": [
    "barrier",
    "num_parties"
  ],
  "report_results": [
    "args",
    "read_op",
    "pool_results"
  ],
  "get_block_size_and_count": [
    "io_bytes"
  ],
  "refine_integer_value": [
    "value"
  ],
  "create_filename": [
    "folder",
    "read_op",
    "size",
    "tid"
  ],
  "create_file": [
    "filename",
    "num_bytes"
  ],
  "create_page_locked_tensor": [
    "num_elem",
    "use_accelerator",
    "aio_handle"
  ],
  "prepare_operation": [
    "args",
    "tid",
    "read_op"
  ],
  "prepare_read": [
    "pool_params"
  ],
  "prepare_write": [
    "pool_params"
  ],
  "post_operation": [
    "pool_params"
  ],
  "read_operation": [
    "pool_params"
  ],
  "write_operation": [
    "pool_params"
  ],
  "get_schedule": [
    "args",
    "read_op"
  ],
  "io_engine_tasklet": [
    "pool_params"
  ],
  "_init_takslet": [
    "b"
  ],
  "io_engine_multiprocessing": [
    "args",
    "read_op"
  ],
  "TorchIO_Engine": {
    "__init__": [
      "self",
      "args",
      "tid",
      "read_op"
    ],
    "fini": [
      "self"
    ],
    "read": [
      "self",
      "args",
      "tid"
    ],
    "write": [
      "self",
      "args",
      "tid"
    ],
    "_create_context": [
      "self",
      "args",
      "tid",
      "read_op"
    ]
  },
  "SCRIPT_PREFIX": [],
  "WRITE_OP_DESC": [],
  "READ_OP_DESC": [],
  "READ_IO_DIR": [],
  "WRITE_IO_DIR": [],
  "BENCH_LOG_DIR": [],
  "READ_LOG_DIR": [],
  "WRITE_LOG_DIR": [],
  "AIOHandle_Engine": {
    "__init__": [
      "self",
      "args",
      "tid",
      "read_op"
    ],
    "fini": [
      "self"
    ],
    "read": [
      "self",
      "args",
      "tid",
      "loop_id"
    ],
    "write": [
      "self",
      "args",
      "tid",
      "loop_id"
    ],
    "_create_files": [
      "self",
      "args",
      "folder",
      "tid"
    ],
    "_create_context": [
      "self",
      "args",
      "tid",
      "read_op"
    ]
  },
  "MAPPING_DELIMITER": [],
  "refine_args": [
    "args"
  ],
  "_get_mapping_dict": [
    "args"
  ],
  "_validate_folder_mapping": [
    "args"
  ],
  "get_validated_args": [],
  "Torch_FastIO_Engine": {
    "__init__": [
      "self",
      "args",
      "tid",
      "read_op"
    ],
    "fini": [
      "self"
    ],
    "read": [
      "self",
      "args",
      "tid"
    ],
    "write": [
      "self",
      "args",
      "tid"
    ],
    "_create_context": [
      "self",
      "args",
      "tid",
      "read_op"
    ]
  },
  "DeepSpeedTransformerBase": {
    "__init__": [
      "self"
    ]
  },
  "DeepSpeedMegatronGPTInference": {
    "__init__": [
      "self",
      "config",
      "mp_group",
      "quantize_scales",
      "quantize_groups",
      "merge_count",
      "mlp_extra_grouping"
    ]
  },
  "DeepSpeedOPTInference": {
    "__init__": [
      "self",
      "config",
      "mp_group",
      "quantize_scales",
      "quantize_groups",
      "merge_count",
      "mlp_extra_grouping"
    ]
  },
  "DeepSpeedBloomInference": {
    "__init__": [
      "self",
      "config",
      "mp_group",
      "quantize_scales",
      "quantize_groups",
      "merge_count",
      "mlp_extra_grouping"
    ]
  },
  "DeepSpeedBERTInference": {
    "__init__": [
      "self",
      "config",
      "mp_group",
      "quantize_scales",
      "quantize_groups",
      "merge_count",
      "mlp_extra_grouping"
    ]
  },
  "DeepSpeedLlama2Inference": {
    "__init__": [
      "self",
      "config",
      "mp_group",
      "quantize_scales",
      "quantize_groups",
      "merge_count",
      "mlp_extra_grouping"
    ],
    "forward": [
      "self"
    ]
  },
  "DeepSpeedGPTInference": {
    "__init__": [
      "self",
      "config",
      "mp_group",
      "quantize_scales",
      "quantize_groups",
      "merge_count",
      "mlp_extra_grouping"
    ]
  },
  "DSClipEncoder": {
    "__init__": [
      "self",
      "enc",
      "enable_cuda_graph"
    ],
    "_build_causal_attention_mask": [
      "self",
      "bsz",
      "seq_len",
      "dtype"
    ],
    "_graph_replay": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "_create_cuda_graph": [
      "self"
    ],
    "_forward": [
      "self"
    ]
  },
  "DeepSpeedTransformerInference": {
    "layer_id": [],
    "workspace": [],
    "__init__": [
      "self",
      "config",
      "mp_group",
      "quantize_scales",
      "quantize_groups",
      "merge_count",
      "mlp_extra_grouping"
    ],
    "allocate_workspace": [
      "self",
      "size"
    ],
    "reset_cache": [
      "cls"
    ],
    "forward": [
      "self",
      "input",
      "input_mask",
      "attention_mask",
      "attn_mask",
      "head_mask",
      "layer_past",
      "get_key_value",
      "get_present",
      "encoder_output",
      "enc_dec_attn_mask",
      "x",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "use_cache",
      "alibi",
      "output_attentions",
      "layer_head_mask",
      "past_key_value"
    ]
  },
  "CUDAGraph": {
    "__init__": [
      "self",
      "enable_cuda_graph"
    ],
    "_create_cuda_graph": [
      "self"
    ],
    "_graph_replay": [
      "self"
    ]
  },
  "DSUNet": {
    "__init__": [
      "self",
      "unet",
      "enable_cuda_graph"
    ],
    "_graph_replay": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "_create_cuda_graph": [
      "self"
    ],
    "_forward": [
      "self",
      "sample",
      "timestamp",
      "encoder_hidden_states",
      "return_dict",
      "cross_attention_kwargs",
      "timestep_cond",
      "added_cond_kwargs"
    ]
  },
  "DSVAE": {
    "__init__": [
      "self",
      "vae",
      "enable_cuda_graph"
    ],
    "_graph_replay_decoder": [
      "self"
    ],
    "_decode": [
      "self",
      "x",
      "return_dict",
      "generator"
    ],
    "_create_cuda_graph_decoder": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "_graph_replay_encoder": [
      "self"
    ],
    "_encode": [
      "self",
      "x",
      "return_dict"
    ],
    "_create_cuda_graph_encoder": [
      "self"
    ],
    "encode": [
      "self"
    ],
    "_graph_replay": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "_create_cuda_graph": [
      "self"
    ],
    "_forward": [
      "self",
      "sample",
      "timestamp",
      "encoder_hidden_states",
      "return_dict"
    ]
  },
  "DATASTATES_CHECKPOINTING": [],
  "DATASTATES_CHECKPOINTING_ENABLED": [],
  "DeepSpeedDataStatesConfig": {
    "__init__": [
      "self",
      "param_dict"
    ]
  },
  "DeepSpeedNebulaConfig": {
    "__init__": [
      "self",
      "param_dict"
    ],
    "_initialize": [
      "self",
      "nebula_dict"
    ]
  },
  "NEBULA_FORMAT": [],
  "NEBULA": [],
  "NEBULA_ENABLED": [],
  "NEBULA_ENABLED_DEFAULT": [],
  "NEBULA_ENABLE_NEBULA_LOAD": [],
  "NEBULA_ENABLE_NEBULA_LOAD_DEFAULT": [],
  "NEBULA_LOAD_PATH": [],
  "NEBULA_LOAD_PATH_DEFAULT": [],
  "NEBULA_PERSISTENT_STORAGE_PATH": [],
  "NEBULA_PERSISTENT_STORAGE_PATH_DEFAULT": [],
  "NEBULA_PERSISTENT_TIME_INTERVAL": [],
  "NEBULA_PERSISTENT_TIME_INTERVAL_DEFAULT": [],
  "NEBULA_NUM_OF_VERSION_IN_RETENTION": [],
  "NEBULA_NUM_OF_VERSION_IN_RETENTION_DEFAULT": [],
  "NEBULA_EXPORT_ENVS": [],
  "DLTS_POD_ENV_PATH": [],
  "PartitionType": {
    "COLUMN": [],
    "ROW": [],
    "SKIP": []
  },
  "TPLayerSpec": {
    "__post_init__": [
      "self"
    ],
    "_normalize_shape": [
      "shape"
    ],
    "_validate_shape_format": [
      "self"
    ],
    "get_partition_dim": [
      "self"
    ],
    "has_unequal_sub_params": [
      "self"
    ],
    "get_sub_param_sizes": [
      "self"
    ],
    "get_num_sub_params": [
      "self"
    ],
    "matches": [
      "self",
      "param_name",
      "model_type"
    ]
  },
  "AutoTPConfig": {
    "find_matching_spec": [
      "self",
      "param_name",
      "model_type"
    ],
    "from_dict": [
      "cls",
      "config_dict"
    ],
    "_convert_shape": [
      "shape"
    ]
  },
  "AutoTPPresets": {
    "llama": [],
    "llama_gqa": [
      "num_heads",
      "num_kv_heads",
      "head_dim"
    ],
    "bloom": [],
    "chatglm": [],
    "mixtral": [],
    "deepseek_v2": [],
    "qwen2": [],
    "phi3": [],
    "get_preset": [
      "model_type"
    ]
  },
  "merge_autotp_configs": [
    "base",
    "override"
  ],
  "replace_policies": [],
  "generic_policies": [],
  "policy_to_ds_container": [],
  "quantize_transformer_layer": [
    "orig_layer_impl",
    "model",
    "megatron",
    "preln"
  ],
  "quantize_module": [
    "model",
    "orig_class",
    "quantize_fn"
  ],
  "_quantize_module": [
    "model",
    "policies"
  ],
  "move": [
    "tensor",
    "device",
    "copy"
  ],
  "ReplaceWithTensorSlicing": {
    "__init__": [
      "self",
      "mp_group",
      "mp_size",
      "out_dim",
      "in_dim"
    ],
    "merge_assert": [
      "self",
      "dim1",
      "dim2"
    ],
    "strided_copy": [
      "self",
      "dst",
      "src",
      "num_splits",
      "int8",
      "allocate_tensor"
    ],
    "copy": [
      "self",
      "dst",
      "src",
      "int8",
      "allocate_tensor"
    ]
  },
  "Loading": {
    "is_load_module": [
      "module"
    ],
    "load_buffer": [
      "module",
      "state_dict",
      "prefix"
    ],
    "load": [
      "module",
      "state_dict",
      "prefix",
      "mp_group"
    ]
  },
  "AutoTP": {
    "__init__": [
      "self",
      "module",
      "all_reduce_linears",
      "prefix",
      "state_dict",
      "linear_layer_setting",
      "orig_layer_impl",
      "keep_module_on_host",
      "partition_config"
    ],
    "in_module_list": [
      "module",
      "module_list"
    ],
    "get_module_list": [
      "model"
    ],
    "supported": [
      "model"
    ],
    "get_layers": [
      "parent",
      "module"
    ],
    "update_policy_list": [
      "policy_list",
      "new_module",
      "new_gems"
    ],
    "kernel_supported": [
      "module_list"
    ],
    "tp_parser": [
      "model"
    ],
    "set_tensor_parallel_config": [
      "self",
      "mp_size",
      "mp_group"
    ],
    "_replace": [
      "self",
      "child",
      "name",
      "conv_linear_layer"
    ],
    "_replace_with_config": [
      "self",
      "child",
      "name"
    ],
    "_create_row_parallel_layer": [
      "self",
      "module",
      "spec",
      "name"
    ],
    "_create_column_parallel_layer": [
      "self",
      "module",
      "spec",
      "name"
    ],
    "_get_model_type": [
      "self"
    ],
    "_slice_embedding": [
      "self",
      "child",
      "name",
      "conv_linear_layer"
    ],
    "update_mp_params": [
      "self",
      "child"
    ],
    "update_linear_policies": [
      "self"
    ],
    "_replace_module": [
      "self",
      "r_module",
      "prev_name",
      "prev_class_name"
    ],
    "get_model_num_kv_heads": [
      "self",
      "config"
    ],
    "_replace_last_linear_module": [
      "self",
      "r_module"
    ]
  },
  "module_inject": [
    "layer_obj",
    "model",
    "config",
    "micro_batch_size",
    "max_seq_length",
    "seed",
    "preln",
    "fp16"
  ],
  "test_hi": [],
  "load_model_with_checkpoint": [
    "r_module",
    "sd",
    "mp_replace",
    "ckpt_type",
    "ckpt_mp_size",
    "weight_quantizer",
    "rank",
    "container"
  ],
  "transformer_param_names": [],
  "DSPolicy": {
    "_orig_layer_class": [],
    "__init__": [
      "self"
    ],
    "attention": [
      "self"
    ]
  },
  "TransformerPolicy": {
    "hf_model_config": [],
    "__init__": [
      "self",
      "inference",
      "linear_layer",
      "scale_attention",
      "megatron_v2",
      "use_mup",
      "mlp_act_func_type",
      "pre_attn_norm",
      "use_load_prefix",
      "split_qkv",
      "norm_type"
    ],
    "attention": [
      "self"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "mlp": [
      "self"
    ],
    "layernorm": [
      "self"
    ]
  },
  "transpose": [
    "data"
  ],
  "_transpose": [
    "x",
    "heads",
    "mp_replace"
  ],
  "maybe_copy": [
    "module",
    "sd",
    "weight_quantizer",
    "mp_replace",
    "dst_name",
    "src_name",
    "qkv",
    "megatron_v2",
    "split_qkv",
    "heads"
  ],
  "maybe_copy_qkv": [
    "module",
    "sd",
    "weight_quantizer",
    "mp_replace",
    "dst_name",
    "src_names",
    "split_qkv"
  ],
  "maybe_copy_geglu": [
    "module",
    "sd",
    "weight_quantizer",
    "mp_replace",
    "dst_name",
    "src_names"
  ],
  "pack_lora_weights": [
    "p"
  ],
  "maybe_get_lora": [
    "p"
  ],
  "__all__": [],
  "DEEPSPEED_AUTOTP_MODE": [],
  "DS_IS_REPLACED_MODULE": [],
  "DS_TENSOR_MODEL_PARALLEL": [],
  "get_auto_tp_mode": [],
  "is_autotp_training_mode": [],
  "set_autotp_mode": [
    "training"
  ],
  "add_bias": [
    "input",
    "bias"
  ],
  "RowParallel": {
    "symbolic": [
      "graph",
      "input"
    ],
    "forward": [
      "ctx",
      "group",
      "input",
      "is_inference_mode"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "AsyncColumnParallel": {
    "forward": [
      "ctx",
      "group",
      "input",
      "weight",
      "bias"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "ColumnParallel": {
    "symbolic": [
      "graph",
      "input"
    ],
    "forward": [
      "ctx",
      "group",
      "input"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "TensorParallel_Layer": {
    "__init__": [
      "self",
      "mp_group"
    ],
    "set_keep_module_on_host": [
      "cls",
      "value"
    ],
    "forward": [
      "self",
      "input"
    ],
    "gather_params": [
      "self",
      "params_list"
    ],
    "_tp_partition": [
      "self",
      "params_list"
    ],
    "config_requires_grad": [
      "self",
      "weight"
    ],
    "config_tp_params": [
      "self",
      "weight"
    ],
    "is_training_mode": [
      "self"
    ],
    "__deepcopy__": [
      "self",
      "memo"
    ],
    "extra_repr": [
      "self"
    ],
    "move": [
      "self",
      "tensor"
    ]
  },
  "configure_tensor_parallel_runtime": [
    "config"
  ],
  "GatherReplacedLayerParams": {
    "__init__": [
      "self",
      "params",
      "module",
      "enabled"
    ],
    "_is_replaced_module_weight": [
      "self",
      "param"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "LinearAllreduce": {
    "__init__": [
      "self",
      "module",
      "mp_group"
    ],
    "forward": [
      "self",
      "input"
    ],
    "gather_params": [
      "self",
      "params_list"
    ],
    "_tp_partition": [
      "self",
      "params_list"
    ],
    "uneven_partition": [
      "self",
      "params_list"
    ]
  },
  "LinearLayer": {
    "__init__": [
      "self",
      "module",
      "mp_group",
      "skip_partition"
    ],
    "forward": [
      "self",
      "input"
    ],
    "gather_params": [
      "self",
      "params_list"
    ],
    "_tp_partition": [
      "self",
      "params_list"
    ],
    "uneven_partition": [
      "self",
      "params_list"
    ],
    "from_weights": [
      "cls",
      "weight_shape",
      "dtype",
      "weight",
      "bias"
    ]
  },
  "FusedModuleWrapper": {
    "__init__": [
      "self",
      "fused_module"
    ],
    "__getattr__": [
      "self",
      "module"
    ]
  },
  "fused_LinearLayer": {
    "__init__": [
      "self",
      "module",
      "mp_group",
      "skip_partition"
    ],
    "_tp_partition": [
      "self",
      "params_list"
    ]
  },
  "conv_LinearLayer": {
    "_tp_partition": [
      "self",
      "params_list"
    ]
  },
  "Yuan_LinearAllreduce": {
    "_tp_partition": [
      "self",
      "params_list"
    ]
  },
  "Yuan_LinearLayer": {
    "_tp_partition": [
      "self",
      "params_list"
    ]
  },
  "GateUpPack_LinearLayer": {
    "_tp_partition": [
      "self",
      "params_list"
    ]
  },
  "Conv_LinearALlreduce": {
    "_tp_partition": [
      "self",
      "params_list"
    ]
  },
  "LmHeadLinearAllreduce": {
    "__init__": [
      "self",
      "module",
      "mp_group"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TensorParallelConv2d": {
    "__init__": [
      "self",
      "conv",
      "rank",
      "world_size",
      "shard_by_oc"
    ],
    "shard_weights": [
      "self",
      "conv"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TensorParallelOcShardConv2d": {
    "__init__": [
      "self",
      "conv",
      "rank",
      "world_size"
    ]
  },
  "TensorParallelIcShardConv2d": {
    "__init__": [
      "self",
      "conv",
      "rank",
      "world_size"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Normalize": {
    "__init__": [
      "self",
      "dim",
      "dtype",
      "eps",
      "weight",
      "bias"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "EmbeddingLayer": {
    "__init__": [
      "self",
      "weight_shape",
      "dtype",
      "weight",
      "bias"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "OPTEmbedding": {
    "__init__": [
      "self",
      "weight_shape",
      "weight",
      "bias"
    ],
    "forward": [
      "self",
      "attention_mask",
      "past_key_values_length",
      "position_ids"
    ]
  },
  "_shape_prod": [
    "values"
  ],
  "_normalize_shape_spec": [
    "shape"
  ],
  "_infer_subparam_logical_shapes": [
    "weight_shape",
    "shape",
    "partition_dim",
    "name"
  ],
  "_partition_logical_tensor": [
    "tensor",
    "partition_dim",
    "tp_world_size",
    "tp_index",
    "name",
    "subparam_sizes"
  ],
  "_all_gather_along_dim": [
    "tensor",
    "partition_dim",
    "mp_group",
    "tp_world_size"
  ],
  "_gather_logical_tensor": [
    "tensor",
    "logical_shape",
    "partition_dim",
    "mp_group",
    "tp_world_size",
    "name",
    "subparam_sizes"
  ],
  "SubParamLinearLayer": {
    "__init__": [
      "self",
      "module",
      "mp_group",
      "shape",
      "partition_dim"
    ],
    "forward": [
      "self",
      "input"
    ],
    "gather_params": [
      "self",
      "params_list"
    ],
    "_tp_partition": [
      "self",
      "params_list"
    ]
  },
  "SubParamLinearAllreduce": {
    "__init__": [
      "self",
      "module",
      "mp_group",
      "shape",
      "partition_dim"
    ],
    "forward": [
      "self",
      "input"
    ],
    "gather_params": [
      "self",
      "params_list"
    ],
    "_tp_partition": [
      "self",
      "params_list"
    ]
  },
  "RMSNormalize": {
    "__init__": [
      "self",
      "dim",
      "dtype",
      "eps",
      "weight"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "num_kv_heads": [],
  "num_attention_heads": [],
  "n_embd": [],
  "tp_grain_size": [],
  "set_num_kv_heads": [
    "num"
  ],
  "set_num_attention_heads": [
    "num"
  ],
  "set_n_embd": [
    "num"
  ],
  "set_tp_grain_size": [
    "num"
  ],
  "get_num_kv_heads": [],
  "get_num_attention_heads": [],
  "get_shard_size": [
    "total_size",
    "mp_size",
    "name",
    "rank"
  ],
  "get_n_embd": [],
  "get_shard_size_list": [
    "total_size",
    "mp_size",
    "name"
  ],
  "build_bloom_alibi_tensor": [
    "attention_mask",
    "num_heads",
    "dtype"
  ],
  "get_alibi_mask": [
    "self",
    "tensor",
    "seq_length_with_past"
  ],
  "build_mpt_atten_bias_tensor": [
    "self",
    "device",
    "dtype",
    "attention_mask",
    "prefix_mask",
    "sequence_id"
  ],
  "build_mpt_alibi_tensor": [
    "self",
    "num_heads",
    "sequence_length",
    "alibi_bias_max",
    "device"
  ],
  "get_transformer_name": [
    "replaced_module"
  ],
  "GroupQuantizer": {
    "__init__": [
      "self",
      "q_int8",
      "group_size",
      "num_bits",
      "num_groups"
    ],
    "quantize": [
      "self",
      "inputs",
      "qkv",
      "count",
      "parallel_dim"
    ]
  },
  "_module_match": [
    "module"
  ],
  "generic_injection": [
    "module",
    "dtype",
    "enable_cuda_graph"
  ],
  "container_g": [],
  "replace_transformer_layer": [
    "orig_layer_impl",
    "model",
    "checkpoint_dict",
    "config",
    "model_config"
  ],
  "revert_transformer_layer": [
    "orig_layer_impl",
    "model",
    "config",
    "preln"
  ],
  "replace_module": [
    "model",
    "orig_class",
    "replace_fn",
    "_replace_policy",
    "checkpoint"
  ],
  "skip_level_0_prefix": [
    "model",
    "state_dict"
  ],
  "_replace_module": [
    "model",
    "policies",
    "prefix",
    "layer_id",
    "level_id",
    "state_dict"
  ],
  "split_by_qkvlist_and_refuse": [
    "qkv_list",
    "split_size",
    "split_dim",
    "cat_dim"
  ],
  "require_tp_fused_qkvw": [
    "name",
    "mp_size"
  ],
  "prepare_tp_fused_qkvw": [
    "module",
    "src",
    "mp_size",
    "gpu_index"
  ],
  "shard_value_with_share_qk": [
    "weight",
    "bias",
    "rank",
    "world_size",
    "shard_value"
  ],
  "shard_chunk_mlp": [
    "weight",
    "bias",
    "rank",
    "world_size"
  ],
  "DS_GPTNEOContainer": {
    "__init__": [
      "self"
    ],
    "create_module": [
      "self",
      "config"
    ],
    "set_lora_params": [
      "self"
    ],
    "set_q_k_v": [
      "self"
    ],
    "get_lora_matched_pair": [
      "self"
    ],
    "load_params": [
      "self",
      "module",
      "sd",
      "weight_quantizer",
      "mp_replace",
      "prefix"
    ]
  },
  "HFGPTNEOLayerPolicy": {
    "__init__": [
      "self",
      "client_module",
      "inference"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "get_q_k_v": [
      "self"
    ],
    "attention": [
      "self",
      "enable_training"
    ],
    "mlp": [
      "self",
      "enable_training"
    ],
    "layernorm": [
      "self"
    ]
  },
  "DS_OPTContainer": {
    "__init__": [
      "self"
    ],
    "create_module": [
      "self",
      "config"
    ],
    "set_lora_params": [
      "self"
    ],
    "set_q_k_v": [
      "self"
    ],
    "get_lora_matched_pair": [
      "self"
    ],
    "load_params": [
      "self",
      "module",
      "sd",
      "weight_quantizer",
      "mp_replace",
      "prefix"
    ]
  },
  "HFOPTLayerPolicy": {
    "_orig_layer_class": [],
    "__init__": [
      "self",
      "client_module",
      "inference",
      "use_load_prefix"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "attention": [
      "self",
      "enable_training"
    ],
    "mlp": [
      "self",
      "enable_training"
    ],
    "layernorm": [
      "self"
    ]
  },
  "DEFAULT_INTERMEDIATE_SIZE": [],
  "BaseConvolutionContainer": {
    "__init__": [
      "self"
    ]
  },
  "BaseTransformerContainer": {
    "__init__": [
      "self",
      "policy",
      "config",
      "model_config",
      "layer_id",
      "child"
    ],
    "create_ds_model_config": [
      "self"
    ],
    "check_meta_tensor_support": [
      "self"
    ],
    "initialize_tensors": [
      "self",
      "enable_training"
    ],
    "convert_to_required_dtype": [
      "self"
    ],
    "get_rotary_dim": [
      "self"
    ],
    "set_moe": [
      "self",
      "moe"
    ],
    "set_tensor_parallel_config": [
      "self",
      "mp_size",
      "mp_group"
    ],
    "set_quantization_config": [
      "self",
      "quantizer"
    ],
    "set_hidden_heads": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "epsilon",
      "intermediate_size"
    ],
    "set_attention": [
      "self",
      "qkvw",
      "qkvb",
      "dense_w",
      "dense_b"
    ],
    "set_mlp": [
      "self",
      "_h4h_w",
      "_h4h_b",
      "_4hh_w",
      "_4hh_b"
    ],
    "set_layernorm": [
      "self",
      "attn_nw",
      "attn_nb",
      "input_nw",
      "input_nb"
    ],
    "apply_weight_quantization": [
      "self"
    ],
    "attention_quantization": [
      "self"
    ],
    "mlp_quantization": [
      "self"
    ],
    "apply_tensor_parallelism": [
      "self",
      "mp_replace"
    ],
    "attention_qkv_mp": [
      "self",
      "mp_replace",
      "reversed_dim"
    ],
    "attention_o_mp": [
      "self",
      "mp_replace",
      "reversed_dim"
    ],
    "mlp_inter_mp": [
      "self",
      "mp_replace",
      "reversed_dim"
    ],
    "mlp_output_mp": [
      "self",
      "mp_replace",
      "reversed_dim"
    ],
    "copy_data_to_new_module": [
      "self"
    ],
    "transpose": [
      "self"
    ],
    "transpose_attention": [
      "self"
    ],
    "transpose_mlp": [
      "self"
    ],
    "transpose_impl": [
      "self",
      "data"
    ],
    "get_all_params": [
      "self"
    ],
    "get_attn_params": [
      "self"
    ],
    "get_mlp_params": [
      "self"
    ]
  },
  "DS_GPTJContainer": {
    "__init__": [
      "self"
    ],
    "create_module": [
      "self",
      "config"
    ],
    "set_lora_params": [
      "self"
    ],
    "get_lora_matched_pair": [
      "self"
    ],
    "set_q_k_v": [
      "self"
    ],
    "load_params": [
      "self",
      "module",
      "sd",
      "weight_quantizer",
      "mp_replace",
      "prefix"
    ]
  },
  "HFGPTJLayerPolicy": {
    "_orig_layer_class": [],
    "__init__": [
      "self",
      "client_module",
      "inference"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "attention": [
      "self",
      "enable_training"
    ],
    "mlp": [
      "self",
      "enable_training"
    ],
    "layernorm": [
      "self"
    ]
  },
  "DS_BERTContainer": {
    "__init__": [
      "self"
    ],
    "create_module": [
      "self",
      "config"
    ]
  },
  "HFBertLayerPolicy": {
    "__init__": [
      "self",
      "client_module",
      "inference"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "attention": [
      "self",
      "enable_training"
    ],
    "mlp": [
      "self",
      "enable_training"
    ],
    "layernorm": [
      "self"
    ]
  },
  "UNetPolicy": {
    "__init__": [
      "self"
    ],
    "match": [
      "self",
      "module"
    ],
    "match_replaced": [
      "self",
      "module"
    ],
    "apply": [
      "self",
      "module",
      "enable_cuda_graph"
    ],
    "attention": [
      "self",
      "client_module"
    ]
  },
  "DS_GPT2Container": {
    "__init__": [
      "self"
    ],
    "create_module": [
      "self",
      "config"
    ]
  },
  "HFGPT2LayerPolicy": {
    "_orig_layer_class": [],
    "__init__": [
      "self",
      "client_module",
      "inference"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "attention": [
      "self",
      "enable_training"
    ],
    "mlp": [
      "self",
      "enable_training"
    ],
    "layernorm": [
      "self"
    ]
  },
  "DS_CLIPContainer": {
    "__init__": [
      "self"
    ],
    "create_module": [
      "self",
      "config"
    ]
  },
  "HFCLIPLayerPolicy": {
    "__init__": [
      "self",
      "client_module",
      "inference"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "attention": [
      "self",
      "enable_training"
    ],
    "mlp": [
      "self",
      "enable_training"
    ],
    "layernorm": [
      "self"
    ]
  },
  "DS_LLAMA2Container": {
    "__init__": [
      "self"
    ],
    "create_module": [
      "self",
      "config"
    ],
    "set_lora_params": [
      "self"
    ],
    "get_lora_matched_pair": [
      "self"
    ],
    "set_q_k_v": [
      "self"
    ],
    "set_mlp_gate": [
      "self"
    ],
    "load_params": [
      "self",
      "module",
      "sd",
      "weight_quantizer",
      "mp_replace",
      "prefix"
    ]
  },
  "LLAMA2LayerPolicy": {
    "__init__": [
      "self",
      "client_module",
      "inference"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "attention": [
      "self",
      "enable_training"
    ],
    "mlp": [
      "self",
      "enable_training"
    ],
    "layernorm": [
      "self"
    ]
  },
  "DS_GPTNEOXContainer": {
    "__init__": [
      "self"
    ],
    "create_module": [
      "self",
      "config"
    ],
    "get_lora_matched_pair": [
      "self"
    ],
    "set_lora_params": [
      "self"
    ],
    "load_params": [
      "self",
      "module",
      "sd",
      "weight_quantizer",
      "mp_replace",
      "prefix"
    ]
  },
  "GPTNEOXLayerPolicy": {
    "_orig_layer_class": [],
    "version": [],
    "__init__": [
      "self",
      "client_module",
      "inference",
      "megatron_v2",
      "split_qkv"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "attention": [
      "self",
      "enable_training"
    ],
    "mlp": [
      "self",
      "enable_training"
    ],
    "layernorm": [
      "self"
    ]
  },
  "DS_DistilBERTContainer": {
    "__init__": [
      "self"
    ],
    "create_module": [
      "self",
      "config"
    ]
  },
  "HFDistilBertLayerPolicy": {
    "_orig_layer_class": [],
    "__init__": [
      "self",
      "client_module",
      "inference",
      "preln"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "attention": [
      "self",
      "enable_training"
    ],
    "mlp": [
      "self",
      "enable_training"
    ],
    "layernorm": [
      "self"
    ]
  },
  "DS_LLAMAContainer": {
    "__init__": [
      "self"
    ],
    "create_module": [
      "self",
      "config"
    ],
    "set_lora_params": [
      "self"
    ],
    "get_lora_matched_pair": [
      "self"
    ],
    "set_q_k_v": [
      "self"
    ],
    "set_mlp_gate": [
      "self"
    ],
    "load_params": [
      "self",
      "module",
      "sd",
      "weight_quantizer",
      "mp_replace",
      "prefix"
    ]
  },
  "LLAMALayerPolicy": {
    "__init__": [
      "self",
      "client_module",
      "inference"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "attention": [
      "self",
      "enable_training"
    ],
    "mlp": [
      "self",
      "enable_training"
    ],
    "layernorm": [
      "self"
    ]
  },
  "supported_models": [],
  "DS_BloomContainer": {
    "__init__": [
      "self"
    ],
    "create_module": [
      "self",
      "config"
    ],
    "attention_qkv_mp": [
      "self",
      "mp_replace",
      "reversed_dim"
    ],
    "get_lora_matched_pair": [
      "self"
    ],
    "set_lora_params": [
      "self"
    ],
    "load_params": [
      "self",
      "module",
      "sd",
      "weight_quantizer",
      "mp_replace",
      "prefix"
    ]
  },
  "BLOOMLayerPolicy": {
    "_orig_layer_class": [],
    "__init__": [
      "self",
      "client_module",
      "inference",
      "use_load_prefix",
      "split_qkv"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "attention": [
      "self",
      "enable_training"
    ],
    "mlp": [
      "self",
      "enable_training"
    ],
    "layernorm": [
      "self"
    ]
  },
  "DS_InternLMContainer": {
    "__init__": [
      "self"
    ],
    "create_module": [
      "self",
      "config"
    ],
    "set_lora_params": [
      "self"
    ],
    "get_lora_matched_pair": [
      "self"
    ],
    "set_q_k_v": [
      "self"
    ],
    "set_mlp_gate": [
      "self"
    ],
    "load_params": [
      "self",
      "module",
      "sd",
      "weight_quantizer",
      "mp_replace",
      "prefix"
    ]
  },
  "InternLMLayerPolicy": {
    "_orig_layer_class": [],
    "_orig_layer_class_inited": [],
    "__init__": [
      "self",
      "client_module",
      "inference"
    ],
    "_init_orig_layer_class_once": [
      "self"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "attention": [
      "self",
      "enable_training"
    ],
    "mlp": [
      "self",
      "enable_training"
    ],
    "layernorm": [
      "self"
    ]
  },
  "DS_MegatronGPTContainer": {
    "__init__": [
      "self"
    ],
    "create_module": [
      "self",
      "config"
    ]
  },
  "MegatronLayerPolicy": {
    "_orig_layer_class": [],
    "version": [],
    "moe_type": [],
    "megatron_v2": [],
    "use_mup": [],
    "__init__": [
      "self",
      "client_module",
      "inference"
    ],
    "get_hidden_heads": [
      "self"
    ],
    "attention": [
      "self",
      "enable_training"
    ],
    "mlp": [
      "self",
      "moe_type",
      "enable_training"
    ],
    "layernorm": [
      "self"
    ]
  },
  "DS_MegatronGPTMoEContainer": {
    "__init__": [
      "self",
      "policy",
      "config",
      "model_config",
      "layer_id"
    ],
    "create_module": [
      "self",
      "config"
    ]
  },
  "MegatronMoELayerPolicy": {
    "_orig_layer_class": [],
    "version": [],
    "moe_type": [],
    "num_experts": [],
    "__init__": [
      "self",
      "client_module",
      "inference"
    ],
    "get_num_experts": [
      "self"
    ],
    "mlp": [
      "self",
      "moe_type",
      "enable_training"
    ]
  },
  "VAEPolicy": {
    "__init__": [
      "self"
    ],
    "match": [
      "self",
      "module"
    ],
    "match_replaced": [
      "self",
      "module"
    ],
    "apply": [
      "self",
      "module",
      "enable_cuda_graph"
    ],
    "attention": [
      "self",
      "client_module"
    ]
  },
  "BaseTransformerMoEContainer": {
    "__init__": [
      "self"
    ],
    "create_ds_model_config": [
      "self"
    ],
    "initialize_tensors": [
      "self"
    ],
    "set_mlp": [
      "self",
      "config_moe_type"
    ],
    "transpose": [
      "self"
    ],
    "transpose_mlp": [
      "self"
    ],
    "transpose_residual": [
      "self"
    ],
    "apply_tensor_parallelism": [
      "self",
      "mp_replace"
    ],
    "mlp_mp": [
      "self"
    ],
    "copy_data_to_new_module": [
      "self"
    ]
  },
  "HybridEngineContainer": {
    "initialize_tensors": [
      "self",
      "enable_training"
    ],
    "transform_for_training": [
      "self"
    ],
    "transform_for_inference": [
      "self"
    ],
    "set_lora_params": [
      "self"
    ],
    "get_lora_matched_pair": [
      "self"
    ],
    "fuse_lora": [
      "self"
    ],
    "unfuse_lora": [
      "self"
    ],
    "apply_tensor_parallelism": [
      "self",
      "mp_replace",
      "reversed_dim"
    ],
    "_release_params": [
      "self",
      "param_pairs"
    ],
    "release_memory": [
      "self"
    ],
    "release_qkv": [
      "self"
    ],
    "release_mlp": [
      "self"
    ],
    "reset_params": [
      "self"
    ],
    "reset_qkv": [
      "self"
    ],
    "reset_mlp": [
      "self"
    ],
    "get_lora_params": [
      "self"
    ],
    "set_params_wo_copy": [
      "self",
      "Z3_enabled"
    ],
    "set_attn_params_wo_copy": [
      "self"
    ],
    "set_mlp_params_wo_copy": [
      "self"
    ]
  },
  "MegatronContainer": {
    "__init__": [
      "self"
    ],
    "_align_qkv_transposed": [
      "self",
      "x"
    ],
    "transpose": [
      "self"
    ]
  },
  "MetaTensorContainer": {
    "__init__": [
      "self"
    ],
    "initialize_tensors": [
      "self",
      "enable_training"
    ],
    "apply_tensor_parallelism": [
      "self",
      "mp_replace"
    ],
    "copy_data_to_new_module": [
      "self"
    ],
    "transpose": [
      "self"
    ],
    "load_params": [
      "self",
      "module",
      "sd",
      "weight_quantizer",
      "mp_replace",
      "prefix"
    ]
  },
  "HybridGatedMLPContainer": {
    "set_mlp": [
      "self",
      "_h4h_w",
      "_h4h_b",
      "_4hh_w",
      "_4hh_b"
    ],
    "set_mlp_gate": [
      "self"
    ],
    "mlp_inter_mp": [
      "self",
      "mp_replace",
      "reversed_dim"
    ],
    "release_mlp": [
      "self"
    ],
    "reset_mlp": [
      "self"
    ],
    "set_mlp_params_wo_copy": [
      "self",
      "Z3_enabled"
    ],
    "get_mlp_params": [
      "self"
    ]
  },
  "HybridMegatronContainer": {
    "_align_qkv": [
      "self",
      "x"
    ],
    "transform_for_inference": [
      "self"
    ],
    "_partition_qkv": [
      "self",
      "x"
    ],
    "transform_for_training": [
      "self"
    ]
  },
  "HybridSplitQKVContainer": {
    "set_attention": [
      "self",
      "qkvw",
      "qkvb",
      "dense_w",
      "dense_b"
    ],
    "set_q_k_v": [
      "self"
    ],
    "attention_qkv_mp": [
      "self",
      "mp_replace",
      "reversed_dim"
    ],
    "release_qkv": [
      "self"
    ],
    "reset_qkv": [
      "self"
    ],
    "reset_qkv_experimental": [
      "self"
    ],
    "set_attn_params_wo_copy": [
      "self",
      "Z3_enabled"
    ],
    "get_attn_params": [
      "self"
    ]
  },
  "compression_scheduler": {
    "__init__": [
      "self",
      "model",
      "compression_config"
    ],
    "make_init": [
      "self"
    ],
    "check_weight_quantization": [
      "self"
    ],
    "check_activation_quantization": [
      "self"
    ],
    "check_sparse_pruning": [
      "self"
    ],
    "check_head_pruning": [
      "self"
    ],
    "check_row_pruning": [
      "self"
    ],
    "check_channel_pruning": [
      "self"
    ],
    "check_all_modules": [
      "self"
    ],
    "step": [
      "self",
      "step_zero_check"
    ]
  },
  "TopKBinarizer": {
    "forward": [
      "ctx",
      "inputs",
      "threshold",
      "sigmoid"
    ],
    "backward": [
      "ctx",
      "gradOutput"
    ]
  },
  "SymQuantizer": {
    "forward": [
      "ctx",
      "input",
      "num_bits",
      "min_value",
      "max_value",
      "num_groups"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "AsymQuantizer": {
    "forward": [
      "ctx",
      "input",
      "num_bits",
      "min_value",
      "max_value",
      "num_groups"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "TernaryQuantizer": {
    "forward": [
      "ctx",
      "input",
      "num_bits",
      "min_value",
      "max_value",
      "num_groups"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "BinaryQuantizer": {
    "forward": [
      "ctx",
      "input",
      "num_bits",
      "min_value",
      "max_value",
      "num_groups"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "g_mpu": [],
  "QuantAct": {
    "__init__": [
      "self",
      "act_range_momentum",
      "quant_mode"
    ],
    "forward": [
      "self",
      "x",
      "num_bits"
    ]
  },
  "Embedding_Compress": {
    "__init__": [
      "self"
    ],
    "extra_repr": [
      "self"
    ],
    "enable_weight_quantization": [
      "self",
      "start_bits",
      "target_bits",
      "quantization_period",
      "weight_quantization_enabled_in_forward",
      "quantization_type",
      "num_groups"
    ],
    "fix_weight_quantization": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "LinearLayer_Compress": {
    "__init__": [
      "self"
    ],
    "extra_repr": [
      "self"
    ],
    "enable_sparse_pruning": [
      "self",
      "ratio",
      "method"
    ],
    "enable_row_pruning": [
      "self",
      "ratio",
      "method"
    ],
    "enable_head_pruning": [
      "self",
      "ratio",
      "method",
      "num_heads"
    ],
    "fix_sparse_pruning_helper": [
      "self"
    ],
    "fix_row_col_pruning_helper": [
      "self",
      "mask",
      "dim_reduction"
    ],
    "fix_head_pruning_helper": [
      "self",
      "mask",
      "num_heads",
      "dim_reduction"
    ],
    "get_mask": [
      "self",
      "pruning_type"
    ],
    "enable_weight_quantization": [
      "self",
      "start_bits",
      "target_bits",
      "quantization_period",
      "weight_quantization_enabled_in_forward",
      "quantization_type",
      "num_groups"
    ],
    "fix_weight_quantization": [
      "self"
    ],
    "enable_activation_quantization": [
      "self",
      "bits",
      "quantization_type",
      "range_calibration"
    ],
    "head_pruning_reshape": [
      "self",
      "w",
      "mask"
    ],
    "forward": [
      "self",
      "input",
      "skip_bias_add"
    ]
  },
  "Conv2dLayer_Compress": {
    "__init__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "enable_sparse_pruning": [
      "self",
      "ratio",
      "method"
    ],
    "enable_channel_pruning": [
      "self",
      "ratio",
      "method"
    ],
    "fix_sparse_pruning_helper": [
      "self"
    ],
    "fix_channel_pruning_helper": [
      "self",
      "mask",
      "dim_reduction"
    ],
    "get_mask": [
      "self",
      "pruning_type"
    ],
    "fix_weight_quantization": [
      "self"
    ],
    "enable_weight_quantization": [
      "self",
      "start_bits",
      "target_bits",
      "quantization_period",
      "weight_quantization_enabled_in_forward",
      "quantization_type",
      "num_groups"
    ],
    "enable_activation_quantization": [
      "self",
      "bits",
      "quantization_type",
      "range_calibration"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "BNLayer_Compress": {
    "fix_channel_pruning_helper": [
      "self",
      "mask",
      "dim_reduction"
    ]
  },
  "_reduce": [
    "input_"
  ],
  "split_tensor_along_last_dim": [
    "tensor",
    "num_partitions",
    "contiguous_split_chunks"
  ],
  "_split": [
    "input_"
  ],
  "_gather": [
    "input_"
  ],
  "_CopyToModelParallelRegion": {
    "forward": [
      "ctx",
      "input_"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "_ReduceFromModelParallelRegion": {
    "forward": [
      "ctx",
      "input_"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "_ScatterToModelParallelRegion": {
    "forward": [
      "ctx",
      "input_"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "_GatherFromModelParallelRegion": {
    "forward": [
      "ctx",
      "input_"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "copy_to_model_parallel_region": [
    "input_"
  ],
  "reduce_from_model_parallel_region": [
    "input_"
  ],
  "scatter_to_model_parallel_region": [
    "input_"
  ],
  "gather_from_model_parallel_region": [
    "input_"
  ],
  "ColumnParallelLinear_Compress": {
    "__init__": [
      "self",
      "mpu",
      "input_size",
      "output_size",
      "bias",
      "gather_output",
      "skip_bias_add"
    ],
    "forward": [
      "self",
      "input_"
    ]
  },
  "RowParallelLinear_Compress": {
    "__init__": [
      "self",
      "mpu",
      "input_size",
      "output_size",
      "bias",
      "input_is_parallel",
      "skip_bias_add"
    ],
    "forward": [
      "self",
      "input_"
    ]
  },
  "get_compression_config": [
    "param_dict"
  ],
  "get_layer_reduction": [
    "param_dict"
  ],
  "get_layer_reduction_enabled": [
    "param_dict"
  ],
  "get_layer_reduction_params": [
    "param_dict"
  ],
  "get_quantize_enabled": [
    "param_dict"
  ],
  "get_weight_quantization": [
    "param_dict"
  ],
  "get_weight_quantization_shared_parameters": [
    "param_dict"
  ],
  "get_weight_quantization_different_groups": [
    "param_dict"
  ],
  "get_activation_quantization": [
    "param_dict"
  ],
  "get_activation_quantization_shared_parameters": [
    "param_dict"
  ],
  "get_activation_quantization_different_groups": [
    "param_dict"
  ],
  "get_sparse_pruning": [
    "param_dict"
  ],
  "get_sparse_pruning_shared_parameters": [
    "param_dict"
  ],
  "get_sparse_pruning_different_groups": [
    "param_dict"
  ],
  "get_row_pruning": [
    "param_dict"
  ],
  "get_row_pruning_shared_parameters": [
    "param_dict"
  ],
  "get_row_pruning_different_groups": [
    "param_dict"
  ],
  "get_head_pruning": [
    "param_dict"
  ],
  "get_head_pruning_shared_parameters": [
    "param_dict"
  ],
  "get_head_pruning_different_groups": [
    "param_dict"
  ],
  "get_channel_pruning": [
    "param_dict"
  ],
  "get_channel_pruning_shared_parameters": [
    "param_dict"
  ],
  "get_channel_pruning_different_groups": [
    "param_dict"
  ],
  "COMPRESSION_TRAINING": [],
  "SHARED_PARAMETERS": [],
  "DIFFERENT_GROUPS": [],
  "TECHNIQUE_ENABLED": [],
  "TECHNIQUE_SCHEDULE_OFFSET": [],
  "TECHNIQUE_SCHEDULE_OFFSET_END": [],
  "DIFFERENT_GROUPS_PARAMETERS": [],
  "DIFFERENT_GROUPS_MODULE_SCOPE": [],
  "DIFFERENT_GROUPS_MODULE_SCOPE_DEFAULT": [],
  "DIFFERENT_GROUPS_RELATED_MODULE_SCOPE": [],
  "DIFFERENT_GROUPS_RELATED_MODULE_SCOPE_DEFAULT": [],
  "LAYER_REDUCTION": [],
  "LAYER_REDUCTION_ENABLED": [],
  "LAYER_REDUCTION_ENABLED_DEFAULT": [],
  "KEEP_NUMBER_LAYER": [],
  "MODULE_NAME_PREFIX": [],
  "TEACHER_LAYER": [],
  "OTHER_MODULE_NAME": [],
  "WEIGHT_QUANTIZATION": [],
  "WEIGHT_QUANTIZATION_PERIOD": [],
  "WEIGHT_QUANTIZATION_PERIOD_DEFAULT": [],
  "WEIGHT_QUANTIZE_IN_FORWARD_ENABLED": [],
  "WEIGHT_QUANTIZE_IN_FORWARD_ENABLED_DEFAULT": [],
  "WEIGHT_QUANTIZE_ENABLED": [],
  "WEIGHT_QUANTIZE_ENABLED_DEFAULT": [],
  "WEIGHT_QUANTIZE_KERNEL": [],
  "WEIGHT_QUANTIZE_KERNEL_DEFAULT": [],
  "WEIGHT_QUANTIZE_SCHEDULE_OFFSET": [],
  "WEIGHT_QUANTIZE_SCHEDULE_OFFSET_DEFAULT": [],
  "WEIGHT_QUANTIZE_GROUPS": [],
  "WEIGHT_QUANTIZE_GROUPS_DEFAULT": [],
  "WEIGHT_QUANTIZE_VERBOSE": [],
  "WEIGHT_QUANTIZE_VERBOSE_DEFAULT": [],
  "WEIGHT_QUANTIZE_TYPE": [],
  "WEIGHT_QUANTIZE_TYPE_DEFAULT": [],
  "WEIGHT_QUANTIZE_SYMMETRIC": [],
  "WEIGHT_QUANTIZE_ASYMMETRIC": [],
  "WEIGHT_QUANTIZE_ROUNDING": [],
  "WEIGHT_QUANTIZE_ROUNDING_DEFAULT": [],
  "WEIGHT_QUANTIZE_STOCHASTIC_ROUNDING": [],
  "WEIGHT_QUANTIZE_NEAREST_ROUNDING": [],
  "WEIGHT_QUANTIZE_FP16_MIXED_QUANTIZE": [],
  "WEIGHT_QUANTIZE_FP16_MIXED_QUANTIZE_ENABLED": [],
  "WEIGHT_QUANTIZE_FP16_MIXED_QUANTIZE_ENABLED_DEFAULT": [],
  "WEIGHT_QUANTIZE_CHANGE_RATIO": [],
  "WEIGHT_QUANTIZE_CHANGE_RATIO_DEFAULT": [],
  "WEIGHT_QUANTIZE_START_BITS": [],
  "WEIGHT_QUANTIZE_TARGET_BITS": [],
  "ACTIVATION_QUANTIZATION": [],
  "ACTIVATION_QUANTIZATION_ENABLED": [],
  "ACTIVATION_QUANTIZATION_ENABLED_DEFAULT": [],
  "ACTIVATION_QUANTIZE_SCHEDULE_OFFSET": [],
  "ACTIVATION_QUANTIZE_SCHEDULE_OFFSET_DEFAULT": [],
  "ACTIVATION_QUANTIZE_TYPE": [],
  "ACTIVATION_QUANTIZE_TYPE_DEFAULT": [],
  "ACTIVATION_QUANTIZE_SYMMETRIC": [],
  "ACTIVATION_QUANTIZE_ASYMMETRIC": [],
  "ACTIVATION_QUANTIZE_RANGE": [],
  "ACTIVATION_QUANTIZE_RANGE_DEFAULT": [],
  "ACTIVATION_QUANTIZE_RANGE_STATIC": [],
  "ACTIVATION_QUANTIZE_RANGE_DYNAMIC": [],
  "ACTIVATION_QUANTIZE_BITS": [],
  "SPARSE_PRUNING": [],
  "SPARSE_PRUNING_ENABLED": [],
  "SPARSE_PRUNING_ENABLED_DEFAULT": [],
  "SPARSE_PRUNING_METHOD": [],
  "SPARSE_PRUNING_METHOD_DEFAULT": [],
  "SPARSE_PRUNING_METHOD_L1": [],
  "SPARSE_PRUNING_METHOD_TOPK": [],
  "SPARSE_PRUNING_METHOD_SNIP_MOMENTUM": [],
  "SPARSE_PRUNING_BLOCK_PATTERN": [],
  "SPARSE_PRUNING_BLOCK_PATTERN_DEFAULT": [],
  "SPARSE_PRUNING_SCHEDULE_OFFSET_STRIDE": [],
  "SPARSE_PRUNING_SCHEDULE_OFFSET_STRIDE_DEFAULT": [],
  "SPARSE_PRUNING_SCHEDULE_OFFSET": [],
  "SPARSE_PRUNING_SCHEDULE_OFFSET_DEFAULT": [],
  "SPARSE_PRUNING_SCHEDULE_OFFSET_END": [],
  "SPARSE_PRUNING_SCHEDULE_OFFSET_END_DEFAULT": [],
  "SPARSE_PRUNING_DENSE_RATIO": [],
  "SPARSE_PRUNING_DENSE_RATIO_DEFAULT": [],
  "SPARSE_PRUNING_EXCLUDED_MODULES": [],
  "SPARSE_PRUNING_EXCLUDED_MODULES_DEFAULT": [],
  "ROW_PRUNING": [],
  "ROW_PRUNING_ENABLED": [],
  "ROW_PRUNING_ENABLED_DEFAULT": [],
  "ROW_PRUNING_METHOD": [],
  "ROW_PRUNING_METHOD_DEFAULT": [],
  "ROW_PRUNING_METHOD_L1": [],
  "ROW_PRUNING_METHOD_TOPK": [],
  "ROW_PRUNING_SCHEDULE_OFFSET": [],
  "ROW_PRUNING_SCHEDULE_OFFSET_DEFAULT": [],
  "ROW_PRUNING_DENSE_RATIO": [],
  "HEAD_PRUNING": [],
  "HEAD_PRUNING_ENABLED": [],
  "HEAD_PRUNING_ENABLED_DEFAULT": [],
  "HEAD_PRUNING_METHOD": [],
  "HEAD_PRUNING_METHOD_DEFAULT": [],
  "HEAD_PRUNING_METHOD_L1": [],
  "HEAD_PRUNING_METHOD_TOPK": [],
  "HEAD_PRUNING_SCHEDULE_OFFSET": [],
  "HEAD_PRUNING_SCHEDULE_OFFSET_DEFAULT": [],
  "HEAD_PRUNING_NUM_HEADS": [],
  "HEAD_PRUNING_DENSE_RATIO": [],
  "CHANNEL_PRUNING": [],
  "CHANNEL_PRUNING_ENABLED": [],
  "CHANNEL_PRUNING_ENABLED_DEFAULT": [],
  "CHANNEL_PRUNING_METHOD": [],
  "CHANNEL_PRUNING_METHOD_DEFAULT": [],
  "CHANNEL_PRUNING_METHOD_L1": [],
  "CHANNEL_PRUNING_METHOD_TOPK": [],
  "CHANNEL_PRUNING_SCHEDULE_OFFSET": [],
  "CHANNEL_PRUNING_SCHEDULE_OFFSET_DEFAULT": [],
  "CHANNEL_PRUNING_DENSE_RATIO": [],
  "recursive_getattr": [
    "model",
    "module_name"
  ],
  "recursive_setattr": [
    "model",
    "module_name",
    "module"
  ],
  "module_replacement": [
    "model",
    "module_name",
    "compression_technique",
    "mpu"
  ],
  "is_module_compressible": [
    "module",
    "mpu"
  ],
  "compression_preparation": [
    "model",
    "compression_technique_list",
    "mpu"
  ],
  "fix_compression": [
    "model",
    "module_name",
    "compression_technique",
    "mask",
    "dim_reduction"
  ],
  "convert_conv1d_to_linear": [
    "model",
    "convert_type"
  ],
  "generate_pruners": [
    "config",
    "model"
  ],
  "register_on_step_begin": [
    "model"
  ],
  "rewrite_optimizer_step": [
    "opt"
  ],
  "check_deepspeed_config": [
    "config"
  ],
  "get_module_name": [
    "group_name",
    "model",
    "key_word",
    "exist_module_name",
    "mpu",
    "verbose"
  ],
  "get_compress_methods": [
    "model",
    "compress_methods",
    "mpu"
  ],
  "init_compression": [
    "model",
    "deepspeed_config",
    "teacher_model",
    "mpu"
  ],
  "redundancy_clean": [
    "model",
    "deepspeed_config",
    "mpu"
  ],
  "student_initialization": [
    "student_model",
    "teacher_model",
    "deepspeed_config"
  ],
  "required_torch_version": [
    "min_version",
    "max_version"
  ],
  "register_grad_hook": [
    "param",
    "hook"
  ],
  "jit_script_compat": [
    "fn"
  ],
  "get_caller_func": [
    "frame"
  ],
  "print_rank_0": [
    "message"
  ],
  "convert_size": [
    "size_bytes"
  ],
  "calc_bw_log": [
    "comm_op",
    "size",
    "duration"
  ],
  "CommsLogger": {
    "__init__": [
      "self"
    ],
    "configure": [
      "self",
      "comms_config"
    ],
    "start_profiling_comms": [
      "self"
    ],
    "stop_profiling_comms": [
      "self"
    ],
    "start_profiling_op": [
      "self",
      "op_name_list"
    ],
    "stop_profiling_op": [
      "self",
      "op_name_list"
    ],
    "append": [
      "self",
      "raw_name",
      "record_name",
      "latency",
      "msg_size"
    ],
    "get_raw_data": [
      "self"
    ],
    "has_data": [
      "self"
    ],
    "reset_data": [
      "self"
    ],
    "get_operation_names": [
      "self"
    ],
    "get_total_operations": [
      "self"
    ],
    "get_operation_summary": [
      "self",
      "operation_name"
    ],
    "log_all": [
      "self",
      "print_log",
      "show_straggler",
      "return_dict"
    ]
  },
  "fcntl": [],
  "module_names": [],
  "param_names": [],
  "debug_clear_module_and_param_names": [],
  "debug_extract_module_and_param_names": [
    "model"
  ],
  "debug_module2name": [
    "module"
  ],
  "debug_module2name_id": [
    "module"
  ],
  "debug_module2name_class": [
    "module"
  ],
  "debug_param2name": [
    "param"
  ],
  "ds_id": [
    "param"
  ],
  "ds_shape": [
    "param"
  ],
  "debug_param2name_id": [
    "param"
  ],
  "debug_param2name_id_shape": [
    "param"
  ],
  "debug_param2name_id_shape_device": [
    "param"
  ],
  "debug_param2name_id_numel": [
    "param"
  ],
  "debug_param2name_id_shape_status": [
    "param"
  ],
  "printflock": [],
  "fh": [],
  "log_rank_file": [
    "rank"
  ],
  "print_backward_tensors": [
    "tensor"
  ],
  "print_rank": [],
  "print_rank0": [],
  "_EXPERT_PARALLEL_GROUP": [],
  "_EXPERT_PARALLEL_GROUP_RANKS": [],
  "_EXPERT_DATA_PARALLEL_GROUP": [],
  "_EXPERT_DATA_PARALLEL_GROUP_RANKS": [],
  "_WORLD_GROUP": [],
  "_ZERO_PARAM_INTRA_PARALLEL_GROUP": [],
  "mpu": [],
  "expert_tensor_parallel_world_size": [],
  "_ALL_TO_ALL_GROUP": [],
  "mesh_device": [],
  "_ensure_divisibility": [
    "numerator",
    "denominator"
  ],
  "_TENSOR_MODEL_PARALLEL_GROUP": [],
  "_MODEL_PARALLEL_GROUP": [],
  "_DATA_PARALLEL_GROUP": [],
  "_MPU_TENSOR_MODEL_PARALLEL_WORLD_SIZE": [],
  "_MPU_TENSOR_MODEL_PARALLEL_RANK": [],
  "_init_tp_mesh_device": [
    "tensor_model_parallel_size",
    "data_parallel_size"
  ],
  "get_tensor_model_parallel_group": [],
  "get_model_parallel_group": [],
  "get_data_parallel_group": [],
  "set_tensor_model_parallel_world_size": [
    "world_size"
  ],
  "get_tensor_model_parallel_world_size": [],
  "get_model_parallel_world_size": [],
  "set_tensor_model_parallel_rank": [
    "rank"
  ],
  "get_tensor_model_parallel_rank": [],
  "get_model_parallel_rank": [],
  "get_tensor_model_parallel_src_rank": [],
  "get_data_parallel_world_size": [],
  "get_data_parallel_rank": [],
  "_create_model_parallel": [
    "model_parallel_size_"
  ],
  "_create_expert_and_data_parallel": [
    "expert_parallel_size_",
    "use_data_before_expert_parallel_"
  ],
  "_get_expert_parallel_ranks": [
    "world_size",
    "tensor_parallel_size_",
    "expert_parallel_size_",
    "pipeline_parallel_size_",
    "use_data_before_expert_parallel_"
  ],
  "_create_expert_data_and_model_parallel": [
    "expert_parallel_size_",
    "mpu",
    "use_data_before_expert_parallel_"
  ],
  "_get_max_expert_size": [],
  "_get_max_expert_size_name": [],
  "_get_max_expert_parallel_group": [],
  "_get_expert_parallel_group": [
    "group_name"
  ],
  "_get_expert_parallel_group_ranks": [
    "group_name"
  ],
  "_get_expert_parallel_group_dict": [],
  "_get_expert_data_parallel_group": [
    "group_name"
  ],
  "_get_expert_data_parallel_group_ranks": [
    "group_name"
  ],
  "_get_expert_data_parallel_group_dict": [],
  "_clone_world_group": [],
  "_get_local_all_to_all_group": [],
  "_get_data_parallel_group": [],
  "_get_data_parallel_group_ranks": [],
  "_get_broadcast_src_rank": [],
  "_get_expert_broadcast_src_rank": [
    "group_name"
  ],
  "_get_expert_parallel_world_size": [
    "group_name"
  ],
  "_get_expert_data_parallel_world_size": [
    "group_name"
  ],
  "_get_expert_parallel_rank": [
    "group_name"
  ],
  "_get_expert_parallel_src_rank": [
    "group_name"
  ],
  "_get_expert_data_parallel_rank": [
    "group_name"
  ],
  "_get_data_parallel_world_size": [],
  "_get_model_parallel_world_size": [],
  "_get_data_parallel_rank": [],
  "_get_sequence_parallel_world_size": [],
  "_get_sequence_parallel_rank": [],
  "_get_sequence_parallel_group": [],
  "_get_sequence_data_parallel_world_size": [],
  "_get_sequence_data_parallel_rank": [],
  "_get_sequence_data_parallel_group": [],
  "_get_expert_model_parallel_world_size": [],
  "_create_zero_param_parallel_group": [
    "group_size"
  ],
  "_get_zero_param_intra_parallel_group": [],
  "_zero_param_parallel_is_initialized": [],
  "_get_zero_param_intra_parallel_rank_in_mygroup": [],
  "_get_zero_param_intra_parallel_group_world_size": [],
  "_get_zero_param_intra_parallel_group_ranks": [],
  "get_numa_cores": [],
  "check_for_numactl_pkg": [],
  "parse_range": [
    "rng"
  ],
  "parse_range_list": [
    "range_str"
  ],
  "get_numactl_cmd": [
    "bind_core_list",
    "num_local_procs",
    "local_rank"
  ],
  "z3_leaf_module": [
    "model"
  ],
  "z3_leaf_parameter": [
    "model"
  ],
  "get_z3_leaf_modules": [
    "model"
  ],
  "set_z3_leaf_module": [
    "model",
    "flag"
  ],
  "_fully_qualified_class_name": [
    "module"
  ],
  "_do_set_z3_leaf_modules": [
    "model",
    "leaf_module_classes",
    "flag",
    "raise_if_not_found"
  ],
  "set_z3_leaf_modules_by_name": [
    "model",
    "module_names",
    "flag",
    "raise_if_not_found"
  ],
  "set_z3_leaf_modules_by_suffix": [
    "model",
    "module_name_suffixes",
    "flag",
    "raise_if_not_found"
  ],
  "set_z3_leaf_modules": [
    "model",
    "leaf_module_classes",
    "raise_if_not_found"
  ],
  "unset_z3_leaf_modules": [
    "model",
    "leaf_module_classes",
    "raise_if_not_found"
  ],
  "apply_zero_leaf_module_config": [
    "model",
    "leaf_cfg"
  ],
  "fragment_address": {},
  "tensor_fragment": {
    "update_hp": [
      "self"
    ],
    "update_lp": [
      "self"
    ],
    "get_optim_state_fragment": [
      "self",
      "key"
    ],
    "set_optim_state_fragment": [
      "self",
      "flat_hp_partition",
      "optim_fragment"
    ],
    "get_hp_fragment_address": [
      "self"
    ],
    "get_optim_state_keys": [
      "self"
    ],
    "get_hp_fragment": [
      "self",
      "optim_state_key"
    ],
    "get_lp_grad_fragment": [
      "self",
      "index_in_param_group"
    ]
  },
  "map_to_flat_opt_states": [
    "flat_hp_tensor",
    "lp_tensors",
    "optim_state",
    "opt_keys"
  ],
  "get_full_hp_param": [
    "self",
    "optim_state_key"
  ],
  "set_full_hp_param": [
    "self",
    "value",
    "optim_state_key"
  ],
  "get_full_hp_grad": [
    "self"
  ],
  "set_full_hp_grad": [
    "self",
    "value"
  ],
  "safe_get_full_fp32_param": [
    "param"
  ],
  "safe_set_full_fp32_param": [
    "param",
    "value"
  ],
  "safe_get_full_optimizer_state": [
    "param",
    "optim_state_key"
  ],
  "safe_set_full_optimizer_state": [
    "param",
    "value",
    "optim_state_key"
  ],
  "safe_get_full_grad": [
    "param"
  ],
  "safe_set_full_grad": [
    "param",
    "value"
  ],
  "safe_get_local_grad": [
    "param"
  ],
  "safe_set_local_grad": [
    "param",
    "value"
  ],
  "safe_get_local_fp32_param": [
    "param"
  ],
  "safe_get_local_optimizer_state": [
    "param",
    "optim_state_key"
  ],
  "safe_set_local_optimizer_state": [
    "param",
    "value",
    "optim_state_key"
  ],
  "safe_set_local_fp32_param": [
    "param",
    "value"
  ],
  "safe_update_full_grad_vectorized": [
    "param_list",
    "update_func"
  ],
  "get_hp_fragment_mapping": [
    "lp_param",
    "lp_start",
    "flat_hp_partition",
    "gradient_dict",
    "offload_gradient_dict",
    "use_offload",
    "param_group_index",
    "partition_start",
    "partition_size"
  ],
  "log_levels": [],
  "LoggerFactory": {
    "create_logger": [
      "name",
      "level"
    ]
  },
  "logger": [],
  "warning_once": [],
  "print_configuration": [
    "args",
    "name"
  ],
  "get_dist_msg": [
    "message",
    "ranks"
  ],
  "log_dist": [
    "message",
    "ranks",
    "level"
  ],
  "print_dist": [
    "message",
    "ranks"
  ],
  "_log_dist_once_cached": [
    "message",
    "ranks_key",
    "level"
  ],
  "log_dist_once": [
    "message",
    "ranks",
    "level"
  ],
  "print_json_dist": [
    "message",
    "ranks",
    "path"
  ],
  "get_log_level_from_string": [
    "log_level_str"
  ],
  "set_log_level_from_string": [
    "log_level_str",
    "custom_logger"
  ],
  "get_current_level": [],
  "should_log_le": [
    "max_log_level_str"
  ],
  "link_hp_params": [
    "lp_param_list",
    "flat_hp_partition",
    "gradient_dict",
    "offload_gradient_dict",
    "use_offload",
    "param_group_index",
    "partition_start",
    "partition_size",
    "dp_group"
  ],
  "lazy_init_hp_params_optimizer_state": [
    "lp_param_list",
    "flat_hp_partition",
    "optimizer_state"
  ],
  "_init_lp_to_hp_mapping": [
    "lp_param_list",
    "partition_start",
    "partition_size",
    "dp_group"
  ],
  "TIMERS_FORMAT": [],
  "TIMERS": [],
  "TIMERS_THROUGHPUT": [],
  "get_timers_config": [
    "param_dict"
  ],
  "DeepSpeedThroughputTimerConfig": {},
  "enable_nvtx": [],
  "instrument_w_nvtx": [
    "func"
  ],
  "zero_model_state": {},
  "debug": [],
  "device": [],
  "atoi": [
    "text"
  ],
  "natural_keys": [
    "text"
  ],
  "get_model_state_file": [
    "checkpoint_dir",
    "zero_stage"
  ],
  "get_checkpoint_files": [
    "checkpoint_dir",
    "glob_pattern"
  ],
  "get_optim_files": [
    "checkpoint_dir"
  ],
  "get_model_state_files": [
    "checkpoint_dir"
  ],
  "parse_model_states": [
    "files"
  ],
  "parse_optim_states": [
    "files",
    "ds_checkpoint_dir"
  ],
  "_get_fp32_state_dict_from_zero_checkpoint": [
    "ds_checkpoint_dir",
    "exclude_frozen_parameters"
  ],
  "_zero2_merge_frozen_params": [
    "state_dict",
    "zero_model_states"
  ],
  "_has_callable": [
    "obj",
    "fn"
  ],
  "_zero2_merge_trainable_params": [
    "state_dict",
    "world_size",
    "fp32_flat_groups",
    "zero_model_states"
  ],
  "_get_fp32_state_dict_from_zero2_checkpoint": [
    "world_size",
    "fp32_flat_groups",
    "zero_model_states",
    "exclude_frozen_parameters"
  ],
  "zero3_partitioned_param_info": [
    "unpartitioned_numel",
    "world_size"
  ],
  "_zero3_merge_frozen_params": [
    "state_dict",
    "world_size",
    "zero_model_states"
  ],
  "GatheredTensor": {
    "__init__": [
      "self",
      "flat_groups",
      "flat_groups_offset",
      "offset",
      "partitioned_numel",
      "shape"
    ],
    "contiguous": [
      "self"
    ]
  },
  "_zero3_merge_trainable_params": [
    "state_dict",
    "world_size",
    "fp32_flat_groups",
    "zero_model_states"
  ],
  "_get_fp32_state_dict_from_zero3_checkpoint": [
    "world_size",
    "fp32_flat_groups",
    "zero_model_states",
    "exclude_frozen_parameters"
  ],
  "to_torch_tensor": [
    "state_dict",
    "return_empty_tensor"
  ],
  "get_fp32_state_dict_from_zero_checkpoint": [
    "checkpoint_dir",
    "tag",
    "exclude_frozen_parameters",
    "lazy_mode"
  ],
  "convert_zero_checkpoint_to_fp32_state_dict": [
    "checkpoint_dir",
    "output_dir",
    "max_shard_size",
    "safe_serialization",
    "tag",
    "exclude_frozen_parameters"
  ],
  "load_state_dict_from_zero_checkpoint": [
    "model",
    "checkpoint_dir",
    "tag"
  ],
  "DeprecatedException": {},
  "GATED_ACTIVATION_TYPES": [],
  "NormType": {
    "UNKNOWN": [],
    "LayerNorm": [],
    "GroupNorm": [],
    "RMSNorm": []
  },
  "OnDevice": {
    "_orig_torch_empty": [],
    "_orig_torch_zeros": [],
    "_orig_torch_ones": [],
    "_orig_torch_full": [],
    "__init__": [
      "self",
      "dtype",
      "device",
      "enabled"
    ],
    "fp_tensor_constructor": [
      "self",
      "fn",
      "target_fp_dtype"
    ],
    "get_new_tensor_fn_for_dtype": [
      "self",
      "dtype"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "FORWARD_MICRO_TIMER": [],
  "FORWARD_GLOBAL_TIMER": [],
  "BACKWARD_MICRO_TIMER": [],
  "BACKWARD_GLOBAL_TIMER": [],
  "BACKWARD_INNER_MICRO_TIMER": [],
  "BACKWARD_INNER_GLOBAL_TIMER": [],
  "BACKWARD_REDUCE_MICRO_TIMER": [],
  "BACKWARD_REDUCE_GLOBAL_TIMER": [],
  "STEP_MICRO_TIMER": [],
  "STEP_GLOBAL_TIMER": [],
  "TIME_EPSILON": [],
  "CudaEventTimer": {
    "__init__": [
      "self",
      "start_event",
      "end_event"
    ],
    "get_elapsed_msec": [
      "self"
    ]
  },
  "SynchronizedWallClockTimer": {
    "__init__": [
      "self"
    ],
    "get_timers": [
      "self"
    ],
    "__call__": [
      "self",
      "name"
    ],
    "memory_usage": [],
    "log": [
      "self",
      "names",
      "normalizer",
      "reset",
      "memory_breakdown",
      "ranks"
    ],
    "get_mean": [
      "self",
      "names",
      "normalizer",
      "reset"
    ]
  },
  "NoopTimer": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "name"
    ],
    "get_timers": [
      "self"
    ],
    "log": [
      "self",
      "names",
      "normalizer",
      "reset",
      "memory_breakdown",
      "ranks"
    ],
    "get_mean": [
      "self",
      "names",
      "normalizer",
      "reset"
    ]
  },
  "ThroughputTimer": {
    "__init__": [
      "self",
      "config",
      "batch_size",
      "start_step",
      "steps_per_output",
      "monitor_memory",
      "logging_fn"
    ],
    "update_epoch_count": [
      "self"
    ],
    "_init_timer": [
      "self"
    ],
    "start": [
      "self"
    ],
    "_is_report_boundary": [
      "self"
    ],
    "stop": [
      "self",
      "global_step",
      "report_speed"
    ],
    "avg_samples_per_sec": [
      "self"
    ]
  },
  "trim_mean": [
    "data",
    "trim_percent"
  ],
  "bwc_tensor_model_parallel_rank": [
    "mpu"
  ],
  "bwc_tensor_model_parallel_world_size": [
    "mpu"
  ],
  "bwc_tensor_model_parallel_group": [
    "mpu"
  ],
  "bwc_pipeline_parallel_world_size": [
    "mpu"
  ],
  "bwc_pipeline_parallel_group": [
    "mpu"
  ],
  "Base_IO_Buffer": {
    "__init__": [
      "self",
      "pinned_tensor",
      "dnvme_handle"
    ],
    "fill": [
      "self",
      "src_tensor",
      "src_offset"
    ],
    "drain": [
      "self",
      "num_bytes",
      "fd",
      "file_offset"
    ],
    "is_empty": [
      "self"
    ],
    "is_full": [
      "self"
    ],
    "get_buffer": [
      "self"
    ],
    "get_offset": [
      "self"
    ],
    "get_aligned_num_bytes": [
      "self"
    ],
    "get_unaligned_num_bytes": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "complete_ongoing_drain": [
      "self"
    ],
    "_drain": [
      "self",
      "num_bytes",
      "fd",
      "file_offset",
      "blocking"
    ],
    "fill_buffer": [
      "src_tensor",
      "src_offset",
      "buffer_tensor",
      "buffer_offset"
    ]
  },
  "FASTIO_STAT_KEYS": [],
  "FastFileWriterConfig": {},
  "FastFileWriter": {
    "__init__": [
      "self",
      "file_path",
      "config"
    ],
    "write": [
      "self",
      "buffer"
    ],
    "split_index_list": [
      "self",
      "storage_obj_list",
      "num_splits"
    ],
    "save_torch_storage_object_list": [
      "self",
      "storage_obj_list",
      "save_size"
    ],
    "close": [
      "self"
    ],
    "fileno": [
      "self"
    ],
    "flush": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "_fini": [
      "self"
    ],
    "_fill_io_buffer": [
      "self",
      "src_tensor",
      "src_offset"
    ],
    "_drain_io_buffer": [
      "self",
      "num_bytes"
    ],
    "_io_buffer_is_full": [
      "self"
    ],
    "_io_buffer_is_empty": [
      "self"
    ],
    "_force_drain": [
      "self"
    ],
    "_unaligned_drain": [
      "self",
      "unaligned_tensor"
    ],
    "_dump_state": [
      "self"
    ],
    "_update_write_stats": [
      "self",
      "num_bytes",
      "secs_latency"
    ],
    "_write_from_tensor": [
      "self",
      "buffer_tensor"
    ],
    "_save_storage_list": [
      "self",
      "obj_list",
      "save_size"
    ],
    "_convert_to_byte_tensors": [
      "self",
      "obj_list",
      "save_size"
    ],
    "_partition_byte_tensors": [
      "self",
      "byte_tensor_list",
      "byte_tensor_nbytes",
      "num_ranks",
      "my_rank"
    ]
  },
  "serialize_details": {},
  "tensor_to_bytes": [
    "tensor"
  ],
  "bytes_to_tensor": [
    "buffer"
  ],
  "required_minimum_torch_version": [
    "major_version",
    "minor_version"
  ],
  "_legacy_obj_serialization_details": [
    "storage_obj"
  ],
  "_new_obj_serialization_details": [
    "storage_obj"
  ],
  "obj_serialization_details": [],
  "MockFileWriter": {
    "__init__": [
      "self",
      "file_path"
    ],
    "close": [
      "self"
    ],
    "fileno": [
      "self"
    ],
    "flush": [
      "self"
    ],
    "write": [
      "self",
      "buffer"
    ],
    "save_torch_storage_object_list": [
      "self",
      "storage_obj_list",
      "save_size"
    ],
    "_save_torch_storage_object": [
      "self",
      "storage_obj",
      "save_size"
    ],
    "_write": [
      "self",
      "num_bytes"
    ]
  },
  "BASE_STAT_KEYS": [],
  "BaseFileWriter": {
    "__init__": [
      "self",
      "file_path"
    ],
    "close": [
      "self"
    ],
    "fileno": [
      "self"
    ],
    "flush": [
      "self"
    ],
    "write": [
      "self",
      "buffer"
    ],
    "file_path": [
      "self"
    ],
    "_incr_stats": [
      "self",
      "key",
      "incr"
    ],
    "_dump_state": [
      "self"
    ]
  },
  "NUM_BUFFERS": [],
  "INVALID_BUFFER_INDEX": [],
  "Double_IO_Buffer": {
    "__init__": [
      "self",
      "pinned_tensor",
      "dnvme_handle"
    ],
    "fill": [
      "self",
      "src_tensor",
      "src_offset"
    ],
    "drain": [
      "self",
      "num_bytes",
      "fd",
      "file_offset"
    ],
    "get_buffer": [
      "self"
    ],
    "get_offset": [
      "self"
    ],
    "get_aligned_num_bytes": [
      "self"
    ],
    "get_unaligned_num_bytes": [
      "self"
    ],
    "is_full": [
      "self"
    ],
    "is_empty": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "complete_ongoing_drain": [
      "self"
    ],
    "_split_buffer": [
      "self"
    ],
    "_validate_buffer_index": [
      "self",
      "index"
    ],
    "_wait_for_drain": [
      "self"
    ],
    "_is_ongoing_drain": [
      "self"
    ]
  },
  "PyFileWriter": {
    "__init__": [
      "self",
      "file_path"
    ],
    "close": [
      "self"
    ],
    "fileno": [
      "self"
    ],
    "flush": [
      "self"
    ],
    "write": [
      "self",
      "buffer"
    ]
  },
  "INVALID_FD": [],
  "FILE_PATH_KEY": [],
  "FLUSH_COUNT_KEY": [],
  "WRITE_COUNT_KEY": [],
  "CLOSE_COUNT_KEY": [],
  "FILENO_COUNT_KEY": [],
  "WRITE_BYTES_KEY": [],
  "WRITE_SEC_KEY": [],
  "WRITE_SPEED_KEY": [],
  "AIO_WRITE_SEC_KEY": [],
  "AIO_WRITE_BYTES_KEY": [],
  "AIO_SPEED_KEY": [],
  "SLOW_WRITE_BYTES_KEY": [],
  "SLOW_WRITE_SEC_KEY": [],
  "AIO_FILL_BUFFER_SEC_KEY": [],
  "AIO_FILL_BUFFER_COUNT_KEY": [],
  "AIO_FILL_BUFFER_SPEED_KEY": [],
  "SAVE_STORAGE_KEY": [],
  "SAVE_STORAGE_BYTES_KEY": [],
  "SAVE_STORAGE_SEC_KEY": [],
  "STORAGE_OBJ_SIZE": [],
  "RANK_KEY": [],
  "Single_IO_Buffer": {
    "__init__": [
      "self",
      "pinned_tensor",
      "dnvme_handle"
    ],
    "fill": [
      "self",
      "src_tensor",
      "src_offset"
    ],
    "drain": [
      "self",
      "num_bytes",
      "fd",
      "file_offset"
    ],
    "get_buffer": [
      "self"
    ],
    "get_offset": [
      "self"
    ],
    "get_aligned_num_bytes": [
      "self"
    ],
    "get_unaligned_num_bytes": [
      "self"
    ],
    "is_full": [
      "self"
    ],
    "is_empty": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "TOPK_GATE_TIMER": [],
  "MOE_TIMER": [],
  "FIRST_ALLTOALL_TIMER": [],
  "SECOND_ALLTOALL_TIMER": [],
  "multiplicative_jitter": [
    "x",
    "device",
    "epsilon"
  ],
  "gumbel_rsample": [
    "shape",
    "device"
  ],
  "_AllToAll": {
    "forward": [
      "ctx",
      "group",
      "input"
    ],
    "backward": [
      "ctx"
    ]
  },
  "USE_EINSUM": [],
  "einsum": [
    "rule",
    "a",
    "b"
  ],
  "_capacity": [
    "gates",
    "capacity_factor",
    "min_capacity"
  ],
  "_top_idx": [
    "source",
    "k"
  ],
  "_one_hot_to_float": [
    "x",
    "num_classes"
  ],
  "top1gating": [
    "logits",
    "capacity_factor",
    "min_capacity",
    "used_token",
    "noisy_gate_policy",
    "drop_tokens",
    "use_rts",
    "ep_group",
    "use_tutel"
  ],
  "top2gating": [
    "logits",
    "capacity_factor",
    "min_capacity",
    "drop_tokens",
    "ep_group",
    "top2_2nd_expert_sampling"
  ],
  "topkgating": [
    "logits",
    "k",
    "capacity_factor",
    "min_capacity",
    "drop_tokens",
    "ep_group",
    "drop_policy"
  ],
  "TopKGate": {
    "__init__": [
      "self",
      "model_dim",
      "num_experts",
      "k",
      "capacity_factor",
      "eval_capacity_factor",
      "min_capacity",
      "noisy_gate_policy",
      "drop_tokens",
      "use_rts",
      "ep_group",
      "top2_2nd_expert_sampling"
    ],
    "_set_ep_group": [
      "self",
      "ep_group"
    ],
    "forward": [
      "self",
      "input",
      "used_token",
      "use_tutel"
    ]
  },
  "MOELayer": {
    "__init__": [
      "self",
      "gate",
      "experts",
      "ep_group_name",
      "ep_size",
      "num_local_experts",
      "use_tutel"
    ],
    "_set_ep_group": [
      "self",
      "ep_group"
    ],
    "forward": [
      "self"
    ]
  },
  "_gather_tokens": [
    "input_",
    "dim"
  ],
  "_drop_tokens": [
    "input_",
    "dim"
  ],
  "_GatherTokens": {
    "symbolic": [
      "graph",
      "input_",
      "dim"
    ],
    "forward": [
      "ctx",
      "input_",
      "dim"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "_DropTokens": {
    "symbolic": [
      "graph",
      "input_",
      "dim"
    ],
    "forward": [
      "ctx",
      "input_",
      "dim"
    ],
    "backward": [
      "ctx",
      "input_"
    ]
  },
  "gather_tokens": [
    "input_",
    "dim"
  ],
  "drop_tokens": [
    "input_",
    "dim"
  ],
  "has_moe_layers": [
    "m"
  ],
  "is_moe_param": [
    "param"
  ],
  "split_params_into_shared_and_expert_params": [
    "params"
  ],
  "split_params_grads_into_shared_and_expert_params": [
    "group"
  ],
  "split_params_into_different_moe_groups_for_optimizer": [
    "param_groups",
    "max_group_size"
  ],
  "is_moe_param_group": [
    "param_group"
  ],
  "configure_moe_param_groups": [
    "model_parameters"
  ],
  "MoE": {
    "__init__": [
      "self",
      "hidden_size",
      "expert",
      "num_experts",
      "ep_size",
      "k",
      "capacity_factor",
      "eval_capacity_factor",
      "min_capacity",
      "use_residual",
      "noisy_gate_policy",
      "drop_tokens",
      "use_rts",
      "use_tutel",
      "enable_expert_tensor_parallelism",
      "top2_2nd_expert_sampling"
    ],
    "set_deepspeed_parallelism": [
      "self",
      "use_data_before_expert_parallel_"
    ],
    "_create_process_groups": [
      "self",
      "use_data_before_expert_parallel_"
    ],
    "forward": [
      "self",
      "hidden_states",
      "used_token"
    ]
  },
  "Experts": {
    "__init__": [
      "self",
      "expert",
      "num_local_experts",
      "expert_group_name"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "is_torch_elastic_compatible": [],
  "ElasticityError": {},
  "ElasticityConfigError": {},
  "ElasticityIncompatibleWorldSize": {},
  "ElasticityConfig": {
    "__init__": [
      "self",
      "param_dict"
    ],
    "repr": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "HCN_LIST": [],
  "get_candidate_batch_sizes": [
    "base_list",
    "max_acceptable_batch_size"
  ],
  "get_valid_gpus": [
    "batch_size",
    "micro_batches",
    "min_valid_gpus",
    "max_valid_gpus"
  ],
  "get_best_candidates": [
    "candidate_batch_sizes",
    "micro_batches",
    "min_gpus",
    "max_gpus",
    "prefer_larger"
  ],
  "_get_compatible_gpus_v01": [
    "micro_batches",
    "max_acceptable_batch_size",
    "min_gpus",
    "max_gpus",
    "prefer_larger"
  ],
  "_get_compatible_gpus_v02": [
    "micro_batches",
    "max_acceptable_batch_size",
    "current_num_gpus",
    "min_gpus",
    "max_gpus",
    "prefer_larger",
    "num_gpus_per_node",
    "model_parallel_size"
  ],
  "_compatible_ds_version_check": [
    "target_deepspeed_version"
  ],
  "elasticity_enabled": [
    "ds_config"
  ],
  "ensure_immutable_elastic_config": [
    "runtime_elastic_config_dict"
  ],
  "compute_elastic_config": [
    "ds_config",
    "target_deepspeed_version",
    "world_size",
    "return_microbatch"
  ],
  "log": [],
  "DSElasticAgent": {
    "__init__": [
      "self",
      "spec",
      "env",
      "start_method",
      "exit_barrier_timeout",
      "log_dir"
    ],
    "_set_master_addr_port": [
      "store",
      "master_addr",
      "master_port",
      "local_addr"
    ],
    "_start_workers": [
      "self",
      "worker_group"
    ],
    "_invoke_run": [
      "self",
      "role"
    ]
  },
  "FORMAT": [],
  "ELASTICITY": [],
  "LATEST_ELASTICITY_VERSION": [],
  "ENABLED": [],
  "ENABLED_DEFAULT": [],
  "MAX_ACCEPTABLE_BATCH_SIZE": [],
  "MAX_ACCEPTABLE_BATCH_SIZE_DEFAULT": [],
  "MICRO_BATCHES": [],
  "MICRO_BATCHES_DEFAULT": [],
  "MIN_GPUS": [],
  "MIN_GPUS_DEFAULT": [],
  "MAX_GPUS": [],
  "MAX_GPUS_DEFAULT": [],
  "NUM_GPUS_PER_NODE": [],
  "NUM_GPUS_PER_NODE_DEFAULT": [],
  "MODEL_PARALLEL_SIZE": [],
  "MODEL_PARALLEL_SIZE_DEFAULT": [],
  "MIN_TIME": [],
  "MIN_TIME_DEFAULT": [],
  "PREFER_LARGER_BATCH": [],
  "PREFER_LARGER_BATCH_DEFAULT": [],
  "IGNORE_NON_ELASTIC_BATCH_INFO": [],
  "IGNORE_NON_ELASTIC_BATCH_INFO_DEFAULT": [],
  "VERSION": [],
  "VERSION_DEFAULT": [],
  "MINIMUM_DEEPSPEED_VERSION": [],
  "DEEPSPEED_ELASTICITY_CONFIG": [],
  "remaining_schedule": [],
  "next_pass_step": [],
  "next_passes": [],
  "current_passes": [],
  "GraphOrder": {
    "__init__": [
      "self"
    ],
    "add_graph": [
      "self",
      "graph_id",
      "frame_id",
      "needs_backward"
    ],
    "get_graph_order": [
      "self"
    ],
    "clear": [
      "self"
    ]
  },
  "graph_order_with_frame_id": [],
  "frames_needing_bwd": [],
  "opt_pass_times": [],
  "opt_passes": [],
  "fwd_real_inputs": [],
  "register_compile_pass": [
    "name",
    "opt_pass_fn"
  ],
  "init_schedule": [
    "schedule"
  ],
  "launch_compile_passes": [
    "global_steps"
  ],
  "set_time_and_tensor_size": [
    "graph_id",
    "graph",
    "mem",
    "bwd",
    "profiling_results"
  ],
  "evaluate_symint_from_shape_env": [
    "sym_int_v"
  ],
  "set_example_values_to_symints": [
    "real_inputs",
    "param_indices"
  ],
  "run_opt_passes": [
    "opt_passes",
    "gm",
    "graph_id",
    "graph_order",
    "profiling_results",
    "create_inputs_fn",
    "mem_budget",
    "param_manager",
    "bwd",
    "debug_log"
  ],
  "make_backend": [
    "backend",
    "compile_config",
    "compile_kwargs"
  ],
  "TensorMetadata": {},
  "InputStorage": {
    "__init__": [
      "self",
      "keep_int_input_tensors",
      "keep_all_input_tensors"
    ],
    "_is_int_tensor": [
      "self",
      "tensor"
    ],
    "_extract_tensor_metadata": [
      "self",
      "tensor"
    ],
    "_store_value": [
      "self",
      "value"
    ],
    "_materialize_value": [
      "self",
      "stored_value"
    ],
    "put": [
      "self",
      "real_inputs"
    ],
    "get": [
      "self"
    ],
    "has_data": [
      "self"
    ],
    "clear": [
      "self"
    ]
  },
  "wrap_if_ds_param": [
    "t"
  ],
  "patch_fake_tensor": [],
  "_recompute_param_aliases": [
    "joint_graph",
    "param_indices"
  ],
  "get_wrapped_partitioner": [
    "z3_partition",
    "param_indices",
    "partition_fn"
  ],
  "DSGraphParam": {
    "__post_init__": [
      "self"
    ]
  },
  "DSGraphParamManager": {
    "__init__": [
      "self",
      "fw_graph",
      "sample_inputs",
      "index_to_ds_ids"
    ],
    "get_bwd_mapping": [
      "self",
      "bw_graph"
    ],
    "param_names": [
      "self"
    ],
    "params": [
      "self"
    ],
    "ds_ids": [
      "self"
    ],
    "get_grad_name": [
      "self",
      "param_name"
    ],
    "replace_fake_tensors_with_real_params": [
      "self",
      "sample_inputs",
      "bw_graph"
    ]
  },
  "WARMUP": [],
  "init_z3": [
    "engine",
    "backend",
    "compile_config",
    "compile_kwargs",
    "schedule"
  ],
  "backward_inputs": [],
  "enabled_patched_func": [],
  "original_grad_fn": [],
  "base_meta": [],
  "patch_compiled_func": [],
  "unpatch_compiled_func": [],
  "get_backward_inputs": [],
  "get_output_node": [
    "graph"
  ],
  "move_primals_to_head": [
    "graph"
  ],
  "add_args_process": [
    "graph",
    "node",
    "fn",
    "extra_args",
    "name",
    "meta"
  ],
  "add_postprocess": [
    "graph",
    "node",
    "fn",
    "extra_args",
    "extra_kwargs",
    "name",
    "meta"
  ],
  "_make_node_meta": [
    "node",
    "ds_id",
    "comm"
  ],
  "add_free_activations": [
    "graph_id",
    "graph",
    "activation_node_names"
  ],
  "patch_compiler": [
    "original_compiler",
    "dc_compiler",
    "z3_partition",
    "graph_id",
    "graph_param_manager",
    "bwd"
  ],
  "wrap_partition_fn": [
    "partition_fn",
    "real_inputs",
    "param_indices"
  ],
  "patch_create_aot_dispatcher_function": [
    "graph_id",
    "z3_partition",
    "make_fw_graph",
    "make_bw_graph",
    "real_inputs",
    "param_indices",
    "param_manager"
  ],
  "register_custom_ops": [],
  "CompileConfig": {},
  "is_deepcompile_supported": [],
  "dc_handle": [],
  "get_deepcompile_handle": [],
  "is_backend_inductor": [
    "backend"
  ],
  "backward_started": [],
  "pre_backward_hooks": [],
  "add_pre_backward_hook": [
    "hook"
  ],
  "deepcompile_backward_prologue": [
    "is_gradient_accumulation_boundary"
  ],
  "log_rank0": [
    "msg",
    "enable"
  ],
  "get_no_copy_ops": [],
  "get_input_nodes": [
    "graph"
  ],
  "get_param_nodes": [
    "graph",
    "index_to_ds_ids"
  ],
  "is_comm_op": [
    "node"
  ],
  "is_cast_op": [
    "node"
  ],
  "exclude_from_act_offload": [
    "node"
  ],
  "dtype_to_elem_size": [
    "dtype"
  ],
  "tensor_meta_size": [
    "tensor_meta"
  ],
  "NodeValueOffloadHelper": {
    "__init__": [
      "self",
      "device"
    ],
    "_to_cpu": [
      "self",
      "v"
    ],
    "_from_cpu": [
      "self",
      "v"
    ],
    "save": [
      "self",
      "name",
      "v",
      "offload"
    ],
    "load": [
      "self",
      "name"
    ],
    "get_offloaded_value": [
      "self",
      "name"
    ],
    "has_value": [
      "self",
      "name"
    ],
    "clear": [
      "self"
    ]
  },
  "materialize_fake": [
    "v",
    "device"
  ],
  "get_last_uses": [
    "graph"
  ],
  "get_real_uses": [
    "graph"
  ],
  "count_inflight_values": [
    "graph",
    "file_path"
  ],
  "get_activation_node_names": [
    "graph",
    "param_nodes_bw",
    "fwd_output_names"
  ],
  "TensorOffloadHelper": {
    "__init__": [
      "self"
    ],
    "offload": [
      "self",
      "argument"
    ],
    "reload": [
      "self",
      "in_place"
    ]
  },
  "add_mem_profile_nodes": [
    "graph",
    "prefix"
  ],
  "is_release_node": [
    "n"
  ],
  "get_index_by_graph_id": [
    "graph_order",
    "target_graph_id"
  ],
  "pad_tensors": [
    "specs"
  ],
  "make_graph_from_schedule": [
    "scheduled"
  ],
  "get_original_args_num": [
    "node"
  ],
  "flat_nodes_in_args": [
    "args"
  ],
  "filter_args": [
    "node"
  ],
  "get_runnable_nodes": [
    "scheduled",
    "unscheduled"
  ],
  "choose_next_node": [
    "scheduled",
    "unscheduled",
    "mem_table"
  ],
  "create_mem_table": [
    "graph"
  ],
  "list_schedule": [
    "graph"
  ],
  "get_new_runnable_nodes_with": [
    "scheduled",
    "edges",
    "new_scheduled"
  ],
  "_do_schedule_without_allgather": [
    "scheduled",
    "unscheduled",
    "edges",
    "non_ag_runnable"
  ],
  "schedule_without_allgather": [
    "scheduled",
    "unscheduled",
    "edges"
  ],
  "try_schedule_with_new_allgather": [
    "scheduled",
    "unscheduled",
    "edges",
    "new_scheduled"
  ],
  "simple_prefetch": [
    "graph",
    "available_mem",
    "output_size",
    "debug_log"
  ],
  "init_schedule_with_placeholders": [
    "graph"
  ],
  "get_node_requirements": [
    "target_node",
    "scheduled"
  ],
  "AllgatherTask": {},
  "fast_free_schedule": [
    "graph",
    "available_mem",
    "output_size",
    "debug_log"
  ],
  "init_z1": [
    "engine",
    "backend",
    "compile_config",
    "compile_kwargs",
    "schedule",
    "use_z2"
  ],
  "sync_all": [],
  "get_bw": [
    "comm_op",
    "size",
    "duration"
  ],
  "timed_all_gather": [
    "device",
    "input",
    "output",
    "start_event",
    "end_event",
    "warmup",
    "trials",
    "async_op"
  ],
  "run_all_gather": [
    "device",
    "dtype",
    "maxsize",
    "warmup",
    "trials",
    "async_op"
  ],
  "profile_results": [],
  "create_predictor": [],
  "_all_real_if_tensor": [
    "args"
  ],
  "_to": [
    "v",
    "device"
  ],
  "_args_to_key": [
    "v"
  ],
  "_node_size": [
    "out"
  ],
  "_get_mem_usage_out_of_torch": [],
  "ProfilingInterpreter": {
    "__init__": [
      "self",
      "gm",
      "iteration",
      "warmup",
      "debug_log"
    ],
    "run": [
      "self"
    ],
    "run_node": [
      "self",
      "n"
    ]
  },
  "MemoryProfilingInterpreter": {
    "__init__": [
      "self",
      "gm",
      "debug_log"
    ],
    "run": [
      "self"
    ],
    "run_node": [
      "self",
      "n"
    ],
    "dump": [
      "self",
      "path"
    ]
  },
  "ProfilingResult": {},
  "NAME": [],
  "FUSE_FACTOR": [],
  "MARGIN": [],
  "MAX_FUSE_SIZE": [],
  "MAX_BUFFERED_SIZE": [],
  "run_prefetch_pass": [],
  "get_ds_id": [
    "node"
  ],
  "schedule_prefetch": [
    "gm",
    "graph_id",
    "graph_order",
    "profiling_results",
    "create_inputs_fn",
    "mem_budget",
    "param_manager",
    "bwd"
  ],
  "print_r0": [
    "msg"
  ],
  "copy_stream": [],
  "offload_event": [],
  "reload_event": [],
  "offload_key_events": [],
  "reload_key_events": [],
  "max_memory": [],
  "lazy_init": [],
  "optimizer": [],
  "nz3": [],
  "move_key": [
    "state",
    "key",
    "key_event"
  ],
  "move_back_key": [
    "state",
    "key",
    "key_event"
  ],
  "move_hp_param": [
    "src_tensor",
    "dest_buf",
    "key_event"
  ],
  "move_back_hp_param": [
    "src_tensor",
    "dest_buf",
    "key_event"
  ],
  "offload_adam_states_sync": [],
  "reload_adam_states_sync": [],
  "sync_offload_states": [
    "event"
  ],
  "sync_reload_states": [
    "event"
  ],
  "make_offload_task": [
    "task"
  ],
  "make_offload_sync": [
    "task"
  ],
  "make_reload_task": [
    "task"
  ],
  "update_max_memory": [
    "name"
  ],
  "empty_cache": [],
  "offload_tasks": [],
  "offload_tasks_remaining": [],
  "offload_tasks_scheduled": [],
  "reload_task_remaining": [],
  "total_reload_mem": [],
  "offload_opt_states_inc": [
    "graph",
    "graph_id",
    "graph_order",
    "profiling_results",
    "mem_budget",
    "param_manager",
    "bwd"
  ],
  "add_record_max_mem_nodes": [
    "graph"
  ],
  "insert_offload_opt_states": [
    "graph",
    "graph_id",
    "graph_order",
    "profiling_results",
    "mem_budget",
    "param_manager",
    "bwd"
  ],
  "move_opt_states": [
    "gm",
    "graph_id",
    "graph_order",
    "profiling_results",
    "create_inputs_fn",
    "mem_budget",
    "param_manager",
    "bwd"
  ],
  "move_opt_states_sync": [
    "gm",
    "graph_id",
    "graph_order",
    "profiling_results",
    "create_inputs_fn",
    "mem_budget",
    "param_manager",
    "bwd"
  ],
  "offload_adam_states_for_init": [
    "gm",
    "graph_id",
    "graph_order",
    "profiling_results",
    "create_inputs_fn",
    "mem_budget",
    "param_manager",
    "bwd"
  ],
  "init_offload_opt_states": [
    "adam_optimizer",
    "_nz3"
  ],
  "add_offload_parameter": [
    "graph_id",
    "gm",
    "node",
    "ds_id"
  ],
  "add_reload_parameter": [
    "graph_id",
    "gm",
    "node",
    "ds_id"
  ],
  "offload_parameter_fwd": [
    "gm",
    "graph_id",
    "graph_order",
    "profiling_results",
    "create_inputs_fn",
    "mem_budget",
    "param_manager",
    "bwd"
  ],
  "get_random_id": [],
  "_should_offload": [
    "node"
  ],
  "offload_activation_fwd": [
    "graph",
    "graph_id",
    "nodes_to_offload_with_names",
    "graph_order",
    "mem_budget",
    "param_manager"
  ],
  "reload_activation_bwd": [
    "graph",
    "graph_id",
    "graph_order",
    "mem_budget",
    "param_manager"
  ],
  "add_allgather": [
    "graph_id",
    "graph",
    "node",
    "ds_id",
    "dtype"
  ],
  "add_release": [
    "graph_id",
    "graph",
    "node",
    "release_node",
    "ds_id",
    "n_users"
  ],
  "add_reduce": [
    "graph_id",
    "graph",
    "grad_node",
    "param_name",
    "ds_id"
  ],
  "add_gather_and_release": [
    "graph_id",
    "graph",
    "param_manager",
    "param_nodes"
  ],
  "add_gather_and_reduce": [
    "graph_id",
    "graph",
    "param_manager",
    "param_nodes_bw",
    "param_name_to_grad"
  ],
  "add_z3_gather_release_fw": [
    "gm",
    "graph_id",
    "graph_order",
    "profiling_results",
    "create_inputs_fn",
    "param_manager",
    "debug_log"
  ],
  "add_z3_gather_release_bw": [
    "gm",
    "graph_id",
    "graph_order",
    "profiling_results",
    "create_inputs_fn",
    "param_manager",
    "debug_log"
  ],
  "add_z3_gather_release": [
    "gm",
    "graph_id",
    "graph_order",
    "profiling_results",
    "create_inputs_fn",
    "mem_budget",
    "param_manager",
    "bwd"
  ],
  "add_z1_reduce_fw": [
    "gm",
    "graph_id",
    "profiling_results",
    "param_manager",
    "use_z2"
  ],
  "add_z1_reduce_bw": [
    "gm",
    "graph_id",
    "param_manager"
  ],
  "add_z1_reduce": [
    "gm",
    "graph_id",
    "graph_order",
    "profiling_results",
    "create_inputs_fn",
    "mem_budget",
    "param_manager",
    "bwd"
  ],
  "add_z2_reduce": [
    "gm",
    "graph_id",
    "graph_order",
    "profiling_results",
    "create_inputs_fn",
    "mem_budget",
    "param_manager",
    "bwd"
  ],
  "max_alloc_mem": [],
  "last_optimize_step": [],
  "selective_gather": [
    "gm",
    "graph_id",
    "graph_order",
    "profiling_results",
    "create_inputs_fn",
    "mem_budget",
    "param_manager",
    "bwd"
  ],
  "DeepSpeedFlopsProfilerConfig": {
    "__init__": [
      "self",
      "param_dict"
    ],
    "_initialize": [
      "self",
      "flops_profiler_dict"
    ]
  },
  "FLOPS_PROFILER_FORMAT": [],
  "FLOPS_PROFILER": [],
  "FLOPS_PROFILER_ENABLED": [],
  "FLOPS_PROFILER_ENABLED_DEFAULT": [],
  "FLOPS_PROFILER_RECOMPUTE_FWD_FACTOR": [],
  "FLOPS_PROFILER_RECOMPUTE_FWD_FACTOR_DEFAULT": [],
  "FLOPS_PROFILER_PROFILE_STEP": [],
  "FLOPS_PROFILER_PROFILE_STEP_DEFAULT": [],
  "FLOPS_PROFILER_MODULE_DEPTH": [],
  "FLOPS_PROFILER_MODULE_DEPTH_DEFAULT": [],
  "FLOPS_PROFILER_TOP_MODULES": [],
  "FLOPS_PROFILER_TOP_MODULES_DEFAULT": [],
  "FLOPS_PROFILER_DETAILED": [],
  "FLOPS_PROFILER_DETAILED_DEFAULT": [],
  "FLOPS_PROFILER_OUTPUT_FILE": [],
  "FLOPS_PROFILER_OUTPUT_FILE_DEFAULT": [],
  "Tensor": [],
  "module_flop_count": [],
  "module_mac_count": [],
  "old_functions": [],
  "DEFAULT_PRECISION": [],
  "FlopsProfiler": {
    "__init__": [
      "self",
      "model",
      "ds_engine",
      "recompute_fwd_factor"
    ],
    "start_profile": [
      "self",
      "ignore_list"
    ],
    "stop_profile": [
      "self"
    ],
    "reset_profile": [
      "self"
    ],
    "end_profile": [
      "self"
    ],
    "get_total_flops": [
      "self",
      "as_string"
    ],
    "get_total_macs": [
      "self",
      "as_string"
    ],
    "get_total_duration": [
      "self",
      "as_string"
    ],
    "get_total_params": [
      "self",
      "as_string"
    ],
    "is_expert_tensor_parallelism_enabled": [
      "self"
    ],
    "print_model_profile": [
      "self",
      "profile_step",
      "module_depth",
      "top_modules",
      "detailed",
      "output_file"
    ],
    "print_model_aggregated_profile": [
      "self",
      "module_depth",
      "top_modules"
    ]
  },
  "_prod": [
    "dims"
  ],
  "_linear_flops_compute": [
    "input",
    "weight",
    "bias"
  ],
  "_relu_flops_compute": [
    "input",
    "inplace"
  ],
  "_prelu_flops_compute": [
    "input",
    "weight"
  ],
  "_elu_flops_compute": [
    "input",
    "alpha",
    "inplace"
  ],
  "_leaky_relu_flops_compute": [
    "input",
    "negative_slope",
    "inplace"
  ],
  "_relu6_flops_compute": [
    "input",
    "inplace"
  ],
  "_silu_flops_compute": [
    "input",
    "inplace"
  ],
  "_gelu_flops_compute": [
    "input"
  ],
  "_pool_flops_compute": [
    "input",
    "kernel_size",
    "stride",
    "padding",
    "dilation",
    "ceil_mode",
    "count_include_pad",
    "divisor_override",
    "return_indices"
  ],
  "_conv_flops_compute": [
    "input",
    "weight",
    "bias",
    "stride",
    "padding",
    "dilation",
    "groups"
  ],
  "_conv_trans_flops_compute": [
    "input",
    "weight",
    "bias",
    "stride",
    "padding",
    "output_padding",
    "groups",
    "dilation"
  ],
  "_batch_norm_flops_compute": [
    "input",
    "running_mean",
    "running_var",
    "weight",
    "bias",
    "training",
    "momentum",
    "eps"
  ],
  "_layer_norm_flops_compute": [
    "input",
    "normalized_shape",
    "weight",
    "bias",
    "eps"
  ],
  "_group_norm_flops_compute": [
    "input",
    "num_groups",
    "weight",
    "bias",
    "eps"
  ],
  "_instance_norm_flops_compute": [
    "input",
    "running_mean",
    "running_var",
    "weight",
    "bias",
    "use_input_stats",
    "momentum",
    "eps"
  ],
  "_upsample_flops_compute": [],
  "_softmax_flops_compute": [
    "input",
    "dim",
    "_stacklevel",
    "dtype"
  ],
  "_embedding_flops_compute": [
    "input",
    "weight",
    "padding_idx",
    "max_norm",
    "norm_type",
    "scale_grad_by_freq",
    "sparse"
  ],
  "_dropout_flops_compute": [
    "input",
    "p",
    "training",
    "inplace"
  ],
  "_matmul_flops_compute": [
    "input",
    "other"
  ],
  "_addmm_flops_compute": [
    "input",
    "mat1",
    "mat2"
  ],
  "_einsum_flops_compute": [
    "equation"
  ],
  "_einops_einsum_flops_compute": [],
  "_tensor_addmm_flops_compute": [
    "self",
    "mat1",
    "mat2"
  ],
  "_mul_flops_compute": [
    "input",
    "other"
  ],
  "_add_flops_compute": [
    "input",
    "other"
  ],
  "_elementwise_flops_compute": [
    "input",
    "other"
  ],
  "_attn_flops_compute": [
    "q",
    "k",
    "v"
  ],
  "wrapFunc": [
    "func",
    "funcFlopCompute"
  ],
  "_patch_functionals": [],
  "_patch_tensor_methods": [],
  "_patch_miscellaneous_operations": [],
  "_reload_functionals": [],
  "_reload_tensor_methods": [],
  "_reload_miscellaneous_operations": [],
  "_rnn_flops": [
    "flops",
    "rnn_module",
    "w_ih",
    "w_hh",
    "input_size"
  ],
  "_rnn_forward_hook": [
    "rnn_module",
    "input",
    "output"
  ],
  "_rnn_cell_forward_hook": [
    "rnn_cell_module",
    "input",
    "output"
  ],
  "MODULE_HOOK_MAPPING": [],
  "macs_to_string": [
    "macs",
    "units",
    "precision"
  ],
  "flops_to_string": [
    "flops",
    "units",
    "precision"
  ],
  "bytes_to_string": [
    "b",
    "units",
    "precision"
  ],
  "params_to_string": [
    "params_num",
    "units",
    "precision"
  ],
  "duration_to_string": [
    "duration",
    "units",
    "precision"
  ],
  "get_module_flops": [
    "module"
  ],
  "get_module_macs": [
    "module"
  ],
  "get_module_duration": [
    "module"
  ],
  "get_model_profile": [
    "model",
    "input_shape",
    "args",
    "kwargs",
    "print_profile",
    "detailed",
    "module_depth",
    "top_modules",
    "warm_up",
    "as_string",
    "output_file",
    "ignore_modules",
    "mode"
  ],
  "basic_folder_validation": [
    "dir"
  ],
  "get_files_with_prefix": [
    "all_files",
    "prefix"
  ],
  "validate_files": [
    "file_list"
  ],
  "get_files": [
    "dir"
  ],
  "sort_zero_files": [
    "files",
    "prefix"
  ],
  "get_zero_files": [
    "dir"
  ],
  "partition_data": [
    "data_list",
    "num_partitions"
  ],
  "_key_list_to_string": [
    "key_list"
  ],
  "merge_state_dict": [
    "dict_a",
    "dict_b",
    "key_list"
  ],
  "merge_state_list": [
    "list_a",
    "list_b",
    "key_list"
  ],
  "merge_state": [
    "state_a",
    "state_b",
    "key_list"
  ],
  "get_model_ckpt_name_for_rank": [
    "base_folder",
    "mp_rank_str"
  ],
  "get_zero_ckpt_name_for_rank": [
    "base_folder",
    "dp_rank",
    "mp_rank"
  ],
  "get_layer_ckpt_name_for_rank": [
    "base_folder",
    "layer_id",
    "tp_rank"
  ],
  "clone_tensors_for_torch_save": [
    "item",
    "device"
  ],
  "meg_2d_parallel_map": {
    "__init__": [
      "self",
      "pp_degree",
      "tp_degree"
    ],
    "simple_init": [
      "self"
    ],
    "add_data": [
      "self",
      "pp_index",
      "tp_index",
      "data"
    ],
    "get_data": [
      "self",
      "pp_index",
      "tp_index"
    ],
    "print_data": [
      "self",
      "tag"
    ],
    "_validate_indices": [
      "self",
      "pp_index",
      "tp_index"
    ],
    "_make_key": [
      "self",
      "i",
      "j"
    ]
  },
  "_reshape_tp_dimension": [
    "old_2d_map",
    "new_tp_degree"
  ],
  "_reshape_pp_dimension": [
    "old_2d_map",
    "new_pp_degree"
  ],
  "reshape_meg_2d_parallel": [
    "old_pp_degree",
    "old_tp_degree",
    "new_pp_degree",
    "new_tp_degree",
    "verbose"
  ],
  "get_mpu_ranks": [
    "tp_size",
    "pp_size",
    "dp_size",
    "virtual_pp_size"
  ],
  "reshape": [
    "src",
    "tgt"
  ],
  "SubparamShape": {},
  "load_hp_checkpoint_state": [
    "self",
    "folder",
    "tp_rank",
    "tp_world_size"
  ],
  "enable_universal_checkpoint": [
    "param_list"
  ],
  "_create_checkpoint_paths": [
    "base_folder",
    "iteration",
    "tp_degree",
    "pp_degree"
  ],
  "_save_checkpoint": [
    "file_path",
    "chkpt_sd"
  ],
  "extract_zero_shards": [
    "dir",
    "ds_checkpoint",
    "indices_3D"
  ],
  "extract_zero_shards_stage3": [
    "optim_files",
    "param_shapes",
    "dp_degree",
    "temp_dir",
    "dp_index"
  ],
  "cnt": [],
  "dp_index_to_str": [
    "dp_index"
  ],
  "dump_param_fragment": [
    "dir",
    "tp_index",
    "dp_index",
    "state_name",
    "state_flat_tensor",
    "param_name",
    "offset",
    "numel"
  ],
  "_merge_zero_shards": [
    "param_base_path",
    "state",
    "tp_degree",
    "slice_shape"
  ],
  "merge_tp_slices": [
    "ds_checkpoint",
    "dir",
    "slice_dir",
    "tp_degree",
    "name_and_shape"
  ],
  "merge_zero3_slices": [
    "dp_degree",
    "dir",
    "slice_dir",
    "name"
  ],
  "_do_parallel_work": [
    "do_work",
    "work_chunks",
    "num_workers"
  ],
  "_extract_zero_shard_files": [
    "args",
    "ds_checkpoint",
    "temp_dir"
  ],
  "_extract_zero_shard_files_stage3": [
    "args",
    "optim_files",
    "param_shapes",
    "dp_degree",
    "temp_dir"
  ],
  "_merge_tp_slice_files": [
    "args",
    "ds_checkpoint",
    "slice_shapes",
    "temp_dir"
  ],
  "_merge_zero3_slice_files": [
    "args",
    "param_keys",
    "dp_degree",
    "temp_dir"
  ],
  "_zero_partitioned_param_info": [
    "unpartitioned_numel",
    "world_size"
  ],
  "_parse_model_states_stage3": [
    "files"
  ],
  "_save_optimizer_state": [
    "args",
    "ds_checkpoint"
  ],
  "_save_optimizer_state_stage3": [
    "args",
    "optim_files"
  ],
  "_get_optim_files": [
    "checkpoint_dir"
  ],
  "_get_model_state_files": [
    "checkpoint_dir"
  ],
  "_get_checkpoint_files": [
    "checkpoint_dir",
    "glob_pattern"
  ],
  "_get_zero_stage": [
    "optim_files"
  ],
  "_inject_missing_state": [
    "ds_checkpoint"
  ],
  "_check_for_required_state": [
    "ds_checkpoint"
  ],
  "OPTIMIZER_STATE_DICT": [],
  "FP32_GROUPS": [],
  "FP32_FLAT_GROUPS": [],
  "BASE_OPTIMIZER_STATE": [],
  "BASE_OPTIMIZER_STATE_STEP": [],
  "SINGLE_PARTITION_OF_FP32_GROUPS": [],
  "PARAM_GROUPS": [],
  "GROUP_PADDINGS": [],
  "PARTITION_COUNT": [],
  "ZERO_STAGE": [],
  "CLIP_GRAD": [],
  "FP32_WEIGHT_KEY": [],
  "LOSS_SCALER": [],
  "PARAM": [],
  "PARAM_SHAPES": [],
  "BUFFER_NAMES": [],
  "FROZEN_PARAM_SHAPES": [],
  "FROZEN_PARAM_FRAGMENTS": [],
  "MODEL_FILE_PREFIX": [],
  "ZERO_FILE_PREFIX": [],
  "OPTIM_FILE_SUFFIX": [],
  "MODEL_FILE_SUFFIX": [],
  "LAYER_FILE_PREFIX": [],
  "BF16_ZERO_FILE_PREFIX": [],
  "FP16_ZERO_FILE_PREFIX": [],
  "DS_VERSION": [],
  "UNIVERSAL_CHECKPOINT_INFO": [],
  "UNIVERSAL_CHECKPOINT_VERSION_KEY": [],
  "UNIVERSAL_CHECKPOINT_VERSION_VALUE": [],
  "VOCAB_TENSOR": [],
  "PADDED_VOCAB_SIZE": [],
  "ORIGINAL_VOCAB_SIZE": [],
  "PARAM_SLICE_MAPPINGS": [],
  "CAT_DIM": [],
  "PARAM_N_SUB_PARAMS": [],
  "SUB_PARAM_SHAPE": [],
  "VOCABULARY_PARAMETER_PATTERNS": [],
  "PIPELINE_REPLICATED_PARAMETER_PATTERNS": [],
  "PARAMETER_TO_AVERAGE_PATTERNS": [],
  "PARAMETER_WITH_ROW_PARALLELISM_PATTERNS": [],
  "TP_REPLICATED_PARAMETER_PATTERNS": [],
  "PARAMETER_WITH_2_SUB_PARAMS_CAT_DIM_0": [],
  "PARAMETER_WITH_SUB_PARAMS": [],
  "SUB_PARAMS_SHAPE": [],
  "EMBEDDING_LAYER_INDEX": [],
  "FINAL_LAYER_NORM_INDEX": [],
  "ARGS_KEY": [],
  "CHECKPOINT_INFO_KEY": [],
  "ITERATION_KEY": [],
  "LAYER_FILE_PREFIX_PATTERN": [],
  "SEQUENTIAL_LAYERS": [],
  "LAYER_CONCAT_DIM": [],
  "DeepSpeedCheckpoint": {
    "__init__": [
      "self",
      "dir",
      "tp_degree",
      "pp_degree",
      "dp_degree",
      "final_layer_norm_idx"
    ],
    "is_change_tp_degree": [
      "self"
    ],
    "is_change_pp_degree": [
      "self"
    ],
    "is_change_dp_degree": [
      "self"
    ],
    "show_2d_mapping": [
      "self"
    ],
    "show_tp_embedding_map": [
      "self"
    ],
    "show_tp_final_norm_map": [
      "self"
    ],
    "show_pp_transformer_map": [
      "self"
    ],
    "show_transformer_file_map": [
      "self"
    ],
    "_build_global_state": [
      "self"
    ],
    "get_zero_checkpoint_state": [
      "self",
      "pp_index",
      "tp_index",
      "dp_index",
      "strip_tensor_paddings"
    ],
    "get_zero_files": [
      "self",
      "pp_index",
      "tp_index",
      "dp_index"
    ],
    "get_embedding_layer_id": [
      "self"
    ],
    "get_final_norm_layer_id": [
      "self"
    ],
    "get_iteration": [
      "self"
    ],
    "get_embedding_state": [
      "self",
      "tp_index"
    ],
    "get_embedding_files": [
      "self",
      "tp_index"
    ],
    "_get_checkpoint_value": [
      "self",
      "key"
    ],
    "get_args": [
      "self"
    ],
    "get_checkpoint_info": [
      "self",
      "info_key"
    ],
    "get_2d_parallel_state": [
      "self",
      "tp_index",
      "pp_index"
    ],
    "get_transformer_state": [
      "self",
      "tp_index",
      "pp_index"
    ],
    "get_pp_transformer_map": [
      "self",
      "pp_index"
    ],
    "get_final_norm_state": [
      "self",
      "tp_index"
    ],
    "get_final_norm_files": [
      "self",
      "tp_index"
    ],
    "_build_tp_other_layer_map": [
      "self",
      "layer_index"
    ],
    "get_2d_parallel_files": [
      "self",
      "tp_index",
      "pp_index"
    ],
    "_build_pp_transformer_map": [
      "self"
    ],
    "_dump_mapping": [
      "self",
      "data_map",
      "map_tag"
    ],
    "_build_transformer_file_map": [
      "self"
    ],
    "_sanity_check": [
      "self"
    ],
    "validate_files": [
      "self"
    ],
    "_get_layer_keys": [
      "self"
    ],
    "_merge_state_dicts": [
      "self",
      "sd_list"
    ],
    "_validate_folder": [
      "self",
      "dir",
      "pipeline_parallel"
    ]
  },
  "GROUP_STATE_KEY": [],
  "ZeROCheckpoint": {
    "__init__": [
      "self",
      "dir"
    ],
    "get_src_world_size": [
      "self"
    ],
    "get_src_tp_degree": [
      "self"
    ],
    "get_src_pp_degree": [
      "self"
    ],
    "get_src_dp_degree": [
      "self"
    ],
    "get_file_indices_for_rank": [
      "self",
      "pp_index",
      "tp_index",
      "dp_index"
    ],
    "get_files_for_rank": [
      "self",
      "pp_index",
      "tp_index",
      "dp_index"
    ],
    "get_state_for_rank": [
      "self",
      "pp_index",
      "tp_index",
      "dp_index",
      "keys_to_ignore",
      "strip_tensor_paddings"
    ],
    "print_3d_index_map": [
      "self",
      "tag"
    ],
    "print_3d_file_map": [
      "self",
      "tag"
    ],
    "reshape": [
      "self",
      "target_3d_desc"
    ],
    "_strip_tensor_paddings": [
      "self",
      "sd"
    ],
    "_clear_group_paddings": [
      "self",
      "sd"
    ],
    "_get_optimizer_state": [
      "self",
      "sd",
      "state_key"
    ],
    "_get_param_group_states": [
      "self",
      "sd"
    ],
    "_update_partition_count": [
      "self",
      "sd"
    ]
  },
  "PP_DIM": [],
  "TP_DIM": [],
  "DP_DIM": [],
  "model_3d_desc": {
    "__init__": [
      "self",
      "pp_degree",
      "tp_degree",
      "dp_degree"
    ],
    "reshape": [
      "self",
      "target_3d_desc",
      "verbose"
    ],
    "get_desc": [
      "self"
    ],
    "world_size": [
      "self"
    ],
    "is_valid": [
      "self",
      "pp_index",
      "tp_index",
      "dp_index"
    ],
    "can_reshape": [
      "self",
      "target_3d_desc"
    ]
  },
  "get_model_3d_descriptor": [
    "dir"
  ],
  "flatten_dp_dimension": [
    "meg_2d_map",
    "src_2d_size",
    "dp_degree"
  ],
  "unflatten_dp_dimension": [
    "meg_2d_map",
    "dp_degree"
  ],
  "_VocabSequenceParallelCrossEntropy": {
    "forward": [
      "ctx",
      "vocab_seq_parallel_logits",
      "target",
      "sp_group"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "vocab_sequence_parallel_cross_entropy": [
    "vocab_parallel_logits",
    "target",
    "sp_group"
  ],
  "_rotate_half_backward": [
    "x"
  ],
  "apply_rotary_pos_emb_backward": [
    "grad_output",
    "freqs_cos",
    "freqs_sin"
  ],
  "_update_out_and_lse": [
    "out",
    "lse",
    "block_out",
    "block_lse"
  ],
  "update_out_and_lse": [
    "out",
    "lse",
    "block_out",
    "block_lse",
    "slice_"
  ],
  "FPDT_InputConstruct": {
    "__init__": [
      "self",
      "tokens",
      "labels",
      "loss_mask",
      "attention_mask",
      "position_ids",
      "args",
      "sp_size",
      "sp_rank"
    ],
    "generate": [
      "self"
    ]
  },
  "_FPDTGPUAttentionImpl_": {
    "generate_vmap_rule": [],
    "forward": [
      "ctx",
      "layernorm_output",
      "attention_mask",
      "inference_params",
      "rotary_pos_emb",
      "spg",
      "scatter_idx",
      "gather_idx",
      "hidden_size",
      "projection_size",
      "hidden_size_per_attention_head",
      "kv_projection_size",
      "qkv_linear_weight",
      "qkv_linear_bias",
      "dropout",
      "num_chunks",
      "cpu_offloading"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "SequenceChunk": {
    "__init__": [
      "self",
      "chunk",
      "device",
      "is_in_use"
    ],
    "load_to_gpu": [
      "self"
    ],
    "get_gpu_chunk": [
      "self"
    ],
    "check_gpu_chunk": [
      "self"
    ],
    "offload": [
      "self"
    ],
    "overwrite_to_cpu": [
      "self"
    ]
  },
  "_FPDTGPUOffloadingAttentionImpl_": {
    "generate_vmap_rule": [],
    "forward": [
      "ctx",
      "layernorm_output",
      "attention_mask",
      "inference_params",
      "rotary_pos_emb",
      "spg",
      "scatter_idx",
      "gather_idx",
      "hidden_size",
      "projection_size",
      "hidden_size_per_attention_head",
      "kv_projection_size",
      "qkv_linear_weight",
      "qkv_linear_bias",
      "dropout",
      "num_chunks",
      "cpu_offloading"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "FPDT_Attention": {
    "__init__": [
      "self",
      "config",
      "first_weight",
      "first_bias",
      "second_weight",
      "second_bias",
      "sequence_process_group",
      "gather_idx",
      "scatter_idx",
      "return_bias",
      "chunk_size",
      "enable_offloading"
    ],
    "forward": [
      "self",
      "layernorm_output",
      "attention_mask",
      "inference_params",
      "rotary_pos_emb",
      "cpu_offloading"
    ]
  },
  "bias_gelu": [
    "x"
  ],
  "bias_gelu_back": [
    "g",
    "x"
  ],
  "FPDT_FFN": {
    "generate_vmap_rule": [],
    "forward": [
      "ctx",
      "x",
      "w1",
      "b1",
      "w2",
      "b2",
      "add_bias",
      "chunk_size"
    ],
    "backward": [
      "ctx",
      "grad_output",
      "grad_bias"
    ]
  },
  "FPDT_LogitsLoss": {
    "generate_vmap_rule": [],
    "forward": [
      "ctx",
      "lm_output",
      "labels",
      "logit_weights",
      "rank",
      "spg_size",
      "spg",
      "num_chunk"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "_generate_layout_params": [
    "scatter_idx",
    "batch_dim_idx",
    "seq_world_size",
    "input"
  ],
  "post_all2all": [
    "permute_idx",
    "res_shape"
  ],
  "pre_all2all_fun": [
    "permute_idx",
    "inp_shape",
    "input"
  ],
  "_rotate_half": [
    "x"
  ],
  "apply_rotary_pos_emb": [
    "t",
    "freqs_cos",
    "freqs_sin"
  ],
  "uneven_heads_all2all": [
    "input",
    "scatter_idx",
    "gather_idx",
    "batch_dim_idx",
    "group"
  ],
  "single_all_to_all": [
    "input",
    "scatter_idx",
    "gather_idx",
    "batch_dim_idx",
    "group",
    "async_op",
    "handle",
    "type"
  ],
  "_DimZeroAllToAll": {
    "forward": [
      "ctx",
      "group",
      "input"
    ],
    "backward": [
      "ctx"
    ]
  },
  "_SeqAllToAll": {
    "forward": [
      "ctx",
      "group",
      "input",
      "scatter_idx",
      "gather_idx",
      "batch_dim_idx",
      "stream",
      "handle",
      "type",
      "is_fwd"
    ],
    "backward": [
      "ctx"
    ]
  },
  "DistributedAttention": {
    "__init__": [
      "self",
      "local_attention",
      "sequence_process_group",
      "scatter_idx",
      "gather_idx",
      "sp_stream"
    ],
    "layer_sync": [
      "self",
      "layer"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "batch_dim_idx",
      "rotary_pos_emb"
    ]
  },
  "MultiNodeRunner": {
    "__init__": [
      "self",
      "args",
      "world_info_base64"
    ],
    "backend_exists": [
      "self"
    ],
    "get_cmd": [
      "self",
      "environment",
      "active_resources"
    ],
    "add_export": [
      "self",
      "key",
      "var"
    ],
    "parse_user_args": [
      "self"
    ],
    "name": [
      "self"
    ],
    "validate_args": [
      "self"
    ]
  },
  "PDSHRunner": {
    "__init__": [
      "self",
      "args",
      "world_info_base64"
    ],
    "backend_exists": [
      "self"
    ],
    "parse_user_args": [
      "self"
    ],
    "name": [
      "self"
    ],
    "get_cmd": [
      "self",
      "environment",
      "active_resources"
    ]
  },
  "OpenMPIRunner": {
    "__init__": [
      "self",
      "args",
      "world_info_base64",
      "resource_pool"
    ],
    "backend_exists": [
      "self"
    ],
    "name": [
      "self"
    ],
    "validate_args": [
      "self"
    ],
    "get_cmd": [
      "self",
      "environment",
      "active_resources"
    ]
  },
  "MPICHRunner": {
    "__init__": [
      "self",
      "args",
      "world_info_base64",
      "resource_pool"
    ],
    "backend_exists": [
      "self"
    ],
    "name": [
      "self"
    ],
    "validate_args": [
      "self"
    ],
    "get_cmd": [
      "self",
      "environment",
      "active_resources"
    ]
  },
  "IMPIRunner": {
    "__init__": [
      "self",
      "args",
      "world_info_base64",
      "resource_pool"
    ],
    "backend_exists": [
      "self"
    ],
    "name": [
      "self"
    ],
    "validate_args": [
      "self"
    ],
    "get_cmd": [
      "self",
      "environment",
      "active_resources"
    ]
  },
  "SlurmRunner": {
    "__init__": [
      "self",
      "args",
      "world_info_base64",
      "resource_pool"
    ],
    "backend_exists": [
      "self"
    ],
    "name": [
      "self"
    ],
    "get_cmd": [
      "self",
      "environment",
      "active_resources"
    ]
  },
  "MVAPICHRunner": {
    "__init__": [
      "self",
      "args",
      "world_info_base64",
      "resource_pool"
    ],
    "backend_exists": [
      "self"
    ],
    "name": [
      "self"
    ],
    "validate_args": [
      "self"
    ],
    "get_cmd": [
      "self",
      "environment",
      "active_resources"
    ]
  },
  "PID_FILE_BASEPATH": [],
  "parse_args": [],
  "terminate_process_tree": [
    "pid"
  ],
  "env_mapping": [
    "env",
    "rank_name_list",
    "local_rank_name_list"
  ],
  "PDSH_LAUNCHER": [],
  "OPENMPI_LAUNCHER": [],
  "MPICH_LAUNCHER": [],
  "IMPI_LAUNCHER": [],
  "SLURM_LAUNCHER": [],
  "MVAPICH_LAUNCHER": [],
  "MVAPICH_TMP_HOSTFILE": [],
  "ELASTIC_TRAINING_ID_DEFAULT": [],
  "DLTS_HOSTFILE": [],
  "EXPORT_ENVS": [],
  "DEEPSPEED_ENVIRONMENT_NAME": [],
  "DEEPSPEED_ENVIRONMENT_PATHS": [],
  "EXCLUDE_ENVS": [],
  "_parse_hostfile": [
    "hostfile_lines"
  ],
  "_stable_remove_duplicates": [
    "data"
  ],
  "parse_node_config": [
    "node_config"
  ],
  "parse_node_config_list": [
    "node_config_list"
  ],
  "parse_resource_filter": [
    "host_info",
    "include_str",
    "exclude_str"
  ],
  "parse_inclusion_exclusion": [
    "resource_pool",
    "inclusion",
    "exclusion"
  ],
  "encode_world_info": [
    "world_info"
  ],
  "run_autotuning": [
    "args",
    "active_resources"
  ],
  "parse_num_nodes": [
    "str_num_nodes",
    "elastic_training"
  ],
  "DS_INFERENCE_ENABLED": [],
  "INFERENCE_MODEL_TIMER": [],
  "InferenceEngine": {
    "inference_mp_group": [],
    "inference_ep_group": [],
    "expert_mp_group": [],
    "__init__": [
      "self",
      "model",
      "config"
    ],
    "destroy": [
      "self"
    ],
    "profile_model_time": [
      "self",
      "use_cuda_events"
    ],
    "_get_model_config_generate": [
      "self",
      "config"
    ],
    "remove_mask_prepare_for_bloom": [
      "self"
    ],
    "build_alibi_tensor": [
      "self"
    ],
    "build_attn_bias": [
      "self"
    ],
    "_pre_forward_hook": [
      "self",
      "module"
    ],
    "_post_forward_hook": [
      "self",
      "module",
      "input",
      "output"
    ],
    "_create_model_parallel_group": [
      "self",
      "config"
    ],
    "_create_ep_parallel_group": [
      "self",
      "moe_experts"
    ],
    "_init_quantization_setting": [
      "self",
      "quantization_setting"
    ],
    "load_model_with_checkpoint": [
      "self",
      "r_module"
    ],
    "_apply_injection_policy": [
      "self",
      "config",
      "client_module"
    ],
    "_get_all_ckpt_names": [
      "self",
      "checkpoints_path",
      "tag"
    ],
    "_get_ckpt_name": [
      "self",
      "checkpoints_path",
      "tag",
      "mp_placeholder"
    ],
    "_load_checkpoint": [
      "self",
      "load_dir",
      "load_module_strict",
      "tag"
    ],
    "_choose_module_key": [
      "self",
      "sd"
    ],
    "_convert_to_dtype": [
      "self",
      "config"
    ],
    "_create_cuda_graph": [
      "self"
    ],
    "_graph_replay": [
      "self"
    ],
    "model_times": [
      "self"
    ],
    "_module_match": [
      "self",
      "module"
    ],
    "_local_cuda_graph_used": [
      "self",
      "module"
    ],
    "forward": [
      "self"
    ],
    "_generate": [
      "self"
    ],
    "compile": [
      "self",
      "backend",
      "compile_kwargs"
    ],
    "is_compiled": [
      "self"
    ]
  },
  "DtypeEnum": {
    "fp16": [],
    "fp32": [],
    "bf16": [],
    "int8": [],
    "from_str": [
      "cls",
      "value"
    ]
  },
  "MoETypeEnum": {
    "residual": [],
    "standard": []
  },
  "DeepSpeedTPConfig": {},
  "DeepSpeedMoEConfig": {},
  "QuantTypeEnum": {
    "asym": [],
    "sym": []
  },
  "BaseQuantConfig": {},
  "WeightQuantConfig": {},
  "ActivationQuantConfig": {},
  "QKVQuantConfig": {},
  "QuantizationConfig": {},
  "InferenceCheckpointConfig": {},
  "SchedulingResult": {
    "Success": [],
    "EngineSequenceLimitExceeded": [],
    "BatchSequenceLimitExceeded": [],
    "BatchTokenLimitExceeded": [],
    "KVCacheLimitExceeded": [],
    "SequenceTokenLimitExceeded": []
  },
  "SchedulingError": {
    "__init__": [
      "self",
      "result"
    ]
  },
  "RaggedInferenceEngineConfig": {},
  "CORE_PARAM": [],
  "STR_TO_DTYPE": [],
  "InferenceParameter": {
    "__new__": [
      "cls",
      "tensor"
    ],
    "to": [
      "self"
    ],
    "initialize": [
      "cls",
      "core_param"
    ],
    "initialize_raw": [
      "self"
    ],
    "aux_attrs": [
      "self"
    ]
  },
  "InferenceEngineV2": {
    "free_blocks": [
      "self"
    ],
    "n_kv_cache_groups": [
      "self"
    ],
    "model": [
      "self"
    ],
    "__init__": [
      "self",
      "policy",
      "engine_config"
    ],
    "_initialize_tp_group": [
      "self"
    ],
    "put": [
      "self",
      "batch_uids",
      "batch_tokens",
      "do_checks"
    ],
    "query": [
      "self",
      "uid",
      "max_request_tokens",
      "max_request_blocks"
    ],
    "can_schedule": [
      "self",
      "uids",
      "lengths"
    ],
    "get_remaining_block_capacity": [
      "self",
      "uid"
    ],
    "flush": [
      "self",
      "uid"
    ],
    "serialize": [
      "self",
      "save_path"
    ]
  },
  "Allocator": {
    "cache": [],
    "empty_from": [
      "tensor",
      "shape"
    ]
  },
  "empty_from": [],
  "on_device": [
    "method"
  ],
  "inf_logger": [],
  "inference_logger": [
    "level"
  ],
  "build_engine_from_ds_checkpoint": [
    "path",
    "engine_config",
    "debug_level"
  ],
  "build_hf_engine": [
    "path",
    "engine_config",
    "debug_level"
  ],
  "NormTypeEnum": {},
  "ActivationType": {
    "GELU": [],
    "RELU": [],
    "SILU": [],
    "GEGLU": [],
    "ReGLU": [],
    "SiGLU": [],
    "IDENTITY": [],
    "InvalidType": []
  },
  "is_gated": [
    "act_fn"
  ],
  "elem_size": [
    "dtype"
  ],
  "ceil_div": [
    "a",
    "b"
  ],
  "DSKernelBase": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "CUDABiasActivation": {
    "supported_dtypes": [],
    "supported_act_fns": [],
    "__init__": [
      "self",
      "channels",
      "dtype",
      "act_fn"
    ],
    "__call__": [
      "self",
      "activation",
      "bias"
    ]
  },
  "CUDARMSNormBase": {
    "supported_dtypes": [],
    "__init__": [
      "self",
      "channels",
      "fp_dtype",
      "epsilon"
    ]
  },
  "CUDARMSNorm": {
    "__call__": [
      "self",
      "output_z",
      "input_x",
      "gamma"
    ]
  },
  "CUDARMSPreNorm": {
    "__call__": [
      "self",
      "z_res",
      "z_hid",
      "x_res",
      "y_hid",
      "gamma"
    ]
  },
  "BlasLibLinear": {
    "supported_dtypes": [],
    "__init__": [
      "self",
      "fp_dtype"
    ],
    "__call__": [
      "self",
      "output",
      "hidden_states",
      "weights"
    ]
  },
  "CUDAGatedActivation": {
    "supported_dtypes": [],
    "supported_act_fns": [],
    "__init__": [
      "self",
      "channels",
      "fp_dtype",
      "act_fn"
    ],
    "__call__": [
      "self",
      "output",
      "input",
      "bias"
    ]
  },
  "CUDAFPLNBase": {
    "supported_dtypes": [],
    "__init__": [
      "self",
      "channels",
      "fp_dtype",
      "epsilon"
    ]
  },
  "CUDAFPPostLN": {
    "__call__": [
      "self",
      "output_z",
      "input_x",
      "input_y",
      "gamma",
      "beta"
    ]
  },
  "CUDAFPLN": {
    "__call__": [
      "self",
      "output_z",
      "input_x",
      "gamma",
      "beta"
    ]
  },
  "CUDAFPPreLN": {
    "__call__": [
      "self",
      "z_res",
      "z_hid",
      "x_res",
      "y_hid",
      "gamma",
      "beta"
    ]
  },
  "CUDAWf6Af16Linear": {
    "supported_dtypes": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "output",
      "hidden_states",
      "weights_2bit",
      "weights_4bit",
      "scale",
      "out_channels",
      "tokens",
      "in_channels"
    ],
    "get_workspace": [
      "self",
      "out_channels",
      "tokens",
      "in_channels",
      "split_k",
      "dtype",
      "device"
    ]
  },
  "MoEScatter": {
    "supported_dtypes": [],
    "__init__": [
      "self",
      "dtype",
      "channels"
    ],
    "__call__": [
      "self",
      "moe_input",
      "expert_cumsum",
      "mapped_slots",
      "activations",
      "expert_counts",
      "assignments",
      "offsets"
    ]
  },
  "RaggedLogitsGather": {
    "supported_dtypes": [],
    "__init__": [
      "self",
      "model_dim",
      "fp_dtype"
    ],
    "__call__": [
      "self",
      "final_token_activations",
      "all_activations",
      "ragged_wrapper"
    ]
  },
  "AtomBuilder": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "atoms",
      "ragged_batch",
      "q_block_size",
      "kv_block_size"
    ]
  },
  "RaggedEmbeddingKernel": {
    "supported_dtypes": [],
    "supported_token_dtypes": [],
    "__init__": [
      "self",
      "embed_dtype",
      "token_dtype",
      "embed_dim"
    ],
    "__call__": [
      "self",
      "embedded_tokens",
      "ragged_wrapper",
      "embedding_weight",
      "position_embed_weight",
      "position_embed_offset"
    ]
  },
  "get_q_block_size": [
    "head_size"
  ],
  "get_kv_block_size": [
    "head_size"
  ],
  "BlockedFlashAttn": {
    "supported_dtypes": [],
    "__init__": [
      "self",
      "head_size",
      "dtype"
    ],
    "__call__": [
      "self",
      "out",
      "q",
      "k",
      "v",
      "atoms",
      "softmax_scale"
    ]
  },
  "RaggedTopKGating": {
    "supported_logit_dtypes": [],
    "__init__": [
      "self",
      "logit_dtype"
    ],
    "__call__": [
      "self",
      "expert_counts",
      "scores",
      "assignments",
      "offsets",
      "logits",
      "batch"
    ]
  },
  "LinearBlockedKVCopy": {
    "supported_dtypes": [],
    "supported_head_sizes": [],
    "supported_q_ratios": [],
    "__init__": [
      "self",
      "head_size",
      "n_q_heads",
      "n_kv_heads",
      "dtype"
    ],
    "__call__": [
      "self",
      "kv_cache",
      "qkv",
      "ragged_batch"
    ]
  },
  "BlockedTrainedRotaryEmbeddings": {
    "supported_dtypes": [],
    "supported_head_sizes": [],
    "supported_q_ratios": [],
    "__init__": [
      "self",
      "head_size",
      "n_q_heads",
      "n_kv_heads",
      "dtype"
    ],
    "__call__": [
      "self",
      "kv_cache",
      "qkv",
      "ragged_batch",
      "inverse_freqs"
    ]
  },
  "BlockedRotaryEmbeddings": {
    "supported_dtypes": [],
    "supported_head_sizes": [],
    "supported_q_ratios": [],
    "__init__": [
      "self",
      "head_size",
      "n_q_heads",
      "n_kv_heads",
      "dtype",
      "rotary_dim",
      "theta_base"
    ],
    "__call__": [
      "self",
      "kv_cache",
      "qkv",
      "ragged_batch"
    ]
  },
  "MoEGather": {
    "supported_dtypes": [],
    "__init__": [
      "self",
      "dtype",
      "channels",
      "normalize_scores"
    ],
    "__call__": [
      "self",
      "layer_output",
      "moe_output",
      "scores",
      "mapped_slots",
      "expert_counts"
    ]
  },
  "MoEGEMM": {
    "supported_dtypes": [],
    "supported_act_fns": [],
    "__init__": [
      "self",
      "fp_dtype",
      "act_fn"
    ],
    "__call__": [
      "self",
      "ordered_output",
      "ordered_input",
      "weights",
      "total_rows_before_expert",
      "biases"
    ]
  },
  "MixedMoEGEMM": {
    "supported_dtypes": [],
    "supported_act_fns": [],
    "__init__": [
      "self",
      "fp_dtype",
      "act_fn",
      "num_bits"
    ],
    "__call__": [
      "self",
      "ordered_output",
      "ordered_input",
      "weights",
      "scales",
      "total_rows_before_expert",
      "biases"
    ]
  },
  "MixedGEMM": {
    "supported_dtypes": [],
    "supported_act_fns": [],
    "__init__": [
      "self",
      "fp_dtype",
      "act_fn",
      "num_bits"
    ],
    "__call__": [
      "self",
      "output",
      "hidden_states",
      "weights",
      "scales",
      "biases"
    ]
  },
  "pad_to_aligned_offset": [
    "offset",
    "alignment"
  ],
  "ParameterMetadata": {},
  "LayerMetadata": {},
  "ModelMetadata": {},
  "make_param_filename": [
    "base",
    "rank",
    "n_ranks"
  ],
  "make_metadata_filename": [
    "base",
    "rank",
    "n_ranks"
  ],
  "make_model_config_filename": [
    "base"
  ],
  "flatten_inference_model": [
    "transformer_containers",
    "non_transformer_container",
    "policy_name"
  ],
  "restore_inference_model": [
    "buffer",
    "metadata",
    "transformer_containers",
    "non_transformer_container"
  ],
  "InferenceModel": [],
  "LayerContainer": [],
  "MAPPING_KEY": [],
  "make_param_getter": [
    "clsname",
    "param"
  ],
  "make_param_setter": [
    "clsname",
    "param"
  ],
  "make_readonly_setter": [],
  "ParameterMetaclass": {
    "__new__": [
      "cls",
      "clsname",
      "bases",
      "attrs"
    ],
    "__call__": [
      "cls"
    ]
  },
  "ParameterBase": {
    "__init__": [
      "self",
      "model",
      "parent_container"
    ],
    "finalize": [
      "self"
    ],
    "complete_component": [
      "self"
    ]
  },
  "ParametrizedList": {
    "__init__": [
      "self",
      "param",
      "n_params"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__setitem__": [
      "self",
      "index",
      "value"
    ],
    "__iter__": [
      "self"
    ]
  },
  "ParamList": [
    "attr"
  ],
  "POLICIES": [],
  "ContainerMap": {
    "__init__": [
      "self"
    ],
    "transformer_params": [
      "self"
    ],
    "non_transformer_params": [
      "self"
    ],
    "set_transformer_params": [
      "self",
      "prefixes",
      "containers"
    ],
    "set_non_transformer_params": [
      "self",
      "container"
    ],
    "set_unmapped_params": [
      "self",
      "prefixes"
    ],
    "map_param": [
      "self",
      "name",
      "parameter"
    ],
    "validate": [
      "self"
    ]
  },
  "PolicyMeta": {
    "__new__": [
      "cls",
      "name",
      "bases",
      "dct"
    ]
  },
  "InferenceV2Policy": {
    "__init__": [
      "self",
      "model_config",
      "checkpoint_engine",
      "inf_checkpoint_path"
    ],
    "build_model": [
      "self",
      "engine_config",
      "mp_group"
    ],
    "instantiate_model": [
      "self",
      "engine_config"
    ],
    "build_container_map": [
      "self"
    ],
    "populate_model_parameters": [
      "self"
    ]
  },
  "DSModelImplementationConfig": [],
  "MPType": [],
  "DSInferenceModelBase": {
    "__init__": [
      "self",
      "config",
      "engine_config",
      "base_mp_group"
    ],
    "config": [
      "self"
    ],
    "set_parameters": [
      "self",
      "transformer",
      "non_transformer",
      "flattened_param_buffer",
      "flattened_param_metadata"
    ],
    "set_state_manager": [
      "self",
      "state_manager"
    ],
    "tp_rank": [
      "self"
    ],
    "tp_size": [
      "self"
    ],
    "model_config": [
      "self"
    ],
    "engine_config": [
      "self"
    ],
    "flattened_params": [
      "self"
    ],
    "flattened_param_metadata": [
      "self"
    ],
    "get_kv_requirements": [
      "self",
      "sequence",
      "max_new_tokens",
      "max_new_blocks"
    ],
    "get_remaining_block_capacity": [
      "self",
      "sequence"
    ],
    "maybe_allocate_kv": [
      "self",
      "sequence",
      "n_new_tokens"
    ],
    "kv_cache_config": [
      "self"
    ],
    "max_sequence_length": [
      "self"
    ],
    "maybe_free_kv": [
      "self",
      "sequence"
    ],
    "prepare_batch": [
      "self",
      "wrapped_batch"
    ],
    "forward": [
      "wrapped_batch"
    ]
  },
  "DSTransformerModelBase": {
    "num_layers": [
      "self"
    ],
    "model_dim": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "head_size": [
      "self"
    ],
    "n_heads": [
      "self"
    ],
    "n_heads_q": [
      "self"
    ],
    "n_heads_kv": [
      "self"
    ],
    "intermediate_dim": [
      "self"
    ],
    "positional_embedding_type": [
      "self"
    ],
    "activation_dtype": [
      "self"
    ],
    "mlp_activation_fn": [
      "self"
    ],
    "norm_type": [
      "self"
    ],
    "positional_embedding_config": [
      "self"
    ],
    "n_heads_q_local": [
      "self"
    ],
    "n_heads_kv_local": [
      "self"
    ],
    "gated_mlp": [
      "self"
    ],
    "__init__": [
      "self",
      "config",
      "engine_config",
      "base_mp_group"
    ],
    "make_embedding_layer": [
      "self"
    ],
    "transform_embedding_param": [
      "self",
      "param"
    ],
    "make_unembedding_layer": [
      "self"
    ],
    "transform_unembed_param": [
      "self",
      "param"
    ],
    "make_qkv_layer": [
      "self"
    ],
    "transform_qkv_param": [
      "self",
      "param"
    ],
    "make_attn_layer": [
      "self"
    ],
    "get_kv_requirements": [
      "self",
      "sequence",
      "max_new_tokens",
      "max_new_blocks"
    ],
    "get_remaining_block_capacity": [
      "self",
      "sequence"
    ],
    "maybe_allocate_kv": [
      "self",
      "sequence",
      "n_new_tokens"
    ],
    "kv_cache_config": [
      "self"
    ],
    "prepare_batch": [
      "self",
      "wrapped_batch"
    ],
    "make_attn_out_layer": [
      "self"
    ],
    "transform_attn_out_param": [
      "self",
      "param"
    ],
    "make_mlp_1_layer": [
      "self"
    ],
    "transform_mlp_1_param": [
      "self",
      "param"
    ],
    "make_mlp_2_layer": [
      "self"
    ],
    "transform_mlp_2_param": [
      "self",
      "param"
    ],
    "make_norm_layer": [
      "self"
    ],
    "transform_norm_param": [
      "self",
      "param"
    ]
  },
  "DSMoETransformerModelBase": {
    "n_experts": [
      "self"
    ],
    "n_top_k": [
      "self"
    ],
    "normalize_expert_scores": [
      "self"
    ],
    "make_moe_layer": [
      "self"
    ],
    "transform_moe_gate_param": [
      "self",
      "param"
    ],
    "transform_moe_mlp_1_param": [
      "self",
      "param"
    ],
    "transform_moe_mlp_2_param": [
      "self",
      "param"
    ]
  },
  "PLIST_HELPERS": [],
  "make_finalization_callback": [
    "all_names"
  ],
  "LayerMetaclass": {
    "__new__": [
      "cls",
      "clsname",
      "bases",
      "attrs"
    ],
    "__call__": [
      "cls"
    ]
  },
  "Qwen2MoeTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "Qwen2MoeNonTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "Qwen2MoePolicy": {
    "instantiate_model": [
      "self",
      "engine_config",
      "mp_group"
    ],
    "build_container_map": [
      "self"
    ]
  },
  "Qwen2MoeInferenceModel": {
    "max_sequence_length": [
      "self"
    ],
    "num_layers": [
      "self"
    ],
    "model_dim": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "head_size": [
      "self"
    ],
    "n_heads": [
      "self"
    ],
    "intermediate_dim": [
      "self"
    ],
    "n_heads_kv": [
      "self"
    ],
    "activation_dtype": [
      "self"
    ],
    "mlp_activation_fn": [
      "self"
    ],
    "norm_type": [
      "self"
    ],
    "positional_embedding_type": [
      "self"
    ],
    "positional_embedding_config": [
      "self"
    ],
    "n_experts": [
      "self"
    ],
    "n_top_k": [
      "self"
    ],
    "normalize_expert_scores": [
      "self"
    ],
    "make_moe_layer": [
      "self"
    ],
    "make_shared_expert_mlp_1_layer": [
      "self"
    ],
    "make_shared_expert_mlp_2_layer": [
      "self"
    ],
    "make_shared_expert_gate_layer": [
      "self"
    ],
    "make_norm_layer": [
      "self"
    ],
    "__init__": [
      "self",
      "config",
      "engine_config",
      "base_mp_group"
    ],
    "_forward_embed": [
      "self",
      "ragged_batch"
    ],
    "_forward_transformer": [
      "self",
      "layer_idx",
      "residual",
      "hidden_states",
      "ragged_batch_info"
    ],
    "_forward_unembed": [
      "self",
      "hidden_states",
      "ragged_batch_info"
    ],
    "forward": [
      "self",
      "wrapped_batch"
    ]
  },
  "QwenTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "QwenNonTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "QwenPolicy": {
    "instantiate_model": [
      "self",
      "engine_config",
      "mp_group"
    ],
    "build_container_map": [
      "self"
    ]
  },
  "QwenInferenceModel": {
    "max_sequence_length": [
      "self"
    ],
    "num_layers": [
      "self"
    ],
    "model_dim": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "head_size": [
      "self"
    ],
    "n_heads": [
      "self"
    ],
    "intermediate_dim": [
      "self"
    ],
    "n_heads_kv": [
      "self"
    ],
    "activation_dtype": [
      "self"
    ],
    "mlp_activation_fn": [
      "self"
    ],
    "norm_type": [
      "self"
    ],
    "positional_embedding_type": [
      "self"
    ],
    "positional_embedding_config": [
      "self"
    ],
    "make_norm_layer": [
      "self"
    ],
    "_forward_embed": [
      "self",
      "ragged_batch"
    ],
    "_forward_transformer_layer": [
      "self",
      "layer_idx",
      "residual",
      "hidden_states",
      "ragged_batch_info"
    ],
    "_forward_unembed": [
      "self",
      "hidden_states",
      "ragged_batch_info"
    ],
    "forward": [
      "self",
      "wrapped_batch"
    ]
  },
  "Qwen2TransformerContainer": {
    "PARAM_MAPPING": []
  },
  "Qwen2NonTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "Qwen2Policy": {
    "instantiate_model": [
      "self",
      "engine_config",
      "mp_group"
    ],
    "build_container_map": [
      "self"
    ]
  },
  "Qwen2InferenceModel": {
    "max_sequence_length": [
      "self"
    ],
    "num_layers": [
      "self"
    ],
    "model_dim": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "head_size": [
      "self"
    ],
    "n_heads": [
      "self"
    ],
    "intermediate_dim": [
      "self"
    ],
    "n_heads_kv": [
      "self"
    ],
    "activation_dtype": [
      "self"
    ],
    "mlp_activation_fn": [
      "self"
    ],
    "norm_type": [
      "self"
    ],
    "positional_embedding_type": [
      "self"
    ],
    "positional_embedding_config": [
      "self"
    ],
    "make_norm_layer": [
      "self"
    ],
    "_forward_embed": [
      "self",
      "ragged_batch"
    ],
    "_forward_transformer_layer": [
      "self",
      "layer_idx",
      "residual",
      "hidden_states",
      "ragged_batch_info"
    ],
    "_forward_unembed": [
      "self",
      "hidden_states",
      "ragged_batch_info"
    ],
    "forward": [
      "self",
      "wrapped_batch"
    ]
  },
  "MistralTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "MistralNonTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "MistralPolicy": {
    "instantiate_model": [
      "self",
      "engine_config",
      "mp_group"
    ],
    "build_container_map": [
      "self"
    ]
  },
  "MistralInferenceModel": {
    "max_sequence_length": [
      "self"
    ],
    "num_layers": [
      "self"
    ],
    "model_dim": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "head_size": [
      "self"
    ],
    "n_heads": [
      "self"
    ],
    "intermediate_dim": [
      "self"
    ],
    "n_heads_kv": [
      "self"
    ],
    "activation_dtype": [
      "self"
    ],
    "mlp_activation_fn": [
      "self"
    ],
    "norm_type": [
      "self"
    ],
    "positional_embedding_type": [
      "self"
    ],
    "positional_embedding_config": [
      "self"
    ],
    "_forward_embed": [
      "self",
      "ragged_batch"
    ],
    "_forward_transformer": [
      "self",
      "layer_idx",
      "residual",
      "hidden_states",
      "ragged_batch_info"
    ],
    "_forward_unembed": [
      "self",
      "hidden_states",
      "ragged_batch_info"
    ],
    "forward": [
      "self",
      "wrapped_batch"
    ]
  },
  "PhiTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "PhiNonTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "PhiPolicy": {
    "instantiate_model": [
      "self",
      "engine_config",
      "mp_group"
    ],
    "build_container_map": [
      "self"
    ]
  },
  "PhiInferenceModel": {
    "max_sequence_length": [
      "self"
    ],
    "num_layers": [
      "self"
    ],
    "model_dim": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "head_size": [
      "self"
    ],
    "n_heads": [
      "self"
    ],
    "intermediate_dim": [
      "self"
    ],
    "n_heads_kv": [
      "self"
    ],
    "activation_dtype": [
      "self"
    ],
    "mlp_activation_fn": [
      "self"
    ],
    "norm_type": [
      "self"
    ],
    "positional_embedding_type": [
      "self"
    ],
    "positional_embedding_config": [
      "self"
    ],
    "_forward_embed": [
      "self",
      "ragged_batch"
    ],
    "_forward_transformer_layer": [
      "self",
      "layer_idx",
      "residual",
      "hidden_states",
      "ragged_batch_info"
    ],
    "_forward_unembed": [
      "self",
      "hidden_states",
      "ragged_batch_info"
    ],
    "forward": [
      "self",
      "wrapped_batch"
    ]
  },
  "shard_attn_out_param": [
    "param",
    "shard_rank",
    "num_shards",
    "head_size",
    "n_heads_q",
    "n_heads_kv"
  ],
  "attn_out_in_features": [
    "out_features",
    "shard_rank",
    "num_shards",
    "head_size",
    "n_heads_q",
    "n_heads_kv"
  ],
  "shard_embedding_param": [
    "param",
    "shard_rank",
    "num_shards"
  ],
  "sharded_embedding_dim": [
    "embedding_size",
    "shard_rank",
    "num_shards"
  ],
  "get_shard_endpoints": [
    "dim_size",
    "shard_rank",
    "num_shards",
    "granularity"
  ],
  "shard_param": [
    "param",
    "shard_mode",
    "shard_rank",
    "num_shards",
    "num_concatenated_matrices",
    "granularity",
    "bias_dims"
  ],
  "shard_mlp_1_param": [
    "param",
    "shard_rank",
    "num_shards",
    "gated",
    "is_moe"
  ],
  "shard_mlp_2_param": [
    "param",
    "shard_rank",
    "num_shards",
    "is_moe"
  ],
  "sharded_intermediate_dim": [
    "intermediate_size",
    "num_shards",
    "shard_rank"
  ],
  "shard_qkv_param": [
    "param",
    "shard_rank",
    "num_shards",
    "head_size",
    "n_heads_q",
    "n_heads_kv"
  ],
  "qkv_out_features": [
    "in_features",
    "shard_rank",
    "num_shards",
    "head_size",
    "n_heads_q",
    "n_heads_kv"
  ],
  "get_local_heads": [
    "shard_rank",
    "num_shards",
    "n_heads_q",
    "n_heads_kv"
  ],
  "DEFAULT_SHARD_GRANULARITY": [],
  "ShardingType": {
    "INNER_DIMENSION": [],
    "OUTER_DIMENSION": []
  },
  "shard_unembed_param": [
    "param",
    "shard_rank",
    "num_shards"
  ],
  "sharded_unembed_dim": [
    "vocab_size",
    "shard_rank",
    "num_shards"
  ],
  "Llama2TransformerContainer": {
    "PARAM_MAPPING": []
  },
  "Llama2NonTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "Llama2Policy": {
    "instantiate_model": [
      "self",
      "engine_config",
      "mp_group"
    ],
    "build_container_map": [
      "self"
    ]
  },
  "Llama2InferenceModel": {
    "max_sequence_length": [
      "self"
    ],
    "num_layers": [
      "self"
    ],
    "model_dim": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "head_size": [
      "self"
    ],
    "n_heads": [
      "self"
    ],
    "intermediate_dim": [
      "self"
    ],
    "n_heads_kv": [
      "self"
    ],
    "activation_dtype": [
      "self"
    ],
    "mlp_activation_fn": [
      "self"
    ],
    "norm_type": [
      "self"
    ],
    "positional_embedding_type": [
      "self"
    ],
    "positional_embedding_config": [
      "self"
    ],
    "_forward_embed": [
      "self",
      "ragged_batch"
    ],
    "_forward_transformer_layer": [
      "self",
      "layer_idx",
      "residual",
      "hidden_states",
      "ragged_batch_info"
    ],
    "_forward_unembed": [
      "self",
      "hidden_states",
      "ragged_batch_info"
    ],
    "forward": [
      "self",
      "wrapped_batch"
    ]
  },
  "FalconTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "FalconNonTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "FalconNewArchTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "FalconPolicy": {
    "instantiate_model": [
      "self",
      "engine_config",
      "mp_group"
    ],
    "build_container_map": [
      "self"
    ]
  },
  "FalconInferenceModel": {
    "max_sequence_length": [
      "self"
    ],
    "num_layers": [
      "self"
    ],
    "model_dim": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "head_size": [
      "self"
    ],
    "n_heads": [
      "self"
    ],
    "intermediate_dim": [
      "self"
    ],
    "n_heads_kv": [
      "self"
    ],
    "activation_dtype": [
      "self"
    ],
    "mlp_activation_fn": [
      "self"
    ],
    "norm_type": [
      "self"
    ],
    "positional_embedding_type": [
      "self"
    ],
    "positional_embedding_config": [
      "self"
    ],
    "_forward_embed": [
      "self",
      "ragged_batch"
    ],
    "_forward_transformer_layer": [
      "self",
      "layer_idx",
      "residual",
      "hidden_states",
      "ragged_batch_info"
    ],
    "_forward_unembed": [
      "self",
      "hidden_states",
      "ragged_batch_info"
    ],
    "forward": [
      "self",
      "wrapped_batch"
    ]
  },
  "OPTTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "OPTNonTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "OPTPolicy": {
    "instantiate_model": [
      "self",
      "engine_config",
      "mp_group"
    ],
    "build_container_map": [
      "self"
    ]
  },
  "OPTInferenceModel": {
    "max_sequence_length": [
      "self"
    ],
    "num_layers": [
      "self"
    ],
    "model_dim": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "head_size": [
      "self"
    ],
    "n_heads": [
      "self"
    ],
    "intermediate_dim": [
      "self"
    ],
    "activation_dtype": [
      "self"
    ],
    "mlp_activation_fn": [
      "self"
    ],
    "norm_type": [
      "self"
    ],
    "positional_embedding_type": [
      "self"
    ],
    "positional_embedding_config": [
      "self"
    ],
    "make_embedding_layer": [
      "self"
    ],
    "_forward_embed": [
      "self",
      "ragged_batch"
    ],
    "_forward_transformer_layer": [
      "self",
      "layer_idx",
      "residual",
      "hidden_states",
      "ragged_batch_info"
    ],
    "_forward_unembed": [
      "self",
      "hidden_states",
      "ragged_batch_info"
    ],
    "forward": [
      "self",
      "wrapped_batch"
    ]
  },
  "Phi3TransformerContainer": {
    "PARAM_MAPPING": []
  },
  "Phi3NonTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "Phi3Policy": {
    "instantiate_model": [
      "self",
      "engine_config",
      "mp_group"
    ],
    "build_container_map": [
      "self"
    ]
  },
  "Phi3InferenceModel": {
    "max_sequence_length": [
      "self"
    ],
    "num_layers": [
      "self"
    ],
    "model_dim": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "head_size": [
      "self"
    ],
    "n_heads": [
      "self"
    ],
    "intermediate_dim": [
      "self"
    ],
    "n_heads_kv": [
      "self"
    ],
    "activation_dtype": [
      "self"
    ],
    "mlp_activation_fn": [
      "self"
    ],
    "norm_type": [
      "self"
    ],
    "positional_embedding_type": [
      "self"
    ],
    "positional_embedding_config": [
      "self"
    ],
    "_forward_embed": [
      "self",
      "ragged_batch"
    ],
    "_forward_transformer_layer": [
      "self",
      "layer_idx",
      "residual",
      "hidden_states",
      "ragged_batch_info"
    ],
    "_forward_unembed": [
      "self",
      "hidden_states",
      "ragged_batch_info"
    ],
    "forward": [
      "self",
      "wrapped_batch"
    ]
  },
  "MixtralTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "MixtralNonTransformerContainer": {
    "PARAM_MAPPING": []
  },
  "MixtralPolicy": {
    "instantiate_model": [
      "self",
      "engine_config",
      "mp_group"
    ],
    "build_container_map": [
      "self"
    ]
  },
  "MixtralInferenceModel": {
    "max_sequence_length": [
      "self"
    ],
    "num_layers": [
      "self"
    ],
    "model_dim": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "head_size": [
      "self"
    ],
    "n_heads": [
      "self"
    ],
    "intermediate_dim": [
      "self"
    ],
    "n_heads_kv": [
      "self"
    ],
    "activation_dtype": [
      "self"
    ],
    "mlp_activation_fn": [
      "self"
    ],
    "norm_type": [
      "self"
    ],
    "positional_embedding_type": [
      "self"
    ],
    "positional_embedding_config": [
      "self"
    ],
    "n_experts": [
      "self"
    ],
    "n_top_k": [
      "self"
    ],
    "normalize_expert_scores": [
      "self"
    ],
    "__init__": [
      "self",
      "config",
      "engine_config",
      "base_mp_group"
    ],
    "_forward_embed": [
      "self",
      "ragged_batch"
    ],
    "_forward_transformer": [
      "self",
      "layer_idx",
      "residual",
      "hidden_states",
      "ragged_batch_info"
    ],
    "_forward_unembed": [
      "self",
      "hidden_states",
      "ragged_batch_info"
    ],
    "forward": [
      "self",
      "wrapped_batch"
    ]
  },
  "FusedQKVParameter": {
    "finalize": [
      "self"
    ]
  },
  "UnfusedQKVParameter": {
    "finalize": [
      "self"
    ]
  },
  "megatron_qkv_reshape": [
    "param",
    "head_size",
    "n_heads"
  ],
  "MegatronQKVParameter": {
    "finalize": [
      "self"
    ]
  },
  "transform_gqa_megatron": [
    "src_param",
    "head_size",
    "n_q_heads",
    "n_kv_heads"
  ],
  "GQAMegatronQKVParameter": {
    "finalize": [
      "self"
    ]
  },
  "MLP1Parameter": {
    "finalize": [
      "self"
    ]
  },
  "GatedMLPParameter": {
    "finalize": [
      "self"
    ]
  },
  "FusedGatedMLPParameter": {
    "finalize": [
      "self"
    ]
  },
  "MLP2Parameter": {
    "finalize": [
      "self"
    ]
  },
  "InvFreqParameter": {
    "finalize": [
      "self"
    ]
  },
  "MoEGatingWeightParameter": {
    "finalize": [
      "self"
    ]
  },
  "UnfusedMoEMLP1Parameter": {
    "finalize": [
      "self"
    ]
  },
  "UnfusedMoEMLP2Parameter": {
    "finalize": [
      "self"
    ]
  },
  "UnfusedMoEGatedMLPParameter": {
    "finalize": [
      "self"
    ]
  },
  "AttentionOutputParameter": {
    "finalize": [
      "self"
    ]
  },
  "UnembedParameter": {
    "finalize": [
      "self"
    ]
  },
  "NormParameter": {
    "finalize": [
      "self"
    ]
  },
  "EmbeddingParameter": {
    "finalize": [
      "self"
    ]
  },
  "split_kv": [
    "kv_cache"
  ],
  "BlockedKVCache": {
    "__init__": [
      "self",
      "configs",
      "memory_config",
      "mp_group",
      "offload"
    ],
    "reserve": [
      "self",
      "num_blocks",
      "cache_group"
    ],
    "free": [
      "self",
      "blocks",
      "cache_group"
    ],
    "offload": [
      "self",
      "blocks",
      "cache_group"
    ],
    "restore": [
      "self",
      "blocks",
      "cache_group"
    ],
    "get_cache": [
      "self",
      "cache_id",
      "cache_group"
    ],
    "free_blocks": [
      "self"
    ],
    "num_caches": [
      "self"
    ]
  },
  "BaseSequenceDescriptor": {
    "seen_tokens": [
      "self"
    ],
    "cur_allocated_blocks": [
      "self",
      "cache_group"
    ],
    "kv_blocks_ptr": [
      "self",
      "cache_group"
    ]
  },
  "PlaceholderSequenceDescriptor": {
    "__init__": [
      "self",
      "seen_tokens",
      "cur_allocated_blocks",
      "kv_blocks_ptr"
    ],
    "seen_tokens": [
      "self"
    ],
    "cur_allocated_blocks": [
      "self",
      "cache_group"
    ],
    "kv_blocks_ptr": [
      "self",
      "cache_group"
    ]
  },
  "DSSequenceDescriptor": {
    "__init__": [
      "self",
      "tracking_id",
      "kv_cache_ids",
      "kv_cache_ids_shadow",
      "max_context"
    ],
    "seen_tokens": [
      "self"
    ],
    "in_flight_tokens": [
      "self"
    ],
    "max_context": [
      "self"
    ],
    "tracking_id": [
      "self"
    ],
    "cur_allocated_blocks": [
      "self",
      "cache_group"
    ],
    "kv_cache_ids": [
      "self",
      "cache_group",
      "on_device"
    ],
    "kv_blocks_ptr": [
      "self",
      "cache_group"
    ],
    "all_block_ids": [
      "self",
      "cache_group"
    ],
    "pre_forward": [
      "self",
      "num_tokens"
    ],
    "post_forward": [
      "self"
    ],
    "extend_kv_cache": [
      "self",
      "new_ids",
      "cache_group"
    ],
    "free_kv_cache": [
      "self",
      "free_ids",
      "cache_group"
    ]
  },
  "to_padded": [
    "original_size"
  ],
  "RaggedBatchWrapper": {
    "__init__": [
      "self",
      "config"
    ],
    "clear": [
      "self"
    ],
    "insert_sequence": [
      "self",
      "seq_descriptor",
      "tokens",
      "do_checks"
    ],
    "tensor_toks": [
      "self"
    ],
    "finalize": [
      "self",
      "padding"
    ],
    "input_ids": [
      "self",
      "on_device"
    ],
    "batch_metadata_buffer": [
      "self",
      "on_device"
    ],
    "tokens_to_seq": [
      "self",
      "on_device"
    ],
    "inflight_seq_descriptors": [
      "self",
      "on_device"
    ],
    "kv_ptrs": [
      "self",
      "on_device"
    ],
    "masks": [
      "self",
      "on_device"
    ],
    "current_tokens": [
      "self"
    ],
    "current_sequences": [
      "self"
    ]
  },
  "KVCacheType": {
    "DENSE": [],
    "LOCAL": []
  },
  "KVCacheConfig": {},
  "AllocationMode": {
    "RESERVE": [],
    "ALLOCATE": []
  },
  "MemoryConfig": {},
  "DSStateManagerConfig": {
    "max_ragged_sequence_count_validator": [
      "self"
    ]
  },
  "DSStateManager": {
    "__init__": [
      "self",
      "config",
      "kv_configs",
      "base_mp_group"
    ],
    "get_cache": [
      "self",
      "cache_id",
      "cache_group"
    ],
    "flush_sequence": [
      "self",
      "uid"
    ],
    "get_sequence": [
      "self",
      "uid"
    ],
    "get_or_create_sequence": [
      "self",
      "uid"
    ],
    "_create_sequence": [
      "self",
      "uid"
    ],
    "tracked_sequences": [
      "self"
    ],
    "n_tracked_sequences": [
      "self"
    ],
    "kv_block_size": [
      "self"
    ],
    "n_kv_cache_groups": [
      "self"
    ],
    "free_blocks": [
      "self"
    ],
    "allocate_blocks": [
      "self",
      "n_blocks",
      "cache_group"
    ]
  },
  "BlockedAllocator": {
    "__init__": [
      "self",
      "num_blocks"
    ],
    "allocate": [
      "self",
      "num_blocks"
    ],
    "free": [
      "self",
      "blocks"
    ],
    "free_blocks": [
      "self"
    ]
  },
  "MEGATRON": [],
  "HUGGINGFACE": [],
  "CheckpointEngineBase": {
    "parameters": [
      "self"
    ]
  },
  "InMemoryModelEngine": {
    "__init__": [
      "self",
      "model"
    ],
    "parameters": [
      "self"
    ]
  },
  "HuggingFaceCheckpointEngine": {
    "__init__": [
      "self",
      "model_name_or_path",
      "auth_token"
    ],
    "_fetch_checkpoint_files": [
      "self"
    ],
    "parameters": [
      "self"
    ]
  },
  "instantiate_attention": [
    "attention_config",
    "engine_config"
  ],
  "instantiate_embed": [
    "embed_config",
    "engine_config"
  ],
  "instantiate_linear": [
    "linear_config",
    "engine_config"
  ],
  "instantiate_moe": [
    "moe_config",
    "engine_config"
  ],
  "instantiate_post_norm": [
    "norm_config",
    "engine_config"
  ],
  "instantiate_pre_norm": [
    "norm_config",
    "engine_config"
  ],
  "instantiate_unembed": [
    "unembed_config",
    "engine_config"
  ],
  "ConfigBundle": {},
  "DSModuleRegistryBase": {
    "instantiate_config": [
      "cls",
      "config_bundle"
    ],
    "associated_class": [],
    "register_module": [
      "cls",
      "child_class"
    ]
  },
  "DSModuleConfig": {},
  "DSModuleBase": {
    "name": [],
    "config_class": [],
    "supports_config": [
      "config"
    ],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ]
  },
  "DSLinearBase": {
    "config_class": [],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "transform_param": [
      "self",
      "param"
    ],
    "forward": [
      "self",
      "hidden_states",
      "w",
      "b"
    ],
    "output": [
      "self"
    ]
  },
  "DSLinearRegistry": {
    "associated_class": []
  },
  "DSEmbeddingBase": {
    "config_class": [],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "transform_param": [
      "self",
      "embed_param"
    ],
    "output": [
      "self"
    ],
    "forward": [
      "self",
      "ragged_batch",
      "word_embeddings",
      "position_embeddings",
      "token_type_ids",
      "token_type_embeddings"
    ]
  },
  "DSEmbeddingRegistry": {
    "associated_class": []
  },
  "DSSelfAttentionBase": {
    "config_class": [],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "kv_block_size": [
      "self"
    ],
    "q_block_size": [
      "self"
    ],
    "build_atoms": [
      "self",
      "ragged_batch"
    ],
    "forward": [
      "self",
      "q_k_v",
      "kv_cache",
      "batch",
      "attention_mask",
      "attention_bias",
      "inv_freqs"
    ]
  },
  "DSSelfAttentionRegistry": {
    "associated_class": []
  },
  "DSUnembedBase": {
    "config_class": [],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "vocab_embedding",
      "ragged_metadata",
      "gamma",
      "beta"
    ]
  },
  "DSUnembedRegistry": {
    "associated_class": []
  },
  "DSPreNormBase": {
    "config_class": [],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "transform_param": [
      "self",
      "param"
    ],
    "forward": [
      "self",
      "residual",
      "hidden_states",
      "gamma",
      "beta"
    ]
  },
  "DSPreNormRegistry": {
    "associated_class": []
  },
  "DSPostNormBase": {
    "config_class": [],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "transform_param": [
      "self",
      "param"
    ],
    "forward": [
      "self",
      "residual",
      "hidden_states",
      "gamma",
      "beta"
    ]
  },
  "DSPostNormRegistry": {
    "associated_class": []
  },
  "DSMoEBase": {
    "config_class": [],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "transform_gate_param": [
      "self",
      "param"
    ],
    "transform_moe_mlp_1_param": [
      "self",
      "param"
    ],
    "transform_moe_mlp_2_param": [
      "self",
      "param"
    ],
    "forward": [
      "self",
      "hidden_states",
      "gate_w",
      "mlp_1_w",
      "mlp_2_w",
      "mlp_1_b",
      "mlp_2_b"
    ],
    "output": [
      "self"
    ]
  },
  "DSMoERegistry": {
    "associated_class": []
  },
  "DSRaggedUnembed": {
    "name": [],
    "supports_config": [
      "config"
    ],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "output": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "vocab_embedding",
      "ragged_metadata",
      "bias",
      "gamma",
      "beta"
    ]
  },
  "DSRaggedEmbedding": {
    "name": [],
    "supports_config": [
      "config"
    ],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "output": [
      "self"
    ],
    "forward": [
      "self",
      "ragged_batch",
      "word_embeddings",
      "position_embeddings"
    ]
  },
  "DSPostLNCUDAModule": {
    "name": [],
    "supports_config": [
      "config"
    ],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "transform_param": [
      "self",
      "param"
    ],
    "forward": [
      "self",
      "residual",
      "hidden_in",
      "gamma",
      "beta"
    ]
  },
  "DSMultiGemmMoE": {
    "name": [],
    "supports_config": [
      "config"
    ],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "_create_buffers": [
      "self"
    ],
    "transform_gate_param": [
      "self",
      "param"
    ],
    "transform_moe_mlp_1_param": [
      "self",
      "param"
    ],
    "transform_moe_mlp_2_param": [
      "self",
      "param"
    ],
    "output": [
      "self"
    ],
    "_gate": [
      "self",
      "hidden_states",
      "batch_metadata",
      "gate_w"
    ],
    "forward": [
      "self",
      "hidden_states",
      "batch_metadata",
      "gate_w",
      "mlp_1_w",
      "mlp_2_w",
      "mlp_1_b",
      "mlp_2_b"
    ]
  },
  "DSPreRMSCUDAModule": {
    "name": [],
    "supports_config": [
      "config"
    ],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "transform_param": [
      "self",
      "param"
    ],
    "forward": [
      "self",
      "residual",
      "hidden_in",
      "gamma",
      "beta"
    ]
  },
  "DSPreLNCUDAModule": {
    "name": [],
    "supports_config": [
      "config"
    ],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "transform_param": [
      "self",
      "param"
    ],
    "forward": [
      "self",
      "residual",
      "hidden_in",
      "gamma",
      "beta"
    ]
  },
  "DSDenseBlockedAttention": {
    "name": [],
    "supports_config": [
      "config"
    ],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "kv_block_size": [
      "self"
    ],
    "q_block_size": [
      "self"
    ],
    "build_atoms": [
      "self",
      "ragged_batch"
    ],
    "forward": [
      "self",
      "q_k_v",
      "kv_cache",
      "batch",
      "inv_freqs"
    ]
  },
  "BlasFPLinear": {
    "name": [],
    "supports_config": [
      "config"
    ],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "transform_param": [
      "self",
      "param"
    ],
    "forward": [
      "self",
      "hidden_states",
      "w",
      "b"
    ],
    "output": [
      "self"
    ]
  },
  "fp_quantize": [
    "input",
    "num_bits",
    "exp_bits",
    "min_value",
    "max_value",
    "group_size"
  ],
  "QuantizedWf6Af16Linear": {
    "name": [],
    "supports_config": [
      "config"
    ],
    "__init__": [
      "self",
      "config",
      "implementation_config"
    ],
    "transform_param": [
      "self",
      "param"
    ],
    "forward": [
      "self",
      "hidden_states",
      "w",
      "b"
    ],
    "output": [
      "self"
    ]
  },
  "DSEmbeddingsConfig": {},
  "DSLinearConfig": {},
  "PositionalEmbeddingType": {
    "none": [],
    "rotate_half": [],
    "rotate_every_other": [],
    "alibi": []
  },
  "RotateHalfConfig": {},
  "MaskingType": {
    "none": [],
    "causal": [],
    "local": [],
    "symmetric": [],
    "asymmetric": []
  },
  "DSSelfAttentionConfig": {},
  "DSMoEConfig": {},
  "DSNormConfig": {},
  "DSUnembedConfig": {},
  "QuantizationContext": {
    "__init__": [
      "self",
      "config_dict_or_path",
      "param_swapper"
    ]
  },
  "_init_group_wise_weight_quantization": [
    "model",
    "ds_config"
  ],
  "quantizer_module": [],
  "get_quantizer_module": [],
  "tensor_clamp": [
    "tensor",
    "min",
    "max"
  ],
  "tensor_round": [
    "tensor"
  ],
  "DeQuantizer": {
    "__init__": [
      "self",
      "config",
      "dtype"
    ],
    "dequantize": [
      "self",
      "tensor",
      "quant_scale",
      "quant_min"
    ],
    "_dequantize_int8": [
      "self",
      "tensor",
      "quant_scale",
      "quant_min"
    ],
    "_decompress_uint4_to_uint8": [
      "self",
      "tensor"
    ]
  },
  "get_AsyncPartitionedParameterSwapper": [
    "model"
  ],
  "concat_to_compat_param": [
    "quantized_weight",
    "quant_scale",
    "quant_min",
    "return_param"
  ],
  "_quantize_param": [
    "param",
    "quant_config"
  ],
  "wrap_quantized_functional": [
    "f"
  ],
  "wrap_load_from_state_dict": [
    "f"
  ],
  "WEIGHT_QUANTIZATION_LAYERS": [],
  "quantized_weight_registry": [],
  "is_zero3_enabled": [],
  "get_quantized_weight_wrapper": [
    "model",
    "pre_quant_weight",
    "quantize_weight_fn"
  ],
  "get_quantize_weight_fn": [
    "quantizer",
    "pre_quant_weight"
  ],
  "QuantizedLinear": {
    "__init__": [
      "self",
      "config",
      "pre_quant_layer"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "QuantizedEmbedding": {
    "__init__": [
      "self",
      "config",
      "pre_quant_layer"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "QUANTIZATION_LAYER_MAPPINGS": [],
  "LR_SCHEDULE": [],
  "LR_RANGE_TEST": [],
  "ONE_CYCLE": [],
  "WARMUP_LR": [],
  "WARMUP_DECAY_LR": [],
  "WARMUP_COSINE_LR": [],
  "VALID_LR_SCHEDULES": [],
  "LR_RANGE_TEST_MIN_LR": [],
  "LR_RANGE_TEST_STEP_RATE": [],
  "LR_RANGE_TEST_STEP_SIZE": [],
  "LR_RANGE_TEST_STAIRCASE": [],
  "EDGE_VALUE": [],
  "MID_VALUE": [],
  "CYCLE_FIRST_STEP_SIZE": [],
  "CYCLE_FIRST_STAIR_COUNT": [],
  "CYCLE_SECOND_STEP_SIZE": [],
  "CYCLE_SECOND_STAIR_COUNT": [],
  "DECAY_STEP_SIZE": [],
  "CYCLE_MIN_LR": [],
  "CYCLE_MAX_LR": [],
  "DECAY_LR_RATE": [],
  "CYCLE_MIN_MOM": [],
  "CYCLE_MAX_MOM": [],
  "DECAY_MOM_RATE": [],
  "WARMUP_MIN_LR": [],
  "WARMUP_MAX_LR": [],
  "WARMUP_NUM_STEPS": [],
  "WARMUP_TYPE": [],
  "WARMUP_LOG_RATE": [],
  "WARMUP_LINEAR_RATE": [],
  "WARMUP_MIN_RATIO": [],
  "COS_MIN_RATIO": [],
  "TOTAL_NUM_STEPS": [],
  "add_tuning_arguments": [
    "parser"
  ],
  "override_lr_range_test_params": [
    "args",
    "params"
  ],
  "override_1cycle_params": [
    "args",
    "params"
  ],
  "override_warmupLR_params": [
    "args",
    "params"
  ],
  "override_params": [
    "args",
    "params"
  ],
  "get_config_from_args": [
    "args"
  ],
  "get_lr_from_config": [
    "config"
  ],
  "update_lr": [
    "param_groups",
    "lrs"
  ],
  "get_torch_optimizer": [
    "optimizer"
  ],
  "LRRangeTest": {
    "__init__": [
      "self",
      "optimizer",
      "lr_range_test_min_lr",
      "lr_range_test_step_size",
      "lr_range_test_step_rate",
      "lr_range_test_staircase",
      "last_batch_iteration"
    ],
    "_staircase_interval": [
      "self"
    ],
    "_continuous_interval": [
      "self"
    ],
    "_get_increase": [
      "self"
    ],
    "get_lr": [
      "self"
    ],
    "get_last_lr": [
      "self"
    ],
    "step": [
      "self",
      "batch_iteration"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "sd"
    ]
  },
  "OneCycle": {
    "__init__": [
      "self",
      "optimizer",
      "cycle_min_lr",
      "cycle_max_lr",
      "decay_lr_rate",
      "cycle_first_step_size",
      "cycle_second_step_size",
      "cycle_first_stair_count",
      "cycle_second_stair_count",
      "decay_step_size",
      "cycle_momentum",
      "cycle_min_mom",
      "cycle_max_mom",
      "decay_mom_rate",
      "last_batch_iteration"
    ],
    "_initialize_cycle": [
      "self",
      "cycle_first_step_size",
      "cycle_second_step_size",
      "cycle_first_stair_count",
      "cycle_second_stair_count",
      "decay_step_size"
    ],
    "_initialize_lr": [
      "self",
      "optimizer",
      "cycle_min_lr",
      "cycle_max_lr",
      "decay_lr_rate",
      "last_batch_iteration"
    ],
    "_initialize_momentum": [
      "self",
      "optimizer",
      "cycle_min_mom",
      "cycle_max_mom",
      "decay_mom_rate",
      "last_batch_iteration"
    ],
    "_get_scale_factor": [
      "self"
    ],
    "_get_cycle_mom": [
      "self"
    ],
    "_get_cycle_lr": [
      "self"
    ],
    "_get_decay_mom": [
      "self",
      "decay_batch_iteration"
    ],
    "_get_decay_lr": [
      "self",
      "decay_batch_iteration"
    ],
    "get_lr": [
      "self"
    ],
    "get_mom": [
      "self"
    ],
    "get_last_lr": [
      "self"
    ],
    "step": [
      "self",
      "batch_iteration"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "sd"
    ]
  },
  "WarmupLR": {
    "__init__": [
      "self",
      "optimizer",
      "warmup_min_lr",
      "warmup_max_lr",
      "warmup_num_steps",
      "warmup_type",
      "last_batch_iteration"
    ],
    "get_lr": [
      "self"
    ],
    "get_last_lr": [
      "self"
    ],
    "step": [
      "self",
      "last_batch_iteration"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "sd"
    ],
    "_get_gamma": [
      "self"
    ],
    "_format_param": [
      "self",
      "optimizer",
      "param_value",
      "param_name"
    ]
  },
  "WarmupDecayLR": {
    "__init__": [
      "self",
      "optimizer",
      "total_num_steps",
      "warmup_min_lr",
      "warmup_max_lr",
      "warmup_num_steps",
      "warmup_type",
      "last_batch_iteration"
    ],
    "_get_gamma": [
      "self"
    ]
  },
  "WarmupCosineLR": {
    "__init__": [
      "self",
      "optimizer",
      "total_num_steps",
      "warmup_min_ratio",
      "warmup_num_steps",
      "cos_min_ratio",
      "warmup_type",
      "last_batch_iteration"
    ],
    "get_lr_ratio": [
      "self"
    ],
    "step": [
      "self",
      "last_batch_iteration"
    ],
    "get_lr": [
      "self"
    ],
    "get_last_lr": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "sd"
    ],
    "_format_param": [
      "self",
      "optimizer",
      "param_value",
      "param_name"
    ]
  },
  "DeepSpeedHybridEngine": {
    "inference_mp_group": [],
    "__init__": [
      "self",
      "args",
      "model"
    ],
    "convert_to_linear_transposed": [
      "self",
      "model"
    ],
    "new_inference_container": [
      "self",
      "orig_layer",
      "policy_cls",
      "layer_id"
    ],
    "populate_all_inference_policies": [
      "self"
    ],
    "_fuse_lora_layer": [
      "self",
      "layer_id"
    ],
    "fuse_lora_weight": [
      "self"
    ],
    "_unfuse_lora_layer": [
      "self",
      "layer_id"
    ],
    "unfuse_lora_weight": [
      "self"
    ],
    "unfuse_lora_weight_non_pinned": [
      "self"
    ],
    "retake_inference_cache": [
      "self"
    ],
    "generate": [
      "self"
    ],
    "create_inference_containers": [
      "self",
      "module",
      "layer_id"
    ],
    "create_inference_module": [
      "self"
    ],
    "_zero3_forward": [
      "self",
      "layer_id"
    ],
    "eval": [
      "self"
    ],
    "train": [
      "self",
      "mode"
    ],
    "step": [
      "self",
      "lr_kwargs"
    ]
  },
  "SparseTensor": {
    "__init__": [
      "self",
      "dense_tensor"
    ],
    "to_coo_tensor": [
      "self"
    ],
    "type": [],
    "to_dense": [
      "self"
    ],
    "sparse_size": [
      "self"
    ],
    "add": [
      "self",
      "b"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "DeepSpeedConfigModel": {
    "__init__": [
      "self",
      "strict"
    ],
    "_process_deprecated_field": [
      "self",
      "dep_field"
    ],
    "_deprecated_fields_check": [
      "self"
    ],
    "model_config": [],
    "serialize_torch_dtype": [
      "dtype"
    ]
  },
  "get_config_default": [
    "config",
    "field_name"
  ],
  "pp_int": {
    "__new__": [
      "cls",
      "val",
      "custom_print_str"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ScientificNotationEncoder": {
    "iterencode": [
      "self",
      "o",
      "_one_shot",
      "level"
    ]
  },
  "DeepSpeedConfigObject": {
    "repr": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "get_scalar_param": [
    "param_dict",
    "param_name",
    "param_default_value"
  ],
  "get_list_param": [
    "param_dict",
    "param_name",
    "param_default_value"
  ],
  "get_dict_param": [
    "param_dict",
    "param_name",
    "param_default_value"
  ],
  "dict_raise_error_on_duplicate_keys": [
    "ordered_pairs"
  ],
  "DeepSpeedOptimizer": {},
  "BackwardHookStateManager": {
    "__init__": [
      "self"
    ],
    "register_grad_acc_post_hook": [
      "self",
      "hook"
    ],
    "unregister_grad_acc_post_hooks": [
      "self"
    ],
    "run_grad_acc_post_hooks": [
      "self"
    ],
    "enter_backward": [
      "self"
    ],
    "exit_backward": [
      "self"
    ],
    "reset_for_new_step": [
      "self"
    ],
    "reenter_backward_if_needed": [
      "self"
    ],
    "queue_post_backward_callback": [
      "self"
    ],
    "update_hook_state_and_maybe_run_epilogue": [
      "self",
      "current_expected_count"
    ]
  },
  "ZeROOptimizer": {
    "__init__": [
      "self"
    ],
    "_remaining_grad_acc_hooks": [
      "self",
      "value"
    ],
    "_backward_active_depth": [
      "self",
      "value"
    ],
    "_backward_seen_this_step": [
      "self",
      "value"
    ],
    "_epilogue_ran_this_backward": [
      "self",
      "value"
    ],
    "_hooks_fired_this_backward": [
      "self",
      "value"
    ],
    "_max_expected_hooks_seen": [
      "self",
      "value"
    ],
    "_grad_acc_post_hooks": [
      "self",
      "value"
    ],
    "load_hp_checkpoint_state_from_checkpoint_dir": [
      "self",
      "lp_groups_name",
      "checkpoint_dir"
    ],
    "report_ipg_memory_usage": [
      "self",
      "tag",
      "param_elems",
      "dtype"
    ],
    "get_param_comm_dtype": [
      "self",
      "param"
    ],
    "needs_scaler": [
      "self"
    ],
    "scale_if_loss": [
      "self",
      "value"
    ],
    "backward_prologue": [
      "self"
    ],
    "backward_epilogue": [
      "self"
    ],
    "backward": [
      "self",
      "loss"
    ],
    "register_grad_acc_post_hook": [
      "self",
      "hook"
    ],
    "unregister_grad_acc_post_hooks": [
      "self"
    ],
    "run_grad_acc_post_hooks": [
      "self"
    ],
    "enter_backward": [
      "self"
    ],
    "exit_backward": [
      "self"
    ],
    "clear_backward_seen_flag": [
      "self"
    ],
    "reenter_backward_if_needed": [
      "self"
    ],
    "update_hook_state_and_maybe_run_epilogue": [
      "self",
      "current_expected_count"
    ],
    "queue_post_backward_callback": [
      "self"
    ],
    "_configure_master_weights": [
      "self",
      "fp16_master_weights_and_gradients",
      "bf16_master_weights_and_gradients",
      "bf16_optimizer_states",
      "fp16_offload_validator",
      "bf16_fp32_offload_validator"
    ]
  },
  "LOWER_PRECISION_SAFE_MODULES": [],
  "PARAM_COMM_DTYPE_ATTR_NAME": [],
  "_WARNED_NESTED_AUTOCAST": [],
  "TORCH_AUTOCAST_INITIALIZED": [],
  "TORCH_AUTOCAST_DTYPE": [],
  "_validate_auto_cast_settings": [
    "engine"
  ],
  "init_autocast_params": [
    "engine",
    "dtype",
    "torch_autocast_lower_precision_safe_modules"
  ],
  "is_autocast_initialized": [],
  "get_default_autocast_lower_precision_modules": [],
  "get_autocast_dtype": [],
  "has_comm_dtype": [
    "param"
  ],
  "get_comm_dtype": [
    "param"
  ],
  "get_all_comm_dtypes": [
    "params"
  ],
  "sort_dtypes": [
    "dtypes"
  ],
  "autocast_if_enabled": [
    "engine"
  ],
  "torch_memory_reserved": [],
  "torch_max_memory_reserved": [],
  "DummyOptim": {
    "__init__": [
      "self",
      "params"
    ]
  },
  "filter_empty_parameters": [
    "params"
  ],
  "graph_cache": [],
  "graph_process": [
    "replay_first_step",
    "func"
  ],
  "noop_decorator": [
    "func"
  ],
  "noop_context": {
    "__init__": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "ensure_directory_exists": [
    "filename"
  ],
  "set_random_seed": [
    "seed"
  ],
  "is_model_parallel_parameter": [
    "p"
  ],
  "copy_to_device": [
    "item",
    "device",
    "criterion_func"
  ],
  "move_to_device": [
    "item",
    "device",
    "criterion_func"
  ],
  "get_norm_with_moe_layers_fast": [
    "all_groups_norm",
    "group"
  ],
  "CheckOverflow": {
    "__init__": [
      "self",
      "param_groups",
      "mpu",
      "zero_reduce_scatter",
      "deepspeed"
    ],
    "check_using_norm": [
      "self",
      "norm_group",
      "reduce_overflow"
    ],
    "check": [
      "self",
      "param_groups"
    ],
    "has_overflow_serial": [
      "self",
      "params"
    ],
    "has_overflow": [
      "self",
      "params",
      "has_moe_params"
    ],
    "_has_inf_or_nan": [
      "x",
      "i"
    ]
  },
  "_handle_overflow": [
    "cpu_sum",
    "x",
    "i"
  ],
  "get_global_norm": [
    "norm_list"
  ],
  "clip_grad_norm_": [
    "parameters",
    "max_norm",
    "norm_type",
    "mpu"
  ],
  "get_flattened_grad_norm": [
    "parameters",
    "norm_type",
    "mpu",
    "grad_norm_mask"
  ],
  "get_grad_zeros": [
    "parameters",
    "mpu"
  ],
  "get_weight_norm": [
    "parameters",
    "norm_type",
    "mpu"
  ],
  "prefix_sum_inc": [
    "weights"
  ],
  "partition_uniform": [
    "num_items",
    "num_parts"
  ],
  "partition_balanced": [
    "weights",
    "num_parts"
  ],
  "PartitionedTensor": {
    "__init__": [
      "self",
      "tensor",
      "group",
      "partition_meta"
    ],
    "from_meta": [
      "cls",
      "meta",
      "local_part",
      "group",
      "device"
    ],
    "_partition_tensor": [
      "self",
      "tensor"
    ],
    "full": [
      "self",
      "device"
    ],
    "to_meta": [
      "self"
    ],
    "data": [
      "self"
    ],
    "local_size": [
      "self"
    ],
    "full_size": [
      "self"
    ]
  },
  "mem_alloced": [],
  "mem_cached": [],
  "memory_status": [
    "msg",
    "print_rank",
    "reset_max"
  ],
  "get_ma_status": [],
  "see_memory_usage": [
    "message",
    "force"
  ],
  "call_to_str": [
    "base"
  ],
  "get_only_unique_item": [
    "items"
  ],
  "mask_nan_or_inf_with_val_inplace": [
    "input",
    "device",
    "val"
  ],
  "get_global_norm_of_tensors": [
    "input_tensors",
    "norm_type",
    "mpu",
    "use_graph",
    "moe_ep_group"
  ],
  "clip_tensors_by_global_norm": [
    "input_tensors",
    "max_norm",
    "global_norm",
    "mpu",
    "eps",
    "use_graph"
  ],
  "align_dense_tensors": [
    "tensor_list",
    "alignment"
  ],
  "all_gather_into_tensor_dp_groups": [
    "groups_flat",
    "partitioned_param_groups",
    "dp_process_group"
  ],
  "all_gather_dp_groups": [
    "groups_flat",
    "partitioned_param_groups",
    "dp_process_group",
    "start_alignment_factor",
    "allgather_bucket_size"
  ],
  "get_tensor_bytes": [
    "item"
  ],
  "_get_folder_size": [
    "folder"
  ],
  "get_checkpoint_folder_size": [
    "save_dir",
    "tag",
    "local_rank"
  ],
  "TLinear": {
    "__init__": [
      "self",
      "orig_layer",
      "name"
    ],
    "_fwd": [
      "self",
      "input"
    ],
    "_fwd_bias_add": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "get_inactive_params": [
    "param_list"
  ],
  "get_norm_with_moe_layers": [
    "non_expert_norm",
    "mpu",
    "expert_tensors",
    "norm_type"
  ],
  "_make_offload_state_key": [
    "key"
  ],
  "offload_adam_states": [
    "optimizer",
    "device",
    "pin_memory",
    "non_blocking"
  ],
  "reload_adam_states": [
    "optimizer",
    "device",
    "non_blocking"
  ],
  "compare_tensors_in_structures": [
    "inputs1",
    "inputs2"
  ],
  "maybe_loss_for_backward": [
    "value"
  ],
  "OutputBackwardHookManager": {
    "__init__": [
      "self",
      "preprocess_once_fn",
      "preprocess_per_tensor_fn"
    ],
    "_make_backward_hook": [
      "self",
      "tensor"
    ],
    "_traverse_and_register_hooks": [
      "self",
      "outputs",
      "first_tensor_holder"
    ],
    "register_hooks_on_outputs": [
      "self",
      "outputs"
    ],
    "remove_hooks": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "register_output_backward_hooks": [
    "outputs",
    "preprocess_once_fn",
    "preprocess_per_tensor_fn"
  ],
  "check_internal_apis_for_count_used_parameters": [],
  "count_used_parameters_in_backward": [
    "parameters"
  ],
  "TWO_D_PARAMS": [],
  "MEMORY_OPT_ALLREDUCE_SIZE": [],
  "DeepSpeedOptimizerCallable": [],
  "DeepSpeedSchedulerCallable": [],
  "split_half_float_double_sparse": [
    "tensors"
  ],
  "EngineTimers": {
    "__init__": [
      "self",
      "enable_micro_timers",
      "enable_global_timers"
    ],
    "active_timers": [
      "self"
    ]
  },
  "DeepSpeedEngine": {
    "__init__": [
      "self",
      "args",
      "model",
      "optimizer",
      "model_parameters",
      "training_data",
      "lr_scheduler",
      "mpu",
      "dist_init_required",
      "collate_fn",
      "config",
      "config_class",
      "mesh_device",
      "dont_change_device"
    ],
    "_optimized_linear_offload_setup": [
      "self"
    ],
    "_configure_tensor_parallel": [
      "self",
      "model",
      "tp_config"
    ],
    "_configure_tensor_parallel_states": [
      "self",
      "model"
    ],
    "_apply_autotp_partitioning": [
      "self",
      "model",
      "tp_config"
    ],
    "__del__": [
      "self"
    ],
    "destroy": [
      "self"
    ],
    "_get_model_parameters": [
      "self"
    ],
    "get_batch_info": [
      "self"
    ],
    "set_train_batch_size": [
      "self",
      "train_batch_size"
    ],
    "set_train_micro_batch_size": [
      "self",
      "micro_batch_size"
    ],
    "set_data_post_process_func": [
      "self",
      "post_process_func"
    ],
    "set_custom_curriculum_learning_schedule": [
      "self",
      "schedule_func_dict"
    ],
    "get_global_grad_norm": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "checkpoint_serialization_enabled": [
      "self"
    ],
    "checkpoint_writer_enabled": [
      "self"
    ],
    "checkpoint_tag_validation_enabled": [
      "self"
    ],
    "checkpoint_tag_validation_fail": [
      "self"
    ],
    "elasticity_enabled": [
      "self"
    ],
    "is_elastic_model_parallel_supported": [
      "self"
    ],
    "pld_enabled": [
      "self"
    ],
    "pld_params": [
      "self"
    ],
    "pld_theta": [
      "self"
    ],
    "pld_gamma": [
      "self"
    ],
    "eigenvalue_enabled": [
      "self"
    ],
    "eigenvalue_verbose": [
      "self"
    ],
    "eigenvalue_max_iter": [
      "self"
    ],
    "eigenvalue_tol": [
      "self"
    ],
    "eigenvalue_stability": [
      "self"
    ],
    "eigenvalue_gas_boundary_resolution": [
      "self"
    ],
    "eigenvalue_layer_name": [
      "self"
    ],
    "eigenvalue_layer_num": [
      "self"
    ],
    "curriculum_enabled_legacy": [
      "self"
    ],
    "curriculum_params_legacy": [
      "self"
    ],
    "data_efficiency_enabled": [
      "self"
    ],
    "data_efficiency_config": [
      "self"
    ],
    "data_sampling_enabled": [
      "self"
    ],
    "data_sampling_config": [
      "self"
    ],
    "curriculum_learning_enabled": [
      "self"
    ],
    "curriculum_learning_config": [
      "self"
    ],
    "random_ltd_enabled": [
      "self"
    ],
    "random_ltd_config": [
      "self"
    ],
    "random_ltd_initialize": [
      "self"
    ],
    "get_data_parallel_rank": [
      "self"
    ],
    "get_tensor_parallel_rank": [
      "self"
    ],
    "get_model_parallel_rank": [
      "self"
    ],
    "get_sequence_parallel_group": [
      "self"
    ],
    "wall_clock_breakdown": [
      "self"
    ],
    "flops_profiler_enabled": [
      "self"
    ],
    "flops_profiler_recompute_fwd_factor": [
      "self"
    ],
    "flops_profiler_profile_step": [
      "self"
    ],
    "flops_profiler_module_depth": [
      "self"
    ],
    "flops_profiler_top_modules": [
      "self"
    ],
    "flops_profiler_detailed": [
      "self"
    ],
    "flops_profiler_output_file": [
      "self"
    ],
    "memory_breakdown": [
      "self"
    ],
    "autotuning_enabled": [
      "self"
    ],
    "autotuning_start_profile_step": [
      "self"
    ],
    "autotuning_end_profile_step": [
      "self"
    ],
    "autotuning_metric_path": [
      "self"
    ],
    "autotuning_model_info_path": [
      "self"
    ],
    "autotuning_metric": [
      "self"
    ],
    "autotuning_profile_model_info": [
      "self"
    ],
    "sparse_gradients_enabled": [
      "self"
    ],
    "train_batch_size": [
      "self"
    ],
    "train_micro_batch_size_per_gpu": [
      "self"
    ],
    "optimizer_name": [
      "self"
    ],
    "optimizer_params": [
      "self"
    ],
    "optimizer_legacy_fusion": [
      "self"
    ],
    "scheduler_name": [
      "self"
    ],
    "scheduler_params": [
      "self"
    ],
    "quantize_training": [
      "self"
    ],
    "zero_optimization": [
      "self"
    ],
    "zero_allow_untested_optimizer": [
      "self"
    ],
    "zero_force_ds_cpu_optimizer": [
      "self"
    ],
    "zero_reduce_scatter": [
      "self"
    ],
    "zero_overlap_comm": [
      "self"
    ],
    "zero_offload_optimizer": [
      "self"
    ],
    "zero_offload_param": [
      "self"
    ],
    "zero_use_cpu_optimizer": [
      "self"
    ],
    "zero_cpu_offload": [
      "self"
    ],
    "zero_partial_offload": [
      "self"
    ],
    "super_offload": [
      "self"
    ],
    "cpuadam_cores_perc": [
      "self"
    ],
    "zero_sub_group_size": [
      "self"
    ],
    "zero_optimization_stage": [
      "self"
    ],
    "mics_shard_size": [
      "self"
    ],
    "zero_reduce_bucket_size": [
      "self"
    ],
    "zero_multi_rank_bucket_allreduce": [
      "self"
    ],
    "zero_allgather_bucket_size": [
      "self"
    ],
    "zero_optimization_partition_gradients": [
      "self"
    ],
    "zero_optimization_partition_weights": [
      "self"
    ],
    "is_first_weights_partition_group": [
      "self"
    ],
    "zero_contiguous_gradients": [
      "self"
    ],
    "zero_load_from_fp32_weights": [
      "self"
    ],
    "zero_elastic_checkpoint": [
      "self"
    ],
    "zero_nvme_offload_optimizer": [
      "self"
    ],
    "zero_max_live_parameters": [
      "self"
    ],
    "zero_max_reuse_distance": [
      "self"
    ],
    "zero_prefetch_bucket_size": [
      "self"
    ],
    "zero_module_granularity_threshold": [
      "self"
    ],
    "zero_param_persistence_threshold": [
      "self"
    ],
    "zero_model_persistence_threshold": [
      "self"
    ],
    "zero_gather_16bit_weights_on_model_save": [
      "self"
    ],
    "zero_grad_hooks": [
      "self"
    ],
    "zero_legacy_stage1": [
      "self"
    ],
    "zero_ignore_unused_parameters": [
      "self"
    ],
    "tensor_parallel_config": [
      "self"
    ],
    "autotp_size": [
      "self"
    ],
    "graph_harvesting": [
      "self"
    ],
    "fp16_enabled": [
      "self"
    ],
    "bfloat16_enabled": [
      "self"
    ],
    "fp16_master_weights_and_gradients": [
      "self"
    ],
    "bf16_master_weights_and_gradients": [
      "self"
    ],
    "bf16_optimizer_states": [
      "self"
    ],
    "amp_enabled": [
      "self"
    ],
    "amp_params": [
      "self"
    ],
    "torch_autocast_enabled": [
      "self"
    ],
    "torch_autocast_dtype": [
      "self"
    ],
    "torch_autocast_lower_precision_safe_modules": [
      "self"
    ],
    "fp16_auto_cast": [
      "self"
    ],
    "loss_scale": [
      "self"
    ],
    "gradient_accumulation_steps": [
      "self"
    ],
    "use_node_local_storage": [
      "self"
    ],
    "load_universal_checkpoint": [
      "self"
    ],
    "communication_data_type": [
      "self",
      "value"
    ],
    "postscale_gradients": [
      "self"
    ],
    "gradient_predivide_factor": [
      "self"
    ],
    "steps_per_print": [
      "self"
    ],
    "zero_allgather_partitions": [
      "self"
    ],
    "zero_round_robin_gradients": [
      "self"
    ],
    "zero_hpz_partition_size": [
      "self"
    ],
    "zero_quantized_weights": [
      "self"
    ],
    "zero_quantized_nontrainable_weights": [
      "self"
    ],
    "zero_quantized_gradients": [
      "self"
    ],
    "zeropp_loco_param": [
      "self"
    ],
    "zero_log_trace_cache_warnings": [
      "self"
    ],
    "zero_allgather_sequential": [
      "self"
    ],
    "is_sanity_checks_enabled": [
      "self"
    ],
    "dump_state": [
      "self"
    ],
    "gradient_clipping": [
      "self"
    ],
    "dynamic_loss_scale": [
      "self"
    ],
    "initial_dynamic_scale": [
      "self"
    ],
    "dynamic_loss_scale_args": [
      "self"
    ],
    "swap_tensor_config": [
      "self"
    ],
    "aio_config": [
      "self"
    ],
    "zenflow_config": [
      "self"
    ],
    "get_data_types": [
      "self"
    ],
    "_optimizer_has_ckpt_event_prologue": [
      "self"
    ],
    "_optimizer_has_ckpt_event_epilogue": [
      "self"
    ],
    "_configure_lr_scheduler": [
      "self"
    ],
    "_configure_checkpointing": [
      "self"
    ],
    "_scheduler_from_config": [
      "self",
      "optimizer"
    ],
    "_set_distributed_vars": [
      "self",
      "args"
    ],
    "_configure_with_arguments": [
      "self",
      "args",
      "mpu"
    ],
    "_do_args_sanity_check": [
      "self",
      "args"
    ],
    "_is_supported_optimizer": [
      "self",
      "optimizer_name"
    ],
    "_supported_optims": [
      "self"
    ],
    "_do_sanity_check": [
      "self"
    ],
    "_broadcast_model": [
      "self"
    ],
    "__check_params": [
      "model",
      "dtype"
    ],
    "_set_client_model": [
      "self",
      "model"
    ],
    "_configure_distributed_model": [
      "self",
      "model"
    ],
    "_check_for_duplicates": [
      "self",
      "optimizer"
    ],
    "_do_optimizer_sanity_check": [
      "self",
      "basic_optimizer"
    ],
    "_configure_optimizer": [
      "self",
      "client_optimizer",
      "model_parameters"
    ],
    "_configure_basic_optimizer": [
      "self",
      "model_parameters"
    ],
    "_configure_compression_scheduler": [
      "self"
    ],
    "_configure_random_ltd_scheduler": [
      "self",
      "configs"
    ],
    "_configure_quantization": [
      "self"
    ],
    "_configure_fp16_optimizer": [
      "self",
      "optimizer",
      "low_precision_dtype"
    ],
    "_configure_bf16_optimizer": [
      "self",
      "optimizer"
    ],
    "_configure_zero_optimizer": [
      "self",
      "optimizer"
    ],
    "_return_mics_optimizer": [
      "self",
      "basic_optimizer",
      "timers"
    ],
    "_configure_eigenvalue": [
      "self"
    ],
    "_configure_progressive_layer_drop": [
      "self"
    ],
    "_configure_curriculum_scheduler_legacy": [
      "self"
    ],
    "is_map_style_dataset": [
      "obj"
    ],
    "is_iterable_style_dataset": [
      "obj"
    ],
    "dataloader_drop_last": [
      "self"
    ],
    "was_step_applied": [
      "self"
    ],
    "deepspeed_io": [
      "self",
      "dataset",
      "batch_size",
      "route",
      "pin_memory",
      "data_sampler",
      "collate_fn",
      "num_local_io_workers"
    ],
    "train": [
      "self",
      "mode"
    ],
    "eval": [
      "self"
    ],
    "_scale_loss_by_gas": [
      "self",
      "prescaled_loss",
      "eval_micro_batches"
    ],
    "_create_module_forward_pre_hook": [
      "self"
    ],
    "_create_module_forward_post_hook": [
      "self"
    ],
    "_forward_prologue": [
      "self",
      "inputs",
      "kwargs"
    ],
    "_forward_epilogue": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "_cast_inputs_half": [
      "self",
      "inputs"
    ],
    "print_forward_breakdown": [
      "self",
      "fwd_time"
    ],
    "allreduce_gradients": [
      "self",
      "bucket_size"
    ],
    "_backward_prologue": [
      "self"
    ],
    "_backward_epilogue": [
      "self"
    ],
    "_backward_prologue_per_tensor": [
      "self",
      "grad"
    ],
    "_backward_post_hook": [
      "self"
    ],
    "no_sync": [
      "self"
    ],
    "scale": [
      "self",
      "loss"
    ],
    "backward": [
      "self",
      "loss",
      "retain_graph",
      "scale_wrt_gas"
    ],
    "is_gradient_accumulation_boundary": [
      "self"
    ],
    "set_gradient_accumulation_boundary": [
      "self",
      "is_boundary"
    ],
    "zero_grad": [
      "self"
    ],
    "clip_fp32_gradients": [
      "self"
    ],
    "_take_model_step": [
      "self",
      "lr_kwargs",
      "block_eigenvalue"
    ],
    "step": [
      "self",
      "lr_kwargs"
    ],
    "_start_timers": [
      "self",
      "timer_names"
    ],
    "_stop_timers": [
      "self",
      "timer_names"
    ],
    "_update_wall_clock_timers": [
      "self"
    ],
    "get_wall_clock_timers": [
      "self"
    ],
    "_autotuning_exit": [
      "self"
    ],
    "_write_monitor": [
      "self"
    ],
    "_get_optimizer_param": [
      "self",
      "param_name"
    ],
    "_get_optimizer_loss_scale": [
      "self"
    ],
    "get_lr": [
      "self"
    ],
    "get_type": [
      "self"
    ],
    "get_mom": [
      "self"
    ],
    "get_pld_theta": [
      "self"
    ],
    "_report_progress": [
      "self",
      "step"
    ],
    "allreduce_bucket": [
      "self",
      "bucket",
      "dp_group",
      "dp_world_size"
    ],
    "allreduce_and_copy": [
      "self",
      "small_bucket",
      "dp_group",
      "dp_world_size"
    ],
    "allreduce_no_retain": [
      "self",
      "bucket",
      "dp_group",
      "numel_per_bucket",
      "dp_world_size"
    ],
    "_get_gradients_for_reduction": [
      "self"
    ],
    "_reduce_non_expert_gradients": [
      "self",
      "grads",
      "elements_per_buffer"
    ],
    "_reduce_expert_gradients": [
      "self",
      "expert_grads",
      "elements_per_buffer"
    ],
    "buffered_allreduce_fallback": [
      "self",
      "grads",
      "elements_per_buffer"
    ],
    "sparse_allreduce_no_retain": [
      "self",
      "bucket",
      "dp_group",
      "dp_world_size"
    ],
    "sparse_allreduce_bucket": [
      "self",
      "bucket",
      "dp_group",
      "dp_world_size"
    ],
    "sparse_allreduce": [
      "self",
      "sparse",
      "dp_group",
      "dp_world_size"
    ],
    "sparse_all_gather": [
      "self",
      "value",
      "dp_group"
    ],
    "all_gather_scalar": [
      "self",
      "value",
      "dp_group"
    ],
    "module_state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars",
      "exclude_frozen_parameters"
    ],
    "load_moe_state_dict": [
      "checkpoint_path",
      "tag",
      "state_dict",
      "old_moe_load",
      "model",
      "mpu",
      "num_experts",
      "checkpoint_engine"
    ],
    "load_module_state_dict": [
      "self",
      "checkpoint",
      "strict",
      "custom_load_fn",
      "fetch_z3_params"
    ],
    "_get_zero_ckpt_prefix": [
      "self",
      "dp_rank",
      "bf16_mode"
    ],
    "_get_rank_zero_ckpt_name": [
      "self",
      "checkpoints_path",
      "tag",
      "mp_rank",
      "dp_rank",
      "bf16_mode"
    ],
    "_get_zero_ckpt_name": [
      "self",
      "checkpoints_path",
      "tag"
    ],
    "_get_ckpt_name": [
      "self",
      "checkpoints_path",
      "tag",
      "mp_placeholder",
      "pp_placeholder"
    ],
    "_get_optimizer_ckpt_name": [
      "self",
      "checkpoints_path",
      "tag",
      "expp_rank"
    ],
    "_get_expert_ckpt_name": [
      "checkpoints_path",
      "layer_id",
      "expert_id",
      "tag",
      "mpu"
    ],
    "_get_all_ckpt_names": [
      "self",
      "checkpoints_path",
      "tag"
    ],
    "load_checkpoint": [
      "self",
      "load_dir",
      "tag",
      "load_module_strict",
      "load_optimizer_states",
      "load_lr_scheduler_states",
      "load_module_only",
      "custom_load_fn"
    ],
    "_load_checkpoint": [
      "self",
      "load_dir",
      "tag",
      "load_module_strict",
      "load_optimizer_states",
      "load_lr_scheduler_states",
      "load_module_only",
      "custom_load_fn"
    ],
    "_load_zero_checkpoint": [
      "self",
      "load_dir",
      "tag",
      "load_optimizer_states"
    ],
    "_get_mp_rank_zero_checkpoint_names": [
      "self",
      "load_dir",
      "tag",
      "mp_rank",
      "dp_world_size",
      "bf16_mode"
    ],
    "_get_all_zero_checkpoint_names": [
      "self",
      "load_dir",
      "tag",
      "bf16_mode"
    ],
    "_get_all_zero_checkpoint_state_dicts": [
      "self",
      "zero_ckpt_names"
    ],
    "_get_all_zero_checkpoints": [
      "self",
      "load_dir",
      "tag"
    ],
    "_checkpoint_tag_validation": [
      "self",
      "tag"
    ],
    "save_checkpoint": [
      "self",
      "save_dir",
      "tag",
      "client_state",
      "save_latest",
      "exclude_frozen_parameters"
    ],
    "_commit_decoupled_checkpoint": [
      "self"
    ],
    "_get_non_moe_state_dict": [
      "self",
      "full_state_dict"
    ],
    "_save_moe_checkpoint": [
      "self",
      "save_dir",
      "tag",
      "client_state",
      "exclude_frozen_parameters"
    ],
    "_create_checkpoint_file": [
      "self",
      "save_dir",
      "tag",
      "zero_checkpoint"
    ],
    "_create_zero_checkpoint_files": [
      "self",
      "save_dir",
      "tag"
    ],
    "_save_checkpoint": [
      "self",
      "save_dir",
      "tag",
      "client_state",
      "exclude_frozen_parameters"
    ],
    "_get_buffer_names": [
      "self"
    ],
    "_get_param_shape_func": [
      "self",
      "param"
    ],
    "_get_param_fragment_func": [
      "self",
      "param"
    ],
    "_get_zero_frozen_param_attributes": [
      "self",
      "attr_func"
    ],
    "_get_zero_param_shapes": [
      "self"
    ],
    "_get_shared_params": [
      "self"
    ],
    "_copy_recovery_script": [
      "self",
      "save_path"
    ],
    "_change_recovery_script_permissions": [
      "self",
      "dst"
    ],
    "_save_zero_checkpoint": [
      "self",
      "save_path",
      "tag"
    ],
    "_replace_module_consolidated_state_dict": [
      "self"
    ],
    "_consolidated_16bit_state_dict": [
      "self",
      "exclude_frozen_parameters"
    ],
    "_zero3_consolidated_16bit_state_dict": [
      "self",
      "exclude_frozen_parameters"
    ],
    "save_fp16_model": [
      "self",
      "save_dir",
      "save_filename"
    ],
    "save_16bit_model": [
      "self",
      "save_dir",
      "save_filename",
      "exclude_frozen_parameters"
    ],
    "empty_partition_cache": [
      "self"
    ],
    "compile": [
      "self",
      "backend",
      "compile_kwargs",
      "schedule",
      "compiled_autograd_enabled"
    ],
    "_set_deepcompile_active": [
      "self",
      "active"
    ],
    "get_compile_time": [
      "self"
    ],
    "register_compile_pass": [
      "self",
      "pass_name",
      "pass_fn"
    ],
    "is_deepcompile_enabled": [
      "self"
    ],
    "is_deepcompile_active": [
      "self"
    ],
    "is_compiled": [
      "self"
    ],
    "offload_states": [
      "self",
      "include",
      "device",
      "pin_memory",
      "non_blocking"
    ],
    "reload_states": [
      "self",
      "non_blocking"
    ]
  },
  "ProgressiveLayerDrop": {
    "__init__": [
      "self",
      "theta",
      "gamma"
    ],
    "get_state": [
      "self"
    ],
    "get_theta": [
      "self"
    ],
    "update_state": [
      "self",
      "global_step"
    ]
  },
  "WeightQuantization": {
    "__init__": [
      "self",
      "mlp_extra_grouping",
      "mp_size"
    ],
    "quantize_data": [
      "self",
      "data",
      "quantize_bits",
      "groups",
      "key"
    ],
    "is_mlp": [
      "self",
      "data",
      "merge_count"
    ],
    "is_qkv": [
      "self",
      "data"
    ],
    "Quantize": [
      "self",
      "value_list",
      "quantize_bits",
      "groups",
      "key",
      "merge_dim"
    ],
    "merge_layer_scales": [
      "self",
      "layer_scales"
    ],
    "merge_scales": [
      "self"
    ],
    "merge_scales_split": [
      "self",
      "split_count"
    ],
    "sd_quantize_megatron": [
      "self",
      "sd",
      "quantize_bits",
      "groups"
    ],
    "model_quantize": [
      "self",
      "model",
      "quantize_policy",
      "quantize_bits",
      "groups"
    ]
  },
  "TENSOR_CORE_ALIGN_SIZE": [],
  "ADAGRAD_OPTIMIZER": [],
  "ADAM_OPTIMIZER": [],
  "ADAMW_OPTIMIZER": [],
  "LAMB_OPTIMIZER": [],
  "ONEBIT_ADAM_OPTIMIZER": [],
  "ZERO_ONE_ADAM_OPTIMIZER": [],
  "ONEBIT_LAMB_OPTIMIZER": [],
  "MUADAM_OPTIMIZER": [],
  "MUADAMW_OPTIMIZER": [],
  "MUSGD_OPTIMIZER": [],
  "LION_OPTIMIZER": [],
  "MUON_OPTIMIZER": [],
  "DEEPSPEED_OPTIMIZERS": [],
  "TORCH_ADAM_PARAM": [],
  "ADAM_W_MODE": [],
  "ADAM_W_MODE_DEFAULT": [],
  "DeepSpeedConfigError": {},
  "get_pld_enabled": [
    "param_dict"
  ],
  "get_pld_params": [
    "param_dict"
  ],
  "get_amp_enabled": [
    "param_dict"
  ],
  "get_amp_params": [
    "param_dict"
  ],
  "get_torch_autocast_enabled": [
    "param_dict"
  ],
  "get_torch_autocast_dtype": [
    "param_dict"
  ],
  "get_lower_precision_safe_modules": [
    "param_dict"
  ],
  "get_gradient_accumulation_steps": [
    "param_dict"
  ],
  "get_sparse_gradients_enabled": [
    "param_dict"
  ],
  "get_communication_data_type": [
    "param_dict",
    "comm_type",
    "comm_data_type_default"
  ],
  "get_prescale_gradients": [
    "param_dict"
  ],
  "get_gradient_predivide_factor": [
    "param_dict"
  ],
  "get_steps_per_print": [
    "param_dict"
  ],
  "get_disable_allgather": [
    "param_dict"
  ],
  "get_dump_state": [
    "param_dict"
  ],
  "get_gradient_clipping": [
    "param_dict"
  ],
  "get_graph_harvesting": [
    "param_dict"
  ],
  "get_sparse_attention": [
    "param_dict"
  ],
  "get_sparse_dense_config": [
    "sparsity"
  ],
  "get_sparse_fixed_config": [
    "sparsity"
  ],
  "get_sparse_variable_config": [
    "sparsity"
  ],
  "get_sparse_bigbird_config": [
    "sparsity"
  ],
  "get_sparse_bslongformer_config": [
    "sparsity"
  ],
  "get_sparse_attention_mode": [
    "param_dict"
  ],
  "get_sparse_attention_type": [
    "param_dict"
  ],
  "get_pipeline_config": [
    "param_dict"
  ],
  "get_optimizer_name": [
    "param_dict"
  ],
  "get_optimizer_params": [
    "param_dict"
  ],
  "get_optimizer_gradient_clipping": [
    "param_dict"
  ],
  "get_optimizer_legacy_fusion": [
    "param_dict"
  ],
  "get_zero_allow_untested_optimizer": [
    "param_dict"
  ],
  "get_zero_force_ds_cpu_optimizer": [
    "param_dict"
  ],
  "get_scheduler_name": [
    "param_dict"
  ],
  "get_scheduler_params": [
    "param_dict"
  ],
  "get_train_batch_size": [
    "param_dict"
  ],
  "get_train_micro_batch_size_per_gpu": [
    "param_dict"
  ],
  "get_wall_clock_breakdown": [
    "param_dict"
  ],
  "get_memory_breakdown": [
    "param_dict"
  ],
  "HybridEngineConfig": {},
  "get_hybrid_engine_config": [
    "param_dict"
  ],
  "get_expert_data_topo_config": [
    "param_dict"
  ],
  "get_eigenvalue_config": [
    "param_dict"
  ],
  "get_eigenvalue_enabled": [
    "param_dict"
  ],
  "get_eigenvalue_verbose": [
    "param_dict"
  ],
  "get_eigenvalue_max_iter": [
    "param_dict"
  ],
  "get_eigenvalue_tol": [
    "param_dict"
  ],
  "get_eigenvalue_stability": [
    "param_dict"
  ],
  "get_eigenvalue_gas_boundary_resolution": [
    "param_dict"
  ],
  "get_eigenvalue_layer_name": [
    "param_dict"
  ],
  "get_eigenvalue_layer_num": [
    "param_dict"
  ],
  "get_checkpoint_params": [
    "param_dict"
  ],
  "get_data_types_params": [
    "param_dict"
  ],
  "get_checkpoint_tag_validation_mode": [
    "checkpoint_params"
  ],
  "get_checkpoint_parallel_write_pipeline": [
    "checkpoint_params"
  ],
  "get_dataloader_drop_last": [
    "param_dict"
  ],
  "DeepSpeedConfigWriter": {
    "__init__": [
      "self",
      "data"
    ],
    "add_config": [
      "self",
      "key",
      "value"
    ],
    "load_config": [
      "self",
      "filename"
    ],
    "write_config": [
      "self",
      "filename"
    ]
  },
  "DeepSpeedConfig": {
    "__init__": [
      "self",
      "config",
      "mpu",
      "mesh_device"
    ],
    "_initialize_params": [
      "self",
      "param_dict"
    ],
    "_batch_assertion": [
      "self"
    ],
    "_set_batch_related_parameters": [
      "self"
    ],
    "_configure_train_batch_size": [
      "self"
    ],
    "_do_sanity_check": [
      "self"
    ],
    "print_user_config": [
      "self"
    ],
    "print": [
      "self",
      "name"
    ],
    "_do_error_check": [
      "self"
    ],
    "_do_warning_check": [
      "self"
    ]
  },
  "BFLOAT16_FORMAT": [],
  "BFLOAT16": [],
  "BFLOAT16_OLD": [],
  "get_bfloat16_config": [
    "param_dict"
  ],
  "DeepSpeedBF16Config": {},
  "FP16_FORMAT": [],
  "FP16": [],
  "get_float16_config": [
    "param_dict"
  ],
  "DeepSpeedFP16Config": {
    "initial_dynamic_scale": [
      "self"
    ],
    "dynamic_loss_scale_args": [
      "self"
    ]
  },
  "AUTO_MODULE_KEY": [],
  "SDLoaderFactory": {
    "get_sd_loader_json": [
      "json_file",
      "checkpoint_engine"
    ],
    "get_sd_loader": [
      "ckpt_list",
      "checkpoint_engine",
      "sd_type",
      "version"
    ]
  },
  "SDLoaderBase": {
    "__init__": [
      "self",
      "ckpt_list",
      "version",
      "checkpoint_engine"
    ],
    "load": [
      "self",
      "mp_world_size",
      "mp_rank",
      "module_key",
      "is_pipe_parallel",
      "quantize",
      "quantize_bits",
      "quantize_groups",
      "mlp_extra_grouping"
    ],
    "get_merge_state_dicts": [
      "self",
      "mp_world_size",
      "mp_rank"
    ],
    "get_split_state_dict": [
      "self",
      "mp_world_size",
      "mp_rank"
    ],
    "_choose_module_key": [
      "self",
      "sd"
    ],
    "get_module": [
      "self",
      "sd"
    ],
    "set_module": [
      "self",
      "sd",
      "module"
    ],
    "check_ckpt_list": [
      "self"
    ],
    "merge_state_dict": [
      "self",
      "mp_world_size",
      "mp_rank",
      "quantize",
      "quantize_bits",
      "groups",
      "mlp_extra_grouping"
    ],
    "split_state_dict": [
      "self",
      "mp_world_size",
      "mp_rank",
      "quantize",
      "quantize_bits",
      "groups",
      "mlp_extra_grouping"
    ],
    "sanity_check": [
      "self",
      "ckpt_file_name"
    ]
  },
  "MegatronSDLoader": {
    "__init__": [
      "self",
      "ckpt_list",
      "version",
      "checkpoint_engine"
    ],
    "merge_query_key_value": [
      "self",
      "param_list",
      "ckpt_ver"
    ],
    "split_query_key_value": [
      "self",
      "param",
      "num_to_split",
      "offset",
      "ckpt_ver"
    ],
    "merge_state_dict": [
      "self",
      "mp_world_size",
      "mp_rank",
      "quantize",
      "quantize_bits",
      "groups",
      "mlp_extra_grouping"
    ],
    "split_state_dict": [
      "self",
      "mp_world_size",
      "mp_rank",
      "quantize",
      "quantize_bits",
      "groups",
      "mlp_extra_grouping"
    ],
    "sanity_check": [
      "self",
      "ckpt_file_name"
    ],
    "get_checkpoint_version": [
      "self",
      "state_dict"
    ]
  },
  "Eigenvalue": {
    "__init__": [
      "self",
      "verbose",
      "max_iter",
      "tol",
      "stability",
      "gas_boundary_resolution",
      "layer_name",
      "layer_num"
    ],
    "nan_to_num": [
      "self",
      "x"
    ],
    "normalize": [
      "self",
      "v"
    ],
    "inner_product": [
      "self",
      "xs",
      "ys"
    ],
    "get_layers": [
      "self",
      "module"
    ],
    "compute_eigenvalue": [
      "self",
      "module",
      "device",
      "scale"
    ],
    "post_process": [
      "self",
      "value_list"
    ]
  },
  "is_compile_supported": [],
  "disable": [
    "func"
  ],
  "enable": [
    "min_version"
  ],
  "is_compiling": [],
  "compiled_autograd": [
    "enabled",
    "kwargs"
  ],
  "dummy_decorator": [
    "func"
  ],
  "compile": [],
  "BF16_Optimizer": {
    "__init__": [
      "self",
      "init_optimizer",
      "param_names",
      "bfloat16_config",
      "mpu",
      "clip_grad",
      "norm_type",
      "allgather_bucket_size",
      "dp_process_group",
      "timers",
      "grad_acc_dtype",
      "graph_harvesting",
      "has_moe_layers"
    ],
    "destroy": [
      "self"
    ],
    "_configure_moe_settings": [
      "self"
    ],
    "_setup_for_real_optimizer": [
      "self"
    ],
    "_enable_universal_checkpoint": [
      "self"
    ],
    "_create_param_mapping": [
      "self"
    ],
    "_link_all_hp_params": [
      "self"
    ],
    "_lazy_init_hp_params_optimizer_state": [
      "self"
    ],
    "_split_flat_tensor": [
      "self",
      "flat_tensor",
      "num_elem_list"
    ],
    "_update_storage_to_flattened_tensor": [
      "self",
      "tensor_list",
      "flat_tensor"
    ],
    "_flatten_dense_tensors_aligned": [
      "self",
      "tensor_list",
      "alignment"
    ],
    "step": [
      "self",
      "closure"
    ],
    "backward_prologue": [
      "self"
    ],
    "backward_epilogue": [
      "self",
      "update_hp_grads",
      "clear_lp_grads"
    ],
    "_update_hp_grad": [
      "self",
      "lp",
      "group_idx",
      "param_idx",
      "clear_lp_grads"
    ],
    "_update_hp_grads_func": [
      "self",
      "clear_lp_grads"
    ],
    "update_hp_grads": [
      "self",
      "clear_lp_grads"
    ],
    "get_grads_for_reduction": [
      "self"
    ],
    "get_grads_for_norm": [
      "self",
      "for_clipping"
    ],
    "update_lp_params": [
      "self"
    ],
    "clear_hp_grads": [
      "self"
    ],
    "clear_lp_grads": [
      "self",
      "set_to_none"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ],
    "state_dict": [
      "self"
    ],
    "_restore_from_bit16_weights": [
      "self"
    ],
    "refresh_fp32_params": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict_list",
      "checkpoint_folder",
      "load_optimizer_states",
      "load_from_fp32_weights",
      "load_serial",
      "param_shapes"
    ],
    "_load_legacy_checkpoint": [
      "self",
      "state_dict_list",
      "load_optimizer_states",
      "load_from_fp32_weights"
    ],
    "_load_universal_checkpoint": [
      "self",
      "checkpoint_folder",
      "load_optimizer_states",
      "load_from_fp32_weights"
    ],
    "_load_global_state": [
      "self",
      "sd"
    ],
    "param_groups": [
      "self"
    ],
    "state": [
      "self"
    ],
    "accumulate_hp_grads_and_remove_lp": [
      "self",
      "lp_param",
      "group_idx",
      "param_idx"
    ],
    "create_grad_acc_hooks": [
      "self"
    ]
  },
  "_get_padded_tensor": [
    "src_tensor",
    "size"
  ],
  "ROUTE_TRAIN": [],
  "ROUTE_EVAL": [],
  "ROUTE_PREDICT": [],
  "ROUTE_ENCODE": [],
  "TRAIN_BATCH_SIZE": [],
  "TRAIN_BATCH_SIZE_DEFAULT": [],
  "SPARSE_ATTENTION": [],
  "SPARSE_DENSE_MODE": [],
  "SPARSE_FIXED_MODE": [],
  "SPARSE_VARIABLE_MODE": [],
  "SPARSE_BIGBIRD_MODE": [],
  "SPARSE_BSLONGFORMER_MODE": [],
  "SPARSE_MODE": [],
  "SPARSE_MODE_DEFAULT": [],
  "SPARSE_BLOCK": [],
  "SPARSE_BLOCK_DEFAULT": [],
  "SPARSE_DIFFERENT_LAYOUT_PER_HEAD": [],
  "SPARSE_DIFFERENT_LAYOUT_PER_HEAD_DEFAULT": [],
  "SPARSE_NUM_LOCAL_BLOCKS": [],
  "SPARSE_NUM_LOCAL_BLOCKS_DEFAULT": [],
  "SPARSE_NUM_GLOBAL_BLOCKS": [],
  "SPARSE_NUM_GLOBAL_BLOCKS_DEFAULT": [],
  "SPARSE_ATTENTION_TYPE": [],
  "SPARSE_ATTENTION_TYPE_DEFAULT": [],
  "SPARSE_HORIZONTAL_GLOBAL_ATTENTION": [],
  "SPARSE_HORIZONTAL_GLOBAL_ATTENTION_DEFAULT": [],
  "SPARSE_NUM_DIFFERENT_GLOBAL_PATTERNS": [],
  "SPARSE_NUM_DIFFERENT_GLOBAL_PATTERNS_DEFAULT": [],
  "SPARSE_NUM_RANDOM_BLOCKS": [],
  "SPARSE_NUM_RANDOM_BLOCKS_DEFAULT": [],
  "SPARSE_LOCAL_WINDOW_BLOCKS": [],
  "SPARSE_LOCAL_WINDOW_BLOCKS_DEFAULT": [],
  "SPARSE_GLOBAL_BLOCK_INDICES": [],
  "SPARSE_GLOBAL_BLOCK_INDICES_DEFAULT": [],
  "SPARSE_GLOBAL_BLOCK_END_INDICES": [],
  "SPARSE_GLOBAL_BLOCK_END_INDICES_DEFAULT": [],
  "SPARSE_NUM_SLIDING_WINDOW_BLOCKS": [],
  "SPARSE_NUM_SLIDING_WINDOW_BLOCKS_DEFAULT": [],
  "OPTIMIZER": [],
  "OPTIMIZER_TYPE_DEFAULT": [],
  "OPTIMIZER_PARAMS": [],
  "TYPE": [],
  "LEGACY_FUSION": [],
  "LEGACY_FUSION_DEFAULT": [],
  "SCHEDULER": [],
  "SCHEDULER_TYPE_DEFAULT": [],
  "SCHEDULER_PARAMS": [],
  "MAX_GRAD_NORM": [],
  "ZERO_ALLOW_UNTESTED_OPTIMIZER": [],
  "ZERO_ALLOW_UNTESTED_OPTIMIZER_DEFAULT": [],
  "ZERO_FORCE_DS_CPU_OPTIMIZER": [],
  "ZERO_FORCE_DS_CPU_OPTIMIZER_DEFAULT": [],
  "STEPS_PER_PRINT": [],
  "STEPS_PER_PRINT_DEFAULT": [],
  "TRAIN_MICRO_BATCH_SIZE_PER_GPU": [],
  "TRAIN_MICRO_BATCH_SIZE_PER_GPU_DEFAULT": [],
  "GRADIENT_ACCUMULATION_FORMAT": [],
  "GRADIENT_ACCUMULATION_STEPS": [],
  "GRADIENT_ACCUMULATION_STEPS_DEFAULT": [],
  "SPARSE_GRADIENTS": [],
  "SPARSE_GRADIENTS_DEFAULT": [],
  "BFLOAT16_ENABLED": [],
  "BFLOAT16_ENABLED_DEFAULT": [],
  "CHECK_OVERFLOW": [],
  "BFLOAT16_CHECK_OVERFLOW_DEFAULT": [],
  "BFLOAT16_IMMEDIATE_GRAD_UPDATE": [],
  "BFLOAT16_IMMEDIATE_GRAD_UPDATE_DEFAULT": [],
  "BFLOAT16_MASTER_WEIGHTS_AND_GRADS": [],
  "BFLOAT16_MASTER_WEIGHTS_AND_GRADS_DEFAULT": [],
  "BFLOAT16_OPTIMIZER_STATES": [],
  "BFLOAT16_OPTIMIZER_STATES_DEFAULT": [],
  "DDP_BFLOAT16": [],
  "FP16_ENABLED": [],
  "FP16_ENABLED_DEFAULT": [],
  "FP16_LOSS_SCALE": [],
  "FP16_LOSS_SCALE_DEFAULT": [],
  "FP16_AUTO_CAST": [],
  "FP16_AUTO_CAST_DEFAULT": [],
  "FP16_INITIAL_SCALE_POWER": [],
  "FP16_INITIAL_SCALE_POWER_DEFAULT": [],
  "FP16_LOSS_SCALE_WINDOW": [],
  "FP16_LOSS_SCALE_WINDOW_DEFAULT": [],
  "FP16_HYSTERESIS": [],
  "FP16_HYSTERESIS_DEFAULT": [],
  "FP16_CONSECUTIVE_HYSTERESIS": [],
  "FP16_CONSECUTIVE_HYSTERESIS_DEFAULT": [],
  "FP16_MIN_LOSS_SCALE": [],
  "FP16_MIN_LOSS_SCALE_DEFAULT": [],
  "FP16_MASTER_WEIGHTS_AND_GRADS": [],
  "FP16_MASTER_WEIGHTS_AND_GRADS_DEFAULT": [],
  "AMP_FORMAT": [],
  "AMP": [],
  "AMP_ENABLED": [],
  "AMP_ENABLED_DEFAULT": [],
  "TORCH_AUTOCAST_FORMAT": [],
  "TORCH_AUTOCAST": [],
  "TORCH_AUTOCAST_ENABLED": [],
  "TORCH_AUTOCAST_ENABLED_DEFAULT": [],
  "TORCH_AUTOCAST_LOWER_PRECISION_SAFE_MODULES": [],
  "GRADIENT_CLIPPING_FORMAT": [],
  "GRADIENT_CLIPPING": [],
  "GRADIENT_CLIPPING_DEFAULT": [],
  "GRAPH_HARVESTING_FORMAT": [],
  "GRAPH_HARVESTING": [],
  "GRAPH_HARVESTING_DEFAULT": [],
  "COMMUNICATION_DATA_TYPE_FORMAT": [],
  "COMMUNICATION_DATA_TYPE": [],
  "COMMUNICATION_DATA_TYPE_DEFAULT": [],
  "SEQ_PARALLEL_COMMUNICATION_DATA_TYPE_FORMAT": [],
  "SEQ_PARALLEL_COMMUNICATION_DATA_TYPE": [],
  "SEQ_PARALLEL_COMMUNICATION_DATA_TYPE_DEFAULT": [],
  "PRESCALE_GRADIENTS_FORMAT": [],
  "PRESCALE_GRADIENTS": [],
  "PRESCALE_GRADIENTS_DEFAULT": [],
  "GRADIENT_PREDIVIDE_FACTOR_FORMAT": [],
  "GRADIENT_PREDIVIDE_FACTOR": [],
  "GRADIENT_PREDIVIDE_FACTOR_DEFAULT": [],
  "DISABLE_ALLGATHER_FORMAT": [],
  "DISABLE_ALLGATHER": [],
  "DISABLE_ALLGATHER_DEFAULT": [],
  "DUMP_STATE_FORMAT": [],
  "DUMP_STATE": [],
  "DUMP_STATE_DEFAULT": [],
  "VOCABULARY_SIZE_FORMAT": [],
  "VOCABULARY_SIZE": [],
  "VOCABULARY_SIZE_DEFAULT": [],
  "WALL_CLOCK_BREAKDOWN_FORMAT": [],
  "WALL_CLOCK_BREAKDOWN": [],
  "WALL_CLOCK_BREAKDOWN_DEFAULT": [],
  "MEMORY_BREAKDOWN": [],
  "MEMORY_BREAKDOWN_DEFAULT": [],
  "EIGENVALUE_FORMAT": [],
  "EIGENVALUE": [],
  "EIGENVALUE_ENABLED": [],
  "EIGENVALUE_ENABLED_DEFAULT": [],
  "EIGENVALUE_VERBOSE": [],
  "EIGENVALUE_VERBOSE_DEFAULT": [],
  "EIGENVALUE_MAX_ITER": [],
  "EIGENVALUE_MAX_ITER_DEFAULT": [],
  "EIGENVALUE_TOL": [],
  "EIGENVALUE_TOL_DEFAULT": [],
  "EIGENVALUE_STABILITY": [],
  "EIGENVALUE_STABILITY_DEFAULT": [],
  "EIGENVALUE_GAS_BOUNDARY_RESOLUTION": [],
  "EIGENVALUE_GAS_BOUNDARY_RESOLUTION_DEFAULT": [],
  "EIGENVALUE_LAYER_NAME": [],
  "EIGENVALUE_LAYER_NAME_DEFAULT": [],
  "EIGENVALUE_LAYER_NUM": [],
  "EIGENVALUE_LAYER_NUM_DEFAULT": [],
  "PROGRESSIVE_LAYER_DROP": [],
  "PLD_ENABLED": [],
  "PLD_ENABLED_DEFAULT": [],
  "PLD_THETA": [],
  "PLD_THETA_DEFAULT": [],
  "PLD_GAMMA": [],
  "PLD_GAMMA_DEFAULT": [],
  "ValidationMode": {
    "WARN": [],
    "IGNORE": [],
    "FAIL": []
  },
  "CHECKPOINT": [],
  "CHECKPOINT_TAG_VALIDATION": [],
  "CHECKPOINT_TAG_VALIDATION_DEFAULT": [],
  "CHECKPOINT_TAG_VALIDATION_MODES": [],
  "LOAD_UNIVERSAL_CHECKPOINT": [],
  "LOAD_UNIVERSAL_CHECKPOINT_DEFAULT": [],
  "USE_NODE_LOCAL_STORAGE_CHECKPOINT": [],
  "USE_NODE_LOCAL_STORAGE_CHECKPOINT_DEFAULT": [],
  "CHECKPOINT_PARALLEL_WRITE": [],
  "CHECKPOINT_PARALLEL_WRITE_PIPELINE_STAGE": [],
  "CHECKPOINT_PARALLEL_WRITE_PIPELINE_STAGE_DEFAULT": [],
  "DATA_TYPES": [],
  "GRAD_ACCUM_DTYPE": [],
  "GRAD_ACCUM_DTYPE_DEFAULT": [],
  "DATALOADER_DROP_LAST_FORMAT": [],
  "DATALOADER_DROP_LAST": [],
  "DATALOADER_DROP_LAST_DEFAULT": [],
  "PIPE_REPLICATED": [],
  "DATA_PARALLEL_GROUP": [],
  "GLOBAL_RANK": [],
  "USE_DATA_BEFORE_EXPERT_PARALLEL": [],
  "USE_DATA_BEFORE_EXPERT_PARALLEL_DEFAULT": [],
  "RepeatingLoader": {
    "__init__": [
      "self",
      "loader"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ]
  },
  "DeepSpeedDataLoader": {
    "__init__": [
      "self",
      "dataset",
      "batch_size",
      "pin_memory",
      "local_rank",
      "tput_timer",
      "collate_fn",
      "num_local_io_workers",
      "data_sampler",
      "data_parallel_world_size",
      "data_parallel_rank",
      "dataloader_drop_last",
      "deepspeed_dataloader_config"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "_create_dataloader": [
      "self"
    ]
  },
  "_torch_reduce_scatter_fn": [
    "input_tensor",
    "output_tensor",
    "group",
    "async_op",
    "prof"
  ],
  "all_to_all_quant_reduce": [
    "tensors",
    "groups"
  ],
  "all_to_all_loco_quant_reduce": [
    "params",
    "groups",
    "loco_param"
  ],
  "reduce_scatter_coalesced": [
    "tensors",
    "group"
  ],
  "check_and_handle_empty_buffer": [
    "buffer_m",
    "original_shape",
    "original_size",
    "worker_error",
    "server_error"
  ],
  "HcclBackend": {
    "__init__": [
      "self",
      "mpu"
    ],
    "my_igather": [
      "self",
      "rank",
      "size",
      "group",
      "sendbuf",
      "recvbuf",
      "root"
    ],
    "my_gather": [
      "self",
      "rank",
      "size",
      "group",
      "sendbuf",
      "recvbuf",
      "root"
    ],
    "compressed_allreduce": [
      "self",
      "buffer_m",
      "worker_error",
      "server_error",
      "local_rank"
    ]
  },
  "MpiBackend": {
    "__init__": [
      "self",
      "cuda_aware"
    ],
    "my_igather": [
      "self",
      "rank",
      "size",
      "comm",
      "sendbuf",
      "recbuf",
      "root"
    ],
    "gather_cuda": [
      "self",
      "rank",
      "world_size",
      "comm",
      "cupy_sign_list_packed",
      "cupy_recvbuf_sign",
      "cupy_worker_scale",
      "cupy_recvbuf_scale"
    ],
    "gather_host": [
      "self",
      "rank",
      "world_size",
      "comm",
      "cupy_sign_list_packed",
      "cupy_recvbuf_sign",
      "cupy_worker_scale",
      "cupy_recvbuf_scale"
    ],
    "allgather_cuda": [
      "self",
      "comm",
      "cupy_server_sign_packed",
      "cupy_recvbuf_sign_server",
      "cupy_server_scale",
      "cupy_recvbuf_scale_server"
    ],
    "allgather_host": [
      "self",
      "comm",
      "cupy_server_sign_packed",
      "cupy_recvbuf_sign_server",
      "cupy_server_scale",
      "cupy_recvbuf_scale_server"
    ],
    "compressed_allreduce": [
      "self",
      "buffer_m",
      "worker_error",
      "server_error",
      "local_rank"
    ]
  },
  "CompressedBackend": {
    "__init__": [
      "self",
      "mpu"
    ],
    "my_igather": [
      "self",
      "rank",
      "size",
      "group",
      "sendbuf",
      "recvbuf",
      "root"
    ],
    "my_gather": [
      "self",
      "rank",
      "size",
      "group",
      "sendbuf",
      "recvbuf",
      "root"
    ],
    "pack": [
      "self",
      "buffer",
      "size"
    ],
    "unpack": [
      "self",
      "buffer",
      "size",
      "dtype"
    ],
    "compressed_allreduce": [
      "self",
      "buffer_m",
      "worker_error",
      "server_error",
      "local_rank"
    ]
  },
  "NcclBackend": {
    "__init__": [
      "self",
      "mpu"
    ],
    "my_igather": [
      "self",
      "rank",
      "size",
      "group",
      "sendbuf",
      "recvbuf",
      "root"
    ],
    "my_gather": [
      "self",
      "rank",
      "size",
      "group",
      "sendbuf",
      "recvbuf",
      "root"
    ],
    "compressed_allreduce": [
      "self",
      "buffer_m",
      "worker_error",
      "server_error",
      "local_rank"
    ]
  },
  "FWD_MODULE_STACK": [],
  "_apply_forward_and_backward_to_tensors_only": [
    "module",
    "forward_function",
    "backward_function",
    "outputs"
  ],
  "ZeROOrderedDict": {
    "__init__": [
      "self",
      "parent_module"
    ],
    "__reduce__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ]
  },
  "_inject_parameters": [
    "module",
    "cls"
  ],
  "DeepSpeedZeRoOffload": {
    "__init__": [
      "self",
      "module",
      "timers",
      "ds_config",
      "zenflow",
      "overlap_comm",
      "prefetch_bucket_size",
      "max_reuse_distance",
      "max_live_parameters",
      "param_persistence_threshold",
      "model_persistence_threshold",
      "dp_process_group",
      "offload_param_config",
      "mpu",
      "zero_param_parallel_group",
      "zero_quantized_weights",
      "zero_quantized_nontrainable_weights",
      "zero_module_granularity_threshold",
      "log_trace_cache_warnings"
    ],
    "partition_all_parameters": [
      "self"
    ],
    "get_param_coordinator": [
      "self"
    ],
    "empty_partition_cache": [
      "self"
    ],
    "_convert_to_zero_parameters": [
      "self",
      "ds_config",
      "module",
      "mpu"
    ],
    "destroy": [
      "self"
    ],
    "_remove_module_hooks": [
      "self"
    ],
    "setup_zero_stage3_hooks": [
      "self"
    ],
    "mark_persistent_parameters": [
      "self",
      "param_threshold",
      "model_threshold"
    ],
    "_register_deepspeed_module": [
      "self",
      "module",
      "count"
    ],
    "pre_sub_module_forward_function": [
      "self",
      "sub_module"
    ],
    "post_sub_module_forward_function": [
      "self",
      "sub_module"
    ],
    "pre_sub_module_backward_function": [
      "self",
      "sub_module"
    ],
    "post_sub_module_backward_function": [
      "self",
      "sub_module"
    ],
    "_set_z3_leaf_modules_by_threshold": [
      "self",
      "module",
      "zero_module_granularity_threshold"
    ],
    "_get_granularity_recursively": [
      "self",
      "module"
    ],
    "_set_leaf_by_threshold_preorder": [
      "self",
      "module",
      "granularity_treshhold"
    ]
  },
  "test1": [],
  "test2": [],
  "ContiguousMemoryAllocator": {
    "__init__": [
      "self",
      "size",
      "dtype",
      "device"
    ],
    "allocate_tensor": [
      "self",
      "size"
    ],
    "assign_to_param": [
      "self",
      "tensor",
      "param",
      "numel",
      "shape"
    ],
    "release_tensor": [
      "self",
      "tensor"
    ],
    "release_tensor_with_id": [
      "self",
      "tensor_id"
    ],
    "print_allocation": [
      "self",
      "resolution"
    ],
    "max_allocated": [
      "self"
    ],
    "_reset_param_data": [
      "self"
    ],
    "_unassign_params": [
      "self",
      "tensor_id"
    ],
    "_release_tensor": [
      "self",
      "tensor_id"
    ],
    "_consolidate_address": [
      "self",
      "address",
      "contiguous_size"
    ],
    "_defragment_memory": [
      "self"
    ],
    "_replace_old_address_with_new": [
      "self",
      "tensor_id",
      "new_address"
    ],
    "_get_new_tensor_address": [
      "self",
      "size"
    ],
    "_get_new_tensor": [
      "self",
      "address",
      "size"
    ],
    "_largest_contiguous": [
      "self"
    ],
    "_mark_as_occupied": [
      "self",
      "address",
      "size"
    ]
  },
  "DeepSpeedZeroLeafModuleConfig": {
    "_coerce_container_types": [
      "cls",
      "values"
    ],
    "_validate_entries": [
      "self"
    ]
  },
  "pg_correctness_test": [],
  "OPTIMIZER_ALLGATHER_TIMER": [],
  "OPTIMIZER_GRADIENTS_TIMER": [],
  "OPTIMIZER_STEP_TIMER": [],
  "OPTIMIZER_TIMERS": [],
  "INITIAL_MICRO_STEP_ID": [],
  "input": [
    "msg"
  ],
  "split_half_float_double": [
    "tensors"
  ],
  "isclose": [
    "a",
    "b",
    "rtol",
    "atol"
  ],
  "lcm": [
    "x",
    "y"
  ],
  "get_alignment_padding": [
    "tensor_list",
    "alignment"
  ],
  "print_rank_msg": [
    "msg"
  ],
  "_pad_tensor_by_size": [
    "src_tensor",
    "pad_size",
    "dtype",
    "device"
  ],
  "IPGBucket": {
    "clear": [
      "self"
    ]
  },
  "DeepSpeedZeroOptimizer": {
    "__init__": [
      "self",
      "init_optimizer",
      "param_names",
      "timers",
      "optimizer_params",
      "static_loss_scale",
      "dynamic_loss_scale",
      "dynamic_loss_args",
      "verbose",
      "contiguous_gradients",
      "reduce_bucket_size",
      "use_multi_rank_bucket_allreduce",
      "allgather_bucket_size",
      "dp_process_group",
      "expert_parallel_group",
      "expert_data_parallel_group",
      "reduce_scatter",
      "overlap_comm",
      "offload_optimizer_config",
      "zenflow_config",
      "mpu",
      "clip_grad",
      "gradient_accumulation_dtype",
      "communication_data_type",
      "postscale_gradients",
      "gradient_predivide_factor",
      "gradient_accumulation_steps",
      "ignore_unused_parameters",
      "partition_grads",
      "round_robin_gradients",
      "has_moe_layers",
      "fp16_master_weights_and_gradients",
      "bf16_master_weights_and_gradients",
      "bf16_optimizer_states",
      "elastic_checkpoint",
      "check_grad_overflow"
    ],
    "destroy": [
      "self"
    ],
    "_enable_universal_checkpoint": [
      "self"
    ],
    "_create_param_mapping": [
      "self"
    ],
    "_create_optimizer_mapping": [
      "self"
    ],
    "_link_all_hp_params": [
      "self"
    ],
    "_lazy_init_hp_params_optimizer_state": [
      "self"
    ],
    "is_moe_group": [
      "self",
      "group"
    ],
    "_configure_moe_settings": [
      "self"
    ],
    "_update_model_bit16_weights": [
      "self",
      "group_index"
    ],
    "_round_robin_reorder": [
      "self",
      "tensor_list",
      "num_partitions"
    ],
    "_release_ipg_buffers": [
      "self"
    ],
    "initialize_optimizer_states": [
      "self"
    ],
    "reduce_gradients": [
      "self",
      "pipeline_parallel"
    ],
    "get_first_param_index": [
      "self",
      "group_id",
      "param_group",
      "partition_id"
    ],
    "initialize_gradient_partitioning_data_structures": [
      "self"
    ],
    "independent_gradient_partition_epilogue": [
      "self"
    ],
    "clear_backward_seen_flag": [
      "self"
    ],
    "reset_partition_gradient_structures": [
      "self"
    ],
    "initialize_gradient_partition": [
      "self",
      "i",
      "param_group",
      "partition_id"
    ],
    "overlapping_partition_gradients_reduce_epilogue": [
      "self"
    ],
    "_fill_param_grad_accum_attribute": [
      "self",
      "param"
    ],
    "fill_grad_accum_attribute": [
      "self"
    ],
    "get_gradient_for_reduction": [
      "self",
      "param"
    ],
    "get_param_gradient_attribute": [
      "self",
      "param"
    ],
    "clear_grad_attribute": [
      "self",
      "param"
    ],
    "create_gradient_handling_hooks": [
      "self"
    ],
    "get_param_id": [
      "self",
      "param"
    ],
    "flatten_dense_tensors_aligned": [
      "self",
      "tensor_list",
      "alignment",
      "use_cpu_data"
    ],
    "reduce_independent_p_g_buckets_and_remove_grads": [
      "self",
      "param",
      "i"
    ],
    "print_rank_0": [
      "self",
      "message"
    ],
    "gradient_reduction_w_predivide": [
      "self",
      "tensor",
      "communication_data_type"
    ],
    "allreduce_and_copy_with_multiple_ranks": [
      "self",
      "small_bucket",
      "communication_data_type",
      "log",
      "divide",
      "process_group",
      "bucket_ranks"
    ],
    "allreduce_and_scatter": [
      "self",
      "bucket",
      "communication_data_type",
      "numel_per_bucket",
      "log",
      "divide",
      "process_group"
    ],
    "average_tensor": [
      "self",
      "tensor",
      "communication_data_type"
    ],
    "get_grad_position": [
      "self",
      "group_id",
      "tensor_list",
      "first_offset",
      "partition_size"
    ],
    "update_offload_overflow_tracker": [
      "self",
      "grad"
    ],
    "update_offload_overflow_tracker_for_param_grad": [
      "self",
      "param"
    ],
    "_get_offload_gradient_dict": [
      "self"
    ],
    "async_accumulate_grad_in_cpu_via_gpu": [
      "self",
      "param"
    ],
    "set_norm_for_param_grad": [
      "self",
      "param"
    ],
    "set_norm_for_param_grad_in_gpu": [
      "self",
      "param"
    ],
    "async_inplace_copy_grad_to_fp32_buffer_from_gpu": [
      "self",
      "param"
    ],
    "complete_grad_norm_calculation_for_cpu_offload": [
      "self",
      "params"
    ],
    "copy_grads_in_partition": [
      "self",
      "param"
    ],
    "reduce_ipg_grads": [
      "self",
      "comm_dtype"
    ],
    "process_gradients": [
      "self",
      "param",
      "i"
    ],
    "reduce_ready_partitions_and_remove_grads": [
      "self",
      "param",
      "i"
    ],
    "zero_reduced_gradients": [
      "self",
      "partition_id",
      "i"
    ],
    "flatten_and_print": [
      "self",
      "message",
      "tensors",
      "start",
      "n"
    ],
    "get_grads_to_reduce": [
      "self",
      "i",
      "partition_id"
    ],
    "sequential_execution": [
      "self",
      "function",
      "message",
      "group"
    ],
    "set_none_gradients_to_zero": [
      "self",
      "i",
      "partition_id"
    ],
    "allreduce_bucket": [
      "self",
      "bucket",
      "communication_data_type",
      "rank",
      "log",
      "divide",
      "process_group"
    ],
    "_clear_previous_reduced_grads": [
      "self"
    ],
    "allreduce_and_copy": [
      "self",
      "small_bucket",
      "communication_data_type",
      "rank",
      "log",
      "divide",
      "process_group"
    ],
    "allreduce_no_retain": [
      "self",
      "bucket",
      "communication_data_type",
      "numel_per_bucket",
      "rank",
      "log",
      "divide",
      "process_group"
    ],
    "buffered_reduce_fallback": [
      "self",
      "rank",
      "grads",
      "communication_data_type",
      "elements_per_buffer",
      "log"
    ],
    "get_data_parallel_partitions": [
      "self",
      "tensor",
      "group_id"
    ],
    "get_partition_info": [
      "self",
      "tensor_list",
      "partition_size",
      "partition_id"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ],
    "_clear_param_grad_only": [
      "self"
    ],
    "_model_parallel_all_reduce": [
      "self",
      "tensor",
      "op"
    ],
    "get_grad_norm_direct": [
      "self",
      "gradients",
      "params",
      "norm_type"
    ],
    "get_all_grad_tensors": [
      "self",
      "tensor_list",
      "dtype"
    ],
    "get_flat_partition": [
      "self",
      "tensor_list",
      "first_offset",
      "partition_size",
      "dtype",
      "device",
      "param_group_idx",
      "return_tensor_list"
    ],
    "free_grad_in_param_list": [
      "self",
      "param_list"
    ],
    "reset_cpu_buffers": [
      "self"
    ],
    "set_lr": [
      "self",
      "lr"
    ],
    "get_lr": [
      "self"
    ],
    "override_loss_scale": [
      "self",
      "loss_scale"
    ],
    "scaled_global_norm": [
      "self",
      "norm_type"
    ],
    "get_bit16_param_group": [
      "self",
      "group_no"
    ],
    "_optimizer_step": [
      "self",
      "group_no"
    ],
    "step": [
      "self",
      "closure"
    ],
    "update_lp_params": [
      "self"
    ],
    "_average_expert_grad_norms": [
      "self",
      "norm_groups"
    ],
    "unscale_and_clip_grads": [
      "self",
      "grad_groups_flat",
      "total_norm"
    ],
    "_check_overflow": [
      "self",
      "partition_gradients"
    ],
    "has_overflow_serial": [
      "self",
      "params"
    ],
    "has_overflow_partitioned_grads_serial": [
      "self"
    ],
    "has_overflow": [
      "self",
      "partition_gradients"
    ],
    "_has_inf_or_nan": [
      "x",
      "j"
    ],
    "setup_buckets": [
      "self"
    ],
    "backward_epilogue": [
      "self"
    ],
    "check_overflow": [
      "self",
      "partition_gradients"
    ],
    "_update_scale": [
      "self",
      "has_overflow"
    ],
    "_get_state": [
      "self"
    ],
    "_set_state": [
      "self",
      "value"
    ],
    "state": [],
    "_get_param_groups": [
      "self"
    ],
    "_set_param_groups": [
      "self",
      "value"
    ],
    "param_groups": [],
    "_get_loss_scale": [
      "self"
    ],
    "_set_loss_scale": [
      "self",
      "value"
    ],
    "loss_scale": [],
    "cur_scale": [],
    "_get_groups_without_padding": [
      "self",
      "groups_with_padding"
    ],
    "_get_state_without_padding": [
      "self",
      "state_with_padding",
      "padding"
    ],
    "_get_base_optimizer_state": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "_restore_from_elastic_fp32_weights": [
      "self",
      "all_state_dict"
    ],
    "_restore_from_bit16_weights": [
      "self"
    ],
    "refresh_fp32_params": [
      "self"
    ],
    "_partition_base_optimizer_state": [
      "self",
      "state_key",
      "all_partition_states",
      "group_id"
    ],
    "_restore_step_from_elastic_checkpoint": [
      "self",
      "all_state_dict"
    ],
    "_restore_base_optimizer_state": [
      "self",
      "base_optimizer_group_states",
      "base_optimizer_state_step",
      "group_paddings"
    ],
    "get_ep_ranks": [
      "self",
      "rank",
      "group_name"
    ],
    "_restore_elastic_base_optimizer_state": [
      "self",
      "all_state_dict"
    ],
    "load_state_dict": [
      "self",
      "state_dict_list",
      "load_optimizer_states",
      "load_from_fp32_weights",
      "checkpoint_folder",
      "load_serial",
      "param_shapes"
    ],
    "_load_universal_checkpoint": [
      "self",
      "checkpoint_folder",
      "load_optimizer_states",
      "load_from_fp32_weights"
    ],
    "_load_global_state": [
      "self",
      "sd"
    ],
    "_load_legacy_checkpoint": [
      "self",
      "state_dict_list",
      "load_optimizer_states",
      "load_from_fp32_weights"
    ],
    "_clear_hp_buffer_references": [
      "self"
    ],
    "_clear_lp_params_references": [
      "self"
    ],
    "offload_states": [
      "self",
      "include",
      "device",
      "pin_memory",
      "non_blocking"
    ],
    "reload_states": [
      "self",
      "non_blocking"
    ]
  },
  "estimate_zero2_model_states_mem_needs": [
    "total_params",
    "num_gpus_per_node",
    "num_nodes",
    "cpu_offload",
    "additional_buffer_factor"
  ],
  "model_to_params": [
    "model"
  ],
  "estimate_zero2_model_states_mem_needs_all_live": [
    "model",
    "num_gpus_per_node",
    "num_nodes",
    "additional_buffer_factor"
  ],
  "estimate_zero2_model_states_mem_needs_all_cold": [
    "total_params",
    "num_gpus_per_node",
    "num_nodes",
    "additional_buffer_factor"
  ],
  "warned": [],
  "_initialize_parameter_parallel_groups": [
    "parameter_parallel_size"
  ],
  "ZeRORuntimeException": {},
  "ZERO_SUPPORTED_OPTIMIZERS": [],
  "is_zero_supported_optimizer": [
    "optimizer"
  ],
  "assert_lst_len_same_as_other_ranks": [
    "lst"
  ],
  "get_lst_from_rank0": [
    "lst"
  ],
  "assert_ints_same_as_other_ranks": [
    "ints"
  ],
  "is_builtin_type": [
    "obj"
  ],
  "isinstance_namedtuple": [
    "obj"
  ],
  "is_zero_param": [
    "parameter"
  ],
  "apply_to_tensors_only": [
    "function",
    "value",
    "warning_msg_fn"
  ],
  "get_mapping_to_flat_buffer": [
    "tensors"
  ],
  "partitioned_param_data_shape": [],
  "zero_init_context": [],
  "top_level_context": [],
  "DeepSpeedTensorOverride": {
    "dtype": [],
    "device": []
  },
  "DEFAULT_TENSOR_OVERRIDES": [],
  "get_allgather_dtype": [
    "param",
    "param_ds_tensor"
  ],
  "NoGatherHandle": {
    "__init__": [
      "self",
      "param"
    ],
    "wait": [
      "self"
    ]
  },
  "NoGatherCoalescedHandle": {
    "__init__": [
      "self",
      "params"
    ],
    "wait": [
      "self"
    ]
  },
  "_dist_allgather_fn": [
    "input_tensor",
    "output_tensor",
    "group"
  ],
  "debug_rank0": [
    "msg"
  ],
  "_init_external_params": [
    "module"
  ],
  "register_external_parameter": [
    "module",
    "parameter"
  ],
  "unregister_external_parameter": [
    "module",
    "parameter"
  ],
  "ZeroParamType": {
    "NORMAL": [],
    "PARTITIONED": [],
    "REMOTE": []
  },
  "ZeroParamStatus": {
    "AVAILABLE": [],
    "NOT_AVAILABLE": [],
    "INFLIGHT": []
  },
  "_orig_torch_tensor": [],
  "_orig_torch_empty": [],
  "_orig_torch_zeros": [],
  "_orig_torch_ones": [],
  "_orig_torch_full": [],
  "_orig_torch_arange": [],
  "_orig_torch_eye": [],
  "_orig_torch_randn": [],
  "zero_wrapper_for_fp_tensor_constructor": [
    "fn",
    "target_fp_dtype",
    "target_device"
  ],
  "get_new_tensor_fn_for_dtype": [
    "target_fp_dtype",
    "target_device"
  ],
  "get_all_subclasses": [
    "cls",
    "include_root"
  ],
  "free_param": [
    "param"
  ],
  "reuse_buffers": [],
  "temp_contiguous_tensor": [],
  "empty_buffers": [],
  "InsertPostInitMethodToModuleSubClasses": {
    "num_module_parameters": [],
    "num_module_elements": [],
    "__init__": [
      "self",
      "enabled",
      "mem_efficient_linear",
      "ds_config",
      "dtype"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "_post_init_method": [
      "self",
      "module"
    ],
    "_set_dtype": [
      "self",
      "ds_config",
      "dtype"
    ],
    "patch_init_and_builtins": [
      "self"
    ],
    "unpatch_init_and_builtins": [
      "self"
    ],
    "_add_tensor_creation_wrappers": [
      "self"
    ],
    "_remove_tensor_creation_wrappers": [
      "self"
    ]
  },
  "shutdown_init_context": [],
  "restore_init_context": [],
  "AllGatherHandle": {
    "__init__": [
      "self",
      "handle",
      "param",
      "quantization",
      "param_buffer",
      "original_dtype"
    ],
    "wait": [
      "self",
      "handle_dependency"
    ]
  },
  "AllGatherCoalescedHandle": {
    "data_buffer": [],
    "__init__": [
      "self",
      "allgather_handle",
      "params",
      "partitions",
      "world_size",
      "use_secondary_tensor",
      "quantization"
    ],
    "wait": [
      "self",
      "handle_dependency"
    ],
    "free_buffer": []
  },
  "MultipleAllGatherHandles": {
    "__init__": [
      "self",
      "handles"
    ],
    "wait": [
      "self",
      "handle_dependency"
    ]
  },
  "AllReduceCoalescedHandle": {
    "__init__": [
      "self",
      "handle",
      "params"
    ],
    "wait": [
      "self"
    ]
  },
  "QuantizationInfo": {
    "__init__": [
      "self"
    ]
  },
  "CUDAQuantizer": {
    "async_flag": [],
    "target_group_size": [],
    "group_size_cache": [],
    "quantizer_cuda_module": [],
    "__init__": [
      "self"
    ],
    "quantize": [
      "self",
      "param",
      "groups"
    ],
    "dequantize": [
      "self",
      "quantized_param",
      "scale"
    ]
  },
  "_no_gather_coalesced": [
    "params"
  ],
  "Init": {
    "param_id": [],
    "param_persistence_threshold": [],
    "model_persistence_threshold": [],
    "num_persisted_parameters": [],
    "num_persisted_elements": [],
    "apply_param_persistence": [],
    "override_module_apply": [],
    "__init__": [
      "self",
      "module",
      "data_parallel_group",
      "mem_efficient_linear",
      "remote_device",
      "pin_memory",
      "config_dict_or_path",
      "config",
      "enabled",
      "dtype",
      "mpu",
      "zero_param_parallel_group",
      "zero_quantized_weights",
      "zero_quantized_nontrainable_weights",
      "sequence_data_parallel_group",
      "param_swapper",
      "tensor_overrides"
    ],
    "_update_persist_config": [
      "self",
      "ds_config"
    ],
    "_zero_init_param": [
      "self",
      "param"
    ],
    "_convert_to_zero_parameters": [
      "self",
      "param_list"
    ],
    "_validate_remote_device": [
      "self",
      "remote_device",
      "ds_config"
    ],
    "_post_init_method": [
      "self",
      "module"
    ],
    "_convert_to_deepspeed_param": [
      "self",
      "param"
    ],
    "_aligned_size": [
      "self",
      "param"
    ],
    "_padding_size": [
      "self",
      "param"
    ],
    "_partition_numel": [
      "self",
      "param"
    ],
    "_ensure_availability_of_partitioned_params": [
      "self",
      "params"
    ],
    "_all_gather": [
      "self",
      "param_list",
      "async_op",
      "hierarchy"
    ],
    "_partition": [
      "self",
      "param_list",
      "force",
      "has_been_updated",
      "free_data"
    ],
    "_partition_param": [
      "self",
      "param",
      "buffer",
      "has_been_updated",
      "free_data"
    ],
    "_partition_param_sec": [
      "self",
      "param",
      "buffer",
      "has_been_updated"
    ],
    "_param_status": [
      "self",
      "param"
    ],
    "_allgather_param": [
      "self",
      "param",
      "async_op",
      "hierarchy"
    ],
    "_allgather_params_coalesced": [
      "self",
      "param_list",
      "hierarchy",
      "quantize"
    ],
    "_allgather_params_sequential": [
      "self",
      "param_list",
      "hierarchy"
    ],
    "_reduce_scatter_gradients": [
      "self",
      "param_list"
    ],
    "_reduce_scatter_gradient": [
      "self",
      "param"
    ],
    "_partition_gradients": [
      "self",
      "param_list",
      "partition_buffers",
      "accumulate"
    ],
    "_partition_gradient": [
      "self",
      "param",
      "partition_buffer",
      "accumulate"
    ],
    "get_partition_dp_group": [
      "self",
      "param"
    ],
    "get_partition_rank": [
      "self"
    ],
    "num_partitions": [
      "self"
    ],
    "get_dp_process_group": [
      "self"
    ]
  },
  "GatheredParameters": {
    "__init__": [
      "self",
      "params",
      "modifier_rank",
      "fwd_module",
      "enabled"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "_log_rank0": [
    "msg"
  ],
  "scale_tensors": [
    "tensors",
    "scale"
  ],
  "MiCS_CommGroups": {
    "param_shard_group": [],
    "param_shard_size": [],
    "param_shard_rank": [],
    "param_repli_group": [],
    "param_repli_size": [],
    "param_repli_rank": [],
    "param_intra_node_group": [],
    "param_inter_node_shard_group": []
  },
  "create_mics_comm_groups": [
    "shard_size",
    "dp_group",
    "hierarchical_allgather",
    "mpu"
  ],
  "_generate_mics_config": [
    "world_size",
    "ndev_per_node",
    "shard_size",
    "pp_size"
  ],
  "_sizes_all_same": [
    "groups"
  ],
  "ZERO_FORMAT": [],
  "ZERO_OPTIMIZATION": [],
  "read_zero_config_deprecated": [
    "param_dict"
  ],
  "get_zero_config": [
    "param_dict"
  ],
  "ZeroStageEnum": {
    "disabled": [],
    "optimizer_states": [],
    "gradients": [],
    "weights": [],
    "max_stage": []
  },
  "DeepSpeedZeroConfig": {
    "overlap_comm_valid": [
      "self"
    ],
    "offload_ratio_check": [
      "self"
    ]
  },
  "has_hierarchical_all_gather_groups": [
    "comm_groups"
  ],
  "MiCS_AllGatherCoalescedHandle": {
    "__init__": [
      "self",
      "allgather_handle",
      "params",
      "partitions",
      "world_size"
    ],
    "wait": [
      "self"
    ]
  },
  "MiCS_Init": {
    "__init__": [
      "self",
      "module",
      "data_parallel_group",
      "sequence_data_parallel_group",
      "mem_efficient_linear",
      "remote_device",
      "pin_memory",
      "config_dict_or_path",
      "config",
      "enabled",
      "dtype",
      "mpu"
    ],
    "_convert_to_deepspeed_param": [
      "self",
      "param"
    ],
    "_pre_all_gather": [
      "self",
      "params",
      "params_buffers"
    ],
    "_flat_all_gather_with_coalescing_manager": [
      "self",
      "params",
      "params_buffers"
    ],
    "_hierarchical_all_gather_params": [
      "self",
      "params",
      "params_buffers"
    ],
    "get_partition_dp_group": [
      "self",
      "param"
    ],
    "get_partition_rank": [
      "self"
    ],
    "num_partitions": [
      "self"
    ]
  },
  "MiCS_Offload": {
    "_convert_to_zero_parameters": [
      "self",
      "ds_config",
      "module",
      "mpu"
    ]
  },
  "MiCS_Optimizer": {
    "__init__": [
      "self",
      "module",
      "init_optimizer",
      "param_names",
      "timers",
      "ds_config",
      "gradient_accumulation_dtype"
    ],
    "initialize_ds_offload": [
      "self"
    ],
    "partition_grads": [
      "self",
      "params_to_release",
      "grad_partitions"
    ],
    "allreduce_mics_shard_grads": [
      "self",
      "params",
      "partitioned_grads_buffers"
    ],
    "load_state_dict": [
      "self",
      "state_dict_list",
      "load_optimizer_states",
      "load_from_fp32_weights",
      "checkpoint_folder",
      "load_serial"
    ]
  },
  "offload_optimizer_states": [
    "optimizer",
    "device",
    "pin_memory",
    "non_blocking"
  ],
  "reload_optimizer_states": [
    "optimizer",
    "device",
    "non_blocking"
  ],
  "get_state_devices": [
    "model",
    "state"
  ],
  "PartitionedParameterProfiler": {
    "__init__": [
      "self",
      "timers"
    ],
    "reset_events": [
      "self"
    ],
    "start_event": [
      "self",
      "name"
    ],
    "stop_event": [
      "self",
      "name",
      "num_elem"
    ],
    "_log_timers": [
      "self"
    ],
    "_log_event_counters": [
      "self"
    ],
    "log_events": [
      "self"
    ]
  },
  "TiledLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "in_splits",
      "out_splits",
      "input_is_already_split",
      "combine_out_splits",
      "linear_cls",
      "init_linear"
    ],
    "forward": [
      "self",
      "input_"
    ],
    "_split_global_input": [
      "self",
      "input",
      "split_sizes"
    ],
    "_reduce_local_output": [
      "self",
      "in_id",
      "out_id",
      "current_out",
      "new_out"
    ],
    "_combine_output_splits": [
      "self",
      "outputs"
    ],
    "copy_params_from": [
      "self",
      "other"
    ]
  },
  "TiledLinearReturnBias": {
    "_reduce_local_output": [
      "self",
      "in_id",
      "out_id",
      "current_out",
      "new_out"
    ],
    "_combine_output_splits": [
      "self",
      "outputs"
    ]
  },
  "LinearFunctionForZeroStage3": {
    "forward": [
      "ctx",
      "input",
      "weight",
      "bias"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "zero3_linear_wrap": [
    "input",
    "weight",
    "bias"
  ],
  "LinearModuleForZeroStage3": {
    "__constants__": [],
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "ENABLE_PROFILER": [],
  "get_all_parameters": [
    "sub_module",
    "recurse"
  ],
  "iter_params": [
    "module",
    "recurse"
  ],
  "ZeRoTraceMode": {
    "RECORD": [],
    "COMPLETE": [],
    "INVALID": []
  },
  "InflightParamRegistry": {
    "__setitem__": [
      "self",
      "param",
      "handle"
    ]
  },
  "PartitionedParameterCoordinator": {
    "FORWARD_FETCH_SUBMIT": [],
    "FORWARD_FETCH_WAIT": [],
    "FORWARD_PREFETCH_SUBMIT": [],
    "BACKWARD_FETCH_SUBMIT": [],
    "BACKWARD_FETCH_WAIT": [],
    "BACKWARD_PREFETCH_SUBMIT": [],
    "FORWARD_ALL_GATHER": [],
    "BACKWARD_ALL_GATHER": [],
    "__init__": [
      "self",
      "prefetch_bucket_sz",
      "max_reuse_distance_in_numel",
      "max_available_parameters_in_numel",
      "allgather_stream",
      "inflight_param_registry",
      "prefetch_nvme",
      "timers",
      "zero_quantized_weights",
      "zero_quantized_nontrainable_weights",
      "fast_sharding_for_leaf_module",
      "log_trace_cache_warnings"
    ],
    "_clear_trace_structures": [
      "self"
    ],
    "is_complete_trace": [
      "self"
    ],
    "is_invalid_trace": [
      "self"
    ],
    "is_record_trace": [
      "self"
    ],
    "_clean_inflight_param_registry": [
      "self"
    ],
    "_invalidate_trace": [
      "self"
    ],
    "trace_prologue": [
      "self",
      "sub_module"
    ],
    "record_module": [
      "self",
      "sub_module"
    ],
    "record_parameters": [
      "self",
      "sub_module"
    ],
    "construct_parameter_trace_from_module_trace": [
      "self"
    ],
    "reset_step": [
      "self"
    ],
    "_dump_params": [
      "self",
      "tag",
      "sub_module",
      "params",
      "step_id"
    ],
    "_dump_param_ids": [
      "self",
      "tag",
      "mod_id",
      "p_ids",
      "step_id"
    ],
    "fetch_sub_module": [
      "self",
      "current_submodule",
      "forward"
    ],
    "_fetch_sub_module_impl": [
      "self",
      "current_submodule",
      "forward",
      "is_leaf"
    ],
    "release_sub_module": [
      "self",
      "submodule",
      "forward"
    ],
    "release_and_reset_all": [
      "self",
      "module"
    ],
    "__all_gather_params": [
      "self",
      "params",
      "forward"
    ],
    "__all_gather_params_": [
      "self",
      "params",
      "forward",
      "quantize"
    ],
    "__release_param": [
      "self",
      "param",
      "free_data"
    ],
    "__params_to_release": [
      "self",
      "submodule_to_release",
      "step_id"
    ],
    "__prefetch_nvme_param_partitions": [
      "self"
    ]
  },
  "OffloadDeviceEnum": {
    "none": [],
    "cpu": [],
    "nvme": []
  },
  "DeepSpeedZeroOffloadParamConfig": {},
  "DeepSpeedZeroOffloadOptimizerConfig": {
    "set_pipeline": [
      "self"
    ]
  },
  "OffloadStateTypeEnum": {
    "optim_states": [],
    "hp_params": [],
    "lp_params": [],
    "lp_grads": [],
    "contiguous_grad_buffer": []
  },
  "OPTIMIZER_SWAP_IN_STATE_TIMER": [],
  "INIT_OPTIMIZER_TIMER": [],
  "OPTIMIZER_SWAP_OUT_STATE_TIMER": [],
  "move_to_cpu": [
    "tensor_list"
  ],
  "unwrap_model_for_generation": [
    "model"
  ],
  "IPGBucketZ3": {
    "clear": [
      "self"
    ],
    "clear_params": [
      "self"
    ]
  },
  "DeepSpeedZeroOptimizer_Stage3": {
    "__init__": [
      "self",
      "module",
      "init_optimizer",
      "param_names",
      "timers",
      "ds_config",
      "static_loss_scale",
      "dynamic_loss_scale",
      "dynamic_loss_args",
      "verbose",
      "contiguous_gradients",
      "reduce_bucket_size",
      "prefetch_bucket_size",
      "max_reuse_distance",
      "max_live_parameters",
      "param_persistence_threshold",
      "model_persistence_threshold",
      "dp_process_group",
      "reduce_scatter",
      "overlap_comm",
      "offload_optimizer_config",
      "offload_param_config",
      "zenflow_config",
      "sub_group_size",
      "offload_ratio",
      "mpu",
      "clip_grad",
      "gradient_accumulation_dtype",
      "communication_data_type",
      "fp16_master_weights_and_gradients",
      "bf16_master_weights_and_gradients",
      "bf16_optimizer_states",
      "postscale_gradients",
      "gradient_predivide_factor",
      "gradient_accumulation_steps",
      "elastic_checkpoint",
      "aio_config",
      "all2all_process_group",
      "zero_hpz_partition_size",
      "zero_quantized_weights",
      "zero_quantized_nontrainable_weights",
      "zero_module_granularity_threshold",
      "zeropp_loco_param",
      "log_trace_cache_warnings",
      "enable_sanity_checks",
      "cpuadam_cores_perc"
    ],
    "destroy": [
      "self"
    ],
    "create_zenflow_hooks": [
      "self"
    ],
    "initialize_ds_offload": [
      "self",
      "module",
      "timers",
      "ds_config",
      "zenflow",
      "overlap_comm",
      "prefetch_bucket_size",
      "max_reuse_distance",
      "max_live_parameters",
      "param_persistence_threshold",
      "model_persistence_threshold",
      "dp_process_group",
      "offload_param_config",
      "mpu",
      "zero_param_parallel_group",
      "zero_quantized_weights",
      "zero_quantized_nontrainable_weights",
      "zero_module_granularity_threshold",
      "log_trace_cache_warnings"
    ],
    "_get_trainable_parameter_groups": [
      "self"
    ],
    "_set_zero_group_parallelism": [
      "self"
    ],
    "invalidate_secondary_tensor": [
      "self"
    ],
    "_setup_for_real_optimizer": [
      "self"
    ],
    "_link_all_hp_params": [
      "self"
    ],
    "set_lr": [
      "self",
      "lr"
    ],
    "get_lr": [
      "self"
    ],
    "defragment": [
      "tensors"
    ],
    "_get_param_coordinator": [
      "self"
    ],
    "_configure_offloading": [
      "self",
      "offload_optimizer_config",
      "offload_param_config"
    ],
    "_configure_tensor_swapping": [
      "self",
      "offload_optimizer_config",
      "aio_config"
    ],
    "_move_to_flat_buffer": [
      "self",
      "param_list",
      "flat_buffer",
      "avoid_copy"
    ],
    "_create_param_groups_fp16_flat_cpu_memory": [
      "self"
    ],
    "_create_fp16_partitions_with_defragmentation": [
      "self",
      "fp16_param_groups"
    ],
    "_get_parameter_partitions": [
      "self"
    ],
    "_swap_in_sub_group_to_flat_buffer": [
      "self",
      "flat_buffer",
      "sub_group_id"
    ],
    "_create_next_swappable_fp32_groups": [
      "self"
    ],
    "_get_sub_group_partitions": [
      "self",
      "sub_group_id"
    ],
    "_create_fp32_partitions": [
      "self"
    ],
    "_create_fp16_sub_groups": [
      "self",
      "params_group"
    ],
    "_optimizer_step": [
      "self",
      "sub_group_id"
    ],
    "_swappable_optimizer_subgroup": [
      "self",
      "sub_group_id"
    ],
    "_partitioned_params_swap_out": [
      "self",
      "i"
    ],
    "_set_fp16_partitioned_groups_flat": [
      "self"
    ],
    "initialize_optimizer_states": [
      "self"
    ],
    "get_first_param_index": [
      "self",
      "group_id",
      "param_group",
      "partition_id"
    ],
    "initialize_gradient_partitioning_data_structures": [
      "self"
    ],
    "independent_gradient_partition_epilogue": [
      "self"
    ],
    "overlapping_partition_gradients_reduce_epilogue": [
      "self"
    ],
    "create_reduce_and_remove_grad_hooks": [
      "self"
    ],
    "get_param_id": [
      "self",
      "param"
    ],
    "reduce_independent_p_g_buckets_and_remove_grads": [
      "self",
      "param"
    ],
    "__add_grad_to_ipg_bucket": [
      "self",
      "param"
    ],
    "__reduce_and_partition_ipg_grads": [
      "self",
      "communication_data_type"
    ],
    "__avg_scatter_contiguous_grads": [
      "self",
      "buffer_to_reduce",
      "communication_data_type"
    ],
    "__avg_scatter_grads": [
      "self",
      "params_to_reduce",
      "communication_data_type"
    ],
    "set_grad_positions": [
      "self"
    ],
    "_constant_buffered_norm2": [
      "self",
      "input",
      "buffer_size"
    ],
    "set_norm_for_param_grad_in_gpu": [
      "self",
      "param"
    ],
    "async_inplace_copy_grad_to_fp32_buffer_from_gpu": [
      "self",
      "param",
      "fp32_grad_tensor"
    ],
    "complete_grad_norm_calculation_for_cpu_offload": [
      "self",
      "params"
    ],
    "partition_grads": [
      "self",
      "params_to_release",
      "grad_partitions"
    ],
    "reduce_ready_partitions_and_remove_grads": [
      "self",
      "param"
    ],
    "zero_reduced_gradients": [
      "self",
      "partition_id",
      "i"
    ],
    "quantize_nontrainable_params": [
      "self"
    ],
    "flatten_and_print": [
      "self",
      "message",
      "tensors",
      "start",
      "n"
    ],
    "get_grads_to_reduce": [
      "self",
      "i",
      "partition_id"
    ],
    "sequential_execution": [
      "self",
      "function",
      "message",
      "group"
    ],
    "set_none_gradients_to_zero": [
      "self",
      "i",
      "partition_id"
    ],
    "allreduce_bucket": [
      "self",
      "bucket",
      "rank",
      "log"
    ],
    "allreduce_and_copy": [
      "self",
      "small_bucket",
      "rank",
      "log"
    ],
    "allreduce_no_retain": [
      "self",
      "bucket",
      "numel_per_bucket",
      "rank",
      "log"
    ],
    "get_data_parallel_partitions": [
      "self",
      "tensor"
    ],
    "get_partition_info": [
      "self",
      "tensor_list",
      "partition_size",
      "partition_id"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ],
    "clear_backward_seen_flag": [
      "self"
    ],
    "_model_parallel_all_reduce": [
      "self",
      "tensor",
      "op"
    ],
    "get_grad_norm_direct": [
      "self",
      "gradients",
      "params",
      "norm_type"
    ],
    "get_flat_partition": [
      "self",
      "tensor_list",
      "first_offset",
      "partition_size",
      "return_tensor_list"
    ],
    "free_grad_in_param_list": [
      "self",
      "param_list"
    ],
    "reset_cpu_buffers": [
      "self"
    ],
    "_pre_step": [
      "self"
    ],
    "_get_norm_groups": [
      "self"
    ],
    "_prepare_fp32_grad_for_sub_group": [
      "self",
      "sub_group_id"
    ],
    "_prepare_sub_group": [
      "self",
      "sub_group_id",
      "timer_names"
    ],
    "_optimizer_states_and_gradient_swap_in": [
      "self",
      "sub_group_id",
      "timer_names"
    ],
    "_release_sub_group": [
      "self",
      "sub_group_id",
      "timer_names"
    ],
    "flatten_dense_tensors_aligned": [
      "self",
      "tensor_list",
      "alignment"
    ],
    "_optimizer_states_and_gradient_swap_out": [
      "self",
      "sub_group_id",
      "timer_names"
    ],
    "_release_swap_buffers": [
      "self",
      "sub_group_id"
    ],
    "_writeback_swap_state": [
      "self",
      "sub_group_id",
      "write_opt_state",
      "write_gradients"
    ],
    "_unflatten_partitioned_parameters": [
      "self",
      "sub_group_id"
    ],
    "_overflow_clean_up": [
      "self",
      "prev_scale"
    ],
    "_loco_err_buf_update": [
      "self",
      "overflow",
      "scale"
    ],
    "_overflow_check_and_loss_scale_update": [
      "self"
    ],
    "_post_step": [
      "self",
      "timer_names"
    ],
    "_reassign_or_swap_out_partitioned_parameters": [
      "self",
      "sub_group_id"
    ],
    "override_loss_scale": [
      "self",
      "loss_scale"
    ],
    "step": [
      "self",
      "closure"
    ],
    "dump_pre_step_gradients": [
      "self",
      "debug_fp32_grads"
    ],
    "dump_post_step_gradients": [
      "self"
    ],
    "unscale_and_clip_grads": [
      "self",
      "sub_group_id",
      "total_norm"
    ],
    "_check_overflow": [
      "self",
      "partition_gradients"
    ],
    "has_overflow_serial": [
      "self",
      "params",
      "is_grad_list"
    ],
    "has_overflow_partitioned_grads_serial": [
      "self"
    ],
    "has_overflow": [
      "self",
      "partition_gradients"
    ],
    "_has_inf_or_nan": [
      "x",
      "j"
    ],
    "backward_prologue": [
      "self"
    ],
    "backward_epilogue": [
      "self"
    ],
    "get_fp32_grad_partitions": [
      "self"
    ],
    "_fp32_state_allgather": [
      "self",
      "param",
      "fp32_state_partition"
    ],
    "_get_fp32_grad_state_partition": [
      "self",
      "param",
      "release_swap_buffers"
    ],
    "get_fp32_grad_for_param": [
      "self",
      "param"
    ],
    "set_fp32_grad_for_param": [
      "self",
      "value",
      "param"
    ],
    "_get_fp32_opt_state_partition": [
      "self",
      "param",
      "release_swap_buffers",
      "optim_state_key"
    ],
    "get_full_hp_param": [
      "self",
      "param",
      "optim_state_key"
    ],
    "set_full_hp_param": [
      "self",
      "value",
      "param",
      "optim_state_key"
    ],
    "get_local_fp32_grad_for_param": [
      "self",
      "param"
    ],
    "set_local_grad_for_param": [
      "self",
      "value",
      "param"
    ],
    "get_local_fp32_param": [
      "self",
      "param",
      "optim_state_key"
    ],
    "set_local_hp_param": [
      "self",
      "value",
      "param",
      "optim_state_key"
    ],
    "update_fp32_grad_for_param_vectorized": [
      "self",
      "update_func",
      "param_list"
    ],
    "get_hp_param_device": [
      "self",
      "param",
      "optim_state_key"
    ],
    "_partition_all_parameters": [
      "self"
    ],
    "check_overflow": [
      "self",
      "partition_gradients"
    ],
    "_update_scale": [
      "self",
      "has_overflow"
    ],
    "_get_state": [
      "self"
    ],
    "_set_state": [
      "self",
      "value"
    ],
    "state": [],
    "_get_param_groups": [
      "self"
    ],
    "_set_param_groups": [
      "self",
      "value"
    ],
    "param_groups": [],
    "_get_loss_scale": [
      "self"
    ],
    "_set_loss_scale": [
      "self",
      "value"
    ],
    "loss_scale": [],
    "cur_scale": [],
    "_get_lean_tensors": [
      "self",
      "padded_flattened_tensor",
      "group_tensors",
      "paddings"
    ],
    "get_lean_optimizer_state": [
      "self"
    ],
    "get_groups_without_padding": [
      "self",
      "groups_with_padding"
    ],
    "_set_fp32_optimizer_param_groups": [
      "self"
    ],
    "_clear_fp32_optimizer_param_groups": [
      "self"
    ],
    "_rigid_state_dict": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "_restore_from_fp32_weights": [
      "self",
      "all_state_dict"
    ],
    "_restore_from_bit16_weights": [
      "self"
    ],
    "refresh_fp32_params": [
      "self"
    ],
    "_get_flattened_partition": [
      "self",
      "all_partition_states"
    ],
    "_restore_base_optimizer_state": [
      "self",
      "all_state_dict"
    ],
    "_rigid_load_state_dict": [
      "self",
      "state_dict",
      "load_optimizer_states"
    ],
    "load_state_dict": [
      "self",
      "state_dict_list",
      "load_optimizer_states",
      "load_from_fp32_weights",
      "checkpoint_folder",
      "load_serial",
      "param_shapes"
    ],
    "_load_universal_checkpoint": [
      "self",
      "checkpoint_folder",
      "load_optimizer_states",
      "load_from_fp32_weights"
    ],
    "load_hp_checkpoint_state_from_checkpoint_dir_stage3": [
      "self",
      "checkpoint_dir"
    ],
    "_load_global_state_stage3": [
      "self",
      "sd"
    ],
    "load_hp_checkpoint_state": [
      "self",
      "folder",
      "key"
    ],
    "reset_swap_buffers": [
      "self"
    ],
    "checkpoint_event_prologue": [
      "self"
    ],
    "checkpoint_event_epilogue": [
      "self"
    ],
    "empty_partition_cache": [
      "self"
    ],
    "offload_states": [
      "self",
      "include",
      "device",
      "pin_memory",
      "non_blocking"
    ],
    "reload_states": [
      "self",
      "non_blocking"
    ]
  },
  "estimate_zero3_model_states_mem_needs": [
    "total_params",
    "largest_layer_params",
    "num_gpus_per_node",
    "num_nodes",
    "cpu_offload",
    "cpu_offload_params",
    "zero_init",
    "additional_buffer_factor"
  ],
  "estimate_zero3_model_states_mem_needs_all_live": [
    "model",
    "num_gpus_per_node",
    "num_nodes",
    "additional_buffer_factor"
  ],
  "estimate_zero3_model_states_mem_needs_all_cold": [
    "total_params",
    "largest_layer_params",
    "num_gpus_per_node",
    "num_nodes",
    "additional_buffer_factor"
  ],
  "MuonWithAuxAdam": {
    "__init__": [
      "self"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "zeropower_via_newtonschulz5": [
    "G",
    "steps"
  ],
  "muon_update": [
    "grad",
    "momentum",
    "beta",
    "ns_steps",
    "nesterov"
  ],
  "Muon": {
    "__init__": [
      "self",
      "params",
      "lr",
      "weight_decay",
      "momentum"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "SingleDeviceMuon": {
    "__init__": [
      "self",
      "params",
      "lr",
      "weight_decay",
      "momentum"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "adam_update": [
    "grad",
    "buf1",
    "buf2",
    "step",
    "betas",
    "eps"
  ],
  "SingleDeviceMuonWithAuxAdam": {
    "__init__": [
      "self",
      "param_groups"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "UlyssesSPAttentionHF": {
    "__init__": [
      "self",
      "attn",
      "batch_size",
      "attn_head_count",
      "attn_head_size",
      "kv_head_count",
      "num_hidden_layers",
      "process_group",
      "seq_length_is_variable",
      "local_seq_length",
      "global_seq_length",
      "disable_in_eval"
    ],
    "_combine_local_sequences": [
      "self",
      "query",
      "key",
      "value"
    ],
    "_partition_global_sequence": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "module",
      "query",
      "key",
      "value",
      "attention_mask"
    ],
    "register_with_transformers": [
      "cls",
      "model_name_or_path",
      "core_attn_implementation",
      "sequence_parallel_size",
      "micro_batch_size",
      "seq_length",
      "seq_length_is_variable",
      "disable_in_eval",
      "max_length"
    ]
  },
  "UlyssesSPDataLoaderAdapter": {
    "__init__": [
      "self",
      "dl",
      "sp_rank",
      "sp_group",
      "sp_world_size",
      "device"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "refill": [
      "self"
    ]
  },
  "sequence_tiled_compute": [
    "fn",
    "seqlen",
    "shards",
    "kwargs_to_shard",
    "kwargs_to_pass",
    "grad_requiring_tensor_key",
    "compute_params",
    "output_unshard_dimension",
    "output_reduction"
  ],
  "SequenceTiledCompute": {
    "forward": [
      "ctx",
      "fn",
      "seqlen",
      "shards",
      "keys_to_shard",
      "keys_to_pass",
      "grad_requiring_tensor_key",
      "compute_params",
      "output_unshard_dimension",
      "output_reduction"
    ],
    "backward": [
      "ctx"
    ]
  },
  "TiledMLP": {
    "forward": [
      "ctx",
      "fn",
      "self",
      "x",
      "shards",
      "compute_params"
    ],
    "backward": [
      "ctx"
    ]
  },
  "TiledFusedLogitsLoss": {
    "forward": [
      "ctx",
      "fn",
      "self",
      "x",
      "y",
      "mask",
      "shards",
      "compute_params",
      "output_reduction"
    ],
    "backward": [
      "ctx"
    ]
  },
  "AutogradComputeMLP": {
    "forward": [
      "ctx",
      "fn",
      "self",
      "x"
    ],
    "backward": [
      "ctx"
    ]
  },
  "TiledLoss": {
    "forward": [
      "ctx",
      "loss_fn",
      "logits",
      "vocab_size",
      "shift_labels",
      "shards"
    ],
    "backward": [
      "ctx"
    ]
  },
  "UlyssesSPFwdLossBwdWithLogits": {
    "__init__": [
      "self",
      "model",
      "model_unwrapped",
      "device",
      "num_loss_logit_shards"
    ],
    "sp_fwd_loss_bwd": [
      "self",
      "batch"
    ],
    "forward": [
      "self",
      "batch"
    ],
    "compute_loss": [
      "self",
      "labels",
      "shift_labels"
    ],
    "backward": [
      "self"
    ]
  },
  "_SEQUENCE_PARALLEL_GROUP": [],
  "_SEQUENCE_DATA_PARALLEL_GROUP": [],
  "initialize_sequence_parallel": [
    "sequence_parallel_size"
  ],
  "get_sequence_parallel_group": [],
  "get_sequence_data_parallel_group": [],
  "get_sequence_parallel_world_size": [],
  "get_sequence_data_parallel_world_size": [],
  "get_sequence_parallel_rank": [],
  "get_sequence_data_parallel_rank": [],
  "AIO_DEFAULT_DICT": [],
  "get_aio_config": [
    "param_dict"
  ],
  "PartitionedParamStatus": {
    "AVAILABLE": [],
    "NOT_AVAILABLE": [],
    "INFLIGHT": []
  },
  "AsyncPartitionedParameterSwapper": {
    "__init__": [
      "self",
      "ds_config",
      "model_dtype"
    ],
    "available_swap_in_buffers": [
      "self"
    ],
    "_configure_aio": [
      "self",
      "ds_config"
    ],
    "swappable_tensor": [
      "self",
      "param",
      "numel"
    ],
    "get_path": [
      "self",
      "param",
      "must_exist"
    ],
    "_get_swap_paths": [
      "self",
      "params",
      "must_exist"
    ],
    "_get_swap_buffers": [
      "self",
      "params"
    ],
    "_track_numel": [
      "self",
      "params"
    ],
    "_allocate_and_return_buffers_for_swap_in": [
      "self",
      "params"
    ],
    "synchronize_writes": [
      "self"
    ],
    "synchronize_reads": [
      "self"
    ],
    "remove_partition_and_release_buffers": [
      "self",
      "params"
    ],
    "_swap_out": [
      "self",
      "params",
      "async_op"
    ],
    "swap_out_and_release": [
      "self",
      "params",
      "async_op",
      "force_buffer_release"
    ],
    "_update_inflight_swap_in": [
      "self",
      "params",
      "swap_in_buffers",
      "inflight_numel"
    ],
    "swap_in": [
      "self",
      "params",
      "async_op",
      "swap_in_buffers"
    ],
    "swap_into_buffer": [
      "self",
      "param",
      "dest_buffer"
    ],
    "get_buffer": [
      "self",
      "param",
      "numel"
    ],
    "reserve_available_buffers": [
      "self"
    ],
    "release_reserved_buffers": [
      "self"
    ],
    "_io_aligned_numel": [
      "self",
      "numel"
    ],
    "_is_io_aligned": [
      "self",
      "numel"
    ],
    "reserve_partitioned_swap_space": [
      "self",
      "partition_num_elems"
    ],
    "swap_out_partitioned_params": [
      "self",
      "dst_fp16_params",
      "src_fp32_params"
    ]
  },
  "FlattenedTensorSwapInfo": {
    "__init__": [
      "self",
      "path",
      "length",
      "offset"
    ]
  },
  "SwapTensorContext": {
    "__init__": [
      "self",
      "tensor",
      "swap_folder"
    ],
    "release_memory": [
      "self"
    ],
    "set_buffers": [
      "self",
      "compute_buffer",
      "swap_buffer"
    ]
  },
  "OptimizerStateSwapInfo": {
    "__init__": [
      "self",
      "parameter",
      "numel",
      "base_folder"
    ],
    "numel": [
      "self"
    ],
    "has_gradients": [
      "self"
    ],
    "_add_tensors": [
      "self",
      "tensor_list"
    ],
    "add_state_tensors": [
      "self",
      "tensor_list"
    ],
    "num_tensors": [
      "self"
    ],
    "device": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "release_memory": [
      "self"
    ],
    "get_compute_tensors": [
      "self"
    ],
    "get_swap_paths": [
      "self"
    ],
    "get_swap_buffers_and_paths": [
      "self",
      "pinned"
    ],
    "get_or_create_gradient_paths": [
      "self",
      "offsets",
      "lengths"
    ],
    "set_swap_buffers": [
      "self",
      "buffers",
      "aligned_numel"
    ],
    "get_swap_gradient_buffers": [
      "self",
      "swap_buffer"
    ],
    "get_swap_gradient_paths": [
      "self"
    ],
    "get_unpinned_state_tensors": [
      "self"
    ],
    "read_unswapped_gradients": [
      "self",
      "dest_buffer"
    ],
    "write_unswapped_gradients": [
      "self",
      "src_buffer"
    ],
    "release_unswapped_gradients": [
      "self"
    ]
  },
  "SWAPPER_DEBUG_MODE": [],
  "SWAP_OUT_GRADIENT_TIMER": [],
  "OptimizerSwapper": {
    "parameter_id": [
      "param"
    ],
    "__init__": [
      "self",
      "swap_config",
      "aio_config",
      "base_folder",
      "optimizer",
      "largest_numel",
      "device",
      "dtype",
      "timers"
    ],
    "purge_state": [
      "self"
    ],
    "is_swappable_tensor": [
      "self",
      "tensor",
      "numel"
    ],
    "init_timers": [
      "self"
    ],
    "log_timers": [
      "self"
    ],
    "pre_backward": [
      "self"
    ],
    "post_backward": [
      "self"
    ],
    "_flush_gradient_swapper": [
      "self",
      "gradient_swapper"
    ],
    "_swap_out_gradients": [
      "self",
      "parameter",
      "gradient_offsets",
      "gradient_tensors",
      "gradient_swapper"
    ],
    "_initialize_from_swapped_fp16_params": [
      "self",
      "aio_handle",
      "fp16_partitions_info",
      "fp16_num_elems",
      "fp16_pinned_buffers",
      "fp32_parameters"
    ],
    "_swap_in_fp16_params": [
      "self",
      "aio_handle",
      "fp16_num_elems",
      "fp16_partitions_info",
      "fp16_swap_buffers"
    ],
    "_swap_out_fp16_params": [
      "self",
      "aio_handle",
      "fp32_swap_paths",
      "fp32_swap_buffers",
      "fp16_pinned_tensors"
    ],
    "_initialize_parameters": [
      "self",
      "parameters",
      "src_tensors",
      "aio_handle"
    ],
    "_get_swap_paths": [
      "self",
      "parameters",
      "num_elems"
    ],
    "_swap_out_unpinned_tensors": [
      "self",
      "aio_handle",
      "unpinned_tensors",
      "dest_paths",
      "pinned_buffers"
    ],
    "_adjust_for_misaligned_lengths": [
      "self",
      "tensors",
      "offsets"
    ],
    "_retrieve_unswapped_grad_partitions": [
      "self",
      "swap_info",
      "dest_buffer"
    ],
    "_get_state_tensors": [
      "self",
      "parameter"
    ],
    "_update_param_state_info": [
      "self",
      "swap_info",
      "parameter"
    ],
    "_create_param_swap_info": [
      "self",
      "parameter",
      "numel"
    ],
    "_get_param_swap_info": [
      "self",
      "parameter"
    ],
    "_start_timer": [
      "self",
      "name"
    ],
    "_stop_timer": [
      "self",
      "name"
    ],
    "_log_timers": [
      "self",
      "name_list",
      "force"
    ],
    "_io_aligned_numel": [
      "self",
      "numel"
    ]
  },
  "DEBUG_MODE": [],
  "SWAP_IN_PARAM_TIMER": [],
  "SWAP_OUT_PARAM_TIMER": [],
  "SWAP_IN_GRADIENT_TIMER": [],
  "PartitionedOptimizerSwapper": {
    "__init__": [
      "self",
      "swap_config",
      "aio_config",
      "base_folder",
      "optimizer",
      "largest_numel",
      "device",
      "dtype",
      "timers"
    ],
    "initialize_parameters": [
      "self",
      "parameters",
      "src_tensors"
    ],
    "initialize_from_swapped_fp16_params": [
      "self",
      "fp16_partitions_info",
      "fp16_num_elems",
      "fp16_pinned_buffers",
      "fp32_parameters"
    ],
    "flush_gradients": [
      "self"
    ],
    "release_swap_buffers": [
      "self",
      "parameter"
    ],
    "swap_in_optimizer_state": [
      "self",
      "parameter",
      "async_parameter"
    ],
    "_swap_out_optimizer_state": [
      "self",
      "swap_info"
    ],
    "writeback_optimizer_state_and_gradients": [
      "self",
      "parameter",
      "write_opt_state",
      "write_gradients"
    ],
    "swap_out_optimizer_state": [
      "self",
      "parameter",
      "async_swap"
    ],
    "swap_out_gradients": [
      "self",
      "parameter",
      "gradient_offsets",
      "gradient_tensors"
    ],
    "_swap_in_parameter": [
      "self",
      "aio_handle",
      "parameter",
      "dest_buffers"
    ],
    "_swap_in_pinned_gradients": [
      "self",
      "aio_handle",
      "parameter",
      "gradient_tensor"
    ],
    "_swap_in_gradients": [
      "self",
      "aio_handle",
      "parameter",
      "dest_buffer"
    ]
  },
  "OptimizerSwapOp": {
    "__init__": [
      "self",
      "aio_handle",
      "read_op",
      "param_info",
      "allocated_buffers",
      "state_buffers",
      "num_ops"
    ],
    "is_parameter": [
      "self",
      "parameter"
    ],
    "wait": [
      "self"
    ]
  },
  "SYNC_SWAP_IN": [],
  "ASYNC_SWAP_IN": [],
  "SYNC_SWAP_OUT": [],
  "ASYNC_SWAP_OUT": [],
  "SWAP_IN_STATE_TIMER": [],
  "SWAP_OUT_STATE_TIMER": [],
  "ASYNC_SWAP_IN_STATE_TIMER": [],
  "ASYNC_SWAP_OUT_STATE_TIMER": [],
  "PipelinedOptimizerSwapper": {
    "__init__": [
      "self",
      "swap_config",
      "aio_config",
      "base_folder",
      "optimizer",
      "largest_numel",
      "device",
      "dtype",
      "timers"
    ],
    "initialize_parameters": [
      "self",
      "parameters",
      "src_tensors"
    ],
    "initialize_from_swapped_fp16_params": [
      "self",
      "fp16_partitions_info",
      "fp16_num_elems",
      "fp16_pinned_buffers",
      "fp32_parameters"
    ],
    "flush_gradients": [
      "self"
    ],
    "swap_in_optimizer_state": [
      "self",
      "parameter",
      "async_parameter"
    ],
    "swap_out_optimizer_state": [
      "self",
      "parameter",
      "async_swap"
    ],
    "swap_out_gradients": [
      "self",
      "parameter",
      "gradient_offsets",
      "gradient_tensors"
    ],
    "_complete_swap_out": [
      "self",
      "swap_out_type"
    ],
    "_swap_out_optimizer_state": [
      "self",
      "aio_handle",
      "parameter",
      "swap_in_op"
    ],
    "_swap_in_optimizer_state": [
      "self",
      "aio_handle",
      "parameter"
    ]
  },
  "MIN_AIO_BYTES": [],
  "AIO_ALIGNED_BYTES": [],
  "MIN_SWAPPABLE_BYTES": [],
  "swap_in_tensors": [
    "swap_handle",
    "tensor_buffers",
    "swap_paths"
  ],
  "swap_out_tensors": [
    "swap_handle",
    "tensor_buffers",
    "swap_paths"
  ],
  "print_object": [
    "obj",
    "name",
    "exclude_list"
  ],
  "SwapBuffer": {
    "__init__": [
      "self",
      "buffer"
    ],
    "reset": [
      "self"
    ],
    "insert_tensor": [
      "self",
      "tensor",
      "swap_path",
      "aligned_numel"
    ],
    "allocate_tensor": [
      "self",
      "swap_path",
      "numel",
      "aligned_numel"
    ],
    "has_space": [
      "self",
      "numel"
    ],
    "get_swap_tensors": [
      "self"
    ],
    "get_swap_paths": [
      "self"
    ],
    "get_compute_tensors": [
      "self"
    ],
    "get_num_elem": [
      "self"
    ],
    "get_swap_tensor": [
      "self",
      "offset"
    ],
    "get_compute_tensor": [
      "self",
      "offset"
    ],
    "get_swap_path": [
      "self",
      "offset"
    ]
  },
  "SwapBufferPool": {
    "__init__": [
      "self",
      "buffers"
    ],
    "reset": [
      "self"
    ],
    "allocate_tensor": [
      "self",
      "numel",
      "swap_path",
      "aligned_numel"
    ],
    "insert_tensor": [
      "self",
      "tensor",
      "swap_path",
      "aligned_numel"
    ],
    "get_swap_tensors": [
      "self"
    ],
    "get_swap_paths": [
      "self"
    ],
    "get_compute_tensors": [
      "self"
    ],
    "has_space": [
      "self",
      "numel"
    ],
    "swap_out": [
      "self",
      "aio_handle",
      "async_op"
    ],
    "swap_in": [
      "self",
      "aio_handle",
      "async_op"
    ],
    "_get_current_buffer": [
      "self"
    ],
    "_get_used_buffers": [
      "self"
    ]
  },
  "SwapBufferManager": {
    "__init__": [
      "self",
      "num_elems",
      "count",
      "dtype"
    ],
    "allocate": [
      "self",
      "num_elems",
      "count",
      "dtype"
    ],
    "allocate_all": [
      "self",
      "num_elems",
      "dtype"
    ],
    "free": [
      "self",
      "buffers"
    ]
  },
  "get_sized_buffer": [
    "buffer",
    "num_elems"
  ],
  "get_sized_buffers": [
    "buffer_list",
    "num_elems_list"
  ],
  "ASYNC_SWAPPER_WAIT_TIMER": [],
  "AsyncTensorSwapper": {
    "__init__": [
      "self",
      "aio_handle",
      "numel_alignment",
      "timers"
    ],
    "has_buffers": [
      "self"
    ],
    "add_buffers": [
      "self",
      "buffer_list"
    ],
    "get_timer_names": [
      "self"
    ],
    "release_buffers": [
      "self"
    ],
    "swap_out_tensors": [
      "self",
      "tensor_list",
      "path_list"
    ],
    "_report_statistics": [
      "self",
      "message"
    ],
    "_swap_out_tensor": [
      "self",
      "tensor",
      "swap_path"
    ],
    "_make_swap_space": [
      "self",
      "numel"
    ],
    "_io_aligned_numel": [
      "self",
      "numel"
    ],
    "_allocate_buffer": [
      "self"
    ],
    "_flush_ready_buffers": [
      "self"
    ],
    "_flush_buffers_until_complete": [
      "self"
    ],
    "_swap_out_ready_buffers": [
      "self"
    ],
    "_wait_for_swap_complete": [
      "self"
    ],
    "_get_buffer": [
      "self",
      "index"
    ],
    "_get_current_buffer": [
      "self"
    ],
    "_start_timer": [
      "self",
      "name"
    ],
    "_stop_timer": [
      "self",
      "name"
    ],
    "_log_timers": [
      "self",
      "name_list",
      "force"
    ]
  },
  "AIO_FORMAT": [],
  "AIO": [],
  "AIO_BLOCK_SIZE": [],
  "AIO_BLOCK_SIZE_DEFAULT": [],
  "AIO_QUEUE_DEPTH": [],
  "AIO_QUEUE_DEPTH_DEFAULT": [],
  "AIO_INTRA_OP_PARALLELISM": [],
  "AIO_INTRA_OP_PARALLELISM_DEFAULT": [],
  "AIO_SINGLE_SUBMIT": [],
  "AIO_SINGLE_SUBMIT_DEFAULT": [],
  "AIO_OVERLAP_EVENTS": [],
  "AIO_OVERLAP_EVENTS_DEFAULT": [],
  "AIO_USE_GDS": [],
  "AIO_USE_GDS_DEFAULT": [],
  "FastCheckpointEngine": {
    "__init__": [
      "self",
      "config_params",
      "dp_writer_config",
      "optimize_dp_state"
    ],
    "create": [
      "self",
      "info"
    ],
    "save": [
      "self",
      "state_dict",
      "path"
    ],
    "load": [
      "self",
      "path",
      "map_location"
    ],
    "commit": [
      "self",
      "info"
    ],
    "is_data_parallel_writer": [
      "self",
      "dp_rank"
    ]
  },
  "_get_tag_from_path": [
    "path"
  ],
  "NebulaCheckpointEngine": {
    "__init__": [
      "self",
      "config_params"
    ],
    "create": [
      "self",
      "info"
    ],
    "save": [
      "self",
      "state_dict",
      "path"
    ],
    "load": [
      "self",
      "path",
      "map_location"
    ],
    "commit": [
      "self",
      "info"
    ]
  },
  "create_checkpoint_engine": [
    "config_params",
    "groups",
    "zero_stage",
    "has_moe_layers",
    "optimize_dp_state"
  ],
  "ENGINE_NAME": [],
  "DataStatesCheckpointEngine": {
    "__init__": [
      "self",
      "deepspeed_config",
      "rank"
    ],
    "__del__": [
      "self"
    ],
    "create": [
      "self",
      "info"
    ],
    "save": [
      "self",
      "state_dict",
      "path"
    ],
    "load": [
      "self",
      "path",
      "map_location"
    ],
    "commit": [
      "self",
      "info"
    ],
    "cleanup": [
      "self"
    ],
    "is_decoupled": [
      "self"
    ],
    "preserves_storage_sharing": [
      "self"
    ]
  },
  "DecoupledEvent": {
    "SAVE_EVENT": [],
    "COMMIT_EVENT": [],
    "EXIT_EVENT": []
  },
  "CheckpointSize": {
    "__init__": [
      "self"
    ],
    "gb_size": [
      "self"
    ],
    "set_pre_size": [
      "self",
      "size"
    ],
    "set_post_size": [
      "self",
      "size"
    ]
  },
  "init_decoupled_checkpoint": [
    "config_params",
    "dp_writer_config",
    "save_event",
    "save_queue",
    "optimize_dp_state"
  ],
  "DEFAULT_CHECKPOINT_TIMEOUT_SECONDS": [],
  "PROCESS_HEALTH_CHECK_INTERVAL_SECONDS": [],
  "DecoupledCheckpointEngine": {
    "__init__": [
      "self",
      "config_params",
      "dp_writer_config",
      "optimize_dp_state"
    ],
    "__del__": [
      "self"
    ],
    "_check_process_alive": [
      "self"
    ],
    "_wait_for_event_with_timeout": [
      "self",
      "timeout_seconds"
    ],
    "create": [
      "self",
      "info"
    ],
    "load": [
      "self",
      "path",
      "map_location"
    ],
    "save": [
      "self",
      "state_dict",
      "path"
    ],
    "commit": [
      "self",
      "info"
    ],
    "get_commit_info": [
      "self"
    ],
    "is_decoupled": [
      "self"
    ],
    "cleanup": [
      "self"
    ],
    "is_data_parallel_writer": [
      "self",
      "dp_rank"
    ]
  },
  "CheckpointCommitInfo": {},
  "CheckpointEngine": {
    "__init__": [
      "self",
      "config_params"
    ],
    "create": [
      "self",
      "info"
    ],
    "save": [
      "self",
      "state_dict",
      "path"
    ],
    "makedirs": [
      "self",
      "path",
      "exist_ok"
    ],
    "load": [
      "self",
      "path",
      "map_location"
    ],
    "commit": [
      "self",
      "info"
    ],
    "is_data_parallel_writer": [
      "self",
      "dp_rank"
    ],
    "is_decoupled": [
      "self"
    ],
    "set_commit_info": [
      "self",
      "info"
    ],
    "get_commit_info": [
      "self"
    ],
    "cleanup": [
      "self"
    ],
    "preserves_storage_sharing": [
      "self"
    ]
  },
  "TorchCheckpointEngine": {
    "__init__": [
      "self",
      "config_params"
    ],
    "create": [
      "self",
      "info"
    ],
    "save": [
      "self",
      "state_dict",
      "path"
    ],
    "load": [
      "self",
      "path",
      "map_location"
    ],
    "commit": [
      "self",
      "info"
    ]
  },
  "CurriculumScheduler": {
    "__init__": [
      "self",
      "config"
    ],
    "get_current_difficulty": [
      "self"
    ],
    "set_current_difficulty": [
      "self",
      "difficulty"
    ],
    "set_custom_get_difficulty": [
      "self",
      "schedule_function"
    ],
    "get_state": [
      "self"
    ],
    "set_state": [
      "self",
      "state"
    ],
    "__fixed_discrete_get_difficulty": [
      "self",
      "global_steps"
    ],
    "__fixed_root_get_difficulty": [
      "self",
      "global_steps",
      "root_degree"
    ],
    "get_difficulty": [
      "self",
      "global_steps"
    ],
    "update_difficulty": [
      "self",
      "global_steps"
    ]
  },
  "get_data_efficiency_config": [
    "param_dict"
  ],
  "get_data_efficiency_enabled": [
    "param_dict"
  ],
  "get_data_efficiency_seed": [
    "param_dict"
  ],
  "get_data_sampling": [
    "param_dict"
  ],
  "get_data_sampling_enabled": [
    "param_dict"
  ],
  "get_data_sampling_num_epochs": [
    "param_dict"
  ],
  "get_data_sampling_num_workers": [
    "param_dict"
  ],
  "get_data_sampling_pin_memory": [
    "param_dict"
  ],
  "get_curriculum_learning": [
    "param_dict"
  ],
  "get_dynamic_batching": [
    "param_dict"
  ],
  "get_curriculum_learning_enabled": [
    "param_dict"
  ],
  "get_curriculum_learning_params": [
    "param_dict"
  ],
  "get_curriculum_enabled_legacy": [
    "param_dict"
  ],
  "get_curriculum_params_legacy": [
    "param_dict"
  ],
  "get_data_routing": [
    "param_dict"
  ],
  "get_data_routing_enabled": [
    "param_dict"
  ],
  "get_random_ltd": [
    "param_dict"
  ],
  "get_random_ltd_enabled": [
    "param_dict"
  ],
  "get_random_ltd_params": [
    "param_dict"
  ],
  "DATA_EFFICIENCY": [],
  "DATA_EFFICIENCY_ENABLED": [],
  "DATA_EFFICIENCY_ENABLED_DEFAULT": [],
  "DATA_EFFICIENCY_SEED": [],
  "DATA_EFFICIENCY_SEED_DEFAULT": [],
  "DATA_SAMPLING": [],
  "DATA_SAMPLING_ENABLED": [],
  "DATA_SAMPLING_ENABLED_DEFAULT": [],
  "DATA_SAMPLING_NUM_EPOCHS": [],
  "DATA_SAMPLING_NUM_EPOCHS_DEFAULT": [],
  "DATA_SAMPLING_NUM_WORKERS": [],
  "DATA_SAMPLING_NUM_WORKERS_DEFAULT": [],
  "DATA_SAMPLING_PIN_MEMORY": [],
  "DATA_SAMPLING_PIN_MEMORY_DEFAULT": [],
  "CURRICULUM_LEARNING": [],
  "CURRICULUM_LEARNING_ENABLED": [],
  "CURRICULUM_LEARNING_ENABLED_DEFAULT": [],
  "CURRICULUM_LEARNING_CLUSTER_PATH": [],
  "CURRICULUM_LEARNING_METRICS": [],
  "CURRICULUM_LEARNING_SAMPLE_PATH": [],
  "CURRICULUM_LEARNING_METRIC_PATH": [],
  "CURRICULUM_LEARNING_CLUSTERING_TYPE": [],
  "CURRICULUM_LEARNING_SINGLE_CLUSTER": [],
  "CURRICULUM_LEARNING_CLUSTER_PREFIX": [],
  "CURRICULUM_LEARNING_DIFFICULTY_TYPE": [],
  "CURRICULUM_LEARNING_VALUE_BASED": [],
  "CURRICULUM_LEARNING_PERCENTILE_BASED": [],
  "CURRICULUM_LEARNING_MIN_DIFFICULTY": [],
  "CURRICULUM_LEARNING_MAX_DIFFICULTY": [],
  "CURRICULUM_LEARNING_SCHEDULE_TYPE": [],
  "CURRICULUM_LEARNING_SCHEDULE_CONFIG": [],
  "CURRICULUM_LEARNING_SCHEDULE_DIFFICULTY": [],
  "CURRICULUM_LEARNING_SCHEDULE_MAX_STEP": [],
  "CURRICULUM_LEARNING_SCHEDULE_TOTAL_STEP": [],
  "CURRICULUM_LEARNING_SCHEDULE_DIFFICULTY_STEP": [],
  "CURRICULUM_LEARNING_SCHEDULE_ROOT_DEGREE": [],
  "CURRICULUM_LEARNING_SCHEDULE_FIXED_DISCRETE": [],
  "CURRICULUM_LEARNING_SCHEDULE_FIXED_ROOT": [],
  "CURRICULUM_LEARNING_SCHEDULE_FIXED_LINEAR": [],
  "CURRICULUM_LEARNING_SCHEDULE_CUSTOM": [],
  "CURRICULUM_LEARNING_CURRENT_DIFFICULTY": [],
  "CURRICULUM_LEARNING_BATCH": [],
  "CURRICULUM_LEARNING_CONSUMED_SAMPLES": [],
  "CURRICULUM_LEARNING_STEP": [],
  "CURRICULUM_LEARNING_CURRENT_DIFFICULTIES": [],
  "CURRICULUM_LEARNING_DATA_CLUSTER_PATHS": [],
  "CURRICULUM_LEARNING_DATA_CLUSTER_CURRENT_POSITION": [],
  "CURRICULUM_LEARNING_NP_RNG_STATE": [],
  "DYNAMIC_BATCHING": [],
  "DYNAMIC_BATCHING_ENABLED": [],
  "DYNAMIC_BATCHING_ENABLED_DEFAULT": [],
  "DYNAMIC_BATCHING_METRICS_PATH": [],
  "DYNAMIC_BATCHING_LR_SCALING_METHOD": [],
  "DYNAMIC_BATCHING_LR_SCALING_METHOD_DEFAULT": [],
  "DYNAMIC_BATCHING_MIN_BATCH_SIZE": [],
  "DYNAMIC_BATCHING_MIN_BATCH_SIZE_DEFAULT": [],
  "DYNAMIC_BATCHING_MAX_BATCH_SIZE": [],
  "DYNAMIC_BATCHING_MAX_BATCH_SIZE_DEFAULT": [],
  "DYNAMIC_BATCHING_SEQUENCE_PICKING_ORDER": [],
  "DYNAMIC_BATCHING_SEQUENCE_PICKING_ORDER_DEFAULT": [],
  "DYNAMIC_BATCHING_MAX_TOKENS": [],
  "DYNAMIC_BATCHING_VERBOSE": [],
  "CURRICULUM_LEARNING_LEGACY": [],
  "CURRICULUM_ENABLED_LEGACY": [],
  "CURRICULUM_ENABLED_DEFAULT_LEGACY": [],
  "DATA_ROUTING": [],
  "DATA_ROUTING_ENABLED": [],
  "DATA_ROUTING_ENABLED_DEFAULT": [],
  "RANDOM_LTD": [],
  "RANDOM_LTD_ENABLED": [],
  "RANDOM_LTD_ENABLED_DEFAULT": [],
  "RANDOM_LTD_MODEL_MASK_NAME": [],
  "RANDOM_LTD_MODEL_TYPE": [],
  "RANDOM_LTD_MICRO_BATCH_SIZE": [],
  "RANDOM_LTD_GLOBAL_BATCH_SIZE": [],
  "RANDOM_LTD_SAMPLE_INDEX": [],
  "RANDOM_LTD_ATTENTION_MASK": [],
  "RANDOM_LTD_HIDDEN_STATE_ORDER": [],
  "RANDOM_LTD_LAYER_NUM": [],
  "RANDOM_LTD_LAYER_ID": [],
  "RANDOM_LTD_TOTAL_LAYER_NUM": [],
  "RANDOM_LTD_CONSUMED_LAYER_TOKENS": [],
  "RANDOM_LTD_SCHEDULER": [],
  "RANDOM_LTD_MAX_VALUE": [],
  "RANDOM_LTD_MIN_VALUE": [],
  "RANDOM_LTD_CURRENT_VALUE": [],
  "RANDOM_LTD_SCHEDULE_CONFIG": [],
  "RANDOM_LTD_INCREASE_STEP": [],
  "RANDOM_LTD_REQUIRE_STEP": [],
  "RANDOM_LTD_SCHEDULER_TYPE": [],
  "RANDOM_LTD_CURR_STEP": [],
  "RANDOM_LTD_LAYER_TOKEN_LR_SCHEDULE": [],
  "RANDOM_LTD_LAYER_TOKEN_LR_ENABLED": [],
  "RANDOM_LTD_LAYER_TOKEN_LR_ENABLED_DEFAULT": [],
  "RANDOM_LTD_TOTAL_LAYER_TOKENS": [],
  "RANDOM_LTD_WARMUP_TYPE": [],
  "RANDOM_LTD_WARMUP_LAYER_TOKENS": [],
  "BaseScheduler": {
    "__init__": [
      "self"
    ],
    "__fixed_root_get_value": [
      "self",
      "global_steps",
      "root_degree"
    ],
    "get_value": [
      "self",
      "global_steps"
    ]
  },
  "RandomLTDScheduler": {
    "__init__": [
      "self",
      "config"
    ],
    "get_total_layer_tokens": [
      "self",
      "train_iters"
    ],
    "reset_to_init": [
      "self"
    ],
    "get_current_seq": [
      "self"
    ],
    "set_current_seq": [
      "self",
      "seq_length"
    ],
    "get_random_ltd_layer_num": [
      "self"
    ],
    "get_state": [
      "self"
    ],
    "set_state": [
      "self",
      "state"
    ],
    "update_seq": [
      "self",
      "global_steps"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "bsh_decoder_gather": [
    "reserved_length",
    "hidden_states",
    "mask"
  ],
  "bsh_decoder_scatter": [
    "hidden_states",
    "part_hidden_states",
    "rand_list"
  ],
  "RandomLayerTokenDrop": {
    "__init__": [
      "self",
      "layer"
    ],
    "init_config": [
      "self",
      "config",
      "scheduler",
      "random_ltd_layer_id"
    ],
    "get_bsh": [
      "self",
      "hidden_stats"
    ],
    "get_sbh": [
      "self",
      "hidden_stats"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "convert_to_random_ltd": [
    "model",
    "convert_type"
  ],
  "save_without_random_ltd": [
    "model"
  ],
  "remove_random_ltd_state_dict": [
    "state_dict"
  ],
  "DataAnalyzer": {
    "__init__": [
      "self",
      "dataset",
      "num_workers",
      "worker_id",
      "num_threads",
      "num_threads_reduce",
      "specific_threads",
      "batch_size",
      "metric_names",
      "metric_functions",
      "metric_types",
      "metric_dtypes",
      "save_path",
      "collate_fn",
      "custom_map_init",
      "custom_map_update",
      "custom_map_finalize",
      "custom_reduce",
      "sample_indices"
    ],
    "init_metric_results": [
      "self",
      "thread_id",
      "metric_names",
      "metric_types",
      "metric_dtypes",
      "save_path",
      "worker_id"
    ],
    "update_metric_results": [
      "self",
      "data",
      "metric_types",
      "metric_dtypes",
      "metric_functions",
      "metric_results",
      "batch_start_idx"
    ],
    "finalize_metric_results": [
      "self",
      "metric_types",
      "metric_dtypes",
      "metric_results"
    ],
    "run_map_helper": [
      "self",
      "thread_id"
    ],
    "run_map": [
      "self"
    ],
    "get_metric_value_percentiles": [
      "self",
      "metric_name",
      "num_sample_per_value",
      "total_num_samples"
    ],
    "merge_gather_map_stats": [
      "self",
      "num_workers",
      "num_threads",
      "num_threads_reduce",
      "t_idx_reduce",
      "metric_save_path",
      "metric_name",
      "return_dict"
    ],
    "merge_sample_to_metric": [
      "self",
      "t_idx_reduce",
      "metric_save_path",
      "metric_name",
      "metric_value_dtype",
      "map_worker_thread"
    ],
    "merge_metric_to_sample": [
      "self",
      "t_idx_reduce",
      "metric_save_path",
      "metric_name",
      "sample_idx_dtype",
      "metric_value_dtype",
      "unique_metric_values",
      "num_workers",
      "num_threads"
    ],
    "merge_map_results": [
      "self",
      "dataset",
      "metric_names",
      "metric_types",
      "save_path",
      "num_workers",
      "num_threads",
      "num_threads_reduce"
    ],
    "output_index_to_sample_percentile": [
      "index_to_sample_fname",
      "index_to_metric_fname",
      "metric_name",
      "metric_save_path",
      "total_num_samples",
      "sample_idx_dtype"
    ],
    "run_reduce": [
      "self"
    ],
    "run_map_reduce": [
      "self",
      "comm_group"
    ]
  },
  "DistributedDataAnalyzer": {
    "__init__": [
      "self",
      "dataset",
      "num_workers",
      "num_threads",
      "worker_id",
      "batch_size",
      "metric_names",
      "metric_functions",
      "metric_types",
      "save_path",
      "collate_fn",
      "device",
      "comm_group",
      "sample_indices"
    ],
    "run_map_helper": [
      "self",
      "thread_id",
      "metric_queues"
    ],
    "run_map_reduce": [
      "self"
    ],
    "file_write_ordered": [
      "self",
      "tensor_list",
      "fname",
      "numpy_dtype"
    ]
  },
  "Dist": {
    "min_max": [
      "tensor",
      "comm_group"
    ],
    "gather_v": [
      "tensor",
      "dst",
      "comm_group",
      "num_workers",
      "worker_id"
    ],
    "sample_sort": [
      "tensor",
      "comm_group",
      "num_workers",
      "n_samples"
    ]
  },
  "test_compare_both_data_analyzers": [
    "dataset"
  ],
  "batch_by_seqlens": [
    "seqlens",
    "max_tokens",
    "sequence_ids_per_mb",
    "min_batch_size",
    "max_batch_size",
    "sequence_picking_order",
    "effective_batch_size",
    "required_microbatches_of_same_size",
    "verbose",
    "seed"
  ],
  "scale_lr": [
    "base_batch_size",
    "batch_size",
    "base_lr",
    "method"
  ],
  "dataloader_for_variable_batch_size": [
    "dataset",
    "microbatch_ids",
    "batch_max_seqlens",
    "dataloader_rank",
    "dataloader_batch_size",
    "dataloader_num_replicas",
    "dataloader_collate_fn",
    "dataloader_num_workers",
    "dataloader_pin_memory",
    "required_microbatches_of_same_seqlen",
    "sample_padding_fn"
  ],
  "VariableBatchSizeLR": {
    "optimizer": [
      "self"
    ],
    "__init__": [
      "self",
      "lr_scheduler",
      "base_batch_size",
      "batch_sizes",
      "dataloader",
      "lr_scaling_method",
      "last_epoch",
      "verbose"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "get_last_lr": [
      "self"
    ],
    "get_lr": [
      "self"
    ],
    "step": [
      "self",
      "epoch"
    ]
  },
  "lr_scheduler_for_variable_batch_size": [
    "base_batch_size",
    "batch_sizes",
    "dataloader",
    "lr_scheduler_or_optimizer",
    "lr_scaling_method",
    "verbose"
  ],
  "get_dataloader_and_lr_scheduler_for_variable_batch_size_deepspeed": [
    "dataset",
    "engine",
    "dataset_seqlens",
    "dataset_filter_ids",
    "dataloader_collate_fn",
    "sample_padding_fn",
    "batch_seqlens_fn"
  ],
  "get_dataloader_and_lr_scheduler_for_variable_batch_size": [
    "dataset",
    "dataset_seqlens",
    "max_tokens",
    "effective_batch_size",
    "dataset_filter_ids",
    "lr_scaling_method",
    "min_batch_size",
    "max_batch_size",
    "sequence_picking_order",
    "dataloader_batch_size",
    "dataloader_rank",
    "dataloader_num_replicas",
    "dataloader_num_workers",
    "dataloader_collate_fn",
    "dataloader_pin_memory",
    "lr_scheduler_or_optimizer",
    "required_microbatches_of_same_size",
    "required_microbatches_of_same_seqlen",
    "sample_padding_fn",
    "verbose",
    "seed"
  ],
  "find_fit_int_dtype": [
    "min_value",
    "max_value"
  ],
  "split_index": [
    "start_idx",
    "end_idx",
    "num_partitions"
  ],
  "split_dataset": [
    "dataset",
    "num_workers",
    "worker_id",
    "num_threads"
  ],
  "create_mmap_dataset_builder": [
    "fname",
    "dtype"
  ],
  "close_mmap_dataset_builder": [
    "builder",
    "fname"
  ],
  "DeepSpeedDataSampler": {
    "__init__": [
      "self",
      "data_efficiency_config",
      "one_epoch_total_samples",
      "micro_batch_size",
      "data_parallel_rank",
      "data_parallel_size",
      "data_parallel_group",
      "gradient_accumulation_steps",
      "global_rank",
      "drop_last"
    ],
    "__len__": [
      "self"
    ],
    "set_custom_curriculum_learning_schedule": [
      "self",
      "schedule_func_dict"
    ],
    "get_start_end_idx": [
      "self",
      "batch_len"
    ],
    "get_sample_based_on_metric_value": [
      "self",
      "metric",
      "value_start",
      "value_end"
    ],
    "get_sample_based_on_metric_percentile": [
      "self",
      "metric",
      "percentile_start",
      "percentile_end"
    ],
    "get_new_cluster": [
      "self",
      "previous_difficulties"
    ],
    "sample_from_clusters": [
      "self"
    ],
    "reshuffle_clusters": [
      "self",
      "cidx"
    ],
    "get_sample_from_cluster": [
      "self",
      "cidx",
      "num_samples"
    ],
    "get_next_global_batch": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "__best_fitting_dtype": [
    "vocab_size"
  ],
  "get_available_dataset_impl": [],
  "infer_dataset_impl": [
    "path"
  ],
  "make_builder": [
    "out_file",
    "impl",
    "vocab_size"
  ],
  "make_dataset": [
    "path",
    "impl",
    "skip_warmup"
  ],
  "dataset_exists": [
    "path",
    "impl"
  ],
  "read_longs": [
    "f",
    "n"
  ],
  "write_longs": [
    "f",
    "a"
  ],
  "dtypes": [],
  "valid_dtypes": [],
  "code": [
    "dtype"
  ],
  "index_file_path": [
    "prefix_path"
  ],
  "data_file_path": [
    "prefix_path"
  ],
  "create_doc_idx": [
    "sizes"
  ],
  "IndexedDataset": {
    "_HDR_MAGIC": [],
    "__init__": [
      "self",
      "path"
    ],
    "read_index": [
      "self",
      "path"
    ],
    "read_data": [
      "self",
      "path"
    ],
    "check_index": [
      "self",
      "i"
    ],
    "__del__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "exists": [
      "path"
    ],
    "supports_prefetch": [
      "self"
    ]
  },
  "IndexedCachedDataset": {
    "__init__": [
      "self",
      "path"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "IndexedDatasetBuilder": {
    "__init__": [
      "self",
      "out_file",
      "dtype"
    ],
    "add_item": [
      "self",
      "tensor"
    ],
    "end_document": [
      "self"
    ],
    "merge_file_": [
      "self",
      "another_file"
    ],
    "finalize": [
      "self",
      "index_file"
    ]
  },
  "_warmup_mmap_file": [
    "path"
  ],
  "exscan_from_cumsum_": [
    "arr"
  ],
  "get_pointers_with_total": [
    "sizes",
    "elemsize",
    "dtype"
  ],
  "MMapIndexedDataset": {
    "__init__": [
      "self",
      "path",
      "skip_warmup"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "_do_init": [
      "self",
      "path",
      "skip_warmup"
    ],
    "__del__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "get": [
      "self",
      "idx",
      "offset",
      "length"
    ],
    "sizes": [
      "self"
    ],
    "size": [
      "self",
      "index"
    ],
    "doc_idx": [
      "self"
    ],
    "get_doc_idx": [
      "self"
    ],
    "set_doc_idx": [
      "self",
      "doc_idx_"
    ],
    "supports_prefetch": [
      "self"
    ],
    "exists": [
      "path"
    ],
    "dtype": [
      "self"
    ]
  },
  "MMapIndexedDatasetBuilder": {
    "__init__": [
      "self",
      "out_file",
      "dtype"
    ],
    "add_item": [
      "self",
      "tensor"
    ],
    "add_items": [
      "self",
      "arr_list"
    ],
    "add_item_numpy": [
      "self",
      "np_array"
    ],
    "end_document": [
      "self"
    ],
    "merge_file_": [
      "self",
      "another_file"
    ],
    "finalize": [
      "self",
      "index_file"
    ]
  },
  "INITIAL_LOSS_SCALE": [],
  "SCALE_WINDOW": [],
  "DELAYED_SHIFT": [],
  "CONSECUTIVE_HYSTERESIS": [],
  "MIN_LOSS_SCALE": [],
  "LossScaleProfile": {
    "FUSED": [],
    "UNFUSED": []
  },
  "LossScaleProfileDefaults": {},
  "LOSS_SCALE_PROFILE_DEFAULTS": [],
  "LossScaleConfig": {
    "__init__": [
      "self",
      "low_precision_dtype",
      "dynamic_loss_scale",
      "static_loss_scale",
      "dynamic_loss_args"
    ]
  },
  "to_python_float": [
    "t"
  ],
  "LossScalerBase": {
    "__init__": [
      "self",
      "cur_scale"
    ],
    "loss_scale": [
      "self"
    ],
    "scale_gradient": [
      "self",
      "module",
      "grad_in",
      "grad_out"
    ],
    "update_scale": [
      "self",
      "overflow"
    ],
    "scale_loss": [
      "self",
      "loss"
    ],
    "backward": [
      "self",
      "loss",
      "retain_graph"
    ]
  },
  "LossScaler": {
    "__init__": [
      "self",
      "scale"
    ],
    "has_overflow": [
      "self",
      "params"
    ],
    "_has_inf_or_nan": [
      "x"
    ]
  },
  "DynamicLossScaler": {
    "__init__": [
      "self",
      "init_scale",
      "scale_window",
      "min_scale",
      "delayed_shift",
      "consecutive_hysteresis",
      "raise_error_at_min_scale",
      "dtype"
    ],
    "has_overflow_serial": [
      "self",
      "params"
    ],
    "_has_inf_or_nan": [
      "x"
    ],
    "update_scale": [
      "self",
      "overflow"
    ]
  },
  "CreateLossScaler": [
    "dtype",
    "static_loss_scale",
    "dynamic_scaling",
    "dynamic_loss_args"
  ],
  "FP16_UnfusedOptimizer": {
    "__init__": [
      "self",
      "init_optimizer",
      "deepspeed",
      "loss_scale_config",
      "low_precision_dtype",
      "static_loss_scale",
      "dynamic_loss_scale",
      "dynamic_loss_args",
      "verbose",
      "mpu",
      "clip_grad",
      "fused_lamb_legacy"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ],
    "step_fused_lamb": [
      "self",
      "closure"
    ],
    "set_lr": [
      "self",
      "lr"
    ],
    "get_lr": [
      "self"
    ],
    "override_loss_scale": [
      "self",
      "loss_scale"
    ],
    "step": [
      "self",
      "closure"
    ],
    "unscale_and_clip_grads": [
      "self",
      "total_norm",
      "apply_scale"
    ],
    "backward": [
      "self",
      "loss",
      "create_graph",
      "retain_graph"
    ],
    "_update_scale": [
      "self",
      "skip"
    ],
    "_get_state": [
      "self"
    ],
    "_set_state": [
      "self",
      "value"
    ],
    "state": [],
    "_get_param_groups": [
      "self"
    ],
    "_set_param_groups": [
      "self",
      "value"
    ],
    "param_groups": [],
    "_get_loss_scale": [
      "self"
    ],
    "_set_loss_scale": [
      "self",
      "value"
    ],
    "loss_scale": [],
    "state_dict": [
      "self"
    ],
    "refresh_fp32_params": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "load_optimizer_states"
    ],
    "__repr__": [
      "self"
    ],
    "initialize_optimizer_states": [
      "self"
    ]
  },
  "OVERFLOW_CHECK_TIMER": [],
  "COMPUTE_NORM_TIMER": [],
  "UNSCALE_AND_CLIP_TIMER": [],
  "BASIC_STEP_TIMER": [],
  "UPDATE_FP16_TIMER": [],
  "OVERFLOW_TIMERS": [],
  "STEP_TIMERS": [],
  "FP16_Optimizer": {
    "__init__": [
      "self",
      "init_optimizer",
      "deepspeed",
      "loss_scale_config",
      "low_precision_dtype",
      "static_loss_scale",
      "dynamic_loss_scale",
      "initial_dynamic_scale",
      "dynamic_loss_args",
      "verbose",
      "mpu",
      "clip_grad",
      "fused_adam_legacy",
      "has_moe_layers",
      "timers"
    ],
    "initialize_optimizer_states": [
      "self"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ],
    "step_fused_adam": [
      "self",
      "closure"
    ],
    "set_lr": [
      "self",
      "lr"
    ],
    "get_lr": [
      "self"
    ],
    "override_loss_scale": [
      "self",
      "loss_scale"
    ],
    "_require_avoid_recompute_norm": [
      "self",
      "p",
      "tensor_model_parallel_rank"
    ],
    "_get_norm_mask_idx": [
      "self",
      "group"
    ],
    "step": [
      "self",
      "closure"
    ],
    "unscale_and_clip_grads": [
      "self",
      "grad_groups_flat",
      "total_norm",
      "apply_scale"
    ],
    "backward": [
      "self",
      "loss",
      "create_graph",
      "retain_graph"
    ],
    "_update_scale": [
      "self",
      "skip"
    ],
    "_get_state": [
      "self"
    ],
    "_set_state": [
      "self",
      "value"
    ],
    "state": [],
    "_get_param_groups": [
      "self"
    ],
    "_set_param_groups": [
      "self",
      "value"
    ],
    "param_groups": [],
    "state_dict": [
      "self"
    ],
    "refresh_fp32_params": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "load_optimizer_states"
    ],
    "__repr__": [
      "self"
    ],
    "_get_loss_scale": [
      "self"
    ],
    "_set_loss_scale": [
      "self",
      "value"
    ],
    "loss_scale": []
  },
  "ZeroOneAdam": {
    "__init__": [
      "self",
      "params",
      "deepspeed",
      "lr",
      "bias_correction",
      "betas",
      "eps",
      "eps_inside_sqrt",
      "weight_decay",
      "max_grad_norm",
      "var_freeze_step",
      "var_update_scaler",
      "local_step_scaler",
      "local_step_clipper",
      "amsgrad",
      "cuda_aware",
      "comm_backend_name"
    ],
    "step": [
      "self",
      "closure",
      "grads"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "OnebitAdam": {
    "__init__": [
      "self",
      "params",
      "deepspeed",
      "lr",
      "freeze_step",
      "bias_correction",
      "betas",
      "eps",
      "eps_inside_sqrt",
      "weight_decay",
      "max_grad_norm",
      "amsgrad",
      "cuda_aware",
      "comm_backend_name"
    ],
    "step": [
      "self",
      "closure",
      "grads"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "OnebitLamb": {
    "__init__": [
      "self",
      "params",
      "deepspeed",
      "lr",
      "freeze_step",
      "bias_correction",
      "betas",
      "eps",
      "eps_inside_sqrt",
      "weight_decay",
      "max_grad_norm",
      "max_coeff",
      "min_coeff",
      "amsgrad",
      "cuda_aware",
      "comm_backend_name",
      "coeff_beta",
      "factor_max",
      "factor_min",
      "factor_threshold"
    ],
    "step": [
      "self",
      "closure",
      "grads"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "get_lamb_coeffs": [
      "self"
    ]
  },
  "CupyBackend": {
    "__init__": [
      "self"
    ],
    "torch2cupy": [
      "self",
      "tensor"
    ],
    "cupy2torch": [
      "self",
      "cupy_tensor"
    ],
    "compress_by_chunk": [
      "self",
      "cupy_bool_tensor",
      "num_chunks"
    ]
  },
  "TP_group": [],
  "DominoAsyncColumnParallelLinearImpl": {
    "forward": [
      "ctx",
      "inp",
      "weight",
      "bias",
      "handle_dic",
      "h_id"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "DominoAsyncColumnParallelLinear": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "_tp_group",
      "config",
      "init_method",
      "bias",
      "skip_bias_add"
    ],
    "forward": [
      "self",
      "input_",
      "handle_dic",
      "h_id"
    ]
  },
  "RowParallelLinearNoComm": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "config",
      "init_method",
      "bias",
      "stride",
      "skip_bias_add"
    ],
    "forward": [
      "self",
      "input_"
    ]
  },
  "LayerType": {
    "encoder": [],
    "decoder": []
  },
  "AttnType": {
    "self_attn": [],
    "cross_attn": []
  },
  "AttnMaskType": {
    "padding": [],
    "causal": []
  },
  "ModelType": {
    "encoder_or_decoder": [],
    "encoder_and_decoder": []
  },
  "DominoUtil": {
    "BATCH_0": [],
    "BATCH_1": [],
    "HANDLE_DIC": []
  },
  "DominoModule": {
    "__init__": [
      "self"
    ]
  },
  "_Wait_bwd_comm": [
    "input_",
    "dic_",
    "h_id"
  ],
  "NoOper": {
    "symbolic": [
      "graph",
      "input_",
      "handle_dic",
      "h_id"
    ],
    "forward": [
      "ctx",
      "input_",
      "handle_dic",
      "h_id"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "CoreAttention": {
    "__init__": [
      "self",
      "config",
      "tp_world_size",
      "attn_mask_type"
    ],
    "forward": [
      "self",
      "query_layer",
      "key_layer",
      "value_layer",
      "attention_mask"
    ]
  },
  "ShardedAttention": {
    "__init__": [
      "self",
      "config",
      "mpu",
      "apply_rotary_pos_emb",
      "layer_number",
      "attention_type",
      "attn_mask_type"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "micro_batch_num",
      "rotary_pos_emb"
    ],
    "domino_core_attention_forward": [
      "self",
      "mixed_x_layer",
      "attention_mask",
      "rotary_pos_emb"
    ]
  },
  "bias_dropout_add": {
    "__init__": [
      "self",
      "prob"
    ],
    "forward": [
      "self",
      "x",
      "bias",
      "residual"
    ]
  },
  "DominoTransformerLayer": {
    "__init__": [
      "self",
      "config",
      "mpu",
      "apply_rotary_pos_emb",
      "layer_number",
      "layer_type",
      "self_attn_mask_type",
      "drop_path_rate"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "rotary_pos_emb"
    ]
  },
  "DominoTransformer": {
    "__init__": [
      "self",
      "config",
      "mpu",
      "apply_rotary_pos_emb",
      "model_type",
      "layer_type",
      "self_attn_mask_type",
      "post_layer_norm",
      "pre_process",
      "post_process",
      "drop_path_rate"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "rotary_pos_emb"
    ],
    "inter_layer_overlap_forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "rotary_pos_emb"
    ],
    "intra_layer_overlap_forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "rotary_pos_emb"
    ]
  },
  "CheckpointWriterFactory": {
    "__init__": [
      "self",
      "writer_config",
      "aio_config",
      "dp_writer_config"
    ],
    "create_writer": [
      "self",
      "file_path",
      "optimize_dp_state"
    ],
    "release_writer": [
      "self"
    ],
    "_setup_for_aio": [
      "self",
      "aio_config"
    ],
    "_setup_for_gds": [
      "self",
      "aio_config"
    ]
  },
  "SOCKETS_PER_MACHINE": [],
  "MPUInfo": {},
  "_create_model_parallel_info": [
    "mpu"
  ],
  "ExpertParallelInfo": {},
  "_create_expert_parallel_info": [
    "groups"
  ],
  "UniversalParallelInfo": {},
  "create_universal_parallel_info": [
    "groups",
    "has_moe_layers"
  ],
  "create_data_parallel_writer_config": [
    "groups",
    "parallel_unit",
    "zero_stage",
    "has_moe_layers"
  ],
  "VALID_VALUES": [],
  "CHECKPOINT_DEFAULT_DICT": [],
  "_validate_config_values": [
    "config_name",
    "config_dict",
    "valid_values"
  ],
  "_make_upper_case": [
    "value"
  ],
  "get_checkpoint_writer_config": [
    "param_dict"
  ],
  "get_checkpoint_config": [
    "param_dict"
  ],
  "DataParallelWriterConfig": {},
  "DataParallelWriterFactory": {
    "__init__": [
      "self",
      "uni_parallel_info",
      "parallel_unit"
    ],
    "create_config": [
      "self",
      "zero_stage",
      "has_moe_layers"
    ],
    "_create_config": [
      "self",
      "world_size",
      "rank"
    ],
    "_get_expert_data_parallel_config": [
      "self"
    ],
    "_get_expert_parallel_write_for_2d": [
      "self"
    ],
    "_get_data_parallel_config": [
      "self"
    ],
    "_get_parallel_write_for_3d": [
      "self"
    ],
    "_get_slice_writers": [
      "self",
      "slice_resources",
      "my_dp_ranks"
    ],
    "_assign_resources_to_tensor_slice": [
      "self",
      "slice_resources",
      "my_slice_index",
      "my_dp_ranks"
    ],
    "_get_parallel_write_for_ddp": [
      "self",
      "dp_world_size",
      "dp_rank"
    ]
  },
  "CHECKPOINT_FORMAT": [],
  "CHECKPOINT_SERIALIZATION": [],
  "CHECKPOINT_SERIALIZATION_DEFAULT": [],
  "CHECKPOINT_WRITER": [],
  "CHECKPOINT_WRITER_DEFAULT": [],
  "CHECKPOINT_WRITER_TYPE": [],
  "CheckpointWriterType": {
    "MOCK": [],
    "PYTHON": [],
    "FAST": []
  },
  "CHECKPOINT_WRITER_TYPE_DEFAULT": [],
  "CHECKPOINT_WRITER_TYPES": [],
  "CHECKPOINT_IO_BUFFER_SIZE": [],
  "CHECKPOINT_IO_BUFFER_SIZE_DEFAULT": [],
  "CHECKPOINT_IO_BUFFER_DOUBLE": [],
  "CHECKPOINT_IO_BUFFER_DOUBLE_DEFAULT": [],
  "CHECKPOINT_IO_MULTIPLIER": [],
  "CHECKPOINT_IO_MULTIPLIER_DEFAULT": [],
  "CHECKPOINT_IO_STATISTICS": [],
  "CHECKPOINT_IO_STATISTICS_DEFAULT": [],
  "CHECKPOINT_DATA_PARALLEL": [],
  "CHECKPOINT_DATA_PARALLEL_DEFAULT": [],
  "CheckpointDataParallel": {
    "REPLICA": [],
    "SOCKET": [],
    "MACHINE": []
  },
  "CHECKPOINT_DATA_PARALLEL_UNITS": [],
  "CHECKPOINT_WRITER_DECOUPLED": [],
  "CHECKPOINT_WRITER_DECOUPLED_DEFAULT": [],
  "configure_zenflow": [
    "optimizer_z3",
    "zenflow_config"
  ],
  "_initialize_zenflow_stage3_prologue": [
    "optimizer_z3",
    "module",
    "zenflow_config"
  ],
  "_initialize_zenflow_stage3_epilogue": [
    "optimizer_z3",
    "zenflow_config",
    "overlap_comm"
  ],
  "zenflow_cpu_optimizer_step": [
    "optimizer_z3"
  ],
  "_sync_selective_optimizer_lr": [
    "optimizer_z3"
  ],
  "selective_optimizer_step": [
    "optimizer_z3"
  ],
  "is_zenflow_select_boundary": [
    "optimizer_z3"
  ],
  "update_selected_channels": [
    "optimizer_z3",
    "params_to_update",
    "grad_partitions"
  ],
  "_process_selected_fp32_groups_grad": [
    "optimizer_z3",
    "params_to_update",
    "grad_partitions"
  ],
  "sync_fp32_param_from_gpu": [
    "optimizer_z3"
  ],
  "zenflow_backward_prologue": [
    "optimizer_z3"
  ],
  "zenflow_backward_epilogue": [
    "optimizer_z3"
  ],
  "log_selective_optimizer_timers": [
    "optimizer_z3"
  ],
  "initialize_optimizer_states": [
    "optimizer_z3"
  ],
  "get_overlap_step_state": [
    "optimizer_z3"
  ],
  "partition_grads": [
    "optimizer_z3",
    "params_to_release",
    "grad_partitions"
  ],
  "unscale_and_clip_grads": [
    "self",
    "sub_group_id",
    "total_norm",
    "now_state"
  ],
  "zenflow_cpu_optimizer_overlap_step": [
    "optimizer_z3",
    "now_state",
    "scaled_global_grad_norm"
  ],
  "wait_last_update_and_copy": [
    "optimizer_z3",
    "timer_names"
  ],
  "step": [
    "optimizer_z3",
    "closure"
  ],
  "ZenFlowConfig": {
    "validate_fields": [
      "self"
    ]
  },
  "is_zenflow_update_boundary": [
    "engine"
  ],
  "zenflow_step": [
    "engine",
    "lr_kwargs"
  ],
  "_take_selective_parameter_step": [
    "engine"
  ],
  "_take_lr_scheduler_step": [
    "engine",
    "lr_kwargs"
  ],
  "_log_selective_optimizer_timers": [
    "engine"
  ],
  "sync_zenflow_optimizer_lr": [
    "engine"
  ],
  "_flatten_dense_tensors": [
    "tensors"
  ],
  "_unflatten_dense_tensors": [
    "flat",
    "tensors"
  ],
  "disable_accelerator": [],
  "zenflow_optimizer_process": [
    "pipe",
    "param_groups",
    "shared_overlap_grad_map",
    "shared_stale_param_map",
    "zf_affinity"
  ],
  "all_tensors_equal": [
    "tensor_list"
  ],
  "start_optimizer_process": [
    "zf_optimizer"
  ],
  "OPTIMIZER_TRANSMIT_TIMER": [],
  "OPTIMIZER_CALC_TIMER": [],
  "OPTIMIZER_RECV_PARAMS_TIMER": [],
  "OPTIMIZER_UPDATE_MODEL_TIMER": [],
  "SELECTIVE_OPTIMIZER_UPDATE_TIMER": [],
  "SELECTIVE_OPTIMIZER_PROCESS_TIMER": [],
  "SELECTIVE_OPTIMIZER_STEP_TIMER": [],
  "SELECTIVE_OPTIMIZER_SYNC_TIMER": [],
  "SELECTIVE_OPTIMIZER_TIMERS": [],
  "ZenFlowZeroOptimizer": {
    "__init__": [
      "self",
      "init_optimizer",
      "param_names",
      "timers",
      "optimizer_params"
    ],
    "create": [
      "cls",
      "zenflow_config"
    ],
    "_configure_zenflow": [
      "self",
      "zenflow_config"
    ],
    "is_zenflow_select_boundary": [
      "self"
    ],
    "sync_fp32_param_from_gpu": [
      "self"
    ],
    "update_selected_channels": [
      "self",
      "tensor",
      "total_size",
      "communication_data_type"
    ],
    "_process_selected_fp32_groups_grad": [
      "self",
      "tensor",
      "total_size",
      "communication_data_type"
    ],
    "average_tensor": [
      "self",
      "tensor",
      "communication_data_type"
    ],
    "backward": [
      "self",
      "loss",
      "retain_graph"
    ],
    "log_selective_optimizer_timers": [
      "self"
    ],
    "_sync_selective_optimizer_lr": [
      "self"
    ],
    "_selective_optimizer_step": [
      "self",
      "group_no"
    ],
    "selective_optimizer_step": [
      "self",
      "closure"
    ]
  },
  "ZenFlowZeroOptimizerSequential": {
    "__init__": [
      "self"
    ],
    "zenflow_cpu_optimizer_step": [
      "self",
      "group_no"
    ]
  },
  "ZenFlowZeroOptimizerParallel": {
    "__init__": [
      "self"
    ],
    "initialize_optimizer_states": [
      "self"
    ],
    "_get_offload_gradient_dict": [
      "self"
    ],
    "get_overlap_step_state": [
      "self"
    ],
    "async_inplace_copy_grad_to_fp32_buffer_from_gpu": [
      "self",
      "param"
    ],
    "wait_last_update_and_copy": [
      "self"
    ],
    "zenflow_cpu_optimizer_step": [
      "self",
      "now_state",
      "scaled_global_grad_norm"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "TaskKeys": {
    "PARAM_DATA": [],
    "PARAM_GRAD": [],
    "PARAM_GROUP_ID": [],
    "SUB_GROUP_ID": [],
    "ROLLBACK": []
  },
  "ResultKeys": {
    "UPDATED_PARAM": [],
    "EVENT_TYPE": []
  },
  "EventTypes": {
    "ADAM_STEP": [],
    "ROLLBACK": []
  },
  "superoffload_optimizer_worker": [
    "param_queue",
    "result_queue",
    "optimizer_config",
    "max_grad_numel"
  ],
  "SuperOffloadCPUOptimizer": {
    "__init__": [
      "self",
      "optimizer_config",
      "cpuadam_cores_perc",
      "max_grad_numel"
    ],
    "_set_cpu_affinity": [
      "self",
      "cpuadam_cores_perc"
    ],
    "async_step": [
      "self",
      "param_group_id",
      "sub_group_id",
      "fp32_param",
      "fp32_grad",
      "rollback"
    ],
    "get_result": [
      "self",
      "expected_event_type"
    ],
    "close": [
      "self"
    ]
  },
  "SuperOffloadOptimizer_Stage3": {
    "__init__": [
      "self",
      "module",
      "init_optimizer",
      "param_names",
      "timers",
      "ds_config"
    ],
    "_create_fp16_sub_groups": [
      "self",
      "params_group"
    ],
    "_optimizer_step": [
      "self",
      "sub_group_id"
    ],
    "reduce_independent_p_g_buckets_and_remove_grads": [
      "self",
      "param"
    ],
    "_reassign_or_swap_out_partitioned_parameters": [
      "self",
      "sub_group_id"
    ],
    "_reassign_or_swap_out_partitioned_parameters_async": [
      "self",
      "sub_group_id",
      "updated_param"
    ],
    "partition_grads": [
      "self",
      "params_to_release",
      "grad_partitions"
    ],
    "step": [
      "self",
      "closure"
    ],
    "_wait_for_async_operations": [
      "self",
      "timeout_seconds"
    ],
    "_wait_for_single_async_result": [
      "self",
      "event_type",
      "timeout_seconds"
    ],
    "_sync_cpu_optimizer_step": [
      "self",
      "param_group_id",
      "sub_group_id",
      "fp32_param_data",
      "fp32_grad_data",
      "rollback",
      "timeout_seconds"
    ],
    "_handle_overflow_rollback": [
      "self"
    ],
    "_handle_gradient_clipping": [
      "self",
      "scaled_global_grad_norm"
    ],
    "check_clip_grads": [
      "self",
      "total_norm"
    ]
  },
  "ACTIVATION_CHKPT_FORMAT": [],
  "ACT_CHKPT_PARTITION_ACTIVATIONS": [],
  "ACT_CHKPT_PARTITION_ACTIVATIONS_DEFAULT": [],
  "ACT_CHKPT_NUMBER_CHECKPOINTS": [],
  "ACT_CHKPT_NUMBER_CHECKPOINTS_DEFAULT": [],
  "ACT_CHKPT_CONTIGUOUS_MEMORY_OPTIMIZATION": [],
  "ACT_CHKPT_CONTIGUOUS_MEMORY_OPTIMIZATION_DEFAULT": [],
  "ACT_CHKPT_SYNCHRONIZE_CHECKPOINT_BOUNDARY": [],
  "ACT_CHKPT_SYNCHRONIZE_CHECKPOINT_BOUNDARY_DEFAULT": [],
  "ACT_CHKPT_PROFILE": [],
  "ACT_CHKPT_PROFILE_DEFAULT": [],
  "ACT_CHKPT_CPU_CHECKPOINTING": [],
  "ACT_CHKPT_CPU_CHECKPOINTING_DEFAULT": [],
  "ACT_CHKPT": [],
  "ACT_CHKPT_DEFAULT": [],
  "DeepSpeedActivationCheckpointingConfig": {
    "__init__": [
      "self",
      "param_dict"
    ],
    "_initialize": [
      "self",
      "act_chkpt_config_dict"
    ]
  },
  "deepspeed_checkpointing_enabled": [],
  "mp_rank": [],
  "mp_size": [],
  "mp_group": [],
  "num_layers": [],
  "contiguous_data_buffers": [],
  "data_offsets": [],
  "contiguous_size_buffers": [],
  "size_offsets": [],
  "PARTITION_ACTIVATIONS": [],
  "CPU_CHECKPOINT": [],
  "CONTIGUOUS_CHECKPOINTING": [],
  "SYNCHRONIZE": [],
  "PROFILE_TIME": [],
  "_MODEL_PARALLEL_RNG_TRACKER_NAME": [],
  "detach_variable": [
    "inputs",
    "device"
  ],
  "_set_cuda_rng_state": [
    "new_state",
    "device"
  ],
  "CudaRNGStatesTracker": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "get_states": [
      "self"
    ],
    "set_states": [
      "self",
      "states"
    ],
    "add": [
      "self",
      "name",
      "seed"
    ],
    "fork": [
      "self",
      "name"
    ]
  },
  "_CUDA_RNG_STATE_TRACKER": [],
  "get_cuda_rng_tracker": [],
  "model_parallel_cuda_manual_seed": [
    "seed"
  ],
  "model_parallel_reconfigure_tp_seed": [
    "seed"
  ],
  "get_partition_start": [
    "item"
  ],
  "get_partition_size": [
    "item"
  ],
  "gather_partitioned_activations": [
    "tensors",
    "device"
  ],
  "extract_tensors": [
    "all_objects"
  ],
  "merge_tensors": [
    "tensor_objects",
    "non_tensor_objects",
    "tensor_flags"
  ],
  "is_activation_to_checkpoint": [
    "item"
  ],
  "partition_activations": [
    "args",
    "cpu_checkpoint",
    "contiguous_checkpoint"
  ],
  "get_partitioned_activations_for_backward": [
    "args",
    "inputs",
    "contiguous_checkpoint"
  ],
  "get_cpu_activations_for_backward": [
    "args",
    "inputs"
  ],
  "CheckpointFunction": {
    "forward": [
      "ctx",
      "run_function",
      "all_outputs"
    ],
    "backward": [
      "ctx"
    ]
  },
  "non_reentrant_checkpoint": [
    "function"
  ],
  "checkpoint": [
    "function"
  ],
  "partition_activations_in_checkpoint": [
    "partition_activation"
  ],
  "set_num_layers": [
    "nlayers"
  ],
  "reset": [],
  "_configure_defaults": [],
  "is_configured": [],
  "ProcessTopology": {
    "__init__": [
      "self",
      "axes",
      "dims"
    ],
    "get_rank": [
      "self"
    ],
    "get_axis_names": [
      "self"
    ],
    "get_rank_repr": [
      "self",
      "rank",
      "omit_axes",
      "inner_sep",
      "outer_sep"
    ],
    "get_dim": [
      "self",
      "axis"
    ],
    "get_coord": [
      "self",
      "rank"
    ],
    "get_axis_comm_lists": [
      "self",
      "axis"
    ],
    "filter_match": [
      "self"
    ],
    "get_axis_list": [
      "self",
      "axis",
      "idx"
    ],
    "world_size": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "_prime_factors": [
    "N"
  ],
  "PipeDataParallelTopology": {
    "__init__": [
      "self",
      "num_pp",
      "num_dp"
    ]
  },
  "PipeModelDataParallelTopology": {
    "__init__": [
      "self",
      "num_pp",
      "num_mp",
      "num_dp"
    ]
  },
  "PipelineParallelGrid": {
    "__init__": [
      "self",
      "topology",
      "process_group"
    ],
    "get_stage_id": [
      "self"
    ],
    "get_data_parallel_id": [
      "self"
    ],
    "_build_p2p_groups": [
      "self"
    ],
    "_is_grid_valid": [
      "self"
    ],
    "stage_to_global": [
      "self",
      "stage_id"
    ],
    "topology": [
      "self"
    ],
    "get_global_rank": [
      "self"
    ],
    "get_pipe_parallel_rank": [
      "self"
    ],
    "get_pipeline_model_parallel_rank": [
      "self"
    ],
    "get_pipe_parallel_world_size": [
      "self"
    ],
    "get_pipeline_model_parallel_world_size": [
      "self"
    ],
    "get_pipe_parallel_group": [
      "self"
    ],
    "get_data_parallel_rank": [
      "self"
    ],
    "get_data_parallel_world_size": [
      "self"
    ],
    "get_data_parallel_group": [
      "self"
    ],
    "get_data_parallel_group_ranks": [
      "self"
    ],
    "get_model_parallel_rank": [
      "self"
    ],
    "get_model_parallel_world_size": [
      "self"
    ],
    "get_model_parallel_group": [
      "self"
    ],
    "get_slice_parallel_rank": [
      "self"
    ],
    "get_tensor_model_parallel_rank": [
      "self"
    ],
    "get_slice_parallel_world_size": [
      "self"
    ],
    "get_tensor_model_parallel_world_size": [
      "self"
    ],
    "get_slice_parallel_group": [
      "self"
    ]
  },
  "PipeSchedule": {
    "__init__": [
      "self",
      "micro_batches",
      "stages",
      "stage_id"
    ],
    "steps": [
      "self"
    ],
    "num_pipe_buffers": [
      "self"
    ],
    "_valid_micro_batch": [
      "self",
      "micro_batch_id"
    ],
    "_valid_stage": [
      "self",
      "stage_id"
    ],
    "stage": [
      "self"
    ],
    "num_stages": [
      "self"
    ],
    "num_micro_batches": [
      "self"
    ],
    "is_first_stage": [
      "self"
    ],
    "is_last_stage": [
      "self"
    ],
    "_buffer_idx": [
      "self",
      "micro_batch_id"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ]
  },
  "InferenceSchedule": {
    "steps": [
      "self"
    ],
    "num_pipe_buffers": [
      "self"
    ]
  },
  "TrainSchedule": {
    "steps": [
      "self"
    ],
    "num_pipe_buffers": [
      "self"
    ],
    "_step_to_micro_batch": [
      "self",
      "step_id"
    ],
    "_even_step_forward_id": [
      "self",
      "step_id"
    ],
    "_odd_step_forward_id": [
      "self",
      "step_id"
    ],
    "_even_step_backward_id": [
      "self",
      "step_id"
    ],
    "_odd_step_backward_id": [
      "self",
      "step_id"
    ]
  },
  "DataParallelSchedule": {
    "steps": [
      "self"
    ],
    "num_pipe_buffers": [
      "self"
    ]
  },
  "PipeInstruction": {
    "__init__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "OptimizerStep": {},
  "ReduceGrads": {},
  "ReduceTiedGrads": {},
  "BufferOpInstruction": {
    "__init__": [
      "self",
      "buffer_id"
    ]
  },
  "LoadMicroBatch": {},
  "ForwardPass": {},
  "BackwardPass": {},
  "SendActivation": {},
  "RecvActivation": {},
  "SendGrad": {},
  "RecvGrad": {},
  "_is_even": [
    "x"
  ],
  "_is_odd": [
    "x"
  ],
  "PipelineError": {},
  "LayerSpec": {
    "__init__": [
      "self",
      "typename"
    ],
    "__repr__": [
      "self"
    ],
    "build": [
      "self",
      "log"
    ]
  },
  "TiedLayerSpec": {
    "__init__": [
      "self",
      "key",
      "typename"
    ]
  },
  "PipelineModule": {
    "__init__": [
      "self",
      "layers",
      "num_stages",
      "topology",
      "loss_fn",
      "seed_layers",
      "seed_fn",
      "base_seed",
      "partition_method",
      "activation_checkpoint_interval",
      "activation_checkpoint_func",
      "checkpointable_layers",
      "dynamic_shape"
    ],
    "_precompute_checkpointable_values": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "_get_frozen_parameter_names": [
      "self",
      "layer"
    ],
    "_count_layer_params": [
      "self"
    ],
    "_find_layer_type": [
      "self",
      "layername"
    ],
    "forward": [
      "self",
      "forward_input"
    ],
    "_partition_layers": [
      "self",
      "method"
    ],
    "_recursive_getattr": [
      "module",
      "attr_name"
    ],
    "allreduce_tied_weight_gradients": [
      "self"
    ],
    "get_tied_weights_and_groups": [
      "self"
    ],
    "_synchronize_tied_weights": [
      "self"
    ],
    "_index_tied_modules": [
      "self"
    ],
    "partitions": [
      "self"
    ],
    "stage_owner": [
      "self",
      "layer_idx"
    ],
    "_set_bounds": [
      "self",
      "start",
      "stop"
    ],
    "set_checkpoint_interval": [
      "self",
      "interval"
    ],
    "topology": [
      "self"
    ],
    "mpu": [
      "self"
    ],
    "num_pipeline_stages": [
      "self"
    ],
    "ckpt_prefix": [
      "self",
      "checkpoints_path",
      "tag"
    ],
    "ckpt_layer_path": [
      "self",
      "ckpt_dir",
      "local_layer_idx"
    ],
    "ckpt_layer_path_list": [
      "self",
      "ckpt_dir",
      "local_layer_idx"
    ],
    "save_state_dict": [
      "self",
      "save_dir",
      "checkpoint_engine",
      "exclude_frozen_params"
    ],
    "load_state_dir": [
      "self",
      "load_dir",
      "checkpoint_engine",
      "strict"
    ],
    "_is_checkpointable": [
      "self",
      "funcs"
    ],
    "get_additional_losses": [
      "self"
    ],
    "compile": [
      "self"
    ]
  },
  "TARGET_ID": [],
  "LOG_STAGE": [],
  "DATA_PARALLEL_ID": [],
  "BATCH_INPUT_TIMER": [],
  "TRAIN_BATCH_TIMER": [],
  "PIPE_SEND_OUTPUT_TIMER": [],
  "PIPE_SEND_GRAD_TIMER": [],
  "PIPE_RECV_INPUT_TIMER": [],
  "PIPE_RECV_GRAD_TIMER": [],
  "TENSOR_META_SIZE": [],
  "is_even": [
    "number"
  ],
  "_tensor_bytes": [
    "tensor"
  ],
  "PipelineEngine": {
    "ID_TO_DTYPE": [],
    "DTYPE_TO_ID": [],
    "__init__": [
      "self",
      "has_bool_tensors"
    ],
    "set_has_attention_mask": [
      "self",
      "value"
    ],
    "_build_data_iter": [
      "self",
      "dataset"
    ],
    "_exec_reduce_tied_grads": [
      "self"
    ],
    "_exec_reduce_grads": [
      "self"
    ],
    "_bf16_reduce_grads": [
      "self"
    ],
    "_reserve_pipe_buffers": [
      "self",
      "num_buffers"
    ],
    "reset_activation_shape": [
      "self"
    ],
    "train_batch": [
      "self",
      "data_iter"
    ],
    "eval_batch": [
      "self",
      "data_iter",
      "return_logits",
      "compute_loss",
      "reduce_output",
      "bcast_loss",
      "num_micro_batches"
    ],
    "set_train_batch_size": [
      "self",
      "train_batch_size"
    ],
    "is_first_stage": [
      "self"
    ],
    "is_last_stage": [
      "self"
    ],
    "get_pipeline_parallel_rank": [
      "self"
    ],
    "_reduce_outputs": [
      "self",
      "outputs",
      "reduce",
      "reduce_dp",
      "micro_batches"
    ],
    "_bcast_pipe_scalar": [
      "self",
      "data",
      "src_rank",
      "dtype"
    ],
    "_aggregate_total_loss": [
      "self"
    ],
    "set_dataloader": [
      "self",
      "loader"
    ],
    "set_dataiterator": [
      "self",
      "iterator"
    ],
    "set_batch_fn": [
      "self",
      "fn"
    ],
    "is_gradient_accumulation_boundary": [
      "self"
    ],
    "log_for_device": [
      "self"
    ],
    "tput_log": [
      "self"
    ],
    "_next_batch": [
      "self"
    ],
    "_exec_forward_pass": [
      "self",
      "buffer_id"
    ],
    "_exec_backward_pass": [
      "self",
      "buffer_id"
    ],
    "_exec_load_micro_batch": [
      "self",
      "buffer_id"
    ],
    "_send_tensor_meta": [
      "self",
      "buffer",
      "recv_stage"
    ],
    "_recv_tensor_meta": [
      "self",
      "send_stage"
    ],
    "_exec_send_activations": [
      "self",
      "buffer_id"
    ],
    "_exec_send_grads": [
      "self",
      "buffer_id"
    ],
    "_exec_recv_activations": [
      "self",
      "buffer_id"
    ],
    "_exec_recv_grads": [
      "self",
      "buffer_id"
    ],
    "_exec_optimizer_step": [
      "self",
      "lr_kwargs"
    ],
    "_allocate_zeros": [
      "self",
      "shape"
    ],
    "_allocate_buffer": [
      "self",
      "shape",
      "num_buffers"
    ],
    "_allocate_or_extend_buffers": [
      "self",
      "idx",
      "shape",
      "dtype"
    ],
    "forward": [
      "self"
    ],
    "backward": [
      "self"
    ],
    "step": [
      "self"
    ],
    "module_state_dict": [
      "self",
      "exclude_frozen_parameters"
    ],
    "load_module_state_dict": [
      "self",
      "checkpoint",
      "strict",
      "custom_load_fn",
      "fetch_z3_params"
    ],
    "_INSTRUCTION_MAP": [],
    "_exec_schedule": [
      "self",
      "pipe_schedule"
    ],
    "get_additional_losses": [
      "self"
    ]
  },
  "_groups": [],
  "_grid": [],
  "_async": [],
  "can_send_recv": [],
  "init_process_groups": [
    "grid"
  ],
  "_is_valid_send_recv": [
    "src_stage",
    "dest_stage"
  ],
  "wait": [],
  "send_obj": [
    "msg",
    "dest"
  ],
  "recv_obj": [
    "sender"
  ],
  "_get_send_recv_group": [
    "src_stage",
    "dest_stage"
  ],
  "TpTrainingManager": {
    "__init__": [
      "self",
      "model",
      "tp_size",
      "dtype"
    ],
    "_initialize_config": [
      "self",
      "dtype"
    ],
    "_apply_policies": [
      "self",
      "parser_dict"
    ],
    "_apply_injection_policy": [
      "self",
      "config",
      "client_module"
    ],
    "_initialize_tp_config": [
      "self",
      "tp_size"
    ],
    "_get_model_config_generate": [
      "self"
    ]
  },
  "AUTOTP_MODE": {
    "TRAINING": [],
    "INFERENCE": []
  },
  "TPConfig": {},
  "TPTrainingConfig": {
    "get_partition_config_object": [
      "self"
    ]
  },
  "get_tensor_parallel_config": [
    "ds_config"
  ],
  "_TP_MODEL_INIT_ARGS": [],
  "load_ds_config": [
    "config"
  ],
  "record_tp_model_init_args": [
    "tp_size",
    "dtype",
    "tp_group",
    "dist_module"
  ],
  "tp_group_world_size": [
    "tp_group",
    "dist_module"
  ],
  "infer_config_dtype": [
    "config_dict"
  ],
  "merge_tp_model_init_into_config": [
    "config_dict",
    "mpu",
    "mesh_param",
    "dist_module"
  ],
  "QuantizedParameter": {
    "__new__": [
      "cls",
      "data",
      "requires_grad",
      "quantization_config",
      "quantizer"
    ],
    "_ensure_quantized": [
      "self",
      "tensor"
    ],
    "dequantized": [
      "self"
    ],
    "offload": [
      "self",
      "revert"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "__deepcopy__": [
      "self",
      "memo"
    ],
    "__copy__": [
      "self"
    ],
    "cuda": [
      "self",
      "device",
      "non_blocking"
    ],
    "to": [
      "self"
    ]
  },
  "OptimizedLinear": {
    "__new__": [
      "self",
      "input_dim",
      "output_dim",
      "bias",
      "lora_config",
      "quantization_config",
      "device",
      "dtype",
      "linear_cls"
    ]
  },
  "LoRAOptimizedLinear": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "bias",
      "lora_config",
      "quantization_config",
      "device",
      "dtype",
      "linear_cls"
    ],
    "disable": [
      "self"
    ],
    "init_lora": [
      "self"
    ],
    "_load_from_state_dict": [
      "self",
      "state_dict",
      "prefix",
      "local_metadata",
      "strict",
      "missing_keys",
      "unexpected_keys",
      "error_msgs"
    ],
    "full_weight": [
      "self"
    ],
    "linear_without_F_linear": [
      "self",
      "input",
      "weight"
    ],
    "forward": [
      "self",
      "input_tensor"
    ]
  },
  "init_lora": [
    "model"
  ],
  "LoRAConfig": {},
  "Monitor": {
    "__init__": [
      "self",
      "monitor_config"
    ],
    "write_events": [
      "self",
      "event_list"
    ]
  },
  "MonitorMaster": {
    "__init__": [
      "self",
      "monitor_config"
    ],
    "write_events": [
      "self",
      "event_list"
    ]
  },
  "WandbMonitor": {
    "__init__": [
      "self",
      "wandb_config"
    ],
    "log": [
      "self",
      "data",
      "step",
      "commit"
    ],
    "write_events": [
      "self",
      "event_list"
    ]
  },
  "Name": [],
  "Value": [],
  "GlobalSamples": [],
  "Event": [],
  "CometMonitor": {
    "__init__": [
      "self",
      "comet_config"
    ],
    "experiment": [
      "self"
    ],
    "samples_log_interval": [
      "self"
    ],
    "write_events": [
      "self",
      "event_list"
    ]
  },
  "EventsLogScheduler": {
    "__init__": [
      "self",
      "samples_log_interval"
    ],
    "needs_logging": [
      "self",
      "name",
      "current_sample"
    ]
  },
  "check_tb_availability": [],
  "check_wandb_availability": [],
  "check_comet_availability": [],
  "get_monitor_config": [
    "param_dict"
  ],
  "TensorBoardConfig": {},
  "WandbConfig": {},
  "CSVConfig": {},
  "CometConfig": {},
  "DeepSpeedMonitorConfig": {
    "check_enabled": [
      "self"
    ]
  },
  "TensorBoardMonitor": {
    "__init__": [
      "self",
      "tensorboard_config"
    ],
    "get_summary_writer": [
      "self",
      "base"
    ],
    "write_events": [
      "self",
      "event_list",
      "flush"
    ],
    "flush": [
      "self"
    ]
  },
  "csvMonitor": {
    "__init__": [
      "self",
      "csv_config"
    ],
    "setup_log_dir": [
      "self",
      "base"
    ],
    "write_events": [
      "self",
      "event_list"
    ]
  },
  "HPU_Accelerator": {
    "__init__": [
      "self"
    ],
    "apply_hpu_workarounds": [
      "self"
    ],
    "is_synchronized_device": [
      "self"
    ],
    "use_host_timers": [
      "self"
    ],
    "resolves_data_dependency": [
      "self"
    ],
    "handles_memory_backpressure": [
      "self"
    ],
    "device_name": [
      "self",
      "device_index"
    ],
    "device": [
      "self",
      "device_index"
    ],
    "set_device": [
      "self",
      "device_index"
    ],
    "current_device": [
      "self"
    ],
    "current_device_name": [
      "self"
    ],
    "device_count": [
      "self"
    ],
    "synchronize": [
      "self",
      "device_index"
    ],
    "random": [
      "self"
    ],
    "set_rng_state": [
      "self",
      "new_state",
      "device_index"
    ],
    "get_rng_state": [
      "self",
      "device_index"
    ],
    "manual_seed": [
      "self",
      "seed"
    ],
    "manual_seed_all": [
      "self",
      "seed"
    ],
    "initial_seed": [
      "self"
    ],
    "default_generator": [
      "self",
      "device_index"
    ],
    "Stream": [
      "self"
    ],
    "stream": [
      "self",
      "stream"
    ],
    "current_stream": [
      "self",
      "device_index"
    ],
    "default_stream": [
      "self",
      "device_index"
    ],
    "Event": [
      "self"
    ],
    "empty_cache": [
      "self"
    ],
    "memory_allocated": [
      "self",
      "device_index"
    ],
    "max_memory_allocated": [
      "self",
      "device_index"
    ],
    "reset_max_memory_allocated": [
      "self",
      "device_index"
    ],
    "memory_cached": [
      "self",
      "device_index"
    ],
    "max_memory_cached": [
      "self",
      "device_index"
    ],
    "reset_max_memory_cached": [
      "self",
      "device_index"
    ],
    "memory_stats": [
      "self",
      "device_index"
    ],
    "reset_peak_memory_stats": [
      "self",
      "device_index"
    ],
    "memory_reserved": [
      "self",
      "device_index"
    ],
    "max_memory_reserved": [
      "self",
      "device_index"
    ],
    "total_memory": [
      "self",
      "device_index"
    ],
    "available_memory": [
      "self",
      "device_index"
    ],
    "is_bf16_supported": [
      "self"
    ],
    "is_fp16_supported": [
      "self"
    ],
    "supported_dtypes": [
      "self"
    ],
    "amp": [
      "self"
    ],
    "is_available": [
      "self"
    ],
    "range_push": [
      "self",
      "msg"
    ],
    "range_pop": [
      "self"
    ],
    "lazy_call": [
      "self",
      "callback"
    ],
    "communication_backend_name": [
      "self"
    ],
    "is_triton_supported": [
      "self"
    ],
    "create_graph": [
      "self"
    ],
    "capture_to_graph": [
      "self",
      "graph",
      "pool",
      "stream"
    ],
    "replay_graph": [
      "self",
      "graph"
    ],
    "BFloat16Tensor": [
      "self"
    ],
    "ByteTensor": [
      "self"
    ],
    "DoubleTensor": [
      "self"
    ],
    "FloatTensor": [
      "self"
    ],
    "HalfTensor": [
      "self"
    ],
    "IntTensor": [
      "self"
    ],
    "LongTensor": [
      "self"
    ],
    "pin_memory": [
      "self",
      "tensor",
      "align_bytes"
    ],
    "is_pinned": [
      "self",
      "tensor"
    ],
    "on_accelerator": [
      "self",
      "tensor"
    ],
    "op_builder_dir": [
      "self"
    ],
    "class_dict": [],
    "_lazy_init_class_dict": [
      "self"
    ],
    "create_op_builder": [
      "self",
      "class_name"
    ],
    "get_op_builder": [
      "self",
      "class_name"
    ],
    "build_extension": [
      "self"
    ],
    "export_envs": [
      "self"
    ],
    "visible_devices_envs": [
      "self"
    ],
    "set_visible_devices_envs": [
      "self",
      "current_env",
      "local_accelerator_ids"
    ],
    "get_compile_backend": [
      "self"
    ],
    "set_compile_backend": [
      "self",
      "backend"
    ]
  },
  "MPS_Accelerator": {
    "__init__": [
      "self"
    ],
    "is_synchronized_device": [
      "self"
    ],
    "use_host_timers": [
      "self"
    ],
    "resolves_data_dependency": [
      "self"
    ],
    "handles_memory_backpressure": [
      "self"
    ],
    "device_name": [
      "self",
      "device_index"
    ],
    "device": [
      "self",
      "device_index"
    ],
    "set_device": [
      "self",
      "device_index"
    ],
    "current_device": [
      "self"
    ],
    "current_device_name": [
      "self"
    ],
    "device_count": [
      "self"
    ],
    "synchronize": [
      "self",
      "device_index"
    ],
    "random": [
      "self"
    ],
    "set_rng_state": [
      "self",
      "new_state",
      "device_index"
    ],
    "get_rng_state": [
      "self",
      "device_index"
    ],
    "manual_seed": [
      "self",
      "seed"
    ],
    "manual_seed_all": [
      "self",
      "seed"
    ],
    "seed": [
      "self"
    ],
    "initial_seed": [
      "self"
    ],
    "default_generator": [
      "self",
      "device_index"
    ],
    "Stream": [
      "self"
    ],
    "stream": [
      "self",
      "stream"
    ],
    "current_stream": [
      "self",
      "device_index"
    ],
    "default_stream": [
      "self",
      "device_index"
    ],
    "Event": [
      "self"
    ],
    "empty_cache": [
      "self"
    ],
    "memory_allocated": [
      "self",
      "device_index"
    ],
    "max_memory_allocated": [
      "self",
      "device_index"
    ],
    "set_per_process_memory_fraction": [
      "self",
      "fraction"
    ],
    "reset_max_memory_allocated": [
      "self",
      "device_index"
    ],
    "memory_cached": [
      "self",
      "device_index"
    ],
    "max_memory_cached": [
      "self",
      "device_index"
    ],
    "reset_max_memory_cached": [
      "self",
      "device_index"
    ],
    "memory_stats": [
      "self",
      "device_index"
    ],
    "reset_peak_memory_stats": [
      "self",
      "device_index"
    ],
    "memory_reserved": [
      "self",
      "device_index"
    ],
    "max_memory_reserved": [
      "self",
      "device_index"
    ],
    "total_memory": [
      "self",
      "device_index"
    ],
    "available_memory": [
      "self",
      "device_index"
    ],
    "is_bf16_supported": [
      "self"
    ],
    "is_fp16_supported": [
      "self"
    ],
    "supported_dtypes": [
      "self"
    ],
    "amp": [
      "self"
    ],
    "is_available": [
      "self"
    ],
    "range_push": [
      "self",
      "msg"
    ],
    "range_pop": [
      "self"
    ],
    "lazy_call": [
      "self",
      "callback"
    ],
    "communication_backend_name": [
      "self"
    ],
    "is_triton_supported": [
      "self"
    ],
    "create_graph": [
      "self"
    ],
    "capture_to_graph": [
      "self",
      "graph",
      "pool",
      "stream"
    ],
    "replay_graph": [
      "self",
      "graph"
    ],
    "BFloat16Tensor": [
      "self"
    ],
    "ByteTensor": [
      "self"
    ],
    "DoubleTensor": [
      "self"
    ],
    "FloatTensor": [
      "self"
    ],
    "HalfTensor": [
      "self"
    ],
    "IntTensor": [
      "self"
    ],
    "LongTensor": [
      "self"
    ],
    "pin_memory": [
      "self",
      "tensor",
      "align_bytes"
    ],
    "is_pinned": [
      "self",
      "tensor"
    ],
    "on_accelerator": [
      "self",
      "tensor"
    ],
    "op_builder_dir": [
      "self"
    ],
    "create_op_builder": [
      "self",
      "op_name"
    ],
    "get_op_builder": [
      "self",
      "class_name"
    ],
    "build_extension": [
      "self"
    ],
    "export_envs": [
      "self"
    ],
    "visible_devices_envs": [
      "self"
    ],
    "set_visible_devices_envs": [
      "self",
      "current_env",
      "local_accelerator_ids"
    ],
    "get_compile_backend": [
      "self"
    ],
    "set_compile_backend": [
      "self",
      "backend"
    ]
  },
  "SDAA_Accelerator": {
    "__init__": [
      "self"
    ],
    "is_synchronized_device": [
      "self"
    ],
    "use_host_timers": [
      "self"
    ],
    "resolves_data_dependency": [
      "self"
    ],
    "handles_memory_backpressure": [
      "self"
    ],
    "device_name": [
      "self",
      "device_index"
    ],
    "device": [
      "self",
      "device_index"
    ],
    "set_device": [
      "self",
      "device_index"
    ],
    "current_device": [
      "self"
    ],
    "current_device_name": [
      "self"
    ],
    "device_count": [
      "self"
    ],
    "synchronize": [
      "self",
      "device_index"
    ],
    "random": [
      "self"
    ],
    "set_rng_state": [
      "self",
      "new_state",
      "device_index"
    ],
    "get_rng_state": [
      "self",
      "device_index"
    ],
    "manual_seed": [
      "self",
      "seed"
    ],
    "manual_seed_all": [
      "self",
      "seed"
    ],
    "initial_seed": [
      "self"
    ],
    "default_generator": [
      "self",
      "device_index"
    ],
    "Stream": [
      "self"
    ],
    "stream": [
      "self",
      "stream"
    ],
    "current_stream": [
      "self",
      "device_index"
    ],
    "default_stream": [
      "self",
      "device_index"
    ],
    "Event": [
      "self"
    ],
    "empty_cache": [
      "self"
    ],
    "memory_allocated": [
      "self",
      "device_index"
    ],
    "max_memory_allocated": [
      "self",
      "device_index"
    ],
    "reset_max_memory_allocated": [
      "self",
      "device_index"
    ],
    "memory_cached": [
      "self",
      "device_index"
    ],
    "max_memory_cached": [
      "self",
      "device_index"
    ],
    "reset_max_memory_cached": [
      "self",
      "device_index"
    ],
    "memory_stats": [
      "self",
      "device_index"
    ],
    "reset_peak_memory_stats": [
      "self",
      "device_index"
    ],
    "memory_reserved": [
      "self",
      "device_index"
    ],
    "max_memory_reserved": [
      "self",
      "device_index"
    ],
    "total_memory": [
      "self",
      "device_index"
    ],
    "available_memory": [
      "self",
      "device_index"
    ],
    "is_bf16_supported": [
      "self"
    ],
    "is_fp16_supported": [
      "self"
    ],
    "supported_dtypes": [
      "self"
    ],
    "amp": [
      "self"
    ],
    "is_available": [
      "self"
    ],
    "range_push": [
      "self",
      "msg"
    ],
    "range_pop": [
      "self"
    ],
    "lazy_call": [
      "self",
      "callback"
    ],
    "communication_backend_name": [
      "self"
    ],
    "is_triton_supported": [
      "self"
    ],
    "create_graph": [
      "self"
    ],
    "capture_to_graph": [
      "self",
      "graph",
      "pool",
      "stream"
    ],
    "replay_graph": [
      "self",
      "graph"
    ],
    "BFloat16Tensor": [
      "self"
    ],
    "ByteTensor": [
      "self"
    ],
    "DoubleTensor": [
      "self"
    ],
    "FloatTensor": [
      "self"
    ],
    "HalfTensor": [
      "self"
    ],
    "IntTensor": [
      "self"
    ],
    "LongTensor": [
      "self"
    ],
    "pin_memory": [
      "self",
      "tensor",
      "align_bytes"
    ],
    "is_pinned": [
      "self",
      "tensor"
    ],
    "on_accelerator": [
      "self",
      "tensor"
    ],
    "op_builder_dir": [
      "self"
    ],
    "_lazy_init_class_dict": [
      "self"
    ],
    "create_op_builder": [
      "self",
      "class_name"
    ],
    "get_op_builder": [
      "self",
      "class_name"
    ],
    "build_extension": [
      "self"
    ],
    "export_envs": [
      "self"
    ],
    "visible_devices_envs": [
      "self"
    ],
    "set_visible_devices_envs": [
      "self",
      "current_env",
      "local_accelerator_ids"
    ],
    "get_compile_backend": [
      "self"
    ],
    "set_compile_backend": [
      "self",
      "backend"
    ]
  },
  "XPU_Accelerator": {
    "__init__": [
      "self"
    ],
    "is_synchronized_device": [
      "self"
    ],
    "use_host_timers": [
      "self"
    ],
    "resolves_data_dependency": [
      "self"
    ],
    "handles_memory_backpressure": [
      "self"
    ],
    "device_name": [
      "self",
      "device_index"
    ],
    "device": [
      "self",
      "device_index"
    ],
    "set_device": [
      "self",
      "device_index"
    ],
    "current_device": [
      "self"
    ],
    "current_device_name": [
      "self"
    ],
    "device_count": [
      "self"
    ],
    "synchronize": [
      "self",
      "device_index"
    ],
    "random": [
      "self"
    ],
    "set_rng_state": [
      "self",
      "new_state",
      "device_index"
    ],
    "get_rng_state": [
      "self",
      "device_index"
    ],
    "manual_seed": [
      "self",
      "seed"
    ],
    "manual_seed_all": [
      "self",
      "seed"
    ],
    "initial_seed": [
      "self"
    ],
    "default_generator": [
      "self",
      "device_index"
    ],
    "Stream": [
      "self"
    ],
    "stream": [
      "self",
      "stream"
    ],
    "current_stream": [
      "self",
      "device_index"
    ],
    "default_stream": [
      "self",
      "device_index"
    ],
    "Event": [
      "self"
    ],
    "empty_cache": [
      "self"
    ],
    "memory_allocated": [
      "self",
      "device_index"
    ],
    "max_memory_allocated": [
      "self",
      "device_index"
    ],
    "reset_max_memory_allocated": [
      "self",
      "device_index"
    ],
    "memory_cached": [
      "self",
      "device_index"
    ],
    "max_memory_cached": [
      "self",
      "device_index"
    ],
    "reset_max_memory_cached": [
      "self",
      "device_index"
    ],
    "memory_stats": [
      "self",
      "device_index"
    ],
    "reset_peak_memory_stats": [
      "self",
      "device_index"
    ],
    "memory_reserved": [
      "self",
      "device_index"
    ],
    "max_memory_reserved": [
      "self",
      "device_index"
    ],
    "total_memory": [
      "self",
      "device_index"
    ],
    "available_memory": [
      "self",
      "device_index"
    ],
    "amp": [
      "self"
    ],
    "is_available": [
      "self"
    ],
    "range_push": [
      "self",
      "msg"
    ],
    "range_pop": [
      "self"
    ],
    "lazy_call": [
      "self",
      "callback"
    ],
    "communication_backend_name": [
      "self"
    ],
    "is_triton_supported": [
      "self"
    ],
    "create_graph": [
      "self"
    ],
    "capture_to_graph": [
      "self",
      "graph",
      "pool",
      "stream"
    ],
    "replay_graph": [
      "self",
      "graph"
    ],
    "is_bf16_supported": [
      "self"
    ],
    "is_fp16_supported": [
      "self"
    ],
    "supported_dtypes": [
      "self"
    ],
    "BFloat16Tensor": [
      "self"
    ],
    "ByteTensor": [
      "self"
    ],
    "DoubleTensor": [
      "self"
    ],
    "FloatTensor": [
      "self"
    ],
    "HalfTensor": [
      "self"
    ],
    "IntTensor": [
      "self"
    ],
    "LongTensor": [
      "self"
    ],
    "pin_memory": [
      "self",
      "tensor",
      "align_bytes"
    ],
    "is_pinned": [
      "self",
      "tensor"
    ],
    "op_builder_dir": [
      "self"
    ],
    "on_accelerator": [
      "self",
      "tensor"
    ],
    "_lazy_init_class_dict": [
      "self"
    ],
    "create_op_builder": [
      "self",
      "class_name"
    ],
    "get_op_builder": [
      "self",
      "class_name"
    ],
    "build_extension": [
      "self"
    ],
    "export_envs": [
      "self"
    ],
    "visible_devices_envs": [
      "self"
    ],
    "set_visible_devices_envs": [
      "self",
      "current_env",
      "local_accelerator_ids"
    ],
    "get_compile_backend": [
      "self"
    ],
    "set_compile_backend": [
      "self",
      "backend"
    ]
  },
  "CPU_Accelerator": {
    "__init__": [
      "self"
    ],
    "is_synchronized_device": [
      "self"
    ],
    "use_host_timers": [
      "self"
    ],
    "resolves_data_dependency": [
      "self"
    ],
    "handles_memory_backpressure": [
      "self"
    ],
    "device_name": [
      "self",
      "device_index"
    ],
    "device": [
      "self",
      "device_index"
    ],
    "set_device": [
      "self",
      "device_index"
    ],
    "current_device": [
      "self"
    ],
    "current_device_name": [
      "self"
    ],
    "device_count": [
      "self"
    ],
    "synchronize": [
      "self",
      "device_index"
    ],
    "random": [
      "self"
    ],
    "set_rng_state": [
      "self",
      "new_state",
      "device_index"
    ],
    "get_rng_state": [
      "self",
      "device_index"
    ],
    "manual_seed": [
      "self",
      "seed"
    ],
    "manual_seed_all": [
      "self",
      "seed"
    ],
    "initial_seed": [
      "self"
    ],
    "default_generator": [
      "self",
      "device_index"
    ],
    "Stream": [
      "self"
    ],
    "stream": [
      "self",
      "stream"
    ],
    "current_stream": [
      "self",
      "device_index"
    ],
    "default_stream": [
      "self",
      "device_index"
    ],
    "Event": [
      "self"
    ],
    "empty_cache": [
      "self"
    ],
    "get_rss": [
      "self"
    ],
    "reset_rss": [
      "self"
    ],
    "memory_allocated": [
      "self",
      "device_index"
    ],
    "max_memory_allocated": [
      "self",
      "device_index"
    ],
    "reset_max_memory_allocated": [
      "self",
      "device_index"
    ],
    "memory_cached": [
      "self",
      "device_index"
    ],
    "max_memory_cached": [
      "self",
      "device_index"
    ],
    "reset_max_memory_cached": [
      "self",
      "device_index"
    ],
    "memory_stats": [
      "self",
      "device_index"
    ],
    "reset_peak_memory_stats": [
      "self",
      "device_index"
    ],
    "memory_reserved": [
      "self",
      "device_index"
    ],
    "max_memory_reserved": [
      "self",
      "device_index"
    ],
    "total_memory": [
      "self",
      "device_index"
    ],
    "available_memory": [
      "self",
      "device_index"
    ],
    "amp": [
      "self"
    ],
    "is_available": [
      "self"
    ],
    "range_push": [
      "self",
      "msg"
    ],
    "range_pop": [
      "self"
    ],
    "lazy_call": [
      "self",
      "callback"
    ],
    "communication_backend_name": [
      "self"
    ],
    "is_triton_supported": [
      "self"
    ],
    "is_bf16_supported": [
      "self"
    ],
    "is_fp16_supported": [
      "self"
    ],
    "supported_dtypes": [
      "self"
    ],
    "create_graph": [
      "self"
    ],
    "capture_to_graph": [
      "self",
      "graph",
      "pool",
      "stream"
    ],
    "replay_graph": [
      "self",
      "graph"
    ],
    "BFloat16Tensor": [
      "self"
    ],
    "ByteTensor": [
      "self"
    ],
    "DoubleTensor": [
      "self"
    ],
    "FloatTensor": [
      "self"
    ],
    "HalfTensor": [
      "self"
    ],
    "IntTensor": [
      "self"
    ],
    "LongTensor": [
      "self"
    ],
    "pin_memory": [
      "self",
      "tensor",
      "align_bytes"
    ],
    "is_pinned": [
      "self",
      "tensor"
    ],
    "op_builder_dir": [
      "self"
    ],
    "on_accelerator": [
      "self",
      "tensor"
    ],
    "create_op_builder": [
      "self",
      "op_name"
    ],
    "get_op_builder": [
      "self",
      "class_name"
    ],
    "build_extension": [
      "self"
    ],
    "export_envs": [
      "self"
    ],
    "visible_devices_envs": [
      "self"
    ],
    "set_visible_devices_envs": [
      "self",
      "current_env",
      "local_accelerator_ids"
    ],
    "get_compile_backend": [
      "self"
    ],
    "set_compile_backend": [
      "self",
      "backend"
    ]
  },
  "SUPPORTED_ACCELERATOR_LIST": [],
  "ds_accelerator": [],
  "_validate_accelerator": [
    "accel_obj"
  ],
  "is_current_accelerator_supported": [],
  "get_accelerator": [],
  "set_accelerator": [
    "accel_obj"
  ],
  "DeepSpeedAccelerator": {
    "__init__": [
      "self"
    ],
    "is_synchronized_device": [
      "self"
    ],
    "use_host_timers": [
      "self"
    ],
    "resolves_data_dependency": [
      "self"
    ],
    "handles_memory_backpressure": [
      "self"
    ],
    "device_name": [
      "self",
      "device_index"
    ],
    "device": [
      "self",
      "device_index"
    ],
    "set_device": [
      "self",
      "device_index"
    ],
    "current_device": [
      "self"
    ],
    "current_device_name": [
      "self"
    ],
    "device_count": [
      "self"
    ],
    "synchronize": [
      "self",
      "device_index"
    ],
    "random": [
      "self"
    ],
    "set_rng_state": [
      "self",
      "new_state",
      "device_index"
    ],
    "get_rng_state": [
      "self",
      "device_index"
    ],
    "manual_seed": [
      "self",
      "seed"
    ],
    "manual_seed_all": [
      "self",
      "seed"
    ],
    "initial_seed": [
      "self"
    ],
    "default_generator": [
      "self",
      "device_index"
    ],
    "Stream": [
      "self"
    ],
    "stream": [
      "self",
      "stream"
    ],
    "current_stream": [
      "self",
      "device_index"
    ],
    "default_stream": [
      "self",
      "device_index"
    ],
    "Event": [
      "self"
    ],
    "empty_cache": [
      "self"
    ],
    "memory_allocated": [
      "self",
      "device_index"
    ],
    "max_memory_allocated": [
      "self",
      "device_index"
    ],
    "reset_max_memory_allocated": [
      "self",
      "device_index"
    ],
    "memory_cached": [
      "self",
      "device_index"
    ],
    "max_memory_cached": [
      "self",
      "device_index"
    ],
    "reset_max_memory_cached": [
      "self",
      "device_index"
    ],
    "memory_stats": [
      "self",
      "device_index"
    ],
    "reset_peak_memory_stats": [
      "self",
      "device_index"
    ],
    "memory_reserved": [
      "self",
      "device_index"
    ],
    "max_memory_reserved": [
      "self",
      "device_index"
    ],
    "total_memory": [
      "self",
      "device_index"
    ],
    "available_memory": [
      "self",
      "device_index"
    ],
    "is_bf16_supported": [
      "self"
    ],
    "is_fp16_supported": [
      "self"
    ],
    "supported_dtypes": [
      "self"
    ],
    "amp": [
      "self"
    ],
    "is_available": [
      "self"
    ],
    "range_push": [
      "self",
      "msg"
    ],
    "range_pop": [
      "self"
    ],
    "lazy_call": [
      "self",
      "callback"
    ],
    "communication_backend_name": [
      "self"
    ],
    "is_triton_supported": [
      "self"
    ],
    "create_graph": [
      "self"
    ],
    "capture_to_graph": [
      "self",
      "graph",
      "pool",
      "stream"
    ],
    "replay_graph": [
      "self",
      "graph"
    ],
    "BFloat16Tensor": [
      "self"
    ],
    "ByteTensor": [
      "self"
    ],
    "DoubleTensor": [
      "self"
    ],
    "FloatTensor": [
      "self"
    ],
    "HalfTensor": [
      "self"
    ],
    "IntTensor": [
      "self"
    ],
    "LongTensor": [
      "self"
    ],
    "pin_memory": [
      "self",
      "tensor",
      "align_bytes"
    ],
    "is_pinned": [
      "self",
      "tensor"
    ],
    "on_accelerator": [
      "self",
      "tensor"
    ],
    "op_builder_dir": [
      "self"
    ],
    "create_op_builder": [
      "self",
      "class_name"
    ],
    "get_op_builder": [
      "self",
      "class_name"
    ],
    "build_extension": [
      "self"
    ],
    "export_envs": [
      "self"
    ],
    "visible_devices_envs": [
      "self"
    ],
    "set_visible_devices_envs": [
      "self",
      "current_env",
      "local_accelerator_ids"
    ],
    "get_compile_backend": [
      "self"
    ],
    "set_compile_backend": [
      "self",
      "backend"
    ]
  },
  "MLU_Accelerator": {
    "__init__": [
      "self"
    ],
    "is_synchronized_device": [
      "self"
    ],
    "use_host_timers": [
      "self"
    ],
    "resolves_data_dependency": [
      "self"
    ],
    "handles_memory_backpressure": [
      "self"
    ],
    "device_name": [
      "self",
      "device_index"
    ],
    "device": [
      "self",
      "device_index"
    ],
    "set_device": [
      "self",
      "device_index"
    ],
    "current_device": [
      "self"
    ],
    "current_device_name": [
      "self"
    ],
    "device_count": [
      "self"
    ],
    "synchronize": [
      "self",
      "device_index"
    ],
    "random": [
      "self"
    ],
    "set_rng_state": [
      "self",
      "new_state",
      "device_index"
    ],
    "get_rng_state": [
      "self",
      "device_index"
    ],
    "manual_seed": [
      "self",
      "seed"
    ],
    "manual_seed_all": [
      "self",
      "seed"
    ],
    "initial_seed": [
      "self",
      "seed"
    ],
    "default_generator": [
      "self",
      "device_index"
    ],
    "Stream": [
      "self"
    ],
    "stream": [
      "self",
      "stream"
    ],
    "current_stream": [
      "self",
      "device_index"
    ],
    "default_stream": [
      "self",
      "device_index"
    ],
    "Event": [
      "self"
    ],
    "empty_cache": [
      "self"
    ],
    "memory_allocated": [
      "self",
      "device_index"
    ],
    "max_memory_allocated": [
      "self",
      "device_index"
    ],
    "reset_max_memory_allocated": [
      "self",
      "device_index"
    ],
    "memory_cached": [
      "self",
      "device_index"
    ],
    "max_memory_cached": [
      "self",
      "device_index"
    ],
    "reset_max_memory_cached": [
      "self",
      "device_index"
    ],
    "memory_stats": [
      "self",
      "device_index"
    ],
    "reset_peak_memory_stats": [
      "self",
      "device_index"
    ],
    "memory_reserved": [
      "self",
      "device_index"
    ],
    "max_memory_reserved": [
      "self",
      "device_index"
    ],
    "total_memory": [
      "self",
      "device_index"
    ],
    "available_memory": [
      "self",
      "device_index"
    ],
    "is_bf16_supported": [
      "self"
    ],
    "is_fp16_supported": [
      "self"
    ],
    "supported_dtypes": [
      "self"
    ],
    "amp": [
      "self"
    ],
    "is_available": [
      "self"
    ],
    "range_push": [
      "self",
      "msg"
    ],
    "range_pop": [
      "self"
    ],
    "lazy_call": [
      "self",
      "callback"
    ],
    "communication_backend_name": [
      "self"
    ],
    "is_triton_supported": [
      "self"
    ],
    "create_graph": [
      "self"
    ],
    "capture_to_graph": [
      "self",
      "graph",
      "pool",
      "stream"
    ],
    "replay_graph": [
      "self",
      "graph"
    ],
    "BFloat16Tensor": [
      "self"
    ],
    "ByteTensor": [
      "self"
    ],
    "DoubleTensor": [
      "self"
    ],
    "FloatTensor": [
      "self"
    ],
    "HalfTensor": [
      "self"
    ],
    "IntTensor": [
      "self"
    ],
    "LongTensor": [
      "self"
    ],
    "pin_memory": [
      "self",
      "tensor"
    ],
    "is_pinned": [
      "self",
      "tensor"
    ],
    "on_accelerator": [
      "self",
      "tensor"
    ],
    "op_builder_dir": [
      "self"
    ],
    "_lazy_init_class_dict": [
      "self"
    ],
    "create_op_builder": [
      "self",
      "class_name"
    ],
    "get_op_builder": [
      "self",
      "class_name"
    ],
    "build_extension": [
      "self"
    ],
    "export_envs": [
      "self"
    ],
    "visible_devices_envs": [
      "self"
    ],
    "set_visible_devices_envs": [
      "self",
      "current_env",
      "local_accelerator_ids"
    ],
    "get_compile_backend": [
      "self"
    ],
    "set_compile_backend": [
      "self",
      "backend"
    ]
  },
  "pynvml": [],
  "CUDA_Accelerator": {
    "__init__": [
      "self"
    ],
    "_init_pynvml": [
      "self"
    ],
    "is_synchronized_device": [
      "self"
    ],
    "use_host_timers": [
      "self"
    ],
    "resolves_data_dependency": [
      "self"
    ],
    "handles_memory_backpressure": [
      "self"
    ],
    "device_name": [
      "self",
      "device_index"
    ],
    "communication_backend_version": [
      "self"
    ],
    "device": [
      "self",
      "device_index"
    ],
    "set_device": [
      "self",
      "device_index"
    ],
    "current_device": [
      "self"
    ],
    "current_device_name": [
      "self"
    ],
    "device_count": [
      "self"
    ],
    "synchronize": [
      "self",
      "device_index"
    ],
    "random": [
      "self"
    ],
    "set_rng_state": [
      "self",
      "new_state",
      "device_index"
    ],
    "get_rng_state": [
      "self",
      "device_index"
    ],
    "manual_seed": [
      "self",
      "seed"
    ],
    "manual_seed_all": [
      "self",
      "seed"
    ],
    "initial_seed": [
      "self"
    ],
    "default_generator": [
      "self",
      "device_index"
    ],
    "Stream": [
      "self"
    ],
    "stream": [
      "self",
      "stream"
    ],
    "current_stream": [
      "self",
      "device_index"
    ],
    "default_stream": [
      "self",
      "device_index"
    ],
    "Event": [
      "self"
    ],
    "empty_cache": [
      "self"
    ],
    "memory_allocated": [
      "self",
      "device_index"
    ],
    "max_memory_allocated": [
      "self",
      "device_index"
    ],
    "reset_max_memory_allocated": [
      "self",
      "device_index"
    ],
    "memory_cached": [
      "self",
      "device_index"
    ],
    "max_memory_cached": [
      "self",
      "device_index"
    ],
    "reset_max_memory_cached": [
      "self",
      "device_index"
    ],
    "memory_stats": [
      "self",
      "device_index"
    ],
    "reset_peak_memory_stats": [
      "self",
      "device_index"
    ],
    "memory_reserved": [
      "self",
      "device_index"
    ],
    "max_memory_reserved": [
      "self",
      "device_index"
    ],
    "total_memory": [
      "self",
      "device_index"
    ],
    "_get_nvml_gpu_id": [
      "self",
      "torch_gpu_id"
    ],
    "available_memory": [
      "self",
      "device_index"
    ],
    "is_bf16_supported": [
      "self"
    ],
    "is_fp16_supported": [
      "self"
    ],
    "supported_dtypes": [
      "self"
    ],
    "amp": [
      "self"
    ],
    "is_available": [
      "self"
    ],
    "range_push": [
      "self",
      "msg"
    ],
    "range_pop": [
      "self"
    ],
    "lazy_call": [
      "self",
      "callback"
    ],
    "communication_backend_name": [
      "self"
    ],
    "is_triton_supported": [
      "self"
    ],
    "create_graph": [
      "self"
    ],
    "capture_to_graph": [
      "self",
      "graph",
      "pool",
      "stream"
    ],
    "replay_graph": [
      "self",
      "graph"
    ],
    "BFloat16Tensor": [
      "self"
    ],
    "ByteTensor": [
      "self"
    ],
    "DoubleTensor": [
      "self"
    ],
    "FloatTensor": [
      "self"
    ],
    "HalfTensor": [
      "self"
    ],
    "IntTensor": [
      "self"
    ],
    "LongTensor": [
      "self"
    ],
    "pin_memory": [
      "self",
      "tensor",
      "align_bytes"
    ],
    "is_pinned": [
      "self",
      "tensor"
    ],
    "on_accelerator": [
      "self",
      "tensor"
    ],
    "op_builder_dir": [
      "self"
    ],
    "class_dict": [],
    "_lazy_init_class_dict": [
      "self"
    ],
    "create_op_builder": [
      "self",
      "class_name"
    ],
    "get_op_builder": [
      "self",
      "class_name"
    ],
    "build_extension": [
      "self"
    ],
    "export_envs": [
      "self"
    ],
    "visible_devices_envs": [
      "self"
    ],
    "set_visible_devices_envs": [
      "self",
      "current_env",
      "local_accelerator_ids"
    ],
    "get_compile_backend": [
      "self"
    ],
    "set_compile_backend": [
      "self",
      "backend"
    ]
  },
  "NPU_Accelerator": {
    "__init__": [
      "self"
    ],
    "is_synchronized_device": [
      "self"
    ],
    "use_host_timers": [
      "self"
    ],
    "resolves_data_dependency": [
      "self"
    ],
    "handles_memory_backpressure": [
      "self"
    ],
    "device_name": [
      "self",
      "device_index"
    ],
    "device": [
      "self",
      "device_index"
    ],
    "set_device": [
      "self",
      "device_index"
    ],
    "current_device": [
      "self"
    ],
    "current_device_name": [
      "self"
    ],
    "device_count": [
      "self"
    ],
    "synchronize": [
      "self",
      "device_index"
    ],
    "random": [
      "self"
    ],
    "set_rng_state": [
      "self",
      "new_state",
      "device_index"
    ],
    "get_rng_state": [
      "self",
      "device_index"
    ],
    "manual_seed": [
      "self",
      "seed"
    ],
    "manual_seed_all": [
      "self",
      "seed"
    ],
    "initial_seed": [
      "self"
    ],
    "default_generator": [
      "self",
      "device_index"
    ],
    "Stream": [
      "self"
    ],
    "stream": [
      "self",
      "stream"
    ],
    "current_stream": [
      "self",
      "device_index"
    ],
    "default_stream": [
      "self",
      "device_index"
    ],
    "Event": [
      "self"
    ],
    "empty_cache": [
      "self"
    ],
    "memory_allocated": [
      "self",
      "device_index"
    ],
    "max_memory_allocated": [
      "self",
      "device_index"
    ],
    "reset_max_memory_allocated": [
      "self",
      "device_index"
    ],
    "memory_cached": [
      "self",
      "device_index"
    ],
    "max_memory_cached": [
      "self",
      "device_index"
    ],
    "reset_max_memory_cached": [
      "self",
      "device_index"
    ],
    "memory_stats": [
      "self",
      "device_index"
    ],
    "reset_peak_memory_stats": [
      "self",
      "device_index"
    ],
    "memory_reserved": [
      "self",
      "device_index"
    ],
    "max_memory_reserved": [
      "self",
      "device_index"
    ],
    "total_memory": [
      "self",
      "device_index"
    ],
    "available_memory": [
      "self",
      "device_index"
    ],
    "is_bf16_supported": [
      "self"
    ],
    "is_fp16_supported": [
      "self"
    ],
    "supported_dtypes": [
      "self"
    ],
    "amp": [
      "self"
    ],
    "is_available": [
      "self"
    ],
    "range_push": [
      "self",
      "msg"
    ],
    "range_pop": [
      "self"
    ],
    "lazy_call": [
      "self",
      "callback"
    ],
    "communication_backend_name": [
      "self"
    ],
    "is_triton_supported": [
      "self"
    ],
    "create_graph": [
      "self"
    ],
    "capture_to_graph": [
      "self",
      "graph",
      "pool",
      "stream"
    ],
    "replay_graph": [
      "self",
      "graph"
    ],
    "BFloat16Tensor": [
      "self"
    ],
    "ByteTensor": [
      "self"
    ],
    "DoubleTensor": [
      "self"
    ],
    "FloatTensor": [
      "self"
    ],
    "HalfTensor": [
      "self"
    ],
    "IntTensor": [
      "self"
    ],
    "LongTensor": [
      "self"
    ],
    "pin_memory": [
      "self",
      "tensor",
      "align_bytes"
    ],
    "is_pinned": [
      "self",
      "tensor"
    ],
    "on_accelerator": [
      "self",
      "tensor"
    ],
    "op_builder_dir": [
      "self"
    ],
    "_lazy_init_class_dict": [
      "self"
    ],
    "create_op_builder": [
      "self",
      "class_name"
    ],
    "get_op_builder": [
      "self",
      "class_name"
    ],
    "build_extension": [
      "self"
    ],
    "export_envs": [
      "self"
    ],
    "visible_devices_envs": [
      "self"
    ],
    "set_visible_devices_envs": [
      "self",
      "current_env",
      "local_accelerator_ids"
    ],
    "get_compile_backend": [
      "self"
    ],
    "set_compile_backend": [
      "self",
      "backend"
    ]
  }
}