{
  "write_version_py": [],
  "version": [],
  "NumpyExtension": {
    "__init__": [
      "self"
    ],
    "include_dirs": [
      "self",
      "dirs"
    ]
  },
  "extensions": [],
  "cmdclass": [],
  "extra_packages": [],
  "do_setup": [
    "package_data"
  ],
  "get_files": [
    "path",
    "relative_to"
  ],
  "__version__": [],
  "default_cache_path": [],
  "CONFIG_NAME": [],
  "WEIGHTS_NAME": [],
  "logger": [],
  "load_archive_file": [
    "archive_file"
  ],
  "url_to_filename": [
    "url",
    "etag"
  ],
  "filename_to_url": [
    "filename",
    "cache_dir"
  ],
  "cached_path_from_pm": [
    "url_or_filename"
  ],
  "cached_path": [
    "url_or_filename",
    "cache_dir"
  ],
  "split_s3_path": [
    "url"
  ],
  "s3_request": [
    "func"
  ],
  "s3_etag": [
    "url"
  ],
  "s3_get": [
    "url",
    "temp_file"
  ],
  "request_wrap_timeout": [
    "func",
    "url"
  ],
  "http_get": [
    "url",
    "temp_file"
  ],
  "get_from_cache": [
    "url",
    "cache_dir"
  ],
  "read_set_from_file": [
    "filename"
  ],
  "get_file_extension": [
    "path",
    "dot",
    "lower"
  ],
  "SequenceGenerator": {
    "__init__": [
      "self",
      "models",
      "tgt_dict",
      "beam_size",
      "max_len_a",
      "max_len_b",
      "max_len",
      "min_len",
      "normalize_scores",
      "len_penalty",
      "unk_penalty",
      "temperature",
      "match_source_len",
      "no_repeat_ngram_size",
      "search_strategy",
      "eos",
      "symbols_to_strip_from_output",
      "lm_model",
      "lm_weight",
      "tokens_to_suppress"
    ],
    "cuda": [
      "self"
    ],
    "forward": [
      "self",
      "sample",
      "prefix_tokens",
      "bos_token"
    ],
    "generate_batched_itr": [
      "self",
      "data_itr",
      "beam_size",
      "cuda",
      "timer"
    ],
    "generate": [
      "self",
      "models",
      "sample"
    ],
    "_generate": [
      "self",
      "sample",
      "prefix_tokens",
      "constraints",
      "bos_token"
    ],
    "_prefix_tokens": [
      "self",
      "step",
      "lprobs",
      "scores",
      "tokens",
      "prefix_tokens",
      "beam_size"
    ],
    "replicate_first_beam": [
      "self",
      "tensor",
      "mask",
      "beam_size"
    ],
    "finalize_hypos": [
      "self",
      "step",
      "bbsz_idx",
      "eos_scores",
      "tokens",
      "scores",
      "finalized",
      "finished",
      "beam_size",
      "attn",
      "src_lengths",
      "max_len"
    ],
    "is_finished": [
      "self",
      "step",
      "unfin_idx",
      "max_len",
      "finalized_sent_len",
      "beam_size"
    ]
  },
  "EnsembleModel": {
    "__init__": [
      "self",
      "models"
    ],
    "forward": [
      "self"
    ],
    "has_encoder": [
      "self"
    ],
    "has_incremental_states": [
      "self"
    ],
    "max_decoder_positions": [
      "self"
    ],
    "set_decoder_beam_size": [
      "self",
      "beam_size"
    ],
    "forward_encoder": [
      "self",
      "net_input"
    ],
    "forward_decoder": [
      "self",
      "tokens",
      "encoder_outs",
      "incremental_states",
      "temperature"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_outs",
      "new_order"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_states",
      "new_order"
    ]
  },
  "SequenceGeneratorWithAlignment": {
    "__init__": [
      "self",
      "models",
      "tgt_dict",
      "left_pad_target",
      "print_alignment"
    ],
    "generate": [
      "self",
      "models",
      "sample"
    ],
    "_prepare_batch_for_alignment": [
      "self",
      "sample",
      "hypothesis"
    ]
  },
  "EnsembleModelWithAlignment": {
    "__init__": [
      "self",
      "models"
    ],
    "forward_align": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens"
    ]
  },
  "Trainer": {
    "__init__": [
      "self",
      "cfg",
      "task",
      "model",
      "criterion",
      "quantizer"
    ],
    "reinitialize": [
      "self"
    ],
    "data_parallel_world_size": [
      "self"
    ],
    "data_parallel_process_group": [
      "self"
    ],
    "data_parallel_rank": [
      "self"
    ],
    "is_data_parallel_master": [
      "self"
    ],
    "use_distributed_wrapper": [
      "self"
    ],
    "should_save_checkpoint_on_current_rank": [
      "self"
    ],
    "always_call_state_dict_during_save_checkpoint": [
      "self"
    ],
    "checkpoint_suffix": [
      "self"
    ],
    "criterion": [
      "self"
    ],
    "model": [
      "self"
    ],
    "ema": [
      "self"
    ],
    "_build_ema": [
      "self"
    ],
    "optimizer": [
      "self"
    ],
    "lr_scheduler": [
      "self"
    ],
    "_build_optimizer": [
      "self"
    ],
    "is_fsdp": [
      "self"
    ],
    "consolidate_optimizer": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "save_checkpoint": [
      "self",
      "filename",
      "extra_state"
    ],
    "load_checkpoint": [
      "self",
      "filename",
      "reset_optimizer",
      "reset_lr_scheduler",
      "optimizer_overrides",
      "reset_meters"
    ],
    "get_train_iterator": [
      "self",
      "epoch",
      "combine",
      "load_dataset",
      "data_selector",
      "shard_batch_itr",
      "disable_iterator_cache"
    ],
    "get_valid_iterator": [
      "self",
      "subset",
      "disable_iterator_cache"
    ],
    "begin_epoch": [
      "self",
      "epoch"
    ],
    "begin_valid_epoch": [
      "self",
      "epoch"
    ],
    "reset_dummy_batch": [
      "self",
      "batch"
    ],
    "train_step": [
      "self",
      "samples",
      "raise_oom"
    ],
    "valid_step": [
      "self",
      "sample",
      "raise_oom"
    ],
    "zero_grad": [
      "self"
    ],
    "lr_step_begin_epoch": [
      "self",
      "epoch"
    ],
    "lr_step": [
      "self",
      "epoch",
      "val_loss"
    ],
    "lr_step_update": [
      "self"
    ],
    "get_lr": [
      "self"
    ],
    "get_model": [
      "self"
    ],
    "get_criterion": [
      "self"
    ],
    "get_meter": [
      "self",
      "name"
    ],
    "get_num_updates": [
      "self"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "clip_grad_norm": [
      "self",
      "clip_norm"
    ],
    "cumulative_training_time": [
      "self"
    ],
    "_local_cumulative_training_time": [
      "self"
    ],
    "_fp_convert_sample": [
      "self",
      "sample"
    ],
    "_prepare_sample": [
      "self",
      "sample",
      "is_dummy"
    ],
    "_set_seed": [
      "self"
    ],
    "_sync_stats": [
      "self"
    ],
    "_log_oom": [
      "self",
      "exc"
    ],
    "_aggregate_logging_outputs": [
      "self",
      "logging_outputs"
    ],
    "_all_gather_list_sync": [
      "self",
      "logging_outputs"
    ],
    "_fast_stat_sync_sum": [
      "self",
      "logging_outputs"
    ],
    "_check_grad_norms": [
      "self",
      "grad_norm"
    ],
    "_reduce_and_log_stats": [
      "self",
      "logging_outputs",
      "sample_size",
      "grad_norm"
    ],
    "_check_xla_compilation": [
      "self"
    ],
    "_xla_markstep_and_send_to_cpu": [
      "self",
      "data"
    ]
  },
  "_catalog_shared_params": [
    "module",
    "memo",
    "prefix"
  ],
  "_get_module_by_path": [
    "module",
    "path"
  ],
  "_set_module_by_path": [
    "module",
    "path",
    "value"
  ],
  "BinarizeSummary": {
    "num_replaced": [
      "self"
    ],
    "replaced_percent": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ]
  },
  "Binarizer": {
    "binarize_line": [
      "self",
      "line",
      "summary"
    ]
  },
  "_worker_prefix": [
    "output_prefix",
    "worker_id"
  ],
  "FileBinarizer": {
    "multiprocess_dataset": [
      "cls",
      "input_file",
      "dataset_impl",
      "binarizer",
      "output_prefix",
      "vocab_size",
      "num_workers"
    ],
    "_binarize_file_chunk": [
      "binarizer",
      "filename",
      "offset_start",
      "offset_end",
      "output_prefix",
      "dataset_impl",
      "vocab_size"
    ],
    "_binarize_chunk_and_finalize": [
      "cls",
      "binarizer",
      "filename",
      "offset_start",
      "offset_end",
      "output_prefix",
      "dataset_impl",
      "vocab_size"
    ]
  },
  "VocabularyDatasetBinarizer": {
    "__init__": [
      "self",
      "dict",
      "tokenize",
      "append_eos",
      "reverse_order",
      "already_numberized"
    ],
    "binarize_line": [
      "self",
      "line",
      "summary"
    ]
  },
  "AlignmentDatasetBinarizer": {
    "__init__": [
      "self",
      "alignment_parser"
    ],
    "binarize_line": [
      "self",
      "line",
      "summary"
    ]
  },
  "LegacyBinarizer": {
    "binarize": [
      "cls",
      "filename",
      "dico",
      "consumer",
      "tokenize",
      "append_eos",
      "reverse_order",
      "offset",
      "end",
      "already_numberized"
    ],
    "binarize_alignments": [
      "cls",
      "filename",
      "alignment_parser",
      "consumer",
      "offset",
      "end"
    ],
    "_consume_file": [
      "filename",
      "binarizer",
      "consumer",
      "offset_start",
      "offset_end"
    ]
  },
  "save_checkpoint": [
    "cfg",
    "trainer",
    "epoch_itr",
    "val_loss"
  ],
  "load_checkpoint": [
    "cfg",
    "trainer"
  ],
  "load_checkpoint_to_cpu": [
    "path",
    "arg_overrides",
    "load_on_all_ranks"
  ],
  "load_model_ensemble": [
    "filenames",
    "arg_overrides",
    "task",
    "strict",
    "suffix",
    "num_shards",
    "state"
  ],
  "get_maybe_sharded_checkpoint_filename": [
    "filename",
    "suffix",
    "shard_idx",
    "num_shards"
  ],
  "load_model_ensemble_and_task": [
    "filenames",
    "arg_overrides",
    "task",
    "strict",
    "suffix",
    "num_shards",
    "state"
  ],
  "load_model_ensemble_and_task_from_hf_hub": [
    "model_id",
    "cache_dir",
    "arg_overrides"
  ],
  "checkpoint_paths": [
    "path",
    "pattern",
    "keep_match"
  ],
  "torch_persistent_save": [
    "obj",
    "filename",
    "async_write"
  ],
  "_torch_persistent_save": [
    "obj",
    "f"
  ],
  "_upgrade_state_dict": [
    "state"
  ],
  "prune_state_dict": [
    "state_dict",
    "model_cfg"
  ],
  "load_pretrained_component_from_model": [
    "component",
    "checkpoint",
    "strict"
  ],
  "verify_checkpoint_directory": [
    "save_dir"
  ],
  "save_ema_as_checkpoint": [
    "src_path",
    "dst_path"
  ],
  "load_ema_from_checkpoint": [
    "fpath"
  ],
  "Search": {
    "__init__": [
      "self",
      "tgt_dict"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ],
    "set_src_lengths": [
      "self",
      "src_lengths"
    ],
    "init_constraints": [
      "self",
      "batch_constraints",
      "beam_size"
    ],
    "prune_sentences": [
      "self",
      "batch_idxs"
    ],
    "update_constraints": [
      "self",
      "active_hypos"
    ]
  },
  "BeamSearch": {
    "__init__": [
      "self",
      "tgt_dict"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ]
  },
  "PrefixConstrainedBeamSearch": {
    "__init__": [
      "self",
      "tgt_dict",
      "prefix_allowed_tokens_fn"
    ],
    "apply_mask": [
      "self",
      "x",
      "prev_output_tokens",
      "original_batch_idxs"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ]
  },
  "LexicallyConstrainedBeamSearch": {
    "__init__": [
      "self",
      "tgt_dict",
      "representation"
    ],
    "init_constraints": [
      "self",
      "batch_constraints",
      "beam_size"
    ],
    "prune_sentences": [
      "self",
      "batch_idxs"
    ],
    "update_constraints": [
      "self",
      "active_hypos"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ],
    "step_sentence": [
      "self",
      "step",
      "sentno",
      "lprobs",
      "constraint_states",
      "beams_buf",
      "indices_buf",
      "scores_buf"
    ]
  },
  "LengthConstrainedBeamSearch": {
    "__init__": [
      "self",
      "tgt_dict",
      "min_len_a",
      "min_len_b",
      "max_len_a",
      "max_len_b"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ]
  },
  "DiverseBeamSearch": {
    "__init__": [
      "self",
      "tgt_dict",
      "num_groups",
      "diversity_strength"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ]
  },
  "Sampling": {
    "__init__": [
      "self",
      "tgt_dict",
      "sampling_topk",
      "sampling_topp"
    ],
    "_sample_topp": [
      "self",
      "lprobs"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ]
  },
  "DiverseSiblingsSearch": {
    "__init__": [
      "self",
      "tgt_dict",
      "diversity_rate"
    ],
    "step": [
      "self",
      "step",
      "lprobs",
      "scores",
      "prev_output_tokens",
      "original_batch_idxs"
    ]
  },
  "from_pretrained": [
    "model_name_or_path",
    "checkpoint_file",
    "data_name_or_path",
    "archive_map"
  ],
  "GeneratorHubInterface": {
    "__init__": [
      "self",
      "cfg",
      "task",
      "models"
    ],
    "device": [
      "self"
    ],
    "translate": [
      "self",
      "sentences",
      "beam",
      "verbose"
    ],
    "sample": [
      "self",
      "sentences",
      "beam",
      "verbose"
    ],
    "score": [
      "self",
      "sentences",
      "replace_newline_with_eos"
    ],
    "generate": [
      "self",
      "tokenized_sentences",
      "beam",
      "verbose",
      "skip_invalid_size_inputs",
      "inference_step_args",
      "prefix_allowed_tokens_fn"
    ],
    "encode": [
      "self",
      "sentence"
    ],
    "decode": [
      "self",
      "tokens"
    ],
    "tokenize": [
      "self",
      "sentence"
    ],
    "detokenize": [
      "self",
      "sentence"
    ],
    "apply_bpe": [
      "self",
      "sentence"
    ],
    "remove_bpe": [
      "self",
      "sentence"
    ],
    "binarize": [
      "self",
      "sentence"
    ],
    "string": [
      "self",
      "tokens"
    ],
    "_build_batches": [
      "self",
      "tokens",
      "skip_invalid_size_inputs"
    ]
  },
  "BPEHubInterface": {
    "__init__": [
      "self",
      "bpe"
    ],
    "encode": [
      "self",
      "sentence"
    ],
    "decode": [
      "self",
      "sentence"
    ]
  },
  "TokenizerHubInterface": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "encode": [
      "self",
      "sentence"
    ],
    "decode": [
      "self",
      "sentence"
    ]
  },
  "MANIFOLD_PATH_SEP": [],
  "FileContentsAction": {
    "__init__": [
      "self",
      "option_strings",
      "dest",
      "nargs"
    ],
    "__call__": [
      "self",
      "parser",
      "namespace",
      "values",
      "option_string"
    ]
  },
  "split_paths": [
    "paths",
    "separator"
  ],
  "load_ensemble_for_inference": [
    "filenames",
    "task",
    "model_arg_overrides"
  ],
  "apply_to_sample": [
    "f",
    "sample"
  ],
  "move_to_cuda": [
    "sample",
    "device"
  ],
  "move_to_cpu": [
    "sample"
  ],
  "move_to_tpu": [
    "sample"
  ],
  "get_incremental_state": [
    "module",
    "incremental_state",
    "key"
  ],
  "set_incremental_state": [
    "module",
    "incremental_state",
    "key",
    "value"
  ],
  "load_align_dict": [
    "replace_unk"
  ],
  "print_embed_overlap": [
    "embed_dict",
    "vocab_dict"
  ],
  "parse_embedding": [
    "embed_path"
  ],
  "load_embedding": [
    "embed_dict",
    "vocab",
    "embedding"
  ],
  "replace_unk": [
    "hypo_str",
    "src_str",
    "alignment",
    "align_dict",
    "unk"
  ],
  "post_process_prediction": [
    "hypo_tokens",
    "src_str",
    "alignment",
    "align_dict",
    "tgt_dict",
    "remove_bpe",
    "extra_symbols_to_ignore"
  ],
  "make_positions": [
    "tensor",
    "padding_idx",
    "onnx_trace"
  ],
  "strip_pad": [
    "tensor",
    "pad"
  ],
  "buffered_arange": [
    "max"
  ],
  "convert_padding_direction": [
    "src_tokens",
    "padding_idx",
    "right_to_left",
    "left_to_right"
  ],
  "item": [
    "tensor"
  ],
  "multi_tensor_total_norm": [
    "grads",
    "chunk_size"
  ],
  "clip_grad_norm_": [
    "params",
    "max_norm",
    "aggregate_norm_fn"
  ],
  "fill_with_neg_inf": [
    "t"
  ],
  "_match_types": [
    "arg1",
    "arg2"
  ],
  "resolve_max_positions": [],
  "import_user_module": [
    "args"
  ],
  "softmax": [
    "x",
    "dim",
    "onnx_trace"
  ],
  "log_softmax": [
    "x",
    "dim",
    "onnx_trace"
  ],
  "get_perplexity": [
    "loss",
    "round",
    "base"
  ],
  "deprecation_warning": [
    "message",
    "stacklevel"
  ],
  "relu_squared": [
    "x"
  ],
  "get_activation_fn": [
    "activation"
  ],
  "get_available_activation_fns": [],
  "model_eval": [
    "model"
  ],
  "has_parameters": [
    "module"
  ],
  "get_rng_state": [],
  "set_rng_state": [
    "state"
  ],
  "set_torch_seed": {
    "__init__": [
      "self",
      "seed"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "parse_alignment": [
    "line"
  ],
  "get_token_to_word_mapping": [
    "tokens",
    "exclude_list"
  ],
  "extract_hard_alignment": [
    "attn",
    "src_sent",
    "tgt_sent",
    "pad",
    "eos"
  ],
  "extract_soft_alignment": [
    "attn",
    "src_sent",
    "tgt_sent",
    "pad",
    "eos"
  ],
  "new_arange": [
    "x"
  ],
  "get_tpu_device": [],
  "tpu_data_loader": [
    "itr"
  ],
  "is_xla_tensor": [
    "tensor"
  ],
  "index_put": [
    "tensor",
    "indices",
    "value"
  ],
  "xla_device_to_cpu": [
    "dat"
  ],
  "CudaEnvironment": {
    "__init__": [
      "self"
    ],
    "pretty_print_cuda_env_list": [
      "cuda_env_list"
    ]
  },
  "csv_str_list": [
    "x"
  ],
  "eval_str_list": [
    "x",
    "type"
  ],
  "eval_str_dict": [
    "x",
    "type"
  ],
  "eval_bool": [
    "x",
    "default"
  ],
  "reset_logging": [],
  "safe_getattr": [
    "obj",
    "k",
    "default"
  ],
  "safe_hasattr": [
    "obj",
    "k"
  ],
  "FairseqIncrementalState": {
    "__init__": [
      "self"
    ],
    "init_incremental_state": [
      "self"
    ],
    "_get_full_incremental_state_key": [
      "self",
      "key"
    ],
    "get_incremental_state": [
      "self",
      "incremental_state",
      "key"
    ],
    "set_incremental_state": [
      "self",
      "incremental_state",
      "key",
      "value"
    ]
  },
  "with_incremental_state": [
    "cls"
  ],
  "SPACE_NORMALIZER": [],
  "tokenize_line": [
    "line"
  ],
  "PathManager": {
    "open": [
      "path",
      "mode",
      "buffering",
      "encoding",
      "errors",
      "newline"
    ],
    "copy": [
      "src_path",
      "dst_path",
      "overwrite"
    ],
    "get_local_path": [
      "path"
    ],
    "exists": [
      "path"
    ],
    "isfile": [
      "path"
    ],
    "ls": [
      "path"
    ],
    "mkdirs": [
      "path"
    ],
    "rm": [
      "path"
    ],
    "chmod": [
      "path",
      "mode"
    ],
    "register_handler": [
      "handler"
    ],
    "copy_from_local": [
      "local_path",
      "dst_path",
      "overwrite"
    ],
    "path_requires_pathmanager": [
      "path"
    ],
    "supports_rename": [
      "path"
    ],
    "rename": [
      "src",
      "dst"
    ],
    "opena": [
      "path",
      "mode",
      "buffering",
      "encoding",
      "errors",
      "newline"
    ],
    "async_close": []
  },
  "__all__": [],
  "_stdin": [],
  "_stdin_lock": [],
  "MultiprocessingPdb": {
    "__init__": [
      "self"
    ],
    "_cmdloop": [
      "self"
    ]
  },
  "set_trace": [],
  "ConstraintState": {
    "__init__": [
      "self"
    ]
  },
  "pack_constraints": [
    "batch_constraints"
  ],
  "unpack_constraints": [
    "constraint_tensor"
  ],
  "ConstraintNode": {
    "__init__": [
      "self",
      "token",
      "parent"
    ],
    "id": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "next_tokens": [
      "self"
    ],
    "create": [
      "constraints"
    ],
    "print_graph": [
      "node"
    ],
    "token_counts": [
      "self"
    ],
    "tokens": [
      "self"
    ],
    "add_sequence": [
      "self",
      "sequence"
    ]
  },
  "UnorderedConstraintState": {
    "__init__": [
      "self",
      "node",
      "copy_from"
    ],
    "create": [
      "constraint_tensor"
    ],
    "__str__": [
      "self"
    ],
    "__copy__": [
      "self"
    ],
    "copy": [
      "self"
    ],
    "name": [
      "self"
    ],
    "is_root": [
      "self"
    ],
    "bank": [
      "self"
    ],
    "num_completed": [
      "self"
    ],
    "finished": [
      "self"
    ],
    "token_counts": [
      "self"
    ],
    "tokens": [
      "self"
    ],
    "num_constraint_tokens": [
      "self"
    ],
    "next_tokens": [
      "self"
    ],
    "advance": [
      "self",
      "token"
    ]
  },
  "ConstraintSequence": {
    "__init__": [
      "self",
      "sequences"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__len__": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "OrderedConstraintState": {
    "__init__": [
      "self",
      "sequence",
      "state"
    ],
    "create": [
      "constraint_tensor"
    ],
    "__str__": [
      "self"
    ],
    "__copy__": [
      "self"
    ],
    "copy": [
      "self"
    ],
    "num_completed": [
      "self"
    ],
    "is_root": [
      "self"
    ],
    "name": [
      "self"
    ],
    "bank": [
      "self"
    ],
    "finished": [
      "self"
    ],
    "token_counts": [
      "self"
    ],
    "tokens": [
      "self"
    ],
    "num_constraint_tokens": [
      "self"
    ],
    "next_tokens": [
      "self"
    ],
    "advance": [
      "self",
      "token"
    ]
  },
  "_safe_readline": [
    "fd"
  ],
  "find_offsets": [
    "filename",
    "num_chunks"
  ],
  "ChunkLineIterator": {
    "__init__": [
      "self",
      "fd",
      "start_offset",
      "end_offset"
    ],
    "__iter__": [
      "self"
    ]
  },
  "Chunker": {
    "__init__": [
      "self",
      "path",
      "start_offset",
      "end_offset"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "quantize_model_scalar": [
    "model",
    "model_cfg"
  ],
  "Quantizer": {
    "__init__": [
      "self",
      "config_path",
      "max_epoch",
      "max_update"
    ],
    "set_trainer": [
      "self",
      "trainer"
    ],
    "step": [
      "self"
    ],
    "begin_epoch": [
      "self",
      "epoch"
    ],
    "step_update": [
      "self",
      "num_updates"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "is_cuda_extension_usable": [],
  "NGramRepeatBlock": {
    "__init__": [
      "self",
      "no_repeat_ngram_size",
      "use_extension"
    ],
    "reset_parameters": [
      "self"
    ],
    "call_cuda_extension": [
      "self",
      "tokens",
      "lprobs",
      "bsz",
      "beam_size",
      "step"
    ],
    "forward": [
      "self",
      "tokens",
      "lprobs",
      "bsz",
      "beam_size",
      "step"
    ],
    "_no_repeat_ngram": [
      "self",
      "tokens",
      "lprobs",
      "bsz",
      "beam_size",
      "step"
    ]
  },
  "REGISTRIES": [],
  "setup_registry": [
    "registry_name",
    "base_class",
    "default",
    "required"
  ],
  "NanDetector": {
    "__init__": [
      "self",
      "model",
      "forward",
      "backward"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "exc_traceback"
    ],
    "add_hooks": [
      "self",
      "module"
    ],
    "reset": [
      "self"
    ],
    "_detect": [
      "self",
      "tensor",
      "name",
      "backward"
    ],
    "_apply": [
      "self",
      "module",
      "inp",
      "x",
      "backward"
    ],
    "fhook_fn": [
      "self",
      "module",
      "inp",
      "output"
    ],
    "bhook_fn": [
      "self",
      "module",
      "inp",
      "output"
    ],
    "close": [
      "self"
    ]
  },
  "DecoderOut": [],
  "IterativeRefinementGenerator": {
    "__init__": [
      "self",
      "tgt_dict",
      "models",
      "eos_penalty",
      "max_iter",
      "max_ratio",
      "beam_size",
      "decoding_format",
      "retain_dropout",
      "adaptive",
      "retain_history",
      "reranking"
    ],
    "generate_batched_itr": [
      "self",
      "data_itr",
      "maxlen_a",
      "maxlen_b",
      "cuda",
      "timer",
      "prefix_size"
    ],
    "generate": [
      "self",
      "models",
      "sample",
      "prefix_tokens",
      "constraints"
    ],
    "rerank": [
      "self",
      "reranker",
      "finalized",
      "encoder_input",
      "beam_size"
    ]
  },
  "SequenceScorer": {
    "__init__": [
      "self",
      "tgt_dict",
      "softmax_batch",
      "compute_alignment",
      "eos",
      "symbols_to_strip_from_output"
    ],
    "generate": [
      "self",
      "models",
      "sample"
    ]
  },
  "SpeechGenerator": {
    "__init__": [
      "self",
      "model",
      "vocoder",
      "data_cfg"
    ],
    "gcmvn_denormalize": [
      "self",
      "x"
    ],
    "get_waveform": [
      "self",
      "feat"
    ]
  },
  "AutoRegressiveSpeechGenerator": {
    "__init__": [
      "self",
      "model",
      "vocoder",
      "data_cfg",
      "max_iter",
      "eos_prob_threshold"
    ],
    "generate": [
      "self",
      "model",
      "sample",
      "has_targ"
    ]
  },
  "NonAutoregressiveSpeechGenerator": {
    "generate": [
      "self",
      "model",
      "sample",
      "has_targ"
    ]
  },
  "TeacherForcingAutoRegressiveSpeechGenerator": {
    "generate": [
      "self",
      "model",
      "sample",
      "has_targ"
    ]
  },
  "get_preprocessing_parser": [
    "default_task"
  ],
  "get_training_parser": [
    "default_task"
  ],
  "get_generation_parser": [
    "interactive",
    "default_task"
  ],
  "get_speech_generation_parser": [
    "default_task"
  ],
  "get_interactive_generation_parser": [
    "default_task"
  ],
  "get_eval_lm_parser": [
    "default_task"
  ],
  "get_validation_parser": [
    "default_task"
  ],
  "parse_args_and_arch": [
    "parser",
    "input_args",
    "parse_known",
    "suppress_defaults",
    "modify_parser"
  ],
  "get_parser": [
    "desc",
    "default_task"
  ],
  "add_preprocess_args": [
    "parser"
  ],
  "add_dataset_args": [
    "parser",
    "train",
    "gen"
  ],
  "add_distributed_training_args": [
    "parser",
    "default_world_size"
  ],
  "add_optimization_args": [
    "parser"
  ],
  "add_checkpoint_args": [
    "parser"
  ],
  "add_common_eval_args": [
    "group"
  ],
  "add_eval_lm_args": [
    "parser"
  ],
  "add_generation_args": [
    "parser"
  ],
  "add_speech_generation_args": [
    "parser"
  ],
  "add_interactive_args": [
    "parser"
  ],
  "add_model_args": [
    "parser"
  ],
  "get_args": [
    "data",
    "task",
    "arch"
  ],
  "add_ema_args": [
    "parser"
  ],
  "DummyDataset": {
    "__init__": [
      "self",
      "batch",
      "num_items",
      "item_size"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "sizes": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ]
  },
  "DummyMaskedLMConfig": {},
  "DummyMaskedLMTask": {
    "__init__": [
      "self",
      "cfg"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ]
  },
  "DummyMTTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "dictionary"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ]
  },
  "DummyLMConfig": {},
  "DummyLMTask": {
    "__init__": [
      "self",
      "cfg"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ]
  },
  "DummyModel": {
    "__init__": [
      "self",
      "args",
      "encoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "forward": [
      "self",
      "src_tokens",
      "masked_tokens"
    ]
  },
  "DummyEncoder": {
    "__init__": [
      "self",
      "num_embed",
      "embed_dim",
      "num_layers"
    ],
    "forward": [
      "self",
      "tokens",
      "masked_tokens"
    ],
    "max_positions": [
      "self"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ]
  },
  "base_architecture": [
    "args"
  ],
  "BATCH": [],
  "SEQ": [],
  "EMB": [],
  "HEADS": [],
  "DROP": [],
  "DEVICE": [],
  "ATTN_MASK_DTYPE": [],
  "KEY_PADDING_MASK_DTYPE": [],
  "_reset_seeds": [],
  "_get_mask": [
    "to_dtype",
    "dim0",
    "dim1"
  ],
  "benchmark_multihead_attention": [
    "label",
    "attn_dtype",
    "key_padding_dtype",
    "add_bias_kv",
    "add_zero_attn",
    "static_kv",
    "batch_size",
    "embedding",
    "seq_len",
    "num_heads"
  ],
  "run_benchmarks": [],
  "ModuleProxyWrapper": {
    "__init__": [
      "self",
      "module"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "_USE_MEGATRON": [],
  "_USE_XLA": [],
  "is_master": [
    "cfg"
  ],
  "infer_init_method": [
    "cfg",
    "force_distributed"
  ],
  "_infer_torch_distributed_launch_init": [
    "cfg"
  ],
  "_infer_slurm_init": [
    "cfg",
    "num_pipelines_per_node"
  ],
  "_infer_single_node_init": [
    "cfg"
  ],
  "_pipeline_parallel_pre_init": [
    "cfg"
  ],
  "_pipeline_parallel_post_init": [
    "cfg",
    "num_pipeline_devices",
    "num_pipelines_per_node"
  ],
  "distributed_init": [
    "cfg"
  ],
  "distributed_main": [
    "i",
    "main",
    "cfg",
    "kwargs"
  ],
  "call_main": [
    "cfg",
    "main"
  ],
  "use_xla": [],
  "new_groups": [
    "grouped_ranks"
  ],
  "_find_my_group_index": [
    "grouped_ranks"
  ],
  "_find_my_group": [
    "grouped_ranks"
  ],
  "get_rank": [
    "group"
  ],
  "get_world_size": [
    "group"
  ],
  "get_global_group": [],
  "get_global_rank": [],
  "get_global_world_size": [],
  "get_data_parallel_group": [],
  "get_data_parallel_rank": [],
  "get_data_parallel_world_size": [],
  "get_model_parallel_group": [],
  "get_model_parallel_rank": [],
  "get_model_parallel_world_size": [],
  "all_reduce": [
    "tensor",
    "group",
    "op"
  ],
  "broadcast": [
    "tensor",
    "src",
    "group"
  ],
  "all_to_all": [
    "tensor",
    "group"
  ],
  "all_gather": [
    "tensor",
    "group",
    "return_tensor"
  ],
  "all_gather_list": [
    "data",
    "group",
    "max_size"
  ],
  "all_reduce_dict": [
    "data",
    "device",
    "group"
  ],
  "broadcast_tensors": [
    "tensors",
    "src_rank",
    "group",
    "dist_device"
  ],
  "broadcast_object": [
    "obj",
    "src_rank",
    "group",
    "dist_device"
  ],
  "_broadcast_object_slow": [
    "obj",
    "src_rank",
    "group",
    "dist_device"
  ],
  "_TensorPlaceholder": {},
  "_split_tensors_from_obj": [
    "obj",
    "tensors"
  ],
  "_put_tensors_in_obj": [
    "obj",
    "tensors"
  ],
  "DistributedTimeoutWrapper": {
    "__init__": [
      "self",
      "module",
      "timeout",
      "signal"
    ],
    "__del__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "stop_timeout": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "_check_heartbeat": [
      "self",
      "parent_pid"
    ]
  },
  "TPUDistributedDataParallel": {
    "__init__": [
      "self",
      "module",
      "process_group"
    ],
    "forward": [
      "self"
    ],
    "all_reduce_grads": [
      "self"
    ]
  },
  "LegacyDistributedDataParallel": {
    "__init__": [
      "self",
      "module",
      "process_group",
      "buffer_size"
    ],
    "no_sync": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "all_reduce_grads": [
      "self"
    ]
  },
  "FullyShardedDataParallel": {
    "__init__": [
      "self"
    ],
    "unwrapped_module": [
      "self"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict",
      "model_cfg"
    ]
  },
  "fsdp_enable_wrap": [
    "cfg"
  ],
  "fsdp_wrap": [
    "module",
    "min_num_params"
  ],
  "interpret_dc_type": [
    "field_type"
  ],
  "gen_parser_from_dataclass": [
    "parser",
    "dataclass_instance",
    "delete_default",
    "with_prefix"
  ],
  "_set_legacy_defaults": [
    "args",
    "cls"
  ],
  "_override_attr": [
    "sub_node",
    "data_class",
    "args"
  ],
  "migrate_registry": [
    "name",
    "value",
    "registry",
    "args",
    "overrides",
    "deletes",
    "use_name_as_val"
  ],
  "override_module_args": [
    "args"
  ],
  "omegaconf_no_object_check": {
    "__init__": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "type",
      "value",
      "traceback"
    ]
  },
  "convert_namespace_to_omegaconf": [
    "args"
  ],
  "overwrite_args_by_name": [
    "cfg",
    "overrides"
  ],
  "merge_with_parent": [
    "dc",
    "cfg",
    "remove_missing"
  ],
  "FairseqDataclass": {
    "name": [],
    "_get_all_attributes": [
      "self"
    ],
    "_get_meta": [
      "self",
      "attribute_name",
      "meta",
      "default"
    ],
    "_get_name": [
      "self",
      "attribute_name"
    ],
    "_get_default": [
      "self",
      "attribute_name"
    ],
    "_get_type": [
      "self",
      "attribute_name"
    ],
    "_get_help": [
      "self",
      "attribute_name"
    ],
    "_get_argparse_const": [
      "self",
      "attribute_name"
    ],
    "_get_argparse_alias": [
      "self",
      "attribute_name"
    ],
    "_get_choices": [
      "self",
      "attribute_name"
    ],
    "from_namespace": [
      "cls",
      "args"
    ]
  },
  "CommonConfig": {},
  "DistributedTrainingConfig": {},
  "DatasetConfig": {},
  "OptimizationConfig": {},
  "CheckpointConfig": {},
  "FairseqBMUFConfig": {},
  "GenerationConfig": {},
  "CommonEvalConfig": {},
  "EvalLMConfig": {},
  "InteractiveConfig": {},
  "EMAConfig": {},
  "FairseqConfig": {},
  "hydra_init": [
    "cfg_name"
  ],
  "add_defaults": [
    "cfg"
  ],
  "StrEnumMeta": {
    "__instancecheck__": [
      "cls",
      "other"
    ]
  },
  "StrEnum": {
    "__str__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__repr__": [
      "self"
    ],
    "__hash__": [
      "self"
    ]
  },
  "ChoiceEnum": [
    "choices"
  ],
  "LOG_FORMAT_CHOICES": [],
  "DDP_BACKEND_CHOICES": [],
  "DDP_COMM_HOOK_CHOICES": [],
  "DATASET_IMPL_CHOICES": [],
  "GENERATION_CONSTRAINTS_CHOICES": [],
  "GENERATION_DECODING_FORMAT_CHOICES": [],
  "ZERO_SHARDING_CHOICES": [],
  "PIPELINE_CHECKPOINT_CHOICES": [],
  "PRINT_ALIGNMENT_CHOICES": [],
  "CrossEntropyCriterionConfig": {},
  "CrossEntropyCriterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "compute_loss": [
      "self",
      "model",
      "net_output",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "CompositeLoss": {
    "__init__": [
      "self",
      "args",
      "task"
    ],
    "add_args": [
      "parser"
    ],
    "build_underlying_criterion": [
      "args",
      "task"
    ],
    "build_criterion": [
      "cls",
      "args",
      "task"
    ]
  },
  "MaskedLmConfig": {},
  "MaskedLmLoss": {
    "__init__": [
      "self",
      "cfg",
      "task"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "HubertCriterionConfig": {},
  "HubertCriterion": {
    "__init__": [
      "self",
      "task",
      "pred_masked_weight",
      "pred_nomask_weight",
      "loss_weights",
      "log_keys"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce",
      "log_pred"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "aggregate_logging_outputs": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "LabelSmoothedCrossEntropyCriterionWithAlignmentConfig": {},
  "LabelSmoothedCrossEntropyCriterionWithAlignment": {
    "__init__": [
      "self",
      "task",
      "sentence_avg",
      "label_smoothing",
      "alignment_lambda"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "compute_alignment_loss": [
      "self",
      "sample",
      "net_output"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "MultitaskCriterion": {
    "__init__": [
      "self",
      "multitask_tasks"
    ],
    "set_multitask_loss_weight": [
      "self",
      "task_name",
      "weight"
    ],
    "get_multitask_loss": [
      "self",
      "model",
      "sample",
      "model_out"
    ],
    "reduce_metrics": [
      "cls",
      "logging_outputs"
    ]
  },
  "SpeechToUnitMultitaskTaskCriterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg",
      "label_smoothing",
      "ignore_prefix_size",
      "report_accuracy"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "cls",
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "SpeechToSpectrogramMultitaskTaskCriterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg",
      "use_guided_attention_loss",
      "guided_attention_loss_sigma",
      "bce_pos_weight",
      "ctc_weight"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduction"
    ],
    "reduce_metrics": [
      "cls",
      "logging_outputs"
    ]
  },
  "AdaptiveLossConfig": {},
  "AdaptiveLoss": {
    "__init__": [
      "self",
      "task",
      "sentence_avg"
    ],
    "build_criterion": [
      "cls",
      "cfg",
      "task"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "LabelSmoothedCrossEntropyCriterionConfig": {},
  "label_smoothed_nll_loss": [
    "lprobs",
    "target",
    "epsilon",
    "ignore_index",
    "reduce"
  ],
  "LabelSmoothedCrossEntropyCriterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg",
      "label_smoothing",
      "ignore_prefix_size",
      "report_accuracy"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "get_lprobs_and_target": [
      "self",
      "model",
      "net_output",
      "sample"
    ],
    "compute_loss": [
      "self",
      "model",
      "net_output",
      "sample",
      "reduce"
    ],
    "compute_accuracy": [
      "self",
      "model",
      "net_output",
      "sample"
    ],
    "reduce_metrics": [
      "cls",
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "LabelSmoothedDualImitationCriterionConfig": {},
  "LabelSmoothedDualImitationCriterion": {
    "__init__": [
      "self",
      "task",
      "label_smoothing"
    ],
    "_compute_loss": [
      "self",
      "outputs",
      "targets",
      "masks",
      "label_smoothing",
      "name",
      "factor"
    ],
    "_custom_loss": [
      "self",
      "loss",
      "name",
      "factor"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "Tacotron2CriterionConfig": {},
  "GuidedAttentionLoss": {
    "__init__": [
      "self",
      "sigma"
    ],
    "_get_weight": [
      "s_len",
      "t_len",
      "sigma"
    ],
    "_get_weights": [
      "self",
      "src_lens",
      "tgt_lens"
    ],
    "_get_masks": [
      "src_lens",
      "tgt_lens"
    ],
    "forward": [
      "self",
      "attn",
      "src_lens",
      "tgt_lens",
      "reduction"
    ]
  },
  "Tacotron2Criterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg",
      "use_guided_attention_loss",
      "guided_attention_loss_sigma",
      "bce_pos_weight",
      "ctc_weight"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduction"
    ],
    "compute_loss": [
      "self",
      "feat_out",
      "feat_out_post",
      "eos_out",
      "feat_tgt",
      "eos_tgt",
      "tgt_lens",
      "reduction"
    ],
    "reduce_metrics": [
      "cls",
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "ModelCriterionConfig": {},
  "ModelCriterion": {
    "__init__": [
      "self",
      "task",
      "loss_weights",
      "log_keys"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "SentencePredictionConfig": {},
  "SentencePredictionCriterion": {
    "__init__": [
      "self",
      "cfg",
      "task"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "build_criterion": [
    "cfg",
    "task"
  ],
  "SentencePredictionCriterionAdapters": {
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ]
  },
  "LabelSmoothedCrossEntropyWithCtcCriterionConfig": {},
  "LabelSmoothedCrossEntropyWithCtcCriterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg",
      "label_smoothing",
      "ignore_prefix_size",
      "report_accuracy",
      "ctc_weight"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "cls",
      "logging_outputs"
    ]
  },
  "Wav2VecCriterionConfig": {},
  "Wav2vecCriterion": {
    "__init__": [
      "self",
      "task",
      "infonce",
      "loss_weights",
      "log_keys"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": [
      "self"
    ]
  },
  "LabelSmoothedCrossEntropyCriterionLatencyAugmentConfig": {},
  "LatencyAugmentedLabelSmoothedCrossEntropyCriterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg",
      "label_smoothing",
      "ignore_prefix_size",
      "report_accuracy",
      "latency_avg_weight",
      "latency_var_weight",
      "latency_avg_type",
      "latency_var_type",
      "latency_gather_method",
      "latency_update_after"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "compute_latency_loss": [
      "self",
      "model",
      "sample",
      "net_output"
    ],
    "reduce_metrics": [
      "cls",
      "logging_outputs"
    ]
  },
  "SentenceRankingCriterion": {
    "__init__": [
      "self",
      "task",
      "ranking_head_name",
      "save_predictions",
      "num_classes"
    ],
    "__del__": [
      "self"
    ],
    "add_args": [
      "parser"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "FairseqCriterion": {
    "__init__": [
      "self",
      "task"
    ],
    "add_args": [
      "cls",
      "parser"
    ],
    "build_criterion": [
      "cls",
      "cfg",
      "task"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "aggregate_logging_outputs": [
      "logging_outputs"
    ],
    "reduce_metrics": [
      "cls",
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "LegacyFairseqCriterion": {
    "__init__": [
      "self",
      "args",
      "task"
    ],
    "build_criterion": [
      "cls",
      "args",
      "task"
    ]
  },
  "FastSpeech2CriterionConfig": {},
  "FastSpeech2Loss": {
    "__init__": [
      "self",
      "task",
      "ctc_weight"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduction"
    ],
    "reduce_metrics": [
      "cls",
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "compute_cross_entropy_loss": [
    "logits",
    "targets",
    "ignore_index"
  ],
  "LegacyMaskedLmLoss": {
    "__init__": [
      "self",
      "task",
      "masked_lm_only",
      "nsp_loss_weight"
    ],
    "add_args": [
      "parser"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "CtcCriterionConfig": {},
  "CtcCriterion": {
    "__init__": [
      "self",
      "cfg",
      "task"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "SpeechUnitLmCriterionConfig": {},
  "mae_loss": [
    "pred",
    "targ",
    "mask",
    "reduce"
  ],
  "nll_loss": [
    "pred",
    "targ",
    "mask",
    "reduce"
  ],
  "SpeechUnitLmCriterion": {
    "__init__": [
      "self",
      "cfg",
      "task"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "TransformEosLangPairDataset": {
    "__init__": [
      "self",
      "dataset",
      "src_eos",
      "new_src_eos",
      "tgt_bos",
      "new_tgt_bos"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "sizes": [
      "self"
    ],
    "ordered_indices": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ]
  },
  "_flatten": [
    "dico",
    "prefix"
  ],
  "_unflatten": [
    "dico"
  ],
  "NestedDictionaryDataset": {
    "__init__": [
      "self",
      "defn",
      "sizes"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ],
    "can_reuse_epoch_itr_across_epochs": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "fasta_file_path": [
    "prefix_path"
  ],
  "FastaDataset": {
    "__init__": [
      "self",
      "path",
      "cache_indices"
    ],
    "_get_file": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "_build_index": [
      "self",
      "path"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "__getstate__": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "exists": [
      "path"
    ]
  },
  "EncodedFastaDataset": {
    "__init__": [
      "self",
      "path",
      "dictionary"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "StripTokenDataset": {
    "__init__": [
      "self",
      "dataset",
      "id_to_strip"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "SortDataset": {
    "__init__": [
      "self",
      "dataset",
      "sort_order"
    ],
    "ordered_indices": [
      "self"
    ]
  },
  "TransformEosConcatLangPairDataset": {
    "__init__": [
      "self",
      "datasets",
      "src_eos",
      "tgt_bos",
      "new_src_eos",
      "new_tgt_bos"
    ],
    "src_dict_pad": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "is_left_pad_source": [
      "self",
      "datasets"
    ],
    "is_left_pad_target": [
      "self",
      "datasets"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "MaskTokensDataset": {
    "apply_mask": [
      "cls",
      "dataset"
    ],
    "__init__": [
      "self",
      "dataset",
      "vocab",
      "pad_idx",
      "mask_idx",
      "return_masked_tokens",
      "seed",
      "mask_prob",
      "leave_unmasked_prob",
      "random_token_prob",
      "freq_weighted_replacement",
      "mask_whole_words",
      "mask_multiple_length",
      "mask_stdev"
    ],
    "can_reuse_epoch_itr_across_epochs": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__getitem_cached__": [
      "self",
      "seed",
      "epoch",
      "index"
    ]
  },
  "AddTargetDataset": {
    "__init__": [
      "self",
      "dataset",
      "labels",
      "pad",
      "eos",
      "batch_targets",
      "process_label",
      "label_len_fn",
      "add_to_input",
      "text_compression_level"
    ],
    "get_label": [
      "self",
      "index",
      "process_fn"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "filter_indices_by_size": [
      "self",
      "indices",
      "max_sizes"
    ]
  },
  "ResamplingDataset": {
    "__init__": [
      "self",
      "dataset",
      "weights",
      "replace",
      "size_ratio",
      "batch_by_size",
      "seed",
      "epoch"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "sizes": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ],
    "can_reuse_epoch_itr_across_epochs": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "ListDataset": {
    "__init__": [
      "self",
      "dataset",
      "sizes"
    ],
    "__iter__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "sizes": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "ConcatDataset": {
    "cumsum": [
      "sequence",
      "sample_ratios"
    ],
    "__init__": [
      "self",
      "datasets",
      "sample_ratios"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_get_dataset_and_sample_index": [
      "self",
      "idx"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "size": [
      "self",
      "idx"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "attr": [
      "self",
      "attr",
      "index"
    ],
    "sizes": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "ordered_indices": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ],
    "can_reuse_epoch_itr_across_epochs": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "PadDataset": {
    "__init__": [
      "self",
      "dataset",
      "pad_idx",
      "left_pad",
      "pad_length"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "LeftPadDataset": {
    "__init__": [
      "self",
      "dataset",
      "pad_idx"
    ]
  },
  "RightPadDataset": {
    "__init__": [
      "self",
      "dataset",
      "pad_idx"
    ]
  },
  "RawLabelDataset": {
    "__init__": [
      "self",
      "labels"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "MultiCorpusDataset": {
    "__init__": [
      "self",
      "datasets",
      "distribution",
      "seed",
      "sort_indices",
      "batch_sample",
      "distributed_rank"
    ],
    "ordered_indices": [
      "self"
    ],
    "_map_index": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "can_reuse_epoch_itr_across_epochs": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "supports_prefetch": [
      "self"
    ],
    "supports_fetch_outside_dataloader": [
      "self"
    ],
    "batch_by_size": [
      "self",
      "indices",
      "max_tokens",
      "max_sentences",
      "required_batch_size_multiple"
    ]
  },
  "PrependDataset": {
    "__init__": [
      "self",
      "dataset",
      "prepend_getter",
      "ensure_first_token_is"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "Dictionary": {
    "__init__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "get_count": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "__contains__": [
      "self",
      "sym"
    ],
    "index": [
      "self",
      "sym"
    ],
    "string": [
      "self",
      "tensor",
      "bpe_symbol",
      "escape_unk",
      "extra_symbols_to_ignore",
      "unk_string",
      "include_eos",
      "separator"
    ],
    "unk_string": [
      "self",
      "escape"
    ],
    "add_symbol": [
      "self",
      "word",
      "n",
      "overwrite"
    ],
    "update": [
      "self",
      "new_dict"
    ],
    "finalize": [
      "self",
      "threshold",
      "nwords",
      "padding_factor"
    ],
    "pad_to_multiple_": [
      "self",
      "padding_factor"
    ],
    "bos": [
      "self"
    ],
    "pad": [
      "self"
    ],
    "eos": [
      "self"
    ],
    "unk": [
      "self"
    ],
    "load": [
      "cls",
      "f"
    ],
    "add_from_file": [
      "self",
      "f"
    ],
    "_save": [
      "self",
      "f",
      "kv_iterator"
    ],
    "_get_meta": [
      "self"
    ],
    "_load_meta": [
      "self",
      "lines"
    ],
    "save": [
      "self",
      "f"
    ],
    "dummy_sentence": [
      "self",
      "length"
    ],
    "encode_line": [
      "self",
      "line",
      "line_tokenizer",
      "add_if_not_exist",
      "consumer",
      "append_eos",
      "reverse_order"
    ],
    "_add_file_to_dictionary_single_worker": [
      "filename",
      "tokenize",
      "eos_word",
      "start_offset",
      "end_offset"
    ],
    "add_file_to_dictionary": [
      "filename",
      "dict",
      "tokenize",
      "num_workers"
    ]
  },
  "TruncatedDictionary": {
    "__init__": [
      "self",
      "wrapped_dict",
      "length"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ]
  },
  "IdDataset": {
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "LMContextWindowDataset": {
    "__init__": [
      "self",
      "dataset",
      "tokens_per_sample",
      "context_window",
      "pad_idx"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ]
  },
  "_sentinel": [],
  "CountingIterator": {
    "__init__": [
      "self",
      "iterable",
      "start",
      "total"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "has_next": [
      "self"
    ],
    "skip": [
      "self",
      "n"
    ],
    "take": [
      "self",
      "n"
    ]
  },
  "EpochBatchIterating": {
    "__len__": [
      "self"
    ],
    "next_epoch_idx": [
      "self"
    ],
    "next_epoch_itr": [
      "self",
      "shuffle",
      "fix_batches_to_gpus",
      "set_dataset_epoch"
    ],
    "end_of_epoch": [
      "self"
    ],
    "iterations_in_epoch": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "first_batch": [
      "self"
    ]
  },
  "StreamingEpochBatchIterator": {
    "__init__": [
      "self",
      "dataset",
      "max_sentences",
      "collate_fn",
      "epoch",
      "num_workers",
      "buffer_size",
      "timeout"
    ],
    "next_epoch_idx": [
      "self"
    ],
    "next_epoch_itr": [
      "self",
      "shuffle",
      "fix_batches_to_gpus",
      "set_dataset_epoch"
    ],
    "end_of_epoch": [
      "self"
    ],
    "iterations_in_epoch": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "_get_iterator_for_epoch": [
      "self",
      "epoch",
      "shuffle",
      "offset"
    ]
  },
  "FrozenBatchSampler": {
    "__init__": [
      "self",
      "ordered_batches",
      "epoch",
      "fix_batches_to_gpus",
      "shuffle",
      "initial_offset"
    ],
    "make_batches_for_epoch": [
      "self",
      "epoch",
      "offset"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "EpochBatchIterator": {
    "__init__": [
      "self",
      "dataset",
      "collate_fn",
      "batch_sampler",
      "seed",
      "num_shards",
      "shard_id",
      "num_workers",
      "epoch",
      "buffer_size",
      "timeout",
      "disable_shuffling",
      "skip_remainder_batch",
      "grouped_shuffling",
      "reuse_dataloader"
    ],
    "frozen_batches": [
      "self"
    ],
    "first_batch": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "n": [
      "self"
    ],
    "next_epoch_idx": [
      "self"
    ],
    "next_epoch_itr": [
      "self",
      "shuffle",
      "fix_batches_to_gpus",
      "set_dataset_epoch"
    ],
    "end_of_epoch": [
      "self"
    ],
    "iterations_in_epoch": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "_get_iterator_for_epoch": [
      "self",
      "epoch",
      "shuffle",
      "fix_batches_to_gpus",
      "offset"
    ],
    "ordered_batches": [
      "self",
      "epoch",
      "fix_batches_to_gpus",
      "shuffle"
    ]
  },
  "GroupedIterator": {
    "__init__": [
      "self",
      "iterable",
      "chunk_size",
      "skip_remainder_batch"
    ]
  },
  "_chunk_iterator": [
    "itr",
    "chunk_size",
    "skip_remainder_batch"
  ],
  "ShardedIterator": {
    "__init__": [
      "self",
      "iterable",
      "num_shards",
      "shard_id",
      "fill_value",
      "skip_remainder_batch"
    ]
  },
  "BackgroundConsumer": {
    "__init__": [
      "self",
      "queue",
      "source",
      "max_len",
      "cuda_device"
    ],
    "run": [
      "self"
    ]
  },
  "BufferedIterator": {
    "__init__": [
      "self",
      "size",
      "iterable"
    ],
    "_create_consumer": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "take": [
      "self",
      "n"
    ],
    "__next__": [
      "self"
    ]
  },
  "GroupedEpochBatchIterator": {
    "__init__": [
      "self",
      "dataset",
      "collate_fn",
      "batch_samplers",
      "seed",
      "num_shards",
      "shard_id",
      "num_workers",
      "epoch",
      "mult_rate",
      "buffer_size",
      "skip_remainder_batch"
    ],
    "__len__": [
      "self"
    ],
    "first_batch": [
      "self"
    ],
    "_get_iterator_for_epoch": [
      "self",
      "epoch",
      "shuffle",
      "fix_batches_to_gpus",
      "offset"
    ]
  },
  "collate": [
    "samples",
    "pad_idx",
    "eos_idx",
    "fixed_pad_length",
    "pad_to_bsz"
  ],
  "MonolingualDataset": {
    "__init__": [
      "self",
      "dataset",
      "sizes",
      "src_vocab",
      "tgt_vocab",
      "add_eos_for_other_targets",
      "shuffle",
      "targets",
      "add_bos_token",
      "fixed_pad_length",
      "pad_to_bsz",
      "src_lang_idx",
      "tgt_lang_idx"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "_make_source_target": [
      "self",
      "source",
      "future_target",
      "past_target"
    ],
    "_maybe_add_bos": [
      "self",
      "source",
      "target"
    ],
    "num_tokens_vec": [
      "self",
      "indices"
    ],
    "_filter_vocab": [
      "self",
      "target"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ]
  },
  "NumSamplesDataset": {
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "RollDataset": {
    "__init__": [
      "self",
      "dataset",
      "shifts"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "EpochListening": {
    "can_reuse_epoch_itr_across_epochs": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "FairseqDataset": {
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "num_tokens_vec": [
      "self",
      "indices"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "attr": [
      "self",
      "attr",
      "index"
    ],
    "prefetch": [
      "self",
      "indices"
    ],
    "get_batch_shapes": [
      "self"
    ],
    "batch_by_size": [
      "self",
      "indices",
      "max_tokens",
      "max_sentences",
      "required_batch_size_multiple"
    ],
    "filter_indices_by_size": [
      "self",
      "indices",
      "max_sizes"
    ],
    "supports_fetch_outside_dataloader": [
      "self"
    ]
  },
  "FairseqIterableDataset": {
    "__iter__": [
      "self"
    ]
  },
  "ColorizeDataset": {
    "__init__": [
      "self",
      "dataset",
      "color_getter"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "NumelDataset": {
    "__init__": [
      "self",
      "dataset",
      "reduce"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "BaseWrapperDataset": {
    "__init__": [
      "self",
      "dataset"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "sizes": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "attr": [
      "self",
      "attr",
      "index"
    ],
    "prefetch": [
      "self",
      "indices"
    ],
    "get_batch_shapes": [
      "self"
    ],
    "batch_by_size": [
      "self",
      "indices",
      "max_tokens",
      "max_sentences",
      "required_batch_size_multiple"
    ],
    "filter_indices_by_size": [
      "self",
      "indices",
      "max_sizes"
    ],
    "can_reuse_epoch_itr_across_epochs": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "uniform_sampler": [
    "x"
  ],
  "MultiCorpusSampledDataset": {
    "__init__": [
      "self",
      "datasets",
      "sampling_func"
    ],
    "__len__": [
      "self"
    ],
    "ordered_indices": [
      "self"
    ],
    "_map_index_to_dataset": [
      "self",
      "key",
      "index"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ],
    "supports_fetch_outside_dataloader": [
      "self"
    ]
  },
  "TextCompressionLevel": {
    "none": [],
    "low": [],
    "high": []
  },
  "TextCompressor": {
    "__init__": [
      "self",
      "level",
      "max_input_byte_length"
    ],
    "compress": [
      "self",
      "text"
    ],
    "decompress": [
      "self",
      "compressed"
    ]
  },
  "LanguagePairDataset": {
    "__init__": [
      "self",
      "src",
      "src_sizes",
      "src_dict",
      "tgt",
      "tgt_sizes",
      "tgt_dict",
      "left_pad_source",
      "left_pad_target",
      "shuffle",
      "input_feeding",
      "remove_eos_from_source",
      "append_eos_to_target",
      "align_dataset",
      "constraints",
      "append_bos",
      "eos",
      "num_buckets",
      "src_lang_id",
      "tgt_lang_id",
      "pad_to_multiple"
    ],
    "get_batch_shapes": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples",
      "pad_to_length"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "num_tokens_vec": [
      "self",
      "indices"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ],
    "filter_indices_by_size": [
      "self",
      "indices",
      "max_sizes"
    ]
  },
  "WordNoising": {
    "__init__": [
      "self",
      "dictionary",
      "bpe_cont_marker",
      "bpe_end_marker"
    ],
    "noising": [
      "self",
      "x",
      "lengths",
      "noising_prob"
    ],
    "_get_bpe_word_idx": [
      "self",
      "x"
    ],
    "_get_token_idx": [
      "self",
      "x"
    ]
  },
  "WordDropout": {
    "__init__": [
      "self",
      "dictionary",
      "default_dropout_prob",
      "bpe_cont_marker",
      "bpe_end_marker"
    ],
    "noising": [
      "self",
      "x",
      "lengths",
      "dropout_prob",
      "blank_idx"
    ]
  },
  "WordShuffle": {
    "__init__": [
      "self",
      "dictionary",
      "default_max_shuffle_distance",
      "bpe_cont_marker",
      "bpe_end_marker"
    ],
    "noising": [
      "self",
      "x",
      "lengths",
      "max_shuffle_distance"
    ]
  },
  "UnsupervisedMTNoising": {
    "__init__": [
      "self",
      "dictionary",
      "max_word_shuffle_distance",
      "word_dropout_prob",
      "word_blanking_prob",
      "bpe_cont_marker",
      "bpe_end_marker"
    ],
    "noising": [
      "self",
      "x",
      "lengths"
    ]
  },
  "NoisingDataset": {
    "__init__": [
      "self",
      "src_dataset",
      "src_dict",
      "seed",
      "noiser",
      "noising_class"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ]
  },
  "OffsetTokensDataset": {
    "__init__": [
      "self",
      "dataset",
      "offset"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "RoundRobinZipDatasets": {
    "__init__": [
      "self",
      "datasets",
      "eval_key"
    ],
    "_map_index": [
      "self",
      "key",
      "index"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "filter_indices_by_size": [
      "self",
      "indices",
      "max_positions"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ]
  },
  "ConcatSentencesDataset": {
    "__init__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "sizes": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "PrependTokenDataset": {
    "__init__": [
      "self",
      "dataset",
      "token"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "sizes": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ]
  },
  "BucketPadLengthDataset": {
    "__init__": [
      "self",
      "dataset",
      "sizes",
      "num_buckets",
      "pad_idx",
      "left_pad",
      "tensor_key"
    ],
    "_set_tensor": [
      "self",
      "item",
      "val"
    ],
    "_get_tensor": [
      "self",
      "item"
    ],
    "_pad": [
      "self",
      "tensor",
      "bucket_size",
      "dim"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "sizes": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ]
  },
  "SubsampleDataset": {
    "__init__": [
      "self",
      "dataset",
      "size_ratio",
      "shuffle"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "sizes": [
      "self"
    ],
    "name": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ]
  },
  "F0_FRAME_SPACE": [],
  "ExpressiveCodeDataConfig": {
    "__init__": [
      "self",
      "json_path"
    ],
    "manifests": [
      "self"
    ],
    "n_units": [
      "self"
    ],
    "sampling_rate": [
      "self"
    ],
    "code_hop_size": [
      "self"
    ],
    "f0_stats": [
      "self"
    ],
    "f0_vq_type": [
      "self"
    ],
    "f0_vq_name": [
      "self"
    ],
    "get_f0_vq_naive_quantizer": [
      "self",
      "log",
      "norm_mean",
      "norm_std"
    ],
    "f0_vq_n_units": [
      "self"
    ],
    "multispkr": [
      "self"
    ]
  },
  "get_f0": [
    "audio",
    "rate"
  ],
  "interpolate_f0": [
    "f0"
  ],
  "naive_quantize": [
    "x",
    "edges"
  ],
  "load_wav": [
    "full_path"
  ],
  "parse_code": [
    "code_str",
    "dictionary",
    "append_eos"
  ],
  "parse_manifest": [
    "manifest",
    "dictionary"
  ],
  "parse_speaker": [
    "path",
    "method"
  ],
  "get_f0_by_filename": [
    "filename",
    "tgt_sampling_rate"
  ],
  "align_f0_to_durations": [
    "f0",
    "durations",
    "f0_code_ratio",
    "tol"
  ],
  "Paddings": {
    "__init__": [
      "self",
      "code_val",
      "dur_val",
      "f0_val"
    ]
  },
  "Shifts": {
    "__init__": [
      "self",
      "shifts_str",
      "pads"
    ],
    "dur": [
      "self"
    ],
    "f0": [
      "self"
    ],
    "shift_one": [
      "seq",
      "left_pad_num",
      "right_pad_num",
      "pad"
    ],
    "__call__": [
      "self",
      "code",
      "dur",
      "f0"
    ]
  },
  "CodeDataset": {
    "__init__": [
      "self",
      "manifest",
      "dictionary",
      "dur_dictionary",
      "f0_dictionary",
      "config",
      "discrete_dur",
      "discrete_f0",
      "log_f0",
      "normalize_f0_mean",
      "normalize_f0_std",
      "interpolate_f0",
      "return_filename",
      "strip_filename",
      "shifts",
      "return_continuous_f0"
    ],
    "get_data_handlers": [
      "self"
    ],
    "preprocess_f0": [
      "self",
      "f0",
      "stats"
    ],
    "_get_raw_item": [
      "self",
      "index"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "size": [
      "self",
      "index"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "ReplaceDataset": {
    "__init__": [
      "self",
      "dataset",
      "replace_map",
      "offsets"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "TruncateDataset": {
    "__init__": [
      "self",
      "dataset",
      "truncation_length"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "sizes": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "RandomCropDataset": {
    "__init__": [
      "self",
      "dataset",
      "truncation_length",
      "seed"
    ],
    "can_reuse_epoch_itr_across_epochs": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "maybe_shorten_dataset": [
    "dataset",
    "split",
    "shorten_data_split_list",
    "shorten_method",
    "tokens_per_sample",
    "seed"
  ],
  "AppendTokenDataset": {
    "__init__": [
      "self",
      "dataset",
      "token"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "sizes": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ]
  },
  "TokenBlockDataset": {
    "__init__": [
      "self",
      "dataset",
      "sizes",
      "block_size",
      "pad",
      "eos",
      "break_mode",
      "include_targets",
      "document_sep_len",
      "use_plasma_view",
      "split_path",
      "plasma_path"
    ],
    "_build_slice_indices": [
      "sizes",
      "break_mode",
      "document_sep_len",
      "block_size"
    ],
    "slice_indices": [
      "self"
    ],
    "sizes": [
      "self"
    ],
    "block_to_dataset_index": [
      "self"
    ],
    "attr": [
      "self",
      "attr",
      "index"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ]
  },
  "DenoisingDataset": {
    "__init__": [
      "self",
      "dataset",
      "sizes",
      "vocab",
      "mask_idx",
      "mask_whole_words",
      "shuffle",
      "seed",
      "args",
      "eos",
      "item_transform_func"
    ],
    "can_reuse_epoch_itr_across_epochs": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "permute_sentences": [
      "self",
      "source",
      "p"
    ],
    "word_starts": [
      "self",
      "source"
    ],
    "add_whole_word_mask": [
      "self",
      "source",
      "p"
    ],
    "add_permuted_noise": [
      "self",
      "tokens",
      "p"
    ],
    "add_rolling_noise": [
      "self",
      "tokens"
    ],
    "add_insertion_noise": [
      "self",
      "tokens",
      "p"
    ],
    "collater": [
      "self",
      "samples",
      "pad_to_length"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ],
    "supports_prefetch": [
      "self"
    ]
  },
  "best_fitting_int_dtype": [
    "max_int_to_represent"
  ],
  "get_available_dataset_impl": [],
  "infer_dataset_impl": [
    "path"
  ],
  "make_builder": [
    "out_file",
    "impl",
    "vocab_size"
  ],
  "make_dataset": [
    "path",
    "impl",
    "fix_lua_indexing",
    "dictionary"
  ],
  "dataset_exists": [
    "path",
    "impl"
  ],
  "read_longs": [
    "f",
    "n"
  ],
  "write_longs": [
    "f",
    "a"
  ],
  "_code_to_dtype": [],
  "_dtype_header_code": [
    "dtype"
  ],
  "index_file_path": [
    "prefix_path"
  ],
  "data_file_path": [
    "prefix_path"
  ],
  "IndexedDataset": {
    "_HDR_MAGIC": [],
    "__init__": [
      "self",
      "path",
      "fix_lua_indexing"
    ],
    "read_index": [
      "self",
      "path"
    ],
    "read_data": [
      "self",
      "path"
    ],
    "check_index": [
      "self",
      "i"
    ],
    "__del__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__len__": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "exists": [
      "path"
    ],
    "supports_prefetch": [
      "self"
    ]
  },
  "IndexedCachedDataset": {
    "__init__": [
      "self",
      "path",
      "fix_lua_indexing"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ],
    "__getitem__": [
      "self",
      "i"
    ]
  },
  "IndexedRawTextDataset": {
    "__init__": [
      "self",
      "path",
      "dictionary",
      "append_eos",
      "reverse_order"
    ],
    "read_data": [
      "self",
      "path",
      "dictionary"
    ],
    "check_index": [
      "self",
      "i"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "get_original_text": [
      "self",
      "i"
    ],
    "__del__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "exists": [
      "path"
    ]
  },
  "IndexedDatasetBuilder": {
    "element_sizes": [],
    "__init__": [
      "self",
      "out_file",
      "dtype"
    ],
    "add_item": [
      "self",
      "tensor"
    ],
    "merge_file_": [
      "self",
      "another_file"
    ],
    "finalize": [
      "self",
      "index_file"
    ]
  },
  "_warmup_mmap_file": [
    "path"
  ],
  "MMapIndexedDataset": {
    "__init__": [
      "self",
      "path"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "_do_init": [
      "self",
      "path"
    ],
    "__del__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "sizes": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "exists": [
      "path"
    ]
  },
  "get_indexed_dataset_to_local": [
    "path"
  ],
  "MMapIndexedDatasetBuilder": {
    "__init__": [
      "self",
      "out_file",
      "dtype"
    ],
    "add_item": [
      "self",
      "tensor"
    ],
    "merge_file_": [
      "self",
      "another_file"
    ],
    "finalize": [
      "self",
      "index_file"
    ]
  },
  "TransformEosDataset": {
    "__init__": [
      "self",
      "dataset",
      "eos",
      "append_eos_to_src",
      "remove_eos_from_src",
      "append_eos_to_tgt",
      "remove_eos_from_tgt",
      "has_target"
    ],
    "_check_src": [
      "self",
      "src",
      "expect_eos"
    ],
    "_check_tgt": [
      "self",
      "tgt",
      "expect_eos"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ]
  },
  "LRUCacheDataset": {
    "__init__": [
      "self",
      "dataset",
      "token"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "PlasmaArray": {
    "__init__": [
      "self",
      "array"
    ],
    "plasma": [
      "self"
    ],
    "start_server": [
      "self"
    ],
    "client": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "__del__": [
      "self"
    ]
  },
  "DEFAULT_PLASMA_PATH": [],
  "PlasmaView": {
    "__init__": [
      "self",
      "array",
      "split_path",
      "hash_data",
      "plasma_path"
    ],
    "client": [
      "self"
    ],
    "array": [
      "self"
    ],
    "get_object_id": [
      "split_path",
      "hash_data"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "__del__": [
      "self"
    ],
    "disconnect": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "GB100": [],
  "PlasmaStore": {
    "__init__": [
      "self",
      "path",
      "nbytes"
    ],
    "__del__": [
      "self"
    ],
    "start": [
      "path",
      "nbytes"
    ]
  },
  "backtranslate_samples": [
    "samples",
    "collate_fn",
    "generate_fn",
    "cuda"
  ],
  "BacktranslationDataset": {
    "__init__": [
      "self",
      "tgt_dataset",
      "src_dict",
      "tgt_dict",
      "backtranslation_fn",
      "output_collater",
      "cuda"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "set_backtranslation_fn": [
      "self",
      "backtranslation_fn"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "size": [
      "self",
      "index"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ]
  },
  "infer_language_pair": [
    "path"
  ],
  "collate_tokens": [
    "values",
    "pad_idx",
    "eos_idx",
    "left_pad",
    "move_eos_to_beginning",
    "pad_to_length",
    "pad_to_multiple",
    "pad_to_bsz"
  ],
  "load_indexed_dataset": [
    "path",
    "dictionary",
    "dataset_impl",
    "combine",
    "default"
  ],
  "numpy_seed": [
    "seed"
  ],
  "collect_filtered": [
    "function",
    "iterable",
    "filtered"
  ],
  "_filter_by_size_dynamic": [
    "indices",
    "size_fn",
    "max_positions",
    "raise_exception"
  ],
  "filter_by_size": [
    "indices",
    "dataset",
    "max_positions",
    "raise_exception"
  ],
  "filter_paired_dataset_indices_by_size": [
    "src_sizes",
    "tgt_sizes",
    "indices",
    "max_sizes"
  ],
  "batch_by_size": [
    "indices",
    "num_tokens_fn",
    "num_tokens_vec",
    "max_tokens",
    "max_sentences",
    "required_batch_size_multiple",
    "fixed_shapes"
  ],
  "post_process": [
    "sentence",
    "symbol"
  ],
  "compute_mask_indices": [
    "shape",
    "padding_mask",
    "mask_prob",
    "mask_length",
    "mask_type",
    "mask_other",
    "min_masks",
    "no_overlap",
    "min_space",
    "require_same_masks",
    "mask_dropout"
  ],
  "get_mem_usage": [],
  "lengths_to_padding_mask": [
    "lens"
  ],
  "lengths_to_mask": [
    "lens"
  ],
  "get_buckets": [
    "sizes",
    "num_buckets"
  ],
  "get_bucketed_sizes": [
    "orig_sizes",
    "buckets"
  ],
  "_find_extra_valid_paths": [
    "dataset_path"
  ],
  "raise_if_valid_subsets_unintentionally_ignored": [
    "train_cfg"
  ],
  "HuffmanMMapIndex": {
    "_HDR_MAGIC": [],
    "_VERSION": [],
    "writer": [
      "cls",
      "path",
      "data_len"
    ],
    "__init__": [
      "self",
      "path"
    ],
    "__del__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "data_len": [
      "self"
    ],
    "sizes": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__len__": [
      "self"
    ]
  },
  "vocab_file_path": [
    "prefix_path"
  ],
  "HuffmanMMapIndexedDataset": {
    "__init__": [
      "self",
      "prefix_path"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "_do_init": [
      "self",
      "prefix_path"
    ],
    "__del__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "_decode": [
      "self",
      "i"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__iter__": [
      "self"
    ],
    "get_symbols": [
      "self",
      "i"
    ],
    "sizes": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "coder": [
      "self"
    ],
    "exists": [
      "prefix_path"
    ]
  },
  "HuffmanMMapIndexedDatasetBuilder": {
    "__init__": [
      "self",
      "path_prefix",
      "coder"
    ],
    "open": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "add_item": [
      "self",
      "tokens"
    ],
    "append": [
      "self",
      "other_dataset_path_prefix"
    ],
    "close": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "BLOCKSIZE": [],
  "HuffmanCoder": {
    "__init__": [
      "self",
      "root",
      "bos",
      "pad",
      "eos",
      "unk"
    ],
    "_pad": [
      "self",
      "a"
    ],
    "_unpad": [
      "self",
      "a"
    ],
    "encode": [
      "self",
      "iter"
    ],
    "decode": [
      "self",
      "bits"
    ],
    "get_code": [
      "self",
      "symbol"
    ],
    "get_node": [
      "self",
      "symbol"
    ],
    "from_file": [
      "cls",
      "filename",
      "bos",
      "pad",
      "eos",
      "unk"
    ],
    "to_file": [
      "self",
      "filename",
      "sep"
    ],
    "__iter__": [
      "self"
    ],
    "merge": [
      "self",
      "other_coder"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__len__": [
      "self"
    ],
    "__contains__": [
      "self",
      "sym"
    ],
    "to_dictionary": [
      "self"
    ]
  },
  "HuffmanNode": {
    "is_leaf": [
      "self"
    ],
    "code_table": [
      "self",
      "prefix"
    ],
    "decode": [
      "self",
      "bits"
    ]
  },
  "HuffmanCodeBuilder": {
    "__init__": [
      "self"
    ],
    "add_symbols": [
      "self"
    ],
    "increment": [
      "self",
      "symbol",
      "cnt"
    ],
    "from_file": [
      "cls",
      "filename"
    ],
    "to_file": [
      "self",
      "filename",
      "sep"
    ],
    "_smallest": [
      "self",
      "q1",
      "q2"
    ],
    "__add__": [
      "self",
      "c"
    ],
    "build_code": [
      "self",
      "bos",
      "pad",
      "eos",
      "unk"
    ]
  },
  "WHITESPACE_NORMALIZER": [],
  "SPACE": [],
  "SPACE_ESCAPE": [],
  "PRINTABLE_LATIN": [],
  "BYTE_TO_BCHAR": [],
  "BCHAR_TO_BYTE": [],
  "byte_encode": [
    "x"
  ],
  "byte_decode": [
    "x"
  ],
  "smart_byte_decode": [
    "x"
  ],
  "DEFAULT_ENCODER_JSON": [],
  "DEFAULT_VOCAB_BPE": [],
  "GPT2BPEConfig": {},
  "GPT2BPE": {
    "__init__": [
      "self",
      "cfg"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "x"
    ],
    "is_beginning_of_word": [
      "self",
      "x"
    ]
  },
  "SubwordNMTBPEConfig": {},
  "SubwordNMTBPE": {
    "__init__": [
      "self",
      "cfg"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "x"
    ]
  },
  "ByteBpeConfig": {},
  "ByteBPE": {
    "__init__": [
      "self",
      "cfg"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "x"
    ]
  },
  "get_whole_word_mask": [
    "args",
    "dictionary"
  ],
  "HuggingFaceByteLevelBPEConfig": {},
  "HuggingFaceByteLevelBPE": {
    "__init__": [
      "self",
      "cfg"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "x"
    ],
    "is_beginning_of_word": [
      "self",
      "x"
    ]
  },
  "SentencepieceConfig": {},
  "SentencepieceBPE": {
    "__init__": [
      "self",
      "cfg"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "x"
    ],
    "is_beginning_of_word": [
      "self",
      "x"
    ]
  },
  "Bytes": {
    "__init__": [
      "self"
    ],
    "add_args": [
      "parser"
    ],
    "encode": [
      "x"
    ],
    "decode": [
      "x"
    ]
  },
  "NLTKTokenizer": {
    "__init__": [
      "self"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "x"
    ]
  },
  "MosesTokenizerConfig": {},
  "MosesTokenizer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "x"
    ]
  },
  "SpaceTokenizer": {
    "__init__": [
      "self"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "x"
    ]
  },
  "fastBPEConfig": {},
  "fastBPE": {
    "__init__": [
      "self",
      "cfg"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "x"
    ]
  },
  "Characters": {
    "__init__": [
      "self"
    ],
    "add_args": [
      "parser"
    ],
    "encode": [
      "x"
    ],
    "decode": [
      "x"
    ]
  },
  "bytes_to_unicode": [],
  "get_pairs": [
    "word"
  ],
  "Encoder": {
    "__init__": [
      "self",
      "encoder",
      "bpe_merges",
      "errors"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "tokens"
    ]
  },
  "get_encoder": [
    "encoder_json_path",
    "vocab_bpe_path"
  ],
  "BertBPEConfig": {},
  "BertBPE": {
    "__init__": [
      "self",
      "cfg"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "x"
    ],
    "is_beginning_of_word": [
      "self",
      "x"
    ]
  },
  "load_audio": [
    "manifest_path",
    "max_keep",
    "min_keep"
  ],
  "load_label": [
    "label_path",
    "inds",
    "tot"
  ],
  "load_label_offset": [
    "label_path",
    "inds",
    "tot"
  ],
  "verify_label_lengths": [
    "audio_sizes",
    "audio_rate",
    "label_path",
    "label_rate",
    "inds",
    "tot",
    "tol"
  ],
  "HubertDataset": {
    "__init__": [
      "self",
      "manifest_path",
      "sample_rate",
      "label_paths",
      "label_rates",
      "pad_list",
      "eos_list",
      "label_processors",
      "max_keep_sample_size",
      "min_keep_sample_size",
      "max_sample_size",
      "shuffle",
      "pad_audio",
      "normalize",
      "store_labels",
      "random_crop",
      "single_target"
    ],
    "get_audio": [
      "self",
      "index"
    ],
    "get_label": [
      "self",
      "index",
      "label_idx"
    ],
    "get_labels": [
      "self",
      "index"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "crop_to_max_size": [
      "self",
      "wav",
      "target_size"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "collater_audio": [
      "self",
      "audios",
      "audio_size"
    ],
    "collater_frm_label": [
      "self",
      "targets",
      "audio_size",
      "audio_starts",
      "label_rate",
      "pad"
    ],
    "collater_seq_label": [
      "self",
      "targets",
      "pad"
    ],
    "collater_label": [
      "self",
      "targets_by_label",
      "audio_size",
      "audio_starts"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "postprocess": [
      "self",
      "wav",
      "cur_sample_rate"
    ]
  },
  "RawAudioDataset": {
    "__init__": [
      "self",
      "sample_rate",
      "max_sample_size",
      "min_sample_size",
      "shuffle",
      "pad",
      "normalize",
      "compute_mask_indices"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "postprocess": [
      "self",
      "feats",
      "curr_sample_rate"
    ],
    "crop_to_max_size": [
      "self",
      "wav",
      "target_size"
    ],
    "_compute_mask_indices": [
      "self",
      "dims",
      "padding_mask"
    ],
    "_bucket_tensor": [
      "tensor",
      "num_pad",
      "value"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "_get_mask_indices_dims": [
      "self",
      "size",
      "padding",
      "dilation"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "set_bucket_info": [
      "self",
      "num_buckets"
    ]
  },
  "FileAudioDataset": {
    "__init__": [
      "self",
      "manifest_path",
      "sample_rate",
      "max_sample_size",
      "min_sample_size",
      "shuffle",
      "pad",
      "normalize",
      "num_buckets",
      "compute_mask_indices",
      "text_compression_level"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "BinarizedAudioDataset": {
    "__init__": [
      "self",
      "data_dir",
      "split",
      "sample_rate",
      "max_sample_size",
      "min_sample_size",
      "shuffle",
      "pad",
      "normalize",
      "num_buckets",
      "compute_mask_indices"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "SF_AUDIO_FILE_EXTENSIONS": [],
  "FEATURE_OR_SF_AUDIO_FILE_EXTENSIONS": [],
  "convert_waveform": [
    "waveform",
    "sample_rate",
    "normalize_volume",
    "to_mono",
    "to_sample_rate"
  ],
  "get_waveform": [
    "path_or_fp",
    "normalization",
    "mono",
    "frames",
    "start",
    "always_2d",
    "output_sample_rate",
    "normalize_volume"
  ],
  "get_features_from_npy_or_audio": [
    "path"
  ],
  "get_features_or_waveform_from_stored_zip": [
    "path",
    "byte_offset",
    "byte_size",
    "need_waveform",
    "use_sample_rate"
  ],
  "get_features_or_waveform": [
    "path",
    "need_waveform",
    "use_sample_rate"
  ],
  "_get_kaldi_fbank": [
    "waveform",
    "sample_rate",
    "n_bins"
  ],
  "_get_torchaudio_fbank": [
    "waveform",
    "sample_rate",
    "n_bins"
  ],
  "get_fbank": [
    "path_or_fp",
    "n_bins"
  ],
  "is_npy_data": [
    "data"
  ],
  "is_sf_audio_data": [
    "data"
  ],
  "mmap_read": [
    "path",
    "offset",
    "length"
  ],
  "read_from_stored_zip": [
    "zip_path",
    "offset",
    "length"
  ],
  "parse_path": [
    "path"
  ],
  "get_window": [
    "window_fn",
    "n_fft",
    "win_length"
  ],
  "get_fourier_basis": [
    "n_fft"
  ],
  "get_mel_filters": [
    "sample_rate",
    "n_fft",
    "n_mels",
    "f_min",
    "f_max"
  ],
  "TTSSpectrogram": {
    "__init__": [
      "self",
      "n_fft",
      "win_length",
      "hop_length",
      "window_fn",
      "return_phase"
    ],
    "forward": [
      "self",
      "waveform"
    ]
  },
  "TTSMelScale": {
    "__init__": [
      "self",
      "n_mels",
      "sample_rate",
      "f_min",
      "f_max",
      "n_stft"
    ],
    "forward": [
      "self",
      "specgram"
    ]
  },
  "SpeechToSpeechDatasetItem": {},
  "SpeechToSpeechDataset": {
    "__init__": [
      "self",
      "split",
      "is_train_split",
      "data_cfg",
      "src_audio_paths",
      "src_n_frames",
      "tgt_audio_paths",
      "tgt_n_frames",
      "src_langs",
      "tgt_langs",
      "ids",
      "target_is_code",
      "tgt_dict",
      "n_frames_per_step"
    ],
    "pack_units": [
      "self",
      "input"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_collate_target": [
      "self",
      "samples"
    ],
    "collater": [
      "self",
      "samples",
      "return_order"
    ]
  },
  "TextTargetMultitaskData": {
    "__init__": [
      "self",
      "args",
      "split",
      "tgt_dict"
    ],
    "get": [
      "self",
      "sample_id"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "SpeechToSpeechMultitaskDataset": {
    "__init__": [
      "self"
    ],
    "add_multitask_dataset": [
      "self",
      "task_name",
      "task_data"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "SpeechToSpeechDatasetCreator": {
    "DEFAULT_LANG": [],
    "_from_list": [
      "cls",
      "split_name",
      "is_train_split",
      "samples",
      "data_cfg",
      "target_is_code",
      "target_dictionary",
      "n_frames_per_step",
      "multitask"
    ],
    "from_tsv": [
      "cls",
      "root",
      "data_cfg",
      "splits",
      "is_train_split",
      "epoch",
      "seed",
      "target_is_code",
      "target_dictionary",
      "n_frames_per_step",
      "multitask"
    ]
  },
  "get_config_from_yaml": [
    "yaml_path"
  ],
  "S2TDataConfig": {
    "__init__": [
      "self",
      "yaml_path"
    ],
    "_auto_convert_to_abs_path": [
      "self",
      "x"
    ],
    "vocab_filename": [
      "self"
    ],
    "speaker_set_filename": [
      "self"
    ],
    "shuffle": [
      "self"
    ],
    "pre_tokenizer": [
      "self"
    ],
    "bpe_tokenizer": [
      "self"
    ],
    "prepend_tgt_lang_tag": [
      "self"
    ],
    "prepend_bos_and_append_tgt_lang_tag": [
      "self"
    ],
    "input_feat_per_channel": [
      "self"
    ],
    "input_channels": [
      "self"
    ],
    "sample_rate": [
      "self"
    ],
    "sampling_alpha": [
      "self"
    ],
    "use_audio_input": [
      "self"
    ],
    "standardize_audio": [
      "self"
    ],
    "use_sample_rate": [
      "self"
    ],
    "audio_root": [
      "self"
    ],
    "get_feature_transforms": [
      "self",
      "split",
      "is_train"
    ],
    "global_cmvn_stats_npz": [
      "self"
    ],
    "vocoder": [
      "self"
    ],
    "hub": [
      "self"
    ]
  },
  "S2SDataConfig": {
    "vocab_filename": [
      "self"
    ],
    "pre_tokenizer": [
      "self"
    ],
    "bpe_tokenizer": [
      "self"
    ],
    "input_transformed_channels": [
      "self"
    ],
    "output_sample_rate": [
      "self"
    ],
    "target_speaker_embed": [
      "self"
    ],
    "prepend_tgt_lang_tag_as_bos": [
      "self"
    ]
  },
  "MultitaskConfig": {
    "__init__": [
      "self",
      "yaml_path"
    ],
    "get_all_tasks": [
      "self"
    ],
    "get_single_task": [
      "self",
      "name"
    ]
  },
  "SingleTaskConfig": {
    "__init__": [
      "self",
      "name",
      "config"
    ],
    "data": [
      "self"
    ],
    "decoder_type": [
      "self"
    ],
    "decoder_args": [
      "self"
    ],
    "criterion_cfg": [
      "self"
    ],
    "input_from": [
      "self"
    ],
    "input_layer": [
      "self"
    ],
    "loss_weight_schedule": [
      "self"
    ],
    "get_loss_weight": [
      "self",
      "num_updates"
    ]
  },
  "S2TJointDataConfig": {
    "src_vocab_filename": [
      "self"
    ],
    "src_pre_tokenizer": [
      "self"
    ],
    "src_bpe_tokenizer": [
      "self"
    ],
    "prepend_tgt_lang_tag_no_change": [
      "self"
    ],
    "sampling_text_alpha": [
      "self"
    ]
  },
  "SpeechToTextJointDatasetItem": {},
  "SpeechToTextJointDataset": {
    "__init__": [
      "self",
      "split",
      "is_train_split",
      "cfg",
      "audio_paths",
      "n_frames",
      "src_texts",
      "tgt_texts",
      "speakers",
      "src_langs",
      "tgt_langs",
      "ids",
      "tgt_dict",
      "src_dict",
      "pre_tokenizer",
      "bpe_tokenizer",
      "src_pre_tokenizer",
      "src_bpe_tokenizer",
      "append_eos",
      "alignment",
      "use_src_lang_id"
    ],
    "get_tokenized_src_text": [
      "self",
      "index"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "SpeechToTextJointDatasetCreator": {
    "KEY_ALIGN": [],
    "_from_list": [
      "cls",
      "split_name",
      "is_train_split",
      "samples",
      "cfg",
      "tgt_dict",
      "src_dict",
      "pre_tokenizer",
      "bpe_tokenizer",
      "src_pre_tokenizer",
      "src_bpe_tokenizer",
      "append_eos",
      "use_src_lang_id"
    ],
    "_from_tsv": [
      "cls",
      "root",
      "cfg",
      "split",
      "tgt_dict",
      "src_dict",
      "is_train_split",
      "pre_tokenizer",
      "bpe_tokenizer",
      "src_pre_tokenizer",
      "src_bpe_tokenizer",
      "append_eos",
      "use_src_lang_id"
    ],
    "from_tsv": [
      "cls",
      "root",
      "cfg",
      "splits",
      "tgt_dict",
      "src_dict",
      "pre_tokenizer",
      "bpe_tokenizer",
      "src_pre_tokenizer",
      "src_bpe_tokenizer",
      "is_train_split",
      "epoch",
      "seed",
      "append_eos",
      "use_src_lang_id"
    ]
  },
  "ModalityDatasetItem": {},
  "MultiModalityDataset": {
    "__init__": [
      "self",
      "datasets"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "size": [
      "self",
      "index"
    ],
    "sizes": [
      "self"
    ],
    "ordered_indices": [
      "self"
    ],
    "get_raw_batch_samplers": [
      "self",
      "required_batch_size_multiple",
      "seed"
    ],
    "get_batch_samplers": [
      "self",
      "mult_ratios",
      "required_batch_size_multiple",
      "seed"
    ]
  },
  "LangPairMaskDataset": {
    "__init__": [
      "self",
      "dataset",
      "src_eos",
      "src_bos",
      "noise_id",
      "mask_ratio",
      "mask_type"
    ],
    "src_sizes": [
      "self"
    ],
    "tgt_sizes": [
      "self"
    ],
    "sizes": [
      "self"
    ],
    "get_batch_shapes": [
      "self"
    ],
    "num_tokens_vec": [
      "self",
      "indices"
    ],
    "__len__": [
      "self"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ],
    "mask_src_tokens": [
      "self",
      "sample"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collater": [
      "self",
      "samples",
      "pad_to_length"
    ]
  },
  "FileAudioDatasetWrapper": {
    "collater": [
      "self",
      "samples"
    ]
  },
  "TextToSpeechDatasetItem": {},
  "TextToSpeechDataset": {
    "__init__": [
      "self",
      "split",
      "is_train_split",
      "cfg",
      "audio_paths",
      "n_frames",
      "src_texts",
      "tgt_texts",
      "speakers",
      "src_langs",
      "tgt_langs",
      "ids",
      "tgt_dict",
      "pre_tokenizer",
      "bpe_tokenizer",
      "n_frames_per_step",
      "speaker_to_id",
      "durations",
      "pitches",
      "energies"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "TextToSpeechDatasetCreator": {
    "KEY_DURATION": [],
    "KEY_PITCH": [],
    "KEY_ENERGY": [],
    "_from_list": [
      "cls",
      "split_name",
      "is_train_split",
      "samples",
      "cfg",
      "tgt_dict",
      "pre_tokenizer",
      "bpe_tokenizer",
      "n_frames_per_step",
      "speaker_to_id"
    ]
  },
  "_collate_frames": [
    "frames",
    "is_audio_input"
  ],
  "SpeechToTextDatasetItem": {},
  "SpeechToTextDataset": {
    "LANG_TAG_TEMPLATE": [],
    "__init__": [
      "self",
      "split",
      "is_train_split",
      "cfg",
      "audio_paths",
      "n_frames",
      "src_texts",
      "tgt_texts",
      "speakers",
      "src_langs",
      "tgt_langs",
      "ids",
      "tgt_dict",
      "pre_tokenizer",
      "bpe_tokenizer",
      "n_frames_per_step",
      "speaker_to_id",
      "append_eos"
    ],
    "get_tgt_lens_and_check_oov": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "is_lang_tag": [
      "cls",
      "token"
    ],
    "check_tgt_lang_tag": [
      "self"
    ],
    "tokenize": [
      "cls",
      "tokenizer",
      "text"
    ],
    "get_tokenized_tgt_text": [
      "self",
      "index"
    ],
    "pack_frames": [
      "self",
      "feature"
    ],
    "get_lang_tag_idx": [
      "cls",
      "lang",
      "dictionary"
    ],
    "_get_source_audio": [
      "self",
      "index"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples",
      "return_order"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "sizes": [
      "self"
    ],
    "can_reuse_epoch_itr_across_epochs": [
      "self"
    ],
    "ordered_indices": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ]
  },
  "SpeechToTextDatasetCreator": {
    "KEY_TGT_TEXT": [],
    "DEFAULT_SPEAKER": [],
    "DEFAULT_SRC_TEXT": [],
    "DEFAULT_LANG": [],
    "_from_list": [
      "cls",
      "split_name",
      "is_train_split",
      "samples",
      "cfg",
      "tgt_dict",
      "pre_tokenizer",
      "bpe_tokenizer",
      "n_frames_per_step",
      "speaker_to_id"
    ],
    "get_size_ratios": [
      "cls",
      "datasets",
      "alpha"
    ],
    "_load_samples_from_tsv": [
      "cls",
      "root",
      "split"
    ],
    "_from_tsv": [
      "cls",
      "root",
      "cfg",
      "split",
      "tgt_dict",
      "is_train_split",
      "pre_tokenizer",
      "bpe_tokenizer",
      "n_frames_per_step",
      "speaker_to_id"
    ],
    "from_tsv": [
      "cls",
      "root",
      "cfg",
      "splits",
      "tgt_dict",
      "pre_tokenizer",
      "bpe_tokenizer",
      "is_train_split",
      "epoch",
      "seed",
      "n_frames_per_step",
      "speaker_to_id"
    ]
  },
  "FrmTextToSpeechDataset": {
    "__init__": [
      "self",
      "split",
      "is_train_split",
      "data_cfg",
      "audio_paths",
      "n_frames",
      "src_texts",
      "tgt_texts",
      "speakers",
      "src_langs",
      "tgt_langs",
      "ids",
      "tgt_dict",
      "pre_tokenizer",
      "bpe_tokenizer",
      "n_frames_per_step",
      "speaker_to_id",
      "do_chunk",
      "chunk_bound",
      "chunk_init",
      "chunk_incr",
      "add_eos",
      "dedup",
      "ref_fpu"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "FrmTextToSpeechDatasetCreator": {
    "from_tsv": [
      "cls",
      "root",
      "data_cfg",
      "split",
      "tgt_dict",
      "pre_tokenizer",
      "bpe_tokenizer",
      "is_train_split",
      "n_frames_per_step",
      "speaker_to_id",
      "do_chunk",
      "chunk_bound",
      "chunk_init",
      "chunk_incr",
      "add_eos",
      "dedup",
      "ref_fpu"
    ]
  },
  "DeltaDeltas": {
    "from_config_dict": [
      "cls",
      "config"
    ],
    "__init__": [
      "self",
      "win_length"
    ],
    "__repr__": [
      "self"
    ],
    "__call__": [
      "self",
      "spectrogram"
    ]
  },
  "SpecAugmentTransform": {
    "from_config_dict": [
      "cls",
      "config"
    ],
    "__init__": [
      "self",
      "time_warp_w",
      "freq_mask_n",
      "freq_mask_f",
      "time_mask_n",
      "time_mask_t",
      "time_mask_p",
      "mask_value"
    ],
    "__repr__": [
      "self"
    ],
    "__call__": [
      "self",
      "spectrogram"
    ]
  },
  "AudioFeatureTransform": {
    "from_config_dict": [
      "cls",
      "config"
    ]
  },
  "AUDIO_FEATURE_TRANSFORM_REGISTRY": [],
  "AUDIO_FEATURE_TRANSFORM_CLASS_NAMES": [],
  "register_audio_feature_transform": [
    "name"
  ],
  "get_audio_feature_transform": [
    "name"
  ],
  "transforms_dir": [],
  "CompositeAudioFeatureTransform": {
    "from_config_dict": [
      "cls",
      "config"
    ],
    "__init__": [
      "self",
      "transforms"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "__repr__": [
      "self"
    ]
  },
  "UtteranceCMVN": {
    "from_config_dict": [
      "cls",
      "config"
    ],
    "__init__": [
      "self",
      "norm_means",
      "norm_vars"
    ],
    "__repr__": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "GlobalCMVN": {
    "from_config_dict": [
      "cls",
      "config"
    ],
    "__init__": [
      "self",
      "stats_npz_path"
    ],
    "__repr__": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "MaskedLMDictionary": {
    "__init__": [
      "self",
      "pad",
      "eos",
      "unk",
      "mask"
    ],
    "mask": [
      "self"
    ]
  },
  "BertDictionary": {
    "__init__": [
      "self",
      "pad",
      "eos",
      "unk",
      "mask",
      "cls",
      "sep"
    ],
    "cls": [
      "self"
    ],
    "sep": [
      "self"
    ]
  },
  "MaskedLMDataset": {
    "__init__": [
      "self",
      "dataset",
      "sizes",
      "vocab",
      "pad_idx",
      "mask_idx",
      "classif_token_idx",
      "sep_token_idx",
      "seed",
      "shuffle",
      "has_pairs",
      "segment_id",
      "masking_ratio",
      "masking_prob",
      "random_token_prob"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "_mask_block": [
      "self",
      "sentence",
      "mask_idx",
      "pad_idx",
      "dictionary_token_range"
    ],
    "_collate": [
      "self",
      "samples",
      "pad_idx",
      "eos_idx"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ]
  },
  "BlockPairDataset": {
    "__init__": [
      "self",
      "dataset",
      "dictionary",
      "sizes",
      "block_size",
      "break_mode",
      "short_seq_prob",
      "doc_break_size"
    ],
    "_pair_sentences": [
      "self",
      "dataset_index"
    ],
    "_sent_to_dataset_index": [
      "self",
      "sent_sizes"
    ],
    "_generate_sentence_pair": [
      "self",
      "doc",
      "doc_id",
      "max_num_tokens",
      "sizes"
    ],
    "_skip_sampling": [
      "self",
      "total",
      "skip_ids"
    ],
    "_truncate_sentences": [
      "self",
      "sent_a",
      "sent_b",
      "max_num_tokens"
    ],
    "_cut_sentence": [
      "self",
      "sent",
      "front_cut",
      "end_cut"
    ],
    "_fetch_block": [
      "self",
      "start_ds_idx",
      "offset",
      "end_ds_idx",
      "length"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ]
  },
  "EncoderLangtok": {
    "src": [],
    "tgt": []
  },
  "LangTokSpec": {
    "main": [],
    "mono_dae": []
  },
  "LangTokStyle": {
    "multilingual": [],
    "mbart": []
  },
  "get_lang_tok": [
    "lang",
    "lang_tok_style",
    "spec"
  ],
  "augment_dictionary": [
    "dictionary",
    "language_list",
    "lang_tok_style",
    "langtoks_specs",
    "extra_data"
  ],
  "SRC_DICT_NAME": [],
  "TGT_DICT_NAME": [],
  "_lang_id": [
    "dic",
    "lang"
  ],
  "load_sampling_weights": [
    "from_file"
  ],
  "MultilingualDatasetManager": {
    "__init__": [
      "self",
      "args",
      "lang_pairs",
      "langs",
      "dicts",
      "sampling_method"
    ],
    "setup_data_manager": [
      "cls",
      "args",
      "lang_pairs",
      "langs",
      "dicts",
      "sampling_method"
    ],
    "add_args": [
      "parser"
    ],
    "load_langs": [
      "cls",
      "args"
    ],
    "has_sharded_data": [
      "self",
      "split"
    ],
    "_shared_collater": [
      "self"
    ],
    "estimate_global_pass_epoch": [
      "self",
      "epoch"
    ],
    "prepare": [
      "cls",
      "load_dictionary",
      "args"
    ],
    "load_all_dictionaries": [
      "cls",
      "args",
      "language_list",
      "load_dictionary",
      "training"
    ],
    "get_source_dictionary": [
      "self",
      "lang"
    ],
    "get_target_dictionary": [
      "self",
      "lang"
    ],
    "create_lang_dictionary": [
      "cls",
      "langs"
    ],
    "get_langtok_index": [
      "cls",
      "lang_tok",
      "dic"
    ],
    "get_encoder_langtok": [
      "self",
      "src_lang",
      "tgt_lang",
      "spec"
    ],
    "get_decoder_langtok": [
      "self",
      "tgt_lang",
      "spec"
    ],
    "load_data": [
      "cls",
      "path",
      "vdict",
      "impl"
    ],
    "split_exists": [
      "cls",
      "split",
      "src",
      "tgt",
      "lang",
      "data_path",
      "dataset_impl"
    ],
    "load_lang_dataset": [
      "self",
      "data_path",
      "split",
      "src",
      "src_dict",
      "tgt",
      "tgt_dict",
      "combine",
      "dataset_impl",
      "upsample_primary",
      "max_source_positions",
      "prepend_bos",
      "load_alignments",
      "truncate_source"
    ],
    "load_langpair_dataset": [
      "self",
      "data_path",
      "split",
      "src",
      "src_dict",
      "tgt",
      "tgt_dict",
      "combine",
      "dataset_impl",
      "upsample_primary",
      "left_pad_source",
      "left_pad_target",
      "max_source_positions",
      "max_target_positions",
      "prepend_bos",
      "load_alignments",
      "truncate_source",
      "src_dataset_transform_func",
      "tgt_dataset_transform_func",
      "src_lang_id",
      "tgt_lang_id",
      "langpairs_sharing_datasets"
    ],
    "src_dataset_tranform_func": [
      "self",
      "src_lang",
      "tgt_lang",
      "dataset",
      "spec"
    ],
    "tgt_dataset_tranform_func": [
      "self",
      "source_lang",
      "target_lang",
      "dataset",
      "spec"
    ],
    "alter_dataset_langtok": [
      "self",
      "lang_pair_dataset",
      "src_eos",
      "src_lang",
      "tgt_eos",
      "tgt_lang",
      "src_langtok_spec",
      "tgt_langtok_spec"
    ],
    "load_a_dataset": [
      "self",
      "split",
      "data_path",
      "src",
      "src_dict",
      "tgt",
      "tgt_dict",
      "combine",
      "prepend_bos",
      "langpairs_sharing_datasets",
      "data_category"
    ],
    "load_split_langpair_datasets": [
      "self",
      "split",
      "data_param_list"
    ],
    "get_data_paths_and_lang_pairs": [
      "self",
      "split"
    ],
    "get_dataset_key": [
      "cls",
      "data_category",
      "src",
      "tgt"
    ],
    "_get_shard_num_dict": [
      "cls",
      "split",
      "paths"
    ],
    "get_split_num_data_shards": [
      "self",
      "split"
    ],
    "get_shard_id": [
      "cls",
      "num_shards",
      "epoch",
      "shard_epoch"
    ],
    "get_split_data_path": [
      "self",
      "paths",
      "epoch",
      "shard_epoch",
      "num_shards"
    ],
    "get_split_data_param_list": [
      "self",
      "split",
      "epoch",
      "shard_epoch"
    ],
    "get_train_dataset_sizes": [
      "self",
      "data_param_list",
      "datasets",
      "epoch",
      "shard_epoch"
    ],
    "get_train_sampling_ratios": [
      "self",
      "data_param_list",
      "datasets",
      "epoch",
      "shard_epoch"
    ],
    "get_sampling_ratios": [
      "self",
      "data_param_list",
      "datasets",
      "epoch",
      "shard_epoch"
    ],
    "load_split_datasets": [
      "self",
      "split",
      "training",
      "epoch",
      "combine",
      "shard_epoch"
    ],
    "load_into_concat_dataset": [
      "self",
      "split",
      "datasets",
      "data_param_list"
    ],
    "load_sampled_multi_epoch_dataset": [
      "self",
      "split",
      "training",
      "epoch",
      "combine",
      "shard_epoch"
    ],
    "load_sampled_multi_dataset": [
      "self",
      "split",
      "training",
      "epoch",
      "combine",
      "shard_epoch"
    ],
    "load_dataset": [
      "self",
      "split",
      "training",
      "epoch",
      "combine",
      "shard_epoch"
    ]
  },
  "get_time_gap": [
    "s",
    "e"
  ],
  "default_virtual_size_func": [
    "datasets",
    "ratios",
    "max_scale_up"
  ],
  "CollateFormat": {
    "single": [],
    "ordered_dict": []
  },
  "SampledMultiDataset": {
    "__init__": [
      "self",
      "datasets",
      "sampling_ratios",
      "seed",
      "epoch",
      "eval_key",
      "collate_format",
      "virtual_size",
      "split",
      "shared_collater",
      "shuffle"
    ],
    "_clean_if_not_none": [
      "self",
      "var_list"
    ],
    "_reset_cached_properties": [
      "self"
    ],
    "setup_sampling": [
      "self",
      "sample_ratios",
      "virtual_size"
    ],
    "adjust_sampling": [
      "self",
      "epoch",
      "sampling_ratios",
      "virtual_size"
    ],
    "_sync_sample_ratios": [
      "self",
      "ratios"
    ],
    "random_choice_in_dataset": [
      "self",
      "rng",
      "dataset",
      "choice_size"
    ],
    "get_virtual_indices": [
      "self",
      "rng",
      "datasets",
      "sample_ratios",
      "virtual_size"
    ],
    "_get_dataset_and_index": [
      "self",
      "index"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "num_tokens_vec": [
      "self",
      "indices"
    ],
    "size": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "sizes": [
      "self"
    ],
    "ordered_indices": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ],
    "can_reuse_epoch_itr_across_epochs": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "_establish_virtual_datasets": [
      "self"
    ],
    "filter_indices_by_size": [
      "self",
      "indices",
      "max_sizes"
    ]
  },
  "SampledMultiEpochDataset": {
    "__init__": [
      "self",
      "datasets",
      "sampling_ratios",
      "seed",
      "epoch",
      "eval_key",
      "collate_format",
      "virtual_size",
      "split",
      "virtual_epoch_size",
      "shared_collater",
      "shard_epoch",
      "shuffle"
    ],
    "_setup": [
      "self",
      "epoch"
    ],
    "_map_epoch_index_to_global": [
      "self",
      "index"
    ],
    "sizes": [
      "self"
    ],
    "_get_dataset_and_index": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "_get_epoch_start_index": [
      "self",
      "epoch"
    ],
    "_next_global_indices": [
      "self",
      "epoch"
    ],
    "_next_virtual_epoch": [
      "self",
      "epoch"
    ]
  },
  "uniform": [
    "dataset_sizes"
  ],
  "temperature_sampling": [
    "dataset_sizes",
    "temp"
  ],
  "make_temperature_sampling": [
    "temp"
  ],
  "make_ratio_sampling": [
    "ratios"
  ],
  "SamplingMethod": {
    "add_arguments": [
      "parser"
    ],
    "build_sampler": [
      "args",
      "task"
    ],
    "__init__": [
      "self",
      "args",
      "task"
    ],
    "is_adaptive": [
      "self"
    ],
    "sampling_method_selector": [
      "self"
    ]
  },
  "get_fused_adam_class": [],
  "FusedAdamV1": {
    "__init__": [
      "self",
      "params",
      "lr",
      "bias_correction",
      "betas",
      "eps",
      "eps_inside_sqrt",
      "weight_decay",
      "max_grad_norm",
      "amsgrad",
      "use_fp16_stats"
    ],
    "supports_memory_efficient_fp16": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ],
    "supports_step_with_scale": [
      "self"
    ],
    "step": [
      "self",
      "closure",
      "grads",
      "scale",
      "grad_norms"
    ]
  },
  "Adadelta": {
    "__init__": [
      "self",
      "args",
      "params"
    ],
    "add_args": [
      "parser"
    ],
    "optimizer_config": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ]
  },
  "FairseqAdamConfig": {},
  "FairseqAdam": {
    "__init__": [
      "self",
      "cfg",
      "params"
    ],
    "optimizer_config": [
      "self"
    ],
    "average_params": [
      "self"
    ]
  },
  "Adam": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad"
    ],
    "supports_memory_efficient_fp16": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "FairseqAdamax": {
    "__init__": [
      "self",
      "args",
      "params"
    ],
    "add_args": [
      "parser"
    ],
    "optimizer_config": [
      "self"
    ]
  },
  "Adamax": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "bias_correction"
    ],
    "supports_memory_efficient_fp16": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "shard_": [
    "optimizer",
    "group"
  ],
  "DynamicLossScaler": {
    "__init__": [
      "self",
      "init_scale",
      "scale_factor",
      "scale_window",
      "tolerance",
      "threshold",
      "min_loss_scale"
    ],
    "scale": [
      "self",
      "outputs"
    ],
    "update": [
      "self"
    ],
    "_decrease_loss_scale": [
      "self"
    ],
    "check_overflow": [
      "self",
      "grad_norm"
    ]
  },
  "SGD": {
    "__init__": [
      "self",
      "args",
      "params"
    ],
    "add_args": [
      "parser"
    ],
    "optimizer_config": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ]
  },
  "AMPOptimizer": {
    "__init__": [
      "self",
      "cfg",
      "params",
      "fp32_optimizer"
    ],
    "build_optimizer": [
      "cls",
      "cfg",
      "params"
    ],
    "backward": [
      "self",
      "loss"
    ],
    "step": [
      "self"
    ],
    "clip_grad_norm": [
      "self",
      "max_norm",
      "aggregate_norm_fn"
    ],
    "scaler": [
      "self"
    ],
    "next_loss_scale": [
      "self"
    ],
    "optimizer": [
      "self",
      "optimizer"
    ],
    "lr_scheduler": [
      "self"
    ],
    "optimizer_config": [
      "self"
    ],
    "get_lr": [
      "self"
    ],
    "set_lr": [
      "self",
      "lr"
    ],
    "all_reduce_grads": [
      "self",
      "module"
    ],
    "supports_flat_params": [
      "self"
    ]
  },
  "build_optimizer": [
    "cfg",
    "params"
  ],
  "FairseqAdafactor": {
    "__init__": [
      "self",
      "args",
      "params"
    ],
    "add_args": [
      "parser"
    ],
    "optimizer_config": [
      "self"
    ]
  },
  "Adafactor": {
    "__init__": [
      "self",
      "params",
      "lr",
      "eps",
      "clip_threshold",
      "decay_rate",
      "beta1",
      "weight_decay",
      "scale_parameter",
      "relative_step",
      "warmup_init"
    ],
    "supports_memory_efficient_fp16": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ],
    "_get_lr": [
      "self",
      "param_group",
      "param_state"
    ],
    "_get_options": [
      "self",
      "param_group",
      "param_shape"
    ],
    "_rms": [
      "self",
      "tensor"
    ],
    "_approx_sq_grad": [
      "self",
      "exp_avg_sq_row",
      "exp_avg_sq_col"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "_get_cpu_adam": [],
  "FairseqCPUAdamConfig": {},
  "FairseqCPUAdam": {
    "__init__": [
      "self",
      "cfg",
      "params"
    ],
    "optimizer_config": [
      "self"
    ]
  },
  "CPUAdam": {
    "optimizer_id": [],
    "__init__": [
      "self",
      "params",
      "lr",
      "bias_correction",
      "betas",
      "eps",
      "weight_decay",
      "use_fp16_stats"
    ],
    "supports_memory_efficient_fp16": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "FairseqNAGConfig": {},
  "FairseqNAG": {
    "__init__": [
      "self",
      "cfg",
      "params"
    ],
    "optimizer_config": [
      "self"
    ]
  },
  "NAG": {
    "__init__": [
      "self",
      "params",
      "lr",
      "momentum",
      "weight_decay"
    ],
    "supports_memory_efficient_fp16": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "FairseqOptimizer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "add_args": [
      "cls",
      "parser"
    ],
    "optimizer": [
      "self",
      "optimizer"
    ],
    "optimizer_config": [
      "self"
    ],
    "params": [
      "self"
    ],
    "param_groups": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "get_lr": [
      "self"
    ],
    "set_lr": [
      "self",
      "lr"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "optimizer_overrides"
    ],
    "backward": [
      "self",
      "loss"
    ],
    "all_reduce_grads": [
      "self",
      "module"
    ],
    "multiply_grads": [
      "self",
      "c"
    ],
    "clip_grad_norm": [
      "self",
      "max_norm",
      "aggregate_norm_fn"
    ],
    "step": [
      "self",
      "closure",
      "scale",
      "groups"
    ],
    "zero_grad": [
      "self"
    ],
    "supports_memory_efficient_fp16": [
      "self"
    ],
    "supports_step_with_scale": [
      "self"
    ],
    "supports_groups": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ],
    "average_params": [
      "self"
    ],
    "broadcast_global_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "LegacyFairseqOptimizer": {
    "__init__": [
      "self",
      "args"
    ]
  },
  "Adagrad": {
    "__init__": [
      "self",
      "args",
      "params"
    ],
    "add_args": [
      "parser"
    ],
    "optimizer_config": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ]
  },
  "OptimizerAndSchedulerConfig": {},
  "CompositeOptimizerConfig": {},
  "FairseqCompositeOptimizer": {
    "__init__": [
      "self",
      "cfg",
      "params"
    ],
    "supports_groups": [
      "self"
    ],
    "param_groups": [
      "self"
    ],
    "get_lr": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "optimizer_overrides"
    ]
  },
  "CompositeOptimizer": {
    "__init__": [
      "self",
      "optimizers"
    ],
    "supports_memory_efficient_fp16": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ],
    "step": [
      "self",
      "closure",
      "groups"
    ],
    "zero_grad": [
      "self"
    ]
  },
  "CompositeLRScheduler": {
    "__init__": [
      "self",
      "lr_schedulers"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "step_begin_epoch": [
      "self",
      "epoch"
    ],
    "step": [
      "self",
      "epoch",
      "val_loss"
    ],
    "step_update": [
      "self",
      "num_updates"
    ]
  },
  "FairseqLAMB": {
    "__init__": [
      "self",
      "args",
      "params"
    ],
    "add_args": [
      "parser"
    ],
    "optimizer_config": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ]
  },
  "FairseqBMUF": {
    "__init__": [
      "self",
      "cfg",
      "optimizer"
    ],
    "add_args": [
      "parser"
    ],
    "optimizer": [
      "self"
    ],
    "optimizer_config": [
      "self"
    ],
    "get_lr": [
      "self"
    ],
    "set_lr": [
      "self",
      "lr"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "optimizer_overrides"
    ],
    "multiply_grads": [
      "self",
      "c"
    ],
    "clip_grad_norm": [
      "self",
      "max_norm",
      "aggregate_norm_fn"
    ],
    "average_params": [
      "self"
    ],
    "_block_sync": [
      "self"
    ],
    "_is_warmup_end": [
      "self"
    ],
    "_is_bmuf_iter": [
      "self"
    ],
    "_warmup_sync": [
      "self",
      "root_rank"
    ],
    "step": [
      "self",
      "closure"
    ],
    "zero_grad": [
      "self"
    ],
    "get_num_updates": [
      "self"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "_reset_local_data": [
      "self"
    ],
    "_calc_grad": [
      "self"
    ],
    "_avg_grad_from_all_gpus": [
      "self"
    ],
    "_update_global_model": [
      "self"
    ]
  },
  "_FP16OptimizerMixin": {
    "__init__": [
      "self"
    ],
    "has_flat_params": [
      "self"
    ],
    "build_fp32_params": [
      "cls",
      "args",
      "params",
      "flatten"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "optimizer_overrides"
    ],
    "backward": [
      "self",
      "loss"
    ],
    "_sync_fp16_grads_to_fp32": [
      "self"
    ],
    "_sync_fp32_params_to_fp16": [
      "self"
    ],
    "_unscale_grads": [
      "self"
    ],
    "multiply_grads": [
      "self",
      "c"
    ],
    "clip_grad_norm": [
      "self",
      "max_norm",
      "aggregate_norm_fn"
    ],
    "step": [
      "self",
      "closure",
      "groups"
    ],
    "zero_grad": [
      "self"
    ]
  },
  "FP16Optimizer": {
    "__init__": [
      "self",
      "cfg",
      "params",
      "fp32_optimizer",
      "fp32_params"
    ],
    "build_optimizer": [
      "cls",
      "cfg",
      "params"
    ],
    "optimizer": [
      "self",
      "optimizer"
    ],
    "lr_scheduler": [
      "self"
    ],
    "optimizer_config": [
      "self"
    ],
    "get_lr": [
      "self"
    ],
    "set_lr": [
      "self",
      "lr"
    ],
    "all_reduce_grads": [
      "self",
      "module"
    ],
    "supports_flat_params": [
      "self"
    ]
  },
  "_MemoryEfficientFP16OptimizerMixin": {
    "__init__": [
      "self"
    ],
    "has_flat_params": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "optimizer_overrides"
    ],
    "backward": [
      "self",
      "loss"
    ],
    "_unscale_grads": [
      "self"
    ],
    "multiply_grads": [
      "self",
      "c"
    ],
    "clip_grad_norm": [
      "self",
      "max_norm",
      "aggregate_norm_fn"
    ],
    "step": [
      "self",
      "closure",
      "groups"
    ],
    "zero_grad": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ]
  },
  "MemoryEfficientFP16Optimizer": {
    "__init__": [
      "self",
      "cfg",
      "params",
      "optimizer",
      "allow_unsupported"
    ],
    "build_optimizer": [
      "cls",
      "cfg",
      "params"
    ],
    "optimizer": [
      "self",
      "optimizer"
    ],
    "optimizer_config": [
      "self"
    ],
    "lr_scheduler": [
      "self"
    ],
    "get_lr": [
      "self"
    ],
    "set_lr": [
      "self",
      "lr"
    ],
    "all_reduce_grads": [
      "self",
      "module"
    ]
  },
  "ManualSchedule": {
    "__init__": [
      "self",
      "args",
      "optimizer"
    ],
    "parse_manuallr_args": [
      "self",
      "lr_args_str"
    ],
    "add_args": [
      "parser"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "get_next_lr": [
      "self",
      "epoch"
    ],
    "step_begin_epoch": [
      "self",
      "epoch"
    ],
    "step_update": [
      "self",
      "num_updates"
    ]
  },
  "InverseSquareRootLRScheduleConfig": {},
  "InverseSquareRootSchedule": {
    "__init__": [
      "self",
      "cfg",
      "optimizer"
    ],
    "step": [
      "self",
      "epoch",
      "val_loss"
    ],
    "step_update": [
      "self",
      "num_updates"
    ]
  },
  "PolynomialDecayLRScheduleConfig": {},
  "PolynomialDecayLRSchedule": {
    "__init__": [
      "self",
      "cfg",
      "optimizer"
    ],
    "get_next_lr": [
      "self",
      "epoch"
    ],
    "step_begin_epoch": [
      "self",
      "epoch"
    ],
    "step_update": [
      "self",
      "num_updates"
    ]
  },
  "TriStageLRScheduleConfig": {},
  "TriStageLRSchedule": {
    "__init__": [
      "self",
      "cfg",
      "optimizer"
    ],
    "_decide_stage": [
      "self",
      "update_step"
    ],
    "step": [
      "self",
      "epoch",
      "val_loss"
    ],
    "step_update": [
      "self",
      "num_updates"
    ]
  },
  "build_lr_scheduler": [
    "cfg",
    "optimizer"
  ],
  "CosineLRScheduleConfig": {},
  "CosineLRSchedule": {
    "__init__": [
      "self",
      "cfg",
      "fairseq_optimizer"
    ],
    "step": [
      "self",
      "epoch",
      "val_loss"
    ],
    "step_update": [
      "self",
      "num_updates"
    ]
  },
  "TriangularLRScheduleConfig": {},
  "TriangularLRSchedule": {
    "__init__": [
      "self",
      "cfg",
      "optimizer"
    ],
    "step": [
      "self",
      "epoch",
      "val_loss"
    ],
    "step_update": [
      "self",
      "num_updates"
    ]
  },
  "FixedLRScheduleConfig": {},
  "FixedLRSchedule": {
    "__init__": [
      "self",
      "cfg",
      "optimizer"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "get_next_lr": [
      "self",
      "epoch"
    ],
    "step_begin_epoch": [
      "self",
      "epoch"
    ],
    "step_update": [
      "self",
      "num_updates"
    ]
  },
  "FairseqLRScheduler": {
    "__init__": [
      "self",
      "cfg",
      "optimizer"
    ],
    "add_args": [
      "cls",
      "parser"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "step_begin_epoch": [
      "self",
      "epoch"
    ],
    "step": [
      "self",
      "epoch",
      "val_loss"
    ],
    "step_update": [
      "self",
      "num_updates"
    ]
  },
  "LegacyFairseqLRScheduler": {
    "__init__": [
      "self",
      "args",
      "optimizer"
    ]
  },
  "ReduceLROnPlateauLRScheduleConfig": {},
  "ReduceLROnPlateauLRSchedule": {
    "__init__": [
      "self",
      "cfg",
      "optimizer"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "step": [
      "self",
      "epoch",
      "val_loss"
    ],
    "step_update": [
      "self",
      "num_updates"
    ]
  },
  "StepLRScheduleConfig": {},
  "StepLRSchedule": {
    "__init__": [
      "self",
      "cfg",
      "fairseq_optimizer"
    ],
    "step": [
      "self",
      "epoch",
      "val_loss"
    ],
    "step_update": [
      "self",
      "num_updates"
    ]
  },
  "PassThroughScheduleConfig": {},
  "PassThroughScheduleSchedule": {
    "__init__": [
      "self",
      "cfg",
      "optimizer"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "step_begin_epoch": [
      "self",
      "epoch"
    ],
    "step_update": [
      "self",
      "num_updates"
    ]
  },
  "progress_bar": [
    "iterator",
    "log_format",
    "log_interval",
    "log_file",
    "epoch",
    "prefix",
    "aim_repo",
    "aim_run_hash",
    "aim_param_checkpoint_dir",
    "tensorboard_logdir",
    "default_log_format",
    "wandb_project",
    "wandb_run_name",
    "azureml_logging"
  ],
  "build_progress_bar": [
    "args",
    "iterator",
    "epoch",
    "prefix",
    "default",
    "no_progress_bar"
  ],
  "format_stat": [
    "stat"
  ],
  "BaseProgressBar": {
    "__init__": [
      "self",
      "iterable",
      "epoch",
      "prefix"
    ],
    "__len__": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "log": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "print": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "update_config": [
      "self",
      "config"
    ],
    "_str_commas": [
      "self",
      "stats"
    ],
    "_str_pipes": [
      "self",
      "stats"
    ],
    "_format_stats": [
      "self",
      "stats"
    ]
  },
  "rename_logger": [
    "logger",
    "new_name"
  ],
  "JsonProgressBar": {
    "__init__": [
      "self",
      "iterable",
      "epoch",
      "prefix",
      "log_interval"
    ],
    "__iter__": [
      "self"
    ],
    "log": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "print": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "_format_stats": [
      "self",
      "stats",
      "epoch",
      "update"
    ]
  },
  "NoopProgressBar": {
    "__init__": [
      "self",
      "iterable",
      "epoch",
      "prefix"
    ],
    "__iter__": [
      "self"
    ],
    "log": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "print": [
      "self",
      "stats",
      "tag",
      "step"
    ]
  },
  "SimpleProgressBar": {
    "__init__": [
      "self",
      "iterable",
      "epoch",
      "prefix",
      "log_interval"
    ],
    "__iter__": [
      "self"
    ],
    "log": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "print": [
      "self",
      "stats",
      "tag",
      "step"
    ]
  },
  "TqdmProgressBar": {
    "__init__": [
      "self",
      "iterable",
      "epoch",
      "prefix"
    ],
    "__iter__": [
      "self"
    ],
    "log": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "print": [
      "self",
      "stats",
      "tag",
      "step"
    ]
  },
  "AimProgressBarWrapper": {
    "__init__": [
      "self",
      "wrapped_bar",
      "aim_repo",
      "aim_run_hash",
      "aim_param_checkpoint_dir"
    ],
    "__iter__": [
      "self"
    ],
    "log": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "print": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "update_config": [
      "self",
      "config"
    ],
    "_log_to_aim": [
      "self",
      "stats",
      "tag",
      "step"
    ]
  },
  "_close_writers": [],
  "TensorboardProgressBarWrapper": {
    "__init__": [
      "self",
      "wrapped_bar",
      "tensorboard_logdir"
    ],
    "_writer": [
      "self",
      "key"
    ],
    "__iter__": [
      "self"
    ],
    "log": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "print": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "update_config": [
      "self",
      "config"
    ],
    "_log_to_tensorboard": [
      "self",
      "stats",
      "tag",
      "step"
    ]
  },
  "WandBProgressBarWrapper": {
    "__init__": [
      "self",
      "wrapped_bar",
      "wandb_project",
      "run_name"
    ],
    "__iter__": [
      "self"
    ],
    "log": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "print": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "update_config": [
      "self",
      "config"
    ],
    "_log_to_wandb": [
      "self",
      "stats",
      "tag",
      "step"
    ]
  },
  "AzureMLProgressBarWrapper": {
    "__init__": [
      "self",
      "wrapped_bar"
    ],
    "__exit__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "log": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "print": [
      "self",
      "stats",
      "tag",
      "step"
    ],
    "update_config": [
      "self",
      "config"
    ],
    "_log_to_azureml": [
      "self",
      "stats",
      "tag",
      "step"
    ]
  },
  "_aggregators": [],
  "_active_aggregators": [],
  "_active_aggregators_cnt": [],
  "reset": [],
  "aggregate": [
    "name",
    "new_root"
  ],
  "get_active_aggregators": [],
  "log_scalar": [
    "key",
    "value",
    "weight",
    "priority",
    "round"
  ],
  "log_scalar_sum": [
    "key",
    "value",
    "priority",
    "round"
  ],
  "log_derived": [
    "key",
    "fn",
    "priority"
  ],
  "log_speed": [
    "key",
    "value",
    "priority",
    "round"
  ],
  "log_start_time": [
    "key",
    "priority",
    "round"
  ],
  "log_stop_time": [
    "key",
    "weight",
    "prehook"
  ],
  "log_custom": [
    "new_meter_fn",
    "key"
  ],
  "reset_meter": [
    "name",
    "key"
  ],
  "reset_meters": [
    "name"
  ],
  "get_meter": [
    "name",
    "key"
  ],
  "get_meters": [
    "name"
  ],
  "get_smoothed_value": [
    "name",
    "key"
  ],
  "get_smoothed_values": [
    "name"
  ],
  "state_dict": [],
  "load_state_dict": [
    "state_dict"
  ],
  "xla_metrics_report": [],
  "Meter": {
    "__init__": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "reset": [
      "self"
    ],
    "smoothed_value": [
      "self"
    ]
  },
  "safe_round": [
    "number",
    "ndigits"
  ],
  "AverageMeter": {
    "__init__": [
      "self",
      "round"
    ],
    "reset": [
      "self"
    ],
    "update": [
      "self",
      "val",
      "n"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "avg": [
      "self"
    ],
    "smoothed_value": [
      "self"
    ]
  },
  "SumMeter": {
    "__init__": [
      "self",
      "round"
    ],
    "reset": [
      "self"
    ],
    "update": [
      "self",
      "val"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "smoothed_value": [
      "self"
    ]
  },
  "TimeMeter": {
    "__init__": [
      "self",
      "init",
      "n",
      "round"
    ],
    "reset": [
      "self",
      "init",
      "n"
    ],
    "update": [
      "self",
      "val"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "avg": [
      "self"
    ],
    "elapsed_time": [
      "self"
    ],
    "smoothed_value": [
      "self"
    ]
  },
  "StopwatchMeter": {
    "__init__": [
      "self",
      "round"
    ],
    "start": [
      "self"
    ],
    "stop": [
      "self",
      "n",
      "prehook"
    ],
    "reset": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "avg": [
      "self"
    ],
    "elapsed_time": [
      "self"
    ],
    "smoothed_value": [
      "self"
    ]
  },
  "MetersDict": {
    "__init__": [
      "self"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "add_meter": [
      "self",
      "key",
      "meter",
      "priority"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "get_smoothed_value": [
      "self",
      "key"
    ],
    "get_smoothed_values": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "CrossLingualLMTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "dictionary"
    ],
    "_lang_to_id": [
      "self",
      "languages"
    ],
    "load_dictionary": [
      "cls",
      "filename"
    ],
    "build_dictionary": [
      "cls",
      "filenames",
      "workers",
      "threshold",
      "nwords",
      "padding_factor"
    ],
    "target_dictionary": [
      "self"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "_load_single_lang_dataset": [
      "self",
      "split",
      "epoch"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ]
  },
  "MultiLingualMaskedLMTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "dictionary"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "_get_whole_word_mask": [
      "self"
    ],
    "_get_sample_prob": [
      "self",
      "dataset_lens"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths",
      "sort"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ]
  },
  "LabelEncoder": {
    "__init__": [
      "self",
      "dictionary"
    ],
    "__call__": [
      "self",
      "label"
    ]
  },
  "HubertPretrainingConfig": {},
  "HubertPretrainingTask": {
    "__init__": [
      "self",
      "cfg"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ],
    "dictionaries": [
      "self"
    ],
    "setup_task": [
      "cls",
      "cfg"
    ],
    "load_dictionaries": [
      "self"
    ],
    "get_label_dir": [
      "self"
    ],
    "load_dataset": [
      "self",
      "split"
    ],
    "max_positions": [
      "self"
    ],
    "filter_indices_by_size": [
      "self",
      "indices"
    ]
  },
  "label_len_fn": [
    "label"
  ],
  "AudioFinetuningConfig": {},
  "AudioFinetuningTask": {
    "__init__": [
      "self",
      "cfg"
    ],
    "load_target_dictionary": [
      "self"
    ],
    "load_dataset": [
      "self",
      "split",
      "task_cfg"
    ],
    "target_dictionary": [
      "self"
    ],
    "valid_step": [
      "self",
      "sample",
      "model",
      "criterion"
    ],
    "build_model": [
      "self",
      "model_cfg",
      "from_checkpoint"
    ],
    "_inference_with_wer": [
      "self",
      "generator",
      "sample",
      "model"
    ],
    "_inference_with_bleu": [
      "self",
      "generator",
      "sample",
      "model"
    ],
    "reduce_metrics": [
      "self",
      "logging_outputs",
      "criterion"
    ]
  },
  "MultilingualDenoisingTask": {
    "add_args": [
      "parser"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "__init__": [
      "self",
      "args",
      "dictionary"
    ],
    "_get_sample_prob": [
      "self",
      "dataset_lens"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ]
  },
  "TranslationMultiSimpleEpochTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "langs",
      "dicts",
      "training"
    ],
    "check_dicts": [
      "self",
      "dicts",
      "source_langs",
      "target_langs"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "has_sharded_data": [
      "self",
      "split"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths",
      "constraints"
    ],
    "build_generator": [
      "self",
      "models",
      "args",
      "seq_gen_cls",
      "extra_gen_cls_kwargs"
    ],
    "build_model": [
      "self",
      "args",
      "from_checkpoint"
    ],
    "valid_step": [
      "self",
      "sample",
      "model",
      "criterion"
    ],
    "inference_step": [
      "self",
      "generator",
      "models",
      "sample",
      "prefix_tokens",
      "constraints"
    ],
    "reduce_metrics": [
      "self",
      "logging_outputs",
      "criterion"
    ],
    "max_positions": [
      "self"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ],
    "create_batch_sampler_func": [
      "self",
      "max_positions",
      "ignore_invalid_inputs",
      "max_tokens",
      "max_sentences",
      "required_batch_size_multiple",
      "seed"
    ],
    "get_batch_iterator": [
      "self",
      "dataset",
      "max_tokens",
      "max_sentences",
      "max_positions",
      "ignore_invalid_inputs",
      "required_batch_size_multiple",
      "seed",
      "num_shards",
      "shard_id",
      "num_workers",
      "epoch",
      "data_buffer_size",
      "disable_iterator_cache",
      "skip_remainder_batch",
      "grouped_shuffling",
      "update_epoch_batch_itr"
    ]
  },
  "MaskedLMConfig": {},
  "MaskedLMTask": {
    "__init__": [
      "self",
      "cfg",
      "dictionary"
    ],
    "setup_task": [
      "cls",
      "cfg"
    ],
    "_load_dataset_split": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths",
      "sort"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ]
  },
  "FrmTextToSpeechTask": {
    "add_args": [
      "parser"
    ],
    "load_dataset": [
      "self",
      "split"
    ]
  },
  "TranslationFromPretrainedXLMConfig": {},
  "TranslationFromPretrainedXLMTask": {
    "load_dictionary": [
      "cls",
      "filename"
    ]
  },
  "DenoisingTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "dictionary"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "max_positions": [
      "self"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ]
  },
  "NOISE_CHOICES": [],
  "TranslationLevenshteinConfig": {},
  "TranslationLevenshteinTask": {
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "inject_noise": [
      "self",
      "target_tokens"
    ],
    "build_generator": [
      "self",
      "models",
      "args"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths",
      "constraints"
    ],
    "train_step": [
      "self",
      "sample",
      "model",
      "criterion",
      "optimizer",
      "update_num",
      "ignore_grad"
    ],
    "valid_step": [
      "self",
      "sample",
      "model",
      "criterion"
    ]
  },
  "SAMPLE_BREAK_MODE_CHOICES": [],
  "SHORTEN_METHOD_CHOICES": [],
  "LanguageModelingConfig": {},
  "LanguageModelingTask": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "output_dictionary",
      "targets"
    ],
    "setup_dictionary": [
      "cls",
      "args"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "build_model": [
      "self",
      "args",
      "from_checkpoint"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "inference_step": [
      "self",
      "generator",
      "models",
      "sample",
      "prefix_tokens",
      "constraints"
    ],
    "eval_lm_dataloader": [
      "self",
      "dataset",
      "max_tokens",
      "batch_size",
      "max_positions",
      "num_shards",
      "shard_id",
      "num_workers",
      "data_buffer_size",
      "context_window"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ]
  },
  "SentencePredictionTask": {
    "__init__": [
      "self",
      "cfg",
      "data_dictionary",
      "label_dictionary"
    ],
    "load_dictionary": [
      "cls",
      "filename"
    ],
    "setup_task": [
      "cls",
      "cfg"
    ],
    "load_dataset": [
      "self",
      "split",
      "combine"
    ],
    "build_model": [
      "self",
      "cfg",
      "from_checkpoint"
    ],
    "max_positions": [
      "self"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ],
    "label_dictionary": [
      "self"
    ]
  },
  "TASK_DATACLASS_REGISTRY": [],
  "TASK_REGISTRY": [],
  "TASK_CLASS_NAMES": [],
  "setup_task": [
    "cfg"
  ],
  "register_task": [
    "name",
    "dataclass"
  ],
  "get_task": [
    "name"
  ],
  "import_tasks": [
    "tasks_dir",
    "namespace"
  ],
  "tasks_dir": [],
  "UnitDictionary": {
    "__init__": [
      "self"
    ],
    "encode_line": [
      "self",
      "line",
      "append_eos",
      "prepend_bos"
    ]
  },
  "SpeechUnitModelingConfig": {},
  "SpeechUnitLanguageModelingTask": {
    "__init__": [
      "self",
      "cfg"
    ],
    "source_dictionary": [
      "self"
    ],
    "source_duration_dictionary": [
      "self"
    ],
    "source_f0_dictionary": [
      "self"
    ],
    "channel_names": [
      "self"
    ],
    "channel_sizes": [
      "self"
    ],
    "dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ],
    "target_duration_dictionary": [
      "self"
    ],
    "target_f0_dictionary": [
      "self"
    ],
    "dictionaries": [
      "self"
    ],
    "setup_task": [
      "cls",
      "cfg"
    ],
    "load_dataset": [
      "self",
      "split"
    ],
    "max_positions": [
      "self"
    ],
    "build_criterion": [
      "self",
      "cfg"
    ]
  },
  "SentencePredictionAdapterTask": {
    "build_model": [
      "self",
      "cfg"
    ]
  },
  "SpeechToTextTask": {
    "add_args": [
      "cls",
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "tgt_dict"
    ],
    "_get_speaker_to_id": [
      "self"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "build_criterion": [
      "self",
      "args"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "target_dictionary": [
      "self"
    ],
    "source_dictionary": [
      "self"
    ],
    "max_positions": [
      "self"
    ],
    "build_model": [
      "self",
      "args",
      "from_checkpoint"
    ],
    "build_generator": [
      "self",
      "models",
      "args",
      "seq_gen_cls",
      "extra_gen_cls_kwargs"
    ],
    "build_tokenizer": [
      "self",
      "args"
    ],
    "build_bpe": [
      "self",
      "args"
    ],
    "get_interactive_tokens_and_lengths": [
      "self",
      "lines",
      "encode_fn"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths"
    ]
  },
  "SentenceRankingTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "dictionary"
    ],
    "load_dictionary": [
      "cls",
      "args",
      "filename",
      "source"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "load_dataset": [
      "self",
      "split",
      "combine"
    ],
    "build_model": [
      "self",
      "args",
      "from_checkpoint"
    ],
    "max_positions": [
      "self"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ]
  },
  "StackUnitSequenceGenerator": {
    "__init__": [
      "self",
      "tgt_dict",
      "vocab_size"
    ],
    "pack_units": [
      "self",
      "input",
      "n_frames_per_step"
    ],
    "generate": [
      "self",
      "models",
      "sample"
    ]
  },
  "SpeechToSpeechTask": {
    "add_args": [
      "cls",
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "tgt_dict",
      "infer_tgt_lang_id"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "build_criterion": [
      "self",
      "args"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "target_dictionary": [
      "self"
    ],
    "source_dictionary": [
      "self"
    ],
    "max_positions": [
      "self"
    ],
    "build_model": [
      "self",
      "args",
      "from_checkpoint"
    ],
    "build_generator": [
      "self",
      "models",
      "args",
      "seq_gen_cls",
      "extra_gen_cls_kwargs"
    ],
    "train_step": [
      "self",
      "sample",
      "model",
      "criterion",
      "optimizer",
      "update_num",
      "ignore_grad"
    ],
    "valid_step": [
      "self",
      "sample",
      "model",
      "criterion"
    ],
    "valid_step_with_inference": [
      "self",
      "sample",
      "model",
      "generator"
    ],
    "inference_step": [
      "self",
      "generator",
      "models",
      "sample",
      "prefix_tokens",
      "constraints"
    ]
  },
  "DummyMultiTask": {
    "__init__": [
      "self",
      "args",
      "tgt_dict"
    ],
    "target_dictionary": [
      "self"
    ],
    "inference_step": [
      "self",
      "generator",
      "models",
      "sample",
      "prefix_tokens",
      "constraints"
    ],
    "build_generator": [
      "self",
      "models",
      "args",
      "seq_gen_cls",
      "extra_gen_cls_kwargs"
    ]
  },
  "_lang_token": [
    "lang"
  ],
  "_lang_token_index": [
    "dic",
    "lang"
  ],
  "MultilingualTranslationTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "dicts",
      "training"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "update_args": [
      "cls",
      "args"
    ],
    "prepare": [
      "cls",
      "args"
    ],
    "get_encoder_langtok": [
      "self",
      "src_lang",
      "tgt_lang"
    ],
    "get_decoder_langtok": [
      "self",
      "tgt_lang"
    ],
    "alter_dataset_langtok": [
      "self",
      "lang_pair_dataset",
      "src_eos",
      "src_lang",
      "tgt_eos",
      "tgt_lang"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths",
      "constraints"
    ],
    "build_model": [
      "self",
      "args",
      "from_checkpoint"
    ],
    "_per_lang_pair_train_loss": [
      "self",
      "lang_pair",
      "model",
      "update_num",
      "criterion",
      "sample",
      "optimizer",
      "ignore_grad"
    ],
    "train_step": [
      "self",
      "sample",
      "model",
      "criterion",
      "optimizer",
      "update_num",
      "ignore_grad"
    ],
    "_per_lang_pair_valid_loss": [
      "self",
      "lang_pair",
      "model",
      "criterion",
      "sample"
    ],
    "valid_step": [
      "self",
      "sample",
      "model",
      "criterion"
    ],
    "inference_step": [
      "self",
      "generator",
      "models",
      "sample",
      "prefix_tokens",
      "constraints"
    ],
    "reduce_metrics": [
      "self",
      "logging_outputs",
      "criterion"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ],
    "max_positions": [
      "self"
    ]
  },
  "lang_token": [
    "lang"
  ],
  "MultilingualLanguageModelingConfig": {},
  "MultilingualLanguageModelingTask": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "output_dictionary",
      "targets"
    ],
    "_get_langs": [
      "args",
      "epoch"
    ],
    "setup_dictionary": [
      "cls",
      "args"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "build_model": [
      "self",
      "args",
      "from_checkpoint"
    ],
    "_get_sample_prob": [
      "self",
      "dataset_lens"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths",
      "language"
    ],
    "inference_step": [
      "self",
      "generator",
      "models",
      "sample",
      "language",
      "prefix_tokens",
      "constraints"
    ],
    "eval_lm_dataloader": [
      "self",
      "dataset",
      "max_tokens",
      "batch_size",
      "max_positions",
      "num_shards",
      "shard_id",
      "num_workers",
      "data_buffer_size",
      "context_window"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ]
  },
  "TranslationFromPretrainedBARTTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "src_dict",
      "tgt_dict"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "build_generator": [
      "self",
      "models",
      "args"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths",
      "constraints"
    ]
  },
  "InferredW2vConfig": {},
  "AudioPretrainingConfig": {},
  "AudioPretrainingTask": {
    "setup_task": [
      "cls",
      "cfg"
    ],
    "_get_mask_precompute_kwargs": [
      "self",
      "cfg"
    ],
    "load_dataset": [
      "self",
      "split",
      "task_cfg"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ],
    "max_positions": [
      "self"
    ],
    "build_model": [
      "self",
      "model_cfg",
      "from_checkpoint"
    ]
  },
  "PiecewiseLinearFn": {
    "__init__": [
      "self",
      "pieces"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "from_string": [
      "configuration"
    ],
    "one": []
  },
  "OnlineBackTranslationTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "common_dict",
      "mono_langs",
      "valid_lang_pairs"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "load_train_dataset": [
      "self",
      "data_path"
    ],
    "_langpair_dataset": [
      "self",
      "src",
      "tgt"
    ],
    "_prepend_lang_bos_to_target": [
      "self",
      "dataset",
      "lang"
    ],
    "load_bt_dataset": [
      "self",
      "data_path",
      "lang"
    ],
    "load_denoise_dataset": [
      "self",
      "data_path",
      "lang"
    ],
    "load_translation_dataset": [
      "self",
      "split",
      "data_path",
      "combine"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths",
      "constraints"
    ],
    "build_model": [
      "self",
      "args",
      "from_checkpoint"
    ],
    "max_positions": [
      "self"
    ],
    "dictionary": [
      "self"
    ],
    "display_samples_once_in_a_while": [
      "self",
      "smp",
      "mono_lang",
      "other_lang"
    ],
    "backtranslate_sample": [
      "self",
      "smp",
      "orig_lang",
      "other_lang"
    ],
    "generate": [
      "self",
      "smp",
      "model"
    ],
    "get_other_lang": [
      "self",
      "lang"
    ],
    "train_step": [
      "self",
      "sample",
      "model",
      "criterion",
      "optimizer",
      "update_num",
      "ignore_grad"
    ],
    "get_bos_token_from_sample": [
      "self",
      "sample"
    ],
    "reduce_metrics": [
      "self",
      "logging_outputs",
      "criterion"
    ]
  },
  "extend_embedding": [
    "emb",
    "new_vocab_size",
    "copy_from_token_id"
  ],
  "add_secial_tokens_to_dict_and_model": [
    "dictionary",
    "model",
    "mono_langs"
  ],
  "assert_weights_have_changed": [
    "model"
  ],
  "check_import": [
    "flag"
  ],
  "SimulSpeechToTextTask": {
    "__init__": [
      "self",
      "args",
      "tgt_dict"
    ]
  },
  "SimulTextToTextTask": {
    "__init__": [
      "self",
      "cfg",
      "src_dict",
      "tgt_dict"
    ]
  },
  "TextToSpeechTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "src_dict"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "target_dictionary": [
      "self"
    ],
    "source_dictionary": [
      "self"
    ],
    "get_speaker_embeddings_path": [
      "self"
    ],
    "get_speaker_embeddings": [
      "cls",
      "args"
    ],
    "build_model": [
      "self",
      "cfg",
      "from_checkpoint"
    ],
    "build_generator": [
      "self",
      "models",
      "cfg",
      "vocoder"
    ],
    "build_default_vocoder": [
      "self"
    ],
    "valid_step": [
      "self",
      "sample",
      "model",
      "criterion"
    ],
    "valid_step_with_inference": [
      "self",
      "sample",
      "model",
      "generator"
    ],
    "log_tensorboard": [
      "self",
      "sample",
      "hypos",
      "num_updates",
      "is_na_model"
    ]
  },
  "save_figure_to_numpy": [
    "fig"
  ],
  "DEFAULT_V_MIN": [],
  "plot_tts_output": [
    "data_2d",
    "title_2d",
    "data_1d",
    "title_1d",
    "figsize",
    "v_min",
    "v_max",
    "ret_np",
    "suptitle"
  ],
  "antidiag_indices": [
    "offset",
    "min_i",
    "max_i",
    "min_j",
    "max_j"
  ],
  "batch_dynamic_time_warping": [
    "distance",
    "shapes"
  ],
  "compute_l2_dist": [
    "x1",
    "x2"
  ],
  "compute_rms_dist": [
    "x1",
    "x2"
  ],
  "get_divisor": [
    "pathmap",
    "normalize_type"
  ],
  "batch_compute_distortion": [
    "y1",
    "y2",
    "sr",
    "feat_fn",
    "dist_fn",
    "normalize_type"
  ],
  "batch_mel_cepstral_distortion": [
    "y1",
    "y2",
    "sr",
    "normalize_type",
    "mfcc_fn"
  ],
  "LegacyMaskedLMTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "dictionary"
    ],
    "load_dictionary": [
      "cls",
      "filename"
    ],
    "build_dictionary": [
      "cls",
      "filenames",
      "workers",
      "threshold",
      "nwords",
      "padding_factor"
    ],
    "target_dictionary": [
      "self"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ]
  },
  "_get_bt_dataset_key": [
    "lang_pair"
  ],
  "_get_denoising_dataset_key": [
    "lang_pair"
  ],
  "parse_lambda_config": [
    "x"
  ],
  "SemisupervisedTranslationTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "dicts",
      "training"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch"
    ],
    "build_model": [
      "self",
      "args",
      "from_checkpoint"
    ],
    "train_step": [
      "self",
      "sample",
      "model",
      "criterion",
      "optimizer",
      "update_num",
      "ignore_grad"
    ],
    "update_step": [
      "self",
      "num_updates"
    ]
  },
  "StatefulContainer": {
    "__init__": [
      "self"
    ],
    "add_factory": [
      "self",
      "name",
      "factory"
    ],
    "merge_state_dict": [
      "self",
      "state_dict"
    ],
    "state_dict": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "FairseqTask": {
    "add_args": [
      "cls",
      "parser"
    ],
    "logging_outputs_can_be_summed": [
      "criterion"
    ],
    "__init__": [
      "self",
      "cfg"
    ],
    "load_dictionary": [
      "cls",
      "filename"
    ],
    "build_dictionary": [
      "cls",
      "filenames",
      "workers",
      "threshold",
      "nwords",
      "padding_factor"
    ],
    "setup_task": [
      "cls",
      "cfg"
    ],
    "has_sharded_data": [
      "self",
      "split"
    ],
    "load_dataset": [
      "self",
      "split",
      "combine",
      "task_cfg"
    ],
    "dataset": [
      "self",
      "split"
    ],
    "filter_indices_by_size": [
      "self",
      "indices",
      "dataset",
      "max_positions",
      "ignore_invalid_inputs"
    ],
    "can_reuse_epoch_itr": [
      "self",
      "dataset"
    ],
    "get_batch_iterator": [
      "self",
      "dataset",
      "max_tokens",
      "max_sentences",
      "max_positions",
      "ignore_invalid_inputs",
      "required_batch_size_multiple",
      "seed",
      "num_shards",
      "shard_id",
      "num_workers",
      "epoch",
      "data_buffer_size",
      "disable_iterator_cache",
      "skip_remainder_batch",
      "grouped_shuffling",
      "update_epoch_batch_itr"
    ],
    "build_model": [
      "self",
      "cfg",
      "from_checkpoint"
    ],
    "build_criterion": [
      "self",
      "cfg"
    ],
    "build_generator": [
      "self",
      "models",
      "args",
      "seq_gen_cls",
      "extra_gen_cls_kwargs",
      "prefix_allowed_tokens_fn"
    ],
    "train_step": [
      "self",
      "sample",
      "model",
      "criterion",
      "optimizer",
      "update_num",
      "ignore_grad"
    ],
    "valid_step": [
      "self",
      "sample",
      "model",
      "criterion"
    ],
    "optimizer_step": [
      "self",
      "optimizer",
      "model",
      "update_num"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "inference_step": [
      "self",
      "generator",
      "models",
      "sample",
      "prefix_tokens",
      "constraints"
    ],
    "begin_epoch": [
      "self",
      "epoch",
      "model"
    ],
    "begin_valid_epoch": [
      "self",
      "epoch",
      "model"
    ],
    "aggregate_logging_outputs": [
      "self",
      "logging_outputs",
      "criterion"
    ],
    "reduce_metrics": [
      "self",
      "logging_outputs",
      "criterion"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "max_positions": [
      "self"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ],
    "build_tokenizer": [
      "self",
      "args"
    ],
    "build_bpe": [
      "self",
      "args"
    ],
    "get_interactive_tokens_and_lengths": [
      "self",
      "lines",
      "encode_fn"
    ]
  },
  "LegacyFairseqTask": {
    "__init__": [
      "self",
      "args"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "has_sharded_data": [
      "self",
      "split"
    ],
    "build_model": [
      "self",
      "args",
      "from_checkpoint"
    ],
    "build_criterion": [
      "self",
      "args"
    ]
  },
  "EVAL_BLEU_ORDER": [],
  "load_langpair_dataset": [
    "data_path",
    "split",
    "src",
    "src_dict",
    "tgt",
    "tgt_dict",
    "combine",
    "dataset_impl",
    "upsample_primary",
    "left_pad_source",
    "left_pad_target",
    "max_source_positions",
    "max_target_positions",
    "prepend_bos",
    "load_alignments",
    "truncate_source",
    "append_source_id",
    "num_buckets",
    "shuffle",
    "pad_to_multiple",
    "prepend_bos_src"
  ],
  "TranslationConfig": {},
  "TranslationTask": {
    "__init__": [
      "self",
      "cfg",
      "src_dict",
      "tgt_dict"
    ],
    "setup_task": [
      "cls",
      "cfg"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths",
      "constraints"
    ],
    "build_model": [
      "self",
      "cfg",
      "from_checkpoint"
    ],
    "valid_step": [
      "self",
      "sample",
      "model",
      "criterion"
    ],
    "reduce_metrics": [
      "self",
      "logging_outputs",
      "criterion"
    ],
    "max_positions": [
      "self"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ],
    "_inference_with_bleu": [
      "self",
      "generator",
      "sample",
      "model"
    ]
  },
  "ChrFScorerConfig": {},
  "ChrFScorer": {
    "__init__": [
      "self",
      "args"
    ],
    "add_string": [
      "self",
      "ref",
      "pred"
    ],
    "score": [
      "self",
      "order"
    ],
    "result_string": [
      "self",
      "order"
    ]
  },
  "BertScoreScorerConfig": {},
  "BertScoreScorer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "add_string": [
      "self",
      "ref",
      "pred"
    ],
    "score": [
      "self",
      "order"
    ],
    "result_string": [
      "self",
      "order"
    ]
  },
  "SACREBLEU_V2_ABOVE": [],
  "EvaluationTokenizer": {
    "SPACE": [],
    "SPACE_ESCAPE": [],
    "_ALL_TOKENIZER_TYPES": [],
    "ALL_TOKENIZER_TYPES": [],
    "__init__": [
      "self",
      "tokenizer_type",
      "lowercase",
      "punctuation_removal",
      "character_tokenization"
    ],
    "remove_punctuation": [
      "cls",
      "sent"
    ],
    "tokenize": [
      "self",
      "sent"
    ]
  },
  "BleuStat": {
    "_fields_": []
  },
  "SacrebleuConfig": {},
  "SacrebleuScorer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "add_string": [
      "self",
      "ref",
      "pred"
    ],
    "_score": [
      "self",
      "order"
    ],
    "score": [
      "self",
      "order"
    ],
    "result_string": [
      "self",
      "order"
    ]
  },
  "BleuConfig": {},
  "Scorer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "reset": [
      "self",
      "one_init"
    ],
    "add": [
      "self",
      "ref",
      "pred"
    ],
    "score": [
      "self",
      "order"
    ],
    "precision": [
      "self"
    ],
    "brevity": [
      "self"
    ],
    "result_string": [
      "self",
      "order"
    ]
  },
  "BaseScorer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "add_string": [
      "self",
      "ref",
      "pred"
    ],
    "score": [
      "self"
    ],
    "result_string": [
      "self"
    ]
  },
  "build_scorer": [
    "choice",
    "tgt_dict"
  ],
  "MeteorScorerConfig": {},
  "MeteorScorer": {
    "__init__": [
      "self",
      "args"
    ],
    "add_string": [
      "self",
      "ref",
      "pred"
    ],
    "score": [
      "self",
      "order"
    ],
    "result_string": [
      "self",
      "order"
    ]
  },
  "WerScorerConfig": {},
  "WerScorer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "reset": [
      "self"
    ],
    "add_string": [
      "self",
      "ref",
      "pred"
    ],
    "result_string": [
      "self"
    ],
    "score": [
      "self"
    ]
  },
  "FairseqIncrementalDecoder": {
    "__init__": [
      "self",
      "dictionary"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state"
    ],
    "extract_features": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "reorder_incremental_state_scripting": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "set_beam_size": [
      "self",
      "beam_size"
    ]
  },
  "_SLOWMO_DDP_DISABLED": [],
  "DistributedFairseqModel": [
    "args",
    "model",
    "process_group",
    "device"
  ],
  "MaskedLMModel": {
    "__init__": [
      "self",
      "args",
      "encoder"
    ],
    "add_args": [
      "parser"
    ],
    "forward": [
      "self",
      "src_tokens",
      "segment_labels"
    ],
    "max_positions": [
      "self"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ]
  },
  "MaskedLMEncoder": {
    "__init__": [
      "self",
      "args",
      "dictionary"
    ],
    "forward": [
      "self",
      "src_tokens",
      "segment_labels",
      "masked_tokens"
    ],
    "max_positions": [
      "self"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "bert_base_architecture": [
    "args"
  ],
  "bert_large_architecture": [
    "args"
  ],
  "xlm_architecture": [
    "args"
  ],
  "script_skip_tensor_list": [
    "x",
    "mask"
  ],
  "script_skip_tensor": [
    "x",
    "mask"
  ],
  "expand_2d_or_3d_tensor": [
    "x",
    "trg_dim",
    "padding_idx"
  ],
  "coalesce": [
    "x",
    "y"
  ],
  "fill_tensors": [
    "x",
    "mask",
    "y",
    "padding_idx"
  ],
  "FConvLanguageModel": {
    "__init__": [
      "self",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ]
  },
  "base_lm_architecture": [
    "args"
  ],
  "fconv_lm_dauphin_wikitext103": [
    "args"
  ],
  "fconv_lm_dauphin_gbw": [
    "args"
  ],
  "EncoderOut": [],
  "FairseqEncoder": {
    "__init__": [
      "self",
      "dictionary"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "forward_torchscript": [
      "self",
      "net_input"
    ],
    "forward_non_torchscript": [
      "self",
      "net_input"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ],
    "max_positions": [
      "self"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ]
  },
  "LightConvLanguageModel": {
    "__init__": [
      "self",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ]
  },
  "lightconv_lm_gbw": [
    "args"
  ],
  "MODEL_REGISTRY": [],
  "MODEL_DATACLASS_REGISTRY": [],
  "ARCH_MODEL_REGISTRY": [],
  "ARCH_MODEL_NAME_REGISTRY": [],
  "ARCH_MODEL_INV_REGISTRY": [],
  "ARCH_CONFIG_REGISTRY": [],
  "build_model": [
    "cfg",
    "task",
    "from_checkpoint"
  ],
  "register_model": [
    "name",
    "dataclass"
  ],
  "register_model_architecture": [
    "model_name",
    "arch_name"
  ],
  "import_models": [
    "models_dir",
    "namespace"
  ],
  "models_dir": [],
  "TransformerFromPretrainedXLMModel": {
    "add_args": [
      "parser"
    ],
    "build_model": [
      "self",
      "args",
      "task",
      "cls_dictionary"
    ],
    "build_encoder": [
      "cls",
      "args",
      "src_dict",
      "embed_tokens"
    ],
    "build_decoder": [
      "cls",
      "args",
      "tgt_dict",
      "embed_tokens"
    ]
  },
  "upgrade_state_dict_with_xlm_weights": [
    "state_dict",
    "pretrained_xlm_checkpoint"
  ],
  "TransformerEncoderFromPretrainedXLM": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens"
    ]
  },
  "TransformerDecoderFromPretrainedXLM": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens",
      "no_encoder_attn"
    ]
  },
  "DEFAULT_MAX_SOURCE_POSITIONS": [],
  "DEFAULT_MAX_TARGET_POSITIONS": [],
  "LSTMModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "incremental_state"
    ]
  },
  "LSTMEncoder": {
    "__init__": [
      "self",
      "dictionary",
      "embed_dim",
      "hidden_size",
      "num_layers",
      "dropout_in",
      "dropout_out",
      "bidirectional",
      "left_pad",
      "pretrained_embed",
      "padding_idx",
      "max_source_positions"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "enforce_sorted"
    ],
    "combine_bidir": [
      "self",
      "outs",
      "bsz"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ],
    "max_positions": [
      "self"
    ]
  },
  "AttentionLayer": {
    "__init__": [
      "self",
      "input_embed_dim",
      "source_embed_dim",
      "output_embed_dim",
      "bias"
    ],
    "forward": [
      "self",
      "input",
      "source_hids",
      "encoder_padding_mask"
    ]
  },
  "LSTMDecoder": {
    "__init__": [
      "self",
      "dictionary",
      "embed_dim",
      "hidden_size",
      "out_embed_dim",
      "num_layers",
      "dropout_in",
      "dropout_out",
      "attention",
      "encoder_output_units",
      "pretrained_embed",
      "share_input_output_embed",
      "adaptive_softmax_cutoff",
      "max_target_positions",
      "residuals"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "src_lengths"
    ],
    "extract_features": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state"
    ],
    "output_layer": [
      "self",
      "x"
    ],
    "get_cached_state": [
      "self",
      "incremental_state"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "max_positions": [
      "self"
    ],
    "make_generation_fast_": [
      "self",
      "need_attn"
    ]
  },
  "Embedding": [
    "num_embeddings",
    "embedding_dim",
    "padding_idx"
  ],
  "LSTM": [
    "input_size",
    "hidden_size"
  ],
  "LSTMCell": [
    "input_size",
    "hidden_size"
  ],
  "Linear": [
    "in_features",
    "out_features",
    "bias",
    "dropout"
  ],
  "lstm_wiseman_iwslt_de_en": [
    "args"
  ],
  "lstm_luong_wmt_en_de": [
    "args"
  ],
  "FConvModel": {
    "hub_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ]
  },
  "FConvEncoder": {
    "__init__": [
      "self",
      "dictionary",
      "embed_dim",
      "embed_dict",
      "max_positions",
      "convolutions",
      "dropout"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ],
    "max_positions": [
      "self"
    ]
  },
  "FConvDecoder": {
    "__init__": [
      "self",
      "dictionary",
      "embed_dim",
      "embed_dict",
      "out_embed_dim",
      "max_positions",
      "convolutions",
      "attention",
      "dropout",
      "share_embed",
      "positional_embeddings",
      "adaptive_softmax_cutoff",
      "adaptive_softmax_dropout"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "max_positions": [
      "self"
    ],
    "upgrade_state_dict": [
      "self",
      "state_dict"
    ],
    "make_generation_fast_": [
      "self",
      "need_attn"
    ],
    "_embed_tokens": [
      "self",
      "tokens",
      "incremental_state"
    ],
    "_split_encoder_out": [
      "self",
      "encoder_out",
      "incremental_state"
    ],
    "_transpose_if_training": [
      "self",
      "x",
      "incremental_state"
    ]
  },
  "extend_conv_spec": [
    "convolutions"
  ],
  "PositionalEmbedding": [
    "num_embeddings",
    "embedding_dim",
    "padding_idx"
  ],
  "LinearizedConv1d": [
    "in_channels",
    "out_channels",
    "kernel_size",
    "dropout"
  ],
  "ConvTBC": [
    "in_channels",
    "out_channels",
    "kernel_size",
    "dropout"
  ],
  "fconv_iwslt_de_en": [
    "args"
  ],
  "fconv_wmt_en_ro": [
    "args"
  ],
  "fconv_wmt_en_de": [
    "args"
  ],
  "fconv_wmt_en_fr": [
    "args"
  ],
  "check_type": [
    "module",
    "expected_type"
  ],
  "BaseFairseqModel": {
    "__init__": [
      "self"
    ],
    "add_args": [
      "cls",
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "get_targets": [
      "self",
      "sample",
      "net_output"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "get_normalized_probs_scriptable": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "extract_features": [
      "self"
    ],
    "max_positions": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict",
      "model_cfg",
      "args"
    ],
    "upgrade_state_dict": [
      "self",
      "state_dict"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "prepare_for_inference_": [
      "self",
      "cfg"
    ],
    "make_generation_fast_": [
      "self"
    ],
    "prepare_for_onnx_export_": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "checkpoint_file",
      "data_name_or_path"
    ],
    "hub_models": [
      "cls"
    ]
  },
  "FairseqEncoderDecoderModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens"
    ],
    "forward_decoder": [
      "self",
      "prev_output_tokens"
    ],
    "extract_features": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens"
    ],
    "output_layer": [
      "self",
      "features"
    ],
    "max_positions": [
      "self"
    ],
    "max_decoder_positions": [
      "self"
    ]
  },
  "FairseqModel": {
    "__init__": [
      "self"
    ]
  },
  "FairseqMultiModel": {
    "__init__": [
      "self",
      "encoders",
      "decoders"
    ],
    "build_shared_embeddings": [
      "dicts",
      "langs",
      "embed_dim",
      "build_embedding",
      "pretrained_embed_path"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens"
    ],
    "max_positions": [
      "self"
    ],
    "max_decoder_positions": [
      "self"
    ],
    "encoder": [
      "self"
    ],
    "decoder": [
      "self"
    ],
    "forward_decoder": [
      "self",
      "prev_output_tokens"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict",
      "model_cfg",
      "args"
    ]
  },
  "FairseqLanguageModel": {
    "__init__": [
      "self",
      "decoder"
    ],
    "forward": [
      "self",
      "src_tokens"
    ],
    "forward_decoder": [
      "self",
      "prev_output_tokens"
    ],
    "extract_features": [
      "self",
      "src_tokens"
    ],
    "output_layer": [
      "self",
      "features"
    ],
    "max_positions": [
      "self"
    ],
    "max_decoder_positions": [
      "self"
    ],
    "supported_targets": [
      "self"
    ]
  },
  "FairseqEncoderModel": {
    "__init__": [
      "self",
      "encoder"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "max_positions": [
      "self"
    ]
  },
  "FairseqDecoder": {
    "__init__": [
      "self",
      "dictionary"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out"
    ],
    "extract_features": [
      "self",
      "prev_output_tokens",
      "encoder_out"
    ],
    "output_layer": [
      "self",
      "features"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "get_normalized_probs_scriptable": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "max_positions": [
      "self"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "prepare_for_onnx_export_": [
      "self"
    ]
  },
  "LightConvModel": {
    "hub_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ]
  },
  "LightConvEncoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "src_tokens"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ],
    "max_positions": [
      "self"
    ]
  },
  "LightConvDecoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens",
      "no_encoder_attn",
      "final_norm"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state"
    ],
    "max_positions": [
      "self"
    ],
    "buffered_future_mask": [
      "self",
      "tensor"
    ]
  },
  "LightConvEncoderLayer": {
    "__init__": [
      "self",
      "args",
      "kernel_size"
    ],
    "forward": [
      "self",
      "x",
      "encoder_padding_mask"
    ],
    "maybe_layer_norm": [
      "self",
      "i",
      "x",
      "before",
      "after"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "LightConvDecoderLayer": {
    "__init__": [
      "self",
      "args",
      "no_encoder_attn",
      "kernel_size"
    ],
    "forward": [
      "self",
      "x",
      "encoder_out",
      "encoder_padding_mask",
      "incremental_state",
      "prev_conv_state",
      "prev_attn_state",
      "conv_mask",
      "conv_padding_mask"
    ],
    "maybe_layer_norm": [
      "self",
      "layer_norm",
      "x",
      "before",
      "after"
    ],
    "make_generation_fast_": [
      "self",
      "need_attn"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "lightconv_iwslt_de_en": [
    "args"
  ],
  "lightconv_wmt_en_de": [
    "args"
  ],
  "lightconv_wmt_en_de_big": [
    "args"
  ],
  "lightconv_wmt_en_fr_big": [
    "args"
  ],
  "lightconv_wmt_zh_en_big": [
    "args"
  ],
  "TransformerAlignModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder",
      "args"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens"
    ],
    "forward_decoder": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "features_only"
    ]
  },
  "transformer_align": [
    "args"
  ],
  "transformer_wmt_en_de_big_align": [
    "args"
  ],
  "MASKING_DISTRIBUTION_CHOICES": [],
  "SpeechUnitLanguageModelConfig": {},
  "TransformerUnitLanguageModel": {
    "__init__": [
      "self",
      "cfg",
      "task",
      "decoder"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "apply_seg_dropout": [
      "self",
      "inp",
      "mask_prob",
      "mask_leng",
      "mask_type",
      "mask_val"
    ],
    "apply_seq_dropout": [
      "self",
      "inp",
      "mask_prob",
      "mask_val"
    ],
    "apply_dropout": [
      "self",
      "src_tokens",
      "dur_src",
      "f0_src"
    ],
    "forward": [
      "self",
      "src_tokens",
      "dur_src",
      "f0_src",
      "src_lengths",
      "incremental_state"
    ]
  },
  "base_ulm_architecture": [
    "args"
  ],
  "transformer_ulm_big": [
    "args"
  ],
  "transformer_ulm_tiny": [
    "args"
  ],
  "MultiStreamTransformerDecoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens",
      "embed_other_list",
      "no_encoder_attn",
      "channel_sizes"
    ],
    "extract_features_scriptable": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "full_context_alignment",
      "alignment_layer",
      "alignment_heads"
    ]
  },
  "CompositeEncoder": {
    "__init__": [
      "self",
      "encoders"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ],
    "max_positions": [
      "self"
    ],
    "upgrade_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "FConvModelSelfAtt": {
    "hub_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "encoder",
      "decoder",
      "pretrained_encoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "pretrained": [
      "self"
    ]
  },
  "SelfAttention": {
    "__init__": [
      "self",
      "out_channels",
      "embed_dim",
      "num_heads",
      "project_input",
      "gated",
      "downsample"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "fconv_self_att_wp": [
    "args"
  ],
  "LSTMLanguageModel": {
    "__init__": [
      "self",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ]
  },
  "MultilingualTransformerModel": {
    "__init__": [
      "self",
      "encoders",
      "decoders"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "_get_module_class": [
      "cls",
      "is_encoder",
      "args",
      "lang_dict",
      "embed_tokens",
      "langs"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict",
      "model_cfg"
    ]
  },
  "base_multilingual_architecture": [
    "args"
  ],
  "multilingual_transformer_iwslt_de_en": [
    "args"
  ],
  "TransformerLanguageModelConfig": {},
  "TransformerLanguageModel": {
    "hub_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "decoder"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "build_embedding": [
      "cls",
      "args",
      "dictionary",
      "embed_dim",
      "path"
    ]
  },
  "transformer_lm_big": [
    "args"
  ],
  "transformer_lm_baevski_wiki103": [
    "args"
  ],
  "transformer_lm_baevski_gbw": [
    "args"
  ],
  "transformer_lm_gpt": [
    "args"
  ],
  "transformer_lm_gpt2_small": [
    "args"
  ],
  "transformer_lm_gpt2_tiny": [
    "args"
  ],
  "transformer_lm_gpt2_medium": [
    "args"
  ],
  "transformer_lm_gpt2_big": [
    "args"
  ],
  "transformer_lm_gpt2_big_wide": [
    "args"
  ],
  "transformer_lm_gpt2_bigger": [
    "args"
  ],
  "base_gpt3_architecture": [
    "args"
  ],
  "transformer_lm_gpt3_small": [
    "args"
  ],
  "transformer_lm_gpt3_medium": [
    "args"
  ],
  "transformer_lm_gpt3_large": [
    "args"
  ],
  "transformer_lm_gpt3_xl": [
    "args"
  ],
  "transformer_lm_gpt3_2_7": [
    "args"
  ],
  "transformer_lm_gpt3_6_7": [
    "args"
  ],
  "transformer_lm_gpt3_13": [
    "args"
  ],
  "transformer_lm_gpt3_175": [
    "args"
  ],
  "LRELU_SLOPE": [],
  "init_weights": [
    "m",
    "mean",
    "std"
  ],
  "get_padding": [
    "kernel_size",
    "dilation"
  ],
  "ResBlock": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "Generator": {
    "__init__": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "x"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "model_init": [
    "m"
  ],
  "PositionwiseFeedForward": {
    "__init__": [
      "self",
      "in_dim",
      "hidden_dim",
      "kernel_size",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FFTLayer": {
    "__init__": [
      "self",
      "embed_dim",
      "n_heads",
      "hidden_dim",
      "kernel_size",
      "dropout",
      "attention_dropout"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask"
    ]
  },
  "LengthRegulator": {
    "forward": [
      "self",
      "x",
      "durations"
    ]
  },
  "VariancePredictor": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "VarianceAdaptor": {
    "__init__": [
      "self",
      "args"
    ],
    "get_pitch_emb": [
      "self",
      "x",
      "tgt",
      "factor"
    ],
    "get_energy_emb": [
      "self",
      "x",
      "tgt",
      "factor"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask",
      "durations",
      "pitches",
      "energies",
      "d_factor",
      "p_factor",
      "e_factor"
    ]
  },
  "FastSpeech2Encoder": {
    "__init__": [
      "self",
      "args",
      "src_dict",
      "embed_speaker"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "speaker",
      "durations",
      "pitches",
      "energies"
    ]
  },
  "FastSpeech2Model": {
    "NON_AUTOREGRESSIVE": [],
    "hub_models": [
      "cls"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "checkpoint_file",
      "data_name_or_path",
      "config_yaml",
      "vocoder",
      "fp16"
    ],
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "encoder",
      "args",
      "src_dict"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ]
  },
  "CodeGenerator": {
    "__init__": [
      "self",
      "cfg"
    ],
    "_upsample": [
      "signal",
      "max_frames"
    ],
    "forward": [
      "self"
    ]
  },
  "encoder_init": [
    "m"
  ],
  "TTSTransformerEncoder": {
    "__init__": [
      "self",
      "args",
      "src_dict",
      "embed_speaker"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "speaker"
    ]
  },
  "decoder_init": [
    "m"
  ],
  "TTSTransformerDecoder": {
    "__init__": [
      "self",
      "args",
      "src_dict",
      "padding_idx"
    ],
    "extract_features": [
      "self",
      "prev_outputs",
      "encoder_out",
      "incremental_state",
      "target_lengths",
      "speaker"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "target_lengths",
      "speaker"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "buffered_future_mask": [
      "self",
      "tensor"
    ]
  },
  "TTSTransformerModel": {
    "hub_models": [
      "cls"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "checkpoint_file",
      "data_name_or_path",
      "config_yaml",
      "vocoder",
      "fp16"
    ],
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "forward_encoder": [
      "self",
      "src_tokens",
      "src_lengths",
      "speaker"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ]
  },
  "PseudoInverseMelScale": {
    "__init__": [
      "self",
      "n_stft",
      "n_mels",
      "sample_rate",
      "f_min",
      "f_max"
    ],
    "forward": [
      "self",
      "melspec"
    ]
  },
  "GriffinLim": {
    "__init__": [
      "self",
      "n_fft",
      "win_length",
      "hop_length",
      "n_iter",
      "window_fn"
    ],
    "get_window_sum_square": [
      "cls",
      "n_frames",
      "hop_length",
      "win_length",
      "n_fft",
      "window_fn"
    ],
    "inverse": [
      "self",
      "magnitude",
      "phase"
    ],
    "forward": [
      "self",
      "specgram"
    ]
  },
  "GriffinLimVocoder": {
    "__init__": [
      "self",
      "sample_rate",
      "win_size",
      "hop_size",
      "n_fft",
      "n_mels",
      "f_min",
      "f_max",
      "window_fn",
      "spec_bwd_max_iter",
      "fp16"
    ],
    "forward": [
      "self",
      "x"
    ],
    "from_data_cfg": [
      "cls",
      "args",
      "data_cfg"
    ]
  },
  "HiFiGANVocoder": {
    "__init__": [
      "self",
      "checkpoint_path",
      "model_cfg",
      "fp16"
    ],
    "forward": [
      "self",
      "x"
    ],
    "from_data_cfg": [
      "cls",
      "args",
      "data_cfg"
    ]
  },
  "CodeHiFiGANVocoder": {
    "__init__": [
      "self",
      "checkpoint_path",
      "model_cfg",
      "fp16"
    ],
    "forward": [
      "self",
      "x",
      "dur_prediction"
    ],
    "from_data_cfg": [
      "cls",
      "args",
      "data_cfg"
    ]
  },
  "get_vocoder": [
    "args",
    "data_cfg"
  ],
  "TTSHubInterface": {
    "__init__": [
      "self",
      "cfg",
      "task",
      "model"
    ],
    "phonemize": [
      "cls",
      "text",
      "lang",
      "phonemizer",
      "preserve_punct",
      "to_simplified_zh"
    ],
    "tokenize": [
      "cls",
      "text",
      "tkn_cfg"
    ],
    "update_cfg_with_data_cfg": [
      "cls",
      "cfg",
      "data_cfg"
    ],
    "get_model_input": [
      "cls",
      "task",
      "text",
      "speaker",
      "verbose"
    ],
    "get_prediction": [
      "cls",
      "task",
      "model",
      "generator",
      "sample"
    ],
    "predict": [
      "self",
      "text",
      "speaker",
      "verbose"
    ]
  },
  "Tacotron2Encoder": {
    "__init__": [
      "self",
      "args",
      "src_dict",
      "embed_speaker"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "speaker"
    ]
  },
  "Prenet": {
    "__init__": [
      "self",
      "in_dim",
      "n_layers",
      "n_units",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Postnet": {
    "__init__": [
      "self",
      "in_dim",
      "n_channels",
      "kernel_size",
      "n_layers",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Tacotron2Decoder": {
    "__init__": [
      "self",
      "args",
      "src_dict"
    ],
    "_get_states": [
      "self",
      "incremental_state",
      "enc_out"
    ],
    "_get_init_attn_c": [
      "self",
      "enc_out",
      "enc_mask"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "target_lengths"
    ]
  },
  "Tacotron2Model": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "forward_encoder": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ]
  },
  "HuggingFaceGPT2LanguageModel": {
    "__init__": [
      "self",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ]
  },
  "HuggingFaceGPT2Decoder": {
    "__init__": [
      "self",
      "args",
      "task"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "src_lengths",
      "incremental_state",
      "encoder_out"
    ],
    "extract_features": [
      "self",
      "prev_output_tokens",
      "incremental_state"
    ],
    "max_positions": [
      "self"
    ]
  },
  "default_architecture": [
    "args"
  ],
  "hf_gpt2_medium": [
    "args"
  ],
  "hf_gpt2_large": [
    "args"
  ],
  "hf_gpt2_xl": [
    "args"
  ],
  "Adapter": {
    "__init__": [
      "self",
      "cfg",
      "red_fac"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "XMODTransformerEncoderLayerBase": {
    "__init__": [
      "self",
      "cfg"
    ],
    "lang_adapter": [
      "self",
      "lang_id",
      "x"
    ],
    "forward": [
      "self",
      "x",
      "encoder_padding_mask",
      "attn_mask",
      "lang_id"
    ]
  },
  "DEFAULT_MIN_PARAMS_TO_WRAP": [],
  "XMODModel": {
    "hub_models": [
      "cls"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "checkpoint_file",
      "data_name_or_path",
      "bpe"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "forward": [
      "self",
      "src_tokens",
      "features_only",
      "return_all_hiddens",
      "classification_head_name",
      "lang_id"
    ]
  },
  "XMODEncoder": {
    "build_encoder": [
      "self",
      "args",
      "dictionary",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "src_tokens",
      "features_only",
      "return_all_hiddens",
      "masked_tokens",
      "lang_id"
    ],
    "extract_features": [
      "self",
      "src_tokens",
      "return_all_hiddens",
      "lang_id"
    ]
  },
  "XMODTransformerEncoder": {
    "build_encoder_layer": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens",
      "token_embeddings",
      "lang_id"
    ],
    "forward_scriptable": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens",
      "token_embeddings",
      "lang_id"
    ]
  },
  "roberta_base_architecture": [
    "args"
  ],
  "XMODHubInterface": {
    "extract_features": [
      "self",
      "tokens",
      "return_all_hiddens",
      "lang_id"
    ],
    "predict": [
      "self",
      "head",
      "tokens",
      "return_logits",
      "lang_id"
    ]
  },
  "_mean_pooling": [
    "enc_feats",
    "src_masks"
  ],
  "_argmax": [
    "x",
    "dim"
  ],
  "_uniform_assignment": [
    "src_lens",
    "trg_lens"
  ],
  "NATransformerModel": {
    "allow_length_beam": [
      "self"
    ],
    "add_args": [
      "parser"
    ],
    "build_decoder": [
      "cls",
      "args",
      "tgt_dict",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "tgt_tokens"
    ],
    "forward_decoder": [
      "self",
      "decoder_out",
      "encoder_out",
      "decoding_format"
    ],
    "initialize_output_tokens": [
      "self",
      "encoder_out",
      "src_tokens"
    ],
    "regenerate_length_beam": [
      "self",
      "decoder_out",
      "beam_size"
    ]
  },
  "NATransformerDecoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens",
      "no_encoder_attn"
    ],
    "forward": [
      "self",
      "normalize",
      "encoder_out",
      "prev_output_tokens",
      "step"
    ],
    "forward_length": [
      "self",
      "normalize",
      "encoder_out"
    ],
    "extract_features": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "early_exit",
      "embedding_copy"
    ],
    "forward_embedding": [
      "self",
      "prev_output_tokens",
      "states"
    ],
    "forward_copying_source": [
      "self",
      "src_embeds",
      "src_masks",
      "tgt_masks"
    ],
    "forward_length_prediction": [
      "self",
      "length_out",
      "encoder_out",
      "tgt_tokens"
    ]
  },
  "nonautoregressive_transformer_wmt_en_de": [
    "args"
  ],
  "ensemble_encoder": [
    "func"
  ],
  "ensemble_decoder": [
    "func"
  ],
  "FairseqNATModel": {
    "__init__": [
      "self",
      "args",
      "encoder",
      "decoder"
    ],
    "allow_length_beam": [
      "self"
    ],
    "allow_ensemble": [
      "self"
    ],
    "enable_ensemble": [
      "self",
      "models"
    ],
    "add_args": [
      "parser"
    ],
    "build_decoder": [
      "cls",
      "args",
      "tgt_dict",
      "embed_tokens"
    ],
    "build_encoder": [
      "cls",
      "args",
      "src_dict",
      "embed_tokens"
    ],
    "forward_encoder": [
      "self",
      "encoder_inputs"
    ],
    "forward_decoder": [
      "self"
    ],
    "initialize_output_tokens": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "FairseqNATEncoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens"
    ],
    "forward": [
      "self"
    ]
  },
  "FairseqNATDecoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens",
      "no_encoder_attn"
    ]
  },
  "NACRFTransformerModel": {
    "__init__": [
      "self",
      "args",
      "encoder",
      "decoder"
    ],
    "allow_ensemble": [
      "self"
    ],
    "add_args": [
      "parser"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "tgt_tokens"
    ],
    "forward_decoder": [
      "self",
      "decoder_out",
      "encoder_out",
      "decoding_format"
    ]
  },
  "nacrf_base_architecture": [
    "args"
  ],
  "_skeptical_unmasking": [
    "output_scores",
    "output_masks",
    "p"
  ],
  "CMLMNATransformerModel": {
    "add_args": [
      "parser"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "tgt_tokens"
    ],
    "forward_decoder": [
      "self",
      "decoder_out",
      "encoder_out",
      "decoding_format"
    ]
  },
  "cmlm_base_architecture": [
    "args"
  ],
  "cmlm_wmt_en_de": [
    "args"
  ],
  "NegativeDistanceScore": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "i",
      "L",
      "tau"
    ],
    "compute_score": [
      "self",
      "L",
      "tau"
    ],
    "compute_score_full": [
      "self",
      "L",
      "tau"
    ]
  },
  "neg_scorer": [],
  "_get_ins_targets": [
    "in_tokens",
    "out_tokens",
    "padding_idx",
    "unk_idx",
    "vocab_size",
    "tau"
  ],
  "_apply_ins_words": [
    "in_tokens",
    "in_scores",
    "word_ins_pred",
    "word_ins_scores",
    "padding_idx"
  ],
  "InsertionTransformerModel": {
    "__init__": [
      "self",
      "args",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_decoder": [
      "cls",
      "args",
      "tgt_dict",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "tgt_tokens"
    ],
    "forward_decoder": [
      "self",
      "decoder_out",
      "encoder_out",
      "eos_penalty",
      "max_ratio"
    ]
  },
  "InsertionTransformerDecoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens",
      "no_encoder_attn"
    ],
    "forward_word_ins": [
      "self",
      "normalize",
      "encoder_out",
      "prev_output_tokens"
    ],
    "forward_mask_ins": [
      "self"
    ],
    "forward_word_del": [
      "self"
    ]
  },
  "insertion_base_architecture": [
    "args"
  ],
  "_sequential_poisoning": [
    "s",
    "V",
    "beta",
    "bos",
    "eos",
    "pad"
  ],
  "gumbel_noise": [
    "input",
    "TINY"
  ],
  "IterNATransformerModel": {
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "tgt_tokens"
    ]
  },
  "inat_base_architecture": [
    "args"
  ],
  "iter_nat_wmt_en_de": [
    "args"
  ],
  "load_libnat": [],
  "_get_del_targets": [
    "in_tokens",
    "out_tokens",
    "padding_idx"
  ],
  "_apply_ins_masks": [
    "in_tokens",
    "in_scores",
    "mask_ins_pred",
    "padding_idx",
    "unk_idx",
    "eos_idx"
  ],
  "_apply_del_words": [
    "in_tokens",
    "in_scores",
    "in_attn",
    "word_del_pred",
    "padding_idx",
    "bos_idx",
    "eos_idx"
  ],
  "_skip": [
    "x",
    "mask"
  ],
  "_skip_encoder_out": [
    "encoder",
    "encoder_out",
    "mask"
  ],
  "_fill": [
    "x",
    "mask",
    "y",
    "padding_idx"
  ],
  "LevenshteinTransformerModel": {
    "allow_length_beam": [
      "self"
    ],
    "add_args": [
      "parser"
    ],
    "build_decoder": [
      "cls",
      "args",
      "tgt_dict",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "tgt_tokens"
    ],
    "forward_decoder": [
      "self",
      "decoder_out",
      "encoder_out",
      "eos_penalty",
      "max_ratio"
    ],
    "initialize_output_tokens": [
      "self",
      "encoder_out",
      "src_tokens"
    ]
  },
  "LevenshteinTransformerDecoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens",
      "no_encoder_attn"
    ],
    "extract_features": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "early_exit",
      "layers"
    ],
    "forward_mask_ins": [
      "self",
      "normalize",
      "encoder_out",
      "prev_output_tokens"
    ],
    "forward_word_ins": [
      "self",
      "normalize",
      "encoder_out",
      "prev_output_tokens"
    ],
    "forward_word_del": [
      "self",
      "normalize",
      "encoder_out",
      "prev_output_tokens"
    ]
  },
  "levenshtein_base_architecture": [
    "args"
  ],
  "levenshtein_transformer_wmt_en_de": [
    "args"
  ],
  "levenshtein_transformer_vaswani_wmt_en_de_big": [
    "args"
  ],
  "levenshtein_transformer_wmt_en_de_big_t2t": [
    "args"
  ],
  "_EnsembleModelEncoder": {
    "__init__": [
      "self",
      "models"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_outs",
      "new_order"
    ]
  },
  "BasicEnsembleModel": {
    "__init__": [
      "self",
      "models"
    ],
    "has_encoder": [
      "self"
    ],
    "max_decoder_positions": [
      "self"
    ],
    "forward_encoder": [
      "self",
      "encoder_input"
    ],
    "forward_decoder": [
      "self"
    ],
    "initialize_output_tokens": [
      "self"
    ]
  },
  "EnsembleLevT": {
    "__init__": [
      "self",
      "models"
    ],
    "forward_decoder": [
      "self",
      "decoder_out",
      "encoder_outs",
      "eos_penalty",
      "max_ratio"
    ],
    "forward_word_del": [
      "self",
      "encoder_outs",
      "output_tokens",
      "output_scores",
      "attn",
      "can_del_word"
    ],
    "forward_mask_ins": [
      "self",
      "encoder_outs",
      "output_tokens",
      "output_scores",
      "can_ins_mask",
      "eos_penalty",
      "max_lens"
    ],
    "forward_word_ins": [
      "self",
      "encoder_outs",
      "output_tokens",
      "output_scores",
      "attn",
      "can_ins_word"
    ],
    "initialize_output_tokens": [
      "self",
      "encoder_outs",
      "src_tokens"
    ]
  },
  "S2STransformerEncoder": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "tgt_speaker",
      "return_all_hiddens"
    ]
  },
  "TransformerUnitDecoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens",
      "no_encoder_attn",
      "output_projection"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "features_only",
      "full_context_alignment",
      "alignment_layer",
      "alignment_heads",
      "src_lengths",
      "return_all_hiddens"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "S2STransformerMultitaskModelBase": {
    "build_encoder": [
      "cls",
      "args"
    ],
    "build_multitask_decoder": [
      "cls",
      "args",
      "tgt_dict",
      "in_dim"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "forward_encoder": [
      "self",
      "src_tokens",
      "src_lengths",
      "speaker"
    ]
  },
  "S2UTTransformerModel": {
    "add_args": [
      "parser"
    ],
    "build_decoder": [
      "cls",
      "args",
      "tgt_dict"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "tgt_speaker",
      "return_all_hiddens"
    ]
  },
  "S2SpecTTransformerModel": {
    "add_args": [
      "parser"
    ],
    "build_decoder": [
      "cls",
      "args"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "tgt_speaker",
      "incremental_state",
      "target_lengths",
      "speaker",
      "return_all_hiddens"
    ]
  },
  "base_multitask_text_transformer_decoder_arch": [
    "args"
  ],
  "base_s2st_transformer_encoder_architecture": [
    "args"
  ],
  "s2ut_architecture_base": [
    "args"
  ],
  "s2ut_architecture_fisher": [
    "args"
  ],
  "s2spect_architecture_base": [
    "args"
  ],
  "s2spect_architecture_fisher": [
    "args"
  ],
  "S2SConformerEncoder": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "tgt_speaker",
      "return_all_hiddens"
    ]
  },
  "S2UTConformerModel": {
    "add_args": [
      "parser"
    ],
    "build_encoder": [
      "cls",
      "args"
    ]
  },
  "s2ut_base_architecture": [
    "args"
  ],
  "CTCDecoder": {
    "__init__": [
      "self",
      "dictionary",
      "in_dim"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ]
  },
  "StackedEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embed_dim",
      "padding_idx",
      "num_stacked"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "RobertaEncDecModel": {
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "from_roberta": [
      "roberta_enc",
      "args",
      "dictionary"
    ],
    "read_args_from_roberta": [
      "roberta_args"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "base_enc_dec_architecture": [
    "args"
  ],
  "align_bpe_to_words": [
    "roberta",
    "bpe_tokens",
    "other_tokens"
  ],
  "align_features_to_words": [
    "roberta",
    "features",
    "alignment"
  ],
  "spacy_nlp": [],
  "spacy_tokenizer": [],
  "XLMRModel": {
    "hub_models": [
      "cls"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "checkpoint_file",
      "data_name_or_path",
      "bpe"
    ]
  },
  "RobertaModel": {
    "hub_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "args",
      "encoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "forward": [
      "self",
      "src_tokens",
      "features_only",
      "return_all_hiddens",
      "classification_head_name"
    ],
    "_get_adaptive_head_loss": [
      "self"
    ],
    "_get_adaptive_ffn_loss": [
      "self"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "register_classification_head": [
      "self",
      "name",
      "num_classes",
      "inner_dim"
    ],
    "supported_targets": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "checkpoint_file",
      "data_name_or_path",
      "bpe"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "RobertaLMHead": {
    "__init__": [
      "self",
      "embed_dim",
      "output_dim",
      "activation_fn",
      "weight"
    ],
    "forward": [
      "self",
      "features",
      "masked_tokens"
    ]
  },
  "RobertaClassificationHead": {
    "__init__": [
      "self",
      "input_dim",
      "inner_dim",
      "num_classes",
      "activation_fn",
      "pooler_dropout",
      "q_noise",
      "qn_block_size",
      "do_spectral_norm"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "RobertaEncoder": {
    "__init__": [
      "self",
      "args",
      "dictionary"
    ],
    "build_embedding": [
      "self",
      "vocab_size",
      "embedding_dim",
      "padding_idx"
    ],
    "build_encoder": [
      "self",
      "args",
      "dictionary",
      "embed_tokens"
    ],
    "build_lm_head": [
      "self",
      "embed_dim",
      "output_dim",
      "activation_fn",
      "weight"
    ],
    "forward": [
      "self",
      "src_tokens",
      "features_only",
      "return_all_hiddens",
      "masked_tokens"
    ],
    "extract_features": [
      "self",
      "src_tokens",
      "return_all_hiddens"
    ],
    "output_layer": [
      "self",
      "features",
      "masked_tokens"
    ],
    "max_positions": [
      "self"
    ]
  },
  "roberta_prenorm_architecture": [
    "args"
  ],
  "roberta_large_architecture": [
    "args"
  ],
  "GottbertModel": {
    "hub_models": [
      "cls"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "checkpoint_file",
      "data_name_or_path",
      "bpe",
      "bpe_vocab",
      "bpe_merges",
      "bpe_add_prefix_space"
    ]
  },
  "RobertaHubInterface": {
    "__init__": [
      "self",
      "cfg",
      "task",
      "model"
    ],
    "device": [
      "self"
    ],
    "encode": [
      "self",
      "sentence"
    ],
    "decode": [
      "self",
      "tokens"
    ],
    "extract_features": [
      "self",
      "tokens",
      "return_all_hiddens"
    ],
    "register_classification_head": [
      "self",
      "name",
      "num_classes",
      "embedding_size"
    ],
    "predict": [
      "self",
      "head",
      "tokens",
      "return_logits"
    ],
    "extract_features_aligned_to_words": [
      "self",
      "sentence",
      "return_all_hiddens"
    ],
    "fill_mask": [
      "self",
      "masked_input",
      "topk"
    ],
    "disambiguate_pronoun": [
      "self",
      "sentence"
    ]
  },
  "CamembertModel": {
    "hub_models": [
      "cls"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "checkpoint_file",
      "data_name_or_path",
      "bpe"
    ]
  },
  "EXTRACTOR_MODE_CHOICES": [],
  "LAYER_TYPE_CHOICES": [],
  "Wav2Vec2Config": {},
  "Wav2Vec2Model": {
    "__init__": [
      "self",
      "cfg"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "build_model": [
      "cls",
      "cfg",
      "task"
    ],
    "apply_mask": [
      "self",
      "x",
      "padding_mask",
      "mask_indices",
      "mask_channel_indices"
    ],
    "sample_negatives": [
      "self",
      "y",
      "num",
      "padding_count"
    ],
    "compute_preds": [
      "self",
      "x",
      "y",
      "negatives"
    ],
    "_get_feat_extract_output_lengths": [
      "self",
      "input_lengths"
    ],
    "forward": [
      "self",
      "source",
      "padding_mask",
      "mask",
      "features_only",
      "layer",
      "mask_indices",
      "mask_channel_indices",
      "padding_count"
    ],
    "quantize": [
      "self",
      "x"
    ],
    "extract_features": [
      "self",
      "source",
      "padding_mask",
      "mask",
      "layer"
    ],
    "get_logits": [
      "self",
      "net_output"
    ],
    "get_targets": [
      "self",
      "sample",
      "net_output",
      "expand_steps"
    ],
    "get_extra_losses": [
      "self",
      "net_output"
    ],
    "remove_pretraining_modules": [
      "self",
      "last_layer"
    ]
  },
  "ConvFeatureExtractionModel": {
    "__init__": [
      "self",
      "conv_layers",
      "dropout",
      "mode",
      "conv_bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "make_conv_pos": [
    "e",
    "k",
    "g"
  ],
  "TransformerEncoder": {
    "build_encoder_layer": [
      "self",
      "args"
    ],
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask",
      "layer"
    ],
    "extract_features": [
      "self",
      "x",
      "padding_mask",
      "tgt_layer",
      "min_layer"
    ],
    "max_positions": [
      "self"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "ConformerEncoder": {
    "build_encoder_layer": [
      "self",
      "args"
    ],
    "__init__": [
      "self",
      "args"
    ],
    "extract_features": [
      "self",
      "x",
      "padding_mask",
      "tgt_layer"
    ]
  },
  "TransformerSentenceEncoderLayer": {
    "__init__": [
      "self",
      "embedding_dim",
      "ffn_embedding_dim",
      "num_attention_heads",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "activation_fn",
      "layer_norm_first"
    ],
    "forward": [
      "self",
      "x",
      "self_attn_mask",
      "self_attn_padding_mask",
      "need_weights",
      "att_args"
    ]
  },
  "AGGREGATOR_CHOICES": [],
  "PROJECT_FEATURES_CHOICES": [],
  "ACTIVATION_CHOICES": [],
  "VQ_TYPE_CHOICES": [],
  "Wav2VecConfig": {},
  "Wav2VecModel": {
    "build_model": [
      "cls",
      "cfg",
      "task"
    ],
    "__init__": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "source"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "max_positions": [
      "self"
    ],
    "get_logits": [
      "self",
      "net_output"
    ],
    "get_targets": [
      "self",
      "sample",
      "net_output"
    ],
    "get_target_weights": [
      "self",
      "targets",
      "net_output"
    ],
    "get_extra_losses": [
      "self",
      "net_output"
    ]
  },
  "norm_block": [
    "is_layer_norm",
    "dim",
    "affine"
  ],
  "ZeroPad1d": {
    "__init__": [
      "self",
      "pad_left",
      "pad_right"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvAggegator": {
    "__init__": [
      "self",
      "conv_layers",
      "embed",
      "dropout",
      "skip_connections",
      "residual_scale",
      "non_affine_group_norm",
      "conv_bias",
      "zero_pad",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Wav2VecPredictionsModel": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "prediction_steps",
      "n_negatives",
      "cross_sample_negatives",
      "sample_distance",
      "dropout",
      "offset",
      "balanced_classes",
      "infonce"
    ],
    "sample_negatives": [
      "self",
      "y"
    ],
    "forward": [
      "self",
      "x",
      "y"
    ]
  },
  "pad_to_multiple": [
    "x",
    "multiple",
    "dim",
    "value"
  ],
  "Wav2Vec2AsrConfig": {},
  "Wav2Vec2CtcConfig": {},
  "Wav2VecCtc": {
    "__init__": [
      "self",
      "cfg",
      "w2v_encoder"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "build_model": [
      "cls",
      "cfg",
      "task"
    ],
    "get_logits": [
      "self",
      "net_output",
      "normalize"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs"
    ],
    "forward": [
      "self"
    ]
  },
  "Wav2Vec2Seq2SeqConfig": {},
  "Wav2Vec2Seq2SeqModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "build_model": [
      "cls",
      "cfg",
      "task"
    ],
    "build_encoder": [
      "cls",
      "cfg"
    ],
    "build_decoder": [
      "cls",
      "cfg",
      "tgt_dict",
      "embed_tokens"
    ],
    "forward": [
      "self"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "Wav2VecEncoder": {
    "__init__": [
      "self",
      "cfg",
      "output_size"
    ],
    "load_model_weights": [
      "self",
      "state",
      "model",
      "cfg"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "forward": [
      "self",
      "source",
      "padding_mask"
    ],
    "forward_torchscript": [
      "self",
      "net_input"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ],
    "max_positions": [
      "self"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "TransformerDecoder": {
    "__init__": [
      "self",
      "cfg",
      "dictionary",
      "embed_tokens",
      "no_encoder_attn"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state"
    ],
    "extract_features": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state"
    ],
    "output_layer": [
      "self",
      "features"
    ],
    "max_positions": [
      "self"
    ],
    "buffered_future_mask": [
      "self",
      "tensor"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "build_ema": [
    "model",
    "cfg",
    "device"
  ],
  "EMA": {
    "__init__": [
      "self",
      "model",
      "config",
      "device",
      "skip_keys"
    ],
    "get_model": [
      "self"
    ],
    "build_fp32_params": [
      "self",
      "state_dict"
    ],
    "restore": [
      "self",
      "state_dict",
      "build_fp32_params"
    ],
    "_set_decay": [
      "self",
      "decay"
    ],
    "get_decay": [
      "self"
    ],
    "_step_internal": [
      "self",
      "new_model",
      "updates"
    ],
    "step": [
      "self",
      "new_model",
      "updates"
    ],
    "reverse": [
      "self",
      "model"
    ]
  },
  "BARTModel": {
    "__jit_unused_properties__": [],
    "hub_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "args",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "supported_targets": [
      "self"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "features_only",
      "classification_head_name",
      "token_embeddings",
      "return_all_hiddens",
      "alignment_layer",
      "alignment_heads"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "checkpoint_file",
      "data_name_or_path",
      "bpe",
      "sample_break_mode"
    ],
    "register_classification_head": [
      "self",
      "name",
      "num_classes",
      "inner_dim"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "set_beam_size": [
      "self",
      "beam"
    ]
  },
  "BARTClassificationHead": {
    "__init__": [
      "self",
      "input_dim",
      "inner_dim",
      "num_classes",
      "activation_fn",
      "pooler_dropout",
      "do_spectral_norm"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "bart_large_architecture": [
    "args"
  ],
  "bart_base_architecture": [
    "args"
  ],
  "mbart_large_architecture": [
    "args"
  ],
  "mbart_base_architecture": [
    "args"
  ],
  "mbart_base_wmt20_architecture": [
    "args"
  ],
  "BARTHubInterface": {
    "__init__": [
      "self",
      "cfg",
      "task",
      "model"
    ],
    "encode": [
      "self",
      "sentence"
    ],
    "decode": [
      "self",
      "tokens"
    ],
    "_build_sample": [
      "self",
      "src_tokens"
    ],
    "generate": [
      "self",
      "tokenized_sentences"
    ],
    "extract_features": [
      "self",
      "tokens",
      "return_all_hiddens"
    ],
    "register_classification_head": [
      "self",
      "name",
      "num_classes",
      "embedding_size"
    ],
    "predict": [
      "self",
      "head",
      "tokens",
      "return_logits"
    ],
    "fill_mask": [
      "self",
      "masked_inputs",
      "topk",
      "match_source_len"
    ]
  },
  "_NAME_PARSER": [],
  "EncDecBaseConfig": {},
  "DecoderConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "QuantNoiseConfig": {},
  "TransformerConfig": {
    "__getattr__": [
      "self",
      "name"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "_copy_keys": [
      "args",
      "cls",
      "prefix",
      "seen"
    ],
    "from_namespace": [
      "cls",
      "args"
    ]
  },
  "TransformerModelBase": {
    "__init__": [
      "self",
      "cfg",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "cls",
      "parser"
    ],
    "build_model": [
      "cls",
      "cfg",
      "task"
    ],
    "build_embedding": [
      "cls",
      "cfg",
      "dictionary",
      "embed_dim",
      "path"
    ],
    "build_encoder": [
      "cls",
      "cfg",
      "src_dict",
      "embed_tokens"
    ],
    "build_decoder": [
      "cls",
      "cfg",
      "tgt_dict",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "return_all_hiddens",
      "features_only",
      "alignment_layer",
      "alignment_heads"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ]
  },
  "TransformerModel": {
    "hub_models": [
      "cls"
    ],
    "__init__": [
      "self",
      "args",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "cls",
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "build_embedding": [
      "cls",
      "args",
      "dictionary",
      "embed_dim",
      "path"
    ],
    "build_encoder": [
      "cls",
      "args",
      "src_dict",
      "embed_tokens"
    ],
    "build_decoder": [
      "cls",
      "args",
      "tgt_dict",
      "embed_tokens"
    ]
  },
  "tiny_architecture": [
    "args"
  ],
  "transformer_iwslt_de_en": [
    "args"
  ],
  "transformer_wmt_en_de": [
    "args"
  ],
  "transformer_vaswani_wmt_en_de_big": [
    "args"
  ],
  "transformer_vaswani_wmt_en_fr_big": [
    "args"
  ],
  "transformer_wmt_en_de_big": [
    "args"
  ],
  "transformer_wmt_en_de_big_t2t": [
    "args"
  ],
  "module_name_fordropout": [
    "module_name"
  ],
  "TransformerEncoderBase": {
    "__init__": [
      "self",
      "cfg",
      "dictionary",
      "embed_tokens",
      "return_fc"
    ],
    "build_encoder_layer": [
      "self",
      "cfg"
    ],
    "forward_embedding": [
      "self",
      "src_tokens",
      "token_embedding"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens",
      "token_embeddings"
    ],
    "forward_scriptable": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens",
      "token_embeddings"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ],
    "_reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ],
    "max_positions": [
      "self"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "TransformerDecoderBase": {
    "__init__": [
      "self",
      "cfg",
      "dictionary",
      "embed_tokens",
      "no_encoder_attn",
      "output_projection"
    ],
    "build_output_projection": [
      "self",
      "cfg",
      "dictionary",
      "embed_tokens"
    ],
    "build_decoder_layer": [
      "self",
      "cfg",
      "no_encoder_attn"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "features_only",
      "full_context_alignment",
      "alignment_layer",
      "alignment_heads",
      "src_lengths",
      "return_all_hiddens"
    ],
    "extract_features": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "full_context_alignment",
      "alignment_layer",
      "alignment_heads"
    ],
    "extract_features_scriptable": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "full_context_alignment",
      "alignment_layer",
      "alignment_heads"
    ],
    "output_layer": [
      "self",
      "features"
    ],
    "max_positions": [
      "self"
    ],
    "buffered_future_mask": [
      "self",
      "tensor"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "MultiModalityEncoder": {
    "__init__": [
      "self",
      "dictionary"
    ],
    "select_encoder": [
      "self",
      "mode"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "mode"
    ]
  },
  "MultiInputDecoder": {
    "__init__": [
      "self",
      "dictionary"
    ],
    "select_decoder": [
      "self",
      "mode"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "mode"
    ]
  },
  "Conv1dSubsampler": {
    "__init__": [
      "self",
      "in_channels",
      "mid_channels",
      "out_channels",
      "kernel_sizes"
    ],
    "get_out_seq_lens_tensor": [
      "self",
      "in_seq_lens_tensor"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ]
  },
  "S2TTransformerModel": {
    "hub_models": [
      "cls"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "checkpoint_file",
      "data_name_or_path",
      "config_yaml"
    ],
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_encoder": [
      "cls",
      "args"
    ],
    "build_decoder": [
      "cls",
      "args",
      "task",
      "embed_tokens"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "get_ctc_target": [
      "self",
      "sample"
    ],
    "get_ctc_output": [
      "self",
      "net_output",
      "sample"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens"
    ]
  },
  "S2TTransformerEncoder": {
    "__init__": [
      "self",
      "args"
    ],
    "_forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ]
  },
  "TransformerDecoderScriptable": {
    "extract_features": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "full_context_alignment",
      "alignment_layer",
      "alignment_heads"
    ]
  },
  "s2t_transformer_s": [
    "args"
  ],
  "s2t_transformer_xs": [
    "args"
  ],
  "s2t_transformer_sp": [
    "args"
  ],
  "s2t_transformer_m": [
    "args"
  ],
  "s2t_transformer_mp": [
    "args"
  ],
  "s2t_transformer_l": [
    "args"
  ],
  "s2t_transformer_lp": [
    "args"
  ],
  "SpeechWavTransformerEncoder": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "alway_mask"
    ],
    "apply_mask": [
      "self",
      "x",
      "padding_mask"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens",
      "padding_mask",
      "features_only"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ]
  },
  "StackedSpeechWavTransformerEncoder": {
    "__init__": [
      "self",
      "speech_enc",
      "text_enc_layers",
      "text_layer_norm"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens",
      "padding_mask",
      "features_only"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ]
  },
  "assert_equal": [
    "value1",
    "value2",
    "name1",
    "name2"
  ],
  "fill_config": [
    "config",
    "key",
    "value"
  ],
  "check_and_return_expected": [
    "value",
    "undefined_value",
    "expected_value",
    "name"
  ],
  "get_time_axis": [
    "layout"
  ],
  "get_batch_axis": [
    "layout"
  ],
  "monotonically_increasing_and_bounded": [
    "iterable",
    "min",
    "max"
  ],
  "to_pair": [
    "value",
    "name"
  ],
  "infer_conv_output_attrs": [
    "module",
    "input_channels",
    "input_dim",
    "batch_size",
    "max_length"
  ],
  "NoOp": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Permute": {
    "__init__": [
      "self",
      "dims"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "lengths_to_attention_mask": [
    "lengths",
    "left_context",
    "right_context"
  ],
  "infer_output_norm": [
    "module",
    "output_norm"
  ],
  "infer_channels_from_layout": [
    "layout",
    "channels"
  ],
  "pad_sequence": [
    "sequence",
    "time_axis",
    "extra_left_context",
    "extra_right_context"
  ],
  "sequence_to_segments": [
    "sequence",
    "time_axis",
    "lengths",
    "segment_size",
    "extra_left_context",
    "extra_right_context"
  ],
  "segments_to_sequence": [
    "segments",
    "time_axis"
  ],
  "lengths_to_encoder_padding_mask": [
    "lengths",
    "batch_first"
  ],
  "attention_suppression": [
    "attention_weights",
    "scale"
  ],
  "layer_norm_backward_hook": [
    "module",
    "grad_input",
    "grad_output",
    "clamp_value"
  ],
  "S2TConformerEncoder": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ]
  },
  "S2TConformerModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_encoder": [
      "cls",
      "args"
    ]
  },
  "ConvTransformerModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_encoder": [
      "cls",
      "args"
    ],
    "build_decoder": [
      "cls",
      "args",
      "task",
      "embed_tokens"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "set_batch_first": [
      "lprobs"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "output_layout": [
      "self"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens"
    ]
  },
  "ConvTransformerEncoder": {
    "__init__": [
      "self",
      "args"
    ],
    "pooling_ratio": [
      "self"
    ],
    "infer_conv_output_dim": [
      "self",
      "in_channels",
      "input_dim",
      "out_channels"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ]
  },
  "TransformerDecoderNoExtra": {
    "extract_features": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "full_context_alignment",
      "alignment_layer",
      "alignment_heads"
    ]
  },
  "convtransformer_espnet": [
    "args"
  ],
  "S2THubInterface": {
    "__init__": [
      "self",
      "cfg",
      "task",
      "model"
    ],
    "get_model_input": [
      "cls",
      "task",
      "audio"
    ],
    "detokenize": [
      "cls",
      "task",
      "tokens"
    ],
    "get_prefix_token": [
      "cls",
      "task",
      "lang"
    ],
    "get_prediction": [
      "cls",
      "task",
      "model",
      "generator",
      "sample",
      "tgt_lang",
      "synthesize_speech"
    ],
    "predict": [
      "self",
      "audio",
      "tgt_lang",
      "synthesize_speech"
    ]
  },
  "BerardModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_encoder": [
      "cls",
      "args",
      "task"
    ],
    "build_decoder": [
      "cls",
      "args",
      "task"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ]
  },
  "BerardEncoder": {
    "__init__": [
      "self",
      "input_layers",
      "conv_layers",
      "in_channels",
      "input_feat_per_channel",
      "num_blstm_layers",
      "lstm_size",
      "dropout"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ]
  },
  "MLPAttention": {
    "__init__": [
      "self",
      "decoder_hidden_state_dim",
      "context_dim",
      "attention_dim"
    ],
    "forward": [
      "self",
      "decoder_state",
      "source_hids",
      "encoder_padding_mask"
    ]
  },
  "berard": [
    "args"
  ],
  "berard_256_3_3": [
    "args"
  ],
  "berard_512_3_2": [
    "args"
  ],
  "berard_512_5_3": [
    "args"
  ],
  "Conv1dAdaptor": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "n_layers",
      "kernel_size",
      "stride",
      "layerdrop",
      "layernorm",
      "proj"
    ],
    "add_args": [
      "cls",
      "parser"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask"
    ]
  },
  "add_wav2vec_asr_args": [
    "parser"
  ],
  "need_finetuning": [
    "ft_params",
    "param_name"
  ],
  "Wav2VecEncoderWithAdaptor": {
    "build_adaptor": [
      "self",
      "args"
    ],
    "__init__": [
      "self",
      "args"
    ],
    "add_args": [
      "cls",
      "parser"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ]
  },
  "add_decoder_args": [
    "parser"
  ],
  "remove_weight_norm_from_model": [
    "model"
  ],
  "XMTransformerModel": {
    "hub_models": [
      "cls"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "checkpoint_file",
      "data_name_or_path",
      "config_yaml"
    ],
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "cls",
      "parser"
    ],
    "maybe_load_pretrained": [
      "cls",
      "component",
      "checkpoint"
    ],
    "build_encoder": [
      "cls",
      "args"
    ],
    "get_decoder_args_from_checkpoint": [
      "cls",
      "ckpt_args"
    ],
    "override_decoder_args": [
      "cls",
      "cli_args",
      "decoder_args_dict"
    ],
    "build_decoder": [
      "cls",
      "args",
      "task",
      "embed_tokens"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens"
    ],
    "upgrade_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "set_default_w2v_encoder_args": [
    "args"
  ],
  "set_default_adaptor_args": [
    "args"
  ],
  "set_default_transformer_decoder_args": [
    "args"
  ],
  "set_default_general_args": [
    "args"
  ],
  "HubertConfig": {},
  "HubertModel": {
    "__init__": [
      "self",
      "cfg",
      "task_cfg",
      "dictionaries"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "build_model": [
      "cls",
      "cfg",
      "task"
    ],
    "apply_mask": [
      "self",
      "x",
      "padding_mask",
      "target_list"
    ],
    "compute_nce": [
      "self",
      "x",
      "pos",
      "negs"
    ],
    "forward_features": [
      "self",
      "source"
    ],
    "forward_targets": [
      "self",
      "features",
      "target_list"
    ],
    "forward_padding_mask": [
      "self",
      "features",
      "padding_mask"
    ],
    "forward": [
      "self",
      "source",
      "target_list",
      "padding_mask",
      "mask",
      "features_only",
      "output_layer"
    ],
    "extract_features": [
      "self",
      "source",
      "padding_mask",
      "mask",
      "ret_conv",
      "output_layer"
    ],
    "get_logits": [
      "self",
      "net_output",
      "is_masked"
    ],
    "get_targets": [
      "self",
      "net_output",
      "is_masked"
    ],
    "get_extra_losses": [
      "self",
      "net_output"
    ],
    "remove_pretraining_modules": [
      "self"
    ]
  },
  "HubertAsrConfig": {},
  "HubertCtcConfig": {},
  "HubertCtc": {
    "__init__": [
      "self",
      "cfg",
      "w2v_encoder"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "build_model": [
      "cls",
      "cfg",
      "task"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs"
    ],
    "get_logits": [
      "self",
      "net_output"
    ],
    "forward": [
      "self"
    ]
  },
  "HubertSeq2SeqConfig": {},
  "HubertEncoder": {
    "__init__": [
      "self",
      "cfg",
      "task"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "forward": [
      "self",
      "source",
      "padding_mask",
      "tbc"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ],
    "max_positions": [
      "self"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "MegatronTrainer": {
    "__init__": [
      "self",
      "cfg",
      "task",
      "model",
      "criterion"
    ],
    "clip_grad_norm": [
      "self",
      "clip_norm"
    ],
    "save_checkpoint": [
      "self",
      "filename",
      "extra_state"
    ],
    "load_checkpoint": [
      "self",
      "filename",
      "reset_optimizer",
      "reset_lr_scheduler",
      "optimizer_overrides",
      "reset_meters"
    ]
  },
  "VocabParallelCrossEntropyCriterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "ModelParallelTransformerModel": {
    "build_embedding": [
      "cls",
      "args",
      "dictionary",
      "embed_dim",
      "path"
    ],
    "build_encoder": [
      "cls",
      "args",
      "src_dict",
      "embed_tokens"
    ],
    "build_decoder": [
      "cls",
      "args",
      "tgt_dict",
      "embed_tokens"
    ]
  },
  "ModelParallelTransformerEncoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens"
    ],
    "build_encoder_layer": [
      "self",
      "args"
    ]
  },
  "ModelParallelTransformerDecoder": {
    "build_decoder_layer": [
      "self",
      "args",
      "no_encoder_attn"
    ],
    "output_layer": [
      "self",
      "features"
    ]
  },
  "ModelParallelTransformerLanguageModel": {
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "build_embedding": [
      "cls",
      "args",
      "dictionary",
      "embed_dim",
      "path"
    ]
  },
  "transformer_lm_megatron": [
    "args"
  ],
  "transformer_lm_megatron_11b": [
    "args"
  ],
  "ModelParallelRobertaModel": {
    "__init__": [
      "self",
      "args",
      "encoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "forward": [
      "self",
      "src_tokens",
      "features_only",
      "return_all_hiddens",
      "classification_head_name"
    ],
    "register_classification_head": [
      "self",
      "name",
      "num_classes",
      "inner_dim"
    ]
  },
  "ModelParallelRobertaLMHead": {
    "__init__": [
      "self",
      "embed_dim",
      "output_dim",
      "activation_fn",
      "weight"
    ],
    "forward": [
      "self",
      "features",
      "masked_tokens"
    ]
  },
  "ModelParallelRobertaClassificationHead": {
    "__init__": [
      "self",
      "input_dim",
      "inner_dim",
      "num_classes",
      "activation_fn",
      "pooler_dropout"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "ModelParallelRobertaEncoder": {
    "__init__": [
      "self",
      "args",
      "dictionary"
    ],
    "build_embedding": [
      "self",
      "vocab_size",
      "embedding_dim",
      "padding_idx"
    ],
    "build_encoder": [
      "self",
      "args",
      "dictionary",
      "embed_tokens"
    ],
    "build_lm_head": [
      "self",
      "embed_dim",
      "output_dim",
      "activation_fn",
      "weight"
    ]
  },
  "model_parallel_roberta_v1_architecture": [
    "args"
  ],
  "model_parallel_roberta_postnorm_architecture": [
    "args"
  ],
  "model_parallel_roberta_base_architecture": [
    "args"
  ],
  "model_parallel_roberta_large_architecture": [
    "args"
  ],
  "TORCH_PIPE": [],
  "RPC_INIT": [],
  "import_pipe": [],
  "PipelineParallelTransformerModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder",
      "balance",
      "devices",
      "chunks",
      "checkpoint"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens"
    ],
    "prepare_for_inference_": [
      "self",
      "cfg"
    ],
    "add_args": [
      "parser"
    ],
    "build_model_base": [
      "cls",
      "args",
      "task"
    ],
    "build_encoder": [
      "cls",
      "args",
      "src_dict",
      "embed_tokens"
    ],
    "build_decoder": [
      "cls",
      "args",
      "tgt_dict",
      "embed_tokens"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "output_layer": [
      "self",
      "features"
    ],
    "max_positions": [
      "self"
    ],
    "max_positions_helper": [
      "self",
      "embedding_layer",
      "max_positions_field"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "max_decoder_positions": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict",
      "model_cfg"
    ],
    "convert_to_pipeline_parallel_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "transformer_iwslt_de_en_dist": [
    "args"
  ],
  "transformer_wmt_en_de_big_dist": [
    "args"
  ],
  "TransformerEncoderEmbedding": {
    "__init__": [
      "self",
      "args",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TransformerEncoderLayerNorm": {
    "__init__": [
      "self",
      "args",
      "embed_dim"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TransformerDecoderEmbedding": {
    "__init__": [
      "self",
      "args",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TransformerDecoderOutputLayer": {
    "__init__": [
      "self",
      "args",
      "embed_tokens",
      "dictionary"
    ],
    "forward": [
      "self",
      "input",
      "apply_final_proj"
    ],
    "output_layer": [
      "self",
      "features"
    ]
  },
  "TransformerEncoderLayer": {
    "__init__": [
      "self",
      "args"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "forward": [
      "self",
      "input"
    ],
    "maybe_layer_norm": [
      "self",
      "layer_norm",
      "x",
      "before",
      "after"
    ]
  },
  "TransformerDecoderLayer": {
    "__init__": [
      "self",
      "args",
      "no_encoder_attn",
      "add_bias_kv",
      "add_zero_attn"
    ],
    "prepare_for_onnx_export_": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "buffered_future_mask": [
      "self",
      "tensor"
    ],
    "maybe_layer_norm": [
      "self",
      "layer_norm",
      "x",
      "before",
      "after"
    ],
    "make_generation_fast_": [
      "self",
      "need_attn"
    ]
  },
  "ModelParallelTransformerEncoderLayer": {
    "build_fc1": [
      "self",
      "input_dim",
      "output_dim",
      "q_noise",
      "qn_block_size"
    ],
    "build_fc2": [
      "self",
      "input_dim",
      "output_dim",
      "q_noise",
      "qn_block_size"
    ],
    "build_self_attention": [
      "self",
      "embed_dim",
      "args"
    ]
  },
  "ModelParallelTransformerDecoderLayer": {
    "build_fc1": [
      "self",
      "input_dim",
      "output_dim",
      "q_noise",
      "qn_block_size"
    ],
    "build_fc2": [
      "self",
      "input_dim",
      "output_dim",
      "q_noise",
      "qn_block_size"
    ],
    "build_self_attention": [
      "self",
      "embed_dim",
      "args"
    ],
    "build_encoder_attention": [
      "self",
      "embed_dim",
      "args"
    ]
  },
  "ModelParallelMultiheadAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "kdim",
      "vdim",
      "dropout",
      "bias",
      "self_attention",
      "encoder_decoder_attention"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask",
      "incremental_state",
      "static_kv",
      "attn_mask"
    ],
    "_append_prev_key_padding_mask": [
      "key_padding_mask",
      "prev_key_padding_mask",
      "batch_size",
      "src_len",
      "static_kv"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "_get_input_buffer": [
      "self",
      "incremental_state"
    ],
    "_set_input_buffer": [
      "self",
      "incremental_state",
      "buffer"
    ]
  },
  "DynamicConv": [
    "input_size",
    "kernel_size",
    "padding_l",
    "num_heads",
    "weight_dropout",
    "weight_softmax",
    "renorm_padding",
    "bias",
    "conv_bias",
    "query_size",
    "in_proj"
  ],
  "DynamicConv1dTBC": {
    "__init__": [
      "self",
      "input_size",
      "kernel_size",
      "padding_l",
      "num_heads",
      "weight_dropout",
      "weight_softmax",
      "renorm_padding",
      "bias",
      "conv_bias",
      "query_size",
      "in_proj"
    ],
    "in_proj": [
      "self"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "incremental_state",
      "query",
      "unfold"
    ],
    "_forward_unfolded": [
      "self",
      "x",
      "incremental_state",
      "query"
    ],
    "_forward_expanded": [
      "self",
      "x",
      "incremental_stat",
      "query"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "_get_input_buffer": [
      "self",
      "incremental_state"
    ],
    "_set_input_buffer": [
      "self",
      "incremental_state",
      "new_buffer"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "_cross_entropy_pytorch": [
    "logits",
    "target",
    "ignore_index",
    "reduction"
  ],
  "SamePad": {
    "__init__": [
      "self",
      "kernel_size",
      "causal"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FairseqDropout": {
    "__init__": [
      "self",
      "p",
      "module_name"
    ],
    "forward": [
      "self",
      "x",
      "inplace"
    ],
    "make_generation_fast_": [
      "self",
      "name",
      "retain_dropout",
      "retain_dropout_modules"
    ]
  },
  "BaseLayer": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "input_features"
    ],
    "inverse_sort": [
      "self",
      "order"
    ],
    "balanced_assignment": [
      "self",
      "scores"
    ],
    "greedy_assignment": [
      "self",
      "scores",
      "k"
    ],
    "load_assignment": [
      "self"
    ]
  },
  "BaseSublayer": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "xs"
    ]
  },
  "All2All": {
    "forward": [
      "ctx",
      "xs",
      "input_splits",
      "output_splits"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "PositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate",
      "max_len",
      "reverse"
    ],
    "extend_pe": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RelPositionalEncoding": {
    "__init__": [
      "self",
      "max_len",
      "d_model"
    ],
    "extend_pe": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CHAR_PAD_IDX": [],
  "CHAR_EOS_IDX": [],
  "CharacterTokenEmbedder": {
    "__init__": [
      "self",
      "vocab",
      "filters",
      "char_embed_dim",
      "word_embed_dim",
      "highway_layers",
      "max_char_len",
      "char_inputs"
    ],
    "prepare_for_onnx_export_": [
      "self"
    ],
    "set_vocab": [
      "self",
      "vocab",
      "max_char_len"
    ],
    "padding_idx": [
      "self"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "_convolve": [
      "self",
      "char_idxs"
    ]
  },
  "Highway": {
    "__init__": [
      "self",
      "input_dim",
      "num_layers"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SparseTransformerSentenceEncoder": {
    "__init__": [
      "self",
      "padding_idx",
      "vocab_size",
      "num_encoder_layers",
      "embedding_dim",
      "ffn_embedding_dim",
      "num_attention_heads",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "max_seq_len",
      "num_segments",
      "use_position_embeddings",
      "offset_positions_by_padding",
      "encoder_normalize_before",
      "apply_bert_init",
      "activation_fn",
      "learned_pos_embedding",
      "embed_scale",
      "freeze_embeddings",
      "n_trans_layers_to_freeze",
      "export",
      "is_bidirectional",
      "stride",
      "expressivity"
    ]
  },
  "TiedLinear": {
    "__init__": [
      "self",
      "weight",
      "transpose"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TiedHeadModule": {
    "__init__": [
      "self",
      "weights",
      "input_dim",
      "num_classes",
      "q_noise",
      "qn_block_size"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "AdaptiveSoftmax": {
    "__init__": [
      "self",
      "vocab_size",
      "input_dim",
      "cutoff",
      "dropout",
      "factor",
      "adaptive_inputs",
      "tie_proj",
      "q_noise",
      "qn_block_size"
    ],
    "_make_tail": [
      "self",
      "adaptive_inputs",
      "tie_proj"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "adapt_target": [
      "self",
      "target"
    ],
    "forward": [
      "self",
      "input",
      "target"
    ],
    "get_log_prob": [
      "self",
      "input",
      "target"
    ]
  },
  "EMAModuleConfig": {},
  "EMAModule": {
    "__init__": [
      "self",
      "model",
      "config",
      "device",
      "skip_keys"
    ],
    "build_fp32_params": [
      "self",
      "state_dict"
    ],
    "restore": [
      "self",
      "state_dict",
      "build_fp32_params"
    ],
    "set_decay": [
      "self",
      "decay"
    ],
    "get_decay": [
      "self"
    ],
    "_step_internal": [
      "self",
      "new_model"
    ],
    "step": [
      "self",
      "new_model"
    ],
    "reverse": [
      "self",
      "model"
    ]
  },
  "SingleHeadAttention": {
    "__init__": [
      "self",
      "out_channels",
      "embed_dim",
      "head_dim",
      "head_index",
      "dropout",
      "bias",
      "project_input",
      "gated",
      "downsample",
      "num_heads"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask_future_timesteps",
      "key_padding_mask",
      "use_scalar_bias"
    ]
  },
  "DownsampledMultiHeadAttention": {
    "__init__": [
      "self",
      "out_channels",
      "embed_dim",
      "num_heads",
      "dropout",
      "bias",
      "project_input",
      "gated",
      "downsample"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask_future_timesteps",
      "key_padding_mask",
      "use_scalar_bias"
    ]
  },
  "Downsample": {
    "__init__": [
      "self",
      "index"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GatedLinear": [
    "in_features",
    "out_features",
    "dropout",
    "bias"
  ],
  "BeamableMM": {
    "__init__": [
      "self",
      "beam_size"
    ],
    "forward": [
      "self",
      "input1",
      "input2"
    ],
    "set_beam_size": [
      "self",
      "beam_size"
    ]
  },
  "quant_noise": [
    "module",
    "p",
    "block_size"
  ],
  "TransformerEncoderLayerBase": {
    "__init__": [
      "self",
      "cfg",
      "return_fc"
    ],
    "_load_from_state_dict": [
      "self",
      "state_dict",
      "prefix",
      "local_metadata",
      "strict",
      "missing_keys",
      "unexpected_keys",
      "error_msgs"
    ],
    "build_fc1": [
      "self",
      "input_dim",
      "output_dim",
      "q_noise",
      "qn_block_size"
    ],
    "build_fc2": [
      "self",
      "input_dim",
      "output_dim",
      "q_noise",
      "qn_block_size"
    ],
    "_get_fc_rank": [
      "self",
      "remove_num"
    ],
    "_prune_fc_layer": [
      "self",
      "remove_index"
    ],
    "build_self_attention": [
      "self",
      "embed_dim",
      "cfg"
    ],
    "residual_connection": [
      "self",
      "x",
      "residual"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "forward": [
      "self",
      "x",
      "encoder_padding_mask",
      "attn_mask"
    ]
  },
  "TransformerDecoderLayerBase": {
    "__init__": [
      "self",
      "cfg",
      "no_encoder_attn",
      "add_bias_kv",
      "add_zero_attn"
    ],
    "build_fc1": [
      "self",
      "input_dim",
      "output_dim",
      "q_noise",
      "qn_block_size"
    ],
    "build_fc2": [
      "self",
      "input_dim",
      "output_dim",
      "q_noise",
      "qn_block_size"
    ],
    "build_self_attention": [
      "self",
      "embed_dim",
      "cfg",
      "add_bias_kv",
      "add_zero_attn"
    ],
    "build_encoder_attention": [
      "self",
      "embed_dim",
      "cfg"
    ],
    "prepare_for_onnx_export_": [
      "self"
    ],
    "residual_connection": [
      "self",
      "x",
      "residual"
    ],
    "forward": [
      "self",
      "x",
      "encoder_out",
      "encoder_padding_mask",
      "incremental_state",
      "prev_self_attn_state",
      "prev_attn_state",
      "self_attn_mask",
      "self_attn_padding_mask",
      "need_attn",
      "need_head_weights"
    ],
    "make_generation_fast_": [
      "self",
      "need_attn"
    ]
  },
  "LSTMCellWithZoneOut": {
    "__init__": [
      "self",
      "prob",
      "input_size",
      "hidden_size",
      "bias"
    ],
    "zoneout": [
      "self",
      "h",
      "next_h",
      "prob"
    ],
    "forward": [
      "self",
      "x",
      "h"
    ]
  },
  "TransposeLast": {
    "__init__": [
      "self",
      "deconstruct_idx"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "gelu_accurate": [
    "x"
  ],
  "gelu": [
    "x"
  ],
  "SinusoidalPositionalEmbedding": {
    "__init__": [
      "self",
      "embedding_dim",
      "padding_idx",
      "init_size"
    ],
    "prepare_for_onnx_export_": [
      "self"
    ],
    "get_embedding": [
      "num_embeddings",
      "embedding_dim",
      "padding_idx"
    ],
    "forward": [
      "self",
      "input",
      "incremental_state",
      "timestep",
      "positions"
    ]
  },
  "LayerDropModuleList": {
    "__init__": [
      "self",
      "p",
      "modules"
    ],
    "__iter__": [
      "self"
    ]
  },
  "ESPNETMultiHeadedAttention": {
    "__init__": [
      "self",
      "n_feat",
      "n_head",
      "dropout"
    ],
    "forward_qkv": [
      "self",
      "query",
      "key",
      "value"
    ],
    "forward_attention": [
      "self",
      "value",
      "scores",
      "mask"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask"
    ]
  },
  "RelPositionMultiHeadedAttention": {
    "__init__": [
      "self",
      "n_feat",
      "n_head",
      "dropout",
      "zero_triu"
    ],
    "rel_shift": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "pos_emb",
      "key_padding_mask"
    ]
  },
  "RotaryPositionMultiHeadedAttention": {
    "__init__": [
      "self",
      "n_feat",
      "n_head",
      "dropout",
      "precision",
      "rotary_emd_base"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask"
    ]
  },
  "LayerNorm": [
    "normalized_shape",
    "eps",
    "elementwise_affine",
    "export"
  ],
  "Fp32LayerNorm": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "LinearizedConvolution": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "forward": [
      "self",
      "input",
      "incremental_state"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "_get_input_buffer": [
      "self",
      "incremental_state"
    ],
    "_set_input_buffer": [
      "self",
      "incremental_state",
      "new_buffer"
    ],
    "_get_linearized_weight": [
      "self"
    ],
    "_clear_linearized_weight": [
      "self"
    ]
  },
  "init_bert_params": [
    "module"
  ],
  "TransformerSentenceEncoder": {
    "__init__": [
      "self",
      "padding_idx",
      "vocab_size",
      "num_encoder_layers",
      "embedding_dim",
      "ffn_embedding_dim",
      "num_attention_heads",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "layerdrop",
      "max_seq_len",
      "num_segments",
      "use_position_embeddings",
      "offset_positions_by_padding",
      "encoder_normalize_before",
      "apply_bert_init",
      "activation_fn",
      "learned_pos_embedding",
      "embed_scale",
      "freeze_embeddings",
      "n_trans_layers_to_freeze",
      "export",
      "traceable",
      "q_noise",
      "qn_block_size"
    ],
    "build_embedding": [
      "self",
      "vocab_size",
      "embedding_dim",
      "padding_idx"
    ],
    "build_transformer_sentence_encoder_layer": [
      "self",
      "embedding_dim",
      "ffn_embedding_dim",
      "num_attention_heads",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "activation_fn",
      "export",
      "q_noise",
      "qn_block_size"
    ],
    "forward": [
      "self",
      "tokens",
      "segment_labels",
      "last_state_only",
      "positions",
      "token_embeddings",
      "attn_mask"
    ]
  },
  "LightweightConv": [
    "input_size",
    "kernel_size",
    "padding_l",
    "num_heads",
    "weight_dropout",
    "weight_softmax",
    "bias"
  ],
  "LightweightConv1d": {
    "__init__": [
      "self",
      "input_size",
      "kernel_size",
      "padding",
      "num_heads",
      "weight_softmax",
      "bias",
      "weight_dropout"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "LightweightConv1dTBC": {
    "__init__": [
      "self",
      "input_size",
      "kernel_size",
      "padding_l",
      "num_heads",
      "weight_dropout",
      "weight_softmax",
      "bias"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "incremental_state",
      "unfold"
    ],
    "prepare_for_onnx_export_": [
      "self"
    ],
    "_forward_unfolded": [
      "self",
      "x",
      "incremental_state"
    ],
    "_forward_expanded": [
      "self",
      "x",
      "incremental_state"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "_get_input_buffer": [
      "self",
      "incremental_state"
    ],
    "_set_input_buffer": [
      "self",
      "incremental_state",
      "new_buffer"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "unfold1d": [
    "x",
    "kernel_size",
    "padding_l",
    "pad_value"
  ],
  "ConvolutionModule": {
    "__init__": [
      "self",
      "embed_dim",
      "channels",
      "depthwise_kernel_size",
      "dropout",
      "activation_fn",
      "bias",
      "export"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FeedForwardModule": {
    "__init__": [
      "self",
      "input_feat",
      "hidden_units",
      "dropout1",
      "dropout2",
      "activation_fn",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConformerEncoderLayer": {
    "__init__": [
      "self",
      "embed_dim",
      "ffn_embed_dim",
      "attention_heads",
      "dropout",
      "use_fp16",
      "depthwise_conv_kernel_size",
      "activation_fn",
      "attn_type",
      "pos_enc_type"
    ],
    "forward": [
      "self",
      "x",
      "encoder_padding_mask",
      "position_emb"
    ]
  },
  "ConformerWav2Vec2EncoderLayer": {
    "forward": [
      "self",
      "x",
      "self_attn_mask",
      "self_attn_padding_mask",
      "need_weights",
      "att_args",
      "position_emb"
    ]
  },
  "AdaptiveInput": {
    "__init__": [
      "self",
      "vocab_size",
      "padding_idx",
      "initial_dim",
      "factor",
      "output_dim",
      "cutoff",
      "q_noise",
      "qn_block_size"
    ],
    "weights_for_band": [
      "self",
      "band"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "RotaryPositionalEmbedding": {
    "__init__": [
      "self",
      "dim",
      "base",
      "precision"
    ],
    "forward": [
      "self",
      "x",
      "seq_len"
    ]
  },
  "rotate_half": [
    "x"
  ],
  "apply_rotary_pos_emb": [
    "q",
    "k",
    "cos",
    "sin",
    "offset"
  ],
  "logsumexp": [
    "x",
    "dim"
  ],
  "DynamicCRF": {
    "__init__": [
      "self",
      "num_embedding",
      "low_rank",
      "beam_size"
    ],
    "extra_repr": [
      "self"
    ],
    "forward": [
      "self",
      "emissions",
      "targets",
      "masks",
      "beam"
    ],
    "forward_decoder": [
      "self",
      "emissions",
      "masks",
      "beam"
    ],
    "_compute_score": [
      "self",
      "emissions",
      "targets",
      "masks"
    ],
    "_compute_normalizer": [
      "self",
      "emissions",
      "targets",
      "masks",
      "beam"
    ],
    "_viterbi_decode": [
      "self",
      "emissions",
      "masks",
      "beam"
    ]
  },
  "SparseTransformerSentenceEncoderLayer": {
    "__init__": [
      "self",
      "embedding_dim",
      "ffn_embedding_dim",
      "num_attention_heads",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "activation_fn",
      "export",
      "is_bidirectional",
      "stride",
      "expressivity"
    ]
  },
  "KmeansVectorQuantizer": {
    "__init__": [
      "self",
      "dim",
      "num_vars",
      "groups",
      "combine_groups",
      "vq_dim",
      "time_first",
      "gamma"
    ],
    "_pass_grad": [
      "self",
      "x",
      "y"
    ],
    "expand_embedding": [
      "self"
    ],
    "forward_idx": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x",
      "produce_targets"
    ]
  },
  "_mask_for_xformers": [
    "mask",
    "to_dtype"
  ],
  "MultiheadAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "kdim",
      "vdim",
      "dropout",
      "bias",
      "add_bias_kv",
      "add_zero_attn",
      "self_attention",
      "encoder_decoder_attention",
      "q_noise",
      "qn_block_size",
      "xformers_att_config",
      "xformers_blocksparse_layout",
      "xformers_blocksparse_blocksize"
    ],
    "prepare_for_onnx_export_": [
      "self"
    ],
    "reset_parameters": [
      "self"
    ],
    "_get_reserve_head_index": [
      "self",
      "num_heads_to_keep"
    ],
    "_adaptive_prune_heads": [
      "self",
      "reserve_head_index"
    ],
    "_set_skip_embed_dim_check": [
      "self"
    ],
    "_pad_masks": [
      "self",
      "key_padding_mask",
      "attn_mask"
    ],
    "_add_bias": [
      "self",
      "k",
      "v",
      "key_padding_mask",
      "attn_mask",
      "bsz"
    ],
    "_append_zero_attn": [
      "self",
      "k",
      "v",
      "key_padding_mask",
      "attn_mask"
    ],
    "_xformers_attn_forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask",
      "need_weights",
      "attn_mask"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask",
      "incremental_state",
      "need_weights",
      "static_kv",
      "attn_mask",
      "before_softmax",
      "need_head_weights"
    ],
    "_append_prev_key_padding_mask": [
      "key_padding_mask",
      "prev_key_padding_mask",
      "batch_size",
      "src_len",
      "static_kv"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "set_beam_size": [
      "self",
      "beam_size"
    ],
    "_get_input_buffer": [
      "self",
      "incremental_state"
    ],
    "_set_input_buffer": [
      "self",
      "incremental_state",
      "buffer"
    ],
    "apply_sparse_mask": [
      "self",
      "attn_weights",
      "tgt_len",
      "src_len",
      "bsz"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "GumbelVectorQuantizer": {
    "__init__": [
      "self",
      "dim",
      "num_vars",
      "temp",
      "groups",
      "combine_groups",
      "vq_dim",
      "time_first",
      "activation",
      "weight_proj_depth",
      "weight_proj_factor"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "get_codebook_indices": [
      "self"
    ],
    "codebook": [
      "self"
    ],
    "sample_from_codebook": [
      "self",
      "b",
      "n"
    ],
    "to_codebook_index": [
      "self",
      "indices"
    ],
    "forward_idx": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x",
      "produce_targets"
    ]
  },
  "LearnedPositionalEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "padding_idx"
    ],
    "forward": [
      "self",
      "input",
      "incremental_state",
      "positions"
    ]
  },
  "LocationAttention": {
    "__init__": [
      "self",
      "attn_dim",
      "encoder_dim",
      "decoder_dim",
      "attn_state_kernel_size",
      "conv_dim",
      "conv_kernel_size",
      "scaling"
    ],
    "clear_cache": [
      "self"
    ],
    "forward": [
      "self",
      "encoder_out",
      "encoder_padding_mask",
      "decoder_h",
      "attn_state"
    ]
  },
  "Fp32InstanceNorm": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ScalarBias": {
    "forward": [
      "ctx",
      "input",
      "dim",
      "bias_init"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "scalar_bias": [
    "input",
    "dim",
    "bias_init"
  ],
  "_pair": [
    "v"
  ],
  "infer_conv_output_dim": [
    "conv_op",
    "input_dim",
    "sample_inchannel"
  ],
  "VGGBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "conv_kernel_size",
      "pooling_kernel_size",
      "num_conv_layers",
      "input_dim",
      "conv_stride",
      "padding",
      "layer_norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "checkpoint_wrapper": [
    "m",
    "offload_to_cpu"
  ],
  "unwrap_checkpoint": [
    "m"
  ],
  "_checkpointed_forward": [
    "original_forward",
    "offload_to_cpu"
  ],
  "pack_kwargs": [],
  "unpack_kwargs": [
    "kwarg_keys",
    "flat_args"
  ],
  "split_non_tensors": [
    "mixed"
  ],
  "unpack_non_tensors": [
    "tensors",
    "packed_non_tensors"
  ],
  "CheckpointFunction": {
    "forward": [
      "ctx",
      "run_function",
      "parent_ctx_dict",
      "kwarg_keys"
    ],
    "backward": [
      "ctx"
    ]
  },
  "Fp32BatchNorm": {
    "__init__": [
      "self",
      "sync"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "GradMultiply": {
    "forward": [
      "ctx",
      "x",
      "scale"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "Fp32GroupNorm": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TOKEN_SELF_ATTN_VALUE": [],
  "KMEAN_INIT_ITERS": [],
  "exists": [
    "val"
  ],
  "identity": [
    "x"
  ],
  "default": [
    "x",
    "d"
  ],
  "cast_tuple": [
    "x"
  ],
  "cache_fn": [
    "f"
  ],
  "to": [
    "t"
  ],
  "find_modules": [
    "nn_module",
    "type"
  ],
  "is_empty": [
    "t"
  ],
  "max_neg_value": [
    "tensor"
  ],
  "batched_index_select": [
    "values",
    "indices"
  ],
  "merge_dims": [
    "ind_from",
    "ind_to",
    "tensor"
  ],
  "expand_dim": [
    "t",
    "dim",
    "k"
  ],
  "scatter_mean": [
    "src",
    "t",
    "index",
    "dim",
    "eps"
  ],
  "split_at_index": [
    "dim",
    "index",
    "t"
  ],
  "reshape_dim": [
    "t",
    "dim",
    "split_dims"
  ],
  "ema": [
    "old",
    "new",
    "decay"
  ],
  "ema_inplace": [
    "moving_avg",
    "new",
    "decay"
  ],
  "map_first_tuple_or_el": [
    "x",
    "fn"
  ],
  "Chunk": {
    "__init__": [
      "self",
      "chunks",
      "fn",
      "along_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PreNorm": {
    "__init__": [
      "self",
      "norm_class",
      "dim",
      "fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ReZero": {
    "__init__": [
      "self",
      "fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ScaleNorm": {
    "__init__": [
      "self",
      "dim",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ProjectInOut": {
    "__init__": [
      "self",
      "fn",
      "dim_in",
      "dim_out",
      "project_out"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MatrixMultiply": {
    "__init__": [
      "self",
      "tensor",
      "transpose"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DepthWiseConv1d": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "kernel_size",
      "stride",
      "bias",
      "causal"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FixedPositionalEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_seq_len"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "rotate_every_two": [
    "x"
  ],
  "update_kmeans_on_backwards": [
    "module"
  ],
  "similarity": [
    "x",
    "means"
  ],
  "dists_and_buckets": [
    "x",
    "means"
  ],
  "batched_bincount": [
    "index",
    "num_classes",
    "dim"
  ],
  "kmeans_iter": [
    "x",
    "means",
    "buckets"
  ],
  "distribution": [
    "dists",
    "window_size"
  ],
  "Kmeans": {
    "__init__": [
      "self",
      "num_heads",
      "head_dim",
      "num_clusters",
      "ema_decay",
      "commitment"
    ],
    "init": [
      "self",
      "x"
    ],
    "update": [
      "self",
      "new_means"
    ],
    "forward": [
      "self",
      "x",
      "update_means"
    ]
  },
  "KmeansAttention": {
    "__init__": [
      "self",
      "num_clusters",
      "window_size",
      "num_heads",
      "head_dim",
      "causal",
      "dropout",
      "ema_decay",
      "commitment",
      "context_window_size",
      "receives_context",
      "num_mem_kv",
      "shared_qk"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "query_mask",
      "key_mask"
    ]
  },
  "GELU_": {
    "forward": [
      "self",
      "x"
    ]
  },
  "GELU": [],
  "FeedForward": {
    "__init__": [
      "self",
      "dim",
      "mult",
      "dropout",
      "activation",
      "glu"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SparseMultiheadAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "kdim",
      "vdim",
      "dropout",
      "bias",
      "add_bias_kv",
      "add_zero_attn",
      "self_attention",
      "encoder_decoder_attention",
      "stride",
      "expressivity",
      "is_bidirectional"
    ],
    "compute_checkpoint": [
      "self",
      "word_index"
    ],
    "compute_subset_summaries": [
      "self",
      "absolute_max"
    ],
    "compute_fixed_attention_subset": [
      "self",
      "word_index",
      "tgt_len"
    ],
    "buffered_sparse_mask": [
      "self",
      "tensor",
      "tgt_len",
      "src_len"
    ],
    "apply_sparse_mask": [
      "self",
      "attn_weights",
      "tgt_len",
      "src_len",
      "bsz"
    ]
  },
  "gen_forward": [],
  "gen_backward": [],
  "dynamicconvFunction": {
    "forward": [
      "ctx",
      "x",
      "weights",
      "padding_l"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "DynamicconvLayer": {
    "__init__": [
      "self",
      "input_size",
      "kernel_size",
      "padding_l",
      "weight_softmax",
      "num_heads",
      "weight_dropout",
      "bias",
      "renorm_padding",
      "conv_bias",
      "query_size"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "incremental_state",
      "query",
      "unfold"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "_get_input_buffer": [
      "self",
      "incremental_state"
    ],
    "_set_input_buffer": [
      "self",
      "incremental_state",
      "new_buffer"
    ],
    "_forward_unfolded": [
      "self",
      "x",
      "incremental_state",
      "query"
    ],
    "_forward_expanded": [
      "self",
      "x",
      "incremental_stat",
      "query"
    ]
  },
  "lightconvFunction": {
    "forward": [
      "ctx",
      "x",
      "weights",
      "padding_l"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "LightconvLayer": {
    "__init__": [
      "self",
      "input_size",
      "kernel_size",
      "padding_l",
      "weight_softmax",
      "num_heads",
      "weight_dropout",
      "bias"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "incremental_state"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "_get_input_buffer": [
      "self",
      "incremental_state"
    ],
    "_set_input_buffer": [
      "self",
      "incremental_state",
      "new_buffer"
    ],
    "half": [
      "self"
    ]
  },
  "parse_config_yaml": [
    "yaml_data"
  ],
  "convert_yaml_to_tuple": [
    "yaml_dictionary"
  ],
  "EM": {
    "__init__": [
      "self",
      "W",
      "n_centroids",
      "n_iter",
      "eps",
      "max_tentatives",
      "verbose"
    ],
    "initialize_centroids": [
      "self"
    ],
    "step": [
      "self",
      "i"
    ],
    "resolve_empty_clusters": [
      "self"
    ],
    "compute_distances": [
      "self"
    ],
    "assign": [
      "self"
    ],
    "save": [
      "self",
      "path",
      "layer"
    ],
    "load": [
      "self",
      "path",
      "layer"
    ]
  },
  "EmptyClusterResolveError": {},
  "quantize_model_": [
    "model",
    "size_tracker",
    "layers_to_quantize",
    "block_sizes_config",
    "n_centroids_config",
    "step",
    "n_iter",
    "eps",
    "max_tentatives",
    "remove_weights",
    "verbose",
    "state_dict"
  ],
  "get_layers": [
    "model",
    "filter_regexp",
    "remove_weights"
  ],
  "get_param": [
    "module",
    "layer_name",
    "param_config"
  ],
  "SizeTracker": {
    "__init__": [
      "self",
      "model"
    ],
    "compute_size": [
      "self"
    ],
    "update": [
      "self",
      "W",
      "block_size",
      "n_centroids"
    ],
    "__repr__": [
      "self"
    ]
  },
  "attrsetter": [],
  "PQ": {
    "__init__": [
      "self",
      "W",
      "block_size",
      "n_centroids",
      "n_iter",
      "eps",
      "max_tentatives",
      "verbose"
    ],
    "_reshape": [
      "self",
      "W"
    ],
    "encode": [
      "self"
    ],
    "decode": [
      "self"
    ]
  },
  "PQEmbedding": {
    "__init__": [
      "self",
      "centroids",
      "assignments",
      "num_embeddings",
      "embedding_dim",
      "padding_idx",
      "max_norm",
      "norm_type",
      "scale_grad_by_freq",
      "sparse",
      "_weight"
    ],
    "weight": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "PQLinear": {
    "__init__": [
      "self",
      "centroids",
      "assignments",
      "bias",
      "in_features",
      "out_features"
    ],
    "weight": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "PQConv2d": {
    "__init__": [
      "self",
      "centroids",
      "assignments",
      "bias",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "padding_mode"
    ],
    "weight": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "MAPPING": [],
  "emulate_int": [
    "w",
    "bits",
    "method",
    "scale",
    "zero_point"
  ],
  "quantize": [
    "w",
    "scale",
    "zero_point",
    "bits"
  ],
  "emulate_int8_histogram": [
    "w",
    "scale",
    "zero_point",
    "bits"
  ],
  "emulate_int8_channel": [
    "w",
    "scale",
    "zero_point",
    "bits"
  ],
  "emulate_int8_tensor": [
    "w",
    "scale",
    "zero_point",
    "bits"
  ],
  "IntEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "padding_idx",
      "max_norm",
      "norm_type",
      "scale_grad_by_freq",
      "sparse",
      "_weight",
      "p",
      "update_step",
      "bits",
      "method"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "IntLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "p",
      "update_step",
      "bits",
      "method"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "ActivationQuantizer": {
    "__init__": [
      "self",
      "module",
      "p",
      "update_step",
      "bits",
      "method",
      "clamp_threshold"
    ],
    "register_hook": [
      "self"
    ]
  },
  "IntConv2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "padding_mode",
      "p",
      "bits",
      "method",
      "update_step"
    ],
    "_conv_forward": [
      "self",
      "input",
      "weight"
    ],
    "forward": [
      "self",
      "input"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "main": [],
  "TruncatedBPTTLMConfig": {},
  "TruncatedBPTTLMTask": {
    "__init__": [
      "self",
      "cfg"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "dataset": [
      "self",
      "split"
    ],
    "get_batch_iterator": [
      "self",
      "dataset",
      "num_workers",
      "epoch",
      "data_buffer_size",
      "skip_remainder_batch"
    ],
    "_collate_fn": [
      "self",
      "items"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "inference_step": [
      "self",
      "generator",
      "models",
      "sample",
      "prefix_tokens",
      "constraints"
    ],
    "eval_lm_dataloader": [
      "self",
      "dataset",
      "max_tokens",
      "batch_size",
      "max_positions",
      "num_shards",
      "shard_id",
      "num_workers",
      "data_buffer_size",
      "context_window"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ]
  },
  "TruncatedBPTTDataset": {
    "__init__": [
      "self",
      "data",
      "bsz_per_shard",
      "shard_id",
      "num_shards"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ]
  },
  "TransformerXLConfig": {},
  "TransformerXLLanguageModel": {
    "build_model": [
      "cls",
      "cfg",
      "task"
    ]
  },
  "TransformerXLDecoder": {
    "__init__": [
      "self",
      "cfg",
      "task"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "incremental_state",
      "encoder_out"
    ],
    "max_positions": [
      "self"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ]
  },
  "add_asr_eval_argument": [
    "parser"
  ],
  "check_args": [
    "args"
  ],
  "get_dataset_itr": [
    "args",
    "task",
    "models"
  ],
  "process_predictions": [
    "args",
    "hypos",
    "sp",
    "tgt_dict",
    "target_tokens",
    "res_files",
    "speaker",
    "id"
  ],
  "prepare_result_files": [
    "args"
  ],
  "optimize_models": [
    "args",
    "use_cuda",
    "models"
  ],
  "apply_half": [
    "t"
  ],
  "ExistingEmissionsDecoder": {
    "__init__": [
      "self",
      "decoder",
      "emissions"
    ],
    "generate": [
      "self",
      "models",
      "sample"
    ]
  },
  "make_parser": [],
  "cli_main": [],
  "W2lDecoder": {
    "__init__": [
      "self",
      "args",
      "tgt_dict"
    ],
    "generate": [
      "self",
      "models",
      "sample"
    ],
    "get_emissions": [
      "self",
      "models",
      "encoder_input"
    ],
    "get_tokens": [
      "self",
      "idxs"
    ]
  },
  "W2lViterbiDecoder": {
    "__init__": [
      "self",
      "args",
      "tgt_dict"
    ],
    "decode": [
      "self",
      "emissions"
    ]
  },
  "W2lKenLMDecoder": {
    "__init__": [
      "self",
      "args",
      "tgt_dict"
    ],
    "get_timesteps": [
      "self",
      "token_idxs"
    ],
    "decode": [
      "self",
      "emissions"
    ]
  },
  "FairseqLMState": [],
  "FairseqLM": {
    "__init__": [
      "self",
      "dictionary",
      "model"
    ],
    "start": [
      "self",
      "start_with_nothing"
    ],
    "score": [
      "self",
      "state",
      "token_index",
      "no_cache"
    ],
    "finish": [
      "self",
      "state"
    ],
    "empty_cache": [
      "self"
    ]
  },
  "W2lFairseqLMDecoder": {
    "__init__": [
      "self",
      "args",
      "tgt_dict"
    ],
    "decode": [
      "self",
      "emissions"
    ]
  },
  "script_dir": [],
  "config_path": [],
  "KaldiInitializerConfig": {},
  "create_units": [
    "fst_dir",
    "in_labels",
    "vocab"
  ],
  "create_lexicon": [
    "cfg",
    "fst_dir",
    "unique_label",
    "in_units_file",
    "out_words_file"
  ],
  "create_G": [
    "kaldi_root",
    "fst_dir",
    "lm_arpa",
    "arpa_base"
  ],
  "create_L": [
    "kaldi_root",
    "fst_dir",
    "unique_label",
    "lexicon_file",
    "in_units_file",
    "out_words_file"
  ],
  "create_LG": [
    "kaldi_root",
    "fst_dir",
    "unique_label",
    "lexicon_graph",
    "grammar_graph"
  ],
  "create_H": [
    "kaldi_root",
    "fst_dir",
    "disambig_out_units_file",
    "in_labels",
    "vocab",
    "blk_sym",
    "silence_symbol"
  ],
  "create_HLGa": [
    "kaldi_root",
    "fst_dir",
    "unique_label",
    "h_graph",
    "lg_graph",
    "disambig_in_words_file_int"
  ],
  "create_HLa": [
    "kaldi_root",
    "fst_dir",
    "unique_label",
    "h_graph",
    "l_graph",
    "disambig_in_words_file_int"
  ],
  "create_HLG": [
    "kaldi_root",
    "fst_dir",
    "unique_label",
    "hlga_graph",
    "prefix"
  ],
  "initalize_kaldi": [
    "cfg"
  ],
  "KaldiDecoderConfig": {},
  "KaldiDecoder": {
    "__init__": [
      "self",
      "cfg",
      "beam",
      "nbest"
    ],
    "generate": [
      "self",
      "models",
      "sample"
    ],
    "get_emissions": [
      "self",
      "models",
      "encoder_input"
    ],
    "decode_one": [
      "self",
      "logits",
      "padding"
    ],
    "decode": [
      "self",
      "emissions",
      "padding"
    ]
  },
  "MILLISECONDS_TO_SECONDS": [],
  "process_sample": [
    "aud_path",
    "lable",
    "utt_id",
    "sp",
    "tgt_dict"
  ],
  "DecodingConfig": {},
  "InferConfig": {},
  "InferenceProcessor": {
    "__init__": [
      "self",
      "cfg"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "log": [
      "self"
    ],
    "print": [
      "self"
    ],
    "get_res_file": [
      "self",
      "fname"
    ],
    "merge_shards": [
      "self"
    ],
    "optimize_model": [
      "self",
      "model"
    ],
    "load_model_ensemble": [
      "self"
    ],
    "get_dataset_itr": [
      "self",
      "disable_iterator_cache"
    ],
    "build_progress_bar": [
      "self",
      "epoch",
      "prefix",
      "default_log_format"
    ],
    "data_parallel_world_size": [
      "self"
    ],
    "data_parallel_rank": [
      "self"
    ],
    "process_sentence": [
      "self",
      "sample",
      "hypo",
      "sid",
      "batch_id"
    ],
    "process_sample": [
      "self",
      "sample"
    ],
    "log_generation_time": [
      "self"
    ]
  },
  "parse_wer": [
    "wer_file"
  ],
  "get_wer_file": [
    "cfg"
  ],
  "hydra_main": [
    "cfg"
  ],
  "KenLMDecoder": {
    "__init__": [
      "self",
      "cfg",
      "tgt_dict"
    ],
    "get_timesteps": [
      "self",
      "token_idxs"
    ],
    "decode": [
      "self",
      "emissions"
    ]
  },
  "FairseqLMDecoder": {
    "__init__": [
      "self",
      "cfg",
      "tgt_dict"
    ],
    "decode": [
      "self",
      "emissions"
    ]
  },
  "Decoder": [
    "cfg",
    "tgt_dict"
  ],
  "DECODER_CHOICES": [],
  "FlashlightDecoderConfig": {},
  "ViterbiDecoder": {
    "decode": [
      "self",
      "emissions"
    ]
  },
  "BaseDecoder": {
    "__init__": [
      "self",
      "tgt_dict"
    ],
    "generate": [
      "self",
      "models",
      "sample"
    ],
    "get_emissions": [
      "self",
      "models",
      "encoder_input"
    ],
    "get_tokens": [
      "self",
      "idxs"
    ],
    "decode": [
      "self",
      "emissions"
    ]
  },
  "Code": {
    "match": [],
    "substitution": [],
    "insertion": [],
    "deletion": []
  },
  "Token": {
    "__init__": [
      "self",
      "lbl",
      "st",
      "en"
    ]
  },
  "AlignmentResult": {
    "__init__": [
      "self",
      "refs",
      "hyps",
      "codes",
      "score"
    ]
  },
  "coordinate_to_offset": [
    "row",
    "col",
    "ncols"
  ],
  "offset_to_row": [
    "offset",
    "ncols"
  ],
  "offset_to_col": [
    "offset",
    "ncols"
  ],
  "trimWhitespace": [
    "str"
  ],
  "str2toks": [
    "str"
  ],
  "EditDistance": {
    "__init__": [
      "self",
      "time_mediated"
    ],
    "cost": [
      "self",
      "ref",
      "hyp",
      "code"
    ],
    "get_result": [
      "self",
      "refs",
      "hyps"
    ],
    "align": [
      "self",
      "refs",
      "hyps"
    ]
  },
  "WERTransformer": {
    "__init__": [
      "self",
      "hyp_str",
      "ref_str",
      "verbose"
    ],
    "process": [
      "self",
      "input"
    ],
    "report_result": [
      "self"
    ],
    "wer": [
      "self"
    ],
    "stats": [
      "self"
    ]
  },
  "calc_wer": [
    "hyp_str",
    "ref_str"
  ],
  "calc_wer_stats": [
    "hyp_str",
    "ref_str"
  ],
  "get_wer_alignment_codes": [
    "hyp_str",
    "ref_str"
  ],
  "merge_counts": [
    "x",
    "y"
  ],
  "files_to_skip": [],
  "CrossEntropyWithAccCriterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg"
    ],
    "compute_loss": [
      "self",
      "model",
      "net_output",
      "target",
      "reduction",
      "log_probs"
    ],
    "get_logging_output": [
      "self",
      "sample",
      "target",
      "lprobs",
      "loss"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduction",
      "log_probs"
    ],
    "aggregate_logging_outputs": [
      "logging_outputs"
    ]
  },
  "ASGCriterion": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "task",
      "silence_token",
      "asg_transitions_init",
      "max_replabel",
      "linseg_updates",
      "hide_linseg_messages"
    ],
    "build_criterion": [
      "cls",
      "args",
      "task"
    ],
    "linseg_step": [
      "self"
    ],
    "replace_eos_with_silence": [
      "self",
      "tgt"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "aggregate_logging_outputs": [
      "logging_outputs"
    ]
  },
  "replabel_symbol": [
    "i"
  ],
  "pack_replabels": [
    "tokens",
    "dictionary",
    "max_reps"
  ],
  "unpack_replabels": [
    "tokens",
    "dictionary",
    "max_reps"
  ],
  "AsrDataset": {
    "__init__": [
      "self",
      "aud_paths",
      "aud_durations_ms",
      "tgt",
      "tgt_dict",
      "ids",
      "speakers",
      "num_mel_bins",
      "frame_length",
      "frame_shift"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ]
  },
  "Seq2SeqCollater": {
    "__init__": [
      "self",
      "feature_index",
      "label_index",
      "pad_index",
      "eos_index",
      "move_eos_to_beginning"
    ],
    "_collate_frames": [
      "self",
      "frames"
    ],
    "collate": [
      "self",
      "samples"
    ]
  },
  "calc_mean_invstddev": [
    "feature"
  ],
  "apply_mv_norm": [
    "features"
  ],
  "encoder_padding_mask_to_lengths": [
    "encoder_padding_mask",
    "max_lengths",
    "batch_size",
    "device"
  ],
  "get_asr_dataset_from_json": [
    "data_json_path",
    "tgt_dict"
  ],
  "SpeechRecognitionTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "tgt_dict"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "load_dataset": [
      "self",
      "split",
      "combine"
    ],
    "build_generator": [
      "self",
      "models",
      "args"
    ],
    "target_dictionary": [
      "self"
    ],
    "source_dictionary": [
      "self"
    ],
    "max_positions": [
      "self"
    ]
  },
  "VGGTransformerModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_encoder": [
      "cls",
      "args",
      "task"
    ],
    "build_decoder": [
      "cls",
      "args",
      "task"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ]
  },
  "DEFAULT_ENC_VGGBLOCK_CONFIG": [],
  "DEFAULT_ENC_TRANSFORMER_CONFIG": [],
  "DEFAULT_DEC_TRANSFORMER_CONFIG": [],
  "DEFAULT_DEC_CONV_CONFIG": [],
  "prepare_transformer_encoder_params": [
    "input_dim",
    "num_heads",
    "ffn_dim",
    "normalize_before",
    "dropout",
    "attention_dropout",
    "relu_dropout"
  ],
  "prepare_transformer_decoder_params": [
    "input_dim",
    "num_heads",
    "ffn_dim",
    "normalize_before",
    "dropout",
    "attention_dropout",
    "relu_dropout"
  ],
  "VGGTransformerEncoder": {
    "__init__": [
      "self",
      "input_feat_per_channel",
      "vggblock_config",
      "transformer_config",
      "encoder_output_dim",
      "in_channels",
      "transformer_context",
      "transformer_sampling"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "infer_conv_output_dim": [
      "self",
      "in_channels",
      "input_dim"
    ],
    "validate_transformer_config": [
      "self",
      "transformer_config"
    ],
    "parse_transformer_context": [
      "self",
      "transformer_context"
    ],
    "parse_transformer_sampling": [
      "self",
      "transformer_sampling",
      "num_layers"
    ],
    "slice": [
      "self",
      "embedding",
      "padding_mask",
      "attn_mask",
      "sampling_factor"
    ],
    "lengths_to_attn_mask": [
      "self",
      "input_lengths",
      "subsampling_factor"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ]
  },
  "VGGTransformerEncoderModel": {
    "__init__": [
      "self",
      "encoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ]
  },
  "VGGTransformerEncoderOnly": {
    "__init__": [
      "self",
      "vocab_size",
      "input_feat_per_channel",
      "vggblock_config",
      "transformer_config",
      "encoder_output_dim",
      "in_channels",
      "transformer_context",
      "transformer_sampling"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "max_positions": [
      "self"
    ]
  },
  "vggtransformer_1": [
    "args"
  ],
  "vggtransformer_2": [
    "args"
  ],
  "vggtransformer_base": [
    "args"
  ],
  "base_architecture_enconly": [
    "args"
  ],
  "vggtransformer_enc_1": [
    "args"
  ],
  "default_conv_enc_config": [],
  "W2lConvGluEncoderModel": {
    "__init__": [
      "self",
      "encoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ]
  },
  "W2lConvGluEncoder": {
    "__init__": [
      "self",
      "vocab_size",
      "input_feat_per_channel",
      "in_channels",
      "conv_enc_config"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ],
    "max_positions": [
      "self"
    ]
  },
  "w2l_conv_glu_enc": [
    "args"
  ],
  "gen_and_reprocess_nbest": [
    "args"
  ],
  "random_search": [
    "args"
  ],
  "reprocess": [
    "fle"
  ],
  "reprocess_nbest": [
    "fle"
  ],
  "write_reprocessed": [
    "sources",
    "hypos",
    "targets",
    "source_outfile",
    "hypo_outfile",
    "target_outfile",
    "right_to_left",
    "prefix_len",
    "bpe_symbol",
    "target_prefix_frac",
    "source_prefix_frac"
  ],
  "calc_length_from_frac": [
    "bpe_sentence",
    "prefix_frac",
    "bpe_symbol"
  ],
  "get_prefix": [
    "sentence",
    "prefix_len"
  ],
  "get_prefix_no_bpe": [
    "sentence",
    "bpe_symbol",
    "prefix_len"
  ],
  "get_prefix_from_len": [
    "sentence",
    "bpe_symbol",
    "prefix_len"
  ],
  "get_num_bpe_tokens_from_len": [
    "sentence",
    "bpe_symbol",
    "prefix_len"
  ],
  "make_right_to_left": [
    "line"
  ],
  "remove_bpe": [
    "line",
    "bpe_symbol"
  ],
  "remove_bpe_dict": [
    "pred_dict",
    "bpe_symbol"
  ],
  "parse_bleu_scoring": [
    "line"
  ],
  "get_full_from_prefix": [
    "hypo_prefix",
    "hypos"
  ],
  "get_score": [
    "a",
    "b",
    "c",
    "target_len",
    "bitext_score1",
    "bitext_score2",
    "lm_score",
    "lenpen",
    "src_len",
    "tgt_len",
    "bitext1_backwards",
    "bitext2_backwards",
    "normalize"
  ],
  "BitextOutput": {
    "__init__": [
      "self",
      "output_file",
      "backwards",
      "right_to_left",
      "bpe_symbol",
      "prefix_len",
      "target_prefix_frac",
      "source_prefix_frac"
    ]
  },
  "BitextOutputFromGen": {
    "__init__": [
      "self",
      "predictions_bpe_file",
      "bpe_symbol",
      "nbest",
      "prefix_len",
      "target_prefix_frac"
    ]
  },
  "get_score_from_pos": [
    "pos_score_dict",
    "prefix_len",
    "hypo_dict",
    "bpe_symbol",
    "hypo_frac",
    "backwards"
  ],
  "LMOutput": {
    "__init__": [
      "self",
      "lm_score_file",
      "lm_dict",
      "prefix_len",
      "bpe_symbol",
      "target_prefix_frac"
    ]
  },
  "parse_lm": [
    "input_file",
    "prefix_len",
    "bpe_symbol",
    "target_prefix_frac"
  ],
  "get_directories": [
    "data_dir_name",
    "num_rescore",
    "gen_subset",
    "fw_name",
    "shard_id",
    "num_shards",
    "sampling",
    "prefix_len",
    "target_prefix_frac",
    "source_prefix_frac"
  ],
  "lm_scoring": [
    "preprocess_directory",
    "bpe_status",
    "gen_output",
    "pre_gen",
    "cur_lm_dict",
    "cur_lm_name",
    "cur_language_model",
    "cur_lm_bpe_code",
    "batch_size",
    "lm_score_file",
    "target_lang",
    "source_lang",
    "prefix_len"
  ],
  "rescore_file_name": [
    "nbest_dir",
    "prefix_len",
    "scorer_name",
    "lm_file",
    "target_prefix_frac",
    "source_prefix_frac",
    "backwards"
  ],
  "get_reranking_parser": [
    "default_task"
  ],
  "get_tuning_parser": [
    "default_task"
  ],
  "add_reranking_args": [
    "parser"
  ],
  "add_tuning_args": [
    "parser"
  ],
  "score_target_hypo": [
    "args",
    "a",
    "b",
    "c",
    "lenpen",
    "target_outfile",
    "hypo_outfile",
    "write_hypos",
    "normalize"
  ],
  "match_target_hypo": [
    "args",
    "target_outfile",
    "hypo_outfile"
  ],
  "load_score_files": [
    "args"
  ],
  "rerank": [
    "args"
  ],
  "score_bw": [
    "args"
  ],
  "score_lm": [
    "args"
  ],
  "OOVIndexError": {
    "__init__": [
      "self",
      "pos",
      "source_seq",
      "target_seq"
    ]
  },
  "replace_oovs": [
    "source_in",
    "target_in",
    "target_out"
  ],
  "TransformerPointerGeneratorModel": {
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "build_encoder": [
      "cls",
      "args",
      "src_dict",
      "embed_tokens"
    ],
    "build_decoder": [
      "cls",
      "args",
      "tgt_dict",
      "embed_tokens"
    ]
  },
  "TransformerPointerGeneratorEncoder": {
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens",
      "token_embeddings"
    ]
  },
  "TransformerPointerGeneratorDecoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "features_only",
      "alignment_layer",
      "alignment_heads",
      "src_lengths",
      "return_all_hiddens"
    ],
    "output_layer": [
      "self",
      "features",
      "attn",
      "src_tokens",
      "p_gens"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ]
  },
  "transformer_pointer_generator": [
    "args"
  ],
  "transformer_pointer_generator_iwslt_de_en": [
    "args"
  ],
  "transformer_pointer_generator_wmt_en_de": [
    "args"
  ],
  "transformer_pointer_generator_vaswani_wmt_en_de_big": [
    "args"
  ],
  "transformer_pointer_generator_vaswani_wmt_en_fr_big": [
    "args"
  ],
  "transformer_pointer_generator_wmt_en_de_big": [
    "args"
  ],
  "transformer_pointer_generator_wmt_en_de_big_t2t": [
    "args"
  ],
  "preprocess": [
    "spm_model_path",
    "train_path",
    "valid_path",
    "test_path",
    "dest_dir",
    "remove_empty",
    "output_format",
    "workers"
  ],
  "MultiprocessingEncoder": {
    "__init__": [
      "self",
      "model",
      "remove_empty",
      "output_format"
    ],
    "initializer": [
      "self"
    ],
    "encode": [
      "self",
      "line"
    ]
  },
  "write_lines": [
    "lines",
    "path"
  ],
  "read_jsonl": [
    "path"
  ],
  "read_nli": [
    "path",
    "langs"
  ],
  "MultilingualTranslationTaskLatentDepth": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "dicts",
      "training"
    ],
    "_per_lang_pair_train_loss": [
      "self",
      "lang_pair",
      "model",
      "update_num",
      "criterion",
      "sample",
      "optimizer",
      "ignore_grad"
    ],
    "train_step": [
      "self",
      "sample",
      "model",
      "criterion",
      "optimizer",
      "update_num",
      "ignore_grad"
    ],
    "_per_lang_pair_valid_loss": [
      "self",
      "lang_pair",
      "model",
      "criterion",
      "sample"
    ],
    "inference_step": [
      "self",
      "generator",
      "models",
      "sample",
      "prefix_tokens",
      "constraints"
    ],
    "encoder_latent_layer": [
      "self"
    ],
    "decoder_latent_layer": [
      "self"
    ],
    "src_lang_idx_dict": [
      "self"
    ],
    "tgt_lang_idx_dict": [
      "self"
    ]
  },
  "LatentLayersKLLoss": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "layer_samples",
      "lang_idx",
      "update_num",
      "sample_size"
    ]
  },
  "LatentLayersSparsityLoss": {
    "__init__": [
      "self",
      "args"
    ],
    "is_valid": [
      "self",
      "update_num"
    ],
    "forward": [
      "self",
      "layer_samples_list",
      "update_num",
      "sample_size"
    ]
  },
  "LatentMultilingualTransformerModel": {
    "add_args": [
      "parser"
    ],
    "_get_module_class": [
      "cls",
      "is_encoder",
      "args",
      "lang_dict",
      "embed_tokens",
      "langs"
    ]
  },
  "latent_multilingual_architecture": [
    "args"
  ],
  "LatentTransformerEncoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens",
      "num_logits"
    ],
    "set_lang_idx": [
      "self",
      "lang_idx"
    ],
    "_build_encoder_layer": [
      "self",
      "args",
      "idx"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens"
    ]
  },
  "LatentTransformerEncoderLayer": {
    "__init__": [
      "self",
      "args",
      "idx",
      "layer_select"
    ],
    "residual_connection": [
      "self",
      "x",
      "residual"
    ]
  },
  "LatentTransformerDecoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens",
      "no_encoder_attn",
      "num_logits"
    ],
    "set_lang_idx": [
      "self",
      "lang_idx"
    ],
    "_build_decoder_layer": [
      "self",
      "args",
      "no_encoder_attn",
      "idx"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "features_only",
      "alignment_layer",
      "alignment_heads",
      "src_lengths",
      "return_all_hiddens"
    ]
  },
  "LatentTransformerDecoderLayer": {
    "__init__": [
      "self",
      "args",
      "idx",
      "layer_select",
      "no_encoder_attn",
      "add_bias_kv",
      "add_zero_attn"
    ],
    "residual_connection": [
      "self",
      "x",
      "residual"
    ]
  },
  "LayerSelect": {
    "__init__": [
      "self",
      "num_layers",
      "num_logits",
      "soft_select",
      "sampling_tau"
    ],
    "sample": [
      "self",
      "logit_idx"
    ],
    "forward": [
      "self",
      "i"
    ],
    "_gumbel_sigmoid": [
      "self",
      "logits",
      "tau",
      "hard",
      "eps",
      "dim",
      "threshold"
    ]
  },
  "dump_result": [
    "args",
    "sample_id",
    "pred_wav",
    "suffix"
  ],
  "load_code": [
    "in_file"
  ],
  "BenchmarkingBase": {
    "__init__": [
      "self"
    ],
    "warm_up": [
      "self",
      "sample",
      "repeat"
    ],
    "benchmark_run_time": [
      "self",
      "dataset",
      "repeat"
    ],
    "benchmark_run_time_single_sample": [
      "self",
      "sample",
      "repeat"
    ],
    "count_flops": [
      "self",
      "dataset",
      "repeat"
    ],
    "max_memory": [
      "self",
      "dataset",
      "repeat"
    ],
    "gather_all_metrics": [
      "self",
      "dataset",
      "repeat"
    ],
    "dump_final_speech_output": [
      "self",
      "dataset",
      "output_dir",
      "resample_fn",
      "sample_rate",
      "prefix"
    ]
  },
  "Processing": {
    "__init__": [
      "self",
      "args"
    ],
    "setUp": [
      "self",
      "cfg"
    ],
    "encode_source": [
      "self",
      "src"
    ],
    "decode_target": [
      "self",
      "hypos"
    ],
    "forward": [
      "self",
      "sample"
    ]
  },
  "GenerateWaveformFromCode": {
    "__init__": [
      "self",
      "args"
    ],
    "format_units": [
      "self",
      "input"
    ],
    "generate_vocoder_input": [
      "self",
      "dataset"
    ],
    "forward": [
      "self",
      "sample"
    ]
  },
  "HubertUnitExtractor": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "sample"
    ]
  },
  "SpeechGeneration": {
    "__init__": [
      "self",
      "args"
    ],
    "setUp": [
      "self",
      "args"
    ],
    "processTextInput": [
      "self",
      "text"
    ],
    "forward": [
      "self",
      "sample"
    ]
  },
  "S2UT": {
    "__init__": [
      "self",
      "s2u_args",
      "vocoder_args"
    ],
    "forward": [
      "self",
      "sample"
    ],
    "generate_s2u_outputs": [
      "self",
      "dataset"
    ],
    "compute_metrics": [
      "self",
      "metric_type",
      "dataset",
      "repeat"
    ],
    "benchmark_run_time": [
      "self",
      "dataset",
      "repeat"
    ],
    "count_flops": [
      "self",
      "dataset",
      "repeat"
    ],
    "max_memory": [
      "self",
      "dataset",
      "repeat"
    ]
  },
  "Cascaded2StageS2ST": {
    "__init__": [
      "self",
      "s2t_args",
      "tts_args"
    ],
    "forward": [
      "self",
      "sample"
    ],
    "generate_s2t_outputs": [
      "self",
      "dataset"
    ],
    "generate_tts_inputs": [
      "self",
      "dataset"
    ],
    "compute_metrics": [
      "self",
      "metric_type",
      "dataset",
      "repeat"
    ],
    "benchmark_run_time": [
      "self",
      "dataset",
      "repeat"
    ],
    "count_flops": [
      "self",
      "dataset",
      "repeat"
    ],
    "max_memory": [
      "self",
      "dataset",
      "repeat"
    ]
  },
  "Cascaded3StageS2ST": {
    "__init__": [
      "self",
      "s2t_args",
      "tts_args",
      "mt_args"
    ],
    "forward": [
      "self",
      "sample"
    ],
    "generate_mt_inputs": [
      "self",
      "dataset"
    ],
    "generate_mt_outputs": [
      "self",
      "dataset"
    ],
    "compute_metrics": [
      "self",
      "metric_type",
      "dataset",
      "repeat"
    ]
  },
  "random_number_generator": [],
  "generate_random_data_sample": [
    "T",
    "B",
    "D"
  ],
  "generate_random_dataset": [
    "T_range_min",
    "T_range_max",
    "B",
    "D",
    "dataset_size"
  ],
  "load_dataset_npy": [
    "file_name",
    "dataset_size"
  ],
  "load_dataset_raw_to_waveforms": [
    "file_name",
    "dataset_size",
    "need_waveform",
    "sample_rate",
    "read_using_soundfile"
  ],
  "load_dataset_task": [
    "args",
    "batch_size",
    "limit_size",
    "ref_dataset"
  ],
  "randomly_sample_subset": [
    "dataset",
    "size"
  ],
  "get_short_data_subset": [
    "dataset",
    "size"
  ],
  "get_long_data_subset": [
    "dataset",
    "size"
  ],
  "sort_dataset": [
    "dataset",
    "reverse"
  ],
  "save_dataset_npy": [
    "dataset",
    "file_name"
  ],
  "get_dataset_stats": [
    "dataset"
  ],
  "get_ids_from_dataset": [
    "dataset"
  ],
  "MANIFEST_COLUMNS": [],
  "process": [
    "args"
  ],
  "prepare_target_data": [
    "args",
    "tgt_audios"
  ],
  "gen_config_yaml": [
    "manifest_root",
    "yaml_filename",
    "specaugment_policy",
    "feature_transform",
    "input_channels",
    "input_feat_per_channel",
    "audio_root",
    "vocoder_type",
    "vocoder_checkpoint",
    "vocoder_cfg",
    "extra"
  ],
  "load_units": [
    "in_file"
  ],
  "process_units": [
    "units",
    "reduce"
  ],
  "Batch": [],
  "pool_init_variables": [],
  "init_loaded_scores": [
    "mt_scores",
    "model_scores",
    "hyp",
    "ref"
  ],
  "parse_fairseq_gen": [
    "filename",
    "task"
  ],
  "read_target": [
    "filename"
  ],
  "make_batches": [
    "args",
    "src",
    "hyp",
    "task",
    "max_positions",
    "encode_fn"
  ],
  "decode_rerank_scores": [
    "args"
  ],
  "get_best_hyps": [
    "mt_scores",
    "md_scores",
    "hypos",
    "fw_weight",
    "lenpen",
    "beam"
  ],
  "eval_metric": [
    "args",
    "hypos",
    "ref"
  ],
  "print_result": [
    "best_scores",
    "best_hypos",
    "output_file"
  ],
  "_EPSILON": [],
  "TARGET_DIST_NORM_CHOICES": [],
  "KLDivergenceRerankingCriterionConfig": {},
  "KLDivergenceRerankingCriterion": {
    "__init__": [
      "self",
      "task",
      "target_dist_norm",
      "temperature",
      "forward_batch_size"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "compute_kl_loss": [
      "self",
      "logits",
      "target"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "TARGET_METRIC_CHOICES": [],
  "DiscriminativeRerankingNMTConfig": {},
  "RerankerScorer": {
    "__init__": [
      "self",
      "args",
      "mt_beam"
    ],
    "generate": [
      "self",
      "models",
      "sample"
    ]
  },
  "DiscriminativeRerankingNMTTask": {
    "__init__": [
      "self",
      "cfg",
      "data_dictionary"
    ],
    "load_dictionary": [
      "cls",
      "cfg",
      "filename"
    ],
    "setup_task": [
      "cls",
      "cfg"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "build_dataset_for_inference": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "build_model": [
      "self",
      "cfg",
      "from_checkpoint"
    ],
    "build_generator": [
      "self",
      "args"
    ],
    "max_positions": [
      "self"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ],
    "create_dummy_batch": [
      "self",
      "device"
    ],
    "train_step": [
      "self",
      "sample",
      "model",
      "criterion",
      "optimizer",
      "update_num",
      "ignore_grad"
    ],
    "valid_step": [
      "self",
      "sample",
      "model",
      "criterion"
    ],
    "reduce_metrics": [
      "self",
      "logging_outputs",
      "criterion"
    ]
  },
  "ACTIVATION_FN_CHOICES": [],
  "JOINT_CLASSIFICATION_CHOICES": [],
  "SENTENCE_REP_CHOICES": [],
  "update_init_roberta_model_state": [
    "state"
  ],
  "BaseRanker": {
    "__init__": [
      "self",
      "args",
      "task"
    ],
    "forward": [
      "self",
      "src_tokens"
    ],
    "get_segment_labels": [
      "self",
      "src_tokens"
    ],
    "get_positions": [
      "self",
      "src_tokens",
      "segment_labels"
    ]
  },
  "BertRanker": {
    "__init__": [
      "self",
      "args",
      "task"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "sentence_forward": [
      "self",
      "encoder_out",
      "src_tokens",
      "sentence_rep"
    ],
    "joint_forward": [
      "self",
      "x"
    ],
    "classification_forward": [
      "self",
      "x"
    ]
  },
  "DiscriminativeNMTRerankerConfig": {},
  "DiscriminativeNMTReranker": {
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "__init__": [
      "self",
      "args",
      "model"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "sentence_forward": [
      "self",
      "encoder_out",
      "src_tokens"
    ],
    "joint_forward": [
      "self",
      "x"
    ],
    "classification_forward": [
      "self",
      "x"
    ]
  },
  "read_text_file": [
    "filename"
  ],
  "get_bleu": [
    "in_sent",
    "target_sent"
  ],
  "get_ter": [
    "in_sent",
    "target_sent"
  ],
  "init": [
    "sp_model"
  ],
  "Data2VecAudioConfig": {},
  "get_annealed_rate": [
    "start",
    "end",
    "curr_step",
    "total_steps"
  ],
  "Data2VecAudioModel": {
    "__init__": [
      "self",
      "cfg"
    ],
    "make_ema_teacher": [
      "self"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "_load_from_state_dict": [
      "self",
      "state_dict",
      "prefix"
    ],
    "build_model": [
      "cls",
      "cfg",
      "task"
    ],
    "apply_mask": [
      "self",
      "x",
      "padding_mask",
      "mask_indices",
      "mask_channel_indices"
    ],
    "_get_feat_extract_output_lengths": [
      "self",
      "input_lengths"
    ],
    "forward": [
      "self",
      "source",
      "padding_mask",
      "mask",
      "features_only",
      "layer",
      "mask_indices",
      "mask_channel_indices",
      "padding_count"
    ],
    "compute_var": [
      "y"
    ],
    "extract_features": [
      "self",
      "source",
      "padding_mask",
      "mask",
      "layer"
    ],
    "remove_pretraining_modules": [
      "self",
      "last_layer"
    ]
  },
  "Data2VecTextConfig": {},
  "Data2VecTextModel": {
    "__init__": [
      "self",
      "cfg",
      "encoder"
    ],
    "build_model": [
      "cls",
      "cfg",
      "task"
    ],
    "forward": [
      "self",
      "src_tokens",
      "target_tokens",
      "features_only",
      "return_all_hiddens",
      "classification_head_name"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "register_classification_head": [
      "self",
      "name",
      "num_classes",
      "inner_dim"
    ],
    "supported_targets": [
      "self"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ],
    "remove_pretraining_modules": [
      "self",
      "last_layer"
    ]
  },
  "Data2VecTextEncoder": {
    "__init__": [
      "self",
      "cfg",
      "dictionary",
      "task_data"
    ],
    "build_embedding": [
      "self",
      "vocab_size",
      "embedding_dim",
      "padding_idx"
    ],
    "build_encoder": [
      "self",
      "cfg",
      "dictionary",
      "embed_tokens"
    ],
    "build_lm_head": [
      "self",
      "embed_dim",
      "output_dim",
      "activation_fn",
      "weight"
    ],
    "make_ema_teacher": [
      "self"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "_load_from_state_dict": [
      "self",
      "state_dict",
      "prefix"
    ],
    "forward": [
      "self",
      "src_tokens",
      "target_tokens",
      "features_only",
      "return_all_hiddens",
      "masked_tokens"
    ],
    "extract_features": [
      "self",
      "src_tokens",
      "return_all_hiddens"
    ],
    "output_layer": [
      "self",
      "features",
      "masked_tokens"
    ],
    "max_positions": [
      "self"
    ]
  },
  "InputExample": {
    "__init__": [
      "self",
      "paragraph",
      "qa_list",
      "label"
    ]
  },
  "get_examples": [
    "data_dir",
    "set_type"
  ],
  "CommonsenseQATask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "vocab"
    ],
    "load_dictionary": [
      "cls",
      "filename"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine",
      "data_path",
      "return_only"
    ],
    "build_model": [
      "self",
      "args",
      "from_checkpoint"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ]
  },
  "WSCTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "vocab"
    ],
    "load_dictionary": [
      "cls",
      "filename"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "binarize": [
      "self",
      "s",
      "append_eos"
    ],
    "binarize_with_mask": [
      "self",
      "txt",
      "prefix",
      "suffix",
      "leading_space",
      "trailing_space"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine",
      "data_path",
      "return_only"
    ],
    "build_dataset_for_inference": [
      "self",
      "sample_json"
    ],
    "disambiguate_pronoun": [
      "self",
      "model",
      "sentence",
      "use_cuda"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ]
  },
  "WinograndeTask": {
    "setup_task": [
      "cls",
      "args"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine",
      "data_path",
      "return_only"
    ]
  },
  "convert_sentence_to_json": [
    "sentence"
  ],
  "extended_noun_chunks": [
    "sentence"
  ],
  "find_token": [
    "sentence",
    "start_pos"
  ],
  "find_span": [
    "sentence",
    "search_text",
    "start"
  ],
  "get_detokenizer": [],
  "get_spacy_nlp": [],
  "jsonl_iterator": [
    "input_fname",
    "positive_only",
    "ngram_order",
    "eval"
  ],
  "winogrande_jsonl_iterator": [
    "input_fname",
    "eval"
  ],
  "filter_noun_chunks": [
    "chunks",
    "exclude_pronouns",
    "exclude_query",
    "exact_match"
  ],
  "WSCCriterion": {
    "__init__": [
      "self",
      "args",
      "task"
    ],
    "__del__": [
      "self"
    ],
    "add_args": [
      "parser"
    ],
    "get_masked_input": [
      "self",
      "tokens",
      "mask"
    ],
    "get_lprobs": [
      "self",
      "model",
      "tokens",
      "mask"
    ],
    "get_loss": [
      "self",
      "query_lprobs",
      "cand_lprobs"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "aggregate_logging_outputs": [
      "logging_outputs"
    ]
  },
  "WinograndeCriterion": {
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ]
  },
  "FilesDataset": {
    "__init__": [
      "self",
      "files",
      "labels"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collate": [
      "self",
      "batch"
    ]
  },
  "ArgTypes": {
    "existing_path": [
      "arg"
    ],
    "mkdir": [
      "arg"
    ]
  },
  "DatasetWriter": {
    "__init__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "attr"
    ],
    "read_manifest": [
      "self",
      "fname"
    ],
    "process_splits": [
      "self"
    ],
    "iterate": [
      "self",
      "files"
    ],
    "lbl_file": [
      "self",
      "name"
    ],
    "data_file": [
      "self",
      "name"
    ],
    "var_file": [
      "self"
    ],
    "load_config": [
      "self"
    ],
    "load_data": [
      "self",
      "fnames"
    ],
    "load_model": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "read_audio": [
    "fname"
  ],
  "PretrainedWav2VecModel": {
    "__init__": [
      "self",
      "fname"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EmbeddingWriterConfig": {
    "__init__": [
      "self"
    ]
  },
  "Prediction": {
    "__init__": [
      "self",
      "fname",
      "gpu"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "H5Writer": {
    "__init__": [
      "self",
      "fname"
    ],
    "write": [
      "self",
      "data"
    ]
  },
  "EmbeddingDatasetWriter": {
    "__init__": [
      "self",
      "input_root",
      "output_root",
      "split",
      "model_fname",
      "extension",
      "gpu",
      "verbose",
      "use_feat"
    ],
    "_progress": [
      "self",
      "iterable"
    ],
    "require_output_path": [
      "self",
      "fname"
    ],
    "input_path": [
      "self"
    ],
    "output_path": [
      "self"
    ],
    "get_input_path": [
      "self",
      "fname"
    ],
    "get_output_path": [
      "self",
      "fname"
    ],
    "copy_labels": [
      "self"
    ],
    "input_fnames": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "write_features": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "DecoderType": {
    "VITERBI": [],
    "KENLM": [],
    "FAIRSEQ": [],
    "KALDI": []
  },
  "UnsupGenerateConfig": {},
  "GenResult": [],
  "generate": [
    "cfg",
    "models",
    "saved_cfg",
    "use_cuda"
  ],
  "gen_hypos": [
    "generator",
    "models",
    "num_feats",
    "sample",
    "task",
    "use_cuda"
  ],
  "ExtractedFeaturesDataset": {
    "__init__": [
      "self",
      "path",
      "split",
      "min_length",
      "max_length",
      "labels",
      "label_dict",
      "shuffle",
      "sort_by_length",
      "aux_target_postfix"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "num_tokens": [
      "self",
      "index"
    ],
    "size": [
      "self",
      "index"
    ],
    "ordered_indices": [
      "self"
    ]
  },
  "RandomInputDataset": {
    "__init__": [
      "self",
      "dataset",
      "random_input_dataset",
      "input_key_path",
      "add_to_input",
      "pad_idx"
    ],
    "get_target": [
      "self",
      "item"
    ],
    "get_target_value": [
      "self",
      "item"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collater": [
      "self",
      "samples"
    ]
  },
  "UnpairedAudioTextConfig": {},
  "UnpairedAudioText": {
    "__init__": [
      "self",
      "cfg",
      "source_dictionary",
      "target_dictionary"
    ],
    "setup_task": [
      "cls",
      "cfg"
    ],
    "optimizer_step": [
      "self",
      "optimizer",
      "model",
      "update_num"
    ],
    "valid_step": [
      "self",
      "sample",
      "model",
      "criterion"
    ],
    "load_dataset": [
      "self",
      "split",
      "task_cfg"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ],
    "max_positions": [
      "self"
    ],
    "reduce_metrics": [
      "self",
      "logging_outputs",
      "criterion"
    ],
    "build_model": [
      "self",
      "cfg",
      "from_checkpoint"
    ]
  },
  "SegmentationType": {
    "NONE": [],
    "RANDOM": [],
    "UNIFORM_RANDOM": [],
    "UNIFORM_RANDOM_JOIN": [],
    "JOIN": []
  },
  "SegmentationConfig": {},
  "Wav2vec_UConfig": {},
  "Segmenter": {
    "__init__": [
      "self",
      "cfg"
    ],
    "pre_segment": [
      "self",
      "dense_x",
      "dense_padding_mask"
    ],
    "logit_segment": [
      "self",
      "logits",
      "padding_mask"
    ]
  },
  "RandomSegmenter": {
    "pre_segment": [
      "self",
      "dense_x",
      "dense_padding_mask"
    ]
  },
  "UniformRandomSegmenter": {
    "pre_segment": [
      "self",
      "dense_x",
      "dense_padding_mask"
    ]
  },
  "JoinSegmenter": {
    "logit_segment": [
      "self",
      "logits",
      "padding_mask"
    ]
  },
  "UniformRandomJoinSegmenter": {},
  "SEGMENT_FACTORY": [],
  "Discriminator": {
    "__init__": [
      "self",
      "dim",
      "cfg"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask"
    ]
  },
  "Wav2vec_U": {
    "calc_gradient_penalty": [
      "self",
      "real_data",
      "fake_data"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "discrim_step": [
      "self",
      "num_updates"
    ],
    "get_groups_for_update": [
      "self",
      "num_updates"
    ],
    "__init__": [
      "self",
      "cfg",
      "target_dict"
    ],
    "build_model": [
      "cls",
      "cfg",
      "task"
    ],
    "get_logits": [
      "self",
      "net_output",
      "normalize"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "normalize": [
      "self",
      "dense_x"
    ],
    "forward": [
      "self",
      "features",
      "padding_mask",
      "random_label",
      "dense_x_only",
      "segment",
      "aux_target"
    ]
  },
  "get_iterator": [
    "args"
  ],
  "Wav2VecFeatureReader": {
    "__init__": [
      "self",
      "cp_file",
      "layer"
    ],
    "read_audio": [
      "self",
      "fname"
    ],
    "get_feats": [
      "self",
      "loc"
    ]
  },
  "parser": [],
  "params": [],
  "paths": [],
  "list_intervals": [],
  "get_fname": [
    "line"
  ],
  "seen": [],
  "rvad": [
    "speechproc",
    "path"
  ],
  "compute_wer": [
    "ref_uid_to_tra",
    "hyp_uid_to_tra",
    "g2p"
  ],
  "load_tra": [
    "tra_path"
  ],
  "faiss_spec": [],
  "parse_faiss_specs": [
    "specs_str"
  ],
  "load_lex": [
    "lex_path"
  ],
  "compute_lm_ppl": [
    "hyp_uid_to_tra",
    "score_fn"
  ],
  "endpoint_url": [],
  "urls": [],
  "get_results": [
    "endpoint_url",
    "URL"
  ],
  "all_occupations": [],
  "_normalize_spaces": [
    "line"
  ],
  "aggregate_funcs": [],
  "read_translations": [
    "path",
    "n_repeats"
  ],
  "generate_input": [
    "translations",
    "n_repeats"
  ],
  "run_meteor": [
    "ref_path",
    "mt_path",
    "metric_path",
    "lang"
  ],
  "read_output": [
    "meteor_output_path",
    "n_repeats"
  ],
  "get_logger": [],
  "get_kmeans_model": [
    "n_clusters",
    "init",
    "max_iter",
    "batch_size",
    "tol",
    "max_no_improvement",
    "n_init",
    "reassignment_ratio",
    "random_state"
  ],
  "train_kmeans": [
    "kmeans_model",
    "features_batch"
  ],
  "get_audio_files": [
    "manifest_path"
  ],
  "CpcFeatureReader": {
    "__init__": [
      "self",
      "checkpoint_path",
      "layer",
      "use_encoder_layer",
      "norm_features",
      "sample_rate",
      "max_chunk"
    ],
    "read_audio": [
      "self",
      "path",
      "ref_len"
    ],
    "get_feats": [
      "self",
      "file_path",
      "ref_len"
    ]
  },
  "load_cpc_model": [
    "checkpoint_path",
    "layer"
  ],
  "ChannelNorm": {
    "__init__": [
      "self",
      "num_features",
      "epsilon",
      "affine"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CPCEncoder": {
    "__init__": [
      "self",
      "hidden_dim"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CPCAR": {
    "__init__": [
      "self",
      "dim_encoded",
      "dim_output",
      "keep_hidden",
      "num_layers"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CPCModel": {
    "__init__": [
      "self",
      "encoder",
      "ar_net"
    ],
    "forward": [
      "self",
      "x",
      "label"
    ],
    "extract_features": [
      "self",
      "source",
      "get_encoded",
      "norm_output"
    ]
  },
  "get_feature_reader": [
    "feature_type"
  ],
  "get_feature_iterator": [
    "feature_type",
    "checkpoint_path",
    "layer",
    "manifest_path",
    "sample_pct"
  ],
  "get_features": [
    "feature_type",
    "checkpoint_path",
    "layer",
    "manifest_path",
    "sample_pct",
    "flatten"
  ],
  "get_and_dump_features": [
    "feature_type",
    "checkpoint_path",
    "layer",
    "manifest_path",
    "sample_pct",
    "flatten",
    "out_features_path"
  ],
  "LogMelFeatureReader": {
    "__init__": [
      "self"
    ],
    "get_feats": [
      "self",
      "file_path"
    ]
  },
  "HubertFeatureReader": {
    "__init__": [
      "self",
      "checkpoint_path",
      "layer",
      "max_chunk"
    ],
    "read_audio": [
      "self",
      "path",
      "ref_len"
    ],
    "get_feats": [
      "self",
      "file_path",
      "ref_len"
    ]
  },
  "get_target_sequences": [
    "manifest",
    "ground_truth",
    "to_take"
  ],
  "get_self_bleu": [
    "utterances",
    "averaging_mode",
    "weights"
  ],
  "get_self_bleu2_arithmetic": [
    "utterances"
  ],
  "get_self_bleu2_geometric": [
    "utterances"
  ],
  "get_auto_bleu2_arithmetic": [
    "utterances"
  ],
  "get_auto_bleu2_geometric": [
    "utterances"
  ],
  "get_auto_bleu3_geometric": [
    "utterances"
  ],
  "get_auto_bleu3_arithmetic": [
    "utterances"
  ],
  "get_self_bleu3_arithmetic": [
    "utterances"
  ],
  "get_self_bleu3_geometric": [
    "utterances"
  ],
  "auto_bleu": [
    "sentence",
    "weights",
    "mean_mode"
  ],
  "run_f": [
    "task_params"
  ],
  "corpus_bleu": [
    "list_of_references",
    "hypotheses",
    "weights",
    "smoothing_function",
    "auto_reweigh",
    "averaging_mode",
    "no_length_penalty"
  ],
  "sentence_bleu": [
    "references",
    "hypothesis",
    "weights",
    "smoothing_function",
    "auto_reweigh",
    "averaging_mode",
    "no_length_penalty"
  ],
  "cut": [
    "src",
    "tgt",
    "l"
  ],
  "one_hot": [
    "feat",
    "n_clusters"
  ],
  "Translation": [],
  "load_quantized_audio_from_file": [
    "file_path"
  ],
  "synthesize_audio": [
    "model",
    "waveglow",
    "denoiser",
    "inp",
    "lab",
    "strength"
  ],
  "load_tacotron": [
    "tacotron_model_path",
    "max_decoder_steps"
  ],
  "load_waveglow": [
    "waveglow_path"
  ],
  "TacotronInputDataset": {
    "__init__": [
      "self",
      "hparams",
      "append_str"
    ],
    "process_code": [
      "self",
      "inp_str"
    ],
    "process_text": [
      "self",
      "inp_str"
    ],
    "get_tensor": [
      "self",
      "inp_str"
    ],
    "__len__": [
      "self"
    ]
  },
  "argslist": [],
  "log_dir": [],
  "num_gpus": [],
  "workers": [],
  "job_id": [],
  "find_all_files": [
    "path_dir",
    "extension"
  ],
  "convert16k": [
    "inputfile",
    "outputfile16k"
  ],
  "fused_add_tanh_sigmoid_multiply": [
    "input_a",
    "input_b",
    "n_channels"
  ],
  "WaveGlowLoss": {
    "__init__": [
      "self",
      "sigma"
    ],
    "forward": [
      "self",
      "model_output"
    ]
  },
  "Invertible1x1Conv": {
    "__init__": [
      "self",
      "c"
    ],
    "forward": [
      "self",
      "z",
      "reverse"
    ]
  },
  "WN": {
    "__init__": [
      "self",
      "n_in_channels",
      "n_mel_channels",
      "n_layers",
      "n_channels",
      "kernel_size"
    ],
    "forward": [
      "self",
      "forward_input"
    ]
  },
  "WaveGlow": {
    "__init__": [
      "self",
      "n_mel_channels",
      "n_flows",
      "n_group",
      "n_early_every",
      "n_early_size",
      "WN_config"
    ],
    "forward": [
      "self",
      "forward_input"
    ],
    "infer": [
      "self",
      "spect",
      "sigma"
    ],
    "remove_weightnorm": [
      "model"
    ]
  },
  "remove": [
    "conv_list"
  ],
  "_whitespace_re": [],
  "_abbreviations": [],
  "expand_abbreviations": [
    "text"
  ],
  "expand_numbers": [
    "text"
  ],
  "lowercase": [
    "text"
  ],
  "collapse_whitespace": [
    "text"
  ],
  "convert_to_ascii": [
    "text"
  ],
  "basic_cleaners": [
    "text"
  ],
  "transliteration_cleaners": [
    "text"
  ],
  "english_cleaners": [
    "text"
  ],
  "get_mask_from_lengths": [
    "lengths"
  ],
  "load_wav_to_torch": [
    "full_path",
    "sr"
  ],
  "read_binary_audio": [
    "bin_data",
    "tar_sr"
  ],
  "load_filepaths_and_text": [
    "filename"
  ],
  "to_gpu": [
    "x"
  ],
  "load_code_dict": [
    "path",
    "add_sos",
    "add_eos"
  ],
  "load_obs_label_dict": [
    "path"
  ],
  "CudaTimer": {
    "__init__": [
      "self",
      "keys"
    ],
    "start": [
      "self",
      "key"
    ],
    "stop": [
      "self",
      "key"
    ],
    "reset": [
      "self"
    ],
    "value": [
      "self"
    ],
    "_synchronize": [
      "self"
    ]
  },
  "Timer": {
    "__init__": [
      "self",
      "keys"
    ],
    "start": [
      "self",
      "key"
    ],
    "stop": [
      "self",
      "key"
    ],
    "reset": [
      "self"
    ],
    "value": [
      "self"
    ]
  },
  "_pad": [],
  "_punctuation": [],
  "_special": [],
  "_letters": [],
  "_arpabet": [],
  "symbols": [],
  "valid_symbols": [],
  "_valid_symbol_set": [],
  "CMUDict": {
    "__init__": [
      "self",
      "file_or_path",
      "keep_ambiguous"
    ],
    "__len__": [
      "self"
    ],
    "lookup": [
      "self",
      "word"
    ]
  },
  "_alt_re": [],
  "_parse_cmudict": [
    "file"
  ],
  "_get_pronunciation": [
    "s"
  ],
  "LocationLayer": {
    "__init__": [
      "self",
      "attention_n_filters",
      "attention_kernel_size",
      "attention_dim"
    ],
    "forward": [
      "self",
      "attention_weights_cat"
    ]
  },
  "Attention": {
    "__init__": [
      "self",
      "attention_rnn_dim",
      "embedding_dim",
      "attention_dim",
      "attention_location_n_filters",
      "attention_location_kernel_size"
    ],
    "get_alignment_energies": [
      "self",
      "query",
      "processed_memory",
      "attention_weights_cat"
    ],
    "forward": [
      "self",
      "attention_hidden_state",
      "memory",
      "processed_memory",
      "attention_weights_cat",
      "mask"
    ]
  },
  "AudioEncoder": {
    "__init__": [
      "self",
      "hparams"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "Tacotron2": {
    "__init__": [
      "self",
      "hparams"
    ],
    "parse_batch": [
      "self",
      "batch"
    ],
    "parse_output": [
      "self",
      "outputs",
      "output_lengths"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "inference": [
      "self",
      "inputs",
      "obs_labels",
      "lat",
      "ret_has_eos"
    ]
  },
  "window_sumsquare": [
    "window",
    "n_frames",
    "hop_length",
    "win_length",
    "n_fft",
    "dtype",
    "norm"
  ],
  "griffin_lim": [
    "magnitudes",
    "stft_fn",
    "n_iters"
  ],
  "dynamic_range_compression": [
    "x",
    "C",
    "clip_val"
  ],
  "dynamic_range_decompression": [
    "x",
    "C"
  ],
  "LinearNorm": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "bias",
      "w_init_gain"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvNorm": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "w_init_gain"
    ],
    "forward": [
      "self",
      "signal"
    ]
  },
  "GlobalAvgPool": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "TacotronSTFT": {
    "__init__": [
      "self",
      "filter_length",
      "hop_length",
      "win_length",
      "n_mel_channels",
      "sampling_rate",
      "mel_fmin",
      "mel_fmax"
    ],
    "spectral_normalize": [
      "self",
      "magnitudes"
    ],
    "spectral_de_normalize": [
      "self",
      "magnitudes"
    ],
    "mel_spectrogram": [
      "self",
      "y"
    ]
  },
  "_symbol_to_id": [],
  "_id_to_symbol": [],
  "_curly_re": [],
  "SOS_TOK": [],
  "EOS_TOK": [],
  "text_to_sequence": [
    "text",
    "cleaner_names"
  ],
  "sample_code_chunk": [
    "code",
    "size"
  ],
  "code_to_sequence": [
    "code",
    "code_dict",
    "collapse_code"
  ],
  "sequence_to_text": [
    "sequence"
  ],
  "sequence_to_code": [
    "sequence",
    "code_dict"
  ],
  "_clean_text": [
    "text",
    "cleaner_names"
  ],
  "_symbols_to_sequence": [
    "symbols"
  ],
  "_arpabet_to_sequence": [
    "text"
  ],
  "_should_keep_symbol": [
    "s"
  ],
  "Denoiser": {
    "__init__": [
      "self",
      "waveglow",
      "filter_length",
      "n_overlap",
      "win_length",
      "mode"
    ],
    "forward": [
      "self",
      "audio",
      "strength"
    ]
  },
  "STFT": {
    "__init__": [
      "self",
      "filter_length",
      "hop_length",
      "win_length",
      "window"
    ],
    "transform": [
      "self",
      "input_data"
    ],
    "inverse": [
      "self",
      "magnitude",
      "phase"
    ],
    "forward": [
      "self",
      "input_data"
    ]
  },
  "_inflect": [],
  "_comma_number_re": [],
  "_decimal_number_re": [],
  "_pounds_re": [],
  "_dollars_re": [],
  "_ordinal_re": [],
  "_number_re": [],
  "_remove_commas": [
    "m"
  ],
  "_expand_decimal_point": [
    "m"
  ],
  "_expand_dollars": [
    "m"
  ],
  "_expand_ordinal": [
    "m"
  ],
  "_expand_number": [
    "m"
  ],
  "normalize_numbers": [
    "text"
  ],
  "load_speaker": [
    "path"
  ],
  "quantize_f0": [
    "speaker_to_f0",
    "f0_stats",
    "nbins",
    "normalize",
    "log"
  ],
  "InferenceDataset": {
    "__init__": [
      "self",
      "dataset",
      "prefix",
      "only_prefix",
      "presort_by_length",
      "filter_short",
      "min_length"
    ],
    "pads": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "original_size": [
      "self",
      "k"
    ],
    "__getitem__": [
      "self",
      "k"
    ]
  },
  "explode_batch": [
    "batch",
    "times"
  ],
  "truncated_laplace": [
    "mean",
    "T",
    "truncate_by_zero"
  ],
  "load_data": [
    "in_file"
  ],
  "get_f0_upsample_ratio": [
    "code_hop_size",
    "f_hop_size"
  ],
  "load_meta": [
    "meta_path",
    "split"
  ],
  "_align_f0": [
    "f0",
    "dur",
    "ratio",
    "frm_tol"
  ],
  "align_f0": [
    "path_to_f0",
    "audio_paths",
    "durs",
    "ratio",
    "mp"
  ],
  "prepare_seg_data": [
    "config",
    "audio_paths",
    "codes",
    "durs",
    "speakers",
    "path_to_f0"
  ],
  "dump_seg_data": [
    "data",
    "out_prefix"
  ],
  "Naive_F0_Decoder": {
    "__init__": [
      "self",
      "bounds_path",
      "n_units"
    ],
    "forward": [
      "self",
      "discrete_f0"
    ]
  },
  "process_one": [
    "path",
    "sr"
  ],
  "Stat": {
    "__init__": [
      "self",
      "keep_raw"
    ],
    "update": [
      "self",
      "new_x"
    ],
    "mean": [
      "self"
    ],
    "std": [
      "self"
    ],
    "mean_log": [
      "self"
    ],
    "std_log": [
      "self"
    ],
    "n_frms": [
      "self"
    ],
    "n_utts": [
      "self"
    ],
    "raw_data": [
      "self"
    ]
  },
  "F0Stat": {
    "update": [
      "self",
      "new_x"
    ]
  },
  "dump_speaker_f0_stat": [
    "speaker_to_f0_stat",
    "out_prefix"
  ],
  "load_audio_path": [
    "path"
  ],
  "load_f0": [
    "f0_dir",
    "nshards"
  ],
  "teacher_force_everything": [
    "args",
    "dataset",
    "model",
    "criterion",
    "tgt_dict",
    "rank",
    "world_size"
  ],
  "continuation": [
    "args",
    "dataset",
    "model",
    "criterion",
    "tgt_dict",
    "rank",
    "world_size"
  ],
  "correlation": [
    "args",
    "dataset",
    "model",
    "criterion",
    "tgt_dict",
    "rank",
    "world_size"
  ],
  "wandb_results": [
    "summary",
    "raw_args"
  ],
  "maybe_aggregate_normalize": [
    "values",
    "normalizers",
    "world_size"
  ],
  "maybe_aggregate_correlations": [
    "results",
    "world_size"
  ],
  "CODETYPE_TO_FRAMETIME": [],
  "TemperatureDecoder": {
    "__init__": [
      "self",
      "Ts",
      "discrete_dur",
      "discrete_f0"
    ],
    "__call__": [
      "self",
      "output"
    ]
  },
  "FilterNamesDataset": {
    "__init__": [
      "self",
      "dataset",
      "fnames_path"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "k"
    ],
    "size": [
      "self",
      "k"
    ]
  },
  "do_sampling": [
    "model",
    "batch",
    "eos_token",
    "decoder",
    "autoregressive_steps",
    "teacher_force_tokens",
    "teacher_force_duration",
    "teacher_force_f0",
    "match_duration"
  ],
  "unroll_duration": [
    "token_stream",
    "duration_stream"
  ],
  "realign_shifted_streams": [
    "tokens",
    "durations",
    "F0s",
    "shifts"
  ],
  "maybe_cut_eos": [
    "produced_tokens",
    "produced_duration",
    "produced_f0",
    "eos_idx"
  ],
  "maybe_filter_pad": [
    "produced_tokens",
    "produced_duration",
    "produced_f0",
    "pad_idx"
  ],
  "match_duration": [
    "produced_tokens",
    "produced_duration",
    "produced_f0",
    "target_duration"
  ],
  "JobLauncher": {
    "JOB_CONFIG": [],
    "__init__": [
      "self",
      "yaml_file"
    ],
    "__call__": [
      "self",
      "job_type",
      "dryrun"
    ]
  },
  "Pipeline": {
    "__init__": [
      "self",
      "fn"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "_save_configs": [
      "self",
      "configs_to_save"
    ],
    "_overwrite_task": [
      "self",
      "job_config"
    ]
  },
  "Loss": {
    "__call__": [
      "self"
    ]
  },
  "DummyLoss": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "logits",
      "targets"
    ]
  },
  "DummyK400Loss": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "logits",
      "targets"
    ]
  },
  "CrossEntropy": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "logits",
      "targets"
    ]
  },
  "ArgmaxCrossEntropy": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "logits",
      "targets"
    ]
  },
  "BCE": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "logits",
      "targets"
    ]
  },
  "NLGLoss": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "logits",
      "text_label"
    ]
  },
  "MSE": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "logits",
      "targets"
    ]
  },
  "L1": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "logits",
      "targets"
    ]
  },
  "SmoothL1": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "logits",
      "targets"
    ]
  },
  "NCE": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "align_scores"
    ]
  },
  "T2VContraLoss": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "pooled_video",
      "pooled_text"
    ]
  },
  "V2TContraLoss": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "pooled_video",
      "pooled_text"
    ]
  },
  "MMContraLoss": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "pooled_video",
      "pooled_text"
    ]
  },
  "MTM": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "video_logits",
      "text_logits",
      "video_label",
      "text_label"
    ]
  },
  "MFMMLM": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "video_logits",
      "text_logits",
      "video_label",
      "text_label"
    ]
  },
  "MMCriterion": {
    "__init__": [
      "self",
      "task"
    ],
    "forward": [
      "self",
      "model",
      "sample"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "FairseqMMDataset": {
    "__init__": [
      "self",
      "mmdataset"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "size": [
      "self",
      "index"
    ],
    "num_tokens": [
      "self",
      "index"
    ]
  },
  "MMDataset": {
    "__init__": [
      "self",
      "meta_processor",
      "video_processor",
      "text_processor",
      "align_processor"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "collater": [
      "self",
      "samples"
    ],
    "print_example": [
      "self",
      "output"
    ]
  },
  "Evaluator": {
    "__init__": [
      "self",
      "config",
      "eval_dataloader"
    ],
    "__call__": [
      "self"
    ],
    "evaluate": [
      "self",
      "model",
      "eval_dataloader",
      "output_file"
    ]
  },
  "Metric": {
    "__init__": [
      "self",
      "config",
      "metric_names"
    ],
    "best_metric": [
      "self",
      "metric"
    ],
    "save_metrics": [
      "self",
      "fn",
      "metrics"
    ],
    "print_computed_metrics": [
      "self",
      "metrics"
    ]
  },
  "RetrievalMetric": {
    "__init__": [
      "self",
      "config",
      "metric_names"
    ],
    "compute_metrics": [
      "self",
      "outputs",
      "texts"
    ],
    "print_computed_metrics": [
      "self",
      "metrics"
    ]
  },
  "DiDeMoMetric": {
    "__init__": [
      "self",
      "config",
      "metric_names"
    ],
    "compute_metrics": [
      "self",
      "outputs",
      "targets"
    ],
    "print_computed_metrics": [
      "self",
      "metrics"
    ],
    "_iou": [
      "self",
      "pred",
      "gt"
    ],
    "_rank": [
      "self",
      "pred",
      "gt"
    ],
    "_eval_predictions": [
      "self",
      "segments",
      "data"
    ]
  },
  "NLGMetric": {
    "__init__": [
      "self",
      "config",
      "metric_names"
    ],
    "compute_metrics": [
      "self",
      "outputs",
      "targets"
    ],
    "print_computed_metrics": [
      "self",
      "metrics"
    ]
  },
  "QAMetric": {
    "__init__": [
      "self",
      "config",
      "metric_names"
    ],
    "compute_metrics": [
      "self",
      "outputs",
      "targets"
    ],
    "print_computed_metrics": [
      "self",
      "metrics"
    ]
  },
  "COINActionSegmentationMetric": {
    "__init__": [
      "self",
      "config",
      "metric_name"
    ],
    "compute_metrics": [
      "self",
      "outputs",
      "targets"
    ],
    "print_computed_metrics": [
      "self",
      "metrics"
    ]
  },
  "CrossTaskMetric": {
    "__init__": [
      "self",
      "config",
      "metric_names"
    ],
    "compute_metrics": [
      "self",
      "outputs",
      "targets"
    ],
    "print_computed_metrics": [
      "self",
      "metrics"
    ],
    "_get_recalls": [
      "self",
      "Y_true",
      "Y_pred"
    ]
  },
  "ActionRecognitionMetric": {
    "__init__": [
      "self",
      "config",
      "metric_names"
    ],
    "compute_metrics": [
      "self",
      "outputs",
      "targets",
      "splits"
    ],
    "print_computed_metrics": [
      "self",
      "metrics"
    ]
  },
  "Predictor": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "outputs"
    ],
    "predict_loop": [
      "self",
      "model",
      "eval_dataloader",
      "output_file"
    ],
    "finalize": [
      "self",
      "output_file"
    ],
    "to_ctx": [
      "self",
      "data",
      "ctx",
      "dtype"
    ]
  },
  "NLGPredictor": {
    "__init__": [
      "self",
      "config"
    ],
    "predict_loop": [
      "self",
      "model",
      "eval_dataloader",
      "output_file"
    ],
    "__call__": [
      "self",
      "data",
      "model",
      "outputs"
    ],
    "finalize": [
      "self",
      "outputs",
      "output_file"
    ]
  },
  "RetrievalPredictor": {
    "__init__": [
      "self",
      "config"
    ],
    "predict_loop": [
      "self",
      "model",
      "eval_dataloader",
      "output_file"
    ],
    "__call__": [
      "self",
      "sample",
      "full_scores"
    ],
    "finalize": [
      "self",
      "full_scores",
      "texts",
      "output_file"
    ],
    "_get_pooled_outputs": [
      "self",
      "outputs"
    ],
    "_append_scores": [
      "self",
      "scores",
      "full_scores"
    ],
    "_aggregate_scores": [
      "self",
      "scores"
    ]
  },
  "QAPredictor": {
    "__init__": [
      "self",
      "config"
    ],
    "predict_loop": [
      "self",
      "model",
      "eval_dataloader",
      "output_file"
    ],
    "__call__": [
      "self",
      "sample"
    ],
    "finalize": [
      "self",
      "output_file"
    ],
    "_append_scores": [
      "self",
      "scores",
      "answers",
      "full_scores"
    ],
    "_aggregate_scores": [
      "self",
      "scores"
    ]
  },
  "CrossTaskPredictor": {
    "__init__": [
      "self",
      "config"
    ],
    "predict_loop": [
      "self",
      "model",
      "eval_dataloader",
      "output_file"
    ],
    "__call__": [
      "self",
      "sample",
      "model",
      "Y_pred",
      "Y_true"
    ],
    "finalize": [
      "self",
      "Y_pred",
      "Y_true",
      "output_file"
    ],
    "_read_assignment": [
      "self",
      "T",
      "K",
      "path"
    ]
  },
  "COINPredictor": {
    "__init__": [
      "self",
      "config"
    ],
    "predict_loop": [
      "self",
      "model",
      "eval_dataloader",
      "output_file"
    ],
    "__call__": [
      "self",
      "sample",
      "model",
      "Y_pred",
      "Y_true"
    ],
    "_merge_windows": [
      "self",
      "sample",
      "output"
    ],
    "finalize": [
      "self",
      "Y_pred",
      "Y_true",
      "output_file"
    ]
  },
  "COINZSPredictor": {
    "__init__": [
      "self",
      "config"
    ],
    "predict_loop": [
      "self",
      "model",
      "eval_dataloader",
      "output_file"
    ],
    "reshape_subsample": [
      "self",
      "sample"
    ],
    "flat_subsample": [
      "self",
      "tensor"
    ],
    "__call__": [
      "self",
      "sample",
      "label_hidden_states",
      "model",
      "lbd",
      "Y_pred",
      "Y_true"
    ],
    "finalize": [
      "self",
      "Y_pred",
      "Y_true",
      "output_file"
    ]
  },
  "DiDeMoPredictor": {
    "__init__": [
      "self",
      "config"
    ],
    "predict_loop": [
      "self",
      "model",
      "eval_dataloader",
      "output_file"
    ],
    "__call__": [
      "self",
      "sample"
    ],
    "finalize": [
      "self",
      "output_file"
    ],
    "_aggregate_scores": [
      "self",
      "scores"
    ]
  },
  "ShardedTensor": {
    "__init__": [
      "self",
      "data",
      "starts"
    ],
    "from_list": [
      "xs"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__len__": [
      "self"
    ],
    "lengths": [
      "self"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "path",
      "mmap_mode"
    ]
  },
  "set_seed": [
    "seed"
  ],
  "get_local_rank": [],
  "print_on_rank0": [
    "func"
  ],
  "RetriMeter": {
    "__init__": [
      "self",
      "freq"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "__repr__": [
      "self"
    ]
  },
  "load_config": [
    "args",
    "config_file",
    "overwrite_fairseq"
  ],
  "recursive_config": [
    "config_path"
  ],
  "suffix_rundir": [
    "save_dir",
    "run_dir"
  ],
  "overwrite_dir": [
    "config",
    "replace",
    "basedir"
  ],
  "VLMTask": {
    "flat_subsample": [
      "self",
      "tensor"
    ]
  },
  "FairseqMMTask": {
    "add_args": [
      "parser"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "__init__": [
      "self",
      "args"
    ],
    "load_dataset": [
      "self",
      "split"
    ],
    "get_batch_iterator": [
      "self",
      "dataset",
      "max_tokens",
      "max_sentences",
      "max_positions",
      "ignore_invalid_inputs",
      "required_batch_size_multiple",
      "seed",
      "num_shards",
      "shard_id",
      "num_workers",
      "epoch",
      "data_buffer_size",
      "disable_iterator_cache",
      "skip_remainder_batch",
      "grouped_shuffling",
      "update_epoch_batch_itr"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ]
  },
  "Task": {
    "config_task": [
      "cls",
      "config"
    ],
    "__init__": [
      "self",
      "config"
    ],
    "build_dataset": [
      "self"
    ],
    "build_model": [
      "self",
      "checkpoint"
    ],
    "load_checkpoint": [
      "self",
      "checkpoint"
    ],
    "_trim_state_dict": [
      "self",
      "state_dict"
    ],
    "build_loss": [
      "self"
    ],
    "flat_subsample": [
      "self",
      "tensor"
    ],
    "reshape_subsample": [
      "self",
      "sample"
    ],
    "__call__": [
      "self",
      "model",
      "sample"
    ],
    "build_dataloader": [
      "self"
    ]
  },
  "MILNCETask": {
    "reshape_subsample": [
      "self",
      "sample"
    ]
  },
  "RetriTask": {
    "reshape_subsample": [
      "self",
      "sample"
    ],
    "flat_subsample": [
      "self",
      "tensor"
    ],
    "build_dataloader": [
      "self"
    ],
    "retrive_candidates": [
      "self",
      "epoch",
      "dataloader"
    ]
  },
  "VideoRetriTask": {
    "reshape_subsample": [
      "self",
      "sample"
    ],
    "flat_subsample": [
      "self",
      "tensor"
    ],
    "_retri_predict": [
      "self",
      "epoch",
      "dataloader"
    ],
    "_retri_sync": [
      "self",
      "epoch",
      "out_dir"
    ]
  },
  "VideoPredictor": {
    "__init__": [
      "self",
      "config"
    ],
    "predict_loop": [
      "self",
      "model",
      "dataloader",
      "early_stop"
    ],
    "__call__": [
      "self",
      "sample",
      "model"
    ],
    "finalize": [
      "self"
    ]
  },
  "VideoRetriPredictor": {
    "__init__": [
      "self",
      "config"
    ],
    "predict_loop": [
      "self",
      "model",
      "retriver",
      "epoch",
      "early_stop"
    ],
    "finalize": [
      "self",
      "batched_videos",
      "epoch"
    ]
  },
  "How2MetaProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "ShardedHow2MetaProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "_init_shard": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "ShardedVideoProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "video_id"
    ]
  },
  "ShardedTextProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "video_id"
    ]
  },
  "FixedLenAligner": {
    "__init__": [
      "self",
      "config"
    ],
    "_get_text_maxlen": [
      "self"
    ],
    "__call__": [
      "self",
      "video_id",
      "video_feature",
      "text_feature"
    ],
    "sampling": [
      "self",
      "video_idx",
      "video_feature",
      "text_feature",
      "centerclip_idx",
      "sampled_max_text_len"
    ]
  },
  "VariedLenAligner": {
    "__init__": [
      "self",
      "config"
    ],
    "_get_text_maxlen": [
      "self"
    ]
  },
  "StartClipAligner": {
    "sampling": [
      "self",
      "video_idx",
      "video_feature",
      "text_feature",
      "centerclip_idx",
      "sampled_max_text_len"
    ]
  },
  "OverlappedAligner": {
    "__init__": [
      "self",
      "config"
    ],
    "_get_video_maxlen": [
      "self"
    ],
    "sampling": [
      "self",
      "video_idx",
      "video_feature",
      "text_feature",
      "centerclip_idx",
      "sampled_max_text_len"
    ]
  },
  "MFMMLMAligner": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "video_id",
      "video_feature",
      "text_feature"
    ],
    "sampling": [
      "self",
      "video_id",
      "video_feature",
      "text_feature",
      "centerclip_idx",
      "sampled_max_text_len"
    ]
  },
  "FrameMaskingProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "vmasks",
      "modality_masking",
      "vfeats"
    ]
  },
  "TextGenerationProcessor": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "inputs"
    ]
  },
  "TextMaskingProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "inputs",
      "modality_masking",
      "special_tokens_mask"
    ],
    "mask_input": [
      "self",
      "inputs",
      "special_tokens_mask"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ]
  },
  "TextClipSamplingProcessor": {
    "__init__": [
      "self",
      "max_text_len",
      "keep_prob"
    ],
    "__call__": [
      "self",
      "text_feature",
      "centerclip_idx",
      "sampled_max_text_len",
      "sampled_max_video_len"
    ]
  },
  "VideoClipSamplingProcessor": {
    "__call__": [
      "self",
      "video_len",
      "max_video_len",
      "center"
    ]
  },
  "How2MILNCEAligner": {
    "__init__": [
      "self",
      "config"
    ],
    "sampling": [
      "self",
      "video_id",
      "video_feature",
      "text_feature",
      "centerclip_idx",
      "sampled_max_text_len"
    ],
    "_get_video": [
      "self",
      "video_feature",
      "start",
      "end"
    ],
    "_get_text": [
      "self",
      "cap"
    ],
    "_find_nearest_candidates": [
      "self",
      "caption",
      "ind"
    ]
  },
  "PKLJSONStrTextProcessor": {
    "__init__": [
      "self",
      "config",
      "max_clip_text_len"
    ],
    "__call__": [
      "self",
      "video_id"
    ]
  },
  "ShardedHow2VideoRetriMetaProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__len__": [
      "self"
    ],
    "set_candidates": [
      "self",
      "cands"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "ShardedVideoRetriVideoProcessor": {
    "__call__": [
      "self",
      "sharded_video_idxs"
    ]
  },
  "ShardedVideoRetriTextProcessor": {
    "__call__": [
      "self",
      "sharded_video_idxs"
    ]
  },
  "VideoRetriAligner": {
    "__call__": [
      "self",
      "sharded_video_idxs",
      "video_features",
      "text_features"
    ]
  },
  "VideoRetriOverlappedAligner": {
    "__call__": [
      "self",
      "sharded_video_idxs",
      "video_features",
      "text_features"
    ]
  },
  "Processor": {
    "__call__": [
      "self"
    ]
  },
  "MetaProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_get_split_path": [
      "self",
      "config"
    ]
  },
  "TextProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "text_id"
    ]
  },
  "VideoProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "video_fn"
    ]
  },
  "Aligner": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "video_id",
      "video_feature",
      "text_feature"
    ],
    "_build_video_seq": [
      "self",
      "video_feature",
      "video_clips"
    ],
    "_build_text_seq": [
      "self",
      "text_feature",
      "text_clip_indexs"
    ],
    "batch_post_processing": [
      "self",
      "batch",
      "video_feature"
    ]
  },
  "MMAttentionMask2DProcessor": {
    "__call__": [
      "self",
      "vmask",
      "cmask",
      "mtype"
    ],
    "_build_mm_mask": [
      "self",
      "vmask",
      "cmask"
    ],
    "_build_videogeneration_mask": [
      "self",
      "vmask",
      "cmask"
    ],
    "_build_textgeneration_mask": [
      "self",
      "vmask",
      "cmask"
    ]
  },
  "DSAligner": {
    "__call__": [
      "self",
      "video_id",
      "video_feature",
      "text_feature",
      "wps"
    ]
  },
  "NLGTextProcessor": {
    "__call__": [
      "self",
      "text_id"
    ]
  },
  "DSNLGAligner": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "video_id",
      "video_feature",
      "text_feature"
    ]
  },
  "MSRVTTMetaProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "MSRVTTTextProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "text_id"
    ]
  },
  "MSRVTTNLGTextProcessor": {
    "__call__": [
      "self",
      "text_id"
    ]
  },
  "MSRVTTQAMetaProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "MSRVTTQATextProcessor": {
    "__call__": [
      "self",
      "text_ans"
    ]
  },
  "MSRVTTQAAligner": {
    "__call__": [
      "self",
      "video_id",
      "video_feature",
      "text_feature",
      "wps"
    ]
  },
  "YoucookMetaProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "YoucookVideoProcessor": {
    "__call__": [
      "self",
      "video_fn"
    ]
  },
  "YoucookNLGMetaProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "CrossTaskMetaProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "_random_split": [
      "self",
      "task_vids",
      "test_tasks",
      "n_train"
    ],
    "_get_vids": [
      "self",
      "path",
      "vfeat_dir",
      "annotation_path"
    ],
    "_read_task_info": [
      "self",
      "path"
    ],
    "_get_A": [
      "self",
      "task_steps",
      "share"
    ]
  },
  "CrossTaskVideoProcessor": {
    "__call__": [
      "self",
      "video_fn"
    ]
  },
  "CrossTaskTextProcessor": {
    "__call__": [
      "self",
      "text_id"
    ]
  },
  "CrossTaskAligner": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "video_id",
      "video_feature",
      "text_feature"
    ],
    "_read_assignment": [
      "self",
      "T",
      "K",
      "path"
    ]
  },
  "MetaTextBinarizer": {
    "__call__": [
      "self",
      "text_feature"
    ]
  },
  "COINActionSegmentationMetaProcessor": {
    "split_map": [],
    "__init__": [
      "self",
      "config"
    ],
    "meta_text_labels": [
      "self",
      "config"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "COINActionSegmentationTextProcessor": {
    "__call__": [
      "self",
      "text_label"
    ]
  },
  "COINActionSegmentationAligner": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "video_id",
      "video_feature",
      "text_feature"
    ]
  },
  "DiDeMoMetaProcessor": {
    "__init__": [
      "self",
      "config"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "DiDeMoTextProcessor": {
    "__call__": [
      "self",
      "text"
    ]
  },
  "DiDeMoAligner": {
    "__call__": [
      "self",
      "video_id",
      "video_feature",
      "text_feature"
    ]
  },
  "CaptionDedupProcessor": {
    "__init__": [
      "self",
      "pkl_file"
    ],
    "__call__": [
      "self"
    ],
    "single": [
      "self",
      "video_id"
    ],
    "finalize": [
      "self",
      "tgt_fn"
    ],
    "save_stat": [
      "self",
      "video_id",
      "caption"
    ],
    "print_stat": [
      "self"
    ],
    "_dedup": [
      "self",
      "caption"
    ]
  },
  "InceptionBlock": {
    "__init__": [
      "self",
      "input_dim",
      "num_outputs_0_0a",
      "num_outputs_1_0a",
      "num_outputs_1_0b",
      "num_outputs_2_0a",
      "num_outputs_2_0b",
      "num_outputs_3_0b",
      "gating"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "SelfGating": {
    "__init__": [
      "self",
      "input_dim"
    ],
    "forward": [
      "self",
      "input_tensor"
    ]
  },
  "STConv3D": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "kernel_size",
      "stride",
      "padding",
      "separable"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "MaxPool3dTFPadding": {
    "__init__": [
      "self",
      "kernel_size",
      "stride",
      "padding"
    ],
    "_get_padding_shape": [
      "self",
      "filter_shape",
      "stride"
    ],
    "forward": [
      "self",
      "inp"
    ]
  },
  "Sentence_Embedding": {
    "__init__": [
      "self",
      "embd_dim",
      "num_embeddings",
      "word_embedding_dim",
      "token_to_word_path",
      "max_words",
      "output_dim"
    ],
    "_zero_pad_tensor_token": [
      "self",
      "tensor",
      "size"
    ],
    "_split_text": [
      "self",
      "sentence"
    ],
    "_words_to_token": [
      "self",
      "words"
    ],
    "_words_to_ids": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "S3D": {
    "__init__": [
      "self",
      "dict_path",
      "num_classes",
      "gating",
      "space_to_depth"
    ],
    "_space_to_depth": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "MMPTModel": {
    "from_pretrained": [
      "cls",
      "config",
      "checkpoint"
    ],
    "__init__": [
      "self",
      "config",
      "model",
      "video_encoder"
    ],
    "forward": [
      "self",
      "video_frames",
      "caps",
      "cmasks",
      "return_score"
    ]
  },
  "MMFusion": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "caps",
      "cmasks",
      "vfeats",
      "vmasks"
    ],
    "_mm_on_the_fly": [
      "self",
      "cmasks",
      "vmasks",
      "attention_mask"
    ],
    "_mm_attention_mask": [
      "self",
      "cmasks",
      "vmasks"
    ],
    "_make_iso_mask": [
      "self",
      "batch_size",
      "cmasks",
      "vmasks"
    ],
    "_pooling_vt_layer": [
      "self",
      "layered_sequence_output",
      "cmasks",
      "vmasks"
    ]
  },
  "MMFusionMFMMLM": {
    "forward": [
      "self",
      "caps",
      "cmasks",
      "vfeats",
      "vmasks",
      "attention_mask",
      "video_label",
      "text_label"
    ]
  },
  "MMFusionMTM": {
    "__init__": [
      "self",
      "config"
    ]
  },
  "MMFusionShare": {
    "forward": [
      "self",
      "caps",
      "cmasks",
      "vfeats",
      "vmasks",
      "attention_mask",
      "video_label",
      "text_label",
      "output_hidden_states"
    ],
    "forward_video": [
      "self",
      "vfeats",
      "vmasks",
      "caps",
      "cmasks",
      "output_hidden_states"
    ],
    "forward_text": [
      "self",
      "caps",
      "cmasks",
      "output_hidden_states"
    ]
  },
  "MMFusionSeparate": {
    "forward_video": [
      "self",
      "vfeats",
      "vmasks",
      "caps",
      "cmasks",
      "output_hidden_states"
    ],
    "forward_text": [
      "self",
      "caps",
      "cmasks",
      "output_hidden_states"
    ]
  },
  "MMFusionJoint": {
    "forward": [
      "self",
      "caps",
      "cmasks",
      "vfeats",
      "vmasks",
      "attention_mask",
      "video_label",
      "text_label"
    ]
  },
  "MMFusionActionSegmentation": {
    "forward": [
      "self",
      "caps",
      "cmasks",
      "vfeats",
      "vmasks",
      "attention_mask"
    ]
  },
  "MMFusionActionLocalization": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "caps",
      "cmasks",
      "vfeats",
      "vmasks",
      "attention_mask"
    ]
  },
  "MMFusionSeparateActionSegmentation": {
    "forward": [
      "self",
      "caps",
      "cmasks",
      "vfeats",
      "vmasks",
      "attention_mask"
    ]
  },
  "MMFusionSeparateActionLocalization": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "caps",
      "cmasks",
      "vfeats",
      "vmasks"
    ]
  },
  "MMFusionShareActionLocalization": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "caps",
      "cmasks",
      "vfeats",
      "vmasks"
    ]
  },
  "MMBertForJoint": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "input_video_embeds",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "next_sentence_label",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "separate_forward_split"
    ]
  },
  "MMBertForTokenClassification": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "input_video_embeds",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "next_sentence_label",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "separate_forward_split"
    ]
  },
  "MMBertForEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "input_video_embeds",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MMBertForMFMMLM": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "input_video_embeds",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "masked_frame_labels",
      "target_video_hidden_states",
      "non_masked_frame_mask",
      "masked_lm_labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "BertMFMMLMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "video_hidden_states",
      "target_video_hidden_states",
      "non_masked_frame_hidden_states",
      "text_hidden_states"
    ]
  },
  "MFMMLMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "video_hidden_states",
      "target_video_hidden_states",
      "non_masked_frame_hidden_states",
      "text_hidden_states"
    ]
  },
  "MMBertForMTM": {
    "__init__": [
      "self",
      "config"
    ]
  },
  "BertMTMPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "video_hidden_states",
      "target_video_hidden_states",
      "non_masked_frame_hidden_states",
      "text_hidden_states"
    ]
  },
  "MTMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "video_hidden_states",
      "target_video_hidden_states",
      "non_masked_frame_hidden_states",
      "text_hidden_states"
    ]
  },
  "MMBertModel": {
    "__init__": [
      "self",
      "config",
      "add_pooling_layer"
    ],
    "forward": [
      "self",
      "input_ids",
      "input_video_embeds",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "separate_forward_split"
    ],
    "get_extended_attention_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "device"
    ]
  },
  "MultiLayerAttentionMaskBertEncoder": {
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "MMFusionNLG": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "caps",
      "cmasks",
      "vfeats",
      "vmasks",
      "attention_mask",
      "video_label",
      "text_label"
    ],
    "generate": [
      "self",
      "caps",
      "cmasks",
      "vfeats",
      "vmasks",
      "attention_mask",
      "bos_token_id",
      "eos_token_id"
    ]
  },
  "MMBertForNLG": {
    "__init__": [
      "self",
      "config"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "input_video_embeds",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "masked_lm_labels",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "input_video_embeds",
      "attention_mask",
      "token_type_ids"
    ],
    "generate": [
      "self",
      "input_ids",
      "decoder_input_ids",
      "max_length",
      "min_length",
      "do_sample",
      "early_stopping",
      "num_beams",
      "temperature",
      "top_k",
      "top_p",
      "repetition_penalty",
      "bad_words_ids",
      "bos_token_id",
      "pad_token_id",
      "eos_token_id",
      "length_penalty",
      "no_repeat_ngram_size",
      "num_return_sequences",
      "attention_mask",
      "decoder_start_token_id",
      "use_cache"
    ],
    "_generate_beam_search": [
      "self",
      "input_ids",
      "cur_len",
      "max_length",
      "min_length",
      "do_sample",
      "early_stopping",
      "temperature",
      "top_k",
      "top_p",
      "repetition_penalty",
      "no_repeat_ngram_size",
      "bad_words_ids",
      "pad_token_id",
      "eos_token_id",
      "batch_size",
      "num_return_sequences",
      "length_penalty",
      "num_beams",
      "vocab_size",
      "attention_mask",
      "use_cache",
      "model_kwargs"
    ],
    "_generate_no_beam_search": [
      "self",
      "input_ids",
      "cur_len",
      "max_length",
      "min_length",
      "do_sample",
      "temperature",
      "top_k",
      "top_p",
      "repetition_penalty",
      "no_repeat_ngram_size",
      "bad_words_ids",
      "pad_token_id",
      "eos_token_id",
      "batch_size",
      "attention_mask",
      "use_cache",
      "model_kwargs"
    ]
  },
  "FairseqMMModel": {
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "__init__": [
      "self",
      "mmmodel"
    ],
    "forward": [
      "self"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "mmarch": [
    "args"
  ],
  "VectorRetriever": {
    "__init__": [
      "self",
      "hidden_size",
      "cent",
      "db_type",
      "examples_per_cent_to_train"
    ],
    "make_direct_maps": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "save": [
      "self",
      "out_dir"
    ],
    "load": [
      "self",
      "out_dir"
    ],
    "add": [
      "self",
      "hidden_states",
      "video_ids",
      "last"
    ],
    "finalize_training": [
      "self"
    ],
    "search": [
      "self",
      "query_hidden_states",
      "orig_dist"
    ],
    "search_by_video_ids": [
      "self",
      "video_ids",
      "retri_factor"
    ]
  },
  "VectorRetrieverDM": {
    "__init__": [
      "self",
      "hidden_size",
      "cent",
      "db_type",
      "examples_per_cent_to_train"
    ],
    "make_direct_maps": [
      "self"
    ],
    "search": [
      "self",
      "query_hidden_states",
      "orig_dist"
    ],
    "search_by_video_ids": [
      "self",
      "video_ids",
      "retri_factor"
    ]
  },
  "MMVectorRetriever": {
    "__init__": [
      "self",
      "hidden_size",
      "cent",
      "db_type",
      "examples_per_cent_to_train"
    ],
    "__len__": [
      "self"
    ],
    "make_direct_maps": [
      "self"
    ],
    "save": [
      "self",
      "out_dir"
    ],
    "load": [
      "self",
      "out_dir"
    ],
    "add": [
      "self",
      "hidden_states",
      "video_ids"
    ],
    "get_clips_by_video_id": [
      "self",
      "video_id"
    ],
    "search": [
      "self",
      "video_ids",
      "target_modality",
      "retri_factor"
    ]
  },
  "VideoTokenMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MMBertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "input_video_embeds",
      "token_type_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "AlignHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "dropout_pooled_output"
    ]
  },
  "VectorPool": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "sample"
    ],
    "build_retriver": [
      "self",
      "retriever_cls",
      "hidden_size",
      "centroids",
      "db_type",
      "examples_per_cent_to_train"
    ],
    "__repr__": [
      "self"
    ]
  },
  "VideoVectorPool": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "sample",
      "subsampling"
    ]
  },
  "DistributedVectorPool": {
    "__init__": [
      "self",
      "config"
    ],
    "build_retriver": [
      "self",
      "retriever_cls",
      "hidden_size",
      "centroids",
      "db_type",
      "examples_per_cent_to_train"
    ],
    "load": [
      "self",
      "local_rank"
    ],
    "save": [
      "self"
    ]
  },
  "DistributedVideoVectorPool": {
    "__call__": [
      "self",
      "sample",
      "subsampling"
    ]
  },
  "TextClipVectorPool": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "sample"
    ]
  },
  "MMClipVectorPool": {
    "__init__": [
      "self",
      "out_dir"
    ],
    "__call__": [
      "self",
      "sample"
    ]
  },
  "BaseJob": {
    "__init__": [
      "self",
      "yaml_file",
      "dryrun"
    ],
    "submit": [
      "self"
    ],
    "_normalize_cmd": [
      "self",
      "cmd_list"
    ]
  },
  "LocalJob": {
    "CMD_CONFIG": [],
    "__init__": [
      "self",
      "yaml_file",
      "job_type",
      "dryrun"
    ],
    "submit": [
      "self"
    ]
  },
  "JobStatus": {
    "__init__": [
      "self",
      "job_id"
    ],
    "__repr__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "done": [
      "self"
    ],
    "running": [
      "self"
    ],
    "result": [
      "self"
    ],
    "stderr": [
      "self"
    ],
    "stdout": [
      "self"
    ]
  },
  "get_dataloader": [
    "config"
  ],
  "TokenizerDataset": {
    "__init__": [
      "self",
      "config"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ]
  },
  "numpify": [
    "shard_idx",
    "video_ids",
    "captions",
    "target_dir",
    "split",
    "prefix",
    "max_cap_len"
  ],
  "sharding": [
    "config",
    "out_file"
  ],
  "tokenize": [
    "config",
    "out_file"
  ],
  "args": [],
  "CONFIGS": [],
  "config": [],
  "video_dirs": [],
  "feature_dir": [],
  "video_dict": [],
  "dataset": [],
  "n_dataset": [],
  "sampler": [],
  "loader": [],
  "model": [],
  "supported_formats": [],
  "PathBuilder": {
    "build": [
      "cls",
      "video_dirs",
      "feature_dir",
      "ext",
      "shards",
      "split"
    ]
  },
  "Shard": {
    "__init__": [
      "self",
      "vfeat_dir",
      "tfeat_dir",
      "target_dir",
      "file_paths",
      "shard_size"
    ],
    "__call__": [
      "self",
      "split"
    ]
  },
  "RandomSequenceSampler": {
    "__init__": [
      "self",
      "n_sample",
      "seq_len"
    ],
    "_pad_ind": [
      "self",
      "ind"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "get_model": [
    "args"
  ],
  "Normalize": {
    "__init__": [
      "self",
      "mean",
      "std"
    ],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "Preprocessing": {
    "__init__": [
      "self",
      "type"
    ],
    "_zero_pad": [
      "self",
      "tensor",
      "size"
    ],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "VideoLoader": {
    "__init__": [
      "self",
      "csv",
      "video_dict",
      "framerate",
      "size",
      "centercrop",
      "hflip"
    ],
    "__len__": [
      "self"
    ],
    "_get_video_dim": [
      "self",
      "video_path"
    ],
    "_get_video_info": [
      "self",
      "video_path"
    ],
    "_get_output_dim": [
      "self",
      "h",
      "w"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_decode": [
      "self",
      "output_file",
      "video_path"
    ],
    "_run": [
      "self",
      "cmd",
      "output_file"
    ]
  },
  "VideoVerifier": {
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "VideoCompressor": {
    "__init__": [
      "self",
      "csv",
      "video_dict",
      "framerate",
      "size",
      "centercrop",
      "hflip",
      "crf"
    ],
    "_run": [
      "self",
      "cmd",
      "output_file"
    ]
  },
  "VideoDownloader": {
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "AvKeyframeVideoCompressor": {
    "__init__": [
      "self",
      "csv",
      "video_dict",
      "framerate",
      "size",
      "centercrop",
      "max_num_frames"
    ],
    "_get_video_dim": [
      "self",
      "video_fn"
    ],
    "_get_output_dim": [
      "self",
      "height",
      "width"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "get_avg_pool": [
    "models",
    "sample",
    "prefix_tokens",
    "src_dict",
    "remove_bpe",
    "has_langtok"
  ],
  "GB": [],
  "call": [
    "cmd"
  ],
  "get_batches": [
    "directory",
    "lang",
    "prefix"
  ],
  "load_batch": [
    "emb_file",
    "dim"
  ],
  "knnGPU_sharded": [
    "x_batches_f",
    "y_batches_f",
    "dim",
    "k",
    "direction"
  ],
  "score": [
    "sim",
    "fwd_mean",
    "bwd_mean",
    "margin"
  ],
  "score_candidates": [
    "sim_mat",
    "candidate_inds",
    "fwd_mean",
    "bwd_mean",
    "margin",
    "verbose"
  ],
  "load_text": [
    "files"
  ],
  "DIM": [],
  "compute_dist": [
    "source_embs",
    "target_embs",
    "k",
    "return_sim_mat"
  ],
  "load_embeddings": [
    "directory",
    "LANGS"
  ],
  "compute_accuracy": [
    "directory",
    "LANGS"
  ],
  "dictolist": [
    "d"
  ],
  "load_sys": [
    "paths"
  ],
  "load_ref": [
    "path"
  ],
  "merge": [
    "src",
    "tgt",
    "hypos",
    "log_probs",
    "path"
  ],
  "pairwise": [
    "sents"
  ],
  "multi_ref": [
    "refs",
    "hypos"
  ],
  "intra_ref": [
    "refs"
  ],
  "METHOD_CHOICES": [],
  "TranslationMoEConfig": {},
  "TranslationMoETask": {
    "__init__": [
      "self",
      "cfg",
      "src_dict",
      "tgt_dict"
    ],
    "build_model": [
      "self",
      "cfg",
      "from_checkpoint"
    ],
    "expert_index": [
      "self",
      "i"
    ],
    "_get_loss": [
      "self",
      "sample",
      "model",
      "criterion"
    ],
    "train_step": [
      "self",
      "sample",
      "model",
      "criterion",
      "optimizer",
      "update_num",
      "ignore_grad"
    ],
    "valid_step": [
      "self",
      "sample",
      "model",
      "criterion"
    ],
    "inference_step": [
      "self",
      "generator",
      "models",
      "sample",
      "prefix_tokens",
      "expert",
      "constraints"
    ],
    "reduce_metrics": [
      "self",
      "logging_outputs",
      "criterion"
    ]
  },
  "MeanPoolGatingNetwork": {
    "__init__": [
      "self",
      "embed_dim",
      "num_experts",
      "dropout"
    ],
    "forward": [
      "self",
      "encoder_out"
    ]
  },
  "LogSumExpMoE": {
    "forward": [
      "ctx",
      "logp",
      "posterior",
      "dim"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "SpeechToTextHeadSelectionTask": {
    "add_args": [
      "cls",
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "tgt_dict"
    ],
    "map_task_to_id": [
      "self",
      "train_subset"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "build_model": [
      "self",
      "args"
    ],
    "get_sample_sizes": [
      "self",
      "sample",
      "task_ids",
      "num_tasks"
    ],
    "train_step": [
      "self",
      "sample",
      "model",
      "criterion",
      "optimizer",
      "update_num",
      "ignore_grad"
    ],
    "valid_step": [
      "self",
      "sample",
      "model",
      "criterion"
    ],
    "inference_step": [
      "self",
      "generator",
      "models",
      "sample",
      "prefix_tokens",
      "constraints"
    ]
  },
  "HeadSelectionLoss": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "head_samples",
      "sample_sizes",
      "prior",
      "eps"
    ]
  },
  "SpeechToTextDatasetItemWithDomain": {},
  "SpeechToTextDatasetWithDomain": {
    "__init__": [
      "self",
      "split",
      "is_train_split",
      "cfg",
      "audio_paths",
      "n_frames",
      "src_texts",
      "tgt_texts",
      "speakers",
      "src_langs",
      "tgt_langs",
      "ids",
      "tgt_dict",
      "pre_tokenizer",
      "bpe_tokenizer",
      "n_frames_per_step",
      "speaker_to_id",
      "src_lang_ids",
      "tgt_lang_ids",
      "domain_ids"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "collater": [
      "self",
      "samples",
      "return_order"
    ]
  },
  "SpeechToTextDatasetCreatorWithDomain": {
    "KEY_DOMAIN_ID": [],
    "_from_list": [
      "cls",
      "split_name",
      "is_train_split",
      "samples",
      "cfg",
      "tgt_dict",
      "pre_tokenizer",
      "bpe_tokenizer",
      "n_frames_per_step",
      "speaker_to_id"
    ],
    "_load_samples_from_tsv": [
      "cls",
      "root",
      "split",
      "src_lang_map",
      "tgt_lang_map",
      "domain_map"
    ],
    "_from_tsv": [
      "cls",
      "root",
      "cfg",
      "split",
      "tgt_dict",
      "is_train_split",
      "pre_tokenizer",
      "bpe_tokenizer",
      "n_frames_per_step",
      "speaker_to_id",
      "src_lang_map",
      "tgt_lang_map",
      "domain_map"
    ],
    "from_tsv": [
      "cls",
      "root",
      "cfg",
      "splits",
      "tgt_dict",
      "pre_tokenizer",
      "bpe_tokenizer",
      "is_train_split",
      "epoch",
      "seed",
      "src_lang_map",
      "tgt_lang_map",
      "domain_map",
      "n_frames_per_step",
      "speaker_to_id"
    ]
  },
  "HeadSelectionS2TTransformerModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_encoder": [
      "cls",
      "args"
    ],
    "build_decoder": [
      "cls",
      "args",
      "task",
      "embed_tokens"
    ]
  },
  "HeadSelectionS2TTransformerEncoder": {
    "__init__": [
      "self",
      "args"
    ],
    "set_task_ids": [
      "self",
      "task_ids"
    ],
    "_forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens"
    ]
  },
  "HeadSelectionTransformerDecoderScriptable": {
    "extract_features": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "full_context_alignment",
      "alignment_layer",
      "alignment_heads"
    ]
  },
  "head_selection_s2t_transformer_s": [
    "args"
  ],
  "HeadSelectionTransformerModel": {
    "__init__": [
      "self",
      "args",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_encoder": [
      "cls",
      "args",
      "src_dict",
      "embed_tokens"
    ],
    "build_decoder": [
      "cls",
      "args",
      "tgt_dict",
      "embed_tokens"
    ]
  },
  "HeadSelectionTransformerEncoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens"
    ],
    "set_task_ids": [
      "self",
      "task_ids"
    ],
    "build_encoder_layer": [
      "self",
      "args",
      "layer_idx"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens",
      "token_embeddings"
    ]
  },
  "HeadSelectionTransformerDecoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens",
      "no_encoder_attn",
      "output_projection"
    ],
    "set_task_ids": [
      "self",
      "task_ids"
    ],
    "build_head_selection_decoder_layer": [
      "self",
      "args",
      "no_encoder_attn",
      "layer_idx"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "features_only",
      "full_context_alignment",
      "alignment_layer",
      "alignment_heads",
      "src_lengths",
      "return_all_hiddens"
    ]
  },
  "_scaled_dot_product_attention": [
    "q",
    "k",
    "v",
    "attn_mask",
    "dropout_p",
    "bsz",
    "subset_heads",
    "subset_weights"
  ],
  "_in_projection": [
    "q",
    "k",
    "v",
    "w_q",
    "w_k",
    "w_v",
    "b_q",
    "b_k",
    "b_v"
  ],
  "multi_head_attention_forward": [
    "query",
    "key",
    "value",
    "embed_dim_to_check",
    "total_num_heads",
    "num_heads",
    "in_proj_weight",
    "in_proj_bias",
    "bias_k",
    "bias_v",
    "add_zero_attn",
    "dropout_p",
    "out_proj_weight",
    "out_proj_bias",
    "training",
    "key_padding_mask",
    "need_weights",
    "attn_mask",
    "use_separate_proj_weight",
    "q_proj_weight",
    "k_proj_weight",
    "v_proj_weight",
    "static_k",
    "static_v",
    "subset_heads",
    "subset_weights"
  ],
  "AttnHeadSelector": {
    "__init__": [
      "self",
      "num_tasks",
      "num_layers",
      "total_num_heads",
      "num_heads",
      "select_strategy",
      "head_select_temp"
    ],
    "gumbel_sample": [
      "self",
      "logits",
      "tau"
    ],
    "subset_select": [
      "self",
      "y_soft",
      "topk",
      "dim"
    ],
    "group_selet": [
      "self",
      "y_soft",
      "topk",
      "dim"
    ],
    "head_select": [
      "self",
      "task_ids"
    ],
    "forward": [
      "self",
      "layer_idx"
    ]
  },
  "MultiheadAttentionSelection": {
    "__init__": [
      "self",
      "embed_dim",
      "total_num_heads",
      "num_heads",
      "kdim",
      "vdim",
      "dropout",
      "bias",
      "add_bias_kv",
      "add_zero_attn",
      "self_attention",
      "encoder_decoder_attention",
      "q_noise",
      "qn_block_size",
      "layer_idx",
      "attn_head_selector"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask",
      "incremental_state",
      "need_weights",
      "static_kv",
      "attn_mask",
      "before_softmax",
      "need_head_weights"
    ]
  },
  "HeadSelectionTransformerEncoderLayer": {
    "__init__": [
      "self",
      "args",
      "layer_idx",
      "attn_head_selector"
    ],
    "build_self_attention_selection": [
      "self",
      "embed_dim",
      "args",
      "attn_head_selector"
    ]
  },
  "HeadSelectionTransformerDecoderLayer": {
    "__init__": [
      "self",
      "args",
      "layer_idx",
      "self_attn_head_selector",
      "enc_attn_head_selector",
      "no_encoder_attn",
      "add_bias_kv",
      "add_zero_attn"
    ],
    "build_self_attention_selection": [
      "self",
      "embed_dim",
      "args",
      "self_attn_head_selector",
      "add_bias_kv",
      "add_zero_attn"
    ],
    "build_encoder_attention_selection": [
      "self",
      "embed_dim",
      "args",
      "enc_attn_head_selector"
    ]
  },
  "SpeechTextPreTrainCompoundCriterionConfig": {},
  "SpeechTextPreTrainCompoundCriterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg",
      "label_smoothing",
      "report_accuracy",
      "zero_infinity",
      "post_process"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "logging_outputs_can_be_summed": [],
    "mode2value": [
      "mode"
    ],
    "value2mode": [
      "value"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ]
  },
  "GuidedCrossEntAccCriterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg",
      "guide_alpha",
      "text_input_cost_ratio",
      "label_smoothing",
      "disable_text_guide_update_num",
      "attentive_cost_regularization"
    ],
    "add_args": [
      "parser"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "compute_loss_and_acc": [
      "self",
      "model",
      "lprobs",
      "target",
      "reduction"
    ],
    "guide_loss_and_acc": [
      "self",
      "model",
      "lprobs",
      "lprobs_teacher",
      "target",
      "reduce"
    ],
    "get_logging_output": [
      "self",
      "sample",
      "loss",
      "nll_loss",
      "correct",
      "total",
      "src_token_num",
      "speech_loss",
      "speech_nll_loss",
      "attn_cost",
      "is_dual_input"
    ],
    "aggregate_logging_outputs": [
      "logging_outputs"
    ],
    "reduce_metrics": [
      "cls",
      "logging_outputs"
    ]
  },
  "SpeechTextPreTrainCrossEntCriterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg",
      "label_smoothing",
      "report_accuracy"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "get_lprobs_and_target": [
      "self",
      "model",
      "net_output",
      "sample"
    ],
    "compute_loss": [
      "self",
      "model",
      "net_output",
      "sample",
      "reduce"
    ]
  },
  "LanguagePairDenoisingDataset": {
    "__init__": [
      "self",
      "src",
      "src_sizes",
      "src_dict",
      "tgt",
      "tgt_sizes",
      "tgt_dict",
      "mask_idx",
      "mask_whole_words",
      "seed",
      "args",
      "left_pad_source",
      "left_pad_target",
      "shuffle",
      "input_feeding",
      "remove_eos_from_source",
      "append_eos_to_target",
      "align_dataset",
      "constraints",
      "append_bos",
      "eos",
      "num_buckets",
      "src_lang_id",
      "tgt_lang_id",
      "pad_to_multiple"
    ],
    "can_reuse_epoch_itr_across_epochs": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "word_starts": [
      "self",
      "source"
    ],
    "add_whole_word_mask": [
      "self",
      "source",
      "p"
    ],
    "add_insertion_noise": [
      "self",
      "tokens",
      "p"
    ]
  },
  "LANG_TAG_TEMPLATE": [],
  "SpeechTextJointToTextTask": {
    "add_args": [
      "cls",
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "src_dict",
      "tgt_dict",
      "infer_tgt_lang_id"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "load_langpair_dataset": [
      "self",
      "prepend_tgt_lang_tag",
      "sampling_alpha",
      "epoch"
    ],
    "inference_step": [
      "self",
      "generator",
      "models",
      "sample",
      "prefix_tokens",
      "constraints"
    ],
    "build_src_tokenizer": [
      "self",
      "args"
    ],
    "build_src_bpe": [
      "self",
      "args"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "target_dictionary": [
      "self"
    ],
    "source_dictionary": [
      "self"
    ],
    "get_batch_iterator": [
      "self",
      "dataset",
      "max_tokens",
      "max_sentences",
      "max_positions",
      "ignore_invalid_inputs",
      "required_batch_size_multiple",
      "seed",
      "num_shards",
      "shard_id",
      "num_workers",
      "epoch",
      "data_buffer_size",
      "disable_iterator_cache",
      "skip_remainder_batch",
      "grouped_shuffling",
      "update_epoch_batch_itr"
    ]
  },
  "gen_whole_word_mask": [
    "args",
    "dictionary"
  ],
  "PairedDenoisingTask": {
    "LANG_TAG_TEMPLATE": [],
    "add_args": [
      "parser"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "__init__": [
      "self",
      "args",
      "src_dict",
      "tgt_dict"
    ],
    "language_pair_denoising_dataset": [
      "cls",
      "data_path",
      "do_mask",
      "split",
      "src",
      "src_dict",
      "tgt",
      "tgt_dict",
      "mask_idx",
      "mask_whole_words",
      "seed",
      "args",
      "dataset_impl",
      "combine",
      "left_pad_source",
      "left_pad_target",
      "max_source_positions",
      "max_target_positions",
      "shuffle",
      "src_lang_id",
      "tgt_lang_id"
    ],
    "_get_sample_prob": [
      "self",
      "dataset_lens"
    ],
    "resample_datasets": [
      "self",
      "lang_datasets",
      "lang_pairs_all",
      "epoch"
    ],
    "load_dataset_only": [
      "self",
      "split",
      "lang_pairs",
      "do_mask",
      "epoch",
      "combine"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ]
  },
  "SpeechTextJointDenoisingPreTask": {
    "SIL_TOKEN": [],
    "add_args": [
      "cls",
      "parser"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "__init__": [
      "self",
      "args",
      "src_dict",
      "tgt_dict"
    ],
    "build_model": [
      "self",
      "args"
    ],
    "build_tokenizer": [
      "self",
      "data_cfg",
      "msg"
    ],
    "build_bpe": [
      "self",
      "data_cfg",
      "msg"
    ],
    "resolve_data_type": [
      "cls",
      "split",
      "use_sup_speech_ctc"
    ],
    "create_modalitydatasetitem": [
      "self",
      "dtype",
      "dataset"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch",
      "combine"
    ],
    "get_sample_ratio": [
      "self",
      "epoch"
    ],
    "get_batch_iterator": [
      "self",
      "dataset",
      "max_tokens",
      "max_sentences",
      "max_positions",
      "ignore_invalid_inputs",
      "required_batch_size_multiple",
      "seed",
      "num_shards",
      "shard_id",
      "num_workers",
      "epoch",
      "data_buffer_size",
      "disable_iterator_cache",
      "skip_remainder_batch",
      "grouped_shuffling",
      "update_epoch_batch_itr"
    ]
  },
  "DualInputWavTransformerModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "update_transformer_encoder_cfg": [
      "cls",
      "args",
      "update_dict"
    ],
    "build_text_encoder": [
      "cls",
      "args",
      "src_dictionary"
    ],
    "build_speech_encoder": [
      "cls",
      "args"
    ],
    "check_args": [
      "cls",
      "condition",
      "is_strict",
      "msg"
    ],
    "build_encoder": [
      "cls",
      "args",
      "task"
    ],
    "build_text_decoder": [
      "cls",
      "args",
      "tgt_dictionary",
      "dec_emb_share"
    ],
    "build_decoder": [
      "cls",
      "args",
      "task"
    ],
    "load_pretrained_speech_text_components": [
      "cls",
      "checkpoint",
      "component_pairs"
    ],
    "share_speech_text_encoder": [
      "cls",
      "speech_encoder",
      "text_encoder",
      "shared_layers_from_begin"
    ]
  },
  "dualinputs2twavtransformer_base": [
    "args"
  ],
  "dualinputs2twavtransformer_base_stack": [
    "args"
  ],
  "dualinputs2twavtransformer_large": [
    "args"
  ],
  "SpeechEoSEncoder": {
    "__init__": [
      "self",
      "encoder",
      "eos_num",
      "feat_dim",
      "adapter_type",
      "adapter_dim"
    ],
    "add_adapter": [
      "self",
      "adapter_type",
      "adapter_dim"
    ],
    "add_eos": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "apply_adapter": [
      "self",
      "enc_out"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ]
  },
  "DualInputEncoder": {
    "__init__": [
      "self",
      "args",
      "spch_encoder",
      "text_encoder",
      "dictionary",
      "cross_attentive_loss_before_last_layer"
    ],
    "set_shared_layer": [
      "cls",
      "share_level",
      "src_layer",
      "tgt_layer"
    ],
    "build_spch_encoder": [
      "cls",
      "args"
    ],
    "build_text_encoder": [
      "cls",
      "args",
      "src_dictionary",
      "spch_encoder"
    ],
    "mult_rst_grad": [
      "self",
      "rst",
      "ratio"
    ],
    "process_attentive_loss_states": [
      "self",
      "rst",
      "interstates"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "src_txt_tokens",
      "src_txt_lengths"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ]
  },
  "TransformerMultiInputDecoder": {
    "__init__": [
      "self",
      "dictionary",
      "spch_decoder",
      "text_decoder",
      "compute_cross_attentive_loss",
      "cross_attentive_loss_with_norm",
      "cross_attentive_loss_reverse"
    ],
    "share_spchdecoder": [
      "cls",
      "task_args",
      "text_decoder",
      "spch_decoder"
    ],
    "cross_attentive_loss": [
      "self",
      "teacher_states",
      "student_states",
      "teacher_masking",
      "student_masking",
      "eps"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "has_txt_input"
    ]
  },
  "DualInputS2TTransformerModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "max_positions": [
      "self"
    ],
    "add_args": [
      "parser"
    ],
    "build_encoder": [
      "cls",
      "args",
      "task"
    ],
    "build_decoder": [
      "cls",
      "args",
      "task"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "use_encoder_outputs",
      "src_txt_tokens",
      "src_txt_lengths",
      "mode"
    ]
  },
  "dualinputs2ttransformer_base": [
    "args"
  ],
  "dualinputs2ttransformer_s": [
    "args"
  ],
  "dualinputs2ttransformer_m": [
    "args"
  ],
  "dualinputs2ttransformer_b": [
    "args"
  ],
  "dualinputs2ttransformer_l": [
    "args"
  ],
  "TransformerSentenceEncoderLayerStd": {
    "__init__": [
      "self",
      "sent_enc_layer"
    ],
    "forward": [
      "self",
      "x",
      "self_attn_mask",
      "self_attn_padding_mask",
      "need_weights",
      "att_args"
    ]
  },
  "SharedEncoder": {
    "__init__": [
      "self",
      "wav2vec_enc",
      "mbart_enc",
      "adaptor",
      "shared_layers"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ]
  },
  "StackedWav2VecEncoderWithAdaptor": {
    "__init__": [
      "self",
      "wav2vec_enc",
      "mbart_enc_layers",
      "mbart_layer_norm",
      "adaptor",
      "drop_w2v_layers"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "return_all_hiddens"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ]
  },
  "DualInputXMTransformerModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "add_args": [
      "parser"
    ],
    "build_encoder": [
      "cls",
      "args",
      "task"
    ],
    "build_decoder": [
      "cls",
      "args",
      "task"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ]
  },
  "dualinputxmtransformer_base": [
    "args"
  ],
  "SpeechTextPreTrainEncoder": {
    "__init__": [
      "self",
      "dictionary",
      "sup_speech_encoder",
      "sup_s2s_speech_encoder",
      "unsup_speech_encoder",
      "text_encoder"
    ],
    "update_transformer_encoder_cfg": [
      "cls",
      "args",
      "update_dict"
    ],
    "build_text_encoder": [
      "cls",
      "args",
      "src_dictionary"
    ],
    "build_speech_encoder": [
      "cls",
      "args"
    ],
    "share_layers": [
      "cls",
      "src_layers",
      "tgt_layers"
    ],
    "build_unsup_speech_encoder": [
      "cls",
      "args",
      "sup_speech_encoder"
    ],
    "build_encoder": [
      "cls",
      "args",
      "dictionary"
    ],
    "share_speech_text_encoder": [
      "cls",
      "speech_encoder",
      "text_encoder",
      "shared_layers_from_begin"
    ],
    "select_encoder": [
      "self",
      "mode"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "mode",
      "alignment"
    ]
  },
  "SpeechDummyDecoder": {
    "__init__": [
      "self",
      "dictionary",
      "output_embedding",
      "no_emb_update_unsup",
      "use_output_proj"
    ],
    "extend_alignment": [
      "self",
      "alignment",
      "src_lengths",
      "prev_output_tokens"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "mode",
      "alignment"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ]
  },
  "SpeechTextPreTrainDecoder": {
    "__init__": [
      "self",
      "dictionary",
      "speech_decoder",
      "text_decoder"
    ],
    "select_decoder": [
      "self",
      "mode"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "build_text_decoder": [
      "cls",
      "args",
      "tgt_dictionary",
      "dec_emb_share"
    ],
    "build_dummy_speech_decoder": [
      "cls",
      "args",
      "dictionary",
      "dec_emb_share"
    ],
    "build_decoder": [
      "cls",
      "args",
      "text_dictionary",
      "speech_dictionary",
      "speech_output_embedding"
    ]
  },
  "SpeechTextPreTrainModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "src_lang_ids"
    ],
    "max_positions": [
      "self"
    ],
    "get_targets": [
      "self",
      "sample",
      "net_output"
    ],
    "get_normalized_probs": [
      "self",
      "net_output",
      "log_probs",
      "sample"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ],
    "upgrade_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "speech_text_pretrain_bart_base": [
    "args"
  ],
  "speech_text_pretrain_bart_base_stack": [
    "args"
  ],
  "speech_text_pretrain_bart_large": [
    "args"
  ],
  "speech_text_pretrain_bart_large_stack": [
    "args"
  ],
  "FAIL_SENT": [],
  "parse": [],
  "process_sent": [
    "sent",
    "g2p",
    "res_wrds",
    "args"
  ],
  "remove_punc": [
    "sent"
  ],
  "do_g2p": [
    "g2p",
    "sent",
    "res_wrds",
    "is_first_sent"
  ],
  "pre_process_sent": [
    "sent",
    "do_filter",
    "lower_case",
    "res_wrds"
  ],
  "dup_pho": [
    "sent",
    "dup_v_num",
    "dup_c_num"
  ],
  "add_word_start": [
    "sent"
  ],
  "load_reserve_word": [
    "reserve_word"
  ],
  "process_sents": [
    "sents",
    "args"
  ],
  "is_update": [
    "param_name",
    "module_name"
  ],
  "XSUM_KWARGS": [],
  "CNN_KWARGS": [],
  "LaserTransformerModel": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths",
      "prev_output_tokens",
      "tgt_tokens",
      "tgt_lengths",
      "target_language_id",
      "dataset_name"
    ],
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ]
  },
  "LaserTransformerEncoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "src_tokens"
    ],
    "reorder_encoder_out": [
      "self",
      "encoder_out",
      "new_order"
    ]
  },
  "LaserTransformerDecoder": {
    "__init__": [
      "self",
      "args",
      "dictionary"
    ],
    "build_decoder_layer": [
      "self",
      "args",
      "no_encoder_attn"
    ],
    "extract_features": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "full_context_alignment",
      "alignment_layer",
      "alignment_heads",
      "lang_id"
    ],
    "forward": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "features_only",
      "alignment_layer",
      "alignment_heads",
      "src_lengths",
      "return_all_hiddens",
      "lang_id"
    ]
  },
  "base_laser_transformer_architecture": [
    "args"
  ],
  "LaserTask": {
    "add_args": [
      "parser"
    ],
    "__init__": [
      "self",
      "args",
      "config",
      "src_dictionary",
      "tgt_dictionary",
      "num_tasks"
    ],
    "setup_task": [
      "cls",
      "args"
    ],
    "build_model": [
      "self",
      "args",
      "from_checkpoint"
    ],
    "dataset": [
      "self",
      "split"
    ],
    "load_dataset": [
      "self",
      "split",
      "epoch"
    ],
    "source_dictionary": [
      "self"
    ],
    "target_dictionary": [
      "self"
    ],
    "get_batch_iterator": [
      "self",
      "dataset",
      "max_tokens",
      "max_sentences",
      "max_positions",
      "ignore_invalid_inputs",
      "required_batch_size_multiple",
      "seed",
      "num_shards",
      "shard_id",
      "num_workers",
      "epoch",
      "data_buffer_size",
      "disable_iterator_cache",
      "grouped_shuffling",
      "update_epoch_batch_itr"
    ]
  },
  "MultiItr": {
    "__init__": [
      "self",
      "itr"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ]
  },
  "MultidatasetEpochBatchIterator": {
    "__init__": [
      "self",
      "dataset",
      "batch_sampler",
      "seed",
      "num_shards",
      "shard_id",
      "num_workers",
      "epoch"
    ],
    "__len__": [
      "self"
    ],
    "next_epoch_itr": [
      "self",
      "shuffle",
      "fix_batches_to_gpus"
    ],
    "end_of_epoch": [
      "self"
    ],
    "next_epoch_idx": [
      "self"
    ],
    "iterations_in_epoch": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "MultitaskDatasetWrapper": {
    "__init__": [
      "self",
      "dataset",
      "target_language_id",
      "sample",
      "name"
    ],
    "collater": [
      "self"
    ],
    "num_tokens": [
      "self"
    ],
    "ordered_indices": [
      "self"
    ],
    "size": [
      "self",
      "index"
    ],
    "supports_prefetch": [
      "self"
    ],
    "prefetch": [
      "self",
      "indices"
    ]
  },
  "WORKDIR_ROOT": [],
  "load_langs": [
    "path"
  ],
  "load_sentences": [
    "raw_data",
    "split",
    "direction"
  ],
  "swap_direction": [
    "d"
  ],
  "get_all_test_data": [
    "raw_data",
    "directions",
    "split"
  ],
  "check_train_sentences": [
    "src_path",
    "tgt_path",
    "direction",
    "all_test_data",
    "mess_up_train"
  ],
  "check_train_all": [
    "raw_data",
    "directions",
    "all_test_data"
  ],
  "BLEU_REGEX": [],
  "run_eval_bleu": [
    "cmd"
  ],
  "check_data_test_bleu": [
    "raw_folder",
    "data_lang_pairs"
  ],
  "get_directions": [
    "folder"
  ],
  "diff_list": [
    "lhs",
    "rhs"
  ],
  "check_diff": [
    "from_src_file",
    "from_tgt_file",
    "to_src_file",
    "to_tgt_file"
  ],
  "count_train_in_other_set": [
    "mess_up_train"
  ],
  "train_size_if_remove_in_otherset": [
    "data_sizes",
    "mess_up_train"
  ],
  "remove_messed_up_sentences": [
    "raw_data",
    "direction",
    "mess_up_train",
    "mess_up_train_pairs",
    "corrected_langs"
  ],
  "merge_valid_test_messup": [
    "mess_up_train_valid",
    "mess_up_train_test"
  ],
  "check_train_pairs": [
    "raw_data",
    "direction",
    "all_test_data",
    "mess_up_train"
  ],
  "load_pairs": [
    "raw_data",
    "split",
    "direction"
  ],
  "get_messed_up_test_pairs": [
    "split",
    "directions"
  ],
  "call_output": [
    "cmd"
  ],
  "SPM_PATH": [],
  "SPM_MODEL": [],
  "SPM_VOCAB": [],
  "SPM_ENCODE": [],
  "get_data_size": [
    "raw"
  ],
  "encode_spm": [
    "model",
    "direction",
    "prefix",
    "splits",
    "pairs_per_shard"
  ],
  "binarize_": [
    "bpe_dir",
    "databin_dir",
    "direction",
    "spm_vocab",
    "splits"
  ],
  "binarize": [
    "databin_dir",
    "direction",
    "spm_vocab",
    "prefix",
    "splits",
    "pairs_per_shard"
  ],
  "CWD": [],
  "UTILS": [],
  "MOSES": [],
  "SGM_TOOL": [],
  "TMX2CORPUS": [],
  "TMX_TOOL": [],
  "to_data_path": [],
  "download_to": [],
  "manually_downloads": [],
  "extract_to": [],
  "raw_data": [],
  "DLDataset": {},
  "bar_custom": [
    "current",
    "total",
    "width"
  ],
  "get_downloaded_file": [
    "dl_folder",
    "url"
  ],
  "download_parts_and_combine": [
    "dl_folder",
    "urls",
    "filename"
  ],
  "download_a_url": [
    "dl_folder",
    "url"
  ],
  "download_files": [
    "dl_folder",
    "urls",
    "completed_urls"
  ],
  "check_need_manual_downalod": [
    "dl_folder",
    "to_manually_download_urls"
  ],
  "download_dataset": [
    "to_folder",
    "dl_dataset",
    "completed_urls"
  ],
  "get_extract_name": [
    "file_path"
  ],
  "extract_file": [
    "downloaded_file",
    "extract_folder",
    "get_extract_name",
    "debug"
  ],
  "extract_all_files": [
    "completed_urls",
    "extract_folder",
    "get_extract_name",
    "completed_extraction",
    "debug"
  ],
  "my_glob": [
    "folder"
  ],
  "sgm2raw": [
    "sgm",
    "debug"
  ],
  "tmx2raw": [
    "tmx",
    "debug"
  ],
  "CZENG16_REGEX": [],
  "WMT19_WIKITITLES_REGEX": [],
  "TSV_REGEX": [],
  "cut_wikitles": [
    "wiki_file",
    "debug"
  ],
  "cut_tsv": [
    "file",
    "debug"
  ],
  "convert_file_if_needed": [
    "file",
    "debug"
  ],
  "convert_files_if_needed": [
    "extracted_foldrs",
    "my_glob",
    "debug"
  ],
  "match_patt": [
    "file_path",
    "file_pattern",
    "src",
    "tgt",
    "lang"
  ],
  "match_patts": [
    "file_path",
    "file_patterns",
    "src",
    "tgt",
    "lang"
  ],
  "extracted_glob": [
    "extracted_folder",
    "file_patterns",
    "src",
    "tgt",
    "lang"
  ],
  "all_extracted_files": [
    "split",
    "src",
    "tgt",
    "extracted_folders",
    "split_urls"
  ],
  "concat_files": [
    "split",
    "src",
    "tgt",
    "extracted_folders",
    "split_urls",
    "path_patterns",
    "to_folder",
    "debug"
  ],
  "LID_MODEL": [],
  "LID_MULTI": [],
  "lid_filter": [
    "split",
    "src",
    "tgt",
    "from_folder",
    "to_folder",
    "debug"
  ],
  "concat_into_splits": [
    "dl_dataset",
    "src",
    "tgt",
    "extracted_folders",
    "to_folder",
    "debug"
  ],
  "download_multi": [
    "dl_folder",
    "extract_folder",
    "urls",
    "num_processes",
    "debug"
  ],
  "check_wmt_test_bleu": [
    "raw_folder",
    "wmt_lang_pairs"
  ],
  "download_and_extract": [
    "to_folder",
    "lang_pairs",
    "dl_dataset",
    "to_manually_download_urls",
    "completed_urls",
    "completed_extraction",
    "debug"
  ],
  "download_czang16": [
    "download_to",
    "username"
  ],
  "download_czeng17_script": [
    "download_to",
    "extract_folder",
    "debug"
  ],
  "czeng17_script_path": [],
  "convert2czeng17": [
    "file",
    "debug"
  ],
  "extract_czeng17": [
    "extract_folder",
    "debug"
  ],
  "wmt13_es_en": [],
  "wmt14_de_fr_en": [],
  "wmt16_ro_en": [],
  "cwmt_wmt_instruction": [],
  "wmt17_fi_lv_tr_zh_en_manual_downloads": [],
  "wmt17_fi_lv_tr_zh_en": [],
  "czeng_instruction": [],
  "wmt18_cs_et_en_manual_downloads": [],
  "wmt18_cs_et_en": [],
  "ru_en_yandex_instruction": [],
  "wmt19_ru_gu_kk_lt_manual_downloads": [],
  "wmt19_ru_gu_kk_lt": [],
  "detok_cmd": [],
  "MultiLingualAlignedCorpusReader": {
    "__init__": [
      "self",
      "corpus_path",
      "delimiter",
      "target_token",
      "bilingual",
      "corpus_type",
      "lang_dict",
      "eval_lang_dict",
      "zero_shot",
      "detok"
    ],
    "read_data": [
      "self",
      "file_loc_"
    ],
    "filter_text": [
      "self",
      "dict_"
    ],
    "read_file": [
      "self",
      "split_type",
      "data_type"
    ],
    "save_file": [
      "self",
      "path_",
      "split_type",
      "data_type",
      "lang"
    ],
    "add_target_token": [
      "self",
      "list_",
      "lang_id"
    ],
    "read_from_single_file": [
      "self",
      "path_",
      "s_lang",
      "t_lang"
    ],
    "read_aligned_corpus": [
      "self",
      "split_type"
    ]
  },
  "read_langs": [
    "corpus_path"
  ],
  "extra_english": [
    "corpus_path",
    "split"
  ],
  "tok_file_name": [
    "filename",
    "lang"
  ],
  "de_tok": [
    "tok_file",
    "lang"
  ],
  "extra_bitex": [
    "ted_data_path",
    "lsrc_lang",
    "ltrg_lang",
    "target_token",
    "output_data_path"
  ],
  "deup": [
    "src_file",
    "tgt_file",
    "src_file_out",
    "tgt_file_out"
  ],
  "pred": [
    "lines"
  ],
  "SentencePredictionR3F": {
    "__init__": [
      "self",
      "task",
      "eps",
      "r3f_lambda",
      "noise_type",
      "classification_head_name",
      "regression_target"
    ],
    "add_args": [
      "parser"
    ],
    "_get_symm_kl": [
      "self",
      "noised_logits",
      "input_logits"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "aggregate_logging_outputs": [
      "logging_outputs"
    ]
  },
  "LabelSmoothedCrossEntropyR3FCriterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg",
      "label_smoothing",
      "eps",
      "r3f_lambda",
      "noise_type"
    ],
    "add_args": [
      "parser"
    ],
    "_get_symm_kl": [
      "self",
      "noised_logits",
      "input_logits"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "compute_loss": [
      "self",
      "model",
      "net_output",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "_skew": [
    "X",
    "pad_value"
  ],
  "_unskew": [
    "X"
  ],
  "SeqAttention": {
    "__init__": [
      "self",
      "d_model",
      "n_head",
      "attn_span",
      "dropout",
      "adapt_span_layer"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_pe"
    ],
    "get_cache_size": [
      "self"
    ]
  },
  "MultiHeadSeqAttention": {
    "__init__": [
      "self",
      "d_model",
      "n_head"
    ],
    "head_reshape": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_pe"
    ]
  },
  "FeedForwardLayer": {
    "__init__": [
      "self",
      "d_model",
      "d_inner",
      "dropout"
    ],
    "forward": [
      "self",
      "h"
    ]
  },
  "TransformerSeqLayer": {
    "__init__": [
      "self",
      "d_model"
    ],
    "forward": [
      "self",
      "h",
      "h_cache",
      "key_pe"
    ],
    "get_cache_size": [
      "self"
    ]
  },
  "TransformerSeq": {
    "__init__": [
      "self",
      "vocab_size",
      "d_model",
      "n_head",
      "n_layer",
      "attn_span",
      "emb_dropout",
      "aux_loss_scaler",
      "adapt_span_layer"
    ],
    "forward": [
      "self",
      "x",
      "h_cache",
      "target"
    ],
    "get_aux_loss": [
      "self"
    ],
    "get_current_max_span": [
      "self"
    ],
    "get_current_avg_span": [
      "self"
    ]
  },
  "FairseqAdagradWithGradClip": {
    "__init__": [
      "self",
      "args",
      "params"
    ],
    "add_args": [
      "parser"
    ],
    "optimizer_config": [
      "self"
    ],
    "supports_flat_params": [
      "self"
    ]
  },
  "_clip_grad": [
    "clr",
    "grad",
    "group_grad_clip"
  ],
  "AdagradWithGradClip": {
    "__init__": [
      "self",
      "params",
      "lr",
      "lr_decay",
      "weight_decay",
      "initial_accumulator_value",
      "grad_clip"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "cur_dir": [],
  "AdaptiveSpanCriterionConfig": {},
  "AdaptiveSpanCriterion": {
    "__init__": [
      "self",
      "task",
      "sentence_avg"
    ],
    "forward": [
      "self",
      "model",
      "sample",
      "reduce"
    ],
    "compute_loss": [
      "self",
      "model",
      "net_output",
      "sample",
      "reduce"
    ],
    "reduce_metrics": [
      "logging_outputs"
    ],
    "logging_outputs_can_be_summed": []
  },
  "AdaptiveSpanSmallConfig": {},
  "AdaptiveSpanTransformer": {
    "build_model": [
      "cls",
      "cfg",
      "task"
    ],
    "get_aux_loss": [
      "self"
    ],
    "get_current_max_span": [
      "self"
    ],
    "get_current_avg_span": [
      "self"
    ]
  },
  "AdaptiveSpanDecoder": {
    "__init__": [
      "self",
      "cfg",
      "task"
    ],
    "forward": [
      "self",
      "src_tokens",
      "incremental_state",
      "encoder_out"
    ],
    "max_positions": [
      "self"
    ],
    "init_hid_cache": [
      "self",
      "batch_sz"
    ],
    "get_aux_loss": [
      "self"
    ],
    "get_current_max_span": [
      "self"
    ],
    "get_current_avg_span": [
      "self"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ]
  },
  "AdaptiveMask": {
    "__init__": [
      "self",
      "max_size",
      "ramp_size",
      "init_val",
      "shape"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_current_max_size": [
      "self",
      "include_ramp"
    ],
    "get_current_avg_size": [
      "self",
      "include_ramp"
    ],
    "clamp_param": [
      "self"
    ]
  },
  "AdaptiveSpan": {
    "__init__": [
      "self",
      "attn_span",
      "adapt_span_ramp",
      "adapt_span_init",
      "n_head",
      "adapt_span_layer"
    ],
    "forward": [
      "self",
      "attn",
      "normalize"
    ],
    "get_trim_len": [
      "self"
    ],
    "trim_memory": [
      "self",
      "query",
      "key",
      "value",
      "key_pe"
    ],
    "get_cache_size": [
      "self"
    ],
    "get_loss": [
      "self"
    ],
    "get_current_max_span": [
      "self"
    ],
    "get_current_avg_span": [
      "self"
    ],
    "clamp_param": [
      "self"
    ]
  },
  "NoisyChannelSequenceGenerator": {
    "__init__": [
      "self",
      "combine_method",
      "tgt_dict",
      "src_dict",
      "beam_size",
      "max_len_a",
      "max_len_b",
      "min_len",
      "len_penalty",
      "unk_penalty",
      "retain_dropout",
      "temperature",
      "match_source_len",
      "no_repeat_ngram_size",
      "normalize_scores",
      "channel_models",
      "k2",
      "ch_weight",
      "channel_scoring_type",
      "top_k_vocab",
      "lm_models",
      "lm_dict",
      "lm_weight",
      "normalize_lm_scores_by_tgt_len"
    ],
    "generate": [
      "self",
      "models",
      "sample",
      "prefix_tokens",
      "bos_token"
    ]
  },
  "get_lm_scores": [
    "model",
    "input_tokens",
    "incremental_states",
    "cand_tokens",
    "input_len",
    "k"
  ],
  "make_dict2dict": [
    "old_dict",
    "new_dict"
  ],
  "dict2dict": [
    "tokens",
    "dict2dict_map"
  ],
  "reorder_tokens": [
    "tokens",
    "lengths",
    "eos"
  ],
  "reorder_all_tokens": [
    "tokens",
    "lengths",
    "eos"
  ],
  "normalized_scores_with_batch_vocab": [
    "model_decoder",
    "features",
    "target_ids",
    "k",
    "bsz",
    "beam_size",
    "pad_idx",
    "top_k",
    "vocab_size_meter",
    "start_idx",
    "end_idx"
  ],
  "NoisyChannelTranslation": {
    "add_args": [
      "parser"
    ],
    "build_generator": [
      "self",
      "models",
      "args",
      "seq_gen_cls",
      "extra_gen_cls_kwargs"
    ]
  },
  "NoisyChannelBeamSearch": {
    "__init__": [
      "self",
      "tgt_dict"
    ],
    "_init_buffers": [
      "self",
      "t"
    ],
    "combine_fw_bw": [
      "self",
      "combine_method",
      "fw_cum",
      "bw",
      "step"
    ],
    "step": [
      "self",
      "step",
      "fw_lprobs",
      "scores",
      "bw_lprobs",
      "lm_lprobs",
      "combine_method"
    ]
  },
  "GRUTransformerModel": {
    "build_encoder": [
      "cls",
      "args",
      "src_dict",
      "embed_tokens"
    ]
  },
  "GRUTransformerEncoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens"
    ],
    "forward_embedding": [
      "self",
      "src_tokens"
    ]
  },
  "gru_transformer_base_architecture": [
    "args"
  ],
  "gru_transformer_big": [
    "args"
  ],
  "SPLITS": [],
  "_convert_xml": [
    "in_path",
    "out_path"
  ],
  "_convert_train": [
    "in_path",
    "out_path"
  ],
  "_get_bytes": [
    "in_path",
    "out_path"
  ],
  "_get_chars": [
    "in_path",
    "out_path"
  ],
  "pretokenize": [
    "in_path",
    "out_path",
    "src",
    "tgt"
  ],
  "_convert_to_bchar": [
    "in_path_prefix",
    "src",
    "tgt",
    "out_path"
  ],
  "_get_bpe": [
    "in_path",
    "model_prefix",
    "vocab_size"
  ],
  "_apply_bbpe": [
    "model_path",
    "in_path",
    "out_path"
  ],
  "_apply_bpe": [
    "model_path",
    "in_path",
    "out_path"
  ],
  "_concat_files": [
    "in_paths",
    "out_path"
  ],
  "preprocess_iwslt17": [
    "root",
    "src",
    "tgt",
    "bpe_size",
    "need_chars",
    "bbpe_size",
    "need_bytes"
  ],
  "read_hist": [
    "f"
  ],
  "len_no_punc": [
    "s",
    "punc"
  ],
  "filter_overpunc": [
    "len_npunc",
    "len_sen"
  ],
  "DATADIR": [],
  "DEDUP_FROM_DIR": [],
  "OUTPUT_DIR": [],
  "LanguagePair": [],
  "existing_data": [],
  "dedup": [
    "language_pair",
    "data",
    "verbose",
    "output"
  ],
  "factory": [],
  "normalizer": [],
  "BOS_PREFIX": [],
  "SimulTransTextAgentJA": {
    "__init__": [
      "self",
      "args"
    ],
    "initialize_states": [
      "self",
      "states"
    ],
    "to_device": [
      "self",
      "tensor"
    ],
    "load_model_vocab": [
      "self",
      "args"
    ],
    "add_args": [
      "parser"
    ],
    "build_word_splitter": [
      "self",
      "args"
    ],
    "segment_to_units": [
      "self",
      "segment",
      "states"
    ],
    "update_model_encoder": [
      "self",
      "states"
    ],
    "update_states_read": [
      "self",
      "states"
    ],
    "units_to_segment": [
      "self",
      "units",
      "states"
    ],
    "policy": [
      "self",
      "states"
    ],
    "predict": [
      "self",
      "states"
    ]
  },
  "TEST_CUDA": [],
  "AlignmentTrainTest": {
    "_test_custom_alignment_train_ref": [
      "self",
      "p_choose",
      "eps"
    ],
    "_test_custom_alignment_train_impl": [
      "self",
      "p_choose",
      "alpha",
      "eps"
    ],
    "test_alignment_train": [
      "self",
      "bsz",
      "tgt_len",
      "src_len",
      "device"
    ]
  },
  "DEFAULT_CONFIG": [],
  "PAD_INDEX": [],
  "generate_config": [
    "overrides_kv"
  ],
  "make_sample_with_padding": [
    "longer_src"
  ],
  "build_transformer_monotonic_attention": [],
  "expected_alignment_formula": [
    "p_choose",
    "mass_perservation",
    "padding_mask"
  ],
  "mass_perservation_formula": [
    "alpha",
    "left_padding",
    "padding_mask"
  ],
  "expected_soft_attention_formula": [
    "alpha",
    "soft_energy",
    "padding_mask",
    "chunksize"
  ],
  "MonotonicAttentionTestAbstractClass": {
    "test_forward": [
      "self"
    ],
    "test_p_choose": [
      "self"
    ],
    "test_expected_alignment": [
      "self"
    ]
  },
  "HardMonotonicAttentionTestCase": {
    "setUp": [
      "self"
    ]
  },
  "InfiniteLookbackTestCase": {
    "setUp": [
      "self"
    ],
    "test_fp16_for_long_input": [
      "self"
    ],
    "test_expected_attention": [
      "self"
    ]
  },
  "ChunkwiswTestCase": {
    "setUp": [
      "self"
    ]
  },
  "WaitkTestCase": {
    "setUp": [
      "self"
    ],
    "check_waitk": [
      "self",
      "p_choose",
      "lagging",
      "padding_mask"
    ],
    "test_waitk_p_choose": [
      "self"
    ]
  },
  "expected_alignment_from_p_choose": [
    "p_choose",
    "padding_mask",
    "eps"
  ],
  "expected_soft_attention": [
    "alpha",
    "soft_energy",
    "padding_mask",
    "chunk_size",
    "eps"
  ],
  "mass_preservation": [
    "alpha",
    "padding_mask",
    "left_padding"
  ],
  "waitk_p_choose": [
    "tgt_len",
    "src_len",
    "bsz",
    "waitk_lagging",
    "key_padding_mask",
    "incremental_state"
  ],
  "learnable_p_choose": [
    "energy",
    "noise_mean",
    "noise_var",
    "training"
  ],
  "prob_check": [
    "tensor",
    "eps"
  ],
  "exclusive_cumprod": [
    "tensor",
    "dim",
    "eps"
  ],
  "safe_cumprod": [
    "tensor",
    "dim",
    "eps"
  ],
  "moving_sum": [
    "x",
    "start_idx",
    "end_idx"
  ],
  "SimulConvTransformerModel": {
    "add_args": [
      "parser"
    ],
    "build_decoder": [
      "cls",
      "args",
      "task",
      "embed_tokens"
    ]
  },
  "convtransformer_simul_trans_espnet": [
    "args"
  ],
  "AugmentedMemoryConvTransformerModel": {
    "build_encoder": [
      "cls",
      "args"
    ]
  },
  "augmented_memory_convtransformer_espnet": [
    "args"
  ],
  "ConvTransformerEmformerEncoder": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "src_tokens",
      "src_lengths"
    ],
    "conv_layer_stride": [
      "args"
    ]
  },
  "ConvtransformerEmformer": {
    "add_args": [
      "parser"
    ],
    "build_encoder": [
      "cls",
      "args"
    ]
  },
  "convtransformer_emformer_base": [
    "args"
  ],
  "READ_ACTION": [],
  "WRITE_ACTION": [],
  "TransformerMonotonicDecoderOut": [],
  "TransformerUnidirectionalModel": {
    "build_encoder": [
      "cls",
      "args",
      "src_dict",
      "embed_tokens"
    ]
  },
  "TransformerModelSimulTrans": {
    "build_encoder": [
      "cls",
      "args",
      "src_dict",
      "embed_tokens"
    ],
    "build_decoder": [
      "cls",
      "args",
      "tgt_dict",
      "embed_tokens"
    ]
  },
  "TransformerMonotonicEncoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens"
    ]
  },
  "TransformerMonotonicDecoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens",
      "no_encoder_attn"
    ],
    "set_num_updates": [
      "self",
      "num_updates"
    ],
    "pre_attention": [
      "self",
      "prev_output_tokens",
      "encoder_out_dict",
      "incremental_state"
    ],
    "post_attention": [
      "self",
      "x"
    ],
    "clean_cache": [
      "self",
      "incremental_state",
      "end_id"
    ],
    "extract_features": [
      "self",
      "prev_output_tokens",
      "encoder_out",
      "incremental_state",
      "full_context_alignment",
      "alignment_layer",
      "alignment_heads"
    ]
  },
  "base_monotonic_architecture": [
    "args"
  ],
  "transformer_monotonic_iwslt_de_en": [
    "args"
  ],
  "transformer_monotonic_vaswani_wmt_en_de_big": [
    "args"
  ],
  "transformer_monotonic_vaswani_wmt_en_fr_big": [
    "args"
  ],
  "transformer_unidirectional_iwslt_de_en": [
    "args"
  ],
  "monotonic_tiny_architecture": [
    "args"
  ],
  "MonotonicAttention": {
    "__init__": [
      "self",
      "args"
    ],
    "add_args": [
      "parser"
    ],
    "energy_from_qk": [
      "self",
      "query",
      "key",
      "energy_type",
      "key_padding_mask",
      "bias"
    ],
    "p_choose_from_qk": [
      "self",
      "query",
      "key",
      "key_padding_mask",
      "incremental_states"
    ],
    "p_choose": [
      "self",
      "query",
      "key",
      "key_padding_mask",
      "incremental_states"
    ],
    "monotonic_attention_process_infer": [
      "self",
      "query",
      "key",
      "incremental_state"
    ],
    "monotonic_attention_process_train": [
      "self",
      "query",
      "key",
      "key_padding_mask"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask",
      "attn_mask",
      "incremental_state",
      "need_weights",
      "static_kv",
      "need_head_weights"
    ],
    "_get_monotonic_buffer": [
      "self",
      "incremental_state"
    ],
    "_set_monotonic_buffer": [
      "self",
      "incremental_state",
      "buffer"
    ]
  },
  "MonotonicInfiniteLookbackAttention": {
    "__init__": [
      "self",
      "args"
    ],
    "init_soft_attention": [
      "self"
    ]
  },
  "WaitKAttention": {
    "__init__": [
      "self",
      "args"
    ],
    "add_args": [
      "parser"
    ],
    "p_choose_from_qk": [
      "self",
      "query",
      "key",
      "key_padding_mask",
      "incremental_state"
    ]
  },
  "ChunkwiseAttention": {
    "__init__": [
      "self",
      "args"
    ],
    "add_args": [
      "parser"
    ]
  },
  "TransformerMonotonicEncoderLayer": {
    "forward": [
      "self",
      "x",
      "encoder_padding_mask"
    ]
  },
  "TransformerMonotonicDecoderLayer": {
    "__init__": [
      "self",
      "args"
    ],
    "prune_incremental_state": [
      "self",
      "incremental_state"
    ],
    "forward": [
      "self",
      "x",
      "encoder_out",
      "encoder_padding_mask",
      "incremental_state",
      "prev_self_attn_state",
      "prev_attn_state",
      "self_attn_mask",
      "self_attn_padding_mask",
      "need_attn",
      "need_head_weights"
    ]
  },
  "fixed_pooling_monotonic_attention": [
    "monotonic_attention"
  ],
  "WaitKAttentionFixedStride": {},
  "MonotonicAttentionFixedStride": {},
  "MonotonicInfiniteLookbackAttentionFixedStride": {},
  "log": [],
  "MUSTC": {
    "SPLITS": [],
    "LANGUAGES": [],
    "__init__": [
      "self",
      "root",
      "lang",
      "split"
    ],
    "__getitem__": [
      "self",
      "n"
    ],
    "__len__": [
      "self"
    ]
  },
  "process_joint": [
    "args"
  ],
  "CoVoST": {
    "COVOST_URL_TEMPLATE": [],
    "VERSIONS": [],
    "SPLITS": [],
    "XX_EN_LANGUAGES": [],
    "EN_XX_LANGUAGES": [],
    "__init__": [
      "self",
      "root",
      "split",
      "source_language",
      "target_language",
      "version"
    ],
    "__getitem__": [
      "self",
      "n"
    ],
    "__len__": [
      "self"
    ]
  },
  "mTEDx": {
    "SPLITS": [],
    "LANGPAIRS": [],
    "__init__": [
      "self",
      "root",
      "lang",
      "split"
    ],
    "__getitem__": [
      "self",
      "n"
    ],
    "__len__": [
      "self"
    ]
  },
  "gen_vocab": [
    "input_path",
    "output_path_prefix",
    "model_type",
    "vocab_size",
    "special_symbols"
  ],
  "extract_fbank_features": [
    "waveform",
    "sample_rate",
    "output_path",
    "n_mel_bins",
    "overwrite"
  ],
  "create_zip": [
    "data_root",
    "zip_path"
  ],
  "get_zip_manifest": [
    "zip_path",
    "zip_root",
    "is_audio"
  ],
  "load_df_from_tsv": [
    "path"
  ],
  "save_df_to_tsv": [
    "dataframe",
    "path"
  ],
  "load_tsv_to_dicts": [
    "path"
  ],
  "filter_manifest_df": [
    "df",
    "is_train_split",
    "extra_filters",
    "min_n_frames",
    "max_n_frames"
  ],
  "cal_gcmvn_stats": [
    "features_list"
  ],
  "S2TDataConfigWriter": {
    "DEFAULT_VOCAB_FILENAME": [],
    "DEFAULT_INPUT_FEAT_PER_CHANNEL": [],
    "DEFAULT_INPUT_CHANNELS": [],
    "__init__": [
      "self",
      "yaml_path"
    ],
    "flush": [
      "self"
    ],
    "set_audio_root": [
      "self",
      "audio_root"
    ],
    "set_vocab_filename": [
      "self",
      "vocab_filename"
    ],
    "set_specaugment": [
      "self",
      "time_wrap_w",
      "freq_mask_n",
      "freq_mask_f",
      "time_mask_n",
      "time_mask_t",
      "time_mask_p"
    ],
    "set_specaugment_lb_policy": [
      "self"
    ],
    "set_specaugment_ld_policy": [
      "self"
    ],
    "set_specaugment_sm_policy": [
      "self"
    ],
    "set_specaugment_ss_policy": [
      "self"
    ],
    "set_input_channels": [
      "self",
      "input_channels"
    ],
    "set_input_feat_per_channel": [
      "self",
      "input_feat_per_channel"
    ],
    "set_bpe_tokenizer": [
      "self",
      "bpe_tokenizer"
    ],
    "set_global_cmvn": [
      "self",
      "stats_npz_path"
    ],
    "set_feature_transforms": [
      "self",
      "split",
      "transforms"
    ],
    "set_prepend_tgt_lang_tag": [
      "self",
      "flag"
    ],
    "set_sampling_alpha": [
      "self",
      "sampling_alpha"
    ],
    "set_extra": [
      "self",
      "data"
    ]
  },
  "SHIFT_SIZE": [],
  "WINDOW_SIZE": [],
  "SAMPLE_RATE": [],
  "FEATURE_DIM": [],
  "BOW_PREFIX": [],
  "OnlineFeatureExtractor": {
    "__init__": [
      "self",
      "args"
    ],
    "clear_cache": [
      "self"
    ],
    "__call__": [
      "self",
      "new_samples"
    ],
    "transform": [
      "self",
      "input"
    ]
  },
  "TensorListEntry": {
    "append": [
      "self",
      "value"
    ],
    "info": [
      "self"
    ]
  },
  "FairseqSimulSTAgent": {
    "speech_segment_size": [],
    "__init__": [
      "self",
      "args"
    ],
    "build_states": [
      "self",
      "args",
      "client",
      "sentence_id"
    ],
    "to_device": [
      "self",
      "tensor"
    ],
    "add_args": [
      "parser"
    ],
    "load_model_vocab": [
      "self",
      "args"
    ],
    "initialize_states": [
      "self",
      "states"
    ],
    "segment_to_units": [
      "self",
      "segment",
      "states"
    ],
    "units_to_segment": [
      "self",
      "units",
      "states"
    ],
    "update_model_encoder": [
      "self",
      "states"
    ],
    "update_states_read": [
      "self",
      "states"
    ],
    "policy": [
      "self",
      "states"
    ],
    "predict": [
      "self",
      "states"
    ]
  },
  "batch_mel_spectral_distortion": [
    "y1",
    "y2",
    "sr",
    "normalize_type",
    "mel_fn"
  ],
  "_same_t_in_true_and_est": [
    "func"
  ],
  "gross_pitch_error": [
    "true_t",
    "true_f",
    "est_t",
    "est_f"
  ],
  "_gross_pitch_error_frames": [
    "true_t",
    "true_f",
    "est_t",
    "est_f",
    "eps"
  ],
  "_true_voiced_frames": [
    "true_t",
    "true_f",
    "est_t",
    "est_f"
  ],
  "_voicing_decision_error_frames": [
    "true_t",
    "true_f",
    "est_t",
    "est_f"
  ],
  "f0_frame_error": [
    "true_t",
    "true_f",
    "est_t",
    "est_f"
  ],
  "voicing_decision_error": [
    "true_t",
    "true_f",
    "est_t",
    "est_f"
  ],
  "postprocess_results": [
    "dataset",
    "sample",
    "hypos",
    "resample_fn",
    "dump_target"
  ],
  "trim_or_pad_to_target_length": [
    "data_1d_or_2d",
    "target_length"
  ],
  "extract_logmel_spectrogram": [
    "waveform",
    "sample_rate",
    "output_path",
    "win_length",
    "hop_length",
    "n_fft",
    "win_fn",
    "n_mels",
    "f_min",
    "f_max",
    "eps",
    "overwrite",
    "target_length"
  ],
  "extract_pitch": [
    "waveform",
    "sample_rate",
    "output_path",
    "hop_length",
    "log_scale",
    "phoneme_durations"
  ],
  "extract_energy": [
    "waveform",
    "output_path",
    "hop_length",
    "n_fft",
    "log_scale",
    "phoneme_durations"
  ],
  "get_global_cmvn": [
    "feature_root",
    "output_path"
  ],
  "ipa_phonemize": [
    "text",
    "lang",
    "use_g2p"
  ],
  "ForceAlignmentInfo": {},
  "get_mfa_alignment_by_sample_id": [
    "textgrid_zip_path",
    "sample_id",
    "sample_rate",
    "hop_length",
    "silence_phones"
  ],
  "get_mfa_alignment": [
    "textgrid_zip_path",
    "sample_ids",
    "sample_rate",
    "hop_length"
  ],
  "get_unit_alignment": [
    "id_to_unit_tsv_path",
    "sample_ids"
  ],
  "get_feature_value_min_max": [
    "feature_paths"
  ],
  "load_eval_spec": [
    "path"
  ],
  "eval_distortion": [
    "samples",
    "distortion_fn",
    "device"
  ],
  "eval_mel_cepstral_distortion": [
    "samples",
    "device"
  ],
  "eval_mel_spectral_distortion": [
    "samples",
    "device"
  ],
  "print_results": [
    "results",
    "show_bin"
  ],
  "difference_function": [
    "x",
    "n",
    "tau_max"
  ],
  "cumulative_mean_normalized_difference_function": [
    "df",
    "n"
  ],
  "get_pitch": [
    "cmdf",
    "tau_min",
    "tau_max",
    "harmo_th"
  ],
  "compute_yin": [
    "sig",
    "sr",
    "w_len",
    "w_step",
    "f0_min",
    "f0_max",
    "harmo_thresh"
  ],
  "extract_f0": [
    "samples"
  ],
  "eval_f0_error": [
    "samples",
    "distortion_fn"
  ],
  "eval_gross_pitch_error": [
    "samples"
  ],
  "eval_voicing_decision_error": [
    "samples"
  ],
  "eval_f0_frame_error": [
    "samples"
  ],
  "preprocess_text": [
    "text"
  ],
  "prepare_w2v_data": [
    "dict_dir",
    "sample_rate",
    "label",
    "audio_paths",
    "texts",
    "split",
    "data_dir"
  ],
  "run_asr": [
    "asr_dir",
    "split",
    "w2v_ckpt",
    "w2v_label",
    "res_dir"
  ],
  "compute_error_rate": [
    "hyp_wrd_path",
    "ref_wrd_path",
    "unit"
  ],
  "extract_embedding": [
    "audio_path",
    "embedder"
  ],
  "normalize_text": [
    "text"
  ],
  "get_top_n": [
    "root",
    "n_speakers",
    "min_n_tokens"
  ],
  "get_splits": [
    "df",
    "train_split_ratio",
    "speaker_in_all_splits",
    "rand_seed"
  ],
  "convert_to_wav": [
    "root",
    "filenames",
    "target_sr"
  ],
  "PATHS": [],
  "MIN_T": [],
  "generate_tmp_filename": [
    "extension"
  ],
  "convert_sr": [
    "inpath",
    "sr",
    "output_path"
  ],
  "apply_vad": [
    "vad",
    "inpath"
  ],
  "write": [
    "wav",
    "filename",
    "sr"
  ],
  "sinc": [
    "t"
  ],
  "kernel_upsample2": [
    "zeros"
  ],
  "upsample2": [
    "x",
    "zeros"
  ],
  "kernel_downsample2": [
    "zeros"
  ],
  "downsample2": [
    "x",
    "zeros"
  ],
  "BLSTM": {
    "__init__": [
      "self",
      "dim",
      "layers",
      "bi"
    ],
    "forward": [
      "self",
      "x",
      "hidden"
    ]
  },
  "rescale_conv": [
    "conv",
    "reference"
  ],
  "rescale_module": [
    "module",
    "reference"
  ],
  "Demucs": {
    "__init__": [
      "self",
      "chin",
      "chout",
      "hidden",
      "depth",
      "kernel_size",
      "stride",
      "causal",
      "resample",
      "growth",
      "max_hidden",
      "normalize",
      "glu",
      "rescale",
      "floor"
    ],
    "valid_length": [
      "self",
      "length"
    ],
    "total_stride": [
      "self"
    ],
    "forward": [
      "self",
      "mix"
    ]
  },
  "fast_conv": [
    "conv",
    "x"
  ],
  "DemucsStreamer": {
    "__init__": [
      "self",
      "demucs",
      "dry",
      "num_frames",
      "resample_lookahead",
      "resample_buffer"
    ],
    "reset_time_per_frame": [
      "self"
    ],
    "time_per_frame": [
      "self"
    ],
    "flush": [
      "self"
    ],
    "feed": [
      "self",
      "wav"
    ],
    "_separate_frame": [
      "self",
      "frame"
    ]
  },
  "test": [],
  "EPS": [],
  "capture_init": [
    "init"
  ],
  "deserialize_model": [
    "package",
    "strict"
  ],
  "copy_state": [
    "state"
  ],
  "serialize_model": [
    "model"
  ],
  "swap_state": [
    "model",
    "state"
  ],
  "pull_metric": [
    "history",
    "name"
  ],
  "LogProgress": {
    "__init__": [
      "self",
      "logger",
      "iterable",
      "updates",
      "total",
      "name",
      "level"
    ],
    "update": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "_log": [
      "self"
    ]
  },
  "colorize": [
    "text",
    "color"
  ],
  "bold": [
    "text"
  ],
  "cal_snr": [
    "lbl",
    "est"
  ],
  "ROOT": [],
  "DNS_48_URL": [],
  "DNS_64_URL": [],
  "MASTER_64_URL": [],
  "_demucs": [
    "pretrained",
    "url"
  ],
  "dns48": [
    "pretrained"
  ],
  "dns64": [
    "pretrained"
  ],
  "master64": [
    "pretrained"
  ],
  "add_model_flags": [
    "parser"
  ],
  "EMBEDDER_PARAMS": [],
  "set_requires_grad": [
    "nets",
    "requires_grad"
  ],
  "SpeechEmbedder": {
    "__init__": [
      "self",
      "hp"
    ],
    "forward": [
      "self",
      "mel"
    ]
  },
  "SpkrEmbedder": {
    "RATE": [],
    "__init__": [
      "self",
      "embedder_path",
      "embedder_params",
      "rate",
      "hop_length",
      "win_length",
      "pad"
    ],
    "get_mel": [
      "self",
      "y"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "AUDIO_SUFFIX": [],
  "FS_MS": [],
  "SCALE": [],
  "THRESHOLD": [],
  "read_wave": [
    "path"
  ],
  "write_wave": [
    "path",
    "audio",
    "sample_rate"
  ],
  "Frame": {
    "__init__": [
      "self",
      "bytes",
      "timestamp",
      "duration"
    ]
  },
  "frame_generator": [
    "frame_duration_ms",
    "audio",
    "sample_rate"
  ],
  "vad_collector": [
    "sample_rate",
    "frame_duration_ms",
    "padding_duration_ms",
    "vad",
    "frames"
  ],
  "src_ckpt": [],
  "ref_ckpt": [],
  "new_ckpt": [],
  "update_state": [
    "state"
  ],
  "src_state": [],
  "comp_purity": [
    "p_xy",
    "axis"
  ],
  "comp_entropy": [
    "p"
  ],
  "comp_norm_mutual_info": [
    "p_xy"
  ],
  "pad": [
    "labs",
    "n"
  ],
  "comp_avg_seg_dur": [
    "labs_list"
  ],
  "comp_joint_prob": [
    "uid2refs",
    "uid2hyps"
  ],
  "read_phn": [
    "tsv_path",
    "rm_stress"
  ],
  "read_lab": [
    "tsv_path",
    "lab_path",
    "pad_len",
    "upsample"
  ],
  "main_lab_lab": [
    "tsv_dir",
    "lab_dir",
    "lab_name",
    "lab_sets",
    "ref_dir",
    "ref_name",
    "pad_len",
    "upsample",
    "verbose"
  ],
  "main_phn_lab": [
    "tsv_dir",
    "lab_dir",
    "lab_name",
    "lab_sets",
    "phn_dir",
    "phn_sets",
    "pad_len",
    "upsample",
    "verbose"
  ],
  "_main": [
    "uid2refs",
    "uid2hyps",
    "verbose"
  ],
  "get_shard_range": [
    "tot",
    "nshard",
    "rank"
  ],
  "get_path_iterator": [
    "tsv",
    "nshard",
    "rank"
  ],
  "dump_feature": [
    "reader",
    "generator",
    "num",
    "split",
    "nshard",
    "rank",
    "feat_dir"
  ],
  "HubertFeatureReaderS2T": {
    "read_audio": [
      "self",
      "path",
      "ref_len"
    ]
  },
  "Wav2Vec2FeatureReader": {
    "__init__": [
      "self",
      "ckpt_path",
      "layer",
      "max_chunk"
    ],
    "read_audio": [
      "self",
      "path",
      "ref_len"
    ],
    "get_feats": [
      "self",
      "path",
      "ref_len"
    ]
  },
  "ApplyKmeans": {
    "__init__": [
      "self",
      "km_path"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "get_feat_iterator": [
    "feat_dir",
    "split",
    "nshard",
    "rank"
  ],
  "dump_label": [
    "feat_dir",
    "split",
    "km_path",
    "nshard",
    "rank",
    "lab_dir"
  ],
  "get_km_model": [
    "n_clusters",
    "init",
    "max_iter",
    "batch_size",
    "tol",
    "max_no_improvement",
    "n_init",
    "reassignment_ratio"
  ],
  "load_feature_shard": [
    "feat_dir",
    "split",
    "nshard",
    "rank",
    "percent"
  ],
  "load_feature": [
    "feat_dir",
    "split",
    "nshard",
    "seed",
    "percent"
  ],
  "learn_kmeans": [
    "feat_dir",
    "split",
    "nshard",
    "km_path",
    "n_clusters",
    "seed",
    "percent",
    "init",
    "max_iter",
    "batch_size",
    "tol",
    "n_init",
    "reassignment_ratio",
    "max_no_improvement"
  ],
  "MfccFeatureReader": {
    "__init__": [
      "self",
      "sample_rate"
    ],
    "read_audio": [
      "self",
      "path",
      "ref_len"
    ],
    "get_feats": [
      "self",
      "path",
      "ref_len"
    ]
  },
  "LinformerModel": {
    "add_args": [
      "parser"
    ],
    "build_model": [
      "cls",
      "args",
      "task"
    ]
  },
  "LinformerEncoder": {
    "__init__": [
      "self",
      "args",
      "dictionary"
    ],
    "build_encoder": [
      "self",
      "args",
      "dictionary",
      "embed_tokens"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "linformer_roberta_base_architecture": [
    "args"
  ],
  "linformer_roberta_large_architecture": [
    "args"
  ],
  "MultiheadLinearAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "kdim",
      "vdim",
      "dropout",
      "bias",
      "add_bias_kv",
      "add_zero_attn",
      "self_attention",
      "encoder_decoder_attention",
      "q_noise",
      "qn_block_size",
      "compressed",
      "max_seq_len",
      "shared_kv_compressed",
      "shared_compress_layer",
      "freeze_compress"
    ],
    "prepare_for_onnx_export_": [
      "self"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask",
      "incremental_state",
      "need_weights",
      "static_kv",
      "attn_mask",
      "before_softmax",
      "need_head_weights"
    ],
    "_append_prev_key_padding_mask": [
      "key_padding_mask",
      "prev_key_padding_mask",
      "batch_size",
      "src_len",
      "static_kv"
    ],
    "reorder_incremental_state": [
      "self",
      "incremental_state",
      "new_order"
    ],
    "_get_input_buffer": [
      "self",
      "incremental_state"
    ],
    "_set_input_buffer": [
      "self",
      "incremental_state",
      "buffer"
    ],
    "apply_sparse_mask": [
      "attn_weights",
      "tgt_len",
      "src_len",
      "bsz"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "LinformerTransformerEncoder": {
    "__init__": [
      "self",
      "args",
      "dictionary",
      "embed_tokens"
    ],
    "build_encoder_layer": [
      "self",
      "args"
    ]
  },
  "LinformerTransformerEncoderLayer": {
    "__init__": [
      "self",
      "args",
      "shared_compress_layer"
    ],
    "build_self_attention": [
      "self",
      "embed_dim",
      "args"
    ],
    "upgrade_state_dict_named": [
      "self",
      "state_dict",
      "name"
    ]
  },
  "get_hashes_and_lines": [
    "raw_line"
  ],
  "get_symbols_to_strip_from_output": [
    "generator"
  ],
  "buffered_read": [
    "input",
    "buffer_size"
  ],
  "_train_path": [
    "lang",
    "trainpref"
  ],
  "_file_name": [
    "prefix",
    "lang"
  ],
  "_dest_path": [
    "prefix",
    "lang",
    "destdir"
  ],
  "_dict_path": [
    "lang",
    "destdir"
  ],
  "dataset_dest_prefix": [
    "args",
    "output_prefix",
    "lang"
  ],
  "dataset_dest_file": [
    "args",
    "output_prefix",
    "lang",
    "extension"
  ],
  "_build_dictionary": [
    "filenames",
    "task",
    "args",
    "src",
    "tgt"
  ],
  "_make_binary_dataset": [
    "vocab",
    "input_prefix",
    "output_prefix",
    "lang",
    "num_workers",
    "args"
  ],
  "_make_binary_alignment_dataset": [
    "input_prefix",
    "output_prefix",
    "num_workers",
    "args"
  ],
  "_make_dataset": [
    "vocab",
    "input_prefix",
    "output_prefix",
    "lang",
    "args",
    "num_workers"
  ],
  "_make_all": [
    "lang",
    "vocab",
    "args"
  ],
  "_make_all_alignments": [
    "args"
  ],
  "_align_files": [
    "args",
    "src_dict",
    "tgt_dict"
  ],
  "should_stop_early": [
    "cfg",
    "valid_loss"
  ],
  "train": [
    "cfg",
    "trainer",
    "task",
    "epoch_itr"
  ],
  "_flatten_config": [
    "cfg"
  ],
  "validate_and_save": [
    "cfg",
    "trainer",
    "task",
    "epoch_itr",
    "valid_subsets",
    "end_of_epoch"
  ],
  "get_training_stats": [
    "stats"
  ],
  "validate": [
    "cfg",
    "trainer",
    "task",
    "epoch_itr",
    "subsets"
  ],
  "get_valid_stats": [
    "cfg",
    "trainer",
    "stats",
    "tracking_best"
  ],
  "eval_lm": [
    "models",
    "source_dictionary",
    "batch_iterator",
    "post_process",
    "output_word_probs",
    "output_word_stats",
    "target_dictionary",
    "softmax_batch",
    "remove_bos_token",
    "device"
  ],
  "WordStat": {
    "__init__": [
      "self",
      "word",
      "is_bpe"
    ],
    "add": [
      "self",
      "log_prob",
      "next_word_prob"
    ],
    "__str__": [
      "self"
    ]
  },
  "_hydra_main": [
    "cfg"
  ]
}