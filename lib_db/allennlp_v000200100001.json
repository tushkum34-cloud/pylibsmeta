{
  "_MAJOR": [],
  "_MINOR": [],
  "_PATCH": [],
  "_SUFFIX": [],
  "VERSION_SHORT": [],
  "VERSION": [],
  "_transformers_log_filter": [
    "record"
  ],
  "run": [],
  "logger": [],
  "get_description": [
    "model_class"
  ],
  "ModelCardInfo": {
    "to_dict": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "Paper": {},
  "ModelDetails": {
    "__init__": [
      "self",
      "description",
      "short_description",
      "developed_by",
      "contributed_by",
      "date",
      "version",
      "model_type",
      "paper",
      "license",
      "contact"
    ]
  },
  "IntendedUse": {},
  "Factors": {},
  "Metrics": {},
  "Dataset": {},
  "EvaluationData": {
    "__init__": [
      "self",
      "dataset",
      "motivation",
      "preprocessing"
    ],
    "to_dict": [
      "self"
    ]
  },
  "TrainingData": {
    "__init__": [
      "self",
      "dataset",
      "motivation",
      "preprocessing"
    ],
    "to_dict": [
      "self"
    ]
  },
  "QuantitativeAnalyses": {},
  "ModelEthicalConsiderations": {},
  "ModelCaveatsAndRecommendations": {},
  "ModelUsage": {
    "_storage_location": [],
    "_config_location": [],
    "__init__": [
      "self",
      "archive_file",
      "training_config",
      "install_instructions",
      "overrides"
    ]
  },
  "ModelCard": {
    "__init__": [
      "self",
      "id",
      "registered_model_name",
      "model_class",
      "registered_predictor_name",
      "display_name",
      "task_id",
      "model_usage",
      "model_details",
      "intended_use",
      "factors",
      "metrics",
      "evaluation_data",
      "training_data",
      "quantitative_analyses",
      "model_ethical_considerations",
      "model_caveats_and_recommendations"
    ],
    "to_dict": [
      "self"
    ]
  },
  "CACHE_ROOT": [],
  "CACHE_DIRECTORY": [],
  "DEPRECATED_CACHE_DIRECTORY": [],
  "DATASET_CACHE": [],
  "filename_to_url": [
    "filename",
    "cache_dir"
  ],
  "cached_path": [
    "url_or_filename",
    "cache_dir",
    "extract_archive",
    "force_extract"
  ],
  "_serialize": [
    "data"
  ],
  "_unique_file_id": [
    "path"
  ],
  "TensorCache": {
    "__new__": [
      "cls",
      "filename"
    ],
    "__init__": [
      "self",
      "filename"
    ],
    "read_only": [
      "self"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "tensor"
    ],
    "__delitem__": [
      "self",
      "key"
    ],
    "__del__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "LocalCacheResource": {
    "__init__": [
      "self",
      "resource_name",
      "version",
      "cache_dir"
    ],
    "cached": [
      "self"
    ],
    "writer": [
      "self",
      "mode"
    ],
    "reader": [
      "self",
      "mode"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "read_set_from_file": [
    "filename"
  ],
  "get_file_extension": [
    "path",
    "dot",
    "lower"
  ],
  "open_compressed": [
    "filename",
    "mode",
    "encoding"
  ],
  "text_lines_from_file": [
    "filename",
    "strip_lines"
  ],
  "json_lines_from_file": [
    "filename"
  ],
  "_get_resource_size": [
    "path"
  ],
  "_CacheEntry": {},
  "_find_entries": [
    "patterns",
    "cache_dir"
  ],
  "remove_cache_entries": [
    "patterns",
    "cache_dir"
  ],
  "inspect_cache": [
    "patterns",
    "cache_dir"
  ],
  "hardlink_or_copy": [
    "source",
    "dest"
  ],
  "ShuffledSequence": {
    "__init__": [
      "self",
      "inner_sequence",
      "indices"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__contains__": [
      "self",
      "item"
    ]
  },
  "SlicedSequence": {
    "__init__": [
      "self",
      "inner_sequence",
      "s"
    ]
  },
  "ConcatenatedSequence": {
    "__init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__contains__": [
      "self",
      "item"
    ]
  },
  "LOCAL_PLUGINS_FILENAME": [],
  "GLOBAL_PLUGINS_FILENAME": [],
  "DEFAULT_PLUGINS": [],
  "discover_file_plugins": [
    "plugins_filename"
  ],
  "discover_plugins": [],
  "import_plugins": [],
  "ExampleCategory": {},
  "TaskCard": {},
  "T": [],
  "_NO_DEFAULT": [],
  "takes_arg": [
    "obj",
    "arg"
  ],
  "takes_kwargs": [
    "obj"
  ],
  "can_construct_from_params": [
    "type_"
  ],
  "is_base_registrable": [
    "cls"
  ],
  "remove_optional": [
    "annotation"
  ],
  "infer_constructor_params": [
    "cls",
    "constructor"
  ],
  "infer_params": [],
  "infer_method_params": [
    "cls",
    "method"
  ],
  "create_kwargs": [
    "constructor",
    "cls",
    "params"
  ],
  "create_extras": [
    "cls",
    "extras"
  ],
  "pop_and_construct_arg": [
    "class_name",
    "argument_name",
    "annotation",
    "default",
    "params"
  ],
  "construct_arg": [
    "class_name",
    "argument_name",
    "popped_params",
    "annotation",
    "default"
  ],
  "FromParams": {
    "from_params": [
      "cls",
      "params",
      "constructor_to_call",
      "constructor_to_inspect"
    ],
    "to_params": [
      "self"
    ],
    "_to_params": [
      "self"
    ]
  },
  "README_TEMPLATE": [],
  "_create_model_card": [
    "repo_dir"
  ],
  "_ALLOWLIST_PATHS": [],
  "_copy_allowed_file": [
    "filepath",
    "dst_directory"
  ],
  "push_to_hf": [
    "repo_name",
    "serialization_dir",
    "archive_path",
    "organization",
    "commit_message",
    "local_repo_path",
    "use_auth_token"
  ],
  "infer_and_cast": [
    "value"
  ],
  "_is_encodable": [
    "value"
  ],
  "_environment_variables": [],
  "with_overrides": [
    "original",
    "overrides_dict",
    "prefix"
  ],
  "parse_overrides": [
    "serialized_overrides",
    "ext_vars"
  ],
  "_is_dict_free": [
    "obj"
  ],
  "Params": {
    "DEFAULT": [],
    "__init__": [
      "self",
      "params",
      "history"
    ],
    "pop": [
      "self",
      "key",
      "default",
      "keep_as_dict"
    ],
    "pop_int": [
      "self",
      "key",
      "default"
    ],
    "pop_float": [
      "self",
      "key",
      "default"
    ],
    "pop_bool": [
      "self",
      "key",
      "default"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "pop_choice": [
      "self",
      "key",
      "choices",
      "default_to_first_choice",
      "allow_class_names"
    ],
    "as_dict": [
      "self",
      "quiet",
      "infer_type_and_cast"
    ],
    "as_flat_dict": [
      "self"
    ],
    "duplicate": [
      "self"
    ],
    "assert_empty": [
      "self",
      "class_name"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "__delitem__": [
      "self",
      "key"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "_check_is_dict": [
      "self",
      "new_history",
      "value"
    ],
    "from_file": [
      "cls",
      "params_file",
      "params_overrides",
      "ext_vars"
    ],
    "to_file": [
      "self",
      "params_file",
      "preference_orders"
    ],
    "as_ordered_dict": [
      "self",
      "preference_orders"
    ],
    "get_hash": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "pop_choice": [
    "params",
    "key",
    "choices",
    "default_to_first_choice",
    "history",
    "allow_class_names"
  ],
  "_replace_none": [
    "params"
  ],
  "remove_keys_from_params": [
    "params",
    "keys"
  ],
  "TransformerSpec": {},
  "get": [
    "model_name",
    "make_copy",
    "override_weights_file",
    "override_weights_strip_prefix",
    "reinit_modules",
    "load_weights"
  ],
  "get_tokenizer": [
    "model_name"
  ],
  "_clear_caches": [],
  "AllenNlpLogger": {
    "__init__": [
      "self",
      "name"
    ],
    "debug_once": [
      "self",
      "msg"
    ],
    "info_once": [
      "self",
      "msg"
    ],
    "warning_once": [
      "self",
      "msg"
    ],
    "error_once": [
      "self",
      "msg"
    ],
    "critical_once": [
      "self",
      "msg"
    ]
  },
  "ErrorFilter": {
    "filter": [
      "self",
      "record"
    ]
  },
  "prepare_global_logging": [
    "serialization_dir",
    "rank",
    "world_size"
  ],
  "JsonDict": [],
  "START_SYMBOL": [],
  "END_SYMBOL": [],
  "PathType": [],
  "ContextManagerFunctionReturnType": [],
  "sanitize": [
    "x"
  ],
  "group_by_count": [
    "iterable",
    "count",
    "default_value"
  ],
  "A": [],
  "lazy_groups_of": [
    "iterable",
    "group_size"
  ],
  "pad_sequence_to_length": [
    "sequence",
    "desired_length",
    "default_value",
    "padding_on_right"
  ],
  "add_noise_to_dict_values": [
    "dictionary",
    "noise_param"
  ],
  "namespace_match": [
    "pattern",
    "namespace"
  ],
  "prepare_environment": [
    "params"
  ],
  "get_spacy_model": [
    "spacy_model_name",
    "pos_tags",
    "parse",
    "ner"
  ],
  "pushd": [
    "new_dir",
    "verbose"
  ],
  "push_python_path": [
    "path"
  ],
  "import_module_and_submodules": [
    "package_name",
    "exclude"
  ],
  "peak_cpu_memory": [],
  "peak_gpu_memory": [],
  "ensure_list": [
    "iterable"
  ],
  "is_lazy": [
    "iterable"
  ],
  "int_to_device": [
    "device"
  ],
  "log_frozen_and_tunable_parameter_names": [
    "model"
  ],
  "get_frozen_and_tunable_parameter_names": [
    "model"
  ],
  "dump_metrics": [
    "file_path",
    "metrics",
    "log"
  ],
  "flatten_filename": [
    "file_path"
  ],
  "is_distributed": [],
  "is_global_primary": [],
  "sanitize_wordpiece": [
    "wordpiece"
  ],
  "sanitize_ptb_tokenized_string": [
    "text"
  ],
  "find_open_port": [],
  "format_timedelta": [
    "td"
  ],
  "format_size": [
    "size"
  ],
  "nan_safe_tensor_divide": [
    "numerator",
    "denominator"
  ],
  "shuffle_iterable": [
    "i",
    "pool_size"
  ],
  "cycle_iterator_function": [
    "iterator_function"
  ],
  "hash_object": [
    "o"
  ],
  "SigTermReceived": {},
  "_handle_sigterm": [
    "sig",
    "frame"
  ],
  "install_sigterm_handler": [],
  "_T": [],
  "_RegistrableT": [],
  "_SubclassRegistry": [],
  "Registrable": {
    "register": [
      "cls",
      "name",
      "constructor",
      "exist_ok"
    ],
    "by_name": [
      "cls",
      "name"
    ],
    "resolve_class_name": [
      "cls",
      "name"
    ],
    "list_available": [
      "cls"
    ],
    "_to_params": [
      "self"
    ]
  },
  "_get_suggestion": [
    "name",
    "available"
  ],
  "replace_cr_with_newline": [
    "message"
  ],
  "TqdmToLogsWriter": {
    "__init__": [
      "self"
    ],
    "write": [
      "self",
      "message"
    ],
    "flush": [
      "self"
    ]
  },
  "Tqdm": {
    "tqdm": [],
    "set_lock": [
      "lock"
    ],
    "get_lock": []
  },
  "META_NAME": [],
  "Meta": {
    "new": [
      "cls"
    ],
    "to_file": [
      "self",
      "path"
    ],
    "from_path": [
      "cls",
      "path"
    ]
  },
  "Lazy": {
    "__init__": [
      "self",
      "constructor",
      "params",
      "constructor_extras"
    ],
    "constructor": [
      "self"
    ],
    "construct": [
      "self"
    ]
  },
  "ConfigurationError": {
    "__reduce__": [
      "self"
    ],
    "__init__": [
      "self",
      "message"
    ],
    "__str__": [
      "self"
    ]
  },
  "ExperimentalFeatureWarning": {},
  "log_pytorch_version_info": [],
  "check_dimensions_match": [
    "dimension_1",
    "dimension_2",
    "dim_1_name",
    "dim_2_name"
  ],
  "parse_cuda_device": [
    "cuda_device"
  ],
  "check_for_gpu": [
    "device"
  ],
  "check_for_java": [],
  "TEST_DIR": [],
  "AllenNlpTestCase": {
    "PROJECT_ROOT": [],
    "MODULE_ROOT": [],
    "TOOLS_ROOT": [],
    "PROJECT_ROOT_FALLBACK": [],
    "TESTS_ROOT": [],
    "FIXTURES_ROOT": [],
    "setup_method": [
      "self"
    ],
    "teardown_method": [
      "self"
    ]
  },
  "FakeModelForTestingNormalizationBiasVerification": {
    "__init__": [
      "self",
      "use_bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_available_devices": [],
  "multi_device": [
    "test_method"
  ],
  "requires_gpu": [
    "test_method"
  ],
  "requires_multi_gpu": [
    "test_method"
  ],
  "cpu_or_gpu": [
    "test_method"
  ],
  "assert_metrics_values": [
    "metrics",
    "desired_values",
    "rtol",
    "atol"
  ],
  "global_distributed_metric": [
    "global_rank",
    "world_size",
    "gpu_id",
    "metric",
    "metric_kwargs",
    "desired_values",
    "exact",
    "number_of_runs"
  ],
  "assert_equal_parameters": [
    "old_module",
    "new_module",
    "ignore_missing",
    "mapping"
  ],
  "FakeTaskSuite": {
    "__init__": [
      "self",
      "suite",
      "fake_arg1",
      "fake_arg2"
    ]
  },
  "init_process": [
    "process_rank",
    "world_size",
    "distributed_device_ids",
    "func",
    "func_args",
    "func_kwargs",
    "primary_addr",
    "primary_port"
  ],
  "run_distributed_test": [
    "device_ids",
    "func"
  ],
  "FakeModelForTestingInterpret": {
    "__init__": [
      "self",
      "vocab",
      "max_tokens",
      "num_labels"
    ],
    "forward": [
      "self",
      "tokens",
      "label"
    ],
    "make_output_human_readable": [
      "self",
      "output_dict"
    ]
  },
  "FakePredictorForTestingInterpret": {
    "get_interpretable_layer": [
      "self"
    ],
    "get_interpretable_text_field_embedder": [
      "self"
    ]
  },
  "ModelTestCase": {
    "set_up_model": [
      "self",
      "param_file",
      "dataset_file",
      "serialization_dir",
      "seed"
    ],
    "test_model_batch_norm_verification": [
      "self"
    ],
    "ensure_model_can_train_save_and_load": [
      "self",
      "param_file",
      "tolerance",
      "cuda_device",
      "gradients_to_ignore",
      "overrides",
      "metric_to_check",
      "metric_terminal_value",
      "metric_tolerance",
      "disable_dropout",
      "which_loss",
      "seed"
    ],
    "ensure_model_can_train": [
      "self",
      "trainer",
      "gradients_to_ignore",
      "metric_to_check",
      "metric_terminal_value",
      "metric_tolerance",
      "disable_dropout"
    ],
    "assert_fields_equal": [
      "self",
      "field1",
      "field2",
      "name",
      "tolerance"
    ],
    "check_model_computes_gradients_correctly": [
      "model",
      "model_batch",
      "params_to_ignore",
      "disable_dropout",
      "which_loss"
    ],
    "ensure_batch_predictions_are_consistent": [
      "self",
      "keys_to_ignore"
    ]
  },
  "SentenceTaggerPredictor": {
    "__init__": [
      "self",
      "model",
      "dataset_reader",
      "language"
    ],
    "predict": [
      "self",
      "sentence"
    ],
    "_json_to_instance": [
      "self",
      "json_dict"
    ],
    "predictions_to_labeled_instances": [
      "self",
      "instance",
      "outputs"
    ]
  },
  "Predictor": {
    "__init__": [
      "self",
      "model",
      "dataset_reader",
      "frozen"
    ],
    "load_line": [
      "self",
      "line"
    ],
    "dump_line": [
      "self",
      "outputs"
    ],
    "predict_json": [
      "self",
      "inputs"
    ],
    "json_to_labeled_instances": [
      "self",
      "inputs"
    ],
    "get_gradients": [
      "self",
      "instances"
    ],
    "get_interpretable_layer": [
      "self"
    ],
    "get_interpretable_text_field_embedder": [
      "self"
    ],
    "_register_embedding_gradient_hooks": [
      "self",
      "embedding_gradients"
    ],
    "capture_model_internals": [
      "self",
      "module_regex"
    ],
    "predict_instance": [
      "self",
      "instance"
    ],
    "predictions_to_labeled_instances": [
      "self",
      "instance",
      "outputs"
    ],
    "_json_to_instance": [
      "self",
      "json_dict"
    ],
    "predict_batch_json": [
      "self",
      "inputs"
    ],
    "predict_batch_instance": [
      "self",
      "instances"
    ],
    "_batch_json_to_instances": [
      "self",
      "json_dicts"
    ],
    "from_path": [
      "cls",
      "archive_path",
      "predictor_name",
      "cuda_device",
      "dataset_reader_to_load",
      "frozen",
      "import_plugins",
      "overrides"
    ],
    "from_archive": [
      "cls",
      "archive",
      "predictor_name",
      "dataset_reader_to_load",
      "frozen",
      "extra_args"
    ]
  },
  "TextClassifierPredictor": {
    "predict": [
      "self",
      "sentence"
    ],
    "_json_to_instance": [
      "self",
      "json_dict"
    ],
    "predictions_to_labeled_instances": [
      "self",
      "instance",
      "outputs"
    ]
  },
  "MultiTaskPredictor": {
    "_WRONG_READER_ERROR": [],
    "_WRONG_FIELD_ERROR": [],
    "__init__": [
      "self",
      "model",
      "dataset_reader"
    ],
    "predict_instance": [
      "self",
      "instance"
    ],
    "_json_to_instance": [
      "self",
      "json_dict"
    ],
    "predict_batch_instance": [
      "self",
      "instances"
    ]
  },
  "TrainerCheckpoint": {},
  "Trainer": {
    "default_implementation": [],
    "__init__": [
      "self",
      "serialization_dir",
      "cuda_device",
      "distributed",
      "local_rank",
      "world_size"
    ],
    "train": [
      "self"
    ],
    "get_checkpoint_state": [
      "self"
    ],
    "get_best_weights_path": [
      "self"
    ]
  },
  "ParameterGroupsType": [],
  "make_parameter_groups": [
    "model_parameters",
    "groups"
  ],
  "Optimizer": {
    "default_implementation": [],
    "default": [
      "model_parameters"
    ]
  },
  "MultiOptimizer": {
    "__init__": [
      "self",
      "model_parameters",
      "optimizers",
      "parameter_groups"
    ],
    "step": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "training_state"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ]
  },
  "AdamOptimizer": {
    "__init__": [
      "self",
      "model_parameters",
      "parameter_groups",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad"
    ]
  },
  "SparseAdamOptimizer": {
    "__init__": [
      "self",
      "model_parameters",
      "parameter_groups",
      "lr",
      "betas",
      "eps"
    ]
  },
  "AdamaxOptimizer": {
    "__init__": [
      "self",
      "model_parameters",
      "parameter_groups",
      "lr",
      "betas",
      "eps",
      "weight_decay"
    ]
  },
  "AdamWOptimizer": {
    "__init__": [
      "self",
      "model_parameters",
      "parameter_groups",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad"
    ]
  },
  "HuggingfaceAdamWOptimizer": {
    "__init__": [
      "self",
      "model_parameters",
      "parameter_groups",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "correct_bias"
    ]
  },
  "HuggingfaceAdafactor": {
    "__init__": [
      "self",
      "model_parameters",
      "parameter_groups",
      "lr",
      "eps",
      "clip_threshold",
      "decay_rate",
      "beta1",
      "weight_decay",
      "scale_parameter",
      "relative_step",
      "warmup_init"
    ]
  },
  "AdagradOptimizer": {
    "__init__": [
      "self",
      "model_parameters",
      "parameter_groups",
      "lr",
      "lr_decay",
      "weight_decay",
      "initial_accumulator_value",
      "eps"
    ]
  },
  "AdadeltaOptimizer": {
    "__init__": [
      "self",
      "model_parameters",
      "parameter_groups",
      "lr",
      "rho",
      "eps",
      "weight_decay"
    ]
  },
  "SgdOptimizer": {
    "__init__": [
      "self",
      "model_parameters",
      "lr",
      "parameter_groups",
      "momentum",
      "dampening",
      "weight_decay",
      "nesterov"
    ]
  },
  "RmsPropOptimizer": {
    "__init__": [
      "self",
      "model_parameters",
      "parameter_groups",
      "lr",
      "alpha",
      "eps",
      "weight_decay",
      "momentum",
      "centered"
    ]
  },
  "AveragedSgdOptimizer": {
    "__init__": [
      "self",
      "model_parameters",
      "parameter_groups",
      "lr",
      "lambd",
      "alpha",
      "t0",
      "weight_decay"
    ]
  },
  "DenseSparseAdam": {
    "__init__": [
      "self",
      "model_parameters",
      "parameter_groups",
      "lr",
      "betas",
      "eps"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "Scheduler": {
    "__init__": [
      "self",
      "optimizer",
      "param_group_field",
      "last_epoch"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "get_values": [
      "self"
    ],
    "step": [
      "self",
      "metric"
    ],
    "step_batch": [
      "self",
      "batch_num_total"
    ]
  },
  "GradientDescentTrainer": {
    "__init__": [
      "self",
      "model",
      "optimizer",
      "data_loader",
      "patience",
      "validation_metric",
      "validation_data_loader",
      "num_epochs",
      "serialization_dir",
      "checkpointer",
      "cuda_device",
      "grad_norm",
      "grad_clipping",
      "learning_rate_scheduler",
      "momentum_scheduler",
      "moving_average",
      "callbacks",
      "distributed",
      "local_rank",
      "world_size",
      "num_gradient_accumulation_steps",
      "use_amp",
      "enable_default_callbacks",
      "run_confidence_checks",
      "grad_scaling",
      "ddp_wrapped_model"
    ],
    "_pytorch_model": [
      "self"
    ],
    "clip_gradient": [
      "self"
    ],
    "rescale_gradients": [
      "self"
    ],
    "batch_outputs": [
      "self",
      "batch",
      "for_training"
    ],
    "_train_epoch": [
      "self",
      "epoch"
    ],
    "_validation_loss": [
      "self",
      "epoch"
    ],
    "train": [
      "self"
    ],
    "_try_train": [
      "self"
    ],
    "_save_model_state": [
      "self",
      "path"
    ],
    "_load_model_state": [
      "self",
      "path"
    ],
    "_finalize_model": [
      "self"
    ],
    "_finalize_best_model_state": [
      "self"
    ],
    "get_checkpoint_state": [
      "self"
    ],
    "_maybe_restore_checkpoint": [
      "self"
    ],
    "from_partial_objects": [
      "cls",
      "model",
      "serialization_dir",
      "data_loader",
      "validation_data_loader",
      "local_rank",
      "patience",
      "validation_metric",
      "num_epochs",
      "cuda_device",
      "grad_norm",
      "grad_clipping",
      "distributed",
      "world_size",
      "num_gradient_accumulation_steps",
      "use_amp",
      "no_grad",
      "optimizer",
      "learning_rate_scheduler",
      "momentum_scheduler",
      "moving_average",
      "checkpointer",
      "callbacks",
      "enable_default_callbacks",
      "run_confidence_checks",
      "grad_scaling",
      "ddp_accelerator"
    ],
    "get_best_weights_path": [
      "self"
    ]
  },
  "Checkpointer": {
    "default_implementation": [],
    "__init__": [
      "self",
      "serialization_dir",
      "save_completed_epochs",
      "save_every_num_seconds",
      "save_every_num_batches",
      "keep_most_recent_by_count",
      "keep_most_recent_by_age"
    ],
    "_is_primary": [
      "self"
    ],
    "_model_state_path": [
      "self",
      "epochs_completed",
      "batches_in_epoch_completed"
    ],
    "_training_state_path": [
      "self",
      "epochs_completed",
      "batches_in_epoch_completed"
    ],
    "_model_state_file_re": [],
    "_training_state_file_re": [],
    "_parse_model_state_path": [
      "cls",
      "path"
    ],
    "_parse_training_state_path": [
      "cls",
      "path"
    ],
    "_find_all_checkpoints": [
      "self"
    ],
    "_remove_checkpoint": [
      "self",
      "epochs_completed",
      "batches_in_epoch_completed"
    ],
    "maybe_save_checkpoint": [
      "self",
      "trainer",
      "num_epochs_completed",
      "num_batches_in_epoch_completed"
    ],
    "save_checkpoint": [
      "self",
      "trainer"
    ],
    "find_latest_checkpoint": [
      "self"
    ],
    "load_checkpoint": [
      "self"
    ]
  },
  "HasBeenWarned": {
    "tqdm_ignores_underscores": []
  },
  "move_optimizer_to_cuda": [
    "optimizer"
  ],
  "get_batch_size": [
    "batch"
  ],
  "time_to_str": [
    "timestamp"
  ],
  "str_to_time": [
    "time_str"
  ],
  "data_loaders_from_params": [
    "params",
    "train",
    "validation",
    "test",
    "serialization_dir"
  ],
  "create_serialization_dir": [
    "params",
    "serialization_dir",
    "recover",
    "force"
  ],
  "enable_gradient_clipping": [
    "model",
    "grad_clipping"
  ],
  "rescale_gradients": [
    "model",
    "grad_norm"
  ],
  "get_metrics": [
    "model",
    "total_loss",
    "total_reg_loss",
    "batch_loss",
    "batch_reg_loss",
    "num_batches",
    "reset"
  ],
  "get_train_and_validation_metrics": [
    "metrics"
  ],
  "evaluate": [
    "model",
    "data_loader",
    "cuda_device",
    "batch_weight_key",
    "output_file",
    "predictions_output_file"
  ],
  "description_from_metrics": [
    "metrics"
  ],
  "make_vocab_from_params": [
    "params",
    "serialization_dir",
    "print_statistics"
  ],
  "ngrams": [
    "tensor",
    "ngram_size",
    "exclude_indices"
  ],
  "get_valid_tokens_mask": [
    "tensor",
    "exclude_indices"
  ],
  "MetricTracker": {
    "__init__": [
      "self",
      "metric_name",
      "patience"
    ],
    "clear": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "add_metrics": [
      "self",
      "metrics"
    ],
    "is_best_so_far": [
      "self"
    ],
    "should_stop_early": [
      "self"
    ],
    "combined_score": [
      "self",
      "metrics"
    ]
  },
  "NoOpTrainer": {
    "__init__": [
      "self",
      "serialization_dir",
      "model"
    ],
    "train": [
      "self"
    ],
    "get_checkpoint_state": [
      "self"
    ],
    "get_best_weights_path": [
      "self"
    ]
  },
  "NamedParameter": [],
  "MovingAverage": {
    "default_implementation": [],
    "__init__": [
      "self",
      "parameters"
    ],
    "apply": [
      "self",
      "num_updates"
    ],
    "assign_average_value": [
      "self"
    ],
    "restore": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "ExponentialMovingAverage": {
    "__init__": [
      "self",
      "parameters",
      "decay",
      "numerator",
      "denominator"
    ],
    "apply": [
      "self",
      "num_updates"
    ]
  },
  "ROUGE": {
    "__init__": [
      "self",
      "ngram_size",
      "exclude_indices"
    ],
    "reset": [
      "self"
    ],
    "_longest_common_subsequence": [
      "self",
      "seq_1",
      "seq_2"
    ],
    "_get_rouge_l_score": [
      "self",
      "predicted_tokens",
      "reference_tokens"
    ],
    "_get_rouge_n_stats": [
      "self",
      "predicted_tokens",
      "reference_tokens",
      "ngram_size"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_targets",
      "mask"
    ],
    "_metric_mean": [
      "self",
      "metric_sum"
    ],
    "get_metric": [
      "self",
      "reset"
    ]
  },
  "AttachmentScores": {
    "__init__": [
      "self",
      "ignore_classes"
    ],
    "__call__": [
      "self",
      "predicted_indices",
      "predicted_labels",
      "gold_indices",
      "gold_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "Covariance": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "SpearmanCorrelation": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "Auc": {
    "__init__": [
      "self",
      "positive_label"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "FBetaMeasure": {
    "__init__": [
      "self",
      "beta",
      "average",
      "labels"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ],
    "_true_negative_sum": [
      "self"
    ]
  },
  "F1Measure": {
    "__init__": [
      "self",
      "positive_label"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "_true_positives": [
      "self"
    ],
    "_true_negatives": [
      "self"
    ],
    "_false_positives": [
      "self"
    ],
    "_false_negatives": [
      "self"
    ]
  },
  "PearsonCorrelation": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "Average": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "value"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "DEFAULT_EVALB_DIR": [],
  "EvalbBracketingScorer": {
    "__init__": [
      "self",
      "evalb_directory_path",
      "evalb_param_filename",
      "evalb_num_errors_to_kill"
    ],
    "__call__": [
      "self",
      "predicted_trees",
      "gold_trees"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ],
    "compile_evalb": [
      "evalb_directory_path"
    ],
    "clean_evalb": [
      "evalb_directory_path"
    ]
  },
  "TAGS_TO_SPANS_FUNCTION_TYPE": [],
  "SpanBasedF1Measure": {
    "__init__": [
      "self",
      "vocabulary",
      "tag_namespace",
      "ignore_classes",
      "label_encoding",
      "tags_to_spans_function"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_labels",
      "mask",
      "prediction_map"
    ],
    "_handle_continued_spans": [
      "spans"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "_compute_metrics": [
      "true_positives",
      "false_positives",
      "false_negatives"
    ],
    "reset": [
      "self"
    ]
  },
  "MeanAbsoluteError": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "FBetaVerboseMeasure": {
    "__init__": [
      "self",
      "beta",
      "labels",
      "index_to_label"
    ],
    "get_metric": [
      "self",
      "reset"
    ]
  },
  "CategoricalAccuracy": {
    "supports_distributed": [],
    "__init__": [
      "self",
      "top_k",
      "tie_break"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "SequenceAccuracy": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "BooleanAccuracy": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "BLEU": {
    "__init__": [
      "self",
      "ngram_weights",
      "exclude_indices"
    ],
    "reset": [
      "self"
    ],
    "_get_modified_precision_counts": [
      "self",
      "predicted_tokens",
      "reference_tokens",
      "ngram_size"
    ],
    "_get_brevity_penalty": [
      "self"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_targets",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ]
  },
  "Metric": {
    "supports_distributed": [],
    "__call__": [
      "self",
      "predictions",
      "gold_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ],
    "detach_tensors": []
  },
  "Entropy": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "logits",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "Perplexity": {
    "get_metric": [
      "self",
      "reset"
    ]
  },
  "FBetaMultiLabelMeasure": {
    "__init__": [
      "self",
      "beta",
      "average",
      "labels",
      "threshold"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_labels",
      "mask"
    ],
    "_true_negative_sum": [
      "self"
    ]
  },
  "F1MultiLabelMeasure": {
    "__init__": [
      "self",
      "average",
      "labels",
      "threshold"
    ]
  },
  "UnigramRecall": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "predictions",
      "gold_labels",
      "mask",
      "end_index"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "StepLearningRateScheduler": {
    "__init__": [
      "self",
      "optimizer",
      "step_size",
      "gamma",
      "last_epoch"
    ]
  },
  "MultiStepLearningRateScheduler": {
    "__init__": [
      "self",
      "optimizer",
      "milestones",
      "gamma",
      "last_epoch"
    ]
  },
  "ExponentialLearningRateScheduler": {
    "__init__": [
      "self",
      "optimizer",
      "gamma",
      "last_epoch"
    ]
  },
  "ReduceOnPlateauLearningRateScheduler": {
    "__init__": [
      "self",
      "optimizer",
      "mode",
      "factor",
      "patience",
      "verbose",
      "threshold_mode",
      "threshold",
      "cooldown",
      "min_lr",
      "eps"
    ]
  },
  "NoamLR": {
    "__init__": [
      "self",
      "optimizer",
      "model_size",
      "warmup_steps",
      "factor",
      "last_epoch"
    ],
    "step": [
      "self",
      "metric"
    ],
    "step_batch": [
      "self",
      "batch_num_total"
    ],
    "get_values": [
      "self"
    ]
  },
  "PolynomialDecay": {
    "__init__": [
      "self",
      "optimizer",
      "num_epochs",
      "num_steps_per_epoch",
      "power",
      "warmup_steps",
      "end_learning_rate",
      "last_epoch"
    ],
    "get_values": [
      "self"
    ],
    "step": [
      "self",
      "metric"
    ],
    "step_batch": [
      "self",
      "batch_num_total"
    ]
  },
  "CombinedLearningRateScheduler": {
    "__init__": [
      "self",
      "optimizer",
      "schedulers",
      "num_steps_per_epoch",
      "last_epoch"
    ],
    "current_scheduler": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "get_values": [
      "self"
    ],
    "step_batch": [
      "self",
      "batch_num_total"
    ],
    "step": [
      "self",
      "metric"
    ]
  },
  "LearningRateScheduler": {
    "__init__": [
      "self",
      "optimizer",
      "last_epoch"
    ],
    "get_values": [
      "self"
    ]
  },
  "_PyTorchLearningRateSchedulerWrapper": {
    "__init__": [
      "self",
      "lr_scheduler"
    ],
    "get_values": [
      "self"
    ],
    "step": [
      "self",
      "metric"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "_PyTorchLearningRateSchedulerWithMetricsWrapper": {
    "step": [
      "self",
      "metric"
    ]
  },
  "ConstantLearningRateScheduler": {
    "__init__": [
      "self",
      "optimizer",
      "last_epoch"
    ]
  },
  "ConstantWithWarmupLearningRateScheduler": {
    "__init__": [
      "self",
      "optimizer",
      "num_warmup_steps",
      "last_epoch"
    ]
  },
  "CosineWithWarmupLearningRateScheduler": {
    "__init__": [
      "self",
      "optimizer",
      "num_warmup_steps",
      "num_training_steps",
      "num_cycles",
      "last_epoch"
    ]
  },
  "CosineHardRestartsWithWarmupLearningRateScheduler": {
    "__init__": [
      "self",
      "optimizer",
      "num_warmup_steps",
      "num_training_steps",
      "num_cycles",
      "last_epoch"
    ]
  },
  "LinearWithWarmup": {
    "__init__": [
      "self",
      "optimizer",
      "num_epochs",
      "num_steps_per_epoch",
      "warmup_steps",
      "last_epoch"
    ]
  },
  "CosineWithRestarts": {
    "__init__": [
      "self",
      "optimizer",
      "t_initial",
      "t_mul",
      "eta_min",
      "eta_mul",
      "last_epoch"
    ],
    "get_values": [
      "self"
    ]
  },
  "SlantedTriangular": {
    "__init__": [
      "self",
      "optimizer",
      "num_epochs",
      "num_steps_per_epoch",
      "cut_frac",
      "ratio",
      "last_epoch",
      "gradual_unfreezing",
      "discriminative_fine_tuning",
      "decay_factor"
    ],
    "step": [
      "self",
      "metric"
    ],
    "step_batch": [
      "self",
      "batch_num_total"
    ],
    "get_values": [
      "self"
    ]
  },
  "ShouldValidateCallback": {
    "__init__": [
      "self",
      "serialization_dir",
      "validation_start",
      "validation_interval"
    ],
    "on_start": [
      "self",
      "trainer",
      "is_primary"
    ],
    "on_epoch": [
      "self",
      "trainer",
      "metrics",
      "epoch",
      "is_primary"
    ],
    "on_end": [
      "self",
      "trainer",
      "metrics",
      "epoch",
      "is_primary"
    ],
    "_should_validate": [
      "self",
      "epoch"
    ]
  },
  "WandBCallback": {
    "__init__": [
      "self",
      "serialization_dir",
      "summary_interval",
      "distribution_interval",
      "batch_size_interval",
      "should_log_parameter_statistics",
      "should_log_learning_rate",
      "project",
      "entity",
      "group",
      "name",
      "notes",
      "tags",
      "watch_model",
      "files_to_save",
      "wandb_kwargs"
    ],
    "log_scalars": [
      "self",
      "scalars",
      "log_prefix",
      "epoch"
    ],
    "log_tensors": [
      "self",
      "tensors",
      "log_prefix",
      "epoch"
    ],
    "_log": [
      "self",
      "dict_to_log",
      "log_prefix",
      "epoch"
    ],
    "on_start": [
      "self",
      "trainer",
      "is_primary"
    ],
    "close": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "ConfidenceChecksCallback": {
    "on_start": [
      "self",
      "trainer",
      "is_primary"
    ],
    "on_batch": [
      "self",
      "trainer",
      "batch_inputs",
      "batch_outputs",
      "batch_metrics",
      "epoch",
      "batch_number",
      "is_training",
      "is_primary",
      "batch_grad_norm"
    ]
  },
  "ConfidenceCheckError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "LogWriterCallback": {
    "__init__": [
      "self",
      "serialization_dir",
      "summary_interval",
      "distribution_interval",
      "batch_size_interval",
      "should_log_parameter_statistics",
      "should_log_learning_rate",
      "batch_loss_moving_average_count"
    ],
    "log_scalars": [
      "self",
      "scalars",
      "log_prefix",
      "epoch"
    ],
    "log_tensors": [
      "self",
      "tensors",
      "log_prefix",
      "epoch"
    ],
    "log_inputs": [
      "self",
      "inputs",
      "log_prefix"
    ],
    "close": [
      "self"
    ],
    "on_start": [
      "self",
      "trainer",
      "is_primary"
    ],
    "on_batch": [
      "self",
      "trainer",
      "batch_inputs",
      "batch_outputs",
      "batch_metrics",
      "epoch",
      "batch_number",
      "is_training",
      "is_primary",
      "batch_grad_norm"
    ],
    "on_epoch": [
      "self",
      "trainer",
      "metrics",
      "epoch",
      "is_primary"
    ],
    "on_end": [
      "self",
      "trainer",
      "metrics",
      "epoch",
      "is_primary"
    ],
    "log_batch": [
      "self",
      "batch_grad_norm",
      "metrics",
      "batch_group",
      "param_updates",
      "batch_number"
    ],
    "log_epoch": [
      "self",
      "train_metrics",
      "val_metrics",
      "epoch"
    ],
    "_should_log_distributions_next_batch": [
      "self"
    ],
    "_should_log_distributions_this_batch": [
      "self"
    ],
    "_enable_activation_logging": [
      "self"
    ],
    "_should_log_this_batch": [
      "self"
    ],
    "_log_activation_distribution": [
      "self",
      "outputs",
      "module_name"
    ],
    "_log_parameter_and_gradient_statistics": [
      "self",
      "batch_grad_norm"
    ],
    "_log_learning_rates": [
      "self"
    ],
    "_log_distributions": [
      "self"
    ],
    "_log_gradient_updates": [
      "self",
      "param_updates"
    ]
  },
  "TensorBoardCallback": {
    "__init__": [
      "self",
      "serialization_dir",
      "summary_interval",
      "distribution_interval",
      "batch_size_interval",
      "should_log_parameter_statistics",
      "should_log_learning_rate"
    ],
    "log_scalars": [
      "self",
      "scalars",
      "log_prefix",
      "epoch"
    ],
    "log_tensors": [
      "self",
      "tensors",
      "log_prefix",
      "epoch"
    ],
    "close": [
      "self"
    ]
  },
  "TrainerCallback": {
    "__init__": [
      "self",
      "serialization_dir"
    ],
    "on_start": [
      "self",
      "trainer",
      "is_primary"
    ],
    "on_backward": [
      "self",
      "trainer",
      "batch_outputs",
      "backward_called"
    ],
    "on_batch": [
      "self",
      "trainer",
      "batch_inputs",
      "batch_outputs",
      "batch_metrics",
      "epoch",
      "batch_number",
      "is_training",
      "is_primary",
      "batch_grad_norm"
    ],
    "on_epoch": [
      "self",
      "trainer",
      "metrics",
      "epoch",
      "is_primary"
    ],
    "on_end": [
      "self",
      "trainer",
      "metrics",
      "epoch",
      "is_primary"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "MixedPrecisionBackwardCallback": {
    "on_backward": [
      "self",
      "trainer",
      "batch_outputs",
      "backward_called"
    ]
  },
  "OnBackwardException": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "TrackEpochCallback": {
    "on_start": [
      "self",
      "trainer",
      "is_primary"
    ],
    "on_epoch": [
      "self",
      "trainer",
      "metrics",
      "epoch",
      "is_primary"
    ]
  },
  "ConsoleLoggerCallback": {
    "__init__": [
      "self",
      "serialization_dir",
      "should_log_inputs"
    ],
    "on_batch": [
      "self",
      "trainer",
      "batch_inputs",
      "batch_outputs",
      "batch_metrics",
      "epoch",
      "batch_number",
      "is_training",
      "is_primary",
      "batch_grad_norm"
    ],
    "_log_fields": [
      "self",
      "fields",
      "log_prefix"
    ],
    "on_epoch": [
      "self",
      "trainer",
      "metrics",
      "epoch",
      "is_primary"
    ]
  },
  "MomentumScheduler": {
    "__init__": [
      "self",
      "optimizer",
      "last_epoch"
    ],
    "get_values": [
      "self"
    ]
  },
  "InvertedTriangular": {
    "__init__": [
      "self",
      "optimizer",
      "cool_down",
      "warm_up",
      "ratio",
      "last_epoch"
    ],
    "get_values": [
      "self"
    ]
  },
  "Diff": {
    "add_subparser": [
      "self",
      "parser"
    ]
  },
  "Keep": {
    "display": [
      "self"
    ]
  },
  "Insert": {
    "display": [
      "self"
    ]
  },
  "Remove": {
    "display": [
      "self"
    ]
  },
  "Modify": {
    "display": [
      "self"
    ]
  },
  "_Frontier": {},
  "_finalize": [
    "history",
    "state_dict_a",
    "state_dict_b",
    "scale",
    "threshold"
  ],
  "checkpoint_diff": [
    "state_dict_a",
    "state_dict_b",
    "scale",
    "threshold"
  ],
  "_get_checkpoint_path": [
    "checkpoint"
  ],
  "_diff": [
    "args"
  ],
  "PushToHf": {
    "add_subparser": [
      "self",
      "parser"
    ]
  },
  "push": [
    "args"
  ],
  "CachedPath": {
    "add_subparser": [
      "self",
      "parser"
    ]
  },
  "_cached_path": [
    "args"
  ],
  "ArgumentParserWithDefaults": {
    "_action_defaults_to_ignore": [],
    "_is_empty_default": [
      "default"
    ],
    "add_argument": [
      "self"
    ]
  },
  "parse_args": [
    "prog"
  ],
  "main": [
    "prog"
  ],
  "Train": {
    "add_subparser": [
      "self",
      "parser"
    ]
  },
  "train_model_from_args": [
    "args"
  ],
  "train_model_from_file": [
    "parameter_filename",
    "serialization_dir",
    "overrides",
    "recover",
    "force",
    "node_rank",
    "include_package",
    "dry_run",
    "file_friendly_logging",
    "return_model"
  ],
  "train_model": [
    "params",
    "serialization_dir",
    "recover",
    "force",
    "node_rank",
    "include_package",
    "dry_run",
    "file_friendly_logging",
    "return_model"
  ],
  "_train_worker": [
    "process_rank",
    "params",
    "serialization_dir",
    "include_package",
    "dry_run",
    "node_rank",
    "primary_addr",
    "primary_port",
    "world_size",
    "distributed_device_ids",
    "file_friendly_logging",
    "include_in_archive",
    "distributed_params"
  ],
  "TrainModel": {
    "default_implementation": [],
    "__init__": [
      "self",
      "serialization_dir",
      "model",
      "trainer",
      "evaluation_data_loader",
      "evaluate_on_test",
      "batch_weight_key"
    ],
    "run": [
      "self"
    ],
    "finish": [
      "self",
      "metrics"
    ],
    "from_partial_objects": [
      "cls",
      "serialization_dir",
      "local_rank",
      "dataset_reader",
      "train_data_path",
      "model",
      "data_loader",
      "trainer",
      "vocabulary",
      "datasets_for_vocab_creation",
      "validation_dataset_reader",
      "validation_data_path",
      "validation_data_loader",
      "test_data_path",
      "evaluate_on_test",
      "batch_weight_key",
      "ddp_accelerator"
    ]
  },
  "TestInstall": {
    "add_subparser": [
      "self",
      "parser"
    ]
  },
  "_get_module_root": [],
  "_run_test": [
    "args"
  ],
  "FindLearningRate": {
    "add_subparser": [
      "self",
      "parser"
    ]
  },
  "find_learning_rate_from_args": [
    "args"
  ],
  "find_learning_rate_model": [
    "params",
    "serialization_dir",
    "start_lr",
    "end_lr",
    "num_batches",
    "linear_steps",
    "stopping_factor",
    "force"
  ],
  "search_learning_rate": [
    "trainer",
    "start_lr",
    "end_lr",
    "num_batches",
    "linear_steps",
    "stopping_factor"
  ],
  "_smooth": [
    "values",
    "beta"
  ],
  "_save_plot": [
    "learning_rates",
    "losses",
    "save_path"
  ],
  "BuildVocab": {
    "add_subparser": [
      "self",
      "parser"
    ]
  },
  "build_vocab_from_args": [
    "args"
  ],
  "PrintResults": {
    "add_subparser": [
      "self",
      "parser"
    ]
  },
  "print_results_from_args": [
    "args"
  ],
  "Predict": {
    "add_subparser": [
      "self",
      "parser"
    ]
  },
  "_get_predictor": [
    "args"
  ],
  "_PredictManager": {
    "__init__": [
      "self",
      "predictor",
      "input_file",
      "output_file",
      "batch_size",
      "print_to_console",
      "has_dataset_reader",
      "multitask_head"
    ],
    "_predict_json": [
      "self",
      "batch_data"
    ],
    "_predict_instances": [
      "self",
      "batch_data"
    ],
    "_maybe_print_to_console_and_file": [
      "self",
      "index",
      "prediction",
      "model_input"
    ],
    "_get_json_data": [
      "self"
    ],
    "_get_instance_data": [
      "self"
    ],
    "run": [
      "self"
    ]
  },
  "_predict": [
    "args"
  ],
  "CountInstances": {
    "add_subparser": [
      "self",
      "parser"
    ]
  },
  "count_instances_from_args": [
    "args"
  ],
  "Subcommand": {
    "add_subparser": [
      "self",
      "parser"
    ],
    "register": [
      "cls",
      "name",
      "constructor",
      "exist_ok"
    ],
    "name": [
      "self"
    ]
  },
  "Evaluate": {
    "add_subparser": [
      "self",
      "parser"
    ]
  },
  "evaluate_from_args": [
    "args"
  ],
  "evaluate_from_archive": [
    "archive_file",
    "input_file",
    "metrics_output_file",
    "predictions_output_file",
    "batch_size",
    "cmd_overrides",
    "cuda_device",
    "embedding_sources_mapping",
    "extend_vocab",
    "weights_file",
    "file_friendly_logging",
    "batch_weight_key",
    "auto_names"
  ],
  "CheckList": {
    "add_subparser": [
      "self",
      "parser"
    ]
  },
  "_get_task_suite": [
    "args"
  ],
  "_CheckListManager": {
    "__init__": [
      "self",
      "task_suite",
      "predictor",
      "capabilities",
      "max_examples",
      "output_file",
      "print_summary_args"
    ],
    "run": [
      "self"
    ]
  },
  "_run_suite": [
    "args"
  ],
  "Initializer": {
    "default_implementation": [],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "uniform_unit_scaling": [
    "tensor",
    "nonlinearity"
  ],
  "block_orthogonal": [
    "tensor",
    "split_sizes",
    "gain"
  ],
  "zero": [
    "tensor"
  ],
  "lstm_hidden_bias": [
    "tensor"
  ],
  "_InitializerWrapper": {
    "__init__": [
      "self",
      "init_function"
    ],
    "__call__": [
      "self",
      "tensor"
    ],
    "__repr__": [
      "self"
    ]
  },
  "NormalInitializer": {
    "__init__": [
      "self",
      "mean",
      "std"
    ]
  },
  "OrthogonalInitializer": {
    "__init__": [
      "self",
      "gain"
    ]
  },
  "UniformInitializer": {
    "__init__": [
      "self",
      "a",
      "b"
    ]
  },
  "ConstantInitializer": {
    "__init__": [
      "self",
      "val"
    ]
  },
  "DiracInitializer": {
    "__init__": [
      "self"
    ]
  },
  "XavierUniformInitializer": {
    "__init__": [
      "self",
      "gain"
    ]
  },
  "XavierNormalInitializer": {
    "__init__": [
      "self",
      "gain"
    ]
  },
  "KaimingUniformInitializer": {
    "__init__": [
      "self",
      "a",
      "mode",
      "nonlinearity"
    ]
  },
  "KaimingNormalInitializer": {
    "__init__": [
      "self",
      "a",
      "mode",
      "nonlinearity"
    ]
  },
  "SparseInitializer": {
    "__init__": [
      "self",
      "sparsity",
      "std"
    ]
  },
  "EyeInitializer": {
    "__init__": [
      "self"
    ]
  },
  "BlockOrthogonalInitializer": {
    "__init__": [
      "self",
      "split_sizes",
      "gain"
    ]
  },
  "UniformUnitScalingInitializer": {
    "__init__": [
      "self",
      "nonlinearity"
    ]
  },
  "ZeroInitializer": {
    "__init__": [
      "self"
    ]
  },
  "LstmHiddenBiasInitializer": {
    "__init__": [
      "self"
    ]
  },
  "PretrainedModelInitializer": {
    "__init__": [
      "self",
      "weights_file_path",
      "parameter_name_overrides"
    ],
    "__call__": [
      "self",
      "tensor",
      "parameter_name"
    ]
  },
  "InitializerApplicator": {
    "__init__": [
      "self",
      "regexes",
      "prevent_regexes"
    ],
    "__call__": [
      "self",
      "module"
    ]
  },
  "Activation": {
    "forward": [
      "self",
      "x"
    ]
  },
  "LinearActivation": {
    "forward": [
      "self",
      "x"
    ]
  },
  "MishActivation": {
    "forward": [
      "self",
      "x"
    ]
  },
  "SwishActivation": {
    "forward": [
      "self",
      "x"
    ]
  },
  "GeluNew": {
    "forward": [
      "self",
      "x"
    ]
  },
  "GeluFast": {
    "forward": [
      "self",
      "x"
    ]
  },
  "Module": {
    "_post_load_state_dict": [
      "self",
      "missing_keys",
      "unexpected_keys"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "load_state_dict_distributed": [
      "self",
      "state_dict",
      "strict"
    ]
  },
  "decode_mst": [
    "energy",
    "length",
    "has_labels"
  ],
  "chu_liu_edmonds": [
    "length",
    "score_matrix",
    "current_nodes",
    "final_edges",
    "old_input",
    "old_output",
    "representatives"
  ],
  "_find_cycle": [
    "parents",
    "length",
    "current_nodes"
  ],
  "StateDictType": [],
  "move_to_device": [
    "obj",
    "device"
  ],
  "clamp_tensor": [
    "tensor",
    "minimum",
    "maximum"
  ],
  "batch_tensor_dicts": [
    "tensor_dicts",
    "remove_trailing_dimension"
  ],
  "get_lengths_from_binary_sequence_mask": [
    "mask"
  ],
  "get_mask_from_sequence_lengths": [
    "sequence_lengths",
    "max_length"
  ],
  "sort_batch_by_length": [
    "tensor",
    "sequence_lengths"
  ],
  "get_final_encoder_states": [
    "encoder_outputs",
    "mask",
    "bidirectional"
  ],
  "get_dropout_mask": [
    "dropout_probability",
    "tensor_for_masking"
  ],
  "masked_softmax": [
    "vector",
    "mask",
    "dim",
    "memory_efficient"
  ],
  "masked_log_softmax": [
    "vector",
    "mask",
    "dim"
  ],
  "masked_max": [
    "vector",
    "mask",
    "dim",
    "keepdim"
  ],
  "masked_mean": [
    "vector",
    "mask",
    "dim",
    "keepdim"
  ],
  "masked_flip": [
    "padded_sequence",
    "sequence_lengths"
  ],
  "viterbi_decode": [
    "tag_sequence",
    "transition_matrix",
    "tag_observations",
    "allowed_start_transitions",
    "allowed_end_transitions",
    "top_k"
  ],
  "get_text_field_mask": [
    "text_field_tensors",
    "num_wrapping_dims",
    "padding_id"
  ],
  "get_token_ids_from_text_field_tensors": [
    "text_field_tensors"
  ],
  "weighted_sum": [
    "matrix",
    "attention"
  ],
  "sequence_cross_entropy_with_logits": [
    "logits",
    "targets",
    "weights",
    "average",
    "label_smoothing",
    "gamma",
    "alpha"
  ],
  "replace_masked_values": [
    "tensor",
    "mask",
    "replace_with"
  ],
  "tensors_equal": [
    "tensor1",
    "tensor2",
    "tolerance"
  ],
  "device_mapping": [
    "cuda_device"
  ],
  "read_state_dict": [
    "path",
    "strip_prefix",
    "ignore",
    "strict",
    "cuda_device"
  ],
  "combine_tensors": [
    "combination",
    "tensors"
  ],
  "_rindex": [
    "sequence",
    "obj"
  ],
  "_get_combination": [
    "combination",
    "tensors"
  ],
  "combine_tensors_and_multiply": [
    "combination",
    "tensors",
    "weights"
  ],
  "_get_combination_and_multiply": [
    "combination",
    "tensors",
    "weight"
  ],
  "get_combined_dim": [
    "combination",
    "tensor_dims"
  ],
  "_get_combination_dim": [
    "combination",
    "tensor_dims"
  ],
  "logsumexp": [
    "tensor",
    "dim",
    "keepdim"
  ],
  "get_device_of": [
    "tensor"
  ],
  "flatten_and_batch_shift_indices": [
    "indices",
    "sequence_length"
  ],
  "batched_index_select": [
    "target",
    "indices",
    "flattened_indices"
  ],
  "masked_index_fill": [
    "target",
    "indices",
    "mask",
    "fill_value"
  ],
  "masked_index_replace": [
    "target",
    "indices",
    "mask",
    "replace"
  ],
  "batched_span_select": [
    "target",
    "spans"
  ],
  "flattened_index_select": [
    "target",
    "indices"
  ],
  "get_range_vector": [
    "size",
    "device"
  ],
  "bucket_values": [
    "distances",
    "num_identity_buckets",
    "num_total_buckets"
  ],
  "add_sentence_boundary_token_ids": [
    "tensor",
    "mask",
    "sentence_begin_token",
    "sentence_end_token"
  ],
  "remove_sentence_boundaries": [
    "tensor",
    "mask"
  ],
  "add_positional_features": [
    "tensor",
    "min_timescale",
    "max_timescale"
  ],
  "clone": [
    "module",
    "num_copies"
  ],
  "combine_initial_dims": [
    "tensor"
  ],
  "uncombine_initial_dims": [
    "tensor",
    "original_size"
  ],
  "inspect_parameters": [
    "module",
    "quiet"
  ],
  "find_text_field_embedder": [
    "model"
  ],
  "find_embedding_layer": [
    "model"
  ],
  "get_token_offsets_from_text_field_inputs": [
    "text_field_inputs"
  ],
  "extend_layer": [
    "layer",
    "new_dim"
  ],
  "masked_topk": [
    "input_",
    "mask",
    "k",
    "dim"
  ],
  "info_value_of_dtype": [
    "dtype"
  ],
  "min_value_of_dtype": [
    "dtype"
  ],
  "max_value_of_dtype": [
    "dtype"
  ],
  "tiny_value_of_dtype": [
    "dtype"
  ],
  "_V": [],
  "distributed_device": [],
  "dist_reduce": [
    "value",
    "reduce_op"
  ],
  "dist_reduce_sum": [
    "value"
  ],
  "_collect_state_dict": [
    "module",
    "state_dict",
    "recurse",
    "prefix"
  ],
  "_IncompatibleKeys": {
    "__repr__": [
      "self"
    ]
  },
  "_check_incompatible_keys": [
    "module",
    "missing_keys",
    "unexpected_keys",
    "strict"
  ],
  "load_state_dict_distributed": [
    "module",
    "state_dict",
    "strict",
    "prefix"
  ],
  "StateType": [],
  "StepFunctionTypeWithTimestep": [],
  "StepFunctionTypeNoTimestep": [],
  "StepFunctionType": [],
  "ConstraintStateType": [],
  "Sampler": {
    "default_implementation": [],
    "init_state": [
      "self",
      "start_class_log_probabilities",
      "batch_size",
      "num_classes"
    ],
    "sample_nodes": [
      "self",
      "log_probs",
      "per_node_beam_size",
      "state"
    ],
    "sample_beams": [
      "self",
      "log_probs",
      "beam_size",
      "state"
    ]
  },
  "DeterministicSampler": {
    "sample_nodes": [
      "self",
      "log_probs",
      "per_node_beam_size",
      "state"
    ]
  },
  "MultinomialSampler": {
    "__init__": [
      "self",
      "temperature",
      "with_replacement"
    ],
    "sample_nodes": [
      "self",
      "log_probs",
      "per_node_beam_size",
      "state"
    ]
  },
  "TopKSampler": {
    "__init__": [
      "self",
      "k",
      "temperature",
      "with_replacement"
    ],
    "sample_nodes": [
      "self",
      "log_probs",
      "per_node_beam_size",
      "state"
    ]
  },
  "TopPSampler": {
    "__init__": [
      "self",
      "p",
      "temperature",
      "with_replacement"
    ],
    "sample_nodes": [
      "self",
      "log_probs",
      "per_node_beam_size",
      "state"
    ]
  },
  "GumbelSampler": {
    "__init__": [
      "self",
      "temperature"
    ],
    "init_state": [
      "self",
      "start_class_log_probabilities",
      "batch_size",
      "num_classes"
    ],
    "sample_nodes": [
      "self",
      "log_probs",
      "per_node_beam_size",
      "state"
    ],
    "sample_beams": [
      "self",
      "log_probs",
      "beam_size",
      "state"
    ],
    "gumbel": [
      "self",
      "phi"
    ],
    "gumbel_with_max": [
      "self",
      "phi",
      "T"
    ]
  },
  "FinalSequenceScorer": {
    "default_implementation": [],
    "score": [
      "self",
      "predictions",
      "log_probabilities",
      "end_index"
    ]
  },
  "SequenceLogProbabilityScorer": {
    "score": [
      "self",
      "predictions",
      "log_probabilities",
      "end_index"
    ]
  },
  "LengthNormalizedSequenceLogProbabilityScorer": {
    "__init__": [
      "self",
      "length_penalty"
    ],
    "score": [
      "self",
      "predictions",
      "log_probabilities",
      "end_index"
    ]
  },
  "Constraint": {
    "__init__": [
      "self",
      "vocab"
    ],
    "init_state": [
      "self",
      "batch_size"
    ],
    "apply": [
      "self",
      "state",
      "class_log_probabilities"
    ],
    "_copy_state": [
      "state",
      "batch_size",
      "beam_size",
      "last_backpointer"
    ],
    "update_state": [
      "self",
      "state",
      "last_prediction",
      "last_backpointer"
    ],
    "_update_state": [
      "self",
      "state",
      "last_prediction"
    ]
  },
  "RepeatedNGramBlockingConstraint": {
    "__init__": [
      "self",
      "ngram_size"
    ],
    "init_state": [
      "self",
      "batch_size"
    ],
    "apply": [
      "self",
      "state",
      "class_log_probabilities"
    ],
    "_update_state": [
      "self",
      "state",
      "last_prediction"
    ]
  },
  "BeamSearch": {
    "default_implementation": [],
    "__init__": [
      "self",
      "end_index",
      "max_steps",
      "beam_size",
      "per_node_beam_size",
      "sampler",
      "min_steps",
      "final_sequence_scorer",
      "constraints",
      "vocab"
    ],
    "_reconstruct_sequences": [
      "predictions",
      "backpointers"
    ],
    "search": [
      "self",
      "start_predictions",
      "start_state",
      "step"
    ],
    "_search": [
      "self",
      "start_predictions",
      "start_state",
      "step"
    ],
    "_is_multilayer_rnn_decoder": [
      "key",
      "state_tensor"
    ],
    "_update_initial_state": [
      "self",
      "state",
      "batch_size"
    ],
    "_update_state": [
      "self",
      "state",
      "backpointer"
    ]
  },
  "_FSDP": {
    "get_original_module": [
      "self"
    ]
  },
  "FairScaleFsdpWrappedModel": {
    "consolidate_sharded_state": [
      "sharded_state_files"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "state_dict": [
      "self"
    ],
    "clip_grad_norm_": [
      "self",
      "max_norm"
    ],
    "init_grad_scaler": [
      "self"
    ]
  },
  "FairScaleFsdpAccelerator": {
    "__init__": [
      "self"
    ],
    "wrap_model": [
      "self",
      "model"
    ],
    "wrap_module": [
      "self",
      "module"
    ]
  },
  "LoadStateDictReturnType": {},
  "DdpWrappedModel": {
    "__init__": [
      "self",
      "model",
      "local_rank",
      "world_size"
    ],
    "is_sharded": [
      "self"
    ],
    "consolidate_sharded_state": [
      "sharded_state_files"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ],
    "state_dict": [
      "self"
    ],
    "clip_grad_norm_": [
      "self",
      "max_norm"
    ],
    "init_grad_scaler": [
      "self"
    ]
  },
  "DdpAccelerator": {
    "default_implementation": [],
    "__init__": [
      "self",
      "local_rank",
      "world_size",
      "cuda_device"
    ],
    "wrap_model": [
      "self",
      "model"
    ],
    "wrap_module": [
      "self",
      "module"
    ]
  },
  "TorchDdpAccelerator": {
    "__init__": [
      "self"
    ],
    "wrap_model": [
      "self",
      "model"
    ],
    "_add_torch_ddp_prefix": [
      "state_dict",
      "prefix"
    ],
    "_remove_torch_ddp_prefix": [
      "module",
      "state_dict",
      "prefix"
    ]
  },
  "ShardedModuleMixin": {
    "get_original_module": [
      "self"
    ]
  },
  "RegularizerApplicator": {
    "__init__": [
      "self",
      "regexes"
    ],
    "__call__": [
      "self",
      "module"
    ]
  },
  "Regularizer": {
    "default_implementation": [],
    "__call__": [
      "self",
      "parameter"
    ]
  },
  "L1Regularizer": {
    "__init__": [
      "self",
      "alpha"
    ],
    "__call__": [
      "self",
      "parameter"
    ]
  },
  "L2Regularizer": {
    "__init__": [
      "self",
      "alpha"
    ],
    "__call__": [
      "self",
      "parameter"
    ]
  },
  "CheckpointWrapper": {
    "default_implementation": [],
    "wrap_module": [
      "self",
      "module"
    ]
  },
  "TorchCheckpointWrapper": {
    "wrap_module": [
      "self",
      "module"
    ]
  },
  "_checkpointed_forward": [
    "original_forward",
    "weak_self"
  ],
  "FairScaleCheckpointWrapper": {
    "__init__": [
      "self",
      "offload_to_cpu"
    ],
    "wrap_module": [
      "self",
      "module"
    ]
  },
  "Evaluator": {
    "default_implementation": [],
    "__init__": [
      "self",
      "batch_serializer",
      "cuda_device",
      "postprocessor_fn_name"
    ],
    "__call__": [
      "self",
      "model",
      "data_loader",
      "batch_weight_key",
      "metrics_output_file",
      "predictions_output_file"
    ]
  },
  "SimpleEvaluator": {
    "__init__": [
      "self",
      "batch_serializer",
      "cuda_device",
      "postprocessor_fn_name"
    ],
    "__call__": [
      "self",
      "model",
      "data_loader",
      "batch_weight_key",
      "metrics_output_file",
      "predictions_output_file"
    ],
    "_to_params": [
      "self"
    ]
  },
  "Serializer": {
    "__call__": [
      "self",
      "batch",
      "output_dict",
      "data_loader",
      "output_postprocess_function"
    ],
    "default_implementation": []
  },
  "SimpleSerializer": {
    "_to_params": [
      "self"
    ],
    "__call__": [
      "self",
      "batch",
      "output_dict",
      "data_loader",
      "output_postprocess_function"
    ]
  },
  "DEFAULT_NON_PADDED_NAMESPACES": [],
  "DEFAULT_PADDING_TOKEN": [],
  "DEFAULT_OOV_TOKEN": [],
  "NAMESPACE_PADDING_FILE": [],
  "_NEW_LINE_REGEX": [],
  "_NamespaceDependentDefaultDict": {
    "__init__": [
      "self",
      "non_padded_namespaces",
      "padded_function",
      "non_padded_function"
    ],
    "__missing__": [
      "self",
      "key"
    ],
    "add_non_padded_namespaces": [
      "self",
      "non_padded_namespaces"
    ]
  },
  "_TokenToIndexDefaultDict": {
    "__init__": [
      "self",
      "non_padded_namespaces",
      "padding_token",
      "oov_token"
    ]
  },
  "_IndexToTokenDefaultDict": {
    "__init__": [
      "self",
      "non_padded_namespaces",
      "padding_token",
      "oov_token"
    ]
  },
  "_read_pretrained_tokens": [
    "embeddings_file_uri"
  ],
  "Vocabulary": {
    "default_implementation": [],
    "__init__": [
      "self",
      "counter",
      "min_count",
      "max_vocab_size",
      "non_padded_namespaces",
      "pretrained_files",
      "only_include_pretrained_words",
      "tokens_to_add",
      "min_pretrained_embeddings",
      "padding_token",
      "oov_token"
    ],
    "from_pretrained_transformer": [
      "cls",
      "model_name",
      "namespace",
      "oov_token"
    ],
    "from_instances": [
      "cls",
      "instances",
      "min_count",
      "max_vocab_size",
      "non_padded_namespaces",
      "pretrained_files",
      "only_include_pretrained_words",
      "tokens_to_add",
      "min_pretrained_embeddings",
      "padding_token",
      "oov_token"
    ],
    "from_files": [
      "cls",
      "directory",
      "padding_token",
      "oov_token"
    ],
    "from_files_and_instances": [
      "cls",
      "instances",
      "directory",
      "padding_token",
      "oov_token",
      "min_count",
      "max_vocab_size",
      "non_padded_namespaces",
      "pretrained_files",
      "only_include_pretrained_words",
      "tokens_to_add",
      "min_pretrained_embeddings"
    ],
    "from_pretrained_transformer_and_instances": [
      "cls",
      "instances",
      "transformers",
      "min_count",
      "max_vocab_size",
      "non_padded_namespaces",
      "pretrained_files",
      "only_include_pretrained_words",
      "tokens_to_add",
      "min_pretrained_embeddings",
      "padding_token",
      "oov_token"
    ],
    "empty": [
      "cls"
    ],
    "add_transformer_vocab": [
      "self",
      "tokenizer",
      "namespace"
    ],
    "set_from_file": [
      "self",
      "filename",
      "is_padded",
      "oov_token",
      "namespace"
    ],
    "extend_from_instances": [
      "self",
      "instances"
    ],
    "extend_from_vocab": [
      "self",
      "vocab"
    ],
    "_extend": [
      "self",
      "counter",
      "min_count",
      "max_vocab_size",
      "non_padded_namespaces",
      "pretrained_files",
      "only_include_pretrained_words",
      "tokens_to_add",
      "min_pretrained_embeddings"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "save_to_files": [
      "self",
      "directory"
    ],
    "is_padded": [
      "self",
      "namespace"
    ],
    "add_token_to_namespace": [
      "self",
      "token",
      "namespace"
    ],
    "add_tokens_to_namespace": [
      "self",
      "tokens",
      "namespace"
    ],
    "get_index_to_token_vocabulary": [
      "self",
      "namespace"
    ],
    "get_token_to_index_vocabulary": [
      "self",
      "namespace"
    ],
    "get_token_index": [
      "self",
      "token",
      "namespace"
    ],
    "get_token_from_index": [
      "self",
      "index",
      "namespace"
    ],
    "get_vocab_size": [
      "self",
      "namespace"
    ],
    "get_namespaces": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "print_statistics": [
      "self"
    ]
  },
  "Batch": {
    "__slots__": [],
    "__init__": [
      "self",
      "instances"
    ],
    "_check_types": [
      "self"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor_dict": [
      "self",
      "padding_lengths",
      "verbose"
    ],
    "__iter__": [
      "self"
    ],
    "index_instances": [
      "self",
      "vocab"
    ],
    "print_statistics": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "Instance": {
    "__slots__": [],
    "__init__": [
      "self",
      "fields"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "add_field": [
      "self",
      "field_name",
      "field",
      "vocab"
    ],
    "count_vocab_items": [
      "self",
      "counter"
    ],
    "index_fields": [
      "self",
      "vocab"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor_dict": [
      "self",
      "padding_lengths"
    ],
    "__str__": [
      "self"
    ],
    "duplicate": [
      "self"
    ],
    "human_readable_dict": [
      "self"
    ]
  },
  "OnePath": [],
  "ManyPaths": [],
  "ImagesWithSize": [],
  "ImageLoader": {
    "default_implementation": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "filename_or_filenames"
    ],
    "load": [
      "self",
      "filename"
    ],
    "_pack_image_list": [
      "self",
      "images",
      "sizes"
    ]
  },
  "TorchImageLoader": {
    "__init__": [
      "self"
    ],
    "load": [
      "self",
      "filename"
    ]
  },
  "MetadataField": {
    "__slots__": [],
    "__init__": [
      "self",
      "metadata"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "batch_tensors": [
      "self",
      "tensor_list"
    ],
    "__str__": [
      "self"
    ],
    "human_readable_repr": [
      "self"
    ]
  },
  "SequenceLabelField": {
    "__slots__": [],
    "__init__": [
      "self",
      "labels",
      "sequence_field",
      "label_namespace"
    ],
    "_maybe_warn_for_namespace": [
      "self",
      "label_namespace"
    ],
    "__iter__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "count_vocab_items": [
      "self",
      "counter"
    ],
    "index": [
      "self",
      "vocab"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "human_readable_repr": [
      "self"
    ]
  },
  "SequenceField": {
    "__slots__": [],
    "sequence_length": [
      "self"
    ],
    "empty_field": [
      "self"
    ]
  },
  "AdjacencyField": {
    "__slots__": [],
    "__init__": [
      "self",
      "indices",
      "sequence_field",
      "labels",
      "label_namespace",
      "padding_value"
    ],
    "_maybe_warn_for_namespace": [
      "self",
      "label_namespace"
    ],
    "count_vocab_items": [
      "self",
      "counter"
    ],
    "index": [
      "self",
      "vocab"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "human_readable_repr": [
      "self"
    ]
  },
  "IndexField": {
    "__slots__": [],
    "__init__": [
      "self",
      "index",
      "sequence_field"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__len__": [
      "self"
    ],
    "human_readable_repr": [
      "self"
    ]
  },
  "LabelField": {
    "__slots__": [],
    "__init__": [
      "self",
      "label",
      "label_namespace",
      "skip_indexing"
    ],
    "_maybe_warn_for_namespace": [
      "self",
      "label_namespace"
    ],
    "count_vocab_items": [
      "self",
      "counter"
    ],
    "index": [
      "self",
      "vocab"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "human_readable_repr": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "DataArray": [],
  "Field": {
    "__slots__": [],
    "count_vocab_items": [
      "self",
      "counter"
    ],
    "human_readable_repr": [
      "self"
    ],
    "index": [
      "self",
      "vocab"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "batch_tensors": [
      "self",
      "tensor_list"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__len__": [
      "self"
    ],
    "duplicate": [
      "self"
    ]
  },
  "_tensorize": [
    "x"
  ],
  "TransformerTextField": {
    "__slots__": [],
    "__init__": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "special_tokens_mask",
      "offsets_mapping",
      "padding_token_id"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "batch_tensors": [
      "self",
      "tensor_list"
    ],
    "human_readable_repr": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "TensorField": {
    "__slots__": [],
    "__init__": [
      "self",
      "tensor",
      "padding_value",
      "dtype"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "array": [
      "self"
    ],
    "human_readable_repr": [
      "self"
    ]
  },
  "NamespaceSwappingField": {
    "__slots__": [],
    "__init__": [
      "self",
      "source_tokens",
      "target_namespace"
    ],
    "index": [
      "self",
      "vocab"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "human_readable_repr": [
      "self"
    ]
  },
  "SpanField": {
    "__slots__": [],
    "__init__": [
      "self",
      "span_start",
      "span_end",
      "sequence_field"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__len__": [
      "self"
    ],
    "human_readable_repr": [
      "self"
    ]
  },
  "FlagField": {
    "__slots__": [],
    "__init__": [
      "self",
      "flag_value"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "batch_tensors": [
      "self",
      "tensor_list"
    ],
    "human_readable_repr": [
      "self"
    ]
  },
  "ArrayField": [],
  "TextFieldTensors": [],
  "TextField": {
    "__slots__": [],
    "__init__": [
      "self",
      "tokens",
      "token_indexers"
    ],
    "token_indexers": [
      "self",
      "token_indexers"
    ],
    "count_vocab_items": [
      "self",
      "counter"
    ],
    "index": [
      "self",
      "vocab"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "sequence_length": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "batch_tensors": [
      "self",
      "tensor_list"
    ],
    "__str__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "duplicate": [
      "self"
    ],
    "human_readable_repr": [
      "self"
    ]
  },
  "MultiLabelField": {
    "__slots__": [],
    "__init__": [
      "self",
      "labels",
      "label_namespace",
      "skip_indexing",
      "num_labels"
    ],
    "_maybe_warn_for_namespace": [
      "self",
      "label_namespace"
    ],
    "count_vocab_items": [
      "self",
      "counter"
    ],
    "index": [
      "self",
      "vocab"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "human_readable_repr": [
      "self"
    ]
  },
  "ListField": {
    "__slots__": [],
    "__init__": [
      "self",
      "field_list"
    ],
    "__iter__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "count_vocab_items": [
      "self",
      "counter"
    ],
    "index": [
      "self",
      "vocab"
    ],
    "get_padding_lengths": [
      "self"
    ],
    "sequence_length": [
      "self"
    ],
    "as_tensor": [
      "self",
      "padding_lengths"
    ],
    "empty_field": [
      "self"
    ],
    "batch_tensors": [
      "self",
      "tensor_list"
    ],
    "__str__": [
      "self"
    ],
    "human_readable_repr": [
      "self"
    ]
  },
  "MultiProcessDataLoader": {
    "__init__": [
      "self",
      "reader",
      "data_path"
    ],
    "index_with": [
      "self",
      "vocab"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "iter_instances": [
      "self"
    ],
    "set_target_device": [
      "self",
      "device"
    ],
    "_iter_batches": [
      "self"
    ],
    "_start_instance_workers": [
      "self",
      "queue",
      "ctx"
    ],
    "_start_batch_workers": [
      "self",
      "queue",
      "ctx"
    ],
    "_join_workers": [
      "self",
      "workers",
      "queue",
      "txs"
    ],
    "_safe_queue_put": [
      "self",
      "worker_id",
      "item",
      "queue",
      "rx"
    ],
    "_instance_worker": [
      "self",
      "worker_id",
      "queue",
      "lock",
      "rx"
    ],
    "_batch_worker": [
      "self",
      "worker_id",
      "queue",
      "lock",
      "rx"
    ],
    "_gather_instances": [
      "self",
      "queue"
    ],
    "_index_instance": [
      "self",
      "instance"
    ],
    "_instances_to_batches": [
      "self",
      "instance_iterator",
      "move_to_device"
    ],
    "_maybe_tqdm": [
      "self",
      "iterator"
    ]
  },
  "WorkerError": {
    "__init__": [
      "self",
      "original_err_repr",
      "traceback"
    ]
  },
  "maybe_shuffle_instances": [
    "loader",
    "shuffle"
  ],
  "MultiTaskDataLoader": {
    "__init__": [
      "self",
      "reader",
      "data_path",
      "scheduler"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "iter_instances": [
      "self"
    ],
    "index_with": [
      "self",
      "vocab"
    ],
    "set_target_device": [
      "self",
      "device"
    ],
    "_get_instances_for_epoch": [
      "self"
    ],
    "_make_data_loader": [
      "self",
      "key"
    ]
  },
  "MultiTaskScheduler": {
    "batch_instances": [
      "self",
      "epoch_instances"
    ],
    "update_from_epoch_metrics": [
      "self",
      "epoch_metrics"
    ],
    "count_batches": [
      "self",
      "dataset_counts"
    ],
    "default_implementation": []
  },
  "_chunked_iterator": [
    "i",
    "chunk_size",
    "drop_last"
  ],
  "RoundRobinScheduler": {
    "__init__": [
      "self",
      "batch_size",
      "drop_last"
    ],
    "batch_instances": [
      "self",
      "epoch_instances"
    ],
    "count_batches": [
      "self",
      "dataset_counts"
    ]
  },
  "HomogeneousRoundRobinScheduler": {
    "__init__": [
      "self",
      "batch_size",
      "drop_last"
    ],
    "batch_instances": [
      "self",
      "epoch_instances"
    ],
    "count_batches": [
      "self",
      "dataset_counts"
    ]
  },
  "TensorDict": [],
  "DataLoader": {
    "default_implementation": [],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "iter_instances": [
      "self"
    ],
    "index_with": [
      "self",
      "vocab"
    ],
    "set_target_device": [
      "self",
      "device"
    ]
  },
  "SimpleDataLoader": {
    "__init__": [
      "self",
      "instances",
      "batch_size"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "_iter_batches": [
      "self"
    ],
    "iter_instances": [
      "self"
    ],
    "index_with": [
      "self",
      "vocab"
    ],
    "set_target_device": [
      "self",
      "device"
    ],
    "from_dataset_reader": [
      "cls",
      "reader",
      "data_path",
      "batch_size",
      "shuffle",
      "batches_per_epoch",
      "quiet"
    ]
  },
  "allennlp_collate": [
    "instances"
  ],
  "DataCollator": {
    "default_implementation": [],
    "__call__": [
      "self",
      "instances"
    ]
  },
  "DefaultDataCollator": {
    "__call__": [
      "self",
      "instances"
    ]
  },
  "LanguageModelingDataCollator": {
    "__init__": [
      "self",
      "model_name",
      "mlm",
      "mlm_probability",
      "filed_name",
      "namespace"
    ],
    "__call__": [
      "self",
      "instances"
    ],
    "process_tokens": [
      "self",
      "tensor_dicts"
    ]
  },
  "MultiTaskEpochSampler": {
    "get_task_proportions": [
      "self",
      "data_loaders"
    ],
    "update_from_epoch_metrics": [
      "self",
      "epoch_metrics"
    ]
  },
  "UniformSampler": {
    "get_task_proportions": [
      "self",
      "data_loaders"
    ]
  },
  "WeightedSampler": {
    "__init__": [
      "self",
      "weights"
    ],
    "get_task_proportions": [
      "self",
      "data_loaders"
    ]
  },
  "ProportionalSampler": {
    "get_task_proportions": [
      "self",
      "data_loaders"
    ]
  },
  "SpacyTokenizer": {
    "__init__": [
      "self",
      "language",
      "pos_tags",
      "parse",
      "ner",
      "keep_spacy_tokens",
      "split_on_spaces",
      "start_tokens",
      "end_tokens"
    ],
    "_sanitize": [
      "self",
      "tokens"
    ],
    "batch_tokenize": [
      "self",
      "texts"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "_to_params": [
      "self"
    ]
  },
  "_WhitespaceSpacyTokenizer": {
    "__init__": [
      "self",
      "vocab"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "_remove_spaces": [
    "tokens"
  ],
  "CharacterTokenizer": {
    "__init__": [
      "self",
      "byte_encoding",
      "lowercase_characters",
      "start_tokens",
      "end_tokens"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "_to_params": [
      "self"
    ]
  },
  "Tokenizer": {
    "default_implementation": [],
    "batch_tokenize": [
      "self",
      "texts"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "add_special_tokens": [
      "self",
      "tokens1",
      "tokens2"
    ],
    "num_special_tokens_for_sequence": [
      "self"
    ],
    "num_special_tokens_for_pair": [
      "self"
    ]
  },
  "LettersDigitsTokenizer": {
    "tokenize": [
      "self",
      "text"
    ]
  },
  "SentenceSplitter": {
    "default_implementation": [],
    "split_sentences": [
      "self",
      "text"
    ],
    "batch_split_sentences": [
      "self",
      "texts"
    ]
  },
  "SpacySentenceSplitter": {
    "__init__": [
      "self",
      "language",
      "rule_based"
    ],
    "split_sentences": [
      "self",
      "text"
    ],
    "batch_split_sentences": [
      "self",
      "texts"
    ],
    "_to_params": [
      "self"
    ]
  },
  "WhitespaceTokenizer": {
    "tokenize": [
      "self",
      "text"
    ],
    "_to_params": [
      "self"
    ]
  },
  "PretrainedTransformerTokenizer": {
    "__init__": [
      "self",
      "model_name",
      "add_special_tokens",
      "max_length",
      "tokenizer_kwargs",
      "verification_tokens"
    ],
    "_reverse_engineer_special_tokens": [
      "self",
      "token_a",
      "token_b",
      "model_name",
      "tokenizer_kwargs"
    ],
    "tokenizer_lowercases": [
      "tokenizer"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "_estimate_character_indices": [
      "self",
      "text",
      "token_ids"
    ],
    "_intra_word_tokenize": [
      "self",
      "string_tokens"
    ],
    "_increment_offsets": [
      "offsets",
      "increment"
    ],
    "intra_word_tokenize": [
      "self",
      "string_tokens"
    ],
    "intra_word_tokenize_sentence_pair": [
      "self",
      "string_tokens_a",
      "string_tokens_b"
    ],
    "add_special_tokens": [
      "self",
      "tokens1",
      "tokens2"
    ],
    "num_special_tokens_for_sequence": [
      "self"
    ],
    "num_special_tokens_for_pair": [
      "self"
    ],
    "_to_params": [
      "self"
    ]
  },
  "Token": {
    "__slots__": [],
    "__init__": [
      "self",
      "text",
      "idx",
      "idx_end",
      "lemma_",
      "pos_",
      "tag_",
      "dep_",
      "ent_type_",
      "text_id",
      "type_id"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "ensure_text": [
      "self"
    ]
  },
  "show_token": [
    "token"
  ],
  "MaxTokensBatchSampler": {
    "__init__": [
      "self",
      "max_tokens",
      "sorting_keys",
      "padding_noise"
    ],
    "_lazy_groups_of_max_size": [
      "self",
      "iterable",
      "sizes"
    ],
    "get_batch_indices": [
      "self",
      "instances"
    ],
    "get_num_batches": [
      "self",
      "instances"
    ]
  },
  "BatchSampler": {
    "get_batch_indices": [
      "self",
      "instances"
    ],
    "get_num_batches": [
      "self",
      "instances"
    ],
    "get_batch_size": [
      "self"
    ]
  },
  "add_noise_to_value": [
    "value",
    "noise_param"
  ],
  "BucketBatchSampler": {
    "__init__": [
      "self",
      "batch_size",
      "sorting_keys",
      "padding_noise",
      "drop_last",
      "shuffle"
    ],
    "_argsort_by_padding": [
      "self",
      "instances"
    ],
    "get_batch_indices": [
      "self",
      "instances"
    ],
    "_guess_sorting_keys": [
      "self",
      "instances",
      "num_instances"
    ],
    "get_num_batches": [
      "self",
      "instances"
    ],
    "get_batch_size": [
      "self"
    ]
  },
  "PretrainedTransformerIndexer": {
    "__init__": [
      "self",
      "model_name",
      "namespace",
      "max_length",
      "tokenizer_kwargs"
    ],
    "_add_encoding_to_vocabulary_if_needed": [
      "self",
      "vocab"
    ],
    "count_vocab_items": [
      "self",
      "token",
      "counter"
    ],
    "tokens_to_indices": [
      "self",
      "tokens",
      "vocabulary"
    ],
    "indices_to_tokens": [
      "self",
      "indexed_tokens",
      "vocabulary"
    ],
    "_extract_token_and_type_ids": [
      "self",
      "tokens"
    ],
    "_postprocess_output": [
      "self",
      "output"
    ],
    "get_empty_token_list": [
      "self"
    ],
    "as_padded_tensor_dict": [
      "self",
      "tokens",
      "padding_lengths"
    ],
    "__eq__": [
      "self",
      "other"
    ]
  },
  "TokenCharactersIndexer": {
    "__init__": [
      "self",
      "namespace",
      "character_tokenizer",
      "start_tokens",
      "end_tokens",
      "min_padding_length",
      "token_min_padding_length"
    ],
    "count_vocab_items": [
      "self",
      "token",
      "counter"
    ],
    "tokens_to_indices": [
      "self",
      "tokens",
      "vocabulary"
    ],
    "get_padding_lengths": [
      "self",
      "indexed_tokens"
    ],
    "as_padded_tensor_dict": [
      "self",
      "tokens",
      "padding_lengths"
    ],
    "get_empty_token_list": [
      "self"
    ]
  },
  "_make_bos_eos": [
    "character",
    "padding_character",
    "beginning_of_word_character",
    "end_of_word_character",
    "max_word_length"
  ],
  "ELMoCharacterMapper": {
    "max_word_length": [],
    "beginning_of_sentence_character": [],
    "end_of_sentence_character": [],
    "beginning_of_word_character": [],
    "end_of_word_character": [],
    "padding_character": [],
    "beginning_of_sentence_characters": [],
    "end_of_sentence_characters": [],
    "bos_token": [],
    "eos_token": [],
    "__init__": [
      "self",
      "tokens_to_add"
    ],
    "convert_word_to_char_ids": [
      "self",
      "word"
    ],
    "__eq__": [
      "self",
      "other"
    ]
  },
  "ELMoTokenCharactersIndexer": {
    "__init__": [
      "self",
      "namespace",
      "tokens_to_add",
      "token_min_padding_length"
    ],
    "count_vocab_items": [
      "self",
      "token",
      "counter"
    ],
    "get_empty_token_list": [
      "self"
    ],
    "tokens_to_indices": [
      "self",
      "tokens",
      "vocabulary"
    ],
    "as_padded_tensor_dict": [
      "self",
      "tokens",
      "padding_lengths"
    ]
  },
  "PretrainedTransformerMismatchedIndexer": {
    "__init__": [
      "self",
      "model_name",
      "namespace",
      "max_length",
      "tokenizer_kwargs"
    ],
    "count_vocab_items": [
      "self",
      "token",
      "counter"
    ],
    "tokens_to_indices": [
      "self",
      "tokens",
      "vocabulary"
    ],
    "get_empty_token_list": [
      "self"
    ],
    "as_padded_tensor_dict": [
      "self",
      "tokens",
      "padding_lengths"
    ],
    "__eq__": [
      "self",
      "other"
    ]
  },
  "IndexedTokenList": [],
  "TokenIndexer": {
    "default_implementation": [],
    "has_warned_for_as_padded_tensor": [],
    "__init__": [
      "self",
      "token_min_padding_length"
    ],
    "count_vocab_items": [
      "self",
      "token",
      "counter"
    ],
    "tokens_to_indices": [
      "self",
      "tokens",
      "vocabulary"
    ],
    "indices_to_tokens": [
      "self",
      "indexed_tokens",
      "vocabulary"
    ],
    "get_empty_token_list": [
      "self"
    ],
    "get_padding_lengths": [
      "self",
      "indexed_tokens"
    ],
    "as_padded_tensor_dict": [
      "self",
      "tokens",
      "padding_lengths"
    ],
    "__eq__": [
      "self",
      "other"
    ]
  },
  "_DEFAULT_VALUE": [],
  "SingleIdTokenIndexer": {
    "__init__": [
      "self",
      "namespace",
      "lowercase_tokens",
      "start_tokens",
      "end_tokens",
      "feature_name",
      "default_value",
      "token_min_padding_length"
    ],
    "count_vocab_items": [
      "self",
      "token",
      "counter"
    ],
    "tokens_to_indices": [
      "self",
      "tokens",
      "vocabulary"
    ],
    "get_empty_token_list": [
      "self"
    ],
    "_get_feature_value": [
      "self",
      "token"
    ],
    "_to_params": [
      "self"
    ]
  },
  "SpacyTokenIndexer": {
    "__init__": [
      "self",
      "hidden_dim",
      "token_min_padding_length"
    ],
    "count_vocab_items": [
      "self",
      "token",
      "counter"
    ],
    "tokens_to_indices": [
      "self",
      "tokens",
      "vocabulary"
    ],
    "as_padded_tensor_dict": [
      "self",
      "tokens",
      "padding_lengths"
    ]
  },
  "TextClassificationJsonReader": {
    "__init__": [
      "self",
      "token_indexers",
      "tokenizer",
      "segment_sentences",
      "max_sequence_length",
      "skip_label_indexing",
      "text_key",
      "label_key"
    ],
    "_read": [
      "self",
      "file_path"
    ],
    "_truncate": [
      "self",
      "tokens"
    ],
    "text_to_instance": [
      "self",
      "text",
      "label"
    ],
    "apply_token_indexers": [
      "self",
      "instance"
    ]
  },
  "_is_divider": [
    "line"
  ],
  "Conll2003DatasetReader": {
    "_VALID_LABELS": [],
    "__init__": [
      "self",
      "token_indexers",
      "tag_label",
      "feature_labels",
      "convert_to_coding_scheme",
      "label_namespace"
    ],
    "_read": [
      "self",
      "file_path"
    ],
    "text_to_instance": [
      "self",
      "tokens",
      "pos_tags",
      "chunk_tags",
      "ner_tags"
    ],
    "apply_token_indexers": [
      "self",
      "instance"
    ]
  },
  "_VALID_SCHEMES": [],
  "InterleavingDatasetReader": {
    "__init__": [
      "self",
      "readers",
      "dataset_field_name",
      "scheme"
    ],
    "_set_worker_info": [
      "self",
      "info"
    ],
    "_set_distributed_info": [
      "self",
      "info"
    ],
    "_read_round_robin": [
      "self",
      "datasets"
    ],
    "_read_all_at_once": [
      "self",
      "datasets"
    ],
    "_read": [
      "self",
      "file_path"
    ],
    "text_to_instance": [
      "self",
      "dataset_key"
    ],
    "apply_token_indexers": [
      "self",
      "instance"
    ]
  },
  "ShardedDatasetReader": {
    "__init__": [
      "self",
      "base_reader"
    ],
    "text_to_instance": [
      "self"
    ],
    "apply_token_indexers": [
      "self",
      "instance"
    ],
    "_read": [
      "self",
      "file_path"
    ]
  },
  "WorkerInfo": {},
  "DistributedInfo": {},
  "PathOrStr": [],
  "DatasetReaderInput": [],
  "DatasetReader": {
    "__init__": [
      "self",
      "max_instances",
      "manual_distributed_sharding",
      "manual_multiprocess_sharding",
      "serialization_dir"
    ],
    "read": [
      "self",
      "file_path"
    ],
    "_read": [
      "self",
      "file_path"
    ],
    "text_to_instance": [
      "self"
    ],
    "apply_token_indexers": [
      "self",
      "instance"
    ],
    "get_worker_info": [
      "self"
    ],
    "get_distributed_info": [
      "self"
    ],
    "_set_worker_info": [
      "self",
      "info"
    ],
    "_set_distributed_info": [
      "self",
      "info"
    ],
    "shard_iterable": [
      "self",
      "iterable"
    ],
    "_multi_worker_islice": [
      "self",
      "iterable"
    ]
  },
  "BabiReader": {
    "__init__": [
      "self",
      "keep_sentences",
      "token_indexers"
    ],
    "_read": [
      "self",
      "file_path"
    ],
    "text_to_instance": [
      "self",
      "context",
      "question",
      "answer",
      "supports"
    ],
    "apply_token_indexers": [
      "self",
      "instance"
    ]
  },
  "MultiTaskDatasetReader": {
    "__init__": [
      "self",
      "readers"
    ],
    "read": [
      "self",
      "file_paths"
    ]
  },
  "_MultitaskDatasetReaderShim": {
    "__init__": [
      "self",
      "inner",
      "head"
    ],
    "_set_worker_info": [
      "self",
      "info"
    ],
    "read": [
      "self",
      "file_path"
    ],
    "text_to_instance": [
      "self"
    ],
    "apply_token_indexers": [
      "self",
      "instance"
    ]
  },
  "DEFAULT_WORD_TAG_DELIMITER": [],
  "SequenceTaggingDatasetReader": {
    "__init__": [
      "self",
      "word_tag_delimiter",
      "token_delimiter",
      "token_indexers"
    ],
    "_read": [
      "self",
      "file_path"
    ],
    "text_to_instance": [
      "self",
      "tokens",
      "tags"
    ],
    "apply_token_indexers": [
      "self",
      "instance"
    ],
    "_to_params": [
      "self"
    ]
  },
  "TypedSpan": [],
  "TypedStringSpan": [],
  "InvalidTagSequence": {
    "__init__": [
      "self",
      "tag_sequence"
    ],
    "__str__": [
      "self"
    ]
  },
  "enumerate_spans": [
    "sentence",
    "offset",
    "max_span_width",
    "min_span_width",
    "filter_function"
  ],
  "bio_tags_to_spans": [
    "tag_sequence",
    "classes_to_ignore"
  ],
  "iob1_tags_to_spans": [
    "tag_sequence",
    "classes_to_ignore"
  ],
  "_iob1_start_of_chunk": [
    "prev_bio_tag",
    "prev_conll_tag",
    "curr_bio_tag",
    "curr_conll_tag"
  ],
  "bioul_tags_to_spans": [
    "tag_sequence",
    "classes_to_ignore"
  ],
  "iob1_to_bioul": [
    "tag_sequence"
  ],
  "to_bioul": [
    "tag_sequence",
    "encoding"
  ],
  "bmes_tags_to_spans": [
    "tag_sequence",
    "classes_to_ignore"
  ],
  "NormalizationBiasVerification": {
    "normalization_layers": [],
    "__init__": [
      "self",
      "model"
    ],
    "detected_pairs": [
      "self"
    ],
    "check": [
      "self",
      "inputs"
    ],
    "collect_detections": [
      "self"
    ],
    "_verification_message": [
      "self"
    ],
    "register_hooks": [
      "self"
    ],
    "_create_hook": [
      "self",
      "module_name"
    ],
    "destroy_hooks": [
      "self"
    ]
  },
  "VerificationBase": {
    "__init__": [
      "self",
      "model"
    ],
    "check": [
      "self"
    ],
    "_get_inputs_copy": [
      "self",
      "inputs"
    ],
    "_model_forward": [
      "self",
      "inputs"
    ]
  },
  "_add_phrase_function": [
    "phrases",
    "num_samples"
  ],
  "SentimentAnalysisSuite": {
    "__init__": [
      "self",
      "suite",
      "positive",
      "negative"
    ],
    "_prediction_and_confidence_scores": [
      "self",
      "predictor"
    ],
    "_format_failing_examples": [
      "self",
      "inputs",
      "pred",
      "conf",
      "label"
    ],
    "_default_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_setup_editor": [
      "self"
    ],
    "_default_vocabulary_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_robustness_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_ner_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_temporal_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_fairness_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_negation_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_positive_change": [
      "self",
      "orig_conf",
      "conf"
    ],
    "_diff_up": [
      "self",
      "orig_pred",
      "pred",
      "orig_conf",
      "conf",
      "labels",
      "meta"
    ],
    "_diff_down": [
      "self",
      "orig_pred",
      "pred",
      "orig_conf",
      "conf",
      "labels",
      "meta"
    ]
  },
  "add_common_lexicons": [
    "editor"
  ],
  "spacy_wrap": [
    "fn",
    "language"
  ],
  "strip_punctuation": [
    "data"
  ],
  "toggle_punctuation": [
    "data"
  ],
  "random_string": [
    "n"
  ],
  "random_url": [
    "n"
  ],
  "random_handle": [
    "n"
  ],
  "add_random_strings": [
    "data"
  ],
  "_wrap_apply_to_each": [
    "perturb_fn",
    "both"
  ],
  "TextualEntailmentSuite": {
    "__init__": [
      "self",
      "suite",
      "entails",
      "contradicts",
      "neutral",
      "premise",
      "hypothesis",
      "probs_key"
    ],
    "_prediction_and_confidence_scores": [
      "self",
      "predictor"
    ],
    "_format_failing_examples": [
      "self",
      "inputs",
      "pred",
      "conf",
      "label"
    ],
    "contractions": [
      "cls"
    ],
    "typos": [
      "cls"
    ],
    "punctuation": [
      "cls"
    ],
    "_setup_editor": [
      "self"
    ],
    "_default_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_vocabulary_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_taxonomy_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_coreference_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_robustness_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_logic_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_negation_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_ner_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_temporal_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_fairness_tests": [
      "self",
      "data",
      "num_test_cases"
    ]
  },
  "_crossproduct": [
    "template"
  ],
  "QuestionAnsweringSuite": {
    "__init__": [
      "self",
      "suite",
      "context_key",
      "question_key",
      "answer_key"
    ],
    "_prediction_and_confidence_scores": [
      "self",
      "predictor"
    ],
    "_format_failing_examples": [
      "self",
      "inputs",
      "pred",
      "conf",
      "label"
    ],
    "contractions": [
      "cls"
    ],
    "typos": [
      "cls"
    ],
    "punctuation": [
      "cls"
    ],
    "_setup_editor": [
      "self"
    ],
    "_default_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_vocabulary_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_default_taxonomy_tests": [
      "self",
      "data",
      "num_test_cases"
    ]
  },
  "TaskSuite": {
    "__init__": [
      "self",
      "suite",
      "add_default_tests",
      "data",
      "num_test_cases"
    ],
    "_prediction_and_confidence_scores": [
      "self",
      "predictor"
    ],
    "describe": [
      "self"
    ],
    "summary": [
      "self",
      "capabilities",
      "file"
    ],
    "_summary": [
      "self",
      "overview_only",
      "capabilities"
    ],
    "_format_failing_examples": [
      "self",
      "inputs",
      "pred",
      "conf"
    ],
    "run": [
      "self",
      "predictor",
      "capabilities",
      "max_examples"
    ],
    "constructor": [
      "cls",
      "name",
      "suite_file",
      "extra_args"
    ],
    "save_suite": [
      "self",
      "suite_file"
    ],
    "_default_tests": [
      "self",
      "data",
      "num_test_cases"
    ],
    "contractions": [
      "cls"
    ],
    "typos": [
      "cls"
    ],
    "punctuation": [
      "cls"
    ],
    "_punctuation_test": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_typo_test": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_contraction_test": [
      "self",
      "data",
      "num_test_cases"
    ],
    "_setup_editor": [
      "self"
    ],
    "add_test": [
      "self",
      "test"
    ]
  },
  "BiasDirection": {
    "__init__": [
      "self",
      "requires_grad"
    ],
    "_normalize_bias_direction": [
      "self",
      "bias_direction"
    ]
  },
  "PCABiasDirection": {
    "__call__": [
      "self",
      "seed_embeddings"
    ]
  },
  "PairedPCABiasDirection": {
    "__call__": [
      "self",
      "seed_embeddings1",
      "seed_embeddings2"
    ]
  },
  "TwoMeansBiasDirection": {
    "__call__": [
      "self",
      "seed_embeddings1",
      "seed_embeddings2"
    ]
  },
  "ClassificationNormalBiasDirection": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "seed_embeddings1",
      "seed_embeddings2"
    ]
  },
  "BiasMitigatorWrapper": {
    "train": [
      "self",
      "mode"
    ]
  },
  "HardBiasMitigatorWrapper": {
    "__init__": [
      "self",
      "bias_direction",
      "embedding_layer",
      "equalize_word_pairs_file",
      "tokenizer",
      "mitigator_vocab",
      "namespace",
      "requires_grad"
    ],
    "__call__": [
      "self",
      "module",
      "module_in",
      "module_out"
    ],
    "train": [
      "self",
      "mode"
    ]
  },
  "LinearBiasMitigatorWrapper": {
    "__init__": [
      "self",
      "bias_direction",
      "embedding_layer",
      "requires_grad"
    ],
    "__call__": [
      "self",
      "module",
      "module_in",
      "module_out"
    ],
    "train": [
      "self",
      "mode"
    ]
  },
  "INLPBiasMitigatorWrapper": {
    "__init__": [
      "self",
      "embedding_layer",
      "seed_word_pairs_file",
      "tokenizer",
      "mitigator_vocab",
      "namespace"
    ],
    "__call__": [
      "self",
      "module",
      "module_in",
      "module_out"
    ],
    "train": [
      "self",
      "mode"
    ]
  },
  "OSCaRBiasMitigatorWrapper": {
    "__init__": [
      "self",
      "bias_direction1",
      "bias_direction2",
      "embedding_layer",
      "requires_grad"
    ],
    "__call__": [
      "self",
      "module",
      "module_in",
      "module_out"
    ],
    "train": [
      "self",
      "mode"
    ]
  },
  "BiasMitigatorApplicator": {
    "__init__": [
      "self",
      "vocab",
      "base_model",
      "bias_mitigator"
    ],
    "train": [
      "self",
      "mode"
    ],
    "forward": [
      "self"
    ],
    "forward_on_instance": [
      "self"
    ],
    "forward_on_instances": [
      "self"
    ],
    "get_regularization_penalty": [
      "self"
    ],
    "get_parameters_for_histogram_logging": [
      "self"
    ],
    "get_parameters_for_histogram_tensorboard_logging": [
      "self"
    ],
    "make_output_human_readable": [
      "self"
    ],
    "get_metrics": [
      "self"
    ],
    "_get_prediction_device": [
      "self"
    ],
    "_maybe_warn_for_unseparable_batches": [
      "self"
    ],
    "extend_embedder_vocab": [
      "self"
    ]
  },
  "WordEmbeddingAssociationTest": {
    "__call__": [
      "self",
      "target_embeddings1",
      "target_embeddings2",
      "attribute_embeddings1",
      "attribute_embeddings2"
    ]
  },
  "EmbeddingCoherenceTest": {
    "__call__": [
      "self",
      "target_embeddings1",
      "target_embeddings2",
      "attribute_embeddings"
    ],
    "_get_ranks": [
      "self",
      "x"
    ],
    "spearman_correlation": [
      "self",
      "x",
      "y"
    ]
  },
  "NaturalLanguageInference": {
    "__init__": [
      "self",
      "neutral_label",
      "taus"
    ],
    "__call__": [
      "self",
      "nli_probabilities"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "AssociationWithoutGroundTruth": {
    "__init__": [
      "self",
      "num_classes",
      "num_protected_variable_labels",
      "association_metric",
      "gap_type"
    ],
    "__call__": [
      "self",
      "predicted_labels",
      "protected_variable_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ],
    "_ova_gap": [
      "self",
      "x"
    ],
    "_pairwise_gaps": [
      "self",
      "x"
    ],
    "_all_pmi_terms": [
      "self"
    ]
  },
  "_convert_word_to_ids_tensor": [
    "word",
    "tokenizer",
    "vocab",
    "namespace",
    "all_cases"
  ],
  "load_words": [
    "fname",
    "tokenizer",
    "vocab",
    "namespace",
    "all_cases"
  ],
  "load_word_pairs": [
    "fname",
    "tokenizer",
    "vocab",
    "namespace",
    "all_cases"
  ],
  "BiasMitigator": {
    "__init__": [
      "self",
      "requires_grad"
    ],
    "_proj": [
      "self",
      "u",
      "v",
      "normalize"
    ],
    "_remove_component": [
      "self",
      "embeddings",
      "bias_direction",
      "normalize"
    ]
  },
  "HardBiasMitigator": {
    "__call__": [
      "self",
      "evaluation_embeddings",
      "bias_direction",
      "equalize_embeddings1",
      "equalize_embeddings2"
    ]
  },
  "LinearBiasMitigator": {
    "__call__": [
      "self",
      "evaluation_embeddings",
      "bias_direction"
    ]
  },
  "INLPBiasMitigator": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "evaluation_embeddings",
      "seed_embeddings1",
      "seed_embeddings2",
      "num_iters"
    ],
    "_get_rowspace_proj": [
      "self",
      "weights"
    ]
  },
  "OSCaRBiasMitigator": {
    "__call__": [
      "self",
      "evaluation_embeddings",
      "bias_direction1",
      "bias_direction2"
    ]
  },
  "Independence": {
    "__init__": [
      "self",
      "num_classes",
      "num_protected_variable_labels",
      "dist_metric"
    ],
    "__call__": [
      "self",
      "predicted_labels",
      "protected_variable_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "Separation": {
    "__init__": [
      "self",
      "num_classes",
      "num_protected_variable_labels",
      "dist_metric"
    ],
    "__call__": [
      "self",
      "predicted_labels",
      "gold_labels",
      "protected_variable_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "Sufficiency": {
    "__init__": [
      "self",
      "num_classes",
      "num_protected_variable_labels",
      "dist_metric"
    ],
    "__call__": [
      "self",
      "predicted_labels",
      "gold_labels",
      "protected_variable_labels",
      "mask"
    ],
    "get_metric": [
      "self",
      "reset"
    ],
    "reset": [
      "self"
    ]
  },
  "BiasDirectionWrapper": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "module"
    ],
    "train": [
      "self",
      "mode"
    ],
    "add_noise": [
      "self",
      "t"
    ]
  },
  "PCABiasDirectionWrapper": {
    "__init__": [
      "self",
      "seed_words_file",
      "tokenizer",
      "direction_vocab",
      "namespace",
      "requires_grad",
      "noise"
    ],
    "__call__": [
      "self",
      "module"
    ]
  },
  "PairedPCABiasDirectionWrapper": {
    "__init__": [
      "self",
      "seed_word_pairs_file",
      "tokenizer",
      "direction_vocab",
      "namespace",
      "requires_grad",
      "noise"
    ],
    "__call__": [
      "self",
      "module"
    ]
  },
  "TwoMeansBiasDirectionWrapper": {
    "__init__": [
      "self",
      "seed_word_pairs_file",
      "tokenizer",
      "direction_vocab",
      "namespace",
      "requires_grad",
      "noise"
    ],
    "__call__": [
      "self",
      "module"
    ]
  },
  "ClassificationNormalBiasDirectionWrapper": {
    "__init__": [
      "self",
      "seed_word_pairs_file",
      "tokenizer",
      "direction_vocab",
      "namespace",
      "noise"
    ],
    "__call__": [
      "self",
      "module"
    ]
  },
  "AdversarialBiasMitigator": {
    "__init__": [
      "self",
      "vocab",
      "predictor",
      "adversary",
      "bias_direction",
      "predictor_output_key"
    ],
    "train": [
      "self",
      "mode"
    ],
    "forward": [
      "self"
    ],
    "forward_on_instance": [
      "self"
    ],
    "forward_on_instances": [
      "self"
    ],
    "get_regularization_penalty": [
      "self"
    ],
    "get_parameters_for_histogram_logging": [
      "self"
    ],
    "get_parameters_for_histogram_tensorboard_logging": [
      "self"
    ],
    "make_output_human_readable": [
      "self"
    ],
    "get_metrics": [
      "self"
    ],
    "_get_prediction_device": [
      "self"
    ],
    "_maybe_warn_for_unseparable_batches": [
      "self"
    ],
    "extend_embedder_vocab": [
      "self"
    ]
  },
  "FeedForwardRegressionAdversary": {
    "__init__": [
      "self",
      "vocab",
      "feedforward",
      "initializer"
    ],
    "forward": [
      "self",
      "input",
      "label"
    ]
  },
  "AdversarialBiasMitigatorBackwardCallback": {
    "__init__": [
      "self",
      "serialization_dir",
      "adversary_loss_weight"
    ],
    "on_backward": [
      "self",
      "trainer",
      "batch_outputs",
      "backward_called"
    ]
  },
  "_AdversaryLabelHook": {
    "__init__": [
      "self",
      "predetermined_bias_direction"
    ],
    "__call__": [
      "self",
      "module",
      "module_in",
      "module_out"
    ]
  },
  "SimpleInfluence": {
    "__init__": [
      "self",
      "model",
      "train_data_path",
      "train_dataset_reader"
    ],
    "_calculate_influence_scores": [
      "self",
      "test_instance",
      "test_loss",
      "test_grads"
    ]
  },
  "get_inverse_hvp_lissa": [
    "vs",
    "model",
    "used_params",
    "lissa_data_loader",
    "damping",
    "num_samples",
    "scale"
  ],
  "get_hvp": [
    "loss",
    "params",
    "vectors"
  ],
  "_flatten_tensors": [
    "tensors"
  ],
  "InstanceInfluence": {},
  "InterpretOutput": {},
  "InstanceWithGrads": {},
  "InfluenceInterpreter": {
    "default_implementation": [],
    "__init__": [
      "self",
      "model",
      "train_data_path",
      "train_dataset_reader"
    ],
    "used_params": [
      "self"
    ],
    "used_param_names": [
      "self"
    ],
    "train_instances": [
      "self"
    ],
    "from_path": [
      "cls",
      "archive_path"
    ],
    "from_archive": [
      "cls",
      "archive"
    ],
    "interpret": [
      "self",
      "test_instance",
      "k"
    ],
    "interpret_from_file": [
      "self",
      "test_data_path",
      "k"
    ],
    "interpret_instances": [
      "self",
      "test_instances",
      "k"
    ],
    "_gather_instances": [
      "self",
      "scores",
      "indices"
    ],
    "_gather_train_instances_and_compute_gradients": [
      "self"
    ],
    "_calculate_influence_scores": [
      "self",
      "test_instance",
      "test_loss",
      "test_grads"
    ]
  },
  "IntegratedGradient": {
    "saliency_interpret_from_json": [
      "self",
      "inputs"
    ],
    "_register_hooks": [
      "self",
      "alpha",
      "embeddings_list",
      "token_offsets"
    ],
    "_integrate_gradients": [
      "self",
      "instance"
    ]
  },
  "SaliencyInterpreter": {
    "__init__": [
      "self",
      "predictor"
    ],
    "saliency_interpret_from_json": [
      "self",
      "inputs"
    ],
    "_aggregate_token_embeddings": [
      "embeddings_list",
      "token_offsets"
    ]
  },
  "SmoothGradient": {
    "__init__": [
      "self",
      "predictor"
    ],
    "saliency_interpret_from_json": [
      "self",
      "inputs"
    ],
    "_register_forward_hook": [
      "self",
      "stdev"
    ],
    "_smooth_grads": [
      "self",
      "instance"
    ]
  },
  "SimpleGradient": {
    "saliency_interpret_from_json": [
      "self",
      "inputs"
    ],
    "_register_hooks": [
      "self",
      "embeddings_list",
      "token_offsets"
    ]
  },
  "InputReduction": {
    "__init__": [
      "self",
      "predictor",
      "beam_size"
    ],
    "attack_from_json": [
      "self",
      "inputs",
      "input_field_to_attack",
      "grad_input_field",
      "ignore_tokens",
      "target"
    ],
    "_attack_instance": [
      "self",
      "inputs",
      "instance",
      "input_field_to_attack",
      "grad_input_field",
      "ignore_tokens"
    ]
  },
  "_remove_one_token": [
    "instance",
    "input_field_to_attack",
    "grads",
    "ignore_tokens",
    "beam_size",
    "tag_mask"
  ],
  "_get_ner_tags_and_mask": [
    "instance",
    "input_field_to_attack",
    "ignore_tokens"
  ],
  "get_fields_to_compare": [
    "inputs",
    "instance",
    "input_field_to_attack"
  ],
  "instance_has_changed": [
    "instance",
    "fields_to_compare"
  ],
  "DEFAULT_IGNORE_TOKENS": [],
  "Hotflip": {
    "__init__": [
      "self",
      "predictor",
      "vocab_namespace",
      "max_tokens"
    ],
    "initialize": [
      "self"
    ],
    "_construct_embedding_matrix": [
      "self"
    ],
    "_make_embedder_input": [
      "self",
      "all_tokens"
    ],
    "attack_from_json": [
      "self",
      "inputs",
      "input_field_to_attack",
      "grad_input_field",
      "ignore_tokens",
      "target"
    ],
    "attack_instance": [
      "self",
      "instance",
      "inputs",
      "input_field_to_attack",
      "grad_input_field",
      "ignore_tokens",
      "target"
    ],
    "_first_order_taylor": [
      "self",
      "grad",
      "token_idx",
      "sign"
    ]
  },
  "Attacker": {
    "__init__": [
      "self",
      "predictor"
    ],
    "initialize": [
      "self"
    ],
    "attack_from_json": [
      "self",
      "inputs",
      "input_field_to_attack",
      "grad_input_field",
      "ignore_tokens",
      "target"
    ]
  },
  "Archive": {
    "extract_module": [
      "self",
      "path",
      "freeze"
    ]
  },
  "CONFIG_NAME": [],
  "_WEIGHTS_NAME": [],
  "_VERSION_TUPLE": [],
  "verify_include_in_archive": [
    "include_in_archive"
  ],
  "archive_model": [
    "serialization_dir",
    "weights",
    "archive_path",
    "include_in_archive"
  ],
  "load_archive": [
    "archive_file",
    "cuda_device",
    "overrides",
    "weights_file"
  ],
  "_load_dataset_readers": [
    "config",
    "serialization_dir"
  ],
  "_load_model": [
    "config",
    "weights_path",
    "serialization_dir",
    "cuda_device"
  ],
  "get_weights_path": [
    "serialization_dir"
  ],
  "extracted_archive": [
    "resolved_archive_file",
    "cleanup"
  ],
  "_parse_version": [
    "version"
  ],
  "_check_version_compatibility": [
    "archive_file",
    "meta"
  ],
  "BasicClassifier": {
    "__init__": [
      "self",
      "vocab",
      "text_field_embedder",
      "seq2vec_encoder",
      "seq2seq_encoder",
      "feedforward",
      "dropout",
      "num_labels",
      "label_namespace",
      "namespace",
      "initializer"
    ],
    "forward": [
      "self",
      "tokens",
      "label",
      "metadata"
    ],
    "make_output_human_readable": [
      "self",
      "output_dict"
    ],
    "get_metrics": [
      "self",
      "reset"
    ],
    "default_predictor": []
  },
  "_DEFAULT_WEIGHTS": [],
  "Model": {
    "__init__": [
      "self",
      "vocab",
      "regularizer",
      "serialization_dir",
      "ddp_accelerator"
    ],
    "get_regularization_penalty": [
      "self"
    ],
    "get_parameters_for_histogram_logging": [
      "self"
    ],
    "get_parameters_for_histogram_tensorboard_logging": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "forward_on_instance": [
      "self",
      "instance"
    ],
    "forward_on_instances": [
      "self",
      "instances"
    ],
    "make_output_human_readable": [
      "self",
      "output_dict"
    ],
    "get_metrics": [
      "self",
      "reset"
    ],
    "_get_prediction_device": [
      "self"
    ],
    "_maybe_warn_for_unseparable_batches": [
      "self",
      "output_key"
    ],
    "_load": [
      "cls",
      "config",
      "serialization_dir",
      "weights_file",
      "cuda_device"
    ],
    "load": [
      "cls",
      "config",
      "serialization_dir",
      "weights_file",
      "cuda_device"
    ],
    "extend_embedder_vocab": [
      "self",
      "embedding_sources_mapping"
    ],
    "from_archive": [
      "cls",
      "archive_file",
      "vocab"
    ]
  },
  "remove_weights_related_keys_from_params": [
    "params",
    "keys"
  ],
  "remove_pretrained_embedding_params": [
    "params"
  ],
  "SimpleTagger": {
    "__init__": [
      "self",
      "vocab",
      "text_field_embedder",
      "encoder",
      "calculate_span_f1",
      "label_encoding",
      "label_namespace",
      "verbose_metrics",
      "initializer"
    ],
    "forward": [
      "self",
      "tokens",
      "tags",
      "metadata",
      "ignore_loss_on_o_tags"
    ],
    "make_output_human_readable": [
      "self",
      "output_dict"
    ],
    "get_metrics": [
      "self",
      "reset"
    ],
    "default_predictor": []
  },
  "get_forward_arguments": [
    "module"
  ],
  "MultiTaskModel": {
    "default_predictor": [],
    "__init__": [
      "self",
      "vocab",
      "backbone",
      "heads"
    ],
    "forward": [
      "self"
    ],
    "_get_arguments": [
      "self",
      "available_args",
      "component"
    ],
    "get_metrics": [
      "self",
      "reset"
    ],
    "make_output_human_readable": [
      "self",
      "output_dict"
    ]
  },
  "ClassifierHead": {
    "__init__": [
      "self",
      "vocab",
      "seq2vec_encoder",
      "feedforward",
      "input_dim",
      "dropout",
      "num_labels",
      "label_namespace"
    ],
    "forward": [
      "self",
      "encoded_text",
      "encoded_text_mask",
      "label"
    ],
    "make_output_human_readable": [
      "self",
      "output_dict"
    ],
    "get_metrics": [
      "self",
      "reset"
    ]
  },
  "Head": {},
  "LstmCellWithProjection": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "cell_size",
      "go_forward",
      "recurrent_dropout_probability",
      "memory_cell_clip_value",
      "state_projection_clip_value"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "batch_lengths",
      "initial_state"
    ]
  },
  "FeedForward": {
    "__init__": [
      "self",
      "input_dim",
      "num_layers",
      "hidden_dims",
      "activations",
      "dropout"
    ],
    "get_output_dim": [
      "self"
    ],
    "get_input_dim": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "ElmoLstm": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "cell_size",
      "num_layers",
      "requires_grad",
      "recurrent_dropout_probability",
      "memory_cell_clip_value",
      "state_projection_clip_value"
    ],
    "forward": [
      "self",
      "inputs",
      "mask"
    ],
    "_lstm_forward": [
      "self",
      "inputs",
      "initial_state"
    ],
    "load_weights": [
      "self",
      "weight_file"
    ]
  },
  "AugmentedLSTMCell": {
    "__init__": [
      "self",
      "embed_dim",
      "lstm_dim",
      "use_highway",
      "use_bias"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "states",
      "variational_dropout_mask"
    ]
  },
  "AugmentedLstm": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "go_forward",
      "recurrent_dropout_probability",
      "use_highway",
      "use_input_projection_bias"
    ],
    "forward": [
      "self",
      "inputs",
      "states"
    ]
  },
  "BiAugmentedLstm": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "bias",
      "recurrent_dropout_probability",
      "bidirectional",
      "padding_value",
      "use_highway"
    ],
    "forward": [
      "self",
      "inputs",
      "states"
    ],
    "_forward_bidirectional": [
      "self",
      "inputs",
      "states"
    ],
    "_forward_unidirectional": [
      "self",
      "inputs",
      "states"
    ]
  },
  "Elmo": {
    "__init__": [
      "self",
      "options_file",
      "weight_file",
      "num_output_representations",
      "requires_grad",
      "do_layer_norm",
      "dropout",
      "vocab_to_cache",
      "keep_sentence_boundaries",
      "scalar_mix_parameters",
      "module"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "word_inputs"
    ]
  },
  "batch_to_ids": [
    "batch"
  ],
  "_ElmoCharacterEncoder": {
    "__init__": [
      "self",
      "options_file",
      "weight_file",
      "requires_grad"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "_load_weights": [
      "self"
    ],
    "_load_char_embedding": [
      "self"
    ],
    "_load_cnn_weights": [
      "self"
    ],
    "_load_highway": [
      "self"
    ],
    "_load_projection": [
      "self"
    ]
  },
  "_ElmoBiLm": {
    "__init__": [
      "self",
      "options_file",
      "weight_file",
      "requires_grad",
      "vocab_to_cache"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "word_inputs"
    ],
    "create_cached_cnn_embeddings": [
      "self",
      "tokens"
    ]
  },
  "multi_perspective_match": [
    "vector1",
    "vector2",
    "weight"
  ],
  "multi_perspective_match_pairwise": [
    "vector1",
    "vector2",
    "weight"
  ],
  "BiMpmMatching": {
    "__init__": [
      "self",
      "hidden_dim",
      "num_perspectives",
      "share_weights_between_directions",
      "is_forward",
      "with_full_match",
      "with_maxpool_match",
      "with_attentive_match",
      "with_max_attentive_match"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "context_1",
      "mask_1",
      "context_2",
      "mask_2"
    ]
  },
  "TimeDistributed": {
    "__init__": [
      "self",
      "module"
    ],
    "forward": [
      "self"
    ],
    "_reshape_tensor": [
      "input_tensor"
    ]
  },
  "_choice": [
    "num_words",
    "num_samples"
  ],
  "SampledSoftmaxLoss": {
    "__init__": [
      "self",
      "num_words",
      "embedding_dim",
      "num_samples",
      "sparse",
      "unk_id",
      "use_character_inputs",
      "use_fast_sampler"
    ],
    "initialize_num_words": [
      "self"
    ],
    "forward": [
      "self",
      "embeddings",
      "targets",
      "target_token_embedding"
    ],
    "_forward_train": [
      "self",
      "embeddings",
      "targets",
      "target_token_embedding"
    ],
    "_forward_eval": [
      "self",
      "embeddings",
      "targets"
    ],
    "log_uniform_candidate_sampler": [
      "self",
      "targets",
      "choice_func"
    ]
  },
  "GatedSum": {
    "__init__": [
      "self",
      "input_dim",
      "activation"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "input_a",
      "input_b"
    ]
  },
  "Highway": {
    "__init__": [
      "self",
      "input_dim",
      "num_layers",
      "activation"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "LayerNorm": {
    "__init__": [
      "self",
      "dimension"
    ],
    "forward": [
      "self",
      "tensor"
    ]
  },
  "replicate_layers": [
    "layer",
    "num_copies"
  ],
  "MaskedLayerNorm": {
    "__init__": [
      "self",
      "size",
      "gamma0"
    ],
    "forward": [
      "self",
      "tensor",
      "mask"
    ]
  },
  "InputVariationalDropout": {
    "forward": [
      "self",
      "input_tensor"
    ]
  },
  "SoftmaxLoss": {
    "__init__": [
      "self",
      "num_words",
      "embedding_dim"
    ],
    "forward": [
      "self",
      "embeddings",
      "targets"
    ]
  },
  "RnnState": [],
  "RnnStateStorage": [],
  "_EncoderBase": {
    "__init__": [
      "self",
      "stateful"
    ],
    "sort_and_run_forward": [
      "self",
      "module",
      "inputs",
      "mask",
      "hidden_state"
    ],
    "_get_initial_states": [
      "self",
      "batch_size",
      "num_valid",
      "sorting_indices"
    ],
    "_update_states": [
      "self",
      "final_states",
      "restoration_indices"
    ],
    "reset_states": [
      "self",
      "mask"
    ]
  },
  "TensorPair": [],
  "StackedBidirectionalLstm": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "recurrent_dropout_probability",
      "layer_dropout_probability",
      "use_highway"
    ],
    "forward": [
      "self",
      "inputs",
      "initial_state"
    ]
  },
  "StackedAlternatingLstm": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "recurrent_dropout_probability",
      "use_highway",
      "use_input_projection_bias"
    ],
    "forward": [
      "self",
      "inputs",
      "initial_state"
    ]
  },
  "ScalarMix": {
    "__init__": [
      "self",
      "mixture_size",
      "do_layer_norm",
      "initial_scalar_parameters",
      "trainable"
    ],
    "forward": [
      "self",
      "tensors",
      "mask"
    ]
  },
  "ResidualWithLayerDropout": {
    "__init__": [
      "self",
      "undecayed_dropout_prob"
    ],
    "forward": [
      "self",
      "layer_input",
      "layer_output",
      "layer_index",
      "total_layers"
    ]
  },
  "Maxout": {
    "__init__": [
      "self",
      "input_dim",
      "num_layers",
      "output_dims",
      "pool_sizes",
      "dropout"
    ],
    "get_output_dim": [
      "self"
    ],
    "get_input_dim": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "VilbertBackbone": {
    "__init__": [
      "self",
      "vocab",
      "text_embeddings",
      "image_embeddings",
      "encoder",
      "pooled_output_dim",
      "fusion_method",
      "dropout",
      "vocab_namespace"
    ],
    "from_huggingface_model_name": [
      "cls",
      "vocab",
      "model_name",
      "image_feature_dim",
      "image_num_hidden_layers",
      "image_hidden_size",
      "image_num_attention_heads",
      "combined_hidden_size",
      "combined_num_attention_heads",
      "pooled_output_dim",
      "image_intermediate_size",
      "image_attention_dropout",
      "image_hidden_dropout",
      "image_biattention_id",
      "text_biattention_id",
      "text_fixed_layer",
      "image_fixed_layer",
      "fusion_method"
    ],
    "forward": [
      "self",
      "box_features",
      "box_coordinates",
      "box_mask",
      "text"
    ]
  },
  "PretrainedTransformerBackbone": {
    "__init__": [
      "self",
      "vocab",
      "model_name"
    ],
    "forward": [
      "self",
      "text"
    ],
    "make_output_human_readable": [
      "self",
      "output_dict"
    ]
  },
  "Backbone": {
    "forward": [
      "self"
    ],
    "make_output_human_readable": [
      "self",
      "output_dict"
    ]
  },
  "CosineMatrixAttention": {
    "forward": [
      "self",
      "matrix_1",
      "matrix_2"
    ]
  },
  "DotProductMatrixAttention": {
    "forward": [
      "self",
      "matrix_1",
      "matrix_2"
    ]
  },
  "LinearMatrixAttention": {
    "__init__": [
      "self",
      "tensor_1_dim",
      "tensor_2_dim",
      "combination",
      "activation"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "matrix_1",
      "matrix_2"
    ]
  },
  "ScaledDotProductMatrixAttention": {
    "forward": [
      "self",
      "matrix_1",
      "matrix_2"
    ]
  },
  "BilinearMatrixAttention": {
    "__init__": [
      "self",
      "matrix_1_dim",
      "matrix_2_dim",
      "activation",
      "use_input_biases",
      "label_dim"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "matrix_1",
      "matrix_2"
    ]
  },
  "MatrixAttention": {
    "forward": [
      "self",
      "matrix_1",
      "matrix_2"
    ]
  },
  "SelfAttentiveSpanExtractor": {
    "__init__": [
      "self",
      "input_dim",
      "num_width_embeddings",
      "span_width_embedding_dim",
      "bucket_widths"
    ],
    "get_output_dim": [
      "self"
    ],
    "_embed_spans": [
      "self",
      "sequence_tensor",
      "span_indices",
      "sequence_mask",
      "span_indices_mask"
    ]
  },
  "SpanExtractorWithSpanWidthEmbedding": {
    "__init__": [
      "self",
      "input_dim",
      "num_width_embeddings",
      "span_width_embedding_dim",
      "bucket_widths"
    ],
    "forward": [
      "self",
      "sequence_tensor",
      "span_indices",
      "sequence_mask",
      "span_indices_mask"
    ],
    "get_input_dim": [
      "self"
    ],
    "_embed_spans": [
      "self",
      "sequence_tensor",
      "span_indices",
      "sequence_mask",
      "span_indices_mask"
    ]
  },
  "BidirectionalEndpointSpanExtractor": {
    "__init__": [
      "self",
      "input_dim",
      "forward_combination",
      "backward_combination",
      "num_width_embeddings",
      "span_width_embedding_dim",
      "bucket_widths",
      "use_sentinels"
    ],
    "get_output_dim": [
      "self"
    ],
    "_embed_spans": [
      "self",
      "sequence_tensor",
      "span_indices",
      "sequence_mask",
      "span_indices_mask"
    ]
  },
  "MaxPoolingSpanExtractor": {
    "__init__": [
      "self",
      "input_dim",
      "num_width_embeddings",
      "span_width_embedding_dim",
      "bucket_widths"
    ],
    "get_output_dim": [
      "self"
    ],
    "_embed_spans": [
      "self",
      "sequence_tensor",
      "span_indices",
      "sequence_mask",
      "span_indices_mask"
    ]
  },
  "EndpointSpanExtractor": {
    "__init__": [
      "self",
      "input_dim",
      "combination",
      "num_width_embeddings",
      "span_width_embedding_dim",
      "bucket_widths",
      "use_exclusive_start_indices"
    ],
    "get_output_dim": [
      "self"
    ],
    "_embed_spans": [
      "self",
      "sequence_tensor",
      "span_indices",
      "sequence_mask",
      "span_indices_mask"
    ]
  },
  "SpanExtractor": {
    "forward": [
      "self",
      "sequence_tensor",
      "span_indices",
      "sequence_mask",
      "span_indices_mask"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ]
  },
  "BertPooler": {
    "__init__": [
      "self",
      "pretrained_model"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "tokens",
      "mask",
      "num_wrapping_dims"
    ]
  },
  "BagOfEmbeddingsEncoder": {
    "__init__": [
      "self",
      "embedding_dim",
      "averaged"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "tokens",
      "mask"
    ]
  },
  "ClsPooler": {
    "__init__": [
      "self",
      "embedding_dim",
      "cls_is_last_token"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "tokens",
      "mask"
    ]
  },
  "PytorchSeq2VecWrapper": {
    "__init__": [
      "self",
      "module"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "mask",
      "hidden_state"
    ]
  },
  "GruSeq2VecEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "bias",
      "dropout",
      "bidirectional"
    ]
  },
  "LstmSeq2VecEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "bias",
      "dropout",
      "bidirectional"
    ]
  },
  "RnnSeq2VecEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "nonlinearity",
      "bias",
      "dropout",
      "bidirectional"
    ]
  },
  "AugmentedLstmSeq2VecEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "go_forward",
      "recurrent_dropout_probability",
      "use_highway",
      "use_input_projection_bias"
    ]
  },
  "StackedAlternatingLstmSeq2VecEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "recurrent_dropout_probability",
      "use_highway",
      "use_input_projection_bias"
    ]
  },
  "StackedBidirectionalLstmSeq2VecEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "recurrent_dropout_probability",
      "layer_dropout_probability",
      "use_highway"
    ]
  },
  "Seq2VecEncoder": {
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ]
  },
  "CnnEncoder": {
    "__init__": [
      "self",
      "embedding_dim",
      "num_filters",
      "ngram_filter_sizes",
      "conv_layer_activation",
      "output_dim"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "tokens",
      "mask"
    ]
  },
  "_VALID_PROJECTION_LOCATIONS": [],
  "CnnHighwayEncoder": {
    "__init__": [
      "self",
      "embedding_dim",
      "filters",
      "num_highway",
      "projection_dim",
      "activation",
      "projection_location",
      "do_layer_norm"
    ],
    "forward": [
      "self",
      "inputs",
      "mask"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ]
  },
  "PretrainedTransformerMismatchedEmbedder": {
    "__init__": [
      "self",
      "model_name",
      "max_length",
      "sub_module",
      "train_parameters",
      "last_layer_only",
      "override_weights_file",
      "override_weights_strip_prefix",
      "load_weights",
      "gradient_checkpointing",
      "tokenizer_kwargs",
      "transformer_kwargs",
      "sub_token_mode"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "token_ids",
      "mask",
      "offsets",
      "wordpiece_mask",
      "type_ids",
      "segment_concat_mask"
    ]
  },
  "ElmoTokenEmbedder": {
    "__init__": [
      "self",
      "options_file",
      "weight_file",
      "do_layer_norm",
      "dropout",
      "requires_grad",
      "projection_dim",
      "vocab_to_cache",
      "scalar_mix_parameters"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "elmo_tokens",
      "word_inputs"
    ]
  },
  "PassThroughTokenEmbedder": {
    "__init__": [
      "self",
      "hidden_dim"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "tokens"
    ]
  },
  "TokenCharactersEncoder": {
    "__init__": [
      "self",
      "embedding",
      "encoder",
      "dropout"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "token_characters"
    ]
  },
  "Embedding": {
    "__init__": [
      "self",
      "embedding_dim",
      "num_embeddings",
      "projection_dim",
      "weight",
      "padding_index",
      "trainable",
      "max_norm",
      "norm_type",
      "scale_grad_by_freq",
      "sparse",
      "vocab_namespace",
      "pretrained_file",
      "vocab"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "tokens"
    ],
    "extend_vocab": [
      "self",
      "extended_vocab",
      "vocab_namespace",
      "extension_pretrained_file",
      "model_path"
    ]
  },
  "_read_pretrained_embeddings_file": [
    "file_uri",
    "embedding_dim",
    "vocab",
    "namespace"
  ],
  "_read_embeddings_from_text_file": [
    "file_uri",
    "embedding_dim",
    "vocab",
    "namespace"
  ],
  "_read_embeddings_from_hdf5": [
    "embeddings_filename",
    "embedding_dim",
    "vocab",
    "namespace"
  ],
  "format_embeddings_file_uri": [
    "main_file_path_or_url",
    "path_inside_archive"
  ],
  "EmbeddingsFileURI": {},
  "parse_embeddings_file_uri": [
    "uri"
  ],
  "EmbeddingsTextFile": {
    "DEFAULT_ENCODING": [],
    "__init__": [
      "self",
      "file_uri",
      "encoding",
      "cache_dir"
    ],
    "_open_inside_zip": [
      "self",
      "archive_path",
      "member_path"
    ],
    "_open_inside_tar": [
      "self",
      "archive_path",
      "member_path"
    ],
    "read": [
      "self"
    ],
    "readline": [
      "self"
    ],
    "close": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "_get_the_only_file_in_the_archive": [
      "members_list",
      "archive_path"
    ],
    "_get_num_tokens_from_first_line": [
      "line"
    ]
  },
  "TokenEmbedder": {
    "default_implementation": [],
    "get_output_dim": [
      "self"
    ]
  },
  "EmptyEmbedder": {
    "__init__": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "BagOfWordCountsTokenEmbedder": {
    "__init__": [
      "self",
      "vocab",
      "vocab_namespace",
      "projection_dim",
      "ignore_oov"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "PretrainedTransformerEmbedder": {
    "authorized_missing_keys": [],
    "__init__": [
      "self",
      "model_name"
    ],
    "train": [
      "self",
      "mode"
    ],
    "get_output_dim": [
      "self"
    ],
    "_number_of_token_type_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "token_ids",
      "mask",
      "type_ids",
      "segment_concat_mask"
    ],
    "_fold_long_sequences": [
      "self",
      "token_ids",
      "mask",
      "type_ids"
    ],
    "_unfold_long_sequences": [
      "self",
      "embeddings",
      "mask",
      "batch_size",
      "num_segment_concat_wordpieces"
    ]
  },
  "ConditionalRandomFieldWeightLannoy": {
    "__init__": [
      "self",
      "num_tags",
      "label_weights",
      "constraints",
      "include_start_end_transitions"
    ],
    "forward": [
      "self",
      "inputs",
      "tags",
      "mask"
    ],
    "_input_likelihood_lannoy": [
      "self",
      "logits",
      "tags",
      "mask"
    ],
    "_joint_likelihood_lannoy": [
      "self",
      "logits",
      "tags",
      "mask"
    ]
  },
  "ConditionalRandomFieldWeightEmission": {
    "__init__": [
      "self",
      "num_tags",
      "label_weights",
      "constraints",
      "include_start_end_transitions"
    ],
    "forward": [
      "self",
      "inputs",
      "tags",
      "mask"
    ]
  },
  "VITERBI_DECODING": [],
  "allowed_transitions": [
    "constraint_type",
    "labels"
  ],
  "is_transition_allowed": [
    "constraint_type",
    "from_tag",
    "from_entity",
    "to_tag",
    "to_entity"
  ],
  "ConditionalRandomField": {
    "__init__": [
      "self",
      "num_tags",
      "constraints",
      "include_start_end_transitions"
    ],
    "reset_parameters": [
      "self"
    ],
    "_input_likelihood": [
      "self",
      "logits",
      "transitions",
      "mask"
    ],
    "_joint_likelihood": [
      "self",
      "logits",
      "transitions",
      "tags",
      "mask"
    ],
    "forward": [
      "self",
      "inputs",
      "tags",
      "mask"
    ],
    "viterbi_tags": [
      "self",
      "logits",
      "mask",
      "top_k"
    ]
  },
  "ConditionalRandomFieldWeightTrans": {
    "__init__": [
      "self",
      "num_tags",
      "label_weights",
      "constraints",
      "include_start_end_transitions"
    ],
    "forward": [
      "self",
      "inputs",
      "tags",
      "mask"
    ]
  },
  "FeedForwardEncoder": {
    "__init__": [
      "self",
      "feedforward"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "is_bidirectional": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "mask"
    ]
  },
  "PassThroughEncoder": {
    "__init__": [
      "self",
      "input_dim"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "is_bidirectional": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "mask"
    ]
  },
  "ResidualBlock": {
    "__init__": [
      "self",
      "input_dim",
      "layers",
      "direction",
      "do_weight_norm",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GatedCnnEncoder": {
    "__init__": [
      "self",
      "input_dim",
      "layers",
      "dropout",
      "return_all_layers"
    ],
    "forward": [
      "self",
      "token_embeddings",
      "mask"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "is_bidirectional": [
      "self"
    ]
  },
  "PytorchTransformer": {
    "__init__": [
      "self",
      "input_dim",
      "num_layers",
      "feedforward_hidden_dim",
      "num_attention_heads",
      "positional_encoding",
      "positional_embedding_size",
      "dropout_prob",
      "activation"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "is_bidirectional": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "mask"
    ]
  },
  "Seq2SeqEncoder": {
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "is_bidirectional": [
      "self"
    ]
  },
  "PytorchSeq2SeqWrapper": {
    "__init__": [
      "self",
      "module",
      "stateful"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "is_bidirectional": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "mask",
      "hidden_state"
    ]
  },
  "GruSeq2SeqEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "bias",
      "dropout",
      "bidirectional",
      "stateful"
    ]
  },
  "LstmSeq2SeqEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "bias",
      "dropout",
      "bidirectional",
      "stateful"
    ]
  },
  "RnnSeq2SeqEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "nonlinearity",
      "bias",
      "dropout",
      "bidirectional",
      "stateful"
    ]
  },
  "AugmentedLstmSeq2SeqEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "go_forward",
      "recurrent_dropout_probability",
      "use_highway",
      "use_input_projection_bias",
      "stateful"
    ]
  },
  "StackedAlternatingLstmSeq2SeqEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "recurrent_dropout_probability",
      "use_highway",
      "use_input_projection_bias",
      "stateful"
    ]
  },
  "StackedBidirectionalLstmSeq2SeqEncoder": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "recurrent_dropout_probability",
      "layer_dropout_probability",
      "use_highway",
      "stateful"
    ]
  },
  "ComposeEncoder": {
    "__init__": [
      "self",
      "encoders"
    ],
    "forward": [
      "self",
      "inputs",
      "mask"
    ],
    "get_input_dim": [
      "self"
    ],
    "get_output_dim": [
      "self"
    ],
    "is_bidirectional": [
      "self"
    ]
  },
  "TextFieldEmbedder": {
    "default_implementation": [],
    "forward": [
      "self",
      "text_field_input",
      "num_wrapping_dims"
    ],
    "get_output_dim": [
      "self"
    ]
  },
  "BasicTextFieldEmbedder": {
    "__init__": [
      "self",
      "token_embedders"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "text_field_input",
      "num_wrapping_dims"
    ]
  },
  "BiModalAttention": {
    "__init__": [
      "self",
      "hidden_size1",
      "hidden_size2",
      "combined_hidden_size",
      "num_attention_heads",
      "dropout1",
      "dropout2",
      "scoring_func1",
      "scoring_func2"
    ],
    "_transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "input_tensor1",
      "input_tensor2",
      "attention_mask1",
      "attention_mask2",
      "co_attention_mask"
    ]
  },
  "SinusoidalPositionalEncoding": {
    "__init__": [
      "self",
      "min_timescale",
      "max_timescale"
    ],
    "forward": [
      "self",
      "input_tensor"
    ]
  },
  "AttentionOutput": {},
  "AttentionModule": {
    "__init__": [
      "self",
      "hidden_size",
      "attention_head_size",
      "num_attention_heads",
      "scoring_func",
      "output_linear",
      "dropout",
      "bias",
      "normalize_weights",
      "is_decoder",
      "is_cross_attention",
      "relative_attention_num_buckets"
    ],
    "_normalize": [
      "self"
    ],
    "_transpose_for_scores": [
      "self",
      "x"
    ],
    "_query_layer": [
      "self",
      "query_states"
    ],
    "_project": [
      "self",
      "hidden_states",
      "layer",
      "source_states",
      "past_key_or_value"
    ],
    "_position_bias": [
      "self",
      "position_bias",
      "seq_lengths",
      "past_key_states",
      "attention_scores"
    ],
    "_get_attention_probs": [
      "self",
      "query_layer",
      "key_layer",
      "attention_mask",
      "head_mask",
      "seq_lengths",
      "position_bias",
      "past_key_states"
    ],
    "_output_layer": [
      "self",
      "attention_probs",
      "value_layer"
    ],
    "_get_lengths": [
      "self",
      "query_states",
      "past_key_states",
      "source_states",
      "query_length"
    ],
    "forward": [
      "self",
      "query_states",
      "past_key_states",
      "past_value_states",
      "attention_mask",
      "source_states",
      "source_attention_mask",
      "head_mask",
      "position_bias",
      "output_attentions",
      "use_cache",
      "query_length"
    ],
    "_relative_position_bucket": [
      "relative_position",
      "bidirectional",
      "num_buckets",
      "max_distance"
    ],
    "compute_bias": [
      "self",
      "query_length",
      "key_length"
    ]
  },
  "T5Attention": {
    "_pretrained_relevant_module": [],
    "_pretrained_mapping": [],
    "__init__": [
      "self",
      "is_decoder",
      "hidden_size",
      "key_value_proj_dim",
      "num_heads",
      "has_relative_attention_bias",
      "relative_attention_num_buckets",
      "dropout",
      "normalize",
      "is_cross_attention"
    ],
    "forward": [
      "self",
      "hidden_states",
      "mask",
      "key_value_states",
      "position_bias",
      "past_key_value",
      "layer_head_mask",
      "query_length",
      "use_cache",
      "output_attentions"
    ],
    "_from_config": [
      "cls",
      "config"
    ]
  },
  "SelfAttention": {
    "_pretrained_relevant_module": [],
    "_pretrained_mapping": [],
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "dropout",
      "scoring_func",
      "output_linear",
      "is_decoder",
      "is_cross_attention"
    ],
    "_from_config": [
      "cls",
      "config"
    ]
  },
  "AttentionLayer": {
    "_pretrained_relevant_module": [],
    "_pretrained_mapping": [],
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "attention_dropout",
      "hidden_dropout",
      "is_cross_attention",
      "is_decoder"
    ],
    "forward": [
      "self",
      "input_tensor",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "output_attentions"
    ],
    "_from_config": [
      "cls",
      "config"
    ]
  },
  "TransformerLayerOutput": {},
  "TransformerLayer": {
    "_pretrained_relevant_module": [],
    "_pretrained_mapping": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "num_attention_heads",
      "attention_dropout",
      "hidden_dropout",
      "activation",
      "add_cross_attention"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "output_attentions"
    ],
    "_from_config": [
      "cls",
      "config"
    ]
  },
  "TransformerStackOutput": {},
  "TransformerStack": {
    "_pretrained_mapping": [],
    "_pretrained_relevant_module": [],
    "__init__": [
      "self",
      "num_hidden_layers",
      "layer",
      "hidden_size",
      "intermediate_size",
      "num_attention_heads",
      "attention_dropout",
      "hidden_dropout",
      "activation",
      "add_cross_attention"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "head_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "output_attentions",
      "output_hidden_states"
    ],
    "_from_config": [
      "cls",
      "config"
    ]
  },
  "BiModalOutput": {
    "__init__": [
      "self",
      "hidden_size1",
      "hidden_size2",
      "combined_hidden_size",
      "dropout1",
      "dropout2"
    ],
    "forward": [
      "self",
      "hidden_states1",
      "input_tensor1",
      "hidden_states2",
      "input_tensor2"
    ]
  },
  "BiModalConnectionLayer": {
    "_pretrained_mapping": [],
    "__init__": [
      "self",
      "hidden_size1",
      "hidden_size2",
      "combined_hidden_size",
      "intermediate_size1",
      "intermediate_size2",
      "num_attention_heads",
      "dropout1",
      "dropout2",
      "activation"
    ],
    "forward": [
      "self",
      "input_tensor1",
      "attention_mask1",
      "input_tensor2",
      "attention_mask2",
      "co_attention_mask"
    ]
  },
  "TransformerPooler": {
    "_pretrained_relevant_module": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "activation"
    ],
    "_from_config": [
      "cls",
      "config"
    ]
  },
  "ActivationLayer": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "activation",
      "pool"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "FloatT": [],
  "IntT": [],
  "BoolT": [],
  "apply_mask": [
    "values",
    "mask"
  ],
  "get_extended_attention_mask": [
    "attention_mask",
    "input_shape",
    "dtype",
    "is_decoder"
  ],
  "OutputLayer": {
    "_pretrained_mapping": [],
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "dropout"
    ],
    "get_output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "Embeddings": {
    "__init__": [
      "self",
      "embeddings",
      "embedding_size",
      "dropout",
      "layer_norm_eps"
    ],
    "forward": [
      "self"
    ]
  },
  "ImageFeatureEmbeddings": {
    "__init__": [
      "self",
      "feature_size",
      "embedding_size",
      "dropout"
    ]
  },
  "TransformerEmbeddings": {
    "_pretrained_relevant_module": [],
    "_pretrained_mapping": [],
    "_pretrained_ignore": [],
    "__init__": [
      "self",
      "vocab_size",
      "embedding_size",
      "pad_token_id",
      "max_position_embeddings",
      "position_pad_token_id",
      "type_vocab_size",
      "dropout",
      "layer_norm_eps",
      "output_size"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "position_ids",
      "attention_mask"
    ],
    "_from_config": [
      "cls",
      "config"
    ]
  },
  "TransformerModule": {
    "_get_mapping": [
      "cls",
      "mapping"
    ],
    "_get_mapped_state_dict": [
      "self",
      "state_dict",
      "mapping"
    ],
    "_get_relevant_submodule_state": [
      "cls",
      "state_dict",
      "relevant_module"
    ],
    "_get_pretrained_state_dict": [
      "cls",
      "model_name",
      "weights_path",
      "relevant_module",
      "ignore"
    ],
    "_from_config": [
      "cls",
      "config"
    ],
    "from_pretrained_module": [
      "cls",
      "model_name"
    ]
  },
  "_get_mapped_state_dict": [
    "module",
    "state_dict",
    "mapping"
  ],
  "T5LayerNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5FeedForwardProjection": {
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5DenseReluDense": {
    "__init__": [
      "self",
      "hidden_size",
      "ff_size",
      "dropout"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5DenseGatedGeluDense": {
    "__init__": [
      "self",
      "hidden_size",
      "ff_size",
      "dropout"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5LayerFF": {
    "_pretrained_mapping": [],
    "__init__": [
      "self",
      "ff_proj",
      "layer_norm",
      "dropout"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5LayerSelfAttentionOutput": {},
  "T5LayerSelfAttention": {
    "_pretrained_mapping": [],
    "__init__": [
      "self",
      "self_attention",
      "layer_norm",
      "dropout",
      "has_relative_attention_bias"
    ],
    "hidden_size": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias",
      "layer_head_mask",
      "past_key_value",
      "use_cache",
      "output_attentions"
    ]
  },
  "T5LayerCrossAttentionOutput": {},
  "T5LayerCrossAttention": {
    "_pretrained_mapping": [],
    "__init__": [
      "self",
      "enc_dec_attention",
      "layer_norm",
      "dropout"
    ],
    "forward": [
      "self",
      "hidden_states",
      "key_value_states",
      "attention_mask",
      "position_bias",
      "layer_head_mask",
      "past_key_value",
      "use_cache",
      "query_length",
      "output_attentions"
    ]
  },
  "KeyValueStates": [],
  "T5BlockOutput": {},
  "T5Block": {
    "__init__": [
      "self",
      "attention",
      "cross_attention",
      "ff"
    ],
    "hidden_size": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_bias",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "encoder_decoder_position_bias",
      "layer_head_mask",
      "encoder_layer_head_mask",
      "past_key_value",
      "use_cache",
      "output_attentions"
    ]
  },
  "T5StackOutput": {},
  "T5Stack": {
    "_pretrained_mapping": [],
    "__init__": [
      "self",
      "token_embeddings",
      "blocks",
      "final_layer_norm",
      "dropout"
    ],
    "num_blocks": [
      "self"
    ],
    "hidden_size": [
      "self"
    ],
    "get_head_mask": [
      "head_mask",
      "num_hidden_layers"
    ],
    "resize_token_embeddings": [
      "self",
      "new_size"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "inputs_embeds",
      "head_mask",
      "encoder_head_mask",
      "past_key_values",
      "use_cache",
      "output_attentions",
      "output_all_hidden_states"
    ]
  },
  "T5EncoderStack": {
    "__init__": [
      "self",
      "token_embeddings",
      "blocks",
      "final_layer_norm",
      "dropout"
    ],
    "basic_encoder": [
      "cls",
      "token_embeddings",
      "num_blocks",
      "block_self_attention",
      "final_layer_norm",
      "block_ff",
      "dropout",
      "ddp_accelerator",
      "checkpoint_wrapper"
    ]
  },
  "T5DecoderStack": {
    "__init__": [
      "self",
      "token_embeddings",
      "blocks",
      "final_layer_norm",
      "dropout"
    ],
    "basic_decoder": [
      "cls",
      "token_embeddings",
      "num_blocks",
      "block_self_attention",
      "block_cross_attention",
      "final_layer_norm",
      "block_ff",
      "dropout",
      "ddp_accelerator",
      "checkpoint_wrapper"
    ]
  },
  "T5Output": {},
  "T5": {
    "_pretrained_mapping": [],
    "_pretrained_ignore": [],
    "default_implementation": [],
    "__init__": [
      "self",
      "token_embeddings",
      "encoder",
      "decoder",
      "decoder_start_token_id",
      "pad_token_id",
      "eos_token_id",
      "vocab_size",
      "model_dim",
      "output_attentions",
      "output_all_hidden_states",
      "beam_search",
      "ddp_accelerator",
      "checkpoint_wrapper",
      "tie_word_embeddings"
    ],
    "resize_token_embeddings": [
      "self",
      "new_size"
    ],
    "_post_load_state_dict": [
      "self",
      "missing_keys",
      "unexpected_keys"
    ],
    "_from_config": [
      "cls",
      "config"
    ],
    "_shift_right": [
      "self",
      "input_ids",
      "start_value"
    ],
    "_get_lm_logits": [
      "self",
      "decoder_last_hidden_state"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "labels",
      "decoder_attention_mask"
    ],
    "take_search_step": [
      "self",
      "last_predictions",
      "state",
      "step"
    ],
    "_decoder_cache_to_dict": [
      "decoder_cache"
    ],
    "_dict_to_decoder_cache": [
      "self",
      "cache_dict"
    ]
  },
  "BiModalEncoder": {
    "_pretrained_mapping": [],
    "_pretrained_relevant_module": [],
    "_pretrained_allow_missing": [],
    "__init__": [
      "self",
      "num_hidden_layers1",
      "num_hidden_layers2",
      "hidden_size1",
      "hidden_size2",
      "combined_hidden_size",
      "intermediate_size1",
      "intermediate_size2",
      "num_attention_heads1",
      "num_attention_heads2",
      "combined_num_attention_heads",
      "attention_dropout1",
      "hidden_dropout1",
      "attention_dropout2",
      "hidden_dropout2",
      "activation",
      "biattention_id1",
      "biattention_id2",
      "fixed_layer1",
      "fixed_layer2",
      "fast_mode",
      "with_coattention",
      "in_batch_pairs"
    ],
    "forward": [
      "self",
      "embedding1",
      "embedding2",
      "attention_mask1",
      "attention_mask2",
      "co_attention_mask",
      "output_all_encoded_layers"
    ],
    "_from_config": [
      "cls",
      "config"
    ]
  },
  "Image2ImageModule": {
    "forward": [
      "self",
      "images",
      "sizes"
    ]
  },
  "NormalizeImage": {
    "__init__": [
      "self",
      "means",
      "stds"
    ],
    "forward": [
      "self",
      "images",
      "sizes"
    ]
  },
  "RegionDetectorOutput": {},
  "RegionDetector": {
    "forward": [
      "self",
      "images",
      "sizes",
      "image_features"
    ]
  },
  "RandomRegionDetector": {
    "__init__": [
      "self",
      "seed"
    ],
    "_seeded_random_tensor": [
      "self"
    ],
    "forward": [
      "self",
      "images",
      "sizes",
      "image_features"
    ]
  },
  "FasterRcnnRegionDetector": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "images",
      "sizes",
      "image_features"
    ],
    "_postprocess_detections": [
      "self",
      "class_logits",
      "box_features",
      "box_regression",
      "proposals",
      "image_shapes"
    ]
  },
  "GridEmbedder": {
    "forward": [
      "self",
      "images",
      "sizes"
    ],
    "get_feature_names": [
      "self"
    ]
  },
  "NullGridEmbedder": {
    "forward": [
      "self",
      "images",
      "sizes"
    ],
    "get_feature_names": [
      "self"
    ]
  },
  "ResnetBackbone": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "images",
      "sizes"
    ],
    "get_feature_names": [
      "self"
    ]
  },
  "AdditiveAttention": {
    "__init__": [
      "self",
      "vector_dim",
      "matrix_dim",
      "normalize"
    ],
    "reset_parameters": [
      "self"
    ],
    "_forward_internal": [
      "self",
      "vector",
      "matrix"
    ]
  },
  "CosineAttention": {
    "_forward_internal": [
      "self",
      "vector",
      "matrix"
    ]
  },
  "Attention": {
    "__init__": [
      "self",
      "normalize"
    ],
    "forward": [
      "self",
      "vector",
      "matrix",
      "matrix_mask"
    ],
    "_forward_internal": [
      "self",
      "vector",
      "matrix"
    ]
  },
  "LinearAttention": {
    "__init__": [
      "self",
      "tensor_1_dim",
      "tensor_2_dim",
      "combination",
      "activation",
      "normalize"
    ],
    "reset_parameters": [
      "self"
    ],
    "_forward_internal": [
      "self",
      "vector",
      "matrix"
    ]
  },
  "DotProductAttention": {
    "_forward_internal": [
      "self",
      "vector",
      "matrix"
    ]
  },
  "ScaledDotProductAttention": {
    "__init__": [
      "self",
      "scaling_factor",
      "normalize"
    ],
    "_forward_internal": [
      "self",
      "vector",
      "matrix"
    ]
  },
  "BilinearAttention": {
    "__init__": [
      "self",
      "vector_dim",
      "matrix_dim",
      "activation",
      "normalize"
    ],
    "reset_parameters": [
      "self"
    ],
    "_forward_internal": [
      "self",
      "vector",
      "matrix"
    ]
  }
}