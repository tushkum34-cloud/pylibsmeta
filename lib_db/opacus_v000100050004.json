{
  "run_layer_benchmark": [
    "num_repeats",
    "forward_only",
    "gsm_mode",
    "create_layer"
  ],
  "main": [
    "args"
  ],
  "Memory": [],
  "reset_peak_memory_stats": [
    "device"
  ],
  "get_layer_set": [
    "layer"
  ],
  "get_path": [
    "layer",
    "batch_size",
    "num_runs",
    "num_repeats",
    "gsm_mode",
    "random_seed",
    "forward_only",
    "root",
    "suffix"
  ],
  "save_results": [
    "layer",
    "batch_size",
    "num_runs",
    "num_repeats",
    "gsm_mode",
    "results",
    "config",
    "random_seed",
    "forward_only",
    "root",
    "suffix"
  ],
  "generate_report": [
    "path_to_results",
    "save_path",
    "format"
  ],
  "LayerType": {},
  "Layer": {
    "__init__": [
      "self"
    ],
    "_get_memory_difference": [
      "device",
      "stats"
    ],
    "_inputs_to": [
      "self",
      "device",
      "stats"
    ],
    "to": [
      "self",
      "device"
    ],
    "forward_only": [
      "self"
    ],
    "forward_backward": [
      "self"
    ],
    "make_private": [
      "self",
      "gsm_mode"
    ],
    "module": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "LinearBase": {
    "__init__": [
      "self"
    ]
  },
  "ConvBase": {
    "__init__": [
      "self"
    ]
  },
  "LayerNormBase": {
    "__init__": [
      "self"
    ]
  },
  "InstanceNormBase": {
    "__init__": [
      "self"
    ]
  },
  "GroupNormBase": {
    "__init__": [
      "self"
    ]
  },
  "EmbeddingBase": {
    "__init__": [
      "self"
    ]
  },
  "MHABase": {
    "__init__": [
      "self"
    ],
    "_inputs_to": [
      "self",
      "device",
      "stats"
    ],
    "forward_only": [
      "self"
    ]
  },
  "RNNBase": {
    "__init__": [
      "self"
    ],
    "_inputs_to": [
      "self",
      "device",
      "stats"
    ],
    "forward_only": [
      "self"
    ]
  },
  "LSTMBase": {
    "__init__": [
      "self"
    ],
    "_inputs_to": [
      "self",
      "device",
      "stats"
    ],
    "forward_only": [
      "self"
    ]
  },
  "LayerFactory": {
    "create": [
      "layer_name",
      "gsm_mode"
    ]
  },
  "logger": [],
  "run_and_save_benchmark": [
    "layer",
    "batch_size",
    "gsm_mode",
    "args",
    "layer_config",
    "root",
    "suffix"
  ],
  "__version__": [],
  "average_gradients": [
    "model"
  ],
  "DifferentiallyPrivateDistributedDataParallel": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self"
    ]
  },
  "PrivacyEngine": {
    "__init__": [
      "self"
    ],
    "_prepare_optimizer": [
      "self"
    ],
    "_prepare_data_loader": [
      "self",
      "data_loader"
    ],
    "_prepare_model": [
      "self",
      "module"
    ],
    "_prepare_criterion": [
      "self"
    ],
    "is_compatible": [
      "self"
    ],
    "validate": [
      "self"
    ],
    "get_compatible_module": [
      "cls",
      "module"
    ],
    "make_private": [
      "self"
    ],
    "make_private_with_epsilon": [
      "self"
    ],
    "get_epsilon": [
      "self",
      "delta"
    ],
    "save_checkpoint": [
      "self"
    ],
    "load_checkpoint": [
      "self"
    ]
  },
  "collate": [
    "batch"
  ],
  "wrap_collate_with_empty": [],
  "shape_safe": [
    "x"
  ],
  "dtype_safe": [
    "x"
  ],
  "DPDataLoader": {
    "__init__": [
      "self",
      "dataset"
    ],
    "from_data_loader": [
      "cls",
      "data_loader"
    ]
  },
  "_is_supported_batch_sampler": [
    "sampler"
  ],
  "switch_generator": [],
  "DPLightningDataModule": {
    "__init__": [
      "self",
      "datamodule",
      "generator"
    ],
    "prepare_data": [
      "self"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "test_dataloader": [
      "self"
    ],
    "predict_dataloader": [
      "self"
    ],
    "transfer_batch_to_device": [
      "self",
      "batch",
      "device",
      "dataloader_idx"
    ],
    "on_before_batch_transfer": [
      "self",
      "batch",
      "dataloader_idx"
    ],
    "on_after_batch_transfer": [
      "self",
      "batch",
      "dataloader_idx"
    ]
  },
  "__all__": [],
  "PoissonSamplingTest": {
    "_init_data": [
      "self",
      "seed"
    ],
    "setUp": [
      "self"
    ],
    "test_length": [
      "self"
    ],
    "test_batch_sizes": [
      "self"
    ],
    "test_same_seed": [
      "self"
    ],
    "test_different_seed": [
      "self"
    ]
  },
  "SampleConvNet": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "name": [
      "self"
    ]
  },
  "GradSampleModuleTest": {
    "CLS": [],
    "setUp": [
      "self"
    ],
    "setUp_data": [
      "self"
    ],
    "test_outputs_unaltered": [
      "self"
    ],
    "test_zero_grad": [
      "self"
    ],
    "test_to_standard_module": [
      "self"
    ],
    "test_remove_hooks": [
      "self"
    ],
    "test_enable_hooks": [
      "self"
    ],
    "test_disable_hooks": [
      "self"
    ],
    "test_standard_module_validation": [
      "self"
    ],
    "test_custom_module_validation": [
      "self"
    ],
    "test_submodule_access": [
      "self"
    ],
    "test_state_dict": [
      "self"
    ],
    "test_load_state_dict": [
      "self"
    ]
  },
  "EWGradSampleModuleTest": {
    "CLS": [],
    "test_remove_hooks": [
      "self"
    ],
    "test_enable_hooks": [
      "self"
    ],
    "test_disable_hooks": [
      "self"
    ]
  },
  "GradientAccumulationTest": {
    "setUp": [
      "self"
    ],
    "setUp_data": [
      "self"
    ],
    "setUp_model_and_optimizer": [
      "self"
    ],
    "model_forward_backward": [
      "self",
      "model",
      "data_iter",
      "optimizer",
      "num_steps",
      "do_zero_grad"
    ],
    "test_grad_sample_accumulation": [
      "self"
    ],
    "test_privacy_engine_poisson_accumulation": [
      "self"
    ],
    "test_privacy_engine_no_poisson_accumulation": [
      "self"
    ],
    "test_privacy_engine_zero_grad": [
      "self"
    ],
    "test_batch_splitter_zero_grad": [
      "self"
    ]
  },
  "GradientAccumulationTestFunctorch": {
    "setUp": [
      "self"
    ]
  },
  "PrivacyEngineValidationTest": {
    "setUp": [
      "self"
    ],
    "_init": [
      "self",
      "module",
      "size",
      "batch_size"
    ],
    "test_supported_hooks": [
      "self"
    ],
    "test_supported_ew": [
      "self"
    ],
    "test_custom_linear_hooks": [
      "self"
    ],
    "test_custom_linear_ew": [
      "self"
    ],
    "test_unsupported_hooks": [
      "self"
    ],
    "test_unsupported_ew": [
      "self"
    ],
    "test_extra_param_hooks_requires_grad": [
      "self"
    ],
    "test_extra_param_hooks_no_requires_grad": [
      "self"
    ],
    "test_extra_param_ew": [
      "self"
    ],
    "test_extra_param_disabled_ew": [
      "self"
    ]
  },
  "BasicSupportedModule": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CustomLinearModule": {
    "__init__": [
      "self",
      "in_features",
      "out_features"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MatmulModule": {
    "__init__": [
      "self",
      "input_features",
      "output_features"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LinearWithExtraParam": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "hidden_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_epoch": [
    "model",
    "optim",
    "dl"
  ],
  "_read_all": [
    "dl"
  ],
  "TensorCompareTestCase": {
    "assertNotEqualTensors": [
      "self",
      "a",
      "b"
    ],
    "assertEqualTensors": [
      "self",
      "a",
      "b"
    ]
  },
  "DataLoaderRandomnessTest": {
    "setUp": [
      "self"
    ],
    "_read_all_dp": [
      "self",
      "dp_generator",
      "original_generator"
    ],
    "test_no_seed": [
      "self"
    ],
    "test_global_seed": [
      "self"
    ],
    "test_custom_generator": [
      "self"
    ],
    "test_custom_generator_with_global_seed": [
      "self"
    ],
    "test_original_generator": [
      "self"
    ],
    "test_custom_generator_overrides_original": [
      "self"
    ]
  },
  "DataLoaderSwitchRandomnessTest": {
    "setUp": [
      "self"
    ],
    "_read_all_simple": [
      "self",
      "orig_generator",
      "shuffle"
    ],
    "_read_all_switch": [
      "self",
      "orig_generator",
      "new_generator",
      "shuffle"
    ],
    "test_consistent": [
      "self"
    ],
    "test_basic_switch": [
      "self"
    ],
    "test_switch_same_seed": [
      "self"
    ],
    "test_raise_sequential": [
      "self"
    ]
  },
  "OptimizerRandomnessTest": {
    "setUp": [
      "self"
    ],
    "_init_training": [
      "self",
      "generator",
      "noise"
    ],
    "test_no_seed": [
      "self"
    ],
    "test_no_noise": [
      "self"
    ],
    "test_global_seed": [
      "self"
    ],
    "test_generator": [
      "self"
    ],
    "test_generator_with_global_seed": [
      "self"
    ],
    "test_generator_seed": [
      "self"
    ]
  },
  "_init_generator": [
    "seed"
  ],
  "PrivacyEngineSecureModeTest": {
    "setUp": [
      "self"
    ],
    "_init_training": [
      "self",
      "dl_generator"
    ],
    "_init_dp_training": [
      "self",
      "secure_mode",
      "dl_seed",
      "noise_seed",
      "noise",
      "poisson_sampling"
    ],
    "test_basic": [
      "self"
    ],
    "test_raise_secure_mode": [
      "self"
    ],
    "test_global_seed": [
      "self"
    ],
    "test_secure_mode_global_seed": [
      "self"
    ],
    "test_dl_seed_with_noise": [
      "self"
    ],
    "test_dl_seed_no_noise": [
      "self"
    ],
    "test_seed": [
      "self"
    ],
    "test_custom_and_global_seed": [
      "self"
    ],
    "test_data_seed_consistency": [
      "self"
    ],
    "test_secure_mode_no_poisson": [
      "self"
    ]
  },
  "get_grad_sample_aggregated": [
    "tensor",
    "loss_type"
  ],
  "BasePrivacyEngineTest": {
    "setUp": [
      "self"
    ],
    "_init_data": [
      "self"
    ],
    "_init_model": [
      "self"
    ],
    "_init_vanilla_training": [
      "self",
      "state_dict",
      "opt_exclude_frozen"
    ],
    "_init_private_training": [
      "self",
      "state_dict",
      "secure_mode",
      "noise_multiplier",
      "max_grad_norm",
      "poisson_sampling",
      "clipping",
      "grad_sample_mode",
      "opt_exclude_frozen"
    ],
    "_train_steps": [
      "self",
      "model",
      "optimizer",
      "dl",
      "max_steps"
    ],
    "_train_steps_with_closure": [
      "self",
      "model",
      "optimizer",
      "dl",
      "max_steps"
    ],
    "test_basic": [
      "self"
    ],
    "_compare_to_vanilla": [
      "self",
      "do_noise",
      "do_clip",
      "expected_match",
      "grad_sample_mode",
      "use_closure",
      "max_steps"
    ],
    "test_compare_to_vanilla": [
      "self",
      "do_clip",
      "do_noise",
      "use_closure",
      "max_steps"
    ],
    "test_flat_clipping": [
      "self"
    ],
    "test_per_layer_clipping": [
      "self"
    ],
    "test_sample_grad_aggregation": [
      "self"
    ],
    "test_noise_changes_every_time": [
      "self"
    ],
    "test_get_compatible_module_inaction": [
      "self"
    ],
    "test_model_validator": [
      "self"
    ],
    "test_model_validator_after_fix": [
      "self"
    ],
    "test_make_private_with_epsilon": [
      "self"
    ],
    "test_deterministic_run": [
      "self"
    ],
    "test_validator_weight_update_check": [
      "self"
    ],
    "test_parameters_match": [
      "self"
    ],
    "test_checkpoints": [
      "self",
      "has_noise_scheduler",
      "has_grad_clip_scheduler"
    ],
    "test_noise_level": [
      "self",
      "noise_multiplier",
      "max_steps",
      "secure_mode"
    ],
    "test_generate_noise_in_secure_mode": [
      "self"
    ]
  },
  "PrivacyEngineConvNetTest": {
    "_init_data": [
      "self"
    ],
    "_init_model": [
      "self"
    ]
  },
  "PrivacyEngineConvNetEmptyBatchTest": {
    "setUp": [
      "self"
    ],
    "test_checkpoints": [
      "self"
    ],
    "test_noise_level": [
      "self"
    ]
  },
  "PrivacyEngineConvNetFrozenTest": {
    "_init_data": [
      "self"
    ],
    "_init_model": [
      "self"
    ]
  },
  "PrivacyEngineConvNetFrozenTestFunctorch": {
    "setUp": [
      "self"
    ]
  },
  "PrivacyEngineConvNetTestExpandedWeights": {
    "setUp": [
      "self"
    ],
    "test_sample_grad_aggregation": [
      "self"
    ]
  },
  "PrivacyEngineConvNetTestFunctorch": {
    "setUp": [
      "self"
    ]
  },
  "SampleAttnNet": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MockTextDataset": {
    "__init__": [
      "self",
      "x",
      "y",
      "batch_first"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "batch_second_collate": [
    "batch"
  ],
  "PrivacyEngineTextTest": {
    "setUp": [
      "self"
    ],
    "_init_data": [
      "self"
    ],
    "_init_model": [
      "self",
      "private",
      "state_dict",
      "model"
    ]
  },
  "PrivacyEngineTextTestFunctorch": {
    "setUp": [
      "self"
    ]
  },
  "SampleTiedWeights": {
    "__init__": [
      "self",
      "tie"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PrivacyEngineTiedWeightsTest": {
    "setUp": [
      "self"
    ],
    "_init_data": [
      "self"
    ],
    "_init_model": [
      "self"
    ]
  },
  "PrivacyEngineTiedWeightsTestFunctorch": {
    "setUp": [
      "self"
    ]
  },
  "ModelWithCustomLinear": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PrivacyEngineCustomLayerTest": {
    "_init_data": [
      "self"
    ],
    "_init_model": [
      "self"
    ]
  },
  "PRIVACY_ALPHAS": [],
  "setup_and_get_device": [
    "rank",
    "world_size",
    "nonce"
  ],
  "cleanup": [],
  "ToyModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "demo_basic": [
    "rank",
    "world_size",
    "weight",
    "dp",
    "noise_multiplier",
    "max_grad_norm"
  ],
  "demo_ddp_hook": [
    "rank",
    "world_size",
    "weight",
    "dp",
    "noise_multiplier",
    "max_grad_norm"
  ],
  "add_remove_ddp_hooks": [
    "rank",
    "world_size",
    "remaining_hooks",
    "dp",
    "noise_multiplier",
    "max_grad_norm"
  ],
  "debug": [
    "rank",
    "world_size",
    "tensor",
    "dp",
    "noise_multiplier",
    "max_grad_norm"
  ],
  "run_function": [
    "local_function",
    "tensor",
    "dp",
    "noise_multiplier",
    "max_grad_norm"
  ],
  "GradientComputationTest": {
    "test_connection": [
      "self"
    ],
    "test_gradient_noclip_zeronoise": [
      "self"
    ],
    "test_ddp_hook": [
      "self"
    ],
    "test_add_remove_ddp_hooks": [
      "self"
    ]
  },
  "setup": [
    "rank",
    "world_size"
  ],
  "run_ghost_clipping_test": [
    "model",
    "optimizer",
    "data_loader",
    "batch_size",
    "max_grad_norm",
    "weight",
    "rank"
  ],
  "run_demo": [
    "demo_fn",
    "weight",
    "world_size",
    "dp",
    "clipping",
    "grad_sample_mode"
  ],
  "DPDataLoaderTest": {
    "setUp": [
      "self"
    ],
    "test_collate_classes": [
      "self"
    ],
    "test_collate_tensor": [
      "self"
    ],
    "test_drop_last_true": [
      "self"
    ]
  },
  "GradientComputationTestAdaptiveClipping": {
    "test_gradient_correct_adaptive": [
      "self"
    ]
  },
  "PerSampleGradientsUtilsTest": {
    "per_sample_grads_utils_test": [
      "self",
      "x",
      "model",
      "grad_sample_mode",
      "is_empty",
      "atol",
      "rtol"
    ],
    "test_conv1d": [
      "self",
      "N",
      "C",
      "W",
      "out_channels_mapper",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "grad_sample_mode"
    ],
    "test_linear": [
      "self",
      "N",
      "Z",
      "H",
      "W",
      "input_dim",
      "bias",
      "batch_first",
      "grad_sample_mode"
    ]
  },
  "SyntheticDataset": {
    "__init__": [
      "self",
      "size",
      "length",
      "dim"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "SampleModule": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SampleEmbeddingModule": {
    "__init__": [
      "self",
      "vocab_size",
      "embedding_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GradSampleModuleFastGradientClippingTest": {
    "CLS": [],
    "setUp": [
      "self"
    ],
    "setUp_data_sequantial": [
      "self",
      "size",
      "length",
      "dim"
    ],
    "test_norm_calculation_fast_gradient_clipping": [
      "self",
      "size",
      "length",
      "dim"
    ],
    "test_gradient_calculation_fast_gradient_clipping": [
      "self",
      "size",
      "length",
      "dim"
    ]
  },
  "GradSampleModuleFastGradientClippingEmbeddingLayerTest": {
    "test_norm_calculation": [
      "self"
    ],
    "test_gradient_calculation": [
      "self"
    ]
  },
  "ModuleValidator_test": {
    "setUp": [
      "self"
    ],
    "test_is_valid": [
      "self"
    ],
    "test_validate_invalid_model": [
      "self"
    ],
    "test_validate_valid_model": [
      "self"
    ],
    "test_validate_training_mode": [
      "self"
    ],
    "test_is_valid_unsupported_grdsample_module": [
      "self"
    ],
    "test_is_valid_extra_param": [
      "self"
    ],
    "test_fix": [
      "self"
    ],
    "test_fix_device": [
      "self"
    ],
    "test_fix_w_replace_bn_with_in": [
      "self"
    ],
    "test_is_valid_non_learnable_bn": [
      "self"
    ],
    "test_fix_bn_with_args": [
      "self"
    ]
  },
  "msr_values": [],
  "PRVAccountantTest": {
    "test_values": [
      "self"
    ]
  },
  "AccountingTest": {
    "test_rdp_accountant": [
      "self"
    ],
    "test_gdp_accountant": [
      "self"
    ],
    "test_prv_accountant": [
      "self"
    ],
    "test_get_noise_multiplier_rdp_epochs": [
      "self"
    ],
    "test_get_noise_multiplier_rdp_steps": [
      "self"
    ],
    "test_get_noise_multiplier_prv_epochs": [
      "self"
    ],
    "test_get_noise_multiplier_prv_steps": [
      "self"
    ],
    "test_get_noise_multiplier_overshoot": [
      "self",
      "epsilon",
      "epochs",
      "sample_rate",
      "delta"
    ],
    "test_get_noise_multiplier_gdp": [
      "self"
    ],
    "test_accountant_state_dict": [
      "self"
    ],
    "test_accountant_load_state_dict": [
      "self"
    ]
  },
  "Model": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BatchMemoryManagerTest": {
    "GSM_MODE": [],
    "setUp": [
      "self"
    ],
    "_init_training": [
      "self",
      "batch_size"
    ],
    "test_basic": [
      "self",
      "num_workers",
      "pin_memory",
      "batch_size",
      "max_physical_batch_size"
    ],
    "test_empty_batch": [
      "self",
      "num_workers",
      "pin_memory"
    ],
    "test_equivalent_to_one_batch": [
      "self"
    ]
  },
  "BatchMemoryManagerTestWithExpandedWeights": {
    "GSM_MODE": [],
    "test_empty_batch": [
      "self"
    ]
  },
  "BatchMemoryManagerTestWithFunctorch": {
    "GSM_MODE": []
  },
  "BatchNormValidator_test": {
    "setUp": [
      "self"
    ],
    "test_validate": [
      "self"
    ],
    "test_fix": [
      "self"
    ]
  },
  "InstanceNormValidator_test": {
    "setUp": [
      "self"
    ],
    "test_validate": [
      "self"
    ],
    "test_fix": [
      "self"
    ]
  },
  "MultiheadAttentionValidator_test": {
    "setUp": [
      "self"
    ],
    "test_validate": [
      "self"
    ],
    "test_fix": [
      "self"
    ]
  },
  "LSTMValidator_test": {
    "setUp": [
      "self"
    ],
    "test_validate": [
      "self"
    ],
    "test_fix": [
      "self"
    ]
  },
  "GradClipSchedulerTest": {
    "setUp": [
      "self"
    ],
    "test_exponential_scheduler": [
      "self"
    ],
    "test_step_scheduler": [
      "self"
    ],
    "test_lambda_scheduler": [
      "self"
    ]
  },
  "NoiseSchedulerTest": {
    "setUp": [
      "self"
    ],
    "test_exponential_scheduler": [
      "self"
    ],
    "test_step_scheduler": [
      "self"
    ],
    "test_lambda_scheduler": [
      "self"
    ]
  },
  "clone_module": [
    "module"
  ],
  "flatten": [
    "seq"
  ],
  "default_train_fn": [
    "model",
    "x"
  ],
  "DPModules_test": {
    "compare_forward_outputs": [
      "self",
      "nn_module",
      "dp_module"
    ],
    "compare_gradients": [
      "self",
      "nn_module",
      "dp_module",
      "train_fn"
    ],
    "_check_shapes": [
      "self",
      "nn_outs",
      "dp_outs",
      "output_names"
    ],
    "_check_values": [
      "self",
      "nn_outs",
      "dp_outs",
      "atol",
      "rtol",
      "output_names",
      "batch_first_nn",
      "batch_first_dp"
    ],
    "_check_packed_sequence": [
      "self",
      "name",
      "nn_out",
      "dp_out",
      "batch_first_nn",
      "batch_first_dp",
      "atol",
      "rtol",
      "failure_msgs"
    ]
  },
  "remove_in_proj_bias_hook": [
    "self",
    "state_dict",
    "prefix",
    "local_metadata"
  ],
  "attn_train_fn": [
    "model"
  ],
  "DPMultiheadAttention_test": {
    "test_attn": [
      "self",
      "batch_size",
      "src_seq_len",
      "tgt_seq_len",
      "num_heads",
      "bias",
      "add_bias_kv",
      "add_zero_attn",
      "kdim",
      "vdim"
    ],
    "test_dp_attn": [
      "self",
      "batch_size",
      "src_seq_len",
      "tgt_seq_len",
      "num_heads",
      "bias",
      "add_bias_kv",
      "add_zero_attn",
      "kdim",
      "vdim"
    ],
    "test_dp_attn_hook": [
      "self",
      "batch_size",
      "src_seq_len",
      "tgt_seq_len",
      "num_heads",
      "bias",
      "add_bias_kv",
      "add_zero_attn",
      "kdim",
      "vdim"
    ]
  },
  "rnn_train_fn": [
    "model",
    "x",
    "state_init"
  ],
  "DPLSTM_test": {
    "test_rnn": [
      "self",
      "mode",
      "batch_size",
      "seq_len",
      "emb_size",
      "hidden_size",
      "num_layers",
      "bidirectional",
      "bias",
      "batch_first",
      "zero_init",
      "packed_input_flag"
    ]
  },
  "RMSNorm_test": {
    "test_input_norm": [
      "self",
      "N",
      "Z",
      "W",
      "H",
      "input_dim",
      "norm_dim"
    ],
    "get_x_shape_and_norm_shape": [
      "H",
      "N",
      "W",
      "Z",
      "input_dim",
      "norm_dim"
    ]
  },
  "Embedding_bag_test": {
    "test_input_across_dims": [
      "self",
      "N",
      "sz",
      "V",
      "D",
      "mode"
    ]
  },
  "expander": [
    "x",
    "factor"
  ],
  "shrinker": [
    "x",
    "factor"
  ],
  "GradSampleHooks_test": {
    "run_test": [
      "self",
      "x",
      "module",
      "batch_first",
      "atol",
      "rtol",
      "ew_compatible",
      "chunk_method"
    ],
    "run_test_with_reduction": [
      "self",
      "x",
      "module",
      "batch_first",
      "loss_reduction",
      "atol",
      "rtol",
      "grad_sample_mode",
      "chunk_method"
    ],
    "check_shapes": [
      "self",
      "microbatch_grad_samples",
      "opacus_grad_samples",
      "loss_reduction"
    ],
    "check_values": [
      "self",
      "microbatch_grad_samples",
      "opacus_grad_samples",
      "loss_reduction",
      "atol",
      "rtol"
    ]
  },
  "GroupNorm_test": {
    "test_3d_input_groups": [
      "self",
      "N",
      "C",
      "H",
      "W",
      "num_groups"
    ]
  },
  "Conv3d_test": {
    "test_conv3d": [
      "self",
      "N",
      "C",
      "D",
      "H",
      "W",
      "out_channels_mapper",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups"
    ]
  },
  "DPMultiheadAttentionAdapter": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MultiHeadAttention_test": {
    "test_multihead_attention": [
      "self",
      "N",
      "T",
      "D",
      "P",
      "bias",
      "add_bias_kv",
      "add_zero_attn",
      "kv_dim",
      "test_or_check"
    ]
  },
  "TestComputeEmbeddingNormSample": {
    "test_compute_embedding_norm_sample": [
      "self"
    ],
    "test_compute_embedding_norm_sample_with_non_one_embedding_dim": [
      "self"
    ],
    "test_compute_embedding_norm_sample_with_extra_activations_per_example": [
      "self"
    ]
  },
  "SequenceBias_test": {
    "test_batch_second": [
      "self",
      "N",
      "T",
      "D",
      "batch_first"
    ]
  },
  "Linear_test": {
    "test_input_bias": [
      "self",
      "N",
      "Z",
      "W",
      "H",
      "input_dim",
      "bias",
      "batch_first"
    ]
  },
  "LayerNorm_test": {
    "test_input_norm": [
      "self",
      "N",
      "Z",
      "W",
      "H",
      "input_dim",
      "norm_dim"
    ],
    "get_x_shape_and_norm_shape": [
      "H",
      "N",
      "W",
      "Z",
      "input_dim",
      "norm_dim"
    ]
  },
  "Conv2d_test": {
    "test_conv2d": [
      "self",
      "N",
      "C",
      "H",
      "W",
      "out_channels_mapper",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups"
    ],
    "test_unfold2d": [
      "self",
      "B",
      "C",
      "H",
      "W",
      "k_h",
      "k_w",
      "pad_h",
      "pad_w",
      "stride_h",
      "stride_w",
      "dilation_h",
      "dilation_w"
    ],
    "test_asymetric_dilation_and_kernel_size": [
      "self"
    ]
  },
  "Conv1d_test": {
    "test_conv1d": [
      "self",
      "N",
      "C",
      "W",
      "out_channels_mapper",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups"
    ]
  },
  "InstanceNorm3d_test": {
    "test_5d_input": [
      "self",
      "N",
      "C",
      "W",
      "H",
      "Z"
    ]
  },
  "MODELS": [],
  "DPRNNAdapter": {
    "__init__": [
      "self",
      "dp_rnn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RNN_test": {
    "test_rnn": [
      "self",
      "model",
      "N",
      "T",
      "D",
      "H",
      "num_layers",
      "bias",
      "batch_first",
      "bidirectional",
      "using_packed_sequences",
      "packed_sequences_sorted"
    ]
  },
  "InstanceNorm1d_test": {
    "test_3d_input": [
      "self",
      "N",
      "C",
      "W"
    ]
  },
  "Embedding_test": {
    "test_input_across_dims": [
      "self",
      "N",
      "T",
      "Q",
      "R",
      "V",
      "D",
      "dim",
      "batch_first"
    ]
  },
  "InstanceNorm2d_test": {
    "test_4d_input": [
      "self",
      "N",
      "C",
      "W",
      "H"
    ]
  },
  "UnsupportedError": {},
  "UnsupportedModuleError": {},
  "UnsupportableModuleError": {},
  "NotYetSupportedModuleError": {},
  "ShouldReplaceModuleError": {},
  "IllegalModuleConfigurationError": {},
  "INSTANCENORM": [],
  "validate": [
    "module"
  ],
  "fix": [
    "module"
  ],
  "DEFAULT_MODULE_VALIDATOR": [],
  "register_module_validator": [
    "target_class_or_classes",
    "validator_class"
  ],
  "register_module_fixer": [
    "target_class_or_classes",
    "validator_class"
  ],
  "BATCHNORM": [],
  "_batchnorm_to_groupnorm": [
    "module"
  ],
  "_batchnorm_to_instancenorm": [
    "module"
  ],
  "_nullify_batch_norm": [],
  "ModuleValidator": {
    "VALIDATORS": [],
    "FIXERS": [],
    "validate": [
      "cls",
      "module"
    ],
    "is_valid": [
      "cls",
      "module"
    ],
    "fix": [
      "cls",
      "module"
    ],
    "_replace_sub_module": [
      "cls"
    ],
    "fix_and_validate": [
      "cls",
      "module"
    ]
  },
  "_GradClipScheduler": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "get_max_grad_norm": [
      "self"
    ],
    "step": [
      "self"
    ]
  },
  "ExponentialGradClip": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "get_max_grad_norm": [
      "self"
    ]
  },
  "LambdaGradClip": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "get_max_grad_norm": [
      "self"
    ]
  },
  "StepGradClip": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "get_max_grad_norm": [
      "self"
    ]
  },
  "_NoiseScheduler": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "get_noise_multiplier": [
      "self"
    ],
    "step": [
      "self"
    ]
  },
  "ExponentialNoise": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "get_noise_multiplier": [
      "self"
    ]
  },
  "LambdaNoise": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "get_noise_multiplier": [
      "self"
    ]
  },
  "StepNoise": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "get_noise_multiplier": [
      "self"
    ]
  },
  "has_trainable_params": [
    "module"
  ],
  "parametrized_modules": [
    "module"
  ],
  "trainable_modules": [
    "module"
  ],
  "trainable_parameters": [
    "module"
  ],
  "requires_grad": [
    "module"
  ],
  "get_submodule": [
    "module",
    "target"
  ],
  "are_state_dict_equal": [
    "sd1",
    "sd2"
  ],
  "is_batch_empty": [
    "batch"
  ],
  "ModelWithLoss": {
    "supported_reductions": [],
    "__init__": [
      "self",
      "module",
      "loss_reduction"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "compute_microbatch_grad_sample": [
    "x",
    "module",
    "batch_first",
    "loss_reduction",
    "chunk_method"
  ],
  "compute_opacus_grad_sample": [
    "x",
    "module",
    "batch_first",
    "loss_reduction",
    "grad_sample_mode"
  ],
  "check_torch_version_for_ew_sample": [],
  "get_grad_sample_modes": [
    "use_ew"
  ],
  "check_per_sample_gradients_are_correct": [
    "x",
    "module"
  ],
  "compute_microbatch_grad_sample_tensor_or_seq": [
    "x",
    "module",
    "batch_first",
    "loss_reduction"
  ],
  "compute_grad_samples_microbatch_and_opacus": [
    "x",
    "module",
    "batch_first",
    "loss_reduction",
    "grad_sample_mode",
    "chunk_method"
  ],
  "_check_per_sample_gradients_are_correct_with_reduction": [
    "x",
    "module",
    "batch_first",
    "loss_reduction",
    "atol",
    "rtol",
    "grad_sample_mode"
  ],
  "unpack_packedsequences": [
    "X"
  ],
  "_compute_loss_packedsequences": [
    "criterion",
    "x"
  ],
  "UniformWithReplacementSampler": {
    "__init__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "DistributedUniformWithReplacementSampler": {
    "__init__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "_gen_packed_data": [
    "minibatch_size",
    "max_seq_length",
    "input_dim",
    "batch_first",
    "sorted_"
  ],
  "compute_seq_lengths": [
    "batch_sizes"
  ],
  "DPTensorFastGradientClipping": {
    "__init__": [
      "self",
      "module",
      "optimizer",
      "loss_per_sample",
      "loss_reduction"
    ],
    "item": [
      "self"
    ],
    "backward": [
      "self"
    ]
  },
  "DPLossFastGradientClipping": {
    "__init__": [
      "self",
      "module",
      "optimizer",
      "criterion",
      "loss_reduction"
    ],
    "__call__": [
      "self",
      "input",
      "target",
      "shape"
    ]
  },
  "BatchSplittingSampler": {
    "__init__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "wrap_data_loader": [],
  "BatchMemoryManager": {
    "__init__": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "type",
      "value",
      "traceback"
    ]
  },
  "calc_sample_norms": [
    "named_params"
  ],
  "calc_sample_norms_one_layer": [
    "param"
  ],
  "sum_over_all_but_batch_and_last_n": [
    "tensor",
    "n_dims"
  ],
  "unfold2d": [
    "input"
  ],
  "unfold3d": [
    "tensor"
  ],
  "filter_dilated_rows": [
    "tensor",
    "dilation",
    "dilated_kernel_size",
    "kernel_size"
  ],
  "DPTensorFastGradientAdaptiveClipping": {
    "__init__": [
      "self",
      "module",
      "optimizer",
      "loss_per_sample",
      "loss_reduction",
      "target_unclipped_quantile",
      "min_clipbound",
      "max_clipbound",
      "clipbound_learning_rate",
      "initial_noise_multiplier"
    ],
    "backward": [
      "self"
    ],
    "_is_distributed": [
      "self"
    ],
    "_update_clip_and_noise": [
      "self",
      "per_sample_norms"
    ]
  },
  "DPLossFastGradientAdaptiveClipping": {
    "__init__": [
      "self",
      "module",
      "optimizer",
      "criterion",
      "loss_reduction",
      "target_unclipped_quantile",
      "min_clipbound",
      "max_clipbound",
      "clipbound_learning_rate",
      "initial_noise_multiplier"
    ],
    "__call__": [
      "self",
      "input",
      "target"
    ]
  },
  "PrivacyEngineAdaptiveClipping": {
    "__init__": [
      "self"
    ],
    "_prepare_criterion": [
      "self"
    ]
  },
  "GradSampleModuleExpandedWeights": {
    "__init__": [
      "self",
      "m"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "compute_conv_grad_sample": [
    "layer",
    "activations",
    "backprops"
  ],
  "convolution2d_backward_as_a_convolution": [
    "layer",
    "activations",
    "backprops"
  ],
  "compute_sequence_bias_grad_sample": [
    "layer",
    "activations",
    "backprops"
  ],
  "compute_embedding_grad_sample": [
    "layer",
    "activations",
    "backprops"
  ],
  "compute_embeddingbag_gradsampler": [
    "layer",
    "inputs",
    "backprops"
  ],
  "compute_embedding_norm_sample": [
    "layer",
    "activations",
    "backprops"
  ],
  "create_norm_sample": [],
  "GradSampleModuleFastGradientClipping": {
    "NORM_SAMPLERS": [],
    "__init__": [
      "self",
      "m"
    ],
    "get_clipping_coef": [
      "self"
    ],
    "get_norm_sample": [
      "self"
    ],
    "capture_activations_hook": [
      "self",
      "module",
      "forward_input",
      "_forward_output"
    ],
    "capture_backprops_hook": [
      "self",
      "module",
      "_forward_input",
      "forward_output",
      "loss_reduction",
      "batch_first"
    ],
    "log_module_gradient_sample_mode": [
      "self",
      "module"
    ],
    "per_sample_gradient_norms": [
      "self",
      "value"
    ]
  },
  "compute_instance_norm_grad_sample": [
    "layer",
    "activations",
    "backprops"
  ],
  "register_grad_sampler": [
    "target_class_or_classes"
  ],
  "register_norm_sampler": [
    "target_class_or_classes"
  ],
  "wrap_model": [
    "model",
    "grad_sample_mode"
  ],
  "get_gsm_class": [
    "grad_sample_mode"
  ],
  "compute_layer_norm_grad_sample": [
    "layer",
    "activations",
    "backprops"
  ],
  "create_or_accumulate_grad_sample": [],
  "promote_current_grad_sample": [
    "p"
  ],
  "GradSampleModule": {
    "GRAD_SAMPLERS": [],
    "__init__": [
      "self",
      "m"
    ],
    "forward": [
      "self"
    ],
    "iterate_submodules": [
      "self",
      "module"
    ],
    "add_hooks": [
      "self"
    ],
    "remove_hooks": [
      "self"
    ],
    "disable_hooks": [
      "self"
    ],
    "enable_hooks": [
      "self"
    ],
    "_close": [
      "self"
    ],
    "capture_activations_hook": [
      "self",
      "module",
      "forward_input",
      "_forward_output"
    ],
    "capture_backprops_hook": [
      "self",
      "module",
      "_forward_input",
      "forward_output",
      "loss_reduction",
      "batch_first"
    ],
    "rearrange_grad_samples": [
      "self"
    ],
    "is_supported": [
      "cls",
      "module"
    ],
    "validate": [
      "cls",
      "module"
    ],
    "forbid_grad_accumulation": [
      "self"
    ],
    "allow_grad_accumulation": [
      "self"
    ]
  },
  "_get_batch_size": [],
  "make_functional": [
    "mod",
    "disable_autograd_tracking"
  ],
  "prepare_layer": [
    "layer",
    "batch_first"
  ],
  "ft_compute_per_sample_gradient": [
    "layer",
    "activations",
    "backprops"
  ],
  "GradSampleModuleNoOp": {
    "__init__": [
      "self",
      "m"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "compute_group_norm_grad_sample": [
    "layer",
    "activations",
    "backprops"
  ],
  "compute_rms_norm_grad_sample": [
    "layer",
    "activations",
    "backprops"
  ],
  "compute_rnn_linear_grad_sample": [
    "layer",
    "activations",
    "backprops"
  ],
  "OPACUS_PARAM_MONKEYPATCH_ATTRS": [],
  "AbstractGradSampleModule": {
    "__init__": [
      "self",
      "m"
    ],
    "forward": [
      "self"
    ],
    "__getattr__": [
      "self",
      "item"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ],
    "set_grad_sample_to_none": [
      "self"
    ],
    "del_grad_sample": [
      "self"
    ],
    "to_standard_module": [
      "self"
    ],
    "_close": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "forbid_grad_accumulation": [
      "self"
    ],
    "allow_grad_accumulation": [
      "self"
    ]
  },
  "compute_linear_grad_sample": [
    "layer",
    "activations",
    "backprops"
  ],
  "compute_linear_norm_sample": [
    "layer",
    "activations",
    "backprops"
  ],
  "AdaClipDPOptimizer": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ],
    "clip_and_accumulate": [
      "self"
    ],
    "add_noise": [
      "self"
    ],
    "update_max_grad_norm": [
      "self"
    ],
    "pre_step": [
      "self",
      "closure"
    ]
  },
  "params": [
    "optimizer"
  ],
  "get_optimizer_class": [
    "clipping",
    "distributed",
    "grad_sample_mode"
  ],
  "DPPerLayerOptimizer": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "clip_and_accumulate": [
      "self"
    ]
  },
  "_clip_and_accumulate_parameter": [
    "p",
    "max_grad_norm"
  ],
  "SimpleDistributedPerLayerOptimizer": {
    "__init__": [
      "self",
      "optimizer"
    ]
  },
  "DistributedPerLayerOptimizer": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "_add_noise_parameter": [
      "self",
      "p"
    ],
    "accumulated_iterations": [
      "self"
    ],
    "_scale_grad_parameter": [
      "self",
      "p"
    ],
    "clip_and_accumulate": [
      "self"
    ],
    "add_noise": [
      "self"
    ],
    "pre_step": [
      "self",
      "closure"
    ],
    "_ddp_per_layer_hook": [
      "self",
      "p",
      "max_grad_norm",
      "_"
    ],
    "_register_hooks": [
      "self"
    ]
  },
  "DistributedDPOptimizer": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "add_noise": [
      "self"
    ],
    "reduce_gradients": [
      "self"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "DistributedDPOptimizerFastGradientClipping": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "add_noise": [
      "self"
    ],
    "reduce_gradients": [
      "self"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "DPOptimizerFastGradientClipping": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "accumulated_iterations": [
      "self"
    ],
    "accumulate": [
      "self"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ],
    "pre_step": [
      "self",
      "closure"
    ],
    "_get_flat_grad_sample": [
      "self",
      "p"
    ],
    "clip_and_accumulate": [
      "self"
    ]
  },
  "_mark_as_processed": [
    "obj"
  ],
  "_check_processed_flag_tensor": [
    "x"
  ],
  "_check_processed_flag": [
    "obj"
  ],
  "_generate_noise": [
    "std",
    "reference",
    "generator",
    "secure_mode"
  ],
  "DPOptimizer": {
    "__init__": [
      "self",
      "optimizer"
    ],
    "_get_flat_grad_sample": [
      "self",
      "p"
    ],
    "signal_skip_step": [
      "self",
      "do_skip"
    ],
    "_check_skip_next_step": [
      "self",
      "pop_next"
    ],
    "params": [
      "self"
    ],
    "grad_samples": [
      "self"
    ],
    "accumulated_iterations": [
      "self"
    ],
    "param_groups": [
      "self",
      "param_groups"
    ],
    "state": [
      "self",
      "state"
    ],
    "defaults": [
      "self",
      "defaults"
    ],
    "attach_step_hook": [
      "self",
      "fn"
    ],
    "clip_and_accumulate": [
      "self"
    ],
    "add_noise": [
      "self"
    ],
    "scale_grad": [
      "self"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ],
    "pre_step": [
      "self",
      "closure"
    ],
    "step": [
      "self",
      "closure"
    ],
    "__repr__": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "SequenceBias": {
    "__init__": [
      "self",
      "embed_dim",
      "batch_first"
    ],
    "_reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DPMultiheadAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "dropout",
      "bias",
      "add_bias_kv",
      "add_zero_attn",
      "kdim",
      "vdim",
      "batch_first",
      "device",
      "dtype"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask",
      "need_weights",
      "attn_mask",
      "is_causal"
    ],
    "unsqueeze_0_2": [
      "self",
      "t"
    ],
    "state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ]
  },
  "filter_out_old_keys": [
    "self",
    "state_dict",
    "prefix",
    "local_metadata"
  ],
  "RenameParamsMixin": {
    "set_rename_map": [
      "self",
      "rename_map"
    ],
    "_register_renamed_parameters": [
      "self"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ]
  },
  "apply_permutation": [
    "tensor",
    "dim",
    "permutation"
  ],
  "RNNLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias"
    ]
  },
  "DPRNNCellBase": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "bias",
      "num_chunks"
    ],
    "reset_parameters": [
      "self"
    ],
    "set_max_batch_length": [
      "self",
      "max_batch_length"
    ]
  },
  "DPRNNCell": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "bias",
      "nonlinearity"
    ],
    "forward": [
      "self",
      "input",
      "hx",
      "batch_size_t"
    ]
  },
  "DPGRUCell": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "bias"
    ],
    "forward": [
      "self",
      "input",
      "hx",
      "batch_size_t"
    ]
  },
  "DPLSTMCell": {
    "has_cell_state": [],
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "bias"
    ],
    "forward": [
      "self",
      "input",
      "hx",
      "batch_size_t"
    ]
  },
  "RNN_CELL_TYPES": [],
  "DPRNNBase": {
    "__init__": [
      "self",
      "mode",
      "input_size",
      "hidden_size",
      "num_layers",
      "bias",
      "batch_first",
      "dropout",
      "bidirectional",
      "proj_size",
      "cell_params"
    ],
    "forward": [
      "self",
      "input",
      "state_init"
    ],
    "forward_layer": [
      "self",
      "x",
      "h_0",
      "c_0",
      "batch_sizes",
      "cell",
      "max_batch_size",
      "seq_length",
      "is_packed",
      "reverse_layer"
    ],
    "iterate_layers": [
      "self"
    ],
    "initialize_cells": [
      "self"
    ]
  },
  "DPRNN": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "bias",
      "batch_first",
      "dropout",
      "bidirectional",
      "proj_size",
      "nonlinearity"
    ]
  },
  "DPGRU": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "bias",
      "batch_first",
      "dropout",
      "bidirectional",
      "proj_size"
    ]
  },
  "DPLSTM": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "bias",
      "batch_first",
      "dropout",
      "bidirectional",
      "proj_size"
    ]
  },
  "T_state_dict": [],
  "IAccountant": {
    "__init__": [
      "self"
    ],
    "step": [
      "self"
    ],
    "get_epsilon": [
      "self",
      "delta"
    ],
    "__len__": [
      "self"
    ],
    "mechanism": [
      "cls"
    ],
    "get_optimizer_hook_fn": [
      "self",
      "sample_rate"
    ],
    "state_dict": [
      "self",
      "destination"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "MAX_SIGMA": [],
  "get_noise_multiplier": [],
  "create_accountant": [
    "mechanism"
  ],
  "GaussianAccountant": {
    "__init__": [
      "self"
    ],
    "step": [
      "self"
    ],
    "get_epsilon": [
      "self",
      "delta",
      "poisson"
    ],
    "__len__": [
      "self"
    ],
    "mechanism": [
      "cls"
    ]
  },
  "PRVAccountant": {
    "__init__": [
      "self"
    ],
    "step": [
      "self"
    ],
    "get_epsilon": [
      "self",
      "delta"
    ],
    "_get_dprv": [
      "self",
      "eps_error",
      "delta_error"
    ],
    "_get_domain": [
      "self",
      "prvs",
      "num_self_compositions",
      "eps_error",
      "delta_error"
    ],
    "mechanism": [
      "cls"
    ],
    "__len__": [
      "self"
    ]
  },
  "RDPAccountant": {
    "DEFAULT_ALPHAS": [],
    "__init__": [
      "self"
    ],
    "step": [
      "self"
    ],
    "get_privacy_spent": [
      "self"
    ],
    "get_epsilon": [
      "self",
      "delta",
      "alphas"
    ],
    "__len__": [
      "self"
    ],
    "mechanism": [
      "cls"
    ]
  },
  "compute_mu_uniform": [],
  "compute_mu_poisson": [],
  "delta_eps_mu": [],
  "eps_from_mu": [],
  "compute_eps_uniform": [],
  "compute_eps_poisson": [],
  "_log_add": [
    "logx",
    "logy"
  ],
  "_log_sub": [
    "logx",
    "logy"
  ],
  "_compute_log_a_for_int_alpha": [
    "q",
    "sigma",
    "alpha"
  ],
  "_compute_log_a_for_frac_alpha": [
    "q",
    "sigma",
    "alpha"
  ],
  "_compute_log_a": [
    "q",
    "sigma",
    "alpha"
  ],
  "_log_erfc": [
    "x"
  ],
  "_compute_rdp": [
    "q",
    "sigma",
    "alpha"
  ],
  "compute_rdp": [],
  "get_privacy_spent": [],
  "_compose_fourier": [
    "dprv",
    "num_self_composition"
  ],
  "_compose_two": [
    "dprv_left",
    "dprv_right"
  ],
  "_compose_convolution_tree": [
    "dprvs"
  ],
  "compose_heterogeneous": [
    "dprvs",
    "num_self_compositions"
  ],
  "Domain": {
    "__post_init__": [
      "self"
    ],
    "create_aligned": [
      "cls",
      "t_min",
      "t_max",
      "dt"
    ],
    "shift_right": [
      "self",
      "dt"
    ],
    "dt": [
      "self"
    ],
    "ts": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ]
  },
  "compute_safe_domain_size": [
    "prvs",
    "max_self_compositions",
    "eps_error",
    "delta_error"
  ],
  "SQRT2": [],
  "PoissonSubsampledGaussianPRV": {
    "__init__": [
      "self",
      "sample_rate",
      "noise_multiplier"
    ],
    "pdf": [
      "self",
      "t"
    ],
    "cdf": [
      "self",
      "t"
    ],
    "rdp": [
      "self",
      "alpha"
    ]
  },
  "TruncatedPrivacyRandomVariable": {
    "__init__": [
      "self",
      "prv",
      "t_min",
      "t_max"
    ],
    "pdf": [
      "self",
      "t"
    ],
    "cdf": [
      "self",
      "t"
    ],
    "mean": [
      "self"
    ]
  },
  "DiscretePRV": {
    "__len__": [
      "self"
    ],
    "compute_epsilon": [
      "self",
      "delta",
      "delta_error",
      "eps_error"
    ],
    "compute_delta_estimate": [
      "self",
      "eps"
    ]
  },
  "discretize": [
    "prv",
    "domain"
  ],
  "MNIST_MEAN": [],
  "MNIST_STD": [],
  "train": [
    "args",
    "model",
    "device",
    "train_loader",
    "optimizer",
    "privacy_engine",
    "epoch"
  ],
  "test": [
    "model",
    "device",
    "test_loader"
  ],
  "parser": [],
  "CharByteEncoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "s",
      "pad_to"
    ],
    "decode": [
      "self",
      "char_ids_tensor"
    ],
    "__len__": [
      "self"
    ]
  },
  "NamesDataset": {
    "__init__": [
      "self",
      "root"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__len__": [
      "self"
    ],
    "construct_samples": [
      "self"
    ],
    "label_count": [
      "self"
    ]
  },
  "VOCAB_SIZE": [],
  "CharNNClassifier": {
    "__init__": [
      "self",
      "rnn_type",
      "embedding_size",
      "hidden_size",
      "output_size",
      "num_layers",
      "bidirectional",
      "vocab_size"
    ],
    "forward": [
      "self",
      "x",
      "hidden"
    ]
  },
  "padded_collate": [
    "batch",
    "padding_idx"
  ],
  "convnet": [
    "num_classes"
  ],
  "save_checkpoint": [
    "state",
    "is_best",
    "filename"
  ],
  "accuracy": [
    "preds",
    "labels"
  ],
  "parse_args": [],
  "pretty_number": [
    "n"
  ],
  "opt": [],
  "dataloader": [],
  "device": [],
  "ngpu": [],
  "nz": [],
  "ngf": [],
  "ndf": [],
  "weights_init": [
    "m"
  ],
  "Generator": {
    "__init__": [
      "self",
      "ngpu"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "netG": [],
  "Discriminator": {
    "__init__": [
      "self",
      "ngpu"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "netD": [],
  "criterion": [],
  "FIXED_NOISE": [],
  "REAL_LABEL": [],
  "FAKE_LABEL": [],
  "optimizerD": [],
  "optimizerG": [],
  "LitSampleConvNetClassifier": {
    "__init__": [
      "self",
      "lr",
      "enable_dp",
      "delta",
      "noise_multiplier",
      "max_grad_norm"
    ],
    "forward": [
      "self",
      "x"
    ],
    "configure_optimizers": [
      "self"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "test_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "on_train_epoch_end": [
      "self"
    ]
  },
  "cli_main": [],
  "SampleNet": {
    "__init__": [
      "self",
      "vocab_size"
    ],
    "forward": [
      "self",
      "x"
    ],
    "name": [
      "self"
    ]
  },
  "binary_accuracy": [
    "preds",
    "y"
  ],
  "evaluate": [
    "args",
    "model",
    "test_loader"
  ]
}