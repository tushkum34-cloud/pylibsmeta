{
  "DEFAULT_REQUEST_TIMEOUT": [],
  "dispatcher": [],
  "get_additional_kwargs": [
    "response",
    "exclude"
  ],
  "force_single_tool_call": [
    "response"
  ],
  "Ollama": {
    "__init__": [
      "self",
      "model",
      "base_url",
      "temperature",
      "context_window",
      "request_timeout",
      "prompt_key",
      "json_mode",
      "additional_kwargs",
      "client",
      "async_client",
      "is_function_calling_model",
      "keep_alive",
      "thinking"
    ],
    "class_name": [
      "cls"
    ],
    "metadata": [
      "self"
    ],
    "client": [
      "self"
    ],
    "async_client": [
      "self"
    ],
    "_model_kwargs": [
      "self"
    ],
    "get_context_window": [
      "self"
    ],
    "_convert_to_ollama_messages": [
      "self",
      "messages"
    ],
    "_get_response_token_counts": [
      "self",
      "raw_response"
    ],
    "_prepare_chat_with_tools": [
      "self",
      "tools",
      "user_msg",
      "chat_history",
      "verbose",
      "allow_parallel_tool_calls",
      "tool_required"
    ],
    "_validate_chat_with_tools_response": [
      "self",
      "response",
      "tools",
      "allow_parallel_tool_calls"
    ],
    "get_tool_calls_from_response": [
      "self",
      "response",
      "error_on_no_tool_call"
    ],
    "chat": [
      "self",
      "messages"
    ],
    "stream_chat": [
      "self",
      "messages"
    ],
    "astream_chat": [
      "self",
      "messages"
    ],
    "achat": [
      "self",
      "messages"
    ],
    "complete": [
      "self",
      "prompt",
      "formatted"
    ],
    "acomplete": [
      "self",
      "prompt",
      "formatted"
    ],
    "stream_complete": [
      "self",
      "prompt",
      "formatted"
    ],
    "astream_complete": [
      "self",
      "prompt",
      "formatted"
    ],
    "structured_predict": [
      "self",
      "output_cls",
      "prompt",
      "llm_kwargs"
    ],
    "astructured_predict": [
      "self",
      "output_cls",
      "prompt",
      "llm_kwargs"
    ],
    "stream_structured_predict": [
      "self",
      "output_cls",
      "prompt",
      "llm_kwargs"
    ],
    "astream_structured_predict": [
      "self",
      "output_cls",
      "prompt",
      "llm_kwargs"
    ]
  },
  "__all__": []
}