{
  "__version__": [],
  "_sanitize_temperature_and_top_p": [
    "temperature",
    "top_p"
  ],
  "LLM": {
    "__init__": [
      "self",
      "checkpoint_dir",
      "tokenizer",
      "medusa_choices",
      "tp",
      "trust_remote_code",
      "max_seq_len",
      "max_batch_size"
    ],
    "max_seq_len": [
      "self"
    ],
    "max_beam_width": [
      "self"
    ],
    "gather_context_logits": [
      "self"
    ],
    "_generate": [
      "self",
      "prompts",
      "max_new_tokens",
      "temperature",
      "top_p",
      "stop_words"
    ],
    "generate_tokens": [
      "self",
      "prompts",
      "max_new_tokens",
      "temperature",
      "top_p",
      "stop_words"
    ],
    "generate_text": [
      "self",
      "prompts",
      "max_new_tokens",
      "temperature",
      "top_p",
      "stop_words"
    ],
    "generate_context_logits": [
      "self",
      "prompts",
      "temperature",
      "top_p"
    ]
  },
  "is_unary_op": [
    "op_type"
  ],
  "is_binary_op": [
    "op_type"
  ],
  "is_fusible_reduction_op": [
    "op_type"
  ],
  "is_fusible_scaling_op": [
    "op_type"
  ],
  "get_copy_ops": [],
  "is_copy_op": [
    "op_type"
  ],
  "is_linear_op": [
    "op_type"
  ],
  "is_pointwise_or_elementwise_op": [
    "op_type"
  ],
  "is_pooling_or_window_op": [
    "op_type"
  ],
  "is_normalization_op": [
    "op_type"
  ],
  "is_conversion_op": [
    "op_type"
  ],
  "is_non_reshape_copy_op": [
    "op_type"
  ],
  "is_irregular_mem_access_op": [
    "op_type"
  ],
  "is_generator_op": [
    "op_type"
  ],
  "is_modifier_op": [
    "op_type"
  ],
  "is_sequence_op": [
    "op_type"
  ],
  "is_selection_op": [
    "op_type"
  ],
  "is_control_flow_op": [
    "op_type"
  ],
  "is_multiclass_op": [
    "op_type"
  ],
  "is_recurrent_op": [
    "op_type"
  ],
  "is_shape_op": [
    "op_type"
  ],
  "is_default_quantizable_op_by_ort": [
    "op_type"
  ],
  "is_data_dependent_shape_op": [
    "op_type"
  ],
  "get_input_names_from_bytes": [
    "model_bytes",
    "external_inputs_only"
  ],
  "get_all_input_names": [
    "model"
  ],
  "_get_initializer_names": [
    "model"
  ],
  "get_input_names": [
    "model",
    "external_inputs_only"
  ],
  "get_output_names_from_bytes": [
    "model_bytes"
  ],
  "get_output_names": [
    "model"
  ],
  "get_node_names_from_bytes": [
    "model_bytes"
  ],
  "get_node_names": [
    "model"
  ],
  "_get_tensor_shape": [
    "tensor"
  ],
  "get_dynamic_graph_inputs": [
    "onnx_model"
  ],
  "_get_all_shapes": [
    "container"
  ],
  "_get_selected_shapes": [
    "container",
    "inputs_to_include"
  ],
  "get_input_shapes_from_bytes": [
    "model_bytes"
  ],
  "get_input_shapes": [
    "model",
    "external_inputs_only"
  ],
  "get_output_shapes": [
    "model"
  ],
  "parse_shapes_spec": [
    "shapes_spec"
  ],
  "_get_tensor_type": [
    "tensor"
  ],
  "_get_container_types": [
    "container",
    "inputs_to_include"
  ],
  "_get_input_types": [
    "model",
    "external_inputs_only"
  ],
  "_get_output_types": [
    "model"
  ],
  "_convert_types_to_np": [
    "types"
  ],
  "get_tensor_by_name": [
    "onnx_model",
    "tensor_name"
  ],
  "gen_random_inputs": [
    "model",
    "shapes_spec"
  ],
  "remove_weights_data": [
    "onnx_bytes"
  ],
  "randomize_weights": [
    "onnx_path"
  ],
  "randomize_weights_onnx_bytes": [
    "onnx_bytes",
    "seed"
  ],
  "validate_onnx": [
    "onnx_bytes"
  ],
  "validate_batch_size": [
    "onnx_bytes",
    "batch_size"
  ],
  "get_batch_size": [
    "model"
  ],
  "get_batch_size_from_bytes": [
    "onnx_bytes"
  ],
  "save_onnx_bytes_to_dir": [
    "onnx_bytes",
    "onnx_dir",
    "onnx_name"
  ],
  "name_onnx_nodes": [
    "graph"
  ],
  "duplicate_shared_constants": [
    "onnx_model"
  ],
  "check_model": [
    "model"
  ],
  "find_lowest_common_ancestor": [
    "node1",
    "node2"
  ],
  "get_parent_nodes": [
    "node"
  ],
  "get_child_nodes": [
    "node"
  ],
  "get_variable_inputs": [
    "node"
  ],
  "save_onnx": [
    "model",
    "onnx_path",
    "save_as_external_data"
  ],
  "update_domain": [
    "onnx_model",
    "op_type",
    "domain"
  ],
  "get_opset_version": [
    "model"
  ],
  "bfloat16_to_float32": [
    "bf16_array"
  ],
  "read_f16_tensor_as_fp32": [
    "tensor"
  ],
  "has_attribute": [
    "node",
    "attr_name"
  ],
  "get_attribute": [
    "node",
    "attr_name"
  ],
  "infer_shapes": [
    "model"
  ],
  "onnx_type_str_to_enum": [
    "dtype"
  ],
  "remove_node_training_mode": [
    "onnx_model",
    "node_op_type"
  ],
  "MIN_PYTHON_VERSION": [],
  "MAX_IR_VERSION": [],
  "_is_static_plugin": [
    "plugin_path"
  ],
  "_load_trt_plugin": [
    "plugin_path",
    "registry"
  ],
  "get_custom_layers": [
    "onnx_path",
    "trt_plugins",
    "strongly_typed"
  ],
  "infer_types_shapes": [
    "model",
    "all_tensor_info"
  ],
  "set_trt_plugin_domain": [
    "model",
    "custom_ops"
  ],
  "infer_types_shapes_tensorrt": [
    "model",
    "trt_plugins",
    "all_tensor_info",
    "strongly_typed"
  ],
  "load_onnx_model": [
    "onnx_path",
    "trt_plugins",
    "override_shapes",
    "use_external_data_format",
    "intermediate_generated_files"
  ],
  "interpret_trt_plugins_precision_flag": [
    "onnx_model",
    "trt_plugins_precision",
    "quantize_mode"
  ],
  "logger": [],
  "configure_logging": [
    "level",
    "log_file"
  ],
  "INT4QuantExporter": {
    "pre_process": [
      "onnx_model"
    ],
    "compute_scales": [
      "onnx_model"
    ],
    "compress_weights": [
      "onnx_model"
    ],
    "post_process": [
      "onnx_model"
    ]
  },
  "_cast_fp4": [
    "array"
  ],
  "_cast_fp8": [
    "array"
  ],
  "_replace_fp4qdq_with_2dq": [
    "graph",
    "node",
    "initializer_indices",
    "value_info_map",
    "graph_inputs",
    "w_f4",
    "sw_f32_per_tensor",
    "sw_f8_per_block",
    "block_size"
  ],
  "NVFP4QuantExporter": {
    "pre_process": [
      "onnx_model"
    ],
    "compute_scales": [
      "onnx_model"
    ],
    "compress_weights": [
      "onnx_model"
    ],
    "post_process": [
      "onnx_model"
    ]
  },
  "FP8QuantExporter": {
    "pre_process": [
      "onnx_model"
    ],
    "compute_scales": [
      "onnx_model"
    ],
    "compress_weights": [
      "onnx_model"
    ],
    "post_process": [
      "onnx_model"
    ]
  },
  "INT8QuantExporter": {
    "pre_process": [
      "onnx_model"
    ],
    "compute_scales": [
      "onnx_model"
    ],
    "compress_weights": [
      "onnx_model"
    ],
    "post_process": [
      "onnx_model"
    ]
  },
  "E8_M0_BIAS": [],
  "DEFAULT_BLOCK_SIZE": [],
  "DEFAULT_QUANT_AXIS": [],
  "_get_weight_dq_nodes": [
    "graph"
  ],
  "_get_quant_params": [
    "node"
  ],
  "MXFP8QuantExporter": {
    "pre_process": [
      "onnx_model"
    ],
    "compute_scales": [
      "onnx_model"
    ],
    "compress_weights": [
      "onnx_model"
    ],
    "post_process": [
      "onnx_model"
    ]
  },
  "__all__": [],
  "ONNXQuantExporter": {
    "process_model": [
      "cls",
      "onnx_model"
    ],
    "pre_process": [
      "onnx_model"
    ],
    "compute_scales": [
      "onnx_model"
    ],
    "compress_weights": [
      "onnx_model"
    ],
    "post_process": [
      "onnx_model"
    ]
  },
  "clear_inputs": [
    "node"
  ],
  "clear_outputs": [
    "node"
  ],
  "extract_layer_id": [
    "name"
  ],
  "no_none_elements": [
    "elements"
  ],
  "fold_fp8_qdq_to_dq": [
    "graph"
  ],
  "RopeType": {
    "K_NONE": [],
    "K_ROPE_ROTATE_GPTJ": [],
    "K_ROPE_ROTATE_NEOX": [],
    "K_MROPE": []
  },
  "ModelLoader": {
    "__init__": [
      "self",
      "hf_model_path",
      "config_path"
    ],
    "get_model_type": [
      "self"
    ],
    "load_model": [
      "self",
      "trust_remote_code"
    ],
    "get_rope_type": [
      "self"
    ]
  },
  "WrapperModelForCausalLM": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values"
    ]
  },
  "llm_to_onnx": [
    "model",
    "output_dir",
    "extra_inputs",
    "extra_dyn_axes"
  ],
  "torch_to_onnx": [
    "model",
    "inputs",
    "onnx_dir",
    "onnx_name",
    "input_names",
    "output_names",
    "dynamic_axes"
  ],
  "_quantize_model": [
    "model",
    "quant_config",
    "calib_dataloader"
  ],
  "get_quant_config": [
    "precision",
    "lm_head_precision"
  ],
  "quantize": [
    "model",
    "tokenizer",
    "precision",
    "lm_head_precision",
    "dataset_dir",
    "calib_size"
  ],
  "int8_to_fp8": [
    "onnx_model"
  ],
  "upgrade_opset_21": [
    "onnx_model"
  ],
  "_find_nodes_to_quantize": [
    "graph",
    "quantizable_op_types",
    "nodes_to_exclude"
  ],
  "QDQNormalization": {
    "__init__": [
      "self",
      "onnx_quantizer",
      "onnx_node"
    ],
    "quantize": [
      "self"
    ]
  },
  "QDQConvTranspose": {
    "__init__": [
      "self",
      "onnx_quantizer",
      "onnx_node"
    ],
    "quantize": [
      "self"
    ]
  },
  "QDQCustomOp": {
    "__init__": [
      "self",
      "onnx_quantizer",
      "onnx_node"
    ],
    "quantize": [
      "self"
    ]
  },
  "INT4_MIN": [],
  "INT4_MAX": [],
  "UINT4_MIN": [],
  "UINT4_MAX": [],
  "CLIP_MIN": [],
  "pack_float32_to_4bit_optimized": [
    "array",
    "signed"
  ],
  "pack_float32_to_4bit_cpp_based": [
    "array",
    "signed"
  ],
  "get_weights_scaling_factor_2": [
    "input"
  ],
  "get_weights_scaling_factor": [
    "input",
    "block_size",
    "weights_scaling_factor_2"
  ],
  "update_block_size": [
    "block_size",
    "layer_info",
    "name",
    "quantize_axis",
    "w"
  ],
  "get_num_bits": [
    "layer_info",
    "name"
  ],
  "get_layer_block_size": [
    "layer_info",
    "name",
    "default_block_size"
  ],
  "get_layer_axis": [
    "layer_info",
    "name",
    "default_axis"
  ],
  "_next_block_size_multiple": [
    "x",
    "block_size"
  ],
  "_pad": [
    "w",
    "block_size",
    "quantize_axis"
  ],
  "_depad": [
    "w",
    "orig_shape",
    "quantize_axis"
  ],
  "reshape_scales_for_per_channel_nodes": [
    "scales_map",
    "block_size",
    "layer_info"
  ],
  "find_scales": [
    "w",
    "block_size",
    "quantize_axis",
    "alpha",
    "use_zero_point",
    "num_bits"
  ],
  "rtn": [
    "w",
    "s",
    "block_size",
    "quantize_axis",
    "zp",
    "num_bits"
  ],
  "dq_tensor": [
    "w",
    "s",
    "block_size",
    "quantize_axis",
    "zp"
  ],
  "quant_tensor": [
    "w",
    "block_size",
    "quantize_axis",
    "alpha",
    "use_zero_point",
    "num_bits"
  ],
  "pack_weights_to_int4": [
    "weight"
  ],
  "get_amax": [
    "weight",
    "quant_axis",
    "block_size"
  ],
  "compute_e8m0": [
    "amax",
    "weight_shape",
    "quant_axis",
    "block_size"
  ],
  "_preprocess_onnx": [
    "onnx_path",
    "use_external_data_format",
    "output_path",
    "enable_shared_constants_duplication",
    "trt_plugins",
    "trt_plugins_precision",
    "override_shapes",
    "simplify",
    "quantize_mode"
  ],
  "_onnx_supports_int4": [],
  "_make_constant": [
    "name",
    "values",
    "dtype"
  ],
  "_make_variable": [
    "name",
    "dtype",
    "shape"
  ],
  "_export_tensor_proto": [
    "tensor"
  ],
  "_export_value_info_proto": [
    "tensor",
    "do_type_check"
  ],
  "patch_gs_modules": [],
  "DEFAULT_GATHER_BLOCK_SIZE": [],
  "DEFAULT_GATHER_QUANTIZE_AXIS": [],
  "is_const_input": [
    "tensor"
  ],
  "has_const_input": [
    "node"
  ],
  "has_path_type": [
    "node",
    "graph",
    "path_type",
    "is_forward",
    "wild_card_types",
    "path_nodes"
  ],
  "get_fusible_backbone": [
    "node",
    "graph"
  ],
  "get_tensor_from_name": [
    "graph",
    "tensor_name"
  ],
  "get_tensor_producer_nodes": [
    "graph",
    "get_initializer_producers"
  ],
  "get_tensor_consumer_nodes": [
    "graph"
  ],
  "filter_quantizable_kgen_heads": [
    "cask_fusible_partitions",
    "kgen_partitions",
    "quantizable_op_types",
    "graph"
  ],
  "classify_partition_nodes": [
    "partitions"
  ],
  "classify_partially_quantized_weighted_ops": [
    "graph",
    "nodes_to_exclude"
  ],
  "build_non_residual_input_map": [
    "graph"
  ],
  "remove_partial_input_qdq": [
    "graph",
    "no_quantize_inputs"
  ],
  "_find_nodes_from_op_types_to_exclude": [
    "graph",
    "op_types_to_exclude"
  ],
  "_find_int4_quantizable_weights": [
    "graph",
    "nodes_to_exclude"
  ],
  "should_quantize_to_8bit": [
    "layer_name",
    "layers_8bit"
  ],
  "validate_8bit_layers": [
    "layers_str"
  ],
  "get_layer_precision_mapping": [
    "onnx_model",
    "precision_pattern_8bit",
    "nodes_to_exclude",
    "block_size",
    "quantize_axis"
  ],
  "get_layer_info": [
    "onnx_model",
    "nodes_to_exclude",
    "block_size",
    "quantize_axis"
  ],
  "expand_node_names_from_patterns": [
    "graph",
    "name_patterns"
  ],
  "find_nodes_to_exclude": [
    "graph",
    "nodes_to_exclude",
    "op_types_to_exclude"
  ],
  "get_extended_model_outputs": [
    "onnx_path",
    "extended_model",
    "use_external_data_format",
    "intermediate_generated_files",
    "calibration_data_reader",
    "calibration_eps"
  ],
  "find_nodes_from_matmul_to_exclude": [
    "onnx_path",
    "use_external_data_format",
    "intermediate_generated_files",
    "calibration_data_reader",
    "calibration_eps",
    "calibration_shapes"
  ],
  "find_nodes_from_convs_to_exclude": [
    "graph",
    "quantize_mode"
  ],
  "_exclude_matmuls_by_shape_inference": [
    "model",
    "matmul_nodes",
    "calibration_shapes"
  ],
  "_exclude_matmuls_by_inference": [
    "onnx_path",
    "model",
    "matmul_nodes",
    "use_external_data_format",
    "intermediate_generated_files",
    "calibration_data_reader",
    "calibration_eps"
  ],
  "find_nodes_from_mha_to_exclude": [
    "onnx_path",
    "use_external_data_format",
    "nodes_to_exclude",
    "disable_mha_qdq",
    "quantize_mode",
    "intermediate_generated_files",
    "calibration_data_reader",
    "calibration_eps"
  ],
  "validate_op_types_spelling": [
    "onnx_path",
    "op_types_to_quantize",
    "op_types_to_exclude"
  ],
  "cast_custom_ops": [
    "onnx_model",
    "ops_to_cast"
  ],
  "print_stat": [
    "graph"
  ],
  "find_mha_partitions": [
    "graph"
  ],
  "match_fp8_mha_pattern": [
    "graph",
    "softmax_op",
    "has_fp8_qdq"
  ],
  "insert_matmul_casts": [
    "graph",
    "matmul_node"
  ],
  "insert_fp8_mha_casts": [
    "onnx_model"
  ],
  "convert_fp16_io": [
    "graph"
  ],
  "remove_output_initializers": [
    "graph",
    "graph_initializers"
  ],
  "get_resize_scales": [
    "onnx_model"
  ],
  "get_concat_eliminated_tensors": [
    "onnx_model",
    "nodes_to_quantize"
  ],
  "remove_redundant_cast_nodes": [
    "graph"
  ],
  "QUANTIZE_NODE_NAME": [],
  "DEQUANTIZE_NODE_NAME": [],
  "onnx_dtype_map": [],
  "onnx_bit_dtype_signed_map": [],
  "onnx_bit_dtype_unsigned_map": [],
  "np_dtype_map": [],
  "use_trt_qdq_ops": [],
  "_wq_name": [
    "name"
  ],
  "_scale_name": [
    "name"
  ],
  "_awq_scale_name": [
    "name"
  ],
  "_zp_name": [
    "name"
  ],
  "_q_name": [
    "name"
  ],
  "_q_out_name": [
    "name"
  ],
  "_dq_name": [
    "name"
  ],
  "_pqs_name": [
    "name"
  ],
  "_dq_out_name": [
    "name"
  ],
  "_pqs_out_name": [
    "name"
  ],
  "make_gs_quantized_weight": [
    "name",
    "wq",
    "dtype"
  ],
  "make_gs_zp": [
    "name",
    "shape",
    "dtype"
  ],
  "make_gs_scale": [
    "name",
    "scale"
  ],
  "make_gs_awq_scale": [
    "name",
    "scale"
  ],
  "make_gs_quantize_output": [
    "name",
    "shape",
    "dtype"
  ],
  "make_gs_quantize_node": [
    "name",
    "inputs",
    "outputs"
  ],
  "make_gs_pre_quant_scale_output": [
    "name",
    "shape",
    "dtype"
  ],
  "make_gs_dequantize_output": [
    "name",
    "shape",
    "dtype"
  ],
  "make_gs_pre_quant_scale_node": [
    "name",
    "inputs",
    "outputs"
  ],
  "make_gs_dequantize_node": [
    "name",
    "inputs",
    "outputs",
    "attributes"
  ],
  "_postprocess_qdq": [
    "graph",
    "orig_weight_names",
    "q_nodes",
    "dq_nodes"
  ],
  "insert_pre_quant_scale_nodes": [
    "graph",
    "input_tensors",
    "pre_quant_scale"
  ],
  "get_tensor_dtype": [
    "num_bits",
    "has_zero_point"
  ],
  "update_attributes_for_per_channel_nodes": [
    "attributes",
    "num_bits"
  ],
  "validate_scale_shape_for_per_channel_nodes": [
    "scale",
    "attrs",
    "num_bits"
  ],
  "insert_dq_nodes": [
    "graph",
    "scales",
    "quantized_weights",
    "attributes",
    "zero_points",
    "layer_info"
  ],
  "insert_qdq_nodes": [
    "graph",
    "scales",
    "weight_map",
    "layer_info"
  ],
  "replace_scale_values": [
    "graph",
    "act_scales_dict"
  ],
  "has_qdq_nodes": [
    "onnx_model"
  ],
  "_get_graph_metadata": [
    "graph"
  ],
  "_get_scale_and_zp": [
    "node",
    "initializers",
    "tensor_producers"
  ],
  "_get_successive_consumers": [
    "node",
    "tensor_consumers"
  ],
  "_convert_weight": [
    "weight_array",
    "scale",
    "zp",
    "quantized_node"
  ],
  "_create_fp8_tensor": [
    "scaled",
    "weight_name"
  ],
  "qdq_to_dq": [
    "onnx_model"
  ],
  "remove_input_dq_and_output_q": [
    "onnx_model",
    "quantizable_custom_ops"
  ],
  "remove_graph_input_q": [
    "onnx_model"
  ],
  "replace_zero_scale_with_smallest_nonzero": [
    "onnx_model"
  ],
  "cast_initializer_to_dtype": [
    "node",
    "dtype",
    "initializer_map"
  ],
  "load_model_with_shape_infer": [
    "model_path"
  ],
  "_collect_value": [
    "histogram_collector",
    "name_to_arr"
  ],
  "_collect_absolute_value": [
    "histogram_collector",
    "name_to_arr"
  ],
  "_check_opset_version": [
    "onnx_quantizer"
  ],
  "_select_tensors_to_calibrate": [
    "calibrator",
    "model"
  ],
  "_create_inference_session_with_ep_config": [
    "calibrator"
  ],
  "_compute_data_minmax_calibrator": [
    "calibrator"
  ],
  "_compute_data_min_max_calibrater_single_node_calibration": [
    "calibrater"
  ],
  "_collect_data_minmax_calibrator": [
    "calibrator",
    "data_reader"
  ],
  "_merge_range_minmax_calibrator": [
    "calibrator",
    "old_range",
    "new_range"
  ],
  "_merge_range_min_max_calibrater_single_node_calibration": [
    "calibrater",
    "old_range",
    "new_range"
  ],
  "_collect_data_histogram_calibrator": [
    "calibrator",
    "data_reader"
  ],
  "_collect_data_min_max_calibrater_single_node_calibration": [
    "calibrater",
    "data_reader"
  ],
  "_collect_data_histogram_calibrater_single_node_calibration": [
    "calibrator",
    "data_reader"
  ],
  "_collect_histogram_collector_single_node_calibration": [
    "histogram_collector",
    "name_to_arr"
  ],
  "_collect_value_histogram_collector_single_node_calibration": [
    "histogram_collector",
    "name_to_arr"
  ],
  "_augment_graph_min_max_calibrater_single_node_calibration": [
    "calibrater"
  ],
  "_augment_graph_histogram_calibrater_single_node_calibration": [
    "calibrater"
  ],
  "_adjust_tensor_ranges": [
    "base_quantizer"
  ],
  "_create_calibrator_with_extra_options": [
    "model",
    "op_types_to_calibrate",
    "augmented_model_path",
    "calibrate_method",
    "use_external_data_format",
    "extra_options"
  ],
  "_quantize_static": [
    "model_input",
    "model_output",
    "calibration_data_reader",
    "quant_format",
    "op_types_to_quantize",
    "per_channel",
    "reduce_range",
    "activation_type",
    "weight_type",
    "nodes_to_quantize",
    "nodes_to_exclude",
    "use_external_data_format",
    "calibrate_method",
    "extra_options"
  ],
  "_init_calibrater_base": [
    "calibrater",
    "model_path",
    "op_types_to_calibrate",
    "augmented_model_path",
    "symmetric",
    "use_external_data_format",
    "per_channel"
  ],
  "patch_ort_modules": [
    "calibrate_per_node"
  ],
  "CalibrationDataType": [],
  "CalibrationDataProvider": {
    "__init__": [
      "self",
      "onnx_path",
      "calibration_data",
      "calibration_shapes"
    ],
    "get_next": [
      "self"
    ],
    "get_first": [
      "self"
    ],
    "rewind": [
      "self"
    ]
  },
  "RandomDataProvider": {
    "__init__": [
      "self",
      "onnx_model",
      "calibration_shapes"
    ],
    "get_next": [
      "self"
    ],
    "get_first": [
      "self"
    ],
    "rewind": [
      "self"
    ]
  },
  "import_scales_from_calib_cache": [
    "cache_path"
  ],
  "_check_lib_in_ld_library_path": [
    "ld_library_path",
    "lib_pattern"
  ],
  "_check_for_tensorrt": [
    "min_version"
  ],
  "_check_for_libcudnn": [],
  "_check_for_nv_tensorrt_rtx_libs": [],
  "_prepare_ep_list": [
    "calibration_eps"
  ],
  "update_trt_ep_support": [
    "calibration_eps",
    "has_dds_op",
    "has_custom_op",
    "trt_plugins"
  ],
  "create_inference_session": [
    "onnx_path_or_model",
    "calibration_eps",
    "input_shapes_profile"
  ],
  "get_quantizable_op_types": [
    "op_types_to_quantize"
  ],
  "configure_ort": [
    "op_types",
    "op_types_to_quantize",
    "trt_extra_plugin_lib_paths",
    "calibration_eps",
    "calibrate_per_node",
    "custom_ops_to_quantize"
  ],
  "has_cupy": [],
  "cupy_warning_msg": [],
  "NUM_BITS": [],
  "INT4_SCALE": [],
  "safe_cupy_array": [
    "tensor"
  ],
  "_quantize_gather_nodes": [
    "graph",
    "nodes_to_exclude",
    "use_zero_point",
    "dq_only",
    "layer_info"
  ],
  "quantize_rtn": [
    "onnx_model",
    "block_size",
    "dq_only",
    "nodes_to_exclude"
  ],
  "AWQClipHelper": {
    "min_alpha": [],
    "alpha_step": [],
    "__init__": [
      "self",
      "w",
      "block_size"
    ],
    "update_best_params": [
      "self"
    ]
  },
  "_clip_search": [
    "x",
    "w",
    "awq_clip",
    "max_tokens",
    "num_bits"
  ],
  "_augment_graph": [
    "graph",
    "wa_pack"
  ],
  "_change_input_type": [
    "graph",
    "input_name",
    "gemm_io_type"
  ],
  "_quantize_awq_clip": [
    "onnx_model",
    "data_reader",
    "use_external_data_format",
    "calibration_eps",
    "block_size",
    "force_fp16",
    "nodes_to_exclude",
    "input_shapes_profile"
  ],
  "AWQLiteHelper": {
    "alpha_step": [],
    "__init__": [
      "self",
      "x",
      "w",
      "block_size"
    ],
    "update_best_params": [
      "self"
    ]
  },
  "get_act_scale": [
    "x"
  ],
  "get_weight_scale": [
    "weight",
    "block_size"
  ],
  "get_scale": [
    "x_max",
    "w_max",
    "alpha"
  ],
  "run_awq_scale_search_per_node": [
    "wa_pack",
    "augmented_onnx_path",
    "block_size",
    "use_zero_point",
    "session",
    "awq_lite",
    "inputs",
    "tqdm_msg_append_str",
    "enable_weight_clipping",
    "enable_fast_path_using_high_sysram",
    "output_data",
    "clip_alphas",
    "layer_info"
  ],
  "get_act_to_weight_map_and_act_to_wa_pack_map": [
    "wa_pack"
  ],
  "get_x_w_mean_for_subgraph": [
    "wa_pack",
    "wa_pack_idx_list",
    "augmented_onnx_path",
    "x",
    "block_size"
  ],
  "run_awq_scale_search_per_subgraph": [
    "wa_pack",
    "act_to_wa_pack_map",
    "act_to_quant_nodes_weight_shape_map",
    "augmented_onnx_path",
    "block_size",
    "use_zero_point",
    "session",
    "awq_lite",
    "inputs",
    "tqdm_msg_append_str"
  ],
  "get_parent_child_nodes_map": [
    "graph",
    "wa_pack",
    "nodes_to_exclude"
  ],
  "_quantize_awq_lite": [
    "onnx_model",
    "data_reader",
    "use_external_data_format",
    "calibration_eps",
    "block_size",
    "force_fp16",
    "enable_fast_path_using_high_sysram",
    "enable_weight_clipping",
    "use_zero_point",
    "nodes_to_exclude",
    "input_shapes_profile"
  ],
  "validate_file_size": [
    "file_path",
    "max_size_bytes"
  ],
  "get_parser": [],
  "main": [],
  "_build_fusible_partition": [
    "cur_node",
    "fusible_partition",
    "partitioned_nodes",
    "non_residual_inputs",
    "graph"
  ],
  "_find_quantizable_kgen_partitions": [
    "graph",
    "cask_fusible_partitions"
  ],
  "find_fusible_partitions": [
    "graph",
    "partitioned_nodes",
    "non_residual_inputs"
  ],
  "get_skipped_output_layers": [
    "graph",
    "partially_quantizable_nodes"
  ],
  "find_quantizable_nodes": [
    "graph",
    "nodes_to_quantize",
    "partitioned_nodes",
    "quantizable_op_types"
  ],
  "find_hardcoded_patterns": [
    "graph"
  ],
  "find_layer_norm_partitions": [
    "graph"
  ],
  "find_non_quantizable_partitions_from_patterns": [
    "graph"
  ],
  "setup_mappings": [
    "model"
  ],
  "get_consumer_nodes": [
    "model",
    "tensor_name"
  ],
  "get_producer_nodes": [
    "model",
    "tensor_name"
  ],
  "get_unique_consumer_node": [
    "model",
    "tensor_name"
  ],
  "get_cast_to_type": [
    "cast_node"
  ],
  "walk_subgraphs_recursive": [
    "graph",
    "callback",
    "parent_node",
    "is_subgraph"
  ],
  "get_op_types_not_supported_in_low_precision": [
    "model",
    "min_opset",
    "low_precision_type"
  ],
  "ReferenceRunner": {
    "__init__": [
      "self",
      "model",
      "providers",
      "trt_plugins"
    ],
    "_prepare_ep_list_with_trt_plugin_path": [
      "self",
      "providers",
      "trt_plugins"
    ],
    "_load_inputs_from_json": [
      "self",
      "input_data_path"
    ],
    "_load_inputs_from_npz": [
      "self",
      "input_data_path"
    ],
    "_validate_inputs": [
      "self",
      "data_loader"
    ],
    "_load_inputs": [
      "self",
      "inputs"
    ],
    "run": [
      "self",
      "inputs"
    ]
  },
  "GraphSanitizer": {
    "__init__": [
      "self",
      "model",
      "min_opset",
      "max_ir_version",
      "trt_plugins",
      "trt_plugins_precision"
    ],
    "sanitize": [
      "self"
    ],
    "convert_fp64_to_fp32": [
      "self"
    ],
    "ensure_custom_ops_precision": [
      "self"
    ],
    "find_custom_nodes": [
      "self"
    ],
    "remove_disconnected_outputs": [
      "self"
    ],
    "convert_opset": [
      "self"
    ],
    "set_ir_version": [
      "self",
      "max_ir_version"
    ],
    "replace_layernorm_pattern": [
      "self"
    ],
    "ensure_graph_name_exists": [
      "self"
    ],
    "duplicate_shared_constants": [
      "self"
    ],
    "_match_layernorm_pattern": [
      "self",
      "mean_node"
    ],
    "sanitize_io_casts": [
      "self"
    ],
    "_create_layernorm_node": [
      "self",
      "pattern"
    ],
    "_find_insertion_point": [
      "self",
      "input_name"
    ],
    "_remove_nodes": [
      "self",
      "nodes_to_remove"
    ],
    "_update_opset_version": [
      "self"
    ],
    "_get_initializer_value": [
      "self",
      "name",
      "return_array"
    ],
    "_convert_fp64_initializers": [
      "self"
    ],
    "_convert_fp64_io_types": [
      "self"
    ],
    "_convert_fp64_nodes": [
      "self"
    ],
    "cleanup_model": [
      "self"
    ],
    "replace_custom_domain_nodes": [
      "self"
    ]
  },
  "PrecisionTypes": [],
  "InputIndexTracker": {},
  "InitializerConsumerTracker": {},
  "PRECISION_MAP": [],
  "ONNX_TYPES": [],
  "OP_TYPES_NOT_SUPPORTED_IN_LOW_PRECISION": [],
  "SKIP_LOW_PRECISION_MAPPING_FP16": [],
  "SKIP_LOW_PRECISION_MAPPING_BF16": [],
  "PrecisionConverter": {
    "__init__": [
      "self",
      "model",
      "value_info_map",
      "initializer_map",
      "node_to_init_map",
      "keep_io_types",
      "low_precision_type",
      "init_conversion_max_bytes",
      "custom_ops",
      "min_opset",
      "max_ir_version",
      "trt_plugins",
      "tensor_block_dict"
    ],
    "convert": [
      "self",
      "high_precision_nodes",
      "low_precision_nodes"
    ],
    "_ensure_types_are_defined": [
      "self"
    ],
    "_clear_types_and_shapes_recursive": [
      "self",
      "graph",
      "is_subgraph"
    ],
    "_propagate_types_shapes_custom_ops": [
      "self",
      "model"
    ],
    "_is_bf16": [
      "self",
      "type"
    ],
    "_is_fp16": [
      "self",
      "type"
    ],
    "_is_fp32": [
      "self",
      "type"
    ],
    "_get_node_initializers_map": [
      "self"
    ],
    "_is_castable_tensor": [
      "self",
      "tensor_name"
    ],
    "_is_empty_tensor": [
      "self",
      "tensor_name"
    ],
    "_filter_unsupported_op_types": [
      "self",
      "high_precision_nodes",
      "low_precision_nodes"
    ],
    "_get_tensors_to_cast": [
      "self",
      "low_precision_nodes",
      "high_precision_tensors"
    ],
    "_convert_initializers": [
      "self",
      "low_precision_nodes",
      "high_precision_nodes"
    ],
    "_convert_initializers_recursive": [
      "self",
      "low_precision_nodes",
      "high_precision_nodes"
    ],
    "_convert_initializer_data": [
      "self",
      "init",
      "from_type",
      "to_type"
    ],
    "_cast_initializer": [
      "self",
      "init",
      "from_type",
      "to_type",
      "low_precision_nodes",
      "high_precision_nodes"
    ],
    "_replace_tensor_name": [
      "self",
      "consumers",
      "original_tensor_name",
      "new_tensor_name"
    ],
    "_bypass_cast_node": [
      "self",
      "node"
    ],
    "_remove_preexisting_casts": [
      "self"
    ],
    "_add_cast": [
      "self",
      "tensor_name",
      "cast_to",
      "exclude_consumers",
      "tensor_to_consumers",
      "tensor_to_producers"
    ],
    "_cleanup": [
      "self"
    ],
    "_cleanup_no_consumer_nodes": [
      "self"
    ],
    "_cleanup_pre_output_same_type_cast": [
      "self"
    ],
    "_is_same_type_cast": [
      "self",
      "node"
    ],
    "_is_sequential_cast": [
      "self",
      "node"
    ],
    "_remove_redundant_casts": [
      "self"
    ],
    "_fix_network_output_names": [
      "self"
    ],
    "_sanity_check": [
      "self"
    ],
    "_get_tensor_type": [
      "self",
      "tensor_name"
    ],
    "_convert_constant_values": [
      "self",
      "const_node",
      "cast_node"
    ],
    "_is_foldable_constant_cast_pattern": [
      "self",
      "node"
    ],
    "_sanitize_model": [
      "self"
    ],
    "_create_skip_inputs_mapping": [
      "self",
      "tensor_block_dict"
    ],
    "_should_skip_low_precision_input_conversion": [
      "self",
      "node",
      "input_name"
    ]
  },
  "DEFAULT_DATA_MAX": [],
  "DEFAULT_INIT_MAX": [],
  "LATEST_IR_VERSION_SUPPORTED_BY_ORT": [],
  "convert_to_mixed_precision": [
    "onnx_path",
    "low_precision_type",
    "nodes_to_exclude",
    "op_types_to_exclude",
    "nodes_to_include",
    "op_types_to_include",
    "data_max",
    "init_max",
    "keep_io_types",
    "calibration_data",
    "custom_rule",
    "init_conversion_max_bytes",
    "providers",
    "trt_plugins",
    "trt_plugins_precision",
    "max_depth_of_reduction",
    "opset"
  ],
  "convert_to_f16": [
    "model",
    "low_precision_type",
    "keep_io_types",
    "op_block_list",
    "tensor_block_dict",
    "trt_plugins"
  ],
  "NodeRuleBase": {
    "_check_inner": [
      "self",
      "node"
    ],
    "_log_skipped": [
      "self",
      "node"
    ],
    "check": [
      "self",
      "node"
    ]
  },
  "DisabledNodeNameRegexRule": {
    "__init__": [
      "self",
      "disabled_node_name_regex"
    ],
    "_check_inner": [
      "self",
      "node"
    ]
  },
  "DisabledOpTypes": {
    "__init__": [
      "self",
      "op_types_to_exclude"
    ],
    "_check_inner": [
      "self",
      "node"
    ]
  },
  "IncludeNodeNameRegexRule": {
    "_log_skipped": [
      "self",
      "node"
    ]
  },
  "IncludeOpTypes": {
    "_log_skipped": [
      "self",
      "node"
    ]
  },
  "InitializerRangeRule": {
    "__init__": [
      "self",
      "init_max",
      "node_to_init_map"
    ],
    "_check_inner": [
      "self",
      "node"
    ],
    "_log_skipped": [
      "self",
      "node"
    ]
  },
  "IORangeRule": {
    "__init__": [
      "self",
      "data_max",
      "reference_data",
      "node_to_init_map"
    ],
    "_check_inner": [
      "self",
      "node"
    ],
    "_log_skipped": [
      "self",
      "node"
    ]
  },
  "DepthOfReductionRule": {
    "__init__": [
      "self",
      "max_depth_of_reduction",
      "reference_data",
      "node_to_init_map",
      "initializer_map"
    ],
    "_get_tensor_shape": [
      "self",
      "tensor_name"
    ],
    "_log_skipped": [
      "self",
      "node"
    ],
    "_check_inner": [
      "self",
      "node"
    ]
  },
  "NodeClassifier": {
    "__init__": [
      "self",
      "model",
      "node_to_init_map",
      "initializer_map",
      "nodes_to_exclude",
      "op_types_to_exclude",
      "nodes_to_include",
      "op_types_to_include",
      "custom_rule",
      "data_max",
      "init_max",
      "max_depth_of_reduction",
      "custom_ops_low_precision_nodes"
    ],
    "_gen_exclude_node_rules": [
      "self",
      "reference_data"
    ],
    "_gen_include_node_rules": [
      "self"
    ],
    "run": [
      "self",
      "ref_outputs_dict"
    ]
  },
  "KIMI_K2_REPO_ID": [],
  "KIMI_K2_PACKAGE_NAME": [],
  "REMOVE_THINK_CHAT_TEMPLATE": [],
  "calibrate_frequent_vocab": [
    "tokenizer",
    "text",
    "target_vocab_size",
    "output_file"
  ],
  "get_default_attention_mask_and_position_ids": [
    "input_ids"
  ],
  "TreeNode": {
    "__init__": [
      "self",
      "value",
      "children"
    ]
  },
  "Tree": {
    "__init__": [
      "self",
      "tree_paths"
    ],
    "create_tree": [
      "self",
      "tree_paths"
    ],
    "create_attention_mask": [
      "self"
    ]
  },
  "ResBlock": {
    "__init__": [
      "self",
      "hidden_size",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AcceptanceRateValidation": {
    "__init__": [
      "self",
      "model",
      "tokenizer"
    ],
    "tokenize": [
      "self",
      "prompt"
    ],
    "get_ground_truth": [
      "self",
      "input_ids",
      "osl"
    ],
    "check_draft": [
      "self",
      "ground_truth",
      "input_ids",
      "draft_tokens"
    ],
    "check_data_consistency_across_ranks": [
      "self",
      "data",
      "group",
      "fail_when_mismatch"
    ],
    "validate": [
      "self",
      "osl",
      "prompt",
      "input_ids",
      "ground_truth",
      "steps",
      "tree_paths"
    ]
  },
  "temporary_set_config_value": [
    "config",
    "field",
    "value"
  ],
  "_patch_dynamic_cache_compatibility": [],
  "_import_module_from_path": [
    "module_path",
    "module_name",
    "package_name"
  ],
  "_setup_kimi_k2_decoder": [],
  "SpeculativeDecodingModeRegistry": [],
  "MedusaModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ]
  },
  "EagleModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ]
  },
  "kimik2_eagle_default_config": [],
  "eagle3_default_config": [],
  "eagle_mtp_default_config": [],
  "EAGLE1_DEFAULT_CFG": [],
  "EAGLE3_DEFAULT_CFG": [],
  "EAGLE_MTP_DEFAULT_CFG": [],
  "MedusaConfig": {},
  "EagleConfig": {},
  "convert": [
    "model",
    "mode"
  ],
  "EagleModel": {
    "_setup": [
      "self"
    ],
    "modify": [
      "self",
      "eagle_offline",
      "eagle_hidden_state_distillation",
      "eagle_self_logit_distillation",
      "eagle_freeze_base_model",
      "eagle_report_acc",
      "eagle_reuse_base_decoder",
      "eagle_loss_decay_factor",
      "eagle_architecture_config",
      "eagle_decoder_type"
    ]
  },
  "make_causal_mask": [
    "input_ids_shape",
    "dtype",
    "device",
    "past_key_values_length"
  ],
  "expand_mask": [
    "mask",
    "dtype",
    "tgt_len"
  ],
  "EagleDMRegistry": [],
  "convert_to_eagle_model": [
    "model",
    "config"
  ],
  "restore_eagle_model": [
    "model",
    "config",
    "metadata"
  ],
  "default_eagle_config": [],
  "default_kimik2_eagle_config": [],
  "MedusaDMRegistry": [],
  "convert_to_medusa_model": [
    "model",
    "config"
  ],
  "restore_medusa_model": [
    "model",
    "config",
    "metadata"
  ],
  "MedusaModel": {
    "_setup": [
      "self"
    ],
    "modify": [
      "self",
      "medusa_num_heads",
      "medusa_num_layers"
    ]
  },
  "MedusaLayer": {
    "__init__": [
      "self",
      "config",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MedusaHead": {
    "__init__": [
      "self",
      "config",
      "vocab_size",
      "num_layers",
      "parallel_output"
    ],
    "forward": [
      "self",
      "x"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "_DynamicMedusaGPTModel": {
    "_setup": [
      "self"
    ],
    "modify": [
      "self",
      "medusa_num_heads",
      "medusa_num_layers",
      "medusa_freeze_base_model",
      "medusa_report_acc"
    ],
    "_base_model_forward": [
      "self"
    ],
    "_medusa_forward": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ],
    "pseudo_speculative_generate": [
      "self"
    ]
  },
  "dict_to_config": [
    "architecture_config",
    "use_cpu_initialization",
    "fp16",
    "bf16",
    "sequence_parallel"
  ],
  "mcore_version_higher_than": [
    "target_version"
  ],
  "logits_kld_loss": [
    "logits",
    "gt_logits",
    "mapping"
  ],
  "right_padding": [
    "input_ids",
    "hidden_states"
  ],
  "set_multi_step_attention_mask": [
    "attn_mask",
    "step"
  ],
  "ParallelDraft": {
    "__init__": [
      "self",
      "config",
      "vocab_size",
      "num_heads",
      "num_layers",
      "parallel_output"
    ],
    "forward": [
      "self",
      "x"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "EagleLanguageModelEmbedding": {
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "EagleTransformerBlock": {
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "EagleModule": {
    "__init__": [
      "self",
      "config",
      "rotary_pos_emb",
      "bias"
    ],
    "_get_eagle_transformer_layer_spec": [
      "self",
      "config"
    ],
    "_eagle3_layer_forward_hook": [
      "self",
      "module",
      "input",
      "output"
    ],
    "_eagle3_attention_forward_pre_hook": [
      "self",
      "module",
      "input_layernorm_output"
    ],
    "forward": [
      "self",
      "embeddings",
      "hidden_states",
      "attention_mask",
      "rotary_pos_emb",
      "inference_params",
      "packed_seq_params",
      "inference_context",
      "extra_block_kwargs"
    ]
  },
  "_DynamicEagleGPTModel": {
    "_set_default_aux_hidden_state_layers": [
      "self"
    ],
    "_transformer_layer_forward_hook": [
      "self",
      "module",
      "input",
      "output"
    ],
    "_setup": [
      "self"
    ],
    "modify": [
      "self",
      "eagle_offline",
      "eagle_hidden_state_distillation",
      "eagle_self_logit_distillation",
      "eagle_freeze_base_model",
      "eagle_report_acc",
      "eagle_reuse_base_decoder",
      "eagle_loss_decay_factor",
      "eagle_architecture_config",
      "eagle_decoder_type"
    ],
    "_get_eagle_input_hidden_states": [
      "self",
      "hidden_states",
      "apply_fc"
    ],
    "_get_eagle_module_inputs": [
      "self",
      "input_ids",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "ttt_step"
    ],
    "_compute_eagle_loss": [
      "self",
      "logits",
      "labels",
      "eagle_logits"
    ],
    "_base_model_forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "decoder_input",
      "inference_params",
      "packed_seq_params",
      "extra_block_kwargs",
      "return_eagle_inputs"
    ],
    "_eagle_forward": [
      "self",
      "eagle_inputs",
      "output_weight",
      "inference_params",
      "packed_seq_params",
      "inference_context",
      "extra_block_kwargs"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "decoder_input",
      "labels",
      "inference_params",
      "packed_seq_params",
      "extra_block_kwargs",
      "return_eagle_inputs",
      "ttt_steps"
    ],
    "pseudo_speculative_generate": [
      "self",
      "input_ids",
      "steps"
    ]
  },
  "MegatronARValidation": {
    "get_ground_truth": [
      "self",
      "input_ids",
      "osl"
    ]
  },
  "IGNORE_TOKEN_ID": [],
  "HFMedusaModel": {
    "modify": [
      "self",
      "medusa_num_heads",
      "medusa_num_layers"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "cache_position",
      "logits_to_keep",
      "freeze_base_model",
      "medusa_heads_coefficient",
      "medusa_decay_coefficient"
    ]
  },
  "HFEagleModel": {
    "_base_model": [
      "self"
    ],
    "_base_model_embeddings": [
      "self"
    ],
    "_base_model_lm_head": [
      "self"
    ],
    "_base_llm_config": [
      "self"
    ],
    "_find_base_model_parts": [
      "self"
    ],
    "_set_default_aux_hidden_state_layers": [
      "self"
    ],
    "_collect_aux_hidden_states_forward_hook": [
      "self",
      "module",
      "input",
      "output"
    ],
    "pop_and_gather_aux_hiddens": [
      "self"
    ],
    "_get_eagle_device": [
      "self"
    ],
    "modify": [
      "self",
      "eagle_offline",
      "eagle_hidden_state_distillation",
      "eagle_self_logit_distillation",
      "eagle_freeze_base_model",
      "eagle_report_acc",
      "eagle_reuse_base_decoder",
      "eagle_loss_decay_factor",
      "eagle_architecture_config",
      "eagle_decoder_type"
    ],
    "_get_ttt_attention_mask": [
      "self",
      "batch_size",
      "seq_length",
      "ttt_step"
    ],
    "_prepare_decoder_attention_mask": [
      "self",
      "attention_mask",
      "input_shape",
      "inputs_embeds",
      "past_key_values_length"
    ],
    "_get_eagle_module_inputs": [
      "self",
      "input_ids",
      "eagle_input_hidden_states",
      "attention_mask",
      "position_ids",
      "eagle_cache"
    ],
    "_compute_ttt_attention_mask": [
      "self",
      "batch_size",
      "seq_length",
      "ttt_step"
    ],
    "_llm_or_vlm_embedding": [
      "self",
      "input_ids",
      "kwargs"
    ],
    "_base_model_forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "freeze_base_model",
      "labels"
    ],
    "_map_logits_to_draft_vocab": [
      "self",
      "full_logits"
    ],
    "_eagle_forward": [
      "self",
      "eagle_input_hidden_states",
      "inputs_embeds",
      "attention_mask",
      "position_ids",
      "eagle_cache"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "cache_position",
      "logits_to_keep",
      "loss_mask"
    ],
    "_eagle_loss": [
      "self",
      "base_model_logits",
      "eagle_logits",
      "loss_mask"
    ],
    "pseudo_speculative_generate": [
      "self",
      "input_ids",
      "steps"
    ]
  },
  "HFARValidation": {
    "get_ground_truth": [
      "self",
      "input_ids",
      "osl"
    ]
  },
  "DistillationModel": {
    "_setup": [
      "self"
    ],
    "modify": [
      "self",
      "teacher_model",
      "criterion",
      "loss_balancer",
      "expose_minimal_state_dict"
    ],
    "teacher_model": [
      "self"
    ],
    "loss_modules": [
      "self"
    ],
    "loss_balancer": [
      "self"
    ],
    "hide_teacher_model": [
      "self",
      "enable"
    ],
    "hide_loss_modules": [
      "self",
      "enable"
    ],
    "only_teacher_forward": [
      "self",
      "enable"
    ],
    "only_student_forward": [
      "self",
      "enable"
    ],
    "train": [
      "self",
      "mode"
    ],
    "state_dict": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "forward": [
      "self"
    ],
    "compute_kd_loss": [
      "self",
      "student_loss",
      "loss_reduction_fn",
      "skip_balancer"
    ]
  },
  "student_output_capture_fwd_hook": [
    "module",
    "input",
    "output"
  ],
  "teacher_output_capture_fwd_hook": [
    "module",
    "input",
    "output"
  ],
  "LogitsDistillationLoss": {
    "__init__": [
      "self",
      "temperature",
      "reduction"
    ],
    "forward": [
      "self",
      "logits_s",
      "logits_t"
    ]
  },
  "MFTLoss": {
    "__init__": [
      "self",
      "temperature",
      "threshold",
      "reduction"
    ],
    "forward": [
      "self",
      "logits_s",
      "logits_t",
      "labels"
    ],
    "_prepare_corrected_distributions": [
      "self",
      "logits",
      "labels",
      "threshold",
      "apply_threshold_to_all"
    ]
  },
  "MGDLoss": {
    "__init__": [
      "self",
      "num_student_channels",
      "num_teacher_channels",
      "alpha_mgd",
      "lambda_mgd"
    ],
    "_loss_fn": [
      "self",
      "out_s",
      "out_t"
    ],
    "forward": [
      "self",
      "out_s",
      "out_t"
    ]
  },
  "STUDENT_LOSS_KEY": [],
  "DistillationLossBalancer": {
    "__init__": [
      "self"
    ],
    "set_student_loss_reduction_fn": [
      "self",
      "student_loss_reduction_fn"
    ],
    "forward": [
      "self",
      "loss"
    ]
  },
  "StaticLossBalancer": {
    "__init__": [
      "self",
      "kd_loss_weight"
    ],
    "forward": [
      "self",
      "loss"
    ]
  },
  "export": [
    "model"
  ],
  "DistillModeRegistry": [],
  "KnowledgeDistillationModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "export_mode": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ],
    "update_for_new_mode": [
      "self"
    ],
    "save_mode_in_state": [
      "self"
    ]
  },
  "ExportStudentModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "is_export_mode": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ],
    "save_mode_in_state": [
      "self"
    ]
  },
  "_convert_for_kd": [
    "model",
    "config"
  ],
  "_reset_kd_state_config": [
    "model",
    "config",
    "metadata"
  ],
  "_export_student": [
    "model",
    "config"
  ],
  "Criterion": [],
  "KDLossConfig": {
    "model_config": [],
    "format_criterion": [
      "cls",
      "criterion"
    ],
    "model_dump": [
      "self"
    ],
    "_strict_validate": [
      "self"
    ]
  },
  "ExportStudentConfig": {},
  "DistillationDMRegistry": [],
  "DistillationConfig": {
    "__post_init__": [
      "self"
    ],
    "parse_intermediate_entry": [
      "entry"
    ]
  },
  "setup_distillation_config": [
    "config_or_path",
    "student_cfg",
    "teacher_cfg"
  ],
  "_adjust_layer_index_for_pp": [
    "submodule_name",
    "model_cfg"
  ],
  "BaseLoss": {
    "__init__": [
      "self",
      "model_config",
      "projection_layer"
    ],
    "pre_forward": [
      "self",
      "predictions",
      "targets"
    ],
    "post_forward": [
      "self",
      "loss",
      "tp_reduce",
      "is_sequence_parallel"
    ]
  },
  "MSELoss": {
    "forward": [
      "self",
      "predictions",
      "targets"
    ]
  },
  "HiddenStateCosineLoss": {
    "__init__": [
      "self",
      "model_config",
      "projection_layer"
    ],
    "forward": [
      "self",
      "predictions",
      "targets"
    ]
  },
  "LogitsKLLoss": {
    "__init__": [
      "self",
      "model_config",
      "temperature",
      "reverse"
    ],
    "forward": [
      "self",
      "predictions",
      "targets"
    ]
  },
  "LogitsAndIntermediatesLossBalancer": {
    "__init__": [
      "self",
      "kd_loss_scale",
      "skip_original_loss"
    ],
    "forward": [
      "self",
      "loss_dict"
    ]
  },
  "ProjectionLayer": {
    "__init__": [
      "self",
      "student_config",
      "teacher_config"
    ],
    "forward": [
      "self",
      "student_tensor"
    ],
    "_init_weights": [
      "self",
      "module"
    ]
  },
  "_AllReduce": {
    "forward": [
      "ctx",
      "op",
      "group",
      "tensor"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "all_reduce_autograd": [
    "tensor",
    "op",
    "group"
  ],
  "adjust_distillation_model_for_mcore": [
    "model",
    "distill_cfg"
  ],
  "get_tensor_shapes_adjust_fn_for_distillation": [
    "model"
  ],
  "KDTrainer": {
    "__init__": [
      "self"
    ],
    "_convert_to_distillation_model": [
      "self"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs"
    ],
    "save_model": [
      "self",
      "output_dir",
      "_internal_call"
    ],
    "train": [
      "self"
    ]
  },
  "LMLogitsLoss": {
    "forward": [
      "self",
      "out_student",
      "out_teacher"
    ]
  },
  "convert_to_peft_model": [
    "model",
    "config"
  ],
  "restore_peft_model": [
    "model",
    "config",
    "metadata"
  ],
  "replace_lora_module": [
    "model",
    "version",
    "config",
    "registry"
  ],
  "export_peft_model": [
    "model",
    "config"
  ],
  "restore_export_peft_model": [
    "model",
    "config",
    "metadata"
  ],
  "update_peft_metadata": [
    "model",
    "config",
    "metadata"
  ],
  "add_adapter": [
    "model",
    "config"
  ],
  "_iter_lora_modules": [
    "model",
    "layer_patterns"
  ],
  "_set_base_requires_grad": [
    "model"
  ],
  "_iter_adapter_names": [
    "module",
    "adapter_patterns"
  ],
  "_set_lora_requires_grad": [
    "model"
  ],
  "freeze_lora_weights": [
    "model"
  ],
  "unfreeze_lora_weights": [
    "model"
  ],
  "_update_lora_grads": [
    "model",
    "config"
  ],
  "update_model": [
    "model",
    "config"
  ],
  "is_peft_model": [
    "model"
  ],
  "_set_adapter_state": [
    "model",
    "enable_state",
    "layer_patterns",
    "adapter_patterns"
  ],
  "disable_adapters": [
    "model",
    "layers_to_disable",
    "adapters_to_disable"
  ],
  "enable_adapters": [
    "model",
    "layers_to_enable",
    "adapters_to_enable"
  ],
  "is_megatron_core_model": [
    "model"
  ],
  "PEFTModeRegistry": [],
  "PEFTModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "export_mode": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ],
    "update_for_save": [
      "self"
    ],
    "update_for_new_mode": [
      "self"
    ]
  },
  "ExportPEFTModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "is_export_mode": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ]
  },
  "InitRuntimeType": [],
  "_qualname": [
    "fn"
  ],
  "InitField": [],
  "PEFTAttributeConfig": {
    "_parse_init_callable": [
      "cls",
      "v"
    ],
    "validate_init_method": [
      "cls",
      "v"
    ],
    "validate_rank": [
      "cls",
      "v"
    ],
    "validate_scale": [
      "cls",
      "v"
    ]
  },
  "PEFTAdapterCfgType": [],
  "PEFTConfig": {
    "validate_adapter_type": [
      "cls",
      "v"
    ],
    "validate_adapter_cfg": [
      "cls",
      "v"
    ]
  },
  "ExportPEFTConfig": {},
  "CUSTOM_MODEL_PLUGINS": [],
  "register_custom_model_plugins_on_the_fly": [
    "model"
  ],
  "LoRAModule": {
    "_setup": [
      "self"
    ],
    "adapter_names": [
      "self"
    ],
    "_register_adapter": [
      "self",
      "adapter_name",
      "lora_a",
      "lora_b",
      "rank",
      "scale",
      "enable"
    ],
    "update_layer_lora": [
      "self",
      "adapter_name",
      "attr_config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LoRAModuleRegistry": [],
  "DEFAULT_LORA_RANK": [],
  "DEFAULT_SCALE": [],
  "megatron_replace_lora_module_hook": [
    "model"
  ],
  "_MegatronParallelLoRABase": {
    "_register_adapter_with_device": [
      "self",
      "adapter_name",
      "lora_a",
      "lora_b",
      "rank",
      "scale",
      "enable"
    ]
  },
  "_LoRAMegatronColumnParallelLinear": {
    "update_layer_lora": [
      "self",
      "adapter_name",
      "attr_config"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "_LoRAMegatronRowParallelLinear": {
    "update_layer_lora": [
      "self",
      "adapter_name",
      "attr_config"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "_QuantLoRAMegatronColumnParallelLinear": {
    "_setup": [
      "self"
    ]
  },
  "_QuantLoRAMegatronRowParallelLinear": {
    "_setup": [
      "self"
    ]
  },
  "_same_tensor": [
    "tensors"
  ],
  "view_as_uint8_if_needed": [
    "tensor"
  ],
  "view_as_float8_e4m3fn_if_needed": [
    "tensor"
  ],
  "_shallow_copy_with_field_instantiation": [
    "obj"
  ],
  "_split_model_config_for_tp": [
    "merged_config",
    "split_factor"
  ],
  "_split_model_config_for_pp": [
    "merged_config",
    "split_factor"
  ],
  "_merge_model_configs_to_first_tp": [
    "config",
    "ranks",
    "group"
  ],
  "_model_model_configs_to_first_pp": [
    "model_config",
    "ranks",
    "workspace_path"
  ],
  "postprocess_model_config": [
    "model_config",
    "inference_tensor_parallel",
    "inference_pipeline_parallel",
    "training_pipeline_parallel",
    "workspace_path"
  ],
  "pad_embedding_lm_head": [
    "model_config",
    "padding_factor"
  ],
  "update_lm_head_quantization": [
    "config",
    "lm_head",
    "inference_tensor_parallel"
  ],
  "check_weight_shape_valid": [
    "config",
    "inference_tensor_parallel",
    "training_tensor_parallel"
  ],
  "postprocess_tensors": [
    "weights",
    "dtype",
    "force_cpu",
    "force_contiguous",
    "force_non_view"
  ],
  "_convert_model": [
    "model"
  ],
  "convert_to_transformer_engine": [
    "model"
  ],
  "NFSWorkspace": {
    "__init__": [
      "self",
      "workspace_path"
    ],
    "is_initialized": [
      "self"
    ],
    "write_configs_and_weights": [
      "self",
      "config_json",
      "weights"
    ],
    "read_configs_and_weights_from_rank": [
      "self",
      "target_rank"
    ],
    "_get_state_path": [
      "self",
      "target_rank"
    ],
    "_clean_up": [
      "self"
    ]
  },
  "get_tensors_parallel": [
    "tensor",
    "ranks",
    "group"
  ],
  "get_configs_parallel": [
    "config",
    "ranks",
    "group",
    "workspace_path"
  ],
  "MODEL_NAME_TO_HF_ARCH_MAP": [],
  "is_tensorrt_llm_0_8_or_9": [],
  "_find_layernorm_type": [
    "model_config"
  ],
  "convert_to_tensorrt_llm_config": [
    "model_config",
    "quant_config",
    "hf_config"
  ],
  "prepare_enc_dec_export_dir": [
    "tensorrt_llm_config",
    "export_root"
  ],
  "prepare_t5_decoder_layer": [
    "layer_config",
    "model_config",
    "enc_dec",
    "layers"
  ],
  "HF_CONFIG_MAP": [],
  "MODEL_NAME_TO_TYPE": [],
  "__doc__": [],
  "get_model_type": [
    "model"
  ],
  "is_multimodal_model": [
    "model"
  ],
  "get_language_model_from_vl": [
    "model"
  ],
  "MCORE_CONFIG_MAP": [],
  "convert_hf_quant_config_format": [
    "input_config"
  ],
  "get_scaling_factor_from_weight": [
    "weight",
    "group_size"
  ],
  "maybe_transpose_expert_weight_dimensions": [
    "weight",
    "weight_scale",
    "is_bmm_expert_weight"
  ],
  "resmooth_and_get_scale": [
    "merged_weights",
    "pre_quant_scales",
    "ranks",
    "group_size",
    "new_pre_quant_scale",
    "quantization"
  ],
  "adjust_attn_amax_values": [
    "module"
  ],
  "get_scaling_factor": [
    "quantizer"
  ],
  "get_activation_scaling_factor": [
    "module",
    "input_quantizer_name"
  ],
  "get_weight_scaling_factor": [
    "module",
    "weight_name"
  ],
  "get_weight_scaling_factor_2": [
    "module",
    "weight_name"
  ],
  "get_prequant_scaling_factor": [
    "module"
  ],
  "get_kv_cache_bias": [
    "kv_module"
  ],
  "get_kv_cache_scaling_factor": [
    "kv_module"
  ],
  "get_kv_cache_dtype": [
    "modules"
  ],
  "get_weight_block_size": [
    "module",
    "weight_name"
  ],
  "get_quantization_format": [
    "module"
  ],
  "_prefix_wildcard_summarize_exclude_modules": [
    "unquantized_layers",
    "quantized_layers"
  ],
  "process_layer_quant_config": [
    "layer_config_dict"
  ],
  "pack_int4_in_uint8": [
    "weight",
    "weights_scaling_factor"
  ],
  "to_quantized_weight": [
    "weight",
    "weights_scaling_factor",
    "quantization",
    "weights_scaling_factor2",
    "block_size"
  ],
  "from_quantized_weight": [
    "weight",
    "weights_scaling_factor",
    "quantization",
    "torch_dtype"
  ],
  "postprocess_state_dict": [
    "state_dict",
    "maxbound",
    "quantization",
    "is_modelopt_qlora"
  ],
  "all_items_same": [
    "item_list"
  ],
  "_update_pre_quant_scale": [
    "module",
    "new_pre_quant_scale"
  ],
  "PQS_FUSE_MODULE_MAPPING": [],
  "fuse_prequant_to_linear": [
    "model",
    "fuse_grouped_heads"
  ],
  "_layernorm_uses_weight_plus_one": [
    "module"
  ],
  "fuse_prequant_layernorm": [
    "layernorm_module",
    "modules"
  ],
  "preprocess_linear_fusion": [
    "modules",
    "resmooth_only"
  ],
  "has_mcore": [],
  "GPTModelExporter": {
    "__init__": [
      "self",
      "model",
      "pretrained_model_name_or_path",
      "export_extra_modules",
      "dtype",
      "trust_remote_code",
      "moe_router_dtype"
    ],
    "save_pretrained": [
      "self",
      "save_directory",
      "pretrained_model_name_or_path"
    ],
    "state_dict": [
      "self"
    ],
    "extra_state_dict": [
      "self"
    ],
    "_populate_rule_book": [
      "self"
    ],
    "_get_quantized_state": [
      "self",
      "module",
      "dtype"
    ],
    "_get_quantization_format": [
      "self",
      "module"
    ],
    "_get_weight_scales": [
      "self",
      "quantized_state",
      "qformat"
    ],
    "_name_remapping": [
      "self",
      "module",
      "prefix",
      "skip_output_scale",
      "mapping",
      "dtype"
    ],
    "_gated_mlp_slicing": [
      "self",
      "module",
      "prefix",
      "gate_proj_name",
      "up_proj_name"
    ],
    "_qkv_slicing": [
      "self",
      "module",
      "prefix",
      "q_proj_name",
      "k_proj_name",
      "v_proj_name",
      "k_scale_name",
      "v_scale_name"
    ],
    "_pack_name_remapping": [
      "self",
      "module",
      "prefix",
      "layer_type"
    ],
    "_pack_name_remapping_gpt_oss": [
      "self",
      "module",
      "prefix",
      "layer_type"
    ],
    "_get_medusa_heads_state_dict": [
      "self"
    ],
    "_get_eagle_module_state_dict": [
      "self"
    ],
    "_get_state_dict": [
      "self"
    ]
  },
  "export_mcore_gpt_to_hf": [
    "model",
    "pretrained_model_name_or_path",
    "export_extra_modules",
    "dtype",
    "export_dir",
    "trust_remote_code",
    "moe_router_dtype"
  ],
  "import_mcore_gpt_from_hf": [
    "model",
    "pretrained_model_path",
    "workspace_dir",
    "dtype",
    "trust_remote_code",
    "moe_router_dtype"
  ],
  "_is_enabled_quantizer": [
    "quantizer"
  ],
  "requantize_resmooth_fused_llm_layers": [
    "model"
  ],
  "_export_quantized_weight": [
    "sub_module",
    "dtype",
    "weight_name"
  ],
  "_export_hf_checkpoint": [
    "model",
    "dtype",
    "is_modelopt_qlora"
  ],
  "export_hf_checkpoint": [
    "model",
    "dtype",
    "export_dir",
    "save_modelopt_state"
  ],
  "np_bfloat16": [],
  "_numpy_to_torch": [
    "x"
  ],
  "model_config_to_dict": [
    "model_config"
  ],
  "split_config_and_weights": [
    "config",
    "weights",
    "prefix",
    "layer_config_dict"
  ],
  "_unified_weights_key": [
    "k"
  ],
  "_restore_model_config": [
    "model_config",
    "weights"
  ],
  "restore_model_config": [
    "model_config",
    "weights"
  ],
  "_from_dict": [
    "class_type",
    "data"
  ],
  "model_config_from_dict": [
    "d"
  ],
  "pad_weights": [
    "weights",
    "tp_size"
  ],
  "merge_qkv": [
    "model_config"
  ],
  "merge_gate_fc": [
    "model_config"
  ],
  "pack_linear_weights": [
    "model_config"
  ],
  "QUANTIZATION_NONE": [],
  "QUANTIZATION_FP8": [],
  "QUANTIZATION_INT8_SQ": [],
  "QUANTIZATION_INT8_WO": [],
  "QUANTIZATION_INT4_AWQ": [],
  "QUANTIZATION_W4A8_AWQ": [],
  "QUANTIZATION_NVFP4": [],
  "QUANTIZATION_W4A8_NVFP4_FP8": [],
  "QUANTIZATION_MXFP4": [],
  "QUANTIZATION_W4A8_MXFP4_FP8": [],
  "QUANTIZATION_NVFP4_AWQ": [],
  "QUANTIZATION_FP8_PB_REAL": [],
  "QUANTIZATION_FP8_PB_WO": [],
  "QUANTIZATION_FP8_PC_PT": [],
  "KV_CACHE_FP8": [],
  "KV_CACHE_INT8": [],
  "KV_CACHE_NVFP4": [],
  "KV_CACHE_NVFP4_AFFINE": [],
  "LINEAR_COLUMN": [],
  "LINEAR_ROW": [],
  "LINEAR_GROUP": [],
  "LAYERNORM_DEFAULT": [],
  "LAYERNORM_RMS": [],
  "EmbeddingConfig": {
    "local_vocab_size": [
      "self"
    ],
    "hidden_size": [
      "self"
    ]
  },
  "LayernormConfig": {},
  "LinearConfig": {
    "__del__": [
      "self"
    ]
  },
  "LinearActConfig": {},
  "ConvConfig": {},
  "QKVConfig": {
    "weight": [
      "self"
    ],
    "bias": [
      "self"
    ],
    "activation_scaling_factor": [
      "self"
    ],
    "weights_scaling_factor": [
      "self"
    ],
    "weights_scaling_factor_2": [
      "self"
    ],
    "prequant_scaling_factor": [
      "self"
    ],
    "awq_block_size": [
      "self"
    ]
  },
  "RelativeAttentionTableConfig": {},
  "AttentionConfig": {},
  "MLPConfig": {},
  "ExpertConfig": {},
  "RgLruConfig": {},
  "RecurrentConfig": {},
  "MOEConfig": {
    "fc": [
      "self"
    ]
  },
  "DecoderLayerConfig": {
    "hidden_size": [
      "self"
    ],
    "ffn_hidden_size_local": [
      "self"
    ]
  },
  "MedusaHeadConfig": {},
  "ModelConfig": {
    "vocab_size_padded": [
      "self"
    ],
    "hidden_size": [
      "self"
    ],
    "max_position_embeddings": [
      "self"
    ],
    "num_attention_heads": [
      "self"
    ],
    "num_kv_heads": [
      "self"
    ],
    "hidden_act": [
      "self"
    ]
  },
  "LayerNormType": {
    "LayerNorm": [],
    "RmsNorm": [],
    "GroupNorm": []
  },
  "LayerNormPositionType": {
    "pre_layernorm": [],
    "post_layernorm": []
  },
  "MLPType": {
    "MLP": [],
    "GatedMLP": [],
    "FusedGatedMLP": []
  },
  "torch_to_tensorrt_llm_checkpoint": [
    "model",
    "decoder_type",
    "dtype",
    "inference_tensor_parallel",
    "inference_pipeline_parallel",
    "workspace_path"
  ],
  "export_tensorrt_llm_checkpoint": [
    "model",
    "decoder_type",
    "dtype",
    "export_dir",
    "inference_tensor_parallel",
    "inference_pipeline_parallel",
    "use_nfs_workspace"
  ],
  "get_experts_list": [
    "module",
    "model_type"
  ],
  "get_dtype": [
    "model"
  ],
  "check_model_compatibility": [
    "module_list"
  ],
  "get_transformer_layers": [
    "model"
  ],
  "is_linear": [
    "module"
  ],
  "is_conv": [
    "module"
  ],
  "is_embedding": [
    "module"
  ],
  "build_embedding_config": [
    "module",
    "normalization_constant"
  ],
  "is_layernorm": [
    "module"
  ],
  "build_layernorm_config": [
    "module"
  ],
  "is_decoder_list": [
    "module"
  ],
  "is_attention": [
    "module"
  ],
  "is_mlp": [
    "module"
  ],
  "is_moe": [
    "module"
  ],
  "is_quantlinear": [
    "module"
  ],
  "dup_kv_weight": [
    "v",
    "head_size",
    "num_head",
    "tp_size"
  ],
  "build_qkv": [
    "qkv_modules",
    "model_metadata_config",
    "ext_config",
    "tp_size"
  ],
  "build_linear_config": [
    "module",
    "linear_type"
  ],
  "build_fused_linear_config": [
    "modules",
    "linear_type"
  ],
  "build_attention_config": [
    "module",
    "model_metadata_config",
    "ext_config",
    "tp_size"
  ],
  "_is_qkv": [
    "name"
  ],
  "_get_hidden_act": [
    "act_func"
  ],
  "build_mlp_config": [
    "module",
    "decoder_type",
    "hidden_act",
    "merge_gate_fc"
  ],
  "_get_expert_attr": [
    "experts",
    "export_id",
    "linear_name"
  ],
  "_get_dbrx_expert": [
    "experts",
    "export_id",
    "linear_name"
  ],
  "_build_stacked_linear": [
    "experts",
    "module_name",
    "linear_type",
    "num_experts",
    "expert_getter"
  ],
  "get_expert_linear_names": [
    "module"
  ],
  "set_expert_quantizer_amax": [
    "modules",
    "quantizer_attrs",
    "fallback_value",
    "device"
  ],
  "build_stacked_experts": [
    "experts",
    "linear_names",
    "num_experts",
    "expert_getter"
  ],
  "build_moe_config": [
    "module",
    "decoder_type"
  ],
  "build_conv_config": [
    "module"
  ],
  "is_recurrent": [
    "module"
  ],
  "build_recurrent_config": [
    "module"
  ],
  "_set_layer_config_from_metaconfig": [
    "layer_config",
    "metaconfig"
  ],
  "build_decoder_config": [
    "module",
    "model_metadata_config",
    "decoder_type",
    "tp_size"
  ],
  "build_medusa_heads_config": [
    "model"
  ],
  "_split_fused_qkv_weight_and_scaling": [
    "weight",
    "num_heads",
    "num_kv_heads",
    "training_tp",
    "keep_channel_order"
  ],
  "_update_encoder_decoder_layernorm_config": [
    "model_metadata_config",
    "config",
    "layernorm_config"
  ],
  "_move_input_layernorm_for_noop_attention": [
    "complete_decoder_config"
  ],
  "update_experts_avg_prequant_scale": [
    "experts"
  ],
  "get_experts_linear_names": [
    "model"
  ],
  "model_type_is_enc_dec": [
    "model_type"
  ],
  "get_enc_dec_models": [
    "hf_model",
    "model_type"
  ],
  "get_encoder_config": [
    "encoder_config"
  ],
  "get_enc_dec_token_ids": [
    "decoder_config"
  ],
  "export_hf_vllm_fq_checkpoint": [
    "model",
    "export_dir"
  ],
  "export_most_recent_ckpt": [
    "directory",
    "output_path"
  ],
  "_get_most_recent_subdir": [
    "directory"
  ],
  "_get_most_recent_ckpt": [
    "directory"
  ],
  "LLAMA_EAGLE_SINGLE_LAYER": [],
  "KIMIK2_EAGLE_SINGLE_LAYER": [],
  "_check_valid_sd": [
    "state_dict",
    "eagle_decoder_type",
    "num_hidden_layers"
  ],
  "spec_opt_only": [
    "model"
  ],
  "export_spec_ckpt_state_dict": [
    "model"
  ],
  "export_spec_ckpt_config": [
    "model"
  ],
  "gather_mcore_vllm_fq_quantized_state_dict": [
    "model",
    "state_dict",
    "save_directory"
  ],
  "VllmFqGPTModelExporter": {
    "save_pretrained": [
      "self",
      "save_directory",
      "pretrained_model_name_or_path"
    ],
    "_get_quantization_format": [
      "self",
      "module"
    ]
  },
  "export_mcore_gpt_to_hf_vllm_fq": [
    "model",
    "pretrained_model_name_or_path",
    "export_extra_modules",
    "dtype",
    "export_dir",
    "moe_router_dtype"
  ],
  "deepseek_causal_lm_import": [],
  "GPTModelImporter": {
    "__init__": [
      "self",
      "model",
      "pretrained_model_name_or_path",
      "workspace_dir",
      "dtype",
      "dequantize",
      "trust_remote_code",
      "verbose",
      "moe_router_dtype"
    ],
    "_populate_rule_book": [
      "self"
    ],
    "_get_safetensor": [
      "self",
      "key",
      "parallel_config"
    ],
    "_name_remapping": [
      "self",
      "module",
      "prefix",
      "mapping",
      "parallel_config",
      "dtype"
    ],
    "_gated_mlp_merging": [
      "self",
      "module",
      "prefix",
      "gate_proj_name",
      "up_proj_name",
      "parallel_config"
    ],
    "_qkv_merging": [
      "self",
      "module",
      "prefix",
      "q_proj_name",
      "k_proj_name",
      "v_proj_name",
      "parallel_config"
    ],
    "_unpack_name_remapping": [
      "self",
      "module",
      "prefix",
      "layer_type",
      "parallel_config"
    ],
    "_unpack_name_remapping_gpt_oss": [
      "self",
      "module",
      "prefix",
      "layer_type",
      "parallel_config"
    ],
    "_import_state_dict": [
      "self"
    ]
  },
  "MAX_SAFETENSOR_SIZE": [],
  "PER_RANK_PARTITIONS": [],
  "ParallelConfig": {},
  "COL_TP": [],
  "ROW_TP": [],
  "COL_ETP": [],
  "ROW_ETP": [],
  "PACK_COL_ETP": [],
  "PACK_ROW_ETP": [],
  "PACK_EP": [],
  "REPLICATE": [],
  "CustomModuleMapping": {
    "__init__": [
      "self",
      "func_name",
      "target_name_or_prefix",
      "func_kwargs"
    ]
  },
  "NameRemapping": {
    "__init__": [
      "self",
      "target_name_or_prefix",
      "func_kwargs"
    ]
  },
  "QKVMerging": {
    "__init__": [
      "self",
      "target_name_or_prefix",
      "func_kwargs"
    ]
  },
  "GatedMLPMerging": {
    "__init__": [
      "self",
      "target_name_or_prefix",
      "func_kwargs"
    ]
  },
  "QKVSlicing": {
    "__init__": [
      "self",
      "target_name_or_prefix",
      "func_kwargs"
    ]
  },
  "GatedMLPSlicing": {
    "__init__": [
      "self",
      "target_name_or_prefix",
      "func_kwargs"
    ]
  },
  "PackNameRemapping": {
    "__init__": [
      "self",
      "target_name_or_prefix",
      "func_kwargs"
    ]
  },
  "UnpackNameRemapping": {
    "__init__": [
      "self",
      "target_name_or_prefix",
      "func_kwargs"
    ]
  },
  "PackNameRemappingGPT": {
    "__init__": [
      "self",
      "target_name_or_prefix",
      "func_kwargs"
    ]
  },
  "UnpackNameRemappingGPT": {
    "__init__": [
      "self",
      "target_name_or_prefix",
      "func_kwargs"
    ]
  },
  "save_safetensors": [
    "state_dict",
    "save_directory"
  ],
  "_get_safetensors_file": [
    "pretrained_model_path",
    "key"
  ],
  "_get_safetensor_slices": [
    "pretrained_model_path",
    "key",
    "parallel_config"
  ],
  "_get_dsfp8_weight_scale_inv": [
    "pretrained_model_path",
    "key",
    "parallel_config"
  ],
  "get_safetensor": [
    "pretrained_model_path",
    "key",
    "parallel_config",
    "dequantize"
  ],
  "dequantize_mxfp4_to_bf16": [
    "blocks",
    "scales"
  ],
  "Map": {
    "Dependency": [],
    "__init__": [
      "self"
    ],
    "is_root": [
      "self",
      "node"
    ],
    "is_dependent": [
      "self",
      "node"
    ],
    "root": [
      "self",
      "node"
    ],
    "target": [
      "self",
      "node"
    ],
    "id": [
      "self",
      "node"
    ],
    "is_free": [
      "self",
      "node"
    ],
    "set_free": [
      "self",
      "node",
      "is_free"
    ],
    "priority": [
      "self",
      "node"
    ],
    "__contains__": [
      "self",
      "node"
    ],
    "__iter__": [
      "self"
    ],
    "_get_dependency": [
      "self",
      "node"
    ],
    "link_nodes": [
      "self",
      "node",
      "other_node"
    ],
    "create_root": [
      "self",
      "node",
      "target",
      "id",
      "is_free",
      "priority"
    ],
    "clear": [
      "self"
    ]
  },
  "NodeProcessor": {
    "SymIterator": [],
    "__init__": [
      "self",
      "model",
      "gc",
      "sym_map",
      "dependency_map"
    ],
    "is_special_node": [
      "self",
      "node",
      "target"
    ],
    "reset": [
      "self"
    ],
    "process": [
      "self",
      "node",
      "id",
      "input_nodes"
    ],
    "post_process": [
      "self"
    ],
    "_filtered_named_symbols": [
      "self",
      "target",
      "filter"
    ],
    "named_in_symbols": [
      "self",
      "target"
    ],
    "named_out_symbols": [
      "self",
      "target"
    ],
    "named_searchable_out_symbols": [
      "self",
      "target"
    ],
    "named_dangling_symbols": [
      "self",
      "target"
    ],
    "named_cross_layer_symbols": [
      "self",
      "target"
    ],
    "_is_from_node_list": [
      "cls",
      "target",
      "node_list",
      "gc",
      "check_failed"
    ],
    "_get_node_target": [
      "self",
      "node"
    ],
    "_get_root_target": [
      "self",
      "node"
    ],
    "_identify_in_out_nodes": [
      "self",
      "node"
    ],
    "_disable_node": [
      "self",
      "node"
    ],
    "build_sym_matching": [
      "syms_other",
      "syms2"
    ],
    "_get_root_nodes": [
      "self",
      "nodes"
    ],
    "_synchronize_nodes": [
      "self",
      "nodes",
      "disable"
    ],
    "_create_root": [
      "self",
      "node",
      "id",
      "is_free",
      "priority"
    ],
    "_process_passthrough": [
      "self",
      "node",
      "id",
      "input_nodes"
    ],
    "_process_boundary": [
      "self",
      "node",
      "id",
      "input_nodes"
    ]
  },
  "BoundaryNodeProcessor": {
    "is_special_node": [
      "self",
      "node",
      "target"
    ],
    "process": [
      "self",
      "node",
      "id",
      "input_nodes"
    ]
  },
  "GraphDependencyProcessor": {
    "T": [],
    "__init__": [
      "self",
      "model",
      "gc",
      "sym_map"
    ],
    "register_node_processor": [
      "cls",
      "node_processor_cls"
    ],
    "reset": [
      "self"
    ],
    "process": [
      "self"
    ],
    "_get_constraint_func": [
      "self",
      "node"
    ]
  },
  "FeatureAdaptiveNodeProcessor": {
    "_link_feature_adaptive_node": [
      "self",
      "node",
      "id",
      "input_nodes"
    ],
    "is_special_node": [
      "self",
      "node",
      "target"
    ],
    "_process_if_first_usage_node": [
      "self",
      "node",
      "id",
      "input_nodes"
    ],
    "process": [
      "self",
      "node",
      "id",
      "input_nodes"
    ]
  },
  "FreeNodeProcessor": {
    "is_special_node": [
      "self",
      "node",
      "target"
    ],
    "_process_if_first_usage_node": [
      "self",
      "node",
      "id",
      "input_nodes"
    ]
  },
  "PassthroughUnivariateNodeProcessor": {
    "PASSSTHROUGH_OPS": [],
    "PASSTHROUGH_FUNCTIONALS": [],
    "PASSTHROUGH_MODULES": [],
    "_get_passthrough_targets": [
      "cls"
    ],
    "_get_filtered_list": [
      "cls",
      "filt_fn"
    ],
    "is_shape_preserving": [
      "cls",
      "target",
      "gc"
    ],
    "is_special_node": [
      "self",
      "node",
      "target"
    ],
    "process": [
      "self",
      "node",
      "id",
      "input_nodes"
    ]
  },
  "MultivariateDimensionPreservingNodeProcessor": {
    "OPS": [],
    "_get_supported_targets": [
      "cls"
    ],
    "is_special_node": [
      "self",
      "node",
      "target"
    ],
    "process": [
      "self",
      "node",
      "id",
      "input_nodes"
    ]
  },
  "is_in_slice_range": [
    "slice_obj",
    "num"
  ],
  "SpecialPassthroughNodeProcessor": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "is_special_node": [
      "self",
      "node",
      "target"
    ],
    "process": [
      "self",
      "node",
      "id",
      "input_nodes"
    ]
  },
  "DanglingSymProcessor": {
    "process": [
      "gc",
      "sym_map",
      "has_concrete_args",
      "_strict"
    ]
  },
  "SequentialDepthProcessor": {
    "__init__": [
      "self",
      "gc",
      "sym_map",
      "concrete_args"
    ],
    "process": [
      "self"
    ],
    "_process": [
      "self"
    ],
    "_post_process": [
      "self"
    ],
    "_is_skippable": [
      "self",
      "module"
    ],
    "_is_shape_preserving": [
      "self",
      "target"
    ],
    "_is_shape_preserving_residual_block": [
      "self",
      "module"
    ],
    "_get_tracing_errors": [
      "self"
    ],
    "_set_depth": [
      "self",
      "config"
    ],
    "_check_min_depth_subnet": [
      "self"
    ]
  },
  "analyze_symbols": [
    "model",
    "concrete_args",
    "_strict"
  ],
  "Symbol": {
    "_extra_repr_attrs": [],
    "__init__": [
      "self",
      "is_searchable",
      "is_sortable",
      "cl_type",
      "elastic_dims"
    ],
    "_reset_state": [
      "self"
    ],
    "link_to": [
      "self",
      "sp_parent"
    ],
    "disable": [
      "self",
      "_memo"
    ],
    "_check_sortable": [
      "self",
      "_memo"
    ],
    "parent": [
      "self"
    ],
    "is_searchable": [
      "self"
    ],
    "is_sortable": [
      "self",
      "value"
    ],
    "is_dynamic": [
      "self"
    ],
    "is_constant": [
      "self"
    ],
    "is_free": [
      "self"
    ],
    "cl_type": [
      "self"
    ],
    "is_cross_layer": [
      "self"
    ],
    "is_incoming": [
      "self"
    ],
    "is_outgoing": [
      "self"
    ],
    "is_dangling": [
      "self"
    ],
    "elastic_dims": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SymInfo": {
    "SymDict": [],
    "__init__": [
      "self",
      "is_shape_preserving"
    ],
    "is_shape_preserving": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SymMap": {
    "SymRegisterFunc": [],
    "register": [
      "cls",
      "nn_cls",
      "is_explicit_leaf"
    ],
    "unregister": [
      "cls",
      "nn_cls"
    ],
    "_get_from_registry": [
      "cls",
      "nn_cls"
    ],
    "__init__": [
      "self",
      "model"
    ],
    "__len__": [
      "self"
    ],
    "__bool__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "__iter__": [
      "self"
    ],
    "items": [
      "self"
    ],
    "pop": [
      "self",
      "key"
    ],
    "named_modules": [
      "self"
    ],
    "named_sym_dicts": [
      "self"
    ],
    "named_symbols": [
      "self",
      "key",
      "free",
      "dynamic",
      "searchable",
      "constant"
    ],
    "get_symbol": [
      "self",
      "mod",
      "name"
    ],
    "set_symbol": [
      "self",
      "mod",
      "name",
      "symbol"
    ],
    "prune": [
      "self"
    ],
    "is_shape_preserving": [
      "self",
      "key"
    ],
    "add_sym_info": [
      "self",
      "key",
      "sym_info"
    ],
    "__repr__": [
      "self"
    ]
  },
  "RobustTracer": {
    "is_registered_leaf": [
      "cls",
      "m"
    ],
    "register_leaf": [
      "cls",
      "m"
    ],
    "unregister_leaf": [
      "cls",
      "m"
    ],
    "__init__": [
      "self"
    ],
    "record_call_module": [
      "self",
      "m",
      "e"
    ],
    "is_failed": [
      "self",
      "m"
    ],
    "failure_msg": [
      "self",
      "m"
    ],
    "is_unvisited": [
      "self",
      "m"
    ],
    "is_leaf_module": [
      "self",
      "m",
      "module_qualified_name"
    ],
    "trace": [
      "self",
      "root",
      "concrete_args"
    ],
    "_get_full_kwargs": [
      "self",
      "root",
      "concrete_args"
    ]
  },
  "GraphCollection": {
    "__init__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "is_failed": [
      "self",
      "m"
    ],
    "failure_msg": [
      "self",
      "m"
    ],
    "is_unvisited": [
      "self",
      "m"
    ],
    "recursive_trace": [
      "self",
      "model",
      "concrete_args"
    ]
  },
  "recursive_trace": [
    "model",
    "concrete_args"
  ],
  "SymAttentionHead": {},
  "get_hf_attn_sym_info": [
    "sortable_attn"
  ],
  "get_hf_attn_sym_info_sortable": [
    "mod"
  ],
  "get_hf_attn_sym_info_unsortable": [
    "mod"
  ],
  "ConcatSymbol": {
    "__init__": [
      "self",
      "symbols",
      "cl_type",
      "elastic_dims"
    ],
    "disable": [
      "self",
      "_memo"
    ],
    "_strict_link_to": [
      "self_sym",
      "other"
    ],
    "link_to": [
      "self",
      "other"
    ],
    "input_syms": [
      "self"
    ],
    "is_searchable": [
      "self"
    ],
    "is_constant": [
      "self"
    ],
    "_check_sortable": [
      "self",
      "_memo"
    ]
  },
  "ConcatModule": {
    "__init__": [
      "self",
      "out_sym"
    ],
    "get_sym_info": [
      "self"
    ]
  },
  "ConcatNodeProcessor": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "is_special_node": [
      "self",
      "node",
      "target"
    ],
    "process": [
      "self",
      "node",
      "id",
      "input_nodes"
    ],
    "_flatten_nested_cats": [
      "cls",
      "sym",
      "memo"
    ],
    "post_process": [
      "self"
    ]
  },
  "_get_ndim": [
    "mod"
  ],
  "get_linear_sym_info": [
    "mod"
  ],
  "get_norm_sym_info": [
    "mod"
  ],
  "get_layer_norm_sym_info": [
    "mod"
  ],
  "get_groupnorm_sym_info": [
    "mod"
  ],
  "SymDepth": {
    "_extra_repr_attrs": [],
    "__init__": [
      "self"
    ],
    "is_skippable": [
      "self",
      "idx"
    ],
    "set_skippable": [
      "self",
      "idx",
      "val"
    ],
    "skippable_idxs": [
      "self"
    ],
    "max_depth": [
      "self"
    ],
    "min_depth": [
      "self"
    ],
    "disable": [
      "self",
      "_memo"
    ],
    "link_to": [
      "self",
      "sp_parent"
    ]
  },
  "get_sequential_sym_info": [
    "module"
  ],
  "get_conv_sym_info": [
    "mod"
  ],
  "is_available": [],
  "is_initialized": [],
  "backend": [],
  "size": [
    "group"
  ],
  "rank": [
    "group"
  ],
  "local_rank": [],
  "is_master": [
    "group"
  ],
  "is_last_process": [
    "group"
  ],
  "_serialize": [
    "obj"
  ],
  "_deserialize": [
    "tensor",
    "size"
  ],
  "_broadcast": [
    "tensor",
    "src",
    "group"
  ],
  "broadcast": [
    "obj",
    "src",
    "group"
  ],
  "_allgather": [
    "tensors",
    "tensor",
    "group"
  ],
  "allgather": [
    "obj",
    "group"
  ],
  "allreduce": [
    "obj",
    "reduction",
    "group"
  ],
  "barrier": [
    "group"
  ],
  "master_only": [
    "func"
  ],
  "setup": [
    "timeout"
  ],
  "cleanup": [],
  "DistributedProcessGroup": {
    "__init__": [
      "self",
      "group"
    ],
    "is_initialized": [
      "self"
    ],
    "rank": [
      "self"
    ],
    "world_size": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "get_dist_syncd_obj": [
      "obj",
      "groups",
      "op"
    ]
  },
  "ParallelState": {
    "__init__": [
      "self",
      "data_parallel_group",
      "tensor_parallel_group",
      "expert_model_parallel_group"
    ],
    "__repr__": [
      "self"
    ]
  },
  "get_group": [
    "ranks"
  ],
  "is_dtensor_sharded": [
    "model"
  ],
  "FileLock": {
    "__init__": [
      "self",
      "lockfile_path",
      "all_acquire",
      "poll_time"
    ],
    "try_acquire": [
      "self"
    ],
    "wait": [
      "self"
    ],
    "release": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "NodeTarget": [],
  "_get_node_target": [
    "node",
    "root"
  ],
  "_local_match": [
    "nx",
    "ny",
    "mx",
    "my"
  ],
  "_recursive_match": [
    "nx",
    "ny",
    "mx",
    "my",
    "maps"
  ],
  "match": [
    "module",
    "patterns"
  ],
  "ModelLike": [],
  "ConstructorLike": [],
  "is_parallel": [
    "model"
  ],
  "get_module_device": [
    "module"
  ],
  "param_num": [
    "network",
    "trainable_only",
    "unit"
  ],
  "param_num_from_forward": [
    "model",
    "trainable_only",
    "args",
    "unit"
  ],
  "get_same_padding": [
    "kernel_size"
  ],
  "make_divisible": [
    "v",
    "divisor",
    "min_val"
  ],
  "is_channels_last": [
    "model"
  ],
  "model_to": [
    "model",
    "target_model"
  ],
  "set_submodule": [
    "model",
    "target",
    "target_submodule"
  ],
  "remove_bn": [
    "model"
  ],
  "_preprocess_args": [
    "args"
  ],
  "standardize_named_model_args": [
    "model_or_fw_or_sig",
    "args"
  ],
  "standardize_model_args": [
    "model_or_fw_or_sig",
    "args",
    "use_kwargs"
  ],
  "get_model_attributes": [
    "model"
  ],
  "compare_dict": [
    "dict1",
    "dict2"
  ],
  "unwrap_model": [
    "model",
    "warn",
    "raise_error",
    "msg",
    "force_unwrap"
  ],
  "zero_grad": [
    "model"
  ],
  "standardize_model_like_tuple": [
    "model"
  ],
  "standardize_constructor_args": [
    "constructor_args"
  ],
  "init_model_from_model_like": [
    "model"
  ],
  "run_forward_loop": [
    "model",
    "data_loader",
    "max_iters",
    "collect_func",
    "progress_bar",
    "post_process"
  ],
  "create_param_grad_clear_hook": [
    "param"
  ],
  "get_unwrapped_name": [
    "name",
    "model"
  ],
  "temporarily_remove_accelerate_hook": [
    "module"
  ],
  "bind_forward_method": [
    "module",
    "forward_fn",
    "orig_forward_cache_name"
  ],
  "unpatch_forward_method": [
    "module",
    "orig_forward_cache_name"
  ],
  "GPUMemoryMonitor": {
    "__init__": [
      "self",
      "monitor_interval"
    ],
    "_monitor_loop": [
      "self"
    ],
    "start": [
      "self"
    ],
    "stop": [
      "self"
    ]
  },
  "launch_memory_monitor": [
    "monitor_interval"
  ],
  "list_closest_to_median": [
    "x"
  ],
  "val2list": [
    "val",
    "repeat_time"
  ],
  "val2tuple": [
    "val",
    "min_len",
    "idx_repeat"
  ],
  "stats": [
    "vals"
  ],
  "TreeSpec": {
    "__init__": [
      "self",
      "pytree",
      "names"
    ],
    "_fill_spec": [
      "values",
      "spec"
    ],
    "generate_pytree": [
      "self",
      "values"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__ne__": [
      "self",
      "other"
    ]
  },
  "_check_serializable_keys": [
    "data"
  ],
  "unflatten_tree": [
    "values",
    "tree_spec"
  ],
  "flatten_tree": [
    "pytree",
    "prefix"
  ],
  "import_plugin": [
    "plugin_name",
    "msg_if_missing",
    "verbose",
    "success_msg"
  ],
  "num2hrb": [
    "num",
    "suffix"
  ],
  "_monkeypatched": [
    "obj",
    "name",
    "patch"
  ],
  "_disable_tqdm": [],
  "no_stdout": [],
  "print_rank_0": [],
  "warn_rank_0": [
    "message"
  ],
  "_print_lock": [],
  "atomic_print": [
    "func"
  ],
  "capture_io": [
    "capture_stderr"
  ],
  "silence_matched_warnings": [
    "pattern"
  ],
  "DeprecatedError": {},
  "clear_cuda_cache": [],
  "get_cuda_memory_stats": [
    "device"
  ],
  "report_memory": [
    "name",
    "rank",
    "device"
  ],
  "Timer": {
    "__init__": [
      "self",
      "name"
    ],
    "start": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "type",
      "value",
      "traceback"
    ]
  },
  "AccumulatingTimer": {
    "_accumulated_times": [],
    "_call_counts": [],
    "_prefix": [],
    "__init__": [
      "self",
      "name"
    ],
    "start": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "get_total_time": [
      "cls",
      "name"
    ],
    "get_call_count": [
      "cls",
      "name"
    ],
    "reset": [
      "cls"
    ],
    "report": [
      "cls"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "type",
      "value",
      "traceback"
    ]
  },
  "_get_dataset_samples": [
    "dataset_name",
    "num_samples"
  ],
  "_CustomDataset": {
    "__init__": [
      "self",
      "encodings"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ]
  },
  "get_dataset_dataloader": [
    "dataset_name",
    "tokenizer",
    "batch_size",
    "num_samples",
    "max_sample_length",
    "device",
    "include_labels"
  ],
  "get_supported_datasets": [],
  "get_max_batch_size": [
    "model",
    "max_sample_length",
    "sample_memory_usage_ratio",
    "sample_input_single_batch",
    "enable_grad"
  ],
  "_process_batch": [
    "batch_data",
    "infer_method",
    "max_working_batch_size"
  ],
  "_forward_loop": [
    "model",
    "dataloader"
  ],
  "create_forward_loop": [
    "model",
    "dataset_name",
    "tokenizer",
    "batch_size",
    "num_samples",
    "max_sample_length",
    "device",
    "include_labels",
    "dataloader"
  ],
  "_get_vlm_dataset": [
    "dataset_name",
    "num_samples"
  ],
  "get_supported_vlm_datasets": [],
  "get_vlm_dataset_dataloader": [
    "dataset_name",
    "processor",
    "batch_size",
    "num_samples"
  ],
  "matches_pattern": [
    "name",
    "patterns"
  ],
  "same_device_as": [
    "inputs"
  ],
  "torch_to": [
    "data"
  ],
  "torch_detach": [
    "data"
  ],
  "torch_to_numpy": [
    "inputs"
  ],
  "numpy_to_torch": [
    "np_outputs"
  ],
  "to_empty_if_meta_device": [
    "module"
  ],
  "BaseImageProcessor": {
    "__init__": [
      "self",
      "tokenizer",
      "device"
    ],
    "__call__": [
      "self"
    ],
    "preprocess_function": [
      "self",
      "examples"
    ],
    "collate_function": [
      "self",
      "examples"
    ]
  },
  "MllamaImageProcessor": {
    "preprocess_function": [
      "self",
      "examples"
    ],
    "collate_function": [
      "self",
      "batch"
    ]
  },
  "_get_speech_dataset": [
    "dataset_name",
    "num_samples"
  ],
  "get_supported_speech_datasets": [],
  "get_speech_dataset_dataloader": [
    "dataset_name",
    "processor",
    "batch_size",
    "num_samples",
    "device",
    "dtype"
  ],
  "load_cpp_extension": [
    "name",
    "sources",
    "cuda_version_specifiers",
    "fail_msg",
    "raise_if_failed"
  ],
  "T": [],
  "FSample": [],
  "_get_generator": [
    "seed"
  ],
  "_set_deterministic_seed": [
    "seed"
  ],
  "random": [],
  "choice": [
    "seq"
  ],
  "sample": [],
  "centroid": [
    "seq"
  ],
  "original": [
    "seq"
  ],
  "shuffle": [
    "seq"
  ],
  "_deterministic_seed": [],
  "get_current_memory_info": [],
  "megatron_prefill": [
    "model",
    "input_ids",
    "pixel_values",
    "image_grid_thw",
    "image_sizes"
  ],
  "megatron_generate": [
    "model",
    "input_ids",
    "pixel_values",
    "image_grid_thw",
    "image_sizes",
    "osl",
    "eos_token_id",
    "enable_kv_cache",
    "disable_tqdm",
    "return_dict"
  ],
  "_Encoder": {
    "__init__": [
      "self",
      "tokenizer_name_or_path",
      "json_keys",
      "append_eod",
      "max_sequence_length"
    ],
    "initializer": [
      "self"
    ],
    "encode": [
      "self",
      "json_line"
    ]
  },
  "_Partition": {
    "__init__": [
      "self",
      "vocab_size",
      "json_keys",
      "log_interval",
      "workers"
    ],
    "_print_processing_stats": [
      "self",
      "count",
      "total_doc_len",
      "total_enc_len"
    ],
    "process_json_file": [
      "self",
      "input_file_name",
      "output_dir",
      "encoder"
    ]
  },
  "megatron_preprocess_data": [
    "input_path",
    "output_dir",
    "tokenizer_name_or_path",
    "json_keys",
    "append_eod",
    "max_sequence_length",
    "workers",
    "log_interval"
  ],
  "_get_all_subjects": [],
  "megatron_mmlu": [
    "model",
    "tokenizer",
    "few_shots",
    "percentage",
    "enable_kv_cache"
  ],
  "PatchData": [],
  "PatchMethods": [],
  "PatchManager": {
    "_patch_data_key": [],
    "_patch_cls_key": [],
    "__init__": [
      "self",
      "model"
    ],
    "_get_named_patched_module": [
      "cls",
      "model"
    ],
    "is_patched": [
      "cls",
      "model"
    ],
    "_get_default_patch_data": [
      "self"
    ],
    "get_manager": [
      "cls",
      "model"
    ],
    "patch_data": [
      "self"
    ],
    "patch_data_or_empty": [
      "self"
    ],
    "patch": [
      "self"
    ],
    "unpatch": [
      "self"
    ],
    "reset_before_sample": [
      "self"
    ],
    "call_post_eval": [
      "self",
      "forward_loop"
    ],
    "_hook_pre_sample": [
      "self"
    ],
    "_hook_post_eval": [
      "self",
      "forward_loop"
    ],
    "_hook_pre_forward": [
      "self"
    ],
    "_hook_post__replicate_for_data_parallel": [
      "self"
    ],
    "hooked_forward": [
      "mod"
    ],
    "hooked_train": [
      "mod",
      "mode"
    ],
    "hooked__replicate_for_data_parallel": [
      "mod"
    ],
    "_get_methods_for_patching": [
      "self"
    ],
    "_set_patched_methods": [
      "self"
    ],
    "_unset_patched_methods": [
      "self"
    ]
  },
  "_modelopt_eval_recursion_guard": [
    "model"
  ],
  "prep_for_eval": [
    "model",
    "forward_loop"
  ],
  "MODULE_TYPE_TO_CONSTRAINTS_FUNC": [],
  "ConstraintsRes": [],
  "ConstraintEvalFunc": [],
  "ConstraintInterpolator": {
    "__init__": [
      "self",
      "model",
      "points_funcs",
      "value_func"
    ],
    "_add_point": [
      "self",
      "point"
    ],
    "__call__": [
      "self",
      "pre_computed"
    ]
  },
  "ConstraintsFunc": {
    "__init__": [
      "self",
      "model",
      "constraints",
      "dummy_input",
      "deployment",
      "fast_eval",
      "dp_group"
    ],
    "is_configurable": [
      "model",
      "hparam_suffix"
    ],
    "get_sample_points": [
      "self"
    ],
    "fast_eval": [
      "self",
      "value"
    ],
    "limits": [
      "self",
      "constraints"
    ],
    "effective_limits": [
      "self"
    ],
    "trivial_limit": [
      "self"
    ],
    "get_expanded_limits": [
      "self",
      "constraints"
    ],
    "set_rel_lower_bounds": [
      "self",
      "rel_lower"
    ],
    "_get_params": [
      "self",
      "_"
    ],
    "_get_flops": [
      "self",
      "_"
    ],
    "_get_flops_min_depth": [
      "self",
      "_"
    ],
    "_get_true_latency": [
      "self",
      "_"
    ],
    "_get_latency": [
      "self",
      "precomputed"
    ],
    "constraint_eval_funcs": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "evaluate_constraints": [
      "self"
    ]
  },
  "StatisticsEstimator": {
    "__init__": [
      "self",
      "constraints_func",
      "num_of_samples"
    ],
    "reset": [
      "self"
    ],
    "num_of_collected_samples": [
      "self"
    ],
    "_sample_random_subnets": [
      "self",
      "model"
    ],
    "median": [
      "self",
      "model"
    ],
    "std": [
      "self",
      "model"
    ],
    "median_subnet": [
      "self",
      "model"
    ]
  },
  "get_constraints_func": [
    "model"
  ],
  "search": [
    "model",
    "constraints",
    "dummy_input",
    "config"
  ],
  "profile": [
    "model",
    "dummy_input",
    "constraints",
    "deployment",
    "strict",
    "verbose",
    "use_centroid"
  ],
  "TracedHparamType": [],
  "TracedHpRegistry": {
    "register": [
      "cls",
      "sym_cls"
    ],
    "unregister": [
      "cls",
      "sym_cls"
    ],
    "initialize_from": [
      "cls",
      "sym",
      "hp"
    ],
    "get": [
      "cls",
      "sym"
    ]
  },
  "TracedHp": {
    "initialize_from": [
      "cls",
      "hp"
    ],
    "_initialize_from": [
      "cls",
      "hp"
    ],
    "resolve_dependencies": [
      "self",
      "sym",
      "get_hp"
    ],
    "_resolve_dependencies": [
      "self",
      "sym",
      "get_hp"
    ]
  },
  "batch_norm_ignored_flops": [],
  "inference_flops": [
    "network",
    "dummy_input",
    "data_shape",
    "unit",
    "return_str"
  ],
  "_SearchSpaceUnwrapped": {
    "__init__": [
      "self",
      "model"
    ]
  },
  "select": [
    "model",
    "config",
    "strict"
  ],
  "get_subnet_config": [
    "model",
    "configurable"
  ],
  "_reset_before_sample": [
    "model"
  ],
  "sort_parameters": [
    "model",
    "hps_to_sort",
    "verbose"
  ],
  "print_search_space_summary": [
    "model",
    "skipped_hparams"
  ],
  "_ModeloptOpsState": {
    "_auto_enabled": [],
    "__new__": [
      "cls"
    ],
    "set_modelopt_mode_enabled": [
      "self",
      "enabled"
    ],
    "enabled": [
      "self"
    ]
  },
  "is_modelopt_patches_enabled": [],
  "no_modelopt_patches": {
    "__init__": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "enable_modelopt_patches": {
    "__init__": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "set_modelopt_patches_enabled": {
    "__init__": [
      "self",
      "enabled"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "clone": [
      "self"
    ]
  },
  "replace_forward": [
    "model",
    "new_forward"
  ],
  "sample_and_reset": [
    "model",
    "sample_func"
  ],
  "NASModeRegistry": [],
  "ExportConfig": {},
  "export_searchspace": [
    "model",
    "config"
  ],
  "restore_export": [
    "model",
    "config",
    "metadata"
  ],
  "ExportNASModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "is_export_mode": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ]
  },
  "SampleFunc": [],
  "SearchSpace": {
    "__init__": [
      "self",
      "model",
      "sym_map"
    ],
    "_sym_to_hp": [
      "self",
      "sym"
    ],
    "_should_be_converted": [
      "self",
      "mod"
    ],
    "generate": [
      "self",
      "rules"
    ],
    "sample": [
      "self",
      "sample_func"
    ],
    "sort_parameters": [
      "self",
      "hps_to_sort",
      "verbose"
    ],
    "export": [
      "self",
      "dm_registry"
    ],
    "print_summary": [
      "self",
      "skipped_hparams"
    ]
  },
  "generate_search_space": [
    "model",
    "rules"
  ],
  "MODELOPT_QUEUE_MAXLEN": [],
  "MODELOPT_BN_CALIB_ITERS": [],
  "_get_ratio_list": [],
  "_conv_config": [],
  "_norm_lin_config": [],
  "AutoNASPatchManager": {
    "_get_default_patch_data": [
      "self"
    ],
    "_hook_post_eval": [
      "self",
      "forward_loop"
    ],
    "_is_modelopt_queue_needed": [
      "model"
    ],
    "_reset_bn": [
      "cls",
      "model",
      "forward_loop"
    ],
    "_hook_pre_sample": [
      "self"
    ],
    "sample_during_training": [
      "self"
    ],
    "_hook_pre_forward": [
      "self"
    ]
  },
  "IterativeSearcher": {
    "default_search_config": [
      "self"
    ],
    "default_state_dict": [
      "self"
    ],
    "sanitize_search_config": [
      "self",
      "config"
    ],
    "_sample": [
      "self"
    ],
    "sample": [
      "self"
    ],
    "before_search": [
      "self"
    ],
    "run_search": [
      "self"
    ],
    "after_search": [
      "self"
    ],
    "before_step": [
      "self"
    ],
    "run_step": [
      "self"
    ],
    "after_step": [
      "self"
    ],
    "early_stop": [
      "self"
    ],
    "_configurable_config": [
      "self",
      "model"
    ]
  },
  "RandomSearcher": {
    "sample": [
      "self"
    ]
  },
  "EvolveSearcher": {
    "default_search_config": [
      "self"
    ],
    "default_state_dict": [
      "self"
    ],
    "_mutate": [
      "self",
      "input"
    ],
    "_crossover": [
      "self",
      "inputs"
    ],
    "sample": [
      "self"
    ],
    "before_search": [
      "self"
    ],
    "before_step": [
      "self"
    ],
    "after_step": [
      "self"
    ]
  },
  "convert_searchspace": [
    "model",
    "config",
    "patch_manager_type"
  ],
  "convert_autonas_searchspace": [
    "model",
    "config"
  ],
  "restore_autonas_searchspace": [
    "model",
    "config",
    "metadata"
  ],
  "restore_searchspace": [
    "model",
    "config",
    "metadata",
    "patch_manager"
  ],
  "update_autonas_metadata": [
    "model",
    "config",
    "metadata"
  ],
  "AutoNASModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "next_modes": [
      "self"
    ],
    "export_mode": [
      "self"
    ],
    "search_algorithm": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ],
    "update_for_save": [
      "self"
    ],
    "update_for_new_mode": [
      "self"
    ]
  },
  "DMRegistry": [],
  "ConcatTracedHp": {
    "_choice_combos": [],
    "_get_sum_to_combo": [
      "self"
    ],
    "_set_hp_start_idx": [
      "self"
    ],
    "active": [
      "self",
      "val"
    ],
    "active_slice": [
      "self"
    ],
    "_get_importance": [
      "self"
    ],
    "_split_order": [
      "self",
      "order"
    ],
    "_enforce_order": [
      "self",
      "order"
    ],
    "_resolve_dependencies": [
      "self",
      "sym",
      "get_hp"
    ],
    "reset_choices": [
      "self"
    ]
  },
  "build_concat_hp": [
    "inputs"
  ],
  "DepthHparam": {
    "_resolve_dependencies": [
      "self",
      "sym",
      "get_hp"
    ]
  },
  "wrapped_convert_sync_batchnorm": [
    "module"
  ],
  "SUPPORTED_MODELS": [],
  "_DynamicParallelLinear": {
    "_setup": [
      "self"
    ],
    "_get_weight": [
      "mod",
      "weight"
    ],
    "_get_bias": [
      "mod",
      "bias"
    ]
  },
  "_DynamicColumnParallelLinear": {
    "_setup": [
      "self"
    ]
  },
  "_DynamicRowParallelLinear": {
    "_setup": [
      "self"
    ]
  },
  "_DynamicEmbedding": {
    "_setup": [
      "self"
    ],
    "_get_weight": [
      "mod",
      "weight"
    ]
  },
  "_DynamicLanguageModelEmbedding": {
    "_setup": [
      "self"
    ],
    "export": [
      "self"
    ]
  },
  "_DynamicFusedLayerNorm": {
    "_setup": [
      "self"
    ]
  },
  "_DynamicMLP": {
    "_setup": [
      "self"
    ],
    "modify": [
      "self",
      "ffn_hidden_size_divisor"
    ],
    "export": [
      "self"
    ]
  },
  "expand_head_indices": [
    "heads",
    "hidden_size_per_head"
  ],
  "NumAttentionHeadsHp": {
    "__init__": [
      "self",
      "num_attention_heads",
      "num_query_groups"
    ],
    "num_heads_per_group": [
      "self"
    ],
    "active_slice": [
      "self"
    ]
  },
  "_DynamicQKVColumnParallelLinear": {
    "_setup": [
      "self"
    ],
    "_get_output_size_indices": [
      "self"
    ],
    "_get_weight": [
      "mod",
      "weight"
    ],
    "_get_bias": [
      "mod",
      "bias"
    ]
  },
  "_DynamicProjRowParallelLinear": {
    "_setup": [
      "self"
    ],
    "_get_input_size_indices": [
      "self"
    ],
    "_get_weight": [
      "mod",
      "weight"
    ],
    "_get_bias": [
      "mod",
      "bias"
    ]
  },
  "_DynamicSelfAttention": {
    "_setup": [
      "self"
    ],
    "export": [
      "self"
    ]
  },
  "_DynamicTopKRouter": {
    "_setup": [
      "self"
    ],
    "_get_router_weight": [
      "mod",
      "weight"
    ],
    "_get_slice_by_num_experts": [
      "mod",
      "val"
    ]
  },
  "_DynamicSequentialMLP": {
    "_setup": [
      "self"
    ],
    "export": [
      "self"
    ]
  },
  "_DynamicMoELayer": {
    "_setup": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "modify": [
      "self"
    ],
    "_export_reinit_token_dispatcher": [
      "self"
    ],
    "export": [
      "self"
    ]
  },
  "_DynamicTransformerLayer": {
    "_setup": [
      "self"
    ],
    "modify": [
      "self"
    ],
    "export": [
      "self"
    ]
  },
  "MambaNumHeadsHp": {
    "__init__": [
      "self",
      "nheads",
      "ngroups"
    ],
    "active_slice": [
      "self"
    ]
  },
  "MambaDInnerHp": {
    "__init__": [
      "self",
      "mamba_num_heads",
      "mamba_head_dim"
    ],
    "active": [
      "self"
    ],
    "active_slice": [
      "self"
    ],
    "_get_choices": [
      "self"
    ],
    "reset_choices": [
      "self"
    ],
    "choices": [
      "self"
    ],
    "_resolve_dependencies": [
      "self",
      "sym",
      "get_hp"
    ]
  },
  "_DynamicExtendedRMSNorm": {
    "_setup": [
      "self"
    ],
    "_get_group_size": [
      "mod",
      "value"
    ],
    "_cut_to_active_hidden_size": [
      "mod",
      "value"
    ]
  },
  "_MambaContextParallelProxy": {
    "__init__": [
      "self",
      "mixer",
      "cp"
    ],
    "__getattribute__": [
      "self",
      "name"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ]
  },
  "_DynamicMambaMixer": {
    "_setup": [
      "self"
    ],
    "_get_dt_bias_A_log_D": [
      "mod",
      "data"
    ],
    "export": [
      "self"
    ]
  },
  "_DynamicMambaLayer": {
    "_setup": [
      "self"
    ],
    "modify": [
      "self"
    ],
    "export": [
      "self"
    ]
  },
  "_DynamicMCoreLanguageModel": {
    "_setup": [
      "self"
    ],
    "modify": [
      "self"
    ],
    "export": [
      "self"
    ]
  },
  "MegatronConstraintsFunc": {
    "__init__": [
      "self",
      "model",
      "constraints",
      "dummy_input",
      "deployment",
      "fast_eval"
    ],
    "constraint_eval_funcs": [
      "self"
    ],
    "_get_params": [
      "self",
      "_"
    ],
    "_get_flops": [
      "self",
      "_"
    ],
    "_get_flops_min_depth": [
      "self",
      "_"
    ],
    "_get_true_latency": [
      "self",
      "_"
    ],
    "_get_latency": [
      "self",
      "precomputed"
    ]
  },
  "_DynamicTENorm": {
    "_setup": [
      "self"
    ]
  },
  "AttentionHeadTracedHp": {
    "active": [
      "self",
      "val"
    ],
    "choices": [
      "self",
      "val"
    ],
    "_get_importance": [
      "self"
    ],
    "_enforce_order": [
      "self",
      "order"
    ],
    "_resolve_dependencies": [
      "self",
      "sym",
      "get_hp"
    ]
  },
  "_DynamicAttention": {
    "_setup": [
      "self"
    ],
    "configure_qkv_out": [
      "self",
      "q_name",
      "k_name",
      "v_name",
      "out_name"
    ],
    "modify": [
      "self"
    ]
  },
  "_DynamicBertSelfAttention": {
    "_setup": [
      "self"
    ],
    "export": [
      "self"
    ]
  },
  "_DynamicBertAttention": {
    "_setup": [
      "self"
    ],
    "export": [
      "self"
    ]
  },
  "_DynamicGPTJAttention": {
    "_setup": [
      "self"
    ],
    "export": [
      "self"
    ]
  },
  "_n_heads_config": [],
  "_DynamicBatchInstance": {
    "_cut_to_active_features": [
      "mod",
      "value"
    ],
    "_setup": [
      "self"
    ],
    "modify": [
      "self"
    ]
  },
  "_DynamicBatchNorm": {},
  "_DynamicInstanceNorm": {},
  "_DynamicLayerNorm": {
    "_get_normalized_shape": [
      "mod",
      "value"
    ],
    "_cut_to_active_features": [
      "mod",
      "value"
    ],
    "_setup": [
      "self"
    ],
    "modify": [
      "self"
    ]
  },
  "_DynamicGroupNorm": {
    "_get_num_groups": [
      "mod",
      "value"
    ],
    "_cut_to_active_channels": [
      "mod",
      "value"
    ],
    "_setup": [
      "self"
    ],
    "modify": [
      "self"
    ]
  },
  "_DynamicConvNd": {
    "ndim": [
      "self"
    ],
    "_assert_input_format": [
      "mod",
      "input"
    ],
    "_get_padding": [
      "mod",
      "padding"
    ],
    "_get_bias": [
      "mod",
      "bias"
    ],
    "_get_channel_order": [],
    "_get_weight": [
      "mod",
      "weight"
    ],
    "_get_groups": [
      "mod",
      "groups"
    ],
    "_estimate_importance": [
      "self"
    ],
    "_setup": [
      "self"
    ],
    "modify": [
      "self"
    ]
  },
  "_DynamicConvTransposeNd": {
    "_get_channel_order": [],
    "_estimate_importance": [
      "self"
    ]
  },
  "get_sliced_tensor_by_slices": [
    "tensor",
    "slices"
  ],
  "get_sliced_tensor": [
    "mod",
    "tensor"
  ],
  "_activate_depth": [
    "func"
  ],
  "_DynamicSequential": {
    "forward": [
      "self",
      "input"
    ],
    "export": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "extra_repr": [
      "self"
    ],
    "_get_modules": [
      "mod",
      "modules"
    ],
    "_setup": [
      "self"
    ],
    "modify": [
      "self"
    ]
  },
  "DynamicModuleList": {
    "_setup": [
      "self"
    ],
    "_get_modules": [
      "mod",
      "modules"
    ]
  },
  "_DynamicLinear": {
    "_get_weight": [
      "mod",
      "weight"
    ],
    "_get_bias": [
      "mod",
      "bias"
    ],
    "_estimate_importance": [
      "self"
    ],
    "_setup": [
      "self"
    ],
    "modify": [
      "self"
    ]
  },
  "GradientDataManager": {
    "__init__": [
      "self",
      "shape",
      "model",
      "reduce_func"
    ],
    "process_gradient": [
      "self"
    ],
    "score": [
      "self"
    ]
  },
  "_setup_grad_manager_linear": [
    "module"
  ],
  "_setup_grad_manager_hf_attention": [
    "module",
    "head_mask_idx"
  ],
  "_setup_grad_manager_bert_attention": [
    "module"
  ],
  "_setup_grad_manager_gptj_attention": [
    "module"
  ],
  "GradientBinarySearcher": {
    "default_search_config": [
      "self"
    ],
    "before_search": [
      "self"
    ],
    "sanitize_search_config": [
      "self",
      "config"
    ],
    "hparam_names_for_search": [
      "self"
    ],
    "gradnas_score_func": [
      "model"
    ],
    "_estimate_gradient_scores": [
      "self",
      "data_loader",
      "loss_func",
      "collect_func",
      "max_iter_data_loader"
    ],
    "_overwrite_hp_importance": [
      "self",
      "hps_for_grad_calc"
    ]
  },
  "GradNASModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "search_algorithm": [
      "self"
    ]
  },
  "FastNASPatchManager": {
    "sample_during_training": [
      "self"
    ]
  },
  "update_fastnas_metadata": [],
  "convert_fastnas_searchspace": [
    "model",
    "config"
  ],
  "restore_fastnas_searchspace": [
    "model",
    "config",
    "metadata"
  ],
  "BinarySearcher": {
    "hparam_names_for_search": [
      "self"
    ],
    "hparam_types_for_search": [
      "self"
    ],
    "before_search": [
      "self"
    ],
    "before_step": [
      "self"
    ],
    "_apply_fastnas_according_to_threshold": [
      "self",
      "threshold"
    ],
    "sample": [
      "self"
    ],
    "after_step": [
      "self"
    ],
    "early_stop": [
      "self"
    ],
    "default_state_dict": [
      "self"
    ],
    "load_search_checkpoint": [
      "self"
    ],
    "_get_binary_search_hps": [
      "self"
    ],
    "_build_sensitivity_map": [
      "self",
      "verbose"
    ]
  },
  "_get_fastnas_default_rules": [],
  "FastNASModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "next_modes": [
      "self"
    ],
    "export_mode": [
      "self"
    ],
    "search_algorithm": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ],
    "update_for_save": [
      "self"
    ],
    "update_for_new_mode": [
      "self"
    ]
  },
  "PruneModeRegistry": [],
  "prune": [
    "model",
    "mode",
    "constraints",
    "dummy_input",
    "config"
  ],
  "SUPPORTED_HPARAMS": [],
  "drop_mcore_language_model_layers": [
    "model"
  ],
  "MCoreMinitronSearcher": {
    "default_search_config": [
      "self"
    ],
    "default_state_dict": [
      "self"
    ],
    "sanitize_search_config": [
      "self",
      "config"
    ],
    "before_search": [
      "self"
    ],
    "run_search": [
      "self"
    ]
  },
  "get_mcore_minitron_config": [
    "channel_divisor",
    "mamba_head_dim_divisor",
    "num_moe_experts_divisor"
  ],
  "_convert_model_to_dynamic_space": [
    "model",
    "config"
  ],
  "convert_mcore_minitron": [
    "model",
    "config"
  ],
  "restore_mcore_minitron": [
    "model",
    "config",
    "metadata"
  ],
  "MCoreMinitronModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "next_modes": [
      "self"
    ],
    "export_mode": [
      "self"
    ],
    "search_algorithm": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ]
  },
  "ImportanceEstimatorRegistry": {
    "__init__": [
      "self",
      "model"
    ],
    "register_hook": [
      "self",
      "module",
      "hook_fn",
      "hook_type"
    ],
    "register_importance": [
      "self",
      "dynamic_module",
      "hparam_name",
      "importance_fn",
      "importance_is_order"
    ],
    "cleanup": [
      "self"
    ],
    "get_layer_scores": [
      "self"
    ],
    "get_activations_and_layer_scores": [
      "self"
    ],
    "set_activations_and_layer_scores": [
      "self",
      "activations_per_rank",
      "layer_scores"
    ]
  },
  "_register_hidden_size_importance": [
    "module",
    "registry"
  ],
  "_register_depth_cosine_importance": [
    "module",
    "registry"
  ],
  "_register_self_attention_importance": [
    "module",
    "registry"
  ],
  "_register_mlp_importance": [
    "module",
    "registry"
  ],
  "_register_sequential_mlp_importance": [
    "module",
    "registry"
  ],
  "_register_mamba_mixer_importance": [
    "module",
    "registry"
  ],
  "_DynamicSpaceUnwrapped": {
    "__init__": [
      "self",
      "model"
    ]
  },
  "is_configurable": [
    "model"
  ],
  "is_dynamic": [
    "model"
  ],
  "named_hparams": [
    "model",
    "configurable",
    "unique"
  ],
  "named_dynamic_modules": [
    "model"
  ],
  "get_hparam": [
    "model",
    "name"
  ],
  "search_space_size": [
    "model"
  ],
  "forward_with_reshard": [
    "model"
  ],
  "ModeloptStateList": [],
  "ModeloptStateManager": {
    "_state_key": [],
    "_state_version_key": [],
    "__init__": [
      "self",
      "model",
      "init_state"
    ],
    "has_state": [
      "self"
    ],
    "is_converted": [
      "cls",
      "model",
      "is_root"
    ],
    "state_dict": [
      "self"
    ],
    "state_version": [
      "self"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "version"
    ],
    "transfer_state_dict": [
      "cls",
      "model_from",
      "model_to"
    ],
    "has_state_for_mode_type": [
      "mode_type"
    ],
    "remove_state": [
      "cls",
      "model"
    ],
    "modes_with_states": [
      "self"
    ],
    "last_mode": [
      "self"
    ],
    "_last_metadata": [
      "self"
    ],
    "_last_config": [
      "self",
      "config"
    ],
    "_export_stack": [
      "self"
    ],
    "get_config_class": [
      "mode",
      "config"
    ],
    "check_mode": [
      "self",
      "mode"
    ],
    "add_mode": [
      "self",
      "mode",
      "config",
      "metadata"
    ],
    "update_last_state_before_new_mode": [
      "self",
      "model"
    ],
    "update_last_state_before_save": [
      "self",
      "model"
    ]
  },
  "ApplyModeError": {},
  "ModelLikeModule": {
    "__init__": [
      "self",
      "modellike"
    ],
    "init_modellike": [
      "self"
    ]
  },
  "_check_init_modellike": [
    "model",
    "mode"
  ],
  "apply_mode": [
    "model",
    "mode",
    "registry",
    "init_state",
    "mode_kwargs"
  ],
  "get_mode": [
    "model"
  ],
  "modelopt_state": [
    "model"
  ],
  "save": [
    "model",
    "f"
  ],
  "restore_from_modelopt_state": [
    "model",
    "modelopt_state"
  ],
  "restore": [
    "model",
    "f"
  ],
  "_safe_setattr_tensor_or_param_with_dm_check": [
    "module",
    "param_name",
    "tensor_or_param"
  ],
  "_writeback_orig_param": [
    "self"
  ],
  "_unsafe_setattr_param_with_dm_check": [
    "module",
    "param_name",
    "param"
  ],
  "reset_sharded_param_with_dm_check": [
    "self"
  ],
  "_get_model_state_dict_with_dm_check": [
    "model"
  ],
  "_pytorch_managed": [],
  "_da_val_default": [],
  "DynamicAttributeCallback": [],
  "SetAttrHook": [],
  "DelAttrHook": [],
  "_FoldedCallback": {
    "__init__": [
      "self"
    ],
    "callback": [
      "self",
      "cb"
    ],
    "__iter__": [
      "self"
    ],
    "__call__": [
      "self",
      "self_module",
      "val"
    ],
    "__len__": [
      "self"
    ],
    "extend": [
      "self",
      "cbs_other"
    ]
  },
  "_DMAttributeManager": {
    "__init__": [
      "self"
    ],
    "__bool__": [
      "self"
    ],
    "_get_lookup": [
      "self",
      "name",
      "lookup_all"
    ],
    "og_cls": [
      "self"
    ],
    "level": [
      "self"
    ],
    "append_level": [
      "self",
      "original_cls"
    ],
    "pop_level": [
      "self"
    ],
    "hp_keys": [
      "self",
      "all"
    ],
    "get_hp": [
      "self",
      "name"
    ],
    "named_hps": [
      "self",
      "all"
    ],
    "set_hp": [
      "self",
      "name",
      "hparam"
    ],
    "pop_hp": [
      "self",
      "name"
    ],
    "da_keys": [
      "self"
    ],
    "set_da": [
      "self",
      "name",
      "val",
      "cb"
    ],
    "pop_da": [
      "self",
      "name"
    ],
    "get_da_value": [
      "self",
      "name"
    ],
    "get_da_cb": [
      "self",
      "name"
    ],
    "retain_cbs": [
      "self"
    ],
    "fold_cbs": [
      "self"
    ],
    "attr_keys": [
      "self"
    ],
    "get_attr_set_hook": [
      "self",
      "name"
    ],
    "set_attr": [
      "self",
      "name",
      "set_hook",
      "del_hook"
    ],
    "pop_attr": [
      "self",
      "name"
    ]
  },
  "DynamicModule": {
    "__init__": [
      "self"
    ],
    "_get_dm_attribute_manager": [
      "self",
      "use_default"
    ],
    "_register_hparam": [
      "self",
      "name",
      "hparam"
    ],
    "_register_dynamic_attribute": [
      "self",
      "name",
      "callback"
    ],
    "_register_temp_attribute": [
      "self",
      "name",
      "val",
      "set_hook",
      "del_hook"
    ],
    "export": [
      "self"
    ],
    "convert": [
      "cls",
      "module"
    ],
    "_setup": [
      "self"
    ],
    "modify": [
      "self"
    ],
    "freeze": [
      "self"
    ],
    "reset_dynamic_attributes": [
      "self"
    ],
    "_dict_with_special": [
      "self"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "__delattr__": [
      "self",
      "name"
    ],
    "get_hparam": [
      "self",
      "target"
    ],
    "named_hparams": [
      "self",
      "configurable"
    ],
    "extra_repr": [
      "self"
    ],
    "original_cls": [
      "self"
    ],
    "parallel_state": [
      "self",
      "parallel_state"
    ],
    "_initialize_parallel_state": [
      "self"
    ],
    "get_original_cls_by_level": [
      "self",
      "level"
    ]
  },
  "_DMRegistryCls": {
    "T": [],
    "__init__": [
      "self",
      "prefix",
      "dm_base_cls"
    ],
    "_generate_rule_class": [
      "self",
      "dm_cls"
    ],
    "_get_dynamic_class_name": [
      "self",
      "nn_cls"
    ],
    "_get_registered_nn_class": [
      "self",
      "nn_cls"
    ],
    "__contains__": [
      "self",
      "item"
    ],
    "__getitem__": [
      "self",
      "nn_cls"
    ],
    "_create_new_dynamic_class": [
      "self",
      "dm_class",
      "nn_cls"
    ],
    "get": [
      "self",
      "nn_cls",
      "default"
    ],
    "get_key_from_dm": [
      "self",
      "dm_cls"
    ],
    "get_key": [
      "self",
      "nn_cls"
    ],
    "get_rule_class": [
      "self",
      "nn_cls"
    ],
    "register": [
      "self",
      "cls_to_key"
    ],
    "unregister": [
      "self",
      "nn_cls"
    ],
    "convert": [
      "self",
      "nn_mod"
    ],
    "prefix": [
      "self"
    ]
  },
  "DynamicSpace": {
    "__init__": [
      "self",
      "model"
    ],
    "_should_be_converted": [
      "self",
      "mod"
    ],
    "convert_to_dynamic": [
      "self",
      "rules",
      "dm_registry"
    ],
    "named_dynamic_modules": [
      "self"
    ],
    "is_dynamic": [
      "self"
    ],
    "named_hparams": [
      "self",
      "configurable",
      "unique"
    ],
    "get_hparam": [
      "self",
      "name"
    ],
    "is_configurable": [
      "self"
    ],
    "size": [
      "self"
    ],
    "config": [
      "self",
      "configurable"
    ],
    "select": [
      "self",
      "config",
      "strict"
    ],
    "export": [
      "self",
      "dm_registry"
    ],
    "__repr__": [
      "self"
    ]
  },
  "MetadataDict": [],
  "ModeConfigList": [],
  "ModeState": [],
  "ModeEntrypoint": [],
  "ConvertReturnType": [],
  "_ConvertEntrypoint": [],
  "_ConvertEntrypointWithKwargs": [],
  "ConvertEntrypoint": [],
  "RestoreEntrypoint": [],
  "UpdateEntrypoint": [],
  "ModeDescriptor": {
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "__hash__": [
      "self"
    ],
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "next_modes": [
      "self"
    ],
    "next_prohibited_modes": [
      "self"
    ],
    "export_mode": [
      "self"
    ],
    "is_export_mode": [
      "self"
    ],
    "search_algorithm": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ],
    "update_for_save": [
      "self"
    ],
    "update_for_new_mode": [
      "self"
    ],
    "require_model_like": [
      "self"
    ],
    "save_mode_in_state": [
      "self"
    ],
    "assert_compatibility_as_next_mode_of": [
      "self",
      "other_mode"
    ]
  },
  "ModeType": [],
  "ModeLike": [],
  "ModeKwargsType": [],
  "_ModeRegistryCls": {
    "T": [],
    "__init__": [
      "self",
      "registry_name"
    ],
    "register_mode": [
      "self",
      "cls_descriptor"
    ],
    "remove_mode": [
      "self",
      "mode"
    ],
    "get": [
      "self",
      "mode"
    ],
    "__getitem__": [
      "self",
      "mode"
    ],
    "__contains__": [
      "self",
      "mode"
    ],
    "__del__": [
      "self"
    ],
    "contained_in_any": [
      "cls",
      "mode"
    ],
    "get_from_any": [
      "cls",
      "mode"
    ],
    "get_registry_by_name": [
      "cls",
      "registry_name"
    ]
  },
  "get_mode_config": [
    "mode_like"
  ],
  "CustomHPType": {
    "__repr__": [
      "self"
    ],
    "__lt__": [
      "self",
      "other"
    ],
    "__eq__": [
      "self",
      "other"
    ]
  },
  "HPType": [],
  "Hparam": {
    "Importance": [],
    "ImportanceEstimator": [],
    "ActiveSlice": [],
    "__init__": [
      "self",
      "choices",
      "original"
    ],
    "__iter__": [
      "self"
    ],
    "is_configurable": [
      "self"
    ],
    "_force_configurable": [
      "self"
    ],
    "is_sortable": [
      "self"
    ],
    "active": [
      "self",
      "val"
    ],
    "active_slice": [
      "self"
    ],
    "choices": [
      "self",
      "val"
    ],
    "reset_choices": [
      "self"
    ],
    "min": [
      "self"
    ],
    "max": [
      "self"
    ],
    "original": [
      "self"
    ],
    "importance": [
      "self"
    ],
    "register_importance": [
      "self",
      "importance_estimator"
    ],
    "_default_get_importance": [
      "self"
    ],
    "_get_importance": [
      "self"
    ],
    "enforce_order": [
      "self",
      "order"
    ],
    "_enforce_order": [
      "self",
      "order"
    ],
    "attrs": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "__iand__": [
      "self",
      "hp"
    ]
  },
  "ConfigDict": [],
  "SimpleRule": [],
  "WrappedRule": [],
  "Rule": [],
  "RulesDict": [],
  "ModeloptField": [
    "default"
  ],
  "ModeloptBaseConfig": {
    "model_config": [],
    "model_dump": [
      "self"
    ],
    "model_dump_json": [
      "self"
    ],
    "_iterable_model_extra": [
      "self"
    ],
    "get_field_name_from_key": [
      "self",
      "key"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "_get_kv_dict": [
      "self"
    ],
    "keys": [
      "self"
    ],
    "values": [
      "self"
    ],
    "items": [
      "self"
    ],
    "update": [
      "self",
      "config"
    ]
  },
  "ModeloptBaseRule": {
    "get_rule_type": [
      "cls",
      "wrapped_only"
    ],
    "validate_rule": [
      "cls",
      "rule"
    ],
    "customize_rule": [
      "cls",
      "rule",
      "key"
    ]
  },
  "ModeloptBaseRuleConfig": {
    "model_config": [],
    "__init_subclass__": [
      "cls"
    ],
    "register_default": [
      "cls",
      "extra_default"
    ],
    "unregister_default": [
      "cls",
      "key"
    ],
    "_check_for_extra_fields": [
      "self"
    ]
  },
  "_get_default_description": [
    "prefix",
    "alias",
    "rule_cls",
    "default"
  ],
  "_get_field_validator": [
    "alias"
  ],
  "_get_field_name": [
    "alias"
  ],
  "get_kwargs_for_create_model_with_rules": [
    "registry",
    "default_rules",
    "doc"
  ],
  "LimitsTuple": [],
  "ConstraintsDict": [],
  "Deployment": [],
  "ForwardLoop": [],
  "ScoreFunc": [],
  "SearchConfig": [],
  "SearchStateDict": [],
  "BaseSearcher": {
    "__init__": [
      "self"
    ],
    "default_search_config": [
      "self"
    ],
    "default_state_dict": [
      "self"
    ],
    "sanitize_search_config": [
      "self",
      "config"
    ],
    "search": [
      "self",
      "model",
      "constraints",
      "dummy_input",
      "config"
    ],
    "reset_search": [
      "self"
    ],
    "before_search": [
      "self"
    ],
    "run_search": [
      "self"
    ],
    "after_search": [
      "self"
    ],
    "has_score": [
      "self"
    ],
    "eval_score": [
      "self",
      "silent"
    ],
    "construct_forward_loop": [
      "self",
      "silent",
      "progress_bar_msg",
      "max_iter_data_loader",
      "post_process_fn"
    ],
    "state_dict": [
      "self"
    ],
    "load_search_checkpoint": [
      "self"
    ],
    "save_search_checkpoint": [
      "self",
      "verbose"
    ]
  },
  "LPS": {
    "__init__": [
      "self",
      "name",
      "constraints",
      "constraints_to_candidate_costs",
      "candidate_scores",
      "objective_type",
      "verbose"
    ],
    "_build_selection_vars": [
      "self"
    ],
    "_build_objective_problem": [
      "self",
      "selection_vars"
    ],
    "_build_one_hot_constraints": [
      "self",
      "selection_vars"
    ],
    "_build_budget_constraints": [
      "self",
      "selection_vars"
    ],
    "__call__": [
      "self"
    ]
  },
  "ensure_metadata_has_dp_cp_group": [
    "metadata"
  ],
  "_modelopt_get_extra_state": [
    "self"
  ],
  "_modelopt_set_extra_state": [
    "self",
    "state"
  ],
  "register_modelopt_extra_state_callbacks": [
    "module",
    "get_extra_state_func",
    "set_extra_state_func"
  ],
  "_MegatronMLP": {
    "_modelopt_state_keys": [],
    "_setup": [
      "self"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "DROP_SUBSTRINGS": [],
  "remove_per_module_state": [
    "modelopt_state"
  ],
  "save_modelopt_state": [
    "model",
    "state_dict"
  ],
  "restore_modelopt_state": [
    "model",
    "state_dict"
  ],
  "save_sharded_modelopt_state": [
    "model",
    "checkpoint_name",
    "sharded_strategy",
    "prefix"
  ],
  "_load_extra_state_from_sharded_checkpoint": [
    "model",
    "checkpoint_name",
    "prefix",
    "metadata"
  ],
  "restore_sharded_modelopt_state": [
    "model",
    "checkpoint_name",
    "prefix",
    "metadata"
  ],
  "_new_from_pretrained": [
    "pretrained_model_name_or_path"
  ],
  "modelmixin_patch_methods": [],
  "_undo_torch_init_override_by_transformers": [],
  "_new_from_config": [
    "config"
  ],
  "_save_pretrained_with_checks": [
    "self",
    "save_directory"
  ],
  "_load_params_and_buffers_into_zero3_model": [
    "model_to_load",
    "state_dict"
  ],
  "pretrained_model_patch_methods": [],
  "_report_memory": [
    "msg"
  ],
  "_MemoryReportCallback": {
    "on_step_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_evaluate": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "ModelOptHFTrainer": {
    "__init__": [
      "self"
    ]
  },
  "_MODELOPT_STATE_SAVE_NAME": [],
  "_PATCHED_CLASSES": [],
  "register_for_patching": [
    "name",
    "cls",
    "patch_methods"
  ],
  "_get_modelopt_state_path": [
    "model_name_or_path"
  ],
  "_patch_model_init_for_modelopt": [
    "cls",
    "model_path",
    "extra_context"
  ],
  "_new_save_pretrained": [
    "self",
    "save_directory"
  ],
  "_patch_lock": [],
  "patch_pretrained_methods": [
    "cls",
    "patch_methods"
  ],
  "enable_huggingface_checkpointing": [],
  "_get_quantizer_state_save_path": [
    "dir"
  ],
  "_new_save_pretrained_peft": [
    "self",
    "save_directory"
  ],
  "_new_load_adapter": [
    "self",
    "model_id",
    "adapter_name"
  ],
  "get_latency": [
    "model",
    "dummy_input",
    "deployment"
  ],
  "DeviceModel": {
    "__init__": [
      "self",
      "client",
      "compiled_model",
      "metadata",
      "compilation_args",
      "io_shapes",
      "ignore_nesting"
    ],
    "__call__": [
      "self"
    ],
    "get_latency": [
      "self"
    ],
    "profile": [
      "self",
      "verbose"
    ],
    "forward": [
      "self"
    ],
    "save_compile_model": [
      "self",
      "path",
      "remove_hash"
    ],
    "_profile_device": [
      "self"
    ]
  },
  "compile": [
    "model",
    "dummy_input",
    "deployment",
    "dynamic_axes",
    "compilation_args"
  ],
  "timeit": [
    "method"
  ],
  "init_logging": [],
  "read_bytes": [
    "file_path"
  ],
  "read_string": [
    "file_path"
  ],
  "write_bytes": [
    "data",
    "file_path"
  ],
  "write_string": [
    "data",
    "file_path"
  ],
  "DeploymentTable": [],
  "DetailedResults": [],
  "RuntimeClient": {
    "__init__": [
      "self",
      "deployment"
    ],
    "runtime": [
      "self"
    ],
    "sanitize_deployment_config": [
      "self",
      "deployment"
    ],
    "ir_to_compiled": [
      "self",
      "ir_bytes",
      "compilation_args"
    ],
    "profile": [
      "self",
      "compiled_model",
      "compilation_args"
    ],
    "inference": [
      "self",
      "compiled_model",
      "inputs",
      "io_shapes"
    ],
    "default_deployment": [
      "self"
    ],
    "deployment_table": [
      "self"
    ],
    "_ir_to_compiled": [
      "self",
      "ir_bytes",
      "compilation_args"
    ],
    "_profile": [
      "self",
      "compiled_model",
      "compilation_args"
    ],
    "_inference": [
      "self",
      "compiled_model",
      "inputs",
      "io_shapes"
    ]
  },
  "TRTLocalClient": {
    "default_deployment": [
      "self"
    ],
    "deployment_table": [
      "self"
    ],
    "__init__": [
      "self",
      "deployment"
    ],
    "_ir_to_compiled": [
      "self",
      "ir_bytes",
      "compilation_args"
    ],
    "_profile": [
      "self",
      "compiled_model",
      "compilation_args"
    ],
    "_inference": [
      "self",
      "compiled_model",
      "inputs",
      "io_shapes"
    ],
    "_teardown_all_sessions": [
      "self"
    ]
  },
  "ORTLocalClient": {
    "_profile_defaults": [
      "self"
    ],
    "_accelerator_to_provider": [
      "self"
    ],
    "default_deployment": [
      "self"
    ],
    "deployment_table": [
      "self"
    ],
    "_ir_to_compiled": [
      "self",
      "ir_bytes",
      "compilation_args"
    ],
    "_onnx_to_np_dtype": [
      "self",
      "onnx_type"
    ],
    "_init_session": [
      "self",
      "compiled_model",
      "session_options"
    ],
    "_profile": [
      "self",
      "compiled_model",
      "compilation_args"
    ],
    "_inference": [
      "self",
      "compiled_model",
      "inputs",
      "io_shapes"
    ],
    "_run_session": [
      "self",
      "ort_session",
      "inputs",
      "iterations",
      "iterations_max",
      "warm_up",
      "duration"
    ]
  },
  "RuntimeRegistry": {
    "register": [
      "cls",
      "runtime"
    ],
    "unregister": [
      "cls",
      "runtime"
    ],
    "get": [
      "cls",
      "deployment"
    ]
  },
  "MAX_WORKSPACE_SIZE": [],
  "TACTIC_SOURCES": [],
  "ALL_TATIC_SOURCES_COMPONENT": [],
  "TENSORRT_HW_PARAMS_SUGGESTED_OPTIONS": [],
  "TENSORRT_HW_PARAMS_OPT_OPTIONS": [],
  "__to_float": [
    "line"
  ],
  "__get_stats": [
    "line"
  ],
  "FileSection": {
    "__init__": [
      "self",
      "section_header"
    ],
    "entered_section": [
      "self",
      "line"
    ],
    "parse_line": [
      "self",
      "line"
    ]
  },
  "__parse_log_file": [
    "trtexec_log",
    "sections"
  ],
  "parse_build_log": [
    "trtexec_log"
  ],
  "parse_profiling_log": [
    "trtexec_log"
  ],
  "_run_command": [
    "cmd",
    "cwd"
  ],
  "_get_profiling_params": [
    "profiling_runs"
  ],
  "_get_trtexec_params": [
    "engine_path",
    "builder_optimization_level",
    "timing_cache_file",
    "verbose"
  ],
  "_is_low_bit_mode": [
    "trt_mode"
  ],
  "_update_dynamic_shapes": [
    "dynamic_shapes",
    "cmd"
  ],
  "build_engine": [
    "onnx_bytes",
    "trt_mode",
    "engine_path",
    "timing_cache_path",
    "calib_cache",
    "dynamic_shapes",
    "plugin_config",
    "builder_optimization_level",
    "output_dir",
    "verbose"
  ],
  "profile_engine": [
    "engine_bytes",
    "profiling_runs",
    "onnx_node_names",
    "enable_layerwise_profiling",
    "dynamic_shapes",
    "output_dir"
  ],
  "_merge_reformatters": [
    "layer_latency_dict"
  ],
  "process_layerwise_result": [
    "profile_path",
    "onnx_node_names"
  ],
  "map_trt_layers_to_onnx": [
    "layerwise_result",
    "onnx_node_names"
  ],
  "is_trt8": [],
  "HostDeviceMem": {
    "__init__": [
      "self",
      "host_mem",
      "device_mem",
      "dtype"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "get_engine_bytes": [
    "engine"
  ],
  "load_engine": [
    "buffer",
    "log_level"
  ],
  "calib_data_generator": [
    "onnx_bytes",
    "input_tensors"
  ],
  "convert_trt_dtype_to_torch": [
    "trt_dtype"
  ],
  "prepend_hash_to_bytes": [
    "engine_bytes"
  ],
  "convert_shape_to_string": [
    "shape"
  ],
  "TENSORRT_7_MAJOR_VERSION": [],
  "TENSORRT_8_MAJOR_VERSION": [],
  "ONE_MEBI": [],
  "ONE_GIBI": [],
  "ONE_MEBI_IN_BYTES": [],
  "ONE_GIBI_IN_BYTES": [],
  "TRTEXEC": [],
  "TRTEXEC_PATH": [],
  "DEFAULT_ARTIFACT_DIR": [],
  "DEFAULT_VALIDATION_THRESHOLD": [],
  "DEFAULT_MAX_BATCH_SIZE": [],
  "DEFAULT_ACCELERATOR": [],
  "DEFAULT_TACTIC_SOURCES": [],
  "DEFAULT_NVTX_MODE": [],
  "DEFAULT_MIN_TIMING": [],
  "DEFAULT_AVG_TIMING": [],
  "DEFAULT_BATCH_SIZE": [],
  "DEFAULT_GPU_ID": [],
  "DEFAULT_MAX_WORKSPACE_SIZE": [],
  "WARMUP_TIME_MS": [],
  "DEFAULT_PROFILING_RUNS": [],
  "DEFAULT_NUM_INFERENCE_PER_RUN": [],
  "INPUT_DATA_KEY": [],
  "OUTPUT_DATA_KEY": [],
  "UNNAMED_LAYER_KEY": [],
  "NODE_NAME_DELIMITER": [],
  "TRTMode": {
    "FLOAT32": [],
    "FLOAT16": [],
    "BFLOAT16": [],
    "FLOAT8": [],
    "INT8": [],
    "INT4": [],
    "STRONGLY_TYPED": [],
    "BEST": []
  },
  "TRT_MODE_FLAGS": [],
  "SHA_256_HASH_LENGTH": [],
  "ModelMetadata": [],
  "ModelType": [],
  "ValueInfoType": [],
  "DEFAULT_ONNX_OPSET": [],
  "ONNX_EXPORT_OUT_PREFIX": [],
  "TWO_GB": [],
  "OnnxBytes": {
    "__init__": [
      "self",
      "onnx_load_path"
    ],
    "write_to_disk": [
      "self",
      "onnx_save_dir",
      "clean_dir"
    ],
    "to_bytes": [
      "self"
    ],
    "get_onnx_model_file_bytes": [
      "self"
    ],
    "from_bytes": [
      "cls",
      "onnx_bytes"
    ]
  },
  "_to_expected_onnx_type": [
    "val"
  ],
  "generate_onnx_input": [
    "model_metadata",
    "input",
    "ignore_nesting"
  ],
  "optimize": [
    "name",
    "onnx_graph",
    "verbose"
  ],
  "split_args_kwargs": [
    "args_tuple"
  ],
  "is_int4_quantized": [
    "model"
  ],
  "is_fp4_quantized": [
    "model"
  ],
  "is_mxfp8_quantized": [
    "model"
  ],
  "is_int8_quantized": [
    "model"
  ],
  "is_fp8_quantized": [
    "model"
  ],
  "quantize_weights": [
    "model",
    "onnx_model"
  ],
  "get_onnx_bytes_and_metadata": [
    "model",
    "dummy_input",
    "model_name",
    "onnx_load_path",
    "dynamic_axes",
    "remove_exported_model",
    "dynamo_export",
    "onnx_opset",
    "dq_only",
    "weights_dtype"
  ],
  "get_external_tensor_paths": [
    "model_dir"
  ],
  "has_external_data": [
    "onnx_model_path"
  ],
  "create_model_metadata": [
    "tree_spec_input",
    "tree_spec_output",
    "input_none_names",
    "onnx_graph",
    "model"
  ],
  "_get_onnx_external_data_tensors": [
    "model"
  ],
  "check_model_uses_external_data": [
    "model"
  ],
  "Optimizer": {
    "__init__": [
      "self",
      "onnx_graph",
      "verbose"
    ],
    "info": [
      "self",
      "prefix"
    ],
    "cleanup": [
      "self",
      "return_onnx"
    ],
    "select_outputs": [
      "self",
      "keep",
      "names"
    ],
    "infer_shapes": [
      "self",
      "return_onnx"
    ],
    "clip_add_hidden_states": [
      "self",
      "return_onnx"
    ],
    "fold_constants": [
      "self",
      "return_onnx"
    ]
  },
  "weight_only_quantize": [
    "model"
  ],
  "max_calibrate": [
    "model",
    "forward_loop",
    "distributed_sync"
  ],
  "mse_calibrate": [
    "model",
    "forward_loop",
    "distributed_sync",
    "num_steps",
    "start_multiplier",
    "stop_multiplier"
  ],
  "enable_stats_collection": [
    "model"
  ],
  "finish_stats_collection": [
    "model",
    "method"
  ],
  "disable_pre_quant_scale_and_resmooth": [
    "linear",
    "delete_pre_quant_scale"
  ],
  "_ENABLE_FOLDING_PQS_TO_WEIGHTS": [],
  "_apply_weight_pre_quant_scale": [
    "linear",
    "pre_quant_scale"
  ],
  "apply_pre_quant_scale_and_smooth": [
    "linear",
    "pre_quant_scale"
  ],
  "smoothquant": [
    "model",
    "forward_loop",
    "alpha"
  ],
  "awq": [
    "model",
    "forward_loop",
    "algorithm"
  ],
  "awq_lite": [
    "model",
    "forward_loop",
    "alpha_step",
    "debug"
  ],
  "awq_clip": [
    "model",
    "forward_loop",
    "max_co_batch_size",
    "max_tokens_per_batch",
    "min_clip_ratio",
    "shrink_step",
    "debug"
  ],
  "_get_awq_quantizer_block_size": [
    "tensor",
    "quantizer"
  ],
  "svdquant": [
    "model",
    "forward_loop",
    "lowrank"
  ],
  "estimate_quant_compression": [
    "quant_cfg"
  ],
  "QuantRecipe": {
    "__init__": [
      "self",
      "quant_cfg",
      "name"
    ],
    "get_auto_name_for_config": [
      "quant_cfg"
    ],
    "num_bits": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "__lt__": [
      "self",
      "other"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__hash__": [
      "self"
    ],
    "disable_folding_pqs_to_weights": [],
    "fold_pqs_to_weights": [
      "model"
    ]
  },
  "QuantRecipeHparam": {
    "__init__": [
      "self",
      "choices",
      "quant_modules",
      "score_modules",
      "name"
    ],
    "active": [
      "self",
      "val"
    ],
    "importance": [
      "self"
    ],
    "get_score": [
      "self",
      "recipe"
    ],
    "get_cost": [
      "self",
      "recipe"
    ],
    "attrs": [
      "self"
    ]
  },
  "_AutoQuantizeBaseSearcher": {
    "quant_grouping_rules": [],
    "score_module_rules": [],
    "default_search_config": [
      "self"
    ],
    "default_state_dict": [
      "self"
    ],
    "sanitize_search_config": [
      "self",
      "config"
    ],
    "_is_auto_quantize_module": [
      "module"
    ],
    "_get_search_recipes": [
      "quantization_formats"
    ],
    "_apply_quant_group_rule": [
      "self",
      "name",
      "rule"
    ],
    "_apply_score_group_rule": [
      "self",
      "name",
      "rule"
    ],
    "_get_score_module_from_name": [
      "self",
      "model",
      "score_module_name",
      "quant_module"
    ],
    "insert_hparams_after_merge_rules": [
      "self",
      "model",
      "quant_recipes",
      "disabled_layers"
    ],
    "_get_formatted_weight_compression_constraint": [
      "self"
    ],
    "_verify_constraint": [
      "self",
      "search_recipes"
    ],
    "estimate_sensitivity_scores": [
      "self"
    ],
    "initialize_candidate_stats": [
      "self"
    ],
    "_run_func": [
      "self",
      "func",
      "num_iters",
      "desc"
    ],
    "before_search": [
      "self"
    ],
    "_get_total_weight_size": [
      "modules"
    ],
    "_get_constraints_for_search": [
      "self",
      "max_weight_size",
      "lower_bound"
    ],
    "run_search_with_stats": [
      "self",
      "max_weight_size",
      "verbose"
    ],
    "run_search": [
      "self"
    ]
  },
  "_get_auto_quantize_score": [
    "grad_output",
    "output_diff"
  ],
  "_add_auto_quantize_score": [
    "grad_output",
    "output_diff",
    "score_tensor"
  ],
  "AutoQuantizeGradientSearcher": {
    "score_module_rules": [],
    "default_search_config": [
      "self"
    ],
    "sanitize_search_config": [
      "self",
      "config"
    ],
    "register_custom_support": [
      "cls",
      "is_supported_checker",
      "grad_ckpt_context",
      "is_param_grad_enabled"
    ],
    "_get_default_forward_backward_step": [
      "self"
    ],
    "_estimate_auto_quantize_scores": [
      "self",
      "is_param_grad_enabled"
    ],
    "estimate_sensitivity_scores": [
      "self"
    ],
    "run_search_with_stats": [
      "self",
      "max_weight_size",
      "verbose"
    ]
  },
  "_get_softmax_dist": [
    "logits",
    "tp_group",
    "return_log_prob"
  ],
  "_get_softmax": [
    "logits",
    "return_log_prob"
  ],
  "_get_p_log_q": [
    "p",
    "log_q"
  ],
  "_get_prob_from_logits": [
    "logits",
    "return_log_prob",
    "lm_head"
  ],
  "_get_kl_div_loss": [
    "prob_unquant",
    "logits_quant",
    "lm_head"
  ],
  "_get_lm_head": [
    "model"
  ],
  "AutoQuantizeKLDivSearcher": {
    "default_search_config": [
      "self"
    ],
    "sanitize_search_config": [
      "self",
      "config"
    ],
    "estimate_sensitivity_scores": [
      "self"
    ],
    "run_search_with_stats": [
      "self",
      "max_weight_size",
      "verbose"
    ]
  },
  "AutoQuantizeSearcher": [],
  "calibrate": [
    "model",
    "algorithm",
    "forward_loop"
  ],
  "postprocess_amax": [
    "model",
    "key",
    "post_process_fn"
  ],
  "auto_quantize": [
    "model",
    "constraints",
    "quantization_formats",
    "data_loader",
    "forward_step",
    "loss_func",
    "forward_backward_step",
    "disabled_layers",
    "num_calib_steps",
    "num_score_steps",
    "verbose",
    "method",
    "checkpoint"
  ],
  "disable_quantizer": [
    "model",
    "wildcard_or_filter_func"
  ],
  "enable_quantizer": [
    "model",
    "wildcard_or_filter_func"
  ],
  "print_quant_summary": [
    "model"
  ],
  "fold_weight": [
    "model"
  ],
  "mx_format_map": [],
  "DISABLE_TRITON_KERNEL": [],
  "_fp8_eager": [
    "x",
    "amax"
  ],
  "fp8_eager": [
    "x",
    "amax"
  ],
  "scaled_e4m3_impl": [
    "inputs",
    "amax"
  ],
  "fake_quant_impl": [
    "inputs",
    "amax",
    "num_bits",
    "unsigned",
    "narrow_range"
  ],
  "_quantize_impl": [
    "inputs",
    "amax",
    "num_bits",
    "exponent_bits",
    "unsigned",
    "narrow_range"
  ],
  "_quantize_impl_abstract": [
    "input",
    "amax",
    "num_bits",
    "exponent_bits",
    "unsigned",
    "narrow_range"
  ],
  "_dynamic_block_quantize_impl": [
    "inputs",
    "block_size",
    "amax",
    "num_bits",
    "exponent_bits",
    "scale_num_bits",
    "scale_exponent_bits"
  ],
  "_dynamic_block_quantize_impl_abstract": [
    "inputs",
    "block_size",
    "amax",
    "num_bits",
    "exponent_bits",
    "scale_num_bits",
    "scale_exponent_bits"
  ],
  "quantize_op": [],
  "dynamic_block_quantize_op": [],
  "QUANT_DESC_8BIT_PER_TENSOR": [],
  "QUANT_DESC_UNSIGNED_8BIT_PER_TENSOR": [],
  "QUANT_DESC_8BIT_CONV1D_WEIGHT_PER_CHANNEL": [],
  "QUANT_DESC_8BIT_CONV2D_WEIGHT_PER_CHANNEL": [],
  "QUANT_DESC_8BIT_CONV3D_WEIGHT_PER_CHANNEL": [],
  "QUANT_DESC_8BIT_LINEAR_WEIGHT_PER_ROW": [],
  "QUANT_DESC_8BIT_CONVTRANSPOSE1D_WEIGHT_PER_CHANNEL": [],
  "QUANT_DESC_8BIT_CONVTRANSPOSE2D_WEIGHT_PER_CHANNEL": [],
  "QUANT_DESC_8BIT_CONVTRANSPOSE3D_WEIGHT_PER_CHANNEL": [],
  "_fake_tensor_quant_backward": [
    "inputs",
    "amax",
    "grad_outputs"
  ],
  "_fake_quant_backward_function": [
    "ctx",
    "grad_outputs",
    "num_args"
  ],
  "_save_for_backward_if_needed": [
    "ctx",
    "pass_through_bwd",
    "inputs",
    "amax"
  ],
  "FakeTensorQuantFunction": {
    "symbolic": [
      "g",
      "inputs",
      "amax",
      "bias",
      "num_bits",
      "unsigned",
      "narrow_range",
      "trt_high_precision_dtype",
      "pass_through_bwd",
      "block_size",
      "axis"
    ],
    "forward": [
      "ctx",
      "inputs",
      "amax",
      "bias",
      "num_bits",
      "unsigned",
      "narrow_range",
      "trt_high_precision_dtype",
      "pass_through_bwd",
      "block_size",
      "axis"
    ],
    "backward": [
      "ctx",
      "grad_outputs"
    ]
  },
  "ScaledE4M3Function": {
    "symbolic": [
      "g",
      "inputs",
      "amax",
      "bias",
      "E",
      "M",
      "trt_high_precision_dtype",
      "pass_through_bwd"
    ],
    "forward": [
      "ctx",
      "inputs",
      "amax",
      "bias",
      "E",
      "M",
      "trt_high_precision_dtype",
      "pass_through_bwd"
    ],
    "backward": [
      "ctx",
      "grad_outputs"
    ]
  },
  "_dynamic_block_quantize_forward": [
    "ctx",
    "inputs",
    "block_size",
    "amax",
    "num_bits",
    "scale_bits",
    "trt_high_precision_dtype",
    "onnx_quantizer_type",
    "pass_through_bwd"
  ],
  "DynamicBlockQuantizationFunction": {
    "symbolic": [
      "g",
      "inputs",
      "block_size",
      "amax",
      "bias",
      "num_bits",
      "scale_bits",
      "trt_high_precision_dtype",
      "onnx_quantizer_type",
      "pass_through_bwd"
    ],
    "forward": [
      "ctx",
      "inputs",
      "block_size",
      "amax",
      "bias",
      "num_bits",
      "scale_bits",
      "trt_high_precision_dtype",
      "onnx_quantizer_type",
      "pass_through_bwd"
    ],
    "backward": [
      "ctx",
      "grad_outputs"
    ]
  },
  "_tensor_quant": [
    "inputs",
    "amax",
    "num_bits",
    "unsigned",
    "narrow_range"
  ],
  "fake_tensor_quant": [],
  "scaled_e4m3": [],
  "dynamic_block_quant": [],
  "reduce_block_amax": [
    "input_tensor",
    "block_sizes"
  ],
  "reduce_block_padding": [
    "input",
    "block_sizes",
    "pad_value"
  ],
  "convert_quantization_axis_to_reduce_axis": [
    "input",
    "axis"
  ],
  "reduce_amax": [
    "input",
    "axis",
    "keepdims",
    "squeeze_scalar"
  ],
  "reduce_sum": [
    "input",
    "axis",
    "keepdims"
  ],
  "weight_attr_names": [
    "module"
  ],
  "QuantizerAttrNames": [],
  "quantizer_attr_names": [
    "weight_name"
  ],
  "is_quantized": [
    "module"
  ],
  "is_quantized_linear": [
    "module"
  ],
  "is_quantized_column_parallel_linear": [
    "module"
  ],
  "is_quantized_row_parallel_linear": [
    "module"
  ],
  "is_quantized_parallel_linear": [
    "module"
  ],
  "calibrate_with_adapters": [
    "model",
    "args"
  ],
  "disable_lora_quantizers_in_config": [
    "config",
    "layers"
  ],
  "replace_function": [
    "package",
    "name",
    "new_func",
    "og_func_cache_name"
  ],
  "multi_context": [],
  "export_torch_mode": [],
  "is_torch_export_mode": [],
  "is_pow2": [
    "n"
  ],
  "_get_fsdp2_mesh": [
    "module"
  ],
  "_get_module_name": [
    "module",
    "root_model",
    "name_to_module"
  ],
  "_get_enclosing_fsdp_module": [
    "module",
    "root_model",
    "name_to_module"
  ],
  "fsdp2_weight_access_and_writeback_context": [
    "module",
    "root_model"
  ],
  "enable_weight_access_and_writeback": [
    "module",
    "root_model",
    "name_to_module"
  ],
  "get_quantizer_state_dict": [
    "model"
  ],
  "set_quantizer_state_dict": [
    "model",
    "quantizer_state_dict"
  ],
  "patch_fsdp_mp_dtypes": [],
  "get_prefixed_param_names": [
    "parent_model",
    "target_module"
  ],
  "create_fsdp_param_mapping": [
    "fsdp_param_list",
    "model"
  ],
  "no_requires_grad": [],
  "enable_fake_quant": [
    "module"
  ],
  "enable_quant": [
    "quantizer"
  ],
  "disable_calib": [
    "quantizer"
  ],
  "fsdp2_aware_weight_update": [
    "root_model",
    "modules_to_update",
    "reshard"
  ],
  "update_quant_cfg_with_kv_cache_quant": [
    "quant_cfg",
    "kv_cache_quant_cfg"
  ],
  "convert_to_quantized_model": [
    "model",
    "config"
  ],
  "convert_to_quantized_model_svdquant": [
    "model",
    "config"
  ],
  "restore_quantized_model": [
    "model",
    "config",
    "metadata"
  ],
  "restore_quantizer_state": [
    "model",
    "config",
    "metadata"
  ],
  "SVDQuantModuleRegistry": [],
  "create_and_replace_svdquant_linear_on_the_fly": [
    "model"
  ],
  "restore_svdquant_model": [
    "model",
    "config",
    "metadata"
  ],
  "update_quantize_metadata": [
    "model",
    "config",
    "metadata"
  ],
  "quantizer_state": [
    "model"
  ],
  "replace_quant_module": [
    "model",
    "version",
    "registry"
  ],
  "_replace_quant_module": [
    "model",
    "version",
    "registry"
  ],
  "set_quantizer_by_cfg": [
    "quant_model",
    "quant_cfg"
  ],
  "set_quantizer_attribute": [
    "quant_model",
    "wildcard_or_filter_func",
    "attribute",
    "parent_class"
  ],
  "set_quantizer_by_cfg_context": [
    "quant_model",
    "quant_cfg"
  ],
  "register": [
    "original_cls",
    "quantized_cls"
  ],
  "unregister": [
    "original_cls"
  ],
  "export_quantized_model": [
    "model",
    "config"
  ],
  "restore_export_quantized_model": [
    "model",
    "config",
    "metadata"
  ],
  "mha_valid_precisions": [],
  "torch_dtype_map": [],
  "export_int8": [
    "g",
    "inputs",
    "amax",
    "num_bits",
    "unsigned",
    "narrow_range",
    "trt_high_precision_dtype"
  ],
  "export_int4": [
    "g",
    "inputs",
    "amax",
    "num_bits",
    "trt_high_precision_dtype",
    "block_size",
    "axis"
  ],
  "_fp8_quantize": [
    "g",
    "inputs",
    "scale_inv",
    "trt_high_precision_dtype"
  ],
  "_fp8_dequantize": [
    "g",
    "inputs",
    "scale_inv",
    "trt_high_precision_dtype",
    "otype"
  ],
  "export_fp8": [
    "g",
    "inputs",
    "amax",
    "trt_high_precision_dtype"
  ],
  "scaled_dot_product_attention": [
    "g",
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal",
    "scale",
    "enable_gqa"
  ],
  "export_fp8_mha": [
    "g",
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal",
    "scale",
    "q_quantized_scale",
    "k_quantized_scale",
    "v_quantized_scale",
    "high_precision_flag",
    "disable_fp8_mha"
  ],
  "_fp4_dynamic_quantize": [
    "g",
    "inputs",
    "scale",
    "trt_high_precision_dtype",
    "block_size",
    "axis",
    "scale_type"
  ],
  "_fp4_dequantize": [
    "g",
    "inputs",
    "scale",
    "trt_high_precision_dtype"
  ],
  "_fp4_dequantize_2": [
    "g",
    "inputs",
    "dyn_scale",
    "block_size",
    "axis"
  ],
  "_mxfp8_dynamic_quantize": [
    "g",
    "inputs",
    "block_size",
    "axis"
  ],
  "_mxfp8_dequantize": [
    "g",
    "inputs",
    "scale",
    "block_size",
    "axis",
    "input_dtype"
  ],
  "export_mxfp8": [
    "g",
    "inputs",
    "onnx_quantizer_type",
    "block_size",
    "axis"
  ],
  "export_fp4": [
    "g",
    "inputs",
    "block_size",
    "amax",
    "num_bits",
    "trt_high_precision_dtype",
    "onnx_quantizer_type"
  ],
  "configure_linear_module_onnx_quantizers": [
    "model"
  ],
  "QuantizeModeRegistry": [],
  "QuantizeModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "next_prohibited_modes": [
      "self"
    ],
    "export_mode": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ],
    "update_for_save": [
      "self"
    ],
    "update_for_new_mode": [
      "self"
    ]
  },
  "QuantizeExportModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "is_export_mode": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ]
  },
  "RealQuantizeModeDescriptor": {
    "name": [
      "self"
    ],
    "next_modes": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ],
    "update_for_save": [
      "self"
    ],
    "update_for_new_mode": [
      "self"
    ]
  },
  "AutoQuantizeModeDescriptor": {
    "name": [
      "self"
    ]
  },
  "wrapped_calib_func": [
    "model",
    "config",
    "forward_loop",
    "func"
  ],
  "BaseCalibrateModeDescriptor": {
    "__init__": [
      "self"
    ],
    "_get_mode_name": [
      "cls",
      "algo_name",
      "check"
    ],
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ],
    "update_for_save": [
      "self"
    ],
    "update_for_new_mode": [
      "self"
    ]
  },
  "get_modelike_from_algo_cfg": [
    "algo_cfg"
  ],
  "_CalibrateModeRegistryCls": {
    "register_mode": [
      "self",
      "cls_descriptor"
    ]
  },
  "CalibrateModeRegistry": [],
  "NoneCalibrateModeDescriptor": {
    "config_class": [
      "self"
    ],
    "_calib_func": []
  },
  "MaxCalibrateModeDescriptor": {
    "config_class": [
      "self"
    ],
    "_calib_func": []
  },
  "MseCalibrateModeDescriptor": {
    "config_class": [
      "self"
    ],
    "_calib_func": []
  },
  "SmoothQuantModeDescriptor": {
    "config_class": [
      "self"
    ],
    "_calib_func": []
  },
  "AWQLiteModeDescriptor": {
    "config_class": [
      "self"
    ],
    "_calib_func": []
  },
  "AWQClipModeDescriptor": {
    "config_class": [
      "self"
    ],
    "_calib_func": []
  },
  "AWQFullModeDescriptor": {
    "config_class": [
      "self"
    ],
    "_calib_func": []
  },
  "SVDQuantModeDescriptor": {
    "config_class": [
      "self"
    ],
    "_calib_func": [],
    "restore": [
      "self"
    ]
  },
  "_default_disabled_quantizer_cfg": [],
  "INT8_DEFAULT_CFG": [],
  "INT8_SMOOTHQUANT_CFG": [],
  "INT8_WEIGHT_ONLY_CFG": [],
  "FP8_DEFAULT_CFG": [],
  "FP8_PER_CHANNEL_PER_TOKEN_CFG": [],
  "FP8_2D_BLOCKWISE_WEIGHT_ONLY_CFG": [],
  "INT4_BLOCKWISE_WEIGHT_ONLY_CFG": [],
  "INT4_AWQ_CFG": [],
  "W4A8_AWQ_BETA_CFG": [],
  "MXFP8_DEFAULT_CFG": [],
  "MXFP6_DEFAULT_CFG": [],
  "MXFP4_DEFAULT_CFG": [],
  "W4A8_MXFP4_FP8_CFG": [],
  "MXINT8_DEFAULT_CFG": [],
  "FP8_KV_CFG": [],
  "FP8_AFFINE_KV_CFG": [],
  "NVFP4_DEFAULT_CFG": [],
  "NVFP4_AWQ_LITE_CFG": [],
  "NVFP4_AWQ_CLIP_CFG": [],
  "NVFP4_AWQ_FULL_CFG": [],
  "NVFP4_AFFINE_KV_CFG": [],
  "NVFP4_KV_CFG": [],
  "NVFP4_FP8_MHA_CONFIG": [],
  "NVFP4_KV_ROTATE_CFG": [],
  "NVFP4_SVDQUANT_DEFAULT_CFG": [],
  "W4A8_NVFP4_FP8_CFG": [],
  "MXFP4_MLP_WEIGHT_ONLY_CFG": [],
  "NVFP4_MLP_WEIGHT_ONLY_CFG": [],
  "NVFP4_MLP_ONLY_CFG": [],
  "BiasType": [],
  "BiasMethod": [],
  "QuantizerAttributeConfig": {
    "validate_config": [
      "cls",
      "values"
    ],
    "validate_num_bits": [
      "self"
    ],
    "validate_learn_amax": [
      "cls",
      "v"
    ],
    "_get_block_quant_axes_and_sizes": [
      "block_sizes"
    ],
    "validate_block_sizes": [
      "cls",
      "v",
      "info"
    ],
    "validate_bias": [
      "cls",
      "v"
    ],
    "validate_calibrator": [
      "cls",
      "v",
      "info"
    ]
  },
  "QuantizeAlgorithmConfig": {},
  "MaxCalibConfig": {},
  "MseCalibConfig": {},
  "SmoothQuantCalibConfig": {},
  "AWQLiteCalibConfig": {},
  "AWQClipCalibConfig": {},
  "AWQFullCalibConfig": {},
  "SVDQuantConfig": {},
  "QuantizeQuantCfgType": [],
  "_QuantizeAlgoCfgType": [],
  "QuantizeAlgoCfgType": [],
  "QuantizeConfig": {},
  "CompressConfig": {},
  "CompressCfgType": [],
  "_QuantizeExportConfig": {},
  "need_calibration": [
    "config"
  ],
  "RealQuantModuleRegistry": [],
  "compress_convert": [
    "model",
    "config",
    "skip_real_quantize_weight"
  ],
  "compress_restore": [
    "model",
    "config",
    "metadata"
  ],
  "update_compress_metadata": [
    "model",
    "config",
    "metadata"
  ],
  "compress": [
    "model",
    "config"
  ],
  "is_real_quantized": [
    "model"
  ],
  "path": [],
  "get_cuda_ext": [
    "raise_if_failed"
  ],
  "get_cuda_ext_fp8": [
    "raise_if_failed"
  ],
  "get_cuda_ext_mx": [
    "raise_if_failed"
  ],
  "__getattr__": [
    "name"
  ],
  "precompile": [],
  "_Calibrator": {
    "__init__": [
      "self",
      "num_bits",
      "axis",
      "unsigned"
    ],
    "collect": [
      "self",
      "x"
    ],
    "reset": [
      "self"
    ],
    "compute_amax": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "HistogramCalibrator": {
    "__init__": [
      "self",
      "num_bits",
      "axis",
      "unsigned",
      "num_bins",
      "grow_method",
      "skip_zeros",
      "torch_hist"
    ],
    "collect": [
      "self",
      "x"
    ],
    "reset": [
      "self"
    ],
    "compute_amax": [
      "self",
      "method"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_compute_amax_entropy": [
    "calib_hist",
    "calib_bin_edges",
    "num_bits",
    "unsigned",
    "stride",
    "start_bin"
  ],
  "_compute_amax_mse": [
    "calib_hist",
    "calib_bin_edges",
    "num_bits",
    "unsigned",
    "stride",
    "start_bin"
  ],
  "_compute_amax_percentile": [
    "calib_hist",
    "calib_bin_edges",
    "percentile"
  ],
  "calibrate_weights": [
    "model",
    "method",
    "perchannel",
    "percentile",
    "num_bins"
  ],
  "MaxCalibrator": {
    "__init__": [
      "self",
      "num_bits",
      "axis",
      "unsigned",
      "track_amax"
    ],
    "amaxs": [
      "self"
    ],
    "collect": [
      "self",
      "x"
    ],
    "reset": [
      "self"
    ],
    "compute_amax": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "MseCalibrator": {
    "__init__": [
      "self",
      "amax",
      "axis",
      "num_steps",
      "start_multiplier",
      "stop_multiplier",
      "quant_func",
      "error_func"
    ],
    "collect": [
      "self",
      "x"
    ],
    "reset": [
      "self"
    ],
    "compute_amax": [
      "self",
      "verbose"
    ]
  },
  "compute_maxmin": [
    "inputs",
    "axis"
  ],
  "compute_maxmin_bias": [
    "inputs",
    "axis"
  ],
  "compute_mean_bias": [
    "inputs",
    "axis"
  ],
  "compute_bias": [
    "inputs",
    "axis",
    "method"
  ],
  "subtract_bias": [
    "inputs",
    "bias"
  ],
  "add_bias": [
    "inputs",
    "bias"
  ],
  "BiasCalibrator": {
    "__init__": [
      "self",
      "method",
      "axis"
    ],
    "collect": [
      "self",
      "x"
    ],
    "compute_bias": [
      "self"
    ],
    "compute_dynamic_bias": [
      "self",
      "inputs"
    ],
    "reset": [
      "self"
    ]
  },
  "_TORCH_TO_TL_DTYPE": [],
  "_torch_dtype_to_tl": [
    "dtype"
  ],
  "fp4_fake_quant_kernel": [
    "x_ptr",
    "y_ptr",
    "M",
    "N",
    "global_scale_ptr",
    "stride_xm",
    "stride_xn",
    "stride_ym",
    "stride_yn",
    "BLOCK_SIZE",
    "TILE_M",
    "TILE_N",
    "NUM_FP4_BLOCKS",
    "OUT_DTYPE"
  ],
  "fp4_fake_quant_block": [
    "x",
    "global_amax",
    "block_size",
    "tile_rows",
    "tile_cols",
    "num_warps",
    "num_stages"
  ],
  "fp4_dequantize_kernel": [
    "packed_ptr",
    "scale_ptr",
    "global_scale_ptr",
    "output_ptr",
    "N",
    "BLOCK_SIZE",
    "TILE_SIZE"
  ],
  "fp4_dequantize": [
    "packed_tensor",
    "scale_tensor",
    "global_scale",
    "block_size",
    "tile_size",
    "dtype"
  ],
  "IS_AVAILABLE": [],
  "e2m1_bounds": [],
  "e2m1_values": [],
  "NVFP4QTensor": {
    "e2m1_values_on_device": [],
    "e2m1_bounds_on_device": [],
    "get_e2m1_values": [
      "cls",
      "device"
    ],
    "get_e2m1_bounds": [
      "cls",
      "device"
    ],
    "get_weights_scaling_factor_2_from_quantizer": [
      "cls",
      "weight_quantizer"
    ],
    "get_weights_scaling_factor": [
      "cls",
      "input",
      "block_size",
      "weights_scaling_factor_2",
      "keep_high_precision"
    ],
    "get_weights_scaling_factor_2": [
      "cls",
      "input"
    ],
    "get_activation_scaling_factor": [
      "cls",
      "quantizer"
    ],
    "_cast_fp4": [
      "cls",
      "weight"
    ],
    "quantize": [
      "cls",
      "input",
      "block_size",
      "weights_scaling_factor",
      "weights_scaling_factor_2",
      "keep_high_precision",
      "try_tensorrt"
    ],
    "dequantize": [
      "self",
      "dtype",
      "fast"
    ]
  },
  "FP8QTensor": {
    "quantize": [
      "cls",
      "input",
      "scales",
      "axis",
      "block_sizes"
    ],
    "dequantize": [
      "self",
      "dtype"
    ]
  },
  "nf4_table": [],
  "_dequantize_scalers": [
    "scales",
    "double_scale",
    "scale_zeros",
    "dtype"
  ],
  "_quantize_to_nearest_lut": [
    "flatten_tensor",
    "lut"
  ],
  "_nf4_lookup": [
    "quantized_idx"
  ],
  "NF4QTensor": {
    "quantize": [
      "cls",
      "input",
      "block_size",
      "scale_block_size"
    ],
    "double_quantization": [
      "cls",
      "scales",
      "scale_block_size",
      "num_scale_bits"
    ],
    "dequantize": [
      "self",
      "dtype"
    ]
  },
  "MXFP4QTensor": {
    "E2M1_max": [],
    "E2M1_values": [],
    "E2M1_bounds": [],
    "quantize": [
      "cls",
      "input",
      "block_size"
    ],
    "dequantize": [
      "self",
      "dtype"
    ]
  },
  "QTensorType": {
    "INT4": [],
    "INT8": [],
    "FP8": [],
    "NF4": []
  },
  "BaseQuantizedTensor": {
    "__init__": [
      "self",
      "original_shape",
      "original_dtype",
      "quantized_data"
    ],
    "quantize": [
      "cls",
      "input",
      "block_size"
    ],
    "dequantize": [
      "self",
      "dtype"
    ]
  },
  "QTensorWrapper": {
    "__new__": [
      "cls",
      "qtensor",
      "metadata"
    ],
    "dim": [
      "self"
    ],
    "to": [
      "self"
    ],
    "get_qtensor": [
      "self"
    ],
    "get_state": [
      "self"
    ]
  },
  "QFSDPParam": {
    "__init__": [
      "self"
    ],
    "_setattr_on_modules": [
      "self",
      "param"
    ]
  },
  "dynamically_update_state_methods": [
    "module"
  ],
  "pack_real_quantize_weight": [
    "module",
    "force_quantize"
  ],
  "INT8QTensor": {
    "quantize": [
      "cls",
      "input",
      "scales",
      "axis",
      "block_sizes"
    ],
    "dequantize": [
      "self",
      "dtype"
    ]
  },
  "INT4QTensor": {
    "_get_quant_maxbound": [
      "num_bits"
    ],
    "quantize": [
      "cls",
      "input",
      "block_size"
    ],
    "dequantize": [
      "self",
      "dtype"
    ]
  },
  "ClipFunction": {
    "forward": [
      "ctx",
      "input",
      "clip_value_min",
      "clip_value_max"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "clip": [],
  "FastHadamardTransform": {
    "forward": [
      "ctx",
      "inputs"
    ],
    "backward": [
      "ctx",
      "grad_outputs"
    ]
  },
  "normalized_hadamard_transform": [
    "inputs"
  ],
  "QuantModule": {
    "modelopt_post_restore": [
      "self",
      "prefix"
    ],
    "fold_weight": [
      "self"
    ]
  },
  "QuantModuleRegistry": [],
  "QuantInputBase": {
    "default_quant_desc_input": [],
    "default_quant_desc_output": [],
    "forward": [
      "self",
      "input"
    ],
    "_setup": [
      "self"
    ]
  },
  "QuantLinearConvBase": {
    "default_quant_desc_weight": [],
    "quantize_weight": [
      "self"
    ],
    "_get_quantized_weight": [
      "module",
      "weight"
    ],
    "forward": [
      "self",
      "input"
    ],
    "_setup": [
      "self"
    ]
  },
  "_LegacyQuantInputBaseMixin": {
    "_quantized_cls": [],
    "default_quant_desc_input": [],
    "default_quant_desc_output": [],
    "__init__": [
      "self"
    ]
  },
  "_LegacyQuantLinearConvBaseMixin": {
    "_quantized_cls": [],
    "default_quant_desc_weight": [],
    "__init__": [
      "self"
    ]
  },
  "_QuantConv1d": {
    "default_quant_desc_weight": []
  },
  "QuantConv1d": {
    "default_quant_desc_weight": []
  },
  "_QuantConv2d": {
    "default_quant_desc_weight": []
  },
  "QuantConv2d": {
    "default_quant_desc_weight": []
  },
  "_QuantConv3d": {
    "default_quant_desc_weight": []
  },
  "QuantConv3d": {
    "default_quant_desc_weight": []
  },
  "_QuantConvTranspose1d": {
    "default_quant_desc_weight": []
  },
  "QuantConvTranspose1d": {
    "default_quant_desc_weight": []
  },
  "_QuantConvTranspose2d": {
    "default_quant_desc_weight": []
  },
  "QuantConvTranspose2d": {
    "default_quant_desc_weight": []
  },
  "_QuantConvTranspose3d": {
    "default_quant_desc_weight": []
  },
  "QuantConvTranspose3d": {
    "default_quant_desc_weight": []
  },
  "Conv1d": [],
  "Conv2d": [],
  "Conv3d": [],
  "ConvTranspose1d": [],
  "ConvTranspose2d": [],
  "ConvTranspose3d": [],
  "_cell_call_map": [],
  "_layer_call_name_map": [],
  "QuantRNNBase": {
    "default_quant_desc_weight": [],
    "default_quant_desc_input": [],
    "functionals_to_replace": [
      "self"
    ],
    "all_input_quantizers_disabled": [
      "self"
    ],
    "quantize_weight": [
      "self"
    ],
    "_get_quantized_weight_handler": [
      "weight_quantizer_name"
    ],
    "forward": [
      "self",
      "input"
    ],
    "_setup": [
      "self"
    ]
  },
  "QuantRNNFullBase": {
    "_disable_input_quantizers": [
      "self"
    ],
    "_enable_input_quantizers": [
      "self"
    ],
    "_disable_weight_quantizers": [
      "self"
    ],
    "_enable_weight_quantizer": [
      "self"
    ],
    "_setup": [
      "self"
    ]
  },
  "VFRNNForward": {
    "__init__": [
      "self",
      "mode",
      "bidirectional",
      "num_layers",
      "has_proj",
      "has_bias",
      "input_quantizers",
      "proj_input_quantizers",
      "batch_first"
    ],
    "forward": [
      "self",
      "layer_forwards",
      "input",
      "flat_weights",
      "hidden",
      "dropout",
      "training",
      "batch_sizes"
    ],
    "__call__": [
      "self"
    ]
  },
  "RNNLayerForward": {
    "__init__": [
      "self",
      "cell",
      "reverse",
      "variable_len"
    ],
    "__call__": [
      "self",
      "input",
      "hidden",
      "weights",
      "input_quantizer",
      "batch_sizes",
      "proj_input_quantizer"
    ]
  },
  "lstm_cell_with_proj": [
    "input",
    "hidden"
  ],
  "quantized_cell_forward": [
    "cell",
    "input",
    "hidden",
    "weights",
    "input_quantizer",
    "proj_input_quantizer"
  ],
  "get_quantized_rnn_layer_forward": [
    "cell",
    "reverse"
  ],
  "get_quantized_rnn_layer_variable_len_forward": [
    "cell"
  ],
  "get_quantized_rnn_layer_variable_len_reverse_forward": [
    "cell"
  ],
  "QuantInstanceNorm1d": {},
  "QuantInstanceNorm2d": {},
  "QuantInstanceNorm3d": {},
  "QuantMaxPool1d": {},
  "QuantMaxPool2d": {},
  "QuantMaxPool3d": {},
  "QuantAvgPool1d": {},
  "QuantAvgPool2d": {},
  "QuantAvgPool3d": {},
  "QuantAdaptiveAvgPool1d": {},
  "QuantAdaptiveAvgPool2d": {},
  "QuantAdaptiveAvgPool3d": {},
  "MaxPool1d": [],
  "MaxPool2d": [],
  "MaxPool3d": [],
  "AvgPool1d": [],
  "AvgPool2d": [],
  "AvgPool3d": [],
  "AdaptiveAvgPool1d": [],
  "AdaptiveAvgPool2d": [],
  "AdaptiveAvgPool3d": [],
  "QuantBackendEntrypoint": [],
  "register_quant_backend": [
    "name",
    "entrypoint"
  ],
  "unregister_quant_backend": [
    "name"
  ],
  "is_registered_quant_backend": [
    "name"
  ],
  "TensorQuantizerCache": {},
  "TensorQuantizer": {
    "_skip_properties_for_save_restore": [],
    "__init__": [
      "self",
      "quant_attribute_cfg",
      "if_quant",
      "if_calib",
      "amax"
    ],
    "set_from_attribute_config": [
      "self",
      "attribute_cfg"
    ],
    "dequantize": [
      "self",
      "inputs"
    ],
    "num_bits": [
      "self",
      "value"
    ],
    "maxbound": [
      "self"
    ],
    "unsigned": [
      "self",
      "value"
    ],
    "pre_quant_scale": [
      "self",
      "value"
    ],
    "amax": [
      "self",
      "value"
    ],
    "reset_amax": [
      "self"
    ],
    "reset_bias": [
      "self"
    ],
    "step_size": [
      "self"
    ],
    "axis": [
      "self",
      "value"
    ],
    "block_sizes": [
      "self",
      "value"
    ],
    "bias": [
      "self"
    ],
    "bias_axis": [
      "self",
      "value"
    ],
    "bias_method": [
      "self"
    ],
    "bias_type": [
      "self",
      "value"
    ],
    "bias_value": [
      "self",
      "value"
    ],
    "bias_calibrator": [
      "self"
    ],
    "fake_quant": [
      "self"
    ],
    "narrow_range": [
      "self",
      "value"
    ],
    "is_enabled": [
      "self"
    ],
    "disable": [
      "self"
    ],
    "enable": [
      "self"
    ],
    "trt_high_precision_dtype": [
      "self",
      "value"
    ],
    "is_mx_format": [
      "self"
    ],
    "is_static_block_quant": [
      "self"
    ],
    "disable_calib": [
      "self"
    ],
    "enable_calib": [
      "self"
    ],
    "disable_quant": [
      "self"
    ],
    "enable_quant": [
      "self"
    ],
    "load_calib_amax": [
      "self"
    ],
    "load_calib_bias": [
      "self"
    ],
    "_get_amax": [
      "self",
      "inputs"
    ],
    "validate_attr": [
      "self",
      "attr_value",
      "attr_name",
      "raise_error",
      "warn_error",
      "name"
    ],
    "_get_bias": [
      "self",
      "inputs"
    ],
    "_is_real_quantize_support": [
      "self"
    ],
    "_real_quantize": [
      "self",
      "inputs"
    ],
    "_fake_quantize": [
      "self",
      "inputs"
    ],
    "_check_onnx_readiness": [
      "self",
      "inputs"
    ],
    "_setup_for_blockquant": [
      "self",
      "inputs"
    ],
    "_process_for_blockquant": [
      "self",
      "inputs"
    ],
    "_reset_to_original_shape": [
      "self",
      "outputs"
    ],
    "_block_sizes_to_axis": [
      "self",
      "x"
    ],
    "export_amax": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "_short_amax": [
      "self",
      "fmt"
    ],
    "_short_tensor": [
      "self",
      "tensor",
      "fmt"
    ],
    "extra_repr": [
      "self"
    ],
    "_get_properties_for_modelopt_state": [
      "self"
    ],
    "_get_pytorch_state_metadata": [
      "self"
    ],
    "_del_pytorch_state": [
      "self"
    ],
    "_reset_pytorch_state_from_metadata": [
      "self",
      "metadata"
    ],
    "get_modelopt_state": [
      "self",
      "properties_only"
    ],
    "set_from_modelopt_state": [
      "self",
      "modelopt_state",
      "properties_only"
    ],
    "sync_amax_across_distributed_group": [
      "self",
      "parallel_group"
    ],
    "disable_pre_quant_scale": [
      "self"
    ],
    "collect": [
      "self",
      "inputs"
    ],
    "_set_buffer": [
      "self",
      "key",
      "value"
    ]
  },
  "SequentialQuantizer": {
    "_delegated_properties": [],
    "_delegated_methods": [],
    "__init__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "get_modelopt_state": [
      "self"
    ],
    "set_from_attribute_config": [
      "self",
      "attributes"
    ],
    "convert_to_single_quantizer": [
      "model",
      "indx"
    ]
  },
  "_QuantLinear": {
    "default_quant_desc_weight": [],
    "quantized_linear_fn": [
      "package",
      "func_name",
      "self",
      "input",
      "weight"
    ]
  },
  "QuantLinear": {
    "default_quant_desc_weight": []
  },
  "Linear": [],
  "SVDQuantTensorQuantizer": {
    "svdquant_lora_a": [
      "self",
      "value"
    ],
    "svdquant_lora_b": [
      "self",
      "value"
    ]
  },
  "SVDQuantLinear": {
    "_setup": [
      "self"
    ],
    "_not_sequential_quantizers": [
      "self"
    ],
    "_apply_pre_quant_scale": [
      "self",
      "input"
    ],
    "_compute_lora_residual": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "fold_weight": [
      "self"
    ]
  },
  "RealQuantLinear": {
    "list_of_scale_tensors": [],
    "allow_real_quant_gemm": [],
    "_should_run_real_quant_gemm": [
      "self"
    ],
    "has_real_quant_gemm_impl": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "_setup": [
      "self"
    ],
    "_apply": [
      "self",
      "fn",
      "recurse"
    ]
  },
  "all": [],
  "GEMMRegistry": {
    "__init__": [
      "self"
    ],
    "register": [
      "self",
      "gemm_func",
      "availability_check"
    ],
    "unregister": [
      "self",
      "gemm_func"
    ],
    "find_match": [
      "self",
      "module",
      "input"
    ],
    "__contains__": [
      "self",
      "gemm_func"
    ]
  },
  "gemm_registry": [],
  "enable_real_quant_gemm": [
    "model"
  ],
  "disable_real_quant_gemm": [
    "model"
  ],
  "is_real_quant_gemm_enabled": [
    "model"
  ],
  "nvfp4_gemm": [
    "quant_module",
    "input_tensor",
    "bias"
  ],
  "Nvfp4Linear": {
    "forward": [
      "ctx",
      "quant_module",
      "input_tensor",
      "weight",
      "bias",
      "allreduce_dgrad",
      "tp_group"
    ],
    "backward": [
      "ctx",
      "grad_outputs"
    ],
    "apply": [
      "cls"
    ]
  },
  "_nvfp4_availability_check": [
    "module",
    "input",
    "args",
    "kwargs"
  ],
  "fp8_compatible": [],
  "fp4_compatible": [],
  "FP8_MIN": [],
  "FP8_MAX": [],
  "_to_fp8": [
    "x",
    "scale"
  ],
  "_fp8_gemm_impl": [
    "input",
    "weight_fp8",
    "scale_a",
    "scale_b",
    "bias"
  ],
  "fp8_per_tensor_gemm": [
    "quant_module",
    "input",
    "bias"
  ],
  "_fp8_availability_check": [
    "module",
    "input",
    "args",
    "kwargs"
  ],
  "Fp8PerTensorLinear": {
    "forward": [
      "ctx",
      "quant_module",
      "input_tensor",
      "weight",
      "bias",
      "allreduce_dgrad",
      "tp_group"
    ],
    "backward": [
      "ctx",
      "grad_outputs"
    ],
    "apply": [
      "cls"
    ]
  },
  "real_quant_module_get_extra_state": [
    "self"
  ],
  "quant_module_get_extra_state": [
    "self"
  ],
  "real_quant_module_set_extra_state": [
    "self",
    "state"
  ],
  "quant_module_set_extra_state": [
    "self",
    "state"
  ],
  "_create_incompatible_method": [
    "method_name"
  ],
  "megatron_replace_quant_module_hook": [
    "model"
  ],
  "_MegatronParallelLinear": {
    "_functionals_to_replace": [],
    "_setup": [
      "self"
    ],
    "_process_quantizer_amax": [
      "self",
      "k",
      "v",
      "quantizer_state_dict"
    ],
    "_process_activation_quantizer_pre_quant_scale": [
      "self",
      "k",
      "v",
      "quantizer_state_dict"
    ],
    "_get_shard_axis_dict": [
      "self",
      "state_dict"
    ],
    "_parameter_to_keep_in_quantizer_state_dict": [
      "self",
      "key"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ],
    "_load_from_state_dict": [
      "self",
      "state_dict",
      "prefix"
    ]
  },
  "_MegatronColumnParallelLinear": {
    "_is_column_parallel": [],
    "_get_shard_axis_dict": [
      "self",
      "state_dict"
    ]
  },
  "_MegatronRowParallelLinear": {
    "_is_row_parallel": [],
    "_get_shard_axis_dict": [
      "self",
      "state_dict"
    ]
  },
  "_QuantMegatronMLP": {
    "_modelopt_state_keys": []
  },
  "_RealQuantMegatronParallelLinear": {
    "allow_real_quant_gemm": [],
    "_scale_tensor_shard_axis": [],
    "_parameter_to_keep_in_quantizer_state_dict": [
      "self",
      "key"
    ],
    "_get_shard_axis_dict": [
      "self",
      "state_dict"
    ],
    "modelopt_post_restore": [
      "self",
      "prefix"
    ],
    "_forward_impl": [
      "self",
      "input"
    ]
  },
  "_RealQuantMegatronColumnParallelLinear": {
    "_scale_tensor_shard_axis": [],
    "forward": [
      "self",
      "input"
    ]
  },
  "_RealQuantMegatronRowParallelLinear": {
    "_scale_tensor_shard_axis": [],
    "forward": [
      "self",
      "input"
    ]
  },
  "_MegatronSequentialMLP": {
    "_setup": [
      "self"
    ],
    "sync_moe_local_experts_amax": [
      "self"
    ],
    "sharded_state_dict": [
      "self",
      "prefix",
      "sharded_offsets",
      "metadata"
    ]
  },
  "_QuantMoELayer": {
    "_setup": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "_TE_VERSION": [],
  "_assert_te_fp8_enabled": [],
  "_QuantTELinear": {
    "_functionals_to_replace": [
      "self",
      "value"
    ],
    "_setup": [
      "self"
    ],
    "te_quantized_linear_fn": [
      "package",
      "func_name",
      "self"
    ],
    "_quantized_linear_fn": []
  },
  "_QuantTEGroupedLinear": {
    "_functionals_to_replace": [
      "self",
      "value"
    ],
    "_setup": [
      "self"
    ],
    "modelopt_post_restore": [
      "self",
      "prefix"
    ],
    "te_grouped_quantized_linear_fn": [
      "package",
      "func_name",
      "self"
    ],
    "_quantized_linear_fn": []
  },
  "_QuantLayerNormLinearFunc": {
    "_get_original_gemm": [],
    "_gemm_replace_args": [],
    "forward": [
      "ctx",
      "inp",
      "ln_weight",
      "ln_bias",
      "weight"
    ],
    "backward": [
      "ctx"
    ]
  },
  "_QuantTELayerNormLinear": {
    "_functionals_to_replace": [],
    "_setup": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "QuantPyGLinear": {
    "default_quant_desc_weight": []
  },
  "QuantizationArguments": {},
  "QuantizationArgumentsWithConfig": {},
  "check_awq_smoothquant": [
    "quant_cfg"
  ],
  "QATTrainer": {
    "__init__": [
      "self"
    ],
    "_save_modelopt_state_with_weights": [
      "self"
    ],
    "_restore_modelopt_state_with_weights": [
      "self"
    ],
    "_quantize_model": [
      "self"
    ],
    "training_step": [
      "self"
    ],
    "prediction_step": [
      "self"
    ],
    "evaluate": [
      "self"
    ],
    "train": [
      "self"
    ],
    "save_model": [
      "self"
    ],
    "_load_best_model": [
      "self"
    ],
    "_update_config_json_dtype": [
      "self",
      "output_dir",
      "dtype_str"
    ],
    "_patch_accelerate_for_fsdp2_fix": [
      "self"
    ]
  },
  "QADTrainer": {
    "_quantize_model": [
      "self"
    ]
  },
  "_FairscaleParallelLinear": {
    "_functionals_to_replace": [],
    "_setup": [
      "self"
    ]
  },
  "_FairscaleColumnParallelLinear": {
    "_is_column_parallel": []
  },
  "_FairscaleRowParallelLinear": {
    "_is_row_parallel": []
  },
  "QATSFTTrainer": {},
  "_QuantLoRACompatibleLinearConvBase": {
    "_setup": [
      "self"
    ]
  },
  "_QuantLoRACompatibleConv": {
    "default_quant_desc_weight": []
  },
  "_QuantLoRACompatibleLinear": {
    "default_quant_desc_weight": []
  },
  "_quantized_bmm": [
    "self",
    "input",
    "mat2"
  ],
  "_quantized_baddbmm": [
    "self",
    "input",
    "batch1",
    "batch2"
  ],
  "_quantized_sdpa": [
    "self"
  ],
  "_QuantAttention": {
    "_functionals_to_replace": [],
    "functionals_to_replace": [
      "self"
    ],
    "_setup": [
      "self"
    ]
  },
  "original_scaled_dot_product_attention": [],
  "FP8SDPA": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "q_quantized_scale",
      "k_quantized_scale",
      "v_quantized_scale",
      "high_precision_flag",
      "disable_fp8_mha"
    ],
    "symbolic": [
      "g",
      "query",
      "key",
      "value",
      "attn_mask",
      "dropout_p",
      "is_causal",
      "scale",
      "q_quantized_scale",
      "k_quantized_scale",
      "v_quantized_scale",
      "high_precision_flag",
      "disable_fp8_mha"
    ]
  },
  "make_deepspeed_compatible": [
    "model"
  ],
  "register_attention_for_kv_quant": [
    "attention_cls"
  ],
  "_create_quantized_class_from_ast": [
    "head",
    "org_class",
    "new_class_name",
    "temp_file_name"
  ],
  "_ApexParallelLinear": {
    "_setup": [
      "self"
    ]
  },
  "_ApexColumnParallelLinear": {
    "_is_column_parallel": []
  },
  "_ApexRowParallelLinear": {
    "_is_row_parallel": []
  },
  "_T5QuantAttention": {
    "_quantized_matmul": [
      "self",
      "batch1",
      "batch2"
    ],
    "_setup": [
      "self"
    ],
    "is_compatible_attention": [
      "attn"
    ],
    "forward": [
      "self"
    ]
  },
  "register_hf_attentions_on_the_fly": [
    "model"
  ],
  "HFParallelLinear": {
    "supported_hf_tp_plans": [],
    "shard": [],
    "_setup": [
      "self"
    ],
    "is_compatible": [
      "cls",
      "linear"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HFColumnParallelLinear": {
    "supported_hf_tp_plans": [],
    "shard": []
  },
  "HFRowParallelLinear": {
    "supported_hf_tp_plans": [],
    "shard": []
  },
  "_QuantHFParallelLinear": {
    "_functionals_to_replace": [],
    "fold_weight": [
      "self"
    ],
    "enable_weight_access_and_writeback": [
      "self"
    ]
  },
  "QuantHFColumnParallelLinear": {
    "_is_column_parallel": []
  },
  "QuantHFRowParallelLinear": {
    "_is_row_parallel": []
  },
  "convert_hf_parallel_linears_on_the_fly": [
    "model"
  ],
  "_TransposedQuantization": {
    "forward": [
      "ctx",
      "inputs",
      "quantizer"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "_transposed_quantize": [],
  "_QuantSparseMoe": {
    "_setup": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "_QuantLlama4TextExperts": {
    "_setup": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "_QuantDbrxExperts": {
    "_setup": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "weights",
      "top_weights",
      "top_experts"
    ]
  },
  "_QuantDbrxExpertGLU": {
    "_setup": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "expert_idx"
    ]
  },
  "_QuantDbrxFFN": {
    "num_experts": [
      "self"
    ],
    "top_k": [
      "self",
      "value"
    ]
  },
  "_QuantGptOssExperts": {
    "_get_quantized_weight": [
      "quantizer",
      "module",
      "weight"
    ],
    "_setup_for_weight_quantization": [
      "self"
    ],
    "_setup": [
      "self"
    ],
    "functionals_to_replace": [
      "self"
    ],
    "quantize_weight": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "router_indices",
      "routing_weights"
    ]
  },
  "register_dbrx_moe_on_the_fly": [
    "model"
  ],
  "register_falcon_linears_on_the_fly": [
    "model"
  ],
  "_is_supported_hf_model": [
    "model"
  ],
  "setup_model_for_gradient_checkpointing": [
    "model"
  ],
  "_is_param_grad_enabled_for_auto_quantize": [
    "pname",
    "model"
  ],
  "_QuantLoraLinear": {
    "_setup": [
      "self"
    ],
    "_is_compressed_weight": [
      "self",
      "weight"
    ],
    "forward": [
      "self",
      "x"
    ],
    "merge": [
      "self"
    ]
  },
  "_QuantParamWrapper": {
    "_setup": [
      "self"
    ],
    "_activate_lora": [
      "self",
      "active_adapters"
    ]
  },
  "CUSTOM_POST_CONVERSION_PLUGINS": [],
  "register_custom_post_conversion_plugins": [
    "model"
  ],
  "_QuantFunctionalMixin": {
    "functionals_to_replace": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "_ParallelLinear": {
    "_is_column_parallel": [],
    "_is_row_parallel": [],
    "functionals_to_replace": [
      "self"
    ],
    "_setup": [
      "self"
    ],
    "modelopt_post_restore": [
      "self",
      "prefix"
    ]
  },
  "_get_cpu_offload_hook": [
    "hook"
  ],
  "weight_access_and_writeback_context": [
    "module"
  ],
  "init_quantized_weights": [
    "quant_cfg",
    "gpu_mem_percentage",
    "quant_gemm"
  ],
  "vllm_shared_fused_moe_layer": [],
  "vllm_fused_moe_package": [],
  "FakeQuantMethod": {
    "__init__": [
      "self",
      "quant_method"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "create_parallel_state": [],
  "_VLLMParallelLinear": {
    "_setup": [
      "self"
    ],
    "forward": [
      "self",
      "input_"
    ]
  },
  "_QuantVLLMRowParallelLinear": {},
  "_QuantVLLMColumnParallelLinear": {},
  "_QuantVLLMMergedColumnParallelLinear": {},
  "_QuantVLLMQKVParallelLinear": {},
  "_QuantFusedMoEBase": {
    "_setup": [
      "self"
    ],
    "invoke_fused_moe_quantized": [
      "self",
      "A",
      "B",
      "C"
    ],
    "forward": [
      "self",
      "hidden_states",
      "router_logits"
    ],
    "fold_weight": [
      "self"
    ]
  },
  "_QuantVLLMFusedMoE": {},
  "_QuantVLLMAttention": {
    "_setup": [
      "self"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value"
    ]
  },
  "_QuantVLLMCrossAttention": {},
  "_QuantVLLMEncoderOnlyAttention": {},
  "SparseAttentionModule": {
    "set_from_attribute_config": [
      "self",
      "attribute_cfg"
    ],
    "_init_sparse_method": [
      "self"
    ],
    "enable": [
      "self"
    ],
    "disable": [
      "self"
    ],
    "is_enabled": [
      "self"
    ],
    "get_stats": [
      "self"
    ],
    "_setup": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "_get_sparse_context": [
      "self"
    ],
    "_create_softmax_patch_context": [
      "self"
    ],
    "_create_sparse_softmax": [
      "self"
    ]
  },
  "SparseAttentionRegistry": [],
  "sparsify": [
    "model",
    "config",
    "forward_loop"
  ],
  "is_attn_sparsified": [
    "model"
  ],
  "convert_to_sparse_attention_model": [
    "model",
    "config"
  ],
  "replace_sparse_attention_modules": [
    "model",
    "version"
  ],
  "_replace_sparse_attention_modules": [
    "model",
    "version"
  ],
  "set_sparse_attention_by_cfg": [
    "model",
    "sparse_cfg"
  ],
  "set_sparse_attention_attribute": [
    "model",
    "wildcard_or_filter",
    "attribute_cfg"
  ],
  "restore_sparse_attention_model": [
    "model",
    "config",
    "metadata"
  ],
  "restore_sparse_attention_state": [
    "model",
    "state_dict"
  ],
  "update_sparse_attention_metadata": [
    "model",
    "config",
    "metadata"
  ],
  "disable_sparse_attention": [
    "model",
    "wildcard_or_filter_func"
  ],
  "enable_sparse_attention": [
    "model",
    "wildcard_or_filter_func"
  ],
  "SparseAttentionModeRegistry": [],
  "SparseAttentionModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "next_prohibited_modes": [
      "self"
    ],
    "export_mode": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ],
    "update_for_save": [
      "self"
    ],
    "update_for_new_mode": [
      "self"
    ]
  },
  "SparseAttributeConfig": [],
  "SparseAttentionCfgType": [],
  "SparseAttentionAttributeConfig": {
    "validate_method": [
      "cls",
      "v"
    ],
    "validate_backend": [
      "cls",
      "v"
    ],
    "validate_block_size": [
      "cls",
      "v"
    ],
    "validate_threshold": [
      "cls",
      "v"
    ]
  },
  "SKIP_SOFTMAX_DEFAULT": [],
  "SparseAttentionConfig": {},
  "FlashSkipSoftmaxConfig": {},
  "FlashSkipSoftmax": {
    "__init__": [
      "self",
      "method_config"
    ],
    "_update_threshold": [
      "self",
      "phase"
    ],
    "_infer_phase": [
      "self",
      "attention_scores"
    ],
    "_reshape_to_blocks": [
      "self",
      "tensor",
      "br",
      "bc"
    ],
    "calc_correction_factor_and_p": [
      "self",
      "attn_weights",
      "phase"
    ],
    "apply_sparsity": [
      "self",
      "query",
      "key",
      "value",
      "attention_scores"
    ],
    "name": [
      "self"
    ]
  },
  "SparseAttentionMethod": {
    "apply_sparsity": [
      "self",
      "query",
      "key",
      "value",
      "attention_scores"
    ],
    "name": [
      "self"
    ]
  },
  "_version_key": [
    "version_str"
  ],
  "register_sparse_method": [
    "name",
    "version"
  ],
  "get_sparse_method": [
    "name",
    "version"
  ],
  "_GenericSparseAttention": {
    "_setup": [
      "self"
    ],
    "get_attn_type": [
      "self",
      "attn_module"
    ]
  },
  "register_sparse_attention_on_the_fly": [
    "model"
  ],
  "_is_supported_model": [
    "model"
  ],
  "invert": [
    "hessian"
  ],
  "prepare": [
    "tensor",
    "hessian",
    "hessian_damp"
  ],
  "create_sgpt_mask": [
    "tensor",
    "hessian",
    "config"
  ],
  "SparseGPTSearcher": {
    "default_search_config": [
      "self"
    ],
    "_check_weight_size": [
      "self",
      "weight",
      "mod_name"
    ],
    "_compute_mask": [
      "self",
      "module"
    ],
    "before_search": [
      "self"
    ],
    "after_search": [
      "self"
    ],
    "_is_memory_sufficient": [
      "device_id",
      "threshold"
    ],
    "_setup_forward_hook": [
      "cls",
      "mod"
    ],
    "_hook_compute_hessian": [
      "cls",
      "mod",
      "inp",
      "out"
    ]
  },
  "SpDMRegistry": [],
  "SparseModule": {
    "_get_weight": [
      "mod",
      "weight"
    ],
    "_setup": [
      "self"
    ],
    "modify": [
      "self"
    ],
    "set_mask": [
      "self",
      "value"
    ]
  },
  "SparsityModeRegistry": [],
  "convert_sparse_model": [
    "model",
    "config"
  ],
  "restore_sparse_model": [
    "model",
    "config",
    "metadata"
  ],
  "update_sparse_metadata": [
    "model",
    "config",
    "metadata"
  ],
  "export_sparse": [
    "model",
    "config"
  ],
  "restore_export_sparse": [
    "model",
    "config",
    "metadata"
  ],
  "SparseMagnitudeModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "next_modes": [
      "self"
    ],
    "export_mode": [
      "self"
    ],
    "search_algorithm": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ],
    "update_for_save": [
      "self"
    ],
    "update_for_new_mode": [
      "self"
    ]
  },
  "SparseGPTModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "search_algorithm": [
      "self"
    ]
  },
  "ExportSparseModeDescriptor": {
    "name": [
      "self"
    ],
    "config_class": [
      "self"
    ],
    "is_export_mode": [
      "self"
    ],
    "convert": [
      "self"
    ],
    "restore": [
      "self"
    ]
  },
  "SparseMagnitudeConfig": [],
  "SparseGPTConfig": [],
  "ExportSparseConfig": {},
  "get_nmprune_info": [
    "pattern"
  ],
  "fill": [
    "x"
  ],
  "reshape_1d": [
    "matrix",
    "m"
  ],
  "compute_valid_1d_patterns": [
    "m",
    "n"
  ],
  "mn_1d_best": [
    "matrix",
    "m",
    "n"
  ],
  "m4n2_1d": [
    "mat"
  ],
  "create_asp_mask": [
    "tensor",
    "pattern"
  ],
  "MagnitudeSearcher": {
    "_check_weight_size": [
      "self",
      "weight",
      "mod_name"
    ],
    "_compute_mask": [
      "self",
      "module"
    ]
  },
  "BaseSparseSearcher": {
    "_pattern_2_4": [],
    "default_search_config": [
      "self"
    ],
    "default_state_dict": [
      "self"
    ],
    "sanitize_search_config": [
      "self",
      "config"
    ],
    "_check_weight_size": [
      "self",
      "weight",
      "mod_name"
    ],
    "_compute_mask": [
      "self",
      "module"
    ],
    "_named_sparsifiable_modules": [
      "self"
    ],
    "run_search": [
      "self"
    ]
  },
  "_SparseMegatronMLP": {
    "_modelopt_state_keys": []
  },
  "_get_extra_rules": []
}