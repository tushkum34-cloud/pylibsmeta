{
  "__all__": [],
  "function_call_to_param": [
    "func"
  ],
  "custom_to_param": [
    "func"
  ],
  "function_to_param": [
    "func"
  ],
  "tool_calls_to_params": [
    "tools"
  ],
  "llm_tool_to_param": [
    "tool"
  ],
  "llm_tools_to_param": [
    "tools"
  ],
  "chat_completion_message_to_param": [
    "message"
  ],
  "build_chat_messages": [
    "prompt",
    "history",
    "special_token_behavior"
  ],
  "_rewrite_prompt": [
    "prompt",
    "special_token_behavior"
  ],
  "is_reasoning_model": [
    "model"
  ],
  "OpenAIRateLimitBehavior": {
    "NONE": [],
    "LIMIT": [],
    "SLEEP": []
  },
  "OpenAISpecialTokenBehavior": {
    "KEEP": [],
    "REMOVE": [],
    "REPLACE": []
  },
  "CommonOpenAIConfig": {},
  "PublicOpenAIConfig": {},
  "AzureOpenAIConfig": {},
  "OpenAIConfig": [],
  "_OpenAIBaseRole": {
    "role": [],
    "_substitute_template": [
      "self",
      "value",
      "variables"
    ],
    "__str__": [
      "self"
    ],
    "__hash__": [
      "self"
    ]
  },
  "_OpenAISystemRole": {
    "message": [
      "self",
      "content"
    ]
  },
  "_OpenAIUserRole": {
    "message": [
      "self",
      "content"
    ]
  },
  "_OpenAIAssistantRole": {
    "message": [
      "self",
      "content"
    ]
  },
  "_OpenAIToolRole": {
    "message": [
      "self",
      "content",
      "tool_call_id"
    ]
  },
  "_OpenAIFunctionRole": {
    "message": [
      "self",
      "content",
      "name"
    ]
  },
  "OpenAIChatRole": {},
  "OpenAIParseToolsLLM": {
    "__init__": [
      "self",
      "delegate"
    ],
    "child": [
      "self",
      "name"
    ],
    "is_reasoning_model": [
      "self"
    ],
    "_add_tools_to_parameters": [
      "self",
      "parameters",
      "tools"
    ],
    "_parse_arguments": [
      "self",
      "tool_call"
    ],
    "_parse_tool_calls": [
      "self",
      "raw_output"
    ],
    "__call__": [
      "self",
      "prompt"
    ]
  },
  "TextChunk": {},
  "InvalidMaxLengthError": {},
  "OpenAITextService": {
    "__init__": [
      "self",
      "encoding"
    ],
    "encoding": [
      "self"
    ],
    "count_tokens": [
      "self",
      "text"
    ],
    "trim_to_max_tokens": [
      "self",
      "text",
      "max_length"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "tokens"
    ],
    "split": [
      "self",
      "text",
      "max_length"
    ]
  },
  "OpenAITokenEstimator": {
    "__init__": [
      "self",
      "encoding"
    ],
    "__call__": [
      "self",
      "prompt",
      "kwargs"
    ]
  },
  "OpenAIBackoffLimiter": {
    "__init__": [
      "self"
    ],
    "acquire": [
      "self",
      "manifest"
    ],
    "release": [
      "self",
      "manifest"
    ],
    "sleep_for": [
      "self",
      "time"
    ]
  },
  "OpenAIRetryableErrorHandler": {
    "__init__": [
      "self",
      "limiter",
      "strategy"
    ],
    "__call__": [
      "self",
      "error"
    ],
    "_handle_retry_after": [
      "self",
      "retry_after"
    ]
  },
  "OpenAIEmbeddingsCacheAdapter": {
    "__init__": [
      "self",
      "cache",
      "model",
      "global_parameters"
    ],
    "build_cache_key": [
      "self",
      "prompt",
      "kwargs"
    ],
    "get_cache_input_data": [
      "self",
      "prompt",
      "kwargs"
    ],
    "_build_embeddings_parameters": [
      "self",
      "local_parameters"
    ],
    "wrap_output": [
      "self",
      "prompt",
      "kwargs",
      "cached_result"
    ],
    "dump_raw_model": [
      "self",
      "output"
    ]
  },
  "OpenAITextChatCacheAdapter": {
    "__init__": [
      "self",
      "cache",
      "model",
      "global_parameters",
      "special_token_behavior"
    ],
    "build_cache_key": [
      "self",
      "prompt",
      "kwargs"
    ],
    "get_cache_input_data": [
      "self",
      "prompt",
      "kwargs"
    ],
    "_build_completion_parameters": [
      "self",
      "local_parameters"
    ],
    "wrap_output": [
      "self",
      "prompt",
      "kwargs",
      "cached_result"
    ],
    "dump_raw_model": [
      "self",
      "output"
    ]
  },
  "OpenAIHistoryExtractor": {
    "extract_history": [
      "self",
      "history",
      "output"
    ]
  },
  "TOutputWithUsageMetrics": [],
  "OpenAIUsageExtractor": {
    "extract_usage": [
      "self",
      "output"
    ]
  },
  "create_json_handler": [
    "strategy",
    "max_retries"
  ],
  "OpenAIJsonMarshaler": {
    "inject_json_string": [
      "self",
      "json_string",
      "output"
    ],
    "extract_json_string": [
      "self",
      "output"
    ]
  },
  "OpenAIClient": [],
  "OpenAIChatLLM": {
    "__call__": [
      "self",
      "prompt"
    ],
    "child": [
      "self",
      "name"
    ],
    "is_reasoning_model": [
      "self"
    ]
  },
  "_ChatCompletionAssistantMessageParam": {},
  "OpenAIChatParameters": {},
  "OpenAIChatOutput": {},
  "OpenAIStreamingChatOutput": {},
  "OpenAIEmbeddingsParameters": {},
  "OpenAIEmbeddingsOutput": {},
  "OpenAIEmbeddingsLLMImpl": {
    "__init__": [
      "self",
      "client",
      "model"
    ],
    "child": [
      "self",
      "name"
    ],
    "is_reasoning_model": [
      "self"
    ],
    "_build_embeddings_parameters": [
      "self",
      "local_parameters"
    ],
    "_execute_llm": [
      "self",
      "prompt",
      "kwargs"
    ]
  },
  "CannotSplitBatchError": {},
  "OpenAIEmbeddingBatcher": {
    "__init__": [
      "self"
    ],
    "child": [
      "self",
      "name"
    ],
    "is_reasoning_model": [
      "self"
    ],
    "_invoke": [
      "self",
      "batch"
    ],
    "_compute_cost": [
      "self",
      "content"
    ]
  },
  "OpenAINoChoicesAvailableError": {
    "__init__": [
      "self"
    ]
  },
  "OpenAITextChatLLMImpl": {
    "__init__": [
      "self",
      "client",
      "model"
    ],
    "child": [
      "self",
      "name"
    ],
    "is_reasoning_model": [
      "self"
    ],
    "_build_completion_parameters": [
      "self",
      "local_parameters"
    ],
    "_execute_llm": [
      "self",
      "prompt",
      "kwargs"
    ],
    "_rewrite_input": [
      "self",
      "prompt",
      "kwargs"
    ],
    "_enable_oai_json_mode": [
      "self",
      "parameters"
    ]
  },
  "OpenAIChatLLMImpl": {
    "__init__": [
      "self"
    ],
    "child": [
      "self",
      "name"
    ],
    "is_reasoning_model": [
      "self"
    ],
    "__call__": [
      "self",
      "prompt"
    ]
  },
  "OpenAIStreamingChatLLMImpl": {
    "__init__": [
      "self",
      "client",
      "model"
    ],
    "child": [
      "self",
      "name"
    ],
    "is_reasoning_model": [
      "self"
    ],
    "_build_completion_parameters": [
      "self",
      "local_parameters"
    ],
    "_execute_llm": [
      "self",
      "prompt",
      "kwargs"
    ]
  },
  "StreamingChatIterator": {
    "__init__": [
      "self",
      "chunks",
      "events"
    ],
    "on_usage": [
      "self",
      "cb"
    ],
    "__stream__": [
      "self"
    ],
    "iterator": [
      "self"
    ],
    "close": [
      "self"
    ]
  },
  "create_azure_openai_client": [
    "config"
  ],
  "_get_azure_ad_token_provider": [
    "config",
    "credential"
  ],
  "create_openai_embeddings_llm": [
    "config"
  ],
  "_create_cached_embeddings_handler": [
    "config",
    "cache",
    "events"
  ],
  "_get_encoding": [
    "encoding_name"
  ],
  "_get_header_value": [
    "output",
    "header_name"
  ],
  "_tpm_reconciler": [
    "output"
  ],
  "_rpm_reconciler": [
    "output"
  ],
  "create_backoff_limiter": [],
  "create_limiter": [
    "config",
    "backoff_limiter"
  ],
  "create_rate_limiter": [],
  "create_retryer": [],
  "create_openai_client": [
    "config"
  ],
  "create_public_openai_client": [
    "config"
  ],
  "get_max_retries": [
    "config"
  ],
  "create_openai_chat_llm": [
    "config"
  ],
  "_create_openai_text_chat_llm": [],
  "_create_openai_streaming_chat_llm": [],
  "_create_cached_chat_handler": [
    "config",
    "cache",
    "events"
  ],
  "Cache": {
    "has": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key"
    ],
    "remove": [
      "self",
      "key"
    ],
    "clear": [
      "self"
    ],
    "sweep": [
      "self",
      "age"
    ],
    "set": [
      "self",
      "key",
      "value",
      "metadata"
    ],
    "child": [
      "self",
      "key"
    ],
    "create_key": [
      "self",
      "data"
    ]
  },
  "_hash": [
    "_input"
  ],
  "InvalidBlobContainerNameError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "InvalidBlobCacheArgumentsError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "BlobCache": {
    "__init__": [
      "self"
    ],
    "container_name": [
      "self"
    ],
    "blob_service_client": [
      "self"
    ],
    "container_client": [
      "self"
    ],
    "blob_client": [
      "self",
      "name"
    ],
    "create_container": [
      "self"
    ],
    "delete_container": [
      "self"
    ],
    "has": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key"
    ],
    "set": [
      "self",
      "key",
      "value",
      "metadata"
    ],
    "remove": [
      "self",
      "key"
    ],
    "clear": [
      "self"
    ],
    "child": [
      "self",
      "key"
    ],
    "_keyname": [
      "self",
      "key"
    ]
  },
  "validate_blob_container_name": [
    "container_name"
  ],
  "_log": [],
  "FileCache": {
    "__init__": [
      "self",
      "cache_path",
      "encoding"
    ],
    "root_path": [
      "self"
    ],
    "sweep": [
      "self",
      "age"
    ],
    "has": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key"
    ],
    "remove": [
      "self",
      "key"
    ],
    "clear": [
      "self"
    ],
    "set": [
      "self",
      "key",
      "value",
      "metadata"
    ],
    "child": [
      "self",
      "key"
    ]
  },
  "_content_text": [
    "item"
  ],
  "_clear_dir": [
    "path"
  ],
  "CallInput": [],
  "CallOutput": [],
  "BatchResponseInvalidError": {
    "__init__": [
      "self",
      "expected",
      "actual"
    ]
  },
  "Call": {},
  "CallBatch": {
    "cost": [
      "self"
    ],
    "num_calls": [
      "self"
    ],
    "on_response": [
      "self",
      "response"
    ]
  },
  "Batcher": {
    "__init__": [
      "self"
    ],
    "max_batch_size": [
      "self"
    ],
    "max_batch_cost": [
      "self"
    ],
    "__call__": [
      "self",
      "content"
    ],
    "flush": [
      "self"
    ],
    "_can_add_to_batch": [
      "self",
      "call"
    ],
    "_submit_inflight_batch": [
      "self"
    ],
    "_process_batch": [
      "self",
      "batch"
    ],
    "_compute_cost": [
      "self",
      "content"
    ],
    "_invoke": [
      "self",
      "batch"
    ]
  },
  "get_current_ts": [],
  "SlidingWindowEntry": {},
  "SlidingWindow": {
    "__init__": [
      "self",
      "time_window"
    ],
    "_track_total": [
      "self",
      "value"
    ],
    "_remove_outside_window": [
      "self",
      "now"
    ],
    "insert": [
      "self",
      "value"
    ],
    "sum": [
      "self"
    ],
    "avg": [
      "self"
    ]
  },
  "NoopLimiter": {
    "acquire": [
      "self",
      "manifest"
    ],
    "release": [
      "self",
      "manifest"
    ]
  },
  "LimitContext": {
    "__init__": [
      "self",
      "limiter",
      "manifest"
    ],
    "__aenter__": [
      "self"
    ],
    "__aexit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "Limiter": {
    "acquire": [
      "self",
      "manifest"
    ],
    "release": [
      "self",
      "manifest"
    ],
    "use": [
      "self",
      "manifest"
    ],
    "reconcile": [
      "self",
      "output"
    ]
  },
  "TPMLimiter": {
    "__init__": [
      "self",
      "limiter",
      "tokens_per_minute",
      "reconciler"
    ],
    "acquire": [
      "self",
      "manifest"
    ],
    "release": [
      "self",
      "manifest"
    ],
    "reconcile": [
      "self",
      "output"
    ],
    "from_tpm": [
      "cls",
      "tokens_per_minute"
    ]
  },
  "ConcurrencyLimiter": {
    "__init__": [
      "self",
      "semaphore"
    ],
    "acquire": [
      "self",
      "manifest"
    ],
    "release": [
      "self",
      "manifest"
    ],
    "from_max_concurrency": [
      "cls",
      "max_concurrency"
    ]
  },
  "update_limiter": [
    "limiter",
    "reconciliation"
  ],
  "LimitReconciliation": {},
  "LimitReconciler": [],
  "Manifest": {},
  "LimitUpdate": {},
  "RPMLimiter": {
    "__init__": [
      "self",
      "limiter",
      "reconciler"
    ],
    "acquire": [
      "self",
      "manifest"
    ],
    "release": [
      "self",
      "manifest"
    ],
    "reconcile": [
      "self",
      "output"
    ],
    "from_rpm": [
      "cls",
      "requests_per_minute",
      "burst_mode",
      "reconciler"
    ]
  },
  "_rpm_to_rps": [
    "rpm"
  ],
  "CompositeLimiter": {
    "__init__": [
      "self",
      "limiters"
    ],
    "acquire": [
      "self",
      "manifest"
    ],
    "release": [
      "self",
      "manifest"
    ],
    "reconcile": [
      "self",
      "output"
    ]
  },
  "LOGGER": [],
  "LLMEventsLogger": {
    "__init__": [
      "self"
    ],
    "on_error": [
      "self",
      "error",
      "traceback",
      "arguments"
    ],
    "on_usage": [
      "self",
      "usage"
    ],
    "on_limit_acquired": [
      "self",
      "manifest"
    ],
    "on_limit_released": [
      "self",
      "manifest"
    ],
    "on_post_limit": [
      "self",
      "manifest"
    ],
    "on_limit_reconcile": [
      "self",
      "value"
    ],
    "on_success": [
      "self",
      "metrics"
    ],
    "on_cache_hit": [
      "self",
      "cache_key",
      "name"
    ],
    "on_cache_miss": [
      "self",
      "cache_key",
      "name"
    ],
    "on_try": [
      "self",
      "attempt_number"
    ],
    "on_retryable_error": [
      "self",
      "error",
      "attempt_number"
    ],
    "on_non_retryable_error": [
      "self",
      "error",
      "attempt_number"
    ],
    "on_recover_from_error": [
      "self",
      "attempt_number"
    ]
  },
  "LLMUsageTracker": {
    "__init__": [
      "self",
      "rpm_sliding_window",
      "tpm_sliding_window"
    ],
    "total_usage": [
      "self"
    ],
    "total_requests": [
      "self"
    ],
    "current_concurrency": [
      "self"
    ],
    "max_concurrency": [
      "self"
    ],
    "current_rpm": [
      "self"
    ],
    "avg_rpm": [
      "self"
    ],
    "current_tpm": [
      "self"
    ],
    "avg_tpm": [
      "self"
    ],
    "on_usage": [
      "self",
      "usage"
    ],
    "on_limit_acquired": [
      "self",
      "manifest"
    ],
    "on_limit_released": [
      "self",
      "manifest"
    ],
    "on_post_limit": [
      "self",
      "manifest"
    ],
    "create": [
      "cls"
    ]
  },
  "LLMEvents": {
    "on_execute_llm": [
      "self"
    ],
    "on_error": [
      "self",
      "error",
      "traceback",
      "arguments"
    ],
    "on_usage": [
      "self",
      "usage"
    ],
    "on_limit_acquired": [
      "self",
      "manifest"
    ],
    "on_limit_released": [
      "self",
      "manifest"
    ],
    "on_post_limit": [
      "self",
      "manifest"
    ],
    "on_limit_reconcile": [
      "self",
      "value"
    ],
    "on_success": [
      "self",
      "metrics"
    ],
    "on_cache_hit": [
      "self",
      "cache_key",
      "name"
    ],
    "on_cache_miss": [
      "self",
      "cache_key",
      "name"
    ],
    "on_try": [
      "self",
      "attempt_number"
    ],
    "on_retryable_error": [
      "self",
      "error",
      "attempt_number"
    ],
    "on_non_retryable_error": [
      "self",
      "error",
      "attempt_number"
    ],
    "on_recover_from_error": [
      "self",
      "attempt_number"
    ]
  },
  "LLMCompositeEvents": {
    "__init__": [
      "self",
      "handlers"
    ],
    "on_execute_llm": [
      "self"
    ],
    "on_error": [
      "self",
      "error",
      "traceback",
      "arguments"
    ],
    "on_usage": [
      "self",
      "usage"
    ],
    "on_limit_acquired": [
      "self",
      "manifest"
    ],
    "on_limit_released": [
      "self",
      "manifest"
    ],
    "on_post_limit": [
      "self",
      "manifest"
    ],
    "on_limit_reconcile": [
      "self",
      "value"
    ],
    "on_success": [
      "self",
      "metrics"
    ],
    "on_cache_hit": [
      "self",
      "cache_key",
      "name"
    ],
    "on_cache_miss": [
      "self",
      "cache_key",
      "name"
    ],
    "on_try": [
      "self",
      "attempt_number"
    ],
    "on_retryable_error": [
      "self",
      "error",
      "attempt_number"
    ]
  },
  "EmbeddingsLLMOutput": {},
  "TEmbeddingsInput": [],
  "TEmbeddingsOutput": [],
  "ChatLLMOutput": {
    "__str__": [
      "self"
    ]
  },
  "TChatInput": [],
  "TChatOutput": [],
  "TInput": [],
  "TOutput": [],
  "TJsonModel": [],
  "THistoryEntry": [],
  "TModelParameters": [],
  "LLMUsageMetrics": {
    "total_tokens": [
      "self"
    ]
  },
  "LLMRetryMetrics": {},
  "LLMMetrics": {
    "tokens_diff": [
      "self"
    ]
  },
  "LLM": {
    "__call__": [
      "self",
      "prompt"
    ],
    "child": [
      "self",
      "name"
    ],
    "is_reasoning_model": [
      "self"
    ]
  },
  "LLMInput": {},
  "LLMOutput": {
    "serialize_tool_calls": [
      "self",
      "tool_calls"
    ]
  },
  "BaseLLM": {
    "__init__": [
      "self"
    ],
    "child": [
      "self",
      "name"
    ],
    "is_reasoning_model": [
      "self"
    ],
    "events": [
      "self"
    ],
    "decorators": [
      "self"
    ],
    "_decorator_target": [
      "self",
      "prompt"
    ],
    "__call__": [
      "self",
      "prompt"
    ],
    "_rewrite_input": [
      "self",
      "prompt",
      "kwargs"
    ],
    "_inject_usage": [
      "self",
      "result"
    ],
    "_inject_history": [
      "self",
      "result",
      "history"
    ],
    "_execute_llm": [
      "self",
      "prompt",
      "kwargs"
    ],
    "is_json_mode": [
      "self",
      "kwargs"
    ]
  },
  "InvalidLLMResultError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "RetriesExhaustedError": {
    "__init__": [
      "self",
      "name",
      "num_retries"
    ]
  },
  "FailedToGenerateValidJsonError": {},
  "CacheAdapter": {
    "build_cache_key": [
      "self",
      "prompt",
      "kwargs"
    ],
    "get_cache_input_data": [
      "self",
      "prompt",
      "kwargs"
    ],
    "wrap_output": [
      "self",
      "prompt",
      "kwargs",
      "cached_result"
    ],
    "dump_raw_model": [
      "self",
      "output"
    ]
  },
  "Cached": {
    "__init__": [
      "self"
    ],
    "child": [
      "self",
      "name"
    ],
    "_dump_output": [
      "self",
      "output"
    ],
    "decorate": [
      "self",
      "delegate"
    ],
    "_get_metadata": [
      "self"
    ]
  },
  "VariableInjector": {
    "inject_variables": [
      "self",
      "prompt",
      "variables"
    ]
  },
  "RetryableErrorHandler": [],
  "Retryer": {
    "__init__": [
      "self"
    ],
    "_create_wait_strategy": [
      "self",
      "retry_strategy",
      "max_retry_wait"
    ],
    "decorate": [
      "self",
      "delegate"
    ],
    "_execute_with_retry": [
      "self",
      "delegate",
      "prompt",
      "kwargs"
    ]
  },
  "UsageExtractor": {
    "extract_usage": [
      "self",
      "output"
    ]
  },
  "TokenEstimator": [],
  "RateLimiter": {
    "__init__": [
      "self",
      "limiter"
    ],
    "_handle_post_request_limiting": [
      "self",
      "result"
    ],
    "decorate": [
      "self",
      "delegate"
    ]
  },
  "JsonMarshaler": {
    "inject_json_string": [
      "self",
      "json_string",
      "output"
    ],
    "extract_json_string": [
      "self",
      "output"
    ]
  },
  "JsonReceiver": {
    "__init__": [
      "self",
      "marshaler",
      "max_retries"
    ],
    "decorate": [
      "self",
      "delegate"
    ],
    "invoke_json": [
      "self",
      "delegate",
      "prompt",
      "kwargs"
    ],
    "try_receive_json": [
      "self",
      "delegate",
      "prompt",
      "kwargs"
    ],
    "_parse_json_string": [
      "self",
      "value"
    ],
    "_read_model_from_json": [
      "self",
      "value",
      "json_model"
    ]
  },
  "LooseModeJsonReceiver": {
    "try_receive_json": [
      "self",
      "delegate",
      "prompt",
      "kwargs"
    ],
    "_parse_json_string": [
      "self",
      "value"
    ],
    "_read_model_from_json": [
      "self",
      "value",
      "json_model"
    ],
    "_try_recovering_malformed_json": [
      "self",
      "err",
      "json_string",
      "prompt",
      "kwargs"
    ]
  },
  "LLMDecorator": {
    "decorate": [
      "self",
      "delegate"
    ]
  },
  "HistoryExtractor": {
    "extract_history": [
      "self",
      "history",
      "output"
    ]
  },
  "RetryStrategy": {
    "EXPONENTIAL_BACKOFF": [],
    "RANDOM_WAIT": [],
    "INCREMENTAL_WAIT": [],
    "NATIVE": []
  },
  "Config": {},
  "JsonStrategy": {
    "NONE": [],
    "LOOSE": [],
    "VALID": [],
    "STRUCTURED": []
  },
  "ToolInvalidArgumentsError": {
    "__init__": [
      "self",
      "raw_output"
    ]
  },
  "ToolNotFoundError": {
    "__init__": [
      "self",
      "raw_output"
    ]
  },
  "LLMTool": {
    "name": [
      "self"
    ],
    "description": [
      "self"
    ],
    "execute": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_description": [
      "cls"
    ],
    "get_json_schema": [
      "cls"
    ],
    "get_parameters_schema": [
      "cls"
    ],
    "find_tool": [
      "tools",
      "name"
    ]
  }
}