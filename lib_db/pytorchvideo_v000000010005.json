{
  "get_version": [],
  "get_name": [],
  "__version__": [],
  "Swish": {
    "forward": [
      "self",
      "x"
    ]
  },
  "SwishFunction": {
    "forward": [
      "ctx",
      "x"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "get_world_size": [],
  "PositionalEncoding": {
    "__init__": [
      "self",
      "embed_dim",
      "seq_len"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SpatioTemporalClsPositionalEncoding": {
    "__init__": [
      "self",
      "embed_dim",
      "patch_embed_shape",
      "sep_pos_embed",
      "has_cls"
    ],
    "patch_embed_shape": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "set_attributes": [
    "self",
    "params"
  ],
  "round_width": [
    "width",
    "multiplier",
    "min_width",
    "divisor",
    "ceil"
  ],
  "round_repeats": [
    "repeats",
    "multiplier"
  ],
  "make_multilayer_perceptron": [
    "fully_connected_dims",
    "norm",
    "mid_activation",
    "final_activation",
    "dropout_rate"
  ],
  "_is_pos_int": [
    "number"
  ],
  "SqueezeAndExcitationLayer2D": {
    "__init__": [
      "self",
      "in_planes",
      "reduction_ratio",
      "reduced_planes"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "create_audio_2d_squeeze_excitation_block": [
    "dim_in",
    "dim_out",
    "use_se",
    "se_reduction_ratio",
    "branch_fusion",
    "conv_a_kernel_size",
    "conv_a_stride",
    "conv_a_padding",
    "conv_b_kernel_size",
    "conv_b_stride",
    "conv_b_padding",
    "norm",
    "norm_eps",
    "norm_momentum",
    "activation"
  ],
  "NaiveSyncBatchNorm1d": {
    "forward": [
      "self",
      "input"
    ]
  },
  "NaiveSyncBatchNorm2d": {
    "forward": [
      "self",
      "input"
    ]
  },
  "NaiveSyncBatchNorm3d": {
    "forward": [
      "self",
      "input"
    ]
  },
  "Mlp": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "act_layer",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_attention_pool": [
    "tensor",
    "pool",
    "thw_shape",
    "has_cls_embed",
    "norm"
  ],
  "MultiScaleAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "qkv_bias",
      "dropout_rate",
      "kernel_q",
      "kernel_kv",
      "stride_q",
      "stride_kv",
      "norm_layer",
      "has_cls_embed",
      "pool_mode",
      "pool_first"
    ],
    "_qkv_proj": [
      "self",
      "q",
      "q_size",
      "k",
      "k_size",
      "v",
      "v_size",
      "batch_size",
      "chan_size"
    ],
    "_qkv_pool": [
      "self",
      "q",
      "k",
      "v",
      "thw_shape"
    ],
    "_get_qkv_length": [
      "self",
      "q_shape",
      "k_shape",
      "v_shape"
    ],
    "_reshape_qkv_to_seq": [
      "self",
      "q",
      "k",
      "v",
      "q_N",
      "v_N",
      "k_N",
      "B",
      "C"
    ],
    "forward": [
      "self",
      "x",
      "thw_shape"
    ]
  },
  "MultiScaleBlock": {
    "__init__": [
      "self",
      "dim",
      "dim_out",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "dropout_rate",
      "droppath_rate",
      "act_layer",
      "norm_layer",
      "kernel_q",
      "kernel_kv",
      "stride_q",
      "stride_kv",
      "pool_mode",
      "has_cls_embed",
      "pool_first"
    ],
    "forward": [
      "self",
      "x",
      "thw_shape"
    ]
  },
  "drop_path": [
    "x",
    "drop_prob",
    "training"
  ],
  "DropPath": {
    "__init__": [
      "self",
      "drop_prob"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvReduce3D": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "create_conv_2plus1d": [],
  "Conv2plus1d": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "make_fusion_layer": [
    "method",
    "feature_dims"
  ],
  "ConcatFusion": {
    "__init__": [
      "self",
      "feature_dims"
    ],
    "output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "input_list"
    ]
  },
  "TemporalConcatFusion": {
    "__init__": [
      "self",
      "feature_dims"
    ],
    "output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "input_list"
    ]
  },
  "ReduceFusion": {
    "__init__": [
      "self",
      "feature_dims",
      "reduce_fn"
    ],
    "output_dim": [
      "self"
    ],
    "forward": [
      "self",
      "input_list"
    ]
  },
  "_verify_feature_dim": [
    "feature_dims"
  ],
  "NonLocal": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "create_nonlocal": [],
  "AdaptiveAvgPool3dOutSize1": {
    "__init__": [
      "self"
    ],
    "convert": [
      "self",
      "input_blob_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AdaptiveAvgPool2dOutSize1": {
    "__init__": [
      "self"
    ],
    "convert": [
      "self",
      "input_blob_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AdaptiveAvgPool3d": {
    "__init__": [
      "self",
      "output_size"
    ]
  },
  "AdaptiveAvgPool2d": {
    "__init__": [
      "self",
      "output_size"
    ]
  },
  "SqueezeExcitation": {
    "__init__": [
      "self",
      "num_channels",
      "num_channels_reduced",
      "reduction_ratio",
      "is_3d",
      "activation"
    ],
    "convert": [
      "self",
      "input_blob_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv3dPwBnAct": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bias",
      "activation",
      "use_bn",
      "norm_eps",
      "norm_momentum"
    ],
    "convert": [
      "self",
      "input_blob_size",
      "convert_for_quantize",
      "native_conv3d_op_qnnpack"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv3d3x3x3DwBnAct": {
    "__init__": [
      "self",
      "in_channels",
      "spatial_stride",
      "bias",
      "activation",
      "use_bn",
      "norm_eps",
      "norm_momentum"
    ],
    "convert": [
      "self",
      "input_blob_size",
      "convert_for_quantize",
      "native_conv3d_op_qnnpack"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv3dTemporalKernel1BnAct": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "bias",
      "groups",
      "spatial_kernel",
      "spatial_stride",
      "spatial_padding",
      "spatial_dilation",
      "activation",
      "use_bn",
      "norm_eps",
      "norm_momentum"
    ],
    "convert": [
      "self",
      "input_blob_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv3d3x1x1BnAct": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "groups",
      "bias",
      "activation",
      "use_bn",
      "norm_eps",
      "norm_momentum"
    ],
    "convert": [
      "self",
      "input_blob_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv3d5x1x1BnAct": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "groups",
      "bias",
      "activation",
      "use_bn",
      "norm_eps",
      "norm_momentum"
    ],
    "convert": [
      "self",
      "input_blob_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_Reshape": {
    "__init__": [
      "self",
      "reshape_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_SkipConnectMul": {
    "__init__": [
      "self",
      "layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_Conv3dTemporalKernel3Decomposed": {
    "__init__": [
      "self",
      "conv3d_in",
      "input_THW_tuple"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_Conv3dTemporalKernel5Decomposed": {
    "__init__": [
      "self",
      "conv3d_in",
      "thw_shape"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_Conv3dTemporalKernel1Decomposed": {
    "__init__": [
      "self",
      "conv3d_eq",
      "input_THW_tuple"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FullyConnected": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias"
    ]
  },
  "_NaiveSwish": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HardSwish": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "convert": [
      "self"
    ]
  },
  "ReLU": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "convert": [
      "self"
    ]
  },
  "Identity": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "convert": [
      "self"
    ]
  },
  "supported_act_functions": [],
  "logger": [],
  "video_only_dataset": [
    "data_path",
    "clip_sampler",
    "video_sampler",
    "transform",
    "video_path_prefix",
    "decode_audio",
    "decoder"
  ],
  "clip_recognition_dataset": [
    "data_path",
    "clip_sampler",
    "video_sampler",
    "transform",
    "video_path_prefix",
    "decode_audio",
    "decoder"
  ],
  "UntrimmedClipSampler": {
    "__init__": [
      "self",
      "clip_sampler"
    ],
    "__call__": [
      "self",
      "last_clip_time",
      "video_duration",
      "clip_info"
    ],
    "reset": [
      "self"
    ]
  },
  "ClipSampling": {
    "Random": []
  },
  "EpicKitchenForecasting": {
    "__init__": [
      "self",
      "video_info_file_path",
      "actions_file_path",
      "video_data_manifest_file_path",
      "clip_sampling",
      "dataset_type",
      "seconds_per_clip",
      "clip_time_stride",
      "num_input_clips",
      "frames_per_clip",
      "num_forecast_actions",
      "transform",
      "multithreaded_io"
    ],
    "_transform_generator": [
      "transform",
      "num_forecast_actions",
      "frames_per_clip",
      "num_input_clips"
    ],
    "_frame_filter_generator": [
      "frames_per_clip",
      "seconds_per_clip",
      "clip_time_stride",
      "num_input_clips"
    ],
    "_define_clip_structure_generator": [
      "clip_sampling",
      "seconds_per_clip",
      "clip_time_stride",
      "num_input_clips",
      "num_forecast_actions"
    ]
  },
  "select_video_class": [
    "decoder"
  ],
  "EncodedVideo": {
    "from_path": [
      "cls",
      "file_path",
      "decode_audio",
      "decoder"
    ]
  },
  "SSv2": {
    "__init__": [
      "self",
      "label_name_file",
      "video_label_file",
      "video_path_label_file",
      "clip_sampler",
      "video_sampler",
      "transform",
      "video_path_prefix",
      "frames_per_clip",
      "rand_sample_frames"
    ],
    "_sample_clip_frames": [
      "frame_indices",
      "frames_per_clip",
      "rand_sample"
    ],
    "video_sampler": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "_read_video_paths_and_labels": [
    "label_name_file",
    "video_label_file",
    "video_path_label_file",
    "prefix"
  ],
  "VideoPathHandler": {
    "__init__": [
      "self"
    ],
    "video_from_path": [
      "self",
      "filepath",
      "decode_audio",
      "decoder",
      "fps"
    ]
  },
  "Video": {
    "__init__": [
      "self",
      "file",
      "video_name",
      "decode_audio"
    ],
    "duration": [
      "self"
    ],
    "get_clip": [
      "self",
      "start_sec",
      "end_sec"
    ],
    "close": [
      "self"
    ]
  },
  "LabeledVideoPaths": {
    "from_path": [
      "cls",
      "data_path"
    ],
    "from_csv": [
      "cls",
      "file_path"
    ],
    "from_directory": [
      "cls",
      "dir_path"
    ],
    "__init__": [
      "self",
      "paths_and_labels",
      "path_prefix"
    ],
    "path_prefix": [],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "Kinetics": [
    "data_path",
    "clip_sampler",
    "video_sampler",
    "transform",
    "video_path_prefix",
    "decode_audio",
    "decoder"
  ],
  "EpicKitchenRecognition": {
    "__init__": [
      "self",
      "video_info_file_path",
      "actions_file_path",
      "video_data_manifest_file_path",
      "clip_sampling",
      "dataset_type",
      "seconds_per_clip",
      "frames_per_clip",
      "transform",
      "multithreaded_io"
    ],
    "_transform_generator": [
      "transform"
    ],
    "_frame_filter_generator": [
      "frames_per_clip"
    ],
    "_define_clip_structure_generator": [
      "seconds_per_clip",
      "clip_sampling"
    ]
  },
  "EncodedVideoTorchVision": {
    "SEEK_FRAME_MARGIN": [],
    "__init__": [
      "self",
      "file",
      "video_name",
      "decode_audio"
    ],
    "name": [
      "self"
    ],
    "duration": [
      "self"
    ],
    "close": [
      "self"
    ],
    "get_clip": [
      "self",
      "start_sec",
      "end_sec"
    ],
    "_torch_vision_decode_video": [
      "self",
      "start_pts",
      "end_pts"
    ]
  },
  "Charades": {
    "NUM_CLASSES": [],
    "__init__": [
      "self",
      "data_path",
      "clip_sampler",
      "video_sampler",
      "transform",
      "video_path_prefix",
      "frames_per_clip"
    ],
    "_sample_clip_frames": [
      "frame_indices",
      "frames_per_clip"
    ],
    "video_sampler": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "EncodedVideoPyAV": {
    "__init__": [
      "self",
      "file",
      "video_name",
      "decode_audio"
    ],
    "name": [
      "self"
    ],
    "duration": [
      "self"
    ],
    "get_clip": [
      "self",
      "start_sec",
      "end_sec"
    ],
    "close": [
      "self"
    ],
    "_pyav_decode_video": [
      "self",
      "start_secs",
      "end_secs"
    ]
  },
  "_pyav_decode_stream": [
    "container",
    "start_pts",
    "end_pts",
    "stream",
    "stream_name",
    "buffer_size"
  ],
  "LabeledVideoDataset": {
    "_MAX_CONSECUTIVE_FAILURES": [],
    "__init__": [
      "self",
      "labeled_video_paths",
      "clip_sampler",
      "video_sampler",
      "transform",
      "decode_audio",
      "decoder"
    ],
    "video_sampler": [
      "self"
    ],
    "num_videos": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "labeled_video_dataset": [
    "data_path",
    "clip_sampler",
    "video_sampler",
    "transform",
    "video_path_prefix",
    "decode_audio",
    "decoder"
  ],
  "thwc_to_cthw": [
    "data"
  ],
  "secs_to_pts": [
    "time_in_seconds",
    "time_base",
    "start_pts",
    "round_mode"
  ],
  "pts_to_secs": [
    "pts",
    "time_base",
    "start_pts"
  ],
  "MultiProcessSampler": {
    "__init__": [
      "self",
      "sampler"
    ],
    "__iter__": [
      "self"
    ]
  },
  "optional_threaded_foreach": [
    "target",
    "args_iterable",
    "multithreaded"
  ],
  "DataclassFieldCaster": {
    "COMPLEX_INITIALIZER": [],
    "__post_init__": [
      "self"
    ],
    "complex_initialized_dataclass_field": [
      "field_initializer"
    ]
  },
  "load_dataclass_dict_from_csv": [
    "input_csv_file_path",
    "dataclass_class",
    "dict_key_field",
    "list_per_key"
  ],
  "save_dataclass_objs_to_headered_csv": [
    "dataclass_objs",
    "file_name"
  ],
  "FrameVideo": {
    "__init__": [
      "self",
      "duration",
      "fps",
      "video_frame_to_path_fn",
      "video_frame_paths",
      "multithreaded_io"
    ],
    "from_directory": [
      "cls",
      "path",
      "fps",
      "multithreaded_io",
      "path_order_cache"
    ],
    "from_frame_paths": [
      "cls",
      "video_frame_paths",
      "fps",
      "multithreaded_io"
    ],
    "name": [
      "self"
    ],
    "duration": [
      "self"
    ],
    "_get_frame_index_for_time": [
      "self",
      "time_sec"
    ],
    "get_clip": [
      "self",
      "start_sec",
      "end_sec",
      "frame_filter"
    ],
    "_video_frame_to_path": [
      "self",
      "frame_index"
    ]
  },
  "_load_images_with_retries": [
    "image_paths",
    "num_retries",
    "multithreaded"
  ],
  "AvaLabeledVideoFramePaths": {
    "AVA_VALID_FRAMES": [],
    "FPS": [],
    "AVA_VIDEO_START_SEC": [],
    "_aggregate_bboxes_labels": [
      "cls",
      "inp"
    ],
    "from_csv": [
      "cls",
      "frame_paths_file",
      "frame_labels_file",
      "video_path_prefix",
      "label_map_file"
    ],
    "load_and_parse_labels_csv": [
      "frame_labels_file",
      "video_name_to_idx",
      "allowed_class_ids"
    ],
    "load_image_lists": [
      "frame_paths_file",
      "video_path_prefix"
    ],
    "read_label_map": [
      "label_map_file"
    ]
  },
  "TimeStampClipSampler": {
    "__init__": [
      "self",
      "clip_sampler"
    ],
    "__call__": [
      "self",
      "last_clip_time",
      "video_duration",
      "annotation"
    ],
    "reset": [
      "self"
    ]
  },
  "Ava": [
    "frame_paths_file",
    "frame_labels_file",
    "video_path_prefix",
    "label_map_file",
    "clip_sampler",
    "video_sampler",
    "transform"
  ],
  "USER_ENVIRONMENT_MAP": [],
  "USER_ACTIVITY_MAP": [],
  "USER_ATTENTION_MAP": [],
  "LabelType": {
    "Environment": [],
    "Activity": [],
    "UserAttention": []
  },
  "LABEL_TYPE_2_MAP": [],
  "LabelData": {},
  "_seconds_to_frame_index": [
    "time_in_seconds",
    "fps",
    "zero_indexed"
  ],
  "_get_overlap_for_time_range_pair": [
    "t1_start",
    "t1_stop",
    "t2_start",
    "t2_stop"
  ],
  "DomsevFrameDataset": {
    "__init__": [
      "self",
      "video_data_manifest_file_path",
      "video_info_file_path",
      "labels_file_path",
      "transform",
      "multithreaded_io"
    ],
    "_assign_labels_to_frames": [
      "frames_dict",
      "video_labels"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "_transform_frame": [
      "self",
      "frame"
    ]
  },
  "DomsevVideoDataset": {
    "__init__": [
      "self",
      "video_data_manifest_file_path",
      "video_info_file_path",
      "labels_file_path",
      "clip_sampler",
      "dataset_type",
      "frames_per_second",
      "transform",
      "frame_filter",
      "multithreaded_io"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "_transform_clip": [
      "self",
      "clip"
    ]
  },
  "_load_image_from_path": [
    "image_path",
    "num_retries"
  ],
  "DecoderType": {
    "PYAV": [],
    "TORCHVISION": [],
    "DECORD": []
  },
  "ClipInfo": {},
  "ClipInfoList": {},
  "ClipSampler": {
    "__init__": [
      "self",
      "clip_duration"
    ],
    "__call__": [
      "self",
      "last_clip_time",
      "video_duration",
      "annotation"
    ],
    "reset": [
      "self"
    ]
  },
  "make_clip_sampler": [
    "sampling_type"
  ],
  "UniformClipSampler": {
    "__init__": [
      "self",
      "clip_duration",
      "stride",
      "backpad_last",
      "eps"
    ],
    "_clip_start_end": [
      "self",
      "last_clip_time",
      "video_duration",
      "backpad_last"
    ],
    "__call__": [
      "self",
      "last_clip_time",
      "video_duration",
      "annotation"
    ],
    "reset": [
      "self"
    ]
  },
  "RandomClipSampler": {
    "__call__": [
      "self",
      "last_clip_time",
      "video_duration",
      "annotation"
    ]
  },
  "RandomMultiClipSampler": {
    "__init__": [
      "self",
      "clip_duration",
      "num_clips"
    ],
    "__call__": [
      "self",
      "last_clip_time",
      "video_duration",
      "annotation"
    ]
  },
  "ConstantClipsPerVideoSampler": {
    "__init__": [
      "self",
      "clip_duration",
      "clips_per_video",
      "augs_per_clip"
    ],
    "__call__": [
      "self",
      "last_clip_time",
      "video_duration",
      "annotation"
    ],
    "reset": [
      "self"
    ]
  },
  "DecordDevice": [],
  "EncodedVideoDecord": {
    "__init__": [
      "self",
      "file",
      "video_name",
      "decode_audio",
      "sample_rate",
      "mono",
      "width",
      "height",
      "num_threads",
      "fault_tol"
    ],
    "name": [
      "self"
    ],
    "duration": [
      "self"
    ],
    "close": [
      "self"
    ],
    "get_clip": [
      "self",
      "start_sec",
      "end_sec"
    ]
  },
  "Ucf101": [
    "data_path",
    "clip_sampler",
    "video_sampler",
    "transform",
    "video_path_prefix",
    "decode_audio",
    "decoder"
  ],
  "EncodedVideoInfo": {},
  "VideoFrameInfo": {},
  "VideoInfo": {},
  "VideoClipInfo": {},
  "ImageFrameInfo": {},
  "VideoDatasetType": {
    "Frame": [],
    "EncodedVideo": []
  },
  "ImageDataset": {
    "_load_images": [
      "frame_manifest_file_path",
      "video_info_file_path",
      "multithreaded_io"
    ]
  },
  "VideoDataset": {
    "_load_videos": [
      "video_data_manifest_file_path",
      "video_info_file_path",
      "multithreaded_io",
      "dataset_type"
    ],
    "_load_frame_videos": [
      "frame_manifest_file_path",
      "video_infos",
      "multithreaded_io"
    ],
    "_load_encoded_videos": [
      "encoded_video_manifest_file_path",
      "video_infos"
    ],
    "_frame_number_to_filepaths": [
      "video_id",
      "video_frames",
      "video_infos"
    ],
    "_remove_video_info_missing_or_incomplete_videos": [
      "video_data_infos",
      "video_infos"
    ]
  },
  "get_seconds_from_hms_time": [
    "time_str"
  ],
  "save_encoded_video_manifest": [
    "encoded_video_infos",
    "file_name"
  ],
  "save_video_frame_info": [
    "video_frames",
    "file_name"
  ],
  "Hmdb51LabeledVideoPaths": {
    "_allowed_splits": [],
    "_split_type_dict": [],
    "from_dir": [
      "cls",
      "data_path",
      "split_id",
      "split_type"
    ],
    "from_csvs": [
      "cls",
      "file_paths",
      "split_type"
    ],
    "__init__": [
      "self",
      "paths_and_labels",
      "path_prefix"
    ],
    "path_prefix": [],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "Hmdb51": [
    "data_path",
    "clip_sampler",
    "video_sampler",
    "transform",
    "video_path_prefix",
    "split_id",
    "split_type",
    "decode_audio",
    "decoder"
  ],
  "build_frame_manifest_from_flat_directory": [
    "data_directory_path",
    "multithreaded"
  ],
  "build_frame_manifest_from_nested_directory": [
    "data_directory_path",
    "multithreaded"
  ],
  "build_encoded_manifest_from_nested_directory": [
    "data_directory_path"
  ],
  "ActionData": {
    "start_time": [
      "self"
    ],
    "stop_time": [
      "self"
    ]
  },
  "EpicKitchenDataset": {
    "__init__": [
      "self",
      "video_info_file_path",
      "actions_file_path",
      "clip_sampler",
      "video_data_manifest_file_path",
      "dataset_type",
      "transform",
      "frame_filter",
      "multithreaded_io"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "_AUGMENTATION_MAX_LEVEL": [],
  "_check_fill_arg": [
    "kwargs"
  ],
  "_autocontrast": [
    "video"
  ],
  "_equalize": [
    "video"
  ],
  "_invert": [
    "video"
  ],
  "_rotate": [
    "video",
    "factor"
  ],
  "_solarize": [
    "video",
    "factor"
  ],
  "_adjust_contrast": [
    "video",
    "factor"
  ],
  "_adjust_saturation": [
    "video",
    "factor"
  ],
  "_adjust_brightness": [
    "video",
    "factor"
  ],
  "_adjust_sharpness": [
    "video",
    "factor"
  ],
  "_posterize": [
    "video",
    "factor"
  ],
  "_shear_x": [
    "video",
    "factor"
  ],
  "_shear_y": [
    "video",
    "factor"
  ],
  "_translate_x": [
    "video",
    "factor"
  ],
  "_translate_y": [
    "video",
    "factor"
  ],
  "_randomly_negate": [
    "magnitude"
  ],
  "_increasing_magnitude_to_arg": [
    "level",
    "params"
  ],
  "_increasing_randomly_negate_to_arg": [
    "level",
    "params"
  ],
  "_decreasing_int_to_arg": [
    "level",
    "params"
  ],
  "_decreasing_to_arg": [
    "level",
    "params"
  ],
  "_NAME_TO_TRANSFORM_FUNC": [],
  "_LEVEL_TO_ARG": [],
  "_TRANSFORM_MAX_PARAMS": [],
  "SAMPLING_DEFAULT_HPARAS": [],
  "TRANSFORM_DEFAULT_HPARAS": [],
  "AugmentTransform": {
    "__init__": [
      "self",
      "transform_name",
      "magnitude",
      "prob",
      "name_to_transform_func",
      "level_to_arg",
      "transform_max_paras",
      "transform_hparas",
      "sampling_type",
      "sampling_hparas"
    ],
    "_get_magnitude": [
      "self"
    ],
    "__call__": [
      "self",
      "video"
    ]
  },
  "_AUGMIX_LEVEL_TO_ARG": [],
  "_TRANSFORM_AUGMIX_MAX_PARAMS": [],
  "SAMPLING_AUGMIX_DEFAULT_HPARAS": [],
  "AugMix": {
    "__init__": [
      "self",
      "magnitude",
      "alpha",
      "width",
      "depth",
      "transform_hparas",
      "sampling_hparas"
    ],
    "__call__": [
      "self",
      "video"
    ]
  },
  "ApplyTransformToKey": {
    "__init__": [
      "self",
      "key",
      "transform"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "RemoveKey": {
    "__init__": [
      "self",
      "key"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "UniformTemporalSubsample": {
    "__init__": [
      "self",
      "num_samples",
      "temporal_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UniformTemporalSubsampleRepeated": {
    "__init__": [
      "self",
      "frame_ratios",
      "temporal_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ShortSideScale": {
    "__init__": [
      "self",
      "size",
      "interpolation",
      "backend"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RandomShortSideScale": {
    "__init__": [
      "self",
      "min_size",
      "max_size",
      "interpolation",
      "backend"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UniformCropVideo": {
    "__init__": [
      "self",
      "size",
      "video_key",
      "aug_index_key"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Normalize": {
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvertFloatToUint8": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvertUint8ToFloat": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MoveChannelRear": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MoveChannelFront": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RandomResizedCrop": {
    "__init__": [
      "self",
      "target_height",
      "target_width",
      "scale",
      "aspect_ratio",
      "shift",
      "log_uniform_ratio",
      "interpolation",
      "num_tries"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "Permute": {
    "__init__": [
      "self",
      "dims"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OpSampler": {
    "__init__": [
      "self",
      "transforms_list",
      "transforms_prob",
      "num_sample_op",
      "randomly_sample_depth",
      "replacement"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Div255": {
    "forward": [
      "self",
      "x"
    ]
  },
  "_RANDAUG_DEFAULT_PARAS": [],
  "_AUGMIX_DEFAULT_PARAS": [],
  "_RANDOM_RESIZED_CROP_DEFAULT_PARAS": [],
  "_get_augmentation": [
    "aug_type",
    "aug_paras"
  ],
  "create_video_transform": [
    "mode",
    "video_key",
    "remove_key",
    "num_samples",
    "convert_to_float",
    "video_mean",
    "video_std",
    "min_size",
    "max_size",
    "crop_size",
    "horizontal_flip_prob",
    "aug_type",
    "aug_paras",
    "random_resized_crop_paras"
  ],
  "uniform_temporal_subsample": [
    "x",
    "num_samples",
    "temporal_dim"
  ],
  "_interpolate_opencv": [
    "x",
    "size",
    "interpolation"
  ],
  "short_side_scale": [
    "x",
    "size",
    "interpolation",
    "backend"
  ],
  "uniform_temporal_subsample_repeated": [
    "frames",
    "frame_ratios",
    "temporal_dim"
  ],
  "convert_to_one_hot": [
    "targets",
    "num_class",
    "label_smooth"
  ],
  "short_side_scale_with_boxes": [
    "images",
    "boxes",
    "size",
    "interpolation",
    "backend"
  ],
  "random_short_side_scale_with_boxes": [
    "images",
    "boxes",
    "min_size",
    "max_size",
    "interpolation",
    "backend"
  ],
  "random_crop_with_boxes": [
    "images",
    "size",
    "boxes"
  ],
  "_uniform_crop_helper": [
    "images",
    "size",
    "spatial_idx"
  ],
  "uniform_crop": [
    "images",
    "size",
    "spatial_idx"
  ],
  "uniform_crop_with_boxes": [
    "images",
    "size",
    "spatial_idx",
    "boxes"
  ],
  "horizontal_flip_with_boxes": [
    "prob",
    "images",
    "boxes"
  ],
  "clip_boxes_to_image": [
    "boxes",
    "height",
    "width"
  ],
  "crop_boxes": [
    "boxes",
    "x_offset",
    "y_offset"
  ],
  "_get_param_spatial_crop": [
    "scale",
    "ratio",
    "height",
    "width",
    "log_uniform_ratio",
    "num_tries"
  ],
  "random_resized_crop": [
    "frames",
    "target_height",
    "target_width",
    "scale",
    "aspect_ratio",
    "shift",
    "log_uniform_ratio",
    "interpolation",
    "num_tries"
  ],
  "div_255": [
    "x"
  ],
  "_mix_labels": [
    "labels",
    "num_classes",
    "lam",
    "label_smoothing"
  ],
  "MixUp": {
    "__init__": [
      "self",
      "alpha",
      "label_smoothing",
      "num_classes"
    ],
    "forward": [
      "self",
      "x",
      "labels"
    ]
  },
  "CutMix": {
    "__init__": [
      "self",
      "alpha",
      "label_smoothing",
      "num_classes"
    ],
    "_clip": [
      "self",
      "value",
      "min_value",
      "max_value"
    ],
    "_get_rand_box": [
      "self",
      "input_shape",
      "cutmix_lamda"
    ],
    "_cutmix": [
      "self",
      "x",
      "cutmix_lamda"
    ],
    "forward": [
      "self",
      "x",
      "labels"
    ]
  },
  "MixVideo": {
    "__init__": [
      "self",
      "cutmix_prob",
      "mixup_alpha",
      "cutmix_alpha",
      "label_smoothing",
      "num_classes"
    ],
    "forward": [
      "self",
      "x",
      "labels"
    ]
  },
  "_TRANSFORM_RANDAUG_MAX_PARAMS": [],
  "SAMPLING_RANDAUG_DEFAULT_HPARAS": [],
  "RandAugment": {
    "__init__": [
      "self",
      "magnitude",
      "num_layers",
      "prob",
      "transform_hparas",
      "sampling_type",
      "sampling_hparas"
    ],
    "__call__": [
      "self",
      "video"
    ]
  },
  "create_x3d_stem": [],
  "create_x3d_bottleneck_block": [],
  "create_x3d_res_block": [],
  "create_x3d_res_stage": [],
  "create_x3d_head": [],
  "create_x3d": [],
  "ProjectedPool": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BYOL": {
    "__init__": [
      "self",
      "backbone",
      "projector",
      "predictor",
      "feature_dim",
      "predictor_inner",
      "mmt",
      "norm"
    ],
    "sim_loss": [
      "self",
      "q",
      "k"
    ],
    "update_mmt": [
      "self",
      "mmt"
    ],
    "get_mmt": [
      "self"
    ],
    "_momentum_update_backbone": [
      "self"
    ],
    "forward_backbone_mmt": [
      "self",
      "x"
    ],
    "forward_backbone": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x1",
      "x2"
    ]
  },
  "create_audio_visual_slowfast": [],
  "AudioToSlowFastFusionBuilder": {
    "__init__": [
      "self",
      "slowfast_channel_reduction_ratio",
      "slowfast_audio_reduction_ratio",
      "conv_fusion_channel_ratio",
      "conv_kernel_size",
      "conv_kernel_size_a",
      "conv_stride",
      "conv_stride_a",
      "conv_fusion_channel_interm_dim",
      "conv_num_a",
      "norm",
      "norm_eps",
      "norm_momentum",
      "activation",
      "max_stage_idx"
    ],
    "create_module": [
      "self",
      "fusion_dim_in",
      "stage_idx"
    ]
  },
  "FuseAudioToFastSlow": {
    "__init__": [
      "self",
      "block_fast_to_slow",
      "block_audio_to_fastslow"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "create_csn": [],
  "create_bottleneck_block": [],
  "create_acoustic_bottleneck_block": [],
  "_trivial_sum": [
    "x",
    "y"
  ],
  "create_res_block": [],
  "create_res_stage": [],
  "_MODEL_STAGE_DEPTH": [],
  "create_resnet": [],
  "create_resnet_with_roi_head": [],
  "create_acoustic_resnet": [],
  "ResBlock": {
    "__init__": [
      "self",
      "branch1_conv",
      "branch1_norm",
      "branch2",
      "activation",
      "branch_fusion"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SeparableBottleneckBlock": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BottleneckBlock": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResStage": {
    "__init__": [
      "self",
      "res_blocks"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Net": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DetectionBBoxNetwork": {
    "__init__": [
      "self",
      "model",
      "detection_head"
    ],
    "forward": [
      "self",
      "x",
      "bboxes"
    ]
  },
  "MultiPathWayWithFuse": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "create_res_basic_stem": [],
  "create_acoustic_res_basic_stem": [],
  "ResNetBasicStem": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PatchEmbed": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "create_conv_patch_embed": [],
  "create_2plus1d_bottleneck_block": [],
  "create_r2plus1d": [],
  "MultiscaleVisionTransformers": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "create_multiscale_vision_transformers": [],
  "MemoryBank": {
    "__init__": [
      "self",
      "backbone",
      "mlp",
      "neg_size",
      "temperature",
      "bank_size",
      "dim",
      "mmt"
    ],
    "_init_mem_bank": [
      "self",
      "bank_size",
      "dim"
    ],
    "forward": [
      "self",
      "x",
      "x_ind"
    ]
  },
  "MaskedTemporalPooling": {
    "__init__": [
      "self",
      "method"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "TransposeMultiheadAttention": {
    "__init__": [
      "self",
      "feature_dim",
      "num_heads"
    ],
    "attention_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "LearnMaskedDefault": {
    "__init__": [
      "self",
      "feature_dim",
      "init_method",
      "freeze"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "LSTM": {
    "__init__": [
      "self",
      "dim_in",
      "hidden_dim",
      "dropout",
      "bidirectional"
    ],
    "forward": [
      "self",
      "data",
      "mask"
    ]
  },
  "TransposeTransformerEncoder": {
    "__init__": [
      "self",
      "dim_in",
      "num_heads",
      "num_layers"
    ],
    "forward": [
      "self",
      "data",
      "mask"
    ]
  },
  "MaskedSequential": {
    "_MASK_MODULES": [],
    "forward": [
      "self",
      "input",
      "mask"
    ]
  },
  "MaskedMultiPathWay": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x_and_mask"
    ]
  },
  "SequencePool": {
    "__init__": [
      "self",
      "mode"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "create_res_basic_head": [],
  "create_vit_basic_head": [],
  "create_res_roi_pooling_head": [],
  "ResNetBasicHead": {
    "__init__": [
      "self",
      "pool",
      "dropout",
      "proj",
      "activation",
      "output_pool"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNetRoIHead": {
    "__init__": [
      "self",
      "pool",
      "pool_spatial",
      "roi_layer",
      "dropout",
      "proj",
      "activation",
      "output_pool"
    ],
    "forward": [
      "self",
      "x",
      "bboxes"
    ]
  },
  "VisionTransformerBasicHead": {
    "__init__": [
      "self",
      "sequence_pool",
      "dropout",
      "proj",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_init_resnet_weights": [
    "model",
    "fc_init_std"
  ],
  "_init_vit_weights": [
    "model",
    "trunc_normal_std"
  ],
  "init_net_weights": [
    "model",
    "init_std",
    "style"
  ],
  "SimCLR": {
    "__init__": [
      "self",
      "mlp",
      "backbone",
      "temperature"
    ],
    "forward": [
      "self",
      "x1",
      "x2"
    ]
  },
  "create_slowfast": [],
  "create_slowfast_with_roi_head": [],
  "PoolConcatPathway": {
    "__init__": [
      "self",
      "retain_list",
      "pool",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FastToSlowFusionBuilder": {
    "__init__": [
      "self",
      "slowfast_channel_reduction_ratio",
      "conv_fusion_channel_ratio",
      "conv_kernel_size",
      "conv_stride",
      "norm",
      "norm_eps",
      "norm_momentum",
      "activation",
      "max_stage_idx"
    ],
    "create_module": [
      "self",
      "fusion_dim_in",
      "stage_idx"
    ]
  },
  "FuseFastToSlow": {
    "__init__": [
      "self",
      "conv_fast_to_slow",
      "norm",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "root_dir": [],
  "checkpoint_paths": [],
  "_x3d": [
    "pretrained",
    "progress",
    "checkpoint_path"
  ],
  "x3d_xs": [
    "pretrained",
    "progress"
  ],
  "x3d_s": [
    "pretrained",
    "progress"
  ],
  "x3d_m": [
    "pretrained",
    "progress"
  ],
  "x3d_l": [
    "pretrained",
    "progress"
  ],
  "csn_r101": [
    "pretrained",
    "progress"
  ],
  "_resnet": [
    "pretrained",
    "progress",
    "checkpoint_path",
    "model_builder"
  ],
  "slow_r50": [
    "pretrained",
    "progress"
  ],
  "slow_r50_detection": [
    "pretrained",
    "progress"
  ],
  "c2d_r50": [
    "pretrained",
    "progress"
  ],
  "i3d_r50": [
    "pretrained",
    "progress"
  ],
  "MODEL_ZOO_ROOT_DIR": [],
  "hub_model_builder": [
    "model_builder_func",
    "pretrained",
    "progress",
    "checkpoint_path",
    "default_config"
  ],
  "r2plus1d_r50": [
    "pretrained",
    "progress"
  ],
  "mvit_video_base_config": [],
  "mvit_video_base_32x3_config": [],
  "mvit_image_base_16_config": [],
  "mvit_base_16x4": [
    "pretrained",
    "progress"
  ],
  "mvit_base_32x3": [
    "pretrained",
    "progress"
  ],
  "mvit_base_16": [
    "pretrained",
    "progress"
  ],
  "_root_dir": [],
  "_checkpoint_paths": [],
  "_efficient_x3d": [
    "pretrained",
    "progress",
    "checkpoint_path",
    "expansion"
  ],
  "efficient_x3d_xs": [
    "pretrained",
    "progress"
  ],
  "efficient_x3d_s": [
    "pretrained",
    "progress"
  ],
  "_slowfast": [
    "pretrained",
    "progress",
    "checkpoint_path",
    "model_builder"
  ],
  "slowfast_r50": [
    "pretrained",
    "progress"
  ],
  "slowfast_r101": [
    "pretrained",
    "progress"
  ],
  "slowfast_16x8_r101_50_50": [
    "pretrained",
    "progress"
  ],
  "slowfast_r50_detection": [
    "pretrained",
    "progress"
  ],
  "X3dBottleneckBlock": {
    "__init__": [
      "self",
      "in_channels",
      "mid_channels",
      "out_channels",
      "use_residual",
      "spatial_stride",
      "se_ratio",
      "act_functions",
      "bias",
      "use_bn",
      "norm_eps",
      "norm_momentum"
    ],
    "forward": [
      "self",
      "x"
    ],
    "convert": [
      "self",
      "input_blob_size"
    ]
  },
  "EfficientX3d": {
    "__init__": [
      "self",
      "num_classes",
      "dropout",
      "expansion",
      "head_act",
      "enable_head"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NoOpConvertBlock": {
    "__init__": [
      "self",
      "model"
    ],
    "convert": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EfficientBlockBase": {
    "convert": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "EFFICIENT_BLOCK_TRANSMUTER_REGISTRY": [],
  "_find_equivalent_efficient_module": [
    "module_input",
    "efficient_block_transmuter_list",
    "module_name"
  ],
  "transmute_model": [
    "model",
    "target_device",
    "prefix"
  ],
  "_add_input_tensor_size_lut_hook": [
    "module",
    "input_tensor_size_lut",
    "hook_handle_list",
    "base_name"
  ],
  "_convert_module": [
    "module",
    "input_tensor_size_lut",
    "base_name",
    "convert_for_quantize",
    "native_conv3d_op_qnnpack"
  ],
  "convert_to_deployable_form": [
    "model",
    "input_tensor",
    "convert_for_quantize",
    "native_conv3d_op_qnnpack"
  ],
  "transmute_Conv3dPwBnAct": [
    "input_module"
  ],
  "transmute_Conv3d3x3x3DwBnAct": [
    "input_module"
  ],
  "transmute_Conv3dTemporalKernel1BnAct": [
    "input_module"
  ],
  "transmute_Conv3d3x1x1BnAct": [
    "input_module"
  ],
  "transmute_Conv3d5x1x1BnAct": [
    "input_module"
  ],
  "EFFICIENT_BLOCK_TRANSMUTER_MOBILE_CPU": []
}