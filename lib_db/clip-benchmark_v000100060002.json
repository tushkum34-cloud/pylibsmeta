{
  "__author__": [],
  "__email__": [],
  "__version__": [],
  "get_parser_args": [],
  "main": [],
  "main_build": [
    "base"
  ],
  "main_eval": [
    "base"
  ],
  "_as_list": [
    "l"
  ],
  "_single_option_to_multiple_datasets": [
    "cur_option",
    "datasets",
    "name"
  ],
  "run": [
    "args"
  ],
  "world_info_from_env": [],
  "get_model_collection_from_file": [
    "path"
  ],
  "model_collection": [],
  "PIL_to_bytes": [
    "image_format"
  ],
  "path_to_bytes": [
    "filepath"
  ],
  "convert_dataset": [
    "dataset",
    "split",
    "output_folder"
  ],
  "convert_retrieval_dataset": [
    "dataset",
    "split",
    "output_folder"
  ],
  "assign_learning_rate": [
    "param_group",
    "new_lr"
  ],
  "_warmup_lr": [
    "base_lr",
    "warmup_length",
    "step"
  ],
  "cosine_lr": [
    "optimizer",
    "base_lrs",
    "warmup_length",
    "steps"
  ],
  "Featurizer": {
    "__init__": [
      "self",
      "model",
      "normalize"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "FeatureDataset": {
    "__init__": [
      "self",
      "features",
      "targets"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ]
  },
  "train": [
    "dataloader",
    "input_shape",
    "output_shape",
    "weight_decay",
    "lr",
    "epochs",
    "amp",
    "device",
    "seed"
  ],
  "infer": [
    "model",
    "dataloader",
    "amp",
    "device"
  ],
  "find_peak": [
    "wd_list",
    "idxs",
    "train_loader",
    "val_loader",
    "input_shape",
    "output_shape",
    "lr",
    "epochs",
    "amp",
    "device",
    "verbose",
    "seed"
  ],
  "evaluate": [
    "model",
    "train_dataloader",
    "dataloader",
    "fewshot_k",
    "batch_size",
    "num_workers",
    "lr",
    "epochs",
    "model_id",
    "seed",
    "feature_root",
    "device",
    "val_dataloader",
    "normalize",
    "amp",
    "verbose"
  ],
  "dataloader_with_indices": [
    "dataloader"
  ],
  "recall_at_k": [
    "scores",
    "positive_pairs",
    "k"
  ],
  "batchify": [
    "func",
    "X",
    "Y",
    "batch_size",
    "device"
  ],
  "zero_shot_classifier": [
    "model",
    "tokenizer",
    "classnames",
    "templates",
    "device",
    "amp"
  ],
  "accuracy": [
    "output",
    "target",
    "topk"
  ],
  "run_classification": [
    "model",
    "classifier",
    "dataloader",
    "device",
    "amp"
  ],
  "average_precision_per_class": [
    "scores",
    "targets"
  ],
  "COCOEvalCap": {
    "__init__": [
      "self",
      "results"
    ],
    "evaluate": [
      "self"
    ],
    "setEval": [
      "self",
      "score",
      "method"
    ],
    "setImgToEvalImgs": [
      "self",
      "scores",
      "imgIds",
      "method"
    ],
    "setEvalImgs": [
      "self"
    ]
  },
  "Flickr": {
    "__init__": [
      "self",
      "root",
      "ann_file",
      "transform",
      "target_transform"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "GITHUB_DATA_PATH": [],
  "GITHUB_MIC_DATA_PATH": [],
  "GITHUB_STAIR_DATA_PATH": [],
  "SUPPORTED_LANGUAGES": [],
  "IMAGE_INDEX_FILENAME": [],
  "CAPTIONS_FILENAME_TEMPLATE": [],
  "OUTPUT_FILENAME_TEMPLATE": [],
  "IMAGES_DOWNLOAD_URL": [],
  "XTD10": {
    "__init__": [
      "self",
      "root",
      "ann_file",
      "transform",
      "target_transform"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "_get_lines": [
    "url"
  ],
  "_download_images": [
    "out_path"
  ],
  "create_annotation_file": [
    "root",
    "lang_code"
  ],
  "BabelImageNet": {
    "__init__": [
      "self",
      "root",
      "idxs",
      "split",
      "download"
    ],
    "__getitem__": [
      "self",
      "i"
    ]
  },
  "XTD200": {
    "__init__": [
      "self",
      "root",
      "ann_file",
      "transform",
      "target_transform"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "URLS": [],
  "FNAMES": [],
  "V2_DATASET_SIZE": [],
  "ImageNetV2Dataset": {
    "__init__": [
      "self",
      "variant",
      "transform",
      "location"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ]
  },
  "CAPTIONS_DOWNLOAD_URL": [],
  "Crossmodal3600": {
    "__init__": [
      "self",
      "root",
      "ann_file",
      "transform",
      "target_transform"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "_download_captions": [
    "out_path"
  ],
  "flores_languages": [],
  "get_metadata": [
    "folder"
  ],
  "ObjectNetDataset": {
    "__init__": [
      "self",
      "root",
      "transform"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "build_dataset": [
    "dataset_name",
    "root",
    "transform",
    "split",
    "download",
    "annotation_file",
    "language",
    "task",
    "wds_cache_dir",
    "custom_classname_file",
    "custom_template_file"
  ],
  "value_from_first_key_found": [
    "dic",
    "keys"
  ],
  "Dummy": {
    "__init__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__len__": [
      "self"
    ]
  },
  "get_dataset_default_task": [
    "dataset"
  ],
  "get_dataset_collate_fn": [
    "dataset_name"
  ],
  "has_gdown": [],
  "has_kaggle": [],
  "build_vtab_dataset": [
    "dataset_name",
    "transform",
    "download",
    "split",
    "data_dir",
    "classnames"
  ],
  "build_tfds_dataset": [
    "name",
    "transform",
    "download",
    "split",
    "data_dir",
    "classes"
  ],
  "build_wds_dataset": [
    "dataset_name",
    "transform",
    "split",
    "data_dir",
    "cache_dir"
  ],
  "_extract_task": [
    "dataset_name"
  ],
  "image_captions_collate_fn": [
    "batch"
  ],
  "get_dataset_collection_from_file": [
    "path"
  ],
  "dataset_collection": [],
  "all_imagenet_wordnet_ids": [],
  "Caltech101": {
    "__init__": [
      "self",
      "root",
      "target_type",
      "transform",
      "target_transform",
      "download"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_check_integrity": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "download": [
      "self"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "Caltech256": {
    "__init__": [
      "self",
      "root",
      "transform",
      "target_transform",
      "download"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "_check_integrity": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "download": [
      "self"
    ]
  },
  "GITHUB_DATA_PATH_DE_FR": [],
  "GITHUB_DATA_PATH_JP": [],
  "Multilingual_MSCOCO": {
    "__init__": [
      "self",
      "root",
      "ann_file",
      "transform",
      "target_transform"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "_count_all_pp": [
    "x"
  ],
  "_count_vehicles_pp": [
    "x"
  ],
  "_count_left_pp": [
    "x"
  ],
  "_count_far_pp": [
    "x"
  ],
  "_count_near_pp": [
    "x"
  ],
  "_closest_object_distance_pp": [
    "x"
  ],
  "_closest_vehicle_distance_pp": [
    "x"
  ],
  "_closest_object_x_location_pp": [
    "x"
  ],
  "_TASK_DICT": [],
  "KittiData": {
    "__init__": [
      "self",
      "task",
      "data_dir"
    ]
  },
  "Flickr30k_200": {
    "__init__": [
      "self",
      "root",
      "ann_file",
      "transform",
      "target_transform"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "SugarCrepe": {
    "__init__": [
      "self",
      "root",
      "ann_file",
      "transform"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ]
  },
  "download_tfds_dataset": [
    "name",
    "data_dir"
  ],
  "disable_gpus_on_tensorflow": [],
  "VTABIterableDataset": {
    "__init__": [
      "self",
      "tfds_dataset",
      "split",
      "input_name",
      "label_name",
      "input_mode",
      "transform",
      "target_transform",
      "classes"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "WinoGround": {
    "__init__": [
      "self",
      "root",
      "transform"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ]
  },
  "object_categories": [],
  "category_to_idx": [],
  "urls": [],
  "download_url": [
    "url",
    "path"
  ],
  "download_voc2007": [
    "root"
  ],
  "read_split": [
    "root",
    "dataset",
    "split"
  ],
  "read_bndbox": [
    "root",
    "dataset",
    "paths"
  ],
  "PASCALVoc2007": {
    "__init__": [
      "self",
      "root",
      "set",
      "transform",
      "download",
      "target_transform"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "PASCALVoc2007Cropped": {
    "__init__": [
      "self",
      "root",
      "set",
      "transform",
      "download",
      "target_transform"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ]
  },
  "set_language": [
    "tokenizer",
    "lang_code"
  ],
  "lang_map": [],
  "TYPE2FUNC": [],
  "MODEL_TYPES": [],
  "load_clip": [
    "model_type",
    "model_name",
    "pretrained",
    "cache_dir",
    "device"
  ],
  "DictTensor": {
    "__init__": [
      "self",
      "d"
    ],
    "to": [
      "self",
      "device"
    ]
  },
  "JaCLIPForBenchmark": {
    "__init__": [
      "self",
      "model"
    ],
    "encode_text": [
      "self",
      "dict_tensor"
    ],
    "encode_image": [
      "self",
      "image"
    ]
  },
  "load_japanese_clip": [
    "pretrained",
    "device"
  ],
  "load_open_clip": [
    "model_name",
    "pretrained",
    "cache_dir",
    "device"
  ]
}