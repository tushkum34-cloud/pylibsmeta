{
  "logger": [],
  "DEFAULT_LOG_CONFIG": [],
  "INTRA_EPOCH_CKPT_FLAG": [],
  "PYTHON_VERSION_MAJOR": [],
  "PYTHON_VERSION_MINOR": [],
  "run_opt_defaults": [],
  "create_experiment_directory": [
    "experiment_directory",
    "hyperparams_to_save",
    "overrides",
    "log_config",
    "save_env_desc"
  ],
  "_logging_excepthook": [
    "exc_type",
    "exc_value",
    "exc_traceback"
  ],
  "parse_arguments": [
    "arg_list"
  ],
  "_convert_to_yaml": [
    "overrides"
  ],
  "Stage": {
    "TRAIN": [],
    "VALID": [],
    "TEST": []
  },
  "Brain": {
    "__init__": [
      "self",
      "modules",
      "opt_class",
      "hparams",
      "run_opts",
      "checkpointer"
    ],
    "print_trainable_parameters": [
      "self"
    ],
    "compute_forward": [
      "self",
      "batch",
      "stage"
    ],
    "compute_objectives": [
      "self",
      "predictions",
      "batch",
      "stage"
    ],
    "on_stage_start": [
      "self",
      "stage",
      "epoch"
    ],
    "on_stage_end": [
      "self",
      "stage",
      "stage_loss",
      "epoch"
    ],
    "make_dataloader": [
      "self",
      "dataset",
      "stage",
      "ckpt_prefix"
    ],
    "_train_loader_specifics": [
      "self",
      "dataset",
      "loader_kwargs"
    ],
    "on_fit_start": [
      "self"
    ],
    "init_optimizers": [
      "self"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ],
    "on_evaluate_start": [
      "self",
      "max_key",
      "min_key"
    ],
    "fit_batch": [
      "self",
      "batch"
    ],
    "check_loss_isfinite": [
      "self",
      "loss"
    ],
    "check_gradients": [
      "self"
    ],
    "freeze_optimizers": [
      "self",
      "optimizers"
    ],
    "optimizers_step": [
      "self"
    ],
    "on_fit_batch_start": [
      "self",
      "batch",
      "should_step"
    ],
    "on_fit_batch_end": [
      "self",
      "batch",
      "outputs",
      "loss",
      "should_step"
    ],
    "evaluate_batch": [
      "self",
      "batch",
      "stage"
    ],
    "_fit_train": [
      "self",
      "train_set",
      "epoch",
      "enable"
    ],
    "_should_save_intra_epoch_ckpt": [
      "self",
      "last_ckpt_time",
      "steps_since_ckpt"
    ],
    "_fit_valid": [
      "self",
      "valid_set",
      "epoch",
      "enable"
    ],
    "fit": [
      "self",
      "epoch_counter",
      "train_set",
      "valid_set",
      "progressbar",
      "train_loader_kwargs",
      "valid_loader_kwargs"
    ],
    "_optimizer_step_limit_exceeded": [
      "self"
    ],
    "_save_intra_epoch_ckpt": [
      "self"
    ],
    "_compile": [
      "self"
    ],
    "_wrap_distributed": [
      "self"
    ],
    "evaluate": [
      "self",
      "test_set",
      "max_key",
      "min_key",
      "progressbar",
      "test_loader_kwargs"
    ],
    "update_average": [
      "self",
      "loss",
      "avg_loss"
    ],
    "no_sync": [
      "self",
      "use"
    ],
    "_save": [
      "self",
      "path"
    ],
    "_recover": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "__all__": [],
  "__version__": [],
  "make_deprecated_redirections": [],
  "Downsampler": {
    "forward": [
      "self",
      "x"
    ]
  },
  "SignalDownsampler": {
    "__init__": [
      "self",
      "downsampling_factor",
      "initial_sampling_rate"
    ]
  },
  "Conv1DDownsampler": {
    "__init__": [
      "self",
      "downsampling_factor",
      "kernel_size"
    ]
  },
  "PoolingDownsampler": {
    "__init__": [
      "self",
      "downsampling_factor",
      "kernel_size",
      "padding",
      "pool_type"
    ]
  },
  "Fbank": {
    "__init__": [
      "self",
      "deltas",
      "context",
      "requires_grad",
      "sample_rate",
      "f_min",
      "f_max",
      "n_fft",
      "n_mels",
      "filter_shape",
      "param_change_factor",
      "param_rand_factor",
      "left_frames",
      "right_frames",
      "win_length",
      "hop_length"
    ],
    "forward": [
      "self",
      "wav"
    ],
    "get_filter_properties": [
      "self"
    ]
  },
  "MFCC": {
    "__init__": [
      "self",
      "deltas",
      "context",
      "requires_grad",
      "sample_rate",
      "f_min",
      "f_max",
      "n_fft",
      "n_mels",
      "n_mfcc",
      "filter_shape",
      "param_change_factor",
      "param_rand_factor",
      "left_frames",
      "right_frames",
      "win_length",
      "hop_length"
    ],
    "forward": [
      "self",
      "wav"
    ]
  },
  "Leaf": {
    "__init__": [
      "self",
      "out_channels",
      "window_len",
      "window_stride",
      "sample_rate",
      "input_shape",
      "in_channels",
      "min_freq",
      "max_freq",
      "use_pcen",
      "learnable_pcen",
      "use_legacy_complex",
      "skip_transpose",
      "n_fft"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_squared_modulus_activation": [
      "self",
      "x"
    ],
    "_check_input_shape": [
      "self",
      "shape"
    ]
  },
  "upalign_value": [
    "x",
    "to"
  ],
  "StreamingFeatureWrapperContext": {},
  "StreamingFeatureWrapper": {
    "__init__": [
      "self",
      "module",
      "properties"
    ],
    "get_required_padding": [
      "self"
    ],
    "get_output_count_per_pad_frame": [
      "self"
    ],
    "get_recommended_final_chunk_count": [
      "self",
      "frames_per_chunk"
    ],
    "forward": [
      "self",
      "chunk",
      "context"
    ],
    "get_filter_properties": [
      "self"
    ],
    "make_streaming_context": [
      "self"
    ]
  },
  "VocalFeatures": {
    "__init__": [
      "self",
      "min_f0_Hz",
      "max_f0_Hz",
      "step_size",
      "window_size",
      "sample_rate",
      "log_scores",
      "eps",
      "sma_neighbors",
      "n_mels",
      "n_mfcc"
    ],
    "forward": [
      "self",
      "audio"
    ]
  },
  "moving_average": [
    "features",
    "dim",
    "n"
  ],
  "DelaySum_Beamformer": {
    "__init__": [
      "self",
      "sampling_rate"
    ],
    "forward": [
      "self",
      "mics_signals"
    ]
  },
  "conv3x3": [
    "in_planes",
    "out_planes",
    "stride"
  ],
  "conv1x1": [
    "in_planes",
    "out_planes",
    "stride"
  ],
  "SEBlock": {
    "__init__": [
      "self",
      "channels",
      "reduction",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BasicBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "downsample",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SEBasicBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "reduction",
      "stride",
      "downsample",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNet": {
    "__init__": [
      "self",
      "input_size",
      "device",
      "activation",
      "channels",
      "block_sizes",
      "strides",
      "lin_neurons"
    ],
    "_make_layer_se": [
      "self",
      "in_channels",
      "out_channels",
      "block_num",
      "stride"
    ],
    "_make_layer": [
      "self",
      "in_channels",
      "out_channels",
      "block_num",
      "stride"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "Classifier": {
    "__init__": [
      "self",
      "input_size",
      "device",
      "lin_blocks",
      "lin_neurons",
      "out_neurons"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "VanillaNN": {
    "__init__": [
      "self",
      "input_shape",
      "activation",
      "dnn_blocks",
      "dnn_neurons"
    ]
  },
  "CRDNN": {
    "__init__": [
      "self",
      "input_size",
      "input_shape",
      "activation",
      "dropout",
      "cnn_blocks",
      "cnn_channels",
      "cnn_kernelsize",
      "time_pooling",
      "time_pooling_size",
      "freq_pooling_size",
      "rnn_class",
      "inter_layer_pooling_size",
      "using_2d_pooling",
      "rnn_layers",
      "rnn_neurons",
      "rnn_bidirectional",
      "rnn_re_init",
      "dnn_blocks",
      "dnn_neurons",
      "projection_dim",
      "use_rnnp"
    ]
  },
  "CNN_Block": {
    "__init__": [
      "self",
      "input_shape",
      "channels",
      "kernel_size",
      "activation",
      "using_2d_pool",
      "pooling_size",
      "dropout"
    ]
  },
  "DNN_Block": {
    "__init__": [
      "self",
      "input_shape",
      "neurons",
      "activation",
      "dropout"
    ]
  },
  "ContextNet": {
    "__init__": [
      "self",
      "input_shape",
      "out_channels",
      "conv_channels",
      "kernel_size",
      "strides",
      "num_blocks",
      "num_layers",
      "inner_dim",
      "alpha",
      "beta",
      "dropout",
      "activation",
      "se_activation",
      "norm",
      "residuals"
    ]
  },
  "SEmodule": {
    "__init__": [
      "self",
      "input_shape",
      "inner_dim",
      "activation",
      "norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ContextNetBlock": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "num_layers",
      "inner_dim",
      "input_shape",
      "stride",
      "beta",
      "dropout",
      "activation",
      "se_activation",
      "norm",
      "residual"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_reset_params": [
      "self"
    ]
  },
  "compute_mask": [
    "shape",
    "sample_lens",
    "mask_prob",
    "mask_length"
  ],
  "brq_mask_collate_fn": [
    "samples_lst",
    "get_out_len_fn",
    "mask_prob",
    "mask_length",
    "n_mels"
  ],
  "get_irrelevant_regions": [
    "labels",
    "K",
    "num_classes",
    "N_shared",
    "stage"
  ],
  "weights_init": [
    "m"
  ],
  "VectorQuantization": {
    "forward": [
      "ctx",
      "inputs",
      "codebook",
      "labels",
      "num_classes",
      "activate_class_partitioning",
      "shared_keys",
      "training"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "VectorQuantizationStraightThrough": {
    "forward": [
      "ctx",
      "inputs",
      "codebook",
      "labels",
      "num_classes",
      "activate_class_partitioning",
      "shared_keys",
      "training"
    ],
    "backward": [
      "ctx",
      "grad_output",
      "grad_indices",
      "labels",
      "num_classes",
      "activate_class_partitioning",
      "shared_keys",
      "training"
    ]
  },
  "Conv2dEncoder_v2": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResBlockAudio": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "VectorQuantizedPSI_Audio": {
    "__init__": [
      "self",
      "dim",
      "K",
      "numclasses",
      "activate_class_partitioning",
      "shared_keys",
      "use_adapter",
      "adapter_reduce_dim"
    ],
    "forward": [
      "self",
      "hs",
      "labels"
    ]
  },
  "VectorQuantizedPSIFocalNet_Audio": {
    "__init__": [
      "self",
      "dim"
    ]
  },
  "VectorQuantizedPSIViT_Audio": {
    "__init__": [
      "self",
      "dim"
    ]
  },
  "VQEmbedding": {
    "__init__": [
      "self",
      "K",
      "D",
      "numclasses",
      "activate_class_partitioning",
      "shared_keys"
    ],
    "forward": [
      "self",
      "z_e_x",
      "labels"
    ],
    "straight_through": [
      "self",
      "z_e_x",
      "labels"
    ]
  },
  "W2VLatentExtractor": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_sizes",
      "strides",
      "dropout",
      "conv_init"
    ],
    "forward": [
      "self",
      "x",
      "normalize_signal"
    ],
    "get_output_lengths": [
      "self",
      "input_lengths"
    ]
  },
  "W2VTargetQuantiser": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "quantiser",
      "num_vars",
      "temperature_decay"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EncoderWrapper": {
    "__init__": [
      "self",
      "in_dim",
      "embedding_dim",
      "latent_encoder",
      "positional_encoding",
      "dropout_encoder_input"
    ],
    "forward": [
      "self",
      "latents",
      "wav_lens",
      "padding_mask",
      "mask"
    ]
  },
  "sample_negatives": [
    "y",
    "num_neg"
  ],
  "w2v_mask_collate_fn": [
    "samples_lst",
    "get_out_len_fn",
    "mask_prob",
    "mask_length"
  ],
  "EncoderPreNet": {
    "__init__": [
      "self",
      "n_vocab",
      "blank_id",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PostNet": {
    "__init__": [
      "self",
      "n_mel_channels",
      "postnet_embedding_dim",
      "postnet_kernel_size",
      "postnet_n_convolutions",
      "postnet_dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DurationPredictor": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dropout",
      "n_units"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "SPNPredictor": {
    "__init__": [
      "self",
      "enc_num_layers",
      "enc_num_head",
      "enc_d_model",
      "enc_ffn_dim",
      "enc_k_dim",
      "enc_v_dim",
      "enc_dropout",
      "normalize_before",
      "ffn_type",
      "ffn_cnn_kernel_size_list",
      "n_char",
      "padding_idx"
    ],
    "forward": [
      "self",
      "tokens",
      "last_phonemes"
    ],
    "infer": [
      "self",
      "tokens",
      "last_phonemes"
    ]
  },
  "FastSpeech2": {
    "__init__": [
      "self",
      "enc_num_layers",
      "enc_num_head",
      "enc_d_model",
      "enc_ffn_dim",
      "enc_k_dim",
      "enc_v_dim",
      "enc_dropout",
      "dec_num_layers",
      "dec_num_head",
      "dec_d_model",
      "dec_ffn_dim",
      "dec_k_dim",
      "dec_v_dim",
      "dec_dropout",
      "normalize_before",
      "ffn_type",
      "ffn_cnn_kernel_size_list",
      "n_char",
      "n_mels",
      "postnet_embedding_dim",
      "postnet_kernel_size",
      "postnet_n_convolutions",
      "postnet_dropout",
      "padding_idx",
      "dur_pred_kernel_size",
      "pitch_pred_kernel_size",
      "energy_pred_kernel_size",
      "variance_predictor_dropout"
    ],
    "forward": [
      "self",
      "tokens",
      "durations",
      "pitch",
      "energy",
      "pace",
      "pitch_rate",
      "energy_rate"
    ]
  },
  "average_over_durations": [
    "values",
    "durs"
  ],
  "upsample": [
    "feats",
    "durs",
    "pace",
    "padding_value"
  ],
  "TextMelCollate": {
    "__call__": [
      "self",
      "batch"
    ]
  },
  "Loss": {
    "__init__": [
      "self",
      "log_scale_durations",
      "ssim_loss_weight",
      "duration_loss_weight",
      "pitch_loss_weight",
      "energy_loss_weight",
      "mel_loss_weight",
      "postnet_mel_loss_weight",
      "spn_loss_weight",
      "spn_loss_max_epochs"
    ],
    "forward": [
      "self",
      "predictions",
      "targets",
      "current_epoch"
    ]
  },
  "mel_spectogram": [
    "sample_rate",
    "hop_length",
    "win_length",
    "n_fft",
    "n_mels",
    "f_min",
    "f_max",
    "power",
    "normalized",
    "min_max_energy_norm",
    "norm",
    "mel_scale",
    "compression",
    "audio"
  ],
  "dynamic_range_compression": [
    "x",
    "C",
    "clip_val"
  ],
  "SSIMLoss": {
    "__init__": [
      "self"
    ],
    "sequence_mask": [
      "self",
      "sequence_length",
      "max_len"
    ],
    "sample_wise_min_max": [
      "self",
      "x",
      "mask"
    ],
    "forward": [
      "self",
      "y_hat",
      "y",
      "length"
    ]
  },
  "_SSIMLoss": {
    "__constants__": [],
    "__init__": [
      "self",
      "kernel_size",
      "kernel_sigma",
      "k1",
      "k2",
      "downsample",
      "reduction",
      "data_range"
    ],
    "_reduce": [
      "self",
      "x",
      "reduction"
    ],
    "_validate_input": [
      "self",
      "tensors",
      "dim_range",
      "data_range",
      "size_range"
    ],
    "gaussian_filter": [
      "self",
      "kernel_size",
      "sigma"
    ],
    "_ssim_per_channel": [
      "self",
      "x",
      "y",
      "kernel",
      "k1",
      "k2"
    ],
    "_ssim_per_channel_complex": [
      "self",
      "x",
      "y",
      "kernel",
      "k1",
      "k2"
    ],
    "ssim": [
      "self",
      "x",
      "y",
      "kernel_size",
      "kernel_sigma",
      "data_range",
      "reduction",
      "full",
      "downsample",
      "k1",
      "k2"
    ],
    "forward": [
      "self",
      "x",
      "y"
    ]
  },
  "TextMelCollateWithAlignment": {
    "__call__": [
      "self",
      "batch"
    ]
  },
  "maximum_path_numpy": [
    "value",
    "mask"
  ],
  "AlignmentNetwork": {
    "__init__": [
      "self",
      "in_query_channels",
      "in_key_channels",
      "attn_channels",
      "temperature"
    ],
    "forward": [
      "self",
      "queries",
      "keys",
      "mask",
      "attn_prior"
    ]
  },
  "FastSpeech2WithAlignment": {
    "__init__": [
      "self",
      "enc_num_layers",
      "enc_num_head",
      "enc_d_model",
      "enc_ffn_dim",
      "enc_k_dim",
      "enc_v_dim",
      "enc_dropout",
      "in_query_channels",
      "in_key_channels",
      "attn_channels",
      "temperature",
      "dec_num_layers",
      "dec_num_head",
      "dec_d_model",
      "dec_ffn_dim",
      "dec_k_dim",
      "dec_v_dim",
      "dec_dropout",
      "normalize_before",
      "ffn_type",
      "ffn_cnn_kernel_size_list",
      "n_char",
      "n_mels",
      "postnet_embedding_dim",
      "postnet_kernel_size",
      "postnet_n_convolutions",
      "postnet_dropout",
      "padding_idx",
      "dur_pred_kernel_size",
      "pitch_pred_kernel_size",
      "energy_pred_kernel_size",
      "variance_predictor_dropout"
    ],
    "_forward_aligner": [
      "self",
      "x",
      "y",
      "x_mask",
      "y_mask"
    ],
    "forward": [
      "self",
      "tokens",
      "mel_spectograms",
      "pitch",
      "energy",
      "pace",
      "pitch_rate",
      "energy_rate"
    ]
  },
  "LossWithAlignment": {
    "__init__": [
      "self",
      "log_scale_durations",
      "ssim_loss_weight",
      "duration_loss_weight",
      "pitch_loss_weight",
      "energy_loss_weight",
      "mel_loss_weight",
      "postnet_mel_loss_weight",
      "aligner_loss_weight",
      "binary_alignment_loss_weight",
      "binary_alignment_loss_warmup_epochs",
      "binary_alignment_loss_max_epochs"
    ],
    "forward": [
      "self",
      "predictions",
      "targets",
      "current_epoch"
    ]
  },
  "ForwardSumLoss": {
    "__init__": [
      "self",
      "blank_logprob"
    ],
    "forward": [
      "self",
      "attn_logprob",
      "key_lens",
      "query_lens"
    ]
  },
  "BinaryAlignmentLoss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "alignment_hard",
      "alignment_soft"
    ]
  },
  "ESPnetVGG": {
    "__init__": [
      "self",
      "input_shape",
      "activation",
      "dropout",
      "cnn_channels",
      "rnn_class",
      "rnn_layers",
      "rnn_neurons",
      "rnn_bidirectional",
      "rnn_re_init",
      "projection_neurons"
    ]
  },
  "FairseqWav2Vec2": {
    "__init__": [
      "self",
      "pretrained_path",
      "save_path",
      "input_norm",
      "output_norm",
      "freeze",
      "freeze_feature_extractor",
      "pretrain",
      "dropout",
      "layer_drop"
    ],
    "forward": [
      "self",
      "wav",
      "wav_lens"
    ],
    "extract_features": [
      "self",
      "wav",
      "padding_mask"
    ],
    "reset_layer": [
      "self",
      "model"
    ],
    "remove_pretraining_modules": [
      "self"
    ],
    "make_masks": [
      "self",
      "src",
      "wav_len",
      "pad_idx"
    ]
  },
  "FairseqWav2Vec1": {
    "__init__": [
      "self",
      "pretrained_path",
      "save_path",
      "output_norm",
      "freeze",
      "pretrain"
    ],
    "forward": [
      "self",
      "wav"
    ],
    "extract_features": [
      "self",
      "wav"
    ],
    "reset_layer": [
      "self",
      "model"
    ]
  },
  "Psi": {
    "__init__": [
      "self",
      "n_comp",
      "T",
      "in_emb_dims"
    ],
    "forward": [
      "self",
      "inp"
    ]
  },
  "NMFDecoderAudio": {
    "__init__": [
      "self",
      "n_comp",
      "n_freq",
      "device"
    ],
    "forward": [
      "self",
      "H"
    ],
    "return_W": [
      "self"
    ]
  },
  "PsiOptimized": {
    "__init__": [
      "self",
      "dim",
      "K",
      "numclasses",
      "use_adapter",
      "adapter_reduce_dim"
    ],
    "forward": [
      "self",
      "hs"
    ]
  },
  "Theta": {
    "__init__": [
      "self",
      "n_comp",
      "T",
      "num_classes"
    ],
    "forward": [
      "self",
      "H"
    ]
  },
  "NMFEncoder": {
    "__init__": [
      "self",
      "n_freq",
      "n_comp"
    ],
    "forward": [
      "self",
      "X"
    ]
  },
  "CNN14PSI_stft": {
    "__init__": [
      "self",
      "dim",
      "K"
    ],
    "forward": [
      "self",
      "hs",
      "labels"
    ]
  },
  "CNN14PSI_stft_2d": {
    "__init__": [
      "self",
      "dim",
      "K"
    ],
    "forward": [
      "self",
      "hs",
      "labels"
    ]
  },
  "BEATs": {
    "__init__": [
      "self",
      "ckp_path",
      "freeze",
      "output_all_hiddens"
    ],
    "forward_padding_mask": [
      "self",
      "features",
      "padding_mask"
    ],
    "preprocess": [
      "self",
      "source",
      "fbank_mean",
      "fbank_std"
    ],
    "forward": [
      "self",
      "wav",
      "wav_lens",
      "fbank_mean",
      "fbank_std"
    ],
    "extract_features": [
      "self",
      "wav",
      "wav_lens",
      "fbank_mean",
      "fbank_std"
    ]
  },
  "gelu_accurate": [
    "x"
  ],
  "gelu": [
    "x"
  ],
  "get_activation_fn": [
    "activation"
  ],
  "SamePad": {
    "__init__": [
      "self",
      "kernel_size",
      "causal"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Swish": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GLU_Linear": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "glu_type",
      "bias_in_glu"
    ]
  },
  "GradMultiply": {
    "forward": [
      "ctx",
      "x",
      "scale"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "quant_noise": [
    "module",
    "p",
    "block_size"
  ],
  "TransformerEncoder": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask",
      "output_all_hiddens"
    ],
    "extract_features": [
      "self",
      "x",
      "padding_mask",
      "output_all_hiddens"
    ]
  },
  "TransformerSentenceEncoderLayer": {
    "__init__": [
      "self",
      "embedding_dim",
      "ffn_embedding_dim",
      "num_attention_heads",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "activation_fn",
      "layer_norm_first",
      "deep_norm",
      "has_relative_attention_bias",
      "num_buckets",
      "max_distance",
      "rescale_init",
      "gru_rel_pos",
      "encoder_layers"
    ],
    "forward": [
      "self",
      "x",
      "self_attn_mask",
      "self_attn_padding_mask",
      "need_weights",
      "pos_bias"
    ]
  },
  "MultiheadAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "kdim",
      "vdim",
      "dropout",
      "bias",
      "add_bias_kv",
      "add_zero_attn",
      "self_attention",
      "encoder_decoder_attention",
      "q_noise",
      "qn_block_size",
      "has_relative_attention_bias",
      "num_buckets",
      "max_distance",
      "gru_rel_pos",
      "rescale_init"
    ],
    "reset_parameters": [
      "self"
    ],
    "_relative_positions_bucket": [
      "self",
      "relative_positions",
      "bidirectional"
    ],
    "compute_bias": [
      "self",
      "query_length",
      "key_length"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask",
      "incremental_state",
      "need_weights",
      "static_kv",
      "attn_mask",
      "before_softmax",
      "need_head_weights",
      "position_bias"
    ],
    "_compute_attention_output": [
      "self",
      "q",
      "v",
      "attn_weights",
      "position_bias",
      "bsz",
      "tgt_len",
      "src_len",
      "embed_dim",
      "need_weights",
      "need_head_weights",
      "alpha"
    ],
    "_process_attention_weights": [
      "self",
      "q",
      "k",
      "v",
      "attn_mask",
      "key_padding_mask",
      "bsz",
      "tgt_len",
      "src_len",
      "alpha"
    ],
    "apply_bias": [
      "self",
      "k",
      "v",
      "bsz",
      "attn_mask",
      "key_padding_mask"
    ],
    "_prepare_attention_inputs": [
      "self",
      "query",
      "key",
      "value",
      "bsz",
      "tgt_len",
      "key_padding_mask",
      "attn_mask",
      "alpha"
    ],
    "_append_prev_key_padding_mask": [
      "key_padding_mask",
      "prev_key_padding_mask",
      "batch_size",
      "src_len",
      "static_kv"
    ],
    "_get_input_buffer": [
      "self",
      "incremental_state"
    ],
    "_set_input_buffer": [
      "self",
      "incremental_state",
      "buffer"
    ],
    "apply_sparse_mask": [
      "self",
      "attn_weights",
      "tgt_len",
      "src_len",
      "bsz"
    ]
  },
  "init_bert_params": [
    "module"
  ],
  "BEATsConfig": {
    "__init__": [
      "self",
      "cfg"
    ],
    "update": [
      "self",
      "cfg"
    ]
  },
  "EPS": [],
  "GlobalLayerNorm": {
    "__init__": [
      "self",
      "dim",
      "shape",
      "eps",
      "elementwise_affine"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CumulativeLayerNorm": {
    "__init__": [
      "self",
      "dim",
      "elementwise_affine",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "select_norm": [
    "norm",
    "dim",
    "shape",
    "eps"
  ],
  "Encoder": {
    "__init__": [
      "self",
      "kernel_size",
      "out_channels",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Decoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "IdentityBlock": {
    "_init__": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "FastTransformerBlock": {
    "__init__": [
      "self",
      "attention_type",
      "out_channels",
      "num_layers",
      "nhead",
      "d_ffn",
      "dropout",
      "activation",
      "reformer_bucket_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PyTorchPositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout",
      "max_len"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PytorchTransformerBlock": {
    "__init__": [
      "self",
      "out_channels",
      "num_layers",
      "nhead",
      "d_ffn",
      "dropout",
      "activation",
      "use_positional_encoding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SBTransformerBlock": {
    "__init__": [
      "self",
      "num_layers",
      "d_model",
      "nhead",
      "d_ffn",
      "input_shape",
      "kdim",
      "vdim",
      "dropout",
      "activation",
      "use_positional_encoding",
      "norm_before",
      "attention_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SBRNNBlock": {
    "__init__": [
      "self",
      "input_size",
      "hidden_channels",
      "num_layers",
      "rnn_type",
      "dropout",
      "bidirectional"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DPTNetBlock": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "dim_feedforward",
      "dropout",
      "activation"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "forward": [
      "self",
      "src"
    ]
  },
  "_get_activation_fn": [
    "activation"
  ],
  "Dual_Computation_Block": {
    "__init__": [
      "self",
      "intra_mdl",
      "inter_mdl",
      "out_channels",
      "norm",
      "skip_around_intra",
      "linear_layer_after_inter_intra"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Dual_Path_Model": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "intra_model",
      "inter_model",
      "num_layers",
      "norm",
      "K",
      "num_spks",
      "skip_around_intra",
      "linear_layer_after_inter_intra",
      "use_global_pos_enc",
      "max_length"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_padding": [
      "self",
      "input",
      "K"
    ],
    "_Segmentation": [
      "self",
      "input",
      "K"
    ],
    "_over_add": [
      "self",
      "input",
      "gap"
    ]
  },
  "SepformerWrapper": {
    "__init__": [
      "self",
      "encoder_kernel_size",
      "encoder_in_nchannels",
      "encoder_out_nchannels",
      "masknet_chunksize",
      "masknet_numlayers",
      "masknet_norm",
      "masknet_useextralinearlayer",
      "masknet_extraskipconnection",
      "masknet_numspks",
      "intra_numlayers",
      "inter_numlayers",
      "intra_nhead",
      "inter_nhead",
      "intra_dffn",
      "inter_dffn",
      "intra_use_positional",
      "inter_use_positional",
      "intra_norm_before",
      "inter_norm_before"
    ],
    "reset_layer_recursively": [
      "self",
      "layer"
    ],
    "forward": [
      "self",
      "mix"
    ]
  },
  "SBConformerEncoderBlock": {
    "__init__": [
      "self",
      "num_layers",
      "d_model",
      "nhead",
      "d_ffn",
      "input_shape",
      "kdim",
      "vdim",
      "dropout",
      "activation",
      "kernel_size",
      "bias",
      "use_positional_encoding",
      "attention_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "xavier_init_layer": [
    "in_size",
    "out_size",
    "spec_norm",
    "layer_type"
  ],
  "shifted_sigmoid": [
    "x"
  ],
  "Learnable_sigmoid": {
    "__init__": [
      "self",
      "in_features"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EnhancementGenerator": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "MetricDiscriminator": {
    "__init__": [
      "self",
      "kernel_size",
      "base_channels",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv1d": {
    "__init__": [
      "self"
    ]
  },
  "BatchNorm1d": {
    "__init__": [
      "self"
    ]
  },
  "TDNNBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dilation",
      "activation",
      "groups",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Res2NetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "scale",
      "kernel_size",
      "dilation",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AttentiveStatisticsPooling": {
    "__init__": [
      "self",
      "channels",
      "attention_channels",
      "global_context"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "SERes2NetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "res2net_scale",
      "se_channels",
      "kernel_size",
      "dilation",
      "activation",
      "groups",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "ECAPA_TDNN": {
    "__init__": [
      "self",
      "input_size",
      "device",
      "lin_neurons",
      "activation",
      "channels",
      "kernel_sizes",
      "dilations",
      "attention_channels",
      "res2net_scale",
      "se_channels",
      "global_context",
      "groups",
      "dropout"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "ConvolutionalSpatialGatingUnit": {
    "__init__": [
      "self",
      "input_size",
      "kernel_size",
      "dropout",
      "use_linear_after_conv",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvolutionFrontEnd": {
    "__init__": [
      "self",
      "input_shape",
      "num_blocks",
      "num_layers_per_block",
      "out_channels",
      "kernel_sizes",
      "strides",
      "dilations",
      "residuals",
      "conv_module",
      "activation",
      "norm",
      "dropout",
      "conv_bias",
      "padding",
      "conv_init"
    ],
    "get_filter_properties": [
      "self"
    ]
  },
  "ConvBlock": {
    "__init__": [
      "self",
      "num_layers",
      "out_channels",
      "input_shape",
      "kernel_size",
      "stride",
      "dilation",
      "residual",
      "conv_module",
      "activation",
      "norm",
      "dropout",
      "conv_bias",
      "padding",
      "conv_init"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_filter_properties": [
      "self"
    ]
  },
  "Xvector": {
    "__init__": [
      "self",
      "device",
      "activation",
      "tdnn_blocks",
      "tdnn_channels",
      "tdnn_kernel_sizes",
      "tdnn_dilations",
      "lin_neurons",
      "in_channels"
    ],
    "forward": [
      "self",
      "x",
      "lens"
    ]
  },
  "Discriminator": {
    "__init__": [
      "self",
      "input_shape",
      "activation",
      "lin_blocks",
      "lin_neurons",
      "out_neurons"
    ]
  },
  "LinearNorm": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "bias",
      "w_init_gain"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvNorm": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "w_init_gain"
    ],
    "forward": [
      "self",
      "signal"
    ]
  },
  "LocationLayer": {
    "__init__": [
      "self",
      "attention_n_filters",
      "attention_kernel_size",
      "attention_dim"
    ],
    "forward": [
      "self",
      "attention_weights_cat"
    ]
  },
  "Attention": {
    "__init__": [
      "self",
      "attention_rnn_dim",
      "embedding_dim",
      "attention_dim",
      "attention_location_n_filters",
      "attention_location_kernel_size"
    ],
    "get_alignment_energies": [
      "self",
      "query",
      "processed_memory",
      "attention_weights_cat"
    ],
    "forward": [
      "self",
      "attention_hidden_state",
      "memory",
      "processed_memory",
      "attention_weights_cat",
      "mask"
    ]
  },
  "Prenet": {
    "__init__": [
      "self",
      "in_dim",
      "sizes",
      "dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Postnet": {
    "__init__": [
      "self",
      "n_mel_channels",
      "postnet_embedding_dim",
      "postnet_kernel_size",
      "postnet_n_convolutions"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Tacotron2": {
    "__init__": [
      "self",
      "mask_padding",
      "n_mel_channels",
      "n_symbols",
      "symbols_embedding_dim",
      "encoder_kernel_size",
      "encoder_n_convolutions",
      "encoder_embedding_dim",
      "attention_rnn_dim",
      "attention_dim",
      "attention_location_n_filters",
      "attention_location_kernel_size",
      "n_frames_per_step",
      "decoder_rnn_dim",
      "prenet_dim",
      "max_decoder_steps",
      "gate_threshold",
      "p_attention_dropout",
      "p_decoder_dropout",
      "postnet_embedding_dim",
      "postnet_kernel_size",
      "postnet_n_convolutions",
      "decoder_no_early_stopping"
    ],
    "parse_output": [
      "self",
      "outputs",
      "output_lengths",
      "alignments_dim"
    ],
    "forward": [
      "self",
      "inputs",
      "alignments_dim"
    ],
    "infer": [
      "self",
      "inputs",
      "input_lengths"
    ]
  },
  "infer": [
    "model",
    "text_sequences",
    "input_lengths"
  ],
  "LossStats": [],
  "Linear": [],
  "ConvTranspose2d": [],
  "silu": [
    "x"
  ],
  "diffwave_mel_spectogram": [
    "sample_rate",
    "hop_length",
    "win_length",
    "n_fft",
    "n_mels",
    "f_min",
    "f_max",
    "power",
    "normalized",
    "norm",
    "mel_scale",
    "audio"
  ],
  "DiffusionEmbedding": {
    "__init__": [
      "self",
      "max_steps"
    ],
    "forward": [
      "self",
      "diffusion_step"
    ],
    "_lerp_embedding": [
      "self",
      "t"
    ],
    "_build_embedding": [
      "self",
      "max_steps"
    ]
  },
  "SpectrogramUpsampler": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResidualBlock": {
    "__init__": [
      "self",
      "n_mels",
      "residual_channels",
      "dilation",
      "uncond"
    ],
    "forward": [
      "self",
      "x",
      "diffusion_step",
      "conditioner"
    ]
  },
  "DiffWave": {
    "__init__": [
      "self",
      "input_channels",
      "residual_layers",
      "residual_channels",
      "dilation_cycle_length",
      "total_steps",
      "unconditional"
    ],
    "forward": [
      "self",
      "audio",
      "diffusion_step",
      "spectrogram",
      "length"
    ],
    "diffusion_forward": [
      "self",
      "x",
      "timesteps",
      "cond_emb",
      "length",
      "out_mask_value",
      "latent_mask_value"
    ]
  },
  "DiffWaveDiffusion": {
    "__init__": [
      "self",
      "model",
      "timesteps",
      "noise",
      "beta_start",
      "beta_end",
      "sample_min",
      "sample_max",
      "show_progress"
    ],
    "inference": [
      "self",
      "unconditional",
      "scale",
      "condition",
      "fast_sampling",
      "fast_sampling_noise_schedule",
      "device"
    ]
  },
  "LRELU_SLOPE": [],
  "process_duration": [
    "code",
    "code_feat"
  ],
  "ResBlock1": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "ResBlock2": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "HifiganGenerator": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "resblock_type",
      "resblock_dilation_sizes",
      "resblock_kernel_sizes",
      "upsample_kernel_sizes",
      "upsample_initial_channel",
      "upsample_factors",
      "inference_padding",
      "cond_channels",
      "conv_post_bias"
    ],
    "forward": [
      "self",
      "x",
      "g"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "inference": [
      "self",
      "c",
      "padding"
    ]
  },
  "VariancePredictor": {
    "__init__": [
      "self",
      "encoder_embed_dim",
      "var_pred_hidden_dim",
      "var_pred_kernel_size",
      "var_pred_dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UnitHifiganGenerator": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "resblock_type",
      "resblock_dilation_sizes",
      "resblock_kernel_sizes",
      "upsample_kernel_sizes",
      "upsample_initial_channel",
      "upsample_factors",
      "inference_padding",
      "cond_channels",
      "conv_post_bias",
      "vocab_size",
      "embedding_dim",
      "attn_dim",
      "duration_predictor",
      "var_pred_hidden_dim",
      "var_pred_kernel_size",
      "var_pred_dropout",
      "multi_speaker",
      "normalize_speaker_embeddings",
      "skip_token_embedding",
      "pooling_type"
    ],
    "_upsample": [
      "x",
      "max_frames"
    ],
    "forward": [
      "self",
      "x",
      "g",
      "spk"
    ],
    "inference": [
      "self",
      "x",
      "spk"
    ]
  },
  "DiscriminatorP": {
    "__init__": [
      "self",
      "period",
      "kernel_size",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MultiPeriodDiscriminator": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DiscriminatorS": {
    "__init__": [
      "self",
      "use_spectral_norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MultiScaleDiscriminator": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HifiganDiscriminator": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "stft": [
    "x",
    "n_fft",
    "hop_length",
    "win_length",
    "window_fn"
  ],
  "STFTLoss": {
    "__init__": [
      "self",
      "n_fft",
      "hop_length",
      "win_length"
    ],
    "forward": [
      "self",
      "y_hat",
      "y"
    ]
  },
  "MultiScaleSTFTLoss": {
    "__init__": [
      "self",
      "n_ffts",
      "hop_lengths",
      "win_lengths"
    ],
    "forward": [
      "self",
      "y_hat",
      "y"
    ]
  },
  "L1SpecLoss": {
    "__init__": [
      "self",
      "sample_rate",
      "hop_length",
      "win_length",
      "n_mel_channels",
      "n_fft",
      "n_stft",
      "mel_fmin",
      "mel_fmax",
      "mel_normalized",
      "power",
      "norm",
      "mel_scale",
      "dynamic_range_compression"
    ],
    "forward": [
      "self",
      "y_hat",
      "y"
    ]
  },
  "MSEGLoss": {
    "forward": [
      "self",
      "score_fake"
    ]
  },
  "MelganFeatureLoss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "fake_feats",
      "real_feats"
    ]
  },
  "MSEDLoss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "score_fake",
      "score_real"
    ]
  },
  "_apply_G_adv_loss": [
    "scores_fake",
    "loss_func"
  ],
  "_apply_D_loss": [
    "scores_fake",
    "scores_real",
    "loss_func"
  ],
  "GeneratorLoss": {
    "__init__": [
      "self",
      "stft_loss",
      "stft_loss_weight",
      "mseg_loss",
      "mseg_loss_weight",
      "feat_match_loss",
      "feat_match_loss_weight",
      "l1_spec_loss",
      "l1_spec_loss_weight",
      "mseg_dur_loss",
      "mseg_dur_loss_weight"
    ],
    "forward": [
      "self",
      "stage",
      "y_hat",
      "y",
      "scores_fake",
      "feats_fake",
      "feats_real",
      "log_dur_pred",
      "log_dur"
    ]
  },
  "DiscriminatorLoss": {
    "__init__": [
      "self",
      "msed_loss"
    ],
    "forward": [
      "self",
      "scores_fake",
      "scores_real"
    ]
  },
  "Generator": {
    "__init__": [
      "self",
      "kernel_size",
      "latent_vae",
      "z_prob"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "d1_loss": [
    "d_outputs",
    "reduction"
  ],
  "d2_loss": [
    "d_outputs",
    "reduction"
  ],
  "g3_loss": [
    "d_outputs",
    "predictions",
    "targets",
    "length",
    "l1LossCoeff",
    "klLossCoeff",
    "z_mean",
    "z_logvar",
    "reduction"
  ],
  "RNNLM": {
    "__init__": [
      "self",
      "output_neurons",
      "embedding_dim",
      "activation",
      "dropout",
      "rnn_class",
      "rnn_layers",
      "rnn_neurons",
      "rnn_re_init",
      "return_hidden",
      "dnn_blocks",
      "dnn_neurons"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ]
  },
  "MemLSTM": {
    "__init__": [
      "self",
      "hidden_size",
      "dropout",
      "bidirectional",
      "mem_type",
      "norm_type"
    ],
    "forward": [
      "self",
      "hc",
      "S"
    ]
  },
  "SegLSTM": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "dropout",
      "bidirectional",
      "norm_type"
    ],
    "forward": [
      "self",
      "input",
      "hc"
    ]
  },
  "SBTransformerBlock_wnormandskip": {
    "__init__": [
      "self",
      "num_layers",
      "d_model",
      "nhead",
      "d_ffn",
      "input_shape",
      "kdim",
      "vdim",
      "dropout",
      "activation",
      "use_positional_encoding",
      "norm_before",
      "attention_type",
      "causal",
      "use_norm",
      "use_skip",
      "norm_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResourceEfficientSeparationPipeline": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "output_size",
      "dropout",
      "num_blocks",
      "segment_size",
      "bidirectional",
      "mem_type",
      "norm_type",
      "seg_model",
      "mem_model"
    ],
    "forward": [
      "self",
      "input"
    ],
    "_padfeature": [
      "self",
      "input"
    ]
  },
  "ResourceEfficientSeparator": {
    "__init__": [
      "self",
      "input_dim",
      "causal",
      "num_spk",
      "nonlinear",
      "layer",
      "unit",
      "segment_size",
      "dropout",
      "mem_type",
      "seg_model",
      "mem_model"
    ],
    "forward": [
      "self",
      "inpt"
    ]
  },
  "EnhanceResnet": {
    "__init__": [
      "self",
      "n_fft",
      "win_length",
      "hop_length",
      "sample_rate",
      "channel_counts",
      "dense_count",
      "dense_nodes",
      "activation",
      "normalization",
      "dropout",
      "mask_weight"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extract_feats": [
      "self",
      "x"
    ]
  },
  "SEblock": {
    "__init__": [
      "self",
      "input_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TemporalBlocksSequential": {
    "__init__": [
      "self",
      "input_shape",
      "H",
      "P",
      "R",
      "X",
      "norm_type",
      "causal"
    ]
  },
  "MaskNet": {
    "__init__": [
      "self",
      "N",
      "B",
      "H",
      "P",
      "X",
      "R",
      "C",
      "norm_type",
      "causal",
      "mask_nonlinear"
    ],
    "forward": [
      "self",
      "mixture_w"
    ]
  },
  "TemporalBlock": {
    "__init__": [
      "self",
      "input_shape",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "norm_type",
      "causal"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DepthwiseSeparableConv": {
    "__init__": [
      "self",
      "input_shape",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "norm_type",
      "causal"
    ]
  },
  "Chomp1d": {
    "__init__": [
      "self",
      "chomp_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "choose_norm": [
    "norm_type",
    "channel_size"
  ],
  "ChannelwiseLayerNorm": {
    "__init__": [
      "self",
      "channel_size"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "y"
    ]
  },
  "MiniBatchKMeansSklearn": {
    "__init__": [
      "self"
    ],
    "to": [
      "self",
      "device"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch"
    ],
    "fit": [
      "self",
      "input"
    ],
    "partial_fit": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ],
    "inertia": [
      "self",
      "input"
    ],
    "n_steps": [
      "self"
    ],
    "cluster_centers_": [
      "self"
    ]
  },
  "init_layer": [
    "layer"
  ],
  "init_bn": [
    "bn"
  ],
  "Cnn14": {
    "__init__": [
      "self",
      "mel_bins",
      "emb_dim",
      "norm_type",
      "return_reps",
      "l2i"
    ],
    "init_weight": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CNN14PSI": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "hs",
      "labels"
    ]
  },
  "RE_MULTI_SPACE": [],
  "clean_pipeline": [
    "txt",
    "graphemes"
  ],
  "grapheme_pipeline": [
    "char",
    "grapheme_encoder",
    "uppercase"
  ],
  "tokenizer_encode_pipeline": [
    "seq",
    "tokenizer",
    "tokens",
    "wordwise",
    "word_separator",
    "token_space_index",
    "char_map"
  ],
  "_wordwise_tokenize": [
    "tokenizer",
    "sequence",
    "input_separator",
    "token_separator"
  ],
  "_wordwise_detokenize": [
    "tokenizer",
    "sequence",
    "output_separator",
    "token_separator"
  ],
  "_split_list": [
    "items",
    "separator"
  ],
  "enable_eos_bos": [
    "tokens",
    "encoder",
    "bos_index",
    "eos_index"
  ],
  "phoneme_pipeline": [
    "phn",
    "phoneme_encoder"
  ],
  "add_bos_eos": [
    "seq",
    "encoder"
  ],
  "beam_search_pipeline": [
    "char_lens",
    "encoder_out",
    "beam_searcher"
  ],
  "phoneme_decoder_pipeline": [
    "hyps",
    "phoneme_encoder"
  ],
  "char_range": [
    "start_char",
    "end_char"
  ],
  "build_token_char_map": [
    "tokens"
  ],
  "flip_map": [
    "map_dict"
  ],
  "text_decode": [
    "seq",
    "encoder"
  ],
  "char_map_detokenize": [
    "char_map",
    "tokenizer",
    "token_space_index",
    "wordwise"
  ],
  "_map_tokens_batch": [
    "tokens",
    "char_map"
  ],
  "_map_tokens_item": [
    "tokens",
    "char_map"
  ],
  "LazyInit": {
    "__init__": [
      "self",
      "init"
    ],
    "__call__": [
      "self"
    ],
    "to": [
      "self",
      "device"
    ]
  },
  "lazy_init": [
    "init"
  ],
  "get_sequence_key": [
    "key",
    "mode"
  ],
  "phonemes_to_label": [
    "phns",
    "decoder"
  ],
  "remove_special": [
    "phn"
  ],
  "word_emb_pipeline": [
    "txt",
    "grapheme_encoded",
    "grapheme_encoded_len",
    "grapheme_encoder",
    "word_emb",
    "use_word_emb"
  ],
  "SubsequenceLoss": {
    "__init__": [
      "self",
      "seq_cost",
      "word_separator",
      "word_separator_base"
    ],
    "word_separator": [
      "self",
      "value"
    ],
    "word_separator_base": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "phns",
      "phn_lens",
      "p_seq",
      "subsequence_phn_start",
      "subsequence_phn_end",
      "phns_base",
      "phn_lens_base"
    ]
  },
  "SubsequenceExtractor": {
    "__init__": [
      "self",
      "word_separator",
      "word_separator_base"
    ],
    "__call__": [
      "self"
    ],
    "extract_seq": [
      "self",
      "phns",
      "phn_lens",
      "p_seq",
      "subsequence_phn_start",
      "subsequence_phn_end",
      "phns_base",
      "phn_base_lens"
    ],
    "_pad_subsequence": [
      "self",
      "sequence",
      "longest_subsequence"
    ],
    "_get_phns_subsequence": [
      "self",
      "phns",
      "target_word_indexes",
      "longest_subsequence",
      "edge"
    ],
    "_get_p_seq_subsequence": [
      "self",
      "p_seq",
      "target_word_indexes",
      "longest_subsequence",
      "edge"
    ],
    "_get_target_word_indexes": [
      "self",
      "phns",
      "range_phns",
      "start",
      "word_separator",
      "phn_lens"
    ],
    "_get_word_boundaries": [
      "self",
      "seq",
      "word_indexes",
      "edge",
      "word_separator"
    ],
    "_get_positions": [
      "self",
      "index_match",
      "words_range",
      "aggregation",
      "no_match_value"
    ],
    "extract_hyps": [
      "self",
      "ref_seq",
      "hyps",
      "subsequence_phn_start",
      "use_base"
    ],
    "_extract_hyp_word": [
      "self",
      "hyps",
      "separator_indexes",
      "word_index"
    ]
  },
  "AttentionSeq2Seq": {
    "__init__": [
      "self",
      "enc",
      "encoder_emb",
      "emb",
      "dec",
      "lin",
      "out",
      "bos_token",
      "use_word_emb",
      "word_emb_enc"
    ],
    "forward": [
      "self",
      "grapheme_encoded",
      "phn_encoded",
      "word_emb"
    ],
    "_apply_word_emb": [
      "self",
      "emb_char",
      "word_emb"
    ]
  },
  "WordEmbeddingEncoder": {
    "__init__": [
      "self",
      "word_emb_dim",
      "word_emb_enc_dim",
      "norm",
      "norm_type"
    ],
    "_get_norm": [
      "self",
      "norm",
      "dim"
    ],
    "forward": [
      "self",
      "emb"
    ],
    "NORMS": []
  },
  "TransformerG2P": {
    "__init__": [
      "self",
      "emb",
      "encoder_emb",
      "char_lin",
      "phn_lin",
      "lin",
      "out",
      "d_model",
      "nhead",
      "num_encoder_layers",
      "num_decoder_layers",
      "d_ffn",
      "dropout",
      "activation",
      "custom_src_module",
      "custom_tgt_module",
      "positional_encoding",
      "normalize_before",
      "kernel_size",
      "bias",
      "encoder_module",
      "attention_type",
      "max_length",
      "causal",
      "pad_idx",
      "encoder_kdim",
      "encoder_vdim",
      "decoder_kdim",
      "decoder_vdim",
      "use_word_emb",
      "word_emb_enc"
    ],
    "forward": [
      "self",
      "grapheme_encoded",
      "phn_encoded",
      "word_emb"
    ],
    "_reset_params": [
      "self"
    ],
    "make_masks": [
      "self",
      "src",
      "tgt",
      "src_len",
      "pad_idx"
    ],
    "decode": [
      "self",
      "tgt",
      "encoder_out",
      "enc_lens"
    ]
  },
  "input_dim": [
    "use_word_emb",
    "embedding_dim",
    "word_emb_enc_dim"
  ],
  "_apply_word_emb": [
    "word_emb_enc",
    "emb_char",
    "word_emb"
  ],
  "get_dummy_phonemes": [
    "batch_size",
    "device"
  ],
  "FlairEmbeddings": {
    "__init__": [
      "self",
      "embeddings"
    ],
    "from_hf": [
      "embeddings_class",
      "source",
      "save_path",
      "filename"
    ],
    "__call__": [
      "self",
      "inputs",
      "pad_tensor"
    ],
    "embed_word": [
      "self",
      "word"
    ]
  },
  "FlairSequenceTagger": {
    "__init__": [
      "self",
      "model"
    ],
    "from_hf": [
      "source",
      "save_path",
      "filename"
    ],
    "__call__": [
      "self",
      "inputs"
    ]
  },
  "SpeechTokenizer": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "sample_rate"
    ],
    "forward": [
      "self",
      "wav",
      "wav_lens"
    ],
    "encode": [
      "self",
      "wav",
      "wav_lens"
    ],
    "decode": [
      "self",
      "codes"
    ]
  },
  "SUPPORTED_VERSIONS": [],
  "__MODEL_LATEST_TAGS__": [],
  "__MODEL_URLS__": [],
  "WNConv1d": [],
  "WNConvTranspose1d": [],
  "init_weights": [
    "m"
  ],
  "download": [
    "model_type",
    "model_bitrate",
    "tag",
    "local_path"
  ],
  "snake": [
    "x",
    "alpha"
  ],
  "VectorQuantize": {
    "__init__": [
      "self",
      "input_dim",
      "codebook_size",
      "codebook_dim"
    ],
    "forward": [
      "self",
      "z"
    ],
    "embed_code": [
      "self",
      "embed_id"
    ],
    "decode_code": [
      "self",
      "embed_id"
    ],
    "decode_latents": [
      "self",
      "latents"
    ]
  },
  "ResidualVectorQuantize": {
    "__init__": [
      "self",
      "input_dim",
      "n_codebooks",
      "codebook_size",
      "codebook_dim",
      "quantizer_dropout"
    ],
    "forward": [
      "self",
      "z",
      "n_quantizers"
    ],
    "from_codes": [
      "self",
      "codes"
    ],
    "from_latents": [
      "self",
      "latents"
    ]
  },
  "Snake1d": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResidualUnit": {
    "__init__": [
      "self",
      "dim",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EncoderBlock": {
    "__init__": [
      "self",
      "dim",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DecoderBlock": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DAC": {
    "__init__": [
      "self",
      "encoder_dim",
      "encoder_rates",
      "latent_dim",
      "decoder_dim",
      "decoder_rates",
      "n_codebooks",
      "codebook_size",
      "codebook_dim",
      "quantizer_dropout",
      "sample_rate",
      "model_type",
      "model_bitrate",
      "tag",
      "load_path",
      "strict",
      "load_pretrained"
    ],
    "encode": [
      "self",
      "audio_data",
      "n_quantizers"
    ],
    "decode": [
      "self",
      "z"
    ],
    "forward": [
      "self",
      "audio_data",
      "sample_rate",
      "n_quantizers"
    ]
  },
  "WavTokenizer": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "config",
      "checkpoint",
      "sample_rate",
      "freeze"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "_compute_embedding": [
      "self"
    ],
    "encode": [
      "self",
      "inputs"
    ],
    "decode": [
      "self",
      "tokens"
    ]
  },
  "SAMPLE_RATE": [],
  "N_FFT": [],
  "HOP_LENGTH": [],
  "CHUNK_LENGTH": [],
  "N_SAMPLES": [],
  "Whisper": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "sampling_rate",
      "encoder_only",
      "freeze",
      "freeze_encoder",
      "output_attentions",
      "output_all_hiddens",
      "language",
      "task"
    ],
    "freeze_model": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "wav",
      "decoder_input_ids"
    ],
    "_get_mel": [
      "self",
      "wav"
    ],
    "log_mel_spectrogram": [
      "self",
      "audio",
      "padding"
    ],
    "pad_or_trim": [
      "self",
      "array",
      "length",
      "axis"
    ],
    "forward_encoder": [
      "self",
      "mel"
    ],
    "forward_decoder": [
      "self",
      "encoder_states",
      "decoder_input_ids",
      "use_cache",
      "past_key_values"
    ],
    "all_language_tokens": [
      "self"
    ],
    "all_language_codes": [
      "self"
    ],
    "non_speech_tokens": [
      "self"
    ],
    "transcribe": [
      "self"
    ],
    "translate": [
      "self"
    ],
    "bos": [
      "self"
    ],
    "eos": [
      "self"
    ],
    "bos_lm": [
      "self"
    ],
    "bos_prev": [
      "self"
    ],
    "no_timestamps": [
      "self"
    ],
    "timestamp_begin": [
      "self"
    ],
    "no_speech": [
      "self"
    ],
    "language_token": [
      "self"
    ],
    "to_language_token": [
      "self",
      "language"
    ],
    "set_language_token": [
      "self",
      "language"
    ],
    "set_task": [
      "self",
      "task"
    ],
    "is_multilingual": [
      "self"
    ],
    "get_suppress_tokens": [
      "self"
    ],
    "detect_language": [
      "self",
      "mel"
    ]
  },
  "MERT": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "output_norm",
      "freeze",
      "freeze_feature_extractor",
      "apply_spec_augment",
      "output_all_hiddens"
    ]
  },
  "DEFAULT_SAMPLE_RATE": [],
  "BANDWIDTHS": [],
  "Vocos": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "revision",
      "bandwidth",
      "freeze"
    ],
    "_load_model": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "length"
    ]
  },
  "Encodec": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "sample_rate",
      "bandwidth",
      "flat_embeddings",
      "freeze",
      "renorm_embeddings"
    ],
    "_precalibrate": [
      "self"
    ],
    "_compute_embedding_norm": [
      "self",
      "sample",
      "length"
    ],
    "calibrate": [
      "self",
      "sample",
      "length"
    ],
    "forward": [
      "self",
      "inputs",
      "length"
    ],
    "encode": [
      "self",
      "inputs",
      "length"
    ],
    "_encode_tokens": [
      "self",
      "inputs",
      "length"
    ],
    "_raw_embeddings": [
      "self",
      "tokens"
    ],
    "embeddings": [
      "self",
      "tokens"
    ],
    "decode": [
      "self",
      "tokens",
      "length"
    ],
    "tokens": [
      "self",
      "emb",
      "length"
    ],
    "decode_emb": [
      "self",
      "emb",
      "length"
    ]
  },
  "Wav2Vec2": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "output_norm",
      "freeze",
      "freeze_feature_extractor",
      "apply_spec_augment",
      "output_all_hiddens"
    ],
    "_modify_state_dict": [
      "self",
      "path",
      "replaceables"
    ],
    "forward": [
      "self",
      "wav",
      "wav_lens"
    ],
    "extract_features": [
      "self",
      "wav",
      "wav_lens"
    ]
  },
  "Wav2Vec2Pretrain": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "mask_prob",
      "mask_length",
      "normalize_wav"
    ],
    "forward": [
      "self",
      "wav",
      "wav_lens"
    ],
    "override_config": [
      "self",
      "config"
    ]
  },
  "LaBSE": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "freeze",
      "output_norm"
    ],
    "forward": [
      "self",
      "input_texts"
    ]
  },
  "Mimi": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "sample_rate",
      "freeze",
      "num_codebooks"
    ],
    "_compute_embedding": [
      "self"
    ],
    "forward": [
      "self",
      "inputs",
      "length"
    ],
    "encode": [
      "self",
      "inputs",
      "length"
    ],
    "decode": [
      "self",
      "tokens",
      "length"
    ]
  },
  "GPT": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "freeze",
      "max_new_tokens",
      "min_length",
      "top_k",
      "top_p",
      "num_beams",
      "eos_token_id",
      "early_stopping"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ],
    "generate": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "decoder_type"
    ]
  },
  "WavLM": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "output_norm",
      "freeze",
      "freeze_feature_extractor",
      "apply_spec_augment",
      "output_all_hiddens"
    ]
  },
  "NLLB": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "freeze",
      "target_lang",
      "decoder_only",
      "share_input_output_embed"
    ]
  },
  "HuBERT": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "output_norm",
      "freeze",
      "freeze_feature_extractor",
      "apply_spec_augment",
      "output_all_hiddens"
    ]
  },
  "mBART": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "freeze",
      "target_lang",
      "decoder_only",
      "share_input_output_embed"
    ],
    "forward": [
      "self",
      "src",
      "tgt",
      "pad_idx"
    ],
    "decode": [
      "self",
      "tgt",
      "encoder_out",
      "enc_len"
    ],
    "custom_padding": [
      "self",
      "x",
      "org_pad",
      "custom_pad"
    ],
    "override_config": [
      "self",
      "config"
    ]
  },
  "LLAMA2": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "freeze",
      "max_new_tokens",
      "use_4bit",
      "bnb_4bit_compute_dtype",
      "bnb_4bit_quant_type",
      "use_nested_quant",
      "min_length",
      "top_k",
      "top_p",
      "num_beams",
      "early_stopping",
      "with_peft"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ],
    "_modify_state_dict": [
      "self",
      "path",
      "replaceables"
    ],
    "replace_linear": [
      "self",
      "module"
    ],
    "generate": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_type"
    ],
    "override_config": [
      "self",
      "config"
    ],
    "print_trainable_parameters": [
      "self",
      "model"
    ]
  },
  "WeightedSSLModel": {
    "__init__": [
      "self",
      "hub",
      "save_path",
      "layernorm",
      "freeze"
    ],
    "forward": [
      "self",
      "wav",
      "wav_lens"
    ],
    "override_config": [
      "self",
      "config"
    ]
  },
  "TextEncoder": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "freeze",
      "num_layers"
    ],
    "truncate": [
      "self",
      "keep_layers"
    ],
    "forward": [
      "self",
      "input_texts",
      "return_tokens"
    ]
  },
  "HFTransformersInterface": {
    "__init__": [
      "self",
      "source",
      "save_path",
      "for_pretraining",
      "with_lm_head",
      "with_casual_lm",
      "seq2seqlm",
      "quantization_config",
      "freeze",
      "cache_dir",
      "device"
    ],
    "_from_pretrained": [
      "self",
      "source",
      "save_path",
      "cache_dir",
      "device"
    ],
    "_check_model_source": [
      "self",
      "path",
      "save_path"
    ],
    "_modify_state_dict": [
      "self",
      "path"
    ],
    "_load_sb_pretrained_parameters": [
      "self",
      "path"
    ],
    "forward": [
      "self"
    ],
    "forward_encoder": [
      "self"
    ],
    "forward_decoder": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "encode": [
      "self"
    ],
    "freeze_model": [
      "self",
      "model"
    ],
    "override_config": [
      "self",
      "config"
    ],
    "load_feature_extractor": [
      "self",
      "source",
      "cache_dir"
    ],
    "load_tokenizer": [
      "self",
      "source"
    ]
  },
  "make_padding_masks": [
    "src",
    "wav_len",
    "pad_idx"
  ],
  "DiscreteSSL": {
    "__init__": [
      "self",
      "save_path",
      "ssl_model",
      "kmeans_dataset",
      "vocoder_repo_id",
      "num_clusters",
      "layers_num",
      "device",
      "sample_rate"
    ],
    "check_if_input_is_compatible": [
      "self",
      "layers_num",
      "num_clusters"
    ],
    "load_kmeans": [
      "self",
      "repo_id",
      "kmeans_dataset",
      "encoder_name",
      "num_clusters",
      "cache_dir",
      "layers_num"
    ],
    "forward": [
      "self",
      "wav",
      "wav_lens",
      "SSL_layers",
      "deduplicates",
      "bpe_tokenizers"
    ],
    "encode": [
      "self",
      "wav",
      "wav_lens",
      "SSL_layers",
      "deduplicates",
      "bpe_tokenizers"
    ],
    "decode": [
      "self",
      "tokens",
      "SSL_layers"
    ]
  },
  "TransformerLM": {
    "__init__": [
      "self",
      "vocab",
      "d_model",
      "nhead",
      "num_encoder_layers",
      "num_decoder_layers",
      "d_ffn",
      "dropout",
      "activation",
      "positional_encoding",
      "normalize_before",
      "d_embedding",
      "max_length",
      "causal",
      "attention_type",
      "decoder_use_memory"
    ],
    "forward": [
      "self",
      "src"
    ],
    "_reset_params": [
      "self"
    ],
    "make_masks": [
      "self",
      "src",
      "pad_idx",
      "look_ahead_mask",
      "padding_mask"
    ]
  },
  "ConformerEncoderLayerStreamingContext": {},
  "ConformerEncoderStreamingContext": {},
  "ConvolutionModule": {
    "__init__": [
      "self",
      "input_size",
      "kernel_size",
      "bias",
      "activation",
      "dropout",
      "causal",
      "dilation"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "dynchunktrain_config"
    ]
  },
  "ConformerEncoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "d_ffn",
      "nhead",
      "kernel_size",
      "kdim",
      "vdim",
      "activation",
      "bias",
      "dropout",
      "causal",
      "attention_type"
    ],
    "forward": [
      "self",
      "x",
      "src_mask",
      "src_key_padding_mask",
      "pos_embs",
      "dynchunktrain_config"
    ],
    "forward_streaming": [
      "self",
      "x",
      "context",
      "pos_embs"
    ],
    "make_streaming_context": [
      "self",
      "mha_left_context_size"
    ]
  },
  "ConformerEncoder": {
    "__init__": [
      "self",
      "num_layers",
      "d_model",
      "d_ffn",
      "nhead",
      "kernel_size",
      "kdim",
      "vdim",
      "activation",
      "bias",
      "dropout",
      "causal",
      "attention_type",
      "output_hidden_states",
      "layerdrop_prob"
    ],
    "forward": [
      "self",
      "src",
      "src_mask",
      "src_key_padding_mask",
      "pos_embs",
      "dynchunktrain_config"
    ],
    "forward_streaming": [
      "self",
      "src",
      "context",
      "pos_embs"
    ],
    "make_streaming_context": [
      "self",
      "dynchunktrain_config"
    ]
  },
  "ConformerDecoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "d_ffn",
      "nhead",
      "kernel_size",
      "kdim",
      "vdim",
      "activation",
      "bias",
      "dropout",
      "causal",
      "attention_type"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "tgt_key_padding_mask",
      "memory_key_padding_mask",
      "pos_embs_tgt",
      "pos_embs_src"
    ]
  },
  "ConformerDecoder": {
    "__init__": [
      "self",
      "num_layers",
      "nhead",
      "d_ffn",
      "d_model",
      "kdim",
      "vdim",
      "dropout",
      "activation",
      "kernel_size",
      "bias",
      "causal",
      "attention_type"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "tgt_key_padding_mask",
      "memory_key_padding_mask",
      "pos_embs_tgt",
      "pos_embs_src"
    ]
  },
  "TransformerST": {
    "__init__": [
      "self",
      "tgt_vocab",
      "input_size",
      "d_model",
      "nhead",
      "num_encoder_layers",
      "num_decoder_layers",
      "d_ffn",
      "dropout",
      "activation",
      "positional_encoding",
      "normalize_before",
      "kernel_size",
      "bias",
      "encoder_module",
      "conformer_activation",
      "attention_type",
      "max_length",
      "causal",
      "ctc_weight",
      "asr_weight",
      "mt_weight",
      "asr_tgt_vocab",
      "mt_src_vocab"
    ],
    "forward_asr": [
      "self",
      "encoder_out",
      "src",
      "tgt",
      "wav_len",
      "pad_idx"
    ],
    "forward_mt": [
      "self",
      "src",
      "tgt",
      "pad_idx"
    ],
    "forward_mt_decoder_only": [
      "self",
      "src",
      "tgt",
      "pad_idx"
    ],
    "decode_asr": [
      "self",
      "tgt",
      "encoder_out"
    ],
    "make_masks_for_mt": [
      "self",
      "src",
      "tgt",
      "pad_idx"
    ]
  },
  "TransformerInterface": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "num_encoder_layers",
      "num_decoder_layers",
      "d_ffn",
      "dropout",
      "activation",
      "custom_src_module",
      "custom_tgt_module",
      "positional_encoding",
      "normalize_before",
      "kernel_size",
      "bias",
      "encoder_module",
      "conformer_activation",
      "branchformer_activation",
      "attention_type",
      "max_length",
      "causal",
      "encoder_kdim",
      "encoder_vdim",
      "decoder_kdim",
      "decoder_vdim",
      "csgu_linear_units",
      "gate_activation",
      "use_linear_after_conv",
      "output_hidden_states",
      "layerdrop_prob"
    ],
    "forward": [
      "self"
    ]
  },
  "PositionalEncoding": {
    "__init__": [
      "self",
      "input_size",
      "max_len"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TransformerEncoderLayer": {
    "__init__": [
      "self",
      "d_ffn",
      "nhead",
      "d_model",
      "kdim",
      "vdim",
      "dropout",
      "activation",
      "normalize_before",
      "attention_type",
      "ffn_type",
      "ffn_cnn_kernel_size_list",
      "causal"
    ],
    "forward": [
      "self",
      "src",
      "src_mask",
      "src_key_padding_mask",
      "pos_embs"
    ]
  },
  "TransformerDecoderLayer": {
    "__init__": [
      "self",
      "d_ffn",
      "nhead",
      "d_model",
      "kdim",
      "vdim",
      "dropout",
      "activation",
      "normalize_before",
      "attention_type",
      "causal"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "tgt_key_padding_mask",
      "memory_key_padding_mask",
      "pos_embs_tgt",
      "pos_embs_src"
    ],
    "_load_from_state_dict": [
      "self",
      "state_dict",
      "prefix"
    ]
  },
  "TransformerDecoder": {
    "__init__": [
      "self",
      "num_layers",
      "nhead",
      "d_ffn",
      "d_model",
      "kdim",
      "vdim",
      "dropout",
      "activation",
      "normalize_before",
      "causal",
      "attention_type"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "tgt_key_padding_mask",
      "memory_key_padding_mask",
      "pos_embs_tgt",
      "pos_embs_src"
    ]
  },
  "NormalizedEmbedding": {
    "__init__": [
      "self",
      "d_model",
      "vocab"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_key_padding_mask": [
    "padded_input",
    "pad_idx"
  ],
  "get_lookahead_mask": [
    "padded_input"
  ],
  "get_mask_from_lengths": [
    "lengths",
    "max_len"
  ],
  "TransformerASRStreamingContext": {},
  "make_transformer_src_mask": [
    "src",
    "causal",
    "dynchunktrain_config"
  ],
  "make_transformer_src_tgt_masks": [
    "src",
    "tgt",
    "wav_len",
    "pad_idx",
    "causal",
    "dynchunktrain_config"
  ],
  "TransformerASR": {
    "__init__": [
      "self",
      "tgt_vocab",
      "input_size",
      "d_model",
      "nhead",
      "num_encoder_layers",
      "num_decoder_layers",
      "d_ffn",
      "dropout",
      "activation",
      "positional_encoding",
      "normalize_before",
      "kernel_size",
      "bias",
      "encoder_module",
      "conformer_activation",
      "branchformer_activation",
      "attention_type",
      "max_length",
      "causal",
      "csgu_linear_units",
      "gate_activation",
      "use_linear_after_conv",
      "output_hidden_states",
      "layerdrop_prob"
    ],
    "forward": [
      "self",
      "src",
      "tgt",
      "wav_len",
      "pad_idx"
    ],
    "decode": [
      "self",
      "tgt",
      "encoder_out",
      "enc_len"
    ],
    "encode": [
      "self",
      "src",
      "wav_len",
      "pad_idx",
      "dynchunktrain_config"
    ],
    "encode_streaming": [
      "self",
      "src",
      "context"
    ],
    "make_streaming_context": [
      "self",
      "dynchunktrain_config",
      "encoder_kwargs"
    ],
    "_init_params": [
      "self"
    ]
  },
  "ConvolutionBranch": {
    "__init__": [
      "self",
      "input_size",
      "linear_units",
      "kernel_size",
      "activation",
      "gate_activation",
      "dropout",
      "use_linear_after_conv"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BranchformerEncoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "kernel_size",
      "kdim",
      "vdim",
      "activation",
      "dropout",
      "attention_type",
      "csgu_linear_units",
      "gate_activation",
      "use_linear_after_conv"
    ],
    "forward": [
      "self",
      "x",
      "src_mask",
      "src_key_padding_mask",
      "pos_embs"
    ]
  },
  "BranchformerEncoder": {
    "__init__": [
      "self",
      "num_layers",
      "d_model",
      "nhead",
      "kernel_size",
      "kdim",
      "vdim",
      "activation",
      "dropout",
      "attention_type",
      "csgu_linear_units",
      "gate_activation",
      "use_linear_after_conv",
      "output_hidden_states",
      "layerdrop_prob"
    ],
    "forward": [
      "self",
      "src",
      "src_mask",
      "src_key_padding_mask",
      "pos_embs",
      "dynchunktrain_config"
    ]
  },
  "CNNTransformerSE": {
    "__init__": [
      "self",
      "d_model",
      "output_size",
      "output_activation",
      "nhead",
      "num_layers",
      "d_ffn",
      "dropout",
      "activation",
      "causal",
      "custom_emb_module",
      "normalize_before"
    ],
    "forward": [
      "self",
      "x",
      "src_key_padding_mask"
    ]
  },
  "_as_sentence": [
    "sentence"
  ],
  "_extract_lemmas": [
    "docs"
  ],
  "SpacyPipeline": {
    "__init__": [
      "self",
      "nlp"
    ],
    "from_name": [
      "name"
    ],
    "__call__": [
      "self",
      "inputs"
    ],
    "lemmatize": [
      "self",
      "inputs"
    ]
  },
  "MHA_WARNING": [],
  "AdaptedModel": {
    "__init__": [
      "self",
      "model_to_adapt",
      "adapter_class",
      "all_linear",
      "all_conv",
      "target_layers",
      "unfrozen_layers",
      "adapter_kwargs",
      "manual_adapter_insertion"
    ],
    "insert_adapters": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "saver": [
      "self",
      "path"
    ],
    "loader": [
      "self",
      "path",
      "end_of_epoch"
    ],
    "parameter_transfer": [
      "self",
      "path"
    ],
    "__getattr__": [
      "self",
      "item"
    ]
  },
  "is_layer_adaptable": [
    "name",
    "module",
    "all_linear",
    "all_conv",
    "target_layers"
  ],
  "replace_module": [
    "model",
    "name",
    "new_module"
  ],
  "HoulsbyAdapterLinear": {
    "__init__": [
      "self",
      "target_linear",
      "projection_size",
      "activation",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LoRA": {
    "__init__": [
      "self",
      "target_module",
      "rank",
      "alpha"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "transducer_loss": [
    "logits",
    "targets",
    "input_lens",
    "target_lens",
    "blank_index",
    "reduction",
    "use_torchaudio"
  ],
  "PitWrapper": {
    "__init__": [
      "self",
      "base_loss"
    ],
    "_fast_pit": [
      "self",
      "loss_mat"
    ],
    "_opt_perm_loss": [
      "self",
      "pred",
      "target"
    ],
    "reorder_tensor": [
      "self",
      "tensor",
      "p"
    ],
    "forward": [
      "self",
      "preds",
      "targets"
    ]
  },
  "ctc_loss": [
    "log_probs",
    "targets",
    "input_lens",
    "target_lens",
    "blank_index",
    "reduction"
  ],
  "l1_loss": [
    "predictions",
    "targets",
    "length",
    "allowed_len_diff",
    "reduction"
  ],
  "mse_loss": [
    "predictions",
    "targets",
    "length",
    "allowed_len_diff",
    "reduction"
  ],
  "classification_error": [
    "probabilities",
    "targets",
    "length",
    "allowed_len_diff",
    "reduction"
  ],
  "nll_loss": [
    "log_probabilities",
    "targets",
    "length",
    "label_smoothing",
    "allowed_len_diff",
    "weight",
    "reduction"
  ],
  "bce_loss": [
    "inputs",
    "targets",
    "length",
    "weight",
    "pos_weight",
    "reduction",
    "allowed_len_diff",
    "label_smoothing"
  ],
  "kldiv_loss": [
    "log_probabilities",
    "targets",
    "length",
    "label_smoothing",
    "allowed_len_diff",
    "pad_idx",
    "reduction"
  ],
  "distance_diff_loss": [
    "predictions",
    "targets",
    "length",
    "beta",
    "max_weight",
    "reduction"
  ],
  "_distance_diff_loss": [
    "predictions",
    "targets",
    "beta",
    "max_weight"
  ],
  "truncate": [
    "predictions",
    "targets",
    "allowed_len_diff"
  ],
  "compute_masked_loss": [
    "loss_fn",
    "predictions",
    "targets",
    "length",
    "label_smoothing",
    "mask_shape",
    "reduction"
  ],
  "compute_length_mask": [
    "data",
    "length",
    "len_dim"
  ],
  "reduce_loss": [
    "loss",
    "mask",
    "reduction",
    "label_smoothing",
    "predictions",
    "targets"
  ],
  "get_si_snr_with_pitwrapper": [
    "source",
    "estimate_source"
  ],
  "get_snr_with_pitwrapper": [
    "source",
    "estimate_source"
  ],
  "cal_si_snr": [
    "source",
    "estimate_source"
  ],
  "cal_snr": [
    "source",
    "estimate_source"
  ],
  "get_mask": [
    "source",
    "source_lengths"
  ],
  "AngularMargin": {
    "__init__": [
      "self",
      "margin",
      "scale"
    ],
    "forward": [
      "self",
      "outputs",
      "targets"
    ]
  },
  "AdditiveAngularMargin": {
    "__init__": [
      "self",
      "margin",
      "scale",
      "easy_margin"
    ],
    "forward": [
      "self",
      "outputs",
      "targets"
    ]
  },
  "LogSoftmaxWrapper": {
    "__init__": [
      "self",
      "loss_fn"
    ],
    "forward": [
      "self",
      "outputs",
      "targets",
      "length"
    ]
  },
  "ctc_loss_kd": [
    "log_probs",
    "targets",
    "input_lens",
    "blank_index",
    "device"
  ],
  "ce_kd": [
    "inp",
    "target"
  ],
  "nll_loss_kd": [
    "probabilities",
    "targets",
    "rel_lab_lengths"
  ],
  "ContrastiveLoss": {
    "__init__": [
      "self",
      "logit_temp"
    ],
    "forward": [
      "self",
      "x",
      "y",
      "negs"
    ]
  },
  "VariationalAutoencoderLoss": {
    "__init__": [
      "self",
      "rec_loss",
      "len_dim",
      "dist_loss_weight"
    ],
    "forward": [
      "self",
      "predictions",
      "targets",
      "length",
      "reduction"
    ],
    "details": [
      "self",
      "predictions",
      "targets",
      "length",
      "reduction"
    ],
    "_compute_components": [
      "self",
      "predictions",
      "targets"
    ],
    "_align_length_axis": [
      "self",
      "tensor"
    ]
  },
  "AutoencoderLoss": {
    "__init__": [
      "self",
      "rec_loss",
      "len_dim"
    ],
    "forward": [
      "self",
      "predictions",
      "targets",
      "length",
      "reduction"
    ],
    "details": [
      "self",
      "predictions",
      "targets",
      "length",
      "reduction"
    ],
    "_align_length_axis": [
      "self",
      "tensor"
    ]
  },
  "_reduce_autoencoder_loss": [
    "loss",
    "length",
    "reduction"
  ],
  "VariationalAutoencoderLossDetails": [],
  "AutoencoderLossDetails": [],
  "Laplacian": {
    "__init__": [
      "self",
      "kernel_size",
      "dtype"
    ],
    "get_kernel": [
      "self"
    ],
    "forward": [
      "self",
      "data"
    ]
  },
  "LaplacianVarianceLoss": {
    "__init__": [
      "self",
      "kernel_size",
      "len_dim"
    ],
    "forward": [
      "self",
      "predictions",
      "length",
      "reduction"
    ]
  },
  "Autoencoder": {
    "encode": [
      "self",
      "x",
      "length"
    ],
    "decode": [
      "self",
      "latent"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "VariationalAutoencoder": {
    "__init__": [
      "self",
      "encoder",
      "decoder",
      "mean",
      "log_var",
      "len_dim",
      "latent_padding",
      "mask_latent",
      "mask_out",
      "out_mask_value",
      "latent_mask_value",
      "latent_stochastic"
    ],
    "encode": [
      "self",
      "x",
      "length"
    ],
    "decode": [
      "self",
      "latent"
    ],
    "reparameterize": [
      "self",
      "mean",
      "log_var"
    ],
    "train_sample": [
      "self",
      "x",
      "length",
      "out_mask_value",
      "latent_mask_value"
    ]
  },
  "VariationalAutoencoderOutput": [],
  "AutoencoderOutput": [],
  "NormalizingAutoencoder": {
    "__init__": [
      "self",
      "encoder",
      "decoder",
      "latent_padding",
      "norm",
      "len_dim",
      "mask_out",
      "mask_latent",
      "out_mask_value",
      "latent_mask_value"
    ],
    "encode": [
      "self",
      "x",
      "length"
    ],
    "decode": [
      "self",
      "latent"
    ],
    "train_sample": [
      "self",
      "x",
      "length",
      "out_mask_value",
      "latent_mask_value"
    ]
  },
  "Softmax": {
    "__init__": [
      "self",
      "apply_log",
      "dim",
      "reshape",
      "dtype"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GumbelSoftmax": {
    "__init__": [
      "self",
      "tau",
      "hard",
      "apply_log"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Embedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "consider_as_one_hot",
      "blank_id"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DoneDetector": {
    "__init__": [
      "self",
      "model",
      "out"
    ],
    "forward": [
      "self",
      "feats",
      "length"
    ]
  },
  "SincConv": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "input_shape",
      "in_channels",
      "stride",
      "dilation",
      "padding",
      "padding_mode",
      "sample_rate",
      "min_low_hz",
      "min_band_hz"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_check_input_shape": [
      "self",
      "shape"
    ],
    "_get_sinc_filters": [
      "self"
    ],
    "_init_sinc_conv": [
      "self"
    ],
    "_to_mel": [
      "self",
      "hz"
    ],
    "_to_hz": [
      "self",
      "mel"
    ],
    "_manage_padding": [
      "self",
      "x",
      "kernel_size",
      "dilation",
      "stride"
    ]
  },
  "Conv2d": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "input_shape",
      "in_channels",
      "stride",
      "dilation",
      "padding",
      "groups",
      "bias",
      "padding_mode",
      "max_norm",
      "swap",
      "skip_transpose",
      "weight_norm",
      "conv_init"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_manage_padding": [
      "self",
      "x",
      "kernel_size",
      "dilation",
      "stride"
    ],
    "_check_input": [
      "self",
      "shape"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "ConvTranspose1d": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "input_shape",
      "in_channels",
      "stride",
      "dilation",
      "padding",
      "output_padding",
      "groups",
      "bias",
      "skip_transpose",
      "weight_norm"
    ],
    "forward": [
      "self",
      "x",
      "output_size"
    ],
    "_check_input_shape": [
      "self",
      "shape"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "DepthwiseSeparableConv1d": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "input_shape",
      "stride",
      "dilation",
      "padding",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DepthwiseSeparableConv2d": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "input_shape",
      "stride",
      "dilation",
      "padding",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GaborConv1d": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "stride",
      "input_shape",
      "in_channels",
      "padding",
      "padding_mode",
      "sample_rate",
      "min_freq",
      "max_freq",
      "n_fft",
      "normalize_energy",
      "bias",
      "sort_filters",
      "use_legacy_complex",
      "skip_transpose"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_gabor_constraint": [
      "self",
      "kernel_data"
    ],
    "_gabor_filters": [
      "self",
      "kernel"
    ],
    "_manage_padding": [
      "self",
      "x",
      "kernel_size"
    ],
    "_mel_filters": [
      "self"
    ],
    "_gabor_params_from_mels": [
      "self"
    ],
    "_initialize_kernel": [
      "self"
    ],
    "_check_input_shape": [
      "self",
      "shape"
    ]
  },
  "get_padding_elem": [
    "L_in",
    "stride",
    "kernel_size",
    "dilation"
  ],
  "get_padding_elem_transposed": [
    "L_out",
    "L_in",
    "stride",
    "kernel_size",
    "dilation",
    "output_padding"
  ],
  "BatchNorm2d": {
    "__init__": [
      "self",
      "input_shape",
      "input_size",
      "eps",
      "momentum",
      "affine",
      "track_running_stats"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LayerNorm": {
    "__init__": [
      "self",
      "input_size",
      "input_shape",
      "eps",
      "elementwise_affine"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InstanceNorm1d": {
    "__init__": [
      "self",
      "input_shape",
      "input_size",
      "eps",
      "momentum",
      "track_running_stats",
      "affine"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InstanceNorm2d": {
    "__init__": [
      "self",
      "input_shape",
      "input_size",
      "eps",
      "momentum",
      "track_running_stats",
      "affine"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GroupNorm": {
    "__init__": [
      "self",
      "input_shape",
      "input_size",
      "num_groups",
      "eps",
      "affine"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ExponentialMovingAverage": {
    "__init__": [
      "self",
      "input_size",
      "coeff_init",
      "per_channel",
      "trainable",
      "skip_transpose"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PCEN": {
    "__init__": [
      "self",
      "input_size",
      "alpha",
      "smooth_coef",
      "delta",
      "root",
      "floor",
      "trainable",
      "per_channel_smooth_coef",
      "skip_transpose"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "fixup": [
    "module",
    "use_fixup_init"
  ],
  "conv_nd": [
    "dims"
  ],
  "avg_pool_nd": [
    "dims"
  ],
  "timestep_embedding": [
    "timesteps",
    "dim",
    "max_period"
  ],
  "AttentionPool2d": {
    "__init__": [
      "self",
      "spatial_dim",
      "embed_dim",
      "num_heads_channels",
      "output_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TimestepBlock": {
    "forward": [
      "self",
      "x",
      "emb"
    ]
  },
  "TimestepEmbedSequential": {
    "forward": [
      "self",
      "x",
      "emb"
    ]
  },
  "Upsample": {
    "__init__": [
      "self",
      "channels",
      "use_conv",
      "dims",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Downsample": {
    "__init__": [
      "self",
      "channels",
      "use_conv",
      "dims",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResBlock": {
    "__init__": [
      "self",
      "channels",
      "emb_channels",
      "dropout",
      "out_channels",
      "use_conv",
      "dims",
      "up",
      "down",
      "norm_num_groups",
      "use_fixup_init"
    ],
    "forward": [
      "self",
      "x",
      "emb"
    ]
  },
  "AttentionBlock": {
    "__init__": [
      "self",
      "channels",
      "num_heads",
      "num_head_channels",
      "norm_num_groups",
      "use_fixup_init"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QKVAttention": {
    "__init__": [
      "self",
      "n_heads"
    ],
    "forward": [
      "self",
      "qkv"
    ]
  },
  "build_emb_proj": [
    "emb_config",
    "proj_dim",
    "use_emb"
  ],
  "UNetModel": {
    "__init__": [
      "self",
      "in_channels",
      "model_channels",
      "out_channels",
      "num_res_blocks",
      "attention_resolutions",
      "dropout",
      "channel_mult",
      "conv_resample",
      "dims",
      "emb_dim",
      "cond_emb",
      "use_cond_emb",
      "num_heads",
      "num_head_channels",
      "num_heads_upsample",
      "norm_num_groups",
      "resblock_updown",
      "use_fixup_init"
    ],
    "forward": [
      "self",
      "x",
      "timesteps",
      "cond_emb"
    ],
    "diffusion_forward": [
      "self",
      "x",
      "timesteps",
      "cond_emb",
      "length",
      "out_mask_value",
      "latent_mask_value"
    ]
  },
  "EncoderUNetModel": {
    "__init__": [
      "self",
      "in_channels",
      "model_channels",
      "out_channels",
      "num_res_blocks",
      "attention_resolutions",
      "dropout",
      "channel_mult",
      "conv_resample",
      "dims",
      "num_heads",
      "num_head_channels",
      "num_heads_upsample",
      "norm_num_groups",
      "resblock_updown",
      "pool",
      "attention_pool_dim",
      "out_kernel_size",
      "use_fixup_init"
    ],
    "forward": [
      "self",
      "x",
      "timesteps"
    ]
  },
  "EmbeddingProjection": {
    "__init__": [
      "self",
      "emb_dim",
      "proj_dim"
    ],
    "forward": [
      "self",
      "emb"
    ]
  },
  "DecoderUNetModel": {
    "__init__": [
      "self",
      "in_channels",
      "model_channels",
      "out_channels",
      "num_res_blocks",
      "attention_resolutions",
      "dropout",
      "channel_mult",
      "conv_resample",
      "dims",
      "num_heads",
      "num_head_channels",
      "num_heads_upsample",
      "resblock_updown",
      "norm_num_groups",
      "out_kernel_size",
      "use_fixup_init"
    ],
    "forward": [
      "self",
      "x",
      "timesteps"
    ]
  },
  "DEFAULT_PADDING_DIMS": [],
  "DownsamplingPadding": {
    "__init__": [
      "self",
      "factor",
      "len_dim",
      "dims"
    ],
    "forward": [
      "self",
      "x",
      "length"
    ]
  },
  "UNetNormalizingAutoencoder": {
    "__init__": [
      "self",
      "in_channels",
      "model_channels",
      "encoder_out_channels",
      "latent_channels",
      "encoder_num_res_blocks",
      "encoder_attention_resolutions",
      "decoder_num_res_blocks",
      "decoder_attention_resolutions",
      "dropout",
      "channel_mult",
      "dims",
      "num_heads",
      "num_head_channels",
      "num_heads_upsample",
      "norm_num_groups",
      "resblock_updown",
      "out_kernel_size",
      "len_dim",
      "out_mask_value",
      "latent_mask_value",
      "use_fixup_norm",
      "downsampling_padding"
    ]
  },
  "Dropout2d": {
    "__init__": [
      "self",
      "drop_rate",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Pooling1d": {
    "__init__": [
      "self",
      "pool_type",
      "kernel_size",
      "input_dims",
      "pool_axis",
      "ceil_mode",
      "padding",
      "dilation",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Pooling2d": {
    "__init__": [
      "self",
      "pool_type",
      "kernel_size",
      "pool_axis",
      "ceil_mode",
      "padding",
      "dilation",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StatisticsPooling": {
    "__init__": [
      "self",
      "return_mean",
      "return_std"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ],
    "_get_gauss_noise": [
      "self",
      "shape_of_tensor",
      "device"
    ]
  },
  "AdaptivePool": {
    "__init__": [
      "self",
      "output_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GaussianLowpassPooling": {
    "__init__": [
      "self",
      "in_channels",
      "kernel_size",
      "stride",
      "initialization_constant",
      "padding",
      "padding_mode",
      "bias",
      "skip_transpose"
    ],
    "_get_impulse_responses": [
      "self",
      "sigma"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_manage_padding": [
      "self",
      "x",
      "kernel_size"
    ]
  },
  "AttentionPooling": {
    "__init__": [
      "self",
      "input_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "pack_padded_sequence": [
    "inputs",
    "lengths"
  ],
  "pad_packed_sequence": [
    "inputs"
  ],
  "RNN": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "input_size",
      "nonlinearity",
      "num_layers",
      "bias",
      "dropout",
      "re_init",
      "bidirectional"
    ],
    "forward": [
      "self",
      "x",
      "hx",
      "lengths"
    ]
  },
  "LSTM": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "input_size",
      "num_layers",
      "bias",
      "dropout",
      "re_init",
      "bidirectional"
    ],
    "forward": [
      "self",
      "x",
      "hx",
      "lengths"
    ]
  },
  "GRU": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "input_size",
      "num_layers",
      "bias",
      "dropout",
      "re_init",
      "bidirectional"
    ],
    "forward": [
      "self",
      "x",
      "hx",
      "lengths"
    ]
  },
  "RNNCell": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "input_size",
      "num_layers",
      "bias",
      "dropout",
      "re_init",
      "nonlinearity"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ]
  },
  "GRUCell": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "input_size",
      "num_layers",
      "bias",
      "dropout",
      "re_init"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ]
  },
  "LSTMCell": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "input_size",
      "num_layers",
      "bias",
      "dropout",
      "re_init"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ]
  },
  "AttentionalRNNDecoder": {
    "__init__": [
      "self",
      "rnn_type",
      "attn_type",
      "hidden_size",
      "attn_dim",
      "num_layers",
      "enc_dim",
      "input_size",
      "nonlinearity",
      "re_init",
      "normalization",
      "scaling",
      "channels",
      "kernel_size",
      "bias",
      "dropout"
    ],
    "forward_step": [
      "self",
      "inp",
      "hs",
      "c",
      "enc_states",
      "enc_len"
    ],
    "forward": [
      "self",
      "inp_tensor",
      "enc_states",
      "wav_len"
    ]
  },
  "LiGRU": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "nonlinearity",
      "normalization",
      "num_layers",
      "bias",
      "dropout",
      "re_init",
      "bidirectional"
    ],
    "_init_layers": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_forward_ligru": [
      "self",
      "x",
      "hx"
    ]
  },
  "LiGRU_Layer": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "batch_size",
      "dropout",
      "nonlinearity",
      "normalization",
      "bias",
      "bidirectional"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_ligru_cell": [
      "self",
      "w",
      "ht"
    ],
    "_init_drop": [
      "self"
    ],
    "_sample_drop_mask": [
      "self",
      "w"
    ],
    "_change_batch_size": [
      "self",
      "x"
    ]
  },
  "SLiGRU": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "nonlinearity",
      "ff_normalization",
      "recurrent_elementwise_affine",
      "num_layers",
      "bias",
      "dropout",
      "re_init",
      "bidirectional"
    ],
    "_init_layers": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_forward_sligru": [
      "self",
      "x",
      "hx"
    ]
  },
  "SLiGRU_Layer": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "batch_size",
      "dropout",
      "nonlinearity",
      "ff_normalization",
      "recurrent_elementwise_affine",
      "bias",
      "bidirectional"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_sligru_cell": [
      "self",
      "w",
      "ht"
    ],
    "_init_drop": [
      "self"
    ],
    "_sample_drop_mask": [
      "self",
      "w"
    ],
    "_change_batch_size": [
      "self",
      "x"
    ]
  },
  "QuasiRNNLayer": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "bidirectional",
      "zoneout",
      "output_gate"
    ],
    "forgetMult": [
      "self",
      "f",
      "x",
      "hidden"
    ],
    "split_gate_inputs": [
      "self",
      "y"
    ],
    "forward": [
      "self",
      "x",
      "hidden"
    ]
  },
  "QuasiRNN": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "input_size",
      "num_layers",
      "bias",
      "dropout",
      "bidirectional"
    ],
    "forward": [
      "self",
      "x",
      "hidden"
    ]
  },
  "rnn_init": [
    "module"
  ],
  "Sequential": {
    "__init__": [
      "self"
    ],
    "append": [
      "self",
      "layer"
    ],
    "get_output_shape": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LengthsCapableSequential": {
    "__init__": [
      "self"
    ],
    "append": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ]
  },
  "ModuleList": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "append": [
      "self",
      "module"
    ],
    "extend": [
      "self",
      "modules"
    ],
    "insert": [
      "self",
      "index",
      "module"
    ]
  },
  "ConnectBlocks": {
    "__init__": [
      "self",
      "input_shape",
      "shortcut_type",
      "shortcut_projection",
      "shortcut_combine_fn"
    ],
    "append": [
      "self",
      "layer"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_combine": [
      "self",
      "shortcut",
      "x",
      "block_index"
    ]
  },
  "ContentBasedAttention": {
    "__init__": [
      "self",
      "enc_dim",
      "dec_dim",
      "attn_dim",
      "output_dim",
      "scaling"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_states",
      "enc_len",
      "dec_states"
    ]
  },
  "LocationAwareAttention": {
    "__init__": [
      "self",
      "enc_dim",
      "dec_dim",
      "attn_dim",
      "output_dim",
      "conv_channels",
      "kernel_size",
      "scaling"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_states",
      "enc_len",
      "dec_states"
    ]
  },
  "KeyValueAttention": {
    "__init__": [
      "self",
      "enc_dim",
      "dec_dim",
      "attn_dim",
      "output_dim"
    ],
    "reset": [
      "self"
    ],
    "forward": [
      "self",
      "enc_states",
      "enc_len",
      "dec_states"
    ]
  },
  "RelPosEncXL": {
    "__init__": [
      "self",
      "emb_dim",
      "dtype"
    ],
    "make_pe": [
      "self",
      "seq_len"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RelPosMHAXL": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "dropout",
      "vbias",
      "vdim",
      "mask_pos_future"
    ],
    "_reset_parameters": [
      "self"
    ],
    "rel_shift": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "pos_embs",
      "key_padding_mask",
      "attn_mask",
      "return_attn_weights"
    ]
  },
  "PositionalwiseFeedForward": {
    "__init__": [
      "self",
      "d_ffn",
      "input_shape",
      "input_size",
      "dropout",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PrecomputedRoPESinusoids": {
    "__init__": [
      "self",
      "max_length",
      "input_size",
      "dtype",
      "device"
    ]
  },
  "MemoiseAtLeastSize": {
    "__init__": [
      "self",
      "function",
      "round_up"
    ],
    "__call__": [
      "self",
      "size"
    ]
  },
  "memoise_at_least": [
    "round_up"
  ],
  "_get_precomputed_values": [
    "length",
    "input_size",
    "dtype",
    "device"
  ],
  "_rope_rotate": [
    "x"
  ],
  "RoPEMHA": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "dropout",
      "vbias",
      "vdim"
    ],
    "_reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask",
      "attn_mask",
      "pos_embs",
      "return_attn_weights"
    ]
  },
  "masks_union": [
    "bsz",
    "klen",
    "num_heads",
    "attn_mask",
    "key_padding_mask"
  ],
  "HyperMixing": {
    "__init__": [
      "self",
      "input_output_dim",
      "hypernet_size",
      "tied",
      "num_heads",
      "fix_tm_hidden_size",
      "max_length"
    ],
    "_mlp_pass_from_components": [
      "self",
      "out",
      "W1",
      "W2",
      "activation"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attn_mask",
      "key_padding_mask",
      "return_attn_weights",
      "pos_embs"
    ]
  },
  "HyperNetwork": {
    "__init__": [
      "self",
      "input_output_dim",
      "hypernet_size",
      "tied",
      "num_heads",
      "keep_output_size"
    ],
    "forward": [
      "self",
      "input_tensor"
    ]
  },
  "ParallelMLPs": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "output_size",
      "num_mlps",
      "keep_output_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Diffuser": {
    "__init__": [
      "self",
      "model",
      "timesteps",
      "noise"
    ],
    "distort": [
      "self",
      "x",
      "timesteps"
    ],
    "train_sample": [
      "self",
      "x",
      "timesteps",
      "condition"
    ],
    "sample": [
      "self",
      "shape"
    ],
    "forward": [
      "self",
      "x",
      "timesteps"
    ]
  },
  "DDPM_DEFAULT_BETA_START": [],
  "DDPM_DEFAULT_BETA_END": [],
  "DDPM_REF_TIMESTEPS": [],
  "DESC_SAMPLING": [],
  "DenoisingDiffusion": {
    "__init__": [
      "self",
      "model",
      "timesteps",
      "noise",
      "beta_start",
      "beta_end",
      "sample_min",
      "sample_max",
      "show_progress"
    ],
    "compute_coefficients": [
      "self"
    ],
    "distort": [
      "self",
      "x",
      "noise",
      "timesteps"
    ],
    "sample": [
      "self",
      "shape"
    ],
    "sample_step": [
      "self",
      "sample",
      "timestep"
    ]
  },
  "LatentDiffusion": {
    "__init__": [
      "self",
      "autoencoder",
      "diffusion",
      "latent_downsample_factor",
      "latent_pad_dim"
    ],
    "train_sample": [
      "self",
      "x"
    ],
    "_pad_latent": [
      "self",
      "latent"
    ],
    "train_sample_latent": [
      "self",
      "x"
    ],
    "distort": [
      "self",
      "x"
    ],
    "sample": [
      "self",
      "shape"
    ]
  },
  "sample_timesteps": [
    "x",
    "num_timesteps"
  ],
  "GaussianNoise": {
    "forward": [
      "self",
      "sample"
    ]
  },
  "LengthMaskedGaussianNoise": {
    "__init__": [
      "self",
      "length_dim"
    ],
    "forward": [
      "self",
      "sample",
      "length"
    ],
    "_compute_mask_shape": [
      "self",
      "noise",
      "max_len"
    ]
  },
  "_NOISE_FUNCTIONS": [],
  "DiffusionTrainSample": [],
  "LatentDiffusionTrainSample": [],
  "update_learning_rate": [
    "optimizer",
    "new_lr",
    "param_group"
  ],
  "WarmAndExpDecayLRSchedule": {
    "__init__": [
      "self",
      "lr",
      "n_warmup_steps",
      "total_steps",
      "decay_factor"
    ],
    "__call__": [
      "self",
      "opt"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch",
      "device"
    ]
  },
  "NewBobScheduler": {
    "__init__": [
      "self",
      "initial_value",
      "annealing_factor",
      "improvement_threshold",
      "patient"
    ],
    "__call__": [
      "self",
      "metric_value"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "LinearScheduler": {
    "__init__": [
      "self",
      "initial_value",
      "final_value",
      "epoch_count"
    ],
    "__call__": [
      "self",
      "current_epoch"
    ]
  },
  "LinearWarmupScheduler": {
    "__init__": [
      "self",
      "initial_value",
      "num_warmup_steps",
      "num_training_steps"
    ],
    "calculate_lr": [
      "self",
      "current_step"
    ],
    "get_next_value": [
      "self"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "StepScheduler": {
    "DEFAULT_DECAY_FACTOR": [],
    "DEFAULT_DECAY_DROP": [],
    "__init__": [
      "self",
      "initial_value",
      "decay_factor",
      "decay_drop",
      "half_life"
    ],
    "_compute_half_life_decay_factor": [
      "self",
      "half_life"
    ],
    "__call__": [
      "self",
      "current_epoch"
    ],
    "_compute_value": [
      "self",
      "current_epoch"
    ]
  },
  "NoamScheduler": {
    "__init__": [
      "self",
      "lr_initial",
      "n_warmup_steps",
      "model_size"
    ],
    "__call__": [
      "self",
      "opt"
    ],
    "_get_lr_scale": [
      "self"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "NoamIntervalScheduler": {
    "__init__": [
      "self",
      "lr_initial",
      "n_warmup_steps",
      "anneal_steps",
      "anneal_rates",
      "model_size"
    ],
    "__call__": [
      "self",
      "opt"
    ],
    "_get_lr_scale": [
      "self"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch",
      "device"
    ]
  },
  "LinearNoamScheduler": {
    "__init__": [
      "self",
      "lr_initial",
      "n_warmup_steps",
      "n_keep_steps"
    ],
    "__call__": [
      "self",
      "opt"
    ],
    "_get_lr_scale": [
      "self"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch",
      "device"
    ]
  },
  "CyclicCosineScheduler": {
    "__init__": [
      "self",
      "n_warmup_steps",
      "lr_initial",
      "total_steps"
    ],
    "__call__": [
      "self",
      "opt"
    ],
    "_get_lr_scale": [
      "self"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "ReduceLROnPlateau": {
    "__init__": [
      "self",
      "lr_min",
      "factor",
      "patience",
      "dont_halve_until_epoch"
    ],
    "__call__": [
      "self",
      "optim_list",
      "current_epoch",
      "current_loss"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "CyclicLRScheduler": {
    "__init__": [
      "self",
      "base_lr",
      "max_lr",
      "step_size",
      "mode",
      "gamma",
      "scale_fn",
      "scale_mode"
    ],
    "_reset": [
      "self",
      "new_base_lr",
      "new_max_lr",
      "new_step_size"
    ],
    "__call__": [
      "self",
      "epoch"
    ],
    "clr": [
      "self",
      "clr_iterations"
    ],
    "on_batch_end": [
      "self",
      "opt"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "IntervalScheduler": {
    "__init__": [
      "self",
      "intervals"
    ],
    "__call__": [
      "self",
      "opt"
    ],
    "_compute_next": [
      "self"
    ],
    "_get_lr": [
      "self",
      "current_lr"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "InverseSquareRootScheduler": {
    "__init__": [
      "self",
      "warmup_steps"
    ],
    "__call__": [
      "self",
      "opt"
    ],
    "_compute_value": [
      "self"
    ],
    "save": [
      "self",
      "path"
    ]
  },
  "WarmCoolDecayLRSchedule": {
    "__init__": [
      "self",
      "lr",
      "warmup",
      "cooldown",
      "total_steps",
      "decay_factor",
      "decay_every"
    ],
    "__call__": [
      "self",
      "opt",
      "num_updates"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "ScheduledLoss": {
    "__init__": [
      "self",
      "schedule"
    ],
    "forward": [
      "self"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch",
      "device"
    ],
    "find_next_switch": [
      "self"
    ]
  },
  "TriStageLRSchedule": {
    "__init__": [
      "self",
      "lr",
      "warmup_steps",
      "hold_steps",
      "decay_steps",
      "total_steps",
      "init_lr_scale",
      "final_lr_scale"
    ],
    "__call__": [
      "self",
      "opt",
      "num_updates"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch",
      "device"
    ]
  },
  "GumbelVectorQuantizer": {
    "__init__": [
      "self",
      "input_dim",
      "num_vars",
      "temp_tuple",
      "groups",
      "vq_dim"
    ],
    "update_temp": [
      "self",
      "steps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RandomProjectionQuantizer": {
    "__init__": [
      "self",
      "input_dim",
      "cb_dim",
      "cb_vocab"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "smallVal": [],
  "si_snr_loss": [
    "y_pred_batch",
    "y_true_batch",
    "lens",
    "reduction"
  ],
  "GuidedAttentionLoss": {
    "__init__": [
      "self",
      "sigma"
    ],
    "forward": [
      "self",
      "attention",
      "input_lengths",
      "target_lengths",
      "max_input_len",
      "max_target_len"
    ],
    "guided_attentions": [
      "self",
      "input_lengths",
      "target_lengths",
      "max_input_len",
      "max_target_len"
    ]
  },
  "NUMBA_VERBOSE": [],
  "cu_kernel_forward": [
    "log_probs",
    "labels",
    "alpha",
    "log_p",
    "T",
    "U",
    "blank",
    "lock"
  ],
  "cu_kernel_backward": [
    "log_probs",
    "labels",
    "beta",
    "log_p",
    "T",
    "U",
    "blank",
    "lock"
  ],
  "cu_kernel_compute_grad": [
    "log_probs",
    "labels",
    "alpha",
    "beta",
    "grads",
    "T",
    "U",
    "blank"
  ],
  "Transducer": {
    "forward": [
      "ctx",
      "log_probs",
      "labels",
      "T",
      "U",
      "blank",
      "reduction"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "TransducerLoss": {
    "__init__": [
      "self",
      "blank",
      "reduction"
    ],
    "forward": [
      "self",
      "logits",
      "labels",
      "T",
      "U"
    ]
  },
  "thirdoct": [
    "fs",
    "nfft",
    "num_bands",
    "min_freq"
  ],
  "removeSilentFrames": [
    "x",
    "y",
    "dyn_range",
    "N",
    "K"
  ],
  "stoi_loss": [
    "y_pred_batch",
    "y_true_batch",
    "lens",
    "reduction"
  ],
  "Transducer_joint": {
    "__init__": [
      "self",
      "joint_network",
      "joint",
      "nonlinearity"
    ],
    "init_params": [
      "self",
      "first_input"
    ],
    "forward": [
      "self",
      "input_TN",
      "input_PN"
    ]
  },
  "CLSTM": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "num_layers",
      "bias",
      "dropout",
      "bidirectional",
      "return_hidden",
      "init_criterion",
      "weight_init"
    ],
    "_init_layers": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_forward_rnn": [
      "self",
      "x",
      "hx"
    ]
  },
  "CLSTM_Layer": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "batch_size",
      "dropout",
      "bidirectional",
      "init_criterion",
      "weight_init"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_complexlstm_cell": [
      "self",
      "w",
      "ht"
    ],
    "_init_drop": [
      "self",
      "batch_size"
    ],
    "_sample_drop_mask": [
      "self",
      "w"
    ],
    "_change_batch_size": [
      "self",
      "x"
    ]
  },
  "CRNN": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "nonlinearity",
      "num_layers",
      "bias",
      "dropout",
      "bidirectional",
      "return_hidden",
      "init_criterion",
      "weight_init"
    ],
    "_init_layers": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_forward_rnn": [
      "self",
      "x",
      "hx"
    ]
  },
  "CRNN_Layer": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "batch_size",
      "dropout",
      "nonlinearity",
      "bidirectional",
      "init_criterion",
      "weight_init"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_complexrnn_cell": [
      "self",
      "w",
      "ht"
    ],
    "_init_drop": [
      "self",
      "batch_size"
    ],
    "_sample_drop_mask": [
      "self",
      "w"
    ],
    "_change_batch_size": [
      "self",
      "x"
    ]
  },
  "CLiGRU": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "nonlinearity",
      "normalization",
      "num_layers",
      "bias",
      "dropout",
      "bidirectional",
      "return_hidden",
      "init_criterion",
      "weight_init"
    ],
    "_init_layers": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_forward_ligru": [
      "self",
      "x",
      "hx"
    ]
  },
  "CLiGRU_Layer": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "batch_size",
      "dropout",
      "nonlinearity",
      "normalization",
      "bidirectional",
      "init_criterion",
      "weight_init"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_complex_ligru_cell": [
      "self",
      "w",
      "ht"
    ],
    "_init_drop": [
      "self",
      "batch_size"
    ],
    "_sample_drop_mask": [
      "self",
      "w"
    ],
    "_change_batch_size": [
      "self",
      "x"
    ]
  },
  "check_complex_input": [
    "input_shape"
  ],
  "get_real": [
    "input",
    "input_type",
    "channels_axis"
  ],
  "get_imag": [
    "input",
    "input_type",
    "channels_axis"
  ],
  "get_conjugate": [
    "input",
    "input_type",
    "channels_axis"
  ],
  "complex_linear_op": [
    "input",
    "real_weight",
    "imag_weight",
    "bias"
  ],
  "complex_conv_op": [
    "input",
    "real_weight",
    "imag_weight",
    "bias",
    "stride",
    "padding",
    "dilation",
    "conv1d"
  ],
  "unitary_init": [
    "in_features",
    "out_features",
    "kernel_size",
    "criterion"
  ],
  "complex_init": [
    "in_features",
    "out_features",
    "kernel_size",
    "criterion"
  ],
  "affect_init": [
    "real_weight",
    "imag_weight",
    "init_func",
    "criterion"
  ],
  "affect_conv_init": [
    "real_weight",
    "imag_weight",
    "kernel_size",
    "init_func",
    "criterion"
  ],
  "multi_mean": [
    "input",
    "axes",
    "keepdim"
  ],
  "CLinear": {
    "__init__": [
      "self",
      "n_neurons",
      "input_shape",
      "bias",
      "init_criterion",
      "weight_init"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CBatchNorm": {
    "__init__": [
      "self",
      "input_shape",
      "input_size",
      "dim",
      "eps",
      "momentum",
      "scale",
      "center",
      "track_running_stats"
    ],
    "reset_running_stats": [
      "self"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "_retrieve_real_imag": [
      "self",
      "tensor",
      "ndim",
      "input_dim"
    ],
    "_check_input": [
      "self",
      "input_shape"
    ]
  },
  "CLayerNorm": {
    "__init__": [
      "self",
      "input_shape",
      "input_size",
      "dim",
      "eps",
      "scale",
      "center"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ],
    "_check_input": [
      "self",
      "input_shape"
    ]
  },
  "c_norm": [
    "input_centred",
    "Vrr",
    "Vii",
    "Vri",
    "beta",
    "gamma_rr",
    "gamma_ri",
    "gamma_ii",
    "scale",
    "center",
    "layernorm",
    "dim"
  ],
  "c_standardization": [
    "input_centred",
    "Vrr",
    "Vii",
    "Vri",
    "layernorm",
    "dim"
  ],
  "CConv1d": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "input_shape",
      "stride",
      "dilation",
      "padding",
      "groups",
      "bias",
      "padding_mode",
      "init_criterion",
      "weight_init"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_manage_padding": [
      "self",
      "x",
      "kernel_size",
      "dilation",
      "stride"
    ],
    "_check_input": [
      "self",
      "input_shape"
    ],
    "_get_kernel_and_weight_shape": [
      "self"
    ]
  },
  "CConv2d": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "input_shape",
      "stride",
      "dilation",
      "padding",
      "groups",
      "bias",
      "padding_mode",
      "init_criterion",
      "weight_init"
    ],
    "forward": [
      "self",
      "x",
      "init_params"
    ],
    "_get_kernel_and_weight_shape": [
      "self"
    ],
    "_manage_padding": [
      "self",
      "x",
      "kernel_size",
      "dilation",
      "stride"
    ],
    "_check_input": [
      "self",
      "input_shape"
    ]
  },
  "QPooling2d": {
    "__init__": [
      "self",
      "pool_type",
      "kernel_size",
      "pool_axis",
      "ceil_mode",
      "padding",
      "dilation",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QBatchNorm": {
    "__init__": [
      "self",
      "input_size",
      "dim",
      "gamma_init",
      "beta_param",
      "momentum",
      "eps",
      "track_running_stats"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "QLinear": {
    "__init__": [
      "self",
      "n_neurons",
      "input_shape",
      "bias",
      "init_criterion",
      "weight_init",
      "autograd",
      "spinor",
      "vector_scale",
      "max_norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QConv1d": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "input_shape",
      "stride",
      "dilation",
      "padding",
      "groups",
      "bias",
      "padding_mode",
      "init_criterion",
      "weight_init",
      "spinor",
      "vector_scale",
      "max_norm"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_get_kernel_and_weight_shape": [
      "self"
    ],
    "_manage_padding": [
      "self",
      "x",
      "kernel_size",
      "dilation",
      "stride"
    ],
    "_check_input": [
      "self",
      "input_shape"
    ]
  },
  "QConv2d": {
    "__init__": [
      "self",
      "out_channels",
      "kernel_size",
      "input_shape",
      "stride",
      "dilation",
      "padding",
      "groups",
      "bias",
      "padding_mode",
      "init_criterion",
      "weight_init",
      "spinor",
      "vector_scale",
      "max_norm",
      "swap",
      "skip_transpose"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_check_input": [
      "self",
      "input_shape"
    ],
    "_get_kernel_and_weight_shape": [
      "self"
    ],
    "_manage_padding": [
      "self",
      "x",
      "kernel_size",
      "dilation",
      "stride"
    ]
  },
  "QLSTM": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "num_layers",
      "bias",
      "dropout",
      "bidirectional",
      "init_criterion",
      "weight_init",
      "autograd"
    ],
    "_init_layers": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_forward_rnn": [
      "self",
      "x",
      "hx"
    ]
  },
  "QLSTM_Layer": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "batch_size",
      "dropout",
      "bidirectional",
      "init_criterion",
      "weight_init",
      "autograd"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_quaternionlstm_cell": [
      "self",
      "w",
      "ht"
    ],
    "_init_drop": [
      "self",
      "batch_size"
    ],
    "_sample_drop_mask": [
      "self",
      "w"
    ],
    "_change_batch_size": [
      "self",
      "x"
    ]
  },
  "QRNN": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "nonlinearity",
      "num_layers",
      "bias",
      "dropout",
      "bidirectional",
      "init_criterion",
      "weight_init",
      "autograd"
    ],
    "_init_layers": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_forward_rnn": [
      "self",
      "x",
      "hx"
    ]
  },
  "QRNN_Layer": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "batch_size",
      "dropout",
      "nonlinearity",
      "bidirectional",
      "init_criterion",
      "weight_init",
      "autograd"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_quaternionrnn_cell": [
      "self",
      "w",
      "ht"
    ],
    "_init_drop": [
      "self",
      "batch_size"
    ],
    "_sample_drop_mask": [
      "self",
      "w"
    ],
    "_change_batch_size": [
      "self",
      "x"
    ]
  },
  "QLiGRU": {
    "__init__": [
      "self",
      "hidden_size",
      "input_shape",
      "nonlinearity",
      "num_layers",
      "bias",
      "dropout",
      "bidirectional",
      "init_criterion",
      "weight_init",
      "autograd"
    ],
    "_init_layers": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_forward_ligru": [
      "self",
      "x",
      "hx"
    ]
  },
  "QLiGRU_Layer": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "num_layers",
      "batch_size",
      "dropout",
      "nonlinearity",
      "normalization",
      "bidirectional",
      "init_criterion",
      "weight_init",
      "autograd"
    ],
    "forward": [
      "self",
      "x",
      "hx"
    ],
    "_quaternion_ligru_cell": [
      "self",
      "w",
      "ht"
    ],
    "_init_drop": [
      "self",
      "batch_size"
    ],
    "_sample_drop_mask": [
      "self",
      "w"
    ],
    "_change_batch_size": [
      "self",
      "x"
    ]
  },
  "QuaternionLinearCustomBackward": {
    "forward": [
      "ctx",
      "input",
      "r_weight",
      "i_weight",
      "j_weight",
      "k_weight",
      "bias"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "quaternion_linear_op": [
    "input",
    "r_weight",
    "i_weight",
    "j_weight",
    "k_weight",
    "bias"
  ],
  "quaternion_linear_rotation_op": [
    "input",
    "r_weight",
    "i_weight",
    "j_weight",
    "k_weight",
    "bias",
    "scale",
    "zero_kernel"
  ],
  "quaternion_conv_rotation_op": [
    "input",
    "r_weight",
    "i_weight",
    "j_weight",
    "k_weight",
    "bias",
    "scale",
    "zero_kernel",
    "stride",
    "padding",
    "groups",
    "dilation",
    "conv1d"
  ],
  "quaternion_conv_op": [
    "input",
    "r_weight",
    "i_weight",
    "j_weight",
    "k_weight",
    "bias",
    "stride",
    "padding",
    "groups",
    "dilation",
    "conv1d"
  ],
  "quaternion_init": [
    "in_features",
    "out_features",
    "kernel_size",
    "criterion"
  ],
  "check_quaternion_input": [
    "input_shape"
  ],
  "renorm_quaternion_weights_inplace": [
    "r_weight",
    "i_weight",
    "j_weight",
    "k_weight",
    "max_norm"
  ],
  "prepare_dataset_from_URL": [
    "URL",
    "dest_folder",
    "ext",
    "csv_file",
    "max_length"
  ],
  "prepare_csv": [
    "filelist",
    "csv_file",
    "max_length"
  ],
  "write_csv": [
    "filelist",
    "csv_file",
    "max_length"
  ],
  "_write_csv_row": [
    "w",
    "filename",
    "index",
    "max_length"
  ],
  "_ensure_single_channel": [
    "signal",
    "filename",
    "rate"
  ],
  "_handle_long_waveform": [
    "w",
    "filename",
    "ID",
    "ext",
    "signal",
    "rate",
    "duration",
    "max_length",
    "index"
  ],
  "_write_short_waveform_csv": [
    "w",
    "ID",
    "ext",
    "duration",
    "filename",
    "index"
  ],
  "AddNoise": {
    "__init__": [
      "self",
      "csv_file",
      "csv_keys",
      "sorting",
      "num_workers",
      "snr_low",
      "snr_high",
      "pad_noise",
      "start_index",
      "normalize",
      "noise_funct",
      "replacements",
      "noise_sample_rate",
      "clean_sample_rate"
    ],
    "forward": [
      "self",
      "waveforms",
      "lengths"
    ],
    "_load_noise": [
      "self",
      "lengths",
      "max_length"
    ],
    "_load_noise_batch_of_size": [
      "self",
      "batch_size"
    ],
    "_concat_batch": [
      "noise_batch",
      "noise_lens",
      "added_noise",
      "added_lens"
    ],
    "_load_noise_batch": [
      "self"
    ]
  },
  "AddReverb": {
    "__init__": [
      "self",
      "csv_file",
      "sorting",
      "num_workers",
      "rir_scale_factor",
      "replacements",
      "reverb_sample_rate",
      "clean_sample_rate"
    ],
    "forward": [
      "self",
      "waveforms"
    ],
    "_load_rir": [
      "self",
      "waveforms"
    ]
  },
  "SpeedPerturb": {
    "__init__": [
      "self",
      "orig_freq",
      "speeds",
      "device"
    ],
    "forward": [
      "self",
      "waveform"
    ]
  },
  "Resample": {
    "__init__": [
      "self",
      "orig_freq",
      "new_freq"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "DropFreq": {
    "__init__": [
      "self",
      "drop_freq_low",
      "drop_freq_high",
      "drop_freq_count_low",
      "drop_freq_count_high",
      "drop_freq_width",
      "epsilon"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "DropChunk": {
    "__init__": [
      "self",
      "drop_length_low",
      "drop_length_high",
      "drop_count_low",
      "drop_count_high",
      "drop_start",
      "drop_end",
      "noise_factor"
    ],
    "forward": [
      "self",
      "waveforms",
      "lengths"
    ]
  },
  "FastDropChunk": {
    "__init__": [
      "self",
      "drop_length_low",
      "drop_length_high",
      "drop_count_low",
      "drop_count_high",
      "drop_start",
      "drop_end",
      "n_masks"
    ],
    "initialize_masks": [
      "self",
      "waveforms"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "DoClip": {
    "__init__": [
      "self",
      "clip_low",
      "clip_high"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "RandAmp": {
    "__init__": [
      "self",
      "amp_low",
      "amp_high"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "ChannelDrop": {
    "__init__": [
      "self",
      "drop_rate"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "ChannelSwap": {
    "__init__": [
      "self",
      "min_swap",
      "max_swap"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "CutCat": {
    "__init__": [
      "self",
      "min_num_segments",
      "max_num_segments"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "pink_noise_like": [
    "waveforms",
    "alpha_low",
    "alpha_high",
    "sample_rate"
  ],
  "DropBitResolution": {
    "__init__": [
      "self",
      "target_dtype"
    ],
    "forward": [
      "self",
      "float32_tensor"
    ]
  },
  "SignFlip": {
    "__init__": [
      "self",
      "flip_prob"
    ],
    "forward": [
      "self",
      "waveform"
    ]
  },
  "SpectrogramDrop": {
    "__init__": [
      "self",
      "drop_length_low",
      "drop_length_high",
      "drop_count_low",
      "drop_count_high",
      "replace",
      "dim"
    ],
    "forward": [
      "self",
      "spectrogram"
    ]
  },
  "Warping": {
    "__init__": [
      "self",
      "warp_window",
      "warp_mode",
      "dim"
    ],
    "forward": [
      "self",
      "spectrogram"
    ]
  },
  "RandomShift": {
    "__init__": [
      "self",
      "min_shift",
      "max_shift",
      "dim"
    ],
    "forward": [
      "self",
      "waveforms",
      "lengths"
    ]
  },
  "Augmenter": {
    "__init__": [
      "self",
      "parallel_augment",
      "parallel_augment_fixed_bs",
      "concat_original",
      "min_augmentations",
      "max_augmentations",
      "shuffle_augmentations",
      "repeat_augment",
      "augment_start_index",
      "augment_end_index",
      "concat_start_index",
      "concat_end_index",
      "augment_prob",
      "augmentations",
      "enable_augmentations"
    ],
    "augment": [
      "self",
      "x",
      "lengths",
      "selected_augmentations"
    ],
    "forward": [
      "self",
      "x",
      "lengths"
    ],
    "concatenate_outputs": [
      "self",
      "augment_lst",
      "augment_len_lst"
    ],
    "replicate_multiple_labels": [
      "self"
    ],
    "replicate_labels": [
      "self",
      "labels"
    ],
    "check_min_max_augmentations": [
      "self"
    ]
  },
  "CodecAugment": {
    "__init__": [
      "self",
      "sample_rate"
    ],
    "apply_codec": [
      "self",
      "waveform",
      "format",
      "encoder"
    ],
    "forward": [
      "self",
      "waveform"
    ]
  },
  "HMMAligner": {
    "__init__": [
      "self",
      "states_per_phoneme",
      "output_folder",
      "neg_inf",
      "batch_reduction",
      "input_len_norm",
      "target_len_norm",
      "lexicon_path"
    ],
    "_use_lexicon": [
      "self",
      "words",
      "interword_sils",
      "sample_pron"
    ],
    "use_lexicon": [
      "self",
      "words",
      "interword_sils",
      "sample_pron"
    ],
    "_make_pi_prob": [
      "self",
      "phn_lens_abs"
    ],
    "_make_trans_prob": [
      "self",
      "phn_lens_abs"
    ],
    "_make_emiss_pred_useful": [
      "self",
      "emission_pred",
      "lens_abs",
      "phn_lens_abs",
      "phns"
    ],
    "_dp_forward": [
      "self",
      "pi_prob",
      "trans_prob",
      "emiss_pred_useful",
      "lens_abs",
      "phn_lens_abs",
      "phns"
    ],
    "_dp_viterbi": [
      "self",
      "pi_prob",
      "trans_prob",
      "emiss_pred_useful",
      "lens_abs",
      "phn_lens_abs",
      "phns",
      "final_states"
    ],
    "_loss_reduction": [
      "self",
      "loss",
      "input_lens",
      "target_lens"
    ],
    "forward": [
      "self",
      "emission_pred",
      "lens",
      "phns",
      "phn_lens",
      "dp_algorithm",
      "prob_matrices"
    ],
    "expand_phns_by_states_per_phoneme": [
      "self",
      "phns",
      "phn_lens"
    ],
    "store_alignments": [
      "self",
      "ids",
      "alignments"
    ],
    "_get_flat_start_batch": [
      "self",
      "lens_abs",
      "phn_lens_abs",
      "phns"
    ],
    "_get_viterbi_batch": [
      "self",
      "ids",
      "lens_abs"
    ],
    "get_prev_alignments": [
      "self",
      "ids",
      "emission_pred",
      "lens",
      "phns",
      "phn_lens"
    ],
    "_calc_accuracy_sent": [
      "self",
      "alignments_",
      "ends_",
      "phns_"
    ],
    "calc_accuracy": [
      "self",
      "alignments",
      "ends",
      "phns",
      "ind2labs"
    ],
    "collapse_alignments": [
      "self",
      "alignments"
    ],
    "_save": [
      "self",
      "path"
    ],
    "_load": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "map_inds_to_intersect": [
    "lists1",
    "lists2",
    "ind2labs"
  ],
  "batch_log_matvecmul": [
    "A",
    "b"
  ],
  "batch_log_maxvecmul": [
    "A",
    "b"
  ],
  "CTCSegmentationTask": {
    "text": [],
    "ground_truth_mat": [],
    "utt_begin_indices": [],
    "timings": [],
    "char_probs": [],
    "state_list": [],
    "segments": [],
    "config": [],
    "done": [],
    "name": [],
    "utt_ids": [],
    "lpz": [],
    "print_confidence_score": [],
    "print_utterance_text": [],
    "set": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "CTCSegmentation": {
    "fs": [],
    "kaldi_style_text": [],
    "samples_to_frames_ratio": [],
    "time_stamps": [],
    "choices_time_stamps": [],
    "text_converter": [],
    "choices_text_converter": [],
    "warned_about_misconfiguration": [],
    "config": [],
    "__init__": [
      "self",
      "asr_model",
      "kaldi_style_text",
      "text_converter",
      "time_stamps"
    ],
    "set_config": [
      "self",
      "time_stamps",
      "fs",
      "samples_to_frames_ratio",
      "set_blank",
      "replace_spaces_with_blanks",
      "kaldi_style_text",
      "text_converter",
      "gratis_blank",
      "min_window_size",
      "max_window_size",
      "scoring_length"
    ],
    "get_timing_config": [
      "self",
      "speech_len",
      "lpz_len"
    ],
    "estimate_samples_to_frames_ratio": [
      "self",
      "speech_len"
    ],
    "get_lpz": [
      "self",
      "speech"
    ],
    "_split_text": [
      "self",
      "text"
    ],
    "prepare_segmentation_task": [
      "self",
      "text",
      "lpz",
      "name",
      "speech_len"
    ],
    "get_segments": [
      "task"
    ],
    "__call__": [
      "self",
      "speech",
      "text",
      "name"
    ]
  },
  "ctc_k2": [
    "log_probs",
    "input_lens",
    "graph_compiler",
    "texts",
    "reduction",
    "beam_size",
    "use_double_scores",
    "is_training"
  ],
  "lattice_path_to_textid": [
    "best_paths",
    "return_ragged"
  ],
  "lattice_paths_to_text": [
    "best_paths",
    "word_table"
  ],
  "load_G": [
    "path",
    "cache"
  ],
  "prepare_rescoring_G": [
    "G"
  ],
  "get_decoding": [
    "hparams",
    "graphCompiler",
    "device"
  ],
  "get_lattice": [
    "log_probs_nnet_output",
    "input_lens",
    "decoder",
    "search_beam",
    "output_beam",
    "min_active_states",
    "max_active_states",
    "ac_scale",
    "subsampling_factor"
  ],
  "one_best_decoding": [
    "lattice",
    "use_double_scores"
  ],
  "rescore_with_whole_lattice": [
    "lattice",
    "G_with_epsilon_loops",
    "lm_scale_list",
    "use_double_scores"
  ],
  "GraphCompiler": {
    "topo": [
      "self"
    ],
    "lexicon": [
      "self"
    ],
    "device": [
      "self"
    ],
    "compile": [
      "self",
      "texts",
      "is_training"
    ],
    "compile_HL": [
      "self",
      "cache_dir",
      "cache"
    ],
    "compile_HLG": [
      "self",
      "G",
      "cache_dir",
      "cache"
    ]
  },
  "CtcGraphCompiler": {
    "__init__": [
      "self",
      "_lexicon",
      "device",
      "need_repeat_flag"
    ],
    "topo": [
      "self"
    ],
    "lexicon": [
      "self"
    ],
    "device": [
      "self"
    ],
    "compile": [
      "self",
      "texts",
      "is_training"
    ]
  },
  "Lexicon": [],
  "write_mapping": [
    "filename",
    "sym2id"
  ],
  "get_tokens": [
    "lexicon",
    "sil_token",
    "manually_add_sil_to_tokens"
  ],
  "get_words": [
    "lexicon"
  ],
  "add_disambig_symbols": [
    "lexicon"
  ],
  "generate_id_map": [
    "symbols"
  ],
  "add_self_loops": [
    "arcs",
    "disambig_token",
    "disambig_word"
  ],
  "lexicon_to_fst": [
    "lexicon",
    "token2id",
    "word2id",
    "sil_token",
    "sil_prob",
    "need_self_loops"
  ],
  "lexicon_to_fst_no_sil": [
    "lexicon",
    "token2id",
    "word2id",
    "need_self_loops"
  ],
  "prepare_lang": [
    "lang_dir",
    "sil_token",
    "sil_prob",
    "cache"
  ],
  "UNK": [],
  "UNK_t": [],
  "EOW": [],
  "prepare_char_lexicon": [
    "lang_dir",
    "vocab_files",
    "extra_csv_files",
    "column_text_key",
    "add_word_boundary"
  ],
  "read_lexicon": [
    "filename"
  ],
  "write_lexicon": [
    "filename",
    "lexicon"
  ],
  "PaddedData": [],
  "PaddedBatch": {
    "__init__": [
      "self",
      "examples",
      "padded_keys",
      "device_prep_keys",
      "padding_func",
      "padding_kwargs",
      "apply_default_convert",
      "nonpadded_stack"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__iter__": [
      "self"
    ],
    "pin_memory": [
      "self"
    ],
    "to": [
      "self"
    ],
    "at_position": [
      "self",
      "pos"
    ],
    "batchsize": [
      "self"
    ]
  },
  "BatchsizeGuesser": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "batch"
    ],
    "find_suitable_method": [
      "self",
      "batch"
    ],
    "attr_based": [
      "self",
      "batch"
    ],
    "torch_tensor_bs": [
      "self",
      "batch"
    ],
    "len_of_first": [
      "self",
      "batch"
    ],
    "len_of_iter_first": [
      "self",
      "batch"
    ],
    "fallback": [
      "self",
      "batch"
    ]
  },
  "load_data_json": [
    "json_path",
    "replacements"
  ],
  "_recursive_format": [
    "data",
    "replacements"
  ],
  "load_data_csv": [
    "csv_path",
    "replacements"
  ],
  "read_audio_info": [
    "path",
    "backend"
  ],
  "read_audio": [
    "waveforms_obj",
    "backend"
  ],
  "read_audio_multichannel": [
    "waveforms_obj",
    "backend"
  ],
  "write_audio": [
    "filepath",
    "audio",
    "samplerate"
  ],
  "load_pickle": [
    "pickle_path"
  ],
  "to_floatTensor": [
    "x"
  ],
  "to_doubleTensor": [
    "x"
  ],
  "to_longTensor": [
    "x"
  ],
  "convert_index_to_lab": [
    "batch",
    "ind2lab"
  ],
  "relative_time_to_absolute": [
    "batch",
    "relative_lens",
    "rate"
  ],
  "IterativeCSVWriter": {
    "__init__": [
      "self",
      "outstream",
      "data_fields",
      "defaults"
    ],
    "set_default": [
      "self",
      "field",
      "value"
    ],
    "write": [
      "self"
    ],
    "write_batch": [
      "self"
    ],
    "_expand_data_fields": [
      "data_fields"
    ]
  },
  "write_txt_file": [
    "data",
    "filename",
    "sampling_rate"
  ],
  "write_stdout": [
    "data",
    "filename",
    "sampling_rate"
  ],
  "length_to_mask": [
    "length",
    "max_len",
    "dtype",
    "device"
  ],
  "read_kaldi_lab": [
    "kaldi_ali",
    "kaldi_lab_opts"
  ],
  "get_md5": [
    "file"
  ],
  "save_md5": [
    "files",
    "out_file"
  ],
  "save_pkl": [
    "obj",
    "file"
  ],
  "load_pkl": [
    "file"
  ],
  "prepend_bos_token": [
    "label",
    "bos_index"
  ],
  "append_eos_token": [
    "label",
    "length",
    "eos_index"
  ],
  "merge_char": [
    "sequences",
    "space"
  ],
  "merge_csvs": [
    "data_folder",
    "csv_lst",
    "merged_csv"
  ],
  "split_word": [
    "sequences",
    "space"
  ],
  "clean_padding_": [
    "tensor",
    "length",
    "len_dim",
    "mask_value"
  ],
  "clean_padding": [
    "tensor",
    "length",
    "len_dim",
    "mask_value"
  ],
  "extract_concepts_values": [
    "sequences",
    "keep_values",
    "tag_in",
    "tag_out",
    "space"
  ],
  "LengthItem": {},
  "total_length_with_padding": [
    "lengths"
  ],
  "padding_ratio": [
    "lengths"
  ],
  "RatioIndex": {},
  "indices_around_random_pivot": [
    "databuffer",
    "target_batch_numel",
    "max_batch_size",
    "max_batch_numel",
    "max_padding_ratio",
    "randint_generator"
  ],
  "dynamic_bucketed_batch": [
    "data",
    "len_key",
    "len_fn",
    "min_sample_len",
    "max_sample_len",
    "buffersize",
    "collate_fn",
    "sampler_fn",
    "sampler_kwargs",
    "drop_end"
  ],
  "AudioNormalizer": {
    "__init__": [
      "self",
      "sample_rate",
      "mix"
    ],
    "__call__": [
      "self",
      "audio",
      "sample_rate"
    ],
    "_mix": [
      "self",
      "audio"
    ]
  },
  "DynamicItemDataset": {
    "__init__": [
      "self",
      "data",
      "dynamic_items",
      "output_keys"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "add_dynamic_item": [
      "self",
      "func",
      "takes",
      "provides"
    ],
    "set_output_keys": [
      "self",
      "keys"
    ],
    "output_keys_as": [
      "self",
      "keys"
    ],
    "filtered_sorted": [
      "self",
      "key_min_value",
      "key_max_value",
      "key_test",
      "sort_key",
      "reverse",
      "select_n"
    ],
    "_filtered_sorted_ids": [
      "self",
      "key_min_value",
      "key_max_value",
      "key_test",
      "sort_key",
      "reverse",
      "select_n"
    ],
    "overfit_test": [
      "self",
      "sample_count",
      "total_count"
    ],
    "batch_shuffle": [
      "self",
      "batch_size"
    ],
    "from_json": [
      "cls",
      "json_path",
      "replacements",
      "dynamic_items",
      "output_keys"
    ],
    "from_csv": [
      "cls",
      "csv_path",
      "replacements",
      "dynamic_items",
      "output_keys"
    ],
    "from_arrow_dataset": [
      "cls",
      "dataset",
      "replacements",
      "dynamic_items",
      "output_keys"
    ]
  },
  "FilteredSortedDynamicItemDataset": {
    "__init__": [
      "self",
      "from_dataset",
      "data_ids"
    ],
    "from_json": [
      "cls",
      "json_path",
      "replacements",
      "dynamic_items",
      "output_keys"
    ],
    "from_csv": [
      "cls",
      "csv_path",
      "replacements",
      "dynamic_items",
      "output_keys"
    ]
  },
  "add_dynamic_item": [
    "datasets",
    "func",
    "takes",
    "provides"
  ],
  "set_output_keys": [
    "datasets",
    "output_keys"
  ],
  "apply_overfit_test": [
    "overfit_test",
    "overfit_test_sample_count",
    "overfit_test_epoch_data_count",
    "dataset"
  ],
  "TORCHAUDIO_FORMATS": [],
  "ITEM_POSTFIX": [],
  "CSVItem": [],
  "ExtendedCSVDataset": {
    "__init__": [
      "self",
      "csvpath",
      "replacements",
      "sorting",
      "min_duration",
      "max_duration",
      "dynamic_items",
      "output_keys"
    ]
  },
  "load_sb_extended_csv": [
    "csv_path",
    "replacements"
  ],
  "_read_csv_item": [
    "item"
  ],
  "_parse_csv_item_opts": [
    "entry"
  ],
  "read_pkl": [
    "file",
    "data_options",
    "lab2ind"
  ],
  "DEFAULT_UNK": [],
  "DEFAULT_BOS": [],
  "DEFAULT_EOS": [],
  "DEFAULT_BLANK": [],
  "CategoricalEncoder": {
    "VALUE_SEPARATOR": [],
    "EXTRAS_SEPARATOR": [],
    "__init__": [
      "self",
      "starting_index"
    ],
    "handle_special_labels": [
      "self",
      "special_labels"
    ],
    "__len__": [
      "self"
    ],
    "from_saved": [
      "cls",
      "path"
    ],
    "update_from_iterable": [
      "self",
      "iterable",
      "sequence_input"
    ],
    "update_from_didataset": [
      "self",
      "didataset",
      "output_key",
      "sequence_input"
    ],
    "limited_labelset_from_iterable": [
      "self",
      "iterable",
      "sequence_input",
      "n_most_common",
      "min_count"
    ],
    "load_or_create": [
      "self",
      "path",
      "from_iterables",
      "from_didatasets",
      "sequence_input",
      "output_key",
      "special_labels"
    ],
    "add_label": [
      "self",
      "label"
    ],
    "ensure_label": [
      "self",
      "label"
    ],
    "insert_label": [
      "self",
      "label",
      "index"
    ],
    "enforce_label": [
      "self",
      "label",
      "index"
    ],
    "add_unk": [
      "self",
      "unk_label"
    ],
    "_next_index": [
      "self"
    ],
    "is_continuous": [
      "self"
    ],
    "encode_label": [
      "self",
      "label",
      "allow_unk"
    ],
    "encode_label_torch": [
      "self",
      "label",
      "allow_unk"
    ],
    "encode_sequence": [
      "self",
      "sequence",
      "allow_unk"
    ],
    "encode_sequence_torch": [
      "self",
      "sequence",
      "allow_unk"
    ],
    "decode_torch": [
      "self",
      "x"
    ],
    "decode_ndim": [
      "self",
      "x"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path"
    ],
    "load_if_possible": [
      "self",
      "path",
      "end_of_epoch"
    ],
    "expect_len": [
      "self",
      "expected_len"
    ],
    "ignore_len": [
      "self"
    ],
    "_assert_len": [
      "self"
    ],
    "_get_extras": [
      "self"
    ],
    "_set_extras": [
      "self",
      "extras"
    ],
    "_save_literal": [
      "path",
      "lab2ind",
      "extras"
    ],
    "_load_literal": [
      "path"
    ]
  },
  "CTCTextEncoder": {
    "handle_special_labels": [
      "self",
      "special_labels"
    ],
    "add_blank": [
      "self",
      "blank_label"
    ],
    "insert_blank": [
      "self",
      "blank_label",
      "index"
    ],
    "get_blank_index": [
      "self"
    ],
    "collapse_labels": [
      "self",
      "x",
      "merge_repeats"
    ],
    "collapse_indices_ndim": [
      "self",
      "x",
      "merge_repeats"
    ],
    "_get_extras": [
      "self"
    ],
    "_set_extras": [
      "self",
      "extras"
    ]
  },
  "load_text_encoder_tokens": [
    "model_path"
  ],
  "print_wer_summary": [
    "wer_details",
    "file"
  ],
  "print_alignments": [
    "details_by_utterance",
    "file",
    "empty_symbol",
    "separator",
    "print_header",
    "sample_separator"
  ],
  "_print_top_wer_utts": [
    "top_non_empty",
    "top_empty",
    "file"
  ],
  "_print_top_wer_spks": [
    "spks_by_wer",
    "file"
  ],
  "_print_alignment": [
    "alignment",
    "a",
    "b",
    "empty_symbol",
    "separator",
    "file"
  ],
  "_print_alignments_global_header": [
    "empty_symbol",
    "separator",
    "file"
  ],
  "_print_alignment_header": [
    "wer_details",
    "file"
  ],
  "ReproducibleRandomSampler": {
    "__init__": [
      "self",
      "data_source",
      "seed",
      "epoch"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__iter__": [
      "self"
    ]
  },
  "ReproducibleWeightedRandomSampler": {
    "__init__": [
      "self",
      "weights",
      "num_samples",
      "replacement",
      "seed",
      "epoch"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__iter__": [
      "self"
    ]
  },
  "ConcatDatasetBatchSampler": {
    "__init__": [
      "self",
      "samplers",
      "batch_sizes",
      "epoch"
    ],
    "_iter_one_dataset": [
      "self",
      "c_batch_size",
      "c_sampler",
      "c_offset"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "DynamicBatchSampler": {
    "__init__": [
      "self",
      "dataset",
      "max_batch_length",
      "num_buckets",
      "length_func",
      "shuffle",
      "batch_ordering",
      "max_batch_ex",
      "bucket_boundaries",
      "lengths_list",
      "seed",
      "epoch",
      "drop_last",
      "verbose"
    ],
    "get_durations": [
      "self",
      "batch"
    ],
    "_get_boundaries_through_warping": [
      "self",
      "max_batch_length",
      "num_quantiles"
    ],
    "_permute_batches": [
      "self"
    ],
    "_generate_batches": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ],
    "__len__": [
      "self"
    ]
  },
  "DistributedSamplerWrapper": {
    "__init__": [
      "self",
      "sampler"
    ],
    "__iter__": [
      "self"
    ],
    "set_epoch": [
      "self",
      "epoch"
    ]
  },
  "BalancingDataSampler": {
    "__init__": [
      "self",
      "dataset",
      "key",
      "num_samples",
      "replacement",
      "seed",
      "epoch"
    ],
    "_compute_weights": [
      "self"
    ]
  },
  "distributed_loader_specifics": [
    "distributed_launch",
    "rank",
    "dataset",
    "loader_kwargs"
  ],
  "make_dataloader": [
    "dataset",
    "looped_nominal_epoch"
  ],
  "__new_init": [
    "self",
    "loader"
  ],
  "__new_reset": [
    "self",
    "loader",
    "first_iter"
  ],
  "SaveableDataLoader": {
    "__init__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "_speechbrain_save": [
      "self",
      "path"
    ],
    "_speechbrain_load": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "LoopedLoader": {
    "__init__": [
      "self",
      "loader",
      "epoch_length",
      "batchsize_fn"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "save": [
      "self",
      "path"
    ],
    "load": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "compute_amplitude": [
    "waveforms",
    "lengths",
    "amp_type",
    "scale"
  ],
  "normalize": [
    "waveforms",
    "lengths",
    "amp_type",
    "eps"
  ],
  "mean_std_norm": [
    "waveforms",
    "dims",
    "eps"
  ],
  "rescale": [
    "waveforms",
    "lengths",
    "target_lvl",
    "amp_type",
    "scale"
  ],
  "convolve1d": [
    "waveform",
    "kernel",
    "padding",
    "pad_type",
    "stride",
    "groups",
    "use_fft",
    "rotation_index"
  ],
  "reverberate": [
    "waveforms",
    "rir_waveform",
    "rescale_amp"
  ],
  "dB_to_amplitude": [
    "SNR"
  ],
  "notch_filter": [
    "notch_freq",
    "filter_width",
    "notch_width"
  ],
  "overlap_and_add": [
    "signal",
    "frame_step"
  ],
  "resynthesize": [
    "enhanced_mag",
    "noisy_inputs",
    "stft",
    "istft",
    "normalize_wavs"
  ],
  "gabor_impulse_response": [
    "t",
    "center",
    "fwhm"
  ],
  "gabor_impulse_response_legacy_complex": [
    "t",
    "center",
    "fwhm"
  ],
  "STFT": {
    "__init__": [
      "self",
      "sample_rate",
      "win_length",
      "hop_length",
      "n_fft",
      "window_fn",
      "normalized_stft",
      "center",
      "pad_mode",
      "onesided"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_filter_properties": [
      "self"
    ]
  },
  "ISTFT": {
    "__init__": [
      "self",
      "sample_rate",
      "n_fft",
      "win_length",
      "hop_length",
      "window_fn",
      "normalized_stft",
      "center",
      "onesided",
      "epsilon"
    ],
    "forward": [
      "self",
      "x",
      "sig_length"
    ]
  },
  "spectral_magnitude": [
    "stft",
    "power",
    "log",
    "eps"
  ],
  "Filterbank": {
    "__init__": [
      "self",
      "n_mels",
      "log_mel",
      "filter_shape",
      "f_min",
      "f_max",
      "n_fft",
      "sample_rate",
      "power_spectrogram",
      "amin",
      "ref_value",
      "top_db",
      "param_change_factor",
      "param_rand_factor",
      "freeze"
    ],
    "forward": [
      "self",
      "spectrogram"
    ],
    "_to_mel": [
      "hz"
    ],
    "_to_hz": [
      "mel"
    ],
    "_triangular_filters": [
      "self",
      "all_freqs",
      "f_central",
      "band"
    ],
    "_rectangular_filters": [
      "self",
      "all_freqs",
      "f_central",
      "band"
    ],
    "_gaussian_filters": [
      "self",
      "all_freqs",
      "f_central",
      "band",
      "smooth_factor"
    ],
    "_create_fbank_matrix": [
      "self",
      "f_central_mat",
      "band_mat"
    ],
    "_amplitude_to_DB": [
      "self",
      "x"
    ]
  },
  "DCT": {
    "__init__": [
      "self",
      "input_size",
      "n_out",
      "ortho_norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Deltas": {
    "__init__": [
      "self",
      "input_size",
      "window_length"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ContextWindow": {
    "__init__": [
      "self",
      "left_frames",
      "right_frames"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "gaussian_statistics": [
    "x",
    "dim",
    "mask"
  ],
  "combine_gaussian_statistics": [
    "left_statistics",
    "right_statistics"
  ],
  "combine_gaussian_statistics_distributed": [
    "statistics"
  ],
  "mean_std_update": [
    "x",
    "mask",
    "dim",
    "run_count",
    "run_mean",
    "run_std"
  ],
  "InputNormalization": {
    "__init__": [
      "self",
      "mean_norm",
      "std_norm",
      "norm_type",
      "avg_factor",
      "requires_grad",
      "update_until_epoch"
    ],
    "forward": [
      "self",
      "x",
      "lengths",
      "spk_ids",
      "epoch"
    ],
    "_compute_current_stats": [
      "self",
      "x"
    ],
    "_statistics_dict": [
      "self"
    ],
    "_load_statistics_dict": [
      "self",
      "state"
    ],
    "to": [
      "self",
      "device"
    ],
    "_save": [
      "self",
      "path"
    ],
    "_load": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "GlobalNorm": {
    "__init__": [
      "self",
      "norm_mean",
      "norm_std",
      "update_steps",
      "length_dim",
      "mask_value"
    ],
    "forward": [
      "self",
      "x",
      "lengths",
      "mask_value",
      "skip_update"
    ],
    "normalize": [
      "self",
      "x"
    ],
    "get_mask": [
      "self",
      "x",
      "lengths"
    ],
    "denormalize": [
      "self",
      "x"
    ],
    "freeze": [
      "self"
    ],
    "unfreeze": [
      "self"
    ]
  },
  "MinLevelNorm": {
    "__init__": [
      "self",
      "min_level_db"
    ],
    "forward": [
      "self",
      "x"
    ],
    "denormalize": [
      "self",
      "x"
    ]
  },
  "DynamicRangeCompression": {
    "__init__": [
      "self",
      "multiplier",
      "clip_val"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "spectral_phase": [
    "stft"
  ],
  "NMF_separate_spectra": [
    "Whats",
    "Xmix"
  ],
  "reconstruct_results": [
    "X1hat",
    "X2hat",
    "X_stft",
    "sample_rate",
    "win_length",
    "hop_length"
  ],
  "read_rttm": [
    "rttm_file_path"
  ],
  "write_ders_file": [
    "ref_rttm",
    "DER",
    "out_der_file"
  ],
  "prepare_subset_csv": [
    "full_diary_csv",
    "rec_id",
    "out_csv_file"
  ],
  "is_overlapped": [
    "end1",
    "start2"
  ],
  "merge_ssegs_same_speaker": [
    "lol"
  ],
  "distribute_overlap": [
    "lol"
  ],
  "write_rttm": [
    "segs_list",
    "out_rttm_file"
  ],
  "_graph_connected_component": [
    "graph",
    "node_id"
  ],
  "_graph_is_connected": [
    "graph"
  ],
  "_set_diag": [
    "laplacian",
    "value",
    "norm_laplacian"
  ],
  "_deterministic_vector_sign_flip": [
    "u"
  ],
  "_check_random_state": [
    "seed"
  ],
  "get_oracle_num_spkrs": [
    "rec_id",
    "spkr_info"
  ],
  "spectral_embedding_sb": [
    "adjacency",
    "n_components",
    "norm_laplacian",
    "drop_first"
  ],
  "spectral_clustering_sb": [
    "affinity",
    "n_clusters",
    "n_components",
    "random_state",
    "n_init"
  ],
  "Spec_Cluster": {
    "perform_sc": [
      "self",
      "X",
      "n_neighbors"
    ]
  },
  "Spec_Clust_unorm": {
    "__init__": [
      "self",
      "min_num_spkrs",
      "max_num_spkrs"
    ],
    "do_spec_clust": [
      "self",
      "X",
      "k_oracle",
      "p_val"
    ],
    "get_sim_mat": [
      "self",
      "X"
    ],
    "p_pruning": [
      "self",
      "A",
      "pval"
    ],
    "get_laplacian": [
      "self",
      "M"
    ],
    "get_spec_embs": [
      "self",
      "L",
      "k_oracle"
    ],
    "cluster_embs": [
      "self",
      "emb",
      "k"
    ],
    "getEigenGaps": [
      "self",
      "eig_vals"
    ]
  },
  "do_spec_clustering": [
    "diary_obj",
    "out_rttm_file",
    "rec_id",
    "k",
    "pval",
    "affinity_type",
    "n_neighbors"
  ],
  "do_kmeans_clustering": [
    "diary_obj",
    "out_rttm_file",
    "rec_id",
    "k_oracle",
    "p_val"
  ],
  "do_AHC": [
    "diary_obj",
    "out_rttm_file",
    "rec_id",
    "k_oracle",
    "p_val"
  ],
  "Covariance": {
    "__init__": [
      "self",
      "average"
    ],
    "forward": [
      "self",
      "Xs"
    ],
    "_cov": [
      "Xs",
      "average"
    ]
  },
  "DelaySum": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "Xs",
      "localization_tensor",
      "doa_mode",
      "mics",
      "fs",
      "c"
    ],
    "_delaysum": [
      "Xs",
      "As"
    ]
  },
  "Mvdr": {
    "__init__": [
      "self",
      "eps"
    ],
    "forward": [
      "self",
      "Xs",
      "NNs",
      "localization_tensor",
      "doa_mode",
      "mics",
      "fs",
      "c"
    ],
    "_mvdr": [
      "Xs",
      "NNs",
      "As",
      "eps"
    ]
  },
  "Gev": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "Xs",
      "SSs",
      "NNs"
    ],
    "_gev": [
      "Xs",
      "SSs",
      "NNs"
    ]
  },
  "GccPhat": {
    "__init__": [
      "self",
      "tdoa_max",
      "eps"
    ],
    "forward": [
      "self",
      "XXs"
    ],
    "_gcc_phat": [
      "XXs",
      "eps"
    ],
    "_extract_delays": [
      "xxs",
      "tdoa_max"
    ],
    "_interpolate": [
      "xxs",
      "delays"
    ]
  },
  "SrpPhat": {
    "__init__": [
      "self",
      "mics",
      "space",
      "sample_rate",
      "speed_sound",
      "eps"
    ],
    "forward": [
      "self",
      "XXs"
    ],
    "_srp_phat": [
      "XXs",
      "As",
      "doas",
      "eps"
    ]
  },
  "Music": {
    "__init__": [
      "self",
      "mics",
      "space",
      "sample_rate",
      "speed_sound",
      "eps",
      "n_sig"
    ],
    "forward": [
      "self",
      "XXs"
    ],
    "_music": [
      "XXs",
      "As",
      "doas",
      "n_sig",
      "eps"
    ]
  },
  "doas2taus": [
    "doas",
    "mics",
    "fs",
    "c"
  ],
  "tdoas2taus": [
    "tdoas"
  ],
  "steering": [
    "taus",
    "n_fft"
  ],
  "sphere": [
    "levels_count"
  ],
  "STAT_TYPE": [],
  "StatObject_SB": {
    "__init__": [
      "self",
      "modelset",
      "segset",
      "start",
      "stop",
      "stat0",
      "stat1"
    ],
    "__repr__": [
      "self"
    ],
    "save_stat_object": [
      "self",
      "filename"
    ],
    "get_model_segsets": [
      "self",
      "mod_id"
    ],
    "get_model_start": [
      "self",
      "mod_id"
    ],
    "get_model_stop": [
      "self",
      "mod_id"
    ],
    "get_mean_stat1": [
      "self"
    ],
    "get_total_covariance_stat1": [
      "self"
    ],
    "get_model_stat0": [
      "self",
      "mod_id"
    ],
    "get_model_stat1": [
      "self",
      "mod_id"
    ],
    "sum_stat_per_model": [
      "self"
    ],
    "center_stat1": [
      "self",
      "mu"
    ],
    "norm_stat1": [
      "self"
    ],
    "rotate_stat1": [
      "self",
      "R"
    ],
    "whiten_stat1": [
      "self",
      "mu",
      "sigma",
      "isSqrInvSigma"
    ],
    "align_models": [
      "self",
      "model_list"
    ],
    "align_segments": [
      "self",
      "segment_list"
    ],
    "get_lda_matrix_stat1": [
      "self",
      "rank"
    ]
  },
  "diff": [
    "list1",
    "list2"
  ],
  "ismember": [
    "list1",
    "list2"
  ],
  "Ndx": {
    "__init__": [
      "self",
      "ndx_file_name",
      "models",
      "testsegs"
    ],
    "save_ndx_object": [
      "self",
      "output_file_name"
    ],
    "filter": [
      "self",
      "modlist",
      "seglist",
      "keep"
    ],
    "validate": [
      "self"
    ]
  },
  "Scores": {
    "__init__": [
      "self",
      "scores_file_name"
    ],
    "__repr__": [
      "self"
    ]
  },
  "fa_model_loop": [
    "batch_start",
    "mini_batch_indices",
    "factor_analyser",
    "stat0",
    "stat1",
    "e_h",
    "e_hh"
  ],
  "_check_missing_model": [
    "enroll",
    "test",
    "ndx"
  ],
  "fast_PLDA_scoring": [
    "enroll",
    "test",
    "ndx",
    "mu",
    "F",
    "Sigma",
    "p_known",
    "scaling_factor",
    "check_missing"
  ],
  "LDA": {
    "__init__": [
      "self"
    ],
    "do_lda": [
      "self",
      "stat_server",
      "reduced_dim",
      "transform_mat"
    ]
  },
  "PLDA": {
    "__init__": [
      "self",
      "mean",
      "F",
      "Sigma",
      "rank_f",
      "nb_iter",
      "scaling_factor"
    ],
    "plda": [
      "self",
      "stat_server",
      "output_file_name",
      "whiten",
      "w_stat_server"
    ]
  },
  "PERIODIC_NEIGHBORS": [],
  "compute_autocorr_features": [
    "frames",
    "min_lag",
    "max_lag",
    "neighbors"
  ],
  "autocorrelate": [
    "frames"
  ],
  "compute_periodic_features": [
    "frames",
    "best_lags",
    "neighbors"
  ],
  "compute_spectral_features": [
    "spectrum",
    "eps"
  ],
  "spec_norm": [
    "value",
    "spectrum",
    "eps"
  ],
  "compute_gne": [
    "audio",
    "sample_rate",
    "bandwidth",
    "fshift",
    "frame_len",
    "hop_len"
  ],
  "inverse_filter": [
    "frames",
    "lpc_order"
  ],
  "compute_hilbert_envelopes": [
    "frames",
    "center_freq",
    "bandwidth",
    "sample_rate"
  ],
  "compute_cross_correlation": [
    "frames_a",
    "frames_b",
    "width"
  ],
  "gevd": [
    "a",
    "b"
  ],
  "svdl": [
    "a"
  ],
  "f": [
    "ws"
  ],
  "finv": [
    "wsh"
  ],
  "g": [
    "ws"
  ],
  "ginv": [
    "wsh"
  ],
  "pos_def": [
    "ws",
    "alpha",
    "eps"
  ],
  "inv": [
    "x"
  ],
  "SentencePiece": {
    "__init__": [
      "self",
      "model_dir",
      "vocab_size",
      "annotation_train",
      "annotation_read",
      "model_type",
      "char_format_input",
      "character_coverage",
      "user_defined_symbols",
      "max_sentencepiece_length",
      "bos_id",
      "eos_id",
      "pad_id",
      "unk_id",
      "split_by_whitespace",
      "num_sequences",
      "annotation_list_to_check",
      "annotation_format",
      "text_file",
      "add_dummy_prefix"
    ],
    "_csv2text": [
      "self"
    ],
    "_json2text": [
      "self"
    ],
    "_train_BPE": [
      "self"
    ],
    "_check_coverage_from_bpe": [
      "self",
      "list_annotation_files"
    ],
    "__call__": [
      "self",
      "batch",
      "batch_lens",
      "ind2lab",
      "task"
    ]
  },
  "get_spm_tokens": [
    "model_path"
  ],
  "SentencePieceDecoderStreamingContext": {},
  "spm_decode_preserve_leading_space": [
    "tokenizer",
    "hyps",
    "context"
  ],
  "DiscreteSSLTokenizer": {
    "__init__": [
      "self",
      "num_clusters"
    ],
    "textify": [
      "self",
      "tokens"
    ],
    "encode": [
      "self",
      "input",
      "SSL_layers",
      "deduplicates",
      "bpe_tokenizers"
    ]
  },
  "MetricStats": {
    "__init__": [
      "self",
      "metric",
      "n_jobs",
      "batch_eval"
    ],
    "clear": [
      "self"
    ],
    "append": [
      "self",
      "ids"
    ],
    "summarize": [
      "self",
      "field"
    ],
    "write_stats": [
      "self",
      "filestream",
      "verbose"
    ]
  },
  "multiprocess_evaluation": [
    "metric",
    "predict",
    "target",
    "lengths",
    "n_jobs"
  ],
  "sequence_evaluation": [
    "metric",
    "predict",
    "target",
    "lengths"
  ],
  "ErrorRateStats": {
    "__init__": [
      "self",
      "merge_tokens",
      "split_tokens",
      "space_token",
      "keep_values",
      "extract_concepts_values",
      "tag_in",
      "tag_out",
      "equality_comparator"
    ],
    "append": [
      "self",
      "ids",
      "predict",
      "target",
      "predict_len",
      "target_len",
      "ind2lab"
    ],
    "summarize": [
      "self",
      "field"
    ],
    "write_stats": [
      "self",
      "filestream"
    ]
  },
  "WeightedErrorRateStats": {
    "__init__": [
      "self",
      "base_stats",
      "cost_function",
      "weight_name"
    ],
    "append": [
      "self"
    ],
    "summarize": [
      "self",
      "field"
    ],
    "write_stats": [
      "self",
      "filestream"
    ]
  },
  "EmbeddingErrorRateSimilarity": {
    "__init__": [
      "self",
      "embedding_function",
      "low_similarity_weight",
      "high_similarity_weight",
      "threshold"
    ],
    "__call__": [
      "self",
      "edit_symbol",
      "a",
      "b"
    ]
  },
  "BinaryMetricStats": {
    "__init__": [
      "self",
      "positive_label"
    ],
    "clear": [
      "self"
    ],
    "append": [
      "self",
      "ids",
      "scores",
      "labels"
    ],
    "summarize": [
      "self",
      "field",
      "threshold",
      "max_samples",
      "beta",
      "eps"
    ]
  },
  "EER": [
    "positive_scores",
    "negative_scores"
  ],
  "minDCF": [
    "positive_scores",
    "negative_scores",
    "c_miss",
    "c_fa",
    "p_target"
  ],
  "ClassificationStats": {
    "__init__": [
      "self"
    ],
    "append": [
      "self",
      "ids",
      "predictions",
      "targets",
      "categories"
    ],
    "summarize": [
      "self",
      "field"
    ],
    "_compute_accuracy": [
      "self"
    ],
    "_build_lookups": [
      "self"
    ],
    "_compute_confusion_matrix": [
      "self"
    ],
    "_compute_classwise_stats": [
      "self",
      "confusion_matrix"
    ],
    "_get_keys": [
      "self"
    ],
    "_get_confusion_entries": [
      "self"
    ],
    "_index_lookup": [
      "self",
      "items"
    ],
    "clear": [
      "self"
    ],
    "write_stats": [
      "self",
      "filestream"
    ],
    "_write_classwise_stats": [
      "self",
      "filestream"
    ],
    "_write_confusion": [
      "self",
      "filestream"
    ],
    "_write_header": [
      "self",
      "header",
      "filestream"
    ],
    "_pad_to_length": [
      "self",
      "label",
      "length"
    ],
    "_format_key_label": [
      "self",
      "key"
    ]
  },
  "MultiMetricStats": {
    "__init__": [
      "self",
      "metric",
      "n_jobs",
      "batch_eval"
    ],
    "append": [
      "self",
      "ids"
    ],
    "eval_simple": [
      "self"
    ],
    "summarize": [
      "self",
      "field",
      "flat"
    ]
  },
  "_dictify": [
    "f"
  ],
  "ORDERS_ABBREV": [],
  "ORDERS_WORDS": [],
  "MultiProcessLoggerAdapter": {
    "_should_log": [
      "main_process_only"
    ],
    "log": [
      "self",
      "level",
      "msg"
    ],
    "warning_once": [
      "self"
    ]
  },
  "get_logger": [
    "name"
  ],
  "setup_logging": [
    "config_path",
    "overrides",
    "default_level"
  ],
  "TqdmCompatibleStreamHandler": {
    "emit": [
      "self",
      "record"
    ]
  },
  "format_order_of_magnitude": [
    "number",
    "abbreviate"
  ],
  "get_environment_description": [],
  "prepare_profiler": [
    "profile_warmup",
    "profile_steps",
    "logdir"
  ],
  "rank_prefixed_message": [
    "message"
  ],
  "get_rank": [],
  "run_on_main": [
    "func",
    "args",
    "kwargs",
    "post_func",
    "post_args",
    "post_kwargs",
    "run_post_on_main"
  ],
  "is_distributed_initialized": [],
  "if_main_process": [],
  "MainProcessContext": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "main_process_only": [
    "function"
  ],
  "ddp_barrier": [],
  "ddp_broadcast": [
    "communication_object",
    "src"
  ],
  "ddp_all_reduce": [
    "communication_object",
    "reduce_op"
  ],
  "ddp_init_group": [
    "run_opts"
  ],
  "WEAKREF_MARKER": [],
  "_cycliclrsaver": [
    "obj",
    "path"
  ],
  "_cycliclrloader": [
    "obj",
    "path",
    "end_of_epoch"
  ],
  "SynonymDictionary": {
    "__init__": [
      "self"
    ],
    "from_json_file": [
      "file"
    ],
    "from_json_path": [
      "path"
    ],
    "add_synonym_set": [
      "self",
      "words"
    ],
    "__call__": [
      "self",
      "a",
      "b"
    ],
    "get_synonyms_for": [
      "self",
      "word"
    ]
  },
  "rm_vector_weight_decay": [
    "modules"
  ],
  "valid_symbols": [],
  "_pad": [],
  "_punctuation": [],
  "_special": [],
  "_letters": [],
  "_arpabet": [],
  "symbols": [],
  "_symbol_to_id": [],
  "_id_to_symbol": [],
  "_curly_re": [],
  "_whitespace_re": [],
  "_abbreviations": [],
  "expand_abbreviations": [
    "text"
  ],
  "lowercase": [
    "text"
  ],
  "collapse_whitespace": [
    "text"
  ],
  "convert_to_ascii": [
    "text"
  ],
  "basic_cleaners": [
    "text"
  ],
  "german_cleaners": [
    "text"
  ],
  "transliteration_cleaners": [
    "text"
  ],
  "english_cleaners": [
    "text"
  ],
  "text_to_sequence": [
    "text",
    "cleaner_names"
  ],
  "sequence_to_text": [
    "sequence"
  ],
  "_clean_text": [
    "text",
    "cleaner_names"
  ],
  "_symbols_to_sequence": [
    "symbols"
  ],
  "_arpabet_to_sequence": [
    "text"
  ],
  "_should_keep_symbol": [
    "s"
  ],
  "_g2p_keep_punctuations": [
    "g2p_model",
    "text"
  ],
  "BERTScoreStats": {
    "__init__": [
      "self",
      "lm",
      "batch_size",
      "use_idf",
      "sentence_level_averaging",
      "allow_matching_special_tokens"
    ],
    "clear": [
      "self"
    ],
    "append": [
      "self",
      "ids",
      "predict",
      "target"
    ],
    "summarize": [
      "self",
      "field"
    ],
    "_update_summary": [
      "self"
    ],
    "_make_weights": [
      "self",
      "corpus"
    ],
    "_select_by_tokens": [
      "self",
      "token_weight",
      "input_tokens"
    ]
  },
  "get_bert_token_mask": [
    "tokenizer"
  ],
  "get_bertscore_token_weights": [
    "tokenizer",
    "corpus"
  ],
  "choice": [
    "value",
    "choices",
    "default"
  ],
  "try_parse_torchaudio_major_version": [],
  "check_torchaudio_backend": [],
  "validate_backend": [
    "backend"
  ],
  "EDER": [
    "prediction",
    "id",
    "duration",
    "emotion",
    "window_length",
    "stride"
  ],
  "getOverlap": [
    "a",
    "b"
  ],
  "merge_ssegs_same_emotion_adjacent": [
    "lol"
  ],
  "reference_to_lol": [
    "id",
    "duration",
    "emotion"
  ],
  "BLEUStats": {
    "__init__": [
      "self",
      "max_ngram_order"
    ],
    "append": [
      "self",
      "ids",
      "predict",
      "targets"
    ],
    "summarize": [
      "self",
      "field"
    ],
    "write_stats": [
      "self",
      "filestream"
    ]
  },
  "BaseSemDistStats": {
    "__init__": [
      "self",
      "embed_function",
      "scale",
      "batch_size"
    ],
    "clear": [
      "self"
    ],
    "append": [
      "self",
      "ids",
      "predict",
      "target"
    ],
    "summarize": [
      "self",
      "field"
    ],
    "_update_summary": [
      "self"
    ]
  },
  "SemDistStats": {
    "__init__": [
      "self",
      "lm",
      "method"
    ],
    "_embed": [
      "self",
      "sentences"
    ]
  },
  "LazyModule": {
    "__init__": [
      "self",
      "name",
      "target",
      "package"
    ],
    "ensure_module": [
      "self",
      "stacklevel"
    ],
    "__repr__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "attr"
    ]
  },
  "DeprecatedModuleRedirect": {
    "__init__": [
      "self",
      "old_import",
      "new_import",
      "extra_reason"
    ],
    "_redirection_warn": [
      "self"
    ],
    "ensure_module": [
      "self",
      "stacklevel"
    ]
  },
  "find_imports": [
    "file_path",
    "find_subpackages"
  ],
  "lazy_export": [
    "name",
    "package"
  ],
  "lazy_export_all": [
    "init_file_path",
    "package",
    "export_subpackages"
  ],
  "deprecated_redirect": [
    "old_import",
    "new_import",
    "extra_reason",
    "also_lazy_export"
  ],
  "FilterProperties": {
    "__post_init__": [
      "self"
    ],
    "pointwise_filter": [],
    "get_effective_size": [
      "self"
    ],
    "get_convolution_padding": [
      "self"
    ],
    "get_noncausal_equivalent": [
      "self"
    ],
    "with_on_top": [
      "self",
      "other",
      "allow_approximate"
    ]
  },
  "stack_filter_properties": [
    "filters",
    "allow_approximate"
  ],
  "FILE_IDS": [],
  "SCORED_SPEAKER_TIME": [],
  "MISS_SPEAKER_TIME": [],
  "FA_SPEAKER_TIME": [],
  "ERROR_SPEAKER_TIME": [],
  "rectify": [
    "arr"
  ],
  "DER": [
    "ref_rttm",
    "sys_rttm",
    "ignore_overlap",
    "collar",
    "individual_file_scores"
  ],
  "MODULE_ORION": [],
  "FORMAT_TIMESTAMP": [],
  "DEFAULT_TRIAL_ID": [],
  "DEFAULT_REPORTER": [],
  "ORION_TRIAL_ID_ENV": [],
  "KEY_HPOPT": [],
  "KEY_HPOPT_MODE": [],
  "KEY_TRIAL_ID": [],
  "HPOPT_KEYS": [],
  "_hpopt_modes": [],
  "hpopt_mode": [
    "mode"
  ],
  "HyperparameterOptimizationReporter": {
    "__init__": [
      "self",
      "objective_key"
    ],
    "report_objective": [
      "self",
      "result"
    ],
    "is_available": [
      "self"
    ],
    "trial_id": [
      "self"
    ]
  },
  "GenericHyperparameterOptimizationReporter": {
    "__init__": [
      "self",
      "reference_date",
      "output"
    ],
    "report_objective": [
      "self",
      "result"
    ],
    "trial_id": [
      "self"
    ]
  },
  "OrionHyperparameterOptimizationReporter": {
    "__init__": [
      "self",
      "objective_key"
    ],
    "_check_client": [
      "self"
    ],
    "_format_message": [
      "self",
      "result"
    ],
    "report_objective": [
      "self",
      "result"
    ],
    "trial_id": [
      "self"
    ],
    "is_available": [
      "self"
    ]
  },
  "get_reporter": [
    "mode"
  ],
  "_context": [],
  "HyperparameterOptimizationContext": {
    "__init__": [
      "self",
      "reporter_args",
      "reporter_kwargs"
    ],
    "parse_arguments": [
      "self",
      "arg_list",
      "pass_hpopt_args",
      "pass_trial_id"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "hyperparameter_optimization": [],
  "report_result": [
    "result"
  ],
  "get_trial_id": [],
  "_chunk_process_wrapper": [
    "fn",
    "chunk"
  ],
  "CancelFuturesOnExit": {
    "__init__": [
      "self",
      "future_list"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "_type",
      "_value",
      "_traceback"
    ]
  },
  "_ParallelMapper": {
    "__init__": [
      "self",
      "fn",
      "source",
      "process_count",
      "chunk_size",
      "queue_size",
      "executor",
      "progress_bar",
      "progress_bar_kwargs"
    ],
    "run": [
      "self"
    ],
    "_bump_processed_count": [
      "self",
      "future"
    ],
    "_enqueue_job": [
      "self"
    ],
    "_map_all": [
      "self"
    ]
  },
  "parallel_map": [
    "fn",
    "source",
    "process_count",
    "chunk_size",
    "queue_size",
    "executor",
    "progress_bar",
    "progress_bar_kwargs"
  ],
  "EpochCounter": {
    "__init__": [
      "self",
      "limit"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "_save": [
      "self",
      "path"
    ],
    "_recover": [
      "self",
      "path",
      "end_of_epoch"
    ]
  },
  "EpochCounterWithStopper": {
    "__init__": [
      "self",
      "limit",
      "limit_to_stop",
      "limit_warmup",
      "direction"
    ],
    "__next__": [
      "self"
    ],
    "update_metric": [
      "self",
      "current_metric"
    ],
    "_save": [
      "self",
      "path"
    ],
    "_recover": [
      "self",
      "path",
      "end_of_epoch",
      "device"
    ]
  },
  "FetchFrom": {
    "LOCAL": [],
    "HUGGING_FACE": [],
    "URI": []
  },
  "FetchSource": [],
  "LocalStrategy": {
    "SYMLINK": [],
    "COPY": [],
    "COPY_SKIP_CACHE": [],
    "NO_LINK": []
  },
  "link_with_strategy": [
    "src",
    "dst",
    "local_strategy"
  ],
  "guess_source": [
    "source"
  ],
  "fetch": [
    "filename",
    "source",
    "savedir",
    "overwrite",
    "allow_updates",
    "allow_network",
    "save_filename",
    "use_auth_token",
    "revision",
    "huggingface_cache_dir",
    "local_strategy"
  ],
  "import_from_path": [
    "path"
  ],
  "run_shell": [
    "cmd"
  ],
  "EDIT_SYMBOLS": [],
  "_str_equals": [
    "a",
    "b"
  ],
  "accumulatable_wer_stats": [
    "refs",
    "hyps",
    "stats",
    "equality_comparator"
  ],
  "_batch_stats": [
    "refs",
    "hyps",
    "equality_comparator"
  ],
  "op_table": [
    "a",
    "b",
    "equality_comparator"
  ],
  "alignment": [
    "table"
  ],
  "count_ops": [
    "table"
  ],
  "_batch_to_dict_format": [
    "ids",
    "seqs"
  ],
  "wer_details_for_batch": [
    "ids",
    "refs",
    "hyps",
    "compute_alignments",
    "equality_comparator"
  ],
  "wer_details_by_utterance": [
    "ref_dict",
    "hyp_dict",
    "compute_alignments",
    "scoring_mode",
    "equality_comparator"
  ],
  "wer_summary": [
    "details_by_utterance"
  ],
  "wer_details_by_speaker": [
    "details_by_utterance",
    "utt2spk"
  ],
  "top_wer_utts": [
    "details_by_utterance",
    "top_k"
  ],
  "top_wer_spks": [
    "details_by_speaker",
    "top_k"
  ],
  "save_for_pretrained": [
    "hparams",
    "min_key",
    "max_key",
    "ckpt_predicate",
    "pretrainer_key",
    "checkpointer_key"
  ],
  "StaticItem": {},
  "DynamicItem": {
    "__init__": [
      "self",
      "takes",
      "func",
      "provides"
    ],
    "__call__": [
      "self"
    ],
    "next_takes": [
      "self"
    ],
    "next_provides": [
      "self"
    ],
    "provided_in_order": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "GeneratorDynamicItem": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "next_takes": [
      "self"
    ],
    "next_provides": [
      "self"
    ],
    "provided_in_order": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "takes": [],
  "takes_decorator": [],
  "provides": [],
  "provides_decorator": [],
  "DataPipeline": {
    "__init__": [
      "self",
      "static_data_keys",
      "dynamic_items",
      "output_keys"
    ],
    "add_static_keys": [
      "self",
      "static_keys"
    ],
    "add_dynamic_items": [
      "self",
      "dynamic_items"
    ],
    "add_dynamic_item": [
      "self",
      "func",
      "takes",
      "provides"
    ],
    "_add_dynamic_item_object": [
      "self",
      "obj"
    ],
    "set_output_keys": [
      "self",
      "keys"
    ],
    "_output_keys_to_mapping": [
      "keys"
    ],
    "compute_outputs": [
      "self",
      "data"
    ],
    "compute_specific": [
      "self",
      "keys",
      "data"
    ],
    "_compute": [
      "self",
      "data",
      "order",
      "output_mapping"
    ],
    "get_selected_node_ids": [
      "self",
      "selected_keys"
    ],
    "__call__": [
      "self",
      "data"
    ],
    "_prepare_run": [
      "self",
      "data"
    ]
  },
  "split_fixed_chunks": [
    "x",
    "chunk_size",
    "dim"
  ],
  "split_wav_lens": [
    "chunk_lens",
    "wav_lens"
  ],
  "infer_dependency_matrix": [
    "model",
    "seq_shape",
    "in_stride"
  ],
  "plot_dependency_matrix": [
    "deps"
  ],
  "AMPConfig": {
    "from_name": [
      "self",
      "name"
    ]
  },
  "TorchAutocast": {
    "__init__": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "fwd_default_precision": [
    "fwd",
    "cast_inputs"
  ],
  "CircularDependencyError": {},
  "DGNode": [],
  "DependencyGraph": {
    "__init__": [
      "self"
    ],
    "get_unique_key": [],
    "add_node": [
      "self",
      "key",
      "data"
    ],
    "add_edge": [
      "self",
      "from_key",
      "to_key"
    ],
    "_get_ind_and_add_if_new": [
      "self",
      "key"
    ],
    "is_valid": [
      "self"
    ],
    "get_evaluation_order": [
      "self",
      "selected_keys"
    ],
    "_find_first_cycle": [
      "self"
    ],
    "__contains__": [
      "self",
      "key"
    ]
  },
  "max_seed_value": [],
  "min_seed_value": [],
  "seed_everything": [
    "seed",
    "verbose",
    "deterministic"
  ],
  "DynChunkTrainConfig": {
    "is_infinite_left_context": [
      "self"
    ],
    "left_context_size_frames": [
      "self"
    ]
  },
  "DynChunkTrainConfigRandomSampler": {
    "_sample_bool": [
      "self",
      "prob"
    ],
    "__call__": [
      "self",
      "stage"
    ]
  },
  "TrainLogger": {
    "log_stats": [
      "self",
      "stats_meta",
      "train_stats",
      "valid_stats",
      "test_stats",
      "verbose"
    ]
  },
  "FileTrainLogger": {
    "__init__": [
      "self",
      "save_file",
      "precision"
    ],
    "_item_to_string": [
      "self",
      "key",
      "value",
      "dataset"
    ],
    "_stats_to_string": [
      "self",
      "stats",
      "dataset"
    ],
    "log_stats": [
      "self",
      "stats_meta",
      "train_stats",
      "valid_stats",
      "test_stats",
      "verbose"
    ]
  },
  "TensorboardLogger": {
    "__init__": [
      "self",
      "save_dir"
    ],
    "log_stats": [
      "self",
      "stats_meta",
      "train_stats",
      "valid_stats",
      "test_stats",
      "verbose"
    ],
    "log_audio": [
      "self",
      "name",
      "value",
      "sample_rate"
    ],
    "log_figure": [
      "self",
      "name",
      "value"
    ]
  },
  "WandBLogger": {
    "__init__": [
      "self",
      "initializer"
    ],
    "log_stats": [
      "self",
      "stats_meta",
      "train_stats",
      "valid_stats",
      "test_stats",
      "verbose"
    ]
  },
  "_get_image_saver": [],
  "ProgressSampleLogger": {
    "_DEFAULT_FORMAT_DEFS": [],
    "DEFAULT_FORMAT": [],
    "__init__": [
      "self",
      "output_path",
      "formats",
      "format_defs",
      "batch_sample_size"
    ],
    "reset": [
      "self"
    ],
    "remember": [
      "self"
    ],
    "get_batch_sample": [
      "self",
      "value"
    ],
    "save": [
      "self",
      "epoch"
    ],
    "save_item": [
      "self",
      "key",
      "data",
      "epoch"
    ]
  },
  "plot_spectrogram": [
    "spectrogram",
    "ap",
    "fig_size",
    "output_fig"
  ],
  "detach": [
    "value"
  ],
  "CKPT_PREFIX": [],
  "METAFNAME": [],
  "PARAMFILE_EXT": [],
  "map_old_state_dict_weights": [
    "state_dict",
    "mapping"
  ],
  "hook_on_loading_state_dict_checkpoint": [
    "state_dict"
  ],
  "torch_recovery": [
    "obj",
    "path",
    "end_of_epoch"
  ],
  "torch_patched_state_dict_load": [
    "path",
    "device"
  ],
  "torch_save": [
    "obj",
    "path"
  ],
  "torch_parameter_transfer": [
    "obj",
    "path"
  ],
  "DEFAULT_LOAD_HOOKS": [],
  "DEFAULT_SAVE_HOOKS": [],
  "DEFAULT_TRANSFER_HOOKS": [],
  "mark_as_saver": [
    "method"
  ],
  "mark_as_loader": [
    "method"
  ],
  "mark_as_transfer": [
    "method"
  ],
  "register_checkpoint_hooks": [
    "cls",
    "save_on_main_only"
  ],
  "get_default_hook": [
    "obj",
    "default_hooks"
  ],
  "Checkpoint": [],
  "ckpt_recency": [
    "ckpt"
  ],
  "Checkpointer": {
    "__init__": [
      "self",
      "checkpoints_dir",
      "recoverables",
      "custom_load_hooks",
      "custom_save_hooks",
      "allow_partial_load"
    ],
    "add_recoverable": [
      "self",
      "name",
      "obj",
      "custom_load_hook",
      "custom_save_hook",
      "optional_load"
    ],
    "add_recoverables": [
      "self",
      "recoverables"
    ],
    "save_checkpoint": [
      "self",
      "meta",
      "end_of_epoch",
      "name",
      "verbosity"
    ],
    "save_and_keep_only": [
      "self",
      "meta",
      "end_of_epoch",
      "name",
      "num_to_keep",
      "keep_recent",
      "importance_keys",
      "max_keys",
      "min_keys",
      "ckpt_predicate",
      "verbosity"
    ],
    "find_checkpoint": [
      "self",
      "importance_key",
      "max_key",
      "min_key",
      "ckpt_predicate"
    ],
    "find_checkpoints": [
      "self",
      "importance_key",
      "max_key",
      "min_key",
      "ckpt_predicate",
      "max_num_checkpoints"
    ],
    "recover_if_possible": [
      "self",
      "importance_key",
      "max_key",
      "min_key",
      "ckpt_predicate"
    ],
    "load_checkpoint": [
      "self",
      "checkpoint"
    ],
    "list_checkpoints": [
      "self"
    ],
    "delete_checkpoints": [
      "self"
    ],
    "_delete_checkpoint": [
      "checkpoint",
      "verbosity"
    ],
    "_call_load_hooks": [
      "self",
      "checkpoint"
    ],
    "_list_checkpoint_dirs": [
      "self"
    ],
    "_construct_checkpoint_objects": [
      "checkpoint_dirs"
    ],
    "_is_checkpoint_dir": [
      "path"
    ],
    "_new_checkpoint_dirpath": [
      "self"
    ],
    "_custom_checkpoint_dirpath": [
      "self",
      "name"
    ],
    "_save_checkpoint_metafile": [
      "self",
      "fpath",
      "meta_to_include",
      "end_of_epoch"
    ]
  },
  "average_state_dicts": [
    "state_dicts"
  ],
  "average_checkpoints": [
    "checkpoint_list",
    "recoverable_name",
    "parameter_loader",
    "averager"
  ],
  "Pretrainer": {
    "__init__": [
      "self",
      "collect_in",
      "loadables",
      "paths",
      "custom_hooks",
      "conditions"
    ],
    "set_collect_in": [
      "self",
      "path"
    ],
    "add_loadables": [
      "self",
      "loadables"
    ],
    "add_paths": [
      "self",
      "paths"
    ],
    "add_custom_hooks": [
      "self",
      "custom_hooks"
    ],
    "add_conditions": [
      "self",
      "conditions"
    ],
    "split_path": [
      "path"
    ],
    "collect_files": [
      "self",
      "default_source",
      "use_auth_token",
      "local_strategy"
    ],
    "is_loadable": [
      "self",
      "name"
    ],
    "load_collected": [
      "self"
    ],
    "_call_load_hooks": [
      "self",
      "paramfiles"
    ]
  },
  "disable_cudnn_benchmarking": [],
  "disable_jit_profiling": [],
  "allow_tf32": [],
  "KNOWN_QUIRKS": [],
  "applied_quirks": [],
  "excluded_quirks": [],
  "apply_quirks": [],
  "log_applied_quirks": [],
  "accumulate_and_extract_features": [
    "batch",
    "features_list",
    "ssl_model",
    "ssl_layer_num",
    "device"
  ],
  "fetch_kmeans_model": [
    "n_clusters",
    "init",
    "max_iter",
    "batch_size",
    "tol",
    "max_no_improvement",
    "n_init",
    "reassignment_ratio",
    "random_state",
    "checkpoint_path"
  ],
  "process_chunks": [
    "data",
    "chunk_size",
    "model"
  ],
  "train": [
    "model",
    "train_set",
    "ssl_model",
    "save_path",
    "ssl_layer_num",
    "kmeans_batch_size",
    "device",
    "checkpoint_interval"
  ],
  "save_model": [
    "model",
    "checkpoint_path"
  ],
  "lengths_arg_exists": [
    "func"
  ],
  "LengthsCapableChain": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "x",
      "lengths"
    ],
    "append": [
      "self",
      "func"
    ],
    "__str__": [
      "self"
    ]
  },
  "Accuracy": [
    "log_probabilities",
    "targets",
    "length"
  ],
  "AccuracyStats": {
    "__init__": [
      "self"
    ],
    "append": [
      "self",
      "log_probabilities",
      "targets",
      "length"
    ],
    "summarize": [
      "self"
    ]
  },
  "cosine_similarity_matrix": [
    "a",
    "b",
    "eps"
  ],
  "undo_padding": [
    "batch",
    "lengths"
  ],
  "get_all_files": [
    "dirName",
    "match_and",
    "match_or",
    "exclude_and",
    "exclude_or"
  ],
  "get_list_from_csv": [
    "csvfile",
    "field",
    "delimiter",
    "skipinitialspace"
  ],
  "split_list": [
    "seq",
    "num"
  ],
  "recursive_items": [
    "dictionary"
  ],
  "recursive_update": [
    "d",
    "u",
    "must_match"
  ],
  "download_file": [
    "source",
    "dest",
    "unpack",
    "dest_unpack",
    "replace_existing",
    "write_permissions"
  ],
  "set_writing_permissions": [
    "folder_path"
  ],
  "pad_right_to": [
    "tensor",
    "target_shape",
    "mode",
    "value"
  ],
  "batch_pad_right": [
    "tensors",
    "mode",
    "value"
  ],
  "split_by_whitespace": [
    "text"
  ],
  "recursive_to": [
    "data"
  ],
  "np_str_obj_array_pattern": [],
  "mod_default_collate": [
    "batch"
  ],
  "split_path": [
    "path"
  ],
  "scalarize": [
    "value"
  ],
  "unsqueeze_as": [
    "x",
    "target"
  ],
  "pad_divisible": [
    "tensor",
    "length",
    "factor",
    "len_dim",
    "pad_value"
  ],
  "trim_to_shape": [
    "tensor",
    "shape"
  ],
  "trim_as": [
    "tensor",
    "other"
  ],
  "match_shape": [
    "tensor",
    "other"
  ],
  "batch_shuffle": [
    "items",
    "batch_size"
  ],
  "concat_padded_features": [
    "feats",
    "lens",
    "dim",
    "feats_slice_start",
    "feats_slice_end"
  ],
  "_offset_to_tensor": [
    "offset",
    "lengths"
  ],
  "_lens_to_boundaries": [
    "lengths",
    "slice_start",
    "slice_end",
    "cumulative"
  ],
  "_boundaries_to_mask": [
    "target",
    "start",
    "end",
    "len_dim"
  ],
  "unsqueeze_1d": [
    "value",
    "dim",
    "value_dim"
  ],
  "length_range": [
    "feats",
    "len_dim"
  ],
  "non_batch_dims": [
    "sample"
  ],
  "masked_mean": [
    "sample",
    "mask"
  ],
  "masked_std": [
    "sample",
    "mask"
  ],
  "masked_min": [
    "sample",
    "mask"
  ],
  "masked_max": [
    "sample",
    "mask"
  ],
  "dist_stats": [
    "sample",
    "mask"
  ],
  "dict_value_combinations": [
    "values"
  ],
  "dict_value_combinations_gen": [
    "values",
    "keys"
  ],
  "_last_n_layers": [
    "count"
  ],
  "TransformerWordEmbeddings": {
    "MSG_WORD": [],
    "DEFAULT_LAYERS": [],
    "__init__": [
      "self",
      "model",
      "tokenizer",
      "layers",
      "device"
    ],
    "forward": [
      "self",
      "sentence",
      "word"
    ],
    "embedding": [
      "self",
      "sentence",
      "word"
    ],
    "embeddings": [
      "self",
      "sentence"
    ],
    "batch_embeddings": [
      "self",
      "sentences"
    ],
    "_to_device": [
      "self",
      "encoded"
    ],
    "_tensor_to_device": [
      "self",
      "value"
    ],
    "_get_word_idx": [
      "self",
      "sent",
      "word"
    ],
    "_get_hidden_states": [
      "self",
      "states",
      "token_ids_word"
    ],
    "_get_word_vector": [
      "self",
      "encoded",
      "states",
      "idx"
    ],
    "to": [
      "self",
      "device"
    ]
  },
  "MissingTransformersError": {
    "MESSAGE": [],
    "__init__": [
      "self"
    ]
  },
  "_get_model": [
    "identifier"
  ],
  "_get_tokenizer": [
    "identifier"
  ],
  "expand_to_chars": [
    "emb",
    "seq",
    "seq_len",
    "word_separator"
  ],
  "NEGINFINITY": [],
  "BackoffNgramLM": {
    "__init__": [
      "self",
      "ngrams",
      "backoffs"
    ],
    "logprob": [
      "self",
      "token",
      "context"
    ]
  },
  "ngram_evaluation_details": [
    "data",
    "LM"
  ],
  "ngram_perplexity": [
    "eval_details",
    "logbase"
  ],
  "pad_ends": [
    "sequence",
    "pad_left",
    "left_pad_symbol",
    "right_pad_symbol"
  ],
  "ngrams": [
    "sequence",
    "n"
  ],
  "ngrams_for_evaluation": [
    "sequence",
    "max_n",
    "predict_first"
  ],
  "read_arpa": [
    "fstream"
  ],
  "_find_data_section": [
    "fstream"
  ],
  "_next_section_or_end": [
    "fstream"
  ],
  "_starts_ngrams_section": [
    "line"
  ],
  "_parse_order": [
    "line"
  ],
  "_ends_arpa": [
    "line"
  ],
  "arpa_to_fst": [
    "words_txt",
    "in_arpa",
    "out_fst",
    "ngram_order",
    "disambig_symbol",
    "cache"
  ],
  "EndToEndSLU": {
    "HPARAMS_NEEDED": [],
    "MODULES_NEEDED": [],
    "__init__": [
      "self"
    ],
    "decode_file": [
      "self",
      "path"
    ],
    "encode_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "decode_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "forward": [
      "self",
      "wavs",
      "wav_lens"
    ]
  },
  "SpeakerRecognition": {
    "MODULES_NEEDED": [],
    "__init__": [
      "self"
    ],
    "verify_batch": [
      "self",
      "wavs1",
      "wavs2",
      "wav1_lens",
      "wav2_lens",
      "threshold"
    ],
    "verify_files": [
      "self",
      "path_x",
      "path_y"
    ]
  },
  "EncoderDecoderASR": {
    "HPARAMS_NEEDED": [],
    "MODULES_NEEDED": [],
    "__init__": [
      "self"
    ],
    "transcribe_file": [
      "self",
      "path"
    ],
    "encode_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "transcribe_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "forward": [
      "self",
      "wavs",
      "wav_lens"
    ]
  },
  "EncoderASR": {
    "HPARAMS_NEEDED": [],
    "MODULES_NEEDED": [],
    "__init__": [
      "self"
    ],
    "set_decoding_function": [
      "self"
    ],
    "transcribe_file": [
      "self",
      "path"
    ],
    "encode_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "transcribe_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "forward": [
      "self",
      "wavs",
      "wav_lens"
    ]
  },
  "ASRWhisperSegment": {},
  "WhisperASR": {
    "HPARAMS_NEEDED": [],
    "MODULES_NEEDED": [],
    "TASKS": [],
    "__init__": [
      "self"
    ],
    "detect_language_file": [
      "self",
      "path"
    ],
    "detect_language_batch": [
      "self",
      "wav"
    ],
    "_detect_language": [
      "self",
      "mel",
      "task"
    ],
    "_get_audio_stream": [
      "self",
      "streamer",
      "frames_per_chunk"
    ],
    "transcribe_file_streaming": [
      "self",
      "path",
      "task",
      "initial_prompt",
      "logprob_threshold",
      "no_speech_threshold",
      "condition_on_previous_text",
      "verbose",
      "use_torchaudio_streaming",
      "chunk_size"
    ],
    "transcribe_file": [
      "self",
      "path",
      "task",
      "initial_prompt",
      "logprob_threshold",
      "no_speech_threshold",
      "condition_on_previous_text",
      "verbose",
      "use_torchaudio_streaming",
      "chunk_size"
    ],
    "encode_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "transcribe_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "forward": [
      "self",
      "wavs",
      "wav_lens"
    ]
  },
  "ASRStreamingContext": {},
  "StreamingASR": {
    "HPARAMS_NEEDED": [],
    "MODULES_NEEDED": [],
    "__init__": [
      "self"
    ],
    "_get_audio_stream": [
      "self",
      "streamer",
      "frames_per_chunk"
    ],
    "transcribe_file_streaming": [
      "self",
      "path",
      "dynchunktrain_config",
      "use_torchaudio_streaming"
    ],
    "transcribe_file": [
      "self",
      "path",
      "dynchunktrain_config",
      "use_torchaudio_streaming"
    ],
    "make_streaming_context": [
      "self",
      "dynchunktrain_config"
    ],
    "get_chunk_size_frames": [
      "self",
      "dynchunktrain_config"
    ],
    "encode_chunk": [
      "self",
      "context",
      "chunk",
      "chunk_len"
    ],
    "decode_chunk": [
      "self",
      "context",
      "x"
    ],
    "transcribe_chunk": [
      "self",
      "context",
      "chunk",
      "chunk_len"
    ]
  },
  "SNREstimator": {
    "MODULES_NEEDED": [],
    "HPARAMS_NEEDED": [],
    "estimate_batch": [
      "self",
      "mix",
      "predictions"
    ],
    "forward": [
      "self",
      "mix",
      "predictions"
    ],
    "gettrue_snrrange": [
      "self",
      "inp"
    ]
  },
  "foreign_class": [
    "source",
    "hparams_file",
    "pymodule_file",
    "classname",
    "overrides",
    "overrides_must_match",
    "savedir",
    "use_auth_token",
    "download_only",
    "huggingface_cache_dir",
    "local_strategy"
  ],
  "Pretrained": {
    "HPARAMS_NEEDED": [],
    "MODULES_NEEDED": [],
    "__init__": [
      "self",
      "modules",
      "hparams",
      "run_opts",
      "freeze_params"
    ],
    "_prepare_modules": [
      "self",
      "freeze_params"
    ],
    "load_audio": [
      "self",
      "path",
      "savedir"
    ],
    "_compile": [
      "self"
    ],
    "_compile_jit": [
      "self"
    ],
    "_wrap_distributed": [
      "self"
    ],
    "from_hparams": [
      "cls",
      "source",
      "hparams_file",
      "pymodule_file",
      "overrides",
      "savedir",
      "use_auth_token",
      "revision",
      "download_only",
      "huggingface_cache_dir",
      "overrides_must_match",
      "local_strategy"
    ]
  },
  "EncodeDecodePipelineMixin": {
    "create_pipelines": [
      "self"
    ],
    "_run_init_steps": [
      "self",
      "pipeline_definition"
    ],
    "_run_pipeline": [
      "self",
      "pipeline",
      "input",
      "batch"
    ],
    "_get_encode_pipeline_input": [
      "self",
      "input"
    ],
    "_get_decode_pipeline_input": [
      "self",
      "model_output"
    ],
    "_itemize": [
      "self",
      "pipeline_input"
    ],
    "to_dict": [
      "self",
      "data"
    ],
    "_get_value": [
      "self",
      "data",
      "key"
    ],
    "batch_inputs": [
      "self"
    ],
    "input_use_padded_data": [
      "self"
    ],
    "batch_outputs": [
      "self"
    ],
    "_collate": [
      "self",
      "data"
    ],
    "encode_input": [
      "self",
      "input"
    ],
    "decode_output": [
      "self",
      "output"
    ]
  },
  "EncoderClassifier": {
    "MODULES_NEEDED": [],
    "encode_batch": [
      "self",
      "wavs",
      "wav_lens",
      "normalize"
    ],
    "classify_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "classify_file": [
      "self",
      "path"
    ],
    "forward": [
      "self",
      "wavs",
      "wav_lens"
    ]
  },
  "AudioClassifier": {
    "classify_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "classify_file": [
      "self",
      "path",
      "savedir"
    ],
    "forward": [
      "self",
      "wavs",
      "wav_lens"
    ]
  },
  "VAD": {
    "HPARAMS_NEEDED": [],
    "MODULES_NEEDED": [],
    "__init__": [
      "self"
    ],
    "get_speech_prob_file": [
      "self",
      "audio_file",
      "large_chunk_size",
      "small_chunk_size",
      "overlap_small_chunk"
    ],
    "_manage_overlapped_chunks": [
      "self",
      "small_chunks_prob"
    ],
    "get_speech_prob_chunk": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "apply_threshold": [
      "self",
      "vad_prob",
      "activation_th",
      "deactivation_th"
    ],
    "get_boundaries": [
      "self",
      "prob_th",
      "output_value"
    ],
    "merge_close_segments": [
      "self",
      "boundaries",
      "close_th"
    ],
    "remove_short_segments": [
      "self",
      "boundaries",
      "len_th"
    ],
    "save_boundaries": [
      "self",
      "boundaries",
      "save_path",
      "print_boundaries",
      "audio_file"
    ],
    "energy_VAD": [
      "self",
      "audio_file",
      "boundaries",
      "activation_th",
      "deactivation_th",
      "eps"
    ],
    "create_chunks": [
      "self",
      "x",
      "chunk_size",
      "chunk_stride"
    ],
    "_get_audio_info": [
      "self",
      "audio_file"
    ],
    "upsample_VAD": [
      "self",
      "vad_out",
      "audio_file",
      "time_resolution"
    ],
    "upsample_boundaries": [
      "self",
      "boundaries",
      "audio_file"
    ],
    "double_check_speech_segments": [
      "self",
      "boundaries",
      "audio_file",
      "speech_th"
    ],
    "get_segments": [
      "self",
      "boundaries",
      "audio_file",
      "before_margin",
      "after_margin"
    ],
    "get_speech_segments": [
      "self",
      "audio_file",
      "large_chunk_size",
      "small_chunk_size",
      "overlap_small_chunk",
      "apply_energy_VAD",
      "double_check",
      "close_th",
      "len_th",
      "activation_th",
      "deactivation_th",
      "en_activation_th",
      "en_deactivation_th",
      "speech_th"
    ],
    "forward": [
      "self",
      "wavs",
      "wav_lens"
    ]
  },
  "SepformerSeparation": {
    "MODULES_NEEDED": [],
    "separate_batch": [
      "self",
      "mix"
    ],
    "separate_file": [
      "self",
      "path",
      "savedir"
    ],
    "forward": [
      "self",
      "mix"
    ]
  },
  "SpectralMaskEnhancement": {
    "HPARAMS_NEEDED": [],
    "MODULES_NEEDED": [],
    "compute_features": [
      "self",
      "wavs"
    ],
    "enhance_batch": [
      "self",
      "noisy",
      "lengths"
    ],
    "enhance_file": [
      "self",
      "filename",
      "output_filename"
    ]
  },
  "WaveformEnhancement": {
    "MODULES_NEEDED": [],
    "enhance_batch": [
      "self",
      "noisy",
      "lengths"
    ],
    "enhance_file": [
      "self",
      "filename",
      "output_filename"
    ],
    "forward": [
      "self",
      "noisy",
      "lengths"
    ]
  },
  "EncoderDecoderS2UT": {
    "HPARAMS_NEEDED": [],
    "MODULES_NEEDED": [],
    "__init__": [
      "self"
    ],
    "translate_file": [
      "self",
      "path"
    ],
    "encode_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "translate_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "forward": [
      "self",
      "wavs",
      "wav_lens"
    ]
  },
  "Speech_Emotion_Diarization": {
    "MODULES_NEEDED": [],
    "diarize_file": [
      "self",
      "path"
    ],
    "encode_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "diarize_batch": [
      "self",
      "wavs",
      "wav_lens",
      "batch_id"
    ],
    "preds_to_diarization": [
      "self",
      "prediction",
      "batch_id"
    ],
    "forward": [
      "self",
      "wavs",
      "wav_lens",
      "batch_id"
    ],
    "is_overlapped": [
      "self",
      "end1",
      "start2"
    ],
    "merge_ssegs_same_emotion_adjacent": [
      "self",
      "lol"
    ]
  },
  "GraphemeToPhoneme": {
    "INPUT_STATIC_KEYS": [],
    "OUTPUT_KEYS": [],
    "__init__": [
      "self"
    ],
    "phonemes": [
      "self"
    ],
    "language": [
      "self"
    ],
    "g2p": [
      "self",
      "text"
    ],
    "_remove_eos": [
      "self",
      "phonemes"
    ],
    "_update_graphemes": [
      "self",
      "model_inputs"
    ],
    "load_dependencies": [
      "self"
    ],
    "__call__": [
      "self",
      "text"
    ],
    "forward": [
      "self",
      "noisy",
      "lengths"
    ]
  },
  "ResponseGenerator": {
    "MODULES_NEEDED": [],
    "__init__": [
      "self"
    ],
    "generate_response": [
      "self",
      "turn"
    ],
    "prepare_input": [
      "self"
    ],
    "generate": [
      "self"
    ]
  },
  "GPTResponseGenerator": {
    "__init__": [
      "self"
    ],
    "generate": [
      "self",
      "inputs"
    ],
    "prepare_input": [
      "self"
    ]
  },
  "Llama2ResponseGenerator": {
    "__init__": [
      "self"
    ],
    "generate": [
      "self",
      "inputs"
    ],
    "prepare_input": [
      "self"
    ]
  },
  "PIQAudioInterpreter": {
    "__init__": [
      "self"
    ],
    "preprocess": [
      "self",
      "wavs"
    ],
    "classifier_forward": [
      "self",
      "X_stft_logpower"
    ],
    "invert_stft_with_phase": [
      "self",
      "X_int",
      "X_stft_phase"
    ],
    "interpret_batch": [
      "self",
      "wavs"
    ],
    "interpret_file": [
      "self",
      "path",
      "savedir"
    ],
    "forward": [
      "self",
      "wavs",
      "wav_lens"
    ]
  },
  "HIFIGAN": {
    "HPARAMS_NEEDED": [],
    "__init__": [
      "self"
    ],
    "decode_batch": [
      "self",
      "spectrogram",
      "mel_lens",
      "hop_len"
    ],
    "mask_noise": [
      "self",
      "waveform",
      "mel_lens",
      "hop_len"
    ],
    "decode_spectrogram": [
      "self",
      "spectrogram"
    ],
    "forward": [
      "self",
      "spectrogram"
    ]
  },
  "DiffWaveVocoder": {
    "HPARAMS_NEEDED": [],
    "__init__": [
      "self"
    ],
    "decode_batch": [
      "self",
      "mel",
      "hop_len",
      "mel_lens",
      "fast_sampling",
      "fast_sampling_noise_schedule"
    ],
    "mask_noise": [
      "self",
      "waveform",
      "mel_lens",
      "hop_len"
    ],
    "decode_spectrogram": [
      "self",
      "spectrogram",
      "hop_len",
      "fast_sampling",
      "fast_sampling_noise_schedule"
    ],
    "forward": [
      "self",
      "spectrogram"
    ]
  },
  "UnitHIFIGAN": {
    "HPARAMS_NEEDED": [],
    "__init__": [
      "self"
    ],
    "decode_batch": [
      "self",
      "units",
      "spk"
    ],
    "decode_unit": [
      "self",
      "units",
      "spk"
    ],
    "forward": [
      "self",
      "units",
      "spk"
    ]
  },
  "WaveformEncoder": {
    "MODULES_NEEDED": [],
    "encode_file": [
      "self",
      "path"
    ],
    "encode_batch": [
      "self",
      "wavs",
      "wav_lens"
    ],
    "forward": [
      "self",
      "wavs",
      "wav_lens"
    ]
  },
  "MelSpectrogramEncoder": {
    "MODULES_NEEDED": [],
    "dynamic_range_compression": [
      "self",
      "x",
      "C",
      "clip_val"
    ],
    "mel_spectogram": [
      "self",
      "audio"
    ],
    "encode_waveform": [
      "self",
      "wav"
    ],
    "encode_mel_spectrogram": [
      "self",
      "mel_spec"
    ],
    "encode_mel_spectrogram_batch": [
      "self",
      "mel_specs",
      "lens"
    ],
    "__forward": [
      "self",
      "mel_specs",
      "lens"
    ]
  },
  "MSTacotron2": {
    "HPARAMS_NEEDED": [],
    "__init__": [
      "self"
    ],
    "__text_to_seq": [
      "self",
      "txt"
    ],
    "clone_voice": [
      "self",
      "texts",
      "audio_path"
    ],
    "generate_random_voice": [
      "self",
      "texts"
    ],
    "__encode_batch": [
      "self",
      "texts",
      "spk_embs"
    ],
    "__sample_random_speaker": [
      "self"
    ]
  },
  "FastSpeech2InternalAlignment": {
    "HPARAMS_NEEDED": [],
    "__init__": [
      "self"
    ],
    "encode_text": [
      "self",
      "texts",
      "pace",
      "pitch_rate",
      "energy_rate"
    ],
    "_g2p_keep_punctuations": [
      "self",
      "g2p_model",
      "text"
    ],
    "encode_phoneme": [
      "self",
      "phonemes",
      "pace",
      "pitch_rate",
      "energy_rate"
    ],
    "encode_batch": [
      "self",
      "tokens_padded",
      "pace",
      "pitch_rate",
      "energy_rate"
    ],
    "forward": [
      "self",
      "text",
      "pace",
      "pitch_rate",
      "energy_rate"
    ]
  },
  "_update_mem": [
    "inp_tokens",
    "memory"
  ],
  "inflate_tensor": [
    "tensor",
    "times",
    "dim"
  ],
  "mask_by_condition": [
    "tensor",
    "cond",
    "fill_value"
  ],
  "batch_filter_seq2seq_output": [
    "prediction",
    "eos_id"
  ],
  "filter_seq2seq_output": [
    "string_pred",
    "eos_id"
  ],
  "BaseScorerInterface": {
    "score": [
      "self",
      "inp_tokens",
      "memory",
      "candidates",
      "attn"
    ],
    "permute_mem": [
      "self",
      "memory",
      "index"
    ],
    "reset_mem": [
      "self",
      "x",
      "enc_lens"
    ]
  },
  "CTCScorer": {
    "__init__": [
      "self",
      "ctc_fc",
      "blank_index",
      "eos_index",
      "ctc_window_size"
    ],
    "score": [
      "self",
      "inp_tokens",
      "memory",
      "candidates",
      "attn"
    ],
    "permute_mem": [
      "self",
      "memory",
      "index"
    ],
    "reset_mem": [
      "self",
      "x",
      "enc_lens"
    ]
  },
  "RNNLMScorer": {
    "__init__": [
      "self",
      "language_model",
      "temperature"
    ],
    "score": [
      "self",
      "inp_tokens",
      "memory",
      "candidates",
      "attn"
    ],
    "permute_mem": [
      "self",
      "memory",
      "index"
    ],
    "reset_mem": [
      "self",
      "x",
      "enc_lens"
    ]
  },
  "TransformerLMScorer": {
    "__init__": [
      "self",
      "language_model",
      "temperature"
    ],
    "score": [
      "self",
      "inp_tokens",
      "memory",
      "candidates",
      "attn"
    ],
    "permute_mem": [
      "self",
      "memory",
      "index"
    ],
    "reset_mem": [
      "self",
      "x",
      "enc_lens"
    ]
  },
  "KenLMScorer": {
    "__init__": [
      "self",
      "lm_path",
      "vocab_size",
      "token_list"
    ],
    "score": [
      "self",
      "inp_tokens",
      "memory",
      "candidates",
      "attn"
    ],
    "permute_mem": [
      "self",
      "memory",
      "index"
    ],
    "reset_mem": [
      "self",
      "x",
      "enc_lens"
    ]
  },
  "CoverageScorer": {
    "__init__": [
      "self",
      "vocab_size",
      "threshold"
    ],
    "score": [
      "self",
      "inp_tokens",
      "coverage",
      "candidates",
      "attn"
    ],
    "permute_mem": [
      "self",
      "coverage",
      "index"
    ],
    "reset_mem": [
      "self",
      "x",
      "enc_lens"
    ]
  },
  "LengthScorer": {
    "__init__": [
      "self",
      "vocab_size"
    ],
    "score": [
      "self",
      "inp_tokens",
      "memory",
      "candidates",
      "attn"
    ]
  },
  "ScorerBuilder": {
    "__init__": [
      "self",
      "weights",
      "full_scorers",
      "partial_scorers",
      "scorer_beam_scale"
    ],
    "score": [
      "self",
      "inp_tokens",
      "memory",
      "attn",
      "log_probs",
      "beam_size"
    ],
    "permute_scorer_mem": [
      "self",
      "memory",
      "index",
      "candidates"
    ],
    "reset_scorer_mem": [
      "self",
      "x",
      "enc_lens"
    ],
    "_validate_scorer": [
      "self",
      "scorer_names"
    ]
  },
  "BaseRescorerInterface": {
    "normalize_text": [
      "self",
      "text"
    ],
    "preprocess_func": [
      "self",
      "hyps"
    ],
    "rescore_hyps": [
      "self",
      "hyps"
    ],
    "to_device": [
      "self",
      "device"
    ]
  },
  "RNNLMRescorer": {
    "__init__": [
      "self",
      "language_model",
      "tokenizer",
      "device",
      "temperature",
      "bos_index",
      "eos_index",
      "pad_index"
    ],
    "normalize_text": [
      "self",
      "text"
    ],
    "to_device": [
      "self",
      "device"
    ],
    "preprocess_func": [
      "self",
      "topk_hyps"
    ],
    "rescore_hyps": [
      "self",
      "topk_hyps"
    ]
  },
  "TransformerLMRescorer": {
    "__init__": [
      "self",
      "language_model",
      "tokenizer",
      "device",
      "temperature",
      "bos_index",
      "eos_index",
      "pad_index"
    ],
    "normalize_text": [
      "self",
      "text"
    ],
    "to_device": [
      "self",
      "device"
    ],
    "preprocess_func": [
      "self",
      "topk_hyps"
    ],
    "rescore_hyps": [
      "self",
      "topk_hyps"
    ]
  },
  "HuggingFaceLMRescorer": {
    "__init__": [
      "self",
      "model_name",
      "device"
    ],
    "to_device": [
      "self",
      "device"
    ],
    "normalize_text": [
      "self",
      "text"
    ],
    "_add_special_tokens": [
      "self",
      "text"
    ],
    "preprocess_func": [
      "self",
      "topk_hyps"
    ],
    "rescore_hyps": [
      "self",
      "topk_hyps"
    ]
  },
  "RescorerBuilder": {
    "__init__": [
      "self",
      "weights",
      "rescorers"
    ],
    "rescore": [
      "self",
      "topk_candidates",
      "topk_scores"
    ],
    "_validate_scorer": [
      "self",
      "rescorer_names"
    ],
    "move_rescorers_to_device": [
      "self",
      "device"
    ]
  },
  "load_unigram_set_from_arpa": [
    "arpa_path"
  ],
  "KenlmState": {
    "__init__": [
      "self",
      "state"
    ],
    "state": [
      "self"
    ]
  },
  "_prepare_unigram_set": [
    "unigrams",
    "kenlm_model"
  ],
  "_get_empty_lm_state": [],
  "LanguageModel": {
    "__init__": [
      "self",
      "kenlm_model",
      "unigrams",
      "alpha",
      "beta",
      "unk_score_offset",
      "score_boundary"
    ],
    "order": [
      "self"
    ],
    "get_start_state": [
      "self"
    ],
    "_get_raw_end_score": [
      "self",
      "start_state"
    ],
    "score_partial_token": [
      "self",
      "partial_token"
    ],
    "score": [
      "self",
      "prev_state",
      "word",
      "is_last_word"
    ]
  },
  "TransducerGreedySearcherStreamingContext": {},
  "TransducerBeamSearcher": {
    "__init__": [
      "self",
      "decode_network_lst",
      "tjoint",
      "classifier_network",
      "blank_id",
      "beam_size",
      "nbest",
      "lm_module",
      "lm_weight",
      "state_beam",
      "expand_beam"
    ],
    "forward": [
      "self",
      "tn_output"
    ],
    "transducer_greedy_decode": [
      "self",
      "tn_output",
      "hidden_state",
      "return_hidden"
    ],
    "transducer_greedy_decode_streaming": [
      "self",
      "x",
      "context"
    ],
    "transducer_beam_search_decode": [
      "self",
      "tn_output"
    ],
    "_joint_forward_step": [
      "self",
      "h_i",
      "out_PN"
    ],
    "_lm_forward_step": [
      "self",
      "inp_tokens",
      "memory"
    ],
    "_get_sentence_to_update": [
      "self",
      "selected_sentences",
      "output_PN",
      "hidden"
    ],
    "_update_hiddens": [
      "self",
      "selected_sentences",
      "updated_hidden",
      "hidden"
    ],
    "_forward_PN": [
      "self",
      "out_PN",
      "decode_network_lst",
      "hidden"
    ],
    "_forward_after_joint": [
      "self",
      "out",
      "classifier_network"
    ]
  },
  "get_transducer_key": [
    "x"
  ],
  "AlivedHypotheses": {
    "__init__": [
      "self",
      "alived_seq",
      "alived_log_probs",
      "sequence_scores"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__str__": [
      "self"
    ]
  },
  "S2SBaseSearcher": {
    "__init__": [
      "self",
      "bos_index",
      "eos_index",
      "min_decode_ratio",
      "max_decode_ratio"
    ],
    "forward": [
      "self",
      "enc_states",
      "wav_len"
    ],
    "forward_step": [
      "self",
      "inp_tokens",
      "memory",
      "enc_states",
      "enc_lens"
    ],
    "reset_mem": [
      "self",
      "batch_size",
      "device"
    ],
    "change_max_decoding_length": [
      "self",
      "min_decode_steps",
      "max_decode_steps"
    ],
    "set_n_out": [
      "self"
    ],
    "_check_end_condition": [
      "self",
      "memory"
    ]
  },
  "S2SGreedySearcher": {
    "forward": [
      "self",
      "enc_states",
      "wav_len"
    ],
    "_get_top_prediction": [
      "self",
      "hyps",
      "scores",
      "log_probs"
    ]
  },
  "S2STransformerGreedySearcher": {
    "__init__": [
      "self",
      "modules",
      "temperature"
    ],
    "reset_mem": [
      "self",
      "batch_size",
      "device"
    ],
    "forward_step": [
      "self",
      "inp_tokens",
      "memory",
      "enc_states",
      "enc_lens"
    ]
  },
  "S2SWhisperGreedySearcher": {
    "__init__": [
      "self",
      "model",
      "temperature",
      "use_kv_cache",
      "suppress_blank",
      "suppress_tokens",
      "sample_len",
      "prefix",
      "prompt"
    ],
    "set_lang_tokens": [
      "self",
      "lang_tokens"
    ],
    "set_task": [
      "self",
      "task"
    ],
    "set_prompt": [
      "self",
      "prompt"
    ],
    "get_tokens_to_suppress": [
      "self"
    ],
    "_get_initial_tokens": [
      "self"
    ],
    "reset_mem": [
      "self",
      "batch_size",
      "device"
    ],
    "forward_step": [
      "self",
      "inp_tokens",
      "memory",
      "enc_states",
      "enc_lens"
    ],
    "_check_end_condition": [
      "self",
      "memory"
    ]
  },
  "S2SRNNGreedySearcher": {
    "__init__": [
      "self",
      "embedding",
      "decoder",
      "linear",
      "temperature"
    ],
    "reset_mem": [
      "self",
      "batch_size",
      "device"
    ],
    "forward_step": [
      "self",
      "inp_tokens",
      "memory",
      "enc_states",
      "enc_lens"
    ]
  },
  "S2SBeamSearcher": {
    "__init__": [
      "self",
      "bos_index",
      "eos_index",
      "min_decode_ratio",
      "max_decode_ratio",
      "beam_size",
      "scorer",
      "return_topk",
      "topk",
      "using_eos_threshold",
      "eos_threshold",
      "length_normalization",
      "using_max_attn_shift",
      "max_attn_shift",
      "minus_inf"
    ],
    "_check_full_beams": [
      "self",
      "hyps"
    ],
    "_check_attn_shift": [
      "self",
      "attn",
      "prev_attn_peak"
    ],
    "_check_eos_threshold": [
      "self",
      "log_probs"
    ],
    "init_hypotheses": [
      "self"
    ],
    "_attn_weight_step": [
      "self",
      "inp_tokens",
      "memory",
      "enc_states",
      "enc_lens",
      "attn",
      "log_probs"
    ],
    "_max_attn_shift_step": [
      "self",
      "attn",
      "prev_attn_peak",
      "log_probs"
    ],
    "_scorer_step": [
      "self",
      "inp_tokens",
      "scorer_memory",
      "attn",
      "log_probs"
    ],
    "_set_eos_minus_inf_step": [
      "self",
      "log_probs",
      "step",
      "min_decode_steps"
    ],
    "_eos_threshold_step": [
      "self",
      "log_probs"
    ],
    "_attn_weight_permute_memory_step": [
      "self",
      "memory",
      "predecessors"
    ],
    "_scorer_permute_memory_step": [
      "self",
      "scorer_memory",
      "predecessors",
      "candidates"
    ],
    "_max_attn_shift_permute_memory_step": [
      "self",
      "prev_attn_peak",
      "predecessors"
    ],
    "_update_reset_memory": [
      "self",
      "enc_states",
      "enc_lens"
    ],
    "_update_permute_memory": [
      "self",
      "memory",
      "scorer_memory",
      "predecessors",
      "candidates",
      "prev_attn_peak"
    ],
    "_update_sequences_and_log_probs": [
      "self",
      "log_probs",
      "inp_tokens",
      "predecessors",
      "candidates",
      "alived_hyps"
    ],
    "_compute_scores_and_next_inp_tokens": [
      "self",
      "alived_hyps",
      "log_probs",
      "step"
    ],
    "init_beam_search_data": [
      "self",
      "enc_states",
      "wav_len"
    ],
    "_update_hyps_and_scores_if_eos_token": [
      "self",
      "inp_tokens",
      "alived_hyps",
      "eos_hyps_and_log_probs_scores",
      "scores"
    ],
    "_get_topk_prediction": [
      "self",
      "eos_hyps_and_log_probs_scores"
    ],
    "search_step": [
      "self",
      "alived_hyps",
      "inp_tokens",
      "log_probs",
      "eos_hyps_and_log_probs_scores",
      "memory",
      "scorer_memory",
      "attn",
      "prev_attn_peak",
      "enc_states",
      "enc_lens",
      "step"
    ],
    "_fill_alived_hyps_with_eos_token": [
      "self",
      "alived_hyps",
      "eos_hyps_and_log_probs_scores",
      "scores"
    ],
    "forward": [
      "self",
      "enc_states",
      "wav_len"
    ],
    "_check_end_condition": [
      "self",
      "alived_hyps"
    ],
    "permute_mem": [
      "self",
      "memory",
      "index"
    ]
  },
  "S2SRNNBeamSearcher": {
    "__init__": [
      "self",
      "embedding",
      "decoder",
      "linear",
      "temperature"
    ],
    "reset_mem": [
      "self",
      "batch_size",
      "device"
    ],
    "forward_step": [
      "self",
      "inp_tokens",
      "memory",
      "enc_states",
      "enc_lens"
    ],
    "permute_mem": [
      "self",
      "memory",
      "index"
    ]
  },
  "S2STransformerBeamSearcher": {
    "__init__": [
      "self",
      "modules",
      "temperature"
    ],
    "reset_mem": [
      "self",
      "batch_size",
      "device"
    ],
    "permute_mem": [
      "self",
      "memory",
      "index"
    ],
    "forward_step": [
      "self",
      "inp_tokens",
      "memory",
      "enc_states",
      "enc_lens"
    ]
  },
  "S2SWhisperBeamSearcher": {
    "__init__": [
      "self",
      "module",
      "temperature",
      "use_kv_cache",
      "suppress_blank",
      "suppress_tokens",
      "sample_len",
      "prefix",
      "prompt"
    ],
    "set_lang_tokens": [
      "self",
      "lang_tokens"
    ],
    "set_task": [
      "self",
      "task"
    ],
    "set_prompt": [
      "self",
      "prompt"
    ],
    "get_tokens_to_suppress": [
      "self"
    ],
    "_get_initial_tokens": [
      "self"
    ],
    "reset_mem": [
      "self",
      "batch_size",
      "device"
    ],
    "permute_mem": [
      "self",
      "memory",
      "index"
    ],
    "_reorder_cache": [
      "self",
      "past_key_values",
      "beam_idx"
    ],
    "set_n_out": [
      "self"
    ],
    "forward_step": [
      "self",
      "inp_tokens",
      "memory",
      "enc_states",
      "enc_lens"
    ],
    "_check_end_condition": [
      "self",
      "alived_hyps"
    ]
  },
  "S2SHFTextBasedBeamSearcher": {
    "__init__": [
      "self",
      "modules",
      "vocab_size"
    ],
    "forward_step": [
      "self",
      "inp_tokens",
      "memory",
      "enc_states",
      "enc_lens"
    ],
    "set_n_out": [
      "self"
    ]
  },
  "CTCPrefixScore": {
    "__init__": [
      "self",
      "x",
      "enc_lens",
      "blank_index",
      "eos_index",
      "ctc_window_size"
    ],
    "forward_step": [
      "self",
      "inp_tokens",
      "states",
      "candidates",
      "attn"
    ],
    "permute_mem": [
      "self",
      "memory",
      "index"
    ]
  },
  "filter_ctc_output": [
    "string_pred",
    "blank_id"
  ],
  "ctc_greedy_decode": [
    "probabilities",
    "seq_lens",
    "blank_id"
  ],
  "CTCBeam": {
    "from_lm_beam": [
      "self",
      "lm_beam"
    ],
    "step": [
      "self"
    ]
  },
  "LMCTCBeam": {},
  "CTCHypothesis": {},
  "CTCBaseSearcher": {
    "__init__": [
      "self",
      "blank_index",
      "vocab_list",
      "space_token",
      "kenlm_model_path",
      "unigrams",
      "alpha",
      "beta",
      "unk_score_offset",
      "score_boundary",
      "beam_size",
      "beam_prune_logp",
      "token_prune_min_logp",
      "prune_history",
      "blank_skip_threshold",
      "topk",
      "spm_token"
    ],
    "partial_decoding": [
      "self",
      "log_probs",
      "beams",
      "cached_lm_scores",
      "cached_p_lm_scores",
      "processed_frames"
    ],
    "normalize_whitespace": [
      "self",
      "text"
    ],
    "merge_tokens": [
      "self",
      "token_1",
      "token_2"
    ],
    "merge_beams": [
      "self",
      "beams"
    ],
    "sort_beams": [
      "self",
      "beams"
    ],
    "_prune_history": [
      "self",
      "beams",
      "lm_order"
    ],
    "finalize_decoding": [
      "self",
      "beams",
      "cached_lm_scores",
      "cached_p_lm_scores",
      "force_next_word",
      "is_end"
    ],
    "decode_beams": [
      "self",
      "log_probs",
      "wav_lens",
      "lm_start_state"
    ],
    "__call__": [
      "self",
      "log_probs",
      "wav_lens",
      "lm_start_state"
    ],
    "partial_decode_beams": [
      "self",
      "log_probs",
      "cached_lm_scores",
      "cached_p_lm_scores",
      "beams",
      "processed_frames",
      "force_next_word",
      "is_end"
    ],
    "decode_log_probs": [
      "self",
      "log_probs",
      "wav_len",
      "lm_start_state"
    ]
  },
  "CTCBeamSearcher": {
    "get_lm_beams": [
      "self",
      "beams",
      "cached_lm_scores",
      "cached_partial_token_scores",
      "is_eos"
    ],
    "partial_decoding": [
      "self",
      "log_probs",
      "wav_len",
      "beams",
      "cached_lm_scores",
      "cached_p_lm_scores",
      "processed_frames"
    ]
  },
  "CTCPrefixBeamSearcher": {
    "get_lm_beams": [
      "self",
      "beams",
      "cached_lm_scores",
      "cached_partial_token_scores",
      "is_eos"
    ],
    "_get_new_beam": [
      "self",
      "frame_index",
      "new_prefix",
      "new_token",
      "new_token_index",
      "beams",
      "p",
      "previous_beam"
    ],
    "partial_decoding": [
      "self",
      "log_probs",
      "wav_len",
      "beams",
      "cached_lm_scores",
      "cached_p_lm_scores",
      "processed_frames"
    ]
  },
  "TorchAudioCTCPrefixBeamSearcher": {
    "__init__": [
      "self",
      "tokens",
      "lexicon",
      "lm",
      "lm_dict",
      "topk",
      "beam_size",
      "beam_size_token",
      "beam_threshold",
      "lm_weight",
      "word_score",
      "unk_score",
      "sil_score",
      "log_add",
      "blank_index",
      "sil_index",
      "unk_word",
      "using_cpu_decoder",
      "blank_skip_threshold"
    ],
    "decode_beams": [
      "self",
      "log_probs",
      "wav_len"
    ],
    "__call__": [
      "self",
      "log_probs",
      "wav_len"
    ]
  }
}