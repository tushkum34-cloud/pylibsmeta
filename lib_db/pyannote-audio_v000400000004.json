{
  "__version__": [],
  "__all__": [],
  "Subset": {
    "train": [],
    "development": [],
    "test": []
  },
  "Device": {
    "CPU": [],
    "CUDA": [],
    "MPS": [],
    "AUTO": []
  },
  "NumSpeakers": {
    "ORACLE": [],
    "AUTO": []
  },
  "Metric": {
    "DiarizationErrorRate": [],
    "JaccardErrorRate": [],
    "from_str": [
      "cls",
      "metric"
    ]
  },
  "parse_device": [
    "device"
  ],
  "get_diarization": [
    "prediction"
  ],
  "app": [],
  "optimize": [
    "pipeline",
    "protocol",
    "subset",
    "device",
    "registry",
    "max_iterations",
    "num_speakers",
    "metric"
  ],
  "download": [
    "pipeline",
    "revision",
    "token",
    "cache"
  ],
  "apply": [
    "pipeline",
    "audio",
    "into",
    "revision",
    "token",
    "cache",
    "device"
  ],
  "MinDurationOffOptimizer": {
    "_compute_metric": [
      "self",
      "files",
      "metric",
      "collar"
    ],
    "__call__": [
      "self",
      "files",
      "metric",
      "bounds"
    ]
  },
  "benchmark": [
    "pipeline",
    "protocol",
    "into",
    "subset",
    "revision",
    "token",
    "cache",
    "device",
    "registry",
    "num_speakers",
    "optimize",
    "progress",
    "per_file"
  ],
  "strip": [
    "checkpoint",
    "into"
  ],
  "CONFIG_FILE": [],
  "OTLP_ENDPOINT": [],
  "OTLP_HEADERS": [],
  "SESSION_ID": [],
  "DEFAULT_LOG_LEVEL": [],
  "exporter": [],
  "reader": [],
  "provider": [],
  "meter": [],
  "model_init_counter": [],
  "track_model_init": [
    "model"
  ],
  "pipeline_init_counter": [],
  "track_pipeline_init": [
    "pipeline"
  ],
  "file_duration_bucket": [],
  "track_pipeline_apply": [
    "pipeline",
    "file",
    "num_speakers",
    "min_speakers",
    "max_speakers"
  ],
  "is_metrics_enabled": [],
  "_save_metrics_config": [
    "enabled"
  ],
  "set_telemetry_metrics": [
    "enabled",
    "save_choice_as_default"
  ],
  "set_opentelemetry_log_level": [
    "level"
  ],
  "DiarizationErrorRate": {
    "higher_is_better": [],
    "is_differentiable": [],
    "__init__": [
      "self",
      "threshold"
    ],
    "update": [
      "self",
      "preds",
      "target"
    ],
    "compute": [
      "self"
    ]
  },
  "SegmentationErrorRate": {
    "__init__": [
      "self",
      "window_size",
      "step_size",
      "threshold"
    ],
    "update": [
      "self",
      "preds",
      "target"
    ]
  },
  "SpeakerConfusionRate": {
    "higher_is_better": [],
    "compute": [
      "self"
    ]
  },
  "DiarizationPrecision": {
    "higher_is_better": [],
    "compute": [
      "self"
    ]
  },
  "DiarizationRecall": {
    "higher_is_better": [],
    "compute": [
      "self"
    ]
  },
  "FalseAlarmRate": {
    "higher_is_better": [],
    "compute": [
      "self"
    ]
  },
  "MissedDetectionRate": {
    "higher_is_better": [],
    "compute": [
      "self"
    ]
  },
  "DetectionErrorRate": {
    "higher_is_better": [],
    "compute": [
      "self"
    ]
  },
  "OptimalDiarizationErrorRate": {
    "higher_is_better": [],
    "is_differentiable": [],
    "__init__": [
      "self",
      "threshold"
    ],
    "update": [
      "self",
      "preds",
      "target"
    ],
    "compute": [
      "self"
    ]
  },
  "OptimalDiarizationErrorRateThreshold": {
    "higher_is_better": [],
    "compute": [
      "self"
    ]
  },
  "OptimalSpeakerConfusionRate": {
    "higher_is_better": [],
    "compute": [
      "self"
    ]
  },
  "OptimalFalseAlarmRate": {
    "higher_is_better": [],
    "compute": [
      "self"
    ]
  },
  "OptimalMissedDetectionRate": {
    "higher_is_better": [],
    "compute": [
      "self"
    ]
  },
  "EqualErrorRate": {
    "__init__": [
      "self",
      "distances",
      "compute_on_cpu"
    ],
    "update": [
      "self",
      "scores",
      "y_true"
    ],
    "compute": [
      "self"
    ]
  },
  "_der_update": [
    "preds",
    "target",
    "threshold",
    "reduce"
  ],
  "_der_compute": [
    "false_alarm",
    "missed_detection",
    "speaker_confusion",
    "speech_total"
  ],
  "diarization_error_rate": [
    "preds",
    "target",
    "threshold",
    "reduce",
    "return_components"
  ],
  "optimal_diarization_error_rate": [
    "preds",
    "target",
    "threshold"
  ],
  "load_stm": [
    "file_stm"
  ],
  "_sample": [
    "uri"
  ],
  "SAMPLE_FILE": [],
  "register_augmentation": [
    "augmentation",
    "module",
    "when"
  ],
  "unregister_augmentation": [
    "module",
    "when"
  ],
  "wrap_augmentation": [
    "augmentation",
    "model",
    "when"
  ],
  "TorchAudiomentationsWaveformTransformWrapper": {
    "__init__": [
      "self",
      "augmentation",
      "model",
      "when"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "_": [
    "augmentation",
    "model",
    "when"
  ],
  "MixSpeakerDiarization": {
    "supported_modes": [],
    "supports_multichannel": [],
    "requires_sample_rate": [],
    "supports_target": [],
    "requires_target": [],
    "__init__": [
      "self",
      "min_snr_in_db",
      "max_snr_in_db",
      "mode",
      "p",
      "p_mode",
      "sample_rate",
      "target_rate",
      "max_num_speakers",
      "output_type"
    ],
    "randomize_parameters": [
      "self",
      "samples",
      "sample_rate",
      "targets",
      "target_rate"
    ]
  },
  "probe": [
    "trunk",
    "branches"
  ],
  "LowerTemporalResolution": {
    "preprocessed_key": [],
    "__init__": [
      "self",
      "resolution"
    ],
    "__call__": [
      "self",
      "current_file"
    ]
  },
  "DeriveMetaLabels": {
    "__init__": [
      "self",
      "classes",
      "unions",
      "intersections"
    ],
    "all_classes": [
      "self"
    ],
    "__call__": [
      "self",
      "current_file"
    ]
  },
  "Waveform": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "file"
    ]
  },
  "SampleRate": {
    "__call__": [
      "self",
      "file"
    ]
  },
  "binarize": [
    "scores",
    "onset",
    "offset",
    "initial_state"
  ],
  "binarize_ndarray": [
    "scores",
    "onset",
    "offset",
    "initial_state"
  ],
  "binarize_swf": [
    "scores",
    "onset",
    "offset",
    "initial_state"
  ],
  "Binarize": {
    "__init__": [
      "self",
      "onset",
      "offset",
      "min_duration_on",
      "min_duration_off",
      "pad_onset",
      "pad_offset"
    ],
    "__call__": [
      "self",
      "scores"
    ]
  },
  "Peak": {
    "__init__": [
      "self",
      "alpha",
      "min_duration"
    ],
    "__call__": [
      "self",
      "scores"
    ]
  },
  "interpolate": [
    "target",
    "weight"
  ],
  "binary_cross_entropy": [
    "prediction",
    "target",
    "weight"
  ],
  "mse_loss": [
    "prediction",
    "target",
    "weight"
  ],
  "nll_loss": [
    "prediction",
    "target",
    "class_weight",
    "weight"
  ],
  "ReproducibilityError": {},
  "ReproducibilityWarning": {},
  "raise_reproducibility": [
    "device"
  ],
  "warn_reproducibility": [
    "device"
  ],
  "fix_reproducibility": [
    "device"
  ],
  "Powerset": {
    "__init__": [
      "self",
      "num_classes",
      "max_set_size"
    ],
    "powerset_classes": [
      "self"
    ],
    "num_powerset_classes": [
      "self"
    ],
    "build_mapping": [
      "self"
    ],
    "build_cardinality": [
      "self"
    ],
    "to_multilabel": [
      "self",
      "powerset",
      "soft"
    ],
    "forward": [
      "self",
      "powerset",
      "soft"
    ],
    "to_powerset": [
      "self",
      "multilabel"
    ],
    "_permutation_powerset": [
      "self",
      "multilabel_permutation"
    ],
    "permutation_mapping": [
      "self"
    ]
  },
  "conv1d_num_frames": [
    "num_samples",
    "kernel_size",
    "stride",
    "padding",
    "dilation"
  ],
  "multi_conv_num_frames": [
    "num_samples",
    "kernel_size",
    "stride",
    "padding",
    "dilation"
  ],
  "conv1d_receptive_field_size": [
    "num_frames",
    "kernel_size",
    "stride",
    "padding",
    "dilation"
  ],
  "multi_conv_receptive_field_size": [
    "num_frames",
    "kernel_size",
    "stride",
    "padding",
    "dilation"
  ],
  "conv1d_receptive_field_center": [
    "frame",
    "kernel_size",
    "stride",
    "padding",
    "dilation"
  ],
  "multi_conv_receptive_field_center": [
    "frame",
    "kernel_size",
    "stride",
    "padding",
    "dilation"
  ],
  "map_with_specifications": [
    "specifications",
    "func"
  ],
  "listen": [
    "audio_file",
    "segment"
  ],
  "preview": [
    "audio_file",
    "segment",
    "zoom",
    "video_fps",
    "video_ext",
    "display"
  ],
  "BROKEN_preview_training_samples": [
    "model",
    "blank",
    "video_fps",
    "video_ext",
    "display"
  ],
  "VBx": [
    "X",
    "Phi",
    "Fa",
    "Fb",
    "pi",
    "gamma",
    "maxIters",
    "epsilon",
    "alphaQInit",
    "ref",
    "plot",
    "return_model",
    "alpha",
    "invL"
  ],
  "cluster_vbx": [
    "ahc_init",
    "fea",
    "Phi",
    "Fa",
    "Fb",
    "maxIters",
    "init_smoothing"
  ],
  "l2_norm": [
    "vec_or_matrix"
  ],
  "vbx_setup": [
    "transform_npz",
    "plda_npz"
  ],
  "merge_dict": [
    "defaults",
    "custom"
  ],
  "get_duration": [],
  "check_protocol": [
    "protocol"
  ],
  "FilterByNumberOfSpeakers": {
    "__init__": [
      "self",
      "num_speakers",
      "min_speakers",
      "max_speakers"
    ],
    "__call__": [
      "self",
      "current_file"
    ]
  },
  "discrete_diarization_error_rate": [
    "reference",
    "hypothesis"
  ],
  "DiscreteDiarizationErrorRate": {
    "metric_name": [
      "cls"
    ],
    "metric_components": [
      "cls"
    ],
    "compute_components": [
      "self",
      "reference",
      "hypothesis",
      "uem"
    ],
    "compute_components_helper": [
      "self",
      "hypothesis",
      "reference",
      "uem"
    ],
    "der_from_ndarray": [
      "self",
      "hypothesis",
      "reference",
      "uem"
    ],
    "der_from_swf": [
      "self",
      "hypothesis",
      "reference",
      "uem"
    ],
    "compute_metric": [
      "self",
      "components"
    ]
  },
  "SlidingDiarizationErrorRate": {
    "__init__": [
      "self",
      "window"
    ],
    "metric_name": [
      "cls"
    ],
    "metric_components": [
      "cls"
    ],
    "compute_components": [
      "self",
      "reference",
      "hypothesis",
      "uem"
    ],
    "compute_metric": [
      "self",
      "components"
    ]
  },
  "MacroAverageFMeasure": {
    "metric_components": [
      "self"
    ],
    "metric_name": [
      "cls"
    ],
    "__init__": [
      "self",
      "classes",
      "collar",
      "beta"
    ],
    "reset": [
      "self"
    ],
    "compute_components": [
      "self",
      "reference",
      "hypothesis",
      "uem"
    ],
    "compute_metric": [
      "self",
      "detail"
    ],
    "report": [
      "self",
      "display"
    ],
    "__abs__": [
      "self"
    ]
  },
  "MissingDependency": {
    "__init__": [
      "self",
      "what",
      "dependency",
      "required"
    ]
  },
  "WrongDependencyVersion": {
    "__init__": [
      "self",
      "what",
      "dependency",
      "required",
      "available"
    ]
  },
  "check_dependencies": [
    "dependencies",
    "what"
  ],
  "AssetFileName": {
    "Calibration": [],
    "Model": [],
    "Pipeline": [],
    "__str__": [
      "self"
    ]
  },
  "download_from_hf_hub": [
    "model_id",
    "asset_file",
    "subfolder",
    "revision",
    "cache_dir",
    "token"
  ],
  "create_rng_for_worker": [
    "model"
  ],
  "permutate": [
    "y1",
    "y2",
    "cost_func",
    "return_cost"
  ],
  "mse_cost_func": [
    "Y",
    "y"
  ],
  "mae_cost_func": [
    "Y",
    "y"
  ],
  "permutate_torch": [
    "y1",
    "y2",
    "cost_func",
    "return_cost"
  ],
  "permutate_numpy": [
    "y1",
    "y2",
    "cost_func",
    "return_cost"
  ],
  "build_permutation_graph": [
    "segmentations",
    "onset",
    "cost_func"
  ],
  "SpeakerEmbedding": [],
  "SupervisedRepresentationLearningWithArcFace": {
    "__init__": [
      "self",
      "protocol",
      "min_duration",
      "duration",
      "num_classes_per_batch",
      "num_chunks_per_class",
      "margin",
      "scale",
      "num_workers",
      "pin_memory",
      "augmentation",
      "metric"
    ],
    "setup_loss_func": [
      "self"
    ]
  },
  "SupervisedRepresentationLearningTaskMixin": {
    "num_classes_per_batch": [
      "self",
      "num_classes_per_batch"
    ],
    "num_chunks_per_class": [
      "self",
      "num_chunks_per_class"
    ],
    "batch_size": [
      "self",
      "batch_size"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "default_metric": [
      "self"
    ],
    "train__iter__": [
      "self"
    ],
    "train__len__": [
      "self"
    ],
    "collate_fn": [
      "self",
      "batch",
      "stage"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "prepare_validation": [
      "self",
      "prepared_dict"
    ],
    "val__getitem__": [
      "self",
      "idx"
    ],
    "val__len__": [
      "self"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ]
  },
  "VoiceActivityDetection": {
    "__init__": [
      "self",
      "protocol",
      "cache",
      "duration",
      "warm_up",
      "balance",
      "weight",
      "batch_size",
      "num_workers",
      "pin_memory",
      "augmentation",
      "metric"
    ],
    "prepare_chunk": [
      "self",
      "file_id",
      "start_time",
      "duration"
    ]
  },
  "Subsets": [],
  "Scopes": [],
  "SpeakerDiarization": {
    "__init__": [
      "self",
      "protocol",
      "cache",
      "duration",
      "max_speakers_per_chunk",
      "max_speakers_per_frame",
      "balance",
      "weight",
      "batch_size",
      "num_workers",
      "pin_memory",
      "augmentation",
      "metric",
      "max_num_speakers",
      "loss"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "setup_loss_func": [
      "self"
    ],
    "prepare_chunk": [
      "self",
      "file_id",
      "start_time",
      "duration"
    ],
    "collate_y": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "default_metric": [
      "self"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ]
  },
  "evaluate": [
    "protocol",
    "subset",
    "model"
  ],
  "MultiLabelSegmentation": {
    "__init__": [
      "self",
      "protocol",
      "cache",
      "classes",
      "duration",
      "warm_up",
      "balance",
      "weight",
      "batch_size",
      "num_workers",
      "pin_memory",
      "augmentation",
      "metric"
    ],
    "post_prepare_data": [
      "self",
      "prepared_data"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "prepare_chunk": [
      "self",
      "file_id",
      "start_time",
      "duration"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "val_monitor": [
      "self"
    ]
  },
  "SegmentationTask": {
    "get_file": [
      "self",
      "file_id"
    ],
    "default_metric": [
      "self"
    ],
    "train__iter__helper": [
      "self",
      "rng"
    ],
    "train__iter__": [
      "self"
    ],
    "collate_X": [
      "self",
      "batch"
    ],
    "collate_y": [
      "self",
      "batch"
    ],
    "collate_meta": [
      "self",
      "batch"
    ],
    "collate_fn": [
      "self",
      "batch",
      "stage"
    ],
    "train__len__": [
      "self"
    ],
    "prepare_validation": [
      "self",
      "prepared_data"
    ],
    "val__getitem__": [
      "self",
      "idx"
    ],
    "val__len__": [
      "self"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ]
  },
  "ValDataset": {
    "__init__": [
      "self",
      "task"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "PixIT": {
    "__init__": [
      "self",
      "protocol",
      "cache",
      "duration",
      "max_speakers_per_chunk",
      "max_speakers_per_frame",
      "weigh_by_cardinality",
      "balance",
      "weight",
      "batch_size",
      "num_workers",
      "pin_memory",
      "augmentation",
      "metric",
      "max_num_speakers",
      "loss",
      "separation_loss_weight"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "prepare_chunk": [
      "self",
      "file_id",
      "start_time",
      "duration"
    ],
    "val_dataloader": [
      "self"
    ],
    "val__iter__": [
      "self"
    ],
    "common__iter__helper": [
      "self",
      "split",
      "rng"
    ],
    "val__iter__helper": [
      "self",
      "rng"
    ],
    "train__iter__helper": [
      "self",
      "rng"
    ],
    "collate_fn": [
      "self",
      "batch",
      "stage"
    ],
    "collate_y": [
      "self",
      "batch"
    ],
    "segmentation_loss": [
      "self",
      "permutated_prediction",
      "target",
      "weight"
    ],
    "create_mixtures_of_mixtures": [
      "self",
      "mix1",
      "mix2",
      "target1",
      "target2"
    ],
    "common_step": [
      "self",
      "batch"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "default_metric": [
      "self"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ]
  },
  "OracleVoiceActivityDetection": {
    "apply": [
      "file"
    ]
  },
  "NeMoPretrainedSpeakerEmbedding": {
    "__init__": [
      "self",
      "embedding",
      "device"
    ],
    "to": [
      "self",
      "device"
    ],
    "sample_rate": [
      "self"
    ],
    "dimension": [
      "self"
    ],
    "metric": [
      "self"
    ],
    "min_num_samples": [
      "self"
    ],
    "__call__": [
      "self",
      "waveforms",
      "masks"
    ]
  },
  "SpeechBrainPretrainedSpeakerEmbedding": {
    "__init__": [
      "self",
      "embedding",
      "device",
      "token",
      "cache_dir"
    ],
    "to": [
      "self",
      "device"
    ],
    "sample_rate": [
      "self"
    ],
    "dimension": [
      "self"
    ],
    "metric": [
      "self"
    ],
    "min_num_samples": [
      "self"
    ],
    "__call__": [
      "self",
      "waveforms",
      "masks"
    ]
  },
  "ONNXWeSpeakerPretrainedSpeakerEmbedding": {
    "__init__": [
      "self",
      "embedding",
      "device",
      "token",
      "cache_dir"
    ],
    "to": [
      "self",
      "device"
    ],
    "sample_rate": [
      "self"
    ],
    "dimension": [
      "self"
    ],
    "metric": [
      "self"
    ],
    "min_num_samples": [
      "self"
    ],
    "min_num_frames": [
      "self"
    ],
    "compute_fbank": [
      "self",
      "waveforms",
      "num_mel_bins",
      "frame_length",
      "frame_shift",
      "dither"
    ],
    "__call__": [
      "self",
      "waveforms",
      "masks"
    ]
  },
  "PyannoteAudioPretrainedSpeakerEmbedding": {
    "__init__": [
      "self",
      "embedding",
      "device",
      "token",
      "cache_dir"
    ],
    "to": [
      "self",
      "device"
    ],
    "sample_rate": [
      "self"
    ],
    "dimension": [
      "self"
    ],
    "metric": [
      "self"
    ],
    "min_num_samples": [
      "self"
    ],
    "__call__": [
      "self",
      "waveforms",
      "masks"
    ]
  },
  "PretrainedSpeakerEmbedding": [
    "embedding",
    "device",
    "token",
    "cache_dir"
  ],
  "main": [
    "protocol",
    "subset",
    "embedding",
    "segmentation"
  ],
  "BaseClustering": {
    "__init__": [
      "self",
      "metric",
      "constrained_assignment"
    ],
    "set_num_clusters": [
      "self",
      "num_embeddings",
      "num_clusters",
      "min_clusters",
      "max_clusters"
    ],
    "filter_embeddings": [
      "self",
      "embeddings",
      "segmentations",
      "min_active_ratio"
    ],
    "constrained_argmax": [
      "self",
      "soft_clusters"
    ],
    "assign_embeddings": [
      "self",
      "embeddings",
      "train_chunk_idx",
      "train_speaker_idx",
      "train_clusters",
      "constrained"
    ],
    "__call__": [
      "self",
      "embeddings",
      "segmentations",
      "num_clusters",
      "min_clusters",
      "max_clusters"
    ]
  },
  "AgglomerativeClustering": {
    "__init__": [
      "self",
      "metric",
      "constrained_assignment"
    ],
    "cluster": [
      "self",
      "embeddings",
      "min_clusters",
      "max_clusters",
      "num_clusters"
    ]
  },
  "KMeansClustering": {
    "__init__": [
      "self",
      "metric"
    ],
    "cluster": [
      "self",
      "embeddings",
      "min_clusters",
      "max_clusters",
      "num_clusters"
    ]
  },
  "VBxClustering": {
    "__init__": [
      "self",
      "plda",
      "metric",
      "constrained_assignment"
    ],
    "__call__": [
      "self",
      "embeddings",
      "segmentations",
      "num_clusters",
      "min_clusters",
      "max_clusters"
    ]
  },
  "OracleClustering": {
    "__call__": [
      "self",
      "embeddings",
      "segmentations",
      "file",
      "frames"
    ]
  },
  "Clustering": {
    "AgglomerativeClustering": [],
    "KMeansClustering": [],
    "VBxClustering": [],
    "OracleClustering": []
  },
  "batchify": [
    "iterable",
    "batch_size",
    "fillvalue"
  ],
  "SpeechSeparation": {
    "__init__": [
      "self",
      "segmentation",
      "segmentation_step",
      "embedding",
      "embedding_exclude_overlap",
      "clustering",
      "embedding_batch_size",
      "segmentation_batch_size",
      "der_variant",
      "token",
      "cache_dir"
    ],
    "segmentation_batch_size": [
      "self",
      "batch_size"
    ],
    "default_parameters": [
      "self"
    ],
    "classes": [
      "self"
    ],
    "CACHED_SEGMENTATION": [
      "self"
    ],
    "get_segmentations": [
      "self",
      "file",
      "hook"
    ],
    "get_embeddings": [
      "self",
      "file",
      "binary_segmentations",
      "exclude_overlap",
      "hook"
    ],
    "reconstruct": [
      "self",
      "segmentations",
      "hard_clusters",
      "count"
    ],
    "apply": [
      "self",
      "file",
      "num_speakers",
      "min_speakers",
      "max_speakers",
      "return_embeddings",
      "hook"
    ],
    "get_metric": [
      "self"
    ]
  },
  "DiarizeOutput": {
    "serialize": [
      "self"
    ]
  },
  "Local": {
    "__init__": [
      "self",
      "token"
    ],
    "_deserialize": [
      "self",
      "diarization"
    ],
    "apply": [
      "self",
      "file",
      "num_speakers",
      "min_speakers",
      "max_speakers"
    ]
  },
  "SDK": {
    "__init__": [
      "self",
      "model",
      "token"
    ],
    "_deserialize": [
      "self",
      "diarization"
    ],
    "apply": [
      "self",
      "file",
      "num_speakers",
      "min_speakers",
      "max_speakers"
    ]
  },
  "get_pipeline": [
    "pipeline",
    "token",
    "cache_dir"
  ],
  "PipelineModel": [],
  "get_model": [
    "model",
    "token",
    "cache_dir"
  ],
  "PipelineAugmentation": [],
  "PipelineCalibration": [],
  "get_calibration": [
    "calibration",
    "token",
    "cache_dir"
  ],
  "PipelinePLDA": [],
  "get_plda": [
    "plda",
    "token",
    "cache_dir"
  ],
  "get_augmentation": [
    "augmentation"
  ],
  "get_devices": [
    "needs"
  ],
  "ArtifactHook": {
    "__init__": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "__call__": [
      "self",
      "step_name",
      "step_artifact",
      "file",
      "total",
      "completed"
    ]
  },
  "ProgressHook": {
    "__init__": [
      "self",
      "transient",
      "hidden"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "__call__": [
      "self",
      "step_name",
      "step_artifact",
      "file",
      "total",
      "completed"
    ]
  },
  "TimingHook": {
    "__init__": [
      "self",
      "file_key"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "__call__": [
      "self",
      "step_name",
      "step_artifact",
      "file",
      "total",
      "completed"
    ]
  },
  "Hooks": {
    "__init__": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "__call__": [
      "self",
      "step_name",
      "step_artifact",
      "file",
      "total",
      "completed"
    ]
  },
  "oracle_segmentation": [
    "file",
    "window",
    "frames",
    "num_speakers"
  ],
  "set_num_speakers": [
    "num_speakers",
    "min_speakers",
    "max_speakers"
  ],
  "SpeakerDiarizationMixin": {
    "set_num_speakers": [
      "num_speakers",
      "min_speakers",
      "max_speakers"
    ],
    "optimal_mapping": [
      "reference",
      "hypothesis",
      "return_mapping"
    ],
    "speaker_count": [
      "binarized_segmentations",
      "frames",
      "warm_up"
    ],
    "to_annotation": [
      "discrete_diarization",
      "min_duration_on",
      "min_duration_off"
    ],
    "to_diarization": [
      "segmentations",
      "count"
    ],
    "classes": [
      "self"
    ]
  },
  "XVectorMFCC": {
    "MFCC_DEFAULTS": [],
    "__init__": [
      "self",
      "sample_rate",
      "num_channels",
      "mfcc",
      "dimension",
      "task"
    ],
    "dimension": [
      "self"
    ],
    "num_frames": [
      "self",
      "num_samples"
    ],
    "receptive_field_size": [
      "self",
      "num_frames"
    ],
    "receptive_field_center": [
      "self",
      "frame"
    ],
    "forward": [
      "self",
      "waveforms",
      "weights"
    ]
  },
  "XVectorSincNet": {
    "SINCNET_DEFAULTS": [],
    "__init__": [
      "self",
      "sample_rate",
      "num_channels",
      "sincnet",
      "dimension",
      "task"
    ],
    "dimension": [
      "self"
    ],
    "num_frames": [
      "self",
      "num_samples"
    ],
    "receptive_field_size": [
      "self",
      "num_frames"
    ],
    "receptive_field_center": [
      "self",
      "frame"
    ],
    "forward": [
      "self",
      "waveforms",
      "weights"
    ]
  },
  "SimpleEmbeddingModel": {
    "__init__": [
      "self",
      "sample_rate",
      "num_channels",
      "task"
    ],
    "num_frames": [
      "self",
      "num_samples"
    ],
    "receptive_field_size": [
      "self",
      "num_frames"
    ],
    "receptive_field_center": [
      "self",
      "frame"
    ],
    "dimension": [
      "self"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "TSTP": {
    "__init__": [
      "self",
      "in_dim"
    ],
    "forward": [
      "self",
      "features",
      "weights"
    ],
    "get_out_dim": [
      "self"
    ]
  },
  "POOLING_LAYERS": [],
  "BasicBlock": {
    "expansion": [],
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride"
    ],
    "num_frames": [
      "self",
      "num_samples"
    ],
    "receptive_field_size": [
      "self",
      "num_frames"
    ],
    "receptive_field_center": [
      "self",
      "frame"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Bottleneck": {
    "expansion": [],
    "__init__": [
      "self",
      "in_planes",
      "planes",
      "stride"
    ],
    "num_frames": [
      "self",
      "num_samples"
    ],
    "receptive_field_size": [
      "self",
      "num_frames"
    ],
    "receptive_field_center": [
      "self",
      "frame"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNet": {
    "__init__": [
      "self",
      "block",
      "num_blocks",
      "m_channels",
      "feat_dim",
      "embed_dim",
      "pooling_func",
      "two_emb_layer"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "num_blocks",
      "stride"
    ],
    "num_frames": [
      "self",
      "num_samples"
    ],
    "receptive_field_size": [
      "self",
      "num_frames"
    ],
    "receptive_field_center": [
      "self",
      "frame"
    ],
    "forward_frames": [
      "self",
      "fbank"
    ],
    "forward_embedding": [
      "self",
      "frames",
      "weights"
    ],
    "forward": [
      "self",
      "fbank",
      "weights"
    ]
  },
  "ResNet18": [
    "feat_dim",
    "embed_dim",
    "pooling_func",
    "two_emb_layer"
  ],
  "ResNet34": [
    "feat_dim",
    "embed_dim",
    "pooling_func",
    "two_emb_layer"
  ],
  "ResNet50": [
    "feat_dim",
    "embed_dim",
    "pooling_func",
    "two_emb_layer"
  ],
  "ResNet101": [
    "feat_dim",
    "embed_dim",
    "pooling_func",
    "two_emb_layer"
  ],
  "ResNet152": [
    "feat_dim",
    "embed_dim",
    "pooling_func",
    "two_emb_layer"
  ],
  "ResNet221": [
    "feat_dim",
    "embed_dim",
    "pooling_func",
    "two_emb_layer"
  ],
  "ResNet293": [
    "feat_dim",
    "embed_dim",
    "pooling_func",
    "two_emb_layer"
  ],
  "BaseWeSpeakerResNet": {
    "__init__": [
      "self",
      "sample_rate",
      "num_channels",
      "num_mel_bins",
      "frame_length",
      "frame_shift",
      "round_to_power_of_two",
      "snip_edges",
      "dither",
      "window_type",
      "use_energy",
      "fbank_centering_span",
      "task"
    ],
    "fbank_only": [
      "self",
      "value"
    ],
    "compute_fbank": [
      "self",
      "waveforms"
    ],
    "dimension": [
      "self"
    ],
    "num_frames": [
      "self",
      "num_samples"
    ],
    "receptive_field_size": [
      "self",
      "num_frames"
    ],
    "receptive_field_center": [
      "self",
      "frame"
    ],
    "forward": [
      "self",
      "waveforms",
      "weights"
    ],
    "forward_frames": [
      "self",
      "waveforms"
    ],
    "forward_embedding": [
      "self",
      "frames",
      "weights"
    ]
  },
  "WeSpeakerResNet34": {
    "__init__": [
      "self",
      "sample_rate",
      "num_channels",
      "num_mel_bins",
      "frame_length",
      "frame_shift",
      "dither",
      "window_type",
      "use_energy",
      "task"
    ]
  },
  "WeSpeakerResNet152": {
    "__init__": [
      "self",
      "sample_rate",
      "num_channels",
      "num_mel_bins",
      "frame_length",
      "frame_shift",
      "dither",
      "window_type",
      "use_energy",
      "task"
    ]
  },
  "WeSpeakerResNet221": {
    "__init__": [
      "self",
      "sample_rate",
      "num_channels",
      "num_mel_bins",
      "frame_length",
      "frame_shift",
      "dither",
      "window_type",
      "use_energy",
      "task"
    ]
  },
  "WeSpeakerResNet293": {
    "__init__": [
      "self",
      "sample_rate",
      "num_channels",
      "num_mel_bins",
      "frame_length",
      "frame_shift",
      "dither",
      "window_type",
      "use_energy",
      "task"
    ]
  },
  "wespeaker_checkpoint_dir": [],
  "wespeaker_checkpoint": [],
  "depth": [],
  "Klass": [],
  "duration": [],
  "specifications": [],
  "state_dict": [],
  "model": [],
  "checkpoint": [],
  "pyannote_checkpoint": [],
  "SincNet": {
    "__init__": [
      "self",
      "sample_rate",
      "stride"
    ],
    "num_frames": [
      "self",
      "num_samples"
    ],
    "receptive_field_size": [
      "self",
      "num_frames"
    ],
    "receptive_field_center": [
      "self",
      "frame"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "_pool": [
    "sequences",
    "weights"
  ],
  "StatsPool": {
    "forward": [
      "self",
      "sequences",
      "weights"
    ]
  },
  "PyanNet": {
    "SINCNET_DEFAULTS": [],
    "LSTM_DEFAULTS": [],
    "LINEAR_DEFAULTS": [],
    "__init__": [
      "self",
      "sincnet",
      "lstm",
      "linear",
      "sample_rate",
      "num_channels",
      "task"
    ],
    "dimension": [
      "self"
    ],
    "build": [
      "self"
    ],
    "num_frames": [
      "self",
      "num_samples"
    ],
    "receptive_field_size": [
      "self",
      "num_frames"
    ],
    "receptive_field_center": [
      "self",
      "frame"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "SimpleSegmentationModel": {
    "__init__": [
      "self",
      "sample_rate",
      "num_channels",
      "task"
    ],
    "num_frames": [
      "self",
      "num_samples"
    ],
    "receptive_field_size": [
      "self",
      "num_frames"
    ],
    "receptive_field_center": [
      "self",
      "frame"
    ],
    "dimension": [
      "self"
    ],
    "build": [
      "self"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "SSeRiouSS": {
    "WAV2VEC_DEFAULTS": [],
    "LSTM_DEFAULTS": [],
    "LINEAR_DEFAULTS": [],
    "__init__": [
      "self",
      "wav2vec",
      "wav2vec_frozen",
      "wav2vec_layer",
      "lstm",
      "linear",
      "sample_rate",
      "num_channels",
      "task"
    ],
    "dimension": [
      "self"
    ],
    "build": [
      "self"
    ],
    "num_frames": [
      "self",
      "num_samples"
    ],
    "receptive_field_size": [
      "self",
      "num_frames"
    ],
    "receptive_field_center": [
      "self",
      "frame"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "ToTaToNet": {
    "ENCODER_DECODER_DEFAULTS": [],
    "LINEAR_DEFAULTS": [],
    "DPRNN_DEFAULTS": [],
    "DIAR_DEFAULTS": [],
    "__init__": [
      "self",
      "encoder_decoder",
      "linear",
      "diar",
      "dprnn",
      "sample_rate",
      "num_channels",
      "task",
      "n_sources",
      "use_wavlm",
      "wavlm_frozen",
      "gradient_clip_val"
    ],
    "dimension": [
      "self"
    ],
    "build": [
      "self"
    ],
    "num_frames": [
      "self",
      "num_samples"
    ],
    "receptive_field_size": [
      "self",
      "num_frames"
    ],
    "receptive_field_center": [
      "self",
      "frame"
    ],
    "forward": [
      "self",
      "waveforms"
    ]
  },
  "Calibration": {
    "__init__": [
      "self"
    ],
    "safe_transform": [
      "self",
      "values",
      "nan_value"
    ],
    "save": [
      "self",
      "path"
    ],
    "from_tensor_dict": [
      "cls",
      "tensor_dict"
    ],
    "from_file": [
      "cls",
      "path"
    ],
    "from_pretrained": [
      "cls",
      "checkpoint",
      "subfolder",
      "revision",
      "token",
      "cache_dir"
    ]
  },
  "Problem": {
    "BINARY_CLASSIFICATION": [],
    "MONO_LABEL_CLASSIFICATION": [],
    "MULTI_LABEL_CLASSIFICATION": [],
    "REPRESENTATION": [],
    "REGRESSION": []
  },
  "Resolution": {
    "FRAME": [],
    "CHUNK": []
  },
  "UnknownSpecificationsError": {},
  "Specifications": {
    "powerset": [
      "self"
    ],
    "num_powerset_classes": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "TrainDataset": {
    "__init__": [
      "self",
      "task"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "get_dtype": [
    "value"
  ],
  "Task": {
    "__init__": [
      "self",
      "protocol",
      "cache",
      "duration",
      "min_duration",
      "warm_up",
      "batch_size",
      "num_workers",
      "pin_memory",
      "augmentation",
      "metric"
    ],
    "prepare_data": [
      "self"
    ],
    "post_prepare_data": [
      "self",
      "prepared_data"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "automatic_optimization": [
      "self",
      "automatic_optimisation"
    ],
    "specifications": [
      "self",
      "specifications"
    ],
    "setup_loss_func": [
      "self"
    ],
    "train__iter__": [
      "self"
    ],
    "train__len__": [
      "self"
    ],
    "collate_fn": [
      "self",
      "batch",
      "stage"
    ],
    "train_dataloader": [
      "self"
    ],
    "default_loss": [
      "self",
      "specifications",
      "target",
      "prediction",
      "weight"
    ],
    "common_step": [
      "self",
      "batch",
      "batch_idx",
      "stage"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "val__getitem__": [
      "self",
      "idx"
    ],
    "val__len__": [
      "self"
    ],
    "val_dataloader": [
      "self"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "default_metric": [
      "self"
    ],
    "metric": [
      "self"
    ],
    "setup_validation_metric": [
      "self"
    ],
    "val_monitor": [
      "self"
    ]
  },
  "AudioFile": [],
  "AudioFileDocString": [],
  "get_audio_metadata": [
    "file"
  ],
  "Audio": {
    "PRECISION": [],
    "power_normalize": [
      "waveform"
    ],
    "validate_file": [
      "file"
    ],
    "__init__": [
      "self",
      "sample_rate",
      "mono"
    ],
    "downmix_and_resample": [
      "self",
      "waveform",
      "sample_rate",
      "channel"
    ],
    "get_duration": [
      "self",
      "file"
    ],
    "get_num_samples": [
      "self",
      "duration",
      "sample_rate"
    ],
    "__call__": [
      "self",
      "file"
    ],
    "crop": [
      "self",
      "file",
      "segment",
      "mode"
    ]
  },
  "expand_subfolders": [
    "config",
    "model_id",
    "parent_revision",
    "cache_dir",
    "token"
  ],
  "Pipeline": {
    "from_pretrained": [
      "cls",
      "checkpoint",
      "revision",
      "hparams_file",
      "token",
      "cache_dir"
    ],
    "__init__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "__delattr__": [
      "self",
      "name"
    ],
    "setup_hook": [
      "file",
      "hook"
    ],
    "default_parameters": [
      "self"
    ],
    "classes": [
      "self"
    ],
    "__call__": [
      "self",
      "file",
      "preload"
    ],
    "to": [
      "self",
      "device"
    ],
    "cuda": [
      "self",
      "device"
    ]
  },
  "Introspection": {},
  "Output": {},
  "Model": {
    "__init__": [
      "self",
      "sample_rate",
      "num_channels",
      "task"
    ],
    "task": [
      "self",
      "task"
    ],
    "build": [
      "self"
    ],
    "specifications": [
      "self"
    ],
    "__example_input_array": [
      "self",
      "duration"
    ],
    "example_input_array": [
      "self"
    ],
    "receptive_field": [
      "self"
    ],
    "prepare_data": [
      "self"
    ],
    "setup": [
      "self",
      "stage"
    ],
    "on_save_checkpoint": [
      "self",
      "checkpoint"
    ],
    "on_load_checkpoint": [
      "self",
      "checkpoint"
    ],
    "forward": [
      "self",
      "waveforms"
    ],
    "default_activation": [
      "self"
    ],
    "train_dataloader": [
      "self"
    ],
    "training_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "val_dataloader": [
      "self"
    ],
    "validation_step": [
      "self",
      "batch",
      "batch_idx"
    ],
    "configure_optimizers": [
      "self"
    ],
    "__up_to": [
      "self",
      "module_name",
      "requires_grad"
    ],
    "freeze_up_to": [
      "self",
      "module_name"
    ],
    "unfreeze_up_to": [
      "self",
      "module_name"
    ],
    "__by_name": [
      "self",
      "modules",
      "recurse",
      "requires_grad"
    ],
    "freeze_by_name": [
      "self",
      "modules",
      "recurse"
    ],
    "unfreeze_by_name": [
      "self",
      "modules",
      "recurse"
    ],
    "from_pretrained": [
      "cls",
      "checkpoint",
      "map_location",
      "strict",
      "subfolder",
      "revision",
      "token",
      "cache_dir"
    ]
  },
  "GraduallyUnfreeze": {
    "__init__": [
      "self",
      "schedule",
      "epochs_per_stage"
    ],
    "on_fit_start": [
      "self",
      "trainer",
      "model"
    ],
    "on_train_epoch_start": [
      "self",
      "trainer",
      "model"
    ]
  },
  "PLDA": {
    "__init__": [
      "self",
      "transform_npz",
      "plda_npz",
      "lda_dimension"
    ],
    "phi": [
      "self"
    ],
    "__call__": [
      "self",
      "embeddings"
    ],
    "from_pretrained": [
      "cls",
      "checkpoint",
      "subfolder",
      "revision",
      "token",
      "cache_dir"
    ]
  },
  "BaseInference": {},
  "Inference": {
    "__init__": [
      "self",
      "model",
      "window",
      "duration",
      "step",
      "pre_aggregation_hook",
      "skip_aggregation",
      "skip_conversion",
      "device",
      "batch_size"
    ],
    "to": [
      "self",
      "device"
    ],
    "infer": [
      "self",
      "chunks"
    ],
    "slide": [
      "self",
      "waveform",
      "sample_rate",
      "hook"
    ],
    "__call__": [
      "self",
      "file",
      "hook"
    ],
    "crop": [
      "self",
      "file",
      "chunk",
      "hook"
    ],
    "aggregate": [
      "scores",
      "frames",
      "warm_up",
      "epsilon",
      "hamming",
      "missing",
      "skip_average"
    ],
    "trim": [
      "scores",
      "warm_up"
    ]
  }
}