{
  "__all__": [],
  "_get_package_dir": [],
  "get_pdx_version": [],
  "get_version_dict": [],
  "show_versions": [],
  "_SPECIAL_MODS": [],
  "_loaded_special_mods": [],
  "_initialize": [],
  "__version__": [],
  "Engine": {
    "__init__": [
      "self"
    ],
    "run": [
      "self"
    ]
  },
  "create_model": [
    "model_name",
    "model_dir"
  ],
  "_BaseModel": {
    "check_dataset": [
      "self"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self"
    ],
    "export": [
      "self"
    ],
    "predict": [
      "self"
    ],
    "set_predict": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "_ModelBasedInference": {
    "__init__": [
      "self"
    ],
    "predict": [
      "self"
    ],
    "set_predictor": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "_ModelBasedConfig": {
    "__init__": [
      "self",
      "config"
    ],
    "_build_predictor": [
      "self"
    ],
    "check_dataset": [
      "self"
    ],
    "train": [
      "self"
    ],
    "evaluate": [
      "self"
    ],
    "export": [
      "self"
    ],
    "predict": [
      "self"
    ]
  },
  "args_cfg": [],
  "install": [
    "args"
  ],
  "pipeline_predict": [
    "pipeline",
    "input",
    "device",
    "save_path",
    "use_hpip",
    "hpi_config"
  ],
  "serve": [
    "pipeline"
  ],
  "paddle_to_onnx": [
    "paddle_model_dir",
    "onnx_model_dir"
  ],
  "main": [],
  "console_entry": [],
  "get_user_home": [],
  "get_pprndr_home": [],
  "get_sub_home": [
    "directory"
  ],
  "TMP_HOME": [],
  "custom_ops": [],
  "CustomOpNotFoundException": {
    "__init__": [
      "self",
      "op_name"
    ],
    "__str__": [
      "self"
    ]
  },
  "CustomOperatorPathFinder": {
    "find_spec": [
      "self",
      "fullname",
      "path",
      "target"
    ]
  },
  "CustomOperatorPathLoader": {
    "load_module": [
      "self",
      "fullname"
    ]
  },
  "PaddleXCustomOperatorModule": {
    "__init__": [
      "self",
      "modulename",
      "fullname"
    ],
    "jit_build": [
      "self"
    ],
    "_load_module": [
      "self"
    ],
    "__getattr__": [
      "self",
      "attr"
    ]
  },
  "_parse_repo_deps": [
    "repos"
  ],
  "_GlobalContext": {
    "REPO_PARENT_DIR": [],
    "PDX_COLLECTION_MOD": [],
    "REPOS": [],
    "set_parent_dirs": [
      "cls",
      "repo_parent_dir",
      "pdx_collection_mod"
    ],
    "build_repo_instance": [
      "cls",
      "repo_name"
    ],
    "is_initialized": [
      "cls"
    ],
    "initialize": [
      "cls"
    ],
    "add_repo": [
      "cls",
      "repo"
    ],
    "add_repos": [
      "cls",
      "repos"
    ]
  },
  "set_parent_dirs": [],
  "is_initialized": [],
  "setup": [
    "repo_names",
    "no_deps",
    "constraints",
    "platform",
    "update_repos",
    "use_local_repos",
    "deps_to_replace"
  ],
  "initialize": [
    "repo_names"
  ],
  "get_versions": [
    "repo_names"
  ],
  "PLATFORM": [],
  "_check_call": [],
  "_compare_version": [
    "version1",
    "version2"
  ],
  "check_package_installation": [
    "package"
  ],
  "install_external_deps": [
    "repo_name",
    "repo_root"
  ],
  "clone_repo_using_git": [
    "url",
    "branch"
  ],
  "fetch_repo_using_git": [
    "branch",
    "url",
    "depth"
  ],
  "reset_repo_using_git": [
    "pointer",
    "hard"
  ],
  "remove_repo_using_rm": [
    "name"
  ],
  "mute": [],
  "switch_working_dir": [
    "new_wd"
  ],
  "build_repo_instance": [
    "repo_name"
  ],
  "build_repo_group_installer": [],
  "build_repo_group_getter": [],
  "PPRepository": {
    "__init__": [
      "self",
      "name",
      "repo_parent_dir",
      "pdx_collection_mod"
    ],
    "initialize": [
      "self"
    ],
    "check_installation": [
      "self"
    ],
    "replace_repo_deps": [
      "self",
      "deps_to_replace",
      "src_requirements"
    ],
    "check_repo_exiting": [
      "self"
    ],
    "install_packages": [
      "self",
      "clean"
    ],
    "uninstall_packages": [
      "self"
    ],
    "mark_installed": [
      "self"
    ],
    "mark_uninstalled": [
      "self"
    ],
    "download": [
      "self"
    ],
    "remove": [
      "self"
    ],
    "update": [
      "self",
      "platform"
    ],
    "get_pdx": [
      "self"
    ],
    "get_deps": [
      "self",
      "deps_to_replace"
    ],
    "get_version": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "RepositoryGroupInstaller": {
    "__init__": [
      "self",
      "repos"
    ],
    "install": [
      "self",
      "force_reinstall",
      "no_deps",
      "constraints",
      "deps_to_replace"
    ],
    "uninstall": [
      "self"
    ],
    "get_deps": [
      "self",
      "deps_to_replace"
    ],
    "install_deps": [
      "self",
      "constraints",
      "deps_to_replace"
    ],
    "_sort_repos": [
      "self",
      "repos",
      "check_missing"
    ],
    "_normalize_deps": [
      "self",
      "deps",
      "headline"
    ]
  },
  "RepositoryGroupGetter": {
    "__init__": [
      "self",
      "repos"
    ],
    "get": [
      "self",
      "force",
      "platform"
    ],
    "remove": [
      "self"
    ]
  },
  "REPO_DOWNLOAD_BASE": [],
  "REPO_NAMES": [],
  "REPO_META": [],
  "REPO_DIST_NAMES": [],
  "get_repo_meta": [
    "repo_name"
  ],
  "get_all_repo_names": [],
  "custom_type": [
    "cli_expected_type"
  ],
  "PIPELINE_ARGUMENTS": [],
  "DCU_WHITELIST": [],
  "MLU_WHITELIST": [],
  "NPU_BLACKLIST": [],
  "XPU_WHITELIST": [],
  "GCU_WHITELIST": [],
  "METAX_GPU_WHITELIST": [],
  "interactive_get_pipeline": [
    "pipeline",
    "save_path"
  ],
  "DEFAULT_CACHE_DIR": [],
  "CACHE_DIR": [],
  "FUNC_CACHE_DIR": [],
  "FILE_LOCK_DIR": [],
  "TEMP_DIR": [],
  "create_cache_dir": [],
  "get_cache_dir": [],
  "persist": [
    "cond"
  ],
  "TempFileManager": {
    "__init__": [
      "self"
    ],
    "create_temp_file": [
      "self"
    ],
    "cleanup": [
      "self"
    ],
    "temp_file_context": [
      "self"
    ]
  },
  "temp_file_manager": [],
  "install_packages_from_requirements_file": [
    "requirements_file_path",
    "pip_install_opts",
    "constraints"
  ],
  "install_packages": [
    "requirements",
    "pip_install_opts",
    "constraints"
  ],
  "uninstall_packages": [
    "packages",
    "pip_uninstall_opts"
  ],
  "SUPPORTED_DEVICE_TYPE": [],
  "constr_device": [
    "device_type",
    "device_ids"
  ],
  "get_default_device": [],
  "parse_device": [
    "device"
  ],
  "update_device_num": [
    "device",
    "num"
  ],
  "set_env_for_device": [
    "device"
  ],
  "set_env_for_device_type": [
    "device_type"
  ],
  "check_supported_device_type": [
    "device_type",
    "model_name"
  ],
  "check_supported_device": [
    "device",
    "model_name"
  ],
  "TemporaryDeviceChanger": {
    "__init__": [
      "self",
      "new_device"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "create_font": [
    "txt",
    "sz",
    "font_path"
  ],
  "create_font_vertical": [
    "txt",
    "sz",
    "font_path",
    "scale"
  ],
  "Font": {
    "__init__": [
      "self",
      "font_name",
      "local_path"
    ],
    "path": [
      "self"
    ],
    "_get_offical_font": [
      "self"
    ]
  },
  "PINGFANG_FONT": [],
  "SIMFANG_FONT": [],
  "LATIN_FONT": [],
  "TH_FONT": [],
  "EL_FONT": [],
  "KOREAN_FONT": [],
  "ARABIC_FONT": [],
  "CYRILLIC_FONT": [],
  "KANNADA_FONT": [],
  "TELUGU_FONT": [],
  "TAMIL_FONT": [],
  "DEVANAGARI_FONT": [],
  "custom_open": [
    "file_path",
    "mode"
  ],
  "read_yaml_file": [
    "yaml_path",
    "to_dict"
  ],
  "write_config_file": [
    "yaml_dict",
    "yaml_path"
  ],
  "update_yaml_file_with_dict": [
    "yaml_path",
    "key_values"
  ],
  "get_yaml_keys": [
    "yaml_path"
  ],
  "generate_markdown_from_dict": [
    "metrics"
  ],
  "read_jsonl_file": [
    "jsonl_path"
  ],
  "write_json_file": [
    "content",
    "jsonl_path",
    "ensure_ascii"
  ],
  "check_dict_keys": [
    "to_checked_dict",
    "standard_dict",
    "escape_list"
  ],
  "check_dataset_valid": [
    "path_list"
  ],
  "LOGGER_NAME": [],
  "_LOG_CONFIG": [],
  "_logger": [],
  "debug": [
    "msg"
  ],
  "info": [
    "msg"
  ],
  "warning": [
    "msg"
  ],
  "warning_once": [
    "msg"
  ],
  "error": [
    "msg"
  ],
  "critical": [
    "msg"
  ],
  "exception": [
    "msg"
  ],
  "setup_logging": [
    "verbosity"
  ],
  "_configure_logger": [
    "logger",
    "verbosity"
  ],
  "_add_handler": [
    "logger"
  ],
  "advertise": [],
  "FuncRegister": {
    "__init__": [
      "self",
      "register_map"
    ],
    "__call__": [
      "self",
      "key"
    ]
  },
  "AutoRegisterMetaClass": {
    "__model_type_attr_name": [],
    "__base_class_flag": [],
    "__registered_map_name": [],
    "__new__": [
      "mcs",
      "name",
      "bases",
      "attrs"
    ],
    "__register_model_entity": [
      "mcs",
      "bases",
      "cls",
      "attrs"
    ],
    "__find_base_class": [
      "mcs",
      "cls"
    ],
    "__register_to_base_class": [
      "mcs",
      "base",
      "cls"
    ],
    "all": [
      "cls"
    ],
    "get": [
      "cls",
      "name"
    ]
  },
  "AutoRegisterABCMetaClass": {},
  "AttrDict": {
    "__getattr__": [
      "self",
      "key"
    ],
    "__setattr__": [
      "self",
      "key",
      "value"
    ],
    "__deepcopy__": [
      "self",
      "content"
    ]
  },
  "create_attr_dict": [
    "yaml_config"
  ],
  "parse_config": [
    "cfg_file"
  ],
  "print_dict": [
    "d",
    "delimiter"
  ],
  "print_config": [
    "config"
  ],
  "override": [
    "dl",
    "ks",
    "v"
  ],
  "override_config": [
    "config",
    "options"
  ],
  "get_config": [
    "fname",
    "overrides",
    "show"
  ],
  "parse_args": [],
  "_EXTRA_PATTERN": [],
  "_COLLECTIVE_EXTRA_NAMES": [],
  "_SUPPORTED_GENAI_ENGINE_BACKENDS": [],
  "DependencyError": {},
  "_get_extra_name_and_remove_extra_marker": [
    "dep_spec"
  ],
  "_get_extras": [],
  "EXTRAS": [],
  "_get_base_dep_specs": [
    "required_only"
  ],
  "BASE_DEP_SPECS": [],
  "REQUIRED_DEP_SPECS": [],
  "get_dep_version": [
    "dep"
  ],
  "is_dep_available": [
    "check_version"
  ],
  "require_deps": [],
  "function_requires_deps": [],
  "class_requires_deps": [],
  "is_extra_available": [
    "extra"
  ],
  "require_extra": [
    "extra"
  ],
  "pipeline_requires_extra": [
    "extra"
  ],
  "is_hpip_available": [],
  "require_hpip": [],
  "is_serving_plugin_available": [],
  "require_serving_plugin": [],
  "get_serving_dep_specs": [],
  "is_paddle2onnx_plugin_available": [],
  "require_paddle2onnx_plugin": [],
  "get_paddle2onnx_dep_specs": [],
  "is_genai_engine_plugin_available": [
    "backend"
  ],
  "require_genai_engine_plugin": [
    "backend"
  ],
  "is_genai_client_plugin_available": [],
  "require_genai_client_plugin": [],
  "get_genai_fastdeploy_spec": [
    "device_type"
  ],
  "get_genai_dep_specs": [
    "type"
  ],
  "convert_and_remove_types": [
    "data"
  ],
  "abspath": [
    "path"
  ],
  "CachedProperty": {
    "__init__": [
      "self",
      "func"
    ],
    "__get__": [
      "self",
      "obj",
      "cls"
    ]
  },
  "Constant": {
    "__init__": [
      "self",
      "val"
    ],
    "__get__": [
      "self",
      "obj",
      "type_"
    ],
    "__set__": [
      "self",
      "obj",
      "val"
    ]
  },
  "Singleton": {
    "_insts": [],
    "_lock": [],
    "__call__": [
      "cls"
    ]
  },
  "_ProgressPrinter": {
    "__init__": [
      "self",
      "flush_interval"
    ],
    "print": [
      "self",
      "str_",
      "end"
    ]
  },
  "_download": [
    "url",
    "save_path",
    "print_progress"
  ],
  "_extract_zip_file": [
    "file_path",
    "extd_dir"
  ],
  "_extract_tar_file": [
    "file_path",
    "extd_dir"
  ],
  "_extract": [
    "file_path",
    "extd_dir",
    "print_progress"
  ],
  "_remove_if_exists": [
    "path"
  ],
  "download": [
    "url",
    "save_path",
    "print_progress",
    "overwrite"
  ],
  "extract": [
    "file_path",
    "extd_dir",
    "print_progress"
  ],
  "download_and_extract": [
    "url",
    "save_dir",
    "dst_name",
    "print_progress",
    "overwrite",
    "no_interm_dir"
  ],
  "get_device_type": [],
  "get_paddle_version": [],
  "get_paddle_cuda_version": [],
  "get_paddle_cudnn_version": [],
  "is_cuda_available": [],
  "get_gpu_compute_capability": [],
  "get_flag_from_env_var": [
    "name",
    "default",
    "format_func"
  ],
  "DEBUG": [],
  "DRY_RUN": [],
  "CHECK_OPTS": [],
  "EAGER_INITIALIZATION": [],
  "FLAGS_json_format_model": [],
  "USE_PIR_TRT": [],
  "DISABLE_DEV_MODEL_WL": [],
  "DISABLE_CINN_MODEL_WL": [],
  "DISABLE_TRT_MODEL_BL": [],
  "DISABLE_MKLDNN_MODEL_BL": [],
  "LOCAL_FONT_FILE_PATH": [],
  "ENABLE_MKLDNN_BYDEFAULT": [],
  "DISABLE_DEVICE_FALLBACK": [],
  "MODEL_SOURCE": [],
  "DISABLE_MODEL_SOURCE_CHECK": [],
  "HUGGING_FACE_ENDPOINT": [],
  "INFER_BENCHMARK": [],
  "PIPELINE_BENCHMARK": [],
  "INFER_BENCHMARK_WARMUP": [],
  "INFER_BENCHMARK_OUTPUT_DIR": [],
  "INFER_BENCHMARK_ITERS": [],
  "INFER_BENCHMARK_USE_CACHE_FOR_READ": [],
  "PDF_RENDER_SCALE": [],
  "try_except_decorator": [
    "func"
  ],
  "save_result": [
    "run_pass",
    "mode",
    "output",
    "result_dict",
    "err_type",
    "err_msg"
  ],
  "disable_pir_bydefault": [],
  "LazyLoader": {
    "__init__": [
      "self",
      "local_name",
      "parent_module_globals",
      "name"
    ],
    "loaded": [
      "self"
    ],
    "_load": [
      "self"
    ],
    "__getattr__": [
      "self",
      "item"
    ],
    "__dir__": [
      "self"
    ]
  },
  "FailedError": {
    "__init__": [
      "self",
      "err_info",
      "solution",
      "message"
    ],
    "_construct_message": [
      "self",
      "err_info",
      "solution"
    ]
  },
  "CheckFailedError": {
    "mode": []
  },
  "ConvertFailedError": {
    "mode": []
  },
  "SplitFailedError": {
    "mode": []
  },
  "AnalyseFailedError": {
    "mode": []
  },
  "DatasetFileNotFoundError": {
    "__init__": [
      "self",
      "file_path",
      "err_info",
      "solution",
      "message"
    ]
  },
  "UnsupportedAPIError": {},
  "UnsupportedParamError": {},
  "KeyNotFoundError": {},
  "ClassNotFoundException": {},
  "NoEntityRegisteredException": {},
  "UnsupportedDeviceError": {},
  "CalledProcessError": {
    "__init__": [
      "self",
      "returncode",
      "cmd",
      "output",
      "stderr"
    ],
    "__str__": [
      "self"
    ]
  },
  "DuplicateRegistrationError": {},
  "ModelNotFoundError": {},
  "raise_unsupported_api_error": [
    "api_name",
    "cls"
  ],
  "raise_key_not_found_error": [
    "key",
    "config"
  ],
  "raise_class_not_found_error": [
    "cls_name",
    "base_cls",
    "all_entities"
  ],
  "raise_no_entity_registered_error": [
    "base_cls"
  ],
  "raise_unsupported_device_error": [
    "device",
    "supported_device"
  ],
  "raise_model_not_found_error": [
    "model_path"
  ],
  "REPO_ROOT_PATH": [],
  "PDX_CONFIG_DIR": [],
  "ShiTuRecConfig": {
    "update_dataset": [
      "self",
      "dataset_path",
      "dataset_type"
    ],
    "update_batch_size": [
      "self",
      "batch_size",
      "mode"
    ],
    "update_num_classes": [
      "self",
      "num_classes"
    ],
    "update_num_workers": [
      "self",
      "num_workers"
    ],
    "update_shared_memory": [
      "self",
      "shared_memeory"
    ],
    "update_shuffle": [
      "self",
      "shuffle"
    ],
    "_get_backbone_name": [
      "self"
    ]
  },
  "ShiTuRecModel": {},
  "ShiTuRecRunner": {},
  "_extract_eval_metrics": [
    "stdout"
  ],
  "ClsConfig": {
    "update": [
      "self",
      "list_like_obj"
    ],
    "load": [
      "self",
      "config_file_path"
    ],
    "dump": [
      "self",
      "config_file_path"
    ],
    "update_dataset": [
      "self",
      "dataset_path",
      "dataset_type"
    ],
    "update_batch_size": [
      "self",
      "batch_size",
      "mode"
    ],
    "update_learning_rate": [
      "self",
      "learning_rate"
    ],
    "update_warmup_epochs": [
      "self",
      "warmup_epochs"
    ],
    "update_pretrained_weights": [
      "self",
      "pretrained_model"
    ],
    "update_num_classes": [
      "self",
      "num_classes"
    ],
    "update_ml_query_num": [
      "self",
      "query_num"
    ],
    "update_ml_class_num": [
      "self",
      "class_num"
    ],
    "_update_slim_config": [
      "self",
      "slim_config_path"
    ],
    "_update_amp": [
      "self",
      "amp"
    ],
    "update_num_workers": [
      "self",
      "num_workers"
    ],
    "update_shared_memory": [
      "self",
      "shared_memeory"
    ],
    "update_shuffle": [
      "self",
      "shuffle"
    ],
    "update_dali": [
      "self",
      "dali"
    ],
    "update_seed": [
      "self",
      "seed"
    ],
    "update_device": [
      "self",
      "device"
    ],
    "update_label_dict_path": [
      "self",
      "dict_path"
    ],
    "_update_to_static": [
      "self",
      "dy2st"
    ],
    "_update_use_vdl": [
      "self",
      "use_vdl"
    ],
    "_update_epochs": [
      "self",
      "epochs"
    ],
    "_update_checkpoints": [
      "self",
      "resume_path"
    ],
    "_update_output_dir": [
      "self",
      "save_dir"
    ],
    "update_log_interval": [
      "self",
      "log_interval"
    ],
    "update_eval_interval": [
      "self",
      "eval_interval"
    ],
    "update_save_interval": [
      "self",
      "save_interval"
    ],
    "update_log_ranks": [
      "self",
      "device"
    ],
    "update_print_mem_info": [
      "self",
      "print_mem_info"
    ],
    "_update_predict_img": [
      "self",
      "infer_img",
      "infer_list"
    ],
    "_update_save_inference_dir": [
      "self",
      "save_inference_dir"
    ],
    "_update_inference_model_dir": [
      "self",
      "model_dir"
    ],
    "_update_infer_img": [
      "self",
      "infer_img"
    ],
    "_update_infer_device": [
      "self",
      "device"
    ],
    "_update_enable_mkldnn": [
      "self",
      "enable_mkldnn"
    ],
    "_update_infer_img_shape": [
      "self",
      "img_shape"
    ],
    "_update_save_predict_result": [
      "self",
      "save_dir"
    ],
    "update_model": [
      "self"
    ],
    "update_teacher_model": [
      "self"
    ],
    "update_student_model": [
      "self"
    ],
    "get_epochs_iters": [
      "self"
    ],
    "get_log_interval": [
      "self"
    ],
    "get_eval_interval": [
      "self"
    ],
    "get_save_interval": [
      "self"
    ],
    "get_learning_rate": [
      "self"
    ],
    "get_warmup_epochs": [
      "self"
    ],
    "get_label_dict_path": [
      "self"
    ],
    "get_batch_size": [
      "self",
      "mode"
    ],
    "get_qat_epochs_iters": [
      "self"
    ],
    "get_qat_learning_rate": [
      "self"
    ],
    "_get_arch_name": [
      "self"
    ],
    "_get_dataset_root": [
      "self"
    ],
    "get_train_save_dir": [
      "self"
    ]
  },
  "ClsModel": {
    "train": [
      "self",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "ips",
      "device",
      "resume_path",
      "dy2st",
      "amp",
      "num_workers",
      "use_vdl",
      "save_dir"
    ],
    "evaluate": [
      "self",
      "weight_path",
      "batch_size",
      "ips",
      "device",
      "amp",
      "num_workers"
    ],
    "predict": [
      "self",
      "weight_path",
      "input_path",
      "input_list_path",
      "device",
      "save_dir"
    ],
    "export": [
      "self",
      "weight_path",
      "save_dir"
    ],
    "infer": [
      "self",
      "model_dir",
      "input_path",
      "device",
      "save_dir",
      "dict_path"
    ],
    "compression": [
      "self",
      "weight_path",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "device",
      "use_vdl",
      "save_dir"
    ]
  },
  "ClsRunner": {
    "train": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips",
      "save_dir",
      "do_eval"
    ],
    "evaluate": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "export": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "save_dir"
    ],
    "infer": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "compression": [
      "self",
      "config_path",
      "train_cli_args",
      "export_cli_args",
      "device",
      "train_save_dir"
    ]
  },
  "load_config": [
    "file_path"
  ],
  "merge_config": [
    "config",
    "opts"
  ],
  "VideoDetConfig": {
    "update": [
      "self",
      "dict_like_obj"
    ],
    "load": [
      "self",
      "config_file_path"
    ],
    "dump": [
      "self",
      "config_file_path"
    ],
    "update_dataset": [
      "self",
      "dataset_path",
      "dataset_type"
    ],
    "update_batch_size": [
      "self",
      "batch_size",
      "mode"
    ],
    "update_learning_rate": [
      "self",
      "learning_rate"
    ],
    "update_num_classes": [
      "self",
      "num_classes"
    ],
    "update_label_list": [
      "self",
      "label_path"
    ],
    "update_pretrained_weights": [
      "self",
      "pretrained_model"
    ],
    "_update_slim_config": [
      "self",
      "slim_config_path"
    ],
    "_update_amp": [
      "self",
      "amp"
    ],
    "update_num_workers": [
      "self",
      "num_workers"
    ],
    "update_shared_memory": [
      "self",
      "shared_memeory"
    ],
    "update_shuffle": [
      "self",
      "shuffle"
    ],
    "update_dali": [
      "self",
      "dali"
    ],
    "update_seed": [
      "self",
      "seed"
    ],
    "update_device": [
      "self",
      "device"
    ],
    "update_label_dict_path": [
      "self",
      "dict_path"
    ],
    "_update_to_static": [
      "self",
      "dy2st"
    ],
    "_update_use_vdl": [
      "self",
      "use_vdl"
    ],
    "_update_epochs": [
      "self",
      "epochs"
    ],
    "_update_checkpoints": [
      "self",
      "resume_path"
    ],
    "_update_output_dir": [
      "self",
      "save_dir"
    ],
    "update_log_interval": [
      "self",
      "log_interval"
    ],
    "update_eval_interval": [
      "self",
      "eval_interval"
    ],
    "update_save_interval": [
      "self",
      "save_interval"
    ],
    "update_log_ranks": [
      "self",
      "device"
    ],
    "update_print_mem_info": [
      "self",
      "print_mem_info"
    ],
    "_update_predict_video": [
      "self",
      "infer_video",
      "infer_list"
    ],
    "_update_save_inference_dir": [
      "self",
      "save_inference_dir"
    ],
    "_update_inference_model_dir": [
      "self",
      "model_dir"
    ],
    "_update_infer_video": [
      "self",
      "infer_video"
    ],
    "_update_infer_device": [
      "self",
      "device"
    ],
    "_update_enable_mkldnn": [
      "self",
      "enable_mkldnn"
    ],
    "_update_infer_video_shape": [
      "self",
      "img_shape"
    ],
    "_update_save_predict_result": [
      "self",
      "save_dir"
    ],
    "get_epochs_iters": [
      "self"
    ],
    "get_log_interval": [
      "self"
    ],
    "get_eval_interval": [
      "self"
    ],
    "get_save_interval": [
      "self"
    ],
    "get_learning_rate": [
      "self"
    ],
    "get_warmup_epochs": [
      "self"
    ],
    "get_label_dict_path": [
      "self"
    ],
    "get_batch_size": [
      "self",
      "mode"
    ],
    "get_qat_epochs_iters": [
      "self"
    ],
    "get_qat_learning_rate": [
      "self"
    ],
    "_get_arch_name": [
      "self"
    ],
    "_get_dataset_root": [
      "self"
    ],
    "get_train_save_dir": [
      "self"
    ]
  },
  "VideoDetModel": {
    "train": [
      "self",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "ips",
      "device",
      "resume_path",
      "dy2st",
      "amp",
      "num_workers",
      "use_vdl",
      "save_dir"
    ],
    "evaluate": [
      "self",
      "weight_path",
      "batch_size",
      "ips",
      "device",
      "amp",
      "num_workers"
    ],
    "predict": [
      "self",
      "weight_path",
      "input_path",
      "input_list_path",
      "device",
      "save_dir"
    ],
    "export": [
      "self",
      "weight_path",
      "save_dir"
    ],
    "infer": [
      "self",
      "model_dir",
      "input_path",
      "device",
      "save_dir",
      "dict_path"
    ],
    "compression": [
      "self",
      "weight_path",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "device",
      "use_vdl",
      "save_dir"
    ]
  },
  "VideoDetRunner": {
    "train": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips",
      "save_dir",
      "do_eval"
    ],
    "evaluate": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "export": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "save_dir"
    ],
    "infer": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "compression": [
      "self",
      "config_path",
      "train_cli_args",
      "export_cli_args",
      "device",
      "train_save_dir"
    ]
  },
  "VideoClsConfig": {
    "update": [
      "self",
      "dict_like_obj"
    ],
    "load": [
      "self",
      "config_file_path"
    ],
    "dump": [
      "self",
      "config_file_path"
    ],
    "update_dataset": [
      "self",
      "dataset_path",
      "dataset_type"
    ],
    "update_batch_size": [
      "self",
      "batch_size",
      "mode"
    ],
    "update_learning_rate": [
      "self",
      "learning_rate"
    ],
    "update_warmup_epochs": [
      "self",
      "warmup_epochs"
    ],
    "update_pretrained_weights": [
      "self",
      "pretrained_model"
    ],
    "update_num_classes": [
      "self",
      "num_classes"
    ],
    "_update_slim_config": [
      "self",
      "slim_config_path"
    ],
    "_update_amp": [
      "self",
      "amp"
    ],
    "update_num_workers": [
      "self",
      "num_workers"
    ],
    "update_shared_memory": [
      "self",
      "shared_memeory"
    ],
    "update_shuffle": [
      "self",
      "shuffle"
    ],
    "update_dali": [
      "self",
      "dali"
    ],
    "update_seed": [
      "self",
      "seed"
    ],
    "update_device": [
      "self",
      "device"
    ],
    "update_label_dict_path": [
      "self",
      "dict_path"
    ],
    "_update_to_static": [
      "self",
      "dy2st"
    ],
    "_update_use_vdl": [
      "self",
      "use_vdl"
    ],
    "_update_epochs": [
      "self",
      "epochs"
    ],
    "_update_checkpoints": [
      "self",
      "resume_path"
    ],
    "_update_output_dir": [
      "self",
      "save_dir"
    ],
    "update_log_interval": [
      "self",
      "log_interval"
    ],
    "update_eval_interval": [
      "self",
      "eval_interval"
    ],
    "update_save_interval": [
      "self",
      "save_interval"
    ],
    "update_log_ranks": [
      "self",
      "device"
    ],
    "update_print_mem_info": [
      "self",
      "print_mem_info"
    ],
    "_update_predict_video": [
      "self",
      "infer_video",
      "infer_list"
    ],
    "_update_save_inference_dir": [
      "self",
      "save_inference_dir"
    ],
    "_update_inference_model_dir": [
      "self",
      "model_dir"
    ],
    "_update_infer_video": [
      "self",
      "infer_video"
    ],
    "_update_infer_device": [
      "self",
      "device"
    ],
    "_update_enable_mkldnn": [
      "self",
      "enable_mkldnn"
    ],
    "_update_infer_video_shape": [
      "self",
      "img_shape"
    ],
    "_update_save_predict_result": [
      "self",
      "save_dir"
    ],
    "get_epochs_iters": [
      "self"
    ],
    "get_log_interval": [
      "self"
    ],
    "get_eval_interval": [
      "self"
    ],
    "get_save_interval": [
      "self"
    ],
    "get_learning_rate": [
      "self"
    ],
    "get_warmup_epochs": [
      "self"
    ],
    "get_label_dict_path": [
      "self"
    ],
    "get_batch_size": [
      "self",
      "mode"
    ],
    "get_qat_epochs_iters": [
      "self"
    ],
    "get_qat_learning_rate": [
      "self"
    ],
    "_get_arch_name": [
      "self"
    ],
    "_get_dataset_root": [
      "self"
    ],
    "get_train_save_dir": [
      "self"
    ]
  },
  "VideoClsModel": {
    "train": [
      "self",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "ips",
      "device",
      "resume_path",
      "dy2st",
      "amp",
      "num_workers",
      "use_vdl",
      "save_dir"
    ],
    "evaluate": [
      "self",
      "weight_path",
      "batch_size",
      "ips",
      "device",
      "amp",
      "num_workers"
    ],
    "predict": [
      "self",
      "weight_path",
      "input_path",
      "input_list_path",
      "device",
      "save_dir"
    ],
    "export": [
      "self",
      "weight_path",
      "save_dir"
    ],
    "infer": [
      "self",
      "model_dir",
      "input_path",
      "device",
      "save_dir",
      "dict_path"
    ],
    "compression": [
      "self",
      "weight_path",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "device",
      "use_vdl",
      "save_dir"
    ]
  },
  "VideoClsRunner": {
    "train": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips",
      "save_dir",
      "do_eval"
    ],
    "evaluate": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "export": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "save_dir"
    ],
    "infer": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "compression": [
      "self",
      "config_path",
      "train_cli_args",
      "export_cli_args",
      "device",
      "train_save_dir"
    ]
  },
  "PP3DConfig": {
    "update": [
      "self",
      "dict_like_obj"
    ],
    "load": [
      "self",
      "config_path"
    ],
    "dump": [
      "self",
      "config_path"
    ],
    "update_learning_rate": [
      "self",
      "learning_rate"
    ],
    "update_batch_size": [
      "self",
      "batch_size",
      "mode"
    ],
    "update_epochs": [
      "self",
      "epochs",
      "mode"
    ],
    "update_pretrained_weights": [
      "self",
      "weight_path",
      "is_backbone"
    ],
    "get_epochs_iters": [
      "self"
    ],
    "get_learning_rate": [
      "self"
    ],
    "get_batch_size": [
      "self",
      "mode"
    ],
    "get_qat_epochs_iters": [
      "self"
    ],
    "get_qat_learning_rate": [
      "self"
    ],
    "update_warmup_steps": [
      "self",
      "steps"
    ],
    "update_end_lr": [
      "self",
      "learning_rate"
    ],
    "update_iters": [
      "self",
      "iters"
    ],
    "update_finetune_iters": [
      "self",
      "iters"
    ],
    "update_save_dir": [
      "self",
      "save_dir"
    ]
  },
  "BEVFusionConfig": {
    "update_dataset": [
      "self",
      "dataset_dir",
      "datart_prefix",
      "dataset_type"
    ],
    "_make_nuscenes_mm_dataset_config": [
      "self",
      "dataset_root_path",
      "datart_prefix",
      "version"
    ],
    "_update_amp": [
      "self",
      "amp"
    ],
    "update_class_names": [
      "self",
      "class_names"
    ],
    "update_pretrained_model": [
      "self",
      "load_cam_from",
      "load_lidar_from"
    ],
    "update_weights": [
      "self",
      "weight_path"
    ]
  },
  "BEVFusionModel": {
    "train": [
      "self",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "pretrained",
      "ips",
      "device",
      "resume_path",
      "dy2st",
      "amp",
      "num_workers",
      "use_vdl",
      "save_dir"
    ],
    "evaluate": [
      "self",
      "weight_path",
      "batch_size",
      "ips",
      "device",
      "amp",
      "num_workers"
    ],
    "predict": [
      "self",
      "weight_path",
      "input_path",
      "device",
      "save_dir"
    ],
    "export": [
      "self",
      "weight_path",
      "save_dir"
    ],
    "infer": [
      "self",
      "model_dir",
      "device"
    ],
    "compression": [
      "self",
      "weight_path",
      "ann_file",
      "class_names",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "device",
      "use_vdl",
      "save_dir"
    ]
  },
  "BEVFusionRunner": {
    "train": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips",
      "save_dir",
      "do_eval"
    ],
    "evaluate": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "export": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "infer": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "infer_dir",
      "save_dir"
    ],
    "compression": [
      "self",
      "config_path",
      "train_cli_args",
      "export_cli_args",
      "device",
      "train_save_dir"
    ]
  },
  "BaseSegConfig": {
    "update": [
      "self",
      "dict_like_obj"
    ],
    "load": [
      "self",
      "config_path"
    ],
    "dump": [
      "self",
      "config_path"
    ],
    "update_learning_rate": [
      "self",
      "learning_rate"
    ],
    "update_batch_size": [
      "self",
      "batch_size",
      "mode"
    ],
    "update_log_ranks": [
      "self",
      "device"
    ],
    "update_print_mem_info": [
      "self",
      "print_mem_info"
    ],
    "update_shuffle": [
      "self",
      "shuffle"
    ],
    "update_pretrained_weights": [
      "self",
      "weight_path",
      "is_backbone"
    ],
    "update_dy2st": [
      "self",
      "dy2st"
    ],
    "update_dataset": [
      "self",
      "dataset_dir",
      "dataset_type"
    ],
    "get_epochs_iters": [
      "self"
    ],
    "get_learning_rate": [
      "self"
    ],
    "get_batch_size": [
      "self",
      "mode"
    ],
    "get_qat_epochs_iters": [
      "self"
    ],
    "get_qat_learning_rate": [
      "self"
    ]
  },
  "_set_alias": [
    "model_name",
    "alias"
  ],
  "SegConfig": {
    "update_dataset": [
      "self",
      "dataset_path",
      "dataset_type"
    ],
    "update_num_classes": [
      "self",
      "num_classes"
    ],
    "update_train_crop_size": [
      "self",
      "crop_size"
    ],
    "get_epochs_iters": [
      "self"
    ],
    "get_learning_rate": [
      "self"
    ],
    "get_batch_size": [
      "self",
      "mode"
    ],
    "_make_custom_dataset_config": [
      "self",
      "dataset_root_path"
    ]
  },
  "SegModel": {
    "train": [
      "self",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "ips",
      "device",
      "resume_path",
      "dy2st",
      "amp",
      "num_workers",
      "use_vdl",
      "save_dir"
    ],
    "evaluate": [
      "self",
      "weight_path",
      "batch_size",
      "ips",
      "device",
      "amp",
      "num_workers"
    ],
    "predict": [
      "self",
      "weight_path",
      "input_path",
      "device",
      "save_dir"
    ],
    "analyse": [
      "self",
      "weight_path",
      "ips",
      "device",
      "save_dir"
    ],
    "export": [
      "self",
      "weight_path",
      "save_dir"
    ],
    "infer": [
      "self",
      "model_dir",
      "input_path",
      "device",
      "save_dir"
    ],
    "compression": [
      "self",
      "weight_path",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "device",
      "use_vdl",
      "save_dir"
    ]
  },
  "SegRunner": {
    "train": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips",
      "save_dir",
      "do_eval"
    ],
    "evaluate": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "analyse": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "export": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "infer": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "compression": [
      "self",
      "config_path",
      "train_cli_args",
      "export_cli_args",
      "device",
      "train_save_dir"
    ],
    "_gather_opts_args": [
      "self",
      "args"
    ]
  },
  "PPDetConfigMixin": {
    "load_config_literally": [
      "self",
      "config_path"
    ],
    "dump_literal_config": [
      "self",
      "config_path",
      "dic"
    ],
    "update_from_dict": [
      "self",
      "src_dic",
      "dst_dic"
    ]
  },
  "_PPDetSerializableHandler": {
    "TYPE_KEY": [],
    "EMPTY_TAG": [],
    "__init__": [
      "self",
      "tag",
      "dic"
    ],
    "__repr__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "val"
    ],
    "__delitem__": [
      "self",
      "key"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "has_nonempty_tag": [
      "self"
    ],
    "is_convertible": [
      "cls",
      "obj"
    ],
    "build_from_dict": [
      "cls",
      "dic"
    ]
  },
  "merge_dicts": [
    "src_dic",
    "dst_dic"
  ],
  "_PPDetSerializableConstructor": {
    "construct_sohandler": [
      "self",
      "tag_suffix",
      "node"
    ]
  },
  "_PPDetSerializableLoader": {
    "__init__": [
      "self",
      "stream"
    ]
  },
  "_PPDetSerializableRepresenter": {
    "represent_sohandler": [
      "self",
      "data"
    ]
  },
  "_PPDetSerializableDumper": {
    "__init__": [
      "self",
      "stream",
      "default_style",
      "default_flow_style",
      "canonical",
      "indent",
      "width",
      "allow_unicode",
      "line_break",
      "encoding",
      "explicit_start",
      "explicit_end",
      "version",
      "tags",
      "sort_keys"
    ],
    "ignore_aliases": [
      "self",
      "data"
    ]
  },
  "DetConfig": {
    "load": [
      "self",
      "config_path"
    ],
    "dump": [
      "self",
      "config_path"
    ],
    "update": [
      "self",
      "dict_like_obj"
    ],
    "update_dataset": [
      "self",
      "dataset_path",
      "dataset_type"
    ],
    "_make_dataset_config": [
      "self",
      "dataset_root_path",
      "data_fields",
      "image_dir",
      "train_anno_path",
      "val_anno_path",
      "test_anno_path"
    ],
    "update_ema": [
      "self",
      "use_ema",
      "ema_decay",
      "ema_decay_type",
      "ema_filter_no_grad"
    ],
    "update_learning_rate": [
      "self",
      "learning_rate"
    ],
    "update_warmup_steps": [
      "self",
      "warmup_steps"
    ],
    "update_warmup_enable": [
      "self",
      "use_warmup"
    ],
    "update_cossch_epoch": [
      "self",
      "max_epochs"
    ],
    "update_milestone": [
      "self",
      "milestones"
    ],
    "update_batch_size": [
      "self",
      "batch_size",
      "mode"
    ],
    "update_epochs": [
      "self",
      "epochs"
    ],
    "update_device": [
      "self",
      "device_type"
    ],
    "update_save_dir": [
      "self",
      "save_dir"
    ],
    "update_log_interval": [
      "self",
      "log_interval"
    ],
    "update_eval_interval": [
      "self",
      "eval_interval"
    ],
    "update_save_interval": [
      "self",
      "save_interval"
    ],
    "update_log_ranks": [
      "self",
      "device"
    ],
    "update_print_mem_info": [
      "self",
      "print_mem_info"
    ],
    "update_shared_memory": [
      "self",
      "shared_memeory"
    ],
    "update_shuffle": [
      "self",
      "shuffle"
    ],
    "update_weights": [
      "self",
      "weight_path"
    ],
    "update_pretrained_weights": [
      "self",
      "pretrain_weights"
    ],
    "update_num_class": [
      "self",
      "num_classes"
    ],
    "update_random_size": [
      "self",
      "randomsize"
    ],
    "update_num_workers": [
      "self",
      "num_workers"
    ],
    "_recursively_set": [
      "self",
      "config",
      "update_dict"
    ],
    "update_static_assigner_epochs": [
      "self",
      "static_assigner_epochs"
    ],
    "update_HybridEncoder": [
      "self",
      "update_dict"
    ],
    "get_epochs_iters": [
      "self"
    ],
    "get_log_interval": [
      "self"
    ],
    "get_eval_interval": [
      "self"
    ],
    "get_save_interval": [
      "self"
    ],
    "get_learning_rate": [
      "self"
    ],
    "get_batch_size": [
      "self",
      "mode"
    ],
    "get_qat_epochs_iters": [
      "self"
    ],
    "get_qat_learning_rate": [
      "self"
    ],
    "get_train_save_dir": [
      "self"
    ]
  },
  "DetModel": {
    "train": [
      "self",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "ips",
      "device",
      "resume_path",
      "dy2st",
      "amp",
      "num_workers",
      "use_vdl",
      "save_dir"
    ],
    "evaluate": [
      "self",
      "weight_path",
      "batch_size",
      "ips",
      "device",
      "amp",
      "num_workers"
    ],
    "predict": [
      "self",
      "input_path",
      "weight_path",
      "device",
      "save_dir"
    ],
    "export": [
      "self",
      "weight_path",
      "save_dir"
    ],
    "infer": [
      "self",
      "model_dir",
      "input_path",
      "device",
      "save_dir"
    ],
    "compression": [
      "self",
      "weight_path",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "device",
      "use_vdl",
      "save_dir"
    ]
  },
  "official_categories": [],
  "DetRunner": {
    "train": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips",
      "save_dir",
      "do_eval"
    ],
    "evaluate": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "export": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "infer": [
      "self",
      "cli_args",
      "device"
    ],
    "compression": [
      "self",
      "config_path",
      "train_cli_args",
      "export_cli_args",
      "device",
      "train_save_dir"
    ],
    "_gather_opts_args": [
      "self",
      "args"
    ]
  },
  "InstanceSegConfig": {
    "load": [
      "self",
      "config_path"
    ],
    "dump": [
      "self",
      "config_path"
    ],
    "update": [
      "self",
      "dict_like_obj"
    ],
    "update_dataset": [
      "self",
      "dataset_path",
      "dataset_type"
    ],
    "_make_dataset_config": [
      "self",
      "dataset_root_path",
      "data_fields",
      "image_dir",
      "train_anno_path",
      "val_anno_path",
      "test_anno_path"
    ],
    "update_ema": [
      "self",
      "use_ema",
      "ema_decay",
      "ema_decay_type",
      "ema_filter_no_grad"
    ],
    "update_learning_rate": [
      "self",
      "learning_rate"
    ],
    "update_warmup_steps": [
      "self",
      "warmup_steps"
    ],
    "update_warmup_enable": [
      "self",
      "use_warmup"
    ],
    "update_cossch_epoch": [
      "self",
      "max_epochs"
    ],
    "update_milestone": [
      "self",
      "milestones"
    ],
    "update_batch_size": [
      "self",
      "batch_size",
      "mode"
    ],
    "update_epochs": [
      "self",
      "epochs"
    ],
    "update_device": [
      "self",
      "device_type"
    ],
    "update_save_dir": [
      "self",
      "save_dir"
    ],
    "update_log_interval": [
      "self",
      "log_interval"
    ],
    "update_eval_interval": [
      "self",
      "eval_interval"
    ],
    "update_save_interval": [
      "self",
      "save_interval"
    ],
    "update_log_ranks": [
      "self",
      "device"
    ],
    "update_weights": [
      "self",
      "weight_path"
    ],
    "update_pretrained_weights": [
      "self",
      "pretrain_weights"
    ],
    "update_num_class": [
      "self",
      "num_classes"
    ],
    "update_random_size": [
      "self",
      "randomsize"
    ],
    "update_num_workers": [
      "self",
      "num_workers"
    ],
    "update_static_assigner_epochs": [
      "self",
      "static_assigner_epochs"
    ],
    "get_epochs_iters": [
      "self"
    ],
    "get_log_interval": [
      "self"
    ],
    "get_eval_interval": [
      "self"
    ],
    "get_save_interval": [
      "self"
    ],
    "get_learning_rate": [
      "self"
    ],
    "get_batch_size": [
      "self",
      "mode"
    ],
    "get_qat_epochs_iters": [
      "self"
    ],
    "get_qat_learning_rate": [
      "self"
    ],
    "get_train_save_dir": [
      "self"
    ]
  },
  "InstanceSegModel": {
    "train": [
      "self",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "ips",
      "device",
      "resume_path",
      "dy2st",
      "amp",
      "num_workers",
      "use_vdl",
      "save_dir"
    ],
    "evaluate": [
      "self",
      "weight_path",
      "batch_size",
      "ips",
      "device",
      "amp",
      "num_workers"
    ],
    "predict": [
      "self",
      "input_path",
      "weight_path",
      "device",
      "save_dir"
    ],
    "export": [
      "self",
      "weight_path",
      "save_dir"
    ],
    "infer": [
      "self",
      "model_dir",
      "input_path",
      "device",
      "save_dir"
    ],
    "compression": [
      "self",
      "weight_path",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "device",
      "use_vdl",
      "save_dir"
    ]
  },
  "InstanceSegRunner": {
    "train": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips",
      "save_dir",
      "do_eval"
    ],
    "evaluate": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "export": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "infer": [
      "self",
      "cli_args",
      "device"
    ],
    "compression": [
      "self",
      "config_path",
      "train_cli_args",
      "export_cli_args",
      "device",
      "train_save_dir"
    ],
    "_gather_opts_args": [
      "self",
      "args"
    ]
  },
  "TimesNetAD_CFG_PATH": [],
  "AE_CFG_PATH": [],
  "DL_CFG_PATH": [],
  "PATCHTST_CFG_PATH": [],
  "NS_CFG_PATH": [],
  "TSAnomalyConfig": {
    "update_input_len": [
      "self",
      "seq_len"
    ],
    "update_dataset": [
      "self",
      "dataset_dir",
      "dataset_type"
    ],
    "update_basic_info": [
      "self",
      "info_params"
    ],
    "_make_custom_dataset_config": [
      "self",
      "dataset_root_path"
    ]
  },
  "TSADRunner": {
    "train": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips",
      "save_dir",
      "do_eval"
    ],
    "evaluate": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "export": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "infer": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "compression": [
      "self",
      "config_path",
      "train_cli_args",
      "export_cli_args",
      "device",
      "train_save_dir"
    ],
    "_gather_opts_args": [
      "self",
      "args"
    ]
  },
  "BaseTSConfig": {
    "update": [
      "self",
      "dict_like_obj"
    ],
    "load": [
      "self",
      "config_file_path"
    ],
    "dump": [
      "self",
      "config_file_path"
    ],
    "update_epochs": [
      "self",
      "epochs"
    ],
    "update_to_static": [
      "self",
      "dy2st"
    ],
    "update_amp": [
      "self",
      "amp"
    ],
    "update_weights": [
      "self",
      "weight_path"
    ],
    "update_learning_rate": [
      "self",
      "learning_rate"
    ],
    "update_batch_size": [
      "self",
      "batch_size",
      "mode"
    ],
    "update_pretrained_weights": [
      "self",
      "weight_path"
    ],
    "update_log_ranks": [
      "self",
      "device"
    ],
    "update_print_mem_info": [
      "self",
      "print_mem_info"
    ],
    "update_log_interval": [
      "self",
      "log_interval"
    ],
    "update_dataset": [
      "self",
      "dataset_dir",
      "dataset_type"
    ],
    "update_save_dir": [
      "self",
      "save_dir"
    ],
    "get_epochs_iters": [
      "self"
    ],
    "get_learning_rate": [
      "self"
    ],
    "get_batch_size": [
      "self",
      "mode"
    ]
  },
  "TSModel": {
    "train": [
      "self",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "ips",
      "device",
      "resume_path",
      "dy2st",
      "amp",
      "num_workers",
      "use_vdl",
      "save_dir"
    ],
    "evaluate": [
      "self",
      "weight_path",
      "batch_size",
      "ips",
      "device",
      "amp",
      "num_workers"
    ],
    "predict": [
      "self",
      "weight_path",
      "input_path",
      "device",
      "save_dir"
    ],
    "export": [
      "self",
      "weight_path",
      "save_dir",
      "device"
    ],
    "infer": [
      "self",
      "model_dir",
      "input_path",
      "device",
      "save_dir"
    ],
    "compression": [
      "self",
      "weight_path",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "device",
      "use_vdl",
      "save_dir"
    ]
  },
  "TSRunner": {
    "train": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips",
      "save_dir",
      "do_eval"
    ],
    "evaluate": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "export": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "infer": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "compression": [
      "self",
      "config_path",
      "train_cli_args",
      "export_cli_args",
      "device",
      "train_save_dir"
    ],
    "_gather_opts_args": [
      "self",
      "args"
    ]
  },
  "TimesNetCLS_CFG_PATH": [],
  "TSClassifyConfig": {
    "update_dataset": [
      "self",
      "dataset_dir",
      "dataset_type"
    ],
    "update_basic_info": [
      "self",
      "info_params"
    ],
    "_make_custom_dataset_config": [
      "self",
      "dataset_root_path"
    ]
  },
  "TSCLSRunner": {
    "train": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips",
      "save_dir",
      "do_eval"
    ],
    "evaluate": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "export": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "infer": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "compression": [
      "self",
      "config_path",
      "train_cli_args",
      "export_cli_args",
      "device",
      "train_save_dir"
    ],
    "_gather_opts_args": [
      "self",
      "args"
    ]
  },
  "DLinear_CFG_PATH": [],
  "TiDE_CFG_PATH": [],
  "PatchTST_CFG_PATH": [],
  "Nonstationary_CFG_PATH": [],
  "TimesNet_CFG_PATH": [],
  "LongForecastConfig": {
    "update_input_len": [
      "self",
      "seq_len"
    ],
    "update_predict_len": [
      "self",
      "predict_len"
    ],
    "update_sampling_stride": [
      "self",
      "sampling_stride"
    ],
    "update_dataset": [
      "self",
      "dataset_dir",
      "dataset_type"
    ],
    "update_basic_info": [
      "self",
      "info_params"
    ],
    "update_patience": [
      "self",
      "patience"
    ],
    "_make_custom_dataset_config": [
      "self",
      "dataset_root_path"
    ]
  },
  "FormulaRecConfig": {
    "update": [
      "self",
      "dict_like_obj"
    ],
    "load": [
      "self",
      "config_file_path"
    ],
    "dump": [
      "self",
      "config_file_path"
    ],
    "update_dataset": [
      "self",
      "dataset_path",
      "dataset_type"
    ],
    "update_batch_size": [
      "self",
      "batch_size",
      "mode"
    ],
    "update_batch_size_pair": [
      "self",
      "batch_size",
      "mode"
    ],
    "update_learning_rate": [
      "self",
      "learning_rate"
    ],
    "update_label_dict_path": [
      "self",
      "dict_path"
    ],
    "update_warmup_epochs": [
      "self",
      "warmup_epochs"
    ],
    "update_pretrained_weights": [
      "self",
      "pretrained_model"
    ],
    "update_class_path": [
      "self",
      "class_path"
    ],
    "_update_amp": [
      "self",
      "amp"
    ],
    "update_device": [
      "self",
      "device"
    ],
    "_update_epochs": [
      "self",
      "epochs"
    ],
    "_update_checkpoints": [
      "self",
      "resume_path"
    ],
    "_update_to_static": [
      "self",
      "dy2st"
    ],
    "_update_use_vdl": [
      "self",
      "use_vdl"
    ],
    "_update_output_dir": [
      "self",
      "save_dir"
    ],
    "update_log_interval": [
      "self",
      "log_interval"
    ],
    "update_log_ranks": [
      "self",
      "device"
    ],
    "update_print_mem_info": [
      "self",
      "print_mem_info"
    ],
    "update_shared_memory": [
      "self",
      "shared_memeory"
    ],
    "update_shuffle": [
      "self",
      "shuffle"
    ],
    "update_cal_metrics": [
      "self",
      "cal_metrics"
    ],
    "update_seed": [
      "self",
      "seed"
    ],
    "_update_eval_interval_by_epoch": [
      "self",
      "eval_interval"
    ],
    "update_eval_interval": [
      "self",
      "eval_interval",
      "eval_start_step"
    ],
    "update_delimiter": [
      "self",
      "delimiter",
      "mode"
    ],
    "_update_save_interval": [
      "self",
      "save_interval"
    ],
    "update_save_interval": [
      "self",
      "save_interval"
    ],
    "_update_infer_img": [
      "self",
      "infer_img",
      "infer_list"
    ],
    "_update_save_inference_dir": [
      "self",
      "save_inference_dir"
    ],
    "_update_save_res_path": [
      "self",
      "save_res_path"
    ],
    "update_num_workers": [
      "self",
      "num_workers",
      "modes"
    ],
    "_get_model_type": [
      "self"
    ],
    "get_epochs_iters": [
      "self"
    ],
    "get_learning_rate": [
      "self"
    ],
    "get_batch_size": [
      "self",
      "mode"
    ],
    "get_qat_epochs_iters": [
      "self"
    ],
    "get_qat_learning_rate": [
      "self"
    ],
    "get_label_dict_path": [
      "self"
    ],
    "_get_dataset_root": [
      "self"
    ],
    "_get_infer_shape": [
      "self"
    ],
    "get_train_save_dir": [
      "self"
    ],
    "get_predict_save_dir": [
      "self"
    ]
  },
  "FormulaRecModel": {
    "METRICS": [],
    "train": [
      "self",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "ips",
      "device",
      "resume_path",
      "dy2st",
      "amp",
      "num_workers",
      "use_vdl",
      "save_dir"
    ],
    "evaluate": [
      "self",
      "weight_path",
      "batch_size",
      "ips",
      "device",
      "amp",
      "num_workers"
    ],
    "predict": [
      "self",
      "weight_path",
      "input_path",
      "device",
      "save_dir"
    ],
    "export": [
      "self",
      "weight_path",
      "save_dir"
    ],
    "infer": [
      "self",
      "model_dir",
      "input_path",
      "device",
      "save_dir"
    ],
    "compression": [
      "self",
      "weight_path",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "device",
      "use_vdl",
      "save_dir"
    ]
  },
  "FormulaRecRunner": {
    "train": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips",
      "save_dir",
      "do_eval"
    ],
    "evaluate": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "export": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "save_dir"
    ],
    "infer": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "compression": [
      "self",
      "config_path",
      "train_cli_args",
      "export_cli_args",
      "device",
      "train_save_dir"
    ]
  },
  "TextDetConfig": {
    "update_batch_size": [
      "self",
      "batch_size"
    ],
    "update_dataset": [
      "self",
      "dataset_path",
      "dataset_type"
    ]
  },
  "TextDetModel": {
    "infer": [
      "self",
      "model_dir",
      "input_path",
      "device",
      "save_dir"
    ]
  },
  "TextDetRunner": {
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "infer": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ]
  },
  "TextRecConfig": {
    "update": [
      "self",
      "dict_like_obj"
    ],
    "load": [
      "self",
      "config_file_path"
    ],
    "dump": [
      "self",
      "config_file_path"
    ],
    "update_dataset": [
      "self",
      "dataset_path",
      "dataset_type"
    ],
    "update_dataset_by_list": [
      "self",
      "label_file_list",
      "ratio_list"
    ],
    "update_batch_size": [
      "self",
      "batch_size",
      "mode"
    ],
    "update_batch_size_pair": [
      "self",
      "batch_size_train",
      "batch_size_val",
      "mode"
    ],
    "update_learning_rate": [
      "self",
      "learning_rate"
    ],
    "update_label_dict_path": [
      "self",
      "dict_path"
    ],
    "update_warmup_epochs": [
      "self",
      "warmup_epochs"
    ],
    "update_pretrained_weights": [
      "self",
      "pretrained_model"
    ],
    "update_class_path": [
      "self",
      "class_path"
    ],
    "_update_amp": [
      "self",
      "amp"
    ],
    "update_device": [
      "self",
      "device"
    ],
    "_update_epochs": [
      "self",
      "epochs"
    ],
    "_update_checkpoints": [
      "self",
      "resume_path"
    ],
    "_update_to_static": [
      "self",
      "dy2st"
    ],
    "_update_use_vdl": [
      "self",
      "use_vdl"
    ],
    "_update_output_dir": [
      "self",
      "save_dir"
    ],
    "update_log_interval": [
      "self",
      "log_interval"
    ],
    "update_log_ranks": [
      "self",
      "device"
    ],
    "update_print_mem_info": [
      "self",
      "print_mem_info"
    ],
    "update_shared_memory": [
      "self",
      "shared_memeory"
    ],
    "update_shuffle": [
      "self",
      "shuffle"
    ],
    "update_cal_metrics": [
      "self",
      "cal_metrics"
    ],
    "update_seed": [
      "self",
      "seed"
    ],
    "_update_eval_interval_by_epoch": [
      "self",
      "eval_interval"
    ],
    "update_eval_interval": [
      "self",
      "eval_interval",
      "eval_start_step"
    ],
    "_update_save_interval": [
      "self",
      "save_interval"
    ],
    "update_save_interval": [
      "self",
      "save_interval"
    ],
    "_update_infer_img": [
      "self",
      "infer_img",
      "infer_list"
    ],
    "_update_save_inference_dir": [
      "self",
      "save_inference_dir"
    ],
    "_update_save_res_path": [
      "self",
      "save_res_path"
    ],
    "update_num_workers": [
      "self",
      "num_workers",
      "modes"
    ],
    "_get_model_type": [
      "self"
    ],
    "get_epochs_iters": [
      "self"
    ],
    "get_learning_rate": [
      "self"
    ],
    "get_batch_size": [
      "self",
      "mode"
    ],
    "get_qat_epochs_iters": [
      "self"
    ],
    "get_qat_learning_rate": [
      "self"
    ],
    "get_label_dict_path": [
      "self"
    ],
    "_get_dataset_root": [
      "self"
    ],
    "_get_infer_shape": [
      "self"
    ],
    "get_train_save_dir": [
      "self"
    ],
    "get_predict_save_dir": [
      "self"
    ]
  },
  "TextRecModel": {
    "METRICS": [],
    "train": [
      "self",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "ips",
      "device",
      "resume_path",
      "dy2st",
      "amp",
      "num_workers",
      "use_vdl",
      "save_dir"
    ],
    "evaluate": [
      "self",
      "weight_path",
      "batch_size",
      "ips",
      "device",
      "amp",
      "num_workers"
    ],
    "predict": [
      "self",
      "weight_path",
      "input_path",
      "device",
      "save_dir"
    ],
    "export": [
      "self",
      "weight_path",
      "save_dir"
    ],
    "infer": [
      "self",
      "model_dir",
      "input_path",
      "device",
      "save_dir"
    ],
    "compression": [
      "self",
      "weight_path",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "device",
      "use_vdl",
      "save_dir"
    ]
  },
  "TextRecRunner": {
    "train": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips",
      "save_dir",
      "do_eval"
    ],
    "evaluate": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "export": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "save_dir"
    ],
    "infer": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "compression": [
      "self",
      "config_path",
      "train_cli_args",
      "export_cli_args",
      "device",
      "train_save_dir"
    ]
  },
  "TableRecConfig": {
    "update_dataset": [
      "self",
      "dataset_path",
      "dataset_type"
    ],
    "_get_infer_shape": [
      "self"
    ]
  },
  "TableRecModel": {
    "METRICS": [],
    "predict": [
      "self",
      "weight_path",
      "input_path",
      "device",
      "save_dir"
    ],
    "infer": [
      "self",
      "model_dir",
      "input_path",
      "device",
      "save_dir"
    ]
  },
  "TableRecRunner": {
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "infer": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ]
  },
  "_Record": {
    "__init__": [
      "self",
      "dict_"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Registry": {
    "__init__": [
      "self",
      "required_keys",
      "primary_key"
    ],
    "register_record": [
      "self",
      "record",
      "validate",
      "allow_overwrite"
    ],
    "_validate_record": [
      "self",
      "record"
    ],
    "query": [
      "self",
      "prim_key"
    ],
    "all_records": [
      "self"
    ],
    "is_compatible_with": [
      "self",
      "registry"
    ],
    "__str__": [
      "self"
    ]
  },
  "build_runner_from_model_info": [
    "model_info"
  ],
  "build_model_from_model_info": [
    "model_info",
    "config"
  ],
  "MODEL_INFO_REQUIRED_KEYS": [],
  "MODEL_INFO_PRIMARY_KEY": [],
  "MODEL_INFO_REGISTRY": [],
  "SUITE_INFO_REQUIRED_KEYS": [],
  "SUITE_INFO_PRIMARY_KEY": [],
  "SUITE_INFO_REGISTRY": [],
  "get_registered_model_info": [],
  "get_registered_suite_info": [],
  "register_model_info": [],
  "register_suite_info": [],
  "_create_config": [
    "model_name",
    "config_path"
  ],
  "Config": [],
  "_Config": {
    "_DICT_TYPE_": [],
    "__init__": [
      "self",
      "cfg"
    ],
    "dict": [
      "self"
    ],
    "__getattr__": [
      "self",
      "key"
    ],
    "set_val": [
      "self",
      "key",
      "val"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "val"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "new_config": [
      "self"
    ],
    "copy": [
      "self"
    ],
    "pop": [
      "self",
      "key"
    ],
    "__repr__": [
      "self"
    ],
    "reset_from_dict": [
      "self",
      "dict_like_obj"
    ]
  },
  "BaseConfig": {
    "__init__": [
      "self",
      "model_name",
      "config_path",
      "cfg"
    ],
    "update_device": [
      "self",
      "device"
    ],
    "load": [
      "self",
      "config_path"
    ],
    "dump": [
      "self",
      "config_path"
    ],
    "update": [
      "self",
      "dict_like_obj"
    ],
    "update_dataset": [
      "self",
      "dataset_dir",
      "dataset_type"
    ],
    "update_learning_rate": [
      "self",
      "learning_rate"
    ],
    "update_batch_size": [
      "self",
      "batch_size",
      "mode"
    ],
    "update_pretrained_weights": [
      "self",
      "weight_path",
      "is_backbone"
    ],
    "get_epochs_iters": [
      "self"
    ],
    "get_learning_rate": [
      "self"
    ],
    "get_batch_size": [
      "self",
      "mode"
    ],
    "get_qat_epochs_iters": [
      "self"
    ],
    "get_qat_learning_rate": [
      "self"
    ],
    "copy": [
      "self"
    ]
  },
  "format_cfg": [
    "cfg",
    "indent"
  ],
  "_create_model": [
    "model_name",
    "config"
  ],
  "PaddleModel": [],
  "BaseModel": {
    "_API_FULL_LIST": [],
    "_API_SUPPORTED_OPTS_KEY_PATTERN": [],
    "__init__": [
      "self",
      "model_name",
      "config"
    ],
    "train": [
      "self",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "ips",
      "device",
      "resume_path",
      "dy2st",
      "amp",
      "num_workers",
      "use_vdl",
      "save_dir"
    ],
    "evaluate": [
      "self",
      "weight_path",
      "batch_size",
      "ips",
      "device",
      "amp",
      "num_workers"
    ],
    "predict": [
      "self",
      "weight_path",
      "input_path",
      "device",
      "save_dir"
    ],
    "export": [
      "self",
      "weight_path",
      "save_dir"
    ],
    "infer": [
      "self",
      "model_dir",
      "input_path",
      "device",
      "save_dir"
    ],
    "compression": [
      "self",
      "weight_path",
      "batch_size",
      "learning_rate",
      "epochs_iters",
      "device",
      "use_vdl",
      "save_dir"
    ],
    "_create_new_config_file": [
      "self"
    ],
    "_create_new_val_json_file": [
      "self"
    ],
    "supported_apis": [
      "self"
    ],
    "supported_train_opts": [
      "self"
    ],
    "supported_evaluate_opts": [
      "self"
    ],
    "supported_predict_opts": [
      "self"
    ],
    "supported_infer_opts": [
      "self"
    ],
    "supported_compression_opts": [
      "self"
    ],
    "supported_dataset_types": [
      "self"
    ],
    "_assert_empty_kwargs": [
      "kwargs"
    ],
    "_patch_apis": [
      "self"
    ]
  },
  "_CheckFailed": {
    "check_failed_error": [],
    "__init__": [
      "self",
      "arg_name",
      "arg_val",
      "legal_vals"
    ],
    "__str__": [
      "self"
    ]
  },
  "_APICallArgsChecker": {
    "__init__": [
      "self",
      "legal_vals"
    ],
    "check": [
      "self",
      "args"
    ]
  },
  "_CheckDevice": {
    "__init__": [
      "self",
      "legal_vals",
      "check_mc"
    ],
    "check": [
      "self",
      "args"
    ]
  },
  "_CheckDy2St": {
    "check": [
      "self",
      "args"
    ]
  },
  "_CheckAMP": {
    "check": [
      "self",
      "args"
    ]
  },
  "BaseRunner": {
    "__init__": [
      "self",
      "runner_root_path"
    ],
    "prepare": [
      "self"
    ],
    "train": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips",
      "save_dir",
      "do_eval"
    ],
    "evaluate": [
      "self",
      "config_path",
      "cli_args",
      "device",
      "ips"
    ],
    "predict": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "export": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "infer": [
      "self",
      "config_path",
      "cli_args",
      "device"
    ],
    "compression": [
      "self",
      "config_path",
      "train_cli_args",
      "export_cli_args",
      "device",
      "train_save_dir"
    ],
    "distributed": [
      "self",
      "device",
      "ips",
      "log_dir"
    ],
    "run_cmd": [
      "self",
      "cmd",
      "env",
      "switch_wdir",
      "silent",
      "echo",
      "capture_output",
      "log_path"
    ],
    "_get_dist_train_log_dir": [
      "self",
      "log_dir"
    ],
    "_get_train_log_path": [
      "self",
      "log_dir"
    ]
  },
  "InferOnlyRunner": {
    "train": [
      "self"
    ],
    "evaluate": [
      "self"
    ],
    "predict": [
      "self"
    ],
    "export": [
      "self"
    ],
    "compression": [
      "self"
    ]
  },
  "CLIArgument": {
    "__init__": [
      "self",
      "key"
    ],
    "__repr__": [
      "self"
    ],
    "lst": [
      "self"
    ]
  },
  "gather_opts_args": [
    "args",
    "opts_key"
  ],
  "run_cmd": [
    "cmd",
    "env",
    "silent",
    "cwd",
    "timeout",
    "echo",
    "pipe_stdout",
    "pipe_stderr",
    "blocking",
    "async_run",
    "text"
  ],
  "CompletedProcess": {
    "__slots__": [],
    "__init__": [
      "self",
      "args",
      "returncode",
      "stdout",
      "stderr"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "__setattr__": [
      "self",
      "name",
      "val"
    ],
    "__repr__": [
      "self"
    ]
  },
  "BaseCVResult": {
    "__init__": [
      "self",
      "data"
    ],
    "_get_input_fn": [
      "self"
    ]
  },
  "BaseVideoResult": {
    "INPUT_IMG_KEY": [],
    "__init__": [
      "self",
      "data"
    ]
  },
  "WordMixin": {
    "__init__": [
      "self"
    ],
    "_to_word": [
      "self"
    ],
    "word": [
      "self"
    ],
    "save_to_word": [
      "self",
      "save_path"
    ]
  },
  "LatexMixin": {
    "__init__": [
      "self"
    ],
    "_to_latex": [
      "self"
    ],
    "latex": [
      "self"
    ],
    "save_to_latex": [
      "self",
      "save_path"
    ]
  },
  "StrMixin": {
    "str": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "print": [
      "self"
    ]
  },
  "_format_data": [
    "obj"
  ],
  "JsonMixin": {
    "__init__": [
      "self"
    ],
    "_to_json": [
      "self"
    ],
    "json": [
      "self"
    ],
    "save_to_json": [
      "self",
      "save_path",
      "indent",
      "ensure_ascii"
    ],
    "_to_str": [
      "self",
      "json_format",
      "indent",
      "ensure_ascii"
    ],
    "print": [
      "self",
      "json_format",
      "indent",
      "ensure_ascii"
    ]
  },
  "Base64Mixin": {
    "__init__": [
      "self"
    ],
    "_to_base64": [
      "self"
    ],
    "base64": [
      "self"
    ],
    "save_to_base64": [
      "self",
      "save_path"
    ]
  },
  "ImgMixin": {
    "__init__": [
      "self",
      "backend"
    ],
    "_to_img": [
      "self"
    ],
    "img": [
      "self"
    ],
    "save_to_img": [
      "self",
      "save_path"
    ]
  },
  "CSVMixin": {
    "__init__": [
      "self",
      "backend"
    ],
    "csv": [
      "self"
    ],
    "_to_csv": [
      "self"
    ],
    "save_to_csv": [
      "self",
      "save_path"
    ]
  },
  "HtmlMixin": {
    "__init__": [
      "self"
    ],
    "html": [
      "self"
    ],
    "_to_html": [
      "self"
    ],
    "save_to_html": [
      "self",
      "save_path"
    ]
  },
  "XlsxMixin": {
    "__init__": [
      "self"
    ],
    "xlsx": [
      "self"
    ],
    "_to_xlsx": [
      "self"
    ],
    "save_to_xlsx": [
      "self",
      "save_path"
    ]
  },
  "VideoMixin": {
    "__init__": [
      "self",
      "backend"
    ],
    "_to_video": [
      "self"
    ],
    "video": [
      "self"
    ],
    "save_to_video": [
      "self",
      "save_path"
    ]
  },
  "AudioMixin": {
    "__init__": [
      "self",
      "backend"
    ],
    "_to_audio": [
      "self"
    ],
    "audio": [
      "self"
    ],
    "save_to_audio": [
      "self",
      "save_path"
    ]
  },
  "MarkdownMixin": {
    "MARKDOWN_SAVE_KEYS": [],
    "__init__": [
      "self"
    ],
    "_to_markdown": [
      "self",
      "pretty",
      "show_formula_number"
    ],
    "markdown": [
      "self"
    ],
    "save_to_markdown": [
      "self",
      "save_path",
      "pretty",
      "show_formula_number"
    ],
    "_save_data": [
      "self",
      "save_mkd_func",
      "save_img_func",
      "save_path",
      "data"
    ]
  },
  "BaseTSResult": {
    "INPUT_TS_KEY": [],
    "__init__": [
      "self",
      "data"
    ]
  },
  "CopyableWeakMethod": {
    "__copy__": [
      "self"
    ],
    "__deepcopy__": [
      "self",
      "memo"
    ]
  },
  "AutoWeakList": {
    "append": [
      "self",
      "item"
    ],
    "__iter__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ]
  },
  "BaseResult": {
    "__init__": [
      "self",
      "data"
    ],
    "save_all": [
      "self",
      "save_path"
    ],
    "_get_input_fn": [
      "self"
    ]
  },
  "BaseAudioResult": {
    "INPUT_AUDIO_KEY": [],
    "__init__": [
      "self",
      "data"
    ]
  },
  "_EasyDict": {
    "__getattr__": [
      "self",
      "key"
    ],
    "__setattr__": [
      "self",
      "key",
      "value"
    ]
  },
  "SampleMeta": {
    "__slots__": [],
    "__init__": [
      "self"
    ]
  },
  "Sample": {
    "_VALID_MODALITIES": [],
    "__init__": [
      "self",
      "path",
      "modality"
    ]
  },
  "ReadNuscenesData": {
    "__init__": [
      "self",
      "dataset_root",
      "load_interval",
      "noise_sensor_type",
      "drop_frames",
      "drop_set",
      "modality",
      "extrinsics_noise",
      "extrinsics_noise_type"
    ],
    "get_data_info": [
      "self",
      "info"
    ],
    "prepare_test_data": [
      "self",
      "info"
    ],
    "add_new_fields": [
      "self",
      "sample"
    ],
    "__call__": [
      "self",
      "batch_data"
    ]
  },
  "ReadImage": {
    "__init__": [
      "self",
      "format"
    ],
    "__call__": [
      "self",
      "imgs"
    ],
    "read": [
      "self",
      "img"
    ]
  },
  "ReadAudio": {
    "__init__": [
      "self"
    ],
    "read": [
      "self",
      "input"
    ]
  },
  "ReadVideo": {
    "__init__": [
      "self",
      "backend",
      "num_seg",
      "seg_len",
      "sample_type"
    ],
    "__call__": [
      "self",
      "videos"
    ],
    "_read": [
      "self",
      "file_path"
    ],
    "_read_video": [
      "self",
      "video_path"
    ]
  },
  "ReadTS": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "ts_list"
    ],
    "read": [
      "self",
      "ts"
    ]
  },
  "DocVLMBatchSampler": {
    "model_names_only_supports_batchsize_of_one": [],
    "__init__": [
      "self",
      "model_name",
      "batch_size"
    ],
    "sample": [
      "self",
      "inputs"
    ],
    "batch_size": [
      "self",
      "batch_size"
    ]
  },
  "AudioBatchSampler": {
    "__init__": [
      "self"
    ],
    "_download_from_url": [
      "self",
      "in_path"
    ],
    "sample": [
      "self",
      "inputs"
    ],
    "batch_size": [
      "self",
      "batch_size"
    ]
  },
  "VideoBatchSampler": {
    "SUFFIX": [],
    "_download_from_url": [
      "self",
      "in_path"
    ],
    "_get_files_list": [
      "self",
      "fp"
    ],
    "sample": [
      "self",
      "inputs"
    ]
  },
  "MarkDownBatchSampler": {
    "SUFFIX": [],
    "__init__": [
      "self"
    ],
    "_download_from_url": [
      "self",
      "in_path"
    ],
    "_get_files_list": [
      "self",
      "fp"
    ],
    "sample": [
      "self",
      "inputs"
    ]
  },
  "Det3DBatchSampler": {
    "__init__": [
      "self",
      "temp_dir"
    ],
    "_download_from_url": [
      "self",
      "in_path"
    ],
    "batch_size": [
      "self",
      "batch_size"
    ],
    "load_annotations": [
      "self",
      "ann_file",
      "data_root_dir"
    ],
    "sample": [
      "self",
      "inputs"
    ],
    "_rand_batch": [
      "self",
      "data_size"
    ],
    "extract_tar": [
      "self",
      "tar_path",
      "extract_path"
    ]
  },
  "Batch": {
    "__init__": [
      "self"
    ],
    "append": [
      "self",
      "instance",
      "input_path"
    ],
    "reset": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "BaseBatchSampler": {
    "__init__": [
      "self",
      "batch_size"
    ],
    "batch_size": [
      "self",
      "batch_size"
    ],
    "__call__": [
      "self",
      "input"
    ],
    "sample": [
      "self"
    ],
    "_rand_batch": [
      "self",
      "batch_size"
    ]
  },
  "TSBatchSampler": {
    "SUFFIX": [],
    "_download_from_url": [
      "self",
      "in_path"
    ],
    "_get_files_list": [
      "self",
      "fp"
    ],
    "sample": [
      "self",
      "inputs"
    ]
  },
  "TextBatchSampler": {
    "__init__": [
      "self"
    ],
    "sample": [
      "self",
      "inputs"
    ],
    "batch_size": [
      "self",
      "batch_size"
    ]
  },
  "ImgBatch": {
    "__init__": [
      "self"
    ],
    "append": [
      "self",
      "instance",
      "input_path",
      "page_index",
      "page_count"
    ],
    "reset": [
      "self"
    ]
  },
  "ImageBatchSampler": {
    "IMG_SUFFIX": [],
    "PDF_SUFFIX": [],
    "__init__": [
      "self"
    ],
    "_download_from_url": [
      "self",
      "in_path"
    ],
    "_get_files_list": [
      "self",
      "fp"
    ],
    "sample": [
      "self",
      "inputs"
    ]
  },
  "model_name_to_module_name": [
    "model_name"
  ],
  "check_backend": [
    "backend"
  ],
  "get_arg_parser": [],
  "run_genai_server": [
    "args"
  ],
  "SUPPORTED_BACKENDS": [],
  "DEFAULT_BACKEND": [],
  "load_backend_config": [
    "config_path"
  ],
  "update_backend_config": [
    "config",
    "overrides"
  ],
  "set_config_defaults": [
    "config",
    "defaults"
  ],
  "backend_config_to_args": [
    "config",
    "convert_underscores_to_dashes"
  ],
  "run_sglang_server": [
    "host",
    "port",
    "model_name",
    "model_dir",
    "config",
    "chat_template_path"
  ],
  "run_fastdeploy_server": [
    "host",
    "port",
    "model_name",
    "model_dir",
    "config",
    "chat_template_path"
  ],
  "register_models": [],
  "run_vllm_server": [
    "host",
    "port",
    "model_name",
    "model_dir",
    "config",
    "chat_template_path"
  ],
  "NETWORK_CLASS_GETTER_KEY": [],
  "PROCESSOR_CLASS_GETTER_KEY": [],
  "CONFIG_GETTER_KEY": [],
  "CHAT_TEMPLATE_PATH_GETTER_KEY": [],
  "DEFAULT_CHAT_TEMPLATE_FILENAME": [],
  "ALL_MODEL_INFO": [],
  "_check_model_name_and_backend": [
    "model_name",
    "backend"
  ],
  "is_integrated_model_available": [
    "model_name",
    "backend"
  ],
  "get_model_dir": [
    "model_name",
    "backend"
  ],
  "get_model_components": [
    "model_name",
    "backend"
  ],
  "get_default_config": [
    "model_name",
    "backend"
  ],
  "get_chat_template_path": [
    "model_name",
    "backend",
    "model_dir"
  ],
  "get_network_class": [
    "backend"
  ],
  "get_processor_class": [
    "backend"
  ],
  "TRT_BLOCKLIST": [],
  "get_colormap": [
    "rgb"
  ],
  "get_color_map_list": [
    "num_classes"
  ],
  "font_colormap": [
    "color_index"
  ],
  "LazyLoadDict": {
    "__init__": [
      "self"
    ],
    "_initialize": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "_load": [
      "self"
    ]
  },
  "OLD_IR_TRT_PRECISION_MAP_CLASS": {
    "_load": [
      "self"
    ]
  },
  "PIR_TRT_PRECISION_MAP_CLASS": {
    "_load": [
      "self"
    ]
  },
  "OLD_IR_TRT_PRECISION_MAP": [],
  "OLD_IR_TRT_CFG_DEFAULT_SETTING": [],
  "OLD_IR_TRT_CFG_SETTING": [],
  "DISABLE_TRT_HALF_OPS_CONFIG": [],
  "PIR_TRT_PRECISION_MAP": [],
  "PIR_TRT_CFG_SETTING": [],
  "get_default_run_mode": [
    "model_name",
    "device_type"
  ],
  "PaddlePredictorOption": {
    "SUPPORT_RUN_MODE": [],
    "SUPPORT_DEVICE": [],
    "__init__": [
      "self"
    ],
    "copy": [
      "self"
    ],
    "_init_option": [
      "self"
    ],
    "setdefault_by_model_name": [
      "self",
      "model_name"
    ],
    "_get_default_config": [
      "self",
      "model_name"
    ],
    "_update": [
      "self",
      "k",
      "v"
    ],
    "run_mode": [
      "self",
      "run_mode"
    ],
    "device_type": [
      "self",
      "device_type"
    ],
    "device_id": [
      "self",
      "device_id"
    ],
    "cpu_threads": [
      "self",
      "cpu_threads"
    ],
    "delete_pass": [
      "self",
      "delete_pass"
    ],
    "enable_new_ir": [
      "self",
      "enable_new_ir"
    ],
    "enable_cinn": [
      "self",
      "enable_cinn"
    ],
    "trt_cfg_setting": [
      "self",
      "config"
    ],
    "trt_use_dynamic_shapes": [
      "self",
      "trt_use_dynamic_shapes"
    ],
    "trt_collect_shape_range_info": [
      "self",
      "trt_collect_shape_range_info"
    ],
    "trt_discard_cached_shape_range_info": [
      "self",
      "trt_discard_cached_shape_range_info"
    ],
    "trt_dynamic_shapes": [
      "self",
      "trt_dynamic_shapes"
    ],
    "trt_dynamic_shape_input_data": [
      "self",
      "trt_dynamic_shape_input_data"
    ],
    "trt_shape_range_info_path": [
      "self",
      "trt_shape_range_info_path"
    ],
    "trt_allow_rebuild_at_runtime": [
      "self",
      "trt_allow_rebuild_at_runtime"
    ],
    "mkldnn_cache_capacity": [
      "self",
      "capacity"
    ],
    "shape_info_filename": [
      "self",
      "shape_info_filename"
    ],
    "set_device": [
      "self",
      "device"
    ],
    "get_support_run_mode": [
      "self"
    ],
    "get_support_device": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "key"
    ],
    "__eq__": [
      "self",
      "obj"
    ],
    "_has_setter": [
      "self",
      "attr"
    ],
    "_get_settable_attributes": [
      "self"
    ]
  },
  "MKLDNN_BLOCKLIST": [],
  "PaddleInferenceInfo": {},
  "TensorRTInfo": {},
  "InferenceBackendInfoCollection": {},
  "HPIInfo": {},
  "OpenVINOConfig": {},
  "ONNXRuntimeConfig": {},
  "TensorRTConfig": {},
  "OMConfig": {},
  "HPIConfig": {},
  "ModelInfo": {},
  "_get_hpi_model_info_collection": [],
  "suggest_inference_backend_and_config": [
    "hpi_config",
    "model_paths"
  ],
  "NEWIR_BLOCKLIST": [],
  "pdfium_lock": [],
  "ALL_MODELS": [],
  "OCR_MODELS": [],
  "_BaseModelHoster": {
    "alias": [],
    "model_list": [],
    "healthcheck_url": [],
    "_healthcheck_timeout": [],
    "__init__": [
      "self",
      "save_dir"
    ],
    "get_model": [
      "self",
      "model_name"
    ],
    "_download": [
      "self"
    ],
    "is_available": [
      "cls"
    ]
  },
  "_BosModelHoster": {
    "model_list": [],
    "alias": [],
    "healthcheck_url": [],
    "version": [],
    "base_url": [],
    "special_model_fn": [],
    "_download": [
      "self",
      "model_name",
      "save_dir"
    ]
  },
  "_HuggingFaceModelHoster": {
    "model_list": [],
    "alias": [],
    "healthcheck_url": [],
    "_download": [
      "self",
      "model_name",
      "save_dir"
    ]
  },
  "_ModelScopeModelHoster": {
    "model_list": [],
    "alias": [],
    "healthcheck_url": [],
    "_download": [
      "self",
      "model_name",
      "save_dir"
    ]
  },
  "_AIStudioModelHoster": {
    "model_list": [],
    "alias": [],
    "healthcheck_url": [],
    "_download": [
      "self",
      "model_name",
      "save_dir"
    ]
  },
  "_ModelManager": {
    "model_list": [],
    "_save_dir": [],
    "hoster_candidates": [],
    "__init__": [
      "self"
    ],
    "_build_hosters": [
      "self"
    ],
    "_get_model_local_path": [
      "self",
      "model_name"
    ],
    "_download_from_hoster": [
      "self",
      "hosters",
      "model_name"
    ],
    "__contains__": [
      "self",
      "model_name"
    ],
    "__getitem__": [
      "self",
      "model_name"
    ]
  },
  "official_models": [],
  "is_mkldnn_available": [],
  "is_bfloat16_available": [
    "device"
  ],
  "is_float16_available": [
    "device"
  ],
  "ModelPaths": {},
  "get_model_paths": [
    "model_dir",
    "model_file_prefix"
  ],
  "ENTRY_POINT_NAME": [],
  "_inference_operations": [],
  "_is_measuring_time": [],
  "PIPELINE_FUNC_BLACK_LIST": [],
  "_step": [],
  "_level": [],
  "_top_func": [],
  "Benchmark": {
    "__init__": [
      "self",
      "enabled"
    ],
    "timeit_with_options": [
      "self",
      "name",
      "is_read_operation"
    ],
    "timeit": [
      "self",
      "func_or_cls"
    ],
    "_is_public_method": [
      "self",
      "name"
    ],
    "time_methods": [
      "self",
      "cls"
    ],
    "watch_generator": [
      "self",
      "generator",
      "name"
    ],
    "watch_generator_simple": [
      "self",
      "generator",
      "name"
    ],
    "reset": [
      "self"
    ],
    "_update": [
      "self",
      "elapse",
      "name"
    ],
    "logs": [
      "self"
    ],
    "start_timing": [
      "self"
    ],
    "stop_timing": [
      "self"
    ],
    "start_warmup": [
      "self"
    ],
    "stop_warmup": [
      "self"
    ],
    "gather": [
      "self",
      "batch_size"
    ],
    "collect": [
      "self",
      "batch_size"
    ],
    "gather_pipeline": [
      "self"
    ],
    "_initialize_pipeline_data": [
      "self"
    ],
    "print_pipeline_data": [
      "self"
    ],
    "print_operation_info": [
      "self"
    ],
    "print_detail_data": [
      "self"
    ],
    "print_summary_data": [
      "self"
    ],
    "save_pipeline_data": [
      "self",
      "save_path"
    ]
  },
  "get_inference_operations": [],
  "set_inference_operations": [
    "val"
  ],
  "add_inference_operations": [],
  "get_pipeline_path": [
    "pipeline_name"
  ],
  "string_to_int": [
    "s"
  ],
  "get_Tables": [
    "doc"
  ],
  "write_rows": [
    "worksheet",
    "elem",
    "row",
    "column"
  ],
  "table_to_sheet": [
    "table",
    "wb"
  ],
  "document_to_workbook": [
    "doc",
    "wb",
    "base_url"
  ],
  "document_to_xl": [
    "doc",
    "filename",
    "base_url"
  ],
  "insert_table": [
    "table",
    "worksheet",
    "column",
    "row"
  ],
  "insert_table_at_cell": [
    "table",
    "cell"
  ],
  "FORMAT_DATE_MMDDYYYY": [],
  "colormap": [
    "color"
  ],
  "style_string_to_dict": [
    "style"
  ],
  "get_side": [
    "style",
    "name"
  ],
  "known_styles": [],
  "style_dict_to_named_style": [
    "style_dict",
    "number_format"
  ],
  "StyleDict": {
    "__init__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "__hash__": [
      "self"
    ],
    "_keys": [
      "self"
    ],
    "get": [
      "self",
      "k",
      "d"
    ],
    "get_color": [
      "self",
      "k",
      "d"
    ]
  },
  "Element": {
    "__init__": [
      "self",
      "element",
      "parent"
    ],
    "style": [
      "self"
    ],
    "get_dimension": [
      "self",
      "dimension_key"
    ]
  },
  "Table": {
    "__init__": [
      "self",
      "table"
    ]
  },
  "TableHead": {
    "__init__": [
      "self",
      "head",
      "parent"
    ]
  },
  "TableBody": {
    "__init__": [
      "self",
      "body",
      "parent"
    ]
  },
  "TableRow": {
    "__init__": [
      "self",
      "tr",
      "parent"
    ]
  },
  "element_to_string": [
    "el"
  ],
  "_element_to_string": [
    "el"
  ],
  "TableCell": {
    "CELL_TYPES": [],
    "__init__": [
      "self",
      "cell",
      "parent"
    ],
    "data_type": [
      "self"
    ],
    "get_number_format": [
      "self"
    ],
    "format": [
      "self",
      "cell"
    ]
  },
  "WriterType": {
    "IMAGE": [],
    "VIDEO": [],
    "TEXT": [],
    "JSON": [],
    "HTML": [],
    "XLSX": [],
    "CSV": [],
    "YAML": [],
    "MARKDOWN": [],
    "TXT": [],
    "AUDIO": []
  },
  "_BaseWriter": {
    "__init__": [
      "self",
      "backend"
    ],
    "write": [
      "self",
      "out_path",
      "obj"
    ],
    "get_backend": [
      "self",
      "bk_args"
    ],
    "set_backend": [
      "self",
      "backend"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ],
    "get_default_backend_args": [
      "self"
    ]
  },
  "ImageWriter": {
    "__init__": [
      "self",
      "backend"
    ],
    "write": [
      "self",
      "out_path",
      "obj"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "VideoWriter": {
    "__init__": [
      "self",
      "backend"
    ],
    "write": [
      "self",
      "out_path",
      "obj"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "TextWriter": {
    "__init__": [
      "self",
      "backend"
    ],
    "write": [
      "self",
      "out_path",
      "obj"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "JsonWriter": {
    "__init__": [
      "self",
      "backend"
    ],
    "write": [
      "self",
      "out_path",
      "obj"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "HtmlWriter": {
    "__init__": [
      "self",
      "backend"
    ],
    "write": [
      "self",
      "out_path",
      "obj"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "XlsxWriter": {
    "__init__": [
      "self",
      "backend"
    ],
    "write": [
      "self",
      "out_path",
      "obj"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "YAMLWriter": {
    "__init__": [
      "self",
      "backend"
    ],
    "write": [
      "self",
      "out_path",
      "obj"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "MarkdownWriter": {
    "__init__": [
      "self",
      "backend"
    ],
    "write": [
      "self",
      "out_path",
      "obj"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "AudioWriter": {
    "__init__": [
      "self",
      "sample_rate",
      "backend"
    ],
    "write": [
      "self",
      "out_path",
      "obj"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "_BaseWriterBackend": {
    "write_obj": [
      "self",
      "out_path",
      "obj"
    ],
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "TextWriterBackend": {
    "__init__": [
      "self",
      "mode",
      "encoding"
    ],
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "HtmlWriterBackend": {
    "__init__": [
      "self",
      "mode",
      "encoding"
    ],
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "XlsxWriterBackend": {
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "_ImageWriterBackend": {},
  "OpenCVImageWriterBackend": {
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "PILImageWriterBackend": {
    "__init__": [
      "self",
      "format_"
    ],
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "_VideoWriterBackend": {},
  "OpenCVVideoWriterBackend": {
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "_BaseJsonWriterBackend": {
    "__init__": [
      "self",
      "indent",
      "ensure_ascii"
    ],
    "write_obj": [
      "self",
      "out_path",
      "obj"
    ],
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "JsonWriterBackend": {
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "UJsonWriterBackend": {
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "YAMLWriterBackend": {
    "__init__": [
      "self",
      "mode",
      "encoding"
    ],
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "CSVWriter": {
    "__init__": [
      "self",
      "backend"
    ],
    "write": [
      "self",
      "out_path",
      "obj"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "_CSVWriterBackend": {},
  "PandasCSVWriterBackend": {
    "__init__": [
      "self"
    ],
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "MarkdownWriterBackend": {
    "__init__": [
      "self"
    ],
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "AudioWriterBackend": {
    "__init__": [
      "self",
      "sample_rate"
    ],
    "_write_obj": [
      "self",
      "out_path",
      "obj"
    ]
  },
  "ReaderType": {
    "IMAGE": [],
    "GENERATIVE": [],
    "POINT_CLOUD": [],
    "JSON": [],
    "TS": [],
    "PDF": [],
    "YAML": [],
    "MARKDOWN": [],
    "TXT": []
  },
  "_BaseReader": {
    "__init__": [
      "self",
      "backend"
    ],
    "read": [
      "self",
      "in_path"
    ],
    "get_backend": [
      "self",
      "bk_args"
    ],
    "set_backend": [
      "self",
      "backend"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ],
    "get_default_backend_args": [
      "self"
    ]
  },
  "PDFReader": {
    "__init__": [
      "self",
      "backend"
    ],
    "read": [
      "self",
      "in_path"
    ],
    "load": [
      "self",
      "in_path"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "ImageReader": {
    "__init__": [
      "self",
      "backend"
    ],
    "read": [
      "self",
      "in_path"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "_GenerativeReader": {
    "get_type": [
      "self"
    ]
  },
  "is_generative_reader": [
    "reader"
  ],
  "VideoReader": {
    "__init__": [
      "self",
      "backend",
      "st_frame_id",
      "max_num_frames",
      "auto_close"
    ],
    "read": [
      "self",
      "in_path"
    ],
    "get_fps": [
      "self"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ]
  },
  "YAMLReader": {
    "__init__": [
      "self",
      "backend"
    ],
    "read": [
      "self",
      "in_path"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "MarkDownReader": {
    "__init__": [
      "self",
      "backend"
    ],
    "read": [
      "self",
      "in_path"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "TXTReader": {
    "__init__": [
      "self",
      "backend"
    ],
    "read": [
      "self",
      "in_path"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "_BaseReaderBackend": {
    "read_file": [
      "self",
      "in_path"
    ]
  },
  "_ImageReaderBackend": {},
  "OpenCVImageReaderBackend": {
    "__init__": [
      "self",
      "flags"
    ],
    "read_file": [
      "self",
      "in_path"
    ]
  },
  "PILImageReaderBackend": {
    "__init__": [
      "self"
    ],
    "read_file": [
      "self",
      "in_path"
    ]
  },
  "PDFReaderBackend": {
    "__init__": [
      "self",
      "rotate",
      "zoom"
    ],
    "load_file": [
      "self",
      "in_path"
    ],
    "read_file": [
      "self",
      "in_path"
    ]
  },
  "TXTReaderBackend": {
    "read_file": [
      "self",
      "in_path"
    ]
  },
  "_VideoReaderBackend": {
    "set_pos": [
      "self",
      "pos"
    ],
    "close": [
      "self"
    ]
  },
  "OpenCVVideoReaderBackend": {
    "__init__": [
      "self"
    ],
    "get_fps": [
      "self"
    ],
    "read_file": [
      "self",
      "in_path"
    ],
    "_read_frames": [
      "self",
      "cap"
    ],
    "_cap_open": [
      "self",
      "video_path"
    ],
    "_cap_release": [
      "self"
    ],
    "_cap_set_pos": [
      "self"
    ],
    "set_pos": [
      "self",
      "pos"
    ],
    "close": [
      "self"
    ]
  },
  "DecordVideoReaderBackend": {
    "__init__": [
      "self"
    ],
    "set_pos": [
      "self",
      "pos"
    ],
    "sample": [
      "self",
      "frames_len",
      "video_object"
    ],
    "get_fps": [
      "self"
    ],
    "read_file": [
      "self",
      "in_path"
    ],
    "close": [
      "self"
    ]
  },
  "CSVReader": {
    "__init__": [
      "self",
      "backend"
    ],
    "read": [
      "self",
      "in_path"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "get_type": [
      "self"
    ]
  },
  "_CSVReaderBackend": {},
  "PandasCSVReaderBackend": {
    "__init__": [
      "self"
    ],
    "read_file": [
      "self",
      "in_path"
    ]
  },
  "YAMLReaderBackend": {
    "read_file": [
      "self",
      "in_path"
    ]
  },
  "AudioReader": {
    "__init__": [
      "self",
      "backend"
    ],
    "_init_backend": [
      "self",
      "bk_type",
      "bk_args"
    ],
    "read": [
      "self",
      "in_path"
    ]
  },
  "_AudioReaderBackend": {},
  "WAVReaderBackend": {
    "__init__": [
      "self"
    ],
    "read_file": [
      "self",
      "in_path"
    ]
  },
  "InferRequest": {},
  "Segment": {},
  "InferResult": {},
  "LayoutParsingResult": {},
  "Person": {},
  "AnalyzeImagesRequest": {},
  "AnalyzeImagesResult": {},
  "BuildVectorStoreRequest": {},
  "BuildVectorStoreResult": {},
  "InvokeMLLMRequest": {},
  "InvokeMLLMResult": {},
  "ChatRequest": {},
  "ChatResult": {},
  "Attribute": {},
  "Vehicle": {},
  "Pedestrian": {},
  "DetectedObject": {},
  "Instance": {},
  "MarkdownData": {},
  "Page": {},
  "RestructurePagesRequest": {},
  "RestructurePagesResult": {},
  "TranslateRequest": {},
  "TranslationResult": {},
  "TranslateResult": {},
  "MaskInfo": {},
  "get_pipeline_schema_mod": [
    "pipeline_name"
  ],
  "FormulaRecResult": {},
  "TableRecResult": {},
  "DocPreprocessingResult": {},
  "OCRResult": {},
  "Frame": {},
  "ImageLabelPair": {},
  "BuildIndexRequest": {},
  "BuildIndexResult": {},
  "AddImagesToIndexRequest": {},
  "AddImagesToIndexResult": {},
  "RemoveImagesFromIndexRequest": {},
  "RemoveImagesFromIndexResult": {},
  "RecResult": {},
  "Face": {},
  "ContentType": {
    "TEXT": [],
    "IMAGE_URL": []
  },
  "RoleType": {
    "USER": [],
    "ASSISTANT": [],
    "SYSTEM": []
  },
  "ImageUrl": {},
  "TextContent": {},
  "ImageContent": {},
  "Message": {},
  "SealRecResult": {},
  "Mask": {},
  "Category": {},
  "BaseInferRequest": {},
  "run_server": [
    "app"
  ],
  "PipelineT": [],
  "P": [],
  "R": [],
  "_Error": {},
  "_is_error": [
    "obj"
  ],
  "PipelineWrapper": {
    "__init__": [
      "self",
      "pipeline"
    ],
    "pipeline": [
      "self"
    ],
    "infer": [
      "self"
    ],
    "call": [
      "self",
      "func"
    ],
    "close": [
      "self"
    ],
    "_worker": [
      "self"
    ]
  },
  "AppContext": {
    "__init__": [
      "self"
    ],
    "config": [
      "self"
    ],
    "pipeline": [
      "self",
      "val"
    ],
    "aiohttp_session": [
      "self",
      "val"
    ]
  },
  "create_app": [],
  "primary_operation": [
    "app",
    "path",
    "operation_id"
  ],
  "create_pipeline_app": [
    "pipeline",
    "app_config"
  ],
  "_rle": [
    "mask"
  ],
  "prune_result": [
    "result"
  ],
  "postprocess_image": [
    "image",
    "log_id",
    "filename"
  ],
  "postprocess_images": [
    "images",
    "log_id",
    "filename_template",
    "file_storage",
    "return_urls",
    "url_expires_in",
    "max_img_size"
  ],
  "update_app_context": [
    "app_context"
  ],
  "generate_index_key": [],
  "get_file_type": [
    "request"
  ],
  "get_images": [
    "request",
    "app_context"
  ],
  "AIStudioNoResultResponse": {},
  "ResultT": [],
  "AIStudioResultResponse": {},
  "ImageInfo": {},
  "PDFPageInfo": {},
  "PDFInfo": {},
  "generate_log_id": [],
  "is_url": [
    "s"
  ],
  "infer_file_type": [
    "url"
  ],
  "infer_file_ext": [
    "file"
  ],
  "image_bytes_to_array": [
    "data"
  ],
  "image_bytes_to_image": [
    "data"
  ],
  "image_to_bytes": [
    "image",
    "format"
  ],
  "image_array_to_bytes": [
    "image",
    "ext"
  ],
  "csv_bytes_to_data_frame": [
    "data"
  ],
  "data_frame_to_bytes": [
    "df"
  ],
  "base64_encode": [
    "data"
  ],
  "read_pdf": [
    "bytes_",
    "max_num_imgs"
  ],
  "file_to_images": [
    "file_bytes",
    "file_type"
  ],
  "get_image_info": [
    "image"
  ],
  "write_to_temp_file": [
    "file_bytes",
    "suffix"
  ],
  "get_raw_bytes": [
    "file"
  ],
  "get_raw_bytes_async": [
    "file",
    "session"
  ],
  "call_async": [],
  "InMemoryStorageConfig": {},
  "FileSystemStorageConfig": {},
  "BOSConfig": {},
  "FileStorageConfig": [],
  "SupportsGetURL": {
    "get_url": [
      "self",
      "key",
      "expires_in"
    ]
  },
  "Storage": {
    "get": [
      "self",
      "key"
    ],
    "set": [
      "self",
      "key",
      "value"
    ],
    "delete": [
      "self",
      "key"
    ]
  },
  "InMemoryStorage": {
    "__init__": [
      "self",
      "config"
    ],
    "get": [
      "self",
      "key"
    ],
    "set": [
      "self",
      "key",
      "value"
    ],
    "delete": [
      "self",
      "key"
    ]
  },
  "FileSystemStorage": {
    "__init__": [
      "self",
      "config"
    ],
    "get": [
      "self",
      "key"
    ],
    "set": [
      "self",
      "key",
      "value"
    ],
    "delete": [
      "self",
      "key"
    ],
    "_get_file_path": [
      "self",
      "key"
    ]
  },
  "BOS": {
    "__init__": [
      "self",
      "config"
    ],
    "get": [
      "self",
      "key"
    ],
    "set": [
      "self",
      "key",
      "value"
    ],
    "delete": [
      "self",
      "key"
    ],
    "get_url": [
      "self",
      "key",
      "expires_in"
    ],
    "_get_full_key": [
      "self",
      "key"
    ]
  },
  "create_storage": [],
  "AppConfig": {},
  "create_app_config": [
    "pipeline_config"
  ],
  "PIPELINE_APP_ROUTER": [],
  "pipeline_name_to_mod_name": [
    "pipeline_name"
  ],
  "BasePipeline": {
    "__is_base": [],
    "__init__": [
      "self",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input"
    ],
    "create_model": [
      "self",
      "config"
    ],
    "create_pipeline": [
      "self",
      "config"
    ],
    "close": [
      "self"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "load_pipeline_config": [
    "pipeline"
  ],
  "create_pipeline": [
    "pipeline",
    "config",
    "device",
    "pp_option",
    "use_hpip",
    "hpi_config"
  ],
  "create_chat_bot": [
    "config"
  ],
  "create_retriever": [
    "config"
  ],
  "create_prompt_engineering": [
    "config"
  ],
  "MultiDeviceSimpleInferenceExecutor": {
    "__init__": [
      "self",
      "pipelines",
      "batch_sampler"
    ],
    "pipelines": [
      "self"
    ],
    "execute": [
      "self",
      "input"
    ]
  },
  "AutoParallelSimpleInferencePipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "multi_device_inference": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "predict": [
      "self",
      "input"
    ],
    "_create_internal_pipeline": [
      "self",
      "config",
      "device"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ],
    "_create_batch_sampler": [
      "self",
      "batch_size"
    ],
    "_postprocess_result": [
      "self",
      "result",
      "input_batch"
    ]
  },
  "AutoParallelImageSimpleInferencePipeline": {
    "_pipeline_cls": [
      "self"
    ],
    "_create_internal_pipeline": [
      "self",
      "config",
      "device"
    ],
    "_create_batch_sampler": [
      "self",
      "batch_size"
    ],
    "_postprocess_result": [
      "self",
      "result",
      "input_batch"
    ]
  },
  "PP_ChatOCRv3_Pipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config",
      "initial_predictor"
    ],
    "inintial_visual_predictor": [
      "self",
      "config"
    ],
    "inintial_retriever_predictor": [
      "self",
      "config"
    ],
    "inintial_chat_predictor": [
      "self",
      "config"
    ],
    "decode_visual_result": [
      "self",
      "layout_parsing_result"
    ],
    "visual_predict": [
      "self",
      "input",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_seal_recognition",
      "use_table_recognition",
      "layout_threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode",
      "text_det_limit_side_len",
      "text_det_limit_type",
      "text_det_thresh",
      "text_det_box_thresh",
      "text_det_unclip_ratio",
      "text_rec_score_thresh",
      "seal_det_limit_side_len",
      "seal_det_limit_type",
      "seal_det_thresh",
      "seal_det_box_thresh",
      "seal_det_unclip_ratio",
      "seal_rec_score_thresh"
    ],
    "save_visual_info_list": [
      "self",
      "visual_info",
      "save_path"
    ],
    "load_visual_info_list": [
      "self",
      "data_path"
    ],
    "merge_visual_info_list": [
      "self",
      "visual_info_list"
    ],
    "build_vector": [
      "self",
      "visual_info",
      "min_characters",
      "block_size",
      "flag_save_bytes_vector",
      "retriever_config"
    ],
    "save_vector": [
      "self",
      "vector_info",
      "save_path",
      "retriever_config"
    ],
    "load_vector": [
      "self",
      "data_path",
      "retriever_config"
    ],
    "format_key": [
      "self",
      "key_list"
    ],
    "generate_and_merge_chat_results": [
      "self",
      "chat_bot",
      "prompt",
      "key_list",
      "final_results",
      "failed_results"
    ],
    "get_related_normal_text": [
      "self",
      "retriever_config",
      "use_vector_retrieval",
      "vector_info",
      "key_list",
      "all_normal_text_list",
      "min_characters"
    ],
    "chat": [
      "self",
      "key_list",
      "visual_info",
      "use_vector_retrieval",
      "vector_info",
      "min_characters",
      "text_task_description",
      "text_output_format",
      "text_rules_str",
      "text_few_shot_demo_text_content",
      "text_few_shot_demo_key_value_list",
      "table_task_description",
      "table_output_format",
      "table_rules_str",
      "table_few_shot_demo_text_content",
      "table_few_shot_demo_key_value_list",
      "chat_bot_config",
      "retriever_config"
    ],
    "predict": [
      "self"
    ]
  },
  "PP_ChatOCR_Pipeline": {
    "__init__": [
      "self",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "visual_predict": [
      "self"
    ],
    "save_visual_info_list": [
      "self"
    ],
    "load_visual_info_list": [
      "self"
    ],
    "build_vector": [
      "self"
    ],
    "save_vector": [
      "self"
    ],
    "load_vector": [
      "self"
    ],
    "chat": [
      "self"
    ],
    "predict": [
      "self"
    ]
  },
  "PP_ChatOCRv4_Pipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config",
      "initial_predictor"
    ],
    "close": [
      "self"
    ],
    "inintial_visual_predictor": [
      "self",
      "config"
    ],
    "inintial_retriever_predictor": [
      "self",
      "config"
    ],
    "inintial_chat_predictor": [
      "self",
      "config"
    ],
    "inintial_mllm_predictor": [
      "self",
      "config"
    ],
    "decode_visual_result": [
      "self",
      "layout_parsing_result"
    ],
    "visual_predict": [
      "self",
      "input",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_textline_orientation",
      "use_seal_recognition",
      "use_table_recognition",
      "layout_threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode",
      "text_det_limit_side_len",
      "text_det_limit_type",
      "text_det_thresh",
      "text_det_box_thresh",
      "text_det_unclip_ratio",
      "text_rec_score_thresh",
      "seal_det_limit_side_len",
      "seal_det_limit_type",
      "seal_det_thresh",
      "seal_det_box_thresh",
      "seal_det_unclip_ratio",
      "seal_rec_score_thresh"
    ],
    "save_visual_info_list": [
      "self",
      "visual_info",
      "save_path"
    ],
    "load_visual_info_list": [
      "self",
      "data_path"
    ],
    "merge_visual_info_list": [
      "self",
      "visual_info_list"
    ],
    "build_vector": [
      "self",
      "visual_info",
      "min_characters",
      "block_size",
      "flag_save_bytes_vector",
      "retriever_config"
    ],
    "save_vector": [
      "self",
      "vector_info",
      "save_path",
      "retriever_config"
    ],
    "load_vector": [
      "self",
      "data_path",
      "retriever_config"
    ],
    "format_key": [
      "self",
      "key_list"
    ],
    "mllm_pred": [
      "self",
      "input",
      "key_list",
      "mllm_chat_bot_config"
    ],
    "generate_and_merge_chat_results": [
      "self",
      "chat_bot",
      "prompt",
      "key_list",
      "final_results",
      "failed_results"
    ],
    "get_related_normal_text": [
      "self",
      "retriever_config",
      "use_vector_retrieval",
      "vector_info",
      "key_list",
      "all_normal_text_list",
      "min_characters"
    ],
    "ensemble_ocr_llm_mllm": [
      "self",
      "chat_bot",
      "key_list",
      "ocr_llm_predict_dict",
      "mllm_predict_dict"
    ],
    "chat": [
      "self",
      "key_list",
      "visual_info",
      "use_vector_retrieval",
      "vector_info",
      "min_characters",
      "text_task_description",
      "text_output_format",
      "text_rules_str",
      "text_few_shot_demo_text_content",
      "text_few_shot_demo_key_value_list",
      "table_task_description",
      "table_output_format",
      "table_rules_str",
      "table_few_shot_demo_text_content",
      "table_few_shot_demo_key_value_list",
      "mllm_predict_info",
      "mllm_integration_strategy",
      "chat_bot_config",
      "retriever_config"
    ],
    "predict": [
      "self"
    ]
  },
  "_TableRecognitionPipelineV2": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "get_model_settings": [
      "self",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_layout_detection",
      "use_ocr_model"
    ],
    "check_model_settings_valid": [
      "self",
      "model_settings",
      "overall_ocr_res",
      "layout_det_res"
    ],
    "predict_doc_preprocessor_res": [
      "self",
      "image_array",
      "input_params"
    ],
    "extract_results": [
      "self",
      "pred",
      "task"
    ],
    "cells_det_results_nms": [
      "self",
      "cells_det_results",
      "cells_det_scores",
      "cells_det_threshold"
    ],
    "get_region_ocr_det_boxes": [
      "self",
      "ocr_det_boxes",
      "table_box"
    ],
    "cells_det_results_reprocessing": [
      "self",
      "cells_det_results",
      "cells_det_scores",
      "ocr_det_results",
      "html_pred_boxes_nums"
    ],
    "split_ocr_bboxes_by_table_cells": [
      "self",
      "cells_det_results",
      "overall_ocr_res",
      "ori_img",
      "k"
    ],
    "gen_ocr_with_table_cells": [
      "self",
      "ori_img",
      "cells_bboxes"
    ],
    "map_cells_to_original_image": [
      "self",
      "detections",
      "table_angle",
      "img_width",
      "img_height"
    ],
    "split_string_by_keywords": [
      "self",
      "html_string"
    ],
    "cluster_positions": [
      "self",
      "positions",
      "tolerance"
    ],
    "trans_cells_det_results_to_html": [
      "self",
      "cells_det_results"
    ],
    "predict_single_table_recognition_res": [
      "self",
      "image_array",
      "overall_ocr_res",
      "table_box",
      "use_e2e_wired_table_rec_model",
      "use_e2e_wireless_table_rec_model",
      "use_wired_table_cells_trans_to_html",
      "use_wireless_table_cells_trans_to_html",
      "use_ocr_results_with_table_cells",
      "flag_find_nei_text"
    ],
    "predict": [
      "self",
      "input",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_layout_detection",
      "use_ocr_model",
      "overall_ocr_res",
      "layout_det_res",
      "text_det_limit_side_len",
      "text_det_limit_type",
      "text_det_thresh",
      "text_det_box_thresh",
      "text_det_unclip_ratio",
      "text_rec_score_thresh",
      "use_e2e_wired_table_rec_model",
      "use_e2e_wireless_table_rec_model",
      "use_wired_table_cells_trans_to_html",
      "use_wireless_table_cells_trans_to_html",
      "use_table_orientation_classify",
      "use_ocr_results_with_table_cells"
    ]
  },
  "TableRecognitionPipelineV2": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "get_neighbor_boxes_idx": [
    "src_boxes",
    "ref_box"
  ],
  "_TableRecognitionPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "get_model_settings": [
      "self",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_layout_detection",
      "use_ocr_model"
    ],
    "check_model_settings_valid": [
      "self",
      "model_settings",
      "overall_ocr_res",
      "layout_det_res"
    ],
    "predict_doc_preprocessor_res": [
      "self",
      "image_array",
      "input_params"
    ],
    "split_ocr_bboxes_by_table_cells": [
      "self",
      "ori_img",
      "cells_bboxes"
    ],
    "predict_single_table_recognition_res": [
      "self",
      "image_array",
      "overall_ocr_res",
      "table_box",
      "use_ocr_results_with_table_cells",
      "flag_find_nei_text",
      "cell_sort_by_y_projection"
    ],
    "predict": [
      "self",
      "input",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_layout_detection",
      "use_ocr_model",
      "overall_ocr_res",
      "layout_det_res",
      "text_det_limit_side_len",
      "text_det_limit_type",
      "text_det_thresh",
      "text_det_box_thresh",
      "text_det_unclip_ratio",
      "text_rec_score_thresh",
      "use_ocr_results_with_table_cells",
      "cell_sort_by_y_projection"
    ]
  },
  "TableRecognitionPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "SingleTableRecognitionResult": {
    "__init__": [
      "self",
      "data"
    ],
    "_get_input_fn": [
      "self"
    ],
    "_to_html": [
      "self"
    ],
    "_to_xlsx": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "TableRecognitionResult": {
    "__init__": [
      "self",
      "data"
    ],
    "_get_input_fn": [
      "self"
    ],
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ],
    "_to_html": [
      "self"
    ],
    "_to_xlsx": [
      "self"
    ]
  },
  "get_ori_image_coordinate": [
    "x",
    "y",
    "box_list"
  ],
  "convert_table_structure_pred_bbox": [
    "table_structure_pred",
    "crop_start_point",
    "img_shape"
  ],
  "distance": [
    "box_1",
    "box_2"
  ],
  "compute_iou": [
    "rec1",
    "rec2"
  ],
  "_whether_y_overlap_exceeds_threshold": [
    "bbox1",
    "bbox2",
    "overlap_ratio_threshold"
  ],
  "_sort_box_by_y_projection": [
    "boxes",
    "line_height_iou_threshold"
  ],
  "match_table_and_ocr": [
    "cell_box_list",
    "ocr_dt_boxes",
    "cell_sort_by_y_projection"
  ],
  "get_html_result": [
    "matched_index",
    "ocr_contents",
    "pred_structures"
  ],
  "get_table_recognition_res": [
    "table_box",
    "table_structure_pred",
    "overall_ocr_res",
    "cells_texts_list",
    "use_table_cells_ocr_results",
    "cell_sort_by_y_projection"
  ],
  "compute_inter": [
    "rec1",
    "rec2"
  ],
  "sort_table_cells_boxes": [
    "boxes"
  ],
  "convert_to_four_point_coordinates": [
    "boxes"
  ],
  "find_row_start_index": [
    "html_list"
  ],
  "map_and_get_max": [
    "table_cells_flag",
    "row_start_index"
  ],
  "IndexData": {
    "VECTOR_FN": [],
    "VECTOR_SUFFIX": [],
    "IDMAP_FN": [],
    "IDMAP_SUFFIX": [],
    "__init__": [
      "self",
      "index",
      "index_info"
    ],
    "index": [
      "self"
    ],
    "index_bytes": [
      "self"
    ],
    "id_map": [
      "self"
    ],
    "metric_type": [
      "self"
    ],
    "index_type": [
      "self"
    ],
    "index_info": [
      "self"
    ],
    "from_bytes": [
      "cls",
      "bytes"
    ],
    "to_bytes": [
      "self"
    ],
    "_convert_int": [
      "self",
      "id_map"
    ],
    "_convert_int64": [
      "id_map"
    ],
    "save": [
      "self",
      "save_dir"
    ],
    "load": [
      "cls",
      "index"
    ]
  },
  "FaissIndexer": {
    "__init__": [
      "self",
      "index"
    ],
    "__call__": [
      "self",
      "feature",
      "score_thres",
      "hamming_radius",
      "topk"
    ]
  },
  "FaissBuilder": {
    "SUPPORT_METRIC_TYPE": [],
    "SUPPORT_INDEX_TYPE": [],
    "BINARY_METRIC_TYPE": [],
    "BINARY_SUPPORT_INDEX_TYPE": [],
    "_get_index_type": [
      "cls",
      "metric_type",
      "index_type",
      "num"
    ],
    "_get_metric_type": [
      "cls",
      "metric_type"
    ],
    "build": [
      "cls",
      "gallery_imgs",
      "gallery_label",
      "predict_func",
      "metric_type",
      "index_type"
    ],
    "remove": [
      "cls",
      "remove_ids",
      "index"
    ],
    "append": [
      "cls",
      "gallery_imgs",
      "gallery_label",
      "predict_func",
      "index"
    ],
    "_add_gallery": [
      "cls",
      "metric_type",
      "index",
      "ids",
      "gallery_features",
      "gallery_docs",
      "mode"
    ],
    "load_gallery": [
      "cls",
      "gallery_label_path",
      "gallery_imgs_root",
      "delimiter"
    ]
  },
  "CropByBoxes": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "img",
      "boxes",
      "layout_shape_mode"
    ]
  },
  "CropByPolys": {
    "entities": [],
    "__init__": [
      "self",
      "det_box_type"
    ],
    "__call__": [
      "self",
      "img",
      "dt_polys"
    ],
    "get_minarea_rect_crop": [
      "self",
      "img",
      "points"
    ],
    "get_rotate_crop_image": [
      "self",
      "img",
      "points"
    ],
    "reorder_poly_edge": [
      "self",
      "points"
    ],
    "vector_slope": [
      "self",
      "vec"
    ],
    "find_head_tail": [
      "self",
      "points",
      "orientation_thr"
    ],
    "vector_angle": [
      "self",
      "vec1",
      "vec2"
    ],
    "get_minarea_rect": [
      "self",
      "img",
      "points"
    ],
    "sample_points_on_bbox_bp": [
      "self",
      "line",
      "n"
    ],
    "sample_points_on_bbox": [
      "self",
      "line",
      "n"
    ],
    "get_poly_rect_crop": [
      "self",
      "img",
      "points"
    ]
  },
  "convert_points_to_boxes": [
    "dt_polys"
  ],
  "is_vertical_text": [
    "box"
  ],
  "cal_ocr_word_box": [
    "rec_str",
    "box",
    "rec_word_info"
  ],
  "sort_boxes": [
    "boxes",
    "y_thresh"
  ],
  "SortQuadBoxes": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "dt_polys"
    ]
  },
  "SortPolyBoxes": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "dt_polys"
    ]
  },
  "BaseOperator": {
    "__is_base": [],
    "__init__": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "CVResult": {
    "__init__": [
      "self",
      "data"
    ]
  },
  "Homography": [
    "image",
    "img_points",
    "world_width",
    "world_height",
    "interpolation",
    "ratio_width",
    "ratio_height"
  ],
  "PlanB": {
    "__call__": [
      "self",
      "image",
      "points",
      "curveTextRectifier",
      "interpolation",
      "ratio_width",
      "ratio_height",
      "loss_thresh",
      "square"
    ]
  },
  "CurveTextRectifier": {
    "__init__": [
      "self"
    ],
    "get_virtual_camera_parameter": [
      "self"
    ],
    "vertical_text_process": [
      "self",
      "points",
      "org_size"
    ],
    "horizontal_text_process": [
      "self",
      "points"
    ],
    "horizontal_text_estimate": [
      "self",
      "points"
    ],
    "virtual_camera_to_world": [
      "self",
      "size"
    ],
    "world_to_image": [
      "self",
      "image_size",
      "world",
      "intrinsic",
      "distCoeffs",
      "rotation",
      "tvec"
    ],
    "spatial_transform": [
      "self",
      "image_data",
      "new_image_size",
      "mtx",
      "dist",
      "rvecs",
      "tvecs",
      "interpolation"
    ],
    "calibrate": [
      "self",
      "org_size",
      "image_coord",
      "world_coord"
    ],
    "dc_homo": [
      "self",
      "img",
      "img_points",
      "obj_points",
      "is_horizontal_text",
      "interpolation",
      "ratio_width",
      "ratio_height"
    ],
    "Homography": [
      "self",
      "image",
      "img_points",
      "world_width",
      "world_height",
      "interpolation",
      "ratio_width",
      "ratio_height"
    ],
    "__call__": [
      "self",
      "image_data",
      "points",
      "interpolation",
      "ratio_width",
      "ratio_height",
      "mode"
    ]
  },
  "AutoRectifier": {
    "__init__": [
      "self"
    ],
    "get_rotate_crop_image": [
      "img",
      "points",
      "interpolation",
      "ratio_width",
      "ratio_height"
    ],
    "visualize": [
      "self",
      "image_data",
      "points_list"
    ],
    "__call__": [
      "self",
      "image_data",
      "points",
      "interpolation",
      "ratio_width",
      "ratio_height",
      "loss_thresh",
      "mode"
    ],
    "run": [
      "self",
      "image_data",
      "points_list",
      "interpolation",
      "ratio_width",
      "ratio_height",
      "loss_thresh",
      "mode"
    ]
  },
  "rotate_image": [
    "image",
    "angle"
  ],
  "BaseChat": {
    "__is_base": [],
    "__init__": [
      "self"
    ],
    "generate_chat_results": [
      "self"
    ]
  },
  "OpenAIBotChat": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ],
    "generate_chat_results": [
      "self",
      "prompt",
      "image",
      "temperature",
      "max_retries"
    ],
    "fix_llm_result_format": [
      "self",
      "llm_result"
    ]
  },
  "BaseGeneratePrompt": {
    "__is_base": [],
    "__init__": [
      "self"
    ],
    "generate_prompt": [
      "self"
    ]
  },
  "GenerateTranslatePrompt": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ],
    "generate_prompt": [
      "self",
      "original_text",
      "language",
      "task_description",
      "output_format",
      "rules_str",
      "few_shot_demo_text_content",
      "few_shot_demo_key_value_list"
    ]
  },
  "GenerateKIEPrompt": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ],
    "generate_prompt": [
      "self",
      "text_content",
      "key_list",
      "task_description",
      "output_format",
      "rules_str",
      "few_shot_demo_text_content",
      "few_shot_demo_key_value_list"
    ]
  },
  "GenerateEnsemblePrompt": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ],
    "generate_prompt": [
      "self",
      "key",
      "result_methodA",
      "result_methodB",
      "task_description",
      "output_format",
      "rules_str",
      "few_shot_demo_text_content",
      "few_shot_demo_key_value_list"
    ]
  },
  "_save_list_data": [
    "save_func",
    "save_path",
    "data"
  ],
  "OpenAIBotRetriever": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "BaseRetriever": {
    "__is_base": [],
    "VECTOR_STORE_PREFIX": [],
    "__init__": [
      "self"
    ],
    "generate_vector_database": [
      "self",
      "text_list",
      "block_size",
      "separators"
    ],
    "similarity_retrieval": [
      "self",
      "query_text_list",
      "vectorstore",
      "sleep_time",
      "topk",
      "min_characters"
    ],
    "get_model_name": [
      "self"
    ],
    "is_vector_store": [
      "self",
      "s"
    ],
    "encode_vector_store": [
      "self",
      "vector_store_bytes"
    ],
    "decode_vector_store": [
      "self",
      "vector_store_str"
    ],
    "encode_vector_store_to_bytes": [
      "self",
      "vectorstore"
    ],
    "decode_vector_store_from_bytes": [
      "self",
      "vectorstore"
    ]
  },
  "QianFanBotRetriever": {
    "entities": [],
    "MODELS": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "_AnomalyDetectionPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input"
    ]
  },
  "AnomalyDetectionPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "TextToSpeechPipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input"
    ],
    "get_text_to_pinyin_result": [
      "self",
      "input"
    ],
    "get_text_to_speech_acoustic_result": [
      "self",
      "input"
    ]
  },
  "_FormulaRecognitionPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "get_model_settings": [
      "self",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_layout_detection"
    ],
    "check_model_settings_valid": [
      "self",
      "model_settings",
      "layout_det_res"
    ],
    "predict": [
      "self",
      "input",
      "use_layout_detection",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "layout_det_res",
      "layout_threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode"
    ]
  },
  "FormulaRecognitionPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "FormulaRecognitionResult": {
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "draw_box_formula_fine": [
    "img_size",
    "box",
    "formula",
    "is_debug"
  ],
  "_ImageClassificationPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input"
    ]
  },
  "ImageClassificationPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "Number": [],
  "OpenVocabularySegmentationPipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input",
      "prompt",
      "prompt_type"
    ]
  },
  "TSClsPipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input"
    ]
  },
  "DocUnderstandingPipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input"
    ],
    "close": [
      "self"
    ]
  },
  "make_valid": [
    "poly"
  ],
  "calculate_polygon_overlap_ratio": [
    "polygon1",
    "polygon2",
    "mode"
  ],
  "filter_overlap_boxes": [
    "layout_det_res",
    "layout_shape_mode"
  ],
  "to_pil_image": [
    "img"
  ],
  "to_np_array": [
    "img"
  ],
  "calc_merged_wh": [
    "images"
  ],
  "merge_images": [
    "images",
    "aligns",
    "layout_shape_mode"
  ],
  "merge_blocks": [
    "blocks",
    "non_merge_labels",
    "layout_shape_mode"
  ],
  "paint_token": [
    "image",
    "box",
    "token_str"
  ],
  "tokenize_figure_of_table": [
    "table_block_img",
    "table_box",
    "figures"
  ],
  "untokenize_figure_of_table": [
    "table_res_str",
    "figure_token_map",
    "image_path_to_obj_map"
  ],
  "TableData": {
    "grid": [
      "self"
    ]
  },
  "OTSL_NL": [],
  "OTSL_FCEL": [],
  "OTSL_ECEL": [],
  "OTSL_LCEL": [],
  "OTSL_UCEL": [],
  "OTSL_XCEL": [],
  "NON_CAPTURING_TAG_GROUP": [],
  "OTSL_FIND_PATTERN": [],
  "otsl_extract_tokens_and_text": [
    "s"
  ],
  "otsl_parse_texts": [
    "texts",
    "tokens"
  ],
  "export_to_html": [
    "table_data"
  ],
  "otsl_pad_to_sqr_v2": [
    "otsl_str"
  ],
  "convert_otsl_to_html": [
    "otsl_content"
  ],
  "find_shortest_repeating_substring": [
    "s"
  ],
  "find_repeating_suffix": [
    "s",
    "min_len",
    "min_repeats"
  ],
  "truncate_repetitive_content": [
    "content",
    "line_threshold",
    "char_threshold",
    "min_len",
    "min_count"
  ],
  "crop_margin": [
    "img"
  ],
  "ANNOT_TEXT_RE": [],
  "LOC_BLOCK_RE": [],
  "LOC_ITEM_RE": [],
  "LOC_TOKEN_RE": [],
  "pre_process_for_spotting": [
    "image"
  ],
  "post_process_for_spotting": [
    "input_str",
    "w",
    "h"
  ],
  "IMAGE_LABELS": [],
  "_PaddleOCRVLPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config",
      "initial_predictor"
    ],
    "close": [
      "self"
    ],
    "get_model_settings": [
      "self",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_layout_detection",
      "use_chart_recognition",
      "use_seal_recognition",
      "use_ocr_for_image_block",
      "format_block_content",
      "merge_layout_blocks",
      "markdown_ignore_labels"
    ],
    "check_model_settings_valid": [
      "self",
      "input_params"
    ],
    "get_layout_parsing_results": [
      "self",
      "images",
      "layout_det_results",
      "imgs_in_doc",
      "use_chart_recognition",
      "use_seal_recognition",
      "use_ocr_for_image_block",
      "vlm_kwargs",
      "merge_layout_blocks",
      "layout_shape_mode"
    ],
    "predict": [
      "self",
      "input",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_layout_detection",
      "use_chart_recognition",
      "use_seal_recognition",
      "use_ocr_for_image_block",
      "layout_threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode",
      "layout_shape_mode",
      "use_queues",
      "prompt_label",
      "format_block_content",
      "repetition_penalty",
      "temperature",
      "top_p",
      "min_pixels",
      "max_pixels",
      "max_new_tokens",
      "merge_layout_blocks",
      "markdown_ignore_labels",
      "vlm_extra_args"
    ],
    "concatenate_markdown_pages": [
      "self",
      "markdown_list"
    ],
    "concatenate_pages": [
      "self",
      "res_list",
      "merge_table",
      "title_level",
      "merge_pages"
    ],
    "restructure_pages": [
      "self",
      "res_list",
      "merge_tables",
      "relevel_titles",
      "concatenate_pages"
    ]
  },
  "_BasePaddleOCRVLPipeline": {
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "PaddleOCRVLPipeline": {
    "entities": []
  },
  "PaddleOCRVL15Pipeline": {
    "entities": []
  },
  "SKIP_ORDER_LABELS": [],
  "PaddleOCRVLBlock": {
    "__init__": [
      "self",
      "label",
      "bbox",
      "content",
      "group_id",
      "polygon_points",
      "global_block_id",
      "global_group_id"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "merge_formula_and_number": [
    "formula",
    "formula_number"
  ],
  "format_chart2table_func": [
    "block"
  ],
  "format_table_center_func": [
    "block"
  ],
  "build_handle_funcs_dict": [],
  "PaddleOCRVLResult": {
    "__init__": [
      "self",
      "data"
    ],
    "_to_img": [
      "self"
    ],
    "_to_html": [
      "self"
    ],
    "_to_xlsx": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ],
    "_to_markdown": [
      "self",
      "pretty",
      "show_formula_number"
    ]
  },
  "PaddleOCRVLPagesResult": {
    "save_to_img": [
      "self"
    ],
    "save_to_html": [
      "self"
    ],
    "save_to_xlsx": [
      "self"
    ],
    "_to_markdown": [
      "self",
      "pretty",
      "show_formula_number"
    ]
  },
  "MultilingualSpeechRecognitionPipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input"
    ]
  },
  "_SemanticSegmentationPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input",
      "target_size"
    ]
  },
  "SemanticSegmentationPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "OpenVocabularyDetectionPipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input",
      "prompt",
      "thresholds"
    ]
  },
  "_AttributeRecPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input",
      "det_threshold",
      "cls_threshold"
    ],
    "get_cls_result": [
      "self",
      "raw_img",
      "det_res",
      "cls_threshold"
    ],
    "get_final_result": [
      "self",
      "input_path",
      "raw_img",
      "det_res",
      "rec_res"
    ]
  },
  "AttributeRecPipeline": {
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "PedestrianAttributeRecPipeline": {
    "entities": []
  },
  "VehicleAttributeRecPipeline": {
    "entities": []
  },
  "draw_attribute_result": [
    "img",
    "boxes"
  ],
  "AttributeRecResult": {
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ],
    "_to_img": [
      "self"
    ]
  },
  "_ImageMultiLabelClassificationPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input",
      "threshold"
    ]
  },
  "ImageMultiLabelClassificationPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "_SealRecognitionPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "check_model_settings_valid": [
      "self",
      "model_settings",
      "layout_det_res"
    ],
    "get_model_settings": [
      "self",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_layout_detection"
    ],
    "predict": [
      "self",
      "input",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_layout_detection",
      "layout_det_res",
      "layout_threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode",
      "seal_det_limit_side_len",
      "seal_det_limit_type",
      "seal_det_thresh",
      "seal_det_box_thresh",
      "seal_det_unclip_ratio",
      "seal_rec_score_thresh"
    ]
  },
  "SealRecognitionPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "SealRecognitionResult": {
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "_KeypointDetectionPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "_box_xyxy2cs": [
      "self",
      "bbox",
      "padding"
    ],
    "predict": [
      "self",
      "input",
      "det_threshold"
    ]
  },
  "KeypointDetectionPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "_InstanceSegmentationPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input",
      "threshold"
    ]
  },
  "InstanceSegmentationPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "BEVDet3DPipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input"
    ]
  },
  "TSAnomalyDetPipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input"
    ]
  },
  "_is_sentence_dot": [
    "text",
    "i"
  ],
  "_find_split_pos": [
    "text",
    "chunk_size"
  ],
  "split_text_recursive": [
    "text",
    "chunk_size",
    "translate_func"
  ],
  "translate_code_block": [
    "code_block",
    "chunk_size",
    "translate_func",
    "results"
  ],
  "translate_html_block": [
    "html_block",
    "chunk_size",
    "translate_func",
    "results"
  ],
  "split_original_texts": [
    "text"
  ],
  "split_and_append_text": [
    "result",
    "text_content"
  ],
  "PP_DocTranslation_Pipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config",
      "initial_predictor"
    ],
    "close": [
      "self"
    ],
    "inintial_visual_predictor": [
      "self",
      "config"
    ],
    "inintial_chat_predictor": [
      "self",
      "config"
    ],
    "predict": [
      "self"
    ],
    "visual_predict": [
      "self",
      "input",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_textline_orientation",
      "use_seal_recognition",
      "use_table_recognition",
      "use_formula_recognition",
      "use_chart_recognition",
      "use_region_detection",
      "layout_threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode",
      "text_det_limit_side_len",
      "text_det_limit_type",
      "text_det_thresh",
      "text_det_box_thresh",
      "text_det_unclip_ratio",
      "text_rec_score_thresh",
      "seal_det_limit_side_len",
      "seal_det_limit_type",
      "seal_det_thresh",
      "seal_det_box_thresh",
      "seal_det_unclip_ratio",
      "seal_rec_score_thresh",
      "use_wired_table_cells_trans_to_html",
      "use_wireless_table_cells_trans_to_html",
      "use_table_orientation_classify",
      "use_ocr_results_with_table_cells",
      "use_e2e_wired_table_rec_model",
      "use_e2e_wireless_table_rec_model"
    ],
    "load_from_markdown": [
      "self",
      "input"
    ],
    "chunk_translate": [
      "self",
      "md_blocks",
      "chunk_size",
      "translate_func"
    ],
    "translate": [
      "self",
      "ori_md_info_list",
      "target_language",
      "chunk_size",
      "task_description",
      "output_format",
      "rules_str",
      "few_shot_demo_text_content",
      "few_shot_demo_key_value_list",
      "glossary",
      "llm_request_interval",
      "chat_bot_config"
    ],
    "concatenate_markdown_pages": [
      "self",
      "markdown_list"
    ],
    "concatenate_word_pages": [
      "self",
      "word_list"
    ],
    "concatenate_latex_pages": [
      "self",
      "latex_info_list"
    ]
  },
  "MarkdownResult": {
    "__init__": [
      "self",
      "data"
    ],
    "_get_input_fn": [
      "self"
    ],
    "_to_markdown": [
      "self",
      "pretty",
      "show_formula_number"
    ],
    "_to_word": [
      "self",
      "save_path"
    ],
    "_to_latex": [
      "self",
      "save_path"
    ]
  },
  "DocumentResult": {
    "__init__": [
      "self",
      "data"
    ],
    "_get_input_fn": [
      "self"
    ],
    "_to_word": [
      "self"
    ]
  },
  "LatexResult": {
    "__init__": [
      "self",
      "data"
    ],
    "_get_input_fn": [
      "self"
    ],
    "_to_latex": [
      "self"
    ]
  },
  "SYMBOL_PATTERNS": [],
  "get_symbol_and_level": [
    "content"
  ],
  "SPECIAL_KEYWORDS": [],
  "get_title_height": [
    "block"
  ],
  "cluster_global_heights": [
    "entries",
    "k_clusters"
  ],
  "compute_global_symbol_seq": [
    "entries",
    "title_symbol_level"
  ],
  "compute_levels_for_entries": [
    "entries"
  ],
  "assign_levels_to_parsing_res": [
    "blocks_by_page"
  ],
  "_LayoutParsingPipelineV2": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config",
      "initial_predictor"
    ],
    "close": [
      "self"
    ],
    "inintial_predictor": [
      "self",
      "config"
    ],
    "get_text_paragraphs_ocr_res": [
      "self",
      "overall_ocr_res",
      "layout_det_res"
    ],
    "check_model_settings_valid": [
      "self",
      "input_params"
    ],
    "standardized_data": [
      "self",
      "image",
      "region_det_res",
      "layout_det_res",
      "overall_ocr_res",
      "formula_res_list",
      "text_rec_model",
      "text_rec_score_thresh"
    ],
    "get_layout_parsing_objects": [
      "self",
      "image",
      "region_block_ocr_idx_map",
      "region_det_res",
      "overall_ocr_res",
      "layout_det_res",
      "table_res_list",
      "seal_res_list",
      "chart_res_list",
      "text_rec_model",
      "text_rec_score_thresh"
    ],
    "sort_layout_parsing_blocks": [
      "self",
      "layout_parsing_page"
    ],
    "get_layout_parsing_res": [
      "self",
      "image",
      "region_det_res",
      "layout_det_res",
      "overall_ocr_res",
      "table_res_list",
      "seal_res_list",
      "chart_res_list",
      "formula_res_list",
      "text_rec_score_thresh",
      "markdown_ignore_labels"
    ],
    "get_model_settings": [
      "self",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_seal_recognition",
      "use_table_recognition",
      "use_formula_recognition",
      "use_chart_recognition",
      "use_region_detection",
      "format_block_content",
      "markdown_ignore_labels"
    ],
    "predict": [
      "self",
      "input",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_textline_orientation",
      "use_seal_recognition",
      "use_table_recognition",
      "use_formula_recognition",
      "use_chart_recognition",
      "use_region_detection",
      "format_block_content",
      "layout_threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode",
      "text_det_limit_side_len",
      "text_det_limit_type",
      "text_det_thresh",
      "text_det_box_thresh",
      "text_det_unclip_ratio",
      "text_rec_score_thresh",
      "seal_det_limit_side_len",
      "seal_det_limit_type",
      "seal_det_thresh",
      "seal_det_box_thresh",
      "seal_det_unclip_ratio",
      "seal_rec_score_thresh",
      "use_wired_table_cells_trans_to_html",
      "use_wireless_table_cells_trans_to_html",
      "use_table_orientation_classify",
      "use_ocr_results_with_table_cells",
      "use_e2e_wired_table_rec_model",
      "use_e2e_wireless_table_rec_model",
      "markdown_ignore_labels"
    ],
    "concatenate_markdown_pages": [
      "self",
      "markdown_list"
    ],
    "merge_text_across_page": [
      "self",
      "blocks_by_page"
    ]
  },
  "LayoutParsingPipelineV2": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "XYCUT_SETTINGS": [],
  "REGION_SETTINGS": [],
  "BLOCK_SETTINGS": [],
  "LINE_SETTINGS": [],
  "BLOCK_LABEL_MAP": [],
  "get_overlap_boxes_idx": [
    "src_boxes",
    "ref_boxes"
  ],
  "get_sub_regions_ocr_res": [
    "overall_ocr_res",
    "object_boxes",
    "flag_within",
    "return_match_idx"
  ],
  "sorted_layout_boxes": [
    "res",
    "w"
  ],
  "calculate_projection_overlap_ratio": [
    "bbox1",
    "bbox2",
    "direction",
    "mode"
  ],
  "calculate_overlap_ratio": [
    "bbox1",
    "bbox2",
    "mode"
  ],
  "calculate_minimum_enclosing_bbox": [
    "bboxes"
  ],
  "is_english_letter": [
    "char"
  ],
  "is_numeric": [
    "char"
  ],
  "is_non_breaking_punctuation": [
    "char"
  ],
  "construct_img_path": [
    "label",
    "box"
  ],
  "gather_imgs": [
    "original_img",
    "layout_det_objs"
  ],
  "_get_minbox_if_overlap_by_ratio": [
    "bbox1",
    "bbox2",
    "ratio",
    "smaller"
  ],
  "remove_overlap_blocks": [
    "blocks",
    "threshold",
    "smaller"
  ],
  "get_bbox_intersection": [
    "bbox1",
    "bbox2",
    "return_format"
  ],
  "shrink_supplement_region_bbox": [
    "supplement_region_bbox",
    "ref_region_bbox",
    "image_width",
    "image_height",
    "block_idxes_set",
    "block_bboxes"
  ],
  "update_region_box": [
    "bbox",
    "region_box"
  ],
  "convert_formula_res_to_ocr_format": [
    "formula_res_list",
    "ocr_res"
  ],
  "calculate_bbox_area": [
    "bbox"
  ],
  "caculate_euclidean_dist": [
    "point1",
    "point2"
  ],
  "get_seg_flag": [
    "block",
    "prev_block"
  ],
  "get_show_color": [
    "label",
    "order_label"
  ],
  "_LayoutParsingPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "inintial_predictor": [
      "self",
      "config"
    ],
    "get_layout_parsing_res": [
      "self",
      "image",
      "layout_det_res",
      "overall_ocr_res",
      "table_res_list",
      "seal_res_list",
      "formula_res_list",
      "text_det_limit_side_len",
      "text_det_limit_type",
      "text_det_thresh",
      "text_det_box_thresh",
      "text_det_unclip_ratio",
      "text_rec_score_thresh"
    ],
    "check_model_settings_valid": [
      "self",
      "input_params"
    ],
    "get_model_settings": [
      "self",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_seal_recognition",
      "use_table_recognition",
      "use_formula_recognition"
    ],
    "predict": [
      "self",
      "input",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_textline_orientation",
      "use_seal_recognition",
      "use_table_recognition",
      "use_formula_recognition",
      "layout_threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode",
      "text_det_limit_side_len",
      "text_det_limit_type",
      "text_det_thresh",
      "text_det_box_thresh",
      "text_det_unclip_ratio",
      "text_rec_score_thresh",
      "seal_det_limit_side_len",
      "seal_det_limit_type",
      "seal_det_thresh",
      "seal_det_box_thresh",
      "seal_det_unclip_ratio",
      "seal_rec_score_thresh"
    ]
  },
  "LayoutParsingPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "compile_title_pattern": [],
  "TITLE_RE_PATTERN": [],
  "format_title_func": [
    "block"
  ],
  "format_para_title_func": [
    "block"
  ],
  "format_centered_by_html": [
    "string",
    "remove_symbol"
  ],
  "format_text_plain_func": [
    "block"
  ],
  "format_image_scaled_by_html_func": [
    "block",
    "original_image_width",
    "show_ocr_content"
  ],
  "format_image_plain_func": [
    "block",
    "show_ocr_content"
  ],
  "simplify_table_func": [
    "table_code"
  ],
  "format_first_line_func": [
    "block",
    "templates",
    "format_func",
    "spliter"
  ],
  "LayoutParsingResultV2": {
    "__init__": [
      "self",
      "data"
    ],
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ],
    "_to_html": [
      "self"
    ],
    "_to_xlsx": [
      "self"
    ],
    "_to_markdown": [
      "self",
      "pretty",
      "show_formula_number"
    ],
    "_to_word": [
      "self"
    ],
    "_to_latex": [
      "self"
    ]
  },
  "ProcessedLayoutParsingResult": {
    "__init__": [
      "self",
      "data"
    ],
    "_to_markdown": [
      "self",
      "pretty",
      "show_formula_number"
    ]
  },
  "TextSpan": {
    "__init__": [
      "self",
      "box",
      "text",
      "label"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "TextLine": {
    "__init__": [
      "self",
      "spans",
      "direction"
    ],
    "labels": [
      "self"
    ],
    "boxes": [
      "self"
    ],
    "height": [
      "self"
    ],
    "width": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "add_span": [
      "self",
      "span"
    ],
    "get_region_box": [
      "self"
    ],
    "get_texts": [
      "self",
      "block_label",
      "block_text_width",
      "block_start_coordinate",
      "block_stop_coordinate",
      "ori_image",
      "text_rec_model",
      "text_rec_score_thresh"
    ],
    "is_projection_contained": [
      "self",
      "box_a",
      "box_b",
      "start_idx",
      "end_idx"
    ],
    "split_boxes_by_projection": [
      "self",
      "offset"
    ],
    "format_line": [
      "self",
      "block_text_width",
      "block_start_coordinate",
      "block_stop_coordinate",
      "line_gap_limit",
      "block_label"
    ]
  },
  "LayoutBlock": {
    "__init__": [
      "self",
      "label",
      "bbox",
      "content",
      "group_id"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "update_direction": [
      "self",
      "direction"
    ],
    "update_direction_info": [
      "self"
    ],
    "append_child_block": [
      "self",
      "child_block"
    ],
    "get_child_blocks": [
      "self"
    ],
    "get_centroid": [
      "self"
    ],
    "get_bbox_direction": [
      "self",
      "direction_ratio"
    ],
    "calculate_text_line_direction": [
      "self",
      "bboxes",
      "direction_ratio"
    ],
    "group_boxes_into_lines": [
      "self",
      "ocr_rec_res",
      "line_height_iou_threshold"
    ],
    "update_text_content": [
      "self",
      "image",
      "ocr_rec_res",
      "text_rec_model",
      "text_rec_score_thresh"
    ]
  },
  "LayoutRegion": {
    "__init__": [
      "self",
      "bbox",
      "blocks"
    ],
    "init_region_info_from_layout": [
      "self",
      "blocks"
    ],
    "update_euclidean_distance": [
      "self"
    ],
    "update_direction": [
      "self",
      "direction"
    ]
  },
  "full_to_half": [
    "text"
  ],
  "calculate_table_total_columns": [
    "soup"
  ],
  "calculate_row_columns": [
    "row"
  ],
  "calculate_visual_columns": [
    "row"
  ],
  "detect_table_headers": [
    "soup1",
    "soup2",
    "max_header_rows"
  ],
  "check_rows_match": [
    "soup1",
    "soup2"
  ],
  "is_skippable": [
    "block",
    "allowed_labels"
  ],
  "can_merge_tables": [
    "prev_page",
    "prev_block",
    "curr_page",
    "curr_block"
  ],
  "perform_table_merge": [
    "soup_prev",
    "soup_curr"
  ],
  "merge_tables_across_pages": [
    "pages"
  ],
  "get_nearest_edge_distance": [
    "bbox1",
    "bbox2",
    "weight"
  ],
  "projection_by_bboxes": [
    "boxes",
    "axis"
  ],
  "split_projection_profile": [
    "arr_values",
    "min_value",
    "min_gap"
  ],
  "recursive_yx_cut": [
    "boxes",
    "indices",
    "res",
    "min_gap"
  ],
  "recursive_xy_cut": [
    "boxes",
    "indices",
    "res",
    "min_gap"
  ],
  "reference_insert": [
    "block",
    "sorted_blocks"
  ],
  "manhattan_insert": [
    "block",
    "sorted_blocks"
  ],
  "euclidean_insert": [
    "block",
    "sorted_blocks"
  ],
  "weighted_distance_insert": [
    "block",
    "sorted_blocks",
    "region"
  ],
  "insert_child_blocks": [
    "block",
    "block_idx",
    "sorted_blocks"
  ],
  "sort_child_blocks": [
    "blocks",
    "direction"
  ],
  "_get_weights": [
    "label",
    "direction"
  ],
  "_manhattan_distance": [
    "point1",
    "point2",
    "weight_x",
    "weight_y"
  ],
  "sort_normal_blocks": [
    "blocks",
    "text_line_height",
    "text_line_width",
    "region_direction"
  ],
  "get_cut_blocks": [
    "blocks",
    "cut_direction",
    "cut_coordinates",
    "mask_labels"
  ],
  "get_blocks_by_direction_interval": [
    "blocks",
    "start_index",
    "end_index",
    "direction"
  ],
  "get_nearest_blocks": [
    "block",
    "ref_blocks",
    "overlap_threshold",
    "direction"
  ],
  "update_doc_title_child_blocks": [
    "block",
    "region"
  ],
  "update_paragraph_title_child_blocks": [
    "block",
    "region"
  ],
  "update_vision_child_blocks": [
    "block",
    "region"
  ],
  "update_region_child_blocks": [
    "block",
    "region"
  ],
  "calculate_discontinuous_projection": [
    "boxes",
    "direction",
    "return_num"
  ],
  "shrink_overlapping_boxes": [
    "boxes",
    "direction",
    "min_threshold",
    "max_threshold"
  ],
  "find_local_minima_flat_regions": [
    "arr"
  ],
  "pre_process": [
    "region"
  ],
  "update_region_label": [
    "block",
    "region"
  ],
  "get_layout_structure": [
    "blocks",
    "region_direction",
    "region_secondary_direction"
  ],
  "sort_by_xycut": [
    "block_bboxes",
    "direction",
    "min_gap"
  ],
  "match_unsorted_blocks": [
    "sorted_blocks",
    "unsorted_blocks",
    "region"
  ],
  "xycut_enhanced": [
    "region"
  ],
  "_DocPreprocessorPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "check_model_settings_valid": [
      "self",
      "model_settings"
    ],
    "get_model_settings": [
      "self",
      "use_doc_orientation_classify",
      "use_doc_unwarping"
    ],
    "predict": [
      "self",
      "input",
      "use_doc_orientation_classify",
      "use_doc_unwarping"
    ]
  },
  "DocPreprocessorPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "DocPreprocessorResult": {
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "_SmallObjectDetectionPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input",
      "threshold"
    ]
  },
  "SmallObjectDetectionPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "VideoDetectionPipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input",
      "nms_thresh",
      "score_thresh"
    ]
  },
  "_OCRPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "rotate_image": [
      "self",
      "image_array_list",
      "rotate_angle_list"
    ],
    "check_model_settings_valid": [
      "self",
      "model_settings"
    ],
    "get_model_settings": [
      "self",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_textline_orientation"
    ],
    "get_text_det_params": [
      "self",
      "text_det_limit_side_len",
      "text_det_limit_type",
      "text_det_max_side_limit",
      "text_det_thresh",
      "text_det_box_thresh",
      "text_det_unclip_ratio"
    ],
    "predict": [
      "self",
      "input",
      "use_doc_orientation_classify",
      "use_doc_unwarping",
      "use_textline_orientation",
      "text_det_limit_side_len",
      "text_det_limit_type",
      "text_det_max_side_limit",
      "text_det_thresh",
      "text_det_box_thresh",
      "text_det_unclip_ratio",
      "text_rec_score_thresh",
      "return_word_box"
    ]
  },
  "OCRPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "draw_box_txt_fine": [
    "img_size",
    "box",
    "txt",
    "font_path"
  ],
  "draw_vertical_text": [
    "draw",
    "position",
    "text",
    "font",
    "fill",
    "line_spacing"
  ],
  "get_minarea_rect": [
    "points"
  ],
  "ShiTuV2Pipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input",
      "index"
    ],
    "get_rec_result": [
      "self",
      "raw_img",
      "det_res",
      "indexer",
      "rec_threshold",
      "hamming_radius",
      "topk"
    ],
    "get_final_result": [
      "self",
      "input_data",
      "raw_img",
      "det_res",
      "rec_res"
    ],
    "build_index": [
      "self",
      "gallery_imgs",
      "gallery_label",
      "metric_type",
      "index_type"
    ],
    "remove_index": [
      "self",
      "remove_ids",
      "index"
    ],
    "append_index": [
      "self",
      "gallery_imgs",
      "gallery_label",
      "index"
    ]
  },
  "draw_box": [
    "img",
    "boxes"
  ],
  "ShiTuResult": {
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "VideoClassificationPipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input",
      "topk"
    ]
  },
  "_RotatedObjectDetectionPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input",
      "threshold"
    ]
  },
  "RotatedObjectDetectionPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "FaceRecPipeline": {
    "entities": [],
    "get_rec_result": [
      "self",
      "raw_img",
      "det_res",
      "indexer",
      "rec_threshold",
      "hamming_radius",
      "topk"
    ],
    "get_final_result": [
      "self",
      "input_data",
      "raw_img",
      "det_res",
      "rec_res"
    ]
  },
  "FaceRecResult": {
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "_ObjectDetectionPipeline": {
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input",
      "threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode"
    ]
  },
  "ObjectDetectionPipeline": {
    "entities": [],
    "_pipeline_cls": [
      "self"
    ],
    "_get_batch_size": [
      "self",
      "config"
    ]
  },
  "TSFcPipeline": {
    "entities": [],
    "__init__": [
      "self",
      "config",
      "device",
      "pp_option",
      "use_hpip",
      "hpi_config"
    ],
    "predict": [
      "self",
      "input"
    ]
  },
  "create_predictor": [
    "model_name",
    "model_dir",
    "device",
    "pp_option",
    "use_hpip",
    "hpi_config",
    "genai_config"
  ],
  "INFERENCE_OPERATIONS": [],
  "_pd_dtype_to_np_dtype": [
    "pd_dtype"
  ],
  "_collect_trt_shape_range_info": [
    "model_file",
    "model_params",
    "gpu_id",
    "shape_range_info_path",
    "dynamic_shapes",
    "dynamic_shape_input_data"
  ],
  "_convert_trt": [
    "trt_cfg_setting",
    "pp_model_file",
    "pp_params_file",
    "trt_save_path",
    "device_id",
    "dynamic_shapes",
    "dynamic_shape_input_data"
  ],
  "_sort_inputs": [
    "inputs",
    "names"
  ],
  "PaddleInferChainLegacy": {
    "__init__": [
      "self",
      "predictor"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "StaticInfer": {
    "__call__": [
      "self",
      "x"
    ]
  },
  "PaddleInfer": {
    "__init__": [
      "self",
      "model_name",
      "model_dir",
      "model_file_prefix",
      "option"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "_check_run_mode": [
      "self"
    ],
    "_create": [
      "self"
    ],
    "_configure_trt": [
      "self",
      "model_file",
      "params_file",
      "cache_dir"
    ]
  },
  "MultiBackendInfer": {
    "__init__": [
      "self",
      "ui_runtime"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "HPInfer": {
    "__init__": [
      "self",
      "model_dir",
      "model_file_prefix",
      "config"
    ],
    "model_dir": [
      "self"
    ],
    "model_file_prefix": [
      "self"
    ],
    "config": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "_call_paddle_infer": [
      "self",
      "x"
    ],
    "_call_multi_backend_infer": [
      "self",
      "x"
    ],
    "_determine_backend_and_config": [
      "self"
    ],
    "_build_paddle_infer": [
      "self",
      "backend_config"
    ],
    "_build_ui_runtime": [
      "self",
      "backend",
      "backend_config",
      "ui_option"
    ]
  },
  "SERVER_BACKENDS": [],
  "GenAIConfig": {
    "check_server_url": [
      "self"
    ]
  },
  "need_local_model": [
    "genai_config"
  ],
  "_AsyncThreadManager": {
    "__init__": [
      "self"
    ],
    "start": [
      "self"
    ],
    "_cleanup_loop_internal": [
      "self"
    ],
    "stop": [
      "self",
      "timeout"
    ],
    "run_async": [
      "self",
      "coro"
    ],
    "is_running": [
      "self"
    ],
    "is_shutting_down": [
      "self"
    ]
  },
  "_async_thread_manager": [],
  "get_async_manager": [],
  "is_aio_loop_ready": [],
  "start_aio_loop": [],
  "close_aio_loop": [
    "timeout"
  ],
  "run_async": [
    "coro",
    "return_future",
    "timeout"
  ],
  "GenAIClient": {
    "__init__": [
      "self",
      "backend",
      "base_url",
      "max_concurrency",
      "model_name"
    ],
    "openai_client": [
      "self"
    ],
    "create_chat_completion": [
      "self",
      "messages"
    ],
    "close": [
      "self"
    ],
    "_get_model_name": [
      "self"
    ]
  },
  "world_size": [],
  "convert_file_size_to_int": [
    "size"
  ],
  "reduce_tensor": [
    "tensor",
    "buffer_size"
  ],
  "dtype_byte_size": [
    "dtype"
  ],
  "distributed_gather": [
    "tensor",
    "dst",
    "group",
    "offload"
  ],
  "distributed_allgather": [
    "tensor",
    "group",
    "offload"
  ],
  "fuse_param_func": [],
  "split_param_func": [],
  "split_or_fuse_func": [
    "is_fuse"
  ],
  "NewGELUActivation": {
    "forward": [
      "self",
      "input"
    ]
  },
  "GELUActivation": {
    "__init__": [
      "self",
      "use_gelu_python"
    ],
    "_gelu_python": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "FastGELUActivation": {
    "forward": [
      "self",
      "input"
    ]
  },
  "QuickGELUActivation": {
    "forward": [
      "self",
      "input"
    ]
  },
  "ClippedGELUActivation": {
    "__init__": [
      "self",
      "min",
      "max"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SiLUActivation": {
    "forward": [
      "self",
      "input"
    ]
  },
  "MishActivation": {
    "forward": [
      "self",
      "input"
    ]
  },
  "LinearActivation": {
    "forward": [
      "self",
      "input"
    ]
  },
  "ClassInstantier": {
    "__getitem__": [
      "self",
      "key"
    ]
  },
  "ACT2CLS": [],
  "ACT2FN": [],
  "get_activation": [
    "activation_string"
  ],
  "gelu_python": [],
  "gelu_new": [],
  "gelu": [],
  "gelu_fast": [],
  "quick_gelu": [],
  "silu": [],
  "mish": [],
  "linear_act": [],
  "ASYMMETRY_QUANT_SCALE_MIN": [],
  "ASYMMETRY_QUANT_SCALE_MAX": [],
  "SYMMETRY_QUANT_SCALE": [],
  "CONFIG_NAME": [],
  "LEGACY_CONFIG_NAME": [],
  "PADDLE_WEIGHTS_NAME": [],
  "PADDLE_WEIGHTS_INDEX_NAME": [],
  "PYTORCH_WEIGHTS_INDEX_NAME": [],
  "PYTORCH_WEIGHTS_NAME": [],
  "SAFE_WEIGHTS_INDEX_NAME": [],
  "SAFE_WEIGHTS_NAME": [],
  "GENERATION_CONFIG_NAME": [],
  "resolve_file_path": [
    "pretrained_model_name_or_path",
    "filenames",
    "subfolder"
  ],
  "device_guard": [
    "device",
    "dev_id"
  ],
  "get_env_device": [],
  "IndexFirstAxis": {
    "forward": [
      "ctx",
      "input",
      "indices"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "index_first_axis": [],
  "IndexPutFirstAxis": {
    "forward": [
      "ctx",
      "values",
      "indices",
      "first_axis_dim"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "index_put_first_axis": [],
  "unpad_input": [
    "hidden_states",
    "attention_mask"
  ],
  "pad_input": [
    "hidden_states",
    "indices",
    "batch",
    "seqlen"
  ],
  "is_flash_attn_available": [],
  "HAS_FLASH_ATTN": [],
  "has_flash_attn_func": [],
  "fusion_rope": [
    "query_states",
    "key_states",
    "value_states",
    "hidden_states",
    "position_ids",
    "past_key_value",
    "rotary_emb",
    "context_parallel_degree"
  ],
  "rms_norm_fused": [
    "x_in",
    "w",
    "eps",
    "use_fast_ln"
  ],
  "fusion_rms_norm": [
    "hidden_states",
    "weight",
    "variance_epsilon",
    "use_fast_ln"
  ],
  "tuple_output": [
    "outputs",
    "loss"
  ],
  "convert_encoder_output": [
    "encoder_output"
  ],
  "layer_init_wrapper": [
    "func"
  ],
  "_transformer_encoder_layer_fwd": [
    "self",
    "src",
    "src_mask",
    "cache",
    "output_attentions"
  ],
  "_transformer_decoder_layer_fwd": [
    "self",
    "tgt",
    "memory",
    "tgt_mask",
    "memory_mask",
    "cache",
    "output_attentions"
  ],
  "_transformer_decoder_fwd": [
    "self",
    "tgt",
    "memory",
    "tgt_mask",
    "memory_mask",
    "cache",
    "output_attentions",
    "output_hidden_states",
    "return_dict"
  ],
  "_transformer_encoder_fwd": [
    "self",
    "src",
    "src_mask",
    "cache",
    "output_attentions",
    "output_hidden_states",
    "return_dict"
  ],
  "_encoder_init": [],
  "_decoder_init": [],
  "_get_wrap_setattr": [
    "cls"
  ],
  "is_tensor": [
    "x"
  ],
  "ModelOutput": {
    "__post_init__": [
      "self"
    ],
    "__delitem__": [
      "self"
    ],
    "setdefault": [
      "self"
    ],
    "pop": [
      "self"
    ],
    "update": [
      "self"
    ],
    "__getitem__": [
      "self",
      "k"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "to_tuple": [
      "self"
    ]
  },
  "BaseModelOutput": {},
  "BaseModelOutputWithNoAttention": {},
  "BaseModelOutputWithPooling": {},
  "BaseModelOutputWithPast": {},
  "BaseModelOutputWithPastAndCrossAttentions": {},
  "BaseModelOutputWithPastAndMTP": {},
  "BaseModelOutputWithPoolingAndCrossAttentions": {},
  "SequenceClassifierOutput": {},
  "TokenClassifierOutput": {},
  "QuestionAnsweringModelOutput": {},
  "MultipleChoiceModelOutput": {},
  "MaskedLMOutput": {},
  "CausalLMOutputWithPast": {},
  "CausalLMOutputWithCrossAttentions": {},
  "Seq2SeqModelOutput": {},
  "Seq2SeqLMOutput": {},
  "Seq2SeqQuestionAnsweringModelOutput": {},
  "Seq2SeqSequenceClassifierOutput": {},
  "SequenceClassifierOutputWithPast": {},
  "BackboneOutput": {},
  "BaseModelOutputWithPoolingAndNoAttention": {},
  "ImageClassifierOutputWithNoAttention": {},
  "DepthEstimatorOutput": {},
  "SemanticSegmenterOutput": {},
  "Seq2SeqSpectrogramOutput": {},
  "MoEModelOutputWithPast": {},
  "MoECausalLMOutputWithPast": {},
  "Module": [],
  "PytorchTensor": [],
  "StateDictNameMapping": {
    "__post_init__": [
      "self"
    ],
    "should_transpose": [
      "self"
    ],
    "should_merge_last_two_dim": [
      "self"
    ],
    "run": [
      "self",
      "state_dict",
      "name"
    ],
    "matched": [
      "self",
      "text"
    ]
  },
  "ConversionMixin": {
    "support_conversion": [
      "cls",
      "config"
    ],
    "_get_name_mappings": [
      "cls",
      "config"
    ],
    "get_tensor_parallel_convert_actions": [
      "cls",
      "config",
      "loaded_state_dict_keys",
      "is_split",
      "ignore_error"
    ],
    "convert_tensor_parallel": [
      "cls",
      "weight_file",
      "config",
      "state_dict",
      "ignore_error"
    ],
    "merge_tensor_parallel": [
      "cls",
      "state_dict",
      "config"
    ],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ],
    "_resolve_prefix_keys": [
      "state_keys_base",
      "state_keys_real",
      "ignore_error"
    ],
    "convert_fuse_and_split": [
      "cls",
      "config",
      "state_dict",
      "tp_actions"
    ],
    "get_fuse_or_split_param_convert_actions": [
      "cls",
      "config",
      "loaded_state_dict_keys",
      "is_fuse",
      "ignore_error"
    ],
    "_get_fuse_or_split_param_mappings": [
      "cls",
      "config",
      "is_fuse"
    ],
    "_resolve_prefix_keys_for_fuse_and_split": [
      "state_keys_base",
      "state_keys_real",
      "ignore_error",
      "is_fuse"
    ]
  },
  "_add_variant": [
    "weights_name",
    "variant"
  ],
  "dtype_guard": [
    "dtype"
  ],
  "_init_weights": [],
  "no_init_weights": [
    "_enable"
  ],
  "_split_keys_evenly": [
    "keys",
    "n"
  ],
  "_load_part_state_dict_from_safetensors": [
    "keys",
    "checkpoint_file",
    "tensor_parallel_split_mapping",
    "fliter_dict_keys",
    "device",
    "quantization_linear_list",
    "quantization_config",
    "dtype",
    "return_numpy",
    "convert_from_hf",
    "transpose_weight_keys"
  ],
  "load_state_dict": [
    "checkpoint_file",
    "tensor_parallel_split_mapping",
    "fliter_dict_keys",
    "device",
    "ckpt_quant_stage",
    "convert_from_hf",
    "transpose_weight_keys"
  ],
  "_re_layer_prefix": [],
  "_load_state_dict_into_model": [
    "model_to_load",
    "state_dict",
    "start_prefix",
    "convert_from_hf"
  ],
  "_convert_state_dict_dtype_and_shape": [
    "state_dict",
    "model_to_load",
    "convert_from_hf"
  ],
  "_load_state_dict_into_meta_model": [
    "model",
    "state_dict",
    "loaded_state_dict_keys",
    "start_prefix",
    "expected_keys",
    "dtype",
    "is_safetensors",
    "keep_in_fp32_modules"
  ],
  "PretrainedModel": {
    "model_config_file": [],
    "pretrained_init_configuration": [],
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "base_model_prefix": [],
    "main_input_name": [],
    "config_class": [],
    "_keep_in_fp32_modules": [],
    "_keys_to_ignore_on_load_missing": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "_keys_to_ignore_on_save": [],
    "_tied_weights_keys": [],
    "__init__": [
      "self"
    ],
    "_post_init": [
      "self",
      "original_init"
    ],
    "_init_weights": [
      "self",
      "layer"
    ],
    "_initialize_weights": [
      "self",
      "layer"
    ],
    "init_weights": [
      "self"
    ],
    "_from_config": [
      "cls",
      "config"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "set_inference_config": [
      "cls",
      "config",
      "predictor_args"
    ],
    "confirm_inference_model": [
      "cls",
      "predictor_args"
    ],
    "base_model": [
      "self"
    ],
    "model_name_list": [
      "self"
    ],
    "can_generate": [
      "self"
    ],
    "recompute_enable": [
      "self"
    ],
    "recompute_disable": [
      "self"
    ],
    "tie_weights": [
      "self"
    ],
    "resize_position_embeddings": [
      "self",
      "new_num_position_embeddings"
    ],
    "constructed_from_pretrained_config": [
      "cls",
      "init_func"
    ],
    "resize_token_embeddings": [
      "self",
      "new_num_tokens"
    ],
    "_update_init_config": [
      "self",
      "init_config",
      "key",
      "value"
    ],
    "_get_resized_embeddings": [
      "self",
      "old_embeddings",
      "new_num_tokens"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "_resolve_model_file_path": [
      "cls",
      "pretrained_model_name_or_path",
      "from_hf_hub",
      "from_aistudio",
      "cache_dir",
      "subfolder",
      "config",
      "convert_from_torch",
      "use_safetensors",
      "variant"
    ],
    "_load_pretrained_model": [
      "cls",
      "model",
      "state_dict",
      "loaded_keys",
      "resolved_archive_file",
      "pretrained_model_name_or_path",
      "config",
      "ignore_mismatched_sizes",
      "low_cpu_mem_usage",
      "dtype",
      "keep_in_fp32_modules",
      "quantization_linear_list",
      "sharded_metadata",
      "convert_from_hf"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "merge_auto_dist_configs": [
      "self",
      "configs"
    ],
    "_generate_auto_dist_config": [
      "self",
      "auto_dist_degree"
    ],
    "get_transpose_weight_keys": [
      "self"
    ],
    "get_hf_state_dict": [
      "self"
    ],
    "set_hf_state_dict": [
      "self"
    ]
  },
  "ContextManagers": {
    "__init__": [
      "self",
      "context_managers"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "fn_args_to_dict": [
    "func"
  ],
  "get_checkpoint_shard_files": [
    "pretrained_model_name_or_path",
    "index_filename",
    "cache_dir",
    "subfolder"
  ],
  "is_paddle_support_lazy_init": [],
  "paddlenlp_load": [
    "path",
    "map_location"
  ],
  "use_hybrid_parallel": [],
  "weight_name_suffix": [],
  "_re_configuration_file": [],
  "attribute_map": [
    "config",
    "kwargs"
  ],
  "convert_to_legacy_config": [
    "attribute_map",
    "config"
  ],
  "flatten_model_config": [
    "config"
  ],
  "set_expected_keys": [
    "config",
    "llm_meta",
    "kwargs"
  ],
  "LlmMetaConfig": {
    "op_fusion_attributes": [],
    "hybrid_parallel_attributes": [],
    "recompute_attributes": [],
    "_get_defaults": [
      "cls"
    ],
    "_get_all_meta": [
      "cls"
    ],
    "_get_unsavable_keys": [
      "cls"
    ],
    "set_llm_config": [
      "cls",
      "config",
      "args"
    ]
  },
  "PretrainedConfig": {
    "pretrained_init_configuration": [],
    "_unsavable_keys": [],
    "__setattr__": [
      "self",
      "key",
      "value"
    ],
    "__getattribute__": [
      "self",
      "key"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "__init__": [
      "self"
    ],
    "_get_generation_defaults": [],
    "_has_non_default_generation_parameters": [
      "self"
    ],
    "name_or_path": [
      "self",
      "value"
    ],
    "use_return_dict": [
      "self"
    ],
    "num_labels": [
      "self",
      "num_labels"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "get_config_dict": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "_get_config_dict": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "from_dict": [
      "cls",
      "config_dict"
    ],
    "from_json_file": [
      "cls",
      "json_file"
    ],
    "_dict_from_json_file": [
      "cls",
      "json_file"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "to_diff_dict": [
      "self",
      "saving_file"
    ],
    "register_unsavable_keys": [
      "self",
      "keys"
    ],
    "to_dict": [
      "self",
      "saving_file"
    ],
    "update": [
      "self",
      "config_dict"
    ],
    "update_from_string": [
      "self",
      "update_str"
    ],
    "get": [
      "self",
      "key",
      "default"
    ]
  },
  "get_configuration_file": [
    "configuration_files"
  ],
  "BatchNormHFStateDictMixin": {
    "_get_forward_key_rules": [
      "self"
    ],
    "_get_reverse_key_rules": [
      "self"
    ],
    "get_hf_state_dict": [
      "self"
    ],
    "set_hf_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "get_scale_by_dtype": [
    "dtype",
    "return_positive"
  ],
  "get_unfinished_flag": [
    "input_ids",
    "unfinished_flag",
    "eos_token_id"
  ],
  "BeamHypotheses": {
    "__init__": [
      "self",
      "num_beams",
      "length_penalty",
      "early_stopping"
    ],
    "__len__": [
      "self"
    ],
    "add": [
      "self",
      "hyp",
      "sum_logprobs",
      "origin_len"
    ],
    "is_done": [
      "self",
      "best_sum_logprobs",
      "cur_len",
      "origin_len"
    ]
  },
  "BeamSearchScorer": {
    "__init__": [
      "self",
      "batch_size",
      "max_length",
      "num_beams",
      "length_penalty",
      "do_early_stopping",
      "num_beam_hyps_to_keep",
      "num_beam_groups"
    ],
    "is_done": [
      "self"
    ],
    "process": [
      "self",
      "input_ids",
      "next_scores",
      "next_tokens",
      "next_indices",
      "origin_len",
      "pad_token_id",
      "eos_token_id"
    ],
    "finalize": [
      "self",
      "input_ids",
      "final_beam_scores",
      "final_beam_tokens",
      "final_beam_indices",
      "origin_len",
      "pad_token_id",
      "eos_token_id"
    ]
  },
  "GenerationMixin": {
    "enable_to_static_method": [],
    "prepare_input_ids_for_generation": [
      "bos_token_id",
      "encoder_output"
    ],
    "prepare_attention_mask_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "prepare_seq_len_for_generation": [
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "get_logits_processor": [
      "self",
      "min_length",
      "max_length",
      "eos_token_id",
      "forced_bos_token_id",
      "forced_eos_token_id",
      "num_beams",
      "num_beam_groups",
      "diversity_rate",
      "repetition_penalty",
      "no_repeat_ngram_size",
      "logits_processors"
    ],
    "expand_inputs_for_generation": [
      "input_ids",
      "expand_size",
      "attention_mask"
    ],
    "update_model_kwargs_for_generation": [
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "update_scores_for_generation": [
      "scores",
      "next_scores",
      "length",
      "unfinished_flag"
    ],
    "prepare_encoder_decoder_kwargs_for_generation": [
      "self",
      "input_ids",
      "model_kwargs"
    ],
    "prepare_decoder_input_ids_for_generation": [
      "self",
      "input_ids",
      "decoder_start_token_id",
      "bos_token_id"
    ],
    "get_decoder_start_token_id": [
      "self",
      "decoder_start_token_id",
      "bos_token_id"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids"
    ],
    "adjust_logits_during_generation": [
      "self",
      "logits"
    ],
    "prepare_fast_entry": [
      "self",
      "kwargs"
    ],
    "_convert_to_fast": [
      "self",
      "kwargs"
    ],
    "_build_fast": [
      "self",
      "kwargs"
    ],
    "set_pad_token_id": [
      "self",
      "pad_token_id",
      "eos_token_id"
    ],
    "generate": [
      "self",
      "input_ids",
      "generation_config",
      "stopping_criteria",
      "streamer",
      "synced_gpus"
    ],
    "greedy_search": [
      "self",
      "input_ids",
      "logits_processors",
      "max_length",
      "pad_token_id",
      "eos_token_id",
      "stopping_criteria",
      "streamer",
      "fast_ptq_sampling",
      "trunc_input",
      "synced_gpus"
    ],
    "sample": [
      "self",
      "input_ids",
      "logits_processors",
      "max_length",
      "pad_token_id",
      "eos_token_id",
      "top_k",
      "top_p",
      "temperature",
      "min_tokens_to_keep",
      "stopping_criteria",
      "streamer",
      "fast_ptq_sampling",
      "trunc_input",
      "synced_gpus"
    ],
    "_get_model_inputs_spec": [
      "self",
      "dtype"
    ],
    "to_static": [
      "self",
      "path",
      "config"
    ],
    "sample_d2s": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "logits_processors",
      "max_new_tokens",
      "pad_token_id",
      "eos_token_id",
      "top_k",
      "top_p",
      "temperature",
      "min_tokens_to_keep"
    ],
    "reorder_cache": [
      "self",
      "cache",
      "beam_idx"
    ],
    "beam_search": [
      "self",
      "input_ids",
      "beam_scorer",
      "logits_processors",
      "max_length",
      "diversity_rate",
      "pad_token_id",
      "eos_token_id",
      "stopping_criteria",
      "fast_ptq_sampling",
      "trunc_input",
      "synced_gpus"
    ],
    "group_beam_search": [
      "self",
      "input_ids",
      "beam_scorer",
      "logits_processors",
      "max_length",
      "pad_token_id",
      "eos_token_id",
      "stopping_criteria",
      "fast_ptq_sampling",
      "trunc_input",
      "synced_gpus"
    ]
  },
  "DEFAULT_MAX_NEW_TOKENS": [],
  "GenerationConfig": {
    "_get_generation_mode": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "to_dict": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__repr__": [
      "self"
    ],
    "validate": [
      "self",
      "is_init"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path",
      "from_hf_hub",
      "from_aistudio",
      "config_file_name",
      "cache_dir",
      "force_download"
    ],
    "_dict_from_json_file": [
      "cls",
      "json_file"
    ],
    "dict_paddle_dtype_to_str": [
      "self",
      "d"
    ],
    "from_dict": [
      "cls",
      "config_dict"
    ],
    "to_diff_dict": [
      "self"
    ],
    "to_json_string": [
      "self",
      "use_diff"
    ],
    "to_json_file": [
      "self",
      "json_file_path",
      "use_diff"
    ],
    "from_model_config": [
      "cls",
      "model_config"
    ],
    "update": [
      "self"
    ]
  },
  "LogitsProcessor": {
    "__call__": [
      "self",
      "input_ids",
      "logits"
    ]
  },
  "LogitsProcessorList": {
    "__init__": [
      "self",
      "processors"
    ],
    "__call__": [
      "self",
      "input_ids",
      "logits"
    ],
    "append": [
      "self",
      "processor"
    ]
  },
  "MinLengthLogitsProcessor": {
    "__init__": [
      "self",
      "min_length",
      "eos_token_id"
    ],
    "__call__": [
      "self",
      "input_ids",
      "logits"
    ]
  },
  "RepetitionPenaltyLogitsProcessor": {
    "__init__": [
      "self",
      "penalty"
    ],
    "__call__": [
      "self",
      "input_ids",
      "logits"
    ]
  },
  "_get_ngrams": [
    "ngram_size",
    "prev_input_ids",
    "num_hypos"
  ],
  "_get_generated_ngrams": [
    "banned_ngrams",
    "prev_input_ids",
    "ngram_size",
    "cur_len"
  ],
  "_calc_banned_ngram_tokens": [
    "ngram_size",
    "prev_input_ids",
    "num_hypos",
    "cur_len"
  ],
  "NoRepeatNGramLogitsProcessor": {
    "__init__": [
      "self",
      "ngram_size"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "HammingDiversityLogitsProcessor": {
    "__init__": [
      "self",
      "diversity_rate",
      "num_beams",
      "num_beam_groups"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores",
      "current_tokens",
      "beam_group_idx"
    ]
  },
  "ForcedBOSTokenLogitsProcessor": {
    "__init__": [
      "self",
      "forced_bos_token_id"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "ForcedEOSTokenLogitsProcessor": {
    "__init__": [
      "self",
      "max_length",
      "forced_eos_token_id"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "TopKProcess": [
    "probs",
    "top_k",
    "min_tokens_to_keep"
  ],
  "TopPProcess": [
    "probs",
    "top_p",
    "min_tokens_to_keep"
  ],
  "LogitsWarper": {
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "TemperatureLogitsWarper": {
    "__init__": [
      "self",
      "temperature"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "SequenceBiasLogitsProcessor": {
    "__init__": [
      "self",
      "sequence_bias"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ],
    "_prepare_bias_variables": [
      "self",
      "scores"
    ],
    "_validate_arguments": [
      "self"
    ]
  },
  "NoBadWordsLogitsProcessor": {
    "__init__": [
      "self",
      "bad_words_ids",
      "eos_token_id"
    ],
    "_validate_arguments": [
      "self"
    ]
  },
  "PrefixConstrainedLogitsProcessor": {
    "__init__": [
      "self",
      "prefix_allowed_tokens_fn",
      "num_beams"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "StoppingCriteria": {
    "__call__": [
      "self",
      "input_ids",
      "logits"
    ]
  },
  "MaxTimeCriteria": {
    "__init__": [
      "self",
      "max_time",
      "initial_timestamp"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "MaxLengthCriteria": {
    "__init__": [
      "self",
      "max_length"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "StoppingCriteriaList": {
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ],
    "max_length": [
      "self"
    ]
  },
  "validate_stopping_criteria": [
    "stopping_criteria",
    "max_length"
  ],
  "check_image_size": [
    "input_"
  ],
  "resize": [
    "im",
    "target_size",
    "interp",
    "backend"
  ],
  "_cv2_resize": [
    "src",
    "size",
    "resample"
  ],
  "_pil_resize": [
    "src",
    "size",
    "resample"
  ],
  "flip_h": [
    "im"
  ],
  "flip_v": [
    "im"
  ],
  "slice": [
    "im",
    "coords"
  ],
  "pad": [
    "im",
    "pad",
    "val"
  ],
  "_BaseResize": {
    "__init__": [
      "self",
      "size_divisor",
      "interp",
      "backend"
    ],
    "_rescale_size": [
      "img_size",
      "target_size"
    ]
  },
  "Resize": {
    "__init__": [
      "self",
      "target_size",
      "keep_ratio",
      "size_divisor",
      "interp",
      "backend"
    ],
    "__call__": [
      "self",
      "imgs"
    ],
    "resize": [
      "self",
      "img"
    ]
  },
  "ResizeByLong": {
    "__init__": [
      "self",
      "target_long_edge",
      "size_divisor",
      "interp",
      "backend"
    ],
    "__call__": [
      "self",
      "imgs"
    ],
    "resize": [
      "self",
      "img"
    ]
  },
  "ResizeByShort": {
    "__init__": [
      "self",
      "target_short_edge",
      "size_divisor",
      "interp",
      "backend"
    ],
    "__call__": [
      "self",
      "imgs"
    ],
    "resize": [
      "self",
      "img"
    ]
  },
  "Normalize": {
    "__init__": [
      "self",
      "scale",
      "mean",
      "std"
    ],
    "norm": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "imgs"
    ]
  },
  "ToCHWImage": {
    "__call__": [
      "self",
      "imgs"
    ]
  },
  "ToBatch": {
    "__call__": [
      "self",
      "imgs"
    ]
  },
  "MAX_WINDOW": [],
  "EasterSunday": [],
  "NewYearsDay": [],
  "SuperBowl": [],
  "MothersDay": [],
  "IndependenceDay": [],
  "ChristmasEve": [],
  "ChristmasDay": [],
  "NewYearsEve": [],
  "BlackFriday": [],
  "CyberMonday": [],
  "HOLIDAYS": [],
  "_cal_year": [
    "x"
  ],
  "_cal_month": [
    "x"
  ],
  "_cal_day": [
    "x"
  ],
  "_cal_hour": [
    "x"
  ],
  "_cal_weekday": [
    "x"
  ],
  "_cal_quarter": [
    "x"
  ],
  "_cal_hourofday": [
    "x"
  ],
  "_cal_dayofweek": [
    "x"
  ],
  "_cal_dayofmonth": [
    "x"
  ],
  "_cal_dayofyear": [
    "x"
  ],
  "_cal_weekofyear": [
    "x"
  ],
  "_cal_holiday": [
    "x"
  ],
  "_cal_workday": [
    "x"
  ],
  "_cal_minuteofhour": [
    "x"
  ],
  "_cal_monthofyear": [
    "x"
  ],
  "CAL_DATE_METHOD": [],
  "load_from_one_dataframe": [
    "data",
    "time_col",
    "value_cols",
    "freq",
    "drop_tail_nan",
    "dtype"
  ],
  "load_from_dataframe": [
    "df",
    "group_id",
    "time_col",
    "target_cols",
    "label_col",
    "observed_cov_cols",
    "feature_cols",
    "known_cov_cols",
    "static_cov_cols",
    "freq",
    "fill_missing_dates",
    "fillna_method",
    "fillna_window_size"
  ],
  "_distance_to_holiday": [
    "holiday"
  ],
  "time_feature": [
    "dataset",
    "freq",
    "feature_cols",
    "extend_points",
    "inplace"
  ],
  "TSCutOff": {
    "__init__": [
      "self",
      "size"
    ],
    "__call__": [
      "self",
      "ts_list"
    ],
    "cutoff": [
      "self",
      "ts"
    ]
  },
  "TSNormalize": {
    "__init__": [
      "self",
      "scale_path",
      "params_info"
    ],
    "__call__": [
      "self",
      "ts_list"
    ],
    "tsnorm": [
      "self",
      "ts"
    ]
  },
  "BuildTSDataset": {
    "__init__": [
      "self",
      "params_info"
    ],
    "__call__": [
      "self",
      "ts_list"
    ],
    "buildtsdata": [
      "self",
      "ts"
    ]
  },
  "TimeFeature": {
    "__init__": [
      "self",
      "params_info",
      "size",
      "holiday"
    ],
    "__call__": [
      "self",
      "ts_list"
    ],
    "timefeat": [
      "self",
      "ts"
    ]
  },
  "TStoArray": {
    "__init__": [
      "self",
      "input_data"
    ],
    "__call__": [
      "self",
      "ts_list"
    ],
    "tstoarray": [
      "self",
      "ts"
    ]
  },
  "TStoBatch": {
    "__call__": [
      "self",
      "ts_list"
    ]
  },
  "ChatTemplate": {
    "_compile_jinja_template": [
      "chat_template"
    ],
    "render_conversation": [
      "self",
      "conversation_data",
      "index",
      "context_data"
    ],
    "render_query": [
      "self",
      "query",
      "index",
      "context_data"
    ],
    "_init_context_data": [
      "self",
      "context_data"
    ],
    "render_system": [
      "self",
      "context_data"
    ],
    "__call__": [
      "self",
      "conversations",
      "context_data"
    ],
    "from_dict": [
      "cls",
      "config"
    ],
    "from_file": [
      "cls",
      "file"
    ]
  },
  "adapt_stale_fwd_patch": [
    "self",
    "name",
    "value"
  ],
  "InitTrackerMeta": {
    "__init__": [
      "cls",
      "name",
      "bases",
      "attrs"
    ],
    "init_and_track_conf": [
      "init_func",
      "pre_init_func",
      "post_init_func"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ]
  },
  "Trie": {
    "__init__": [
      "self"
    ],
    "add": [
      "self",
      "word"
    ],
    "split": [
      "self",
      "text"
    ],
    "cut_text": [
      "self",
      "text",
      "offsets"
    ]
  },
  "_insert_one_token_to_ordered_list": [
    "token_list",
    "new_token"
  ],
  "_is_control": [
    "char"
  ],
  "_is_nonnormalized_char": [
    "char"
  ],
  "_is_nonnormalized_numeric": [
    "char"
  ],
  "normalize_chars": [
    "text"
  ],
  "ChatTemplateMixin": {
    "apply_chat_template": [
      "self",
      "conversation",
      "tokenize",
      "context_data"
    ],
    "_apply_chat_template_paddle": [
      "self",
      "conversation",
      "context_data"
    ],
    "_apply_chat_template": [
      "self",
      "conversation",
      "add_generation_prompt"
    ],
    "encode_chat_inputs": [
      "self",
      "conversations",
      "context_data"
    ],
    "_encode_chat_inputs_paddle": [
      "self",
      "conversations",
      "context_data"
    ],
    "_encode_chat_inputs": [
      "self",
      "conversations",
      "context_data",
      "system",
      "add_generation_prompt"
    ],
    "_extract_non_learnable_parts": [
      "self",
      "origin_msg",
      "split_s"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "init_chat_template": [
      "self",
      "chat_template"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ]
  },
  "PretrainedTokenizer": {
    "tokens_trie": [],
    "_decode_use_source_tokenizer": [],
    "_pre_init": [
      "self",
      "original_init"
    ],
    "_build_special_tokens_map_extended": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "is_fast": [
      "self"
    ],
    "get_added_vocab": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "_add_tokens": [
      "self",
      "new_tokens",
      "special_tokens"
    ],
    "_create_trie": [
      "self",
      "unique_no_split_tokens"
    ],
    "prepare_for_tokenization": [
      "self",
      "text",
      "is_split_into_words"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "_convert_token_to_id_with_added_voc": [
      "self",
      "token"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "load_vocabulary": [
      "filepath",
      "unk_token",
      "pad_token",
      "bos_token",
      "eos_token"
    ],
    "save_vocabulary": [
      "filepath",
      "vocab"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "_encode_plus": [
      "self",
      "text",
      "text_pair",
      "add_special_tokens",
      "padding_strategy",
      "truncation_strategy",
      "max_length",
      "stride",
      "is_split_into_words",
      "pad_to_multiple_of",
      "padding_side",
      "return_tensors",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "_batch_encode_plus": [
      "self",
      "batch_text_or_text_pairs",
      "add_special_tokens",
      "padding_strategy",
      "truncation_strategy",
      "max_length",
      "stride",
      "is_split_into_words",
      "pad_to_multiple_of",
      "padding_side",
      "return_position_ids",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "_batch_prepare_for_model": [
      "self",
      "batch_ids_pairs",
      "add_special_tokens",
      "padding_strategy",
      "truncation_strategy",
      "max_length",
      "stride",
      "pad_to_multiple_of",
      "padding_side",
      "return_position_ids",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "_get_bert_like_offset_mapping": [
      "self",
      "text"
    ],
    "get_offset_mapping": [
      "self",
      "text",
      "split_tokens"
    ],
    "_decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces",
      "spaces_between_special_tokens"
    ]
  },
  "_is_punctuation": [
    "char"
  ],
  "_is_symbol": [
    "char"
  ],
  "_is_whitespace": [
    "char"
  ],
  "convert_to_unicode": [
    "text"
  ],
  "whitespace_tokenize": [
    "text"
  ],
  "MIXQwen2_5_Tokenizer": {
    "__init__": [
      "self"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "VOCAB_FILES_NAMES": [],
  "MAX_MODEL_INPUT_SIZES": [],
  "PRETOKENIZE_REGEX": [],
  "bytes_to_unicode": [],
  "get_pairs": [
    "word"
  ],
  "Qwen2Tokenizer": {
    "resource_files_names": [],
    "model_input_names": [],
    "max_model_input_sizes": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "unk_token",
      "bos_token",
      "eos_token",
      "pad_token",
      "clean_up_tokenization_spaces",
      "split_special_tokens"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "_decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces",
      "spaces_between_special_tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "prepare_for_tokenization": [
      "self",
      "text"
    ]
  },
  "MIXQwen2Tokenizer": {
    "__init__": [
      "self"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "PAT_STR": [],
  "ENDOFTEXT": [],
  "IMSTART": [],
  "IMEND": [],
  "SPECIAL_TOKENS": [],
  "tiktoken": [],
  "is_tiktoken_available": [],
  "_load_tiktoken_bpe": [
    "tiktoken_bpe_file"
  ],
  "QWenTokenizer": {
    "model_input_names": [],
    "resource_files_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "errors",
      "padding_side"
    ],
    "__len__": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "_update_tiktoken": [
      "self",
      "tokens",
      "special_tokens"
    ],
    "_add_tokens": [
      "self",
      "new_tokens",
      "special_tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory"
    ],
    "tokenize": [
      "self",
      "text",
      "allowed_special",
      "disallowed_special"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "vocab_size": [
      "self"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "errors"
    ]
  },
  "convert_to_dict_message": [
    "conversation"
  ],
  "whitespace_clean": [
    "text",
    "re"
  ],
  "BasicTokenizer": {
    "__init__": [
      "self",
      "do_lower_case",
      "never_split",
      "tokenize_chinese_chars",
      "strip_accents",
      "do_split_on_punc"
    ],
    "tokenize": [
      "self",
      "text",
      "never_split"
    ],
    "_run_strip_accents": [
      "self",
      "text"
    ],
    "_run_split_on_punc": [
      "self",
      "text",
      "never_split"
    ],
    "_tokenize_chinese_chars": [
      "self",
      "text"
    ],
    "_is_chinese_char": [
      "self",
      "cp"
    ],
    "_clean_text": [
      "self",
      "text"
    ]
  },
  "CLIPTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "model_input_names": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "max_len",
      "bos_token",
      "eos_token",
      "unk_token",
      "pad_token"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ]
  },
  "Vocab": {
    "__init__": [
      "self",
      "counter",
      "max_size",
      "min_freq",
      "token_to_idx",
      "unk_token",
      "pad_token",
      "bos_token",
      "eos_token"
    ],
    "_index_counter_keys": [
      "self",
      "counter",
      "special_tokens",
      "max_size",
      "min_freq"
    ],
    "_sort_index_according_to_user_specification": [
      "self",
      "token_to_idx"
    ],
    "to_tokens": [
      "self",
      "indices"
    ],
    "to_indices": [
      "self",
      "tokens"
    ],
    "__getitem__": [
      "self",
      "tokens"
    ],
    "__len__": [
      "self"
    ],
    "__contains__": [
      "self",
      "token"
    ],
    "__call__": [
      "self",
      "tokens"
    ],
    "idx_to_token": [
      "self"
    ],
    "token_to_idx": [
      "self"
    ],
    "to_json": [
      "self",
      "path"
    ],
    "from_json": [
      "cls",
      "json_str"
    ],
    "from_dict": [
      "cls",
      "token_to_idx",
      "unk_token",
      "pad_token",
      "bos_token",
      "eos_token"
    ],
    "build_vocab": [
      "iterator",
      "max_size",
      "min_freq",
      "token_to_idx",
      "unk_token",
      "pad_token",
      "bos_token",
      "eos_token"
    ],
    "load_vocabulary": [
      "filepath",
      "unk_token",
      "pad_token",
      "bos_token",
      "eos_token"
    ],
    "save_vocabulary": [
      "self",
      "filepath"
    ],
    "get_unk_token_id": [
      "self"
    ],
    "get_bos_token_id": [
      "self"
    ],
    "get_eos_token_id": [
      "self"
    ],
    "get_pad_token_id": [
      "self"
    ]
  },
  "GPTTokenizer": {
    "resource_files_names": [],
    "gpt_vocab_link": [],
    "gpt_merges_link": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "__init__": [
      "self",
      "vocab_file",
      "merges_file",
      "errors",
      "max_len",
      "pad_token",
      "eos_token",
      "unk_token",
      "eol_token",
      "add_prefix_space",
      "add_bos_token"
    ],
    "vocab_size": [
      "self"
    ],
    "eol_token_id": [
      "self"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_ids_to_string": [
      "self",
      "ids"
    ],
    "save_resources": [
      "self",
      "save_directory"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "get_vocab": [
      "self"
    ],
    "prepare_for_tokenization": [
      "self",
      "text",
      "is_split_into_words"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "return_attention_mask"
    ]
  },
  "TOKENIZER_CONFIG_NAME": [],
  "CHAT_TEMPLATE_CONFIG_NAME": [],
  "VERY_LARGE_INTEGER": [],
  "LARGE_INTEGER": [],
  "TextInput": [],
  "PreTokenizedInput": [],
  "EncodedInput": [],
  "TextInputPair": [],
  "PreTokenizedInputPair": [],
  "EncodedInputPair": [],
  "SPECIAL_TOKENS_MAP_FILE": [],
  "ADDED_TOKENS_FILE": [],
  "TOKENIZER_CONFIG_FILE": [],
  "AddedToken": {
    "__getstate__": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "FastEncoding": {},
  "ExplicitEnum": {
    "_missing_": [
      "cls",
      "value"
    ]
  },
  "PaddingStrategy": {
    "LONGEST": [],
    "MAX_LENGTH": [],
    "DO_NOT_PAD": []
  },
  "TensorType": {
    "PADDLE": [],
    "NUMPY": []
  },
  "to_py_obj": [
    "obj"
  ],
  "_is_numpy": [
    "x"
  ],
  "TruncationStrategy": {
    "ONLY_FIRST": [],
    "ONLY_SECOND": [],
    "LONGEST_FIRST": [],
    "DO_NOT_TRUNCATE": []
  },
  "CharSpan": {},
  "TokenSpan": {},
  "BatchEncoding": {
    "__init__": [
      "self",
      "data",
      "encoding",
      "tensor_type",
      "prepend_batch_axis",
      "n_sequences"
    ],
    "n_sequences": [
      "self"
    ],
    "is_fast": [
      "self"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "__getattr__": [
      "self",
      "item"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "keys": [
      "self"
    ],
    "values": [
      "self"
    ],
    "items": [
      "self"
    ],
    "encodings": [
      "self"
    ],
    "tokens": [
      "self",
      "batch_index"
    ],
    "sequence_ids": [
      "self",
      "batch_index"
    ],
    "words": [
      "self",
      "batch_index"
    ],
    "word_ids": [
      "self",
      "batch_index"
    ],
    "token_to_sequence": [
      "self",
      "batch_or_token_index",
      "token_index"
    ],
    "token_to_word": [
      "self",
      "batch_or_token_index",
      "token_index"
    ],
    "word_to_tokens": [
      "self",
      "batch_or_word_index",
      "word_index",
      "sequence_index"
    ],
    "token_to_chars": [
      "self",
      "batch_or_token_index",
      "token_index"
    ],
    "char_to_token": [
      "self",
      "batch_or_char_index",
      "char_index",
      "sequence_index"
    ],
    "word_to_chars": [
      "self",
      "batch_or_word_index",
      "word_index",
      "sequence_index"
    ],
    "char_to_word": [
      "self",
      "batch_or_char_index",
      "char_index",
      "sequence_index"
    ],
    "convert_to_tensors": [
      "self",
      "tensor_type",
      "prepend_batch_axis"
    ]
  },
  "SpecialTokensMixin": {
    "SPECIAL_TOKENS_ATTRIBUTES": [],
    "__init__": [
      "self",
      "verbose"
    ],
    "sanitize_special_tokens": [
      "self"
    ],
    "add_special_tokens": [
      "self",
      "special_tokens_dict",
      "replace_additional_special_tokens"
    ],
    "add_tokens": [
      "self",
      "new_tokens",
      "special_tokens"
    ],
    "_add_extra_special_tokens": [
      "cls",
      "extra_sp_token"
    ],
    "_add_tokens": [
      "self",
      "new_tokens",
      "special_tokens"
    ],
    "bos_token": [
      "self",
      "value"
    ],
    "eos_token": [
      "self",
      "value"
    ],
    "unk_token": [
      "self",
      "value"
    ],
    "sep_token": [
      "self",
      "value"
    ],
    "pad_token": [
      "self",
      "value"
    ],
    "cls_token": [
      "self",
      "value"
    ],
    "mask_token": [
      "self",
      "value"
    ],
    "additional_special_tokens": [
      "self",
      "value"
    ],
    "bos_token_id": [
      "self",
      "value"
    ],
    "eos_token_id": [
      "self",
      "value"
    ],
    "unk_token_id": [
      "self",
      "value"
    ],
    "sep_token_id": [
      "self",
      "value"
    ],
    "pad_token_id": [
      "self",
      "value"
    ],
    "pad_token_type_id": [
      "self"
    ],
    "cls_token_id": [
      "self",
      "value"
    ],
    "mask_token_id": [
      "self",
      "value"
    ],
    "additional_special_tokens_ids": [
      "self",
      "values"
    ],
    "special_tokens_map": [
      "self"
    ],
    "special_tokens_map_extended": [
      "self"
    ],
    "all_special_tokens": [
      "self"
    ],
    "all_special_tokens_extended": [
      "self"
    ],
    "all_special_ids": [
      "self"
    ]
  },
  "PretrainedTokenizerBase": {
    "tokenizer_config_file": [],
    "slow_tokenizer_class": [],
    "__init__": [
      "self"
    ],
    "max_len_single_sentence": [
      "self",
      "value"
    ],
    "max_len_sentences_pair": [
      "self",
      "value"
    ],
    "_switch_to_input_mode": [
      "self"
    ],
    "_set_processor_class": [
      "self",
      "processor_class"
    ],
    "__repr__": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "_from_pretrained": [
      "cls",
      "resolved_vocab_files",
      "pretrained_model_name_or_path",
      "init_configuration"
    ],
    "save_pretrained": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "_save_pretrained": [
      "self",
      "save_directory",
      "file_names",
      "filename_prefix"
    ],
    "tokenize": [
      "self",
      "text",
      "pair",
      "add_special_tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "_get_padding_truncation_strategies": [
      "self",
      "padding",
      "truncation",
      "max_length",
      "pad_to_multiple_of",
      "verbose"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "max_length",
      "stride",
      "is_split_into_words",
      "padding",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "add_special_tokens",
      "pad_to_multiple_of",
      "padding_side",
      "return_tensors",
      "verbose"
    ],
    "encode": [
      "self",
      "text",
      "text_pair",
      "add_special_tokens",
      "padding",
      "truncation",
      "max_length",
      "stride",
      "is_split_into_words",
      "pad_to_multiple_of",
      "padding_side",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_offsets_mapping",
      "return_length",
      "verbose",
      "return_position_ids"
    ],
    "encode_plus": [
      "self",
      "text",
      "text_pair",
      "add_special_tokens",
      "padding",
      "truncation",
      "max_length",
      "stride",
      "is_split_into_words",
      "padding_side",
      "pad_to_multiple_of",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "_encode_plus": [
      "self",
      "text",
      "text_pair",
      "add_special_tokens",
      "padding_strategy",
      "truncation_strategy",
      "max_length",
      "stride",
      "is_split_into_words",
      "pad_to_multiple_of",
      "padding_side",
      "return_position_ids",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "batch_encode": [
      "self",
      "batch_text_or_text_pairs",
      "max_length",
      "stride",
      "is_split_into_words",
      "padding",
      "truncation",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "add_special_tokens",
      "pad_to_multiple_of",
      "padding_side",
      "return_tensors",
      "verbose"
    ],
    "_batch_encode_plus": [
      "self",
      "batch_text_or_text_pairs",
      "add_special_tokens",
      "padding_strategy",
      "truncation_strategy",
      "max_length",
      "stride",
      "is_split_into_words",
      "pad_to_multiple_of",
      "padding_side",
      "return_position_ids",
      "return_tensors",
      "return_token_type_ids",
      "return_attention_mask",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_dict",
      "return_offsets_mapping",
      "return_length",
      "verbose"
    ],
    "pad": [
      "self",
      "encoded_inputs",
      "padding",
      "max_length",
      "padding_side",
      "pad_to_multiple_of",
      "return_attention_mask",
      "return_tensors",
      "verbose"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "prepare_for_model": [
      "self",
      "ids",
      "pair_ids",
      "padding",
      "truncation",
      "max_length",
      "stride",
      "pad_to_multiple_of",
      "padding_side",
      "return_tensors",
      "return_position_ids",
      "return_token_type_ids",
      "return_attention_mask",
      "return_length",
      "return_overflowing_tokens",
      "return_special_tokens_mask",
      "return_offsets_mapping",
      "add_special_tokens",
      "verbose",
      "prepend_batch_axis"
    ],
    "truncate_sequences": [
      "self",
      "ids",
      "pair_ids",
      "num_tokens_to_remove",
      "truncation_strategy",
      "stride"
    ],
    "_pad": [
      "self",
      "encoded_inputs",
      "max_length",
      "padding_strategy",
      "pad_to_multiple_of",
      "padding_side",
      "return_attention_mask"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "decode_token": [
      "self",
      "all_input_ids",
      "prefix_offset",
      "read_offset"
    ],
    "batch_decode": [
      "self",
      "sequences",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ],
    "decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ],
    "_decode": [
      "self",
      "token_ids",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "clean_up_tokenization": [
      "out_string"
    ],
    "_eventual_warn_about_too_long_sequence": [
      "self",
      "ids",
      "max_length",
      "verbose"
    ]
  },
  "LlamaTokenizer": {
    "model_input_names": [],
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "unk_token",
      "bos_token",
      "eos_token",
      "add_bos_token",
      "add_eos_token",
      "sp_model_kwargs",
      "decode_with_prefix_space"
    ],
    "vocab_size": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "bos_token_id": [
      "self"
    ],
    "eos_token_id": [
      "self"
    ],
    "get_spm_processor": [
      "self",
      "from_slow"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ]
  },
  "WordpieceTokenizer": {
    "__init__": [
      "self",
      "vocab",
      "unk_token",
      "max_input_chars_per_word"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "BertTokenizer": {
    "resource_files_names": [],
    "pretrained_resource_files_map": [],
    "pretrained_init_configuration": [],
    "max_model_input_sizes": [],
    "padding_side": [],
    "__init__": [
      "self",
      "vocab_file",
      "do_lower_case",
      "do_basic_tokenize",
      "never_split",
      "unk_token",
      "sep_token",
      "pad_token",
      "cls_token",
      "mask_token",
      "tokenize_chinese_chars",
      "strip_accents"
    ],
    "vocab_size": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "num_special_tokens_to_add": [
      "self",
      "pair"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "build_offset_mapping_with_special_tokens": [
      "self",
      "offset_mapping_0",
      "offset_mapping_1"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ]
  },
  "TextRecResult": {
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ],
    "_to_img": [
      "self"
    ],
    "adjust_font_size": [
      "self",
      "image_width",
      "text",
      "font_path"
    ]
  },
  "TextRecPredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data",
      "return_word_box"
    ],
    "build_readimg": [
      "self",
      "channel_first",
      "img_mode"
    ],
    "build_resize": [
      "self",
      "image_shape"
    ],
    "build_postprocess": [
      "self"
    ],
    "foo": [
      "self"
    ],
    "get_vis_font": [
      "self"
    ]
  },
  "OCRReisizeNormImg": {
    "__init__": [
      "self",
      "rec_image_shape",
      "input_shape"
    ],
    "resize_norm_img": [
      "self",
      "img",
      "max_wh_ratio"
    ],
    "__call__": [
      "self",
      "imgs"
    ],
    "resize": [
      "self",
      "img"
    ],
    "staticResize": [
      "self",
      "img"
    ]
  },
  "BaseRecLabelDecode": {
    "__init__": [
      "self",
      "character_str",
      "use_space_char"
    ],
    "pred_reverse": [
      "self",
      "pred"
    ],
    "add_special_char": [
      "self",
      "character_list"
    ],
    "get_word_info": [
      "self",
      "text",
      "selection"
    ],
    "decode": [
      "self",
      "text_index",
      "text_prob",
      "is_remove_duplicate",
      "return_word_box"
    ],
    "get_ignored_tokens": [
      "self"
    ],
    "__call__": [
      "self",
      "pred"
    ]
  },
  "CTCLabelDecode": {
    "__init__": [
      "self",
      "character_list",
      "use_space_char"
    ],
    "__call__": [
      "self",
      "pred",
      "return_word_box"
    ],
    "add_special_char": [
      "self",
      "character_list"
    ]
  },
  "PPOCRV5RecConfig": {
    "__init__": [
      "self",
      "backbone",
      "MultiHead"
    ]
  },
  "PPOCRV5Rec": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_transpose_weight_keys": [
      "self"
    ],
    "get_hf_state_dict": [
      "self"
    ],
    "set_hf_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "UadResult": {
    "_to_img": [
      "self"
    ],
    "get_pseudo_color_map": [
      "self",
      "pred"
    ],
    "_get_color_map_list": [
      "num_classes",
      "custom_color"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "UadPredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data"
    ],
    "build_resize": [
      "self",
      "target_size",
      "keep_ratio",
      "size_divisor",
      "interp"
    ],
    "build_normalize": [
      "self",
      "mean",
      "std"
    ],
    "map_to_mask": [
      "self",
      "mask_map"
    ]
  },
  "MapToMask": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "preds"
    ],
    "apply": [
      "self",
      "pred"
    ]
  },
  "TextDetResult": {
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "TextDetPredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self",
      "limit_side_len",
      "limit_type",
      "thresh",
      "box_thresh",
      "unclip_ratio",
      "input_shape",
      "max_side_limit"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data",
      "limit_side_len",
      "limit_type",
      "thresh",
      "box_thresh",
      "unclip_ratio",
      "max_side_limit"
    ],
    "build_readimg": [
      "self",
      "channel_first",
      "img_mode"
    ],
    "build_resize": [
      "self",
      "limit_side_len",
      "limit_type"
    ],
    "build_normalize": [
      "self",
      "mean",
      "std",
      "scale",
      "order"
    ],
    "build_to_chw": [
      "self"
    ],
    "build_postprocess": [
      "self"
    ],
    "foo": [
      "self"
    ]
  },
  "DetResizeForTest": {
    "__init__": [
      "self",
      "input_shape",
      "max_side_limit"
    ],
    "__call__": [
      "self",
      "imgs",
      "limit_side_len",
      "limit_type",
      "max_side_limit"
    ],
    "resize": [
      "self",
      "img",
      "limit_side_len",
      "limit_type",
      "max_side_limit"
    ],
    "image_padding": [
      "self",
      "im",
      "value"
    ],
    "resize_image_type1": [
      "self",
      "img"
    ],
    "resize_image_type0": [
      "self",
      "img",
      "limit_side_len",
      "limit_type",
      "max_side_limit"
    ],
    "resize_image_type2": [
      "self",
      "img"
    ],
    "resize_image_type3": [
      "self",
      "img"
    ]
  },
  "NormalizeImage": {
    "__init__": [
      "self",
      "scale",
      "mean",
      "std",
      "order"
    ],
    "__call__": [
      "self",
      "imgs"
    ]
  },
  "DBPostProcess": {
    "__init__": [
      "self",
      "thresh",
      "box_thresh",
      "max_candidates",
      "unclip_ratio",
      "use_dilation",
      "score_mode",
      "box_type"
    ],
    "polygons_from_bitmap": [
      "self",
      "pred",
      "_bitmap",
      "dest_width",
      "dest_height",
      "box_thresh",
      "unclip_ratio"
    ],
    "boxes_from_bitmap": [
      "self",
      "pred",
      "_bitmap",
      "dest_width",
      "dest_height",
      "box_thresh",
      "unclip_ratio"
    ],
    "unclip": [
      "self",
      "box",
      "unclip_ratio"
    ],
    "get_mini_boxes": [
      "self",
      "contour"
    ],
    "box_score_fast": [
      "self",
      "bitmap",
      "_box"
    ],
    "box_score_slow": [
      "self",
      "bitmap",
      "contour"
    ],
    "__call__": [
      "self",
      "preds",
      "img_shapes",
      "thresh",
      "box_thresh",
      "unclip_ratio"
    ],
    "process": [
      "self",
      "pred",
      "img_shape",
      "thresh",
      "box_thresh",
      "unclip_ratio"
    ]
  },
  "kaiming_normal_": [],
  "zeros_": [],
  "ones_": [],
  "ConvBNAct": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "groups",
      "use_act",
      "use_lab",
      "lr_mult"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LightConvBNAct": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "use_lab",
      "lr_mult"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StemBlock": {
    "__init__": [
      "self",
      "in_channels",
      "mid_channels",
      "out_channels",
      "use_lab",
      "lr_mult"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HGV2_Block": {
    "__init__": [
      "self",
      "in_channels",
      "mid_channels",
      "out_channels",
      "kernel_size",
      "layer_num",
      "identity",
      "light_block",
      "use_lab",
      "lr_mult"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HGV2_Stage": {
    "__init__": [
      "self",
      "in_channels",
      "mid_channels",
      "out_channels",
      "block_num",
      "layer_num",
      "is_downsample",
      "light_block",
      "kernel_size",
      "use_lab",
      "stride",
      "lr_mult"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PPHGNetV2": {
    "__init__": [
      "self",
      "stage_config",
      "stem_channels",
      "use_lab",
      "use_last_conv",
      "class_expand",
      "class_num",
      "lr_mult_list",
      "det",
      "out_indices"
    ],
    "_init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DSConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "padding",
      "stride",
      "groups",
      "if_act",
      "act"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "IntraCLBlock": {
    "__init__": [
      "self",
      "in_channels",
      "reduce_factor",
      "intraclblock_config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LKPAN": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "mode",
      "reduce_factor",
      "intraclblock_config",
      "upsample_mode",
      "upsample_align_mode"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvBNLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "groups",
      "if_act",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LocalModule": {
    "__init__": [
      "self",
      "in_c",
      "mid_c",
      "act"
    ],
    "forward": [
      "self",
      "x",
      "init_map"
    ]
  },
  "PFHeadLocal": {
    "__init__": [
      "self",
      "in_channels",
      "k",
      "mode",
      "scale_factor",
      "act",
      "upsample_mode",
      "upsample_align_mode"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PPOCRV5ServerDet": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DEFAULT_CONFIG": [],
  "PPOCRV5MobileDetConfig": {
    "model_type": [],
    "__init__": [
      "self"
    ]
  },
  "get_bias_attr": [
    "k"
  ],
  "LearnableAffineBlock": {
    "__init__": [
      "self",
      "scale_value",
      "bias_value",
      "lr_mult",
      "lab_lr"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Head": {
    "__init__": [
      "self",
      "in_channels",
      "kernel_list",
      "fix_nan"
    ],
    "forward": [
      "self",
      "x",
      "return_f"
    ]
  },
  "DBHead": {
    "__init__": [
      "self",
      "in_channels",
      "k"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "make_divisible": [
    "v",
    "divisor",
    "min_value"
  ],
  "Act": {
    "__init__": [
      "self",
      "act",
      "lr_mult",
      "lab_lr"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LearnableRepLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "act",
      "stride",
      "lr_mult",
      "lab_lr",
      "num_conv_branches",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SELayer": {
    "__init__": [
      "self",
      "channel",
      "reduction",
      "lr_mult"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LCNetV3Block": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "act",
      "stride",
      "dw_size",
      "use_se",
      "conv_kxk_num",
      "reduction",
      "lr_mult",
      "lab_lr"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PPLCNetV3": {
    "__init__": [
      "self",
      "scale",
      "conv_kxk_num",
      "reduction",
      "act",
      "lr_mult_list",
      "lab_lr",
      "net_config",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SEModule": {
    "__init__": [
      "self",
      "in_channels",
      "reduction"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "RSELayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "shortcut",
      "reduction"
    ],
    "forward": [
      "self",
      "ins"
    ]
  },
  "RSEFPN": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "shortcut",
      "reduction"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PPOCRV5MobileDet": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PPOCRV5ServerDetConfig": {
    "model_type": [],
    "__init__": [
      "self"
    ]
  },
  "DocTrResult": {
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "WarpPredictor": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data"
    ]
  },
  "DocTrPostProcess": {
    "__init__": [
      "self",
      "scale"
    ],
    "__call__": [
      "self",
      "imgs"
    ],
    "doctr": [
      "self",
      "pred"
    ]
  },
  "conv3x3": [
    "in_channels",
    "out_channels",
    "kernel_size",
    "stride"
  ],
  "dilated_conv_bn_act": [
    "in_channels",
    "out_channels",
    "dilation"
  ],
  "dilated_conv": [
    "in_channels",
    "out_channels",
    "kernel_size",
    "dilation",
    "stride"
  ],
  "ResidualBlockWithDilation": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "downsample",
      "is_activation",
      "is_top"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResnetStraight": {
    "__init__": [
      "self",
      "num_filter",
      "map_num",
      "block_nums",
      "kernel_size",
      "stride"
    ],
    "blocklayer": [
      "self",
      "out_channels",
      "block_nums",
      "kernel_size",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UVDocNet": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_get_forward_key_rules": [
      "self"
    ],
    "_get_reverse_key_rules": [
      "self"
    ]
  },
  "UVDocNetConfig": {
    "model_type": [],
    "__init__": [
      "self"
    ]
  },
  "STATIC_SHAPE_MODEL_LIST": [],
  "restore_to_draw_masks": [
    "img_size",
    "boxes"
  ],
  "draw_mask": [
    "im",
    "boxes",
    "img_size"
  ],
  "LayoutAnalysisResult": {
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "LayoutAnalysisPredictor": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "process": [
      "self",
      "batch_data",
      "threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode",
      "layout_shape_mode",
      "filter_overlap_boxes",
      "skip_order_labels"
    ],
    "build_resize": [
      "self",
      "target_size",
      "keep_ratio",
      "interp"
    ],
    "build_to_batch": [
      "self"
    ],
    "build_postprocess": [
      "self"
    ]
  },
  "Boxes": [],
  "is_convex": [
    "p_prev",
    "p_curr",
    "p_next"
  ],
  "angle_between_vectors": [
    "v1",
    "v2"
  ],
  "calc_new_point": [
    "p_curr",
    "v1",
    "v2",
    "distance"
  ],
  "extract_custom_vertices": [
    "polygon",
    "max_allowed_dist",
    "sharp_angle_thresh",
    "max_dist_ratio"
  ],
  "mask2polygon": [
    "mask",
    "max_allowed_dist",
    "epsilon_ratio",
    "extract_custom"
  ],
  "extract_polygon_points_by_masks": [
    "boxes",
    "masks",
    "scale_ratio",
    "layout_shape_mode"
  ],
  "convert_polygon_to_quad": [
    "polygon"
  ],
  "restructured_boxes": [
    "boxes",
    "labels",
    "img_size",
    "polygon_points"
  ],
  "unclip_boxes": [
    "boxes",
    "unclip_ratio"
  ],
  "filter_boxes": [
    "src_boxes",
    "layout_shape_mode"
  ],
  "update_order_index": [
    "boxes",
    "skip_order_labels"
  ],
  "find_label_position": [
    "box",
    "polygon_points",
    "text_w",
    "text_h",
    "max_shift"
  ],
  "LayoutAnalysisProcess": {
    "__init__": [
      "self",
      "labels",
      "scale_size"
    ],
    "apply": [
      "self",
      "boxes",
      "img_size",
      "threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode",
      "masks",
      "layout_shape_mode"
    ],
    "__call__": [
      "self",
      "batch_outputs",
      "datas",
      "threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode",
      "layout_shape_mode",
      "filter_overlap_boxes",
      "skip_order_labels"
    ]
  },
  "get_align_equation": [
    "equation"
  ],
  "add_text_for_zh_formula": [
    "formula"
  ],
  "generate_tex_file": [
    "tex_file_path",
    "equation"
  ],
  "generate_pdf_file": [
    "tex_path",
    "pdf_dir",
    "is_debug"
  ],
  "crop_white_area": [
    "image"
  ],
  "pdf2img": [
    "pdf_path",
    "img_path",
    "is_padding"
  ],
  "draw_formula_module": [
    "img_size",
    "box",
    "formula",
    "is_debug"
  ],
  "env_valid": [],
  "FormulaRecPredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data"
    ],
    "build_readimg": [
      "self",
      "channel_first",
      "img_mode"
    ],
    "build_min_max_resize": [
      "self",
      "min_dimensions",
      "max_dimensions"
    ],
    "build_latex_test_transform": [
      "self"
    ],
    "build_normalize": [
      "self",
      "mean",
      "std",
      "order"
    ],
    "build_latexocr_imageformat": [
      "self"
    ],
    "build_unimernet_decode": [
      "self",
      "input_size"
    ],
    "build_postprocess": [
      "self"
    ],
    "build_unimernet_imageformat": [
      "self"
    ],
    "foo": [
      "self"
    ]
  },
  "MinMaxResize": {
    "__init__": [
      "self",
      "min_dimensions",
      "max_dimensions"
    ],
    "pad_": [
      "self",
      "img",
      "divable"
    ],
    "minmax_size_": [
      "self",
      "img",
      "max_dimensions",
      "min_dimensions"
    ],
    "resize": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "imgs"
    ]
  },
  "LatexTestTransform": {
    "__init__": [
      "self"
    ],
    "transform": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "imgs"
    ]
  },
  "LatexImageFormat": {
    "__init__": [
      "self"
    ],
    "format": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "imgs"
    ]
  },
  "LaTeXOCRDecode": {
    "__init__": [
      "self",
      "character_list"
    ],
    "post_process": [
      "self",
      "s"
    ],
    "decode": [
      "self",
      "tokens"
    ],
    "__call__": [
      "self",
      "preds",
      "label",
      "mode"
    ]
  },
  "UniMERNetImgDecode": {
    "__init__": [
      "self",
      "input_size",
      "random_padding"
    ],
    "crop_margin": [
      "self",
      "img"
    ],
    "get_dimensions": [
      "self",
      "img"
    ],
    "_compute_resized_output_size": [
      "self",
      "image_size",
      "size",
      "max_size"
    ],
    "resize": [
      "self",
      "img",
      "size"
    ],
    "img_decode": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "imgs"
    ]
  },
  "UniMERNetDecode": {
    "SPECIAL_TOKENS_ATTRIBUTES": [],
    "__init__": [
      "self",
      "character_list"
    ],
    "_add_tokens": [
      "self",
      "new_tokens",
      "special_tokens"
    ],
    "added_tokens_encoder": [
      "self",
      "added_tokens_decoder"
    ],
    "all_special_tokens": [
      "self"
    ],
    "all_special_tokens_extended": [
      "self"
    ],
    "special_tokens_map_extended": [
      "self"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "detokenize": [
      "self",
      "tokens"
    ],
    "token2str": [
      "self",
      "token_ids"
    ],
    "normalize": [
      "self",
      "s"
    ],
    "remove_chinese_text_wrapping": [
      "self",
      "formula"
    ],
    "post_process": [
      "self",
      "text"
    ],
    "__call__": [
      "self",
      "preds",
      "label",
      "mode"
    ]
  },
  "UniMERNetTestTransform": {
    "__init__": [
      "self"
    ],
    "transform": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "imgs"
    ]
  },
  "UniMERNetImageFormat": {
    "__init__": [
      "self"
    ],
    "format": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "imgs"
    ]
  },
  "TopkResult": {
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ],
    "_to_img": [
      "self"
    ],
    "_get_font_colormap": [
      "self",
      "color_index"
    ]
  },
  "ClasPredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self",
      "topk"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data",
      "topk"
    ],
    "build_resize": [
      "self",
      "resize_short",
      "size",
      "backend",
      "interpolation"
    ],
    "build_crop": [
      "self",
      "size"
    ],
    "build_normalize": [
      "self",
      "mean",
      "std",
      "scale",
      "order",
      "channel_num"
    ],
    "build_to_chw": [
      "self"
    ],
    "build_topk": [
      "self",
      "topk",
      "label_list"
    ]
  },
  "Crop": {
    "__init__": [
      "self",
      "crop_size",
      "mode"
    ],
    "__call__": [
      "self",
      "imgs"
    ],
    "crop": [
      "self",
      "img"
    ]
  },
  "Topk": {
    "__init__": [
      "self",
      "class_ids"
    ],
    "_parse_class_id_map": [
      "self",
      "class_ids"
    ],
    "__call__": [
      "self",
      "preds",
      "topk"
    ]
  },
  "PPLCNetConfig": {
    "model_type": [],
    "__init__": [
      "self"
    ]
  },
  "_create_act": [
    "act"
  ],
  "AdaptiveAvgPool2D": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DepthwiseSeparable": {
    "__init__": [
      "self",
      "num_channels",
      "num_filters",
      "stride",
      "reduction",
      "dw_size",
      "use_se",
      "lr_mult",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PPLCNet": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_transpose_weight_keys": [
      "self"
    ]
  },
  "OVSegPredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data",
      "prompts"
    ],
    "build_sam_preprocessor": [
      "self",
      "size",
      "mean",
      "std"
    ]
  },
  "draw_segm": [
    "im",
    "masks",
    "mask_info",
    "alpha"
  ],
  "SAMSegResult": {
    "__init__": [
      "self",
      "data"
    ],
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "_get_preprocess_shape": [
    "oldh",
    "oldw",
    "long_side_length"
  ],
  "SAMProcessor": {
    "__init__": [
      "self",
      "size",
      "image_mean",
      "image_std"
    ],
    "preprocess": [
      "self",
      "images"
    ],
    "postprocess": [
      "self",
      "low_res_masks",
      "mask_threshold"
    ]
  },
  "SamPromptProcessor": {
    "__init__": [
      "self",
      "size"
    ],
    "apply_coords": [
      "self",
      "coords",
      "original_size"
    ],
    "apply_boxes": [
      "self",
      "boxes",
      "original_size"
    ],
    "__call__": [
      "self",
      "original_size",
      "point_coords",
      "box"
    ]
  },
  "SamImageProcessor": {
    "__init__": [
      "self",
      "size",
      "image_mean",
      "image_std"
    ],
    "apply_image": [
      "self",
      "image"
    ],
    "__call__": [
      "self",
      "images"
    ],
    "preprocess": [
      "self",
      "images"
    ]
  },
  "Fastspeech2Result": {
    "__init__": [
      "self",
      "data"
    ]
  },
  "Fastspeech2Predictor": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "process": [
      "self",
      "batch_data"
    ]
  },
  "visualize": [
    "predicted_label",
    "input_ts",
    "target_cols"
  ],
  "TSClsResult": {
    "_to_img": [
      "self"
    ],
    "_to_csv": [
      "self"
    ]
  },
  "TSClsPredictor": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data"
    ]
  },
  "GetCls": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "pred_list"
    ],
    "getcls": [
      "self",
      "pred"
    ]
  },
  "BuildPadMask": {
    "__init__": [
      "self",
      "input_data"
    ],
    "__call__": [
      "self",
      "ts_list"
    ],
    "padmask": [
      "self",
      "ts"
    ]
  },
  "TablePredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data"
    ],
    "build_readimg": [
      "self",
      "channel_first",
      "img_mode"
    ],
    "foo": [
      "self"
    ],
    "build_resize_table": [
      "self",
      "max_len",
      "resize_bboxes"
    ],
    "build_normalize": [
      "self",
      "mean",
      "std",
      "scale",
      "order"
    ],
    "build_padding": [
      "self",
      "size",
      "pad_value"
    ],
    "build_to_chw": [
      "self"
    ],
    "_pack_res": [
      "self",
      "single"
    ]
  },
  "Pad": {
    "__init__": [
      "self",
      "target_size",
      "val"
    ],
    "apply": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "imgs"
    ]
  },
  "TableLabelDecode": {
    "ENABLE_BATCH": [],
    "INPUT_KEYS": [],
    "OUTPUT_KEYS": [],
    "DEAULT_INPUTS": [],
    "DEAULT_OUTPUTS": [],
    "__init__": [
      "self",
      "model_name",
      "merge_no_span_structure",
      "dict_character"
    ],
    "add_special_char": [
      "self",
      "dict_character"
    ],
    "get_ignored_tokens": [
      "self"
    ],
    "get_beg_end_flag_idx": [
      "self",
      "beg_or_end"
    ],
    "__call__": [
      "self",
      "pred",
      "img_size",
      "ori_img_size"
    ],
    "decode": [
      "self",
      "structure_probs",
      "bbox_preds",
      "padding_size",
      "ori_img_size"
    ],
    "decode_label": [
      "self",
      "batch"
    ],
    "_get_bbox_scales": [
      "self",
      "padding_shape",
      "ori_shape"
    ]
  },
  "SLANeXtConfig": {
    "__init__": [
      "self",
      "backbone",
      "SLAHead"
    ]
  },
  "SLANeXt": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_transpose_weight_keys": [
      "self"
    ],
    "get_hf_state_dict": [
      "self"
    ],
    "set_hf_state_dict": [
      "self",
      "state_dict"
    ]
  },
  "WhisperResult": {
    "__init__": [
      "self",
      "data"
    ]
  },
  "WhisperPredictor": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data"
    ]
  },
  "exact_div": [
    "x",
    "y"
  ],
  "_MODELS": [],
  "SAMPLE_RATE": [],
  "N_FFT": [],
  "N_MELS": [],
  "HOP_LENGTH": [],
  "CHUNK_LENGTH": [],
  "N_SAMPLES": [],
  "N_FRAMES": [],
  "ModelDimensions": {},
  "LANGUAGES": [],
  "TO_LANGUAGE_CODE": [],
  "compression_ratio": [
    "text"
  ],
  "format_timestamp": [
    "seconds",
    "always_include_hours",
    "decimal_marker"
  ],
  "Tokenizer": {
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "token_ids"
    ],
    "decode_with_timestamps": [
      "self",
      "tokens"
    ],
    "eot": [
      "self"
    ],
    "sot": [
      "self"
    ],
    "sot_lm": [
      "self"
    ],
    "sot_prev": [
      "self"
    ],
    "no_speech": [
      "self"
    ],
    "no_timestamps": [
      "self"
    ],
    "timestamp_begin": [
      "self"
    ],
    "language_token": [
      "self"
    ],
    "all_language_tokens": [
      "self"
    ],
    "all_language_codes": [
      "self"
    ],
    "sot_sequence_including_notimestamps": [
      "self"
    ],
    "non_speech_tokens": [
      "self"
    ],
    "_get_single_token_id": [
      "self",
      "text"
    ]
  },
  "build_tokenizer": [
    "resource_path",
    "name"
  ],
  "get_tokenizer": [
    "multilingual",
    "resource_path"
  ],
  "MultiHeadAttention": {
    "__init__": [
      "self",
      "n_state",
      "n_head"
    ],
    "forward": [
      "self",
      "x",
      "xa",
      "mask",
      "kv_cache"
    ],
    "qkv_attention": [
      "self",
      "q",
      "k",
      "v",
      "mask"
    ]
  },
  "ResidualAttentionBlock": {
    "__init__": [
      "self",
      "n_state",
      "n_head",
      "cross_attention"
    ],
    "forward": [
      "self",
      "x",
      "xa",
      "mask",
      "kv_cache"
    ]
  },
  "sinusoids": [
    "length",
    "channels",
    "max_timescale"
  ],
  "AudioEncoder": {
    "__init__": [
      "self",
      "n_mels",
      "n_ctx",
      "n_state",
      "n_head",
      "n_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TextDecoder": {
    "__init__": [
      "self",
      "n_vocab",
      "n_ctx",
      "n_state",
      "n_head",
      "n_layer"
    ],
    "forward": [
      "self",
      "x",
      "xa",
      "kv_cache"
    ]
  },
  "DecodingOptions": {},
  "DecodingResult": {},
  "Inference": {
    "logits": [
      "self",
      "tokens",
      "audio_features"
    ],
    "rearrange_kv_cache": [
      "self",
      "source_indices"
    ],
    "cleanup_caching": [
      "self"
    ]
  },
  "WhisperInference": {
    "__init__": [
      "self",
      "model",
      "initial_token_length"
    ],
    "logits": [
      "self",
      "tokens",
      "audio_features"
    ],
    "cleanup_caching": [
      "self"
    ],
    "rearrange_kv_cache": [
      "self",
      "source_indices"
    ]
  },
  "detect_language": [
    "model",
    "mel",
    "resource_path",
    "tokenizer"
  ],
  "transcribe": [
    "model",
    "mel",
    "resource_path"
  ],
  "SequenceRanker": {
    "rank": [
      "self",
      "tokens",
      "sum_logprobs"
    ]
  },
  "MaximumLikelihoodRanker": {
    "__init__": [
      "self",
      "length_penalty"
    ],
    "rank": [
      "self",
      "tokens",
      "sum_logprobs"
    ]
  },
  "TokenDecoder": {
    "reset": [
      "self"
    ],
    "update": [
      "self",
      "tokens",
      "logits",
      "sum_logprobs"
    ],
    "finalize": [
      "self",
      "tokens",
      "sum_logprobs"
    ]
  },
  "GreedyDecoder": {
    "__init__": [
      "self",
      "temperature",
      "eot"
    ],
    "update": [
      "self",
      "tokens",
      "logits",
      "sum_logprobs"
    ],
    "finalize": [
      "self",
      "tokens",
      "sum_logprobs"
    ]
  },
  "BeamSearchDecoder": {
    "__init__": [
      "self",
      "beam_size",
      "eot",
      "inference",
      "patience"
    ],
    "reset": [
      "self"
    ],
    "update": [
      "self",
      "tokens",
      "logits",
      "sum_logprobs"
    ],
    "finalize": [
      "self",
      "preceding_tokens",
      "sum_logprobs"
    ]
  },
  "LogitFilter": {
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "SuppressBlank": {
    "__init__": [
      "self",
      "tokenizer",
      "sample_begin"
    ],
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "SuppressTokens": {
    "__init__": [
      "self",
      "suppress_tokens"
    ],
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "ApplyTimestampRules": {
    "__init__": [
      "self",
      "tokenizer",
      "sample_begin",
      "max_initial_timestamp_index"
    ],
    "apply": [
      "self",
      "logits",
      "tokens"
    ]
  },
  "DecodingTask": {
    "__init__": [
      "self",
      "model",
      "options",
      "resource_path"
    ],
    "_verify_options": [
      "self",
      "options"
    ],
    "_get_initial_tokens": [
      "self"
    ],
    "_get_suppress_tokens": [
      "self"
    ],
    "_get_audio_features": [
      "self",
      "mel"
    ],
    "_detect_language": [
      "self",
      "audio_features",
      "tokens",
      "resource_path"
    ],
    "_main_loop": [
      "self",
      "audio_features",
      "tokens"
    ],
    "run": [
      "self",
      "mel"
    ]
  },
  "decode": [
    "model",
    "mel",
    "options",
    "resource_path"
  ],
  "Whisper": {
    "__init__": [
      "self",
      "dims"
    ],
    "embed_audio": [
      "self",
      "mel"
    ],
    "logits": [
      "self",
      "tokens",
      "audio_features"
    ],
    "forward": [
      "self",
      "mel",
      "tokens"
    ],
    "device": [
      "self"
    ],
    "is_multilingual": [
      "self"
    ],
    "install_kv_cache_hooks": [
      "self",
      "cache"
    ],
    "detect_language": [],
    "transcribe": [],
    "decode": []
  },
  "pad_or_trim": [
    "array",
    "length"
  ],
  "hann_window": [
    "n_fft"
  ],
  "mel_filters": [
    "resource_path",
    "n_mels"
  ],
  "log_mel_spectrogram": [
    "audio",
    "n_mels",
    "resource_path"
  ],
  "SegResult": {
    "_to_img": [
      "self"
    ],
    "get_pseudo_color_map": [
      "self",
      "pred"
    ],
    "_get_color_map_list": [
      "num_classes",
      "custom_color"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "SegPredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self",
      "target_size"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data",
      "target_size"
    ],
    "build_normalize": [
      "self",
      "mean",
      "std"
    ],
    "build_resize": [
      "self",
      "target_size",
      "keep_ratio",
      "size_divisor",
      "interp"
    ]
  },
  "SegPostProcess": {
    "__call__": [
      "self",
      "imgs",
      "src_images"
    ],
    "reverse_resize": [
      "self",
      "img",
      "src_size"
    ]
  },
  "PwganResult": {
    "__init__": [
      "self",
      "data"
    ],
    "_to_audio": [
      "self"
    ]
  },
  "PwganPredictor": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "process": [
      "self",
      "batch_data"
    ]
  },
  "FaceFeaturePredictor": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "process": [
      "self",
      "batch_data"
    ]
  },
  "OVDetPredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data",
      "prompt",
      "thresholds"
    ],
    "_parse_current_thresholds": [
      "self",
      "func",
      "init_thresholds",
      "process_thresholds"
    ],
    "build_postprocess": [
      "self"
    ],
    "build_grounding_dino_preprocessor": [
      "self",
      "text_max_words",
      "target_size"
    ],
    "build_yoloworld_preprocessor": [
      "self",
      "image_target_size",
      "image_mean",
      "image_std"
    ]
  },
  "LetterResize": {
    "__init__": [
      "self",
      "scale",
      "pad_val",
      "use_mini_pad",
      "stretch_only",
      "allow_scale_up"
    ],
    "_resize_img": [
      "self",
      "image"
    ],
    "__call__": [
      "self",
      "images"
    ]
  },
  "YOLOWorldProcessor": {
    "__init__": [
      "self",
      "model_dir",
      "image_target_size",
      "image_mean",
      "image_std"
    ],
    "__call__": [
      "self",
      "images",
      "text"
    ],
    "process_image": [
      "self",
      "images"
    ],
    "process_text": [
      "self",
      "text"
    ]
  },
  "YOLOWorldPostProcessor": {
    "__init__": [
      "self",
      "threshold"
    ],
    "__call__": [
      "self",
      "pred_boxes",
      "pred_nums",
      "prompt",
      "src_images",
      "threshold"
    ],
    "postprocess": [
      "self",
      "pred_boxes",
      "classnames",
      "src_image",
      "threshold"
    ],
    "prompt_to_classnames": [
      "self",
      "text"
    ]
  },
  "_max_by_axis": [
    "the_list"
  ],
  "_text_pad_batch_data": [
    "insts",
    "pad_idx",
    "max_seq_len",
    "return_pos",
    "return_input_mask",
    "return_max_len",
    "return_num_token",
    "return_seq_lens",
    "pad_2d_pos_ids",
    "pad_segment_id",
    "select",
    "extract"
  ],
  "GroundingDINOPostProcessor": {
    "__init__": [
      "self",
      "tokenizer",
      "box_threshold",
      "text_threshold"
    ],
    "__call__": [
      "self",
      "pred_boxes",
      "pred_logits",
      "prompt",
      "src_images",
      "box_threshold",
      "text_threshold"
    ],
    "postprocess": [
      "self",
      "pred_logits",
      "pred_boxes",
      "src_prompt",
      "src_image",
      "box_threshold",
      "text_threshold"
    ],
    "decode": [
      "self",
      "posmap",
      "prompt"
    ]
  },
  "GroundingDINOProcessor": {
    "__init__": [
      "self",
      "model_dir",
      "text_max_words",
      "image_do_resize",
      "image_target_size",
      "image_do_normalize",
      "image_mean",
      "image_std",
      "image_do_nested"
    ],
    "__call__": [
      "self",
      "images",
      "text"
    ]
  },
  "GroundingDinoTextProcessor": {
    "__init__": [
      "self",
      "max_words"
    ],
    "__call__": [
      "self",
      "input_ids",
      "special_tokens_list"
    ],
    "pre_caption": [
      "self",
      "caption"
    ],
    "generate_masks_with_special_tokens_and_transfer_map": [
      "self",
      "tokenized",
      "special_tokens_list"
    ]
  },
  "GroundingDinoImageProcessor": {
    "__init__": [
      "self",
      "do_resize",
      "target_size",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_nested"
    ],
    "__call__": [
      "self",
      "images"
    ],
    "resize": [
      "self",
      "image",
      "size",
      "max_size"
    ],
    "nested_tensor_from_tensor_list": [
      "self",
      "tensor_list"
    ],
    "preprocess": [
      "self",
      "images",
      "do_resize",
      "target_size",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_nested"
    ]
  },
  "MLClassResult": {
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ],
    "_to_img": [
      "self"
    ],
    "_get_font_colormap": [
      "self",
      "color_index"
    ]
  },
  "MLClasPredictor": {
    "entities": [],
    "__init__": [
      "self",
      "threshold"
    ],
    "_get_result_class": [
      "self"
    ],
    "process": [
      "self",
      "batch_data",
      "threshold"
    ],
    "build_threshoutput": [
      "self",
      "threshold",
      "label_list"
    ]
  },
  "MultiLabelThreshOutput": {
    "__init__": [
      "self",
      "class_ids",
      "delimiter"
    ],
    "_parse_class_id_map": [
      "self",
      "class_ids"
    ],
    "__call__": [
      "self",
      "preds",
      "threshold"
    ]
  },
  "TextToPinyinResult": {
    "__init__": [
      "self",
      "data"
    ]
  },
  "TextToPinyinPredictor": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data"
    ]
  },
  "INITIALS": [],
  "FINALS": [],
  "SPECIALS": [],
  "simplified_charcters": [],
  "traditional_characters": [],
  "s2t_dict": [],
  "t2s_dict": [],
  "tranditional_to_simplified": [
    "text"
  ],
  "ANCHOR_CHAR": [],
  "prepare_onnx_input": [
    "tokenizer",
    "labels",
    "char2phonemes",
    "chars",
    "texts",
    "query_ids",
    "use_mask",
    "window_size",
    "max_len"
  ],
  "_truncate_texts": [
    "window_size",
    "texts",
    "query_ids"
  ],
  "rule": [
    "C",
    "V",
    "R",
    "T"
  ],
  "generate_lexicon": [
    "with_tone",
    "with_erhua"
  ],
  "_truncate": [
    "max_len",
    "text",
    "query_id",
    "tokens",
    "text2token",
    "token2text"
  ],
  "get_phoneme_labels": [
    "polyphonic_chars"
  ],
  "get_char_phoneme_labels": [
    "polyphonic_chars"
  ],
  "wordize_and_map": [
    "text"
  ],
  "tokenize_and_map": [
    "tokenizer",
    "text"
  ],
  "_load_config": [
    "config_path"
  ],
  "default_config_dict": [],
  "predict": [
    "session",
    "onnx_input",
    "labels"
  ],
  "G2PWOnnxConverter": {
    "__init__": [
      "self",
      "model_dir",
      "style",
      "model_source",
      "enable_non_tradional_chinese"
    ],
    "_pinyin2p": [
      "self",
      "pinyins",
      "words"
    ],
    "_p2id": [
      "self",
      "phonemes"
    ],
    "_convert_bopomofo_to_pinyin": [
      "self",
      "bopomofo"
    ],
    "__call__": [
      "self",
      "sentences"
    ],
    "_prepare_data": [
      "self",
      "sentences"
    ]
  },
  "get_color": [
    "idx"
  ],
  "draw_keypoints": [
    "img",
    "results",
    "visual_thresh",
    "ids"
  ],
  "KptResult": {
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "KptBatchSampler": {
    "PDF_SUFFIX": [],
    "sample": [
      "self",
      "inputs"
    ]
  },
  "KptPredictor": {
    "entities": [],
    "flip_perm": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_format_output": [
      "self",
      "pred"
    ],
    "flip_back": [
      "self",
      "output_flipped",
      "matched_parts"
    ],
    "process": [
      "self",
      "batch_data"
    ],
    "build_topdown_affine": [
      "self",
      "trainsize",
      "use_udp"
    ],
    "build_to_batch": [
      "self"
    ],
    "build_postprocess": [
      "self"
    ]
  },
  "Kpts": [],
  "get_warp_matrix": [
    "theta",
    "size_input",
    "size_dst",
    "size_target"
  ],
  "TopDownAffine": {
    "__init__": [
      "self",
      "input_size",
      "use_udp"
    ],
    "apply": [
      "self",
      "img",
      "center",
      "scale"
    ],
    "__call__": [
      "self",
      "datas"
    ]
  },
  "affine_transform": [
    "pt",
    "t"
  ],
  "transform_preds": [
    "coords",
    "center",
    "scale",
    "output_size"
  ],
  "KptPostProcess": {
    "__init__": [
      "self",
      "use_dark"
    ],
    "apply": [
      "self",
      "heatmap",
      "center",
      "scale"
    ],
    "__call__": [
      "self",
      "batch_outputs",
      "datas"
    ],
    "get_final_preds": [
      "self",
      "heatmaps",
      "center",
      "scale",
      "kernelsize"
    ],
    "get_max_preds": [
      "self",
      "heatmaps"
    ],
    "gaussian_blur": [
      "self",
      "heatmap",
      "kernel"
    ],
    "dark_parse": [
      "self",
      "hm",
      "coord"
    ],
    "dark_postprocess": [
      "self",
      "hm",
      "coords",
      "kernelsize"
    ]
  },
  "InstanceSegResult": {
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "InstanceSegPredictor": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "build_to_batch": [
      "self"
    ],
    "process": [
      "self",
      "batch_data",
      "threshold"
    ],
    "_format_output": [
      "self",
      "pred"
    ],
    "build_postprocess": [
      "self"
    ]
  },
  "extract_masks_from_boxes": [
    "boxes",
    "masks"
  ],
  "InstanceSegPostProcess": {
    "__init__": [
      "self",
      "threshold",
      "labels"
    ],
    "apply": [
      "self",
      "masks",
      "img_size",
      "boxes",
      "class_id",
      "threshold"
    ],
    "__call__": [
      "self",
      "batch_outputs",
      "datas",
      "threshold"
    ]
  },
  "open3d": [],
  "Visualizer3D": {
    "__init__": [
      "self"
    ],
    "boxes_to_lines": [
      "self",
      "box"
    ],
    "draw_results": [
      "self",
      "points",
      "result",
      "score_threshold"
    ]
  },
  "BEV3DDetResult": {
    "__init__": [
      "self",
      "data"
    ],
    "visualize": [
      "self",
      "save_path",
      "show"
    ]
  },
  "BEVDet3DPredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "_format_output": [
      "self",
      "infer_input",
      "outs",
      "img_metas"
    ],
    "process": [
      "self",
      "batch_data"
    ],
    "build_load_img_from_file": [
      "self",
      "load_dim",
      "use_dim",
      "shift_height",
      "use_color"
    ],
    "build_load_points_from_multi_sweeps": [
      "self",
      "sweeps_num",
      "load_dim",
      "use_dim",
      "pad_empty_sweeps",
      "remove_close",
      "test_mode",
      "point_cloud_angle_range"
    ],
    "build_load_multi_view_image_from_files": [
      "self",
      "to_float32",
      "project_pts_to_img_depth",
      "cam_depth_range",
      "constant_std",
      "imread_flag"
    ],
    "build_resize_image": [
      "self",
      "img_scale",
      "multiscale_mode",
      "ratio_range",
      "keep_ratio",
      "bbox_clip_border",
      "backend",
      "override"
    ],
    "build_normalize_image": [
      "self",
      "mean",
      "std",
      "to_rgb"
    ],
    "build_pad_image": [
      "self",
      "size",
      "size_divisor",
      "pad_val"
    ],
    "build_sample_filter_by_key": [
      "self",
      "keys",
      "meta_keys"
    ],
    "build_get_infer_input": [
      "self"
    ],
    "apply": [
      "self",
      "input"
    ]
  },
  "LoadPointsFromFile": {
    "__init__": [
      "self",
      "load_dim",
      "use_dim",
      "shift_height",
      "use_color"
    ],
    "_load_points": [
      "self",
      "pts_filename"
    ],
    "__call__": [
      "self",
      "results"
    ]
  },
  "LoadPointsFromMultiSweeps": {
    "__init__": [
      "self",
      "sweeps_num",
      "load_dim",
      "use_dim",
      "pad_empty_sweeps",
      "remove_close",
      "test_mode",
      "point_cloud_angle_range"
    ],
    "_load_points": [
      "self",
      "pts_filename"
    ],
    "_remove_close": [
      "self",
      "points",
      "radius"
    ],
    "filter_point_by_angle": [
      "self",
      "points"
    ],
    "__call__": [
      "self",
      "results"
    ]
  },
  "LoadMultiViewImageFromFiles": {
    "__init__": [
      "self",
      "to_float32",
      "project_pts_to_img_depth",
      "cam_depth_range",
      "constant_std",
      "imread_flag"
    ],
    "__call__": [
      "self",
      "sample"
    ]
  },
  "ResizeImage": {
    "__init__": [
      "self",
      "img_scale",
      "multiscale_mode",
      "ratio_range",
      "keep_ratio",
      "bbox_clip_border",
      "backend",
      "override"
    ],
    "random_select": [
      "img_scales"
    ],
    "random_sample": [
      "img_scales"
    ],
    "random_sample_ratio": [
      "img_scale",
      "ratio_range"
    ],
    "_random_scale": [
      "self",
      "results"
    ],
    "_resize_img": [
      "self",
      "results"
    ],
    "rescale_size": [
      "self",
      "old_size",
      "scale",
      "return_scale"
    ],
    "imrescale": [
      "self",
      "img",
      "scale",
      "return_scale",
      "interpolation",
      "backend"
    ],
    "imresize": [
      "self",
      "img",
      "size",
      "return_scale",
      "interpolation",
      "out",
      "backend"
    ],
    "_resize_bboxes": [
      "self",
      "results"
    ],
    "_resize_masks": [
      "self",
      "results"
    ],
    "_resize_seg": [
      "self",
      "results"
    ],
    "__call__": [
      "self",
      "results"
    ]
  },
  "PadImage": {
    "__init__": [
      "self",
      "size",
      "size_divisor",
      "pad_val"
    ],
    "impad": [
      "self",
      "img"
    ],
    "impad_to_multiple": [
      "self",
      "img",
      "divisor",
      "pad_val"
    ],
    "_pad_img": [
      "self",
      "results"
    ],
    "_pad_masks": [
      "self",
      "results"
    ],
    "_pad_seg": [
      "self",
      "results"
    ],
    "__call__": [
      "self",
      "results"
    ]
  },
  "SampleFilterByKey": {
    "__init__": [
      "self",
      "keys",
      "meta_keys"
    ],
    "__call__": [
      "self",
      "sample"
    ]
  },
  "GetInferInput": {
    "collate_fn": [
      "self",
      "batch"
    ],
    "__call__": [
      "self",
      "sample"
    ]
  },
  "TSAdResult": {
    "_to_img": [
      "self"
    ],
    "_to_csv": [
      "self"
    ]
  },
  "TSAdPredictor": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data"
    ]
  },
  "GetAnomaly": {
    "__init__": [
      "self",
      "model_threshold",
      "info_params"
    ],
    "__call__": [
      "self",
      "ori_ts_list",
      "pred_list"
    ],
    "getanomaly": [
      "self",
      "ori_ts",
      "pred"
    ]
  },
  "IdentityResult": {
    "__init__": [
      "self",
      "data"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "ImageFeaturePredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data"
    ],
    "build_resize": [
      "self",
      "resize_short",
      "size",
      "backend",
      "interpolation"
    ],
    "build_normalize": [
      "self",
      "mean",
      "std",
      "scale",
      "order",
      "channel_num"
    ],
    "build_to_chw": [
      "self"
    ],
    "build_normalize_features": [
      "self"
    ]
  },
  "NormalizeFeatures": {
    "_normalize": [
      "self",
      "preds"
    ],
    "__call__": [
      "self",
      "preds"
    ]
  },
  "DocVLMResult": {
    "__init__": [
      "self",
      "data"
    ]
  },
  "DocVLMPredictor": {
    "entities": [],
    "model_group": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "_determine_batch_size": [
      "self"
    ],
    "process": [
      "self",
      "data",
      "max_new_tokens",
      "skip_special_tokens",
      "repetition_penalty",
      "temperature",
      "top_p",
      "min_pixels",
      "max_pixels",
      "use_cache"
    ],
    "build_processor": [
      "self"
    ],
    "_format_result_dict": [
      "self",
      "model_preds",
      "src_data"
    ],
    "_infer_dynamic_forward_device": [
      "self",
      "device"
    ],
    "_switch_inputs_to_device": [
      "self",
      "input_dict"
    ],
    "_genai_client_process": [
      "self",
      "data",
      "max_new_tokens",
      "skip_special_tokens",
      "repetition_penalty",
      "temperature",
      "top_p",
      "min_pixels",
      "max_pixels"
    ]
  },
  "Linear": [],
  "ColumnParallelLinear": [],
  "RowParallelLinear": [],
  "ColumnSequenceParallelLinear": [],
  "RowSequenceParallelLinear": [],
  "Qwen2Config": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "seq_length",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_theta",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "use_sliding_window",
      "sliding_window",
      "max_window_layers",
      "attention_dropout",
      "rope_scaling_factor",
      "rope_scaling_type",
      "dpo_config"
    ]
  },
  "get_triangle_upper_mask": [
    "x",
    "mask"
  ],
  "parallel_matmul": [
    "x",
    "y",
    "transpose_y",
    "tensor_parallel_output"
  ],
  "scaled_dot_product_attention": [
    "query_states",
    "config",
    "key_states",
    "value_states",
    "attention_mask",
    "output_attentions",
    "attn_mask_startend_row_indices",
    "training",
    "sequence_parallel",
    "skip_recompute"
  ],
  "is_casual_mask": [
    "attention_mask"
  ],
  "_make_causal_mask": [
    "input_ids_shape",
    "past_key_values_length"
  ],
  "_expand_2d_mask": [
    "mask",
    "dtype",
    "tgt_length"
  ],
  "Qwen2RMSNorm": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen2RotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "base"
    ],
    "_set_cos_sin_cache": [
      "self",
      "seq_len"
    ],
    "forward": [
      "self",
      "x",
      "seq_len"
    ]
  },
  "rotate_half": [
    "x"
  ],
  "apply_rotary_pos_emb": [
    "q",
    "k",
    "cos",
    "sin",
    "position_ids"
  ],
  "Qwen2MLP": {
    "__init__": [
      "self",
      "config",
      "is_shared",
      "skip_recompute_ops"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "repeat_kv": [
    "hidden_states",
    "n_rep"
  ],
  "Qwen2Attention": {
    "__init__": [
      "self",
      "config",
      "layerwise_recompute",
      "skip_recompute_ops"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "past_key_value",
      "attention_mask",
      "output_attentions",
      "use_cache",
      "attn_mask_startend_row_indices"
    ]
  },
  "Qwen2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layerwise_recompute",
      "skip_recompute_ops"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "attention_mask",
      "output_attentions",
      "past_key_value",
      "use_cache",
      "attn_mask_startend_row_indices"
    ]
  },
  "Qwen2PretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "_keys_to_ignore_on_load_unexpected": [],
    "_get_fuse_or_split_param_mappings": [
      "cls",
      "config",
      "is_fuse"
    ]
  },
  "Qwen2Model": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prepare_decoder_attention_mask": [
      "attention_mask",
      "input_shape",
      "past_key_values_length",
      "dtype"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "use_cache",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "attn_mask_startend_row_indices"
    ]
  },
  "Qwen2PretrainingCriterion": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "masked_lm_labels"
    ]
  },
  "Qwen2LMHead": {
    "__init__": [
      "self",
      "config",
      "embedding_weights",
      "transpose_y"
    ],
    "forward": [
      "self",
      "hidden_states",
      "tensor_parallel_output"
    ]
  },
  "Qwen2ForCausalLM": {
    "enable_to_static_method": [],
    "_tied_weights_keys": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "use_cache",
      "past_key_values",
      "attention_mask",
      "inputs_embeds"
    ],
    "_get_model_inputs_spec": [
      "self",
      "dtype"
    ],
    "update_model_kwargs_for_generation": [
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "labels",
      "use_cache",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "attn_mask_startend_row_indices"
    ]
  },
  "Qwen2_5_VLVisionConfig": {
    "model_type": [],
    "base_config_key": [],
    "__init__": [
      "self",
      "depth",
      "hidden_size",
      "hidden_act",
      "intermediate_size",
      "num_heads",
      "in_channels",
      "patch_size",
      "spatial_merge_size",
      "temporal_patch_size",
      "tokens_per_second",
      "window_size",
      "out_hidden_size",
      "fullatt_block_indexes"
    ]
  },
  "Qwen2_5_VLConfig": {
    "model_type": [],
    "sub_configs": [],
    "keys_to_ignore_at_inference": [],
    "base_model_tp_plan": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_theta",
      "use_sliding_window",
      "sliding_window",
      "max_window_layers",
      "attention_dropout",
      "vision_config",
      "rope_scaling"
    ]
  },
  "_compute_default_rope_parameters": [
    "config",
    "device",
    "seq_len"
  ],
  "ROPE_INIT_FUNCTIONS": [],
  "_get_unpad_data": [
    "attention_mask"
  ],
  "Qwen2_5_VLCausalLMOutputWithPast": {},
  "Qwen2_5_VLRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "base",
      "device",
      "scaling_factor",
      "rope_type",
      "config"
    ],
    "_set_cos_sin_cache": [
      "self",
      "seq_len"
    ],
    "_dynamic_frequency_update": [
      "self",
      "position_ids",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "apply_multimodal_rotary_pos_emb": [
    "q",
    "k",
    "cos",
    "sin",
    "mrope_section",
    "unsqueeze_dim"
  ],
  "apply_rotary_pos_emb_vision": [
    "tensor",
    "freqs"
  ],
  "Qwen2_5_VisionRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "Qwen2_5_VisionPatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "temporal_patch_size",
      "in_channels",
      "embed_dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen2_5_VLPatchMerger": {
    "__init__": [
      "self",
      "dim",
      "context_dim",
      "spatial_merge_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2_5_VLMLP": {
    "__init__": [
      "self",
      "config",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "Qwen2_5_VLVisionAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "Qwen2_5_VLVisionFlashAttention2": {
    "__init__": [
      "self",
      "dim",
      "num_heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "Qwen2_5_VLVisionSdpaAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "QWEN2_5_VL_VISION_ATTENTION_CLASSES": [],
  "Qwen2_5_VLVisionBlock": {
    "__init__": [
      "self",
      "config",
      "attn_implementation"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "apply_rotary_emb": [
    "tensor",
    "cos",
    "sin"
  ],
  "apply_rotary_pos_emb_flashatt": [
    "tensor",
    "freqs"
  ],
  "Qwen2_5_VLAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_value",
      "output_attentions",
      "use_cache",
      "cache_position"
    ]
  },
  "Qwen2_5_VLFlashAttention2": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_value",
      "output_attentions",
      "use_cache",
      "cache_position"
    ],
    "_flash_attention_forward": [
      "self",
      "query_states",
      "key_states",
      "value_states",
      "attention_mask",
      "query_length",
      "dropout",
      "softmax_scale"
    ],
    "_unpad_input": [
      "self",
      "query_layer",
      "key_layer",
      "value_layer",
      "attention_mask",
      "query_length"
    ]
  },
  "Qwen2_5_VLSdpaAttention": {
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_value",
      "output_attentions",
      "use_cache",
      "cache_position",
      "position_embeddings"
    ]
  },
  "QWEN2_5_VL_ATTENTION_CLASSES": [],
  "Qwen2_5_VLDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_value",
      "output_attentions",
      "use_cache",
      "cache_position"
    ]
  },
  "Qwen2_5_VLPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "_no_split_modules": [],
    "_skip_keys_device_placement": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "Qwen2_5_VisionTransformerPretrainedModel": {
    "config_class": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "get_window_index": [
      "self",
      "grid_thw"
    ],
    "recompute_training_full": [
      "self",
      "layer_module",
      "hidden_states",
      "cu_seqlens_now",
      "rotary_pos_emb"
    ],
    "forward": [
      "self",
      "hidden_states",
      "grid_thw"
    ]
  },
  "Qwen2_5_VLModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prepare_decoder_attention_mask": [
      "attention_mask",
      "input_shape",
      "past_key_values_length",
      "dtype"
    ],
    "recompute_training_full": [
      "self",
      "layer_module",
      "hidden_states",
      "position_ids",
      "attention_mask",
      "output_attentions",
      "past_key_value",
      "use_cache",
      "cache_position"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "cache_position"
    ]
  },
  "Qwen2_5_VLForConditionalGeneration": {
    "_tied_weights_keys": [],
    "config_class": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config",
      "attn_implementation"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ],
    "get_rope_index": [
      "spatial_merge_size",
      "image_token_id",
      "video_token_id",
      "vision_start_token_id",
      "tokens_per_second",
      "input_ids",
      "image_grid_thw",
      "video_grid_thw",
      "second_per_grid_ts",
      "attention_mask"
    ],
    "update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "vision_forward": [
      "self",
      "input_ids",
      "inputs_embeds",
      "attention_mask",
      "position_ids",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "rope_deltas",
      "second_per_grid_ts"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "rope_deltas",
      "second_per_grid_ts"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "inputs_embeds",
      "cache_position",
      "position_ids",
      "use_cache",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "second_per_grid_ts"
    ]
  },
  "PPDocBee2TransformerPretrainedModel": {
    "layer_idx": [],
    "forward": [
      "self",
      "hidden_states",
      "grid_thw"
    ]
  },
  "PPDocBee2Inference": {
    "__init__": [
      "self",
      "config",
      "attn_implementation"
    ],
    "generate": [
      "self",
      "inputs"
    ]
  },
  "MLPBlock": {
    "__init__": [
      "self",
      "embedding_dim",
      "mlp_dim",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LayerNorm2d": {
    "__init__": [
      "self",
      "num_channels",
      "epsilon"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ImageEncoderViT": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "in_chans",
      "embed_dim",
      "depth",
      "num_heads",
      "mlp_ratio",
      "out_chans",
      "qkv_bias",
      "norm_layer",
      "act_layer",
      "use_abs_pos",
      "use_rel_pos",
      "rel_pos_zero_init",
      "window_size",
      "global_attn_indexes"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Block": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "norm_layer",
      "act_layer",
      "use_rel_pos",
      "rel_pos_zero_init",
      "window_size",
      "input_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Attention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "qkv_bias",
      "use_rel_pos",
      "rel_pos_zero_init",
      "input_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "window_partition": [
    "x",
    "window_size"
  ],
  "window_unpartition": [
    "windows",
    "window_size",
    "pad_hw",
    "hw"
  ],
  "get_rel_pos": [
    "q_size",
    "k_size",
    "rel_pos"
  ],
  "add_decomposed_rel_pos": [
    "attn",
    "q",
    "rel_pos_h",
    "rel_pos_w",
    "q_size",
    "k_size"
  ],
  "PatchEmbed": {
    "__init__": [
      "self",
      "kernel_size",
      "stride",
      "padding",
      "in_chans",
      "embed_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DEFAULT_IMAGE_TOKEN": [],
  "DEFAULT_IMAGE_PATCH_TOKEN": [],
  "DEFAULT_IM_START_TOKEN": [],
  "DEFAULT_IM_END_TOKEN": [],
  "GOTConfig": {
    "model_type": []
  },
  "GOTQwenModel": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "images",
      "return_dict"
    ]
  },
  "GOTQwenForCausalLM": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_model": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "images",
      "return_dict"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "inputs_embeds"
    ]
  },
  "PPChart2TableInference": {
    "get_transpose_weight_keys": [
      "self"
    ],
    "generate": [
      "self",
      "inputs"
    ]
  },
  "_IS_NPU": [],
  "Qwen2VLVisionConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "depth",
      "embed_dim",
      "hidden_size",
      "hidden_act",
      "mlp_ratio",
      "num_heads",
      "in_channels",
      "patch_size",
      "spatial_merge_size",
      "temporal_patch_size",
      "attn_implementation"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "Qwen2VLConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_theta",
      "use_sliding_window",
      "sliding_window",
      "max_window_layers",
      "attention_dropout",
      "vision_config",
      "rope_scaling"
    ]
  },
  "Qwen2VLCausalLMOutputWithPast": {},
  "Qwen2VLRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_position_embeddings",
      "base",
      "device",
      "scaling_factor",
      "rope_type",
      "config"
    ],
    "_set_cos_sin_cache": [
      "self",
      "seq_len"
    ],
    "_dynamic_frequency_update": [
      "self",
      "position_ids",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "VisionRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "PatchMerger": {
    "__init__": [
      "self",
      "dim",
      "context_dim",
      "spatial_merge_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "VisionMlp": {
    "__init__": [
      "self",
      "dim",
      "hidden_dim",
      "hidden_act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "VisionAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "VisionFlashAttention2": {
    "__init__": [
      "self",
      "dim",
      "num_heads"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "create_attention_module": [
    "config",
    "module_type",
    "layer_idx"
  ],
  "Qwen2VLVisionBlock": {
    "__init__": [
      "self",
      "config",
      "attn_implementation"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "_prepare_4d_causal_attention_mask_with_cache_position": [
    "attention_mask",
    "sequence_length",
    "target_length",
    "dtype",
    "min_dtype",
    "cache_position",
    "batch_size"
  ],
  "Qwen2VLAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_value",
      "output_attentions",
      "use_cache",
      "cache_position"
    ]
  },
  "Qwen2VLFlashAttention2": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_value",
      "output_attentions",
      "use_cache",
      "cache_position"
    ],
    "_flash_attention_forward": [
      "self",
      "query_states",
      "key_states",
      "value_states",
      "attention_mask",
      "query_length",
      "dropout",
      "softmax_scale"
    ],
    "_unpad_input": [
      "self",
      "query_layer",
      "key_layer",
      "value_layer",
      "attention_mask",
      "query_length"
    ]
  },
  "Qwen2VLDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_value",
      "output_attentions",
      "use_cache",
      "cache_position"
    ]
  },
  "Qwen2VLPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "_no_split_modules": [],
    "_skip_keys_device_placement": [],
    "_init_weights": [
      "self",
      "layer"
    ]
  },
  "Qwen2VisionTransformerPretrainedModel": {
    "config_class": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_dtype": [
      "self"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "recompute_training_full": [
      "self",
      "layer_module",
      "hidden_states",
      "cu_seqlens_now",
      "rotary_pos_emb"
    ],
    "forward": [
      "self",
      "hidden_states",
      "grid_thw"
    ]
  },
  "Qwen2VLModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "_prepare_decoder_attention_mask": [
      "attention_mask",
      "input_shape",
      "past_key_values_length",
      "dtype"
    ],
    "recompute_training_full": [
      "self",
      "layer_module",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_value",
      "output_attentions",
      "use_cache",
      "cache_position"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "cache_position"
    ]
  },
  "Qwen2VLForConditionalGeneration": {
    "_tied_weights_keys": [],
    "__init__": [
      "self",
      "config",
      "attn_implementation"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "get_rope_index": [
      "spatial_merge_size",
      "image_token_id",
      "video_token_id",
      "vision_start_token_id",
      "input_ids",
      "image_grid_thw",
      "video_grid_thw",
      "attention_mask"
    ],
    "update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "rope_deltas"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "inputs_embeds",
      "cache_position",
      "position_ids",
      "use_cache",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw"
    ],
    "gme_qwen2_vl_forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "rope_deltas"
    ]
  },
  "PPDocBeeInference": {
    "generate": [
      "self",
      "inputs"
    ]
  },
  "PaddleOCRVisionConfig": {
    "model_type": [],
    "base_config_key": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "hidden_act",
      "layer_norm_eps",
      "attention_dropout",
      "spatial_merge_size",
      "temporal_patch_size",
      "tokens_per_second"
    ]
  },
  "PaddleOCRVLConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "sub_configs": [],
    "base_model_tp_plan": [],
    "base_model_pp_plan": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "max_position_embeddings",
      "num_hidden_layers",
      "num_attention_heads",
      "image_token_id",
      "video_token_id",
      "vision_start_token_id",
      "rope_scaling",
      "rms_norm_eps",
      "use_cache",
      "use_flash_attention",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "head_dim",
      "hidden_act",
      "use_bias",
      "rope_theta",
      "weight_share_add_bias",
      "ignored_index",
      "attention_probs_dropout_prob",
      "hidden_dropout_prob",
      "compression_ratio",
      "num_key_value_heads",
      "max_sequence_length",
      "tie_word_embeddings",
      "vision_config"
    ]
  },
  "_AllToAll": {
    "forward": [
      "ctx",
      "input",
      "group",
      "output_split_sizes",
      "input_split_sizes"
    ],
    "backward": [
      "ctx"
    ]
  },
  "AllGatherVarlenOpV2": {
    "forward": [
      "ctx",
      "input",
      "indices",
      "axis",
      "group"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "SliceVarlenOp": {
    "forward": [
      "ctx",
      "input",
      "indices",
      "group"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "ScatterOp": {
    "forward": [
      "ctx",
      "input",
      "axis",
      "group"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "SliceOp": [],
  "GatherOp": {
    "forward": [
      "ctx",
      "input",
      "axis",
      "group"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "AllGatherOp": {
    "forward": [
      "ctx",
      "input",
      "group"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "AllGatherVarlenOp": {
    "forward": [
      "ctx",
      "input",
      "group"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "sequence_parallel_sparse_mask_labels": [
    "labels",
    "ignore_label"
  ],
  "mark_as_sequence_parallel_parameter": [
    "parameter"
  ],
  "MPScale": {
    "forward": [
      "ctx",
      "x",
      "mp_degree"
    ],
    "backward": [
      "ctx",
      "dout"
    ]
  },
  "Projector": {
    "__init__": [
      "self",
      "text_config",
      "vision_config"
    ],
    "forward": [
      "self",
      "image_features",
      "image_grid_thw"
    ]
  },
  "calc_lm_head_logits": [
    "config",
    "hidden_states",
    "weight",
    "bias",
    "tensor_parallel_output",
    "training"
  ],
  "subbatch": [
    "f",
    "arg_idx",
    "axis",
    "bs",
    "out_idx",
    "use_recompute",
    "same_arg_idx"
  ],
  "_rotate_half": [
    "x"
  ],
  "_apply_multimodal_rotary_pos_emb": [
    "q",
    "k",
    "cos",
    "sin",
    "mrope_section",
    "unsqueeze_dim"
  ],
  "FusedDropoutImpl": {
    "__init__": [
      "self",
      "prob",
      "mode"
    ],
    "forward": [
      "self",
      "x",
      "y"
    ]
  },
  "RMSNorm": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LayerNorm": {
    "__init__": [
      "self",
      "config"
    ]
  },
  "KeyeRotaryEmbedding": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "Ernie4_5MLP": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Ernie4_5Attention": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "set_attn_func": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_embeddings",
      "past_key_value",
      "attention_mask",
      "attn_mask_start_row_indices",
      "position_ids",
      "output_attentions",
      "use_cache",
      "token_type_ids"
    ],
    "_flash_attention_wrapper": [
      "self",
      "q",
      "k",
      "v",
      "attention_mask",
      "attn_mask_start_row_indices",
      "seq_length"
    ],
    "core_attn": [
      "self",
      "q",
      "k",
      "v",
      "attention_mask",
      "attn_mask_start_row_indices",
      "seq_length"
    ],
    "rope_attn": [
      "self",
      "mix_layer",
      "query_states",
      "key_states",
      "value_states",
      "position_embeddings",
      "attention_mask",
      "position_ids",
      "output_attentions",
      "past_key_value",
      "use_cache",
      "attn_mask_start_row_indices"
    ]
  },
  "FusedHeadParallelCrossEntropy": {
    "forward": [
      "ctx",
      "hidden_states",
      "weight",
      "bias",
      "labels",
      "tensor_parallel_degree",
      "mp_group",
      "ignore_index",
      "seq_chunk_size",
      "transpose_y",
      "fuse_linear",
      "training"
    ],
    "backward": [
      "ctx",
      "loss_all_grad",
      "labels_all_grad"
    ]
  },
  "ErniePretrainingCriterion": {
    "__init__": [
      "self",
      "config",
      "return_tuple"
    ],
    "forward": [
      "self",
      "prediction_scores",
      "masked_lm_labels",
      "loss_mask"
    ],
    "forward_impl_with_fused_head_loss_fn": [
      "self",
      "masked_lm_labels",
      "loss_mask",
      "hidden_states",
      "outlinear_weight",
      "outlinear_bias"
    ],
    "forward_impl_with_calc_logits": [
      "self",
      "masked_lm_labels",
      "loss_mask",
      "hidden_states",
      "outlinear_weight",
      "outlinear_bias"
    ],
    "loss_impl": [
      "self",
      "prediction_scores",
      "masked_lm_labels"
    ],
    "forward_impl": [
      "self",
      "prediction_scores",
      "masked_lm_labels",
      "loss_mask"
    ]
  },
  "Ernie4_5LMHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "tensor_parallel_output"
    ]
  },
  "Ernie4_5DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_embeddings",
      "attention_mask",
      "attn_mask_start_row_indices",
      "position_ids",
      "token_type_ids",
      "output_attentions",
      "past_key_value",
      "use_cache"
    ],
    "model_parallel_dropout": [
      "self"
    ]
  },
  "Ernie4_5PretrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "_get_tensor_parallel_mappings": [
      "cls",
      "config",
      "is_split"
    ]
  },
  "Ernie4_5Model": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "recompute_training": [
      "self",
      "layer_module",
      "hidden_states",
      "position_embeddings",
      "attention_mask",
      "attn_mask_start_row_indices",
      "position_ids",
      "token_type_ids",
      "output_attentions",
      "past_key_value",
      "use_cache"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "token_type_ids",
      "attention_mask",
      "attn_mask_start_row_indices",
      "inputs_embeds",
      "use_cache",
      "past_key_values",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_update_causal_mask": [
      "self",
      "attention_mask",
      "input_tensor",
      "past_key_values",
      "output_attentions"
    ],
    "_prepare_4d_causal_attention_mask_with_cache_position": [
      "attention_mask",
      "sequence_length",
      "target_length",
      "dtype",
      "cache_position",
      "batch_size"
    ]
  },
  "PaddleOCRVLCausalLMOutputWithPast": {},
  "PaddleOCRVLForConditionalGeneration": {
    "_tied_weights_keys": [],
    "config_class": [],
    "_no_split_modules": [],
    "_keep_in_fp32_modules": [],
    "base_model_prefix": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "get_rope_index": [
      "self",
      "input_ids",
      "image_grid_thw",
      "video_grid_thw",
      "second_per_grid_ts",
      "attention_mask"
    ],
    "prepare_attention_mask_for_generation": [
      "self",
      "input_ids",
      "pad_token_id",
      "eos_token_id"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "use_cache",
      "past_key_values",
      "inputs_embeds",
      "pixel_values",
      "pixel_values_videos",
      "position_ids"
    ],
    "update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "get_transpose_weight_keys": [
      "self"
    ],
    "get_hf_state_dict": [
      "self"
    ],
    "set_hf_state_dict": [
      "self",
      "state_dict"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "rope_deltas",
      "second_per_grid_ts"
    ],
    "generate": [
      "self",
      "inputs"
    ],
    "_get_image_nums_and_video_nums": [
      "self",
      "input_ids"
    ]
  },
  "_ensure_cos_sin_dim": [
    "cos",
    "sin",
    "dim_needed"
  ],
  "eager_attention_forward": [
    "module",
    "query",
    "key",
    "value",
    "attention_mask",
    "scaling",
    "dropout"
  ],
  "SiglipAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions",
      "cu_seqlens",
      "rope_emb"
    ]
  },
  "SiglipVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "interpolate_pos_encoding": [
      "self",
      "embeddings",
      "height",
      "width",
      "is_after_patchify"
    ],
    "flatten_list": [
      "image_grid_thw"
    ],
    "fetch_position_embedding_lfu_cache": [
      "self",
      "embeddings",
      "h",
      "w",
      "max_cache"
    ],
    "forward": [
      "self",
      "pixel_values",
      "position_ids",
      "image_grid_thw",
      "interpolate_pos_encoding"
    ]
  },
  "SiglipMLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SiglipEncoderLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions",
      "cu_seqlens",
      "rope_emb"
    ]
  },
  "SigLIPRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta"
    ],
    "rope_init": [
      "self"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "SiglipEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "flatten_list": [
      "image_grid_thw"
    ],
    "build_window_index": [
      "self",
      "image_grid",
      "window_size"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "cu_seqlens",
      "image_grid_thw",
      "height_position_ids",
      "width_position_ids",
      "use_rope",
      "window_size",
      "vision_or_text"
    ]
  },
  "SiglipMultiheadAttentionPoolingHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_state",
      "key_padding_mask"
    ]
  },
  "SiglipVisionTransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "interpolate_pos_encoding",
      "attention_mask",
      "sample_indices",
      "image_indices",
      "position_ids",
      "height_position_ids",
      "width_position_ids",
      "cu_seqlens",
      "padding_mask",
      "vision_return_embed_list",
      "image_grid_thw",
      "return_pooler_output",
      "use_rope",
      "window_size"
    ]
  },
  "SiglipPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "_supports_flash_attn_2": [],
    "_supports_sdpa": []
  },
  "SiglipVisionModel": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "sample_indices",
      "output_attentions",
      "output_hidden_states",
      "interpolate_pos_encoding",
      "position_ids",
      "vision_return_embed_list",
      "image_grid_thw",
      "cu_seqlens",
      "return_pooler_output",
      "use_rope",
      "window_size"
    ]
  },
  "get_hcg": [],
  "_parallel_matmul": [
    "x",
    "y",
    "bias",
    "transpose_y",
    "tensor_parallel_degree",
    "tensor_parallel_output",
    "fuse_linear"
  ],
  "scatter_axis": [
    "input",
    "group",
    "axis"
  ],
  "mp_slice": [
    "x",
    "indices",
    "group",
    "axis"
  ],
  "all_gather_varlen": [
    "input",
    "indices",
    "group",
    "axis",
    "sync_op"
  ],
  "ReduceScatterGroupOp": {
    "forward": [
      "ctx",
      "input",
      "group"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "AllGatherGroupOp": {
    "forward": [
      "ctx",
      "input",
      "group"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "RRColumnSequenceParallelLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "weight_attr",
      "has_bias",
      "gather_output",
      "fuse_matmul_bias",
      "mp_group",
      "use_rr",
      "name"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RRRowSequenceParallelLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "weight_attr",
      "has_bias",
      "input_is_parallel",
      "fuse_matmul_bias",
      "mp_group",
      "use_rr",
      "name"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "async_loader": [],
  "get_async_loader": [],
  "hack_offload_wait": [
    "task"
  ],
  "hack_reload_wait": [
    "task"
  ],
  "all_gather_group": [
    "input",
    "group",
    "axis"
  ],
  "reduce_scatter_group": [
    "input",
    "group"
  ],
  "_is_second_fwd": [],
  "is_second_fwd": [],
  "set_second_fwd": [
    "value"
  ],
  "CustomSavedTensorsHooks": {
    "__init__": [
      "self",
      "pack_hook",
      "unpack_hook"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "create_skip_config_for_refined_recompute": [
    "layer_idx",
    "config"
  ],
  "RefinedRcomputeQueue": {
    "__init__": [
      "self"
    ],
    "update": [
      "self",
      "queue",
      "queue_name"
    ],
    "check": [
      "self"
    ]
  },
  "global_rr_queue_log": [],
  "_NoopSaveInputs": {
    "forward": [
      "ctx"
    ],
    "backward": [
      "ctx"
    ]
  },
  "RefinedRecomputeFunction": {
    "__init__": [
      "self"
    ],
    "post_init": [
      "self",
      "function",
      "function_name"
    ],
    "__call__": [
      "self",
      "function"
    ],
    "forward": [
      "self"
    ],
    "_first_fwd": [
      "self"
    ],
    "_second_fwd": [
      "self"
    ],
    "parse_to_args": [
      "self"
    ]
  },
  "fusion_flash_attention": [
    "q",
    "k",
    "v",
    "training_mode",
    "attention_probs_dropout_prob",
    "use_sparse_flash_attn",
    "attention_mask",
    "attn_mask_start_row_indices",
    "seq_length",
    "use_var_len_flash_attn",
    "rr_flash_attn"
  ],
  "npu_combining": [
    "x",
    "combine_weights",
    "scatter_index",
    "hard_gate"
  ],
  "npu_cal_aux_loss_func": [
    "gate_prob",
    "dispatch_mask",
    "tokens_mask",
    "dispatch_tokens_mask",
    "num_experts",
    "use_group",
    "moe_k",
    "global_aux_loss",
    "rank",
    "group",
    "clip_min"
  ],
  "_fusion_flash_attention": [
    "q",
    "k",
    "v",
    "training_mode",
    "attention_probs_dropout_prob",
    "use_sparse_flash_attn",
    "attention_mask",
    "attn_mask_start_row_indices",
    "rr_flash_attn"
  ],
  "_gen_from_sparse_attn_mask_indices": [
    "attn_mask_start_row_indices",
    "dtype"
  ],
  "OPENAI_CLIP_MEAN": [],
  "OPENAI_CLIP_STD": [],
  "IMAGE_FACTOR": [],
  "MIN_PIXELS": [],
  "MAX_PIXELS": [],
  "MAX_RATIO": [],
  "is_scaled_image": [
    "image"
  ],
  "Qwen2_5_VLProcessor": {
    "__init__": [
      "self",
      "image_processor",
      "tokenizer"
    ],
    "preprocess": [
      "self",
      "images",
      "text",
      "padding",
      "truncation",
      "max_length",
      "return_tensors"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ]
  },
  "Qwen2_5_VLImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "min_pixels",
      "max_pixels",
      "patch_size",
      "temporal_patch_size",
      "merge_size"
    ],
    "_preprocess": [
      "self",
      "images",
      "do_resize",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "data_format",
      "input_data_format"
    ],
    "__call__": [
      "self",
      "images",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "return_tensors",
      "data_format",
      "input_data_format"
    ]
  },
  "PPDocBee2Processor": {
    "preprocess": [
      "self",
      "input_dicts"
    ],
    "postprocess": [
      "self",
      "model_pred"
    ]
  },
  "is_paddle_tensor": [
    "tensor"
  ],
  "to_numpy": [
    "obj"
  ],
  "ImageInput": [],
  "ChannelDimension": {
    "FIRST": [],
    "LAST": []
  },
  "is_valid_image": [
    "img"
  ],
  "valid_images": [
    "imgs"
  ],
  "is_batched": [
    "img"
  ],
  "make_list_of_images": [
    "images",
    "expected_ndims"
  ],
  "to_numpy_array": [
    "img"
  ],
  "infer_channel_dimension_format": [
    "image"
  ],
  "get_channel_dimension_axis": [
    "image"
  ],
  "get_image_size": [
    "image",
    "channel_dim"
  ],
  "convert_to_rgb": [
    "image"
  ],
  "to_channel_dimension_format": [
    "image",
    "channel_dim",
    "input_channel_dim"
  ],
  "BatchFeature": {
    "__init__": [
      "self",
      "data",
      "tensor_type"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "__getattr__": [
      "self",
      "item"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "keys": [
      "self"
    ],
    "values": [
      "self"
    ],
    "items": [
      "self"
    ],
    "convert_to_tensors": [
      "self",
      "tensor_type"
    ]
  },
  "extract_vision_info": [
    "conversations"
  ],
  "process_vision_info": [
    "conversations"
  ],
  "fetch_image": [
    "ele",
    "size_factor",
    "min_pixels",
    "max_pixels",
    "max_ratio"
  ],
  "round_by_factor": [
    "number",
    "factor"
  ],
  "ceil_by_factor": [
    "number",
    "factor"
  ],
  "floor_by_factor": [
    "number",
    "factor"
  ],
  "smart_resize": [
    "height",
    "width",
    "factor",
    "min_pixels",
    "max_pixels",
    "max_ratio"
  ],
  "make_batched_images": [
    "images"
  ],
  "MEAN": [],
  "STD": [],
  "GOTImageProcessor": {
    "__init__": [
      "self",
      "image_size"
    ],
    "__call__": [
      "self",
      "image"
    ]
  },
  "PPChart2TableProcessor": {
    "__init__": [
      "self",
      "image_processor",
      "tokenizer",
      "dtype"
    ],
    "preprocess": [
      "self",
      "image"
    ],
    "postprocess": [
      "self",
      "model_pred"
    ],
    "_load_image": [
      "self",
      "image_file"
    ]
  },
  "Qwen2VLProcessor": {
    "__init__": [
      "self",
      "image_processor",
      "tokenizer"
    ],
    "preprocess": [
      "self",
      "images",
      "text",
      "padding",
      "truncation",
      "max_length",
      "return_tensors"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ]
  },
  "Qwen2VLImageProcessor": {
    "__init__": [
      "self",
      "do_resize",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "min_pixels",
      "max_pixels",
      "patch_size",
      "temporal_patch_size",
      "merge_size"
    ],
    "_preprocess": [
      "self",
      "images",
      "do_resize",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "data_format",
      "input_data_format"
    ],
    "preprocess": [
      "self",
      "images",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "return_tensors",
      "data_format",
      "input_data_format"
    ],
    "__call__": [
      "self",
      "images"
    ]
  },
  "PPDocBeeProcessor": {
    "preprocess": [
      "self",
      "input_dicts"
    ],
    "postprocess": [
      "self",
      "model_pred"
    ]
  },
  "PaddleOCRVLProcessor": {
    "_DEFAULT_TEXT_KWARGS": [],
    "_DEFAULT_VIDEO_KWARGS": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer"
    ],
    "preprocess": [
      "self",
      "input_dicts",
      "min_pixels",
      "max_pixels"
    ],
    "postprocess": [
      "self",
      "model_pred"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "model_input_names": [
      "self"
    ]
  },
  "_OPENAI_CLIP_MEAN": [],
  "_OPENAI_CLIP_STD": [],
  "adjust_size": [
    "size",
    "patch_size"
  ],
  "SiglipImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "min_pixels",
      "max_pixels",
      "patch_size",
      "temporal_patch_size",
      "merge_size"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_dir"
    ],
    "_preprocess": [
      "self",
      "images",
      "size",
      "do_resize",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb"
    ],
    "__call__": [
      "self",
      "images",
      "videos",
      "do_resize",
      "size",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "return_tensors"
    ]
  },
  "DetVideoResult": {
    "_to_video": [
      "self"
    ],
    "_get_font_colormap": [
      "self",
      "color_index"
    ]
  },
  "VideoDetPredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self",
      "nms_thresh",
      "score_thresh"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data",
      "nms_thresh",
      "score_thresh"
    ],
    "build_readvideo": [
      "self",
      "num_seg"
    ],
    "build_resize": [
      "self",
      "target_size"
    ],
    "build_image2array": [
      "self",
      "data_format"
    ],
    "build_normalize": [
      "self",
      "scale"
    ],
    "build_postprocess": [
      "self",
      "nms_thresh",
      "score_thresh",
      "label_list"
    ]
  },
  "ResizeVideo": {
    "__init__": [
      "self",
      "target_size"
    ],
    "resize": [
      "self",
      "video"
    ],
    "__call__": [
      "self",
      "videos"
    ]
  },
  "Image2Array": {
    "__init__": [
      "self",
      "data_format"
    ],
    "img2array": [
      "self",
      "video"
    ],
    "__call__": [
      "self",
      "videos"
    ]
  },
  "NormalizeVideo": {
    "__init__": [
      "self",
      "scale"
    ],
    "normalize_video": [
      "self",
      "video"
    ],
    "__call__": [
      "self",
      "videos"
    ]
  },
  "convert2cpu": [
    "gpu_matrix"
  ],
  "convert2cpu_long": [
    "gpu_matrix"
  ],
  "get_region_boxes": [
    "output",
    "conf_thresh",
    "num_classes",
    "anchors",
    "num_anchors",
    "only_objectness"
  ],
  "nms": [
    "boxes",
    "nms_thresh"
  ],
  "bbox_iou": [
    "box1",
    "box2",
    "x1y1x2y2"
  ],
  "DetVideoPostProcess": {
    "__init__": [
      "self",
      "label_list"
    ],
    "postprocess": [
      "self",
      "pred",
      "nms_thresh",
      "score_thresh"
    ],
    "__call__": [
      "self",
      "preds",
      "nms_thresh",
      "score_thresh"
    ]
  },
  "TopkVideoResult": {
    "_to_video": [
      "self"
    ],
    "_get_font_colormap": [
      "self",
      "color_index"
    ]
  },
  "VideoClasPredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self",
      "topk"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data",
      "topk"
    ],
    "build_readvideo": [
      "self",
      "num_seg",
      "target_size",
      "seg_len",
      "sample_type"
    ],
    "build_scale": [
      "self",
      "short_size"
    ],
    "build_center_crop": [
      "self",
      "target_size"
    ],
    "build_image2array": [
      "self",
      "data_format"
    ],
    "build_normalize": [
      "self",
      "mean",
      "std"
    ],
    "build_topk": [
      "self",
      "topk",
      "label_list"
    ],
    "foo": [
      "self"
    ]
  },
  "Scale": {
    "__init__": [
      "self",
      "short_size",
      "fixed_ratio",
      "keep_ratio",
      "do_round"
    ],
    "scale": [
      "self",
      "video"
    ],
    "__call__": [
      "self",
      "videos"
    ]
  },
  "CenterCrop": {
    "__init__": [
      "self",
      "target_size",
      "do_round"
    ],
    "center_crop": [
      "self",
      "imgs"
    ],
    "__call__": [
      "self",
      "videos"
    ]
  },
  "VideoClasTopk": {
    "__init__": [
      "self",
      "class_ids"
    ],
    "softmax": [
      "self",
      "data"
    ],
    "_parse_class_id_map": [
      "self",
      "class_ids"
    ],
    "__call__": [
      "self",
      "preds",
      "topk"
    ]
  },
  "PredictionWrap": {
    "__init__": [
      "self",
      "data",
      "num"
    ],
    "get_by_idx": [
      "self",
      "idx"
    ]
  },
  "BasePredictor": {
    "MODEL_FILE_PREFIX": [],
    "__is_base": [],
    "__init__": [
      "self",
      "model_dir",
      "config"
    ],
    "config_path": [
      "self"
    ],
    "model_name": [
      "self"
    ],
    "pp_option": [
      "self"
    ],
    "hpi_config": [
      "self"
    ],
    "use_hpip": [
      "self"
    ],
    "genai_config": [
      "self"
    ],
    "__call__": [
      "self",
      "input",
      "batch_size"
    ],
    "set_predictor": [
      "self",
      "batch_size"
    ],
    "get_hpi_info": [
      "self"
    ],
    "create_static_infer": [
      "self"
    ],
    "apply": [
      "self",
      "input"
    ],
    "process": [
      "self",
      "batch_data"
    ],
    "close": [
      "self"
    ],
    "get_config_path": [
      "cls",
      "model_dir"
    ],
    "load_config": [
      "cls",
      "model_dir"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_prepare_pp_option": [
      "self",
      "pp_option",
      "device"
    ],
    "_prepare_hpi_config": [
      "self",
      "hpi_config",
      "device"
    ],
    "_get_device_info": [
      "self",
      "device"
    ]
  },
  "DetResult": {
    "_to_img": [
      "self"
    ],
    "_to_str": [
      "self"
    ],
    "_to_json": [
      "self"
    ]
  },
  "DetPredictor": {
    "entities": [],
    "_FUNC_MAP": [],
    "register": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "_format_output": [
      "self",
      "pred"
    ],
    "process": [
      "self",
      "batch_data",
      "threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode"
    ],
    "build_resize": [
      "self",
      "target_size",
      "keep_ratio",
      "interp"
    ],
    "build_normalize": [
      "self",
      "norm_type",
      "mean",
      "std",
      "is_scale"
    ],
    "build_to_chw": [
      "self"
    ],
    "build_pad": [
      "self",
      "fill_value",
      "size"
    ],
    "build_pad_stride": [
      "self",
      "stride"
    ],
    "build_warp_affine": [
      "self",
      "input_h",
      "input_w",
      "keep_res"
    ],
    "build_to_batch": [
      "self"
    ],
    "build_postprocess": [
      "self"
    ]
  },
  "DetPad": {
    "__init__": [
      "self",
      "size",
      "fill_value"
    ],
    "apply": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "datas"
    ]
  },
  "PadStride": {
    "__init__": [
      "self",
      "stride"
    ],
    "apply": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "datas"
    ]
  },
  "rotate_point": [
    "pt",
    "angle_rad"
  ],
  "_get_3rd_point": [
    "a",
    "b"
  ],
  "get_affine_transform": [
    "center",
    "input_size",
    "rot",
    "output_size",
    "shift",
    "inv"
  ],
  "WarpAffine": {
    "__init__": [
      "self",
      "keep_res",
      "pad",
      "input_h",
      "input_w",
      "scale",
      "shift",
      "down_ratio"
    ],
    "apply": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "datas"
    ]
  },
  "restructured_rotated_boxes": [
    "boxes",
    "labels",
    "img_size"
  ],
  "iou": [
    "box1",
    "box2"
  ],
  "is_contained": [
    "box1",
    "box2"
  ],
  "check_containment": [
    "boxes",
    "formula_index",
    "category_index",
    "mode"
  ],
  "DetPostProcess": {
    "__init__": [
      "self",
      "labels"
    ],
    "apply": [
      "self",
      "boxes",
      "img_size",
      "threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode"
    ],
    "__call__": [
      "self",
      "batch_outputs",
      "datas",
      "threshold",
      "layout_nms",
      "layout_unclip_ratio",
      "layout_merge_bboxes_mode"
    ]
  },
  "DETRPostProcess": {
    "__shared__": [],
    "__inject__": [],
    "__init__": [
      "self",
      "num_classes",
      "num_top_queries",
      "dual_queries",
      "dual_groups",
      "use_focal_loss",
      "with_mask",
      "mask_stride",
      "mask_threshold",
      "use_avg_mask_score",
      "bbox_decode_type"
    ],
    "_mask_postprocess": [
      "self",
      "mask_pred",
      "score_pred"
    ],
    "__call__": [
      "self",
      "head_out",
      "im_shape",
      "scale_factor",
      "pad_shape"
    ]
  },
  "RTDETRConfig": {
    "__init__": [
      "self",
      "backbone",
      "HybridEncoder",
      "RTDETRTransformer",
      "DINOHead",
      "DETRPostProcess"
    ]
  },
  "RTDETR": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "inputs"
    ],
    "get_transpose_weight_keys": [
      "self"
    ]
  },
  "TSFcResult": {
    "_to_img": [
      "self"
    ],
    "_to_csv": [
      "self"
    ]
  },
  "TSFcPredictor": {
    "entities": [],
    "__init__": [
      "self"
    ],
    "_build_batch_sampler": [
      "self"
    ],
    "_get_result_class": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "process": [
      "self",
      "batch_data"
    ]
  },
  "TSDeNormalize": {
    "__init__": [
      "self",
      "scale_path",
      "params_info"
    ],
    "__call__": [
      "self",
      "preds_list"
    ],
    "tsdenorm": [
      "self",
      "pred"
    ]
  },
  "ArraytoTS": {
    "__init__": [
      "self",
      "info_params"
    ],
    "__call__": [
      "self",
      "ori_ts_list",
      "pred_list"
    ],
    "arraytots": [
      "self",
      "ori_ts",
      "pred"
    ]
  },
  "MODELS": [],
  "MLClsTrainer": {
    "entities": [],
    "dump_label_dict": [
      "self",
      "src_label_dict_path"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "MLClsEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "MLClsExportor": {
    "entities": []
  },
  "MLClsDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "check_src_dataset": [
    "root_dir",
    "dataset_type"
  ],
  "convert": [
    "dataset_type",
    "input_dir"
  ],
  "convert_coco_dataset": [
    "root_dir"
  ],
  "coco2multilabels": [
    "src_img_dir",
    "src_anno_path",
    "root_dir"
  ],
  "check": [
    "dataset_dir",
    "output",
    "sample_num"
  ],
  "deep_analyse": [
    "dataset_path",
    "output"
  ],
  "split_dataset": [
    "root_dir",
    "train_rate",
    "val_rate"
  ],
  "draw_multi_label": [
    "image",
    "label",
    "label_map_dict"
  ],
  "TextRecTrainer": {
    "entities": [],
    "dump_label_dict": [
      "self",
      "src_label_dict_path"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "TextRecEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "TextRecExportor": {
    "entities": []
  },
  "TextRecDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "convert_pkl_dataset": [
    "root_dir"
  ],
  "txt2pickle": [
    "images",
    "equations",
    "save_dir"
  ],
  "simple_analyse": [
    "dataset_path",
    "images_dict"
  ],
  "TableRecTrainer": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "TableRecEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "TableRecExportor": {
    "entities": []
  },
  "TableRecDatasetChecker": {
    "entities": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "UadTrainer": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "UadEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_config_path": [
      "self",
      "weight_path"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "UadExportor": {
    "entities": []
  },
  "UadDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "convert_dataset": [
    "dataset_type",
    "input_dir"
  ],
  "convert_labelme_dataset": [
    "input_dir"
  ],
  "shape2label": [
    "img_size",
    "shapes",
    "class_name_mapping"
  ],
  "polygon2mask": [
    "img_size",
    "points"
  ],
  "save_item_to_txt": [
    "items",
    "file_path"
  ],
  "save_training_txt": [
    "cls_root",
    "mode",
    "cat"
  ],
  "check_old_txt": [
    "cls_pth",
    "mode"
  ],
  "convert_mvtec_dataset": [
    "input_dir"
  ],
  "check_dataset": [
    "dataset_dir",
    "output",
    "sample_num"
  ],
  "anaylse_dataset": [
    "dataset_dir",
    "output"
  ],
  "CURVE_MODELS": [],
  "TextDetTrainer": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "TextDetEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "TextDetExportor": {
    "entities": []
  },
  "TextDetDatasetChecker": {
    "entities": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "show_label_img": [
    "img_path",
    "dt_boxes"
  ],
  "get_files": [
    "input_dir",
    "format"
  ],
  "get_labels_files": [
    "input_dir",
    "format"
  ],
  "FormulaRecTrainer": {
    "entities": [],
    "dump_label_dict": [
      "self",
      "src_label_dict_path"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "FormulaRecEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "FormulaRecExportor": {
    "entities": []
  },
  "FormulaRecDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "ClsTrainer": {
    "entities": [],
    "dump_label_dict": [
      "self",
      "src_label_dict_path"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "ClsEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "ClsExportor": {
    "entities": []
  },
  "ClsDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "draw_label": [
    "image",
    "label",
    "label_map_dict"
  ],
  "OVSegDatasetChecker": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "OVSegTrainer": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "OVSegEvaluator": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "OVSegExportor": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "TextToSpeechAcousticDatasetChecker": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "TextToSpeechAcousticTrainer": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "TextToSpeechAcousticEvaluator": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "TextToSpeechAcousticExportor": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "TSCLSTrainer": {
    "entities": [],
    "train": [
      "self"
    ],
    "make_tar_file": [
      "self"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "TSCLSEvaluator": {
    "entities": [],
    "get_config_path": [
      "self",
      "weight_path"
    ],
    "update_config": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ],
    "uncompress_tar_file": [
      "self"
    ]
  },
  "TSCLSExportor": {
    "entities": [],
    "get_config_path": [
      "self",
      "weight_path"
    ]
  },
  "TSCLSDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "convert_excel_dataset": [
    "input_dir"
  ],
  "WhisperDatasetChecker": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "WhisperTrainer": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "WhisperEvaluator": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "WhisperExportor": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "SegTrainer": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "SegEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_config_path": [
      "self",
      "weight_path"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "SegExportor": {
    "entities": [],
    "get_export_kwargs": [
      "self"
    ]
  },
  "SegDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "TextToSpeechVocoderDatasetChecker": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "TextToSpeechVocoderTrainer": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "TextToSpeechVocoderEvaluator": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "TextToSpeechVocoderExportor": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "OVDetDatasetChecker": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "OVDetTrainer": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "OVDetEvaluator": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "OVDetExportor": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "TSFCTrainer": {
    "entities": [],
    "train": [
      "self"
    ],
    "make_tar_file": [
      "self"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "TSFCEvaluator": {
    "entities": [],
    "get_config_path": [
      "self",
      "weight_path"
    ],
    "update_config": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ],
    "uncompress_tar_file": [
      "self"
    ]
  },
  "TSFCExportor": {
    "entities": [],
    "get_config_path": [
      "self",
      "weight_path"
    ]
  },
  "TSFCDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "TextToPinyinDatasetChecker": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "TextToPinyinTrainer": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "TextToPinyinEvaluator": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "TextToPinyinExportor": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "KeypointTrainer": {
    "entities": [],
    "_update_dataset": [
      "self"
    ]
  },
  "KeypointEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ]
  },
  "KeypointExportor": {
    "entities": []
  },
  "KeypointDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_type": [
      "self"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ]
  },
  "draw_keypoint": [
    "image",
    "coco_info",
    "img_id"
  ],
  "InstanceSegTrainer": {
    "entities": [],
    "_update_dataset": [
      "self"
    ]
  },
  "InstanceSegEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ]
  },
  "InstanceSegExportor": {
    "entities": []
  },
  "COCOInstSegDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "Indexer": {
    "__init__": [
      "self"
    ],
    "get_id": [
      "self",
      "key"
    ],
    "get_list": [
      "self",
      "key_name"
    ]
  },
  "Extension": {
    "__init__": [
      "self",
      "exts_list"
    ],
    "__iter__": [
      "self"
    ],
    "update": [
      "self",
      "ext"
    ]
  },
  "split_anno_list": [
    "root_dir",
    "anno_map"
  ],
  "labelme2coco": [
    "label_indexer",
    "img_indexer",
    "root_dir",
    "anno_path",
    "save_path"
  ],
  "points_to_mask": [
    "img_shape",
    "points"
  ],
  "json2list": [
    "json_path",
    "base_image_num"
  ],
  "assemble_write": [
    "image_info_list",
    "category_list",
    "save_path"
  ],
  "draw_bbox": [
    "image",
    "coco_info",
    "img_id"
  ],
  "BEVFusionTrainer": {
    "entities": [],
    "_update_dataset": [
      "self"
    ],
    "_update_pretrained_model": [
      "self"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "BEVFusionEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "BEVFusionExportor": {
    "entities": []
  },
  "BEVFusionDatasetChecker": {
    "entities": [],
    "check_dataset": [
      "self",
      "dataset_dir"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_data": [
      "self",
      "ann_file",
      "max_sample_num"
    ],
    "data_infos": [
      "self",
      "ann_file",
      "max_sample_num"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "get_data": [
    "ann_file",
    "max_sample_num"
  ],
  "data_infos": [
    "ann_file",
    "max_sample_num"
  ],
  "ShiTuRecTrainer": {
    "entities": [],
    "update_config": [
      "self"
    ]
  },
  "ShiTuRecEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ]
  },
  "ShiTuRecExportor": {
    "entities": []
  },
  "ShiTuRecDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "TSADTrainer": {
    "entities": [],
    "train": [
      "self"
    ],
    "make_tar_file": [
      "self"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "TSADEvaluator": {
    "entities": [],
    "get_config_path": [
      "self",
      "weight_path"
    ],
    "update_config": [
      "self"
    ],
    "uncompress_tar_file": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "TSADExportor": {
    "entities": [],
    "get_config_path": [
      "self",
      "weight_path"
    ]
  },
  "TSADDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "DocVLMDatasetChecker": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "DocVLMTrainer": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "DocVLMEvaluator": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "DocVLMExportor": {
    "entities": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "VideoDetTrainer": {
    "entities": [],
    "dump_label_dict": [
      "self",
      "src_label_dict_path"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "VideoDetEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "VideoDetExportor": {
    "entities": []
  },
  "VideoDetDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "VideoClsTrainer": {
    "entities": [],
    "dump_label_dict": [
      "self",
      "src_label_dict_path"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "VideoClsEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "VideoClsExportor": {
    "entities": []
  },
  "VideoClsDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "build_trainer": [
    "config"
  ],
  "BaseTrainer": {
    "__is_base": [],
    "__init__": [
      "self",
      "config"
    ],
    "train": [
      "self"
    ],
    "dump_config": [
      "self",
      "config_file_path"
    ],
    "get_device": [
      "self",
      "using_device_number"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "build_evaluator": [
    "config"
  ],
  "BaseEvaluator": {
    "__is_base": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_config_path": [
      "self",
      "weight_path"
    ],
    "check_return": [
      "self",
      "metrics"
    ],
    "evaluate": [
      "self"
    ],
    "dump_config": [
      "self",
      "config_file_path"
    ],
    "get_device": [
      "self",
      "using_device_number"
    ],
    "update_config": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "build_exportor": [
    "config"
  ],
  "BaseExportor": {
    "__is_base": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_config_path": [
      "self",
      "weight_path"
    ],
    "export": [
      "self"
    ],
    "get_device": [
      "self",
      "using_device_number"
    ],
    "update_config": [
      "self"
    ],
    "get_export_kwargs": [
      "self"
    ]
  },
  "build_model": [
    "model_name",
    "config_path"
  ],
  "build_dataset_checker": [
    "config"
  ],
  "BaseDatasetChecker": {
    "__is_base": [],
    "__init__": [
      "self",
      "config"
    ],
    "check": [
      "self"
    ],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "build_res_dict": [
    "check_pass",
    "err_type",
    "err_msg"
  ],
  "_is_known_error_type": [
    "err_type"
  ],
  "AvgMetrics": {
    "__init__": [
      "self"
    ],
    "avg": [
      "self"
    ],
    "avg_info": [
      "self"
    ]
  },
  "TopkAcc": {
    "__init__": [
      "self",
      "topk"
    ],
    "forward": [
      "self",
      "x",
      "label"
    ]
  },
  "prase_pt_info": [
    "pt_info",
    "num_classes"
  ],
  "CINN_WHITELIST": [],
  "enable_cinn_backend": [],
  "json_eval_results": [
    "args"
  ],
  "cocoapi_eval": [
    "jsonfile",
    "style",
    "coco_gt",
    "anno_file",
    "max_dets",
    "sigmas",
    "use_area"
  ],
  "FaceRecTrainer": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "update_dataset_cfg": [
      "self"
    ]
  },
  "FaceRecEvaluator": {
    "entities": [],
    "update_config": [
      "self"
    ],
    "update_dataset_cfg": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "FaceRecExportor": {
    "entities": []
  },
  "FaceRecDatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "check_train": [
    "dataset_dir",
    "output",
    "sample_num"
  ],
  "check_val": [
    "dataset_dir",
    "output",
    "sample_num"
  ],
  "LAYOUTANALYSIS_MODELS": [],
  "DetTrainer": {
    "entities": [],
    "_update_dataset": [
      "self"
    ],
    "update_config": [
      "self"
    ],
    "get_train_kwargs": [
      "self"
    ]
  },
  "DetEvaluator": {
    "entities": [],
    "_update_dataset": [
      "self"
    ],
    "update_config": [
      "self"
    ],
    "get_eval_kwargs": [
      "self"
    ]
  },
  "DetExportor": {
    "entities": []
  },
  "COCODatasetChecker": {
    "entities": [],
    "sample_num": [],
    "get_dataset_root": [
      "self",
      "dataset_dir"
    ],
    "convert_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "split_dataset": [
      "self",
      "src_dataset_dir"
    ],
    "check_dataset": [
      "self",
      "dataset_dir",
      "sample_num"
    ],
    "analyse": [
      "self",
      "dataset_dir"
    ],
    "get_show_type": [
      "self"
    ],
    "get_dataset_type": [
      "self"
    ]
  },
  "convert_voc_dataset": [
    "root_dir",
    "anno_map"
  ],
  "voc_get_label_anno": [
    "root_dir",
    "anno_path"
  ],
  "voc_get_image_info": [
    "annotation_root",
    "img_indexer"
  ],
  "voc_get_coco_annotation": [
    "obj",
    "label_indexer"
  ],
  "voc_xmls_to_cocojson": [
    "root_dir",
    "annotation_paths",
    "label_indexer",
    "img_indexer",
    "output",
    "output_file"
  ]
}