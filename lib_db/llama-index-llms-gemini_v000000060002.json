{
  "dispatcher": [],
  "GEMINI_MODELS": [],
  "Gemini": {
    "__init__": [
      "self",
      "api_key",
      "model",
      "temperature",
      "max_tokens",
      "generation_config",
      "safety_settings",
      "callback_manager",
      "api_base",
      "transport",
      "model_name",
      "default_headers",
      "request_options"
    ],
    "class_name": [
      "cls"
    ],
    "metadata": [
      "self"
    ],
    "complete": [
      "self",
      "prompt",
      "formatted"
    ],
    "acomplete": [
      "self",
      "prompt",
      "formatted"
    ],
    "stream_complete": [
      "self",
      "prompt",
      "formatted"
    ],
    "astream_complete": [
      "self",
      "prompt",
      "formatted"
    ],
    "chat": [
      "self",
      "messages"
    ],
    "achat": [
      "self",
      "messages"
    ],
    "stream_chat": [
      "self",
      "messages"
    ],
    "astream_chat": [
      "self",
      "messages"
    ],
    "_to_function_calling_config": [
      "self",
      "tool_required",
      "tool_choice"
    ],
    "_prepare_chat_with_tools": [
      "self",
      "tools",
      "user_msg",
      "chat_history",
      "verbose",
      "allow_parallel_tool_calls",
      "tool_required",
      "tool_choice",
      "strict"
    ],
    "get_tool_calls_from_response": [
      "self",
      "response",
      "error_on_no_tool_call"
    ],
    "structured_predict": [
      "self",
      "output_cls",
      "prompt",
      "llm_kwargs"
    ],
    "astructured_predict": [
      "self",
      "output_cls",
      "prompt",
      "llm_kwargs"
    ],
    "stream_structured_predict": [
      "self",
      "output_cls",
      "prompt",
      "llm_kwargs"
    ],
    "astream_structured_predict": [
      "self",
      "output_cls",
      "prompt",
      "llm_kwargs"
    ]
  },
  "MODELS_WITHOUT_FUNCTION_CALLING_SUPPORT": [],
  "_error_if_finished_early": [
    "candidate"
  ],
  "completion_from_gemini_response": [
    "response",
    "text",
    "delta"
  ],
  "chat_from_gemini_response": [
    "response"
  ],
  "chat_message_to_gemini": [
    "message"
  ],
  "is_function_calling_model": [
    "model"
  ],
  "__all__": []
}