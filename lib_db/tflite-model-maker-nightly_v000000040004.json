{
  "_IMAGE_MODELS": [],
  "_TEXT_MODELS": [],
  "_QA_MODELS": [],
  "FormatDoc": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "fn"
    ]
  },
  "ModelMakerCLI": {
    "__init__": [
      "self",
      "tf"
    ],
    "image_classification": [
      "self",
      "data_dir",
      "export_dir",
      "spec"
    ],
    "text_classification": [
      "self",
      "data_dir",
      "export_dir",
      "spec"
    ],
    "question_answer": [
      "self",
      "train_data_path",
      "validation_data_path",
      "export_dir",
      "spec"
    ]
  },
  "main": [],
  "FLAGS": [],
  "define_flags": [],
  "load_image": [
    "image_path",
    "image_size"
  ],
  "save_visualized_image": [
    "image",
    "prediction",
    "output_path"
  ],
  "TFLiteRunner": {
    "__init__": [
      "self",
      "model_path"
    ],
    "run": [
      "self",
      "image"
    ]
  },
  "convert2trt": [
    "tf_savedmodel_dir",
    "trt_savedmodel_dir"
  ],
  "benchmark": [
    "trt_savedmodel_dir",
    "warmup_runs",
    "bm_runs"
  ],
  "FloatType": [],
  "_get_v": [
    "b1_height",
    "b1_width",
    "b2_height",
    "b2_width"
  ],
  "_iou_per_anchor": [
    "pred_boxes",
    "target_boxes",
    "iou_type"
  ],
  "iou_loss": [
    "pred_boxes",
    "target_boxes",
    "iou_type"
  ],
  "_DEFAULT_BATCH_SIZE": [],
  "update_learning_rate_schedule_parameters": [
    "params"
  ],
  "stepwise_lr_schedule": [
    "adjusted_learning_rate",
    "adjusted_lr_warmup_init",
    "lr_warmup_step",
    "first_lr_drop_step",
    "second_lr_drop_step",
    "global_step"
  ],
  "cosine_lr_schedule": [
    "adjusted_lr",
    "adjusted_lr_warmup_init",
    "lr_warmup_step",
    "total_steps",
    "step"
  ],
  "polynomial_lr_schedule": [
    "adjusted_lr",
    "adjusted_lr_warmup_init",
    "lr_warmup_step",
    "power",
    "total_steps",
    "step"
  ],
  "learning_rate_schedule": [
    "params",
    "global_step"
  ],
  "focal_loss": [
    "y_pred",
    "y_true",
    "alpha",
    "gamma",
    "normalizer",
    "label_smoothing"
  ],
  "_box_loss": [
    "box_outputs",
    "box_targets",
    "num_positives",
    "delta"
  ],
  "detection_loss": [
    "cls_outputs",
    "box_outputs",
    "labels",
    "params"
  ],
  "reg_l2_loss": [
    "weight_decay",
    "regex"
  ],
  "_model_fn": [
    "features",
    "labels",
    "mode",
    "params",
    "model",
    "variable_filter_fn"
  ],
  "efficientdet_model_fn": [
    "features",
    "labels",
    "mode",
    "params"
  ],
  "get_model_arch": [
    "model_name"
  ],
  "get_model_fn": [
    "model_name"
  ],
  "srelu_fn": [
    "x"
  ],
  "activation_fn": [
    "features",
    "act_type"
  ],
  "cross_replica_mean": [
    "t",
    "num_shards_per_group"
  ],
  "get_ema_vars": [],
  "get_ckpt_var_map": [
    "ckpt_path",
    "ckpt_scope",
    "var_scope",
    "skip_mismatch"
  ],
  "TpuBatchNormalization": {
    "__init__": [
      "self",
      "fused"
    ],
    "_moments": [
      "self",
      "inputs",
      "reduction_axes",
      "keep_dims",
      "mask"
    ],
    "call": [
      "self",
      "inputs",
      "mask",
      "training"
    ]
  },
  "SyncBatchNormalization": {
    "__init__": [
      "self",
      "fused"
    ],
    "_moments": [
      "self",
      "inputs",
      "reduction_axes",
      "keep_dims",
      "mask"
    ],
    "call": [
      "self",
      "inputs",
      "mask",
      "training"
    ]
  },
  "BatchNormalization": {
    "__init__": [
      "self"
    ],
    "call": [
      "self",
      "inputs",
      "mask",
      "training"
    ]
  },
  "batch_norm_class": [
    "is_training",
    "strategy"
  ],
  "_BN_LAYER_CACHE": [],
  "batch_normalization": [
    "inputs",
    "training",
    "strategy",
    "reuse_scope"
  ],
  "batch_norm_act": [
    "inputs",
    "is_training_bn",
    "act_type",
    "init_zero",
    "data_format",
    "momentum",
    "epsilon",
    "strategy",
    "name",
    "batch_norm_trainable"
  ],
  "drop_connect": [
    "inputs",
    "is_training",
    "survival_prob"
  ],
  "num_params_flops": [
    "readable_format"
  ],
  "conv_kernel_initializer": [],
  "dense_kernel_initializer": [],
  "Pair": {
    "__new__": [
      "cls",
      "name",
      "value"
    ],
    "__init__": [
      "self",
      "name",
      "_"
    ]
  },
  "scalar": [
    "name",
    "tensor",
    "is_tpu"
  ],
  "image": [
    "name",
    "tensor",
    "is_tpu"
  ],
  "get_tpu_host_call": [
    "global_step",
    "params"
  ],
  "archive_ckpt": [
    "ckpt_eval",
    "ckpt_objective",
    "ckpt_path"
  ],
  "parse_image_size": [
    "image_size"
  ],
  "get_feat_sizes": [
    "image_size",
    "max_level"
  ],
  "verify_feats_size": [
    "feats",
    "feat_sizes",
    "min_level",
    "max_level",
    "data_format"
  ],
  "get_precision": [
    "strategy",
    "mixed_precision"
  ],
  "float16_scope": [],
  "set_precision_policy": [
    "policy_name"
  ],
  "build_model_with_precision": [
    "pp",
    "mm",
    "ii"
  ],
  "_recompute_grad": [
    "f"
  ],
  "recompute_grad": [
    "recompute"
  ],
  "eval_str_fn": [
    "val"
  ],
  "Config": {
    "__init__": [
      "self",
      "config_dict"
    ],
    "__setattr__": [
      "self",
      "k",
      "v"
    ],
    "__getattr__": [
      "self",
      "k"
    ],
    "__getitem__": [
      "self",
      "k"
    ],
    "__repr__": [
      "self"
    ],
    "__deepcopy__": [
      "self",
      "memodict"
    ],
    "__str__": [
      "self"
    ],
    "_update": [
      "self",
      "config_dict",
      "allow_new_keys"
    ],
    "get": [
      "self",
      "k",
      "default_value"
    ],
    "update": [
      "self",
      "config_dict"
    ],
    "keys": [
      "self"
    ],
    "override": [
      "self",
      "config_dict_or_str",
      "allow_new_keys"
    ],
    "parse_from_yaml": [
      "self",
      "yaml_file_path"
    ],
    "save_to_yaml": [
      "self",
      "yaml_file_path"
    ],
    "parse_from_str": [
      "self",
      "config_str"
    ],
    "as_dict": [
      "self"
    ]
  },
  "default_detection_configs": [],
  "efficientdet_model_param_dict": [],
  "lite_common_param": [],
  "efficientdet_lite_param_dict": [],
  "get_efficientdet_config": [
    "model_name"
  ],
  "get_detection_config": [
    "model_name"
  ],
  "MIN_CLASS_SCORE": [],
  "_DUMMY_DETECTION_SCORE": [],
  "MAX_DETECTION_POINTS": [],
  "diou_nms": [
    "dets",
    "iou_thresh"
  ],
  "hard_nms": [
    "dets",
    "iou_thresh"
  ],
  "soft_nms": [
    "dets",
    "nms_configs"
  ],
  "nms": [
    "dets",
    "nms_configs"
  ],
  "per_class_nms": [
    "boxes",
    "scores",
    "classes",
    "image_id",
    "image_scale",
    "num_classes",
    "max_boxes_to_draw",
    "nms_configs"
  ],
  "ModelInspector": {
    "__init__": [
      "self",
      "model_name",
      "logdir",
      "tensorrt",
      "use_xla",
      "ckpt_path",
      "export_ckpt",
      "saved_model_dir",
      "tflite_path",
      "batch_size",
      "hparams"
    ],
    "build_model": [
      "self",
      "inputs"
    ],
    "export_saved_model": [
      "self"
    ],
    "saved_model_inference": [
      "self",
      "image_path_pattern",
      "output_dir"
    ],
    "saved_model_benchmark": [
      "self",
      "image_path_pattern",
      "trace_filename"
    ],
    "saved_model_video": [
      "self",
      "video_path",
      "output_video"
    ],
    "inference_single_image": [
      "self",
      "image_image_path",
      "output_dir"
    ],
    "build_and_save_model": [
      "self"
    ],
    "eval_ckpt": [
      "self"
    ],
    "freeze_model": [
      "self"
    ],
    "benchmark_model": [
      "self",
      "warmup_runs",
      "bm_runs",
      "num_threads",
      "trace_filename"
    ],
    "convert_tr": [
      "self",
      "graph_def",
      "fetches"
    ],
    "run_model": [
      "self",
      "runmode"
    ]
  },
  "freeze_vars": [
    "variables",
    "pattern"
  ],
  "resample_feature_map": [
    "feat",
    "name",
    "target_height",
    "target_width",
    "target_num_channels",
    "apply_bn",
    "is_training",
    "conv_after_downsample",
    "strategy",
    "data_format",
    "batch_norm_trainable"
  ],
  "class_net": [
    "images",
    "level",
    "num_classes",
    "num_anchors",
    "num_filters",
    "is_training",
    "act_type",
    "separable_conv",
    "repeats",
    "survival_prob",
    "strategy",
    "data_format"
  ],
  "box_net": [
    "images",
    "level",
    "num_anchors",
    "num_filters",
    "is_training",
    "act_type",
    "repeats",
    "separable_conv",
    "survival_prob",
    "strategy",
    "data_format"
  ],
  "build_class_and_box_outputs": [
    "feats",
    "config"
  ],
  "build_backbone": [
    "features",
    "config"
  ],
  "build_feature_network": [
    "features",
    "config"
  ],
  "fuse_features": [
    "nodes",
    "weight_method"
  ],
  "build_bifpn_layer": [
    "feats",
    "feat_sizes",
    "config"
  ],
  "efficientdet": [
    "features",
    "model_name",
    "config"
  ],
  "block_print": [
    "log_level"
  ],
  "enable_print": [
    "original_stdout"
  ],
  "EvaluationMetric": {
    "__init__": [
      "self",
      "filename",
      "testdev_dir",
      "label_map"
    ],
    "reset_states": [
      "self"
    ],
    "evaluate": [
      "self",
      "log_level"
    ],
    "result": [
      "self",
      "log_level"
    ],
    "update_state": [
      "self",
      "groundtruth_data",
      "detections"
    ],
    "estimator_metric_fn": [
      "self",
      "detections",
      "groundtruth_data"
    ]
  },
  "InputProcessor": {
    "__init__": [
      "self",
      "image",
      "output_size"
    ],
    "image": [
      "self",
      "image"
    ],
    "normalize_image": [
      "self",
      "mean_rgb",
      "stddev_rgb"
    ],
    "set_training_random_scale_factors": [
      "self",
      "scale_min",
      "scale_max",
      "target_size"
    ],
    "set_scale_factors_to_output_size": [
      "self"
    ],
    "resize_and_crop_image": [
      "self",
      "method"
    ]
  },
  "DetectionInputProcessor": {
    "__init__": [
      "self",
      "image",
      "output_size",
      "boxes",
      "classes"
    ],
    "random_horizontal_flip": [
      "self"
    ],
    "clip_boxes": [
      "self",
      "boxes"
    ],
    "resize_and_crop_boxes": [
      "self"
    ],
    "image_scale": [
      "self"
    ],
    "image_scale_to_original": [
      "self"
    ],
    "offset_x": [
      "self"
    ],
    "offset_y": [
      "self"
    ]
  },
  "pad_to_fixed_size": [
    "data",
    "pad_value",
    "output_shape"
  ],
  "InputReader": {
    "__init__": [
      "self",
      "file_pattern",
      "is_training",
      "use_fake_data",
      "max_instances_per_image",
      "debug"
    ],
    "dataset_parser": [
      "self",
      "value",
      "example_decoder",
      "anchor_labeler",
      "params"
    ],
    "process_example": [
      "self",
      "params",
      "batch_size",
      "images",
      "cls_targets",
      "box_targets",
      "num_positives",
      "source_ids",
      "image_scales",
      "boxes",
      "is_crowds",
      "areas",
      "classes",
      "image_masks"
    ],
    "dataset_options": [
      "self"
    ],
    "__call__": [
      "self",
      "params",
      "input_context",
      "batch_size"
    ]
  },
  "image_preprocess": [
    "image",
    "image_size",
    "mean_rgb",
    "stddev_rgb"
  ],
  "batch_image_files_decode": [
    "image_files"
  ],
  "batch_image_preprocess": [
    "raw_images",
    "image_size",
    "mean_rgb",
    "stddev_rgb",
    "batch_size"
  ],
  "build_inputs": [
    "image_path_pattern",
    "image_size",
    "mean_rgb",
    "stddev_rgb"
  ],
  "build_model": [
    "model_name",
    "inputs"
  ],
  "restore_ckpt": [
    "sess",
    "ckpt_path",
    "ema_decay",
    "export_ckpt"
  ],
  "det_post_process": [
    "params",
    "cls_outputs",
    "box_outputs",
    "scales"
  ],
  "visualize_image": [
    "image",
    "boxes",
    "classes",
    "scores",
    "label_map",
    "min_score_thresh",
    "max_boxes_to_draw",
    "line_thickness"
  ],
  "visualize_image_prediction": [
    "image",
    "prediction",
    "label_map"
  ],
  "ServingDriver": {
    "__init__": [
      "self",
      "model_name",
      "ckpt_path",
      "batch_size",
      "use_xla",
      "min_score_thresh",
      "max_boxes_to_draw",
      "line_thickness",
      "model_params"
    ],
    "__del__": [
      "self"
    ],
    "_build_session": [
      "self"
    ],
    "build": [
      "self",
      "params_override"
    ],
    "visualize": [
      "self",
      "image",
      "prediction"
    ],
    "serve_files": [
      "self",
      "image_files"
    ],
    "benchmark": [
      "self",
      "image_arrays",
      "trace_filename"
    ],
    "serve_images": [
      "self",
      "image_arrays"
    ],
    "load": [
      "self",
      "saved_model_dir_or_frozen_graph"
    ],
    "freeze": [
      "self"
    ],
    "export": [
      "self",
      "output_dir",
      "tflite_path",
      "tensorrt"
    ]
  },
  "InferenceDriver": {
    "__init__": [
      "self",
      "model_name",
      "ckpt_path",
      "model_params"
    ],
    "inference": [
      "self",
      "image_path_pattern",
      "output_dir"
    ]
  },
  "RecordInspect": {
    "__init__": [
      "self",
      "config"
    ],
    "visualize": [
      "self"
    ]
  },
  "SETS": [],
  "YEARS": [],
  "pascal_label_map_dict": [],
  "UniqueId": {
    "__init__": [
      "self"
    ],
    "get_image_id": [
      "self"
    ],
    "get_ann_id": [
      "self"
    ]
  },
  "dict_to_tf_example": [
    "data",
    "images_dir",
    "label_map_dict",
    "unique_id",
    "ignore_difficult_instances",
    "ann_json_dict"
  ],
  "create_tf_example": [
    "image",
    "image_dir",
    "bbox_annotations",
    "category_index",
    "caption_annotations",
    "include_masks"
  ],
  "_pool_create_tf_example": [
    "args"
  ],
  "_load_object_annotations": [
    "object_annotations_file"
  ],
  "_load_caption_annotations": [
    "caption_annotations_file"
  ],
  "_load_images_info": [
    "image_info_file"
  ],
  "_create_tf_record_from_coco_annotations": [
    "image_info_file",
    "image_dir",
    "output_path",
    "num_shards",
    "object_annotations_file",
    "caption_annotations_file",
    "include_masks"
  ],
  "_validate_label_map": [
    "label_map"
  ],
  "create_category_index": [
    "categories"
  ],
  "get_max_label_map_index": [
    "label_map"
  ],
  "convert_label_map_to_categories": [
    "label_map",
    "max_num_classes",
    "use_display_name"
  ],
  "create_class_agnostic_category_index": [],
  "int64_feature": [
    "value"
  ],
  "int64_list_feature": [
    "value"
  ],
  "bytes_feature": [
    "value"
  ],
  "bytes_list_feature": [
    "value"
  ],
  "float_list_feature": [
    "value"
  ],
  "read_examples_list": [
    "path"
  ],
  "recursive_parse_xml_to_dict": [
    "xml"
  ],
  "open_sharded_output_tfrecords": [
    "exit_stack",
    "base_path",
    "num_shards"
  ],
  "get_dim_as_int": [
    "dim"
  ],
  "get_batch_size": [
    "tensor_shape"
  ],
  "get_height": [
    "tensor_shape"
  ],
  "get_width": [
    "tensor_shape"
  ],
  "get_depth": [
    "tensor_shape"
  ],
  "_is_tensor": [
    "t"
  ],
  "_set_dim_0": [
    "t",
    "d0"
  ],
  "pad_tensor": [
    "t",
    "length"
  ],
  "clip_tensor": [
    "t",
    "length"
  ],
  "pad_or_clip_tensor": [
    "t",
    "length"
  ],
  "pad_or_clip_nd": [
    "tensor",
    "output_shape"
  ],
  "combined_static_and_dynamic_shape": [
    "tensor"
  ],
  "static_or_dynamic_map_fn": [
    "fn",
    "elems",
    "dtype",
    "parallel_iterations",
    "back_prop"
  ],
  "check_min_image_dim": [
    "min_dim",
    "image_tensor"
  ],
  "assert_shape_equal": [
    "shape_a",
    "shape_b"
  ],
  "assert_shape_equal_along_first_dimension": [
    "shape_a",
    "shape_b"
  ],
  "assert_box_normalized": [
    "boxes",
    "maximum_normalized_coordinate"
  ],
  "flatten_dimensions": [
    "inputs",
    "first",
    "last"
  ],
  "flatten_first_n_dimensions": [
    "inputs",
    "n"
  ],
  "expand_first_dimension": [
    "inputs",
    "dims"
  ],
  "resize_images_and_return_shapes": [
    "inputs",
    "image_resizer_fn"
  ],
  "_TITLE_LEFT_MARGIN": [],
  "_TITLE_TOP_MARGIN": [],
  "STANDARD_COLORS": [],
  "_force_matplotlib_backend": [],
  "_get_multiplier_for_color_randomness": [],
  "save_image_array_as_png": [
    "image",
    "output_path"
  ],
  "encode_image_array_as_png_str": [
    "image"
  ],
  "draw_bounding_box_on_image_array": [
    "image",
    "ymin",
    "xmin",
    "ymax",
    "xmax",
    "color",
    "thickness",
    "display_str_list",
    "use_normalized_coordinates"
  ],
  "draw_bounding_box_on_image": [
    "image",
    "ymin",
    "xmin",
    "ymax",
    "xmax",
    "color",
    "thickness",
    "display_str_list",
    "use_normalized_coordinates"
  ],
  "draw_bounding_boxes_on_image_array": [
    "image",
    "boxes",
    "color",
    "thickness",
    "display_str_list_list"
  ],
  "draw_bounding_boxes_on_image": [
    "image",
    "boxes",
    "color",
    "thickness",
    "display_str_list_list"
  ],
  "create_visualization_fn": [
    "category_index",
    "include_masks",
    "include_keypoints",
    "include_track_ids"
  ],
  "_resize_original_image": [
    "image",
    "image_shape"
  ],
  "draw_bounding_boxes_on_image_tensors": [
    "images",
    "boxes",
    "classes",
    "scores",
    "category_index",
    "original_image_spatial_shape",
    "true_image_shape",
    "instance_masks",
    "keypoints",
    "keypoint_edges",
    "track_ids",
    "max_boxes_to_draw",
    "min_score_thresh",
    "use_normalized_coordinates"
  ],
  "draw_side_by_side_evaluation_image": [
    "eval_dict",
    "category_index",
    "max_boxes_to_draw",
    "min_score_thresh",
    "use_normalized_coordinates",
    "keypoint_edges"
  ],
  "draw_keypoints_on_image_array": [
    "image",
    "keypoints",
    "color",
    "radius",
    "use_normalized_coordinates",
    "keypoint_edges",
    "keypoint_edge_color",
    "keypoint_edge_width"
  ],
  "draw_keypoints_on_image": [
    "image",
    "keypoints",
    "color",
    "radius",
    "use_normalized_coordinates",
    "keypoint_edges",
    "keypoint_edge_color",
    "keypoint_edge_width"
  ],
  "draw_mask_on_image_array": [
    "image",
    "mask",
    "color",
    "alpha"
  ],
  "visualize_boxes_and_labels_on_image_array": [
    "image",
    "boxes",
    "classes",
    "scores",
    "category_index",
    "instance_masks",
    "instance_boundaries",
    "keypoints",
    "keypoint_edges",
    "track_ids",
    "use_normalized_coordinates",
    "max_boxes_to_draw",
    "min_score_thresh",
    "agnostic_mode",
    "line_thickness",
    "groundtruth_box_visualization_color",
    "skip_boxes",
    "skip_scores",
    "skip_labels",
    "skip_track_ids"
  ],
  "add_cdf_image_summary": [
    "values",
    "name"
  ],
  "add_hist_image_summary": [
    "values",
    "bins",
    "name"
  ],
  "EvalMetricOpsVisualization": {
    "__init__": [
      "self",
      "category_index",
      "max_examples_to_draw",
      "max_boxes_to_draw",
      "min_score_thresh",
      "use_normalized_coordinates",
      "summary_name_prefix",
      "keypoint_edges"
    ],
    "clear": [
      "self"
    ],
    "add_images": [
      "self",
      "images"
    ],
    "get_estimator_eval_metric_ops": [
      "self",
      "eval_dict"
    ],
    "images_from_evaluation_dict": [
      "self",
      "eval_dict"
    ]
  },
  "VisualizeSingleFrameDetections": {
    "__init__": [
      "self",
      "category_index",
      "max_examples_to_draw",
      "max_boxes_to_draw",
      "min_score_thresh",
      "use_normalized_coordinates",
      "summary_name_prefix",
      "keypoint_edges"
    ],
    "images_from_evaluation_dict": [
      "self",
      "eval_dict"
    ]
  },
  "InputDataFields": {
    "image": [],
    "image_additional_channels": [],
    "original_image": [],
    "original_image_spatial_shape": [],
    "key": [],
    "source_id": [],
    "filename": [],
    "groundtruth_image_classes": [],
    "groundtruth_image_confidences": [],
    "groundtruth_boxes": [],
    "groundtruth_classes": [],
    "groundtruth_confidences": [],
    "groundtruth_label_types": [],
    "groundtruth_is_crowd": [],
    "groundtruth_area": [],
    "groundtruth_difficult": [],
    "groundtruth_group_of": [],
    "proposal_boxes": [],
    "proposal_objectness": [],
    "groundtruth_instance_masks": [],
    "groundtruth_instance_boundaries": [],
    "groundtruth_instance_classes": [],
    "groundtruth_keypoints": [],
    "groundtruth_keypoint_visibilities": [],
    "groundtruth_keypoint_weights": [],
    "groundtruth_label_weights": [],
    "groundtruth_weights": [],
    "num_groundtruth_boxes": [],
    "is_annotated": [],
    "true_image_shape": [],
    "multiclass_scores": [],
    "context_features": [],
    "context_feature_length": [],
    "valid_context_size": []
  },
  "DetectionResultFields": {
    "source_id": [],
    "key": [],
    "detection_boxes": [],
    "detection_scores": [],
    "detection_multiclass_scores": [],
    "detection_features": [],
    "detection_classes": [],
    "detection_masks": [],
    "detection_boundaries": [],
    "detection_keypoints": [],
    "detection_keypoint_scores": [],
    "num_detections": [],
    "raw_detection_boxes": [],
    "raw_detection_scores": [],
    "detection_anchor_indices": []
  },
  "BoxListFields": {
    "boxes": [],
    "classes": [],
    "scores": [],
    "weights": [],
    "confidences": [],
    "objectness": [],
    "masks": [],
    "boundaries": [],
    "keypoints": [],
    "keypoint_heatmaps": [],
    "is_crowd": []
  },
  "PredictionFields": {
    "feature_maps": [],
    "anchors": [],
    "raw_detection_boxes": [],
    "raw_detection_feature_map_indices": []
  },
  "TfExampleFields": {
    "image_encoded": [],
    "image_format": [],
    "filename": [],
    "channels": [],
    "colorspace": [],
    "height": [],
    "width": [],
    "source_id": [],
    "image_class_text": [],
    "image_class_label": [],
    "object_class_text": [],
    "object_class_label": [],
    "object_bbox_ymin": [],
    "object_bbox_xmin": [],
    "object_bbox_ymax": [],
    "object_bbox_xmax": [],
    "object_view": [],
    "object_truncated": [],
    "object_occluded": [],
    "object_difficult": [],
    "object_group_of": [],
    "object_depiction": [],
    "object_is_crowd": [],
    "object_segment_area": [],
    "object_weight": [],
    "instance_masks": [],
    "instance_boundaries": [],
    "instance_classes": [],
    "detection_class_label": [],
    "detection_bbox_ymin": [],
    "detection_bbox_xmin": [],
    "detection_bbox_ymax": [],
    "detection_bbox_xmax": [],
    "detection_score": []
  },
  "get_model_builder": [
    "model_name"
  ],
  "get_model": [
    "model_name",
    "override_params",
    "model_dir"
  ],
  "GlobalParams": [],
  "BlockArgs": [],
  "superpixel_kernel_initializer": [
    "shape",
    "dtype",
    "partition_info"
  ],
  "round_filters": [
    "filters",
    "global_params",
    "skip"
  ],
  "round_repeats": [
    "repeats",
    "global_params",
    "skip"
  ],
  "SE": {
    "__init__": [
      "self",
      "global_params",
      "se_filters",
      "output_filters",
      "name"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "SuperPixel": {
    "__init__": [
      "self",
      "block_args",
      "global_params",
      "name"
    ],
    "call": [
      "self",
      "inputs",
      "training"
    ]
  },
  "MBConvBlock": {
    "__init__": [
      "self",
      "block_args",
      "global_params",
      "name"
    ],
    "block_args": [
      "self"
    ],
    "_build": [
      "self"
    ],
    "call": [
      "self",
      "inputs",
      "training",
      "survival_prob"
    ]
  },
  "MBConvBlockWithoutDepthwise": {
    "_build": [
      "self"
    ],
    "call": [
      "self",
      "inputs",
      "training",
      "survival_prob"
    ]
  },
  "Stem": {
    "__init__": [
      "self",
      "global_params",
      "stem_filters",
      "name"
    ],
    "call": [
      "self",
      "inputs",
      "training"
    ]
  },
  "Head": {
    "__init__": [
      "self",
      "global_params",
      "name"
    ],
    "call": [
      "self",
      "inputs",
      "training",
      "pooled_features_only"
    ]
  },
  "Model": {
    "__init__": [
      "self",
      "blocks_args",
      "global_params",
      "name"
    ],
    "_get_conv_block": [
      "self",
      "conv_type"
    ],
    "_build": [
      "self"
    ],
    "call": [
      "self",
      "inputs",
      "training",
      "features_only",
      "pooled_features_only"
    ]
  },
  "efficientnet_params": [
    "model_name"
  ],
  "BlockDecoder": {
    "_decode_block_string": [
      "self",
      "block_string"
    ],
    "_encode_block_string": [
      "self",
      "block"
    ],
    "decode": [
      "self",
      "string_list"
    ],
    "encode": [
      "self",
      "blocks_args"
    ]
  },
  "swish": [
    "features",
    "use_native",
    "use_hard"
  ],
  "_DEFAULT_BLOCKS_ARGS": [],
  "efficientnet": [
    "width_coefficient",
    "depth_coefficient",
    "dropout_rate",
    "survival_prob"
  ],
  "get_model_params": [
    "model_name",
    "override_params"
  ],
  "build_model_base": [
    "images",
    "model_name",
    "training",
    "override_params"
  ],
  "MEAN_RGB": [],
  "STDDEV_RGB": [],
  "efficientnet_lite_params": [
    "model_name"
  ],
  "efficientnet_lite": [
    "width_coefficient",
    "depth_coefficient",
    "dropout_rate",
    "survival_prob"
  ],
  "_MAX_LEVEL": [],
  "policy_v0": [],
  "policy_vtest": [],
  "blend": [
    "image1",
    "image2",
    "factor"
  ],
  "cutout": [
    "image",
    "pad_size",
    "replace"
  ],
  "solarize": [
    "image",
    "threshold"
  ],
  "solarize_add": [
    "image",
    "addition",
    "threshold"
  ],
  "color": [
    "image",
    "factor"
  ],
  "contrast": [
    "image",
    "factor"
  ],
  "brightness": [
    "image",
    "factor"
  ],
  "posterize": [
    "image",
    "bits"
  ],
  "rotate": [
    "image",
    "degrees",
    "replace"
  ],
  "translate_x": [
    "image",
    "pixels",
    "replace"
  ],
  "translate_y": [
    "image",
    "pixels",
    "replace"
  ],
  "shear_x": [
    "image",
    "level",
    "replace"
  ],
  "shear_y": [
    "image",
    "level",
    "replace"
  ],
  "autocontrast": [
    "image"
  ],
  "sharpness": [
    "image",
    "factor"
  ],
  "equalize": [
    "image"
  ],
  "invert": [
    "image"
  ],
  "wrap": [
    "image"
  ],
  "unwrap": [
    "image",
    "replace"
  ],
  "NAME_TO_FUNC": [],
  "_randomly_negate_tensor": [
    "tensor"
  ],
  "_rotate_level_to_arg": [
    "level"
  ],
  "_shrink_level_to_arg": [
    "level"
  ],
  "_enhance_level_to_arg": [
    "level"
  ],
  "_shear_level_to_arg": [
    "level"
  ],
  "_translate_level_to_arg": [
    "level",
    "translate_const"
  ],
  "level_to_arg": [
    "hparams"
  ],
  "_parse_policy_info": [
    "name",
    "prob",
    "level",
    "replace_value",
    "augmentation_hparams"
  ],
  "_apply_func_with_prob": [
    "func",
    "image",
    "args",
    "prob"
  ],
  "select_and_apply_random_policy": [
    "policies",
    "image"
  ],
  "build_and_apply_nas_policy": [
    "policies",
    "image",
    "augmentation_hparams"
  ],
  "distort_image_with_autoaugment": [
    "image",
    "augmentation_name"
  ],
  "distort_image_with_randaugment": [
    "image",
    "num_layers",
    "magnitude"
  ],
  "create_dataset": [
    "dataset",
    "num_classes",
    "is_training"
  ],
  "TrainableModel": {
    "__init__": [
      "self",
      "blocks_args",
      "global_params",
      "name",
      "weight_decay"
    ],
    "_reg_l2_loss": [
      "self",
      "weight_decay",
      "regex"
    ],
    "train_step": [
      "self",
      "data"
    ],
    "test_step": [
      "self",
      "data"
    ]
  },
  "IMAGE_SIZE": [],
  "CROP_PADDING": [],
  "distorted_bounding_box_crop": [
    "image_bytes",
    "bbox",
    "min_object_covered",
    "aspect_ratio_range",
    "area_range",
    "max_attempts",
    "scope"
  ],
  "_at_least_x_are_equal": [
    "a",
    "b",
    "x"
  ],
  "_resize_image": [
    "image",
    "image_size",
    "method"
  ],
  "_decode_and_random_crop": [
    "image_bytes",
    "image_size",
    "resize_method"
  ],
  "_decode_and_center_crop": [
    "image_bytes",
    "image_size",
    "resize_method"
  ],
  "_flip": [
    "image"
  ],
  "preprocess_for_train": [
    "image_bytes",
    "use_bfloat16",
    "image_size",
    "augment_name",
    "randaug_num_layers",
    "randaug_magnitude",
    "resize_method"
  ],
  "preprocess_for_eval": [
    "image_bytes",
    "use_bfloat16",
    "image_size",
    "resize_method"
  ],
  "preprocess_image": [
    "image_bytes",
    "is_training",
    "use_bfloat16",
    "image_size",
    "augment_name",
    "randaug_num_layers",
    "randaug_magnitude",
    "resize_method"
  ],
  "vectorized_iou": [
    "clusters",
    "detection"
  ],
  "find_matching_cluster": [
    "clusters",
    "detection"
  ],
  "weighted_average": [
    "samples",
    "weights"
  ],
  "average_detections": [
    "detections",
    "num_models"
  ],
  "ensemble_detections": [
    "params",
    "detections",
    "num_models"
  ],
  "T": [],
  "CLASS_OFFSET": [],
  "TFLITE_MAX_CLASSES_PER_DETECTION": [],
  "TFLITE_DETECTION_POSTPROCESS_FUNC": [],
  "TFLITE_USE_REGULAR_NMS": [],
  "to_list": [
    "inputs"
  ],
  "batch_map_fn": [
    "map_fn",
    "inputs"
  ],
  "clip_boxes": [
    "boxes",
    "image_size"
  ],
  "merge_class_box_level_outputs": [
    "params",
    "cls_outputs",
    "box_outputs"
  ],
  "topk_class_boxes": [
    "params",
    "cls_outputs",
    "box_outputs"
  ],
  "pre_nms": [
    "params",
    "cls_outputs",
    "box_outputs",
    "topk"
  ],
  "postprocess_combined": [
    "params",
    "cls_outputs",
    "box_outputs",
    "image_scales"
  ],
  "tflite_nms_implements_signature": [
    "params"
  ],
  "tflite_pre_nms": [
    "params",
    "cls_outputs",
    "box_outputs"
  ],
  "postprocess_tflite": [
    "params",
    "cls_outputs",
    "box_outputs"
  ],
  "postprocess_global": [
    "params",
    "cls_outputs",
    "box_outputs",
    "image_scales"
  ],
  "postprocess_per_class": [
    "params",
    "cls_outputs",
    "box_outputs",
    "image_scales"
  ],
  "generate_detections_from_nms_output": [
    "nms_boxes_bs",
    "nms_classes_bs",
    "nms_scores_bs",
    "image_ids",
    "original_image_widths",
    "flip"
  ],
  "generate_detections": [
    "params",
    "cls_outputs",
    "box_outputs",
    "image_scales",
    "image_ids",
    "flip",
    "pre_class_nms"
  ],
  "transform_detections": [
    "detections"
  ],
  "_collect_prunable_layers": [
    "model"
  ],
  "UpdatePruningStep": {
    "__init__": [
      "self"
    ],
    "on_train_begin": [
      "self",
      "logs"
    ],
    "on_train_batch_begin": [
      "self",
      "batch",
      "logs"
    ],
    "on_epoch_end": [
      "self",
      "batch",
      "logs"
    ]
  },
  "PruningSummaries": {
    "__init__": [
      "self",
      "log_dir",
      "update_freq"
    ],
    "_log_pruning_metrics": [
      "self",
      "logs",
      "step"
    ],
    "on_epoch_begin": [
      "self",
      "epoch",
      "logs"
    ]
  },
  "StepwiseLrSchedule": {
    "__init__": [
      "self",
      "adjusted_lr",
      "lr_warmup_init",
      "lr_warmup_step",
      "first_lr_drop_step",
      "second_lr_drop_step"
    ],
    "__call__": [
      "self",
      "step"
    ]
  },
  "CosineLrSchedule": {
    "__init__": [
      "self",
      "adjusted_lr",
      "lr_warmup_init",
      "lr_warmup_step",
      "total_steps"
    ],
    "__call__": [
      "self",
      "step"
    ]
  },
  "PolynomialLrSchedule": {
    "__init__": [
      "self",
      "adjusted_lr",
      "lr_warmup_init",
      "lr_warmup_step",
      "power",
      "total_steps"
    ],
    "__call__": [
      "self",
      "step"
    ]
  },
  "get_optimizer": [
    "params"
  ],
  "COCOCallback": {
    "__init__": [
      "self",
      "test_dataset",
      "update_freq"
    ],
    "set_model": [
      "self",
      "model"
    ],
    "_get_detections": [
      "self",
      "images",
      "labels"
    ],
    "on_epoch_end": [
      "self",
      "epoch",
      "logs"
    ]
  },
  "DisplayCallback": {
    "__init__": [
      "self",
      "sample_image",
      "output_dir",
      "update_freq"
    ],
    "set_model": [
      "self",
      "model"
    ],
    "on_train_batch_end": [
      "self",
      "batch",
      "logs"
    ],
    "_draw_inference": [
      "self",
      "step"
    ]
  },
  "get_callbacks": [
    "params",
    "val_dataset"
  ],
  "AdversarialLoss": {
    "__init__": [
      "self",
      "adv_config"
    ],
    "build": [
      "self",
      "model",
      "loss_fn",
      "tape"
    ],
    "call": [
      "self",
      "features",
      "y",
      "y_pred",
      "labeled_loss"
    ]
  },
  "FocalLoss": {
    "__init__": [
      "self",
      "alpha",
      "gamma",
      "label_smoothing"
    ],
    "call": [
      "self",
      "y",
      "y_pred"
    ]
  },
  "BoxLoss": {
    "__init__": [
      "self",
      "delta"
    ],
    "call": [
      "self",
      "y_true",
      "box_outputs"
    ]
  },
  "BoxIouLoss": {
    "__init__": [
      "self",
      "iou_loss_type",
      "min_level",
      "max_level",
      "num_scales",
      "aspect_ratios",
      "anchor_scale",
      "image_size"
    ],
    "call": [
      "self",
      "y_true",
      "box_outputs"
    ]
  },
  "EfficientDetNetTrain": {
    "__init__": [
      "self"
    ],
    "_freeze_vars": [
      "self"
    ],
    "_reg_l2_loss": [
      "self",
      "weight_decay",
      "regex"
    ],
    "_detection_loss": [
      "self",
      "cls_outputs",
      "box_outputs",
      "labels",
      "loss_vals"
    ],
    "train_step": [
      "self",
      "data"
    ],
    "test_step": [
      "self",
      "data"
    ]
  },
  "EfficientDetNetTrainHub": {
    "__init__": [
      "self",
      "config",
      "hub_module_url",
      "name"
    ],
    "call": [
      "self",
      "inputs",
      "training"
    ]
  },
  "coco": [],
  "voc": [],
  "waymo": [],
  "get_label_map": [
    "mapping"
  ],
  "decode_box_outputs": [
    "pred_boxes",
    "anchor_boxes"
  ],
  "decode_anchors_to_centersize": [
    "pred_boxes",
    "anchor_boxes"
  ],
  "Anchors": {
    "__init__": [
      "self",
      "min_level",
      "max_level",
      "num_scales",
      "aspect_ratios",
      "anchor_scale",
      "image_size"
    ],
    "_generate_configs": [
      "self"
    ],
    "_generate_boxes": [
      "self"
    ],
    "get_anchors_per_location": [
      "self"
    ]
  },
  "AnchorLabeler": {
    "__init__": [
      "self",
      "anchors",
      "num_classes",
      "match_threshold"
    ],
    "_unpack_labels": [
      "self",
      "labels"
    ],
    "label_anchors": [
      "self",
      "gt_boxes",
      "gt_labels"
    ]
  },
  "quantize": [
    "layer",
    "quantize_config"
  ],
  "optimzation_methods": [],
  "set_config": [
    "configs"
  ],
  "get_method": [
    "method"
  ],
  "bifpn_config": [
    "min_level",
    "max_level",
    "weight_method"
  ],
  "qufpn_config": [
    "min_level",
    "max_level",
    "weight_method"
  ],
  "get_fpn_config": [
    "fpn_name",
    "min_level",
    "max_level",
    "weight_method"
  ],
  "setup_model": [
    "model",
    "config"
  ],
  "init_experimental": [
    "config"
  ],
  "create_mask": [
    "pred_mask"
  ],
  "normalize": [
    "input_image",
    "input_mask"
  ],
  "load_image_train": [
    "datapoint"
  ],
  "load_image_test": [
    "datapoint"
  ],
  "add_n": [
    "nodes"
  ],
  "FNode": {
    "__init__": [
      "self",
      "feat_level",
      "inputs_offsets",
      "fpn_num_filters",
      "apply_bn_for_resampling",
      "is_training_bn",
      "conv_after_downsample",
      "conv_bn_act_pattern",
      "separable_conv",
      "act_type",
      "strategy",
      "weight_method",
      "data_format",
      "model_optimizations",
      "name"
    ],
    "fuse_features": [
      "self",
      "nodes"
    ],
    "_add_wsm": [
      "self",
      "initializer",
      "shape"
    ],
    "build": [
      "self",
      "feats_shape"
    ],
    "call": [
      "self",
      "feats",
      "training"
    ]
  },
  "OpAfterCombine": {
    "__init__": [
      "self",
      "is_training_bn",
      "conv_bn_act_pattern",
      "separable_conv",
      "fpn_num_filters",
      "act_type",
      "data_format",
      "strategy",
      "model_optimizations",
      "name"
    ],
    "call": [
      "self",
      "new_node",
      "training"
    ]
  },
  "ResampleFeatureMap": {
    "__init__": [
      "self",
      "feat_level",
      "target_num_channels",
      "apply_bn",
      "is_training_bn",
      "conv_after_downsample",
      "strategy",
      "data_format",
      "pooling_type",
      "upsampling_type",
      "model_optimizations",
      "name"
    ],
    "_pool2d": [
      "self",
      "inputs",
      "height",
      "width",
      "target_height",
      "target_width"
    ],
    "_upsample2d": [
      "self",
      "inputs",
      "target_height",
      "target_width",
      "training"
    ],
    "_maybe_apply_1x1": [
      "self",
      "feat",
      "training",
      "num_channels"
    ],
    "call": [
      "self",
      "feat",
      "training",
      "all_feats"
    ]
  },
  "ClassNet": {
    "__init__": [
      "self",
      "num_classes",
      "num_anchors",
      "num_filters",
      "min_level",
      "max_level",
      "is_training_bn",
      "act_type",
      "repeats",
      "separable_conv",
      "survival_prob",
      "strategy",
      "data_format",
      "grad_checkpoint",
      "name",
      "feature_only"
    ],
    "_conv_bn_act": [
      "self",
      "image",
      "i",
      "level_id",
      "training"
    ],
    "call": [
      "self",
      "inputs",
      "training"
    ],
    "conv2d_layer": [
      "cls",
      "separable_conv",
      "data_format"
    ],
    "classes_layer": [
      "cls",
      "conv2d_layer",
      "num_classes",
      "num_anchors",
      "name"
    ]
  },
  "BoxNet": {
    "__init__": [
      "self",
      "num_anchors",
      "num_filters",
      "min_level",
      "max_level",
      "is_training_bn",
      "act_type",
      "repeats",
      "separable_conv",
      "survival_prob",
      "strategy",
      "data_format",
      "grad_checkpoint",
      "name",
      "feature_only"
    ],
    "_conv_bn_act": [
      "self",
      "image",
      "i",
      "level_id",
      "training"
    ],
    "call": [
      "self",
      "inputs",
      "training"
    ],
    "boxes_layer": [
      "cls",
      "separable_conv",
      "num_anchors",
      "data_format",
      "name"
    ]
  },
  "SegmentationHead": {
    "__init__": [
      "self",
      "num_classes",
      "num_filters",
      "min_level",
      "max_level",
      "data_format",
      "is_training_bn",
      "act_type",
      "strategy",
      "name"
    ],
    "call": [
      "self",
      "feats",
      "training"
    ]
  },
  "FPNCells": {
    "__init__": [
      "self",
      "config",
      "name"
    ],
    "call": [
      "self",
      "feats",
      "training"
    ]
  },
  "FPNCell": {
    "__init__": [
      "self",
      "config",
      "name"
    ],
    "call": [
      "self",
      "feats",
      "training"
    ]
  },
  "EfficientDetNet": {
    "__init__": [
      "self",
      "model_name",
      "config",
      "name",
      "feature_only"
    ],
    "_init_set_name": [
      "self",
      "name",
      "zero_based"
    ],
    "call": [
      "self",
      "inputs",
      "training"
    ]
  },
  "EfficientDetModel": {
    "_preprocessing": [
      "self",
      "raw_images",
      "image_size",
      "mean_rgb",
      "stddev_rgb",
      "mode"
    ],
    "_postprocess": [
      "self",
      "cls_outputs",
      "box_outputs",
      "scales",
      "mode"
    ],
    "call": [
      "self",
      "inputs",
      "training",
      "pre_mode",
      "post_mode"
    ]
  },
  "HUB_CPT_NAME": [],
  "build_batch_norm": [
    "is_training_bn",
    "beta_initializer",
    "gamma_initializer",
    "data_format",
    "momentum",
    "epsilon",
    "strategy",
    "name"
  ],
  "average_name": [
    "ema",
    "var"
  ],
  "load_from_hub_checkpoint": [
    "model",
    "ckpt_path_or_file"
  ],
  "fp16_to_fp32_nested": [
    "input_nested"
  ],
  "LiteRunner": {
    "__init__": [
      "self",
      "tflite_model_path",
      "only_network"
    ],
    "run": [
      "self",
      "image"
    ]
  },
  "ExportNetwork": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self",
      "imgs"
    ]
  },
  "ExportModel": {
    "__init__": [
      "self",
      "model",
      "pre_mode",
      "post_mode"
    ],
    "__call__": [
      "self",
      "imgs"
    ]
  },
  "GridMask": {
    "__init__": [
      "self",
      "prob",
      "ratio",
      "rotate",
      "gridmask_size_ratio",
      "fill",
      "interpolation"
    ],
    "random_rotate": [
      "self",
      "mask"
    ],
    "crop": [
      "mask",
      "h",
      "w"
    ],
    "mask": [
      "self",
      "h",
      "w"
    ],
    "__call__": [
      "self",
      "image",
      "label"
    ]
  },
  "gridmask": [
    "image",
    "boxes",
    "prob",
    "ratio",
    "rotate",
    "gridmask_size_ratio",
    "fill"
  ],
  "_INVALID_BOX": [],
  "policy_v1": [],
  "policy_v2": [],
  "policy_v3": [],
  "random_shift_bbox": [
    "image",
    "bbox",
    "pixel_scaling",
    "replace",
    "new_min_bbox_coords"
  ],
  "_clip_bbox": [
    "min_y",
    "min_x",
    "max_y",
    "max_x"
  ],
  "_check_bbox_area": [
    "min_y",
    "min_x",
    "max_y",
    "max_x",
    "delta"
  ],
  "_scale_bbox_only_op_probability": [
    "prob"
  ],
  "_apply_bbox_augmentation": [
    "image",
    "bbox",
    "augmentation_func"
  ],
  "_concat_bbox": [
    "bbox",
    "bboxes"
  ],
  "_apply_bbox_augmentation_wrapper": [
    "image",
    "bbox",
    "new_bboxes",
    "prob",
    "augmentation_func",
    "func_changes_bbox"
  ],
  "_apply_multi_bbox_augmentation": [
    "image",
    "bboxes",
    "prob",
    "aug_func",
    "func_changes_bbox"
  ],
  "_apply_multi_bbox_augmentation_wrapper": [
    "image",
    "bboxes",
    "prob",
    "aug_func",
    "func_changes_bbox"
  ],
  "rotate_only_bboxes": [
    "image",
    "bboxes",
    "prob",
    "degrees",
    "replace"
  ],
  "shear_x_only_bboxes": [
    "image",
    "bboxes",
    "prob",
    "level",
    "replace"
  ],
  "shear_y_only_bboxes": [
    "image",
    "bboxes",
    "prob",
    "level",
    "replace"
  ],
  "translate_x_only_bboxes": [
    "image",
    "bboxes",
    "prob",
    "pixels",
    "replace"
  ],
  "translate_y_only_bboxes": [
    "image",
    "bboxes",
    "prob",
    "pixels",
    "replace"
  ],
  "flip_only_bboxes": [
    "image",
    "bboxes",
    "prob"
  ],
  "solarize_only_bboxes": [
    "image",
    "bboxes",
    "prob",
    "threshold"
  ],
  "equalize_only_bboxes": [
    "image",
    "bboxes",
    "prob"
  ],
  "cutout_only_bboxes": [
    "image",
    "bboxes",
    "prob",
    "pad_size",
    "replace"
  ],
  "_rotate_bbox": [
    "bbox",
    "image_height",
    "image_width",
    "degrees"
  ],
  "rotate_with_bboxes": [
    "image",
    "bboxes",
    "degrees",
    "replace"
  ],
  "_shift_bbox": [
    "bbox",
    "image_height",
    "image_width",
    "pixels",
    "shift_horizontal"
  ],
  "translate_bbox": [
    "image",
    "bboxes",
    "pixels",
    "replace",
    "shift_horizontal"
  ],
  "_shear_bbox": [
    "bbox",
    "image_height",
    "image_width",
    "level",
    "shear_horizontal"
  ],
  "shear_with_bboxes": [
    "image",
    "bboxes",
    "level",
    "replace",
    "shear_horizontal"
  ],
  "_cutout_inside_bbox": [
    "image",
    "bbox",
    "pad_fraction"
  ],
  "bbox_cutout": [
    "image",
    "bboxes",
    "pad_fraction",
    "replace_with_mean"
  ],
  "_bbox_cutout_level_to_arg": [
    "level",
    "hparams"
  ],
  "bbox_wrapper": [
    "func"
  ],
  "Mosaic": {
    "__init__": [
      "self",
      "out_size",
      "n_images",
      "_minimum_mosaic_image_dim"
    ],
    "n_images": [
      "self"
    ],
    "out_size": [
      "self"
    ],
    "_mosaic_divide_points": [
      "self"
    ],
    "_scale_box": [
      "box",
      "image",
      "mosaic_image"
    ],
    "_scale_images": [
      "self",
      "images",
      "mosaic_divide_points"
    ],
    "_mosaic": [
      "self",
      "images",
      "boxes",
      "mosaic_divide_points"
    ],
    "__call__": [
      "self",
      "images",
      "boxes"
    ]
  },
  "ArgMaxMatcher": {
    "__init__": [
      "self",
      "matched_threshold",
      "unmatched_threshold",
      "negatives_lower_than_unmatched",
      "force_match_for_each_row"
    ],
    "_match": [
      "self",
      "similarity_matrix"
    ],
    "_set_values_using_indicator": [
      "self",
      "x",
      "indicator",
      "val"
    ]
  },
  "EPSILON": [],
  "FasterRcnnBoxCoder": {
    "__init__": [
      "self",
      "scale_factors"
    ],
    "code_size": [
      "self"
    ],
    "_encode": [
      "self",
      "boxes",
      "anchors"
    ],
    "_decode": [
      "self",
      "rel_codes",
      "anchors"
    ]
  },
  "area": [
    "boxlist",
    "scope"
  ],
  "intersection": [
    "boxlist1",
    "boxlist2",
    "scope"
  ],
  "iou": [
    "boxlist1",
    "boxlist2",
    "scope"
  ],
  "RegionSimilarityCalculator": {
    "__metaclass__": [],
    "compare": [
      "self",
      "boxlist1",
      "boxlist2",
      "scope"
    ],
    "_compare": [
      "self",
      "boxlist1",
      "boxlist2"
    ]
  },
  "IouSimilarity": {
    "_compare": [
      "self",
      "boxlist1",
      "boxlist2"
    ]
  },
  "FASTER_RCNN": [],
  "KEYPOINT": [],
  "MEAN_STDDEV": [],
  "SQUARE": [],
  "BoxCoder": {
    "__metaclass__": [],
    "code_size": [
      "self"
    ],
    "encode": [
      "self",
      "boxes",
      "anchors"
    ],
    "decode": [
      "self",
      "rel_codes",
      "anchors"
    ],
    "_encode": [
      "self",
      "boxes",
      "anchors"
    ],
    "_decode": [
      "self",
      "rel_codes",
      "anchors"
    ]
  },
  "batch_decode": [
    "encoded_boxes",
    "box_coder",
    "anchors"
  ],
  "KEYPOINTS_FIELD_NAME": [],
  "TargetAssigner": {
    "__init__": [
      "self",
      "similarity_calc",
      "matcher",
      "box_coder",
      "negative_class_weight",
      "unmatched_cls_target"
    ],
    "box_coder": [
      "self"
    ],
    "assign": [
      "self",
      "anchors",
      "groundtruth_boxes",
      "groundtruth_labels",
      "groundtruth_weights"
    ],
    "_reset_target_shape": [
      "self",
      "target",
      "num_anchors"
    ],
    "_create_regression_targets": [
      "self",
      "anchors",
      "groundtruth_boxes",
      "match"
    ],
    "_default_regression_target": [
      "self"
    ],
    "_create_classification_targets": [
      "self",
      "groundtruth_labels",
      "match"
    ],
    "_create_regression_weights": [
      "self",
      "match",
      "groundtruth_weights"
    ],
    "_create_classification_weights": [
      "self",
      "match",
      "groundtruth_weights"
    ],
    "get_box_coder": [
      "self"
    ]
  },
  "Match": {
    "__init__": [
      "self",
      "match_results"
    ],
    "match_results": [
      "self"
    ],
    "matched_column_indices": [
      "self"
    ],
    "matched_column_indicator": [
      "self"
    ],
    "num_matched_columns": [
      "self"
    ],
    "unmatched_column_indices": [
      "self"
    ],
    "unmatched_column_indicator": [
      "self"
    ],
    "num_unmatched_columns": [
      "self"
    ],
    "ignored_column_indices": [
      "self"
    ],
    "ignored_column_indicator": [
      "self"
    ],
    "num_ignored_columns": [
      "self"
    ],
    "unmatched_or_ignored_column_indices": [
      "self"
    ],
    "matched_row_indices": [
      "self"
    ],
    "_reshape_and_cast": [
      "self",
      "t"
    ],
    "gather_based_on_match": [
      "self",
      "input_tensor",
      "unmatched_value",
      "ignored_value"
    ]
  },
  "Matcher": {
    "__metaclass__": [],
    "match": [
      "self",
      "similarity_matrix",
      "scope"
    ],
    "_match": [
      "self",
      "similarity_matrix"
    ]
  },
  "_flip_boxes_left_right": [
    "boxes"
  ],
  "_flip_masks_left_right": [
    "masks"
  ],
  "keypoint_flip_horizontal": [
    "keypoints",
    "flip_point",
    "flip_permutation",
    "scope"
  ],
  "random_horizontal_flip": [
    "image",
    "boxes",
    "masks",
    "keypoints",
    "keypoint_flip_permutation",
    "seed"
  ],
  "_compute_new_static_size": [
    "image",
    "min_dimension",
    "max_dimension"
  ],
  "_compute_new_dynamic_size": [
    "image",
    "min_dimension",
    "max_dimension"
  ],
  "resize_to_range": [
    "image",
    "masks",
    "min_dimension",
    "max_dimension",
    "method",
    "align_corners",
    "pad_to_max_dimension"
  ],
  "_copy_extra_fields": [
    "boxlist_to_copy_to",
    "boxlist_to_copy_from"
  ],
  "box_list_scale": [
    "boxlist",
    "y_scale",
    "x_scale",
    "scope"
  ],
  "keypoint_scale": [
    "keypoints",
    "y_scale",
    "x_scale",
    "scope"
  ],
  "scale_boxes_to_pixel_coordinates": [
    "image",
    "boxes",
    "keypoints"
  ],
  "_get_source_id_from_encoded_image": [
    "parsed_tensors"
  ],
  "TfExampleDecoder": {
    "__init__": [
      "self",
      "include_mask",
      "regenerate_source_id"
    ],
    "_decode_image": [
      "self",
      "parsed_tensors"
    ],
    "_decode_boxes": [
      "self",
      "parsed_tensors"
    ],
    "_decode_masks": [
      "self",
      "parsed_tensors"
    ],
    "_decode_areas": [
      "self",
      "parsed_tensors"
    ],
    "decode": [
      "self",
      "serialized_example"
    ]
  },
  "BoxList": {
    "__init__": [
      "self",
      "boxes"
    ],
    "num_boxes": [
      "self"
    ],
    "num_boxes_static": [
      "self"
    ],
    "get_all_fields": [
      "self"
    ],
    "get_extra_fields": [
      "self"
    ],
    "add_field": [
      "self",
      "field",
      "field_data"
    ],
    "has_field": [
      "self",
      "field"
    ],
    "get": [
      "self"
    ],
    "set": [
      "self",
      "boxes"
    ],
    "get_field": [
      "self",
      "field"
    ],
    "set_field": [
      "self",
      "field",
      "value"
    ],
    "get_center_coordinates_and_sizes": [
      "self",
      "scope"
    ],
    "transpose_coordinates": [
      "self",
      "scope"
    ],
    "as_tensor_dict": [
      "self",
      "fields"
    ]
  },
  "MOVIELENS_1M_URL": [],
  "MOVIELENS_ZIP_FILENAME": [],
  "MOVIELENS_ZIP_HASH": [],
  "MOVIELENS_EXTRACTED_DIR": [],
  "RATINGS_FILE_NAME": [],
  "MOVIES_FILE_NAME": [],
  "RATINGS_DATA_COLUMNS": [],
  "MOVIES_DATA_COLUMNS": [],
  "OUTPUT_TRAINING_DATA_FILENAME": [],
  "OUTPUT_TESTING_DATA_FILENAME": [],
  "OUTPUT_MOVIE_VOCAB_FILENAME": [],
  "OUTPUT_MOVIE_YEAR_VOCAB_FILENAME": [],
  "OUTPUT_MOVIE_GENRE_VOCAB_FILENAME": [],
  "OUTPUT_MOVIE_TITLE_UNIGRAM_VOCAB_FILENAME": [],
  "OUTPUT_MOVIE_TITLE_BIGRAM_VOCAB_FILENAME": [],
  "PAD_MOVIE_ID": [],
  "PAD_RATING": [],
  "PAD_MOVIE_YEAR": [],
  "UNKNOWN_STR": [],
  "VOCAB_MOVIE_ID_INDEX": [],
  "VOCAB_COUNT_INDEX": [],
  "MovieInfo": {
    "__slots__": [],
    "__new__": [
      "cls",
      "movie_id",
      "timestamp",
      "rating",
      "title",
      "genres"
    ]
  },
  "download_and_extract_data": [
    "data_directory",
    "url",
    "fname",
    "file_hash",
    "extracted_dir_name"
  ],
  "read_data": [
    "data_directory",
    "min_rating"
  ],
  "convert_to_timelines": [
    "ratings_df"
  ],
  "generate_movies_dict": [
    "movies_df"
  ],
  "extract_year_from_title": [
    "title"
  ],
  "generate_feature_of_movie_years": [
    "movies_dict",
    "movies"
  ],
  "generate_movie_genres": [
    "movies_dict",
    "movies"
  ],
  "_pad_or_truncate_movie_feature": [
    "feature",
    "max_len",
    "pad_value"
  ],
  "generate_examples_from_single_timeline": [
    "timeline",
    "movies_dict",
    "max_context_len",
    "max_context_movie_genre_len"
  ],
  "generate_examples_from_timelines": [
    "timelines",
    "movies_df",
    "min_timeline_len",
    "max_context_len",
    "max_context_movie_genre_len",
    "train_data_fraction",
    "random_seed",
    "shuffle"
  ],
  "generate_movie_feature_vocabs": [
    "movies_df",
    "movie_counts"
  ],
  "write_tfrecords": [
    "tf_examples",
    "filename"
  ],
  "write_vocab_json": [
    "vocab",
    "filename"
  ],
  "write_vocab_txt": [
    "vocab",
    "filename"
  ],
  "generate_datasets": [
    "extracted_data_dir",
    "output_dir",
    "min_timeline_length",
    "max_context_length",
    "max_context_movie_genre_length",
    "min_rating",
    "build_vocabs",
    "train_data_fraction",
    "train_filename",
    "test_filename",
    "vocab_filename",
    "vocab_year_filename",
    "vocab_genre_filename"
  ],
  "_sym_db": [],
  "DESCRIPTOR": [],
  "_FEATURETYPE": [],
  "FeatureType": [],
  "_ENCODERTYPE": [],
  "EncoderType": [],
  "STRING": [],
  "INT": [],
  "FLOAT": [],
  "BOW": [],
  "CNN": [],
  "LSTM": [],
  "_FEATURE": [],
  "_FEATUREGROUP": [],
  "_INPUTCONFIG": [],
  "Feature": [],
  "FeatureGroup": [],
  "InputConfig": [],
  "ModelConfig": {},
  "safe_div": [
    "x",
    "y"
  ],
  "ContextEncoder": {
    "__init__": [
      "self",
      "input_config",
      "model_config"
    ],
    "call": [
      "self",
      "input_context"
    ]
  },
  "FeatureGroupEncoder": {
    "__init__": [
      "self",
      "feature_group",
      "model_config",
      "final_embedding_dim"
    ],
    "call": [
      "self",
      "input_context"
    ]
  },
  "BatchSoftmax": {
    "__init__": [
      "self",
      "name"
    ],
    "call": [
      "self",
      "y_true",
      "y_pred"
    ]
  },
  "GlobalSoftmax": {
    "__init__": [
      "self",
      "name"
    ],
    "call": [
      "self",
      "y_true",
      "y_pred"
    ]
  },
  "LabelEncoder": {
    "__init__": [
      "self",
      "input_config"
    ],
    "label_name": [
      "self"
    ],
    "encode": [
      "self",
      "input_label"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "_get_batch_similarities": [
    "batch_label",
    "full_vocab_similarities"
  ],
  "BatchRecall": {
    "__init__": [
      "self",
      "top_k",
      "name"
    ],
    "update_state": [
      "self",
      "y_true",
      "y_pred",
      "sample_weight"
    ]
  },
  "GlobalRecall": {
    "__init__": [
      "self",
      "top_k",
      "name"
    ],
    "update_state": [
      "self",
      "y_true",
      "y_pred",
      "sample_weight"
    ]
  },
  "BatchMeanRank": {
    "__init__": [
      "self",
      "name"
    ],
    "update_state": [
      "self",
      "y_true",
      "y_pred",
      "sample_weight"
    ]
  },
  "GlobalMeanRank": {
    "__init__": [
      "self",
      "name"
    ],
    "update_state": [
      "self",
      "y_true",
      "y_pred",
      "sample_weight"
    ]
  },
  "TFGradient": [],
  "Scalar": [],
  "GetShardFilenames": [
    "filepattern"
  ],
  "ClipGradient": [
    "grads_and_vars",
    "clip_val",
    "include_histogram_summary"
  ],
  "DotProductSimilarity": {
    "call": [
      "self",
      "context_embeddings",
      "label_embeddings",
      "top_k"
    ]
  },
  "INT_DEFAULT_VALUE": [],
  "STRING_DEFAULT_VALUE": [],
  "FLOAT_DEFAULT_VALUE": [],
  "FeaturesAndVocabsByName": {
    "__slots__": [],
    "__new__": [
      "cls",
      "features_by_name",
      "vocabs_by_name"
    ]
  },
  "_prepare_feature_vocab_table": [
    "feature",
    "vocab_file_dir"
  ],
  "_get_features_vocabs_for_groups": [
    "feature_groups",
    "vocab_file_dir"
  ],
  "get_features_and_vocabs_by_name": [
    "input_config",
    "vocab_file_dir"
  ],
  "_get_feature_spec": [
    "feature_type",
    "feature_length"
  ],
  "_get_serving_feature_spec": [
    "feature_name",
    "feature_type",
    "feature_length"
  ],
  "get_serving_input_specs": [
    "input_config"
  ],
  "decode_example": [
    "serialized_proto",
    "features_and_vocabs_by_name",
    "label_feature_name"
  ],
  "get_input_dataset": [
    "data_filepattern",
    "input_config",
    "vocab_file_dir",
    "batch_size"
  ],
  "RecommendationModel": {
    "__init__": [
      "self",
      "input_config",
      "model_config"
    ],
    "call": [
      "self",
      "inputs"
    ],
    "serve": [
      "self"
    ]
  },
  "SimpleCheckpoint": {
    "__init__": [
      "self",
      "checkpoint_manager"
    ],
    "on_epoch_end": [
      "self",
      "epoch",
      "logs"
    ]
  },
  "_get_optimizer": [
    "learning_rate",
    "gradient_clip_norm"
  ],
  "_get_metrics": [
    "eval_top_k"
  ],
  "compile_model": [
    "model",
    "eval_top_k",
    "learning_rate",
    "gradient_clip_norm"
  ],
  "build_keras_model": [
    "input_config",
    "model_config"
  ],
  "train_and_eval": [
    "model",
    "model_dir",
    "train_input_dataset",
    "eval_input_dataset",
    "steps_per_epoch",
    "epochs",
    "eval_steps"
  ],
  "save_model": [
    "checkpoint_path",
    "export_dir",
    "input_config",
    "model_config"
  ],
  "export_tflite": [
    "export_dir"
  ],
  "export": [
    "checkpoint_path",
    "input_config",
    "model_config",
    "export_dir"
  ],
  "load_input_config": [],
  "prepare_model_config": [],
  "download_demo_data": [],
  "run": [
    "data_dir",
    "export_dir",
    "spec"
  ],
  "download_data": [
    "download_dir"
  ],
  "get_input_spec": [
    "encoder_type",
    "num_classes"
  ],
  "get_model_hparams": [],
  "_define_flags": [],
  "_download_dataset": [
    "filename",
    "url",
    "extracted_folder_name"
  ],
  "download_bird_dataset": [],
  "download_speech_commands_dataset": [],
  "download_esc50_dataset": [],
  "DataLoader": {
    "create": [
      "cls",
      "spec",
      "is_training",
      "shuffle"
    ]
  },
  "BinaryClassificationBaseSpec": {
    "compat_tf_versions": [],
    "__init__": [
      "self",
      "model_dir",
      "strategy"
    ],
    "create_model": [
      "self"
    ],
    "run_classifier": [
      "self",
      "model",
      "epochs",
      "train_ds",
      "train_steps",
      "validation_ds",
      "validation_steps"
    ],
    "preprocess_ds": [
      "self",
      "ds",
      "is_training"
    ]
  },
  "Spec": {
    "preprocess_ds": [
      "self",
      "ds",
      "is_training"
    ],
    "create_model": [
      "self"
    ],
    "run_classifier": [
      "self",
      "model",
      "epochs",
      "train_ds",
      "train_steps",
      "validation_ds"
    ]
  },
  "BinaryClassifier": {
    "__init__": [
      "self",
      "spec",
      "shuffle"
    ],
    "train": [
      "self",
      "train_data",
      "validation_data",
      "epochs",
      "batch_size"
    ],
    "evaluate": [
      "self",
      "data",
      "batch_size"
    ],
    "evaluate_tflite": [
      "self",
      "tflite_filepath",
      "data"
    ]
  },
  "train_xor_model": [
    "export_dir"
  ],
  "_DEFAULT_TF_BEHAVIOR": [],
  "_tf_behavior_version": [],
  "setup_tf_behavior": [
    "tf_version"
  ],
  "get_tf_behavior": [],
  "get_compat_tf_versions": [
    "compat_tf_versions"
  ],
  "ExportFormat": {
    "TFLITE": [],
    "SAVED_MODEL": [],
    "LABEL": [],
    "VOCAB": [],
    "TFJS": []
  },
  "load_json_file": [
    "json_file"
  ],
  "write_json_file": [
    "json_file",
    "data"
  ],
  "test_srcdir": [],
  "get_test_data_path": [
    "file_or_dirname"
  ],
  "get_cache_dir": [
    "temp_dir",
    "filename"
  ],
  "test_in_tf_1": [
    "fn"
  ],
  "test_in_tf_2": [
    "fn"
  ],
  "test_in_tf_1and2": [
    "fn"
  ],
  "get_dataloader": [
    "data_size",
    "input_shape",
    "num_classes",
    "max_input_value"
  ],
  "create_pascal_voc": [
    "temp_dir"
  ],
  "is_same_output": [
    "tflite_file",
    "keras_model",
    "input_tensors",
    "model_spec",
    "atol"
  ],
  "ClassificationModel": {
    "DEFAULT_EXPORT_FORMAT": [],
    "ALLOWED_EXPORT_FORMAT": [],
    "__init__": [
      "self",
      "model_spec",
      "index_to_label",
      "shuffle",
      "train_whole_model"
    ],
    "evaluate": [
      "self",
      "data",
      "batch_size"
    ],
    "predict_top_k": [
      "self",
      "data",
      "k",
      "batch_size"
    ],
    "_export_labels": [
      "self",
      "label_filepath"
    ],
    "evaluate_tflite": [
      "self",
      "tflite_filepath",
      "data",
      "postprocess_fn"
    ]
  },
  "ObjectDetector": {
    "ALLOWED_EXPORT_FORMAT": [],
    "__init__": [
      "self",
      "model_spec",
      "label_map",
      "representative_data"
    ],
    "create_model": [
      "self"
    ],
    "_get_dataset_and_steps": [
      "self",
      "data",
      "batch_size",
      "is_training"
    ],
    "train": [
      "self",
      "train_data",
      "validation_data",
      "epochs",
      "batch_size"
    ],
    "evaluate": [
      "self",
      "data",
      "batch_size"
    ],
    "evaluate_tflite": [
      "self",
      "tflite_filepath",
      "data"
    ],
    "_export_saved_model": [
      "self",
      "saved_model_dir"
    ],
    "_export_tflite": [
      "self",
      "tflite_filepath",
      "quantization_config",
      "with_metadata",
      "export_metadata_json_file"
    ],
    "_export_labels": [
      "self",
      "label_filepath"
    ],
    "create": [
      "cls",
      "train_data",
      "model_spec",
      "validation_data",
      "epochs",
      "batch_size",
      "train_whole_model",
      "do_train"
    ]
  },
  "create": [],
  "HParams": {},
  "get_default_hparams": [],
  "ESTIMITED_STEPS_PER_EPOCH": [],
  "set_batch_size": [
    "model",
    "batch_size"
  ],
  "get_steps_per_epoch": [
    "steps_per_epoch",
    "batch_size",
    "train_data"
  ],
  "_create_temp_dir": [
    "convert_from_saved_model"
  ],
  "DummyContextManager": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "export_labels": [
    "filepath",
    "index_to_label"
  ],
  "export_saved_model": [
    "model",
    "filepath",
    "overwrite",
    "include_optimizer",
    "save_format",
    "signatures",
    "options"
  ],
  "get_lite_runner": [
    "tflite_filepath",
    "model_spec"
  ],
  "_get_input_tensor": [
    "input_tensors",
    "input_details",
    "i"
  ],
  "export_tfjs": [
    "keras_or_saved_model",
    "output_dir",
    "tflite_filepath"
  ],
  "load_tfjs_keras_model": [
    "model_path"
  ],
  "extract_tflite_metadata_json": [
    "tflite_filepath"
  ],
  "_get_params": [
    "f"
  ],
  "CustomModel": {
    "DEFAULT_EXPORT_FORMAT": [],
    "ALLOWED_EXPORT_FORMAT": [],
    "__init__": [
      "self",
      "model_spec",
      "shuffle"
    ],
    "train": [
      "self",
      "train_data",
      "validation_data"
    ],
    "summary": [
      "self"
    ],
    "evaluate": [
      "self",
      "data"
    ],
    "_get_default_export_format": [
      "self"
    ],
    "_get_export_format": [
      "self",
      "export_format"
    ],
    "export": [
      "self",
      "export_dir",
      "tflite_filename",
      "label_filename",
      "vocab_filename",
      "saved_model_filename",
      "tfjs_folder_name",
      "export_format"
    ],
    "create_serving_model": [
      "self"
    ],
    "_export_saved_model": [
      "self",
      "filepath",
      "overwrite",
      "include_optimizer",
      "save_format",
      "signatures",
      "options"
    ],
    "_export_tflite": [
      "self",
      "tflite_filepath",
      "quantization_config"
    ],
    "_export_tfjs": [
      "self",
      "tfjs_filepath",
      "tflite_filepath"
    ],
    "_keras_callbacks": [
      "self",
      "model_dir"
    ]
  },
  "Recommendation": {
    "DEFAULT_EXPORT_FORMAT": [],
    "ALLOWED_EXPORT_FORMAT": [],
    "OOV_ID": [],
    "__init__": [
      "self",
      "model_spec",
      "model_dir",
      "shuffle",
      "learning_rate",
      "gradient_clip_norm"
    ],
    "input_spec": [
      "self"
    ],
    "model_hparams": [
      "self"
    ],
    "create_model": [
      "self",
      "do_train"
    ],
    "train": [
      "self",
      "train_data",
      "validation_data",
      "batch_size",
      "steps_per_epoch",
      "epochs"
    ],
    "evaluate": [
      "self",
      "data",
      "batch_size"
    ],
    "_keras_callbacks": [
      "self",
      "model_dir"
    ],
    "_get_serve_fn": [
      "self",
      "keras_model"
    ],
    "_export_tflite": [
      "self",
      "tflite_filepath"
    ],
    "_export_saved_model": [
      "self",
      "filepath"
    ],
    "evaluate_tflite": [
      "self",
      "tflite_filepath",
      "data"
    ],
    "create": [
      "cls",
      "train_data",
      "model_spec",
      "model_dir",
      "validation_data",
      "batch_size",
      "steps_per_epoch",
      "epochs",
      "learning_rate",
      "gradient_clip_norm",
      "shuffle",
      "do_train"
    ]
  },
  "DEFAULT_QUANTIZATION_STEPS": [],
  "_get_representative_dataset_gen": [
    "dataset",
    "num_steps"
  ],
  "QuantizationConfig": {
    "__init__": [
      "self",
      "optimizations",
      "representative_data",
      "quantization_steps",
      "inference_input_type",
      "inference_output_type",
      "supported_ops",
      "supported_types",
      "experimental_new_quantizer"
    ],
    "for_dynamic": [
      "cls"
    ],
    "for_int8": [
      "cls",
      "representative_data",
      "quantization_steps",
      "inference_input_type",
      "inference_output_type",
      "supported_ops"
    ],
    "for_float16": [
      "cls"
    ],
    "get_converter_with_quantization": [
      "self",
      "converter"
    ]
  },
  "QuantizationConfigType": [],
  "get_hub_lib_hparams": [],
  "_get_model_info": [
    "model_spec",
    "num_classes",
    "quantization_config",
    "version"
  ],
  "ImageClassifier": {
    "__init__": [
      "self",
      "model_spec",
      "index_to_label",
      "shuffle",
      "hparams",
      "use_augmentation",
      "representative_data"
    ],
    "_get_tflite_input_tensors": [
      "self",
      "input_tensors"
    ],
    "create_model": [
      "self",
      "hparams",
      "with_loss_and_metrics"
    ],
    "train": [
      "self",
      "train_data",
      "validation_data",
      "hparams",
      "steps_per_epoch"
    ],
    "_export_tflite": [
      "self",
      "tflite_filepath",
      "quantization_config",
      "with_metadata",
      "export_metadata_json_file"
    ],
    "_get_hparams_or_default": [
      "self",
      "hparams"
    ],
    "create": [
      "cls",
      "train_data",
      "model_spec",
      "validation_data",
      "batch_size",
      "epochs",
      "steps_per_epoch",
      "train_whole_model",
      "dropout_rate",
      "learning_rate",
      "momentum",
      "shuffle",
      "use_augmentation",
      "use_hub_library",
      "warmup_steps",
      "model_dir",
      "do_train"
    ]
  },
  "DEFAULT_DECAY_SAMPLES": [],
  "DEFAULT_WARMUP_EPOCHS": [],
  "add_params": [
    "hparams"
  ],
  "create_optimizer": [
    "init_lr",
    "num_decay_steps",
    "num_warmup_steps"
  ],
  "get_default_callbacks": [
    "model_dir"
  ],
  "hub_train_model": [
    "model",
    "hparams",
    "train_ds",
    "validation_ds",
    "steps_per_epoch"
  ],
  "train_model": [
    "model",
    "hparams",
    "train_ds",
    "validation_ds",
    "steps_per_epoch"
  ],
  "ModelSpecificInfo": {
    "__init__": [
      "self",
      "name",
      "version",
      "image_width",
      "image_height",
      "image_min",
      "image_max",
      "mean",
      "std",
      "num_classes",
      "author"
    ]
  },
  "_MODEL_INFO": [],
  "MetadataPopulatorForImageClassifier": {
    "__init__": [
      "self",
      "model_file",
      "model_info",
      "label_file_path"
    ],
    "populate": [
      "self"
    ],
    "_create_metadata": [
      "self"
    ],
    "_populate_metadata": [
      "self"
    ]
  },
  "HubKerasLayerV1V2": {
    "_setup_layer": [
      "self",
      "trainable"
    ],
    "_check_trainability": [
      "self"
    ],
    "_setup_layer_v1": [
      "self",
      "trainable"
    ],
    "_check_trainability_v1": [
      "self"
    ]
  },
  "QuestionAnswer": {
    "DEFAULT_EXPORT_FORMAT": [],
    "ALLOWED_EXPORT_FORMAT": [],
    "train": [
      "self",
      "train_data",
      "epochs",
      "batch_size",
      "steps_per_epoch"
    ],
    "create_model": [
      "self"
    ],
    "evaluate": [
      "self",
      "data",
      "max_answer_length",
      "null_score_diff_threshold",
      "verbose_logging",
      "output_dir"
    ],
    "evaluate_tflite": [
      "self",
      "tflite_filepath",
      "data",
      "max_answer_length",
      "null_score_diff_threshold",
      "verbose_logging",
      "output_dir"
    ],
    "_export_tflite": [
      "self",
      "tflite_filepath",
      "quantization_config",
      "with_metadata",
      "export_metadata_json_file"
    ],
    "create": [
      "cls",
      "train_data",
      "model_spec",
      "batch_size",
      "epochs",
      "steps_per_epoch",
      "shuffle",
      "do_train"
    ]
  },
  "_get_bert_model_info": [
    "model_spec",
    "vocab_file",
    "label_file"
  ],
  "TextClassifier": {
    "DEFAULT_EXPORT_FORMAT": [],
    "ALLOWED_EXPORT_FORMAT": [],
    "__init__": [
      "self",
      "model_spec",
      "index_to_label",
      "shuffle"
    ],
    "create_model": [
      "self",
      "with_loss_and_metrics"
    ],
    "train": [
      "self",
      "train_data",
      "validation_data",
      "epochs",
      "batch_size",
      "steps_per_epoch"
    ],
    "_export_tflite": [
      "self",
      "tflite_filepath",
      "quantization_config",
      "with_metadata",
      "export_metadata_json_file"
    ],
    "create": [
      "cls",
      "train_data",
      "model_spec",
      "validation_data",
      "batch_size",
      "epochs",
      "steps_per_epoch",
      "shuffle",
      "do_train"
    ]
  },
  "_USE_RESPONSE_ENCODING_INDEX": [],
  "Tree": {},
  "ScoreAH": {},
  "ScoreBruteForce": {},
  "ScaNNOptions": {},
  "Searcher": {
    "__init__": [
      "self",
      "serialized_scann_path",
      "metadata",
      "embedder_path"
    ],
    "create_from_server_scann": [
      "cls",
      "serialized_scann_path",
      "metadata",
      "embedder_path"
    ],
    "create_from_data": [
      "cls",
      "data",
      "scann_options",
      "cache_dir"
    ],
    "export": [
      "self",
      "export_format",
      "export_filename",
      "userinfo",
      "compression"
    ]
  },
  "Preprocessor": {
    "__init__": [
      "self",
      "input_shape",
      "num_classes",
      "mean_rgb",
      "stddev_rgb",
      "use_augmentation"
    ],
    "__call__": [
      "self",
      "image",
      "label",
      "is_training"
    ],
    "_preprocess_with_augmentation": [
      "self",
      "image",
      "label",
      "is_training"
    ],
    "_preprocess_without_augmentation": [
      "self",
      "image",
      "label"
    ]
  },
  "AudioClassifier": {
    "DEFAULT_EXPORT_FORMAT": [],
    "ALLOWED_EXPORT_FORMAT": [],
    "train": [
      "self",
      "train_data",
      "validation_data",
      "epochs",
      "batch_size"
    ],
    "create_model": [
      "self",
      "num_classes",
      "train_whole_model"
    ],
    "_export_tflite": [
      "self",
      "tflite_filepath",
      "with_metadata",
      "export_metadata_json_file",
      "quantization_config"
    ],
    "confusion_matrix": [
      "self",
      "data",
      "batch_size"
    ],
    "create": [
      "cls",
      "train_data",
      "model_spec",
      "validation_data",
      "batch_size",
      "epochs",
      "model_dir",
      "do_train",
      "train_whole_model"
    ]
  },
  "MetadataWriter": {
    "__init__": [
      "self",
      "model_file",
      "export_directory",
      "associated_files"
    ],
    "populate": [
      "self",
      "export_metadata_json_file"
    ],
    "_create_metadata": [
      "self"
    ],
    "_get_subgraph": [
      "self"
    ],
    "_get_input_tensor_names": [
      "self"
    ],
    "_get_output_tensor_names": [
      "self"
    ],
    "_order_tensor_metadata_with_names": [
      "self",
      "tensor_metadata",
      "tensor_names",
      "ordered_tensor_names"
    ],
    "_populate_metadata": [
      "self",
      "export_metadata_json_file"
    ]
  },
  "Tokenizer": {
    "BERT_TOKENIZER": [],
    "SENTENCE_PIECE": []
  },
  "bert_qa_inputs": [
    "ids_name",
    "mask_name",
    "segment_ids_name"
  ],
  "MetadataPopulatorForBert": {
    "__init__": [
      "self",
      "model_file",
      "export_directory",
      "model_info"
    ],
    "_create_metadata": [
      "self"
    ],
    "_create_input_metadata": [
      "self"
    ],
    "_create_output_metadata": [
      "self"
    ],
    "_create_bert_tokenizer": [
      "self"
    ],
    "_create_sentence_piece_tokenizer": [
      "self"
    ]
  },
  "ClassifierSpecificInfo": {
    "__init__": [
      "self",
      "name",
      "version",
      "description",
      "input_names",
      "tokenizer_type",
      "label_file",
      "vocab_file",
      "sp_model"
    ]
  },
  "DEFAULT_DESCRIPTION": [],
  "MetadataPopulatorForBertTextClassifier": {
    "__init__": [
      "self",
      "model_file",
      "export_directory",
      "model_info"
    ],
    "_create_output_metadata": [
      "self"
    ]
  },
  "bert_qa_outputs": [
    "start_logits_name",
    "end_logits_name"
  ],
  "QuestionAnswererInfo": {
    "__init__": [
      "self",
      "name",
      "version",
      "description",
      "input_names",
      "output_names",
      "tokenizer_type",
      "vocab_file",
      "sp_model"
    ]
  },
  "DEFAULT_INPUT_NAMES": [],
  "DEFAULT_OUTPUT_NAMES": [],
  "MetadataPopulatorForBertQuestionAndAnswer": {
    "_create_output_metadata": [
      "self"
    ]
  },
  "DEFAULT_LABEL_FILE": [],
  "DEFAULT_VOCAB_FILE": [],
  "DEFAULT_DELIM_REGEX_PATTERN": [],
  "MetadataPopulatorForTextClassifier": {
    "__init__": [
      "self",
      "model_file",
      "export_directory",
      "model_info",
      "label_file_path",
      "vocab_file_path"
    ],
    "_create_metadata": [
      "self"
    ]
  },
  "AverageWordVecModelSpec": {
    "PAD": [],
    "START": [],
    "UNKNOWN": [],
    "compat_tf_versions": [],
    "need_gen_vocab": [],
    "convert_from_saved_model_tf2": [],
    "__init__": [
      "self",
      "num_words",
      "seq_len",
      "wordvec_dim",
      "lowercase",
      "dropout_rate",
      "name",
      "default_training_epochs",
      "default_batch_size",
      "model_dir",
      "index_to_label"
    ],
    "get_name_to_features": [
      "self"
    ],
    "select_data_from_record": [
      "self",
      "record"
    ],
    "convert_examples_to_features": [
      "self",
      "examples",
      "tfrecord_file",
      "label_names"
    ],
    "create_model": [
      "self",
      "num_classes",
      "optimizer",
      "with_loss_and_metrics"
    ],
    "run_classifier": [
      "self",
      "train_ds",
      "validation_ds",
      "epochs",
      "steps_per_epoch",
      "num_classes"
    ],
    "gen_vocab": [
      "self",
      "examples"
    ],
    "preprocess": [
      "self",
      "raw_text"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "save_vocab": [
      "self",
      "vocab_filename"
    ],
    "load_vocab": [
      "self",
      "vocab_filename"
    ],
    "get_config": [
      "self"
    ],
    "get_default_quantization_config": [
      "self"
    ]
  },
  "create_classifier_model": [
    "bert_config",
    "num_labels",
    "max_seq_length",
    "initializer",
    "hub_module_url",
    "hub_module_trainable",
    "is_tf2"
  ],
  "BertModelSpec": {
    "compat_tf_versions": [],
    "need_gen_vocab": [],
    "convert_from_saved_model_tf2": [],
    "__init__": [
      "self",
      "uri",
      "model_dir",
      "seq_len",
      "dropout_rate",
      "initializer_range",
      "learning_rate",
      "distribution_strategy",
      "num_gpus",
      "tpu",
      "trainable",
      "do_lower_case",
      "is_tf2",
      "name",
      "tflite_input_name",
      "default_batch_size"
    ],
    "get_default_quantization_config": [
      "self"
    ],
    "reorder_input_details": [
      "self",
      "tflite_input_details"
    ],
    "build": [
      "self"
    ],
    "save_vocab": [
      "self",
      "vocab_filename"
    ]
  },
  "BertClassifierModelSpec": {
    "__init__": [
      "self",
      "uri",
      "model_dir",
      "seq_len",
      "dropout_rate",
      "initializer_range",
      "learning_rate",
      "distribution_strategy",
      "num_gpus",
      "tpu",
      "trainable",
      "do_lower_case",
      "is_tf2",
      "name",
      "tflite_input_name",
      "default_batch_size",
      "index_to_label"
    ],
    "get_name_to_features": [
      "self"
    ],
    "select_data_from_record": [
      "self",
      "record"
    ],
    "convert_examples_to_features": [
      "self",
      "examples",
      "tfrecord_file",
      "label_names"
    ],
    "create_model": [
      "self",
      "num_classes",
      "optimizer",
      "with_loss_and_metrics"
    ],
    "run_classifier": [
      "self",
      "train_ds",
      "validation_ds",
      "epochs",
      "steps_per_epoch",
      "num_classes"
    ],
    "get_config": [
      "self"
    ]
  },
  "dump_to_files": [
    "all_predictions",
    "all_nbest_json",
    "scores_diff_json",
    "version_2_with_negative",
    "output_dir"
  ],
  "create_qa_model": [
    "bert_config",
    "max_seq_length",
    "initializer",
    "hub_module_url",
    "hub_module_trainable",
    "is_tf2"
  ],
  "create_qa_model_from_squad": [
    "max_seq_length",
    "hub_module_url",
    "hub_module_trainable",
    "is_tf2"
  ],
  "BertQAModelSpec": {
    "__init__": [
      "self",
      "uri",
      "model_dir",
      "seq_len",
      "query_len",
      "doc_stride",
      "dropout_rate",
      "initializer_range",
      "learning_rate",
      "distribution_strategy",
      "num_gpus",
      "tpu",
      "trainable",
      "predict_batch_size",
      "do_lower_case",
      "is_tf2",
      "tflite_input_name",
      "tflite_output_name",
      "init_from_squad_model",
      "default_batch_size",
      "name"
    ],
    "get_name_to_features": [
      "self",
      "is_training"
    ],
    "select_data_from_record": [
      "self",
      "record"
    ],
    "get_config": [
      "self"
    ],
    "convert_examples_to_features": [
      "self",
      "examples",
      "is_training",
      "output_fn",
      "batch_size"
    ],
    "create_model": [
      "self"
    ],
    "train": [
      "self",
      "train_ds",
      "epochs",
      "steps_per_epoch"
    ],
    "_predict": [
      "self",
      "model",
      "dataset",
      "num_steps"
    ],
    "predict": [
      "self",
      "model",
      "dataset",
      "num_steps"
    ],
    "reorder_output_details": [
      "self",
      "tflite_output_details"
    ],
    "predict_tflite": [
      "self",
      "tflite_filepath",
      "dataset"
    ],
    "evaluate": [
      "self",
      "model",
      "tflite_filepath",
      "dataset",
      "num_steps",
      "eval_examples",
      "eval_features",
      "predict_file",
      "version_2_with_negative",
      "max_answer_length",
      "null_score_diff_threshold",
      "verbose_logging",
      "output_dir"
    ]
  },
  "mobilebert_classifier_spec": [],
  "mobilebert_qa_spec": [],
  "mobilebert_qa_squad_spec": [],
  "RecommendationSpec": {
    "compat_tf_versions": [],
    "__init__": [
      "self",
      "input_spec",
      "model_hparams"
    ],
    "create_model": [
      "self"
    ],
    "get_default_quantization_config": [
      "self"
    ]
  },
  "ImageModelSpec": {
    "mean_rgb": [],
    "stddev_rgb": [],
    "__init__": [
      "self",
      "uri",
      "compat_tf_versions",
      "input_image_shape",
      "name"
    ],
    "get_default_quantization_config": [
      "self",
      "representative_data"
    ]
  },
  "mobilenet_v2_spec": [],
  "resnet_50_spec": [],
  "efficientnet_lite0_spec": [],
  "efficientnet_lite1_spec": [],
  "efficientnet_lite2_spec": [],
  "efficientnet_lite3_spec": [],
  "efficientnet_lite4_spec": [],
  "MODEL_SPECS": [],
  "IMAGE_CLASSIFICATION_MODELS": [],
  "TEXT_CLASSIFICATION_MODELS": [],
  "QUESTION_ANSWER_MODELS": [],
  "AUDIO_CLASSIFICATION_MODELS": [],
  "RECOMMENDATION_MODELS": [],
  "OBJECT_DETECTION_MODELS": [],
  "get": [
    "spec_or_str"
  ],
  "dict_with_default": [
    "default_dict"
  ],
  "create_int_feature": [
    "values"
  ],
  "get_num_gpus": [
    "num_gpus"
  ],
  "wrap_doc": [
    "func_or_class",
    "short_desciption"
  ],
  "_NUM_CALIBRATION_STEPS": [],
  "_get_ordered_label_map": [
    "label_map"
  ],
  "EfficientDetModelSpec": {
    "compat_tf_versions": [],
    "__init__": [
      "self",
      "model_name",
      "uri",
      "hparams",
      "model_dir",
      "epochs",
      "batch_size",
      "steps_per_execution",
      "moving_average_decay",
      "var_freeze_expr",
      "tflite_max_detections",
      "strategy",
      "tpu",
      "gcp_project",
      "tpu_zone",
      "use_xla",
      "profile",
      "debug",
      "tf_random_seed",
      "verbose"
    ],
    "create_model": [
      "self"
    ],
    "train": [
      "self",
      "model",
      "train_dataset",
      "steps_per_epoch",
      "val_dataset",
      "validation_steps",
      "epochs",
      "batch_size",
      "val_json_file"
    ],
    "_get_evaluator_and_label_map": [
      "self",
      "json_file"
    ],
    "_get_metric_dict": [
      "self",
      "evaluator",
      "label_map"
    ],
    "evaluate": [
      "self",
      "model",
      "dataset",
      "steps",
      "json_file"
    ],
    "evaluate_tflite": [
      "self",
      "tflite_filepath",
      "dataset",
      "steps",
      "json_file"
    ],
    "export_saved_model": [
      "self",
      "model",
      "saved_model_dir",
      "batch_size",
      "pre_mode",
      "post_mode"
    ],
    "get_default_quantization_config": [
      "self",
      "representative_data"
    ],
    "export_tflite": [
      "self",
      "model",
      "tflite_filepath",
      "quantization_config"
    ]
  },
  "efficientdet_lite0_spec": [],
  "efficientdet_lite1_spec": [],
  "efficientdet_lite2_spec": [],
  "efficientdet_lite3_spec": [],
  "efficientdet_lite4_spec": [],
  "_ensure_tf25": [
    "tf_version"
  ],
  "_get_tf_version": [],
  "BaseSpec": {
    "__init__": [
      "self",
      "model_dir",
      "strategy"
    ],
    "target_sample_rate": [
      "self"
    ],
    "create_model": [
      "self",
      "num_classes",
      "train_whole_model"
    ],
    "run_classifier": [
      "self",
      "model",
      "epochs",
      "train_ds",
      "validation_ds"
    ],
    "preprocess_ds": [
      "self",
      "ds",
      "is_training",
      "cache_fn"
    ],
    "get_default_quantization_config": [
      "self"
    ]
  },
  "_remove_suffix_if_possible": [
    "text",
    "suffix"
  ],
  "TFJS_MODEL_ROOT": [],
  "_load_browser_fft_preprocess_model": [],
  "_load_tfjs_speech_command_model": [],
  "BrowserFFTSpec": {
    "EXPECTED_WAVEFORM_LENGTH": [],
    "_MODEL_NAME": [],
    "_MODEL_DESCRIPTION": [],
    "_MODEL_VERSION": [],
    "_MODEL_AUTHOR": [],
    "_MODEL_LICENSES": [],
    "_SAMPLE_RATE": [],
    "_CHANNELS": [],
    "_INPUT_NAME": [],
    "_INPUT_DESCRIPTION": [],
    "_OUTPUT_NAME": [],
    "_OUTPUT_DESCRIPTION": [],
    "__init__": [
      "self",
      "model_dir",
      "strategy"
    ],
    "target_sample_rate": [
      "self"
    ],
    "_ensure_length": [
      "self",
      "wav",
      "unused_label"
    ],
    "_split": [
      "self",
      "wav",
      "label"
    ],
    "_preprocess": [
      "self",
      "x",
      "label"
    ],
    "preprocess_ds": [
      "self",
      "ds",
      "is_training",
      "cache_fn"
    ],
    "create_model": [
      "self",
      "num_classes",
      "train_whole_model"
    ],
    "run_classifier": [
      "self",
      "model",
      "epochs",
      "train_ds",
      "validation_ds"
    ],
    "create_serving_model": [
      "self",
      "training_model"
    ],
    "_export_metadata": [
      "self",
      "tflite_filepath",
      "index_to_label",
      "export_metadata_json_file"
    ],
    "export_tflite": [
      "self",
      "model",
      "tflite_filepath",
      "with_metadata",
      "export_metadata_json_file",
      "index_to_label",
      "quantization_config"
    ]
  },
  "YAMNetSpec": {
    "EXPECTED_WAVEFORM_LENGTH": [],
    "EMBEDDING_SIZE": [],
    "_MODEL_NAME": [],
    "_MODEL_DESCRIPTION": [],
    "_MODEL_VERSION": [],
    "_MODEL_AUTHOR": [],
    "_MODEL_LICENSES": [],
    "_SAMPLE_RATE": [],
    "_CHANNELS": [],
    "_INPUT_NAME": [],
    "_INPUT_DESCRIPTION": [],
    "_YAMNET_OUTPUT_NAME": [],
    "_YAMNET_OUTPUT_DESCRIPTION": [],
    "_CUSTOM_OUTPUT_NAME": [],
    "_CUSTOM_OUTPUT_DESCRIPTION": [],
    "__init__": [
      "self",
      "model_dir",
      "strategy",
      "yamnet_model_handle",
      "frame_length",
      "frame_step",
      "keep_yamnet_and_custom_heads"
    ],
    "target_sample_rate": [
      "self"
    ],
    "create_model": [
      "self",
      "num_classes",
      "train_whole_model"
    ],
    "run_classifier": [
      "self",
      "model",
      "epochs",
      "train_ds",
      "validation_ds"
    ],
    "_frame": [
      "self",
      "wav",
      "label"
    ],
    "_extract_embedding": [
      "self",
      "wav",
      "label"
    ],
    "_add_noise": [
      "self",
      "embedding",
      "label"
    ],
    "preprocess_ds": [
      "self",
      "ds",
      "is_training",
      "cache_fn"
    ],
    "_yamnet_labels": [
      "self"
    ],
    "_export_metadata": [
      "self",
      "tflite_filepath",
      "index_to_label",
      "export_metadata_json_file"
    ],
    "create_serving_model": [
      "self",
      "training_model"
    ],
    "export_tflite": [
      "self",
      "model",
      "tflite_filepath",
      "with_metadata",
      "export_metadata_json_file",
      "index_to_label",
      "quantization_config"
    ]
  },
  "builder": [
    "db",
    "num_neighbors",
    "distance_measure"
  ],
  "OndeviceScannBuilder": {
    "create_config": [
      "self"
    ]
  },
  "_DISTANCE_MAP": [],
  "_LOOKUP_TYPE_MAP": [],
  "OnDeviceArtifacts": {},
  "get_distance_measure": [
    "distance_measure_str"
  ],
  "get_indexer": [
    "on_device_distance",
    "lookup_type",
    "ah_codebook"
  ],
  "get_partitioner": [
    "on_device_distance",
    "search_fraction",
    "partition_centroids"
  ],
  "convert_serialized_to_on_device": [
    "serialized_path"
  ],
  "convert_artifacts_to_leveldb": [
    "output_file_path",
    "metadata",
    "userinfo",
    "artifacts",
    "compression"
  ],
  "IMPORTS": [],
  "DOCS": [],
  "NAME_TO_SYMBOL": [],
  "LICENSE": [],
  "PACKAGE_PLACEHOLDER": [],
  "ROOT_PACKAGE_KEY": [],
  "Symbol": {
    "from_callable": [
      "cls",
      "exported_name",
      "func"
    ],
    "from_constant": [
      "cls",
      "exported_name",
      "module",
      "name"
    ],
    "get_package_name": [
      "self"
    ],
    "gen_import": [
      "self"
    ],
    "gen_parents_import": [
      "self"
    ]
  },
  "split_name": [
    "name"
  ],
  "as_package": [
    "names"
  ],
  "as_path": [
    "names"
  ],
  "_get_module_and_name": [
    "func"
  ],
  "mm_export": {
    "__init__": [
      "self",
      "name"
    ],
    "__call__": [
      "self",
      "func"
    ],
    "export_constant": [
      "self",
      "module",
      "name"
    ]
  },
  "_reset_apis": [],
  "_case_insensitive": [
    "s"
  ],
  "generate_imports": [],
  "generate_package_doc": [
    "package_name"
  ],
  "write_packages": [
    "base_dir",
    "imports",
    "doc_dict",
    "base_package",
    "version",
    "deprecated_imports"
  ],
  "PathOrStrType": [],
  "make_dirs_or_not": [
    "dirpath"
  ],
  "write_python_file": [
    "filepath",
    "package_doc",
    "lines"
  ],
  "_version_line": [
    "version"
  ],
  "overwrite_version_in_package": [
    "base_dir",
    "version"
  ],
  "parse_arguments": [],
  "_read_golden_text": [
    "json_file"
  ],
  "load_golden": [
    "json_file"
  ],
  "MetadataType": {
    "FROM_FILE_NAME": [],
    "FROM_DAT_FILE": []
  },
  "MetadataLoader": {
    "__init__": [
      "self",
      "func"
    ],
    "load": [
      "self",
      "path"
    ],
    "from_file_name": [
      "cls"
    ],
    "from_dat_file": [
      "cls"
    ]
  },
  "RecommendationDataLoader": {
    "__init__": [
      "self",
      "dataset",
      "size",
      "vocab"
    ],
    "gen_dataset": [
      "self",
      "batch_size",
      "is_training",
      "shuffle",
      "input_pipeline_context",
      "preprocess",
      "drop_remainder",
      "total_steps"
    ],
    "split": [
      "self",
      "fraction"
    ],
    "load_vocab": [
      "cls",
      "vocab_file"
    ],
    "_read_dataset": [
      "cls",
      "data_filepattern",
      "input_spec",
      "vocab_file_dir"
    ],
    "download_and_extract_movielens": [
      "cls",
      "download_dir"
    ],
    "generate_movielens_dataset": [
      "cls",
      "data_dir",
      "generated_examples_dir",
      "train_filename",
      "test_filename",
      "vocab_filename",
      "meta_filename",
      "min_timeline_length",
      "max_context_length",
      "max_context_movie_genre_length",
      "min_rating",
      "train_data_fraction",
      "build_vocabs"
    ],
    "get_num_classes": [
      "cls",
      "meta"
    ],
    "from_movielens": [
      "cls",
      "data_dir",
      "data_tag",
      "input_spec",
      "generated_examples_dir",
      "min_timeline_length",
      "max_context_length",
      "max_context_movie_genre_length",
      "min_rating",
      "train_data_fraction",
      "build_vocabs",
      "train_filename",
      "test_filename",
      "vocab_filename",
      "meta_filename"
    ]
  },
  "_MetadataType": [],
  "_BaseOptions": [],
  "ANN_JSON_FILE_SUFFIX": [],
  "META_DATA_FILE_SUFFIX": [],
  "_get_cache_dir_or_create": [
    "cache_dir"
  ],
  "_get_dir_basename": [
    "dirname"
  ],
  "get_cache_prefix_filename_from_pascal": [
    "images_dir",
    "annotations_dir",
    "annotation_filenames",
    "num_shards"
  ],
  "get_cache_prefix_filename_from_csv": [
    "csv_file",
    "num_shards"
  ],
  "CacheFiles": {},
  "get_cache_files": [
    "cache_dir",
    "cache_prefix_filename",
    "num_shards"
  ],
  "is_cached": [
    "cache_files"
  ],
  "is_all_cached": [
    "cache_files_collection"
  ],
  "get_cache_files_sequence": [
    "cache_dir",
    "cache_prefix_filename",
    "set_prefixes",
    "num_shards"
  ],
  "CacheFilesWriter": {
    "__init__": [
      "self",
      "label_map",
      "images_dir",
      "num_shards",
      "max_num_images",
      "ignore_difficult_instances"
    ],
    "write_files": [
      "self",
      "cache_files"
    ],
    "_get_xml_dict": [
      "self"
    ]
  },
  "PascalVocCacheFilesWriter": {
    "_get_xml_dict": [
      "self",
      "annotations_dir",
      "annotation_filenames"
    ]
  },
  "_get_xml_dict_from_csv_lines": [
    "images_dir",
    "image_filename",
    "lines"
  ],
  "CsvCacheFilesWriter": {
    "_get_xml_dict": [
      "self",
      "csv_lines"
    ]
  },
  "_load": [
    "tfrecord_file",
    "meta_data_file",
    "model_spec",
    "is_training"
  ],
  "_get_cache_filenames": [
    "cache_dir",
    "model_spec",
    "data_name",
    "is_training"
  ],
  "_get_cache_info": [
    "cache_dir",
    "data_name",
    "model_spec",
    "is_training"
  ],
  "TextClassifierDataLoader": {
    "from_folder": [
      "cls",
      "filename",
      "model_spec",
      "is_training",
      "class_labels",
      "shuffle",
      "cache_dir"
    ],
    "from_csv": [
      "cls",
      "filename",
      "text_column",
      "label_column",
      "fieldnames",
      "model_spec",
      "is_training",
      "delimiter",
      "quotechar",
      "shuffle",
      "cache_dir"
    ],
    "_load_data": [
      "cls",
      "tfrecord_file",
      "meta_data_file",
      "model_spec"
    ],
    "_save_data": [
      "cls",
      "examples",
      "model_spec",
      "label_names",
      "tfrecord_file",
      "meta_data_file",
      "vocab_file",
      "is_training"
    ],
    "_get_cache_info": [
      "cls",
      "cache_dir",
      "data_name",
      "model_spec",
      "is_training"
    ],
    "_read_csv": [
      "cls",
      "input_file",
      "fieldnames",
      "delimiter",
      "quotechar"
    ]
  },
  "QuestionAnswerDataLoader": {
    "__init__": [
      "self",
      "dataset",
      "size",
      "version_2_with_negative",
      "examples",
      "features",
      "squad_file"
    ],
    "from_squad": [
      "cls",
      "filename",
      "model_spec",
      "is_training",
      "version_2_with_negative",
      "cache_dir"
    ],
    "_generate_tf_record_from_squad_file": [
      "cls",
      "input_file_path",
      "model_spec",
      "output_path",
      "is_training",
      "version_2_with_negative"
    ]
  },
  "MOVIE_SIZE": [],
  "RATING_SIZE": [],
  "USER_SIZE": [],
  "TRAIN_SIZE": [],
  "TEST_SIZE": [],
  "VOCAB_SIZE": [],
  "MAX_ITEM_ID": [],
  "_generate_fake_data": [
    "data_dir"
  ],
  "_write_file_by_lines": [
    "data",
    "filename"
  ],
  "setup_fake_testdata": [
    "obj"
  ],
  "patch_download_and_extract_data": [
    "data_dir"
  ],
  "error_import_librosa": [],
  "ExamplesHelper": {
    "from_examples_folder": [
      "cls",
      "path",
      "examples_filter_fn"
    ],
    "__init__": [
      "self",
      "examples_in_absolute_path",
      "labels"
    ],
    "_get_index_to_label": [
      "self",
      "used_labels"
    ],
    "_get_label_to_index": [
      "self",
      "index_to_label"
    ],
    "shuffle": [
      "self"
    ],
    "filter": [
      "self",
      "labels"
    ],
    "examples_and_label_indices": [
      "self"
    ],
    "examples_and_labels": [
      "self"
    ],
    "examples_and_label_indices_ds": [
      "self"
    ]
  },
  "create_data": [
    "name",
    "data",
    "info",
    "label_names"
  ],
  "ImageClassifierDataLoader": {
    "from_folder": [
      "cls",
      "filename",
      "shuffle"
    ],
    "from_tfds": [
      "cls",
      "name"
    ]
  },
  "generate_elements": [
    "ds"
  ],
  "DetectorDataLoader": [],
  "CsvLines": [],
  "_get_label_map": [
    "label_map"
  ],
  "_group_csv_lines": [
    "csv_file",
    "set_prefixes",
    "delimiter",
    "quotechar"
  ],
  "shard": [
    "ds",
    "input_pipeline_context"
  ],
  "ClassificationDataLoader": {
    "__init__": [
      "self",
      "dataset",
      "size",
      "index_to_label"
    ],
    "num_classes": [
      "self"
    ],
    "split": [
      "self",
      "fraction"
    ]
  },
  "ModelHParams": [],
  "InputSpec": [],
  "WarmUp": {
    "__init__": [
      "self",
      "initial_learning_rate",
      "decay_schedule_fn",
      "warmup_steps",
      "name"
    ],
    "__call__": [
      "self",
      "step"
    ],
    "get_config": [
      "self"
    ]
  },
  "__version__": []
}