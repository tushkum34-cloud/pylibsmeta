{
  "_root": [],
  "_data_dir": [],
  "_create_build_metadata": [],
  "write_if_different": [
    "path",
    "content"
  ],
  "_create_data_dir": [
    "use_symlinks"
  ],
  "_prepare_for_wheel": [],
  "_prepare_for_editable": [],
  "_prepare_for_sdist": [],
  "get_requires_for_build_wheel": [
    "config_settings"
  ],
  "get_requires_for_build_sdist": [
    "config_settings"
  ],
  "get_requires_for_build_editable": [
    "config_settings"
  ],
  "prepare_metadata_for_build_wheel": [
    "metadata_directory",
    "config_settings"
  ],
  "prepare_metadata_for_build_editable": [
    "metadata_directory",
    "config_settings"
  ],
  "build_editable": [
    "wheel_directory",
    "config_settings",
    "metadata_directory"
  ],
  "build_sdist": [
    "sdist_directory",
    "config_settings"
  ],
  "build_wheel": [
    "wheel_directory",
    "config_settings",
    "metadata_directory"
  ],
  "get_git_version": [
    "cwd"
  ],
  "get_cascade_module": [],
  "merge_state": [
    "v_a",
    "s_a",
    "v_b",
    "s_b"
  ],
  "_fake_merge_state": [
    "v_a",
    "s_a",
    "v_b",
    "s_b"
  ],
  "merge_state_in_place": [
    "v",
    "s",
    "v_other",
    "s_other",
    "mask"
  ],
  "_fake_merge_state_in_place": [
    "v",
    "s",
    "v_other",
    "s_other",
    "mask"
  ],
  "merge_states": [
    "v",
    "s"
  ],
  "_fake_merge_states": [
    "v",
    "s"
  ],
  "MultiLevelCascadeAttentionWrapper": {
    "__init__": [
      "self",
      "num_levels",
      "float_workspace_buffer",
      "kv_layout",
      "use_cuda_graph",
      "qo_indptr_buf_arr",
      "paged_kv_indptr_buf_arr",
      "paged_kv_indices_buf_arr",
      "paged_kv_last_page_len_buf_arr"
    ],
    "is_cuda_graph_enabled": [
      "self"
    ],
    "reset_workspace_buffer": [
      "self",
      "float_workspace_buffer",
      "int_workspace_buffers"
    ],
    "plan": [
      "self",
      "qo_indptr_arr",
      "paged_kv_indptr_arr",
      "paged_kv_indices_arr",
      "paged_kv_last_page_len",
      "num_qo_heads",
      "num_kv_heads",
      "head_dim",
      "page_size",
      "causal",
      "pos_encoding_mode",
      "use_fp16_qk_reduction",
      "sm_scale",
      "window_left",
      "logits_soft_cap",
      "rope_scale",
      "rope_theta",
      "q_data_type",
      "kv_data_type"
    ],
    "begin_forward": [],
    "run": [
      "self",
      "q",
      "paged_kv_cache"
    ],
    "forward": []
  },
  "BatchDecodeWithSharedPrefixPagedKVCacheWrapper": {
    "__init__": [
      "self",
      "float_workspace_buffer",
      "kv_layout"
    ],
    "reset_workspace_buffer": [
      "self",
      "float_workspace_buffer",
      "int_workspace_buffer"
    ],
    "begin_forward": [
      "self",
      "unique_kv_indptr",
      "unique_kv_indices",
      "unique_kv_last_page_len",
      "num_qo_heads",
      "num_kv_heads",
      "head_dim",
      "page_size",
      "data_type"
    ],
    "forward": [
      "self",
      "q",
      "k_shared",
      "v_shared",
      "unique_kv_cache"
    ],
    "end_forward": [
      "self"
    ]
  },
  "BatchPrefillWithSharedPrefixPagedKVCacheWrapper": {
    "__init__": [
      "self",
      "float_workspace_buffer",
      "kv_layout"
    ],
    "reset_workspace_buffer": [
      "self",
      "float_workspace_buffer",
      "int_workspace_buffer"
    ],
    "begin_forward": [
      "self",
      "qo_indptr",
      "paged_kv_indptr",
      "paged_kv_indices",
      "paged_kv_last_page_len",
      "num_qo_heads",
      "num_kv_heads",
      "head_dim",
      "page_size"
    ],
    "forward": [
      "self",
      "q",
      "k_shared",
      "v_shared",
      "unique_kv_cache",
      "causal",
      "use_fp16_qk_reduction",
      "sm_scale",
      "rope_scale",
      "rope_theta"
    ],
    "end_forward": [
      "self"
    ]
  },
  "get_norm_module": [],
  "rmsnorm": [
    "input",
    "weight",
    "eps",
    "out",
    "enable_pdl"
  ],
  "_rmsnorm": [
    "out",
    "input",
    "weight",
    "eps",
    "enable_pdl"
  ],
  "_rmsnorm_fake": [
    "out",
    "input",
    "weight",
    "eps",
    "enable_pdl"
  ],
  "rmsnorm_quant": [
    "out",
    "input",
    "weight",
    "scale",
    "eps",
    "enable_pdl"
  ],
  "_rmsnorm_quant_fake": [
    "out",
    "input",
    "weight",
    "scale",
    "eps",
    "enable_pdl"
  ],
  "fused_add_rmsnorm": [
    "input",
    "residual",
    "weight",
    "eps",
    "enable_pdl"
  ],
  "_fused_add_rmsnorm_fake": [
    "input",
    "residual",
    "weight",
    "eps",
    "enable_pdl"
  ],
  "fused_add_rmsnorm_quant": [
    "out",
    "input",
    "residual",
    "weight",
    "scale",
    "eps",
    "enable_pdl"
  ],
  "_fused_add_rmsnorm_quant_fake": [
    "out",
    "input",
    "residual",
    "weight",
    "scale",
    "eps",
    "enable_pdl"
  ],
  "gemma_rmsnorm": [
    "input",
    "weight",
    "eps",
    "out",
    "enable_pdl"
  ],
  "_gemma_rmsnorm": [
    "out",
    "input",
    "weight",
    "eps",
    "enable_pdl"
  ],
  "_gemma_rmsnorm_fake": [
    "out",
    "input",
    "weight",
    "eps",
    "enable_pdl"
  ],
  "gemma_fused_add_rmsnorm": [
    "input",
    "residual",
    "weight",
    "eps",
    "enable_pdl"
  ],
  "_gemma_fused_add_rmsnorm_fake": [
    "input",
    "residual",
    "weight",
    "eps",
    "enable_pdl"
  ],
  "layernorm": [
    "input",
    "gemma",
    "beta",
    "eps"
  ],
  "_layernorm_fake": [
    "input",
    "gemma",
    "beta",
    "eps"
  ],
  "_cudaGetErrorEnum": [
    "error"
  ],
  "checkCudaErrors": [
    "result"
  ],
  "get_trtllm_utils_module": [],
  "delay_kernel": [
    "stream_delay_micro_secs"
  ],
  "get_gdn_prefill_module": [],
  "chunk_gated_delta_rule": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "output_final_state",
    "cu_seqlens",
    "use_qk_l2norm_in_kernel",
    "output",
    "output_state"
  ],
  "get_seed_and_offset": [
    "increment",
    "generator",
    "device"
  ],
  "get_sampling_module": [],
  "_to_tensor_scalar_tuple": [
    "x"
  ],
  "_validate_and_convert_seed_offset": [
    "seed",
    "offset",
    "device",
    "batch_size"
  ],
  "softmax": [
    "logits",
    "temperature",
    "enable_pdl"
  ],
  "sampling_from_logits": [
    "logits",
    "indices",
    "deterministic",
    "generator",
    "check_nan",
    "seed",
    "offset"
  ],
  "sampling_from_probs": [
    "probs",
    "indices",
    "deterministic",
    "generator",
    "check_nan",
    "seed",
    "offset"
  ],
  "top_p_sampling_from_probs": [
    "probs",
    "top_p",
    "indices",
    "deterministic",
    "generator",
    "check_nan",
    "seed",
    "offset"
  ],
  "top_k_sampling_from_probs": [
    "probs",
    "top_k",
    "indices",
    "deterministic",
    "generator",
    "check_nan",
    "seed",
    "offset"
  ],
  "min_p_sampling_from_probs": [
    "probs",
    "min_p",
    "indices",
    "deterministic",
    "generator",
    "check_nan",
    "seed",
    "offset"
  ],
  "top_k_top_p_sampling_from_logits": [
    "logits",
    "top_k",
    "top_p",
    "indices",
    "filter_apply_order",
    "deterministic",
    "generator",
    "check_nan",
    "seed",
    "offset"
  ],
  "top_k_top_p_sampling_from_probs": [
    "probs",
    "top_k",
    "top_p",
    "indices",
    "filter_apply_order",
    "deterministic",
    "generator",
    "check_nan",
    "seed",
    "offset"
  ],
  "top_p_renorm_probs": [
    "probs",
    "top_p"
  ],
  "top_p_renorm_prob": [],
  "top_k_renorm_probs": [
    "probs",
    "top_k"
  ],
  "top_k_renorm_prob": [],
  "top_k_mask_logits": [
    "logits",
    "top_k"
  ],
  "chain_speculative_sampling": [
    "draft_probs",
    "draft_token_ids",
    "target_probs",
    "maybe_output_accepted_token_num",
    "maybe_output_emitted_draft_token_num",
    "deterministic",
    "generator",
    "seed",
    "offset"
  ],
  "get_quantization_module": [],
  "_packbits": [
    "x",
    "bitorder"
  ],
  "_fake_packbits": [
    "x",
    "bitorder"
  ],
  "packbits": [
    "x",
    "bitorder"
  ],
  "segment_packbits": [
    "x",
    "indptr",
    "bitorder"
  ],
  "_split_scale_param": [
    "scale"
  ],
  "get_fmha_module": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap",
    "device",
    "use_fp16_qk_reduction"
  ],
  "make_hashable_cache": [
    "func"
  ],
  "get_customize_batch_prefill_module": [
    "backend",
    "uri",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "idtype",
    "head_dim_qk",
    "head_dim_vo",
    "additional_tensor_names",
    "additional_tensor_dtypes",
    "additional_scalar_names",
    "additional_scalar_dtypes",
    "variant_name",
    "variant_decl",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap",
    "use_fp16_qk_reduction",
    "fp8_enabled"
  ],
  "get_trtllm_gen_prefill_module": [],
  "get_single_prefill_module": [
    "backend"
  ],
  "get_batch_prefill_module": [
    "backend"
  ],
  "get_batch_prefill_jit_module": [
    "module_name",
    "jit_module"
  ],
  "single_prefill_with_kv_cache_with_jit_module": [
    "jit_module",
    "q",
    "k",
    "v"
  ],
  "single_prefill_with_kv_cache": [
    "q",
    "k",
    "v",
    "scale_q",
    "scale_k",
    "scale_v",
    "o_dtype",
    "custom_mask",
    "packed_custom_mask",
    "causal",
    "kv_layout",
    "pos_encoding_mode",
    "use_fp16_qk_reduction",
    "sm_scale",
    "window_left",
    "logits_soft_cap",
    "rope_scale",
    "rope_theta",
    "backend",
    "return_lse"
  ],
  "single_prefill_with_kv_cache_return_lse": [],
  "_compute_page_mask_indptr": [
    "qo_indptr",
    "paged_kv_indptr",
    "paged_kv_last_page_len",
    "page_size"
  ],
  "BatchPrefillWithPagedKVCacheWrapper": {
    "__init__": [
      "self",
      "float_workspace_buffer",
      "kv_layout",
      "use_cuda_graph",
      "qo_indptr_buf",
      "paged_kv_indptr_buf",
      "paged_kv_indices_buf",
      "paged_kv_last_page_len_buf",
      "custom_mask_buf",
      "mask_indptr_buf",
      "backend",
      "jit_args",
      "jit_kwargs"
    ],
    "is_cuda_graph_enabled": [
      "self"
    ],
    "reset_workspace_buffer": [
      "self",
      "float_workspace_buffer",
      "int_workspace_buffer"
    ],
    "plan": [
      "self",
      "qo_indptr",
      "paged_kv_indptr",
      "paged_kv_indices",
      "paged_kv_last_page_len",
      "num_qo_heads",
      "num_kv_heads",
      "head_dim_qk",
      "page_size",
      "head_dim_vo",
      "custom_mask",
      "packed_custom_mask",
      "causal",
      "pos_encoding_mode",
      "use_fp16_qk_reduction",
      "sm_scale",
      "window_left",
      "logits_soft_cap",
      "rope_scale",
      "rope_theta",
      "q_data_type",
      "kv_data_type",
      "o_data_type",
      "non_blocking",
      "prefix_len_ptr",
      "token_pos_in_items_ptr",
      "token_pos_in_items_len",
      "max_item_len_ptr",
      "seq_lens",
      "seq_lens_q",
      "block_tables",
      "max_token_per_sequence",
      "max_sequence_kv",
      "fixed_split_size",
      "disable_split_kv"
    ],
    "begin_forward": [],
    "forward": [
      "self",
      "q",
      "paged_kv_cache",
      "causal",
      "pos_encoding_mode",
      "use_fp16_qk_reduction",
      "k_scale",
      "v_scale",
      "window_left",
      "logits_soft_cap",
      "sm_scale",
      "rope_scale",
      "rope_theta"
    ],
    "run": [
      "self",
      "q",
      "paged_kv_cache"
    ],
    "run_return_lse": [],
    "forward_return_lse": [
      "self",
      "q",
      "paged_kv_cache",
      "causal",
      "pos_encoding_mode",
      "use_fp16_qk_reduction",
      "k_scale",
      "v_scale",
      "window_left",
      "logits_soft_cap",
      "sm_scale",
      "rope_scale",
      "rope_theta"
    ],
    "end_forward": [
      "self"
    ]
  },
  "_compute_mask_indptr": [
    "qo_indptr",
    "kv_indptr"
  ],
  "BatchPrefillWithRaggedKVCacheWrapper": {
    "__init__": [
      "self",
      "float_workspace_buffer",
      "kv_layout",
      "use_cuda_graph",
      "qo_indptr_buf",
      "kv_indptr_buf",
      "custom_mask_buf",
      "mask_indptr_buf",
      "backend",
      "jit_args",
      "jit_kwargs"
    ],
    "is_cuda_graph_enabled": [
      "self"
    ],
    "reset_workspace_buffer": [
      "self",
      "float_workspace_buffer",
      "int_workspace_buffer"
    ],
    "plan": [
      "self",
      "qo_indptr",
      "kv_indptr",
      "num_qo_heads",
      "num_kv_heads",
      "head_dim_qk",
      "head_dim_vo",
      "custom_mask",
      "packed_custom_mask",
      "causal",
      "pos_encoding_mode",
      "use_fp16_qk_reduction",
      "window_left",
      "logits_soft_cap",
      "sm_scale",
      "rope_scale",
      "rope_theta",
      "q_data_type",
      "kv_data_type",
      "o_data_type",
      "non_blocking",
      "prefix_len_ptr",
      "token_pos_in_items_ptr",
      "token_pos_in_items_len",
      "max_item_len_ptr",
      "fixed_split_size",
      "disable_split_kv",
      "seq_lens",
      "seq_lens_q",
      "max_token_per_sequence",
      "max_sequence_kv",
      "v_indptr",
      "o_indptr"
    ],
    "begin_forward": [],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "causal",
      "pos_encoding_mode",
      "use_fp16_qk_reduction",
      "window_left",
      "logits_soft_cap",
      "sm_scale",
      "rope_scale",
      "rope_theta"
    ],
    "run": [
      "self",
      "q",
      "k",
      "v"
    ],
    "run_return_lse": [],
    "forward_return_lse": [
      "self",
      "q",
      "k",
      "v",
      "causal",
      "pos_encoding_mode",
      "use_fp16_qk_reduction",
      "window_left",
      "logits_soft_cap",
      "sm_scale",
      "rope_scale",
      "rope_theta"
    ],
    "end_forward": [
      "self"
    ]
  },
  "fmha_varlen_plan": [
    "module",
    "qo_segment_offsets",
    "kv_segment_offsets",
    "num_qo_heads",
    "causal"
  ],
  "fmha_varlen": [
    "q",
    "k",
    "v",
    "qo_segment_offsets",
    "kv_segment_offsets",
    "plan_info",
    "max_qo_len",
    "out",
    "lse",
    "causal",
    "sm_scale",
    "q_scale",
    "k_scale",
    "v_scale",
    "o_scale",
    "return_lse"
  ],
  "get_trtllm_gen_fmha_module": [],
  "trtllm_ragged_attention_deepseek": [
    "query",
    "key",
    "value",
    "workspace_buffer",
    "seq_lens",
    "max_q_len",
    "max_kv_len",
    "bmm1_scale",
    "bmm2_scale",
    "o_sf_scale",
    "batch_size",
    "window_left",
    "cum_seq_lens_q",
    "cum_seq_lens_kv",
    "enable_pdl",
    "is_causal",
    "return_lse",
    "attention_sinks",
    "skip_softmax_threshold_scale_factor",
    "out",
    "lse"
  ],
  "trtllm_batch_context_with_kv_cache": [
    "query",
    "kv_cache",
    "workspace_buffer",
    "block_tables",
    "seq_lens",
    "max_q_len",
    "max_kv_len",
    "bmm1_scale",
    "bmm2_scale",
    "batch_size",
    "cum_seq_lens_q",
    "cum_seq_lens_kv",
    "window_left",
    "out",
    "out_dtype",
    "o_sf_scale",
    "o_sf_vec_size",
    "kv_layout",
    "enable_pdl",
    "sinks",
    "skip_softmax_threshold_scale_factor"
  ],
  "fmha_v2_prefill_deepseek": [
    "query",
    "key",
    "value",
    "out",
    "num_heads",
    "head_dim",
    "seq_len",
    "scale_softmax",
    "scale_bmm1",
    "scale_bmm2",
    "return_lse",
    "lse"
  ],
  "get_sm_count_constraint": [
    "major",
    "minor"
  ],
  "get_cudevice": [
    "dev"
  ],
  "get_device_resource": [
    "cu_dev"
  ],
  "split_resource": [
    "resource",
    "num_groups",
    "min_count"
  ],
  "split_resource_by_sm_count": [
    "cu_dev",
    "resource",
    "sm_counts"
  ],
  "create_green_ctx_streams": [
    "cu_dev",
    "resources"
  ],
  "split_device_green_ctx": [
    "dev",
    "num_groups",
    "min_count"
  ],
  "split_device_green_ctx_by_sm_count": [
    "dev",
    "sm_counts"
  ],
  "get_single_decode_module": [],
  "get_batch_decode_jit_module": [
    "module_name",
    "jit_module"
  ],
  "get_batch_decode_module": [],
  "single_decode_with_kv_cache_with_jit_module": [
    "jit_module",
    "q",
    "k",
    "v"
  ],
  "get_batch_decode_mla_module": [],
  "single_decode_with_kv_cache": [
    "q",
    "k",
    "v",
    "kv_layout",
    "pos_encoding_mode",
    "use_tensor_cores",
    "q_scale",
    "k_scale",
    "v_scale",
    "window_left",
    "logits_soft_cap",
    "sm_scale",
    "rope_scale",
    "rope_theta",
    "return_lse"
  ],
  "BatchDecodeWithPagedKVCacheWrapper": {
    "__init__": [
      "self",
      "float_workspace_buffer",
      "kv_layout",
      "use_cuda_graph",
      "use_tensor_cores",
      "paged_kv_indptr_buffer",
      "paged_kv_indices_buffer",
      "paged_kv_last_page_len_buffer",
      "backend",
      "jit_args"
    ],
    "use_tensor_cores": [
      "self"
    ],
    "is_cuda_graph_enabled": [
      "self"
    ],
    "reset_workspace_buffer": [
      "self",
      "float_workspace_buffer",
      "int_workspace_buffer"
    ],
    "plan": [
      "self",
      "indptr",
      "indices",
      "last_page_len",
      "num_qo_heads",
      "num_kv_heads",
      "head_dim",
      "page_size",
      "pos_encoding_mode",
      "window_left",
      "logits_soft_cap",
      "q_data_type",
      "kv_data_type",
      "o_data_type",
      "data_type",
      "sm_scale",
      "rope_scale",
      "rope_theta",
      "non_blocking",
      "block_tables",
      "seq_lens",
      "fixed_split_size",
      "disable_split_kv"
    ],
    "begin_forward": [],
    "forward": [
      "self",
      "q",
      "paged_kv_cache",
      "pos_encoding_mode",
      "q_scale",
      "k_scale",
      "v_scale",
      "window_left",
      "logits_soft_cap",
      "sm_scale",
      "rope_scale",
      "rope_theta"
    ],
    "run": [
      "self",
      "q",
      "paged_kv_cache"
    ],
    "forward_return_lse": [
      "self",
      "q",
      "paged_kv_cache",
      "pos_encoding_mode",
      "q_scale",
      "k_scale",
      "v_scale",
      "window_left",
      "logits_soft_cap",
      "sm_scale",
      "rope_scale",
      "rope_theta"
    ],
    "run_return_lse": [],
    "end_forward": [
      "self"
    ]
  },
  "CUDAGraphBatchDecodeWithPagedKVCacheWrapper": {
    "__init__": [
      "self",
      "workspace_buffer",
      "indptr_buffer",
      "indices_buffer",
      "last_page_len_buffer",
      "kv_layout",
      "use_tensor_cores"
    ]
  },
  "BatchDecodeMlaWithPagedKVCacheWrapper": {
    "__init__": [
      "self",
      "float_workspace_buffer",
      "use_cuda_graph",
      "use_tensor_cores",
      "paged_kv_indptr_buffer",
      "paged_kv_indices_buffer",
      "paged_kv_last_page_len_buffer"
    ],
    "is_cuda_graph_enabled": [
      "self"
    ],
    "use_tensor_cores": [
      "self"
    ],
    "reset_workspace_buffer": [
      "self",
      "float_workspace_buffer",
      "int_workspace_buffer"
    ],
    "plan": [
      "self",
      "indptr",
      "indices",
      "last_page_len",
      "num_qo_heads",
      "head_dim_compressed_kv",
      "page_size",
      "sm_scale",
      "window_left",
      "logits_soft_cap",
      "data_type",
      "q_data_type",
      "rope_scale",
      "rope_theta"
    ],
    "run": [
      "self",
      "q_nope",
      "q_pe",
      "paged_ckv_cache",
      "paged_kpe_cache",
      "q_scale",
      "k_scale",
      "v_scale",
      "out",
      "lse",
      "return_lse",
      "enable_pdl"
    ],
    "run_return_lse": []
  },
  "TrtllmGenDecodeModule": {
    "__init__": [
      "self"
    ],
    "_paged_run": [
      "self",
      "query",
      "k_cache",
      "v_cache",
      "workspace_buffer",
      "block_tables",
      "seq_lens",
      "max_seq_len",
      "bmm1_scale",
      "bmm2_scale",
      "workspace_size",
      "window_left",
      "enable_pdl",
      "out",
      "sinks",
      "skip_softmax_threshold_scale_factor"
    ],
    "_plan": [
      "self"
    ]
  },
  "get_trtllm_gen_decode_module": [],
  "trtllm_batch_decode_with_kv_cache": [
    "query",
    "kv_cache",
    "workspace_buffer",
    "block_tables",
    "seq_lens",
    "max_seq_len",
    "bmm1_scale",
    "bmm2_scale",
    "window_left",
    "out",
    "out_dtype",
    "o_sf_scale",
    "o_sf_vec_size",
    "sinks",
    "kv_layout",
    "enable_pdl",
    "backend",
    "q_len_per_req",
    "o_scale",
    "mask",
    "max_q_len",
    "cum_seq_lens_q",
    "skip_softmax_threshold_scale_factor"
  ],
  "xqa_batch_decode_with_kv_cache": [
    "query",
    "kv_cache",
    "workspace_buffer",
    "block_tables",
    "seq_lens",
    "max_seq_len",
    "bmm1_scale",
    "bmm2_scale",
    "window_left",
    "out",
    "sinks",
    "kv_layout",
    "enable_pdl",
    "q_len_per_req",
    "o_scale",
    "mask"
  ],
  "fast_decode_plan": [
    "self",
    "indptr",
    "indices",
    "last_page_len",
    "num_qo_heads",
    "num_kv_heads",
    "head_dim",
    "page_size",
    "pos_encoding_mode",
    "window_left",
    "logits_soft_cap",
    "q_data_type",
    "kv_data_type",
    "data_type",
    "sm_scale",
    "rope_scale",
    "rope_theta",
    "non_blocking",
    "fixed_split_size",
    "disable_split_kv",
    "global_override_indptr_cpu"
  ],
  "get_topk_module": [],
  "can_implement_filtered_topk": [],
  "top_k": [
    "input",
    "k",
    "sorted"
  ],
  "topk": [],
  "top_k_page_table_transform": [
    "input",
    "src_page_table",
    "lengths",
    "k",
    "row_to_batch"
  ],
  "top_k_ragged_transform": [
    "input",
    "offsets",
    "lengths",
    "k"
  ],
  "PosEncodingMode": {
    "NONE": [],
    "ROPE_LLAMA": [],
    "ALIBI": []
  },
  "MaskMode": {
    "NON_CAUSAL": [],
    "CAUSAL": [],
    "CUSTOM": [],
    "MULTIITEMSCORING": []
  },
  "TensorLayout": {
    "NHD": [],
    "HND": []
  },
  "log2e": [],
  "GPUArchitectureError": {},
  "LibraryError": {},
  "BackendSupportedError": {},
  "_expand_5d": [
    "x",
    "kv_layout"
  ],
  "_expand_4d": [
    "x",
    "kv_layout"
  ],
  "next_positive_power_of_2": [
    "x"
  ],
  "calculate_tile_tokens_dim": [
    "num_tokens",
    "num_experts",
    "top_k",
    "max_tile_tokens_dim"
  ],
  "_check_pos_encoding_mode": [
    "pos_encoding_mode"
  ],
  "_check_kv_layout": [
    "kv_layout"
  ],
  "is_float8": [
    "x"
  ],
  "get_indptr": [
    "x"
  ],
  "_unpack_paged_kv_cache": [
    "paged_kv_cache",
    "kv_layout"
  ],
  "get_alibi_slopes": [
    "n_heads"
  ],
  "_get_cache_buf": [
    "name",
    "bytes",
    "device",
    "zero_init"
  ],
  "_ceil_pow2": [
    "x"
  ],
  "_get_range_buf": [
    "seq_len",
    "device"
  ],
  "_get_cache_alibi_slopes_buf": [
    "num_qo_heads",
    "device"
  ],
  "canonicalize_torch_dtype": [
    "dtype"
  ],
  "get_compute_capability": [
    "device"
  ],
  "get_gpu_memory_bandwidth": [
    "device"
  ],
  "_check_cached_qkv_data_type": [
    "q",
    "k",
    "dtype_q",
    "dtype_kv"
  ],
  "determine_gemm_backend": [
    "device"
  ],
  "is_fa3_backend_supported": [
    "pos_encoding_mode",
    "use_fp16_qk_reductions",
    "use_custom_mask",
    "dtype_q",
    "dtype_kv"
  ],
  "is_cutlass_backend_supported": [
    "pos_encoding_mode",
    "use_fp16_qk_reductions",
    "use_custom_mask",
    "dtype_q",
    "dtype_kv"
  ],
  "determine_attention_backend": [
    "device",
    "pos_encoding_mode",
    "use_fp16_qk_reductions",
    "use_custom_mask",
    "dtype_q",
    "dtype_kv"
  ],
  "version_at_least": [
    "version",
    "base_version"
  ],
  "has_cuda_cudart": [],
  "get_cuda_python_version": [],
  "is_sm90a_supported": [
    "device"
  ],
  "is_sm100a_supported": [
    "device"
  ],
  "is_sm100f_supported": [
    "device"
  ],
  "is_sm110a_supported": [
    "device"
  ],
  "is_sm120a_supported": [
    "device"
  ],
  "is_sm121a_supported": [
    "device"
  ],
  "determine_mla_backend": [
    "device"
  ],
  "check_shape_dtype_device": [
    "x",
    "expected_shape",
    "expected_dtype",
    "expected_device",
    "name"
  ],
  "get_logging_module": [],
  "LogLevel": {
    "TRACE": [],
    "DEBUG": [],
    "INFO": [],
    "WARN": [],
    "ERROR": [],
    "CRITICAL": []
  },
  "log_level_map": [],
  "set_log_level": [
    "lvl_str"
  ],
  "device_support_pdl": [
    "device"
  ],
  "ceil_div": [
    "x",
    "y"
  ],
  "round_up": [
    "x",
    "y"
  ],
  "get_device_sm_count": [
    "device"
  ],
  "FP4Tensor": {
    "__init__": [
      "self",
      "data",
      "scale",
      "scale_start_index",
      "original_shape"
    ]
  },
  "srcToDstBlk16RowMap": [],
  "srcToDstBlk32RowMap": [],
  "get_shuffle_block_size": [
    "epilogue_tile_m"
  ],
  "get_shuffle_matrix_a_row_indices": [
    "input_tensor",
    "epilogue_tile_m"
  ],
  "get_shuffle_matrix_sf_a_row_indices": [
    "input_tensor",
    "epilogue_tile_m",
    "num_elts_per_sf"
  ],
  "get_native_fp4_dtype": [],
  "supported_compute_capability": [
    "supported_ccs"
  ],
  "backend_requirement": [
    "backend_checks",
    "common_check",
    "heuristic_func"
  ],
  "get_default_generators": [
    "device"
  ],
  "get_act_and_mul_module": [
    "act_func_name"
  ],
  "_check_shape": [
    "input",
    "output"
  ],
  "silu_and_mul": [
    "input",
    "out",
    "enable_pdl"
  ],
  "gelu_tanh_and_mul": [
    "input",
    "out",
    "enable_pdl"
  ],
  "gelu_and_mul": [
    "input",
    "out",
    "enable_pdl"
  ],
  "silu_and_mul_scaled_nvfp4_experts_quantize": [
    "a",
    "mask",
    "a_global_sf"
  ],
  "convert_bsr_mask_layout": [
    "mask",
    "indptr"
  ],
  "BlockSparseAttentionWrapper": {
    "__init__": [
      "self",
      "float_workspace_buffer",
      "backend"
    ],
    "reset_workspace_buffer": [
      "self",
      "float_workspace_buffer",
      "int_workspace_buffer"
    ],
    "plan": [
      "self",
      "indptr",
      "indices",
      "M",
      "N",
      "R",
      "C",
      "num_qo_heads",
      "num_kv_heads",
      "head_dim",
      "mask",
      "packed_mask",
      "causal",
      "pos_encoding_mode",
      "use_fp16_qk_reduction",
      "logits_soft_cap",
      "sm_scale",
      "rope_scale",
      "rope_theta",
      "q_data_type",
      "kv_data_type",
      "o_data_type",
      "non_blocking"
    ],
    "begin_forward": [],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "scale_q",
      "scale_k",
      "scale_v",
      "pos_encoding_mode",
      "use_fp16_qk_reduction",
      "logits_soft_cap",
      "sm_scale",
      "rope_scale",
      "rope_theta"
    ],
    "run": [
      "self",
      "q",
      "k",
      "v",
      "scale_q",
      "scale_k",
      "scale_v",
      "out",
      "lse",
      "return_lse",
      "enable_pdl"
    ],
    "end_forward": [
      "self"
    ]
  },
  "VariableBlockSparseAttentionWrapper": {
    "__init__": [
      "self",
      "float_workspace_buffer",
      "backend"
    ],
    "reset_workspace_buffer": [
      "self",
      "float_workspace_buffer",
      "int_workspace_buffer"
    ],
    "plan": [
      "self",
      "block_mask_map",
      "block_row_sz",
      "block_col_sz",
      "num_qo_heads",
      "num_kv_heads",
      "head_dim",
      "causal",
      "pos_encoding_mode",
      "use_fp16_qk_reduction",
      "logits_soft_cap",
      "sm_scale",
      "rope_scale",
      "rope_theta",
      "non_blocking",
      "q_data_type",
      "kv_data_type"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "pos_encoding_mode",
      "use_fp16_qk_reduction",
      "logits_soft_cap",
      "sm_scale",
      "rope_scale",
      "rope_theta"
    ],
    "run": [
      "self",
      "q",
      "k",
      "v",
      "out",
      "lse",
      "return_lse",
      "enable_pdl"
    ]
  },
  "get_holistic_attention_module": [],
  "BatchAttention": {
    "__init__": [
      "self",
      "kv_layout",
      "device"
    ],
    "plan": [
      "self",
      "qo_indptr",
      "kv_indptr",
      "kv_indices",
      "kv_len_arr",
      "num_qo_heads",
      "num_kv_heads",
      "head_dim_qk",
      "head_dim_vo",
      "page_size",
      "causal",
      "sm_scale",
      "logits_soft_cap",
      "q_data_type",
      "kv_data_type",
      "use_profiler"
    ],
    "run": [
      "self",
      "q",
      "kv_cache",
      "out",
      "lse",
      "k_scale",
      "v_scale",
      "logits_soft_cap",
      "profiler_buffer"
    ]
  },
  "BatchAttentionWithAttentionSinkWrapper": {
    "__init__": [
      "self",
      "float_workspace_buffer",
      "kv_layout",
      "use_cuda_graph",
      "qo_indptr_buf",
      "paged_kv_indptr_buf",
      "paged_kv_indices_buf",
      "paged_kv_last_page_len_buf",
      "custom_mask_buf",
      "mask_indptr_buf",
      "backend",
      "pos_encoding_mode",
      "use_fp16_qk_reduction",
      "q_data_type",
      "kv_data_type",
      "head_dim_qk",
      "head_dim_vo",
      "window_left"
    ]
  },
  "get_pod_module": [],
  "get_batch_pod_module": [],
  "PODWithPagedKVCacheWrapper": {
    "__init__": [
      "self",
      "float_workspace_buffer",
      "kv_layout",
      "use_cuda_graph",
      "paged_kv_indptr_buffer",
      "paged_kv_indices_buffer",
      "paged_kv_last_page_len_buffer",
      "jit_args"
    ],
    "is_cuda_graph_enabled": [
      "self"
    ],
    "reset_workspace_buffer": [
      "self",
      "float_workspace_buffer",
      "int_workspace_buffer"
    ],
    "plan": [
      "self",
      "indptr",
      "indices",
      "last_page_len",
      "num_qo_heads",
      "num_kv_heads",
      "head_dim",
      "page_size",
      "pos_encoding_mode",
      "window_left",
      "q_data_type",
      "kv_data_type",
      "data_type",
      "sm_scale",
      "rope_scale",
      "rope_theta",
      "non_blocking"
    ],
    "begin_forward": [],
    "run": [
      "self",
      "q_p",
      "k_p",
      "v_p",
      "q_d",
      "paged_kv_cache_d",
      "custom_mask_p",
      "packed_custom_mask_p",
      "causal_p",
      "kv_layout_p",
      "pos_encoding_mode_p",
      "sm_scale_p",
      "window_left_p",
      "rope_scale_p",
      "rope_theta_p",
      "return_lse_p",
      "custom_mask_d",
      "packed_custom_mask_d",
      "causal_d",
      "kv_layout_d",
      "pos_encoding_mode_d",
      "sm_scale_d",
      "window_left_d",
      "rope_scale_d",
      "rope_theta_d",
      "q_scale",
      "k_scale",
      "v_scale",
      "return_lse_d",
      "use_fp16_qk_reduction",
      "enable_pdl"
    ],
    "end_forward": [
      "self"
    ]
  },
  "BatchPODWithPagedKVCacheWrapper": {
    "__init__": [
      "self",
      "float_workspace_buffer",
      "kv_layout"
    ],
    "is_cuda_graph_enabled": [
      "self"
    ],
    "plan": [
      "self",
      "qo_indptr_p",
      "kv_indptr_p",
      "kv_indices_p",
      "last_page_len_p",
      "qo_indptr_d",
      "kv_indptr_d",
      "kv_indices_d",
      "last_page_len_d",
      "num_qo_heads",
      "num_kv_heads",
      "head_dim",
      "page_size",
      "pos_encoding_mode",
      "window_left",
      "q_data_type",
      "kv_data_type",
      "data_type",
      "sm_scale",
      "rope_scale",
      "rope_theta",
      "non_blocking"
    ],
    "begin_forward": [],
    "run": [
      "self",
      "q_p",
      "paged_kv_cache_p",
      "q_d",
      "paged_kv_cache_d",
      "custom_mask_p",
      "packed_custom_mask_p",
      "causal_p",
      "q_scale",
      "k_scale",
      "v_scale",
      "return_lse",
      "use_fp16_qk_reduction",
      "enable_pdl"
    ],
    "end_forward": [
      "self"
    ]
  },
  "_compute_swizzled_layout_sf_size": [
    "total_row",
    "total_column",
    "row_size"
  ],
  "_pad_scale_factors": [
    "unswizzled_sf",
    "m",
    "n",
    "sf_vec_size"
  ],
  "gen_fp4_quantization_sm100_module": [],
  "gen_fp4_quantization_sm103_module": [],
  "gen_fp4_quantization_sm90_module": [],
  "gen_fp4_quantization_sm110_module": [],
  "gen_fp4_quantization_sm120_module": [],
  "gen_fp4_quantization_sm121_module": [],
  "gen_fp4_quantization_module": [
    "nvcc_flags",
    "device_arch"
  ],
  "get_fp4_quantization_module": [
    "backend"
  ],
  "fp4_quantize": [
    "input",
    "global_scale",
    "sf_vec_size",
    "sf_use_ue8m0",
    "is_sf_swizzled_layout",
    "is_sf_8x4_layout",
    "enable_pdl"
  ],
  "block_scale_interleave": [
    "unswizzled_sf"
  ],
  "nvfp4_block_scale_interleave": [],
  "e2m1_and_ufp8sf_scale_to_float": [
    "e2m1_tensor",
    "ufp8_scale_tensor",
    "global_scale_tensor",
    "sf_vec_size",
    "ufp8_type",
    "is_sf_swizzled_layout"
  ],
  "shuffle_matrix_a": [
    "input_tensor",
    "epilogue_tile_m"
  ],
  "shuffle_matrix_sf_a": [
    "input_tensor",
    "epilogue_tile_m",
    "num_elts_per_sf"
  ],
  "SfLayout": {
    "layout_128x4": [],
    "layout_8x4": [],
    "layout_linear": []
  },
  "nvfp4_quantize": [
    "a",
    "a_global_sf",
    "sfLayout",
    "do_shuffle",
    "sf_vec_size",
    "enable_pdl"
  ],
  "mxfp4_quantize": [
    "a"
  ],
  "mxfp4_dequantize": [
    "a_fp4",
    "a_sf"
  ],
  "mxfp4_dequantize_host": [
    "weight",
    "scale",
    "group_size"
  ],
  "nvfp4_batched_quantize": [
    "a",
    "a_global_sf",
    "sf_vec_size"
  ],
  "scaled_fp4_grouped_quantize": [
    "a",
    "mask",
    "a_global_sf"
  ],
  "_check_cutlass_shape": [
    "q_nope_pe",
    "ckv_kpe_cache",
    "kv_len",
    "page_table"
  ],
  "_check_trtllm_gen_mla_shape": [
    "query",
    "kv_cache",
    "qk_nope_head_dim",
    "kv_lora_rank",
    "qk_rope_head_dim",
    "sparse_mla_top_k",
    "page_table",
    "page_size"
  ],
  "get_mla_module": [],
  "get_batch_mla_module": [
    "backend"
  ],
  "BatchMLAPagedAttentionWrapper": {
    "__init__": [
      "self",
      "float_workspace_buffer",
      "use_cuda_graph",
      "qo_indptr",
      "kv_indptr",
      "kv_indices",
      "kv_len_arr",
      "backend"
    ],
    "plan": [
      "self",
      "qo_indptr",
      "kv_indptr",
      "kv_indices",
      "kv_len_arr",
      "num_heads",
      "head_dim_ckv",
      "head_dim_kpe",
      "page_size",
      "causal",
      "sm_scale",
      "q_data_type",
      "kv_data_type",
      "use_profiler"
    ],
    "run": [
      "self",
      "q_nope",
      "q_pe",
      "ckv_cache",
      "kpe_cache",
      "out",
      "lse",
      "return_lse",
      "profiler_buffer",
      "kv_len",
      "page_table",
      "return_lse_base_on_e"
    ]
  },
  "trtllm_batch_decode_with_kv_cache_mla": [
    "query",
    "kv_cache",
    "workspace_buffer",
    "qk_nope_head_dim",
    "kv_lora_rank",
    "qk_rope_head_dim",
    "block_tables",
    "seq_lens",
    "max_seq_len",
    "sparse_mla_top_k",
    "out",
    "bmm1_scale",
    "bmm2_scale",
    "sinks",
    "skip_softmax_threshold_scale_factor",
    "enable_pdl",
    "backend"
  ],
  "xqa_batch_decode_with_kv_cache_mla": [
    "query",
    "kv_cache",
    "workspace_buffer",
    "qk_nope_head_dim",
    "kv_lora_rank",
    "qk_rope_head_dim",
    "block_tables",
    "seq_lens",
    "max_seq_len",
    "out",
    "bmm1_scale",
    "bmm2_scale",
    "sinks",
    "enable_pdl"
  ],
  "get_concat_mla_module": [],
  "concat_mla_k": [
    "k",
    "k_nope",
    "k_rope"
  ],
  "GemmType": {
    "Normal": [],
    "GroupedContiguous": [],
    "GroupedMasked": [],
    "__str__": [
      "self"
    ]
  },
  "MajorTypeAB": {
    "KMajor": [],
    "MNMajor": [],
    "shape_direction": [
      "self"
    ],
    "non_contiguous_dim": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "MajorTypeCD": {
    "NMajor": [],
    "MMajor": [],
    "non_contiguous_dim": [
      "self"
    ]
  },
  "major_check": [
    "t"
  ],
  "get_major_type_ab": [
    "t"
  ],
  "get_major_type_cd": [
    "t"
  ],
  "get_element_size": [
    "dtype"
  ],
  "get_m_alignment_for_contiguous_layout": [],
  "get_tma_aligned_size": [
    "x",
    "element_size"
  ],
  "get_col_major_tma_aligned_packed_tensor": [
    "x"
  ],
  "check_sf_layout": [
    "sf",
    "mn",
    "k",
    "gran",
    "num_groups",
    "tma_stride_check",
    "type_check"
  ],
  "transform_sf_into_required_layout": [
    "sf",
    "mn",
    "k",
    "recipe",
    "num_groups",
    "is_sfa"
  ],
  "get_device_arch": [],
  "hash_to_hex": [
    "s"
  ],
  "must_be_k_major": [],
  "get_default_recipe": [
    "sfa_dtype",
    "sfb_dtype"
  ],
  "MulticastConfig": {
    "__init__": [
      "self",
      "num_multicast",
      "is_multicast_on_a"
    ],
    "get_ab_load_block_m": [
      "self",
      "block_m"
    ],
    "get_ab_load_block_n": [
      "self",
      "block_n"
    ]
  },
  "SharedMemoryConfig": {
    "__init__": [
      "self",
      "smem_size",
      "swizzle_a_mode",
      "swizzle_b_mode",
      "swizzle_cd_mode"
    ]
  },
  "is_multicast_legal": [
    "shape_dim",
    "block_dim",
    "num_multicast",
    "num_sms",
    "require_divisible"
  ],
  "get_swizzle_mode": [
    "block_size",
    "elem_size"
  ],
  "get_sf_aligned_block_sizes": [
    "block_m",
    "block_n",
    "ab_dtype"
  ],
  "is_tmem_size_legal": [
    "block_m",
    "block_n",
    "ab_dtype"
  ],
  "get_smem_config": [
    "block_m",
    "block_n",
    "block_k",
    "major_a",
    "major_b",
    "major_d",
    "ab_dtype",
    "cd_dtype",
    "num_stages",
    "multicast_config"
  ],
  "get_best_configs": [
    "gemm_type",
    "m",
    "n",
    "k",
    "num_groups",
    "major_a",
    "major_b",
    "major_d",
    "ab_dtype",
    "cd_dtype",
    "num_sms"
  ],
  "swizzle_type_map": [],
  "make_tma_xd_desc": [
    "t",
    "gmem_dims",
    "gmem_strides",
    "smem_dims",
    "swizzle_type"
  ],
  "make_tma_2d_desc": [
    "t",
    "gmem_inner_dim",
    "gmem_outer_dim",
    "smem_inner_dim",
    "smem_outer_dim",
    "gmem_outer_stride",
    "swizzle_mode"
  ],
  "make_tma_a_desc": [
    "major_type",
    "t",
    "shape_m",
    "shape_k",
    "block_m",
    "block_k",
    "outer_stride",
    "num_groups",
    "swizzle_mode"
  ],
  "make_tma_b_desc": [
    "major_type",
    "t",
    "shape_n",
    "shape_k",
    "block_n",
    "block_k",
    "outer_stride",
    "num_groups",
    "swizzle_mode"
  ],
  "make_tma_cd_desc": [
    "major_type",
    "t",
    "shape_m",
    "shape_n",
    "block_m",
    "block_n",
    "outer_stride",
    "num_groups",
    "swizzle_mode"
  ],
  "make_tma_sf_desc": [
    "major_type",
    "t",
    "shape_mn",
    "shape_k",
    "block_mn",
    "block_k",
    "num_groups",
    "swizzle_mode"
  ],
  "pytypes_to_ctypes": [],
  "RUNTIME_CACHE": [],
  "SM100FP8GemmRuntime": {
    "__init__": [
      "self",
      "path",
      "symbol"
    ],
    "__call__": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "generate": [
      "kwargs"
    ],
    "launch": [
      "kernel",
      "kwargs"
    ]
  },
  "load_all": [],
  "load": [
    "name",
    "code"
  ],
  "m_grouped_fp8_gemm_nt_contiguous_static_kwargs_gen": [
    "m",
    "n",
    "k",
    "aligned_k",
    "num_groups",
    "major_a",
    "major_b",
    "major_d",
    "compiled_dims",
    "output_dtype"
  ],
  "m_grouped_fp8_gemm_nt_contiguous_kwargs_gen": [
    "a",
    "sfa",
    "b",
    "sfb",
    "d",
    "m_indices",
    "major_a",
    "major_b",
    "compiled_dims"
  ],
  "m_grouped_fp8_gemm_nt_contiguous_sm10x": [
    "a",
    "sfa",
    "b",
    "sfb",
    "d",
    "m_indices",
    "major_a",
    "major_b",
    "compiled_dims"
  ],
  "m_grouped_fp8_gemm_nt_masked_static_kwargs_gen": [
    "m",
    "n",
    "k",
    "expected_m",
    "aligned_k",
    "num_groups",
    "major_a",
    "major_b",
    "major_d",
    "compiled_dims",
    "output_dtype"
  ],
  "m_grouped_fp8_gemm_nt_masked_kwargs_gen": [
    "a",
    "sfa",
    "b",
    "sfb",
    "d",
    "masked_m",
    "expected_m",
    "major_a",
    "major_b",
    "compiled_dims"
  ],
  "m_grouped_fp8_gemm_nt_masked_sm10x": [
    "a",
    "sfa",
    "b",
    "sfb",
    "d",
    "masked_m",
    "expected_m",
    "major_a",
    "major_b",
    "compiled_dims"
  ],
  "_check_group_deepgemm_fp8_nt_contiguous_problem_size": [
    "a_fp8",
    "b_fp8",
    "d",
    "m_indices",
    "recipe",
    "compiled_dims"
  ],
  "m_grouped_fp8_gemm_nt_contiguous": [
    "a_fp8",
    "b_fp8",
    "d",
    "m_indices",
    "recipe",
    "compiled_dims"
  ],
  "_check_m_grouped_fp8_gemm_nt_masked_problem_size": [
    "a_fp8",
    "b_fp8",
    "d",
    "masked_m",
    "expected_m",
    "recipe",
    "compiled_dims"
  ],
  "m_grouped_fp8_gemm_nt_masked": [
    "a_fp8",
    "b_fp8",
    "d",
    "masked_m",
    "expected_m",
    "recipe",
    "compiled_dims"
  ],
  "KernelMap": {
    "KERNEL_MAP_HASH": [],
    "__init__": [
      "self"
    ],
    "init_indices": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ]
  },
  "KERNEL_MAP": [],
  "_substitute_process_id": [
    "path"
  ],
  "_API_LOG_LEVEL": [],
  "_API_LOG_DEST": [],
  "_DUMP_DIR": [],
  "_DUMP_MAX_SIZE_GB": [],
  "_DUMP_MAX_COUNT": [],
  "_DUMP_INCLUDE": [],
  "_DUMP_EXCLUDE": [],
  "_DUMP_INCLUDE_PATTERNS": [],
  "_DUMP_EXCLUDE_PATTERNS": [],
  "_DUMP_SAFETENSORS": [],
  "_dump_count": [],
  "_dump_total_size_bytes": [],
  "_dump_call_counter": [],
  "_session_jsonl_initialized": [],
  "_logger": [],
  "_setup_logger": [],
  "_get_timestamp": [],
  "_warn_dump": [],
  "_should_dump_function": [
    "func_name"
  ],
  "_append_to_jsonl": [
    "filepath",
    "record"
  ],
  "_read_jsonl_last_record": [
    "filepath"
  ],
  "_get_tensor_size_bytes": [
    "tensor"
  ],
  "_serialize_value": [
    "value"
  ],
  "_extract_tensors_and_metadata": [
    "args",
    "kwargs"
  ],
  "_dump_function_inputs": [
    "func",
    "func_name",
    "args",
    "kwargs",
    "self_id"
  ],
  "_dump_function_outputs": [
    "dump_dir",
    "result"
  ],
  "_reconstruct_value": [
    "value"
  ],
  "_resolve_function": [
    "module_name",
    "function_name"
  ],
  "_compare_results": [
    "actual",
    "expected",
    "rtol",
    "atol"
  ],
  "replay_from_dump": [
    "dump_dir",
    "compare_outputs",
    "device",
    "run",
    "object_registry"
  ],
  "replay_sequence": [
    "root_dir",
    "device"
  ],
  "_log_system_info": [],
  "_format_value": [
    "value",
    "level",
    "indent"
  ],
  "_get_default_params": [
    "func",
    "args",
    "kwargs"
  ],
  "_log_function_inputs": [
    "func",
    "func_name",
    "args",
    "kwargs",
    "level"
  ],
  "_log_function_outputs": [
    "func_name",
    "result",
    "level"
  ],
  "flashinfer_api": [
    "func"
  ],
  "get_page_module": [],
  "_append_paged_mla_kv_cache_kernel": [
    "append_ckv",
    "append_kpe",
    "batch_indices",
    "positions",
    "ckv_cache",
    "kpe_cache",
    "kv_indices",
    "kv_indptr",
    "kv_last_page_len"
  ],
  "_append_paged_kv_cache_kernel": [
    "append_key",
    "append_value",
    "batch_indices",
    "positions",
    "paged_k_cache",
    "paged_v_cache",
    "kv_indices",
    "kv_indptr",
    "kv_last_page_len",
    "layout"
  ],
  "_fake_append_paged_kv_cache_kernel": [
    "append_key",
    "append_value",
    "batch_indices",
    "positions",
    "paged_k_cache",
    "paged_v_cache",
    "kv_indices",
    "kv_indptr",
    "kv_last_page_len",
    "layout"
  ],
  "get_batch_indices_positions": [
    "append_indptr",
    "seq_lens",
    "nnz",
    "batch_indices",
    "positions"
  ],
  "get_seq_lens": [
    "kv_indptr",
    "kv_last_page_len",
    "page_size"
  ],
  "append_paged_mla_kv_cache": [
    "append_ckv",
    "append_kpe",
    "batch_indices",
    "positions",
    "ckv_cache",
    "kpe_cache",
    "kv_indices",
    "kv_indptr",
    "kv_last_page_len"
  ],
  "append_paged_kv_cache": [
    "append_key",
    "append_value",
    "batch_indices",
    "positions",
    "paged_kv_cache",
    "kv_indices",
    "kv_indptr",
    "kv_last_page_len",
    "kv_layout"
  ],
  "_nvfp4_cutlass_version": [],
  "get_config_path": [
    "is_module"
  ],
  "DynamicTensorSpec": {
    "__post_init__": [
      "self"
    ],
    "__hash__": [
      "self"
    ]
  },
  "ConstraintSpec": {},
  "TuningConfig": {},
  "StaticDim": {
    "_opt": [
      "self"
    ]
  },
  "DynamicDim": {
    "_opt": [
      "self"
    ]
  },
  "Dim": [],
  "OptimizationProfile": {
    "get_hash_key": [
      "self"
    ],
    "get_opt_shapes": [
      "self"
    ]
  },
  "FakeTensor": {},
  "TunableRunner": {
    "get_valid_tactics": [
      "self",
      "inputs",
      "profile"
    ],
    "__call__": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "inputs",
      "tactic",
      "do_preparation"
    ],
    "__hash__": [
      "self"
    ]
  },
  "autotune": [
    "tune_mode"
  ],
  "AutoTunerStatistics": {
    "__str__": [
      "self"
    ]
  },
  "load_from_file": [
    "key"
  ],
  "AutoTuner": {
    "_instance": [],
    "__init__": [
      "self",
      "warmup",
      "repeat",
      "stream_delay_micro_secs"
    ],
    "get": [
      "cls"
    ],
    "search_cache": [
      "self",
      "custom_op",
      "runners",
      "input_shapes",
      "tuning_config"
    ],
    "choose_one": [
      "self",
      "custom_op",
      "runners",
      "tuning_config",
      "inputs"
    ],
    "_get_input_sizes": [
      "self",
      "inputs"
    ],
    "_profile_single_kernel": [
      "self",
      "runner",
      "inputs",
      "tactic"
    ],
    "_generate_optimization_profiles": [
      "self",
      "tuning_config",
      "inputs"
    ],
    "_find_nearest_profile": [
      "cls",
      "shapes",
      "tuning_config"
    ],
    "_get_cache_key": [
      "cls",
      "custom_op",
      "runner",
      "input_shapes",
      "tuning_config"
    ],
    "_create_tensor_like": [
      "self",
      "origin_tensor",
      "dims",
      "initializer"
    ],
    "_prepare_input_tensors": [
      "self",
      "profile",
      "inputs"
    ],
    "clear_cache": [
      "self"
    ],
    "reset_statistics": [
      "self"
    ]
  },
  "get_xqa_module": [
    "input_dtype",
    "kv_cache_dtype",
    "page_size",
    "head_dim",
    "head_group_ratio",
    "use_sliding_window",
    "output_dtype",
    "q_seq_len"
  ],
  "xqa": [
    "q",
    "k_cache",
    "v_cache",
    "page_table",
    "seq_lens",
    "output",
    "workspace_buffer",
    "semaphores",
    "num_kv_heads",
    "page_size",
    "sinks",
    "q_scale",
    "kv_scale",
    "sliding_win_size",
    "kv_layout",
    "sm_count",
    "enable_pdl",
    "rcp_out_scale",
    "q_seq_len",
    "mask"
  ],
  "get_xqa_module_mla": [
    "input_dtype",
    "kv_cache_dtype",
    "page_size",
    "head_dim",
    "head_group_ratio",
    "use_sliding_window"
  ],
  "xqa_mla": [
    "q",
    "k_cache",
    "v_cache",
    "page_table",
    "seq_lens",
    "output",
    "workspace_buffer",
    "semaphores",
    "page_size",
    "q_scale",
    "kv_scale",
    "sm_count",
    "enable_pdl"
  ],
  "gen_fa2": [
    "dtype_qo",
    "dtype_kv",
    "head_dim_qk",
    "head_dim_vo",
    "use_sliding_window",
    "use_logits_soft_cap"
  ],
  "gen_fa3": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "head_dim_qk",
    "head_dim_vo",
    "use_sliding_window",
    "use_logits_soft_cap"
  ],
  "gen_attention": [
    "f16_dtype_",
    "f8_dtype_",
    "fa2_head_dim_",
    "fa3_head_dim_",
    "use_sliding_window_",
    "use_logits_soft_cap_",
    "has_sm90",
    "has_sm100",
    "add_gemma",
    "add_oai_oss"
  ],
  "gen_xqa": [
    "input_type_",
    "fp8_kv_cache_",
    "token_per_page_",
    "head_size_",
    "head_grp_size_",
    "use_sliding_window_",
    "has_sm90",
    "has_sm100",
    "has_sm120",
    "has_sm121"
  ],
  "gen_all_modules": [
    "f16_dtype_",
    "f8_dtype_",
    "fa2_head_dim_",
    "fa3_head_dim_",
    "use_sliding_window_",
    "use_logits_soft_cap_",
    "sm_capabilities",
    "add_comm",
    "add_gemma",
    "add_oai_oss",
    "add_moe",
    "add_act",
    "add_misc",
    "add_xqa"
  ],
  "copy_built_kernels": [
    "jit_specs",
    "out_dir"
  ],
  "compile_and_package_modules": [
    "out_dir",
    "build_dir",
    "project_root",
    "config",
    "verbose",
    "skip_prebuilt"
  ],
  "parse_bool": [
    "s"
  ],
  "parse_head_dim": [
    "head_dim"
  ],
  "get_default_config": [],
  "detect_sm_capabilities": [],
  "register_default_modules": [],
  "main": [],
  "logger": [],
  "temp_env_var": [
    "key",
    "value"
  ],
  "get_available_cubin_files": [
    "source",
    "retries",
    "delay",
    "timeout"
  ],
  "ArtifactPath": {},
  "CheckSumHash": {},
  "get_checksums": [
    "subdirs"
  ],
  "get_subdir_file_list": [],
  "download_artifacts": [],
  "get_artifacts_status": [],
  "clear_cubin": [],
  "get_rope_module": [],
  "_apply_rope": [
    "q",
    "k",
    "q_rope",
    "k_rope",
    "indptr",
    "offsets",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta"
  ],
  "_fake_apply_rope": [
    "q",
    "k",
    "q_rope",
    "k_rope",
    "indptr",
    "offsets",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta"
  ],
  "_apply_llama31_rope": [
    "q",
    "k",
    "q_rope",
    "k_rope",
    "indptr",
    "offsets",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta",
    "low_freq_factor",
    "high_freq_factor",
    "old_context_len"
  ],
  "_fake_apply_llama31_rope": [
    "q",
    "k",
    "q_rope",
    "k_rope",
    "indptr",
    "offsets",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta",
    "low_freq_factor",
    "high_freq_factor",
    "old_context_len"
  ],
  "_apply_rope_pos_ids": [
    "q",
    "k",
    "q_rope",
    "k_rope",
    "pos_ids",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta"
  ],
  "_fake_apply_rope_pos_ids": [
    "q",
    "k",
    "q_rope",
    "k_rope",
    "pos_ids",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta"
  ],
  "_rope_quantize": [
    "q_rope_in",
    "k_rope_in",
    "q_nope_in",
    "k_nope_in",
    "cos_sin_cache",
    "pos_ids",
    "q_rope_out",
    "k_rope_out",
    "q_nope_out",
    "k_nope_out",
    "quant_scale_q",
    "quant_scale_kv",
    "interleave",
    "enable_pdl"
  ],
  "_fake_rope_quantize": [
    "q_rope_in",
    "k_rope_in",
    "q_nope_in",
    "k_nope_in",
    "cos_sin_cache",
    "pos_ids",
    "q_rope_out",
    "k_rope_out",
    "q_nope_out",
    "k_nope_out",
    "quant_scale_q",
    "quant_scale_kv",
    "interleave",
    "enable_pdl"
  ],
  "_rope_quantize_fp8_append_paged_kv_cache": [
    "q_rope_in",
    "k_rope_in",
    "q_nope_in",
    "k_nope_in",
    "v_in",
    "q_rope_out",
    "q_nope_out",
    "cos_sin_cache",
    "pos_ids",
    "k_cache",
    "v_cache",
    "ckv_cache",
    "kpe_cache",
    "kv_indices",
    "kv_indptr",
    "batch_indices",
    "positions",
    "kv_layout_code",
    "page_size",
    "quant_scale_q",
    "quant_scale_kv",
    "interleave",
    "enable_pdl"
  ],
  "_fake_rope_quantize_fp8_append_paged_kv_cache": [
    "q_rope_in",
    "k_rope_in",
    "q_nope_in",
    "k_nope_in",
    "v_in",
    "q_rope_out",
    "q_nope_out",
    "cos_sin_cache",
    "pos_ids",
    "k_cache",
    "v_cache",
    "ckv_cache",
    "kpe_cache",
    "kv_indices",
    "kv_indptr",
    "batch_indices",
    "positions",
    "kv_layout_code",
    "page_size",
    "quant_scale_q",
    "quant_scale_kv",
    "interleave",
    "enable_pdl"
  ],
  "_apply_rope_pos_ids_cos_sin_cache": [
    "q",
    "k",
    "q_rope",
    "k_rope",
    "cos_sin_cache",
    "pos_ids",
    "interleave"
  ],
  "_fake_apply_rope_pos_ids_cos_sin_cache": [
    "q",
    "k",
    "q_rope",
    "k_rope",
    "cos_cache",
    "sin_cache",
    "pos_ids",
    "interleave"
  ],
  "_apply_llama31_rope_pos_ids": [
    "q",
    "k",
    "q_rope",
    "k_rope",
    "pos_ids",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta",
    "low_freq_factor",
    "high_freq_factor",
    "old_context_len"
  ],
  "_fake_apply_llama31_rope_pos_ids": [
    "q",
    "k",
    "q_rope",
    "k_rope",
    "pos_ids",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta",
    "low_freq_factor",
    "high_freq_factor",
    "old_context_len"
  ],
  "apply_rope_inplace": [
    "q",
    "k",
    "indptr",
    "offsets",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta"
  ],
  "apply_rope_pos_ids_inplace": [
    "q",
    "k",
    "pos_ids",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta"
  ],
  "apply_llama31_rope_inplace": [
    "q",
    "k",
    "indptr",
    "offsets",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta",
    "low_freq_factor",
    "high_freq_factor",
    "old_context_len"
  ],
  "apply_llama31_rope_pos_ids_inplace": [
    "q",
    "k",
    "pos_ids",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta",
    "low_freq_factor",
    "high_freq_factor",
    "old_context_len"
  ],
  "apply_rope": [
    "q",
    "k",
    "indptr",
    "offsets",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta"
  ],
  "apply_rope_pos_ids": [
    "q",
    "k",
    "pos_ids",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta"
  ],
  "apply_llama31_rope": [
    "q",
    "k",
    "indptr",
    "offsets",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta",
    "low_freq_factor",
    "high_freq_factor",
    "old_context_len"
  ],
  "apply_llama31_rope_pos_ids": [
    "q",
    "k",
    "pos_ids",
    "rotary_dim",
    "interleave",
    "rope_scale",
    "rope_theta",
    "low_freq_factor",
    "high_freq_factor",
    "old_context_len"
  ],
  "apply_rope_with_cos_sin_cache": [
    "positions",
    "query",
    "key",
    "head_size",
    "cos_sin_cache",
    "is_neox"
  ],
  "apply_rope_with_cos_sin_cache_inplace": [
    "positions",
    "query",
    "key",
    "head_size",
    "cos_sin_cache",
    "is_neox"
  ],
  "mla_rope_quantize_fp8": [
    "q_rope",
    "k_rope",
    "q_nope",
    "k_nope",
    "cos_sin_cache",
    "pos_ids",
    "is_neox",
    "quantize_dtype",
    "quant_scale_q",
    "quant_scale_kv",
    "q_rope_out",
    "k_rope_out",
    "q_nope_out",
    "k_nope_out",
    "enable_pdl"
  ],
  "rope_quantize_fp8": [
    "q_rope",
    "k_rope",
    "q_nope",
    "k_nope",
    "cos_sin_cache",
    "pos_ids",
    "is_neox",
    "quantize_dtype",
    "quant_scale_q",
    "quant_scale_kv",
    "q_rope_out",
    "k_rope_out",
    "q_nope_out",
    "k_nope_out",
    "enable_pdl"
  ],
  "rope_quantize_fp8_append_paged_kv_cache": [
    "q_rope",
    "k_rope",
    "q_nope",
    "k_nope",
    "v",
    "cos_sin_cache",
    "pos_ids",
    "paged_kv_cache",
    "kv_indices",
    "kv_indptr",
    "batch_indices",
    "positions",
    "is_neox",
    "quantize_dtype",
    "quant_scale_q",
    "quant_scale_kv",
    "page_size",
    "kv_layout",
    "q_rope_out",
    "q_nope_out",
    "enable_pdl"
  ],
  "CompilationContext": {
    "COMMON_NVCC_FLAGS": [],
    "__init__": [
      "self"
    ],
    "get_nvcc_flags_list": [
      "self",
      "supported_major_versions"
    ]
  },
  "TILE_V": [],
  "TILE_K": [],
  "NUM_STAGES": [],
  "NUM_THREADS": [],
  "NUM_BLOCKS_PER_STATE": [],
  "TILE_K_NT": [],
  "TILE_V_NT": [],
  "TILE_V_PADDED_NT": [],
  "TILE_V_SMALL_NT": [],
  "TILE_V_SMALL_PADDED_NT": [],
  "NUM_STAGES_NT": [],
  "NUM_THREADS_NT": [],
  "NUM_BLOCKS_PER_STATE_SMALL_NT": [],
  "NUM_THREADS_LARGE_NT": [],
  "NUM_WARPS_LARGE_NT": [],
  "V_PER_WARP_NT": [],
  "ROWS_PER_ITER_NT": [],
  "NUM_K_ITERS_NT": [],
  "SMALL_BATCH_THRESHOLD_NT": [],
  "TILE_K_MTP": [],
  "NUM_THREADS_MTP": [],
  "get_vec_size_mtp": [
    "batch_size",
    "seq_len"
  ],
  "get_tile_v_mtp": [
    "batch_size",
    "seq_len"
  ],
  "gdn_decode_kernel_small_batch_pretranspose": [
    "tiled_copy_load",
    "h0_source",
    "smem_layout_staged",
    "vec_size",
    "num_v_tiles",
    "A_log",
    "a",
    "dt_bias",
    "q",
    "k",
    "v",
    "b",
    "o",
    "h0_indices",
    "cu_seqlens",
    "softplus_beta",
    "softplus_threshold",
    "scale",
    "HV",
    "B",
    "T",
    "H",
    "K",
    "V",
    "use_initial_state",
    "use_qk_l2norm",
    "is_varlen"
  ],
  "gdn_decode_kernel_big_batch_pretranspose": [
    "tiled_copy_load",
    "h0_source",
    "smem_layout_staged",
    "vec_size",
    "num_v_tiles",
    "A_log",
    "a",
    "dt_bias",
    "q",
    "k",
    "v",
    "b",
    "o",
    "h0_indices",
    "cu_seqlens",
    "softplus_beta",
    "softplus_threshold",
    "scale",
    "HV",
    "B",
    "T",
    "H",
    "K",
    "V",
    "use_initial_state",
    "use_qk_l2norm",
    "is_varlen"
  ],
  "run_gdn_decode_kernel_small_batch_pretranspose": [
    "h0_source",
    "A_log",
    "a",
    "dt_bias",
    "q",
    "k",
    "v",
    "b",
    "o",
    "h0_indices",
    "cu_seqlens",
    "softplus_beta",
    "softplus_threshold",
    "scale",
    "HV",
    "B",
    "T",
    "H",
    "K",
    "V",
    "use_initial_state",
    "use_qk_l2norm",
    "is_varlen",
    "stream"
  ],
  "run_gdn_decode_kernel_big_batch_pretranspose": [
    "h0_source",
    "A_log",
    "a",
    "dt_bias",
    "q",
    "k",
    "v",
    "b",
    "o",
    "h0_indices",
    "cu_seqlens",
    "softplus_beta",
    "softplus_threshold",
    "scale",
    "HV",
    "B",
    "T",
    "H",
    "K",
    "V",
    "use_initial_state",
    "use_qk_l2norm",
    "is_varlen",
    "stream"
  ],
  "_get_compiled_decode_kernel": [
    "B",
    "T",
    "H",
    "HV",
    "K",
    "V",
    "dtype",
    "scale",
    "use_qk_l2norm"
  ],
  "_get_compiled_decode_kernel_nontranspose": [
    "B",
    "T",
    "H",
    "HV",
    "K",
    "V",
    "dtype",
    "scale",
    "use_qk_l2norm"
  ],
  "gated_delta_rule_decode_pretranspose": [
    "q",
    "k",
    "v",
    "state",
    "A_log",
    "a",
    "dt_bias",
    "b",
    "scale",
    "output",
    "use_qk_l2norm"
  ],
  "gdn_decode_kernel_small_batch_nontranspose": [
    "tiled_copy_load",
    "h0_source",
    "smem_layout_staged",
    "num_v_tiles",
    "q",
    "k",
    "v",
    "a",
    "b",
    "A_log",
    "dt_bias",
    "o",
    "h0_indices",
    "softplus_beta",
    "softplus_threshold",
    "scale",
    "H",
    "HV",
    "use_qk_l2norm"
  ],
  "gdn_decode_kernel_big_batch_nontranspose": [
    "tiled_copy_load",
    "h0_source",
    "smem_layout_staged",
    "num_v_tiles",
    "q",
    "k",
    "v",
    "a",
    "b",
    "A_log",
    "dt_bias",
    "o",
    "h0_indices",
    "softplus_beta",
    "softplus_threshold",
    "scale",
    "H",
    "HV",
    "use_qk_l2norm"
  ],
  "run_gdn_decode_kernel_small_batch_nontranspose": [
    "cu_seqlens",
    "q",
    "k",
    "v",
    "a",
    "b",
    "A_log",
    "dt_bias",
    "h0_source",
    "h0_indices",
    "o",
    "softplus_beta",
    "softplus_threshold",
    "scale",
    "B",
    "T",
    "H",
    "HV",
    "K",
    "V",
    "use_initial_state",
    "use_qk_l2norm",
    "stream"
  ],
  "run_gdn_decode_kernel_big_batch_nontranspose": [
    "cu_seqlens",
    "q",
    "k",
    "v",
    "a",
    "b",
    "A_log",
    "dt_bias",
    "h0_source",
    "h0_indices",
    "o",
    "softplus_beta",
    "softplus_threshold",
    "scale",
    "B",
    "T",
    "H",
    "HV",
    "K",
    "V",
    "use_initial_state",
    "use_qk_l2norm",
    "stream"
  ],
  "gated_delta_rule_decode": [
    "q",
    "k",
    "v",
    "state",
    "A_log",
    "a",
    "dt_bias",
    "b",
    "scale",
    "output",
    "use_qk_l2norm"
  ],
  "gdn_verify_kernel_mtp": [
    "h0_source",
    "intermediate_states",
    "vec_size",
    "num_v_tiles",
    "tile_v",
    "A_log",
    "a",
    "dt_bias",
    "q",
    "k",
    "v",
    "b",
    "o",
    "h0_indices",
    "cu_seqlens",
    "softplus_beta",
    "softplus_threshold",
    "scale",
    "HV",
    "B",
    "T",
    "H",
    "K",
    "V",
    "use_initial_state",
    "use_qk_l2norm",
    "is_varlen",
    "disable_state_update",
    "cache_intermediate_states"
  ],
  "run_gdn_verify_kernel_mtp": [
    "h0_source",
    "intermediate_states",
    "A_log",
    "a",
    "dt_bias",
    "q",
    "k",
    "v",
    "b",
    "o",
    "h0_indices",
    "cu_seqlens",
    "softplus_beta",
    "softplus_threshold",
    "scale",
    "HV",
    "B",
    "T",
    "H",
    "K",
    "V",
    "tile_v",
    "vec_size",
    "use_initial_state",
    "use_qk_l2norm",
    "is_varlen",
    "disable_state_update",
    "cache_intermediate_states",
    "stream"
  ],
  "_get_compiled_mtp_kernel": [
    "B",
    "T",
    "H",
    "HV",
    "K",
    "V",
    "pool_size",
    "cache_steps",
    "disable_state_update",
    "cache_intermediate_states",
    "scale",
    "use_qk_l2norm",
    "tile_v",
    "vec_size"
  ],
  "gated_delta_rule_mtp": [
    "q",
    "k",
    "v",
    "initial_state",
    "initial_state_indices",
    "A_log",
    "a",
    "dt_bias",
    "b",
    "scale",
    "output",
    "intermediate_states_buffer",
    "disable_state_update",
    "use_qk_l2norm"
  ],
  "__version__": [],
  "__git_version__": [],
  "get_mxfp8_quantization_sm100_module": [],
  "mxfp8_quantize": [
    "input",
    "is_sf_swizzled_layout",
    "alignment",
    "enable_pdl"
  ],
  "mxfp8_dequantize_host": [
    "input",
    "scale_tensor",
    "is_sf_swizzled_layout"
  ],
  "_download_cubin": [],
  "_ensure_modules_registered": [],
  "cli": [
    "ctx",
    "download_cubin_flag"
  ],
  "env_variables": [],
  "show_config_cmd": [],
  "list_cubins_cmd": [],
  "download_cubin_cmd": [],
  "clear_cache_cmd": [],
  "clear_cubin_cmd": [],
  "module_status_cmd": [
    "detailed",
    "filter"
  ],
  "list_modules_cmd": [
    "module_name"
  ],
  "export_compile_commands_cmd": [
    "path",
    "output"
  ],
  "replay_cmd": [
    "dump_dir"
  ],
  "get_trtllm_low_latency_gemm_module": [],
  "trtllm_low_latency_gemm": [
    "A",
    "B",
    "global_scale",
    "out"
  ],
  "prepare_low_latency_gemm_weights": [
    "w",
    "permutation_indices_cache"
  ],
  "AllReduceFusionWorkspace": {
    "__init__": [
      "self",
      "world_size",
      "rank"
    ],
    "backend": [
      "self"
    ],
    "destroy": [
      "self"
    ],
    "is_buffer_size_sufficient": [
      "self",
      "tp_size",
      "num_tokens",
      "hidden_dim",
      "dtype",
      "use_oneshot"
    ],
    "__del__": [
      "self"
    ]
  },
  "NVSHMEMAllReduce": {
    "__init__": [
      "self",
      "local_rank",
      "world_size",
      "max_buffer_elements",
      "dtype",
      "device",
      "group",
      "should_init"
    ],
    "init_nvshmem": [
      "self"
    ],
    "all_reduce": [
      "self",
      "inp",
      "out"
    ],
    "shutdown": [
      "self"
    ]
  },
  "get_nvshmem_module": [],
  "get_unique_id": [],
  "unique_id_size": [],
  "alloc_empty_unique_id": [],
  "init": [
    "uid",
    "rank",
    "world_size"
  ],
  "alltoall": [
    "dest",
    "source"
  ],
  "finalize": [],
  "my_pe": [],
  "n_pes": [],
  "malloc": [
    "shape",
    "dtype",
    "device"
  ],
  "barrier_all": [],
  "barrier_all_on_current_stream": [],
  "_A2AState": {},
  "get_moe_alltoall_module": [],
  "moe_a2a_initialize": [
    "workspace",
    "ep_rank",
    "ep_size",
    "max_num_tokens"
  ],
  "moe_a2a_wrap_payload_tensor_in_workspace": [
    "workspace",
    "leading_shape",
    "slice_start",
    "slice_end",
    "dtype"
  ],
  "moe_a2a_dispatch": [
    "token_selected_experts",
    "input_payloads",
    "workspace",
    "metainfo",
    "runtime_max_tokens_per_rank",
    "ep_rank",
    "ep_size",
    "top_k",
    "num_experts"
  ],
  "moe_a2a_combine": [
    "payload",
    "local_num_tokens",
    "workspace",
    "metainfo",
    "runtime_max_tokens_per_rank",
    "ep_rank",
    "ep_size",
    "top_k",
    "combine_payload_offset",
    "payload_in_workspace"
  ],
  "moe_a2a_sanitize_expert_ids": [
    "expert_ids",
    "workspace",
    "metainfo",
    "ep_rank",
    "invalid_expert_id"
  ],
  "moe_a2a_get_workspace_size_per_rank": [
    "ep_size",
    "max_num_tokens",
    "total_dispatch_payload_size_per_token",
    "combine_payload_size_per_token"
  ],
  "MoeAlltoAll": {
    "get_workspace": [
      "cls",
      "workspace_size_per_rank",
      "ep_rank",
      "ep_size",
      "max_num_tokens",
      "mapping"
    ],
    "get_moe_workspace_size_per_rank": [
      "ep_size",
      "top_k",
      "max_num_tokens",
      "hidden_size",
      "extra_payload_bytes_per_token"
    ],
    "_init_constants": [
      "cls"
    ],
    "__init__": [
      "self",
      "mapping",
      "max_num_tokens",
      "top_k",
      "num_experts",
      "workspace_size_per_rank",
      "hidden_size",
      "mnnvl_config"
    ],
    "_reset_workspace": [
      "self"
    ],
    "dispatch": [
      "self",
      "token_selected_experts",
      "input_payloads",
      "runtime_max_tokens_per_rank",
      "invalid_token_expert_id",
      "expert_id_payload_index"
    ],
    "combine": [
      "self",
      "payload",
      "runtime_max_tokens_per_rank",
      "payload_in_workspace"
    ],
    "get_combine_payload_tensor_in_workspace": [
      "self",
      "runtime_max_tokens_per_rank",
      "hidden_size",
      "dtype"
    ]
  },
  "__all__": [],
  "cudaError_t": [],
  "cudaMemcpyKind": [],
  "cudaIpcMemHandle_t": {
    "_fields_": []
  },
  "Function": {},
  "find_loaded_library": [
    "lib_name"
  ],
  "CudaRTLibrary": {
    "exported_functions": [],
    "__init__": [
      "self",
      "so_file"
    ],
    "CUDART_CHECK": [
      "self",
      "result"
    ],
    "cudaGetErrorString": [
      "self",
      "error"
    ],
    "cudaSetDevice": [
      "self",
      "device"
    ],
    "cudaDeviceSynchronize": [
      "self"
    ],
    "cudaDeviceReset": [
      "self"
    ],
    "cudaMalloc": [
      "self",
      "size"
    ],
    "cudaFree": [
      "self",
      "devPtr"
    ],
    "cudaMemset": [
      "self",
      "devPtr",
      "value",
      "count"
    ],
    "cudaMemcpy": [
      "self",
      "dst",
      "src",
      "count"
    ],
    "cudaIpcGetMemHandle": [
      "self",
      "devPtr"
    ],
    "cudaIpcOpenMemHandle": [
      "self",
      "handle"
    ]
  },
  "cudart": [],
  "create_shared_buffer": [
    "size_in_bytes",
    "group"
  ],
  "free_shared_buffer": [
    "pointers",
    "group"
  ],
  "AllReduceStrategyType": {
    "NCCL": [],
    "MIN_LATENCY": [],
    "UB": [],
    "AUTO": [],
    "ONESHOT": [],
    "TWOSHOT": [],
    "LOWPRECISION": []
  },
  "AllReduceStrategyConfig": {
    "USE_MEMCPY": [],
    "PUSH_MODE": []
  },
  "AllReduceFusionOp": {
    "NONE": [],
    "RESIDUAL_RMS_NORM": [],
    "LAST_PROCESS_FOR_UB": [],
    "RESIDUAL_RMS_PREPOST_NORM": [],
    "RESIDUAL_RMS_NORM_QUANT_FP8": [],
    "RESIDUAL_RMS_NORM_QUANT_NVFP4": [],
    "RESIDUAL_RMS_NORM_OUT_QUANT_FP8": [],
    "RESIDUAL_RMS_NORM_OUT_QUANT_NVFP4": [],
    "MOE_ALLREDUCE_RESIDUAL_RMS_NORM": [],
    "MOE_FINALIZE_ALLREDUCE_RESIDUAL_RMS_NORM": []
  },
  "AllReduceFusionPattern": {
    "kAllReduce": [],
    "kARResidualRMSNorm": [],
    "kARResidualRMSNormFP8Quant": [],
    "kARResidualRMSNormFP4Quant": [],
    "kARResidualRMSNormOutFP8Quant": [],
    "kARResidualRMSNormOutFP4Quant": []
  },
  "QuantizationSFLayout": {
    "SWIZZLED_128x4": [],
    "SWIZZLED_8x4": [],
    "LINEAR": []
  },
  "get_trtllm_comm_module": [],
  "OneShotMaxToken": [],
  "MAX_ALL_REDUCE_BLOCKS": [],
  "LamportTokenNumThreshold": [],
  "trtllm_create_ipc_workspace_for_all_reduce": [
    "rank",
    "tp_size",
    "max_token_num",
    "hidden_dim",
    "group"
  ],
  "trtllm_destroy_ipc_workspace_for_all_reduce": [
    "workspace",
    "group"
  ],
  "BarrierFlagCount": [],
  "MAX_COMM_SIZE": [],
  "trtllm_create_ipc_workspace_for_all_reduce_fusion": [
    "tp_rank",
    "tp_size",
    "max_token_num",
    "hidden_dim",
    "use_fp32_lamport",
    "group",
    "create_metadata",
    "comm_backend",
    "use_symm_dev_mem"
  ],
  "trtllm_destroy_ipc_workspace_for_all_reduce_fusion": [
    "workspace",
    "group"
  ],
  "compute_fp4_swizzled_layout_sf_size": [
    "total_row",
    "total_column"
  ],
  "trtllm_lamport_initialize": [
    "buffer_ptr",
    "size",
    "dtype"
  ],
  "trtllm_lamport_initialize_all": [
    "buffer_0_ptr",
    "buffer_1_ptr",
    "buffer_2_ptr",
    "size",
    "dtype"
  ],
  "trtllm_custom_all_reduce": [
    "inp",
    "out",
    "tp_size",
    "tp_rank",
    "token_num",
    "fusion_op_code",
    "strategy_code",
    "config_code",
    "launch_with_pdl",
    "flag_value",
    "peer_comm_buffer_ptrs",
    "peer_barrier_ptrs_in",
    "peer_barrier_ptrs_out",
    "bias",
    "residual",
    "weight",
    "weight_pre_residual_norm",
    "eps",
    "intermediate_buffer",
    "lamport_peer_comm_buffer_ptrs_0",
    "lamport_peer_comm_buffer_ptrs_1",
    "lamport_peer_comm_buffer_ptrs_2"
  ],
  "_should_use_oneshot": [
    "token_num",
    "hidden_dim",
    "dtype",
    "world_size"
  ],
  "check_trtllm_allreduce_fusion_workspace_metadata": [
    "token_num",
    "hidden_dim",
    "world_size",
    "dtype",
    "metadata"
  ],
  "trtllm_allreduce_fusion": [
    "allreduce_in",
    "world_size",
    "world_rank",
    "token_num",
    "hidden_dim",
    "workspace_ptrs",
    "launch_with_pdl",
    "trigger_completion_at_end",
    "fp32_acc",
    "pattern_code",
    "use_oneshot",
    "allreduce_out",
    "residual_in",
    "residual_out",
    "norm_out",
    "quant_out",
    "scale_out",
    "rms_gamma",
    "rms_eps",
    "scale_factor",
    "layout_code",
    "metadata"
  ],
  "trtllm_moe_allreduce_fusion": [
    "world_size",
    "world_rank",
    "token_num",
    "hidden_dim",
    "workspace_ptrs",
    "launch_with_pdl",
    "residual_in",
    "rms_gamma",
    "rms_eps",
    "scale_factor",
    "moe_reduction_device_num_experts",
    "moe_reduction_scale_input",
    "moe_reduction_active_experts_token_input",
    "moe_reduction_token_input",
    "layout_code",
    "moe_allreduce_out",
    "residual_out",
    "norm_out",
    "quant_out",
    "scale_out"
  ],
  "trtllm_moe_finalize_allreduce_fusion": [
    "allreduce_in",
    "residual_in",
    "norm_weight",
    "expanded_idx_to_permuted_idx",
    "norm_out",
    "residual_out",
    "workspace_ptrs",
    "launch_with_pdl",
    "world_rank",
    "world_size",
    "eps",
    "shared_expert_output",
    "expert_scale_factor"
  ],
  "DLDataType": {
    "_fields_": []
  },
  "DLDevice": {
    "_fields_": []
  },
  "DLTensor": {
    "_fields_": []
  },
  "DLManagedTensorDeleter": [],
  "DLManagedTensor": {},
  "no_op_deleter": [
    "dmt_ptr"
  ],
  "CapsuleWrapper": {
    "__init__": [
      "self",
      "capsule",
      "shape_array",
      "managed_tensor"
    ]
  },
  "create_dlpack_capsule": [
    "ptr",
    "segment_size",
    "segment_stride",
    "num_segments",
    "torch_dtype",
    "dev_id"
  ],
  "pack_strided_memory": [
    "ptr",
    "segment_size",
    "segment_stride",
    "num_segments",
    "dtype",
    "dev_id"
  ],
  "TRTLLMAllReduceFusionWorkspace": {
    "__init__": [
      "self",
      "tp_size",
      "tp_rank",
      "max_token_num",
      "hidden_dim",
      "dtype",
      "comm_backend"
    ],
    "backend": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "is_buffer_size_sufficient": [
      "self",
      "tp_size",
      "num_tokens",
      "hidden_dim",
      "dtype",
      "use_oneshot"
    ],
    "destroy": [
      "self"
    ]
  },
  "_trtllm_workspace_check": [
    "backend",
    "world_size",
    "rank",
    "max_token_num",
    "hidden_dim",
    "dtype"
  ],
  "_mnnvl_workspace_check": [
    "backend",
    "world_size",
    "rank",
    "max_token_num",
    "hidden_dim",
    "dtype"
  ],
  "_workspace_creation_heuristic": [
    "suitable_backends",
    "backend",
    "world_size",
    "rank",
    "max_token_num",
    "hidden_dim",
    "dtype"
  ],
  "create_allreduce_fusion_workspace": [
    "backend",
    "world_size",
    "rank",
    "max_token_num",
    "hidden_dim",
    "dtype",
    "gpus_per_node",
    "comm_backend",
    "force_oneshot_support"
  ],
  "allreduce_fusion": [
    "input",
    "workspace",
    "pattern",
    "launch_with_pdl",
    "output",
    "residual_out",
    "norm_out",
    "quant_out",
    "scale_out",
    "residual_in",
    "rms_gamma",
    "rms_eps",
    "scale_factor",
    "layout_code",
    "use_oneshot",
    "fp32_acc"
  ],
  "get_comm_alltoall_module": [],
  "moe_comm_prepare_indices": [
    "gathered_target_rank_ids",
    "real_rank_token_count_cum_sum",
    "max_token_count_per_rank",
    "expert_count",
    "top_k",
    "ep_rank",
    "ep_size"
  ],
  "moe_local_gather": [
    "recv_rank_cum_sum",
    "local_gather_indices",
    "gathered_expert_ids",
    "gathered_scales",
    "local_expert_ids",
    "local_scales",
    "max_token_count_per_rank",
    "expert_count",
    "top_k",
    "ep_rank",
    "ep_size"
  ],
  "moe_comm": [
    "input",
    "send_rank_cum_sum",
    "send_indices",
    "output",
    "recv_rank_cum_sum",
    "recv_indices",
    "all_workspaces",
    "ep_rank",
    "ep_size"
  ],
  "set_moe_max_usable_sm_count": [
    "max_sm_count"
  ],
  "get_moe_commworkspace_size_per_rank": [
    "ep_size"
  ],
  "get_moe_prepare_workspace_size_per_rank": [
    "ep_size"
  ],
  "moe_prepare": [
    "experts_ids",
    "scales",
    "experts_statics",
    "workspace",
    "max_token_count_per_rank",
    "ep_rank",
    "ep_size",
    "expert_count",
    "slot_count",
    "top_k"
  ],
  "MoEAlltoallInfo": {},
  "MnnvlMoe": {
    "get_moe_workspaces": [
      "mapping",
      "config"
    ],
    "get_moe_prepare_workspace": [
      "mapping",
      "config"
    ],
    "compute_target_rank_id": [
      "token_selected_experts",
      "expert_count",
      "ep_size"
    ],
    "mnnvl_moe_alltoallv_prepare_without_allgather": [
      "expert_ids",
      "scales",
      "expert_statics",
      "workspace",
      "max_token_count_per_rank",
      "ep_rank",
      "ep_size",
      "expert_count",
      "slot_count",
      "top_k"
    ],
    "mnnvl_moe_alltoallv_prepare": [
      "gathered_target_rank_ids",
      "real_rank_token_count_cumsum",
      "gathered_expert_ids",
      "gathered_scales",
      "max_token_count_per_rank",
      "expert_count",
      "top_k",
      "ep_rank",
      "ep_size"
    ],
    "mnnvl_moe_alltoallv": [
      "x",
      "alltoall_info",
      "workspace",
      "ep_rank",
      "ep_size"
    ],
    "mnnvl_moe_alltoallv_combine": [
      "x",
      "alltoall_info",
      "workspace",
      "ep_rank",
      "ep_size",
      "top_k",
      "token_count"
    ]
  },
  "OMPI_COMM_TYPE_HOST": [],
  "SIGNAL_PAD_SIZE": [],
  "MNNVL_DEBUG": [],
  "create_tensor_from_cuda_memory": [
    "ptr",
    "shape",
    "dtype",
    "device_id"
  ],
  "test_cuda_memory_access": [
    "ptr",
    "size",
    "device_id"
  ],
  "alloc_and_copy_to_cuda": [
    "host_ptr_array"
  ],
  "CommBackend": {
    "Get_rank": [
      "self"
    ],
    "Get_size": [
      "self"
    ],
    "allgather": [
      "self",
      "data"
    ],
    "bcast": [
      "self",
      "data",
      "root"
    ],
    "barrier": [
      "self"
    ],
    "Split": [
      "self",
      "color",
      "key"
    ]
  },
  "lazy_import_mpi": [],
  "MpiComm": {
    "_get_mpi": [
      "cls"
    ],
    "set_mpi_comm": [
      "cls",
      "new_comm"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "MPIBackend": {
    "__init__": [
      "self"
    ],
    "Get_rank": [
      "self"
    ],
    "Get_size": [
      "self"
    ],
    "allgather": [
      "self",
      "data"
    ],
    "bcast": [
      "self",
      "data",
      "root"
    ],
    "barrier": [
      "self"
    ],
    "Split": [
      "self",
      "color",
      "key"
    ]
  },
  "TorchDistBackend": {
    "__init__": [
      "self",
      "group"
    ],
    "Get_rank": [
      "self"
    ],
    "Get_size": [
      "self"
    ],
    "allgather": [
      "self",
      "data"
    ],
    "bcast": [
      "self",
      "data",
      "root"
    ],
    "barrier": [
      "self"
    ],
    "Split": [
      "self",
      "color",
      "key"
    ]
  },
  "MnnvlConfig": {},
  "MnnvlMemory": {
    "__init__": [
      "self",
      "mapping",
      "size"
    ],
    "__del__": [
      "self"
    ],
    "as_torch_strided_tensor": [
      "self",
      "dtype"
    ],
    "initialize": [],
    "set_comm_from_config": [
      "mapping",
      "config"
    ],
    "get_comm": [
      "mapping"
    ],
    "get_allocation_prop": [
      "dev_id"
    ],
    "get_allocation_granularity": [
      "dev_id"
    ],
    "new_mnnvl_memory_address": [
      "mapping",
      "size"
    ],
    "open_mnnvl_memory": [
      "mapping",
      "size"
    ],
    "close_mnnvl_memory": [
      "ptr"
    ],
    "support_nvlink": [
      "need_all_up"
    ],
    "supports_mnnvl": []
  },
  "IpcSocket": {
    "__init__": [
      "self",
      "rank",
      "op_id",
      "use_abstract"
    ],
    "send_fd": [
      "self",
      "fd",
      "dest_rank",
      "dest_op_id"
    ],
    "recv_fd": [
      "self"
    ],
    "close": [
      "self"
    ]
  },
  "HandleExchanger": {
    "__init__": [
      "self",
      "comm_backend",
      "group_rank",
      "group_size"
    ],
    "handle_type": [
      "self"
    ],
    "allgather": [
      "self",
      "local_handle"
    ],
    "broadcast": [
      "self",
      "handle",
      "root"
    ],
    "cleanup": [
      "self",
      "handle"
    ],
    "close": [
      "self"
    ]
  },
  "FabricHandleExchanger": {
    "handle_type": [
      "self"
    ],
    "allgather": [
      "self",
      "local_handle"
    ],
    "broadcast": [
      "self",
      "handle",
      "root"
    ],
    "cleanup": [
      "self",
      "handle"
    ],
    "close": [
      "self"
    ]
  },
  "PosixFDHandleExchanger": {
    "__init__": [
      "self",
      "comm_backend",
      "group_rank",
      "group_size"
    ],
    "_init_ipc_socket": [
      "self"
    ],
    "handle_type": [
      "self"
    ],
    "allgather": [
      "self",
      "local_handle"
    ],
    "broadcast": [
      "self",
      "handle",
      "root"
    ],
    "cleanup": [
      "self",
      "handle"
    ],
    "close": [
      "self"
    ]
  },
  "is_mnnvl_fabric_supported": [
    "device_idx"
  ],
  "SymmDeviceMemory": {
    "__init__": [
      "self",
      "buf_size",
      "group_size",
      "group_rank",
      "device_idx",
      "comm_backend_for_handle_transfer",
      "enable_multicast",
      "allocate_signal_pads"
    ],
    "__del__": [
      "self"
    ],
    "get_signal_pad_ptrs_host": [
      "self"
    ],
    "get_buffer_ptrs_host": [
      "self"
    ],
    "get_signal_pad_ptrs_dev": [
      "self"
    ],
    "get_buffer_ptrs_dev": [
      "self"
    ],
    "get_unicast_ptr": [
      "self",
      "rank"
    ],
    "get_multicast_ptr": [
      "self"
    ],
    "get_rank": [
      "self"
    ],
    "get_world_size": [
      "self"
    ],
    "get_allocation_size": [
      "self"
    ],
    "get_usable_buffer_size": [
      "self"
    ],
    "_alloc_mn_mcast_mem": [
      "self",
      "buf_size",
      "enable_multicast"
    ],
    "_verify_cuda_context": [
      "self"
    ],
    "_get_allocation_prop": [
      "self",
      "buf_size"
    ],
    "_allocate_unicast_buffers": [
      "self",
      "allocation_prop"
    ],
    "_setup_multicast": [
      "self",
      "mc_prop"
    ],
    "_get_mem_access_desc": [
      "self"
    ],
    "lamport_initialize": [
      "self",
      "rank",
      "dtype"
    ]
  },
  "McastGPUBuffer": {
    "__init__": [
      "self",
      "buf_size",
      "group_size",
      "group_rank",
      "device",
      "comm_backend_for_handle_transfer"
    ],
    "lamport_initialize": [
      "self",
      "rank",
      "dtype"
    ],
    "get_multicast_buffer": [
      "self",
      "sizes",
      "dtype",
      "storage_offset"
    ],
    "get_unicast_buffer": [
      "self",
      "sizes",
      "dtype",
      "storage_offset"
    ],
    "get_multicast_ptr": [
      "self"
    ],
    "get_unicast_ptr": [
      "self",
      "rank"
    ],
    "get_buffer_ptrs_dev": [
      "self"
    ]
  },
  "mpi_barrier": [],
  "MNNVLAllreduceFusionStrategy": {
    "ONESHOT": [],
    "TWOSHOT": [],
    "AUTO": [],
    "select_strategy": [
      "tp_size",
      "num_tokens",
      "hidden_dim",
      "dtype"
    ]
  },
  "MNNVL_ONE_SHOT_THRESHOLD": [],
  "MNNVLAllReduceFusionWorkspace": {
    "NUM_LAMPORT_BUFFERS": [],
    "__init__": [
      "self",
      "mapping",
      "max_num_tokens",
      "hidden_dim",
      "dtype",
      "buffer_size_in_bytes",
      "comm_backend"
    ],
    "is_buffer_size_sufficient": [
      "self",
      "tp_size",
      "num_tokens",
      "hidden_dim",
      "dtype",
      "strategy"
    ],
    "get_required_buffer_size_bytes": [
      "tp_size",
      "num_tokens",
      "hidden_dim",
      "dtype",
      "strategy"
    ],
    "backend": [
      "self"
    ],
    "destroy": [
      "self"
    ]
  },
  "get_trtllm_mnnvl_comm_module": [],
  "trtllm_mnnvl_allreduce": [
    "input",
    "workspace",
    "launch_with_pdl",
    "output",
    "strategy"
  ],
  "trtllm_mnnvl_fused_allreduce_add_rmsnorm": [
    "input",
    "residual_in",
    "gamma",
    "workspace",
    "epsilon",
    "output",
    "residual_out",
    "launch_with_pdl",
    "strategy"
  ],
  "get_allreduce_mnnvl_workspace": [
    "mapping",
    "dtype",
    "comm_backend_for_handle_transfer",
    "buffer_size_in_bytes"
  ],
  "trtllm_mnnvl_all_reduce": [
    "inp",
    "multicast_buffer_ptr",
    "buffer_ptrs_dev",
    "buffer_M",
    "buffer_flags_mnnvl",
    "nranks",
    "rank",
    "wait_for_results",
    "launch_with_pdl",
    "out"
  ],
  "trtllm_mnnvl_fused_allreduce_rmsnorm": [
    "prenorm_output",
    "normed_output",
    "shard_input",
    "multicast_buffer_ptr",
    "buffer_ptrs_dev",
    "unicast_ptr",
    "buffer_M",
    "buffer_flags_mnnvl",
    "nranks",
    "rank",
    "gamma",
    "epsilon",
    "residual",
    "launch_with_pdl"
  ],
  "get_vllm_comm_module": [],
  "init_custom_ar": [
    "ipc_tensors",
    "rank_data",
    "rank",
    "full_nvlink"
  ],
  "dispose": [
    "fa"
  ],
  "all_reduce": [
    "fa",
    "inp",
    "out",
    "reg_buffer",
    "reg_buffer_sz_bytes",
    "num_ctas"
  ],
  "get_graph_buffer_ipc_meta": [
    "fa"
  ],
  "register_buffer": [
    "fa",
    "fake_ipc_ptrs"
  ],
  "register_graph_buffers": [
    "fa",
    "handles",
    "offsets"
  ],
  "meta_size": [],
  "Mapping": {
    "__init__": [
      "self",
      "world_size",
      "rank",
      "gpus_per_node"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__hash__": [
      "self"
    ],
    "rank": [
      "self",
      "rank"
    ],
    "tp_rank": [
      "self"
    ],
    "pp_rank": [
      "self"
    ],
    "cp_rank": [
      "self"
    ],
    "moe_tp_rank": [
      "self"
    ],
    "moe_cluster_rank": [
      "self"
    ],
    "moe_ep_rank": [
      "self"
    ],
    "tp_group": [
      "self"
    ],
    "pp_group": [
      "self"
    ],
    "cp_group": [
      "self"
    ],
    "moe_tp_group": [
      "self"
    ],
    "moe_cluster_group": [
      "self"
    ],
    "moe_ep_group": [
      "self"
    ],
    "node_rank": [
      "self"
    ],
    "local_rank": [
      "self"
    ],
    "has_cp": [
      "self"
    ],
    "get_node_rank": [
      "self",
      "rank"
    ],
    "get_local_rank": [
      "self",
      "rank"
    ],
    "is_multi_node": [
      "self"
    ],
    "has_tp": [
      "self"
    ],
    "is_last_pp_rank": [
      "self"
    ],
    "is_second_last_pp_rank": [
      "self"
    ],
    "is_first_pp_rank": [
      "self"
    ],
    "has_pp": [
      "self"
    ],
    "prev_pp_rank": [
      "self"
    ],
    "next_pp_rank": [
      "self"
    ],
    "has_moe_cluster": [
      "self"
    ],
    "has_moe_tp": [
      "self"
    ],
    "has_moe_ep": [
      "self"
    ],
    "pp_layers": [
      "self",
      "num_layers"
    ],
    "ep_experts": [
      "self",
      "num_experts"
    ],
    "from_dict": [
      "cls",
      "mapping"
    ],
    "to_dict": [
      "self"
    ]
  },
  "gen_cascade_module": [],
  "gen_norm_module": [],
  "gen_moe_utils_module": [],
  "gen_trtllm_utils_module": [],
  "parse_env_flags": [
    "env_var_name"
  ],
  "_get_glibcxx_abi_build_flags": [],
  "get_cuda_path": [],
  "get_cuda_version": [],
  "is_cuda_version_at_least": [
    "version_str"
  ],
  "join_multiline": [
    "vs"
  ],
  "get_system_includes": [
    "cuda_home"
  ],
  "build_common_cflags": [
    "cuda_home",
    "extra_include_dirs"
  ],
  "build_cflags": [
    "common_cflags",
    "extra_cflags"
  ],
  "build_cuda_cflags": [
    "common_cflags",
    "extra_cuda_cflags"
  ],
  "generate_ninja_build_for_op": [
    "name",
    "sources",
    "extra_cflags",
    "extra_cuda_cflags",
    "extra_ldflags",
    "extra_include_dirs",
    "needs_device_linking"
  ],
  "_get_num_workers": [],
  "run_ninja": [
    "workdir",
    "ninja_file",
    "verbose"
  ],
  "gen_comm_alltoall_module": [],
  "gen_trtllm_mnnvl_comm_module": [],
  "gen_nvshmem_module": [],
  "gen_trtllm_comm_module": [],
  "gen_vllm_comm_module": [],
  "gen_moe_alltoall_module": [],
  "MissingJITCacheError": {
    "__init__": [
      "self",
      "message",
      "spec"
    ]
  },
  "FlashInferJITLogger": {
    "__init__": [
      "self",
      "name"
    ],
    "debug_once": [
      "self",
      "msg"
    ],
    "info_once": [
      "self",
      "msg"
    ],
    "warning_once": [
      "self",
      "msg"
    ],
    "_print_once": [
      "self",
      "log_method",
      "msg"
    ]
  },
  "check_cuda_arch": [],
  "clear_cache_dir": [],
  "common_nvcc_flags": [],
  "sm89_nvcc_flags": [],
  "sm90a_nvcc_flags": [],
  "sm100a_nvcc_flags": [],
  "sm103a_nvcc_flags": [],
  "sm100f_nvcc_flags": [],
  "sm110a_nvcc_flags": [],
  "sm120a_nvcc_flags": [],
  "sm121a_nvcc_flags": [],
  "current_compilation_context": [],
  "JitSpecStatus": {
    "status": [
      "self"
    ]
  },
  "JitSpecRegistry": {
    "__init__": [
      "self"
    ],
    "register": [
      "self",
      "spec"
    ],
    "get_all_specs": [
      "self"
    ],
    "get_spec_status": [
      "self",
      "name"
    ],
    "get_all_statuses": [
      "self"
    ],
    "get_stats": [
      "self"
    ]
  },
  "jit_spec_registry": [],
  "JitSpec": {
    "ninja_path": [
      "self"
    ],
    "build_dir": [
      "self"
    ],
    "jit_library_path": [
      "self"
    ],
    "get_library_path": [
      "self"
    ],
    "get_object_paths": [
      "self"
    ],
    "aot_path": [
      "self"
    ],
    "is_aot": [
      "self"
    ],
    "is_compiled": [
      "self"
    ],
    "lock_path": [
      "self"
    ],
    "write_ninja": [
      "self"
    ],
    "is_ninja_generated": [
      "self"
    ],
    "build": [
      "self",
      "verbose",
      "need_lock"
    ],
    "load": [
      "self",
      "so_path"
    ],
    "build_and_load": [
      "self"
    ],
    "get_compile_commands": [
      "self"
    ]
  },
  "gen_jit_spec": [
    "name",
    "sources",
    "extra_cflags",
    "extra_cuda_cflags",
    "extra_ldflags",
    "extra_include_paths",
    "needs_device_linking"
  ],
  "get_tmpdir": [],
  "build_jit_specs": [
    "specs",
    "verbose",
    "skip_prebuilt"
  ],
  "gen_sampling_module": [],
  "gen_quantization_module": [],
  "gen_topk_module": [],
  "dtype_map": [],
  "dtype_cutlass_map": [],
  "filename_safe_dtype_map": [],
  "pos_encoding_mode_literal": [],
  "mask_mode_literal": [],
  "activation_templ": [],
  "get_act_and_mul_cu_str": [
    "act_func_name",
    "act_func_def"
  ],
  "silu_def_cu_str": [],
  "gelu_def_cu_str": [],
  "gelu_def_tanh_cu_str": [],
  "act_func_def_str": [],
  "gen_act_and_mul_module": [
    "act_func_name"
  ],
  "cuda_lib_path": [],
  "gen_gdn_prefill_sm90_module": [],
  "gen_spdlog_module": [],
  "gen_mla_module": [],
  "gen_page_module": [],
  "xqa_nvcc_flags": [],
  "gen_xqa_module": [
    "input_dtype",
    "kv_cache_dtype",
    "page_size",
    "head_dim",
    "head_group_ratio",
    "use_sliding_window",
    "output_dtype",
    "q_seq_len"
  ],
  "gen_xqa_module_mla": [
    "input_dtype",
    "kv_cache_dtype",
    "page_size",
    "head_dim",
    "head_group_ratio",
    "use_sliding_window"
  ],
  "has_flashinfer_jit_cache": [],
  "has_flashinfer_cubin": [],
  "_get_cubin_dir": [],
  "_get_aot_dir": [],
  "_get_workspace_dir_name": [],
  "get_nvshmem_include_dirs": [],
  "get_nvshmem_lib_dirs": [],
  "FLASHINFER_CUBINS_REPOSITORY": [],
  "safe_urljoin": [
    "base",
    "path"
  ],
  "download_file": [
    "source",
    "destination",
    "retries",
    "delay",
    "timeout",
    "lock_timeout",
    "session"
  ],
  "get_meta_hash": [
    "checksums_bytes"
  ],
  "verify_cubin": [
    "cubin_path",
    "expected_sha256"
  ],
  "load_cubin": [
    "cubin_path",
    "sha256"
  ],
  "get_cubin": [
    "file_name",
    "sha256",
    "session"
  ],
  "convert_to_ctypes_char_p": [
    "data"
  ],
  "dll_cubin_handlers": [],
  "setup_cubin_loader": [
    "dll_path"
  ],
  "gen_rope_module": [],
  "gen_concat_mla_module": [],
  "gen_dsv3_router_gemm_module": [],
  "gen_dsv3_fused_routing_module": [],
  "gen_mxfp8_quantization_sm100_module": [],
  "gen_cutlass_fused_moe_sm120_module": [
    "use_fast_build"
  ],
  "gen_cutlass_fused_moe_sm103_module": [
    "use_fast_build"
  ],
  "gen_cutlass_fused_moe_sm100_module": [
    "use_fast_build"
  ],
  "gen_cutlass_fused_moe_sm90_module": [
    "use_fast_build"
  ],
  "gen_cutlass_fused_moe_sm89_module": [
    "use_fast_build"
  ],
  "gen_cutlass_fused_moe_module": [
    "nvcc_flags",
    "device_arch",
    "use_fast_build"
  ],
  "gen_trtllm_gen_fused_moe_sm100_module": [],
  "gen_gemm_module": [],
  "gen_gemm_sm100_module_cutlass_fp4": [],
  "gen_gemm_sm103_module_cutlass_fp4": [],
  "gen_gemm_sm120_module_cutlass_fp4": [],
  "gen_gemm_sm100_module_cutlass_fp8": [],
  "gen_gemm_sm100_module_cutlass_bf16": [],
  "gen_gemm_sm100_module_cutlass_mxfp8": [],
  "gen_gemm_sm100_module": [],
  "gen_gemm_sm120_module": [],
  "gen_trtllm_gen_gemm_module": [],
  "gen_tgv_gemm_sm10x_module": [
    "dtype",
    "use_sm_100f"
  ],
  "gen_gemm_sm90_module": [],
  "gen_trtllm_low_latency_gemm_module": [],
  "gen_deepgemm_sm100_module": [],
  "gen_fp8_blockscale_gemm_sm90_module": [
    "use_fast_build"
  ],
  "GeneratorTarget": {
    "Library": []
  },
  "GeneratorTargetNames": [],
  "DataType": {
    "void": [],
    "b1": [],
    "u2": [],
    "u4": [],
    "u8": [],
    "u16": [],
    "u32": [],
    "u64": [],
    "s2": [],
    "s4": [],
    "s8": [],
    "s16": [],
    "s32": [],
    "s64": [],
    "e4m3": [],
    "e5m2": [],
    "f8": [],
    "f6": [],
    "f4": [],
    "e3m2": [],
    "e2m3": [],
    "e2m1": [],
    "ue8m0": [],
    "ue4m3": [],
    "f16": [],
    "bf16": [],
    "f32": [],
    "tf32": [],
    "f64": [],
    "cf16": [],
    "cbf16": [],
    "cf32": [],
    "ctf32": [],
    "cf64": [],
    "cs2": [],
    "cs4": [],
    "cs8": [],
    "cs16": [],
    "cs32": [],
    "cs64": [],
    "cu2": [],
    "cu4": [],
    "cu8": [],
    "cu16": [],
    "cu32": [],
    "cu64": [],
    "invalid": []
  },
  "ShortDataTypeNames": [],
  "DataTypeNames": [],
  "DataTypeTag": [],
  "DataTypeSize": [],
  "BlasMode": {
    "symmetric": [],
    "hermitian": []
  },
  "BlasModeTag": [],
  "ComplexTransform": {
    "none": [],
    "conj": []
  },
  "ComplexTransformTag": [],
  "ComplexTransformTag3x": [],
  "RealComplexBijection": [],
  "is_complex": [
    "data_type"
  ],
  "is_block_scaled": [
    "gemm_kind"
  ],
  "is_blockwise": [
    "gemm_kind"
  ],
  "is_grouped": [
    "gemm_kind"
  ],
  "get_complex_from_real": [
    "real_type"
  ],
  "get_real_from_complex": [
    "complex_type"
  ],
  "get_tma_alignment": [
    "data_type"
  ],
  "ComplexMultiplyOp": {
    "multiply_add": [],
    "gaussian": []
  },
  "MathOperation": {
    "multiply_add": [],
    "multiply_add_saturate": [],
    "multiply_add_mixed_input_upcast": [],
    "xor_popc": [],
    "and_popc": [],
    "multiply_add_fast_bf16": [],
    "multiply_add_fast_f16": [],
    "multiply_add_fast_f32": [],
    "multiply_add_complex_fast_f32": [],
    "multiply_add_complex": [],
    "multiply_add_complex_gaussian": [],
    "multiply_add_fast_accum": []
  },
  "MathOperationTag": [],
  "LayoutType": {
    "ColumnMajor": [],
    "RowMajor": [],
    "ColumnMajorInterleaved2": [],
    "RowMajorInterleaved2": [],
    "ColumnMajorInterleaved32": [],
    "RowMajorInterleaved32": [],
    "ColumnMajorInterleaved64": [],
    "RowMajorInterleaved64": [],
    "TensorNWC": [],
    "TensorNHWC": [],
    "TensorNDHWC": [],
    "TensorNCHW": [],
    "TensorNGHWC": [],
    "TensorNC32HW32": [],
    "TensorNC64HW64": [],
    "TensorC32RSK32": [],
    "TensorC64RSK64": [],
    "TensorKCS": [],
    "TensorKCSR": [],
    "TensorKCSRT": []
  },
  "LayoutTag": [],
  "TransposedLayout": [],
  "ShortLayoutTypeNames": [],
  "ShortComplexLayoutNames": [],
  "KernelScheduleType": {
    "ScheduleAuto": [],
    "Multistage": [],
    "CpAsyncWarpSpecialized": [],
    "CpAsyncWarpSpecializedPingpong": [],
    "CpAsyncWarpSpecializedCooperative": [],
    "Tma": [],
    "TmaWarpSpecialized": [],
    "TmaWarpSpecializedPingpong": [],
    "TmaWarpSpecializedCooperative": [],
    "TmaWarpSpecializedFP8FastAccum": [],
    "TmaWarpSpecializedCooperativeFP8FastAccum": [],
    "TmaWarpSpecializedPingpongFP8FastAccum": [],
    "ImplicitTmaWarpSpecializedSm90": [],
    "PtrArrayTmaWarpSpecializedCooperative": [],
    "PtrArrayTmaWarpSpecializedCooperativeFP8FastAccum": [],
    "PtrArrayTmaWarpSpecializedPingpong": [],
    "PtrArrayTmaWarpSpecializedPingpongFP8FastAccum": [],
    "BlockwiseTmaWarpSpecializedCooperative": [],
    "PtrArrayBlockwiseTmaWarpSpecializedCooperative": [],
    "TmaWarpSpecialized1SmSm100": [],
    "TmaWarpSpecialized2SmSm100": [],
    "ImplicitTmaWarpSpecialized1SmSm100": [],
    "ImplicitTmaWarpSpecialized2SmSm100": [],
    "PtrArrayTmaWarpSpecialized1SmSm100": [],
    "PtrArrayTmaWarpSpecialized2SmSm100": [],
    "PtrArrayTmaWarpSpecialized1SmBlockScaledSm100": [],
    "PtrArrayTmaWarpSpecialized2SmBlockScaledSm100": [],
    "PtrArrayNvf4TmaWarpSpecialized1SmSm100": [],
    "PtrArrayNvf4TmaWarpSpecialized2SmSm100": [],
    "PtrArrayMxf4TmaWarpSpecialized1SmSm100": [],
    "PtrArrayMxf4TmaWarpSpecialized2SmSm100": [],
    "PtrArrayMxf8f6f4TmaWarpSpecialized1SmSm100": [],
    "PtrArrayMxf8f6f4TmaWarpSpecialized2SmSm100": [],
    "SparseTmaWarpSpecialized1SmSm100": [],
    "SparseTmaWarpSpecialized2SmSm100": [],
    "BlockScaledTmaWarpSpecialized1SmSm100": [],
    "BlockScaledTmaWarpSpecialized2SmSm100": [],
    "Mxf8f6f4TmaWarpSpecialized1SmSm100": [],
    "Mxf8f6f4TmaWarpSpecialized2SmSm100": [],
    "BlockwiseTmaWarpSpecialized1SmSm100": [],
    "BlockwiseTmaWarpSpecialized2SmSm100": [],
    "PtrArrayBlockwiseTmaWarpSpecialized1SmSm100": [],
    "PtrArrayBlockwiseTmaWarpSpecialized2SmSm100": [],
    "Mxf4TmaWarpSpecialized1SmSm100": [],
    "Mxf4TmaWarpSpecialized2SmSm100": [],
    "Nvf4TmaWarpSpecialized1SmSm100": [],
    "Nvf4TmaWarpSpecialized2SmSm100": [],
    "Mxf8f6f4TmaWarpSpecializedCooperativeSm120": [],
    "Mxf8f6f4TmaWarpSpecializedPingpongSm120": [],
    "Nvf4TmaWarpSpecializedCooperativeSm120": [],
    "Nvf4TmaWarpSpecializedPingpongSm120": [],
    "Mxf4TmaWarpSpecializedCooperativeSm120": [],
    "Mxf4TmaWarpSpecializedPingpongSm120": [],
    "F8f6f4SparseTmaWarpSpecializedCooperativeSm120": [],
    "BlockwiseTmaWarpSpecializedCooperativeSm120": [],
    "BlockwiseTmaWarpSpecializedPingpongSm120": []
  },
  "KernelScheduleTag": [],
  "KernelScheduleSuffixes": [],
  "EpilogueScheduleType": {
    "ScheduleAuto": [],
    "EpilogueTransposed": [],
    "NoSmemWarpSpecialized": [],
    "PtrArrayNoSmemWarpSpecialized": [],
    "NoSmemWarpSpecialized1Sm": [],
    "NoSmemWarpSpecialized2Sm": [],
    "PtrArrayNoSmemWarpSpecialized1Sm": [],
    "PtrArrayNoSmemWarpSpecialized2Sm": [],
    "TmaWarpSpecialized": [],
    "TmaWarpSpecializedCooperative": [],
    "TmaWarpSpecialized1Sm": [],
    "TmaWarpSpecialized2Sm": [],
    "PtrArrayTmaWarpSpecialized1Sm": [],
    "PtrArrayTmaWarpSpecialized2Sm": [],
    "PtrArrayTmaWarpSpecializedPingpong": [],
    "PtrArrayTmaWarpSpecializedCooperative": []
  },
  "EpilogueScheduleTag": [],
  "EpilogueScheduleSuffixes": [],
  "EpilogueFunctor3x": {
    "LinearCombination": [],
    "LinearCombinationBlockScaleFactor": []
  },
  "EpilogueFunctor3xTag": [],
  "is_tma_epilogue": [
    "epilogue_schedule_type"
  ],
  "to_grouped_schedule": [
    "schedule",
    "grouped"
  ],
  "TileSchedulerType": {
    "Default": [],
    "Persistent": [],
    "StreamK": []
  },
  "TileSchedulerTag": [],
  "TileSchedulerSuffixes": [],
  "SideMode": {
    "Left": [],
    "Right": []
  },
  "SideModeTag": [],
  "ShortSideModeNames": [],
  "FillMode": {
    "Lower": [],
    "Upper": []
  },
  "FillModeTag": [],
  "ShortFillModeNames": [],
  "DiagType": {
    "NonUnit": [],
    "Unit": []
  },
  "DiagTypeTag": [],
  "ShortDiagTypeNames": [],
  "OpcodeClass": {
    "Simt": [],
    "TensorOp": [],
    "WmmaTensorOp": [],
    "SparseTensorOp": [],
    "BlockScaledTensorOp": []
  },
  "OpcodeClassNames": [],
  "OpcodeClassTag": [],
  "OperationKind": {
    "Gemm": [],
    "RankK": [],
    "Rank2K": [],
    "Trmm": [],
    "Symm": [],
    "Conv2d": [],
    "Conv3d": []
  },
  "OperationKindNames": [],
  "Target": {
    "library": []
  },
  "ArchitectureNames": [],
  "SharedMemPerCC": [],
  "SubstituteTemplate": [
    "template",
    "values"
  ],
  "GemmKind": {
    "Gemm": [],
    "Sparse": [],
    "Universal": [],
    "Universal3x": [],
    "SparseUniversal3x": [],
    "PlanarComplex": [],
    "PlanarComplexArray": [],
    "Grouped": [],
    "BlockScaledUniversal3x": [],
    "GroupedUniversal3x": [],
    "GroupedBlockScaledUniversal3x": [],
    "BlockwiseUniversal3x": [],
    "GroupedBlockwiseUniversal3x": []
  },
  "GemmKindNames": [],
  "RankKKind": {
    "Universal": []
  },
  "RankKKindNames": [],
  "TrmmKind": {
    "Universal": []
  },
  "TrmmKindNames": [],
  "SymmKind": {
    "Universal": []
  },
  "SymmKindNames": [],
  "EpilogueFunctor": {
    "LinearCombination": [],
    "LinearCombinationClamp": []
  },
  "EpilogueFunctorTag": [],
  "MixedInputMode": {
    "ConvertOnly": [],
    "ScaleOnly": [],
    "ScaleWithZeroPoint": []
  },
  "SwizzlingFunctor": {
    "Identity1": [],
    "Identity2": [],
    "Identity4": [],
    "Identity8": [],
    "Horizontal": [],
    "StridedDgradIdentity1": [],
    "StridedDgradIdentity4": [],
    "StridedDgradHorizontal": [],
    "StreamK": []
  },
  "SwizzlingFunctorTag": [],
  "GroupScheduleMode": {
    "Device": [],
    "Host": []
  },
  "GroupScheduleModeTag": [],
  "ShortGroupScheduleModeNames": [],
  "ConvKind": {
    "Fprop": [],
    "Dgrad": [],
    "Wgrad": []
  },
  "ConvKindTag": [],
  "ConvKindNames": [],
  "ConvMode": {
    "CrossCorrelation": [],
    "Convolution": []
  },
  "IteratorAlgorithm": {
    "Analytic": [],
    "Optimized": [],
    "FixedChannels": [],
    "FewChannels": [],
    "FixedStrideDilation": []
  },
  "IteratorAlgorithmTag": [],
  "IteratorAlgorithmNames": [],
  "StrideSupport": {
    "Strided": [],
    "Unity": [],
    "Fixed": []
  },
  "StrideSupportTag": [],
  "StrideSupportNames": [],
  "GroupMode": {
    "NoneGroup": [],
    "SingleGroup": [],
    "MultipleGroup": [],
    "Depthwise": []
  },
  "GroupModeTag": [],
  "GroupModeNames": [],
  "DynamicClusterShape": [],
  "MathInstruction": {
    "__init__": [
      "self",
      "instruction_shape",
      "element_a",
      "element_b",
      "element_accumulator",
      "opcode_class",
      "math_operation",
      "element_scale_factor"
    ]
  },
  "TileDescription": {
    "__init__": [
      "self",
      "threadblock_shape",
      "stages",
      "warp_count",
      "math_instruction",
      "min_compute",
      "max_compute",
      "cluster_shape",
      "explicit_vector_sizes"
    ],
    "procedural_name": [
      "self"
    ]
  },
  "Direct2dConvFixedStrideDilationTileDescription": {
    "__init__": [
      "self",
      "threadblock_output_shape",
      "filter_shape",
      "stages",
      "stride",
      "dilation",
      "warp_count",
      "math_instruction",
      "min_compute",
      "max_compute"
    ],
    "procedural_name": [
      "self"
    ]
  },
  "TensorDescription": {
    "__init__": [
      "self",
      "element",
      "layout",
      "alignment",
      "complex_transform"
    ]
  },
  "SymmetricTensorDescription": {
    "__init__": [
      "self",
      "element",
      "layout",
      "fill_mode",
      "alignment",
      "complex_transform",
      "side_mode"
    ]
  },
  "TriangularTensorDescription": {
    "__init__": [
      "self",
      "element",
      "layout",
      "side_mode",
      "fill_mode",
      "diag_type",
      "alignment",
      "complex_transform"
    ]
  },
  "CalculateSmemUsage": [
    "operation"
  ],
  "GemmUniversalMode": {
    "Gemm": [],
    "GemmSplitKParallel": [],
    "Batched": [],
    "Array": []
  },
  "SplitKMode": {
    "NoneSplitK": [],
    "Serial": [],
    "Parallel": []
  },
  "TrtLlm_EpilogueTag": {
    "epilogue_op_default": [],
    "epilogue_op_bias": [],
    "epilogue_op_silu": [],
    "epilogue_op_gelu": []
  },
  "TrtLlm_EpilogueFusion": {
    "epilogue_fusion_none": [],
    "epilogue_fusion_finalize": []
  },
  "EpiTagNames": [],
  "EpiTag": [],
  "EpiFusion": [],
  "EpiFusionSuffixes": [],
  "TrtLlm_QuantOp": {
    "per_column_scale_only": [],
    "finegrained_scale_only": [],
    "finegrained_scale_and_zeros": [],
    "none": []
  },
  "QuantOpNames": [],
  "QuantOpTag": [],
  "e2m1_type": {},
  "e2m1": [],
  "GetDataTypeBits": [
    "type"
  ],
  "GetDataTypeNames": [
    "type",
    "is_mx_fpx"
  ],
  "CudaTypeName": [],
  "TrtLlm_GemmLauncher": {
    "__init__": [
      "self",
      "gemm_kind",
      "arch",
      "act_type",
      "weight_type",
      "scalezero_type",
      "bias_type",
      "output_type",
      "quant_op",
      "epi_tag",
      "cta_shape",
      "warp_shape",
      "stages",
      "cga_shape",
      "mainloop_schedule",
      "epi_schedule",
      "epi_fusion",
      "is_mx_fpx",
      "dynamic_cga",
      "swap_ab"
    ],
    "__repr__": [
      "self"
    ]
  },
  "tuple_to_cute_shape": [
    "shape"
  ],
  "instantiate_operation_tma_warp_specialized": [
    "operation"
  ],
  "instantiate_operation_sm80": [
    "operation"
  ],
  "instantiate_operation": [
    "operation"
  ],
  "get_file_content": [
    "launcher_inl_files",
    "operations"
  ],
  "clean_leftover_files": [
    "output_dir",
    "generated_files"
  ],
  "write_file": [
    "launcher_inl_files",
    "operations",
    "output_file"
  ],
  "is_gemm_op_valid_sm100": [
    "op"
  ],
  "is_gemm_op_valid": [
    "op"
  ],
  "is_grouped_gemm_op_valid": [
    "op"
  ],
  "is_op_valid": [
    "op"
  ],
  "generate_sm90_mixed_gemm_operations": [],
  "generate_sm90_grouped_gemm_operations": [
    "is_arch_enabled"
  ],
  "generate_sm90_mixed_type_grouped_gemm_operations": [
    "is_arch_enabled"
  ],
  "generate_sm90_operations": [
    "is_arch_enabled"
  ],
  "calc_shape_mnk_sm100_grouped_gemm": [
    "cta_shape_mn",
    "dtype"
  ],
  "generate_sm120_grouped_gemm_operations": [
    "is_arch_enabled"
  ],
  "generate_sm120_operations": [
    "is_arch_enabled"
  ],
  "generate_sm100_grouped_gemm_operations": [
    "is_arch_enabled",
    "arch"
  ],
  "generate_sm103_operations": [
    "is_arch_enabled"
  ],
  "generate_sm100_operations": [
    "is_arch_enabled"
  ],
  "GemmSm80LauncherConfig": {
    "__init__": [
      "self",
      "gemm_kind",
      "arch",
      "dtype",
      "epi_tag",
      "cta_shape",
      "stage"
    ]
  },
  "generate_sm80_fused_grouped_gemm_operations": [],
  "generate_sm80_operations": [
    "is_arch_enabled"
  ],
  "generate_gemm_operations": [
    "output_dir",
    "architectures"
  ],
  "gen_selective_state_update_module": [],
  "gen_selective_state_update_sm90_module": [],
  "gen_selective_state_update_sm100_module": [],
  "generate_additional_params": [
    "additional_tensor_names",
    "additional_tensor_dtypes",
    "additional_scalar_names",
    "additional_scalar_dtypes",
    "is_sm90_template"
  ],
  "attention_sink_fa2_decl": [],
  "attention_sink_fa3_decl": [],
  "attention_sink_decl": [],
  "get_single_decode_uri": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap"
  ],
  "get_batch_decode_uri": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap"
  ],
  "get_batch_mla_uri": [
    "backend",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_ckv",
    "head_dim_kpe",
    "use_profiler"
  ],
  "gen_batch_mla_module": [
    "backend",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_ckv",
    "head_dim_kpe",
    "use_profiler"
  ],
  "get_batch_decode_mla_uri": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_ckv",
    "use_sliding_window",
    "use_logits_soft_cap",
    "arc"
  ],
  "gen_batch_decode_mla_module": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim",
    "num_qo_heads",
    "use_sliding_window",
    "use_logits_soft_cap",
    "use_tensor_cores"
  ],
  "get_single_prefill_uri": [
    "backend",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap",
    "use_fp16_qk_reduction"
  ],
  "get_pod_uri": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "head_dim",
    "pos_encoding_mode_p",
    "use_sliding_window_p",
    "use_logits_soft_cap_p",
    "use_fp16_qk_reduction",
    "dtype_idx",
    "pos_encoding_mode_d",
    "use_sliding_window_d",
    "use_logits_soft_cap_d"
  ],
  "get_batch_prefill_uri": [
    "backend",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap",
    "use_fp16_qk_reduction"
  ],
  "get_batch_prefill_attention_sink_uri": [
    "backend",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_sliding_window"
  ],
  "get_batch_attention_uri": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_logits_soft_cap",
    "use_profiler"
  ],
  "gen_single_decode_module": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap"
  ],
  "gen_single_prefill_module": [
    "backend",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap",
    "use_fp16_qk_reduction"
  ],
  "gen_pod_module": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "head_dim",
    "pos_encoding_mode_p",
    "use_sliding_window_p",
    "use_logits_soft_cap_p",
    "use_fp16_qk_reduction",
    "dtype_idx",
    "pos_encoding_mode_d",
    "use_sliding_window_d",
    "use_logits_soft_cap_d"
  ],
  "gen_batch_pod_module": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "head_dim",
    "pos_encoding_mode_p",
    "use_sliding_window_p",
    "use_logits_soft_cap_p",
    "use_fp16_qk_reduction",
    "dtype_idx",
    "pos_encoding_mode_d",
    "use_sliding_window_d",
    "use_logits_soft_cap_d"
  ],
  "gen_customize_pod_module": [
    "uri",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim",
    "additional_tensor_names",
    "additional_tensor_dtypes",
    "additional_scalar_names",
    "additional_scalar_dtypes",
    "variant_name_p",
    "variant_name_d",
    "variant_decl",
    "pos_encoding_mode_p",
    "use_sliding_window_p",
    "use_logits_soft_cap_p",
    "pos_encoding_mode_d",
    "use_sliding_window_d",
    "use_logits_soft_cap_d",
    "use_fp16_qk_reduction"
  ],
  "gen_customize_batch_pod_module": [
    "uri",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim",
    "additional_tensor_names",
    "additional_tensor_dtypes",
    "additional_scalar_names",
    "additional_scalar_dtypes",
    "variant_name_p",
    "variant_name_d",
    "variant_decl",
    "pos_encoding_mode_p",
    "use_sliding_window_p",
    "use_logits_soft_cap_p",
    "pos_encoding_mode_d",
    "use_sliding_window_d",
    "use_logits_soft_cap_d",
    "use_fp16_qk_reduction"
  ],
  "gen_batch_decode_module": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap"
  ],
  "gen_batch_prefill_module": [
    "backend",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap",
    "use_fp16_qk_reduction"
  ],
  "gen_batch_prefill_attention_sink_module": [
    "backend",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_sliding_window"
  ],
  "gen_batch_attention_module": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_logits_soft_cap",
    "use_profiler"
  ],
  "gen_customize_single_decode_module": [
    "uri",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "head_dim_qk",
    "head_dim_vo",
    "additional_tensor_names",
    "additional_tensor_dtypes",
    "additional_scalar_names",
    "additional_scalar_dtypes",
    "variant_name",
    "variant_decl",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap"
  ],
  "gen_customize_single_prefill_module": [
    "backend",
    "uri",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "head_dim_qk",
    "head_dim_vo",
    "additional_tensor_names",
    "additional_tensor_dtypes",
    "additional_scalar_names",
    "additional_scalar_dtypes",
    "variant_name",
    "variant_decl",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap",
    "use_fp16_qk_reduction",
    "fp8_enabled"
  ],
  "gen_customize_batch_decode_module": [
    "uri",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "idtype",
    "head_dim_qk",
    "head_dim_vo",
    "additional_tensor_names",
    "additional_tensor_dtypes",
    "additional_scalar_names",
    "additional_scalar_dtypes",
    "variant_name",
    "variant_decl",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap"
  ],
  "gen_customize_batch_prefill_module": [
    "backend",
    "uri",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "idtype",
    "head_dim_qk",
    "head_dim_vo",
    "additional_tensor_names",
    "additional_tensor_dtypes",
    "additional_scalar_names",
    "additional_scalar_dtypes",
    "variant_name",
    "variant_decl",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap",
    "use_fp16_qk_reduction",
    "fp8_enabled"
  ],
  "get_fmha_cutlass_sm100a_uri": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap"
  ],
  "gen_fmha_cutlass_sm100a_module": [
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "dtype_idx",
    "head_dim_qk",
    "head_dim_vo",
    "pos_encoding_mode",
    "use_sliding_window",
    "use_logits_soft_cap"
  ],
  "gen_trtllm_gen_fmha_module": [],
  "gen_customize_batch_attention_module": [
    "uri",
    "dtype_q",
    "dtype_kv",
    "dtype_o",
    "idtype",
    "head_dim_qk",
    "head_dim_vo",
    "additional_tensor_names",
    "additional_tensor_dtypes",
    "additional_scalar_names",
    "additional_scalar_dtypes",
    "variant_name",
    "variant_decl",
    "pos_encoding_mode",
    "use_logits_soft_cap",
    "use_profiler"
  ],
  "gen_cudnn_fmha_module": [],
  "get_trtllm_fmha_v2_module": [],
  "gen_trtllm_fmha_v2_module": [],
  "sm2name": [],
  "dtype2traits": [],
  "dtype2OutputType": [],
  "dtype2bytes": [],
  "hopper_dtype2traits": [],
  "hopper_traits2shape": [],
  "dtype2typename": [],
  "pythonBoolean2cpp": [],
  "AttentionMaskType": {
    "PADDING": [],
    "CAUSAL": [],
    "SLIDING_OR_CHUNKED_CAUSAL": [],
    "CUSTOM_MASK": []
  },
  "InputLayout": {
    "PACKED_QKV": [],
    "CONTIGUOUS_Q_KV": [],
    "Q_PAGED_KV": [],
    "SEPARATE_Q_K_V": []
  },
  "spec_fields": [],
  "kernel_spec": [],
  "generate_cu_trtllm": [],
  "ns_open": [],
  "ns_close": [],
  "copyright": [],
  "makefile_template": [],
  "get_makefile_code": [
    "specs_names"
  ],
  "MAX_STGS_PER_LOOP": [],
  "kernel_template": [],
  "flash_attention_kernel_template": [],
  "kernel_hopper_template": [],
  "kernel_hopper_warp_specialization_template": [],
  "encode_name": [
    "kernel_spec"
  ],
  "get_GMMA_shape": [
    "instruction_traits",
    "m",
    "n",
    "k",
    "warps_n"
  ],
  "enable_mutex": [
    "kspec"
  ],
  "enable_tma_store": [
    "kspec"
  ],
  "get_reg_count": [
    "kspec"
  ],
  "get_hopper_instruction_traits": [
    "instruction_traits",
    "kernel_spec"
  ],
  "get_effective_sm_and_name": [
    "kspec"
  ],
  "selected_mask_types": [
    "kspec"
  ],
  "get_kernel_code": [
    "kspec",
    "kname",
    "lname"
  ],
  "get_api_code": [
    "specs_names"
  ],
  "ktraits_code_template": [],
  "get_kernel_traits_code": [
    "specs_names"
  ],
  "use_cubin_header": [
    "sm",
    "head_size",
    "dtype"
  ],
  "get_cubin_header": [
    "kernel_traits",
    "specs_names"
  ],
  "modify_cubin_header": [
    "cubin_header"
  ],
  "generate_files": [
    "specs_names"
  ],
  "enumerate_hgmma_tma_kernels": [
    "specs",
    "sm"
  ],
  "enumerate_hgmma_ldgsts_kernels": [
    "specs",
    "sm",
    "dtype"
  ],
  "enumerate_hgmma_flash_warpspec_kernels": [
    "specs",
    "sm",
    "dtype"
  ],
  "enumerate_qgmma_flash_warpspec_kernels": [
    "specs",
    "sm",
    "dtype",
    "sage_block_sizes",
    "output_dtype"
  ],
  "enumerate_igmma_kernels": [
    "specs",
    "sm"
  ],
  "enumerate_hmma_kernels": [
    "specs",
    "sm",
    "dtype"
  ],
  "enumerate_hmma884_kernels": [
    "specs",
    "sm"
  ],
  "enumerate_hmma_paged_kv_flash_kernels": [
    "specs",
    "sm",
    "dtype"
  ],
  "enumerate_hmma_flash_kernels": [
    "specs",
    "sm",
    "dtype",
    "head_size_v"
  ],
  "enumerate_hmma_flash_kernels_base": [
    "specs",
    "sm",
    "dtype",
    "input_layout",
    "enable_attn_logit_softcapping",
    "head_size_v"
  ],
  "enumerate_qgmma_kernels": [
    "specs",
    "sm"
  ],
  "enumerate_qmma_kernels": [
    "specs",
    "sm"
  ],
  "enumerate_qmma_flash_kernels": [
    "specs",
    "sm",
    "dtype",
    "head_sizes",
    "sage_block_sizes",
    "output_dtype"
  ],
  "enumerate_imma_kernels": [
    "specs",
    "sm"
  ],
  "enumerate_cross_mha_kernels": [
    "specs"
  ],
  "enumerate_kernels": [],
  "working_directory": [
    "path"
  ],
  "_setup_output_directory": [
    "src_target",
    "gen_dir"
  ],
  "_mm_M1_16_K7168_shape_checks": [
    "mat_a",
    "mat_b",
    "out",
    "launch_with_pdl",
    "expected_num_experts",
    "expected_out_dtype"
  ],
  "_mm_M1_16_K7168_N256_shape_checks": [
    "mat_a",
    "mat_b",
    "out",
    "launch_with_pdl"
  ],
  "_mm_M1_16_K7168_N128_shape_checks": [
    "mat_a",
    "mat_b",
    "out",
    "launch_with_pdl"
  ],
  "get_dsv3_router_gemm_module": [],
  "mm_M1_16_K7168_N128": [
    "mat_a",
    "mat_b",
    "out",
    "launch_with_pdl"
  ],
  "mm_M1_16_K7168_N256": [
    "mat_a",
    "mat_b",
    "out",
    "launch_with_pdl"
  ],
  "_cute_dsl_kernels": [],
  "CUDNN_AVAILABLE": [],
  "DEFAULT_WORKSPACE_SIZE": [],
  "CUDNN_FP4_MXFP4_SM120_CUDNN_VERSION_ERROR": [],
  "_match_sm_version": [
    "device",
    "sm_version"
  ],
  "get_gemm_module": [],
  "_cutlass_mm_bf16_requirement": [
    "a",
    "b",
    "out",
    "out_dtype",
    "bias",
    "pdl",
    "backend"
  ],
  "_cudnn_mm_bf16_requirement": [
    "a",
    "b",
    "out",
    "out_dtype",
    "bias",
    "pdl",
    "backend"
  ],
  "_tgv_gemm_requirement": [
    "a",
    "b",
    "out",
    "out_dtype",
    "bias",
    "pdl",
    "backend"
  ],
  "_check_mm_bf16_problem_size": [
    "a",
    "b",
    "bias",
    "pdl",
    "out",
    "out_dtype",
    "backend"
  ],
  "_heuristic_func_mm_bf16": [
    "suitable_backends",
    "a",
    "b",
    "bias",
    "pdl",
    "out",
    "out_dtype",
    "backend"
  ],
  "mm_bf16": [
    "a",
    "b",
    "bias",
    "pdl",
    "out",
    "out_dtype",
    "backend"
  ],
  "_cutlass_bmm_bf16_requirement": [
    "A",
    "B",
    "out",
    "out_dtype",
    "backend"
  ],
  "_cudnn_bmm_bf16_requirement": [
    "A",
    "B",
    "out",
    "out_dtype",
    "backend"
  ],
  "_check_bmm_bf16_problem_size": [
    "A",
    "B",
    "out",
    "out_dtype",
    "backend"
  ],
  "_heuristic_func_bmm_bf16": [
    "suitable_backends",
    "A",
    "B",
    "out",
    "out_dtype",
    "backend"
  ],
  "bmm_bf16": [
    "A",
    "B",
    "out",
    "out_dtype",
    "backend"
  ],
  "get_gemm_sm100_module": [],
  "get_gemm_sm120_module": [],
  "get_gemm_sm120_module_cutlass_fp8": [],
  "get_trtllm_gemm_module": [],
  "get_gemm_sm100_module_cutlass_fp8": [],
  "_FP8_GEMM_SM100_TUNING_CONFIG": [],
  "get_gemm_sm100_module_cutlass_bf16": [],
  "_BF16_GEMM_SM100_TUNING_CONFIG": [],
  "bf16_gemm_sm100": [
    "a",
    "b",
    "bias",
    "pdl",
    "out",
    "workspace_buffer",
    "runner_names"
  ],
  "fp8_gemm_sm100": [
    "a",
    "b",
    "scale_a",
    "scale_b",
    "out",
    "workspace_buffer",
    "runner_names"
  ],
  "_create_cutlass_fp4_gemm_module": [
    "module",
    "op_name",
    "tuner_name"
  ],
  "get_gemm_sm100_module_cutlass_fp4": [],
  "get_gemm_sm103_module_cutlass_fp4": [],
  "get_gemm_sm120_module_cutlass_fp4": [],
  "get_cutlass_fp4_gemm_module": [
    "sm_major",
    "sm_minor"
  ],
  "get_tgv_gemm_sm10x_module": [
    "dtype",
    "use_sm_100f"
  ],
  "tgv_gemm_sm100": [
    "a",
    "b",
    "bias",
    "pdl",
    "out"
  ],
  "get_gemm_sm90_module": [],
  "launch_compute_sm80_group_gemm_args": [
    "x",
    "weights",
    "y",
    "w_column_major",
    "batch_size",
    "seg_indptr",
    "weight_indices"
  ],
  "launch_compute_sm90_group_gemm_args": [
    "x",
    "weights",
    "y",
    "w_column_major",
    "batch_size",
    "seg_indptr",
    "weight_indices"
  ],
  "SegmentGEMMWrapper": {
    "__init__": [
      "self",
      "float_workspace_buffer",
      "backend"
    ],
    "reset_workspace_buffer": [
      "self",
      "float_workspace_buffer",
      "int_workspace_buffer"
    ],
    "run": [
      "self",
      "x",
      "weights",
      "batch_size",
      "weight_column_major",
      "out",
      "seg_lens",
      "seg_indptr",
      "weight_indices"
    ],
    "forward": []
  },
  "UIDs": {
    "A_UID": [],
    "B_UID": [],
    "ALPHA_UID": [],
    "BLOCK_DESCALE_A_UID": [],
    "BLOCK_DESCALE_B_UID": [],
    "A_SCALE_UID": [],
    "B_SCALE_UID": [],
    "O_UID": []
  },
  "_check_cudnn_availability": [],
  "_check_cudnn_fp4_availability": [],
  "_is_cublas_fp4_available_in_cudnn": [],
  "_cudnn_handle": [],
  "_get_cudnn_handle": [
    "stream"
  ],
  "_validate_fp8_output_dtype": [
    "dtype"
  ],
  "_validate_bf16_output_dtype": [
    "dtype"
  ],
  "create_cudnn_execution_plans_fp4_gemm": [
    "a_shape",
    "a_stride",
    "b_shape",
    "b_stride",
    "a_descale_shape",
    "a_descale_stride",
    "b_descale_shape",
    "b_descale_stride",
    "ab_type",
    "o_type",
    "block_size",
    "device",
    "alpha_is_not_none",
    "use_nvfp4"
  ],
  "build_plans_cudnn_fp4_gemm_graph": [
    "a_shape",
    "a_stride",
    "b_shape",
    "b_stride",
    "a_descale_shape",
    "a_descale_stride",
    "b_descale_shape",
    "b_descale_stride",
    "ab_type",
    "o_type",
    "block_size",
    "device",
    "alpha",
    "use_nvfp4",
    "tactic"
  ],
  "execute_cudnn_gemm_fp4_graph": [
    "graph",
    "a",
    "b",
    "a_descale",
    "b_descale",
    "alpha",
    "c_final",
    "workspace_buffer",
    "tactic"
  ],
  "execute_cudnn_gemm_mxfp8_graph": [
    "graph",
    "a",
    "b",
    "a_descale",
    "b_descale",
    "c_final",
    "workspace_buffer",
    "tactic"
  ],
  "build_cudnn_gemm_with_per_tensor_q_graph": [
    "a_shape",
    "a_stride",
    "b_shape",
    "b_stride",
    "a_type",
    "b_type",
    "o_type",
    "device"
  ],
  "execute_cudnn_gemm_with_per_tensor_q_graph": [
    "graph",
    "a",
    "b",
    "a_scale",
    "b_scale",
    "c_final",
    "workspace"
  ],
  "_torch_data_type_to_cudnn_data_type": [
    "dtype"
  ],
  "_cudnn_gemm_fp8": [
    "workspace",
    "a",
    "b",
    "a_scale",
    "b_scale",
    "out",
    "torch_out_dtype"
  ],
  "_cudnn_gemm_fp8_runner": [],
  "_get_bf16_3d_shape_stride": [
    "tensor"
  ],
  "build_cudnn_gemm_bf16_graph": [
    "a_shape",
    "a_stride",
    "b_shape",
    "b_stride",
    "o_type",
    "device"
  ],
  "execute_cudnn_gemm_bf16_graph": [
    "graph",
    "a",
    "b",
    "c_final",
    "workspace",
    "tactic"
  ],
  "_cudnn_gemm_bf16": [
    "workspace",
    "a",
    "b",
    "out",
    "tactic"
  ],
  "_cudnn_gemm_bf16_runner": [],
  "_get_real_fp4_shape_from_packed_uint8": [
    "packed_fp4_tensor"
  ],
  "_expand_block_scale_tensor_shape": [
    "block_scale_tensor",
    "batch_size"
  ],
  "mm_fp8": [
    "a",
    "b",
    "alpha",
    "out_dtype",
    "out",
    "backend"
  ],
  "_create_cutlass_mxfp8_gemm_module": [
    "module",
    "op_name",
    "tuner_name"
  ],
  "get_gemm_sm100_module_cutlass_mxfp8": [],
  "get_cutlass_mxfp8_gemm_module": [
    "sm_major"
  ],
  "_check_mm_mxfp8_problem_size": [
    "a",
    "b",
    "a_descale",
    "b_descale",
    "out",
    "out_dtype",
    "backend"
  ],
  "_cutlass_gemm_mxfp8_requirement": [
    "a",
    "b",
    "a_descale",
    "b_descale",
    "out",
    "out_dtype",
    "backend"
  ],
  "_heuristic_func_mm_mxfp8": [
    "suitable_backends",
    "a",
    "b",
    "a_descale",
    "b_descale",
    "out",
    "out_dtype",
    "backend"
  ],
  "mm_mxfp8": [
    "a",
    "b",
    "a_descale",
    "b_descale",
    "out",
    "out_dtype",
    "backend"
  ],
  "_get_cudnn_fp4_gemm_graph": [
    "a",
    "b",
    "a_descale",
    "b_descale",
    "alpha",
    "out_dtype",
    "out",
    "block_size",
    "use_nvfp4",
    "tactic"
  ],
  "_cudnn_gemm_fp4": [
    "a",
    "b",
    "a_descale",
    "b_descale",
    "alpha",
    "out_dtype",
    "out",
    "block_size",
    "use_nvfp4",
    "workspace_buffer",
    "tactic"
  ],
  "_cudnn_gemm_fp4_runner": [],
  "_check_mm_fp4_problem_size": [
    "a",
    "b",
    "a_descale",
    "b_descale",
    "alpha",
    "out_dtype",
    "out",
    "block_size",
    "use_8x4_sf_layout",
    "backend",
    "use_nvfp4"
  ],
  "_cudnn_gemm_fp4_requirement": [
    "a",
    "b",
    "a_descale",
    "b_descale",
    "alpha",
    "out_dtype",
    "out",
    "block_size",
    "use_8x4_sf_layout",
    "backend",
    "use_nvfp4"
  ],
  "_trtllm_gemm_fp4_requirement": [
    "a",
    "b",
    "a_descale",
    "b_descale",
    "alpha",
    "out_dtype",
    "out",
    "block_size",
    "use_8x4_sf_layout",
    "backend",
    "use_nvfp4"
  ],
  "_cutlass_gemm_fp4_requirement": [
    "a",
    "b",
    "a_descale",
    "b_descale",
    "alpha",
    "out_dtype",
    "out",
    "block_size",
    "use_8x4_sf_layout",
    "backend",
    "use_nvfp4"
  ],
  "_heuristic_func_mm_fp4": [
    "suitable_backends",
    "a",
    "b",
    "a_descale",
    "b_descale",
    "alpha",
    "out_dtype",
    "out",
    "block_size",
    "use_8x4_sf_layout",
    "backend",
    "use_nvfp4"
  ],
  "_pad_up": [
    "x",
    "y"
  ],
  "_mxfp8_swizzled_scale_len": [
    "m",
    "k"
  ],
  "_MM_FP4_TUNING_CONFIG_8x4": [],
  "_MM_FP4_TUNING_CONFIG_128x4": [],
  "_MM_MXFP8_TUNING_CONFIG": [],
  "mm_fp4": [
    "a",
    "b",
    "a_descale",
    "b_descale",
    "alpha",
    "out_dtype",
    "out",
    "block_size",
    "use_8x4_sf_layout",
    "backend",
    "use_nvfp4"
  ],
  "_cudnn_bmm_fp8_requirement": [
    "A",
    "B",
    "A_scale",
    "B_scale",
    "dtype",
    "out",
    "backend"
  ],
  "_cublas_bmm_fp8_requirement": [
    "A",
    "B",
    "A_scale",
    "B_scale",
    "dtype",
    "out",
    "backend"
  ],
  "_cutlass_bmm_fp8_requirement": [
    "A",
    "B",
    "A_scale",
    "B_scale",
    "dtype",
    "out",
    "backend"
  ],
  "_check_bmm_fp8_problem_size": [
    "A",
    "B",
    "A_scale",
    "B_scale",
    "dtype",
    "out",
    "backend"
  ],
  "_heuristic_func_bmm_fp8": [
    "suitable_backends",
    "A",
    "B",
    "A_scale",
    "B_scale",
    "dtype",
    "out",
    "backend"
  ],
  "bmm_fp8": [
    "A",
    "B",
    "A_scale",
    "B_scale",
    "dtype",
    "out",
    "backend"
  ],
  "_cutlass_gemm_fp8_nt_groupwise_requirement": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "scale_major_mode",
    "mma_sm",
    "scale_granularity_mnk",
    "out",
    "out_dtype",
    "backend"
  ],
  "_trtllm_gemm_fp8_nt_groupwise_requirement": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "scale_major_mode",
    "mma_sm",
    "scale_granularity_mnk",
    "out",
    "out_dtype",
    "backend"
  ],
  "_check_gemm_fp8_nt_groupwise_problem_size": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "scale_major_mode",
    "mma_sm",
    "scale_granularity_mnk",
    "out",
    "out_dtype",
    "backend"
  ],
  "gemm_fp8_nt_groupwise": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "scale_major_mode",
    "mma_sm",
    "scale_granularity_mnk",
    "out",
    "out_dtype",
    "backend"
  ],
  "get_trtllm_fp4_gemm_module": [],
  "_check_gemm_fp8_nt_blockscaled_problem_size": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "scale_major_mode",
    "mma_sm",
    "out",
    "out_dtype"
  ],
  "gemm_fp8_nt_blockscaled": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "scale_major_mode",
    "mma_sm",
    "out",
    "out_dtype"
  ],
  "_check_group_gemm_fp8_nt_groupwise_problem_size": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "m_indptr",
    "scale_granularity_mnk",
    "scale_major_mode",
    "mma_sm",
    "out",
    "out_dtype"
  ],
  "group_gemm_fp8_nt_groupwise": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "m_indptr",
    "scale_granularity_mnk",
    "scale_major_mode",
    "mma_sm",
    "out",
    "out_dtype"
  ],
  "_check_group_gemm_mxfp8_mxfp4_nt_groupwise_problem_size": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "m_indptr",
    "mma_sm",
    "tile_m",
    "tile_n",
    "tile_k",
    "swap_ab",
    "out",
    "out_dtype"
  ],
  "group_gemm_mxfp8_mxfp4_nt_groupwise": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "m_indptr",
    "mma_sm",
    "tile_m",
    "tile_n",
    "tile_k",
    "swap_ab",
    "out",
    "out_dtype"
  ],
  "group_gemm_mxfp4_nt_groupwise": [],
  "pad_indptr_to_multiple_of_4": [
    "m_indptr"
  ],
  "get_deepgemm_sm100_module": [],
  "_check_group_deepgemm_fp8_nt_groupwise_problem_size": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "m_indices",
    "scale_granularity_mnk",
    "out",
    "out_dtype"
  ],
  "group_deepgemm_fp8_nt_groupwise": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "m_indices",
    "scale_granularity_mnk",
    "out",
    "out_dtype"
  ],
  "_check_batch_deepgemm_fp8_nt_groupwise": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "masked_m",
    "expected_m",
    "scale_granularity_mnk",
    "out",
    "out_dtype"
  ],
  "batch_deepgemm_fp8_nt_groupwise": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "masked_m",
    "expected_m",
    "scale_granularity_mnk",
    "out",
    "out_dtype"
  ],
  "get_fp8_blockscale_gemm_runner_sm90": [],
  "fp8_blockscale_gemm_sm90": [
    "input",
    "weight",
    "input_scale",
    "weight_scale",
    "out",
    "out_dtype"
  ],
  "_calculate_block_scale_dims": [
    "m",
    "n",
    "k",
    "block_size"
  ],
  "create_cudnn_execution_plans_mxfp8_gemm": [
    "a_shape",
    "a_stride",
    "a_type",
    "b_shape",
    "b_stride",
    "b_type",
    "block_size",
    "o_type",
    "device"
  ],
  "_get_cudnn_mxfp8_gemm_graph": [
    "a",
    "b",
    "out_dtype",
    "out",
    "block_size",
    "tactic"
  ],
  "_cudnn_gemm_mxfp8": [
    "a",
    "b",
    "a_descale",
    "b_descale",
    "out_dtype",
    "out",
    "workspace_buffer",
    "tactic"
  ],
  "_cudnn_gemm_mxfp8_runner": [],
  "mxfp8_gemm_sm100": [
    "a",
    "b",
    "scale_a",
    "scale_b",
    "out",
    "workspace_buffer",
    "runner_names"
  ],
  "_cudnn_bmm_mxfp8_requirement": [
    "A",
    "B",
    "A_scale",
    "B_scale",
    "dtype",
    "out",
    "backend"
  ],
  "_validate_mxfp8_output_dtype": [
    "dtype"
  ],
  "_check_bmm_mxfp8_problem_size": [
    "A",
    "B",
    "A_scale",
    "B_scale",
    "dtype",
    "out",
    "backend"
  ],
  "_heuristic_func_bmm_mxfp8": [
    "suitable_backends",
    "A",
    "B",
    "A_scale",
    "B_scale",
    "dtype",
    "out",
    "backend"
  ],
  "bmm_mxfp8": [
    "A",
    "B",
    "A_scale",
    "B_scale",
    "dtype",
    "out",
    "backend"
  ],
  "sizeof_i32": [],
  "with_byte": [
    "obj",
    "index",
    "value"
  ],
  "read_byte": [
    "obj",
    "index"
  ],
  "atomic_add_release_global": [
    "addr",
    "value"
  ],
  "MaskedSchedulerParams": {
    "__init__": [
      "self",
      "masked_m",
      "dst_signals",
      "c",
      "c_tiler",
      "cluster_shape_mnk"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "get_grid_shape": [
      "self",
      "max_active_clusters"
    ]
  },
  "MaskedScheduler": {
    "__init__": [
      "self",
      "params",
      "num_persistent_clusters",
      "current_work_linear_idx",
      "current_batch_idx",
      "accum_tile_m",
      "cta_id_in_cluster",
      "num_tiles_executed"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "create": [
      "params",
      "block_idx",
      "grid_dim"
    ],
    "get_grid_shape": [
      "params",
      "max_active_clusters"
    ],
    "_get_current_work_for_linear_idx": [
      "self",
      "current_work_linear_idx",
      "dsm_pending_packed",
      "dsm_counter",
      "num_c_stage"
    ],
    "get_current_work": [
      "self",
      "dsm_pending_packed",
      "dsm_counter",
      "num_c_stage"
    ],
    "initial_work_tile_info": [
      "self"
    ],
    "advance_to_next_work": [
      "self"
    ],
    "num_tiles_executed": [
      "self"
    ]
  },
  "Sm100BlockScaledPersistentDenseGemmKernel": {
    "__init__": [
      "self",
      "sf_vec_size",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "sm_version"
    ],
    "_setup_attributes": [
      "self"
    ],
    "__call__": [
      "self",
      "a_tensor",
      "b_tensor",
      "sfa_tensor",
      "sfb_tensor",
      "c_tensor",
      "masked_m_tensor",
      "dst_signals",
      "alpha_tensor",
      "max_active_clusters",
      "stream"
    ],
    "kernel": [
      "self",
      "tiled_mma",
      "tiled_mma_sfb",
      "tma_atom_a",
      "mA_mkl",
      "tma_atom_b",
      "mB_nkl",
      "tma_atom_sfa",
      "mSFA_mkl",
      "tma_atom_sfb",
      "mSFB_nkl",
      "tma_atom_c",
      "mC_mnl",
      "alpha",
      "cluster_layout_vmnk",
      "cluster_layout_sfb_vmnk",
      "a_smem_layout_staged",
      "b_smem_layout_staged",
      "sfa_smem_layout_staged",
      "sfb_smem_layout_staged",
      "c_smem_layout_staged",
      "epi_tile",
      "tile_sched_params"
    ],
    "mainloop_s2t_copy_and_partition": [
      "self",
      "sSF",
      "tSF"
    ],
    "epilog_tmem_copy_and_partition": [
      "self",
      "tidx",
      "tAcc",
      "gC_mnl",
      "epi_tile",
      "use_2cta_instrs"
    ],
    "epilog_smem_copy_and_partition": [
      "self",
      "tiled_copy_t2r",
      "tTR_rC",
      "tidx",
      "sC"
    ],
    "epilog_gmem_copy_and_partition": [
      "self",
      "tidx",
      "atom",
      "gC_mnl",
      "epi_tile",
      "sC"
    ],
    "_compute_stages": [
      "tiled_mma",
      "mma_tiler_mnk",
      "a_dtype",
      "a_major_mode",
      "b_dtype",
      "b_major_mode",
      "epi_tile",
      "c_dtype",
      "c_layout",
      "sf_dtype",
      "sf_vec_size",
      "smem_capacity",
      "occupancy"
    ],
    "_compute_grid": [
      "masked_m_tensor",
      "dst_signals",
      "c",
      "cta_tile_shape_mnk",
      "cluster_shape_mn",
      "max_active_clusters"
    ],
    "is_valid_dtypes_and_scale_factor_vec_size": [
      "ab_dtype",
      "sf_dtype",
      "sf_vec_size",
      "c_dtype"
    ],
    "is_valid_layouts": [
      "ab_dtype",
      "c_dtype",
      "a_major",
      "b_major",
      "c_major"
    ],
    "is_valid_mma_tiler_and_cluster_shape": [
      "mma_tiler_mn",
      "cluster_shape_mn"
    ],
    "is_valid_tensor_alignment": [
      "m",
      "n",
      "k",
      "l",
      "ab_dtype",
      "c_dtype",
      "a_major",
      "b_major",
      "c_major"
    ],
    "can_implement": [
      "ab_dtype",
      "sf_dtype",
      "sf_vec_size",
      "c_dtype",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "m",
      "n",
      "k",
      "l",
      "a_major",
      "b_major",
      "c_major"
    ]
  },
  "cvt_sf_MKL_to_M32x4xrm_K4xrk_L": [
    "sf_ref_tensor",
    "sf_mma_tensor"
  ],
  "cvt_sf_MKL_to_M32x4xrm_K4xrk_L_mma_spec": [
    "sf_mma_tensor"
  ],
  "create_scale_factor_tensor": [
    "l",
    "mn",
    "k",
    "sf_vec_size",
    "dtype",
    "device"
  ],
  "MaskedBatchedMatmulCuteDSL": {
    "__init__": [
      "self",
      "m",
      "n",
      "k",
      "l",
      "a_major",
      "b_major",
      "c_major",
      "ab_dtype",
      "sf_dtype",
      "c_dtype",
      "alpha_dtype",
      "sf_vec_size",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "sm_count",
      "sm_version"
    ],
    "__call__": [
      "self",
      "a_ptr",
      "b_ptr",
      "sfa_ptr",
      "sfb_ptr",
      "c_ptr",
      "masked_m_ptr",
      "dst_signals_ptr",
      "alpha_ptr",
      "current_stream"
    ]
  },
  "get_cute_dsl_compiled_masked_gemm_kernel": [
    "m",
    "n",
    "k",
    "l",
    "a_major",
    "b_major",
    "c_major",
    "ab_dtype",
    "sf_dtype",
    "c_dtype",
    "alpha_dtype",
    "sf_vec_size",
    "mma_tiler_mn",
    "cluster_shape_mn",
    "sm_count",
    "sm_version",
    "enable_dst_signals"
  ],
  "grouped_gemm_nt_masked": [
    "lhs",
    "rhs",
    "out",
    "masked_m"
  ],
  "get_l2_cache_size": [
    "device"
  ],
  "_calculate_tensor_bytes": [
    "tensors"
  ],
  "_extract_gpu_tensors": [
    "obj"
  ],
  "calculate_rotation_count": [
    "tensors",
    "device",
    "min_rotations"
  ],
  "_clone_structure": [
    "obj"
  ],
  "_create_rotated_buffer_copies": [
    "input_args",
    "input_kwargs",
    "num_rotations"
  ],
  "_infer_device_from_tensors": [
    "input_args",
    "input_kwargs",
    "default"
  ],
  "_ceil_to_ue8m0": [
    "x"
  ],
  "per_token_cast_to_fp8": [
    "x"
  ],
  "per_block_cast_to_fp8": [
    "x"
  ],
  "quantize_fp8": [
    "x",
    "scale_shape",
    "tile_shape",
    "scale_major_mode"
  ],
  "dequantize_fp8": [
    "x",
    "x_scale",
    "scale_major_mode"
  ],
  "set_seed": [
    "random_seed"
  ],
  "sleep_after_kernel_run": [
    "execution_time"
  ],
  "attention_flops": [
    "batch_size",
    "qo_seqlen",
    "kv_seqlen",
    "head_dim_qk",
    "head_dim_vo",
    "num_qo_heads",
    "causal"
  ],
  "attention_flops_with_actual_seq_lens": [
    "actual_seq_lens_q",
    "actual_seq_lens_kv",
    "head_dim_qk",
    "head_dim_vo",
    "num_qo_heads",
    "causal"
  ],
  "attention_tflops_per_sec": [
    "batch_size",
    "qo_seqlen",
    "kv_seqlen",
    "head_dim_qk",
    "head_dim_vo",
    "num_qo_heads",
    "causal",
    "time"
  ],
  "attention_tflops_per_sec_with_actual_seq_lens": [
    "actual_seq_lens_q",
    "actual_seq_lens_kv",
    "head_dim_qk",
    "head_dim_vo",
    "num_qo_heads",
    "causal",
    "ms"
  ],
  "attention_tb_per_sec": [
    "batch_size",
    "qo_seqlen",
    "kv_seqlen",
    "head_dim_qk",
    "head_dim_vo",
    "num_qo_heads",
    "num_kv_heads",
    "time",
    "q_dtype",
    "kv_dtype",
    "o_dtype"
  ],
  "attention_tb_per_sec_with_actual_seq_lens": [
    "actual_seq_lens_q",
    "actual_seq_lens_kv",
    "head_dim_qk",
    "head_dim_vo",
    "num_qo_heads",
    "num_kv_heads",
    "time",
    "q_dtype",
    "kv_dtype",
    "o_dtype"
  ],
  "bench_gpu_time_with_cuda_event": [
    "fn",
    "dry_run_iters",
    "repeat_iters",
    "dry_run_time_ms",
    "repeat_time_ms",
    "l2_flush",
    "l2_flush_size_mb",
    "l2_flush_device",
    "sleep_after_run",
    "input_args",
    "input_kwargs",
    "cold_l2_cache"
  ],
  "bench_gpu_time_with_cupti": [
    "fn",
    "dry_run_iters",
    "repeat_iters",
    "dry_run_time_ms",
    "repeat_time_ms",
    "l2_flush",
    "l2_flush_size_mb",
    "l2_flush_device",
    "sleep_after_run",
    "use_cuda_graph",
    "input_args",
    "input_kwargs",
    "cold_l2_cache"
  ],
  "bench_gpu_time_with_cudagraph": [
    "fn",
    "dry_run_iters",
    "repeat_iters",
    "dry_run_time_ms",
    "repeat_time_ms",
    "num_iters_within_graph",
    "l2_flush",
    "l2_flush_size_mb",
    "l2_flush_device",
    "sleep_after_run",
    "input_args",
    "input_kwargs",
    "cold_l2_cache"
  ],
  "bench_gpu_time": [
    "fn",
    "dry_run_iters",
    "repeat_iters",
    "dry_run_time_ms",
    "repeat_time_ms",
    "l2_flush",
    "l2_flush_size_mb",
    "l2_flush_device",
    "sleep_after_run",
    "enable_cupti",
    "use_cuda_graph",
    "num_iters_within_graph",
    "input_args",
    "input_kwargs",
    "cold_l2_cache"
  ],
  "empty_suppress": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "suppress_stdout_stderr": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "bench_kineto": [
    "fn",
    "kernel_names",
    "num_tests",
    "suppress_kineto_output",
    "trace_path",
    "flush_l2",
    "with_multiple_kernels"
  ],
  "count_bytes": [],
  "EXPECT_HOPPER": [],
  "variable_length_merge_states": [
    "v",
    "s",
    "indptr"
  ],
  "rms_norm": [
    "x",
    "weight",
    "out",
    "eps",
    "in_scale",
    "out_scale"
  ],
  "rms_norm_add_residual": [
    "x",
    "residual",
    "weight",
    "eps",
    "x_out",
    "x_in_scale",
    "x_out_scale"
  ],
  "check_input": [
    "x"
  ],
  "check_dim": [
    "d",
    "x"
  ],
  "check_shape": [
    "a",
    "b"
  ],
  "check_device": [
    "tensors",
    "major",
    "minor"
  ],
  "_patch_triton_ptxas_blackwell": [],
  "compute_sm80_group_gemm_args": [
    "all_problems_ptr",
    "x_ptr",
    "w_ptr",
    "y_ptr",
    "x_ld_ptr",
    "w_ld_ptr",
    "y_ld_ptr",
    "x",
    "w",
    "y",
    "xy_indptr",
    "w_indices",
    "d_in",
    "d_out",
    "w_column_major"
  ],
  "compute_sm90_group_gemm_args": [
    "all_problems_ptr",
    "x_ptr",
    "w_ptr",
    "y_ptr",
    "x_stride_ptr",
    "w_stride_ptr",
    "y_stride_ptr",
    "x",
    "w",
    "y",
    "xy_indptr",
    "w_indices",
    "d_in",
    "d_out",
    "w_column_major"
  ],
  "compute_padding_mapping": [
    "m_indptr",
    "padded_m_indptr",
    "m_rank",
    "padded_m_rank"
  ],
  "get_batch_indices_positions_kernel": [
    "append_indptr",
    "seq_lens_ptr",
    "batch_indices_ptr",
    "positions_ptr",
    "num_stages"
  ],
  "gemm_persistent": [
    "a",
    "b",
    "c",
    "alpha",
    "beta",
    "out_dtype",
    "num_sms"
  ],
  "gemm": [
    "a",
    "b",
    "c",
    "alpha",
    "beta",
    "out_dtype"
  ],
  "gemm_descriptor_persistent": [
    "a",
    "b",
    "c",
    "alpha",
    "beta",
    "out_dtype",
    "num_sms",
    "EPILOGUE_SUBTILE"
  ],
  "state_merge": [
    "o",
    "m",
    "d",
    "other_o",
    "other_m",
    "other_d"
  ],
  "state_normalize": [
    "o",
    "m",
    "d"
  ],
  "state_get_lse": [
    "o",
    "m",
    "d"
  ],
  "merge_state_kernel": [
    "v_a_ptr",
    "s_a_ptr",
    "v_b_ptr",
    "s_b_ptr",
    "v_merged_ptr",
    "s_merged_ptr",
    "num_heads",
    "head_dim",
    "bdx",
    "bdy"
  ],
  "merge_state_in_place_kernel": [
    "v_ptr",
    "s_ptr",
    "v_other_ptr",
    "s_other_ptr",
    "num_heads",
    "head_dim",
    "mask_ptr",
    "bdx",
    "bdy"
  ],
  "merge_states_kernel": [
    "v_ptr",
    "s_ptr",
    "v_merged_ptr",
    "s_merged_ptr",
    "num_index_sets",
    "num_heads",
    "head_dim",
    "bdx",
    "bdy"
  ],
  "variable_length_merge_states_kernel": [
    "v_ptr",
    "s_ptr",
    "indptr",
    "v_merged_ptr",
    "s_merged_ptr",
    "num_heads",
    "head_dim",
    "bdx",
    "bdy"
  ],
  "scale_and_clamp": [
    "x",
    "scale",
    "dtype"
  ],
  "rms_norm_kernel": [
    "n",
    "b",
    "x_ptr",
    "x_stride",
    "x_scale_ptr",
    "r_ptr",
    "r_stride",
    "w_ptr",
    "o_ptr",
    "o_stride",
    "o_scale_ptr",
    "EPS",
    "BLOCK_SIZE",
    "HAS_IN_SCALE",
    "HAS_OUT_SCALE",
    "HAS_OUTPUT",
    "HAS_RESIDUAL"
  ],
  "silu_and_mul_kernel": [
    "o_ptr",
    "o_stride",
    "o_scale_ptr",
    "x_ptr",
    "x_stride",
    "x_scale_ptr",
    "d",
    "BLOCK_SIZE",
    "HAS_X_SCALE",
    "HAS_O_SCALE"
  ],
  "matmul_get_configs": [],
  "_matmul_launch_metadata": [
    "grid",
    "kernel",
    "args"
  ],
  "_compute_pid": [
    "tile_id",
    "num_pid_in_group",
    "num_pid_m",
    "GROUP_SIZE_M",
    "NUM_SMS"
  ],
  "gemm_kernel_persistent": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "M",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "alpha",
    "beta",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "NUM_SMS"
  ],
  "gemm_kernel_descriptor_persistent": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "M",
    "N",
    "K",
    "alpha",
    "beta",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "EPILOGUE_SUBTILE",
    "NUM_SMS"
  ],
  "gemm_kernel": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "M",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "alpha",
    "beta",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M"
  ],
  "get_selective_state_update_module_base": [],
  "get_selective_state_update_module_sm90": [],
  "get_selective_state_update_module_sm100": [],
  "get_selective_state_update_module": [
    "device"
  ],
  "selective_state_update": [
    "state",
    "x",
    "dt",
    "A",
    "B",
    "C",
    "D",
    "z",
    "dt_bias",
    "dt_softplus",
    "state_batch_indices",
    "pad_slot_id",
    "out",
    "disable_state_update",
    "intermediate_states_buffer",
    "intermediate_state_indices",
    "cache_steps"
  ],
  "_selective_state_update": [
    "state",
    "x",
    "dt",
    "A",
    "B",
    "C",
    "D",
    "z",
    "dt_bias",
    "dt_softplus",
    "state_batch_indices",
    "pad_slot_id",
    "output",
    "disable_state_update",
    "intermediate_states_buffer",
    "intermediate_state_indices",
    "cache_steps"
  ],
  "_selective_state_update_fake": [
    "state",
    "x",
    "dt",
    "A",
    "B",
    "C",
    "D",
    "z",
    "dt_bias",
    "dt_softplus",
    "state_batch_indices",
    "pad_slot_id",
    "output",
    "disable_state_update",
    "intermediate_states_buffer",
    "intermediate_state_indices",
    "cache_steps"
  ],
  "RoutingMethodType": {
    "Default": [],
    "Renormalize": [],
    "DeepSeekV3": [],
    "Llama4": [],
    "RenormalizeNaive": [],
    "TopK": [],
    "Unspecified": []
  },
  "ActivationType": {
    "Gelu": [],
    "Relu": [],
    "Silu": [],
    "Swiglu": [],
    "Geglu": [],
    "SwigluBias": [],
    "Relu2": [],
    "Identity": [],
    "InvalidType": []
  },
  "DtypeTrtllmGen": {
    "__new__": [
      "cls",
      "block_format_bit",
      "signed_bit",
      "integer_bit",
      "num_bits",
      "uid"
    ],
    "Bfloat16": [],
    "Bool": [],
    "E2m1": [],
    "E2m3": [],
    "E3m2": [],
    "E4m3": [],
    "E5m2": [],
    "Fp16": [],
    "Fp32": [],
    "Int8": [],
    "Int32": [],
    "Int64": [],
    "MxE2m1": [],
    "MxE4m3": [],
    "MxInt4": [],
    "UE8m0": [],
    "UInt8": [],
    "UInt16": [],
    "UInt32": [],
    "UInt64": [],
    "UInt128": [],
    "Void": []
  },
  "trtllm_gen_dtype_has_scale": [
    "dtype"
  ],
  "deduce_trtllm_gen_tensor_dtype": [
    "x",
    "scale"
  ],
  "WeightLayout": {
    "MajorK": [],
    "MajorMn": [],
    "BlockMajorK": []
  },
  "GatedActType": {
    "SwiGlu": [],
    "GeGlu": []
  },
  "Fp8QuantizationType": {
    "NoneFp8": [],
    "DeepSeekFp8": [],
    "MxFp8": []
  },
  "is_trtllm_moe_supported": [
    "dtype_weights",
    "dtype_act",
    "quant_method"
  ],
  "_maybe_get_cached_w3_w1_permute_indices": [
    "_cache_permute_indices",
    "dst_w3_w1_weight",
    "epilogue_tile_m",
    "num_elts_per_sf",
    "is_gated_act_gemm"
  ],
  "get_w2_permute_indices_with_cache": [
    "_cache_permute_indices",
    "dst_w2_weight",
    "epilogue_tile_m",
    "num_elts_per_sf"
  ],
  "get_reorder_rows_for_gated_act_gemm_row_indices": [
    "x"
  ],
  "reorder_rows_for_gated_act_gemm": [
    "x"
  ],
  "convert_to_block_layout": [
    "input_tensor",
    "blockK"
  ],
  "get_cutlass_fused_moe_module": [
    "backend",
    "use_fast_build"
  ],
  "cutlass_fused_moe": [
    "input",
    "token_selected_experts",
    "token_final_scales",
    "fc1_expert_weights",
    "fc2_expert_weights",
    "output_dtype",
    "quant_scales",
    "fc1_expert_biases",
    "fc2_expert_biases",
    "input_sf",
    "swiglu_alpha",
    "swiglu_beta",
    "swiglu_limit",
    "tp_size",
    "tp_rank",
    "ep_size",
    "ep_rank",
    "cluster_size",
    "cluster_rank",
    "output",
    "enable_alltoall",
    "use_deepseek_fp8_block_scale",
    "use_w4_group_scaling",
    "use_mxfp8_act_scaling",
    "min_latency_mode",
    "use_packed_weights",
    "tune_max_num_tokens",
    "enable_pdl",
    "activation_type"
  ],
  "get_trtllm_moe_sm100_module": [],
  "trtllm_bf16_moe": [
    "routing_logits",
    "routing_bias",
    "hidden_states",
    "gemm1_weights",
    "gemm2_weights",
    "num_experts",
    "top_k",
    "n_group",
    "topk_group",
    "intermediate_size",
    "local_expert_offset",
    "local_num_experts",
    "routed_scaling_factor",
    "routing_method_type",
    "use_shuffled_weight",
    "weight_layout",
    "enable_pdl",
    "tune_max_num_tokens"
  ],
  "trtllm_fp8_per_tensor_scale_moe": [
    "routing_logits",
    "routing_bias",
    "hidden_states",
    "gemm1_weights",
    "output1_scales_scalar",
    "output1_scales_gate_scalar",
    "gemm2_weights",
    "output2_scales_scalar",
    "num_experts",
    "top_k",
    "n_group",
    "topk_group",
    "intermediate_size",
    "local_expert_offset",
    "local_num_experts",
    "routed_scaling_factor",
    "use_routing_scales_on_input",
    "routing_method_type",
    "enable_pdl",
    "tune_max_num_tokens",
    "activation_type"
  ],
  "trtllm_fp8_block_scale_moe": [
    "routing_logits",
    "routing_bias",
    "hidden_states",
    "hidden_states_scale",
    "gemm1_weights",
    "gemm1_weights_scale",
    "gemm2_weights",
    "gemm2_weights_scale",
    "num_experts",
    "top_k",
    "n_group",
    "topk_group",
    "intermediate_size",
    "local_expert_offset",
    "local_num_experts",
    "routed_scaling_factor",
    "routing_method_type",
    "use_shuffled_weight",
    "weight_layout",
    "enable_pdl",
    "tune_max_num_tokens",
    "fp8_quantization_type"
  ],
  "trtllm_fp8_block_scale_routed_moe": [
    "topk_ids",
    "routing_bias",
    "hidden_states",
    "hidden_states_scale",
    "gemm1_weights",
    "gemm1_weights_scale",
    "gemm2_weights",
    "gemm2_weights_scale",
    "num_experts",
    "top_k",
    "n_group",
    "topk_group",
    "intermediate_size",
    "local_expert_offset",
    "local_num_experts",
    "routed_scaling_factor",
    "routing_method_type",
    "use_shuffled_weight",
    "weight_layout",
    "enable_pdl",
    "output",
    "tune_max_num_tokens",
    "fp8_quantization_type"
  ],
  "trtllm_fp4_block_scale_moe": [
    "routing_logits",
    "routing_bias",
    "hidden_states",
    "hidden_states_scale",
    "gemm1_weights",
    "gemm1_weights_scale",
    "gemm1_bias",
    "gemm1_alpha",
    "gemm1_beta",
    "gemm1_clamp_limit",
    "gemm2_weights",
    "gemm2_weights_scale",
    "gemm2_bias",
    "output1_scale_scalar",
    "output1_scale_gate_scalar",
    "output2_scale_scalar",
    "num_experts",
    "top_k",
    "n_group",
    "topk_group",
    "intermediate_size",
    "local_expert_offset",
    "local_num_experts",
    "routed_scaling_factor",
    "routing_method_type",
    "do_finalize",
    "enable_pdl",
    "activation_type",
    "output",
    "tune_max_num_tokens"
  ],
  "trtllm_fp4_block_scale_routed_moe": [
    "topk_ids",
    "routing_bias",
    "hidden_states",
    "hidden_states_scale",
    "gemm1_weights",
    "gemm1_weights_scale",
    "gemm1_bias",
    "gemm1_alpha",
    "gemm1_beta",
    "gemm1_clamp_limit",
    "gemm2_weights",
    "gemm2_weights_scale",
    "gemm2_bias",
    "output1_scale_scalar",
    "output1_scale_gate_scalar",
    "output2_scale_scalar",
    "num_experts",
    "top_k",
    "n_group",
    "topk_group",
    "intermediate_size",
    "local_expert_offset",
    "local_num_experts",
    "routed_scaling_factor",
    "routing_method_type",
    "do_finalize",
    "enable_pdl",
    "activation_type",
    "output",
    "tune_max_num_tokens"
  ],
  "trtllm_mxint4_block_scale_moe": [
    "routing_logits",
    "routing_bias",
    "hidden_states",
    "gemm1_weights",
    "gemm1_weights_scale",
    "gemm1_alpha",
    "gemm1_beta",
    "gemm1_clamp_limit",
    "gemm2_weights",
    "gemm2_weights_scale",
    "num_experts",
    "top_k",
    "n_group",
    "topk_group",
    "intermediate_size",
    "local_expert_offset",
    "local_num_experts",
    "routed_scaling_factor",
    "routing_method_type",
    "enable_pdl",
    "output",
    "tune_max_num_tokens"
  ],
  "is_torch_compiling_flag": [],
  "AuxStreamType": [],
  "EventType": [],
  "set_torch_compiling": [
    "enable"
  ],
  "is_torch_compiling": [],
  "_global_attrs": [],
  "get_global_attrs": [],
  "_model_extra_attrs": [],
  "get_model_extra_attrs": [],
  "model_extra_attrs": [
    "attrs"
  ],
  "with_model_extra_attrs": [
    "get_attrs"
  ],
  "Fp4QuantizedTensor": {
    "shape": [
      "self"
    ]
  },
  "compute_swizzled_sf_shape": [
    "row",
    "col"
  ],
  "swizzle_sf": [
    "sf",
    "rows",
    "cols",
    "scaling_vector_size"
  ],
  "unswizzle_sf": [
    "sf",
    "rows",
    "cols",
    "scaling_vector_size"
  ],
  "reswizzle_sf": [
    "sf",
    "rows",
    "cols",
    "scaling_vector_size"
  ],
  "_": [
    "sf",
    "rows",
    "cols",
    "scaling_vector_size"
  ],
  "last_positive_power_of_2": [
    "x"
  ],
  "nearest_in_buckets": [
    "x",
    "buckets"
  ],
  "get_power_of_2_num_tokens_buckets": [
    "max_num_tokens"
  ],
  "get_last_power_of_2_num_tokens_buckets": [
    "max_num_tokens",
    "min_num_tokens"
  ],
  "get_fp4_shape": [
    "input_shape",
    "sf_vec_size",
    "is_swizzled_layout"
  ],
  "fp4_scale_infer_shape": [
    "input_shapes"
  ],
  "_enable_piecewise_cuda_graph": [],
  "set_piecewise_cuda_graph_flag": [
    "enable"
  ],
  "get_piecewise_cuda_graph_flag": [],
  "_check_dsv3_fused_routing_supported": [
    "scores",
    "bias",
    "n_group",
    "topk_group",
    "topk",
    "routed_scaling_factor",
    "topk_values",
    "topk_indices",
    "launch_with_pdl"
  ],
  "get_dsv3_fused_routing_module": [],
  "fused_topk_deepseek": [
    "scores",
    "bias",
    "n_group",
    "topk_group",
    "topk",
    "routed_scaling_factor",
    "topk_values",
    "topk_indices",
    "launch_with_pdl"
  ],
  "_get_cuda_stream_ptr": [],
  "get_max_num_tiles": [
    "num_tokens",
    "top_k",
    "num_local_experts",
    "tile_size"
  ],
  "get_max_num_permuted_tokens": [
    "num_tokens",
    "top_k",
    "num_local_experts",
    "tile_size"
  ],
  "MoeActivationType": {
    "Gelu": [],
    "Relu": [],
    "Silu": [],
    "Swiglu": [],
    "Geglu": [],
    "Identity": []
  },
  "_get_moe_utils_module": [],
  "_get_dtype_suffix": [
    "dtype"
  ],
  "moe_permute": [
    "input",
    "permuted_output",
    "tile_idx_to_mn_limit",
    "permuted_idx_to_expanded_idx",
    "num_non_exiting_tiles",
    "max_num_permuted_tokens",
    "top_k",
    "tile_size",
    "enable_pdl",
    "input_sf",
    "permuted_sf"
  ],
  "moe_unpermute": [
    "permuted_input",
    "output",
    "expanded_idx_to_permuted_idx",
    "topk_scales",
    "num_tokens",
    "top_k",
    "enable_pdl"
  ],
  "moe_output_memset": [
    "output",
    "tile_idx_to_mn_limit",
    "expanded_idx_to_permuted_idx",
    "permuted_idx_to_expanded_idx",
    "num_non_exiting_tiles",
    "max_num_permuted_tokens",
    "top_k",
    "tile_size",
    "enable_pdl"
  ],
  "allocate_moe_sort_buffers": [
    "num_tokens",
    "num_experts",
    "top_k",
    "num_local_experts",
    "tile_tokens_dim",
    "device"
  ],
  "moe_sort": [
    "token_selected_experts",
    "token_final_scales",
    "num_experts",
    "top_k",
    "local_expert_offset",
    "num_local_experts",
    "tile_tokens_dim",
    "enable_pdl",
    "out_tile_idx_to_expert_idx",
    "out_tile_idx_to_mn_limit",
    "out_expanded_idx_to_permuted_idx",
    "out_permuted_idx_to_expanded_idx",
    "out_total_num_padded_tokens",
    "out_num_non_exiting_tiles"
  ],
  "moe_activation": [
    "input",
    "output",
    "tile_idx_to_mn_limit",
    "num_non_exiting_tiles",
    "activation_type",
    "max_num_permuted_tokens",
    "tile_size",
    "enable_pdl"
  ],
  "moe_swiglu": [
    "input",
    "output",
    "tile_idx_to_mn_limit",
    "num_non_exiting_tiles",
    "max_num_permuted_tokens",
    "tile_size",
    "enable_pdl"
  ],
  "moe_geglu": [
    "input",
    "output",
    "tile_idx_to_mn_limit",
    "num_non_exiting_tiles",
    "max_num_permuted_tokens",
    "tile_size",
    "enable_pdl"
  ],
  "moe_gelu": [
    "input",
    "output",
    "tile_idx_to_mn_limit",
    "num_non_exiting_tiles",
    "max_num_permuted_tokens",
    "tile_size",
    "enable_pdl"
  ],
  "moe_silu": [
    "input",
    "output",
    "tile_idx_to_mn_limit",
    "num_non_exiting_tiles",
    "max_num_permuted_tokens",
    "tile_size",
    "enable_pdl"
  ],
  "moe_relu": [
    "input",
    "output",
    "tile_idx_to_mn_limit",
    "num_non_exiting_tiles",
    "max_num_permuted_tokens",
    "tile_size",
    "enable_pdl"
  ],
  "create_tile_mapping": [
    "group_m_list",
    "mma_tiler_m",
    "permuted_m"
  ],
  "_get_compiled_kernel": [
    "permuted_m",
    "n",
    "k",
    "num_experts",
    "ab_dtype_name",
    "sf_dtype_name",
    "c_dtype_name",
    "sf_vec_size",
    "mma_tiler_mn",
    "cluster_shape_mn"
  ],
  "blockscaled_contiguous_grouped_gemm_nvfp4": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "alpha",
    "tile_idx_to_group_idx",
    "num_non_exiting_tiles",
    "out"
  ],
  "_get_compiled_swiglu_kernel": [
    "ab_dtype_name",
    "sf_dtype_name",
    "c_dtype_name",
    "sf_vec_size",
    "mma_tiler_mn",
    "cluster_shape_mn",
    "vectorized_f32"
  ],
  "blockscaled_contiguous_grouped_gemm_swiglu_fusion_nvfp4": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "alpha",
    "tile_idx_to_group_idx",
    "num_non_exiting_tiles",
    "out",
    "out_scale",
    "global_scale"
  ],
  "create_finalize_fusion_tensors": [
    "seq_len",
    "topk",
    "permuted_m",
    "group_m_list",
    "mma_tiler_mn",
    "final_scale_dtype"
  ],
  "_get_compiled_finalize_kernel": [
    "seq_len",
    "permuted_m",
    "n",
    "k",
    "num_experts",
    "topk",
    "a_ptr",
    "b_ptr",
    "a_sf_ptr",
    "b_sf_ptr",
    "c_ptr",
    "alpha_ptr",
    "tile_idx_ptr",
    "mn_limit_ptr",
    "permuted_idx_ptr",
    "num_tiles_ptr",
    "token_scales_ptr",
    "max_active_clusters",
    "stream",
    "sf_vec_size",
    "tile_size",
    "mma_tiler_mn",
    "cluster_shape_mn",
    "raster_along_m"
  ],
  "blockscaled_contiguous_grouped_gemm_finalize_fusion_nvfp4": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "alpha",
    "tile_idx_to_expert_idx",
    "num_non_exiting_tiles",
    "tile_idx_to_mn_limit",
    "permuted_idx_to_expanded_idx",
    "token_final_scales",
    "out"
  ],
  "create_gather_gemm_tensors": [
    "seq_len",
    "topk",
    "group_m_list",
    "mma_tiler_m"
  ],
  "_get_compiled_gather_kernel": [
    "orig_m",
    "permuted_m",
    "n",
    "k",
    "num_experts",
    "a_ptr",
    "b_ptr",
    "a_sf_ptr",
    "b_sf_ptr",
    "c_ptr",
    "c_sf_ptr",
    "alpha_ptr",
    "tile_idx_ptr",
    "mn_limit_ptr",
    "token_id_ptr",
    "num_tiles_ptr",
    "norm_const_ptr",
    "max_active_clusters",
    "stream",
    "ab_dtype",
    "sf_dtype",
    "c_dtype",
    "sf_vec_size",
    "tile_size",
    "topk",
    "mma_tiler_mn",
    "cluster_shape_mn",
    "vectorized_f32",
    "raster_along_m"
  ],
  "blockscaled_contiguous_gather_grouped_gemm_swiglu_fusion_nvfp4": [
    "a",
    "b",
    "a_scale",
    "b_scale",
    "alpha",
    "tile_idx_to_expert_idx",
    "tile_idx_to_mn_limit",
    "token_id_mapping",
    "num_non_exiting_tiles",
    "out",
    "out_scale",
    "global_scale"
  ],
  "get_gemm1_valid_tactics": [
    "tile_size"
  ],
  "get_gemm2_valid_tactics": [
    "tile_size"
  ],
  "get_moe_valid_tactics": [],
  "ALL_MOE_TACTICS": [],
  "DEFAULT_MOE_TACTIC": [],
  "_extract_tactic_params": [
    "tactic"
  ],
  "CuteDslFusedMoENvfp4Runner": {
    "dynamic_tensor_initializers": [],
    "tuning_config": [],
    "__init__": [
      "self",
      "forward_impl",
      "num_experts",
      "top_k",
      "num_local_experts",
      "local_expert_offset",
      "use_fused_finalize",
      "output_dtype"
    ],
    "__hash__": [
      "self"
    ],
    "get_valid_tactics": [
      "self",
      "inputs",
      "profile"
    ],
    "forward": [
      "self",
      "inputs",
      "tactic",
      "do_preparation"
    ]
  },
  "print_all_tactics": [],
  "_get_cuda_graph_resources": [],
  "_moe_core_impl": [
    "x",
    "x_sf",
    "token_selected_experts",
    "token_final_scales",
    "w1_weight",
    "w1_weight_sf",
    "w1_alpha",
    "fc2_input_scale",
    "w2_weight",
    "w2_weight_sf",
    "w2_alpha",
    "num_experts",
    "top_k",
    "num_local_experts",
    "local_expert_offset",
    "tile_size",
    "gemm1_mma_tiler_mn",
    "gemm1_cluster_shape_mn",
    "gemm2_mma_tiler_mn",
    "gemm2_cluster_shape_mn",
    "moe_sort_buffers",
    "gemm1_out",
    "gemm1_out_scale",
    "moe_output",
    "aux_stream",
    "main_event",
    "memset_event",
    "output_dtype",
    "use_async_memset"
  ],
  "CuteDslMoEWrapper": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "use_cuda_graph",
      "max_num_tokens",
      "num_local_experts",
      "local_expert_offset",
      "tile_size",
      "sf_vec_size",
      "output_dtype",
      "device"
    ],
    "_allocate_buffers": [
      "self"
    ],
    "_forward_with_tactic": [
      "self",
      "x",
      "x_sf",
      "token_selected_experts",
      "token_final_scales",
      "w1_weight",
      "w1_weight_sf",
      "w1_alpha",
      "fc2_input_scale",
      "w2_weight",
      "w2_weight_sf",
      "w2_alpha",
      "num_experts",
      "top_k",
      "num_local_experts",
      "local_expert_offset",
      "tile_size",
      "gemm1_mma_tiler_mn",
      "gemm1_cluster_shape_mn",
      "gemm2_mma_tiler_mn",
      "gemm2_cluster_shape_mn",
      "output_dtype",
      "use_fused_finalize",
      "moe_output"
    ],
    "run": [
      "self",
      "x",
      "x_sf",
      "token_selected_experts",
      "token_final_scales",
      "w1_weight",
      "w1_weight_sf",
      "w1_alpha",
      "fc2_input_scale",
      "w2_weight",
      "w2_weight_sf",
      "w2_alpha",
      "tactic"
    ],
    "get_valid_tactics": [
      "self"
    ]
  },
  "_cute_dsl_fused_moe_nvfp4_impl": [
    "x",
    "x_sf",
    "token_selected_experts",
    "token_final_scales",
    "w1_weight",
    "w1_weight_sf",
    "w1_alpha",
    "fc2_input_scale",
    "w2_weight",
    "w2_weight_sf",
    "w2_alpha",
    "num_experts",
    "top_k",
    "num_local_experts",
    "local_expert_offset",
    "tile_size",
    "gemm1_mma_tiler_mn",
    "gemm1_cluster_shape_mn",
    "gemm2_mma_tiler_mn",
    "gemm2_cluster_shape_mn",
    "output_dtype",
    "use_fused_finalize",
    "moe_output",
    "aux_stream"
  ],
  "cute_dsl_fused_moe_nvfp4": [
    "x",
    "x_sf",
    "token_selected_experts",
    "token_final_scales",
    "w1_weight",
    "w1_weight_sf",
    "w1_alpha",
    "fc2_input_scale",
    "w2_weight",
    "w2_weight_sf",
    "w2_alpha",
    "num_experts",
    "top_k",
    "num_local_experts",
    "local_expert_offset",
    "output_dtype",
    "use_fused_finalize",
    "moe_output",
    "aux_stream"
  ],
  "pipeline_init_wait": [
    "cta_layout_vmnk"
  ],
  "PipelineTmaUmma": {
    "_compute_mcast_arrival_mask": [
      "cta_layout_vmnk",
      "mcast_mode_mn"
    ],
    "_compute_is_leader_cta": [
      "cta_layout_vmnk"
    ],
    "create": [],
    "consumer_release": [
      "self",
      "state"
    ],
    "producer_acquire": [
      "self",
      "state",
      "try_acquire_token"
    ],
    "producer_commit": [
      "self",
      "state"
    ]
  },
  "PipelineUmmaAsync": {
    "_compute_tmem_sync_mask": [
      "cta_layout_vmnk"
    ],
    "_compute_peer_cta_rank": [],
    "create": [],
    "producer_commit": [
      "self",
      "state"
    ],
    "producer_tail": [
      "self",
      "state"
    ]
  },
  "PipelineCpAsyncUmma": {
    "_compute_leading_cta_rank": [
      "cta_v_size"
    ],
    "_compute_is_leader_cta": [
      "cta_layout_vmnk"
    ],
    "_compute_peer_cta_mask": [
      "cta_layout_vmnk"
    ],
    "create": [],
    "consumer_release": [
      "self",
      "state"
    ]
  },
  "Sm100BlockScaledContiguousGroupedGemmKernel": {
    "__init__": [
      "self",
      "sf_vec_size",
      "mma_tiler_mn",
      "cluster_shape_mn"
    ],
    "_setup_attributes": [
      "self"
    ],
    "__call__": [
      "self",
      "a",
      "b",
      "c",
      "sfa",
      "sfb",
      "tile_idx_to_group_idx",
      "num_non_exiting_tiles",
      "alpha",
      "max_active_clusters",
      "stream",
      "epilogue_op"
    ],
    "mainloop_s2t_copy_and_partition": [
      "self",
      "sSF",
      "tSF"
    ],
    "kernel": [
      "self",
      "tiled_mma",
      "tiled_mma_sfb",
      "tma_atom_a",
      "mA_mkl",
      "tma_atom_b",
      "mB_nkl",
      "tma_atom_sfa",
      "mSFA_mkl",
      "tma_atom_sfb",
      "mSFB_nkl",
      "tma_atom_c",
      "mC_mnl",
      "tile_idx_to_group_idx",
      "num_non_exiting_tiles",
      "alpha",
      "cluster_layout_vmnk",
      "cluster_layout_sfb_vmnk",
      "a_smem_layout_staged",
      "b_smem_layout_staged",
      "sfa_smem_layout_staged",
      "sfb_smem_layout_staged",
      "c_smem_layout_staged",
      "epi_tile",
      "tile_sched_params",
      "epilogue_op"
    ],
    "epilog_tmem_copy_and_partition": [
      "self",
      "tidx",
      "tAcc",
      "gC_mnl",
      "epi_tile",
      "use_2cta_instrs"
    ],
    "epilog_smem_copy_and_partition": [
      "self",
      "tiled_copy_t2r",
      "tTR_rC",
      "tidx",
      "sC"
    ],
    "epilog_gmem_copy_and_partition": [
      "self",
      "tidx",
      "atom",
      "gC_mnl",
      "epi_tile",
      "sC"
    ],
    "_compute_stages": [
      "tiled_mma",
      "mma_tiler_mnk",
      "a_dtype",
      "b_dtype",
      "epi_tile",
      "c_dtype",
      "c_layout",
      "sf_dtype",
      "sf_vec_size",
      "num_smem_capacity",
      "occupancy"
    ],
    "_compute_grid": [
      "c",
      "cta_tile_shape_mnk",
      "cluster_shape_mn",
      "max_active_clusters"
    ],
    "_get_tma_atom_kind": [
      "atom_sm_cnt",
      "mcast"
    ],
    "is_valid_dtypes_and_scale_factor_vec_size": [
      "ab_dtype",
      "sf_dtype",
      "sf_vec_size",
      "c_dtype"
    ],
    "is_valid_layouts": [
      "ab_dtype",
      "c_dtype",
      "a_major",
      "b_major",
      "c_major"
    ],
    "is_valid_mma_tiler_and_cluster_shape": [
      "mma_tiler_mn",
      "cluster_shape_mn"
    ],
    "is_valid_tensor_alignment": [
      "m",
      "n",
      "k",
      "l",
      "ab_dtype",
      "c_dtype",
      "a_major",
      "b_major",
      "c_major"
    ],
    "can_implement": [
      "ab_dtype",
      "sf_dtype",
      "sf_vec_size",
      "c_dtype",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "m",
      "n",
      "k",
      "l",
      "a_major",
      "b_major",
      "c_major"
    ],
    "wrapper": [
      "self",
      "a_ptr",
      "b_ptr",
      "a_sf_ptr",
      "b_sf_ptr",
      "c_ptr",
      "alpha_ptr",
      "tile_idx_to_group_idx_ptr",
      "num_non_exiting_tiles_ptr",
      "m",
      "n",
      "k",
      "l",
      "tile_size",
      "scaling_vector_size",
      "max_active_clusters",
      "stream",
      "epilogue_op"
    ]
  },
  "TRTLLM_ENABLE_PDL": [],
  "_Pointer": {
    "__init__": [
      "self",
      "pointer",
      "dtype",
      "mem_space",
      "assumed_align"
    ],
    "size_in_bytes": [
      "self"
    ],
    "__get_mlir_types__": [
      "self"
    ],
    "__c_pointers__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "mlir_type": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "memspace": [
      "self"
    ],
    "align": [
      "self",
      "min_align"
    ],
    "verify": [
      "self",
      "expected_py_type"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "make_ptr": [
    "dtype",
    "value",
    "mem_space",
    "assumed_align"
  ],
  "is_power_of_2": [
    "x"
  ],
  "fmin": [
    "a",
    "b"
  ],
  "sigmoid_f32": [
    "a",
    "fastmath"
  ],
  "silu_f32": [
    "a",
    "fastmath"
  ],
  "vectorized_atomic_add_bf16x8": [
    "rOut_epi_packed",
    "scatter_out_offset",
    "loc",
    "ip"
  ],
  "vectorized_atomic_add_fp32x2": [
    "rOut_epi_packed",
    "scatter_out_offset",
    "loc",
    "ip"
  ],
  "atomic_add_func": [
    "rOut_epi_packed",
    "scatter_out_offset",
    "loc",
    "ip"
  ],
  "blk_reduce_bf16": [
    "dst_gemm",
    "src_smem",
    "size",
    "loc",
    "ip"
  ],
  "blk_reduce_fp32": [
    "dst_gemm",
    "src_smem",
    "size",
    "loc",
    "ip"
  ],
  "blk_reduce_fp16": [
    "dst_gemm",
    "src_smem",
    "size",
    "loc",
    "ip"
  ],
  "griddepcontrol_wait": [],
  "griddepcontrol_launch_dependents": [],
  "Sm100BlockScaledContiguousGroupedGemmSwigluFusionKernel": {
    "__init__": [
      "self",
      "sf_vec_size",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "vectorized_f32"
    ],
    "_setup_attributes": [
      "self"
    ],
    "__call__": [
      "self",
      "a",
      "b",
      "c",
      "sfa",
      "sfb",
      "sfc_tensor",
      "norm_const_tensor",
      "tile_idx_to_expert_idx",
      "num_non_exiting_tiles",
      "alpha",
      "max_active_clusters",
      "stream",
      "epilogue_op"
    ],
    "mainloop_s2t_copy_and_partition": [
      "self",
      "sSF",
      "tSF"
    ],
    "kernel": [
      "self",
      "tiled_mma",
      "tiled_mma_sfb",
      "tma_atom_a",
      "mA_mkl",
      "tma_atom_b",
      "mB_nkl",
      "tma_atom_sfa",
      "mSFA_mkl",
      "tma_atom_sfb",
      "mSFB_nkl",
      "tma_atom_c",
      "mC_mnl",
      "mSFC_mnl",
      "norm_const_tensor",
      "tile_idx_to_expert_idx",
      "num_non_exiting_tiles",
      "alpha",
      "cluster_layout_vmnk",
      "cluster_layout_sfb_vmnk",
      "a_smem_layout_staged",
      "b_smem_layout_staged",
      "sfa_smem_layout_staged",
      "sfb_smem_layout_staged",
      "c_smem_layout_staged",
      "epi_tile",
      "tile_sched_params",
      "epilogue_op"
    ],
    "epilog_tmem_copy_and_partition": [
      "self",
      "tidx",
      "tAcc",
      "gC_mnl",
      "epi_tile",
      "use_2cta_instrs"
    ],
    "epilog_smem_copy_and_partition": [
      "self",
      "tiled_copy_t2r",
      "tTR_rC",
      "tidx",
      "sC"
    ],
    "epilog_gmem_copy_and_partition": [
      "self",
      "tidx",
      "atom",
      "gC_mnl",
      "epi_tile",
      "sC"
    ],
    "_compute_stages": [
      "tiled_mma",
      "mma_tiler_mnk",
      "a_dtype",
      "b_dtype",
      "epi_tile",
      "c_dtype",
      "c_layout",
      "sf_dtype",
      "sf_vec_size",
      "num_smem_capacity",
      "occupancy"
    ],
    "_compute_grid": [
      "c",
      "cta_tile_shape_mnk",
      "cluster_shape_mn",
      "max_active_clusters"
    ],
    "_get_tma_atom_kind": [
      "atom_sm_cnt",
      "mcast"
    ],
    "get_dtype_rcp_limits": [
      "dtype"
    ],
    "is_valid_dtypes_and_scale_factor_vec_size": [
      "ab_dtype",
      "sf_dtype",
      "sf_vec_size",
      "c_dtype"
    ],
    "is_valid_layouts": [
      "ab_dtype",
      "c_dtype",
      "a_major",
      "b_major",
      "c_major"
    ],
    "is_valid_mma_tiler_and_cluster_shape": [
      "mma_tiler_mn",
      "cluster_shape_mn"
    ],
    "is_valid_tensor_alignment": [
      "m",
      "n",
      "k",
      "l",
      "ab_dtype",
      "c_dtype",
      "a_major",
      "b_major",
      "c_major"
    ],
    "can_implement": [
      "cls",
      "ab_dtype",
      "sf_dtype",
      "sf_vec_size",
      "c_dtype",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "m",
      "n",
      "k",
      "l",
      "a_major",
      "b_major",
      "c_major"
    ],
    "wrapper": [
      "self",
      "a_ptr",
      "b_ptr",
      "a_sf_ptr",
      "b_sf_ptr",
      "c_ptr",
      "c_sf_ptr",
      "alpha_ptr",
      "tile_idx_to_group_idx_ptr",
      "num_non_exiting_tiles_ptr",
      "global_sf_ptr",
      "m",
      "n",
      "k",
      "l",
      "tile_size",
      "scaling_vector_size",
      "max_active_clusters",
      "stream",
      "epilogue_op"
    ]
  },
  "hooked_PersistentTileSchedulerParams_init": [
    "self",
    "problem_shape_ntile_mnl",
    "cluster_shape_mnk",
    "swizzle_size",
    "raster_along_m"
  ],
  "hooked_get_cluster_work_idx_with_fastdivmod": [
    "self",
    "current_work_linear_idx"
  ],
  "Sm100BlockScaledContiguousGroupedGemmFinalizeFusionKernel": {
    "__init__": [
      "self",
      "sf_vec_size",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "use_blkred",
      "raster_along_m"
    ],
    "_setup_attributes": [
      "self"
    ],
    "__call__": [
      "self",
      "a",
      "b",
      "out",
      "sfa",
      "sfb",
      "tile_idx_to_expert_idx",
      "num_non_exiting_tiles",
      "tile_idx_to_mn_limit",
      "alpha",
      "max_active_clusters",
      "stream",
      "permuted_idx_to_expanded_idx",
      "token_final_scales",
      "epilogue_op"
    ],
    "mainloop_s2t_copy_and_partition": [
      "self",
      "sSF",
      "tSF"
    ],
    "kernel": [
      "self",
      "tiled_mma",
      "tiled_mma_sfb",
      "tma_atom_a",
      "mA_mkl",
      "tma_atom_b",
      "mB_nkl",
      "tma_atom_sfa",
      "mSFA_mkl",
      "tma_atom_sfb",
      "mSFB_nkl",
      "out",
      "tile_idx_to_expert_idx",
      "num_non_exiting_tiles",
      "tile_idx_to_mn_limit",
      "alpha",
      "permuted_idx_to_expanded_idx",
      "token_final_scales",
      "cluster_layout_vmnk",
      "cluster_layout_sfb_vmnk",
      "a_smem_layout_staged",
      "b_smem_layout_staged",
      "sfa_smem_layout_staged",
      "sfb_smem_layout_staged",
      "c_smem_layout_staged",
      "epi_tile",
      "epi_layout",
      "topK",
      "tile_sched_params",
      "epilogue_op"
    ],
    "epilog_tmem_copy_and_partition": [
      "self",
      "tidx",
      "tAcc",
      "gC_mnl",
      "epi_tile",
      "use_2cta_instrs"
    ],
    "epilog_smem_copy_and_partition": [
      "self",
      "tidx",
      "tTR_rC",
      "sC",
      "tiled_copy_t2r"
    ],
    "_compute_stages": [
      "tiled_mma",
      "mma_tiler_mnk",
      "a_dtype",
      "b_dtype",
      "out_dtype",
      "cta_tile",
      "sf_dtype",
      "sf_vec_size",
      "num_smem_capacity",
      "occupancy",
      "use_blkred"
    ],
    "_compute_grid": [
      "gemm_shape",
      "cta_tile_shape_mnk",
      "cluster_shape_mn",
      "max_active_clusters",
      "raster_along_m"
    ],
    "_get_tma_atom_kind": [
      "atom_sm_cnt",
      "mcast"
    ],
    "is_valid_dtypes_and_scale_factor_vec_size": [
      "ab_dtype",
      "sf_dtype",
      "sf_vec_size",
      "out_dtype"
    ],
    "is_valid_layouts": [
      "ab_dtype",
      "out_dtype",
      "a_major",
      "b_major",
      "out_major"
    ],
    "is_valid_mma_tiler_and_cluster_shape": [
      "mma_tiler_mn",
      "cluster_shape_mn"
    ],
    "is_valid_tensor_alignment": [
      "m",
      "n",
      "k",
      "l",
      "ab_dtype",
      "out_dtype",
      "a_major",
      "b_major",
      "out_major"
    ],
    "can_implement": [
      "cls",
      "ab_dtype",
      "sf_dtype",
      "sf_vec_size",
      "out_dtype",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "m",
      "n",
      "k",
      "l",
      "a_major",
      "b_major",
      "out_major"
    ],
    "wrapper": [
      "self",
      "a_ptr",
      "b_ptr",
      "a_sf_ptr",
      "b_sf_ptr",
      "c_ptr",
      "alpha_ptr",
      "tile_idx_to_group_idx_ptr",
      "tile_idx_to_mn_limit_ptr",
      "permuted_idx_to_expanded_idx_ptr",
      "num_non_exiting_tiles_ptr",
      "token_final_scales_ptr",
      "m",
      "n",
      "k",
      "l",
      "num_tokens",
      "top_k",
      "tile_size",
      "scaling_vector_size",
      "max_active_clusters",
      "stream",
      "epilogue_op"
    ]
  },
  "BlockScaledContiguousGatherGroupedGemmKernel": {
    "__init__": [
      "self",
      "sf_vec_size",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "vectorized_f32",
      "topk",
      "raster_along_m"
    ],
    "_setup_attributes": [
      "self"
    ],
    "__call__": [
      "self",
      "a",
      "b",
      "c",
      "sfa",
      "sfb",
      "sfc_tensor",
      "norm_const_tensor",
      "tile_idx_to_expert_idx",
      "tile_idx_to_mn_limit",
      "token_id_mapping_tensor",
      "num_non_exiting_tiles",
      "alpha",
      "max_active_clusters",
      "stream",
      "epilogue_op"
    ],
    "mainloop_s2t_copy_and_partition": [
      "self",
      "sSF",
      "tSF"
    ],
    "kernel": [
      "self",
      "tiled_mma",
      "tiled_mma_sfb",
      "mA_mkl",
      "tma_atom_b",
      "mB_nkl",
      "mSFA_mkl",
      "tma_atom_sfb",
      "mSFB_nkl",
      "tma_atom_c",
      "mC_mnl",
      "mSFC_mnl",
      "norm_const_tensor",
      "tile_idx_to_expert_idx",
      "tile_idx_to_mn_limit",
      "token_id_mapping_tensor",
      "num_non_exiting_tiles",
      "alpha",
      "cluster_layout_vmnk",
      "cluster_layout_sfb_vmnk",
      "a_smem_layout_staged",
      "b_smem_layout_staged",
      "sfa_smem_layout_staged",
      "sfb_smem_layout_staged",
      "c_smem_layout_staged",
      "epi_tile",
      "tile_sched_params",
      "epilogue_op"
    ],
    "epilog_tmem_copy_and_partition": [
      "self",
      "tidx",
      "tAcc",
      "gC_mnl",
      "epi_tile",
      "use_2cta_instrs"
    ],
    "epilog_smem_copy_and_partition": [
      "self",
      "tiled_copy_t2r",
      "tTR_rC",
      "tidx",
      "sC"
    ],
    "epilog_gmem_copy_and_partition": [
      "self",
      "tidx",
      "atom",
      "gC_mnl",
      "epi_tile",
      "sC"
    ],
    "_compute_stages": [
      "tiled_mma",
      "mma_tiler_mnk",
      "a_dtype",
      "b_dtype",
      "epi_tile",
      "c_dtype",
      "c_layout",
      "sf_dtype",
      "sf_vec_size",
      "num_smem_capacity",
      "occupancy"
    ],
    "_compute_grid": [
      "c",
      "cta_tile_shape_mnk",
      "cluster_shape_mn",
      "max_active_clusters",
      "raster_along_m"
    ],
    "_get_tma_atom_kind": [
      "atom_sm_cnt",
      "mcast"
    ],
    "get_dtype_rcp_limits": [
      "dtype"
    ],
    "is_valid_dtypes_and_scale_factor_vec_size": [
      "ab_dtype",
      "sf_dtype",
      "sf_vec_size",
      "c_dtype"
    ],
    "is_valid_layouts": [
      "ab_dtype",
      "c_dtype",
      "a_major",
      "b_major",
      "c_major"
    ],
    "is_valid_mma_tiler_and_cluster_shape": [
      "mma_tiler_mn",
      "cluster_shape_mn"
    ],
    "is_valid_tensor_alignment": [
      "m",
      "n",
      "k",
      "l",
      "ab_dtype",
      "c_dtype",
      "a_major",
      "b_major",
      "c_major"
    ],
    "can_implement": [
      "cls",
      "ab_dtype",
      "sf_dtype",
      "sf_vec_size",
      "c_dtype",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "m",
      "n",
      "k",
      "l",
      "a_major",
      "b_major",
      "c_major"
    ],
    "wrapper": [
      "self",
      "a_ptr",
      "b_ptr",
      "a_sf_ptr",
      "b_sf_ptr",
      "c_ptr",
      "c_sf_ptr",
      "alpha_ptr",
      "tile_idx_to_group_idx_ptr",
      "tile_idx_to_mn_limit_ptr",
      "token_id_mapping_ptr",
      "num_non_exiting_tiles_ptr",
      "global_sf_ptr",
      "orig_m",
      "m",
      "n",
      "k",
      "l",
      "tile_size",
      "scaling_vector_size",
      "max_active_clusters",
      "stream",
      "epilogue_op"
    ]
  },
  "cvt_sf_M32x4xrm_K4xrk_L_to_MKL": [
    "sf_swizzled_tensor",
    "sf_unswizzled_tensor"
  ],
  "_get_dummy_scale_tensor": [
    "device"
  ],
  "_create_cudnn_handle": [
    "stream"
  ],
  "_sdpa_prefill_key_fn": [
    "q",
    "k_cache",
    "v_cache",
    "scale"
  ],
  "_batch_prefill_with_kv_cache": [
    "q",
    "k_cache",
    "v_cache",
    "scale",
    "workspace_buffer"
  ],
  "cudnn_batch_prefill_with_kv_cache": [
    "q",
    "k_cache",
    "v_cache",
    "scale",
    "workspace_buffer"
  ],
  "_sdpa_decode_key_fn": [
    "q",
    "k_cache",
    "v_cache",
    "scale"
  ],
  "_batch_decode_with_kv_cache": [
    "q",
    "k_cache",
    "v_cache",
    "scale",
    "workspace_buffer"
  ],
  "cudnn_batch_decode_with_kv_cache": [
    "q",
    "k_cache",
    "v_cache",
    "scale",
    "workspace_buffer"
  ],
  "get_cudnn_fmha_gen_module": [],
  "best_configs": [],
  "FLOAT4_E2M1_MAX": [],
  "FLOAT8_E4M3_MAX": [],
  "SF_VEC_SIZE": [],
  "COPY_BITS": [],
  "get_sm_version": [
    "device"
  ],
  "set_block_rank": [
    "smem_ptr",
    "peer_cta_rank_in_cluster"
  ],
  "store_shared_remote": [
    "val",
    "smem_ptr",
    "mbar_ptr",
    "peer_cta_rank_in_cluster"
  ],
  "elem_pointer": [
    "x",
    "coord"
  ],
  "ld_global_v4_u32": [
    "base_ptr"
  ],
  "st_global_u64": [
    "base_ptr",
    "value"
  ],
  "get_ptr_as_int64": [
    "tensor",
    "offset"
  ],
  "rcp_approx_ftz": [
    "a"
  ],
  "fmin_f32": [
    "a",
    "b"
  ],
  "fmax_f32": [
    "a",
    "b"
  ],
  "fabs_f32": [
    "a"
  ],
  "half2_mul": [
    "a",
    "b"
  ],
  "hadd2": [
    "a",
    "b"
  ],
  "habs2": [
    "x"
  ],
  "hmax2": [
    "a",
    "b"
  ],
  "hmax_to_f32": [
    "x"
  ],
  "half2_to_float2_scaled": [
    "h2",
    "scale"
  ],
  "bfloat2_mul": [
    "a",
    "b"
  ],
  "bfloat2_add": [
    "a",
    "b"
  ],
  "bfloat2_habs2": [
    "x"
  ],
  "bfloat2_hmax2": [
    "a",
    "b"
  ],
  "bfloat2_hmax_to_f32": [
    "x"
  ],
  "bfloat2_to_float2_scaled": [
    "bf2",
    "scale"
  ],
  "cvt_f32_to_e4m3": [
    "a"
  ],
  "fp8_e4m3_to_f32_and_rcp": [
    "fp8_val"
  ],
  "cvt_f32_to_ue8m0": [
    "max_val"
  ],
  "ue8m0_to_output_scale": [
    "ue8m0_val"
  ],
  "cvt_e2m1x8_f32": [
    "v0",
    "v1",
    "v2",
    "v3",
    "v4",
    "v5",
    "v6",
    "v7"
  ],
  "warp_reduce": [
    "val",
    "op",
    "width"
  ],
  "block_reduce": [
    "val",
    "op",
    "reduction_buffer",
    "init_val"
  ],
  "cluster_reduce": [
    "val",
    "op",
    "reduction_buffer",
    "mbar_ptr",
    "cluster_n",
    "init_val"
  ],
  "row_reduce": [
    "x",
    "op",
    "threads_per_row",
    "reduction_buffer",
    "mbar_ptr",
    "cluster_n",
    "init_val"
  ],
  "predicate_k": [
    "tXcX",
    "limit"
  ],
  "load_8_half2": [
    "mX",
    "mW",
    "row_offset",
    "col_offset",
    "H"
  ],
  "half2_mul_8": [
    "x_h2",
    "w_h2"
  ],
  "bfloat2_mul_8": [
    "x_h2",
    "w_h2"
  ],
  "half2_max_abs_8": [
    "xw_h2"
  ],
  "bfloat2_max_abs_8": [
    "xw_h2"
  ],
  "half2_to_float16": [
    "xw_h2",
    "scale"
  ],
  "bfloat2_to_float16": [
    "xw_h2",
    "scale"
  ],
  "quantize_and_pack_16": [
    "y_f32",
    "inv_scale"
  ],
  "load_f32_16_from_smem": [
    "sH",
    "row_idx",
    "col_offset"
  ],
  "compute_y_and_max_abs_f32": [
    "h_f32",
    "w_f32",
    "rstd"
  ],
  "AddRMSNormFP4QuantKernel": {
    "__init__": [
      "self",
      "dtype",
      "H",
      "block_size",
      "output_swizzled",
      "is_fp16",
      "sm_version",
      "scale_format",
      "output_both_sf_layouts"
    ],
    "_compute_cluster_n": [
      "H",
      "dtype",
      "sm_version"
    ],
    "_compute_threads_per_row": [
      "H_per_cta"
    ],
    "_compute_num_threads": [
      "H_per_cta"
    ],
    "_estimate_smem_bytes": [
      "H",
      "cluster_n",
      "elem_size"
    ],
    "_make_tv_layout": [
      "threads_per_row",
      "rows_per_block",
      "vec_size",
      "num_vec_blocks"
    ],
    "_smem_size_in_bytes": [
      "self"
    ],
    "__call__": [
      "self",
      "mX",
      "mR",
      "mW",
      "mY",
      "mS",
      "mS_unswizzled",
      "mGlobalScale",
      "M",
      "eps",
      "stream"
    ],
    "kernel": [
      "self",
      "mX",
      "mR",
      "mW",
      "mY",
      "mS",
      "mS_unswizzled",
      "mGlobalScale",
      "M",
      "eps",
      "tv_layout",
      "tiler_mn"
    ]
  },
  "add_rmsnorm_fp4quant": [
    "input",
    "residual",
    "weight",
    "y_fp4",
    "block_scale",
    "global_scale",
    "eps",
    "block_size",
    "scale_format",
    "is_sf_swizzled_layout",
    "output_both_sf_layouts",
    "block_scale_unswizzled"
  ],
  "is_cute_dsl_available": [],
  "get_cutlass_dtype": [
    "dtype"
  ],
  "cutlass_to_torch_dtype": [
    "cutlass_dtype"
  ],
  "get_num_sm": [
    "device"
  ],
  "get_hardware_info": [],
  "get_max_active_clusters": [
    "cluster_size"
  ],
  "convert_sf_to_mma_layout": [
    "sf",
    "m",
    "k",
    "num_groups",
    "sf_vec_size"
  ],
  "convert_sf_from_mma_layout": [
    "sf_6d",
    "m",
    "k",
    "num_groups",
    "sf_vec_size"
  ],
  "get_mma_sf_shape": [
    "m",
    "k",
    "num_groups",
    "sf_vec_size"
  ],
  "RMSNormFP4QuantKernel": {
    "__init__": [
      "self",
      "dtype",
      "H",
      "block_size",
      "output_swizzled",
      "is_fp16",
      "sm_version",
      "scale_format"
    ],
    "_compute_cluster_n": [
      "H",
      "dtype",
      "sm_version"
    ],
    "_compute_threads_per_row": [
      "H_per_cta"
    ],
    "_compute_num_threads": [
      "H_per_cta"
    ],
    "_estimate_smem_bytes": [
      "H",
      "cluster_n",
      "elem_size"
    ],
    "_make_tv_layout": [
      "threads_per_row",
      "rows_per_block",
      "vec_size",
      "num_vec_blocks"
    ],
    "_smem_size_in_bytes": [
      "self"
    ],
    "__call__": [
      "self",
      "mX",
      "mW",
      "mY",
      "mS",
      "mGlobalScale",
      "M",
      "eps",
      "stream"
    ],
    "kernel": [
      "self",
      "mX",
      "mW",
      "mY",
      "mS",
      "mGlobalScale",
      "M",
      "eps",
      "tv_layout",
      "tiler_mn"
    ]
  },
  "rmsnorm_fp4quant": [
    "input",
    "weight",
    "y_fp4",
    "block_scale",
    "global_scale",
    "eps",
    "block_size",
    "scale_format",
    "is_sf_swizzled_layout"
  ],
  "spin_lock_multimem_arrive": [
    "lock_ptr",
    "loc",
    "ip"
  ],
  "spin_lock_atom_cas_acquire_wait": [
    "lock_ptr"
  ],
  "sm_wise_inter_gpu_multimem_barrier": [
    "barrier",
    "barrier_mc",
    "num_ranks",
    "loc",
    "ip"
  ],
  "PersistentDenseGemmKernel": {
    "__init__": [
      "self",
      "acc_dtype",
      "use_2cta_instrs",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "use_tma_store",
      "all_reduce",
      "sm_version"
    ],
    "is_valid": [
      "self"
    ],
    "_setup_attributes": [
      "self"
    ],
    "__call__": [
      "self",
      "a",
      "b",
      "c",
      "max_active_clusters",
      "stream",
      "epilogue_op",
      "c_mc",
      "barrier_flag",
      "barrier_flag_mc"
    ],
    "kernel": [
      "self",
      "tiled_mma",
      "tma_atom_a",
      "mA_mkl",
      "tma_atom_b",
      "mB_nkl",
      "tma_atom_c",
      "mC_mnl",
      "cluster_layout_vmnk",
      "a_smem_layout_staged",
      "b_smem_layout_staged",
      "c_smem_layout_staged",
      "epi_tile",
      "tile_sched_params",
      "epilogue_op",
      "c_mc",
      "barrier_flag",
      "barrier_flag_mc"
    ],
    "epilog_tmem_copy_and_partition": [
      "self",
      "tidx",
      "tAcc",
      "gC_mnl",
      "epi_tile",
      "use_2cta_instrs"
    ],
    "epilog_smem_copy_and_partition": [
      "self",
      "tiled_copy_t2r",
      "tTR_rC",
      "tidx",
      "sC"
    ],
    "epilog_gmem_copy_and_partition": [
      "self",
      "tidx",
      "atom",
      "gC_mnl",
      "epi_tile",
      "sC"
    ],
    "_compute_stages": [
      "tiled_mma",
      "mma_tiler_mnk",
      "a_dtype",
      "b_dtype",
      "epi_tile",
      "c_dtype",
      "c_layout",
      "smem_capacity",
      "occupancy",
      "use_tma_store"
    ],
    "_compute_grid": [
      "c",
      "cta_tile_shape_mnk",
      "cluster_shape_mn",
      "max_active_clusters"
    ],
    "_compute_num_tmem_alloc_cols": [
      "tiled_mma",
      "mma_tiler",
      "num_acc_stage"
    ],
    "is_valid_dtypes": [
      "ab_dtype",
      "acc_dtype",
      "c_dtype",
      "all_reduce"
    ],
    "is_valid_mma_tiler_and_cluster_shape": [
      "use_2cta_instrs",
      "mma_tiler_mn",
      "cluster_shape_mn"
    ],
    "is_valid_tensor_alignment": [
      "m",
      "n",
      "k",
      "l",
      "ab_dtype",
      "c_dtype",
      "a_major",
      "b_major",
      "c_major",
      "all_reduce"
    ],
    "is_valid_epilog_store_option": [
      "use_2cta_instrs",
      "use_tma_store",
      "m",
      "n",
      "mma_tiler_mn"
    ],
    "can_implement": [
      "ab_dtype",
      "acc_dtype",
      "c_dtype",
      "use_2cta_instrs",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "use_tma_store",
      "m",
      "n",
      "k",
      "l",
      "a_major",
      "b_major",
      "c_major",
      "all_reduce"
    ]
  },
  "perform_setup": [],
  "IdentitySwizzle1": [],
  "IdentitySwizzle2": [],
  "IdentitySwizzle4": [],
  "IdentitySwizzle8": [],
  "HorizontalSwizzle": [],
  "ThreadblockSwizzleStreamK": [],
  "StridedDgradIdentitySwizzle1": [],
  "StridedDgradIdentitySwizzle4": [],
  "StridedDgradHorizontalSwizzle": [],
  "_swizzling_functors": [],
  "get_swizzling_functors": [],
  "MatrixCoord": {
    "__init__": [
      "self",
      "row",
      "col"
    ],
    "row": [
      "self"
    ],
    "column": [
      "self"
    ],
    "leading_dimension": [
      "self",
      "layout"
    ]
  },
  "GemmCoord": {
    "__init__": [
      "self",
      "m",
      "n",
      "k"
    ],
    "m": [
      "self"
    ],
    "n": [
      "self"
    ],
    "k": [
      "self"
    ],
    "mk": [
      "self"
    ],
    "mn": [
      "self"
    ],
    "kn": [
      "self"
    ],
    "ctype": [
      "self"
    ],
    "batched_ctype": [
      "self",
      "batch_count"
    ]
  },
  "Conv2DProblemSize": {
    "__init__": [
      "self",
      "n",
      "h",
      "w",
      "c",
      "k",
      "r",
      "s",
      "c_",
      "pad_h",
      "pad_w",
      "stride_h",
      "stride_w",
      "dilation_h",
      "dilation_w",
      "mode",
      "split_k_slices",
      "groups"
    ],
    "ctype": [
      "self"
    ],
    "implicit_gemm_size": [
      "self",
      "kind"
    ],
    "from_sizes": [
      "input_size",
      "weight_size"
    ]
  },
  "_cuda_install_path_from_nvcc": [],
  "CUTLASS_PATH": [],
  "source_path": [],
  "_NVCC_VERSION": [],
  "nvcc_version": [],
  "_CUDA_INSTALL_PATH": [],
  "cuda_install_path": [],
  "CACHE_FILE": [],
  "this": [],
  "get_option_registry": [],
  "get_memory_pool": [],
  "base_cuda": [],
  "cuda": [],
  "check_cuda_versions": [],
  "initialize_cuda_context": [],
  "device_id": [],
  "_generator_ccs": [],
  "KernelsForDataType": {
    "__init__": [
      "self",
      "datatype_comb",
      "layout_comb"
    ],
    "add": [
      "self",
      "operation"
    ],
    "alignments": [
      "self",
      "operand"
    ],
    "all_operations": [
      "self"
    ],
    "default_operation": [
      "self",
      "math_operation"
    ],
    "operations": [
      "self",
      "alignment_A",
      "alignment_B",
      "alignment_C",
      "math_operation"
    ],
    "_operand_idx": [
      "self",
      "key"
    ],
    "find_alignment": [
      "self",
      "shape",
      "layout",
      "operand"
    ],
    "sort": [
      "self"
    ],
    "supports_math_operation": [
      "self",
      "math_operation"
    ]
  },
  "ArchOptions": {
    "__init__": [
      "self",
      "target_cc",
      "kernel_cc",
      "operation_kind",
      "gemm_kinds",
      "allowed_math_operations"
    ],
    "opclass_supports_combination": [
      "self",
      "op_class",
      "datatype_comb",
      "layout_comb",
      "math_operation"
    ],
    "supporting_opclasses": [
      "self",
      "element_a",
      "element_b",
      "element_accumulator",
      "layout_a",
      "layout_b",
      "math_operation"
    ],
    "operations": [
      "self",
      "op_class",
      "element_a",
      "element_b",
      "element_accumulator",
      "layout_a",
      "layout_b",
      "math_operation"
    ]
  },
  "OptionRegistry": {
    "__init__": [
      "self",
      "target_cc"
    ],
    "options_for_cc": [
      "self",
      "cc",
      "op_kind"
    ]
  },
  "Conv2d": {
    "__init__": [
      "self",
      "kind",
      "A",
      "B",
      "C",
      "D",
      "alpha",
      "beta",
      "element",
      "element_A",
      "element_B",
      "element_C",
      "element_D",
      "element_accumulator",
      "cc",
      "kernel_cc"
    ],
    "_reset_operations": [
      "self",
      "reset_epilogue"
    ],
    "tile_description": [
      "self",
      "td"
    ],
    "_valid_tile_description": [
      "self",
      "td"
    ],
    "tile_descriptions": [
      "self"
    ],
    "swizzling_stride": [
      "self",
      "stride"
    ],
    "_propose_swizzling_functor": [
      "self",
      "stride"
    ],
    "iterator_algorithm": [
      "self",
      "alg"
    ],
    "_propose_iterator_algorithm": [
      "self",
      "problem_size",
      "alignment_a",
      "alignment_b"
    ],
    "_validate_iterator_algorithm": [
      "self",
      "iterator_algorithm",
      "problem_size",
      "alignment_a",
      "alignment_b"
    ],
    "_propose_stride_support": [
      "self",
      "stride"
    ],
    "construct": [
      "self",
      "tile_description",
      "alignment_A",
      "alignment_B",
      "alignment_C",
      "iterator_algorithm",
      "stride_support",
      "swizzling_functor",
      "epilogue_functor"
    ],
    "compile": [
      "self",
      "tile_description",
      "alignment_A",
      "alignment_B",
      "alignment_C",
      "iterator_algorithm",
      "stride_support",
      "swizzling_functor",
      "epilogue_functor",
      "print_module"
    ],
    "_verify_type_and_layout": [
      "self",
      "tensor",
      "ref_type",
      "ref_layout",
      "name"
    ],
    "_get_and_verify_conv_problem_size": [
      "self",
      "A",
      "B",
      "C",
      "stride",
      "padding",
      "dilation"
    ],
    "run": [
      "self",
      "A",
      "B",
      "C",
      "D",
      "stride",
      "padding",
      "dilation",
      "alpha",
      "beta",
      "split_k",
      "sync",
      "print_module",
      "stream"
    ],
    "output_size": [
      "input_size",
      "weight_size",
      "padding",
      "stride",
      "dilation"
    ]
  },
  "Conv2dFprop": {
    "__init__": [
      "self",
      "input",
      "weight",
      "C",
      "output",
      "alpha",
      "beta",
      "element",
      "element_input",
      "element_weight",
      "element_C",
      "element_output",
      "element_accumulator",
      "cc",
      "kernel_cc"
    ],
    "run": [
      "self",
      "input",
      "weight",
      "C",
      "output",
      "alpha",
      "beta",
      "stride",
      "padding",
      "dilation",
      "split_k",
      "sync",
      "print_module",
      "stream"
    ]
  },
  "Conv2dDgrad": {
    "__init__": [
      "self",
      "grad_output",
      "weight",
      "C",
      "grad_input",
      "alpha",
      "beta",
      "element",
      "element_grad_output",
      "element_weight",
      "element_C",
      "element_grad_input",
      "element_accumulator",
      "cc",
      "kernel_cc"
    ],
    "run": [
      "self",
      "grad_output",
      "weight",
      "C",
      "grad_input",
      "alpha",
      "beta",
      "stride",
      "padding",
      "dilation",
      "split_k",
      "sync",
      "print_module",
      "stream"
    ]
  },
  "Conv2dWgrad": {
    "__init__": [
      "self",
      "grad_output",
      "input",
      "C",
      "grad_weight",
      "alpha",
      "beta",
      "element",
      "element_grad_output",
      "element_input",
      "element_C",
      "element_grad_weight",
      "element_accumulator",
      "cc",
      "kernel_cc"
    ],
    "run": [
      "self",
      "grad_output",
      "input",
      "C",
      "grad_weight",
      "alpha",
      "beta",
      "stride",
      "padding",
      "dilation",
      "split_k",
      "sync",
      "print_module",
      "stream"
    ]
  },
  "OperationBase": {
    "__init__": [
      "self",
      "cc",
      "kernel_cc",
      "operation_kind"
    ],
    "_find_closest_cc": [
      "self",
      "cc"
    ],
    "activations": [
      "self"
    ],
    "swizzling_functors": [
      "self"
    ],
    "_reset_options": [
      "self",
      "cc"
    ],
    "_verify_scalar": [
      "self",
      "scalar",
      "ref_scalar",
      "ref_dtype",
      "name"
    ],
    "_verify_tensor": [
      "self",
      "tensor",
      "ref_tensor",
      "ref_dtype",
      "ref_layout",
      "name"
    ],
    "opclass": [
      "self",
      "oc"
    ],
    "math_operation": [
      "self",
      "mo"
    ],
    "_elements_per_access": [
      "self"
    ],
    "_create_epilogue_functor_activation": [
      "self",
      "activation"
    ],
    "_reset_epilogue_functor_activation": [
      "self",
      "activation"
    ],
    "_reset_epilogue_functor_alignment": [
      "self",
      "alignment",
      "epilogue_functor"
    ],
    "activation": [
      "self",
      "act"
    ],
    "epilogue_visitor": [
      "self",
      "visitor"
    ],
    "run_setup": [
      "self"
    ]
  },
  "GroupedGemm": {
    "__init__": [
      "self",
      "A",
      "B",
      "C",
      "D",
      "alpha",
      "beta",
      "element_accumulator",
      "element",
      "layout",
      "element_A",
      "element_B",
      "element_C",
      "element_D",
      "layout_A",
      "layout_B",
      "layout_C",
      "cc"
    ],
    "swizzling_functor": [
      "self",
      "swizzling_functor"
    ],
    "construct": [
      "self",
      "tile_description",
      "alignment_A",
      "alignment_B",
      "alignment_C"
    ],
    "run": [
      "self",
      "A",
      "B",
      "C",
      "D",
      "alpha",
      "beta",
      "sync",
      "print_module",
      "stream"
    ]
  },
  "Gemm": {
    "__init__": [
      "self",
      "A",
      "B",
      "C",
      "D",
      "alpha",
      "beta",
      "element_accumulator",
      "element",
      "layout",
      "element_A",
      "element_B",
      "element_C",
      "element_D",
      "layout_A",
      "layout_B",
      "layout_C",
      "cc",
      "kernel_cc"
    ],
    "_reset_operations": [
      "self",
      "reset_epilogue"
    ],
    "swizzling_functor": [
      "self",
      "swizzling_functor"
    ],
    "tile_description": [
      "self",
      "td"
    ],
    "_valid_tile_description": [
      "self",
      "td"
    ],
    "tile_descriptions": [
      "self"
    ],
    "construct": [
      "self",
      "tile_description",
      "alignment_A",
      "alignment_B",
      "alignment_C"
    ],
    "compile": [
      "self",
      "tile_description",
      "alignment_A",
      "alignment_B",
      "alignment_C",
      "print_module"
    ],
    "_verify_rank": [
      "self",
      "tensor"
    ],
    "_get_batch_count": [
      "self",
      "A",
      "B",
      "C",
      "D"
    ],
    "_get_batch_stride": [
      "self",
      "tensor"
    ],
    "_get_problem_args": [
      "self",
      "A",
      "B",
      "C",
      "D"
    ],
    "_verify_type_and_layout": [
      "self",
      "tensor",
      "ref_type",
      "ref_layout",
      "name"
    ],
    "run": [
      "self",
      "A",
      "B",
      "C",
      "D",
      "alpha",
      "beta",
      "sync",
      "print_module",
      "visitor_args",
      "stream"
    ]
  },
  "multiply_add": [
    "x",
    "y",
    "z"
  ],
  "sum": [
    "x",
    "dim"
  ],
  "max": [
    "x",
    "dim"
  ],
  "maximum": [
    "x",
    "y"
  ],
  "minimum": [
    "x",
    "y"
  ],
  "exp": [
    "x"
  ],
  "permute": [
    "x",
    "indices"
  ],
  "reshape": [
    "x",
    "new_shape"
  ],
  "gelu": [],
  "hardswish": [],
  "identity": [],
  "leaky_relu": [],
  "relu": [],
  "sigmoid": [],
  "silu": [],
  "tanh": [],
  "_activations": [],
  "get_activations": [],
  "get_activation_epilogue": [
    "activation",
    "element_output",
    "elements_per_access",
    "element_accumulator",
    "element_compute"
  ],
  "trace": [
    "fn",
    "example_tensors"
  ],
  "calculate_smem_usage_per_stage": [
    "td",
    "operation_kind"
  ],
  "calculate_smem_usage": [
    "operation"
  ],
  "valid_stage_count": [
    "cc",
    "kernel_cc",
    "td",
    "element_C",
    "element_D",
    "verbose"
  ],
  "valid_cluster_shape": [
    "cc",
    "cluster_shape"
  ],
  "valid_schedule": [
    "cc",
    "kernel_schedule",
    "epilogue_schedule",
    "tile_scheduler"
  ],
  "alignment_or_default": [
    "alignment_provided",
    "default_alignment"
  ],
  "update_alignment": [
    "alignment_provided",
    "default_alignment"
  ],
  "bfloat16_available": [],
  "cupy_available": [],
  "numpy_available": [],
  "torch_available": [],
  "_library_to_cupy_dict": [],
  "_library_to_numpy_dict": [],
  "_library_to_torch_dict": [],
  "_torch_to_library_dict": [],
  "is_numpy_available": [],
  "is_numpy_tensor": [
    "inp"
  ],
  "numpy_library_type": [
    "inp"
  ],
  "numpy_type": [
    "inp"
  ],
  "is_cupy_available": [],
  "is_cupy_tensor": [
    "inp"
  ],
  "cupy_library_type": [
    "inp"
  ],
  "cupy_type": [
    "inp"
  ],
  "is_torch_available": [],
  "is_torch_tensor": [
    "inp"
  ],
  "torch_library_type": [
    "inp"
  ],
  "torch_type": [
    "inp"
  ],
  "is_bfloat16_available": [],
  "bfloat16_library_type": [
    "inp"
  ],
  "bfloat16_type": [
    "inp"
  ],
  "library_type": [
    "inp"
  ],
  "_tensor_from_numpy": [
    "np_tensor"
  ],
  "_tensor_from_torch": [
    "pt_tensor"
  ],
  "get_datatype_and_layout": [
    "tensor"
  ],
  "get_tensor_shape": [
    "tensor",
    "op"
  ],
  "_math_operation_value_map": [],
  "backend_math_operation": [
    "math_op"
  ],
  "construct_backend_td": [
    "td",
    "kernel_schedule",
    "epilogue_schedule",
    "tile_scheduler"
  ],
  "td_from_profiler_op": [
    "op"
  ],
  "td_from_profiler_td": [
    "td"
  ],
  "to_camel_case": [
    "snake_str"
  ],
  "getattr_enum": [
    "obj",
    "attr_name"
  ],
  "lazy_import": [
    "mod_name"
  ],
  "GpuTimer": {
    "__init__": [
      "self"
    ],
    "start": [
      "self",
      "stream"
    ],
    "stop": [
      "self",
      "stream"
    ],
    "stop_and_wait": [
      "self",
      "stream"
    ],
    "duration": [
      "self",
      "iterations"
    ]
  },
  "CUDAEventProfiler": {
    "__init__": [
      "self",
      "op",
      "warmup_iterations",
      "iterations"
    ],
    "__call__": [
      "self"
    ],
    "run_cutlass_profiler": [
      "self"
    ],
    "bytes": [
      "self",
      "problem_size",
      "batch_count",
      "beta"
    ],
    "flops": [
      "self",
      "problem_size",
      "batch_count",
      "beta"
    ]
  },
  "_AUTOGEN_STR": [],
  "_CSTYLE_AUTOGEN_COMMENT": [],
  "_PYSTYLE_AUTOGEN_COMMENT": [],
  "_CUTLASS_KERNEL_ARGS_2x": [],
  "_CUTLASS_KERNEL_ARGS_2x_STREAM_K": [],
  "_CUTLASS_KERNEL_RUN_GEMM_2x": [],
  "_CUTLASS_KERNEL_RUN_GEMM_3x": [],
  "_CUTLASS_KERNEL_RUN_GROUPED_GEMM_2x": [],
  "_CUTLASS_KERNEL_RUN_CONV2D_2x": [],
  "_PYTORCH_CUDA_TEMPLATE": [],
  "_PYTORCH_GEMM_CPP_TEMPLATE": [],
  "_PYTORCH_GROUPED_GEMM_CPP_TEMPLATE": [],
  "_PYTORCH_CONV2D_FPROP_CPP_TEMPLATE": [],
  "_PYTORCH_CONV2D_GRAD_CPP_TEMPLATE": [],
  "_PYTORCH_GEMM_INCLUDES": [],
  "_PYTORCH_GROUPED_GEMM_INCLUDES": [],
  "_PYTORCH_CONV2D_INCLUDES": [],
  "_CUTLASS_TYPE_TO_TORCH_TYPE": [],
  "_PYTORCH_GEMM_IMPL_TEMPLATE_2x": [],
  "_PYTORCH_GEMM_IMPL_TEMPLATE_3x": [],
  "_PYTORCH_GROUPED_GEMM_IMPL_TEMPLATE": [],
  "_PYTORCH_CONV2D_IMPL_TEMPLATE_2x": [],
  "_PYTORCH_CONV2D_FPROP_IMPL_TEMPLATE_2x": [],
  "_PYTORCH_CONV2D_DGRAD_IMPL_TEMPLATE_2x": [],
  "_PYTORCH_CONV2D_WGRAD_IMPL_TEMPLATE_2x": [],
  "_PYTORCH_SETUP_PY": [],
  "_generate_setup": [
    "name",
    "sourcedir",
    "extra_compile_args"
  ],
  "_ArchListSetter": {
    "_TORCH_CUDA_ARCH_LIST": [],
    "__init__": [
      "self",
      "cc"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "traceback"
    ]
  },
  "_jit": [
    "name",
    "cc",
    "cpp_file",
    "cuda_file"
  ],
  "_pytorch_gemm": [
    "op",
    "name",
    "cc",
    "jit",
    "sourcedir"
  ],
  "_pytorch_grouped_gemm": [
    "op",
    "name",
    "cc",
    "jit",
    "sourcedir"
  ],
  "_pytorch_conv2d": [
    "op",
    "name",
    "cc",
    "jit",
    "sourcedir"
  ],
  "pytorch": [
    "op",
    "name",
    "cc",
    "jit",
    "sourcedir"
  ],
  "GemmCoord_": {
    "_fields_": [],
    "__init__": [
      "self",
      "m",
      "n",
      "k"
    ]
  },
  "GemmCoordBatched_": {
    "_fields_": [],
    "__init__": [
      "self",
      "gemm_coord",
      "batch_count"
    ]
  },
  "MatrixCoord_": {
    "_fields_": []
  },
  "dim3_": {
    "_fields_": []
  },
  "StrideBatched_": {
    "_fields_": []
  },
  "GenericMainloopArguments3x_": {
    "_fields_": []
  },
  "_PersistentTileSchedulerArguments": {
    "_fields_": []
  },
  "_PersistentTileSchedulerStreamKArguments": {
    "_fields_": []
  },
  "get_tile_scheduler_arguments_3x": [
    "tile_scheduler",
    "splits"
  ],
  "get_mainloop_arguments_3x": [
    "kernel_schedule",
    "element_A",
    "element_B",
    "alignment_A",
    "alignment_B"
  ],
  "get_gemm_arguments_3x": [
    "mainloop_arguments",
    "epilogue_functor",
    "scheduler_args",
    "default_epilogue"
  ],
  "get_gemm_arguments": [
    "epilogue_functor"
  ],
  "get_gemm_arguments_streamk": [
    "epilogue_functor"
  ],
  "get_gemm_grouped_arguments": [
    "epilogue_functor"
  ],
  "Conv2DProblemSize_": {
    "_fields_": [],
    "__init__": [
      "self",
      "problem_size"
    ]
  },
  "Layout4D": {
    "_fields_": [],
    "__init__": [
      "self",
      "tensor_ref"
    ]
  },
  "TensorRef_": {
    "_fields_": [],
    "__init__": [
      "self",
      "tensor_ref"
    ]
  },
  "TensorRef2D_": {
    "_fields_": []
  },
  "get_conv2d_arguments": [
    "epilogue_functor"
  ],
  "get_reduction_params": [
    "epilogue_functor"
  ],
  "Empty": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "EmptyByte": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "EBO": {
    "__init__": [
      "self",
      "index",
      "type"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__hash__": [
      "self"
    ],
    "__ne__": [
      "self",
      "other"
    ],
    "__str__": [
      "self"
    ]
  },
  "tuple_factory_": [
    "input_tuple",
    "dtype",
    "constants"
  ],
  "tuple_factory": [
    "input_tuple",
    "dtype",
    "constants"
  ],
  "visitor_factory": [
    "node_types",
    "node_names"
  ],
  "ReductionOperation": {
    "__init__": [
      "self",
      "shape",
      "C",
      "element_accumulator",
      "element_workspace",
      "element_compute",
      "epilogue_functor",
      "count",
      "partitions_per_stage"
    ],
    "extended_name": [
      "self"
    ],
    "configuration_name": [
      "self"
    ],
    "procedural_name": [
      "self"
    ],
    "run": [
      "self",
      "arguments"
    ]
  },
  "ReductionArguments": {
    "__init__": [
      "self",
      "operation",
      "problem_size",
      "partitions",
      "workspace",
      "destination",
      "source"
    ],
    "get_tensor_ref": [
      "extent",
      "device_ptr",
      "layout"
    ],
    "get_arguments": [
      "self"
    ],
    "sync": [
      "self"
    ],
    "free": [
      "self"
    ]
  },
  "ReductionRT": {
    "KernelTemplate": [],
    "HostTemplate": [],
    "__init__": [
      "self",
      "operation"
    ],
    "emit": [
      "self"
    ],
    "plan": [
      "self",
      "arguments"
    ],
    "initialize": [
      "self"
    ]
  },
  "EmitReductionInstance": {
    "__init__": [
      "self",
      "operation_suffix"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "ArgumentBase": {
    "__init__": [
      "self",
      "A",
      "B",
      "C",
      "D"
    ],
    "tensor_to_ptr": [
      "self",
      "tensor",
      "name",
      "is_output"
    ],
    "sync": [
      "self",
      "stream_sync"
    ],
    "free": [
      "self"
    ]
  },
  "Conv2dArguments": {
    "__init__": [
      "self",
      "operation",
      "problem_size",
      "A",
      "B",
      "C",
      "D",
      "split_k_mode"
    ],
    "get_arguments": [
      "self"
    ],
    "initialize": [
      "self"
    ],
    "sync": [
      "self"
    ]
  },
  "Conv2dRT": {
    "KernelTemplate": [],
    "HostTemplate": [],
    "__init__": [
      "self",
      "operation"
    ],
    "emit": [
      "self"
    ],
    "plan": [
      "self",
      "arguments"
    ],
    "initialize": [
      "self"
    ]
  },
  "Conv2dOperation": {
    "__init__": [
      "self",
      "conv_kind",
      "iterator_algorithm",
      "arch",
      "tile_description",
      "A",
      "B",
      "C",
      "stride_support",
      "epilogue_functor",
      "swizzling_functor",
      "emission_type"
    ],
    "run": [
      "self",
      "arguments"
    ],
    "procedural_name": [
      "self"
    ],
    "configuration_name": [
      "self"
    ],
    "extended_name": [
      "self"
    ],
    "layout_name": [
      "self"
    ],
    "core_name": [
      "self"
    ],
    "is_complex": [
      "self"
    ],
    "accumulator_type": [
      "self"
    ],
    "device_op": [
      "self"
    ]
  },
  "EmitConv2dInstance": {
    "__init__": [
      "self",
      "operation_suffix"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "NumpyFrontend": {
    "argument": [
      "np_tensor",
      "is_output"
    ]
  },
  "TorchFrontend": {
    "argument": [
      "torch_tensor"
    ]
  },
  "CupyFrontend": {
    "argument": [
      "cupy_ndarray"
    ]
  },
  "TensorFrontend": {
    "argument": [
      "tensor",
      "is_output"
    ]
  },
  "_supports_cluster_launch": [],
  "supports_cluster_launch": [],
  "LaunchConfiguration": {
    "__init__": [
      "self",
      "grid",
      "block",
      "smem"
    ]
  },
  "ExecutableOperation": {
    "__init__": [
      "self",
      "operation"
    ],
    "name": [
      "self"
    ],
    "emit": [
      "self"
    ],
    "can_implement": [
      "self",
      "configuration",
      "arguments"
    ],
    "get_host_workspace_size": [
      "self",
      "arguments"
    ],
    "get_device_workspace_size": [
      "self",
      "arguments"
    ],
    "plan": [
      "self",
      "arguments"
    ],
    "initialize": [
      "self",
      "host_workspace",
      "device_workspace",
      "launch_config",
      "arguments",
      "stream"
    ],
    "run_with_clusters": [
      "self",
      "launch_config",
      "kernel_params",
      "stream"
    ],
    "run_without_clusters": [
      "self",
      "launch_config",
      "kernel_params",
      "stream"
    ],
    "run": [
      "self",
      "host_workspace",
      "device_workspace",
      "launch_config",
      "stream"
    ]
  },
  "PoolMemoryManager": {
    "__init__": [
      "self",
      "init_pool_size",
      "max_pool_size"
    ],
    "pool_size": [
      "self"
    ]
  },
  "DevicePtrWrapper": {
    "__init__": [
      "self",
      "dev_ptr"
    ],
    "ptr": [
      "self"
    ]
  },
  "_todevice": [
    "host_data"
  ],
  "todevice": [
    "host_data",
    "dtype"
  ],
  "device_mem_alloc": [
    "size"
  ],
  "align_size": [
    "size",
    "alignment"
  ],
  "create_memory_pool": [
    "init_pool_size",
    "max_pool_size"
  ],
  "compiler": [],
  "DataTypeSizeBytes": {
    "__class_getitem__": [
      "datatype"
    ]
  },
  "SchedulerMode": {
    "Device": [],
    "Host": []
  },
  "SchedulerModeTag": [],
  "ShortSchedulerModeNames": [],
  "FunctionalOp": {
    "AtomicAdd": [],
    "AtomicMaximum": [],
    "Divides": [],
    "Maximum": [],
    "Minimum": [],
    "Minus": [],
    "Multiplies": [],
    "MultiplyAdd": [],
    "Plus": [],
    "Exp": []
  },
  "FunctionalOpTag": [],
  "ActivationOp": {
    "DGelu": [],
    "Gelu": [],
    "GeluTaylor": [],
    "HardSwish": [],
    "Identity": [],
    "LeakyReLU": [],
    "ReLU": [],
    "Sigmoid": [],
    "SiLU": [],
    "Tanh": []
  },
  "ActivationOpTag": [],
  "op_tag": [
    "op"
  ],
  "FloatRoundStyle": {
    "ToNearest": [],
    "ToNearestSatfinite": [],
    "Indeterminate": [],
    "TowardZero": [],
    "TowardInfinity": [],
    "TowardNegInfinity": [],
    "HalfUlpTruncDntz": [],
    "HalfUlpTruncate": []
  },
  "FloatRoundStyleTag": [],
  "to_blackwell_threadblock_shape": [
    "tile_description",
    "cluster_shape",
    "kernel_schedule"
  ],
  "CalculateSmemUsagePerStage": [
    "operation"
  ],
  "ApiVersion": {
    "v2x": [],
    "v3x": []
  },
  "api_version": [
    "arch",
    "opclass",
    "dtype"
  ],
  "EmissionType": {
    "Kernel": [],
    "Device": []
  },
  "leading_dimension": [
    "layout",
    "shape"
  ],
  "transpose_layout": [
    "layout"
  ],
  "GemmArguments2x": {
    "__init__": [
      "self",
      "operation",
      "problem_size",
      "A",
      "B",
      "C",
      "D",
      "gemm_mode"
    ],
    "get_arguments": [
      "self"
    ],
    "initialize": [
      "self"
    ],
    "sync": [
      "self",
      "stream_sync"
    ]
  },
  "GemmArguments2xStreamK": {
    "__init__": [
      "self",
      "operation",
      "problem_size",
      "A",
      "B",
      "C",
      "D",
      "gemm_mode"
    ],
    "get_arguments": [
      "self"
    ],
    "initialize": [
      "self"
    ]
  },
  "GemmArguments3x": {
    "__init__": [
      "self",
      "operation",
      "problem_size",
      "A",
      "B",
      "C",
      "D",
      "gemm_mode"
    ],
    "get_arguments": [
      "self"
    ],
    "initialize": [
      "self"
    ]
  },
  "GemmArguments": [
    "operation",
    "problem_size",
    "A",
    "B",
    "C",
    "D",
    "gemm_mode"
  ],
  "GemmGroupedArguments": {
    "__init__": [
      "self",
      "operation",
      "problem_sizes",
      "A",
      "B",
      "C",
      "D"
    ],
    "get_arguments": [
      "self"
    ],
    "initialize": [
      "self"
    ],
    "sync": [
      "self"
    ]
  },
  "GemmRTbase": {
    "KernelTemplate": [],
    "__init__": [
      "self",
      "operation"
    ],
    "emit": [
      "self"
    ],
    "can_implement": [
      "self",
      "configuration",
      "arguments"
    ],
    "get_host_workspace_size": [
      "self",
      "arguments"
    ],
    "get_device_workspace_size": [
      "self",
      "arguments"
    ],
    "initialize": [
      "self"
    ]
  },
  "GemmRTUniversal": {
    "HostTemplate": [],
    "__init__": [
      "self",
      "operation"
    ],
    "plan": [
      "self",
      "arguments"
    ],
    "get_device_workspace_size": [
      "self",
      "arguments"
    ]
  },
  "GemmRTUniversalStreamK": {
    "HostTemplate": [],
    "__init__": [
      "self",
      "operation"
    ],
    "occupancy": [
      "self"
    ],
    "get_device_workspace_size": [
      "self",
      "arguments",
      "device_sms",
      "sm_occupancy"
    ]
  },
  "GemmRTUniversal3x": {
    "KernelTemplate": [],
    "HostTemplate": [],
    "__init__": [
      "self",
      "operation"
    ],
    "get_device_workspace_size": [
      "self",
      "arguments"
    ]
  },
  "EmitGemmUniversalInstance3x": {
    "__init__": [
      "self",
      "operation_suffix"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "GemmRTGrouped": {
    "KernelTemplate": [],
    "HostTemplate": [],
    "__init__": [
      "self",
      "operation"
    ],
    "host_precompute": [
      "self",
      "arguments",
      "workspace_bytes"
    ],
    "plan": [
      "self",
      "arguments"
    ],
    "get_workspace_size": [
      "self",
      "arguments"
    ]
  },
  "GemmOperationBase": {
    "__init__": [
      "self",
      "gemm_kind",
      "arch",
      "tile_description",
      "A",
      "B",
      "C",
      "epilogue_functor",
      "swizzling_functor",
      "api",
      "emission_type"
    ],
    "get_operands": [
      "A",
      "B",
      "C",
      "swap"
    ],
    "run": [
      "self",
      "arguments"
    ],
    "is_complex": [
      "self"
    ],
    "is_planar_complex": [
      "self"
    ],
    "accumulator_type": [
      "self"
    ],
    "short_math_name": [
      "self"
    ],
    "core_name": [
      "self"
    ],
    "extended_name": [
      "self"
    ],
    "extended_name_3x": [
      "self"
    ],
    "layout_name": [
      "self"
    ],
    "layout_name_3x": [
      "self"
    ],
    "kernel_schedule_name_3x": [
      "self"
    ],
    "epilogue_schedule_name_3x": [
      "self"
    ],
    "procedural_name": [
      "self"
    ],
    "configuration_name": [
      "self"
    ]
  },
  "GemmOperationUniversal": {
    "__init__": [
      "self",
      "arch",
      "tile_description",
      "A",
      "B",
      "C",
      "epilogue_functor",
      "swizzling_functor"
    ],
    "device_op": [
      "self"
    ]
  },
  "GemmOperationGrouped": {
    "__init__": [
      "self",
      "arch",
      "tile_description",
      "A",
      "B",
      "C",
      "epilogue_functor",
      "swizzling_functor"
    ],
    "device_op": [
      "self"
    ]
  },
  "EmitGemmUniversalInstance": {
    "__init__": [
      "self",
      "operation_suffix",
      "direct_store"
    ],
    "instance_template": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "EmitGemmGroupedInstance": {
    "__init__": [
      "self",
      "operation_suffix"
    ],
    "instance_template": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "nvrtc": [],
  "IncludeTemplate": [],
  "compile_with_nvcc": [
    "cmd",
    "source",
    "error_file"
  ],
  "CompilationOptions": {
    "__init__": [
      "self",
      "flags",
      "arch",
      "include_paths"
    ],
    "get_str": [
      "self"
    ],
    "get": [
      "self"
    ]
  },
  "convertToBinaryData": [
    "filename"
  ],
  "CDLLBin": [
    "host_binary"
  ],
  "ArtifactManager": {
    "__init__": [
      "self"
    ],
    "nvrtc": [
      "self"
    ],
    "nvcc": [
      "self"
    ],
    "insert_operation": [
      "self",
      "op_key",
      "cubin",
      "hostfile",
      "op_name",
      "op_attrs"
    ],
    "load_operation": [
      "self",
      "op_key",
      "extra_funcs"
    ],
    "emit_compile_": [
      "self",
      "operation_list",
      "compilation_options",
      "host_compilation_options"
    ],
    "add_module": [
      "self",
      "operations",
      "compile_options",
      "bypass_cache"
    ]
  },
  "GemmOperation": [],
  "Tensor": [],
  "dtype2ctype": [],
  "get_scalar": [
    "value"
  ],
  "to_ctype_value": [
    "value",
    "dtype"
  ],
  "EpilogueFunctorBase": {
    "__init__": [
      "self"
    ],
    "emit": [
      "self",
      "tag",
      "template_argument"
    ]
  },
  "LinearCombination": {
    "tag": [],
    "__init__": [
      "self",
      "element_output",
      "epilogue_vector_length",
      "element_accumulator",
      "element_epilogue"
    ],
    "emit": [
      "self"
    ]
  },
  "LinearCombinationClamp": {
    "tag": [],
    "__init__": [
      "self",
      "element_output",
      "epilogue_vector_length",
      "element_accumulator",
      "element_epilogue"
    ]
  },
  "FastLinearCombinationClamp": {
    "tag": [],
    "__init__": [
      "self",
      "element_output",
      "epilogue_vector_length"
    ],
    "emit": [
      "self"
    ]
  },
  "LinearCombinationGeneric": {
    "tag": [],
    "__init__": [
      "self",
      "activation_functor",
      "element_output",
      "epilogue_vector_length",
      "element_accumulator",
      "element_epilogue"
    ]
  },
  "ActivationFunctor": {
    "numpy": [
      "x"
    ],
    "emit": [
      "cls"
    ],
    "epilogue_output_op": [
      "element_epilogue"
    ]
  },
  "ActivationMeta": {
    "__call__": [
      "cls",
      "x"
    ],
    "numpy": [
      "cls"
    ],
    "torch": [
      "cls"
    ]
  },
  "identityMeta": {
    "numpy": [
      "cls",
      "x"
    ],
    "torch": [
      "cls",
      "x"
    ]
  },
  "reluMeta": {
    "numpy": [
      "cls",
      "x"
    ],
    "torch": [
      "cls",
      "x"
    ]
  },
  "leakyReLUMeta": {
    "numpy": [
      "cls",
      "x",
      "leaky_alpha"
    ],
    "torch": [
      "cls",
      "x",
      "leaky_alpha"
    ]
  },
  "tanhMeta": {
    "numpy": [
      "cls",
      "x"
    ],
    "torch": [
      "cls",
      "x"
    ]
  },
  "sigmoidMeta": {
    "numpy": [
      "cls",
      "x"
    ],
    "torch": [
      "cls",
      "x"
    ]
  },
  "siluMeta": {
    "numpy": [
      "cls",
      "x"
    ],
    "silu": [
      "cls",
      "x"
    ]
  },
  "hardswishMeta": {
    "numpy": [
      "cls",
      "x"
    ],
    "torch": [
      "cls",
      "x"
    ]
  },
  "geluMeta": {
    "numpy": [
      "cls",
      "x"
    ],
    "torch": [
      "cls",
      "x"
    ]
  },
  "check_cuda_errors": [
    "result"
  ],
  "device_cc": [
    "device"
  ],
  "device_sm_count": [
    "device"
  ],
  "to_device_ptr": [
    "tensor"
  ],
  "EpilogueFunctorVisitor": {
    "__init__": [
      "self",
      "cc",
      "visitor",
      "element_compute"
    ],
    "emit": [
      "self",
      "operation"
    ],
    "get_smem_size": [
      "self",
      "tile_description"
    ]
  },
  "PassNoOpElimination": {
    "dependencies": [],
    "call": [
      "self"
    ]
  },
  "PassGetArgumentType": {
    "dependencies": [],
    "requires": [
      "self"
    ],
    "call": [
      "self"
    ],
    "get_evt_argument_type": [
      "self",
      "node"
    ],
    "get_dag_argument_type": [
      "self",
      "node"
    ],
    "set_argument_type": [
      "self"
    ],
    "sm90_set_argument_type": [
      "self"
    ],
    "sm100_set_argument_type": [
      "self"
    ],
    "sm80_set_argument_type": [
      "self"
    ]
  },
  "EVTPassBase": {
    "dependencies": [],
    "__init__": [
      "self",
      "dag_ir"
    ],
    "requires": [
      "self"
    ],
    "call": [
      "self"
    ],
    "ensures": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "cc_specific_method": [
      "self",
      "func"
    ]
  },
  "EVTPassManager": {
    "__init__": [
      "self",
      "dag_ir",
      "pass_list"
    ],
    "get_callable": [
      "self",
      "pass_name"
    ],
    "add_pass": [
      "self",
      "pass_cls"
    ],
    "schedule": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "_COLOR_MAP": [],
  "EVTGraphDrawer": {
    "__init__": [
      "self",
      "graph",
      "name"
    ],
    "_get_node_style": [
      "self",
      "node"
    ],
    "_get_node_label": [
      "self",
      "node"
    ],
    "_to_dot": [
      "self",
      "graph",
      "name"
    ],
    "get_dot_graph": [
      "self"
    ],
    "get_dot_graph_by_name": [
      "self",
      "name"
    ],
    "get_main_dot_graph": [
      "self"
    ]
  },
  "PassPreprocessRed": {
    "call": [
      "self"
    ]
  },
  "GetSmemSize": {
    "__init__": [
      "self",
      "dag_ir"
    ],
    "sm90_epilogue_tile": [
      "self",
      "tile_description"
    ],
    "sm90_or_sm100_epilogue_smem_size": [
      "self",
      "tile_description"
    ],
    "sm90_epilogue_smem_size": [
      "self",
      "tile_description"
    ],
    "sm100_epilogue_tile": [
      "self",
      "tile_description"
    ],
    "sm100_epilogue_smem_size": [
      "self",
      "tile_description"
    ],
    "__call__": [
      "self",
      "tile_description"
    ],
    "get_visitor_size": [
      "members",
      "ebo"
    ],
    "get_struct_size": [
      "self",
      "members"
    ],
    "get_evt_smem_type": [
      "self",
      "node"
    ],
    "get_dag_smem_type": [
      "self",
      "node"
    ]
  },
  "cc_map": [],
  "PassLayoutManipulateElimination": {
    "dependencies": [],
    "__init__": [
      "self",
      "dag_ir"
    ],
    "call": [
      "self"
    ],
    "get_all_layout_nodes": [
      "self"
    ],
    "get_propagation_direction": [
      "self",
      "node"
    ],
    "get_influenced_users": [
      "self",
      "node"
    ],
    "get_influenced_inputs": [
      "self",
      "node"
    ],
    "add_copy_before": [
      "self",
      "layout_node_meta",
      "target"
    ],
    "add_copy_after": [
      "self",
      "layout_node_meta",
      "target"
    ],
    "propagate_to_users": [
      "self",
      "layout_node_meta",
      "node"
    ],
    "propagate_to_inputs": [
      "self",
      "layout_node_meta",
      "node"
    ]
  },
  "PassGetImpl": {
    "dependencies": [],
    "__init__": [
      "self",
      "dag_ir"
    ],
    "requires": [
      "self"
    ],
    "call": [
      "self"
    ],
    "ensures": [
      "self"
    ]
  },
  "PassDAG2Tree": {
    "dependencies": [],
    "call": [
      "self"
    ],
    "ensures": [
      "self"
    ]
  },
  "PassShapeTypePropagation": {
    "dependencies": [],
    "call": [
      "self"
    ]
  },
  "PassFixElementD": {
    "dependencies": [],
    "get_producer": [
      "self",
      "node",
      "element_D"
    ],
    "call": [
      "self"
    ]
  },
  "Sm80AccumulatorImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm80AuxLoadImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm80LoadSrcImpl": {},
  "Sm80ScalarBroadcastImpl": {
    "__init__": [
      "self",
      "node"
    ],
    "type_decl": [
      "self"
    ]
  },
  "Sm80RowBroadcastImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm80ColumnBroadcastImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm80ComputeImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm80AuxStoreImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm80StoreDImpl": {},
  "Sm80ColumnReductionImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm80RowReductionImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm80ScalarReductionImpl": {
    "type_decl": [
      "self"
    ]
  },
  "FusionCallbacks": {
    "__init__": [
      "self",
      "dag_ir",
      "cc",
      "emit_CD"
    ],
    "get_visitor_name": [
      "self",
      "node"
    ],
    "emit": [
      "self"
    ],
    "emit_evt": [
      "self",
      "node"
    ],
    "emit_dag": [
      "self",
      "node"
    ],
    "emit_node": [
      "self",
      "node"
    ]
  },
  "Sm80Emitter": {
    "__init__": [
      "self",
      "operation",
      "graph"
    ],
    "emit": [
      "self"
    ]
  },
  "Sm90AccumulatorImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm90LoadSrcImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm90AuxLoadImpl": {
    "descriptor": [
      "self"
    ],
    "decl_descriptor": [
      "self"
    ],
    "type_decl": [
      "self"
    ],
    "get_smem_size": [
      "self",
      "cta_tile_mnk",
      "epilogue_tile_mn",
      "stages_c",
      "stages_d",
      "epi_tiles"
    ]
  },
  "Sm90ScalarBroadcastImpl": {
    "__init__": [
      "self",
      "node"
    ],
    "type_decl": [
      "self"
    ]
  },
  "Sm90RowBroadcastImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm90ColumnBroadcastImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm90ComputeImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm90AuxStoreImpl": {
    "descriptor": [
      "self"
    ],
    "decl_descriptor": [
      "self"
    ],
    "type_decl": [
      "self"
    ],
    "get_smem_size": [
      "self",
      "cta_tile_mnk",
      "epilogue_tile_mn",
      "stages_c",
      "stages_d",
      "epi_tiles"
    ]
  },
  "Sm90StoreDImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm90ColumnReductionImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm90RowReductionImpl": {
    "type_decl": [
      "self"
    ]
  },
  "Sm90ScalarReductionImpl": {
    "type_decl": [
      "self"
    ]
  },
  "CollectiveEpilogue": {
    "__init__": [
      "self",
      "tile_description",
      "schedule",
      "element_c",
      "element_d",
      "fusion_callbacks"
    ],
    "CtaTileMNK": [
      "self"
    ],
    "EpilogueTileType": [
      "self"
    ],
    "Schedule": [
      "self"
    ],
    "emit": [
      "self"
    ]
  },
  "Sm90Emitter": {
    "__init__": [
      "self",
      "operation",
      "graph"
    ],
    "emit": [
      "self"
    ]
  },
  "Sm100CollectiveEpilogue": {
    "__init__": [
      "self",
      "tile_description",
      "kernel_schedule",
      "epilogue_schedule",
      "element_accumulator",
      "element_d",
      "fusion_callbacks"
    ],
    "CtaTileMNK": [
      "self"
    ],
    "EpilogueTileType": [
      "self"
    ],
    "Schedule": [
      "self"
    ],
    "emit": [
      "self"
    ]
  },
  "Sm100Emitter": {
    "__init__": [
      "self",
      "operation",
      "graph"
    ],
    "emit": [
      "self"
    ]
  },
  "Sm100AccumulatorImpl": [],
  "Sm100LoadSrcImpl": [],
  "Sm100ScalarBroadcastImpl": [],
  "Sm100RowBroadcastImpl": [],
  "Sm100ColumnBroadcastImpl": [],
  "Sm100ComputeImpl": [],
  "Sm100StoreDImpl": [],
  "Sm100ColumnReductionImpl": [],
  "Sm100RowReductionImpl": [],
  "Sm100ScalarReductionImpl": [],
  "Sm100AuxLoadImpl": {
    "descriptor": [
      "self"
    ],
    "decl_descriptor": [
      "self"
    ],
    "type_decl": [
      "self"
    ],
    "get_smem_size": [
      "self",
      "cta_tile_mnk",
      "epilogue_tile_mn",
      "stages_c",
      "stages_d",
      "epi_tiles"
    ]
  },
  "Sm100AuxStoreImpl": {
    "descriptor": [
      "self"
    ],
    "decl_descriptor": [
      "self"
    ],
    "type_decl": [
      "self"
    ],
    "get_smem_size": [
      "self",
      "cta_tile_mnk",
      "epilogue_tile_mn",
      "stages_c",
      "stages_d",
      "epi_tiles"
    ]
  },
  "StoreImplBase": {
    "reserved_names": [],
    "__init__": [
      "self",
      "node"
    ]
  },
  "StoreDImpl": {
    "argument_type_d": [
      "self"
    ],
    "match": [
      "node",
      "problem_size"
    ]
  },
  "AuxStoreImpl": {
    "__init__": [
      "self",
      "node"
    ],
    "argument_type": [
      "self"
    ],
    "match": [
      "node",
      "problem_size"
    ]
  },
  "ReductionImplBase": {
    "__init__": [
      "self",
      "node"
    ],
    "get_reduce_identity": [
      "self"
    ],
    "argument_type": [
      "self"
    ]
  },
  "ColumnReductionImpl": {
    "match": [
      "node",
      "problem_size"
    ]
  },
  "RowReductionImpl": {
    "match": [
      "node",
      "problem_size"
    ]
  },
  "ScalarReductionImpl": {
    "match": [
      "node",
      "problem_size"
    ]
  },
  "StoreNode": {
    "possible_impls": [],
    "__init__": [
      "self",
      "name"
    ],
    "store_tensor": [
      "self",
      "kwargs"
    ],
    "type_propagation": [
      "self",
      "input_node_metas"
    ],
    "broadcast_propagation": [
      "self",
      "input_node_metas"
    ]
  },
  "_infer_split": [
    "old_shape",
    "new_shape"
  ],
  "_infer_merge": [
    "flatten_shape",
    "shape"
  ],
  "_list_to_tuple": [
    "nested_list"
  ],
  "_tuple_to_list": [
    "nested_tuple"
  ],
  "_reverse_tuple": [
    "nested_tuple"
  ],
  "_get_first_lhs_nonzero_stride": [
    "stride_list",
    "idx"
  ],
  "_get_first_rhs_nonzero_stride": [
    "stride_list",
    "idx"
  ],
  "permutation": [
    "layout",
    "permutation"
  ],
  "_broadcast": [
    "layout",
    "new_shape"
  ],
  "broadcast": [
    "layout",
    "new_shape"
  ],
  "debroadcast": [
    "layout",
    "dims"
  ],
  "canonicalization_": [
    "shapes",
    "strides"
  ],
  "canonicalization": [
    "layout"
  ],
  "PermutationImpl": {
    "__init__": [
      "self",
      "node"
    ],
    "get_inverse_impl": [
      "self"
    ],
    "update": [
      "self",
      "shape"
    ],
    "get_inverse_indices": [
      "self",
      "indices"
    ],
    "shape_propagation": [
      "self",
      "input_node_meta"
    ],
    "broadcast": [
      "self",
      "shape",
      "node_meta"
    ],
    "apply_to_user": [
      "self",
      "usr_meta"
    ],
    "apply_to_input": [
      "self",
      "input_meta"
    ]
  },
  "ReshapeImpl": {
    "__init__": [
      "self",
      "node"
    ],
    "get_inverse_impl": [
      "self"
    ],
    "shape_propagation": [
      "self",
      "input_node_meta"
    ],
    "broadcast": [
      "self",
      "shape",
      "node_meta"
    ],
    "apply_to_user": [
      "self",
      "user_meta"
    ],
    "apply_to_input": [
      "self",
      "input_meta"
    ],
    "infer_split": [
      "self",
      "input_shape",
      "output_shape"
    ],
    "infer_merge": [
      "self",
      "flatten_shape",
      "shape"
    ]
  },
  "LayoutNode": {
    "fn_to_impl": [],
    "__init__": [
      "self",
      "name",
      "fn",
      "kwargs"
    ],
    "get_inverse_node": [
      "self"
    ],
    "shape_propagation": [
      "self",
      "input_node_metas"
    ],
    "type_propagation": [
      "self",
      "input_node_metas"
    ],
    "broadcast_propagation": [
      "self",
      "input_node_metas"
    ],
    "apply_to_user": [
      "self",
      "usr_meta"
    ],
    "apply_to_input": [
      "self",
      "input_meta"
    ]
  },
  "ComputeImplBase": {
    "__init__": [
      "self",
      "node"
    ]
  },
  "ComputeImpl": {
    "__init__": [
      "self",
      "node"
    ],
    "match": [
      "node",
      "problem_size"
    ]
  },
  "ComputeNode": {
    "possible_impls": [],
    "__init__": [
      "self",
      "name",
      "fn",
      "element_output",
      "element_compute",
      "round_style"
    ],
    "type_propagation": [
      "self"
    ]
  },
  "LoadImplBase": {
    "reserved_names": [],
    "__init__": [
      "self",
      "node"
    ]
  },
  "AccumulatorImpl": {
    "match": [
      "node",
      "problem_size"
    ]
  },
  "LoadSrcImpl": {
    "name_camel": [
      "self"
    ],
    "argument_type_c": [
      "self"
    ],
    "match": [
      "node",
      "problem_size"
    ]
  },
  "AuxLoadImpl": {
    "argument_type": [
      "self"
    ],
    "match": [
      "node",
      "problem_size"
    ]
  },
  "RowBroadcastImpl": {
    "__init__": [
      "self",
      "node"
    ],
    "argument_type": [
      "self"
    ],
    "match": [
      "node",
      "problem_size"
    ]
  },
  "ColumnBroadcastImpl": {
    "__init__": [
      "self",
      "node"
    ],
    "argument_type": [
      "self"
    ],
    "match": [
      "node",
      "problem_size"
    ]
  },
  "ScalarBroadcastImpl": {
    "__init__": [
      "self",
      "node"
    ],
    "argument_type": [
      "self"
    ],
    "match": [
      "node",
      "problem_size"
    ]
  },
  "LoadNode": {
    "cnt": [],
    "possible_impls": [],
    "__init__": [
      "self",
      "name"
    ],
    "type_propagation": [
      "self"
    ]
  },
  "TupleEmitter": {
    "__init__": [
      "self",
      "stride_dtype"
    ],
    "emit": [
      "self",
      "py_tuple"
    ]
  },
  "ImplBase": {
    "__init__": [
      "self",
      "node"
    ],
    "stride_dtype": [
      "self",
      "stride_dtype"
    ],
    "match": [
      "node",
      "problem_size"
    ],
    "argument_type": [
      "self"
    ],
    "name_camel": [
      "self"
    ],
    "stride_mnl": [
      "self"
    ],
    "get_non_constant_stride": [
      "self",
      "py_tuple"
    ],
    "get_stride_mnl": [
      "self"
    ],
    "get_smem_size": [
      "self"
    ]
  },
  "NoOpImpl": {
    "__init__": [
      "self",
      "node"
    ],
    "match": [
      "node",
      "problem_size"
    ]
  },
  "NodeBase": {
    "__init__": [
      "self",
      "name"
    ],
    "name_camel": [
      "self"
    ],
    "tensor": [
      "self",
      "kwargs"
    ],
    "shape_propagation": [
      "self",
      "input_node_metas"
    ],
    "type_propagation": [
      "self"
    ],
    "broadcast_propagation": [
      "self",
      "input_node_metas"
    ],
    "get_underlying_impl": [
      "self",
      "problem_size"
    ]
  },
  "TopoVisitorImpl": {
    "__init__": [
      "self",
      "node"
    ]
  },
  "TopoVisitorNode": {
    "__init__": [
      "self",
      "name",
      "subgraph",
      "output_node"
    ]
  },
  "DAGIR": {
    "__init__": [
      "self",
      "cc",
      "element_compute"
    ],
    "add_node": [
      "self",
      "meta"
    ],
    "add_edge": [
      "self",
      "src",
      "dst",
      "weight"
    ],
    "remove_node": [
      "self",
      "node"
    ],
    "remove_edge": [
      "self",
      "src",
      "dst"
    ],
    "has_node": [
      "self",
      "node"
    ],
    "in_degree": [
      "self",
      "node"
    ],
    "in_edges": [
      "self",
      "node"
    ],
    "out_degree": [
      "self",
      "node"
    ],
    "out_edges": [
      "self",
      "node"
    ],
    "get_node_meta": [
      "self",
      "node"
    ],
    "get_edge_weight": [
      "self",
      "src",
      "dst"
    ],
    "all_reachable_nodes": [
      "self",
      "node"
    ],
    "get_users": [
      "self",
      "node"
    ],
    "get_all_inputs": [
      "self",
      "node"
    ],
    "get_all_inputs_meta": [
      "self",
      "node"
    ],
    "replace_all_uses_with": [
      "self",
      "node1",
      "node2"
    ],
    "nodes_topological_order": [
      "self"
    ],
    "node_metas_topological_order": [
      "self"
    ],
    "nodes": [
      "self"
    ],
    "nodes_meta": [
      "self"
    ],
    "edges": [
      "self"
    ],
    "has_path": [
      "self",
      "src",
      "target"
    ]
  },
  "EVTFrontendBase": {
    "layout_fns": [],
    "__init__": [
      "self",
      "cc",
      "element_compute",
      "additional_passes"
    ],
    "epilogue_stages": [
      "self",
      "stages"
    ],
    "parse": [
      "self"
    ],
    "trace": [
      "self"
    ],
    "add_node": [
      "self",
      "node"
    ],
    "add_edge": [
      "self",
      "src",
      "tgt",
      "weight"
    ],
    "set_tensor": [
      "self",
      "node_name",
      "example"
    ],
    "set_store_tensor": [
      "self",
      "node_name",
      "example"
    ],
    "mark_output": [
      "self",
      "node_name"
    ],
    "add_load_node": [
      "self",
      "name",
      "example"
    ],
    "add_imm": [
      "self",
      "value"
    ],
    "add_compute_node": [
      "self",
      "op",
      "name"
    ],
    "add_layout_node": [
      "self",
      "op",
      "kwargs",
      "name"
    ],
    "add_store_node": [
      "self",
      "name"
    ],
    "visualize": [
      "self",
      "name"
    ],
    "get_smem_size": [
      "self",
      "tile_description"
    ]
  },
  "PythonASTFrontend": {
    "__init__": [
      "self",
      "cc",
      "element_compute"
    ],
    "parse": [
      "self",
      "example_inputs"
    ],
    "ast_op_to_bindings": [
      "op"
    ],
    "visit_FunctionDef": [
      "self",
      "node"
    ],
    "visit_arg": [
      "self",
      "node"
    ],
    "visit_Name": [
      "self",
      "node"
    ],
    "visit_Constant": [
      "self",
      "node"
    ],
    "visit_Tuple": [
      "self",
      "node"
    ],
    "visit_keyword": [
      "self",
      "node"
    ],
    "visit_BinOp": [
      "self",
      "node"
    ],
    "visit_Assign": [
      "self",
      "node"
    ],
    "visit_Call": [
      "self",
      "node"
    ],
    "visit_Return": [
      "self",
      "node"
    ]
  },
  "CudaToolkitVersionSatisfies": [
    "semantic_ver_string",
    "major",
    "minor",
    "patch"
  ],
  "get_wgmma_level_from_global_level": [
    "global_level"
  ],
  "get_mma_level_from_global_level": [
    "global_level"
  ],
  "get_cluster_level_from_global_level": [
    "global_level"
  ],
  "get_pruning_level_from_global_level": [
    "global_level"
  ],
  "generate_tf32_math_instruction_shapes_sm90": [
    "level"
  ],
  "generate_fp16_bf16_math_instruction_shapes_sm90": [
    "level"
  ],
  "generate_fp8_math_instruction_shapes_sm90": [
    "level"
  ],
  "generate_int8_math_instruction_shapes_sm90": [
    "level"
  ],
  "generate_mixed_dtype_math_instructions_shapes_sm90": [
    "wgmma_level",
    "a_type",
    "b_type"
  ],
  "generate_tf32_math_instructions_sm90": [
    "level"
  ],
  "generate_fp16_bf16_math_instructions_sm90": [
    "level"
  ],
  "generate_fp8_math_instructions_sm90": [
    "level"
  ],
  "generate_mixed_dtype_math_instructions_sm90": [
    "level",
    "types_of_a_b_acc"
  ],
  "generate_int8_math_instructions_sm90": [
    "level"
  ],
  "make_sparse_math_instructions": [
    "math_instructions"
  ],
  "is_tile_desc_valid": [
    "tile_description"
  ],
  "get_mma_multipliers": [
    "level"
  ],
  "get_cluster_sizes": [
    "level",
    "is_aligned"
  ],
  "generate_tile_descriptions_sm90": [
    "math_instructions",
    "is_aligned",
    "level"
  ],
  "is_tile_desc_compatible_with_cooperative": [
    "tile_description"
  ],
  "can_tile_desc_use_shmem_in_epilogue": [
    "tile_description",
    "data_types"
  ],
  "get_valid_schedules": [
    "tile_description",
    "cuda_version",
    "is_aligned",
    "data_types",
    "layout",
    "instantiation_level",
    "enable_fp8_fast_acc",
    "gemm_kind"
  ],
  "generate_data_types_from_math_instruction": [
    "math_instruction",
    "element_source",
    "element_dest",
    "element_epilogue"
  ],
  "fix_alignments": [
    "data_types",
    "layout",
    "alignment_bits"
  ],
  "TrmmOperation": {
    "__init__": [
      "self",
      "trmm_kind",
      "arch",
      "tile_description",
      "A",
      "B",
      "C",
      "element_epilogue",
      "epilogue_functor",
      "swizzling_functor"
    ],
    "is_complex": [
      "self"
    ],
    "is_planar_complex": [
      "self"
    ],
    "is_mixed_input": [
      "self"
    ],
    "accumulator_type": [
      "self"
    ],
    "short_math_name": [
      "self"
    ],
    "core_name": [
      "self"
    ],
    "extended_name": [
      "self"
    ],
    "layout_name": [
      "self"
    ],
    "side_mode_name": [
      "self"
    ],
    "fill_mode_name": [
      "self"
    ],
    "diag_type_name": [
      "self"
    ],
    "procedural_name": [
      "self"
    ],
    "configuration_name": [
      "self"
    ]
  },
  "EmitTrmmUniversalInstance": {
    "__init__": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "EmitTrmmConfigurationLibrary": {
    "__init__": [
      "self",
      "operation_path",
      "configuration_name"
    ],
    "__enter__": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ],
    "__exit__": [
      "self",
      "exception_type",
      "exception_value",
      "traceback"
    ]
  },
  "SM90_MMA_MULTIPLIERS": [],
  "SM90_CLUSTER_SIZES": [],
  "SM90_WGMMA_SHAPES_FP16_BF16_DENSE": [],
  "SM90_WGMMA_SHAPES_TF32_DENSE": [],
  "SM90_WGMMA_SHAPES_FP8_DENSE": [],
  "SM90_WGMMA_SHAPES_INT8_DENSE": [],
  "_LOGGER": [],
  "serialize_heuristics_results_to_json": [
    "problems_with_configs",
    "outfile_path"
  ],
  "get_single_gemm_config": [
    "m",
    "n",
    "k",
    "batch_count",
    "layouts",
    "dtypes",
    "alignment_a",
    "alignment_b",
    "voidC",
    "use_fast_acc",
    "count",
    "provider"
  ],
  "get_gemm_configs": [
    "problems",
    "provider",
    "count"
  ],
  "generate_sm100_from_heuristics_configs": [
    "manifest",
    "cuda_version",
    "kernel_configs"
  ],
  "generate_sm90_from_heuristics_configs": [
    "manifest",
    "cuda_version",
    "kernel_configs"
  ],
  "filter_manifest_and_write_heuristics_file": [
    "manifest",
    "args"
  ],
  "write_profiler_testlist_to_csv": [
    "configs_list",
    "outfile_path"
  ],
  "GenerateConv2dTensorOp": [
    "manifest",
    "tile_descriptions",
    "min_cc",
    "align"
  ],
  "EmitConv2dIncludes": {
    "__init__": [
      "self"
    ],
    "operation_is_3x": [
      "self",
      "operation"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "EmitConv2dConfigurationLibrary": {
    "__init__": [
      "self",
      "operation_path",
      "configuration_name"
    ],
    "operation_is_3x": [
      "self",
      "operation"
    ],
    "__enter__": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ],
    "__exit__": [
      "self",
      "exception_type",
      "exception_value",
      "traceback"
    ]
  },
  "RankKOperation": {
    "__init__": [
      "self",
      "rank_k_kind",
      "arch",
      "tile_description",
      "A",
      "C",
      "element_epilogue",
      "epilogue_functor",
      "swizzling_functor",
      "blas_mode"
    ],
    "is_complex": [
      "self"
    ],
    "is_mixed_input": [
      "self"
    ],
    "is_planar_complex": [
      "self"
    ],
    "accumulator_type": [
      "self"
    ],
    "short_math_name": [
      "self"
    ],
    "core_name": [
      "self"
    ],
    "extended_name": [
      "self"
    ],
    "layout_name": [
      "self"
    ],
    "fill_mode_name": [
      "self"
    ],
    "procedural_name": [
      "self"
    ],
    "configuration_name": [
      "self"
    ]
  },
  "EmitRankKUniversalInstance": {
    "__init__": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "EmitRankKConfigurationLibrary": {
    "__init__": [
      "self",
      "operation_path",
      "configuration_name"
    ],
    "__enter__": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ],
    "__exit__": [
      "self",
      "exception_type",
      "exception_value",
      "traceback"
    ]
  },
  "SymmOperation": {
    "__init__": [
      "self",
      "symm_kind",
      "arch",
      "tile_description",
      "A",
      "B",
      "C",
      "element_epilogue",
      "epilogue_functor",
      "swizzling_functor",
      "blas_mode"
    ],
    "is_complex": [
      "self"
    ],
    "is_mixed_input": [
      "self"
    ],
    "is_planar_complex": [
      "self"
    ],
    "accumulator_type": [
      "self"
    ],
    "short_math_name": [
      "self"
    ],
    "core_name": [
      "self"
    ],
    "extended_name": [
      "self"
    ],
    "layout_name": [
      "self"
    ],
    "side_mode_name": [
      "self"
    ],
    "fill_mode_name": [
      "self"
    ],
    "procedural_name": [
      "self"
    ],
    "configuration_name": [
      "self"
    ]
  },
  "EmitSymmUniversalInstance": {
    "__init__": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "EmitSymmConfigurationLibrary": {
    "__init__": [
      "self",
      "operation_path",
      "configuration_name"
    ],
    "__enter__": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ],
    "__exit__": [
      "self",
      "exception_type",
      "exception_value",
      "traceback"
    ]
  },
  "MatmulHeuristics": {
    "__init__": [
      "self",
      "gpu"
    ],
    "_layout_from_cutlass": [
      "self",
      "layouts"
    ],
    "_precision_from_cutlass_dtypes": [
      "self",
      "dtypes"
    ],
    "set_cta_div_n": [
      "self",
      "div_n"
    ],
    "set_cta_div_m": [
      "self",
      "div_m"
    ],
    "get_configs": [
      "self",
      "m",
      "n",
      "k",
      "batch_count",
      "dtypes",
      "layouts",
      "align_a",
      "align_b",
      "voidC",
      "use_fast_acc",
      "count"
    ]
  },
  "audit_csv_fields": [],
  "audit_csv_runtime_fields": [],
  "hash_cutlass_string": [
    "input_string"
  ],
  "transform_hashed_string": [
    "hashed_kernel_name",
    "runtime_datatype_a",
    "runtime_datatype_b"
  ],
  "get_kernel_features": [
    "operation",
    "kernel_name",
    "dynamic_datatype",
    "runtime_input_datatype"
  ],
  "get_kernel_params": [
    "operation",
    "kernel_name",
    "cluster_shape",
    "fallback_cluster_shape",
    "problem_shape",
    "alpha",
    "beta",
    "dynamic_datatype",
    "dynamic_cluster"
  ],
  "_getSubOperationType": [
    "kernel"
  ],
  "_get_inst_shape": [
    "math_instruction"
  ],
  "_is_simt_inst": [
    "math_instruction"
  ],
  "_getInstType": [
    "input_precision",
    "accumulate_precision",
    "math_instruction"
  ],
  "_computeFlopsPerByte": [
    "operation",
    "m",
    "n",
    "k",
    "batch_count",
    "beta",
    "num_groups"
  ],
  "emit_gemm_kernel_testlist": [
    "manifest",
    "curr_build_dir",
    "arch",
    "mode"
  ],
  "SM100_CLUSTER_SHAPES_1SM": [],
  "SM100_CLUSTER_SHAPES_2SM": [],
  "SM100_MMA_SHAPES_16b_DENSE_1SM": [],
  "SM100_MMA_SHAPES_16b_DENSE_2SM": [],
  "SM100_MMA_SHAPES_TF32_DENSE_1SM": [],
  "SM100_MMA_SHAPES_TF32_DENSE_2SM": [],
  "SM100_MMA_SHAPES_F8F6F4_DENSE_1SM": [],
  "SM100_MMA_SHAPES_F8F6F4_DENSE_2SM": [],
  "SM100_MMA_SHAPES_MXF8F6F4_DENSE_1SM": [],
  "SM100_MMA_SHAPES_MXF8F6F4_DENSE_2SM": [],
  "SM100_MMA_SHAPES_MXF4NVF4_DENSE_1SM": [],
  "SM100_MMA_SHAPES_MXF4NVF4_DENSE_2SM": [],
  "Conv3dOperation": {
    "__init__": [
      "self",
      "conv_kind",
      "iterator_algorithm",
      "arch",
      "tile_description",
      "A",
      "B",
      "C",
      "element_epilogue",
      "stride_support",
      "epilogue_functor",
      "swizzling_functor"
    ],
    "is_mixed_input": [
      "self"
    ],
    "core_name": [
      "self"
    ],
    "extended_name": [
      "self"
    ],
    "configuration_name": [
      "self"
    ],
    "procedural_name": [
      "self"
    ]
  },
  "EmitConv3dInstance": {
    "__init__": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "GenerateConv3dTensorOp": [
    "manifest",
    "tile_descriptions",
    "min_cc",
    "align"
  ],
  "EmitConv3dIncludes": {
    "__init__": [
      "self"
    ],
    "operation_is_3x": [
      "self",
      "operation"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "EmitConv3dConfigurationLibrary": {
    "__init__": [
      "self",
      "operation_path",
      "configuration_name"
    ],
    "operation_is_3x": [
      "self",
      "operation"
    ],
    "__enter__": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ],
    "__exit__": [
      "self",
      "exception_type",
      "exception_value",
      "traceback"
    ]
  },
  "install_source_path": [],
  "logging_prefix": [
    "indent_level"
  ],
  "log_debug_line": [
    "line",
    "indent_level"
  ],
  "_add_package_disablement_flag": [
    "argparser"
  ],
  "_parser": [],
  "ThorSMRenumbering": [
    "cuda_version"
  ],
  "EpilogueAlignment": [
    "max_alignment",
    "tile",
    "epilogue_steps"
  ],
  "DefaultSwizzlingFunctor": [],
  "CreateGemmOperator": [
    "manifest",
    "layouts",
    "tile_descriptions",
    "data_type",
    "alignment_constraints",
    "complex_transforms",
    "epilogue_functor",
    "swizzling_functor"
  ],
  "CreateGemmUniversal3xOperator": [
    "manifest",
    "layouts",
    "tile_descriptions",
    "data_types",
    "schedules",
    "complex_transforms",
    "epilogue_functor",
    "swizzling_functor",
    "tile_schedulers",
    "gemm_kind"
  ],
  "CreateSparseGemmUniversal3xOperator": [
    "manifest",
    "layouts",
    "tile_descriptions",
    "data_types",
    "schedules",
    "complex_transforms",
    "epilogue_functor",
    "swizzling_functor",
    "tile_schedulers"
  ],
  "CreateSparseGemmOperator": [
    "manifest",
    "layouts",
    "tile_descriptions",
    "data_type",
    "alignment_constraints",
    "complex_transforms",
    "epilogue_functor",
    "swizzling_functor"
  ],
  "CreateGemmPlanarComplexOperator": [
    "manifest",
    "layouts",
    "tile_descriptions",
    "data_type",
    "alignment_constraints",
    "complex_transforms"
  ],
  "CreateGemmGroupedOperator": [
    "manifest",
    "layouts",
    "tile_descriptions",
    "data_type",
    "alignment_constraints",
    "complex_transforms",
    "epilogue_functor",
    "swizzling_functor"
  ],
  "CreateRankKOperator": [
    "manifest",
    "layouts",
    "fill_modes",
    "tile_descriptions",
    "data_type",
    "alignment_constraints",
    "blas_mode",
    "epilogue_functor",
    "swizzling_functor"
  ],
  "CreateTrmmOperator": [
    "manifest",
    "layouts",
    "side_modes",
    "fill_modes",
    "diag_types",
    "tile_descriptions",
    "data_type",
    "alignment_constraints",
    "complex_transforms",
    "epilogue_functor",
    "swizzling_functor"
  ],
  "CreateSymmOperator": [
    "manifest",
    "layouts",
    "side_modes",
    "fill_modes",
    "tile_descriptions",
    "data_type",
    "alignment_constraints",
    "blas_mode",
    "epilogue_functor",
    "swizzling_functor"
  ],
  "CreateConv2dOperator": [
    "manifest",
    "layout",
    "tile_descriptions",
    "data_type",
    "alignment_constraints",
    "conv_kinds",
    "epilogue_functor",
    "swizzling_functor"
  ],
  "CreateConv2dFixedChannelsOperator": [
    "manifest",
    "layout",
    "tile_descriptions",
    "data_type",
    "channel_counts",
    "conv_kinds",
    "epilogue_functor",
    "swizzling_functor"
  ],
  "CreateConv2dFewChannelsOperator": [
    "manifest",
    "layout",
    "tile_descriptions",
    "data_type",
    "channel_counts",
    "conv_kinds",
    "epilogue_functor",
    "swizzling_functor"
  ],
  "CreateConv3dOperator": [
    "manifest",
    "layout",
    "tile_descriptions",
    "data_type",
    "alignment",
    "conv_kinds",
    "epilogue_functor"
  ],
  "CreateDepthwiseConv2dOperator": [
    "manifest",
    "layout",
    "tile_descriptions",
    "data_type",
    "alignment_constraints",
    "conv_kinds",
    "epilogue_functor",
    "swizzling_functor"
  ],
  "ConvOperation3x": {
    "__init__": [
      "self",
      "conv_kind",
      "tile_description",
      "A",
      "B",
      "C",
      "element_compute",
      "D",
      "kernel_schedule",
      "epilogue_schedule",
      "tile_scheduler",
      "log_indent_level"
    ],
    "__str__": [
      "self"
    ],
    "is_complex": [
      "self"
    ],
    "is_mixed_input": [
      "self"
    ],
    "accumulator_type": [
      "self"
    ],
    "short_math_name": [
      "self"
    ],
    "core_name": [
      "self"
    ],
    "extended_name": [
      "self"
    ],
    "kernel_schedule_name": [
      "self"
    ],
    "epilogue_schedule_name": [
      "self"
    ],
    "opcode_class_name": [
      "self"
    ],
    "configuration_name": [
      "self"
    ],
    "procedural_name": [
      "self"
    ]
  },
  "convolution_tensor_layout_type_to_operation_kind": [
    "layout"
  ],
  "CreateConvOperator3x": [
    "manifest",
    "dims_and_alignments",
    "tile_descriptions",
    "data_types",
    "schedule_pairs",
    "complex_transforms",
    "tile_schedulers",
    "conv_kind",
    "log_indent_level"
  ],
  "GenerateSM50_Simt": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM50_Simt_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM50": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM60_Simt": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM60_Simt_DepthwiseConv2d": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM60": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM61_Simt": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM61": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM70_TensorOp_884": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM70_PlanarComplexTensorOp_884": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM70_WmmaTensorOp_161616": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM70": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM75_TensorOp_1688_FewChannels": [
    "manifest",
    "cuda_version",
    "math_inst"
  ],
  "GenerateSM75_TensorOp_1688": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM75_PlanarComplexTensorOp_1688": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM75_TensorOp_8816_TN": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM75_TensorOp_8816_Interleaved": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM75_TensorOp_8832_TN": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM75_TensorOp_8832_Interleaved": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM75_TensorOp_88128": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM75_WmmaTensorOp_161616": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM75_Simt_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM75": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_16816": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_SparseTensorOp_16832": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_PlanarComplexTensorOp_16816": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_16816_mixed_input_upcast_a": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_16816_mixed_input_upcast_b": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_16832_TN": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_16832_TN_mixed_input_upcast_a": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_16832_TN_mixed_input_upcast_b": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_SparseTensorOp_16864_TN": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_16832_Interleaved": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_16864_TN": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_SparseTensorOp_168128_TN": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_16864_Interleaved": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_168256": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_1688": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_1688_fast_math": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_1688_fast_fp32_math": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_1688_fast_fp32_math_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_SparseTensorOp_16816_fast_math": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_1688_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_1688_rank_k": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_1688_rank_k_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_1688_trmm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_1688_trmm_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_1688_symm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_1688_symm_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_884": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_884_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_884_complex_gaussian": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_884_rank_k": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_884_rank_k_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_884_rank_k_complex_gaussian": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_884_trmm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_884_trmm_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_884_trmm_complex_gaussian": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_884_symm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_884_symm_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_TensorOp_884_symm_complex_gaussian": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_Simt_f32": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_Simt_f64": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80_Simt_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM80": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM89_TensorOp_16832_fp8": [
    "manifest",
    "element_acc"
  ],
  "GenerateSM89_TensorOp_16832_fp8_fp32acc": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM89_TensorOp_16832_fp8_fp16acc": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM89_SparseTensorOp_16864_fp8": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM89": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_16b_WGMMA_gemm": [
    "manifest",
    "cuda_version",
    "gemm_kind"
  ],
  "GenerateSM90_TensorOp_16b_WGMMA_alignx_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_SparseTensorOp_16b_WGMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_tf32_WGMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_tf32_WGMMA_alignx_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_SparseTensorOp_tf32_WGMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_int8_WGMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_int8_WGMMA_alignx_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_SparseTensorOp_int8_WGMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_fp8_WGMMA_gemm": [
    "manifest",
    "cuda_version",
    "gemm_kind"
  ],
  "GenerateSM90_TensorOp_fp8_WGMMA_gemm_with_blockwise": [
    "manifest",
    "cuda_version",
    "gemm_kind"
  ],
  "GenerateSM90_TensorOp_fp8_WGMMA_alignx_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_mixed_dtype_WGMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_SparseTensorOp_fp8_WGMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_1684": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_1684_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_1684_complex_gaussian": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_1684_rank_k": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_1684_rank_k_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_1684_rank_k_complex_gaussian": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_1684_trmm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_1684_trmm_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_1684_trmm_complex_gaussian": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_1684_symm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_1684_symm_complex": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_TensorOp_1684_symm_complex_gaussian": [
    "manifest",
    "cuda_version"
  ],
  "get_tma_alignment_elt": [
    "data_type",
    "is_f8f6f4"
  ],
  "sm100_cluster_shape_1sm": [],
  "sm100_cluster_shape_2sm": [],
  "GenerateSM100_TensorOp_32b_UMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM100_TensorOp_16b_UMMA_gemm": [
    "manifest",
    "cuda_version",
    "gemm_kind"
  ],
  "GenerateSM100_TensorOp_fp8_UMMA_gemm": [
    "manifest",
    "cuda_version",
    "gemm_kind"
  ],
  "GenerateSM100_TensorOp_fp8_UMMA_gemm_with_blockwise": [
    "manifest",
    "cuda_version",
    "gemm_kind"
  ],
  "GenerateSM100_TensorOp_mixed_8bits_UMMA_gemm": [
    "manifest",
    "cuda_version",
    "gemm_kind"
  ],
  "GenerateSM100_TensorOp_mixed_8bits_UMMA_gemm_with_block_scaled": [
    "manifest",
    "cuda_version",
    "gemm_kind"
  ],
  "GenerateSM100_TensorOp_fp4_UMMA_gemm_with_block_scaled": [
    "manifest",
    "cuda_version",
    "gemm_kind"
  ],
  "GenerateSM103_TensorOp_fp4_ultra_UMMA_gemm_with_block_scaled": [
    "manifest",
    "cuda_version",
    "gemm_kind"
  ],
  "GenerateSM100_TensorOp_int8_UMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM100_SparseTensorOp_32b_UMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM100_SparseTensorOp_16b_UMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM100_SparseTensorOp_int8_UMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM100_SparseTensorOp_fp8_UMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM100_SparseTensorOp_mixed_8bits_UMMA_gemm": [
    "manifest",
    "cuda_version"
  ],
  "make_dims_and_alignments_triple": [
    "dim",
    "bit_per_element_A",
    "bit_per_element_B",
    "bit_per_element_C"
  ],
  "make_math_instruction_w_output": [
    "data_types",
    "instruction_shape"
  ],
  "GenerateSM100_TensorOp_16b_UMMA_conv3x": [
    "manifest",
    "cuda_version",
    "log_indent_level"
  ],
  "GenerateSM100_TensorOp_fp8_UMMA_conv3x": [
    "manifest",
    "cuda_version",
    "log_indent_level"
  ],
  "GenerateSM120_TensorOp_mixed_8bits_UMMA_gemm_with_block_scaled": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM120_TensorOp_fp4_UMMA_gemm_with_block_scaled": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM120_Sparse_TensorOp_gemm": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM120_TensorOp_fp8_UMMA_gemm_with_blockwise": [
    "manifest",
    "cuda_version",
    "gemm_kind"
  ],
  "GenerateSM100": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM120": [
    "manifest",
    "cuda_version"
  ],
  "GenerateSM90_Conv3x": [
    "manifest",
    "cuda_version",
    "log_indent_level"
  ],
  "GenerateSM90": [
    "manifest",
    "cuda_version"
  ],
  "numeric_log_level": [
    "log_level"
  ],
  "define_parser": [],
  "GroupedGemmOperation": {
    "__init__": [
      "self",
      "gemm_kind",
      "arch",
      "tile_description",
      "A",
      "B",
      "C",
      "element_epilogue",
      "epilogue_functor",
      "swizzling_functor",
      "scheduler_mode"
    ],
    "procedural_name": [
      "self"
    ]
  },
  "EmitGemmInstance": {
    "__init__": [
      "self",
      "operation_suffix"
    ],
    "instance_template": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "EmitSparseGemmInstance": {
    "__init__": [
      "self",
      "operation_suffix"
    ],
    "instance_template": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "EmitGemmUniversal3xInstance": {
    "__init__": [
      "self",
      "operation_suffix"
    ],
    "instance_template": [
      "self"
    ],
    "emit_block_scale_epilogue_functor": [
      "self",
      "operation"
    ],
    "pointerize_if_grouped": [
      "operation",
      "layout"
    ],
    "transform_layout_A_if_blockwise": [
      "operation",
      "layout"
    ],
    "transform_layout_B_if_blockwise": [
      "operation",
      "layout"
    ],
    "problem_shape": [
      "operation"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "EmitGemmPlanarComplexInstance": {
    "__init__": [
      "self",
      "operation_suffix"
    ],
    "instance_template": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "EmitGemmPlanarComplexArrayInstance": {
    "__init__": [
      "self",
      "operation_suffix"
    ],
    "instance_template": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "EmitGemmConfigurationLibrary": {
    "__init__": [
      "self",
      "operation_path",
      "configuration_name"
    ],
    "__enter__": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ],
    "__exit__": [
      "self",
      "exception_type",
      "exception_value",
      "traceback"
    ]
  },
  "EmitOperationKindAll": {
    "__init__": [
      "self",
      "generated_path",
      "kind",
      "args"
    ],
    "__enter__": [
      "self"
    ],
    "emit": [
      "self",
      "operations"
    ],
    "__exit__": [
      "self",
      "exception_type",
      "exception_value",
      "traceback"
    ]
  },
  "EmitOperationKindLibrary": {
    "__init__": [
      "self",
      "generated_path",
      "min_cc",
      "kind",
      "args"
    ],
    "__enter__": [
      "self"
    ],
    "emit": [
      "self",
      "configuration_name",
      "operations"
    ],
    "__exit__": [
      "self",
      "exception_type",
      "exception_value",
      "traceback"
    ]
  },
  "EmitInterfaceLibrary": {
    "__init__": [
      "self",
      "generated_path",
      "operation_count",
      "args"
    ],
    "__enter__": [
      "self"
    ],
    "emit": [
      "self",
      "operation_name"
    ],
    "__exit__": [
      "self",
      "exception_type",
      "exception_value",
      "traceback"
    ]
  },
  "Options": {
    "__init__": [
      "self"
    ]
  },
  "Manifest": {
    "__init__": [
      "self",
      "args"
    ],
    "add_kernel_filter": [
      "self",
      "filter_str"
    ],
    "get_instantiation_level": [
      "self",
      "pruned_level",
      "default_level",
      "exhaustive_level"
    ],
    "get_kernel_filters": [
      "self",
      "kernelListFile"
    ],
    "filter_out_kernels": [
      "self",
      "kernel_name",
      "kernel_filter_list"
    ],
    "_filter_string_matches": [
      "self",
      "filter_string",
      "haystack"
    ],
    "filter": [
      "self",
      "operation"
    ],
    "append": [
      "self",
      "operation"
    ],
    "emit_manifest_cmake": [
      "self",
      "manifest_path",
      "top_level_path",
      "source_files"
    ],
    "emit_disable_full_archs_compilation": [
      "manifest_file",
      "source_files"
    ],
    "emit": [
      "self",
      "target"
    ]
  },
  "EmitConv3xInstance": {
    "__init__": [
      "self"
    ],
    "arch_number_to_type": [
      "self",
      "arch"
    ],
    "mma_tile_shape": [
      "self",
      "operation",
      "cta_m",
      "cta_n",
      "cta_k"
    ],
    "cluster_shape": [
      "self",
      "operation"
    ],
    "stage_count": [
      "self",
      "operation"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "EmitConv3xIncludes": {
    "__init__": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "get_tcgen05_level_from_global_level": [
    "global_level"
  ],
  "generate_tf32_math_instructions_sm100": [
    "level"
  ],
  "generate_16b_math_instructions_sm100": [
    "level"
  ],
  "generate_fp8_math_instructions_sm100": [
    "level",
    "enable_runtime_dtype",
    "enable_compile_time_dtype"
  ],
  "generate_f8f6f4_math_instructions_sm100": [
    "level",
    "enable_runtime_dtype",
    "enable_compile_time_dtype"
  ],
  "generate_mxf8f6f4_math_instructions_sm100": [
    "level",
    "enable_runtime_dtype",
    "enable_compile_time_dtype"
  ],
  "generate_mxf4nvf4_math_instructions_sm100": [
    "level",
    "enable_runtime_dtype",
    "enable_compile_time_dtype"
  ],
  "generate_cluster_shapes_sm100": [
    "level",
    "change_priority_func"
  ],
  "Rank2KOperation": {
    "__init__": [
      "self",
      "rank_k_kind",
      "arch",
      "tile_description",
      "A",
      "C",
      "element_epilogue",
      "epilogue_functor",
      "swizzling_functor",
      "blas_mode"
    ],
    "is_complex": [
      "self"
    ],
    "is_mixed_input": [
      "self"
    ],
    "is_planar_complex": [
      "self"
    ],
    "accumulator_type": [
      "self"
    ],
    "short_math_name": [
      "self"
    ],
    "core_name": [
      "self"
    ],
    "extended_name": [
      "self"
    ],
    "layout_name": [
      "self"
    ],
    "fill_mode_name": [
      "self"
    ],
    "procedural_name": [
      "self"
    ],
    "configuration_name": [
      "self"
    ]
  },
  "EmitRank2KUniversalInstance": {
    "__init__": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ]
  },
  "EmitRank2KConfigurationLibrary": {
    "__init__": [
      "self",
      "operation_path",
      "configuration_name"
    ],
    "__enter__": [
      "self"
    ],
    "emit": [
      "self",
      "operation"
    ],
    "__exit__": [
      "self",
      "exception_type",
      "exception_value",
      "traceback"
    ]
  },
  "dtype": [
    "ty"
  ],
  "as_tensor": [
    "pointer",
    "shape",
    "torch_type"
  ],
  "ScalarInitConfig": {},
  "RandomInitConfig": {},
  "GaussianInitConfig": {},
  "TensorInitType": {
    "SKIP": [],
    "SCALAR": [],
    "RANDOM": [],
    "GAUSSIAN": []
  },
  "create_and_permute_torch_tensor": [
    "shape",
    "dtype",
    "permute_order",
    "init_type",
    "init_config",
    "device"
  ],
  "convert_cute_tensor": [
    "f32_torch_tensor",
    "cute_tensor",
    "dtype",
    "is_dynamic_layout"
  ],
  "default_stream": [],
  "current_stream": [],
  "matrix": [
    "l",
    "mode0",
    "mode1",
    "is_mode0_major",
    "cutlass_dtype",
    "init_type",
    "init_config",
    "device"
  ],
  "cute_tensor_like": [
    "data_ref",
    "cutlass_dtype",
    "is_dynamic_layout",
    "assumed_align"
  ],
  "check_value_in": [
    "value",
    "possible_values",
    "value_description",
    "prefix"
  ],
  "check_type_in": [
    "ty",
    "possible_types",
    "type_description",
    "prefix"
  ],
  "LaunchConfig": [],
  "register_jit_arg_adapter": [],
  "gpu": [],
  "_math_op": [
    "func",
    "fastmath"
  ],
  "acos": [
    "a",
    "fastmath"
  ],
  "asin": [
    "a",
    "fastmath"
  ],
  "atan": [
    "a",
    "fastmath"
  ],
  "atan2": [
    "a",
    "b",
    "fastmath"
  ],
  "cos": [
    "a",
    "fastmath"
  ],
  "erf": [
    "a",
    "fastmath"
  ],
  "exp2": [
    "a",
    "fastmath"
  ],
  "log": [
    "a",
    "fastmath"
  ],
  "log2": [
    "a",
    "fastmath"
  ],
  "log10": [
    "a",
    "fastmath"
  ],
  "rsqrt": [
    "a",
    "fastmath"
  ],
  "sin": [
    "a",
    "fastmath"
  ],
  "sqrt": [
    "a",
    "fastmath"
  ],
  "tan": [
    "a",
    "fastmath"
  ],
  "_get_typed_value": [
    "x"
  ],
  "_pack_x": [
    "x",
    "packer",
    "op"
  ],
  "_pack_shape": [
    "shape"
  ],
  "_pack_stride": [
    "stride"
  ],
  "_pack_coord": [
    "coord"
  ],
  "_pack_int_tuple": [
    "int_tuple"
  ],
  "_pack_tile": [
    "tile"
  ],
  "_unpack_x_tuple": [
    "t"
  ],
  "_check_coord": [
    "coord"
  ],
  "_check_stride": [
    "stride"
  ],
  "_check_int_tuple": [
    "int_tuple"
  ],
  "_check_tile": [
    "tile"
  ],
  "IntValue": {
    "__init__": [
      "self",
      "v",
      "signed"
    ],
    "get_typed_value": [
      "self"
    ],
    "divisibility": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "pretty_str": [
      "self"
    ],
    "_binary_op": [
      "op"
    ],
    "__add__": [
      "self",
      "other"
    ],
    "__sub__": [
      "self",
      "other"
    ],
    "__mul__": [
      "self",
      "other"
    ],
    "__floordiv__": [
      "self",
      "other"
    ],
    "__mod__": [
      "self",
      "other"
    ],
    "__radd__": [
      "self",
      "other"
    ],
    "__rsub__": [
      "self",
      "other"
    ],
    "__rmul__": [
      "self",
      "other"
    ],
    "__rfloordiv__": [
      "self",
      "other"
    ],
    "__rmod__": [
      "self",
      "other"
    ]
  },
  "Ratio": {
    "__init__": [
      "self",
      "numerator",
      "denominator"
    ],
    "is_integral": [
      "self"
    ],
    "reduced": [
      "self"
    ],
    "__mul__": [
      "self",
      "other"
    ],
    "__rmul__": [
      "self",
      "other"
    ],
    "__str__": [
      "self"
    ],
    "to": [
      "self",
      "dtype"
    ]
  },
  "ScaledBasis": {
    "__init__": [
      "self",
      "value",
      "mode"
    ],
    "is_static": [
      "self"
    ],
    "to": [
      "self",
      "dtype"
    ],
    "__str__": [
      "self"
    ],
    "__hash__": [
      "self"
    ],
    "value": [
      "self"
    ],
    "mode": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__rmul__": [
      "self",
      "scale"
    ]
  },
  "E": [
    "mode"
  ],
  "get_divisibility": [
    "x"
  ],
  "Swizzle": {
    "__str__": [
      "self"
    ]
  },
  "_Layout": {
    "__init__": [
      "self",
      "op_result"
    ],
    "__str__": [
      "self"
    ],
    "shape": [
      "self"
    ],
    "stride": [
      "self"
    ],
    "max_alignment": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__req__": [
      "self",
      "other"
    ],
    "__ne__": [
      "self",
      "other"
    ],
    "__rne__": [
      "self",
      "other"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__call__": [
      "self",
      "coord",
      "loc",
      "ip"
    ],
    "get_hier_coord": [
      "self",
      "idx"
    ],
    "get_flat_coord": [
      "self",
      "idx"
    ]
  },
  "ComposedLayout": {
    "__init__": [
      "self",
      "value"
    ],
    "__str__": [
      "self"
    ],
    "inner": [
      "self"
    ],
    "offset": [
      "self"
    ],
    "outer": [
      "self"
    ],
    "shape": [
      "self"
    ],
    "max_alignment": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__req__": [
      "self",
      "other"
    ],
    "__ne__": [
      "self",
      "other"
    ],
    "__rne__": [
      "self",
      "other"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__call__": [
      "self",
      "coord",
      "loc",
      "ip"
    ]
  },
  "_Tensor": {
    "__init__": [
      "self",
      "value",
      "dtype"
    ],
    "__str__": [
      "self"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "__class__": [
      "self"
    ],
    "type": [
      "self"
    ],
    "__getitem__": [
      "self",
      "crd"
    ],
    "_cvt_to_dest": [
      "self",
      "data"
    ],
    "__setitem__": [
      "self",
      "crd",
      "data"
    ],
    "iterator": [
      "self"
    ],
    "layout": [
      "self"
    ],
    "shape": [
      "self"
    ],
    "stride": [
      "self"
    ],
    "leading_dim": [
      "self"
    ],
    "element_type": [
      "self"
    ],
    "memspace": [
      "self"
    ],
    "load": [
      "self"
    ],
    "store": [
      "self",
      "data"
    ],
    "fill": [
      "self",
      "value"
    ],
    "_check_can_load_store": [
      "self"
    ],
    "_check_can_dereference": [
      "self"
    ]
  },
  "print_tensor": [
    "tensor"
  ],
  "is_integer": [
    "a"
  ],
  "is_valid_leaf": [
    "a"
  ],
  "is_int_tuple": [
    "a"
  ],
  "is_static": [
    "x"
  ],
  "has_underscore": [
    "a"
  ],
  "has_scaled_basis": [
    "a"
  ],
  "_tuple_str": [
    "t"
  ],
  "pretty_str": [
    "arg"
  ],
  "printf": [],
  "front": [
    "input"
  ],
  "is_major": [
    "mode",
    "stride"
  ],
  "leading_dim": [
    "shape",
    "stride"
  ],
  "find_if": [
    "t",
    "pred_fn"
  ],
  "find": [
    "t",
    "x"
  ],
  "transform_leaf": [
    "f"
  ],
  "assume": [
    "src",
    "divby"
  ],
  "make_swizzle": [
    "b",
    "m",
    "s"
  ],
  "depth": [
    "a"
  ],
  "rank": [
    "a"
  ],
  "is_congruent": [
    "a",
    "b"
  ],
  "is_weakly_congruent": [
    "a",
    "b"
  ],
  "get": [
    "input",
    "mode"
  ],
  "select": [
    "input",
    "mode"
  ],
  "group_modes": [
    "input",
    "begin",
    "end"
  ],
  "slice_": [
    "src",
    "coord"
  ],
  "dice": [
    "src",
    "dicer"
  ],
  "wrap": [
    "x"
  ],
  "_extend": [
    "func",
    "input",
    "elem",
    "up_to_rank",
    "loc",
    "ip"
  ],
  "prepend": [
    "input",
    "elem",
    "up_to_rank"
  ],
  "append": [
    "input",
    "elem",
    "up_to_rank"
  ],
  "prepend_ones": [
    "t",
    "up_to_rank"
  ],
  "append_ones": [
    "t",
    "up_to_rank"
  ],
  "repeat_like": [
    "x",
    "target"
  ],
  "flatten_to_tuple": [
    "a"
  ],
  "flatten": [
    "a"
  ],
  "unflatten": [
    "sequence",
    "profile"
  ],
  "elem_less": [
    "lhs",
    "rhs"
  ],
  "filter_zeros": [
    "input"
  ],
  "filter": [
    "input"
  ],
  "product": [
    "a"
  ],
  "product_like": [
    "a",
    "target_profile"
  ],
  "product_each": [
    "a"
  ],
  "size": [
    "a",
    "mode"
  ],
  "shape_div": [
    "lhs",
    "rhs"
  ],
  "make_layout": [
    "shape"
  ],
  "make_identity_layout": [
    "shape"
  ],
  "make_ordered_layout": [
    "shape",
    "order"
  ],
  "make_composed_layout": [
    "inner",
    "offset",
    "outer"
  ],
  "cosize": [
    "a",
    "mode"
  ],
  "size_in_bytes": [
    "dtype",
    "layout"
  ],
  "coalesce": [
    "input"
  ],
  "crd2idx": [
    "coord",
    "layout"
  ],
  "recast_layout": [
    "new_type_bits",
    "old_type_bits",
    "src_layout"
  ],
  "slice_and_offset": [
    "coord",
    "src"
  ],
  "shape": [
    "input"
  ],
  "recast_ptr": [
    "ptr",
    "swizzle_",
    "dtype",
    "loc",
    "ip"
  ],
  "make_tensor": [
    "iterator",
    "layout"
  ],
  "make_identity_tensor": [
    "shape"
  ],
  "make_fragment": [
    "layout_or_shape",
    "dtype"
  ],
  "make_fragment_like": [
    "src",
    "dtype"
  ],
  "recast_tensor": [
    "src",
    "dtype",
    "swizzle_"
  ],
  "domain_offset": [
    "coord",
    "tensor"
  ],
  "composition": [
    "lhs",
    "rhs"
  ],
  "complement": [
    "input",
    "cotarget"
  ],
  "right_inverse": [
    "input"
  ],
  "left_inverse": [
    "input"
  ],
  "logical_product": [
    "block",
    "tiler"
  ],
  "zipped_product": [
    "block",
    "tiler"
  ],
  "tiled_product": [
    "block",
    "tiler"
  ],
  "flat_product": [
    "block",
    "tiler"
  ],
  "raked_product": [
    "block",
    "tiler"
  ],
  "blocked_product": [
    "block",
    "tiler"
  ],
  "logical_divide": [
    "target",
    "tiler"
  ],
  "zipped_divide": [
    "target",
    "tiler"
  ],
  "tiled_divide": [
    "target",
    "tiler"
  ],
  "flat_divide": [
    "target",
    "tiler"
  ],
  "max_common_layout": [
    "a",
    "b"
  ],
  "max_common_vector": [
    "a",
    "b"
  ],
  "tile_to_shape": [
    "atom",
    "trg_shape",
    "order"
  ],
  "local_partition": [
    "target",
    "tiler",
    "index",
    "proj"
  ],
  "local_tile": [
    "input",
    "tiler",
    "coord",
    "proj"
  ],
  "make_layout_image_mask": [
    "lay",
    "coord",
    "mode"
  ],
  "Op": {},
  "MmaOp": {
    "_make_trait": [
      "self"
    ]
  },
  "CopyOp": {
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "Trait": {
    "__init__": [
      "self",
      "value"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "set": [
      "self",
      "field",
      "value"
    ],
    "unpack": [
      "self"
    ]
  },
  "Atom": {
    "__init__": [
      "self",
      "op",
      "trait"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "op": [
      "self"
    ],
    "type": [
      "self"
    ],
    "set": [
      "self",
      "modifier",
      "value"
    ],
    "_unpack": [
      "self"
    ]
  },
  "MmaAtom": {
    "__str__": [
      "self"
    ],
    "thr_id": [
      "self"
    ],
    "shape_mnk": [
      "self"
    ],
    "tv_layout_A": [
      "self"
    ],
    "tv_layout_B": [
      "self"
    ],
    "tv_layout_C": [
      "self"
    ],
    "make_fragment_A": [
      "self",
      "input"
    ],
    "make_fragment_B": [
      "self",
      "input"
    ],
    "make_fragment_C": [
      "self",
      "input"
    ]
  },
  "TiledMma": {
    "__str__": [
      "self"
    ],
    "tv_layout_A_tiled": [
      "self"
    ],
    "tv_layout_B_tiled": [
      "self"
    ],
    "tv_layout_C_tiled": [
      "self"
    ],
    "permutation_mnk": [
      "self"
    ],
    "thr_layout_vmnk": [
      "self"
    ],
    "size": [
      "self"
    ],
    "get_tile_size": [
      "self",
      "mode_idx"
    ],
    "get_slice": [
      "self",
      "thr_idx"
    ],
    "_partition_shape": [
      "self",
      "operand_id",
      "shape"
    ],
    "partition_shape_A": [
      "self",
      "shape_mk"
    ],
    "partition_shape_B": [
      "self",
      "shape_nk"
    ],
    "partition_shape_C": [
      "self",
      "shape_mn"
    ],
    "_thrfrg": [
      "self",
      "operand_id",
      "input"
    ],
    "_thrfrg_A": [
      "self",
      "input"
    ],
    "_thrfrg_B": [
      "self",
      "input"
    ],
    "_thrfrg_C": [
      "self",
      "input"
    ]
  },
  "ThrMma": {
    "__init__": [
      "self",
      "op",
      "trait",
      "thr_idx"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "thr_idx": [
      "self"
    ],
    "partition_A": [
      "self",
      "input_mk"
    ],
    "partition_B": [
      "self",
      "input_nk"
    ],
    "partition_C": [
      "self",
      "input_mn"
    ]
  },
  "make_mma_atom": [
    "op"
  ],
  "make_tiled_mma": [
    "op_or_atom",
    "atom_layout_mnk",
    "permutation_mnk"
  ],
  "CopyAtom": {
    "__str__": [
      "self"
    ],
    "value_type": [
      "self"
    ],
    "thr_id": [
      "self"
    ],
    "layout_src_tv": [
      "self"
    ],
    "layout_dst_tv": [
      "self"
    ]
  },
  "TiledCopy": {
    "__str__": [
      "self"
    ],
    "layout_tv_tiled": [
      "self"
    ],
    "tiler_mn": [
      "self"
    ],
    "layout_src_tv_tiled": [
      "self"
    ],
    "layout_dst_tv_tiled": [
      "self"
    ],
    "size": [
      "self"
    ],
    "get_slice": [
      "self",
      "thr_idx"
    ],
    "retile": [
      "self",
      "src"
    ]
  },
  "ThrCopy": {
    "__init__": [
      "self",
      "op",
      "trait",
      "thr_idx"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "thr_idx": [
      "self"
    ],
    "partition_S": [
      "self",
      "src"
    ],
    "partition_D": [
      "self",
      "dst"
    ]
  },
  "make_copy_atom": [
    "op",
    "copy_internal_type"
  ],
  "make_layout_tv": [
    "thr_layout",
    "val_layout"
  ],
  "_make_tiled_copy": [
    "atom",
    "layout_tv",
    "tiler_mn"
  ],
  "make_tiled_copy": [
    "atom",
    "layout_tv",
    "tiler_mn"
  ],
  "make_tiled_copy_tv": [
    "atom",
    "thr_layout",
    "val_layout"
  ],
  "make_tiled_copy_A": [
    "atom",
    "tiled_mma"
  ],
  "make_tiled_copy_B": [
    "atom",
    "tiled_mma"
  ],
  "make_tiled_copy_C": [
    "atom",
    "tiled_mma"
  ],
  "make_tiled_copy_S": [
    "atom",
    "tiled_copy"
  ],
  "make_tiled_copy_D": [
    "atom",
    "tiled_copy"
  ],
  "make_tiled_copy_C_atom": [
    "atom",
    "mma"
  ],
  "basic_copy": [
    "src",
    "dst"
  ],
  "basic_copy_if": [
    "pred",
    "src",
    "dst"
  ],
  "_basic_copy_if_static": [
    "pred",
    "src",
    "dst"
  ],
  "autovec_copy": [
    "src",
    "dst"
  ],
  "copy": [
    "atom",
    "src",
    "dst"
  ],
  "copy_atom_call": [
    "atom",
    "src",
    "dst"
  ],
  "prefetch": [
    "atom",
    "src"
  ],
  "ReductionOp": {
    "ADD": [],
    "MUL": [],
    "MAX": [],
    "MIN": [],
    "INC": [],
    "DEC": [],
    "AND": [],
    "OR": [],
    "XOR": [],
    "__str__": [
      "self"
    ]
  },
  "TensorSSA": {
    "__init__": [
      "self",
      "value",
      "shape",
      "dtype"
    ],
    "dtype": [
      "self"
    ],
    "element_type": [
      "self"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "__str__": [
      "self"
    ],
    "shape": [
      "self"
    ],
    "_apply_op": [
      "self",
      "op",
      "other",
      "flip"
    ],
    "broadcast_to": [
      "self",
      "target_shape"
    ],
    "__pow__": [
      "self",
      "other"
    ],
    "__rpow__": [
      "self",
      "other"
    ],
    "__add__": [
      "self",
      "other"
    ],
    "__radd__": [
      "self",
      "other"
    ],
    "__sub__": [
      "self",
      "other"
    ],
    "__rsub__": [
      "self",
      "other"
    ],
    "__mul__": [
      "self",
      "other"
    ],
    "__rmul__": [
      "self",
      "other"
    ],
    "__mod__": [
      "self",
      "other"
    ],
    "__rmod__": [
      "self",
      "other"
    ],
    "__floordiv__": [
      "self",
      "other"
    ],
    "__rfloordiv__": [
      "self",
      "other"
    ],
    "__truediv__": [
      "self",
      "other"
    ],
    "__rtruediv__": [
      "self",
      "other"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__ne__": [
      "self",
      "other"
    ],
    "__lt__": [
      "self",
      "other"
    ],
    "__le__": [
      "self",
      "other"
    ],
    "__gt__": [
      "self",
      "other"
    ],
    "__ge__": [
      "self",
      "other"
    ],
    "__xor__": [
      "self",
      "other"
    ],
    "__rxor__": [
      "self",
      "other"
    ],
    "__or__": [
      "self",
      "other"
    ],
    "__ror__": [
      "self",
      "other"
    ],
    "__and__": [
      "self",
      "other"
    ],
    "__rand__": [
      "self",
      "other"
    ],
    "__neg__": [
      "self"
    ],
    "_flatten_shape_and_coord": [
      "self",
      "crd"
    ],
    "_build_result": [
      "self",
      "res_vect",
      "res_shp"
    ],
    "__getitem__": [
      "self",
      "crd"
    ],
    "to": [
      "self",
      "dtype"
    ],
    "ir_value": [
      "self"
    ],
    "ir_value_int8": [
      "self"
    ],
    "reduce": [
      "self",
      "op",
      "init_val",
      "reduction_profile"
    ]
  },
  "full": [
    "shape",
    "fill_value",
    "dtype"
  ],
  "full_like": [
    "a",
    "fill_value",
    "dtype"
  ],
  "empty_like": [
    "a",
    "dtype"
  ],
  "ones_like": [
    "a",
    "dtype"
  ],
  "zeros_like": [
    "a",
    "dtype"
  ],
  "where": [
    "cond",
    "x",
    "y"
  ],
  "any_": [
    "x"
  ],
  "all_": [
    "x"
  ],
  "struct": {
    "_is_scalar_type": [
      "dtype"
    ],
    "__init__": [
      "self",
      "cls"
    ],
    "__call__": [
      "self",
      "base"
    ],
    "size_in_bytes": [
      "self"
    ],
    "__sizeof__": [
      "self"
    ],
    "__alignof__": [
      "self"
    ],
    "align_offset": [
      "offset",
      "align"
    ]
  },
  "from_dlpack": [
    "tensor_dlpack",
    "assumed_align"
  ],
  "TensorAdapter": {
    "__init__": [
      "self",
      "arg"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "__c_pointers__": [
      "self"
    ],
    "__get_mlir_types__": [
      "self"
    ]
  },
  "jit": [],
  "kernel": [],
  "compile": [],
  "assert_": [
    "cond",
    "msg"
  ],
  "_maybe_recast_tensor_from_f4": [
    "src",
    "tv_layout"
  ],
  "_maybe_recast_to_f4": [
    "input",
    "dtype"
  ],
  "_maybe_recast_from_f4": [
    "input",
    "src_dtype"
  ],
  "_convert_kernel": [
    "gSrc",
    "gDst",
    "cSrc",
    "src_tv_layout",
    "dst_tv_layout",
    "src_shape",
    "src_ty",
    "dst_ty"
  ],
  "_convert": [
    "src",
    "dst",
    "leading_mode",
    "elem_per_copy"
  ],
  "convert": [
    "src",
    "dst"
  ],
  "sample_pytest": [
    "rand_cfg"
  ],
  "JitArguments": {
    "__init__": [
      "self"
    ]
  },
  "_cuda_success": [
    "err",
    "message"
  ],
  "_does_kernel_use_stream": [
    "kernel",
    "stream"
  ],
  "benchmark": [
    "callable"
  ],
  "get_workspace_count": [
    "one_workspace_bytes",
    "warmup_iterations",
    "iterations"
  ],
  "Int": [],
  "IntTuple": [],
  "Shape": [],
  "Stride": [],
  "Coord": [],
  "Layout": {
    "__init__": [
      "self",
      "op_result"
    ],
    "__str__": [
      "self"
    ],
    "get_hier_coord": [
      "self",
      "idx"
    ],
    "shape": [
      "self"
    ],
    "stride": [
      "self"
    ]
  },
  "Tile": [],
  "XTuple": [],
  "Tiler": [],
  "Pointer": {
    "value_type": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "align": [
      "self",
      "min_align"
    ],
    "__get_mlir_types__": [
      "self"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ]
  },
  "OpError": {
    "__init__": [
      "self",
      "op",
      "message",
      "suggestion"
    ]
  },
  "MmaUniversalOp": {
    "__post_init__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "_make_trait": [
      "self"
    ],
    "_verify_fragment_A": [
      "self",
      "input"
    ],
    "_verify_fragment_B": [
      "self",
      "input"
    ]
  },
  "MmaUniversalTrait": {},
  "MemoryOrder": {
    "WEAK": [],
    "RELAXED": [],
    "ACQUIRE": [],
    "RELEASE": [],
    "ACQ_REL": [],
    "SC": [],
    "MMIO": [],
    "CONSTANT": [],
    "VOLATILE": [],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_to_ir": [
      "self"
    ]
  },
  "MemoryScope": {
    "CTA": [],
    "CLUSTER": [],
    "GPU": [],
    "SYS": [],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_to_ir": [
      "self"
    ]
  },
  "CopyUniversalOp": {
    "__str__": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "CopyUniversalTrait": {},
  "make_tiled_tma_atom_A": [
    "op",
    "gmem_tensor",
    "smem_layout",
    "mma_tiler_mnk",
    "tiled_mma",
    "cluster_shape_vmnk"
  ],
  "make_tiled_tma_atom_B": [
    "op",
    "gmem_tensor",
    "smem_layout",
    "mma_tiler_mnk",
    "tiled_mma",
    "cluster_shape_vmnk"
  ],
  "make_smem_layout_atom": [
    "kind",
    "element_type"
  ],
  "tile_to_mma_shape": [
    "atom",
    "mma_tile_shape",
    "order"
  ],
  "commit": [
    "mbar_ptr",
    "mask",
    "cta_group"
  ],
  "is_tmem_load": [
    "atom"
  ],
  "is_tmem_store": [
    "atom"
  ],
  "get_tmem_copy_properties": [
    "atom"
  ],
  "find_tmem_tensor_col_offset": [
    "tmem_tensor"
  ],
  "make_tmem_copy": [
    "atom",
    "tmem_tensor"
  ],
  "make_s2t_copy": [
    "atom",
    "tmem_tensor"
  ],
  "get_s2t_smem_desc_tensor": [
    "atom",
    "smem_tensor"
  ],
  "Repetition": {
    "x1": [],
    "x2": [],
    "x4": [],
    "x8": [],
    "x16": [],
    "x32": [],
    "x64": [],
    "x128": [],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_missing_": [
      "cls",
      "value"
    ]
  },
  "Pack": {
    "NONE": [],
    "PACK_16b_IN_32b": [],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Unpack": {
    "NONE": [],
    "UNPACK_32b_IN_16b": [],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_LdBase": {
    "admissible_archs": [],
    "__post_init__": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "Ld16x64bOp": {
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "Ld16x64bTrait": {},
  "Ld16x128bOp": {
    "__post_init__": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "Ld16x128bTrait": {},
  "Ld16x256bOp": {
    "__post_init__": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "Ld16x256bTrait": {},
  "Ld16x32bx2Op": {
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "Ld16x32bx2Trait": {},
  "Ld32x32bOp": {
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "Ld32x32bTrait": {},
  "_StBase": {
    "admissible_archs": [],
    "__post_init__": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "St16x64bOp": {
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "St16x64bTrait": {},
  "St16x128bOp": {
    "__post_init__": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "St16x128bTrait": {},
  "St16x256bOp": {
    "__post_init__": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "St16x256bTrait": {},
  "St16x32bx2Op": {
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "St16x32bx2Trait": {},
  "St32x32bOp": {
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "St32x32bTrait": {},
  "_S2TCopyBase": {
    "admissible_archs": [],
    "__post_init__": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "Cp128x256bOp": {
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "Cp128x256bTrait": {},
  "Cp128x128bOp": {
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "Cp128x128bTrait": {},
  "Cp4x256bOp": {
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "Cp4x256bTrait": {},
  "Cp4x32x128bOp": {
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "Cp4x32x128bTrait": {},
  "Cp2x64x128b0213Op": {
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "Cp2x64x128b0213Trait": {},
  "Cp2x64x128b0123Op": {
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "Cp2x64x128b0123Trait": {},
  "OperandMajorMode": {
    "MN": [],
    "K": [],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_missing_": [
      "cls",
      "value"
    ],
    "_to_ir": [
      "self"
    ]
  },
  "OperandSource": {
    "TMEM": [],
    "SMEM": [],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_to_ir": [
      "self"
    ]
  },
  "CtaGroup": {
    "ONE": [],
    "TWO": [],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Field": {
    "NEGATE_A": [],
    "NEGATE_B": [],
    "ACCUMULATE": [],
    "SFA": [],
    "SFB": [],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_to_ir_field_name": [
      "self"
    ]
  },
  "MmaTrait": {
    "admissible_fields": [],
    "set": [
      "self",
      "field",
      "value"
    ]
  },
  "BlockScaledMmaOp": {
    "admissible_archs": [],
    "__post_init__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "_verify_fragment_A": [
      "self",
      "input"
    ],
    "_verify_fragment_B": [
      "self",
      "input"
    ]
  },
  "BlockScaledMmaTraits": {
    "admissible_fields": [],
    "set": [
      "self",
      "field",
      "value"
    ]
  },
  "MmaTF32Op": {
    "descriptive_name": [],
    "__init__": [
      "self",
      "instruction_shape",
      "cta_group",
      "a_src",
      "a_major_mode",
      "b_major_mode"
    ],
    "_verify": [
      "self"
    ],
    "_make_trait": [
      "self"
    ]
  },
  "MmaTF32Trait": {},
  "MmaF16BF16Op": {
    "descriptive_name": [],
    "__init__": [
      "self",
      "ab_dtype",
      "acc_dtype",
      "instruction_shape",
      "cta_group",
      "a_src",
      "a_major_mode",
      "b_major_mode"
    ],
    "_verify": [
      "self"
    ],
    "_make_trait": [
      "self"
    ]
  },
  "MmaF16BF16Trait": {},
  "MmaI8Op": {
    "descriptive_name": [],
    "__init__": [
      "self",
      "ab_dtype",
      "instruction_shape",
      "cta_group",
      "a_src",
      "a_major_mode",
      "b_major_mode"
    ],
    "_verify": [
      "self"
    ],
    "_make_trait": [
      "self"
    ]
  },
  "MmaI8Trait": {},
  "MmaFP8Op": {
    "descriptive_name": [],
    "__init__": [
      "self",
      "ab_dtype",
      "acc_dtype",
      "instruction_shape",
      "cta_group",
      "a_src",
      "a_major_mode",
      "b_major_mode"
    ],
    "_verify": [
      "self"
    ],
    "_make_trait": [
      "self"
    ]
  },
  "MmaFP8Trait": {},
  "MmaMXF8Op": {
    "descriptive_name": [],
    "__init__": [
      "self",
      "ab_dtype",
      "instruction_shape",
      "cta_group",
      "a_src",
      "a_major_mode",
      "b_major_mode"
    ],
    "_verify": [
      "self"
    ],
    "_make_trait": [
      "self"
    ]
  },
  "MmaMXF8Trait": {},
  "MmaMXF4Op": {
    "descriptive_name": [],
    "__init__": [
      "self",
      "instruction_shape",
      "cta_group",
      "a_src"
    ],
    "_verify": [
      "self"
    ],
    "_make_trait": [
      "self"
    ]
  },
  "MmaMXF4Trait": {},
  "MmaMXF4NVF4Op": {
    "descriptive_name": [],
    "__init__": [
      "self",
      "sf_dtype",
      "instruction_shape",
      "cta_group",
      "a_src"
    ],
    "_verify": [
      "self"
    ],
    "_make_trait": [
      "self"
    ]
  },
  "MmaMXF4NVF4Trait": {},
  "SmemLayoutAtomKind": {
    "MN_INTER": [],
    "MN_SW32": [],
    "MN_SW64": [],
    "MN_SW128": [],
    "MN_SW128_32B": [],
    "K_INTER": [],
    "K_SW32": [],
    "K_SW64": [],
    "K_SW128": []
  },
  "make_tiled_tma_atom": [
    "op",
    "gmem_tensor",
    "smem_layout",
    "cta_tiler",
    "num_multicast"
  ],
  "tma_partition": [
    "atom",
    "cta_coord",
    "cta_layout",
    "smem_tensor",
    "gmem_tensor"
  ],
  "create_tma_multicast_mask": [
    "cta_layout_vmnk",
    "cta_coord_vmnk",
    "mcast_mode"
  ],
  "prefetch_descriptor": [
    "tma_atom"
  ],
  "copy_tensormap": [
    "tma_atom",
    "tensormap_ptr"
  ],
  "update_tma_descriptor": [
    "tma_atom",
    "gmem_tensor",
    "tma_desc_ptr"
  ],
  "fence_tma_desc_acquire": [
    "tma_desc_ptr"
  ],
  "cp_fence_tma_desc_release": [
    "tma_desc_global_ptr",
    "tma_desc_shared_ptr"
  ],
  "fence_tma_desc_release": [],
  "LoadCacheMode": {
    "ALWAYS": [],
    "GLOBAL": [],
    "STREAMING": [],
    "LAST_USE": [],
    "NONE": [],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_to_ir": [
      "self"
    ]
  },
  "CopyG2SOp": {
    "__str__": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "CopyG2STrait": {},
  "TMA_MBAR_PTR_FIELD_NAME": [],
  "TMA_MASK_FIELD_NAME": [],
  "TMA_DESC_PTR_FIELD_NAME": [],
  "CopyBulkTensorTileG2SOp": {
    "admissible_archs": [],
    "__post_init__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ],
    "_to_ir": [
      "self"
    ]
  },
  "CopyBulkTensorTileG2SNonExecTrait": {
    "unpack": [
      "self"
    ]
  },
  "CopyBulkTensorTileG2SMulticastOp": {
    "admissible_archs": [],
    "__post_init__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ],
    "_to_ir": [
      "self"
    ]
  },
  "CopyBulkTensorTileG2SMulticastNonExecTrait": {
    "unpack": [
      "self"
    ]
  },
  "CopyBulkTensorTileS2GOp": {
    "admissible_archs": [],
    "__post_init__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "CopyBulkTensorTileS2GTrait": {
    "unpack": [
      "self"
    ]
  },
  "CopyReduceBulkTensorTileS2GOp": {
    "admissible_archs": [],
    "__post__init__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ],
    "_to_ir": [
      "self"
    ]
  },
  "CopyReduceBulkTensorTileS2GTrait": {
    "unpack": [
      "self"
    ]
  },
  "BaseOp": {
    "__post_init__": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "LdMatrix8x8x16bOp": {
    "__post_init__": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "LdMatrix8x8x16bTrait": {},
  "LdMatrix16x16x8bOp": {
    "__init__": [
      "self",
      "num_matrices"
    ],
    "_verify": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "LdMatrix16x16x8bTrait": {},
  "StMatrix8x8x16bOp": {
    "__post_init__": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "StMatrix8x8x16bTrait": {},
  "StMatrix16x8x8bOp": {
    "__init__": [
      "self",
      "num_matrices"
    ],
    "_verify": [
      "self"
    ],
    "_make_trait": [
      "self",
      "copy_internal_type"
    ]
  },
  "StMatrix16x8x8bTrait": {},
  "fence": [],
  "commit_group": [],
  "wait_group": [
    "group"
  ],
  "MmaF8Op": {
    "descriptive_name": [],
    "__init__": [
      "self",
      "a_dtype",
      "b_dtype",
      "acc_dtype",
      "instruction_shape",
      "a_src",
      "a_major_mode",
      "b_major_mode"
    ],
    "_verify": [
      "self"
    ],
    "_make_trait": [
      "self"
    ]
  },
  "MmaF8Trait": {},
  "mbarrier_init": [
    "mbar_ptr",
    "cnt"
  ],
  "mbarrier_init_fence": [],
  "mbarrier_arrive_and_expect_tx": [
    "mbar_ptr",
    "bytes",
    "peer_cta_rank_in_cluster"
  ],
  "mbarrier_expect_tx": [
    "mbar_ptr",
    "bytes",
    "peer_cta_rank_in_cluster"
  ],
  "mbarrier_wait": [
    "mbar_ptr",
    "phase"
  ],
  "mbarrier_try_wait": [
    "mbar_ptr",
    "phase"
  ],
  "mbarrier_conditional_try_wait": [
    "cond",
    "mbar_ptr",
    "phase"
  ],
  "mbarrier_arrive": [
    "mbar_ptr",
    "peer_cta_rank_in_cluster"
  ],
  "cp_async_mbarrier_arrive_noinc": [
    "mbar_ptr"
  ],
  "SM100_TMEM_CAPACITY_COLUMNS": [],
  "SM100_TMEM_MIN_ALLOC_COLUMNS": [],
  "retrieve_tmem_ptr": [
    "element_type",
    "alignment",
    "ptr_to_buffer_holding_addr"
  ],
  "alloc_tmem": [
    "num_columns",
    "smem_ptr_to_write_address",
    "is_two_cta"
  ],
  "relinquish_tmem_alloc_permit": [
    "is_two_cta"
  ],
  "dealloc_tmem": [
    "tmem_ptr",
    "num_columns",
    "is_two_cta"
  ],
  "WARP_SIZE": [],
  "FULL_MASK": [],
  "lane_idx": [],
  "warp_idx": [],
  "thread_idx": [],
  "block_dim": [],
  "block_idx": [],
  "grid_dim": [],
  "cluster_idx": [],
  "cluster_dim": [],
  "block_in_cluster_idx": [],
  "block_in_cluster_dim": [],
  "block_idx_in_cluster": [],
  "shuffle_sync_op": [
    "value",
    "offset",
    "mask",
    "mask_and_clamp",
    "kind"
  ],
  "shuffle_sync": [],
  "shuffle_sync_up": [],
  "shuffle_sync_down": [],
  "shuffle_sync_bfly": [],
  "barrier": [],
  "barrier_arrive": [],
  "sync_threads": [],
  "sync_warp": [
    "mask"
  ],
  "fence_acq_rel_cta": [],
  "fence_acq_rel_cluster": [],
  "fence_acq_rel_gpu": [],
  "fence_acq_rel_sys": [],
  "cp_async_commit_group": [],
  "cp_async_wait_group": [
    "n"
  ],
  "cp_async_bulk_commit_group": [],
  "cp_async_bulk_wait_group": [
    "group"
  ],
  "cluster_wait": [],
  "cluster_arrive": [],
  "cluster_arrive_relaxed": [],
  "fence_proxy": [
    "kind"
  ],
  "vote_ballot_sync": [
    "pred",
    "mask"
  ],
  "popc": [
    "value"
  ],
  "fence_view_async_tmem_op": [
    "kind"
  ],
  "fence_view_async_tmem_load": [],
  "fence_view_async_tmem_store": [],
  "warpgroup_reg_realloc_op": [
    "reg_count",
    "kind"
  ],
  "warpgroup_reg_alloc": [],
  "warpgroup_reg_dealloc": [],
  "calc_packed_f32x2_op": [
    "src_a",
    "src_b",
    "src_c",
    "calc_func"
  ],
  "fma_packed_f32x2": [],
  "mul_packed_f32x2": [],
  "add_packed_f32x2": [],
  "fmax": [
    "a",
    "b"
  ],
  "rcp_approx": [
    "a"
  ],
  "exp_packed_f32x2": [
    "a"
  ],
  "make_warp_uniform": [
    "value"
  ],
  "IfOpRegion": {
    "__init__": [
      "self",
      "block"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "elect_one": [],
  "alloc_smem": [
    "element_type",
    "size_in_elems",
    "alignment"
  ],
  "get_dyn_smem": [
    "element_type",
    "alignment"
  ],
  "get_dyn_smem_size": [],
  "SmemCapacity": {
    "SM80_SMEM_CAPACITY_BYTES": [],
    "SM86_SMEM_CAPACITY_BYTES": [],
    "SM89_SMEM_CAPACITY_BYTES": []
  },
  "SMEM_CAPACITY": [],
  "WorkTileInfo": {
    "__init__": [
      "self",
      "tile_idx",
      "is_valid_tile"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "is_valid_tile": [
      "self"
    ],
    "tile_idx": [
      "self"
    ]
  },
  "PersistentTileSchedulerParams": {
    "__init__": [
      "self",
      "problem_shape_ntile_mnl",
      "cluster_shape_mnk"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "get_grid_shape": [
      "self",
      "max_active_clusters"
    ]
  },
  "StaticPersistentTileScheduler": {
    "__init__": [
      "self",
      "params",
      "num_persistent_clusters",
      "current_work_linear_idx",
      "cta_id_in_cluster",
      "num_tiles_executed"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "create": [
      "params",
      "block_idx",
      "grid_dim"
    ],
    "get_grid_shape": [
      "params",
      "max_active_clusters"
    ],
    "_get_current_work_for_linear_idx": [
      "self",
      "current_work_linear_idx"
    ],
    "get_current_work": [
      "self"
    ],
    "initial_work_tile_info": [
      "self"
    ],
    "advance_to_next_work": [
      "self"
    ],
    "num_tiles_executed": [
      "self"
    ]
  },
  "BlockScaledBasicChunk": {
    "__post_init__": [
      "self"
    ],
    "layout": [
      "self"
    ]
  },
  "tile_atom_to_shape_SF": [
    "Shape",
    "sf_vec_size"
  ],
  "make_smem_layout_sfa": [
    "tiled_mma",
    "mma_tiler_mnk",
    "sf_vec_size",
    "num_stages"
  ],
  "make_smem_layout_sfb": [
    "tiled_mma",
    "mma_tiler_mnk",
    "sf_vec_size",
    "num_stages"
  ],
  "make_tmem_layout_sfa": [
    "tiled_mma",
    "mma_tiler_mnk",
    "sf_vec_size",
    "smem_layout"
  ],
  "make_tmem_layout_sfb": [
    "tiled_mma",
    "mma_tiler_mnk",
    "sf_vec_size",
    "smem_layout"
  ],
  "compute_epilogue_tile_shape": [
    "cta_tile_shape",
    "use_2cta_instrs",
    "layout_d",
    "elem_ty_d"
  ],
  "get_smem_store_op": [
    "layout_d",
    "elem_ty_d",
    "elem_ty_acc",
    "tiled_tmem_load"
  ],
  "get_tmem_load_op": [
    "cta_tile_shape",
    "layout_d",
    "elem_ty_d",
    "elem_ty_acc",
    "epi_tile",
    "use_2cta_instrs"
  ],
  "get_num_tmem_alloc_cols": [
    "tmem_tensors",
    "rounding"
  ],
  "get_smem_layout_atom_ab": [
    "major_mode",
    "element_type",
    "smem_shape_mn_k"
  ],
  "make_smem_layout_a": [
    "tiled_mma",
    "mma_tiler_mnk",
    "a_dtype",
    "num_stages"
  ],
  "make_smem_layout_b": [
    "tiled_mma",
    "mma_tiler_mnk",
    "b_dtype",
    "num_stages"
  ],
  "get_smem_layout_atom_epi": [
    "layout",
    "element_type",
    "epi_tile"
  ],
  "make_smem_layout_epi": [
    "epi_dtype",
    "epi_layout",
    "epi_tile",
    "epi_stage"
  ],
  "make_trivial_tiled_mma": [
    "ab_dtype",
    "a_leading_mode",
    "b_leading_mode",
    "acc_dtype",
    "cta_group",
    "mma_tiler_mn",
    "a_source"
  ],
  "make_blockscaled_trivial_tiled_mma": [
    "ab_dtype",
    "a_leading_mode",
    "b_leading_mode",
    "sf_dtype",
    "sf_vec_size",
    "cta_group",
    "mma_tiler_mn",
    "a_source"
  ],
  "cluster_shape_to_tma_atom_A": [
    "cluster_shape_mnk",
    "atom_thr_id"
  ],
  "cluster_shape_to_tma_atom_B": [
    "cluster_shape_mnk",
    "atom_thr_id"
  ],
  "cluster_shape_to_tma_atom_SFB": [
    "cluster_shape_mnk",
    "atom_thr_id"
  ],
  "LayoutEnum": {
    "ROW_MAJOR": [],
    "COL_MAJOR": [],
    "mma_major_mode": [
      "self"
    ],
    "sm90_mma_major_mode": [
      "self"
    ],
    "is_n_major_c": [
      "self"
    ],
    "is_m_major_c": [
      "self"
    ],
    "from_tensor": [
      "tensor"
    ]
  },
  "GroupSearchResult": {
    "__init__": [
      "self",
      "group_idx",
      "cta_tile_idx_m",
      "cta_tile_idx_n",
      "problem_shape_m",
      "problem_shape_n",
      "problem_shape_k",
      "cta_tile_count_k"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ]
  },
  "GroupedGemmGroupSearchState": {
    "__init__": [
      "self",
      "start_group_idx",
      "tile_count_prev_group",
      "tile_count_searched"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ]
  },
  "create_initial_search_state": [],
  "GroupedGemmTileSchedulerHelper": {
    "__init__": [
      "self",
      "group_count",
      "tile_sched_params",
      "cluster_tile_shape_mnk",
      "search_state"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "delinearize_z": [
      "self",
      "cta_tile_coord",
      "problem_shape_mnkl"
    ],
    "search_cluster_tile_count_k": [
      "self",
      "cta_tile_coord",
      "problem_shape_mnkl"
    ],
    "_prefix_sum": [
      "self",
      "value_per_thread"
    ],
    "_get_problem_for_group": [
      "self",
      "problem_shape_mnkl",
      "group_idx"
    ],
    "_get_cluster_tile_count_mn": [
      "self",
      "problem_shape"
    ],
    "_compute_cta_tile_coord": [
      "self",
      "cluster_tile_idx",
      "cta_tile_coord_in_cluster",
      "cluster_tile_count_m",
      "cluster_tile_count_n"
    ],
    "_group_search": [
      "self",
      "linear_idx",
      "problem_shape_mnkl",
      "init_group_idx",
      "init_tile_count_searched"
    ],
    "_group_search_and_load_problem_shape": [
      "self",
      "linear_idx",
      "problem_shape_mnkl",
      "start_group_idx",
      "tile_count_searched"
    ]
  },
  "SmemAllocator": {
    "__init__": [
      "self"
    ],
    "allocate": [
      "self",
      "size_or_type",
      "byte_alignment"
    ],
    "allocate_array": [
      "self",
      "element_type",
      "num_elems"
    ],
    "allocate_tensor": [
      "self",
      "element_type",
      "layout",
      "byte_alignment",
      "swizzle"
    ]
  },
  "SMEM_CAPACITY_MAP": [],
  "get_smem_capacity_in_bytes": [
    "compute_capability"
  ],
  "sm90_get_smem_store_op": [
    "layout_d",
    "elem_ty_d",
    "elem_ty_acc"
  ],
  "get_smem_layout_atom": [
    "layout",
    "element_type",
    "major_mode_size"
  ],
  "HardwareInfo": {
    "__init__": [
      "self",
      "device_id"
    ],
    "get_max_active_clusters": [
      "self",
      "cluster_size"
    ],
    "get_l2_cache_size_in_bytes": [
      "self"
    ],
    "get_device_multiprocessor_count": [
      "self"
    ],
    "_checkCudaErrors": [
      "self",
      "result"
    ],
    "_cudaGetErrorEnum": [
      "self",
      "error"
    ],
    "_cuda_driver_version_ge": [
      "self",
      "major",
      "minor"
    ],
    "_cuda_driver_version_lt": [
      "self",
      "major",
      "minor"
    ],
    "_empty_kernel": [
      "self"
    ],
    "_host_function": [
      "self"
    ],
    "_get_device_function": [
      "self"
    ]
  },
  "TensorMapUpdateMode": {
    "GMEM": [],
    "SMEM": []
  },
  "TensorMapManager": {
    "get_tensormap_ptr": [
      "self",
      "ptr",
      "address_space"
    ],
    "init_tensormap_from_atom": [
      "self",
      "copy_atom",
      "dst_ptr",
      "warp_id"
    ],
    "fence_tensormap_initialization": [
      "self"
    ],
    "fence_tensormap_update": [
      "self",
      "tensormap_ptr"
    ],
    "update_tensormap": [
      "self",
      "tensor_gmem",
      "tma_copy_atom",
      "tensormap_gmem_ptr",
      "warp_id",
      "tensormap_smem_ptr"
    ]
  },
  "atomicAdd": [
    "dst_ptr",
    "val",
    "loc",
    "ip"
  ],
  "ld_bypass": [
    "input_tensor"
  ],
  "spin_lock_wait": [
    "lock_ptr",
    "expect_count",
    "mem_order",
    "mem_scope",
    "loc",
    "ip"
  ],
  "multimem_red_add_sys_release": [
    "mc_ptr",
    "loc",
    "ip"
  ],
  "multimem_red_add_gpu_relaxed": [
    "mc_ptr",
    "loc",
    "ip"
  ],
  "multimem_ld_reduce_base": [
    "mc_ptr"
  ],
  "multimem_ld_reduce_8xf16": [],
  "multimem_ld_reduce_4xf32": [],
  "multimem_ld_reduce_8xbf16": [],
  "multimem_ld_reduce_16xe4m3": [],
  "multimem_ld_reduce_16xe5m2": [],
  "multimem_st_4xb32": [
    "mc_ptr",
    "x",
    "y",
    "z",
    "w"
  ],
  "PipelineAsync": {
    "_make_sync_object": [
      "barrier_storage",
      "num_stages",
      "agent",
      "tx_count"
    ],
    "create": [],
    "producer_acquire": [
      "self",
      "state",
      "try_acquire_token"
    ],
    "producer_try_acquire": [
      "self",
      "state"
    ],
    "producer_commit": [
      "self",
      "state"
    ],
    "consumer_wait": [
      "self",
      "state",
      "try_wait_token"
    ],
    "consumer_try_wait": [
      "self",
      "state"
    ],
    "consumer_release": [
      "self",
      "state"
    ],
    "producer_get_barrier": [
      "self",
      "state"
    ],
    "producer_tail": [
      "self",
      "state"
    ],
    "make_producer": [
      "self"
    ],
    "make_consumer": [
      "self"
    ],
    "make_participants": [
      "self"
    ]
  },
  "PipelineCpAsync": {
    "create": [
      "barrier_storage",
      "num_stages",
      "producer_group",
      "consumer_group",
      "producer_mask",
      "consumer_mask"
    ]
  },
  "PipelineTmaAsync": {
    "init_empty_barrier_arrive_signal": [
      "cta_layout_vmnk",
      "tidx"
    ],
    "create": [],
    "producer_acquire": [
      "self",
      "state",
      "try_acquire_token"
    ],
    "producer_commit": [
      "self",
      "state"
    ],
    "consumer_release": [
      "self",
      "state"
    ]
  },
  "PipelineTmaMultiConsumersAsync": {
    "create": [],
    "producer_acquire": [
      "self",
      "state",
      "try_acquire_token"
    ],
    "producer_commit": [
      "self",
      "state"
    ],
    "consumer_release": [
      "self",
      "state",
      "op_type"
    ]
  },
  "PipelineTmaStore": {
    "create": [],
    "producer_acquire": [
      "self"
    ],
    "producer_commit": [
      "self"
    ],
    "consumer_wait": [
      "self"
    ],
    "consumer_release": [
      "self"
    ],
    "producer_tail": [
      "self"
    ]
  },
  "ImmutableResourceHandle": {
    "__init__": [
      "self",
      "origin",
      "immutable_state"
    ],
    "index": [
      "self"
    ],
    "count": [
      "self"
    ],
    "get_origin": [
      "self"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ]
  },
  "PipelineProducer": {
    "__init__": [
      "self",
      "pipeline",
      "state",
      "group"
    ],
    "acquire": [
      "self",
      "try_acquire_token"
    ],
    "advance": [
      "self"
    ],
    "acquire_and_advance": [
      "self",
      "try_acquire_token"
    ],
    "try_acquire": [
      "self"
    ],
    "commit": [
      "self",
      "handle"
    ],
    "tail": [
      "self"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ]
  },
  "PipelineConsumer": {
    "__init__": [
      "self",
      "pipeline",
      "state",
      "group"
    ],
    "wait": [
      "self",
      "try_wait_token"
    ],
    "advance": [
      "self"
    ],
    "wait_and_advance": [
      "self",
      "try_wait_token"
    ],
    "try_wait": [
      "self"
    ],
    "release": [
      "self",
      "handle"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ]
  },
  "PipelineAsyncUmma": {
    "_compute_leading_cta_rank": [
      "cta_v_size"
    ],
    "_compute_is_leader_cta": [
      "cta_layout_vmnk"
    ],
    "_compute_peer_cta_mask": [
      "cta_layout_vmnk"
    ],
    "create": [],
    "consumer_release": [
      "self",
      "state"
    ]
  },
  "Agent": {
    "Thread": [],
    "ThreadBlock": [],
    "ThreadBlockCluster": []
  },
  "CooperativeGroup": {
    "__init__": [
      "self",
      "agent",
      "size",
      "alignment"
    ]
  },
  "PipelineOp": {
    "AsyncThread": [],
    "TCGen05Mma": [],
    "TmaLoad": [],
    "TmaStore": [],
    "Composite": [],
    "AsyncLoad": []
  },
  "_get_pipeline_op": [
    "type_str"
  ],
  "SyncObject": {
    "arrive": [
      "self"
    ],
    "wait": [
      "self"
    ],
    "arrive_and_wait": [
      "self"
    ],
    "arrive_and_drop": [
      "self"
    ],
    "get_barrier": [
      "self"
    ],
    "max": [
      "self"
    ]
  },
  "MbarrierArray": {
    "__init__": [
      "self",
      "barrier_storage",
      "num_stages",
      "agent",
      "tx_count"
    ],
    "recast_to_new_op_type": [
      "self",
      "new_op_type"
    ],
    "mbarrier_init": [
      "self"
    ],
    "arrive": [
      "self",
      "index",
      "dst",
      "cta_group"
    ],
    "arrive_mbarrier": [
      "self",
      "index",
      "dst_rank"
    ],
    "arrive_cp_async_mbarrier": [
      "self",
      "index"
    ],
    "arrive_tcgen05mma": [
      "self",
      "index",
      "mask",
      "cta_group"
    ],
    "arrive_and_expect_tx": [
      "self",
      "index",
      "tx_count"
    ],
    "try_wait": [
      "self",
      "index",
      "phase"
    ],
    "wait": [
      "self",
      "index",
      "phase"
    ],
    "arrive_and_wait": [
      "self",
      "index",
      "phase",
      "dst",
      "cta_group"
    ],
    "arrive_and_drop": [
      "self"
    ],
    "get_barrier": [
      "self",
      "index"
    ],
    "max": [
      "self"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ]
  },
  "NamedBarrier": {
    "__post_init__": [
      "self"
    ],
    "arrive": [
      "self"
    ],
    "arrive_unaligned": [
      "self"
    ],
    "wait": [
      "self"
    ],
    "wait_unaligned": [
      "self"
    ],
    "arrive_and_wait": [
      "self"
    ],
    "arrive_and_drop": [
      "self"
    ],
    "sync": [
      "self"
    ],
    "get_barrier": [
      "self"
    ],
    "max": [
      "self"
    ]
  },
  "TmaStoreFence": {
    "__init__": [
      "self",
      "num_stages"
    ],
    "arrive": [
      "self"
    ],
    "wait": [
      "self"
    ],
    "arrive_and_wait": [
      "self"
    ],
    "arrive_and_drop": [
      "self"
    ],
    "get_barrier": [
      "self"
    ],
    "max": [
      "self"
    ],
    "tail": [
      "self"
    ]
  },
  "PipelineUserType": {
    "Producer": [],
    "Consumer": []
  },
  "PipelineState": {
    "__init__": [
      "self",
      "stages",
      "count",
      "index",
      "phase"
    ],
    "clone": [
      "self"
    ],
    "index": [
      "self"
    ],
    "count": [
      "self"
    ],
    "stages": [
      "self"
    ],
    "phase": [
      "self"
    ],
    "reset_count": [
      "self"
    ],
    "advance": [
      "self"
    ],
    "reverse": [
      "self"
    ],
    "__get_mlir_types__": [
      "self"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ]
  },
  "make_pipeline_state": [
    "type",
    "stages"
  ],
  "_sync": [
    "group"
  ],
  "_mbarrier_i64_to_ptr": [
    "val"
  ],
  "arrive": [
    "barrier_id",
    "num_threads"
  ],
  "arrive_unaligned": [
    "barrier_id",
    "num_threads"
  ],
  "wait": [
    "barrier_id",
    "num_threads"
  ],
  "wait_unaligned": [
    "barrier_id",
    "num_threads"
  ],
  "arrive_and_wait": [
    "barrier_id",
    "num_threads"
  ],
  "sync": [
    "barrier_id"
  ],
  "LoopUnroll": {
    "__init__": [
      "self"
    ]
  },
  "ScfGenerator": {
    "__init__": [
      "self"
    ],
    "_normalize_region_result_to_list": [
      "region_result"
    ],
    "_check_region_result": [
      "original_value",
      "region_value",
      "arg_name",
      "op_type_name"
    ],
    "scf_execute_dynamic": [
      "self",
      "op_type_name",
      "mix_iter_args",
      "full_write_args_count",
      "mix_iter_arg_names",
      "create_op_func",
      "region_builders",
      "block_term_op_builder"
    ]
  },
  "_attr_const_check": [
    "attr",
    "expected_type",
    "attr_name"
  ],
  "_loop_execute_range_dynamic": [
    "func",
    "start",
    "stop",
    "step",
    "mix_iter_args",
    "full_write_args_count",
    "mix_iter_arg_names",
    "unroll",
    "unroll_full",
    "prefetch_stages"
  ],
  "_if_execute_dynamic": [
    "pred",
    "then_block",
    "else_block",
    "mix_yield_args",
    "full_write_args_count",
    "mix_yield_arg_names",
    "if_constexpr"
  ],
  "_while_execute_dynamic": [
    "while_before_block",
    "while_after_block",
    "write_args",
    "full_write_args_count",
    "write_args_names"
  ],
  "DSLTreeFlattenError": {
    "__init__": [
      "self",
      "msg",
      "type_str"
    ]
  },
  "unzip2": [
    "pairs"
  ],
  "get_fully_qualified_class_name": [
    "x"
  ],
  "is_frozen_dataclass": [
    "obj_or_cls"
  ],
  "is_dynamic_expression": [
    "x"
  ],
  "is_constexpr_field": [
    "field"
  ],
  "NodeType": {},
  "PyTreeDef": {},
  "Leaf": {},
  "extract_dataclass_members": [
    "x"
  ],
  "default_dataclass_to_iterable": [
    "x"
  ],
  "set_dataclass_attributes": [
    "instance",
    "fields",
    "values",
    "constexpr_fields"
  ],
  "default_dataclass_from_iterable": [
    "metadata",
    "children"
  ],
  "dynamic_expression_to_iterable": [
    "x"
  ],
  "dynamic_expression_from_iterable": [
    "metadata",
    "children"
  ],
  "default_dict_to_iterable": [
    "x"
  ],
  "default_dict_from_iterable": [
    "metadata",
    "children"
  ],
  "register_pytree_node": [
    "ty",
    "to_iter",
    "from_iter"
  ],
  "register_default_node_types": [],
  "tree_flatten": [
    "x"
  ],
  "get_registered_node_types_or_insert": [
    "x"
  ],
  "create_leaf_for_value": [
    "x",
    "is_numeric",
    "is_none",
    "node_metadata",
    "ir_type_str"
  ],
  "_tree_flatten": [
    "x"
  ],
  "tree_unflatten": [
    "treedef",
    "xs"
  ],
  "_tree_unflatten": [
    "treedef",
    "xs"
  ],
  "_check_tree_equal": [
    "lhs",
    "rhs"
  ],
  "check_tree_equal": [
    "lhs",
    "rhs"
  ],
  "get_sparse_tuple_ctype": [
    "dyn"
  ],
  "is_cute_algebra_type": [
    "arg_spec"
  ],
  "_get_c_pointers_cutlass": [
    "obj"
  ],
  "CutlassBaseDSL": {
    "__init__": [
      "self",
      "name",
      "compiler_provider",
      "pass_sm_arch_name",
      "device_compilation_only",
      "preprocess"
    ],
    "_is_tensor_descriptor": [
      "self",
      "maybe_tensor_descriptor"
    ],
    "_handle_tensor_descriptor": [
      "self",
      "maybe_tensor",
      "arg_name",
      "need_gpu_memory"
    ],
    "_build_gpu_module": [
      "self",
      "attrs"
    ],
    "_get_pipeline": [
      "self",
      "pipeline"
    ],
    "preprocess_pipeline": [
      "self",
      "pipeline",
      "arch"
    ],
    "_enter_gpu_module": [
      "self"
    ],
    "_generate_kernel_attrs": [
      "self",
      "config"
    ],
    "get_version": [
      "self"
    ],
    "track_smem_allocator": [
      "allocator",
      "callback"
    ],
    "_set_smem_tracking": [
      "self",
      "allocator",
      "callback"
    ],
    "_reset_smem_tracking": [
      "self"
    ],
    "_get_smem_usage": [
      "self"
    ],
    "_kernel_helper": [
      "self",
      "funcBody"
    ],
    "_preprocess_launch_config_args": [
      "self",
      "args",
      "kwargs"
    ],
    "mangle_name": [
      "self",
      "function_name",
      "args",
      "args_spec"
    ],
    "_validate_arg": [
      "self",
      "arg",
      "arg_index",
      "arg_name",
      "arg_annotation"
    ],
    "_generate_jit_func_args_for_known_types": [
      "self",
      "func",
      "arg",
      "arg_name",
      "arg_spec",
      "arg_index"
    ],
    "_generate_execution_arguments_for_known_types": [
      "self",
      "arg",
      "arg_spec",
      "arg_name",
      "i",
      "fop_args",
      "iv_block_args"
    ]
  },
  "CuTeDSL": {
    "__init__": [
      "self"
    ]
  },
  "KernelLauncher": {
    "__init__": [
      "self",
      "dsl",
      "kernelGenHelper",
      "funcBody"
    ],
    "_check_func_args": [
      "self",
      "funcBody"
    ],
    "smem_usage": [
      "self"
    ],
    "launch": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "_filter_readonly_frozen_dataclass": [
    "iter_args",
    "items_to_filter",
    "full_write_args_count"
  ],
  "remove_read_only_frozen_dataclass": [
    "iter_args",
    "full_write_args_count"
  ],
  "filter_readonly_frozen_dataclass_names": [
    "iter_args",
    "iter_args_names",
    "full_write_args_count"
  ],
  "insert_read_only_frozen_dataclass": [
    "iter_args",
    "original_iter_args",
    "full_write_args_count"
  ],
  "unpack_to_irvalue": [
    "mixed_values",
    "body_name",
    "full_write_args_count"
  ],
  "pack_from_irvalue": [
    "ir_values",
    "pytree_def",
    "mixed_values",
    "full_write_args_count"
  ],
  "to_index": [
    "value"
  ],
  "_validate_iter_args_structure": [
    "iter_args",
    "ir_values"
  ],
  "_minmax": [
    "op"
  ],
  "min": [],
  "and_": [],
  "or_": [],
  "select_": [
    "cond",
    "if_value",
    "else_value"
  ],
  "yield_out": [
    "args",
    "loc",
    "ip"
  ],
  "for_generate": [
    "start",
    "stop",
    "step",
    "iter_args"
  ],
  "not_": [
    "lhs"
  ],
  "if_generate": [
    "cond",
    "then_body",
    "else_body",
    "input_args",
    "return_types"
  ],
  "WhileLoopContext": {
    "__init__": [
      "self",
      "inputs",
      "condition"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "results": [
      "self"
    ]
  },
  "while_generate": [
    "inputs",
    "condition"
  ],
  "equal": [
    "lhs",
    "rhs"
  ],
  "not_equal": [
    "lhs",
    "rhs"
  ],
  "in_": [
    "lhs",
    "rhs"
  ],
  "_lte_gte": [
    "lhs",
    "rhs",
    "op"
  ],
  "greater_than": [
    "lhs",
    "rhs"
  ],
  "greater_equal": [
    "lhs",
    "rhs"
  ],
  "less_than": [
    "lhs",
    "rhs"
  ],
  "less_equal": [
    "lhs",
    "rhs"
  ],
  "_compare_dispatch": [
    "lhs",
    "rhs",
    "op"
  ],
  "_compare_executor": [
    "left",
    "comparators",
    "ops"
  ],
  "_builtin_redirector": [
    "fcn"
  ],
  "Colors": {
    "RED": [],
    "YELLOW": [],
    "BLUE": [],
    "GREEN": [],
    "BOLD": [],
    "RESET": []
  },
  "DSLBaseError": {
    "__init__": [
      "self",
      "message",
      "line",
      "snippet",
      "filename",
      "error_code",
      "context",
      "suggestion",
      "cause"
    ],
    "_format_message": [
      "self"
    ]
  },
  "DSLRuntimeError": {},
  "_get_friendly_cuda_error_message": [
    "error_code",
    "error_name"
  ],
  "DSLCudaRuntimeError": {
    "__init__": [
      "self",
      "error_code",
      "error_name"
    ]
  },
  "DSLAstPreprocessorError": {},
  "DSLNotImplemented": {},
  "OrderedSet": {
    "__init__": [
      "self",
      "iterable"
    ],
    "add": [
      "self",
      "item"
    ],
    "__iter__": [
      "self"
    ],
    "__and__": [
      "self",
      "other"
    ],
    "__or__": [
      "self",
      "other"
    ],
    "__sub__": [
      "self",
      "other"
    ],
    "intersections": [
      "self",
      "others"
    ]
  },
  "ImportInfo": {},
  "ScopeManager": {
    "create": [
      "cls"
    ],
    "add_to_scope": [
      "self",
      "name"
    ],
    "get_active_symbols": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "DSLPreprocessor": {
    "DECORATOR_FOR_STATEMENT": [],
    "DECORATOR_IF_STATEMENT": [],
    "DECORATOR_WHILE_STATEMENT": [],
    "IF_EXECUTOR": [],
    "WHILE_EXECUTOR": [],
    "ASSERT_EXECUTOR": [],
    "BOOL_CAST": [],
    "IMPLICIT_DOWNCAST_NUMERIC_TYPE": [],
    "SUPPORTED_FOR_RANGE_STATEMENTS": [],
    "COMPARE_EXECUTOR": [],
    "ANY_EXECUTOR": [],
    "ALL_EXECUTOR": [],
    "__init__": [
      "self",
      "client_module_name"
    ],
    "_create_module_attribute": [
      "self",
      "func_name"
    ],
    "_get_module_imports": [
      "self",
      "decorated_func"
    ],
    "exec": [
      "self",
      "function_name",
      "original_function",
      "code_object",
      "exec_globals"
    ],
    "print_ast": [
      "transformed_tree"
    ],
    "make_func_param_name": [
      "self",
      "base_name",
      "used_names"
    ],
    "transform_function": [
      "self",
      "func_name",
      "function_pointer"
    ],
    "check_early_exit": [
      "self",
      "tree",
      "kind"
    ],
    "is_node_constexpr": [
      "self",
      "node"
    ],
    "_get_range_kind": [
      "self",
      "iter_node"
    ],
    "transform": [
      "self",
      "original_function",
      "exec_globals"
    ],
    "analyze_region_variables": [
      "self",
      "node",
      "active_symbols"
    ],
    "extract_range_args": [
      "self",
      "iter_node"
    ],
    "extract_unroll_args": [
      "self",
      "iter_node"
    ],
    "issue_deprecation_warning": [
      "self"
    ],
    "extract_prefetch_stages_args": [
      "self",
      "iter_node"
    ],
    "create_loop_function": [
      "self",
      "func_name",
      "node",
      "start",
      "stop",
      "step",
      "unroll",
      "unroll_full",
      "prefetch_stages",
      "write_args",
      "full_write_args_count"
    ],
    "visit_BoolOp": [
      "self",
      "node"
    ],
    "visit_UnaryOp": [
      "self",
      "node"
    ],
    "_insert_range_value_check": [
      "self",
      "node"
    ],
    "_insert_cf_symbol_check": [
      "self",
      "func"
    ],
    "visit_For": [
      "self",
      "node"
    ],
    "_hoist_expr_to_assignments": [
      "expr",
      "name"
    ],
    "_build_select_and_assign": [
      "self"
    ],
    "_handle_negative_step": [
      "self",
      "node",
      "start_expr",
      "stop_expr",
      "step_expr"
    ],
    "transform_for_loop": [
      "self",
      "node",
      "active_symbols"
    ],
    "visit_Assert": [
      "self",
      "node"
    ],
    "visit_Call": [
      "self",
      "node"
    ],
    "visit_ClassDef": [
      "self",
      "node"
    ],
    "_visit_target": [
      "self",
      "target"
    ],
    "visit_Assign": [
      "self",
      "node"
    ],
    "visit_AugAssign": [
      "self",
      "node"
    ],
    "visit_Name": [
      "self",
      "node"
    ],
    "check_decorator": [
      "self",
      "node"
    ],
    "remove_dsl_decorator": [
      "self",
      "decorator_list"
    ],
    "visit_FunctionDef": [
      "self",
      "node"
    ],
    "visit_With": [
      "self",
      "node"
    ],
    "visit_While": [
      "self",
      "node"
    ],
    "visit_Try": [
      "self",
      "node"
    ],
    "visit_ExceptHandler": [
      "self",
      "node"
    ],
    "create_cf_call": [
      "self",
      "func_name",
      "yield_args",
      "node"
    ],
    "visit_IfExp": [
      "self",
      "node"
    ],
    "cmpops": [],
    "compare_ops_to_str": [
      "self",
      "node"
    ],
    "visit_Compare": [
      "self",
      "node"
    ],
    "visit_If": [
      "self",
      "node"
    ],
    "generate_get_locals_or_none_call": [
      "self",
      "write_args"
    ],
    "create_if_function": [
      "self",
      "func_name",
      "node",
      "write_args",
      "full_write_args_count"
    ],
    "create_while_function": [
      "self",
      "func_name",
      "node",
      "write_args",
      "full_write_args_count"
    ]
  },
  "IS_WINDOWS": [],
  "CLIB_EXT": [],
  "get_str_env_var": [
    "var_name",
    "default_value"
  ],
  "get_bool_env_var": [
    "var_name",
    "default_value"
  ],
  "get_int_env_var": [
    "var_name",
    "default_value"
  ],
  "has_env_var": [
    "var_name"
  ],
  "detect_gpu_arch": [
    "prefix"
  ],
  "find_libs_in_ancestors": [
    "start",
    "target_libs",
    "lib_folder_guesses"
  ],
  "_find_cuda_home": [],
  "get_cuda_toolkit_path": [],
  "get_prefix_dsl_libs": [
    "prefix"
  ],
  "EnvironmentVarManager": {
    "__init__": [
      "self",
      "prefix"
    ]
  },
  "get_current_user": [],
  "load_ir": [
    "file",
    "asBytecode"
  ],
  "make_unique_filename": [
    "fpath",
    "new_ext"
  ],
  "save_ir": [
    "dsl_name",
    "module",
    "fname",
    "isTemp",
    "asBytecode"
  ],
  "check_func_name": [
    "jit_cache",
    "func_name"
  ],
  "load_cache_from_path": [
    "dsl_name",
    "cache_limit",
    "path"
  ],
  "dump_cache_to_path": [
    "dsl_name",
    "jit_cache",
    "cache_limit",
    "path"
  ],
  "DynamicExpression": {
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ]
  },
  "JitArgument": {
    "__c_pointers__": [
      "self"
    ],
    "__get_mlir_types__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ]
  },
  "get_c_pointers": [
    "obj"
  ],
  "get_mlir_types": [
    "obj"
  ],
  "DslType": {
    "__new__": [
      "cls",
      "name",
      "bases",
      "attrs",
      "is_abstract"
    ],
    "is_abstract": [
      "cls"
    ]
  },
  "NumericMeta": {
    "_mlir_type": [],
    "__new__": [
      "cls",
      "name",
      "bases",
      "attrs",
      "width",
      "np_dtype",
      "mlir_type",
      "is_abstract"
    ],
    "numpy_dtype": [
      "cls"
    ],
    "is_integer": [
      "cls"
    ],
    "is_float": [
      "cls"
    ],
    "is_same_kind": [
      "cls",
      "other"
    ],
    "from_python": [
      "value"
    ],
    "mlir_type": [
      "cls"
    ]
  },
  "Value": [],
  "cast": [
    "obj",
    "type_"
  ],
  "IntegerMeta": {
    "__new__": [
      "cls",
      "name",
      "bases",
      "attrs",
      "width",
      "signed",
      "mlir_type",
      "is_abstract"
    ],
    "__str__": [
      "cls"
    ],
    "is_integer": [
      "cls"
    ],
    "is_float": [
      "cls"
    ],
    "zero": [
      "cls"
    ],
    "min": [
      "cls"
    ],
    "max": [
      "cls"
    ],
    "recast_width": [
      "cls",
      "width"
    ]
  },
  "FloatMeta": {
    "__new__": [
      "cls",
      "name",
      "bases",
      "attrs",
      "width",
      "mlir_type",
      "is_abstract"
    ],
    "__str__": [
      "cls"
    ],
    "is_integer": [
      "cls"
    ],
    "is_float": [
      "cls"
    ],
    "zero": [
      "cls"
    ],
    "inf": [
      "cls"
    ],
    "nan": [
      "cls"
    ],
    "exponent_width": [
      "cls"
    ],
    "mantissa_width": [
      "cls"
    ],
    "recast_width": [
      "cls",
      "width"
    ]
  },
  "_arith_signless_to_int": [
    "a",
    "target_type"
  ],
  "_binary_op_type_promote": [
    "a",
    "b",
    "promote_bool"
  ],
  "_binary_op": [
    "op",
    "promote_operand",
    "promote_bool",
    "flip"
  ],
  "Numeric": {
    "__init__": [
      "self",
      "value"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "__hash__": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "to": [
      "self",
      "dtype"
    ],
    "ir_value": [
      "self"
    ],
    "zero": [
      "self"
    ],
    "__dsl_not__": [
      "self"
    ],
    "__dsl_and__": [
      "self",
      "other"
    ],
    "__dsl_or__": [
      "self",
      "other"
    ],
    "__dsl_bool__": [
      "self"
    ],
    "__bool__": [
      "self"
    ],
    "__index__": [
      "self"
    ],
    "__neg__": [
      "self"
    ],
    "_from_python_value": [
      "value"
    ],
    "__add__": [
      "self",
      "other"
    ],
    "__sub__": [
      "self",
      "other"
    ],
    "__mul__": [
      "self",
      "other"
    ],
    "__floordiv__": [
      "self",
      "other"
    ],
    "__truediv__": [
      "self",
      "other"
    ],
    "__mod__": [
      "self",
      "other"
    ],
    "__radd__": [
      "self",
      "other"
    ],
    "__rsub__": [
      "self",
      "other"
    ],
    "__rmul__": [
      "self",
      "other"
    ],
    "__rfloordiv__": [
      "self",
      "other"
    ],
    "__rtruediv__": [
      "self",
      "other"
    ],
    "__rmod__": [
      "self",
      "other"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__ne__": [
      "self",
      "other"
    ],
    "__lt__": [
      "self",
      "other"
    ],
    "__le__": [
      "self",
      "other"
    ],
    "__gt__": [
      "self",
      "other"
    ],
    "__ge__": [
      "self",
      "other"
    ],
    "__pow__": [
      "self",
      "other"
    ],
    "__c_pointers__": [
      "self"
    ],
    "__get_mlir_types__": [
      "self"
    ],
    "from_mlir_type": [
      "mlir_type"
    ]
  },
  "as_numeric": [
    "obj"
  ],
  "Integer": {
    "__init__": [
      "self",
      "x"
    ],
    "__invert__": [
      "self"
    ],
    "__lshift__": [
      "self",
      "other"
    ],
    "__rlshift__": [
      "self",
      "other"
    ],
    "__rshift__": [
      "self",
      "other"
    ],
    "__rrshift__": [
      "self",
      "other"
    ],
    "__and__": [
      "self",
      "other"
    ],
    "__rand__": [
      "self",
      "other"
    ],
    "__or__": [
      "self",
      "other"
    ],
    "__ror__": [
      "self",
      "other"
    ],
    "__xor__": [
      "self",
      "other"
    ],
    "__rxor__": [
      "self",
      "other"
    ]
  },
  "Float": {
    "__init__": [
      "self",
      "x"
    ]
  },
  "Boolean": {
    "__init__": [
      "self",
      "a"
    ],
    "ir_value_int8": [
      "self"
    ],
    "__neg__": [
      "self"
    ]
  },
  "Int8": {},
  "Int16": {},
  "Int32": {},
  "Int64": {},
  "Int128": {},
  "Uint8": {},
  "Uint16": {},
  "Uint32": {},
  "Uint64": {},
  "Uint128": {},
  "Float64": {
    "__c_pointers__": [
      "self"
    ]
  },
  "Float32": {
    "_get_c_pointer": [
      "value"
    ],
    "__c_pointers__": [
      "self"
    ]
  },
  "TFloat32": {
    "__c_pointers__": [
      "self"
    ]
  },
  "Float16": {
    "_get_c_pointer": [
      "value"
    ],
    "__c_pointers__": [
      "self"
    ]
  },
  "BFloat16": {
    "__c_pointers__": [
      "self"
    ]
  },
  "Float8E5M2": {},
  "Float8E4M3FN": {},
  "Float8E4M3B11FNUZ": {},
  "Float8E4M3": {},
  "Float8E8M0FNU": {},
  "Float4E2M1FN": {},
  "Float6E3M2FN": {},
  "Float6E2M3FN": {},
  "_unsupported_dst_float_types": [],
  "ALL_DTYPES": [],
  "__STR_TO_DTYPE__": [],
  "TensorMeta": {
    "_element_type": [],
    "_shape": [],
    "__new__": [
      "cls",
      "name",
      "bases",
      "attrs",
      "element_type",
      "shape"
    ]
  },
  "TY": [],
  "Constexpr": {},
  "align": {
    "__init__": [
      "self",
      "value"
    ],
    "__str__": [
      "self"
    ]
  },
  "PointerMeta": {
    "__new__": [
      "cls",
      "name",
      "bases",
      "attrs",
      "value_type",
      "align_"
    ],
    "__eq__": [
      "cls",
      "other"
    ],
    "__hash__": [
      "cls"
    ],
    "__getitem__": [
      "cls",
      "params"
    ],
    "__str__": [
      "cls"
    ]
  },
  "IRConst": {
    "__init__": [
      "self",
      "ty"
    ]
  },
  "IRValue": {
    "__init__": [
      "self",
      "ty"
    ]
  },
  "IRVariadic": {
    "__init__": [
      "self",
      "operands"
    ],
    "block_arg_types": [
      "self"
    ],
    "set_func_args": [
      "self",
      "block_args"
    ],
    "__len__": [
      "self"
    ]
  },
  "FuncArgWithAttr": {
    "__init__": [
      "self",
      "ty",
      "attr_name",
      "attr_ty",
      "attr_value"
    ]
  },
  "implicitDowncastNumericType": [
    "value"
  ],
  "CudaSingleModule": {
    "__init__": [
      "self",
      "cuda_module",
      "kernel_ptr"
    ]
  },
  "CudaModules": {
    "__init__": [
      "self",
      "modules",
      "args"
    ]
  },
  "JitExecutor": {
    "__init__": [
      "self",
      "dsl",
      "engine",
      "capi_func",
      "ir_module",
      "args_spec",
      "function_name",
      "cuda_modules",
      "jit_time_profiling"
    ],
    "filter_runtime_arg_spec": [
      "self",
      "arg_spec"
    ],
    "__del__": [
      "self"
    ],
    "get_constexpr_args": [
      "self"
    ],
    "generate_execution_args": [
      "self",
      "args",
      "kwargs",
      "args_spec"
    ],
    "__call__": [
      "self"
    ],
    "get_invoke_packed_args": [
      "self",
      "exe_args"
    ],
    "run_compiled_program": [
      "self",
      "exe_args"
    ],
    "update_jit_cuda_modules": [
      "self",
      "kernel_symbols"
    ],
    "_get_escaped_cubin_bytes": [
      "self",
      "cubin_data"
    ],
    "walk_module_and_get_cubin_data": [
      "self",
      "module",
      "sym",
      "callback"
    ]
  },
  "_SCRIPT_PATH": [],
  "CompilationError": {
    "RED": [],
    "YELLOW": [],
    "BLUE": [],
    "GREEN": [],
    "BOLD": [],
    "RESET": [],
    "__init__": [
      "self",
      "message",
      "nvvm_error",
      "ir_context",
      "cuda_toolkit",
      "arch"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_format_error": [
      "self"
    ]
  },
  "Compiler": {
    "__init__": [
      "self",
      "passmanager",
      "execution_engine"
    ],
    "__call__": [
      "self",
      "module"
    ],
    "_process_error": [
      "self",
      "error_msg"
    ],
    "compile": [
      "self",
      "module",
      "pipeline",
      "cuda_toolkit",
      "arch",
      "enable_verifier"
    ],
    "jit": [
      "self",
      "module",
      "opt_level",
      "shared_libs"
    ],
    "compile_and_jit": [
      "self",
      "module",
      "pipeline",
      "shared_libs",
      "opt_level",
      "cuda_toolkit",
      "arch"
    ]
  },
  "CompileOptions": {
    "__init__": [
      "self",
      "options"
    ],
    "to_str": [
      "self"
    ]
  },
  "MLIR_DYNAMIC": [],
  "_numpy_type_to_mlir_type": [
    "dtype"
  ],
  "_mlir_type_to_numpy_type": [
    "type"
  ],
  "extract_mlir_values": [
    "obj"
  ],
  "new_from_mlir_values": [
    "obj",
    "values"
  ],
  "DSLCallable": {
    "__init__": [
      "self",
      "func"
    ],
    "__call__": [
      "self"
    ],
    "__func__": [
      "self"
    ],
    "__signature__": [
      "self"
    ],
    "__name__": [
      "self"
    ]
  },
  "BaseDSL": {
    "gpu_module": [],
    "__init__": [
      "self"
    ],
    "dump_cache": [
      "self"
    ],
    "print_warning_once": [
      "self",
      "message"
    ],
    "print_warning": [
      "self",
      "message"
    ],
    "_get_dsl": [
      "cls"
    ],
    "_can_preprocess": [],
    "_get_original_function": [
      "fcn_ptr",
      "name"
    ],
    "_preprocess_and_execute": [
      "func"
    ],
    "jit_runner": [
      "self",
      "executor",
      "frame"
    ],
    "jit": [
      "cls"
    ],
    "kernel": [
      "cls"
    ],
    "_kernel_helper": [
      "self",
      "func"
    ],
    "_build_gpu_module": [
      "self",
      "attrs"
    ],
    "_get_pipeline": [
      "self",
      "pipeline"
    ],
    "log_additions": [
      "func_type",
      "operands",
      "types",
      "arg_attrs"
    ],
    "mangle_name": [
      "self",
      "function_name",
      "args",
      "args_spec"
    ],
    "_generate_execution_arguments_for_known_types": [
      "self",
      "arg",
      "arg_spec",
      "arg_name",
      "i",
      "fop_args",
      "iv_block_args"
    ],
    "generate_execution_arguments": [
      "self",
      "args",
      "kwargs",
      "fop",
      "args_spec"
    ],
    "_generate_mlir_type_for_tensor_descriptor": [
      "self",
      "tensor"
    ],
    "_generate_executable_arg_for_tensor_descriptor": [
      "self",
      "mlir_value",
      "ptr_tensor_ty",
      "tensor"
    ],
    "_get_globals": [
      "self"
    ],
    "_is_tensor_descriptor": [
      "self",
      "maybe_tensor_descriptor"
    ],
    "_handle_tensor_descriptor": [
      "self",
      "maybe_tensor",
      "arg_name",
      "need_gpu_memory"
    ],
    "_validate_arg": [
      "self",
      "arg",
      "arg_index",
      "arg_name",
      "arg_spec"
    ],
    "_generate_jit_func_args_for_known_types": [
      "self",
      "func",
      "arg",
      "arg_name",
      "arg_spec",
      "arg_index"
    ],
    "_generate_jit_func_args": [
      "self",
      "func",
      "function_name",
      "args",
      "kwargs",
      "args_spec"
    ],
    "generate_mlir_function_types": [
      "self",
      "func",
      "function_name",
      "input_args",
      "kwargs",
      "args_spec"
    ],
    "diagnostic": [
      "self"
    ],
    "get_location": [
      "self"
    ],
    "compile_and_jit": [
      "self",
      "module",
      "pipeline",
      "shared_libs",
      "function_name"
    ],
    "preprocess_pipeline": [
      "self",
      "pipeline",
      "arch"
    ],
    "get_shared_libs": [
      "self"
    ],
    "get_version": [
      "self"
    ],
    "get_module_hash": [
      "self",
      "module",
      "function_name"
    ],
    "build_module": [
      "self",
      "module",
      "function_name"
    ],
    "generate_original_ir": [
      "self",
      "ir",
      "func",
      "funcBody",
      "kwargs",
      "function_name",
      "func_types",
      "gpu_module_attrs",
      "args",
      "args_spec"
    ],
    "compile_and_cache": [
      "self",
      "module",
      "module_hash",
      "function_name",
      "pipeline",
      "args_spec",
      "no_cache"
    ],
    "post_compilation_cleanup": [
      "self"
    ],
    "generate_mlir": [
      "self",
      "funcBody",
      "kwargs",
      "function_name",
      "gpu_module_attrs",
      "args",
      "args_spec",
      "pipeline",
      "no_cache",
      "compile_only",
      "loc"
    ],
    "run_preprocessor": [
      "self",
      "funcBody"
    ],
    "get_function_ptr": [
      "self",
      "original_function"
    ],
    "_get_function_bound_args": [
      "self",
      "sig",
      "func_name"
    ],
    "_canonicalize_args": [
      "self",
      "sig"
    ],
    "_check_arg_count": [
      "self"
    ],
    "_func": [
      "self",
      "funcBody"
    ],
    "enter_gpu_module": [
      "module"
    ],
    "_get_default_stream": [
      "self"
    ],
    "_execute_cuda": [
      "self",
      "fname_cubin",
      "kernel_name",
      "grid_size",
      "block_size",
      "smem_size",
      "stream"
    ],
    "_execute_by_cuda_driver": [
      "self",
      "kernel_generator",
      "generate_cubin",
      "grid_size",
      "block_size",
      "smem_size",
      "stream"
    ],
    "generate_kernel_operands_and_types": [
      "self",
      "kernel_func",
      "kernel_name",
      "args_spec",
      "args",
      "kwargs"
    ],
    "kernel_launcher": [
      "self"
    ]
  },
  "Executor": {
    "__init__": [
      "self"
    ],
    "set_functions": [
      "self"
    ],
    "convert_to_list": [
      "x"
    ],
    "converge_ret_val": [
      "res"
    ],
    "for_execute": [
      "self",
      "func",
      "start",
      "stop",
      "step",
      "write_args",
      "full_write_args_count",
      "write_args_names",
      "unroll",
      "unroll_full",
      "prefetch_stages"
    ],
    "if_execute": [
      "self",
      "pred",
      "then_block",
      "else_block",
      "write_args",
      "full_write_args_count",
      "write_args_names"
    ],
    "while_execute": [
      "self",
      "pred",
      "while_before_block",
      "while_after_block",
      "write_args",
      "full_write_args_count",
      "write_args_names"
    ]
  },
  "executor": [],
  "loop_selector": [
    "start",
    "stop",
    "step"
  ],
  "if_selector": [
    "pred",
    "write_args"
  ],
  "while_selector": [
    "pred",
    "write_args"
  ],
  "while_executor": [
    "pred",
    "while_before_block",
    "while_after_block",
    "write_args",
    "full_write_args_count",
    "write_args_names"
  ],
  "if_executor": [
    "pred",
    "then_block",
    "else_block",
    "write_args",
    "full_write_args_count",
    "write_args_names"
  ],
  "range": {
    "__new__": [
      "cls"
    ],
    "__iter__": [
      "self"
    ]
  },
  "range_dynamic": [],
  "range_constexpr": [],
  "const_expr": [
    "expression"
  ],
  "dynamic_expr": [
    "expression"
  ],
  "assert_executor": [
    "test",
    "msg"
  ],
  "bool_cast": [
    "value"
  ],
  "compare_executor": [
    "left",
    "comparators",
    "ops"
  ],
  "any_executor": [
    "iterable"
  ],
  "all_executor": [
    "iterable"
  ],
  "DSLOptimizationWarning": {
    "__init__": [
      "self",
      "message"
    ],
    "__str__": [
      "self"
    ]
  },
  "range_value_check": [],
  "range_perf_warning": [
    "filename",
    "lineno"
  ],
  "_get_self_module": [],
  "cf_symbol_check": [
    "symbol"
  ],
  "redirect_builtin_function": [
    "fcn"
  ],
  "copy_members": [
    "dest",
    "src"
  ],
  "get_locals_or_none": [
    "locals",
    "symbols"
  ],
  "create_async_token": [],
  "get_ir_context": [
    "func"
  ],
  "lru_cache_ir": [
    "maxsize",
    "typed"
  ],
  "recast_type": [
    "src_type",
    "res_elem_type"
  ],
  "is_scalar": [
    "ty"
  ],
  "element_type": [
    "ty"
  ],
  "is_narrow_precision": [
    "ty"
  ],
  "is_float_type": [
    "ty"
  ],
  "truncf_to_narrow": [
    "res_ty",
    "src",
    "loc",
    "ip"
  ],
  "extf_from_narrow": [
    "res_ty",
    "src",
    "loc",
    "ip"
  ],
  "bitcast": [
    "src",
    "res_elem_type"
  ],
  "cvtf": [
    "src",
    "res_elem_type"
  ],
  "fptoi": [
    "src",
    "signed",
    "res_elem_type"
  ],
  "itofp": [
    "src",
    "signed",
    "res_elem_type"
  ],
  "int_to_int": [
    "a",
    "dst_elem_type"
  ],
  "_cast": [
    "res_elem_ty",
    "src",
    "is_signed"
  ],
  "const": [
    "value",
    "ty"
  ],
  "_dispatch_to_rhs_r_op": [
    "op"
  ],
  "ArithValue": {
    "__init__": [
      "self",
      "v",
      "signed"
    ],
    "with_signedness": [
      "self",
      "signed"
    ],
    "__neg__": [
      "self"
    ],
    "__pow__": [
      "self",
      "other"
    ],
    "__rpow__": [
      "self",
      "other"
    ],
    "__add__": [
      "self",
      "other"
    ],
    "__sub__": [
      "self",
      "other"
    ],
    "__mul__": [
      "self",
      "other"
    ],
    "__truediv__": [
      "self",
      "other"
    ],
    "__floordiv__": [
      "self",
      "other"
    ],
    "__mod__": [
      "self",
      "other"
    ],
    "__radd__": [
      "self",
      "other"
    ],
    "__rsub__": [
      "self",
      "other"
    ],
    "__rmul__": [
      "self",
      "other"
    ],
    "__rtruediv__": [
      "self",
      "other"
    ],
    "__rfloordiv__": [
      "self",
      "other"
    ],
    "__rmod__": [
      "self",
      "other"
    ],
    "__lt__": [
      "self",
      "other"
    ],
    "__le__": [
      "self",
      "other"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__ne__": [
      "self",
      "other"
    ],
    "__gt__": [
      "self",
      "other"
    ],
    "__ge__": [
      "self",
      "other"
    ],
    "__invert__": [
      "self"
    ],
    "__and__": [
      "self",
      "other"
    ],
    "__or__": [
      "self",
      "other"
    ],
    "__xor__": [
      "self",
      "other"
    ],
    "__rshift__": [
      "self",
      "other"
    ],
    "__lshift__": [
      "self",
      "other"
    ],
    "__rand__": [
      "self",
      "other"
    ],
    "__ror__": [
      "self",
      "other"
    ],
    "__rxor__": [
      "self",
      "other"
    ],
    "__rrshift__": [
      "self",
      "other"
    ],
    "__rlshift__": [
      "self",
      "other"
    ],
    "__hash__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_min": [
    "lhs",
    "rhs"
  ],
  "_max": [
    "lhs",
    "rhs"
  ],
  "dsl_user_op": [
    "opFunc"
  ],
  "setup_log": [
    "name",
    "log_to_console",
    "log_to_file",
    "log_file_path",
    "log_level"
  ],
  "walk_to_top_module": [
    "start_path"
  ],
  "_filter_internal_frames": [
    "traceback",
    "internal_path"
  ],
  "_generated_function_names": [],
  "_filter_duplicated_frames": [
    "traceback"
  ],
  "filter_stackframe": [
    "traceback",
    "prefix_path"
  ],
  "filter_exception": [
    "value",
    "module_dir"
  ],
  "timer": [],
  "TensorDescriptor": {
    "__init__": [
      "self",
      "tensor"
    ],
    "can_transformed_to_dlpack": [
      "dl_tensor"
    ],
    "is_in_device": [
      "self"
    ],
    "device_id": [
      "self"
    ],
    "element_type": [
      "self"
    ],
    "shape": [
      "self"
    ],
    "rank": [
      "self"
    ],
    "strides": [
      "self"
    ],
    "element_size_in_bytes": [
      "self"
    ],
    "size_in_bytes": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "_check_is_managed_by_framework": [
      "self"
    ],
    "is_compatible": [
      "maybe_tensor_descriptor"
    ]
  },
  "from_tensor": [
    "tensor"
  ],
  "to_tensor": [
    "tensor_descriptor"
  ],
  "DLDeviceType": {
    "kDLCPU": [],
    "kDLGPU": [],
    "kDLCPUPinned": []
  },
  "DLDataTypeCode": {
    "kDLInt": [],
    "kDLUInt": [],
    "kDLFloat": [],
    "kDLOpaqueHandle": [],
    "kDLBfloat": [],
    "kDLComplex": [],
    "kDLBool": []
  },
  "allocate": [
    "tensor",
    "stream"
  ],
  "deallocate": [
    "tensor",
    "stream"
  ],
  "copy_to_gpu": [
    "tensor",
    "do_allocate",
    "stream"
  ],
  "copy_from_gpu": [
    "tensor",
    "do_deallocate",
    "stream"
  ],
  "to_gpu": [
    "tensor",
    "stream"
  ],
  "from_gpu": [
    "tensor",
    "stream"
  ],
  "is_arg_spec_constexpr": [
    "arg_spec",
    "arg_name",
    "arg_index",
    "owning_func"
  ],
  "is_argument_constexpr": [
    "arg",
    "arg_spec",
    "arg_name",
    "arg_index",
    "owning_func"
  ],
  "JitArgAdapterRegistry": {
    "jit_arg_adapter_registry": [],
    "register_jit_arg_adapter": [
      "cls"
    ],
    "get_registered_adapter": [
      "cls",
      "ty"
    ]
  },
  "_convert_python_scalar": [
    "arg"
  ],
  "_convert_python_sequence": [
    "arg"
  ],
  "_get_gpu_arch_info": [
    "major",
    "minor"
  ],
  "get_compute_capability_major_minor": [
    "device_id"
  ],
  "DeviceInfo": {
    "pretty_str": [
      "self"
    ]
  },
  "get_device_info": [],
  "load_cubin_module": [
    "cubin_file"
  ],
  "unload_cubin_module": [
    "module"
  ],
  "load_cubin_module_data": [
    "cubin_data"
  ],
  "get_kernel_function": [
    "module",
    "kernel_name"
  ],
  "launch_kernel": [
    "kernel",
    "grid_dims",
    "block_dims",
    "stream",
    "smem_size",
    "kernel_args"
  ],
  "stream_sync": [
    "stream"
  ],
  "stream_create": [
    "id"
  ],
  "stream_destroy": [
    "stream"
  ],
  "context_destroy": [
    "context"
  ],
  "memcpy_h2d": [
    "host_pointer",
    "device_pointer",
    "size_in_bytes",
    "stream"
  ],
  "memcpy_d2h": [
    "host_pointer",
    "device_pointer",
    "size_in_bytes",
    "stream"
  ],
  "get_driver_version": [],
  "set_kernel_attribute": [
    "kernel",
    "attribute",
    "value"
  ],
  "StreamAdapter": {
    "__init__": [
      "self",
      "arg"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "__c_pointers__": [
      "self"
    ],
    "__get_mlir_types__": [
      "self"
    ]
  },
  "shiftr": [
    "a",
    "s"
  ],
  "shiftl": [
    "a",
    "s"
  ],
  "LayoutBase": {},
  "is_layout": [
    "x"
  ],
  "hier_unzip": [
    "splitter",
    "layoutA",
    "layoutB"
  ],
  "is_int": [
    "x"
  ],
  "is_tuple": [
    "x"
  ],
  "signum": [
    "a"
  ],
  "inner_product": [
    "a",
    "b"
  ],
  "tuple_max": [
    "a"
  ],
  "elem_scale": [
    "a",
    "b"
  ],
  "prefix_product": [
    "a",
    "init"
  ],
  "idx2crd": [
    "idx",
    "shape",
    "stride"
  ],
  "crd2crd": [
    "crd",
    "dst_shape",
    "src_shape"
  ],
  "has_none": [
    "a"
  ],
  "project": [],
  "author": [],
  "release": [],
  "extensions": [],
  "source_suffix": [],
  "autodoc_typehints": [],
  "pygments_style": [],
  "pygments_dark_style": [],
  "templates_path": [],
  "exclude_patterns": [],
  "nbsphinx_allow_errors": [],
  "language": [],
  "html_static_path": [],
  "html_title": [],
  "html_baseurl": [],
  "html_theme": [],
  "html_theme_options": [],
  "InstallationTest": {
    "test_cutlass_source_paths": [
      "self"
    ]
  },
  "cc": [],
  "GemmS8Sm90": {},
  "add_test_specialized": [],
  "add_test_tensorop": [],
  "add_test_simt": [],
  "pytorch_reference": [
    "A",
    "B",
    "C",
    "alpha",
    "beta"
  ],
  "initialize": [
    "rows",
    "cols",
    "batch"
  ],
  "GemmF16Batched": {
    "run_batched": [
      "self",
      "batch_count",
      "batch_A",
      "batch_B",
      "batch_C"
    ],
    "test_batched_ABC": [
      "self"
    ],
    "test_batched_AB": [
      "self"
    ],
    "test_batched_AC": [
      "self"
    ],
    "test_batched_BC": [
      "self"
    ],
    "test_batched_A": [
      "self"
    ],
    "test_batched_B": [
      "self"
    ]
  },
  "GemmF16Sm80": {},
  "GemmF16Sm80StreamK": {},
  "add_test_streamk": [],
  "GemmF64Sm90": {},
  "GemmF32Sm80": {},
  "GemmF32Sm80StreamK": {},
  "GemmF64Sm80": {},
  "GemmF64Sm80StreamK": {},
  "LayoutCombination": {
    "NNN": [],
    "NNT": [],
    "NTN": [],
    "NTT": [],
    "TNN": [],
    "TNT": [],
    "TTN": [],
    "TTT": []
  },
  "get_name": [
    "layouts",
    "alignments",
    "element_output",
    "element_accumulator",
    "element_epilogue",
    "cluster_shape",
    "threadblock_shape",
    "stages",
    "element_a",
    "element_b",
    "element_c",
    "arch",
    "opclass",
    "kernel_schedule",
    "epilogue_schedule",
    "suffix"
  ],
  "add_test_gemm": [
    "cls",
    "cc",
    "element",
    "layouts",
    "alignments",
    "element_output",
    "element_accumulator",
    "cluster_shape",
    "threadblock_shape",
    "warp_count",
    "stages",
    "opclass",
    "swizzle",
    "kernel_schedule",
    "epilogue_schedule",
    "compilation_modes",
    "element_A",
    "element_B",
    "element_C"
  ],
  "GemmF8E4M3Sm90": {},
  "GemmF8E5M2Sm90": {},
  "GemmF16Sm90": {},
  "add_test_unit_cluster": [],
  "add_test_cluster_shape": [],
  "add_test_schedule": [],
  "GemmUniversalLauncher": {
    "__init__": [
      "self",
      "operation",
      "seed",
      "verification",
      "iterations",
      "compiler_mode"
    ],
    "print_problem_size": [
      "self",
      "p",
      "mode",
      "batch_count"
    ],
    "uniform_init": [
      "self",
      "shape",
      "dtype",
      "layout"
    ],
    "reference": [
      "self",
      "problem_size",
      "tensor_A",
      "tensor_B",
      "tensor_C",
      "alpha",
      "beta"
    ],
    "run": [
      "self",
      "mode",
      "problem_size",
      "batch_count",
      "split_k_slices",
      "alpha",
      "beta"
    ]
  },
  "test_all_gemm": [
    "operation",
    "testcase",
    "compilation_mode"
  ],
  "GemmS8Sm80": {},
  "GemmS8Sm80StreamK": {},
  "GemmMixedSm80": {},
  "add_test_mixed": [],
  "TestbedConv2dProblemSizes": {
    "__init__": [
      "self",
      "minimum_channel_size"
    ],
    "initialize_conv2d_default_sizes": [
      "self",
      "minimum_channel_size"
    ],
    "initialize_conv2d_rigorous_sizes": [
      "self",
      "minimum_channel_size"
    ],
    "initialize_conv2d_resnet50_sizes": [
      "self",
      "batch_size"
    ],
    "initialize_conv2d_grouped_sizes": [
      "self"
    ]
  },
  "Conv2dSm80": {},
  "conv_problems": [],
  "get_name_conv2d": [
    "arch",
    "conv_kind",
    "element",
    "element_accumulator",
    "element_output",
    "opclass",
    "threadblock_shape",
    "warp_count",
    "instruction_shape",
    "stages",
    "iterator_algorithm",
    "swizzle",
    "split_k_mode",
    "split_k_slices",
    "activation"
  ],
  "conv2d_few_channel_problemsizes": [
    "channels"
  ],
  "validate_problem_size": [
    "ps",
    "conv_kind",
    "split_k_slices"
  ],
  "Conv2dLauncherFrontend": {
    "__init__": [
      "self",
      "plan",
      "seed",
      "backend"
    ],
    "uniform_init": [
      "self",
      "size",
      "dtype"
    ],
    "reference": [
      "self",
      "ps",
      "A",
      "B",
      "C",
      "alpha",
      "beta",
      "activation"
    ],
    "run": [
      "self",
      "ps",
      "split_k_mode",
      "split_k_slices",
      "alpha",
      "beta"
    ]
  },
  "add_test": [
    "cls",
    "cc",
    "conv_kind",
    "problem_sizes",
    "element",
    "element_accumulator",
    "element_output",
    "opclass",
    "threadblock_shape",
    "warp_count",
    "instruction_shape",
    "stages",
    "iterator_algorithm",
    "swizzle",
    "split_k_mode",
    "split_k_slices",
    "activation"
  ],
  "get_conv_problems": [],
  "_initialize": [
    "dtype",
    "M",
    "N",
    "K"
  ],
  "_generate_problems": [
    "dtype",
    "num"
  ],
  "_generate_conv2d_problem": [
    "conv_kind",
    "dtype",
    "ps"
  ],
  "PyTorchExtensionTest": {
    "test_gemm": [
      "self"
    ],
    "test_grouped_gemm": [
      "self"
    ],
    "test_conv2d_fprop": [
      "self"
    ],
    "test_conv2d_dgrad": [
      "self"
    ],
    "test_conv2d_wgrad": [
      "self"
    ]
  },
  "ExpectException": {
    "__init__": [
      "self",
      "exception_expected",
      "message",
      "verify_msg"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "traceback"
    ]
  },
  "Conv2dEquivalence": {
    "__init__": [
      "self",
      "conv_kind",
      "element_A",
      "element_B",
      "element_C",
      "element_D",
      "element_accumulator",
      "alignment_A",
      "alignment_B",
      "alignment_C"
    ],
    "_plans_equal": [
      "self",
      "other_plan"
    ],
    "generic_test": [
      "self"
    ],
    "numpy_test": [
      "self"
    ],
    "torch_test": [
      "self"
    ],
    "tensor_test": [
      "self",
      "type_A",
      "type_B",
      "type_C",
      "type_D",
      "type_accum",
      "A",
      "B",
      "C",
      "D"
    ],
    "test_all": [
      "self"
    ]
  },
  "ConvEquivalenceTest": {},
  "type2alignment": [],
  "Conv2dErrorTests": {
    "test_alignment": [
      "self"
    ],
    "test_invalid_tile_description": [
      "self"
    ]
  },
  "GemmEquivalence": {
    "__init__": [
      "self",
      "element_A",
      "element_B",
      "element_C",
      "element_D",
      "element_accumulator",
      "layout_A",
      "layout_B",
      "layout_C",
      "alignment_A",
      "alignment_B",
      "alignment_C"
    ],
    "_plans_equal": [
      "self",
      "other_plan"
    ],
    "generic_test": [
      "self"
    ],
    "numpy_test": [
      "self"
    ],
    "test_all": [
      "self"
    ]
  },
  "GemmEquivalenceTest": {
    "test_gemm_equivalence_f16_f16_f16_f16_f16_ttt_8_8_8": [
      "self"
    ],
    "test_gemm_equivalence_f16_f16_f16_f16_f32_ntn_8_8_8": [
      "self"
    ],
    "test_gemm_equivalence_f16_f16_f16_f16_f16_ttt_4_4_4": [
      "self"
    ],
    "test_gemm_equivalence_f64_f64_f64_f64_f64_tnt_1_1_1": [
      "self"
    ]
  },
  "GemmErrorTests": {
    "test_alignment": [
      "self"
    ],
    "test_tensorop_availability": [
      "self"
    ],
    "test_opclass_switch": [
      "self"
    ],
    "test_invalid_tile_description": [
      "self"
    ]
  },
  "EVTErrorTests": {
    "test_root_not_d": [
      "self"
    ],
    "test_no_accum": [
      "self"
    ],
    "test_too_much_shared_memory": [
      "self"
    ],
    "test_not_ssa": [
      "self"
    ],
    "test_missing_example_tensor": [
      "self"
    ],
    "test_return_expression": [
      "self"
    ],
    "test_incompatible_shape": [
      "self"
    ],
    "test_no_matching_impl": [
      "self"
    ],
    "fake_tensor": [
      "self",
      "element",
      "shape"
    ]
  },
  "TestEVTMixed": {
    "test_same_variable_used_multiple_times": [
      "self"
    ],
    "test_no_lca": [
      "self"
    ],
    "test_mixed_dag": [
      "self"
    ],
    "test_mixed_dag_float": [
      "self"
    ],
    "test_mixed_dag_stage2": [
      "self"
    ],
    "test_mixed_dag_partition_k": [
      "self"
    ],
    "test_mixed_dag_stream_k": [
      "self"
    ],
    "test_mixed_dag_no_batch": [
      "self"
    ]
  },
  "TestEVTCompute": {
    "test_arith": [
      "self"
    ],
    "test_func_call": [
      "self"
    ],
    "test_func_call2": [
      "self"
    ],
    "test_tanh": [
      "self"
    ],
    "test_sigmoid": [
      "self"
    ],
    "test_gelu": [
      "self"
    ],
    "test_exp": [
      "self"
    ]
  },
  "TestEVTLoad": {
    "test_tensor_load": [
      "self"
    ],
    "test_row_broadcast": [
      "self"
    ],
    "test_column_broadcast": [
      "self"
    ],
    "test_scalar_broadcast": [
      "self"
    ]
  },
  "TestEVTLayout": {
    "test_permute_1": [
      "self"
    ],
    "test_permute_2": [
      "self"
    ],
    "test_permute_3": [
      "self"
    ],
    "test_reshape": [
      "self"
    ],
    "test_reshape2": [
      "self"
    ]
  },
  "TestEVTStore": {
    "test_invalid_store": [
      "self"
    ],
    "test_aux_store": [
      "self"
    ],
    "test_col_reduce": [
      "self"
    ],
    "test_row_reduce": [
      "self"
    ],
    "test_scalar_reduce": [
      "self"
    ]
  },
  "EVTReferenceModule": {
    "__init__": [
      "self",
      "layout_A",
      "layout_B",
      "layout_C",
      "epilogue_visitor"
    ],
    "run": [
      "self",
      "A",
      "B",
      "C",
      "problem_size",
      "alpha",
      "beta",
      "batch"
    ],
    "__call__": [
      "self",
      "A",
      "B",
      "C",
      "problem_size",
      "batch",
      "epilogue_args"
    ]
  },
  "EVTTestBed": {
    "__init__": [
      "self",
      "element",
      "evt_fn",
      "example_inputs",
      "profile"
    ],
    "get_torch_tensor": [
      "self",
      "shape",
      "dtype",
      "fill"
    ],
    "verify": [
      "self",
      "problem_size",
      "input_keys",
      "result_keys",
      "batch_count"
    ]
  },
  "EVTTestCaseBase": {
    "__init__": [
      "self",
      "methodName",
      "lmnk"
    ],
    "fake_tensor": [
      "self",
      "element",
      "shape",
      "stride"
    ],
    "get_problem_sizes": [
      "self",
      "alignment",
      "k",
      "batch_count"
    ]
  },
  "TestLeftInverse": {
    "helper_test_left_inverse": [
      "self",
      "layout"
    ],
    "test_left_inverse": [
      "self"
    ]
  },
  "TestComposition": {
    "helper_test_composition": [
      "self",
      "layoutA",
      "layoutB"
    ],
    "test_composition": [
      "self"
    ]
  },
  "TestRightInverse": {
    "helper_test_right_inverse": [
      "self",
      "layout"
    ],
    "test_right_inverse": [
      "self"
    ]
  },
  "TestTyping": {
    "helper_test_typing": [
      "self",
      "_cls",
      "_obj",
      "cls",
      "expected"
    ],
    "test_typing": [
      "self"
    ]
  },
  "TestCoalesce": {
    "helper_test_coalesce": [
      "self",
      "layout"
    ],
    "test_coalesce": [
      "self"
    ]
  },
  "TestIntTuple": {
    "test_product": [
      "self"
    ],
    "test_inner_product": [
      "self"
    ],
    "test_shape_div": [
      "self"
    ],
    "test_prefix_product": [
      "self"
    ]
  },
  "TestComplement": {
    "helper_test_complement": [
      "self",
      "layout"
    ],
    "test_complement": [
      "self"
    ]
  },
  "outputDir": [],
  "warpsPerThreadblockEdge": [],
  "warpsPerThreadblockRatio": [],
  "warpsPerThreadblockMax": [],
  "warpShapeEdges": [],
  "warpShapeRatio": [],
  "warpShapeMax": [],
  "warpShapeMin": [],
  "threadblockEdgeMax": [],
  "precisions": [],
  "transposes": [],
  "warpsPerThreadblocks": [],
  "warpNumThreads": [],
  "warpShapes": [],
  "numL0": [],
  "numL1": [],
  "numL2": [],
  "run": [
    "mnkl",
    "ab_dtype",
    "sf_dtype",
    "sf_vec_size",
    "c_dtype",
    "a_major",
    "b_major",
    "c_major",
    "mma_tiler_mn",
    "cluster_shape_mn",
    "tolerance",
    "warmup_iterations",
    "iterations",
    "skip_ref_check",
    "use_cold_l2"
  ],
  "FmhaStaticTileSchedulerParams": {
    "__init__": [
      "self",
      "is_persistent",
      "problem_shape_mbh"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ]
  },
  "create_fmha_static_tile_scheduler_params": [
    "is_persistent",
    "problem_shape_mbh"
  ],
  "FmhaStaticTileScheduler": {
    "__init__": [
      "self",
      "params",
      "current_work_linear_idx",
      "blk_coord",
      "grid_shape"
    ],
    "get_grid_shape": [
      "params"
    ],
    "check_valid_work_for_seqlen_q": [
      "q_tiler",
      "current_idx",
      "seqlen_q"
    ],
    "get_current_work": [
      "self"
    ],
    "initial_work_tile_info": [
      "self"
    ],
    "advance_to_next_work": [
      "self"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ]
  },
  "create_fmha_static_tile_scheduler": [
    "params",
    "blk_coord",
    "grid_shape"
  ],
  "MaskType": {
    "NO_MASK": [],
    "RESIDUAL_MASK": [],
    "CAUSAL_MASK": []
  },
  "make_thread_cooperative_group": [
    "size"
  ],
  "BlackwellFusedMultiHeadAttentionForward": {
    "__init__": [
      "self",
      "qk_acc_dtype",
      "pv_acc_dtype",
      "mma_tiler",
      "is_persistent",
      "mask_type"
    ],
    "_setup_attributes": [
      "self"
    ],
    "__call__": [
      "self",
      "q_iter",
      "k_iter",
      "v_iter",
      "o_iter",
      "problem_size",
      "cum_seqlen_q",
      "cum_seqlen_k",
      "scale_softmax_log2",
      "scale_output",
      "stream"
    ],
    "kernel": [
      "self",
      "qk_tiled_mma",
      "pv_tiled_mma",
      "tma_atom_q",
      "mQ_qdl",
      "tma_atom_k",
      "mK_kdl",
      "tma_atom_v",
      "mV_dkl",
      "tma_atom_o",
      "mO_qdl",
      "cum_seqlen_q",
      "cum_seqlen_k",
      "scale_softmax_log2",
      "scale_output",
      "q_smem_layout_staged",
      "k_smem_layout_staged",
      "p_tmem_layout_staged",
      "v_smem_layout_staged",
      "o_smem_layout_staged",
      "tile_sched_params"
    ],
    "softmax_step": [
      "self",
      "stage",
      "need_apply_mask",
      "iter_args",
      "value_args",
      "pipeline_args",
      "atom_args",
      "tensor_args"
    ],
    "softmax": [
      "self",
      "stage",
      "seqlen_k",
      "cum_seqlen_q",
      "cum_seqlen_k",
      "scale_softmax_log2",
      "qk_thr_mma",
      "tStS",
      "tStSi",
      "mma_si_consumer",
      "si_corr_producer",
      "s0_s1_sequence_consumer",
      "s0_s1_sequence_producer",
      "tile_sched_params"
    ],
    "correction_rescale": [
      "self",
      "thr_mma",
      "tOtO",
      "scale"
    ],
    "correction_epilog": [
      "self",
      "thr_mma",
      "tOtO",
      "scale",
      "sO"
    ],
    "get_trip_count": [
      "self",
      "blk_coord",
      "tile_shape",
      "seqlen_k"
    ],
    "get_masked_trip_count": [
      "self",
      "blk_coord",
      "tile_shape",
      "seqlen_k"
    ],
    "get_unmasked_trip_count": [
      "self",
      "blk_coord",
      "tile_shape",
      "seqlen_k"
    ],
    "apply_mask": [
      "self",
      "acc_qk",
      "index_qk",
      "seqlen_k"
    ],
    "_compute_grid": [
      "o_shape",
      "cta_tiler",
      "is_persistent"
    ]
  },
  "DenseGemmKernel": {
    "__init__": [
      "self",
      "acc_dtype",
      "use_2cta_instrs",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "use_tma_store"
    ],
    "_setup_attributes": [
      "self"
    ],
    "__call__": [
      "self",
      "a",
      "b",
      "c",
      "stream",
      "epilogue_op"
    ],
    "kernel": [
      "self",
      "tiled_mma",
      "tma_atom_a",
      "mA_mkl",
      "tma_atom_b",
      "mB_nkl",
      "tma_atom_c",
      "mC_mnl",
      "cluster_layout_vmnk",
      "a_smem_layout_staged",
      "b_smem_layout_staged",
      "c_smem_layout_staged",
      "epi_tile",
      "epilogue_op"
    ],
    "epilog_tmem_copy_and_partition": [
      "self",
      "tidx",
      "tAcc",
      "gC_mnl",
      "epi_tile",
      "use_2cta_instrs"
    ],
    "epilog_smem_copy_and_partition": [
      "self",
      "tiled_copy_t2r",
      "tTR_rC",
      "tidx",
      "sC"
    ],
    "epilog_gmem_copy_and_partition": [
      "self",
      "tidx",
      "atom",
      "gC_mnl",
      "epi_tile",
      "sC"
    ],
    "_compute_stages": [
      "tiled_mma",
      "mma_tiler_mnk",
      "a_dtype",
      "b_dtype",
      "epi_tile",
      "c_dtype",
      "c_layout",
      "smem_capacity",
      "occupancy",
      "use_tma_store"
    ],
    "_compute_grid": [
      "c",
      "cta_tile_shape_mnk",
      "cluster_shape_mn"
    ],
    "_compute_num_tmem_alloc_cols": [
      "tiled_mma",
      "mma_tiler"
    ],
    "is_valid_dtypes": [
      "ab_dtype",
      "acc_dtype",
      "c_dtype"
    ],
    "is_valid_mma_tiler_and_cluster_shape": [
      "use_2cta_instrs",
      "mma_tiler_mn",
      "cluster_shape_mn"
    ],
    "is_valid_tensor_alignment": [
      "m",
      "n",
      "k",
      "l",
      "ab_dtype",
      "c_dtype",
      "a_major",
      "b_major",
      "c_major"
    ],
    "is_valid_epilog_store_option": [
      "use_2cta_instrs",
      "use_tma_store",
      "m",
      "n",
      "mma_tiler_mn"
    ],
    "can_implement": [
      "ab_dtype",
      "acc_dtype",
      "c_dtype",
      "use_2cta_instrs",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "use_tma_store",
      "m",
      "n",
      "k",
      "l",
      "a_major",
      "b_major",
      "c_major"
    ]
  },
  "run_dense_gemm": [
    "mnkl",
    "ab_dtype",
    "c_dtype",
    "acc_dtype",
    "a_major",
    "b_major",
    "c_major",
    "mma_tiler_mn",
    "cluster_shape_mn",
    "use_2cta_instrs",
    "use_tma_store",
    "tolerance",
    "warmup_iterations",
    "iterations",
    "skip_ref_check"
  ],
  "GroupedGemmKernel": {
    "__init__": [
      "self",
      "acc_dtype",
      "use_2cta_instrs",
      "mma_tiler_mn",
      "cluster_shape_mn",
      "tensormap_update_mode"
    ],
    "_setup_attributes": [
      "self"
    ],
    "__call__": [
      "self",
      "initial_a",
      "initial_b",
      "initial_c",
      "group_count",
      "problem_shape_mnkl",
      "strides_abc",
      "tensor_address_abc",
      "total_num_clusters",
      "tensormap_cute_tensor",
      "max_active_clusters",
      "stream"
    ],
    "kernel": [
      "self",
      "tiled_mma",
      "tma_atom_a",
      "mA_mkl",
      "tma_atom_b",
      "mB_nkl",
      "tma_atom_c",
      "mC_mnl",
      "cluster_layout_vmnk",
      "a_smem_layout_staged",
      "b_smem_layout_staged",
      "epi_smem_layout_staged",
      "epi_tile",
      "tile_sched_params",
      "group_count",
      "problem_sizes_mnkl",
      "strides_abc",
      "ptrs_abc",
      "tensormaps"
    ],
    "make_tensor_for_tensormap_update": [
      "self",
      "group_idx",
      "dtype",
      "problem_shape_mnk",
      "strides_abc",
      "tensor_address_abc",
      "tensor_index"
    ],
    "epilog_tmem_copy_and_partition": [
      "self",
      "tidx",
      "tAcc",
      "gC_mnl",
      "epi_tile",
      "use_2cta_instrs"
    ],
    "epilog_smem_copy_and_partition": [
      "self",
      "tiled_copy_t2r",
      "tTR_rC",
      "tidx",
      "sC"
    ],
    "epilog_gmem_copy_and_partition": [
      "self",
      "tma_atom_c",
      "gC_mnl",
      "epi_tile",
      "sC"
    ],
    "_compute_stages": [
      "tiled_mma",
      "mma_tiler_mnk",
      "a_dtype",
      "b_dtype",
      "epi_tile",
      "c_dtype",
      "c_layout",
      "smem_capacity",
      "occupancy"
    ],
    "_compute_grid": [
      "total_num_clusters",
      "cluster_shape_mn",
      "max_active_clusters"
    ],
    "_get_mbar_smem_bytes": [],
    "_get_tensormap_smem_bytes": [
      "tensormap_update_mode"
    ],
    "_get_tensor_smem_bytes": [
      "a_smem_layout_staged",
      "a_dtype",
      "b_smem_layout_staged",
      "b_dtype",
      "epi_smem_layout_staged",
      "c_dtype"
    ],
    "_compute_num_tmem_alloc_cols": [
      "tiled_mma",
      "mma_tiler",
      "num_acc_stage"
    ],
    "reserved_smem_bytes": [],
    "bytes_per_tensormap": [],
    "num_tensormaps": [],
    "tensor_memory_management_bytes": []
  },
  "create_tensor_and_stride": [
    "l",
    "mode0",
    "mode1",
    "is_mode0_major",
    "dtype",
    "is_dynamic_layout",
    "torch_tensor_cpu"
  ],
  "create_tensors_for_all_groups": [
    "problem_sizes_mnkl",
    "ab_dtype",
    "c_dtype",
    "a_major",
    "b_major",
    "c_major",
    "torch_fp32_tensors_abc"
  ],
  "SSDKernel": {
    "__init__": [
      "self",
      "io_dtype",
      "cumsum_delta_dtype",
      "acc_dtype",
      "L",
      "D",
      "N",
      "has_d",
      "d_has_hdim"
    ],
    "_setup_attributes": [
      "self"
    ],
    "__call__": [
      "self",
      "x",
      "cumsum_delta",
      "delta",
      "b",
      "c",
      "y",
      "fstate",
      "d",
      "max_active_clusters",
      "stream"
    ],
    "kernel": [
      "self",
      "tma_atom_x",
      "tma_tensor_x",
      "tma_atom_b",
      "tma_tensor_b",
      "tma_atom_c",
      "tma_tensor_c",
      "tma_atom_p",
      "tma_tensor_p",
      "tma_atom_y",
      "tma_tensor_y",
      "tma_atom_delta",
      "tma_tensor_delta",
      "tma_atom_cumsum_delta",
      "tma_tensor_cumsum_delta",
      "tma_atom_d",
      "tma_tensor_d",
      "cluster_layout_vmnk",
      "x_smem_layout",
      "xt_smem_layout",
      "b_smem_layout",
      "bt_smem_layout",
      "bt_internal_smem_layout",
      "c_smem_layout",
      "pt_smem_layout",
      "p_smem_layout",
      "q_tmem_layout",
      "p_smem_layout_store",
      "y_smem_layout",
      "delta_linear_smem_layout",
      "cumsum_delta_linear_smem_layout",
      "d_linear_smem_layout",
      "epi_tile",
      "tile_sched_params"
    ],
    "_compute_stages": [
      "smem_capacity"
    ],
    "_compute_grid": [
      "y",
      "b",
      "max_active_clusters"
    ],
    "_plan_tmem_offsets": [
      "tiled_mma_intra1",
      "tile_shape_mnk_intra1",
      "tiled_mma_intra2",
      "tile_shape_mnk_intra2",
      "tiled_mma_inter1",
      "tile_shape_mnk_inter1",
      "tiled_mma_inter2",
      "tile_shape_mnk_inter2",
      "acc_stages",
      "intra2_a_tmem_layout",
      "a_dtype",
      "internal_stages",
      "intra1_acc_stages"
    ],
    "make_tiled_mmas": [
      "io_dtype",
      "acc_dtype",
      "cta_group",
      "tile_shape_mnk_intra1",
      "tile_shape_mnk_intra2",
      "tile_shape_mnk_inter1",
      "tile_shape_mnk_inter2"
    ],
    "make_and_init_x_pipeline": [
      "self",
      "x_full_mbar_ptr"
    ],
    "make_and_init_b_pipeline": [
      "self",
      "b_full_mbar_ptr"
    ],
    "make_and_init_c_pipeline": [
      "self",
      "c_full_mbar_ptr"
    ],
    "make_and_init_deltas_pipeline": [
      "self",
      "deltas_full_mbar_ptr"
    ],
    "make_and_init_d_pipeline": [
      "self",
      "d_full_mbar_ptr"
    ],
    "make_and_init_intra1_acc_pipeline": [
      "self",
      "intra1_acc_full_mbar_ptr"
    ],
    "make_and_init_intra2_q_pipeline": [
      "self",
      "intra2_q_full_mbar_ptr"
    ],
    "make_and_init_intra2_acc_pipeline": [
      "self",
      "intra2_acc_full_mbar_ptr"
    ],
    "make_and_init_inter1_b_pipeline": [
      "self",
      "inter1_b_full_mbar_ptr"
    ],
    "make_and_init_inter1_acc_pipeline": [
      "self",
      "inter1_acc_full_mbar_ptr"
    ],
    "make_and_init_inter2_p_pipeline": [
      "self",
      "inter2_p_full_mbar_ptr"
    ],
    "make_and_init_inter2_acc_pipeline": [
      "self",
      "inter2_acc_full_mbar_ptr"
    ],
    "tma_partition_for_mma_b_operand": [
      "self",
      "tma_atom_x",
      "tma_tensor_x",
      "smem_x",
      "tiled_mma_intra2",
      "cluster_layout_vmnk",
      "mma_tile_coord_v",
      "block_in_cluster_coord_vmnk"
    ],
    "tma_partition_for_mma_a_operand": [
      "self",
      "tma_atom_c",
      "tma_tensor_c",
      "smem_c",
      "tiled_mma_intra1",
      "cluster_layout_vmnk",
      "mma_tile_coord_v",
      "block_in_cluster_coord_vmnk"
    ],
    "tma_partition_with_shape": [
      "self",
      "tma_atom_delta",
      "tma_tensor_delta",
      "smem_delta",
      "shape"
    ],
    "mma_partition_ss": [
      "self",
      "tiled_mma",
      "tile_shape_mnk",
      "smem_a",
      "smem_b",
      "tmem_acc_ptr",
      "acc_stages"
    ],
    "mma_partition_ts": [
      "self",
      "tiled_mma",
      "tile_shape_mnk",
      "a_tmem_layout",
      "smem_b",
      "tmem_a_ptr",
      "tmem_acc_ptr",
      "acc_stages"
    ],
    "mma_partition_a_tmem": [
      "self",
      "tiled_mma",
      "a_tmem_layout",
      "tmem_a_ptr"
    ],
    "mma_partition_c": [
      "self",
      "tiled_mma",
      "tile_shape_mnk",
      "tmem_acc_ptr",
      "acc_stages"
    ],
    "exec_mma": [
      "self",
      "tiled_mma",
      "tCtAcc",
      "tCrA",
      "tCrB",
      "acc_producer_state",
      "a_consumer_state",
      "b_consumer_state"
    ],
    "conditional_consumer_try_wait": [
      "self",
      "b_consumer_state",
      "b_pipeline",
      "C"
    ],
    "conditional_producer_try_acquire": [
      "self",
      "intra1_acc_producer_state",
      "intra1_acc_pipeline",
      "C"
    ],
    "pre_intra_tmem_load_and_partition_q": [
      "self",
      "tIntra1",
      "local_tidx"
    ],
    "pre_intra_make_delta": [
      "self",
      "smem_delta",
      "extend_on_row_or_col"
    ],
    "pre_intra_tmem_store_and_partition_q": [
      "self",
      "local_tidx",
      "tCrQ"
    ],
    "pre_intra_segsum": [
      "self",
      "tTR_rQ",
      "tQrDeltaA_Row",
      "tQrDeltaA_Col",
      "tQrDelta",
      "tCoord",
      "tRT_rQ"
    ],
    "pre_inter_smem_load_and_partition_b": [
      "self",
      "local_tidx",
      "smem_bt"
    ],
    "pre_inter_smem_store_and_partition_b": [
      "self",
      "local_tidx",
      "smem_bt_internal",
      "tiled_s2r_b",
      "tBrB_s2r"
    ],
    "smem_load_and_partition_delta_d": [
      "self",
      "tiled_s2r_b",
      "local_tidx",
      "smem_delta",
      "smem_tile_coord"
    ],
    "pre_inter_tmem_load_and_partition_p": [
      "self",
      "local_tidx",
      "tInter1",
      "smem_pt"
    ],
    "make_tmem_load_and_partition": [
      "self",
      "copy_atom_t2r",
      "tmem_tensor",
      "tmem_tile_coord",
      "local_tidx",
      "smem_tensor"
    ],
    "smem_store_and_partition_p_y": [
      "self",
      "local_tidx",
      "smem_pt",
      "tiled_t2r_inter1"
    ],
    "pre_inter_make_delta": [
      "self",
      "smem_delta",
      "smem_bt_layout"
    ],
    "pre_inter_scale_bt_with_delta": [
      "self",
      "tBrB_s2r",
      "tBrDelta_s2r",
      "tBrDeltaA_s2r",
      "last_column"
    ],
    "epilog_make_delta": [
      "self",
      "smem_cumsum_delta"
    ],
    "epilog_make_d": [
      "self",
      "smem_d"
    ],
    "epilog_tma_partition_y": [
      "self",
      "tma_tensor_y",
      "tma_atom_y",
      "smem_y",
      "epi_tile"
    ],
    "epilog_smem_load_and_partition_x": [
      "self",
      "tiled_t2r_inter2_intra2",
      "local_tidx",
      "smem_xt",
      "epi_tile"
    ],
    "epilog_tmem_load_and_partition_acc": [
      "self",
      "local_tidx",
      "tIntra",
      "smem_y"
    ]
  },
  "ssd_reference_fp32_all": [
    "x",
    "a",
    "delta",
    "B",
    "C",
    "Y_out",
    "Fstate_out",
    "D",
    "has_d",
    "d_has_hdim"
  ],
  "ssd_reference_lowprecision_intermediates": [
    "x",
    "a",
    "delta",
    "B",
    "C",
    "Y_out",
    "Fstate_out",
    "intermediate_dtype",
    "D",
    "has_d",
    "d_has_hdim"
  ],
  "analyze_relative_diffs": [
    "actual",
    "expected"
  ],
  "segsum": [
    "x"
  ],
  "ssd_minimal_discrete_fp32_all": [
    "X",
    "A",
    "B",
    "C",
    "block_len",
    "initial_states"
  ],
  "ssd_minimal_discrete_lowprecision_intermediates": [
    "X",
    "A",
    "delta",
    "B",
    "C",
    "block_len",
    "intermediate_dtype",
    "initial_states"
  ],
  "Mamba2SSDTileSchedulerParams": {
    "__init__": [
      "self",
      "problem_shape_ntiles",
      "eh",
      "ngroup_ratio"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "get_grid_shape": [
      "self",
      "max_active_clusters"
    ]
  },
  "Mamba2SSDTileScheduler": {
    "__init__": [
      "self",
      "params",
      "num_persistent_ctas",
      "current_work_linear_idx",
      "num_tiles_executed"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "create": [
      "params",
      "block_idx",
      "grid_dim"
    ],
    "get_grid_shape": [
      "params",
      "max_active_clusters"
    ],
    "_get_current_work_for_linear_idx": [
      "self",
      "current_work_linear_idx"
    ],
    "get_current_work": [
      "self"
    ],
    "initial_work_tile_info": [
      "self"
    ],
    "advance_to_next_work": [
      "self"
    ],
    "num_tiles_executed": [
      "self"
    ]
  },
  "ExampleTensorValue": {
    "__init__": [
      "self",
      "v"
    ],
    "data_ptr": [
      "self"
    ],
    "shape": [
      "self"
    ],
    "stride": [
      "self"
    ]
  },
  "ExampleTensor": {
    "__init__": [
      "self",
      "c_struct_p",
      "rank"
    ],
    "__get_mlir_types__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ],
    "__c_pointers__": [
      "self"
    ]
  },
  "foo": [
    "tensor"
  ],
  "run_test": [
    "tmpdir"
  ],
  "SharedData": {},
  "kernel_no_smem": [],
  "BufferWithLayout": {
    "__init__": [
      "self",
      "ptr",
      "stride_order"
    ],
    "to_tensor": [
      "self",
      "shape"
    ],
    "__c_pointers__": [
      "self"
    ],
    "__get_mlir_types__": [
      "self"
    ],
    "__extract_mlir_values__": [
      "self"
    ],
    "__new_from_mlir_values__": [
      "self",
      "values"
    ]
  },
  "tensor_op_gemm_wrapper": [
    "buffer_a",
    "buffer_b",
    "buffer_c",
    "mnkl",
    "acc_dtype",
    "atom_layout_mnk"
  ],
  "run_tensor_op_gemm_wrapper": [
    "mnkl"
  ],
  "elementwise_add_kernel": [
    "gA",
    "gB",
    "gC",
    "cC",
    "shape",
    "thr_layout",
    "val_layout"
  ],
  "elementwise_add": [
    "mA",
    "mB",
    "mC",
    "copy_bits"
  ],
  "run_elementwise_add": [
    "M",
    "N",
    "dtype",
    "is_a_dynamic_layout",
    "is_b_dynamic_layout",
    "is_result_dynamic_layout",
    "skip_ref_check",
    "benchmark",
    "warmup_iterations",
    "iterations"
  ],
  "TensorOpGemm": {
    "__init__": [
      "self",
      "ab_dtype",
      "c_dtype",
      "acc_dtype",
      "atom_layout_mnk"
    ],
    "__call__": [
      "self",
      "mA",
      "mB",
      "mC",
      "epilogue_op"
    ],
    "kernel": [
      "self",
      "mA",
      "mB",
      "mC",
      "sA_layout",
      "sB_layout",
      "sC_layout",
      "tiled_copy_A",
      "tiled_copy_B",
      "tiled_copy_C",
      "tiled_mma",
      "rasterization_factor",
      "epilogue_op"
    ],
    "_make_smem_layout_AB": [
      "self",
      "dtype",
      "major_mode",
      "copy_bits",
      "smem_tiler"
    ],
    "_make_smem_layout_C": [
      "self",
      "dtype",
      "major_mode",
      "copy_bits",
      "smem_tiler"
    ],
    "_make_gmem_tiled_copy_AB": [
      "self",
      "atom_copy",
      "dtype",
      "major_mode",
      "copy_bits"
    ],
    "_make_gmem_tiled_copy_C": [
      "self",
      "atom_copy",
      "dtype",
      "major_mode",
      "copy_bits"
    ],
    "raster_tile": [
      "self",
      "i",
      "j",
      "f"
    ]
  },
  "complex": {},
  "SharedStorage": {},
  "run_allocation_kernel": [
    "const_a",
    "dst_a",
    "const_b",
    "dst_b",
    "const_c",
    "dst_c"
  ],
  "veify_allocation_kernel": [
    "const_a",
    "const_b",
    "const_c"
  ],
  "FlashAttentionForwardAmpere": {
    "__init__": [
      "self",
      "head_dim",
      "m_block_size",
      "n_block_size",
      "num_threads",
      "is_causal"
    ],
    "can_implement": [
      "dtype",
      "head_dim",
      "m_block_size",
      "n_block_size",
      "num_threads",
      "is_causal"
    ],
    "__call__": [
      "self",
      "mQ",
      "mK",
      "mV",
      "mO",
      "softmax_scale",
      "stream"
    ],
    "kernel": [
      "self",
      "mQ",
      "mK",
      "mV",
      "mO",
      "softmax_scale_log2",
      "sQ_layout",
      "sKV_layout",
      "sO_layout",
      "gmem_tiled_copy_QKV",
      "gmem_tiled_copy_O",
      "tiled_mma",
      "SharedStorage"
    ],
    "compute_one_n_block": [
      "self",
      "basic_params",
      "mma_params",
      "gmem_copy_params",
      "smem_copy_params",
      "softmax_params",
      "is_first_n_block",
      "in_mask_steps"
    ],
    "softmax_rescale_O": [
      "self",
      "basic_params",
      "mma_params",
      "softmax_params",
      "acc_S",
      "is_first_n_block",
      "in_mask_steps"
    ],
    "normalize_softmax": [
      "self",
      "acc_O",
      "row_sum"
    ],
    "_make_acc_tensor_mn_view": [
      "self",
      "acc"
    ],
    "_threadquad_reduce": [
      "self",
      "val",
      "op"
    ],
    "_threadquad_reduce_max": [
      "self",
      "val"
    ],
    "_threadquad_reduce_sum": [
      "self",
      "val"
    ]
  },
  "elementwise_apply_kernel": [
    "op",
    "inputs",
    "gC",
    "cC",
    "shape",
    "tv_layout"
  ],
  "elementwise_apply": [
    "op",
    "a",
    "b",
    "result",
    "stream"
  ],
  "run_elementwise_apply_and_verify": [
    "op",
    "M",
    "N",
    "dtype",
    "skip_ref_check",
    "benchmark",
    "warmup_iterations",
    "iterations"
  ],
  "SGemm": {
    "__init__": [
      "self",
      "cta_tiler",
      "num_stages",
      "num_threads"
    ],
    "__call__": [
      "self",
      "mA",
      "mB",
      "mC",
      "epilogue_op",
      "stream"
    ],
    "kernel": [
      "self",
      "mA",
      "mB",
      "mC",
      "sA_layout",
      "sB_layout",
      "tiled_copy_A",
      "tiled_copy_B",
      "tiled_mma",
      "epilogue_op"
    ]
  },
  "parse_comma_separated_ints": [
    "s"
  ],
  "parse_arguments": [],
  "HopperWgmmaGemmKernel": {
    "__init__": [
      "self",
      "acc_dtype",
      "tile_shape_mn",
      "cluster_shape_mn"
    ],
    "_setup_attributes": [
      "self"
    ],
    "__call__": [
      "self",
      "a",
      "b",
      "c",
      "stream"
    ],
    "kernel": [
      "self",
      "tma_atom_a",
      "mA_mkl",
      "tma_atom_b",
      "mB_nkl",
      "tma_atom_c",
      "mC_mnl",
      "tiled_mma",
      "cta_layout_mnk",
      "a_smem_layout_staged",
      "b_smem_layout_staged",
      "epi_smem_layout_staged"
    ],
    "_compute_stages": [
      "tile_shape_mnk",
      "a_dtype",
      "b_dtype",
      "smem_capacity",
      "occupancy"
    ],
    "_sm90_compute_tile_shape_or_override": [
      "tile_shape_mnk",
      "element_type",
      "is_cooperative",
      "epi_tile_override"
    ],
    "_make_smem_layouts": [
      "tile_shape_mnk",
      "epi_tile",
      "a_dtype",
      "a_layout",
      "b_dtype",
      "b_layout",
      "ab_stage",
      "c_dtype",
      "c_layout",
      "epi_stage"
    ],
    "_compute_grid": [
      "c",
      "tile_shape_mnk",
      "cluster_shape_mn"
    ],
    "_make_tma_store_atoms_and_tensors": [
      "tensor_c",
      "epi_smem_layout_staged",
      "epi_tile"
    ],
    "_make_tma_atoms_and_tensors": [
      "tensor",
      "smem_layout_staged",
      "smem_tile",
      "mcast_dim"
    ],
    "is_valid_dtypes": [
      "a_dtype",
      "b_dtype",
      "acc_dtype",
      "c_dtype",
      "a_major",
      "b_major"
    ]
  },
  "fuse_gemm_info": [],
  "AnalysisNodeVisitor": {
    "visit_Import": [
      "self",
      "node"
    ],
    "visit_ImportFrom": [
      "self",
      "node"
    ],
    "visit_Assign": [
      "self",
      "node"
    ],
    "visit_BinOp": [
      "self",
      "node"
    ],
    "visit_Expr": [
      "self",
      "node"
    ],
    "visit_Num": [
      "self",
      "node"
    ],
    "visit_Name": [
      "self",
      "node"
    ],
    "visit_Str": [
      "self",
      "node"
    ]
  },
  "CodeVisitor": {
    "visit_BinOp": [
      "self",
      "node"
    ],
    "visit_Assign": [
      "self",
      "node"
    ],
    "visit_Name": [
      "self",
      "node"
    ],
    "visit_FunctionDef": [
      "self",
      "node"
    ]
  },
  "visitor": [],
  "code": [],
  "gen_build_sys": {
    "__init__": [
      "self",
      "cutlass_deps_dir",
      "output_dir"
    ],
    "gen_top": [
      "self"
    ],
    "gen_code": [
      "self"
    ]
  },
  "gen_default_Gemm": {
    "__init__": [
      "self",
      "template_param",
      "gen_class_name",
      "b2b_num",
      "cutlass_deps_root",
      "project_root"
    ],
    "gen_B2bMma": [
      "self",
      "specialized_template_args"
    ],
    "gen_epilogue": [
      "self"
    ],
    "gen_include_header": [
      "self"
    ],
    "gen_code": [
      "self"
    ]
  },
  "gen_Kernel": {
    "__init__": [
      "self",
      "template_param",
      "gen_class_name",
      "b2b_num",
      "cutlass_deps_root",
      "project_root"
    ],
    "gen_include_header": [
      "self"
    ],
    "gen_Params": [
      "self"
    ],
    "gen_Memberfunc": [
      "self"
    ],
    "gen_using": [
      "self"
    ],
    "gen_can_implement": [
      "self"
    ],
    "gen_operator_and_constr": [
      "self"
    ],
    "gen_code": [
      "self"
    ]
  },
  "gen_kernel": {
    "__init__": [
      "self",
      "template_param",
      "gen_class_name",
      "b2b_num",
      "output_dir",
      "cutlass_deps_root",
      "project_root"
    ],
    "gen_code": [
      "self",
      "first_use_1stage"
    ]
  },
  "gen_device": {
    "__init__": [
      "self",
      "fuse_gemm_info",
      "gen_class_name",
      "user_header_file",
      "cutlass_deps_root",
      "project_root",
      "output_dir"
    ],
    "__check_arg_type": [
      "self",
      "temp_arg"
    ],
    "set_arch": [
      "self",
      "sm_cap",
      "mma_tp"
    ],
    "gen_include_header": [
      "self"
    ],
    "gen_code": [
      "self",
      "sm_cap",
      "mma_tp",
      "ifprint"
    ],
    "update_b2b_class_template_args": [
      "self"
    ],
    "update_b2b_args": [
      "self"
    ],
    "gen_using_kernel": [
      "self"
    ],
    "gen_args": [
      "self"
    ],
    "gen_func_constructs": [
      "self"
    ],
    "gen_func_initialize": [
      "self"
    ],
    "gen_func_run": [
      "self"
    ],
    "gen_func_operator": [
      "self"
    ],
    "gen_all_func": [
      "self"
    ]
  },
  "indentation": [],
  "append_word": [
    "word"
  ],
  "gen_namespace": [
    "namespace",
    "codeBody"
  ],
  "gen_expression": [
    "type",
    "lval",
    "rval"
  ],
  "gen_class": [
    "name",
    "codeBody",
    "inheritance_code"
  ],
  "gen_struct": [
    "name",
    "codeBody",
    "specialized"
  ],
  "gen_template_arg": [
    "arg_type",
    "arg_name",
    "default_val"
  ],
  "gen_template_args": [
    "args",
    "set_default"
  ],
  "gen_template_head": [
    "args",
    "set_default"
  ],
  "export_template_args": [
    "args"
  ],
  "gen_template_class": [
    "class_name",
    "args",
    "codeBody",
    "set_default",
    "inheritance_code"
  ],
  "gen_template_struct": [
    "struct_name",
    "args",
    "codeBody",
    "speicalized",
    "set_default",
    "export_args"
  ],
  "gen_declare_template_struct": [
    "name"
  ],
  "filtered_param": [
    "params",
    "name_and_value_pair",
    "keep_"
  ],
  "gen_func": [
    "func_name",
    "arg_lists",
    "code_body",
    "only_declare",
    "with_cudaStream"
  ],
  "indent_level": [
    "code",
    "level"
  ],
  "gen_verify": {
    "__init__": [
      "self",
      "fuse_gemm_info",
      "gen_class_name",
      "user_header_file",
      "output_dir"
    ],
    "gen_code": [
      "self"
    ],
    "gen_params": [
      "self"
    ],
    "get_params": [
      "self",
      "declaration"
    ],
    "gen_initialize": []
  },
  "replace_fix_impl": {
    "__init__": [
      "self",
      "src_dir",
      "dst_dir",
      "cutlass_deps_root"
    ],
    "gen_code": [
      "self"
    ]
  },
  "parser": [],
  "args": [],
  "gen_name": [],
  "cutlass_deps_dir": [],
  "output_dir": [],
  "cutlass_deps_root": [],
  "keys": [],
  "for_cutlass_gen_user_include_header_file": [],
  "for_fused_wrapper": [],
  "fix_impl": [],
  "auto_gen_output_dir": [],
  "project_root": [],
  "turing_plus": [],
  "api": [],
  "sample_dir": [],
  "sample": [],
  "cmake_gen": [],
  "verify": [],
  "gen_test": {
    "__init__": [
      "self",
      "fuse_gemm_info",
      "gen_class_name",
      "user_header_file",
      "output_dir"
    ],
    "gen_cpp_sample": [
      "self"
    ]
  },
  "gen_default_b2b_mma": {
    "__init__": [
      "self",
      "template_param",
      "gen_class_name",
      "b2b_num",
      "cutlass_deps_root",
      "project_root"
    ],
    "gen_include_header": [
      "self"
    ],
    "gen_using_MmaCore": [
      "self",
      "stage"
    ],
    "gen_using_FusedAddBiasEpilogue": [
      "self"
    ],
    "gen_using_Iterator": [
      "self"
    ],
    "gen_fragment_iterator": [
      "self"
    ],
    "gen_threadblockmma": [
      "self"
    ],
    "gen_code": [
      "self"
    ]
  },
  "gen_b2b_mme_pipelined": {
    "__init__": [
      "self",
      "template_param",
      "gen_class_name",
      "b2b_num",
      "cutlass_deps_root",
      "project_root"
    ],
    "gen_include_header": [
      "self"
    ],
    "gen_using": [
      "self"
    ],
    "gen_operator": [
      "self",
      "first_use_1stage"
    ],
    "gen_construct_func": [
      "self"
    ],
    "gen_member_func": [
      "self",
      "first_use_1stage"
    ],
    "gen_code": [
      "self",
      "first_use_1stage"
    ]
  },
  "gen_b2b_mma_base": {
    "__init__": [
      "self",
      "template_param",
      "gen_class_name",
      "b2b_num",
      "cutlass_deps_root",
      "project_root"
    ],
    "gen_include_header": [
      "self"
    ],
    "gen_shared_storage": [
      "self"
    ],
    "gen_using_and_misc": [
      "self",
      "b2b_num"
    ],
    "gen_protected": [
      "self"
    ],
    "gen_public_member": [
      "self"
    ],
    "gen_code": [
      "self"
    ]
  },
  "gen_threadblock": {
    "__init__": [
      "self",
      "template_param",
      "gen_class_name",
      "b2b_num",
      "output_dir",
      "cutlass_deps_root",
      "project_root"
    ],
    "gen_code": [
      "self",
      "first_use_1stage"
    ]
  },
  "gen_turing_impl": {
    "__init__": [
      "self",
      "fuse_gemm_info",
      "gen_class_name",
      "user_header_file",
      "output_dir"
    ],
    "gen_using": [
      "self"
    ],
    "gen_initialize": [
      "self"
    ],
    "gen_run": [
      "self"
    ],
    "gen_wrapper": [
      "self"
    ],
    "gen_code": [
      "self"
    ]
  },
  "gen_volta_turing_fuse_act_impl": {
    "__init__": [
      "self",
      "fuse_gemm_info",
      "gen_class_name",
      "user_header_file",
      "output_dir"
    ],
    "perf_tiling": [
      "self",
      "layer_mnk"
    ],
    "process_epilogue": [
      "self",
      "epilogue_tp",
      "n",
      "C_tp",
      "Acc_tp"
    ],
    "gen_using": [
      "self",
      "volta"
    ],
    "gen_initialize": [
      "self"
    ],
    "gen_run": [
      "self"
    ],
    "gen_wrapper": [
      "self"
    ],
    "gen_code": [
      "self"
    ]
  },
  "gen_one_API": {
    "__init__": [
      "self",
      "fuse_gemm_info",
      "gen_class_name",
      "user_header_file",
      "output_dir"
    ],
    "gen_CUTLASS_irrelevant_API": [
      "self"
    ],
    "gen_one_api": [
      "self"
    ],
    "gen_code": [
      "self"
    ]
  },
  "type_2_cutlass_type": [
    "input_type"
  ],
  "cvt_2_cutlass_shape": [
    "gemm_shape"
  ],
  "write_2_headfile": [
    "filename",
    "file_dir",
    "string"
  ],
  "var_idx": [
    "variable",
    "index"
  ],
  "list_2_string": [
    "input_list"
  ],
  "get_epilogue_info": [
    "layer_info"
  ],
  "get_epilogue_tp": [
    "layer_info"
  ],
  "get_epilogue_add_bias_or_not": [
    "layer_info"
  ],
  "get_epilogue_add_bias_tp": [
    "layer_info"
  ],
  "get_epilogue_args": [
    "layer_info"
  ],
  "get_epilogue_bias_shape": [
    "layer_info"
  ],
  "get_epilogue_bias_ldm": [
    "layer_info"
  ],
  "get_epilogue_compute_tp": [
    "layer_info"
  ],
  "TORCH_DTYPE_NAME": [],
  "NAME_TORCH_DTYPE": [],
  "_tensor_from_storage": [
    "tensor",
    "dtype"
  ],
  "PipedSubprocess": {
    "__init__": [
      "self",
      "binary"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "temp_filename": [
      "self",
      "suffix"
    ],
    "write": [
      "self"
    ],
    "writeTensor": [
      "self",
      "tensor",
      "name",
      "stride_names"
    ],
    "readTensor": [
      "self",
      "name",
      "stride_name",
      "shape"
    ],
    "readNamed": [
      "self",
      "name"
    ],
    "readExpect": [
      "self",
      "what"
    ],
    "read": [
      "self"
    ]
  },
  "causal": [],
  "repeat_count": [],
  "ATOL": [],
  "RTOL": [],
  "fmha_bw_binary": [],
  "create_lower_triangular_mask": [],
  "ref_mha_bmk": [
    "q",
    "k",
    "v",
    "mask"
  ],
  "bmhk2bmk": [
    "t"
  ],
  "ref_mha_bmhk": [
    "q",
    "k",
    "v",
    "mask"
  ],
  "ref_mha_bw_bmhk": [
    "q",
    "k",
    "v",
    "mask",
    "lse",
    "out",
    "grad_out",
    "delta"
  ],
  "query": [],
  "key": [],
  "value": [],
  "mask": [],
  "out": [],
  "grad_out": [],
  "scale": [],
  "delta": [],
  "pad_amount": [],
  "lse": [],
  "float_ops": [],
  "alignment": [],
  "A": [],
  "B": [],
  "C": [],
  "element_acc": [],
  "element_epilogue": [],
  "math_inst": [],
  "tile_description": [],
  "epilogue_functor": [],
  "operation": [],
  "operations": [],
  "problem_size": [],
  "tensor_A_size": [],
  "tensor_B_size": [],
  "tensor_C_size": [],
  "tensor_A": [],
  "tensor_B": [],
  "tensor_C": [],
  "tensor_D": [],
  "alpha": [],
  "beta": [],
  "arguments": [],
  "reference": [],
  "tensor_D_ref": [],
  "problem_sizes": [],
  "problem_count": [],
  "tensor_As": [],
  "tensor_Bs": [],
  "tensor_Cs": [],
  "tensor_Ds": [],
  "tensor_D_refs": [],
  "element_a": [],
  "element_b": [],
  "element_c": [],
  "math_operation": [],
  "opclass": [],
  "layout_a": [],
  "layout_b": [],
  "layout_c": [],
  "iterator_algorithm": [],
  "swizzling_functor": [],
  "stride_support": [],
  "conv_kind": [],
  "tensor_D_size": [],
  "reference_model": [],
  "precompute_mode": [],
  "reference_module": [],
  "problem_sizes_coord": [],
  "tensor_a_size": [],
  "tensor_b_size": [],
  "output_op": [],
  "Testcase": {
    "__init__": [
      "self",
      "prefix_text"
    ]
  },
  "ParseState": {
    "Filler": [],
    "InTest": [],
    "TestDeclaredWaitingStart": []
  },
  "cmake_src_list": [],
  "base_path": [],
  "config_h": [],
  "data": [],
  "reg": [],
  "decode_tag": [
    "tag",
    "num_blocks",
    "num_groups"
  ],
  "export_to_perfetto_trace": [
    "profiler_buffer",
    "event_names",
    "file_name"
  ],
  "FusionRule": {},
  "joint_topk_topp_sampleprobs_guard": [
    "window"
  ],
  "build_temperature_softmax": [
    "window"
  ],
  "build_topk_sampling": [
    "window"
  ],
  "build_topp_sampling": [
    "window"
  ],
  "build_minp_sampling": [
    "window"
  ],
  "get_default_fusion_rules": [],
  "LegalizationError": {},
  "legalize_processors": [
    "processors",
    "initial_type"
  ],
  "infer_initial_type": [
    "processors"
  ],
  "_get_supported_types": [
    "processor"
  ],
  "validate_processor_chain": [
    "processors"
  ],
  "TemperatureOp": {
    "IN": [],
    "OUT": [],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "SoftmaxOp": {
    "IN": [],
    "OUT": [],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "ProbsTopKOp": {
    "IN": [],
    "OUT": [],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "LogitsTopKOp": {
    "IN": [],
    "OUT": [],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "TopPOp": {
    "IN": [],
    "OUT": [],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "MinPOp": {
    "IN": [],
    "OUT": [],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "ProbsSampleOp": {
    "IN": [],
    "OUT": [],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "LogitsSampleOp": {
    "IN": [],
    "OUT": [],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "FusedTemperatureSoftmaxOp": {
    "IN": [],
    "OUT": [],
    "__init__": [
      "self",
      "enable_pdl"
    ],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "FusedProbsTopKSampleOp": {
    "IN": [],
    "OUT": [],
    "__init__": [
      "self",
      "deterministic"
    ],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "FusedProbsTopPSampleOp": {
    "IN": [],
    "OUT": [],
    "__init__": [
      "self",
      "deterministic"
    ],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "FusedProbsMinPSampleOp": {
    "IN": [],
    "OUT": [],
    "__init__": [
      "self",
      "deterministic"
    ],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "FusedProbsTopKTopPSampleOp": {
    "IN": [],
    "OUT": [],
    "__init__": [
      "self",
      "deterministic"
    ],
    "__call__": [
      "self",
      "tensor"
    ]
  },
  "LogitsPipe": {
    "__init__": [
      "self",
      "processors",
      "compile",
      "input_type",
      "custom_fusion_rules",
      "custom_validity_checks"
    ],
    "__repr__": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "initial_type": [
      "self"
    ],
    "compile": [
      "self",
      "custom_fusion_rules",
      "custom_validity_checks"
    ]
  },
  "ParameterizedOp": {
    "__init__": [
      "self"
    ],
    "_get_param": [
      "self",
      "name",
      "kwargs",
      "required"
    ]
  },
  "TensorType": {
    "LOGITS": [],
    "PROBS": [],
    "INDICES": [],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "TaggedTensor": {
    "logits": [
      "t"
    ],
    "probs": [
      "t"
    ],
    "indices": [
      "t"
    ],
    "__torch_function__": [
      "self",
      "func",
      "types",
      "args",
      "kwargs"
    ],
    "shape": [
      "self"
    ],
    "device": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "size": [
      "self",
      "dim"
    ],
    "__repr__": [
      "self"
    ]
  },
  "compile_pipeline": [
    "ops",
    "custom_fusion_rules",
    "custom_validity_checks"
  ],
  "CompileError": {},
  "ValidityCheck": [],
  "single_softmax_rule": [
    "ops"
  ],
  "indices_terminal_rule": [
    "ops"
  ],
  "get_default_validity_checks": [],
  "validate_pipeline": [
    "ops",
    "custom_checks"
  ],
  "LogitsProcessor": {
    "__init__": [
      "self"
    ],
    "legalize": [
      "self",
      "input_type"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Temperature": {
    "__init__": [
      "self"
    ],
    "legalize": [
      "self",
      "input_type"
    ]
  },
  "Softmax": {
    "__init__": [
      "self",
      "enable_pdl"
    ],
    "legalize": [
      "self",
      "input_type"
    ]
  },
  "TopK": {
    "__init__": [
      "self",
      "joint_topk_topp"
    ],
    "legalize": [
      "self",
      "input_type"
    ]
  },
  "TopP": {
    "__init__": [
      "self"
    ],
    "legalize": [
      "self",
      "input_type"
    ]
  },
  "MinP": {
    "__init__": [
      "self"
    ],
    "legalize": [
      "self",
      "input_type"
    ]
  },
  "Sample": {
    "__init__": [
      "self",
      "deterministic"
    ],
    "legalize": [
      "self",
      "input_type"
    ]
  },
  "H_SMEM_PADDING": [],
  "H_SMEM_STRIDE": [],
  "write_h_chunk_to_smem": [
    "h_chunk_f32",
    "h_sh_chunk",
    "lane_idx",
    "k_base"
  ],
  "store_h_smem_to_gmem": [
    "h_sh_chunk",
    "h_out",
    "tidx",
    "v_row_offset"
  ],
  "load_h_chunk_async": [
    "h_sh_chunk",
    "h_global",
    "tidx",
    "row_offset"
  ],
  "compute_single_gate": [
    "alpha",
    "beta_raw",
    "dt_bias_val",
    "A_log_val",
    "softplus_beta",
    "softplus_threshold"
  ],
  "normalize_and_store_qk_to_smem": [
    "q_head",
    "k_head",
    "q_sh",
    "k_sh",
    "lane_idx",
    "scale",
    "eps"
  ],
  "load_v_to_smem": [
    "v_head",
    "v_sh",
    "tidx"
  ],
  "load_kq_chunk_from_smem": [
    "kq_sh",
    "kq_chunk",
    "k_base"
  ],
  "decay_h_from_smem_and_compute_pred": [
    "h_sh_chunk",
    "h_chunk",
    "kq_chunk",
    "g_exp",
    "lane_idx",
    "k_base"
  ],
  "update_h_with_delta": [
    "h_chunk",
    "kq_chunk",
    "v_delta"
  ],
  "compute_output": [
    "h_chunk",
    "kq_chunk"
  ],
  "decay_h_in_place": [
    "h_chunk",
    "g_exp"
  ],
  "cross_warp_reduce_single": [
    "reduce_sh",
    "slot",
    "warp_idx",
    "lane_idx",
    "value"
  ],
  "cross_warp_reduce_two": [
    "reduce_sh",
    "slot1",
    "slot2",
    "warp_idx",
    "lane_idx",
    "value1",
    "value2"
  ],
  "process_first_token": [
    "h_sh_chunk_curr",
    "h_chunk",
    "kq_chunk",
    "k_sh",
    "q_sh",
    "v_sh",
    "reduce_sh",
    "o_head",
    "g_exp",
    "beta",
    "v_offset",
    "pred_slot",
    "warp_idx",
    "lane_idx",
    "k_base"
  ],
  "process_middle_token": [
    "h_chunk",
    "kq_chunk",
    "k_sh",
    "q_sh",
    "v_sh",
    "reduce_sh",
    "o_head_prev",
    "g_exp",
    "beta",
    "v_offset",
    "out_slot_prev",
    "pred_slot",
    "out_prev",
    "warp_idx",
    "lane_idx",
    "k_base"
  ],
  "process_last_token_and_finish": [
    "h_sh_chunk_curr",
    "h_chunk",
    "kq_chunk",
    "k_sh",
    "q_sh",
    "v_sh",
    "reduce_sh",
    "o_head_prev",
    "o_head_last",
    "g_exp",
    "beta",
    "v_offset",
    "out_slot_prev",
    "pred_slot",
    "out_slot_last",
    "out_prev",
    "warp_idx",
    "lane_idx",
    "k_base"
  ],
  "process_vchunk_unified_234": [
    "h_sh_chunk_curr",
    "h_sh_chunk_prev",
    "h_out",
    "h_chunk",
    "kq_chunk",
    "k_sh0",
    "k_sh1",
    "k_sh2",
    "k_sh3",
    "q_sh0",
    "q_sh1",
    "q_sh2",
    "q_sh3",
    "v_sh0",
    "v_sh1",
    "v_sh2",
    "v_sh3",
    "reduce_sh",
    "o_head0",
    "o_head1",
    "o_head2",
    "o_head3",
    "g_exp0",
    "g_exp1",
    "g_exp2",
    "g_exp3",
    "beta0",
    "beta1",
    "beta2",
    "beta3",
    "v_offset",
    "prev_v_offset",
    "store_prev",
    "tidx",
    "warp_idx",
    "lane_idx",
    "k_base",
    "NUM_TOKENS"
  ],
  "gated_delta_rule_decode_kernel_seqlen1": [
    "gQ",
    "gK",
    "gV",
    "ga",
    "gb",
    "gA_log",
    "gdt_bias",
    "gH",
    "gO",
    "scale",
    "softplus_beta",
    "softplus_threshold",
    "eps"
  ],
  "gated_delta_rule_decode_kernel_seqlen234_unified": [
    "gQ",
    "gK",
    "gV",
    "ga",
    "gb",
    "gA_log",
    "gdt_bias",
    "gH",
    "gO",
    "scale",
    "softplus_beta",
    "softplus_threshold",
    "eps",
    "NUM_TOKENS"
  ],
  "gated_delta_rule_launch_seqlen1": [
    "mQ",
    "mK",
    "mV",
    "ma",
    "mb",
    "mA_log",
    "mdt_bias",
    "mH",
    "mO",
    "scale",
    "softplus_beta",
    "softplus_threshold",
    "eps",
    "stream"
  ],
  "gated_delta_rule_decode_kernel_seqlen1_lowBS_1chunk": [
    "gQ",
    "gK",
    "gV",
    "ga",
    "gb",
    "gA_log",
    "gdt_bias",
    "gH",
    "gO",
    "scale",
    "softplus_beta",
    "softplus_threshold",
    "eps"
  ],
  "gated_delta_rule_launch_seqlen1_lowBS_1chunk": [
    "mQ",
    "mK",
    "mV",
    "ma",
    "mb",
    "mA_log",
    "mdt_bias",
    "mH",
    "mO",
    "scale",
    "softplus_beta",
    "softplus_threshold",
    "eps",
    "stream"
  ],
  "gated_delta_rule_launch_seqlen2": [
    "mQ",
    "mK",
    "mV",
    "ma",
    "mb",
    "mA_log",
    "mdt_bias",
    "mH",
    "mO",
    "scale",
    "softplus_beta",
    "softplus_threshold",
    "eps",
    "stream"
  ],
  "gated_delta_rule_launch_seqlen3": [
    "mQ",
    "mK",
    "mV",
    "ma",
    "mb",
    "mA_log",
    "mdt_bias",
    "mH",
    "mO",
    "scale",
    "softplus_beta",
    "softplus_threshold",
    "eps",
    "stream"
  ],
  "gated_delta_rule_launch_seqlen4": [
    "mQ",
    "mK",
    "mV",
    "ma",
    "mb",
    "mA_log",
    "mdt_bias",
    "mH",
    "mO",
    "scale",
    "softplus_beta",
    "softplus_threshold",
    "eps",
    "stream"
  ],
  "GatedDeltaRuleKernel": {
    "__init__": [
      "self",
      "seq_len"
    ],
    "_get_launch_fn": [
      "self"
    ]
  },
  "_compiled_kernels": [],
  "gated_delta_rule": [
    "A_log",
    "a",
    "dt_bias",
    "softplus_beta",
    "softplus_threshold",
    "q",
    "k",
    "v",
    "b",
    "initial_state_source",
    "initial_state_indices",
    "use_qk_l2norm_in_kernel",
    "scale"
  ]
}