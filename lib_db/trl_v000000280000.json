{
  "clone_chat_template": [
    "model",
    "tokenizer",
    "source_tokenizer_path",
    "resize_to_multiple_of"
  ],
  "qwen3_schema": [],
  "qwen3_chat_template": [],
  "add_response_schema": [
    "tokenizer"
  ],
  "is_chat_template_prefix_preserving": [
    "tokenizer"
  ],
  "qwen3_training_chat_template": [],
  "get_training_chat_template": [
    "tokenizer"
  ],
  "_validate_tool_calls": [
    "tool_calls"
  ],
  "parse_response": [
    "tokenizer",
    "ids"
  ],
  "_import_structure": [],
  "logger": [],
  "main": [],
  "LIGER_KERNEL_MIN_VERSION": [],
  "is_deepspeed_available": [],
  "is_fastapi_available": [],
  "is_jmespath_available": [],
  "is_joblib_available": [],
  "is_liger_kernel_available": [
    "min_version"
  ],
  "is_llm_blender_available": [],
  "is_math_verify_available": [],
  "is_mergekit_available": [],
  "is_pydantic_available": [],
  "is_requests_available": [],
  "is_unsloth_available": [],
  "is_uvicorn_available": [],
  "is_vllm_available": [],
  "is_vllm_ascend_available": [],
  "is_weave_available": [],
  "TRLExperimentalWarning": {},
  "suppress_warning": [
    "category"
  ],
  "suppress_experimental_warning": [],
  "_LazyModule": {
    "__init__": [
      "self",
      "name",
      "module_file",
      "import_structure",
      "module_spec",
      "extra_objects"
    ],
    "__dir__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "_get_module": [
      "self",
      "module_name"
    ],
    "__reduce__": [
      "self"
    ]
  },
  "upload_model_to_hf": [],
  "MergeConfig": {
    "__init__": [
      "self"
    ]
  },
  "merge_models": [],
  "_is_package_version_below": [
    "package_name",
    "version_threshold"
  ],
  "_is_package_version_at_least": [
    "package_name",
    "version_threshold"
  ],
  "_patch_vllm_logging": [],
  "_patch_vllm_disabled_tqdm": [],
  "_patch_vllm_cached_tokenizer": [],
  "_patch_transformers_hybrid_cache": [],
  "DatasetType": [],
  "prepare_multimodal_messages": [
    "messages",
    "images"
  ],
  "prepare_multimodal_messages_vllm": [
    "messages"
  ],
  "is_conversational": [
    "example"
  ],
  "apply_chat_template": [
    "example",
    "tokenizer",
    "tools"
  ],
  "maybe_apply_chat_template": [
    "example",
    "tokenizer",
    "tools"
  ],
  "_unpair_row": [
    "examples"
  ],
  "unpair_preference_dataset": [
    "dataset",
    "num_proc",
    "desc"
  ],
  "maybe_unpair_preference_dataset": [
    "dataset",
    "num_proc",
    "desc"
  ],
  "extract_prompt": [
    "example"
  ],
  "maybe_extract_prompt": [
    "example"
  ],
  "_SegmentTree": {
    "__init__": [
      "self",
      "maxval"
    ],
    "add": [
      "self",
      "val"
    ],
    "remove": [
      "self",
      "val"
    ],
    "search": [
      "self",
      "val"
    ]
  },
  "_pack_bfd": [
    "examples",
    "seq_length"
  ],
  "_pack_wrapped": [
    "examples",
    "seq_length"
  ],
  "pack_dataset": [
    "dataset",
    "seq_length",
    "strategy",
    "map_kwargs"
  ],
  "truncate_dataset": [
    "dataset",
    "max_length",
    "map_kwargs"
  ],
  "is_conversational_from_value": [
    "example"
  ],
  "maybe_convert_to_chatml": [
    "example"
  ],
  "pil_to_base64": [
    "image"
  ],
  "VLLMClient": {
    "__init__": [
      "self",
      "base_url",
      "host",
      "server_port",
      "group_port",
      "connection_timeout"
    ],
    "check_server": [
      "self",
      "total_timeout",
      "retry_interval"
    ],
    "generate": [
      "self",
      "prompts",
      "images",
      "n",
      "repetition_penalty",
      "temperature",
      "top_p",
      "top_k",
      "min_p",
      "max_tokens",
      "truncate_prompt_tokens",
      "structured_outputs_regex",
      "generation_kwargs"
    ],
    "chat": [
      "self",
      "messages",
      "n",
      "repetition_penalty",
      "temperature",
      "top_p",
      "top_k",
      "min_p",
      "max_tokens",
      "truncate_prompt_tokens",
      "structured_outputs_regex",
      "generation_kwargs",
      "chat_template_kwargs",
      "tools",
      "chat_template"
    ],
    "init_communicator": [
      "self",
      "device"
    ],
    "update_named_param": [
      "self",
      "name",
      "weights"
    ],
    "update_model_params": [
      "self",
      "model"
    ],
    "reset_prefix_cache": [
      "self"
    ],
    "chat_completions": [
      "self",
      "messages",
      "model",
      "temperature",
      "top_p",
      "max_tokens",
      "n",
      "tools"
    ],
    "tokenize": [
      "self",
      "messages",
      "tools"
    ],
    "close_communicator": [
      "self"
    ]
  },
  "sanitize_logprob": [
    "logprob"
  ],
  "VLLMGeneration": {
    "__init__": [
      "self",
      "model",
      "accelerator",
      "is_fsdp_enabled",
      "processing_class",
      "mode",
      "structured_outputs_regex",
      "server_base_url",
      "server_host",
      "server_port",
      "server_timeout",
      "group_port",
      "tensor_parallel_size",
      "gpu_memory_utilization",
      "max_model_length",
      "max_num_seqs",
      "enable_sleep_mode",
      "model_impl",
      "repetition_penalty",
      "temperature",
      "top_p",
      "top_k",
      "min_p",
      "max_completion_length",
      "generation_kwargs",
      "chat_template",
      "chat_template_kwargs",
      "tools",
      "rollout_func"
    ],
    "_init_vllm": [
      "self"
    ],
    "_fix_param_name_to_vllm": [
      "self",
      "name",
      "extra_prefixes"
    ],
    "_sync_fsdp1_params_to_vllm": [
      "self",
      "module",
      "prefix",
      "visited"
    ],
    "_sync_fsdp2_params_to_vllm": [
      "self",
      "module"
    ],
    "sync_weights": [
      "self"
    ],
    "generate": [
      "self",
      "prompts",
      "num_generations",
      "profiler"
    ]
  },
  "__all__": [],
  "DPODataCollatorWithPadding": {
    "__call__": [
      "self",
      "features"
    ]
  },
  "DataCollatorForChatML": {
    "__post_init__": [
      "self"
    ],
    "__call__": [
      "self",
      "examples"
    ]
  },
  "truncate_right": [
    "input_ids",
    "stop_token_id",
    "pad_token_id"
  ],
  "SIMPLE_CHAT_TEMPLATE": [],
  "add_bos_token_if_needed": [
    "bos_token_id",
    "prompt_len_input_ids",
    "prompt_tokens",
    "chosen_prompt_len_input_ids",
    "chosen_tokens",
    "rejected_prompt_len_input_ids",
    "rejected_tokens"
  ],
  "add_eos_token_if_needed": [
    "eos_token_id",
    "chosen_tokens",
    "rejected_tokens"
  ],
  "first_true_indices": [
    "bools",
    "dtype"
  ],
  "get_reward": [
    "model",
    "query_responses",
    "pad_token_id",
    "context_length"
  ],
  "prepare_model_for_kbit_training": [
    "model",
    "use_gradient_checkpointing",
    "gradient_checkpointing_kwargs"
  ],
  "enable_gradient_checkpointing": [
    "model",
    "gradient_checkpointing_kwargs"
  ],
  "prepare_peft_model": [
    "model",
    "peft_config",
    "args"
  ],
  "MergeModelCallback": {
    "__init__": [
      "self",
      "merge_config",
      "merge_at_every_checkpoint",
      "push_to_hub"
    ],
    "_merge_and_maybe_push": [
      "self",
      "output_dir",
      "global_step",
      "model"
    ],
    "on_save": [
      "self",
      "args",
      "state",
      "control",
      "model"
    ],
    "on_train_end": [
      "self",
      "args",
      "state",
      "control",
      "model"
    ]
  },
  "_generate_completions": [
    "prompts",
    "model",
    "tokenizer",
    "accelerator",
    "generation_config",
    "batch_size"
  ],
  "_win_rate_completions_df": [
    "state",
    "prompts",
    "completions",
    "winner_indices"
  ],
  "WinRateCallback": {
    "__init__": [
      "self",
      "judge",
      "trainer",
      "generation_config",
      "num_prompts",
      "shuffle_order",
      "use_soft_judge"
    ],
    "on_train_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_evaluate": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "DEFAULT_PAIRWISE_SYSTEM_PROMPT": [],
  "_ensure_llm_blender_importable": [],
  "BaseJudge": {
    "judge": [
      "self",
      "prompts",
      "completions",
      "shuffle_order"
    ]
  },
  "BaseRankJudge": {
    "judge": [
      "self",
      "prompts",
      "completions",
      "shuffle_order"
    ]
  },
  "BasePairwiseJudge": {
    "judge": [
      "self",
      "prompts",
      "completions",
      "shuffle_order"
    ]
  },
  "BaseBinaryJudge": {
    "judge": [
      "self",
      "prompts",
      "completions",
      "gold_completions",
      "shuffle_order"
    ]
  },
  "PairRMJudge": {
    "__init__": [
      "self"
    ],
    "judge": [
      "self",
      "prompts",
      "completions",
      "shuffle_order",
      "return_scores",
      "temperature"
    ]
  },
  "HfPairwiseJudge": {
    "__init__": [
      "self",
      "model",
      "token",
      "system_prompt"
    ],
    "judge": [
      "self",
      "prompts",
      "completions",
      "shuffle_order"
    ]
  },
  "OpenAIPairwiseJudge": {
    "__init__": [
      "self",
      "model",
      "system_prompt",
      "max_requests"
    ],
    "judge": [
      "self",
      "prompts",
      "completions",
      "shuffle_order"
    ]
  },
  "AllTrueJudge": {
    "__init__": [
      "self",
      "judges"
    ],
    "judge": [
      "self",
      "prompts",
      "completions",
      "gold_completions",
      "shuffle_order"
    ]
  },
  "log1mexp": [
    "x"
  ],
  "ORPOTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "model",
      "args",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "model_init",
      "callbacks",
      "optimizers",
      "preprocess_logits_for_metrics",
      "peft_config",
      "compute_metrics"
    ],
    "build_tokenized_answer": [
      "self",
      "prompt",
      "answer"
    ],
    "tokenize_row": [
      "self",
      "feature",
      "model"
    ],
    "concatenated_inputs": [
      "batch",
      "is_encoder_decoder",
      "padding_value",
      "device"
    ],
    "odds_ratio_loss": [
      "self",
      "policy_chosen_logps",
      "policy_rejected_logps"
    ],
    "get_batch_logps": [
      "logits",
      "labels",
      "average_log_prob",
      "is_encoder_decoder"
    ],
    "concatenated_forward": [
      "self",
      "model",
      "batch"
    ],
    "get_batch_loss_metrics": [
      "self",
      "model",
      "batch",
      "train_eval"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs",
      "return_outputs",
      "num_items_in_batch"
    ],
    "generate_from_model": [
      "self",
      "model",
      "batch"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs",
      "prediction_loss_only",
      "ignore_keys"
    ],
    "store_metrics": [
      "self",
      "metrics",
      "train_eval"
    ],
    "evaluation_loop": [
      "self",
      "dataloader",
      "description",
      "prediction_loss_only",
      "ignore_keys",
      "metric_key_prefix"
    ],
    "log": [
      "self",
      "logs",
      "start_time"
    ],
    "_shift_right": [
      "self",
      "input_ids"
    ],
    "_save_checkpoint": [
      "self",
      "model",
      "trial"
    ]
  },
  "ORPOConfig": {
    "_VALID_DICT_FIELDS": [],
    "__post_init__": [
      "self"
    ]
  },
  "KTOConfig": {
    "_VALID_DICT_FIELDS": [],
    "__post_init__": [
      "self"
    ]
  },
  "RUNNING_NAME": [],
  "_get_kl_dataset": [
    "batch"
  ],
  "_tokenize": [
    "batch",
    "tokenizer"
  ],
  "_process_tokens": [
    "example",
    "model"
  ],
  "KTOTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "model",
      "ref_model",
      "args",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "data_collator",
      "model_init",
      "callbacks",
      "optimizers",
      "preprocess_logits_for_metrics",
      "peft_config",
      "compute_metrics",
      "model_adapter_name",
      "ref_adapter_name"
    ],
    "null_ref_context": [
      "self"
    ],
    "get_train_dataloader": [
      "self"
    ],
    "get_eval_dataloader": [
      "self",
      "eval_dataset"
    ],
    "compute_reference_log_probs": [
      "self",
      "padded_batch"
    ],
    "get_batch_logps": [
      "logits",
      "labels",
      "average_log_prob"
    ],
    "forward": [
      "self",
      "model",
      "batch"
    ],
    "kto_loss": [
      "self",
      "policy_chosen_logps",
      "policy_rejected_logps",
      "policy_KL_logps",
      "reference_chosen_logps",
      "reference_rejected_logps",
      "reference_KL_logps"
    ],
    "_compute_kl_logps": [
      "self",
      "model",
      "batch"
    ],
    "_compute_loss_liger": [
      "self",
      "model",
      "batch"
    ],
    "get_batch_loss_metrics": [
      "self",
      "model",
      "batch"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs",
      "return_outputs",
      "num_items_in_batch"
    ],
    "store_metrics": [
      "self",
      "metrics",
      "train_eval"
    ],
    "_get_train_sampler": [
      "self",
      "dataset"
    ],
    "generate_from_model_and_ref": [
      "self",
      "model",
      "batch"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs",
      "prediction_loss_only",
      "ignore_keys"
    ],
    "evaluation_loop": [
      "self",
      "dataloader",
      "description",
      "prediction_loss_only",
      "ignore_keys",
      "metric_key_prefix"
    ],
    "log": [
      "self",
      "logs",
      "start_time"
    ],
    "_save_checkpoint": [
      "self",
      "model",
      "trial"
    ]
  },
  "GRPOTrainer": {
    "_compute_loss": [
      "self",
      "model",
      "inputs"
    ]
  },
  "NashMDConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "GeometricMixtureWrapper": {
    "main_input_name": [],
    "_supports_cache_class": [],
    "_supports_static_cache": [],
    "_is_stateful": [],
    "__init__": [
      "self",
      "model",
      "ref_model",
      "generation_config",
      "mixture_coef",
      "device"
    ],
    "__call__": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self"
    ],
    "_validate_model_class": [
      "self"
    ],
    "_validate_model_kwargs": [
      "self",
      "model_kwargs"
    ]
  },
  "NashMDTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "model",
      "ref_model",
      "reward_funcs",
      "judge",
      "args",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "peft_config",
      "compute_metrics",
      "callbacks",
      "optimizers",
      "preprocess_logits_for_metrics"
    ],
    "mixture_coef": [
      "self"
    ],
    "_generate_completions": [
      "self",
      "model",
      "prompts"
    ],
    "_process_completions": [
      "self",
      "model_output",
      "mixture_output",
      "prompts"
    ],
    "_compute_rewards": [
      "self",
      "model_data",
      "mixture_data",
      "context_length"
    ],
    "_compute_judge": [
      "self",
      "model_data",
      "mixture_data",
      "context_length"
    ],
    "_compute_logprobs": [
      "self",
      "model",
      "model_data",
      "context_length"
    ],
    "_compute_losses": [
      "self",
      "model_logprobs_model_data",
      "ref_logprobs_model_data",
      "probability"
    ],
    "_log_statistics": [
      "self",
      "model_data",
      "mixture_data",
      "model_logprobs_model_data",
      "ref_logprobs_model_data",
      "probability",
      "score",
      "kl_div",
      "context_length",
      "model_scores",
      "mixture_scores"
    ],
    "training_step": [
      "self",
      "model",
      "inputs",
      "num_items_in_batch"
    ]
  },
  "_build_base_generation_kwargs": [
    "trainer",
    "overrides"
  ],
  "_build_colocate_sampling_params": [
    "trainer",
    "overrides"
  ],
  "_build_server_generation_kwargs": [
    "trainer",
    "overrides"
  ],
  "generate_rollout_completions": [
    "trainer",
    "prompts"
  ],
  "_generate_rollout_completions_server": [
    "trainer",
    "prompts",
    "generation_overrides",
    "as_chat"
  ],
  "_generate_rollout_completions_colocate": [
    "trainer",
    "prompts",
    "generation_overrides",
    "as_chat"
  ],
  "GKDTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "model",
      "teacher_model",
      "args",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "compute_metrics",
      "callbacks",
      "optimizers",
      "preprocess_logits_for_metrics",
      "peft_config",
      "formatting_func"
    ],
    "generalized_jsd_loss": [
      "student_logits",
      "teacher_logits",
      "labels",
      "beta",
      "temperature",
      "reduction"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs",
      "return_outputs",
      "num_items_in_batch"
    ],
    "generate_on_policy_outputs": [
      "model",
      "inputs",
      "generation_config",
      "pad_token_id"
    ],
    "training_step": [
      "self",
      "model",
      "inputs",
      "num_items_in_batch"
    ]
  },
  "GKDConfig": {
    "_VALID_DICT_FIELDS": [],
    "__post_init__": [
      "self"
    ]
  },
  "BCOConfig": {
    "_VALID_DICT_FIELDS": [],
    "__post_init__": [
      "self"
    ]
  },
  "CLF_NAME": [],
  "BCOTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "model",
      "ref_model",
      "args",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "data_collator",
      "model_init",
      "callbacks",
      "optimizers",
      "preprocess_logits_for_metrics",
      "peft_config",
      "compute_metrics",
      "model_adapter_name",
      "ref_adapter_name",
      "embedding_func",
      "embedding_tokenizer"
    ],
    "match_underlying_distribution": [
      "self"
    ],
    "_get_chosen_prob": [
      "self",
      "prompt_embeddings"
    ],
    "_vectorize_prompt": [
      "self",
      "input_ids",
      "attention_mask"
    ],
    "_get_prompt_embeddings": [
      "self",
      "batch"
    ],
    "_get_sample_prompt_embeddings": [
      "self",
      "dataset",
      "sample_size"
    ],
    "_save_optimizer_and_scheduler": [
      "self",
      "output_dir"
    ],
    "_load_optimizer_and_scheduler": [
      "self",
      "checkpoint"
    ],
    "null_ref_context": [
      "self"
    ],
    "get_train_dataloader": [
      "self"
    ],
    "get_eval_dataloader": [
      "self",
      "eval_dataset"
    ],
    "compute_reference_log_probs": [
      "self",
      "padded_batch"
    ],
    "get_batch_logps": [
      "logits",
      "labels",
      "average_log_prob",
      "is_encoder_decoder"
    ],
    "forward": [
      "self",
      "model",
      "batch"
    ],
    "_get_udm_weight": [
      "self",
      "rejected_embeddings"
    ],
    "bco_loss": [
      "self",
      "policy_chosen_logps",
      "policy_rejected_logps",
      "reference_chosen_logps",
      "reference_rejected_logps",
      "chosen_embeddings",
      "rejected_embeddings",
      "do_train"
    ],
    "get_batch_loss_metrics": [
      "self",
      "model",
      "batch",
      "do_train"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs",
      "return_outputs",
      "num_items_in_batch"
    ],
    "store_metrics": [
      "self",
      "metrics",
      "train_eval"
    ],
    "_get_train_sampler": [
      "self",
      "dataset"
    ],
    "generate_from_model_and_ref": [
      "self",
      "model",
      "batch"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs",
      "prediction_loss_only",
      "ignore_keys"
    ],
    "evaluation_loop": [
      "self",
      "dataloader",
      "description",
      "prediction_loss_only",
      "ignore_keys",
      "metric_key_prefix"
    ],
    "log": [
      "self",
      "logs",
      "start_time"
    ],
    "_save_checkpoint": [
      "self",
      "model",
      "trial"
    ]
  },
  "GRPOWithReplayBufferConfig": {},
  "ReplayBuffer": {
    "__init__": [
      "self",
      "max_size"
    ],
    "add": [
      "self",
      "scores",
      "data"
    ],
    "sample": [
      "self",
      "num_samples"
    ]
  },
  "GRPOWithReplayBufferTrainer": {
    "__init__": [
      "self",
      "args"
    ],
    "_generate_and_score_completions": [
      "self",
      "inputs"
    ],
    "slice_group_data": [
      "self",
      "data",
      "mask",
      "group_idx"
    ],
    "update_replay_buffer": [
      "self",
      "groups_with_variance",
      "group_advantages",
      "group_std_rewards",
      "prompt_ids",
      "prompt_mask",
      "completion_ids",
      "completion_mask",
      "forward_kwargs",
      "optional_vision_fields",
      "old_per_token_logps",
      "ref_per_token_logps",
      "importance_sampling_ratio"
    ],
    "sample_from_replay_buffer": [
      "self",
      "num_samples",
      "optional_vision_fields",
      "optional_tensor_fields"
    ],
    "update_with_replay_buffer": [
      "self",
      "group_advantages",
      "group_std_rewards",
      "prompt_ids",
      "prompt_mask",
      "completion_ids",
      "completion_mask",
      "forward_kwargs",
      "num_items_in_batch",
      "old_per_token_logps",
      "ref_per_token_logps",
      "importance_sampling_ratio"
    ]
  },
  "print_prompt_completions_sample_uld": [
    "prompts",
    "completions",
    "step",
    "num_samples"
  ],
  "build_teacher_inputs_from_texts": [
    "tokenizer",
    "prompt_texts",
    "completion_texts"
  ],
  "ULDLoss": {
    "__init__": [
      "self",
      "config",
      "student_tokenizer",
      "teacher_tokenizer",
      "device"
    ],
    "__call__": [
      "self",
      "student_logits",
      "teacher_logits",
      "student_labels",
      "teacher_labels",
      "student_input_ids",
      "teacher_input_ids"
    ],
    "_initialize_vocabulary_mapping": [
      "self"
    ],
    "_compute_distillation_loss": [
      "self",
      "student_logits",
      "teacher_logits",
      "student_labels",
      "teacher_labels",
      "student_input_ids",
      "teacher_input_ids"
    ],
    "_build_alignment_groups_from_ids": [
      "self",
      "student_token_ids",
      "teacher_token_ids"
    ],
    "_merge_probabilities_with_alignment_groups": [
      "self",
      "probs",
      "alignment_groups",
      "token_ids"
    ],
    "_compute_hybrid_uld_loss": [
      "self",
      "student_aligned",
      "teacher_aligned"
    ],
    "_compute_jsd_loss_for_matched_tokens": [
      "self",
      "student_logits",
      "teacher_logits"
    ],
    "_get_start_and_size_answers": [
      "self",
      "answer_tensors"
    ]
  },
  "GOLDVLLMSyncCallback": {
    "__init__": [
      "self",
      "trainer"
    ],
    "on_step_end": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "GOLDTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "model",
      "teacher_model",
      "args",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "compute_metrics",
      "callbacks",
      "optimizers",
      "preprocess_logits_for_metrics",
      "peft_config"
    ],
    "_set_signature_columns_if_needed": [
      "self"
    ],
    "_prepare_dataset": [
      "self",
      "dataset",
      "processing_class",
      "args",
      "packing",
      "formatting_func",
      "dataset_name"
    ],
    "_prepare_dataset_with_original_text": [
      "self",
      "dataset",
      "processing_class",
      "args",
      "packing",
      "formatting_func",
      "dataset_name"
    ],
    "generalized_jsd_loss": [
      "student_logits",
      "teacher_logits",
      "labels",
      "beta",
      "temperature",
      "reduction",
      "logits_are_probs"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs",
      "return_outputs",
      "num_items_in_batch"
    ],
    "generate_on_policy_outputs": [
      "self",
      "model",
      "inputs",
      "generation_config",
      "pad_token_id"
    ],
    "_generate_on_policy_outputs_vllm": [
      "self",
      "inputs",
      "generation_config",
      "pad_token_id"
    ],
    "_sync_fsdp_params_to_vllm": [
      "self",
      "module",
      "prefix",
      "visited"
    ],
    "_move_model_to_vllm": [
      "self"
    ],
    "_wake_vllm_if_needed": [
      "self"
    ],
    "training_step": [
      "self",
      "model",
      "inputs",
      "num_items_in_batch"
    ],
    "log": [
      "self",
      "logs",
      "start_time"
    ]
  },
  "GOLDConfig": {
    "_VALID_DICT_FIELDS": [],
    "__post_init__": [
      "self"
    ]
  },
  "PRMConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "compute_accuracy": [
    "eval_pred"
  ],
  "PRMTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "model",
      "args",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "model_init",
      "compute_metrics",
      "callbacks",
      "optimizers",
      "preprocess_logits_for_metrics",
      "peft_config"
    ],
    "tokenize_row": [
      "features",
      "tokenizer",
      "step_separator",
      "max_length",
      "max_completion_length",
      "train_on_last_step_only",
      "is_eval"
    ],
    "_save_checkpoint": [
      "self",
      "model",
      "trial"
    ]
  },
  "dummy_reward_func": [
    "completions"
  ],
  "MiniLLMTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "model",
      "teacher_model",
      "reward_funcs",
      "args",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "reward_processing_classes",
      "callbacks",
      "optimizers",
      "peft_config",
      "rollout_func"
    ],
    "_single_step_decomposition_loss": [
      "self",
      "student_log_probs",
      "teacher_log_probs",
      "mask",
      "reduction"
    ],
    "_compute_advantage": [
      "self",
      "student_log_probs_on_labels",
      "teacher_log_probs_on_labels",
      "mask"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs",
      "return_outputs",
      "num_items_in_batch"
    ]
  },
  "MiniLLMConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "CallbackHandlerWithRefModel": {
    "__init__": [
      "self",
      "callbacks",
      "model",
      "ref_model",
      "processing_class",
      "optimizer",
      "lr_scheduler"
    ],
    "call_event": [
      "self",
      "event",
      "args",
      "state",
      "control"
    ]
  },
  "BEMACallback": {
    "__init__": [
      "self",
      "update_freq",
      "ema_power",
      "bias_power",
      "lag",
      "update_after",
      "multiplier",
      "min_ema_multiplier",
      "device",
      "update_ref_model",
      "ref_model_update_freq",
      "ref_model_update_after"
    ],
    "on_step_end": [
      "self",
      "args",
      "state",
      "control",
      "model"
    ],
    "_update_model_with_bema_weights": [
      "self",
      "model",
      "bema_state_dict",
      "is_peft_base"
    ]
  },
  "DPOTrainer": {
    "__init__": [
      "self"
    ]
  },
  "PAPOConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "PAPOTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "model",
      "reward_funcs",
      "args",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "reward_processing_classes",
      "callbacks",
      "optimizers",
      "peft_config"
    ],
    "_mask_image": [
      "self",
      "pixel_values",
      "mask_ratio"
    ],
    "_compute_loss": [
      "self",
      "model",
      "inputs"
    ]
  },
  "CPOTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "model",
      "args",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "model_init",
      "callbacks",
      "optimizers",
      "preprocess_logits_for_metrics",
      "peft_config",
      "compute_metrics"
    ],
    "build_tokenized_answer": [
      "self",
      "prompt",
      "answer"
    ],
    "tokenize_row": [
      "self",
      "feature",
      "model"
    ],
    "concatenated_inputs": [
      "batch",
      "is_encoder_decoder",
      "padding_value",
      "device"
    ],
    "cpo_loss": [
      "self",
      "policy_chosen_logps",
      "policy_rejected_logps"
    ],
    "get_batch_logps": [
      "logits",
      "labels",
      "average_log_prob",
      "is_encoder_decoder"
    ],
    "concatenated_forward": [
      "self",
      "model",
      "batch"
    ],
    "get_batch_loss_metrics": [
      "self",
      "model",
      "batch",
      "train_eval"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs",
      "return_outputs",
      "num_items_in_batch"
    ],
    "generate_from_model": [
      "self",
      "model",
      "batch"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs",
      "prediction_loss_only",
      "ignore_keys"
    ],
    "store_metrics": [
      "self",
      "metrics",
      "train_eval"
    ],
    "evaluation_loop": [
      "self",
      "dataloader",
      "description",
      "prediction_loss_only",
      "ignore_keys",
      "metric_key_prefix"
    ],
    "log": [
      "self",
      "logs",
      "start_time"
    ],
    "_shift_right": [
      "self",
      "input_ids"
    ],
    "_save_checkpoint": [
      "self",
      "model",
      "trial"
    ]
  },
  "CPOConfig": {
    "_VALID_DICT_FIELDS": [],
    "__post_init__": [
      "self"
    ]
  },
  "XPOConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "XPOTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "model",
      "ref_model",
      "reward_funcs",
      "judge",
      "args",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "reward_processing_classes",
      "peft_config",
      "compute_metrics",
      "callbacks",
      "optimizers",
      "preprocess_logits_for_metrics"
    ],
    "alpha": [
      "self"
    ],
    "_generate_completions": [
      "self",
      "prompts",
      "model"
    ],
    "_process_completions": [
      "self",
      "model_output",
      "ref_output",
      "prompts"
    ],
    "_compute_rewards": [
      "self",
      "model_data",
      "ref_data",
      "context_length"
    ],
    "_compute_judge": [
      "self",
      "model_data",
      "ref_data",
      "context_length"
    ],
    "_compute_logprobs": [
      "self",
      "model",
      "model_data",
      "ref_data",
      "context_length"
    ],
    "_compute_losses": [
      "self",
      "model_logprobs_model_data",
      "model_logprobs_ref_data",
      "ref_logprobs_ref_data",
      "ref_logprobs_model_data",
      "chosen_mask"
    ],
    "_log_statistics": [
      "self",
      "model_data",
      "ref_data",
      "model_logprobs_model_data",
      "model_logprobs_ref_data",
      "ref_logprobs_ref_data",
      "ref_logprobs_model_data",
      "chosen_mask",
      "dpo_losses",
      "xpo_losses",
      "context_length",
      "model_scores",
      "ref_scores"
    ],
    "training_step": [
      "self",
      "model",
      "inputs",
      "num_items_in_batch"
    ]
  },
  "PPOConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "PreTrainedModelWrapper": {
    "transformers_parent_class": [],
    "supported_args": [],
    "supported_modules": [],
    "supported_rm_modules": [],
    "supported_pretrained_model_architectures": [],
    "__init__": [
      "self",
      "pretrained_model",
      "score_module",
      "supports_rm_adapter",
      "rm_adapter_name"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "_get_checkpoint_from_hub": [
      "cls",
      "pretrained_model",
      "pretrained_model_name_or_path",
      "index_filename",
      "token",
      "model_name",
      "model_index_name"
    ],
    "_get_current_device": [
      "cls"
    ],
    "_split_kwargs": [
      "cls",
      "kwargs"
    ],
    "add_and_load_reward_modeling_adapter": [
      "cls",
      "pretrained_model",
      "adapter_model_id",
      "adapter_name",
      "token"
    ],
    "push_to_hub": [
      "self"
    ],
    "save_pretrained": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "post_init": [
      "self"
    ],
    "compute_reward_score": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "ValueHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AutoModelForCausalLMWithValueHead": {
    "transformers_parent_class": [],
    "supported_args": [],
    "__init__": [
      "self",
      "pretrained_model"
    ],
    "_init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "return_past_key_values"
    ],
    "generate": [
      "self"
    ],
    "state_dict": [
      "self"
    ],
    "push_to_hub": [
      "self"
    ],
    "post_init": [
      "self",
      "state_dict"
    ]
  },
  "AutoModelForSeq2SeqLMWithValueHead": {
    "transformers_parent_class": [],
    "lm_head_namings": [],
    "supported_args": [],
    "__init__": [
      "self",
      "pretrained_model"
    ],
    "_has_lm_head": [
      "self"
    ],
    "post_init": [
      "self",
      "state_dict"
    ],
    "state_dict": [
      "self"
    ],
    "push_to_hub": [
      "self"
    ],
    "_init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "return_past_key_values"
    ],
    "generate": [
      "self"
    ]
  },
  "INVALID_LOGPROB": [],
  "generate": [
    "lm_backbone",
    "queries",
    "pad_token_id",
    "generation_config"
  ],
  "batch_generation": [
    "model",
    "queries",
    "local_rollout_forward_batch_size",
    "pad_token_id",
    "generation_config"
  ],
  "exact_div": [
    "a",
    "b",
    "custom_error_message"
  ],
  "print_rich_table": [
    "df"
  ],
  "truncate_response": [
    "stop_token_id",
    "pad_token_id",
    "responses"
  ],
  "forward": [
    "model",
    "query_responses",
    "pad_token_id"
  ],
  "OnlineTrainerState": {},
  "masked_mean": [
    "values",
    "mask",
    "axis"
  ],
  "masked_var": [
    "values",
    "mask",
    "unbiased"
  ],
  "masked_whiten": [
    "values",
    "mask",
    "shift_mean"
  ],
  "PolicyAndValueWrapper": {
    "__init__": [
      "self",
      "policy",
      "value_model"
    ],
    "forward": [
      "self"
    ]
  },
  "PPOTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "args",
      "processing_class",
      "model",
      "ref_model",
      "reward_model",
      "train_dataset",
      "value_model",
      "data_collator",
      "eval_dataset",
      "optimizers",
      "callbacks",
      "peft_config"
    ],
    "get_train_dataloader": [
      "self"
    ],
    "get_eval_dataloader": [
      "self"
    ],
    "null_ref_context": [
      "self"
    ],
    "save_model": [
      "self",
      "output_dir",
      "_internal_call"
    ],
    "train": [
      "self"
    ],
    "generate_completions": [
      "self",
      "sampling"
    ],
    "_save_checkpoint": [
      "self",
      "model",
      "trial"
    ]
  },
  "RewardFunc": [],
  "OnlineDPOTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "model",
      "ref_model",
      "reward_funcs",
      "judge",
      "args",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "reward_processing_classes",
      "peft_config",
      "compute_metrics",
      "callbacks",
      "optimizers",
      "preprocess_logits_for_metrics"
    ],
    "beta": [
      "self"
    ],
    "tokenize_row": [
      "feature",
      "is_encoder_decoder",
      "tokenizer"
    ],
    "get_train_dataloader": [
      "self"
    ],
    "get_eval_dataloader": [
      "self",
      "eval_dataset"
    ],
    "_enable_gradient_checkpointing": [
      "self",
      "model",
      "args"
    ],
    "_generate_vllm": [
      "self",
      "prompts",
      "images"
    ],
    "_generate_vllm_server": [
      "self",
      "prompts",
      "images"
    ],
    "_generate_vllm_colocate": [
      "self",
      "prompts",
      "images"
    ],
    "_sync_fsdp2_params_to_vllm": [
      "self",
      "module"
    ],
    "_move_model_to_vllm": [
      "self"
    ],
    "_sync_fsdp1_params_to_vllm": [
      "self",
      "module",
      "prefix",
      "visited"
    ],
    "_fix_param_name_to_vllm": [
      "self",
      "name",
      "extra_prefixes"
    ],
    "process_vision_row": [
      "self",
      "features",
      "processing_class"
    ],
    "_generate": [
      "self",
      "model",
      "prompts",
      "images"
    ],
    "_calculate_rewards_from_functions": [
      "self",
      "prompts",
      "completions",
      "completion_ids_list"
    ],
    "_forward": [
      "self",
      "model",
      "prompt_ids",
      "prompt_mask",
      "completion_ids",
      "completion_mask",
      "vision_inputs"
    ],
    "training_step": [
      "self",
      "model",
      "inputs",
      "num_items_in_batch"
    ],
    "_maybe_log_save_evaluate": [
      "self",
      "tr_loss",
      "grad_norm",
      "model",
      "trial",
      "epoch",
      "ignore_keys_for_eval",
      "start_time",
      "learning_rate"
    ],
    "_save_checkpoint": [
      "self",
      "model",
      "trial"
    ]
  },
  "OnlineDPOConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "GFPOConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "GroupFilterFunc": [],
  "GFPOTrainer": {
    "__init__": [
      "self",
      "model",
      "reward_funcs",
      "args",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "reward_processing_classes",
      "group_filter_func",
      "callbacks",
      "optimizers",
      "peft_config"
    ],
    "_generate_and_score_completions": [
      "self",
      "inputs"
    ]
  },
  "RewardConfig": {
    "_VALID_DICT_FIELDS": [],
    "__post_init__": [
      "self"
    ]
  },
  "SyncRefModelCallback": {
    "__init__": [
      "self",
      "ref_model",
      "accelerator"
    ],
    "_sync_target_model": [
      "model",
      "target_model",
      "alpha"
    ],
    "sync_target_model": [
      "model",
      "target_model",
      "alpha"
    ],
    "on_step_end": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "RichProgressCallback": {
    "__init__": [
      "self"
    ],
    "on_train_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_step_end": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_prediction_step": [
      "self",
      "args",
      "state",
      "control",
      "eval_dataloader"
    ],
    "on_evaluate": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_predict": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_log": [
      "self",
      "args",
      "state",
      "control",
      "logs"
    ],
    "on_train_end": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "LogCompletionsCallback": {
    "__init__": [
      "self",
      "trainer",
      "generation_config",
      "num_prompts",
      "freq"
    ],
    "on_step_end": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "WeaveCallback": {
    "__init__": [
      "self",
      "trainer",
      "project_name",
      "scorers",
      "generation_config",
      "num_prompts",
      "dataset_name",
      "model_name"
    ],
    "_initialize_weave": [
      "self"
    ],
    "is_evaluation_mode": [
      "self"
    ],
    "on_train_begin": [
      "self",
      "args",
      "state",
      "control"
    ],
    "on_evaluate": [
      "self",
      "args",
      "state",
      "control"
    ]
  },
  "BaseTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "_template_file": [],
    "create_model_card": [
      "self",
      "model_name",
      "dataset_name",
      "tags"
    ]
  },
  "GRPOConfig": {
    "_VALID_DICT_FIELDS": [],
    "__post_init__": [
      "self"
    ]
  },
  "RolloutFunc": [],
  "FLASH_ATTENTION_VARIANTS": [],
  "get_dataset_column_names": [
    "dataset"
  ],
  "DataCollatorForLanguageModeling": {
    "torch_call": [
      "self",
      "examples"
    ],
    "get_position_ids_from_packed_seq_lengths": [
      "batch_seq_lengths"
    ]
  },
  "DataCollatorForVisionLanguageModeling": {
    "torch_call": [
      "self",
      "examples"
    ],
    "_collate_language_modeling": [
      "self",
      "examples"
    ],
    "_collate_prompt_completion": [
      "self",
      "examples"
    ]
  },
  "dft_loss": [
    "outputs",
    "labels",
    "num_items_in_batch"
  ],
  "SFTTrainer": {
    "_tag_names": [],
    "_name": [],
    "__init__": [
      "self",
      "model",
      "args",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "compute_loss_func",
      "compute_metrics",
      "callbacks",
      "optimizers",
      "optimizer_cls_and_kwargs",
      "preprocess_logits_for_metrics",
      "peft_config",
      "formatting_func"
    ],
    "_prepare_dataset": [
      "self",
      "dataset",
      "processing_class",
      "args",
      "packing",
      "formatting_func",
      "dataset_name"
    ],
    "_set_signature_columns_if_needed": [
      "self"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs",
      "return_outputs",
      "num_items_in_batch"
    ],
    "training_step": [
      "self"
    ],
    "log": [
      "self",
      "logs",
      "start_time"
    ],
    "_save_checkpoint": [
      "self",
      "model",
      "trial"
    ]
  },
  "_is_port_free": [
    "port",
    "host"
  ],
  "_find_free_port": [],
  "ensure_master_addr_port": [
    "addr",
    "port"
  ],
  "pad": [
    "tensors",
    "padding_value",
    "padding_side",
    "pad_to_multiple_of"
  ],
  "RunningMoments": {
    "update": [
      "self",
      "xs"
    ],
    "save_to_json": [
      "self",
      "json_path"
    ],
    "load_from_json": [
      "cls",
      "accelerator",
      "json_path"
    ]
  },
  "get_global_statistics": [
    "accelerator",
    "xs",
    "mask",
    "device"
  ],
  "pad_to_length": [
    "tensor",
    "length",
    "pad_value",
    "dim"
  ],
  "disable_dropout_in_model": [
    "model"
  ],
  "get_quantization_config": [
    "model_args"
  ],
  "get_kbit_device_map": [],
  "get_peft_config": [
    "model_args"
  ],
  "get_exp_cap": [
    "value",
    "decimal"
  ],
  "cap_exp": [
    "value",
    "cap"
  ],
  "prepare_deepspeed": [
    "model",
    "per_device_train_batch_size",
    "fp16",
    "bf16"
  ],
  "empty_cache": [],
  "generate_model_card": [
    "base_model",
    "model_name",
    "hub_model_id",
    "dataset_name",
    "tags",
    "wandb_url",
    "trainer_name",
    "trainer_citation",
    "template_file",
    "paper_title",
    "paper_id",
    "comet_url"
  ],
  "get_comet_experiment_url": [],
  "log_table_to_comet_experiment": [
    "name",
    "table"
  ],
  "flush_left": [
    "mask"
  ],
  "flush_right": [
    "mask"
  ],
  "selective_log_softmax": [
    "logits",
    "index"
  ],
  "entropy_from_logits": [
    "logits",
    "chunk_size"
  ],
  "print_prompt_completions_sample": [
    "prompts",
    "completions",
    "rewards",
    "advantages",
    "step",
    "num_samples"
  ],
  "RepeatSampler": {
    "__init__": [
      "self",
      "data_source",
      "mini_repeat_count",
      "batch_size",
      "repeat_count",
      "shuffle",
      "seed"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "nanstd": [
    "tensor",
    "dim",
    "keepdim"
  ],
  "split_tensor_dict": [
    "tensor_dict",
    "num_chunks"
  ],
  "shuffle_sequence_dict": [
    "seq_dict"
  ],
  "nanmin": [
    "tensor"
  ],
  "nanmax": [
    "tensor"
  ],
  "identity": [
    "x"
  ],
  "split_pixel_values_by_grid": [
    "batch"
  ],
  "unsplit_pixel_values_by_grid": [
    "batch"
  ],
  "TListOrMapping": [],
  "remove_none_values": [
    "example"
  ],
  "create_model_from_path": [
    "model_id",
    "architecture"
  ],
  "get_config_model_id": [
    "config"
  ],
  "CausalLMOutputWithPastAndFlatLogits": {},
  "forward_masked_logits": [
    "model",
    "logits_mask"
  ],
  "use_adapter": [
    "model",
    "adapter_name"
  ],
  "start_event_loop_in_daemon": [
    "name"
  ],
  "shutdown_event_loop_in_daemon": [
    "thread",
    "loop"
  ],
  "FDivergenceType": {
    "REVERSE_KL": [],
    "JS_DIVERGENCE": [],
    "ALPHA_DIVERGENCE": []
  },
  "FDivergenceConstants": {
    "ALPHA_DIVERGENCE_COEF_KEY": [],
    "ALPHA_DIVERGENCE_COEF_DEFAULT": []
  },
  "DPOConfig": {
    "_VALID_DICT_FIELDS": [],
    "__post_init__": [
      "self"
    ]
  },
  "shift_tokens_right": [
    "input_ids",
    "decoder_start_token_id"
  ],
  "DataCollatorForPreference": {
    "torch_call": [
      "self",
      "examples"
    ]
  },
  "suppress_from_pretrained_warning": [
    "logger"
  ],
  "RewardTrainer": {
    "_tag_names": [],
    "_name": [],
    "_template_file": [],
    "__init__": [
      "self",
      "model",
      "args",
      "data_collator",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "compute_metrics",
      "callbacks",
      "optimizers",
      "optimizer_cls_and_kwargs",
      "preprocess_logits_for_metrics",
      "peft_config"
    ],
    "_prepare_dataset": [
      "self",
      "dataset",
      "processing_class",
      "args",
      "dataset_name"
    ],
    "_set_signature_columns_if_needed": [
      "self"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs",
      "return_outputs",
      "num_items_in_batch"
    ],
    "training_step": [
      "self"
    ],
    "log": [
      "self",
      "logs",
      "start_time"
    ],
    "_save_checkpoint": [
      "self",
      "model",
      "trial"
    ]
  },
  "RLOOConfig": {
    "_VALID_DICT_FIELDS": [],
    "__post_init__": [
      "self"
    ]
  },
  "ModelConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "RLOOTrainer": {
    "_tag_names": [],
    "_name": [],
    "_paper": [],
    "__init__": [
      "self",
      "model",
      "reward_funcs",
      "args",
      "train_dataset",
      "eval_dataset",
      "processing_class",
      "reward_processing_classes",
      "callbacks",
      "optimizers",
      "peft_config"
    ],
    "_set_signature_columns_if_needed": [
      "self"
    ],
    "get_train_dataloader": [
      "self"
    ],
    "_get_train_sampler": [
      "self",
      "dataset"
    ],
    "_get_eval_sampler": [
      "self",
      "eval_dataset"
    ],
    "_get_per_token_logps_and_entropies": [
      "self",
      "model",
      "input_ids",
      "attention_mask",
      "logits_to_keep",
      "batch_size",
      "compute_entropy",
      "pixel_values",
      "image_grid_thw",
      "num_images",
      "pixel_attention_mask",
      "image_sizes",
      "token_type_ids"
    ],
    "training_step": [
      "self",
      "model",
      "inputs",
      "num_items_in_batch"
    ],
    "_prepare_inputs": [
      "self",
      "generation_batch"
    ],
    "_calculate_rewards": [
      "self",
      "inputs",
      "prompts",
      "completions",
      "completion_ids_list"
    ],
    "_generate_single_turn": [
      "self",
      "prompts"
    ],
    "_generate": [
      "self",
      "prompts"
    ],
    "_generate_and_score_completions": [
      "self",
      "inputs"
    ],
    "compute_loss": [
      "self",
      "model",
      "inputs",
      "return_outputs",
      "num_items_in_batch"
    ],
    "_compute_loss": [
      "self",
      "model",
      "inputs"
    ],
    "prediction_step": [
      "self",
      "model",
      "inputs",
      "prediction_loss_only",
      "ignore_keys"
    ],
    "log": [
      "self",
      "logs",
      "start_time"
    ],
    "_save_checkpoint": [
      "self",
      "model",
      "trial"
    ]
  },
  "SFTConfig": {
    "_VALID_DICT_FIELDS": [],
    "__post_init__": [
      "self"
    ]
  },
  "ProfilingContext": {
    "__init__": [
      "self",
      "name",
      "report_to",
      "is_main_process",
      "step",
      "metric_prefix"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "_log_metrics": [
      "self",
      "duration"
    ]
  },
  "profiling_context": [
    "trainer",
    "name"
  ],
  "profiling_decorator": [
    "func"
  ],
  "think_format_reward": [
    "completions"
  ],
  "accuracy_reward": [
    "completions",
    "solution"
  ],
  "reasoning_accuracy_reward": [
    "completions",
    "solution",
    "reasoning_delimiters"
  ],
  "get_soft_overlong_punishment": [
    "max_completion_len",
    "soft_punish_cache"
  ],
  "DTensor": [],
  "_get_unique_tensor_key": [
    "tensor"
  ],
  "OffloadActivations": {
    "__init__": [
      "self",
      "use_pin_memory",
      "use_streams",
      "min_offload_size",
      "max_fwd_stash_size"
    ],
    "update_model_params": [
      "self",
      "model"
    ]
  },
  "NoOpManager": {
    "__init__": [
      "self"
    ]
  },
  "get_act_offloading_ctx_manager": [
    "model",
    "use_pin_memory",
    "use_streams",
    "min_offload_size",
    "max_fwd_stash_size",
    "warn_if_no_head"
  ],
  "remove_hooks": [
    "model"
  ],
  "get_all_parameters": [
    "sub_module",
    "recurse"
  ],
  "iter_params": [
    "module",
    "recurse"
  ],
  "add_hooks": [
    "model"
  ],
  "_unwrap_model_for_generation": [
    "model",
    "accelerator",
    "gather_deepspeed3_params"
  ],
  "_override_model_generation_config": [
    "model",
    "generation_kwargs"
  ],
  "unwrap_model_for_generation": [
    "model",
    "accelerator",
    "gather_deepspeed3_params",
    "generation_kwargs"
  ],
  "prepare_fsdp": [
    "model",
    "accelerator"
  ],
  "_ForwardRedirection": {
    "__call__": [
      "self",
      "wrapper_module",
      "original_module",
      "method"
    ],
    "on_after_inner_forward": [
      "self",
      "wrapper_module",
      "original_module"
    ],
    "on_after_outer_forward": [
      "self",
      "wrapper_module",
      "original_module"
    ]
  },
  "peft_module_casting_to_bf16": [
    "model"
  ],
  "disable_gradient_checkpointing": [
    "model",
    "gradient_checkpointing_kwargs"
  ],
  "LAYER_PATTERNS": [],
  "create_reference_model": [
    "model",
    "num_shared_layers",
    "pattern"
  ],
  "make_parser": [
    "subparsers"
  ],
  "WeightSyncWorkerExtension": {
    "communicator": [],
    "client_rank": [],
    "init_communicator": [
      "self",
      "host",
      "port",
      "world_size",
      "client_device_uuid"
    ],
    "update_named_param": [
      "self",
      "name",
      "dtype",
      "shape"
    ],
    "close_communicator": [
      "self"
    ]
  },
  "ScriptArguments": {},
  "llm_worker": [
    "script_args",
    "data_parallel_rank",
    "master_port",
    "connection"
  ],
  "chunk_list": [
    "lst",
    "n"
  ],
  "_replace_prefix_tokens": [
    "tokenizer",
    "model_prefix_token_ids",
    "template_prefix_token_ids",
    "template_token_ids"
  ],
  "reward_funcs_registry": [],
  "RLOOScriptArguments": {},
  "_ensure_transformers_parallelism_config": [],
  "DatasetConfig": {},
  "DatasetMixtureConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "init_zero_verbose": [],
  "TrlParser": {
    "__init__": [
      "self",
      "dataclass_types"
    ],
    "parse_args_and_config": [
      "self",
      "args",
      "return_remaining_strings",
      "fail_with_unknown_args"
    ],
    "set_defaults_with_config": [
      "self"
    ]
  },
  "get_git_commit_hash": [
    "package_name"
  ],
  "get_dataset": [
    "mixture_config"
  ],
  "GRPOScriptArguments": {},
  "print_env": []
}