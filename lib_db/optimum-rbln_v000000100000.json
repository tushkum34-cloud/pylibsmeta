{
  "_import_structure": [],
  "set_nested_dict": [
    "dictionary",
    "key_path",
    "value"
  ],
  "parse_value": [
    "value_str"
  ],
  "parse_single_value": [
    "value_str"
  ],
  "ANSI_RESET": [],
  "ANSI_DIM": [],
  "ANSI_UNDERLINE": [],
  "ANSI_RED": [],
  "ANSI_GREEN": [],
  "ANSI_YELLOW": [],
  "ANSI_BLUE": [],
  "ANSI_MAGENTA": [],
  "ANSI_CYAN": [],
  "ANSI_BRIGHT_RED": [],
  "ANSI_BRIGHT_GREEN": [],
  "ANSI_BRIGHT_YELLOW": [],
  "ANSI_BRIGHT_BLUE": [],
  "ANSI_BRIGHT_MAGENTA": [],
  "ANSI_BRIGHT_CYAN": [],
  "STYLES_ENABLED": [],
  "_color": [
    "text",
    "color"
  ],
  "_underline": [
    "text"
  ],
  "_section": [
    "title",
    "color",
    "icon"
  ],
  "_label": [
    "text"
  ],
  "EXAMPLES_TEXT": [],
  "_list_available_rbln_classes": [],
  "_print_rbln_config_options": [
    "class_name"
  ],
  "_read_json_from_model_id": [
    "model_id",
    "filename"
  ],
  "_infer_rbln_class_from_model_id": [
    "model_id"
  ],
  "main": [],
  "logger": [],
  "RBLNModel": {
    "update_kwargs": [
      "cls",
      "kwargs"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "get_compiled_model": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_reconstruct_model_if_needed": [
      "cls",
      "model"
    ],
    "from_model": [
      "cls",
      "model",
      "config",
      "rbln_config",
      "model_save_dir",
      "subfolder"
    ],
    "get_pytorch_model": [
      "cls",
      "model_id",
      "use_auth_token",
      "revision",
      "force_download",
      "cache_dir",
      "subfolder",
      "local_files_only",
      "trust_remote_code",
      "rbln_config"
    ],
    "_create_runtimes": [
      "cls",
      "compiled_models",
      "rbln_config"
    ],
    "forward": [
      "self"
    ],
    "get_hf_output_class": [
      "cls"
    ],
    "_prepare_output": [
      "self",
      "output",
      "return_dict"
    ]
  },
  "DEFAULT_COMPILED_MODEL_NAME": [],
  "TypeInputInfo": [],
  "nested_update": [
    "base",
    "override"
  ],
  "RBLNSerializableConfigProtocol": {
    "_prepare_for_serialization": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "RBLNCompileConfig": {
    "normalize_dtype": [
      "dtype"
    ],
    "is_multiple_input_info": [
      "self"
    ],
    "__post_init__": [
      "self"
    ],
    "update": [
      "self",
      "kwargs"
    ],
    "get_dummy_inputs": [
      "self",
      "fill",
      "static_tensors",
      "meta_tensor_names"
    ],
    "asdict": [
      "self"
    ]
  },
  "RUNTIME_KEYWORDS": [],
  "get_rbln_config_class": [
    "rbln_config_class_name"
  ],
  "load_config": [
    "path"
  ],
  "RBLNAutoConfig": {
    "__new__": [
      "cls"
    ],
    "load_from_dict": [
      "config_dict"
    ],
    "register": [
      "config",
      "exist_ok"
    ],
    "from_pretrained": [
      "cls",
      "path",
      "rbln_config",
      "return_unused_kwargs"
    ],
    "load": [
      "cls",
      "path",
      "rbln_config",
      "return_unused_kwargs"
    ]
  },
  "RBLNModelConfig": {
    "non_save_attributes": [],
    "subclass_non_save_attributes": [],
    "_allow_no_compile_cfgs": [],
    "initialize_submodule_config": [
      "self",
      "submodule_config",
      "force_kwargs"
    ],
    "filter_parameters": [
      "self",
      "config_cls",
      "parameters"
    ],
    "__setattr__": [
      "self",
      "key",
      "value"
    ],
    "__init__": [
      "self",
      "cls_name",
      "create_runtimes",
      "device",
      "device_map",
      "activate_profiler",
      "npu",
      "tensor_parallel_size",
      "timeout",
      "optimum_rbln_version",
      "dtype",
      "_compile_cfgs"
    ],
    "torch_dtype": [
      "self",
      "torch_dtype"
    ],
    "dtype": [
      "self",
      "dtype"
    ],
    "rbln_model_cls_name": [
      "self"
    ],
    "rbln_model_cls": [
      "self"
    ],
    "_prepare_for_serialization": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "compile_cfgs": [
      "self",
      "compile_cfgs"
    ],
    "set_compile_cfgs": [
      "self",
      "compile_cfgs"
    ],
    "freeze": [
      "self"
    ],
    "is_frozen": [
      "self"
    ],
    "save": [
      "self",
      "path"
    ],
    "from_pretrained": [
      "cls",
      "path",
      "rbln_config",
      "return_unused_kwargs"
    ],
    "load": [
      "cls",
      "path",
      "rbln_config",
      "return_unused_kwargs"
    ],
    "initialize_from_kwargs": [
      "cls",
      "rbln_config"
    ],
    "get_default_values_for_original_cls": [
      "self",
      "func_name",
      "keys"
    ],
    "create_runtimes": [
      "self",
      "create_runtimes"
    ],
    "device": [
      "self",
      "device"
    ],
    "device_map": [
      "self",
      "device_map"
    ],
    "activate_profiler": [
      "self",
      "activate_profiler"
    ],
    "timeout": [
      "self",
      "timeout"
    ]
  },
  "convert_rbln_config_dict": [
    "rbln_config"
  ],
  "__all__": [],
  "TYPE_CHECKING": [],
  "__version__": [],
  "version": [],
  "__version_tuple__": [],
  "version_tuple": [],
  "__commit_id__": [],
  "commit_id": [],
  "PreTrainedModel": {},
  "RBLNBaseModelConfig": {},
  "RBLNBaseModel": {
    "model_type": [],
    "auto_model_class": [],
    "config_class": [],
    "config_name": [],
    "hf_library_name": [],
    "_supports_non_fp32": [],
    "__init__": [
      "self",
      "models",
      "config",
      "rbln_config",
      "model_save_dir",
      "subfolder",
      "rbln_compiled_models",
      "rbln_submodules"
    ],
    "_load_compiled_model_dir": [
      "cls",
      "model_id",
      "token",
      "revision",
      "force_download",
      "cache_dir",
      "subfolder",
      "local_files_only"
    ],
    "_load_compiled_models": [
      "cls",
      "model_path",
      "expected_compiled_model_names"
    ],
    "_from_pretrained": [
      "cls",
      "model_id",
      "config",
      "token",
      "revision",
      "force_download",
      "cache_dir",
      "subfolder",
      "local_files_only",
      "trust_remote_code",
      "model_save_dir",
      "rbln_config",
      "rbln_compiled_models",
      "rbln_submodules"
    ],
    "_from_compiled_models": [
      "cls",
      "rbln_compiled_models",
      "rbln_config",
      "config",
      "model_save_dir",
      "subfolder",
      "rbln_submodules"
    ],
    "_export": [
      "cls",
      "model_id"
    ],
    "prepare_rbln_config": [
      "cls",
      "rbln_config"
    ],
    "_is_compiled": [
      "cls",
      "model_id",
      "token",
      "revision",
      "force_download",
      "cache_dir",
      "subfolder",
      "local_files_only"
    ],
    "from_pretrained": [
      "cls",
      "model_id",
      "export",
      "rbln_config"
    ],
    "compile": [
      "cls",
      "model",
      "rbln_compile_config",
      "create_runtimes",
      "device"
    ],
    "update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "get_hf_class": [
      "cls"
    ],
    "get_rbln_config_class": [
      "cls"
    ],
    "can_generate": [
      "self"
    ],
    "to": [
      "self"
    ],
    "parameters": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "__post_init__": [
      "self"
    ],
    "save_pretrained": [
      "self",
      "save_directory",
      "push_to_hub"
    ],
    "_raise_missing_compiled_file_error": [
      "missing_files"
    ]
  },
  "paged_flash_attn_decode": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition"
  ],
  "paged_flash_attn_decode_fake": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition"
  ],
  "paged_flash_attn_decode_kv_fp8": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition",
    "k_scale",
    "v_scale"
  ],
  "paged_flash_attn_decode_kv_fp8_fake": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition",
    "k_scale",
    "v_scale"
  ],
  "paged_flash_attn_prefill": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition"
  ],
  "paged_flash_attn_prefill_fake": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition"
  ],
  "paged_flash_attn_prefill_kv_fp8": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition",
    "k_scale",
    "v_scale"
  ],
  "paged_flash_attn_prefill_kv_fp8_fake": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition",
    "k_scale",
    "v_scale"
  ],
  "paged_flash_causal_attn_decode": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition",
    "mask",
    "s_aux"
  ],
  "paged_flash_causal_attn_decode_fake": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition",
    "mask",
    "s_aux"
  ],
  "paged_flash_causal_attn_decode_kv_fp8": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition",
    "k_scale",
    "v_scale",
    "mask",
    "s_aux"
  ],
  "paged_flash_causal_attn_decode_kv_fp8_fake": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition",
    "k_scale",
    "v_scale",
    "mask",
    "s_aux"
  ],
  "paged_flash_causal_attn_prefill": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition",
    "is_bidirectional",
    "mask",
    "s_aux"
  ],
  "paged_flash_causal_attn_prefill_fake": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition",
    "is_bidirectional",
    "mask",
    "s_aux"
  ],
  "paged_flash_causal_attn_prefill_kv_fp8": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition",
    "is_bidirectional",
    "k_scale",
    "v_scale",
    "mask",
    "s_aux"
  ],
  "paged_flash_causal_attn_prefill_kv_fp8_fake": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "partition",
    "is_bidirectional",
    "k_scale",
    "v_scale",
    "mask",
    "s_aux"
  ],
  "paged_attn_decode": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size"
  ],
  "paged_attn_decode_fake": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size"
  ],
  "paged_attn_decode_kv_fp8": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "k_scale",
    "v_scale"
  ],
  "paged_attn_decode_kv_fp8_fake": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "k_scale",
    "v_scale"
  ],
  "paged_attn_prefill": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size"
  ],
  "paged_attn_prefill_fake": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size"
  ],
  "paged_attn_prefill_kv_fp8": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "k_scale",
    "v_scale"
  ],
  "paged_attn_prefill_kv_fp8_fake": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "k_scale",
    "v_scale"
  ],
  "paged_causal_attn_decode": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "mask",
    "s_aux"
  ],
  "paged_causal_attn_decode_fake": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "mask",
    "s_aux"
  ],
  "paged_causal_attn_prefill": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "is_bidirectional",
    "mask",
    "s_aux"
  ],
  "paged_causal_attn_prefill_fake": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "is_bidirectional",
    "mask",
    "s_aux"
  ],
  "paged_causal_attn_decode_kv_fp8": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "k_scale",
    "v_scale",
    "mask",
    "s_aux"
  ],
  "paged_causal_attn_decode_kv_fp8_fake": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "k_scale",
    "v_scale",
    "mask",
    "s_aux"
  ],
  "paged_causal_attn_prefill_kv_fp8": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "is_bidirectional",
    "k_scale",
    "v_scale",
    "mask",
    "s_aux"
  ],
  "paged_causal_attn_prefill_kv_fp8_fake": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size",
    "is_bidirectional",
    "k_scale",
    "v_scale",
    "mask",
    "s_aux"
  ],
  "paged_add_softmax_attn_decode": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size"
  ],
  "paged_add_softmax_attn_decode_fake": [
    "q",
    "k",
    "v",
    "mask",
    "kcache",
    "vcache",
    "seq",
    "scale",
    "block_table",
    "block_size"
  ],
  "paged_sliding_window_attn_prefill": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "cache_seq_len",
    "cache_offset",
    "scale",
    "block_table",
    "block_size",
    "is_bidirectional",
    "s_aux"
  ],
  "paged_sliding_window_attn_prefill_fake": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "cache_seq_len",
    "cache_offset",
    "scale",
    "block_table",
    "block_size",
    "is_bidirectional",
    "s_aux"
  ],
  "paged_sliding_window_attn_decode": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "cache_seq_len",
    "cache_offset",
    "scale",
    "block_table",
    "block_size",
    "attn_mask",
    "s_aux"
  ],
  "paged_sliding_window_attn_decode_fake": [
    "q",
    "k",
    "v",
    "kcache",
    "vcache",
    "cache_seq_len",
    "cache_offset",
    "scale",
    "block_table",
    "block_size",
    "attn_mask",
    "s_aux"
  ],
  "linear": [
    "input",
    "weight",
    "bias"
  ],
  "linear_fake": [
    "input",
    "weight",
    "bias"
  ],
  "rbln_cache_update": [
    "cache",
    "state",
    "position",
    "axis"
  ],
  "rbln_cache_update_fake": [
    "cache",
    "state",
    "position",
    "axis"
  ],
  "custom_moe_glu": [
    "hidden_states",
    "gate_proj_weight",
    "up_proj_weight",
    "down_proj_weight",
    "router_logits",
    "topk",
    "norm_topk_prob",
    "gate_proj_bias",
    "up_proj_bias",
    "down_proj_bias"
  ],
  "custom_moe_glu_fake": [
    "hidden_states",
    "gate_proj_weight",
    "up_proj_weight",
    "down_proj_weight",
    "router_logits",
    "topk",
    "norm_topk_prob",
    "gate_proj_bias",
    "up_proj_bias",
    "down_proj_bias"
  ],
  "custom_moe_ff": [
    "hidden_states",
    "gate_proj_weight",
    "down_proj_weight",
    "masked_routing_weight",
    "gate_proj_bias",
    "down_proj_bias"
  ],
  "custom_moe_ff_fake": [
    "hidden_states",
    "gate_proj_weight",
    "down_proj_weight",
    "masked_routing_weight",
    "gate_proj_bias",
    "down_proj_bias"
  ],
  "custom_moe_glu_mxfp4": [
    "hidden_states",
    "gate_proj_blocks",
    "gate_proj_scales",
    "gate_proj_bias",
    "up_proj_blocks",
    "up_proj_scales",
    "up_proj_bias",
    "down_proj_blocks",
    "down_proj_scales",
    "down_proj_bias",
    "router_logits",
    "alpha",
    "limit",
    "k",
    "post_norm"
  ],
  "custom_moe_glu_mxfp4_fake": [
    "hidden_states",
    "gate_proj_blocks",
    "gate_proj_scales",
    "gate_proj_bias",
    "up_proj_blocks",
    "up_proj_scales",
    "up_proj_bias",
    "down_proj_blocks",
    "down_proj_scales",
    "down_proj_bias",
    "router_logits",
    "alpha",
    "limit",
    "k",
    "post_norm"
  ],
  "RBLNTransformerEncoderConfig": {
    "__init__": [
      "self",
      "max_seq_len",
      "batch_size",
      "model_input_names",
      "model_input_shapes"
    ]
  },
  "RBLNImageModelConfig": {
    "__init__": [
      "self",
      "image_size",
      "batch_size"
    ],
    "image_width": [
      "self"
    ],
    "image_height": [
      "self"
    ]
  },
  "RBLNModelForQuestionAnsweringConfig": {},
  "RBLNModelForSequenceClassificationConfig": {},
  "RBLNModelForMaskedLMConfig": {},
  "RBLNModelForTextEncodingConfig": {},
  "RBLNTransformerEncoderForFeatureExtractionConfig": {},
  "RBLNModelForImageClassificationConfig": {},
  "RBLNModelForDepthEstimationConfig": {},
  "RBLNTransformerEncoder": {
    "auto_model_class": [],
    "rbln_model_input_names": [],
    "rbln_dtype": [],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "update_rbln_config_for_transformers_encoder": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ]
  },
  "RBLNImageModel": {
    "auto_model_class": [],
    "main_input_name": [],
    "output_class": [],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "update_rbln_config_for_image_model": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ]
  },
  "RBLNModelForQuestionAnswering": {
    "auto_model_class": [],
    "rbln_model_input_names": [],
    "output_class": [],
    "_prepare_output": [
      "self",
      "output",
      "return_dict"
    ]
  },
  "RBLNModelForSequenceClassification": {
    "auto_model_class": [],
    "rbln_model_input_names": []
  },
  "RBLNModelForMaskedLM": {
    "auto_model_class": [],
    "rbln_model_input_names": []
  },
  "RBLNModelForTextEncoding": {
    "auto_model_class": [],
    "rbln_model_input_names": []
  },
  "RBLNTransformerEncoderForFeatureExtraction": {
    "auto_model_class": [],
    "rbln_model_input_names": []
  },
  "RBLNModelForImageClassification": {
    "auto_model_class": []
  },
  "RBLNModelForDepthEstimation": {
    "auto_model_class": [],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ]
  },
  "_compute_default_rope_parameters": [
    "config",
    "device",
    "seq_len"
  ],
  "_compute_linear_scaling_rope_parameters": [
    "config",
    "device",
    "seq_len"
  ],
  "_compute_dynamic_ntk_parameters": [
    "config",
    "device",
    "seq_len"
  ],
  "_compute_yarn_parameters": [
    "config",
    "device",
    "seq_len"
  ],
  "_compute_longrope_parameters": [
    "config",
    "device",
    "seq_len"
  ],
  "_compute_llama3_parameters": [
    "config",
    "device",
    "seq_len"
  ],
  "ROPE_INIT_FUNCTIONS": [],
  "DEFAULT_FLASH_ATTN_PARTITION_LENGTH": [],
  "DEFAULT_MAX_EAGER_ATTN_SEQUENCE_LENGTH": [],
  "MIN_FLASH_ATTN_MAX_SEQ_LEN": [],
  "MIN_FLASH_ATTN_PARTITION_LENGTH": [],
  "MAX_FLASH_ATTN_PARTITION_LENGTH": [],
  "MAX_SLIDING_WINDOW_SIZE": [],
  "set_default_values": [
    "attn_impl",
    "kvcache_partition_len",
    "kvcache_block_size",
    "max_seq_len"
  ],
  "validate_attention_method": [
    "attn_impl",
    "kvcache_partition_len",
    "kvcache_block_size",
    "max_seq_len"
  ],
  "validate_sliding_window": [
    "rbln_config"
  ],
  "align": [
    "x",
    "nbytes"
  ],
  "align_2MB": [
    "x"
  ],
  "get_alloc_memory_by_key": [
    "compiled_models"
  ],
  "format_byte_size": [
    "nbytes"
  ],
  "RBLNDecoderOnlyFlashAttentionMixin": {
    "set_kvcache_num_blocks_after_compilation": [
      "cls",
      "compiled_models",
      "rbln_config"
    ],
    "estimate_num_kvcache_blocks": [
      "cls",
      "compiled_models",
      "rbln_config",
      "available_dram"
    ],
    "multiply_kv_cache_num_blocks": [
      "cls",
      "compiled_models",
      "rbln_config",
      "multiplier"
    ]
  },
  "RBLNDecoderOnlyOutput": {},
  "RBLNGemma3ForCausalLMOutput": {},
  "RBLNSeq2SeqTSDecoderOutput": {},
  "_validate_output_hidden_states": [
    "output_hidden_states",
    "rbln_config"
  ],
  "_validate_output_attentions": [
    "output_attentions",
    "rbln_config"
  ],
  "LoopProcessor": {
    "__init__": [
      "self",
      "model"
    ],
    "__repr__": [
      "self"
    ],
    "_is_batch_implemented": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "_forward_loop": [
      "self"
    ],
    "_forward_batch": [
      "self"
    ],
    "_get_batch_size": [
      "self"
    ],
    "_prepare_inputs_for_iteration": [
      "self",
      "index",
      "common_inputs"
    ],
    "_prepare_inputs_before_loop": [
      "self"
    ],
    "_process_outputs": [
      "self",
      "outputs"
    ]
  },
  "QUANTIZED_WEIGHTS": [],
  "RBLNQuantizationConfig": {
    "SUPPORTED_FORMATS": [],
    "SUPPORTED_WEIGHTS": [],
    "SUPPORTED_ACTIVATIONS": [],
    "SUPPORTED_KVCACHES": [],
    "RBLN_QUANT_BITS_ENV": [],
    "__init__": [
      "self",
      "format",
      "weights",
      "activations",
      "kv_caches"
    ],
    "_validate": [
      "self"
    ],
    "_prepare_for_serialization": [
      "self"
    ],
    "maybe_set_quantization_env": [
      "self"
    ],
    "maybe_reset_quantization_env": [
      "self"
    ],
    "nbits_per_param": [
      "self"
    ]
  },
  "QuantizedLayerFactory": {
    "__init__": [
      "self",
      "quantization_config"
    ],
    "create_linear": [
      "self",
      "layer"
    ],
    "create_qlinear": [
      "self",
      "layer"
    ],
    "create_fp8linear": [
      "self",
      "layer"
    ]
  },
  "get_quantized_model": [
    "hf_auto_model_class",
    "model_id",
    "use_auth_token",
    "revision",
    "cache_dir",
    "force_download",
    "local_files_only",
    "rbln_quantization"
  ],
  "load_weight_files": [
    "model_id",
    "use_auth_token",
    "revision",
    "cache_dir",
    "force_download",
    "local_files_only",
    "exception_keywords"
  ],
  "update_layers_to_quantize": [
    "module",
    "rbln_quantization"
  ],
  "_last_segment": [
    "key"
  ],
  "_replace_last_with": [
    "key",
    "new_tail"
  ],
  "_matches_any_alias": [
    "key",
    "kind"
  ],
  "_reduce_to_scalar": [
    "t"
  ],
  "_coerce_per_out_channel_scale": [
    "scale",
    "out_features"
  ],
  "_kv_split_items": [
    "base_key",
    "tensor"
  ],
  "canonicalize_checkpoint_items": [
    "model",
    "items",
    "rbln_quantization"
  ],
  "load_weights_from_files": [
    "model",
    "safetensors",
    "rbln_quantization"
  ],
  "is_target_for_qlinear_replacement": [
    "layer_name",
    "layer"
  ],
  "is_target_for_adding_kv_scales": [
    "layer_name"
  ],
  "get_parent_and_child": [
    "module",
    "full_name"
  ],
  "access_attribute": [
    "obj",
    "attributes"
  ],
  "create_qlinear": [
    "layer",
    "rbln_quantization"
  ],
  "create_fp8linear": [
    "layer",
    "rbln_quantization"
  ],
  "window_partition": [
    "input_feature",
    "window_size"
  ],
  "get_attn_mask": [
    "self",
    "height",
    "width",
    "dtype",
    "device"
  ],
  "_SwinEncoder": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_dimensions",
      "head_mask",
      "output_attentions",
      "output_hidden_states",
      "output_hidden_states_before_downsampling",
      "always_partition",
      "return_dict"
    ]
  },
  "_SwinBackbone": {
    "__init__": [
      "self",
      "model",
      "output_hidden_states",
      "output_attentions"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "RBLNSwinBackbone": {
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_submodule_config": [
      "cls",
      "model",
      "rbln_config",
      "preprocessors"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "return_dict",
      "output_attentions",
      "output_hidden_states"
    ]
  },
  "RBLNSwinBackboneConfig": {
    "__init__": [
      "self",
      "image_size",
      "batch_size",
      "output_hidden_states",
      "output_attentions"
    ]
  },
  "LoopVisionTower": {
    "__init__": [
      "self",
      "vision_tower"
    ],
    "_get_batch_size": [
      "self",
      "pixel_values"
    ],
    "_prepare_inputs_for_iteration": [
      "self",
      "index",
      "common_inputs",
      "pixel_values"
    ],
    "_process_outputs": [
      "self",
      "outputs"
    ]
  },
  "LoopProjector": {
    "__init__": [
      "self",
      "multi_modal_projector"
    ],
    "_get_batch_size": [
      "self",
      "image_feature"
    ],
    "_prepare_inputs_for_iteration": [
      "self",
      "index",
      "common_inputs",
      "image_feature"
    ],
    "_process_outputs": [
      "self",
      "outputs"
    ]
  },
  "RBLNGemma3ForConditionalGeneration": {
    "auto_model_class": [],
    "_rbln_submodules": [],
    "__getattr__": [
      "self",
      "__name"
    ],
    "can_generate": [
      "self"
    ],
    "_reconstruct_model_if_needed": [
      "cls",
      "model"
    ],
    "__post_init__": [
      "self"
    ],
    "get_attn_impl": [
      "self"
    ],
    "get_kvcache_num_blocks": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "inputs_embeds",
      "pixel_values",
      "image_sizes",
      "attention_mask",
      "generate_idx",
      "padded_cache_lengths",
      "token_type_ids"
    ],
    "_update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs"
    ],
    "get_image_features": [
      "self",
      "pixel_values"
    ],
    "_preprocess_prefill": [
      "self",
      "input_ids",
      "inputs_embeds",
      "pixel_values"
    ],
    "get_padded_cache_position": [
      "self",
      "cache_position",
      "token_type_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "pixel_values",
      "cache_position",
      "inputs_embeds",
      "generate_idx",
      "padded_cache_lengths",
      "position_ids",
      "output_hidden_states"
    ]
  },
  "RBLNGemma3ForCausalLM": {
    "_decoder_wrapper_cls": [],
    "_supports_non_fp32": [],
    "setup_runtime": [
      "self"
    ],
    "_create_embedding_layer": [
      "self"
    ],
    "_update_submodule_config": [
      "cls",
      "model",
      "rbln_config",
      "preprocessors"
    ]
  },
  "Gemma3ForCausalLMWrapper": {
    "get_rotary_emb": [
      "self",
      "max_seq_len"
    ],
    "get_rbln_attn_class": [
      "self"
    ],
    "get_rbln_layer_class": [
      "self"
    ],
    "get_rbln_model_class": [
      "self"
    ]
  },
  "Gemma3TextModel": {
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds",
      "attention_mask",
      "cache_position",
      "position_ids",
      "query_position",
      "past_key_values",
      "rotary_emb",
      "global_block_tables",
      "local_block_tables",
      "lora_int_id",
      "output_hidden_states"
    ]
  },
  "Gemma3DecoderLayer": {
    "_PRE_FF_LAYERNORM_ATTRS": [],
    "_POST_FF_LAYERNORM_ATTRS": [],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "seq_positions",
      "past_key_values",
      "cos",
      "sin",
      "block_tables",
      "lora_int_id"
    ]
  },
  "Gemma3Attention": {
    "__post_init__": [
      "self",
      "self_attn"
    ],
    "get_attn_scale": [
      "self",
      "self_attn"
    ]
  },
  "RBLNGemma3ForCausalLMConfig": {
    "__init__": [
      "self",
      "use_position_ids",
      "use_attention_mask",
      "prefill_chunk_size",
      "image_prefill_chunk_size"
    ]
  },
  "RBLNGemma3ForConditionalGenerationConfig": {
    "submodules": [],
    "__init__": [
      "self",
      "batch_size",
      "vision_tower",
      "language_model"
    ],
    "image_prefill_chunk_size": [
      "self"
    ],
    "prefill_chunk_size": [
      "self"
    ]
  },
  "RBLNGemma3RuntimeModel": {
    "__init__": [
      "self"
    ],
    "_prepare_prefill_inputs": [
      "self"
    ],
    "prefill_forward": [
      "self",
      "inputs",
      "cache_position",
      "attention_mask",
      "batch_idx",
      "block_tables",
      "is_external_block_tables",
      "position_embed",
      "token_type_ids",
      "local_block_tables",
      "lora_int_ids"
    ]
  },
  "RBLNResNetForImageClassification": {
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "RBLNResNetForImageClassificationConfig": {
    "__init__": [
      "self",
      "image_size",
      "batch_size",
      "output_hidden_states"
    ]
  },
  "GPT2Wrapper": {
    "get_rbln_attn_class": [
      "self"
    ],
    "get_attn_layer": [
      "self",
      "layer"
    ],
    "get_model_layer": [
      "self",
      "model"
    ],
    "get_decoder_layers": [
      "self",
      "model"
    ]
  },
  "GPT2Attention": {
    "__post_init__": [
      "self",
      "self_attn"
    ],
    "projection": [
      "self",
      "hidden_states",
      "lora_int_id"
    ],
    "get_attn_scale": [
      "self",
      "self_attn"
    ]
  },
  "RBLNGPT2LMHeadModelConfig": {},
  "RBLNGPT2ModelConfig": {},
  "RBLNGPT2LMHeadModel": {
    "_decoder_wrapper_cls": [],
    "_use_rotary_emb": []
  },
  "RBLNGPT2Model": {
    "_decoder_wrapper_cls": [],
    "_use_rotary_emb": []
  },
  "RBLNBertModelConfig": {},
  "RBLNBertForMaskedLMConfig": {},
  "RBLNBertForQuestionAnsweringConfig": {},
  "BertModelWrapper": {
    "__init__": [
      "self",
      "model",
      "rbln_config"
    ],
    "forward": [
      "self"
    ]
  },
  "RBLNBertModel": {
    "rbln_model_input_names": [],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids"
    ]
  },
  "RBLNBertForMaskedLM": {
    "rbln_model_input_names": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids"
    ]
  },
  "RBLNBertForQuestionAnswering": {
    "rbln_model_input_names": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids"
    ]
  },
  "RBLNMidmLMHeadModel": {
    "_decoder_wrapper_cls": [],
    "_hf_class": [],
    "_supports_cache_class": [],
    "from_pretrained": [
      "cls",
      "model_id"
    ],
    "__getattr__": [
      "self",
      "__name"
    ]
  },
  "this_path": [],
  "local_dir": [],
  "RBLNMidmLMHeadModelConfig": {},
  "apply_rotary_to_tensor": [
    "tensor",
    "cos",
    "sin",
    "rot_dim"
  ],
  "apply_rotary_pos_emb": [
    "q",
    "k",
    "cos",
    "sin"
  ],
  "MidmLMHeadModelWrapper": {
    "get_rotary_emb": [
      "self",
      "max_seq_len"
    ],
    "get_rbln_attn_class": [
      "self"
    ],
    "get_rbln_layer_class": [
      "self"
    ],
    "get_rbln_model_class": [
      "self"
    ],
    "get_model_layer": [
      "self",
      "causal_lm"
    ],
    "get_decoder_layers": [
      "self",
      "causal_lm"
    ]
  },
  "MidmModel": {
    "__init__": [
      "self",
      "model",
      "layers",
      "rbln_config",
      "use_learned_pos_emb",
      "use_rotary_emb"
    ],
    "get_layernorm1p": [
      "self",
      "module"
    ],
    "get_last_layernorm": [
      "self"
    ],
    "get_embedding": [
      "self"
    ],
    "get_pos_embedding": [
      "self"
    ]
  },
  "MidmLayer": {
    "__init__": [
      "self",
      "layer",
      "self_attn",
      "lora_config"
    ],
    "get_layernorm1p": [
      "self",
      "module"
    ],
    "get_pre_attention_layernorm": [
      "self"
    ],
    "get_post_attention_layernorm": [
      "self"
    ]
  },
  "MidmAttention": {
    "__post_init__": [
      "self",
      "self_attn"
    ],
    "projection": [
      "self",
      "hidden_states",
      "lora_int_id"
    ],
    "get_attn_scale": [
      "self",
      "self_attn"
    ],
    "apply_rotary_pos_embed": [
      "self",
      "query_states",
      "key_states",
      "cos",
      "sin"
    ]
  },
  "Gemma2Wrapper": {
    "get_rbln_layer_class": [
      "self"
    ],
    "get_rbln_attn_class": [
      "self"
    ],
    "get_rbln_model_class": [
      "self"
    ]
  },
  "Gemma2DecoderLayer": {
    "_PRE_FF_LAYERNORM_ATTRS": [],
    "_POST_FF_LAYERNORM_ATTRS": [],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "seq_positions",
      "past_key_values",
      "cos",
      "sin",
      "block_tables",
      "lora_int_id"
    ]
  },
  "Gemma2Attention": {
    "get_attn_scale": [
      "self",
      "self_attn"
    ]
  },
  "Gemma2Model": {
    "hidden_multiplier": [
      "self"
    ]
  },
  "RBLNGemma2ForCausalLMConfig": {},
  "RBLNGemma2ModelConfig": {},
  "RBLNGemma2ForCausalLM": {
    "_decoder_wrapper_cls": []
  },
  "RBLNGemma2Model": {
    "_decoder_wrapper_cls": []
  },
  "RBLNXLMRobertaModelConfig": {},
  "RBLNXLMRobertaForSequenceClassificationConfig": {},
  "RBLNXLMRobertaModel": {
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids"
    ]
  },
  "RBLNXLMRobertaForSequenceClassification": {
    "rbln_model_input_names": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids"
    ]
  },
  "RBLNColQwen2ForRetrieval": {
    "_rbln_submodule_postfix": [],
    "_rbln_submodules": [],
    "_supports_non_fp32": [],
    "__post_init__": [
      "self"
    ],
    "_reconstruct_model_if_needed": [
      "cls",
      "model"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds",
      "attention_mask",
      "pixel_values",
      "image_grid_thw",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "RBLNColQwen2ForRetrievalConfig": {
    "submodules": [],
    "_allow_no_compile_cfgs": [],
    "__init__": [
      "self",
      "batch_size",
      "output_hidden_states",
      "vlm"
    ]
  },
  "RBLNViTForImageClassification": {
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "RBLNViTForImageClassificationConfig": {},
  "RBLNT5EncoderModelConfig": {},
  "RBLNT5ForConditionalGenerationConfig": {
    "support_paged_attention": []
  },
  "T5EncoderWrapper": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self"
    ]
  },
  "RBLNT5EncoderModel": {
    "auto_model_class": [],
    "output_class": [],
    "_wrap_model_if_needed": [
      "self",
      "model",
      "rbln_config"
    ],
    "update_rbln_config_using_pipe": [
      "cls",
      "pipe",
      "rbln_config",
      "submodule_name"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "RBLNT5ForConditionalGeneration": {
    "support_causal_attn": [],
    "_wrap_model_if_needed": [
      "self",
      "model",
      "rbln_config"
    ],
    "__getattr__": [
      "self",
      "__name"
    ]
  },
  "T5Wrapper": {
    "__init__": [
      "self",
      "model",
      "enc_max_seq_len",
      "dec_max_seq_len"
    ]
  },
  "T5DecoderWrapper": {
    "__post_init__": [
      "self",
      "model",
      "dec_max_seq_len"
    ],
    "convert_to_rbln_conditional_generation": [
      "self",
      "model",
      "dec_max_seq_len"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_attention_mask",
      "cache_position",
      "block_tables"
    ]
  },
  "T5ForConditionalGeneration": {
    "has_rescaling": [],
    "__post_init__": [
      "self"
    ]
  },
  "T5Decoder": {
    "has_pos_emb": [],
    "__post_init__": [
      "self",
      "model",
      "dec_max_seq_len"
    ],
    "precompute_dec_position_bias": [
      "self",
      "model",
      "dec_max_length"
    ],
    "prepare_attn_mask": [
      "self",
      "attention_mask",
      "encoder_attention_mask",
      "cache_position"
    ]
  },
  "T5Block": {
    "__init__": [
      "self",
      "decoder_layer",
      "self_attn"
    ],
    "__post_init__": [
      "self",
      "decoder_layer"
    ],
    "pre_self_attn_layer_norm": [
      "self",
      "hidden_states"
    ],
    "post_self_attn_layer_norm": [
      "self",
      "hidden_states"
    ],
    "pre_cross_attn_layer_norm": [
      "self",
      "hidden_states"
    ],
    "post_cross_attn_layer_norm": [
      "self",
      "hidden_states"
    ]
  },
  "T5LayerSelfAttention": {
    "__post_init__": [
      "self",
      "attn"
    ],
    "projection": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "past_key_value",
      "attention_mask",
      "cache_position",
      "block_tables"
    ]
  },
  "T5CrossAttention": {
    "__init__": [
      "self",
      "attn"
    ],
    "forward": [
      "self",
      "hidden_states",
      "past_key_value",
      "attention_mask",
      "key_value_states"
    ]
  },
  "RBLNLlavaNextForConditionalGenerationConfig": {
    "submodules": [],
    "__init__": [
      "self",
      "batch_size",
      "vision_tower",
      "language_model"
    ]
  },
  "RBLNLlavaNextForConditionalGeneration": {
    "auto_model_class": [],
    "_rbln_submodules": [],
    "__getattr__": [
      "self",
      "__name"
    ],
    "can_generate": [
      "self"
    ],
    "_reconstruct_model_if_needed": [
      "cls",
      "model"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "__post_init__": [
      "self"
    ],
    "get_attn_impl": [
      "self"
    ],
    "get_kvcache_num_blocks": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "inputs_embeds",
      "pixel_values",
      "attention_mask",
      "cache_position",
      "image_sizes",
      "generate_idx"
    ],
    "_update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "image_sizes",
      "vision_feature_layer",
      "vision_feature_select_strategy"
    ],
    "pack_image_features": [
      "self",
      "image_features",
      "image_sizes",
      "vision_feature_select_strategy",
      "image_newline"
    ],
    "_preprocess_prefill": [
      "self",
      "input_ids",
      "pixel_values",
      "image_sizes",
      "inputs_embeds",
      "vision_feature_layer",
      "vision_feature_select_strategy"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "pixel_values",
      "image_sizes",
      "inputs_embeds",
      "cache_position",
      "generate_idx",
      "return_dict"
    ]
  },
  "RBLNDPTForDepthEstimation": {
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "RBLNDPTForDepthEstimationConfig": {},
  "RBLNQwen3MoeForCausalLM": {
    "_decoder_wrapper_cls": []
  },
  "Qwen3MoeWrapper": {
    "get_rbln_layer_class": [
      "self"
    ],
    "get_rbln_attn_class": [
      "self"
    ]
  },
  "Qwen3MoeAttention": {
    "__post_init__": [
      "self",
      "self_attn"
    ]
  },
  "Qwen3MoeLayer": {
    "__init__": [
      "self",
      "layer",
      "self_attn",
      "lora_config"
    ],
    "get_mlp": [
      "self"
    ]
  },
  "Qwen3MoeSparseMoeBlock": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen3MoeMLP": {
    "__init__": [
      "self",
      "expert_list",
      "top_k",
      "norm_topk_prob"
    ],
    "forward": [
      "self",
      "x",
      "router_logits"
    ]
  },
  "RBLNQwen3MoeForCausalLMConfig": {},
  "RBLNGemmaForCausalLM": {
    "_decoder_wrapper_cls": []
  },
  "RBLNGemmaModel": {
    "_decoder_wrapper_cls": []
  },
  "RBLNGemmaForCausalLMConfig": {},
  "RBLNGemmaModelConfig": {},
  "GemmaWrapper": {
    "get_rbln_model_class": [
      "self"
    ]
  },
  "GemmaModel": {
    "hidden_multiplier": [
      "self"
    ]
  },
  "PegasusWrapper": {
    "__init__": [
      "self",
      "model",
      "enc_max_seq_len",
      "use_attention_mask"
    ]
  },
  "PegasusDecoderWrapper": {
    "convert_to_rbln_conditional_generation": [
      "self",
      "model"
    ]
  },
  "PegasusForConditionalGeneration": {},
  "PegasusDecoder": {
    "has_pos_emb": [],
    "__post_init__": [
      "self",
      "model"
    ],
    "prepare_attn_mask": [
      "self",
      "attention_mask",
      "encoder_attention_mask"
    ],
    "apply_position_embedding": [
      "self",
      "inputs_embeds",
      "cache_position"
    ],
    "get_embedding": [
      "self"
    ]
  },
  "PegasusLayerFF": {
    "__init__": [
      "self",
      "decoder_layer"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "PegasusDecoderLayer": {
    "__post_init__": [
      "self",
      "decoder_layer"
    ],
    "pre_self_attn_layer_norm": [
      "self",
      "hidden_states"
    ],
    "post_self_attn_layer_norm": [
      "self",
      "hidden_states"
    ],
    "pre_cross_attn_layer_norm": [
      "self",
      "hidden_states"
    ],
    "post_cross_attn_layer_norm": [
      "self",
      "hidden_states"
    ]
  },
  "PegasusSelfAttention": {
    "__post_init__": [
      "self",
      "attn",
      "use_attention_mask"
    ],
    "projection": [
      "self",
      "hidden_states"
    ]
  },
  "PegasusCrossAttention": {
    "__post_init__": [
      "self",
      "attn"
    ]
  },
  "RBLNPegasusModelConfig": {
    "rbln_model_input_names": []
  },
  "RBLNPegasusForConditionalGenerationConfig": {
    "support_paged_attention": []
  },
  "RBLNPegasusModel": {
    "rbln_model_input_names": []
  },
  "RBLNPegasusForConditionalGeneration": {
    "support_causal_attn": [],
    "_wrap_model_if_needed": [
      "self",
      "model",
      "rbln_config"
    ],
    "__getattr__": [
      "self",
      "__name"
    ]
  },
  "RBLNDistilBertForQuestionAnswering": {
    "rbln_model_input_names": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "RBLNDistilBertForQuestionAnsweringConfig": {},
  "_TextEncoder": {
    "__init__": [
      "self",
      "enc"
    ],
    "forward": [
      "self",
      "inp"
    ]
  },
  "RBLNCLIPTextModel": {
    "_tp_support": [],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "update_rbln_config_using_pipe": [
      "cls",
      "pipe",
      "rbln_config",
      "submodule_name"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "return_dict"
    ],
    "_prepare_output": [
      "self",
      "output",
      "return_dict"
    ]
  },
  "RBLNCLIPTextModelWithProjection": {},
  "_VisionEncoder": {
    "__init__": [
      "self",
      "enc",
      "interpolate_pos_encoding",
      "output_hidden_states",
      "output_attentions"
    ],
    "forward": [
      "self",
      "inp"
    ]
  },
  "RBLNCLIPVisionModel": {
    "_tp_support": [],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "update_rbln_config_using_pipe": [
      "cls",
      "pipe",
      "rbln_config",
      "submodule_name"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "return_dict",
      "output_attentions",
      "output_hidden_states",
      "interpolate_pos_encoding"
    ],
    "_prepare_output": [
      "self",
      "output",
      "return_dict"
    ]
  },
  "RBLNCLIPVisionModelWithProjection": {
    "forward": [
      "self",
      "pixel_values",
      "return_dict",
      "output_attentions",
      "output_hidden_states",
      "interpolate_pos_encoding"
    ],
    "_prepare_output": [
      "self",
      "output",
      "return_dict"
    ]
  },
  "RBLNCLIPTextModelConfig": {
    "__init__": [
      "self",
      "batch_size"
    ]
  },
  "RBLNCLIPTextModelWithProjectionConfig": {},
  "RBLNCLIPVisionModelConfig": {
    "__init__": [
      "self",
      "batch_size",
      "image_size",
      "interpolate_pos_encoding",
      "output_hidden_states",
      "output_attentions"
    ],
    "image_width": [
      "self"
    ],
    "image_height": [
      "self"
    ]
  },
  "RBLNCLIPVisionModelWithProjectionConfig": {},
  "RBLNRobertaForMaskedLMConfig": {},
  "RBLNRobertaForSequenceClassificationConfig": {},
  "RBLNRobertaForMaskedLM": {
    "rbln_model_input_names": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "RBLNRobertaForSequenceClassification": {
    "rbln_model_input_names": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "RBLNQwen2VLForConditionalGenerationConfig": {
    "submodules": [],
    "__init__": [
      "self",
      "use_inputs_embeds",
      "visual"
    ]
  },
  "RBLNQwen2VLModelConfig": {
    "submodules": [],
    "__init__": [
      "self",
      "visual"
    ]
  },
  "RBLNQwen2VisionTransformerPretrainedModelConfig": {
    "__init__": [
      "self",
      "max_seq_lens"
    ]
  },
  "Qwen2VisionTransformerWrapper": {
    "__init__": [
      "self",
      "model",
      "rbln_config"
    ],
    "wrap_vision_blocks": [
      "self",
      "blocks",
      "rbln_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "full_attn_masks",
      "cos",
      "sin"
    ]
  },
  "Qwen2VLVisionBlock": {
    "__init__": [
      "self",
      "model",
      "rbln_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attn_masks",
      "position_embeddings"
    ]
  },
  "VisionAttention": {
    "__init__": [
      "self",
      "model",
      "rbln_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attn_masks",
      "position_embeddings"
    ]
  },
  "Qwen2VL_LanguageModelWrapper": {
    "get_decoder_layers": [
      "self",
      "model"
    ],
    "get_model_layer": [
      "self",
      "model"
    ],
    "prepare_forward_args": [
      "self"
    ]
  },
  "RBLNQwen2VisionTransformerPretrainedModel": {
    "auto_model_class": [],
    "_supports_non_fp32": [],
    "__post_init__": [
      "self"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "__getattr__": [
      "self",
      "__name"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_pad_for_full_attn_layers": [
      "hidden_state",
      "cos",
      "sin",
      "max_seq_len"
    ],
    "forward": [
      "self",
      "hidden_states",
      "grid_thw"
    ]
  },
  "RBLNQwen2VLModel": {
    "auto_model_class": [],
    "_decoder_wrapper_cls": [],
    "_supports_non_fp32": [],
    "_use_rotary_emb": [],
    "_rbln_submodules": [],
    "_config_class": [],
    "_rotary_emb_class": [],
    "_get_rope_index_func": [],
    "__post_init__": [
      "self"
    ],
    "logits_last_dim": [
      "self"
    ],
    "_create_embedding_layer": [
      "self"
    ],
    "get_input_info": [
      "cls",
      "batch_size",
      "query_length",
      "rbln_config",
      "model_config"
    ],
    "_get_position_embeddings": [
      "self",
      "hidden_states",
      "position_ids"
    ],
    "_preprocess_prefill": [
      "self",
      "input_ids",
      "attention_mask",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds",
      "attention_mask",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "cache_position",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "RBLNQwen2VLForConditionalGeneration": {
    "auto_model_class": [],
    "_decoder_wrapper_cls": [],
    "_supports_non_fp32": [],
    "_use_rotary_emb": [],
    "_rbln_submodules": [],
    "__post_init__": [
      "self"
    ],
    "can_generate": [
      "self"
    ],
    "_reconstruct_model_if_needed": [
      "cls",
      "model"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "generate_idx",
      "attention_mask",
      "inputs_embeds",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw"
    ],
    "_preprocess_decoder": [
      "self",
      "input_ids",
      "cache_position"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds",
      "attention_mask",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "cache_position",
      "generate_idx",
      "return_dict",
      "output_hidden_states"
    ]
  },
  "RBLNQwen3ForCausalLMConfig": {},
  "RBLNQwen3ModelConfig": {},
  "Qwen3Wrapper": {
    "get_rbln_attn_class": [
      "self"
    ]
  },
  "Qwen3Attention": {
    "__post_init__": [
      "self",
      "self_attn"
    ]
  },
  "RBLNQwen3ForCausalLM": {
    "_decoder_wrapper_cls": [],
    "forward": [
      "self"
    ]
  },
  "RBLNQwen3Model": {
    "_decoder_wrapper_cls": [],
    "_use_rotary_emb": []
  },
  "QWEN2Wrapper": {},
  "RBLNQwen2ForCausalLM": {
    "_decoder_wrapper_cls": []
  },
  "RBLNQwen2Model": {
    "_decoder_wrapper_cls": []
  },
  "RBLNQwen2ForCausalLMConfig": {},
  "RBLNQwen2ModelConfig": {},
  "RBLNQwen2MoeForCausalLMConfig": {},
  "Qwen2MoeWrapper": {
    "get_rbln_layer_class": [
      "self"
    ]
  },
  "Qwen2MoeLayer": {
    "__init__": [
      "self",
      "layer",
      "self_attn",
      "lora_config"
    ],
    "get_mlp": [
      "self"
    ]
  },
  "Qwen2MoeSparseMoeBlock": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen2MoeMLP": {
    "__init__": [
      "self",
      "expert_list",
      "top_k",
      "norm_topk_prob"
    ],
    "forward": [
      "self",
      "x",
      "router_logits"
    ]
  },
  "RBLNQwen2MoeForCausalLM": {
    "_decoder_wrapper_cls": []
  },
  "RBLNASTForAudioClassificationConfig": {
    "__init__": [
      "self",
      "batch_size",
      "max_length"
    ]
  },
  "RBLNASTForAudioClassification": {
    "auto_model_class": [],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "forward": [
      "self",
      "input_values"
    ]
  },
  "RBLNMistralForCausalLMConfig": {},
  "RBLNMistralModelConfig": {},
  "RBLNMistralForCausalLM": {
    "_decoder_wrapper_cls": []
  },
  "RBLNMistralModel": {
    "_decoder_wrapper_cls": []
  },
  "MistralWrapper": {},
  "RBLNWhisperForConditionalGenerationConfig": {
    "__init__": [
      "self",
      "batch_size",
      "token_timestamps",
      "use_attention_mask",
      "enc_max_seq_len",
      "dec_max_seq_len",
      "kvcache_num_blocks",
      "kvcache_block_size"
    ]
  },
  "WhisperWrapper": {
    "__init__": [
      "self",
      "model",
      "use_attention_mask",
      "rbln_token_timestamps"
    ]
  },
  "WhisperEncoderWrapper": {
    "__init__": [
      "self",
      "model"
    ],
    "_extract_cross_kv_projects": [
      "self",
      "decoder_layers"
    ],
    "forward": [
      "self",
      "input_features",
      "b_idx",
      "cross_key_values"
    ]
  },
  "WhisperDecoderWrapper": {
    "__init__": [
      "self",
      "model",
      "use_attention_mask",
      "output_attentions"
    ],
    "__post_init__": [
      "self",
      "model"
    ],
    "convert_to_rbln_conditional_generation": [
      "self",
      "model"
    ],
    "forward": [
      "self"
    ]
  },
  "WhisperDecoder": {
    "__init__": [
      "self",
      "model",
      "layers"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "self_past_key_values",
      "cross_past_key_values",
      "cache_position",
      "block_tables"
    ]
  },
  "WhisperDecoderLayer": {
    "__init__": [
      "self",
      "decoder_layer",
      "self_attn",
      "cross_attn"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "self_past_key_value",
      "cross_past_key_value",
      "cache_position",
      "block_tables"
    ]
  },
  "WhisperAttention": {
    "__init__": [
      "self",
      "attn"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ]
  },
  "WhisperSelfAttention": {
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states",
      "past_key_value",
      "attention_mask",
      "cache_position",
      "block_tables"
    ]
  },
  "WhisperCrossAttention": {
    "forward": [
      "self",
      "hidden_states",
      "past_key_value"
    ]
  },
  "RBLNWhisperGenerationMixin": {
    "generate": [
      "self",
      "input_features",
      "attention_mask",
      "generation_config",
      "return_segments",
      "return_timestamps",
      "return_token_timestamps"
    ],
    "_postprocess_outputs": [
      "self",
      "seek_outputs",
      "decoder_input_ids",
      "return_token_timestamps",
      "generation_config",
      "is_shortform",
      "seek",
      "batch_idx_map"
    ]
  },
  "RBLNRuntimeEncoder": {
    "mandatory_members": [],
    "forward": [
      "self"
    ]
  },
  "RBLNRuntimeDecoder": {
    "mandatory_members": [],
    "__init__": [
      "self",
      "runtime",
      "batch_size",
      "dec_max_seq_len",
      "use_attention_mask"
    ],
    "forward": [
      "self",
      "decoder_input_ids",
      "decoder_attention_mask",
      "cache_position",
      "block_tables"
    ]
  },
  "RBLNWhisperForConditionalGeneration": {
    "auto_model_class": [],
    "main_input_name": [],
    "_is_stateful": [],
    "__post_init__": [
      "self"
    ],
    "can_generate": [
      "self"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "__getattr__": [
      "self",
      "__name"
    ],
    "_reorder_cache": [
      "self",
      "past_key_values",
      "beam_idx"
    ],
    "_wrap_model_if_needed": [
      "self",
      "model",
      "rbln_config"
    ],
    "get_compiled_model": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_paged_attention_config": [
      "cls",
      "model_config",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_create_runtimes": [
      "cls",
      "compiled_models",
      "rbln_config"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "cache_position",
      "attention_mask"
    ],
    "_prepare_encoder_decoder_kwargs_for_generation": [
      "self",
      "inputs_tensor",
      "model_kwargs",
      "model_input_name",
      "generation_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "cache_position",
      "input_features",
      "decoder_input_ids",
      "encoder_outputs"
    ]
  },
  "RBLNTimeSeriesTransformerForPrediction": {
    "auto_model_class": [],
    "main_input_name": [],
    "__post_init__": [
      "self"
    ],
    "__getattr__": [
      "self",
      "__name"
    ],
    "_wrap_model_if_needed": [
      "self",
      "model",
      "rbln_config"
    ],
    "get_compiled_model": [
      "cls",
      "model",
      "rbln_config"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_create_runtimes": [
      "cls",
      "compiled_models",
      "rbln_config"
    ],
    "validate_batch_size": [
      "self"
    ],
    "generate": [
      "self",
      "past_values",
      "past_time_features",
      "future_time_features",
      "past_observed_mask",
      "static_categorical_features",
      "static_real_features"
    ]
  },
  "TimeSeriesTransformersWrapper": {
    "__init__": [
      "self",
      "model",
      "num_parallel_samples"
    ]
  },
  "TimeSeriesTransformersEncoderWrapper": {
    "__init__": [
      "self",
      "model"
    ],
    "_extract_cross_kv_projects": [
      "self",
      "decoder_layers"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "cross_key_values"
    ]
  },
  "TimeSeriesTransformersDecoderWrapper": {
    "__init__": [
      "self",
      "model",
      "num_parallel_samples"
    ],
    "convert_to_rbln_tst_decoder": [
      "self",
      "model",
      "num_parallel_samples"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "decoder_attention_mask",
      "cache_position",
      "block_tables",
      "cross_kv_cache"
    ]
  },
  "TimeSeriesTransformersDecoder": {
    "__init__": [
      "self",
      "model",
      "layers"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "self_past_key_values",
      "cross_past_key_values",
      "cache_position",
      "block_tables"
    ]
  },
  "TimeSeriesTransformersDecoderLayer": {
    "__init__": [
      "self",
      "decoder_layer",
      "self_attn",
      "cross_attn"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "self_past_key_value",
      "cross_past_key_value",
      "cache_position",
      "block_tables"
    ]
  },
  "TimeSeriesTransformersAttention": {
    "__init__": [
      "self",
      "attn",
      "num_parallel_samples"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ]
  },
  "TimeSeriesTransformersSelfAttention": {
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states",
      "past_key_value",
      "attention_mask",
      "cache_position",
      "block_tables"
    ]
  },
  "TimeSeriesTransformersCrossAttention": {
    "forward": [
      "self",
      "hidden_states",
      "past_key_value"
    ]
  },
  "RBLNTimeSeriesTransformerForPredictionConfig": {
    "__init__": [
      "self",
      "batch_size",
      "enc_max_seq_len",
      "dec_max_seq_len",
      "num_parallel_samples"
    ]
  },
  "RBLNBartModel": {
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "RBLNBartForConditionalGeneration": {
    "support_causal_attn": [],
    "_wrap_model_if_needed": [
      "self",
      "model",
      "rbln_config"
    ],
    "__getattr__": [
      "self",
      "__name"
    ]
  },
  "BartWrapper": {
    "__init__": [
      "self",
      "model",
      "enc_max_seq_len",
      "use_attention_mask"
    ]
  },
  "BartDecoderWrapper": {
    "convert_to_rbln_conditional_generation": [
      "self",
      "model"
    ]
  },
  "BartForConditionalGeneration": {},
  "BartDecoder": {
    "has_pos_emb": [],
    "__post_init__": [
      "self",
      "model"
    ],
    "prepare_attn_mask": [
      "self",
      "attention_mask",
      "encoder_attention_mask"
    ],
    "apply_position_embedding": [
      "self",
      "inputs_embeds",
      "cache_position"
    ],
    "get_embedding": [
      "self"
    ]
  },
  "BartLayerFF": {
    "__init__": [
      "self",
      "decoder_layer"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BartDecoderLayer": {
    "__post_init__": [
      "self",
      "decoder_layer"
    ],
    "pre_self_attn_layer_norm": [
      "self",
      "hidden_states"
    ],
    "post_self_attn_layer_norm": [
      "self",
      "hidden_states"
    ],
    "pre_cross_attn_layer_norm": [
      "self",
      "hidden_states"
    ],
    "post_cross_attn_layer_norm": [
      "self",
      "hidden_states"
    ]
  },
  "BartSelfAttention": {
    "__post_init__": [
      "self",
      "attn",
      "use_attention_mask"
    ],
    "projection": [
      "self",
      "hidden_states"
    ]
  },
  "BartCrossAttention": {
    "__post_init__": [
      "self",
      "attn"
    ]
  },
  "RBLNBartModelConfig": {},
  "RBLNBartForConditionalGenerationConfig": {
    "support_paged_attention": []
  },
  "RBLNModelForSeq2SeqLM": {
    "main_input_name": [],
    "auto_model_class": [],
    "support_causal_attn": [],
    "_is_stateful": [],
    "__post_init__": [
      "self"
    ],
    "get_compiled_model": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_paged_attention_config": [
      "cls",
      "model_config",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_create_runtimes": [
      "cls",
      "compiled_models",
      "rbln_config"
    ],
    "can_generate": [
      "self"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_attention_mask"
    ],
    "forward": [
      "self",
      "decoder_input_ids",
      "cache_position"
    ],
    "_prepare_encoder_decoder_kwargs_for_generation": [
      "self",
      "inputs_tensor",
      "model_kwargs",
      "model_input_name",
      "generation_config"
    ],
    "generate": [
      "self",
      "input_ids",
      "attention_mask",
      "generation_config"
    ]
  },
  "RBLNModelForSeq2SeqLMConfig": {
    "support_paged_attention": [],
    "__init__": [
      "self",
      "batch_size",
      "enc_max_seq_len",
      "dec_max_seq_len",
      "use_attention_mask",
      "kvcache_num_blocks",
      "kvcache_block_size"
    ]
  },
  "Seq2SeqWrapper": {
    "__init__": [
      "self",
      "model",
      "enc_max_seq_len"
    ]
  },
  "Seq2SeqEncoderWrapper": {
    "__init__": [
      "self",
      "model",
      "enc_max_seq_len"
    ],
    "__post_init__": [
      "self",
      "model"
    ],
    "_extract_cross_kv_projects": [
      "self",
      "decoder_layers"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "b_idx"
    ]
  },
  "Seq2SeqDecoderWrapper": {
    "__init__": [
      "self",
      "model",
      "use_attention_mask"
    ],
    "__post_init__": [
      "self",
      "model"
    ],
    "convert_to_rbln_conditional_generation": [
      "self",
      "model"
    ],
    "forward": [
      "self"
    ]
  },
  "Seq2SeqForConditionalGeneration": {
    "has_rescaling": [],
    "__init__": [
      "self",
      "model",
      "decoder_model"
    ],
    "__post_init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_attention_mask",
      "self_past_key_values",
      "cross_past_key_values",
      "cache_position",
      "block_tables"
    ]
  },
  "Seq2SeqDecoder": {
    "has_pos_emb": [],
    "__init__": [
      "self",
      "model",
      "layers"
    ],
    "__post_init__": [
      "self",
      "model"
    ],
    "get_embedding": [
      "self"
    ],
    "prepare_attn_mask": [
      "self"
    ],
    "apply_position_embedding": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_attention_mask",
      "self_past_key_values",
      "cross_past_key_values",
      "cache_position",
      "block_tables"
    ]
  },
  "Seq2SeqDecoderLayer": {
    "__init__": [
      "self",
      "decoder_layer",
      "self_attn",
      "cross_attn"
    ],
    "__post_init__": [
      "self",
      "decoder_layer"
    ],
    "pre_self_attn_layer_norm": [
      "self",
      "hidden_states"
    ],
    "post_self_attn_layer_norm": [
      "self",
      "hidden_states"
    ],
    "pre_cross_attn_layer_norm": [
      "self",
      "hidden_states"
    ],
    "post_cross_attn_layer_norm": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_attention_mask",
      "self_past_key_value",
      "cross_past_key_value",
      "cache_position",
      "block_tables"
    ]
  },
  "Seq2SeqSelfAttention": {
    "__init__": [
      "self",
      "attn"
    ],
    "__post_init__": [
      "self",
      "attn"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "projection": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "past_key_value",
      "attention_mask",
      "cache_position",
      "block_tables"
    ]
  },
  "Seq2SeqCrossAttention": {
    "__init__": [
      "self",
      "attn"
    ],
    "__post_init__": [
      "self",
      "attn"
    ],
    "forward": [
      "self",
      "hidden_states",
      "key_value_states",
      "past_key_value",
      "attention_mask"
    ]
  },
  "RBLNDetrForObjectDetection": {
    "forward": [
      "self",
      "pixel_values",
      "return_dict"
    ]
  },
  "RBLNDetrForObjectDetectionConfig": {
    "__init__": [
      "self"
    ]
  },
  "RBLNPhiForCausalLM": {
    "_decoder_wrapper_cls": []
  },
  "RBLNPhiModel": {
    "_decoder_wrapper_cls": []
  },
  "PhiWrapper": {
    "get_rbln_attn_class": [
      "self"
    ],
    "get_rbln_layer_class": [
      "self"
    ],
    "get_model_layer": [
      "self",
      "model"
    ],
    "get_decoder_layers": [
      "self",
      "model"
    ]
  },
  "PhiAttention": {
    "__post_init__": [
      "self",
      "self_attn"
    ],
    "projection": [
      "self",
      "hidden_states",
      "lora_int_id"
    ],
    "apply_rotary_pos_embed": [
      "self",
      "query_states",
      "key_states",
      "cos",
      "sin"
    ]
  },
  "PhiLayer": {
    "_POST_ATTN_LAYERNORM": [],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "seq_positions",
      "past_key_values",
      "cos",
      "sin",
      "block_tables",
      "lora_int_id"
    ]
  },
  "RBLNPhiForCausalLMConfig": {},
  "RBLNPhiModelConfig": {},
  "RBLNAutoModel": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForCTC": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForCausalLM": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForSeq2SeqLM": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForSpeechSeq2Seq": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForDepthEstimation": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForSequenceClassification": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForVision2Seq": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForImageTextToText": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForMaskedLM": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForAudioClassification": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForImageClassification": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForQuestionAnswering": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForTextEncoding": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoModelForZeroShotObjectDetection": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "_BaseAutoModelClass": {
    "_model_mapping": [],
    "__init__": [
      "self"
    ],
    "get_rbln_cls": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "infer_hf_model_class": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "get_rbln_model_cls_name": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "from_pretrained": [
      "cls",
      "model_id",
      "export",
      "rbln_config"
    ],
    "from_model": [
      "cls",
      "model",
      "config",
      "rbln_config"
    ],
    "register": [
      "rbln_cls",
      "exist_ok"
    ]
  },
  "RBLNExaoneForCausalLM": {
    "_decoder_wrapper_cls": [],
    "_hf_class": [],
    "_supports_cache_class": [],
    "from_pretrained": [
      "cls",
      "model_id"
    ],
    "__getattr__": [
      "self",
      "__name"
    ]
  },
  "RBLNExaoneForCausalLMConfig": {},
  "ExaoneForCausalLMWrapper": {
    "get_decoder_layers": [
      "self",
      "causal_lm"
    ],
    "get_attn_layer": [
      "self",
      "layer"
    ],
    "get_model_layer": [
      "self",
      "causal_lm"
    ]
  },
  "RBLNSiglipVisionModelConfig": {
    "__init__": [
      "self",
      "batch_size",
      "image_size",
      "interpolate_pos_encoding",
      "output_hidden_states",
      "output_attentions"
    ],
    "image_width": [
      "self"
    ],
    "image_height": [
      "self"
    ]
  },
  "_SiglipVisionModel": {
    "__init__": [
      "self",
      "model",
      "interpolate_pos_encoding",
      "output_hidden_states",
      "output_attentions"
    ],
    "forward": [
      "self",
      "inp"
    ]
  },
  "RBLNSiglipVisionModel": {
    "_tp_support": [],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "return_dict",
      "output_attentions",
      "output_hidden_states",
      "interpolate_pos_encoding"
    ],
    "_prepare_output": [
      "self",
      "output",
      "return_dict"
    ]
  },
  "RBLNDepthAnythingForDepthEstimationConfig": {},
  "RBLNDepthAnythingForDepthEstimation": {
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "RBLNPaliGemmaForConditionalGeneration": {
    "auto_model_class": [],
    "_rbln_submodules": [],
    "__getattr__": [
      "self",
      "__name"
    ],
    "can_generate": [
      "self"
    ],
    "_update_submodule_rbln_config": [
      "cls",
      "submodule_name",
      "submodule_cls",
      "model",
      "submodule_config",
      "submodule_rbln_config",
      "preprocessors"
    ],
    "_reconstruct_model_if_needed": [
      "cls",
      "model"
    ],
    "__post_init__": [
      "self"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "get_attn_impl": [
      "self"
    ],
    "get_kvcache_num_blocks": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "_create_embedding_layer": [
      "self"
    ],
    "_create_multi_modal_projector": [
      "self"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "inputs_embeds",
      "pixel_values",
      "image_sizes",
      "attention_mask",
      "generate_idx",
      "position_ids",
      "token_type_ids"
    ],
    "_update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "get_image_features": [
      "self",
      "pixel_values"
    ],
    "get_placeholder_mask": [
      "self",
      "input_ids",
      "inputs_embeds",
      "image_features"
    ],
    "_preprocess_prefill": [
      "self",
      "input_ids",
      "inputs_embeds",
      "pixel_values"
    ],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "attention_mask",
      "position_ids",
      "token_type_ids",
      "inputs_embeds",
      "cache_position",
      "generate_idx",
      "return_dict"
    ]
  },
  "RBLNPaliGemmaModel": {
    "_rbln_submodules": [],
    "__post_init__": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "_update_submodule_rbln_config": [
      "cls",
      "submodule_name",
      "submodule_cls",
      "model",
      "submodule_config",
      "submodule_rbln_config",
      "preprocessors"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "_create_embedding_layer": [
      "self"
    ],
    "_create_multi_modal_projector": [
      "self"
    ],
    "get_image_features": [
      "self",
      "pixel_values"
    ],
    "get_placeholder_mask": [
      "self",
      "input_ids",
      "inputs_embeds",
      "image_features"
    ],
    "_preprocess_prefill": [
      "self",
      "input_ids",
      "inputs_embeds",
      "pixel_values"
    ],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "attention_mask",
      "position_ids",
      "token_type_ids",
      "inputs_embeds",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "RBLNPaliGemmaForConditionalGenerationConfig": {
    "submodules": [],
    "_allow_no_compile_cfgs": [],
    "__init__": [
      "self",
      "batch_size",
      "vision_tower",
      "language_model",
      "output_hidden_states"
    ]
  },
  "RBLNPaliGemmaModelConfig": {
    "submodules": [],
    "_allow_no_compile_cfgs": [],
    "__init__": [
      "self",
      "batch_size",
      "vision_tower",
      "language_model",
      "output_hidden_states"
    ]
  },
  "MLP": {
    "__init__": [
      "self",
      "fc1",
      "fc2",
      "activation_fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RBLNOPTForCausalLM": {
    "_decoder_wrapper_cls": [],
    "_use_rotary_emb": [],
    "modify_opt_decoder_layer": [
      "layer"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ]
  },
  "RBLNOPTModel": {
    "_decoder_wrapper_cls": [],
    "_use_rotary_emb": [],
    "modify_opt_decoder_layer": [
      "layer"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ]
  },
  "RBLNOPTForCausalLMConfig": {},
  "RBLNOPTModelConfig": {},
  "OPTWrapper": {
    "_use_learned_pos_emb": [],
    "get_model_layer": [
      "self",
      "model"
    ],
    "get_decoder_layers": [
      "self",
      "model"
    ]
  },
  "slice_and_unsqueeze_cos_sin": [
    "cos",
    "sin",
    "position_ids"
  ],
  "RBLNColPaliForRetrievalWrapper": {
    "__init__": [
      "self",
      "causal_lm",
      "embedding_proj_layer",
      "max_seq_len",
      "output_hidden_states"
    ],
    "get_rotary_emb": [
      "self",
      "max_seq_len"
    ],
    "convert_to_rbln_language_model": [
      "self",
      "gemma_model",
      "max_seq_len"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "position_ids"
    ]
  },
  "ColPaliModel": {
    "__init__": [
      "self",
      "model",
      "layers",
      "output_hidden_states",
      "max_seq_len"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "rotary_emb",
      "position_ids"
    ]
  },
  "ColPaliLayer": {
    "__init__": [
      "self",
      "layer",
      "self_attn"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "cos",
      "sin"
    ]
  },
  "ColPaliAttention": {
    "__init__": [
      "self",
      "self_attn"
    ],
    "projection": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "cos",
      "sin"
    ]
  },
  "LoopLanguageModel": {
    "__init__": [
      "self",
      "language_model",
      "rbln_config"
    ],
    "_get_batch_size": [
      "self",
      "inputs_embeds"
    ],
    "_prepare_inputs_before_loop": [
      "self"
    ],
    "_prepare_inputs_for_iteration": [
      "self",
      "index",
      "common_inputs"
    ],
    "_process_outputs": [
      "self",
      "outputs"
    ]
  },
  "RBLNColPaliForRetrieval": {
    "auto_model_class": [],
    "_rbln_submodule_postfix": [],
    "_rbln_submodules": [],
    "__post_init__": [
      "self"
    ],
    "_create_embedding_proj_layer": [
      "self"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "attention_mask",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "RBLNColPaliForRetrievalConfig": {
    "_allow_no_compile_cfgs": [],
    "submodules": [],
    "__init__": [
      "self",
      "batch_size",
      "vlm",
      "output_hidden_states"
    ]
  },
  "RBLNBlip2VisionModelConfig": {
    "__init__": [
      "self",
      "batch_size"
    ]
  },
  "RBLNBlip2QFormerModelConfig": {
    "__init__": [
      "self",
      "batch_size",
      "num_query_tokens",
      "image_text_hidden_size"
    ]
  },
  "RBLNBlip2ForConditionalGenerationConfig": {
    "submodules": [],
    "__init__": [
      "self",
      "batch_size",
      "vision_model",
      "qformer",
      "language_model"
    ]
  },
  "RBLNBlip2VisionModel": {
    "_tp_support": [],
    "get_input_embeddings": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "interpolate_pos_encoding",
      "return_dict"
    ]
  },
  "RBLNBlip2QFormerModel": {
    "_tp_support": [],
    "get_input_embeddings": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_submodule_config": [
      "cls",
      "model",
      "rbln_config",
      "preprocessors"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "forward": [
      "self",
      "query_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "return_dict"
    ]
  },
  "RBLNBlip2ForConditionalGeneration": {
    "auto_model_class": [],
    "_rbln_submodules": [],
    "__getattr__": [
      "self",
      "__name"
    ],
    "can_generate": [
      "self"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "__post_init__": [
      "self"
    ],
    "get_attn_impl": [
      "self"
    ],
    "get_kvcache_num_blocks": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_preprocess_prefill": [
      "self",
      "pixel_values",
      "input_ids",
      "attention_mask",
      "return_dict",
      "interpolate_pos_encoding"
    ],
    "generate": [
      "self",
      "pixel_values",
      "input_ids",
      "attention_mask",
      "inputs_embeds",
      "interpolate_pos_encoding"
    ]
  },
  "RBLNWav2Vec2ForCTCConfig": {
    "__init__": [
      "self",
      "max_seq_len",
      "batch_size"
    ]
  },
  "_Wav2Vec2": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "input_values"
    ]
  },
  "RBLNWav2Vec2ForCTC": {
    "main_input_name": [],
    "auto_model_class": [],
    "rbln_dtype": [],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "forward": [
      "self",
      "input_values",
      "return_dict"
    ]
  },
  "RBLNMixtralForCausalLM": {
    "_decoder_wrapper_cls": []
  },
  "RBLNMixtralForCausalLMConfig": {},
  "MixtralWrapper": {
    "get_rbln_layer_class": [
      "self"
    ]
  },
  "MixtralLayer": {
    "_MLP_ATTR": [],
    "__init__": [
      "self",
      "layer",
      "self_attn",
      "lora_config"
    ],
    "get_mlp": [
      "self"
    ]
  },
  "MixtralSparseMoeBlock": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MixtralBlockSparseTop2MLP": {
    "__init__": [
      "self",
      "expert_list",
      "top_k"
    ],
    "forward": [
      "self",
      "x",
      "router_logits"
    ]
  },
  "RBLNGptOssWrapper": {
    "get_rbln_layer_class": [
      "self"
    ]
  },
  "RBLNGptOssLayer": {
    "__init__": [
      "self",
      "layer",
      "self_attn",
      "lora_config"
    ],
    "get_mlp": [
      "self"
    ]
  },
  "RBLNGptOssTopKRouter": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "RBLNGptOssExperts": {
    "__init__": [
      "self",
      "model",
      "top_k"
    ],
    "forward": [
      "self",
      "hidden_states",
      "router_logits"
    ]
  },
  "RBLNGptOssMLP": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "RBLNGptOssForCausalLM": {
    "_decoder_wrapper_cls": [],
    "_get_dtype": [
      "dtype",
      "torch_dtype"
    ],
    "get_pytorch_model": [
      "cls",
      "model_id"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ]
  },
  "_replace_with_mxfp4_linear": [
    "model",
    "config"
  ],
  "RBLNGptOssForCausalLMConfig": {},
  "LlamaWrapper": {},
  "RBLNLlamaForCausalLM": {
    "_decoder_wrapper_cls": []
  },
  "RBLNLlamaModel": {
    "_decoder_wrapper_cls": []
  },
  "RBLNLlamaForCausalLMConfig": {},
  "RBLNLlamaModelConfig": {},
  "Qwen2_5_VisionTransformerWrapper": {
    "__init__": [
      "self",
      "model",
      "rbln_config"
    ],
    "wrap_vision_blocks": [
      "self",
      "blocks",
      "window_seq_len",
      "rbln_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "full_attn_masks",
      "window_attn_masks",
      "cos",
      "sin"
    ]
  },
  "Qwen2_5_VLVisionBlock": {
    "__init__": [
      "self",
      "model",
      "is_full_attn",
      "window_seq_len",
      "rbln_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attn_masks",
      "position_embeddings"
    ]
  },
  "Qwen2_5_VLVisionFullAttention": {
    "__init__": [
      "self",
      "model",
      "rbln_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attn_masks",
      "position_embeddings"
    ]
  },
  "Qwen2_5_VLVisionWindowAttention": {
    "__init__": [
      "self",
      "model",
      "window_seq_len",
      "rbln_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attn_masks",
      "position_embeddings"
    ]
  },
  "Qwen2_5_VL_LanguageModelWrapper": {
    "get_decoder_layers": [
      "self",
      "model"
    ],
    "get_model_layer": [
      "self",
      "model"
    ],
    "prepare_forward_args": [
      "self"
    ]
  },
  "RBLNQwen2_5_VisionTransformerPretrainedModel": {
    "auto_model_class": [],
    "_supports_non_fp32": [],
    "__post_init__": [
      "self"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "__getattr__": [
      "self",
      "__name"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_pad_for_window_attn_layers": [
      "window_indice",
      "hidden_states",
      "position_embeddings",
      "window_seq_len",
      "max_seq_len"
    ],
    "_pad_for_full_attn_layers": [
      "hidden_state_padded",
      "cos_padded",
      "sin_padded",
      "max_seq_len",
      "window_valid_lengths",
      "window_seq_len"
    ],
    "forward": [
      "self",
      "hidden_states",
      "grid_thw"
    ]
  },
  "RBLNQwen2_5_VLModel": {
    "auto_model_class": [],
    "_decoder_wrapper_cls": [],
    "_use_rotary_emb": [],
    "_rbln_submodules": [],
    "_config_class": [],
    "_rotary_emb_class": [],
    "_get_rope_index_func": [],
    "__post_init__": [
      "self"
    ],
    "logits_last_dim": [
      "self"
    ],
    "_create_embedding_layer": [
      "self"
    ],
    "get_input_info": [
      "cls",
      "batch_size",
      "query_length",
      "rbln_config",
      "model_config"
    ],
    "_get_position_embeddings": [
      "self",
      "hidden_states",
      "position_ids"
    ],
    "_preprocess_prefill": [
      "self",
      "input_ids",
      "attention_mask",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "second_per_grid_ts"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds",
      "attention_mask",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "cache_position",
      "second_per_grid_ts",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "RBLNQwen2_5_VLForConditionalGeneration": {
    "auto_model_class": [],
    "_decoder_wrapper_cls": [],
    "_supports_non_fp32": [],
    "_use_rotary_emb": [],
    "_rbln_submodules": [],
    "__post_init__": [
      "self"
    ],
    "can_generate": [
      "self"
    ],
    "_reconstruct_model_if_needed": [
      "cls",
      "model"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "generate_idx",
      "attention_mask",
      "inputs_embeds",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "second_per_grid_ts"
    ],
    "_preprocess_decoder": [
      "self",
      "input_ids",
      "cache_position"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds",
      "attention_mask",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "cache_position",
      "second_per_grid_ts",
      "generate_idx",
      "return_dict",
      "output_hidden_states"
    ]
  },
  "RBLNQwen2_5_VLForConditionalGenerationConfig": {
    "submodules": [],
    "__init__": [
      "self",
      "use_inputs_embeds",
      "visual"
    ]
  },
  "RBLNQwen2_5_VLModelConfig": {
    "submodules": [],
    "__init__": [
      "self",
      "visual"
    ]
  },
  "RBLNQwen2_5_VisionTransformerPretrainedModelConfig": {
    "__init__": [
      "self",
      "max_seq_lens"
    ]
  },
  "RBLNDecoderOnlyGenerationMixin": {
    "_supports_cache_class": [],
    "_is_stateful": [],
    "_reorder_cache": [
      "self",
      "past_key_values",
      "beam_idx"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "generate_idx",
      "attention_mask",
      "inputs_embeds",
      "padded_cache_lengths"
    ],
    "_update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs"
    ],
    "generate": [
      "self",
      "input_ids",
      "attention_mask",
      "generation_config"
    ]
  },
  "RBLNPageTableManager": {
    "EMPTY_BLOCK": [],
    "NO_BLOCKS_ERROR": [],
    "__init__": [
      "self",
      "rbln_config"
    ],
    "update_block": [
      "self",
      "batch_idx",
      "block_idx"
    ],
    "replace_empty_block": [
      "self",
      "block_tables"
    ],
    "get_block_tables": [
      "self",
      "cache_position",
      "batch_idx",
      "batch_size",
      "phase"
    ],
    "is_external_block_tables": [
      "self",
      "block_tables",
      "local_block_tables"
    ],
    "get_block_tables_if_needed": [
      "self",
      "batch_size",
      "cache_position",
      "batch_idx",
      "phase",
      "block_tables",
      "local_block_tables"
    ]
  },
  "RBLNRuntimeModel": {
    "mandatory_members": [],
    "__init__": [
      "self",
      "runtime",
      "phase",
      "batch_size",
      "dec_attn_mask",
      "page_table_manager",
      "rbln_config",
      "config",
      "logits_last_dim"
    ],
    "inputs_embeddings_if_needed": [
      "self",
      "input_ids",
      "inputs_embeds"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds",
      "cache_position",
      "attention_mask",
      "batch_idx",
      "block_tables",
      "position_embed",
      "position_ids",
      "token_type_ids",
      "local_block_tables",
      "lora_int_ids"
    ],
    "decode_forward": [
      "self",
      "inputs",
      "cache_position",
      "block_tables",
      "is_external_block_tables",
      "attention_mask",
      "position_embed",
      "position_ids",
      "local_block_tables",
      "lora_int_ids"
    ],
    "_prepare_prefill_inputs": [
      "self",
      "inputs",
      "cache_position",
      "attention_mask",
      "position_ids",
      "position_embed",
      "token_type_ids"
    ],
    "_prepare_prefill_outputs": [
      "self",
      "query_length",
      "attention_mask"
    ],
    "prefill_forward": [
      "self",
      "inputs",
      "cache_position",
      "attention_mask",
      "batch_idx",
      "block_tables",
      "is_external_block_tables",
      "position_ids",
      "position_embed",
      "token_type_ids",
      "local_block_tables",
      "lora_int_ids"
    ]
  },
  "RBLNLoRAAdapterConfig": {
    "__init__": [
      "self",
      "lora_int_id",
      "lora_name",
      "lora_path",
      "r",
      "lora_alpha",
      "target_modules",
      "bias",
      "use_rslora",
      "scaling_factor"
    ],
    "_resolve_adapter_path": [
      "self",
      "path"
    ],
    "_load_adapter_config": [
      "self"
    ],
    "_prepare_for_serialization": [
      "self"
    ]
  },
  "RBLNLoRABaseAdapterConfig": {
    "__init__": [
      "self",
      "lora_int_id",
      "lora_name",
      "lora_path",
      "r",
      "lora_alpha",
      "target_modules",
      "bias",
      "use_rslora",
      "scaling_factor"
    ]
  },
  "RBLNLoRAConfig": {
    "__init__": [
      "self",
      "adapters",
      "max_lora_rank"
    ],
    "num_adapters": [
      "self"
    ],
    "adapter_ids": [
      "self"
    ],
    "adapter_names": [
      "self"
    ],
    "get_adapter_by_id": [
      "self",
      "lora_int_id"
    ],
    "get_adapter_by_name": [
      "self",
      "lora_name"
    ],
    "validate_adapter_weights": [
      "self"
    ],
    "_prepare_for_serialization": [
      "self"
    ]
  },
  "LoRALinear": {
    "__init__": [
      "self",
      "original_linear",
      "lora_config",
      "projection_name",
      "layer_idx"
    ],
    "_should_apply_lora": [
      "self"
    ],
    "_load_adapter_weights": [
      "self",
      "adapter_path"
    ],
    "_init_lora_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "lora_int_id"
    ]
  },
  "DecoderOnlyWrapper": {
    "_use_learned_pos_emb": [],
    "__init__": [
      "self",
      "model",
      "rbln_config",
      "use_rotary_emb"
    ],
    "get_rotary_emb": [
      "self",
      "max_seq_len"
    ],
    "get_decoder_layers": [
      "self",
      "model"
    ],
    "get_attn_layer": [
      "self",
      "layer"
    ],
    "get_model_layer": [
      "self",
      "model"
    ],
    "get_rbln_attn_class": [
      "self"
    ],
    "get_rbln_layer_class": [
      "self"
    ],
    "get_rbln_model_class": [
      "self"
    ],
    "get_rbln_causal_lm_class": [
      "self"
    ],
    "convert_to_rbln_class": [
      "self",
      "model",
      "max_seq_len",
      "use_rotary_emb"
    ],
    "phase": [
      "self",
      "phase"
    ],
    "prepare_forward_args": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "DecoderOnlyForCausalLM": {
    "__init__": [
      "self",
      "causal_lm",
      "model"
    ],
    "phase": [
      "self",
      "phase"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds",
      "attention_mask",
      "cache_position",
      "position_ids",
      "query_position",
      "past_key_values",
      "rotary_emb",
      "global_block_tables",
      "local_block_tables",
      "lora_int_id",
      "output_hidden_states"
    ]
  },
  "DecoderOnlyModel": {
    "_EMBEDDING_ATTRS": [],
    "_POSITION_ATTRS": [],
    "_LAYERNORM_ATTRS": [],
    "_PRE_FF_LAYERNORM_ATTRS": [],
    "_POST_FF_LAYERNORM_ATTRS": [],
    "__init__": [
      "self",
      "model",
      "layers",
      "rbln_config",
      "use_learned_pos_emb",
      "use_rotary_emb"
    ],
    "phase": [
      "self",
      "phase"
    ],
    "attn_impl": [
      "self"
    ],
    "hidden_multiplier": [
      "self"
    ],
    "convert_sequence_positions_for_flash_attn": [
      "self",
      "seq_positions",
      "max_seq_len"
    ],
    "get_swa_custom_op_args": [
      "self",
      "position_ids",
      "query_position"
    ],
    "get_last_layernorm": [
      "self"
    ],
    "get_embedding": [
      "self"
    ],
    "get_pos_embedding": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds",
      "attention_mask",
      "cache_position",
      "position_ids",
      "query_position",
      "past_key_values",
      "rotary_emb",
      "global_block_tables",
      "local_block_tables",
      "lora_int_id",
      "output_hidden_states"
    ]
  },
  "DecoderOnlyLayer": {
    "_PRE_ATTN_LAYERNORM": [],
    "_POST_ATTN_LAYERNORM": [],
    "_PRE_FF_LAYERNORM_ATTRS": [],
    "_POST_FF_LAYERNORM_ATTRS": [],
    "_MLP_ATTR": [],
    "__init__": [
      "self",
      "layer",
      "self_attn",
      "lora_config"
    ],
    "phase": [
      "self",
      "phase"
    ],
    "get_pre_attention_layernorm": [
      "self"
    ],
    "get_post_attention_layernorm": [
      "self"
    ],
    "get_pre_feedforward_layernorm": [
      "self"
    ],
    "get_post_feedforward_layernorm": [
      "self"
    ],
    "get_mlp": [
      "self"
    ],
    "forward_mlp": [
      "self",
      "hidden_states",
      "lora_int_id"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "seq_positions",
      "past_key_values",
      "cos",
      "sin",
      "block_tables",
      "lora_int_id"
    ]
  },
  "DecoderOnlyAttention": {
    "_O_PROJ_ATTRS": [],
    "__init__": [
      "self",
      "self_attn",
      "rbln_config",
      "is_sliding"
    ],
    "_init_lora_weights": [
      "self"
    ],
    "get_attention_name": [
      "self"
    ],
    "get_attention_op": [
      "self"
    ],
    "phase": [
      "self",
      "phase"
    ],
    "create_attention_op": [
      "self"
    ],
    "__post_init__": [
      "self",
      "self_attn"
    ],
    "projection": [
      "self",
      "hidden_states",
      "lora_int_id"
    ],
    "apply_rotary_pos_embed": [
      "self",
      "query_states",
      "key_states",
      "cos",
      "sin"
    ],
    "get_attn_scale": [
      "self",
      "self_attn"
    ],
    "maybe_get_kvcache_scale": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "seq_positions",
      "past_key_values",
      "cos",
      "sin",
      "block_tables",
      "lora_int_id"
    ]
  },
  "DecoderOnlyFlashAttention": {
    "__init__": [
      "self"
    ]
  },
  "AttentionOp": {
    "__init__": [
      "self",
      "num_heads",
      "head_dim",
      "num_key_value_heads",
      "rbln_config",
      "is_sliding"
    ],
    "get_attn_op_name": [
      "self"
    ],
    "forward": [
      "self",
      "query_state",
      "key_state",
      "value_state",
      "attn_mask",
      "past_key_state",
      "past_value_state",
      "seq_position",
      "scale",
      "block_tables",
      "block_size",
      "k_scale",
      "v_scale",
      "s_aux"
    ]
  },
  "FlashAttentionOp": {
    "__init__": [
      "self",
      "num_heads",
      "head_dim",
      "num_key_value_heads",
      "kvcache_partition_len",
      "rbln_config",
      "is_sliding"
    ],
    "get_attn_op_name": [
      "self"
    ],
    "forward": [
      "self",
      "query_state",
      "key_state",
      "value_state",
      "attn_mask",
      "past_key_state",
      "past_value_state",
      "seq_position",
      "scale",
      "block_tables",
      "block_size",
      "k_scale",
      "v_scale",
      "s_aux"
    ]
  },
  "SlidingWindowAttentionOp": {
    "__init__": [
      "self",
      "num_heads",
      "head_dim",
      "num_key_value_heads",
      "rbln_config"
    ],
    "get_attn_op_name": [
      "self"
    ],
    "forward": [
      "self",
      "query_state",
      "key_state",
      "value_state",
      "attn_mask",
      "past_key_state",
      "past_value_state",
      "seq_position",
      "scale",
      "block_tables",
      "block_size",
      "k_scale",
      "v_scale",
      "s_aux"
    ]
  },
  "RotaryEmbedding": {
    "__init__": [
      "self",
      "config",
      "max_seq_len_cached"
    ],
    "forward": [
      "self",
      "x",
      "seq_len"
    ]
  },
  "rotate_half": [
    "x"
  ],
  "apply_rotary_pos_emb_partial": [
    "query_states",
    "key_states",
    "cos",
    "sin",
    "ndim"
  ],
  "_get_attr_from_candidates": [
    "src",
    "candidates"
  ],
  "RBLNDecoderOnlyModel": {
    "_tp_support": [],
    "main_input_name": [],
    "auto_model_class": [],
    "_decoder_wrapper_cls": [],
    "_use_rotary_emb": [],
    "_supports_non_fp32": [],
    "__post_init__": [
      "self"
    ],
    "setup_runtime": [
      "self"
    ],
    "logits_last_dim": [
      "self"
    ],
    "get_quantized_model": [
      "cls",
      "model_id",
      "config",
      "use_auth_token",
      "revision",
      "force_download",
      "cache_dir",
      "subfolder",
      "local_files_only",
      "trust_remote_code",
      "rbln_config"
    ],
    "__getattr__": [
      "self",
      "__name"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "_create_embedding_layer": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "can_generate": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_attn_impl": [
      "self"
    ],
    "get_kvcache_num_blocks": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_compile_model": [
      "cls",
      "wrapped_model",
      "compile_config",
      "example_inputs",
      "compile_context",
      "rbln_config",
      "quantization",
      "phase"
    ],
    "_get_compile_context": [
      "cls",
      "compile_config",
      "example_inputs"
    ],
    "get_compiled_model": [
      "cls",
      "model",
      "rbln_config"
    ],
    "get_pytorch_model": [
      "cls"
    ],
    "use_query_position": [
      "cls",
      "use_local_attention",
      "is_prefill",
      "logits_to_keep"
    ],
    "get_input_info": [
      "cls",
      "batch_size",
      "query_length",
      "rbln_config",
      "model_config"
    ],
    "_update_sliding_window_config": [
      "cls",
      "model_config",
      "rbln_config"
    ],
    "_update_attention_config": [
      "cls",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_create_runtimes": [
      "cls",
      "compiled_models",
      "rbln_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds",
      "attention_mask",
      "position_ids",
      "position_embed",
      "output_hidden_states"
    ]
  },
  "RBLNDecoderOnlyModelForCausalLM": {
    "auto_model_class": [],
    "logits_last_dim": [
      "self"
    ],
    "set_lora_int_ids": [
      "self",
      "lora_int_ids"
    ],
    "set_adapter": [
      "self",
      "adapter_name"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds",
      "cache_position",
      "attention_mask",
      "generate_idx",
      "padded_cache_lengths",
      "position_ids",
      "token_type_ids",
      "lora_int_ids",
      "return_dict",
      "output_hidden_states"
    ]
  },
  "CacheImplType": [],
  "PhaseType": [],
  "RBLNDecoderOnlyModelConfig": {
    "_default_phases": [],
    "_default_logits_to_keep": [],
    "__init__": [
      "self",
      "batch_size",
      "max_seq_len",
      "use_inputs_embeds",
      "use_attention_mask",
      "use_position_ids",
      "attn_impl",
      "kvcache_partition_len",
      "kvcache_block_size",
      "quantization",
      "lora_config",
      "prefill_chunk_size",
      "kvcache_num_blocks",
      "decoder_batch_sizes",
      "cache_impl",
      "sliding_window",
      "sliding_window_layers",
      "phases",
      "logits_to_keep",
      "output_hidden_states",
      "kvcache_metas"
    ],
    "validate_phases_type": [
      "phases"
    ],
    "use_global_attention": [
      "self"
    ],
    "use_local_attention": [
      "self"
    ],
    "use_multiple_decoder": [
      "self"
    ],
    "use_lora": [
      "self"
    ],
    "can_generate": [
      "self"
    ],
    "use_image_prefill": [
      "self"
    ],
    "image_prefill_runtime_idx": [
      "self"
    ],
    "expected_compiled_model_names": [
      "self"
    ],
    "decoder_runtime_idx": [
      "self"
    ],
    "nbits_per_param": [
      "self"
    ],
    "is_auto_num_blocks": [
      "self"
    ],
    "num_full_blocks": [
      "self"
    ],
    "num_min_blocks": [
      "self"
    ]
  },
  "RBLNDecoderOnlyModelForCausalLMConfig": {
    "_default_phases": [],
    "_default_logits_to_keep": []
  },
  "KVCacheMeta": {
    "_prepare_for_serialization": [
      "self"
    ],
    "compile_shape": [
      "self"
    ],
    "can_resize": [
      "self"
    ],
    "num_blocks": [
      "self"
    ],
    "block_size": [
      "self"
    ],
    "make": [
      "name",
      "layer_index",
      "num_key_value_heads",
      "head_dim",
      "dtype",
      "rbln_config"
    ]
  },
  "RBLNRuntimeVisionModel": {
    "mandatory_members": [],
    "__init__": [
      "self",
      "runtime",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "patch_attention_mask",
      "return_dict"
    ]
  },
  "RBLNIdefics3VisionTransformer": {
    "_tp_support": [],
    "__post_init__": [
      "self"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "patch_attention_mask",
      "return_dict"
    ]
  },
  "RBLNIdefics3ForConditionalGeneration": {
    "auto_model_class": [],
    "_rbln_submodules": [],
    "_rbln_submodule_prefix": [],
    "__getattr__": [
      "self",
      "__name"
    ],
    "can_generate": [
      "self"
    ],
    "_reconstruct_model_if_needed": [
      "cls",
      "model"
    ],
    "__post_init__": [
      "self"
    ],
    "get_attn_impl": [
      "self"
    ],
    "get_kvcache_num_blocks": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "attention_mask",
      "inputs_embeds",
      "cache_position",
      "pixel_values",
      "pixel_attention_mask",
      "image_hidden_states",
      "generate_idx"
    ],
    "_update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "inputs_merger": [
      "self",
      "input_ids",
      "inputs_embeds",
      "image_hidden_states"
    ],
    "_preprocess_prefill": [
      "self",
      "input_ids",
      "inputs_embeds",
      "pixel_values",
      "pixel_attention_mask",
      "image_hidden_states"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "inputs_embeds",
      "pixel_values",
      "pixel_attention_mask",
      "image_hidden_states",
      "cache_position",
      "generate_idx",
      "return_dict"
    ]
  },
  "RBLNIdefics3VisionTransformerConfig": {
    "__init__": [
      "self",
      "batch_size"
    ]
  },
  "RBLNIdefics3ForConditionalGenerationConfig": {
    "submodules": [],
    "__init__": [
      "self",
      "batch_size",
      "vision_model",
      "text_model"
    ]
  },
  "RBLNLlavaForConditionalGenerationConfig": {
    "submodules": [],
    "__init__": [
      "self",
      "batch_size",
      "vision_tower",
      "language_model"
    ]
  },
  "RBLNLlavaForConditionalGeneration": {
    "auto_model_class": [],
    "_rbln_submodules": [],
    "__getattr__": [
      "self",
      "__name"
    ],
    "can_generate": [
      "self"
    ],
    "_reconstruct_model_if_needed": [
      "cls",
      "model"
    ],
    "__post_init__": [
      "self"
    ],
    "get_attn_impl": [
      "self"
    ],
    "get_kvcache_num_blocks": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "inputs_embeds",
      "pixel_values",
      "attention_mask",
      "cache_position",
      "image_sizes",
      "generate_idx"
    ],
    "_update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "vision_feature_layer",
      "vision_feature_select_strategy"
    ],
    "_preprocess_prefill": [
      "self",
      "input_ids",
      "pixel_values",
      "inputs_embeds",
      "vision_feature_layer",
      "vision_feature_select_strategy",
      "return_dict",
      "image_sizes"
    ],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "attention_mask",
      "inputs_embeds",
      "return_dict",
      "cache_position",
      "image_sizes",
      "generate_idx"
    ]
  },
  "RBLNGroundingDinoForObjectDetection": {
    "_rbln_submodules": [],
    "__post_init__": [
      "self"
    ],
    "_setup_cpu_instances": [
      "self"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "_reconstruct_model_if_needed": [
      "cls",
      "model"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "generate_encoder_output_proposals": [
      "self"
    ],
    "get_valid_ratio": [
      "self"
    ],
    "_model_forward": [
      "self",
      "pixel_values",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "pixel_mask",
      "encoder_outputs",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "_init_reference_points"
    ],
    "pad_image_to_rbln_config": [
      "self",
      "pixel_values",
      "pixel_mask"
    ],
    "pad_text_to_rbln_config": [
      "self",
      "input_ids",
      "token_type_ids",
      "attention_mask"
    ],
    "forward": [
      "self",
      "pixel_values",
      "input_ids",
      "token_type_ids",
      "attention_mask",
      "pixel_mask",
      "encoder_outputs",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "_update_spatial_shapes": [
    "model_config",
    "rbln_config"
  ],
  "RBLNGroundingDinoEncoder": {
    "__post_init__": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_submodule_config": [
      "cls",
      "model",
      "rbln_config",
      "preprocessors"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "get_reference_points": [
      "spatial_shapes",
      "valid_ratios",
      "device"
    ],
    "validate_output_config": [
      "self",
      "output_attentions",
      "output_hidden_states"
    ],
    "forward": [
      "self",
      "vision_features",
      "vision_attention_mask",
      "vision_position_embedding",
      "spatial_shapes",
      "spatial_shapes_list",
      "level_start_index",
      "valid_ratios",
      "text_features",
      "text_attention_mask",
      "text_position_embedding",
      "text_self_attention_masks",
      "text_position_ids",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "RBLNGroundingDinoDecoder": {
    "__post_init__": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_submodule_config": [
      "cls",
      "model",
      "rbln_config",
      "preprocessors"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "validate_output_config": [
      "self",
      "output_attentions",
      "output_hidden_states"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "vision_encoder_hidden_states",
      "vision_encoder_attention_mask",
      "text_encoder_hidden_states",
      "text_encoder_attention_mask",
      "reference_points",
      "valid_ratios",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "RBLNGroundingDinoForObjectDetectionConfig": {
    "submodules": [],
    "__init__": [
      "self",
      "batch_size",
      "encoder",
      "decoder",
      "text_backbone",
      "backbone",
      "output_attentions",
      "output_hidden_states"
    ]
  },
  "RBLNGroundingDinoComponentConfig": {
    "__init__": [
      "self",
      "image_size",
      "batch_size",
      "spatial_shapes_list",
      "output_attentions",
      "output_hidden_states"
    ],
    "spatial_shapes": [
      "self"
    ]
  },
  "RBLNGroundingDinoEncoderConfig": {},
  "RBLNGroundingDinoDecoderConfig": {},
  "monkey_patch": [],
  "restore_monkey_patch": [
    "original_forward",
    "original_bi_multihead_attention_forward",
    "original_encoder_layer_forward",
    "original_multiscale_deform_attn"
  ],
  "monkey_patch_decorator": [
    "func"
  ],
  "get_sine_pos_embed": [
    "pos_tensor",
    "num_pos_feats",
    "temperature",
    "exchange_xy"
  ],
  "_GroundingDinoEncoder": {
    "__init__": [
      "self",
      "model",
      "rbln_config"
    ],
    "forward": [
      "self",
      "vision_features",
      "vision_attention_mask",
      "vision_position_embedding",
      "text_features",
      "text_attention_mask",
      "text_self_attention_masks",
      "reference_points"
    ]
  },
  "_GroundingDinoDecoder": {
    "__init__": [
      "self",
      "model",
      "rbln_config"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "vision_encoder_hidden_states",
      "vision_encoder_attention_mask",
      "text_encoder_hidden_states",
      "text_encoder_attention_mask",
      "reference_points",
      "valid_ratios"
    ]
  },
  "_GroundingDinoEncoderLayer": {
    "forward": [
      "self",
      "vision_features",
      "vision_position_embedding",
      "spatial_shapes",
      "spatial_shapes_list",
      "level_start_index",
      "key_padding_mask",
      "reference_points",
      "text_features",
      "text_attention_mask",
      "text_position_embedding",
      "text_self_attention_masks",
      "text_position_ids"
    ]
  },
  "_GroundingDinoMultiscaleDeformableAttention": {
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "position_embeddings",
      "reference_points",
      "spatial_shapes",
      "spatial_shapes_list",
      "level_start_index",
      "output_attentions"
    ]
  },
  "_GroundingDinoBiMultiHeadAttention": {
    "forward": [
      "self",
      "vision_features",
      "text_features",
      "vision_attention_mask",
      "text_attention_mask"
    ]
  },
  "_MultiScaleDeformableAttention": {
    "forward": [
      "self",
      "value",
      "value_spatial_shapes",
      "value_spatial_shapes_list",
      "level_start_index",
      "sampling_grids",
      "attention_weights",
      "im2col_step"
    ]
  },
  "RBLNPixtralVisionModelConfig": {
    "__init__": [
      "self",
      "max_image_size",
      "batch_size",
      "output_hidden_states"
    ]
  },
  "PixtralAttention": {
    "__init__": [
      "self",
      "self_attention"
    ],
    "__post_init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_embeddings",
      "output_attentions"
    ]
  },
  "RBLNRuntimePixtralVisionModel": {
    "mandatory_members": [],
    "__init__": [
      "self",
      "runtime",
      "config",
      "rbln_config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "image_sizes",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "_PixtralVisionModel": {
    "__init__": [
      "self",
      "model",
      "output_hidden_states"
    ],
    "convert_to_rbln_pixtral_vision_model": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "patch_embeds",
      "attention_mask",
      "position_embeddings_1",
      "position_embeddings_2"
    ]
  },
  "RBLNPixtralVisionModel": {
    "__post_init__": [
      "self"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "image_sizes",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "remove_compile_time_kwargs": [
    "func"
  ],
  "warn_deprecated_npu": [
    "npu"
  ],
  "Action": {
    "NONE": [],
    "NOTIFY": [],
    "RAISE": []
  },
  "deprecate_kwarg": [
    "old_name",
    "version",
    "new_name",
    "deprecated_type",
    "value_replacer",
    "raise_if_greater_or_equal_version",
    "raise_if_both_names",
    "additional_message"
  ],
  "deprecate_method": [
    "version",
    "new_method",
    "raise_if_greater_or_equal_version",
    "additional_message"
  ],
  "pull_compiled_model_from_hub": [
    "model_id",
    "subfolder",
    "token",
    "revision",
    "cache_dir",
    "force_download",
    "local_files_only"
  ],
  "validate_files": [
    "files",
    "config_files",
    "location"
  ],
  "_get_huggingface_token": [
    "token"
  ],
  "RBLN_PREFIX": [],
  "MODEL_MAPPING": [],
  "convert_hf_to_rbln_model_name": [
    "hf_model_name"
  ],
  "convert_rbln_to_hf_model_name": [
    "rbln_model_name"
  ],
  "get_rbln_model_cls": [
    "cls_name"
  ],
  "SubModulesMixin": {
    "__init__": [
      "self"
    ],
    "_get_submodule_config_class": [
      "cls",
      "cls_name",
      "submodule_rbln_config"
    ],
    "_update_submodule_config": [
      "cls",
      "model",
      "rbln_config",
      "preprocessors"
    ],
    "_update_submodule_rbln_config": [
      "cls",
      "submodule_name",
      "submodule_cls",
      "model",
      "submodule_config",
      "submodule_rbln_config",
      "preprocessors"
    ],
    "_export_submodules_from_model": [
      "cls",
      "model",
      "model_save_dir",
      "rbln_config"
    ],
    "_load_submodules_from_compiled_models": [
      "cls",
      "model_save_dir",
      "rbln_config"
    ],
    "_load_submodules": [
      "cls",
      "model_save_dir",
      "rbln_config",
      "model"
    ]
  },
  "maybe_load_preprocessors": [
    "src_name_or_path",
    "subfolder",
    "trust_remote_code"
  ],
  "maybe_save_preprocessors": [
    "src_name_or_path",
    "dest_dir",
    "src_subfolder",
    "trust_remote_code"
  ],
  "VersionCompat": {},
  "RBLN_VERSION_COMPATS": [],
  "is_rbln_available": [],
  "check_version_compats": [],
  "_lock": [],
  "log_levels": [],
  "_default_log_level": [],
  "_get_default_logging_level": [],
  "_get_library_name": [],
  "_get_library_root_logger": [],
  "_configure_library_root_logger": [],
  "get_logger": [
    "name"
  ],
  "is_compiler_supports_buffer_resize": [],
  "get_available_dram": [
    "npu"
  ],
  "normalize_npu": [
    "npu"
  ],
  "tp_and_devices_are_ok": [
    "tensor_parallel_size",
    "device",
    "npu"
  ],
  "RBLNPytorchRuntime": {
    "mandatory_members": [],
    "__init__": [
      "self",
      "runtime"
    ],
    "__call__": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "parameters": [
      "self"
    ]
  },
  "UnavailableRuntime": {
    "__call__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__iter__": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ContextRblnConfig": {
    "_local": [],
    "__init__": [
      "self",
      "device",
      "device_map",
      "create_runtimes",
      "activate_profiler",
      "timeout"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "get_current_context": [
      "cls"
    ]
  },
  "RBLNDiffusionMixinConfig": {},
  "RBLNDiffusionMixin": {
    "_connected_classes": [],
    "_submodules": [],
    "_optional_submodules": [],
    "_prefix": [],
    "_maybe_apply_and_fuse_lora": [
      "model",
      "lora_ids",
      "lora_weights_names",
      "lora_scales"
    ],
    "get_rbln_config_class": [
      "cls"
    ],
    "get_hf_class": [
      "cls"
    ],
    "from_pretrained": [
      "cls",
      "model_id"
    ],
    "_compile_pipelines": [
      "cls",
      "model",
      "passed_submodules",
      "model_save_dir",
      "rbln_config"
    ],
    "_compile_submodules": [
      "cls",
      "model",
      "passed_submodules",
      "model_save_dir",
      "rbln_config",
      "prefix"
    ],
    "_compile_multicontrolnet": [
      "cls",
      "controlnets",
      "model_save_dir",
      "controlnet_rbln_config",
      "prefix"
    ],
    "_construct_pipe": [
      "cls",
      "model",
      "submodules",
      "model_save_dir",
      "rbln_config"
    ],
    "get_compiled_image_size": [
      "self"
    ],
    "handle_additional_kwargs": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "RBLNCosmosPipelineBaseConfig": {
    "submodules": [],
    "_vae_uses_encoder": [],
    "__init__": [
      "self",
      "text_encoder",
      "transformer",
      "vae",
      "safety_checker"
    ],
    "batch_size": [
      "self"
    ],
    "max_seq_len": [
      "self"
    ]
  },
  "RBLNCosmosTextToWorldPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNCosmosVideoToWorldPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNStableDiffusionControlNetPipelineBaseConfig": {
    "submodules": [],
    "_vae_uses_encoder": [],
    "__init__": [
      "self",
      "text_encoder",
      "unet",
      "vae",
      "controlnet"
    ],
    "batch_size": [
      "self"
    ],
    "sample_size": [
      "self"
    ],
    "image_size": [
      "self"
    ]
  },
  "RBLNStableDiffusionControlNetPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNStableDiffusionControlNetImg2ImgPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNStableDiffusionXLControlNetPipelineBaseConfig": {
    "submodules": [],
    "_vae_uses_encoder": [],
    "__init__": [
      "self",
      "text_encoder",
      "text_encoder_2",
      "unet",
      "vae",
      "controlnet"
    ],
    "batch_size": [
      "self"
    ],
    "sample_size": [
      "self"
    ],
    "image_size": [
      "self"
    ]
  },
  "RBLNStableDiffusionXLControlNetPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNStableDiffusionXLControlNetImg2ImgPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNStableDiffusionXLPipelineBaseConfig": {
    "submodules": [],
    "_vae_uses_encoder": [],
    "__init__": [
      "self",
      "text_encoder",
      "text_encoder_2",
      "unet",
      "vae"
    ],
    "batch_size": [
      "self"
    ],
    "sample_size": [
      "self"
    ],
    "image_size": [
      "self"
    ]
  },
  "RBLNStableDiffusionXLPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNStableDiffusionXLImg2ImgPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNStableDiffusionXLInpaintPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNKandinskyV22PipelineBaseConfig": {
    "submodules": [],
    "_movq_uses_encoder": [],
    "__init__": [
      "self",
      "unet",
      "movq"
    ],
    "batch_size": [
      "self"
    ],
    "image_size": [
      "self"
    ]
  },
  "RBLNKandinskyV22PipelineConfig": {
    "_movq_uses_encoder": []
  },
  "RBLNKandinskyV22Img2ImgPipelineConfig": {
    "_movq_uses_encoder": []
  },
  "RBLNKandinskyV22InpaintPipelineConfig": {
    "_movq_uses_encoder": []
  },
  "RBLNKandinskyV22PriorPipelineConfig": {
    "submodules": [],
    "__init__": [
      "self",
      "text_encoder",
      "image_encoder",
      "prior"
    ],
    "batch_size": [
      "self"
    ],
    "image_size": [
      "self"
    ]
  },
  "RBLNKandinskyV22CombinedPipelineBaseConfig": {
    "submodules": [],
    "_decoder_pipe_cls": [],
    "__init__": [
      "self",
      "prior_pipe",
      "decoder_pipe"
    ],
    "batch_size": [
      "self"
    ],
    "image_size": [
      "self"
    ],
    "prior_prior": [
      "self"
    ],
    "prior_image_encoder": [
      "self"
    ],
    "prior_text_encoder": [
      "self"
    ],
    "unet": [
      "self"
    ],
    "movq": [
      "self"
    ]
  },
  "RBLNKandinskyV22CombinedPipelineConfig": {
    "_decoder_pipe_cls": []
  },
  "RBLNKandinskyV22InpaintCombinedPipelineConfig": {
    "_decoder_pipe_cls": []
  },
  "RBLNKandinskyV22Img2ImgCombinedPipelineConfig": {
    "_decoder_pipe_cls": []
  },
  "RBLNStableVideoDiffusionPipelineConfig": {
    "submodules": [],
    "_vae_uses_encoder": [],
    "__init__": [
      "self",
      "image_encoder",
      "unet",
      "vae"
    ],
    "batch_size": [
      "self"
    ],
    "sample_size": [
      "self"
    ],
    "image_size": [
      "self"
    ]
  },
  "RBLNStableDiffusion3PipelineBaseConfig": {
    "submodules": [],
    "_vae_uses_encoder": [],
    "__init__": [
      "self",
      "transformer",
      "text_encoder",
      "text_encoder_2",
      "text_encoder_3",
      "vae"
    ],
    "max_seq_len": [
      "self"
    ],
    "batch_size": [
      "self"
    ],
    "sample_size": [
      "self"
    ],
    "image_size": [
      "self"
    ]
  },
  "RBLNStableDiffusion3PipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNStableDiffusion3Img2ImgPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNStableDiffusion3InpaintPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNStableDiffusionPipelineBaseConfig": {
    "submodules": [],
    "_vae_uses_encoder": [],
    "__init__": [
      "self",
      "text_encoder",
      "unet",
      "vae"
    ],
    "batch_size": [
      "self"
    ],
    "sample_size": [
      "self"
    ],
    "image_size": [
      "self"
    ]
  },
  "RBLNStableDiffusionPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNStableDiffusionImg2ImgPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNStableDiffusionInpaintPipelineConfig": {
    "_vae_uses_encoder": []
  },
  "RBLNAutoencoderKLTemporalDecoderConfig": {
    "__init__": [
      "self",
      "batch_size",
      "sample_size",
      "uses_encoder",
      "num_frames",
      "decode_chunk_size",
      "vae_scale_factor"
    ],
    "image_size": [
      "self"
    ],
    "latent_sample_size": [
      "self"
    ]
  },
  "RBLNControlNetModelConfig": {
    "subclass_non_save_attributes": [],
    "__init__": [
      "self",
      "batch_size",
      "max_seq_len",
      "unet_sample_size",
      "vae_sample_size",
      "text_model_hidden_size"
    ],
    "batch_size_is_specified": [
      "self"
    ]
  },
  "RBLNSD3Transformer2DModelConfig": {
    "subclass_non_save_attributes": [],
    "__init__": [
      "self",
      "batch_size",
      "sample_size",
      "prompt_embed_length"
    ],
    "batch_size_is_specified": [
      "self"
    ]
  },
  "RBLNAutoencoderKLCosmosConfig": {
    "__init__": [
      "self",
      "batch_size",
      "uses_encoder",
      "num_frames",
      "height",
      "width",
      "num_channels_latents",
      "vae_scale_factor_temporal",
      "vae_scale_factor_spatial",
      "use_slicing"
    ],
    "image_size": [
      "self"
    ]
  },
  "RBLNVQModelConfig": {
    "__init__": [
      "self",
      "batch_size",
      "sample_size",
      "uses_encoder",
      "vqmodel_scale_factor",
      "in_channels",
      "latent_channels"
    ],
    "image_size": [
      "self"
    ],
    "latent_sample_size": [
      "self"
    ]
  },
  "RBLNUNetSpatioTemporalConditionModelConfig": {
    "subclass_non_save_attributes": [],
    "__init__": [
      "self",
      "batch_size",
      "sample_size",
      "in_features",
      "num_frames"
    ],
    "batch_size_is_specified": [
      "self"
    ]
  },
  "RBLNPriorTransformerConfig": {
    "subclass_non_save_attributes": [],
    "__init__": [
      "self",
      "batch_size",
      "embedding_dim",
      "num_embeddings"
    ],
    "batch_size_is_specified": [
      "self"
    ]
  },
  "RBLNCosmosTransformer3DModelConfig": {
    "__init__": [
      "self",
      "batch_size",
      "num_frames",
      "height",
      "width",
      "fps",
      "max_seq_len",
      "embedding_dim",
      "num_channels_latents",
      "num_latent_frames",
      "latent_height",
      "latent_width"
    ]
  },
  "RBLNAutoencoderKLConfig": {
    "__init__": [
      "self",
      "batch_size",
      "sample_size",
      "uses_encoder",
      "vae_scale_factor",
      "in_channels",
      "latent_channels"
    ],
    "image_size": [
      "self"
    ],
    "latent_sample_size": [
      "self"
    ]
  },
  "RBLNUNet2DConditionModelConfig": {
    "subclass_non_save_attributes": [],
    "__init__": [
      "self",
      "batch_size",
      "sample_size",
      "in_channels",
      "cross_attention_dim",
      "use_additional_residuals",
      "max_seq_len",
      "in_features",
      "text_model_hidden_size",
      "image_model_hidden_size"
    ],
    "batch_size_is_specified": [
      "self"
    ]
  },
  "RBLNAutoPipelineBase": {
    "_model_mapping": [],
    "_model_mapping_names": [],
    "get_rbln_cls": [
      "cls",
      "pretrained_model_name_or_path",
      "export"
    ],
    "get_rbln_model_cls_name": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "_is_compiled_pipeline": [
      "cls",
      "pretrained_model_name_or_path",
      "cache_dir",
      "force_download",
      "proxies",
      "token",
      "local_files_only",
      "revision"
    ],
    "infer_hf_model_class": [
      "cls",
      "pretrained_model_or_path",
      "cache_dir",
      "force_download",
      "proxies",
      "token",
      "local_files_only",
      "revision"
    ],
    "get_pipeline_key_name": [
      "cls",
      "config"
    ],
    "from_pretrained": [
      "cls",
      "model_id"
    ],
    "register": [
      "rbln_cls",
      "exist_ok"
    ]
  },
  "RBLNAutoPipelineForText2Image": {
    "_model_mapping": [],
    "_model_mapping_names": []
  },
  "RBLNAutoPipelineForImage2Image": {
    "_model_mapping": [],
    "_model_mapping_names": [],
    "get_pipeline_key_name": [
      "cls",
      "config"
    ]
  },
  "RBLNAutoPipelineForInpainting": {
    "_model_mapping": [],
    "_model_mapping_names": [],
    "get_pipeline_key_name": [
      "cls",
      "config"
    ]
  },
  "RBLNKandinskyV22PriorPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": []
  },
  "RBLNKandinskyV22Img2ImgPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": [],
    "get_compiled_image_size": [
      "self"
    ]
  },
  "RBLNKandinskyV22InpaintPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": [],
    "get_compiled_image_size": [
      "self"
    ]
  },
  "RBLNKandinskyV22CombinedPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_connected_classes": [],
    "_submodules": [],
    "_prefix": [],
    "__init__": [
      "self",
      "unet",
      "scheduler",
      "movq",
      "prior_prior",
      "prior_image_encoder",
      "prior_text_encoder",
      "prior_tokenizer",
      "prior_scheduler",
      "prior_image_processor"
    ],
    "get_compiled_image_size": [
      "self"
    ]
  },
  "RBLNKandinskyV22Img2ImgCombinedPipeline": {
    "original_class": [],
    "_connected_classes": [],
    "_submodules": [],
    "_prefix": [],
    "__init__": [
      "self",
      "unet",
      "scheduler",
      "movq",
      "prior_prior",
      "prior_image_encoder",
      "prior_text_encoder",
      "prior_tokenizer",
      "prior_scheduler",
      "prior_image_processor"
    ],
    "get_compiled_image_size": [
      "self"
    ]
  },
  "RBLNKandinskyV22InpaintCombinedPipeline": {
    "original_class": [],
    "_connected_classes": [],
    "_submodules": [],
    "_prefix": [],
    "__init__": [
      "self",
      "unet",
      "scheduler",
      "movq",
      "prior_prior",
      "prior_image_encoder",
      "prior_text_encoder",
      "prior_tokenizer",
      "prior_scheduler",
      "prior_image_processor"
    ],
    "get_compiled_image_size": [
      "self"
    ]
  },
  "RBLNKandinskyV22Pipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": [],
    "get_compiled_image_size": [
      "self"
    ]
  },
  "RBLNCosmosTextToWorldPipeline": {
    "original_class": [],
    "_submodules": [],
    "_optional_submodules": [],
    "__init__": [
      "self",
      "text_encoder",
      "tokenizer",
      "transformer",
      "vae",
      "scheduler",
      "safety_checker"
    ],
    "handle_additional_kwargs": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "model_id"
    ]
  },
  "RBLNVideoSafetyModelConfig": {
    "__init__": [
      "self",
      "batch_size",
      "input_size",
      "image_size"
    ]
  },
  "RBLNRetinaFaceFilterConfig": {
    "__init__": [
      "self",
      "batch_size",
      "image_size"
    ]
  },
  "RBLNCosmosSafetyCheckerConfig": {
    "submodules": [],
    "__init__": [
      "self",
      "llamaguard3",
      "video_safety_model",
      "face_blur_filter",
      "siglip_encoder"
    ]
  },
  "is_compiled_dir": [
    "dir"
  ],
  "get_image_features": [
    "self",
    "pixel_values",
    "return_dict",
    "output_attentions",
    "output_hidden_states",
    "interpolate_pos_encoding"
  ],
  "RBLNSigLIPEncoder": {
    "__init__": [
      "self",
      "model_name",
      "checkpoint_id",
      "rbln_config"
    ],
    "save_pretrained": [
      "self",
      "checkpoint_id"
    ]
  },
  "RBLNRetinaFaceFilter": {
    "__init__": [
      "self",
      "checkpoint_id",
      "batch_size",
      "confidence_threshold",
      "rbln_config"
    ],
    "save_pretrained": [
      "self",
      "checkpoint_id"
    ]
  },
  "RBLNVideoSafetyModel": {
    "__init__": [
      "self",
      "config",
      "checkpoint_id",
      "rbln_config"
    ],
    "save_pretrained": [
      "self",
      "checkpoint_id"
    ],
    "parameters": [
      "self"
    ]
  },
  "RBLNVideoContentSafetyFilter": {
    "__init__": [
      "self",
      "checkpoint_id",
      "rbln_config"
    ],
    "save_pretrained": [
      "self",
      "checkpoint_id"
    ]
  },
  "RBLNLlamaGuard3": {
    "__init__": [
      "self",
      "checkpoint_id",
      "base_model_id",
      "rbln_config"
    ],
    "save_pretrained": [
      "self",
      "checkpoint_id"
    ]
  },
  "RBLNCosmosSafetyChecker": {
    "__init__": [
      "self",
      "checkpoint_id",
      "llamaguard_model_id",
      "rbln_config"
    ],
    "save_pretrained": [
      "self",
      "save_dir"
    ],
    "from_pretrained": [
      "cls",
      "checkpoint_id",
      "rbln_config",
      "subfolder",
      "export"
    ],
    "prepare_rbln_config": [
      "cls",
      "rbln_config"
    ]
  },
  "RBLNCosmosVideoToWorldPipeline": {
    "original_class": [],
    "_submodules": [],
    "_optional_submodules": [],
    "__init__": [
      "self",
      "text_encoder",
      "tokenizer",
      "transformer",
      "vae",
      "scheduler",
      "safety_checker"
    ],
    "handle_additional_kwargs": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "model_id"
    ]
  },
  "RBLNStableDiffusion3Img2ImgPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": []
  },
  "RBLNStableDiffusion3Pipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": []
  },
  "RBLNStableDiffusion3InpaintPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": []
  },
  "RBLNStableDiffusionXLControlNetImg2ImgPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": [],
    "check_inputs": [
      "self",
      "prompt",
      "prompt_2",
      "image",
      "strength",
      "num_inference_steps",
      "callback_steps",
      "negative_prompt",
      "negative_prompt_2",
      "prompt_embeds",
      "negative_prompt_embeds",
      "pooled_prompt_embeds",
      "negative_pooled_prompt_embeds",
      "ip_adapter_image",
      "ip_adapter_image_embeds",
      "controlnet_conditioning_scale",
      "control_guidance_start",
      "control_guidance_end",
      "callback_on_step_end_tensor_inputs"
    ],
    "__call__": [
      "self",
      "prompt",
      "prompt_2",
      "image",
      "control_image",
      "height",
      "width",
      "strength",
      "num_inference_steps",
      "guidance_scale",
      "negative_prompt",
      "negative_prompt_2",
      "num_images_per_prompt",
      "eta",
      "generator",
      "latents",
      "prompt_embeds",
      "negative_prompt_embeds",
      "pooled_prompt_embeds",
      "negative_pooled_prompt_embeds",
      "ip_adapter_image",
      "ip_adapter_image_embeds",
      "output_type",
      "return_dict",
      "cross_attention_kwargs",
      "controlnet_conditioning_scale",
      "guess_mode",
      "control_guidance_start",
      "control_guidance_end",
      "original_size",
      "crops_coords_top_left",
      "target_size",
      "negative_original_size",
      "negative_crops_coords_top_left",
      "negative_target_size",
      "aesthetic_score",
      "negative_aesthetic_score",
      "clip_skip",
      "callback_on_step_end",
      "callback_on_step_end_tensor_inputs"
    ]
  },
  "RBLNMultiControlNetModel": {
    "hf_library_name": [],
    "_hf_class": [],
    "__init__": [
      "self",
      "models"
    ],
    "compiled_models": [
      "self"
    ],
    "_from_pretrained": [
      "cls",
      "model_id"
    ],
    "save_pretrained": [
      "self",
      "save_directory"
    ],
    "_update_rbln_config": [
      "cls"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "encoder_hidden_states",
      "controlnet_cond",
      "conditioning_scale",
      "class_labels",
      "timestep_cond",
      "attention_mask",
      "added_cond_kwargs",
      "cross_attention_kwargs",
      "guess_mode",
      "return_dict"
    ]
  },
  "RBLNStableDiffusionControlNetPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": [],
    "check_inputs": [
      "self",
      "prompt",
      "image",
      "callback_steps",
      "negative_prompt",
      "prompt_embeds",
      "negative_prompt_embeds",
      "ip_adapter_image",
      "ip_adapter_image_embeds",
      "controlnet_conditioning_scale",
      "control_guidance_start",
      "control_guidance_end",
      "callback_on_step_end_tensor_inputs"
    ],
    "__call__": [
      "self",
      "prompt",
      "image",
      "height",
      "width",
      "num_inference_steps",
      "timesteps",
      "guidance_scale",
      "negative_prompt",
      "num_images_per_prompt",
      "eta",
      "generator",
      "latents",
      "prompt_embeds",
      "negative_prompt_embeds",
      "ip_adapter_image",
      "ip_adapter_image_embeds",
      "output_type",
      "return_dict",
      "cross_attention_kwargs",
      "controlnet_conditioning_scale",
      "guess_mode",
      "control_guidance_start",
      "control_guidance_end",
      "clip_skip",
      "callback_on_step_end",
      "callback_on_step_end_tensor_inputs"
    ]
  },
  "RBLNStableDiffusionControlNetImg2ImgPipeline": {
    "original_class": [],
    "_submodules": [],
    "_rbln_config_class": [],
    "check_inputs": [
      "self",
      "prompt",
      "image",
      "callback_steps",
      "negative_prompt",
      "prompt_embeds",
      "negative_prompt_embeds",
      "ip_adapter_image",
      "ip_adapter_image_embeds",
      "controlnet_conditioning_scale",
      "control_guidance_start",
      "control_guidance_end",
      "callback_on_step_end_tensor_inputs"
    ],
    "__call__": [
      "self",
      "prompt",
      "image",
      "control_image",
      "height",
      "width",
      "strength",
      "num_inference_steps",
      "guidance_scale",
      "negative_prompt",
      "num_images_per_prompt",
      "eta",
      "generator",
      "latents",
      "prompt_embeds",
      "negative_prompt_embeds",
      "ip_adapter_image",
      "ip_adapter_image_embeds",
      "output_type",
      "return_dict",
      "cross_attention_kwargs",
      "controlnet_conditioning_scale",
      "guess_mode",
      "control_guidance_start",
      "control_guidance_end",
      "clip_skip",
      "callback_on_step_end",
      "callback_on_step_end_tensor_inputs"
    ]
  },
  "RBLNStableDiffusionXLControlNetPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": [],
    "check_inputs": [
      "self",
      "prompt",
      "prompt_2",
      "image",
      "callback_steps",
      "negative_prompt",
      "negative_prompt_2",
      "prompt_embeds",
      "negative_prompt_embeds",
      "pooled_prompt_embeds",
      "ip_adapter_image",
      "ip_adapter_image_embeds",
      "negative_pooled_prompt_embeds",
      "controlnet_conditioning_scale",
      "control_guidance_start",
      "control_guidance_end",
      "callback_on_step_end_tensor_inputs"
    ],
    "__call__": [
      "self",
      "prompt",
      "prompt_2",
      "image",
      "height",
      "width",
      "num_inference_steps",
      "denoising_end",
      "guidance_scale",
      "negative_prompt",
      "negative_prompt_2",
      "num_images_per_prompt",
      "eta",
      "generator",
      "latents",
      "prompt_embeds",
      "negative_prompt_embeds",
      "pooled_prompt_embeds",
      "negative_pooled_prompt_embeds",
      "ip_adapter_image",
      "ip_adapter_image_embeds",
      "output_type",
      "return_dict",
      "cross_attention_kwargs",
      "controlnet_conditioning_scale",
      "guess_mode",
      "control_guidance_start",
      "control_guidance_end",
      "original_size",
      "crops_coords_top_left",
      "target_size",
      "negative_original_size",
      "negative_crops_coords_top_left",
      "negative_target_size",
      "clip_skip",
      "callback_on_step_end",
      "callback_on_step_end_tensor_inputs"
    ]
  },
  "RBLNStableDiffusionXLInpaintPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": []
  },
  "RBLNStableDiffusionXLImg2ImgPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": []
  },
  "RBLNStableDiffusionXLPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": []
  },
  "RBLNStableVideoDiffusionPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": [],
    "handle_additional_kwargs": [
      "self"
    ]
  },
  "RBLNStableDiffusionImg2ImgPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": []
  },
  "RBLNStableDiffusionInpaintPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": []
  },
  "RBLNStableDiffusionPipeline": {
    "original_class": [],
    "_rbln_config_class": [],
    "_submodules": []
  },
  "_ControlNetModel": {
    "__init__": [
      "self",
      "controlnet"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "controlnet_cond",
      "conditioning_scale",
      "text_embeds",
      "time_ids"
    ]
  },
  "_ControlNetModel_Cross_Attention": {
    "__init__": [
      "self",
      "controlnet"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "encoder_hidden_states",
      "controlnet_cond",
      "conditioning_scale",
      "text_embeds",
      "time_ids"
    ]
  },
  "RBLNControlNetModel": {
    "hf_library_name": [],
    "auto_model_class": [],
    "output_class": [],
    "__post_init__": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "update_rbln_config_using_pipe": [
      "cls",
      "pipe",
      "rbln_config",
      "submodule_name"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "compiled_batch_size": [
      "self"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "encoder_hidden_states",
      "controlnet_cond",
      "conditioning_scale",
      "added_cond_kwargs",
      "return_dict"
    ],
    "_prepare_output": [
      "self",
      "output",
      "return_dict"
    ]
  },
  "CosmosTransformer3DModelWrapper": {
    "__init__": [
      "self",
      "model",
      "num_latent_frames",
      "latent_height",
      "latent_width"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "embedded_timestep",
      "temb",
      "image_rotary_emb_0",
      "image_rotary_emb_1",
      "extra_pos_emb",
      "attention_mask",
      "return_dict"
    ]
  },
  "RBLNCosmosTransformer3DModel": {
    "hf_library_name": [],
    "auto_model_class": [],
    "__post_init__": [
      "self"
    ],
    "compute_embedding": [
      "self",
      "hidden_states",
      "timestep",
      "attention_mask",
      "fps",
      "condition_mask",
      "padding_mask"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "update_rbln_config_using_pipe": [
      "cls",
      "pipe",
      "rbln_config",
      "submodule_name"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_create_runtimes": [
      "cls",
      "compiled_models",
      "rbln_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "timestep",
      "encoder_hidden_states",
      "attention_mask",
      "fps",
      "condition_mask",
      "padding_mask",
      "return_dict"
    ]
  },
  "SD3Transformer2DModelWrapper": {
    "__init__": [
      "self",
      "model"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "pooled_projections",
      "timestep",
      "block_controlnet_hidden_states",
      "joint_attention_kwargs",
      "return_dict"
    ]
  },
  "RBLNSD3Transformer2DModel": {
    "hf_library_name": [],
    "auto_model_class": [],
    "_output_class": [],
    "__post_init__": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "update_rbln_config_using_pipe": [
      "cls",
      "pipe",
      "rbln_config",
      "submodule_name"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "compiled_batch_size": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "pooled_projections",
      "timestep",
      "block_controlnet_hidden_states",
      "joint_attention_kwargs",
      "return_dict"
    ]
  },
  "_PriorTransformer": {
    "__init__": [
      "self",
      "prior"
    ],
    "forward": [
      "self",
      "hidden_states",
      "timestep",
      "proj_embedding",
      "encoder_hidden_states",
      "attention_mask",
      "return_dict"
    ]
  },
  "RBLNPriorTransformer": {
    "hf_library_name": [],
    "auto_model_class": [],
    "_output_class": [],
    "__post_init__": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "update_rbln_config_using_pipe": [
      "cls",
      "pipe",
      "rbln_config",
      "submodule_name"
    ],
    "save_torch_artifacts": [
      "cls",
      "model",
      "save_dir_path",
      "subfolder",
      "rbln_config"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "post_process_latents": [
      "self",
      "prior_latents"
    ],
    "forward": [
      "self",
      "hidden_states",
      "timestep",
      "proj_embedding",
      "encoder_hidden_states",
      "attention_mask",
      "return_dict"
    ]
  },
  "RBLNVQModel": {
    "auto_model_class": [],
    "config_name": [],
    "hf_library_name": [],
    "__post_init__": [
      "self"
    ],
    "get_compiled_model": [
      "cls",
      "model",
      "rbln_config"
    ],
    "update_rbln_config_using_pipe": [
      "cls",
      "pipe",
      "rbln_config",
      "submodule_name"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_create_runtimes": [
      "cls",
      "compiled_models",
      "rbln_config"
    ],
    "encode": [
      "self",
      "x",
      "return_dict"
    ],
    "decode": [
      "self",
      "h",
      "return_dict"
    ]
  },
  "RBLNAutoencoderKLTemporalDecoder": {
    "auto_model_class": [],
    "hf_library_name": [],
    "_rbln_config_class": [],
    "__post_init__": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "get_compiled_model": [
      "cls",
      "model",
      "rbln_config"
    ],
    "get_vae_sample_size": [
      "cls",
      "pipe",
      "rbln_config",
      "return_vae_scale_factor"
    ],
    "update_rbln_config_using_pipe": [
      "cls",
      "pipe",
      "rbln_config",
      "submodule_name"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_create_runtimes": [
      "cls",
      "compiled_models",
      "rbln_config"
    ],
    "encode": [
      "self",
      "x",
      "return_dict"
    ],
    "decode": [
      "self",
      "z",
      "return_dict"
    ]
  },
  "RBLNAutoencoderKL": {
    "auto_model_class": [],
    "hf_library_name": [],
    "_rbln_config_class": [],
    "__post_init__": [
      "self"
    ],
    "get_compiled_model": [
      "cls",
      "model",
      "rbln_config"
    ],
    "get_vae_sample_size": [
      "cls",
      "pipe",
      "rbln_config",
      "return_vae_scale_factor"
    ],
    "update_rbln_config_using_pipe": [
      "cls",
      "pipe",
      "rbln_config",
      "submodule_name"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_create_runtimes": [
      "cls",
      "compiled_models",
      "rbln_config"
    ],
    "encode": [
      "self",
      "x",
      "return_dict"
    ],
    "decode": [
      "self",
      "z",
      "return_dict"
    ]
  },
  "RBLNAutoencoderKLCosmos": {
    "auto_model_class": [],
    "hf_library_name": [],
    "_rbln_config_class": [],
    "__post_init__": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "get_compiled_model": [
      "cls",
      "model",
      "rbln_config"
    ],
    "update_rbln_config_using_pipe": [
      "cls",
      "pipe",
      "rbln_config",
      "submodule_name"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "_create_runtimes": [
      "cls",
      "compiled_models",
      "rbln_config"
    ],
    "encode": [
      "self",
      "x",
      "return_dict"
    ],
    "decode": [
      "self",
      "z",
      "return_dict"
    ]
  },
  "RBLNRuntimeVAEEncoder": {
    "encode": [
      "self",
      "x"
    ]
  },
  "RBLNRuntimeVAEDecoder": {
    "decode": [
      "self",
      "z"
    ]
  },
  "RBLNRuntimeCosmosVAEEncoder": {
    "encode": [
      "self",
      "x"
    ]
  },
  "RBLNRuntimeCosmosVAEDecoder": {
    "decode": [
      "self",
      "z"
    ]
  },
  "_VAEDecoder": {
    "__init__": [
      "self",
      "vae"
    ],
    "forward": [
      "self",
      "z"
    ]
  },
  "_VAETemporalDecoder": {
    "__init__": [
      "self",
      "vae"
    ],
    "forward": [
      "self",
      "z"
    ]
  },
  "_VAEEncoder": {
    "__init__": [
      "self",
      "vae"
    ],
    "encode": [
      "self",
      "x",
      "return_dict"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_VAECosmosEncoder": {
    "__init__": [
      "self",
      "vae"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_VAECosmosDecoder": {
    "__init__": [
      "self",
      "vae"
    ],
    "forward": [
      "self",
      "z"
    ]
  },
  "RBLNRuntimeVQEncoder": {
    "encode": [
      "self",
      "x"
    ]
  },
  "RBLNRuntimeVQDecoder": {
    "decode": [
      "self",
      "h",
      "force_not_quantize",
      "shape"
    ]
  },
  "_VQEncoder": {
    "__init__": [
      "self",
      "vq_model"
    ],
    "encode": [
      "self",
      "x",
      "return_dict"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_VQDecoder": {
    "__init__": [
      "self",
      "vq_model"
    ],
    "decode": [
      "self",
      "h",
      "force_not_quantize",
      "return_dict",
      "shape"
    ],
    "forward": [
      "self",
      "h"
    ]
  },
  "_UNet_SD": {
    "__init__": [
      "self",
      "unet"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "encoder_hidden_states"
    ]
  },
  "_UNet_SDXL": {
    "__init__": [
      "self",
      "unet"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "encoder_hidden_states"
    ]
  },
  "_UNet_Kandinsky": {
    "__init__": [
      "self",
      "unet"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "image_embeds"
    ]
  },
  "RBLNUNet2DConditionModel": {
    "hf_library_name": [],
    "auto_model_class": [],
    "_rbln_config_class": [],
    "_output_class": [],
    "__post_init__": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "get_unet_sample_size": [
      "cls",
      "pipe",
      "rbln_config",
      "image_size"
    ],
    "update_rbln_config_using_pipe": [
      "cls",
      "pipe",
      "rbln_config",
      "submodule_name"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "compiled_batch_size": [
      "self"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "encoder_hidden_states",
      "class_labels",
      "timestep_cond",
      "attention_mask",
      "cross_attention_kwargs",
      "added_cond_kwargs",
      "down_block_additional_residuals",
      "mid_block_additional_residual",
      "down_intrablock_additional_residuals",
      "encoder_attention_mask",
      "return_dict"
    ]
  },
  "_UNet_STCM": {
    "__init__": [
      "self",
      "unet"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "encoder_hidden_states",
      "added_time_ids"
    ]
  },
  "RBLNUNetSpatioTemporalConditionModel": {
    "hf_library_name": [],
    "auto_model_class": [],
    "_rbln_config_class": [],
    "output_class": [],
    "output_key": [],
    "__post_init__": [
      "self"
    ],
    "_wrap_model_if_needed": [
      "cls",
      "model",
      "rbln_config"
    ],
    "get_unet_sample_size": [
      "cls",
      "pipe",
      "rbln_config",
      "image_size"
    ],
    "update_rbln_config_using_pipe": [
      "cls",
      "pipe",
      "rbln_config",
      "submodule_name"
    ],
    "_update_rbln_config": [
      "cls",
      "preprocessors",
      "model",
      "model_config",
      "rbln_config"
    ],
    "compiled_batch_size": [
      "self"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "encoder_hidden_states",
      "added_time_ids",
      "return_dict"
    ]
  }
}