{
  "__all__": [],
  "main": [],
  "_title_case_display": [
    "s"
  ],
  "_build_choices_and_map": [
    "items"
  ],
  "_dtype_from_str": [
    "s"
  ],
  "_maybe": [
    "v"
  ],
  "build_parser": [],
  "_resolve_checkpoint": [
    "args"
  ],
  "_collect_gen_kwargs": [
    "args"
  ],
  "_normalize_audio": [
    "wav",
    "eps",
    "clip"
  ],
  "_audio_to_tuple": [
    "audio"
  ],
  "_wav_to_gradio_audio": [
    "wav",
    "sr"
  ],
  "_detect_model_kind": [
    "ckpt",
    "tts"
  ],
  "build_demo": [
    "tts",
    "ckpt",
    "gen_kwargs_default"
  ],
  "AudioLike": [],
  "MaybeList": [],
  "VoiceClonePromptItem": {},
  "Qwen3TTSModel": {
    "__init__": [
      "self",
      "model",
      "processor",
      "generate_defaults"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "_supported_languages_set": [
      "self"
    ],
    "_supported_speakers_set": [
      "self"
    ],
    "_validate_languages": [
      "self",
      "languages"
    ],
    "_validate_speakers": [
      "self",
      "speakers"
    ],
    "_is_probably_base64": [
      "self",
      "s"
    ],
    "_is_url": [
      "self",
      "s"
    ],
    "_decode_base64_to_wav_bytes": [
      "self",
      "b64"
    ],
    "_load_audio_to_np": [
      "self",
      "x"
    ],
    "_normalize_audio_inputs": [
      "self",
      "audios"
    ],
    "_ensure_list": [
      "self",
      "x"
    ],
    "_build_assistant_text": [
      "self",
      "text"
    ],
    "_build_ref_text": [
      "self",
      "text"
    ],
    "_build_instruct_text": [
      "self",
      "instruct"
    ],
    "_tokenize_texts": [
      "self",
      "texts"
    ],
    "_merge_generate_kwargs": [
      "self",
      "do_sample",
      "top_k",
      "top_p",
      "temperature",
      "repetition_penalty",
      "subtalker_dosample",
      "subtalker_top_k",
      "subtalker_top_p",
      "subtalker_temperature",
      "max_new_tokens"
    ],
    "create_voice_clone_prompt": [
      "self",
      "ref_audio",
      "ref_text",
      "x_vector_only_mode"
    ],
    "_prompt_items_to_voice_clone_prompt": [
      "self",
      "items"
    ],
    "generate_voice_clone": [
      "self",
      "text",
      "language",
      "ref_audio",
      "ref_text",
      "x_vector_only_mode",
      "voice_clone_prompt",
      "non_streaming_mode"
    ],
    "generate_voice_design": [
      "self",
      "text",
      "instruct",
      "language",
      "non_streaming_mode"
    ],
    "generate_custom_voice": [
      "self",
      "text",
      "speaker",
      "language",
      "instruct",
      "non_streaming_mode"
    ],
    "get_supported_speakers": [
      "self"
    ],
    "get_supported_languages": [
      "self"
    ]
  },
  "AudioInput": [],
  "Qwen3TTSTokenizer": {
    "__init__": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "_is_probably_base64": [
      "self",
      "s"
    ],
    "_is_url": [
      "self",
      "s"
    ],
    "_decode_base64_to_wav_bytes": [
      "self",
      "b64"
    ],
    "load_audio": [
      "self",
      "x",
      "target_sr"
    ],
    "_normalize_audio_inputs": [
      "self",
      "audios",
      "sr"
    ],
    "encode": [
      "self",
      "audios",
      "sr",
      "return_dict"
    ],
    "decode": [
      "self",
      "encoded"
    ],
    "get_model_type": [
      "self"
    ],
    "get_input_sample_rate": [
      "self"
    ],
    "get_output_sample_rate": [
      "self"
    ],
    "get_encode_downsample_rate": [
      "self"
    ],
    "get_decode_upsample_rate": [
      "self"
    ]
  },
  "logger": [],
  "Qwen3TTSTokenizerV2DecoderConfig": {
    "__init__": [
      "self",
      "codebook_size",
      "hidden_size",
      "latent_dim",
      "max_position_embeddings",
      "rope_theta",
      "num_attention_heads",
      "num_key_value_heads",
      "attention_bias",
      "sliding_window",
      "intermediate_size",
      "hidden_act",
      "layer_scale_initial_scale",
      "rms_norm_eps",
      "num_hidden_layers",
      "num_quantizers",
      "upsample_rates",
      "upsampling_ratios",
      "decoder_dim",
      "attention_dropout"
    ],
    "layer_types": [
      "self"
    ]
  },
  "Qwen3TTSTokenizerV2Config": {
    "model_type": [],
    "sub_configs": [],
    "__init__": [
      "self",
      "encoder_config",
      "decoder_config",
      "encoder_valid_num_quantizers",
      "input_sample_rate",
      "output_sample_rate",
      "decode_upsample_rate",
      "encode_downsample_rate"
    ]
  },
  "Qwen3TTSTokenizerV2EncoderOutput": {},
  "Qwen3TTSTokenizerV2DecoderOutput": {},
  "rotate_half": [
    "x"
  ],
  "apply_rotary_pos_emb": [
    "q",
    "k",
    "cos",
    "sin",
    "position_ids",
    "unsqueeze_dim"
  ],
  "repeat_kv": [
    "hidden_states",
    "n_rep"
  ],
  "eager_attention_forward": [
    "module",
    "query",
    "key",
    "value",
    "attention_mask",
    "scaling",
    "dropout"
  ],
  "Qwen3TTSTokenizerV2DecoderPreTrainedModel": {
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_skip_keys_device_placement": [],
    "_supports_flash_attn": [],
    "_supports_sdpa": [],
    "_can_compile_fullgraph": [],
    "_supports_attention_backend": []
  },
  "Qwen3TTSTokenizerV2CausalConvNet": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dilation",
      "stride",
      "groups"
    ],
    "_get_extra_padding_for_conv1d": [
      "self",
      "hidden_state"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "Qwen3TTSTokenizerV2CausalTransConvNet": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "Qwen3TTSTokenizerV2ConvNeXtBlock": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen3TTSTokenizerV2DecoderRotatoryEmbedding": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "Qwen3TTSTokenizerV2DecoderAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_embeddings",
      "attention_mask",
      "past_key_values",
      "cache_position"
    ]
  },
  "Qwen3TTSTokenizerV2DecoderMlp": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3TTSTokenizerV2DecoderRMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "Qwen3TTSTokenizerV2DecoderLayerScale": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3TTSTokenizerV2DecoderTransformerLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "use_cache",
      "cache_position"
    ]
  },
  "Qwen3TTSTokenizerV2DecoderTransformerModel": {
    "_can_record_outputs": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "cache_position"
    ]
  },
  "SnakeBeta": {
    "__init__": [
      "self",
      "in_features",
      "alpha"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen3TTSTokenizerV2DecoderDecoderResidualUnit": {
    "__init__": [
      "self",
      "dim",
      "dilation"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "Qwen3TTSTokenizerV2DecoderDecoderBlock": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden"
    ]
  },
  "EuclideanCodebook": {
    "__init__": [
      "self",
      "dim",
      "codebook_size",
      "epsilon"
    ],
    "decode": [
      "self",
      "codes"
    ]
  },
  "VectorQuantization": {
    "__init__": [
      "self",
      "dim",
      "codebook_size",
      "codebook_dim",
      "epsilon"
    ],
    "decode": [
      "self",
      "codes"
    ]
  },
  "ResidualVectorQuantization": {
    "__init__": [
      "self"
    ],
    "decode": [
      "self",
      "codes"
    ]
  },
  "ResidualVectorQuantizer": {
    "__init__": [
      "self",
      "dimension",
      "input_dimension",
      "output_dimension",
      "n_q",
      "q_dropout",
      "no_quantization_rate",
      "bins",
      "decay",
      "force_projection"
    ],
    "decode": [
      "self",
      "codes"
    ]
  },
  "SplitResidualVectorQuantizer": {
    "__init__": [
      "self"
    ],
    "decode": [
      "self",
      "codes"
    ]
  },
  "Qwen3TTSTokenizerV2Decoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "codes"
    ],
    "chunked_decode": [
      "self",
      "codes",
      "chunk_size",
      "left_context_size"
    ]
  },
  "Qwen3TTSTokenizerV2Encoder": {
    "__init__": [
      "self",
      "config"
    ]
  },
  "Qwen3TTSTokenizerV2PreTrainedModel": {
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_skip_keys_device_placement": [],
    "_supports_flash_attn": [],
    "_supports_sdpa": [],
    "_can_compile_fullgraph": [],
    "_supports_attention_backend": []
  },
  "Qwen3TTSTokenizerV2Model": {
    "__init__": [
      "self",
      "config"
    ],
    "get_model_type": [
      "self"
    ],
    "get_input_sample_rate": [
      "self"
    ],
    "get_output_sample_rate": [
      "self"
    ],
    "get_encode_downsample_rate": [
      "self"
    ],
    "get_decode_upsample_rate": [
      "self"
    ],
    "encode": [
      "self",
      "input_values",
      "padding_mask",
      "return_dict"
    ],
    "decode": [
      "self",
      "audio_codes",
      "return_dict"
    ]
  },
  "Qwen3TTSProcessorKwargs": {
    "_defaults": []
  },
  "Qwen3TTSProcessor": {
    "attributes": [],
    "tokenizer_class": [],
    "__init__": [
      "self",
      "tokenizer",
      "chat_template"
    ],
    "__call__": [
      "self",
      "text"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "apply_chat_template": [
      "self",
      "conversations",
      "chat_template"
    ],
    "model_input_names": [
      "self"
    ]
  },
  "download_weights_from_hf_specific": [
    "model_name_or_path",
    "cache_dir",
    "allow_patterns",
    "revision",
    "ignore_patterns"
  ],
  "Res2NetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "scale",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SqueezeExcitationBlock": {
    "__init__": [
      "self",
      "in_channels",
      "se_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AttentiveStatisticsPooling": {
    "__init__": [
      "self",
      "channels",
      "attention_channels"
    ],
    "_length_to_mask": [
      "self",
      "length",
      "max_len",
      "dtype",
      "device"
    ],
    "_compute_statistics": [
      "self",
      "x",
      "m",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "TimeDelayNetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SqueezeExcitationRes2NetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "res2net_scale",
      "se_channels",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "Qwen3TTSSpeakerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "dynamic_range_compression_torch": [
    "x",
    "C",
    "clip_val"
  ],
  "mel_spectrogram": [
    "y",
    "n_fft",
    "num_mels",
    "sampling_rate",
    "hop_size",
    "win_size",
    "fmin",
    "fmax",
    "center"
  ],
  "Qwen3TTSPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "_skip_keys_device_placement": [],
    "_supports_flash_attn": [],
    "_supports_sdpa": [],
    "_supports_cache_class": [],
    "_supports_static_cache": [],
    "_supports_attention_backend": [],
    "_init_weights": [
      "self",
      "module"
    ]
  },
  "Qwen3TTSTalkerTextPreTrainedModel": {
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "_skip_keys_device_placement": [],
    "_supports_flash_attn": [],
    "_supports_sdpa": [],
    "_supports_flex_attn": [],
    "_supports_cache_class": [],
    "_supports_quantized_cache": [],
    "_supports_static_cache": [],
    "_supports_attention_backend": [],
    "_init_weights": [
      "self",
      "module"
    ]
  },
  "Qwen3TTSTalkerRotaryEmbedding": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "Qwen3TTSRotaryEmbedding": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "Qwen3TTSRMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "apply_multimodal_rotary_pos_emb": [
    "q",
    "k",
    "cos",
    "sin",
    "mrope_section",
    "mrope_interleaved",
    "unsqueeze_dim"
  ],
  "Qwen3TTSTalkerAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_embeddings",
      "attention_mask",
      "past_key_values",
      "cache_position"
    ]
  },
  "Qwen3TTSTalkerResizeMLP": {
    "__init__": [
      "self",
      "input_size",
      "intermediate_size",
      "output_size",
      "act",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "Qwen3TTSTalkerCodePredictorOutputWithPast": {},
  "Qwen3TTSTalkerTextMLP": {
    "__init__": [
      "self",
      "config",
      "intermediate_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3TTSAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_embeddings",
      "attention_mask",
      "past_key_values",
      "cache_position"
    ]
  },
  "Qwen3TTSDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "output_attentions",
      "use_cache",
      "cache_position",
      "position_embeddings"
    ]
  },
  "Qwen3TTSTalkerCodePredictorModel": {
    "config_class": [],
    "base_model_prefix": [],
    "__init__": [
      "self",
      "config",
      "embedding_dim"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "cache_position",
      "generation_steps"
    ]
  },
  "Qwen3TTSTalkerCodePredictorModelForConditionalGeneration": {
    "_tied_weights_keys": [],
    "_tp_plan": [],
    "_pp_plan": [],
    "config_class": [],
    "base_model_prefix": [],
    "__init__": [
      "self",
      "config",
      "talker_config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "forward_finetune": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "cache_position",
      "generation_steps"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "cache_position",
      "generation_steps"
    ],
    "_update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder",
      "num_new_tokens"
    ]
  },
  "Qwen3TTSTalkerOutputWithPast": {},
  "Qwen3TTSTalkerDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "output_attentions",
      "use_cache",
      "cache_position",
      "position_embeddings"
    ]
  },
  "Qwen3TTSTalkerModel": {
    "config_class": [],
    "base_model_prefix": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_text_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "cache_position"
    ]
  },
  "Qwen3TTSTalkerForConditionalGeneration": {
    "_tied_weights_keys": [],
    "_tp_plan": [],
    "_pp_plan": [],
    "config_class": [],
    "base_model_prefix": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_text_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "new_embeddings"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "forward_sub_talker_finetune": [
      "self",
      "codec_ids",
      "talker_hidden_states"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "cache_position",
      "past_hidden",
      "trailing_text_hidden",
      "tts_pad_embed",
      "generation_step",
      "subtalker_dosample",
      "subtalker_top_p",
      "subtalker_top_k",
      "subtalker_temperature"
    ],
    "get_rope_index": [
      "self",
      "attention_mask"
    ],
    "_update_model_kwargs_for_generation": [
      "self",
      "outputs",
      "model_kwargs",
      "is_encoder_decoder",
      "num_new_tokens"
    ]
  },
  "Qwen3TTSForConditionalGeneration": {
    "config_class": [],
    "__init__": [
      "self",
      "config"
    ],
    "load_speech_tokenizer": [
      "self",
      "speech_tokenizer"
    ],
    "load_generate_config": [
      "self",
      "generate_config"
    ],
    "get_supported_speakers": [
      "self"
    ],
    "get_supported_languages": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "extract_speaker_embedding": [
      "self",
      "audio",
      "sr"
    ],
    "generate_speaker_prompt": [
      "self",
      "voice_clone_prompt"
    ],
    "generate_icl_prompt": [
      "self",
      "text_id",
      "ref_id",
      "ref_code",
      "tts_pad_embed",
      "tts_eos_embed",
      "non_streaming_mode"
    ],
    "generate": [
      "self",
      "input_ids",
      "instruct_ids",
      "ref_ids",
      "voice_clone_prompt",
      "languages",
      "speakers",
      "non_streaming_mode",
      "max_new_tokens",
      "do_sample",
      "top_k",
      "top_p",
      "temperature",
      "subtalker_dosample",
      "subtalker_top_k",
      "subtalker_top_p",
      "subtalker_temperature",
      "eos_token_id",
      "repetition_penalty"
    ]
  },
  "Qwen3TTSSpeakerEncoderConfig": {
    "__init__": [
      "self",
      "mel_dim",
      "enc_dim",
      "enc_channels",
      "enc_kernel_sizes",
      "enc_dilations",
      "enc_attention_channels",
      "enc_res2net_scale",
      "enc_se_channels",
      "sample_rate"
    ]
  },
  "Qwen3TTSTalkerCodePredictorConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "base_model_tp_plan": [],
    "base_model_pp_plan": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "head_dim",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_theta",
      "rope_scaling",
      "attention_bias",
      "use_sliding_window",
      "sliding_window",
      "max_window_layers",
      "layer_types",
      "attention_dropout",
      "num_code_groups"
    ]
  },
  "Qwen3TTSTalkerConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "base_model_tp_plan": [],
    "base_model_pp_plan": [],
    "sub_configs": [],
    "__init__": [
      "self",
      "code_predictor_config",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_theta",
      "rope_scaling",
      "attention_bias",
      "use_sliding_window",
      "sliding_window",
      "attention_dropout",
      "num_code_groups",
      "text_hidden_size",
      "codec_eos_token_id",
      "codec_think_id",
      "codec_nothink_id",
      "codec_think_bos_id",
      "codec_think_eos_id",
      "codec_pad_id",
      "codec_bos_id",
      "spk_id",
      "spk_is_dialect",
      "codec_language_id"
    ]
  },
  "Qwen3TTSConfig": {
    "model_type": [],
    "sub_configs": [],
    "__init__": [
      "self",
      "talker_config",
      "speaker_encoder_config",
      "tokenizer_type",
      "tts_model_size",
      "tts_model_type",
      "im_start_token_id",
      "im_end_token_id",
      "tts_pad_token_id",
      "tts_bos_token_id",
      "tts_eos_token_id"
    ]
  },
  "Qwen3TTSTokenizerV1EncoderOutput": {},
  "Qwen3TTSTokenizerV1DecoderOutput": {},
  "Qwen3TTSTokenizerV1DecoderPreTrainedModel": {
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_skip_keys_device_placement": [],
    "_supports_flash_attn": [],
    "_supports_sdpa": [],
    "_can_compile_fullgraph": [],
    "_supports_attention_backend": []
  },
  "Qwen3TTSTokenizerV1EncoderPreTrainedModel": {
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_skip_keys_device_placement": [],
    "_supports_flash_attn": [],
    "_supports_sdpa": [],
    "_can_compile_fullgraph": [],
    "_supports_attention_backend": []
  },
  "Qwen3TTSTokenizerV1DecoderDiTRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "base"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ECAPA_TimeDelayNet": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DiTInputEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "speaker_embedding",
      "condition_vector",
      "code_embed",
      "drop_audio_cond",
      "code_embed_uncond",
      "apply_cfg"
    ]
  },
  "DiTCodecEmbedding": {
    "__init__": [
      "self",
      "codec_num_embeds",
      "codec_dim",
      "repeats"
    ],
    "forward": [
      "self",
      "code",
      "drop_code"
    ]
  },
  "AdaLayerNormZero": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "emb"
    ]
  },
  "AdaLayerNormZero_Final": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "emb"
    ]
  },
  "DiTMLP": {
    "__init__": [
      "self",
      "dim",
      "mult",
      "dropout"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DiTAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_embeddings",
      "attention_mask"
    ]
  },
  "SinusPositionEmbedding": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "scale"
    ]
  },
  "DiTTimestepEmbedding": {
    "__init__": [
      "self",
      "dim",
      "freq_embed_dim"
    ],
    "forward": [
      "self",
      "timestep"
    ]
  },
  "DiTDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "look_ahead_block",
      "look_backward_block"
    ],
    "forward": [
      "self",
      "hidden_states",
      "timestep",
      "position_embeddings",
      "block_diff"
    ]
  },
  "kaiser_sinc_filter1d": [
    "cutoff",
    "half_width",
    "kernel_size"
  ],
  "UpSample1d": {
    "__init__": [
      "self",
      "ratio",
      "kernel_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DownSample1d": {
    "__init__": [
      "self",
      "ratio",
      "kernel_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "TorchActivation1d": {
    "__init__": [
      "self",
      "activation",
      "up_ratio",
      "down_ratio",
      "up_kernel_size",
      "down_kernel_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CausalConv1d": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AMPBlock": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "dilation",
      "causal_type"
    ],
    "_get_padding": [
      "self",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3TTSTokenizerV1DecoderBigVGANModel": {
    "__init__": [
      "self",
      "config"
    ],
    "normalize_spectrogram": [
      "self",
      "spectrogram",
      "max_value",
      "min_db"
    ],
    "amplitude_to_db": [
      "self",
      "amplitude",
      "min_db_level"
    ],
    "process_mel_spectrogram": [
      "self",
      "mel_spectrogram"
    ],
    "forward": [
      "self",
      "mel_spectrogram"
    ]
  },
  "Qwen3TTSTokenizerV1DecoderDiTModel": {
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "_create_block_diff": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "condition_vector",
      "speaker_embedding",
      "quantized_code",
      "time_step",
      "drop_audio_conditioning",
      "drop_code",
      "apply_cfg"
    ],
    "optimized_scale": [
      "self",
      "positive_flat",
      "negative_flat"
    ],
    "sample": [
      "self",
      "conditioning_vector",
      "reference_mel_spectrogram",
      "quantized_code",
      "num_steps",
      "guidance_scale",
      "sway_coefficient"
    ]
  },
  "Qwen3TTSTokenizerV1Decoder": {
    "base_model_prefix": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "code",
      "conditioning",
      "reference_mel",
      "num_steps",
      "guidance_scale",
      "sway_coefficient"
    ]
  },
  "Qwen3TTSTokenizerV1Encoder": {
    "__init__": [
      "self",
      "config"
    ],
    "speech2mel": [
      "self",
      "speechs"
    ],
    "mel2code": [
      "self",
      "mels"
    ],
    "quantize_speech": [
      "self",
      "speechs"
    ]
  },
  "Qwen3TTSTokenizerV1PreTrainedModel": {
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_skip_keys_device_placement": [],
    "_supports_flash_attn": [],
    "_supports_sdpa": [],
    "_can_compile_fullgraph": [],
    "_supports_attention_backend": []
  },
  "Qwen3TTSTokenizerV1Model": {
    "__init__": [
      "self",
      "config"
    ],
    "load_encoder_xvector_extractor": [
      "self",
      "model_path"
    ],
    "get_model_type": [
      "self"
    ],
    "get_input_sample_rate": [
      "self"
    ],
    "get_output_sample_rate": [
      "self"
    ],
    "get_encode_downsample_rate": [
      "self"
    ],
    "get_decode_upsample_rate": [
      "self"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "encode": [
      "self",
      "input_values",
      "padding_mask",
      "return_dict"
    ],
    "decode": [
      "self",
      "audio_codes",
      "xvectors",
      "ref_mels",
      "return_dict"
    ]
  },
  "Qwen3TTSTokenizerV1DecoderDiTConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "ff_mult",
      "emb_dim",
      "head_dim",
      "rope_theta",
      "max_position_embeddings",
      "block_size",
      "look_ahead_layers",
      "look_backward_layers",
      "repeats",
      "num_embeds",
      "mel_dim",
      "dropout",
      "enc_emb_dim",
      "enc_dim",
      "enc_channels",
      "enc_kernel_sizes",
      "enc_dilations",
      "enc_attention_channels",
      "enc_res2net_scale",
      "enc_se_channels"
    ]
  },
  "Qwen3TTSTokenizerV1DecoderBigVGANConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "mel_dim",
      "upsample_initial_channel",
      "resblock_kernel_sizes",
      "resblock_dilation_sizes",
      "upsample_rates",
      "upsample_kernel_sizes"
    ]
  },
  "Qwen3TTSTokenizerV1DecoderConfig": {
    "model_type": [],
    "sub_configs": [],
    "__init__": [
      "self",
      "dit_config",
      "bigvgan_config"
    ]
  },
  "Qwen3TTSTokenizerV1EncoderConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "n_mels",
      "n_ctx",
      "n_state",
      "n_head",
      "n_layer",
      "n_window",
      "output_dim",
      "grad_checkpointing",
      "enable_mp",
      "audio_sequence_parallel",
      "audio_vq_type",
      "audio_vq_layers",
      "audio_vq_codebook_size",
      "audio_vq_codebook_dim",
      "audio_vq_pe",
      "audio_vq_ds_rate"
    ]
  },
  "Qwen3TTSTokenizerV1Config": {
    "model_type": [],
    "sub_configs": [],
    "__init__": [
      "self",
      "encoder_config",
      "decoder_config",
      "input_sample_rate",
      "output_sample_rate",
      "decode_upsample_rate",
      "encode_downsample_rate"
    ]
  },
  "round_up_multiple": [
    "num",
    "mult"
  ],
  "default": [
    "val",
    "d"
  ],
  "ema_inplace": [
    "moving_avg",
    "new",
    "decay"
  ],
  "laplace_smoothing": [
    "x",
    "n_categories",
    "epsilon"
  ],
  "uniform_init": [],
  "sample_vectors": [
    "samples",
    "num"
  ],
  "kmeans": [
    "samples",
    "num_clusters",
    "num_iters"
  ],
  "preprocess": [
    "x"
  ],
  "postprocess_emb": [
    "embed_ind",
    "shape"
  ],
  "DistributedResidualVectorQuantization": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "n_q"
    ],
    "encode": [
      "self",
      "x",
      "n_q"
    ],
    "decode": [
      "self",
      "q_indices"
    ]
  },
  "DistributedGroupResidualVectorQuantization": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "n_q"
    ],
    "encode": [
      "self",
      "x",
      "n_q"
    ],
    "decode": [
      "self",
      "q_indices"
    ]
  },
  "spectral_normalize_torch": [
    "magnitudes"
  ],
  "MelSpectrogramFeatures": {
    "__init__": [
      "self",
      "filter_length",
      "hop_length",
      "win_length",
      "n_mel_channels",
      "mel_fmin",
      "mel_fmax",
      "sampling_rate",
      "sampling_rate_org",
      "padding",
      "use_db"
    ],
    "forward": [
      "self",
      "audio"
    ],
    "extract": [
      "self",
      "audio"
    ]
  },
  "XVectorExtractor": {
    "__init__": [
      "self",
      "audio_codec_with_xvector"
    ],
    "extract_code": [
      "self",
      "audio"
    ],
    "sox_norm": [
      "self",
      "audio"
    ]
  },
  "WhisperEncoderVQ": {
    "__init__": [
      "self",
      "n_mels",
      "n_ctx",
      "n_state",
      "n_head",
      "n_layer",
      "n_window",
      "output_dim",
      "grad_checkpointing",
      "enable_mp",
      "audio_sequence_parallel",
      "audio_vq_layers",
      "audio_vq_type",
      "audio_vq_codebook_size",
      "audio_vq_pe",
      "audio_vq_commit_loss",
      "audio_vq_out_commit_loss",
      "audio_vq_no_quantize",
      "audio_vq_ff_layer",
      "audio_vq_threshold_ema_dead_code",
      "audio_vq_codebook_dim",
      "audio_vq_ds_rate"
    ],
    "_calc_quantize_activities": [
      "self",
      "indices"
    ],
    "_do_quantize": [
      "self",
      "x",
      "pe",
      "y"
    ],
    "forward": [
      "self",
      "x_list",
      "audio_mellens",
      "audio_aftercnnlens",
      "audio_seqlens",
      "return_indices",
      "audio_pitchs"
    ]
  },
  "N_FFT": [],
  "HOP_LENGTH": [],
  "mel_filters": [
    "device",
    "n_mels"
  ],
  "log_mel_spectrogram": [
    "audio",
    "n_mels",
    "padding",
    "device"
  ],
  "get_T_after_cnn": [
    "L_in",
    "dilation"
  ],
  "get_mel_audio": [
    "audio",
    "padding",
    "audio_vq_ds_rate",
    "n_mels"
  ],
  "sinusoids": [
    "length",
    "channels",
    "max_timescale"
  ],
  "Conv1d": {
    "_conv_forward": [
      "self",
      "x",
      "weight",
      "bias"
    ]
  },
  "ConvTranspose1d": {
    "_conv_forward": [
      "self",
      "x",
      "weight",
      "bias"
    ]
  },
  "Linear": {
    "forward": [
      "self",
      "x"
    ]
  },
  "MultiHeadAttention": {
    "__init__": [
      "self",
      "n_state",
      "n_head"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens"
    ],
    "qkv_flash_attention": [
      "self",
      "q",
      "k",
      "v",
      "cu_seqlens"
    ],
    "qkv_attention_manual": [
      "self",
      "q",
      "k",
      "v",
      "cu_seqlens"
    ]
  },
  "ResidualAttentionBlock": {
    "__init__": [
      "self",
      "n_state",
      "n_head",
      "enable_mp",
      "sequence_parallel"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens"
    ]
  },
  "WhisperEncoder": {
    "__init__": [
      "self",
      "n_mels",
      "n_ctx",
      "n_state",
      "n_head",
      "n_layer",
      "n_window",
      "output_dim",
      "grad_checkpointing",
      "enable_mp",
      "audio_sequence_parallel"
    ],
    "set_audio_sync": [
      "self"
    ],
    "forward": [
      "self",
      "x_list",
      "audio_mellens",
      "audio_aftercnnlens",
      "audio_seqlens"
    ],
    "lock": [
      "self",
      "layers"
    ]
  }
}