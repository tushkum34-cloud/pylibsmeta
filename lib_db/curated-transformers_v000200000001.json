{
  "Default": {
    "__init__": [
      "self"
    ]
  },
  "T": [],
  "FutureMandatory": [],
  "registry": {},
  "_has_scipy": [],
  "has_bitsandbytes": [],
  "has_safetensors": [],
  "GeneratorWrapper": {
    "__call__": [
      "self",
      "prompts",
      "config"
    ],
    "generate": [
      "self",
      "prompts",
      "config"
    ]
  },
  "GeneratorState": {
    "__init__": [
      "self"
    ],
    "is_finished": [
      "self"
    ],
    "last_step_ids": [
      "self"
    ],
    "step": [
      "self"
    ],
    "_remove_completed": [
      "self",
      "completed"
    ]
  },
  "__all__": [],
  "Generator": {
    "__init__": [
      "self",
      "model"
    ],
    "__call__": [
      "self"
    ],
    "generate": [
      "self"
    ],
    "_decode_greedy": [
      "self",
      "logits_transform",
      "output"
    ],
    "_decode_sample": [
      "self",
      "logits_transform",
      "output"
    ]
  },
  "StopCondition": {
    "update_completed": [
      "self"
    ]
  },
  "CompoundStopCondition": {
    "update_completed": [
      "self"
    ]
  },
  "EndOfSequenceCondition": {
    "__init__": [
      "self",
      "eos_id"
    ],
    "update_completed": [
      "self"
    ]
  },
  "MaxGeneratedPiecesCondition": {
    "__init__": [
      "self",
      "max_generated_pieces"
    ],
    "update_completed": [
      "self"
    ]
  },
  "GeneratorConfig": {
    "logits_transform": [
      "self"
    ],
    "stop_condition": [
      "self"
    ]
  },
  "GreedyGeneratorConfig": {
    "logits_transform": [
      "self"
    ]
  },
  "SampleGeneratorConfig": {
    "logits_transform": [
      "self"
    ]
  },
  "LogitsTransform": {
    "__call__": [
      "self",
      "logits",
      "inplace"
    ],
    "_process_logits": [
      "self",
      "logits"
    ]
  },
  "CompoundLogitsTransform": {
    "_process_logits": [
      "self",
      "logits"
    ]
  },
  "TopKTransform": {
    "__init__": [
      "self",
      "k"
    ],
    "_process_logits": [
      "self",
      "logits"
    ]
  },
  "TopPTransform": {
    "__init__": [
      "self",
      "p"
    ],
    "_process_logits": [
      "self",
      "logits"
    ]
  },
  "TemperatureTransform": {
    "__init__": [
      "self",
      "temperature"
    ],
    "_process_logits": [
      "self",
      "logits"
    ]
  },
  "VocabMaskTransform": {
    "__init__": [
      "self",
      "pieces_to_mask"
    ],
    "_process_logits": [
      "self",
      "logits"
    ]
  },
  "Self": [],
  "DefaultGenerator": {
    "__init__": [
      "self",
      "tokenizer",
      "causal_lm",
      "default_config"
    ],
    "from_hf_hub_to_cache": [
      "cls"
    ],
    "from_hf_hub": [
      "cls"
    ],
    "generate": [
      "self",
      "prompts",
      "config"
    ],
    "preprocess_prompts": [
      "self",
      "prompts"
    ]
  },
  "StringGenerator": {
    "__init__": [
      "self",
      "tokenizer",
      "generator"
    ],
    "__call__": [
      "self",
      "prompts",
      "config"
    ],
    "generate": [
      "self",
      "prompts",
      "config"
    ]
  },
  "LlamaGenerator": {
    "__init__": [
      "self",
      "tokenizer",
      "causal_lm"
    ]
  },
  "FromHF": {
    "from_hf_hub_to_cache": [
      "cls"
    ],
    "from_hf_hub": [
      "cls"
    ]
  },
  "FalconGenerator": {
    "__init__": [
      "self",
      "tokenizer",
      "causal_lm"
    ],
    "preprocess_prompts": [
      "self",
      "prompts"
    ]
  },
  "INSTRUCTION_KEY": [],
  "RESPONSE_KEY": [],
  "END_KEY": [],
  "INTRO_BLURB": [],
  "DollyV2Generator": {
    "__init__": [
      "self",
      "tokenizer",
      "causal_lm"
    ],
    "preprocess_prompts": [
      "self",
      "prompts"
    ]
  },
  "AutoGenerator": {
    "from_hf_hub_to_cache": [
      "cls"
    ],
    "from_hf_hub": [
      "cls"
    ]
  },
  "_resolve_generator_class": [
    "name"
  ],
  "MPTGenerator": {
    "__init__": [
      "self",
      "tokenizer",
      "causal_lm"
    ]
  },
  "has_torch_compile": [],
  "TORCH_DEVICES": [],
  "GPU_TESTS_ENABLED": [],
  "pytest_addoption": [
    "parser"
  ],
  "pytest_configure": [
    "config"
  ],
  "pytest_runtest_setup": [
    "item"
  ],
  "test_dir": [
    "request"
  ],
  "french_sample_texts": [],
  "short_sample_texts": [],
  "sample_texts": [],
  "make_tempdir": [],
  "torch_assertclose": [
    "a",
    "b"
  ],
  "test_temperature_transform": [],
  "test_invalid_temperature_raises": [],
  "test_top_k_transform": [],
  "test_top_p_transform": [],
  "test_invalid_top_p_raises": [],
  "test_mask_transform": [],
  "test_invalid_mask_transform_raises": [],
  "test_auto_generator": [],
  "test_end_of_sequence_condition": [],
  "test_max_generated_pieces_condition": [],
  "falcon_generator": [],
  "test_generate_deterministic": [
    "falcon_generator"
  ],
  "test_generate_max_generated_pieces": [
    "falcon_generator"
  ],
  "test_generate_sample": [
    "falcon_generator"
  ],
  "test_generate_masked_output": [
    "falcon_generator"
  ],
  "dolly_generator": [],
  "TEST_LINES": [],
  "test_hf_hub_upload_txt": [],
  "test_hf_hub_upload_binary": [],
  "test_hf_hub_transactions": [],
  "test_hf_hub_failures": [],
  "_TestModel": {},
  "_MODELS": [],
  "_FRENCH_MODELS": [],
  "toy_tokenizer_path": [],
  "toy_tokenizer": [
    "toy_tokenizer_path"
  ],
  "test_against_hf_tokenizers": [
    "model",
    "sample_texts"
  ],
  "test_against_hf_tokenizers_short": [
    "model",
    "short_sample_texts"
  ],
  "test_against_hf_tokenizers_french": [
    "model",
    "french_sample_texts"
  ],
  "test_special_pieces": [
    "model"
  ],
  "test_from_dir": [
    "toy_tokenizer",
    "toy_tokenizer_path",
    "sample_texts"
  ],
  "test_from_json": [
    "toy_tokenizer_path",
    "sample_texts"
  ],
  "test_invalid_string_input": [
    "toy_tokenizer"
  ],
  "test_invalid_chunk_input": [
    "toy_tokenizer"
  ],
  "test_text_chunk_merge": [],
  "test_special_text_special_chunk_merge": [],
  "test_special_special_chunk_merge": [],
  "compare_tokenizer_outputs_with_hf_tokenizer": [
    "sample_texts",
    "hf_name",
    "tokenizer_cls",
    "pad_token",
    "with_hf_fast",
    "with_fsspec",
    "revision"
  ],
  "test_auto_tokenizer": [
    "model_revision"
  ],
  "test_auto_tokenizer_fsspec": [
    "model_revision"
  ],
  "test_cannot_infer": [],
  "test_from_hf_hub_to_cache": [],
  "test_from_hf_hub_to_cache_legacy": [],
  "test_fsspec": [
    "sample_texts"
  ],
  "toy_tokenizer_from_files": [
    "test_dir"
  ],
  "test_from_hf_hub_equals_hf_tokenizer": [
    "sample_texts"
  ],
  "test_from_hf_hub_equals_hf_tokenizer_short": [
    "short_sample_texts"
  ],
  "test_from_files": [
    "toy_tokenizer_from_files",
    "short_sample_texts"
  ],
  "_check_toy_tokenizer": [
    "pieces"
  ],
  "test_bert_tokenizer_normalizer_preencoder": [],
  "test_camembert_tokenizer_toy_tokenizer": [
    "toy_tokenizer",
    "short_sample_texts"
  ],
  "test_xlmr_toy_tokenizer": [
    "toy_tokenizer",
    "short_sample_texts"
  ],
  "test_rotary_embeddings_against_hf": [
    "device"
  ],
  "test_rotary_embeddings_rejects_uneven_width": [],
  "test_rotary_embeddings_resize": [
    "device"
  ],
  "test_rotary_embeddings_small": [
    "device"
  ],
  "test_rotary_embeddings_positions_small": [
    "device"
  ],
  "test_sinusoidal_embeddings_without_norm": [],
  "test_sinusoidal_embeddings_with_norm": [],
  "N_PIECES": [],
  "test_context_manager": [],
  "test_torch_sdp": [
    "torch_device"
  ],
  "test_torch_sdp_mask": [
    "torch_device"
  ],
  "test_torch_sdp_causal": [
    "torch_device"
  ],
  "test_torch_sdp_causal_with_mask": [
    "torch_device"
  ],
  "test_attention_linear_biases": [
    "torch_device"
  ],
  "PROMPTS_AND_KEYWORDS": [],
  "dolly_generator_8_bit": [],
  "dolly_generator_4_bit": [],
  "_check_quantized_generator_output": [
    "output",
    "expected_keywords"
  ],
  "test_quantization_8_bit": [
    "dolly_generator_8_bit"
  ],
  "test_quantization_4_bit": [
    "dolly_generator_4_bit"
  ],
  "test_quantization_on_non_gpu": [],
  "DecoderWithCache": {
    "__init__": [
      "self",
      "decoder"
    ],
    "forward": [
      "self",
      "piece_ids",
      "attention_mask",
      "cache"
    ]
  },
  "DecoderWithPositions": {
    "__init__": [
      "self",
      "decoder"
    ],
    "forward": [
      "self",
      "piece_ids",
      "attention_mask",
      "positions"
    ]
  },
  "JITMethod": {
    "Disable": [],
    "TorchCompile": [],
    "convert": [
      "self",
      "model",
      "with_torch_sdp"
    ]
  },
  "assert_causal_lm_output_equals_hf": [
    "model_class",
    "model_name",
    "torch_device"
  ],
  "assert_decoder_output_equals_hf": [
    "model_class",
    "model_name",
    "torch_device"
  ],
  "assert_encoder_output_equals_hf": [
    "model_class",
    "model_name",
    "torch_device"
  ],
  "assert_decoder_with_cache_output_equals_hf": [
    "orig_model",
    "hf_model",
    "torch_device",
    "atol",
    "rtol",
    "jit_method",
    "with_torch_sdp"
  ],
  "assert_with_mask_output_equals_hf": [
    "orig_model",
    "hf_model",
    "torch_device",
    "atol",
    "rtol",
    "jit_method",
    "with_torch_sdp"
  ],
  "assert_decoder_with_positions_equals_hf": [
    "orig_model",
    "hf_model",
    "torch_device",
    "atol",
    "rtol",
    "jit_method",
    "with_torch_sdp"
  ],
  "assert_model_config": [
    "model",
    "model_output"
  ],
  "assert_model_hf_serialization_roundtrip": [
    "model_class",
    "model_name",
    "torch_device"
  ],
  "check_params_buffers": [
    "model",
    "device"
  ],
  "test_sharded_model_checkpoints": [
    "torch_device"
  ],
  "test_checkpoint_type_without_safetensors": [],
  "test_checkpoint_type_with_safetensors": [],
  "test_fsspec_sharded": [
    "torch_device"
  ],
  "test_fsspec_safetensors": [
    "torch_device"
  ],
  "model_encoder_map": [],
  "test_auto_encoder": [
    "model_encoder_map"
  ],
  "test_auto_encoder_fsspec": [
    "model_encoder_map"
  ],
  "test_auto_decoder": [],
  "test_auto_causal_lm": [],
  "test_encoder": [
    "model_name",
    "torch_device",
    "with_torch_sdp"
  ],
  "test_encoder_with_torch_compile": [
    "torch_device",
    "with_torch_sdp"
  ],
  "test_encoder_hf_serializtion_roundtrip": [
    "torch_device"
  ],
  "test_decoder": [
    "torch_device",
    "with_torch_sdp"
  ],
  "test_decoder_with_torch_compile": [
    "torch_device",
    "with_torch_sdp"
  ],
  "test_decoder_hf_serializtion_roundtrip": [
    "torch_device"
  ],
  "test_causal_lm": [
    "torch_device",
    "with_torch_sdp"
  ],
  "test_causal_lm_with_torch_compile": [
    "torch_device",
    "with_torch_sdp"
  ],
  "test_causal_lm_hf_serializtion_roundtrip": [
    "torch_device"
  ],
  "test_rejects_incorrect_number_of_groups": [],
  "FALCON_TEST_MODELS": [],
  "test_decoder_with_cache": [
    "torch_device",
    "model_revision"
  ],
  "LLAMA_TEST_MODELS": [],
  "test_causal_lm_torch_compile": [
    "torch_device",
    "model",
    "with_torch_sdp"
  ],
  "HF_MODEL_CONFIG": [],
  "HF_MODEL_CHECKPOINT": [],
  "HF_MODEL_CHECKPOINT_SAFETENSORS": [],
  "HF_MODEL_SHARDED_CHECKPOINT_INDEX": [],
  "HF_MODEL_SHARDED_CHECKPOINT_INDEX_SAFETENSORS": [],
  "HF_MODEL_SHARDED_CHECKPOINT_INDEX_WEIGHTS_KEY": [],
  "HF_TOKENIZER_CONFIG": [],
  "SPECIAL_TOKENS_MAP": [],
  "TOKENIZER_JSON": [],
  "PRIMARY_CHECKPOINT_FILENAMES": [],
  "SHARDED_CHECKPOINT_INDEX_FILENAMES": [],
  "SHARDED_CHECKPOINT_INDEX_WEIGHTS_KEY": [],
  "FsspecArgs": {
    "__init__": [
      "self"
    ]
  },
  "FsspecFile": {
    "__init__": [
      "self",
      "fs",
      "path",
      "fsspec_args"
    ],
    "open": [
      "self",
      "mode",
      "encoding"
    ],
    "path": [
      "self"
    ],
    "exists": [
      "self"
    ]
  },
  "FsspecRepository": {
    "__init__": [
      "self",
      "fs",
      "path",
      "fsspec_args"
    ],
    "file": [
      "self",
      "path"
    ],
    "pretty_path": [
      "self",
      "path"
    ],
    "transaction": [
      "self"
    ],
    "_protocol": [
      "self"
    ]
  },
  "FsspecTransactionContext": {
    "__init__": [
      "self",
      "repo"
    ],
    "open": [
      "self",
      "path",
      "mode",
      "encoding"
    ],
    "repo": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "exc_tb"
    ]
  },
  "HfHubFile": {
    "__init__": [
      "self",
      "repo",
      "path"
    ],
    "_validate_model_repo": [
      "self"
    ],
    "_download_to_cache": [
      "self"
    ],
    "open": [
      "self",
      "mode",
      "encoding"
    ],
    "path": [
      "self"
    ],
    "exists": [
      "self"
    ]
  },
  "HfHubRepository": {
    "__init__": [
      "self",
      "name"
    ],
    "file": [
      "self",
      "path"
    ],
    "pretty_path": [
      "self",
      "path"
    ],
    "transaction": [
      "self"
    ]
  },
  "HfHubTransactionContext": {
    "__init__": [
      "self",
      "repo"
    ],
    "open": [
      "self",
      "path",
      "mode",
      "encoding"
    ],
    "repo": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "exc_tb"
    ],
    "_upload_temp_files": [
      "self"
    ],
    "_release_temp_files": [
      "self"
    ]
  },
  "UploadStagingBuffer": {
    "__init__": [
      "self",
      "repo",
      "remote_path"
    ],
    "_upload": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "mode": [
      "self"
    ],
    "name": [
      "self"
    ],
    "close": [
      "self"
    ],
    "closed": [
      "self"
    ],
    "fileno": [
      "self"
    ],
    "flush": [
      "self"
    ],
    "isatty": [
      "self"
    ],
    "read": [
      "self",
      "n"
    ],
    "readable": [
      "self"
    ],
    "readline": [
      "self",
      "limit"
    ],
    "readlines": [
      "self",
      "hint"
    ],
    "seek": [
      "self",
      "offset",
      "whence"
    ],
    "seekable": [
      "self"
    ],
    "tell": [
      "self"
    ],
    "truncate": [
      "self",
      "size"
    ],
    "writable": [
      "self"
    ],
    "write": [
      "self",
      "s"
    ],
    "writelines": [
      "self",
      "lines"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "exc_tb"
    ]
  },
  "hf_hub_download": [
    "repo_id",
    "filename",
    "revision"
  ],
  "lookup_file_in_cache": [
    "repo_id",
    "revision",
    "filename"
  ],
  "RepositoryFile": {
    "open": [
      "self",
      "mode",
      "encoding"
    ],
    "path": [
      "self"
    ],
    "exists": [
      "self"
    ]
  },
  "LocalFile": {
    "__init__": [
      "self",
      "path"
    ],
    "open": [
      "self",
      "mode",
      "encoding"
    ],
    "path": [
      "self"
    ],
    "exists": [
      "self"
    ]
  },
  "Repository": {
    "file": [
      "self",
      "path"
    ],
    "json_file": [
      "self",
      "path"
    ],
    "pretty_path": [
      "self",
      "path"
    ],
    "transaction": [
      "self"
    ]
  },
  "ModelRepository": {
    "__init__": [
      "self",
      "repo"
    ],
    "file": [
      "self",
      "filename"
    ],
    "json_file": [
      "self",
      "path"
    ],
    "model_checkpoints": [
      "self"
    ],
    "model_config": [
      "self"
    ],
    "model_type": [
      "self"
    ],
    "pretty_path": [
      "self",
      "path"
    ],
    "transaction": [
      "self"
    ]
  },
  "TokenizerRepository": {
    "__init__": [
      "self",
      "repo"
    ],
    "file": [
      "self",
      "path"
    ],
    "json_file": [
      "self",
      "path"
    ],
    "model_type": [
      "self"
    ],
    "pretty_path": [
      "self",
      "path"
    ],
    "special_tokens_map": [
      "self"
    ],
    "tokenizer_config": [
      "self"
    ],
    "tokenizer_json": [
      "self"
    ],
    "transaction": [
      "self"
    ]
  },
  "TransactionContext": {
    "open": [
      "self",
      "path",
      "mode",
      "encoding"
    ],
    "repo": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "exc_tb"
    ]
  },
  "clean_up_decoded_string_like_hf": [
    "out_string"
  ],
  "tokenize_chinese_chars_bert": [
    "text"
  ],
  "_is_chinese_char_bert": [
    "cp"
  ],
  "ChunkT": [],
  "MergedChunkT": [],
  "MergedSpecialPieceChunk": {},
  "SpecialPieceChunk": {},
  "TextChunk": {},
  "MergedInputChunks": {},
  "InputChunks": {
    "merge_text_chunks": [
      "self"
    ]
  },
  "PiecesWithIds": {
    "attention_mask": [
      "self"
    ],
    "padded_tensor": [
      "self"
    ]
  },
  "TokenizerBase": {
    "__call__": [
      "self",
      "input"
    ],
    "decode": [
      "self",
      "input"
    ],
    "encode": [
      "self",
      "input"
    ],
    "piece_to_id": [
      "self",
      "piece"
    ],
    "eos_piece": [
      "self"
    ]
  },
  "Tokenizer": {
    "__init__": [
      "self"
    ],
    "_get_special_piece": [
      "self"
    ],
    "decode": [
      "self",
      "input"
    ],
    "encode": [
      "self",
      "input"
    ],
    "_encode_strings": [
      "self",
      "input"
    ],
    "_encode_chunks": [
      "self",
      "input"
    ],
    "eos_piece": [
      "self"
    ],
    "from_dir": [
      "cls",
      "path"
    ],
    "from_hf_hub_to_cache": [
      "cls"
    ],
    "from_repo": [
      "cls",
      "repo"
    ],
    "from_json": [
      "cls",
      "tokenizer_json",
      "config_json",
      "special_tokens_map_json"
    ],
    "piece_to_id": [
      "self",
      "piece"
    ]
  },
  "get_special_piece": [
    "special_tokens_map",
    "piece_name"
  ],
  "remove_pieces_from_sequence": [
    "input",
    "pieces_to_remove"
  ],
  "AutoTokenizer": {
    "from_hf_hub_to_cache": [
      "cls"
    ],
    "from_fsspec": [
      "cls"
    ],
    "from_repo": [
      "cls",
      "repo"
    ],
    "from_hf_hub": [
      "cls"
    ]
  },
  "_get_tokenizer_class_from_config": [
    "tokenizer_config"
  ],
  "_resolve_tokenizer_class": [
    "repo"
  ],
  "SelfFromHF": [],
  "SelfLegacyFromHF": [],
  "LegacyFromHF": {
    "_load_from_vocab_files": [
      "cls"
    ],
    "from_hf_hub_to_cache": [
      "cls"
    ],
    "from_repo": [
      "cls",
      "repo"
    ]
  },
  "_XLMR_FAIRSEQ_OFFSET": [],
  "XLMRPostEncoder": {
    "__init__": [
      "self"
    ],
    "_sentencepiece_to_fairseq": [
      "piece_id"
    ]
  },
  "XLMRPreDecoder": {
    "__init__": [
      "self"
    ],
    "_fairseq_to_sentencepiece": [
      "piece_id"
    ]
  },
  "XLMRTokenizer": {
    "__init__": [
      "self"
    ],
    "from_files": [
      "cls"
    ],
    "_load_from_vocab_files": [
      "cls"
    ]
  },
  "FAIRSEQ_PIECE_IDS": {
    "FAIRSEQ_BOS": [],
    "FAIRSEQ_EOS": [],
    "FAIRSEQ_UNK": [],
    "SPP_BOS": [],
    "SPP_EOS": [],
    "SPP_UNK": []
  },
  "FairSeqPostEncoder": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "pieces_with_ids"
    ]
  },
  "FairSeqPreDecoder": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "RoBERTaPreDecoder": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "RoBERTaTokenizer": {
    "__init__": [
      "self"
    ],
    "from_files": [
      "cls"
    ],
    "eos_piece": [
      "self"
    ],
    "_load_from_vocab_files": [
      "cls"
    ]
  },
  "_get_piece_id_or_fail": [
    "processor",
    "piece"
  ],
  "ByteBPETokenizer": {
    "__init__": [
      "self"
    ],
    "piece_to_id": [
      "self",
      "piece"
    ],
    "_decode": [
      "self",
      "input",
      "skip_special_pieces"
    ],
    "_encode": [
      "self",
      "input"
    ]
  },
  "PreDecoder": {
    "__call__": [
      "self",
      "input"
    ]
  },
  "PostDecoder": {
    "__call__": [
      "self",
      "output"
    ]
  },
  "PreEncoder": {
    "__call__": [
      "self",
      "chunks"
    ]
  },
  "PostEncoder": {
    "__call__": [
      "self",
      "pieces"
    ]
  },
  "Normalizer": {
    "__call__": [
      "self",
      "chunks"
    ]
  },
  "LegacyTokenizer": {
    "__call__": [
      "self",
      "input"
    ],
    "decode": [
      "self",
      "input",
      "skip_special_pieces"
    ],
    "encode": [
      "self",
      "input"
    ],
    "_convert_strings": [
      "self",
      "input"
    ],
    "_decode": [
      "self",
      "input",
      "skip_special_pieces"
    ],
    "_encode": [
      "self",
      "input"
    ]
  },
  "AddBosEosPreEncoder": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "chunks"
    ]
  },
  "UnicodeNormalization": {
    "NFC": [],
    "NFKC": [],
    "NFD": [],
    "NFKD": []
  },
  "DefaultNormalizer": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "chunks"
    ]
  },
  "_CAMEMBERT_FAIRSEQ_OFFSET": [],
  "CamemBERTPostEncoder": {
    "__init__": [
      "self"
    ],
    "_sentencepiece_to_fairseq": [
      "piece_id"
    ]
  },
  "CamemBERTPreDecoder": {
    "__init__": [
      "self"
    ],
    "_fairseq_to_sentencepiece": [
      "piece_id"
    ]
  },
  "CamemBERTTokenizer": {
    "__init__": [
      "self"
    ],
    "from_files": [
      "cls"
    ],
    "_load_from_vocab_files": [
      "cls"
    ]
  },
  "WordPieceTokenizer": {
    "__init__": [
      "self"
    ],
    "piece_to_id": [
      "self",
      "piece"
    ],
    "_decode": [
      "self",
      "input",
      "skip_special_pieces"
    ],
    "_encode": [
      "self",
      "input"
    ]
  },
  "DEFAULT_BOS_PIECE": [],
  "LlamaTokenizer": {
    "__init__": [
      "self"
    ],
    "from_files": [
      "cls"
    ],
    "_load_from_vocab_files": [
      "cls"
    ]
  },
  "BERTPreEncoder": {
    "__init__": [
      "self"
    ],
    "split_token_on_punctuation": [
      "self",
      "token"
    ],
    "is_punctuation": [
      "self",
      "char"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "BERTPreDecoder": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "input"
    ]
  },
  "BERTPostDecoder": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "output"
    ]
  },
  "BERTNormalizer": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "chunks"
    ]
  },
  "BERTTokenizer": {
    "__init__": [
      "self"
    ],
    "from_files": [
      "cls"
    ],
    "eos_piece": [
      "self"
    ],
    "_load_from_vocab_files": [
      "cls"
    ],
    "_encode": [
      "self",
      "input"
    ]
  },
  "SentencePieceTokenizer": {
    "__init__": [
      "self"
    ],
    "eos_piece": [
      "self"
    ],
    "piece_to_id": [
      "self",
      "piece"
    ],
    "_decode": [
      "self",
      "input",
      "skip_special_pieces"
    ],
    "_encode": [
      "self",
      "input"
    ]
  },
  "PointwiseFeedForward": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "SinusoidalPositionalEmbedding": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "RotaryEmbeddings": {
    "__init__": [
      "self",
      "width"
    ],
    "_create_rotary_embed": [
      "self"
    ],
    "_rotate": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "QueryKeyRotaryEmbeddings": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "Activation": {
    "ReLU": [],
    "GELU": [],
    "GELUFast": [],
    "GELUNew": [],
    "SiLU": [],
    "_missing_": [
      "cls",
      "value"
    ],
    "module": [
      "self"
    ]
  },
  "GELUNew": {
    "forward": [
      "self",
      "input"
    ]
  },
  "GELUFast": {
    "forward": [
      "self",
      "input"
    ]
  },
  "CacheProtocolSelf": [],
  "CacheProtocol": {
    "filter_batch_items": [
      "self",
      "mask"
    ]
  },
  "KeyValueCache": {
    "filter_batch_items": [
      "self",
      "mask"
    ]
  },
  "RMSNorm": {
    "__init__": [
      "self",
      "width"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "enable_torch_sdp": [
    "use_torch_sdp"
  ],
  "AttentionMask": {
    "__init__": [
      "self",
      "bool_mask"
    ],
    "apply_logit_mask": [
      "self",
      "input"
    ],
    "filter_batch_items": [
      "self",
      "mask"
    ],
    "dim": [
      "self"
    ],
    "merge_mask": [
      "self",
      "other"
    ],
    "logit_mask": [
      "self",
      "dtype"
    ],
    "extend_length": [
      "self",
      "count",
      "fill_value"
    ],
    "shape": [
      "self"
    ],
    "device": [
      "self"
    ]
  },
  "create_causal_mask": [
    "query",
    "key"
  ],
  "QkvSplit": {
    "split": [
      "self"
    ]
  },
  "QkvSplitGroupedByHead": {
    "split": [
      "self"
    ]
  },
  "QkvSplitGroupedByKVHeads": {
    "split": [
      "self"
    ]
  },
  "AttentionHeads": {
    "__init__": [
      "self"
    ],
    "uniform": [
      "cls",
      "n_attention_heads",
      "qkv_split"
    ],
    "multi_query": [
      "cls",
      "n_query_heads",
      "qkv_split"
    ],
    "key_value_broadcast": [
      "cls"
    ]
  },
  "QkvMode": {
    "SEPARATE": [],
    "MERGED_SPLIT_BEFORE": [],
    "MERGED_SPLIT_AFTER": []
  },
  "AttentionLinearBiases": {
    "__init__": [
      "self"
    ],
    "_calculate_slopes": [
      "self",
      "n_attention_heads"
    ],
    "calculate_biases": [
      "self",
      "seq_len"
    ],
    "forward": [
      "self"
    ]
  },
  "AttentionScorer": {
    "forward": [
      "self"
    ]
  },
  "ScaledDotProductAttention": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "SelfAttention": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input",
      "attention_mask",
      "use_causal_mask",
      "cache",
      "store_cache",
      "positions"
    ],
    "_query_key_value": [
      "self",
      "input"
    ],
    "_query_key_value_separate": [
      "self",
      "input"
    ],
    "_query_key_value_merged_split_before": [
      "self",
      "input"
    ],
    "_query_key_value_merged_split_after": [
      "self",
      "input"
    ]
  },
  "split_heads": [
    "input",
    "n_heads"
  ],
  "combine_heads": [
    "input"
  ],
  "EmbeddingLayerNorms": {},
  "EmbeddingDropouts": {},
  "TransformerEmbeddings": {
    "__init__": [
      "self"
    ],
    "_get_positions": [
      "self",
      "x"
    ],
    "_get_type_ids": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "piece_ids"
    ]
  },
  "TransformerLayerNorms": {},
  "TransformerDropouts": {
    "layer_output_dropouts": [
      "cls",
      "p"
    ],
    "parallel_attention_dropout": [
      "cls",
      "p"
    ]
  },
  "_TransformerLayer": {
    "__init__": [
      "self"
    ],
    "_forward": [
      "self",
      "input",
      "attention_mask"
    ]
  },
  "DecoderLayer": {
    "forward": [
      "self",
      "input",
      "attention_mask"
    ]
  },
  "EncoderLayer": {
    "forward": [
      "self",
      "input",
      "attention_mask"
    ]
  },
  "prepare_module_for_quantization": [
    "module",
    "config"
  ],
  "Quantizable": {
    "modules_to_not_quantize": [
      "cls"
    ]
  },
  "prepare_for_quantization": [
    "module",
    "config",
    "non_quantizable_module_prefixes"
  ],
  "_replace_quantizable_modules": [
    "module",
    "config",
    "non_quantizable_module_prefixes",
    "init_quantized_module"
  ],
  "_convert_tensor_to_quantized_parameter": [
    "module",
    "module_prefix",
    "parameter_name",
    "tensor",
    "device"
  ],
  "_init_8bit_linear": [
    "source",
    "config",
    "device"
  ],
  "_init_4bit_linear": [
    "source",
    "config",
    "device"
  ],
  "_assert_bitsandbytes_installed": [],
  "Dtype4Bit": {
    "FP4": [],
    "NF4": []
  },
  "_4BitConfig": {},
  "_8BitConfig": {},
  "BitsAndBytesConfig": {
    "for_8bit": [
      "outlier_threshold",
      "finetunable"
    ],
    "for_4bit": [
      "quantization_dtype",
      "compute_dtype",
      "double_quantization"
    ]
  },
  "ModelT": [],
  "AutoModel": {
    "_resolve_model_cls": [
      "cls",
      "repo"
    ],
    "_instantiate_model": [
      "cls",
      "repo",
      "device",
      "quantization_config"
    ],
    "from_fsspec": [
      "cls"
    ],
    "from_hf_hub": [
      "cls"
    ],
    "from_repo": [
      "cls"
    ],
    "from_hf_hub_to_cache": [
      "cls"
    ]
  },
  "AutoEncoder": {
    "_base_cls": [],
    "from_repo": [
      "cls"
    ]
  },
  "AutoDecoder": {
    "_base_cls": [],
    "_registry": [],
    "from_repo": [
      "cls"
    ]
  },
  "AutoCausalLM": {
    "_base_cls": [],
    "from_repo": [
      "cls"
    ]
  },
  "ConfigT": [],
  "TransformerModule": {
    "__init__": [
      "self",
      "config"
    ],
    "config": [
      "self"
    ]
  },
  "CausalLMModule": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "piece_ids",
      "attention_mask"
    ]
  },
  "DecoderModule": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "piece_ids",
      "attention_mask"
    ]
  },
  "EncoderModule": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "piece_ids",
      "attention_mask"
    ]
  },
  "TransformerDecoder": {
    "forward": [
      "self",
      "piece_ids",
      "attention_mask"
    ]
  },
  "TransformerCausalLM": {
    "forward": [
      "self",
      "piece_ids",
      "attention_mask",
      "cache",
      "positions",
      "store_cache"
    ]
  },
  "TransformerEncoder": {
    "forward": [
      "self",
      "piece_ids",
      "attention_mask"
    ]
  },
  "RotaryEmbeddingConfig": {},
  "TransformerAttentionLayerConfig": {},
  "TransformerEmbeddingLayerConfig": {},
  "TransformerFeedForwardLayerConfig": {},
  "TransformerLayerConfig": {},
  "TransformerConfig": {},
  "CacheT": [],
  "ModelOutput": {
    "embedding_layer": [
      "self"
    ],
    "hidden_layer_states": [
      "self",
      "idx"
    ],
    "last_hidden_layer_state": [
      "self"
    ],
    "all_hidden_layer_states": [
      "self"
    ]
  },
  "ModelOutputWithCache": {},
  "CausalLMOutputWithCache": {},
  "HF_SPECIFIC_CONFIG": [],
  "_config_from_hf": [
    "hf_config"
  ],
  "_config_to_hf": [
    "curated_config"
  ],
  "ELECTRAEncoder": {
    "is_supported": [
      "cls",
      "config"
    ],
    "state_dict_from_hf": [
      "cls",
      "params"
    ],
    "state_dict_to_hf": [
      "cls",
      "params"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ]
  },
  "CamemBERTEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "is_supported": [
      "cls",
      "config"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ]
  },
  "DECODER_HF_PARAM_KEY_TRANSFORMS": [],
  "CAUSAL_LM_HF_PARAM_KEY_TRANSFORMS": [],
  "HFConfigKeys": {
    "conv_intermediate_width_multiplier": [
      "config"
    ],
    "conv_model_max_length": [
      "config"
    ],
    "conv_use_bias": [
      "config"
    ],
    "D_MODEL": [],
    "EXPANSION_RATIO": [],
    "MAX_SEQ_LEN": [],
    "N_LAYERS": [],
    "N_HEADS": [],
    "NO_BIAS": [],
    "LAYER_NORM_EPSILON": []
  },
  "HF_SPECIFIC_CONFIG_DECODER": [],
  "HF_SPECIFIC_CONFIG_CAUSAL_LM": [],
  "MPTDecoder": {
    "__init__": [
      "self",
      "config"
    ],
    "is_supported": [
      "cls",
      "config"
    ],
    "state_dict_from_hf": [
      "cls",
      "params"
    ],
    "state_dict_to_hf": [
      "cls",
      "params"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ],
    "from_hf_config": [
      "cls"
    ]
  },
  "MPTConfig": {
    "__init__": [
      "self"
    ]
  },
  "MPTCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "piece_ids",
      "attention_mask",
      "cache",
      "positions",
      "store_cache"
    ],
    "is_supported": [
      "cls",
      "config"
    ],
    "state_dict_from_hf": [
      "cls",
      "params"
    ],
    "state_dict_to_hf": [
      "cls",
      "params"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ],
    "from_hf_config": [
      "cls"
    ],
    "modules_to_not_quantize": [
      "cls"
    ]
  },
  "BERTConfig": {
    "__init__": [
      "self"
    ]
  },
  "BERTEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "is_supported": [
      "cls",
      "config"
    ],
    "state_dict_from_hf": [
      "cls",
      "params"
    ],
    "state_dict_to_hf": [
      "cls",
      "params"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ],
    "from_hf_config": [
      "cls"
    ]
  },
  "XLMREncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "is_supported": [
      "cls",
      "config"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ]
  },
  "ALBERTLayerConfig": {
    "__init__": [
      "self"
    ]
  },
  "ALBERTConfig": {
    "__init__": [
      "self"
    ]
  },
  "ALBERTEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "piece_ids",
      "attention_mask"
    ],
    "is_supported": [
      "cls",
      "config"
    ],
    "state_dict_from_hf": [
      "cls",
      "params"
    ],
    "state_dict_to_hf": [
      "cls",
      "params"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ],
    "from_hf_config": [
      "cls"
    ]
  },
  "ALBERTLayerGroup": {
    "__init__": [
      "self",
      "layer_config"
    ],
    "forward": [
      "self",
      "input",
      "attention_mask"
    ]
  },
  "RoBERTaEmbeddings": {
    "__init__": [
      "self"
    ],
    "_get_positions": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "piece_ids"
    ]
  },
  "RoBERTaConfig": {
    "__init__": [
      "self"
    ]
  },
  "RoBERTaEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "is_supported": [
      "cls",
      "config"
    ],
    "state_dict_from_hf": [
      "cls",
      "params"
    ],
    "state_dict_to_hf": [
      "cls",
      "params"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ],
    "from_hf_config": [
      "cls"
    ]
  },
  "HFSpecificConfig": {
    "merge": [
      "self",
      "hf_config"
    ]
  },
  "HFConfigKey": {
    "curated_config_kwarg": [
      "self"
    ],
    "get_kwarg": [
      "self",
      "kwargs"
    ],
    "set_kwarg": [
      "self",
      "value",
      "kwargs"
    ],
    "remove_kwarg": [
      "self",
      "kwargs"
    ]
  },
  "HFConfigKeyDefault": {},
  "CommonCuratedToHFConverters": {
    "n_attention_heads_uniform": [
      "config"
    ],
    "attention_dropout": [
      "config"
    ],
    "activation": [
      "config"
    ],
    "dtype": [
      "config"
    ],
    "embedding_width": [
      "config"
    ],
    "hidden_width": [
      "config"
    ],
    "intermediate_width": [
      "config"
    ],
    "layer_norm_eps": [
      "config"
    ],
    "hidden_dropout": [
      "config"
    ],
    "n_pieces": [
      "config"
    ],
    "n_types": [
      "config"
    ],
    "n_hidden_layers": [
      "config"
    ],
    "n_positions": [
      "config"
    ]
  },
  "CommonHFToCuratedConverters": {
    "dtype": [
      "serialized_dtype_str"
    ]
  },
  "CommonHFKeys": {
    "ATTENTION_PROBS_DROPOUT_PROB": [],
    "DTYPE": [],
    "EMBEDDING_SIZE": [],
    "HIDDEN_ACT": [],
    "HIDDEN_SIZE": [],
    "INTERMEDIATE_SIZE": [],
    "LAYER_NORM_EPS": [],
    "MAX_POSITION_EMBEDDINGS": [],
    "TYPE_VOCAB_SIZE": [],
    "VOCAB_SIZE": [],
    "NUM_ATTENTION_HEADS_UNIFORM": [],
    "NUM_HIDDEN_LAYERS": [],
    "HIDDEN_DROPOUT_PROB": []
  },
  "config_from_hf": [
    "model_name",
    "hf_config",
    "hf_keys"
  ],
  "config_to_hf": [
    "curated_config",
    "hf_keys"
  ],
  "state_dict_from_hf": [
    "params",
    "transforms"
  ],
  "state_dict_to_hf": [
    "params",
    "transforms"
  ],
  "GPTNeoXDecoder": {
    "__init__": [
      "self",
      "config"
    ],
    "is_supported": [
      "cls",
      "config"
    ],
    "state_dict_from_hf": [
      "cls",
      "params"
    ],
    "state_dict_to_hf": [
      "cls",
      "params"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ],
    "from_hf_config": [
      "cls"
    ]
  },
  "GPTNeoXConfig": {
    "__init__": [
      "self"
    ]
  },
  "GPTNeoXCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "is_supported": [
      "cls",
      "config"
    ],
    "state_dict_from_hf": [
      "cls",
      "params"
    ],
    "state_dict_to_hf": [
      "cls",
      "params"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ],
    "from_hf_config": [
      "cls"
    ],
    "modules_to_not_quantize": [
      "cls"
    ]
  },
  "ATTENTION_DROPOUT": [],
  "HIDDEN_DROPOUT": [],
  "EXTRA_KWARG_KEYS": [],
  "_config_from_hf_refined_web_model": [
    "hf_config"
  ],
  "_config_from_hf_falcon": [
    "hf_config"
  ],
  "FalconDecoder": {
    "__init__": [
      "self",
      "config"
    ],
    "is_supported": [
      "cls",
      "config"
    ],
    "state_dict_from_hf": [
      "cls",
      "params"
    ],
    "state_dict_to_hf": [
      "cls",
      "params"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ],
    "from_hf_config": [
      "cls"
    ],
    "_create_old_decoder_architecture_layer": [
      "self",
      "config",
      "device"
    ],
    "_create_new_decoder_architecture_layer": [
      "self",
      "config",
      "device"
    ]
  },
  "FalconConfig": {
    "__init__": [
      "self"
    ]
  },
  "OldFalconDecoderLayer": {
    "__init__": [
      "self",
      "layer_config"
    ],
    "forward": [
      "self",
      "input",
      "attention_mask"
    ]
  },
  "FalconCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "state_dict_from_hf": [
      "cls",
      "params"
    ],
    "is_supported": [
      "cls",
      "config"
    ],
    "state_dict_to_hf": [
      "cls",
      "params"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ],
    "from_hf_config": [
      "cls"
    ],
    "modules_to_not_quantize": [
      "cls"
    ]
  },
  "LlamaDecoder": {
    "__init__": [
      "self",
      "config"
    ],
    "is_supported": [
      "cls",
      "config"
    ],
    "state_dict_from_hf": [
      "cls",
      "params"
    ],
    "state_dict_to_hf": [
      "cls",
      "params"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ],
    "from_hf_config": [
      "cls"
    ]
  },
  "LlamaConfig": {
    "__init__": [
      "self"
    ]
  },
  "LlamaCausalLM": {
    "__init__": [
      "self",
      "config"
    ],
    "is_supported": [
      "cls",
      "config"
    ],
    "state_dict_from_hf": [
      "cls",
      "params"
    ],
    "state_dict_to_hf": [
      "cls",
      "params"
    ],
    "config_from_hf": [
      "cls",
      "hf_config"
    ],
    "config_to_hf": [
      "cls",
      "curated_config"
    ],
    "from_hf_config": [
      "cls"
    ],
    "modules_to_not_quantize": [
      "cls"
    ]
  },
  "StringTransform": {
    "__init__": [
      "self",
      "reversible"
    ],
    "_apply": [
      "self",
      "string"
    ],
    "_revert": [
      "self",
      "string"
    ],
    "apply": [
      "self",
      "string"
    ],
    "revert": [
      "self",
      "string"
    ]
  },
  "StringTransformations": {
    "regex_sub": [
      "forward",
      "backward"
    ],
    "sub": [
      "substring",
      "replacement"
    ],
    "replace": [
      "replacee",
      "replacement"
    ],
    "remove_prefix": [
      "prefix"
    ]
  },
  "StringSubRegEx": {
    "__init__": [
      "self",
      "forward",
      "backward"
    ],
    "_apply": [
      "self",
      "string"
    ],
    "_revert": [
      "self",
      "string"
    ]
  },
  "StringSub": {
    "__init__": [
      "self",
      "substring",
      "replacement"
    ],
    "_apply": [
      "self",
      "string"
    ],
    "_revert": [
      "self",
      "string"
    ]
  },
  "StringReplace": {
    "__init__": [
      "self",
      "replacee",
      "replacement"
    ],
    "_apply": [
      "self",
      "string"
    ],
    "_revert": [
      "self",
      "string"
    ]
  },
  "StringRemovePrefix": {
    "__init__": [
      "self",
      "prefix"
    ],
    "_apply": [
      "self",
      "string"
    ],
    "_revert": [
      "self",
      "string"
    ]
  },
  "ModuleIterator": {},
  "apply_to_module": [
    "module",
    "func"
  ],
  "use_nvtx_ranges_for_forward_pass": [
    "module"
  ],
  "ModelCheckpointType": {
    "PYTORCH_STATE_DICT": [],
    "SAFE_TENSORS": [],
    "loader": [
      "self"
    ],
    "pretty_name": [
      "self"
    ]
  },
  "_load_safetensor_state_dicts_from_checkpoints": [
    "checkpoints"
  ],
  "_load_pytorch_state_dicts_from_checkpoints": [
    "checkpoints"
  ],
  "TensorToParameterConverterT": [],
  "HFStateDictConverterT": [],
  "load_model_from_checkpoints": [
    "model"
  ],
  "default_tensor_to_parameter_converter": [
    "module",
    "module_prefix",
    "parameter_name",
    "tensor",
    "device"
  ],
  "_emplace_module_state_dict": [
    "module",
    "state_dict"
  ],
  "_emplace_module_tensor": [
    "module",
    "module_prefix",
    "tensor_name",
    "replacement_tensor",
    "tensor_to_param_converter",
    "device"
  ],
  "_validate_replacement": [
    "replaced",
    "replacement",
    "name"
  ]
}