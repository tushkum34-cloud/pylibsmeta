{
  "_prev_minor_version_was": [
    "version_str"
  ],
  "_prev_minor_version": [],
  "logger": [],
  "CompletionOutput": {
    "finished": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "PoolingOutput": {
    "__repr__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ]
  },
  "RequestOutput": {
    "__init__": [
      "self",
      "request_id",
      "prompt",
      "prompt_token_ids",
      "prompt_logprobs",
      "outputs",
      "finished",
      "metrics",
      "lora_request",
      "encoder_prompt",
      "encoder_prompt_token_ids",
      "num_cached_tokens"
    ],
    "add": [
      "self",
      "next_output",
      "aggregate"
    ],
    "__repr__": [
      "self"
    ]
  },
  "STREAM_FINISHED": [],
  "_O": [],
  "PoolingRequestOutput": {
    "__init__": [
      "self",
      "request_id",
      "outputs",
      "prompt_token_ids",
      "num_cached_tokens",
      "finished"
    ],
    "__repr__": [
      "self"
    ]
  },
  "EmbeddingOutput": {
    "from_base": [
      "pooling_output"
    ],
    "hidden_size": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "EmbeddingRequestOutput": {
    "from_base": [
      "request_output"
    ]
  },
  "ClassificationOutput": {
    "from_base": [
      "pooling_output"
    ],
    "num_classes": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ClassificationRequestOutput": {
    "from_base": [
      "request_output"
    ]
  },
  "ScoringOutput": {
    "from_base": [
      "pooling_output"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ScoringRequestOutput": {
    "from_base": [
      "request_output"
    ]
  },
  "GenerationTask": [],
  "PoolingTask": [],
  "SupportedTask": [],
  "BatchDescriptor": {
    "relax_for_mixed_batch_cudagraphs": [
      "self"
    ]
  },
  "_compute_sp_num_tokens": [
    "num_tokens_across_dp_cpu",
    "sequence_parallel_size"
  ],
  "_compute_chunked_local_num_tokens": [
    "num_tokens_across_dp_cpu",
    "sequence_parallel_size",
    "max_num_tokens",
    "chunk_idx"
  ],
  "DPMetadata": {
    "make": [
      "parallel_config",
      "num_tokens",
      "num_tokens_across_dp_cpu"
    ],
    "chunked_sizes": [
      "self",
      "sequence_parallel_size",
      "max_chunk_size_per_rank",
      "chunk_idx"
    ],
    "sp_local_sizes": [
      "self",
      "sequence_parallel_size"
    ],
    "get_chunk_sizes_across_dp_rank": [
      "self"
    ],
    "cu_tokens_across_sp": [
      "self",
      "sp_size"
    ]
  },
  "ForwardContext": {
    "__post_init__": [
      "self"
    ]
  },
  "get_forward_context": [],
  "is_forward_context_available": [],
  "create_forward_context": [
    "attn_metadata",
    "vllm_config",
    "virtual_engine",
    "dp_metadata",
    "cudagraph_runtime_mode",
    "batch_descriptor",
    "ubatch_slices",
    "slot_mapping",
    "additional_kwargs",
    "skip_compiled"
  ],
  "override_forward_context": [
    "forward_context"
  ],
  "set_forward_context": [
    "attn_metadata",
    "vllm_config",
    "virtual_engine",
    "num_tokens",
    "num_tokens_across_dp",
    "cudagraph_runtime_mode",
    "batch_descriptor",
    "ubatch_slices",
    "slot_mapping",
    "skip_compiled"
  ],
  "_FORMAT": [],
  "_DATE_FORMAT": [],
  "_use_color": [],
  "DEFAULT_LOGGING_CONFIG": [],
  "_print_debug_once": [
    "logger",
    "msg"
  ],
  "_print_info_once": [
    "logger",
    "msg"
  ],
  "_print_warning_once": [
    "logger",
    "msg"
  ],
  "LogScope": [],
  "_should_log_with_scope": [
    "scope"
  ],
  "_VllmLogger": {
    "debug_once": [
      "self",
      "msg"
    ],
    "info_once": [
      "self",
      "msg"
    ],
    "warning_once": [
      "self",
      "msg"
    ]
  },
  "_METHODS_TO_PATCH": [],
  "_configure_vllm_root_logger": [],
  "init_logger": [
    "name"
  ],
  "suppress_logging": [
    "level"
  ],
  "current_formatter_type": [
    "lgr"
  ],
  "_trace_calls": [
    "log_path",
    "root_dir",
    "frame",
    "event",
    "arg"
  ],
  "enable_trace_function_call": [
    "log_file_path",
    "root_dir"
  ],
  "PoolingParams": {
    "all_parameters": [
      "self"
    ],
    "valid_parameters": [
      "self"
    ],
    "clone": [
      "self"
    ],
    "verify": [
      "self",
      "task",
      "model_config"
    ],
    "_merge_default_parameters": [
      "self",
      "model_config"
    ],
    "_verify_step_pooling": [
      "self",
      "pooler_config",
      "valid_parameters"
    ],
    "_set_default_parameters": [
      "self",
      "model_config"
    ],
    "_verify_valid_parameters": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "__post_init__": [
      "self"
    ]
  },
  "Logprob": {},
  "LogprobsOnePosition": [],
  "FlatLogprobs": {
    "append": [
      "self",
      "logprobs_one_position"
    ],
    "append_fast": [
      "self",
      "token_ids",
      "logprobs",
      "ranks",
      "decoded_tokens"
    ],
    "extend": [
      "self",
      "logprobs_multi_positions"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__setitem__": [
      "self",
      "item",
      "value"
    ],
    "__delitem__": [
      "self",
      "item"
    ],
    "insert": [
      "self",
      "item"
    ],
    "__iter__": [
      "self"
    ]
  },
  "PromptLogprobs": [],
  "SampleLogprobs": [],
  "create_prompt_logprobs": [
    "flat_logprobs"
  ],
  "create_sample_logprobs": [
    "flat_logprobs"
  ],
  "append_logprobs_for_next_position": [
    "request_logprobs",
    "token_ids",
    "logprobs",
    "decoded_tokens",
    "rank",
    "num_logprobs"
  ],
  "get_default_cache_root": [],
  "get_default_config_root": [],
  "maybe_convert_int": [
    "value"
  ],
  "maybe_convert_bool": [
    "value"
  ],
  "disable_compile_cache": [],
  "use_aot_compile": [],
  "env_with_choices": [
    "env_name",
    "default",
    "choices",
    "case_sensitive"
  ],
  "env_list_with_choices": [
    "env_name",
    "default",
    "choices",
    "case_sensitive"
  ],
  "env_set_with_choices": [
    "env_name",
    "default",
    "choices",
    "case_sensitive"
  ],
  "get_vllm_port": [],
  "get_env_or_set_default": [
    "env_name",
    "default_factory"
  ],
  "__getattr__": [
    "name"
  ],
  "_is_envs_cache_enabled": [],
  "enable_envs_cache": [],
  "disable_envs_cache": [],
  "__dir__": [],
  "is_set": [
    "name"
  ],
  "compile_factors": [],
  "main": [],
  "memory_plan_reuse_patched": [
    "self"
  ],
  "get_graph_partition_signature_patched": [
    "self",
    "partitions",
    "skip_cudagraphs"
  ],
  "should_partition_patched": [
    "self",
    "node",
    "should_log"
  ],
  "_update_scheduler_patched": [
    "self"
  ],
  "_patch_get_raw_stream_if_needed": [],
  "MODULE_ATTRS": [],
  "__all__": [],
  "BeamSearchSequence": {},
  "BeamSearchOutput": {},
  "BeamSearchInstance": {
    "__init__": [
      "self",
      "prompt_tokens",
      "lora_request",
      "logprobs"
    ]
  },
  "get_beam_search_score": [
    "tokens",
    "cumulative_logprob",
    "eos_token_id",
    "length_penalty"
  ],
  "create_sort_beams_key_function": [
    "eos_token_id",
    "length_penalty"
  ],
  "_FP8_DTYPE": [],
  "is_aiter_found": [],
  "IS_AITER_FOUND": [],
  "is_aiter_found_and_supported": [],
  "if_aiter_supported": [
    "func"
  ],
  "_rocm_aiter_fused_moe_impl": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weight",
    "topk_ids",
    "expert_mask",
    "activation_method",
    "quant_method",
    "doweight_stage1",
    "w1_scale",
    "w2_scale",
    "a1_scale",
    "a2_scale",
    "num_local_tokens",
    "output_dtype"
  ],
  "_rocm_aiter_fused_moe_fake": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weight",
    "topk_ids",
    "expert_mask",
    "activation_method",
    "quant_method",
    "doweight_stage1",
    "w1_scale",
    "w2_scale",
    "a1_scale",
    "a2_scale",
    "num_local_tokens",
    "output_dtype"
  ],
  "_rocm_aiter_asm_moe_tkw1_impl": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "fc1_scale",
    "fc2_scale",
    "fc1_smooth_scale",
    "fc2_smooth_scale",
    "a16",
    "per_tensor_quant_scale",
    "expert_mask",
    "activation_method"
  ],
  "_rocm_aiter_asm_moe_tkw1_fake": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "fc1_scale",
    "fc2_scale",
    "fc1_smooth_scale",
    "fc2_smooth_scale",
    "a16",
    "per_tensor_quant_scale",
    "expert_mask",
    "activation_method"
  ],
  "_rocm_aiter_topk_softmax_impl": [
    "topk_weights",
    "topk_indices",
    "token_expert_indices",
    "gating_output",
    "renormalize"
  ],
  "_rocm_aiter_topk_softmax_fake": [
    "topk_weights",
    "topk_indices",
    "token_expert_indices",
    "gating_output",
    "renormalize"
  ],
  "_rocm_aiter_topk_sigmoid_impl": [
    "topk_weights",
    "topk_indices",
    "gating_output"
  ],
  "_rocm_aiter_topk_sigmoid_fake": [
    "topk_weights",
    "topk_indices",
    "gating_output"
  ],
  "_rocm_aiter_biased_grouped_topk_impl": [
    "gating_output",
    "correction_bias",
    "topk_weights",
    "topk_ids",
    "num_expert_group",
    "topk_group",
    "need_renorm",
    "routed_scaling_factor"
  ],
  "_rocm_aiter_biased_grouped_topk_fake": [
    "gating_output",
    "correction_bias",
    "topk_weights",
    "topk_ids",
    "num_expert_group",
    "topk_group",
    "need_renorm",
    "routed_scaling_factor"
  ],
  "_rocm_aiter_grouped_topk_impl": [
    "gating_output",
    "topk_weights",
    "topk_ids",
    "num_expert_group",
    "topk_group",
    "need_renorm",
    "scoring_func",
    "routed_scaling_factor"
  ],
  "_rocm_aiter_grouped_topk_fake": [
    "gating_output",
    "topk_weights",
    "topk_ids",
    "num_expert_group",
    "topk_group",
    "need_renorm",
    "scoring_func",
    "routed_scaling_factor"
  ],
  "_check_aiter_mla_fp8_support": [],
  "_rocm_aiter_mla_decode_fwd_impl": [
    "q",
    "kv_buffer",
    "o",
    "qo_indptr",
    "max_seqlen_qo",
    "kv_indptr",
    "kv_indices",
    "kv_last_page_lens",
    "sm_scale",
    "logit_cap",
    "q_scale",
    "kv_scale"
  ],
  "_rocm_aiter_mla_decode_fwd_fake": [
    "q",
    "kv_buffer",
    "o",
    "qo_indptr",
    "max_seqlen_qo",
    "kv_indptr",
    "kv_indices",
    "kv_last_page_lens",
    "sm_scale",
    "logit_cap",
    "q_scale",
    "kv_scale"
  ],
  "_rocm_aiter_gemm_a8w8_impl": [
    "A",
    "B",
    "As",
    "Bs",
    "bias",
    "output_dtype"
  ],
  "_rocm_aiter_gemm_a8w8_fake": [
    "A",
    "B",
    "As",
    "Bs",
    "bias",
    "output_dtype"
  ],
  "_rocm_aiter_triton_gemm_a8w8_blockscale_impl": [
    "A",
    "B",
    "As",
    "Bs",
    "output_dtype"
  ],
  "_rocm_aiter_triton_gemm_a8w8_blockscale_fake": [
    "A",
    "B",
    "As",
    "Bs",
    "output_dtype"
  ],
  "_rocm_aiter_gemm_a8w8_blockscale_impl": [
    "A",
    "B",
    "As",
    "Bs",
    "output_dtype"
  ],
  "_rocm_aiter_gemm_a8w8_blockscale_fake": [
    "A",
    "B",
    "As",
    "Bs",
    "output_dtype"
  ],
  "_rocm_aiter_rms_norm_impl": [
    "x",
    "weight",
    "variance_epsilon"
  ],
  "_rocm_aiter_rms_norm_fake": [
    "x",
    "weight",
    "variance_epsilon"
  ],
  "_rocm_aiter_rmsnorm2d_fwd_with_add_impl": [
    "x",
    "residual",
    "weight",
    "variance_epsilon"
  ],
  "_rocm_aiter_rmsnorm2d_fwd_with_add_fake": [
    "x",
    "residual",
    "weight",
    "variance_epsilon"
  ],
  "_rocm_aiter_rmsnorm_fused_add_dynamic_quant_impl": [
    "x",
    "residual",
    "weight",
    "epsilon",
    "quant_dtype"
  ],
  "_rocm_aiter_rmsnorm_fused_add_dynamic_quant_fake": [
    "x",
    "residual",
    "weight",
    "epsilon",
    "quant_dtype"
  ],
  "_rocm_aiter_rmsnorm_fused_dynamic_quant_impl": [
    "x",
    "weight",
    "epsilon",
    "quant_dtype"
  ],
  "_rocm_aiter_rmsnorm_fused_dynamic_quant_fake": [
    "x",
    "weight",
    "epsilon",
    "quant_dtype"
  ],
  "_rocm_aiter_per_tensor_quant_impl": [
    "x",
    "quant_dtype",
    "scale"
  ],
  "_rocm_aiter_per_tensor_quant_fake": [
    "x",
    "quant_dtype",
    "scale"
  ],
  "_rocm_aiter_per_token_quant_impl": [
    "x",
    "quant_dtype",
    "scale"
  ],
  "_rocm_aiter_per_token_quant_fake": [
    "x",
    "quant_dtype",
    "scale"
  ],
  "_rocm_aiter_rmsnorm_with_add_fp8_group_quant_impl": [
    "x",
    "residual",
    "weight",
    "variance_epsilon",
    "group_size"
  ],
  "_rocm_aiter_rmsnorm_with_add_fp8_group_quant_fake": [
    "x",
    "residual",
    "weight",
    "variance_epsilon",
    "group_size"
  ],
  "_rocm_aiter_rmsnorm_fp8_group_quant_impl": [
    "x",
    "weight",
    "variance_epsilon",
    "group_size"
  ],
  "_rocm_aiter_rmsnorm_fp8_group_quant_fake": [
    "x",
    "weight",
    "variance_epsilon",
    "group_size"
  ],
  "_rocm_aiter_group_fp8_quant_impl": [
    "x",
    "group_size"
  ],
  "_rocm_aiter_group_fp8_quant_fake": [
    "x",
    "group_size"
  ],
  "_rocm_aiter_act_mul_and_fp8_group_quant_impl": [
    "x",
    "group_size"
  ],
  "_rocm_aiter_act_mul_and_fp8_group_quant_fake": [
    "x",
    "group_size"
  ],
  "_OPS_REGISTERED": [],
  "rocm_aiter_ops": {
    "_AITER_ENABLED": [],
    "_LINEAR_ENABLED": [],
    "_RMSNORM_ENABLED": [],
    "_FMOE_ENABLED": [],
    "_MLA_ENABLED": [],
    "_MHA_ENABLED": [],
    "_SHUFFLE_KV_CACHE_ENABLED": [],
    "_TRITON_UNIFIED_ATTN_ENABLED": [],
    "_FP8BMM_ENABLED": [],
    "_FP4BMM_ENABLED": [],
    "_FP4_GEMM_DYNAMIC_QUANT_ASM": [],
    "_TRITON_ROTARY_EMBED": [],
    "_MOE_SHARED_EXPERTS_ENABLED": [],
    "_TRITON_UNQUANT_GEMM": [],
    "refresh_env_variables": [
      "cls"
    ],
    "is_enabled": [
      "cls"
    ],
    "is_linear_enabled": [
      "cls"
    ],
    "is_linear_fp8_enabled": [
      "cls"
    ],
    "is_rmsnorm_enabled": [
      "cls"
    ],
    "is_fused_moe_enabled": [
      "cls"
    ],
    "is_fusion_moe_shared_experts_enabled": [
      "cls"
    ],
    "is_mla_enabled": [
      "cls"
    ],
    "is_mha_enabled": [
      "cls"
    ],
    "is_shuffle_kv_cache_enabled": [
      "cls"
    ],
    "is_triton_unified_attn_enabled": [
      "cls"
    ],
    "is_fp8bmm_enabled": [
      "cls"
    ],
    "is_fp4bmm_enabled": [
      "cls"
    ],
    "is_asm_fp4_gemm_dynamic_quant_enabled": [
      "cls"
    ],
    "is_triton_rotary_embed_enabled": [
      "cls"
    ],
    "is_triton_gemm_enabled": [
      "cls"
    ],
    "register_ops_once": [],
    "get_rmsnorm_fused_add_op": [],
    "get_rmsnorm_op": [],
    "get_rmsnorm_fused_add_dynamic_quant_op": [],
    "get_rmsnorm_fused_dynamic_quant_op": [],
    "get_rmsnorm_group_fused_quant_op": [],
    "get_rmsnorm_group_add_fused_quant_op": [],
    "get_per_token_quant_op": [],
    "get_group_quant_op": [],
    "get_act_mul_fused_fp8_group_quant_op": [],
    "rms_norm": [
      "x",
      "weight",
      "variance_epsilon"
    ],
    "rms_norm2d_with_add": [
      "x",
      "residual",
      "weight",
      "variance_epsilon"
    ],
    "gemm_a8w8": [
      "A",
      "B",
      "As",
      "Bs",
      "bias",
      "output_dtype"
    ],
    "triton_gemm_a8w8_blockscale": [
      "A",
      "B",
      "As",
      "Bs",
      "block_size",
      "output_dtype"
    ],
    "gemm_a8w8_blockscale": [
      "A",
      "B",
      "As",
      "Bs",
      "block_size",
      "output_dtype"
    ],
    "fused_moe": [
      "hidden_states",
      "w1",
      "w2",
      "topk_weight",
      "topk_ids",
      "expert_mask",
      "activation_method",
      "quant_method",
      "doweight_stage1",
      "w1_scale",
      "w2_scale",
      "a1_scale",
      "a2_scale",
      "num_local_tokens",
      "output_dtype"
    ],
    "asm_moe_tkw1": [
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "fc1_scale",
      "fc2_scale",
      "fc1_smooth_scale",
      "fc2_smooth_scale",
      "a16",
      "per_tensor_quant_scale",
      "expert_mask",
      "activation_method"
    ],
    "topk_softmax": [
      "topk_weights",
      "topk_indices",
      "token_expert_indices",
      "gating_output",
      "renormalize"
    ],
    "topk_sigmoid": [
      "topk_weights",
      "topk_indices",
      "token_expert_indices",
      "gating_output",
      "renormalize"
    ],
    "biased_grouped_topk": [
      "gating_output",
      "correction_bias",
      "topk_weights",
      "topk_ids",
      "num_expert_group",
      "topk_group",
      "need_renorm",
      "routed_scaling_factor"
    ],
    "grouped_topk": [
      "gating_output",
      "topk_weights",
      "topk_ids",
      "num_expert_group",
      "topk_group",
      "need_renorm",
      "scoring_func",
      "routed_scaling_factor"
    ],
    "mla_decode_fwd": [
      "q",
      "kv_buffer",
      "o",
      "sm_scale",
      "qo_indptr",
      "max_seqlen_qo",
      "kv_indptr",
      "kv_indices",
      "kv_last_page_lens",
      "logit_cap",
      "q_scale",
      "kv_scale"
    ],
    "per_tensor_quant": [
      "x",
      "quant_dtype",
      "scale"
    ],
    "per_token_quant": [
      "x",
      "quant_dtype",
      "scale"
    ],
    "triton_fp4_gemm_dynamic_qaunt": [
      "x",
      "weight",
      "weight_scale",
      "out_dtype",
      "x_scales"
    ],
    "triton_rotary_embed": [
      "positions",
      "query",
      "key",
      "cos_sin_cache",
      "head_size",
      "rotary_dim",
      "is_neox_style"
    ],
    "batched_gemm_a16wfp4": [
      "X",
      "W",
      "w_scale",
      "Y",
      "transpose_bm",
      "prequant",
      "y_scale"
    ],
    "triton_fp8_bmm": [
      "X",
      "WQ",
      "w_scale",
      "group_size",
      "bias",
      "dtype",
      "splitK",
      "YQ",
      "transpose_bm",
      "config"
    ],
    "group_fp8_quant": [
      "input_2d",
      "group_size"
    ],
    "is_triton_gemm_w8a8_tuned": [
      "n",
      "k"
    ],
    "is_triton_gemm_afp4wfp4_presh_ws_tuned": [
      "n",
      "k"
    ],
    "shuffle_weight": [
      "self",
      "tensor",
      "layout"
    ],
    "shuffle_weights": []
  },
  "IntermediateTensors": {
    "__init__": [
      "self",
      "tensors",
      "kv_connector_output"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "items": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__repr__": [
      "self"
    ]
  },
  "VLLMValidationError": {
    "__init__": [
      "self",
      "message"
    ],
    "__str__": [
      "self"
    ]
  },
  "SystemEnv": [],
  "DEFAULT_CONDA_PATTERNS": [],
  "DEFAULT_PIP_PATTERNS": [],
  "run": [
    "command"
  ],
  "run_and_read_all": [
    "run_lambda",
    "command"
  ],
  "run_and_parse_first_match": [
    "run_lambda",
    "command",
    "regex"
  ],
  "run_and_return_first_line": [
    "run_lambda",
    "command"
  ],
  "get_conda_packages": [
    "run_lambda",
    "patterns"
  ],
  "get_gcc_version": [
    "run_lambda"
  ],
  "get_clang_version": [
    "run_lambda"
  ],
  "get_cmake_version": [
    "run_lambda"
  ],
  "get_nvidia_driver_version": [
    "run_lambda"
  ],
  "get_gpu_info": [
    "run_lambda"
  ],
  "get_running_cuda_version": [
    "run_lambda"
  ],
  "get_cudnn_version": [
    "run_lambda"
  ],
  "get_nvidia_smi": [],
  "get_rocm_version": [
    "run_lambda"
  ],
  "get_vllm_version": [],
  "summarize_vllm_build_flags": [],
  "get_gpu_topo": [
    "run_lambda"
  ],
  "get_cpu_info": [
    "run_lambda"
  ],
  "get_platform": [],
  "get_mac_version": [
    "run_lambda"
  ],
  "get_windows_version": [
    "run_lambda"
  ],
  "get_lsb_version": [
    "run_lambda"
  ],
  "check_release_file": [
    "run_lambda"
  ],
  "get_os": [
    "run_lambda"
  ],
  "get_python_platform": [],
  "get_libc_version": [],
  "is_uv_venv": [],
  "get_pip_packages": [
    "run_lambda",
    "patterns"
  ],
  "get_cachingallocator_config": [],
  "get_cuda_module_loading_config": [],
  "is_xnnpack_available": [],
  "get_env_vars": [],
  "get_env_info": [],
  "env_info_fmt": [],
  "pretty_str": [
    "envinfo"
  ],
  "get_pretty_env_info": [],
  "T": [],
  "bc_linter_skip": [
    "obj"
  ],
  "bc_linter_include": [
    "obj"
  ],
  "HTTPConnection": {
    "__init__": [
      "self"
    ],
    "get_sync_client": [
      "self"
    ],
    "get_async_client": [
      "self"
    ],
    "_validate_http_url": [
      "self",
      "url"
    ],
    "_headers": [
      "self"
    ],
    "get_response": [
      "self",
      "url"
    ],
    "get_async_response": [
      "self",
      "url"
    ],
    "get_bytes": [
      "self",
      "url"
    ],
    "async_get_bytes": [
      "self",
      "url"
    ],
    "get_text": [
      "self",
      "url"
    ],
    "async_get_text": [
      "self",
      "url"
    ],
    "get_json": [
      "self",
      "url"
    ],
    "async_get_json": [
      "self",
      "url"
    ],
    "download_file": [
      "self",
      "url",
      "save_path"
    ],
    "async_download_file": [
      "self",
      "url",
      "save_path"
    ]
  },
  "global_http_connection": [],
  "TRACE_HEADERS": [],
  "_is_otel_imported": [],
  "is_otel_available": [],
  "init_tracer": [
    "instrumenting_module_name",
    "otlp_traces_endpoint"
  ],
  "get_span_exporter": [
    "endpoint"
  ],
  "extract_trace_context": [
    "headers"
  ],
  "extract_trace_headers": [
    "headers"
  ],
  "SpanAttributes": {
    "GEN_AI_USAGE_COMPLETION_TOKENS": [],
    "GEN_AI_USAGE_PROMPT_TOKENS": [],
    "GEN_AI_REQUEST_MAX_TOKENS": [],
    "GEN_AI_REQUEST_TOP_P": [],
    "GEN_AI_REQUEST_TEMPERATURE": [],
    "GEN_AI_RESPONSE_MODEL": [],
    "GEN_AI_REQUEST_ID": [],
    "GEN_AI_REQUEST_N": [],
    "GEN_AI_USAGE_NUM_SEQUENCES": [],
    "GEN_AI_LATENCY_TIME_IN_QUEUE": [],
    "GEN_AI_LATENCY_TIME_TO_FIRST_TOKEN": [],
    "GEN_AI_LATENCY_E2E": [],
    "GEN_AI_LATENCY_TIME_IN_SCHEDULER": [],
    "GEN_AI_LATENCY_TIME_IN_MODEL_FORWARD": [],
    "GEN_AI_LATENCY_TIME_IN_MODEL_EXECUTE": [],
    "GEN_AI_LATENCY_TIME_IN_MODEL_PREFILL": [],
    "GEN_AI_LATENCY_TIME_IN_MODEL_DECODE": [],
    "GEN_AI_LATENCY_TIME_IN_MODEL_INFERENCE": []
  },
  "contains_trace_headers": [
    "headers"
  ],
  "log_tracing_disabled_warning": [],
  "_SAMPLING_EPS": [],
  "_MAX_TEMP": [],
  "SamplingType": {
    "GREEDY": [],
    "RANDOM": [],
    "RANDOM_SEED": []
  },
  "StructuredOutputsParams": {
    "__post_init__": [
      "self"
    ],
    "all_constraints_none": [
      "self"
    ],
    "all_non_structural_tag_constraints_none": [
      "self"
    ]
  },
  "RequestOutputKind": {
    "CUMULATIVE": [],
    "DELTA": [],
    "FINAL_ONLY": []
  },
  "SamplingParams": {
    "from_optional": [
      "n",
      "presence_penalty",
      "frequency_penalty",
      "repetition_penalty",
      "temperature",
      "top_p",
      "top_k",
      "min_p",
      "seed",
      "stop",
      "stop_token_ids",
      "bad_words",
      "include_stop_str_in_output",
      "ignore_eos",
      "max_tokens",
      "min_tokens",
      "logprobs",
      "prompt_logprobs",
      "detokenize",
      "skip_special_tokens",
      "spaces_between_special_tokens",
      "logits_processors",
      "truncate_prompt_tokens",
      "output_kind",
      "structured_outputs",
      "logit_bias",
      "allowed_token_ids",
      "extra_args",
      "skip_clone"
    ],
    "__post_init__": [
      "self"
    ],
    "_verify_args": [
      "self"
    ],
    "_verify_greedy_sampling": [
      "self"
    ],
    "update_from_generation_config": [
      "self",
      "generation_config",
      "model_eos_token_id"
    ],
    "update_from_tokenizer": [
      "self",
      "tokenizer"
    ],
    "sampling_type": [
      "self"
    ],
    "all_stop_token_ids": [
      "self"
    ],
    "bad_words_token_ids": [
      "self"
    ],
    "clone": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "BeamSearchParams": {},
  "_SCALAR_TYPES_ID_MAP": [],
  "NanRepr": {
    "NONE": [],
    "IEEE_754": [],
    "EXTD_RANGE_MAX_MIN": []
  },
  "ScalarType": {
    "_floating_point_max_int": [
      "self"
    ],
    "_floating_point_max": [
      "self"
    ],
    "_raw_max": [
      "self"
    ],
    "_raw_min": [
      "self"
    ],
    "id": [
      "self"
    ],
    "size_bits": [
      "self"
    ],
    "min": [
      "self"
    ],
    "max": [
      "self"
    ],
    "is_signed": [
      "self"
    ],
    "is_floating_point": [
      "self"
    ],
    "is_integer": [
      "self"
    ],
    "has_bias": [
      "self"
    ],
    "has_infs": [
      "self"
    ],
    "has_nans": [
      "self"
    ],
    "is_ieee_754": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "int_": [
      "cls",
      "size_bits",
      "bias"
    ],
    "uint": [
      "cls",
      "size_bits",
      "bias"
    ],
    "float_IEEE754": [
      "cls",
      "exponent",
      "mantissa"
    ],
    "float_": [
      "cls",
      "exponent",
      "mantissa",
      "finite_values_only",
      "nan_repr"
    ],
    "from_id": [
      "cls",
      "scalar_type_id"
    ]
  },
  "scalar_types": {
    "int4": [],
    "uint4": [],
    "int8": [],
    "uint8": [],
    "float8_e4m3fn": [],
    "float8_e5m2": [],
    "float8_e8m0fnu": [],
    "float16_e8m7": [],
    "float16_e5m10": [],
    "float6_e3m2f": [],
    "float6_e2m3f": [],
    "float4_e2m1f": [],
    "uint2b2": [],
    "uint3b4": [],
    "uint4b8": [],
    "uint8b128": [],
    "bfloat16": [],
    "float16": []
  },
  "get_bad_words_logits_processors": [
    "bad_words",
    "tokenizer"
  ],
  "NoBadWordsLogitsProcessor": {
    "_SMALLEST_LOGIT": [],
    "_NEUTRAL_LOGIT": [],
    "__init__": [
      "self",
      "bad_words_ids"
    ],
    "__call__": [
      "self",
      "past_tokens_ids",
      "logits"
    ],
    "_init_word_bias": [
      "self",
      "logits"
    ],
    "_check_token_ids_bounds": [
      "self",
      "vocab_size"
    ]
  },
  "_get_module_info": [
    "module"
  ],
  "_get_child_signature": [
    "child"
  ],
  "_format_index_ranges": [
    "indices"
  ],
  "_format_module_tree": [
    "module",
    "name",
    "indent"
  ],
  "format_model_inspection": [
    "model"
  ],
  "ipex_ops": {
    "_reshape_activation_tensor": [
      "x"
    ],
    "silu_and_mul": [
      "out",
      "x"
    ],
    "gelu_and_mul": [
      "out",
      "x"
    ],
    "gelu_tanh_and_mul": [
      "out",
      "x"
    ],
    "gelu_fast": [
      "x"
    ],
    "gelu_new": [
      "x"
    ],
    "gelu_quick": [
      "out",
      "x"
    ],
    "paged_attention_v1": [
      "out",
      "query",
      "key_cache",
      "value_cache",
      "num_kv_heads",
      "scale",
      "block_tables",
      "context_lens",
      "block_size",
      "max_context_len",
      "alibi_slopes",
      "kv_cache_dtype",
      "k_scale",
      "v_scale",
      "tp_rank",
      "blocksparse_local_blocks",
      "blocksparse_vert_stride",
      "blocksparse_block_size",
      "blocksparse_head_sliding_step"
    ],
    "paged_attention_v2": [
      "out",
      "exp_sum",
      "max_logits",
      "tmp_out",
      "query",
      "key_cache",
      "value_cache",
      "num_kv_heads",
      "scale",
      "block_tables",
      "context_lens",
      "block_size",
      "max_context_len",
      "alibi_slopes",
      "kv_cache_dtype",
      "k_scale",
      "v_scale",
      "tp_rank",
      "blocksparse_local_blocks",
      "blocksparse_vert_stride",
      "blocksparse_block_size",
      "blocksparse_head_sliding_step"
    ],
    "rotary_embedding": [
      "positions",
      "query",
      "key",
      "head_size",
      "cos_sin_cache",
      "is_neox"
    ],
    "rms_norm": [
      "input",
      "weight",
      "epsilon"
    ],
    "fused_add_rms_norm": [
      "input",
      "residual",
      "weight",
      "epsilon"
    ],
    "varlen_attention": [
      "query",
      "key",
      "value",
      "out",
      "seqlen_q",
      "seqlen_k",
      "alibi_slopes",
      "max_seqlen_q",
      "max_seqlen_k",
      "pdropout",
      "softmax_scale",
      "zero_tensors",
      "is_causal",
      "return_softmax",
      "gen_",
      "window_size_left",
      "window_size_right",
      "logits_soft_cap"
    ],
    "reshape_and_cache": [
      "key",
      "value",
      "key_cache",
      "value_cache",
      "slot_mapping",
      "kv_cache_dtype",
      "k_scale",
      "v_scale"
    ],
    "reshape_and_cache_flash": [
      "key",
      "value",
      "key_cache",
      "value_cache",
      "slot_mapping",
      "kv_cache_dtype",
      "k_scale",
      "v_scale",
      "k_scale_float",
      "v_scale_float"
    ],
    "flash_attn_varlen_func": [
      "q",
      "k",
      "v",
      "cu_seqlens_q",
      "max_seqlen_q",
      "max_seqlen_k",
      "softmax_scale",
      "causal",
      "out",
      "block_table",
      "alibi_slopes",
      "window_size",
      "softcap",
      "seqused_k",
      "cu_seqlens_k",
      "dropout_p",
      "scheduler_metadata",
      "fa_version",
      "q_descale",
      "k_descale",
      "v_descale",
      "num_splits",
      "s_aux"
    ],
    "get_scheduler_metadata": [
      "batch_size",
      "max_seqlen_q",
      "max_seqlen_k",
      "num_heads_q",
      "num_heads_kv",
      "headdim",
      "cache_seqlens",
      "qkv_dtype",
      "headdim_v",
      "cu_seqlens_q",
      "cu_seqlens_k_new",
      "cache_leftpad",
      "page_size",
      "max_seqlen_k_new",
      "causal",
      "window_size",
      "has_softcap",
      "num_splits",
      "pack_gqa",
      "sm_margin"
    ],
    "swap_blocks": [
      "src",
      "dst",
      "block_mapping"
    ],
    "scaled_fp8_quant": [
      "input",
      "scale",
      "num_token_padding",
      "scale_ub",
      "use_per_token_if_dynamic",
      "output"
    ]
  },
  "paged_attention_v1": [
    "out",
    "query",
    "key_cache",
    "value_cache",
    "num_kv_heads",
    "scale",
    "block_tables",
    "seq_lens",
    "block_size",
    "max_seq_len",
    "alibi_slopes",
    "kv_cache_dtype",
    "k_scale",
    "v_scale",
    "tp_rank",
    "blocksparse_local_blocks",
    "blocksparse_vert_stride",
    "blocksparse_block_size",
    "blocksparse_head_sliding_step"
  ],
  "paged_attention_v2": [
    "out",
    "exp_sum",
    "max_logits",
    "tmp_out",
    "query",
    "key_cache",
    "value_cache",
    "num_kv_heads",
    "scale",
    "block_tables",
    "seq_lens",
    "block_size",
    "max_seq_len",
    "alibi_slopes",
    "kv_cache_dtype",
    "k_scale",
    "v_scale",
    "tp_rank",
    "blocksparse_local_blocks",
    "blocksparse_vert_stride",
    "blocksparse_block_size",
    "blocksparse_head_sliding_step"
  ],
  "paged_attention_rocm": [
    "out",
    "exp_sum",
    "max_logits",
    "tmp_out",
    "query",
    "key_cache",
    "value_cache",
    "num_kv_heads",
    "scale",
    "block_tables",
    "seq_lens",
    "query_start_loc",
    "block_size",
    "max_seq_len",
    "alibi_slopes",
    "kv_cache_dtype",
    "k_scale",
    "v_scale",
    "fp8_out_scale",
    "mfma_type"
  ],
  "mla_decode_kvcache_cpu": [
    "out",
    "query",
    "kv_cache",
    "scale",
    "block_tables",
    "seq_lens"
  ],
  "merge_attn_states": [
    "output",
    "prefix_output",
    "prefix_lse",
    "suffix_output",
    "suffix_lse",
    "output_lse"
  ],
  "convert_vertical_slash_indexes": [
    "q_seqlens",
    "kv_seqlens",
    "vertical_indexes",
    "slash_indexes",
    "context_size",
    "block_size_M",
    "block_size_N",
    "causal"
  ],
  "convert_vertical_slash_indexes_mergehead": [
    "q_seqlens",
    "kv_seqlens",
    "vertical_indexes",
    "slash_indexes",
    "vertical_indices_count",
    "slash_indices_count",
    "context_size",
    "block_size_M",
    "block_size_N",
    "causal"
  ],
  "rotary_embedding": [
    "positions",
    "query",
    "key",
    "head_size",
    "cos_sin_cache",
    "is_neox"
  ],
  "rms_norm": [
    "out",
    "input",
    "weight",
    "epsilon"
  ],
  "fused_add_rms_norm": [
    "input",
    "residual",
    "weight",
    "epsilon"
  ],
  "fused_qk_norm_rope": [
    "qkv",
    "num_heads_q",
    "num_heads_k",
    "num_heads_v",
    "head_dim",
    "eps",
    "q_weight",
    "k_weight",
    "cos_sin_cache",
    "is_neox",
    "position_ids"
  ],
  "apply_repetition_penalties_torch": [
    "logits",
    "prompt_mask",
    "output_mask",
    "repetition_penalties"
  ],
  "apply_repetition_penalties_cuda": [
    "logits",
    "prompt_mask",
    "output_mask",
    "repetition_penalties"
  ],
  "apply_repetition_penalties": [
    "logits",
    "prompt_mask",
    "output_mask",
    "repetition_penalties"
  ],
  "rms_norm_dynamic_per_token_quant": [
    "input",
    "weight",
    "epsilon",
    "quant_dtype",
    "scale_ub",
    "residual"
  ],
  "rms_norm_per_block_quant": [
    "input",
    "weight",
    "epsilon",
    "quant_dtype",
    "group_size",
    "scale_ub",
    "residual",
    "is_scale_transposed"
  ],
  "awq_dequantize": [
    "qweight",
    "scales",
    "zeros",
    "split_k_iters",
    "thx",
    "thy"
  ],
  "awq_gemm": [
    "input",
    "qweight",
    "scales",
    "qzeros",
    "split_k_iters"
  ],
  "gptq_gemm": [
    "a",
    "b_q_weight",
    "b_gptq_qzeros",
    "b_gptq_scales",
    "b_g_idx",
    "use_exllama",
    "use_v2_format",
    "bit"
  ],
  "gptq_shuffle": [
    "q_weight",
    "q_perm",
    "bit"
  ],
  "gptq_marlin_24_gemm": [
    "a",
    "b_q_weight",
    "b_meta",
    "b_scales",
    "workspace",
    "b_q_type",
    "size_m",
    "size_n",
    "size_k"
  ],
  "cutlass_scaled_mm_supports_fp4": [
    "cuda_device_capability"
  ],
  "cutlass_scaled_fp4_mm": [
    "a",
    "b",
    "block_scale_a",
    "block_scale_b",
    "alpha",
    "out_dtype"
  ],
  "cutlass_scaled_mm_supports_fp8": [
    "cuda_device_capability"
  ],
  "cutlass_scaled_mm_supports_block_fp8": [
    "cuda_device_capability"
  ],
  "cutlass_scaled_mm": [
    "a",
    "b",
    "scale_a",
    "scale_b",
    "out_dtype",
    "bias"
  ],
  "cutlass_scaled_mm_azp": [
    "a",
    "b",
    "scale_a",
    "scale_b",
    "out_dtype",
    "azp_adj",
    "azp",
    "bias"
  ],
  "cutlass_sparse_scaled_mm_supported": [
    "cuda_device_capability"
  ],
  "cutlass_group_gemm_supported": [
    "cuda_device_capability"
  ],
  "cutlass_sparse_compress": [
    "a"
  ],
  "cutlass_scaled_sparse_mm": [
    "a",
    "bt_nzs",
    "bt_meta",
    "scale_a",
    "scale_b",
    "out_dtype",
    "bias"
  ],
  "get_cutlass_moe_mm_data": [
    "topk_ids",
    "expert_offsets",
    "problem_sizes1",
    "problem_sizes2",
    "input_permutation",
    "output_permutation",
    "num_experts",
    "n",
    "k",
    "blockscale_offsets"
  ],
  "get_cutlass_moe_mm_problem_sizes_from_expert_offsets": [
    "expert_first_token_offset",
    "problem_sizes1",
    "problem_sizes2",
    "n",
    "k",
    "swap_ab"
  ],
  "shuffle_rows": [
    "input_tensor",
    "dst2src_map"
  ],
  "get_cutlass_pplx_moe_mm_data": [
    "expert_offsets",
    "problem_sizes1",
    "problem_sizes2",
    "expert_num_tokens",
    "num_local_experts",
    "padded_m",
    "n",
    "k"
  ],
  "cutlass_moe_mm": [
    "out_tensors",
    "a_tensors",
    "b_tensors",
    "a_scales",
    "b_scales",
    "expert_offsets",
    "problem_sizes",
    "a_strides",
    "b_strides",
    "c_strides",
    "per_act_token",
    "per_out_ch"
  ],
  "cutlass_fp4_moe_mm": [
    "out_tensors",
    "a_tensors",
    "b_tensors",
    "a_scales",
    "b_scales",
    "alphas",
    "problem_sizes",
    "expert_offsets",
    "sf_offsets"
  ],
  "gptq_marlin_repack": [
    "b_q_weight",
    "perm",
    "size_k",
    "size_n",
    "num_bits",
    "is_a_8bit"
  ],
  "awq_marlin_repack": [
    "b_q_weight",
    "size_k",
    "size_n",
    "num_bits",
    "is_a_8bit"
  ],
  "gptq_marlin_moe_repack": [
    "b_q_weight",
    "perm",
    "size_k",
    "size_n",
    "num_bits",
    "is_a_8bit"
  ],
  "awq_marlin_moe_repack": [
    "b_q_weight",
    "perm",
    "size_k",
    "size_n",
    "num_bits",
    "is_a_8bit"
  ],
  "marlin_int4_fp8_preprocess": [
    "qweight",
    "qzeros_or_none",
    "inplace"
  ],
  "marlin_gemm": [
    "a",
    "c",
    "b_q_weight",
    "b_bias",
    "b_scales",
    "a_scales",
    "global_scale",
    "b_zeros",
    "g_idx",
    "perm",
    "workspace",
    "b_q_type",
    "size_m",
    "size_n",
    "size_k",
    "is_k_full",
    "use_atomic_add",
    "use_fp32_reduce",
    "is_zp_float"
  ],
  "machete_supported_schedules": [
    "a_type",
    "b_type",
    "group_scales_type",
    "group_zeros_type",
    "channel_scales_type",
    "token_scales_type",
    "out_type"
  ],
  "machete_mm": [
    "a",
    "b_q",
    "b_type",
    "out_type",
    "b_group_scales",
    "b_group_zeros",
    "b_group_size",
    "b_channel_scales",
    "a_token_scales",
    "schedule"
  ],
  "machete_prepack_B": [
    "b_q_weight",
    "a_type",
    "b_type",
    "group_scales_type"
  ],
  "cutlass_w4a8_mm": [
    "a",
    "b_q",
    "b_group_scales",
    "b_group_size",
    "b_channel_scales",
    "a_token_scales",
    "out_type",
    "maybe_schedule"
  ],
  "cutlass_pack_scale_fp8": [
    "scales"
  ],
  "cutlass_encode_and_reorder_int4b": [
    "b"
  ],
  "cutlass_w4a8_moe_mm": [
    "out_tensors",
    "a_tensors",
    "b_tensors",
    "a_scales",
    "b_scales",
    "b_group_scales",
    "b_group_size",
    "expert_offsets",
    "problem_sizes",
    "a_strides",
    "b_strides",
    "c_strides",
    "group_scale_strides",
    "maybe_schedule"
  ],
  "cutlass_encode_and_reorder_int4b_grouped": [
    "b_tensors"
  ],
  "permute_cols": [
    "a",
    "perm"
  ],
  "scaled_fp4_quant": [
    "input",
    "input_global_scale",
    "is_sf_swizzled_layout",
    "backend"
  ],
  "scaled_fp4_experts_quant": [
    "input_tensor",
    "input_global_scale",
    "expert_offsets",
    "blockscale_offsets",
    "topk"
  ],
  "silu_and_mul_scaled_fp4_experts_quant": [
    "input_tensor",
    "input_global_scale",
    "expert_offsets",
    "blockscale_offsets",
    "topk"
  ],
  "scaled_fp8_quant": [
    "input",
    "scale",
    "num_token_padding",
    "scale_ub",
    "use_per_token_if_dynamic",
    "output",
    "group_shape"
  ],
  "allspark_repack_weight": [
    "qweight",
    "scale",
    "zero_point",
    "has_zp"
  ],
  "allspark_w8a16_gemm": [
    "a",
    "b_qweight",
    "b_scales",
    "b_qzeros",
    "n",
    "group_size",
    "sm_count",
    "sm_version",
    "CUBLAS_M_THRESHOLD",
    "has_zp",
    "n32k16_reorder"
  ],
  "scaled_int8_quant": [
    "input",
    "scale",
    "azp",
    "symmetric"
  ],
  "ggml_dequantize": [
    "W",
    "quant_type",
    "m",
    "n",
    "dtype"
  ],
  "ggml_mul_mat_vec_a8": [
    "W",
    "X",
    "quant_type",
    "row"
  ],
  "ggml_mul_mat_a8": [
    "W",
    "X",
    "quant_type",
    "row"
  ],
  "ggml_moe_a8": [
    "X",
    "W",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_post_padded",
    "quant_type",
    "row",
    "top_k",
    "tokens"
  ],
  "ggml_moe_a8_vec": [
    "X",
    "W",
    "topk_ids",
    "top_k",
    "quant_type",
    "row",
    "tokens"
  ],
  "ggml_moe_get_block_size": [
    "quant_type"
  ],
  "selective_scan_fwd": [
    "u",
    "delta",
    "A",
    "B",
    "C",
    "D_",
    "z_",
    "delta_bias_",
    "delta_softplus",
    "query_start_loc",
    "cache_indices",
    "has_initial_state",
    "ssm_states",
    "pad_slot_id",
    "block_size",
    "block_idx_first_scheduled_token",
    "block_idx_last_scheduled_token",
    "initial_state_idx"
  ],
  "LLMM1": [
    "a",
    "b",
    "rows_per_block"
  ],
  "wvSplitK": [
    "a",
    "b",
    "cu_count",
    "bias"
  ],
  "wvSplitKrc": [
    "a",
    "b",
    "cu_count",
    "bias"
  ],
  "wvSplitKQ": [
    "a",
    "b",
    "out_dtype",
    "scale_a",
    "scale_b",
    "cu_count",
    "bias"
  ],
  "moe_sum": [
    "input",
    "output"
  ],
  "moe_align_block_size": [
    "topk_ids",
    "num_experts",
    "block_size",
    "sorted_token_ids",
    "experts_ids",
    "num_tokens_post_pad",
    "expert_map"
  ],
  "batched_moe_align_block_size": [
    "max_tokens_per_batch",
    "block_size",
    "expert_num_tokens",
    "sorted_ids",
    "expert_ids",
    "num_tokens_post_pad"
  ],
  "moe_lora_align_block_size": [
    "topk_ids",
    "token_lora_mapping",
    "num_experts",
    "block_size",
    "max_loras",
    "max_num_tokens_padded",
    "max_num_m_blocks",
    "sorted_token_ids",
    "experts_ids",
    "num_tokens_post_pad",
    "adapter_enabled",
    "lora_ids",
    "expert_map"
  ],
  "moe_wna16_gemm": [
    "input",
    "output",
    "b_qweight",
    "b_scales",
    "b_qzeros",
    "topk_weights",
    "sorted_token_ids",
    "experts_ids",
    "num_tokens_post_pad",
    "top_k",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "bit"
  ],
  "topk_softmax": [
    "topk_weights",
    "topk_ids",
    "token_expert_indices",
    "gating_output",
    "renormalize",
    "e_score_correction_bias"
  ],
  "topk_sigmoid": [
    "topk_weights",
    "topk_ids",
    "token_expert_indices",
    "gating_output",
    "renormalize",
    "e_score_correction_bias"
  ],
  "grouped_topk": [
    "scores",
    "num_expert_group",
    "topk_group",
    "topk",
    "renormalize",
    "routed_scaling_factor",
    "bias",
    "scoring_func"
  ],
  "moe_wna16_marlin_gemm": [
    "input",
    "output",
    "b_qweight",
    "b_bias",
    "b_scales",
    "a_scales",
    "global_scale",
    "b_qzeros",
    "g_idx",
    "perm",
    "workspace",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_past_padded",
    "topk_weights",
    "moe_block_size",
    "top_k",
    "mul_topk_weights",
    "b_q_type",
    "size_m",
    "size_n",
    "size_k",
    "is_k_full",
    "use_atomic_add",
    "use_fp32_reduce",
    "is_zp_float",
    "thread_k",
    "thread_n",
    "blocks_per_sm"
  ],
  "reshape_and_cache": [
    "key",
    "value",
    "key_cache",
    "value_cache",
    "slot_mapping",
    "kv_cache_dtype",
    "k_scale",
    "v_scale"
  ],
  "reshape_and_cache_flash": [
    "key",
    "value",
    "key_cache",
    "value_cache",
    "slot_mapping",
    "kv_cache_dtype",
    "k_scale",
    "v_scale"
  ],
  "concat_and_cache_mla": [
    "kv_c",
    "k_pe",
    "kv_cache",
    "slot_mapping",
    "kv_cache_dtype",
    "scale"
  ],
  "concat_and_cache_mla_rope_fused": [
    "positions",
    "q_pe",
    "k_pe",
    "kv_c",
    "cos_sin_cache",
    "is_neox",
    "slot_mapping",
    "kv_cache",
    "kv_cache_dtype",
    "kv_cache_scale"
  ],
  "swap_blocks": [
    "src",
    "dst",
    "block_size_in_bytes",
    "block_mapping"
  ],
  "convert_fp8": [
    "output",
    "input",
    "scale",
    "kv_dtype"
  ],
  "gather_and_maybe_dequant_cache": [
    "src_cache",
    "dst",
    "block_table",
    "cu_seq_lens",
    "token_to_seq",
    "num_tokens",
    "kv_cache_dtype",
    "scale",
    "seq_starts"
  ],
  "cp_gather_cache": [
    "src_cache",
    "dst",
    "block_table",
    "cu_seq_lens",
    "batch_size",
    "seq_starts"
  ],
  "cp_gather_and_upconvert_fp8_kv_cache": [
    "src_cache",
    "dst",
    "block_table",
    "seq_lens",
    "workspace_starts",
    "batch_size"
  ],
  "indexer_k_quant_and_cache": [
    "k",
    "kv_cache",
    "slot_mapping",
    "quant_block_size",
    "kv_cache_dtype"
  ],
  "cp_gather_indexer_k_quant_cache": [
    "kv_cache",
    "dst_k",
    "dst_scale",
    "block_table",
    "cu_seq_lens"
  ],
  "get_device_attribute": [
    "attribute",
    "device"
  ],
  "get_max_shared_memory_per_block_device_attribute": [
    "device"
  ],
  "init_custom_ar": [
    "ipc_tensors",
    "rank_data",
    "rank",
    "fully_connected"
  ],
  "all_reduce": [
    "fa",
    "inp",
    "out",
    "reg_buffer",
    "reg_buffer_sz_bytes"
  ],
  "dispose": [
    "fa"
  ],
  "meta_size": [],
  "register_buffer": [
    "fa",
    "ipc_tensors"
  ],
  "get_graph_buffer_ipc_meta": [
    "fa"
  ],
  "register_graph_buffers": [
    "fa",
    "handles",
    "offsets"
  ],
  "allocate_shared_buffer_and_handle": [
    "size"
  ],
  "open_mem_handle": [
    "mem_handle"
  ],
  "free_shared_buffer": [
    "ptr"
  ],
  "init_custom_qr": [
    "rank",
    "world_size",
    "qr_max_size"
  ],
  "qr_destroy": [
    "fa"
  ],
  "qr_all_reduce": [
    "fa",
    "inp",
    "out",
    "quant_level",
    "cast_bf2half"
  ],
  "qr_get_handle": [
    "fa"
  ],
  "qr_open_handles": [
    "fa",
    "handles"
  ],
  "qr_max_size": [],
  "get_flash_mla_metadata": [
    "cache_seqlens",
    "num_heads_per_head_k",
    "num_heads_k"
  ],
  "flash_mla_with_kvcache": [
    "q",
    "k_cache",
    "block_table",
    "cache_seqlens",
    "head_dim_v",
    "tile_scheduler_metadata",
    "num_splits",
    "softmax_scale",
    "causal"
  ],
  "sm100_cutlass_mla_decode": [
    "out",
    "lse",
    "q_nope",
    "q_pe",
    "kv_c_and_k_pe_cache",
    "seq_lens",
    "page_table",
    "workspace",
    "scale",
    "num_kv_splits"
  ],
  "sm100_cutlass_mla_get_workspace_size": [
    "max_seq_len",
    "num_batches",
    "sm_count",
    "num_kv_splits"
  ],
  "CPUDNNLGEMMHandler": {
    "__init__": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "_supports_onednn": [],
  "is_onednn_acl_supported": [],
  "create_onednn_mm": [
    "weight",
    "primitive_cache_size"
  ],
  "onednn_mm": [
    "dnnl_handler",
    "x",
    "bias"
  ],
  "create_onednn_scaled_mm": [
    "weight",
    "weight_scales",
    "output_type",
    "dynamic_quant",
    "use_azp",
    "primitive_cache_size"
  ],
  "onednn_scaled_int8_quant": [
    "input",
    "scale",
    "azp",
    "symmetric"
  ],
  "onednn_scaled_mm": [
    "dnnl_handler",
    "x",
    "output",
    "input_scale",
    "input_zp",
    "input_zp_adj",
    "bias"
  ],
  "cpu_attn_get_scheduler_metadata": [
    "num_reqs",
    "num_heads",
    "num_kv_heads",
    "head_dim",
    "seq_lens",
    "dtype",
    "query_start_loc",
    "causal",
    "sliding_window_size",
    "isa",
    "enable_kv_split"
  ],
  "cpu_attn_reshape_and_cache": [
    "key",
    "value",
    "key_cache",
    "value_cache",
    "slot_mapping",
    "isa"
  ],
  "cpu_attention_with_kv_cache": [
    "query",
    "key_cache",
    "value_cache",
    "output",
    "query_start_loc",
    "seq_lens",
    "scale",
    "causal",
    "alibi_slopes",
    "sliding_window",
    "block_table",
    "softcap",
    "scheduler_metadata",
    "s_aux"
  ],
  "cpu_gemm_wna16": [
    "input",
    "q_weight",
    "scales",
    "zeros",
    "g_idx",
    "bias",
    "pack_factor",
    "isa_hint"
  ],
  "cpu_prepack_moe_weight": [
    "weight",
    "isa"
  ],
  "cpu_fused_moe": [
    "input",
    "w13",
    "w2",
    "w13_bias",
    "w2_bias",
    "topk_weights",
    "topk_ids",
    "act",
    "isa"
  ],
  "matmul_mxf4_bf16_tn": [
    "a",
    "b",
    "a_sf",
    "b_sf",
    "alpha"
  ],
  "matmul_ada_mxf4_bf16_tn": [
    "a",
    "b",
    "a_sf",
    "b_sf",
    "alpha"
  ],
  "fusedQuantizeMx": [
    "a",
    "b"
  ],
  "fusedQuantizeNv": [
    "a",
    "b",
    "global_scale"
  ],
  "hadacore_transform": [
    "x",
    "inplace"
  ],
  "TYPE_CHECKING": [],
  "__version__": [],
  "version": [],
  "__version_tuple__": [],
  "version_tuple": [],
  "__commit_id__": [],
  "commit_id": [],
  "Glm47MoeModelToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ]
  },
  "SeedOssToolParser": {
    "TOOL_CALL_START": [],
    "TOOL_CALL_END": [],
    "__init__": [
      "self",
      "tokenizer"
    ],
    "_generate_tool_call_id": [
      "self"
    ],
    "_reset_streaming_state": [
      "self"
    ],
    "_parse_xml_function_call": [
      "self",
      "function_call_str",
      "tools"
    ],
    "_get_function_calls": [
      "self",
      "model_output"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "OpenAIToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request",
      "token_ids"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "FunctionGemmaToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "_parse_arguments": [
      "self",
      "args_str"
    ],
    "adjust_request": [
      "self",
      "request"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "_buffer_delta_text": [
      "self",
      "delta_text"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "ALPHANUMERIC": [],
  "StreamingState": {
    "WAITING_FOR_TOOL_START": [],
    "WAITING_FOR_TOOL_KEY": [],
    "PARSING_NAME": [],
    "PARSING_NAME_COMPLETED": [],
    "WAITING_FOR_ARGUMENTS_START": [],
    "PARSING_ARGUMENTS": [],
    "PARSING_ARGUMENTS_COMPLETED": [],
    "TOOL_COMPLETE": [],
    "ALL_TOOLS_COMPLETE": []
  },
  "MistralToolCall": {
    "generate_random_id": [],
    "is_valid_id": [
      "id"
    ]
  },
  "_is_pre_v11_tokeniser": [
    "model_tokenizer"
  ],
  "MistralToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "adjust_request": [
      "self",
      "request"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ],
    "_extract_tool_calls_streaming": [
      "self",
      "delta_text",
      "delta_token_ids"
    ],
    "_generate_delta_tool_call": [
      "self",
      "delta_text"
    ],
    "update_stream_state_pre_v11_tokenizer": [
      "self"
    ],
    "_extract_tool_calls_streaming_pre_v11_tokenizer": [
      "self",
      "delta_text",
      "delta_token_ids"
    ],
    "_split_delta": [
      "self",
      "delta_text",
      "stop_after_quotes",
      "stop_after_opening_curly_braces",
      "stop_after_closing_curly_braces",
      "stop_after_closing_brackets",
      "stop_after_colon",
      "stop_after_comma"
    ]
  },
  "LongcatFlashToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ]
  },
  "ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "vocab": [
      "self"
    ],
    "adjust_request": [
      "self",
      "request"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "ToolParserManager": {
    "get_tool_parser": [
      "cls",
      "name"
    ],
    "_load_lazy_parser": [
      "cls",
      "name"
    ],
    "_register_module": [
      "cls",
      "module",
      "module_name",
      "force"
    ],
    "register_lazy_module": [
      "cls",
      "name",
      "module_path",
      "class_name"
    ],
    "register_module": [
      "cls",
      "name",
      "force",
      "module"
    ],
    "list_registered": [
      "cls"
    ],
    "import_tool_parser": [
      "cls",
      "plugin_path"
    ]
  },
  "DeepSeekV31ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "StreamingXMLToolCallParser": {
    "__init__": [
      "self"
    ],
    "reset_streaming_state": [
      "self"
    ],
    "parse_single_streaming_chunks": [
      "self",
      "xml_chunk"
    ],
    "_escape_xml_special_chars": [
      "self",
      "text"
    ],
    "_process_complete_xml_elements": [
      "self"
    ],
    "_should_skip_element": [
      "self",
      "element"
    ],
    "_find_next_complete_element": [
      "self",
      "start_pos"
    ],
    "_merge_new_deltas_to_single_response": [
      "self",
      "initial_count"
    ],
    "_preprocess_xml_chunk": [
      "self",
      "chunk"
    ],
    "_emit_delta": [
      "self",
      "delta"
    ],
    "_auto_close_open_parameter_if_needed": [
      "self",
      "incoming_tag"
    ],
    "_start_element": [
      "self",
      "name",
      "attrs"
    ],
    "_char_data": [
      "self",
      "data"
    ],
    "_end_element": [
      "self",
      "name"
    ],
    "setup_parser": [
      "self"
    ],
    "set_tools": [
      "self",
      "tools"
    ],
    "_extract_function_name": [
      "self",
      "name",
      "attrs"
    ],
    "_extract_parameter_name": [
      "self",
      "name",
      "attrs"
    ],
    "_get_param_type": [
      "self",
      "param_name"
    ],
    "repair_param_type": [
      "self",
      "param_type"
    ],
    "_convert_param_value": [
      "self",
      "param_value",
      "param_type"
    ],
    "_convert_for_json_streaming": [
      "self",
      "converted_value",
      "param_type"
    ],
    "_reset_xml_parser_after_tool_call": [
      "self"
    ]
  },
  "Qwen3XMLToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "Step3ToolParser": {
    "TOOL_CALLS_BEGIN": [],
    "TOOL_CALLS_END": [],
    "TOOL_CALL_BEGIN": [],
    "TOOL_CALL_END": [],
    "TOOL_SEP": [],
    "SPECIAL_TOKENS": [],
    "__init__": [
      "self",
      "tokenizer"
    ],
    "adjust_request": [
      "self",
      "request"
    ],
    "_parse_steptml_invoke": [
      "action_text"
    ],
    "_cast_arguments": [
      "self",
      "func_name",
      "params",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ]
  },
  "MinimaxM2ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "_generate_tool_call_id": [
      "self"
    ],
    "_reset_streaming_state": [
      "self"
    ],
    "_extract_name": [
      "self",
      "name_str"
    ],
    "_convert_param_value": [
      "self",
      "value",
      "param_type"
    ],
    "_extract_types_from_schema": [
      "self",
      "schema"
    ],
    "_convert_param_value_with_types": [
      "self",
      "value",
      "param_types"
    ],
    "_get_param_types_from_config": [
      "self",
      "param_name",
      "param_config"
    ],
    "_parse_single_invoke": [
      "self",
      "invoke_str",
      "tools"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "xLAMToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "preprocess_model_output": [
      "self",
      "model_output"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "Hermes2ProToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "tool_call_delta_buffer": [
      "self",
      "delta_text"
    ],
    "adjust_request": [
      "self",
      "request"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "Ernie45ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "JambaToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "adjust_request": [
      "self",
      "request"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "find_common_prefix": [
    "s1",
    "s2"
  ],
  "find_common_suffix": [
    "s1",
    "s2"
  ],
  "extract_intermediate_diff": [
    "curr",
    "old"
  ],
  "find_all_indices": [
    "string",
    "substring"
  ],
  "partial_json_loads": [
    "input_str",
    "flags"
  ],
  "is_complete_json": [
    "input_str"
  ],
  "consume_space": [
    "i",
    "s"
  ],
  "_extract_tool_info": [
    "tool"
  ],
  "_get_tool_schema_from_tool": [
    "tool"
  ],
  "_get_tool_schema_defs": [
    "tools"
  ],
  "_get_json_schema_from_tools": [
    "tools"
  ],
  "get_json_schema_from_tools": [
    "tool_choice",
    "tools"
  ],
  "MinimaxToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "preprocess_model_output": [
      "self",
      "model_output"
    ],
    "_clean_duplicate_braces": [
      "self",
      "args_text"
    ],
    "_clean_delta_braces": [
      "self",
      "delta_text"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "_update_thinking_state": [
      "self",
      "text"
    ],
    "_is_potential_tag_start": [
      "self",
      "text"
    ],
    "_should_buffer_content": [
      "self",
      "delta_text"
    ],
    "_split_content_for_buffering": [
      "self",
      "delta_text"
    ],
    "_process_buffer": [
      "self",
      "new_content"
    ],
    "_reset_streaming_state": [
      "self"
    ],
    "_advance_to_next_tool": [
      "self"
    ],
    "_set_current_tool_index": [
      "self",
      "index"
    ],
    "_get_current_tool_index": [
      "self"
    ],
    "_get_next_unsent_tool_index": [
      "self",
      "tool_count"
    ],
    "_ensure_state_arrays": [
      "self",
      "tool_count"
    ],
    "_detect_tools_in_text": [
      "self",
      "text"
    ],
    "_find_tool_boundaries": [
      "self",
      "text"
    ],
    "_extract_tool_args": [
      "self",
      "tool_content",
      "args_match"
    ],
    "_get_current_tool_content": [
      "self",
      "text",
      "tool_index"
    ],
    "_handle_tool_name_streaming": [
      "self",
      "tool_content",
      "tool_count"
    ],
    "_handle_tool_args_streaming": [
      "self",
      "tool_content",
      "tool_count"
    ],
    "_is_end_tool_calls": [
      "self",
      "current_text"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ],
    "_find_tool_start_outside_thinking": [
      "self",
      "current_text"
    ],
    "_extract_content_before_tools": [
      "self",
      "current_text",
      "delta_text",
      "tool_start"
    ],
    "_extract_tool_content": [
      "self",
      "current_text",
      "tool_start"
    ]
  },
  "_UnexpectedAstError": {},
  "PythonicToolParser": {
    "TOOL_CALL_REGEX": [],
    "__init__": [
      "self",
      "tokenizer"
    ],
    "current_tool_index": [
      "self",
      "value"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "_get_parameter_value": [
    "val"
  ],
  "_handle_single_tool": [
    "call"
  ],
  "_make_valid_python": [
    "text"
  ],
  "_compute_tool_delta": [
    "previously_sent_args",
    "new_call",
    "index",
    "withheld_suffix"
  ],
  "KimiK2ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "_check_and_strip_markers": [
      "self",
      "text"
    ],
    "_reset_section_state": [
      "self"
    ],
    "reset_streaming_state": [
      "self"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "HunyuanA13BToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "preprocess_model_output": [
      "self",
      "model_output"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ],
    "_try_parse_json_tools": [
      "self",
      "current_text"
    ],
    "_handle_test_compatibility": [
      "self",
      "current_text"
    ],
    "_ensure_state_arrays": [
      "self",
      "tool_count"
    ],
    "_handle_tool_name_streaming": [
      "self",
      "current_idx",
      "tool_count",
      "name_matches"
    ],
    "_handle_tool_args_streaming": [
      "self",
      "current_text",
      "current_idx",
      "tool_count"
    ]
  },
  "Olmo3PythonicToolParser": {
    "TOOL_CALL_REGEX": [],
    "__init__": [
      "self",
      "tokenizer"
    ],
    "current_tool_index": [
      "self",
      "value"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "_TOOL_PARSERS_TO_REGISTER": [],
  "register_lazy_tool_parsers": [],
  "DeepSeekV32ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "_generate_tool_call_id": [
      "self"
    ],
    "_reset_streaming_state": [
      "self"
    ],
    "_parse_invoke_params": [
      "self",
      "invoke_str"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "_extract_name": [
      "self",
      "name_str"
    ],
    "_extract_param_name": [
      "self",
      "input_str"
    ],
    "_convert_param_value": [
      "self",
      "value",
      "param_type"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "Step3p5ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ],
    "parser_should_check_for_unstreamed_tool_arg_tokens": [
      "self"
    ]
  },
  "Phi4MiniJsonToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "Qwen3CoderToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "_generate_tool_call_id": [
      "self"
    ],
    "_reset_streaming_state": [
      "self"
    ],
    "_get_arguments_config": [
      "self",
      "func_name",
      "tools"
    ],
    "_convert_param_value": [
      "self",
      "param_value",
      "param_name",
      "param_config",
      "func_name"
    ],
    "_parse_xml_function_call": [
      "self",
      "function_call_str",
      "tools"
    ],
    "_get_function_calls": [
      "self",
      "model_output"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "REGEX_FUNCTION_CALL": [],
  "NAME_REGEX": [],
  "ARGS_REGEX": [],
  "GigaChat3ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "Internlm2ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "adjust_request": [
      "self",
      "request"
    ],
    "get_arguments": [
      "self",
      "obj"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ]
  },
  "DeepSeekV3ToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "GraniteToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "Granite20bFCToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "Llama3JsonToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "Llama4PythonicToolParser": {
    "TOOL_CALL_REGEX": [],
    "__init__": [
      "self",
      "tokenizer"
    ],
    "current_tool_index": [
      "self",
      "value"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "Glm4MoeModelToolParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "adjust_request": [
      "self",
      "request"
    ],
    "extract_tool_calls": [
      "self",
      "model_output",
      "request"
    ],
    "extract_tool_calls_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids",
      "request"
    ]
  },
  "ASSET_DIR": [],
  "AudioAssetName": [],
  "AudioAsset": {
    "filename": [
      "self"
    ],
    "audio_and_sample_rate": [
      "self"
    ],
    "get_local_path": [
      "self"
    ],
    "url": [
      "self"
    ]
  },
  "download_video_asset": [
    "filename"
  ],
  "video_to_ndarrays": [
    "path",
    "num_frames"
  ],
  "video_to_pil_images_list": [
    "path",
    "num_frames"
  ],
  "video_get_metadata": [
    "path",
    "num_frames"
  ],
  "VideoAssetName": [],
  "VideoAsset": {
    "filename": [
      "self"
    ],
    "video_path": [
      "self"
    ],
    "pil_images": [
      "self"
    ],
    "np_ndarrays": [
      "self"
    ],
    "metadata": [
      "self"
    ],
    "get_audio": [
      "self",
      "sampling_rate"
    ]
  },
  "VLLM_S3_BUCKET_URL": [],
  "get_cache_dir": [],
  "get_vllm_public_assets": [
    "filename",
    "s3_prefix"
  ],
  "VLM_IMAGES_DIR": [],
  "ImageAssetName": [],
  "ImageAsset": {
    "get_path": [
      "self",
      "ext"
    ],
    "pil_image": [
      "self"
    ],
    "pil_image_ext": [
      "self",
      "ext"
    ],
    "image_embeds": [
      "self"
    ],
    "read_bytes": [
      "self",
      "ext"
    ]
  },
  "SSLCertRefresher": {
    "__init__": [
      "self",
      "ssl_context",
      "key_path",
      "cert_path",
      "ca_path"
    ],
    "_watch_files": [
      "self",
      "paths",
      "fun"
    ],
    "stop": [
      "self"
    ]
  },
  "RequestLogger": {
    "__init__": [
      "self"
    ],
    "log_inputs": [
      "self",
      "request_id",
      "prompt",
      "prompt_token_ids",
      "prompt_embeds",
      "params",
      "lora_request"
    ],
    "log_outputs": [
      "self",
      "request_id",
      "outputs",
      "output_token_ids",
      "finish_reason",
      "is_streaming",
      "delta"
    ]
  },
  "app": [],
  "engine": [],
  "health": [],
  "generate": [
    "request"
  ],
  "_generate": [
    "request_dict",
    "raw_request"
  ],
  "build_app": [
    "args"
  ],
  "init_app": [
    "args",
    "llm_engine"
  ],
  "run_server": [
    "args",
    "llm_engine"
  ],
  "VLLM_SUBCMD_PARSER_EPILOG": [],
  "listen_for_disconnect": [
    "request"
  ],
  "with_cancellation": [
    "handler_func"
  ],
  "decrement_server_load": [
    "request"
  ],
  "load_aware_call": [
    "func"
  ],
  "cli_env_setup": [],
  "_validate_truncation_size": [
    "max_model_len",
    "truncate_prompt_tokens",
    "tokenization_kwargs"
  ],
  "get_max_tokens": [
    "max_model_len",
    "request",
    "input_length",
    "default_sampling_params"
  ],
  "log_non_default_args": [
    "args"
  ],
  "should_include_usage": [
    "stream_options",
    "enable_force_include_usage"
  ],
  "process_lora_modules": [
    "args_lora_modules",
    "default_mm_loras"
  ],
  "sanitize_message": [
    "message"
  ],
  "log_version_and_model": [
    "lgr",
    "version",
    "model_name"
  ],
  "serve_http": [
    "app",
    "sock",
    "enable_ssl_refresh"
  ],
  "watchdog_loop": [
    "server",
    "engine"
  ],
  "terminate_if_errored": [
    "server",
    "engine"
  ],
  "_add_shutdown_handlers": [
    "app",
    "server"
  ],
  "RenderConfig": {
    "verify_truncate_prompt_tokens": [
      "self",
      "model_config"
    ]
  },
  "BaseRenderer": {
    "__init__": [
      "self",
      "model_config",
      "tokenizer"
    ],
    "render_prompt": [
      "self"
    ],
    "render_prompt_and_embeds": [
      "self"
    ],
    "load_prompt_embeds": [
      "self",
      "prompt_embeds",
      "truncate_prompt_tokens",
      "cache_salt"
    ]
  },
  "CompletionRenderer": {
    "__init__": [
      "self",
      "model_config",
      "tokenizer",
      "async_tokenizer_pool"
    ],
    "render_prompt": [
      "self"
    ],
    "render_prompt_and_embeds": [
      "self"
    ],
    "_maybe_apply_truncation": [
      "self",
      "token_ids",
      "truncate_prompt_tokens"
    ],
    "_create_prompt": [
      "self",
      "prompt_input",
      "config",
      "truncate_prompt_tokens"
    ],
    "_create_prompt_from_text": [
      "self",
      "text",
      "max_length",
      "truncate_prompt_tokens",
      "add_special_tokens",
      "cache_salt"
    ],
    "_create_prompt_from_token_ids": [
      "self",
      "token_ids",
      "max_length",
      "truncate_prompt_tokens",
      "cache_salt",
      "needs_detokenization"
    ],
    "_get_async_tokenizer": [
      "self"
    ],
    "_create_tokens_prompt": [
      "self",
      "token_ids",
      "max_length",
      "cache_salt",
      "prompt"
    ]
  },
  "_R": [],
  "LLM": {
    "__init__": [
      "self",
      "model"
    ],
    "get_tokenizer": [
      "self"
    ],
    "reset_mm_cache": [
      "self"
    ],
    "get_default_sampling_params": [
      "self"
    ],
    "generate": [
      "self",
      "prompts",
      "sampling_params"
    ],
    "_get_modality_specific_lora_reqs": [
      "self",
      "prompts",
      "lora_request"
    ],
    "_resolve_single_prompt_mm_lora": [
      "self",
      "prompt",
      "lora_request",
      "default_mm_loras"
    ],
    "collective_rpc": [
      "self",
      "method",
      "timeout",
      "args",
      "kwargs"
    ],
    "apply_model": [
      "self",
      "func"
    ],
    "_get_beam_search_lora_requests": [
      "self",
      "lora_request",
      "prompts"
    ],
    "beam_search": [
      "self",
      "prompts",
      "params",
      "lora_request",
      "use_tqdm",
      "concurrency_limit"
    ],
    "preprocess_chat": [
      "self",
      "messages",
      "chat_template",
      "chat_template_content_format",
      "add_generation_prompt",
      "continue_final_message",
      "tools",
      "chat_template_kwargs",
      "mm_processor_kwargs"
    ],
    "chat": [
      "self",
      "messages",
      "sampling_params",
      "use_tqdm",
      "lora_request",
      "chat_template",
      "chat_template_content_format",
      "add_generation_prompt",
      "continue_final_message",
      "tools",
      "chat_template_kwargs",
      "mm_processor_kwargs"
    ],
    "encode": [
      "self",
      "prompts",
      "pooling_params"
    ],
    "embed": [
      "self",
      "prompts"
    ],
    "classify": [
      "self",
      "prompts"
    ],
    "reward": [],
    "_embedding_score": [
      "self",
      "tokenizer",
      "text_1",
      "text_2",
      "truncate_prompt_tokens",
      "use_tqdm",
      "pooling_params",
      "lora_request",
      "tokenization_kwargs"
    ],
    "_cross_encoding_score": [
      "self",
      "tokenizer",
      "data_1",
      "data_2",
      "truncate_prompt_tokens",
      "use_tqdm",
      "pooling_params",
      "lora_request",
      "tokenization_kwargs",
      "score_template"
    ],
    "score": [],
    "start_profile": [
      "self"
    ],
    "stop_profile": [
      "self"
    ],
    "reset_prefix_cache": [
      "self",
      "reset_running_requests",
      "reset_connector"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wake_up": [
      "self",
      "tags"
    ],
    "get_metrics": [
      "self"
    ],
    "_validate_and_add_requests": [
      "self",
      "prompts",
      "params"
    ],
    "_process_inputs": [
      "self",
      "request_id",
      "engine_prompt",
      "params"
    ],
    "_add_request": [
      "self",
      "prompt",
      "params",
      "lora_request",
      "priority",
      "tokenization_kwargs"
    ],
    "_run_engine": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "H11_MAX_INCOMPLETE_EVENT_SIZE_DEFAULT": [],
  "H11_MAX_HEADER_COUNT_DEFAULT": [],
  "MCP_PREFIX": [],
  "ChatTemplateResolutionError": {},
  "MODALITY_PLACEHOLDERS_MAP": [],
  "AudioURL": {},
  "ChatCompletionContentPartAudioParam": {},
  "ChatCompletionContentPartImageEmbedsParam": {},
  "ChatCompletionContentPartAudioEmbedsParam": {},
  "VideoURL": {},
  "ChatCompletionContentPartVideoParam": {},
  "PILImage": {
    "model_config": []
  },
  "CustomChatCompletionContentPILImageParam": {},
  "CustomChatCompletionContentSimpleImageParam": {},
  "CustomChatCompletionContentSimpleAudioParam": {},
  "CustomChatCompletionContentSimpleVideoParam": {},
  "CustomThinkCompletionContentParam": {},
  "CustomChatCompletionMessageParam": {},
  "ConversationMessage": {},
  "ChatTemplateContentFormatOption": [],
  "ChatTemplateContentFormat": [],
  "ModalityStr": [],
  "_T": [],
  "_BatchedSingleItemField": {},
  "_detect_field": [
    "tensors",
    "mm_processor"
  ],
  "_merge_embeds": [
    "data_items",
    "mm_processor"
  ],
  "_get_embeds_data": [
    "modality",
    "data_items",
    "mm_processor"
  ],
  "rebuild_mm_uuids_from_mm_data": [
    "mm_uuids",
    "mm_data"
  ],
  "build_video_prompts_from_mm_data": [
    "mm_data"
  ],
  "BaseMultiModalItemTracker": {
    "__init__": [
      "self",
      "model_config"
    ],
    "use_unified_vision_chunk_modality": [
      "self"
    ],
    "model_config": [
      "self"
    ],
    "model_cls": [
      "self"
    ],
    "allowed_local_media_path": [
      "self"
    ],
    "allowed_media_domains": [
      "self"
    ],
    "mm_registry": [
      "self"
    ],
    "mm_processor": [
      "self"
    ],
    "add": [
      "self",
      "modality",
      "item"
    ],
    "create_parser": [
      "self"
    ]
  },
  "_resolve_items": [
    "items_by_modality",
    "mm_processor",
    "vision_chunk_modality_order"
  ],
  "MultiModalItemTracker": {
    "resolve_items": [
      "self"
    ],
    "create_parser": [
      "self"
    ]
  },
  "AsyncMultiModalItemTracker": {
    "resolve_items": [
      "self"
    ],
    "create_parser": [
      "self"
    ]
  },
  "BaseMultiModalContentParser": {
    "__init__": [
      "self"
    ],
    "_add_placeholder": [
      "self",
      "modality",
      "placeholder"
    ],
    "mm_placeholder_storage": [
      "self"
    ],
    "parse_image": [
      "self",
      "image_url",
      "uuid"
    ],
    "parse_image_embeds": [
      "self",
      "image_embeds",
      "uuid"
    ],
    "parse_image_pil": [
      "self",
      "image_pil",
      "uuid"
    ],
    "parse_audio": [
      "self",
      "audio_url",
      "uuid"
    ],
    "parse_input_audio": [
      "self",
      "input_audio",
      "uuid"
    ],
    "parse_audio_embeds": [
      "self",
      "audio_embeds",
      "uuid"
    ],
    "parse_video": [
      "self",
      "video_url",
      "uuid"
    ]
  },
  "MultiModalContentParser": {
    "__init__": [
      "self",
      "tracker"
    ],
    "model_config": [
      "self"
    ],
    "parse_image": [
      "self",
      "image_url",
      "uuid"
    ],
    "parse_image_embeds": [
      "self",
      "image_embeds",
      "uuid"
    ],
    "parse_audio_embeds": [
      "self",
      "audio_embeds",
      "uuid"
    ],
    "parse_image_pil": [
      "self",
      "image_pil",
      "uuid"
    ],
    "parse_audio": [
      "self",
      "audio_url",
      "uuid"
    ],
    "parse_input_audio": [
      "self",
      "input_audio",
      "uuid"
    ],
    "parse_video": [
      "self",
      "video_url",
      "uuid"
    ]
  },
  "AsyncMultiModalContentParser": {
    "__init__": [
      "self",
      "tracker"
    ],
    "model_config": [
      "self"
    ],
    "_image_with_uuid_async": [
      "self",
      "image_url",
      "uuid"
    ],
    "parse_image": [
      "self",
      "image_url",
      "uuid"
    ],
    "parse_image_embeds": [
      "self",
      "image_embeds",
      "uuid"
    ],
    "parse_audio_embeds": [
      "self",
      "audio_embeds",
      "uuid"
    ],
    "parse_image_pil": [
      "self",
      "image_pil",
      "uuid"
    ],
    "_audio_with_uuid_async": [
      "self",
      "audio_url",
      "uuid"
    ],
    "parse_audio": [
      "self",
      "audio_url",
      "uuid"
    ],
    "parse_input_audio": [
      "self",
      "input_audio",
      "uuid"
    ],
    "_video_with_uuid_async": [
      "self",
      "video_url",
      "uuid"
    ],
    "parse_video": [
      "self",
      "video_url",
      "uuid"
    ]
  },
  "validate_chat_template": [
    "chat_template"
  ],
  "_load_chat_template": [
    "chat_template"
  ],
  "_cached_load_chat_template": [],
  "load_chat_template": [
    "chat_template"
  ],
  "_get_interleaved_text_prompt": [
    "placeholder_storage",
    "texts"
  ],
  "_get_full_multimodal_text_prompt": [
    "placeholder_storage",
    "texts",
    "interleave_strings"
  ],
  "_TextParser": [],
  "_ImageEmbedsParser": [],
  "_AudioEmbedsParser": [],
  "_InputAudioParser": [],
  "_RefusalParser": [],
  "_PILImageParser": [],
  "_ThinkParser": [],
  "_ImageParser": [],
  "_AudioParser": [],
  "_VideoParser": [],
  "_ResponsesInputImageParser": [],
  "_parse_chat_message_content_mm_part": [
    "part"
  ],
  "PART_TYPES_TO_SKIP_NONE_CONTENT": [],
  "_parse_chat_message_content_parts": [
    "role",
    "parts",
    "mm_tracker"
  ],
  "_parse_chat_message_content_part": [
    "part",
    "mm_parser"
  ],
  "_AssistantParser": [],
  "_ToolParser": [],
  "_parse_chat_message_content": [
    "message",
    "mm_tracker",
    "content_format",
    "interleave_strings"
  ],
  "_postprocess_messages": [
    "messages"
  ],
  "parse_chat_messages": [
    "messages",
    "model_config",
    "content_format"
  ],
  "parse_chat_messages_async": [
    "messages",
    "model_config",
    "content_format"
  ],
  "get_history_tool_calls_cnt": [
    "conversation"
  ],
  "make_tool_call_id": [
    "id_type",
    "func_name",
    "idx"
  ],
  "VllmEngineServicer": {
    "__init__": [
      "self",
      "async_llm",
      "start_time"
    ],
    "Generate": [
      "self",
      "request",
      "context"
    ],
    "Embed": [
      "self",
      "request",
      "context"
    ],
    "HealthCheck": [
      "self",
      "request",
      "context"
    ],
    "Abort": [
      "self",
      "request",
      "context"
    ],
    "GetModelInfo": [
      "self",
      "request",
      "context"
    ],
    "GetServerInfo": [
      "self",
      "request",
      "context"
    ],
    "_sampling_params_from_proto": [
      "params",
      "stream"
    ],
    "_chunk_response": [
      "output"
    ],
    "_complete_response": [
      "output"
    ]
  },
  "serve_grpc": [
    "args"
  ],
  "list_server_and_tools": [
    "server_url"
  ],
  "trim_schema": [
    "schema"
  ],
  "post_process_tools_description": [
    "list_tools_result"
  ],
  "ToolServer": {
    "has_tool": [
      "self",
      "tool_name"
    ],
    "get_tool_description": [
      "self",
      "tool_name",
      "allowed_tools"
    ],
    "new_session": [
      "self",
      "tool_name",
      "session_id",
      "headers"
    ]
  },
  "MCPToolServer": {
    "__init__": [
      "self"
    ],
    "add_tool_server": [
      "self",
      "server_url"
    ],
    "has_tool": [
      "self",
      "tool_name"
    ],
    "get_tool_description": [
      "self",
      "server_label",
      "allowed_tools"
    ],
    "new_session": [
      "self",
      "tool_name",
      "session_id",
      "headers"
    ]
  },
  "DemoToolServer": {
    "__init__": [
      "self"
    ],
    "init_and_validate": [
      "self"
    ],
    "has_tool": [
      "self",
      "tool_name"
    ],
    "get_tool_description": [
      "self",
      "tool_name",
      "allowed_tools"
    ],
    "new_session": [
      "self",
      "tool_name",
      "session_id",
      "headers"
    ]
  },
  "MIN_GPT_OSS_VERSION": [],
  "validate_gpt_oss_install": [],
  "Tool": {
    "get_result": [
      "self",
      "context"
    ],
    "get_result_parsable_context": [
      "self",
      "context"
    ]
  },
  "HarmonyBrowserTool": {
    "__init__": [
      "self"
    ],
    "get_result": [
      "self",
      "context"
    ],
    "get_result_parsable_context": [
      "self",
      "context"
    ],
    "tool_config": [
      "self"
    ]
  },
  "HarmonyPythonTool": {
    "__init__": [
      "self"
    ],
    "validate": [
      "self"
    ],
    "get_result": [
      "self",
      "context"
    ],
    "get_result_parsable_context": [
      "self",
      "context"
    ],
    "tool_config": [
      "self"
    ]
  },
  "wrap_data_with_event": [
    "data",
    "event"
  ],
  "AnthropicServingMessages": {
    "__init__": [
      "self",
      "engine_client",
      "models",
      "response_role"
    ],
    "_convert_anthropic_to_openai_request": [
      "self",
      "anthropic_request"
    ],
    "create_messages": [
      "self",
      "request",
      "raw_request"
    ],
    "messages_full_converter": [
      "self",
      "generator"
    ],
    "message_stream_converter": [
      "self",
      "generator"
    ]
  },
  "AnthropicError": {},
  "AnthropicErrorResponse": {},
  "AnthropicUsage": {},
  "AnthropicContentBlock": {},
  "AnthropicMessage": {},
  "AnthropicTool": {
    "validate_input_schema": [
      "cls",
      "v"
    ]
  },
  "AnthropicToolChoice": {},
  "AnthropicMessagesRequest": {
    "validate_model": [
      "cls",
      "v"
    ],
    "validate_max_tokens": [
      "cls",
      "v"
    ]
  },
  "AnthropicDelta": {},
  "AnthropicStreamEvent": {},
  "AnthropicMessagesResponse": {
    "model_post_init": [
      "self",
      "__context"
    ]
  },
  "router": [],
  "messages": [
    "request"
  ],
  "create_messages": [
    "request",
    "raw_request"
  ],
  "attach_router": [
    "app"
  ],
  "register_pooling_api_routers": [
    "app"
  ],
  "init_pooling_state": [
    "engine_client",
    "state",
    "args"
  ],
  "ServingScores": {
    "__init__": [
      "self",
      "engine_client",
      "models"
    ],
    "_embedding_score": [
      "self",
      "tokenizer",
      "data_1",
      "data_2",
      "request",
      "request_id",
      "tokenization_kwargs",
      "lora_request",
      "trace_headers"
    ],
    "_preprocess_score": [
      "self",
      "request",
      "tokenizer",
      "tokenization_kwargs",
      "data_1",
      "data_2"
    ],
    "_cross_encoding_score": [
      "self",
      "tokenizer",
      "data_1",
      "data_2",
      "request",
      "request_id",
      "tokenization_kwargs",
      "lora_request",
      "trace_headers"
    ],
    "_run_scoring": [
      "self",
      "data_1",
      "data_2",
      "request",
      "request_id",
      "raw_request"
    ],
    "create_score": [
      "self",
      "request",
      "raw_request"
    ],
    "do_rerank": [
      "self",
      "request",
      "raw_request"
    ],
    "request_output_to_score_response": [
      "self",
      "final_res_batch",
      "request_id",
      "created_time",
      "model_name"
    ],
    "request_output_to_rerank_response": [
      "self",
      "final_res_batch",
      "request_id",
      "model_name",
      "documents",
      "top_n"
    ]
  },
  "ScoreMultiModalParam": {},
  "_cosine_similarity": [
    "tokenizer",
    "embed_1",
    "embed_2"
  ],
  "_validate_score_input_lens": [
    "data_1",
    "data_2"
  ],
  "parse_score_data": [
    "data_1",
    "data_2",
    "model_config"
  ],
  "_parse_score_content": [
    "data",
    "mm_tracker"
  ],
  "_apply_model_score_template": [
    "model_config",
    "prompt_1",
    "prompt_2"
  ],
  "post_process_tokens": [
    "model_config",
    "prompt"
  ],
  "get_score_prompt": [
    "model_config",
    "tokenizer",
    "tokenization_kwargs",
    "data_1",
    "data_2",
    "score_template"
  ],
  "compress_token_type_ids": [
    "token_type_ids"
  ],
  "ScoreRequestMixin": {
    "to_pooling_params": [
      "self"
    ]
  },
  "ScoreDataRequest": {},
  "ScoreQueriesDocumentsRequest": {
    "data_1": [
      "self"
    ],
    "data_2": [
      "self"
    ]
  },
  "ScoreTextRequest": {
    "data_1": [
      "self"
    ],
    "data_2": [
      "self"
    ]
  },
  "RerankRequest": {},
  "RerankDocument": {},
  "RerankResult": {},
  "RerankUsage": {},
  "RerankResponse": {},
  "ScoreResponseData": {},
  "ScoreResponse": {},
  "score": [
    "request"
  ],
  "rerank": [
    "request"
  ],
  "create_score": [
    "request",
    "raw_request"
  ],
  "create_score_v1": [
    "request",
    "raw_request"
  ],
  "do_rerank": [
    "request",
    "raw_request"
  ],
  "do_rerank_v1": [
    "request",
    "raw_request"
  ],
  "do_rerank_v2": [
    "request",
    "raw_request"
  ],
  "OpenAIServingPooling": {
    "__init__": [
      "self",
      "engine_client",
      "models"
    ],
    "create_pooling": [
      "self",
      "request",
      "raw_request"
    ],
    "request_output_to_pooling_response": [
      "self",
      "final_res_batch",
      "request_id",
      "created_time",
      "model_name",
      "encoding_format",
      "embed_dtype",
      "endianness"
    ],
    "_build_render_config": [
      "self",
      "request"
    ]
  },
  "PoolingCompletionRequest": {
    "to_pooling_params": [
      "self"
    ]
  },
  "PoolingChatRequest": {
    "to_pooling_params": [
      "self"
    ]
  },
  "IOProcessorRequest": {
    "to_pooling_params": [
      "self"
    ]
  },
  "IOProcessorResponse": {},
  "PoolingResponseData": {},
  "PoolingResponse": {},
  "PoolingBytesResponse": {},
  "pooling": [
    "request"
  ],
  "create_pooling": [
    "request",
    "raw_request"
  ],
  "ClassificationMixin": {
    "_preprocess": [
      "self",
      "ctx"
    ],
    "_build_response": [
      "self",
      "ctx"
    ],
    "_build_render_config": [
      "self",
      "request"
    ]
  },
  "ServingClassification": {
    "request_id_prefix": [],
    "__init__": [
      "self",
      "engine_client",
      "models"
    ],
    "create_classify": [
      "self",
      "request",
      "raw_request"
    ],
    "_create_pooling_params": [
      "self",
      "ctx"
    ]
  },
  "ClassificationCompletionRequest": {},
  "ClassificationChatRequest": {},
  "ClassificationData": {},
  "ClassificationResponse": {},
  "classify": [
    "request"
  ],
  "create_classify": [
    "request",
    "raw_request"
  ],
  "EmbeddingMixin": {
    "__init__": [
      "self"
    ],
    "_preprocess": [
      "self",
      "ctx"
    ],
    "_build_render_config": [
      "self",
      "request"
    ],
    "_build_response": [
      "self",
      "ctx"
    ],
    "_get_max_position_embeddings": [
      "self"
    ],
    "_should_use_chunked_processing": [
      "self",
      "request"
    ],
    "_process_chunked_request": [
      "self",
      "ctx",
      "token_ids",
      "pooling_params",
      "trace_headers",
      "prompt_idx"
    ],
    "_validate_input": [
      "self",
      "request",
      "input_ids",
      "input_text"
    ],
    "_create_single_prompt_generator": [
      "self",
      "ctx",
      "engine_prompt",
      "pooling_params",
      "trace_headers",
      "prompt_index"
    ],
    "_prepare_generators": [
      "self",
      "ctx"
    ],
    "_collect_batch": [
      "self",
      "ctx"
    ]
  },
  "OpenAIServingEmbedding": {
    "request_id_prefix": [],
    "__init__": [
      "self",
      "engine_client",
      "models"
    ],
    "create_embedding": [
      "self",
      "request",
      "raw_request"
    ],
    "_create_pooling_params": [
      "self",
      "ctx"
    ],
    "_preprocess": [
      "self",
      "ctx"
    ]
  },
  "EmbeddingCompletionRequest": {},
  "EmbeddingChatRequest": {},
  "EmbeddingResponseData": {},
  "EmbeddingResponse": {},
  "EmbeddingBytesResponse": {},
  "embedding": [
    "request"
  ],
  "create_embedding": [
    "request",
    "raw_request"
  ],
  "PoolingBasicRequestMixin": {},
  "CompletionRequestMixin": {},
  "ChatRequestMixin": {
    "check_generation_prompt": [
      "cls",
      "data"
    ]
  },
  "EncodingRequestMixin": {},
  "EmbedRequestMixin": {
    "to_pooling_params": [
      "self"
    ]
  },
  "ClassifyRequestMixin": {
    "to_pooling_params": [
      "self"
    ]
  },
  "RunBatchSubcommand": {
    "name": [],
    "cmd": [
      "args"
    ],
    "subparser_init": [
      "self",
      "subparsers"
    ]
  },
  "cmd_init": [],
  "DESCRIPTION": [],
  "ServeSubcommand": {
    "name": [],
    "cmd": [
      "args"
    ],
    "validate": [
      "self",
      "args"
    ],
    "subparser_init": [
      "self",
      "subparsers"
    ]
  },
  "run_headless": [
    "args"
  ],
  "run_multi_api_server": [
    "args"
  ],
  "run_api_server_worker_proc": [
    "listen_address",
    "sock",
    "args",
    "client_config"
  ],
  "_register_signal_handlers": [],
  "_interactive_cli": [
    "args"
  ],
  "_print_chat_stream": [
    "stream"
  ],
  "_print_completion_stream": [
    "stream"
  ],
  "chat": [
    "system_prompt",
    "model_name",
    "client"
  ],
  "_add_query_options": [
    "parser"
  ],
  "ChatCommand": {
    "name": [],
    "cmd": [
      "args"
    ],
    "add_cli_args": [
      "parser"
    ],
    "subparser_init": [
      "self",
      "subparsers"
    ]
  },
  "CompleteCommand": {
    "name": [],
    "cmd": [
      "args"
    ],
    "add_cli_args": [
      "parser"
    ],
    "subparser_init": [
      "self",
      "subparsers"
    ]
  },
  "CollectEnvSubcommand": {
    "name": [],
    "cmd": [
      "args"
    ],
    "subparser_init": [
      "self",
      "subparsers"
    ]
  },
  "CLISubcommand": {
    "cmd": [
      "args"
    ],
    "validate": [
      "self",
      "args"
    ],
    "subparser_init": [
      "self",
      "subparsers"
    ]
  },
  "BenchmarkSubcommandBase": {
    "add_cli_args": [
      "cls",
      "parser"
    ],
    "cmd": [
      "args"
    ]
  },
  "BenchmarkMMProcessorSubcommand": {
    "name": [],
    "help": [],
    "add_cli_args": [
      "cls",
      "parser"
    ],
    "cmd": [
      "args"
    ]
  },
  "BenchmarkSubcommand": {
    "name": [],
    "help": [],
    "cmd": [
      "args"
    ],
    "validate": [
      "self",
      "args"
    ],
    "subparser_init": [
      "self",
      "subparsers"
    ]
  },
  "BenchmarkStartupSubcommand": {
    "name": [],
    "help": [],
    "add_cli_args": [
      "cls",
      "parser"
    ],
    "cmd": [
      "args"
    ]
  },
  "BenchmarkServingSubcommand": {
    "name": [],
    "help": [],
    "add_cli_args": [
      "cls",
      "parser"
    ],
    "cmd": [
      "args"
    ]
  },
  "BenchmarkLatencySubcommand": {
    "name": [],
    "help": [],
    "add_cli_args": [
      "cls",
      "parser"
    ],
    "cmd": [
      "args"
    ]
  },
  "BenchmarkSweepSubcommand": {
    "name": [],
    "help": [],
    "add_cli_args": [
      "cls",
      "parser"
    ],
    "cmd": [
      "args"
    ]
  },
  "BenchmarkThroughputSubcommand": {
    "name": [],
    "help": [],
    "add_cli_args": [
      "cls",
      "parser"
    ],
    "cmd": [
      "args"
    ]
  },
  "LoRAParserAction": {
    "__call__": [
      "self",
      "parser",
      "namespace",
      "values",
      "option_string"
    ]
  },
  "FrontendArgs": {
    "add_cli_args": [
      "parser"
    ]
  },
  "make_arg_parser": [
    "parser"
  ],
  "validate_parsed_serve_args": [
    "args"
  ],
  "create_parser_for_docs": [],
  "lifespan": [
    "app"
  ],
  "build_async_engine_client": [
    "args"
  ],
  "build_async_engine_client_from_engine_args": [
    "engine_args"
  ],
  "base": [
    "request"
  ],
  "tokenization": [
    "request"
  ],
  "engine_client": [
    "request"
  ],
  "get_server_load_metrics": [
    "request"
  ],
  "show_version": [],
  "load_log_config": [
    "log_config_file"
  ],
  "AuthenticationMiddleware": {
    "__init__": [
      "self",
      "app",
      "tokens"
    ],
    "verify_token": [
      "self",
      "headers"
    ],
    "__call__": [
      "self",
      "scope",
      "receive",
      "send"
    ]
  },
  "XRequestIdMiddleware": {
    "__init__": [
      "self",
      "app"
    ],
    "__call__": [
      "self",
      "scope",
      "receive",
      "send"
    ]
  },
  "_extract_content_from_chunk": [
    "chunk_data"
  ],
  "SSEDecoder": {
    "__init__": [
      "self"
    ],
    "decode_chunk": [
      "self",
      "chunk"
    ],
    "extract_content": [
      "self",
      "event_data"
    ],
    "add_content": [
      "self",
      "content"
    ],
    "get_complete_content": [
      "self"
    ]
  },
  "_log_streaming_response": [
    "response",
    "response_body"
  ],
  "_log_non_streaming_response": [
    "response_body"
  ],
  "init_app_state": [
    "engine_client",
    "state",
    "args"
  ],
  "create_server_socket": [
    "addr"
  ],
  "create_server_unix_socket": [
    "path"
  ],
  "validate_api_server_args": [
    "args"
  ],
  "setup_server": [
    "args"
  ],
  "run_server_worker": [
    "listen_address",
    "sock",
    "args",
    "client_config"
  ],
  "_ChatCompletionResponseChoiceT": [],
  "maybe_filter_parallel_tool_calls": [
    "choice",
    "request"
  ],
  "validate_json_request": [
    "raw_request"
  ],
  "create_orca_header": [
    "metrics_format",
    "named_metrics"
  ],
  "get_named_metrics_from_prometheus": [],
  "metrics_header": [
    "metrics_format"
  ],
  "BatchRequestInput": {
    "check_type_for_url": [
      "cls",
      "value",
      "info"
    ]
  },
  "BatchResponseData": {},
  "BatchRequestOutput": {},
  "parse_args": [],
  "_BAR_FORMAT": [],
  "BatchProgressTracker": {
    "__init__": [
      "self"
    ],
    "submitted": [
      "self"
    ],
    "completed": [
      "self"
    ],
    "pbar": [
      "self"
    ]
  },
  "read_file": [
    "path_or_url"
  ],
  "write_local_file": [
    "output_path",
    "batch_outputs"
  ],
  "upload_data": [
    "output_url",
    "data_or_file",
    "from_file"
  ],
  "write_file": [
    "path_or_url",
    "batch_outputs",
    "output_tmp_dir"
  ],
  "make_error_request_output": [
    "request",
    "error_msg"
  ],
  "make_async_error_request_output": [
    "request",
    "error_msg"
  ],
  "run_request": [
    "serving_engine_func",
    "request",
    "tracker"
  ],
  "validate_run_batch_args": [
    "args"
  ],
  "run_batch": [
    "engine_client",
    "args"
  ],
  "HarmonyStreamingState": {
    "reset_for_new_item": [
      "self"
    ]
  },
  "_extract_allowed_tools_from_mcp_requests": [
    "tools"
  ],
  "OpenAIServingResponses": {
    "__init__": [
      "self",
      "engine_client",
      "models"
    ],
    "_validate_generator_input": [
      "self",
      "engine_prompt"
    ],
    "_validate_create_responses_input": [
      "self",
      "request"
    ],
    "create_responses": [
      "self",
      "request",
      "raw_request"
    ],
    "_make_request": [
      "self",
      "request",
      "prev_response",
      "renderer"
    ],
    "_make_request_with_harmony": [
      "self",
      "request",
      "prev_response"
    ],
    "_initialize_tool_sessions": [
      "self",
      "request",
      "context",
      "exit_stack"
    ],
    "responses_full_generator": [
      "self",
      "request",
      "sampling_params",
      "result_generator",
      "context",
      "model_name",
      "tokenizer",
      "request_metadata",
      "created_time"
    ],
    "_is_mcp_tool_by_namespace": [
      "self",
      "recipient"
    ],
    "_topk_logprobs": [
      "self",
      "logprobs",
      "top_logprobs",
      "tokenizer"
    ],
    "_create_response_logprobs": [
      "self",
      "token_ids",
      "logprobs",
      "tokenizer",
      "top_logprobs"
    ],
    "_create_stream_response_logprobs": [
      "self",
      "token_ids",
      "logprobs",
      "tokenizer",
      "top_logprobs"
    ],
    "_make_response_output_items": [
      "self",
      "request",
      "final_output",
      "tokenizer"
    ],
    "_make_response_output_items_with_harmony": [
      "self",
      "context"
    ],
    "_extract_system_message_from_request": [
      "self",
      "request"
    ],
    "_construct_harmony_system_input_message": [
      "self",
      "request",
      "with_custom_tools",
      "tool_types"
    ],
    "_construct_input_messages_with_harmony": [
      "self",
      "request",
      "prev_response"
    ],
    "_run_background_request_stream": [
      "self",
      "request"
    ],
    "_run_background_request": [
      "self",
      "request"
    ],
    "responses_background_stream_generator": [
      "self",
      "response_id",
      "starting_after"
    ],
    "retrieve_responses": [
      "self",
      "response_id",
      "starting_after",
      "stream"
    ],
    "cancel_responses": [
      "self",
      "response_id"
    ],
    "_make_not_found_error": [
      "self",
      "response_id"
    ],
    "_make_store_not_supported_error": [
      "self"
    ],
    "_process_simple_streaming_events": [
      "self",
      "request",
      "sampling_params",
      "result_generator",
      "context",
      "model_name",
      "tokenizer",
      "request_metadata",
      "created_time",
      "_increment_sequence_number_and_return"
    ],
    "_emit_function_call_done_events": [
      "self",
      "previous_item",
      "state"
    ],
    "_emit_mcp_call_done_events": [
      "self",
      "previous_item",
      "state"
    ],
    "_emit_reasoning_done_events": [
      "self",
      "previous_item",
      "state"
    ],
    "_emit_text_output_done_events": [
      "self",
      "previous_item",
      "state"
    ],
    "_emit_previous_item_done_events": [
      "self",
      "previous_item",
      "state"
    ],
    "_emit_final_channel_delta_events": [
      "self",
      "ctx",
      "state"
    ],
    "_emit_analysis_channel_delta_events": [
      "self",
      "ctx",
      "state"
    ],
    "_emit_mcp_tool_delta_events": [
      "self",
      "ctx",
      "state",
      "recipient"
    ],
    "_emit_code_interpreter_delta_events": [
      "self",
      "ctx",
      "state"
    ],
    "_emit_mcp_prefix_delta_events": [
      "self",
      "ctx",
      "state"
    ],
    "_emit_content_delta_events": [
      "self",
      "ctx",
      "state"
    ],
    "_emit_browser_tool_events": [
      "self",
      "previous_item",
      "state"
    ],
    "_emit_mcp_tool_completion_events": [
      "self",
      "previous_item",
      "state"
    ],
    "_emit_code_interpreter_completion_events": [
      "self",
      "previous_item",
      "state"
    ],
    "_emit_mcp_prefix_completion_events": [
      "self",
      "previous_item",
      "state"
    ],
    "_emit_tool_action_events": [
      "self",
      "ctx",
      "state"
    ],
    "_emit_function_call_delta_events": [
      "self",
      "ctx",
      "state"
    ],
    "_process_harmony_streaming_events": [
      "self",
      "request",
      "sampling_params",
      "result_generator",
      "context",
      "model_name",
      "tokenizer",
      "request_metadata",
      "created_time",
      "_increment_sequence_number_and_return"
    ],
    "responses_stream_generator": [
      "self",
      "request",
      "sampling_params",
      "result_generator",
      "context",
      "model_name",
      "tokenizer",
      "request_metadata",
      "created_time"
    ]
  },
  "should_continue_final_message": [
    "request_input"
  ],
  "construct_input_messages": [],
  "_maybe_combine_reasoning_and_tool_call": [
    "item",
    "messages"
  ],
  "construct_chat_messages_with_tool_call": [
    "input_messages"
  ],
  "_construct_single_message_from_response_item": [
    "item"
  ],
  "extract_tool_types": [
    "tools"
  ],
  "convert_tool_responses_to_completions_format": [
    "tool"
  ],
  "construct_tool_dicts": [
    "tools",
    "tool_choice"
  ],
  "InputTokensDetails": {},
  "OutputTokensDetails": {},
  "ResponseUsage": {},
  "serialize_message": [
    "msg"
  ],
  "serialize_messages": [
    "msgs"
  ],
  "ResponseRawMessageAndToken": {},
  "ResponsesRequest": {
    "_DEFAULT_SAMPLING_PARAMS": [],
    "to_sampling_params": [
      "self",
      "default_max_tokens",
      "default_sampling_params"
    ],
    "is_include_output_logprobs": [
      "self"
    ],
    "validate_background": [
      "cls",
      "data"
    ],
    "validate_prompt": [
      "cls",
      "data"
    ],
    "check_cache_salt_support": [
      "cls",
      "data"
    ],
    "function_call_parsing": [
      "cls",
      "data"
    ]
  },
  "ResponsesResponse": {
    "serialize_output_messages": [
      "self",
      "msgs",
      "_info"
    ],
    "serialize_input_messages": [
      "self",
      "msgs",
      "_info"
    ],
    "from_request": [
      "cls",
      "request",
      "sampling_params",
      "model_name",
      "created_time",
      "output",
      "status",
      "usage",
      "input_messages",
      "output_messages"
    ]
  },
  "ResponseReasoningPartDoneEvent": {},
  "ResponseReasoningPartAddedEvent": {},
  "ResponseCompletedEvent": {},
  "ResponseCreatedEvent": {},
  "ResponseInProgressEvent": {},
  "_TOOL_NAME_TO_TYPE_MAP": [],
  "_map_tool_name_to_tool_type": [
    "tool_name"
  ],
  "TurnMetrics": {
    "__init__": [
      "self",
      "input_tokens",
      "output_tokens",
      "cached_input_tokens",
      "tool_output_tokens"
    ],
    "reset": [
      "self"
    ],
    "copy": [
      "self"
    ]
  },
  "ConversationContext": {
    "append_output": [
      "self",
      "output"
    ],
    "append_tool_output": [
      "self",
      "output"
    ],
    "call_tool": [
      "self"
    ],
    "need_builtin_tool_call": [
      "self"
    ],
    "render_for_completion": [
      "self"
    ],
    "init_tool_sessions": [
      "self",
      "tool_server",
      "exit_stack",
      "request_id",
      "mcp_tools"
    ],
    "cleanup_session": [
      "self"
    ]
  },
  "_create_json_parse_error_messages": [
    "last_msg",
    "e"
  ],
  "SimpleContext": {
    "__init__": [
      "self"
    ],
    "append_output": [
      "self",
      "output"
    ],
    "final_output": [
      "self"
    ],
    "append_tool_output": [
      "self",
      "output"
    ],
    "need_builtin_tool_call": [
      "self"
    ],
    "call_tool": [
      "self"
    ],
    "render_for_completion": [
      "self"
    ],
    "init_tool_sessions": [
      "self",
      "tool_server",
      "exit_stack",
      "request_id",
      "mcp_tools"
    ],
    "cleanup_session": [
      "self"
    ]
  },
  "ParsableContext": {
    "__init__": [
      "self"
    ],
    "append_output": [
      "self",
      "output"
    ],
    "append_tool_output": [
      "self",
      "output"
    ],
    "need_builtin_tool_call": [
      "self"
    ],
    "call_python_tool": [
      "self",
      "tool_session",
      "last_msg"
    ],
    "call_search_tool": [
      "self",
      "tool_session",
      "last_msg"
    ],
    "call_container_tool": [
      "self",
      "tool_session",
      "last_msg"
    ],
    "call_tool": [
      "self"
    ],
    "render_for_completion": [
      "self"
    ],
    "init_tool_sessions": [
      "self",
      "tool_server",
      "exit_stack",
      "request_id",
      "mcp_tools"
    ],
    "cleanup_session": [
      "self"
    ]
  },
  "HarmonyContext": {
    "__init__": [
      "self",
      "messages",
      "available_tools"
    ],
    "_update_num_reasoning_tokens": [
      "self"
    ],
    "append_output": [
      "self",
      "output"
    ],
    "append_tool_output": [
      "self",
      "output"
    ],
    "_update_prefill_token_usage": [
      "self",
      "output"
    ],
    "_update_decode_token_usage": [
      "self",
      "output"
    ],
    "messages": [
      "self"
    ],
    "need_builtin_tool_call": [
      "self"
    ],
    "call_tool": [
      "self"
    ],
    "render_for_completion": [
      "self"
    ],
    "call_search_tool": [
      "self",
      "tool_session",
      "last_msg"
    ],
    "call_python_tool": [
      "self",
      "tool_session",
      "last_msg"
    ],
    "init_tool_sessions": [
      "self",
      "tool_server",
      "exit_stack",
      "request_id",
      "mcp_tools"
    ],
    "call_container_tool": [
      "self",
      "tool_session",
      "last_msg"
    ],
    "cleanup_session": [
      "self"
    ]
  },
  "StreamingHarmonyContext": {
    "__init__": [
      "self"
    ],
    "messages": [
      "self"
    ],
    "append_output": [
      "self",
      "output"
    ],
    "append_tool_output": [
      "self",
      "output"
    ],
    "is_expecting_start": [
      "self"
    ],
    "is_assistant_action_turn": [
      "self"
    ],
    "render_for_completion": [
      "self"
    ]
  },
  "responses": [
    "request"
  ],
  "_convert_stream_to_sse_events": [
    "generator"
  ],
  "create_responses": [
    "request",
    "raw_request"
  ],
  "retrieve_responses": [
    "response_id",
    "raw_request",
    "starting_after",
    "stream"
  ],
  "cancel_responses": [
    "response_id",
    "raw_request"
  ],
  "TokenState": {},
  "extract_harmony_streaming_delta": [
    "harmony_parser",
    "token_states",
    "prev_recipient",
    "include_reasoning"
  ],
  "OpenAIServingChat": {
    "__init__": [
      "self",
      "engine_client",
      "models",
      "response_role"
    ],
    "warmup": [
      "self"
    ],
    "render_chat_request": [
      "self",
      "request"
    ],
    "create_chat_completion": [
      "self",
      "request",
      "raw_request"
    ],
    "get_chat_request_role": [
      "self",
      "request"
    ],
    "_bracket_level": [
      "s",
      "opening",
      "closing"
    ],
    "_filter_delta_text": [
      "delta_text",
      "previous_text"
    ],
    "extract_tool_call_required_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "function_name_returned",
      "tool_call_idx"
    ],
    "chat_completion_stream_generator": [
      "self",
      "request",
      "result_generator",
      "request_id",
      "model_name",
      "conversation",
      "tokenizer",
      "request_metadata"
    ],
    "chat_completion_full_generator": [
      "self",
      "request",
      "result_generator",
      "request_id",
      "model_name",
      "conversation",
      "tokenizer",
      "request_metadata"
    ],
    "_get_top_logprobs": [
      "self",
      "logprobs",
      "top_logprobs",
      "tokenizer",
      "should_return_as_token_id"
    ],
    "_create_chat_logprobs": [
      "self",
      "token_ids",
      "top_logprobs",
      "tokenizer",
      "num_output_top_logprobs",
      "return_as_token_id"
    ],
    "_should_stream_with_auto_tool_parsing": [
      "self",
      "request"
    ],
    "_should_check_for_unstreamed_tool_arg_tokens": [
      "self",
      "delta_message",
      "output"
    ],
    "_create_remaining_args_delta": [
      "delta_message",
      "remaining_call",
      "index"
    ],
    "_make_request_with_harmony": [
      "self",
      "request",
      "should_include_tools"
    ]
  },
  "_LONG_INFO": [],
  "ChatMessage": {
    "handle_deprecated_reasoning_content": [
      "self"
    ]
  },
  "ChatCompletionLogProb": {},
  "ChatCompletionLogProbsContent": {},
  "ChatCompletionLogProbs": {},
  "ChatCompletionResponseChoice": {},
  "ChatCompletionResponse": {},
  "ChatCompletionResponseStreamChoice": {},
  "ChatCompletionStreamResponse": {},
  "ChatCompletionToolsParam": {},
  "ChatCompletionNamedFunction": {},
  "ChatCompletionNamedToolChoiceParam": {},
  "ChatCompletionRequest": {
    "to_beam_search_params": [
      "self",
      "max_tokens",
      "default_sampling_params"
    ],
    "to_sampling_params": [
      "self",
      "max_tokens",
      "logits_processor_pattern",
      "default_sampling_params"
    ],
    "validate_stream_options": [
      "cls",
      "data"
    ],
    "check_logprobs": [
      "cls",
      "data"
    ],
    "check_structured_outputs_count": [
      "cls",
      "data"
    ],
    "check_tool_usage": [
      "cls",
      "data"
    ],
    "check_generation_prompt": [
      "cls",
      "data"
    ],
    "check_cache_salt_support": [
      "cls",
      "data"
    ]
  },
  "ENDPOINT_LOAD_METRICS_FORMAT_HEADER_LABEL": [],
  "create_chat_completion": [
    "request",
    "raw_request"
  ],
  "render_chat_completion": [
    "request",
    "raw_request"
  ],
  "REASONING_EFFORT": [],
  "_harmony_encoding": [],
  "has_custom_tools": [
    "tool_types"
  ],
  "get_encoding": [],
  "get_system_message": [
    "model_identity",
    "reasoning_effort",
    "start_date",
    "browser_description",
    "python_description",
    "container_description",
    "instructions",
    "with_custom_tools"
  ],
  "create_tool_definition": [
    "tool"
  ],
  "get_developer_message": [
    "instructions",
    "tools"
  ],
  "get_user_message": [
    "content"
  ],
  "parse_response_input": [
    "response_msg",
    "prev_responses"
  ],
  "parse_chat_inputs_to_harmony_messages": [
    "chat_msgs"
  ],
  "auto_drop_analysis_messages": [
    "msgs"
  ],
  "flatten_chat_text_content": [
    "content"
  ],
  "parse_chat_input_to_harmony_message": [
    "chat_msg",
    "tool_id_names"
  ],
  "parse_input_to_harmony_message": [
    "chat_msg"
  ],
  "construct_harmony_previous_input_messages": [
    "request"
  ],
  "render_for_completion": [
    "messages"
  ],
  "_parse_browser_tool_call": [
    "message",
    "recipient"
  ],
  "_parse_function_call": [
    "message",
    "recipient"
  ],
  "_parse_reasoning_content": [
    "message"
  ],
  "_parse_final_message": [
    "message"
  ],
  "_parse_mcp_recipient": [
    "recipient"
  ],
  "_parse_mcp_call": [
    "message",
    "recipient"
  ],
  "parse_output_message": [
    "message"
  ],
  "parse_remaining_state": [
    "parser"
  ],
  "get_stop_tokens_for_assistant_actions": [],
  "get_streamable_parser_for_assistant": [],
  "parse_output_into_messages": [
    "token_ids"
  ],
  "parse_chat_output": [
    "token_ids"
  ],
  "ResponsesParser": {
    "__init__": [
      "self"
    ],
    "process": [
      "self",
      "output"
    ],
    "make_response_output_items_from_parsable_context": [
      "self"
    ]
  },
  "get_responses_parser_for_simple_context": [],
  "GenerationError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "RequestT": [],
  "RequestProcessingMixin": {},
  "ResponseGenerationMixin": {
    "model_config": []
  },
  "ServeContext": {},
  "ClassificationServeContext": {},
  "EmbeddingServeContext": {},
  "OpenAIServing": {
    "__init__": [
      "self",
      "engine_client",
      "models"
    ],
    "_get_tool_parser": [
      "self",
      "tool_parser_name",
      "enable_auto_tools"
    ],
    "_get_reasoning_parser": [
      "self",
      "reasoning_parser_name"
    ],
    "reset_mm_cache": [
      "self"
    ],
    "beam_search": [
      "self",
      "prompt",
      "request_id",
      "params",
      "lora_request",
      "trace_headers"
    ],
    "_get_completion_renderer": [
      "self"
    ],
    "_build_render_config": [
      "self",
      "request"
    ],
    "_get_async_tokenizer": [
      "self",
      "tokenizer"
    ],
    "_preprocess": [
      "self",
      "ctx"
    ],
    "_build_response": [
      "self",
      "ctx"
    ],
    "handle": [
      "self",
      "ctx"
    ],
    "_pipeline": [
      "self",
      "ctx"
    ],
    "_validate_request": [
      "self",
      "ctx"
    ],
    "_create_pooling_params": [
      "self",
      "ctx"
    ],
    "_prepare_generators": [
      "self",
      "ctx"
    ],
    "_collect_batch": [
      "self",
      "ctx"
    ],
    "create_error_response": [
      "self",
      "message",
      "err_type",
      "status_code",
      "param"
    ],
    "create_streaming_error_response": [
      "self",
      "message",
      "err_type",
      "status_code",
      "param"
    ],
    "_raise_if_error": [
      "self",
      "finish_reason",
      "request_id"
    ],
    "_convert_generation_error_to_response": [
      "self",
      "e"
    ],
    "_convert_generation_error_to_streaming_response": [
      "self",
      "e"
    ],
    "_check_model": [
      "self",
      "request"
    ],
    "_get_active_default_mm_loras": [
      "self",
      "request"
    ],
    "_maybe_get_adapters": [
      "self",
      "request",
      "supports_default_mm_loras"
    ],
    "_get_message_types": [
      "self",
      "request"
    ],
    "_normalize_prompt_text_to_input": [
      "self",
      "request",
      "prompt",
      "tokenizer",
      "add_special_tokens"
    ],
    "_normalize_prompt_tokens_to_input": [
      "self",
      "request",
      "prompt_ids",
      "tokenizer"
    ],
    "_validate_input": [
      "self",
      "request",
      "input_ids",
      "input_text"
    ],
    "_tokenize_prompt_input_async": [
      "self",
      "request",
      "tokenizer",
      "prompt_input",
      "add_special_tokens"
    ],
    "_tokenize_prompt_inputs_async": [
      "self",
      "request",
      "tokenizer",
      "prompt_inputs",
      "add_special_tokens"
    ],
    "_validate_chat_template": [
      "self",
      "request_chat_template",
      "chat_template_kwargs",
      "trust_request_chat_template"
    ],
    "_prepare_extra_chat_template_kwargs": [
      "request_chat_template_kwargs",
      "default_chat_template_kwargs"
    ],
    "_preprocess_chat": [
      "self",
      "request",
      "renderer",
      "messages",
      "chat_template",
      "chat_template_content_format",
      "add_generation_prompt",
      "continue_final_message",
      "tool_dicts",
      "documents",
      "chat_template_kwargs",
      "default_chat_template_kwargs",
      "tool_parser",
      "add_special_tokens"
    ],
    "_process_inputs": [
      "self",
      "request_id",
      "engine_prompt",
      "params"
    ],
    "_render_next_turn": [
      "self",
      "request",
      "renderer",
      "messages",
      "tool_dicts",
      "tool_parser",
      "chat_template",
      "chat_template_content_format"
    ],
    "_generate_with_builtin_tools": [
      "self",
      "request_id",
      "engine_prompt",
      "sampling_params",
      "context",
      "lora_request",
      "priority"
    ],
    "_get_prompt_components": [
      "self",
      "prompt"
    ],
    "_log_inputs": [
      "self",
      "request_id",
      "inputs",
      "params",
      "lora_request"
    ],
    "_get_trace_headers": [
      "self",
      "headers"
    ],
    "_base_request_id": [
      "raw_request",
      "default"
    ],
    "_get_data_parallel_rank": [
      "raw_request"
    ],
    "_parse_tool_calls_from_content": [
      "request",
      "tokenizer",
      "enable_auto_tools",
      "tool_parser_cls",
      "content"
    ],
    "_get_decoded_token": [
      "logprob",
      "token_id",
      "tokenizer",
      "return_as_token_id"
    ],
    "_is_model_supported": [
      "self",
      "model_name"
    ]
  },
  "clamp_prompt_logprobs": [
    "prompt_logprobs"
  ],
  "OpenAIBaseModel": {
    "model_config": [],
    "__log_extra_fields__": [
      "cls",
      "data",
      "handler"
    ]
  },
  "ErrorInfo": {},
  "ErrorResponse": {},
  "ModelPermission": {},
  "ModelCard": {},
  "ModelList": {},
  "PromptTokenUsageInfo": {},
  "UsageInfo": {},
  "RequestResponseMetadata": {},
  "JsonSchemaResponseFormat": {},
  "LegacyStructuralTag": {},
  "LegacyStructuralTagResponseFormat": {},
  "StructuralTagResponseFormat": {},
  "ResponseFormat": {},
  "StreamOptions": {},
  "FunctionDefinition": {},
  "LogitsProcessorConstructor": {
    "model_config": []
  },
  "LogitsProcessors": [],
  "get_logits_processors": [
    "processors",
    "pattern"
  ],
  "FunctionCall": {},
  "ToolCall": {},
  "DeltaFunctionCall": {},
  "DeltaToolCall": {},
  "ExtractedToolCallInformation": {},
  "DeltaMessage": {
    "handle_deprecated_reasoning_content": [
      "self"
    ]
  },
  "GenerateRequest": {},
  "OpenAIServingCompletion": {
    "__init__": [
      "self",
      "engine_client",
      "models"
    ],
    "render_completion_request": [
      "self",
      "request"
    ],
    "create_completion": [
      "self",
      "request",
      "raw_request"
    ],
    "completion_stream_generator": [
      "self",
      "request",
      "engine_prompts",
      "result_generator",
      "request_id",
      "created_time",
      "model_name",
      "num_prompts",
      "tokenizer",
      "request_metadata"
    ],
    "request_output_to_completion_response": [
      "self",
      "final_res_batch",
      "request",
      "request_id",
      "created_time",
      "model_name",
      "tokenizer",
      "request_metadata"
    ],
    "_create_completion_logprobs": [
      "self",
      "token_ids",
      "top_logprobs",
      "num_output_top_logprobs",
      "tokenizer",
      "initial_text_offset",
      "return_as_token_id"
    ],
    "_build_render_config": [
      "self",
      "request",
      "max_input_length"
    ]
  },
  "CompletionRequest": {
    "to_beam_search_params": [
      "self",
      "max_tokens",
      "default_sampling_params"
    ],
    "to_sampling_params": [
      "self",
      "max_tokens",
      "logits_processor_pattern",
      "default_sampling_params"
    ],
    "check_structured_outputs_count": [
      "cls",
      "data"
    ],
    "check_logprobs": [
      "cls",
      "data"
    ],
    "validate_stream_options": [
      "cls",
      "data"
    ],
    "validate_prompt_and_prompt_embeds": [
      "cls",
      "data"
    ],
    "check_cache_salt_support": [
      "cls",
      "data"
    ]
  },
  "CompletionLogProbs": {},
  "CompletionResponseChoice": {},
  "CompletionResponse": {},
  "CompletionResponseStreamChoice": {},
  "CompletionStreamResponse": {},
  "completion": [
    "request"
  ],
  "create_completion": [
    "request",
    "raw_request"
  ],
  "render_completion": [
    "request",
    "raw_request"
  ],
  "OpenAIServingTranscription": {
    "__init__": [
      "self",
      "engine_client",
      "models"
    ],
    "create_transcription": [
      "self",
      "audio_data",
      "request",
      "raw_request"
    ],
    "transcription_stream_generator": [
      "self",
      "request",
      "result_generator",
      "request_id",
      "request_metadata",
      "audio_duration_s"
    ]
  },
  "OpenAIServingTranslation": {
    "__init__": [
      "self",
      "engine_client",
      "models"
    ],
    "create_translation": [
      "self",
      "audio_data",
      "request",
      "raw_request"
    ],
    "translation_stream_generator": [
      "self",
      "request",
      "result_generator",
      "request_id",
      "request_metadata",
      "audio_duration_s"
    ]
  },
  "TranscriptionResponseStreamChoice": {},
  "TranscriptionStreamResponse": {},
  "TranscriptionRequest": {
    "to_sampling_params": [
      "self",
      "default_max_tokens",
      "default_sampling_params"
    ],
    "validate_transcription_request": [
      "cls",
      "data"
    ]
  },
  "TranscriptionUsageAudio": {},
  "TranscriptionResponse": {},
  "TranscriptionWord": {},
  "TranscriptionSegment": {},
  "TranscriptionResponseVerbose": {},
  "TranslationResponseStreamChoice": {},
  "TranslationStreamResponse": {},
  "TranslationRequest": {
    "to_sampling_params": [
      "self",
      "default_max_tokens",
      "default_sampling_params"
    ],
    "validate_stream_options": [
      "cls",
      "data"
    ]
  },
  "TranslationResponse": {},
  "TranslationWord": {},
  "TranslationSegment": {},
  "TranslationResponseVerbose": {},
  "V": [],
  "S": [],
  "OpenAISpeechToText": {
    "__init__": [
      "self",
      "engine_client",
      "models"
    ],
    "_warmup_audio_preprocessing": [
      "self"
    ],
    "_warmup_input_processor": [
      "self"
    ],
    "model_cls": [
      "self"
    ],
    "_preprocess_speech_to_text": [
      "self",
      "request",
      "audio_data"
    ],
    "_get_verbose_segments": [
      "self",
      "tokens",
      "log_probs",
      "request",
      "segment_class",
      "start_time"
    ],
    "_create_speech_to_text": [
      "self",
      "audio_data",
      "request",
      "raw_request",
      "response_class",
      "stream_generator_method"
    ],
    "_speech_to_text_stream_generator": [
      "self",
      "request",
      "list_result_generator",
      "request_id",
      "request_metadata",
      "audio_duration_s",
      "chunk_object_type",
      "response_stream_choice_class",
      "stream_response_class"
    ],
    "_split_audio": [
      "self",
      "audio_data",
      "sample_rate"
    ],
    "_find_split_point": [
      "self",
      "wav",
      "start_idx",
      "end_idx"
    ]
  },
  "transcription": [
    "request"
  ],
  "translation": [
    "request"
  ],
  "create_transcriptions": [
    "raw_request",
    "request"
  ],
  "create_translations": [
    "request",
    "raw_request"
  ],
  "OpenAIServingModels": {
    "__init__": [
      "self",
      "engine_client",
      "base_model_paths"
    ],
    "init_static_loras": [
      "self"
    ],
    "is_base_model": [
      "self",
      "model_name"
    ],
    "model_name": [
      "self",
      "lora_request"
    ],
    "show_available_models": [
      "self"
    ],
    "load_lora_adapter": [
      "self",
      "request",
      "base_model_name"
    ],
    "unload_lora_adapter": [
      "self",
      "request"
    ],
    "_check_load_lora_adapter_request": [
      "self",
      "request"
    ],
    "_check_unload_lora_adapter_request": [
      "self",
      "request"
    ],
    "resolve_lora": [
      "self",
      "lora_name"
    ]
  },
  "create_error_response": [
    "message",
    "err_type",
    "status_code"
  ],
  "BaseModelPath": {},
  "LoRAModulePath": {},
  "models": [
    "request"
  ],
  "show_available_models": [
    "raw_request"
  ],
  "RequestType": [],
  "GetHandlerFn": [],
  "EndpointFn": [],
  "INVOCATION_VALIDATORS": [],
  "register_sagemaker_routes": [
    "router"
  ],
  "register_vllm_serve_api_routers": [
    "app"
  ],
  "sleep": [
    "raw_request"
  ],
  "wake_up": [
    "raw_request"
  ],
  "is_sleeping": [
    "raw_request"
  ],
  "pause_generation": [
    "raw_request",
    "wait_for_inflight_requests",
    "clear_cache"
  ],
  "resume_generation": [
    "raw_request"
  ],
  "is_paused": [
    "raw_request"
  ],
  "LoadLoRAAdapterRequest": {},
  "UnloadLoRAAdapterRequest": {},
  "reset_prefix_cache": [
    "raw_request",
    "reset_running_requests",
    "reset_external"
  ],
  "reset_mm_cache": [
    "raw_request"
  ],
  "collective_rpc": [
    "raw_request"
  ],
  "ServingTokens": {
    "__init__": [
      "self",
      "engine_client",
      "models"
    ],
    "serve_tokens": [
      "self",
      "request",
      "raw_request"
    ],
    "serve_tokens_full_generator": [
      "self",
      "request",
      "result_generator",
      "request_id",
      "model_name",
      "request_metadata"
    ],
    "_create_tokens_logprobs": [
      "self",
      "token_ids",
      "top_logprobs",
      "num_output_top_logprobs"
    ]
  },
  "GenerateResponseChoice": {},
  "GenerateResponse": {},
  "generate_tokens": [
    "request"
  ],
  "start_profile": [
    "raw_request"
  ],
  "stop_profile": [
    "raw_request"
  ],
  "scale_elastic_ep": [
    "raw_request"
  ],
  "is_scaling_elastic_ep": [
    "raw_request"
  ],
  "_scaling_elastic_ep": [],
  "get_scaling_elastic_ep": [],
  "set_scaling_elastic_ep": [
    "value"
  ],
  "ScalingMiddleware": {
    "__init__": [
      "self",
      "app"
    ],
    "__call__": [
      "self",
      "scope",
      "receive",
      "send"
    ]
  },
  "OpenAIServingTokenization": {
    "__init__": [
      "self",
      "engine_client",
      "models"
    ],
    "create_tokenize": [
      "self",
      "request",
      "raw_request"
    ],
    "create_detokenize": [
      "self",
      "request",
      "raw_request"
    ],
    "get_tokenizer_info": [
      "self"
    ],
    "_build_render_config": [
      "self",
      "request"
    ]
  },
  "TokenizerInfo": {
    "to_dict": [
      "self"
    ],
    "_get_tokenizer_config": [
      "self"
    ],
    "_make_json_serializable": [
      "self",
      "obj"
    ]
  },
  "TokenizeCompletionRequest": {},
  "TokenizeChatRequest": {
    "check_generation_prompt": [
      "cls",
      "data"
    ]
  },
  "TokenizeResponse": {},
  "DetokenizeRequest": {},
  "DetokenizeResponse": {},
  "TokenizerInfoResponse": {
    "model_config": []
  },
  "tokenize": [
    "request",
    "raw_request"
  ],
  "detokenize": [
    "request",
    "raw_request"
  ],
  "PrometheusResponse": {
    "media_type": []
  },
  "PydanticVllmConfig": [],
  "_get_vllm_env_vars": [],
  "show_server_info": [
    "raw_request",
    "config_format"
  ],
  "FUSED_QK_ROPE_OP": [],
  "P": [],
  "QkNormRopePattern": {
    "__init__": [
      "self",
      "head_dim",
      "num_heads",
      "num_kv_heads",
      "eps",
      "is_neox",
      "rope_flashinfer"
    ],
    "get_inputs": [
      "self"
    ],
    "wrap_trace_fn": [
      "trace_fn"
    ],
    "fx_view_to_reshape": [
      "gm"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "QKNormRoPEFusionPass": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "graph"
    ],
    "uuid": [
      "self"
    ]
  },
  "_pass_context": [],
  "R": [],
  "PassContext": {
    "__init__": [
      "self",
      "compile_range"
    ]
  },
  "get_pass_context": [],
  "pass_context": [
    "compile_range"
  ],
  "InductorPass": {
    "uuid": [
      "self"
    ],
    "hash_source": [],
    "hash_dict": [
      "dict_"
    ],
    "is_applicable_for_range": [
      "self",
      "compile_range"
    ]
  },
  "CallableInductorPass": {
    "__init__": [
      "self",
      "callable",
      "uuid"
    ],
    "__call__": [
      "self",
      "graph"
    ],
    "uuid": [
      "self"
    ]
  },
  "enable_fake_mode": [
    "fn"
  ],
  "FP8_DTYPE": [],
  "BasePattern": {
    "__init__": [
      "self",
      "dtype",
      "device"
    ]
  },
  "GEMMReduceScatterPattern": {
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "AllGatherGEMMPattern": {
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "ScaledMMReduceScatterPattern": {
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "AllGatherScaledMMPattern": {
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "CutlassScaledMMReduceScatterPattern": {
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "AllGatherCutlassScaledMMPattern": {
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "AsyncTPPass": {
    "__init__": [
      "self",
      "config"
    ],
    "is_applicable_for_range": [
      "self",
      "compile_range"
    ],
    "__call__": [
      "self",
      "graph"
    ]
  },
  "FlashInferFusedAllReduceParams": {
    "__init__": [
      "self",
      "rank",
      "world_size",
      "use_fp32_lamport",
      "max_token_num"
    ],
    "get_trtllm_fused_allreduce_kwargs": [
      "self"
    ]
  },
  "AllReduceRMSNormPattern": {
    "__init__": [
      "self",
      "epsilon",
      "dtype",
      "device",
      "allreduce_params"
    ],
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "AllReduceFusedAddRMSNormPattern": {
    "__init__": [
      "self",
      "epsilon",
      "dtype",
      "device",
      "allreduce_params"
    ],
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "AllReduceFusedRMSNormStaticQuantFP8Pattern": {
    "__init__": [
      "self",
      "epsilon",
      "dtype",
      "device",
      "allreduce_params"
    ],
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "AllReduceFusedAddRMSNormStaticQuantFP8Pattern": {
    "__init__": [
      "self",
      "epsilon",
      "dtype",
      "device",
      "allreduce_params"
    ],
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "AllReduceFusedRMSNormStaticQuantNVFP4Pattern": {
    "__init__": [
      "self",
      "epsilon",
      "dtype",
      "device",
      "allreduce_params"
    ],
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "AllReduceFusedAddRMSNormStaticQuantNVFP4Pattern": {
    "__init__": [
      "self",
      "epsilon",
      "dtype",
      "device",
      "allreduce_params"
    ],
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "AllReduceFusionPass": {
    "__init__": [
      "self",
      "config"
    ],
    "register_patterns": [
      "self"
    ],
    "is_applicable_for_range": [
      "self",
      "compile_range"
    ],
    "__call__": [
      "self",
      "graph"
    ],
    "__del__": [
      "self"
    ]
  },
  "AiterRMSNormQuantPattern": {
    "__init__": [
      "self",
      "epsilon",
      "key",
      "match_aiter_quant"
    ]
  },
  "AiterRMSNormDynamicQuantPattern": {
    "FUSED_OP": [],
    "__init__": [
      "self",
      "epsilon",
      "quant_dtype",
      "match_aiter_quant",
      "group_shape",
      "symmetric"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "AiterFusedAddRMSNormDynamicQuantPattern": {
    "FUSED_OP": [],
    "__init__": [
      "self",
      "epsilon",
      "quant_dtype",
      "match_aiter_quant",
      "group_shape",
      "symmetric"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "AiterRMSFp8GroupQuantPattern": {
    "FUSED_OP": [],
    "__init__": [
      "self",
      "epsilon",
      "quant_dtype",
      "group_shape",
      "match_aiter_quant",
      "symmetric"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "AiterFusedAddRMSFp8GroupQuantPattern": {
    "FUSED_OP": [],
    "__init__": [
      "self",
      "epsilon",
      "quant_dtype",
      "group_shape",
      "match_aiter_quant",
      "symmetric"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "RocmAiterRMSNormFusionPass": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "graph"
    ],
    "uuid": [
      "self"
    ]
  },
  "AiterSiluMulFp8GroupQuantPattern": {
    "FUSED_SILU_MUL_QUANT_OP": [],
    "__init__": [
      "self",
      "quant_op"
    ],
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "RocmAiterSiluMulFp8GroupQuantFusionPass": {
    "AITER_GROUP_FP8_QUANT_OP": [],
    "TRITON_GROUP_FP8_QUANT_OP": [],
    "QUANT_OPS": [],
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "graph"
    ],
    "uuid": [
      "self"
    ]
  },
  "context_manager": [],
  "start_monitoring_torch_compile": [
    "vllm_config"
  ],
  "end_monitoring_torch_compile": [
    "vllm_config"
  ],
  "validate_cudagraph_capturing_enabled": [],
  "set_cudagraph_capturing_enabled": [
    "enabled"
  ],
  "Torch25CustomGraphPass": {
    "__call__": [
      "self",
      "graph"
    ],
    "uuid": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "FixFunctionalizationPass": {
    "__call__": [
      "self",
      "graph"
    ],
    "_remove": [
      "self",
      "node_or_nodes"
    ],
    "defunctionalize": [
      "self",
      "graph",
      "node",
      "mutated_args",
      "args"
    ],
    "replace_users_with_mutated_args": [
      "self",
      "node",
      "mutated_args"
    ],
    "getitem_users": [
      "self",
      "node"
    ],
    "insert_defunctionalized": [
      "self",
      "graph",
      "node",
      "args"
    ]
  },
  "FP4_DTYPE": [],
  "SILU_MUL_OP": [],
  "silu_and_mul_nvfp4_quant_supported": [],
  "ActivationQuantPattern": {
    "__init__": [
      "self",
      "quant_key"
    ],
    "empty_quant": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "SiluMulFp8StaticQuantPattern": {
    "__init__": [
      "self"
    ],
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "SiluMulNvfp4QuantPattern": {
    "__init__": [
      "self"
    ],
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "ActivationQuantFusionPass": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "graph"
    ],
    "uuid": [
      "self"
    ]
  },
  "RMS_OP": [],
  "RMS_ADD_OP": [],
  "ROTARY_OP": [],
  "FLASHINFER_ROTARY_OP": [],
  "MatcherCustomOp": {
    "__init__": [
      "self",
      "enabled"
    ],
    "forward_custom": [
      "self"
    ],
    "forward_native": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "empty": [
      "self"
    ],
    "empty_int64": [
      "self"
    ],
    "empty_f32": [
      "self"
    ],
    "inputs": [
      "self"
    ]
  },
  "MatcherRotaryEmbedding": {
    "__init__": [
      "self",
      "is_neox",
      "head_size",
      "num_heads",
      "num_kv_heads",
      "use_flashinfer",
      "enabled"
    ],
    "inputs": [
      "self"
    ],
    "forward_custom": [
      "self",
      "positions",
      "query",
      "key",
      "cos_sin_cache"
    ],
    "forward_native": [
      "self",
      "positions",
      "query",
      "key",
      "cos_sin_cache"
    ]
  },
  "MatcherRMSNorm": {
    "__init__": [
      "self",
      "epsilon",
      "enabled",
      "match_rocm_aiter"
    ],
    "inputs": [
      "self"
    ],
    "forward_rocm_aiter": [
      "self",
      "input",
      "weight"
    ],
    "forward_custom": [
      "self",
      "input",
      "weight"
    ],
    "forward_native": [
      "self",
      "input",
      "weight"
    ]
  },
  "MatcherFusedAddRMSNorm": {
    "__init__": [
      "self",
      "epsilon",
      "enabled",
      "match_rocm_aiter"
    ],
    "inputs": [
      "self"
    ],
    "forward_rocm_aiter": [
      "self",
      "input",
      "weight",
      "residual"
    ],
    "forward_custom": [
      "self",
      "input",
      "weight",
      "residual"
    ],
    "forward_native": [
      "self",
      "input",
      "weight",
      "residual"
    ]
  },
  "MatcherQuantFP8": {
    "__init__": [
      "self",
      "quant_key",
      "enabled",
      "has_col_major_scales",
      "is_e8m0",
      "match_rocm_aiter"
    ],
    "forward_rocm_aiter": [
      "self",
      "input",
      "scale"
    ],
    "forward_custom": [
      "self",
      "input",
      "scale"
    ],
    "forward_native": [
      "self",
      "input",
      "scale"
    ],
    "make_scale": [
      "self",
      "input",
      "transposed"
    ],
    "inputs": [
      "self"
    ]
  },
  "MatcherSiluAndMul": {
    "__init__": [
      "self",
      "enabled"
    ],
    "inputs": [
      "self"
    ],
    "forward_custom": [
      "self",
      "x"
    ],
    "forward_native": [
      "self",
      "x"
    ]
  },
  "with_pattern_match_debug": [
    "fn"
  ],
  "PostGradPassManager": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "graph"
    ],
    "configure": [
      "self",
      "config"
    ],
    "add": [
      "self",
      "pass_"
    ],
    "uuid": [
      "self"
    ]
  },
  "CUDAGraphStat": {},
  "CUDAGraphLogging": {
    "COLUMN_HEADERS": [],
    "__init__": [
      "self",
      "cg_mode",
      "cg_capture_sizes"
    ],
    "reset": [
      "self"
    ],
    "observe": [
      "self",
      "cudagraph_stat"
    ],
    "generate_metric_table": [
      "self"
    ],
    "log": [
      "self",
      "log_fn"
    ]
  },
  "CUDAGraphEntry": {},
  "CUDAGraphOptions": {},
  "CUDAGraphWrapper": {
    "__init__": [
      "self",
      "runnable",
      "vllm_config",
      "runtime_mode",
      "cudagraph_options"
    ],
    "__getattr__": [
      "self",
      "key"
    ],
    "unwrap": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "StandaloneCompiledArtifacts": {
    "__init__": [
      "self"
    ],
    "insert": [
      "self",
      "submod_name",
      "shape",
      "entry"
    ],
    "get": [
      "self",
      "submod_name",
      "shape"
    ],
    "get_loaded": [
      "self",
      "submod_name",
      "shape"
    ],
    "size_bytes": [
      "self"
    ],
    "num_artifacts": [
      "self"
    ],
    "num_entries": [
      "self"
    ],
    "submodule_names": [
      "self"
    ],
    "load_all": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ]
  },
  "VllmSerializableFunction": {
    "__init__": [
      "self",
      "graph_module",
      "example_inputs",
      "prefix",
      "optimized_call",
      "is_encoder",
      "vllm_backend",
      "sym_tensor_indices"
    ],
    "__call__": [
      "self"
    ],
    "serialize_compile_artifacts": [
      "cls",
      "compiled_fn"
    ],
    "deserialize_compile_artifacts": [
      "cls",
      "data"
    ],
    "co_name": [
      "self"
    ]
  },
  "reconstruct_serializable_fn_from_mega_artifact": [
    "state",
    "standalone_compile_artifacts",
    "vllm_config",
    "sym_shape_indices_map",
    "returns_tuple_map"
  ],
  "aot_compile_hash_factors": [
    "vllm_config"
  ],
  "_compute_code_hash_with_content": [
    "file_contents"
  ],
  "_compute_code_hash": [
    "files"
  ],
  "make_copy_and_call": [
    "sym_tensor_indices",
    "input_buffers",
    "callable_fn"
  ],
  "make_compiler": [
    "compilation_config"
  ],
  "CompilerManager": {
    "__init__": [
      "self",
      "compilation_config"
    ],
    "compute_hash": [
      "self",
      "vllm_config"
    ],
    "compile_context": [
      "self",
      "compile_range"
    ],
    "initialize_cache": [
      "self",
      "cache_dir",
      "disable_cache",
      "prefix"
    ],
    "save_to_file": [
      "self"
    ],
    "load": [
      "self",
      "graph",
      "example_inputs",
      "graph_index",
      "compile_range"
    ],
    "compile": [
      "self",
      "graph",
      "example_inputs",
      "additional_inductor_config",
      "compilation_config",
      "compile_range",
      "graph_index",
      "num_graphs"
    ]
  },
  "SplitItem": {},
  "split_graph": [
    "graph",
    "splitting_ops"
  ],
  "compilation_start_time": [],
  "wrap_with_cudagraph_if_needed": [
    "piecewise_backend",
    "vllm_config",
    "compilation_config",
    "is_first_graph",
    "is_last_graph"
  ],
  "PiecewiseCompileInterpreter": {
    "__init__": [
      "self",
      "module",
      "compile_submod_names",
      "vllm_config",
      "vllm_backend"
    ],
    "run": [
      "self"
    ],
    "call_module": [
      "self",
      "target",
      "args",
      "kwargs"
    ]
  },
  "set_on_compilation_complete": [
    "callback"
  ],
  "set_model_tag": [
    "tag",
    "is_encoder"
  ],
  "VllmBackend": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix",
      "is_encoder"
    ],
    "collect_standalone_compile_artifacts": [
      "self"
    ],
    "configure_post_pass": [
      "self"
    ],
    "__call__": [
      "self",
      "graph",
      "example_inputs"
    ]
  },
  "CompilerInterface": {
    "initialize_cache": [
      "self",
      "cache_dir",
      "disable_cache",
      "prefix"
    ],
    "compute_hash": [
      "self",
      "vllm_config"
    ],
    "compile": [
      "self",
      "graph",
      "example_inputs",
      "compiler_config",
      "compile_range",
      "key"
    ],
    "load": [
      "self",
      "handle",
      "graph",
      "example_inputs",
      "graph_index",
      "compile_range"
    ]
  },
  "AlwaysHitShapeEnv": {
    "__init__": [
      "self"
    ],
    "evaluate_guards_expression": [
      "self"
    ],
    "get_pruned_guards": [
      "self"
    ],
    "produce_guards_expression": [
      "self"
    ]
  },
  "get_inductor_factors": [],
  "is_compile_cache_enabled": [
    "vllm_additional_inductor_config"
  ],
  "InductorStandaloneAdaptor": {
    "name": [],
    "__init__": [
      "self",
      "save_format"
    ],
    "compute_hash": [
      "self",
      "vllm_config"
    ],
    "initialize_cache": [
      "self",
      "cache_dir",
      "disable_cache",
      "prefix"
    ],
    "compile": [
      "self",
      "graph",
      "example_inputs",
      "compiler_config",
      "compile_range",
      "key"
    ],
    "load": [
      "self",
      "handle",
      "graph",
      "example_inputs",
      "graph_index",
      "compile_range"
    ]
  },
  "InductorAdaptor": {
    "name": [],
    "compute_hash": [
      "self",
      "vllm_config"
    ],
    "initialize_cache": [
      "self",
      "cache_dir",
      "disable_cache",
      "prefix"
    ],
    "compile": [
      "self",
      "graph",
      "example_inputs",
      "compiler_config",
      "compile_range",
      "key"
    ],
    "load": [
      "self",
      "handle",
      "graph",
      "example_inputs",
      "graph_index",
      "compile_range"
    ],
    "metrics_context": [
      "self"
    ]
  },
  "set_inductor_config": [
    "config",
    "compile_range"
  ],
  "set_functorch_config": [],
  "EagerAdaptor": {
    "name": [],
    "compile": [
      "self",
      "graph",
      "example_inputs",
      "compiler_config",
      "compile_range",
      "key"
    ]
  },
  "is_func": [
    "node",
    "target"
  ],
  "is_auto_func": [
    "node",
    "op"
  ],
  "find_specified_fn_maybe": [
    "nodes",
    "op"
  ],
  "find_specified_fn": [
    "nodes",
    "op"
  ],
  "find_auto_fn_maybe": [
    "nodes",
    "op"
  ],
  "find_auto_fn": [
    "nodes",
    "op"
  ],
  "find_getitem_maybe": [
    "node",
    "idx"
  ],
  "find_getitem": [
    "node",
    "idx"
  ],
  "find_op_nodes": [
    "op",
    "graph"
  ],
  "get_only_user": [
    "node"
  ],
  "CompilationCounter": {
    "clone": [
      "self"
    ],
    "expect": [
      "self"
    ]
  },
  "compilation_counter": [],
  "_noop_add_global_state_guard": [
    "self"
  ],
  "_noop_add_torch_function_mode_stack_guard": [
    "self"
  ],
  "_compilation_context": [],
  "TorchCompileWithNoGuardsWrapper": {
    "check_invariants_and_forward": [
      "self"
    ],
    "_call_with_optional_nvtx_range": [
      "self",
      "callable_fn"
    ],
    "__init__": [
      "self"
    ],
    "aot_compile": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "original_code_object": [
      "self"
    ],
    "bytecode_hook": [
      "self",
      "old_code",
      "new_code"
    ],
    "_dispatch_to_compiled_code": [
      "self"
    ]
  },
  "get_first_out_wrapper": [
    "fn"
  ],
  "_SequenceParallelPatternHelper": {
    "__init__": [
      "self",
      "epsilon",
      "dtype",
      "device"
    ],
    "_all_reduce": [
      "self",
      "x"
    ],
    "_reduce_scatter": [
      "self",
      "x"
    ],
    "_all_gather": [
      "self",
      "x"
    ]
  },
  "FirstAllReduceRMSNormPattern": {
    "__init__": [
      "self",
      "epsilon",
      "dtype",
      "device"
    ],
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "MiddleAllReduceRMSNormPattern": {
    "__init__": [
      "self",
      "epsilon",
      "dtype",
      "device"
    ],
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "FirstAllReduceRMSNormStaticFP8Pattern": {
    "__init__": [
      "self",
      "epsilon",
      "dtype",
      "device"
    ],
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "MiddleAllReduceRMSNormStaticFP8Pattern": {
    "__init__": [
      "self",
      "epsilon",
      "dtype",
      "device"
    ],
    "get_inputs": [
      "self"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "SequenceParallelismPass": {
    "__init__": [
      "self",
      "config"
    ],
    "is_applicable_for_range": [
      "self",
      "compile_range"
    ],
    "__call__": [
      "self",
      "graph"
    ]
  },
  "should_split": [
    "node",
    "splitting_ops"
  ],
  "inductor_partition_rule_context": [
    "splitting_ops"
  ],
  "ATTN_OP": [],
  "RESHAPE_OP": [],
  "AttentionQuantPattern": {
    "__init__": [
      "self",
      "layer",
      "quant_key",
      "dtype"
    ],
    "empty": [
      "self"
    ],
    "empty_quant": [
      "self"
    ],
    "wrap_trace_fn": [
      "trace_fn"
    ],
    "fx_view_to_reshape": [
      "gm"
    ],
    "remove_noop_permutes": [
      "gm"
    ],
    "register_if_supported": [
      "self",
      "pm_pass"
    ],
    "_register": [
      "self",
      "pm_pass"
    ]
  },
  "AttentionFp8StaticQuantPattern": {
    "__init__": [
      "self",
      "layer",
      "dtype",
      "symmetric"
    ],
    "_register": [
      "self",
      "pm_pass"
    ]
  },
  "AttentionNvfp4QuantPattern": {
    "__init__": [
      "self",
      "layer",
      "dtype"
    ],
    "_register": [
      "self",
      "pm_pass"
    ]
  },
  "AttnFusionPass": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "graph"
    ],
    "uuid": [
      "self"
    ]
  },
  "IGNORE_COMPILE_KEY": [],
  "ignore_torch_compile": [
    "cls"
  ],
  "_should_ignore_torch_compile": [
    "cls"
  ],
  "support_torch_compile": [
    "cls"
  ],
  "_model_hash_key": [
    "fn"
  ],
  "_verify_source_unchanged": [
    "source_info",
    "vllm_config"
  ],
  "_support_torch_compile": [
    "cls",
    "dynamic_arg_dims",
    "mark_unbacked_dims",
    "enable_if",
    "shape_invariants"
  ],
  "maybe_use_cudagraph_partition_wrapper": [
    "vllm_config"
  ],
  "_torch27_patch_tensor_subclasses": [],
  "AbstractStaticGraphWrapper": {
    "__init__": [
      "self",
      "runnable",
      "vllm_config",
      "runtime_mode"
    ],
    "__call__": [
      "self"
    ]
  },
  "PostCleanupPass": {
    "__call__": [
      "self",
      "graph"
    ]
  },
  "NoOpEliminationPass": {
    "__call__": [
      "self",
      "graph"
    ],
    "dims_equivalent": [
      "self",
      "dim",
      "i_dim"
    ],
    "all_dims_equivalent": [
      "self",
      "dims",
      "i_dims"
    ]
  },
  "RangeEntry": {},
  "PiecewiseBackend": {
    "__init__": [
      "self",
      "graph",
      "vllm_config",
      "piecewise_compile_index",
      "total_piecewise_compiles",
      "sym_shape_indices",
      "vllm_backend",
      "returns_tuple",
      "compiled_runnables"
    ],
    "get_compiled_graph_wrapper": [
      "self",
      "compiled_graph"
    ],
    "check_for_ending_compilation": [
      "self"
    ],
    "to_bytes": [
      "self"
    ],
    "_fakify_args": [
      "self",
      "args"
    ],
    "_maybe_compile_for_range_entry": [
      "self",
      "range_entry",
      "args"
    ],
    "_find_range_for_shape": [
      "self",
      "runtime_shape"
    ],
    "__call__": [
      "self"
    ]
  },
  "InductorCompilationConfig": {},
  "VllmInductorPass": {
    "__init__": [
      "self",
      "config"
    ],
    "time_and_log": [
      "call_fn"
    ],
    "dump_graph": [
      "self",
      "graph",
      "stage"
    ],
    "begin": [
      "self"
    ],
    "end_and_log": [
      "self"
    ]
  },
  "VllmPatternMatcherPass": {
    "_replace_op_overloads": [
      "self",
      "string"
    ],
    "dump_patterns": [
      "self",
      "config",
      "pm_pass"
    ]
  },
  "PrinterInductorPass": {
    "__init__": [
      "self",
      "name",
      "config"
    ],
    "__call__": [
      "self",
      "graph"
    ]
  },
  "empty_bf16": [],
  "empty_fp32": [],
  "empty_i32": [],
  "empty_i64": [],
  "FusedRMSQuantKey": {
    "__str__": [
      "self"
    ]
  },
  "RMSNormQuantPattern": {
    "__init__": [
      "self",
      "epsilon",
      "key",
      "has_col_major_scales",
      "is_e8m0"
    ]
  },
  "RMSNormStaticQuantPattern": {
    "__init__": [
      "self",
      "epsilon",
      "quant_dtype",
      "symmetric"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "FusedAddRMSNormStaticQuantPattern": {
    "__init__": [
      "self",
      "epsilon",
      "quant_dtype",
      "symmetric"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "FusedAddRMSNormGroupQuantPattern": {
    "__init__": [
      "self",
      "epsilon",
      "quant_dtype",
      "group_shape",
      "symmetric",
      "has_col_major_scales",
      "is_e8m0"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "RMSNormGroupQuantPattern": {
    "__init__": [
      "self",
      "epsilon",
      "quant_dtype",
      "group_shape",
      "symmetric",
      "has_col_major_scales",
      "is_e8m0"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "RMSNormDynamicQuantPattern": {
    "__init__": [
      "self",
      "epsilon",
      "quant_dtype",
      "group_shape",
      "symmetric"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "FusedAddRMSNormDynamicQuantPattern": {
    "__init__": [
      "self",
      "epsilon",
      "quant_dtype",
      "group_shape",
      "symmetric"
    ],
    "register": [
      "self",
      "pm_pass"
    ]
  },
  "RMSNormQuantFusionPass": {
    "__init__": [
      "self",
      "config"
    ],
    "__call__": [
      "self",
      "graph"
    ],
    "uuid": [
      "self"
    ]
  },
  "HAS_TRITON": [],
  "TritonPlaceholder": {
    "__init__": [
      "self"
    ],
    "_dummy_decorator": [
      "self",
      "name"
    ]
  },
  "TritonLanguagePlaceholder": {
    "__init__": [
      "self"
    ]
  },
  "BasevLLMParameter": {
    "__new__": [
      "cls",
      "data"
    ],
    "__init__": [
      "self",
      "data",
      "weight_loader"
    ],
    "weight_loader": [
      "self"
    ],
    "_is_1d_and_scalar": [
      "self",
      "loaded_weight"
    ],
    "_assert_and_load": [
      "self",
      "loaded_weight"
    ],
    "load_column_parallel_weight": [
      "self",
      "loaded_weight"
    ],
    "load_row_parallel_weight": [
      "self",
      "loaded_weight"
    ],
    "load_merged_column_weight": [
      "self",
      "loaded_weight"
    ],
    "load_qkv_weight": [
      "self",
      "loaded_weight"
    ],
    "_shard_id_as_int": [
      "self",
      "shard_id"
    ],
    "__torch_function__": [
      "cls",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "_ColumnvLLMParameter": {
    "__init__": [
      "self",
      "output_dim"
    ],
    "output_dim": [
      "self"
    ],
    "load_column_parallel_weight": [
      "self",
      "loaded_weight"
    ],
    "load_merged_column_weight": [
      "self",
      "loaded_weight"
    ],
    "load_qkv_weight": [
      "self",
      "loaded_weight"
    ]
  },
  "RowvLLMParameter": {
    "__init__": [
      "self",
      "input_dim"
    ],
    "input_dim": [
      "self"
    ],
    "load_row_parallel_weight": [
      "self",
      "loaded_weight"
    ]
  },
  "ModelWeightParameter": {},
  "GroupQuantScaleParameter": {},
  "ChannelQuantScaleParameter": {},
  "PerTensorScaleParameter": {
    "__init__": [
      "self"
    ],
    "load_row_parallel_weight": [
      "self"
    ],
    "load_merged_column_weight": [
      "self"
    ],
    "load_qkv_weight": [
      "self"
    ],
    "load_column_parallel_weight": [
      "self"
    ],
    "_load_into_shard_id": [
      "self",
      "loaded_weight",
      "shard_id"
    ]
  },
  "PackedColumnParameter": {
    "__init__": [
      "self",
      "packed_factor",
      "packed_dim",
      "marlin_tile_size",
      "bitblas_tile_size"
    ],
    "packed_dim": [
      "self"
    ],
    "packed_factor": [
      "self"
    ],
    "marlin_tile_size": [
      "self"
    ],
    "bitblas_tile_size": [
      "self"
    ],
    "adjust_shard_indexes_for_packing": [
      "self",
      "shard_size",
      "shard_offset"
    ]
  },
  "PackedvLLMParameter": {
    "__init__": [
      "self",
      "packed_factor",
      "packed_dim",
      "marlin_tile_size",
      "bitblas_tile_size"
    ],
    "packed_dim": [
      "self"
    ],
    "packed_factor": [
      "self"
    ],
    "marlin_tile_size": [
      "self"
    ],
    "bitblas_tile_size": [
      "self"
    ],
    "adjust_shard_indexes_for_packing": [
      "self",
      "shard_size",
      "shard_offset"
    ]
  },
  "BlockQuantScaleParameter": {},
  "SharedWeightParameter": {
    "__new__": [
      "cls"
    ],
    "__init__": [
      "self",
      "input_dim",
      "output_dim"
    ],
    "add_partition": [
      "self",
      "index",
      "data_key"
    ],
    "load_column_parallel_weight": [
      "self",
      "loaded_weight"
    ],
    "load_row_parallel_weight": [
      "self",
      "loaded_weight"
    ],
    "load_merged_column_weight": [
      "self",
      "loaded_weight"
    ],
    "load_qkv_weight": [
      "self",
      "loaded_weight"
    ],
    "process_weights_after_loading": [
      "self"
    ],
    "data": [
      "self"
    ],
    "_fake_weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "loaded_weight_shard_id"
    ]
  },
  "permute_param_layout_": [
    "param",
    "input_dim",
    "output_dim"
  ],
  "_adjust_shard_indexes_for_marlin": [
    "shard_size",
    "shard_offset",
    "marlin_tile_size"
  ],
  "_adjust_shard_indexes_for_bitblas": [
    "shard_size",
    "shard_offset",
    "bitblas_tile_size"
  ],
  "_adjust_shard_indexes_for_packing": [
    "shard_size",
    "shard_offset",
    "packed_factor",
    "marlin_tile_size",
    "bitblas_tile_size"
  ],
  "set_weight_attrs": [
    "weight",
    "weight_attrs"
  ],
  "replace_parameter": [
    "layer",
    "param_name",
    "new_data"
  ],
  "get_packed_modules_mapping": [
    "model"
  ],
  "get_moe_expert_mapping": [
    "model"
  ],
  "maybe_disable_graph_partition": [
    "current_backend"
  ],
  "PluggableLayer": {
    "__new__": [
      "cls"
    ],
    "register": [
      "cls",
      "name"
    ],
    "register_oot": [
      "cls",
      "_decorated_layer_cls",
      "name"
    ]
  },
  "CustomOp": {
    "__new__": [
      "cls"
    ],
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "forward_native": [
      "self"
    ],
    "forward_cuda": [
      "self"
    ],
    "forward_hip": [
      "self"
    ],
    "forward_xpu": [
      "self"
    ],
    "forward_cpu": [
      "self"
    ],
    "forward_tpu": [
      "self"
    ],
    "forward_oot": [
      "self"
    ],
    "dispatch_forward": [
      "self",
      "compile_native"
    ],
    "maybe_compile": [
      "self",
      "fn"
    ],
    "enabled": [
      "cls"
    ],
    "default_on": [],
    "register": [
      "cls",
      "name"
    ],
    "register_oot": [
      "cls",
      "_decorated_op_cls",
      "name"
    ]
  },
  "_generate_optimal_warmup_m_values": [
    "max_tokens",
    "n",
    "device"
  ],
  "_extract_data_from_linear_base_module": [
    "m"
  ],
  "_extract_data_from_fused_moe_module": [
    "m"
  ],
  "_fp8_linear_may_use_deep_gemm": [
    "module"
  ],
  "_fused_moe_grouped_gemm_may_use_deep_gemm": [
    "module"
  ],
  "_get_fp8_gemm_nt_m_values": [
    "w",
    "max_tokens"
  ],
  "_deepgemm_fp8_gemm_nt_warmup": [
    "w",
    "ws",
    "max_tokens",
    "pbar"
  ],
  "_get_grouped_gemm_params": [
    "w1",
    "w2",
    "num_topk",
    "max_tokens"
  ],
  "_deepgemm_grouped_fp8_gemm_nt_contiguous_warmup": [
    "w1",
    "w2",
    "w1_scale",
    "w2_scale",
    "num_topk",
    "max_tokens",
    "pbar"
  ],
  "deepgemm_fp8_gemm_nt_warmup": [
    "model",
    "max_tokens",
    "pbar"
  ],
  "deepgemm_grouped_fp8_gemm_nt_contiguous_warmup": [
    "model",
    "max_tokens",
    "pbar"
  ],
  "_count_warmup_iterations": [
    "model",
    "max_tokens"
  ],
  "deep_gemm_warmup": [
    "model",
    "max_tokens"
  ],
  "kernel_warmup": [
    "worker"
  ],
  "flashinfer_autotune": [
    "runner"
  ],
  "DefaultModelLoader": {
    "DEFAULT_NUM_THREADS": [],
    "__init__": [
      "self",
      "load_config"
    ],
    "_prepare_weights": [
      "self",
      "model_name_or_path",
      "revision",
      "fall_back_to_pt",
      "allow_patterns_overrides"
    ],
    "_get_weights_iterator": [
      "self",
      "source"
    ],
    "get_all_weights": [
      "self",
      "model_config",
      "model"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "load_weights": [
      "self",
      "model",
      "model_config"
    ]
  },
  "is_valid_deserialization_uri": [
    "uri"
  ],
  "tensorizer_kwargs_arg": [
    "value"
  ],
  "MetaTensorMode": {
    "__torch_dispatch__": [
      "self",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "meta_tensor_mode": [
    "loading_code"
  ],
  "_NoInitOrTensorImpl": {
    "_MODULES": [],
    "_MODULE_ORIGINALS": [],
    "is_active": [],
    "_count_active_lock": [],
    "context_manager": [
      "cls"
    ],
    "_disable": [
      "func"
    ]
  },
  "TensorizerConfig": {
    "__post_init__": [
      "self"
    ],
    "to_serializable": [
      "self"
    ],
    "_construct_tensorizer_args": [
      "self"
    ],
    "verify_with_parallel_config": [
      "self",
      "parallel_config"
    ],
    "verify_with_model_config": [
      "self",
      "model_config"
    ],
    "open_stream": [
      "self",
      "tensorizer_args"
    ],
    "keys": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "__delitem__": []
  },
  "TensorizerArgs": {
    "__init__": [
      "self",
      "tensorizer_config"
    ],
    "add_cli_args": [
      "parser"
    ],
    "from_cli_args": [
      "cls",
      "args"
    ]
  },
  "_check_tensors_on_meta_device": [
    "model"
  ],
  "_resize_lora_embeddings": [
    "model"
  ],
  "init_tensorizer_model": [
    "tensorizer_config",
    "vllm_config"
  ],
  "deserialize_tensorizer_model": [
    "model",
    "tensorizer_config"
  ],
  "tensorizer_weights_iterator": [
    "tensorizer_args"
  ],
  "is_vllm_tensorized": [
    "tensorizer_config"
  ],
  "serialize_extra_artifacts": [
    "tensorizer_args",
    "served_model_name"
  ],
  "serialize_vllm_model": [
    "model",
    "tensorizer_config",
    "model_config"
  ],
  "tensorize_vllm_model": [
    "engine_args",
    "tensorizer_config",
    "generate_keyfile"
  ],
  "tensorize_lora_adapter": [
    "lora_path",
    "tensorizer_config"
  ],
  "maybe_save_metadata_and_attributes_for_weight_reloading": [
    "model",
    "model_config"
  ],
  "_bond_method_to_cls": [
    "func",
    "obj"
  ],
  "support_quantized_model_reload_from_hp_weights": [
    "original_load_weights"
  ],
  "BaseModelLoader": {
    "__init__": [
      "self",
      "load_config"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "load_weights": [
      "self",
      "model",
      "model_config"
    ],
    "load_model": [
      "self",
      "vllm_config",
      "model_config",
      "prefix"
    ]
  },
  "log_model_inspection": [
    "model"
  ],
  "GGUFModelLoader": {
    "__init__": [
      "self",
      "load_config"
    ],
    "_prepare_weights": [
      "self",
      "model_config"
    ],
    "_get_gguf_weights_map": [
      "self",
      "model_config"
    ],
    "_get_gguf_weight_type": [
      "self",
      "model_config",
      "model_name_or_path",
      "gguf_to_hf_name_map"
    ],
    "_get_weights_iterator": [
      "self",
      "model_config",
      "model_name_or_path",
      "gguf_to_hf_name_map"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "load_weights": [
      "self",
      "model",
      "model_config"
    ],
    "load_model": [
      "self",
      "vllm_config",
      "model_config",
      "prefix"
    ]
  },
  "initialize_model": [
    "vllm_config"
  ],
  "process_weights_after_loading": [
    "model",
    "model_config",
    "target_device"
  ],
  "device_loading_context": [
    "module",
    "target_device"
  ],
  "_MODEL_ARCH_BY_HASH": [],
  "_get_model_architecture": [
    "model_config"
  ],
  "get_model_architecture": [
    "model_config"
  ],
  "get_model_cls": [
    "model_config"
  ],
  "get_architecture_class_name": [
    "model_config"
  ],
  "ParamMapping": {
    "__post_init__": [
      "self"
    ],
    "get_sub_modules": [
      "self",
      "module_name"
    ]
  },
  "configure_quant_config": [
    "quant_config",
    "model_class"
  ],
  "temp_dir": [],
  "enable_hf_transfer": [],
  "DisabledTqdm": {
    "__init__": [
      "self"
    ]
  },
  "get_lock": [
    "model_name_or_path",
    "cache_dir"
  ],
  "atomic_writer": [
    "filepath",
    "mode",
    "encoding"
  ],
  "maybe_download_from_modelscope": [
    "model",
    "revision",
    "download_dir",
    "ignore_patterns",
    "allow_patterns"
  ],
  "_shared_pointers": [
    "tensors"
  ],
  "convert_bin_to_safetensor_file": [
    "pt_filename",
    "sf_filename"
  ],
  "get_quant_config": [
    "model_config",
    "load_config"
  ],
  "get_sparse_attention_config": [
    "model_config",
    "load_config",
    "sparse_attention_config_filename"
  ],
  "download_gguf": [
    "repo_id",
    "quant_type",
    "cache_dir",
    "revision",
    "ignore_patterns"
  ],
  "download_weights_from_hf": [
    "model_name_or_path",
    "cache_dir",
    "allow_patterns",
    "revision",
    "ignore_patterns"
  ],
  "download_safetensors_index_file_from_hf": [
    "model_name_or_path",
    "index_file",
    "cache_dir",
    "revision"
  ],
  "filter_duplicate_safetensors_files": [
    "hf_weights_files",
    "hf_folder",
    "index_file"
  ],
  "filter_files_not_needed_for_inference": [
    "hf_weights_files"
  ],
  "enable_tqdm": [
    "use_tqdm_on_load"
  ],
  "np_cache_weights_iterator": [
    "model_name_or_path",
    "cache_dir",
    "hf_folder",
    "hf_weights_files",
    "use_tqdm_on_load"
  ],
  "safetensors_weights_iterator": [
    "hf_weights_files",
    "use_tqdm_on_load",
    "safetensors_load_strategy"
  ],
  "multi_thread_safetensors_weights_iterator": [
    "hf_weights_files",
    "use_tqdm_on_load",
    "max_workers"
  ],
  "runai_safetensors_weights_iterator": [
    "hf_weights_files",
    "use_tqdm_on_load",
    "is_distributed"
  ],
  "_init_loader": [
    "pg",
    "device",
    "f_list"
  ],
  "fastsafetensors_weights_iterator": [
    "hf_weights_files",
    "use_tqdm_on_load"
  ],
  "pt_weights_iterator": [
    "hf_weights_files",
    "use_tqdm_on_load",
    "pt_load_map_location"
  ],
  "multi_thread_pt_weights_iterator": [
    "hf_weights_files",
    "use_tqdm_on_load",
    "pt_load_map_location",
    "max_workers"
  ],
  "get_gguf_extra_tensor_names": [
    "gguf_file",
    "gguf_to_hf_name_map"
  ],
  "get_gguf_weight_type_map": [
    "gguf_file",
    "gguf_to_hf_name_map"
  ],
  "gguf_quant_weights_iterator": [
    "gguf_file",
    "gguf_to_hf_name_map"
  ],
  "convert_pyslice_to_tensor": [
    "x"
  ],
  "default_weight_loader": [
    "param",
    "loaded_weight"
  ],
  "row_parallel_weight_loader": [
    "param",
    "loaded_weight"
  ],
  "LoaderFunction": [],
  "sharded_weight_loader": [
    "shard_axis"
  ],
  "composed_weight_loader": [
    "loader",
    "fn"
  ],
  "initialize_dummy_weights": [
    "model",
    "low",
    "high",
    "seed"
  ],
  "maybe_remap_kv_scale_name": [
    "name",
    "params_dict"
  ],
  "BitsAndBytesModelLoader": {
    "possible_config_file_names": [],
    "__init__": [
      "self",
      "load_config"
    ],
    "_get_weight_files": [
      "self",
      "model_name_or_path",
      "allowed_patterns",
      "revision"
    ],
    "_prepare_weights": [
      "self",
      "model_name_or_path",
      "revision"
    ],
    "_hf_weight_iter": [
      "self",
      "hf_weights_files",
      "use_safetensors"
    ],
    "_get_quantized_weights_iterator": [
      "self",
      "model_name_or_path",
      "revision"
    ],
    "_is_8bit_weight_name": [
      "self",
      "weight_name"
    ],
    "_is_4bit_weight_name": [
      "self",
      "weight_name"
    ],
    "_quantized_8bit_generator": [
      "self",
      "hf_weights_files",
      "use_safetensors",
      "quant_state_dict"
    ],
    "_quantized_4bit_generator": [
      "self",
      "hf_weights_files",
      "use_safetensors",
      "quant_state_dict"
    ],
    "_unquantized_generator": [
      "self",
      "hf_weights_files",
      "use_safetensors",
      "quant_state_dict"
    ],
    "_get_bnb_target_modules": [
      "self",
      "model"
    ],
    "_classify_module_sharding": [
      "self",
      "model"
    ],
    "_verify_model_compatibility": [
      "self",
      "model",
      "model_config"
    ],
    "_initialize_loader_state": [
      "self",
      "model",
      "model_config"
    ],
    "_dequantize_dq": [
      "self",
      "quant_states"
    ],
    "_fuse_moe_quant_states": [
      "self",
      "model",
      "quant_states_dict"
    ],
    "_stack_quantization_states": [
      "self",
      "model",
      "quant_state_dict"
    ],
    "_bind_quant_states_to_params": [
      "self",
      "model",
      "stacked_quant_state_dict"
    ],
    "load_weights": [
      "self",
      "model",
      "model_config"
    ],
    "download_model": [
      "self",
      "model_config"
    ]
  },
  "LoadFormats": [],
  "register_model_loader": [
    "load_format"
  ],
  "get_model_loader": [
    "load_config"
  ],
  "get_model": [],
  "ShardedStateLoader": {
    "DEFAULT_PATTERN": [],
    "__init__": [
      "self",
      "load_config"
    ],
    "_filter_subtensors": [
      "tensors"
    ],
    "_prepare_weights": [
      "self",
      "model_name_or_path",
      "revision"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "load_weights": [
      "self",
      "model",
      "model_config"
    ],
    "iterate_over_files": [
      "self",
      "paths"
    ],
    "save_model": [
      "model",
      "path",
      "pattern",
      "max_size"
    ]
  },
  "DummyModelLoader": {
    "__init__": [
      "self",
      "load_config"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "load_weights": [
      "self",
      "model",
      "model_config"
    ]
  },
  "BLACKLISTED_TENSORIZER_ARGS": [],
  "validate_config": [
    "config"
  ],
  "TensorizerLoader": {
    "__init__": [
      "self",
      "load_config"
    ],
    "_verify_config": [
      "self",
      "model_config",
      "parallel_config"
    ],
    "_get_weights_iterator": [
      "self"
    ],
    "_load_model_serialized_cpu": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "_patch_tensorizer_config": [
      "self",
      "model_config"
    ],
    "load_weights": [
      "self",
      "model",
      "model_config"
    ],
    "load_model": [
      "self",
      "vllm_config",
      "model_config",
      "prefix"
    ],
    "save_model": [
      "model",
      "tensorizer_config",
      "model_config"
    ]
  },
  "RunaiModelStreamerLoader": {
    "__init__": [
      "self",
      "load_config"
    ],
    "_prepare_weights": [
      "self",
      "model_name_or_path",
      "revision"
    ],
    "_get_weights_iterator": [
      "self",
      "model_or_path",
      "revision"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "load_weights": [
      "self",
      "model",
      "model_config"
    ]
  },
  "DEFAULT_VOCAB_PADDING_SIZE": [],
  "UnquantizedEmbeddingMethod": {
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "embedding": [
      "self",
      "layer",
      "input_"
    ]
  },
  "pad_vocab_size": [
    "vocab_size",
    "pad_to"
  ],
  "vocab_range_from_per_partition_vocab_size": [
    "per_partition_vocab_size",
    "rank",
    "offset"
  ],
  "vocab_range_from_global_vocab_size": [
    "global_vocab_size",
    "rank",
    "world_size",
    "offset"
  ],
  "VocabParallelEmbeddingShardIndices": {
    "num_org_elements": [
      "self"
    ],
    "num_added_elements": [
      "self"
    ],
    "num_org_elements_padded": [
      "self"
    ],
    "num_added_elements_padded": [
      "self"
    ],
    "num_org_vocab_padding": [
      "self"
    ],
    "num_added_vocab_padding": [
      "self"
    ],
    "num_elements_padded": [
      "self"
    ],
    "__post_init__": [
      "self"
    ]
  },
  "get_masked_input_and_mask": [
    "input_",
    "org_vocab_start_index",
    "org_vocab_end_index",
    "num_org_vocab_padding",
    "added_vocab_start_index",
    "added_vocab_end_index"
  ],
  "VocabParallelEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "params_dtype",
      "org_num_embeddings",
      "padding_size",
      "quant_config",
      "prefix"
    ],
    "_get_indices": [
      "cls",
      "vocab_size_padded",
      "org_vocab_size_padded",
      "vocab_size",
      "org_vocab_size",
      "tp_rank",
      "tp_size"
    ],
    "get_sharded_to_full_mapping": [
      "self"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "forward_native": [
      "self",
      "input_"
    ],
    "forward_cuda": [
      "self",
      "input_"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "ParallelLMHead": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "bias",
      "params_dtype",
      "org_num_embeddings",
      "padding_size",
      "quant_config",
      "prefix"
    ],
    "tie_weights": [
      "self",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "input_"
    ]
  },
  "AttentionLayerBase": {
    "get_attn_backend": [
      "self"
    ],
    "get_kv_cache_spec": [
      "self",
      "vllm_config"
    ]
  },
  "ConvLayerBase": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "padding_mode"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "Conv2dLayer": {
    "num_dim": [],
    "_forward_mulmat": [
      "self",
      "x"
    ],
    "_forward_conv": [
      "self",
      "x"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ]
  },
  "CausalConv2dLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "padding_mode"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv3dLayer": {
    "num_dim": [],
    "_forward_mulmat": [
      "self",
      "x"
    ],
    "_forward_conv": [
      "self",
      "x"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ]
  },
  "kda_attention": [
    "q_proj_states",
    "k_proj_states",
    "v_proj_states",
    "g1",
    "beta",
    "core_attn_out",
    "layer_name"
  ],
  "kda_attention_fake": [
    "q_proj_states",
    "k_proj_states",
    "v_proj_states",
    "g1",
    "beta",
    "core_attn_out",
    "layer_name"
  ],
  "KimiDeltaAttention": {
    "mamba_type": [
      "self"
    ],
    "get_state_dtype": [
      "self"
    ],
    "get_state_shape": [
      "self"
    ],
    "__init__": [
      "self",
      "layer_idx",
      "hidden_size",
      "quant_config",
      "cache_config",
      "model_config",
      "rms_norm_eps",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "positions",
      "output"
    ],
    "_forward": [
      "self",
      "q_proj_states",
      "k_proj_states",
      "v_proj_states",
      "g1",
      "beta",
      "core_attn_out"
    ]
  },
  "shuffle_weight": [
    "w"
  ],
  "get_token_bin_counts_and_mask": [
    "tokens",
    "vocab_size",
    "num_seqs"
  ],
  "apply_penalties": [
    "logits",
    "prompt_tokens_tensor",
    "output_tokens_tensor",
    "presence_penalties",
    "frequency_penalties",
    "repetition_penalties"
  ],
  "default_unquantized_gemm": [
    "layer",
    "x",
    "weight",
    "bias"
  ],
  "use_aiter_triton_gemm": [
    "n",
    "m",
    "k",
    "dtype"
  ],
  "rocm_unquantized_gemm_impl": [
    "x",
    "weight",
    "bias"
  ],
  "rocm_unquantized_gemm_fake": [
    "x",
    "weight",
    "bias"
  ],
  "rocm_unquantized_gemm": [
    "layer",
    "x",
    "weight",
    "bias"
  ],
  "check_cpu_sgl_kernel": [
    "n",
    "k",
    "dtype"
  ],
  "dispatch_cpu_unquantized_gemm": [
    "layer",
    "remove_weight"
  ],
  "cpu_unquantized_gemm": [
    "layer",
    "x",
    "weight",
    "bias"
  ],
  "dispatch_unquantized_gemm": [],
  "_swiglustep_and_mul_kernel": [
    "o_ptr",
    "o_stride",
    "x_ptr",
    "x_stride",
    "limit",
    "d",
    "BLOCK_SIZE"
  ],
  "swiglustep_and_mul_triton": [
    "output",
    "input",
    "limit"
  ],
  "FatreluAndMul": {
    "__init__": [
      "self",
      "threshold"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ]
  },
  "SiluAndMul": {
    "__init__": [
      "self"
    ],
    "forward_native": [
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ],
    "forward_xpu": [
      "self",
      "x"
    ]
  },
  "MulAndSilu": {
    "__init__": [
      "self"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ]
  },
  "GeluAndMulSparse": {
    "__init__": [
      "self",
      "activation_sparsity",
      "approximate"
    ],
    "_gaussian_topk": [
      "self",
      "x"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ]
  },
  "GeluAndMul": {
    "__init__": [
      "self",
      "approximate"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ],
    "forward_xpu": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "SwigluOAIAndMul": {
    "__init__": [
      "self",
      "alpha",
      "limit"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "SwigluStepAndMul": {
    "__init__": [
      "self",
      "limit"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "NewGELU": {
    "__init__": [
      "self"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ],
    "forward_xpu": [
      "self",
      "x"
    ]
  },
  "FastGELU": {
    "__init__": [
      "self"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ],
    "forward_xpu": [
      "self",
      "x"
    ]
  },
  "QuickGELU": {
    "__init__": [
      "self"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ],
    "forward_xpu": [
      "self",
      "x"
    ]
  },
  "ReLUSquaredActivation": {
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ]
  },
  "XIELU": {
    "__init__": [
      "self",
      "alpha_p_init",
      "alpha_n_init",
      "beta",
      "eps",
      "dtype",
      "with_vector_loads"
    ],
    "_xielu_python": [
      "self",
      "x"
    ],
    "_xielu_cuda": [
      "self",
      "x"
    ],
    "forward_native": [
      "self",
      "input"
    ],
    "forward_cuda": [
      "self",
      "input"
    ]
  },
  "ScaledActivation": {
    "__init__": [
      "self",
      "act_module",
      "intermediate_size",
      "input_is_parallel",
      "params_dtype"
    ],
    "forward": [
      "self",
      "x"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ]
  },
  "_ACTIVATION_REGISTRY": [],
  "get_act_fn": [
    "act_fn_name"
  ],
  "_ACTIVATION_AND_MUL_REGISTRY": [],
  "get_act_and_mul_fn": [
    "act_fn_name"
  ],
  "_matmul_launch_metadata": [
    "grid",
    "kernel",
    "args"
  ],
  "_compute_pid": [
    "tile_id",
    "num_pid_in_group",
    "num_pid_m",
    "GROUP_SIZE_M",
    "NUM_SMS"
  ],
  "matmul_kernel_persistent": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "bias_ptr",
    "M",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "NUM_SMS",
    "A_LARGE",
    "B_LARGE",
    "C_LARGE",
    "HAS_BIAS"
  ],
  "matmul_persistent": [
    "a",
    "b",
    "bias"
  ],
  "bmm_kernel": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "B",
    "M",
    "N",
    "K",
    "stride_ab",
    "stride_am",
    "stride_ak",
    "stride_bb",
    "stride_bk",
    "stride_bn",
    "stride_cb",
    "stride_cm",
    "stride_cn",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "A_LARGE",
    "B_LARGE",
    "C_LARGE"
  ],
  "_log_softmax_kernel": [
    "input_ptr",
    "output_ptr",
    "input_row_stride",
    "output_row_stride",
    "n_cols",
    "BLOCK_SIZE"
  ],
  "log_softmax": [
    "input",
    "dim"
  ],
  "mean_kernel": [
    "input_ptr",
    "output_ptr",
    "input_stride0",
    "input_stride1",
    "input_stride2",
    "output_stride0",
    "output_stride1",
    "M",
    "N",
    "K",
    "BLOCK_SIZE"
  ],
  "mean_dim": [
    "input",
    "dim",
    "keepdim",
    "dtype"
  ],
  "mm_batch_invariant": [
    "a",
    "b"
  ],
  "matmul_batch_invariant": [
    "a",
    "b"
  ],
  "bmm_batch_invariant": [
    "a",
    "b"
  ],
  "addmm_batch_invariant": [
    "bias",
    "a",
    "b"
  ],
  "_log_softmax_batch_invariant": [
    "input",
    "dim",
    "_half_to_float"
  ],
  "softmax_batch_invariant": [
    "input",
    "dim",
    "dtype"
  ],
  "mean_batch_invariant": [
    "input",
    "dim",
    "keepdim",
    "dtype"
  ],
  "_rms_norm_kernel": [
    "input_ptr",
    "weight_ptr",
    "output_ptr",
    "input_row_stride",
    "output_row_stride",
    "n_cols",
    "eps",
    "BLOCK_SIZE"
  ],
  "rms_norm_batch_invariant": [
    "input",
    "weight",
    "eps"
  ],
  "linear_batch_invariant": [
    "input",
    "weight",
    "bias"
  ],
  "_batch_invariant_MODE": [],
  "_batch_invariant_LIB": [],
  "_original_torch_bmm": [],
  "_original_fp16_reduction_precision": [],
  "_original_bf16_reduction_precision": [],
  "_original_cublas_workspace_cfg": [],
  "_original_cublaslt_workspace_size": [],
  "enable_batch_invariant_mode": [],
  "_read_vllm_batch_invariant": [],
  "vllm_is_batch_invariant": [],
  "override_envs_for_invariance": [
    "attention_backend"
  ],
  "init_batch_invariance": [
    "attention_backend"
  ],
  "MLAModules": {},
  "MultiHeadLatentAttentionWrapper": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "scale",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "v_head_dim",
      "q_lora_rank",
      "kv_lora_rank",
      "mla_modules",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "llama_4_scaling"
    ]
  },
  "DEFAULT_LN": [],
  "get_abs_pos": [
    "abs_pos",
    "tgt_size"
  ],
  "get_1d_sincos_pos_embed_from_grid": [
    "embed_dim",
    "pos",
    "version"
  ],
  "get_2d_sincos_pos_embed_from_grid": [
    "embed_dim",
    "grid",
    "version"
  ],
  "get_2d_sincos_pos_embed": [
    "embed_dim",
    "grid_size",
    "cls_token",
    "version"
  ],
  "BaseResampler": {
    "__init__": [
      "self",
      "num_queries",
      "embed_dim",
      "num_heads",
      "kv_dim",
      "norm_layer",
      "do_post_projection",
      "quant_config",
      "prefix"
    ],
    "_repeat": [
      "self",
      "query",
      "N"
    ]
  },
  "Resampler2": {
    "__init__": [
      "self",
      "grid_size",
      "embed_dim",
      "num_heads",
      "kv_dim",
      "norm_layer",
      "adaptive",
      "do_post_projection",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "tgt_sizes",
      "attn_mask"
    ]
  },
  "_fwd_diag_kernel": [
    "Q",
    "K",
    "V",
    "Out",
    "S",
    "b",
    "h",
    "n",
    "d",
    "e",
    "BLOCK",
    "NUM_BLOCK",
    "CBLOCK"
  ],
  "_fwd_kv_parallel": [
    "K",
    "V",
    "K_decay",
    "KV",
    "b",
    "h",
    "n",
    "d",
    "e",
    "BLOCK",
    "NUM_BLOCK",
    "D_FBLOCK",
    "E_FBLOCK",
    "NUM_FBLOCK",
    "CBLOCK",
    "NUM_CBLOCK"
  ],
  "_fwd_kv_reduce": [
    "S",
    "KV",
    "KV_HISTORY",
    "b",
    "h",
    "n",
    "d",
    "e",
    "BLOCK",
    "NUM_BLOCK",
    "D_FBLOCK",
    "E_FBLOCK"
  ],
  "_fwd_none_diag_kernel": [
    "Q",
    "Out",
    "S",
    "KV",
    "b",
    "h",
    "n",
    "d",
    "e",
    "BLOCK",
    "NUM_BLOCK",
    "E_FBLOCK",
    "CBLOCK",
    "NUM_CBLOCK"
  ],
  "_attention": {
    "forward": [
      "ctx",
      "q",
      "k",
      "v",
      "s",
      "kv_history"
    ]
  },
  "lightning_attention_": [],
  "lightning_attention": [
    "q",
    "k",
    "v",
    "ed",
    "block_size",
    "kv_history"
  ],
  "_linear_attn_decode_kernel": [
    "q_ptr",
    "k_ptr",
    "v_ptr",
    "kv_cache_ptr",
    "slope_rate",
    "slot_idx",
    "output_ptr",
    "D",
    "qkv_b_stride",
    "qkv_h_stride",
    "cache_b_stride",
    "cache_h_stride",
    "cache_d0_stride",
    "cache_d1_stride",
    "BLOCK_SIZE"
  ],
  "linear_decode_forward_triton": [
    "q",
    "k",
    "v",
    "kv_caches",
    "slope_rate",
    "slot_idx",
    "BLOCK_SIZE"
  ],
  "WEIGHT_LOADER_V2_SUPPORTED": [],
  "adjust_bitblas_shard": [
    "param",
    "shard_size",
    "shard_offset"
  ],
  "adjust_marlin_shard": [
    "param",
    "shard_size",
    "shard_offset"
  ],
  "adjust_block_scale_shard": [
    "weight_block_size",
    "shard_size",
    "shard_offset"
  ],
  "adjust_bitsandbytes_4bit_shard": [
    "param",
    "shard_offsets",
    "loaded_shard_id"
  ],
  "adjust_scalar_to_fused_array": [
    "param",
    "loaded_weight",
    "shard_id"
  ],
  "left_shift_bitsandbytes_4bit_shard": [
    "bnb_weight_attrs"
  ],
  "LinearMethodBase": {
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "UnquantizedLinearMethod": {
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "LinearBase": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "skip_bias_add",
      "params_dtype",
      "quant_config",
      "prefix"
    ],
    "update_param_tp_status": [
      "self"
    ]
  },
  "ReplicatedLinear": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "bias",
      "skip_bias_add",
      "params_dtype",
      "quant_config",
      "prefix"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "ColumnParallelLinear": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "bias",
      "gather_output",
      "skip_bias_add",
      "params_dtype",
      "quant_config",
      "prefix"
    ],
    "_maybe_allow_fp8_block_shape_mismatch": [
      "self"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "weight_loader_v2": [
      "self",
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "input_"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "MergedColumnParallelLinear": {
    "__init__": [
      "self",
      "input_size",
      "output_sizes",
      "bias",
      "gather_output",
      "skip_bias_add",
      "params_dtype",
      "quant_config",
      "prefix"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "loaded_shard_id"
    ],
    "_load_fused_module_from_checkpoint": [
      "self",
      "param",
      "loaded_weight"
    ],
    "weight_loader_v2": [
      "self",
      "param",
      "loaded_weight",
      "loaded_shard_id"
    ]
  },
  "QKVParallelLinear": {
    "__init__": [
      "self",
      "hidden_size",
      "head_size",
      "total_num_heads",
      "total_num_kv_heads",
      "bias",
      "skip_bias_add",
      "params_dtype",
      "quant_config",
      "prefix"
    ],
    "_get_shard_offset_mapping": [
      "self",
      "loaded_shard_id"
    ],
    "_get_shard_size_mapping": [
      "self",
      "loaded_shard_id"
    ],
    "_load_fused_module_from_checkpoint": [
      "self",
      "param",
      "loaded_weight"
    ],
    "weight_loader_v2": [
      "self",
      "param",
      "loaded_weight",
      "loaded_shard_id"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "loaded_shard_id"
    ]
  },
  "RowParallelLinear": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "bias",
      "input_is_parallel",
      "skip_bias_add",
      "params_dtype",
      "reduce_results",
      "quant_config",
      "prefix"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "weight_loader_v2": [
      "self",
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "input_"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "LogitsProcessor": {
    "__init__": [
      "self",
      "vocab_size",
      "org_vocab_size",
      "scale",
      "logits_as_input",
      "soft_cap"
    ],
    "forward": [
      "self",
      "lm_head",
      "hidden_states",
      "embedding_bias"
    ],
    "_gather_logits": [
      "self",
      "logits"
    ],
    "_get_logits": [
      "self",
      "hidden_states",
      "lm_head",
      "embedding_bias"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "sparse_attn_indexer": [
    "hidden_states",
    "k_cache_prefix",
    "kv_cache",
    "q_fp8",
    "k",
    "weights",
    "quant_block_size",
    "scale_fmt",
    "topk_tokens",
    "head_dim",
    "max_model_len",
    "total_seq_lens",
    "topk_indices_buffer"
  ],
  "sparse_attn_indexer_fake": [
    "hidden_states",
    "k_cache_prefix",
    "kv_cache",
    "q_fp8",
    "k",
    "weights",
    "quant_block_size",
    "scale_fmt",
    "topk_tokens",
    "head_dim",
    "max_model_len",
    "total_seq_lens",
    "topk_indices_buffer"
  ],
  "SparseAttnIndexer": {
    "__init__": [
      "self",
      "k_cache",
      "quant_block_size",
      "scale_fmt",
      "topk_tokens",
      "head_dim",
      "max_model_len",
      "max_total_seq_len",
      "topk_indices_buffer"
    ],
    "forward_native": [
      "self",
      "hidden_states",
      "q_fp8",
      "k",
      "weights"
    ],
    "forward_cuda": [
      "self",
      "hidden_states",
      "q_fp8",
      "k",
      "weights"
    ],
    "forward_hip": [
      "self",
      "hidden_states",
      "q_fp8",
      "k",
      "weights"
    ]
  },
  "poly_norm": [
    "x",
    "weight",
    "bias",
    "variance_epsilon"
  ],
  "dispatch_rocm_rmsnorm_func": [
    "with_fused_add",
    "dtype",
    "use_aiter"
  ],
  "RMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps",
      "var_hidden_size",
      "has_weight",
      "dtype"
    ],
    "forward_static": [
      "x",
      "variance_epsilon",
      "hidden_size",
      "orig_dtype",
      "weight",
      "residual",
      "variance_size_override"
    ],
    "forward_native": [
      "self",
      "x",
      "residual"
    ],
    "forward_cuda": [
      "self",
      "x",
      "residual"
    ],
    "forward_hip": [
      "self",
      "x",
      "residual"
    ],
    "forward_xpu": [
      "self",
      "x",
      "residual"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "GemmaRMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "_forward_static_no_residual": [
      "weight",
      "variance_epsilon",
      "x"
    ],
    "_forward_static_with_residual": [
      "weight",
      "variance_epsilon",
      "x",
      "residual"
    ],
    "forward_native": [
      "self",
      "x",
      "residual"
    ],
    "forward_cuda": [
      "self",
      "x",
      "residual"
    ]
  },
  "RMSNormGated": {
    "__init__": [
      "self",
      "hidden_size",
      "eps",
      "group_size",
      "norm_before_gate",
      "device",
      "dtype"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward_native": [
      "self",
      "x",
      "z"
    ],
    "forward_cuda": [
      "self",
      "x",
      "z"
    ]
  },
  "LayerNorm": {
    "__init__": [
      "self",
      "dim",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ProjectorFn": [],
  "ClassifierFn": [],
  "ActivationFn": [],
  "PoolingParamsUpdate": {
    "__or__": [
      "self",
      "other"
    ],
    "apply": [
      "self",
      "params"
    ]
  },
  "get_classification_act_fn": [
    "config"
  ],
  "get_cross_encoder_act_fn": [
    "config"
  ],
  "resolve_classifier_act_fn": [
    "model_config",
    "static_num_labels",
    "act_fn"
  ],
  "PoolerActivation": {
    "wraps": [
      "module"
    ],
    "forward_chunk": [
      "self",
      "pooled_data"
    ],
    "forward": [
      "self",
      "pooled_data"
    ]
  },
  "PoolerIdentity": {
    "forward_chunk": [
      "self",
      "pooled_data"
    ]
  },
  "PoolerNormalize": {
    "forward_chunk": [
      "self",
      "pooled_data"
    ]
  },
  "PoolerMultiLabelClassify": {
    "forward_chunk": [
      "self",
      "pooled_data"
    ]
  },
  "PoolerClassify": {
    "__init__": [
      "self"
    ],
    "forward_chunk": [
      "self",
      "pooled_data"
    ]
  },
  "LambdaPoolerActivation": {
    "__init__": [
      "self",
      "fn"
    ],
    "forward_chunk": [
      "self",
      "pooled_data"
    ]
  },
  "DispatchPooler": {
    "for_embedding": [
      "cls",
      "pooler_config"
    ],
    "for_seq_cls": [
      "cls",
      "pooler_config"
    ],
    "__init__": [
      "self",
      "poolers_by_task"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "get_pooling_updates": [
      "self",
      "task"
    ],
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "IdentityPooler": {
    "get_supported_tasks": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "BOSEOSFilter": {
    "__init__": [
      "self",
      "pooler",
      "bos_token_id",
      "eos_token_id"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "get_pooling_updates": [
      "self",
      "task"
    ],
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "Pooler": {
    "get_supported_tasks": [
      "self"
    ],
    "get_pooling_updates": [
      "self",
      "task"
    ],
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "SequencePoolingMethod": {
    "get_supported_tasks": [
      "self"
    ],
    "get_pooling_updates": [
      "self",
      "task"
    ],
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "CLSPool": {
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "LastPool": {
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "MeanPool": {
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "get_seq_pooling_method": [
    "pooling_type"
  ],
  "SequencePooler": {
    "__init__": [
      "self",
      "pooling",
      "head"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "get_pooling_updates": [
      "self",
      "task"
    ],
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "pooler_for_embed": [
    "pooler_config"
  ],
  "pooler_for_classify": [
    "pooler_config"
  ],
  "SequencePoolerHead": {
    "get_supported_tasks": [
      "self"
    ],
    "forward": [
      "self",
      "pooled_data",
      "pooling_metadata"
    ]
  },
  "EmbeddingPoolerHead": {
    "__init__": [
      "self",
      "projector",
      "head_dtype",
      "activation"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "forward": [
      "self",
      "pooled_data",
      "pooling_metadata"
    ]
  },
  "ClassifierPoolerHead": {
    "__init__": [
      "self",
      "classifier",
      "logit_bias",
      "head_dtype",
      "activation"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "forward": [
      "self",
      "pooled_data",
      "pooling_metadata"
    ]
  },
  "TokenPoolingMethod": {
    "get_supported_tasks": [
      "self"
    ],
    "get_pooling_updates": [
      "self",
      "task"
    ],
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "AllPool": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "StepPool": {
    "get_pooling_updates": [
      "self",
      "task"
    ],
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "get_tok_pooling_method": [
    "pooling_type"
  ],
  "TokenPooler": {
    "__init__": [
      "self",
      "pooling",
      "head"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "get_pooling_updates": [
      "self",
      "task"
    ],
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "pooler_for_token_embed": [
    "pooler_config",
    "projector"
  ],
  "pooler_for_token_classify": [
    "pooler_config"
  ],
  "TokenPoolerHead": {
    "get_supported_tasks": [
      "self"
    ],
    "forward_chunk": [
      "self",
      "pooled_data",
      "pooling_param"
    ],
    "forward": [
      "self",
      "pooled_data",
      "pooling_metadata"
    ]
  },
  "TokenEmbeddingPoolerHead": {
    "__init__": [
      "self",
      "head_dtype",
      "projector",
      "activation"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "forward_chunk": [
      "self",
      "pooled_data",
      "pooling_param"
    ]
  },
  "TokenClassifierPoolerHead": {
    "__init__": [
      "self",
      "classifier",
      "logit_bias",
      "head_dtype",
      "activation"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "forward_chunk": [
      "self",
      "pooled_data",
      "pooling_param"
    ]
  },
  "MiniMaxText01RMSNormTP": {
    "name": [],
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "weight_loader": [
      "param",
      "loaded_weight"
    ],
    "_forward": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x",
      "residual"
    ],
    "forward_qk": [
      "q_norm",
      "k_norm",
      "q",
      "k"
    ]
  },
  "MiniMaxText01LinearKernel": {
    "jit_linear_forward_prefix": [
      "q",
      "k",
      "v",
      "kv_caches",
      "slope_rate",
      "block_size",
      "layer_idx"
    ]
  },
  "MiniMaxText01LinearAttention": {
    "mamba_type": [
      "self"
    ],
    "get_state_dtype": [
      "self"
    ],
    "get_state_shape": [
      "self"
    ],
    "__init__": [
      "self",
      "hidden_size",
      "hidden_inner_size",
      "num_heads",
      "head_dim",
      "max_position",
      "block_size",
      "num_hidden_layer",
      "model_config",
      "cache_config",
      "quant_config",
      "layer_idx",
      "linear_layer_idx",
      "prefix"
    ],
    "weight_direct_load": [
      "param",
      "loaded_weight"
    ],
    "_build_slope_tensor": [
      "n_attention_heads"
    ],
    "_prefill_and_mix_infer": [
      "self",
      "q",
      "k",
      "v",
      "kv_cache",
      "state_indices_tensor",
      "attn_metadata"
    ],
    "_decode_infer": [
      "self",
      "q",
      "k",
      "v",
      "kv_cache",
      "state_indices_tensor",
      "attn_metadata"
    ],
    "forward": [
      "self",
      "hidden_states",
      "output",
      "positions"
    ],
    "_forward": [
      "self",
      "hidden_states",
      "output",
      "positions"
    ]
  },
  "linear_attention": [
    "hidden_states",
    "output",
    "positions",
    "layer_name"
  ],
  "linear_attention_fake": [
    "hidden_states",
    "output",
    "positions",
    "layer_name"
  ],
  "Mixer2RMSNormGated": {
    "__init__": [
      "self",
      "full_hidden_size",
      "full_n_groups",
      "use_rms_norm",
      "eps"
    ],
    "forward_native": [
      "self",
      "x",
      "gate"
    ],
    "forward_cuda": [
      "self",
      "x",
      "gate"
    ]
  },
  "mamba_v2_sharded_weight_loader": [
    "shard_spec",
    "tp_size",
    "tp_rank"
  ],
  "MambaMixer2": {
    "__init__": [
      "self",
      "hidden_size",
      "ssm_state_size",
      "conv_kernel_size",
      "intermediate_size",
      "use_conv_bias",
      "use_bias",
      "n_groups",
      "num_heads",
      "head_dim",
      "rms_norm_eps",
      "activation",
      "use_rms_norm",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward_native": [
      "self",
      "hidden_states",
      "mup_vector"
    ],
    "forward": [
      "self",
      "hidden_states",
      "mup_vector"
    ],
    "conv_ssm_forward": [
      "self",
      "projected_states",
      "output"
    ],
    "get_state_dtype": [
      "self"
    ],
    "get_state_shape": [
      "self"
    ],
    "mamba_type": [
      "self"
    ]
  },
  "mamba_mixer2": [
    "projected_states",
    "output",
    "layer_name"
  ],
  "mamba_mixer2_fake": [
    "projected_states",
    "output",
    "layer_name"
  ],
  "MambaBase": {
    "get_state_shape": [
      "self"
    ],
    "mamba_type": [
      "self"
    ],
    "get_state_dtype": [
      "self"
    ],
    "get_kv_cache_spec": [
      "self",
      "vllm_config"
    ],
    "get_attn_backend": [
      "self"
    ]
  },
  "MambaMixer": {
    "__init__": [
      "self",
      "hidden_size",
      "ssm_state_size",
      "conv_kernel_size",
      "intermediate_size",
      "time_step_rank",
      "use_conv_bias",
      "use_bias",
      "use_rms_norm",
      "rms_norm_has_weight",
      "rms_norm_eps",
      "activation",
      "is_lora_enabled",
      "model_config",
      "cache_config",
      "prefix"
    ],
    "_ssm_transform": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "output"
    ],
    "forward_native": [
      "self",
      "hidden_states",
      "output"
    ],
    "forward_cuda": [
      "self",
      "hidden_states",
      "output"
    ],
    "get_state_dtype": [
      "self"
    ],
    "get_state_shape": [
      "self"
    ],
    "mamba_type": [
      "self"
    ],
    "_time_proj_bias": [
      "self"
    ]
  },
  "PrefillDecodeSplit": {},
  "split_batch_to_prefill_and_decode": [
    "hidden_states_BC",
    "gate",
    "state_indices_tensor",
    "num_prefill_tokens",
    "num_prefills",
    "num_decode_tokens"
  ],
  "mamba_mixer": [
    "hidden_states",
    "output",
    "layer_name"
  ],
  "mamba_mixer_fake": [
    "hidden_states",
    "output",
    "layer_name"
  ],
  "MambaStateDtypeCalculator": {
    "linear_attention_state_dtype": [
      "cls",
      "model_dtype",
      "mamba_cache_dtype"
    ],
    "mamba1_state_dtype": [
      "cls",
      "model_dtype",
      "mamba_cache_dtype",
      "mamba_ssm_cache_dtype"
    ],
    "mamba2_state_dtype": [
      "cls",
      "model_dtype",
      "mamba_cache_dtype",
      "mamba_ssm_cache_dtype"
    ],
    "_mamba_state_dtype": [
      "cls",
      "model_dtype",
      "mamba_cache_dtype",
      "mamba_ssm_cache_dtype"
    ],
    "short_conv_state_dtype": [
      "cls",
      "model_dtype",
      "mamba_cache_dtype"
    ],
    "gated_delta_net_state_dtype": [
      "cls",
      "model_dtype",
      "mamba_cache_dtype"
    ],
    "kda_state_dtype": [
      "cls",
      "model_dtype",
      "mamba_cache_dtype"
    ]
  },
  "MambaStateShapeCalculator": {
    "linear_attention_state_shape": [
      "cls",
      "num_heads",
      "tp_size",
      "head_dim"
    ],
    "mamba1_state_shape": [
      "cls",
      "tp_world_size",
      "intermediate_size",
      "state_size",
      "conv_kernel"
    ],
    "mamba2_state_shape": [
      "cls",
      "tp_world_size",
      "intermediate_size",
      "n_groups",
      "num_heads",
      "head_dim",
      "state_size",
      "conv_kernel"
    ],
    "short_conv_state_shape": [
      "cls",
      "tp_world_size",
      "intermediate_size",
      "conv_kernel"
    ],
    "extra_groups_for_head_shards": [
      "cls",
      "ngroups",
      "tp_size"
    ],
    "gated_delta_net_state_shape": [
      "cls",
      "tp_world_size",
      "num_k_heads",
      "num_v_heads",
      "head_k_dim",
      "head_v_dim",
      "conv_kernel_size",
      "num_spec"
    ],
    "kda_state_shape": [
      "cls",
      "tp_world_size",
      "num_heads",
      "head_dim",
      "num_k_heads",
      "head_k_dim",
      "conv_kernel_size",
      "num_spec"
    ]
  },
  "MambaCopySpec": {},
  "get_conv_copy_spec": [
    "state",
    "block_ids",
    "cur_block_idx",
    "num_accepted_tokens"
  ],
  "get_temporal_copy_spec": [
    "state",
    "block_ids",
    "cur_block_idx",
    "num_accepted_tokens"
  ],
  "get_full_copy_spec": [],
  "MambaStateCopyFuncCalculator": {
    "linear_attention_state_copy_func": [
      "cls"
    ],
    "mamba1_state_copy_func": [
      "cls"
    ],
    "mamba2_state_copy_func": [
      "cls"
    ],
    "short_conv_state_copy_func": [
      "cls"
    ],
    "gated_delta_net_state_copy_func": [
      "cls"
    ],
    "kda_state_copy_func": [
      "cls"
    ]
  },
  "ShortConv": {
    "__init__": [
      "self",
      "config",
      "dim",
      "layer_idx",
      "model_config",
      "cache_config",
      "prefix"
    ],
    "forward_native": [
      "self",
      "hidden_states",
      "output"
    ],
    "forward": [
      "self",
      "hidden_states",
      "output"
    ],
    "forward_cuda": [
      "self",
      "hidden_states",
      "output"
    ],
    "get_state_dtype": [
      "self"
    ],
    "get_state_shape": [
      "self"
    ],
    "mamba_type": [
      "self"
    ]
  },
  "short_conv": [
    "hidden_states",
    "output",
    "layer_name"
  ],
  "short_conv_fake": [
    "hidden_states",
    "output",
    "layer_name"
  ],
  "TRITON_22": [],
  "is_int_pow_2": [
    "n"
  ],
  "_mamba_chunk_scan_combined_fwd": [
    "x",
    "dt",
    "A",
    "B",
    "C",
    "chunk_size",
    "out",
    "D",
    "z",
    "dt_bias",
    "initial_states",
    "return_intermediate_states",
    "seq_idx",
    "cu_seqlens",
    "cu_chunk_seqlens",
    "last_chunk_indices",
    "dt_softplus",
    "dt_limit",
    "state_dtype"
  ],
  "mamba_chunk_scan_combined_varlen": [
    "x",
    "dt",
    "A",
    "B",
    "C",
    "chunk_size",
    "cu_seqlens",
    "cu_chunk_seqlens",
    "last_chunk_indices",
    "seq_idx",
    "out",
    "D",
    "z",
    "dt_bias",
    "initial_states",
    "dt_softplus",
    "dt_limit",
    "return_intermediate_states",
    "state_dtype"
  ],
  "_causal_conv1d_fwd_kernel": [
    "x_ptr",
    "w_ptr",
    "bias_ptr",
    "initial_states_ptr",
    "cache_indices_ptr",
    "has_initial_states_ptr",
    "query_start_loc_ptr",
    "batch_ptr",
    "token_chunk_offset_ptr",
    "block_idx_first_scheduled_token",
    "block_idx_last_scheduled_token",
    "initial_state_idx",
    "num_computed_tokens",
    "o_ptr",
    "dim",
    "seqlen",
    "num_cache_lines",
    "stride_x_dim",
    "stride_x_token",
    "stride_w_dim",
    "stride_w_width",
    "stride_istate_seq",
    "stride_istate_dim",
    "stride_istate_token",
    "stride_cache_indices",
    "stride_o_dim",
    "stride_o_token",
    "stride_block_m",
    "pad_slot_id",
    "HAS_BIAS",
    "KERNEL_WIDTH",
    "SILU_ACTIVATION",
    "IS_APC_ENABLED",
    "USE_PAD_SLOT",
    "NP2_STATELEN",
    "BLOCK_M",
    "BLOCK_N"
  ],
  "causal_conv1d_fn": [
    "x",
    "weight",
    "bias",
    "conv_states",
    "query_start_loc",
    "cache_indices",
    "has_initial_state",
    "activation",
    "pad_slot_id",
    "block_idx_first_scheduled_token",
    "block_idx_last_scheduled_token",
    "initial_state_idx",
    "num_computed_tokens",
    "block_size_to_align",
    "metadata",
    "validate_data"
  ],
  "_causal_conv1d_update_kernel": [
    "x_ptr",
    "w_ptr",
    "bias_ptr",
    "conv_state_ptr",
    "conv_state_indices_ptr",
    "num_accepted_tokens_ptr",
    "query_start_loc_ptr",
    "block_idx_last_scheduled_token",
    "initial_state_idx",
    "o_ptr",
    "batch",
    "dim",
    "seqlen",
    "state_len",
    "num_cache_lines",
    "stride_x_seq",
    "stride_x_dim",
    "stride_x_token",
    "stride_w_dim",
    "stride_w_width",
    "stride_conv_state_seq",
    "stride_conv_state_dim",
    "stride_conv_state_tok",
    "stride_state_indices",
    "stride_o_seq",
    "stride_o_dim",
    "stride_o_token",
    "pad_slot_id",
    "HAS_BIAS",
    "KERNEL_WIDTH",
    "SILU_ACTIVATION",
    "IS_VARLEN",
    "IS_APC_ENABLED",
    "IS_SPEC_DECODING",
    "NP2_STATELEN",
    "USE_PAD_SLOT",
    "BLOCK_N"
  ],
  "causal_conv1d_update": [
    "x",
    "conv_state",
    "weight",
    "bias",
    "activation",
    "conv_state_indices",
    "num_accepted_tokens",
    "query_start_loc",
    "max_query_len",
    "pad_slot_id",
    "block_idx_last_scheduled_token",
    "initial_state_idx",
    "validate_data"
  ],
  "TRITON3": [],
  "_selective_scan_update_kernel": [
    "state_ptr",
    "x_ptr",
    "dt_ptr",
    "dt_bias_ptr",
    "A_ptr",
    "B_ptr",
    "C_ptr",
    "D_ptr",
    "z_ptr",
    "out_ptr",
    "state_batch_indices_ptr",
    "dst_state_batch_indices_ptr",
    "pad_slot_id",
    "num_accepted_tokens_ptr",
    "cu_seqlens_ptr",
    "N",
    "nheads",
    "dim",
    "dstate",
    "nheads_ngroups_ratio",
    "stride_state_batch",
    "stride_state_head",
    "stride_state_dim",
    "stride_state_dstate",
    "stride_x_batch",
    "stride_x_head",
    "stride_x_dim",
    "stride_dt_batch",
    "stride_dt_head",
    "stride_dt_dim",
    "stride_dt_bias_head",
    "stride_dt_bias_dim",
    "stride_A_head",
    "stride_A_dim",
    "stride_A_dstate",
    "stride_B_batch",
    "stride_B_group",
    "stride_B_dstate",
    "stride_C_batch",
    "stride_C_group",
    "stride_C_dstate",
    "stride_D_head",
    "stride_D_dim",
    "stride_z_batch",
    "stride_z_head",
    "stride_z_dim",
    "stride_out_batch",
    "stride_out_head",
    "stride_out_dim",
    "stride_state_indices_batch",
    "stride_state_indices_T",
    "stride_dst_state_indices_batch",
    "stride_dst_state_indices_T",
    "DT_SOFTPLUS",
    "TIE_HDIM",
    "BLOCK_SIZE_M",
    "HAS_DT_BIAS",
    "HAS_D",
    "HAS_Z",
    "HAS_STATE_BATCH_INDICES",
    "IS_SPEC_DECODING",
    "IS_VARLEN",
    "BLOCK_SIZE_DSTATE"
  ],
  "selective_state_update": [
    "state",
    "x",
    "dt",
    "A",
    "B",
    "C",
    "D",
    "z",
    "dt_bias",
    "dt_softplus",
    "state_batch_indices",
    "dst_state_batch_indices",
    "pad_slot_id",
    "out",
    "num_accepted_tokens",
    "cu_seqlens"
  ],
  "selective_scan_fn": [
    "u",
    "ssm_states",
    "delta",
    "A",
    "B",
    "C",
    "D",
    "z",
    "delta_bias",
    "delta_softplus",
    "query_start_loc",
    "cache_indices",
    "has_initial_state",
    "pad_slot_id",
    "block_size",
    "block_idx_first_scheduled_token",
    "block_idx_last_scheduled_token",
    "initial_state_idx"
  ],
  "_bmm_chunk_fwd_kernel": [
    "a_ptr",
    "b_ptr",
    "out_ptr",
    "cu_chunk_seqlens_ptr",
    "seqlen",
    "chunk_size",
    "K",
    "ngroups",
    "stride_a_seqlen",
    "stride_a_head",
    "stride_ak",
    "stride_b_seqlen",
    "stride_b_head",
    "stride_bk",
    "stride_out_chunk",
    "stride_out_head",
    "stride_outm",
    "stride_outn",
    "IS_CAUSAL",
    "dot_dtype",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K"
  ],
  "_bmm_chunk_fwd": [
    "a",
    "b",
    "chunk_size",
    "cu_chunk_seqlens",
    "causal",
    "output_dtype"
  ],
  "_chunk_scan_fwd_kernel": [
    "cb_ptr",
    "x_ptr",
    "z_ptr",
    "out_ptr",
    "dt_ptr",
    "dA_cumsum_ptr",
    "seq_idx_ptr",
    "C_ptr",
    "states_ptr",
    "D_ptr",
    "initstates_ptr",
    "cu_chunk_seqlens_ptr",
    "chunk_size",
    "hdim",
    "dstate",
    "seqlen",
    "nheads_ngroups_ratio",
    "stride_cb_chunk",
    "stride_cb_head",
    "stride_cb_csize_m",
    "stride_cb_csize_k",
    "stride_x_seqlen",
    "stride_x_head",
    "stride_x_hdim",
    "stride_z_seqlen",
    "stride_z_head",
    "stride_z_hdim",
    "stride_out_seqlen",
    "stride_out_head",
    "stride_out_hdim",
    "stride_dt_chunk",
    "stride_dt_head",
    "stride_dt_csize",
    "stride_dA_cs_chunk",
    "stride_dA_cs_head",
    "stride_dA_cs_csize",
    "stride_seq_idx_chunk",
    "stride_C_seqlen",
    "stride_C_head",
    "stride_C_dstate",
    "stride_states_chunk",
    "stride_states_head",
    "stride_states_hdim",
    "stride_states_dstate",
    "stride_init_states_batch",
    "stride_init_states_head",
    "stride_init_states_hdim",
    "stride_init_states_dstate",
    "stride_D_head",
    "IS_CAUSAL",
    "HAS_D",
    "D_HAS_HDIM",
    "HAS_Z",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "BLOCK_SIZE_DSTATE",
    "IS_TRITON_22",
    "HAS_INITSTATES"
  ],
  "_chunk_scan_fwd": [
    "cb",
    "x",
    "dt",
    "dA_cumsum",
    "C",
    "states",
    "cu_chunk_seqlens",
    "out",
    "seq_idx",
    "D",
    "z",
    "initial_states"
  ],
  "_layer_norm_fwd_1pass_kernel": [
    "X",
    "Y",
    "W",
    "B",
    "Z",
    "Mean",
    "Rstd",
    "stride_x_row",
    "stride_y_row",
    "stride_z_row",
    "M",
    "N",
    "eps",
    "BLOCK_N",
    "HAS_BIAS",
    "HAS_Z",
    "NORM_BEFORE_GATE",
    "IS_RMS_NORM"
  ],
  "_layer_norm_fwd": [
    "x",
    "weight",
    "bias",
    "eps",
    "z",
    "out",
    "group_size",
    "norm_before_gate",
    "is_rms_norm"
  ],
  "rms_norm_gated": [
    "x",
    "weight",
    "bias",
    "z",
    "eps",
    "group_size",
    "norm_before_gate"
  ],
  "_chunk_cumsum_fwd_kernel": [
    "dt_ptr",
    "A_ptr",
    "dt_bias_ptr",
    "dt_out_ptr",
    "dA_cumsum_ptr",
    "cu_chunk_seqlens_ptr",
    "seqlen",
    "nheads",
    "chunk_size",
    "dt_min",
    "dt_max",
    "stride_dt_seqlen",
    "stride_dt_head",
    "stride_A_head",
    "stride_dt_bias_head",
    "stride_dt_out_head",
    "stride_dt_out_chunk",
    "stride_dt_out_csize",
    "stride_dA_cs_head",
    "stride_dA_cs_chunk",
    "stride_dA_cs_csize",
    "DT_SOFTPLUS",
    "HAS_DT_BIAS",
    "BLOCK_SIZE_H",
    "BLOCK_SIZE_CHUNK"
  ],
  "_chunk_state_fwd_kernel": [
    "x_ptr",
    "b_ptr",
    "states_ptr",
    "dt_ptr",
    "dA_cumsum_ptr",
    "cu_chunk_seqlens_ptr",
    "hdim",
    "dstate",
    "chunk_size",
    "seqlen",
    "nheads_ngroups_ratio",
    "stride_x_seqlen",
    "stride_x_head",
    "stride_x_hdim",
    "stride_b_seqlen",
    "stride_b_head",
    "stride_b_dstate",
    "stride_states_chunk",
    "stride_states_head",
    "stride_states_hdim",
    "stride_states_dstate",
    "stride_dt_head",
    "stride_dt_chunk",
    "stride_dt_csize",
    "stride_dA_cs_head",
    "stride_dA_cs_chunk",
    "stride_dA_cs_csize",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K"
  ],
  "_chunk_state_varlen_kernel": [
    "x_ptr",
    "b_ptr",
    "dt_ptr",
    "dA_cumsum_ptr",
    "chunk_states_ptr",
    "cu_seqlens_ptr",
    "states_ptr",
    "initstates_ptr",
    "hdim",
    "dstate",
    "chunk_size",
    "nheads_ngroups_ratio",
    "stride_x_seqlen",
    "stride_x_head",
    "stride_x_hdim",
    "stride_b_seqlen",
    "stride_b_head",
    "stride_b_dstate",
    "stride_dt_head",
    "stride_dt_chunk",
    "stride_dt_csize",
    "stride_dA_cs_head",
    "stride_dA_cs_chunk",
    "stride_dA_cs_csize",
    "stride_chunk_states_chunk",
    "stride_chunk_states_head",
    "stride_chunk_states_hdim",
    "stride_chunk_states_dstate",
    "stride_states_batch",
    "stride_states_head",
    "stride_states_hdim",
    "stride_states_dstate",
    "stride_init_states_batch",
    "stride_init_states_head",
    "stride_init_states_hdim",
    "stride_init_states_dstate",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "HAS_INITSTATES"
  ],
  "_chunk_cumsum_fwd": [
    "dt",
    "A",
    "chunk_size",
    "cu_chunk_seqlens",
    "dt_bias",
    "dt_softplus",
    "dt_limit"
  ],
  "_chunk_state_fwd": [
    "B",
    "x",
    "dt",
    "dA_cumsum",
    "cu_chunk_seqlens",
    "states",
    "states_in_fp32"
  ],
  "chunk_state_varlen": [
    "B",
    "x",
    "dt",
    "dA_cumsum",
    "cu_seqlens",
    "chunk_states",
    "initial_states"
  ],
  "_state_passing_fwd_kernel": [
    "states_ptr",
    "out_ptr",
    "dA_cs_ptr",
    "initstates_ptr",
    "seq_idx_ptr",
    "cu_chunk_seqlens_ptr",
    "dim",
    "nchunks",
    "seqlen",
    "chunk_size",
    "stride_states_chunk",
    "stride_states_head",
    "stride_states_dim",
    "stride_out_chunk",
    "stride_out_head",
    "stride_out_dim",
    "stride_dA_cs_head",
    "stride_dA_cs_chunk",
    "stride_dA_cs_csize",
    "stride_initstates_batch",
    "stride_initstates_head",
    "stride_initstates_dim",
    "stride_seq_idx_chunk",
    "HAS_INITSTATES",
    "BLOCK_SIZE"
  ],
  "_state_passing_fwd": [
    "states",
    "dA_cumsum",
    "cu_chunk_seqlens",
    "seq_idx",
    "initial_states",
    "out_dtype"
  ],
  "UnquantizedFusedMoEMethod": {
    "__init__": [
      "self",
      "moe"
    ],
    "is_monolithic": [
      "self"
    ],
    "supports_eplb": [
      "self"
    ],
    "allow_inplace": [
      "self"
    ],
    "maybe_make_prepare_finalize": [
      "self",
      "routing_tables"
    ],
    "select_gemm_impl": [
      "self",
      "prepare_finalize",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "_maybe_pad_weight": [
      "self",
      "weight"
    ],
    "_setup_kernel": [
      "self",
      "layer",
      "w13",
      "w2"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "forward_cuda": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ],
    "forward_monolithic_cpu": [
      "self",
      "layer",
      "x",
      "router_logits"
    ],
    "forward_monolithic_xpu": [
      "self",
      "layer",
      "x",
      "router_logits"
    ]
  },
  "_valid_deep_gemm_shape": [
    "M",
    "N",
    "K"
  ],
  "_valid_deep_gemm": [
    "hidden_states",
    "w1",
    "w2"
  ],
  "DeepGemmExperts": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config"
    ],
    "activation_format": [],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "supports_chunking": [
      "self"
    ],
    "supports_expert_map": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "_act_mul_quant": [
      "self",
      "input",
      "output",
      "activation"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "TritonOrDeepGemmExperts": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config"
    ],
    "get_clses": [],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "_select_experts_impl": [
      "self",
      "hidden_states",
      "w1",
      "w2"
    ]
  },
  "SharedFusedMoE": {
    "__init__": [
      "self",
      "shared_experts",
      "gate",
      "use_overlapped"
    ],
    "shared_experts": [
      "self"
    ],
    "gate": [
      "self"
    ],
    "is_internal_router": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "router_logits"
    ]
  },
  "FusedMoEModularMethod": {
    "__init__": [
      "self",
      "old_quant_method",
      "experts"
    ],
    "make": [
      "moe_layer",
      "old_quant_method",
      "prepare_finalize",
      "shared_experts"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "supports_eplb": [
      "self"
    ],
    "allow_inplace": [
      "self"
    ],
    "method_name": [
      "self"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "scales_shape_stride_dtype": [
    "E",
    "T",
    "G",
    "quant_scale_fmt"
  ],
  "_silu_mul_fp8_quant_deep_gemm": [
    "input_ptr",
    "y_q_ptr",
    "y_s_ptr",
    "counts_ptr",
    "H",
    "GROUP_SIZE",
    "stride_i_e",
    "stride_i_t",
    "stride_i_h",
    "stride_yq_e",
    "stride_yq_t",
    "stride_yq_h",
    "stride_ys_e",
    "stride_ys_t",
    "stride_ys_g",
    "stride_counts_e",
    "eps",
    "fp8_min",
    "fp8_max",
    "ceil_ue8m0",
    "BLOCK",
    "NUM_STAGES"
  ],
  "persistent_masked_m_silu_mul_quant": [
    "y",
    "tokens_per_expert",
    "num_parallel_tokens",
    "group_size",
    "quant_scale_fmt"
  ],
  "BatchedDeepGemmExperts": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config",
      "max_num_tokens",
      "num_dispatchers"
    ],
    "activation_format": [],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "supports_chunking": [
      "self"
    ],
    "supports_expert_map": [
      "self"
    ],
    "supports_packed_ue8m0_act_scales": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "estimate_expected_m": [
      "self",
      "global_num_experts",
      "max_tokens_per_expert",
      "topk"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "maybe_roundup_layer_hidden_size": [
    "hidden_size",
    "act_dtype",
    "moe_parallel_config"
  ],
  "maybe_make_prepare_finalize": [
    "moe",
    "quant_config",
    "routing_tables"
  ],
  "FlashInferCuteDSLExperts": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config",
      "max_num_tokens",
      "num_dispatchers"
    ],
    "activation_format": [],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "supports_expert_map": [
      "self"
    ],
    "supports_chunking": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "get_cute_dtype": [
    "input"
  ],
  "flashinfer_cutedsl_moe_masked": [
    "hidden_states",
    "input_global_scale",
    "w1",
    "w1_blockscale",
    "w1_alpha",
    "w2",
    "a2_global_scale",
    "w2_blockscale",
    "w2_alpha",
    "masked_m",
    "workspace",
    "out"
  ],
  "_count_expert_num_tokens": [
    "topk_ids_ptr",
    "expert_num_tokens_ptr",
    "num_experts",
    "topk_numel",
    "expert_map",
    "HAS_EXPERT_MAP",
    "BLOCK_SIZE"
  ],
  "count_expert_num_tokens": [
    "topk_ids",
    "num_local_experts",
    "expert_map"
  ],
  "_resize_cache": [
    "x",
    "v"
  ],
  "_nvfp4_quantize": [
    "A",
    "A_scale",
    "is_sf_swizzled_layout"
  ],
  "_fp8_quantize": [
    "A",
    "A_scale",
    "per_act_token",
    "block_shape"
  ],
  "_int8_quantize": [
    "A",
    "A_scale",
    "per_act_token",
    "block_shape"
  ],
  "_mxfp4_quantize": [
    "A",
    "A_scale",
    "per_act_token_quant",
    "block_shape"
  ],
  "_mxfp8_e4m3_quantize": [
    "A",
    "A_scale",
    "per_act_token_quant",
    "block_shape"
  ],
  "_mxfp6_e3m2_quantize": [
    "A",
    "A_scale",
    "per_act_token_quant",
    "block_shape"
  ],
  "_mxfp6_e2m3_quantize": [
    "A",
    "A_scale",
    "per_act_token_quant",
    "block_shape"
  ],
  "moe_kernel_quantize_input": [
    "A",
    "A_scale",
    "quant_dtype",
    "per_act_token_quant",
    "block_shape",
    "is_fp4_scale_swizzled"
  ],
  "_fp8_perm": [
    "m",
    "idx"
  ],
  "normalize_scales_shape": [
    "scales"
  ],
  "normalize_batched_scales_shape": [
    "scales",
    "num_experts"
  ],
  "_validate_scale_shape": [
    "a",
    "a_scale",
    "per_act_token_quant",
    "block_shape"
  ],
  "activation_without_mul": [
    "activation"
  ],
  "apply_moe_activation": [
    "activation",
    "output",
    "input"
  ],
  "disable_inplace": [],
  "_fused_marlin_moe": [
    "hidden_states",
    "w1",
    "w2",
    "bias1",
    "bias2",
    "w1_scale",
    "w2_scale",
    "topk_weights",
    "num_topk",
    "quant_type",
    "apply_router_weight_on_input",
    "expert_map",
    "block_size_m",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_post_padded",
    "activation",
    "activation_func",
    "input_global_scale1",
    "input_global_scale2",
    "global_scale1",
    "global_scale2",
    "g_idx1",
    "g_idx2",
    "sort_indices1",
    "sort_indices2",
    "w1_zeros",
    "w2_zeros",
    "workspace",
    "intermediate_cache13",
    "intermediate_cache2",
    "output",
    "input_dtype",
    "is_k_full"
  ],
  "fused_marlin_moe": [
    "hidden_states",
    "w1",
    "w2",
    "bias1",
    "bias2",
    "w1_scale",
    "w2_scale",
    "topk_weights",
    "topk_ids",
    "quant_type_id",
    "apply_router_weight_on_input",
    "global_num_experts",
    "activation",
    "activation_func",
    "moe_sum",
    "expert_map",
    "input_global_scale1",
    "input_global_scale2",
    "global_scale1",
    "global_scale2",
    "g_idx1",
    "g_idx2",
    "sort_indices1",
    "sort_indices2",
    "w1_zeros",
    "w2_zeros",
    "workspace",
    "intermediate_cache13",
    "intermediate_cache2",
    "is_k_full",
    "output",
    "input_dtype",
    "inplace"
  ],
  "batched_fused_marlin_moe": [
    "hidden_states",
    "expert_num_tokens",
    "w1",
    "w2",
    "bias1",
    "bias2",
    "w1_scale",
    "w2_scale",
    "quant_type_id",
    "apply_router_weight_on_input",
    "global_num_experts",
    "activation",
    "expert_map",
    "global_scale1",
    "global_scale2",
    "g_idx1",
    "g_idx2",
    "sort_indices1",
    "sort_indices2",
    "w1_zeros",
    "w2_zeros",
    "workspace",
    "intermediate_cache13",
    "intermediate_cache2",
    "is_k_full",
    "output",
    "inplace"
  ],
  "MarlinExpertsBase": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config",
      "max_num_tokens",
      "num_dispatchers",
      "w13_g_idx",
      "w2_g_idx",
      "w13_g_idx_sort_indices",
      "w2_g_idx_sort_indices",
      "is_k_full"
    ],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "quant_type_id": [
      "self"
    ],
    "moe_problem_size": [
      "self",
      "a1",
      "w1",
      "w2",
      "topk_ids"
    ]
  },
  "MarlinExperts": {
    "supports_expert_map": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "activation_format": [],
    "supports_chunking": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ],
    "moe_sum": [
      "self",
      "input",
      "output"
    ]
  },
  "BatchedMarlinExperts": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config",
      "max_num_tokens",
      "num_dispatchers",
      "w13_g_idx",
      "w2_g_idx",
      "w13_g_idx_sort_indices",
      "w2_g_idx_sort_indices",
      "is_k_full"
    ],
    "supports_expert_map": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "activation_format": [],
    "supports_chunking": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "_moe_permute": [
    "curr_hidden_states",
    "a1q_scale",
    "curr_topk_ids",
    "global_num_experts",
    "expert_map",
    "block_m"
  ],
  "_moe_unpermute_and_reduce": [
    "out",
    "curr_hidden",
    "inv_perm",
    "topk_weight",
    "apply_router_weight_on_input"
  ],
  "moe_permute": [
    "hidden_states",
    "a1q_scale",
    "topk_ids",
    "n_expert",
    "n_local_expert",
    "expert_map",
    "align_block_size",
    "fill_invalid_expert",
    "permuted_hidden_states"
  ],
  "moe_unpermute": [
    "out",
    "permuted_hidden_states",
    "topk_weights",
    "inv_permuted_idx",
    "expert_first_token_offset"
  ],
  "moe_permute_unpermute_supported": [],
  "pplx_hidden_dim_scale_bytes": [
    "max_num_tokens",
    "hidden_dim",
    "in_dtype",
    "quant_dtype",
    "per_act_token_quant",
    "block_shape"
  ],
  "PplxPrepareAndFinalize": {
    "__init__": [
      "self",
      "a2a",
      "max_num_tokens",
      "num_local_experts",
      "num_dispatchers"
    ],
    "activation_format": [
      "self"
    ],
    "max_num_tokens_per_rank": [
      "self"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "num_dispatchers": [
      "self"
    ],
    "output_is_reduced": [
      "self"
    ],
    "supports_async": [
      "self"
    ],
    "prepare_async": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "quant_config"
    ],
    "_receiver": [
      "self",
      "expert_num_tokens",
      "expert_x",
      "expert_x_scale",
      "orig_a_scale_block_shape"
    ],
    "prepare": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "quant_config"
    ],
    "finalize_async": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl"
    ],
    "finalize": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl"
    ]
  },
  "MoriPrepareAndFinalize": {
    "__init__": [
      "self",
      "mori_op",
      "max_tokens_per_rank",
      "num_dispatchers",
      "use_fp8_dispatch"
    ],
    "activation_format": [
      "self"
    ],
    "output_is_reduced": [
      "self"
    ],
    "num_dispatchers": [
      "self"
    ],
    "max_num_tokens_per_rank": [
      "self"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "supports_async": [
      "self"
    ],
    "prepare": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "quant_config"
    ],
    "finalize": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl"
    ]
  },
  "override_config": [
    "config"
  ],
  "get_config": [],
  "DeepEPHTPrepareAndFinalize": {
    "maybe_roundup_layer_hidden_size": [
      "hidden_size",
      "dtype"
    ],
    "__init__": [
      "self",
      "buffer",
      "num_dispatchers",
      "dp_size",
      "rank_expert_offset"
    ],
    "num_dispatchers": [
      "self"
    ],
    "output_is_reduced": [
      "self"
    ],
    "activation_format": [
      "self"
    ],
    "max_num_tokens_per_rank": [
      "self"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "_get_dispatch_config": [
      "self"
    ],
    "_get_combine_config": [
      "self"
    ],
    "_do_dispatch": [
      "self",
      "tokens",
      "token_scales",
      "rank_topk_ids",
      "rank_topk_weights",
      "num_experts",
      "a1_scale",
      "quant_config"
    ],
    "_receiver": [
      "self",
      "event",
      "has_scales",
      "token_data",
      "expert_topk_ids",
      "num_experts",
      "expert_num_tokens_per_expert_list",
      "expert_topk_weights",
      "a1_scale",
      "quant_config"
    ],
    "supports_async": [
      "self"
    ],
    "prepare_async": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "quant_config"
    ],
    "prepare": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "quant_config"
    ],
    "_finalize": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl",
      "do_async"
    ],
    "finalize_async": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl"
    ],
    "finalize": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl"
    ]
  },
  "TritonOrCutlassExperts": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config"
    ],
    "get_clses": [],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "_select_experts_impl": [
      "self",
      "hidden_states",
      "w1",
      "w2"
    ]
  },
  "DEEPEP_QUANT_BLOCK_SIZE": [],
  "DEEPEP_QUANT_BLOCK_SHAPE": [],
  "dequant_fp8": [
    "expert_x_fp8",
    "expert_x_scales"
  ],
  "DeepEPLLPrepareAndFinalize": {
    "SUPPORTED_HIDDEN_SIZES": [],
    "maybe_roundup_layer_hidden_size": [
      "hidden_size"
    ],
    "__init__": [
      "self",
      "buffer",
      "max_tokens_per_rank",
      "num_dispatchers",
      "use_fp8_dispatch",
      "global_to_physical",
      "physical_to_global",
      "local_expert_global_ids"
    ],
    "post_init_setup": [
      "self",
      "fused_experts"
    ],
    "num_dispatchers": [
      "self"
    ],
    "output_is_reduced": [
      "self"
    ],
    "activation_format": [
      "self"
    ],
    "max_num_tokens_per_rank": [
      "self"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "_map_global_to_physical_ids": [
      "self",
      "topk_ids"
    ],
    "_map_local_to_global_ids": [
      "self",
      "expert_topk_ids"
    ],
    "_do_quant": [
      "self",
      "x",
      "a1_dtype",
      "quant_config"
    ],
    "supports_async": [
      "self"
    ],
    "prepare_async": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "quant_config"
    ],
    "_receiver": [
      "self",
      "expert_x",
      "expert_num_tokens",
      "a1_scale",
      "a1_dtype",
      "quant_config"
    ],
    "prepare": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "quant_config"
    ],
    "_finalize": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl",
      "do_async"
    ],
    "finalize_async": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl"
    ],
    "finalize": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl"
    ]
  },
  "is_valid_flashinfer_cutlass_fused_moe": [
    "hidden_states",
    "w1",
    "w2"
  ],
  "FlashInferExperts": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config"
    ],
    "expects_unquantized_inputs": [
      "moe_config",
      "quant_config"
    ],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "activation_format": [],
    "supports_expert_map": [
      "self"
    ],
    "supports_chunking": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ],
    "moe_sum": [
      "self",
      "input",
      "output"
    ]
  },
  "_get_config_dtype_str": [
    "dtype",
    "use_fp8_w8a8",
    "use_fp8_w8a16",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "ocp_mx_scheme"
  ],
  "_quant_flags_to_group_shape": [
    "quant_dtype",
    "per_act_token_quant",
    "per_out_ch_quant",
    "block_shape"
  ],
  "RoutingMethodType": {
    "Default": [],
    "Renormalize": [],
    "DeepSeekV3": [],
    "Llama4": [],
    "RenormalizeNaive": [],
    "TopK": [],
    "Custom": [],
    "Simulated": [],
    "Unspecified": []
  },
  "FusedMoEQuantDesc": {},
  "FusedMoEQuantConfig": {
    "__post_init__": [
      "self"
    ],
    "quant_dtype": [
      "self"
    ],
    "is_quantized": [
      "self"
    ],
    "is_per_act_token": [
      "self"
    ],
    "per_act_token_quant": [
      "self"
    ],
    "per_out_ch_quant": [
      "self"
    ],
    "is_per_tensor": [
      "self"
    ],
    "block_shape": [
      "self"
    ],
    "is_block_quantized": [
      "self"
    ],
    "a1_scale": [
      "self"
    ],
    "a1_gscale": [
      "self"
    ],
    "a2_scale": [
      "self"
    ],
    "a2_gscale": [
      "self"
    ],
    "w1_scale": [
      "self"
    ],
    "w1_zp": [
      "self"
    ],
    "w1_bias": [
      "self"
    ],
    "w1_precision": [
      "self"
    ],
    "g1_alphas": [
      "self"
    ],
    "w2_scale": [
      "self"
    ],
    "w2_zp": [
      "self"
    ],
    "w2_bias": [
      "self"
    ],
    "w2_precision": [
      "self"
    ],
    "g2_alphas": [
      "self"
    ],
    "use_fp8_w8a8": [
      "self"
    ],
    "use_int8_w8a8": [
      "self"
    ],
    "use_int8_w8a16": [
      "self"
    ],
    "use_fp8_w8a16": [
      "self"
    ],
    "use_int4_w4a16": [
      "self"
    ],
    "use_nvfp4_w4a16": [
      "self"
    ],
    "ocp_mx_scheme": [
      "self"
    ],
    "use_mxfp4_w4a16": [
      "self"
    ],
    "use_mxfp4_w4a4": [
      "self"
    ],
    "use_nvfp4_w4a4": [
      "self"
    ],
    "config_name": [
      "self",
      "dtype"
    ],
    "scale_shape": [
      "self",
      "max_tokens",
      "hidden_dim"
    ],
    "batched_scale_shape": [
      "self",
      "num_experts",
      "max_tokens",
      "hidden_dim"
    ],
    "make": [
      "quant_dtype",
      "per_act_token_quant",
      "per_out_ch_quant",
      "block_shape",
      "w1_scale",
      "w2_scale",
      "a1_scale",
      "a2_scale",
      "g1_alphas",
      "g2_alphas",
      "a1_gscale",
      "a2_gscale",
      "w1_bias",
      "w2_bias",
      "w1_zp",
      "w2_zp",
      "weight_dtype"
    ]
  },
  "fp8_w8a8_moe_quant_config": [
    "w1_scale",
    "w2_scale",
    "a1_scale",
    "a2_scale",
    "per_act_token_quant",
    "per_out_ch_quant",
    "block_shape",
    "a1_gscale",
    "a2_gscale",
    "g1_alphas",
    "g2_alphas"
  ],
  "int8_w8a8_moe_quant_config": [
    "w1_scale",
    "w2_scale",
    "a1_scale",
    "a2_scale",
    "per_act_token_quant"
  ],
  "gptq_marlin_moe_quant_config": [
    "w1_scale",
    "w2_scale",
    "weight_bits",
    "group_size",
    "w1_zp",
    "w2_zp",
    "w1_bias",
    "w2_bias"
  ],
  "mxfp4_w4a16_moe_quant_config": [
    "w1_scale",
    "w2_scale",
    "w1_bias",
    "w2_bias"
  ],
  "mxfp4_mxfp8_moe_quant_config": [
    "w1_scale",
    "w2_scale",
    "a1_scale",
    "a2_scale",
    "w1_bias",
    "w2_bias",
    "block_shape"
  ],
  "ocp_mx_moe_quant_config": [
    "quant_dtype",
    "w1_scale",
    "w2_scale",
    "weight_dtype",
    "a1_scale",
    "a2_scale",
    "w1_bias",
    "w2_bias",
    "block_shape"
  ],
  "nvfp4_moe_quant_config": [
    "g1_alphas",
    "g2_alphas",
    "a1_gscale",
    "a2_gscale",
    "w1_scale",
    "w2_scale"
  ],
  "nvfp4_w4a16_moe_quant_config": [
    "g1_alphas",
    "g2_alphas",
    "w1_scale",
    "w2_scale"
  ],
  "int4_w4a16_moe_quant_config": [
    "w1_scale",
    "w2_scale",
    "w1_zp",
    "w2_zp",
    "block_shape"
  ],
  "fp8_w8a16_moe_quant_config": [
    "w1_scale",
    "w2_scale",
    "block_shape"
  ],
  "int8_w8a16_moe_quant_config": [
    "w1_scale",
    "w2_scale",
    "w1_zp",
    "w2_zp",
    "block_shape"
  ],
  "int4_w4afp8_moe_quant_config": [
    "w1_scale",
    "w2_scale",
    "g1_alphas",
    "g2_alphas",
    "per_act_token_quant",
    "per_out_ch_quant",
    "block_shape"
  ],
  "awq_marlin_moe_quant_config": [
    "w1_scale",
    "w2_scale",
    "w1_zp",
    "w2_zp",
    "weight_bits",
    "group_size",
    "w1_bias",
    "w2_bias"
  ],
  "biased_moe_quant_config": [
    "w1_bias",
    "w2_bias"
  ],
  "FusedMoEParallelConfig": {
    "use_all2all_kernels": [
      "self"
    ],
    "use_pplx_kernels": [
      "self"
    ],
    "use_deepep_ht_kernels": [
      "self"
    ],
    "use_deepep_ll_kernels": [
      "self"
    ],
    "use_batched_activation_format": [
      "self"
    ],
    "use_naive_all2all_kernels": [
      "self"
    ],
    "use_mori_kernels": [
      "self"
    ],
    "flatten_tp_across_dp_and_pcp": [
      "tp_size",
      "dp_size",
      "dp_rank",
      "pcp_size",
      "pcp_rank"
    ],
    "make": [
      "tp_size_",
      "pcp_size_",
      "dp_size_",
      "vllm_parallel_config"
    ],
    "make_no_parallel": [
      "cls"
    ]
  },
  "FusedMoEConfig": {
    "__post_init__": [
      "self"
    ],
    "tp_size": [
      "self"
    ],
    "dp_size": [
      "self"
    ],
    "pcp_size": [
      "self"
    ],
    "ep_size": [
      "self"
    ],
    "tp_rank": [
      "self"
    ],
    "dp_rank": [
      "self"
    ],
    "pcp_rank": [
      "self"
    ],
    "ep_rank": [
      "self"
    ],
    "use_ep": [
      "self"
    ],
    "use_pplx_kernels": [
      "self"
    ],
    "use_deepep_ht_kernels": [
      "self"
    ],
    "use_deepep_ll_kernels": [
      "self"
    ],
    "use_mori_kernels": [
      "self"
    ],
    "use_flashinfer_cutlass_kernels": [
      "self"
    ]
  },
  "_CPU_MOE_LAYER_CACHE": [],
  "_swigluoai_forward_native": [
    "x",
    "alpha",
    "limit"
  ],
  "select_experts": [
    "hidden_states",
    "router_logits",
    "top_k",
    "use_grouped_topk",
    "renormalize",
    "topk_group",
    "num_expert_group",
    "custom_routing_function",
    "scoring_func",
    "routed_scaling_factor",
    "e_score_correction_bias"
  ],
  "SGLFusedMOE": {
    "__init__": [
      "self",
      "layer"
    ],
    "__call__": [
      "self",
      "layer",
      "x",
      "use_grouped_topk",
      "top_k",
      "router_logits",
      "renormalize",
      "topk_group",
      "num_expert_group",
      "global_num_experts",
      "expert_map",
      "custom_routing_function",
      "scoring_func",
      "routed_scaling_factor",
      "e_score_correction_bias",
      "apply_router_weight_on_input",
      "activation"
    ]
  },
  "CPUFusedMOE": {
    "__init__": [
      "self",
      "layer"
    ],
    "__call__": [
      "self",
      "layer",
      "x",
      "use_grouped_topk",
      "top_k",
      "router_logits",
      "renormalize",
      "topk_group",
      "num_expert_group",
      "global_num_experts",
      "expert_map",
      "custom_routing_function",
      "scoring_func",
      "routed_scaling_factor",
      "e_score_correction_bias",
      "apply_router_weight_on_input",
      "activation"
    ],
    "check_grouped_gemm": [
      "self",
      "layer"
    ],
    "init_moe_grouped_gemm": [
      "self",
      "layer"
    ],
    "init_moe_torch": [
      "self",
      "layer"
    ],
    "forward_grouped_gemm": [
      "self",
      "layer",
      "input",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts"
    ],
    "forward_torch": [
      "self",
      "layer",
      "input",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts"
    ]
  },
  "cpu_fused_moe_torch": [
    "layer_id",
    "output",
    "input",
    "topk_weights",
    "topk_ids",
    "activation",
    "global_num_experts"
  ],
  "FusedMoeWeightScaleSupported": {
    "TENSOR": [],
    "CHANNEL": [],
    "GROUP": [],
    "BLOCK": []
  },
  "determine_expert_map": [
    "ep_size",
    "ep_rank",
    "global_num_experts",
    "expert_placement_strategy",
    "num_fused_shared_experts",
    "return_expert_mask"
  ],
  "determine_expert_placement_strategy": [
    "expert_placement_strategy",
    "moe_parallel_config",
    "num_expert_group",
    "num_redundant_experts",
    "enable_eplb"
  ],
  "get_compressed_expert_map": [
    "expert_map"
  ],
  "maybe_roundup_hidden_size": [
    "hidden_size",
    "act_dtype",
    "quant_config",
    "moe_parallel_config",
    "is_lora_enabled"
  ],
  "FusedMoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "params_dtype",
      "reduce_results",
      "renormalize",
      "use_grouped_topk",
      "num_expert_group",
      "topk_group",
      "quant_config",
      "tp_size",
      "ep_size",
      "dp_size",
      "pcp_size",
      "prefix",
      "custom_routing_function",
      "scoring_func",
      "routed_scaling_factor",
      "e_score_correction_bias",
      "apply_router_weight_on_input",
      "activation",
      "is_act_and_mul",
      "enable_eplb",
      "num_redundant_experts",
      "has_bias",
      "is_sequence_parallel",
      "expert_mapping",
      "n_shared_experts",
      "router_logits_dtype"
    ],
    "maybe_init_modular_kernel": [
      "self"
    ],
    "shared_experts": [
      "self"
    ],
    "layer_id": [
      "self"
    ],
    "gate": [
      "self"
    ],
    "tp_size": [
      "self"
    ],
    "dp_size": [
      "self"
    ],
    "pcp_size": [
      "self"
    ],
    "ep_size": [
      "self"
    ],
    "tp_rank": [
      "self"
    ],
    "dp_rank": [
      "self"
    ],
    "pcp_rank": [
      "self"
    ],
    "ep_rank": [
      "self"
    ],
    "use_ep": [
      "self"
    ],
    "use_pplx_kernels": [
      "self"
    ],
    "use_deepep_ht_kernels": [
      "self"
    ],
    "use_deepep_ll_kernels": [
      "self"
    ],
    "use_mori_kernels": [
      "self"
    ],
    "use_flashinfer_cutlass_kernels": [
      "self"
    ],
    "use_marlin_kernels": [
      "self"
    ],
    "use_dp_chunking": [
      "self"
    ],
    "is_internal_router": [
      "self"
    ],
    "_maybe_init_expert_routing_tables": [
      "self"
    ],
    "ensure_round_robin_expert_routing_tables": [
      "global_num_experts",
      "ep_size",
      "ep_rank",
      "local_num_experts",
      "device"
    ],
    "update_expert_map": [
      "self"
    ],
    "_maybe_setup_shared_experts_stream": [
      "self",
      "hidden_states",
      "has_separate_shared_experts",
      "use_chunked_impl"
    ],
    "_load_per_tensor_weight_scale": [
      "self",
      "shard_id",
      "param",
      "loaded_weight",
      "expert_id"
    ],
    "_load_combined_w13_weight_scale": [
      "self",
      "shard_dim",
      "loaded_weight",
      "param",
      "tp_rank"
    ],
    "_load_model_weight_or_group_weight_scale": [
      "self",
      "shard_dim",
      "expert_data",
      "shard_id",
      "loaded_weight",
      "tp_rank",
      "load_full_w2"
    ],
    "_load_per_channel_weight_scale": [
      "self",
      "expert_data",
      "shard_dim",
      "shard_id",
      "loaded_weight",
      "tp_rank"
    ],
    "_load_w13": [
      "self",
      "expert_data",
      "shard_dim",
      "shard_id",
      "loaded_weight",
      "tp_rank",
      "load_full"
    ],
    "_load_w2": [
      "self",
      "expert_data",
      "shard_dim",
      "loaded_weight",
      "tp_rank",
      "load_full"
    ],
    "_load_single_value": [
      "self",
      "param",
      "loaded_weight",
      "expert_id"
    ],
    "_load_g_idx": [
      "self",
      "shard_id",
      "expert_data",
      "shard_dim",
      "loaded_weight",
      "tp_rank"
    ],
    "_map_global_expert_id_to_local_expert_id": [
      "self",
      "expert_id"
    ],
    "_init_aiter_shared_experts_topK_buffer": [
      "self",
      "vllm_config",
      "dp_size"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "weight_name",
      "shard_id",
      "expert_id",
      "return_success"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_weights": [
      "self"
    ],
    "set_eplb_state": [
      "self",
      "moe_layer_idx",
      "expert_load_view",
      "logical_to_physical_map",
      "logical_replica_count"
    ],
    "ensure_moe_quant_config_init": [
      "self"
    ],
    "moe_quant_config": [
      "self"
    ],
    "ensure_dp_chunking_init": [
      "self"
    ],
    "must_reduce_shared_expert_outputs": [
      "self"
    ],
    "maybe_all_reduce_tensor_model_parallel": [
      "self",
      "final_hidden_states"
    ],
    "forward_native": [
      "self",
      "hidden_states",
      "router_logits"
    ],
    "expert_map": [
      "self"
    ],
    "forward_cuda": [
      "self",
      "hidden_states",
      "router_logits"
    ],
    "forward_impl_chunked": [
      "self",
      "full_hidden_states",
      "full_router_logits",
      "has_separate_shared_experts"
    ],
    "forward_impl": [
      "self",
      "hidden_states",
      "router_logits"
    ],
    "make_expert_params_mapping": [
      "cls",
      "model",
      "ckpt_gate_proj_name",
      "ckpt_down_proj_name",
      "ckpt_up_proj_name",
      "num_experts",
      "num_redundant_experts"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "get_layer_from_name": [
    "layer_name"
  ],
  "moe_forward": [
    "hidden_states",
    "router_logits",
    "layer_name"
  ],
  "moe_forward_fake": [
    "hidden_states",
    "router_logits",
    "layer_name"
  ],
  "moe_forward_shared": [
    "hidden_states",
    "router_logits",
    "layer_name"
  ],
  "moe_forward_shared_fake": [
    "hidden_states",
    "router_logits",
    "layer_name"
  ],
  "FusedMoEMethodBase": {
    "__init__": [
      "self",
      "moe"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "uses_weight_scale_2_pattern": [
      "self"
    ],
    "maybe_make_prepare_finalize": [
      "self",
      "routing_tables"
    ],
    "select_gemm_impl": [
      "self",
      "prepare_finalize",
      "layer"
    ],
    "prepare_dp_allgather_tensor": [
      "self",
      "layer",
      "hidden_states",
      "router_logits"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "supports_eplb": [
      "self"
    ],
    "allow_inplace": [
      "self"
    ],
    "method_name": [
      "self"
    ],
    "is_monolithic": [
      "self"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ],
    "apply_monolithic": [
      "self",
      "layer",
      "x",
      "router_logits"
    ]
  },
  "_TMP_DIR": [],
  "_LOCK_FILE_PREFIX": [],
  "_BUFFER_PREFIX": [],
  "_file_lock": [
    "lock_file",
    "mode"
  ],
  "_create_or_attach_shared_memory": [
    "name",
    "size",
    "lock_file"
  ],
  "RoutedExpertsCapturer": {
    "__init__": [
      "self"
    ],
    "create": [
      "cls"
    ],
    "get_instance": [],
    "init_buffer": [
      "self",
      "max_num_batched_tokens",
      "max_num_kv_tokens",
      "vllm_config"
    ],
    "capture": [
      "self",
      "layer_id",
      "topk_ids"
    ],
    "clear_buffer": [
      "self"
    ],
    "save_captured_experts": [
      "self",
      "indices"
    ],
    "cleanup": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "RoutedExpertsReader": {
    "__init__": [
      "self"
    ],
    "create": [
      "cls"
    ],
    "get_instance": [],
    "attach_buffer": [
      "self",
      "max_num_kv_tokens",
      "vllm_config"
    ],
    "get_routed_experts": [
      "self",
      "indices"
    ],
    "cleanup": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "run_cutlass_moe_fp8": [
    "output",
    "hidden_states",
    "w1",
    "w2",
    "topk_ids",
    "activation",
    "global_num_experts",
    "expert_map",
    "w1_scale",
    "w2_scale",
    "a1q_scale",
    "a2_scale",
    "ab_strides1",
    "ab_strides2",
    "c_strides1",
    "c_strides2",
    "workspace13",
    "workspace2",
    "expert_num_tokens",
    "out_dtype",
    "per_act_token",
    "per_out_ch",
    "use_batched_format",
    "topk_weights"
  ],
  "CutlassExpertsFp8Base": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config",
      "max_num_tokens",
      "num_dispatchers"
    ],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "CutlassExpertsFp8": {
    "activation_format": [],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "supports_chunking": [
      "self"
    ],
    "supports_expert_map": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "workspace_dtype": [
      "self",
      "act_dtype"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ]
  },
  "CutlassBatchedExpertsFp8": {
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "activation_format": [],
    "supports_chunking": [
      "self"
    ],
    "supports_expert_map": [
      "self"
    ],
    "workspace_dtype": [
      "self",
      "act_dtype"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ]
  },
  "FLOAT4_E2M1_MAX": [],
  "FLOAT8_E4M3_MAX": [],
  "run_cutlass_moe_fp4": [
    "output",
    "a",
    "a1_gscale",
    "w1_fp4",
    "w1_blockscale",
    "w1_alphas",
    "a2_gscale",
    "w2_fp4",
    "w2_blockscale",
    "w2_alphas",
    "topk_weights",
    "topk_ids",
    "activation",
    "workspace13",
    "workspace2",
    "m",
    "n",
    "k",
    "e",
    "device",
    "apply_router_weight_on_input"
  ],
  "CutlassExpertsFp4": {
    "expects_unquantized_inputs": [
      "moe_config",
      "quant_config"
    ],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "activation_format": [],
    "supports_expert_map": [
      "self"
    ],
    "supports_chunking": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "workspace_dtype": [
      "self",
      "act_dtype"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "run_cutlass_moe_w4a8_fp8": [
    "output",
    "hidden_states",
    "w1",
    "w2",
    "topk_ids",
    "activation",
    "global_num_experts",
    "expert_map",
    "w1_scale",
    "w2_scale",
    "a1q_scale",
    "a2_scale",
    "w1_chan_scale",
    "w2_chan_scale",
    "a_strides1",
    "a_strides2",
    "b_strides1",
    "b_strides2",
    "c_strides1",
    "c_strides2",
    "s_strides1",
    "s_strides2",
    "workspace13",
    "workspace2",
    "expert_num_tokens",
    "out_dtype",
    "per_act_token",
    "per_out_ch",
    "use_batched_format",
    "topk_weights",
    "group_size"
  ],
  "CutlassExpertsW4A8Fp8": {
    "__init__": [
      "self",
      "out_dtype",
      "a_strides1",
      "a_strides2",
      "b_strides1",
      "b_strides2",
      "c_strides1",
      "c_strides2",
      "s_strides1",
      "s_strides2",
      "moe_config",
      "quant_config",
      "group_size"
    ],
    "activation_format": [],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "supports_chunking": [
      "self"
    ],
    "supports_expert_map": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "workspace_dtype": [
      "self",
      "act_dtype"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "cutlass_moe_w4a8_fp8": [
    "a",
    "w1_q",
    "w2_q",
    "topk_weights",
    "topk_ids",
    "a_strides1",
    "a_strides2",
    "b_strides1",
    "b_strides2",
    "c_strides1",
    "c_strides2",
    "s_strides1",
    "s_strides2",
    "quant_config",
    "moe_config",
    "activation",
    "expert_map",
    "apply_router_weight_on_input",
    "global_num_experts",
    "group_size"
  ],
  "TrtLlmGenExperts": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config",
      "gemm1_alpha",
      "gemm1_beta",
      "gemm1_clamp_limit",
      "max_capture_size"
    ],
    "activation_format": [],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "supports_chunking": [
      "self"
    ],
    "supports_expert_map": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "moe_mmk": [
    "a_ptrs",
    "b_ptrs",
    "K",
    "expert_id",
    "a_scale_ptr",
    "b_scale_ptr",
    "stride_ak",
    "stride_bk",
    "stride_ase",
    "stride_asm",
    "stride_ask",
    "stride_bse",
    "stride_bsk",
    "stride_bsn",
    "offs_m",
    "offs_n",
    "offs_bn",
    "mask_m",
    "group_n",
    "group_k",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "compute_type",
    "use_w8a8",
    "use_w8a16",
    "per_act_token_quant"
  ],
  "expert_triton_kernel": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "expert_id",
    "compute_type",
    "M",
    "N",
    "K",
    "a_scale_ptr",
    "b_scale_ptr",
    "b_zp_ptr",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "stride_ase",
    "stride_asm",
    "stride_ask",
    "stride_bse",
    "stride_bsk",
    "stride_bsn",
    "offs_bn",
    "group_n",
    "group_k",
    "use_fp8_w8a8",
    "use_int8_w8a16",
    "per_act_token_quant",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K"
  ],
  "batched_triton_kernel": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "expert_num_tokens",
    "compute_type",
    "max_num_tokens",
    "K",
    "N",
    "a_scale_ptr",
    "b_scale_ptr",
    "b_zp_ptr",
    "stride_ae",
    "stride_am",
    "stride_ak",
    "stride_be",
    "stride_bk",
    "stride_bn",
    "stride_ce",
    "stride_cm",
    "stride_cn",
    "stride_ase",
    "stride_asm",
    "stride_ask",
    "stride_bse",
    "stride_bsk",
    "stride_bsn",
    "group_n",
    "group_k",
    "use_fp8_w8a8",
    "use_int8_w8a16",
    "per_act_token_quant",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K"
  ],
  "invoke_moe_batched_triton_kernel": [
    "A",
    "B",
    "C",
    "expert_num_tokens",
    "compute_type",
    "A_scale",
    "B_scale",
    "B_zp",
    "use_fp8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "config",
    "per_act_token_quant",
    "block_shape"
  ],
  "BatchedPrepareAndFinalize": {
    "__init__": [
      "self",
      "max_num_tokens",
      "num_local_experts",
      "num_dispatchers",
      "rank"
    ],
    "activation_format": [
      "self"
    ],
    "max_num_tokens_per_rank": [
      "self"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "num_dispatchers": [
      "self"
    ],
    "output_is_reduced": [
      "self"
    ],
    "prepare": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "quant_config"
    ],
    "finalize": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl"
    ]
  },
  "NaiveBatchedExperts": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config",
      "max_num_tokens",
      "num_dispatchers"
    ],
    "activation_format": [],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "supports_chunking": [
      "self"
    ],
    "supports_expert_map": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "dequant": [
      "self",
      "t",
      "scale"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "batched_moe_kernel_quantize_input": [
    "A",
    "A_scale",
    "num_tokens",
    "E",
    "N",
    "expert_num_tokens",
    "qtype",
    "per_act_token_quant",
    "block_shape"
  ],
  "BatchedTritonExperts": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config",
      "max_num_tokens",
      "num_dispatchers"
    ],
    "activation_format": [],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "supports_chunking": [
      "self"
    ],
    "supports_expert_map": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "get_local_sizes": [],
  "FlashInferCutlassMoEPrepareAndFinalize": {
    "__init__": [
      "self",
      "use_dp",
      "num_dispatchers",
      "use_deepseek_fp8_block_scale"
    ],
    "activation_format": [
      "self"
    ],
    "max_num_tokens_per_rank": [
      "self"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "num_dispatchers": [
      "self"
    ],
    "output_is_reduced": [
      "self"
    ],
    "_apply_router_weight_on_input": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input"
    ]
  },
  "FlashInferAllToAllMoEPrepareAndFinalize": {
    "__init__": [
      "self",
      "use_dp",
      "num_dispatchers",
      "use_deepseek_fp8_block_scale"
    ],
    "prepare": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "quant_config"
    ],
    "finalize": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl"
    ]
  },
  "FlashInferAllGatherMoEPrepareAndFinalize": {
    "__init__": [
      "self",
      "use_dp",
      "num_dispatchers",
      "use_deepseek_fp8_block_scale"
    ],
    "prepare": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "quant_config"
    ],
    "finalize": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl"
    ]
  },
  "flashinfer_alltoall_dispatch": [
    "all2all_manager",
    "global_num_tokens_cpu",
    "x",
    "gs",
    "topk_ids",
    "topk_weights",
    "top_k",
    "num_experts",
    "quant_config",
    "use_deepseek_fp8_block_scale"
  ],
  "flashinfer_alltoall_combine": [
    "all2all_manager",
    "output",
    "top_k",
    "token_count",
    "alltoall_info"
  ],
  "create_flashinfer_prepare_finalize": [
    "use_dp",
    "use_nvfp4",
    "enable_alltoallv",
    "use_deepseek_fp8_block_scale"
  ],
  "pack_bitmatrix": [
    "bitmatrix",
    "topk_ids",
    "n_rows",
    "bm_cols",
    "n_expts_act",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_K"
  ],
  "triton_kernel_moe_forward": [
    "hidden_states",
    "w1",
    "w2",
    "gating_output",
    "topk",
    "renormalize",
    "activation",
    "quant_config",
    "apply_router_weight_on_input",
    "global_num_experts",
    "expert_map"
  ],
  "triton_kernel_fused_experts": [
    "output_tensor",
    "hidden_states",
    "w1",
    "w2",
    "routing_data",
    "gather_indx",
    "scatter_indx",
    "topk",
    "activation",
    "quant_config",
    "swiglu_alpha",
    "swiglu_limit",
    "apply_router_weight_on_input",
    "global_num_experts",
    "expert_map",
    "intermediate_cache",
    "a1q_scale"
  ],
  "make_routing_data": [
    "topk_ids",
    "topk_weights",
    "num_local_experts"
  ],
  "BaseOAITritonExperts": {
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "supports_expert_map": [
      "self"
    ],
    "moe_problem_size": [
      "self",
      "a1",
      "w1",
      "w2",
      "topk_ids"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "_make_routing_data": [
      "self",
      "topk_ids",
      "topk_weights",
      "num_local_experts"
    ]
  },
  "OAITritonExperts": {
    "activation_format": [],
    "supports_chunking": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "UnfusedOAITritonExperts": {
    "activation_format": [],
    "supports_chunking": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "moe_sum": [
      "self",
      "input",
      "output"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "_supports_current_device": [],
  "_supports_no_act_and_mul": [],
  "_supports_quant_scheme": [
    "weight_key",
    "activation_key"
  ],
  "_supports_activation": [
    "activation"
  ],
  "_supports_routing_method": [
    "weight_key",
    "activation_key",
    "routing_method"
  ],
  "_supports_parallel_config": [
    "moe_parallel_config"
  ],
  "_supports_router_logits_dtype": [
    "router_logits_dtype",
    "routing_method"
  ],
  "is_supported_config_trtllm_fp8": [
    "moe_config",
    "weight_key",
    "activation_key",
    "activation_format"
  ],
  "flashinfer_fused_moe_blockscale_fp8": [
    "routing_logits",
    "routing_bias",
    "x",
    "w13_weight",
    "w13_weight_scale_inv",
    "w2_weight",
    "w2_weight_scale_inv",
    "global_num_experts",
    "top_k",
    "num_expert_group",
    "topk_group",
    "intermediate_size",
    "expert_offset",
    "local_num_experts",
    "block_shape",
    "routing_method_type",
    "routed_scaling"
  ],
  "flashinfer_fused_moe_blockscale_fp8_fake": [
    "routing_logits",
    "routing_bias",
    "x",
    "w13_weight",
    "w13_weight_scale_inv",
    "w2_weight",
    "w2_weight_scale_inv",
    "global_num_experts",
    "top_k",
    "num_expert_group",
    "topk_group",
    "intermediate_size",
    "expert_offset",
    "local_num_experts",
    "block_shape",
    "routing_method_type",
    "routed_scaling"
  ],
  "fi_trtllm_fp8_per_tensor_moe": [
    "routing_logits",
    "routing_bias",
    "hidden_states",
    "input_scale",
    "gemm1_weights",
    "gemm2_weights",
    "output1_scales_scalar",
    "output1_scales_gate_scalar",
    "output2_scales_scalar",
    "num_experts",
    "top_k",
    "num_expert_group",
    "topk_group",
    "intermediate_size",
    "local_expert_offset",
    "local_num_experts",
    "use_routing_scales_on_input",
    "routing_method_type",
    "routed_scaling_factor"
  ],
  "fi_trtllm_fp8_per_tensor_moe_fake": [
    "routing_logits",
    "routing_bias",
    "hidden_states",
    "input_scale",
    "gemm1_weights",
    "gemm2_weights",
    "output1_scales_scalar",
    "output1_scales_gate_scalar",
    "output2_scales_scalar",
    "num_experts",
    "top_k",
    "num_expert_group",
    "topk_group",
    "intermediate_size",
    "local_expert_offset",
    "local_num_experts",
    "use_routing_scales_on_input",
    "routing_method_type",
    "routed_scaling_factor"
  ],
  "ZeroExpertFusedMoE": {
    "__init__": [
      "self",
      "zero_expert_num",
      "zero_expert_type",
      "router"
    ],
    "_temporarily_set_attrs": [
      "self"
    ],
    "_compute_zero_expert_result": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids"
    ],
    "forward": [
      "self",
      "hidden_states",
      "router_logits"
    ]
  },
  "MoEPrepareAndFinalizeNoEP": {
    "__init__": [
      "self",
      "defer_input_quant"
    ],
    "activation_format": [
      "self"
    ],
    "max_num_tokens_per_rank": [
      "self"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "num_dispatchers": [
      "self"
    ],
    "output_is_reduced": [
      "self"
    ],
    "prepare": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "quant_config"
    ],
    "finalize": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl"
    ]
  },
  "FallbackExperts": {
    "__init__": [
      "self",
      "experts",
      "fallback_experts"
    ],
    "get_clses": [],
    "activation_format": [
      "cls"
    ],
    "_supports_current_device": [
      "cls"
    ],
    "_supports_no_act_and_mul": [
      "cls"
    ],
    "_supports_quant_scheme": [
      "cls",
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "cls",
      "activation"
    ],
    "_supports_parallel_config": [
      "cls",
      "moe_parallel_config"
    ],
    "supports_chunking": [
      "self"
    ],
    "supports_expert_map": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "_select_experts_impl": [
      "self",
      "hidden_states",
      "w1",
      "w2"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "QuantMethod": {
    "NO": [],
    "PER_TENSOR": [],
    "PER_TOKEN": [],
    "BLOCK_1X32": [],
    "BLOCK_1X128": [],
    "BLOCK_128x128": []
  },
  "ActivationMethod": {
    "SILU": [],
    "GELU": []
  },
  "aiter_topK_meta_data": [],
  "init_aiter_topK_meta_data": [
    "n_routed_experts",
    "n_shared_experts",
    "top_k",
    "tp_rank",
    "tp_size",
    "shared_experts_score",
    "max_num_tokens",
    "is_EP"
  ],
  "rocm_aiter_grouped_topk": [
    "hidden_states",
    "gating_output",
    "topk",
    "renormalize",
    "num_expert_group",
    "topk_group",
    "scoring_func",
    "routed_scaling_factor",
    "e_score_correction_bias",
    "num_fused_shared_experts"
  ],
  "rocm_aiter_fused_experts": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "activation",
    "apply_router_weight_on_input",
    "expert_map",
    "quant_config",
    "a1q_scale",
    "num_local_tokens",
    "output_dtype"
  ],
  "AiterExperts": {
    "activation_format": [],
    "expects_unquantized_inputs": [
      "fused_moe_config",
      "quant_config"
    ],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "supports_expert_map": [
      "self"
    ],
    "supports_chunking": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "FusedMoEActivationFormat": {
    "Standard": [],
    "BatchedExperts": []
  },
  "ExpertTokensMetadata": {
    "make_from_list": [
      "expert_num_tokens_list",
      "device"
    ]
  },
  "TopKWeightAndReduce": {
    "apply": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input"
    ]
  },
  "PrepareResultType": [],
  "ReceiverType": [],
  "FusedMoEPrepareAndFinalize": {
    "post_init_setup": [
      "self",
      "fused_experts"
    ],
    "prepare": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "quant_config"
    ],
    "supports_async": [
      "self"
    ],
    "prepare_async": [
      "self",
      "a1",
      "topk_weights",
      "topk_ids",
      "num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "quant_config"
    ],
    "finalize": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl"
    ],
    "finalize_async": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input",
      "weight_and_reduce_impl"
    ],
    "activation_format": [
      "self"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "max_num_tokens_per_rank": [
      "self"
    ],
    "num_dispatchers": [
      "self"
    ],
    "output_is_reduced": [
      "self"
    ]
  },
  "FusedMoEPermuteExpertsUnpermute": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config",
      "max_num_tokens",
      "num_dispatchers"
    ],
    "expects_unquantized_inputs": [
      "moe_config",
      "quant_config"
    ],
    "activation_format": [],
    "moe_problem_size": [
      "self",
      "a1",
      "w1",
      "w2",
      "topk_ids"
    ],
    "is_supported_config": [
      "cls",
      "moe_config",
      "weight_key",
      "activation_key",
      "activation_format"
    ],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "quant_dtype": [
      "self"
    ],
    "block_shape": [
      "self"
    ],
    "per_act_token_quant": [
      "self"
    ],
    "per_out_ch_quant": [
      "self"
    ],
    "a1_scale": [
      "self"
    ],
    "a2_scale": [
      "self"
    ],
    "a1_gscale": [
      "self"
    ],
    "a2_gscale": [
      "self"
    ],
    "w1_scale": [
      "self"
    ],
    "w2_scale": [
      "self"
    ],
    "w1_zp": [
      "self"
    ],
    "w2_zp": [
      "self"
    ],
    "w1_bias": [
      "self"
    ],
    "w2_bias": [
      "self"
    ],
    "g1_alphas": [
      "self"
    ],
    "g2_alphas": [
      "self"
    ],
    "supports_chunking": [
      "self"
    ],
    "supports_expert_map": [
      "self"
    ],
    "supports_packed_ue8m0_act_scales": [
      "self"
    ],
    "workspace_dtype": [
      "self",
      "act_dtype"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "adjust_N_for_activation": [
      "N",
      "activation"
    ],
    "activation": [
      "self",
      "activation",
      "output",
      "input"
    ],
    "enable_chunking": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "_slice_scales": [
    "scales",
    "start",
    "end"
  ],
  "FusedMoEModularKernel": {
    "__init__": [
      "self",
      "prepare_finalize",
      "fused_experts",
      "shared_experts",
      "moe_parallel_config"
    ],
    "_post_init_setup": [
      "self"
    ],
    "supports_expert_map": [
      "self"
    ],
    "output_is_reduced": [
      "self"
    ],
    "_chunk_info": [
      "self",
      "M"
    ],
    "_allocate_buffers": [
      "self",
      "out_dtype",
      "device",
      "M_chunk",
      "M_full",
      "N",
      "K",
      "top_k",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "_slice_output_tensor": [
      "fused_out",
      "chunk_idx",
      "num_chunks",
      "CHUNK_SIZE",
      "M"
    ],
    "_slice_expert_tokens_metadata": [
      "num_chunks",
      "full_expert_tokens_meta",
      "chunk_topk_ids",
      "local_num_experts",
      "expert_map"
    ],
    "_prepare": [
      "self",
      "hidden_states",
      "topk_weights",
      "topk_ids",
      "global_num_experts",
      "expert_map",
      "apply_router_weight_on_input"
    ],
    "_fused_experts": [
      "self",
      "in_dtype",
      "a1q",
      "a1q_scale",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "local_num_experts",
      "expert_map",
      "apply_router_weight_on_input",
      "expert_tokens_meta"
    ],
    "_finalize": [
      "self",
      "output",
      "fused_out",
      "hidden_states",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input"
    ],
    "forward": [
      "self",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "inplace",
      "activation",
      "global_num_experts",
      "expert_map",
      "apply_router_weight_on_input"
    ]
  },
  "write_zeros_to_output": [
    "c_ptr",
    "stride_cm",
    "stride_cn",
    "pid_n",
    "N",
    "offs_token",
    "token_mask",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "compute_type"
  ],
  "fused_moe_kernel_gptq_awq": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "b_scale_ptr",
    "b_zp_ptr",
    "topk_weights_ptr",
    "sorted_token_ids_ptr",
    "expert_ids_ptr",
    "num_tokens_post_padded_ptr",
    "N",
    "K",
    "EM",
    "num_valid_tokens",
    "stride_am",
    "stride_ak",
    "stride_be",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "stride_bse",
    "stride_bsk",
    "stride_bsn",
    "stride_bze",
    "stride_bzk",
    "stride_bzn",
    "block_k_diviable",
    "group_size",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "SPLIT_K",
    "MUL_ROUTED_WEIGHT",
    "top_k",
    "compute_type",
    "has_zp",
    "use_int4_w4a16",
    "use_int8_w8a16"
  ],
  "fused_moe_kernel": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "b_bias_ptr",
    "a_scale_ptr",
    "b_scale_ptr",
    "topk_weights_ptr",
    "sorted_token_ids_ptr",
    "expert_ids_ptr",
    "num_tokens_post_padded_ptr",
    "N",
    "K",
    "EM",
    "num_valid_tokens",
    "stride_am",
    "stride_ak",
    "stride_be",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "stride_asm",
    "stride_ask",
    "stride_bse",
    "stride_bsk",
    "stride_bsn",
    "stride_bbe",
    "stride_bbn",
    "group_n",
    "group_k",
    "naive_block_assignment",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "SPLIT_K",
    "MUL_ROUTED_WEIGHT",
    "top_k",
    "compute_type",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "per_channel_quant",
    "HAS_BIAS"
  ],
  "invoke_fused_moe_wna16_cuda_kernel": [
    "A",
    "B",
    "C",
    "B_scale",
    "B_zp",
    "topk_weights",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_post_padded",
    "mul_routed_weight",
    "top_k",
    "config",
    "block_shape"
  ],
  "invoke_fused_moe_wna16_triton_kernel": [
    "A",
    "B",
    "C",
    "B_scale",
    "B_zp",
    "topk_weights",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_post_padded",
    "mul_routed_weight",
    "top_k",
    "config",
    "compute_type",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "block_shape"
  ],
  "invoke_fused_moe_triton_kernel": [
    "A",
    "B",
    "C",
    "A_scale",
    "B_scale",
    "topk_weights",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_post_padded",
    "mul_routed_weight",
    "top_k",
    "config",
    "compute_type",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "per_channel_quant",
    "block_shape",
    "B_bias"
  ],
  "dispatch_fused_moe_kernel": [
    "A",
    "B",
    "C",
    "A_scale",
    "B_scale",
    "B_zp",
    "topk_weights",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_post_padded",
    "mul_routed_weight",
    "top_k",
    "config",
    "compute_type",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "per_channel_quant",
    "block_shape",
    "B_bias"
  ],
  "compute_identity_kernel": [
    "top_k",
    "hidden_states_ptr",
    "expert_scales_ptr",
    "num_tokens",
    "output_ptr",
    "hidden_dim",
    "scales_stride",
    "BLOCK_SIZE"
  ],
  "zero_experts_compute_triton": [
    "expert_indices",
    "expert_scales",
    "num_experts",
    "zero_expert_type",
    "hidden_states"
  ],
  "get_config_file_name": [
    "E",
    "N",
    "dtype",
    "block_shape"
  ],
  "get_moe_configs": [
    "E",
    "N",
    "dtype",
    "block_n",
    "block_k"
  ],
  "_ensure_block_size_k_divisible": [
    "size_k",
    "block_size_k",
    "group_size"
  ],
  "get_moe_wna16_block_config": [
    "config",
    "use_moe_wna16_cuda",
    "num_valid_tokens",
    "size_k",
    "size_n",
    "num_experts",
    "group_size",
    "real_top_k",
    "block_size_m"
  ],
  "should_moe_wna16_use_cuda": [
    "num_valid_tokens",
    "group_size",
    "num_experts",
    "bit"
  ],
  "get_default_config": [
    "M",
    "E",
    "N",
    "K",
    "topk",
    "dtype",
    "block_shape"
  ],
  "try_get_optimal_moe_config": [
    "w1_shape",
    "w2_shape",
    "top_k",
    "dtype",
    "M",
    "block_shape"
  ],
  "inplace_fused_experts": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "activation",
    "apply_router_weight_on_input",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "ocp_mx_scheme",
    "per_channel_quant",
    "global_num_experts",
    "expert_map",
    "w1_scale",
    "w2_scale",
    "w1_zp",
    "w2_zp",
    "a1_scale",
    "a2_scale",
    "block_shape",
    "w1_bias",
    "w2_bias"
  ],
  "inplace_fused_experts_fake": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "activation",
    "apply_router_weight_on_input",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "ocp_mx_scheme",
    "per_channel_quant",
    "global_num_experts",
    "expert_map",
    "w1_scale",
    "w2_scale",
    "w1_zp",
    "w2_zp",
    "a1_scale",
    "a2_scale",
    "block_shape",
    "w1_bias",
    "w2_bias"
  ],
  "outplace_fused_experts": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "activation",
    "apply_router_weight_on_input",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "ocp_mx_scheme",
    "per_channel_quant",
    "global_num_experts",
    "expert_map",
    "w1_scale",
    "w2_scale",
    "w1_zp",
    "w2_zp",
    "a1_scale",
    "a2_scale",
    "block_shape",
    "w1_bias",
    "w2_bias"
  ],
  "outplace_fused_experts_fake": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "activation",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "ocp_mx_scheme",
    "per_channel_quant",
    "global_num_experts",
    "expert_map",
    "w1_scale",
    "w2_scale",
    "w1_zp",
    "w2_zp",
    "a1_scale",
    "a2_scale",
    "block_shape",
    "w1_bias",
    "w2_bias"
  ],
  "torch_vllm_inplace_fused_experts": [],
  "torch_vllm_outplace_fused_experts": [],
  "dispatch_fused_experts_func": [
    "inplace"
  ],
  "fused_experts": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "inplace",
    "activation",
    "apply_router_weight_on_input",
    "global_num_experts",
    "expert_map",
    "quant_config"
  ],
  "_get_config_quant_dtype": [
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "ocp_mx_scheme"
  ],
  "fused_experts_impl": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "inplace",
    "activation",
    "apply_router_weight_on_input",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "ocp_mx_scheme",
    "per_channel_quant",
    "global_num_experts",
    "expert_map",
    "w1_scale",
    "w2_scale",
    "w1_zp",
    "w2_zp",
    "a1_scale",
    "a2_scale",
    "block_shape",
    "w1_bias",
    "w2_bias"
  ],
  "TritonExperts": {
    "__init__": [
      "self",
      "moe_config",
      "quant_config"
    ],
    "activation_format": [],
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "supports_chunking": [
      "self"
    ],
    "supports_expert_map": [
      "self"
    ],
    "finalize_weight_and_reduce_impl": [
      "self"
    ],
    "workspace_shapes": [
      "self",
      "M",
      "N",
      "K",
      "topk",
      "global_num_experts",
      "local_num_experts",
      "expert_tokens_meta",
      "activation"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ],
    "moe_sum": [
      "self",
      "input",
      "output"
    ]
  },
  "TritonWNA16Experts": {
    "_supports_current_device": [],
    "_supports_no_act_and_mul": [],
    "_supports_quant_scheme": [
      "weight_key",
      "activation_key"
    ],
    "_supports_activation": [
      "activation"
    ],
    "_supports_parallel_config": [
      "moe_parallel_config"
    ],
    "apply": [
      "self",
      "output",
      "hidden_states",
      "w1",
      "w2",
      "topk_weights",
      "topk_ids",
      "activation",
      "global_num_experts",
      "expert_map",
      "a1q_scale",
      "a2_scale",
      "workspace13",
      "workspace2",
      "expert_tokens_meta",
      "apply_router_weight_on_input"
    ]
  },
  "modular_triton_fused_moe": [
    "moe_config",
    "quant_config",
    "shared_experts"
  ],
  "expert_num_tokens_round_up_and_sum": [
    "expert_num_tokens",
    "alignment"
  ],
  "compute_aligned_M": [
    "M",
    "num_topk",
    "local_num_experts",
    "alignment",
    "expert_tokens_meta"
  ],
  "apply_expert_map": [
    "expert_id",
    "expert_map"
  ],
  "round_up_128": [
    "x"
  ],
  "_fwd_kernel_ep_scatter_1": [
    "num_recv_tokens_per_expert",
    "expert_start_loc",
    "m_indices",
    "num_experts",
    "BLOCK_E",
    "BLOCK_EXPERT_NUM"
  ],
  "_fwd_kernel_ep_scatter_2": [
    "total_token_num",
    "expert_start_loc",
    "recv_x",
    "recv_x_stride0",
    "recv_x_stride1",
    "recv_x_scale",
    "recv_x_scale_stride0",
    "recv_x_scale_stride1",
    "recv_topk",
    "recv_topk_stride0",
    "recv_topk_stride1",
    "output_tensor",
    "output_tensor_stride0",
    "output_tensor_stride1",
    "output_tensor_scale",
    "output_tensor_scale_stride0",
    "output_tensor_scale_stride1",
    "output_index",
    "output_index_stride0",
    "output_index_stride1",
    "topk_num",
    "expert_map",
    "HAS_EXPERT_MAP",
    "HIDDEN_SIZE",
    "HIDDEN_SIZE_PAD",
    "SCALE_HIDDEN_SIZE",
    "SCALE_HIDDEN_SIZE_PAD"
  ],
  "ep_scatter": [
    "recv_x",
    "recv_x_scale",
    "recv_topk",
    "num_recv_tokens_per_expert",
    "expert_map",
    "expert_start_loc",
    "output_tensor",
    "output_tensor_scale",
    "m_indices",
    "output_index"
  ],
  "_fwd_kernel_ep_gather": [
    "total_token_num",
    "input_tensor",
    "input_tensor_stride0",
    "input_tensor_stride1",
    "recv_topk_ids",
    "recv_topk_ids_stride0",
    "recv_topk_ids_stride1",
    "recv_topk_weight",
    "recv_topk_weight_stride0",
    "recv_topk_weight_stride1",
    "input_index",
    "input_index_stride0",
    "input_index_stride1",
    "output_tensor",
    "output_tensor_stride0",
    "output_tensor_stride1",
    "topk_num",
    "expert_map",
    "HAS_EXPERT_MAP",
    "BLOCK_D"
  ],
  "ep_gather": [
    "input_tensor",
    "recv_topk_ids",
    "recv_topk_weight",
    "input_index",
    "expert_map",
    "output_tensor"
  ],
  "deepgemm_moe_permute": [
    "aq",
    "aq_scale",
    "topk_ids",
    "local_num_experts",
    "expert_map",
    "expert_tokens_meta",
    "aq_out"
  ],
  "deepgemm_unpermute_and_reduce": [
    "a",
    "topk_ids",
    "topk_weights",
    "inv_perm",
    "expert_map",
    "output"
  ],
  "TopKWeightAndReduceDelegate": {
    "__eq__": [
      "self",
      "other"
    ],
    "apply": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input"
    ]
  },
  "TopKWeightAndReduceNoOP": {
    "__eq__": [
      "self",
      "other"
    ],
    "apply": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input"
    ]
  },
  "TopKWeightAndReduceContiguous": {
    "__eq__": [
      "self",
      "other"
    ],
    "apply": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input"
    ]
  },
  "TopKWeightAndReduceNaiveBatched": {
    "__init__": [
      "self",
      "rank"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "apply": [
      "self",
      "output",
      "fused_expert_output",
      "topk_weights",
      "topk_ids",
      "apply_router_weight_on_input"
    ]
  },
  "Fp8MoeBackend": {
    "NONE": [],
    "FLASHINFER_TRTLLM": [],
    "FLASHINFER_CUTLASS": [],
    "DEEPGEMM": [],
    "BATCHED_DEEPGEMM": [],
    "MARLIN": [],
    "TRITON": [],
    "BATCHED_TRITON": [],
    "AITER": [],
    "VLLM_CUTLASS": [],
    "BATCHED_VLLM_CUTLASS": []
  },
  "backend_to_kernel_cls": [
    "backend"
  ],
  "select_fp8_moe_backend": [
    "config",
    "weight_key",
    "activation_key",
    "allow_vllm_cutlass"
  ],
  "convert_to_fp8_moe_kernel_format": [
    "fp8_backend",
    "layer",
    "w13",
    "w2",
    "w13_scale",
    "w2_scale",
    "w13_input_scale",
    "w2_input_scale"
  ],
  "make_fp8_moe_quant_config": [
    "fp8_backend",
    "w1_scale",
    "w2_scale",
    "a1_scale",
    "a2_scale",
    "block_shape",
    "per_act_token_quant",
    "per_out_ch_quant"
  ],
  "make_fp8_moe_kernel_for_mkm": [
    "moe_config",
    "quant_config",
    "experts_cls",
    "prepare_finalize"
  ],
  "make_fp8_moe_kernel": [
    "moe_quant_config",
    "moe_config",
    "fp8_backend",
    "experts_cls"
  ],
  "NvFp4MoeBackend": {
    "FLASHINFER_TRTLLM": [],
    "FLASHINFER_CUTLASS": [],
    "FLASHINFER_CUTEDSL": [],
    "VLLM_CUTLASS": [],
    "MARLIN": []
  },
  "FLASHINFER_NVFP4_MOE_BACKENDS": [],
  "is_global_sf_supported_for_nvfp4_backend": [
    "backend"
  ],
  "select_nvfp4_moe_backend": [
    "config",
    "weight_key",
    "activation_key"
  ],
  "convert_to_nvfp4_moe_kernel_format": [
    "nvfp4_backend",
    "layer",
    "w13",
    "w13_scale",
    "w13_scale_2",
    "a13_scale",
    "w2",
    "w2_scale",
    "w2_scale_2",
    "a2_scale",
    "is_act_and_mul"
  ],
  "make_mxfp4_moe_quant_config": [
    "w13_scale",
    "w2_scale"
  ],
  "make_nvfp4_moe_quant_config": [
    "backend",
    "w13_scale",
    "w2_scale",
    "w13_scale_2",
    "w2_scale_2",
    "a13_scale",
    "a2_scale"
  ],
  "make_nvfp4_moe_kernel_for_mkm": [
    "moe_config",
    "quant_config",
    "experts_cls",
    "prepare_finalize"
  ],
  "make_nvfp4_moe_kernel": [
    "moe_quant_config",
    "moe_config",
    "experts_cls"
  ],
  "UnquantizedMoeBackend": {
    "FLASHINFER_CUTLASS": [],
    "AITER": [],
    "TRITON": [],
    "CPU": [],
    "XPU": [],
    "TPU": [],
    "OOT": []
  },
  "UNSUPPORTED_BACKEND": [],
  "select_unquantized_moe_backend": [
    "use_ep",
    "use_dp"
  ],
  "convert_to_unquantized_kernel_format": [
    "unquantized_backend",
    "layer",
    "w13_weight",
    "w2_weight"
  ],
  "make_unquantized_moe_kernel": [
    "backend",
    "quant_config",
    "moe_config"
  ],
  "vllm_topk_softmax": [
    "topk_weights",
    "topk_indices",
    "token_expert_indices",
    "gating_output",
    "renormalize",
    "e_score_correction_bias"
  ],
  "vllm_topk_sigmoid": [
    "topk_weights",
    "topk_indices",
    "token_expert_indices",
    "gating_output",
    "renormalize",
    "e_score_correction_bias"
  ],
  "fused_topk_bias": [
    "hidden_states",
    "gating_output",
    "e_score_correction_bias",
    "topk",
    "renormalize",
    "scoring_func",
    "indices_type"
  ],
  "FusedTopKBiasRouter": {
    "__init__": [
      "self",
      "top_k",
      "global_num_experts",
      "eplb_state",
      "e_score_correction_bias",
      "scoring_func",
      "renormalize",
      "routed_scaling_factor",
      "enable_eplb",
      "indices_type_getter"
    ],
    "routing_method_type": [
      "self"
    ],
    "_compute_routing": [
      "self",
      "hidden_states",
      "router_logits",
      "indices_type"
    ]
  },
  "create_fused_moe_router": [
    "top_k",
    "global_num_experts",
    "renormalize",
    "indices_type_getter",
    "use_grouped_topk",
    "num_expert_group",
    "topk_group",
    "scoring_func",
    "num_fused_shared_experts",
    "routed_scaling_factor",
    "e_score_correction_bias",
    "custom_routing_function",
    "enable_eplb",
    "eplb_state"
  ],
  "FusedMoERouter": {
    "routing_method_type": [
      "self"
    ],
    "select_experts": [
      "self",
      "hidden_states",
      "router_logits"
    ]
  },
  "RoutingStrategy": {
    "route_tokens": [
      "self",
      "hidden_states",
      "router_logits",
      "top_k",
      "indices_type"
    ]
  },
  "DistributionBasedRouting": {
    "__init__": [
      "self",
      "distribution"
    ],
    "_validate_distribution_params": [
      "self"
    ],
    "route_tokens": [
      "self",
      "hidden_states",
      "router_logits",
      "top_k",
      "indices_type"
    ],
    "_sample_expert_ids": [
      "self",
      "num_tokens",
      "num_experts",
      "top_k",
      "device",
      "indices_type"
    ],
    "_sample_continuous_distribution": [
      "self",
      "num_tokens",
      "top_k",
      "device"
    ],
    "_normalize_samples": [
      "self",
      "samples"
    ],
    "_generate_weights": [
      "self",
      "num_tokens",
      "top_k",
      "device"
    ],
    "get_distribution_info": [
      "self"
    ]
  },
  "RoutingSimulator": {
    "register_strategy": [
      "cls",
      "name",
      "strategy"
    ],
    "get_available_strategies": [
      "cls"
    ],
    "simulate_routing": [
      "hidden_states",
      "router_logits",
      "strategy_name",
      "top_k",
      "indices_type"
    ]
  },
  "RoutingSimulatorRouter": {
    "__init__": [
      "self",
      "top_k",
      "global_num_experts",
      "eplb_state",
      "enable_eplb",
      "indices_type_getter"
    ],
    "routing_method_type": [
      "self"
    ],
    "_compute_routing": [
      "self",
      "hidden_states",
      "router_logits",
      "indices_type"
    ]
  },
  "fused_grouped_topk": [
    "hidden_states",
    "gating_output",
    "topk",
    "renormalize",
    "e_score_correction_bias",
    "num_expert_group",
    "topk_group",
    "scoring_func",
    "routed_scaling_factor"
  ],
  "GroupedTopk": {
    "__init__": [
      "self",
      "topk",
      "renormalize",
      "num_expert_group",
      "topk_group",
      "scoring_func",
      "routed_scaling_factor",
      "num_fused_shared_experts"
    ],
    "forward_native": [
      "self",
      "hidden_states",
      "gating_output",
      "e_score_correction_bias"
    ],
    "forward_cuda": [
      "self",
      "hidden_states",
      "gating_output",
      "e_score_correction_bias"
    ],
    "forward_hip": [
      "self",
      "hidden_states",
      "gating_output",
      "e_score_correction_bias"
    ]
  },
  "GroupedTopKRouter": {
    "__init__": [
      "self",
      "top_k",
      "global_num_experts",
      "eplb_state",
      "num_expert_group",
      "topk_group",
      "renormalize",
      "scoring_func",
      "routed_scaling_factor",
      "e_score_correction_bias",
      "num_fused_shared_experts",
      "enable_eplb",
      "indices_type_getter"
    ],
    "routing_method_type": [
      "self"
    ],
    "_compute_routing": [
      "self",
      "hidden_states",
      "router_logits",
      "indices_type"
    ]
  },
  "dispatch_topk_softmax_func": [
    "use_rocm_aiter"
  ],
  "dispatch_topk_sigmoid_func": [
    "use_rocm_aiter"
  ],
  "fused_topk": [
    "hidden_states",
    "gating_output",
    "topk",
    "renormalize",
    "indices_type",
    "scoring_func"
  ],
  "FusedTopKRouter": {
    "__init__": [
      "self",
      "top_k",
      "global_num_experts",
      "eplb_state",
      "scoring_func",
      "renormalize",
      "enable_eplb",
      "indices_type_getter"
    ],
    "routing_method_type": [
      "self"
    ],
    "_compute_routing": [
      "self",
      "hidden_states",
      "router_logits",
      "indices_type"
    ]
  },
  "CustomRoutingRouter": {
    "__init__": [
      "self",
      "top_k",
      "global_num_experts",
      "eplb_state",
      "custom_routing_function",
      "renormalize",
      "enable_eplb",
      "indices_type_getter"
    ],
    "routing_method_type": [
      "self"
    ],
    "_compute_routing": [
      "self",
      "hidden_states",
      "router_logits",
      "indices_type"
    ]
  },
  "BaseRouter": {
    "__init__": [
      "self",
      "top_k",
      "global_num_experts",
      "eplb_state",
      "enable_eplb",
      "indices_type_getter"
    ],
    "_validate_eplb_state": [
      "self"
    ],
    "_get_indices_type": [
      "self"
    ],
    "_apply_eplb_mapping": [
      "self",
      "topk_ids"
    ],
    "_convert_indices_dtype": [
      "self",
      "topk_ids",
      "indices_type"
    ],
    "_compute_routing": [
      "self",
      "hidden_states",
      "router_logits",
      "indices_type"
    ],
    "select_experts": [
      "self",
      "hidden_states",
      "router_logits"
    ]
  },
  "rotate_neox": [
    "x"
  ],
  "rotate_gptj": [
    "x"
  ],
  "yarn_find_correction_dim": [
    "num_rotations",
    "dim",
    "base",
    "max_position_embeddings"
  ],
  "yarn_find_correction_range": [
    "low_rot",
    "high_rot",
    "dim",
    "base",
    "max_position_embeddings",
    "truncate"
  ],
  "yarn_linear_ramp_mask": [
    "low",
    "high",
    "dim",
    "dtype"
  ],
  "yarn_get_mscale": [
    "scale"
  ],
  "_flashinfer_rotary_embedding": [
    "positions",
    "query",
    "key",
    "head_size",
    "cos_sin_cache",
    "is_neox"
  ],
  "_flashinfer_rotary_embedding_fake": [
    "positions",
    "query",
    "key",
    "head_size",
    "cos_sin_cache",
    "is_neox"
  ],
  "ApplyRotaryEmb": {
    "__init__": [
      "self",
      "enforce_enable",
      "is_neox_style",
      "enable_fp32_compute"
    ],
    "forward_static": [
      "x",
      "cos",
      "sin",
      "is_neox_style",
      "enable_fp32_compute"
    ],
    "_pre_process": [
      "self",
      "x",
      "cos",
      "sin"
    ],
    "_post_process": [
      "self",
      "output",
      "origin_shape",
      "origin_dtype"
    ],
    "forward_native": [
      "self",
      "x",
      "cos",
      "sin"
    ],
    "forward_cuda": [
      "self",
      "x",
      "cos",
      "sin"
    ],
    "forward_hip": [
      "self",
      "x",
      "cos",
      "sin"
    ],
    "forward_cpu": [
      "self",
      "x",
      "cos",
      "sin"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "DualChunkRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "dtype",
      "chunk_size",
      "local_size"
    ],
    "_compute_inv_freq": [
      "self",
      "base"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ],
    "forward_native": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ],
    "forward_cuda": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ],
    "_apply_rotary_embedding": [
      "self",
      "cos_sin",
      "hidden_rot",
      "hidden_pass"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "DynamicNTKAlphaRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "scaling_alpha",
      "dtype"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ]
  },
  "LinearScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "scaling_factors",
      "dtype"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ],
    "scaling_factor_to_offset": [
      "self"
    ]
  },
  "RotaryEmbeddingBase": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "dtype"
    ],
    "_compute_inv_freq": [
      "self",
      "base"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ],
    "_match_cos_sin_cache_dtype": [
      "self",
      "query"
    ],
    "get_cos_sin": [
      "self",
      "seqlen"
    ]
  },
  "RotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "dtype"
    ],
    "forward_static": [
      "positions",
      "query",
      "key",
      "head_size",
      "rotary_dim",
      "cos_sin_cache",
      "is_neox_style"
    ],
    "forward_native": [
      "self",
      "positions",
      "query",
      "key"
    ],
    "forward_cuda": [
      "self",
      "positions",
      "query",
      "key"
    ],
    "forward_hip": [
      "self",
      "positions",
      "query",
      "key"
    ],
    "forward_xpu": [
      "self",
      "positions",
      "query",
      "key"
    ],
    "forward_cpu": [
      "self",
      "positions",
      "query",
      "key"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "Llama3RotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "dtype",
      "scaling_factor",
      "low_freq_factor",
      "high_freq_factor",
      "orig_max_position"
    ],
    "_compute_inv_freq": [
      "self",
      "base"
    ]
  },
  "XDRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "scaling_alpha",
      "dtype",
      "xdrope_section"
    ],
    "forward_native": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ],
    "forward_cuda": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ],
    "get_next_input_positions": [
      "context_len",
      "seq_len",
      "xd_sections"
    ],
    "get_next_input_positions_tensor": [
      "out",
      "out_offset",
      "context_len",
      "num_new_tokens"
    ]
  },
  "YaRNScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "scaling_factor",
      "dtype"
    ],
    "_compute_inv_freq": [
      "self",
      "scaling_factor"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ]
  },
  "Llama4VisionRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "dtype"
    ],
    "_compute_inv_freq": [
      "self",
      "base"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ],
    "forward_native": [
      "self",
      "query",
      "key"
    ],
    "forward_cuda": [
      "self",
      "query",
      "key"
    ]
  },
  "get_rope": [
    "head_size",
    "max_position",
    "is_neox_style",
    "rope_parameters",
    "dtype",
    "dual_chunk_attention_config"
  ],
  "Phi3LongRoPEScaledRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "original_max_position_embeddings",
      "base",
      "is_neox_style",
      "dtype",
      "short_factor",
      "long_factor",
      "short_mscale",
      "long_mscale"
    ],
    "_compute_inv_freq": [
      "self",
      "rescale_factors"
    ],
    "_compute_cos_sin_cache": [
      "self",
      "max_position_embeddings",
      "rescale_factors",
      "mscale"
    ],
    "forward": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ]
  },
  "_triton_mrope_forward": [
    "q_ptr",
    "k_ptr",
    "cos",
    "sin",
    "num_tokens",
    "n_qh",
    "n_kh",
    "hd",
    "rd",
    "pad_n_qh",
    "pad_n_kh",
    "pad_hd",
    "mrope_section_t",
    "mrope_section_h",
    "mrope_section_w",
    "is_interleaved"
  ],
  "triton_mrope": [
    "q",
    "k",
    "cos",
    "sin",
    "mrope_section",
    "head_size",
    "rotary_dim",
    "mrope_interleaved"
  ],
  "apply_interleaved_rope": [
    "x",
    "mrope_section"
  ],
  "MRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "dtype",
      "mrope_section",
      "mrope_interleaved"
    ],
    "_compute_inv_freq": [
      "self",
      "base"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ],
    "forward_native": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ],
    "forward_cuda": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ],
    "forward_cpu": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ],
    "get_next_input_positions": [
      "mrope_position_delta",
      "context_len",
      "seq_len"
    ],
    "get_next_input_positions_tensor": [
      "out",
      "out_offset",
      "mrope_position_delta",
      "context_len",
      "num_new_tokens"
    ]
  },
  "DynamicNTKScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "scaling_factor",
      "dtype"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ]
  },
  "NTKScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "scaling_factor",
      "dtype",
      "mixed_b"
    ],
    "_compute_inv_freq": [
      "self",
      "base"
    ]
  },
  "Ernie4_5_VLRotaryEmbedding": {
    "forward_native": [
      "self",
      "positions",
      "query",
      "key"
    ],
    "forward_cuda": [
      "self",
      "positions",
      "query",
      "key"
    ]
  },
  "DeepseekScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "scaling_factor",
      "dtype"
    ],
    "_compute_inv_freq": [
      "self",
      "scaling_factor"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ],
    "forward_native": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ],
    "forward_hip": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ],
    "forward_cuda": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ]
  },
  "_get_cross_slot_mapping": [
    "encoder_seq_lens",
    "block_table_tensor",
    "kv_cache_spec",
    "device"
  ],
  "create_cross_attention_backend": [
    "underlying_attn_backend"
  ],
  "CrossAttention": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "cache_config",
      "attn_type"
    ],
    "get_kv_cache_spec": [
      "self",
      "vllm_config"
    ]
  },
  "create_chunked_local_attention_backend": [
    "underlying_attn_backend",
    "attention_chunk_size",
    "block_size"
  ],
  "ChunkedLocalAttention": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "attention_chunk_size",
      "num_kv_heads",
      "alibi_slopes",
      "cache_config",
      "quant_config",
      "kv_sharing_target_layer_name",
      "prefix"
    ],
    "get_kv_cache_spec": [
      "self",
      "vllm_config"
    ]
  },
  "MMEncoderAttention": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "prefix"
    ],
    "enabled": [
      "cls"
    ],
    "maybe_reshape_qkv_to_4d": [
      "self",
      "query",
      "key",
      "value",
      "bsz",
      "q_len",
      "kv_len"
    ],
    "_forward_sdpa": [
      "self",
      "query",
      "key",
      "value",
      "cu_seqlens"
    ],
    "_forward_fa": [
      "self",
      "query",
      "key",
      "value",
      "cu_seqlens",
      "max_seqlen"
    ],
    "forward_native": [
      "self",
      "query",
      "key",
      "value",
      "cu_seqlens",
      "max_seqlen"
    ],
    "forward_cuda": [
      "self",
      "query",
      "key",
      "value",
      "cu_seqlens",
      "max_seqlen"
    ],
    "forward_cpu": [
      "self",
      "query",
      "key",
      "value",
      "cu_seqlens",
      "max_seqlen"
    ],
    "forward_xpu": [
      "self",
      "query",
      "key",
      "value",
      "cu_seqlens",
      "max_seqlen"
    ]
  },
  "QueryLenSupport": {
    "SINGLE_ONLY": [],
    "UNIFORM": [],
    "VARLEN": []
  },
  "dynamic_per_batched_tensor_quant": [
    "x",
    "dtype"
  ],
  "_DecodeConcatQuantFP8": {
    "_make_forward": [
      "quant_fn"
    ],
    "forward_native": [],
    "forward_cuda": [],
    "forward_hip": []
  },
  "CUDNN_WORKSPACE_SIZE": [],
  "MLACommonBackend": {
    "get_name": [],
    "get_builder_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ],
    "get_kv_cache_stride_order": [
      "include_num_layers_dimension"
    ],
    "get_supported_head_sizes": [
      "cls"
    ],
    "is_mla": [
      "cls"
    ]
  },
  "MLACommonPrefillMetadata": {},
  "FlashInferPrefillMetadata": {},
  "CudnnPrefillMetadata": {},
  "MLACommonDecodeMetadata": {},
  "D": [],
  "MLACommonMetadata": {
    "__post_init__": [
      "self"
    ]
  },
  "M": [],
  "A": [],
  "is_deepseek_r1_mla_compatible": [
    "vllm_config"
  ],
  "use_flashinfer_prefill": [],
  "use_cudnn_prefill": [],
  "use_trtllm_ragged_deepseek_prefill": [],
  "MLADims": {},
  "get_mla_dims": [
    "model_config"
  ],
  "MLACommonMetadataBuilder": {
    "determine_chunked_prefill_workspace_size": [
      "vllm_config"
    ],
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device",
      "metadata_cls",
      "supports_dcp_with_varlen"
    ],
    "_build_fi_prefill_wrappers": [
      "self",
      "prefill"
    ],
    "_build_decode": [
      "self",
      "block_table_tensor",
      "seq_lens_device",
      "max_seq_len",
      "query_start_loc_cpu",
      "query_start_loc_device",
      "num_decode_tokens",
      "dcp_tot_seq_lens_device"
    ],
    "build_for_cudagraph_capture": [
      "self",
      "common_attn_metadata"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ]
  },
  "reorg_kvcache": [
    "allgatered_kv_c_normed",
    "allgatered_k_pe",
    "padded_local_chunk_seq_lens_lst",
    "local_context_lens_allranks",
    "sum_seq_len",
    "max_seq_len",
    "chunk_size",
    "chunk_idx",
    "toks"
  ],
  "MLACommonBaseImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name",
      "q_lora_rank",
      "kv_lora_rank",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "qk_head_dim",
      "v_head_dim",
      "kv_b_proj",
      "indexer",
      "q_pad_num_heads"
    ],
    "process_weights_after_loading": [
      "self",
      "act_dtype"
    ],
    "_v_up_proj": [
      "self",
      "x",
      "out"
    ]
  },
  "MLACommonImpl": {
    "__init__": [
      "self"
    ],
    "_flash_attn_varlen_diff_headdims": [
      "self",
      "q",
      "k",
      "v",
      "return_softmax_lse",
      "softmax_scale"
    ],
    "_run_prefill_new_tokens_fa": [
      "self",
      "prefill",
      "q",
      "k",
      "v",
      "return_softmax_lse"
    ],
    "_run_prefill_new_tokens_fi": [
      "self",
      "prefill",
      "q",
      "k",
      "v",
      "return_softmax_lse"
    ],
    "_run_prefill_new_tokens_cudnn": [
      "self",
      "prefill",
      "q",
      "k",
      "v",
      "return_softmax_lse"
    ],
    "_run_prefill_context_chunk_fa": [
      "self",
      "prefill",
      "chunk_idx",
      "q",
      "k",
      "v"
    ],
    "_run_prefill_context_chunk_fi": [
      "self",
      "prefill",
      "chunk_idx",
      "q",
      "k",
      "v"
    ],
    "_run_prefill_context_chunk_cudnn": [
      "self",
      "prefill",
      "chunk_idx",
      "q",
      "k",
      "v"
    ],
    "_run_prefill_new_tokens_trtllm_ragged": [
      "self",
      "prefill",
      "q",
      "k",
      "v",
      "return_softmax_lse"
    ],
    "_run_prefill_context_chunk_trtllm_ragged": [
      "self",
      "prefill",
      "chunk_idx",
      "q",
      "k",
      "v"
    ],
    "_concat_k_nope_k_pe": [
      "self",
      "k_nope",
      "k_pe"
    ],
    "_compute_prefill_context": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "attn_metadata",
      "k_scale"
    ],
    "_context_parallel_compute_prefill_context": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "attn_metadata",
      "k_scale",
      "dcp_world_size"
    ],
    "_forward_prefill": [
      "self",
      "q",
      "kv_c_normed",
      "k_pe",
      "kv_c_and_k_pe_cache",
      "attn_metadata",
      "k_scale",
      "output"
    ],
    "_forward_decode": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "attn_metadata",
      "layer"
    ],
    "forward": [
      "self",
      "layer",
      "q",
      "k_c_normed",
      "k_pe",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ]
  },
  "create_static_sink_attention_backend": [
    "underlying_attn_backend",
    "sink_len"
  ],
  "StaticSinkAttention": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "sink_len",
      "attn_backend",
      "cache_config"
    ],
    "update_sink_kv": [
      "self",
      "sink_key",
      "sink_value"
    ],
    "forward_native": [
      "self",
      "query",
      "key",
      "value",
      "output_shape"
    ],
    "forward_cuda": [
      "self",
      "query",
      "key",
      "value",
      "output_shape"
    ],
    "forward": [
      "self"
    ],
    "populate_sink_kv": [
      "self",
      "self_kv_cache"
    ],
    "get_kv_cache_spec": [
      "self",
      "vllm_config"
    ]
  },
  "maybe_populate_sink": [
    "self_kv_cache",
    "layer_name"
  ],
  "maybe_populate_sink_fake": [
    "self_kv_cache",
    "layer_name"
  ],
  "create_encoder_only_attention_backend": [
    "underlying_attn_backend"
  ],
  "EncoderOnlyAttention": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "cache_config",
      "attn_type"
    ],
    "get_kv_cache_spec": [
      "self",
      "vllm_config"
    ]
  },
  "FBGEMMFp8Config": {
    "__init__": [
      "self",
      "ignore_list",
      "input_scale_ub"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "FBGEMMFp8LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "triton_scale_swizzle": [
    "scale_ptr",
    "scale_rows",
    "scale_cols",
    "output_ptr",
    "input_row_stride",
    "output_block_stride",
    "BLOCK_ROWS",
    "BLOCK_COLS"
  ],
  "triton_mx_block_rearrange": [
    "scale_tensor"
  ],
  "to_blocked": [
    "input_matrix",
    "backend"
  ],
  "get_moe_quant_method": [
    "config",
    "layer",
    "prefix",
    "moe_method_cls"
  ],
  "GPTQMarlinConfig": {
    "TYPE_MAP": [],
    "__init__": [
      "self",
      "weight_bits",
      "group_size",
      "desc_act",
      "is_sym",
      "lm_head_quantized",
      "dynamic",
      "full_config",
      "modules_in_block_to_quantize"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "is_gptq_marlin_compatible": [
      "cls",
      "quant_config"
    ],
    "apply_vllm_mapper": [
      "self",
      "hf_to_vllm_mapper"
    ],
    "maybe_update_config": [
      "self",
      "model_name",
      "revision"
    ]
  },
  "GPTQMarlinLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "GPTQMarlinMoEMethod": {
    "__init__": [
      "self",
      "quant_config",
      "moe"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "select_gemm_impl": [
      "self",
      "prepare_finalize",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "BaseKVCacheMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "ACTIVATION_SCHEMES": [],
  "Fp8Config": {
    "__init__": [
      "self",
      "is_checkpoint_fp8_serialized",
      "activation_scheme",
      "ignored_layers",
      "weight_block_size"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "apply_vllm_mapper": [
      "self",
      "hf_to_vllm_mapper"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_xpu_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_cache_scale": [
      "self",
      "name"
    ]
  },
  "CopyNumelCounter": {
    "__init__": [
      "self"
    ],
    "__torch_dispatch__": [
      "self",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "Fp8LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "Fp8OnlineLinearMethod": {
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "Fp8MoEMethod": {
    "__init__": [
      "self",
      "quant_config",
      "layer"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "_setup_kernel": [
      "self",
      "layer",
      "w13",
      "w2",
      "w13_scale",
      "w2_scale",
      "w13_input_scale",
      "w2_input_scale"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "maybe_make_prepare_finalize": [
      "self",
      "routing_tables"
    ],
    "select_gemm_impl": [
      "self",
      "prepare_finalize",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "supports_eplb": [
      "self"
    ],
    "allow_inplace": [
      "self"
    ],
    "is_monolithic": [
      "self"
    ],
    "apply_monolithic": [
      "self",
      "layer",
      "x",
      "router_logits"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "Fp8OnlineMoEMethod": {
    "__init__": [
      "self",
      "quant_config",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "Fp8KVCacheMethod": {
    "__init__": [
      "self",
      "quant_config"
    ]
  },
  "QUANT_ALGOS": [],
  "KV_CACHE_QUANT_ALGOS": [],
  "ModelOptFp8KVCacheMethod": {
    "__init__": [
      "self",
      "quant_config"
    ]
  },
  "ModelOptQuantConfigBase": {
    "__init__": [
      "self",
      "exclude_modules"
    ],
    "is_layer_excluded": [
      "self",
      "prefix"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "apply_vllm_mapper": [
      "self",
      "hf_to_vllm_mapper"
    ],
    "get_config_filenames": [],
    "_from_config": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "ModelOptFp8Config": {
    "__init__": [
      "self",
      "quant_method",
      "is_checkpoint_fp8_serialized",
      "kv_cache_quant_method",
      "exclude_modules"
    ],
    "get_name": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "_from_config": [
      "cls"
    ]
  },
  "ModelOptFp8LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "ModelOptFp8PcPtLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "ModelOptFp8PbWoLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "ModelOptFp8MoEMethod": {
    "__init__": [
      "self",
      "quant_config",
      "moe_config"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "maybe_make_prepare_finalize": [
      "self",
      "routing_tables"
    ],
    "select_gemm_impl": [
      "self",
      "prepare_finalize",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "_setup_kernel": [
      "self",
      "layer",
      "w13",
      "w2",
      "w13_scale",
      "w2_scale",
      "w13_input_scale",
      "w2_input_scale"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "is_monolithic": [
      "self"
    ],
    "apply_monolithic": [
      "self",
      "layer",
      "x",
      "router_logits"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "ModelOptNvFp4Config": {
    "__init__": [
      "self",
      "is_checkpoint_nvfp4_serialized",
      "kv_cache_quant_algo",
      "exclude_modules",
      "group_size"
    ],
    "get_name": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "_from_config": [
      "cls"
    ]
  },
  "ModelOptNvFp4LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "ModelOptNvFp4FusedMoE": {
    "__init__": [
      "self",
      "quant_config",
      "moe_config"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "maybe_make_prepare_finalize": [
      "self",
      "routing_tables"
    ],
    "select_gemm_impl": [
      "self",
      "prepare_finalize",
      "layer"
    ],
    "uses_weight_scale_2_pattern": [
      "self"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "do_post_quant_allgather": [
      "self"
    ],
    "prepare_dp_allgather_tensor": [
      "self",
      "layer",
      "hidden_states",
      "router_logits"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "supports_eplb": [
      "self"
    ],
    "is_monolithic": [
      "self"
    ],
    "apply_monolithic": [
      "self",
      "layer",
      "x",
      "router_logits"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "AWQConfig": {
    "__init__": [
      "self",
      "weight_bits",
      "group_size",
      "zero_point",
      "modules_to_not_convert"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "apply_vllm_mapper": [
      "self",
      "hf_to_vllm_mapper"
    ],
    "maybe_update_config": [
      "self",
      "model_name",
      "revision"
    ]
  },
  "AWQLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "FPQuantConfig": {
    "__init__": [
      "self",
      "hadamard_group_size",
      "forward_dtype",
      "forward_method",
      "pseudoquantization",
      "modules_to_not_convert"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "FPQuantLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "fused_quantize_mx": [
    "x_flat",
    "hadamard_matrix",
    "forward_method"
  ],
  "fused_quantize_mx_fake": [
    "x_flat",
    "hadamard_matrix",
    "forward_method"
  ],
  "matmul_mxf4_bf16": [
    "x",
    "w",
    "xs",
    "ws",
    "alpha"
  ],
  "matmul_mxf4_bf16_fake": [
    "x",
    "w",
    "xs",
    "ws",
    "alpha"
  ],
  "fused_quantize_nv": [
    "x_flat",
    "hadamard_matrix",
    "global_scale"
  ],
  "fused_quantize_nv_fake": [
    "x_flat",
    "hadamard_matrix",
    "global_scale"
  ],
  "matmul_nvf4_bf16": [
    "x",
    "w",
    "xs",
    "ws",
    "alpha"
  ],
  "matmul_nvf4_bf16_fake": [
    "x",
    "w",
    "xs",
    "ws",
    "alpha"
  ],
  "quantized_forward": [
    "x",
    "qweight",
    "weight_scales",
    "weight_global_scale",
    "act_global_scale",
    "bias",
    "forward_hadamard_matrix",
    "forward_method",
    "forward_dtype"
  ],
  "MoeWNA16Config": {
    "__init__": [
      "self",
      "linear_quant_method",
      "weight_bits",
      "group_size",
      "has_zp",
      "lm_head_quantized",
      "modules_to_not_convert",
      "full_config"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "is_moe_wna16_compatible": [
      "cls",
      "quant_config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "is_layer_skipped_quant": [
    "prefix",
    "modules_to_not_convert"
  ],
  "MoeWNA16Method": {
    "__init__": [
      "self",
      "quant_config",
      "moe"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ],
    "get_weight_loader": [
      "layer",
      "weight_loader"
    ]
  },
  "_get_weight_attrs": [
    "param"
  ],
  "_restore_weight_attrs": [
    "param",
    "recorded_weight_attr"
  ],
  "torchao_version_at_least": [
    "torchao_version"
  ],
  "should_skip": [
    "prefix",
    "skip_modules"
  ],
  "TorchAOConfig": {
    "__init__": [
      "self",
      "torchao_config",
      "skip_modules",
      "is_checkpoint_torchao_serialized"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [],
    "from_config": [
      "cls",
      "config"
    ],
    "from_config_file": [
      "cls",
      "config_file"
    ],
    "from_config_dict_json": [
      "cls",
      "config_dict_json"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "torchao_quantize_param_data": [
    "param",
    "torchao_config"
  ],
  "TorchAOLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "CPUAWQConfig": {
    "__init__": [
      "self",
      "weight_bits",
      "group_size",
      "zero_point",
      "lm_head_quantized",
      "modules_to_not_convert",
      "full_config"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "apply_vllm_mapper": [
      "self",
      "hf_to_vllm_mapper"
    ],
    "maybe_update_config": [
      "self",
      "model_name",
      "revision"
    ]
  },
  "CPUAWQLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "_get_isa_hint": [
    "dtype"
  ],
  "INCConfig": {
    "SUPPORTED_BITS": [],
    "SUPPORTED_DTYPES": [],
    "SUPPORTED_FORMATS": [],
    "SUPPORTED_BACKENDS": [],
    "__init__": [
      "self",
      "weight_bits",
      "group_size",
      "sym",
      "packing_format",
      "block_name_to_quantize",
      "extra_config",
      "data_type",
      "backend"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_layer_config": [
      "self",
      "layer",
      "layer_name"
    ],
    "check_quantized": [
      "self",
      "weight_bits"
    ],
    "apply_vllm_mapper": [
      "self",
      "hf_to_vllm_mapper"
    ],
    "apply_awq_quant_layer": [
      "self",
      "layer",
      "prefix",
      "backend"
    ],
    "apply_gptq_quant_layer": [
      "self",
      "layer",
      "prefix",
      "backend"
    ],
    "apply_ipex_quant_layer": [
      "self",
      "layer",
      "prefix"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ]
  },
  "Mxfp4Backend": {
    "NONE": [],
    "SM100_FI_MXFP4_MXFP8_TRTLLM": [],
    "SM100_FI_MXFP4_MXFP8_CUTLASS": [],
    "SM100_FI_MXFP4_BF16": [],
    "SM90_FI_MXFP4_BF16": [],
    "MARLIN": [],
    "TRITON": []
  },
  "get_mxfp4_backend_with_lora": [],
  "get_mxfp4_backend": [
    "with_lora_support"
  ],
  "Mxfp4Config": {
    "__init__": [
      "self",
      "ignored_layers"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "Mxfp4MoEMethod": {
    "__init__": [
      "self",
      "moe"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "select_gemm_impl": [
      "self",
      "prepare_finalize",
      "layer"
    ],
    "allow_inplace": [
      "self"
    ],
    "is_monolithic": [
      "self"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ],
    "apply_monolithic": [
      "self",
      "layer",
      "x",
      "router_logits"
    ]
  },
  "IpexMxfp4MoEMethod": {
    "__init__": [
      "self",
      "moe_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "is_monolithic": [
      "self"
    ],
    "apply_monolithic": [
      "self",
      "layer",
      "x",
      "router_logits"
    ]
  },
  "_FP8_MIN_SCALING_FACTOR": [],
  "QuantFP8": {
    "__init__": [
      "self",
      "static",
      "group_shape",
      "num_token_padding",
      "column_major_scales",
      "tma_aligned_scales",
      "use_ue8m0",
      "compile_native"
    ],
    "forward_cuda": [
      "self",
      "x",
      "scale",
      "scale_ub"
    ],
    "forward_hip": [
      "self",
      "x",
      "scale",
      "scale_ub"
    ],
    "forward_native": [
      "self",
      "x",
      "scale",
      "scale_ub"
    ],
    "_quantize_group_native": [
      "self",
      "x"
    ]
  },
  "KVCacheQuantSchema": {
    "check_is_fp8": [
      "self"
    ],
    "check_tp_ranks": [
      "self",
      "info"
    ],
    "check_current_rank": [
      "self",
      "info"
    ]
  },
  "QuantParamSchema": {
    "model_config": [],
    "check_model_type": [
      "self",
      "info"
    ]
  },
  "GGUFConfig": {
    "__init__": [
      "self",
      "unquantized_modules"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "apply_vllm_mapper": [
      "self",
      "hf_to_vllm_mapper"
    ]
  },
  "is_layer_skipped_gguf": [
    "prefix",
    "unquantized_modules",
    "fused_mapping"
  ],
  "UNQUANTIZED_TYPES": [],
  "STANDARD_QUANT_TYPES": [],
  "KQUANT_TYPES": [],
  "IMATRIX_QUANT_TYPES": [],
  "DEQUANT_TYPES": [],
  "MMVQ_QUANT_TYPES": [],
  "MMQ_QUANT_TYPES": [],
  "_fused_mul_mat_gguf": [
    "x",
    "qweight",
    "qweight_type"
  ],
  "_fused_mul_mat_gguf_fake": [
    "x",
    "qweight",
    "qweight_type"
  ],
  "_fused_moe_gguf": [
    "x",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "qweight_type",
    "qweight_type2",
    "activation"
  ],
  "_fused_moe_gguf_fake": [
    "x",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "qweight_type",
    "qweight_type2",
    "activation"
  ],
  "_apply_gguf_embedding": [
    "x",
    "qweight",
    "qweight_type",
    "hidden_size",
    "dtype"
  ],
  "_apply_gguf_embedding_fake": [
    "x",
    "qweight",
    "qweight_type",
    "hidden_size",
    "dtype"
  ],
  "GGUFLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "_create_padded_weight_param": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "GGUFMoEMethod": {
    "__init__": [
      "self",
      "quant_config",
      "moe"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "GGUFEmbeddingMethod": {
    "embedding": [
      "self",
      "layer",
      "x"
    ]
  },
  "GGUFUninitializedParameter": {
    "cls_to_become": []
  },
  "ExpertsInt8Config": {
    "__init__": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "ExpertsInt8MoEMethod": {
    "__init__": [
      "self",
      "quant_config",
      "moe"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ],
    "quantizing_weight_loader": [
      "layer",
      "weight_loader"
    ]
  },
  "quantize_in_place_and_get_scales": [
    "weight"
  ],
  "BitsAndBytesConfig": {
    "__init__": [
      "self",
      "load_in_8bit",
      "load_in_4bit",
      "bnb_4bit_compute_dtype",
      "bnb_4bit_quant_storage",
      "bnb_4bit_quant_type",
      "bnb_4bit_use_double_quant",
      "llm_int8_enable_fp32_cpu_offload",
      "llm_int8_has_fp16_weight",
      "llm_int8_skip_modules",
      "llm_int8_threshold"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "is_layer_skipped_bnb": [
    "prefix",
    "llm_int8_skip_modules"
  ],
  "calculate_quant_ratio": [
    "dtype"
  ],
  "BitsAndBytesLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "_apply_8bit_weight": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "_apply_4bit_weight": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "_apply_bnb_4bit": [
    "x",
    "weight",
    "offsets",
    "out"
  ],
  "_apply_bnb_4bit_fake": [
    "x",
    "weight",
    "offsets",
    "out"
  ],
  "BitsAndBytesMoEMethod": {
    "__init__": [
      "self",
      "quant_config",
      "moe"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ],
    "_create_weights_4bit": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "_create_weights_8bit": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "_apply_4bit_dequnt": [
      "self",
      "layer"
    ],
    "_apply_8bit_dequant": [
      "self",
      "layer"
    ]
  },
  "QuantizationMethods": [],
  "DEPRECATED_QUANTIZATION_METHODS": [],
  "_CUSTOMIZED_METHOD_TO_QUANT_CONFIG": [],
  "register_quantization_config": [
    "quantization"
  ],
  "get_quantization_config": [
    "quantization"
  ],
  "MIN_IPEX_VERSION": [],
  "IPEXConfig": {
    "IPEX_QUANT_METHOD_MAP": [],
    "__init__": [
      "self",
      "method",
      "weight_bits",
      "group_size",
      "modules_to_not_convert",
      "desc_act",
      "lm_head_quantized",
      "is_sym"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "IPEXGPTQLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "IPEXAWQLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "XPUFp8LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "XPUFp8MoEMethod": {
    "__init__": [
      "self",
      "quant_config",
      "layer"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "is_monolithic": [
      "self"
    ],
    "apply_monolithic": [
      "self",
      "layer",
      "x",
      "router_logits"
    ]
  },
  "PetitNvFp4Config": {
    "__init__": [
      "self",
      "is_checkpoint_nvfp4_serialized",
      "kv_cache_quant_algo",
      "group_size",
      "exclude_modules"
    ],
    "_check_hardware_support": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "is_petit_nvfp4_compatible": [
      "cls",
      "quant_config"
    ],
    "is_layer_excluded": [
      "self",
      "prefix",
      "exclude_modules"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_scaled_act_names": [
      "self"
    ],
    "require_group_size": [
      "self"
    ],
    "require_kv_cache_quant_algo": [
      "self"
    ],
    "require_exclude_modules": [
      "self"
    ]
  },
  "PetitFp8KVCacheMethod": {
    "__init__": [
      "self",
      "quant_config"
    ]
  },
  "PetitNvFp4LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "QuantizeMethodBase": {
    "create_weights": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer"
    ],
    "embedding": [
      "self",
      "layer"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "method_has_implemented_embedding": [
    "method_class"
  ],
  "QuantizationConfig": {
    "__init__": [
      "self"
    ],
    "get_name": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "get_from_keys": [
      "config",
      "keys"
    ],
    "get_from_keys_or": [
      "config",
      "keys",
      "default"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_cache_scale": [
      "self",
      "name"
    ],
    "apply_vllm_mapper": [
      "self",
      "hf_to_vllm_mapper"
    ],
    "maybe_update_config": [
      "self",
      "model_name"
    ]
  },
  "BitBLASConfig": {
    "TORCH_DTYPE": [],
    "STORAGE_DTYPE": [],
    "TORCH_STORAGE_DTYPE": [],
    "ZEROS_MODE": [],
    "__init__": [
      "self",
      "weight_bits",
      "group_size",
      "desc_act",
      "is_sym",
      "quant_method",
      "lm_head_quantized"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "get_from_keys": [
      "config",
      "keys",
      "default"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "BitBLASLinearMethod": {
    "OPT_FEATURES": [],
    "ENABLE_TUNING": [],
    "BITBLAS_DTYPES": [],
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights_gptq": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "_configure_bitblas_matmul": [
      "self",
      "infeatures",
      "outfeatures",
      "params_dtype",
      "enable_tuning",
      "bias",
      "layout",
      "bits",
      "out_dtype"
    ],
    "_get_or_create_bitblas_operator": [
      "self",
      "config",
      "enable_tuning"
    ],
    "apply_gptq": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "apply": [
      "self"
    ]
  },
  "AWQ_TRITON_SUPPORTED_GROUP_SIZES": [],
  "awq_dequantize_kernel": [
    "qweight_ptr",
    "scales_ptr",
    "zeros_ptr",
    "group_size",
    "result_ptr",
    "num_cols",
    "num_rows",
    "BLOCK_SIZE_X",
    "BLOCK_SIZE_Y"
  ],
  "awq_gemm_kernel": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "zeros_ptr",
    "scales_ptr",
    "M",
    "N",
    "K",
    "group_size",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "SPLIT_K"
  ],
  "awq_dequantize_triton": [
    "qweight",
    "scales",
    "zeros",
    "block_size_x",
    "block_size_y"
  ],
  "awq_gemm_triton": [
    "input",
    "qweight",
    "scales",
    "qzeros",
    "split_k_iters",
    "block_size_m",
    "block_size_n",
    "block_size_k"
  ],
  "PTPCFp8Config": {
    "__init__": [
      "self",
      "activation_scheme",
      "ignored_layers"
    ],
    "get_name": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "PTPCFp8LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "GPTQBitBLASConfig": {
    "TYPE_MAP": [],
    "TORCH_DTYPE": [],
    "GPTQ_CKPT_STORAGE_DTYPE": [],
    "GPTQ_BITBLAS_STORAGE_DTYPE": [],
    "TORCH_BITBLAS_STORAGE_DTYPE": [],
    "ZEROS_MODE": [],
    "__init__": [
      "self",
      "weight_bits",
      "group_size",
      "desc_act",
      "is_sym",
      "quant_method",
      "lm_head_quantized"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "torch_storage_dtype": [
      "self"
    ],
    "is_gptq_bitblas_compatible": [
      "cls",
      "quant_config"
    ]
  },
  "GPTQBitBLASLinearMethod": {
    "kernel_type": [],
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "GPTQConfig": {
    "__init__": [
      "self",
      "weight_bits",
      "group_size",
      "desc_act",
      "lm_head_quantized",
      "dynamic",
      "autoround_version",
      "modules_in_block_to_quantize",
      "checkpoint_format"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "apply_vllm_mapper": [
      "self",
      "hf_to_vllm_mapper"
    ],
    "maybe_update_config": [
      "self",
      "model_name",
      "revision"
    ]
  },
  "ExllamaState": {
    "UNUSED": [],
    "UNINITIALIZED": [],
    "READY": []
  },
  "GPTQLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "AWQMarlinConfig": {
    "TYPE_MAP": [],
    "__init__": [
      "self",
      "weight_bits",
      "group_size",
      "zero_point",
      "lm_head_quantized",
      "modules_to_not_convert",
      "full_config"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "is_awq_marlin_compatible": [
      "cls",
      "quant_config"
    ],
    "apply_vllm_mapper": [
      "self",
      "hf_to_vllm_mapper"
    ],
    "maybe_update_config": [
      "self",
      "model_name",
      "revision"
    ]
  },
  "AWQMarlinLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "AWQMarlinMoEMethod": {
    "__init__": [
      "self",
      "quant_config",
      "moe"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "select_gemm_impl": [
      "self",
      "prepare_finalize",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "GPTQ_MARLIN_24_TILE": [],
  "GPTQ_MARLIN_24_MIN_THREAD_N": [],
  "GPTQ_MARLIN_24_MIN_THREAD_K": [],
  "GPTQ_MARLIN_24_MAX_PARALLEL": [],
  "GPTQ_MARLIN_24_SUPPORTED_QUANT_TYPES": [],
  "GPTQ_MARLIN_24_SUPPORTED_GROUP_SIZES": [],
  "GPTQMarlin24Config": {
    "__init__": [
      "self",
      "weight_bits",
      "group_size"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "GPTQMarlin24LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "ScaledMMLinearLayerConfig": {},
  "Int8ScaledMMLinearLayerConfig": {},
  "FP8ScaledMMLinearLayerConfig": {},
  "_FP8ParamsT": [],
  "_Int8ParamsT": [],
  "_ParamsT": [],
  "_ConfigT": [],
  "ScaledMMLinearKernel": {
    "is_supported": [
      "cls",
      "compute_capability"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "__init__": [
      "self",
      "c",
      "layer_param_names"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "_get_layer_params": [
      "self",
      "layer"
    ]
  },
  "FP8ScaledMMLinearKernel": {
    "__init__": [
      "self",
      "c",
      "layer_param_names"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "_get_layer_params": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "apply_scaled_mm": [
      "self"
    ],
    "get_output_padding": [
      "self"
    ]
  },
  "Int8ScaledMMLinearKernel": {
    "_get_layer_params": [
      "self",
      "layer"
    ]
  },
  "rocm_per_tensor_float_w8a8_scaled_mm_impl": [
    "A",
    "B",
    "out_dtype",
    "As",
    "Bs",
    "bias"
  ],
  "rocm_per_tensor_float_w8a8_scaled_mm_fake": [
    "A",
    "B",
    "out_dtype",
    "As",
    "Bs",
    "bias"
  ],
  "ROCmFP8ScaledMMLinearKernel": {
    "is_supported": [
      "cls",
      "compute_capability"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "apply_scaled_mm": [
      "self"
    ]
  },
  "AiterInt8ScaledMMLinearKernel": {
    "is_supported": [
      "cls",
      "compute_capability"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "_KernelT": [],
  "_KernelConfigT": [],
  "is_supported_and_can_implement_kernel": [
    "kernel",
    "config",
    "compute_capability"
  ],
  "choose_scaled_mm_linear_kernel": [
    "config",
    "possible_kernels",
    "compute_capability",
    "force_kernel"
  ],
  "init_fp8_linear_kernel": [
    "activation_quant_key",
    "weight_quant_key",
    "out_dtype",
    "force_kernel",
    "module_name"
  ],
  "init_int8_linear_kernel": [
    "is_channelwise",
    "is_static_input_scheme",
    "input_symmetric",
    "module_name"
  ],
  "TritonInt8ScaledMMLinearKernel": {
    "is_supported": [
      "cls",
      "compute_capability"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "FlashInferFP8ScaledMMLinearKernel": {
    "is_supported": [
      "cls",
      "compute_capability"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "apply_scaled_mm": [
      "self"
    ]
  },
  "CutlassInt8ScaledMMLinearKernel": {
    "is_supported": [
      "cls",
      "compute_capability"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "CutlassFP8ScaledMMLinearKernel": {
    "is_supported": [
      "cls",
      "compute_capability"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "apply_scaled_mm": [
      "self"
    ]
  },
  "CPUInt8ScaledMMLinearKernel": {
    "is_supported": [
      "cls",
      "compute_capability"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "process_weights_for_onednn": [
      "self",
      "layer"
    ],
    "process_weights_for_sgl": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "_apply_weights_onednn": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "_apply_weights_sgl": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "TorchFP8ScaledMMLinearKernel": {
    "is_supported": [
      "cls",
      "compute_capability"
    ],
    "get_output_padding": [
      "self"
    ]
  },
  "PerTensorTorchFP8ScaledMMLinearKernel": {
    "can_implement": [
      "cls",
      "c"
    ],
    "apply_scaled_mm": [
      "self"
    ]
  },
  "RowWiseTorchFP8ScaledMMLinearKernel": {
    "is_supported": [
      "cls",
      "compute_capability"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "apply_scaled_mm": [
      "self"
    ]
  },
  "ChannelWiseTorchFP8ScaledMMLinearKernel": {
    "can_implement": [
      "cls",
      "c"
    ],
    "apply_scaled_mm": [
      "self"
    ]
  },
  "MPLinearLayerConfig": {},
  "MPLinearKernel": {
    "get_min_capability": [
      "cls"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "__init__": [
      "self",
      "c",
      "w_q_param_name",
      "w_s_param_name",
      "w_zp_param_name",
      "w_gidx_param_name"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "_transform_param": [
      "self",
      "layer",
      "name",
      "fn"
    ],
    "_get_weight_params": [
      "self",
      "layer"
    ]
  },
  "MacheteLinearKernel": {
    "get_min_capability": [
      "cls"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "AllSparkLinearKernel": {
    "get_min_capability": [
      "cls"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "choose_mp_linear_kernel": [
    "config",
    "compute_capability"
  ],
  "ExllamaLinearKernel": {
    "SUPPORTED_QUANT_TYPES": [],
    "get_min_capability": [
      "cls"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "MarlinLinearKernel": {
    "get_min_capability": [
      "cls"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "CutlassW4A8LinearKernel": {
    "__init__": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "Dynamic4bitLinearKernel": {
    "SUPPORTED_QUANT_TYPES": [],
    "get_min_capability": [
      "cls"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "ConchLinearKernel": {
    "get_min_capability": [
      "cls"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "BitBLASLinearKernel": {
    "__init__": [
      "self",
      "c",
      "w_q_param_name",
      "w_s_param_name",
      "w_zp_param_name",
      "w_gidx_param_name",
      "bitblas_quant_config"
    ],
    "repack_bitblas_from_gptq": [
      "self",
      "b_q_weight",
      "scales",
      "qzeros"
    ],
    "get_min_capability": [
      "cls"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "configure_bitblas_matmul": [
      "self",
      "infeatures",
      "outfeatures",
      "params_dtype",
      "bias"
    ],
    "_configure_bitblas_matmul": [
      "self",
      "infeatures",
      "outfeatures",
      "params_dtype",
      "enable_tuning",
      "bias",
      "layout",
      "bits"
    ],
    "_get_or_create_bitblas_operator": [
      "self",
      "config",
      "enable_tuning"
    ],
    "apply_gptq_bitblas_linear": [
      "self",
      "layer",
      "x"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "_CPUWNA16_SUPPORTED_QUANT_TYPES": [],
  "CPUWNA16LinearKernel": {
    "get_min_capability": [
      "cls"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "_process_gptq_weights": [
      "self",
      "layer"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "XPUwNa16LinearKernel": {
    "get_min_capability": [
      "cls"
    ],
    "can_implement": [
      "cls",
      "c"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "QuarkMoEMethod": {
    "__init__": [
      "self",
      "moe"
    ],
    "get_moe_method": [
      "quant_config",
      "module",
      "layer_name"
    ]
  },
  "QuarkW8A8Fp8MoEMethod": {
    "__init__": [
      "self",
      "weight_config",
      "input_config",
      "moe"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "QuarkW4A8Fp8MoEMethod": {
    "__init__": [
      "self",
      "weight_config",
      "input_config",
      "moe"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "QuarkOCP_MX_MoEMethod": {
    "__init__": [
      "self",
      "weight_config",
      "input_config",
      "moe"
    ],
    "get_packed_dim": [
      "self",
      "dim",
      "quant_dtype"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "allow_inplace": [
      "self"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "QuarkConfig": {
    "__init__": [
      "self",
      "quant_config",
      "kv_cache_group",
      "kv_cache_config",
      "pack_method"
    ],
    "get_linear_method": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_name": [
      "self"
    ],
    "apply_vllm_mapper": [
      "self",
      "hf_to_vllm_mapper"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "_check_scheme_supported": [
      "self",
      "min_capability",
      "error"
    ],
    "_is_fp8_w4a8": [
      "self",
      "weight_quant",
      "input_quant"
    ],
    "_is_fp8_w8a8": [
      "self",
      "weight_quant",
      "input_quant"
    ],
    "_is_static_tensor_w8a8": [
      "self",
      "weight_quant",
      "input_quant"
    ],
    "_is_ocp_mx": [
      "self",
      "weight_quant",
      "input_quant"
    ],
    "_find_matched_config": [
      "self",
      "layer_name",
      "module"
    ],
    "_get_scheme_from_config": [
      "self",
      "config"
    ],
    "get_scheme": [
      "self",
      "layer",
      "layer_name"
    ],
    "get_cache_scale": [
      "self",
      "name"
    ]
  },
  "QuarkLinearMethod": {
    "__init__": [
      "self",
      "quantization_config"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "QuarkKVCacheMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "validate_kv_cache_config": [
      "kv_cache_config"
    ]
  },
  "deep_compare": [
    "dict1",
    "dict2"
  ],
  "should_ignore_layer": [
    "layer_name",
    "ignore",
    "fused_mapping"
  ],
  "check_equal_or_regex_match": [
    "layer_name",
    "targets"
  ],
  "_is_equal_or_regex_match": [
    "value",
    "target",
    "check_contains"
  ],
  "quark_quantize_weight_to_mxfp4": [
    "w"
  ],
  "QuarkW8A8Int8": {
    "__init__": [
      "self",
      "qscheme",
      "is_static_input_scheme",
      "input_symmetric"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "is_rocm_aiter_fp4_asm_gemm_enabled": [],
  "QuarkOCP_MX": {
    "__init__": [
      "self",
      "weight_quant_spec",
      "input_quant_spec"
    ],
    "get_packed_dim": [
      "self",
      "dim",
      "quant_dtype"
    ],
    "get_min_capability": [
      "cls"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "QuarkScheme": {
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "QuarkW8A8Fp8": {
    "__init__": [
      "self",
      "weight_config",
      "input_config"
    ],
    "get_min_capability": [
      "cls"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "mxfp8_e4m3_quantize": [
    "x"
  ],
  "is_fp8": [
    "x"
  ],
  "_w8a8_triton_block_scaled_mm_func": [
    "qx",
    "weight",
    "x_scale",
    "weight_scale",
    "block_size",
    "output_dtype"
  ],
  "_w8a8_triton_block_scaled_mm_fake": [
    "qx",
    "weight",
    "x_scale",
    "weight_scale",
    "block_size",
    "output_dtype"
  ],
  "_padded_cutlass": [
    "qx",
    "weight",
    "x_scale",
    "weight_scale",
    "block_size",
    "output_dtype"
  ],
  "_padded_cutlass_fake": [
    "qx",
    "weight",
    "x_scale",
    "weight_scale",
    "block_size",
    "output_dtype"
  ],
  "_fp8_gemm_nt_op": [
    "q_input",
    "input_scale",
    "weight",
    "weight_scale",
    "output",
    "use_deep_gemm_e8m0"
  ],
  "_fp8_gemm_nt_op_fake": [
    "q_input",
    "input_scale",
    "weight",
    "weight_scale",
    "output",
    "use_deep_gemm_e8m0"
  ],
  "_triton_per_token_group_quant_fp8_impl": [
    "x",
    "group_size"
  ],
  "_triton_per_token_group_quant_fp8_fake": [
    "x",
    "group_size"
  ],
  "_flashinfer_fp8_blockscale_gemm_impl": [
    "input",
    "weight",
    "weight_scale",
    "group_size",
    "use_deep_gemm_e8m0"
  ],
  "_flashinfer_fp8_blockscale_gemm_fake": [
    "input",
    "weight",
    "weight_scale",
    "group_size",
    "use_deep_gemm_e8m0"
  ],
  "W8A8BlockFp8LinearOp": {
    "__init__": [
      "self",
      "weight_group_shape",
      "act_quant_group_shape",
      "cutlass_block_fp8_supported",
      "use_aiter_and_is_supported"
    ],
    "apply": [
      "self",
      "input",
      "weight",
      "weight_scale",
      "input_scale",
      "bias"
    ],
    "_run_deepgemm": [
      "self",
      "input_2d",
      "weight",
      "weight_scale"
    ],
    "_run_cutlass": [
      "self",
      "input_2d",
      "weight",
      "weight_scale",
      "input_scale"
    ],
    "_run_aiter": [
      "self",
      "input_2d",
      "weight",
      "weight_scale",
      "input_scale"
    ],
    "_run_triton": [
      "self",
      "input_2d",
      "weight",
      "weight_scale",
      "input_scale"
    ],
    "_run_flashinfer": [
      "self",
      "input_2d",
      "weight",
      "weight_scale"
    ],
    "_dispatch_w8a8_blockscale_op": [
      "self",
      "use_cutlass",
      "use_aiter_and_is_supported"
    ]
  },
  "input_to_float8": [
    "x",
    "dtype"
  ],
  "_per_token_group_quant_fp8": [
    "y_ptr",
    "y_q_ptr",
    "y_s_ptr",
    "group_size",
    "y_num_columns",
    "y_row_stride",
    "eps",
    "fp8_min",
    "fp8_max",
    "use_ue8m0",
    "BLOCK"
  ],
  "_silu_mul_per_token_group_quant_fp8_colmajor": [
    "y_ptr",
    "y_q_ptr",
    "y_s_ptr",
    "M",
    "N",
    "y_s_col_stride",
    "eps",
    "fp8_min",
    "fp8_max",
    "use_ue8m0",
    "GROUP_SIZE",
    "BLOCK_M",
    "BLOCK_N"
  ],
  "silu_mul_per_token_group_quant_fp8_colmajor": [
    "input",
    "output",
    "use_ue8m0",
    "eps"
  ],
  "_per_token_group_quant_fp8_colmajor": [
    "y_ptr",
    "y_q_ptr",
    "y_s_ptr",
    "group_size",
    "y_num_columns",
    "y_row_stride",
    "y_s_col_stride",
    "eps",
    "fp8_min",
    "fp8_max",
    "use_ue8m0",
    "BLOCK"
  ],
  "per_token_group_quant_fp8": [
    "x",
    "group_size",
    "eps",
    "dtype",
    "column_major_scales",
    "tma_aligned_scales",
    "out_q",
    "use_ue8m0"
  ],
  "per_token_group_quant_fp8_packed_for_deepgemm": [
    "x",
    "group_size",
    "eps",
    "use_ue8m0",
    "out_q"
  ],
  "_w8a8_triton_block_scaled_mm": [
    "A",
    "B",
    "C",
    "As",
    "Bs",
    "M",
    "N",
    "K",
    "group_n",
    "group_k",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "stride_As_m",
    "stride_As_k",
    "stride_Bs_k",
    "stride_Bs_n",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M"
  ],
  "get_w8a8_block_fp8_configs": [
    "N",
    "K",
    "block_n",
    "block_k"
  ],
  "w8a8_triton_block_scaled_mm": [
    "A",
    "B",
    "As",
    "Bs",
    "block_size",
    "output_dtype"
  ],
  "requant_weight_ue8m0_inplace": [
    "weight",
    "weight_scale",
    "block_size"
  ],
  "deepgemm_post_process_fp8_weight_block": [
    "wq",
    "ws",
    "quant_block_shape",
    "use_e8m0"
  ],
  "prepare_fp8_moe_layer_for_deepgemm": [
    "w13",
    "w2",
    "w13_scale",
    "w2_scale",
    "block_shape"
  ],
  "_maybe_pad_fp8_weight": [
    "weight"
  ],
  "validate_fp8_block_shape": [
    "layer",
    "input_size",
    "output_size",
    "input_size_per_partition",
    "output_partition_sizes",
    "block_size"
  ],
  "create_fp8_weight_parameter": [
    "output_size_per_partition",
    "input_size_per_partition",
    "weight_loader"
  ],
  "create_fp8_scale_parameter": [
    "parameter_type",
    "output_partition_sizes",
    "input_size_per_partition",
    "block_size",
    "weight_loader"
  ],
  "create_fp8_input_scale": [
    "output_partition_sizes",
    "weight_loader"
  ],
  "process_fp8_weight_tensor_strategy": [
    "weight",
    "weight_scale",
    "logical_widths",
    "input_scale"
  ],
  "process_fp8_weight_channel_strategy": [
    "weight",
    "weight_scale",
    "input_scale"
  ],
  "process_fp8_weight_block_strategy": [
    "weight",
    "weight_scale"
  ],
  "maybe_post_process_fp8_weight_block": [
    "layer"
  ],
  "process_fp8_weight_tensor_strategy_moe": [
    "weight",
    "weight_scales",
    "shard_size",
    "num_experts",
    "is_act_and_mul"
  ],
  "process_fp8_input_tensor_strategy_moe": [
    "w13_input_scale",
    "w2_input_scale"
  ],
  "FP4_MARLIN_SUPPORTED_GROUP_SIZES": [],
  "is_fp4_marlin_supported": [],
  "nvfp4_marlin_process_scales": [
    "marlin_scales"
  ],
  "mxfp4_marlin_process_scales": [
    "marlin_scales",
    "input_dtype"
  ],
  "nvfp4_marlin_process_global_scale": [
    "global_scale"
  ],
  "apply_fp4_marlin_linear": [
    "input",
    "weight",
    "weight_scale",
    "weight_scale_2",
    "workspace",
    "size_n",
    "size_k",
    "bias",
    "input_dtype",
    "use_fp32_reduce"
  ],
  "prepare_fp4_layer_for_marlin": [
    "layer",
    "input_dtype"
  ],
  "prepare_nvfp4_moe_layer_for_marlin": [
    "layer",
    "w13",
    "w13_scale",
    "w13_scale_2",
    "w2",
    "w2_scale",
    "w2_scale_2",
    "is_act_and_mul"
  ],
  "prepare_moe_fp4_layer_for_marlin": [
    "layer",
    "input_dtype"
  ],
  "rand_marlin_weight_nvfp4_like": [
    "weight",
    "group_size",
    "input_dtype"
  ],
  "rand_marlin_weight_mxfp4_like": [
    "weight",
    "group_size",
    "input_dtype"
  ],
  "MINIMUM_BITBLAS_VERSION": [],
  "BITBLAS_MIN_WEIGHT_SIZE_N": [],
  "BITBLAS_MIN_WEIGHT_SIZE_K": [],
  "GPTQ_BITBLAS_MAX_PARALLEL": [],
  "BITBLAS_SUPPORTED_GROUP_SIZES": [],
  "BITBLAS_OPTIMIZE_FEATURES": [],
  "BITBLAS_OPTIMIZE_FEATURES_CONTIGUOUS": [],
  "BITBLAS_SUPPORTED_NUM_BITS": [],
  "BITBLAS_SUPPORTED_SYM": [],
  "query_bitblas_supported_quant_types": [
    "has_zp",
    "device_capability"
  ],
  "_check_bitblas_supported": [
    "quant_type",
    "group_size",
    "has_zp",
    "device_capability"
  ],
  "check_bitblas_supported": [
    "quant_type",
    "group_size",
    "has_zp",
    "device_capability"
  ],
  "verify_bitblas_supported": [
    "quant_type",
    "group_size",
    "has_zp"
  ],
  "verify_bitblas_supports_shape": [
    "output_size_per_partition",
    "input_size_per_partition",
    "input_size",
    "group_size"
  ],
  "check_bitblas_supports_shape": [
    "output_size_per_partition",
    "input_size_per_partition",
    "input_size",
    "group_size"
  ],
  "bitblas_is_k_full": [
    "act_order",
    "is_row_parallel"
  ],
  "bitblas_repeat_scales_on_all_ranks": [
    "act_order",
    "group_size",
    "is_row_parallel"
  ],
  "bitblas_make_empty_g_idx": [
    "device"
  ],
  "bitblas_make_empty_zp": [
    "device"
  ],
  "bitblas_sort_g_idx": [
    "g_idx"
  ],
  "unpack_gptq_qzeros": [
    "qzeros",
    "bits",
    "is_gptq_v2"
  ],
  "unpack_gptq_qweight": [
    "qweight",
    "bits"
  ],
  "get_dynamic_override": [
    "config",
    "layer_name",
    "key",
    "default_value"
  ],
  "is_layer_gptq_quantized": [
    "prefix",
    "quantized_layers",
    "fused_mapping"
  ],
  "get_linear_quant_method": [
    "config",
    "layer",
    "prefix",
    "linear_method_cls"
  ],
  "is_supported_config_trtllm": [
    "moe_config",
    "weight_key",
    "activation_key",
    "activation_format"
  ],
  "reorder_w1w3_to_w3w1": [
    "weight",
    "scale",
    "dim"
  ],
  "build_flashinfer_fp4_cutlass_moe_prepare_finalize": [
    "moe"
  ],
  "prepare_static_weights_for_trtllm_fp4_moe": [
    "gemm1_weights",
    "gemm2_weights",
    "gemm1_scales_linear_fp4_bytes",
    "gemm2_scales_linear_fp4_bytes",
    "hidden_size",
    "intermediate_size",
    "num_experts"
  ],
  "flashinfer_trtllm_fp4_moe": [
    "layer",
    "x",
    "router_logits",
    "top_k",
    "activation",
    "global_num_experts",
    "num_expert_group",
    "topk_group",
    "custom_routing_function",
    "e_score_correction_bias"
  ],
  "flashinfer_trtllm_fp4_routed_moe": [
    "layer",
    "x",
    "topk_ids",
    "topk_weights",
    "top_k",
    "activation",
    "global_num_experts"
  ],
  "prepare_nvfp4_moe_layer_for_fi_or_cutlass": [
    "backend",
    "layer",
    "w13",
    "w13_scale",
    "w13_scale_2",
    "a13_scale",
    "w2",
    "w2_scale",
    "w2_scale_2",
    "a2_scale",
    "is_act_and_mul"
  ],
  "_PETIT_INSTALL_MSG": [],
  "_import_petit_kernel": [],
  "_check_petit_nvfp4_supported": [
    "quant_method",
    "group_size"
  ],
  "verify_petit_nvfp4_supported": [
    "quant_method",
    "group_size"
  ],
  "prepare_nvfp4_layer_for_petit": [
    "layer"
  ],
  "apply_petit_nvfp4_linear": [
    "input",
    "weight",
    "weight_scale",
    "weight_scale_2",
    "size_n",
    "size_k",
    "bias"
  ],
  "_quant_dequant_mxfp6": [
    "x",
    "quant_dtype",
    "scale_calculation_mode"
  ],
  "_quant_dequant_mxfp6_fake": [
    "x",
    "quant_dtype",
    "scale_calculation_mode"
  ],
  "_dequant_mxfp6": [
    "x",
    "scale",
    "float_dtype",
    "quant_dtype"
  ],
  "_dequant_mxfp6_fake": [
    "x",
    "scale",
    "float_dtype",
    "quant_dtype"
  ],
  "quant_dequant_mxfp6": [
    "x",
    "quant_dtype",
    "scale_calculation_mode"
  ],
  "dequant_mxfp6": [
    "x",
    "scale",
    "float_dtype",
    "quant_dtype"
  ],
  "kE2M1ToFloat": [],
  "break_fp4_bytes": [
    "a",
    "dtype"
  ],
  "convert_swizzled_to_linear": [
    "a_sf_swizzled",
    "m",
    "k",
    "block_size"
  ],
  "dequantize_to_dtype": [
    "tensor_fp4",
    "tensor_sf",
    "global_scale",
    "dtype",
    "device",
    "block_size"
  ],
  "get_reciprocal": [
    "x"
  ],
  "cast_to_fp4": [
    "x"
  ],
  "ref_nvfp4_quant": [
    "x",
    "global_scale",
    "block_size"
  ],
  "run_nvfp4_emulations": [
    "x",
    "input_global_scale",
    "weight",
    "weight_scale_swizzled",
    "weight_global_scale"
  ],
  "_calculate_meta_reordering_scatter_offsets": [
    "m",
    "meta_ncols",
    "meta_dtype",
    "device"
  ],
  "sparse_semi_structured_from_dense_cutlass": [
    "dense"
  ],
  "sparse_semi_structured_to_dense_cutlass": [
    "sparse",
    "meta_reordered"
  ],
  "mask_creator": [
    "tensor"
  ],
  "inject_24": [
    "w",
    "size_k",
    "size_n"
  ],
  "check_24": [
    "w",
    "num_rows_to_sample",
    "_verbose"
  ],
  "compress_quantized_24_weight": [
    "q_24",
    "size_k",
    "size_n",
    "wtype"
  ],
  "get_scale_perms_24": [],
  "get_weight_perm_24": [
    "num_bits"
  ],
  "marlin_permute_scales_24": [
    "s",
    "size_k",
    "size_n",
    "group_size"
  ],
  "marlin_24_quantize": [
    "w",
    "quant_type",
    "group_size"
  ],
  "_swizzle_mxfp4": [
    "quant_tensor",
    "scale",
    "num_warps"
  ],
  "_can_support_mxfp4": [
    "use_grouped_topk",
    "topk_group",
    "num_expert_group",
    "expert_map",
    "custom_routing_function",
    "e_score_correction_bias",
    "apply_router_weight_on_input",
    "scoring_func",
    "activation",
    "expert_load_view",
    "logical_to_physical_map",
    "logical_replica_count"
  ],
  "get_padding_alignment": [],
  "_dequant_mxfp4": [
    "x",
    "scale",
    "float_dtype"
  ],
  "_dequant_mxfp4_fake": [
    "x",
    "scale",
    "float_dtype"
  ],
  "_quant_dequant_mxfp4": [
    "x",
    "scale_calculation_mode"
  ],
  "_quant_dequant_mxfp4_fake": [
    "x",
    "scale_calculation_mode"
  ],
  "get_fp8_min_max": [],
  "_GroupShape": {},
  "GroupShape": {
    "is_per_tensor": [
      "self"
    ],
    "is_per_token": [
      "self"
    ],
    "is_per_channel": [
      "self"
    ],
    "is_per_group": [
      "self"
    ]
  },
  "ScaleDesc": {
    "__str__": [
      "self"
    ]
  },
  "QuantKey": {
    "__str__": [
      "self"
    ]
  },
  "kStaticTensorScale": [],
  "kFp8StaticTensorSym": [],
  "kDynamicTensorScale": [],
  "kFp8DynamicTensorSym": [],
  "kStaticTokenScale": [],
  "kFp8StaticTokenSym": [],
  "kStaticChannelScale": [],
  "kFp8StaticChannelSym": [],
  "kDynamicTokenScale": [],
  "kFp8DynamicTokenSym": [],
  "kNvfp4DynamicGroupScale": [],
  "kNvfp4Dynamic": [],
  "kNvfp4StaticGroupScale": [],
  "kNvfp4Static": [],
  "kDynamic128Scale": [],
  "kFp8Dynamic128Sym": [],
  "kStatic128BlockScale": [],
  "kFp8Static128BlockSym": [],
  "kDynamic64Scale": [],
  "kFp8Dynamic64Sym": [],
  "_normalize_quant_group_shape": [
    "x",
    "group_shape"
  ],
  "group_broadcast": [
    "t",
    "shape"
  ],
  "prep_scale_for_group_broadcast": [
    "scale",
    "x",
    "group_shape"
  ],
  "scaled_quantize": [
    "x",
    "group_shape",
    "quant_dtype",
    "compute_dtype"
  ],
  "scaled_dequantize": [
    "x_q",
    "x_s",
    "group_shape",
    "out_dtype"
  ],
  "get_attribute_fallback": [
    "obj",
    "attributes"
  ],
  "get_and_maybe_dequant_weights": [
    "layer",
    "out_dtype"
  ],
  "pack_quantized_values_into_int32": [
    "w_q",
    "wtype",
    "packed_dim"
  ],
  "unpack_quantized_values_into_int32": [
    "w_q",
    "wtype",
    "packed_dim"
  ],
  "is_layer_skipped": [
    "prefix",
    "ignored_layers",
    "fused_mapping"
  ],
  "get_pack_factor": [
    "num_bits"
  ],
  "permute_rows": [
    "q_w",
    "w_ref",
    "group_size",
    "test_perm"
  ],
  "quantize_weights": [
    "w",
    "quant_type",
    "group_size",
    "zero_points",
    "ref_zero_points_after_scales"
  ],
  "SUPPORTED_GPTQ_QUANT_TYPES": [],
  "SUPPORTED_GROUP_SIZES": [],
  "gptq_quantize_weights": [
    "w",
    "quant_type",
    "group_size",
    "act_order",
    "test_perm"
  ],
  "sort_weights": [
    "q_w",
    "g_idx"
  ],
  "pack_rows": [
    "q_w",
    "num_bits",
    "size_k",
    "size_n"
  ],
  "pack_cols": [
    "q_w",
    "num_bits",
    "size_k",
    "size_n"
  ],
  "unpack_cols": [
    "packed_q_w",
    "num_bits",
    "size_k",
    "size_n"
  ],
  "gptq_pack": [
    "q_w",
    "num_bits",
    "size_k",
    "size_n"
  ],
  "awq_pack": [
    "q_w",
    "num_bits",
    "size_k",
    "size_n"
  ],
  "swizzle_blockscale": [
    "scale"
  ],
  "cutlass_fp4_supported": [],
  "convert_bf16_scales_to_fp8": [
    "quant_fp8",
    "scales"
  ],
  "convert_packed_uint4b8_to_signed_int4_inplace": [
    "t"
  ],
  "MarlinWorkspace": {
    "__init__": [
      "self",
      "out_features",
      "min_thread_n",
      "max_parallel"
    ]
  },
  "marlin_permute_weights": [
    "q_w",
    "size_k",
    "size_n",
    "perm",
    "tile",
    "is_a_8bit"
  ],
  "marlin_weights": [
    "q_w",
    "size_k",
    "size_n",
    "num_bits",
    "perm",
    "is_a_8bit"
  ],
  "get_weight_perm": [
    "num_bits",
    "is_a_8bit"
  ],
  "marlin_quantize": [
    "w",
    "quant_type",
    "group_size",
    "act_order",
    "test_perm",
    "input_dtype"
  ],
  "awq_marlin_quantize": [
    "w",
    "quant_type",
    "group_size",
    "input_dtype"
  ],
  "FlashinferMoeBackend": {
    "TENSORRT_LLM": [],
    "CUTLASS": [],
    "CUTEDSL": []
  },
  "swap_w13_to_w31": [
    "x"
  ],
  "rotate_weights_for_fi_trtllm_fp8_per_tensor_moe": [
    "gemm1_weights",
    "gemm2_weights"
  ],
  "register_scales_for_trtllm_fp8_per_tensor_moe": [
    "layer",
    "w13_scale",
    "w13_input_scale",
    "w2_scale",
    "w2_input_scale"
  ],
  "apply_fi_trtllm_fp8_per_tensor_moe": [
    "layer",
    "hidden_states",
    "router_logits",
    "routing_bias",
    "top_k",
    "num_expert_group",
    "topk_group",
    "global_num_experts",
    "apply_router_weight_on_input"
  ],
  "make_fp8_moe_alpha_scales_for_fi": [
    "w13_scale",
    "w13_input_scale",
    "w2_scale",
    "w2_input_scale"
  ],
  "build_flashinfer_fp8_cutlass_moe_prepare_finalize": [
    "moe",
    "use_deepseek_fp8_block_scale"
  ],
  "get_flashinfer_moe_backend": [],
  "is_flashinfer_supporting_global_sf": [
    "backend"
  ],
  "align_fp8_moe_weights_for_fi": [
    "w13",
    "w2",
    "is_act_and_mul"
  ],
  "prepare_fp8_moe_layer_for_fi": [
    "layer",
    "w13",
    "w2",
    "w13_scale",
    "w13_input_scale",
    "w2_scale",
    "w2_input_scale",
    "is_trtllm"
  ],
  "GPTQ_MARLIN_TILE": [],
  "GPTQ_MARLIN_MIN_THREAD_N": [],
  "GPTQ_MARLIN_MIN_THREAD_K": [],
  "GPTQ_MARLIN_MAX_PARALLEL": [],
  "MARLIN_SUPPORTED_GROUP_SIZES": [],
  "USE_FP32_REDUCE_DEFAULT": [],
  "query_marlin_supported_quant_types": [
    "has_zp",
    "include_fp_type",
    "device_capability"
  ],
  "_query_cpu_marlin_supported_quant_types": [
    "has_zp",
    "include_fp_type"
  ],
  "_check_marlin_supported": [
    "quant_type",
    "group_size",
    "has_zp",
    "device_capability"
  ],
  "check_marlin_supported": [
    "quant_type",
    "group_size",
    "has_zp",
    "device_capability"
  ],
  "verify_marlin_supported": [
    "quant_type",
    "group_size",
    "has_zp"
  ],
  "verify_marlin_supports_shape": [
    "output_size_per_partition",
    "input_size_per_partition",
    "input_size",
    "group_size"
  ],
  "check_marlin_supports_shape": [
    "output_size_per_partition",
    "input_size_per_partition",
    "input_size",
    "group_size"
  ],
  "check_marlin_supports_layer": [
    "layer",
    "group_size"
  ],
  "check_moe_marlin_supports_layer": [
    "layer",
    "group_size"
  ],
  "marlin_moe_intermediate_size": [
    "w1_packed",
    "w2_packed"
  ],
  "marlin_make_workspace": [
    "output_size_per_partition",
    "device"
  ],
  "marlin_make_workspace_new": [
    "device",
    "max_blocks_per_sm"
  ],
  "marlin_is_k_full": [
    "act_order",
    "is_row_parallel"
  ],
  "marlin_repeat_scales_on_all_ranks": [
    "act_order",
    "group_size",
    "is_row_parallel"
  ],
  "marlin_make_empty_g_idx": [
    "device"
  ],
  "marlin_make_empty_zp": [
    "device"
  ],
  "marlin_sort_g_idx": [
    "g_idx"
  ],
  "get_scale_perms": [],
  "marlin_permute_scales": [
    "s",
    "size_k",
    "size_n",
    "group_size",
    "is_a_8bit"
  ],
  "marlin_permute_bias": [
    "s"
  ],
  "marlin_act_int8_process_scales": [
    "s"
  ],
  "marlin_moe_permute_scales": [
    "s",
    "size_k",
    "size_n",
    "group_size",
    "is_a_8bit"
  ],
  "marlin_zero_points": [
    "zp",
    "size_k",
    "size_n",
    "num_bits",
    "is_a_8bit"
  ],
  "awq_to_marlin_zero_points": [
    "q_zp_packed",
    "size_k",
    "size_n",
    "num_bits",
    "is_a_8bit"
  ],
  "moe_awq_to_marlin_zero_points": [
    "q_zp_packed",
    "size_k",
    "size_n",
    "num_bits",
    "is_a_8bit"
  ],
  "maybe_warn_marlin_atomic_add": [
    "device",
    "dtype"
  ],
  "maybe_warn_marlin_atomic_add_env": [],
  "should_use_atomic_add_reduce": [
    "m",
    "n",
    "k",
    "device",
    "dtype"
  ],
  "get__quant_fp8_method": [],
  "get_marlin_input_dtype": [
    "prefix"
  ],
  "marlin_quant_input": [
    "x",
    "quant_dtype"
  ],
  "apply_gptq_marlin_linear": [
    "input",
    "weight",
    "weight_scale",
    "weight_zp",
    "g_idx",
    "g_idx_sort_indices",
    "workspace",
    "wtype",
    "output_size_per_partition",
    "input_size_per_partition",
    "is_k_full",
    "input_global_scale",
    "bias",
    "use_fp32_reduce",
    "input_dtype"
  ],
  "apply_awq_marlin_linear": [
    "input",
    "weight",
    "weight_scale",
    "weight_zp",
    "g_idx",
    "g_idx_sort_indices",
    "workspace",
    "quant_type",
    "output_size_per_partition",
    "input_size_per_partition",
    "input_global_scale",
    "bias",
    "use_fp32_reduce",
    "input_dtype"
  ],
  "sparse_cutlass_supported": [],
  "cutlass_fp8_supported": [],
  "cutlass_block_fp8_supported": [],
  "CUTLASS_FP8_SUPPORTED": [],
  "CUTLASS_BLOCK_FP8_SUPPORTED": [],
  "per_tensor_dequantize": [
    "tensor",
    "inv_scale"
  ],
  "all_close_1d": [
    "x"
  ],
  "convert_to_channelwise": [
    "weight_scale",
    "logical_widths"
  ],
  "requantize_with_max_scale": [
    "weight",
    "weight_scale",
    "logical_widths"
  ],
  "normalize_e4m3fn_to_e4m3fnuz": [
    "weight",
    "weight_scale",
    "input_scale"
  ],
  "MACHETE_PREPACKED_BLOCK_SHAPE": [],
  "query_machete_supported_quant_types": [
    "zero_points"
  ],
  "query_machete_supported_act_types": [
    "zero_points"
  ],
  "query_machete_supported_group_sizes": [
    "act_type"
  ],
  "check_machete_supports_shape": [
    "in_features",
    "out_featrues"
  ],
  "OCP_MX_BLOCK_SIZE": [],
  "OCP_MX_DTYPES": [],
  "SUPPORTED_OCP_MX_DTYPES": [],
  "OCP_MX_Scheme": {
    "w_mxfp4_a_mxfp4": [],
    "w_mxfp4_a_mxfp6_e3m2": [],
    "w_mxfp4_a_mxfp6_e2m3": [],
    "w_mxfp6_e3m2_a_mxfp6_e3m2": [],
    "w_mxfp6_e2m3_a_mxfp6_e2m3": [],
    "from_quant_dtype": [
      "cls",
      "input_dtype",
      "weight_dtype"
    ]
  },
  "ALLSPARK_AMPERE_M_CUBLAS_THRESHOLD": [],
  "ALLSPARK_SUPPORTED_QUANT_TYPES": [],
  "ALLSPARK_AMPERE_N_ALIGN": [],
  "ALLSPARK_AMPERE_K_ALIGN": [],
  "check_allspark_supported_dtype_shape": [
    "input_size_per_partition",
    "output_size_per_partition",
    "group_size",
    "weight_dtype",
    "act_dtype"
  ],
  "is_fp8_marlin_supported": [],
  "fp8_fused_exponent_bias_into_scales": [
    "scales"
  ],
  "apply_fp8_marlin_linear": [
    "input",
    "weight",
    "weight_scale",
    "workspace",
    "size_n",
    "size_k",
    "bias",
    "input_dtype",
    "use_fp32_reduce"
  ],
  "prepare_fp8_layer_for_marlin": [
    "layer",
    "size_k_first",
    "input_dtype"
  ],
  "prepare_fp8_moe_layer_for_marlin": [
    "layer",
    "w13_weight",
    "w2_weight",
    "w13_weight_scale",
    "w2_weight_scale"
  ],
  "pack_fp8_to_int32": [
    "fp8_tensor",
    "size_k_first"
  ],
  "marlin_quant_fp8_torch": [
    "weight",
    "group_size",
    "input_dtype"
  ],
  "apply_w8a8_block_int8_linear": [
    "input",
    "weight",
    "block_size",
    "weight_scale",
    "input_scale",
    "bias"
  ],
  "input_to_int8": [
    "x",
    "dtype"
  ],
  "block_dequant": [
    "x_q_block",
    "x_s",
    "block_size"
  ],
  "_per_token_quant_int8": [
    "x_ptr",
    "xq_ptr",
    "scale_ptr",
    "stride_x",
    "stride_xq",
    "N",
    "BLOCK"
  ],
  "per_token_quant_int8": [
    "x"
  ],
  "_per_token_group_quant_int8": [
    "y_ptr",
    "y_q_ptr",
    "y_s_ptr",
    "y_stride",
    "N",
    "eps",
    "int8_min",
    "int8_max",
    "BLOCK"
  ],
  "per_token_group_quant_int8": [
    "x",
    "group_size",
    "eps",
    "dtype"
  ],
  "_w8a8_block_int8_matmul": [
    "A",
    "B",
    "C",
    "As",
    "Bs",
    "M",
    "N",
    "K",
    "group_n",
    "group_k",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "stride_As_m",
    "stride_As_k",
    "stride_Bs_k",
    "stride_Bs_n",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M"
  ],
  "get_w8a8_block_int8_configs": [
    "N",
    "K",
    "block_n",
    "block_k"
  ],
  "w8a8_block_int8_matmul": [
    "A",
    "B",
    "As",
    "Bs",
    "block_size",
    "output_dtype"
  ],
  "update_tensor_inplace": [
    "dst",
    "src"
  ],
  "QUANTIZATION_SCHEME_MAP_TYPE": [],
  "CompressedTensorsConfig": {
    "__init__": [
      "self",
      "target_scheme_map",
      "ignore",
      "quant_format",
      "sparsity_scheme_map",
      "sparsity_ignore_list",
      "kv_cache_scheme",
      "config",
      "transform_config",
      "total_num_heads",
      "total_num_kv_heads"
    ],
    "get_linear_method": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_name": [
      "self"
    ],
    "apply_vllm_mapper": [
      "self",
      "hf_to_vllm_mapper"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "_add_fused_moe_to_target_scheme_map": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "_parse_sparsity_config": [
      "cls",
      "config"
    ],
    "_quantization_scheme_map_from_config": [
      "cls",
      "config"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "_check_scheme_supported": [
      "min_capability",
      "error",
      "match_exact"
    ],
    "_is_nvfp4_format": [
      "quant_args"
    ],
    "_is_mxfp4": [
      "quant_args"
    ],
    "_is_static_tensor_w8a8": [
      "weight_quant",
      "input_quant"
    ],
    "_is_dynamic_token_w8a8": [
      "weight_quant",
      "input_quant"
    ],
    "_is_dynamic_token_w4a8_int": [
      "weight_quant",
      "input_quant"
    ],
    "_is_fp8_w8a8": [
      "weight_quant",
      "input_quant"
    ],
    "_is_fp8_w4a8": [
      "weight_quant",
      "input_quant"
    ],
    "_is_fp8_w4a8_sm90": [
      "cls",
      "weight_quant",
      "input_quant"
    ],
    "_is_fp8_w8a8_sm90": [
      "cls",
      "weight_quant",
      "input_quant"
    ],
    "_is_fp8_w8a8_sm100": [
      "cls",
      "weight_quant",
      "input_quant"
    ],
    "_is_fp8_w8a16": [
      "weight_quant",
      "input_quant"
    ],
    "_is_wNa16_group_channel": [
      "weight_quant",
      "input_quant"
    ],
    "_get_scheme_from_parts": [
      "self",
      "weight_quant",
      "input_quant",
      "format",
      "layer_name"
    ],
    "get_scheme": [
      "self",
      "layer",
      "layer_name"
    ],
    "get_scheme_dict": [
      "self",
      "layer",
      "layer_name"
    ],
    "has_blocked_weights": [
      "self"
    ],
    "supports_cutlass_24": [
      "weight_quant",
      "input_quant",
      "sparsity_scheme"
    ]
  },
  "CompressedTensorsLinearMethod": {
    "__init__": [
      "self",
      "quantization_config"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "CompressedTensorsKVCacheMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "validate_kv_cache_scheme": [
      "kv_cache_scheme"
    ],
    "create_weights": [
      "self",
      "layer"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "is_activation_quantization_format": [
    "format"
  ],
  "find_matched_target": [
    "layer_name",
    "module",
    "targets",
    "fused_mapping"
  ],
  "_find_first_match": [
    "value",
    "targets",
    "check_contains"
  ],
  "_match_fused_layer": [
    "layer_name",
    "target_layers",
    "fused_mapping"
  ],
  "GPTQMarlinState": {
    "REPACK": [],
    "READY": []
  },
  "CompressedTensorsMoEMethod": {
    "get_moe_method": [
      "quant_config",
      "layer",
      "layer_name"
    ]
  },
  "CompressedTensorsW4A4Mxfp4MoEMethod": {
    "__init__": [
      "self",
      "moe"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "CompressedTensorsW4A4Nvfp4MoEMethod": {
    "__init__": [
      "self",
      "moe",
      "layer_name",
      "use_a16"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "maybe_make_prepare_finalize": [
      "self",
      "routing_tables"
    ],
    "select_gemm_impl": [
      "self",
      "prepare_finalize",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "is_monolithic": [
      "self"
    ],
    "apply_monolithic": [
      "self",
      "layer",
      "x",
      "router_logits"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "CompressedTensorsW8A8Fp8MoEMethod": {
    "__init__": [
      "self",
      "weight_quant",
      "input_quant",
      "moe",
      "layer_name"
    ],
    "topk_indices_dtype": [
      "self"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "maybe_make_prepare_finalize": [
      "self",
      "routing_tables"
    ],
    "select_gemm_impl": [
      "self",
      "prepare_finalize",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "is_monolithic": [
      "self"
    ],
    "apply_monolithic": [
      "self",
      "layer",
      "x",
      "router_logits"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ],
    "supports_eplb": [
      "self"
    ]
  },
  "CompressedTensorsW8A8Int8MoEMethod": {
    "__init__": [
      "self",
      "weight_quant",
      "input_quant",
      "moe",
      "layer_name"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "CompressedTensorsWNA16MarlinMoEMethod": {
    "__init__": [
      "self",
      "weight_quant",
      "input_quant",
      "moe",
      "layer_name"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "select_gemm_impl": [
      "self",
      "prepare_finalize",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ]
  },
  "CompressedTensorsWNA16MoEMethod": {
    "__init__": [
      "self",
      "weight_quant",
      "input_quant",
      "moe",
      "layer_name"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "select_gemm_impl": [
      "self",
      "prepare_finalize",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ],
    "supports_eplb": [
      "self"
    ]
  },
  "CompressedTensorsW4A8Int8MoEMethod": {
    "__init__": [
      "self",
      "weight_quant",
      "input_quant",
      "moe",
      "layer_name"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "is_monolithic": [
      "self"
    ],
    "apply_monolithic": [
      "self",
      "layer",
      "x",
      "router_logits"
    ]
  },
  "CompressedTensorsW4A8Fp8MoEMethod": {
    "__init__": [
      "self",
      "weight_quant",
      "input_quant",
      "moe",
      "layer_name"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "maybe_make_prepare_finalize": [
      "self",
      "routing_tables"
    ],
    "get_fused_moe_quant_config": [
      "self",
      "layer"
    ],
    "select_gemm_impl": [
      "self",
      "prepare_finalize",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "topk_weights",
      "topk_ids"
    ],
    "supports_eplb": [
      "self"
    ]
  },
  "is_weak_contiguous": [
    "x"
  ],
  "scaled_mm_kernel": [
    "a_ptr",
    "b_ptr",
    "scale_a_ptr",
    "scale_b_ptr",
    "c_ptr",
    "bias_ptr",
    "M",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "ACCUMULATOR_DTYPE",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "BLOCK_SIZE_SCALE_A",
    "BLOCK_SIZE_SCALE_B"
  ],
  "triton_scaled_mm": [
    "input",
    "weight",
    "scale_a",
    "scale_b",
    "out_dtype",
    "bias",
    "block_size_m",
    "block_size_n",
    "block_size_k",
    "use_heuristic"
  ],
  "CompressedTensorsW4A4Fp4": {
    "__init__": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "strategy_to_parameter_type": [],
  "STATIC_QUANT": [],
  "DYNAMIC_QUANT": [],
  "activation_quant_key_mapping": [],
  "weight_quant_key_mapping": [],
  "CompressedTensorsW8A8Fp8": {
    "__init__": [
      "self",
      "weight_quant",
      "is_static_input_scheme"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype",
      "weight_loader"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "CompressedTensorsW4A16Mxfp4": {
    "__init__": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "WNA16_SUPPORTED_TYPES_MAP": [],
  "WNA16_ZP_SUPPORTED_TYPES_MAP": [],
  "WNA16_SUPPORTED_BITS": [],
  "CompressedTensorsWNA16": {
    "__init__": [
      "self",
      "strategy",
      "num_bits",
      "group_size",
      "symmetric",
      "actorder",
      "layer_name"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_size",
      "input_size",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "W4A8_SUPPORTED_TYPES_MAP": [],
  "W4A8_SUPPORTED_BITS": [],
  "CompressedTensorsW4A8Fp8": {
    "__init__": [
      "self",
      "strategy",
      "num_bits",
      "group_size",
      "symmetric",
      "actorder"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_size",
      "input_size",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "CompressedTensorsW8A8Int8": {
    "__init__": [
      "self",
      "strategy",
      "is_static_input_scheme",
      "input_symmetric"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "CompressedTensorsW4A16Fp4": {
    "__init__": [
      "self",
      "has_input_global_scale"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "CompressedTensors24": {
    "__init__": [
      "self",
      "quantized",
      "weight_quant",
      "input_quant",
      "model_compression_config"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "_get_params_dtype": [
      "self",
      "params_dtype"
    ],
    "_get_quant_dtype": [
      "self"
    ],
    "_decompress_bitmask_compressed_weight": [
      "self",
      "compressed",
      "bitmask",
      "layer"
    ]
  },
  "CompressedTensorsW4A8Int": {
    "__init__": [
      "self",
      "strategy",
      "num_bits",
      "group_size",
      "is_static_input_scheme",
      "input_symmetric"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_size",
      "input_size",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "SUPPORTED_STRATEGIES": [],
  "CompressedTensorsW8A16Fp8": {
    "__init__": [
      "self",
      "strategy",
      "is_static_input_scheme"
    ],
    "get_min_capability": [
      "cls"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "CompressedTensorsScheme": {
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "W4A16SPARSE24_SUPPORTED_TYPES_MAP": [],
  "W4A16SPARSE24_SUPPORTED_BITS": [],
  "CompressedTensorsW4A16Sparse24": {
    "__init__": [
      "self",
      "strategy",
      "num_bits",
      "group_size"
    ],
    "get_min_capability": [
      "cls"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "TransformTuple": {},
  "HadamardTransform": {
    "__init__": [
      "self",
      "transforms",
      "layer",
      "weight_loader",
      "input_size_per_partition",
      "output_partition_sizes"
    ],
    "process_weights_after_loading": [
      "self"
    ],
    "forward": [
      "self",
      "value",
      "part_id"
    ],
    "_get_data_key": [
      "self",
      "scheme",
      "weight_size"
    ],
    "_get_weight_size": [
      "self",
      "layer",
      "scheme",
      "args",
      "input_size",
      "output_size"
    ],
    "_validate_input_transforms": [
      "self"
    ]
  },
  "CompressedTensorsLinearTransformMethod": {
    "from_schemes": [
      "cls",
      "quant_method",
      "quant_scheme",
      "input_tfms",
      "output_tfms"
    ],
    "__init__": [
      "self",
      "quant_method",
      "input_tfms",
      "output_tfms"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "_validate_tfm_schemes": [
      "self",
      "num_partitions"
    ]
  },
  "get_linear_transform_schemes": [
    "layer",
    "layer_name",
    "transform_config",
    "packed_modules_mapping"
  ],
  "get_schemes_args": [
    "transform_config"
  ],
  "get_layer_partition_names": [
    "layer_name",
    "packed_modules_mapping"
  ],
  "is_qutlass_fp4_scheme": [
    "quant_scheme",
    "input_tfms"
  ],
  "QutlassNvFP4LinearMethod": {
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "NUM_WARPS": [],
  "chunk_gated_delta_rule_fwd_kernel_h_blockdim64": [
    "k",
    "v",
    "w",
    "v_new",
    "g",
    "gk",
    "h",
    "h0",
    "ht",
    "cu_seqlens",
    "chunk_offsets",
    "T",
    "H",
    "Hg",
    "K",
    "V",
    "BT",
    "BV",
    "USE_G",
    "USE_GK",
    "USE_INITIAL_STATE",
    "STORE_FINAL_STATE",
    "SAVE_NEW_VALUE",
    "IS_VARLEN"
  ],
  "chunk_gated_delta_rule_fwd_h": [
    "k",
    "w",
    "u",
    "g",
    "gk",
    "initial_state",
    "output_final_state",
    "chunk_size",
    "save_new_value",
    "cu_seqlens"
  ],
  "prepare_lens": [
    "cu_seqlens"
  ],
  "prepare_chunk_indices": [
    "cu_seqlens",
    "chunk_size"
  ],
  "prepare_chunk_offsets": [
    "cu_seqlens",
    "chunk_size"
  ],
  "FLA_TRIL_PRECISION": [],
  "ALLOWED_TRIL_PRECISIONS": [],
  "solve_tril_16x16_kernel": [
    "A",
    "Ai",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "BT",
    "USE_TMA",
    "IS_VARLEN",
    "DOT_PRECISION"
  ],
  "merge_16x16_to_32x32_inverse_kernel": [
    "A",
    "Ai",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "BT",
    "USE_TMA",
    "IS_VARLEN",
    "DOT_PRECISION"
  ],
  "merge_16x16_to_64x64_inverse_kernel": [
    "A",
    "Ai",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "BT",
    "USE_TMA",
    "IS_VARLEN",
    "DOT_PRECISION"
  ],
  "solve_tril": [
    "A",
    "cu_seqlens",
    "output_dtype"
  ],
  "recompute_w_u_fwd_kernel": [
    "k",
    "v",
    "beta",
    "w",
    "u",
    "A",
    "g",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "Hg",
    "K",
    "V",
    "BT",
    "BK",
    "BV",
    "IS_VARLEN"
  ],
  "recompute_w_u_fwd": [
    "k",
    "v",
    "beta",
    "g_cumsum",
    "A",
    "cu_seqlens"
  ],
  "chunk_scaled_dot_kkt_fwd_kernel": [
    "k",
    "beta",
    "g",
    "A",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "Hg",
    "K",
    "BT",
    "BK",
    "IS_VARLEN",
    "USE_G"
  ],
  "chunk_scaled_dot_kkt_fwd": [
    "k",
    "g",
    "beta",
    "cu_seqlens",
    "chunk_size",
    "output_dtype"
  ],
  "BT_LIST_AUTOTUNE": [],
  "NUM_WARPS_AUTOTUNE": [],
  "fused_recurrent_kda_fwd": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "inplace_final_state",
    "cu_seqlens",
    "ssm_state_indices",
    "num_accepted_tokens",
    "use_qk_l2norm_in_kernel"
  ],
  "fused_recurrent_kda": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "inplace_final_state",
    "use_qk_l2norm_in_kernel",
    "cu_seqlens",
    "ssm_state_indices"
  ],
  "layer_norm_gated_fwd_kernel": [
    "x",
    "g",
    "y",
    "w",
    "b",
    "residual",
    "residual_out",
    "mean",
    "rstd",
    "eps",
    "T",
    "D",
    "BT",
    "BD",
    "ACTIVATION",
    "IS_RMS_NORM",
    "STORE_RESIDUAL_OUT",
    "HAS_RESIDUAL",
    "HAS_WEIGHT",
    "HAS_BIAS"
  ],
  "layer_norm_gated_fwd_kernel1": [
    "x",
    "g",
    "y",
    "w",
    "b",
    "residual",
    "residual_out",
    "mean",
    "rstd",
    "eps",
    "D",
    "BD",
    "ACTIVATION",
    "IS_RMS_NORM",
    "STORE_RESIDUAL_OUT",
    "HAS_RESIDUAL",
    "HAS_WEIGHT",
    "HAS_BIAS"
  ],
  "layer_norm_gated_fwd": [
    "x",
    "g",
    "weight",
    "bias",
    "activation",
    "eps",
    "residual",
    "out_dtype",
    "residual_dtype",
    "is_rms_norm"
  ],
  "FusedRMSNormGated": {
    "__init__": [
      "self",
      "hidden_size",
      "elementwise_affine",
      "eps",
      "activation",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "x",
      "g",
      "residual",
      "prenorm",
      "residual_in_fp32"
    ]
  },
  "chunk_kda_scaled_dot_kkt_fwd_kernel_intra_sub_inter": [
    "q",
    "k",
    "g",
    "beta",
    "A",
    "Aqk",
    "scale",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "K",
    "BT",
    "BC",
    "BK",
    "NC",
    "IS_VARLEN"
  ],
  "chunk_kda_scaled_dot_kkt_fwd_kernel_intra_sub_intra": [
    "q",
    "k",
    "g",
    "beta",
    "A",
    "Aqk",
    "scale",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "K",
    "BT",
    "BC",
    "BK",
    "IS_VARLEN"
  ],
  "chunk_kda_scaled_dot_kkt_fwd": [
    "q",
    "k",
    "gk",
    "beta",
    "scale",
    "cu_seqlens",
    "chunk_size",
    "output_dtype"
  ],
  "chunk_gla_fwd_kernel_o": [
    "q",
    "v",
    "g",
    "h",
    "o",
    "A",
    "cu_seqlens",
    "chunk_indices",
    "scale",
    "T",
    "H",
    "K",
    "V",
    "BT",
    "BK",
    "BV",
    "IS_VARLEN"
  ],
  "chunk_gla_fwd_o_gk": [
    "q",
    "v",
    "g",
    "A",
    "h",
    "o",
    "scale",
    "cu_seqlens",
    "chunk_size"
  ],
  "chunk_kda_fwd": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "output_final_state",
    "cu_seqlens"
  ],
  "chunk_kda": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "output_final_state",
    "use_qk_l2norm_in_kernel",
    "cu_seqlens"
  ],
  "kda_gate_fwd_kernel": [
    "g",
    "A",
    "y",
    "g_bias",
    "beta",
    "threshold",
    "T",
    "H",
    "D",
    "BT",
    "BD",
    "HAS_BIAS"
  ],
  "fused_kda_gate": [
    "g",
    "A",
    "head_k_dim",
    "g_bias",
    "beta",
    "threshold"
  ],
  "COMPILER_MODE": [],
  "FLA_CI_ENV": [],
  "FLA_GDN_FIX_BT": [],
  "SUPPRESS_LEVEL": [],
  "tensor_cache": [
    "fn"
  ],
  "input_guard": [
    "fn"
  ],
  "get_available_device": [],
  "_check_platform": [],
  "device": [],
  "device_torch_lib": [],
  "device_platform": [],
  "is_amd": [],
  "is_intel": [],
  "is_nvidia": [],
  "is_intel_alchemist": [],
  "is_nvidia_hopper": [],
  "use_cuda_graph": [],
  "is_gather_supported": [],
  "is_tma_supported": [],
  "get_all_max_shared_mem": [],
  "Backend": {
    "ADA": [],
    "AMPERE": [],
    "HOPPER": [],
    "DEFAULT": [],
    "get_shared_memory": [
      "cls",
      "arch"
    ]
  },
  "check_shared_mem": [
    "arch",
    "tensor_idx"
  ],
  "BT_LIST": [],
  "USE_DEFAULT_FLA_NORM": [],
  "l2norm_fwd_kernel1": [
    "x",
    "y",
    "D",
    "BD",
    "eps"
  ],
  "l2norm_fwd_kernel": [
    "x",
    "y",
    "eps",
    "NB",
    "T",
    "D",
    "BT",
    "BD"
  ],
  "l2norm_fwd_kernel2": [
    "X",
    "Y",
    "eps",
    "M",
    "N",
    "MBLOCK"
  ],
  "l2norm_fwd": [
    "x",
    "eps",
    "output_dtype"
  ],
  "chunk_gated_delta_rule_fwd": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "output_final_state",
    "cu_seqlens"
  ],
  "ChunkGatedDeltaRuleFunction": {
    "forward": [
      "ctx",
      "q",
      "k",
      "v",
      "g",
      "beta",
      "scale",
      "initial_state",
      "output_final_state",
      "cu_seqlens",
      "use_qk_l2norm_in_kernel"
    ]
  },
  "chunk_gated_delta_rule": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "output_final_state",
    "cu_seqlens",
    "head_first",
    "use_qk_l2norm_in_kernel"
  ],
  "fused_recurrent_gated_delta_rule_fwd_kernel": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "o",
    "h0",
    "ht",
    "cu_seqlens",
    "ssm_state_indices",
    "num_accepted_tokens",
    "scale",
    "N",
    "T",
    "B",
    "H",
    "HV",
    "K",
    "V",
    "BK",
    "BV",
    "stride_init_state_token",
    "stride_final_state_token",
    "stride_indices_seq",
    "stride_indices_tok",
    "USE_INITIAL_STATE",
    "INPLACE_FINAL_STATE",
    "IS_BETA_HEADWISE",
    "USE_QK_L2NORM_IN_KERNEL",
    "IS_VARLEN",
    "IS_CONTINUOUS_BATCHING",
    "IS_SPEC_DECODING",
    "IS_KDA"
  ],
  "fused_recurrent_gated_delta_rule_fwd": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "inplace_final_state",
    "cu_seqlens",
    "ssm_state_indices",
    "num_accepted_tokens",
    "use_qk_l2norm_in_kernel"
  ],
  "FusedRecurrentFunction": {
    "forward": [
      "ctx",
      "q",
      "k",
      "v",
      "g",
      "beta",
      "scale",
      "initial_state",
      "inplace_final_state",
      "cu_seqlens",
      "ssm_state_indices",
      "num_accepted_tokens",
      "use_qk_l2norm_in_kernel"
    ]
  },
  "fused_recurrent_gated_delta_rule": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "inplace_final_state",
    "cu_seqlens",
    "ssm_state_indices",
    "num_accepted_tokens",
    "use_qk_l2norm_in_kernel"
  ],
  "BKV_LIST": [],
  "chunk_fwd_kernel_o": [
    "q",
    "k",
    "v",
    "h",
    "g",
    "o",
    "cu_seqlens",
    "chunk_indices",
    "scale",
    "T",
    "H",
    "Hg",
    "K",
    "V",
    "BT",
    "BK",
    "BV",
    "USE_G",
    "IS_VARLEN"
  ],
  "chunk_fwd_o": [
    "q",
    "k",
    "v",
    "h",
    "g",
    "scale",
    "cu_seqlens",
    "chunk_size"
  ],
  "BS_LIST": [],
  "chunk_local_cumsum_scalar_kernel": [
    "s",
    "o",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "B",
    "H",
    "BT",
    "REVERSE",
    "IS_VARLEN",
    "HEAD_FIRST"
  ],
  "chunk_local_cumsum_vector_kernel": [
    "s",
    "o",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "B",
    "H",
    "S",
    "BT",
    "BS",
    "REVERSE",
    "IS_VARLEN",
    "HEAD_FIRST"
  ],
  "chunk_local_cumsum_scalar": [
    "g",
    "chunk_size",
    "reverse",
    "cu_seqlens",
    "head_first",
    "output_dtype"
  ],
  "chunk_local_cumsum_vector": [
    "g",
    "chunk_size",
    "reverse",
    "cu_seqlens",
    "head_first",
    "output_dtype"
  ],
  "chunk_local_cumsum": [
    "g",
    "chunk_size",
    "reverse",
    "cu_seqlens",
    "head_first",
    "output_dtype"
  ],
  "rms_norm_ref": [
    "x",
    "weight",
    "bias",
    "z",
    "eps",
    "group_size",
    "norm_before_gate",
    "upcast"
  ],
  "layer_norm_fwd_kernel": [
    "X",
    "Y",
    "W",
    "B",
    "Z",
    "Mean",
    "Rstd",
    "stride_x_row",
    "stride_y_row",
    "stride_z_row",
    "M",
    "N",
    "eps",
    "BLOCK_N",
    "ROWS_PER_BLOCK",
    "HAS_BIAS",
    "HAS_Z",
    "NORM_BEFORE_GATE",
    "IS_RMS_NORM"
  ],
  "_get_sm_count": [
    "device"
  ],
  "calc_rows_per_block": [
    "M",
    "device"
  ],
  "layer_norm_fwd": [
    "x",
    "weight",
    "bias",
    "eps",
    "z",
    "out",
    "group_size",
    "norm_before_gate",
    "is_rms_norm"
  ],
  "LayerNormFn": {
    "forward": [
      "ctx",
      "x",
      "weight",
      "bias",
      "z",
      "eps",
      "group_size",
      "norm_before_gate",
      "is_rms_norm"
    ]
  },
  "layernorm_fn": [
    "x",
    "weight",
    "bias",
    "z",
    "eps",
    "group_size",
    "norm_before_gate",
    "is_rms_norm"
  ],
  "rmsnorm_fn": [
    "x",
    "weight",
    "bias",
    "z",
    "eps",
    "group_size",
    "norm_before_gate"
  ],
  "LayerNormGated": {
    "__init__": [
      "self",
      "hidden_size",
      "eps",
      "group_size",
      "norm_before_gate",
      "device",
      "dtype"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "z"
    ]
  },
  "T_co": [],
  "VllmModel": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions"
    ]
  },
  "_check_vllm_model_init": [
    "model"
  ],
  "_check_vllm_model_embed_input_ids": [
    "model"
  ],
  "_check_vllm_model_forward": [
    "model"
  ],
  "is_vllm_model": [
    "model"
  ],
  "VllmModelForTextGeneration": {
    "compute_logits": [
      "self",
      "hidden_states"
    ]
  },
  "is_text_generation_model": [
    "model"
  ],
  "VllmModelForPooling": {},
  "is_pooling_model": [
    "model"
  ],
  "default_pooling_type": [],
  "get_default_seq_pooling_type": [
    "model"
  ],
  "get_default_tok_pooling_type": [
    "model"
  ],
  "attn_type": [
    "attn_type"
  ],
  "get_attn_type": [
    "model"
  ],
  "SharedHead": {
    "__init__": [
      "self",
      "config",
      "prefix",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Glm4MoeLiteMultiTokenPredictorLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "previous_hidden_states",
      "inputs_embeds",
      "spec_step_index"
    ]
  },
  "Glm4MoeLiteMultiTokenPredictor": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "previous_hidden_states",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ]
  },
  "Glm4MoeLiteMTP": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "intermediate_tensors",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_rewrite_spec_layer_name": [
      "self",
      "spec_layer",
      "name"
    ]
  },
  "_MAX_FRAMES_PER_VIDEO": [],
  "MiniCPMVImagePixelInputs": {},
  "MiniCPMVImageEmbeddingInputs": {},
  "Resampler2_5": {
    "__init__": [
      "self",
      "num_queries",
      "embed_dim",
      "num_heads",
      "kv_dim",
      "norm_layer",
      "max_size",
      "quant_config",
      "prefix"
    ],
    "_set_2d_pos_cache": [
      "self",
      "max_size",
      "device"
    ],
    "_adjust_pos_cache": [
      "self",
      "tgt_sizes",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "tgt_sizes"
    ]
  },
  "Resampler4_5": {
    "__init__": [
      "self",
      "num_queries",
      "embed_dim",
      "num_heads",
      "kv_dim",
      "norm_layer",
      "max_size",
      "max_temporal_size",
      "quant_config",
      "prefix"
    ],
    "get_1d_sincos_pos_embed_from_temporal_size": [
      "self",
      "embed_dim",
      "pos"
    ],
    "_set_temporal_pos_cache": [
      "self",
      "max_temporal_size",
      "device"
    ],
    "_adjust_temporal_pos_cache": [
      "self",
      "max_temporal_size",
      "device"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "forward": [
      "self",
      "x",
      "tgt_sizes",
      "temporal_ids"
    ]
  },
  "get_version_by_config": [
    "config"
  ],
  "_minicpmv_field_config": [
    "hf_inputs"
  ],
  "MiniCPMVImageEmbeddingItems": {
    "__init__": [
      "self",
      "data",
      "fields_factory"
    ],
    "get_image_size": [
      "self",
      "index"
    ]
  },
  "MiniCPMVVideoEmbeddingItems": {
    "__init__": [
      "self",
      "data",
      "fields_factory"
    ],
    "get_frame_size": [
      "self",
      "index"
    ],
    "get_num_frames": [
      "self",
      "index"
    ]
  },
  "MiniCPMVMultiModalDataParser": {
    "_parse_image_data": [
      "self",
      "data"
    ],
    "_parse_video_data": [
      "self",
      "data"
    ]
  },
  "MiniCPMVProcessingInfo": {
    "image_pattern": [],
    "video_pattern": [],
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_model_version": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_slice_image_placeholder": [
      "self",
      "image_size",
      "image_idx",
      "max_slice_nums",
      "use_image_id"
    ],
    "get_sliced_grid": [
      "self",
      "image_size",
      "max_slice_nums"
    ],
    "get_num_image_tokens": [
      "self",
      "image_size",
      "max_slice_nums"
    ],
    "get_max_image_tokens": [
      "self"
    ],
    "get_image_max_slice_num": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_max_video_frame_tokens": [
      "self"
    ],
    "get_max_video_tokens": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "get_video_max_slice_num": [
      "self"
    ],
    "get_video_frame_size_with_most_features": [
      "self"
    ],
    "get_max_video_frames": [
      "self",
      "max_tokens"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len",
      "mm_counts"
    ]
  },
  "_I": [],
  "MiniCPMVDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "MiniCPMVMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "get_image_prompt_texts": [
      "self",
      "image_size",
      "image_idx"
    ],
    "get_video_prompt_texts": [
      "self",
      "image_size",
      "num_frames"
    ],
    "process_images": [
      "self",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "process_videos": [
      "self",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "process_mm_inputs": [
      "self",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_base_call_hf_processor": [
      "self",
      "prompts",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_hf_processor_applies_updates": [
      "self",
      "prompt_text",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_recompute_cached_prompt_update": [
      "self",
      "cached_update",
      "new_item_idx"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "MiniCPMVBaseModel": {
    "supports_encoder_tp_data": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_vision_input": [
      "self",
      "modality"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "_process_vision_input": [
      "self",
      "image_input"
    ],
    "_process_multimodal_inputs": [
      "self",
      "modalities"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "init_llm": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "init_vision_module": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_resampler": [
      "self",
      "embed_dim",
      "vision_dim",
      "quant_config",
      "prefix"
    ],
    "get_vision_hidden_states": [
      "self",
      "data"
    ]
  },
  "MiniCPMV2_0": {
    "supports_encoder_tp_data": [],
    "__init__": [
      "self"
    ],
    "init_llm": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "init_vision_module": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_resampler": [
      "self",
      "embed_dim",
      "vision_dim",
      "quant_config",
      "prefix"
    ],
    "get_vision_hidden_states": [
      "self",
      "data"
    ]
  },
  "MiniCPMV2_5": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "init_llm": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "init_vision_module": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_resampler": [
      "self",
      "embed_dim",
      "vision_dim",
      "quant_config",
      "prefix"
    ],
    "get_vision_hidden_states": [
      "self",
      "data"
    ]
  },
  "MiniCPMV2_6": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "init_llm": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "init_vision_module": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_resampler": [
      "self",
      "embed_dim",
      "vision_dim",
      "quant_config",
      "prefix"
    ],
    "get_vision_hidden_states": [
      "self",
      "data"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiniCPMV4_0": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "init_llm": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "init_vision_module": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_resampler": [
      "self",
      "embed_dim",
      "vision_dim",
      "quant_config",
      "prefix"
    ],
    "get_vision_hidden_states": [
      "self",
      "data"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiniCPMV4_5": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "init_llm": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "init_vision_module": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_resampler": [
      "self",
      "embed_dim",
      "vision_dim",
      "quant_config",
      "prefix"
    ],
    "get_vision_hidden_states": [
      "self",
      "data"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_SUPPORT_VERSION": [],
  "MiniCPMV": {
    "__new__": [
      "cls"
    ]
  },
  "WhisperPosEmbedType": {
    "SINUSOIDAL": [],
    "ROPE": [],
    "LEARNED": []
  },
  "WhisperAudioInputs": {},
  "WhisperEncoderAttention": {
    "forward": [
      "self",
      "query",
      "key",
      "value"
    ]
  },
  "WhisperPositionalEmbedding": {
    "__init__": [
      "self",
      "num_positions",
      "embedding_dim"
    ],
    "forward": [
      "self",
      "position_ids"
    ]
  },
  "WhisperAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "bias",
      "attn_type",
      "per_layer_sliding_window",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "_init_qkv": [
      "self",
      "embed_dim",
      "bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "WhisperCrossAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "bias",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "_init_qkv": [
      "self",
      "embed_dim",
      "bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ]
  },
  "WhisperMLP": {
    "__init__": [
      "self",
      "embed_dim",
      "ffn_dim",
      "act_fn",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "WhisperEncoderLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "WhisperDecoderLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ]
  },
  "WhisperEncoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_features"
    ]
  },
  "WhisperDecoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "encoder_hidden_states"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ]
  },
  "WhisperModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "encoder_outputs"
    ],
    "get_encoder_outputs": [
      "self",
      "input_features"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "WhisperProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "skip_prompt_length_check": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_feature_extractor": [
      "self"
    ],
    "get_target_channels": [
      "self"
    ],
    "get_num_audio_tokens": [
      "self"
    ]
  },
  "WhisperDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "WhisperMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "create_encoder_prompt": [
      "self",
      "prompt",
      "mm_data"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "WhisperForConditionalGeneration": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "supports_transcription_only": [],
    "supports_segment_timestamp": [],
    "supported_languages": [],
    "validate_language": [
      "cls",
      "language"
    ],
    "get_generation_prompt": [
      "cls",
      "audio",
      "model_config",
      "stt_config",
      "language",
      "task_type",
      "request_prompt",
      "to_language"
    ],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "get_speech_to_text_config": [
      "cls",
      "model_config",
      "task_type"
    ],
    "get_num_audio_tokens": [
      "cls",
      "audio_duration_s",
      "stt_config",
      "model_config"
    ],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "encoder_outputs"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "_parse_and_validate_audio_input": [
      "self"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_create_fake_bias_for_k_proj": [
    "weights",
    "fake_bias_key_name"
  ],
  "Qwen2MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_parameters",
      "max_position",
      "cache_config",
      "quant_config",
      "prefix",
      "attn_type",
      "dual_chunk_attention_config",
      "qk_norm",
      "rms_norm_eps"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Qwen2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "qwen_2_model_invariants": [
    "input_ids",
    "positions",
    "intermediate_tensors",
    "inputs_embeds"
  ],
  "Qwen2Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen2ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MistralLarge3ForCausalLM": {
    "remapping": [],
    "load_weights": [
      "self",
      "weights"
    ],
    "_remap_mistral_to_ds": [
      "self",
      "weight"
    ]
  },
  "PaliGemmaImagePixelInputs": {},
  "PaliGemmaImageEmbeddingInputs": {},
  "PaliGemmaMultiModalProjector": {
    "__init__": [
      "self",
      "vision_hidden_size",
      "projection_dim"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "PaliGemmaProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_vision_encoder_info": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ]
  },
  "PaliGemmaDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "PaliGemmaMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "apply": [
      "self",
      "prompt",
      "mm_data",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs",
      "mm_uuids"
    ]
  },
  "PaliGemmaForConditionalGeneration": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_image_pixels_to_features": [
      "self",
      "vision_tower",
      "pixel_values"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "get_num_mm_encoder_tokens": [
      "self",
      "num_image_tokens"
    ],
    "get_num_mm_connector_tokens": [
      "self",
      "num_vision_tokens"
    ]
  },
  "KVCache": [],
  "Qwen3NextSparseMoeBlock": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen3NextGatedDeltaNet": {
    "mamba_type": [
      "self"
    ],
    "get_state_dtype": [
      "self"
    ],
    "get_state_shape": [
      "self"
    ],
    "__init__": [
      "self",
      "config",
      "model_config",
      "cache_config",
      "quant_config",
      "speculative_config",
      "prefix"
    ],
    "fix_query_key_value_ordering": [
      "self",
      "mixed_qkvz",
      "mixed_ba"
    ],
    "rearrange_mixed_qkv": [
      "self",
      "mixed_qkv"
    ],
    "forward": [
      "self",
      "hidden_states",
      "output"
    ],
    "_forward_core": [
      "self",
      "mixed_qkv",
      "b",
      "a",
      "core_attn_out"
    ]
  },
  "Qwen3NextAttention": {
    "__init__": [
      "self",
      "config",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "output",
      "hidden_states"
    ]
  },
  "Qwen3NextDecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "layer_type",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual",
      "positions"
    ]
  },
  "Qwen3NextModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "QwenNextMixtureOfExperts": {
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ],
    "set_moe_parameters": [
      "self"
    ]
  },
  "Qwen3NextForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "gdn_attention_core": [
    "mixed_qkv",
    "b",
    "a",
    "core_attn_out",
    "layer_name"
  ],
  "gdn_attention_core_fake": [
    "mixed_qkv",
    "b",
    "a",
    "core_attn_out",
    "layer_name"
  ],
  "fused_gdn_gating_kernel": [
    "g",
    "beta_output",
    "A_log",
    "a",
    "b",
    "dt_bias",
    "seq_len",
    "NUM_HEADS",
    "beta",
    "threshold",
    "BLK_HEADS"
  ],
  "fused_gdn_gating": [
    "A_log",
    "a",
    "b",
    "dt_bias",
    "beta",
    "threshold"
  ],
  "Qwen2_5_VLImagePixelInputs": {},
  "Qwen2_5_VLImageEmbeddingInputs": {},
  "Qwen2_5_VLVideoPixelInputs": {},
  "Qwen2_5_VLVideoEmbeddingInputs": {},
  "Qwen2_5_VisionMLP": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "bias",
      "act_fn",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2_5_VisionAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "projection_size",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin",
      "max_seqlen"
    ]
  },
  "Qwen2_5_VisionBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_hidden_dim",
      "act_fn",
      "norm_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin",
      "max_seqlen"
    ]
  },
  "Qwen2_5_VisionPatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "temporal_patch_size",
      "in_channels",
      "hidden_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2_5_VisionPatchMerger": {
    "__init__": [
      "self",
      "d_model",
      "context_dim",
      "norm_layer",
      "spatial_merge_size",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2_5_VisionTransformer": {
    "__init__": [
      "self",
      "vision_config",
      "norm_eps",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "rotary_pos_emb_thw": [
      "self",
      "t",
      "h",
      "w"
    ],
    "get_window_index_thw": [
      "self",
      "grid_t",
      "grid_h",
      "grid_w"
    ],
    "get_rope_by_thw": [
      "self",
      "t",
      "h",
      "w"
    ],
    "compute_attn_mask_seqlen": [
      "self",
      "cu_seqlens"
    ],
    "invert_permutation": [
      "perm"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen2_5_VLProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ]
  },
  "Qwen2_5_VLMultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Qwen2_5_VLForConditionalGeneration": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "supports_encoder_tp_data": [],
    "iter_mm_grid_thw": [
      "self",
      "mm_features"
    ],
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_postprocess_image_embeds_evs": [
      "self",
      "image_embeds_split",
      "image_input"
    ],
    "_process_video_input": [
      "self",
      "video_input"
    ],
    "_postprocess_video_embeds_evs": [
      "self",
      "video_embeds_split",
      "video_input"
    ],
    "recompute_mrope_positions": [
      "self",
      "input_ids",
      "multimodal_embeddings",
      "mrope_positions",
      "num_computed_tokens"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "get_num_mm_encoder_tokens": [
      "self",
      "num_image_tokens"
    ],
    "get_num_mm_connector_tokens": [
      "self",
      "num_vision_tokens"
    ]
  },
  "ArceeMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix",
      "reduce_results"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ArceeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "ArceeModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "ArceeForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GritLMMeanPool": {
    "__init__": [
      "self",
      "model_config"
    ],
    "_find_array": [
      "self",
      "arr",
      "target",
      "start_idx",
      "end_idx"
    ],
    "_get_instruction_len": [
      "self",
      "prompt_token_ids"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "get_pooling_updates": [
      "self",
      "task"
    ],
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "GritLMPooler": {
    "__init__": [
      "self",
      "model_config"
    ]
  },
  "GritLM": {
    "is_pooling_model": [],
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ]
  },
  "Plamo3Config": {},
  "rms_norm_weight_loader": [
    "offset"
  ],
  "DenseMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Plamo3AttentionMixer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Plamo3DecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Plamo3Decoder": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Plamo3Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "Plamo3ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_GENERATE_SUFFIXES": [],
  "_load_st_projector": [
    "model_config"
  ],
  "_load_dense_weights": [
    "linear",
    "folder",
    "model_config"
  ],
  "_get_pooling_model_name": [
    "orig_model_name",
    "pooling_suffix"
  ],
  "_create_pooling_model_cls": [
    "orig_cls"
  ],
  "as_embedding_model": [
    "cls"
  ],
  "as_seq_cls_model": [
    "cls"
  ],
  "SequenceClassificationConfig": {
    "verify_and_update_config": [
      "vllm_config"
    ]
  },
  "_get_language_model_for_seq_cls": [
    "model"
  ],
  "_disable_seq_cls_loading_on_inner_model": [
    "language_model",
    "is_vlm"
  ],
  "load_weights_using_from_2_way_softmax": [
    "model",
    "weights"
  ],
  "load_weights_no_post_processing": [
    "model",
    "weights"
  ],
  "SEQ_CLS_LOAD_METHODS": [],
  "seq_cls_model_loader": [
    "model",
    "weights"
  ],
  "MistralMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "gate_up_proj_bias",
      "prefix",
      "reduce_results",
      "disable_tp"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MistralAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "bias_o_proj",
      "cache_config",
      "prefix",
      "attn_type"
    ],
    "_get_llama_4_attn_scale": [
      "self",
      "positions"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "MistralDecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix",
      "config"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual",
      "t_cond"
    ]
  },
  "MistralModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds",
      "t_cond"
    ]
  },
  "MistralForCausalLM": {
    "mistral_mapping": [],
    "__init__": [
      "self"
    ],
    "_init_model": [
      "self",
      "vllm_config",
      "prefix",
      "layer_type"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "maybe_remap_mistral": [
      "self",
      "name",
      "loaded_weight"
    ]
  },
  "GLMVImagePixelInputs": {},
  "EVA2CLIPPatchEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "images"
    ]
  },
  "EVA2CLIPAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EVA2CLIPMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EVA2CLIPTransformerLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EVA2CLIPTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "EVA2CLIPGLU": {
    "__init__": [
      "self",
      "config",
      "in_features",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EVA2CLIPModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "images"
    ]
  },
  "GLM4VModel": {
    "__init__": [
      "self"
    ]
  },
  "GLM4VProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "return_tensors"
    ]
  },
  "GLM4VProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_num_image_feature_tokens": [
      "self"
    ]
  },
  "GLM4VDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "GLM4VMultiModalProcessor": {
    "_hf_processor_applies_updates": [
      "self",
      "prompt_text",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "GLM4VForCausalLM": {
    "packed_modules_mapping": [],
    "get_mm_mapping": [
      "self"
    ],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ],
    "embed_input_ids": [],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "EagleMistralLarge3Model": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "inputs_embeds"
    ]
  },
  "EagleMistralLarge3ForCausalLM": {
    "remapping": [],
    "__init__": [
      "self"
    ],
    "get_language_model": [
      "self"
    ],
    "embed_input_ids": [],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GPTBigCodeAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPTBigMLP": {
    "__init__": [
      "self",
      "intermediate_size",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPTBigCodeBlock": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPTBigCodeModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GPTBigCodeForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GraniteMoeMoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "params_dtype",
      "quant_config",
      "tp_size",
      "is_sequence_parallel",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GraniteMoeAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position",
      "rope_parameters",
      "cache_config",
      "quant_config",
      "attention_multiplier",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "GraniteMoeDecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "GraniteMoeModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "_load_weights": [
      "self",
      "weights"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GraniteMoeForCausalLM": {
    "fall_back_to_pt_during_load": [],
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "make_empty_intermediate_tensors": [
      "self",
      "batch_size",
      "dtype",
      "device"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Idefics3ImagePixelInputs": {},
  "Idefics3ImageEmbeddingInputs": {},
  "Idefics3ProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "_resize_output_size": [
      "self"
    ],
    "_get_resize_output_image_size": [
      "self"
    ],
    "_get_image_feature_grid_size": [
      "self"
    ],
    "get_num_patches": [
      "self"
    ],
    "_get_image_token": [
      "self",
      "processor"
    ],
    "get_image_repl": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "Idefics3DummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Idefics3MultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Idefics3SimpleMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Idefics3Connector": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pixel_shuffle": [
      "self",
      "x",
      "scale_factor"
    ],
    "forward": [
      "self",
      "image_hidden_states"
    ]
  },
  "Idefics3Model": {
    "__init__": [
      "self"
    ],
    "image_pixels_to_features": [
      "self",
      "pixel_values",
      "pixel_attention_mask"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "Idefics3ForConditionalGeneration": {
    "packed_modules_mapping": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_pixels": [
      "self",
      "inputs"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "get_num_mm_encoder_tokens": [
      "self",
      "num_image_tokens"
    ],
    "get_num_mm_connector_tokens": [
      "self",
      "num_vision_tokens"
    ]
  },
  "_cast_if_autocast_enabled": [],
  "NemotronLayerNorm1P": {
    "__init__": [
      "self",
      "normalized_shape",
      "eps",
      "elementwise_affine",
      "bias",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "x",
      "residual"
    ]
  },
  "NemotronMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NemotronAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "cache_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "NemotronDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "NemotronModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "NemotronForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "TeleChat2Model": {
    "__init__": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "TeleChat2ForCausalLM": {
    "hf_to_vllm_mapper": [],
    "_init_model": [
      "self",
      "vllm_config",
      "prefix",
      "layer_type"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_get_gemma_act_fn": [
    "hidden_act",
    "hidden_activation"
  ],
  "GemmaMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "hidden_activation",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GemmaAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "head_dim",
      "rope_parameters",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "GemmaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "GemmaModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GemmaForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "IMG_START": [],
  "IMG_END": [],
  "IMG_CONTEXT": [],
  "IMAGENET_MEAN": [],
  "IMAGENET_STD": [],
  "InternVLImagePixelInputs": {},
  "InternVLImageEmbeddingInputs": {},
  "InternVLVideoPixelInputs": {},
  "InternVLVideoEmbeddingInputs": {},
  "build_transform": [
    "input_size"
  ],
  "find_closest_aspect_ratio": [
    "aspect_ratio",
    "target_ratios"
  ],
  "resolve_internvl_min_max_num": [],
  "get_internvl_target_ratios": [
    "min_num",
    "max_num"
  ],
  "calculate_internvl_targets": [],
  "dynamic_preprocess_internvl": [
    "image"
  ],
  "image_to_pixel_values_internvl": [
    "image"
  ],
  "video_to_pixel_values_internvl": [
    "video"
  ],
  "BaseInternVLProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "image_token_id": [
      "self"
    ],
    "get_image_repl": [
      "self",
      "feature_size",
      "num_patches"
    ],
    "resolve_min_max_num": [
      "self"
    ],
    "resolve_target_ratios": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "_images_to_pixel_values_lst": [
      "self",
      "images",
      "min_dynamic_patch",
      "max_dynamic_patch",
      "dynamic_image_size"
    ],
    "_preprocess_image": [
      "self",
      "text",
      "images",
      "min_dynamic_patch",
      "max_dynamic_patch",
      "dynamic_image_size"
    ],
    "_make_batch_input": [
      "self",
      "input_item"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "min_dynamic_patch",
      "max_dynamic_patch",
      "dynamic_image_size",
      "return_tensors"
    ]
  },
  "InternVLProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "image_token_id": [
      "self"
    ],
    "video_token_id": [
      "self"
    ],
    "supports_video": [
      "self"
    ],
    "_videos_to_pixel_values_lst": [
      "self",
      "videos",
      "dynamic_image_size"
    ],
    "_preprocess_video": [
      "self",
      "text",
      "videos",
      "dynamic_image_size"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "videos",
      "min_dynamic_patch",
      "max_dynamic_patch",
      "dynamic_image_size",
      "return_tensors"
    ],
    "get_image_repl": [
      "self",
      "feature_size",
      "num_patches"
    ],
    "get_video_repl": [
      "self",
      "feature_size",
      "num_patches",
      "video_context_token"
    ]
  },
  "BaseInternVLProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_max_image_tokens": [
      "self"
    ]
  },
  "BaseInternVLDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "BaseInternVLMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "InternVLProcessingInfo": {
    "supports_video": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_video_token": [
      "self"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "get_hf_processor": [
      "self"
    ]
  },
  "InternVLDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "InternVLMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "InternVLChatModel": {
    "supports_encoder_tp_data": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_patch_quant_config": [
      "self",
      "config",
      "quant_config"
    ],
    "_init_vision_model": [
      "self",
      "config",
      "quant_config"
    ],
    "_init_mlp1": [
      "self",
      "config"
    ],
    "pixel_shuffle": [
      "self",
      "x",
      "scale_factor"
    ],
    "extract_feature": [
      "self",
      "pixel_values"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_process_vision_input": [
      "self",
      "image_input"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "_set_visual_token_mask": [
      "self",
      "input_ids"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "get_num_mm_encoder_tokens": [
      "self",
      "num_image_tokens"
    ],
    "get_num_mm_connector_tokens": [
      "self",
      "num_vision_tokens"
    ]
  },
  "GPTNeoXAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "GPTNeoXMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPTNeoXLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "GPTNeoXModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GPTNeoXForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "FlexOlmoAttention": {
    "__init__": [
      "self"
    ]
  },
  "FlexOlmoMoE": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "FlexOlmoDecoderLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "FlexOlmoForCausalLM": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self"
    ]
  },
  "KimiMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "KimiMoE": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "KimiMLAAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "v_head_dim",
      "q_lora_rank",
      "kv_lora_rank",
      "use_nope",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "output"
    ]
  },
  "KimiDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "cache_config",
      "quant_config",
      "parallel_config",
      "model_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "KimiLinearModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "KimiLinearForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "get_spec_layer_idx_from_weight_name": [
    "config",
    "weight_name"
  ],
  "ModernBertEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds"
    ]
  },
  "ModernBertAttention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids"
    ]
  },
  "ModernBertMLP": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ModernBertLayer": {
    "__init__": [
      "self",
      "config",
      "prefix",
      "layer_id"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids"
    ]
  },
  "ModernBertEncoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids"
    ]
  },
  "ModernBertModel": {
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "ModernBertPooler": {
    "__init__": [
      "self",
      "model_config"
    ]
  },
  "ModernBertForSequenceClassification": {
    "is_pooling_model": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "ModernBertPredictionHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ModernBertForTokenClassification": {
    "is_pooling_model": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "GlmAsrEncoderRotaryEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "seq_len"
    ]
  },
  "GlmAsrEncoderAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin"
    ]
  },
  "GlmAsrEncoderMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GlmAsrEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin"
    ]
  },
  "_GlmAsrEncoderOutput": {
    "__slots__": [],
    "__init__": [
      "self",
      "last_hidden_state"
    ]
  },
  "GlmAsrEncoder": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "_get_feat_extract_output_lengths": [
      "self",
      "input_lengths"
    ],
    "forward": [
      "self",
      "input_features"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GlmAsrFeatureInputs": {},
  "GlmAsrEmbeddingInputs": {},
  "GlmAsrMultiModalProjector": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "audio_features"
    ]
  },
  "GlmAsrProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_feature_extractor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ]
  },
  "GlmAsrDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "_glmasr_field_config": [
    "hf_inputs"
  ],
  "GlmAsrMultiModalDataParser": {
    "_parse_audio_data": [
      "self",
      "data"
    ]
  },
  "GlmAsrMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_calculate_chunk_counts": [
      "self",
      "audio_list",
      "feature_extractor",
      "processor"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "GlmAsrForConditionalGeneration": {
    "supported_languages": [],
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "_parse_and_validate_audio_input": [
      "self"
    ],
    "_process_audio_input": [
      "self",
      "audio_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_get_audio_token": [
      "cls",
      "model_config"
    ],
    "get_speech_to_text_config": [
      "cls",
      "model_config",
      "task_type"
    ],
    "get_generation_prompt": [
      "cls",
      "audio",
      "model_config",
      "stt_config",
      "language",
      "task_type",
      "request_prompt",
      "to_language"
    ]
  },
  "MLPBlock": {
    "__init__": [
      "self",
      "embedding_dim",
      "mlp_dim",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LayerNorm2d": {
    "__init__": [
      "self",
      "num_channels",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ImageEncoderViT": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "in_chans",
      "embed_dim",
      "depth",
      "num_heads",
      "mlp_ratio",
      "out_chans",
      "qkv_bias",
      "norm_layer",
      "act_layer",
      "use_abs_pos",
      "use_rel_pos",
      "rel_pos_zero_init",
      "window_size",
      "global_attn_indexes"
    ],
    "get_abs_pos": [
      "self",
      "abs_pos",
      "tgt_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Block": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "norm_layer",
      "act_layer",
      "use_rel_pos",
      "rel_pos_zero_init",
      "window_size",
      "input_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RelPosAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "qkv_bias",
      "use_rel_pos",
      "rel_pos_zero_init",
      "input_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "window_partition": [
    "x",
    "window_size"
  ],
  "window_unpartition": [
    "windows",
    "window_size",
    "pad_hw",
    "hw"
  ],
  "get_rel_pos": [
    "q_size",
    "k_size",
    "rel_pos"
  ],
  "add_decomposed_rel_pos": [
    "q",
    "rel_pos_h",
    "rel_pos_w",
    "q_size",
    "k_size"
  ],
  "PatchEmbed": {
    "__init__": [
      "self",
      "kernel_size",
      "stride",
      "padding",
      "in_chans",
      "embed_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "build_sam_vit_b": [],
  "_build_sam": [
    "encoder_embed_dim",
    "encoder_depth",
    "encoder_num_heads",
    "encoder_global_attn_indexes"
  ],
  "DeepCLIPVisionEmbeddings": {
    "get_abs_pos": [
      "self",
      "abs_pos",
      "tgt_size"
    ],
    "forward": [
      "self",
      "pixel_values",
      "patch_embeds"
    ]
  },
  "DeepCLIPVisionTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "patch_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DUMMY_VIDEO_NUM_FRAMES": [],
  "Qwen3_VisionPatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "temporal_patch_size",
      "in_channels",
      "hidden_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3_VisionMLP": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "bias",
      "act_fn",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3_VisionBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_hidden_dim",
      "act_fn",
      "norm_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin",
      "max_seqlen"
    ]
  },
  "Qwen3_VisionPatchMerger": {
    "__init__": [
      "self",
      "d_model",
      "context_dim",
      "norm_layer",
      "spatial_merge_size",
      "use_postshuffle_norm",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3_VisionTransformer": {
    "__init__": [
      "self",
      "vision_config",
      "norm_eps",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "rot_pos_ids": [
      "h",
      "w",
      "spatial_merge_size"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "fast_pos_embed_interpolate": [
      "self",
      "grid_thw"
    ],
    "compute_attn_mask_seqlen": [
      "self",
      "cu_seqlens"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3VLProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_video_processor": [
      "self"
    ],
    "_get_vision_info": [
      "self"
    ],
    "_get_max_video_frames": [
      "self",
      "max_tokens",
      "start_num_frames"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "get_max_video_tokens": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "_calculate_timestamps": [
      "self",
      "indices",
      "video_fps",
      "merge_size"
    ],
    "_get_video_second_idx": [
      "self",
      "metadata",
      "out_item",
      "do_sample_frames",
      "sampled_fps"
    ]
  },
  "Qwen3VLDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ],
    "_get_dummy_videos": [
      "self"
    ]
  },
  "Qwen3VLMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Qwen3LLMModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds",
      "deepstack_input_embeds"
    ]
  },
  "Qwen3LLMForCausalLM": {
    "__init__": [
      "self"
    ]
  },
  "Qwen3VLForConditionalGeneration": {
    "packed_modules_mapping": [],
    "supports_encoder_tp_data": [],
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ],
    "_get_deepstack_input_embeds": [
      "self",
      "num_tokens"
    ],
    "_set_deepstack_input_embeds": [
      "self",
      "deepstack_input_embeds"
    ],
    "_clear_deepstack_input_embeds": [
      "self",
      "num_tokens"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_process_video_input": [
      "self",
      "video_input"
    ],
    "_postprocess_image_embeds_evs": [
      "self",
      "image_embeds_split",
      "image_input"
    ],
    "_postprocess_video_embeds_evs": [
      "self",
      "video_embeds_split",
      "video_input"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "iter_mm_grid_hw": [
      "self",
      "input_tokens",
      "mm_features"
    ],
    "_get_evs_mask_segments": [
      "self",
      "mm_position",
      "expected_frames"
    ],
    "_extract_frame_offsets_from_mask": [
      "self",
      "mm_position",
      "expected_frames"
    ],
    "_get_actual_frame_token_counts": [
      "self",
      "mm_position",
      "expected_frames"
    ],
    "recompute_mrope_positions": [
      "self",
      "input_ids",
      "multimodal_embeddings",
      "mrope_positions",
      "num_computed_tokens"
    ],
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ],
    "embed_multimodal": [
      "self"
    ],
    "_compute_deepstack_embeds": [
      "self",
      "inputs_embeds",
      "multimodal_embeddings",
      "is_multimodal"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "get_num_mm_encoder_tokens": [
      "self",
      "num_image_tokens"
    ],
    "get_num_mm_connector_tokens": [
      "self",
      "num_vision_tokens"
    ]
  },
  "Glm4MoeMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Glm4MoE": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Glm4MoeAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "head_dim",
      "rms_norm_eps",
      "qkv_bias",
      "use_qk_norm",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Glm4MoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Glm4MoeModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Glm4MixtureOfExperts": {
    "extract_moe_parameters": [
      "self",
      "example_moe"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ]
  },
  "Glm4MoeForCausalLM": {
    "packed_modules_mapping": [],
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "_apply_rope_input_validation": [
    "x",
    "freqs_cis"
  ],
  "apply_rope": [
    "xq",
    "xk",
    "freqs_cis"
  ],
  "Learnable2DInterpPosEmb": {
    "__init__": [
      "self",
      "height",
      "width",
      "dim",
      "interpolation_mode"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "grid_hws"
    ]
  },
  "MoonVisionPatchEmbed": {
    "__init__": [
      "self",
      "out_dim",
      "in_dim",
      "patch_size",
      "pos_emb_height",
      "pos_emb_width"
    ],
    "forward": [
      "self",
      "x",
      "grid_hw"
    ]
  },
  "Rope2DPosEmb": {
    "__init__": [
      "self",
      "dim",
      "max_height",
      "max_width",
      "theta_base",
      "device"
    ],
    "extra_repr": [
      "self"
    ],
    "precomputed_freqs_cis": [
      "self"
    ],
    "get_freqs_cis_by_seqlens": [
      "self",
      "grid_hws"
    ],
    "get_freqs_cis_by_idx": [
      "self",
      "pos_idx",
      "pos_idx_mask"
    ]
  },
  "MLP2": {
    "__init__": [
      "self",
      "dims",
      "activation",
      "bias",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MoonVitEncoderLayer": {
    "__init__": [
      "self",
      "num_heads",
      "hidden_dim",
      "mlp_dim",
      "prefix"
    ],
    "attention_qkvpacked": [
      "self",
      "x",
      "cu_seqlens",
      "rope_freqs_cis"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rope_freqs_cis"
    ]
  },
  "MoonVitEncoder": {
    "__init__": [
      "self",
      "hidden_dim",
      "num_layers",
      "block_cfg",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "grid_hw"
    ]
  },
  "patch_merger": [
    "x",
    "grid_hw",
    "merge_kernel_size"
  ],
  "MoonVitPretrainedModel": {
    "config_class": [],
    "model_type": [],
    "_no_split_modules": [],
    "_supports_flash_attn_2": [],
    "_supports_sdpa": [],
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "pixel_values",
      "grid_hw"
    ]
  },
  "_IMAGE_TOKEN_ID": [],
  "CLIP_VIT_LARGE_PATCH14_336_CONFIG": [],
  "_init_img_processor": [
    "hf_config",
    "quant_config",
    "prefix"
  ],
  "Phi3VImagePixelInputs": {},
  "Phi3VImageEmbeddingInputs": {},
  "Phi3HDImageEmbedding": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_img_features": [
      "self",
      "img_embeds"
    ],
    "forward": [
      "self",
      "pixel_values",
      "image_sizes"
    ],
    "hd_feature_transform": [
      "self",
      "image_features",
      "image_sizes"
    ],
    "reshape_hd_patches_2x2merge": [
      "self",
      "image_features",
      "h_crop",
      "w_crop"
    ],
    "add_image_newline": [
      "self",
      "image_features_hd"
    ]
  },
  "Phi3VProcessingInfo": {
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "Phi3VDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Phi3VMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_recompute_cached_prompt_update": [
      "self",
      "cached_update",
      "new_item_idx"
    ],
    "_apply_prompt_updates": [
      "self",
      "token_ids",
      "mm_prompt_updates"
    ]
  },
  "Phi3VForCausalLM": {
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GraniteMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GraniteAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "cache_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "GraniteDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "GraniteModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GraniteForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "make_empty_intermediate_tensors": [
      "self",
      "batch_size",
      "dtype",
      "device"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "ApertusMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix",
      "reduce_results"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ApertusAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "bias_o_proj",
      "cache_config",
      "prefix",
      "attn_type"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ],
    "_init_rotary_emb": [
      "self",
      "config",
      "quant_config"
    ]
  },
  "ApertusDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "ApertusModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "ApertusForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ],
    "_init_model": [
      "self",
      "vllm_config",
      "prefix",
      "layer_type"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Glm4MoeLiteMLP": {},
  "Glm4MoeLite": {},
  "Glm4LiteMixtureOfExperts": {},
  "Glm4MoeLiteAttention": {},
  "Glm4MoeLiteMLAAttention": {},
  "Glm4MoeLiteDecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix",
      "config",
      "topk_indices_buffer"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual",
      "llama_4_scaling"
    ]
  },
  "Glm4MoeLiteModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "make_empty_intermediate_tensors": [
      "self",
      "batch_size",
      "dtype",
      "device"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Glm4MoeLiteForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "set_moe_parameters": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "STEP_PACKED_MODULES_MAPPING": [],
  "_get_step_alibi_slopes": [
    "total_num_heads"
  ],
  "StepAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "StepMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "quant_config",
      "prefix",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StepDecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "StepDecoderModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "Step1ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiMoModel": {
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiMoForCausalLM": {
    "__init__": [
      "self"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ]
  },
  "InternLM2MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InternLM2Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_parameters",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "split_qkv": [
      "self",
      "qkv"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "InternLMDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "InternLM2Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "InternLM2ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "InternLM2ForRewardModel": {
    "is_pooling_model": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "OlmoAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "OlmoMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OlmoDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "OlmoModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "OlmoForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "check_ffn_act_fn": [
    "act_fn"
  ],
  "OpenPanguMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "reduce_results",
      "is_sequence_parallel",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OpenPanguMoE": {
    "__init__": [
      "self",
      "config",
      "parallel_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "OpenPanguMLAAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "v_head_dim",
      "q_lora_rank",
      "kv_lora_rank",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "OpenPanguEmbeddedAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "bias_o_proj",
      "cache_config",
      "prefix",
      "attn_type"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ],
    "_init_rotary_emb": [
      "self",
      "config",
      "quant_config"
    ]
  },
  "OpenPanguSinkAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_parameters",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "bias_o_proj",
      "cache_config",
      "prefix",
      "attn_type"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ],
    "_init_rotary_emb": [
      "self",
      "config",
      "rope_parameters",
      "quant_config"
    ],
    "post_weight_load": [
      "self"
    ]
  },
  "OpenPanguDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "prefix",
      "vllm_config"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "OpenPanguModel": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_attn_mlp_weight": [
      "self",
      "attn_mlp_replace_mapping",
      "params_dict",
      "weight_name",
      "loaded_weight",
      "loaded_params"
    ],
    "load_expert_weight": [
      "self",
      "expert_merge_mapping",
      "params_dict",
      "weight_name",
      "loaded_weight",
      "loaded_params",
      "flag_dict"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "post_weight_load": [
      "self"
    ]
  },
  "OpenPanguModelBase": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "OpenPanguMoEModel": {
    "__init__": [
      "self"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ]
  },
  "OpenPanguEmbeddedModel": {
    "__init__": [
      "self"
    ]
  },
  "PanguEmbeddedForCausalLM": {},
  "PanguUltraMoEForCausalLM": {},
  "PanguProMoEV2ForCausalLM": {},
  "OlmoeMoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "params_dtype",
      "quant_config",
      "tp_size",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "OlmoeAttention": {
    "__init__": [
      "self"
    ],
    "_apply_qk_norm": [
      "self",
      "q",
      "k"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "OlmoeDecoderLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "OlmoeModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "OlmoeForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "GraniteMoeSharedMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GraniteMoeSharedDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "GraniteMoeSharedModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GraniteMoeSharedForCausalLM": {
    "fall_back_to_pt_during_load": [],
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "make_empty_intermediate_tensors": [
      "self",
      "batch_size",
      "dtype",
      "device"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "OPTLearnedPositionalEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim"
    ],
    "forward": [
      "self",
      "positions"
    ]
  },
  "OPTAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "bias",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "OPTDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "OPTDecoder": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "OPTModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "OPTForCausalLM": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen2MoeMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "expert_gate",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2MoeSparseMoeBlock": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen2MoeAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_parameters",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix",
      "dual_chunk_attention_config"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Qwen2MoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Qwen2MoeModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen2MoeForCausalLM": {
    "fall_back_to_pt_during_load": [],
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "KananaVImagePixelInputs": {},
  "build_pos_embeds": [
    "config",
    "num_input_tokens",
    "vision_hidden_size"
  ],
  "build_mlp": [
    "depth",
    "hidden_size",
    "output_hidden_size"
  ],
  "PatchMerge": {
    "__init__": [
      "self",
      "merge_size"
    ],
    "forward": [
      "self",
      "x",
      "channel_last"
    ]
  },
  "DynamicCAbstractor": {
    "__init__": [
      "self",
      "config",
      "num_input_tokens"
    ],
    "_load_from_state_dict": [
      "self",
      "state_dict"
    ],
    "build_net": [
      "self"
    ],
    "forward": [
      "self",
      "flattened_visual_embeds",
      "grid_thw"
    ],
    "_forward": [
      "self",
      "x",
      "input_size"
    ]
  },
  "CustomQwen2VLVE": {
    "__init__": [
      "self",
      "config"
    ],
    "_from_config": [
      "cls",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "grid_thw",
      "output_hidden_states",
      "return_dict"
    ],
    "get_num_tokens": [
      "self"
    ]
  },
  "KananaVProcessingInfo": {
    "get_supported_mm_limits": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "_get_vision_info": [
      "self"
    ],
    "get_mm_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ]
  },
  "KananaVDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "KananaVMultiModalProcessor": {
    "media_token_id": [
      "self"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "KananaVForConditionalGeneration": {
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_get_visual_feature_at": [
      "self",
      "v_output",
      "layer_index"
    ],
    "forward_vision": [
      "self",
      "pixel_values",
      "image_metas"
    ],
    "forward_projector": [
      "self",
      "visual_features",
      "image_metas"
    ],
    "forward_and_project_vision": [
      "self",
      "pixel_values",
      "image_metas"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DeepSeekMultiTokenPredictorLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "previous_hidden_states",
      "inputs_embeds",
      "spec_step_index"
    ]
  },
  "DeepSeekMultiTokenPredictor": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "previous_hidden_states",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ]
  },
  "DeepSeekMTP": {
    "__init__": [
      "self"
    ],
    "set_moe_parameters": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "intermediate_tensors",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_rewrite_spec_layer_name": [
      "self",
      "spec_layer",
      "name"
    ]
  },
  "_get_alibi_slopes": [
    "total_num_heads"
  ],
  "BaiChuanMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BaiChuanAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "position_embedding",
      "rope_parameters",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "BaiChuanDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "position_embedding",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "BaiChuanModel": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix",
      "position_embedding"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BaiChuanBaseForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "lm_head_weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ]
  },
  "BaichuanForCausalLM": {
    "__init__": [
      "self"
    ]
  },
  "BaiChuanForCausalLM": {
    "__init__": [
      "self"
    ]
  },
  "_require_is_multimodal": [
    "is_multimodal"
  ],
  "_language_model_by_module": [],
  "SupportsMultiModal": {
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "embed_multimodal": [
      "self"
    ],
    "get_language_model": [
      "self"
    ],
    "_mark_language_model": [
      "self",
      "vllm_config"
    ],
    "_mark_tower_model": [
      "self",
      "vllm_config",
      "modalities"
    ],
    "_mark_composite_model": [
      "self",
      "vllm_config"
    ],
    "get_num_mm_encoder_tokens": [
      "self",
      "num_image_tokens"
    ],
    "get_num_mm_connector_tokens": [
      "self",
      "num_vision_tokens"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "_embed_text_input_ids": [
      "self",
      "input_ids",
      "embed_input_ids"
    ]
  },
  "SupportsMultiModalPruning": {
    "recompute_mrope_positions": [
      "self",
      "input_ids",
      "multimodal_embeddings",
      "mrope_positions",
      "num_computed_tokens"
    ]
  },
  "supports_multimodal": [
    "model"
  ],
  "supports_multimodal_raw_input_only": [
    "model"
  ],
  "requires_raw_input_tokens": [
    "model"
  ],
  "supports_multimodal_encoder_tp_data": [
    "model"
  ],
  "supports_multimodal_pruning": [
    "model"
  ],
  "SupportsScoreTemplate": {
    "get_score_template": [
      "cls",
      "query",
      "document"
    ],
    "post_process_tokens": [
      "cls",
      "prompt"
    ]
  },
  "supports_score_template": [
    "model"
  ],
  "SupportsLoRA": {},
  "_SupportsLoRAType": {},
  "supports_lora": [
    "model"
  ],
  "_supports_lora": [
    "model"
  ],
  "SupportsPP": {
    "make_empty_intermediate_tensors": [
      "self",
      "batch_size",
      "dtype",
      "device"
    ],
    "forward": [
      "self"
    ]
  },
  "_SupportsPPType": {
    "make_empty_intermediate_tensors": [
      "self",
      "batch_size",
      "dtype",
      "device"
    ],
    "forward": [
      "self"
    ]
  },
  "supports_pp": [
    "model"
  ],
  "_supports_pp_attributes": [
    "model"
  ],
  "_supports_pp_inspect": [
    "model"
  ],
  "HasInnerState": {},
  "has_inner_state": [
    "model"
  ],
  "IsAttentionFree": {},
  "is_attention_free": [
    "model"
  ],
  "IsHybrid": {
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ]
  },
  "is_hybrid": [
    "model"
  ],
  "MixtureOfExperts": {
    "set_eplb_state": [
      "self",
      "expert_load_view",
      "logical_to_physical_map",
      "logical_replica_count"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ]
  },
  "is_mixture_of_experts": [
    "model"
  ],
  "HasNoOps": {},
  "has_noops": [
    "model"
  ],
  "SupportsMambaPrefixCaching": {},
  "supports_mamba_prefix_caching": [
    "model"
  ],
  "SupportsCrossEncoding": {},
  "supports_cross_encoding": [
    "model"
  ],
  "_supports_cross_encoding": [
    "model"
  ],
  "SupportsQuant": {
    "__new__": [
      "cls"
    ],
    "_find_quant_config": []
  },
  "SupportsTranscription": {
    "__init_subclass__": [
      "cls"
    ],
    "get_generation_prompt": [
      "cls",
      "audio",
      "stt_config",
      "model_config",
      "language",
      "task_type",
      "request_prompt",
      "to_language"
    ],
    "get_other_languages": [
      "cls"
    ],
    "validate_language": [
      "cls",
      "language"
    ],
    "get_speech_to_text_config": [
      "cls",
      "model_config",
      "task_type"
    ],
    "get_num_audio_tokens": [
      "cls",
      "audio_duration_s",
      "stt_config",
      "model_config"
    ]
  },
  "supports_transcription": [
    "model"
  ],
  "SupportsEagleBase": {},
  "supports_any_eagle": [
    "model"
  ],
  "SupportsEagle": {},
  "supports_eagle": [
    "model"
  ],
  "SupportsEagle3": {
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ]
  },
  "supports_eagle3": [
    "model"
  ],
  "SupportsMRoPE": {
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ]
  },
  "supports_mrope": [
    "model"
  ],
  "SupportsXDRoPE": {
    "get_xdrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ]
  },
  "supports_xdrope": [
    "model"
  ],
  "Gemma3ImagePixelInputs": {},
  "Gemma3ImageInputs": [],
  "Gemma3ProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "_resolve_image_kwargs": [
      "self",
      "processor",
      "keys"
    ],
    "get_num_crops": [
      "self"
    ],
    "get_image_repl": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "Gemma3DummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Gemma3MultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_apply_token_matches": [
      "self",
      "prompt",
      "mm_prompt_updates"
    ],
    "_find_mm_placeholders": [
      "self",
      "new_token_ids",
      "mm_prompt_updates"
    ]
  },
  "Gemma3MultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "vision_outputs"
    ]
  },
  "Gemma3ForConditionalGeneration": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_image_pixels_to_features": [
      "self",
      "vision_tower",
      "pixel_values"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "QwenImagePixelInputs": {},
  "QwenImageEmbeddingInputs": {},
  "VisualAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "bias",
      "kdim",
      "vdim",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask"
    ]
  },
  "QwenVLMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "VisualAttentionBlock": {
    "__init__": [
      "self",
      "d_model",
      "n_head",
      "mlp_ratio",
      "norm_layer",
      "quant_config",
      "prefix"
    ],
    "attention": [
      "self",
      "x",
      "attn_mask"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask"
    ]
  },
  "TransformerBlock": {
    "__init__": [
      "self",
      "width",
      "layers",
      "heads",
      "mlp_ratio",
      "norm_layer",
      "quant_config",
      "prefix"
    ],
    "get_cast_dtype": [
      "self"
    ],
    "get_cast_device": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask"
    ]
  },
  "VisionTransformer": {
    "__init__": [
      "self",
      "image_size",
      "patch_size",
      "width",
      "layers",
      "heads",
      "mlp_ratio",
      "n_queries",
      "output_dim",
      "image_start_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QwenVLModel": {
    "__init__": [
      "self"
    ]
  },
  "_get_tokenizer_without_image_pad": [
    "tokenizer"
  ],
  "QwenVLProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "image_start_tag": [
      "self"
    ],
    "image_end_tag": [
      "self"
    ],
    "image_pad_tag": [
      "self"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "return_tensors"
    ]
  },
  "QwenVLProcessingInfo": {
    "get_tokenizer": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ]
  },
  "QwenVLDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "QwenVLMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_hf_processor_applies_updates": [
      "self",
      "prompt_text",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "QwenVLForConditionalGeneration": {
    "packed_modules_mapping": [],
    "embed_input_ids": [],
    "get_mm_mapping": [
      "self"
    ],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "NemotronHMLP": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "intermediate_size",
      "quant_config",
      "bias",
      "reduce_results",
      "is_sequence_parallel",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NemotronHMoE": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "parallel_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "NemotronHMLPDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "parallel_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "NemotronHMoEDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "parallel_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "NemotronHMambaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "parallel_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "NemotronHAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "NemotronHAttentionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "parallel_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "ALL_DECODER_LAYER_TYPES": [],
  "NemotronHModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "NemotronHForCausalLM": {
    "hf_to_vllm_mapper": [],
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ],
    "__init__": [
      "self"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Idefics2VisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "patch_attention_mask",
      "tgt_sizes"
    ]
  },
  "Idefics2VisionAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Idefics2VisionMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Idefics2EncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Idefics2Encoder": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "inputs_embeds"
    ]
  },
  "Idefics2VisionTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "patch_attention_mask",
      "tgt_sizes"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_get_feat_extract_output_lengths": [
    "input_lengths"
  ],
  "SinusoidsPositionEmbedding": {
    "__init__": [
      "self",
      "length",
      "channels",
      "max_timescale"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "Qwen3OmniMoeAudioAttention": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "max_seqlen"
    ]
  },
  "Qwen3OmniMoeAudioEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "max_seqlen"
    ]
  },
  "Qwen3OmniMoeAudioEncoder": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "compute_attn_mask_seqlen": [
      "self",
      "cu_seqlens"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "forward": [
      "self",
      "input_features",
      "feature_lens",
      "aftercnn_lens"
    ],
    "_get_cnn_output_lengths": [
      "self",
      "input_lengths"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3Omni_VisionTransformer": {
    "__init__": [
      "self",
      "vision_config",
      "norm_eps",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "fast_pos_embed_interpolate": [
      "self",
      "grid_thw"
    ],
    "compute_attn_mask_seqlen": [
      "self",
      "cu_seqlens"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3MoeLLMModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds",
      "deepstack_input_embeds"
    ]
  },
  "Qwen3MoeLLMForCausalLM": {
    "__init__": [
      "self"
    ]
  },
  "Qwen3OmniMoeThinkerProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_feature_extractor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ]
  },
  "Qwen3OmniMoeThinkerDummyInputsBuilder": [],
  "Qwen3OmniMoeThinkerMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_maybe_apply_prompt_updates": [
      "self",
      "mm_items",
      "prompt_ids",
      "mm_kwargs",
      "mm_prompt_updates",
      "is_update_applied"
    ],
    "get_updates_use_audio_in_video": [
      "self",
      "thinker_config",
      "audio_len",
      "video_grid_thw",
      "video_second_per_grid_t"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_derive_audio_from_video_placeholders": [
      "self",
      "placeholders",
      "mm_prompt_updates"
    ],
    "_get_raw_input_ids": [
      "self",
      "token_ids",
      "use_audio_in_video"
    ]
  },
  "Qwen3OmniMoeConditionalGenerationMixin": {
    "_process_audio_input": [
      "self",
      "audio_input",
      "audio_hashes",
      "cached_audio_features"
    ]
  },
  "Qwen3OmniMoeThinkerForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "packed_modules_mapping": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_get_deepstack_input_embeds": [
      "self",
      "num_tokens"
    ],
    "_set_deepstack_input_embeds": [
      "self",
      "deepstack_input_embeds"
    ],
    "_clear_deepstack_input_embeds": [
      "self",
      "num_tokens"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "LlavaNextVideoPixelInputs": {},
  "LlavaNextVideoProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_vision_encoder_info": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "_get_num_frame_tokens": [
      "self"
    ],
    "get_num_video_tokens": [
      "self"
    ],
    "_get_max_video_frames": [
      "self",
      "max_tokens"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len",
      "mm_counts"
    ]
  },
  "LlavaNextVideoDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "LlavaNextVideoMultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "LlavaNextVideoPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "LlavaNextMultiModalProjector": {
    "__init__": [
      "self",
      "vision_hidden_size",
      "text_hidden_size",
      "projector_hidden_act",
      "multimodal_projector_bias"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "LlavaNextVideoForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_video_pixels_to_features": [
      "self",
      "vision_tower",
      "pixel_values"
    ],
    "_process_video_pixels": [
      "self",
      "inputs"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Zamba2LoRA": {
    "__init__": [
      "self",
      "input_dim",
      "rank",
      "output_dim",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Zamba2Attention": {
    "__init__": [
      "self",
      "config",
      "bare_block_idx",
      "num_hybrid_layers",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "block_idx",
      "position_ids"
    ]
  },
  "Zamba2MLP": {
    "__init__": [
      "self",
      "config",
      "bare_block_idx",
      "num_hybrid_layers",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "block_idx"
    ]
  },
  "Zamba2AttentionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "bare_block_idx",
      "num_hybrid_layers",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "original_hidden_states",
      "block_idx",
      "positions"
    ]
  },
  "Zamba2MambaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "transformer_hidden_states",
      "positions",
      "original_hidden_states"
    ]
  },
  "Zamba2HybridLayer": {
    "__init__": [
      "self",
      "shared_transformer",
      "config",
      "block_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "original_hidden_states",
      "positions"
    ]
  },
  "Zamba2Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Zamba2ForCausalLM": {
    "hf_to_vllm_mapper": [],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "JambaMoE": {
    "__init__": [
      "self",
      "config",
      "num_experts",
      "top_k",
      "params_dtype",
      "tp_size",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "JambaMambaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "is_lora_enabled",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "JambaAttentionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "self_attention": [
      "self",
      "positions",
      "hidden_states"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "JambaModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "JambaForCausalLM": {
    "hf_to_vllm_mapper": [],
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "copy_inputs_before_cuda_graphs": [
      "self",
      "input_buffers"
    ],
    "get_seqlen_agnostic_capture_inputs": [
      "self",
      "batch_size"
    ],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "JambaForSequenceClassification": {
    "is_pooling_model": [],
    "__init__": [
      "self"
    ]
  },
  "Exaone4GatedMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "bias",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Exaone4Attention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "cache_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Exaone4DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Exaone4Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Exaone4ForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Glm4vImagePixelInputs": {},
  "Glm4vImageEmbeddingInputs": {},
  "Glm4vVideoPixelInputs": {},
  "Glm4vVideoEmbeddingInputs": {},
  "Glm4vVisionMLP": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "all_gather_interleave": [
    "local_tensor",
    "hidden_size",
    "tp_size"
  ],
  "Glm4vVisionAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "projection_size",
      "quant_config",
      "prefix"
    ],
    "split_qkv": [
      "self",
      "qkv"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin",
      "max_seqlen"
    ]
  },
  "Glm4vVisionBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_hidden_dim",
      "norm_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin",
      "max_seqlen"
    ]
  },
  "Glm4vVisionPatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "temporal_patch_size",
      "in_channels",
      "hidden_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Glm4vPatchMerger": {
    "__init__": [
      "self",
      "d_model",
      "context_dim",
      "quant_config",
      "bias",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Glm4vVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "embeddings",
      "lengths",
      "image_shapes",
      "h_coords",
      "w_coords"
    ]
  },
  "Glm4vVisionTransformer": {
    "__init__": [
      "self",
      "vision_config",
      "norm_eps",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "compute_attn_mask_seqlen": [
      "self",
      "cu_seqlens"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Glm4vProcessingInfo": {
    "get_supported_mm_limits": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_video_processor": [
      "self"
    ],
    "_get_vision_info": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_max_image_tokens": [
      "self"
    ],
    "get_num_video_tokens": [
      "self"
    ],
    "_get_max_video_frames": [
      "self",
      "max_tokens"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "_get_video_second_idx_glm4v": [
      "self",
      "metadata",
      "total_frames"
    ],
    "_get_video_second_idx_glm46v": [
      "self",
      "metadata",
      "total_frames"
    ],
    "_construct_video_placeholder": [
      "self",
      "video_array",
      "metadata",
      "grid_thw"
    ]
  },
  "Glm4vDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ],
    "_get_dummy_videos": [
      "self"
    ]
  },
  "Glm4vMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Glm4vForConditionalGeneration": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "supports_encoder_tp_data": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_process_video_input": [
      "self",
      "video_input"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "get_num_mm_encoder_tokens": [
      "self",
      "num_image_tokens"
    ],
    "get_num_mm_connector_tokens": [
      "self",
      "num_vision_tokens"
    ]
  },
  "Glm4vMoeForConditionalGeneration": {
    "packed_modules_mapping": []
  },
  "PhiAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "PhiMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "PhiLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "PhiModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "PhiForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MultiModelKeys": {
    "from_string_field": [
      "language_model",
      "connector",
      "tower_model",
      "generator"
    ]
  },
  "SolarMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SolarAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "cache_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "SolarDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "SolarModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "SolarForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Llama4ImagePatchInputs": {},
  "Llama4VisionMLP": {
    "__init__": [
      "self",
      "input_size",
      "intermediate_size",
      "output_size",
      "bias",
      "output_activation",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Llama4MultiModalProjector": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "pixel_shuffle": [
    "input_tensor",
    "shuffle_ratio"
  ],
  "Llama4VisionPixelShuffleMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "encoded_patches"
    ]
  },
  "Llama4VisionAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Llama4VisionEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "Llama4VisionEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Llama4UnfoldConvolution": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Llama4VisionModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "images_flattened"
    ]
  },
  "Mllama4ProcessingInfo": {
    "__init__": [
      "self",
      "ctx"
    ],
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_patch_per_chunk": [
      "vision_config"
    ],
    "get_max_num_tiles": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "Mllama4MultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Mllama4DummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Llama4ForConditionalGeneration": {
    "packed_modules_mapping": [],
    "supports_encoder_tp_data": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ],
    "set_eplb_state": [
      "self",
      "expert_load_view",
      "logical_to_physical_map",
      "logical_replica_count"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "separate_weights": [
      "self",
      "weights",
      "prefix"
    ],
    "_consolidate_qkv_weights": [
      "self",
      "weights"
    ],
    "_rename_weight_for_modelopt_checkpoint": [
      "self",
      "name"
    ],
    "_separate_and_rename_weights": [
      "self",
      "weights"
    ],
    "_handle_expert_scale_broadcasting": [
      "self",
      "weights",
      "params_dict"
    ],
    "_load_other_weights": [
      "self",
      "other_weights",
      "params_dict",
      "stacked_params_mapping"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "ErnieMultiTokenPredictorLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "positions",
      "previous_hidden_states",
      "spec_step_index"
    ]
  },
  "ErnieMultiTokenPredictor": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "previous_hidden_states",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "lm_head",
      "spec_step_idx"
    ]
  },
  "ErnieMTP": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "intermediate_tensors",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_rewrite_spec_layer_name": [
      "self",
      "config",
      "name"
    ]
  },
  "PATCH_MERGE": [],
  "PixtralImagePixelInputs": {},
  "PixtralProcessorAdapter": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "image_processor": [
      "self"
    ],
    "image_break_id": [
      "self"
    ],
    "image_token_id": [
      "self"
    ],
    "image_end_id": [
      "self"
    ],
    "image_size": [
      "self"
    ],
    "patch_size": [
      "self"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "return_tensors"
    ]
  },
  "PixtralProcessingInfo": {
    "get_tokenizer": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_vision_config": [
      "self",
      "processor"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "PixtralDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ],
    "get_dummy_processor_inputs": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "PixtralMultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_cached_apply_hf_processor": [
      "self",
      "prompt",
      "mm_data_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs",
      "mm_uuids"
    ]
  },
  "PixtralForConditionalGeneration": {
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "get_num_mm_encoder_tokens": [
      "self",
      "num_image_tokens"
    ],
    "get_num_mm_connector_tokens": [
      "self",
      "num_vision_tokens"
    ]
  },
  "VisionEncoderArgs": {},
  "_reshape_for_broadcast": [
    "freqs_cis",
    "x"
  ],
  "precompute_freqs_cis_2d": [
    "dim",
    "height",
    "width",
    "theta"
  ],
  "apply_rotary_emb_vit": [
    "xq",
    "xk",
    "freqs_cis"
  ],
  "FeedForward": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Attention": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "freqs_cis"
    ]
  },
  "Transformer": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "freqs_cis"
    ]
  },
  "position_meshgrid": [
    "patch_embeds_list"
  ],
  "VisionLanguageAdapter": {
    "__init__": [
      "self",
      "args",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PatchMerger": {
    "__init__": [
      "self",
      "vision_encoder_dim",
      "spatial_merge_size",
      "use_mlp_bias"
    ],
    "forward": [
      "self",
      "x",
      "image_sizes"
    ],
    "permute": [
      "self",
      "x",
      "image_sizes"
    ]
  },
  "get_sub_grids": [
    "x",
    "image_sizes",
    "spatial_merge_size"
  ],
  "PixtralHFEncoderInfo": {
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size": [
      "self"
    ],
    "get_patch_size": [
      "self"
    ],
    "get_patch_grid_length": [
      "self"
    ],
    "get_patch_grid_size": [
      "self"
    ]
  },
  "PixtralHFMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PixtralHFAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_embeddings"
    ]
  },
  "PixtralHFTransformerBlock": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_embeddings"
    ]
  },
  "PixtralHFTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "x",
      "attention_mask",
      "position_embeddings",
      "return_all_hidden_states"
    ]
  },
  "PixtralHFVisionModel": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "smart_resize": [
    "height",
    "width",
    "factor",
    "min_pixels",
    "max_pixels"
  ],
  "PaddleOCRVLProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "PaddleOCRVLDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "PaddleOCRVLMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Projector": {
    "__init__": [
      "self",
      "text_config",
      "vision_config",
      "prefix"
    ],
    "forward": [
      "self",
      "image_features",
      "image_grid_thw"
    ]
  },
  "PaddleOCRImagePixelInputs": {},
  "SiglipVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "interpolate_pos_encoding": [
      "self",
      "embeddings",
      "height",
      "width",
      "is_after_patchify"
    ],
    "fetch_position_embedding_lfu_cache": [
      "self",
      "embeddings",
      "h",
      "w",
      "max_cache"
    ],
    "forward": [
      "self",
      "pixel_values",
      "position_ids",
      "image_grid_thw",
      "interpolate_pos_encoding"
    ]
  },
  "SiglipAttention": {
    "__init__": [
      "self"
    ],
    "split_qkv": [
      "self",
      "qkv"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SigLIPRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta"
    ],
    "rope_init": [
      "self"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "SiglipEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SiglipEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "flatten_list": [
      "image_grid_thw"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "cu_seqlens",
      "image_grid_thw",
      "height_position_ids",
      "width_position_ids"
    ]
  },
  "SiglipVisionTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "pixel_values",
      "interpolate_pos_encoding",
      "position_ids",
      "height_position_ids",
      "width_position_ids",
      "cu_seqlens",
      "image_grid_thw"
    ]
  },
  "SiglipVisionModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "interpolate_pos_encoding",
      "position_ids",
      "image_grid_thw",
      "cu_seqlens"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "PaddleOCRVLForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "encode_image": [
      "self",
      "pixel_values",
      "image_grid_thw"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "ConformerEncoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "ext_pw_out_channel",
      "depthwise_seperable_out_channel",
      "depthwise_multiplier",
      "n_head",
      "d_ffn",
      "ext_pw_kernel_size",
      "kernel_size",
      "dropout_rate",
      "causal",
      "batch_norm",
      "activation",
      "chunk_se",
      "chunk_size",
      "conv_activation",
      "conv_glu_type",
      "bias_in_glu",
      "linear_glu_in_convm",
      "attention_inner_dim",
      "attention_glu_type",
      "activation_checkpointing",
      "export",
      "use_pt_scaled_dot_product_attention",
      "attn_group_sizes"
    ],
    "forward": [
      "self",
      "x",
      "pos_k",
      "pos_v",
      "mask",
      "relative_attention_bias"
    ]
  },
  "TransformerEncoderBase": {
    "__init__": [
      "self",
      "input_size",
      "chunk_size",
      "left_chunk",
      "attention_dim",
      "attention_heads",
      "input_layer",
      "cnn_out",
      "cnn_layer_norm",
      "time_reduction",
      "dropout_rate",
      "padding_idx",
      "relative_attention_bias_args",
      "positional_dropout_rate",
      "nemo_conv_settings",
      "conv2d_extra_padding",
      "attention_group_size",
      "encoder_embedding_config"
    ],
    "compute_lens_change": [
      "self",
      "feature_lens"
    ],
    "forward": [
      "self"
    ],
    "_chunk_size_selection": [
      "self",
      "chunk_size",
      "left_chunk"
    ],
    "_get_embed_class": [
      "self",
      "embed"
    ],
    "_forward_embeddings_core": [
      "self",
      "input_tensor",
      "masks"
    ],
    "_position_embedding": [
      "self",
      "input_tensor"
    ],
    "_streaming_mask": [
      "self",
      "seq_len",
      "batch_size",
      "chunk_size",
      "left_chunk"
    ],
    "forward_embeddings": [
      "self",
      "xs_pad",
      "masks",
      "chunk_size_nc",
      "left_chunk_nc"
    ],
    "get_offset": [
      "self"
    ]
  },
  "ConformerEncoder": {
    "__init__": [
      "self",
      "input_size",
      "chunk_size",
      "left_chunk",
      "num_lang",
      "attention_dim",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "input_layer",
      "causal",
      "batch_norm",
      "cnn_out",
      "cnn_layer_norm",
      "ext_pw_out_channel",
      "ext_pw_kernel_size",
      "depthwise_seperable_out_channel",
      "depthwise_multiplier",
      "chunk_se",
      "kernel_size",
      "activation",
      "conv_activation",
      "conv_glu_type",
      "bias_in_glu",
      "linear_glu_in_convm",
      "attention_glu_type",
      "export",
      "extra_layer_output_idx",
      "extra_multi_layer_output_idxs",
      "activation_checkpointing",
      "relative_attention_bias_args",
      "time_reduction",
      "use_pt_scaled_dot_product_attention",
      "nemo_conv_settings",
      "conv2d_extra_padding",
      "replication_pad_for_subsample_embedding",
      "attention_group_size",
      "encoder_embedding_config"
    ],
    "init_relative_attention_bias": [
      "self",
      "input_tensor"
    ],
    "calculate_hs_mask": [
      "self",
      "xs_pad",
      "device",
      "mask"
    ],
    "forward": [
      "self",
      "xs_pad",
      "masks"
    ]
  },
  "WindowQformer": {
    "__init__": [
      "self",
      "window_size",
      "num_queries",
      "num_blocks",
      "attention_dim",
      "attention_heads",
      "linear_units",
      "dropout_rate",
      "normalize_before"
    ],
    "forward": [
      "self",
      "audio_embed",
      "mask",
      "embed_len"
    ]
  },
  "AudioEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "set_audio_embeds": [
      "self",
      "input_embeds"
    ],
    "set_audio_embed_sizes": [
      "self",
      "audio_embed_sizes"
    ],
    "get_audio_features": [
      "self",
      "input_embeds",
      "audio_attention_mask",
      "audio_projection_mode"
    ],
    "forward": [
      "self",
      "audio_features",
      "audio_attention_mask",
      "audio_projection_mode"
    ]
  },
  "MixtralMoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "params_dtype",
      "quant_config",
      "tp_size",
      "dp_size",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MixtralAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "MixtralDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "MixtralModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MixtralForCausalLM": {
    "fall_back_to_pt_during_load": [],
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "BertEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "BertPooler": {
    "__init__": [
      "self",
      "model_config"
    ]
  },
  "BertEncoder": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "layer_norm_eps",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertSelfAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertSelfOutput": {
    "__init__": [
      "self",
      "hidden_size",
      "layer_norm_eps",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "BertIntermediate": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertOutput": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "layer_norm_eps",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "BertModel": {
    "is_pooling_model": [],
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "_load_weights": [
      "self",
      "weights"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BertPoolingModel": {
    "is_pooling_model": [],
    "__init__": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BertEmbeddingModel": {
    "is_pooling_model": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_build_model": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "_build_pooler": [
      "self",
      "pooler_config"
    ]
  },
  "TOKEN_TYPE_SHIFT": [],
  "_encode_token_type_ids": [
    "input_ids",
    "token_type_ids"
  ],
  "_decode_token_type_ids": [
    "input_ids"
  ],
  "BertMLMHead": {
    "__init__": [
      "self",
      "hidden_size",
      "vocab_size",
      "layer_norm_eps"
    ],
    "tie_weights_with_embeddings": [
      "self",
      "embeddings_weight"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SPLADESparsePooler": {
    "__init__": [
      "self",
      "mlm_head",
      "cls_token_id",
      "sep_token_id",
      "pooling",
      "remove_cls_sep"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "get_pooling_updates": [
      "self",
      "task"
    ],
    "forward": [
      "self",
      "hidden_states",
      "pooling_metadata"
    ]
  },
  "BertSpladeSparseEmbeddingModel": {
    "__init__": [
      "self"
    ],
    "_build_pooler": [
      "self",
      "pooler_config"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BertForSequenceClassification": {
    "is_pooling_model": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds",
      "token_type_ids"
    ]
  },
  "BertForTokenClassification": {
    "is_pooling_model": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds",
      "token_type_ids"
    ]
  },
  "LlavaNextImagePixelInputs": {},
  "LlavaNextImageEmbeddingInputs": {},
  "LlavaNextLikeConfig": {},
  "LlavaNextProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "_get_num_unpadded_features": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "BaseLlavaNextMultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "LlavaNextMultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "LlavaNextForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_image_pixels_to_features": [
      "self",
      "vision_tower",
      "pixel_values"
    ],
    "_merge_image_patch_embeddings": [
      "self",
      "image_size",
      "patch_embeddings"
    ],
    "_process_image_pixels": [
      "self",
      "inputs"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Step3p5AMultiTokenPredictorLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "previous_hidden_states",
      "inputs_embeds",
      "spec_step_index"
    ]
  },
  "Step3p5AMultiTokenPredictor": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "previous_hidden_states",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ]
  },
  "Step3p5MTP": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "intermediate_tensors",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_rewrite_spec_layer_name": [
      "self",
      "spec_layer",
      "name"
    ]
  },
  "Llama4MoE": {
    "custom_routing_function": [
      "hidden_states",
      "gating_output",
      "topk",
      "renormalize"
    ],
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Llama4Attention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "bias_o_proj",
      "cache_config",
      "prefix"
    ],
    "_get_attn_scale": [
      "self",
      "positions"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Llama4DecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix",
      "config"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Llama4Model": {
    "__init__": [
      "self"
    ],
    "load_moe_expert_weights": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "loaded_params",
      "expert_params_mapping",
      "fused"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Llama4ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "set_moe_parameters": [
      "self"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ],
    "_init_model": [
      "self",
      "vllm_config",
      "prefix",
      "layer_type"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "permute_qk_weight_for_rotary": [
      "self",
      "name",
      "loaded_weight"
    ]
  },
  "CausalRMSNorm": [],
  "_pad1d": [
    "x",
    "paddings",
    "mode",
    "value"
  ],
  "WhisperCausalConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "create_whisper_attention_backend_with_block_pooling": [
    "underlying_attn_backend",
    "block_pool_size"
  ],
  "WhisperCausalAttentionWithBlockPooling": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "cache_config",
      "quant_config",
      "logits_soft_cap",
      "per_layer_sliding_window",
      "prefix",
      "attn_type",
      "kv_sharing_target_layer_name",
      "block_pool_size",
      "attn_backend"
    ],
    "get_kv_cache_spec": [
      "self",
      "vllm_config"
    ]
  },
  "WhisperCausalAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "head_dim",
      "max_position_embeddings",
      "bias",
      "attn_type",
      "per_layer_sliding_window",
      "block_pool_size",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "_init_rotary_emb": [
      "self",
      "max_position_embeddings"
    ],
    "_init_qkv": [
      "self",
      "embed_dim",
      "bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "positions"
    ]
  },
  "WhisperCausalEncoderLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "positions"
    ]
  },
  "WhisperCausalEncoder": {
    "__init__": [
      "self"
    ],
    "forward_conv": [
      "self",
      "input_features"
    ],
    "forward": [
      "self",
      "hidden_states",
      "positions"
    ]
  },
  "ISO639_1_SUPPORTED_LANGS": [],
  "GraniteSpeechAudioInputs": {},
  "GraniteSpeechMultiModalProcessingInfo": {
    "get_supported_mm_limits": [
      "self"
    ],
    "get_max_audio_tokens": [
      "self"
    ],
    "get_max_audio_len": [
      "self"
    ]
  },
  "GraniteSpeechMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ]
  },
  "GraniteSpeechDummyInputsBuilder": {
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ],
    "get_dummy_text": [
      "self",
      "mm_counts"
    ]
  },
  "GraniteSpeechEncoderProjector": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GraniteSpeechConformerFeedForward": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GraniteSpeechConformerAttention": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_dists"
    ]
  },
  "GraniteSpeechConformerDepthWiseConv1d": {
    "__init__": [
      "self",
      "chan_in",
      "chan_out",
      "kernel_size",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GraniteSpeechConformerConvModule": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GraniteSpeechConformerBlock": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_dists"
    ]
  },
  "GraniteSpeechCTCEncoder": {
    "__init__": [
      "self",
      "config",
      "prefix",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GraniteSpeechForConditionalGeneration": {
    "supported_languages": [],
    "packed_modules_mapping": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_audio_input": [
      "self"
    ],
    "_build_input_features_mask": [
      "self",
      "audio_embed_sizes"
    ],
    "_pad_and_stack_input_features": [
      "self",
      "input_features"
    ],
    "_process_audio_input": [
      "self",
      "audio_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "get_generation_prompt": [
      "cls",
      "audio",
      "model_config",
      "stt_config",
      "language",
      "task_type",
      "request_prompt",
      "to_language"
    ],
    "get_num_audio_tokens": [
      "cls",
      "audio_duration_s",
      "stt_config",
      "model_config"
    ],
    "get_speech_to_text_config": [
      "cls",
      "model_config",
      "task_type"
    ]
  },
  "AriaImagePixelInputs": {},
  "AriaVisionTransformer": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "AriaProjectorMLP": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "output_dim",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AriaProjector": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "attn_mask"
    ]
  },
  "AriaFusedMoE": {
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "shard_id"
    ]
  },
  "AriaTextMoELayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AriaTextDecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ]
  },
  "AriaTextModel": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "AriaProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_vision_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ]
  },
  "AriaDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "AriaMultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "AriaForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_create_patch_attention_mask": [
      "self",
      "pixel_mask"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Gemma2MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "hidden_activation",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Gemma2Attention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "head_dim",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "attn_logits_soft_cap",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Gemma2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Gemma2Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Gemma2ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Ernie4_5_MoeMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "use_bias",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Ernie4_5_MoeMoE": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Ernie4_5_MoeAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_parameters",
      "head_dim",
      "max_position_embeddings",
      "rms_norm_eps",
      "qkv_bias",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Ernie4_5_MoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Ernie4_5_MoeModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Ernie4_5_MoeForCausalLM": {
    "packed_modules_mapping": [],
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "WeightsMapping": [],
  "WeightsMapper": {
    "__or__": [
      "self",
      "other"
    ],
    "_map_name": [
      "self",
      "key"
    ],
    "apply": [
      "self",
      "weights"
    ],
    "apply_list": [
      "self",
      "values"
    ],
    "apply_dict": [
      "self",
      "values"
    ]
  },
  "AutoWeightsLoader": {
    "ROTARY_EMBEDS_UNUSED_WEIGHTS": [],
    "__init__": [
      "self",
      "module"
    ],
    "_groupby_prefix": [
      "self",
      "weights"
    ],
    "_get_qualname": [
      "self",
      "prefix",
      "rest"
    ],
    "_can_skip": [
      "self",
      "qualname"
    ],
    "_can_ignore_unexpected": [
      "self",
      "qualname"
    ],
    "_load_param": [
      "self",
      "base_prefix",
      "param",
      "weights"
    ],
    "_add_loadable_non_param_tensors": [
      "self",
      "module",
      "child_params"
    ],
    "_load_module": [
      "self",
      "base_prefix",
      "module",
      "weights"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "init_vllm_registered_model": [
    "vllm_config"
  ],
  "flatten_bn": [
    "x"
  ],
  "_flatten_embeddings": [
    "embeddings"
  ],
  "_embedding_count_expression": [
    "embeddings"
  ],
  "split_list_into_ranges": [
    "lst",
    "interval"
  ],
  "_merge_multimodal_embeddings": [
    "inputs_embeds",
    "multimodal_embeddings",
    "is_multimodal"
  ],
  "isin_list": [
    "elements",
    "test_elements_list"
  ],
  "StageMissingLayer": {
    "__init__": [
      "self",
      "stage_name",
      "module"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "__call__": [
      "self"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "collect_children": [
    "module"
  ],
  "no_init_weights": [
    "module",
    "placeholder"
  ],
  "LayerFn": {
    "__call__": [
      "self",
      "prefix"
    ]
  },
  "PPMissingLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "_CPU_OFFLOAD_BYTES": [],
  "_CPU_OFFLOAD_MAX_BYTES": [],
  "set_cpu_offload_max_bytes": [
    "max_bytes"
  ],
  "maybe_offload_to_cpu": [
    "module"
  ],
  "make_layers": [
    "num_hidden_layers",
    "layer_fn",
    "prefix"
  ],
  "get_pp_missing_layer_names": [
    "model"
  ],
  "is_pp_missing_parameter": [
    "name",
    "model"
  ],
  "make_empty_intermediate_tensors_factory": [
    "keys",
    "hidden_size"
  ],
  "maybe_prefix": [
    "prefix",
    "name"
  ],
  "get_draft_quant_config": [
    "vllm_config"
  ],
  "extract_layer_index": [
    "layer_name",
    "num_attn_module"
  ],
  "cast_overflow_tensors": [
    "tensors",
    "offset"
  ],
  "fast_topk": [
    "values",
    "topk",
    "dim"
  ],
  "sequence_parallel_chunk": [
    "x"
  ],
  "sequence_parallel_chunk_impl": [
    "x"
  ],
  "sequence_parallel_chunk_impl_fake": [
    "x"
  ],
  "process_eagle_weight": [
    "model",
    "name"
  ],
  "get_layer_index": [
    "feature_layer_index",
    "num_hidden_layers"
  ],
  "_resolve_tuple2": [
    "x"
  ],
  "calculate_mel_frames_dasheng": [
    "audio_length_samples",
    "n_fft",
    "hop_size",
    "dasheng_subsampling",
    "center",
    "model_subsampling"
  ],
  "AudioPatchEmbed": {
    "__init__": [
      "self",
      "input_size",
      "patch_size",
      "patch_stride",
      "in_chans",
      "embed_dim",
      "norm_layer",
      "flatten"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LayerScale": {
    "__init__": [
      "self",
      "dim",
      "init_values",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DashengMlp": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DashengAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "qkv_bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "DashengBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "init_values",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "DashengFrontend": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "waveform"
    ]
  },
  "DashengAudioTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward_features": [
      "self",
      "x",
      "mask"
    ],
    "_to_mask": [
      "self",
      "lengths",
      "max_length"
    ],
    "forward": [
      "self",
      "x",
      "x_length"
    ]
  },
  "AudioProjectorSubsample": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "downsample_rate",
      "dtype",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "MiDashengLMAudioInputs": {},
  "MiDashengLMProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_feature_extractor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_min_audio_len": [
      "self"
    ],
    "get_max_audio_len": [
      "self"
    ]
  },
  "MiDashengLMDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "MiDashengLMMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "MiDashengLMModel": {
    "packed_modules_mapping": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_audio_input": [
      "self"
    ],
    "_process_audio_input": [
      "self",
      "audio_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BertWithRopeEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "token_type_ids"
    ]
  },
  "BertWithRopeAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "cache_config",
      "quant_config",
      "bias",
      "rotary_kwargs",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "BertWithRopeGatedMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertWithRopeMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "NomicMoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "params_dtype",
      "tp_size"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "weight_name"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertWithRopeBlock": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "moe",
      "bias",
      "rotary_kwargs",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "BertWithRopeEncoder": {
    "__init__": [
      "self",
      "vllm_config",
      "bias",
      "rotary_kwargs",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "BertWithRope": {
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds",
      "token_type_ids"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "NomicBertModel": {
    "hf_to_vllm_mapper": []
  },
  "GteNewModel": {
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self"
    ],
    "split_up_gate_proj": [
      "self",
      "weights"
    ],
    "ignore_unnecessary_layers": [
      "self",
      "weights"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "SnowflakeGteNewModel": {
    "hf_to_vllm_mapper": []
  },
  "JinaRobertaModel": {
    "hf_to_vllm_mapper": [],
    "jina_merge_lora_weights": [
      "self",
      "weights"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GteNewForSequenceClassification": {
    "is_pooling_model": [],
    "__init__": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "MAX_AUDIO_LEN": [],
  "AudioFlamingo3FeatureInputs": {},
  "AudioFlamingo3EmbeddingInputs": {},
  "AudioFlamingo3Encoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_features",
      "attention_mask"
    ],
    "_get_feat_extract_output_lengths": [
      "self",
      "input_lengths"
    ]
  },
  "AudioFlamingo3MultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "audio_features"
    ]
  },
  "AudioFlamingo3ProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_feature_extractor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ]
  },
  "AudioFlamingo3DummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "_audioflamingo3_field_config": [
    "hf_inputs"
  ],
  "AudioFlamingo3MultiModalDataParser": {
    "_parse_audio_data": [
      "self",
      "data"
    ]
  },
  "AudioFlamingo3MultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "AudioFlamingo3ForConditionalGeneration": {
    "packed_modules_mapping": [],
    "get_mm_mapping": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_audio_input": [
      "self"
    ],
    "_process_audio_input": [
      "self",
      "audio_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3MoeMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "expert_gate",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3MoeSparseMoeBlock": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen3MoeAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_parameters",
      "max_position_embeddings",
      "head_dim",
      "rms_norm_eps",
      "qkv_bias",
      "cache_config",
      "quant_config",
      "prefix",
      "dual_chunk_attention_config"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Qwen3MoeDecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Qwen3MoeModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3MoeForCausalLM": {
    "packed_modules_mapping": [],
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ],
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "ExaoneMoe": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ExaoneMoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "mtp_layer",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "ExaoneMoeModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "ExaoneMoeForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Cohere2VisionImagePixelInputs": {},
  "Cohere2VisionMultiModalProjector": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "image_features"
    ],
    "pixel_shuffle": [
      "self",
      "image_features"
    ]
  },
  "Cohere2VisionProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_num_patches": [
      "self"
    ]
  },
  "Cohere2VisionDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Cohere2VisionMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Cohere2VisionForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_patch_quant_config": [
      "self",
      "config",
      "quant_config"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ]
  },
  "SiglipImagePixelInputs": {},
  "_get_vision_feature_select_strategy": [
    "pooling_type"
  ],
  "SiglipProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_vision_encoder_info": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_max_image_tokens": [
      "self"
    ]
  },
  "SiglipDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "SiglipMultiModalProcessor": {
    "image_token_id": [
      "self"
    ],
    "apply": [
      "self",
      "prompt",
      "mm_data",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_hf_processor_applies_updates": [
      "self",
      "prompt_text",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "SiglipEncoderInfo": {
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size": [
      "self"
    ],
    "get_patch_size": [
      "self"
    ],
    "get_patch_grid_length": [
      "self"
    ]
  },
  "SiglipMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SiglipTextTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "SiglipMultiheadAttentionPoolingHead": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "maybe_swap_ffn_param": [
    "name",
    "param",
    "loaded_weight",
    "params_dict",
    "quant_config"
  ],
  "SiglipTextEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "SiglipEmbeddingModel": {
    "is_pooling_model": [],
    "packed_modules_mapping": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "get_text_features": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeds"
    ],
    "_flip_sequences_by_position_ids": [
      "self",
      "features",
      "position_ids"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "feature_select_strategy"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_inputs": [
      "self",
      "inputs"
    ],
    "_embed_text_input_ids": [
      "self",
      "input_ids",
      "embed_input_ids"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Mamba2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "Mamba2Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Mamba2ForCausalLM": {
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "copy_inputs_before_cuda_graphs": [
      "self",
      "input_buffers"
    ],
    "get_seqlen_agnostic_capture_inputs": [
      "self",
      "batch_size"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MambaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "model_config",
      "cache_config",
      "quant_config",
      "is_lora_enabled",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "MambaModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MambaForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ],
    "copy_inputs_before_cuda_graphs": [
      "self",
      "input_buffers"
    ],
    "get_seqlen_agnostic_capture_inputs": [
      "self",
      "batch_size"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "SwinSelfAttention": {
    "__init__": [
      "self",
      "config",
      "dim",
      "num_heads",
      "window_size",
      "quant_config",
      "prefix"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "_get_rel_pos_bias": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions"
    ]
  },
  "SwinSelfOutput": {
    "__init__": [
      "self",
      "config",
      "dim",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "SwinAttention": {
    "__init__": [
      "self",
      "config",
      "dim",
      "num_heads",
      "window_size",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions"
    ]
  },
  "SwinIntermediate": {
    "__init__": [
      "self",
      "config",
      "dim",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SwinOutput": {
    "__init__": [
      "self",
      "config",
      "dim",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SwinLayer": {
    "__init__": [
      "self",
      "config",
      "dim",
      "input_resolution",
      "num_heads",
      "drop_path_rate",
      "shift_size",
      "quant_config",
      "prefix"
    ]
  },
  "SwinStage": {
    "__init__": [
      "self",
      "config",
      "dim",
      "input_resolution",
      "depth",
      "num_heads",
      "drop_path",
      "downsample",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_dimensions",
      "output_attentions",
      "always_partition"
    ]
  },
  "SwinEncoder": {
    "__init__": [
      "self",
      "config",
      "grid_size",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_dimensions",
      "output_attentions",
      "always_partition"
    ]
  },
  "SwinModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DEFAULT_ATTN_OUTPUT_MULTIPLIER": [],
  "DEFAULT_OUTPUT_MULTIPLIER_SCALE": [],
  "DEFAULT_EMBEDDING_MULTIPLIER_SCALE": [],
  "DEFAULT_ROUTER_LOGIT_SOFTCAP": [],
  "_get_num_experts": [
    "config"
  ],
  "_get_moe_intermediate_size": [
    "config"
  ],
  "_get_grok_version": [
    "config"
  ],
  "_get_rope_parameters": [
    "config"
  ],
  "_get_moe_renormalize": [
    "config"
  ],
  "Grok1MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Grok1MoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "router_logit_soft_cap",
      "params_dtype",
      "quant_config",
      "tp_size",
      "renormalize",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Grok1Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position",
      "rope_parameters",
      "cache_config",
      "quant_config",
      "prefix",
      "config"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Grok1DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Grok1Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GrokBaseForCausalLM": {
    "fall_back_to_pt_during_load": [],
    "packed_modules_mapping": [],
    "get_weight_name_remapping": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "Grok1ForCausalLM": {
    "ckpt_gate_proj_name": [],
    "ckpt_down_proj_name": [],
    "ckpt_up_proj_name": [],
    "get_weight_name_remapping": [
      "self"
    ]
  },
  "Grok2ForCausalLM": {
    "packed_modules_mapping": [],
    "ckpt_gate_proj_name": [],
    "ckpt_down_proj_name": [],
    "ckpt_up_proj_name": [],
    "get_weight_name_remapping": [
      "self"
    ]
  },
  "GrokForCausalLM": {
    "__new__": [
      "cls"
    ]
  },
  "EPS": [],
  "Gemma3nAltUp": {
    "__init__": [
      "self",
      "hidden_size",
      "rms_norm_eps",
      "altup_num_inputs",
      "altup_coef_clip",
      "altup_active_idx",
      "quant_config",
      "prefix"
    ],
    "_compute_router_modalities": [
      "self",
      "x"
    ],
    "scale_corrected_output": [
      "self",
      "corrected"
    ],
    "predict": [
      "self",
      "hidden_states"
    ],
    "correct": [
      "self",
      "predictions",
      "activated"
    ]
  },
  "Gemma3nLaurelBlock": {
    "__init__": [
      "self",
      "hidden_size",
      "laurel_rank",
      "rms_norm_eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Gemma3nMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_activation",
      "activation_sparsity",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Gemma3nAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "head_dim",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Gemma3nDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "per_layer_input"
    ]
  },
  "Gemma3nSelfDecoder": {
    "__init__": [
      "self"
    ],
    "get_per_layer_input_embeddings": [
      "self",
      "input_ids"
    ],
    "get_per_layer_inputs": [
      "self",
      "hidden_states_0",
      "per_layer_inputs"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "altup_embed": [
      "self",
      "hidden_states_0"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "inputs_embeds",
      "per_layer_inputs"
    ]
  },
  "Gemma3nCrossDecoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "per_layer_inputs"
    ]
  },
  "Gemma3nTextModel": {
    "__init__": [
      "self"
    ],
    "embed_tokens": [
      "self"
    ],
    "get_per_layer_input_embeddings": [
      "self",
      "input_ids"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "fast_prefill_forward": [
      "self",
      "input_ids",
      "positions",
      "inputs_embeds",
      "per_layer_inputs"
    ],
    "normal_forward": [
      "self",
      "input_ids",
      "positions",
      "inputs_embeds",
      "per_layer_inputs"
    ],
    "altup_unembed": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "per_layer_inputs",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Gemma3nForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "ChameleonImagePixelInputs": {},
  "ChameleonProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ]
  },
  "ChameleonDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "ChameleonMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_apply_hf_processor_tokens_only": [
      "self",
      "prompt_tokens"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "ChameleonLayerNorm": {
    "__init__": [
      "self",
      "hidden_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ChameleonMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ChameleonAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_parameters",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "cache_config",
      "prefix"
    ],
    "_apply_qk_norm": [
      "self",
      "q",
      "k"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "ChameleonDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "ChameleonSwinDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "ChameleonVQVAEVectorQuantizer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_state"
    ]
  },
  "ChameleonVQVAEEncoderConvDownsample": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ChameleonVQVAEEncoderResnetBlock": {
    "__init__": [
      "self",
      "config",
      "in_channels",
      "out_channels",
      "conv_shortcut"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ChameleonVQVAEEncoderAttnBlock": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ChameleonVQVAEEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "ChameleonVQVAE": {
    "__init__": [
      "self",
      "config"
    ],
    "encode": [
      "self",
      "pixel_values"
    ]
  },
  "ChameleonImageVocabularyMapping": {
    "__init__": [
      "self",
      "vocab_map"
    ],
    "val2name": [
      "self"
    ],
    "image_tokens": [
      "self"
    ],
    "bpe2img": [
      "self"
    ],
    "img2bpe": [
      "self"
    ],
    "bpe2img_search_tensors": [
      "self"
    ],
    "img2bpe_mapping_tensor": [
      "self"
    ],
    "convert_img2bpe": [
      "self",
      "img_batch"
    ]
  },
  "ChameleonModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "get_image_tokens": [
      "self",
      "pixel_values"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "ChameleonForConditionalGeneration": {
    "packed_modules_mapping": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Gemma3MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_activation",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Gemma3Attention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "head_dim",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "attn_logits_soft_cap",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Gemma3DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Gemma3Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Gemma3ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlavaOnevisionVideoPixelInputs": {},
  "LlavaOnevisionImagePixelInputs": {},
  "LlavaOnevisionImageEmbeddingInputs": {},
  "LlavaOnevisionLikeConfig": {},
  "LlavaOnevisionProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "_get_num_unpadded_features": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "_get_num_frame_tokens": [
      "self"
    ],
    "get_num_video_tokens": [
      "self"
    ],
    "_get_max_video_frames": [
      "self",
      "max_tokens"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "get_max_video_tokens": [
      "self",
      "seq_len",
      "mm_counts"
    ]
  },
  "LlavaOnevisionDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "LlavaOnevisionMultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_hf_processor_applies_updates": [
      "self",
      "prompt_text",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "LlavaOnevisionMultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "LlavaOnevisionForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "_image_pixels_to_features": [
      "self",
      "vision_tower",
      "pixel_values"
    ],
    "_merge_image_patch_embeddings": [
      "self",
      "image_size",
      "patch_embeddings"
    ],
    "_process_image_pixels": [
      "self",
      "inputs"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_video_pixels_to_features": [
      "self",
      "vision_tower",
      "pixel_values"
    ],
    "_process_video_pixels": [
      "self",
      "inputs"
    ],
    "apply_pooling": [
      "self",
      "image_features",
      "stride"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "AIMv2SwiGLUFFN": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AIMv2PatchEmbed": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AIMv2ViTPreprocessor": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AIMv2Attention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AIMv2Block": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AIMv2Transformer": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "tokens"
    ]
  },
  "AIMv2Model": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Blip2ImagePixelInputs": {},
  "Blip2ImageEmbeddingInputs": {},
  "Blip2QFormerMultiHeadAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "transpose_for_scores": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ]
  },
  "Blip2QFormerSelfOutput": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "Blip2QFormerAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states"
    ]
  },
  "Blip2QFormerIntermediate": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Blip2QFormerOutput": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "Blip2QFormerLayer": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "query_length"
    ],
    "feed_forward_chunk": [
      "self",
      "attention_output"
    ],
    "feed_forward_chunk_query": [
      "self",
      "attention_output"
    ]
  },
  "Blip2QFormerEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "query_length"
    ]
  },
  "Blip2QFormerModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "query_embeds",
      "encoder_hidden_states"
    ]
  },
  "Blip2ProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ]
  },
  "Blip2DummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Blip2MultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Blip2ForConditionalGeneration": {
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_image_pixels_to_features": [
      "self",
      "vision_model",
      "pixel_values"
    ],
    "_process_image_pixels": [
      "self",
      "inputs"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "get_num_mm_encoder_tokens": [
      "self",
      "num_image_tokens"
    ],
    "get_num_mm_connector_tokens": [
      "self",
      "num_vision_tokens"
    ]
  },
  "OuroMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OuroAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position",
      "cache_config",
      "quant_config",
      "prefix",
      "attn_type",
      "dual_chunk_attention_config"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "current_ut"
    ]
  },
  "OuroDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "current_ut",
      "residual"
    ]
  },
  "OuroModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "OuroForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "ExaoneMoeMultiTokenPredictor": {
    "__init__": [
      "self"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "intermediate_tensors",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "ExaoneMoeMTP": {
    "__init__": [
      "self"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "intermediate_tensors",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DEFAULT_MAX_AUDIO_LEN_S": [],
  "DEFAULT_MERGE_FACTOR": [],
  "DEFAULT_CONV_PARAMS": [],
  "_calculate_conv_output_length": [
    "input_length",
    "padding",
    "kernel_size",
    "stride"
  ],
  "_as_list_chunk_counts": [
    "chunk_counts"
  ],
  "_normalize_chunk_counts": [
    "chunk_counts",
    "num_chunks"
  ],
  "_get_audio_output_lengths_from_lengths": [
    "audio_lengths",
    "merge_factor",
    "conv_params"
  ],
  "_get_audio_output_lengths_from_mask": [
    "mask",
    "merge_factor",
    "conv_params"
  ],
  "_get_audio_output_lengths_for_tower": [
    "audio_tower",
    "audio_lengths",
    "merge_factor",
    "conv_params"
  ],
  "_flatten_audio_features_by_length": [
    "audio_features",
    "audio_output_lengths"
  ],
  "_group_audio_embeddings": [
    "chunk_embeddings",
    "chunk_counts"
  ],
  "_normalize_to_tensor": [
    "mask"
  ],
  "_extract_mask_for_item": [
    "feature_attention_mask",
    "chunk_counts",
    "item_idx"
  ],
  "GPT2Attention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPT2MLP": {
    "__init__": [
      "self",
      "intermediate_size",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPT2Block": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPT2Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GPT2LMHeadModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GPT2ForSequenceClassification": {
    "is_pooling_model": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "_add_transformer_prefix": [
    "weights"
  ],
  "FalconH1MLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "bias",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FalconH1SSMDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "_init_mup_vector": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "FalconH1AttentionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "self_attention": [
      "self",
      "positions",
      "hidden_states"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "FalconH1ParallelHybrid": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "FalconH1Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "FalconH1ForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "OrionMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OrionAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_parameters",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "OrionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "OrionModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "OrionForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Lfm2MoeMlp": {
    "__init__": [
      "self",
      "dim",
      "ff_dim",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Lfm2MoeSparseMoeBlock": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Lfm2MoeAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Lfm2MoeAttentionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Lfm2MoeShortConvDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "Lfm2MoeModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Lfm2MoeForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "Qwen2RewardBaseModel": {
    "is_pooling_model": [],
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen2ForRewardModel": {
    "__init__": [
      "self"
    ]
  },
  "Qwen2ForProcessRewardModel": {
    "__init__": [
      "self"
    ]
  },
  "BambaMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "bias",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BambaMixerDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "BambaAttentionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "self_attention": [
      "self",
      "positions",
      "hidden_states"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "BambaModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BambaForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "CLIPImagePixelInputs": {},
  "CLIPEncoderInfo": {
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size": [
      "self"
    ],
    "get_patch_size": [
      "self"
    ],
    "get_patch_grid_length": [
      "self"
    ]
  },
  "CLIPProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_vision_encoder_info": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_max_image_tokens": [
      "self"
    ]
  },
  "CLIPDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "CLIPMultiModalProcessor": {
    "image_token_id": [
      "self"
    ],
    "apply": [
      "self",
      "prompt",
      "mm_data",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_hf_processor_applies_updates": [
      "self",
      "prompt_text",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "CLIPTextEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "CLIPVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "CLIPAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CLIPMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CLIPEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "CLIPEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "num_hidden_layers_override"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "return_all_hidden_states"
    ]
  },
  "CLIPTextTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "CLIPVisionTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "CLIPVisionModel": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "select_layers",
      "feature_select_strategy"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ]
  },
  "CLIPEmbeddingModel": {
    "is_pooling_model": [],
    "packed_modules_mapping": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "get_text_features": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeds"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "feature_select_strategy"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_inputs": [
      "self",
      "inputs"
    ],
    "_embed_text_input_ids": [
      "self",
      "input_ids",
      "embed_input_ids"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen2_5OmniAudioFeatureInputs": {},
  "create_qwen2_5_omni_thinker_field_factory": [
    "spatial_merge_size"
  ],
  "Qwen2_5OmniThinkerMultiModalDataParser": {
    "__init__": [
      "self",
      "spatial_merge_size"
    ],
    "_parse_audio_data": [
      "self",
      "data"
    ]
  },
  "Qwen2_5OmniThinkerProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_feature_extractor": [
      "self"
    ],
    "get_target_channels": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ]
  },
  "Qwen2_5OmniThinkerDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Qwen2_5OmniThinkerMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_derive_audio_from_video_placeholders": [
      "self",
      "placeholders",
      "mm_prompt_updates"
    ],
    "_maybe_apply_prompt_updates": [
      "self",
      "mm_items",
      "prompt_ids",
      "mm_kwargs",
      "mm_prompt_updates",
      "is_update_applied"
    ],
    "omni_get_updates_use_audio_in_video": [
      "cls",
      "thinker_config",
      "audio_len",
      "video_grid_thw",
      "video_second_per_grid_t"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_apply_hf_processor_main": [
      "self",
      "prompt",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_apply_hf_processor_mm_only": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ]
  },
  "Qwen2_5OmniConditionalGenerationMixin": {
    "_parse_and_validate_audio_input": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_process_audio_input": [
      "self",
      "audio_input",
      "audio_hashes",
      "cached_audio_features"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_process_video_input": [
      "self",
      "video_input",
      "video_hashes",
      "cached_video_embeds"
    ]
  },
  "Qwen2_5OmniThinkerForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "packed_modules_mapping": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "_get_audio_for_video_mapping": [
      "self",
      "mm_features"
    ],
    "_compute_audio_token_count": [
      "self",
      "audio_feature_length"
    ],
    "iter_mm_features": [
      "self",
      "mm_features"
    ],
    "_compute_interleaved_positions": [
      "self",
      "start_idx",
      "data"
    ],
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "_IMAGE_TOKEN": [],
  "DeepseekOCRImagePixelInputs": {},
  "NoRepeatNGramLogitsProcessor": {
    "__init__": [
      "self",
      "ngram_size",
      "window_size",
      "whitelist_token_ids"
    ],
    "__call__": [
      "self",
      "output_ids",
      "logits"
    ]
  },
  "NGramPerReqLogitsProcessor": {
    "validate_params": [
      "cls",
      "params"
    ],
    "is_argmax_invariant": [
      "self"
    ],
    "new_req_logits_processor": [
      "self",
      "params"
    ]
  },
  "DeepseekOCRProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "DeepseekOCRDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "DeepseekOCRMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "DeepseekOCRForCausalLM": {
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_encode_global_features": [
      "self",
      "image_tensor"
    ],
    "_encode_local_features": [
      "self",
      "patches",
      "crop_shape"
    ],
    "_pixel_values_to_embedding": [
      "self",
      "pixel_values",
      "images_crop",
      "images_spatial_crop"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "Qwen3VLMoeProcessingInfo": {
    "get_hf_config": [
      "self"
    ]
  },
  "Qwen3VLMoeMixtureOfExperts": {
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ],
    "set_moe_parameters": [
      "self"
    ]
  },
  "Qwen3VLMoeForConditionalGeneration": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ]
  },
  "QWenMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QWenAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "max_position_embeddings",
      "rope_parameters",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "QWenBlock": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "QWenModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "QWenBaseModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "QWenLMHeadModel": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "GPTJAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "GPTJMLP": {
    "__init__": [
      "self",
      "intermediate_size",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPTJBlock": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "GPTJModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GPTJForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LightOnOCRMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "_build_LightOnOCR_processor": [
    "info",
    "dummy_inputs"
  ],
  "LightOnOCRForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GraniteMoeHybridMambaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "GraniteMoeHybridAttentionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "GraniteMoeHybridAttention": {
    "__init__": [
      "self",
      "config",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "GraniteMoeHybridModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GraniteMoeHybridForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Siglip2VisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values_packed",
      "spatial_shapes"
    ],
    "resize_positional_embeddings_packed": [
      "positional_embeddings",
      "spatial_shapes",
      "lengths_list"
    ]
  },
  "Siglip2Attention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "max_seqlen"
    ]
  },
  "Siglip2MLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Siglip2EncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "max_seqlen"
    ]
  },
  "Siglip2Encoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "cu_seqlens",
      "max_seqlen"
    ]
  },
  "Siglip2VisionTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values_packed",
      "spatial_shapes",
      "cu_seqlens",
      "max_seqlen"
    ]
  },
  "Siglip2Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "pixel_values_packed",
      "spatial_shapes",
      "cu_seqlens",
      "max_seqlen"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "IMG_PAD": [],
  "NVLMProcessor": {
    "image_token_id": [
      "self"
    ],
    "get_image_repl": [
      "self",
      "feature_size",
      "num_patches"
    ]
  },
  "NVLMProcessingInfo": {
    "get_hf_processor": [
      "self"
    ]
  },
  "NVLMDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "NVLMMultiModalProcessor": {
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "NVLM_D_Model": {
    "_init_mlp1": [
      "self",
      "config"
    ],
    "_init_vision_model": [
      "self",
      "config",
      "quant_config"
    ]
  },
  "ResidualBlock": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_layers"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Medusa": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "NORM2FN": [],
  "InternVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "_get_pos_embed": [
      "self",
      "pos_embed",
      "H",
      "W"
    ],
    "_get_position_embedding": [
      "self",
      "H",
      "W"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "InternVisionPatchModel": {
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "pixel_embeds"
    ]
  },
  "InternParallelAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "_apply_qk_norm": [
      "self",
      "q",
      "k"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InternMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "InternVisionEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "_init_attn": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "InternVisionEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "inputs_embeds"
    ]
  },
  "InternVisionModel": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "pixel_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "IMAGE_TOKEN": [],
  "VIDEO_TOKEN": [],
  "INDICATOR_IDS": [],
  "IMAGE_PAD_TOKEN_MAP": [],
  "IMAGE_PAD_TOKEN_ID_MAP": [],
  "Ovis2_5ImagePatchInputs": {},
  "Ovis2_5VideoPatchInputs": {},
  "VisualTokenizer": {
    "__init__": [
      "self",
      "config",
      "visual_vocab_size",
      "quant_config",
      "prefix"
    ],
    "_init_backbone": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "tokenize": [
      "self",
      "logits"
    ],
    "encode": [
      "self",
      "pixel_values",
      "grid_thws"
    ],
    "forward": [
      "self",
      "pixel_values",
      "grid_thws"
    ]
  },
  "Ovis2_5ProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_image_pad_token": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_max_image_tokens": [
      "self"
    ],
    "_get_max_video_frames": [
      "self",
      "max_tokens"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "get_num_video_tokens": [
      "self"
    ],
    "get_max_video_tokens": [
      "self",
      "seq_len",
      "mm_counts"
    ]
  },
  "Ovis2_5DummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Ovis2_5MultiModalProcessor": {
    "visual_indicators_to_visual_tokens": [
      "self",
      "visual_indicators"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_apply_hf_processor_tokens_only": [
      "self",
      "prompt_tokens"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Ovis2_5": {
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_process_visual_input": [
      "self",
      "visual_input"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LoopCoderAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position",
      "cache_config",
      "quant_config",
      "prefix",
      "attn_type",
      "dual_chunk_attention_config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "loop_idx",
      "gate_proj"
    ]
  },
  "LoopCoderDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix",
      "layer_idx"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "loop_idx",
      "gate_proj"
    ]
  },
  "LoopGateProjection": {
    "__init__": [
      "self",
      "total_num_heads",
      "head_dim",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "query"
    ]
  },
  "IQuestLoopCoderModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "IQuestLoopCoderForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiMoMultiTokenPredictorLayer": {
    "__init__": [
      "self",
      "config",
      "prefix",
      "model_config",
      "cache_config",
      "quant_config"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "positions",
      "previous_hidden_states",
      "spec_step_index"
    ]
  },
  "MiMoMultiTokenPredictor": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "previous_hidden_states",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "lm_head",
      "spec_step_idx"
    ]
  },
  "MiMoMTP": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "intermediate_tensors",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "map_model_name_to_mtp_param_name": [
      "self",
      "name"
    ],
    "_rewrite_spec_layer_name": [
      "self",
      "spec_layer",
      "name"
    ]
  },
  "ExaoneGatedMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ExaoneAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "cache_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "ExaoneBlockAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "cache_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "ExaoneDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "ExaoneModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "ExaoneForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Mistral3ImagePixelInputs": {},
  "Mistral3PatchMerger": {
    "__init__": [
      "self",
      "vision_hidden_size",
      "spatial_merge_size",
      "patch_size"
    ],
    "forward": [
      "self",
      "image_features",
      "image_sizes"
    ]
  },
  "Mistral3MultiModalProjector": {
    "__init__": [
      "self",
      "vision_hidden_size",
      "text_hidden_size",
      "spatial_merge_size",
      "patch_size",
      "projector_hidden_act",
      "multimodal_projector_bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "image_features",
      "image_sizes"
    ]
  },
  "LlavaLikeConfig": {},
  "LlavaLikeProcessor": {},
  "BaseLlavaProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_vision_encoder_info": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "Mistral3DummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Mistral3ProcessingInfo": {
    "get_hf_processor": [
      "self"
    ]
  },
  "Mistral3MultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "_build_mistral3_info": [
    "ctx"
  ],
  "_build_mistral3_processor": [
    "info",
    "dummy_inputs"
  ],
  "_get_num_hidden_layers": [
    "hf_config"
  ],
  "init_vision_tower_for_llava": [
    "hf_config",
    "quant_config"
  ],
  "Mistral3ForConditionalGeneration": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "get_blip_patch_grid_length": [],
  "get_blip_num_patches": [],
  "BlipVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "BlipAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BlipMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BlipEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BlipEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "num_hidden_layers_override",
      "prefix"
    ],
    "forward": [
      "self",
      "inputs_embeds"
    ]
  },
  "BlipVisionModel": {
    "config_class": [],
    "main_input_name": [],
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DeepseekVL2ImagePixelInputs": {},
  "DeepseekVL2VImageEmbeddingInputs": {},
  "MlpProjector": {
    "__init__": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DeepseekVL2ProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "DeepseekVL2DummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "DeepseekVL2MultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_cached_apply_hf_processor": [
      "self",
      "prompt",
      "mm_data_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs",
      "mm_uuids"
    ]
  },
  "DeepseekVLV2ForCausalLM": {
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_get_parent_and_attr": [
      "self",
      "root",
      "dotted_name"
    ],
    "patch_vit_for_tp": [
      "self",
      "vit",
      "quant_config"
    ],
    "_init_vision_module": [
      "self",
      "vision_config",
      "quant_config",
      "prefix"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_pixel_values_to_embedding": [
      "self",
      "pixel_values",
      "images_spatial_crop"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BagelImagePixelInputs": {},
  "BagelVisionMLP": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "act_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PositionEmbedding": {
    "__init__": [
      "self",
      "max_num_patch_per_side",
      "hidden_size"
    ],
    "_get_2d_sincos_pos_embed": [
      "embed_dim",
      "grid_size"
    ],
    "_get_2d_sincos_pos_embed_from_grid": [
      "embed_dim",
      "grid"
    ],
    "_get_1d_sincos_pos_embed_from_grid": [
      "embed_dim",
      "pos"
    ],
    "forward": [
      "self",
      "position_ids"
    ]
  },
  "BagelProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_mm_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "get_num_image_tokens": [
      "self"
    ]
  },
  "BagelDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "BagelMultiModalProcessor": {
    "_hf_processor_applies_updates": [
      "self",
      "prompt_text",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "BagelForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "InternS1MultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "InternS1ImagePixelInputs": {},
  "InternS1ImageEmbeddingInputs": {},
  "InternS1VideoPixelInputs": {},
  "InternS1VideoEmbeddingInputs": {},
  "resolve_interns1_min_max_num": [
    "min_dynamic_patch",
    "max_dynamic_patch",
    "dynamic_image_size",
    "use_thumbnail"
  ],
  "get_interns1_target_ratios": [
    "min_num",
    "max_num"
  ],
  "InternS1ProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "resolve_target_ratios": [
      "self",
      "use_thumbnail"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_max_image_tokens": [
      "self"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len",
      "mm_counts"
    ]
  },
  "InternS1DummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "InternS1MultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "InternS1ForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_init_vision_model": [
      "self",
      "config",
      "quant_config"
    ],
    "_init_mlp1": [
      "self",
      "config"
    ],
    "pixel_shuffle": [
      "self",
      "x",
      "scale_factor"
    ],
    "extract_feature": [
      "self",
      "pixel_values"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_process_vision_input": [
      "self",
      "image_input"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "_set_visual_token_mask": [
      "self",
      "input_ids"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "MiniCPMMoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "params_dtype",
      "tp_size",
      "prefix"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "weight_name",
      "expert_id"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MiniCPMMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "hidden_act_param",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MiniCPMAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_parameters",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "MiniCPMDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "_init_attn_block": [
      "self"
    ],
    "_init_ffn_block": [
      "self"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "MiniCPMModel": {
    "__init__": [
      "self"
    ],
    "_init_layers": [
      "self",
      "prefix",
      "config",
      "cache_config",
      "quant_config"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiniCPMForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "_init_model": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DotsOCRImagePixelInputs": {},
  "DotsOCRImageEmbeddingInputs": {},
  "DotsOCRDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "DotsOCRProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_mm_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "get_hf_processor": [
      "self"
    ]
  },
  "VisionRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "DotsVisionAttention": {
    "__init__": [
      "self",
      "config",
      "dim",
      "num_heads",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "DotsSwiGLUFFN": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DotsPatchEmbed": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ]
  },
  "DotsViTPreprocessor": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ]
  },
  "DotsVisionBlock": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DotsVisionTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "get_pos_ids_by_grid": [
      "self",
      "grid_thw"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "compute_attn_mask_seqlen": [
      "self",
      "cu_seqlens"
    ],
    "forward": [
      "self",
      "hidden_states",
      "grid_thw"
    ]
  },
  "DotsOCRForCausalLM": {
    "hf_to_vllm_mapper": [],
    "packed_modules_mapping": [],
    "supports_encoder_tp_data": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "get_num_mm_encoder_tokens": [
      "self",
      "num_image_tokens"
    ],
    "get_num_mm_connector_tokens": [
      "self",
      "num_vision_tokens"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "VerifyAndUpdateConfig": {
    "verify_and_update_config": [
      "vllm_config"
    ],
    "verify_and_update_model_config": [
      "model_config"
    ]
  },
  "Gemma3TextModelConfig": {
    "verify_and_update_model_config": [
      "model_config"
    ]
  },
  "GteNewModelConfig": {
    "verify_and_update_model_config": [
      "model_config"
    ]
  },
  "JambaForSequenceClassificationConfig": {
    "verify_and_update_model_config": [
      "model_config"
    ]
  },
  "JinaRobertaModelConfig": {
    "verify_and_update_model_config": [
      "model_config"
    ]
  },
  "LlamaBidirectionalConfig": {
    "verify_and_update_model_config": [
      "model_config"
    ]
  },
  "NomicBertModelConfig": {
    "verify_and_update_model_config": [
      "model_config"
    ]
  },
  "Qwen2ForProcessRewardModelConfig": {
    "verify_and_update_model_config": [
      "model_config"
    ]
  },
  "Qwen2ForRewardModelConfig": {
    "verify_and_update_model_config": [
      "model_config"
    ]
  },
  "Qwen3ForSequenceClassificationConfig": {
    "verify_and_update_model_config": [
      "model_config"
    ]
  },
  "Qwen3VLForSequenceClassificationConfig": {},
  "JinaVLForSequenceClassificationConfig": {
    "verify_and_update_model_config": [
      "model_config"
    ]
  },
  "SnowflakeGteNewModelConfig": {
    "verify_and_update_model_config": [
      "model_config"
    ]
  },
  "GptOssForCausalLMConfig": {
    "verify_and_update_config": [
      "vllm_config"
    ]
  },
  "MambaModelConfig": {
    "verify_and_update_config": [
      "cls",
      "vllm_config"
    ]
  },
  "HybridAttentionMambaModelConfig": {
    "verify_and_update_config": [
      "cls",
      "vllm_config"
    ]
  },
  "DeepseekV32ForCausalLM": {
    "verify_and_update_config": [
      "cls",
      "vllm_config"
    ]
  },
  "NemotronHForCausalLMConfig": {
    "verify_and_update_config": [
      "vllm_config"
    ]
  },
  "Glm4MoeMultiTokenPredictorLayer": {
    "__init__": [
      "self",
      "config",
      "prefix",
      "cache_config",
      "quant_config",
      "parallel_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "previous_hidden_states",
      "inputs_embeds",
      "spec_step_index"
    ]
  },
  "Glm4MoeMultiTokenPredictor": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "previous_hidden_states",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ]
  },
  "Glm4MoeMTP": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "intermediate_tensors",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_rewrite_spec_layer_name": [
      "self",
      "spec_layer",
      "name"
    ]
  },
  "FlashConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_layers",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "ep_size",
      "kv_lora_rank",
      "q_lora_rank",
      "qk_rope_head_dim",
      "v_head_dim",
      "qk_nope_head_dim",
      "num_experts_per_tok",
      "norm_topk_prob",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "pretraining_tp",
      "tie_word_embeddings",
      "rope_parameters",
      "attention_bias",
      "attention_dropout",
      "mla_scale_q_lora",
      "mla_scale_kv_lora",
      "dtype",
      "params_dtype",
      "router_dtype",
      "router_bias",
      "topk_method",
      "routed_scaling_factor",
      "zero_expert_num",
      "zero_expert_type",
      "nextn_use_scmoe"
    ]
  },
  "FlashMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LongcatRouter": {
    "__init__": [
      "self",
      "config",
      "zero_expert_num",
      "rounter_params_dtype",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LongcatMoe": {
    "__init__": [
      "self",
      "config",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "params_dtype",
      "quant_config",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "FlashDecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "config",
      "cache_config",
      "quant_config",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "FlashModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "LongcatFlashForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "KeyeImagePixelInputs": {},
  "KeyeImageEmbeddingInputs": {},
  "KeyeVideoPixelInputs": {},
  "KeyeVideoEmbeddingInputs": {},
  "KeyeVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "interpolate_pos_encoding": [
      "self",
      "embeddings",
      "height",
      "width",
      "is_after_patchify"
    ],
    "fetch_position_embedding_lfu_cache": [
      "self",
      "embeddings",
      "h",
      "w",
      "max_cache"
    ],
    "forward": [
      "self",
      "pixel_values",
      "position_ids",
      "image_grid_thw",
      "interpolate_pos_encoding"
    ]
  },
  "apply_rotary_pos_emb_flashatt": [
    "q",
    "k",
    "cos",
    "sin",
    "apply_rotary_emb"
  ],
  "KeyeSiglipAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions",
      "cu_seqlens",
      "rope_emb"
    ]
  },
  "KeyeSiglipEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "output_attentions",
      "cu_seqlens",
      "rope_emb"
    ]
  },
  "KeyeSiglipEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "flatten_list": [
      "image_grid_thw"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "output_attentions",
      "output_hidden_states",
      "cu_seqlens",
      "image_grid_thw",
      "height_position_ids",
      "width_position_ids",
      "use_rope",
      "window_size",
      "vision_or_text"
    ]
  },
  "KeyeSiglipVisionTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_attentions",
      "output_hidden_states",
      "interpolate_pos_encoding",
      "attention_mask",
      "sample_indices",
      "image_indices",
      "position_ids",
      "height_position_ids",
      "width_position_ids",
      "cu_seqlens",
      "padding_mask",
      "vision_return_embed_list",
      "image_grid_thw",
      "return_pooler_output",
      "use_rope",
      "window_size"
    ]
  },
  "KeyeSiglipVisionModel": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "sample_indices",
      "output_attentions",
      "output_hidden_states",
      "interpolate_pos_encoding",
      "position_ids",
      "vision_return_embed_list",
      "image_grid_thw",
      "cu_seqlens",
      "return_pooler_output",
      "use_rope",
      "window_size"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_keye_field_config": [
    "hf_inputs"
  ],
  "KeyeMultiModalDataParser": {
    "_parse_image_data": [
      "self",
      "data"
    ],
    "_parse_video_data": [
      "self",
      "data"
    ]
  },
  "KeyeProcessingInfo": {
    "get_max_image_size": [
      "self"
    ],
    "get_max_frame_per_video": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_mm_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "_get_vision_info": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_num_video_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_max_image_tokens": [
      "self"
    ],
    "_get_max_video_frames": [
      "self",
      "max_tokens"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len"
    ],
    "get_max_video_tokens": [
      "self",
      "seq_len"
    ]
  },
  "KeyeBaseDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "KeyeDummyInputsBuilder": {},
  "KeyeMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "BaseKeyeModule": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_build_projector": [
      "self",
      "text_config",
      "vision_config",
      "quant_config",
      "prefix"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_process_video_embeds": [
      "self",
      "video_type",
      "video_grid_thw",
      "pixel_values_videos"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "KeyeForConditionalGeneration": {
    "_build_projector": [
      "self",
      "text_config",
      "vision_config",
      "quant_config",
      "prefix"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_process_video_input": [
      "self",
      "video_input"
    ],
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ]
  },
  "MiniCPM3Attention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "v_head_dim",
      "q_lora_rank",
      "kv_lora_rank",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "MiniCPM3DecoderLayer": {
    "_init_attn_block": [
      "self"
    ]
  },
  "MiniCPM3Model": {
    "_init_layers": [
      "self",
      "prefix",
      "config",
      "cache_config",
      "quant_config"
    ]
  },
  "MiniCPM3ForCausalLM": {
    "packed_modules_mapping": [],
    "_init_model": [
      "self"
    ]
  },
  "_ffn_mult_to_intermediate_size": [
    "ffn_mult",
    "n_embd"
  ],
  "_find_multiple": [
    "n",
    "k"
  ],
  "DeciLMAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "bias_o_proj",
      "cache_config",
      "prefix",
      "attn_type"
    ],
    "_init_rotary_emb": [
      "self",
      "config",
      "quant_config"
    ]
  },
  "DeciLMDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "DeciModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DeciLMForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "mistral_mapping": [],
    "__init__": [
      "self"
    ],
    "_init_model": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlamaDecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "disable_input_layernorm",
      "prefix",
      "config"
    ],
    "get_quant_config": [
      "self",
      "vllm_config"
    ]
  },
  "LlamaModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "EagleLlamaForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiMoV2MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MiMoV2MoE": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix",
      "is_nextn"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MiMoV2Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "head_dim",
      "v_head_dim",
      "v_scale",
      "sliding_window_size",
      "attention_bias",
      "add_swa_attention_sink_bias",
      "layer_id",
      "rope_theta",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "partial_rotary_factor",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "MiMoV2FlashDecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ],
    "is_moe_layer": [
      "self",
      "layer_idx"
    ],
    "is_compressed_softmax_layer": [
      "self"
    ]
  },
  "MiMoV2Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiMoV2FlashForCausalLM": {
    "__init__": [
      "self"
    ],
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "SwiGLUActivation": {
    "forward": [
      "self",
      "x1",
      "x2"
    ]
  },
  "JAISAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "JAISMLP": {
    "__init__": [
      "self",
      "intermediate_size",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "JAISBlock": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "JAISModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "JAISLMHeadModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "layer_norm_func": [
    "hidden_states",
    "weight",
    "variance_epsilon"
  ],
  "CohereMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CohereAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "_apply_qk_norm": [
      "self",
      "q",
      "k"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "CohereDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "CohereModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "CohereForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MaxImageTokenMeta": {},
  "KimiK25MediaPixelInputs": {},
  "MoonshotKimiVAutoProcessor": {
    "attributes": [],
    "tokenizer_class": [],
    "__init__": [
      "self",
      "media_processor",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "vision_chunks"
    ]
  },
  "KimiK25ProcessingInfo": {
    "__init__": [
      "self",
      "ctx"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_hf_config": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ]
  },
  "KimiK25DummyInputsBuilder": {
    "__init__": [
      "self",
      "info"
    ],
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_items": [
      "self"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "KimiK25MultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "split_video_chunks": [
      "self",
      "video"
    ]
  },
  "KimiK25ForConditionalGeneration": {
    "supports_encoder_tp_data": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "_parse_and_validate_media_input": [
      "self"
    ],
    "_process_media_input": [
      "self",
      "media_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "get_language_model": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "SmolVLMProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "_get_image_token": [
      "self",
      "processor"
    ]
  },
  "SmolVLMForConditionalGeneration": {
    "__init__": [
      "self"
    ]
  },
  "TeleFLMModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ]
  },
  "TeleFLMForCausalLM": {
    "__init__": [
      "self"
    ]
  },
  "Fairseq2LlamaForCausalLM": {
    "__init__": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "flag_sharded_weights": [
      "self",
      "params"
    ],
    "reshape_fairseq2_weights": [
      "self",
      "name",
      "loaded_weight",
      "params"
    ]
  },
  "Dots1MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Dots1MoE": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Dots1Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "config",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Dots1DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "prefix",
      "model_config",
      "cache_config",
      "quant_config"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Dots1Model": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Dots1ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "AyaVisionImagePixelInputs": {},
  "AyaVisionMultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "image_features"
    ],
    "pixel_shuffle": [
      "self",
      "image_features"
    ]
  },
  "AyaVisionProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_num_patches": [
      "self"
    ]
  },
  "AyaVisionDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "AyaVisionMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "AyaVisionForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_image_pixels_to_features": [
      "self",
      "vision_tower",
      "pixel_values"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ]
  },
  "DbrxRouter": {
    "__init__": [
      "self",
      "config",
      "params_dtype"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DbrxExperts": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "params_dtype",
      "prefix"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "weight_name",
      "param_name"
    ]
  },
  "DbrxMoE": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "params_dtype",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DbrxAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "DbrxFusedNormAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "DbrxBlock": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "DbrxModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DbrxForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "PhiMoEConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "head_dim",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings",
      "rope_parameters",
      "sliding_window",
      "attention_dropout",
      "num_experts_per_tok",
      "num_local_experts",
      "output_router_logits",
      "router_aux_loss_coef",
      "router_jitter_noise",
      "attention_bias",
      "lm_head_bias"
    ]
  },
  "mp": {
    "forward": [
      "ctx",
      "scores",
      "multiplier",
      "selected_experts",
      "masked_gates",
      "mask_for_one"
    ],
    "backward": [
      "ctx",
      "grad_at_output"
    ]
  },
  "sparsemixer": [
    "scores",
    "jitter_eps"
  ],
  "phimoe_routing_function": [
    "hidden_states",
    "gating_output",
    "topk",
    "renormalize"
  ],
  "PhiMoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "params_dtype",
      "quant_config",
      "tp_size",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "PhiMoEAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_parameters",
      "head_dim",
      "max_position",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "PhiMoEDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "PhiMoEModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "PhiMoEForCausalLM": {
    "fall_back_to_pt_during_load": [],
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "replace_weight_name": [
    "name",
    "key",
    "to",
    "count",
    "prefix"
  ],
  "weight_loader_with_alias": [
    "alias"
  ],
  "MiniMaxText01MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "quant_config",
      "layer_idx",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MiniMaxText01MoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "params_dtype",
      "layer_idx",
      "quant_config",
      "prefix"
    ],
    "gate_weight_loader": [
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MiniMaxText01Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "head_dim",
      "num_kv_heads",
      "max_position",
      "rope_parameters",
      "sliding_window",
      "quant_config",
      "layer_idx",
      "cache_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "output",
      "positions"
    ]
  },
  "MiniMaxText01DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "model_config",
      "cache_config",
      "quant_config",
      "expert_num",
      "layer_id",
      "linear_layer_id",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "positions",
      "attn_metadata",
      "residual",
      "is_warmup"
    ],
    "shared_moe_coefficient_loader": [
      "param",
      "loaded_weight"
    ]
  },
  "MiniMaxText01Model": {
    "__init__": [
      "self"
    ],
    "_clear_prefill_cache": [
      "self",
      "attn_metadata",
      "minimax_cache_tensors"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "MiniMaxText01ForCausalLM": {
    "__init__": [
      "self"
    ],
    "copy_inputs_before_cuda_graphs": [
      "self",
      "input_buffers"
    ],
    "get_seqlen_agnostic_capture_inputs": [
      "self",
      "batch_size"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "make_empty_intermediate_tensors": [
      "self",
      "batch_size",
      "dtype",
      "device"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ]
  },
  "Lfm2VLImagePixelInputs": {},
  "LFM2VLImageInputs": [],
  "Lfm2VLProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "_is_image_too_large": [
      "self",
      "height",
      "width",
      "max_image_tokens",
      "encoder_patch_size",
      "downsample_factor",
      "max_pixels_tolerance"
    ],
    "smart_resize": [
      "self",
      "height",
      "width",
      "downsample_factor",
      "min_image_tokens",
      "max_image_tokens",
      "encoder_patch_size"
    ],
    "_target_ratios": [
      "self",
      "min_tiles",
      "max_tiles"
    ],
    "_get_grid_layout": [
      "self",
      "height",
      "width",
      "min_tiles",
      "max_tiles",
      "tile_size"
    ],
    "_get_image_feature_grid_size": [
      "self",
      "image_width",
      "image_height",
      "processor"
    ],
    "get_num_patches": [
      "self"
    ],
    "get_image_repl": [
      "self",
      "image_width",
      "image_height",
      "spatial_shapes",
      "processor"
    ],
    "get_num_image_tokens": [
      "self"
    ]
  },
  "Lfm2VLDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Lfm2VLMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Lfm2VLMultiModalProjector": {
    "__init__": [
      "self",
      "config",
      "use_data_parallel",
      "prefix"
    ],
    "forward": [
      "self",
      "vision_features_packed",
      "spatial_shapes"
    ]
  },
  "Lfm2VLForConditionalGeneration": {
    "merge_by_field_config": [],
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "image_pixels_to_features": [
      "self",
      "pixel_values",
      "spatial_shapes"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "Phi3ForCausalLM": {
    "packed_modules_mapping": []
  },
  "Ernie4_5ForCausalLM": {
    "__init__": [
      "self"
    ]
  },
  "DEFAULT_NUM_TILES": [],
  "NanoNemotronVLImagePixelInputs": {},
  "NanoNemotronVLImagePixelInputsDynamic": {},
  "NanoNemotronVLImageEmbeddingInputs": {},
  "NanoNemotronVLVideoPixelInputs": {},
  "NanoNemotronVLVideoEmbeddingInputs": {},
  "dynamic_preprocess": [
    "image"
  ],
  "image_to_pixel_values": [
    "image"
  ],
  "video_to_pixel_values": [
    "video"
  ],
  "input_conditioner": [
    "x",
    "norm_mean",
    "norm_std"
  ],
  "calculate_timestamps": [
    "indices",
    "frame_duration_ms"
  ],
  "DynamicResolutionImageTiler": {
    "CONV_MERGING": [],
    "PIXEL_SHUFFLE": [],
    "USE_THUMBNAIL": [],
    "__init__": [
      "self"
    ],
    "_get_num_embeddings": [
      "self",
      "width",
      "height"
    ],
    "width_and_height_for_max_num_tokens_available": [
      "self",
      "target_num_tokens_post_shuffle"
    ],
    "max_num_tokens_available": [
      "self",
      "text_prompt_length"
    ],
    "_images_to_pixel_values_lst": [
      "self",
      "text_prompt_length",
      "images"
    ],
    "get_cached_feature_size": [
      "cls",
      "image"
    ],
    "apply_params": [
      "self",
      "params"
    ],
    "process_media": [
      "self",
      "media",
      "num_tokens_available"
    ],
    "compute_params": [
      "self",
      "media_list",
      "num_tokens_available"
    ],
    "stack": [
      "images",
      "patch_size"
    ]
  },
  "BaseNanoNemotronVLProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "use_dynamic_resolution": [
      "config"
    ],
    "image_token_id": [
      "self"
    ],
    "get_image_repl": [
      "self",
      "feature_size",
      "num_patches"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "_images_to_pixel_values_lst": [
      "self",
      "images",
      "max_num_tiles"
    ],
    "_preprocess_image": [
      "self",
      "text",
      "images",
      "max_num_tiles"
    ],
    "_make_batch_input": [
      "self",
      "input_item"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "return_tensors",
      "max_num_tiles"
    ]
  },
  "NanoNemotronVLProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "supports_video": [
      "self"
    ],
    "video_token_id": [
      "self"
    ],
    "image_token_id": [
      "self"
    ],
    "_videos_to_pixel_values_lst": [
      "self",
      "videos",
      "max_num_tiles"
    ],
    "_preprocess_video": [
      "self",
      "text",
      "videos",
      "max_num_tiles"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "videos",
      "return_tensors",
      "max_num_tiles"
    ],
    "get_image_repl": [
      "self",
      "feature_size",
      "num_patches"
    ],
    "get_video_repl": [
      "cls"
    ]
  },
  "BaseNanoNemotronVLProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self",
      "max_num_tiles"
    ],
    "get_max_image_tokens": [
      "self"
    ]
  },
  "NanoNemotronVLProcessingInfo": {
    "supports_video": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_video_token": [
      "self"
    ],
    "get_video_pruning_rate": [
      "self"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "get_hf_processor": [
      "self"
    ]
  },
  "NanoNemotronBaseVLMultiModalProcessor": {
    "is_dynamic_tiler": [
      "self"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "NanoNemotronVLMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "NanoNemotronVLDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "_get_dummy_videos": [
      "self"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "NemotronH_Nano_VL_V2": {
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "pixel_shuffle": [
      "self",
      "x",
      "scale_factor"
    ],
    "pixel_shuffle_dynamic_res": [
      "self",
      "x"
    ],
    "extract_feature_dynamic": [
      "self",
      "pixel_values",
      "imgs_sizes"
    ],
    "extract_feature": [
      "self",
      "pixel_values"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input_dynamic": [
      "self",
      "image_input"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_process_video_input": [
      "self",
      "video_input"
    ],
    "_create_final_video_embeddings": [
      "self",
      "video_embeddings",
      "num_tokens_per_frame",
      "frames_indices",
      "frame_duration_ms"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "print_architecture": [
      "self",
      "detailed",
      "save_to_file"
    ],
    "get_vit_model_from_radio_config": [
      "self",
      "hf_config"
    ],
    "copy_inputs_before_cuda_graphs": [
      "self",
      "input_buffers"
    ],
    "get_seqlen_agnostic_capture_inputs": [
      "self",
      "batch_size"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ]
  },
  "VoxtralStreamingMultiModalProcessor": {
    "__init__": [
      "self",
      "info",
      "dummy_inputs"
    ],
    "_maybe_apply_prompt_updates": [
      "self",
      "mm_items",
      "prompt_ids",
      "mm_kwargs",
      "mm_prompt_updates",
      "is_update_applied"
    ]
  },
  "TimeEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta"
    ],
    "forward": [
      "self",
      "t"
    ]
  },
  "_expand_tensor": [
    "input_tensor",
    "scaling"
  ],
  "VoxtralStreamingGeneration": {
    "requires_raw_input_tokens": [],
    "__init__": [
      "self"
    ],
    "audio_config": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "embed_multimodal": [
      "self"
    ],
    "get_speech_to_text_config": [
      "cls",
      "model_config",
      "task_type"
    ],
    "get_generation_prompt": [
      "cls",
      "audio",
      "model_config",
      "stt_config",
      "language",
      "task_type",
      "request_prompt",
      "to_language"
    ]
  },
  "Jais2MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Jais2Attention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "cache_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Jais2DecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ],
    "get_quant_config": [
      "self",
      "vllm_config"
    ]
  },
  "Jais2Model": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix",
      "layer_type"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Jais2ForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "_init_model": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlamaMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix",
      "reduce_results",
      "disable_tp"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LlamaAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "bias_o_proj",
      "cache_config",
      "prefix",
      "attn_type"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ],
    "_init_rotary_emb": [
      "self",
      "config",
      "quant_config"
    ]
  },
  "llama_model_invariants": [
    "input_ids",
    "positions",
    "intermediate_tensors",
    "inputs_embeds"
  ],
  "LlamaForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ],
    "_init_model": [
      "self",
      "vllm_config",
      "prefix",
      "layer_type"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlamaBidirectionalForSequenceClassification": {},
  "LlamaBidirectionalModel": {},
  "BeeProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "_get_num_unpadded_features": [
      "self"
    ]
  },
  "BeeDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "BeeMultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "image_feature"
    ]
  },
  "BeeForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self"
    ]
  },
  "DeepseekAttention": {
    "__init__": [
      "self",
      "vllm_config",
      "config",
      "hidden_size",
      "num_heads",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "DeepseekV2MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "is_sequence_parallel",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DeepseekV2MoE": {
    "__init__": [
      "self",
      "config",
      "parallel_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "_get_llama_4_scaling": [
    "original_max_position_embeddings",
    "scaling_beta",
    "positions"
  ],
  "DeepseekV2Attention": {
    "__init__": [
      "self",
      "vllm_config",
      "config",
      "hidden_size",
      "num_heads",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "v_head_dim",
      "q_lora_rank",
      "kv_lora_rank",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "topk_indices_buffer",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "llama_4_scaling"
    ]
  },
  "DeepseekV32IndexerCache": {
    "__init__": [
      "self",
      "head_dim",
      "dtype",
      "prefix",
      "cache_config"
    ],
    "get_kv_cache_spec": [
      "self",
      "vllm_config"
    ],
    "forward": [
      "self"
    ],
    "get_attn_backend": [
      "self"
    ]
  },
  "Indexer": {
    "__init__": [
      "self",
      "vllm_config",
      "config",
      "hidden_size",
      "q_lora_rank",
      "quant_config",
      "cache_config",
      "topk_indices_buffer",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "qr",
      "positions",
      "rotary_emb"
    ]
  },
  "DeepseekV2MLAAttention": {
    "__init__": [
      "self",
      "vllm_config",
      "config",
      "hidden_size",
      "num_heads",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "v_head_dim",
      "q_lora_rank",
      "kv_lora_rank",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix",
      "topk_indices_buffer"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "llama_4_scaling"
    ]
  },
  "DeepseekV2DecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix",
      "config",
      "topk_indices_buffer"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual",
      "llama_4_scaling"
    ]
  },
  "DeepseekV2Model": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "DeepseekV2MixtureOfExperts": {
    "extract_moe_parameters": [
      "self",
      "example_moe"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ]
  },
  "DeepseekV2ForCausalLM": {
    "packed_modules_mapping": [],
    "model_cls": [],
    "__init__": [
      "self"
    ],
    "set_moe_parameters": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DeepseekForCausalLM": {},
  "DeepseekV3ForCausalLM": {},
  "LlavaImagePixelInputs": {},
  "PixtralHFImagePixelInputs": {},
  "LlavaImageEmbeddingInputs": {},
  "LlavaMultiModalProjector": {
    "__init__": [
      "self",
      "vision_hidden_size",
      "text_hidden_size",
      "projector_hidden_act",
      "multimodal_projector_bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "LlavaDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "LlavaProcessingInfo": {
    "get_hf_processor": [
      "self"
    ]
  },
  "BaseLlavaMultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "LlavaMultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "PixtralHFProcessingInfo": {
    "get_hf_processor": [
      "self"
    ]
  },
  "PixtralHFMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "_build_llava_or_pixtral_hf_info": [
    "ctx"
  ],
  "_build_llava_or_pixtral_hf_processor": [
    "info",
    "dummy_inputs"
  ],
  "LlavaForConditionalGeneration": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_image_pixels_to_features": [
      "self",
      "vision_tower",
      "pixel_values"
    ],
    "_process_image_pixels": [
      "self",
      "inputs"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "get_num_mm_encoder_tokens": [
      "self",
      "num_image_tokens"
    ],
    "get_num_mm_connector_tokens": [
      "self",
      "num_vision_tokens"
    ]
  },
  "MantisProcessingInfo": {
    "get_hf_processor": [
      "self"
    ]
  },
  "MantisMultiModalProcessor": {
    "apply": [
      "self",
      "prompt",
      "mm_data",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs",
      "mm_uuids"
    ]
  },
  "MantisForConditionalGeneration": {},
  "_C": [],
  "_RootConfig": {},
  "VisionEncoderInfo": {
    "__init__": [
      "self",
      "hf_config"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size": [
      "self"
    ],
    "get_patch_size": [
      "self"
    ],
    "get_patch_grid_length": [
      "self"
    ]
  },
  "VisionLanguageConfig": {},
  "get_vision_encoder_info": [
    "hf_config"
  ],
  "_get_vit_attn_backend": [
    "head_size",
    "dtype"
  ],
  "get_vit_attn_backend": [
    "head_size",
    "dtype"
  ],
  "is_vit_use_data_parallel": [],
  "should_torch_compile_mm_vit": [
    "vllm_config"
  ],
  "VisionFeatureSelectStrategyStr": [],
  "_get_vision_feature_selector": [
    "strategy"
  ],
  "get_num_selected_vision_tokens": [
    "num_vision_tokens",
    "strategy"
  ],
  "resolve_visual_encoder_outputs": [
    "encoder_outputs",
    "post_layer_norm"
  ],
  "run_dp_sharded_vision_model": [
    "image_input",
    "vision_model"
  ],
  "get_load_balance_assignment": [
    "sizes",
    "num_gpus"
  ],
  "run_dp_sharded_mrope_vision_model": [
    "vision_model",
    "pixel_values",
    "grid_thw_list"
  ],
  "get_llm_pos_ids_for_vision": [
    "start_idx",
    "vision_idx",
    "spatial_merge_size",
    "t_index",
    "grid_hs",
    "grid_ws"
  ],
  "Olmo2Attention": {
    "__init__": [
      "self"
    ],
    "_apply_qk_norm": [
      "self",
      "q",
      "k"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Olmo2MLP": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Olmo2DecoderLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Olmo2Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Olmo2ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BlockBase": {
    "__init__": [
      "self",
      "input_size",
      "output_size"
    ]
  },
  "get_activation": [
    "name"
  ],
  "adaptive_enc_mask": [
    "x_len",
    "chunk_start_idx",
    "left_window",
    "right_window"
  ],
  "GLU": {
    "__init__": [
      "self",
      "dim",
      "act_name"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GLUPointWiseConv": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "kernel_size",
      "glu_type",
      "bias_in_glu",
      "causal"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DepthWiseSeperableConv1d": {
    "__init__": [
      "self",
      "input_dim",
      "depthwise_seperable_out_channel",
      "kernel_size",
      "depthwise_multiplier",
      "padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvModule": {
    "__init__": [
      "self",
      "input_dim",
      "ext_pw_out_channel",
      "depthwise_seperable_out_channel",
      "ext_pw_kernel_size",
      "kernel_size",
      "depthwise_multiplier",
      "dropout_rate",
      "causal",
      "batch_norm",
      "chunk_se",
      "chunk_size",
      "activation",
      "glu_type",
      "bias_in_glu",
      "linear_glu_in_convm",
      "export"
    ],
    "_add_ext_pw_layer": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GLULinear": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "glu_type",
      "bias_in_glu"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_pre_hook": [
    "state_dict",
    "prefix",
    "local_metadata",
    "strict",
    "missing_keys",
    "unexpected_keys",
    "error_msgs"
  ],
  "T5RelativeAttentionLogitBias": {
    "__init__": [
      "self",
      "num_heads",
      "num_buckets",
      "max_distance",
      "symmetric"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_bucket_relative_position": [
      "self",
      "relative_position"
    ]
  },
  "AbsolutePositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate",
      "max_len"
    ],
    "extend_pe": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MeanVarianceNormLayer": {
    "__init__": [
      "self",
      "input_size"
    ],
    "forward": [
      "self",
      "input_"
    ]
  },
  "CausalConv1D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "padding_mode",
      "device",
      "dtype"
    ],
    "update_cache": [
      "self",
      "x",
      "cache"
    ],
    "forward": [
      "self",
      "x",
      "cache"
    ]
  },
  "CausalConv2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "padding_mode",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NemoConvSubsampling": {
    "__init__": [
      "self",
      "feat_in",
      "feat_out",
      "subsampling_factor",
      "subsampling",
      "conv_channels",
      "subsampling_conv_chunking_factor",
      "activation",
      "is_causal"
    ],
    "get_sampling_frames": [
      "self"
    ],
    "get_streaming_cache_size": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ],
    "reset_parameters": [
      "self"
    ],
    "conv_split_by_batch": [
      "self",
      "x"
    ],
    "conv_split_by_channel": [
      "self",
      "x"
    ],
    "channel_chunked_conv": [
      "self",
      "conv",
      "chunk_size",
      "x"
    ],
    "change_subsampling_conv_chunking_factor": [
      "self",
      "subsampling_conv_chunking_factor"
    ]
  },
  "calc_length": [
    "lengths",
    "all_paddings",
    "kernel_size",
    "stride",
    "ceil_mode",
    "repeat_num"
  ],
  "AttModule": {
    "__init__": [
      "self"
    ],
    "set_export": [
      "self",
      "mode"
    ],
    "forward": [
      "self",
      "x",
      "memory",
      "pos_emb",
      "att_mask"
    ]
  },
  "AttBlock": {
    "memory_dims": [
      "self",
      "max_len"
    ]
  },
  "masked_softmax": [
    "scores",
    "mask"
  ],
  "MultiHeadedAttention": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "dropout_rate",
      "attention_inner_dim",
      "glu_type",
      "bias_in_glu",
      "use_pt_scaled_dot_product_attention",
      "n_value",
      "group_size"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "pos_k",
      "pos_v",
      "mask",
      "relative_attention_bias"
    ]
  },
  "MultiSequential": {
    "forward": [
      "self"
    ]
  },
  "get_offset": [
    "input_layer",
    "time_reduction"
  ],
  "unfold_tensor": [
    "xs_pad",
    "max_seq_len"
  ],
  "BloomAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "BloomMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BloomBlock": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "BloomModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BloomForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Plamo2Config": {},
  "is_mamba": [
    "config",
    "i"
  ],
  "Plamo2MambaMixer": {
    "__init__": [
      "self",
      "vllm_config"
    ],
    "_project_ssm_parameters": [
      "self",
      "hidden_states"
    ],
    "forward_native": [
      "self",
      "hidden_states",
      "output"
    ],
    "forward": [
      "self",
      "hidden_states",
      "output"
    ],
    "forward_cuda": [
      "self",
      "hidden_states",
      "output"
    ],
    "get_state_dtype": [
      "self"
    ],
    "get_state_shape": [
      "self"
    ],
    "mamba_type": [
      "self"
    ]
  },
  "plamo2_mamba_mixer": [
    "hidden_states",
    "output",
    "layer_name"
  ],
  "plamo2_mamba_mixer_fake": [
    "hidden_states",
    "output",
    "layer_name"
  ],
  "Plamo2AttentionMixer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Plamo2DecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "layer_idx",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Plamo2Decoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Plamo2Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "Plamo2ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "JinaVLScorer": {
    "__init__": [
      "self",
      "model_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "JinaVLMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ]
  },
  "JinaVLForSequenceClassification": {
    "is_pooling_model": [],
    "weight_mapper": [],
    "__init__": [
      "self"
    ],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "get_score_template": [
      "cls",
      "query",
      "document"
    ],
    "post_process_tokens": [
      "cls",
      "prompt"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_DEFAULT_NORM_LAYER": [],
  "rotate_half": [
    "x"
  ],
  "apply_rotary_emb": [
    "freqs",
    "t",
    "start_index",
    "scale",
    "seq_dim"
  ],
  "PerceptionEncoderRope2D": {
    "__init__": [
      "self",
      "dim",
      "max_grid_height",
      "max_grid_width",
      "use_cls_token",
      "theta",
      "max_freq",
      "num_freqs",
      "theta_rescale_factor"
    ],
    "_compute_inv_freq": [
      "self",
      "base",
      "dim"
    ],
    "_compute_freqs": [
      "self",
      "t",
      "inv_freq"
    ],
    "_compute_2d_freqs": [
      "self"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "grid_hw"
    ]
  },
  "PerceptionEncoderLayerScale": {
    "__init__": [
      "self",
      "dim",
      "init_values",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PerceptionEncoderMLP": {
    "__init__": [
      "self",
      "input_dim",
      "hidden_dim",
      "act_layer",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PerceptionEncoderVisionAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "max_grid_height",
      "max_grid_width",
      "use_cls_token",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "x",
      "grid_hw"
    ]
  },
  "PerceptionEncoderVisionBlock": {
    "__init__": [
      "self",
      "d_model",
      "n_head",
      "max_grid_height",
      "max_grid_width",
      "mlp_ratio",
      "ls_init_value",
      "act_layer",
      "norm_layer",
      "use_cls_token",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "x",
      "grid_hw"
    ]
  },
  "PerceptionEncoderVisionTransformer": {
    "__init__": [
      "self",
      "width",
      "layers",
      "heads",
      "max_grid_height",
      "max_grid_width",
      "mlp_ratio",
      "ls_init_value",
      "act_layer",
      "norm_layer",
      "use_cls_token",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "x",
      "grid_hw"
    ]
  },
  "PerceptionEncoder": {
    "__init__": [
      "self",
      "config",
      "act_layer",
      "norm_layer",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "sample_abs_posemb": [
      "self",
      "grid_h",
      "grid_w"
    ],
    "forward_features": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StepVLForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self"
    ],
    "_get_vision_model_output": [
      "self",
      "input_tensor"
    ],
    "_process_image_features": [
      "self",
      "image_features"
    ]
  },
  "Qwen3NextMultiTokenPredictor": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "intermediate_tensors",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3NextMTP": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "calculate_nemotron_vl_targets": [],
  "dynamic_preprocess_nemotron_vl": [
    "image"
  ],
  "get_nemotron_vl_target_ratios": [
    "min_num",
    "max_num"
  ],
  "image_to_pixel_values_nemotron_vl": [
    "image"
  ],
  "NemotronVLProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer",
      "image_processor"
    ],
    "image_token_id": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "_images_to_pixel_values_lst": [
      "self",
      "images",
      "min_dynamic_patch",
      "max_dynamic_patch",
      "dynamic_image_size"
    ],
    "_preprocess_image": [
      "self",
      "text",
      "images",
      "min_dynamic_patch",
      "max_dynamic_patch",
      "dynamic_image_size"
    ],
    "get_image_repl": [
      "self",
      "feature_size",
      "num_patches"
    ]
  },
  "NemotronVLProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ]
  },
  "LlamaNemotronVLChatModel": {
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_patch_quant_config": [
      "self",
      "config",
      "quant_config"
    ],
    "_init_vision_model": [
      "self",
      "config",
      "quant_config"
    ],
    "_init_mlp1": [
      "self",
      "config"
    ],
    "pixel_shuffle": [
      "self",
      "x",
      "scale_factor"
    ],
    "extract_feature": [
      "self",
      "pixel_values"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "_set_visual_token_mask": [
      "self",
      "input_ids"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "SQRT2": [],
  "MLPSpeculatorLayerNorm": {
    "__init__": [
      "self",
      "normalized_shape",
      "eps",
      "elementwise_scale_and_shift"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MLPSpeculator": {
    "__init__": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "TarsierImagePixelInputs": {},
  "TarsierImageEmbeddingInputs": {},
  "TarsierHfConfig": {},
  "TarsierProcessorKwargs": {
    "_defaults": []
  },
  "TarsierProcessor": {
    "__call__": [
      "self",
      "images",
      "text",
      "audio",
      "videos"
    ]
  },
  "TarsierMultiModalProjector": {
    "__init__": [
      "self",
      "vision_hidden_size",
      "text_hidden_size",
      "projector_hidden_act",
      "multimodal_projector_bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "TarsierProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_vision_encoder_info": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_max_image_tokens": [
      "self"
    ],
    "get_image_newline_idx": [
      "self"
    ],
    "get_image_new_idx": [
      "self"
    ]
  },
  "_I_Tarsier": [],
  "TarsierDummyInputsBuilder": {},
  "TarsierMultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "_build_tarsier_hf_info": [
    "ctx"
  ],
  "_build_tarsier_hf_processor": [
    "info",
    "dummy_inputs"
  ],
  "init_vision_tower_for_tarsier": [
    "hf_config",
    "quant_config"
  ],
  "TarsierForConditionalGeneration": {
    "packed_modules_mapping": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_image_pixels_to_features": [
      "self",
      "vision_tower",
      "pixel_values"
    ],
    "_add_tarsier_split_tokens": [
      "self",
      "projected_image_features"
    ],
    "_process_image_pixels": [
      "self",
      "inputs"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_parameters",
      "max_position",
      "head_dim",
      "rms_norm_eps",
      "qkv_bias",
      "cache_config",
      "quant_config",
      "prefix",
      "attn_type",
      "dual_chunk_attention_config"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Qwen3DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Qwen3Model": {
    "__init__": [
      "self"
    ]
  },
  "Qwen3ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Ernie4_5_VLMoeMLP": {
    "__init__": [
      "self",
      "shared_experts"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Ernie4_5_VLMoeAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_parameters",
      "head_dim",
      "freq_allocation",
      "max_position_embeddings",
      "rms_norm_eps",
      "qkv_bias",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Ernie4_5_VLMoeMoE": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "visual_token_mask"
    ]
  },
  "Ernie4_5_VLMoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual",
      "visual_token_mask"
    ]
  },
  "Ernie4_5_VLMoeModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds",
      "visual_token_mask"
    ]
  },
  "Ernie4_5_VLMoeForCausalLM": {
    "packed_modules_mapping": [],
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "OpenPanguMultiTokenPredictorLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ]
  },
  "OpenPanguMultiTokenPredictor": {
    "__init__": [
      "self"
    ]
  },
  "OpenPanguMTP": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "intermediate_tensors",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ],
    "get_spec_layer": [
      "self",
      "name"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_rewrite_spec_layer_name": [
      "self",
      "spec_layer",
      "name"
    ]
  },
  "Lfm2MLP": {
    "__init__": [
      "self",
      "dim",
      "ff_dim",
      "multiple_of",
      "auto_adjust_ff_dim",
      "ffn_dim_multiplier",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Lfm2Attention": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Lfm2AttentionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Lfm2ShortConvDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "model_config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "Lfm2Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Lfm2ForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "get_mamba_state_dtype_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_shape_from_config": [
      "cls",
      "vllm_config"
    ],
    "get_mamba_state_copy_func": [
      "cls"
    ],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "IMAGE_PROMPT": [],
  "VIDEO_PROMPT": [],
  "_MAX_VIDEO_FPS": [],
  "Molmo2ImageInputs": {},
  "Molmo2VideoInputs": {},
  "VitConfig": {
    "__post_init__": [
      "self"
    ],
    "image_num_patch": [
      "self"
    ]
  },
  "AdapterConfig": {},
  "TextConfig": {},
  "ViTMLP": {
    "__init__": [
      "self",
      "dim",
      "hidden_dim",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ViTMultiHeadDotProductAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_key_value_heads",
      "head_dim",
      "use_bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "Molmo2VisionBlock": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Molmo2VisionBlockCollection": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Molmo2VisionTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "add_pos_emb": [
      "self",
      "x",
      "patch_num"
    ],
    "forward": [
      "self",
      "x",
      "patch_num"
    ]
  },
  "ImagePoolingAttention": {
    "__init__": [
      "self",
      "input_dim",
      "hidden_size",
      "num_heads",
      "num_key_value_heads",
      "head_dim",
      "use_bias",
      "use_pytorch_sdpa",
      "quant_config",
      "prefix"
    ],
    "forward_sdpa": [
      "self",
      "query",
      "key",
      "value",
      "attn_mask"
    ],
    "forward": [
      "self",
      "inputs_q",
      "inputs_kv",
      "attn_mask"
    ]
  },
  "ImageProjectorMLP": {
    "__init__": [
      "self",
      "input_dim",
      "hidden_dim",
      "output_dim",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Molmo2VisionBackbone": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "vit_config",
      "adapter_config",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "encode_image": [
      "self",
      "images"
    ],
    "forward": [
      "self",
      "images",
      "token_pooling"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Molmo2Attention": {
    "__init__": [
      "self",
      "config",
      "rope_parameters",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "_apply_qk_norm": [
      "self",
      "q",
      "k"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "LanguageModelMLP": {
    "__init__": [
      "self",
      "input_dim",
      "intermediate_size",
      "hidden_act",
      "quant_config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Molmo2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "rope_parameters",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Molmo2DecoderNormAfterLayer": {
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Molmo2TextModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "get_patches_grid_size": [],
  "get_candidate_tilings": [
    "max_num"
  ],
  "select_tiling": [],
  "get_image_size": [
    "image"
  ],
  "exif_tranpose": [
    "images"
  ],
  "build_flat_image_bool_length": [
    "image_grids",
    "image_patch_id",
    "low_res_image_start_id",
    "image_start_id",
    "image_col_id",
    "image_end_id"
  ],
  "build_flat_video_bool_length": [
    "video_grids",
    "image_patch_id",
    "frame_start_id",
    "frame_end_id"
  ],
  "Molmo2ProcessorWrapper": {
    "__init__": [
      "self",
      "processor",
      "hf_config"
    ],
    "vocab": [
      "self"
    ],
    "max_crops": [
      "self"
    ],
    "image_pooling_h": [
      "self"
    ],
    "image_pooling_w": [
      "self"
    ],
    "video_pooling_h": [
      "self"
    ],
    "video_pooling_w": [
      "self"
    ],
    "base_image_input_size": [
      "self"
    ],
    "image_patch_size": [
      "self"
    ],
    "overlap_margins": [
      "self"
    ],
    "bos_token": [
      "self"
    ],
    "image_patch_id": [
      "self"
    ],
    "im_col_id": [
      "self"
    ],
    "im_start_id": [
      "self"
    ],
    "im_end_id": [
      "self"
    ],
    "low_res_im_start_id": [
      "self"
    ],
    "frame_start_id": [
      "self"
    ],
    "frame_end_id": [
      "self"
    ],
    "im_low_res_id": [
      "self"
    ],
    "image_placeholder_id": [
      "self"
    ],
    "video_placeholder_id": [
      "self"
    ],
    "image_token_ids": [
      "self"
    ],
    "select_tiling": [
      "self"
    ],
    "get_base_grid_size": [
      "self",
      "is_video"
    ],
    "get_patches_grid_size": [
      "self"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "videos",
      "return_tensors"
    ]
  },
  "get_candidate_target_fps": [
    "video_fps",
    "sampling_fps",
    "max_fps"
  ],
  "get_target_fps": [
    "video_fps",
    "max_frames",
    "total_frames",
    "frame_sample_mode",
    "candidate_target_fps"
  ],
  "get_frame_times_and_chosen_fps": [
    "selected_target_fps",
    "total_frames",
    "max_frames",
    "video_fps"
  ],
  "Molmo2ProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_num_video_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "_get_max_video_frames": [
      "self",
      "max_tokens"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "_sample_frames": [
      "self",
      "total_num_frames",
      "video_fps",
      "duration",
      "frame_sample_mode",
      "num_frames",
      "max_fps",
      "sampling_fps"
    ],
    "_get_video_second_idx": [
      "self",
      "metadata",
      "do_sample_frames"
    ]
  },
  "Molmo2DummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ],
    "_get_dummy_videos": [
      "self"
    ]
  },
  "Molmo2MultiModalProcessor": {
    "_apply_hf_processor_tokens_only": [
      "self",
      "prompt_tokens"
    ],
    "_get_data_parser": [
      "self"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Molmo2ForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "packed_modules_mapping": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_process_video_input": [
      "self",
      "video_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "_get_weights_with_merged_embedding": [
    "weights"
  ],
  "_NEWLINE_TOKEN_ID": [],
  "FuyuImagePatchInputs": {},
  "FuyuProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_image_feature_grid_size": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "FuyuDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "FuyuMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_apply_hf_processor_tokens_only": [
      "self",
      "prompt_tokens"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "FuyuForCausalLM": {
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "FalconAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "FalconMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FalconDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "FalconModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "FalconForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "resolve_h2ovl_min_max_num": [],
  "get_h2ovl_target_ratios": [
    "min_num",
    "max_num"
  ],
  "calculate_h2ovl_targets": [],
  "dynamic_preprocess_h2ovl": [
    "image"
  ],
  "_preprocess_image": [
    "image"
  ],
  "image_to_pixel_values_h2ovl": [
    "image"
  ],
  "H2OVLProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "image_token_id": [
      "self"
    ],
    "get_image_repl": [
      "self",
      "feature_size",
      "num_patches"
    ],
    "resolve_min_max_num": [
      "self"
    ],
    "resolve_target_ratios": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "_images_to_pixel_values_lst": [
      "self",
      "images",
      "min_dynamic_patch",
      "max_dynamic_patch",
      "dynamic_image_size"
    ]
  },
  "H2OVLProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ]
  },
  "H2OVLMultiModalProcessor": {
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_cached_apply_hf_processor": [
      "self",
      "prompt",
      "mm_data_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs",
      "mm_uuids"
    ]
  },
  "H2OVLChatModel": {
    "_init_vision_model": [
      "self",
      "config",
      "quant_config"
    ]
  },
  "PersimmonMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "PersimmonAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "_split_heads": [
      "self",
      "x"
    ],
    "_merge_heads": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "PersimmonDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "PersimmonModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "PersimmonForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "get_rope_shape_decorate": [
    "func"
  ],
  "get_rope_shape": [
    "org",
    "interpolation_mode",
    "shape"
  ],
  "get_1d_sincos_pos_embed": [
    "embed_dim",
    "t_size",
    "cls_token"
  ],
  "Learnable2DInterpPosEmbDivided_fixed": {
    "__init__": [
      "self",
      "height",
      "width",
      "num_frames",
      "dim",
      "interpolation_mode"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "grid_thws"
    ]
  },
  "MoonVision3dPatchEmbed": {
    "__init__": [
      "self",
      "out_dim",
      "in_dim",
      "patch_size",
      "pos_emb_height",
      "pos_emb_width",
      "pos_emb_time",
      "pos_emb_type"
    ],
    "forward": [
      "self",
      "x",
      "grid_thws"
    ]
  },
  "Rope2DPosEmbRepeated": {
    "__init__": [
      "self",
      "dim",
      "max_height",
      "max_width",
      "theta_base"
    ],
    "extra_repr": [
      "self"
    ],
    "_precompute_freqs_cis": [
      "self",
      "device"
    ],
    "get_freqs_cis": [
      "self",
      "grid_thws",
      "device"
    ]
  },
  "MoonViTEncoderLayer": {
    "__init__": [
      "self",
      "num_heads",
      "hidden_dim",
      "mlp_dim",
      "prefix"
    ],
    "attention_qkvpacked": [
      "self",
      "x",
      "cu_seqlens",
      "rope_freqs_cis"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rope_freqs_cis"
    ]
  },
  "MoonViT3dEncoder": {
    "__init__": [
      "self",
      "hidden_dim",
      "num_layers",
      "block_cfg",
      "video_attn_type",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "grid_thws"
    ]
  },
  "tpool_patch_merger": [
    "x",
    "grid_thws",
    "merge_kernel_size"
  ],
  "MoonViT3dPretrainedModel": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "pixel_values",
      "grid_thws"
    ]
  },
  "mm_projector_forward": [
    "mm_projector",
    "vt_output"
  ],
  "vision_tower_forward": [
    "vision_tower",
    "pixel_values",
    "grid_thw",
    "mm_projector",
    "use_data_parallel"
  ],
  "KimiK25MultiModalProjector": {
    "__init__": [
      "self",
      "config",
      "use_data_parallel",
      "prefix"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "_AUDIO_PLACEHOLDER_OVERRIDE": [],
  "_MAX_ENCODER_BATCH_SIZE": [],
  "UltravoxAudioFeatureInputs": {},
  "UltravoxAudioEmbeddingInputs": {},
  "UltravoxProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "get_feature_extractor": [
      "self"
    ],
    "get_target_channels": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ]
  },
  "UltravoxDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "UltravoxMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "StackAudioFrames": {
    "__init__": [
      "self",
      "stack_factor"
    ],
    "forward": [
      "self",
      "audio_embeds"
    ]
  },
  "UltravoxFeedForwardProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "audio_features",
      "audio_token_len"
    ]
  },
  "UltravoxTransformerProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "audio_features",
      "audio_token_len"
    ]
  },
  "ModifiedWhisperEncoder": {
    "base_model_prefix": [],
    "__init__": [
      "self"
    ],
    "max_context_length": [
      "self"
    ],
    "get_attention_mask_by_audio_len": [
      "self",
      "audio_lens",
      "hidden_states"
    ],
    "forward": [
      "self",
      "input_features",
      "audio_lens"
    ]
  },
  "UltravoxModel": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "_audio_features_to_embeddings": [
      "self",
      "input_features",
      "audio_lens",
      "audio_token_len"
    ],
    "_parse_and_validate_audio_input": [
      "self"
    ],
    "_process_audio_input": [
      "self",
      "audio_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "pad_and_concat_to_dim3": [
    "features"
  ],
  "BailingAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids"
    ]
  },
  "BailingMLP": {
    "__init__": [
      "self",
      "intermediate_size",
      "config",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BailingMoE": {
    "__init__": [
      "self",
      "intermediate_size",
      "config",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BailingMoeBlock": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "residual"
    ]
  },
  "BailingMoeModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BailingMoeForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "BailingMoeV2ForCausalLM": {},
  "Qwen2AudioFeatureInputs": {},
  "Qwen2AudioEmbeddingInputs": {},
  "Qwen2AudioMultiModalProjector": {
    "__init__": [
      "self",
      "audio_hidden_size",
      "text_hidden_size"
    ],
    "forward": [
      "self",
      "audio_features"
    ]
  },
  "Qwen2AudioProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_feature_extractor": [
      "self"
    ],
    "get_target_channels": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ]
  },
  "Qwen2AudioDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "_qwen2audio_field_config": [
    "hf_inputs"
  ],
  "Qwen2AudioMultiModalDataParser": {
    "_parse_audio_data": [
      "self",
      "data"
    ]
  },
  "Qwen2AudioMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Qwen2AudioForConditionalGeneration": {
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_audio_input": [
      "self"
    ],
    "_process_audio_input": [
      "self",
      "audio_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "create_cumulative_seq_lengths": [
    "seq_sizes",
    "device"
  ],
  "Siglip2VariableSequenceEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "positional_embeddings": [
      "self",
      "packed_seq_patches"
    ],
    "forward": [
      "self",
      "packed_seq_patches"
    ]
  },
  "create_pixel_shuffle_index_map": [
    "seq_sizes",
    "token_grids",
    "scale_factor",
    "device"
  ],
  "pixel_shuffle_varlen": [
    "x",
    "token_grids",
    "scale_factor"
  ],
  "MAX_PIXELS": [],
  "VISION_MEAN": [],
  "VISION_STD": [],
  "VISION_SCALE": [],
  "_make_writeable": [
    "arr"
  ],
  "extract_image_pil": [
    "image"
  ],
  "get_image_size_for_max_num_patches": [
    "image_height",
    "image_width",
    "patch_size",
    "max_num_patches",
    "min_num_patches",
    "eps",
    "pixel_shuffle_scale"
  ],
  "_MEAN_TENSOR": [],
  "_STD_TENSOR": [],
  "_resolve_vision_token_id": [
    "model_config",
    "vision_token"
  ],
  "prepare_image_tensor": [
    "image",
    "scale"
  ],
  "patchify_vision": [
    "image",
    "patch_size"
  ],
  "process_vision_for_patches": [
    "images",
    "patch_size",
    "max_num_patches",
    "min_num_patches",
    "pixel_shuffle_scale"
  ],
  "IsaacImageProcessorKwargs": {},
  "IsaacImageProcessor": {
    "patch_size": [],
    "max_num_patches": [],
    "min_num_patches": [],
    "pixel_shuffle_scale": [],
    "valid_kwargs": [],
    "model_input_names": [],
    "__init__": [
      "self",
      "kwargs"
    ],
    "preprocess": [
      "self",
      "images",
      "return_tensors"
    ]
  },
  "IsaacProcessor": {
    "__init__": [
      "self",
      "image_processor",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "text",
      "images"
    ],
    "apply_chat_template": [
      "self",
      "messages",
      "tokenize",
      "add_generation_prompt"
    ]
  },
  "IsaacProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_tokenizer": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_mm_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ]
  },
  "IsaacDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "IsaacImagePixelInputs": {},
  "IsaacMultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Siglip2VisionAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "split_qkv": [
      "self",
      "qkv"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "IsaacVisionEmbedding": {
    "__init__": [
      "self",
      "vision_cfg",
      "hidden_dim",
      "output_dim",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "packed_seq_patches"
    ]
  },
  "IsaacForConditionalGeneration": {
    "packed_modules_mapping": [],
    "supports_encoder_tp_data": [],
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "iter_mm_grid_hw": [
      "self",
      "input_tokens",
      "mm_features"
    ],
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "_terratorch_field_names": [
    "input_definition"
  ],
  "_terratorch_field_factory": [
    "input_definition"
  ],
  "TerratorchProcessingInfo": {
    "get_supported_mm_limits": [
      "self"
    ]
  },
  "TerratorchInputBuilder": {
    "__init__": [
      "self",
      "info"
    ],
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "TerratorchMultiModalDataParser": {
    "__init__": [
      "self",
      "input_definition"
    ],
    "_parse_image_data": [
      "self",
      "data"
    ],
    "parse_mm_data": [
      "self",
      "mm_data"
    ]
  },
  "TerratorchMultiModalProcessor": {
    "__init__": [
      "self",
      "info",
      "dummy_inputs"
    ],
    "_get_data_parser": [
      "self"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "apply": [
      "self",
      "prompt",
      "mm_data",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs",
      "mm_uuids"
    ]
  },
  "Terratorch": {
    "supports_multimodal_raw_input_only": [],
    "is_pooling_model": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "EOT": [],
  "get_num_combined_frames": [
    "num_frames",
    "max_grid_shape"
  ],
  "HCXVisionImagePixelInputs": {},
  "HCXVisionImageInputs": [],
  "HCXVisionVideoPixelInputs": {},
  "HCXVisionVideoInputs": [],
  "HCXVisionProcessingInfo": {
    "get_vision_encoder_info": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_num_video_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_max_image_tokens": [
      "self"
    ]
  },
  "HCXVisionDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "HCXVisionMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_hf_processor_applies_updates": [
      "self",
      "prompt_text",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "_build_hcxvision_hf_info": [
    "ctx"
  ],
  "_build_hcxvision_hf_processor": [
    "info",
    "dummy_inputs"
  ],
  "init_vision_tower_for_hcxvision": [
    "vision_config",
    "quant_config"
  ],
  "HCXVisionMlp": {
    "__init__": [
      "self",
      "mm_projector_type",
      "in_features",
      "hidden_features",
      "out_features",
      "act_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HCXVisionCAbstractor": {
    "__init__": [
      "self",
      "num_queries",
      "num_input_tokens",
      "encoder_hidden_size",
      "hidden_size",
      "output_hidden_size",
      "pos_emb",
      "prenorm"
    ],
    "forward": [
      "self",
      "x",
      "num_queries_vis_abstractors",
      "num_grids"
    ],
    "_forward": [
      "self",
      "x",
      "num_queries_vis_abstractors",
      "num_grids"
    ],
    "_forward_adaptive_num_query": [
      "self",
      "x",
      "num_queries_vis_abstractors",
      "num_grids"
    ],
    "build_net": [
      "self",
      "n_queries",
      "encoder_hidden_size",
      "hidden_size",
      "output_hidden_size",
      "depth",
      "mlp_depth"
    ],
    "build_mlp": [
      "self",
      "depth",
      "hidden_size",
      "output_hidden_size"
    ]
  },
  "HCXVisionForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_process_video_input": [
      "self",
      "video_input"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "forward_images": [
      "self",
      "pixel_values_images",
      "image_sizes_images"
    ],
    "forward_videos": [
      "self",
      "pixel_values_videos"
    ],
    "_prepare_multimodal_kwargs": [
      "self"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_init_possible_resolutions": [
      "self",
      "config",
      "vision_config"
    ],
    "_init_mm_projector": [
      "self",
      "config",
      "text_config",
      "vision_config"
    ]
  },
  "unpad_image": [
    "tensor",
    "original_size"
  ],
  "select_best_resolution": [
    "original_size",
    "possible_resolutions"
  ],
  "get_anyres_image_grid_shape": [
    "image_size",
    "grid_pinpoints",
    "patch_size"
  ],
  "reshape_and_unpad_image_features": [
    "image_feature",
    "height",
    "width",
    "image_size",
    "possible_resolutions",
    "grid_size",
    "unpad",
    "image_newline"
  ],
  "anyres_postprocessing": [
    "image_forward_outs",
    "image_sizes",
    "possible_resolutions",
    "patch_size",
    "grid_size",
    "image_newline",
    "num_queries_vis_abstractor",
    "unpad"
  ],
  "RobertaEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "RobertaClassificationHead": {
    "__init__": [
      "self",
      "model_config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RobertaEmbeddingModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "_build_model": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "filter_secondary_weights": [
    "all_weights",
    "secondary_weights"
  ],
  "BgeM3EmbeddingModel": {
    "__init__": [
      "self"
    ],
    "_build_pooler": [
      "self",
      "pooler_config"
    ],
    "load_weights": [
      "self",
      "all_weights"
    ]
  },
  "RobertaForSequenceClassification": {
    "is_pooling_model": [],
    "jina_to_vllm_mapper": [],
    "__init__": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds",
      "token_type_ids"
    ]
  },
  "replace_roberta_positions": [
    "input_ids",
    "position_ids",
    "padding_idx"
  ],
  "IMAGE_INDICATOR_IDS": [],
  "st_argmax": [
    "y_soft",
    "dim"
  ],
  "OvisImagePatchInputs": {},
  "VisualEmbedding": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "visual_tokens"
    ],
    "device": [
      "self"
    ],
    "dtype": [
      "self"
    ]
  },
  "OvisProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "get_image_segment_len": [
      "self"
    ],
    "get_image_pad_token": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "OvisDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "OvisMultiModalProcessor": {
    "image_indicators_to_visual_tokens": [
      "self",
      "image_indicators"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_apply_hf_processor_tokens_only": [
      "self",
      "prompt_tokens"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "Ovis": {
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "TOKENS_PER_IMAGE": [],
  "TOKENS_PER_AUDIO": [],
  "Gemma3nImagePixelInputs": {},
  "Gemma3nAudioInputs": {},
  "Gemma3nImageInputs": [],
  "Gemma3nProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "get_image_repl": [
      "self"
    ],
    "get_audio_repl": [
      "self"
    ]
  },
  "Gemma3nDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Gemma3nMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_apply_token_matches": [
      "self",
      "prompt",
      "mm_prompt_updates"
    ],
    "_find_mm_placeholders": [
      "self",
      "new_token_ids",
      "mm_prompt_updates"
    ]
  },
  "Gemma3nMultimodalEmbedder": {
    "__init__": [
      "self",
      "multimodal_config",
      "text_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds"
    ]
  },
  "Gemma3nForConditionalGeneration": {
    "supported_languages": [],
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_audio_input": [
      "self"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_process_audio_input": [
      "self",
      "audio_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "get_generation_prompt": [
      "cls",
      "audio",
      "stt_config",
      "model_config",
      "language",
      "task_type",
      "request_prompt",
      "to_language"
    ],
    "get_speech_to_text_config": [
      "cls",
      "model_config",
      "task_type"
    ]
  },
  "GlmForCausalLM": {
    "__init__": [
      "self"
    ]
  },
  "Qwen2VLImagePixelInputs": {},
  "Qwen2VLImageEmbeddingInputs": {},
  "Qwen2VLVideoPixelInputs": {},
  "Qwen2VLVideoEmbeddingInputs": {},
  "Qwen2VisionMLP": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "act_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2VisionAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "projection_size",
      "quant_config",
      "prefix"
    ],
    "split_qkv": [
      "self",
      "qkv"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin",
      "max_seqlen"
    ]
  },
  "Qwen2VisionBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "act_layer",
      "norm_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin",
      "max_seqlen"
    ]
  },
  "Qwen2VisionPatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "temporal_patch_size",
      "in_channels",
      "embed_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2VisionPatchMerger": {
    "__init__": [
      "self",
      "d_model",
      "context_dim",
      "norm_layer",
      "spatial_merge_size",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2VisionTransformer": {
    "__init__": [
      "self",
      "vision_config",
      "norm_eps",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "compute_attn_mask_seqlen": [
      "self",
      "cu_seqlens"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_create_qwen2vl_field_factory": [
    "spatial_merge_size"
  ],
  "Qwen2VLMultiModalDataParser": {
    "__init__": [
      "self",
      "spatial_merge_size"
    ],
    "_parse_image_data": [
      "self",
      "data"
    ],
    "_parse_video_data": [
      "self",
      "data"
    ]
  },
  "Qwen2VLProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_mm_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "_get_vision_info": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_num_video_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self",
      "max_pixels"
    ],
    "get_max_image_tokens": [
      "self"
    ],
    "_get_max_video_frames": [
      "self",
      "max_tokens",
      "start_num_frames"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len",
      "mm_counts",
      "max_frames_per_video"
    ],
    "get_max_video_tokens": [
      "self",
      "seq_len",
      "mm_counts"
    ]
  },
  "Qwen2VLDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Qwen2VLMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "Qwen2VLForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "supports_encoder_tp_data": [],
    "iter_mm_grid_thw": [
      "self",
      "mm_features"
    ],
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_process_video_input": [
      "self",
      "video_input"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "get_num_mm_encoder_tokens": [
      "self",
      "num_image_tokens"
    ],
    "get_num_mm_connector_tokens": [
      "self",
      "num_vision_tokens"
    ]
  },
  "Tarsier2MultiModalProcessor": {},
  "Tarsier2ImageProcessor": {
    "__init__": [
      "self",
      "size"
    ]
  },
  "Tarsier2Processor": {
    "__init__": [
      "self",
      "vision_config",
      "tokenizer"
    ]
  },
  "Tarsier2ProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ]
  },
  "Tarsier2ForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "split_thw": [
    "grid_thw"
  ],
  "get_num_patches": [
    "grid_thw",
    "num_frames"
  ],
  "KeyeVL1_5ImagePixelInputs": {},
  "KeyeVL1_5ImageEmbeddingInputs": {},
  "KeyeVL1_5VideoPixelInputs": {},
  "KeyeVL1_5VideoEmbeddingInputs": {},
  "KeyeVL1_5Projector": {
    "__init__": [
      "self",
      "text_config",
      "vision_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "image_features",
      "image_grid_thw"
    ]
  },
  "KeyeVL1_5ProcessingInfo": {
    "get_max_frame_per_video": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ]
  },
  "KeyeVL1_5MultiModalDataParser": {
    "_parse_image_data": [
      "self",
      "data"
    ],
    "_parse_video_data": [
      "self",
      "data"
    ]
  },
  "KeyeVL1_5MultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "KeyeVL1_5DummyInputsBuilder": {},
  "KeyeVL1_5ForConditionalGeneration": {
    "_build_projector": [
      "self",
      "text_config",
      "vision_config",
      "quant_config",
      "prefix"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_process_video_input": [
      "self",
      "video_input"
    ],
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ]
  },
  "Eagle3LlamaForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings",
      "is_multimodal"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "combine_hidden_states": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiniMaxVL01ImagePixelInputs": {},
  "MiniMaxVL01ImageEmbeddingInputs": {},
  "MiniMaxVL01MultiModalProjector": {
    "__init__": [
      "self",
      "vision_hidden_size",
      "text_hidden_size",
      "projector_hidden_act",
      "multimodal_projector_bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "MiniMaxVL01DummyInputsBuilder": {},
  "MiniMaxVL01ProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ]
  },
  "MiniMaxVL01MultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "MiniMaxVL01ForConditionalGeneration": {
    "packed_modules_mapping": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_image_pixels_to_features": [
      "self",
      "vision_tower",
      "pixel_values"
    ],
    "pack_image_features": [
      "self",
      "image_features",
      "image_sizes"
    ],
    "_process_image_pixels": [
      "self",
      "inputs"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "apply_rotary_pos_emb": [
    "q",
    "k",
    "cos",
    "sin",
    "is_flash_attn_backend",
    "apply_rotary_emb"
  ],
  "Siglip2NavitModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "pixel_values",
      "grid_thws"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DEFAULT_FINAL_IMAGE_SIZE": [],
  "BartScaledWordEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "embed_scale"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "BartParallelLMHead": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "embed_scale"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "BartDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "decoder_hidden_states",
      "encoder_hidden_states"
    ]
  },
  "MBartDecoderLayer": {
    "forward": [
      "self",
      "decoder_hidden_states",
      "encoder_hidden_states"
    ]
  },
  "MBartDecoderNoPos": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "lora_config",
      "embed_tokens",
      "prefix"
    ],
    "forward": [
      "self",
      "decoder_input_ids"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "NemotronParsePixelInputs": {},
  "NemotronParseImageProcessor": {
    "__init__": [
      "self",
      "final_size"
    ],
    "_create_transforms": [
      "self"
    ],
    "_resize_with_aspect_ratio": [
      "self",
      "image"
    ],
    "_pad_to_size": [
      "self",
      "image"
    ],
    "preprocess": [
      "self",
      "images"
    ],
    "__call__": [
      "self",
      "images"
    ]
  },
  "NemotronParseProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "_make_batch_input": [
      "self",
      "input_item"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "return_tensors"
    ]
  },
  "NemotronParseProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "skip_prompt_length_check": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_mm_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ]
  },
  "NemotronParseDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "NemotronParseMultiModalProcessor": {
    "create_encoder_prompt": [
      "self",
      "prompt",
      "mm_data"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "RadioWithNeck": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_vit_model_from_radio_config": [
      "self",
      "hf_config",
      "quant_config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "NemotronParseForConditionalGeneration": {
    "__init__": [
      "self"
    ],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "encoder_outputs"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_TEXT_GENERATION_MODELS": [],
  "_EMBEDDING_MODELS": [],
  "_CROSS_ENCODER_MODELS": [],
  "_MULTIMODAL_MODELS": [],
  "_SPECULATIVE_DECODING_MODELS": [],
  "_TRANSFORMERS_SUPPORTED_MODELS": [],
  "_TRANSFORMERS_BACKEND_MODELS": [],
  "_VLLM_MODELS": [],
  "_SUBPROCESS_COMMAND": [],
  "_PREVIOUSLY_SUPPORTED_MODELS": [],
  "_ModelInfo": {
    "from_model_cls": [
      "model"
    ]
  },
  "_BaseRegisteredModel": {
    "inspect_model_cls": [
      "self"
    ],
    "load_model_cls": [
      "self"
    ]
  },
  "_RegisteredModel": {
    "from_model_cls": [
      "model_cls"
    ],
    "inspect_model_cls": [
      "self"
    ],
    "load_model_cls": [
      "self"
    ]
  },
  "_LazyRegisteredModel": {
    "_get_cache_dir": [],
    "_get_cache_filename": [
      "self"
    ],
    "_load_modelinfo_from_cache": [
      "self",
      "module_hash"
    ],
    "_save_modelinfo_to_cache": [
      "self",
      "mi",
      "module_hash"
    ],
    "inspect_model_cls": [
      "self"
    ],
    "load_model_cls": [
      "self"
    ]
  },
  "_try_load_model_cls": [
    "model_arch",
    "model"
  ],
  "_try_inspect_model_cls": [
    "model_arch",
    "model"
  ],
  "_ModelRegistry": {
    "get_supported_archs": [
      "self"
    ],
    "register_model": [
      "self",
      "model_arch",
      "model_cls"
    ],
    "_raise_for_unsupported": [
      "self",
      "architectures"
    ],
    "_try_load_model_cls": [
      "self",
      "model_arch"
    ],
    "_try_inspect_model_cls": [
      "self",
      "model_arch"
    ],
    "_try_resolve_transformers": [
      "self",
      "architecture",
      "model_config"
    ],
    "_normalize_arch": [
      "self",
      "architecture",
      "model_config"
    ],
    "inspect_model_cls": [
      "self",
      "architectures",
      "model_config"
    ],
    "resolve_model_cls": [
      "self",
      "architectures",
      "model_config"
    ],
    "is_text_generation_model": [
      "self",
      "architectures",
      "model_config"
    ],
    "is_pooling_model": [
      "self",
      "architectures",
      "model_config"
    ],
    "is_cross_encoder_model": [
      "self",
      "architectures",
      "model_config"
    ],
    "is_multimodal_model": [
      "self",
      "architectures",
      "model_config"
    ],
    "is_multimodal_raw_input_only_model": [
      "self",
      "architectures",
      "model_config"
    ],
    "is_pp_supported_model": [
      "self",
      "architectures",
      "model_config"
    ],
    "model_has_inner_state": [
      "self",
      "architectures",
      "model_config"
    ],
    "is_attention_free_model": [
      "self",
      "architectures",
      "model_config"
    ],
    "is_hybrid_model": [
      "self",
      "architectures",
      "model_config"
    ],
    "is_noops_model": [
      "self",
      "architectures",
      "model_config"
    ],
    "is_transcription_model": [
      "self",
      "architectures",
      "model_config"
    ],
    "is_transcription_only_model": [
      "self",
      "architectures",
      "model_config"
    ]
  },
  "ModelRegistry": [],
  "_run_in_subprocess": [
    "fn"
  ],
  "_run": [],
  "_is_moe": [
    "config"
  ],
  "_get_cla_factor": [
    "config"
  ],
  "HunYuanMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix",
      "reduce_results"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunYuanAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "cache_config",
      "prefix",
      "layer_id"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "kv_states"
    ]
  },
  "HunYuanCrossAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "cache_config",
      "prefix",
      "layer_id"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "kv_states"
    ]
  },
  "HunYuanSparseMoeBlock": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "layer_id",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunYuanDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix",
      "layer_id",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual",
      "kv_states"
    ]
  },
  "HunYuanModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "_split_qkv_weight": [
      "self",
      "qkv"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "HunyuanV1ModelBase": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "make_empty_intermediate_tensors": [
      "self",
      "batch_size",
      "dtype",
      "device"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ]
  },
  "HunYuanMoEV1Base": {
    "__init__": [
      "self"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "HunYuanDenseV1Base": {
    "__init__": [
      "self"
    ]
  },
  "HunYuanDenseV1ForCausalLM": {},
  "HunYuanMoEV1ForCausalLM": {},
  "InternS1VisionPatchEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "InternS1VisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "interpolate_pos_encoding": [
      "self",
      "embeddings",
      "height",
      "width"
    ],
    "forward": [
      "self",
      "pixel_values",
      "bool_masked_pos"
    ]
  },
  "InternSdpaAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InternS1VisionMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "InternS1VisionLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "_init_attn": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "InternS1VisionEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "inputs_embeds"
    ]
  },
  "InternS1VisionModel": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "pixel_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_ntuple": [
    "n"
  ],
  "to_1tuple": [],
  "to_2tuple": [],
  "to_3tuple": [],
  "to_4tuple": [],
  "to_ntuple": [],
  "calc_seq_len": [
    "size",
    "patch_size"
  ],
  "calc_seq_lens": [
    "sizes",
    "patch_size"
  ],
  "ClsToken": {
    "__init__": [
      "self",
      "ndim",
      "num_tokens",
      "enabled",
      "register_multiple",
      "num_registers"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ViTPatchGenerator": {
    "__init__": [
      "self",
      "patch_size",
      "embed_dim",
      "input_dims",
      "abs_pos",
      "normalize_patches",
      "cls_token",
      "max_input_dims",
      "pos_dropout",
      "return_pos_enc",
      "num_cls_tokens",
      "register_multiple",
      "num_registers",
      "patch_bias",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "x",
      "imgs_sizes"
    ],
    "apply_pos_enc_dynamic": [
      "self",
      "patches",
      "imgs_sizes"
    ],
    "cls_token_dynamic": [
      "self",
      "patches",
      "imgs_sizes"
    ],
    "apply_cls_token": [
      "self"
    ],
    "num_cls_tokens": [
      "self"
    ],
    "num_cls_patches": [
      "self"
    ],
    "num_registers": [
      "self"
    ],
    "num_skip": [
      "self"
    ],
    "_load_embed": [
      "self",
      "src_embed",
      "targ_embed"
    ],
    "_load_projection": [
      "self",
      "src_proj_weight",
      "targ_proj_weight"
    ],
    "embed_patches": [
      "self",
      "x"
    ],
    "apply_pos_enc": [
      "self",
      "patches",
      "patch_idxs",
      "input_size"
    ],
    "get_pos_enc": [
      "self",
      "batch_size",
      "patch_idxs",
      "input_size"
    ],
    "_get_pos_embeddings": [
      "self",
      "batch_size",
      "input_dims"
    ]
  },
  "Im2Patches": {
    "__init__": [
      "self",
      "patch_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ViTPatchLinear": {
    "__init__": [
      "self",
      "patch_size",
      "embed_dim",
      "bias"
    ]
  },
  "RadioParallelAttention": {
    "forward": [
      "self",
      "x",
      "attn_mask"
    ]
  },
  "RadioVisionEncoderLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attn_mask"
    ]
  },
  "RadioVisionEncoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attn_mask"
    ]
  },
  "RadioInternVisionModel": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "_init_img_size": [
      "self",
      "patch_size",
      "img_size"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "create_inter_image_attention_mask": [
      "self",
      "imgs_sizes",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "imgs_sizes"
    ]
  },
  "RadioModel": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "pixel_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_extract_final": [
      "self",
      "y",
      "imgs_sizes"
    ]
  },
  "FP32ReplicatedLinear": {
    "forward": [
      "self",
      "x"
    ]
  },
  "Step3p5MLP": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Step3p5Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position",
      "head_dim",
      "rms_norm_eps",
      "qkv_bias",
      "rope_theta",
      "cache_config",
      "quant_config",
      "rope_scaling",
      "prefix",
      "attn_type",
      "sliding_window",
      "use_head_wise_attn_gate",
      "layer_types",
      "use_rope_layers",
      "yarn_only_types",
      "swa_num_attention_heads",
      "partial_rotary_factor"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "FusedMoEBlock": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Step3p5DecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "add_and_maybe_inplace_all_reduce": [
      "self",
      "in1",
      "in2"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Step3p5Model": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Step3p5ForCausalLM": {
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "set_eplb_state": [
      "self",
      "expert_load_view",
      "logical_to_physical_map",
      "logical_replica_count"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "InternLM2VEDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual",
      "visual_token_mask"
    ]
  },
  "InternLM2VEModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds",
      "visual_token_mask"
    ]
  },
  "InternLM2VEForCausalLM": {
    "__init__": [
      "self"
    ]
  },
  "ArcticMLP": {
    "__init__": [
      "self",
      "config",
      "expert_id",
      "is_residual_mlp",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ArcticMoE": {
    "__init__": [
      "self",
      "config",
      "tp_size",
      "params_dtype",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "weight_name",
      "expert_id"
    ],
    "local_moe_fused": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "ArcticAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "ArcticDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "ArcticModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "ArcticForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "KimiVLMultiModalProjector": {
    "__init__": [
      "self",
      "config",
      "use_data_parallel",
      "prefix"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "KimiVLImagePixelInputs": {},
  "KimiVLImageInputs": [],
  "KimiVLProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "image_token_id": [
      "self"
    ]
  },
  "KimiVLDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "KimiVLMultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "KimiVLForConditionalGeneration": {
    "supports_encoder_tp_data": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_pixels": [
      "self",
      "inputs"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "AfmoeMoE": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AfmoeAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position_embeddings",
      "head_dim",
      "rms_norm_eps",
      "cache_config",
      "quant_config",
      "prefix",
      "attn_type"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "AfmoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix",
      "enable_eplb"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "AfmoeModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "make_empty_intermediate_tensors": [
      "self",
      "batch_size",
      "dtype",
      "device"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "AfmoeForCausalLM": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self"
    ],
    "set_eplb_state": [
      "self",
      "expert_load_view",
      "logical_to_physical_map",
      "logical_replica_count"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "LongCatMultiTokenPredictorLayer": {
    "__init__": [
      "self",
      "config",
      "prefix",
      "vllm_config",
      "quant_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "previous_hidden_states",
      "inputs_embeds",
      "spec_step_index"
    ]
  },
  "LongCatMultiTokenPredictor": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "previous_hidden_states",
      "inputs_embeds",
      "spec_step_idx"
    ]
  },
  "LongCatFlashMTP": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "intermediate_tensors",
      "inputs_embeds",
      "spec_step_idx"
    ],
    "compute_logits": [
      "self",
      "hidden_states",
      "spec_step_idx"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_rewrite_spec_layer_name": [
      "self",
      "spec_layer",
      "name",
      "new_to_old_names_mapping"
    ],
    "get_spec_layer_idx_from_weight_name": [
      "self",
      "config",
      "weight_name"
    ]
  },
  "CPU_DEVICE": [],
  "MiniCPMOAudioFeatureInputs": {},
  "MiniCPMOAudioEmbeddingInputs": {},
  "_minicpmo_field_config": [
    "hf_inputs"
  ],
  "MiniCPMOAudioEmbeddingItems": {
    "__init__": [
      "self",
      "data",
      "fields_factory"
    ]
  },
  "MiniCPMOMultiModalDataParser": {
    "_parse_audio_data": [
      "self",
      "data"
    ]
  },
  "MiniCPMOProcessingInfo": {
    "audio_pattern": [],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_audio_placeholder": [
      "self",
      "audio_lens",
      "chunk_input",
      "chunk_length"
    ],
    "get_default_audio_pool_step": [
      "self"
    ],
    "get_default_audio_sampling_rate": [
      "self"
    ],
    "get_chunk_length": [
      "self"
    ],
    "get_max_audio_tokens_per_chunk": [
      "self"
    ],
    "get_max_audio_chunks_with_most_features": [
      "self"
    ],
    "get_max_audio_tokens": [
      "self"
    ],
    "get_audio_len_by_num_chunks": [
      "self",
      "num_chunks"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len",
      "mm_counts"
    ]
  },
  "MiniCPMODummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "MiniCPMOMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "get_audio_prompt_texts": [
      "self",
      "audio_lens",
      "chunk_input",
      "chunk_length"
    ],
    "process_audios": [
      "self",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "process_mm_inputs": [
      "self",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "MultiModalProjector": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim"
    ],
    "forward": [
      "self",
      "audio_features"
    ]
  },
  "MiniCPMWhisperEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "MiniCPMWhisperEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_features",
      "attention_mask"
    ]
  },
  "MiniCPMO": {
    "packed_modules_mapping": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "init_audio_module": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "subsequent_chunk_mask": [
      "self",
      "size",
      "chunk_size",
      "num_left_chunks",
      "device",
      "num_lookhead"
    ],
    "_get_feat_extract_output_lengths": [
      "self",
      "input_lengths"
    ],
    "get_audio_hidden_states": [
      "self",
      "data"
    ],
    "_parse_and_validate_audio_input": [
      "self"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "_process_audio_input": [
      "self",
      "audio_input"
    ],
    "_process_multimodal_inputs": [
      "self",
      "modalities"
    ]
  },
  "SkyworkR1VImagePixelInputs": {},
  "SkyworkR1VImageEmbeddingInputs": {},
  "resolve_skyworkr1v_min_max_num": [],
  "get_skyworkr1v_target_ratios": [
    "min_num",
    "max_num"
  ],
  "calculate_skyworkr1v_targets": [],
  "dynamic_preprocess_skyworkr1v": [
    "image"
  ],
  "image_to_pixel_values_skyworkr1v": [
    "image"
  ],
  "SkyworkR1VProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "image_token_id": [
      "self"
    ],
    "get_image_repl": [
      "self",
      "feature_size",
      "num_patches"
    ],
    "resolve_min_max_num": [
      "self"
    ],
    "resolve_target_ratios": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "_images_to_pixel_values_lst": [
      "self",
      "images",
      "min_dynamic_patch",
      "max_dynamic_patch",
      "dynamic_image_size"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "min_dynamic_patch",
      "max_dynamic_patch",
      "dynamic_image_size",
      "return_tensors"
    ]
  },
  "SkyworkR1VProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "SkyworkR1VDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "SkyworkR1VMultiModalProcessor": {
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "SkyworkR1VChatModel": {
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_patch_quant_config": [
      "self",
      "config",
      "quant_config"
    ],
    "_init_vision_model": [
      "self",
      "config",
      "quant_config"
    ],
    "_init_mlp1": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pixel_shuffle": [
      "self",
      "x",
      "scale_factor"
    ],
    "extract_feature": [
      "self",
      "pixel_values"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_set_visual_token_mask": [
      "self",
      "input_ids"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "OAIAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "cache_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "positions"
    ]
  },
  "GptOssModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "_load_weights_mxfp4": [
      "self",
      "ep_rank_end",
      "ep_rank_start",
      "heads_per_rank",
      "head_start",
      "weights",
      "stacked_params_mapping"
    ],
    "_load_weights_other": [
      "self",
      "ep_rank_end",
      "ep_rank_start",
      "heads_per_rank",
      "head_start",
      "weights",
      "stacked_params_mapping"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GptOssForCausalLM": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "SeedOssMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SeedOssAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "head_dim",
      "rope_parameters",
      "max_position",
      "cache_config",
      "quant_config",
      "prefix",
      "attn_type"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "SeedOssDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "SeedOssModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "SeedOssForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "OpenCUAProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ]
  },
  "OpenCUAProcessor": {
    "check_argument_for_proper_class": [
      "self",
      "attribute_name",
      "arg"
    ],
    "__init__": [
      "self",
      "vision_config",
      "tokenizer"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "return_tensors"
    ]
  },
  "OpenCUAMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_hf_processor_applies_updates": [
      "self",
      "prompt_text",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "OpenCUADummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ]
  },
  "OpenCUAForConditionalGeneration": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "supports_encoder_tp_data": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ]
  },
  "Ernie4_5_VisionAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "projection_size",
      "quant_config",
      "prefix"
    ],
    "split_qkv": [
      "self",
      "qkv"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens",
      "rotary_pos_emb",
      "max_seqlen"
    ]
  },
  "Ernie4_5_VisionMLP": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "act_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Ernie4_5_VisionBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "act_layer",
      "norm_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb",
      "max_seqlen"
    ]
  },
  "Ernie4_5_VisionPatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "in_channels",
      "embed_dim",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Ernie4_5_VisionRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "Ernie4_5_VisionTransformer": {
    "__init__": [
      "self",
      "vision_config",
      "norm_eps",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "compute_attn_mask_seqlen": [
      "self",
      "cu_seqlens"
    ],
    "forward": [
      "self",
      "hidden_states",
      "grid_thw",
      "num_pad"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Ernie4_5_VLImagePixelInputs": {},
  "Ernie4_5_VLImageInputs": [],
  "Ernie4_5_VLVideoPixelInputs": {},
  "Ernie4_5_VLVideoInputs": [],
  "round_by_factor": [
    "number",
    "factor"
  ],
  "ceil_by_factor": [
    "number",
    "factor"
  ],
  "floor_by_factor": [
    "number",
    "factor"
  ],
  "VariableResolutionResamplerModel": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "spatial_conv_size",
      "temporal_conv_size",
      "config",
      "prefix"
    ],
    "spatial_conv_reshape": [
      "self",
      "x",
      "spatial_conv_size"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Ernie4_5_VLProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_mm_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "_get_vision_info": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_num_video_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_max_image_tokens": [
      "self"
    ],
    "_get_max_video_frames": [
      "self",
      "max_tokens"
    ],
    "get_num_frames_with_most_features": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "get_max_video_tokens": [
      "self",
      "seq_len",
      "mm_counts"
    ]
  },
  "Ernie4_5VLMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_pixel_values_norm": [
      "self",
      "pixel_values",
      "mm_kwargs"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "Ernie4_5_VLDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ],
    "_get_dummy_videos": [
      "self"
    ]
  },
  "Ernie4_5_VLMoeForConditionalGeneration": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "_vision_forward": [
      "self",
      "pixel_values",
      "grid_thw"
    ],
    "_set_visual_token_mask": [
      "self",
      "input_ids"
    ],
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_video_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_process_video_input": [
      "self",
      "video_input"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Step3TextMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Step3TextAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "norm_eps",
      "rope_parameters",
      "share_q_dim",
      "max_position_embedding",
      "head_dim",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Step3TextDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Step3TextModel": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "Step3TextForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "EagleLlama4ForCausalLM": {
    "__init__": [
      "self"
    ],
    "get_language_model": [
      "self"
    ],
    "embed_input_ids": [],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Step3VLImagePixelInputs": {},
  "Step3VLImageEmbeddingInputs": {},
  "ImageWithPatches": [],
  "Step3VisionProcessor": {
    "__init__": [
      "self",
      "size",
      "interpolation_mode",
      "patch_size"
    ],
    "__call__": [
      "self",
      "image",
      "is_patch"
    ]
  },
  "ImagePatcher": {
    "__init__": [
      "self",
      "enable_patch"
    ],
    "determine_window_size": [
      "self",
      "long",
      "short"
    ],
    "slide_window": [
      "self",
      "width",
      "height",
      "sizes",
      "steps",
      "img_rate_thr"
    ],
    "square_pad": [
      "self",
      "img"
    ],
    "get_image_size_for_padding": [
      "self",
      "img_width",
      "img_height"
    ],
    "get_image_size_for_preprocess": [
      "self",
      "img_width",
      "img_height"
    ],
    "get_image_size_for_crop": [
      "self",
      "img_width",
      "img_height",
      "window_size"
    ],
    "patch_crop": [
      "self",
      "img",
      "i",
      "j",
      "th",
      "tw"
    ],
    "get_num_patches": [
      "self",
      "img_width",
      "img_height"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "Step3VLProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "image_token_id": [
      "self"
    ],
    "get_num_image_tokens": [
      "self",
      "img_width",
      "img_height"
    ],
    "_split_images": [
      "self",
      "images"
    ],
    "_convert_images_to_pixel_values": [
      "self",
      "images",
      "is_patch"
    ],
    "_get_patch_repl": [
      "self",
      "num_patches",
      "patch_newline_mask"
    ],
    "_get_image_repl": [
      "self",
      "num_images"
    ],
    "_get_image_repl_features": [
      "self",
      "num_images",
      "num_patches",
      "patch_new_line_idx"
    ],
    "replace_placeholder": [
      "self",
      "text",
      "placeholder",
      "repls"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "return_tensors"
    ]
  },
  "Step3VLProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_max_image_tokens": [
      "self"
    ],
    "get_mm_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_num_mm_tokens": [
      "self",
      "mm_data"
    ]
  },
  "Step3VLDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Step3VLMultiModalProcessor": {
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "Step3VisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "Step3VisionAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Step3VisionMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Step3VisionEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Step3VisionEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "inputs_embeds"
    ]
  },
  "Step3VisionTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "Step3VLForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "supports_encoder_tp_data": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "device": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_features": [
      "self",
      "image_features"
    ],
    "_get_vision_model_output": [
      "self",
      "input_tensor"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GLMAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids"
    ]
  },
  "GLMMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GLMBlock": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids"
    ]
  },
  "GLMTransformer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids"
    ]
  },
  "ChatGLMModel": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "ChatGLMBaseModel": {
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "ChatGLMForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "EagleMiniCPMDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "_init_attn_block": [
      "self"
    ],
    "_init_ffn_block": [
      "self"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "EagleMiniCPMModel": {
    "__init__": [
      "self"
    ],
    "_init_layers": [
      "self",
      "prefix",
      "config",
      "cache_config",
      "quant_config",
      "start_layer"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "EagleMiniCPMForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "__init__": [
      "self"
    ],
    "_init_model": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Starcoder2Attention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Starcoder2MLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Starcoder2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Starcoder2Model": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Starcoder2ForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_IMAGE_PLACEHOLDER_TOKEN_ID": [],
  "_AUDIO_PLACEHOLDER_TOKEN_ID": [],
  "_AUDIO_MAX_SOUNDFILE_SIZE": [],
  "SIGLIP_NAME": [],
  "VISION_ENCODER_TO_PROCESSING_CONFIG": [],
  "_get_padding_size": [
    "orig_width",
    "orig_height",
    "target_height",
    "target_width"
  ],
  "get_navit_vision_model": [
    "layer_idx"
  ],
  "Phi4MMImageEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "model_dir"
    ],
    "get_img_features": [
      "self",
      "img_embeds",
      "attention_mask"
    ],
    "forward": [
      "self",
      "pixel_values",
      "image_sizes",
      "image_attention_mask"
    ]
  },
  "Phi4MMImagePixelInputs": {},
  "Phi4MMAudioFeatureInputs": {},
  "Phi4MMAudioEmbeddingInputs": {},
  "cat_with_pad": [
    "tensors",
    "dim",
    "padding_value"
  ],
  "Phi4MMProcessingInfo": {
    "image_tokens": [
      "self"
    ],
    "audio_tokens": [
      "self"
    ],
    "get_dynamic_hd": [
      "self",
      "processor"
    ],
    "get_feature_extractor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "_find_target_aspect_ratio": [
      "self",
      "orig_width",
      "orig_height",
      "image_size",
      "max_num",
      "min_num"
    ],
    "_compute_num_image_tokens": [
      "self",
      "orig_width",
      "orig_height",
      "dynamic_hd_size",
      "vit_image_size",
      "vit_patch_size",
      "token_compression_factor"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self",
      "processor"
    ],
    "get_audio_num_frames": [
      "self",
      "audio_len",
      "sr"
    ],
    "_compute_audio_embed_size": [
      "self",
      "audio_frames"
    ]
  },
  "Phi4MMDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "Phi4MMMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_recompute_cached_prompt_update": [
      "self",
      "cached_update",
      "new_item_idx"
    ]
  },
  "Phi4MMForCausalLM": {
    "packed_modules_mapping": [],
    "hf_to_vllm_mapper": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_audio_input": [
      "self"
    ],
    "_process_audio_input": [
      "self",
      "audio_input",
      "audio_projection_mode"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "VIT_LAYERS": [],
  "NUM_PREFIX_TOKENS": [],
  "ADDITIONAL_VOCAB_SIZE": [],
  "IMAGE_PATCH_TOKEN": [],
  "IM_COL_TOKEN": [],
  "IM_START_TOKEN": [],
  "IM_END_TOKEN": [],
  "POOLING_SIZE": [],
  "MolmoImageInputs": {},
  "VisionBackboneConfig": {
    "__post_init__": [
      "self"
    ],
    "image_num_patch": [
      "self"
    ]
  },
  "MultiHeadDotProductAttention": {
    "__init__": [
      "self",
      "config",
      "use_bias",
      "nlayers",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "inputs_q",
      "inputs_kv"
    ]
  },
  "ResidualAttentionBlock": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BlockCollection": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_expand_token": [
    "token",
    "batch_size"
  ],
  "MolmoAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "_apply_qk_norm": [
      "self",
      "q",
      "k"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "MolmoDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "MolmoDecoderNormAfterLayer": {
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "MolmoVisionBackbone": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "vision_config",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "encode_image": [
      "self",
      "images"
    ],
    "forward": [
      "self",
      "images",
      "image_masks"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MolmoModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_lowest_multiple": [
    "x",
    "k"
  ],
  "MolmoProcessorWrapper": {
    "__init__": [
      "self",
      "processor"
    ],
    "vocab": [
      "self"
    ],
    "max_crops": [
      "self"
    ],
    "base_image_input_size": [
      "self"
    ],
    "image_patch_size": [
      "self"
    ],
    "overlap_margins": [
      "self"
    ],
    "image_token_length_w": [
      "self"
    ],
    "image_token_length_h": [
      "self"
    ],
    "message_format": [
      "self"
    ],
    "always_start_with_space": [
      "self"
    ],
    "image_patch_id": [
      "self"
    ],
    "im_col_id": [
      "self"
    ],
    "im_start_id": [
      "self"
    ],
    "im_end_id": [
      "self"
    ],
    "pooling_size": [
      "self"
    ],
    "select_tiling": [
      "self"
    ],
    "get_patches_grid_size": [
      "self"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "return_tensors"
    ]
  },
  "MolmoProcessingInfo": {
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ]
  },
  "MolmoDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "MolmoMultiModalProcessor": {
    "_apply_hf_processor_tokens_only": [
      "self",
      "prompt_tokens"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ]
  },
  "MolmoForCausalLM": {
    "hf_to_vllm_mapper": [],
    "packed_modules_mapping": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "HunYuanVLImagePixelInputs": {},
  "HunYuanVLImageEmbeddingInputs": {},
  "HunYuanVisionMLP": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "bias",
      "act_fn",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunYuanVisionAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "projection_size",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunYuanVisionBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_hidden_dim",
      "act_fn",
      "norm_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunYuanVisionPatchEmbed": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "grid_thw"
    ]
  },
  "HunYuanVisionPatchMerger": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "spatial_merge_size",
      "rms_norm_eps",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "size"
    ]
  },
  "HunYuanVisionTransformer": {
    "__init__": [
      "self",
      "vision_config",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_hunyuan_vl_field_config": [
    "hf_inputs"
  ],
  "HunYuanVLMultiModalDataParser": {
    "_parse_image_data": [
      "self",
      "data"
    ]
  },
  "HunYuanVLProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_image_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_mm_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "_get_vision_info": [
      "self"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_image_size_with_most_features": [
      "self"
    ],
    "get_max_image_tokens": [
      "self"
    ]
  },
  "HunYuanVLDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "HunYuanVLMultiModalProcessor": {
    "_get_data_parser": [
      "self"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ]
  },
  "HunYuanVLForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "supports_encoder_tp_data": [],
    "get_xdrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "_parse_and_validate_multimodal_inputs": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "Glm4Attention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position",
      "head_dim",
      "qkv_bias",
      "cache_config",
      "quant_config",
      "prefix",
      "attn_type"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "Glm4DecoderLayer": {
    "__init__": [
      "self",
      "vllm_config",
      "prefix",
      "config"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "Glm4Model": {
    "__init__": [
      "self"
    ]
  },
  "Glm4ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MPTAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "MPTMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MPTBlock": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states"
    ]
  },
  "MPTModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MPTForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "StablelmMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StablelmAttention": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "StablelmDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "StableLMEpochModel": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "StablelmForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Eagle2_5_VLImagePixelInputs": {},
  "Eagle2_5_VLImageEmbeddingInputs": {},
  "Eagle2_5_VLProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "image_token_id": [
      "self"
    ],
    "get_image_repl": [
      "self",
      "feature_size",
      "num_patches"
    ]
  },
  "Eagle2_5_VLProcessingInfo": {
    "get_hf_processor": [
      "self"
    ]
  },
  "Eagle2_5_VLDummyInputsBuilder": {},
  "Eagle2_5_VLMultiModalProcessor": {},
  "Eagle2_5_VLForConditionalGeneration": {
    "supports_encoder_tp_data": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "_init_vision_model": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "_init_mlp1": [
      "self",
      "config"
    ],
    "pixel_shuffle": [
      "self",
      "x",
      "scale_factor"
    ],
    "extract_feature": [
      "self",
      "pixel_values"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_process_image_input": [
      "self",
      "image_input"
    ],
    "get_language_model": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_mm_mapping": [
      "self"
    ]
  },
  "adjust_audio_features_to_expected_length": [
    "audio_features",
    "expected_tokens",
    "audio_padding_embs"
  ],
  "VoxtralProcessorAdapter": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "_audio_processor": [
      "self"
    ],
    "audio_token_id": [
      "self"
    ],
    "begin_audio_token_id": [
      "self"
    ],
    "sampling_rate": [
      "self"
    ],
    "frame_rate": [
      "self"
    ],
    "get_num_audio_tokens": [
      "self",
      "audio_length"
    ],
    "__call__": [
      "self",
      "text",
      "audios",
      "return_tensors"
    ]
  },
  "VoxtralProcessingInfo": {
    "get_tokenizer": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_mm_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "get_max_audio_tokens": [
      "self"
    ],
    "get_max_audio_array_len": [
      "self"
    ]
  },
  "VoxtralDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ],
    "get_dummy_processor_inputs": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "VoxtralMultiModalProcessor": {
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_cached_apply_hf_processor": [
      "self",
      "prompt",
      "mm_data_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs",
      "mm_uuids"
    ],
    "_get_data_parser": [
      "self"
    ]
  },
  "VoxtralForConditionalGeneration": {
    "supported_languages": [],
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "get_mm_mapping": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "embed_multimodal": [
      "self"
    ],
    "_parse_and_validate_audio_arrays": [
      "self"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "get_speech_to_text_config": [
      "cls",
      "model_config",
      "task_type"
    ],
    "get_generation_prompt": [
      "cls",
      "audio",
      "model_config",
      "stt_config",
      "language",
      "task_type",
      "request_prompt",
      "to_language"
    ],
    "get_num_audio_tokens": [
      "cls",
      "audio_duration_s",
      "stt_config",
      "model_config"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "maybe_update_quant_config": [
      "self",
      "quant_config"
    ]
  },
  "AudioLanguageAdapter": {
    "__init__": [
      "self",
      "hidden_size",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "VoxtralEncoderModel": {
    "packed_modules_mapping": [],
    "mistral_remapping": [],
    "__init__": [
      "self",
      "vllm_config"
    ],
    "compute_whisper_melspec": [
      "self",
      "audio_waveforms"
    ],
    "downsample_factor": [
      "self"
    ],
    "chunk_size": [
      "self"
    ],
    "prepare_inputs_for_conv": [
      "self",
      "audio_waveforms"
    ],
    "forward": [
      "self",
      "input_features"
    ],
    "load_weight": [
      "self",
      "weight"
    ]
  },
  "MiniMaxM2MoE": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "ebias_weight_loader": [
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MiniMaxM2Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rotary_dim",
      "rope_parameters",
      "attn_window_size",
      "max_position_embeddings",
      "head_dim",
      "rms_norm_eps",
      "qkv_bias",
      "cache_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states"
    ]
  },
  "MiniMaxM2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "prefix",
      "model_config",
      "cache_config",
      "quant_config"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual"
    ]
  },
  "MiniMaxM2Model": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiniMaxM2ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_expert_mapping": [
      "self"
    ]
  },
  "EagleDeepseekV3ForCausalLM": {
    "__init__": [
      "self"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "hidden_states",
      "inputs_embeds"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "RVLProcessingInfo": {
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ]
  },
  "RVLDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "RVLMultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "image_feature"
    ]
  },
  "RForConditionalGeneration": {
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self"
    ]
  },
  "DYNAMIC_ARG_DIMS": [],
  "MultiModalProcessingInfo": {
    "get_supported_mm_limits": [
      "self"
    ],
    "get_mm_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ],
    "get_max_image_tokens": [
      "self"
    ],
    "get_max_image_size": [
      "self"
    ]
  },
  "MultiModalDummyInputsBuilder": {
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ]
  },
  "MultiModalProcessor": {
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_hf_mm_data": [
      "self",
      "mm_items"
    ],
    "apply": [
      "self",
      "prompt",
      "mm_data",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs",
      "mm_uuids"
    ]
  },
  "MultiModalMixin": {
    "supports_multimodal_raw_input_only": [],
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "get_language_model": [
      "self"
    ],
    "embed_multimodal": [
      "self"
    ],
    "get_mrope_input_positions": [
      "self",
      "input_tokens",
      "mm_features"
    ]
  },
  "vllm_flash_attention_forward": [
    "module",
    "query",
    "key",
    "value",
    "attention_mask",
    "scaling",
    "attention_instances"
  ],
  "Base": {
    "embedding_modules": [],
    "hf_to_vllm_mapper": [],
    "__init_subclass__": [
      "cls"
    ],
    "__init__": [
      "self"
    ],
    "pipeline_parallel": [
      "self"
    ],
    "recursive_replace": [
      "self"
    ],
    "create_attention_instances": [
      "self"
    ],
    "init_parameters": [
      "self",
      "module",
      "dtype"
    ],
    "embed_input_ids": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "check_version": [
      "min_version",
      "feature"
    ],
    "set_aux_hidden_state_layers": [
      "self",
      "layers"
    ],
    "get_eagle3_aux_hidden_state_layers": [
      "self"
    ]
  },
  "init_on_device_without_buffers": [
    "device"
  ],
  "Style": [],
  "replace_linear_class": [
    "linear",
    "style",
    "quant_config"
  ],
  "TorchConv": [],
  "VllmConv": [],
  "replace_conv_class": [
    "conv"
  ],
  "replace_rms_norm_class": [
    "rms_norm",
    "hidden_size"
  ],
  "log_replacement": [
    "name",
    "old_module",
    "new_module"
  ],
  "get_feature_request_tip": [
    "model",
    "trust_remote_code"
  ],
  "can_enable_torch_compile": [
    "vllm_config"
  ],
  "CausalMixin": {
    "__init__": [
      "self"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ]
  },
  "SequenceClassificationMixin": {
    "default_seq_pooling_type": [],
    "__init__": [
      "self"
    ]
  },
  "TransformersForCausalLM": {},
  "TransformersMoEForCausalLM": {},
  "TransformersMultiModalForCausalLM": {},
  "TransformersMultiModalMoEForCausalLM": {},
  "TransformersEmbeddingModel": {},
  "TransformersMoEEmbeddingModel": {},
  "TransformersMultiModalEmbeddingModel": {},
  "TransformersForSequenceClassification": {},
  "TransformersMoEForSequenceClassification": {},
  "TransformersMultiModalForSequenceClassification": {},
  "LegacyMixin": {
    "hf_to_vllm_mapper": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ]
  },
  "TransformersFusedMoE": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_ids",
      "topk_weights"
    ]
  },
  "transformers_moe_forward": [
    "hidden_states",
    "topk_ids",
    "topk_weights",
    "layer_name"
  ],
  "transformers_moe_forward_fake": [
    "hidden_states",
    "topk_ids",
    "topk_weights",
    "layer_name"
  ],
  "MoEMixin": {
    "__init__": [
      "self"
    ],
    "set_eplb_state": [
      "self",
      "expert_load_view",
      "logical_to_physical_map",
      "logical_replica_count"
    ],
    "update_physical_experts_metadata": [
      "self",
      "num_physical_experts",
      "num_local_physical_experts"
    ],
    "get_expert_mapping": [
      "self"
    ],
    "recursive_replace": [
      "self"
    ]
  },
  "maybe_serialize_tool_calls": [
    "request"
  ],
  "truncate_tool_call_ids": [
    "request"
  ],
  "_prepare_apply_chat_template_tools_and_messages": [
    "messages",
    "tools",
    "continue_final_message",
    "add_generation_prompt"
  ],
  "validate_request_params": [
    "request"
  ],
  "_tekken_token_to_id": [
    "tokenizer",
    "t"
  ],
  "MistralTokenizer": {
    "from_pretrained": [
      "cls",
      "path_or_repo_id"
    ],
    "__init__": [
      "self",
      "tokenizer"
    ],
    "_get_special_token_ids": [
      "self"
    ],
    "_get_special_tokens": [
      "self",
      "all_special_ids"
    ],
    "num_special_tokens_to_add": [
      "self"
    ],
    "all_special_tokens": [
      "self"
    ],
    "all_special_ids": [
      "self"
    ],
    "bos_token_id": [
      "self"
    ],
    "eos_token_id": [
      "self"
    ],
    "pad_token_id": [
      "self"
    ],
    "is_fast": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "max_token_id": [
      "self"
    ],
    "truncation_side": [
      "self"
    ],
    "_is_special_token_id": [
      "self",
      "token_id"
    ],
    "__hash__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "add_special_tokens",
      "truncation",
      "max_length"
    ],
    "vocab": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "get_added_vocab": [
      "self"
    ],
    "encode": [
      "self",
      "text",
      "truncation",
      "max_length",
      "add_special_tokens"
    ],
    "apply_chat_template": [
      "self",
      "messages",
      "tools"
    ],
    "decode": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "batch_decode": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ]
  },
  "TOOLS_SYSTEM_TEMPLATE": [],
  "thinking_template": [],
  "tool_calls_template": [],
  "to_json": [
    "value"
  ],
  "tools_from_openai_format": [
    "tools"
  ],
  "tool_calls_from_openai_format": [
    "tool_calls"
  ],
  "tool_calls_to_openai_format": [
    "tool_calls"
  ],
  "encode_arguments_to_dsml": [
    "tool_call"
  ],
  "decode_dsml_to_arguments": [
    "tool_name",
    "tool_args"
  ],
  "render_tools": [
    "tools"
  ],
  "find_last_user_index": [
    "messages"
  ],
  "render_message": [
    "index",
    "messages",
    "thinking_mode"
  ],
  "drop_thinking_messages": [
    "messages",
    "last_user_idx"
  ],
  "encode_messages": [
    "messages",
    "thinking_mode",
    "context",
    "drop_thinking",
    "add_default_bos_token"
  ],
  "_read_until_stop": [
    "index",
    "text",
    "stop"
  ],
  "parse_tool_calls": [
    "index",
    "text"
  ],
  "parse_message_from_completion_text": [
    "text",
    "thinking_mode"
  ],
  "get_cached_tokenizer": [
    "tokenizer"
  ],
  "CachedHfTokenizer": {
    "from_pretrained": [
      "cls",
      "path_or_repo_id"
    ]
  },
  "TokenizerLike": {
    "from_pretrained": [
      "cls",
      "path_or_repo_id"
    ],
    "num_special_tokens_to_add": [
      "self"
    ],
    "all_special_tokens": [
      "self"
    ],
    "all_special_ids": [
      "self"
    ],
    "bos_token_id": [
      "self"
    ],
    "eos_token_id": [
      "self"
    ],
    "pad_token_id": [
      "self"
    ],
    "is_fast": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "max_token_id": [
      "self"
    ],
    "truncation_side": [
      "self"
    ],
    "__hash__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "add_special_tokens",
      "truncation",
      "max_length"
    ],
    "get_vocab": [
      "self"
    ],
    "get_added_vocab": [
      "self"
    ],
    "encode": [
      "self",
      "text",
      "truncation",
      "max_length",
      "add_special_tokens"
    ],
    "apply_chat_template": [
      "self",
      "messages",
      "tools"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "decode": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ]
  },
  "DeepseekV32Tokenizer": {
    "from_pretrained": [
      "cls",
      "path_or_repo_id"
    ],
    "__init__": [
      "self",
      "tokenizer"
    ],
    "apply_chat_template": [
      "self",
      "messages",
      "tools"
    ],
    "num_special_tokens_to_add": [
      "self"
    ],
    "all_special_tokens": [
      "self"
    ],
    "all_special_ids": [
      "self"
    ],
    "bos_token_id": [
      "self"
    ],
    "eos_token_id": [
      "self"
    ],
    "pad_token_id": [
      "self"
    ],
    "is_fast": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "max_token_id": [
      "self"
    ],
    "truncation_side": [
      "self"
    ],
    "__hash__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "add_special_tokens",
      "truncation",
      "max_length"
    ],
    "get_vocab": [
      "self"
    ],
    "get_added_vocab": [
      "self"
    ],
    "encode": [
      "self",
      "text",
      "truncation",
      "max_length",
      "add_special_tokens"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "decode": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ]
  },
  "_replace_none_with_empty": [
    "tokens"
  ],
  "_convert_tokens_to_string_with_added_encoders": [
    "tokenizer",
    "output_tokens",
    "skip_special_tokens",
    "spaces_between_special_tokens"
  ],
  "INITIAL_INCREMENTAL_DETOKENIZATION_OFFSET": [],
  "convert_prompt_ids_to_tokens": [
    "tokenizer",
    "prompt_ids",
    "skip_special_tokens"
  ],
  "convert_ids_list_to_tokens": [
    "tokenizer",
    "token_ids"
  ],
  "detokenize_incrementally": [
    "tokenizer",
    "all_input_ids",
    "prev_tokens",
    "prefix_offset",
    "read_offset",
    "skip_special_tokens",
    "spaces_between_special_tokens"
  ],
  "_VLLM_TOKENIZERS": [],
  "_TokenizerRegistry": {
    "register": [
      "self",
      "tokenizer_mode",
      "module",
      "class_name"
    ],
    "load_tokenizer_cls": [
      "self",
      "tokenizer_mode"
    ],
    "load_tokenizer": [
      "self",
      "tokenizer_mode"
    ]
  },
  "TokenizerRegistry": [],
  "resolve_tokenizer_args": [
    "tokenizer_name"
  ],
  "cached_resolve_tokenizer_args": [],
  "tokenizer_args_from_config": [
    "config"
  ],
  "get_tokenizer": [
    "tokenizer_name"
  ],
  "cached_get_tokenizer": [],
  "cached_tokenizer_from_config": [
    "model_config"
  ],
  "PAD": [],
  "EOS": [],
  "SEP": [],
  "RESERVED_TOKEN_TEXTS": [],
  "CONTROL_TOKEN_TEXTS": [],
  "DEFAULT_SPECIAL_TOKENS": [],
  "DEFAULT_CONTROL_TOKENS": [],
  "DEFAULT_CHAT_TEMPLATE": [],
  "PAT_STR_B": [],
  "_maybe_load_tokenizer_config": [
    "model_path"
  ],
  "_load_tiktoken_encoding": [
    "vocab_file"
  ],
  "Grok2Tokenizer": {
    "from_pretrained": [
      "cls",
      "path_or_repo_id"
    ],
    "__init__": [
      "self"
    ],
    "num_special_tokens_to_add": [
      "self"
    ],
    "all_special_tokens": [
      "self"
    ],
    "all_special_ids": [
      "self"
    ],
    "bos_token_id": [
      "self"
    ],
    "eos_token_id": [
      "self"
    ],
    "pad_token_id": [
      "self"
    ],
    "is_fast": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "max_token_id": [
      "self"
    ],
    "truncation_side": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "get_added_vocab": [
      "self"
    ],
    "_maybe_truncate": [
      "self",
      "tokens",
      "max_length"
    ],
    "encode": [
      "self",
      "text",
      "truncation",
      "max_length",
      "add_special_tokens"
    ],
    "decode": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "convert_tokens_to_ids": [
      "self",
      "tokens"
    ],
    "convert_ids_to_tokens": [
      "self",
      "ids",
      "skip_special_tokens"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "__call__": [
      "self",
      "text",
      "text_pair",
      "add_special_tokens",
      "truncation",
      "max_length"
    ],
    "get_chat_template": [
      "self",
      "chat_template",
      "tools"
    ],
    "apply_chat_template": [
      "self",
      "messages",
      "tools",
      "chat_template",
      "tokenize"
    ]
  },
  "_nvmlEnableState_t": [],
  "NVML_FEATURE_DISABLED": [],
  "NVML_FEATURE_ENABLED": [],
  "_nvmlBrandType_t": [],
  "NVML_BRAND_UNKNOWN": [],
  "NVML_BRAND_QUADRO": [],
  "NVML_BRAND_TESLA": [],
  "NVML_BRAND_NVS": [],
  "NVML_BRAND_GRID": [],
  "NVML_BRAND_GEFORCE": [],
  "NVML_BRAND_TITAN": [],
  "NVML_BRAND_NVIDIA_VAPPS": [],
  "NVML_BRAND_NVIDIA_VPC": [],
  "NVML_BRAND_NVIDIA_VCS": [],
  "NVML_BRAND_NVIDIA_VWS": [],
  "NVML_BRAND_NVIDIA_CLOUD_GAMING": [],
  "NVML_BRAND_NVIDIA_VGAMING": [],
  "NVML_BRAND_QUADRO_RTX": [],
  "NVML_BRAND_NVIDIA_RTX": [],
  "NVML_BRAND_NVIDIA": [],
  "NVML_BRAND_GEFORCE_RTX": [],
  "NVML_BRAND_TITAN_RTX": [],
  "NVML_BRAND_COUNT": [],
  "_nvmlTemperatureThresholds_t": [],
  "NVML_TEMPERATURE_THRESHOLD_SHUTDOWN": [],
  "NVML_TEMPERATURE_THRESHOLD_SLOWDOWN": [],
  "NVML_TEMPERATURE_THRESHOLD_MEM_MAX": [],
  "NVML_TEMPERATURE_THRESHOLD_GPU_MAX": [],
  "NVML_TEMPERATURE_THRESHOLD_ACOUSTIC_MIN": [],
  "NVML_TEMPERATURE_THRESHOLD_ACOUSTIC_CURR": [],
  "NVML_TEMPERATURE_THRESHOLD_ACOUSTIC_MAX": [],
  "NVML_TEMPERATURE_THRESHOLD_GPS_CURR": [],
  "NVML_TEMPERATURE_THRESHOLD_COUNT": [],
  "_nvmlTemperatureSensors_t": [],
  "NVML_TEMPERATURE_GPU": [],
  "NVML_TEMPERATURE_COUNT": [],
  "_nvmlComputeMode_t": [],
  "NVML_COMPUTEMODE_DEFAULT": [],
  "NVML_COMPUTEMODE_EXCLUSIVE_THREAD": [],
  "NVML_COMPUTEMODE_PROHIBITED": [],
  "NVML_COMPUTEMODE_EXCLUSIVE_PROCESS": [],
  "NVML_COMPUTEMODE_COUNT": [],
  "_nvmlMemoryLocation_t": [],
  "NVML_MEMORY_LOCATION_L1_CACHE": [],
  "NVML_MEMORY_LOCATION_L2_CACHE": [],
  "NVML_MEMORY_LOCATION_DEVICE_MEMORY": [],
  "NVML_MEMORY_LOCATION_DRAM": [],
  "NVML_MEMORY_LOCATION_REGISTER_FILE": [],
  "NVML_MEMORY_LOCATION_TEXTURE_MEMORY": [],
  "NVML_MEMORY_LOCATION_TEXTURE_SHM": [],
  "NVML_MEMORY_LOCATION_CBU": [],
  "NVML_MEMORY_LOCATION_SRAM": [],
  "NVML_MEMORY_LOCATION_COUNT": [],
  "NVML_NVLINK_MAX_LINKS": [],
  "NVML_NVLINK_MAX_LANES": [],
  "_nvmlNvLinkErrorCounter_t": [],
  "NVML_NVLINK_ERROR_DL_REPLAY": [],
  "NVML_NVLINK_ERROR_DL_RECOVERY": [],
  "NVML_NVLINK_ERROR_DL_CRC_FLIT": [],
  "NVML_NVLINK_ERROR_DL_CRC_DATA": [],
  "NVML_NVLINK_ERROR_DL_ECC_DATA": [],
  "NVML_NVLINK_ERROR_COUNT": [],
  "_nvmlNvLinkEccLaneErrorCounter_t": [],
  "NVML_NVLINK_ERROR_DL_ECC_LANE0": [],
  "NVML_NVLINK_ERROR_DL_ECC_LANE1": [],
  "NVML_NVLINK_ERROR_DL_ECC_LANE2": [],
  "NVML_NVLINK_ERROR_DL_ECC_LANE3": [],
  "NVML_NVLINK_ERROR_DL_ECC_COUNT": [],
  "_nvmlNvLinkCapability_t": [],
  "NVML_NVLINK_CAP_P2P_SUPPORTED": [],
  "NVML_NVLINK_CAP_SYSMEM_ACCESS": [],
  "NVML_NVLINK_CAP_P2P_ATOMICS": [],
  "NVML_NVLINK_CAP_SYSMEM_ATOMICS": [],
  "NVML_NVLINK_CAP_SLI_BRIDGE": [],
  "NVML_NVLINK_CAP_VALID": [],
  "NVML_NVLINK_CAP_COUNT": [],
  "_nvmlNvLinkUtilizationCountPktTypes_t": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_NOP": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_READ": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_WRITE": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_RATOM": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_NRATOM": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_FLUSH": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_RESPDATA": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_RESPNODATA": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_ALL": [],
  "_nvmlNvLinkUtilizationCountUnits_t": [],
  "NVML_NVLINK_COUNTER_UNIT_CYCLES": [],
  "NVML_NVLINK_COUNTER_UNIT_PACKETS": [],
  "NVML_NVLINK_COUNTER_UNIT_BYTES": [],
  "NVML_NVLINK_COUNTER_UNIT_RESERVED": [],
  "NVML_NVLINK_COUNTER_UNIT_COUNT": [],
  "_nvmlNvLinkDeviceType_t": [],
  "NVML_NVLINK_DEVICE_TYPE_GPU": [],
  "NVML_NVLINK_DEVICE_TYPE_IBMNPU": [],
  "NVML_NVLINK_DEVICE_TYPE_SWITCH": [],
  "NVML_NVLINK_DEVICE_TYPE_UNKNOWN": [],
  "_nvmlEccBitType_t": [],
  "NVML_SINGLE_BIT_ECC": [],
  "NVML_DOUBLE_BIT_ECC": [],
  "NVML_ECC_ERROR_TYPE_COUNT": [],
  "_nvmlEccCounterType_t": [],
  "NVML_VOLATILE_ECC": [],
  "NVML_AGGREGATE_ECC": [],
  "NVML_ECC_COUNTER_TYPE_COUNT": [],
  "_nvmlMemoryErrorType_t": [],
  "NVML_MEMORY_ERROR_TYPE_CORRECTED": [],
  "NVML_MEMORY_ERROR_TYPE_UNCORRECTED": [],
  "NVML_MEMORY_ERROR_TYPE_COUNT": [],
  "_nvmlClockType_t": [],
  "NVML_CLOCK_GRAPHICS": [],
  "NVML_CLOCK_SM": [],
  "NVML_CLOCK_MEM": [],
  "NVML_CLOCK_VIDEO": [],
  "NVML_CLOCK_COUNT": [],
  "_nvmlClockId_t": [],
  "NVML_CLOCK_ID_CURRENT": [],
  "NVML_CLOCK_ID_APP_CLOCK_TARGET": [],
  "NVML_CLOCK_ID_APP_CLOCK_DEFAULT": [],
  "NVML_CLOCK_ID_CUSTOMER_BOOST_MAX": [],
  "NVML_CLOCK_ID_COUNT": [],
  "_nvmlDriverModel_t": [],
  "NVML_DRIVER_WDDM": [],
  "NVML_DRIVER_WDM": [],
  "NVML_DRIVER_MCDM": [],
  "NVML_MAX_GPU_PERF_PSTATES": [],
  "_nvmlPstates_t": [],
  "NVML_PSTATE_0": [],
  "NVML_PSTATE_1": [],
  "NVML_PSTATE_2": [],
  "NVML_PSTATE_3": [],
  "NVML_PSTATE_4": [],
  "NVML_PSTATE_5": [],
  "NVML_PSTATE_6": [],
  "NVML_PSTATE_7": [],
  "NVML_PSTATE_8": [],
  "NVML_PSTATE_9": [],
  "NVML_PSTATE_10": [],
  "NVML_PSTATE_11": [],
  "NVML_PSTATE_12": [],
  "NVML_PSTATE_13": [],
  "NVML_PSTATE_14": [],
  "NVML_PSTATE_15": [],
  "NVML_PSTATE_UNKNOWN": [],
  "_nvmlInforomObject_t": [],
  "NVML_INFOROM_OEM": [],
  "NVML_INFOROM_ECC": [],
  "NVML_INFOROM_POWER": [],
  "NVML_INFOROM_DEN": [],
  "NVML_INFOROM_COUNT": [],
  "_nvmlReturn_t": [],
  "NVML_SUCCESS": [],
  "NVML_ERROR_UNINITIALIZED": [],
  "NVML_ERROR_INVALID_ARGUMENT": [],
  "NVML_ERROR_NOT_SUPPORTED": [],
  "NVML_ERROR_NO_PERMISSION": [],
  "NVML_ERROR_ALREADY_INITIALIZED": [],
  "NVML_ERROR_NOT_FOUND": [],
  "NVML_ERROR_INSUFFICIENT_SIZE": [],
  "NVML_ERROR_INSUFFICIENT_POWER": [],
  "NVML_ERROR_DRIVER_NOT_LOADED": [],
  "NVML_ERROR_TIMEOUT": [],
  "NVML_ERROR_IRQ_ISSUE": [],
  "NVML_ERROR_LIBRARY_NOT_FOUND": [],
  "NVML_ERROR_FUNCTION_NOT_FOUND": [],
  "NVML_ERROR_CORRUPTED_INFOROM": [],
  "NVML_ERROR_GPU_IS_LOST": [],
  "NVML_ERROR_RESET_REQUIRED": [],
  "NVML_ERROR_OPERATING_SYSTEM": [],
  "NVML_ERROR_LIB_RM_VERSION_MISMATCH": [],
  "NVML_ERROR_IN_USE": [],
  "NVML_ERROR_MEMORY": [],
  "NVML_ERROR_NO_DATA": [],
  "NVML_ERROR_VGPU_ECC_NOT_SUPPORTED": [],
  "NVML_ERROR_INSUFFICIENT_RESOURCES": [],
  "NVML_ERROR_FREQ_NOT_SUPPORTED": [],
  "NVML_ERROR_ARGUMENT_VERSION_MISMATCH": [],
  "NVML_ERROR_DEPRECATED": [],
  "NVML_ERROR_NOT_READY": [],
  "NVML_ERROR_GPU_NOT_FOUND": [],
  "NVML_ERROR_INVALID_STATE": [],
  "NVML_ERROR_UNKNOWN": [],
  "_nvmlFanState_t": [],
  "NVML_FAN_NORMAL": [],
  "NVML_FAN_FAILED": [],
  "_nvmlFanControlPolicy_t": [],
  "NVML_FAN_POLICY_TEMPERATURE_CONTINOUS_SW": [],
  "NVML_FAN_POLICY_MANUAL": [],
  "_nvmlLedColor_t": [],
  "NVML_LED_COLOR_GREEN": [],
  "NVML_LED_COLOR_AMBER": [],
  "_nvmlGpuOperationMode_t": [],
  "NVML_GOM_ALL_ON": [],
  "NVML_GOM_COMPUTE": [],
  "NVML_GOM_LOW_DP": [],
  "_nvmlPageRetirementCause_t": [],
  "NVML_PAGE_RETIREMENT_CAUSE_MULTIPLE_SINGLE_BIT_ECC_ERRORS": [],
  "NVML_PAGE_RETIREMENT_CAUSE_DOUBLE_BIT_ECC_ERROR": [],
  "NVML_PAGE_RETIREMENT_CAUSE_COUNT": [],
  "_nvmlRestrictedAPI_t": [],
  "NVML_RESTRICTED_API_SET_APPLICATION_CLOCKS": [],
  "NVML_RESTRICTED_API_SET_AUTO_BOOSTED_CLOCKS": [],
  "NVML_RESTRICTED_API_COUNT": [],
  "_nvmlBridgeChipType_t": [],
  "NVML_BRIDGE_CHIP_PLX": [],
  "NVML_BRIDGE_CHIP_BRO4": [],
  "NVML_MAX_PHYSICAL_BRIDGE": [],
  "_nvmlValueType_t": [],
  "NVML_VALUE_TYPE_DOUBLE": [],
  "NVML_VALUE_TYPE_UNSIGNED_INT": [],
  "NVML_VALUE_TYPE_UNSIGNED_LONG": [],
  "NVML_VALUE_TYPE_UNSIGNED_LONG_LONG": [],
  "NVML_VALUE_TYPE_SIGNED_LONG_LONG": [],
  "NVML_VALUE_TYPE_SIGNED_INT": [],
  "NVML_VALUE_TYPE_UNSIGNED_SHORT": [],
  "NVML_VALUE_TYPE_COUNT": [],
  "_nvmlNvlinkVersion_t": [],
  "NVML_NVLINK_VERSION_INVALID": [],
  "NVML_NVLINK_VERSION_1_0": [],
  "NVML_NVLINK_VERSION_2_0": [],
  "NVML_NVLINK_VERSION_2_2": [],
  "NVML_NVLINK_VERSION_3_0": [],
  "NVML_NVLINK_VERSION_3_1": [],
  "NVML_NVLINK_VERSION_4_0": [],
  "NVML_NVLINK_VERSION_5_0": [],
  "_nvmlPerfPolicyType_t": [],
  "NVML_PERF_POLICY_POWER": [],
  "NVML_PERF_POLICY_THERMAL": [],
  "NVML_PERF_POLICY_SYNC_BOOST": [],
  "NVML_PERF_POLICY_BOARD_LIMIT": [],
  "NVML_PERF_POLICY_LOW_UTILIZATION": [],
  "NVML_PERF_POLICY_RELIABILITY": [],
  "NVML_PERF_POLICY_TOTAL_APP_CLOCKS": [],
  "NVML_PERF_POLICY_TOTAL_BASE_CLOCKS": [],
  "NVML_PERF_POLICY_COUNT": [],
  "_nvmlEncoderQueryType_t": [],
  "NVML_ENCODER_QUERY_H264": [],
  "NVML_ENCODER_QUERY_HEVC": [],
  "NVML_ENCODER_QUERY_AV1": [],
  "NVML_ENCODER_QUERY_UNKNOWN": [],
  "_nvmlFBCSessionType_t": [],
  "NVML_FBC_SESSION_TYPE_UNKNOWN": [],
  "NVML_FBC_SESSION_TYPE_TOSYS": [],
  "NVML_FBC_SESSION_TYPE_CUDA": [],
  "NVML_FBC_SESSION_TYPE_VID": [],
  "NVML_FBC_SESSION_TYPE_HWENC": [],
  "_nvmlDetachGpuState_t": [],
  "NVML_DETACH_GPU_KEEP": [],
  "NVML_DETACH_GPU_REMOVE": [],
  "_nvmlPcieLinkState_t": [],
  "NVML_PCIE_LINK_KEEP": [],
  "NVML_PCIE_LINK_SHUT_DOWN": [],
  "_nvmlSamplingType_t": [],
  "NVML_TOTAL_POWER_SAMPLES": [],
  "NVML_GPU_UTILIZATION_SAMPLES": [],
  "NVML_MEMORY_UTILIZATION_SAMPLES": [],
  "NVML_ENC_UTILIZATION_SAMPLES": [],
  "NVML_DEC_UTILIZATION_SAMPLES": [],
  "NVML_PROCESSOR_CLK_SAMPLES": [],
  "NVML_MEMORY_CLK_SAMPLES": [],
  "NVML_MODULE_POWER_SAMPLES": [],
  "NVML_JPG_UTILIZATION_SAMPLES": [],
  "NVML_OFA_UTILIZATION_SAMPLES": [],
  "NVML_SAMPLINGTYPE_COUNT": [],
  "_nvmlPcieUtilCounter_t": [],
  "NVML_PCIE_UTIL_TX_BYTES": [],
  "NVML_PCIE_UTIL_RX_BYTES": [],
  "NVML_PCIE_UTIL_COUNT": [],
  "_nvmlGpuTopologyLevel_t": [],
  "NVML_TOPOLOGY_INTERNAL": [],
  "NVML_TOPOLOGY_SINGLE": [],
  "NVML_TOPOLOGY_MULTIPLE": [],
  "NVML_TOPOLOGY_HOSTBRIDGE": [],
  "NVML_TOPOLOGY_NODE": [],
  "NVML_TOPOLOGY_CPU": [],
  "NVML_TOPOLOGY_SYSTEM": [],
  "_nvmlGpuP2PCapsIndex_t": [],
  "NVML_P2P_CAPS_INDEX_READ": [],
  "NVML_P2P_CAPS_INDEX_WRITE": [],
  "NVML_P2P_CAPS_INDEX_NVLINK": [],
  "NVML_P2P_CAPS_INDEX_ATOMICS": [],
  "NVML_P2P_CAPS_INDEX_PROP": [],
  "NVML_P2P_CAPS_INDEX_PCI": [],
  "NVML_P2P_CAPS_INDEX_UNKNOWN": [],
  "_nvmlGpuP2PStatus_t": [],
  "NVML_P2P_STATUS_OK": [],
  "NVML_P2P_STATUS_CHIPSET_NOT_SUPPORED": [],
  "NVML_P2P_STATUS_CHIPSET_NOT_SUPPORTED": [],
  "NVML_P2P_STATUS_GPU_NOT_SUPPORTED": [],
  "NVML_P2P_STATUS_IOH_TOPOLOGY_NOT_SUPPORTED": [],
  "NVML_P2P_STATUS_DISABLED_BY_REGKEY": [],
  "NVML_P2P_STATUS_NOT_SUPPORTED": [],
  "NVML_P2P_STATUS_UNKNOWN": [],
  "_nvmlDeviceArchitecture_t": [],
  "NVML_DEVICE_ARCH_KEPLER": [],
  "NVML_DEVICE_ARCH_MAXWELL": [],
  "NVML_DEVICE_ARCH_PASCAL": [],
  "NVML_DEVICE_ARCH_VOLTA": [],
  "NVML_DEVICE_ARCH_TURING": [],
  "NVML_DEVICE_ARCH_AMPERE": [],
  "NVML_DEVICE_ARCH_ADA": [],
  "NVML_DEVICE_ARCH_HOPPER": [],
  "NVML_DEVICE_ARCH_BLACKWELL": [],
  "NVML_DEVICE_ARCH_T23X": [],
  "NVML_DEVICE_ARCH_UNKNOWN": [],
  "_nvmlBusType_t": [],
  "NVML_BUS_TYPE_UNKNOWN": [],
  "NVML_BUS_TYPE_PCI": [],
  "NVML_BUS_TYPE_PCIE": [],
  "NVML_BUS_TYPE_FPCI": [],
  "NVML_BUS_TYPE_AGP": [],
  "_nvmlPowerSource_t": [],
  "NVML_POWER_SOURCE_AC": [],
  "NVML_POWER_SOURCE_BATTERY": [],
  "NVML_POWER_SOURCE_UNDERSIZED": [],
  "_nvmlAdaptiveClockInfoStatus_t": [],
  "NVML_ADAPTIVE_CLOCKING_INFO_STATUS_DISABLED": [],
  "NVML_ADAPTIVE_CLOCKING_INFO_STATUS_ENABLED": [],
  "_nvmlClockLimitId_t": [],
  "NVML_CLOCK_LIMIT_ID_RANGE_START": [],
  "NVML_CLOCK_LIMIT_ID_TDP": [],
  "NVML_CLOCK_LIMIT_ID_UNLIMITED": [],
  "_nvmlPcieLinkMaxSpeed_t": [],
  "NVML_PCIE_LINK_MAX_SPEED_INVALID": [],
  "NVML_PCIE_LINK_MAX_SPEED_2500MBPS": [],
  "NVML_PCIE_LINK_MAX_SPEED_5000MBPS": [],
  "NVML_PCIE_LINK_MAX_SPEED_8000MBPS": [],
  "NVML_PCIE_LINK_MAX_SPEED_16000MBPS": [],
  "NVML_PCIE_LINK_MAX_SPEED_32000MBPS": [],
  "NVML_PCIE_LINK_MAX_SPEED_64000MBPS": [],
  "_nvmlPcieAtomicsCapability_t": [],
  "NVML_PCIE_ATOMICS_CAP_FETCHADD32": [],
  "NVML_PCIE_ATOMICS_CAP_FETCHADD64": [],
  "NVML_PCIE_ATOMICS_CAP_SWAP32": [],
  "NVML_PCIE_ATOMICS_CAP_SWAP64": [],
  "NVML_PCIE_ATOMICS_CAP_CAS32": [],
  "NVML_PCIE_ATOMICS_CAP_CAS64": [],
  "NVML_PCIE_ATOMICS_CAP_CAS128": [],
  "NVML_PCIE_ATOMICS_OPS_MAX": [],
  "_nvmlAffinityScope_t": [],
  "NVML_AFFINITY_SCOPE_NODE": [],
  "NVML_AFFINITY_SCOPE_SOCKET": [],
  "_nvmlDeviceGpuRecoveryAction_t": [],
  "NVML_GPU_RECOVERY_ACTION_NONE": [],
  "NVML_GPU_RECOVERY_ACTION_GPU_RESET": [],
  "NVML_GPU_RECOVERY_ACTION_NODE_REBOOT": [],
  "NVML_GPU_RECOVERY_ACTION_DRAIN_P2P": [],
  "NVML_GPU_RECOVERY_ACTION_DRAIN_AND_RESET": [],
  "nvmlFlagDefault": [],
  "nvmlFlagForce": [],
  "NVML_INIT_FLAG_NO_GPUS": [],
  "NVML_INIT_FLAG_NO_ATTACH": [],
  "NVML_MAX_GPC_COUNT": [],
  "NVML_DEVICE_INFOROM_VERSION_BUFFER_SIZE": [],
  "NVML_DEVICE_UUID_BUFFER_SIZE": [],
  "NVML_DEVICE_UUID_V2_BUFFER_SIZE": [],
  "NVML_SYSTEM_DRIVER_VERSION_BUFFER_SIZE": [],
  "NVML_SYSTEM_NVML_VERSION_BUFFER_SIZE": [],
  "NVML_DEVICE_NAME_BUFFER_SIZE": [],
  "NVML_DEVICE_NAME_V2_BUFFER_SIZE": [],
  "NVML_DEVICE_SERIAL_BUFFER_SIZE": [],
  "NVML_DEVICE_PART_NUMBER_BUFFER_SIZE": [],
  "NVML_DEVICE_GPU_PART_NUMBER_BUFFER_SIZE": [],
  "NVML_DEVICE_VBIOS_VERSION_BUFFER_SIZE": [],
  "NVML_DEVICE_PCI_BUS_ID_BUFFER_SIZE": [],
  "NVML_DEVICE_PCI_BUS_ID_BUFFER_V2_SIZE": [],
  "NVML_GRID_LICENSE_BUFFER_SIZE": [],
  "NVML_VGPU_NAME_BUFFER_SIZE": [],
  "NVML_GRID_LICENSE_FEATURE_MAX_COUNT": [],
  "NVML_VGPU_METADATA_OPAQUE_DATA_SIZE": [],
  "NVML_VGPU_PGPU_METADATA_OPAQUE_DATA_SIZE": [],
  "NVML_DEVICE_GPU_FRU_PART_NUMBER_BUFFER_SIZE": [],
  "NVML_PERF_MODES_BUFFER_SIZE": [],
  "NVML_DEVICE_PCI_BUS_ID_LEGACY_FMT": [],
  "NVML_DEVICE_PCI_BUS_ID_FMT": [],
  "NVML_VALUE_NOT_AVAILABLE_ulonglong": [],
  "NVML_VALUE_NOT_AVAILABLE_uint": [],
  "NVML_FI_DEV_ECC_CURRENT": [],
  "NVML_FI_DEV_ECC_PENDING": [],
  "NVML_FI_DEV_ECC_SBE_VOL_TOTAL": [],
  "NVML_FI_DEV_ECC_DBE_VOL_TOTAL": [],
  "NVML_FI_DEV_ECC_SBE_AGG_TOTAL": [],
  "NVML_FI_DEV_ECC_DBE_AGG_TOTAL": [],
  "NVML_FI_DEV_ECC_SBE_VOL_L1": [],
  "NVML_FI_DEV_ECC_DBE_VOL_L1": [],
  "NVML_FI_DEV_ECC_SBE_VOL_L2": [],
  "NVML_FI_DEV_ECC_DBE_VOL_L2": [],
  "NVML_FI_DEV_ECC_SBE_VOL_DEV": [],
  "NVML_FI_DEV_ECC_DBE_VOL_DEV": [],
  "NVML_FI_DEV_ECC_SBE_VOL_REG": [],
  "NVML_FI_DEV_ECC_DBE_VOL_REG": [],
  "NVML_FI_DEV_ECC_SBE_VOL_TEX": [],
  "NVML_FI_DEV_ECC_DBE_VOL_TEX": [],
  "NVML_FI_DEV_ECC_DBE_VOL_CBU": [],
  "NVML_FI_DEV_ECC_SBE_AGG_L1": [],
  "NVML_FI_DEV_ECC_DBE_AGG_L1": [],
  "NVML_FI_DEV_ECC_SBE_AGG_L2": [],
  "NVML_FI_DEV_ECC_DBE_AGG_L2": [],
  "NVML_FI_DEV_ECC_SBE_AGG_DEV": [],
  "NVML_FI_DEV_ECC_DBE_AGG_DEV": [],
  "NVML_FI_DEV_ECC_SBE_AGG_REG": [],
  "NVML_FI_DEV_ECC_DBE_AGG_REG": [],
  "NVML_FI_DEV_ECC_SBE_AGG_TEX": [],
  "NVML_FI_DEV_ECC_DBE_AGG_TEX": [],
  "NVML_FI_DEV_ECC_DBE_AGG_CBU": [],
  "NVML_FI_DEV_RETIRED_SBE": [],
  "NVML_FI_DEV_RETIRED_DBE": [],
  "NVML_FI_DEV_RETIRED_PENDING": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L0": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L1": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L2": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L3": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L4": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L5": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_TOTAL": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L0": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L1": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L2": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L3": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L4": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L5": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_TOTAL": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L0": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L1": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L2": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L3": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L4": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L5": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_TOTAL": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L0": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L1": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L2": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L3": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L4": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L5": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_TOTAL": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L0": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L1": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L2": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L3": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L4": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L5": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_TOTAL": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L0": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L1": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L2": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L3": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L4": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L5": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_TOTAL": [],
  "NVML_FI_DEV_PERF_POLICY_POWER": [],
  "NVML_FI_DEV_PERF_POLICY_THERMAL": [],
  "NVML_FI_DEV_PERF_POLICY_SYNC_BOOST": [],
  "NVML_FI_DEV_PERF_POLICY_BOARD_LIMIT": [],
  "NVML_FI_DEV_PERF_POLICY_LOW_UTILIZATION": [],
  "NVML_FI_DEV_PERF_POLICY_RELIABILITY": [],
  "NVML_FI_DEV_PERF_POLICY_TOTAL_APP_CLOCKS": [],
  "NVML_FI_DEV_PERF_POLICY_TOTAL_BASE_CLOCKS": [],
  "NVML_FI_DEV_MEMORY_TEMP": [],
  "NVML_FI_DEV_TOTAL_ENERGY_CONSUMPTION": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L0": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L1": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L2": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L3": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L4": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L5": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_COMMON": [],
  "NVML_FI_DEV_NVLINK_LINK_COUNT": [],
  "NVML_FI_DEV_RETIRED_PENDING_SBE": [],
  "NVML_FI_DEV_RETIRED_PENDING_DBE": [],
  "NVML_FI_DEV_PCIE_REPLAY_COUNTER": [],
  "NVML_FI_DEV_PCIE_REPLAY_ROLLOVER_COUNTER": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L6": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L7": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L8": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L9": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L10": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L11": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L6": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L7": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L8": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L9": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L10": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L11": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L6": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L7": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L8": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L9": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L10": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L11": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L6": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L7": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L8": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L9": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L10": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L11": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L6": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L7": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L8": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L9": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L10": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L11": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L6": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L7": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L8": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L9": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L10": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L11": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L6": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L7": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L8": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L9": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L10": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L11": [],
  "NVML_FI_DEV_NVLINK_THROUGHPUT_DATA_TX": [],
  "NVML_FI_DEV_NVLINK_THROUGHPUT_DATA_RX": [],
  "NVML_FI_DEV_NVLINK_THROUGHPUT_RAW_TX": [],
  "NVML_FI_DEV_NVLINK_THROUGHPUT_RAW_RX": [],
  "NVML_FI_DEV_REMAPPED_COR": [],
  "NVML_FI_DEV_REMAPPED_UNC": [],
  "NVML_FI_DEV_REMAPPED_PENDING": [],
  "NVML_FI_DEV_REMAPPED_FAILURE": [],
  "NVML_FI_DEV_NVLINK_REMOTE_NVLINK_ID": [],
  "NVML_FI_DEV_NVSWITCH_CONNECTED_LINK_COUNT": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L0": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L1": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L2": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L3": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L4": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L5": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L6": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L7": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L8": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L9": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L10": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L11": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_TOTAL": [],
  "NVML_FI_DEV_NVLINK_ERROR_DL_REPLAY": [],
  "NVML_FI_DEV_NVLINK_ERROR_DL_RECOVERY": [],
  "NVML_FI_DEV_NVLINK_ERROR_DL_CRC": [],
  "NVML_FI_DEV_NVLINK_GET_SPEED": [],
  "NVML_FI_DEV_NVLINK_GET_STATE": [],
  "NVML_FI_DEV_NVLINK_GET_VERSION": [],
  "NVML_FI_DEV_NVLINK_GET_POWER_STATE": [],
  "NVML_FI_DEV_NVLINK_GET_POWER_THRESHOLD": [],
  "NVML_FI_DEV_PCIE_L0_TO_RECOVERY_COUNTER": [],
  "NVML_FI_DEV_C2C_LINK_COUNT": [],
  "NVML_FI_DEV_C2C_LINK_GET_STATUS": [],
  "NVML_FI_DEV_C2C_LINK_GET_MAX_BW": [],
  "NVML_FI_DEV_PCIE_COUNT_CORRECTABLE_ERRORS": [],
  "NVML_FI_DEV_PCIE_COUNT_NAKS_RECEIVED": [],
  "NVML_FI_DEV_PCIE_COUNT_RECEIVER_ERROR": [],
  "NVML_FI_DEV_PCIE_COUNT_BAD_TLP": [],
  "NVML_FI_DEV_PCIE_COUNT_NAKS_SENT": [],
  "NVML_FI_DEV_PCIE_COUNT_BAD_DLLP": [],
  "NVML_FI_DEV_PCIE_COUNT_NON_FATAL_ERROR": [],
  "NVML_FI_DEV_PCIE_COUNT_FATAL_ERROR": [],
  "NVML_FI_DEV_PCIE_COUNT_UNSUPPORTED_REQ": [],
  "NVML_FI_DEV_PCIE_COUNT_LCRC_ERROR": [],
  "NVML_FI_DEV_PCIE_COUNT_LANE_ERROR": [],
  "NVML_FI_DEV_IS_RESETLESS_MIG_SUPPORTED": [],
  "NVML_FI_DEV_POWER_AVERAGE": [],
  "NVML_FI_DEV_POWER_INSTANT": [],
  "NVML_FI_DEV_POWER_MIN_LIMIT": [],
  "NVML_FI_DEV_POWER_MAX_LIMIT": [],
  "NVML_FI_DEV_POWER_DEFAULT_LIMIT": [],
  "NVML_FI_DEV_POWER_CURRENT_LIMIT": [],
  "NVML_FI_DEV_ENERGY": [],
  "NVML_FI_DEV_POWER_REQUESTED_LIMIT": [],
  "NVML_FI_DEV_TEMPERATURE_SHUTDOWN_TLIMIT": [],
  "NVML_FI_DEV_TEMPERATURE_SLOWDOWN_TLIMIT": [],
  "NVML_FI_DEV_TEMPERATURE_MEM_MAX_TLIMIT": [],
  "NVML_FI_DEV_TEMPERATURE_GPU_MAX_TLIMIT": [],
  "NVML_FI_DEV_PCIE_COUNT_TX_BYTES": [],
  "NVML_FI_DEV_PCIE_COUNT_RX_BYTES": [],
  "NVML_FI_DEV_IS_MIG_MODE_INDEPENDENT_MIG_QUERY_CAPABLE": [],
  "NVML_FI_DEV_NVLINK_GET_POWER_THRESHOLD_MAX": [],
  "NVML_FI_DEV_NVLINK_COUNT_XMIT_PACKETS": [],
  "NVML_FI_DEV_NVLINK_COUNT_XMIT_BYTES": [],
  "NVML_FI_DEV_NVLINK_COUNT_RCV_PACKETS": [],
  "NVML_FI_DEV_NVLINK_COUNT_RCV_BYTES": [],
  "NVML_FI_DEV_NVLINK_COUNT_VL15_DROPPED": [],
  "NVML_FI_DEV_NVLINK_COUNT_MALFORMED_PACKET_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_BUFFER_OVERRUN_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_RCV_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_RCV_REMOTE_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_RCV_GENERAL_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_LOCAL_LINK_INTEGRITY_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_XMIT_DISCARDS": [],
  "NVML_FI_DEV_NVLINK_COUNT_LINK_RECOVERY_SUCCESSFUL_EVENTS": [],
  "NVML_FI_DEV_NVLINK_COUNT_LINK_RECOVERY_FAILED_EVENTS": [],
  "NVML_FI_DEV_NVLINK_COUNT_LINK_RECOVERY_EVENTS": [],
  "NVML_FI_DEV_NVLINK_COUNT_RAW_BER_LANE0": [],
  "NVML_FI_DEV_NVLINK_COUNT_RAW_BER_LANE1": [],
  "NVML_FI_DEV_NVLINK_COUNT_RAW_BER": [],
  "NVML_FI_DEV_NVLINK_COUNT_EFFECTIVE_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_EFFECTIVE_BER": [],
  "NVML_FI_DEV_NVLINK_COUNT_SYMBOL_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_SYMBOL_BER": [],
  "NVML_FI_DEV_NVLINK_GET_POWER_THRESHOLD_MIN": [],
  "NVML_FI_DEV_NVLINK_GET_POWER_THRESHOLD_UNITS": [],
  "NVML_FI_DEV_NVLINK_GET_POWER_THRESHOLD_SUPPORTED": [],
  "NVML_FI_DEV_RESET_STATUS": [],
  "NVML_FI_DEV_DRAIN_AND_RESET_STATUS": [],
  "NVML_FI_DEV_PCIE_OUTBOUND_ATOMICS_MASK": [],
  "NVML_FI_DEV_PCIE_INBOUND_ATOMICS_MASK": [],
  "NVML_FI_DEV_GET_GPU_RECOVERY_ACTION": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_0": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_1": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_2": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_3": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_4": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_5": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_6": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_7": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_8": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_9": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_10": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_11": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_12": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_13": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_14": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_15": [],
  "NVML_FI_PWR_SMOOTHING_ENABLED": [],
  "NVML_FI_PWR_SMOOTHING_PRIV_LVL": [],
  "NVML_FI_PWR_SMOOTHING_IMM_RAMP_DOWN_ENABLED": [],
  "NVML_FI_PWR_SMOOTHING_APPLIED_TMP_CEIL": [],
  "NVML_FI_PWR_SMOOTHING_APPLIED_TMP_FLOOR": [],
  "NVML_FI_PWR_SMOOTHING_MAX_PERCENT_TMP_FLOOR_SETTING": [],
  "NVML_FI_PWR_SMOOTHING_MIN_PERCENT_TMP_FLOOR_SETTING": [],
  "NVML_FI_PWR_SMOOTHING_HW_CIRCUITRY_PERCENT_LIFETIME_REMAINING": [],
  "NVML_FI_PWR_SMOOTHING_MAX_NUM_PRESET_PROFILES": [],
  "NVML_FI_PWR_SMOOTHING_PROFILE_PERCENT_TMP_FLOOR": [],
  "NVML_FI_PWR_SMOOTHING_PROFILE_RAMP_UP_RATE": [],
  "NVML_FI_PWR_SMOOTHING_PROFILE_RAMP_DOWN_RATE": [],
  "NVML_FI_PWR_SMOOTHING_PROFILE_RAMP_DOWN_HYST_VAL": [],
  "NVML_FI_PWR_SMOOTHING_ACTIVE_PRESET_PROFILE": [],
  "NVML_FI_PWR_SMOOTHING_ADMIN_OVERRIDE_PERCENT_TMP_FLOOR": [],
  "NVML_FI_PWR_SMOOTHING_ADMIN_OVERRIDE_RAMP_UP_RATE": [],
  "NVML_FI_PWR_SMOOTHING_ADMIN_OVERRIDE_RAMP_DOWN_RATE": [],
  "NVML_FI_PWR_SMOOTHING_ADMIN_OVERRIDE_RAMP_DOWN_HYST_VAL": [],
  "NVML_FI_MAX": [],
  "NVML_NVLINK_STATE_INACTIVE": [],
  "NVML_NVLINK_STATE_ACTIVE": [],
  "NVML_NVLINK_STATE_SLEEP": [],
  "NVML_NVLINK_LOW_POWER_THRESHOLD_UNIT_100US": [],
  "NVML_NVLINK_LOW_POWER_THRESHOLD_UNIT_50US": [],
  "NVML_GPU_VIRTUALIZATION_MODE_NONE": [],
  "NVML_GPU_VIRTUALIZATION_MODE_PASSTHROUGH": [],
  "NVML_GPU_VIRTUALIZATION_MODE_VGPU": [],
  "NVML_GPU_VIRTUALIZATION_MODE_HOST_VGPU": [],
  "NVML_GPU_VIRTUALIZATION_MODE_HOST_VSGA": [],
  "nvmlLib": [],
  "libLoadLock": [],
  "_nvmlLib_refcount": [],
  "_nvmlVgpuTypeId_t": [],
  "_nvmlVgpuInstance_t": [],
  "_nvmlVgpuVmIdType_t": [],
  "NVML_VGPU_VM_ID_DOMAIN_ID": [],
  "NVML_VGPU_VM_ID_UUID": [],
  "_nvmlGridLicenseFeatureCode_t": [],
  "NVML_GRID_LICENSE_FEATURE_CODE_UNKNOWN": [],
  "NVML_GRID_LICENSE_FEATURE_CODE_VGPU": [],
  "NVML_GRID_LICENSE_FEATURE_CODE_NVIDIA_RTX": [],
  "NVML_GRID_LICENSE_FEATURE_CODE_VWORKSTATION": [],
  "NVML_GRID_LICENSE_FEATURE_CODE_GAMING": [],
  "NVML_GRID_LICENSE_FEATURE_CODE_COMPUTE": [],
  "_nvmlGridLicenseExpiryStatus_t": [],
  "NVML_GRID_LICENSE_EXPIRY_NOT_AVAILABLE": [],
  "NVML_GRID_LICENSE_EXPIRY_INVALID": [],
  "NVML_GRID_LICENSE_EXPIRY_VALID": [],
  "NVML_GRID_LICENSE_EXPIRY_NOT_APPLICABLE": [],
  "NVML_GRID_LICENSE_EXPIRY_PERMANENT": [],
  "_nvmlVgpuCapability_t": [],
  "NVML_VGPU_CAP_NVLINK_P2P": [],
  "NVML_VGPU_CAP_GPUDIRECT": [],
  "NVML_VGPU_CAP_MULTI_VGPU_EXCLUSIVE": [],
  "NVML_VGPU_CAP_EXCLUSIVE_TYPE": [],
  "NVML_VGPU_CAP_EXCLUSIVE_SIZE": [],
  "NVML_VGPU_CAP_COUNT": [],
  "_nvmlVgpuDriverCapability_t": [],
  "NVML_VGPU_DRIVER_CAP_HETEROGENEOUS_MULTI_VGPU": [],
  "NVML_VGPU_DRIVER_CAP_WARM_UPDATE": [],
  "NVML_VGPU_DRIVER_CAP_COUNT": [],
  "_nvmlDeviceVgpuCapability_t": [],
  "NVML_DEVICE_VGPU_CAP_FRACTIONAL_MULTI_VGPU": [],
  "NVML_DEVICE_VGPU_CAP_HETEROGENEOUS_TIMESLICE_PROFILES": [],
  "NVML_DEVICE_VGPU_CAP_HETEROGENEOUS_TIMESLICE_SIZES": [],
  "NVML_DEVICE_VGPU_CAP_READ_DEVICE_BUFFER_BW": [],
  "NVML_DEVICE_VGPU_CAP_WRITE_DEVICE_BUFFER_BW": [],
  "NVML_DEVICE_VGPU_CAP_DEVICE_STREAMING": [],
  "NVML_DEVICE_VGPU_CAP_MINI_QUARTER_GPU": [],
  "NVML_DEVICE_VGPU_CAP_COMPUTE_MEDIA_ENGINE_GPU": [],
  "NVML_DEVICE_VGPU_CAP_WARM_UPDATE": [],
  "NVML_DEVICE_VGPU_CAP_HOMOGENEOUS_PLACEMENTS": [],
  "NVML_DEVICE_VGPU_CAP_COUNT": [],
  "_nvmlVgpuGuestInfoState_t": [],
  "NVML_VGPU_INSTANCE_GUEST_INFO_STATE_UNINITIALIZED": [],
  "NVML_VGPU_INSTANCE_GUEST_INFO_STATE_INITIALIZED": [],
  "_nvmlVgpuVmCompatibility_t": [],
  "NVML_VGPU_VM_COMPATIBILITY_NONE": [],
  "NVML_VGPU_VM_COMPATIBILITY_COLD": [],
  "NVML_VGPU_VM_COMPATIBILITY_HIBERNATE": [],
  "NVML_VGPU_VM_COMPATIBILITY_SLEEP": [],
  "NVML_VGPU_VM_COMPATIBILITY_LIVE": [],
  "_nvmlVgpuPgpuCompatibilityLimitCode_t": [],
  "NVML_VGPU_COMPATIBILITY_LIMIT_NONE": [],
  "NVML_VGPU_COMPATIBILITY_LIMIT_HOST_DRIVER": [],
  "NVML_VGPU_COMPATIBILITY_LIMIT_GUEST_DRIVER": [],
  "NVML_VGPU_COMPATIBILITY_LIMIT_GPU": [],
  "NVML_VGPU_COMPATIBILITY_LIMIT_OTHER": [],
  "_nvmlHostVgpuMode_t": [],
  "NVML_HOST_VGPU_MODE_NON_SRIOV": [],
  "NVML_HOST_VGPU_MODE_SRIOV": [],
  "_nvmlConfComputeGpusReadyState_t": [],
  "NVML_CC_ACCEPTING_CLIENT_REQUESTS_FALSE": [],
  "NVML_CC_ACCEPTING_CLIENT_REQUESTS_TRUE": [],
  "_nvmlConfComputeGpuCaps_t": [],
  "NVML_CC_SYSTEM_GPUS_CC_NOT_CAPABLE": [],
  "NVML_CC_SYSTEM_GPUS_CC_CAPABLE": [],
  "_nvmlConfComputeCpuCaps_t": [],
  "NVML_CC_SYSTEM_CPU_CAPS_NONE": [],
  "NVML_CC_SYSTEM_CPU_CAPS_AMD_SEV": [],
  "NVML_CC_SYSTEM_CPU_CAPS_INTEL_TDX": [],
  "NVML_CC_SYSTEM_CPU_CAPS_AMD_SEV_SNP": [],
  "NVML_CC_SYSTEM_CPU_CAPS_AMD_SNP_VTOM": [],
  "_nvmlConfComputeDevToolsMode_t": [],
  "NVML_CC_SYSTEM_DEVTOOLS_MODE_OFF": [],
  "NVML_CC_SYSTEM_DEVTOOLS_MODE_ON": [],
  "NVML_CC_SYSTEM_MULTIGPU_NONE": [],
  "NVML_CC_SYSTEM_MULTIGPU_PROTECTED_PCIE": [],
  "NVML_CC_SYSTEM_ENVIRONMENT_UNAVAILABLE": [],
  "NVML_CC_SYSTEM_ENVIRONMENT_SIM": [],
  "NVML_CC_SYSTEM_ENVIRONMENT_PROD": [],
  "_nvmlConfComputeCcFeature_t": [],
  "NVML_CC_SYSTEM_FEATURE_DISABLED": [],
  "NVML_CC_SYSTEM_FEATURE_ENABLED": [],
  "_nvmlConfComputeCcKeyRotationThreshAttackerAdv_t": [],
  "NVML_CC_KEY_ROTATION_THRESH_ATTACKER_ADVANTAGE_MIN": [],
  "NVML_CC_KEY_ROTATION_THRESH_ATTACKER_ADVANTAGE_MAX": [],
  "NVML_GSP_FIRMWARE_VERSION_BUF_SIZE": [],
  "NVMLLibraryMismatchError": {},
  "NVMLError": {
    "_valClassMapping": [],
    "_errcode_to_string": [],
    "__new__": [
      "typ",
      "value"
    ],
    "__str__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ]
  },
  "nvmlExceptionClass": [
    "nvmlErrorCode"
  ],
  "_extractNVMLErrorsAsClasses": [],
  "_nvmlCheckReturn": [
    "ret"
  ],
  "_nvmlGetFunctionPointer_cache": [],
  "_nvmlGetFunctionPointer": [
    "name"
  ],
  "nvmlFriendlyObject": {
    "__init__": [
      "self",
      "dictionary"
    ],
    "__str__": [
      "self"
    ]
  },
  "nvmlStructToFriendlyObject": [
    "struct"
  ],
  "nvmlFriendlyObjectToStruct": [
    "obj",
    "model"
  ],
  "struct_c_nvmlUnit_t": {},
  "c_nvmlUnit_t": [],
  "_PrintableStructure": {
    "_fmt_": [],
    "__str__": [
      "self"
    ],
    "__getattribute__": [
      "self",
      "name"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ]
  },
  "c_nvmlUnitInfo_t": {
    "_fields_": []
  },
  "c_nvmlC2cModeInfo_v1_t": {
    "_fields_": []
  },
  "nvmlC2cModeInfo_v1": [],
  "c_nvmlLedState_t": {
    "_fields_": []
  },
  "c_nvmlPSUInfo_t": {
    "_fields_": []
  },
  "c_nvmlUnitFanInfo_t": {
    "_fields_": []
  },
  "c_nvmlUnitFanSpeeds_t": {
    "_fields_": []
  },
  "struct_c_nvmlDevice_t": {},
  "c_nvmlDevice_t": [],
  "nvmlPciInfoExt_v1_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "nvmlPciInfoExt_v1": [],
  "nvmlPciInfo_v2_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "nvmlPciInfo_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "c_nvmlSystemDriverBranchInfo_v1_t": {
    "_fields_": []
  },
  "SystemDriverBranchInfo_v1": [],
  "c_nvmlExcludedDeviceInfo_t": {
    "_fields_": []
  },
  "nvmlNvLinkUtilizationControl_t": {
    "_fields_": []
  },
  "c_nvmlMemory_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "c_nvmlMemory_v2_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "nvmlMemory_v2": [],
  "c_nvmlBAR1Memory_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "nvmlClkMonFaultInfo_t": {
    "_fields_": []
  },
  "MAX_CLK_DOMAINS": [],
  "nvmlClkMonStatus_t": {
    "_fields_": []
  },
  "c_nvmlProcessInfo_v2_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "c_nvmlProcessInfo_v3_t": [],
  "c_nvmlProcessInfo_t": [],
  "_nvmlProcessMode_t": [],
  "NVML_PROCESS_MODE_COMPUTE": [],
  "NVML_PROCESS_MODE_GRAPHICS": [],
  "NVML_PROCESS_MODE_MPS": [],
  "c_nvmlProcessDetail_v1_t": {
    "_fields_": []
  },
  "c_nvmlProcessDetailList_v1_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "c_nvmlProcessDetailList_t": [],
  "nvmlProcessDetailList_v1": [],
  "c_nvmlBridgeChipInfo_t": {
    "_fields_": []
  },
  "c_nvmlBridgeChipHierarchy_t": {
    "_fields_": []
  },
  "c_nvmlEccErrorCounts_t": {
    "_fields_": []
  },
  "c_nvmlUtilization_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "c_nvmlHwbcEntry_t": {
    "_fields_": []
  },
  "c_nvmlValue_t": {
    "_fields_": []
  },
  "c_nvmlSample_t": {
    "_fields_": []
  },
  "c_nvmlViolationTime_t": {
    "_fields_": []
  },
  "c_nvmlFieldValue_t": {
    "_fields_": []
  },
  "NVML_NVLINK_TOTAL_SUPPORTED_BW_MODES": [],
  "nvmlNvlinkSupportedBwModes_v1": [],
  "c_nvmlNvlinkSupportedBwModes_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlNvlinkGetBwMode_v1": [],
  "c_nvmlNvlinkGetBwMode_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlNvlinkSetBwMode_v1": [],
  "c_nvmlNvlinkSetBwMode_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "c_nvmlVgpuHeterogeneousMode_v1_t": {
    "_fields_": []
  },
  "VgpuHeterogeneousMode_v1": [],
  "c_nvmlVgpuPlacementId_v1_t": {
    "_fields_": []
  },
  "VgpuPlacementId_v1": [],
  "c_nvmlVgpuPlacementList_v1_t": {
    "_fields_": []
  },
  "VgpuPlacementList_v1": [],
  "NVML_VGPU_PGPU_HETEROGENEOUS_MODE": [],
  "NVML_VGPU_PGPU_HOMOGENEOUS_MODE": [],
  "c_nvmlVgpuPlacementList_v2_t": {
    "_fields_": []
  },
  "VgpuPlacementList_v2": [],
  "c_nvmlVgpuTypeBar1Info_v1_t": {
    "_fields_": []
  },
  "VgpuTypeBar1Info_v1": [],
  "c_nvmlVgpuInstanceUtilizationSample_t": {
    "_fields_": []
  },
  "c_nvmlVgpuInstanceUtilizationInfo_v1_t": {
    "_fields_": []
  },
  "c_nvmlVgpuInstancesUtilizationInfo_v1_t": {
    "_fields_": []
  },
  "VgpuInstancesUtilizationInfo_v1": [],
  "c_nvmlVgpuProcessUtilizationSample_t": {
    "_fields_": []
  },
  "c_nvmlVgpuProcessUtilizationInfo_v1_t": {
    "_fields_": []
  },
  "c_nvmlVgpuProcessesUtilizationInfo_v1_t": {
    "_fields_": []
  },
  "VgpuProcessesUtilizationInfo_v1": [],
  "nvmlVgpuRuntimeState_v1_t": {
    "_fields_": []
  },
  "VgpuRuntimeState_v1": [],
  "c_nvmlVgpuLicenseExpiry_t": {
    "_fields_": []
  },
  "NVML_GRID_LICENSE_STATE_UNKNOWN": [],
  "NVML_GRID_LICENSE_STATE_UNINITIALIZED": [],
  "NVML_GRID_LICENSE_STATE_UNLICENSED_UNRESTRICTED": [],
  "NVML_GRID_LICENSE_STATE_UNLICENSED_RESTRICTED": [],
  "NVML_GRID_LICENSE_STATE_UNLICENSED": [],
  "NVML_GRID_LICENSE_STATE_LICENSED": [],
  "c_nvmlVgpuLicenseInfo_t": {
    "_fields_": []
  },
  "c_nvmlEncoderSession_t": {
    "_fields_": []
  },
  "c_nvmlProcessUtilizationSample_t": {
    "_fields_": []
  },
  "c_nvmlProcessUtilizationInfo_v1_t": {
    "_fields_": []
  },
  "c_nvmlProcessesUtilizationInfo_v1_t": {
    "_fields_": []
  },
  "ProcessesUtilizationInfo_v1": [],
  "c_nvmlGridLicenseExpiry_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeature_v4_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeatures_v4_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeature_v3_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeatures_v3_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeature_v2_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeatures_v2_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeature_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeatures_t": {
    "_fields_": []
  },
  "c_nvmlMarginTemperature_v1_t": {
    "_fields_": []
  },
  "nvmlMarginTemperature_v1": [],
  "struct_c_nvmlEventSet_t": {},
  "c_nvmlEventSet_t": [],
  "nvmlEventTypeSingleBitEccError": [],
  "nvmlEventTypeDoubleBitEccError": [],
  "nvmlEventTypePState": [],
  "nvmlEventTypeXidCriticalError": [],
  "nvmlEventTypeClock": [],
  "nvmlEventTypePowerSourceChange": [],
  "nvmlEventMigConfigChange": [],
  "nvmlEventTypeSingleBitEccErrorStorm": [],
  "nvmlEventTypeDramRetirementEvent": [],
  "nvmlEventTypeDramRetirementFailure": [],
  "nvmlEventTypeNonFatalPoisonError": [],
  "nvmlEventTypeFatalPoisonError": [],
  "nvmlEventTypeGpuUnavailableError": [],
  "nvmlEventTypeGpuRecoveryAction": [],
  "nvmlEventTypeNone": [],
  "nvmlEventTypeAll": [],
  "nvmlClocksEventReasonGpuIdle": [],
  "nvmlClocksEventReasonApplicationsClocksSetting": [],
  "nvmlClocksEventReasonUserDefinedClocks": [],
  "nvmlClocksEventReasonSwPowerCap": [],
  "nvmlClocksEventReasonHwSlowdown": [],
  "nvmlClocksEventReasonSyncBoost": [],
  "nvmlClocksEventReasonSwThermalSlowdown": [],
  "nvmlClocksEventReasonHwThermalSlowdown": [],
  "nvmlClocksEventReasonHwPowerBrakeSlowdown": [],
  "nvmlClocksEventReasonDisplayClockSetting": [],
  "nvmlClocksEventReasonNone": [],
  "nvmlClocksEventReasonAll": [],
  "nvmlClocksThrottleReasonGpuIdle": [],
  "nvmlClocksThrottleReasonApplicationsClocksSetting": [],
  "nvmlClocksThrottleReasonUserDefinedClocks": [],
  "nvmlClocksThrottleReasonSwPowerCap": [],
  "nvmlClocksThrottleReasonHwSlowdown": [],
  "nvmlClocksThrottleReasonSyncBoost": [],
  "nvmlClocksThrottleReasonSwThermalSlowdown": [],
  "nvmlClocksThrottleReasonHwThermalSlowdown": [],
  "nvmlClocksThrottleReasonHwPowerBrakeSlowdown": [],
  "nvmlClocksThrottleReasonDisplayClockSetting": [],
  "nvmlClocksThrottleReasonNone": [],
  "nvmlClocksThrottleReasonAll": [],
  "c_nvmlEventData_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "c_nvmlAccountingStats_t": {
    "_fields_": []
  },
  "c_nvmlVgpuVersion_t": {
    "_fields_": []
  },
  "c_nvmlVgpuMetadata_t": {
    "_fields_": []
  },
  "c_nvmlVgpuPgpuMetadata_t": {
    "_fields_": []
  },
  "c_nvmlVgpuPgpuCompatibility_t": {
    "_fields_": []
  },
  "NVML_VGPU_SCHEDULER_POLICY_UNKNOWN": [],
  "NVML_VGPU_SCHEDULER_POLICY_BEST_EFFORT": [],
  "NVML_VGPU_SCHEDULER_POLICY_EQUAL_SHARE": [],
  "NVML_VGPU_SCHEDULER_POLICY_FIXED_SHARE": [],
  "NVML_SUPPORTED_VGPU_SCHEDULER_POLICY_COUNT": [],
  "NVML_SCHEDULER_SW_MAX_LOG_ENTRIES": [],
  "NVML_VGPU_SCHEDULER_ARR_DEFAULT": [],
  "NVML_VGPU_SCHEDULER_ARR_DISABLE": [],
  "NVML_VGPU_SCHEDULER_ARR_ENABLE": [],
  "c_nvmlVgpuSchedDataWithARR_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedData_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerParams_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerLogEntry_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerLog_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerGetState_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedSetDataWithARR_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedSetData_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerSetParams_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerSetState_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerCapabilities_t": {
    "_fields_": []
  },
  "c_nvmlFBCStats_t": {
    "_fields_": []
  },
  "c_nvmlFBCSession_t": {
    "_fields_": []
  },
  "NVML_DEVICE_MIG_DISABLE": [],
  "NVML_DEVICE_MIG_ENABLE": [],
  "NVML_GPU_INSTANCE_PROFILE_1_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_2_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_3_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_4_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_7_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_8_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_6_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_1_SLICE_REV1": [],
  "NVML_GPU_INSTANCE_PROFILE_2_SLICE_REV1": [],
  "NVML_GPU_INSTANCE_PROFILE_1_SLICE_REV2": [],
  "NVML_GPU_INSTANCE_PROFILE_1_SLICE_GFX": [],
  "NVML_GPU_INSTANCE_PROFILE_2_SLICE_GFX": [],
  "NVML_GPU_INSTANCE_PROFILE_4_SLICE_GFX": [],
  "NVML_GPU_INSTANCE_PROFILE_COUNT": [],
  "c_nvmlGpuInstancePlacement_t": {
    "_fields_": []
  },
  "c_nvmlGpuInstanceProfileInfo_t": {
    "_fields_": []
  },
  "nvmlGpuInstanceProfileInfo_v2": [],
  "c_nvmlGpuInstanceProfileInfo_v2_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "c_nvmlGpuInstanceInfo_t": {
    "_fields_": []
  },
  "struct_c_nvmlGpuInstance_t": {},
  "c_nvmlGpuInstance_t": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_1_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_2_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_3_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_4_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_7_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_8_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_6_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_1_SLICE_REV1": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_COUNT": [],
  "NVML_COMPUTE_INSTANCE_ENGINE_PROFILE_SHARED": [],
  "NVML_COMPUTE_INSTANCE_ENGINE_PROFILE_COUNT": [],
  "c_nvmlComputeInstancePlacement_t": {
    "_fields_": []
  },
  "c_nvmlComputeInstanceProfileInfo_t": {
    "_fields_": []
  },
  "nvmlComputeInstanceProfileInfo_v2": [],
  "c_nvmlComputeInstanceProfileInfo_v2_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "c_nvmlComputeInstanceInfo_t": {
    "_fields_": []
  },
  "NVML_MAX_GPU_UTILIZATIONS": [],
  "NVML_GPU_UTILIZATION_DOMAIN_GPU": [],
  "NVML_GPU_UTILIZATION_DOMAIN_FB": [],
  "NVML_GPU_UTILIZATION_DOMAIN_VID": [],
  "NVML_GPU_UTILIZATION_DOMAIN_BUS": [],
  "c_nvmlGpuDynamicPstatesUtilization_t": {
    "_fields_": []
  },
  "c_nvmlGpuDynamicPstatesInfo_t": {
    "_fields_": []
  },
  "NVML_MAX_THERMAL_SENSORS_PER_GPU": [],
  "NVML_THERMAL_TARGET_NONE": [],
  "NVML_THERMAL_TARGET_GPU": [],
  "NVML_THERMAL_TARGET_MEMORY": [],
  "NVML_THERMAL_TARGET_POWER_SUPPLY": [],
  "NVML_THERMAL_TARGET_BOARD": [],
  "NVML_THERMAL_TARGET_VCD_BOARD": [],
  "NVML_THERMAL_TARGET_VCD_INLET": [],
  "NVML_THERMAL_TARGET_VCD_OUTLET": [],
  "NVML_THERMAL_TARGET_ALL": [],
  "NVML_THERMAL_TARGET_UNKNOWN": [],
  "NVML_THERMAL_CONTROLLER_NONE": [],
  "NVML_THERMAL_CONTROLLER_GPU_INTERNAL": [],
  "NVML_THERMAL_CONTROLLER_ADM1032": [],
  "NVML_THERMAL_CONTROLLER_ADT7461": [],
  "NVML_THERMAL_CONTROLLER_MAX6649": [],
  "NVML_THERMAL_CONTROLLER_MAX1617": [],
  "NVML_THERMAL_CONTROLLER_LM99": [],
  "NVML_THERMAL_CONTROLLER_LM89": [],
  "NVML_THERMAL_CONTROLLER_LM64": [],
  "NVML_THERMAL_CONTROLLER_G781": [],
  "NVML_THERMAL_CONTROLLER_ADT7473": [],
  "NVML_THERMAL_CONTROLLER_SBMAX6649": [],
  "NVML_THERMAL_CONTROLLER_VBIOSEVT": [],
  "NVML_THERMAL_CONTROLLER_OS": [],
  "NVML_THERMAL_CONTROLLER_NVSYSCON_CANOAS": [],
  "NVML_THERMAL_CONTROLLER_NVSYSCON_E551": [],
  "NVML_THERMAL_CONTROLLER_MAX6649R": [],
  "NVML_THERMAL_CONTROLLER_ADT7473S": [],
  "NVML_THERMAL_CONTROLLER_UNKNOWN": [],
  "c_nvmlGpuThermalSensor_t": {
    "_fields_": []
  },
  "c_nvmlGpuThermalSettings_t": {
    "_fields_": []
  },
  "_nvmlCoolerControl_t": [],
  "NVML_THERMAL_COOLER_SIGNAL_NONE": [],
  "NVML_THERMAL_COOLER_SIGNAL_TOGGLE": [],
  "NVML_THERMAL_COOLER_SIGNAL_VARIABLE": [],
  "NVML_THERMAL_COOLER_SIGNAL_COUNT": [],
  "_nvmlCoolerTarget_t": [],
  "NVML_THERMAL_COOLER_TARGET_NONE": [],
  "NVML_THERMAL_COOLER_TARGET_GPU": [],
  "NVML_THERMAL_COOLER_TARGET_MEMORY": [],
  "NVML_THERMAL_COOLER_TARGET_POWER_SUPPLY": [],
  "NVML_THERMAL_COOLER_TARGET_GPU_RELATED": [],
  "c_nvmlCoolerInfo_t": {
    "_fields_": []
  },
  "nvmlCoolerInfo_v1": [],
  "nvmlDeviceGetCoolerInfo": [
    "handle"
  ],
  "struct_c_nvmlComputeInstance_t": {},
  "c_nvmlComputeInstance_t": [],
  "c_nvmlDeviceAttributes": {
    "_fields_": []
  },
  "c_nvmlRowRemapperHistogramValues": {
    "_fields_": []
  },
  "NVML_GPU_CERT_CHAIN_SIZE": [],
  "NVML_GPU_ATTESTATION_CERT_CHAIN_SIZE": [],
  "NVML_CC_GPU_CEC_NONCE_SIZE": [],
  "NVML_CC_GPU_ATTESTATION_REPORT_SIZE": [],
  "NVML_CC_GPU_CEC_ATTESTATION_REPORT_SIZE": [],
  "NVML_CC_CEC_ATTESTATION_REPORT_NOT_PRESENT": [],
  "NVML_CC_CEC_ATTESTATION_REPORT_PRESENT": [],
  "c_nvmlConfComputeSystemState_t": {
    "_fields_": []
  },
  "nvmlSystemConfComputeSettings_v1": [],
  "c_nvmlSystemConfComputeSettings_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "c_nvmlConfComputeSystemCaps_t": {
    "_fields_": []
  },
  "c_nvmlConfComputeMemSizeInfo_t": {
    "_fields_": []
  },
  "c_nvmlConfComputeGpuCertificate_t": {
    "_fields_": []
  },
  "c_nvmlConfComputeGpuAttestationReport_t": {
    "_fields_": []
  },
  "c_nvmlConfComputeSetKeyRotationThresholdInfo_t": {
    "_fields_": []
  },
  "ConfComputeSetKeyRotationThresholdInfo_v1": [],
  "c_nvmlConfComputeGetKeyRotationThresholdInfo_t": {
    "_fields_": []
  },
  "ConfComputeGetKeyRotationThresholdInfo_v1": [],
  "convertStrBytes": [
    "func"
  ],
  "throwOnVersionMismatch": [
    "func"
  ],
  "nvmlInitWithFlags": [
    "flags"
  ],
  "nvmlInit": [],
  "_LoadNvmlLibrary": [],
  "nvmlShutdown": [],
  "nvmlErrorString": [
    "result"
  ],
  "nvmlSystemGetNVMLVersion": [],
  "nvmlSystemGetCudaDriverVersion": [],
  "nvmlSystemGetCudaDriverVersion_v2": [],
  "nvmlSystemGetProcessName": [
    "pid"
  ],
  "nvmlSystemGetDriverVersion": [],
  "nvmlSystemGetHicVersion": [],
  "nvmlSystemGetDriverBranch": [],
  "nvmlUnitGetCount": [],
  "nvmlUnitGetHandleByIndex": [
    "index"
  ],
  "nvmlUnitGetUnitInfo": [
    "unit"
  ],
  "nvmlUnitGetLedState": [
    "unit"
  ],
  "nvmlUnitGetPsuInfo": [
    "unit"
  ],
  "nvmlUnitGetTemperature": [
    "unit",
    "type"
  ],
  "nvmlUnitGetFanSpeedInfo": [
    "unit"
  ],
  "nvmlUnitGetDeviceCount": [
    "unit"
  ],
  "nvmlUnitGetDevices": [
    "unit"
  ],
  "nvmlDeviceGetCount": [],
  "nvmlDeviceGetHandleByIndex": [
    "index"
  ],
  "nvmlDeviceGetHandleBySerial": [
    "serial"
  ],
  "nvmlDeviceGetHandleByUUID": [
    "uuid"
  ],
  "nvmlDeviceGetHandleByPciBusId": [
    "pciBusId"
  ],
  "nvmlDeviceGetName": [
    "handle"
  ],
  "c_nvmlDevicePerfModes_v1_t": {
    "_fields_": []
  },
  "nvmlDevicePerfModes_v1": [],
  "nvmlDeviceGetPerformanceModes": [
    "handle"
  ],
  "c_nvmlDeviceCurrentClockFreqs_v1_t": {
    "_fields_": []
  },
  "nvmlDeviceCurrentClockFreqs_v1": [],
  "nvmlDeviceGetCurrentClockFreqs": [
    "handle"
  ],
  "nvmlDeviceGetBoardId": [
    "handle"
  ],
  "nvmlDeviceGetMultiGpuBoard": [
    "handle"
  ],
  "nvmlDeviceGetBrand": [
    "handle"
  ],
  "nvmlDeviceGetC2cModeInfoV1": [
    "handle"
  ],
  "nvmlDeviceGetC2cModeInfoV": [
    "handle"
  ],
  "nvmlDeviceGetBoardPartNumber": [
    "handle"
  ],
  "nvmlDeviceGetSerial": [
    "handle"
  ],
  "nvmlDeviceGetModuleId": [
    "handle",
    "moduleId"
  ],
  "nvmlDeviceGetMemoryAffinity": [
    "handle",
    "nodeSetSize",
    "scope"
  ],
  "nvmlDeviceGetCpuAffinityWithinScope": [
    "handle",
    "cpuSetSize",
    "scope"
  ],
  "nvmlDeviceGetCpuAffinity": [
    "handle",
    "cpuSetSize"
  ],
  "nvmlDeviceSetCpuAffinity": [
    "handle"
  ],
  "nvmlDeviceClearCpuAffinity": [
    "handle"
  ],
  "nvmlDeviceGetNumaNodeId": [
    "handle"
  ],
  "nvmlDeviceGetMinorNumber": [
    "handle"
  ],
  "nvmlDeviceGetUUID": [
    "handle"
  ],
  "nvmlDeviceGetInforomVersion": [
    "handle",
    "infoRomObject"
  ],
  "nvmlDeviceGetInforomImageVersion": [
    "handle"
  ],
  "nvmlDeviceGetInforomConfigurationChecksum": [
    "handle"
  ],
  "nvmlDeviceValidateInforom": [
    "handle"
  ],
  "nvmlDeviceGetLastBBXFlushTime": [
    "handle"
  ],
  "nvmlDeviceGetDisplayMode": [
    "handle"
  ],
  "nvmlDeviceGetDisplayActive": [
    "handle"
  ],
  "nvmlDeviceGetPersistenceMode": [
    "handle"
  ],
  "nvmlDeviceGetPciInfoExt": [
    "handle",
    "c_info"
  ],
  "nvmlDeviceGetPciInfo_v3": [
    "handle"
  ],
  "nvmlDeviceGetPciInfo": [
    "handle"
  ],
  "nvmlDeviceGetClockInfo": [
    "handle",
    "type"
  ],
  "nvmlDeviceGetMaxClockInfo": [
    "handle",
    "type"
  ],
  "nvmlDeviceGetApplicationsClock": [
    "handle",
    "type"
  ],
  "nvmlDeviceGetMaxCustomerBoostClock": [
    "handle",
    "type"
  ],
  "nvmlDeviceGetClock": [
    "handle",
    "type",
    "id"
  ],
  "nvmlDeviceGetDefaultApplicationsClock": [
    "handle",
    "type"
  ],
  "nvmlDeviceGetSupportedMemoryClocks": [
    "handle"
  ],
  "nvmlDeviceGetSupportedGraphicsClocks": [
    "handle",
    "memoryClockMHz"
  ],
  "nvmlDeviceGetFanSpeed": [
    "handle"
  ],
  "nvmlDeviceGetFanSpeed_v2": [
    "handle",
    "fan"
  ],
  "c_nvmlFanSpeedInfo_t": {
    "_fields_": []
  },
  "nvmlFanSpeedInfo_v1": [],
  "nvmlDeviceGetFanSpeedRPM": [
    "handle"
  ],
  "nvmlDeviceGetTargetFanSpeed": [
    "handle",
    "fan"
  ],
  "nvmlDeviceGetNumFans": [
    "device"
  ],
  "nvmlDeviceSetDefaultFanSpeed_v2": [
    "handle",
    "index"
  ],
  "nvmlDeviceGetMinMaxFanSpeed": [
    "handle",
    "minSpeed",
    "maxSpeed"
  ],
  "nvmlDeviceGetFanControlPolicy_v2": [
    "handle",
    "fan",
    "fanControlPolicy"
  ],
  "nvmlDeviceSetFanControlPolicy": [
    "handle",
    "fan",
    "fanControlPolicy"
  ],
  "c_nvmlTemperature_v1_t": {
    "_fields_": []
  },
  "nvmlTemperature_v1": [],
  "nvmlDeviceGetTemperatureV1": [
    "handle",
    "sensor"
  ],
  "nvmlDeviceGetTemperatureV": [
    "handle",
    "sensor",
    "version"
  ],
  "nvmlDeviceGetTemperature": [
    "handle",
    "sensor"
  ],
  "nvmlDeviceGetTemperatureThreshold": [
    "handle",
    "threshold"
  ],
  "nvmlDeviceSetTemperatureThreshold": [
    "handle",
    "threshold",
    "temp"
  ],
  "nvmlDeviceGetMarginTemperature": [
    "handle"
  ],
  "nvmlDeviceGetPowerState": [
    "handle"
  ],
  "nvmlDeviceGetPerformanceState": [
    "handle"
  ],
  "nvmlDeviceGetPowerManagementMode": [
    "handle"
  ],
  "nvmlDeviceGetPowerManagementLimit": [
    "handle"
  ],
  "nvmlDeviceGetPowerManagementLimitConstraints": [
    "handle"
  ],
  "nvmlDeviceGetPowerManagementDefaultLimit": [
    "handle"
  ],
  "nvmlDeviceGetEnforcedPowerLimit": [
    "handle"
  ],
  "nvmlDeviceGetPowerUsage": [
    "handle"
  ],
  "nvmlDeviceGetTotalEnergyConsumption": [
    "handle"
  ],
  "nvmlDeviceGetGpuOperationMode": [
    "handle"
  ],
  "nvmlDeviceGetCurrentGpuOperationMode": [
    "handle"
  ],
  "nvmlDeviceGetPendingGpuOperationMode": [
    "handle"
  ],
  "nvmlDeviceGetMemoryInfo": [
    "handle",
    "version"
  ],
  "nvmlDeviceGetBAR1MemoryInfo": [
    "handle"
  ],
  "nvmlDeviceGetComputeMode": [
    "handle"
  ],
  "nvmlDeviceGetCudaComputeCapability": [
    "handle"
  ],
  "nvmlDeviceGetEccMode": [
    "handle"
  ],
  "nvmlDeviceGetCurrentEccMode": [
    "handle"
  ],
  "nvmlDeviceGetPendingEccMode": [
    "handle"
  ],
  "nvmlDeviceGetDefaultEccMode": [
    "handle"
  ],
  "nvmlDeviceGetTotalEccErrors": [
    "handle",
    "errorType",
    "counterType"
  ],
  "nvmlDeviceGetDetailedEccErrors": [
    "handle",
    "errorType",
    "counterType"
  ],
  "nvmlDeviceGetMemoryErrorCounter": [
    "handle",
    "errorType",
    "counterType",
    "locationType"
  ],
  "nvmlDeviceGetUtilizationRates": [
    "handle"
  ],
  "nvmlDeviceGetEncoderUtilization": [
    "handle"
  ],
  "nvmlDeviceGetDecoderUtilization": [
    "handle"
  ],
  "nvmlDeviceGetJpgUtilization": [
    "handle"
  ],
  "nvmlDeviceGetOfaUtilization": [
    "handle"
  ],
  "nvmlDeviceGetPcieReplayCounter": [
    "handle"
  ],
  "nvmlDeviceGetDriverModel": [
    "handle"
  ],
  "nvmlDeviceGetCurrentDriverModel": [
    "handle"
  ],
  "nvmlDeviceGetPendingDriverModel": [
    "handle"
  ],
  "nvmlDeviceGetVbiosVersion": [
    "handle"
  ],
  "nvmlDeviceGetComputeRunningProcesses_v2": [
    "handle"
  ],
  "nvmlDeviceGetComputeRunningProcesses_v3": [
    "handle"
  ],
  "nvmlDeviceGetComputeRunningProcesses": [
    "handle"
  ],
  "nvmlDeviceGetGraphicsRunningProcesses_v2": [
    "handle"
  ],
  "nvmlDeviceGetGraphicsRunningProcesses_v3": [
    "handle"
  ],
  "nvmlDeviceGetGraphicsRunningProcesses": [
    "handle"
  ],
  "nvmlDeviceGetMPSComputeRunningProcesses": [
    "handle"
  ],
  "nvmlDeviceGetMPSComputeRunningProcesses_v2": [
    "handle"
  ],
  "nvmlDeviceGetMPSComputeRunningProcesses_v3": [
    "handle"
  ],
  "nvmlDeviceGetRunningProcessDetailList": [
    "handle",
    "version",
    "mode"
  ],
  "nvmlDeviceGetAutoBoostedClocksEnabled": [
    "handle"
  ],
  "nvmlUnitSetLedState": [
    "unit",
    "color"
  ],
  "nvmlDeviceSetPersistenceMode": [
    "handle",
    "mode"
  ],
  "nvmlDeviceSetComputeMode": [
    "handle",
    "mode"
  ],
  "nvmlDeviceSetEccMode": [
    "handle",
    "mode"
  ],
  "nvmlDeviceClearEccErrorCounts": [
    "handle",
    "counterType"
  ],
  "nvmlDeviceSetDriverModel": [
    "handle",
    "model"
  ],
  "nvmlDeviceSetAutoBoostedClocksEnabled": [
    "handle",
    "enabled"
  ],
  "nvmlDeviceSetDefaultAutoBoostedClocksEnabled": [
    "handle",
    "enabled",
    "flags"
  ],
  "nvmlDeviceSetGpuLockedClocks": [
    "handle",
    "minGpuClockMHz",
    "maxGpuClockMHz"
  ],
  "nvmlDeviceResetGpuLockedClocks": [
    "handle"
  ],
  "nvmlDeviceSetMemoryLockedClocks": [
    "handle",
    "minMemClockMHz",
    "maxMemClockMHz"
  ],
  "nvmlDeviceResetMemoryLockedClocks": [
    "handle"
  ],
  "nvmlDeviceGetClkMonStatus": [
    "handle",
    "c_clkMonInfo"
  ],
  "nvmlDeviceSetApplicationsClocks": [
    "handle",
    "maxMemClockMHz",
    "maxGraphicsClockMHz"
  ],
  "nvmlDeviceResetApplicationsClocks": [
    "handle"
  ],
  "nvmlDeviceSetPowerManagementLimit": [
    "handle",
    "limit"
  ],
  "nvmlDeviceSetGpuOperationMode": [
    "handle",
    "mode"
  ],
  "nvmlEventSetCreate": [],
  "nvmlDeviceRegisterEvents": [
    "handle",
    "eventTypes",
    "eventSet"
  ],
  "nvmlDeviceGetSupportedEventTypes": [
    "handle"
  ],
  "nvmlEventSetWait_v2": [
    "eventSet",
    "timeoutms"
  ],
  "nvmlEventSetWait": [
    "eventSet",
    "timeoutms"
  ],
  "nvmlEventSetFree": [
    "eventSet"
  ],
  "nvmlDeviceOnSameBoard": [
    "handle1",
    "handle2"
  ],
  "nvmlDeviceGetCurrPcieLinkGeneration": [
    "handle"
  ],
  "nvmlDeviceGetMaxPcieLinkGeneration": [
    "handle"
  ],
  "nvmlDeviceGetCurrPcieLinkWidth": [
    "handle"
  ],
  "nvmlDeviceGetMaxPcieLinkWidth": [
    "handle"
  ],
  "nvmlDeviceGetGpuMaxPcieLinkGeneration": [
    "handle"
  ],
  "nvmlDeviceGetSupportedClocksThrottleReasons": [
    "handle"
  ],
  "nvmlDeviceGetSupportedClocksEventReasons": [
    "handle"
  ],
  "nvmlDeviceGetCurrentClocksThrottleReasons": [
    "handle"
  ],
  "nvmlDeviceGetCurrentClocksEventReasons": [
    "handle"
  ],
  "nvmlDeviceGetIndex": [
    "handle"
  ],
  "nvmlDeviceGetAccountingMode": [
    "handle"
  ],
  "nvmlDeviceSetAccountingMode": [
    "handle",
    "mode"
  ],
  "nvmlDeviceClearAccountingPids": [
    "handle"
  ],
  "nvmlDeviceGetAccountingStats": [
    "handle",
    "pid"
  ],
  "nvmlDeviceGetAccountingPids": [
    "handle"
  ],
  "nvmlDeviceGetAccountingBufferSize": [
    "handle"
  ],
  "nvmlDeviceGetRetiredPages": [
    "device",
    "sourceFilter"
  ],
  "nvmlDeviceGetRetiredPages_v2": [
    "device",
    "sourceFilter"
  ],
  "nvmlDeviceGetRetiredPagesPendingStatus": [
    "device"
  ],
  "nvmlDeviceGetAPIRestriction": [
    "device",
    "apiType"
  ],
  "nvmlDeviceSetAPIRestriction": [
    "handle",
    "apiType",
    "isRestricted"
  ],
  "nvmlDeviceGetBridgeChipInfo": [
    "handle"
  ],
  "nvmlDeviceGetSamples": [
    "device",
    "sampling_type",
    "timeStamp"
  ],
  "nvmlDeviceGetViolationStatus": [
    "device",
    "perfPolicyType"
  ],
  "nvmlDeviceGetPcieThroughput": [
    "device",
    "counter"
  ],
  "nvmlSystemGetTopologyGpuSet": [
    "cpuNumber"
  ],
  "nvmlDeviceGetTopologyNearestGpus": [
    "device",
    "level"
  ],
  "nvmlDeviceGetTopologyCommonAncestor": [
    "device1",
    "device2"
  ],
  "nvmlDeviceGetNvLinkUtilizationCounter": [
    "device",
    "link",
    "counter"
  ],
  "nvmlDeviceFreezeNvLinkUtilizationCounter": [
    "device",
    "link",
    "counter",
    "freeze"
  ],
  "nvmlDeviceResetNvLinkUtilizationCounter": [
    "device",
    "link",
    "counter"
  ],
  "nvmlDeviceSetNvLinkUtilizationControl": [
    "device",
    "link",
    "counter",
    "control",
    "reset"
  ],
  "nvmlDeviceGetNvLinkUtilizationControl": [
    "device",
    "link",
    "counter"
  ],
  "nvmlDeviceGetNvLinkCapability": [
    "device",
    "link",
    "capability"
  ],
  "nvmlDeviceGetNvLinkErrorCounter": [
    "device",
    "link",
    "counter"
  ],
  "nvmlDeviceResetNvLinkErrorCounters": [
    "device",
    "link"
  ],
  "nvmlDeviceGetNvLinkRemotePciInfo": [
    "device",
    "link"
  ],
  "nvmlDeviceGetNvLinkRemoteDeviceType": [
    "handle",
    "link"
  ],
  "nvmlDeviceGetNvLinkState": [
    "device",
    "link"
  ],
  "nvmlDeviceGetNvLinkVersion": [
    "device",
    "link"
  ],
  "nvmlDeviceModifyDrainState": [
    "pciInfo",
    "newState"
  ],
  "nvmlDeviceQueryDrainState": [
    "pciInfo"
  ],
  "nvmlDeviceRemoveGpu": [
    "pciInfo"
  ],
  "nvmlDeviceDiscoverGpus": [
    "pciInfo"
  ],
  "nvmlDeviceGetFieldValues": [
    "handle",
    "fieldIds"
  ],
  "nvmlDeviceClearFieldValues": [
    "handle",
    "fieldIds"
  ],
  "nvmlDeviceGetVirtualizationMode": [
    "handle"
  ],
  "nvmlDeviceSetVirtualizationMode": [
    "handle",
    "virtualization_mode"
  ],
  "nvmlDeviceGetVgpuHeterogeneousMode": [
    "handle"
  ],
  "nvmlDeviceSetVgpuHeterogeneousMode": [
    "handle",
    "heterogeneous_mode"
  ],
  "nvmlVgpuInstanceGetPlacementId": [
    "vgpuInstance"
  ],
  "nvmlDeviceGetVgpuTypeSupportedPlacements": [
    "handle",
    "vgpuTypeId",
    "mode",
    "version"
  ],
  "nvmlDeviceGetVgpuTypeCreatablePlacements": [
    "handle",
    "vgpuTypeId",
    "version"
  ],
  "nvmlGetVgpuDriverCapabilities": [
    "capability"
  ],
  "nvmlDeviceGetVgpuCapabilities": [
    "handle",
    "capability"
  ],
  "nvmlDeviceSetVgpuCapabilities": [
    "handle",
    "capability",
    "state"
  ],
  "nvmlDeviceGetSupportedVgpus": [
    "handle"
  ],
  "nvmlDeviceGetCreatableVgpus": [
    "handle"
  ],
  "nvmlVgpuTypeGetGpuInstanceProfileId": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetClass": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetName": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetDeviceID": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetFramebufferSize": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetNumDisplayHeads": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetResolution": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetLicense": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetFrameRateLimit": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetGspHeapSize": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetFbReservation": [
    "vgpuTypeId"
  ],
  "nvmlVgpuInstanceGetRuntimeStateSize": [
    "vgpuInstance"
  ],
  "nvmlVgpuTypeGetMaxInstances": [
    "handle",
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetMaxInstancesPerVm": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetBAR1Info": [
    "vgpuTypeId"
  ],
  "nvmlDeviceGetActiveVgpus": [
    "handle"
  ],
  "nvmlVgpuInstanceGetVmID": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetUUID": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetMdevUUID": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetVmDriverVersion": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetLicenseStatus": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetLicenseInfo_v2": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetLicenseInfo": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetFrameRateLimit": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetEccMode": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetType": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetEncoderCapacity": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceSetEncoderCapacity": [
    "vgpuInstance",
    "encoder_capacity"
  ],
  "nvmlVgpuInstanceGetFbUsage": [
    "vgpuInstance"
  ],
  "nvmlVgpuTypeGetCapabilities": [
    "vgpuTypeId",
    "capability"
  ],
  "nvmlVgpuInstanceGetGpuInstanceId": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetGpuPciId": [
    "vgpuInstance"
  ],
  "nvmlDeviceGetVgpuUtilization": [
    "handle",
    "timeStamp"
  ],
  "nvmlDeviceGetVgpuInstancesUtilizationInfo": [
    "handle",
    "timeStamp"
  ],
  "nvmlDeviceGetP2PStatus": [
    "device1",
    "device2",
    "p2pIndex"
  ],
  "nvmlDeviceGetGridLicensableFeatures_v4": [
    "handle"
  ],
  "nvmlDeviceGetGridLicensableFeatures": [
    "handle"
  ],
  "nvmlDeviceGetGspFirmwareVersion": [
    "handle",
    "version"
  ],
  "nvmlDeviceGetGspFirmwareMode": [
    "handle",
    "isEnabled",
    "defaultMode"
  ],
  "nvmlDeviceGetEncoderCapacity": [
    "handle",
    "encoderQueryType"
  ],
  "nvmlDeviceGetVgpuProcessUtilization": [
    "handle",
    "timeStamp"
  ],
  "nvmlDeviceGetVgpuProcessesUtilizationInfo": [
    "handle",
    "timeStamp"
  ],
  "nvmlDeviceGetEncoderStats": [
    "handle"
  ],
  "nvmlDeviceGetEncoderSessions": [
    "handle"
  ],
  "nvmlDeviceGetFBCStats": [
    "handle"
  ],
  "nvmlDeviceGetFBCSessions": [
    "handle"
  ],
  "nvmlVgpuInstanceGetEncoderStats": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetEncoderSessions": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetFBCStats": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetFBCSessions": [
    "vgpuInstance"
  ],
  "nvmlDeviceGetProcessUtilization": [
    "handle",
    "timeStamp"
  ],
  "nvmlDeviceGetProcessesUtilizationInfo": [
    "handle",
    "timeStamp"
  ],
  "nvmlVgpuInstanceGetMetadata": [
    "vgpuInstance"
  ],
  "nvmlDeviceGetVgpuMetadata": [
    "handle"
  ],
  "nvmlGetVgpuCompatibility": [
    "vgpuMetadata",
    "pgpuMetadata"
  ],
  "nvmlDeviceGetPgpuMetadataString": [
    "handle"
  ],
  "nvmlDeviceGetVgpuSchedulerLog": [
    "handle"
  ],
  "nvmlDeviceGetVgpuSchedulerState": [
    "handle"
  ],
  "nvmlDeviceGetVgpuSchedulerCapabilities": [
    "handle"
  ],
  "nvmlDeviceSetVgpuSchedulerState": [
    "handle",
    "sched_state"
  ],
  "nvmlSetVgpuVersion": [
    "vgpuVersion"
  ],
  "nvmlGetVgpuVersion": [
    "supported",
    "current"
  ],
  "nvmlVgpuInstanceGetAccountingMode": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetAccountingPids": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetAccountingStats": [
    "vgpuInstance",
    "pid"
  ],
  "nvmlVgpuInstanceClearAccountingPids": [
    "vgpuInstance"
  ],
  "nvmlGetExcludedDeviceCount": [],
  "nvmlGetExcludedDeviceInfoByIndex": [
    "index"
  ],
  "nvmlDeviceGetHostVgpuMode": [
    "handle"
  ],
  "nvmlDeviceSetMigMode": [
    "device",
    "mode"
  ],
  "nvmlDeviceGetMigMode": [
    "device"
  ],
  "nvmlDeviceGetGpuInstanceProfileInfo": [
    "device",
    "profile",
    "version"
  ],
  "nvmlDeviceGetGpuInstanceProfileInfoV": [],
  "nvmlDeviceGetGpuInstanceRemainingCapacity": [
    "device",
    "profileId"
  ],
  "nvmlDeviceGetGpuInstancePossiblePlacements": [
    "device",
    "profileId",
    "placementsRef",
    "countRef"
  ],
  "nvmlDeviceCreateGpuInstance": [
    "device",
    "profileId"
  ],
  "nvmlDeviceCreateGpuInstanceWithPlacement": [
    "device",
    "profileId",
    "placement"
  ],
  "nvmlGpuInstanceDestroy": [
    "gpuInstance"
  ],
  "nvmlDeviceGetGpuInstances": [
    "device",
    "profileId",
    "gpuInstancesRef",
    "countRef"
  ],
  "nvmlDeviceGetGpuInstanceById": [
    "device",
    "gpuInstanceId"
  ],
  "nvmlGpuInstanceGetInfo": [
    "gpuInstance"
  ],
  "nvmlGpuInstanceGetComputeInstanceProfileInfo": [
    "device",
    "profile",
    "engProfile",
    "version"
  ],
  "nvmlGpuInstanceGetComputeInstanceProfileInfoV": [],
  "nvmlGpuInstanceGetComputeInstanceRemainingCapacity": [
    "gpuInstance",
    "profileId"
  ],
  "nvmlGpuInstanceGetComputeInstancePossiblePlacements": [
    "gpuInstance",
    "profileId",
    "placementsRef",
    "countRef"
  ],
  "nvmlGpuInstanceCreateComputeInstance": [
    "gpuInstance",
    "profileId"
  ],
  "nvmlGpuInstanceCreateComputeInstanceWithPlacement": [
    "gpuInstance",
    "profileId",
    "placement"
  ],
  "nvmlComputeInstanceDestroy": [
    "computeInstance"
  ],
  "nvmlGpuInstanceGetComputeInstances": [
    "gpuInstance",
    "profileId",
    "computeInstancesRef",
    "countRef"
  ],
  "nvmlGpuInstanceGetComputeInstanceById": [
    "gpuInstance",
    "computeInstanceId"
  ],
  "nvmlComputeInstanceGetInfo_v2": [
    "computeInstance"
  ],
  "nvmlComputeInstanceGetInfo": [
    "computeInstance"
  ],
  "nvmlDeviceIsMigDeviceHandle": [
    "device"
  ],
  "nvmlDeviceGetGpuInstanceId": [
    "device"
  ],
  "nvmlDeviceGetComputeInstanceId": [
    "device"
  ],
  "nvmlDeviceGetMaxMigDeviceCount": [
    "device"
  ],
  "nvmlDeviceGetMigDeviceHandleByIndex": [
    "device",
    "index"
  ],
  "nvmlDeviceGetDeviceHandleFromMigDeviceHandle": [
    "migDevice"
  ],
  "nvmlDeviceGetAttributes_v2": [
    "device"
  ],
  "nvmlDeviceGetAttributes": [
    "device"
  ],
  "nvmlDeviceGetRemappedRows": [
    "device"
  ],
  "nvmlDeviceGetRowRemapperHistogram": [
    "device"
  ],
  "nvmlDeviceGetArchitecture": [
    "device"
  ],
  "nvmlDeviceGetBusType": [
    "device"
  ],
  "nvmlDeviceGetIrqNum": [
    "device"
  ],
  "nvmlDeviceGetNumGpuCores": [
    "device"
  ],
  "nvmlDeviceGetPowerSource": [
    "device"
  ],
  "nvmlDeviceGetMemoryBusWidth": [
    "device"
  ],
  "nvmlDeviceGetPcieLinkMaxSpeed": [
    "device"
  ],
  "nvmlDeviceGetAdaptiveClockInfoStatus": [
    "device"
  ],
  "nvmlDeviceGetPcieSpeed": [
    "device"
  ],
  "nvmlDeviceGetDynamicPstatesInfo": [
    "device",
    "c_dynamicpstatesinfo"
  ],
  "nvmlDeviceSetFanSpeed_v2": [
    "handle",
    "index",
    "speed"
  ],
  "nvmlDeviceGetThermalSettings": [
    "device",
    "sensorindex",
    "c_thermalsettings"
  ],
  "nvmlDeviceGetMinMaxClockOfPState": [
    "device",
    "clockType",
    "pstate",
    "minClockMHz",
    "maxClockMHz"
  ],
  "c_nvmlClockOffset_t": {
    "_fields_": []
  },
  "nvmlClockOffset_v1": [],
  "nvmlDeviceGetClockOffsets": [
    "device",
    "info"
  ],
  "nvmlDeviceSetClockOffsets": [
    "device",
    "info"
  ],
  "nvmlDeviceGetSupportedPerformanceStates": [
    "device"
  ],
  "nvmlDeviceGetGpcClkVfOffset": [
    "device"
  ],
  "nvmlDeviceSetGpcClkVfOffset": [
    "device",
    "offset"
  ],
  "nvmlDeviceGetGpcClkMinMaxVfOffset": [
    "device",
    "minOffset",
    "maxOffset"
  ],
  "nvmlDeviceGetMemClkVfOffset": [
    "device"
  ],
  "nvmlDeviceSetMemClkVfOffset": [
    "device",
    "offset"
  ],
  "nvmlDeviceGetMemClkMinMaxVfOffset": [
    "device",
    "minOffset",
    "maxOffset"
  ],
  "nvmlSystemSetConfComputeGpusReadyState": [
    "state"
  ],
  "nvmlSystemGetConfComputeGpusReadyState": [],
  "nvmlSystemGetConfComputeCapabilities": [],
  "nvmlSystemGetConfComputeState": [],
  "nvmlSystemGetConfComputeSettings": [
    "settings"
  ],
  "nvmlDeviceSetConfComputeUnprotectedMemSize": [
    "device",
    "c_ccMemSize"
  ],
  "nvmlDeviceGetConfComputeMemSizeInfo": [
    "device"
  ],
  "nvmlDeviceGetConfComputeProtectedMemoryUsage": [
    "device"
  ],
  "nvmlDeviceGetConfComputeGpuCertificate": [
    "device"
  ],
  "nvmlDeviceGetConfComputeGpuAttestationReport": [
    "device",
    "c_nonce"
  ],
  "nvmlSystemSetConfComputeKeyRotationThresholdInfo": [
    "max_atk_adv"
  ],
  "nvmlSystemGetConfComputeKeyRotationThresholdInfo": [],
  "NVML_GPM_METRIC_GRAPHICS_UTIL": [],
  "NVML_GPM_METRIC_SM_UTIL": [],
  "NVML_GPM_METRIC_SM_OCCUPANCY": [],
  "NVML_GPM_METRIC_INTEGER_UTIL": [],
  "NVML_GPM_METRIC_ANY_TENSOR_UTIL": [],
  "NVML_GPM_METRIC_DFMA_TENSOR_UTIL": [],
  "NVML_GPM_METRIC_HMMA_TENSOR_UTIL": [],
  "NVML_GPM_METRIC_IMMA_TENSOR_UTIL": [],
  "NVML_GPM_METRIC_DRAM_BW_UTIL": [],
  "NVML_GPM_METRIC_FP64_UTIL": [],
  "NVML_GPM_METRIC_FP32_UTIL": [],
  "NVML_GPM_METRIC_FP16_UTIL": [],
  "NVML_GPM_METRIC_PCIE_TX_PER_SEC": [],
  "NVML_GPM_METRIC_PCIE_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVDEC_0_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_1_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_2_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_3_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_4_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_5_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_6_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_7_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_0_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_1_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_2_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_3_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_4_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_5_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_6_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_7_UTIL": [],
  "NVML_GPM_METRIC_NVOFA_0_UTIL": [],
  "NVML_GPM_METRIC_NVOFA_1_UTIL": [],
  "NVML_GPM_METRIC_NVLINK_TOTAL_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_TOTAL_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L0_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L0_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L1_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L1_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L2_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L2_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L3_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L3_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L4_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L4_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L5_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L5_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L6_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L6_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L7_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L7_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L8_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L8_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L9_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L9_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L10_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L10_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L11_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L11_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L12_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L12_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L13_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L13_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L14_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L14_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L15_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L15_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L16_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L16_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L17_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L17_TX_PER_SEC": [],
  "NVML_GPM_METRIC_MAX": [],
  "struct_c_nvmlGpmSample_t": {},
  "c_nvmlGpmSample_t": [],
  "c_metricInfo_t": {
    "_fields_": []
  },
  "c_nvmlGpmMetric_t": {
    "_fields_": []
  },
  "c_nvmlGpmMetricsGet_t": {
    "_fields_": []
  },
  "NVML_GPM_METRICS_GET_VERSION": [],
  "c_nvmlGpmSupport_t": {
    "_fields_": []
  },
  "NVML_GPM_SUPPORT_VERSION": [],
  "nvmlGpmMetricsGet": [
    "metricsGet"
  ],
  "nvmlGpmSampleFree": [
    "gpmSample"
  ],
  "nvmlGpmSampleAlloc": [],
  "nvmlGpmSampleGet": [
    "device",
    "gpmSample"
  ],
  "nvmlGpmMigSampleGet": [
    "device",
    "gpuInstanceId",
    "gpmSample"
  ],
  "nvmlGpmQueryDeviceSupport": [
    "device"
  ],
  "nvmlGpmSetStreamingEnabled": [
    "device",
    "state"
  ],
  "nvmlGpmQueryIfStreamingEnabled": [
    "device"
  ],
  "NVML_NVLINK_POWER_STATE_HIGH_SPEED": [],
  "NVML_NVLINK_POWER_STATE_LOW": [],
  "NVML_NVLINK_LOW_POWER_THRESHOLD_MIN": [],
  "NVML_NVLINK_LOW_POWER_THRESHOLD_MAX": [],
  "NVML_NVLINK_LOW_POWER_THRESHOLD_RESET": [],
  "NVML_NVLINK_LOW_POWER_THRESHOLD_DEFAULT": [],
  "c_nvmlNvLinkPowerThres_t": {
    "_fields_": []
  },
  "nvmlDeviceSetNvLinkDeviceLowPowerThreshold": [
    "device",
    "l1threshold"
  ],
  "NVML_GPU_FABRIC_UUID_LEN": [],
  "_nvmlGpuFabricState_t": [],
  "NVML_GPU_FABRIC_STATE_NOT_SUPPORTED": [],
  "NVML_GPU_FABRIC_STATE_NOT_STARTED": [],
  "NVML_GPU_FABRIC_STATE_IN_PROGRESS": [],
  "NVML_GPU_FABRIC_STATE_COMPLETED": [],
  "c_nvmlGpuFabricInfo_t": {
    "_fields_": []
  },
  "NVML_GPU_FABRIC_HEALTH_MASK_DEGRADED_BW_NOT_SUPPORTED": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_DEGRADED_BW_TRUE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_DEGRADED_BW_FALSE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_SHIFT_DEGRADED_BW": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_WIDTH_DEGRADED_BW": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ROUTE_RECOVERY_NOT_SUPPORTED": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ROUTE_RECOVERY_TRUE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ROUTE_RECOVERY_FALSE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_SHIFT_ROUTE_RECOVERY": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_WIDTH_ROUTE_RECOVERY": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ROUTE_UNHEALTHY_NOT_SUPPORTED": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ROUTE_UNHEALTHY_TRUE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ROUTE_UNHEALTHY_FALSE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_SHIFT_ROUTE_UNHEALTHY": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_WIDTH_ROUTE_UNHEALTHY": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ACCESS_TIMEOUT_RECOVERY_NOT_SUPPORTED": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ACCESS_TIMEOUT_RECOVERY_TRUE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ACCESS_TIMEOUT_RECOVERY_FALSE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_SHIFT_ACCESS_TIMEOUT_RECOVERY": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_WIDTH_ACCESS_TIMEOUT_RECOVERY": [],
  "nvmlGpuFabricInfo_v2": [],
  "c_nvmlGpuFabricInfoV_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlDeviceGetGpuFabricInfo": [
    "device",
    "gpuFabricInfo"
  ],
  "nvmlDeviceGetGpuFabricInfoV": [
    "device",
    "gpuFabricInfo"
  ],
  "NVML_GPU_NVLINK_BW_MODE_FULL": [],
  "NVML_GPU_NVLINK_BW_MODE_OFF": [],
  "NVML_GPU_NVLINK_BW_MODE_MIN": [],
  "NVML_GPU_NVLINK_BW_MODE_HALF": [],
  "NVML_GPU_NVLINK_BW_MODE_3QUARTER": [],
  "NVML_GPU_NVLINK_BW_MODE_COUNT": [],
  "nvmlSystemSetNvlinkBwMode": [
    "mode"
  ],
  "nvmlSystemGetNvlinkBwMode": [],
  "_nvmlPowerScopeType_t": [],
  "NVML_POWER_SCOPE_GPU": [],
  "NVML_POWER_SCOPE_MODULE": [],
  "NVML_POWER_SCOPE_MEMORY": [],
  "c_nvmlPowerValue_v2_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "nvmlPowerValue_v2": [],
  "nvmlDeviceSetPowerManagementLimit_v2": [
    "device",
    "powerScope",
    "powerLimit",
    "version"
  ],
  "c_nvmlEccSramErrorStatus_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlEccSramErrorStatus_v1": [],
  "nvmlDeviceGetSramEccErrorStatus": [
    "device",
    "status"
  ],
  "NVML_DEV_CAP_EGM": [],
  "nvmlDeviceCapabilities_v1": [],
  "c_nvmlDeviceCapabilities_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlDeviceGetCapabilities": [
    "device",
    "caps"
  ],
  "c_nvmlPlatformInfo_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlPlatformInfo_v1": [],
  "nvmlDeviceGetPlatformInfo": [
    "device",
    "platformInfo"
  ],
  "c_nvmlMask255_t": {
    "_fields_": []
  },
  "NVML_WORKLOAD_POWER_MAX_PROFILES": [],
  "NVML_POWER_PROFILE_MAX_P": [],
  "NVML_POWER_PROFILE_MAX_Q": [],
  "NVML_POWER_PROFILE_COMPUTE": [],
  "NVML_POWER_PROFILE_MEMORY_BOUND": [],
  "NVML_POWER_PROFILE_NETWORK": [],
  "NVML_POWER_PROFILE_BALANCED": [],
  "NVML_POWER_PROFILE_LLM_INFERENCE": [],
  "NVML_POWER_PROFILE_LLM_TRAINING": [],
  "NVML_POWER_PROFILE_RBM": [],
  "NVML_POWER_PROFILE_DCPCIE": [],
  "NVML_POWER_PROFILE_HMMA_SPARSE": [],
  "NVML_POWER_PROFILE_HMMA_DENSE": [],
  "NVML_POWER_PROFILE_SYNC_BALANCED": [],
  "NVML_POWER_PROFILE_HPC": [],
  "NVML_POWER_PROFILE_MIG": [],
  "NVML_POWER_PROFILE_MAX": [],
  "nvmlWorkloadPowerProfileInfo_v1": [],
  "c_nvmlWorkloadPowerProfileInfo_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlWorkloadPowerProfileProfilesInfo_v1": [],
  "c_nvmlWorkloadPowerProfileProfilesInfo_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlWorkloadPowerProfileCurrentProfiles_v1": [],
  "c_nvmlWorkloadPowerProfileCurrentProfiles_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlWorkloadPowerProfileRequestedProfiles_v1": [],
  "c_nvmlWorkloadPowerProfileRequestedProfiles_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlDeviceWorkloadPowerProfileGetProfilesInfo": [
    "device",
    "profilesInfo"
  ],
  "nvmlDeviceWorkloadPowerProfileGetCurrentProfiles": [
    "device",
    "currentProfiles"
  ],
  "nvmlDeviceWorkloadPowerProfileSetRequestedProfiles": [
    "device",
    "requestedProfiles"
  ],
  "nvmlDeviceWorkloadPowerProfileClearRequestedProfiles": [
    "device",
    "requestedProfiles"
  ],
  "nvmlDeviceGetNvlinkSupportedBwModes": [
    "device",
    "supportedBwModes"
  ],
  "nvmlDeviceGetNvlinkBwMode": [
    "device",
    "getBwMode"
  ],
  "nvmlDeviceSetNvlinkBwMode": [
    "device",
    "setBwMode"
  ],
  "nvmlDramEncryptionInfo_v1": [],
  "c_nvmlDramEncryptionInfo_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlDeviceGetDramEncryptionMode": [
    "handle"
  ],
  "nvmlDeviceGetCurrentDramEncryptionMode": [
    "handle"
  ],
  "nvmlDeviceGetPendingDramEncryptionMode": [
    "handle"
  ],
  "nvmlDeviceSetDramEncryptionMode": [
    "handle",
    "mode"
  ],
  "NVML_POWER_SMOOTHING_MAX_NUM_PROFILES": [],
  "NVML_POWER_SMOOTHING_ADMIN_OVERRIDE_NOT_SET": [],
  "NVML_POWER_SMOOTHING_PROFILE_PARAM_PERCENT_TMP_FLOOR": [],
  "NVML_POWER_SMOOTHING_PROFILE_PARAM_RAMP_UP_RATE": [],
  "NVML_POWER_SMOOTHING_PROFILE_PARAM_RAMP_DOWN_RATE": [],
  "NVML_POWER_SMOOTHING_PROFILE_PARAM_RAMP_DOWN_HYSTERESIS": [],
  "nvmlPowerSmoothingState_v1": [],
  "c_nvmlPowerSmoothingState_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlPowerSmoothingProfile_v1": [],
  "c_nvmlPowerSmoothingProfile_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlDevicePowerSmoothingActivatePresetProfile": [
    "device",
    "profile"
  ],
  "nvmlDevicePowerSmoothingUpdatePresetProfileParam": [
    "device",
    "profile"
  ],
  "nvmlDevicePowerSmoothingSetState": [
    "device",
    "state"
  ],
  "flash_mla_cuda": [],
  "FlashMLASchedMeta": {},
  "get_mla_metadata": [],
  "flash_mla_sparse_fwd": [
    "q",
    "kv",
    "indices",
    "sm_scale",
    "d_v",
    "attn_sink",
    "topk_length"
  ],
  "_flash_attn_varlen_forward": [
    "q",
    "k",
    "v",
    "cu_seqlens_qo",
    "cu_seqlens_kv",
    "max_seqlen_qo",
    "max_seqlen_kv",
    "out",
    "lse",
    "causal",
    "softmax_scale",
    "is_varlen"
  ],
  "_flash_attn_varlen_backward": [
    "do",
    "q",
    "k",
    "v",
    "out",
    "lse",
    "cu_seqlens_qo",
    "cu_seqlens_kv",
    "max_seqlen_qo",
    "max_seqlen_kv",
    "dq",
    "dk",
    "dv",
    "causal",
    "softmax_scale",
    "is_varlen"
  ],
  "FlashAttnVarlenFunc": {
    "forward": [
      "ctx",
      "q",
      "k",
      "v",
      "cu_seqlens_qo",
      "cu_seqlens_kv",
      "max_seqlen_qo",
      "max_seqlen_kv",
      "causal",
      "softmax_scale",
      "is_varlen"
    ],
    "backward": [
      "ctx",
      "do",
      "dlse"
    ]
  },
  "flash_attn_varlen_func": [
    "q",
    "k",
    "v",
    "cu_seqlens_qo",
    "cu_seqlens_kv",
    "max_seqlen_qo",
    "max_seqlen_kv",
    "dropout_p",
    "softmax_scale",
    "causal",
    "deterministic",
    "is_varlen"
  ],
  "flash_attn_varlen_qkvpacked_func": [
    "qkv",
    "cu_seqlens",
    "max_seqlen",
    "head_dim_qk",
    "dropout_p",
    "softmax_scale",
    "causal",
    "deterministic",
    "is_varlen"
  ],
  "flash_attn_varlen_kvpacked_func": [
    "q",
    "kv",
    "cu_seqlens_qo",
    "cu_seqlens_kv",
    "max_seqlen_qo",
    "max_seqlen_kv",
    "head_dim_qk",
    "dropout_p",
    "softmax_scale",
    "causal",
    "deterministic",
    "is_varlen"
  ],
  "_launch_metadata_allow_sync": [],
  "launch_metadata_allow_sync": [],
  "set_launch_metadata_allow_sync": [
    "allow_sync"
  ],
  "topk_forward": [
    "x",
    "k",
    "apply_softmax",
    "dim",
    "return_bitmatrix",
    "y_indx",
    "n_rows"
  ],
  "topk_backward": [
    "x",
    "y_indx",
    "dy_vals",
    "k",
    "n_rows",
    "apply_softmax"
  ],
  "TopK": {
    "forward": [
      "ctx",
      "x",
      "k",
      "apply_softmax",
      "dim",
      "return_bitmatrix",
      "y_indx",
      "n_rows"
    ],
    "backward": [
      "ctx",
      "dy_vals",
      "_0",
      "_1"
    ]
  },
  "topk": [
    "x",
    "k",
    "apply_softmax",
    "dim",
    "return_bitmatrix",
    "y_indx",
    "n_rows"
  ],
  "compaction": [
    "yv",
    "yi",
    "bitmask",
    "sentinel"
  ],
  "compaction_torch": [
    "yv",
    "yi",
    "bitmask",
    "sentinel"
  ],
  "MAX_FINITE_FLOAT8E5": [],
  "MAX_FINITE_FLOAT8E4NV": [],
  "MAX_FINITE_FLOAT8E4B8": [],
  "BaseFlexData": {
    "view": [
      "self",
      "x"
    ],
    "reinterpret": [
      "self",
      "x"
    ]
  },
  "InFlexData": {
    "is_per_batch": [
      "self"
    ]
  },
  "OutFlexData": {
    "__iter__": [
      "self"
    ]
  },
  "GatherIndx": {},
  "ScatterIndx": {},
  "ExptData": {
    "__post_init__": [
      "self"
    ]
  },
  "RoutingData": {
    "n_blocks": [
      "self",
      "n_rows",
      "block_m"
    ]
  },
  "SortTokens": {
    "forward": [
      "ctx",
      "expt_scal",
      "expt_indx",
      "n_expts_tot",
      "bitmatrix"
    ],
    "backward": [
      "ctx",
      "_0",
      "_1",
      "_2",
      "dgate_scal",
      "_3",
      "_4",
      "_5"
    ]
  },
  "sort_tokens": [
    "expt_scal",
    "expt_indx",
    "n_expts_tot",
    "bitmatrix"
  ],
  "PruneRouting": {
    "forward": [
      "ctx",
      "expt_scal",
      "expt_indx",
      "bitmatrix",
      "n_expts_tot",
      "simulated_ep"
    ]
  },
  "prune_routing": [
    "expt_scal",
    "expt_indx",
    "bitmatrix",
    "n_expts_tot",
    "simulated_ep"
  ],
  "log2_power_of_two": [
    "x"
  ],
  "block_m_log2_start": [],
  "_compute_expt_data_internal": [
    "expt_hist",
    "n_expts_tot",
    "n_gates"
  ],
  "_unpack_into_dict": [
    "x"
  ],
  "compute_expt_data": [
    "expt_hist",
    "n_expts_tot",
    "n_gates"
  ],
  "routing_from_bitmatrix": [
    "bitmatrix",
    "expt_scal",
    "expt_indx",
    "n_expts_tot",
    "n_expts_act"
  ],
  "routing": [
    "logits",
    "n_expts_act",
    "sm_first",
    "expt_indx",
    "simulated_ep",
    "n_rows"
  ],
  "compute_expt_data_torch": [
    "hist",
    "n_expts_tot",
    "n_gates"
  ],
  "topk_torch": [
    "vals",
    "k",
    "expt_indx",
    "has_user_provided_indx"
  ],
  "routing_torch": [
    "logits",
    "n_expts_act",
    "sm_first",
    "expt_indx",
    "n_rows"
  ],
  "assert_equal": [
    "ref",
    "tri"
  ],
  "assert_close": [
    "ref",
    "tri",
    "maxtol",
    "rmstol",
    "description",
    "verbose"
  ],
  "ComputeSanitizerTool": {
    "MEMCHECK": [],
    "RACECHECK": [],
    "SYNCCHECK": [],
    "INITCHECK": []
  },
  "compute_sanitizer": [],
  "compute_actual_scale": [
    "x",
    "dtype"
  ],
  "FnSpecs": {
    "default": []
  },
  "FusedActivation": {},
  "Epilogue": {},
  "FnName": {
    "QUANTIZE_MXFP8": []
  },
  "EpilogueSpecs": [],
  "_kernels": [],
  "get_kernels": [
    "epilogue",
    "fused_activation"
  ],
  "can_overflow_int32": [
    "tensor"
  ],
  "should_upcast_indices": [],
  "FlexCtx": {},
  "PrecisionConfig": {},
  "get_swap_xw": [
    "precision_config",
    "opt_flags"
  ],
  "MatmulAllocation": {},
  "init_allocation": [
    "x",
    "w",
    "precision_config",
    "fused_activation",
    "routing_data",
    "gather_indx",
    "scatter_indx",
    "opt_flags"
  ],
  "apply_allocation": [
    "allocation",
    "output"
  ],
  "_canonicalize_storage": [
    "storage",
    "out_ndim",
    "flex_data"
  ],
  "reduce_grouped": [
    "x",
    "indx",
    "out",
    "out_mx_scale",
    "fused_activation",
    "epilogue",
    "x_flex",
    "out_flex",
    "x_mx_scale",
    "out_dtype",
    "flexpoint_saturate_inf"
  ],
  "matmul_ogs_set_idle_sms": [
    "num_idle_sms"
  ],
  "matmul_ogs": [
    "x",
    "w",
    "bias",
    "routing_data",
    "gather_indx",
    "scatter_indx",
    "precision_config",
    "betas",
    "gammas",
    "out_alpha",
    "y",
    "fused_activation",
    "epilogue"
  ],
  "matmul_ogs_torch": [
    "x",
    "w",
    "bias",
    "routing_data",
    "gather_indx",
    "scatter_indx",
    "precision_config",
    "betas",
    "gammas",
    "round_x",
    "round_y"
  ],
  "swiglu_fn": [],
  "SwiGLU": {
    "forward": [
      "ctx",
      "a",
      "alpha",
      "precision_config",
      "routing_data"
    ]
  },
  "swiglu": [
    "a",
    "alpha",
    "precision_config",
    "routing_data"
  ],
  "swiglu_torch": [
    "a",
    "alpha",
    "precision_config"
  ],
  "Storage": {
    "__post_init__": [
      "self"
    ],
    "device": [
      "self"
    ],
    "is_tma_compliant": [
      "self"
    ],
    "make_dense_tma": [
      "self",
      "block_shape",
      "transpose"
    ],
    "make_tma": [
      "self",
      "block_shape",
      "mode",
      "transpose"
    ]
  },
  "IntegerType": {},
  "FloatType": {
    "__post_init__": [
      "self"
    ]
  },
  "BIT": [],
  "FP4": [],
  "bitwidth": [
    "type"
  ],
  "Tensor": {
    "__post_init__": [
      "self"
    ],
    "ndim": [
      "self"
    ],
    "device": [
      "self"
    ],
    "stride": [
      "self",
      "i"
    ],
    "data_ptr": [
      "self"
    ],
    "numel": [
      "self"
    ],
    "element_size": [
      "self"
    ],
    "data": [
      "self"
    ],
    "dim": [
      "self"
    ],
    "size": [
      "self",
      "i"
    ]
  },
  "Bitmatrix": {
    "__init__": [
      "self",
      "storage",
      "shape",
      "shape_max",
      "scratchpad"
    ],
    "sum": [
      "self",
      "partials_block_size"
    ]
  },
  "get_layout": [
    "tensor"
  ],
  "wrap_torch_tensor": [
    "torch_tensor",
    "dtype"
  ],
  "convert_layout": [
    "tensor",
    "layout_cls"
  ],
  "get_cdna_version": [],
  "has_tma_gather": [],
  "has_native_mxfp": [],
  "num_sms": [],
  "cacheable": [
    "f"
  ],
  "define_kernel": [
    "src",
    "module",
    "attrs"
  ],
  "specialize": [
    "fn",
    "module",
    "constants",
    "tuples",
    "name",
    "do_not_specialize"
  ],
  "make_default_matmul_mxfp4_w_layout": [
    "mx_axis"
  ],
  "make_default_matmul_mxfp4_w_scale_layout": [
    "mx_axis",
    "num_warps"
  ],
  "right_shift_unsigned": [
    "x",
    "shift"
  ],
  "_compress_fp4": [
    "x"
  ],
  "_compress_fourth": [
    "x"
  ],
  "_pack_bits": [
    "x",
    "mx_axis"
  ],
  "_bf16_to_fp4e2m1": [
    "x"
  ],
  "_bf16x2_to_fp4e2m1x2": [
    "x"
  ],
  "_unpack_bits": [
    "x",
    "mx_axis"
  ],
  "HopperMXValueLayout": {
    "__init__": [
      "self",
      "shape",
      "mx_axis",
      "mma_version"
    ],
    "_maybe_mT": [
      "self",
      "data"
    ],
    "swizzle_data": [
      "self",
      "data"
    ],
    "unswizzle_data": [
      "self",
      "data"
    ],
    "swizzle_block_shape": [
      "self",
      "block_shape"
    ]
  },
  "_unshuffle_triton": [
    "x",
    "mma_version"
  ],
  "_unpack_fp4_to_bf16_triton": [
    "x"
  ],
  "mxfp4_to_bf16_triton": [
    "x",
    "scale",
    "mx_axis"
  ],
  "Layout": {
    "__init__": [
      "self",
      "shape"
    ],
    "swizzle_data": [
      "self",
      "data"
    ],
    "unswizzle_data": [
      "self",
      "data"
    ],
    "swizzle_block_shape": [
      "self",
      "block_shape"
    ]
  },
  "NON_K_PRESHUFFLE_BLOCK_SIZE": [],
  "CDNA4MXScaleLayout": {
    "__init__": [
      "self",
      "shape"
    ],
    "swizzle_data": [
      "self",
      "data"
    ],
    "unswizzle_data": [
      "self",
      "data"
    ],
    "swizzle_block_shape": [
      "self",
      "block_shape"
    ]
  },
  "unswizzle_mx_scale_cdna4": [
    "x",
    "BLOCK_N",
    "MX_SCALE_BLOCK_K",
    "N_PRESHUFFLE_FACTOR"
  ],
  "BlackwellMXValueLayout": {
    "__init__": [
      "self",
      "shape"
    ],
    "swizzle_data": [
      "self",
      "data"
    ],
    "unswizzle_data": [
      "self",
      "data"
    ],
    "swizzle_block_shape": [
      "self",
      "block_shape"
    ]
  },
  "SWIZZLE_ALIGN_INNER": [],
  "SWIZZLE_SIZE_INNER": [],
  "SWIZZLE_SIZE_OUTER": [],
  "BlackwellMXScaleLayout": {
    "__init__": [
      "self",
      "shape"
    ],
    "swizzle_data": [
      "self",
      "data"
    ],
    "unswizzle_data": [
      "self",
      "data"
    ],
    "swizzle_block_shape": [
      "self",
      "block_shape"
    ]
  },
  "unswizzle_mx_scale_bw": [
    "x",
    "SIZE_OUTER",
    "SIZE_INNER",
    "ALIGN_INNER"
  ],
  "HopperMXScaleLayout": {
    "__init__": [
      "self",
      "shape",
      "mx_axis",
      "num_warps"
    ],
    "_maybe_mT": [
      "self",
      "data"
    ],
    "swizzle_data": [
      "self",
      "data"
    ],
    "unswizzle_data": [
      "self",
      "data"
    ],
    "swizzle_block_shape": [
      "self",
      "block_shape"
    ]
  },
  "unswizzle_mxfp4_scale_hopper": [
    "x",
    "mx_axis",
    "num_warps"
  ],
  "StridedLayout": {
    "__init__": [
      "self",
      "shape"
    ],
    "swizzle_data": [
      "self",
      "data"
    ],
    "unswizzle_data": [
      "self",
      "data"
    ],
    "swizzle_block_shape": [
      "self",
      "block_shape"
    ]
  },
  "_topk_backward": [
    "Yi",
    "stride_ym",
    "DY",
    "stride_dym",
    "X",
    "stride_xm",
    "DX",
    "stride_dxm",
    "n_rows",
    "NRows",
    "n_expts_tot",
    "APPLY_SOFTMAX",
    "N_EXPTS_ACT",
    "N_EXPTS_PAD"
  ],
  "get_topmask_and_fullmask": [
    "x"
  ],
  "fpval_to_key": [
    "x"
  ],
  "key_to_fpval": [
    "x"
  ],
  "indx_to_key": [
    "indx",
    "N_EXPTS_PAD"
  ],
  "key_to_indx": [
    "indx",
    "N_EXPTS_PAD"
  ],
  "streaming_topk": [
    "X",
    "stride_xm",
    "n_expts_tot",
    "offs_m",
    "mask_m",
    "N_EXPTS_PAD",
    "N_EXPTS_ACT",
    "BLOCK_N"
  ],
  "_topk_forward": [
    "X",
    "stride_xm",
    "Yv",
    "Yi",
    "stride_ym",
    "USE_PROVIDED_INDX",
    "Bits",
    "stride_rm",
    "stride_rn",
    "n_rows",
    "n_expts_tot",
    "S",
    "BLOCK_S",
    "s_blocks",
    "APPLY_SOFTMAX",
    "BLOCK_M",
    "N_EXPTS_PAD",
    "N_EXPTS_ACT",
    "BLOCK_N"
  ],
  "clip": [
    "x",
    "limit",
    "clip_lower"
  ],
  "thread_local_absmax": [
    "x",
    "BLOCK_SIZE",
    "NUM_THREADS"
  ],
  "swiglu_repr": [
    "specialization"
  ],
  "swiglu_launch_metadata": [
    "grid",
    "kernel",
    "args"
  ],
  "compute_swiglu": [
    "gelu",
    "linear",
    "scale",
    "alpha",
    "limit"
  ],
  "_swiglu_fn": [
    "input",
    "alpha",
    "limit"
  ],
  "_swiglu": [
    "Out",
    "OutExpectedScale",
    "OutActualScale",
    "OutChecksumScale",
    "A",
    "AScale",
    "alpha",
    "M",
    "N",
    "stride_am",
    "stride_an",
    "stride_outm",
    "stride_outn",
    "limit",
    "NTokens",
    "BLOCK_M",
    "BLOCK_N",
    "EVEN_N",
    "M_BLOCKS",
    "N_BLOCKS",
    "flexpoint_saturate_inf"
  ],
  "_routing_compute_expt_offs": [
    "ExpertHist",
    "FinalExpertOffs",
    "hist_size",
    "BLOCK_N"
  ],
  "_routing_compute_indx_offs": [
    "PartialHist",
    "shape_pm",
    "stride_pm",
    "stride_pn",
    "BLOCK_M",
    "expt_id"
  ],
  "_keyed_add": [
    "x",
    "y"
  ],
  "_routing_compute_indx": [
    "pid_m",
    "GatherIndx",
    "ScatterIndx",
    "GateScal",
    "ExptScal",
    "ExptIndx",
    "PartialOffs",
    "stride_pm",
    "stride_pn",
    "TokensStart",
    "n_tokens",
    "BLOCK_M",
    "N_EXPTS_ACT"
  ],
  "_combined_routing_compute": [
    "GatherIndx",
    "ScatterIndx",
    "GateScal",
    "ExptScal",
    "ExptIndx",
    "PartialOffs",
    "stride_pm",
    "stride_pn",
    "TokensStart",
    "n_tokens",
    "BLOCK_M",
    "N_EXPTS_ACT",
    "Hist",
    "MDTileStarts",
    "tile_starts_stridem",
    "MDTileInfo",
    "tile_info_stridem",
    "first_tile_dim_log2",
    "SIZES",
    "BLOCK",
    "blocks2a"
  ],
  "_routing_clear_bitmatrix": [
    "Bitmatrix",
    "stride_bm",
    "stride_bn",
    "shape_bn",
    "cutoff",
    "BLOCK_N"
  ],
  "_combined_routing_memset": [
    "Indx",
    "size",
    "sentinel",
    "BLOCK",
    "ExpertHist",
    "FinalExpertOffs",
    "hist_size",
    "n_expts_tot",
    "PartialHist",
    "shape_pm",
    "stride_pm",
    "stride_pn",
    "MDStarts",
    "tile_starts_stridem",
    "blocks1a",
    "MDTileInfo",
    "first_tile_dim_log2",
    "SIZES",
    "BLOCK_A",
    "BLOCK_N",
    "BLOCK_M"
  ],
  "_cdiv_pow2": [
    "n",
    "log2_k"
  ],
  "_expt_data_memset": [
    "Hist",
    "n_expts_tot",
    "MDStarts",
    "tile_starts_stridem",
    "MDTileInfo",
    "first_tile_dim_log2",
    "SIZES",
    "BLOCK"
  ],
  "_expt_data_compute": [
    "Hist",
    "MDTileStarts",
    "tile_starts_stridem",
    "MDTileInfo",
    "tile_info_stridem",
    "first_tile_dim_log2",
    "SIZES",
    "BLOCK"
  ],
  "TL_MAX_FINITE_FLOAT8E5": [],
  "TL_MAX_FINITE_FLOAT8E4NV": [],
  "TL_MAX_FINITE_FLOAT8E4B8": [],
  "TL_MAX_FINITE_FLOAT8E4B15": [],
  "TL_MAX_FINITE_FLOAT16": [],
  "TL_RCP_MAX_FINITE_FLOAT8E5": [],
  "TL_RCP_MAX_FINITE_FLOAT8E4NV": [],
  "TL_RCP_MAX_FINITE_FLOAT8E4B8": [],
  "TL_RCP_MAX_FINITE_FLOAT8E4B15": [],
  "TL_RCP_MAX_FINITE_FLOAT16": [],
  "max_finite": [
    "dtype"
  ],
  "rcp_max_finite": [
    "dtype"
  ],
  "sm86_min_nan_xorsign_abs_f32": [
    "a",
    "b"
  ],
  "sm86_max_nan_xorsign_abs_f32": [
    "a",
    "b"
  ],
  "load_scale": [
    "scale_ptr"
  ],
  "flex_to_float": [
    "x",
    "scale_ptr"
  ],
  "nan_propagating_absmax_reduce": [
    "x",
    "axis"
  ],
  "compute_scale": [
    "x",
    "Out"
  ],
  "update_scale": [
    "x",
    "scale_ptr",
    "Out"
  ],
  "float_to_flex": [
    "x",
    "expected_scale_ptr_or_val",
    "actual_scale_ptr",
    "checksum_scale_ptr",
    "mask",
    "Out",
    "saturate_infs"
  ],
  "DequantScaleRoundingMode": {
    "ROUND_UP": [],
    "ROUND_DOWN": []
  },
  "downcast_to_mxfp": [
    "src_tensor",
    "out_quant_type",
    "axis",
    "DEQUANT_SCALE_ROUNDING_MODE"
  ],
  "upcast_from_mxfp": [
    "tensor",
    "scale",
    "target_dtype",
    "axis"
  ],
  "get_max_quant_val": [
    "dtype"
  ],
  "downcast_to_mxfp_torch": [
    "src_tensor",
    "out_quant_type",
    "axis",
    "DEQUANT_SCALE_ROUNDING_MODE"
  ],
  "cvt_e2m1_to_fp32": [
    "input_tensor"
  ],
  "upcast_from_mxfp_torch": [
    "tensor",
    "scale",
    "target_dtype",
    "axis"
  ],
  "quantize_mxfp8_fn": [],
  "_upcast_from_mxfp": [
    "out_ptr",
    "stride_o_outer",
    "stride_o_quant",
    "mx_scale_ptr",
    "stride_scale_outer",
    "stride_scale_quant",
    "mx_tensor_ptr",
    "stride_tensor_outer",
    "stride_tensor_quant",
    "outer_dim",
    "quant_dim",
    "BLOCK_SIZE_OUT_DIM",
    "BLOCK_SIZE_QUANT_DIM"
  ],
  "MXFP_BLOCK_SIZE": [],
  "_get_max_quant_val": [
    "dtype"
  ],
  "_compute_quant_and_scale": [
    "src_tensor",
    "valid_src_mask",
    "mx_tensor_dtype",
    "DEQUANT_SCALE_ROUNDING_MODE"
  ],
  "_downcast_to_mxfp": [
    "mx_tensor_ptr",
    "stride_mxt_outer",
    "stride_mxt_quant",
    "mx_scale_ptr",
    "stride_mx_scale_outer",
    "stride_mx_scale_quant",
    "src_ptr",
    "stride_src_outer",
    "stride_src_quant",
    "outer_dim",
    "quant_dim",
    "BLOCK_SIZE_OUT_DIM",
    "BLOCK_SIZE_QUANT_DIM",
    "DEQUANT_SCALE_ROUNDING_MODE"
  ],
  "_quantize_mxfp8_fn": [
    "input",
    "mask",
    "pid"
  ],
  "_masked_compaction": [
    "Yv",
    "Yi",
    "BitMask",
    "stride_bm",
    "stride_bn",
    "RetYv",
    "RetYi",
    "sentinel",
    "K"
  ],
  "cuda_capability_geq": [
    "major",
    "minor"
  ],
  "get_dtype": [
    "tensor_or_desc"
  ],
  "_load_tile_attrs": [
    "tile_id",
    "num_tiles",
    "grid_m",
    "grid_n",
    "padding_m",
    "M",
    "ExptData",
    "ExptHist",
    "ExptOffs",
    "BLOCK_M",
    "BLOCK_N",
    "SPLIT_K",
    "GROUP_M",
    "XCD_SWIZZLE"
  ],
  "_load_writeback_idx_and_mask": [
    "WriteBackIndx",
    "writeback_size",
    "offs",
    "mask"
  ],
  "_matmul_ogs_repr": [],
  "_p_matmul_ogs": [
    "Y",
    "YPtr",
    "stride_y_k",
    "stride_y_z",
    "stride_y_m",
    "stride_y_n",
    "YExpectedScale",
    "YActualScale",
    "YChecksumScale",
    "stride_y_mx_z",
    "stride_y_mx_m",
    "stride_y_mx_n",
    "X",
    "XPtr",
    "stride_x_z",
    "stride_x_m",
    "stride_x_k",
    "XScale",
    "XMxScale",
    "stride_x_mx_z",
    "stride_x_mx_m",
    "stride_x_mx_k",
    "W",
    "WPtr",
    "stride_w_e",
    "stride_w_k",
    "stride_w_n",
    "W_TRANSPOSE",
    "WScale",
    "MxScale",
    "stride_mx_e",
    "stride_mx_k",
    "stride_mx_n",
    "B",
    "stride_b_e",
    "NRows",
    "M",
    "N",
    "K",
    "Betas",
    "Gammas",
    "GatherIndx",
    "ScatterSrcIndx",
    "num_idxs",
    "WriteBackIndx",
    "writeback_size",
    "ExptHist",
    "ExptOffs",
    "ExptOffsSum",
    "ExptData",
    "batch_size",
    "grid_m",
    "grid_n",
    "out_alpha",
    "ACTIVATION_FN",
    "activation_fn_args",
    "ACTIVATION_REDUCTION_N",
    "EPILOGUE_FN",
    "epilogue_fn_args",
    "N_EXPTS_TOT",
    "N_EXPTS_ACT",
    "MAX_NUM_IMPRECISE_ACC",
    "ALLOW_TF32",
    "FLEXPOINT_SATURATE_INF",
    "PER_BATCH_SCALE",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "GROUP_M",
    "XCD_SWIZZLE",
    "SWIZZLE_MX_VALUE",
    "SWIZZLE_MX_SCALE",
    "EPILOGUE_SUBTILE",
    "EVEN_K",
    "SPLIT_K",
    "W_CACHE_MODIFIER",
    "NUM_SMS",
    "X_TMA_MODE",
    "Y_TMA_MODE",
    "TOKENS_PER_EXPT_FOR_ANNOTATION",
    "UPCAST_INDICES",
    "SWAP_XW",
    "IS_EPILOGUE_QUANT_MXFP8"
  ],
  "_per_device_alloc_fns": [],
  "get_per_device_per_stream_alloc_fn": [
    "device"
  ],
  "get_scaled_dot_format_string": [
    "dtype"
  ],
  "xcd_swizzle": [
    "pid",
    "domain_size",
    "XCD_SWIZZLE"
  ],
  "swizzle2d": [
    "pid",
    "grid_m",
    "grid_n",
    "GROUP_M"
  ],
  "make_matmul_repr": [
    "base_name",
    "order"
  ],
  "matmul_launch_metadata": [
    "grid",
    "kernel",
    "args"
  ],
  "_reduce_grouped": [
    "X",
    "stride_xb",
    "stride_xm",
    "stride_xn",
    "XScale",
    "Out",
    "stride_om",
    "stride_on",
    "OutExpectedScale",
    "OutActualScale",
    "OutChecksumScale",
    "InIndx",
    "B",
    "N",
    "XMxScale",
    "stride_mxb",
    "stride_mxs",
    "OutMxScale",
    "stride_omxs",
    "ACTIVATION_FN",
    "activation_fn_args",
    "ACTIVATION_REDUCTION_N",
    "EPILOGUE_FN",
    "epilogue_fn_args",
    "HAS_IN_MX_SCALE",
    "HAS_OUT_MX_SCALE",
    "FLEXPOINT_SATURATE_INF",
    "K",
    "BLOCK_N"
  ],
  "OptFlags": {
    "__post_init__": [
      "self"
    ]
  },
  "make_default_opt_flags_amd": [
    "out_dtype",
    "lhs_dtype",
    "rhs_dtype",
    "precision_config",
    "m",
    "n",
    "k",
    "routing_data",
    "can_use_persistent_tma",
    "can_use_fused_scatter",
    "enforce_bitwise_invariance",
    "epilogue_effective_itemsize",
    "constraints"
  ],
  "make_default_opt_flags_nvidia": [
    "out_dtype",
    "lhs_dtype",
    "rhs_dtype",
    "precision_config",
    "m",
    "n",
    "k",
    "routing_data",
    "can_use_persistent_tma",
    "can_use_fused_scatter",
    "enforce_bitwise_invariance",
    "epilogue_effective_itemsize",
    "constraints"
  ],
  "update_opt_flags_constraints": [
    "constraints"
  ],
  "reset_opt_flags_constraints": [],
  "set_opt_flags": [
    "opt_flags"
  ],
  "InapplicableConstraint": {},
  "make_opt_flags": [
    "out_dtype",
    "lhs_dtype",
    "rhs_dtype",
    "precision_config",
    "m",
    "n",
    "k",
    "routing_data",
    "can_use_persistent_tma",
    "can_use_fused_scatter",
    "epilogue_effective_itemsize"
  ],
  "_zero_masked_rows": [
    "pid_m",
    "pid_n",
    "Y",
    "stride_y_m",
    "stride_y_n",
    "N",
    "ScatterSrcIndx",
    "num_idxs",
    "BLOCK_M",
    "BLOCK_N"
  ],
  "_matmul_ogs": [
    "Y",
    "YPtr",
    "stride_y_k",
    "stride_y_z",
    "stride_y_m",
    "stride_y_n",
    "YExpectedScale",
    "YActualScale",
    "YChecksumScale",
    "stride_y_mx_z",
    "stride_y_mx_m",
    "stride_y_mx_n",
    "X",
    "XPtr",
    "stride_x_z",
    "stride_x_m",
    "stride_x_k",
    "XScale",
    "XMxScale",
    "stride_x_mx_z",
    "stride_x_mx_m",
    "stride_x_mx_k",
    "W",
    "WPtr",
    "stride_w_e",
    "stride_w_k",
    "stride_w_n",
    "W_TRANSPOSE",
    "WScale",
    "WMxScale",
    "stride_w_mx_e",
    "stride_w_mx_k",
    "stride_w_mx_n",
    "B",
    "stride_b_e",
    "NRows",
    "M",
    "N",
    "K",
    "Betas",
    "Gammas",
    "GatherIndx",
    "ScatterSrcIndx",
    "num_idxs",
    "WriteBackIndx",
    "writeback_size",
    "ExptHist",
    "ExptOffs",
    "ExptOffsSum",
    "ExptData",
    "batch_size",
    "grid_m",
    "grid_n",
    "out_alpha",
    "ACTIVATION_FN",
    "activation_fn_args",
    "ACTIVATION_REDUCTION_N",
    "EPILOGUE_FN",
    "epilogue_fn_args",
    "N_EXPTS_TOT",
    "N_EXPTS_ACT",
    "MAX_NUM_IMPRECISE_ACC",
    "ALLOW_TF32",
    "FLEXPOINT_SATURATE_INF",
    "PER_BATCH_SCALE",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "GROUP_M",
    "XCD_SWIZZLE",
    "SWIZZLE_MX_VALUE",
    "SWIZZLE_MX_SCALE",
    "EPILOGUE_SUBTILE",
    "EVEN_K",
    "SPLIT_K",
    "W_CACHE_MODIFIER",
    "NUM_SMS",
    "X_TMA_MODE",
    "Y_TMA_MODE",
    "TOKENS_PER_EXPT_FOR_ANNOTATION",
    "UPCAST_INDICES",
    "SWAP_XW",
    "IS_EPILOGUE_QUANT_MXFP8"
  ],
  "compute_grid_size": [
    "routing_data",
    "m",
    "n",
    "block_m",
    "block_n"
  ],
  "compute_block_n": [
    "n",
    "arch",
    "precision_config"
  ],
  "compute_block_k": [
    "m",
    "k",
    "is_persistent",
    "lhs_dtype",
    "rhs_dtype",
    "precision_config"
  ],
  "compute_split_k": [
    "block_k",
    "k",
    "grid_size"
  ],
  "compute_num_warps": [
    "block_m",
    "block_n",
    "precision_config"
  ],
  "compute_num_stages": [
    "precision_config",
    "is_persistent",
    "block_m",
    "block_n",
    "block_k",
    "out_dtype",
    "lhs_dtype",
    "rhs_dtype",
    "epilogue_subtile",
    "epilogue_effective_itemsize"
  ],
  "compute_block_nk": [
    "n",
    "block_m",
    "grid_m",
    "num_xcds",
    "lhs_dtype",
    "rhs_dtype",
    "precision_config"
  ],
  "vpopc": [
    "x"
  ],
  "_sum_bitmatrix_memset": [
    "Ret",
    "BLOCK"
  ],
  "_sum_bitmatrix_rows": [
    "B",
    "shape_bm",
    "stride_bm",
    "stride_bn",
    "Ret",
    "Partials",
    "stride_pm",
    "stride_pn",
    "shape_pn",
    "BLOCK_MM",
    "BLOCK_M"
  ],
  "clear_sums": [
    "n_cols",
    "device",
    "MEMSET_BLOCK"
  ],
  "sum_bitmatrix_rows": [
    "x",
    "out_ret",
    "partials_block_size"
  ],
  "collect_mm_processor_stats": [
    "llm_engine",
    "num_warmup_reqs"
  ],
  "calculate_mm_processor_metrics": [
    "stats_by_stage",
    "selected_percentiles"
  ],
  "validate_args": [
    "args"
  ],
  "benchmark_multimodal_processor": [
    "args"
  ],
  "add_cli_args": [
    "parser"
  ],
  "cold_startup": [],
  "run_startup_in_subprocess": [
    "engine_args",
    "result_queue"
  ],
  "save_to_pytorch_benchmark_format": [
    "args",
    "results"
  ],
  "MILLISECONDS_TO_SECONDS_CONVERSION": [],
  "TERM_PLOTLIB_AVAILABLE": [],
  "get_first_model_from_server": [
    "base_url",
    "headers"
  ],
  "SpecDecodeMetrics": {},
  "fetch_spec_decode_metrics": [
    "base_url",
    "session"
  ],
  "TaskType": {
    "GENERATION": [],
    "POOLING": []
  },
  "BenchmarkMetrics": {},
  "EmbedBenchmarkMetrics": {},
  "_get_current_request_rate": [
    "ramp_up_strategy",
    "ramp_up_start_rps",
    "ramp_up_end_rps",
    "request_index",
    "total_requests",
    "request_rate"
  ],
  "get_request": [
    "input_requests",
    "request_rate",
    "burstiness",
    "ramp_up_strategy",
    "ramp_up_start_rps",
    "ramp_up_end_rps"
  ],
  "calculate_metrics_for_embeddings": [
    "outputs",
    "dur_s",
    "selected_percentiles"
  ],
  "calculate_metrics": [
    "input_requests",
    "outputs",
    "dur_s",
    "tokenizer",
    "selected_percentiles",
    "goodput_config_dict"
  ],
  "benchmark": [
    "task_type",
    "endpoint_type",
    "api_url",
    "base_url",
    "model_id",
    "model_name",
    "tokenizer",
    "input_requests",
    "logprobs",
    "request_rate",
    "burstiness",
    "disable_tqdm",
    "num_warmups",
    "profile",
    "selected_percentile_metrics",
    "selected_percentiles",
    "ignore_eos",
    "goodput_config_dict",
    "max_concurrency",
    "lora_modules",
    "extra_headers",
    "extra_body",
    "ramp_up_strategy",
    "ramp_up_start_rps",
    "ramp_up_end_rps",
    "ready_check_timeout_sec"
  ],
  "check_goodput_args": [
    "args"
  ],
  "parse_goodput": [
    "slo_pairs"
  ],
  "main_async": [
    "args"
  ],
  "SampleRequest": {},
  "BenchmarkDataset": {
    "DEFAULT_SEED": [],
    "IS_MULTIMODAL": [],
    "__init__": [
      "self",
      "dataset_path",
      "random_seed",
      "disable_shuffle"
    ],
    "apply_multimodal_chat_transformation": [
      "self",
      "prompt",
      "mm_content"
    ],
    "load_data": [
      "self"
    ],
    "get_random_lora_request": [
      "self",
      "max_loras",
      "lora_path"
    ],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "request_id_prefix",
      "no_oversample"
    ],
    "maybe_oversample_requests": [
      "self",
      "requests",
      "num_requests",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "is_valid_sequence": [
    "prompt_len",
    "output_len",
    "min_len",
    "max_prompt_len",
    "max_total_len",
    "skip_min_output_len_check"
  ],
  "lora_path_on_disk": [
    "lora_path"
  ],
  "process_image": [
    "image"
  ],
  "process_video": [
    "video"
  ],
  "gen_prompt_decode_to_target_len": [
    "tokenizer",
    "token_sequence",
    "target_token_len",
    "max_retry",
    "add_special_tokens",
    "rng"
  ],
  "RandomDataset": {
    "DEFAULT_PREFIX_LEN": [],
    "DEFAULT_RANGE_RATIO": [],
    "DEFAULT_INPUT_LEN": [],
    "DEFAULT_OUTPUT_LEN": [],
    "__init__": [
      "self"
    ],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "request_id_prefix",
      "no_oversample",
      "prefix_len",
      "range_ratio",
      "input_len",
      "output_len",
      "batchsize"
    ],
    "get_prefix": [
      "self",
      "allowed_tokens",
      "prefix_len"
    ],
    "get_sampling_params": [
      "self",
      "num_requests",
      "range_ratio",
      "input_len",
      "output_len",
      "tokenizer"
    ],
    "generate_token_sequence": [
      "self"
    ]
  },
  "RandomDatasetForReranking": {
    "__init__": [
      "self"
    ],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "request_id_prefix",
      "range_ratio",
      "input_len",
      "batchsize",
      "is_reranker"
    ]
  },
  "RandomMultiModalDataset": {
    "IS_MULTIMODAL": [],
    "DEFAULT_LIMIT_MM_PER_PROMPT": [],
    "DEFAULT_BASE_ITEMS_PER_REQUEST": [],
    "DEFAULT_NUM_MM_ITEMS_RANGE_RATIO": [],
    "DEFAULT_MM_ITEM_BUCKET_CONFIG": [],
    "DEFAULT_ENABLE_MULTIMODAL_CHAT": [],
    "__init__": [
      "self"
    ],
    "generate_synthetic_image": [
      "self",
      "width",
      "height"
    ],
    "generate_synthetic_video": [
      "self",
      "width",
      "height",
      "num_frames"
    ],
    "map_config_to_modality": [
      "self",
      "config"
    ],
    "normalize_bucket_config": [
      "self",
      "bucket_config"
    ],
    "generate_mm_item": [
      "self",
      "mm_item_config"
    ],
    "get_mm_item_sampling_params": [
      "self",
      "base_items_per_request",
      "num_mm_items_range_ratio",
      "limit_mm_per_prompt",
      "bucket_config"
    ],
    "get_mm_item_iterator": [
      "self",
      "min_num_mm_items",
      "max_num_mm_items",
      "bucket_config",
      "limit_mm_per_prompt"
    ],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "request_id_prefix",
      "no_oversample",
      "prefix_len",
      "range_ratio",
      "input_len",
      "output_len",
      "limit_mm_per_prompt",
      "base_items_per_request",
      "num_mm_items_range_ratio",
      "bucket_config",
      "enable_multimodal_chat"
    ]
  },
  "ShareGPTDataset": {
    "__init__": [
      "self"
    ],
    "load_data": [
      "self"
    ],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "lora_path",
      "max_loras",
      "output_len",
      "enable_multimodal_chat",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "_ValidateDatasetArgs": {
    "__call__": [
      "self",
      "parser",
      "namespace",
      "values",
      "option_string"
    ]
  },
  "add_dataset_parser": [
    "parser"
  ],
  "add_random_dataset_base_args": [
    "parser_or_group"
  ],
  "add_random_multimodal_dataset_args": [
    "parser_or_group"
  ],
  "get_samples": [
    "args",
    "tokenizer"
  ],
  "CustomDataset": {
    "__init__": [
      "self"
    ],
    "load_data": [
      "self"
    ],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "lora_path",
      "max_loras",
      "output_len",
      "enable_multimodal_chat",
      "skip_chat_template",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "SpecBench": {
    "__init__": [
      "self"
    ],
    "load_data": [
      "self"
    ],
    "sample": [
      "self"
    ]
  },
  "SonnetDataset": {
    "DEFAULT_PREFIX_LEN": [],
    "DEFAULT_INPUT_LEN": [],
    "DEFAULT_OUTPUT_LEN": [],
    "__init__": [
      "self"
    ],
    "load_data": [
      "self"
    ],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "prefix_len",
      "input_len",
      "output_len",
      "return_prompt_formatted",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "BurstGPTDataset": {
    "__init__": [
      "self"
    ],
    "load_data": [
      "self"
    ],
    "_sample_loaded_data": [
      "self",
      "num_requests"
    ],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "max_loras",
      "lora_path",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "HuggingFaceDataset": {
    "__init__": [
      "self",
      "dataset_path",
      "dataset_split",
      "no_stream",
      "dataset_subset",
      "hf_name"
    ],
    "load_data": [
      "self"
    ]
  },
  "ConversationDataset": {
    "SUPPORTED_DATASET_PATHS": [],
    "IS_MULTIMODAL": [],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "output_len",
      "enable_multimodal_chat",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "MultiModalConversationDataset": {
    "SUPPORTED_DATASET_PATHS": [],
    "IS_MULTIMODAL": [],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "output_len",
      "enable_multimodal_chat",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "VisionArenaDataset": {
    "DEFAULT_OUTPUT_LEN": [],
    "SUPPORTED_DATASET_PATHS": [],
    "IS_MULTIMODAL": [],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "output_len",
      "enable_multimodal_chat",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "MMVUDataset": {
    "DEFAULT_OUTPUT_LEN": [],
    "SUPPORTED_DATASET_PATHS": [],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "output_len",
      "enable_multimodal_chat",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "InstructCoderDataset": {
    "DEFAULT_OUTPUT_LEN": [],
    "SUPPORTED_DATASET_PATHS": [],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "output_len",
      "enable_multimodal_chat",
      "skip_chat_template",
      "request_id_prefix",
      "no_oversample"
    ],
    "sample_prompts": [
      "self",
      "n"
    ]
  },
  "MTBenchDataset": {
    "DEFAULT_OUTPUT_LEN": [],
    "SUPPORTED_DATASET_PATHS": [],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "output_len",
      "enable_multimodal_chat",
      "skip_chat_template",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "BlazeditDataset": {
    "DEFAULT_OUTPUT_LEN": [],
    "SUPPORTED_DATASET_PATHS": [],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "output_len",
      "skip_chat_template",
      "request_id_prefix",
      "no_oversample",
      "min_distance",
      "max_distance"
    ]
  },
  "AIMODataset": {
    "SUPPORTED_DATASET_PATHS": [],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "output_len",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "zeta_prompt": [],
  "_format_zeta_prompt": [
    "sample",
    "original_start_marker"
  ],
  "NextEditPredictionDataset": {
    "SUPPORTED_DATASET_PATHS": [],
    "MAPPING_PROMPT_FUNCS": [],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "ASRDataset": {
    "SUPPORTED_DATASET_PATHS": [],
    "DEFAULT_OUTPUT_LEN": [],
    "IS_MULTIMODAL": [],
    "TRANSCRIPTION_PREAMBLE": [],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "output_len",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "MLPerfDataset": {
    "SUPPORTED_DATASET_PATHS": [],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "output_len",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "PrefixRepetitionRandomDataset": {
    "DEFAULT_PREFIX_LEN": [],
    "DEFAULT_SUFFIX_LEN": [],
    "DEFAULT_NUM_PREFIXES": [],
    "DEFAULT_OUTPUT_LEN": [],
    "__init__": [
      "self"
    ],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "prefix_len",
      "suffix_len",
      "num_prefixes",
      "output_len",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "MMStarDataset": {
    "DEFAULT_OUTPUT_LEN": [],
    "SUPPORTED_DATASET_PATHS": [],
    "IS_MULTIMODAL": [],
    "sample": [
      "self",
      "tokenizer",
      "num_requests",
      "output_len",
      "enable_multimodal_chat",
      "request_id_prefix",
      "no_oversample"
    ]
  },
  "run_vllm": [
    "requests",
    "n",
    "engine_args",
    "do_profile",
    "disable_detokenize"
  ],
  "run_vllm_chat": [
    "requests",
    "n",
    "engine_args",
    "do_profile",
    "disable_detokenize"
  ],
  "run_vllm_async": [
    "requests",
    "n",
    "engine_args",
    "do_profile",
    "disable_frontend_multiprocessing",
    "disable_detokenize"
  ],
  "run_hf": [
    "requests",
    "model",
    "tokenizer",
    "n",
    "max_batch_size",
    "trust_remote_code",
    "disable_detokenize"
  ],
  "get_requests": [
    "args",
    "tokenizer"
  ],
  "filter_requests_for_dp": [
    "requests",
    "data_parallel_size"
  ],
  "convert_to_pytorch_benchmark_format": [
    "args",
    "metrics",
    "extra_info"
  ],
  "InfEncoder": {
    "clear_inf": [
      "self",
      "o"
    ],
    "iterencode": [
      "self",
      "o"
    ]
  },
  "write_to_json": [
    "filename",
    "records"
  ],
  "wait_for_endpoint": [
    "request_func",
    "test_input",
    "session",
    "timeout_seconds",
    "retry_interval"
  ],
  "AIOHTTP_TIMEOUT": [],
  "StreamedResponseHandler": {
    "__init__": [
      "self"
    ],
    "add_chunk": [
      "self",
      "chunk_bytes"
    ]
  },
  "RequestFuncInput": {},
  "RequestFuncOutput": {},
  "RequestFunc": {
    "__call__": [
      "self",
      "request_func_input",
      "session",
      "pbar"
    ]
  },
  "_validate_api_url": [
    "api_url",
    "api_name",
    "expected_suffixes"
  ],
  "_update_payload_common": [
    "payload",
    "request_func_input"
  ],
  "_update_headers_common": [
    "headers",
    "request_func_input"
  ],
  "async_request_openai_completions": [
    "request_func_input",
    "session",
    "pbar"
  ],
  "_get_chat_content": [
    "request_func_input",
    "mm_position"
  ],
  "async_request_openai_chat_completions": [
    "request_func_input",
    "session",
    "pbar",
    "mm_position"
  ],
  "async_request_openai_audio": [
    "request_func_input",
    "session",
    "pbar"
  ],
  "_run_pooling_request": [
    "session",
    "api_url",
    "payload",
    "headers",
    "pbar"
  ],
  "async_request_openai_embeddings": [
    "request_func_input",
    "session",
    "pbar"
  ],
  "async_request_vllm_rerank": [
    "request_func_input",
    "session",
    "pbar"
  ],
  "async_request_openai_embeddings_chat": [
    "request_func_input",
    "session",
    "pbar",
    "mm_position"
  ],
  "_try_extract_request_idx": [
    "request_func_input"
  ],
  "_preprocess_clip": [
    "request_func_input"
  ],
  "_preprocess_vlm2vec": [
    "request_func_input"
  ],
  "async_request_openai_embeddings_clip": [
    "request_func_input",
    "session",
    "pbar"
  ],
  "async_request_openai_embeddings_vlm2vec": [
    "request_func_input",
    "session",
    "pbar"
  ],
  "async_request_infinity_embeddings": [
    "request_func_input",
    "session",
    "pbar"
  ],
  "async_request_infinity_embeddings_clip": [
    "request_func_input",
    "session",
    "pbar"
  ],
  "OPENAI_COMPATIBLE_BACKENDS": [],
  "_first_present": [
    "run_data",
    "keys"
  ],
  "_get_numeric": [
    "run_data",
    "keys"
  ],
  "_infer_user_count": [
    "run_data",
    "user_count_var"
  ],
  "_infer_gpu_count": [
    "run_data",
    "gpu_count_var"
  ],
  "_get_throughput": [
    "run_data",
    "throughput_var"
  ],
  "_prepare_records": [
    "all_data"
  ],
  "_pareto_frontier": [
    "df",
    "x_col",
    "y_col"
  ],
  "_get_fig_path": [
    "fig_dir",
    "fig_group"
  ],
  "_plot_fig": [
    "fig_dir",
    "fig_group_data",
    "label_by"
  ],
  "plot_pareto": [
    "output_dir",
    "user_count_var",
    "gpu_count_var",
    "label_by"
  ],
  "SweepPlotParetoArgs": {
    "from_cli_args": [
      "cls",
      "args"
    ],
    "add_cli_args": [
      "cls",
      "parser"
    ]
  },
  "run_main": [
    "args"
  ],
  "_get_sla_base_path": [
    "output_dir",
    "serve_comb",
    "bench_comb"
  ],
  "_get_sla_iter_path": [
    "base_path",
    "sla_comb",
    "sla_variable",
    "sla_value"
  ],
  "_get_sla_run_path": [
    "iter_path",
    "run_number"
  ],
  "_iter_sla_val_paths": [
    "base_path",
    "sla_variable"
  ],
  "_sla_needs_server": [
    "serve_comb",
    "bench_combs",
    "sla_combs",
    "sla_variable",
    "output_dir"
  ],
  "run_sla": [
    "server",
    "bench_cmd"
  ],
  "SLAVariable": [],
  "SLAHistory": {
    "__init__": [
      "self",
      "min_value",
      "max_value"
    ],
    "get_xy": [
      "self"
    ],
    "get_max_passing": [
      "self"
    ],
    "get_min_failing": [
      "self"
    ]
  },
  "_compute_margin": [
    "sla_comb",
    "iter_data"
  ],
  "solve_sla": [
    "server",
    "bench_cmd"
  ],
  "search_sla": [
    "server",
    "bench_cmd"
  ],
  "run_slas": [
    "serve_cmd",
    "bench_cmd",
    "after_bench_cmd"
  ],
  "SweepServeSLAArgs": {
    "from_cli_args": [
      "cls",
      "args"
    ],
    "add_cli_args": [
      "cls",
      "parser"
    ]
  },
  "SLA_EPS": [],
  "SLACriterionBase": {
    "compute_margin": [
      "self",
      "actual"
    ],
    "format_cond": [
      "self",
      "lhs"
    ],
    "print_and_compute_margin": [
      "self",
      "metrics",
      "metrics_key"
    ]
  },
  "SLALessThan": {
    "compute_margin": [
      "self",
      "actual"
    ],
    "format_cond": [
      "self",
      "lhs"
    ]
  },
  "SLALessThanOrEqualTo": {
    "compute_margin": [
      "self",
      "actual"
    ],
    "format_cond": [
      "self",
      "lhs"
    ]
  },
  "SLAGreaterThan": {
    "compute_margin": [
      "self",
      "actual"
    ],
    "format_cond": [
      "self",
      "lhs"
    ]
  },
  "SLAGreaterThanOrEqualTo": {
    "compute_margin": [
      "self",
      "actual"
    ],
    "format_cond": [
      "self",
      "lhs"
    ]
  },
  "SLASweep": {
    "read_json": [
      "cls",
      "filepath"
    ],
    "from_records": [
      "cls",
      "records"
    ]
  },
  "SLASweepItem": {
    "from_record": [
      "cls",
      "record"
    ],
    "as_text": [
      "self",
      "sep"
    ]
  },
  "_get_supported_startup_keys": [],
  "_is_supported_param": [
    "param_key",
    "supported"
  ],
  "_filter_params": [
    "params"
  ],
  "_update_run_data": [
    "run_data",
    "serve_overrides",
    "startup_overrides",
    "run_number"
  ],
  "_strip_arg": [
    "cmd",
    "keys"
  ],
  "_apply_output_json": [
    "cmd",
    "output_path"
  ],
  "_get_comb_base_path": [
    "output_dir",
    "serve_comb",
    "startup_comb"
  ],
  "_get_comb_run_path": [
    "base_path",
    "run_number"
  ],
  "run_benchmark": [
    "startup_cmd"
  ],
  "run_comb": [
    "startup_cmd"
  ],
  "run_combs": [
    "startup_cmd"
  ],
  "SweepStartupArgs": {
    "from_cli_args": [
      "cls",
      "args"
    ],
    "add_cli_args": [
      "cls",
      "parser"
    ]
  },
  "sanitize_filename": [
    "filename"
  ],
  "ParameterSweep": {
    "read_json": [
      "cls",
      "filepath"
    ],
    "read_from_dict": [
      "cls",
      "data"
    ],
    "from_records": [
      "cls",
      "records"
    ]
  },
  "ParameterSweepItem": {
    "from_record": [
      "cls",
      "record"
    ],
    "__or__": [
      "self",
      "other"
    ],
    "name": [
      "self"
    ],
    "_iter_param_key_candidates": [
      "self",
      "param_key"
    ],
    "_iter_cmd_key_candidates": [
      "self",
      "param_key"
    ],
    "_normalize_cmd_key": [
      "self",
      "param_key"
    ],
    "has_param": [
      "self",
      "param_key"
    ],
    "_normalize_cmd_kv_pair": [
      "self",
      "k",
      "v"
    ],
    "apply_to_cmd": [
      "self",
      "cmd"
    ],
    "as_text": [
      "self",
      "sep"
    ]
  },
  "SUBCOMMANDS": [],
  "_comb_needs_server": [
    "serve_comb",
    "bench_combs",
    "output_dir"
  ],
  "SweepServeArgs": {
    "from_cli_args": [
      "cls",
      "args"
    ],
    "add_cli_args": [
      "cls",
      "parser"
    ],
    "parse_link_vars": [
      "s"
    ]
  },
  "PlotFilterBase": {
    "parse_str": [
      "cls",
      "s"
    ],
    "apply": [
      "self",
      "df"
    ]
  },
  "PlotEqualTo": {
    "apply": [
      "self",
      "df"
    ]
  },
  "PlotNotEqualTo": {
    "apply": [
      "self",
      "df"
    ]
  },
  "PlotLessThan": {
    "apply": [
      "self",
      "df"
    ]
  },
  "PlotLessThanOrEqualTo": {
    "apply": [
      "self",
      "df"
    ]
  },
  "PlotGreaterThan": {
    "apply": [
      "self",
      "df"
    ]
  },
  "PlotGreaterThanOrEqualTo": {
    "apply": [
      "self",
      "df"
    ]
  },
  "PlotFilters": {
    "parse_str": [
      "cls",
      "s"
    ],
    "apply": [
      "self",
      "df"
    ]
  },
  "PlotBinner": {
    "parse_str": [
      "cls",
      "s"
    ],
    "apply": [
      "self",
      "df"
    ]
  },
  "PlotBinners": {
    "parse_str": [
      "cls",
      "s"
    ],
    "apply": [
      "self",
      "df"
    ]
  },
  "_json_load_bytes": [
    "path"
  ],
  "_convert_inf_nan_strings": [
    "data"
  ],
  "_get_metric": [
    "run_data",
    "metric_key"
  ],
  "_get_group": [
    "run_data",
    "group_keys"
  ],
  "DummyExecutor": {
    "map": [],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "exc_traceback"
    ]
  },
  "plot": [
    "output_dir",
    "fig_dir",
    "fig_by",
    "row_by",
    "col_by",
    "curve_by"
  ],
  "SweepPlotArgs": {
    "from_cli_args": [
      "cls",
      "args"
    ],
    "add_cli_args": [
      "cls",
      "parser"
    ]
  },
  "ServerProcess": {
    "__init__": [
      "self",
      "server_cmd",
      "after_bench_cmd"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "exc_traceback"
    ],
    "start": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "run_subcommand": [
      "self",
      "cmd"
    ],
    "after_bench": [
      "self"
    ],
    "_get_vllm_server_address": [
      "self"
    ],
    "is_server_ready": [
      "self"
    ],
    "wait_until_ready": [
      "self",
      "timeout"
    ],
    "reset_caches": [
      "self"
    ]
  },
  "LoRARequest": {
    "__post_init__": [
      "self"
    ],
    "adapter_id": [
      "self"
    ],
    "name": [
      "self"
    ],
    "path": [
      "self"
    ],
    "__eq__": [
      "self",
      "value"
    ],
    "__hash__": [
      "self"
    ]
  },
  "DEFAULT_LANGUAGE_WRAPPER_KEY": [],
  "AdapterLRUCache": {
    "__init__": [
      "self",
      "capacity",
      "deactivate_fn"
    ],
    "_on_remove": [
      "self",
      "key",
      "value"
    ]
  },
  "LoRAModelManager": {
    "__init__": [
      "self",
      "model",
      "max_num_seqs",
      "max_num_batched_tokens",
      "vocab_size",
      "lora_config",
      "device",
      "vllm_config"
    ],
    "_init_punica_wrapper": [
      "self",
      "max_num_batched_tokens",
      "vllm_config"
    ],
    "_maybe_init_mm": [
      "self",
      "vllm_config",
      "max_num_batched_tokens"
    ],
    "__len__": [
      "self"
    ],
    "capacity": [
      "self"
    ],
    "lora_slots": [
      "self"
    ],
    "adapter_slots": [
      "self"
    ],
    "activate_adapter": [
      "self",
      "lora_id"
    ],
    "_deactivate_adapter": [
      "self",
      "lora_id"
    ],
    "_add_adapter": [
      "self",
      "lora"
    ],
    "pin_adapter": [
      "self",
      "lora_id"
    ],
    "_set_adapter_mapping": [
      "self",
      "mapping"
    ],
    "remove_all_adapters": [
      "self"
    ],
    "_create_lora_modules": [
      "self"
    ],
    "register_module": [
      "self",
      "module_name",
      "module"
    ],
    "_pad_lora_pairs_to_triplets": [
      "loras"
    ],
    "create_dummy_lora": [
      "self",
      "lora_id",
      "rank",
      "embedding_modules"
    ],
    "_match_target_modules": [
      "self",
      "module_name"
    ],
    "_get_punica_wrapper": [
      "self",
      "module_name"
    ],
    "_register_packed_modules": [
      "self",
      "module_full_name"
    ],
    "_create_merged_loras_inplace": [
      "self",
      "lora_model"
    ],
    "_stack_moe_lora_weights": [
      "self",
      "lora_model",
      "module",
      "module_name"
    ],
    "_get_lora_layer_weights": [
      "self",
      "lora_model",
      "module_name"
    ],
    "deactivate_adapter": [
      "self",
      "adapter_id"
    ],
    "add_adapter": [
      "self",
      "adapter"
    ],
    "set_adapter_mapping": [
      "self",
      "mapping"
    ],
    "remove_adapter": [
      "self",
      "adapter_id"
    ],
    "list_adapters": [
      "self"
    ],
    "get_adapter": [
      "self",
      "adapter_id"
    ]
  },
  "LoRALRUCache": {
    "__init__": [
      "self",
      "capacity",
      "deactivate_lora_fn"
    ]
  },
  "LRUCacheLoRAModelManager": {
    "__init__": [
      "self",
      "model",
      "max_num_seqs",
      "max_num_batched_tokens",
      "vocab_size",
      "lora_config",
      "device",
      "vllm_config"
    ],
    "list_adapters": [
      "self"
    ],
    "add_adapter": [
      "self",
      "lora"
    ],
    "activate_adapter": [
      "self",
      "lora_id"
    ],
    "remove_oldest_adapter": [
      "self"
    ],
    "pin_adapter": [
      "self",
      "lora_id"
    ],
    "_pin_lora_in_cpu_cache": [
      "self",
      "lora_id"
    ],
    "_pin_lora_in_gpu_cache": [
      "self",
      "lora_id"
    ]
  },
  "create_lora_manager": [
    "model",
    "max_num_seqs",
    "max_num_batched_tokens",
    "vocab_size",
    "lora_config",
    "vllm_config",
    "device",
    "lora_manager_cls"
  ],
  "WorkerLoRAManager": {
    "__init__": [
      "self",
      "vllm_config",
      "device",
      "embedding_modules",
      "lora_model_cls"
    ],
    "dummy_lora_cache": [
      "self"
    ],
    "is_enabled": [
      "self"
    ],
    "create_lora_manager": [
      "self",
      "model",
      "vllm_config"
    ],
    "_load_adapter": [
      "self",
      "lora_request"
    ],
    "add_dummy_lora": [
      "self",
      "lora_request",
      "rank"
    ],
    "pin_adapter": [
      "self",
      "adapter_id"
    ],
    "set_active_adapters": [
      "self",
      "requests",
      "mapping"
    ],
    "supports_tower_connector_lora": [
      "self"
    ],
    "_apply_adapters": [
      "self",
      "adapter_requests"
    ],
    "add_adapter": [
      "self",
      "adapter_request"
    ],
    "remove_adapter": [
      "self",
      "adapter_id"
    ],
    "remove_all_adapters": [
      "self"
    ],
    "list_adapters": [
      "self"
    ]
  },
  "LRUCacheWorkerLoRAManager": {
    "create_lora_manager": [
      "self",
      "model",
      "vllm_config"
    ],
    "_apply_adapters": [
      "self",
      "lora_requests"
    ],
    "add_adapter": [
      "self",
      "lora_request"
    ]
  },
  "_GLOBAL_LORA_ID": [],
  "get_lora_id": [],
  "is_moe_model": [
    "model"
  ],
  "from_layer": [
    "layer",
    "max_loras",
    "lora_config",
    "packed_modules_list",
    "model_config"
  ],
  "from_layer_logits_processor": [
    "layer",
    "lm_head",
    "max_loras",
    "lora_config",
    "model_config"
  ],
  "replace_submodule": [
    "model",
    "module_name",
    "new_module"
  ],
  "parse_fine_tuned_lora_name": [
    "name",
    "weights_mapper"
  ],
  "is_base_embeddding_weights": [
    "name"
  ],
  "get_supported_lora_modules": [
    "model"
  ],
  "get_adapter_absolute_path": [
    "lora_path"
  ],
  "process_packed_modules_mapping": [
    "model"
  ],
  "LoRAResolver": {
    "resolve_lora": [
      "self",
      "base_model_name",
      "lora_name"
    ]
  },
  "_LoRAResolverRegistry": {
    "get_supported_resolvers": [
      "self"
    ],
    "register_resolver": [
      "self",
      "resolver_name",
      "resolver"
    ],
    "get_resolver": [
      "self",
      "resolver_name"
    ]
  },
  "LoRAResolverRegistry": [],
  "PEFTHelper": {
    "_validate_features": [
      "self"
    ],
    "__post_init__": [
      "self"
    ],
    "from_dict": [
      "cls",
      "config_dict"
    ],
    "from_local_dir": [
      "cls",
      "lora_path",
      "max_position_embeddings",
      "tensorizer_config_dict"
    ],
    "validate_legal": [
      "self",
      "lora_config"
    ]
  },
  "LoRAModel": {
    "__init__": [
      "self",
      "lora_model_id",
      "rank",
      "loras"
    ],
    "clone": [
      "self",
      "lora_model_id"
    ],
    "get_lora": [
      "self",
      "module_name"
    ],
    "check_lora_name": [
      "self",
      "lora_name"
    ],
    "from_lora_tensors": [
      "cls",
      "lora_model_id",
      "tensors",
      "peft_helper",
      "device",
      "dtype",
      "model_vocab_size",
      "weights_mapper"
    ],
    "from_local_checkpoint": [
      "cls",
      "lora_dir",
      "expected_lora_modules",
      "peft_helper"
    ]
  },
  "LoRALayerWeights": {
    "__init__": [
      "self",
      "module_name",
      "rank",
      "lora_alpha",
      "lora_a",
      "lora_b",
      "scaling"
    ],
    "optimize": [
      "self"
    ],
    "input_dim": [
      "self"
    ],
    "output_dim": [
      "self"
    ],
    "is_packed": [
      "self"
    ],
    "from_config": [
      "cls",
      "module_name",
      "peft_helper"
    ],
    "create_dummy_lora_weights": [
      "cls",
      "module_name",
      "input_dim",
      "output_dim",
      "rank",
      "dtype",
      "device"
    ]
  },
  "PackedLoRALayerWeights": {
    "__init__": [
      "self",
      "module_name",
      "rank",
      "lora_alphas",
      "lora_a",
      "lora_b",
      "scaling"
    ],
    "pack": [
      "cls",
      "loras"
    ],
    "pack_moe": [
      "cls",
      "loras",
      "module_name",
      "is_non_gated_moe"
    ],
    "optimize": [
      "self"
    ],
    "input_dim": [
      "self"
    ],
    "output_dim": [
      "self"
    ],
    "is_packed": [
      "self"
    ]
  },
  "_lora_expand_kernel": [
    "input_ptr",
    "lora_ptr",
    "out_ptr",
    "M",
    "N",
    "K",
    "token_indices_sorted_by_lora_ids",
    "num_tokens_per_lora",
    "lora_token_start_loc",
    "lora_ids",
    "slice_start_loc",
    "input_d0_stride",
    "input_d1_stride",
    "input_d2_stride",
    "ls_d0_ptr",
    "ls_d1_ptr",
    "ls_d2_ptr",
    "output_d0_stride",
    "output_d1_stride",
    "output_hs_ptr",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "EVEN_K",
    "ADD_INPUTS",
    "CAST_TYPE",
    "SLICE_NUM",
    "SAME_STRIDE",
    "USE_GDC",
    "launch_pdl"
  ],
  "_lora_expand": [
    "inputs",
    "lora_b_weights",
    "output_tensor",
    "token_lora_mapping",
    "token_indices_sorted_by_lora_ids",
    "num_tokens_per_lora",
    "lora_token_start_loc",
    "lora_ids",
    "no_lora_flag_cpu",
    "offset_start",
    "add_inputs"
  ],
  "_lora_expand_fake": [
    "inputs",
    "lora_b_weights",
    "output_tensor",
    "token_lora_mapping",
    "token_indices_sorted_by_lora_ids",
    "num_tokens_per_lora",
    "lora_token_start_loc",
    "lora_ids",
    "no_lora_flag_cpu",
    "offset_start",
    "add_inputs"
  ],
  "mm_k": [
    "a_ptr",
    "b_ptr",
    "ak_stride",
    "bk_stride",
    "offset_k",
    "K",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "EVEN_K",
    "SPLIT_K",
    "CAST_TYPE",
    "b_dtype",
    "USE_GDC",
    "base_k"
  ],
  "do_expand_kernel": [
    "pid_n",
    "lora_index",
    "slice_id",
    "input_ptr",
    "lora_ptr",
    "out_ptr",
    "N",
    "K",
    "M_LEN",
    "ram",
    "slice_start_loc",
    "input_d0_stride",
    "input_d1_stride",
    "input_d2_stride",
    "ls_d0_ptr",
    "ls_d1_ptr",
    "ls_d2_ptr",
    "output_d0_stride",
    "output_d1_stride",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "SAME_STRIDE",
    "SLICE_NUM",
    "EVEN_K",
    "CAST_TYPE",
    "ADD_INPUTS",
    "USE_GDC"
  ],
  "do_shrink_kernel": [
    "pid_n",
    "pid_sk",
    "slice_id",
    "lora_index",
    "input_ptr",
    "lora_ptr",
    "out_ptr",
    "N",
    "K",
    "M_LEN",
    "ram",
    "input_d0_stride",
    "input_d1_stride",
    "lora_d0_stride",
    "lora_d1_stride",
    "lora_d2_stride",
    "output_d0_stride",
    "output_d1_stride",
    "output_d2_stride",
    "scaling",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "EVEN_K",
    "SPLIT_K",
    "SLICE_NUM",
    "USE_GDC"
  ],
  "is_batch_invariant": [],
  "_get_lora_a_ptr": [
    "lora_a_weights",
    "device"
  ],
  "_get_lora_b_ptr": [
    "lora_weights",
    "offset_start",
    "device"
  ],
  "load_lora_op_config": [
    "op_type",
    "add_inputs"
  ],
  "get_lora_op_configs": [
    "op_type",
    "max_loras",
    "batch",
    "hidden_size",
    "rank",
    "num_slices",
    "add_inputs",
    "moe_intermediate_size"
  ],
  "supports_pdl": [
    "device"
  ],
  "_get_ptr": [
    "lora_weights",
    "device"
  ],
  "_fused_moe_lora_kernel": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "topk_weights_ptr",
    "sorted_token_ids_ptr",
    "expert_ids_ptr",
    "num_tokens_post_padded_ptr",
    "N",
    "K",
    "EM",
    "num_valid_tokens",
    "num_experts",
    "lora_ids",
    "adapter_enabled",
    "stride_am",
    "stride_ak",
    "stride_bl",
    "stride_be",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "stride_tl",
    "stride_el",
    "slice_a_size",
    "slice_c_size",
    "num_slice_a",
    "num_slice_c",
    "top_k",
    "MUL_ROUTED_WEIGHT",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "SPLIT_K",
    "USE_GDC",
    "launch_pdl",
    "IS_PRIMARY"
  ],
  "_fused_moe_lora_shrink": [
    "a_intermediate_cache1",
    "qcurr_hidden_states",
    "lora_a_stacked",
    "topk_weights",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_post_padded",
    "top_k_num",
    "lora_ids",
    "adapter_enabled",
    "device",
    "N",
    "M",
    "EM",
    "K",
    "num_tokens",
    "num_experts",
    "num_slices",
    "block_size_m",
    "block_size_n",
    "block_size_k",
    "group_size_m",
    "num_warps",
    "num_stages",
    "split_k",
    "mul_routed_weight",
    "use_gdc"
  ],
  "_fused_moe_lora_expand": [
    "output",
    "a_intermediate_cache1",
    "b_intermediate_cache1",
    "lora_b_stacked",
    "topk_weights",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_post_padded",
    "top_k_num",
    "lora_ids",
    "adapter_enabled",
    "device",
    "N",
    "M",
    "EM",
    "K",
    "num_tokens",
    "num_experts",
    "num_slices",
    "max_lora_rank",
    "w1_output_dim_size",
    "block_size_m",
    "block_size_n",
    "block_size_k",
    "group_size_m",
    "num_warps",
    "num_stages",
    "split_k",
    "mul_routed_weight",
    "offset",
    "use_gdc"
  ],
  "_fused_moe_lora": [
    "output",
    "qcurr_hidden_states",
    "lora_a_stacked",
    "lora_b_stacked",
    "topk_weights",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_post_padded",
    "max_lora_rank",
    "top_k_num",
    "lora_ids",
    "adapter_enabled",
    "shrink_block_size_m",
    "shrink_block_size_n",
    "shrink_block_size_k",
    "shrink_group_size_m",
    "shrink_num_warps",
    "shrink_num_stages",
    "shrink_split_k",
    "expand_block_size_m",
    "expand_block_size_n",
    "expand_block_size_k",
    "expand_group_size_m",
    "expand_num_warps",
    "expand_num_stages",
    "expand_split_k",
    "mul_routed_weight",
    "fully_sharded",
    "offset"
  ],
  "_fused_moe_lora_fake": [
    "output",
    "qcurr_hidden_states",
    "lora_a_stacked",
    "lora_b_stacked",
    "topk_weights",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_post_padded",
    "max_lora_rank",
    "top_k_num",
    "lora_ids",
    "adapter_enabled",
    "shrink_block_size_m",
    "shrink_block_size_n",
    "shrink_block_size_k",
    "shrink_group_size_m",
    "shrink_num_warps",
    "shrink_num_stages",
    "shrink_split_k",
    "expand_block_size_m",
    "expand_block_size_n",
    "expand_block_size_k",
    "expand_group_size_m",
    "expand_num_warps",
    "expand_num_stages",
    "expand_split_k",
    "mul_routed_weight"
  ],
  "_fused_moe_lora_shrink_fake": [
    "a_intermediate_cache1",
    "qcurr_hidden_states",
    "lora_a_stacked",
    "topk_weights",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_post_padded",
    "top_k_num",
    "lora_ids",
    "adapter_enabled",
    "device",
    "N",
    "M",
    "EM",
    "K",
    "num_tokens",
    "num_experts",
    "num_slices",
    "block_size_m",
    "block_size_n",
    "block_size_k",
    "group_size_m",
    "num_warps",
    "num_stages",
    "split_k",
    "mul_routed_weight",
    "use_gdc"
  ],
  "_fused_moe_lora_expand_fake": [
    "output",
    "a_intermediate_cache1",
    "lora_b_stacked",
    "topk_weights",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_post_padded",
    "top_k_num",
    "lora_ids",
    "adapter_enabled",
    "device",
    "N",
    "M",
    "EM",
    "K",
    "num_tokens",
    "num_experts",
    "num_slices",
    "max_lora_rank",
    "w1_output_dim_size",
    "block_size_m",
    "block_size_n",
    "block_size_k",
    "group_size_m",
    "num_warps",
    "num_stages",
    "split_k",
    "mul_routed_weight",
    "use_gdc"
  ],
  "_lora_shrink_kernel": [
    "input_ptr",
    "lora_ptr",
    "out_ptr",
    "M",
    "N",
    "K",
    "token_indices_sorted_by_lora_ids",
    "num_tokens_per_lora",
    "lora_token_start_loc",
    "lora_ids",
    "scaling",
    "input_d0_stride",
    "input_d1_stride",
    "lora_d0_stride",
    "lora_d1_stride",
    "lora_d2_stride",
    "output_d0_stride",
    "output_d1_stride",
    "output_d2_stride",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "EVEN_K",
    "SPLIT_K",
    "GROUP_SIZE_M",
    "SLICE_NUM",
    "USE_GDC",
    "launch_pdl"
  ],
  "_lora_shrink": [
    "inputs",
    "lora_a_weights",
    "output_tensor",
    "token_lora_mapping",
    "token_indices_sorted_by_lora_ids",
    "num_tokens_per_lora",
    "lora_token_start_loc",
    "lora_ids",
    "no_lora_flag_cpu",
    "scaling"
  ],
  "_lora_shrink_fake": [
    "inputs",
    "lora_a_weights",
    "output_tensor",
    "token_lora_mapping",
    "token_indices_sorted_by_lora_ids",
    "num_tokens_per_lora",
    "lora_token_start_loc",
    "lora_ids",
    "no_lora_flag_cpu",
    "scaling"
  ],
  "LoRAKernelMeta": {
    "make": [
      "max_loras",
      "max_num_tokens",
      "device"
    ],
    "_reset": [
      "self"
    ],
    "prepare_tensors": [
      "self",
      "token_lora_mapping"
    ],
    "meta_args": [
      "self",
      "token_nums"
    ]
  },
  "bgmv_shrink": [
    "inputs",
    "lora_a_weights",
    "output_tensor",
    "lora_indices_tensor",
    "scaling"
  ],
  "bgmv_expand": [
    "inputs",
    "lora_b_weights",
    "output_tensor",
    "lora_indices_tensor",
    "add_inputs"
  ],
  "bgmv_expand_slice": [
    "inputs",
    "lora_b_weights",
    "output_tensor",
    "lora_indices_tensor",
    "slice_offset",
    "slice_size",
    "add_inputs"
  ],
  "sgmv_expand": [
    "inputs",
    "lora_b_weights",
    "output_tensor",
    "b_seq_start_loc",
    "seq_len_tensor",
    "lora_indices_tensor",
    "batches",
    "max_seq_length",
    "token_nums",
    "add_inputs"
  ],
  "sgmv_shrink": [
    "inputs",
    "lora_a_weights",
    "output_tensor",
    "b_seq_start_loc",
    "seq_len_tensor",
    "lora_indices_tensor",
    "batches",
    "max_seq_length",
    "token_nums",
    "scaling"
  ],
  "sgmv_expand_slice": [
    "inputs",
    "lora_b_weights",
    "output_tensor",
    "b_seq_start_loc",
    "seq_len_tensor",
    "lora_indices_tensor",
    "batches",
    "max_seq_length",
    "token_nums",
    "slice_offset",
    "slice_size",
    "add_inputs"
  ],
  "PunicaWrapperCPU": {
    "__init__": [
      "self",
      "max_num_batched_tokens",
      "max_batches",
      "device"
    ],
    "_shrink_prefill": [
      "self",
      "y",
      "x",
      "w_t_all",
      "scale"
    ],
    "_shrink_decode": [
      "self",
      "y",
      "x",
      "w_t_all",
      "scale"
    ],
    "_expand_prefill": [
      "self",
      "y",
      "x",
      "w_t_all",
      "add_inputs"
    ],
    "_expand_decode": [
      "self",
      "y",
      "x",
      "w_t_all",
      "add_inputs"
    ],
    "_expand_slice_prefill": [
      "self",
      "y",
      "x",
      "w_t_all",
      "y_offset",
      "y_slice_size",
      "add_inputs"
    ],
    "_expand_slice_decode": [
      "self",
      "y",
      "x",
      "w_t_all",
      "y_offset",
      "y_slice_size",
      "add_inputs"
    ],
    "_apply_expand": [
      "self",
      "y",
      "x",
      "w_t_all",
      "y_offset",
      "y_slice_size",
      "add_inputs"
    ],
    "_apply_shrink": [
      "self",
      "y",
      "x",
      "w_t_all",
      "scale"
    ],
    "add_shrink": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "scale"
    ],
    "add_expand": [
      "self",
      "y",
      "x",
      "lora_b_stacked",
      "output_slices",
      "offset_start",
      "add_inputs"
    ],
    "add_lora_embedding": [
      "self",
      "y",
      "x",
      "lora_b_stacked",
      "add_inputs"
    ],
    "add_lora_linear": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "lora_b_stacked",
      "scale",
      "output_slices"
    ],
    "add_lora_logits": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "lora_b_stacked",
      "scale"
    ]
  },
  "PunicaWrapperGPU": {
    "__init__": [
      "self",
      "max_num_batched_tokens",
      "max_batches",
      "device"
    ],
    "update_metadata": [
      "self",
      "mapping",
      "lora_index_to_id",
      "max_loras",
      "vocab_size"
    ],
    "add_shrink": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "scale"
    ],
    "add_expand": [
      "self",
      "y",
      "x",
      "lora_b_stacked",
      "output_slices",
      "offset_start",
      "add_inputs"
    ],
    "add_lora_embedding": [
      "self",
      "y",
      "x",
      "lora_b_stacked",
      "add_inputs"
    ],
    "add_lora_linear": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "lora_b_stacked",
      "scale",
      "output_slices"
    ],
    "add_lora_logits": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "lora_b_stacked",
      "scale"
    ],
    "moe_lora_align_block_size": [
      "self",
      "topk_ids",
      "num_tokens",
      "block_size",
      "num_experts",
      "max_loras",
      "adapter_enabled",
      "expert_map",
      "pad_sorted_ids"
    ],
    "add_lora_fused_moe": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "lora_b_stacked",
      "topk_weights",
      "sorted_token_ids",
      "expert_ids",
      "num_tokens_post_padded",
      "max_lora_rank",
      "top_k_num",
      "shrink_config",
      "expand_config",
      "adapter_enabled",
      "mul_routed_weight",
      "fully_sharded",
      "offset"
    ]
  },
  "compute_meta": [
    "token_lora_tensor"
  ],
  "convert_mapping": [
    "mapping",
    "lora_index_to_id",
    "max_loras",
    "vocab_size",
    "extra_vocab_size",
    "device"
  ],
  "get_punica_wrapper": [],
  "PunicaWrapperABC": {
    "update_metadata": [
      "self",
      "mapping",
      "lora_index_to_id",
      "max_loras",
      "vocab_size"
    ],
    "add_shrink": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "scale"
    ],
    "add_expand": [
      "self",
      "y",
      "x",
      "lora_b_stacked",
      "output_slices",
      "offset_start",
      "add_inputs"
    ],
    "add_lora_embedding": [
      "self",
      "y",
      "x",
      "lora_b_stacked",
      "add_inputs"
    ],
    "add_lora_linear": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "lora_b_stacked",
      "scale",
      "output_slices"
    ],
    "add_lora_logits": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "lora_b_stacked",
      "scale"
    ]
  },
  "PunicaWrapperBase": {
    "__init__": [
      "self",
      "max_num_batched_tokens",
      "max_batches",
      "device"
    ],
    "_update_base_metadata": [
      "self",
      "mapping",
      "lora_index_to_id",
      "max_loras",
      "vocab_size"
    ],
    "_update_prefill_metadata": [
      "self",
      "token_lora_tensor"
    ],
    "prefill_metadata": [
      "self"
    ],
    "token_lora_indices": [
      "self"
    ],
    "sampler_indices": [
      "self"
    ],
    "sampler_indices_padded": [
      "self"
    ],
    "embeddings_indices": [
      "self"
    ],
    "update_metadata": [
      "self",
      "mapping",
      "lora_index_to_id",
      "max_loras",
      "vocab_size"
    ],
    "add_shrink": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "scale"
    ],
    "add_expand": [
      "self",
      "y",
      "x",
      "lora_b_stacked",
      "output_slices",
      "offset_start",
      "add_inputs"
    ],
    "add_lora_embedding": [
      "self",
      "y",
      "x",
      "lora_b_stacked",
      "add_inputs"
    ],
    "add_lora_linear": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "lora_b_stacked",
      "scale",
      "output_slices"
    ],
    "add_lora_logits": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "lora_b_stacked",
      "scale"
    ],
    "moe_lora_align_block_size": [
      "self",
      "topk_ids",
      "num_tokens",
      "block_size",
      "num_experts",
      "max_loras",
      "adapter_enabled",
      "expert_map",
      "pad_sorted_ids"
    ],
    "add_lora_fused_moe": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "lora_b_stacked",
      "topk_weights",
      "sorted_token_ids",
      "expert_ids",
      "num_tokens_post_padded",
      "max_lora_rank",
      "top_k_num",
      "shrink_config",
      "expand_config",
      "adapter_enabled",
      "mul_routed_weight",
      "fully_sharded",
      "offset"
    ]
  },
  "PunicaWrapperXPU": {
    "__init__": [
      "self",
      "max_num_batched_tokens",
      "max_batches",
      "device"
    ],
    "update_metadata": [
      "self",
      "mapping",
      "lora_index_to_id",
      "max_loras",
      "vocab_size"
    ],
    "_get_token_lora_indices": [
      "self",
      "x"
    ],
    "_apply_shrink": [
      "self",
      "y",
      "x",
      "w_t_all",
      "scale"
    ],
    "_apply_expand": [
      "self",
      "y",
      "x",
      "w_t_all",
      "y_offset",
      "y_slice_size",
      "add_inputs"
    ],
    "add_shrink": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "scale"
    ],
    "add_expand": [
      "self",
      "y",
      "x",
      "lora_b_stacked",
      "output_slices",
      "offset_start",
      "add_inputs"
    ],
    "add_lora_embedding": [
      "self",
      "y",
      "x",
      "lora_b_stacked",
      "add_inputs"
    ],
    "add_lora_linear": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "lora_b_stacked",
      "scale",
      "output_slices"
    ],
    "sampler_indices_padded": [
      "self"
    ],
    "add_lora_logits": [
      "self",
      "y",
      "x",
      "lora_a_stacked",
      "lora_b_stacked",
      "scale"
    ]
  },
  "BaseLinearLayerWithLoRA": {
    "__init__": [
      "self",
      "base_layer"
    ],
    "create_lora_weights": [
      "self",
      "max_loras",
      "lora_config",
      "model_config"
    ],
    "reset_lora": [
      "self",
      "index"
    ],
    "set_lora": [
      "self",
      "index",
      "lora_a",
      "lora_b"
    ],
    "apply": [
      "self",
      "x",
      "bias"
    ],
    "weight": [
      "self"
    ],
    "bias": [
      "self"
    ]
  },
  "BaseLayerWithLoRA": {
    "slice_lora_a": [
      "self",
      "lora_a"
    ],
    "slice_lora_b": [
      "self",
      "lora_b"
    ],
    "create_lora_weights": [
      "self",
      "max_loras",
      "lora_config",
      "model_config"
    ],
    "reset_lora": [
      "self",
      "index"
    ],
    "set_lora": [
      "self",
      "index",
      "lora_a",
      "lora_b"
    ],
    "set_mapping": [
      "self",
      "punica_wrapper"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "RowParallelLinearWithLoRA": {
    "__init__": [
      "self",
      "base_layer"
    ],
    "slice_lora_a": [
      "self",
      "lora_a"
    ],
    "slice_lora_b": [
      "self",
      "lora_b"
    ],
    "forward": [
      "self",
      "input_"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "RowParallelLinearWithShardedLoRA": {
    "slice_lora_b": [
      "self",
      "lora_b"
    ],
    "apply": [
      "self",
      "x",
      "bias"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "LoRAMappingType": {
    "LANGUAGE": [],
    "TOWER": [],
    "CONNECTOR": []
  },
  "LoRAMapping": {
    "__post_init__": [
      "self"
    ]
  },
  "_get_lora_device": [
    "base_layer"
  ],
  "_not_fully_sharded_can_replace": [
    "can_replace"
  ],
  "_fully_sharded_can_replace": [
    "can_replace"
  ],
  "try_get_optimal_moe_lora_config": [
    "op_type",
    "w1_shape",
    "w2_shape",
    "rank",
    "top_k",
    "dtype",
    "M",
    "block_shape"
  ],
  "VocabParallelEmbeddingWithLoRA": {
    "__init__": [
      "self",
      "base_layer"
    ],
    "create_lora_weights": [
      "self",
      "max_loras",
      "lora_config",
      "model_config"
    ],
    "reset_lora": [
      "self",
      "index"
    ],
    "set_lora": [
      "self",
      "index",
      "lora_a",
      "lora_b"
    ],
    "forward": [
      "self",
      "x"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ],
    "weight": [
      "self"
    ]
  },
  "ReplicatedLinearWithLoRA": {
    "__init__": [
      "self",
      "base_layer"
    ],
    "forward": [
      "self",
      "input_"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ],
    "slice_lora_a": [
      "self",
      "lora_a"
    ],
    "slice_lora_b": [
      "self",
      "lora_b"
    ]
  },
  "LogitsProcessorWithLoRA": {
    "__init__": [
      "self",
      "base_layer",
      "hidden_size",
      "dtype",
      "device",
      "sharded_to_full_mapping"
    ],
    "logits_as_input": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "scale": [
      "self"
    ],
    "soft_cap": [
      "self"
    ],
    "use_all_gather": [
      "self"
    ],
    "org_vocab_size": [
      "self"
    ],
    "include_gpu_probs_tensor": [
      "self"
    ],
    "should_modify_greedy_probs_inplace": [
      "self"
    ],
    "create_lora_weights": [
      "self",
      "max_loras",
      "lora_config",
      "model_config"
    ],
    "reset_lora": [
      "self",
      "index"
    ],
    "set_lora": [
      "self",
      "index",
      "lora_a",
      "lora_b"
    ],
    "_get_logits": [
      "self",
      "hidden_states",
      "lm_head",
      "embedding_bias"
    ],
    "forward": [
      "self"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "FusedMoEWithLoRA": {
    "__init__": [
      "self",
      "base_layer"
    ],
    "_normalize_keys": [
      "self",
      "config"
    ],
    "_get_lora_moe_configs": [
      "self",
      "op_prefix",
      "num_loras",
      "rank",
      "num_slices",
      "M",
      "layer",
      "top_k",
      "config_dtype"
    ],
    "_inject_lora_into_fused_moe": [
      "self"
    ],
    "_create_lora_a_weights": [
      "self",
      "max_loras",
      "lora_config"
    ],
    "_create_lora_b_weights": [
      "self",
      "max_loras",
      "lora_config"
    ],
    "create_lora_weights": [
      "self",
      "max_loras",
      "lora_config",
      "model_config"
    ],
    "_slice_w13_a": [
      "self",
      "w13_lora_a"
    ],
    "_slice_w13_b": [
      "self",
      "w13_lora_b"
    ],
    "_slice_w2_a": [
      "self",
      "w2_lora_a"
    ],
    "_slice_w2_b": [
      "self",
      "w2_lora_b"
    ],
    "reset_lora": [
      "self",
      "index"
    ],
    "set_lora": [
      "self",
      "index",
      "lora_a",
      "lora_b"
    ],
    "forward": [
      "self"
    ],
    "maybe_all_reduce_tensor_model_parallel": [
      "self"
    ],
    "_shared_experts": [
      "self"
    ],
    "quant_method": [
      "self"
    ],
    "is_internal_router": [
      "self"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "FusedMoE3DWithLoRA": {
    "__init__": [
      "self",
      "base_layer"
    ],
    "_create_lora_b_weights": [
      "self",
      "max_loras",
      "lora_config"
    ],
    "create_lora_weights": [
      "self",
      "max_loras",
      "lora_config",
      "model_config"
    ],
    "_slice_w13_b": [
      "self",
      "w13_lora_b"
    ],
    "set_lora": [
      "self",
      "index",
      "lora_a",
      "lora_b"
    ],
    "w13_input_size": [
      "self"
    ],
    "w13_output_size": [
      "self"
    ],
    "w2_input_size": [
      "self"
    ],
    "w2_output_size": [
      "self"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "_mcp_apply": [
    "x",
    "bias",
    "layer"
  ],
  "ColumnParallelLinearWithLoRA": {
    "__init__": [
      "self",
      "base_layer"
    ],
    "slice_lora_a": [
      "self",
      "lora_a"
    ],
    "slice_lora_b": [
      "self",
      "lora_b"
    ],
    "forward": [
      "self",
      "input_"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "MergedColumnParallelLinearWithLoRA": {
    "__init__": [
      "self",
      "base_layer"
    ],
    "create_lora_weights": [
      "self",
      "max_loras",
      "lora_config",
      "model_config"
    ],
    "slice_lora_a": [
      "self",
      "lora_a"
    ],
    "slice_lora_b": [
      "self",
      "lora_b"
    ],
    "set_lora": [
      "self",
      "index",
      "lora_a",
      "lora_b"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "QKVParallelLinearWithLoRA": {
    "__init__": [
      "self",
      "base_layer"
    ],
    "slice_lora_b": [
      "self",
      "lora_b"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "MergedQKVParallelLinearWithLoRA": {
    "__init__": [
      "self",
      "base_layer"
    ],
    "create_lora_weights": [
      "self",
      "max_loras",
      "lora_config",
      "model_config"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "ColumnParallelLinearWithShardedLoRA": {
    "slice_lora_a": [
      "self",
      "lora_a"
    ],
    "apply": [
      "self",
      "x",
      "bias"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "MergedColumnParallelLinearWithShardedLoRA": {
    "slice_lora_a": [
      "self",
      "lora_a"
    ],
    "apply": [
      "self",
      "x",
      "bias"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "QKVParallelLinearWithShardedLoRA": {
    "slice_lora_a": [
      "self",
      "lora_a"
    ],
    "apply": [
      "self",
      "x",
      "bias"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "MergedQKVParallelLinearWithShardedLoRA": {
    "slice_lora_a": [
      "self",
      "lora_a"
    ],
    "apply": [
      "self",
      "x",
      "bias"
    ],
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ]
  },
  "MergedColumnParallelLinearVariableSliceWithLoRA": {
    "can_replace_layer": [
      "cls",
      "source_layer",
      "lora_config",
      "packed_modules_list",
      "model_config"
    ],
    "set_lora": [
      "self",
      "index",
      "lora_a",
      "lora_b"
    ]
  },
  "BaseDummyOptions": {},
  "VideoDummyOptions": {},
  "ImageDummyOptions": {},
  "AudioDummyOptions": {},
  "MMEncoderTPMode": [],
  "MMCacheType": [],
  "MultiModalConfig": {
    "_validate_limit_per_prompt": [
      "cls",
      "value"
    ],
    "_validate_mm_encoder_attn_backend": [
      "cls",
      "value"
    ],
    "_validate_multimodal_config": [
      "self"
    ],
    "compute_hash": [
      "self"
    ],
    "get_limit_per_prompt": [
      "self",
      "modality"
    ],
    "get_dummy_options": [
      "self",
      "modality"
    ],
    "merge_mm_processor_kwargs": [
      "self",
      "inference_kwargs"
    ],
    "is_multimodal_pruning_enabled": [
      "self"
    ]
  },
  "StructuredOutputsBackend": [],
  "StructuredOutputsConfig": {
    "compute_hash": [
      "self"
    ],
    "_validate_structured_output_config": [
      "self"
    ]
  },
  "LoRADType": [],
  "MaxLoRARanks": [],
  "LoRAExtraVocabSize": [],
  "LoRAConfig": {
    "compute_hash": [
      "self"
    ],
    "_validate_lora_config": [
      "self"
    ],
    "verify_with_model_config": [
      "self",
      "model_config"
    ]
  },
  "DetailedTraceModules": [],
  "ObservabilityConfig": {
    "show_hidden_metrics": [
      "self"
    ],
    "collect_model_forward_time": [
      "self"
    ],
    "collect_model_execute_time": [
      "self"
    ],
    "compute_hash": [
      "self"
    ],
    "_validate_show_hidden_metrics_for_version": [
      "cls",
      "value"
    ],
    "_validate_otlp_traces_endpoint": [
      "cls",
      "value"
    ],
    "_validate_collect_detailed_traces": [
      "cls",
      "value"
    ],
    "_validate_tracing_config": [
      "self"
    ]
  },
  "BlockSize": [],
  "CacheDType": [],
  "MambaDType": [],
  "MambaCacheMode": [],
  "PrefixCachingHashAlgo": [],
  "KVOffloadingBackend": [],
  "CacheConfig": {
    "compute_hash": [
      "self"
    ],
    "metrics_info": [
      "self"
    ],
    "_validate_cache_dtype": [
      "cls",
      "cache_dtype"
    ],
    "verify_with_parallel_config": [
      "self",
      "parallel_config"
    ]
  },
  "Device": [],
  "DeviceConfig": {
    "compute_hash": [
      "self"
    ],
    "__post_init__": [
      "self"
    ]
  },
  "RunnerType": [],
  "SchedulerPolicy": [],
  "SchedulerConfig": {
    "default_factory": [],
    "get_scheduler_cls": [
      "self"
    ],
    "compute_hash": [
      "self"
    ],
    "_skip_none_validation": [
      "cls",
      "value",
      "handler"
    ],
    "__post_init__": [
      "self",
      "max_model_len",
      "is_encoder_decoder"
    ],
    "verify_max_model_len": [
      "self",
      "max_model_len"
    ]
  },
  "ConfigType": [],
  "ConfigT": [],
  "config": [
    "cls"
  ],
  "get_field": [
    "cls",
    "name"
  ],
  "getattr_iter": [
    "object",
    "names",
    "default",
    "default_factory",
    "warn"
  ],
  "contains_object_print": [
    "text"
  ],
  "assert_hashable": [
    "text"
  ],
  "get_attr_docs": [
    "cls"
  ],
  "is_init_field": [
    "cls",
    "name"
  ],
  "SupportsHash": {
    "compute_hash": [
      "self"
    ]
  },
  "SupportsMetricsInfo": {
    "metrics_info": [
      "self"
    ]
  },
  "update_config": [
    "config",
    "overrides"
  ],
  "normalize_value": [
    "x"
  ],
  "get_hash_factors": [
    "config",
    "ignored_factors"
  ],
  "hash_factors": [
    "items"
  ],
  "handle_deprecated": [
    "config",
    "old_name",
    "new_name_or_names",
    "removal_version"
  ],
  "Range": {
    "is_single_size": [
      "self"
    ],
    "__contains__": [
      "self",
      "size"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__hash__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "KVProducer": [],
  "KVConsumer": [],
  "KVRole": [],
  "KVTransferConfig": {
    "compute_hash": [
      "self"
    ],
    "__post_init__": [
      "self"
    ],
    "is_kv_transfer_instance": [
      "self"
    ],
    "is_kv_producer": [
      "self"
    ],
    "is_kv_consumer": [
      "self"
    ],
    "get_from_extra_config": [
      "self",
      "key",
      "default"
    ]
  },
  "LoadConfig": {
    "compute_hash": [
      "self"
    ],
    "_lowercase_load_format": [
      "cls",
      "load_format"
    ],
    "_validate_ignore_patterns": [
      "cls",
      "ignore_patterns"
    ]
  },
  "AttentionConfig": {
    "compute_hash": [
      "self"
    ],
    "validate_backend_before": [
      "cls",
      "value"
    ]
  },
  "SpeechToTextConfig": {
    "allow_audio_chunking": [
      "self"
    ]
  },
  "ModelArchitectureConfig": {},
  "RunnerOption": [],
  "ConvertType": [],
  "ConvertOption": [],
  "TokenizerMode": [],
  "ModelDType": [],
  "LogprobsMode": [],
  "HfOverrides": [],
  "ModelImpl": [],
  "LayerBlockType": [],
  "AttnTypeStr": [],
  "ModelConfig": {
    "compute_hash": [
      "self"
    ],
    "_update_nested": [
      "self",
      "target",
      "updates"
    ],
    "_apply_dict_overrides": [
      "self",
      "config",
      "overrides"
    ],
    "__post_init__": [
      "self",
      "limit_mm_per_prompt",
      "enable_mm_embeds",
      "media_io_kwargs",
      "mm_processor_kwargs",
      "mm_processor_cache_gb",
      "mm_processor_cache_type",
      "mm_shm_cache_max_object_size_mb",
      "mm_encoder_only",
      "mm_encoder_tp_mode",
      "mm_encoder_attn_backend",
      "interleave_mm_strings",
      "skip_mm_profiling",
      "video_pruning_rate"
    ],
    "get_model_arch_config": [
      "self"
    ],
    "_skip_none_validation": [
      "cls",
      "value",
      "handler"
    ],
    "_lowercase_tokenizer_mode": [
      "cls",
      "tokenizer_mode"
    ],
    "validate_quantization_before": [
      "cls",
      "value"
    ],
    "validate_model_config_after": [
      "self"
    ],
    "_get_transformers_backend_cls": [
      "self"
    ],
    "using_transformers_backend": [
      "self"
    ],
    "registry": [
      "self"
    ],
    "architectures": [
      "self"
    ],
    "architecture": [
      "self"
    ],
    "maybe_pull_model_tokenizer_for_runai": [
      "self",
      "model",
      "tokenizer"
    ],
    "_get_encoder_config": [
      "self"
    ],
    "_get_default_runner_type": [
      "self",
      "architectures"
    ],
    "_get_runner_type": [
      "self",
      "architectures",
      "runner"
    ],
    "_get_default_convert_type": [
      "self",
      "architectures",
      "runner_type"
    ],
    "_get_convert_type": [
      "self",
      "architectures",
      "runner_type",
      "convert"
    ],
    "_verify_quantization": [
      "self"
    ],
    "_verify_cuda_graph": [
      "self"
    ],
    "_verify_bnb_config": [
      "self"
    ],
    "_verify_with_expert_parallelism": [
      "self"
    ],
    "_try_verify_and_update_model_config": [
      "self"
    ],
    "verify_dual_chunk_attention_config": [
      "self",
      "load_config"
    ],
    "verify_with_parallel_config": [
      "self",
      "parallel_config"
    ],
    "get_sliding_window": [
      "self"
    ],
    "get_vocab_size": [
      "self"
    ],
    "get_hidden_size": [
      "self"
    ],
    "get_inputs_embeds_size": [
      "self"
    ],
    "is_deepseek_mla": [
      "self"
    ],
    "is_mm_prefix_lm": [
      "self"
    ],
    "get_head_size": [
      "self"
    ],
    "get_total_num_kv_heads": [
      "self"
    ],
    "get_num_kv_heads": [
      "self",
      "parallel_config"
    ],
    "get_num_attention_heads": [
      "self",
      "parallel_config"
    ],
    "get_num_experts": [
      "self"
    ],
    "get_total_num_hidden_layers": [
      "self"
    ],
    "get_layers_start_end_indices": [
      "self",
      "parallel_config"
    ],
    "get_num_layers": [
      "self",
      "parallel_config"
    ],
    "get_num_layers_by_block_type": [
      "self",
      "parallel_config",
      "block_type"
    ],
    "get_mamba_chunk_size": [
      "self"
    ],
    "get_multimodal_config": [
      "self"
    ],
    "try_get_generation_config": [
      "self"
    ],
    "get_diff_sampling_param": [
      "self"
    ],
    "is_encoder_decoder": [
      "self"
    ],
    "uses_alibi": [
      "self"
    ],
    "uses_mrope": [
      "self"
    ],
    "uses_xdrope_dim": [
      "self"
    ],
    "is_multimodal_model": [
      "self"
    ],
    "is_multimodal_raw_input_only_model": [
      "self"
    ],
    "requires_raw_input_tokens": [
      "self"
    ],
    "is_cross_encoder": [
      "self"
    ],
    "is_pp_supported": [
      "self"
    ],
    "is_attention_free": [
      "self"
    ],
    "is_hybrid": [
      "self"
    ],
    "has_noops": [
      "self"
    ],
    "has_inner_state": [
      "self"
    ],
    "supports_mamba_prefix_caching": [
      "self"
    ],
    "use_mla": [
      "self"
    ],
    "is_matryoshka": [
      "self"
    ],
    "matryoshka_dimensions": [
      "self"
    ],
    "use_sep_token": [
      "self"
    ],
    "head_dtype": [
      "self"
    ],
    "embedding_size": [
      "self"
    ],
    "get_and_verify_max_len": [
      "self",
      "max_model_len"
    ],
    "attn_type": [
      "self"
    ],
    "is_chunked_prefill_supported": [
      "self"
    ],
    "is_prefix_caching_supported": [
      "self"
    ],
    "is_moe": [
      "self"
    ],
    "is_quantized": [
      "self"
    ]
  },
  "get_served_model_name": [
    "model",
    "served_model_name"
  ],
  "iter_architecture_defaults": [],
  "try_match_architecture_defaults": [
    "architecture"
  ],
  "_STR_DTYPE_TO_TORCH_DTYPE": [],
  "str_dtype_to_torch_dtype": [
    "type"
  ],
  "_FLOAT16_NOT_SUPPORTED_MODELS": [],
  "_is_valid_dtype": [
    "model_type",
    "dtype"
  ],
  "_check_valid_dtype": [
    "model_type",
    "dtype"
  ],
  "_resolve_auto_dtype": [
    "model_type",
    "config_dtype"
  ],
  "_get_and_verify_dtype": [
    "model_id",
    "config",
    "dtype"
  ],
  "_get_head_dtype": [
    "config",
    "dtype",
    "runner_type"
  ],
  "_get_and_verify_max_len": [
    "hf_config",
    "model_arch_config",
    "tokenizer_config",
    "max_model_len",
    "disable_sliding_window",
    "sliding_window",
    "spec_target_max_model_len",
    "encoder_config"
  ],
  "ECProducer": [],
  "ECConsumer": [],
  "ECRole": [],
  "ECTransferConfig": {
    "compute_hash": [
      "self"
    ],
    "__post_init__": [
      "self"
    ],
    "is_ec_transfer_instance": [
      "self"
    ],
    "is_ec_producer": [
      "self"
    ],
    "is_ec_consumer": [
      "self"
    ],
    "get_from_extra_config": [
      "self",
      "key",
      "default"
    ]
  },
  "ExpertPlacementStrategy": [],
  "DistributedExecutorBackend": [],
  "DataParallelBackend": [],
  "EPLBPolicyOption": [],
  "All2AllBackend": [],
  "EPLBConfig": {
    "_validate_eplb_config": [
      "self"
    ]
  },
  "ParallelConfig": {
    "_skip_none_validation": [
      "cls",
      "value",
      "handler"
    ],
    "_validate_parallel_config": [
      "self"
    ],
    "world_size_across_dp": [
      "self"
    ],
    "use_ubatching": [
      "self"
    ],
    "num_ubatches": [
      "self"
    ],
    "local_engines_only": [
      "self"
    ],
    "get_next_dp_init_port": [
      "self"
    ],
    "stateless_init_dp_group": [
      "self"
    ],
    "use_sequence_parallel_moe": [
      "self"
    ],
    "node_rank_within_dp": [
      "self"
    ],
    "nnodes_within_dp": [
      "self"
    ],
    "local_world_size": [
      "self"
    ],
    "has_unfinished_dp": [
      "dp_group",
      "has_unfinished"
    ],
    "sync_kv_cache_memory_size": [
      "dp_group",
      "kv_cache_memory"
    ],
    "compute_hash": [
      "self"
    ],
    "__post_init__": [
      "self"
    ],
    "use_ray": [
      "self"
    ],
    "_verify_args": [
      "self"
    ],
    "replace": [
      "self"
    ]
  },
  "KVEventsConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "MTPModelTypes": [],
  "EagleModelTypes": [],
  "SpeculativeMethod": [],
  "SpeculativeConfig": {
    "compute_hash": [
      "self"
    ],
    "hf_config_override": [
      "hf_config"
    ],
    "__post_init__": [
      "self"
    ],
    "_validate_suffix_decoding": [
      "self"
    ],
    "_maybe_override_draft_max_model_len": [
      "speculative_max_model_len",
      "draft_max_model_len",
      "target_max_model_len"
    ],
    "_verify_and_get_draft_tp": [
      "target_parallel_config",
      "speculative_draft_tensor_parallel_size",
      "draft_hf_config"
    ],
    "create_draft_parallel_config": [
      "target_parallel_config",
      "speculative_draft_tensor_parallel_size"
    ],
    "_verify_args": [
      "self"
    ],
    "verify_equal_vocab_size_if_draft_model": [
      "self"
    ],
    "use_eagle": [
      "self"
    ],
    "uses_draft_model": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "OptimizationLevel": {
    "O0": [],
    "O1": [],
    "O2": [],
    "O3": []
  },
  "IS_QUANTIZED": [],
  "IS_DENSE": [],
  "enable_norm_fusion": [
    "cfg"
  ],
  "enable_act_fusion": [
    "cfg"
  ],
  "OPTIMIZATION_LEVEL_00": [],
  "OPTIMIZATION_LEVEL_01": [],
  "OPTIMIZATION_LEVEL_02": [],
  "OPTIMIZATION_LEVEL_03": [],
  "OPTIMIZATION_LEVEL_TO_CONFIG": [],
  "VllmConfig": {
    "compute_hash": [
      "self"
    ],
    "pad_for_cudagraph": [
      "self",
      "batch_size"
    ],
    "needs_dp_coordinator": [
      "self"
    ],
    "enable_trace_function_call_for_thread": [
      "self"
    ],
    "_get_quantization_config": [
      "model_config",
      "load_config"
    ],
    "get_quantization_config": [
      "model_config",
      "load_config"
    ],
    "with_hf_config": [
      "self",
      "hf_config",
      "architectures"
    ],
    "_set_config_default": [
      "self",
      "config_obj",
      "key",
      "value"
    ],
    "_apply_optimization_level_defaults": [
      "self",
      "defaults"
    ],
    "_post_init_kv_transfer_config": [
      "self"
    ],
    "__post_init__": [
      "self"
    ],
    "update_sizes_for_sequence_parallelism": [
      "self",
      "possible_sizes"
    ],
    "_set_cudagraph_sizes": [
      "self"
    ],
    "_set_compile_ranges": [
      "self"
    ],
    "try_verify_and_update_config": [
      "self"
    ],
    "compile_debug_dump_path": [
      "self"
    ],
    "replace": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "validate_mamba_block_size": [
      "self"
    ]
  },
  "set_current_vllm_config": [
    "vllm_config",
    "check_compile",
    "prefix"
  ],
  "get_cached_compilation_config": [],
  "get_current_vllm_config": [],
  "get_current_vllm_config_or_none": [],
  "get_layers_from_vllm_config": [
    "vllm_config",
    "layer_type",
    "layer_names"
  ],
  "SequencePoolingType": [],
  "TokenPoolingType": [],
  "PoolerConfig": {
    "__post_init__": [
      "self"
    ],
    "get_seq_pooling_type": [
      "self"
    ],
    "get_tok_pooling_type": [
      "self"
    ],
    "compute_hash": [
      "self"
    ]
  },
  "get_use_activation": [
    "o"
  ],
  "ProfilerKind": [],
  "_is_uri_path": [
    "path"
  ],
  "ProfilerConfig": {
    "compute_hash": [
      "self"
    ],
    "_get_from_env_if_set": [
      "self",
      "field_name",
      "env_var_name"
    ],
    "_set_from_env_if_set": [
      "self",
      "field_name",
      "env_var_name",
      "to_bool",
      "to_int"
    ],
    "_validate_profiler_config": [
      "self"
    ]
  },
  "CompilationMode": {
    "NONE": [],
    "STOCK_TORCH_COMPILE": [],
    "DYNAMO_TRACE_ONCE": [],
    "VLLM_COMPILE": []
  },
  "CUDAGraphMode": {
    "NONE": [],
    "PIECEWISE": [],
    "FULL": [],
    "FULL_DECODE_ONLY": [],
    "FULL_AND_PIECEWISE": [],
    "decode_mode": [
      "self"
    ],
    "mixed_mode": [
      "self"
    ],
    "has_mode": [
      "self",
      "mode"
    ],
    "requires_piecewise_compilation": [
      "self"
    ],
    "max_cudagraph_mode": [
      "self"
    ],
    "has_full_cudagraphs": [
      "self"
    ],
    "has_piecewise_cudagraphs": [
      "self"
    ],
    "separate_routine": [
      "self"
    ],
    "valid_runtime_modes": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "PassConfig": {
    "flashinfer_max_size": [
      "self",
      "world_size"
    ],
    "default_fi_allreduce_fusion_max_size_mb": [],
    "compute_hash": [
      "self"
    ],
    "_skip_none_validation": [
      "cls",
      "value",
      "handler"
    ],
    "__post_init__": [
      "self"
    ]
  },
  "DynamicShapesType": {
    "BACKED": [],
    "UNBACKED": [],
    "BACKED_SIZE_OBLIVIOUS": []
  },
  "DynamicShapesConfig": {
    "compute_hash": [
      "self"
    ]
  },
  "CompilationConfig": {
    "fast_moe_cold_start": [],
    "compute_hash": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "__str__": [],
    "validate_mode_before": [
      "cls",
      "value"
    ],
    "validate_cudagraph_mode_before": [
      "cls",
      "value"
    ],
    "validate_pass_config_before": [
      "cls",
      "value"
    ],
    "validate_compile_cache_save_format": [
      "cls",
      "value"
    ],
    "_skip_none_validation": [
      "cls",
      "value",
      "handler"
    ],
    "__post_init__": [
      "self"
    ],
    "init_backend": [
      "self",
      "vllm_config"
    ],
    "post_init_cudagraph_sizes": [
      "self"
    ],
    "set_splitting_ops_for_v1": [
      "self",
      "all2all_backend",
      "data_parallel_size"
    ],
    "set_splitting_ops_for_attn_fusion": [
      "self"
    ],
    "splitting_ops_contain_attention": [
      "self"
    ],
    "is_attention_compiled_piecewise": [
      "self"
    ],
    "custom_op_log_check": [
      "self"
    ],
    "is_custom_op_enabled": [
      "self",
      "op"
    ],
    "adjust_cudagraph_sizes_for_spec_decode": [
      "self",
      "uniform_decode_query_len",
      "tensor_parallel_size"
    ],
    "get_compile_ranges": [
      "self"
    ]
  },
  "DeepSeekV3ReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "is_reasoning_end": [
      "self",
      "input_ids"
    ],
    "is_reasoning_end_streaming": [
      "self",
      "input_ids",
      "delta_ids"
    ],
    "extract_content_ids": [
      "self",
      "input_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ]
  },
  "Step3ReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ],
    "is_reasoning_end": [
      "self",
      "input_ids"
    ],
    "is_reasoning_end_streaming": [
      "self",
      "input_ids",
      "delta_ids"
    ],
    "extract_content_ids": [
      "self",
      "input_ids"
    ]
  },
  "no_func_reaonsing_tag": [],
  "from_builtin_tool_to_tag": [
    "tool"
  ],
  "tag_with_builtin_funcs": [
    "no_func_reaonsing_tag",
    "builtin_tool_list"
  ],
  "GptOssReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "is_reasoning_end": [
      "self",
      "input_ids"
    ],
    "extract_content_ids": [
      "self",
      "input_ids"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ],
    "prepare_structured_tag": [
      "self",
      "original_tag",
      "tool_server"
    ]
  },
  "DeepSeekR1ReasoningParser": {
    "start_token": [
      "self"
    ],
    "end_token": [
      "self"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ]
  },
  "Glm4MoeModelReasoningParser": {},
  "_REASONING_PARSERS_TO_REGISTER": [],
  "register_lazy_reasoning_parsers": [],
  "SeedOSSReasoningParser": {
    "start_token": [
      "self"
    ],
    "end_token": [
      "self"
    ]
  },
  "Qwen3ReasoningParser": {
    "start_token": [
      "self"
    ],
    "end_token": [
      "self"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ]
  },
  "MistralReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "start_token": [
      "self"
    ],
    "end_token": [
      "self"
    ],
    "is_reasoning_end": [
      "self",
      "input_ids"
    ],
    "extract_content_ids": [
      "self",
      "input_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ]
  },
  "MiniMaxM2ReasoningParser": {
    "start_token": [
      "self"
    ],
    "end_token": [
      "self"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ]
  },
  "MiniMaxM2AppendThinkReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "is_reasoning_end": [
      "self",
      "input_ids"
    ],
    "extract_content_ids": [
      "self",
      "input_ids"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ]
  },
  "Olmo3ReasoningState": {
    "REASONING": [],
    "CONTENT": []
  },
  "Indices": {
    "__len__": [
      "self"
    ]
  },
  "string_overlap": [
    "a",
    "b"
  ],
  "Olmo3ReasoningBuffer": {
    "process_buffer": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "add_text": [
      "self",
      "delta_text"
    ]
  },
  "Olmo3ReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "is_reasoning_end": [
      "self",
      "input_ids"
    ],
    "extract_content_ids": [
      "self",
      "input_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ]
  },
  "HunyuanA13BReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "is_reasoning_end": [
      "self",
      "input_ids"
    ],
    "extract_content_ids": [
      "self",
      "input_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ],
    "_is_strict_increasing_subsequence": [
      "self",
      "subsequence",
      "sequence"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ]
  },
  "Step3p5ReasoningParser": {
    "start_token": [
      "self"
    ],
    "end_token": [
      "self"
    ],
    "__init__": [
      "self",
      "tokenizer"
    ],
    "is_reasoning_end": [
      "self",
      "input_ids"
    ],
    "is_reasoning_end_streaming": [
      "self",
      "input_ids",
      "delta_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ]
  },
  "GraniteReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ],
    "_is_reasoning_start_substr": [
      "self",
      "text"
    ],
    "_is_response_start_substr": [
      "self",
      "text"
    ],
    "_get_delta_message_with_no_reasoning_bounds": [
      "self",
      "current_text",
      "delta_text"
    ],
    "_get_delta_message_with_no_response_bounds": [
      "self",
      "current_text",
      "reasoning",
      "delta_text"
    ],
    "_get_delta_message_with_both_bounds": [
      "self",
      "delta_text",
      "reasoning",
      "response_content",
      "current_text",
      "response_seq_len"
    ],
    "_get_content_sections": [
      "self",
      "current_text"
    ]
  },
  "ReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "vocab": [
      "self"
    ],
    "is_reasoning_end": [
      "self",
      "input_ids"
    ],
    "is_reasoning_end_streaming": [
      "self",
      "input_ids",
      "delta_ids"
    ],
    "extract_content_ids": [
      "self",
      "input_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ],
    "prepare_structured_tag": [
      "self",
      "original_tag",
      "tool_server"
    ]
  },
  "ReasoningParserManager": {
    "get_reasoning_parser": [
      "cls",
      "name"
    ],
    "list_registered": [
      "cls"
    ],
    "_load_lazy_parser": [
      "cls",
      "name"
    ],
    "_register_module": [
      "cls",
      "module",
      "module_name",
      "force"
    ],
    "register_lazy_module": [
      "cls",
      "name",
      "module_path",
      "class_name"
    ],
    "register_module": [
      "cls",
      "name",
      "force",
      "module"
    ],
    "import_reasoning_parser": [
      "cls",
      "plugin_path"
    ]
  },
  "Ernie45ReasoningParser": {
    "start_token": [
      "self"
    ],
    "end_token": [
      "self"
    ],
    "__init__": [
      "self",
      "tokenizer"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ]
  },
  "Holo2ReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "is_reasoning_end": [
      "self",
      "input_ids"
    ],
    "is_reasoning_end_streaming": [
      "self",
      "input_ids",
      "delta_ids"
    ],
    "extract_content_ids": [
      "self",
      "input_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ]
  },
  "IdentityReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "is_reasoning_end": [
      "self",
      "input_ids"
    ],
    "is_reasoning_end_streaming": [
      "self",
      "input_ids",
      "delta_ids"
    ],
    "extract_content_ids": [
      "self",
      "input_ids"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ]
  },
  "KimiK2ReasoningParser": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "is_reasoning_end": [
      "self",
      "input_ids"
    ],
    "is_reasoning_end_streaming": [
      "self",
      "input_ids",
      "delta_ids"
    ],
    "extract_content_ids": [
      "self",
      "input_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ]
  },
  "BaseThinkingReasoningParser": {
    "start_token": [
      "self"
    ],
    "end_token": [
      "self"
    ],
    "__init__": [
      "self",
      "tokenizer"
    ],
    "is_reasoning_end": [
      "self",
      "input_ids"
    ],
    "is_reasoning_end_streaming": [
      "self",
      "input_ids",
      "delta_ids"
    ],
    "extract_content_ids": [
      "self",
      "input_ids"
    ],
    "extract_reasoning_streaming": [
      "self",
      "previous_text",
      "current_text",
      "delta_text",
      "previous_token_ids",
      "current_token_ids",
      "delta_token_ids"
    ],
    "extract_reasoning": [
      "self",
      "model_output",
      "request"
    ]
  },
  "is_ray_initialized": [],
  "is_in_ray_actor": [],
  "CONFIG_HOME": [],
  "RAY_NON_CARRY_OVER_ENV_VARS_FILE": [],
  "get_env_vars_to_copy": [
    "exclude_vars",
    "additional_vars",
    "destination"
  ],
  "USE_SCHED_YIELD": [],
  "sched_yield": [],
  "ensure_divisibility": [
    "numerator",
    "denominator"
  ],
  "divide": [
    "numerator",
    "denominator"
  ],
  "split_tensor_along_last_dim": [
    "tensor",
    "num_partitions",
    "contiguous_split_chunks"
  ],
  "get_pp_indices": [
    "num_hidden_layers",
    "pp_rank",
    "pp_size"
  ],
  "StatelessProcessGroup": {
    "__post_init__": [
      "self"
    ],
    "send_obj": [
      "self",
      "obj",
      "dst"
    ],
    "expire_data": [
      "self"
    ],
    "recv_obj": [
      "self",
      "src"
    ],
    "broadcast_obj": [
      "self",
      "obj",
      "src"
    ],
    "all_gather_obj": [
      "self",
      "obj"
    ],
    "barrier": [
      "self",
      "timeout"
    ],
    "create": [
      "host",
      "port",
      "rank",
      "world_size",
      "data_expiration_seconds",
      "store_timeout"
    ]
  },
  "init_gloo_process_group": [
    "prefix_store",
    "group_rank",
    "group_size",
    "timeout"
  ],
  "stateless_init_torch_distributed_process_group": [
    "host",
    "port",
    "rank",
    "world_size",
    "backend"
  ],
  "stateless_destroy_torch_distributed_process_group": [
    "pg"
  ],
  "GraphCaptureContext": {},
  "TensorMetadata": [],
  "_split_tensor_dict": [
    "tensor_dict"
  ],
  "_get_unique_name": [
    "name"
  ],
  "_register_group": [
    "group"
  ],
  "all_reduce_fake": [
    "tensor",
    "group_name"
  ],
  "reduce_scatter": [
    "tensor",
    "dim",
    "world_size",
    "group_name"
  ],
  "reduce_scatter_fake": [
    "tensor",
    "dim",
    "world_size",
    "group_name"
  ],
  "all_gather": [
    "tensor",
    "dim",
    "world_size",
    "group_name"
  ],
  "all_gather_fake": [
    "tensor",
    "dim",
    "world_size",
    "group_name"
  ],
  "patched_fused_scaled_matmul_reduce_scatter_fake": [
    "A",
    "B",
    "A_scale",
    "B_scale",
    "reduce_op",
    "orig_scatter_dim",
    "scatter_dim_after_maybe_reshape",
    "group_name",
    "output_shape",
    "bias",
    "result_scale",
    "out_dtype",
    "use_fast_accum"
  ],
  "patched_fused_scaled_matmul_reduce_scatter": [
    "A",
    "B",
    "A_scale",
    "B_scale",
    "reduce_op",
    "orig_scatter_dim",
    "scatter_dim_after_maybe_reshape",
    "group_name",
    "output_shape",
    "bias",
    "result_scale",
    "out_dtype",
    "use_fast_accum"
  ],
  "GroupCoordinator": {
    "__init__": [
      "self",
      "group_ranks",
      "local_rank",
      "torch_distributed_backend",
      "use_device_communicator",
      "use_message_queue_broadcaster",
      "group_name"
    ],
    "create_mq_broadcaster": [
      "self",
      "writer_rank",
      "external_writer_handle",
      "blocking"
    ],
    "create_single_reader_mq_broadcasters": [
      "self",
      "reader_rank_in_group",
      "blocking"
    ],
    "first_rank": [
      "self"
    ],
    "last_rank": [
      "self"
    ],
    "is_first_rank": [
      "self"
    ],
    "is_last_rank": [
      "self"
    ],
    "next_rank": [
      "self"
    ],
    "prev_rank": [
      "self"
    ],
    "graph_capture": [
      "self",
      "graph_capture_context"
    ],
    "all_reduce": [
      "self",
      "input_"
    ],
    "_all_reduce_out_place": [
      "self",
      "input_"
    ],
    "all_gather": [
      "self",
      "input_",
      "dim"
    ],
    "_all_gather_out_place": [
      "self",
      "input_",
      "dim"
    ],
    "all_gatherv": [
      "self",
      "input_",
      "dim",
      "sizes"
    ],
    "reduce_scatter": [
      "self",
      "input_",
      "dim"
    ],
    "reduce_scatterv": [
      "self",
      "input_",
      "dim",
      "sizes"
    ],
    "_reduce_scatter_out_place": [
      "self",
      "input_",
      "dim"
    ],
    "gather": [
      "self",
      "input_",
      "dst",
      "dim"
    ],
    "broadcast": [
      "self",
      "input_",
      "src"
    ],
    "broadcast_object": [
      "self",
      "obj",
      "src"
    ],
    "broadcast_object_list": [
      "self",
      "obj_list",
      "src",
      "group"
    ],
    "send_object": [
      "self",
      "obj",
      "dst"
    ],
    "recv_object": [
      "self",
      "src"
    ],
    "broadcast_tensor_dict": [
      "self",
      "tensor_dict",
      "src",
      "group",
      "metadata_group"
    ],
    "send_tensor_dict": [
      "self",
      "tensor_dict",
      "dst",
      "all_gather_group",
      "all_gather_tensors"
    ],
    "recv_tensor_dict": [
      "self",
      "src",
      "all_gather_group",
      "all_gather_tensors"
    ],
    "barrier": [
      "self"
    ],
    "send": [
      "self",
      "tensor",
      "dst"
    ],
    "recv": [
      "self",
      "size",
      "dtype",
      "src"
    ],
    "destroy": [
      "self"
    ],
    "prepare_communication_buffer_for_model": [
      "self",
      "model"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "router_logits",
      "is_sequence_parallel",
      "extra_tensors"
    ],
    "combine": [
      "self",
      "hidden_states",
      "is_sequence_parallel"
    ]
  },
  "get_world_group": [],
  "get_inner_dp_world_group": [],
  "init_world_group": [
    "ranks",
    "local_rank",
    "backend"
  ],
  "init_model_parallel_group": [
    "group_ranks",
    "local_rank",
    "backend",
    "use_message_queue_broadcaster",
    "group_name",
    "use_device_communicator"
  ],
  "get_tp_group": [],
  "get_dcp_group": [],
  "get_context_model_parallel_group": [],
  "get_pp_group": [],
  "get_dp_group": [],
  "get_ep_group": [],
  "get_pcp_group": [],
  "graph_capture": [
    "device"
  ],
  "_ENABLE_CUSTOM_ALL_REDUCE": [],
  "set_custom_all_reduce": [
    "enable"
  ],
  "init_distributed_environment": [
    "world_size",
    "rank",
    "distributed_init_method",
    "local_rank",
    "backend",
    "timeout"
  ],
  "initialize_model_parallel": [
    "tensor_model_parallel_size",
    "pipeline_model_parallel_size",
    "prefill_context_model_parallel_size",
    "decode_context_model_parallel_size",
    "backend"
  ],
  "ensure_model_parallel_initialized": [
    "tensor_model_parallel_size",
    "pipeline_model_parallel_size",
    "prefill_context_model_parallel_size",
    "decode_context_model_parallel_size",
    "backend"
  ],
  "prepare_communication_buffer_for_model": [
    "model"
  ],
  "model_parallel_is_initialized": [],
  "_TP_STATE_PATCHED": [],
  "patch_tensor_parallel_group": [
    "tp_group"
  ],
  "get_tensor_model_parallel_world_size": [],
  "get_tensor_model_parallel_rank": [],
  "get_decode_context_model_parallel_world_size": [],
  "get_decode_context_model_parallel_rank": [],
  "get_node_count": [],
  "destroy_model_parallel": [],
  "destroy_distributed_environment": [],
  "cleanup_dist_env_and_memory": [
    "shutdown_ray"
  ],
  "in_the_same_node_as": [
    "pg",
    "source_rank"
  ],
  "is_global_first_rank": [],
  "is_local_first_rank": [],
  "_node_count": [
    "pg"
  ],
  "tensor_model_parallel_all_reduce": [
    "input_"
  ],
  "tensor_model_parallel_all_gather": [
    "input_",
    "dim"
  ],
  "tensor_model_parallel_reduce_scatter": [
    "input_",
    "dim"
  ],
  "tensor_model_parallel_gather": [
    "input_",
    "dst",
    "dim"
  ],
  "broadcast_tensor_dict": [
    "tensor_dict",
    "src"
  ],
  "EventBatch": {},
  "KVCacheEvent": {},
  "MEDIUM_GPU": [],
  "BlockStored": {
    "__hash__": [
      "self"
    ]
  },
  "BlockRemoved": {
    "__hash__": [
      "self"
    ]
  },
  "AllBlocksCleared": {},
  "KVEventBatch": {},
  "KVEventAggregator": {
    "__slots__": [],
    "__init__": [
      "self",
      "num_workers"
    ],
    "add_events": [
      "self",
      "events"
    ],
    "get_common_events": [
      "self"
    ],
    "get_all_events": [
      "self"
    ],
    "clear_events": [
      "self"
    ],
    "increment_workers": [
      "self",
      "count"
    ],
    "reset_workers": [
      "self"
    ],
    "get_number_of_workers": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "KVConnectorKVEvents": {
    "add_events": [
      "self",
      "events"
    ],
    "aggregate": [
      "self"
    ],
    "increment_workers": [
      "self",
      "count"
    ],
    "get_all_events": [
      "self"
    ],
    "get_number_of_workers": [
      "self"
    ],
    "clear_events": [
      "self"
    ]
  },
  "EventPublisher": {
    "__init__": [
      "self",
      "data_parallel_rank"
    ],
    "publish": [
      "self",
      "events"
    ],
    "shutdown": [
      "self"
    ]
  },
  "NullEventPublisher": {
    "publish": [
      "self",
      "events"
    ],
    "shutdown": [
      "self"
    ]
  },
  "ZmqEventPublisher": {
    "END_SEQ": [],
    "__init__": [
      "self",
      "data_parallel_rank",
      "endpoint",
      "replay_endpoint",
      "buffer_steps",
      "hwm",
      "max_queue_size",
      "topic"
    ],
    "publish": [
      "self",
      "events"
    ],
    "shutdown": [
      "self"
    ],
    "_socket_setup": [
      "self"
    ],
    "_publisher_thread": [
      "self"
    ],
    "_service_replay": [
      "self"
    ],
    "offset_endpoint_port": [
      "endpoint",
      "data_parallel_rank"
    ]
  },
  "EventPublisherFactory": {
    "register_publisher": [
      "cls",
      "name",
      "ctor"
    ],
    "create": [
      "cls",
      "config",
      "data_parallel_rank"
    ]
  },
  "_NCCL_SYMM_OPS_REGISTERED": [],
  "register_nccl_symmetric_ops": [
    "pynccl_comm"
  ],
  "PyNcclCommunicator": {
    "__init__": [
      "self",
      "group",
      "device",
      "library_path"
    ],
    "all_reduce": [
      "self",
      "in_tensor",
      "out_tensor",
      "op",
      "stream"
    ],
    "all_gather": [
      "self",
      "output_tensor",
      "input_tensor",
      "stream"
    ],
    "all_gatherv": [
      "self",
      "output_tensor",
      "input_tensor",
      "sizes",
      "stream"
    ],
    "reduce_scatter": [
      "self",
      "output_tensor",
      "input_tensor",
      "op",
      "stream"
    ],
    "reduce_scatterv": [
      "self",
      "output_tensor",
      "input_tensor",
      "sizes",
      "op",
      "stream"
    ],
    "send": [
      "self",
      "tensor",
      "dst",
      "stream"
    ],
    "recv": [
      "self",
      "tensor",
      "src",
      "stream"
    ],
    "broadcast": [
      "self",
      "tensor",
      "src",
      "stream"
    ],
    "group_start": [
      "self"
    ],
    "group_end": [
      "self"
    ],
    "register_comm_window": [
      "self",
      "tensor"
    ],
    "register_comm_window_raw": [
      "self",
      "ptr",
      "size"
    ],
    "deregister_comm_window": [
      "self",
      "window"
    ]
  },
  "ncclResult_t": [],
  "ncclComm_t": [],
  "ncclWindow_t": [],
  "ncclUniqueId": {
    "_fields_": []
  },
  "cudaStream_t": [],
  "buffer_type": [],
  "ncclDataType_t": [],
  "ncclDataTypeEnum": {
    "ncclInt8": [],
    "ncclChar": [],
    "ncclUint8": [],
    "ncclInt32": [],
    "ncclInt": [],
    "ncclUint32": [],
    "ncclInt64": [],
    "ncclUint64": [],
    "ncclFloat16": [],
    "ncclHalf": [],
    "ncclFloat32": [],
    "ncclFloat": [],
    "ncclFloat64": [],
    "ncclDouble": [],
    "ncclBfloat16": [],
    "ncclFloat8e4m3": [],
    "ncclNumTypes": [],
    "from_torch": [
      "cls",
      "dtype"
    ]
  },
  "ncclRedOp_t": [],
  "ncclRedOpTypeEnum": {
    "ncclSum": [],
    "ncclProd": [],
    "ncclMax": [],
    "ncclMin": [],
    "ncclAvg": [],
    "ncclNumOps": [],
    "from_torch": [
      "cls",
      "op"
    ]
  },
  "Function": {},
  "NCCLLibrary": {
    "exported_functions": [],
    "__init__": [
      "self",
      "so_file"
    ],
    "ncclGetErrorString": [
      "self",
      "result"
    ],
    "NCCL_CHECK": [
      "self",
      "result"
    ],
    "ncclGetRawVersion": [
      "self"
    ],
    "ncclGetVersion": [
      "self"
    ],
    "ncclGetUniqueId": [
      "self"
    ],
    "unique_id_from_bytes": [
      "self",
      "data"
    ],
    "ncclCommInitRank": [
      "self",
      "world_size",
      "unique_id",
      "rank"
    ],
    "ncclAllReduce": [
      "self",
      "sendbuff",
      "recvbuff",
      "count",
      "datatype",
      "op",
      "comm",
      "stream"
    ],
    "ncclReduce": [
      "self",
      "sendbuff",
      "recvbuff",
      "count",
      "datatype",
      "op",
      "root",
      "comm",
      "stream"
    ],
    "ncclReduceScatter": [
      "self",
      "sendbuff",
      "recvbuff",
      "count",
      "datatype",
      "op",
      "comm",
      "stream"
    ],
    "ncclAllGather": [
      "self",
      "sendbuff",
      "recvbuff",
      "count",
      "datatype",
      "comm",
      "stream"
    ],
    "ncclSend": [
      "self",
      "sendbuff",
      "count",
      "datatype",
      "dest",
      "comm",
      "stream"
    ],
    "ncclRecv": [
      "self",
      "recvbuff",
      "count",
      "datatype",
      "src",
      "comm",
      "stream"
    ],
    "ncclBroadcast": [
      "self",
      "sendbuff",
      "recvbuff",
      "count",
      "datatype",
      "root",
      "comm",
      "stream"
    ],
    "ncclCommDestroy": [
      "self",
      "comm"
    ],
    "ncclGroupStart": [
      "self"
    ],
    "ncclGroupEnd": [
      "self"
    ],
    "ncclCommWindowRegister": [
      "self",
      "comm",
      "buff",
      "size",
      "win_flags"
    ],
    "ncclCommWindowDeregister": [
      "self",
      "comm",
      "window"
    ]
  },
  "nccl_allocator_source": [],
  "_allocator": [],
  "_allocator_wrapper": [],
  "_mem_pool": [],
  "_registered_base_addrs": [],
  "_graph_pool_id": [],
  "_nccl_allocator_failed_to_compile": [],
  "_cached_pool_snapshot": [],
  "is_symmetric_memory_enabled": [],
  "is_symmetric_memory_tensor": [
    "tensor"
  ],
  "set_graph_pool_id": [
    "graph_pool_id"
  ],
  "compile_nccl_allocator": [],
  "get_nccl_mem_pool": [],
  "_cleanup_nccl_mem_pool": [],
  "_cleanup_nccl_allocator_wrapper": [],
  "nccl_symm_mem_context": {
    "__init__": [
      "self",
      "pynccl_comm",
      "disabled"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "XpuCommunicator": {
    "__init__": [
      "self",
      "cpu_group",
      "device",
      "device_group",
      "unique_name"
    ],
    "all_reduce": [
      "self",
      "input_"
    ],
    "reduce_scatter": [
      "self",
      "input_",
      "dim"
    ],
    "reduce_scatterv": [
      "self",
      "input_",
      "dim",
      "sizes"
    ],
    "all_gatherv": [
      "self",
      "input_",
      "dim",
      "sizes"
    ],
    "gather": [
      "self",
      "input_",
      "dst",
      "dim"
    ],
    "broadcast": [
      "self",
      "input_",
      "src"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "router_logits",
      "is_sequence_parallel",
      "extra_tensors"
    ],
    "combine": [
      "self",
      "hidden_states",
      "is_sequence_parallel"
    ]
  },
  "MiB": [],
  "CUSTOM_ALL_REDUCE_MAX_SIZES": [],
  "SYMM_MEM_ALL_REDUCE_MAX_SIZES": [],
  "should_nccl_symm_mem_allreduce": [
    "world_size",
    "input_tensor"
  ],
  "producer": [
    "batch_src",
    "producer_queue",
    "consumer_queue",
    "result_queue",
    "cuda_visible_devices"
  ],
  "consumer": [
    "batch_tgt",
    "producer_queue",
    "consumer_queue",
    "result_queue",
    "cuda_visible_devices"
  ],
  "can_actually_p2p": [
    "batch_src",
    "batch_tgt"
  ],
  "gpu_p2p_access_check": [
    "src",
    "tgt"
  ],
  "_can_p2p": [
    "rank",
    "world_size"
  ],
  "CustomAllreduce": {
    "_SUPPORTED_WORLD_SIZES": [],
    "__init__": [
      "self",
      "group",
      "device",
      "max_size",
      "symm_mem_enabled"
    ],
    "capture": [
      "self"
    ],
    "register_graph_buffers": [
      "self"
    ],
    "should_custom_ar": [
      "self",
      "inp"
    ],
    "all_reduce": [
      "self",
      "inp"
    ],
    "custom_all_reduce": [
      "self",
      "input"
    ],
    "close": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "create_shared_buffer": [
      "size_in_bytes",
      "group",
      "uncached"
    ],
    "free_shared_buffer": [
      "pointers",
      "group",
      "rank"
    ]
  },
  "CudaCommunicator": {
    "__init__": [
      "self",
      "cpu_group",
      "device",
      "device_group",
      "unique_name"
    ],
    "all_reduce": [
      "self",
      "input_"
    ],
    "reduce_scatter": [
      "self",
      "input_",
      "dim"
    ],
    "reduce_scatterv": [
      "self",
      "input_",
      "dim",
      "sizes"
    ],
    "send": [
      "self",
      "tensor",
      "dst"
    ],
    "recv": [
      "self",
      "size",
      "dtype",
      "src"
    ],
    "destroy": [
      "self"
    ],
    "all_gatherv": [
      "self",
      "input_",
      "dim",
      "sizes"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "router_logits",
      "is_sequence_parallel",
      "extra_tensors"
    ],
    "combine": [
      "self",
      "hidden_states",
      "is_sequence_parallel"
    ]
  },
  "QuickReduceRegime": {
    "FP": [],
    "INT8": [],
    "INT6": [],
    "INT4": [],
    "NONE": []
  },
  "MB": [],
  "QuickAllReduce": {
    "_SUPPORTED_WORLD_SIZES": [],
    "_SUPPORTED_DTYPES": [],
    "_QR_MIN_SIZE": [],
    "__init__": [
      "self",
      "group",
      "device"
    ],
    "init_quick_all_reduce": [
      "self"
    ],
    "_rocm_arch_available": [
      "self"
    ],
    "create_shared_buffer": [
      "self"
    ],
    "should_quick_allreduce": [
      "self",
      "inp"
    ],
    "quick_all_reduce": [
      "self",
      "inp"
    ],
    "close": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "SymmMemCommunicator": {
    "_WORLD_SIZES_MULTIMEM": [],
    "__init__": [
      "self",
      "group",
      "device",
      "force_multimem",
      "max_size_override"
    ],
    "should_use_symm_mem": [
      "self",
      "inp"
    ],
    "all_reduce": [
      "self",
      "inp"
    ]
  },
  "cudaError_t": [],
  "cudaMemcpyKind": [],
  "cudaIpcMemHandle_t": {
    "_fields_": []
  },
  "CudaRTLibrary": {
    "exported_functions": [],
    "cuda_to_hip_mapping": [],
    "__init__": [
      "self",
      "so_file"
    ],
    "CUDART_CHECK": [
      "self",
      "result"
    ],
    "cudaGetErrorString": [
      "self",
      "error"
    ],
    "cudaSetDevice": [
      "self",
      "device"
    ],
    "cudaDeviceSynchronize": [
      "self"
    ],
    "cudaDeviceReset": [
      "self"
    ],
    "cudaMalloc": [
      "self",
      "size"
    ],
    "cudaFree": [
      "self",
      "devPtr"
    ],
    "cudaMemset": [
      "self",
      "devPtr",
      "value",
      "count"
    ],
    "cudaMemcpy": [
      "self",
      "dst",
      "src",
      "count"
    ],
    "cudaIpcGetMemHandle": [
      "self",
      "devPtr"
    ],
    "cudaIpcOpenMemHandle": [
      "self",
      "handle"
    ]
  },
  "Cache": {
    "__init__": [
      "self"
    ],
    "get_or_create": [
      "self",
      "kwargs",
      "func"
    ]
  },
  "All2AllManagerBase": {
    "__init__": [
      "self",
      "cpu_group"
    ],
    "get_handle": [
      "self",
      "kwargs"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "router_logits",
      "is_sequence_parallel",
      "extra_tensors"
    ],
    "set_num_sms": [
      "self",
      "num_sms"
    ],
    "max_sms_used": [
      "self"
    ],
    "combine": [
      "self",
      "hidden_states",
      "is_sequence_parallel"
    ],
    "destroy": [
      "self"
    ]
  },
  "DeviceCommunicatorBase": {
    "__init__": [
      "self",
      "cpu_group",
      "device",
      "device_group",
      "unique_name"
    ],
    "all_reduce": [
      "self",
      "input_"
    ],
    "all_gather": [
      "self",
      "input_",
      "dim"
    ],
    "all_gatherv": [
      "self",
      "input_",
      "dim",
      "sizes"
    ],
    "reduce_scatter": [
      "self",
      "input_",
      "dim"
    ],
    "reduce_scatterv": [
      "self",
      "input_",
      "dim",
      "sizes"
    ],
    "gather": [
      "self",
      "input_",
      "dst",
      "dim"
    ],
    "send": [
      "self",
      "tensor",
      "dst"
    ],
    "recv": [
      "self",
      "size",
      "dtype",
      "src"
    ],
    "destroy": [
      "self"
    ],
    "prepare_communication_buffer_for_model": [
      "self",
      "model"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "router_logits",
      "is_sequence_parallel",
      "extra_tensors"
    ],
    "combine": [
      "self",
      "hidden_states",
      "is_sequence_parallel"
    ]
  },
  "NaiveAll2AllManager": {
    "__init__": [
      "self",
      "cpu_group"
    ],
    "naive_multicast": [
      "self",
      "x",
      "cu_tokens_across_sp_cpu",
      "is_sequence_parallel"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "router_logits",
      "is_sequence_parallel",
      "extra_tensors"
    ],
    "combine": [
      "self",
      "hidden_states",
      "is_sequence_parallel"
    ],
    "destroy": [
      "self"
    ]
  },
  "AgRsAll2AllManager": {
    "__init__": [
      "self",
      "cpu_group"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "router_logits",
      "is_sequence_parallel",
      "extra_tensors"
    ],
    "combine": [
      "self",
      "hidden_states",
      "is_sequence_parallel"
    ],
    "destroy": [
      "self"
    ]
  },
  "PPLXAll2AllManager": {
    "__init__": [
      "self",
      "cpu_group"
    ],
    "get_handle": [
      "self",
      "kwargs"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "router_logits",
      "is_sequence_parallel",
      "extra_tensors"
    ],
    "combine": [
      "self",
      "hidden_states",
      "is_sequence_parallel"
    ],
    "destroy": [
      "self"
    ]
  },
  "DeepEPAll2AllManagerBase": {
    "__init__": [
      "self",
      "cpu_group"
    ],
    "get_handle": [
      "self",
      "kwargs"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "router_logits",
      "is_sequence_parallel",
      "extra_tensors"
    ],
    "combine": [
      "self",
      "hidden_states",
      "is_sequence_parallel"
    ],
    "destroy": [
      "self"
    ]
  },
  "DeepEPHTAll2AllManager": {
    "__init__": [
      "self",
      "cpu_group"
    ],
    "_make_all2all_kwargs": [
      "self"
    ],
    "get_handle": [
      "self",
      "kwargs"
    ],
    "set_num_sms": [
      "self",
      "num_sms"
    ]
  },
  "DeepEPLLAll2AllManager": {
    "__init__": [
      "self",
      "cpu_group"
    ],
    "_make_all2all_kwargs": [
      "self",
      "max_num_tokens_per_dp_rank",
      "token_hidden_size",
      "num_ep_ranks",
      "num_global_experts",
      "num_local_experts"
    ],
    "get_handle": [
      "self",
      "kwargs"
    ],
    "max_sms_used": [
      "self"
    ]
  },
  "FlashInferAllToAllManager": {
    "__init__": [
      "self",
      "cpu_group"
    ],
    "initialize": [
      "self",
      "world_size",
      "rank",
      "gpus_per_node"
    ],
    "ensure_alltoall_workspace_initialized": [
      "self"
    ],
    "get_handle": [
      "self",
      "kwargs"
    ],
    "cleanup": [
      "self"
    ]
  },
  "MoriAll2AllManager": {
    "__init__": [
      "self",
      "cpu_group"
    ],
    "_make_all2all_kwargs": [
      "self",
      "rank",
      "num_ep_ranks",
      "input_dtype",
      "quant_dtype",
      "token_hidden_size",
      "scale_dim",
      "scale_type_size",
      "max_num_tokens_per_dp_rank",
      "num_local_experts",
      "num_experts_per_token"
    ],
    "_make_handle": [
      "self"
    ],
    "get_handle": [
      "self",
      "kwargs"
    ]
  },
  "SingleWriterShmRingBuffer": {
    "__init__": [
      "self",
      "data_buffer_size",
      "name",
      "create"
    ],
    "handle": [
      "self"
    ],
    "clear": [
      "self"
    ],
    "close": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "int2byte": [
      "self",
      "integer"
    ],
    "byte2int": [
      "self",
      "byte_data"
    ],
    "allocate_buf": [
      "self",
      "size"
    ],
    "access_buf": [
      "self",
      "address"
    ],
    "free_buf": [
      "self",
      "is_free_fn",
      "nbytes"
    ]
  },
  "ObjectSerde": {
    "serialize": [
      "self",
      "value"
    ],
    "deserialize": [
      "self",
      "data"
    ]
  },
  "MsgpackSerde": {
    "__init__": [
      "self"
    ],
    "serialize": [
      "self",
      "value"
    ],
    "deserialize": [
      "self",
      "data_view"
    ]
  },
  "ShmObjectStorageHandle": {},
  "SingleWriterShmObjectStorage": {
    "__init__": [
      "self",
      "max_object_size",
      "n_readers",
      "ring_buffer",
      "serde_class",
      "reader_lock"
    ],
    "clear": [
      "self"
    ],
    "copy_to_buffer": [
      "self",
      "data",
      "data_bytes",
      "metadata",
      "md_bytes",
      "data_view"
    ],
    "increment_writer_flag": [
      "self",
      "id"
    ],
    "increment_reader_flag": [
      "self",
      "data_view"
    ],
    "free_unused": [
      "self"
    ],
    "is_cached": [
      "self",
      "key"
    ],
    "get_cached": [
      "self",
      "key"
    ],
    "put": [
      "self",
      "key",
      "value"
    ],
    "get": [
      "self",
      "address",
      "monotonic_id"
    ],
    "touch": [
      "self",
      "key",
      "address",
      "monotonic_id"
    ],
    "close": [
      "self"
    ],
    "handle": [
      "self"
    ],
    "create_from_handle": [
      "handle"
    ],
    "default_is_free_check": [
      "self",
      "id",
      "buf"
    ]
  },
  "RayPPCommunicator": {
    "__init__": [
      "self",
      "world_size",
      "comm_id",
      "rank",
      "actor_handles",
      "cuda_stream",
      "use_communication_streams"
    ],
    "_build_actor_rank_mapping": [
      "self"
    ],
    "initialize": [
      "self",
      "rank"
    ],
    "get_actor_handles": [
      "self"
    ],
    "get_rank": [
      "self",
      "actor"
    ],
    "get_self_rank": [
      "self"
    ],
    "get_world_size": [
      "self"
    ],
    "send": [
      "self",
      "buf",
      "peer_rank"
    ],
    "recv": [
      "self",
      "shape",
      "dtype",
      "peer_rank",
      "allocator"
    ],
    "allgather": [
      "self",
      "send_buf",
      "recv_buf"
    ],
    "allreduce": [
      "self",
      "send_buf",
      "recv_buf",
      "op"
    ],
    "reducescatter": [
      "self",
      "send_buf",
      "recv_buf",
      "op"
    ],
    "recv_stream": [
      "self"
    ],
    "send_stream": [
      "self"
    ],
    "destroy": [
      "self"
    ],
    "get_transport_name": [
      "self"
    ],
    "generate_communicator_id": [
      "cls"
    ]
  },
  "CpuCommunicator": {
    "__init__": [
      "self",
      "cpu_group",
      "device",
      "device_group",
      "unique_name"
    ],
    "all_reduce": [
      "self",
      "input_"
    ],
    "gather": [
      "self",
      "input_",
      "dst",
      "dim"
    ],
    "all_gather": [
      "self",
      "input_",
      "dim"
    ],
    "send_tensor_dict": [
      "self",
      "tensor_dict",
      "dst"
    ],
    "recv_tensor_dict": [
      "self",
      "src"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "router_logits",
      "is_sequence_parallel",
      "extra_tensors"
    ],
    "combine": [
      "self",
      "hidden_states",
      "is_sequence_parallel"
    ]
  },
  "_CPUSHMDistributed": {
    "__init__": [
      "self",
      "communicator"
    ],
    "_init_cpu_shm": [
      "self"
    ],
    "all_reduce": [
      "self",
      "input",
      "group"
    ],
    "gather": [
      "self",
      "input",
      "gather_list",
      "dst",
      "group"
    ],
    "all_gather_into_tensor": [
      "self",
      "output",
      "input",
      "group"
    ],
    "send_tensor_dict": [
      "self",
      "tensor_dict",
      "dst"
    ],
    "recv_tensor_dict": [
      "self",
      "src"
    ]
  },
  "CustomCommunicator": {
    "__init__": [
      "self",
      "group"
    ],
    "Get_rank": [
      "self"
    ],
    "Get_size": [
      "self"
    ],
    "allgather": [
      "self",
      "data"
    ],
    "Split": [
      "self",
      "color",
      "key"
    ]
  },
  "VLLM_RINGBUFFER_WARNING_INTERVAL": [],
  "from_bytes_big": [],
  "_memory_fence_lock": [],
  "memory_fence": [],
  "to_bytes_big": [
    "value",
    "size"
  ],
  "long_wait_time_msg": [
    "threshold"
  ],
  "SpinTimer": {
    "record_activity": [
      "self"
    ],
    "spin": [
      "self"
    ]
  },
  "SpinSleepTimer": {
    "__init__": [
      "self",
      "busy_loop_s",
      "wait_sleep_s"
    ],
    "record_activity": [
      "self"
    ],
    "spin": [
      "self"
    ]
  },
  "ShmRingBuffer": {
    "__init__": [
      "self",
      "n_reader",
      "max_chunk_bytes",
      "max_chunks",
      "name"
    ],
    "handle": [
      "self"
    ],
    "__reduce__": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "get_data": [
      "self",
      "current_idx"
    ],
    "get_metadata": [
      "self",
      "current_idx"
    ]
  },
  "Handle": {},
  "MessageQueue": {
    "__init__": [
      "self",
      "n_reader",
      "n_local_reader",
      "local_reader_ranks",
      "max_chunk_bytes",
      "max_chunks",
      "connect_ip"
    ],
    "export_handle": [
      "self"
    ],
    "create_from_handle": [
      "handle",
      "rank"
    ],
    "wait_until_ready": [
      "self"
    ],
    "acquire_write": [
      "self",
      "timeout"
    ],
    "acquire_read": [
      "self",
      "timeout",
      "cancel",
      "indefinite"
    ],
    "enqueue": [
      "self",
      "obj",
      "timeout"
    ],
    "dequeue": [
      "self",
      "timeout",
      "cancel",
      "indefinite"
    ],
    "recv": [
      "socket",
      "timeout"
    ],
    "broadcast_object": [
      "self",
      "obj"
    ],
    "create_from_process_group_single_reader": [
      "pg",
      "max_chunk_bytes",
      "max_chunks",
      "reader_rank",
      "blocking"
    ],
    "create_from_process_group": [
      "pg",
      "max_chunk_bytes",
      "max_chunks",
      "writer_rank",
      "external_writer_handle",
      "blocking"
    ]
  },
  "get_kv_transfer_group": [],
  "has_kv_transfer_group": [],
  "is_v1_kv_transfer_group": [
    "connector"
  ],
  "ensure_kv_transfer_initialized": [
    "vllm_config",
    "kv_cache_config"
  ],
  "ensure_kv_transfer_shutdown": [],
  "KVConnectorFactory": {
    "register_connector": [
      "cls",
      "name",
      "module_path",
      "class_name"
    ],
    "create_connector": [
      "cls",
      "config",
      "role",
      "kv_cache_config"
    ],
    "get_connector_class_by_name": [
      "cls",
      "connector_name"
    ],
    "_get_connector_class_with_compat": [
      "cls",
      "kv_transfer_config"
    ],
    "get_connector_class": [
      "cls",
      "kv_transfer_config"
    ]
  },
  "KVConnectorBase": [],
  "KVConnectorBaseType": [],
  "EngineId": [],
  "get_kv_connector_cache_layout": [],
  "KVOutputAggregator": {
    "__init__": [
      "self",
      "expected_finished_count"
    ],
    "from_connector": [
      "cls",
      "connector",
      "world_size"
    ],
    "aggregate": [
      "self",
      "outputs",
      "output_rank"
    ]
  },
  "_make_src_and_dst_indices": [
    "src_block_ids",
    "dst_block_ids",
    "src_device",
    "dst_device"
  ],
  "copy_kv_blocks": [
    "src_kv_caches",
    "dst_kv_caches",
    "src_block_ids",
    "dst_block_ids",
    "direction"
  ],
  "kv_postprocess_blksize_on_receive": [
    "cache",
    "indices",
    "block_size_ratio"
  ],
  "kv_postprocess_layout_on_receive": [
    "cache",
    "indices"
  ],
  "kv_postprocess_blksize_and_layout_on_receive": [
    "cache",
    "indices",
    "block_size_ratio"
  ],
  "yield_req_data": [
    "scheduler_output"
  ],
  "TpKVTopology": {
    "__post_init__": [
      "self"
    ],
    "is_kv_layout_blocks_first": [
      "self"
    ],
    "split_k_and_v": [
      "self"
    ],
    "tp_size": [
      "self"
    ],
    "block_size": [
      "self"
    ],
    "tp_ratio": [
      "self",
      "remote_tp_size"
    ],
    "block_size_ratio": [
      "self",
      "remote_block_size"
    ],
    "tp_ratio_from_engine_id": [
      "self",
      "remote_engine_id"
    ],
    "block_size_ratio_from_engine_id": [
      "self",
      "remote_engine_id"
    ],
    "is_kv_replicated": [
      "self",
      "engine_id"
    ],
    "replicates_kv_cache": [
      "self",
      "remote_engine_id"
    ],
    "get_target_remote_ranks": [
      "self",
      "remote_tp_size"
    ],
    "get_target_remote_ranks_from_engine_id": [
      "self",
      "remote_engine_id"
    ]
  },
  "get_current_attn_backend": [
    "vllm_config"
  ],
  "CopyBlocksOp": [],
  "SupportsHMA": {
    "request_finished_all_groups": [
      "self",
      "request",
      "block_ids"
    ]
  },
  "supports_hma": [
    "connector"
  ],
  "KVConnectorRole": {
    "SCHEDULER": [],
    "WORKER": []
  },
  "KVConnectorHandshakeMetadata": {},
  "KVConnectorMetadata": {},
  "KVConnectorBase_V1": {
    "prefer_cross_layer_blocks": [
      "self"
    ],
    "__init__": [
      "self",
      "vllm_config",
      "role",
      "kv_cache_config"
    ],
    "role": [
      "self"
    ],
    "bind_connector_metadata": [
      "self",
      "connector_metadata"
    ],
    "clear_connector_metadata": [
      "self"
    ],
    "_get_connector_metadata": [
      "self"
    ],
    "has_connector_metadata": [
      "self"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "register_cross_layers_kv_cache": [
      "self",
      "kv_cache",
      "attn_backend"
    ],
    "set_host_xfer_buffer_ops": [
      "self",
      "copy_operation"
    ],
    "handle_preemptions": [
      "self",
      "preempted_req_ids"
    ],
    "start_load_kv": [
      "self",
      "forward_context"
    ],
    "wait_for_layer_load": [
      "self",
      "layer_name"
    ],
    "save_kv_layer": [
      "self",
      "layer_name",
      "kv_layer",
      "attn_metadata"
    ],
    "wait_for_save": [
      "self"
    ],
    "get_finished": [
      "self",
      "finished_req_ids"
    ],
    "get_block_ids_with_load_errors": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "get_kv_connector_stats": [
      "self"
    ],
    "get_kv_connector_kv_cache_events": [
      "self"
    ],
    "get_handshake_metadata": [
      "self"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "update_connector_output": [
      "self",
      "connector_output"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ],
    "take_events": [
      "self"
    ],
    "get_required_kvcache_layout": [
      "cls",
      "vllm_config"
    ],
    "get_finished_count": [
      "self"
    ],
    "build_kv_connector_stats": [
      "cls",
      "data"
    ],
    "set_xfer_handshake_metadata": [
      "self",
      "metadata"
    ],
    "build_prom_metrics": [
      "cls",
      "vllm_config",
      "metric_types",
      "labelnames",
      "per_engine_labelvalues"
    ],
    "reset_cache": [
      "self"
    ]
  },
  "PromMetricT": [],
  "KVConnectorStats": {
    "reset": [
      "self"
    ],
    "aggregate": [
      "self",
      "other"
    ],
    "reduce": [
      "self"
    ],
    "is_empty": [
      "self"
    ]
  },
  "KVConnectorLogging": {
    "__init__": [
      "self",
      "kv_transfer_config"
    ],
    "reset": [
      "self"
    ],
    "observe": [
      "self",
      "transfer_stats_data"
    ],
    "log": [
      "self",
      "log_fn"
    ]
  },
  "KVConnectorPromMetrics": {
    "__init__": [
      "self",
      "vllm_config",
      "metric_types",
      "labelnames",
      "per_engine_labelvalues"
    ],
    "make_per_engine": [
      "self",
      "metric"
    ],
    "observe": [
      "self",
      "transfer_stats_data",
      "engine_idx"
    ]
  },
  "KVConnectorPrometheus": {
    "_gauge_cls": [],
    "_counter_cls": [],
    "_histogram_cls": [],
    "__init__": [
      "self",
      "vllm_config",
      "labelnames",
      "per_engine_labelvalues"
    ],
    "observe": [
      "self",
      "transfer_stats_data",
      "engine_idx"
    ]
  },
  "MultiKVConnectorMetadata": {},
  "MultiKVConnectorStats": {
    "aggregate": [
      "self",
      "other"
    ],
    "reset": [
      "self"
    ],
    "reduce": [
      "self"
    ],
    "is_empty": [
      "self"
    ],
    "__getitem__": [
      "self",
      "connector_id"
    ],
    "__setitem__": [
      "self",
      "connector_id",
      "stats"
    ]
  },
  "MultiKVConnectorPromMetrics": {
    "__init__": [
      "self",
      "vllm_config",
      "metric_types",
      "labelnames",
      "per_engine_labelvalues",
      "prom_metrics"
    ],
    "observe": [
      "self",
      "transfer_stats_data",
      "engine_idx"
    ]
  },
  "MultiConnector": {
    "__init__": [
      "self",
      "vllm_config",
      "role",
      "kv_cache_config"
    ],
    "prefer_cross_layer_blocks": [
      "self"
    ],
    "_get_connector_classes_and_configs": [
      "cls",
      "vllm_config"
    ],
    "register_cross_layers_kv_cache": [
      "self",
      "kv_cache",
      "attn_backend"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "bind_connector_metadata": [
      "self",
      "connector_metadata"
    ],
    "clear_connector_metadata": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "start_load_kv": [
      "self",
      "forward_context"
    ],
    "wait_for_layer_load": [
      "self",
      "layer_name"
    ],
    "save_kv_layer": [
      "self",
      "layer_name",
      "kv_layer",
      "attn_metadata"
    ],
    "wait_for_save": [
      "self"
    ],
    "get_finished": [
      "self",
      "finished_req_ids"
    ],
    "get_block_ids_with_load_errors": [
      "self"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "update_connector_output": [
      "self",
      "connector_output"
    ],
    "request_finished": [
      "self",
      "request",
      "blocks"
    ],
    "take_events": [
      "self"
    ],
    "get_required_kvcache_layout": [
      "cls",
      "vllm_config"
    ],
    "build_kv_connector_stats": [
      "cls",
      "data"
    ],
    "get_kv_connector_stats": [
      "self"
    ],
    "build_prom_metrics": [
      "cls",
      "vllm_config",
      "metric_types",
      "labelnames",
      "per_engine_labelvalues"
    ],
    "reset_cache": [
      "self"
    ]
  },
  "LMCacheKVEvents": {
    "__init__": [
      "self",
      "num_workers"
    ],
    "add_events": [
      "self",
      "events"
    ],
    "aggregate": [
      "self"
    ],
    "increment_workers": [
      "self",
      "count"
    ],
    "get_all_events": [
      "self"
    ],
    "get_number_of_workers": [
      "self"
    ],
    "clear_events": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "LMCacheConnectorV1": {
    "__init__": [
      "self",
      "vllm_config",
      "role",
      "kv_cache_config"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "start_load_kv": [
      "self",
      "forward_context"
    ],
    "wait_for_layer_load": [
      "self",
      "layer_name"
    ],
    "save_kv_layer": [
      "self",
      "layer_name",
      "kv_layer",
      "attn_metadata"
    ],
    "wait_for_save": [
      "self"
    ],
    "get_finished": [
      "self",
      "finished_req_ids"
    ],
    "get_block_ids_with_load_errors": [
      "self"
    ],
    "get_kv_connector_kv_cache_events": [
      "self"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "update_connector_output": [
      "self",
      "connector_output"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ],
    "take_events": [
      "self"
    ]
  },
  "DecodeBenchConnectorMetadata": {},
  "DecodeBenchConnector": {
    "__init__": [
      "self",
      "vllm_config",
      "role",
      "kv_cache_config"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "start_load_kv": [
      "self",
      "forward_context"
    ],
    "wait_for_layer_load": [
      "self",
      "layer_name"
    ],
    "save_kv_layer": [
      "self",
      "layer_name",
      "kv_layer",
      "attn_metadata"
    ],
    "wait_for_save": [
      "self"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ]
  },
  "DecodeBenchConnectorScheduler": {
    "__init__": [
      "self",
      "vllm_config"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "request_finished": [
      "self",
      "request"
    ]
  },
  "DecodeBenchConnectorWorker": {
    "__init__": [
      "self",
      "vllm_config"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "start_fill_kv": [
      "self",
      "metadata"
    ],
    "_fill_blocks": [
      "self",
      "group_idx",
      "block_ids",
      "num_tokens"
    ]
  },
  "ReqId": [],
  "TRANS_DONE": [],
  "TRANS_ERROR": [],
  "MooncakeAgentMetadata": {},
  "RecvReqMeta": {},
  "SendBlockMeta": {},
  "MooncakeConnectorMetadata": {
    "__init__": [
      "self"
    ],
    "add_new_req": [
      "self",
      "request_id",
      "local_block_ids",
      "kv_transfer_params",
      "load_remote_cache"
    ]
  },
  "MooncakeConnector": {
    "__init__": [
      "self",
      "vllm_config",
      "role",
      "kv_cache_config"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "get_finished": [
      "self",
      "finished_req_ids"
    ],
    "start_load_kv": [
      "self",
      "forward_context"
    ],
    "wait_for_layer_load": [
      "self",
      "layer_name"
    ],
    "save_kv_layer": [
      "self",
      "layer_name",
      "kv_layer",
      "attn_metadata"
    ],
    "wait_for_save": [
      "self"
    ]
  },
  "MooncakeConnectorScheduler": {
    "__init__": [
      "self",
      "vllm_config",
      "engine_id"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ]
  },
  "MooncakeConnectorWorker": {
    "__init__": [
      "self",
      "vllm_config",
      "engine_id"
    ],
    "__del__": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "_mooncake_sender_listener": [
      "self",
      "ready_event",
      "base_port",
      "tp_rank"
    ],
    "_sender_worker": [
      "self",
      "sock"
    ],
    "send_kv_to_decode": [
      "self",
      "meta"
    ],
    "_build_transfer_params": [
      "self",
      "send_reqs",
      "agent_meta"
    ],
    "_send_blocks": [
      "self",
      "remote_session",
      "src_ptrs",
      "dst_ptrs",
      "lengths"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "fetch_finished_recving_reqs": [
      "self"
    ],
    "fetch_finished_sending_reqs": [
      "self"
    ],
    "get_finished": [
      "self"
    ],
    "receive_kv": [
      "self",
      "path",
      "req_blocks"
    ],
    "group_kv_pull": [
      "self",
      "metadata"
    ],
    "record_send_reqs": [
      "self",
      "metadata"
    ],
    "start_load_kv": [
      "self",
      "metadata"
    ]
  },
  "group_concurrent_contiguous": [
    "src_indices",
    "dst_indices"
  ],
  "get_mooncake_side_channel_port": [
    "vllm_config"
  ],
  "_async_loop": [
    "loop"
  ],
  "reformat_block_ids": [
    "block_ids"
  ],
  "extract_world_size_and_kv_rank": [
    "world_size",
    "rank",
    "vllm_config"
  ],
  "create_scheduler_adapter": [
    "server_url",
    "zmq_context",
    "vllm_config"
  ],
  "create_worker_adapter": [
    "server_url",
    "zmq_context",
    "vllm_config"
  ],
  "convert_block_hashes_to_bytes": [
    "block_hashes"
  ],
  "LMCacheMPRequestState": {
    "PREFETCHING": [],
    "WAITING_FOR_LOAD": [],
    "READY": []
  },
  "LMCacheMPRequestTracker": {
    "__init__": [
      "self",
      "request"
    ],
    "needs_retrieve": [
      "self"
    ],
    "is_ready_for_retrieving": [
      "self"
    ],
    "increase_num_scheduled_tokens": [
      "self",
      "num_new_tokens"
    ],
    "increase_num_stored_blocks": [
      "self",
      "num_new_blocks"
    ],
    "append_block_ids": [
      "self",
      "new_block_ids"
    ],
    "__repr__": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "LMCacheMPRequestMetadata": {
    "GetStoreMetadata": [
      "tracker",
      "blocks_in_chunk",
      "vllm_block_size"
    ],
    "GetRetrieveMetadata": [
      "tracker",
      "blocks_in_chunk"
    ]
  },
  "LMCacheMPConnectorMetadata": {
    "__init__": [
      "self"
    ],
    "add_request_metadata": [
      "self",
      "request_metadata"
    ],
    "__len__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "LMCacheMPConnector": {
    "__init__": [
      "self",
      "vllm_config",
      "role",
      "kv_cache_config"
    ],
    "role": [
      "self"
    ],
    "_get_connector_metadata": [
      "self"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "start_load_kv": [
      "self",
      "forward_context"
    ],
    "wait_for_layer_load": [
      "self",
      "layer_name"
    ],
    "save_kv_layer": [
      "self",
      "layer_name",
      "kv_layer",
      "attn_metadata"
    ],
    "wait_for_save": [
      "self"
    ],
    "get_finished": [
      "self",
      "finished_req_ids"
    ],
    "get_block_ids_with_load_errors": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "get_kv_connector_stats": [
      "self"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "update_connector_output": [
      "self",
      "connector_output"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ],
    "take_events": [
      "self"
    ],
    "get_required_kvcache_layout": [
      "cls",
      "vllm_config"
    ],
    "get_finished_count": [
      "self"
    ],
    "build_kv_connector_stats": [
      "cls",
      "data"
    ],
    "build_prom_metrics": [
      "cls",
      "vllm_config",
      "metric_types",
      "labelnames",
      "per_engine_labelvalues"
    ],
    "_process_retrieve_requests": [
      "self",
      "metadata"
    ],
    "_process_new_requests": [
      "self",
      "scheduler_output",
      "metadata"
    ],
    "_process_cached_requests": [
      "self",
      "scheduler_output",
      "metadata"
    ],
    "_get_request_tracker": [
      "self",
      "request_id"
    ],
    "_get_or_create_request_tracker": [
      "self",
      "request"
    ],
    "_cleanup_request_tracker": [
      "self",
      "request_id"
    ]
  },
  "TransferHandle": [],
  "GET_META_MSG": [],
  "_NIXL_SUPPORTED_DEVICE": [],
  "NixlAgentMetadata": {},
  "NixlHandshakePayload": {},
  "compute_nixl_compatibility_hash": [
    "vllm_config",
    "attn_backend_name"
  ],
  "RemoteMeta": {},
  "ReqMeta": {},
  "NixlConnectorMetadata": {
    "__init__": [
      "self"
    ],
    "_add_new_req": [
      "self",
      "local_block_ids",
      "kv_transfer_params"
    ],
    "add_new_req_to_save": [
      "self",
      "request_id",
      "local_block_ids",
      "kv_transfer_params"
    ],
    "add_new_req_to_recv": [
      "self",
      "request_id",
      "local_block_ids",
      "kv_transfer_params"
    ]
  },
  "NixlConnector": {
    "__init__": [
      "self",
      "vllm_config",
      "role",
      "kv_cache_config"
    ],
    "get_required_kvcache_layout": [
      "cls",
      "vllm_config"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ],
    "set_xfer_handshake_metadata": [
      "self",
      "metadata"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "set_host_xfer_buffer_ops": [
      "self",
      "copy_operation"
    ],
    "get_finished": [
      "self",
      "finished_req_ids"
    ],
    "get_block_ids_with_load_errors": [
      "self"
    ],
    "get_kv_connector_stats": [
      "self"
    ],
    "build_kv_connector_stats": [
      "cls",
      "data"
    ],
    "build_prom_metrics": [
      "cls",
      "vllm_config",
      "metric_types",
      "labelnames",
      "per_engine_labelvalues"
    ],
    "start_load_kv": [
      "self",
      "forward_context"
    ],
    "wait_for_layer_load": [
      "self",
      "layer_name"
    ],
    "save_kv_layer": [
      "self",
      "layer_name",
      "kv_layer",
      "attn_metadata"
    ],
    "wait_for_save": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "get_handshake_metadata": [
      "self"
    ]
  },
  "NixlConnectorScheduler": {
    "__init__": [
      "self",
      "vllm_config",
      "engine_id"
    ],
    "shutdown": [
      "self"
    ],
    "set_xfer_handshake_metadata": [
      "self",
      "metadata"
    ],
    "_nixl_handshake_listener": [
      "encoded_data",
      "ready_event",
      "stop_event",
      "port"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ]
  },
  "NixlConnectorWorker": {
    "__init__": [
      "self",
      "vllm_config",
      "engine_id"
    ],
    "_nixl_handshake": [
      "self",
      "host",
      "port",
      "remote_tp_size",
      "expected_engine_id"
    ],
    "initialize_host_xfer_buffer": [
      "self",
      "kv_caches"
    ],
    "set_host_xfer_buffer_ops": [
      "self",
      "copy_operation"
    ],
    "_log_failure": [
      "self",
      "failure_type",
      "req_id",
      "msg",
      "error",
      "meta"
    ],
    "_background_nixl_handshake": [
      "self",
      "req_id",
      "remote_engine_id",
      "meta"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "register_local_xfer_handler": [
      "self",
      "block_size"
    ],
    "add_remote_agent": [
      "self",
      "nixl_agent_meta",
      "remote_tp_rank",
      "remote_tp_size"
    ],
    "_validate_remote_agent_handshake": [
      "self",
      "nixl_agent_meta",
      "remote_tp_size"
    ],
    "sync_recved_kv_to_device": [
      "self",
      "req_id",
      "meta"
    ],
    "save_kv_to_host": [
      "self",
      "metadata"
    ],
    "post_process_device_kv_on_receive": [
      "self",
      "block_size_ratio",
      "block_ids_list"
    ],
    "get_finished": [
      "self"
    ],
    "_get_new_notifs": [
      "self"
    ],
    "_pop_done_transfers": [
      "self",
      "transfers"
    ],
    "_handle_failed_transfer": [
      "self",
      "req_id",
      "handle"
    ],
    "start_load_kv": [
      "self",
      "metadata"
    ],
    "_read_blocks_for_req": [
      "self",
      "req_id",
      "meta"
    ],
    "_read_blocks": [
      "self",
      "local_block_ids",
      "remote_block_ids",
      "dst_engine_id",
      "request_id",
      "remote_request_id",
      "remote_rank",
      "local_xfer_side_handle",
      "remote_xfer_side_handle"
    ],
    "get_mapped_blocks": [
      "self",
      "block_ids",
      "block_size_ratio"
    ],
    "_get_block_descs_ids": [
      "self",
      "engine_id",
      "block_ids",
      "layer_idx",
      "block_size_ratio"
    ],
    "_logical_to_kernel_block_ids": [
      "self",
      "block_ids"
    ],
    "get_backend_aware_kv_block_len": [
      "self",
      "layer_idx"
    ],
    "get_kv_connector_stats": [
      "self"
    ],
    "get_block_ids_with_load_errors": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "shutdown": [
      "self"
    ]
  },
  "zmq_ctx": [
    "socket_type",
    "addr"
  ],
  "NixlKVConnectorStats": {
    "__post_init__": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "record_transfer": [
      "self",
      "res"
    ],
    "record_failed_transfer": [
      "self"
    ],
    "record_failed_notification": [
      "self"
    ],
    "record_kv_expired_req": [
      "self"
    ],
    "clone_and_reset": [
      "self"
    ],
    "is_empty": [
      "self"
    ],
    "aggregate": [
      "self",
      "other"
    ],
    "reduce": [
      "self"
    ],
    "num_successful_transfers": [
      "self"
    ]
  },
  "NixlPromMetrics": {
    "__init__": [
      "self",
      "vllm_config",
      "metric_types",
      "labelnames",
      "per_engine_labelvalues"
    ],
    "observe": [
      "self",
      "transfer_stats_data",
      "engine_idx"
    ]
  },
  "OffloadingConnectorMetadata": {},
  "OffloadingConnector": {
    "prefer_cross_layer_blocks": [
      "self"
    ],
    "__init__": [
      "self",
      "vllm_config",
      "role",
      "kv_cache_config"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "register_cross_layers_kv_cache": [
      "self",
      "kv_cache",
      "attn_backend"
    ],
    "handle_preemptions": [
      "self",
      "preempted_req_ids"
    ],
    "start_load_kv": [
      "self",
      "forward_context"
    ],
    "wait_for_layer_load": [
      "self",
      "layer_name"
    ],
    "save_kv_layer": [
      "self",
      "layer_name",
      "kv_layer",
      "attn_metadata"
    ],
    "wait_for_save": [
      "self"
    ],
    "get_finished": [
      "self",
      "finished_req_ids"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "update_connector_output": [
      "self",
      "connector_output"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ],
    "take_events": [
      "self"
    ]
  },
  "OffloadingConnectorScheduler": {
    "__init__": [
      "self",
      "spec"
    ],
    "_get_block_hashes": [
      "self",
      "req",
      "start_idx",
      "end_idx"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "_get_reqs_to_store": [
      "self",
      "scheduler_output"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "update_connector_output": [
      "self",
      "connector_output"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ],
    "take_events": [
      "self"
    ]
  },
  "OffloadingConnectorWorker": {
    "__init__": [
      "self",
      "spec"
    ],
    "_generate_job_id": [
      "self"
    ],
    "_register_handlers": [
      "self",
      "kv_caches",
      "attn_backends"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "register_cross_layers_kv_cache": [
      "self",
      "kv_cache",
      "attn_backend"
    ],
    "handle_preemptions": [
      "self",
      "preempted_req_ids"
    ],
    "start_kv_transfers": [
      "self",
      "metadata"
    ],
    "prepare_store_kv": [
      "self",
      "metadata"
    ],
    "get_finished": [
      "self",
      "finished_req_ids"
    ]
  },
  "ExampleConnectorMetadata": {
    "add_request": [
      "self",
      "token_ids",
      "block_ids",
      "block_size",
      "is_store",
      "mm_hashes"
    ]
  },
  "ExampleConnector": {
    "__init__": [
      "self",
      "vllm_config",
      "role",
      "kv_cache_config"
    ],
    "start_load_kv": [
      "self",
      "forward_context"
    ],
    "wait_for_layer_load": [
      "self",
      "layer_name"
    ],
    "save_kv_layer": [
      "self",
      "layer_name",
      "kv_layer",
      "attn_metadata"
    ],
    "wait_for_save": [
      "self"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "_found_match_for_request": [
      "self",
      "request"
    ],
    "_found_match_for_prompt": [
      "self",
      "prompt_token_ids",
      "mm_hashes"
    ],
    "_generate_foldername_debug": [
      "self",
      "token_ids",
      "mm_hashes",
      "create_folder"
    ],
    "_generate_filename_debug": [
      "self",
      "layer_name",
      "token_ids",
      "mm_hashes"
    ]
  },
  "align_to_block_size": [
    "num_tokens",
    "block_size"
  ],
  "is_moriio_available": [],
  "MoRIIOConnector": {
    "__init__": [
      "self",
      "vllm_config",
      "role",
      "kv_cache_config"
    ],
    "_set_port_defaults": [
      "self",
      "vllm_config"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "get_finished": [
      "self",
      "finished_req_ids"
    ],
    "start_load_kv": [
      "self",
      "forward_context"
    ],
    "wait_for_layer_load": [
      "self",
      "layer_name"
    ],
    "save_kv_layer": [
      "self",
      "layer_name",
      "kv_layer",
      "attn_metadata"
    ],
    "wait_for_save": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "has_connector_metadata": [
      "self"
    ]
  },
  "MoRIIOConnectorScheduler": {
    "__init__": [
      "self",
      "vllm_config",
      "engine_id"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "send_notify_block": [
      "self",
      "req_id",
      "block_notify_list",
      "host",
      "port"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens",
      "connector_worker"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "shutdown": [
      "self"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ]
  },
  "MoRIIOConnectorWorker": {
    "__init__": [
      "self",
      "vllm_config",
      "engine_id"
    ],
    "schedule_write_blocks": [
      "self",
      "request_id",
      "dst_engine_id",
      "local_block_ids",
      "remote_block_ids",
      "layer_name",
      "kv_layer",
      "remote_notify_port",
      "remote_ip"
    ],
    "_get_built_session": [
      "self",
      "remote_engine_id"
    ],
    "_ping": [
      "self",
      "zmq_context"
    ],
    "shutdown": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "_moriio_handshake_listener": [
      "metadata",
      "ready_event",
      "base_port",
      "tp_rank",
      "dp_rank",
      "layer_name_to_local_kv_cache_metadata"
    ],
    "_moriio_handshake": [
      "self",
      "host",
      "port",
      "remote_tp_size",
      "expected_engine_id",
      "remote_dp_rank"
    ],
    "_background_moriio_handshake": [
      "self",
      "req_id",
      "remote_engine_id",
      "meta"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "get_finished": [
      "self"
    ],
    "_pop_done_transfers": [
      "self"
    ],
    "save_kv_layer": [
      "self",
      "metadata",
      "layer_name",
      "kv_layer",
      "attn_metadata"
    ],
    "get_engine_name_with_dp": [
      "self",
      "engine_name",
      "dp_rank"
    ],
    "start_load_kv": [
      "self",
      "metadata"
    ],
    "_read_blocks_for_req": [
      "self",
      "req_id",
      "meta"
    ],
    "_write_blocks_for_req": [
      "self",
      "req_id",
      "meta",
      "layer_name",
      "kv_layer"
    ],
    "_is_last_layer": [
      "self",
      "layer_name"
    ],
    "merge_contiguous_blocks": [
      "self",
      "offsets_local",
      "offsets_remote",
      "sizes",
      "assume_sorted"
    ],
    "_compute_block_transfer_offsets": [
      "self",
      "layer_name",
      "local_block_ids",
      "remote_block_ids",
      "remote_moriio_meta"
    ],
    "_read_blocks": [
      "self",
      "local_block_ids",
      "remote_block_ids",
      "dst_engine_id",
      "request_id",
      "remote_host",
      "remote_notify_port"
    ]
  },
  "Transfer": [],
  "WriteTask": {},
  "LayerTransferPlan": {},
  "RemoteAllocInfo": {},
  "ROLE": {
    "PRODUCER": [],
    "CONSUMER": [],
    "NOTINIT": []
  },
  "MoRIIOAgentMetadata": {},
  "RoleManager": {
    "_lock": [],
    "__init__": [
      "self"
    ],
    "get_instance": [
      "cls"
    ],
    "set_role": [
      "self",
      "role"
    ],
    "get_role": [
      "self"
    ]
  },
  "set_role": [
    "role"
  ],
  "get_role": [],
  "MoRIIOMode": {
    "READ": [],
    "WRITE": []
  },
  "MoRIIOError": {},
  "HandshakeError": {},
  "TransferError": {},
  "get_moriio_mode": [],
  "get_port_offset": [
    "dp_rank",
    "tp_rank",
    "tp_size"
  ],
  "MoRIIOConfig": {
    "from_vllm_config": [
      "cls",
      "vllm_config"
    ]
  },
  "MoRIIOConstants": {
    "GET_META_MSG": [],
    "POP_DONE_RECV": [],
    "OVER": [],
    "COMPLETION_PREFIX": [],
    "PING_INTERVAL": [],
    "MAX_PING_RETRIES": [],
    "DEFAULT_HANDSHAKE_PORT": [],
    "DEFAULT_NOTIFY_PORT": [],
    "VLLM_MORI_READ_ABORT_REQUEST_TIMEOUT": []
  },
  "MoRIIOConnectorMetadata": {
    "__init__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "add_new_req": [
      "self",
      "request_id",
      "local_block_ids",
      "kv_transfer_params",
      "write_mode"
    ]
  },
  "MoRIIOWriter": {
    "__init__": [
      "self",
      "worker"
    ],
    "worker": [
      "self"
    ],
    "ensure_worker_started": [
      "self"
    ],
    "schedule_write": [
      "self",
      "task"
    ],
    "_write_worker_loop": [
      "self"
    ],
    "_process_deferred_tasks": [
      "self"
    ],
    "_is_remote_ready": [
      "self",
      "task"
    ],
    "_get_remote_alloc_info": [
      "self",
      "request_id"
    ],
    "_execute_write_task": [
      "self",
      "task"
    ],
    "_prepare_transfer_plan": [
      "self",
      "task",
      "request_info",
      "remote_moriio_meta"
    ],
    "_do_layer_write": [
      "self",
      "plan",
      "sessions"
    ],
    "_finalize_if_complete": [
      "self",
      "task",
      "request_info"
    ]
  },
  "MoRIIOWrapper": {
    "__init__": [
      "self",
      "moriio_engine",
      "tp_rank",
      "dp_rank"
    ],
    "set_moriio_engine": [
      "self",
      "moriio_engine"
    ],
    "set_backend_type": [
      "self",
      "backend_type"
    ],
    "get_agent_metadata": [
      "self"
    ],
    "register_remote_engine": [
      "self",
      "remote_packed_engine_metadata"
    ],
    "register_local_tensor": [
      "self",
      "tensor"
    ],
    "get_unpack_memory_metadata": [
      "self",
      "packed_memory_metadata"
    ],
    "build_session": [
      "self",
      "local_memory_metadata",
      "remote_memory_metadata"
    ],
    "read_remote_data": [
      "self",
      "transfer_size_byte",
      "local_offset",
      "remote_offset",
      "session"
    ],
    "write_remote_data": [
      "self",
      "transfer_size_byte",
      "local_offset",
      "remote_offset",
      "session"
    ],
    "write_remote_data_single": [
      "self",
      "transfer_size_byte",
      "local_offset",
      "remote_offset",
      "sess_idx"
    ],
    "waiting_for_transfer_complete": [
      "self"
    ],
    "async_wait_reqid": [
      "self"
    ],
    "_handle_message": [
      "self",
      "msg"
    ],
    "_handle_structured_message": [
      "self",
      "data"
    ],
    "_handle_completion_message": [
      "self",
      "msg"
    ],
    "send_notify": [
      "self",
      "req_ids",
      "remote_ip",
      "remote_port"
    ],
    "pop_finished_req_ids": [
      "self"
    ],
    "pop_finished_write_req_ids": [
      "self"
    ],
    "shutdown": [
      "self"
    ]
  },
  "LoadSpec": {},
  "SaveSpec": {},
  "DisaggSpec": {},
  "extract_request_configs": [
    "sampling_params"
  ],
  "RequestTracker": {
    "is_decode_phase": [],
    "from_new_request": [
      "lmcache_config",
      "new_request",
      "num_tokens_to_compute",
      "lmcache_cached_tokens",
      "skip_save"
    ],
    "update": [
      "self",
      "new_token_ids",
      "new_block_ids"
    ]
  },
  "need_gpu_interm_buffer": [
    "lmcache_config"
  ],
  "_calculate_mtp_layers": [
    "vllm_config",
    "model_config"
  ],
  "_init_lmcache_engine": [
    "lmcache_config",
    "vllm_config"
  ],
  "LMCacheConnectorMetadata": {
    "add_request": [
      "self",
      "req_meta"
    ]
  },
  "LMCacheConnectorV1Impl": {
    "__init__": [
      "self",
      "vllm_config",
      "role",
      "parent"
    ],
    "get_inference_info": [
      "self"
    ],
    "get_inference_version": [
      "self"
    ],
    "_init_kv_caches_from_forward_context": [
      "self",
      "forward_context"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "start_load_kv": [
      "self",
      "forward_context"
    ],
    "wait_for_layer_load": [
      "self",
      "layer_name"
    ],
    "save_kv_layer": [
      "self",
      "layer_name",
      "kv_layer",
      "attn_metadata"
    ],
    "wait_for_save": [
      "self"
    ],
    "get_finished": [
      "self",
      "finished_req_ids"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ]
  },
  "ENGINE_NAME": [],
  "_config_lock": [],
  "is_false": [
    "value"
  ],
  "lmcache_get_or_create_config": [],
  "hex_hash_to_int16": [
    "s"
  ],
  "apply_mm_hashes_to_token_ids": [
    "token_ids",
    "mm_hashes",
    "mm_positions"
  ],
  "mla_enabled": [
    "model_config"
  ],
  "create_lmcache_metadata": [
    "vllm_config",
    "model_config",
    "parallel_config",
    "cache_config"
  ],
  "extract_mm_features": [
    "request",
    "modify"
  ],
  "wrap_kv_caches": [
    "kv_caches"
  ],
  "send_lmcache_request": [
    "mq_client",
    "request_type",
    "payloads"
  ],
  "get_lmcache_chunk_size": [
    "mq_client"
  ],
  "striding_block_hashes": [
    "block_hashes",
    "blocks_in_chunk"
  ],
  "LoadStoreOp": {
    "__len__": [
      "self"
    ],
    "__post_init__": [
      "self"
    ]
  },
  "StoreResult": [],
  "RetrieveResult": [],
  "LookupResult": [],
  "LMCacheMPSchedulerAdapter": {
    "__init__": [
      "self",
      "server_url",
      "context",
      "model_name",
      "world_size",
      "kv_rank",
      "vllm_block_size"
    ],
    "maybe_submit_lookup_request": [
      "self",
      "request_id",
      "block_hashes"
    ],
    "check_lookup_result": [
      "self",
      "request_id"
    ],
    "num_blocks_per_chunk": [
      "self"
    ],
    "cleanup_lookup_result": [
      "self",
      "request_id"
    ],
    "_create_key": [
      "self",
      "block_hash"
    ]
  },
  "LMCacheMPWorkerAdapter": {
    "__init__": [
      "self",
      "server_url",
      "context",
      "model_name",
      "world_size",
      "kv_rank",
      "vllm_block_size"
    ],
    "register_kv_caches": [
      "self",
      "kv_caches"
    ],
    "submit_store_request": [
      "self",
      "request_id",
      "op",
      "event"
    ],
    "submit_retrieve_request": [
      "self",
      "request_id",
      "op",
      "event"
    ],
    "batched_submit_store_requests": [
      "self",
      "request_ids",
      "ops",
      "event"
    ],
    "batched_submit_retrieve_requests": [
      "self",
      "request_ids",
      "ops",
      "event"
    ],
    "get_finished": [
      "self",
      "finished_req_ids"
    ],
    "num_blocks_per_chunk": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "_update_and_get_finished_store": [
      "self"
    ],
    "_create_key": [
      "self",
      "block_hash"
    ],
    "_block_hashes_to_keys": [
      "self",
      "block_hashes"
    ]
  },
  "MemoryBlock": {},
  "TensorMemoryPool": {
    "__init__": [
      "self",
      "max_block_size",
      "min_block_size"
    ],
    "_round_to_power_of_two": [
      "self",
      "size"
    ],
    "_initialize_free_lists": [
      "self"
    ],
    "_allocate_pinned_memory": [
      "self"
    ],
    "allocate": [
      "self",
      "size"
    ],
    "_split_block": [
      "self",
      "block",
      "required_size"
    ],
    "free": [
      "self",
      "addr"
    ],
    "_merge_buddies": [
      "self",
      "block"
    ],
    "store_tensor": [
      "self",
      "tensor"
    ],
    "load_tensor": [
      "self",
      "addr",
      "dtype",
      "shape",
      "device"
    ],
    "cleanup": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "P2pNcclConnectorMetadata": {
    "__init__": [
      "self"
    ],
    "add_request": [
      "self",
      "request_id",
      "token_ids",
      "block_ids",
      "block_size"
    ]
  },
  "P2pNcclConnector": {
    "__init__": [
      "self",
      "vllm_config",
      "role",
      "kv_cache_config"
    ],
    "start_load_kv": [
      "self",
      "forward_context"
    ],
    "wait_for_layer_load": [
      "self",
      "layer_name"
    ],
    "save_kv_layer": [
      "self",
      "layer_name",
      "kv_layer",
      "attn_metadata"
    ],
    "wait_for_save": [
      "self"
    ],
    "get_finished": [
      "self",
      "finished_req_ids"
    ],
    "get_num_new_matched_tokens": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "blocks",
      "num_external_tokens"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "request_finished": [
      "self",
      "request",
      "block_ids"
    ],
    "parse_request_id": [
      "request_id",
      "is_prefill"
    ],
    "check_tensors_except_dim": [
      "tensor1",
      "tensor2",
      "dim"
    ]
  },
  "DEFAULT_MEM_POOL_SIZE_GB": [],
  "set_p2p_nccl_context": [
    "num_channels"
  ],
  "SendQueueItem": {},
  "P2pNcclEngine": {
    "__init__": [
      "self",
      "local_rank",
      "config",
      "hostname",
      "port_offset",
      "library_path"
    ],
    "create_connect": [
      "self",
      "remote_address"
    ],
    "send_tensor": [
      "self",
      "tensor_id",
      "tensor",
      "remote_address"
    ],
    "recv_tensor": [
      "self",
      "tensor_id",
      "remote_address"
    ],
    "listen_for_requests": [
      "self"
    ],
    "have_sent_tensor_id": [
      "self",
      "tensor_id"
    ],
    "have_received_tensor_id": [
      "self",
      "tensor_id"
    ],
    "send_async": [
      "self"
    ],
    "wait_for_sent": [
      "self"
    ],
    "send_sync": [
      "self",
      "item"
    ],
    "get_finished": [
      "self",
      "finished_req_ids",
      "no_compile_layers"
    ],
    "ping": [
      "self"
    ],
    "send": [
      "self",
      "comm",
      "tensor",
      "dst",
      "stream"
    ],
    "recv": [
      "self",
      "comm",
      "tensor",
      "src",
      "stream"
    ],
    "close": [
      "self"
    ]
  },
  "get_ec_transfer": [],
  "has_ec_transfer": [],
  "ensure_ec_transfer_initialized": [
    "vllm_config"
  ],
  "ECConnectorFactory": {
    "register_connector": [
      "cls",
      "name",
      "module_path",
      "class_name"
    ],
    "create_connector": [
      "cls",
      "config",
      "role"
    ],
    "get_connector_class": [
      "cls",
      "ec_transfer_config"
    ]
  },
  "ECConnectorRole": {
    "SCHEDULER": [],
    "WORKER": []
  },
  "ECConnectorMetadata": {},
  "ECConnectorBase": {
    "__init__": [
      "self",
      "vllm_config",
      "role"
    ],
    "role": [
      "self"
    ],
    "is_producer": [
      "self"
    ],
    "bind_connector_metadata": [
      "self",
      "connector_metadata"
    ],
    "clear_connector_metadata": [
      "self"
    ],
    "_get_connector_metadata": [
      "self"
    ],
    "register_caches": [
      "self",
      "ec_caches"
    ],
    "start_load_caches": [
      "self",
      "encoder_cache"
    ],
    "save_caches": [
      "self",
      "encoder_cache",
      "mm_hash"
    ],
    "get_finished": [
      "self",
      "finished_req_ids"
    ],
    "has_cache_item": [
      "self",
      "identifier"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "index"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "update_connector_output": [
      "self",
      "connector_output"
    ],
    "request_finished": [
      "self",
      "request"
    ]
  },
  "MMMeta": {
    "make_meta": [
      "mm_hash",
      "num_token"
    ]
  },
  "ECExampleConnectorMetadata": {
    "__init__": [
      "self"
    ],
    "add_mm_data": [
      "self",
      "mm_data"
    ]
  },
  "ECExampleConnector": {
    "__init__": [
      "self",
      "vllm_config",
      "role"
    ],
    "start_load_caches": [
      "self",
      "encoder_cache"
    ],
    "save_caches": [
      "self",
      "encoder_cache",
      "mm_hash"
    ],
    "has_cache_item": [
      "self",
      "identifier"
    ],
    "update_state_after_alloc": [
      "self",
      "request",
      "index"
    ],
    "build_connector_meta": [
      "self",
      "scheduler_output"
    ],
    "_found_match_for_mm_data": [
      "self",
      "mm_hash"
    ],
    "_generate_foldername_debug": [
      "self",
      "mm_hash",
      "create_folder"
    ],
    "_generate_filename_debug": [
      "self",
      "mm_hash"
    ]
  },
  "start_async_worker": [
    "state",
    "rank_mapping",
    "is_profile"
  ],
  "transfer_run_periodically": [
    "state",
    "ep_group",
    "cuda_stream",
    "is_profile",
    "rank_mapping"
  ],
  "EplbModelState": {},
  "EplbState": {
    "__init__": [
      "self",
      "parallel_config",
      "device"
    ],
    "build_initial_global_physical_to_logical_map": [
      "num_routed_experts",
      "num_redundant_experts"
    ],
    "validate_ep_configuration": [
      "self",
      "new_model"
    ],
    "add_model": [
      "self",
      "model",
      "model_config",
      "global_expert_load",
      "old_global_expert_indices",
      "rank_mapping"
    ],
    "step": [
      "self",
      "is_dummy",
      "is_profile",
      "log_stats"
    ],
    "rearrange": [
      "self",
      "is_profile",
      "execute_shuffle",
      "global_expert_loads",
      "rank_mapping"
    ],
    "start_async_loop": [
      "self",
      "rank_mapping",
      "is_profile"
    ],
    "_update_layer_mapping_from_new": [
      "self",
      "model_state",
      "layer"
    ],
    "_all_ranks_buffer_ready": [
      "self",
      "model_state"
    ],
    "move_to_workspace": [
      "self",
      "model_state",
      "ep_group",
      "is_profile"
    ],
    "post_eplb": [
      "self",
      "model_state",
      "is_profile"
    ],
    "recv_state": [],
    "get_eep_state": [
      "cls",
      "parallel_config"
    ],
    "_allreduce_list": [
      "self",
      "tensor_list"
    ],
    "_sync_load_pass": [
      "self"
    ]
  },
  "EplbLayerState": {},
  "_node_count_with_rank_mapping": [
    "pg",
    "rank_mapping"
  ],
  "RecvMetadata": {},
  "MoveToBufferResult": [],
  "get_ep_ranks_with_experts_batch": [
    "expert_ids",
    "num_local_experts",
    "old_indices",
    "new_indices"
  ],
  "move_to_buffer": [
    "num_local_experts",
    "old_indices",
    "new_indices",
    "expert_weights",
    "expert_weights_buffers",
    "cuda_stream",
    "ep_group"
  ],
  "move_from_buffer": [
    "expert_weights",
    "expert_weights_buffers",
    "is_unchanged",
    "is_received_locally",
    "recv_metadata",
    "new_indices",
    "ep_rank"
  ],
  "transfer_layer": [
    "old_global_expert_indices",
    "new_global_expert_indices",
    "expert_weights",
    "expert_weights_buffer",
    "ep_group",
    "is_profile",
    "layer",
    "cuda_stream",
    "rank_mapping"
  ],
  "rearrange_expert_weights_inplace": [
    "old_global_expert_indices",
    "new_global_expert_indices",
    "expert_weights",
    "ep_group",
    "is_profile",
    "rank_mapping"
  ],
  "_map_old_expert_indices_with_rank_mapping": [
    "old_global_expert_indices",
    "rank_mapping",
    "new_ep_size"
  ],
  "_map_new_expert_indices_with_rank_mapping": [
    "new_global_expert_indices",
    "rank_mapping"
  ],
  "DefaultEplbPolicy": {
    "balanced_packing": [
      "cls",
      "weight",
      "num_packs"
    ],
    "replicate_experts": [
      "cls",
      "weight",
      "num_phy"
    ],
    "rebalance_experts_hierarchical": [
      "cls",
      "weight",
      "num_physical_experts",
      "num_groups",
      "num_nodes",
      "num_gpus"
    ],
    "preserve_intragpu_slots": [
      "cls",
      "phy2log",
      "phy_replicas_idx",
      "num_ranks",
      "old_phy2log"
    ],
    "rebalance_experts": [
      "cls",
      "weight",
      "num_replicas",
      "num_groups",
      "num_nodes",
      "num_ranks",
      "old_global_expert_indices"
    ]
  },
  "EPLB_POLICIES": [],
  "AbstractEplbPolicy": {
    "rebalance_experts": [
      "cls",
      "weight",
      "num_replicas",
      "num_groups",
      "num_nodes",
      "num_ranks",
      "old_global_expert_indices"
    ]
  },
  "cumem_available": [],
  "HandleType": [],
  "AllocationData": {},
  "create_and_map": [
    "allocation_handle"
  ],
  "unmap_and_release": [
    "allocation_handle"
  ],
  "get_pluggable_allocator": [
    "python_malloc_fn",
    "python_free_func"
  ],
  "use_memory_pool_with_allocator": [
    "python_malloc_fn",
    "python_free_func"
  ],
  "CuMemAllocator": {
    "get_instance": [],
    "__init__": [
      "self"
    ],
    "_python_malloc_callback": [
      "self",
      "allocation_handle"
    ],
    "_python_free_callback": [
      "self",
      "ptr"
    ],
    "sleep": [
      "self",
      "offload_tags"
    ],
    "wake_up": [
      "self",
      "tags"
    ],
    "use_memory_pool": [
      "self",
      "tag"
    ],
    "get_current_usage": [
      "self"
    ]
  },
  "parse_type": [
    "return_type"
  ],
  "optional_type": [
    "return_type"
  ],
  "union_dict_and_str": [
    "val"
  ],
  "is_type": [
    "type_hint",
    "type"
  ],
  "contains_type": [
    "type_hints",
    "type"
  ],
  "get_type": [
    "type_hints",
    "type"
  ],
  "literal_to_kwargs": [
    "type_hints"
  ],
  "collection_to_kwargs": [
    "type_hints",
    "type"
  ],
  "is_not_builtin": [
    "type_hint"
  ],
  "get_type_hints": [
    "type_hint"
  ],
  "NEEDS_HELP": [],
  "_compute_kwargs": [
    "cls"
  ],
  "get_kwargs": [
    "cls"
  ],
  "EngineArgs": {
    "__post_init__": [
      "self"
    ],
    "add_cli_args": [
      "parser"
    ],
    "from_cli_args": [
      "cls",
      "args"
    ],
    "create_model_config": [
      "self"
    ],
    "validate_tensorizer_args": [
      "self"
    ],
    "create_load_config": [
      "self"
    ],
    "create_speculative_config": [
      "self",
      "target_model_config",
      "target_parallel_config"
    ],
    "create_engine_config": [
      "self",
      "usage_context",
      "headless"
    ],
    "_check_feature_supported": [
      "self",
      "model_config"
    ],
    "get_batch_defaults": [
      "cls",
      "world_size"
    ],
    "_set_default_chunked_prefill_and_prefix_caching_args": [
      "self",
      "model_config"
    ],
    "_set_default_max_num_seqs_and_batched_tokens_args": [
      "self",
      "usage_context",
      "model_config"
    ]
  },
  "AsyncEngineArgs": {
    "add_cli_args": [
      "parser",
      "async_args_only"
    ]
  },
  "_raise_unsupported_error": [
    "feature_name"
  ],
  "human_readable_int": [
    "value"
  ],
  "human_readable_int_or_auto": [
    "value"
  ],
  "EngineClient": {
    "renderer": [
      "self"
    ],
    "is_running": [
      "self"
    ],
    "is_stopped": [
      "self"
    ],
    "errored": [
      "self"
    ],
    "dead_error": [
      "self"
    ],
    "generate": [
      "self",
      "prompt",
      "sampling_params",
      "request_id"
    ],
    "encode": [
      "self",
      "prompt",
      "pooling_params",
      "request_id",
      "lora_request",
      "trace_headers",
      "priority",
      "truncate_prompt_tokens",
      "tokenization_kwargs"
    ],
    "abort": [
      "self",
      "request_id"
    ],
    "is_tracing_enabled": [
      "self"
    ],
    "do_log_stats": [
      "self"
    ],
    "check_health": [
      "self"
    ],
    "start_profile": [
      "self"
    ],
    "stop_profile": [
      "self"
    ],
    "reset_mm_cache": [
      "self"
    ],
    "reset_prefix_cache": [
      "self",
      "reset_running_requests",
      "reset_connector"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wake_up": [
      "self",
      "tags"
    ],
    "is_sleeping": [
      "self"
    ],
    "add_lora": [
      "self",
      "lora_request"
    ],
    "pause_generation": [
      "self"
    ],
    "resume_generation": [
      "self"
    ],
    "is_paused": [
      "self"
    ],
    "scale_elastic_ep": [
      "self",
      "new_data_parallel_size",
      "drain_timeout"
    ],
    "collective_rpc": [
      "self",
      "method",
      "timeout",
      "args",
      "kwargs"
    ],
    "get_supported_tasks": [
      "self"
    ]
  },
  "LLMEngine": [],
  "AsyncLLMEngine": [],
  "SortedHelpFormatter": {
    "_split_lines": [
      "self",
      "text",
      "width"
    ],
    "add_arguments": [
      "self",
      "actions"
    ]
  },
  "FlexibleArgumentParser": {
    "__init__": [
      "self"
    ],
    "format_help": [
      "self"
    ],
    "parse_args": [
      "self",
      "args",
      "namespace"
    ],
    "check_port": [
      "self",
      "value"
    ],
    "_pull_args_from_config": [
      "self",
      "args"
    ],
    "load_config_file": [
      "self",
      "file_path"
    ]
  },
  "format_mib": [
    "b"
  ],
  "format_gib": [
    "b"
  ],
  "get_max_shared_memory_bytes": [
    "gpu"
  ],
  "get_cpu_memory": [],
  "DeviceMemoryProfiler": {
    "__init__": [
      "self",
      "device"
    ],
    "current_memory_usage": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "MemorySnapshot": {
    "__post_init__": [
      "self"
    ],
    "measure": [
      "self"
    ],
    "__sub__": [
      "self",
      "other"
    ],
    "__repr__": [
      "self"
    ]
  },
  "MemoryProfilingResult": {
    "__post_init__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "memory_profiling": [
    "baseline_snapshot",
    "weights_memory"
  ],
  "STR_DTYPE_TO_TORCH_DTYPE": [],
  "TORCH_DTYPE_TO_NUMPY_DTYPE": [],
  "MODELOPT_TO_VLLM_KV_CACHE_DTYPE_MAP": [],
  "is_strictly_contiguous": [
    "t"
  ],
  "set_default_torch_dtype": [
    "dtype"
  ],
  "set_default_torch_num_threads": [
    "num_threads"
  ],
  "guard_cuda_initialization": [],
  "get_dtype_size": [
    "dtype"
  ],
  "_get_precision_level": [
    "dtype"
  ],
  "is_lossless_cast": [
    "src_dtype",
    "tgt_dtype"
  ],
  "common_broadcastable_dtype": [
    "dtypes"
  ],
  "_generate_random_fp8": [
    "tensor",
    "low",
    "high"
  ],
  "get_kv_cache_torch_dtype": [
    "cache_dtype",
    "model_dtype"
  ],
  "get_kv_cache_quant_algo_string": [
    "quant_cfg"
  ],
  "get_kv_cache_quant_algo_dtype": [
    "quant_cfg"
  ],
  "resolve_kv_cache_dtype_string": [
    "kv_cache_dtype",
    "model_config"
  ],
  "kv_cache_dtype_str_to_dtype": [
    "kv_cache_dtype",
    "model_config"
  ],
  "set_random_seed": [
    "seed"
  ],
  "create_kv_caches_with_random_flash": [
    "num_blocks",
    "block_size",
    "num_layers",
    "num_heads",
    "head_size",
    "cache_dtype",
    "model_dtype",
    "seed",
    "device",
    "cache_layout"
  ],
  "create_kv_caches_with_random": [
    "num_blocks",
    "block_size",
    "num_layers",
    "num_heads",
    "head_size",
    "cache_dtype",
    "model_dtype",
    "seed",
    "device"
  ],
  "async_tensor_h2d": [
    "data",
    "dtype",
    "target_device",
    "pin_memory"
  ],
  "make_ndarray_with_pad": [
    "x",
    "pad",
    "dtype"
  ],
  "make_tensor_with_pad": [
    "x",
    "pad",
    "dtype"
  ],
  "prev_set_stream": [],
  "_current_stream_tls": [],
  "_patched_set_stream": [
    "stream"
  ],
  "_StreamPlaceholder": {
    "__init__": [
      "self"
    ]
  },
  "current_stream": [],
  "aux_stream": [],
  "_cuda_device_count_stateless": [
    "cuda_visible_devices"
  ],
  "cuda_device_count_stateless": [],
  "weak_ref_tensor": [
    "tensor"
  ],
  "weak_ref_tensors": [
    "tensors"
  ],
  "get_cuda_view_from_cpu_tensor": [
    "cpu_tensor"
  ],
  "_is_torch_equal_or_newer": [
    "torch_version",
    "target"
  ],
  "is_torch_equal_or_newer": [
    "target"
  ],
  "_is_torch_equal": [
    "target"
  ],
  "is_torch_equal": [
    "target"
  ],
  "supports_xccl": [],
  "vllm_lib": [],
  "direct_register_custom_op": [
    "op_name",
    "op_func",
    "mutates_args",
    "fake_impl",
    "target_lib",
    "dispatch_key",
    "tags"
  ],
  "cprofile_context": [
    "save_file"
  ],
  "cprofile": [
    "save_file",
    "enabled"
  ],
  "GCDebugConfig": {
    "__init__": [
      "self",
      "gc_debug_conf"
    ],
    "__repr__": [
      "self"
    ]
  },
  "GCDebugger": {
    "__init__": [
      "self",
      "config"
    ],
    "handle": [
      "self",
      "phase",
      "info"
    ]
  },
  "freeze_gc_heap": [],
  "maybe_attach_gc_debug_callback": [],
  "_compute_detailed_type": [
    "o"
  ],
  "_compute_top_gc_collected_objects": [
    "objects",
    "top"
  ],
  "TensorShape": {
    "__init__": [
      "self"
    ],
    "resolve": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "TensorSchema": {
    "__init__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "_match_shape_with_dynamic": [
      "self",
      "actual",
      "reference",
      "expected_shape",
      "dynamic_dims"
    ],
    "_fmt_indexer": [
      "self",
      "idxs"
    ],
    "_validate_field": [
      "self",
      "value",
      "field_name",
      "expected_shape",
      "dynamic_dims",
      "leading_idxs"
    ],
    "_validate_tensor_shape_expected": [
      "self",
      "actual_shape",
      "expected_shape",
      "field_name",
      "shape_env",
      "dynamic_dims"
    ],
    "validate": [
      "self"
    ],
    "print_shapes": [
      "self"
    ]
  },
  "cuda_is_initialized": [],
  "xpu_is_initialized": [],
  "get_cu_count": [
    "device_id"
  ],
  "cuda_get_device_properties": [
    "device",
    "names",
    "init_cuda"
  ],
  "is_pin_memory_available": [],
  "is_uva_available": [],
  "_K": [],
  "_V": [],
  "_Sentinel": {},
  "ALL_PINNED_SENTINEL": [],
  "_MappingOrderCacheView": {
    "__init__": [
      "self",
      "data",
      "ordered_keys"
    ],
    "__iter__": [
      "self"
    ],
    "keys": [
      "self"
    ]
  },
  "CacheInfo": {
    "hit_ratio": [
      "self"
    ],
    "__sub__": [
      "self",
      "other"
    ]
  },
  "LRUCache": {
    "__init__": [
      "self",
      "capacity",
      "getsizeof"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__delitem__": [
      "self",
      "key"
    ],
    "cache": [
      "self"
    ],
    "order": [
      "self"
    ],
    "capacity": [
      "self"
    ],
    "usage": [
      "self"
    ],
    "stat": [
      "self"
    ],
    "touch": [
      "self",
      "key"
    ],
    "get": [
      "default"
    ],
    "pop": [
      "self",
      "key",
      "default"
    ],
    "put": [
      "self",
      "key",
      "value"
    ],
    "pin": [
      "self",
      "key"
    ],
    "_unpin": [
      "self",
      "key"
    ],
    "_on_remove": [
      "self",
      "key",
      "value"
    ],
    "remove_oldest": [
      "self"
    ],
    "_remove_old_if_needed": [
      "self"
    ],
    "popitem": [
      "self",
      "remove_pinned"
    ],
    "clear": [
      "self"
    ]
  },
  "print_tensor": [
    "tensor_obj",
    "prefix",
    "tensor_list"
  ],
  "process_layer_params": [
    "module_obj"
  ],
  "construct_marker_dict_and_push": [
    "module_name",
    "module_obj",
    "in_tensor",
    "kwargs",
    "out_tensor"
  ],
  "ResultHolder": {
    "result": []
  },
  "layerwise_nvtx_marker_context": [
    "module_name",
    "module_obj",
    "in_tensor",
    "kwargs"
  ],
  "PytHooks": {
    "__init__": [
      "self"
    ],
    "_process_layer_params": [
      "self",
      "module_obj"
    ],
    "module_fwd_hook": [
      "self",
      "module_obj",
      "in_tensor",
      "out_tensor"
    ],
    "module_fwd_pre_hook": [
      "self",
      "module_obj",
      "in_tensor",
      "kwargs"
    ],
    "register_hooks": [
      "self",
      "network_model",
      "module_prefix"
    ]
  },
  "AsyncMicrobatchTokenizer": {
    "__init__": [
      "self",
      "tokenizer",
      "max_batch_size",
      "batch_wait_timeout_s"
    ],
    "__call__": [
      "self",
      "prompt"
    ],
    "decode": [
      "self",
      "token_ids"
    ],
    "_get_queue": [
      "self",
      "loop",
      "key"
    ],
    "_batch_encode_loop": [
      "self",
      "queue",
      "can_batch"
    ],
    "_batch_decode_loop": [
      "self",
      "queue"
    ],
    "_queue_key": [
      "self",
      "op",
      "kwargs"
    ],
    "__del__": [
      "self"
    ]
  },
  "cancel_task_threadsafe": [
    "task"
  ],
  "make_async": [
    "func",
    "executor"
  ],
  "run_in_loop": [
    "loop",
    "function"
  ],
  "in_loop": [
    "event_loop"
  ],
  "merge_async_iterators": [],
  "collect_from_async_generator": [
    "iterator"
  ],
  "MASK_64_BITS": [],
  "random_uuid": [],
  "length_from_prompt_token_ids_or_embeds": [
    "prompt_token_ids",
    "prompt_embeds"
  ],
  "sha256": [
    "input"
  ],
  "sha256_cbor": [
    "input"
  ],
  "_xxhash_digest": [
    "input_bytes"
  ],
  "xxhash": [
    "input"
  ],
  "xxhash_cbor": [
    "input"
  ],
  "get_hash_fn_by_name": [
    "hash_fn_name"
  ],
  "safe_hash": [
    "data",
    "usedforsecurity"
  ],
  "FLASHINFER_CUBINS_REPOSITORY": [],
  "has_flashinfer_cubin": [],
  "has_flashinfer": [],
  "_missing": [],
  "_get_submodule": [
    "module_name"
  ],
  "_lazy_import_wrapper": [
    "module_name",
    "attr_name",
    "fallback_fn"
  ],
  "flashinfer_trtllm_fp8_block_scale_moe": [],
  "flashinfer_trtllm_fp8_per_tensor_scale_moe": [],
  "flashinfer_cutlass_fused_moe": [],
  "flashinfer_cutedsl_grouped_gemm_nt_masked": [],
  "flashinfer_fp4_quantize": [],
  "nvfp4_batched_quantize": [],
  "silu_and_mul_scaled_nvfp4_experts_quantize": [],
  "scaled_fp4_grouped_quantize": [],
  "nvfp4_block_scale_interleave": [],
  "trtllm_fp4_block_scale_moe": [],
  "autotune": [],
  "has_flashinfer_comm": [],
  "has_flashinfer_all2all": [],
  "has_flashinfer_moe": [],
  "has_flashinfer_cutedsl": [],
  "has_flashinfer_trtllm_fused_moe": [],
  "has_flashinfer_cutlass_fused_moe": [],
  "has_flashinfer_cutedsl_grouped_gemm_nt_masked": [],
  "has_nvidia_artifactory": [],
  "supports_trtllm_attention": [],
  "force_use_trtllm_attention": [],
  "can_use_trtllm_attention": [
    "num_qo_heads",
    "num_kv_heads"
  ],
  "use_trtllm_attention": [
    "num_qo_heads",
    "num_kv_heads",
    "num_tokens",
    "max_seq_len",
    "dcp_world_size",
    "kv_cache_dtype",
    "q_dtype",
    "is_prefill",
    "force_use_trtllm",
    "has_sinks",
    "has_spec"
  ],
  "flashinfer_scaled_fp4_mm": [
    "a",
    "b",
    "block_scale_a",
    "block_scale_b",
    "alpha",
    "out_dtype",
    "backend"
  ],
  "flashinfer_scaled_fp8_mm": [
    "a",
    "b",
    "scale_a",
    "scale_b",
    "out_dtype",
    "bias"
  ],
  "flashinfer_quant_nvfp4_8x4_sf_layout": [
    "a",
    "a_global_sf"
  ],
  "flashinfer_fp8_blockscale_gemm": [],
  "has_flashinfer_fp8_blockscale_gemm": [],
  "is_flashinfer_fp8_blockscale_gemm_supported": [],
  "should_use_flashinfer_for_blockscale_fp8_gemm": [
    "is_flashinfer_supported",
    "output_dtype",
    "input",
    "weight"
  ],
  "import_pynvml": [],
  "import_triton_kernels": [],
  "import_from_path": [
    "module_name",
    "file_path"
  ],
  "resolve_obj_by_qualname": [
    "qualname"
  ],
  "get_vllm_optional_dependencies": [],
  "_PlaceholderBase": {
    "__getattr__": [
      "self",
      "key"
    ],
    "__lt__": [
      "self",
      "other"
    ],
    "__le__": [
      "self",
      "other"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__ne__": [
      "self",
      "other"
    ],
    "__gt__": [
      "self",
      "other"
    ],
    "__ge__": [
      "self",
      "other"
    ],
    "__hash__": [
      "self"
    ],
    "__bool__": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "__delitem__": [
      "self",
      "key"
    ],
    "__add__": [
      "self",
      "other"
    ],
    "__sub__": [
      "self",
      "other"
    ],
    "__mul__": [
      "self",
      "other"
    ],
    "__matmul__": [
      "self",
      "other"
    ],
    "__truediv__": [
      "self",
      "other"
    ],
    "__floordiv__": [
      "self",
      "other"
    ],
    "__mod__": [
      "self",
      "other"
    ],
    "__divmod__": [
      "self",
      "other"
    ],
    "__pow__": [
      "self",
      "other",
      "modulo"
    ],
    "__lshift__": [
      "self",
      "other"
    ],
    "__rshift__": [
      "self",
      "other"
    ],
    "__and__": [
      "self",
      "other"
    ],
    "__xor__": [
      "self",
      "other"
    ],
    "__or__": [
      "self",
      "other"
    ],
    "__neg__": [
      "self"
    ],
    "__pos__": [
      "self"
    ],
    "__abs__": [
      "self"
    ],
    "__invert__": [
      "self"
    ],
    "__index__": [
      "self"
    ],
    "__round__": [
      "self",
      "ndigits"
    ],
    "__trunc__": [
      "self"
    ],
    "__floor__": [
      "self"
    ],
    "__ceil__": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "PlaceholderModule": {
    "__init__": [
      "self",
      "name"
    ],
    "placeholder_attr": [
      "self",
      "attr_path"
    ],
    "__getattr__": [
      "self",
      "key"
    ]
  },
  "_PlaceholderModuleAttr": {
    "__init__": [
      "self",
      "module",
      "attr_path"
    ],
    "placeholder_attr": [
      "self",
      "attr_path"
    ],
    "__getattr__": [
      "self",
      "key"
    ]
  },
  "LazyLoader": {
    "__init__": [
      "self",
      "local_name",
      "parent_module_globals",
      "name"
    ],
    "_load": [
      "self"
    ],
    "__getattr__": [
      "self",
      "item"
    ],
    "__dir__": [
      "self"
    ]
  },
  "_has_module": [
    "module_name"
  ],
  "has_pplx": [],
  "has_deep_ep": [],
  "has_deep_gemm": [],
  "has_triton_kernels": [],
  "has_tilelang": [],
  "has_arctic_inference": [],
  "has_helion": [],
  "has_aiter": [],
  "has_mori": [],
  "sys_byteorder": [],
  "EMBED_DTYPE_TO_TORCH_DTYPE": [],
  "EMBED_DTYPE_TO_N_BYTES": [],
  "EMBED_DTYPE_TO_TORCH_DTYPE_VIEW": [],
  "EMBED_DTYPE_TO_NUMPY_DTYPE_VIEW": [],
  "ENDIANNESS": [],
  "EmbedDType": [],
  "Endianness": [],
  "EncodingFormat": [],
  "tensor2base64": [
    "x"
  ],
  "tensor2binary": [
    "tensor",
    "embed_dtype",
    "endianness"
  ],
  "binary2tensor": [
    "binary",
    "shape",
    "embed_dtype",
    "endianness"
  ],
  "encode_pooling_output": [
    "output",
    "encoding_format",
    "embed_dtype",
    "endianness"
  ],
  "MetadataItem": {},
  "build_metadata_items": [
    "embed_dtype",
    "endianness",
    "shape",
    "n_request"
  ],
  "encode_pooling_bytes": [
    "pooling_outputs",
    "embed_dtype",
    "endianness"
  ],
  "decode_pooling_output": [
    "items",
    "body"
  ],
  "Counter": {
    "__init__": [
      "self",
      "start"
    ],
    "__next__": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "AtomicCounter": {
    "__init__": [
      "self",
      "initial"
    ],
    "value": [
      "self"
    ],
    "inc": [
      "self",
      "num"
    ],
    "dec": [
      "self",
      "num"
    ]
  },
  "MB_bytes": [],
  "MiB_bytes": [],
  "GB_bytes": [],
  "GiB_bytes": [],
  "RCP_LN2": [],
  "cdiv": [
    "a",
    "b"
  ],
  "next_power_of_2": [
    "n"
  ],
  "prev_power_of_2": [
    "n"
  ],
  "round_up": [
    "x",
    "y"
  ],
  "round_down": [
    "x",
    "y"
  ],
  "CYAN": [],
  "RESET": [],
  "update_environment_variables": [
    "envs_dict"
  ],
  "set_env_var": [
    "key",
    "value"
  ],
  "suppress_stdout": [],
  "unique_filepath": [
    "fn"
  ],
  "_maybe_force_spawn": [],
  "get_mp_context": [],
  "set_process_title": [
    "name",
    "suffix",
    "prefix"
  ],
  "_add_prefix": [
    "file",
    "worker_name",
    "pid"
  ],
  "decorate_logs": [
    "process_name"
  ],
  "kill_process_tree": [
    "pid"
  ],
  "set_ulimit": [
    "target_soft_limit"
  ],
  "find_loaded_library": [
    "lib_name"
  ],
  "DeepGemmQuantScaleFMT": {
    "FLOAT32": [],
    "FLOAT32_CEIL_UE8M0": [],
    "UE8M0": [],
    "init_oracle_cache": [
      "cls"
    ],
    "from_oracle": [
      "cls"
    ]
  },
  "is_deep_gemm_supported": [],
  "is_deep_gemm_e8m0_used": [],
  "_lazy_init": [],
  "get_num_sms": [],
  "get_mk_alignment_for_contiguous_layout": [],
  "get_col_major_tma_aligned_tensor": [
    "x"
  ],
  "fp8_gemm_nt": [],
  "m_grouped_fp8_gemm_nt_contiguous": [],
  "fp8_m_grouped_gemm_nt_masked": [],
  "transform_sf_into_required_layout": [],
  "fp8_mqa_logits": [
    "q",
    "kv",
    "weights",
    "cu_seqlen_ks",
    "cu_seqlen_ke"
  ],
  "get_paged_mqa_logits_metadata": [
    "context_lens",
    "block_size",
    "num_sms"
  ],
  "fp8_paged_mqa_logits": [
    "q_fp8",
    "kv_cache_fp8",
    "weights",
    "context_lens",
    "block_tables",
    "schedule_metadata",
    "max_model_len"
  ],
  "_ceil_to_ue8m0": [
    "x"
  ],
  "_align": [
    "x",
    "y"
  ],
  "get_tma_aligned_size": [
    "x",
    "element_size"
  ],
  "DEFAULT_BLOCK_SIZE": [],
  "per_block_cast_to_fp8": [
    "x",
    "block_size",
    "use_ue8m0"
  ],
  "calc_diff": [
    "x",
    "y"
  ],
  "should_use_deepgemm_for_fp8_linear": [
    "output_dtype",
    "weight",
    "supports_deep_gemm"
  ],
  "close_sockets": [
    "sockets"
  ],
  "get_ip": [],
  "test_loopback_bind": [
    "address",
    "family"
  ],
  "get_loopback_ip": [],
  "is_valid_ipv6_address": [
    "address"
  ],
  "split_host_port": [
    "host_port"
  ],
  "join_host_port": [
    "host",
    "port"
  ],
  "get_distributed_init_method": [
    "ip",
    "port"
  ],
  "get_tcp_uri": [
    "ip",
    "port"
  ],
  "get_open_zmq_ipc_path": [],
  "get_open_zmq_inproc_path": [],
  "get_open_port": [],
  "get_open_ports_list": [
    "count"
  ],
  "_get_open_port": [],
  "find_process_using_port": [
    "port"
  ],
  "split_zmq_path": [
    "path"
  ],
  "make_zmq_path": [
    "scheme",
    "host",
    "port"
  ],
  "make_zmq_socket": [
    "ctx",
    "path",
    "socket_type",
    "bind",
    "identity",
    "linger"
  ],
  "zmq_socket_ctx": [
    "path",
    "socket_type",
    "bind",
    "linger",
    "identity"
  ],
  "LazyDict": {
    "__init__": [
      "self",
      "factory"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "as_list": [
    "maybe_list"
  ],
  "as_iter": [
    "obj"
  ],
  "is_list_of": [
    "value",
    "typ"
  ],
  "common_prefix": [
    "items"
  ],
  "chunk_list": [
    "lst",
    "chunk_size"
  ],
  "flatten_2d_lists": [
    "lists"
  ],
  "full_groupby": [
    "values"
  ],
  "swap_dict_values": [
    "obj",
    "key1",
    "key2"
  ],
  "ExtensionManager": {
    "__init__": [
      "self"
    ],
    "register": [
      "self",
      "name"
    ],
    "load": [
      "self",
      "cls_name"
    ]
  },
  "_U": [],
  "json_iter_leaves": [
    "value"
  ],
  "json_map_leaves": [
    "func",
    "value"
  ],
  "json_reduce_leaves": [],
  "json_count_leaves": [
    "value"
  ],
  "F": [],
  "identity": [
    "value"
  ],
  "run_once": [
    "f"
  ],
  "deprecate_args": [
    "start_index",
    "is_deprecated",
    "additional_message"
  ],
  "deprecate_kwargs": [],
  "supports_kw": [
    "callable",
    "kw_name"
  ],
  "get_allowed_kwarg_only_overrides": [
    "callable",
    "overrides"
  ],
  "find_nccl_library": [],
  "find_nccl_include_paths": [],
  "safe_apply_chat_template": [
    "tokenizer",
    "messages"
  ],
  "MistralRenderer": {
    "from_config": [
      "cls",
      "config",
      "tokenizer_kwargs"
    ],
    "__init__": [
      "self",
      "config",
      "tokenizer_kwargs"
    ],
    "tokenizer": [
      "self"
    ],
    "get_tokenizer": [
      "self"
    ],
    "render_messages": [
      "self",
      "messages"
    ],
    "render_messages_async": [
      "self",
      "messages"
    ]
  },
  "_PROCESSOR_CHAT_TEMPLATES": [],
  "_try_get_processor_chat_template": [
    "tokenizer"
  ],
  "resolve_chat_template": [
    "tokenizer",
    "chat_template",
    "tools"
  ],
  "_is_var_access": [
    "node",
    "varname"
  ],
  "_is_attr_access": [
    "node",
    "varname",
    "key"
  ],
  "_is_var_or_elems_access": [
    "node",
    "varname",
    "key"
  ],
  "_iter_nodes_assign_var_or_elems": [
    "root",
    "varname"
  ],
  "_iter_nodes_assign_messages_item": [
    "root"
  ],
  "_iter_nodes_assign_content_item": [
    "root"
  ],
  "_try_extract_ast": [
    "chat_template"
  ],
  "_detect_content_format": [
    "chat_template"
  ],
  "_resolve_chat_template_content_format": [
    "chat_template",
    "tools",
    "tokenizer"
  ],
  "_log_chat_template_content_format": [
    "chat_template",
    "given_format",
    "detected_format"
  ],
  "resolve_chat_template_content_format": [
    "chat_template",
    "tools",
    "given_format",
    "tokenizer"
  ],
  "AssistantTracker": {
    "tags": [],
    "parse": [
      "self",
      "parser"
    ]
  },
  "_resolve_chat_template_kwargs": [
    "chat_template"
  ],
  "_cached_resolve_chat_template_kwargs": [],
  "_get_hf_base_chat_template_params": [],
  "resolve_chat_template_kwargs": [
    "tokenizer",
    "chat_template",
    "chat_template_kwargs",
    "raise_on_unexpected"
  ],
  "HfRenderer": {
    "from_config": [
      "cls",
      "config",
      "tokenizer_kwargs"
    ],
    "__init__": [
      "self",
      "config",
      "tokenizer_kwargs"
    ],
    "tokenizer": [
      "self"
    ],
    "get_tokenizer": [
      "self"
    ],
    "render_messages": [
      "self",
      "messages",
      "chat_template_content_format"
    ],
    "render_messages_async": [
      "self",
      "messages",
      "chat_template_content_format"
    ]
  },
  "RendererLike": {
    "from_config": [
      "cls",
      "config",
      "tokenizer_kwargs"
    ],
    "tokenizer": [
      "self"
    ],
    "get_tokenizer": [
      "self"
    ],
    "render_messages": [
      "self",
      "messages"
    ],
    "render_messages_async": [
      "self",
      "messages"
    ]
  },
  "DeepseekV32Renderer": {
    "from_config": [
      "cls",
      "config",
      "tokenizer_kwargs"
    ],
    "__init__": [
      "self",
      "config",
      "tokenizer_kwargs"
    ],
    "tokenizer": [
      "self"
    ],
    "get_tokenizer": [
      "self"
    ],
    "render_messages": [
      "self",
      "messages"
    ],
    "render_messages_async": [
      "self",
      "messages"
    ]
  },
  "TerratorchRenderer": {
    "from_config": [
      "cls",
      "config",
      "tokenizer_kwargs"
    ],
    "__init__": [
      "self",
      "config"
    ],
    "tokenizer": [
      "self"
    ],
    "get_tokenizer": [
      "self"
    ],
    "render_messages": [
      "self",
      "messages"
    ],
    "render_messages_async": [
      "self",
      "messages"
    ]
  },
  "_VLLM_RENDERERS": [],
  "RendererRegistry": {
    "register": [
      "self",
      "renderer_mode",
      "module",
      "class_name"
    ],
    "load_renderer_cls": [
      "self",
      "renderer_mode"
    ],
    "load_renderer": [
      "self",
      "renderer_mode",
      "config",
      "tokenizer_kwargs"
    ]
  },
  "RENDERER_REGISTRY": [],
  "renderer_from_config": [
    "config"
  ],
  "Grok2Renderer": {
    "from_config": [
      "cls",
      "config",
      "tokenizer_kwargs"
    ],
    "__init__": [
      "self",
      "config",
      "tokenizer_kwargs"
    ],
    "tokenizer": [
      "self"
    ],
    "get_tokenizer": [
      "self"
    ],
    "render_messages": [
      "self",
      "messages"
    ],
    "render_messages_async": [
      "self",
      "messages"
    ]
  },
  "_config_home": [],
  "_USAGE_STATS_JSON_PATH": [],
  "_USAGE_STATS_DO_NOT_TRACK_PATH": [],
  "_USAGE_STATS_ENABLED": [],
  "_USAGE_STATS_SERVER": [],
  "_GLOBAL_RUNTIME_DATA": [],
  "_USAGE_ENV_VARS_TO_COLLECT": [],
  "set_runtime_usage_data": [
    "key",
    "value"
  ],
  "is_usage_stats_enabled": [],
  "_get_current_timestamp_ns": [],
  "_detect_cloud_provider": [],
  "UsageContext": {
    "UNKNOWN_CONTEXT": [],
    "LLM_CLASS": [],
    "API_SERVER": [],
    "OPENAI_API_SERVER": [],
    "OPENAI_BATCH_RUNNER": [],
    "ENGINE_CONTEXT": []
  },
  "UsageMessage": {
    "__init__": [
      "self"
    ],
    "report_usage": [
      "self",
      "model_architecture",
      "usage_context",
      "extra_kvs"
    ],
    "_report_usage_worker": [
      "self",
      "model_architecture",
      "usage_context",
      "extra_kvs"
    ],
    "_report_tpu_inference_usage": [
      "self"
    ],
    "_report_usage_once": [
      "self",
      "model_architecture",
      "usage_context",
      "extra_kvs"
    ],
    "_report_continuous_usage": [
      "self"
    ],
    "_send_to_server": [
      "self",
      "data"
    ],
    "_write_to_file": [
      "self",
      "data"
    ]
  },
  "usage_message": [],
  "compute_retained_tokens_count": [
    "tokens_per_frame",
    "num_frames",
    "q"
  ],
  "compute_retention_mask": [
    "video_embeds",
    "video_size_thw",
    "spatial_merge_size",
    "q"
  ],
  "compute_mrope_for_media": [
    "video_size_thw",
    "spatial_merge_size",
    "tokens_per_second",
    "video_second_per_grid"
  ],
  "recompute_mrope_positions": [
    "input_ids",
    "multimodal_positions",
    "mrope_positions",
    "num_computed_tokens",
    "vision_start_token_id",
    "image_token_id",
    "video_token_id"
  ],
  "ModalityDataItems": {
    "__init__": [
      "self",
      "data",
      "modality"
    ],
    "__repr__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "get_count": [
      "self"
    ],
    "get": [
      "self",
      "index"
    ],
    "get_all": [
      "self"
    ],
    "get_item_for_hash": [
      "self",
      "index"
    ],
    "get_all_items_for_hash": [
      "self"
    ],
    "get_processor_data": [
      "self"
    ],
    "get_passthrough_data": [
      "self"
    ]
  },
  "ProcessorBatchItems": {
    "_unwrap": [
      "self",
      "item"
    ],
    "get_count": [
      "self"
    ],
    "get": [
      "self",
      "index"
    ],
    "get_item_for_hash": [
      "self",
      "index"
    ],
    "get_processor_data": [
      "self"
    ],
    "get_passthrough_data": [
      "self"
    ]
  },
  "validate_embedding_ndim": [
    "tensor",
    "modality",
    "index"
  ],
  "EmbeddingItems": {
    "__init__": [
      "self",
      "data",
      "modality",
      "expected_hidden_size"
    ],
    "_validate_ndim": [
      "self"
    ],
    "_validate_hidden_size": [
      "self",
      "expected_hidden_size"
    ],
    "_unwrap": [
      "self",
      "item"
    ],
    "get_count": [
      "self"
    ],
    "get": [
      "self",
      "index"
    ],
    "get_processor_data": [
      "self"
    ],
    "get_passthrough_data": [
      "self"
    ],
    "get_feature_size": [
      "self",
      "item_idx"
    ]
  },
  "DictEmbeddingItems": {
    "__init__": [
      "self",
      "data",
      "modality",
      "required_fields",
      "fields_factory"
    ],
    "get_count": [
      "self"
    ],
    "get": [
      "self",
      "index"
    ],
    "get_processor_data": [
      "self"
    ],
    "get_passthrough_data": [
      "self"
    ]
  },
  "AudioProcessorItems": {
    "__init__": [
      "self",
      "data"
    ],
    "get_audio_length": [
      "self",
      "item_idx"
    ]
  },
  "AudioEmbeddingItems": {
    "__init__": [
      "self",
      "data",
      "expected_hidden_size"
    ]
  },
  "ImageSize": {},
  "ImageProcessorItems": {
    "__init__": [
      "self",
      "data"
    ],
    "get_image_size": [
      "self",
      "item_idx"
    ]
  },
  "ImageEmbeddingItems": {
    "__init__": [
      "self",
      "data",
      "expected_hidden_size"
    ]
  },
  "VideoProcessorItems": {
    "__init__": [
      "self",
      "data",
      "metadata"
    ],
    "get_num_frames": [
      "self",
      "item_idx"
    ],
    "get_frame_size": [
      "self",
      "item_idx"
    ]
  },
  "VideoEmbeddingItems": {
    "__init__": [
      "self",
      "data",
      "expected_hidden_size"
    ]
  },
  "VisionChunkProcessorItems": {
    "__init__": [
      "self",
      "data"
    ]
  },
  "_D": [],
  "MultiModalDataItems": {
    "get_count": [
      "self",
      "modality"
    ],
    "get_all_counts": [
      "self"
    ],
    "get_items": [
      "self",
      "modality",
      "typ"
    ]
  },
  "MultiModalDataParser": {
    "__init__": [
      "self"
    ],
    "is_embeddings": [
      "cls",
      "data"
    ],
    "_is_empty": [
      "self",
      "data"
    ],
    "_get_audio_with_sr": [
      "self",
      "audio"
    ],
    "_get_video_with_metadata": [
      "self",
      "video"
    ],
    "_parse_audio_data": [
      "self",
      "data"
    ],
    "_parse_image_data": [
      "self",
      "data"
    ],
    "_parse_video_data": [
      "self",
      "data"
    ],
    "_parse_vision_chunk_data": [
      "self",
      "data"
    ],
    "_get_subparsers": [
      "self"
    ],
    "parse_mm_data": [
      "self",
      "mm_data"
    ]
  },
  "VisionChunkImage": {},
  "VisionChunkVideo": {},
  "VisionChunk": [],
  "MultiModalDataBuiltins": {},
  "PlaceholderRange": {
    "embeds_cumsum": [
      "self"
    ],
    "get_num_embeds": [
      "self"
    ],
    "get_embeds_indices_in_range": [
      "self",
      "start_idx",
      "end_idx"
    ],
    "extract_embeds_range": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ]
  },
  "nested_tensors_equal": [
    "a",
    "b"
  ],
  "_nested_tensors_h2d": [
    "tensors",
    "device"
  ],
  "batched_tensors_equal": [
    "a",
    "b"
  ],
  "MultiModalFeatureSpec": {
    "gather_kwargs": [
      "features",
      "keys"
    ]
  },
  "MultiModalFieldElem": {
    "__eq__": [
      "self",
      "other"
    ]
  },
  "BaseMultiModalField": {
    "_field_factory": [
      "self"
    ],
    "build_elems": [
      "self",
      "modality",
      "key",
      "data"
    ],
    "_reduce_data": [
      "self",
      "batch"
    ],
    "reduce_data": [
      "self",
      "elems"
    ]
  },
  "MultiModalBatchedField": {
    "build_elems": [
      "self",
      "modality",
      "key",
      "data"
    ],
    "_reduce_data": [
      "self",
      "batch"
    ]
  },
  "MultiModalFlatField": {
    "build_elems": [
      "self",
      "modality",
      "key",
      "data"
    ],
    "_reduce_data": [
      "self",
      "batch"
    ]
  },
  "MultiModalSharedField": {
    "build_elems": [
      "self",
      "modality",
      "key",
      "data"
    ],
    "_reduce_data": [
      "self",
      "batch"
    ]
  },
  "MultiModalFieldConfig": {
    "batched": [
      "modality"
    ],
    "flat": [
      "modality",
      "slices",
      "dim"
    ],
    "flat_from_sizes": [
      "modality",
      "size_per_item",
      "dim"
    ],
    "shared": [
      "modality",
      "batch_size"
    ],
    "build_elems": [
      "self",
      "key",
      "batch"
    ]
  },
  "MultiModalKwargsItem": {
    "dummy": [
      "modality",
      "nbytes"
    ],
    "from_elems": [
      "elems"
    ],
    "__init__": [
      "self",
      "data"
    ],
    "modality": [
      "self"
    ],
    "get_data": [
      "self"
    ]
  },
  "MultiModalKwargsItems": {
    "from_hf_inputs": [
      "hf_inputs",
      "config_by_key"
    ],
    "from_seq": [
      "items"
    ],
    "__getitem__": [
      "self",
      "modality"
    ],
    "require_data": [
      "self"
    ],
    "get_data": [
      "self"
    ]
  },
  "MultiModalHashes": [],
  "MultiModalInputs": {},
  "MultiModalEncDecInputs": {},
  "ChannelReduction": {
    "MEAN": [],
    "FIRST": [],
    "MAX": [],
    "SUM": []
  },
  "AudioSpec": {
    "needs_normalization": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "MONO_AUDIO_SPEC": [],
  "PASSTHROUGH_AUDIO_SPEC": [],
  "normalize_audio": [
    "audio",
    "spec"
  ],
  "resample_audio_librosa": [
    "audio"
  ],
  "resample_audio_scipy": [
    "audio"
  ],
  "AudioResampler": {
    "__init__": [
      "self",
      "target_sr",
      "method"
    ],
    "resample": [
      "self",
      "audio"
    ]
  },
  "resize_video": [
    "frames",
    "size"
  ],
  "rescale_video_size": [
    "frames",
    "size_factor"
  ],
  "sample_frames_from_video": [
    "frames",
    "num_frames"
  ],
  "VideoLoader": {
    "load_bytes": [
      "cls",
      "data",
      "num_frames"
    ],
    "_can_use_for_recovery": [
      "idx",
      "failed_frames",
      "next_target_map",
      "total_frames"
    ],
    "_read_frames_with_recovery": [
      "cap",
      "frame_indices",
      "total_frames"
    ],
    "_read_frames": [
      "cap",
      "frame_indices",
      "num_expected_frames",
      "max_frame_idx"
    ]
  },
  "VIDEO_LOADER_REGISTRY": [],
  "IdentityVideoLoader": {
    "load_bytes": [
      "cls",
      "data",
      "num_frames"
    ]
  },
  "OpenCVVideoBackend": {
    "get_cv2_video_api": [
      "self"
    ],
    "load_bytes": [
      "cls",
      "data",
      "num_frames",
      "fps",
      "max_duration",
      "frame_recovery"
    ]
  },
  "OpenCVDynamicVideoBackend": {
    "load_bytes": [
      "cls",
      "data",
      "num_frames",
      "fps",
      "max_duration",
      "frame_recovery"
    ]
  },
  "Molmo2VideoBackend": {
    "get_cv2_video_api": [
      "self"
    ],
    "get_candidate_target_fps": [
      "cls",
      "video_fps",
      "sampling_fps",
      "max_fps"
    ],
    "get_target_fps": [
      "cls",
      "video_fps",
      "max_frames",
      "total_frames",
      "frame_sample_mode",
      "candidate_target_fps"
    ],
    "get_frame_times_and_chosen_fps": [
      "cls",
      "selected_target_fps",
      "total_frames",
      "max_frames",
      "video_fps"
    ],
    "sample_times": [
      "cls",
      "duration",
      "max_frames",
      "frame_sample_mode",
      "max_fps",
      "candidate_target_fps"
    ],
    "_sample_frames": [
      "cls",
      "total_num_frames",
      "video_fps",
      "duration",
      "frame_sample_mode",
      "num_frames",
      "max_fps",
      "sampling_fps"
    ],
    "load_bytes_opencv": [
      "cls",
      "data",
      "frame_sample_mode",
      "num_frames",
      "max_fps",
      "sampling_fps"
    ],
    "load_bytes": [
      "cls",
      "data",
      "num_frames"
    ]
  },
  "MultiModalProcessorCacheItem": {
    "__init__": [
      "self",
      "item",
      "prompt_updates"
    ]
  },
  "MultiModalProcessorCacheItemMetadata": {
    "__init__": [
      "self",
      "item",
      "prompt_updates"
    ]
  },
  "MultiModalCache": {
    "get_leaf_size": [
      "cls",
      "leaf"
    ],
    "get_item_size": [
      "cls",
      "value"
    ],
    "get_item_complexity": [
      "cls",
      "value"
    ],
    "get_lru_cache": [
      "cls",
      "capacity_gb",
      "value_type"
    ]
  },
  "BaseMultiModalCache": {
    "get_and_update_item": [
      "self",
      "mm_item",
      "mm_hash"
    ],
    "get_and_update": [
      "self",
      "mm_items",
      "mm_hashes"
    ],
    "clear_cache": [
      "self"
    ]
  },
  "BaseMultiModalProcessorCache": {
    "is_cached_item": [
      "self",
      "mm_hash"
    ],
    "is_cached": [
      "self",
      "mm_hashes"
    ],
    "close": [
      "self"
    ],
    "touch_sender_cache_item": [
      "self",
      "mm_hash"
    ],
    "make_stats": [
      "self"
    ]
  },
  "MultiModalProcessorOnlyCache": {
    "__init__": [
      "self",
      "model_config"
    ],
    "is_cached_item": [
      "self",
      "mm_hash"
    ],
    "get_and_update_item": [
      "self",
      "mm_item",
      "mm_hash"
    ],
    "touch_sender_cache_item": [
      "self",
      "mm_hash"
    ],
    "clear_cache": [
      "self"
    ],
    "make_stats": [
      "self"
    ]
  },
  "MultiModalProcessorSenderCache": {
    "__init__": [
      "self",
      "model_config"
    ],
    "is_cached_item": [
      "self",
      "mm_hash"
    ],
    "get_and_update_item": [
      "self",
      "mm_item",
      "mm_hash"
    ],
    "touch_sender_cache_item": [
      "self",
      "mm_hash"
    ],
    "clear_cache": [
      "self"
    ],
    "make_stats": [
      "self"
    ]
  },
  "ShmObjectStoreSenderCache": {
    "__init__": [
      "self",
      "vllm_config"
    ],
    "_stat": [
      "self"
    ],
    "is_cached_item": [
      "self",
      "mm_hash"
    ],
    "get_and_update_item": [
      "self",
      "mm_item",
      "mm_hash"
    ],
    "touch_sender_cache_item": [
      "self",
      "mm_hash"
    ],
    "clear_cache": [
      "self"
    ],
    "make_stats": [
      "self"
    ],
    "close": [
      "self"
    ],
    "remove_dangling_items": [
      "self"
    ],
    "address_as_item": [
      "self",
      "address",
      "monotonic_id",
      "modality"
    ]
  },
  "BaseMultiModalReceiverCache": {
    "get_and_update_features": [
      "self",
      "mm_features"
    ],
    "touch_receiver_cache_item": [
      "self",
      "mm_hash",
      "mm_item"
    ]
  },
  "MultiModalReceiverCache": {
    "__init__": [
      "self",
      "model_config"
    ],
    "get_and_update_item": [
      "self",
      "mm_item",
      "mm_hash"
    ],
    "touch_receiver_cache_item": [
      "self",
      "mm_hash",
      "mm_item"
    ],
    "clear_cache": [
      "self"
    ]
  },
  "ShmObjectStoreReceiverCache": {
    "__init__": [
      "self",
      "vllm_config",
      "shared_worker_lock"
    ],
    "get_and_update_item": [
      "self",
      "mm_item",
      "mm_hash"
    ],
    "touch_receiver_cache_item": [
      "self",
      "mm_hash",
      "mm_item"
    ],
    "clear_cache": [
      "self"
    ]
  },
  "global_thread_pool": [],
  "_M": [],
  "MEDIA_CONNECTOR_REGISTRY": [],
  "MediaConnector": {
    "__init__": [
      "self",
      "media_io_kwargs",
      "connection"
    ],
    "_load_data_url": [
      "self",
      "url_spec",
      "media_io"
    ],
    "_load_file_url": [
      "self",
      "url_spec",
      "media_io"
    ],
    "_assert_url_in_allowed_media_domains": [
      "self",
      "url_spec"
    ],
    "load_from_url": [
      "self",
      "url",
      "media_io"
    ],
    "load_from_url_async": [
      "self",
      "url",
      "media_io"
    ],
    "fetch_audio": [
      "self",
      "audio_url"
    ],
    "fetch_audio_async": [
      "self",
      "audio_url"
    ],
    "fetch_image": [
      "self",
      "image_url"
    ],
    "fetch_image_async": [
      "self",
      "image_url"
    ],
    "fetch_video": [
      "self",
      "video_url"
    ],
    "fetch_video_async": [
      "self",
      "video_url"
    ],
    "fetch_image_embedding": [
      "self",
      "data"
    ],
    "fetch_audio_embedding": [
      "self",
      "data"
    ]
  },
  "encode_audio_base64": [
    "audio",
    "sampling_rate"
  ],
  "encode_audio_url": [
    "audio",
    "sampling_rate"
  ],
  "encode_image_base64": [
    "image"
  ],
  "encode_image_url": [
    "image"
  ],
  "encode_video_base64": [
    "frames"
  ],
  "encode_video_url": [
    "frames"
  ],
  "argsort_mm_positions": [
    "mm_positions"
  ],
  "group_mm_kwargs_by_modality": [
    "mm_kwargs"
  ],
  "fetch_audio": [
    "audio_url",
    "audio_io_kwargs"
  ],
  "fetch_image": [
    "image_url",
    "image_io_kwargs"
  ],
  "fetch_video": [
    "video_url",
    "video_io_kwargs"
  ],
  "_get_hasher_factory": [
    "algorithm"
  ],
  "MultiModalHasher": {
    "serialize_item": [
      "cls",
      "obj"
    ],
    "iter_item_to_bytes": [
      "cls",
      "key",
      "obj"
    ],
    "hash_kwargs": [
      "cls"
    ]
  },
  "MULTIMODAL_REGISTRY": [],
  "rescale_image_size": [
    "image",
    "size_factor",
    "transpose"
  ],
  "rgba_to_rgb": [
    "image",
    "background_color"
  ],
  "convert_image_mode": [
    "image",
    "to_mode"
  ],
  "N": [],
  "_I_co": [],
  "ProcessingInfoFactory": {
    "__call__": [
      "self",
      "ctx"
    ]
  },
  "DummyInputsBuilderFactory": {
    "__call__": [
      "self",
      "info"
    ]
  },
  "MultiModalProcessorFactory": {
    "__call__": [
      "self",
      "info",
      "dummy_inputs"
    ]
  },
  "_ProcessorFactories": {
    "build_processor": [
      "self",
      "ctx"
    ]
  },
  "MultiModalRegistry": {
    "_extract_mm_options": [
      "self",
      "model_config"
    ],
    "supports_multimodal_inputs": [
      "self",
      "model_config"
    ],
    "get_max_tokens_per_item_by_modality": [
      "self",
      "model_config"
    ],
    "get_mm_limits_per_prompt": [
      "self",
      "model_config"
    ],
    "register_processor": [
      "self",
      "processor"
    ],
    "_get_model_cls": [
      "self",
      "model_config"
    ],
    "_create_processing_ctx": [
      "self",
      "model_config",
      "observability_config",
      "tokenizer"
    ],
    "_create_processing_info": [
      "self",
      "model_config",
      "observability_config"
    ],
    "create_processor": [
      "self",
      "model_config",
      "observability_config"
    ],
    "get_dummy_mm_inputs": [
      "self",
      "model_config",
      "mm_counts"
    ],
    "get_encdec_max_encoder_len": [
      "self",
      "model_config"
    ],
    "_get_cache_type": [
      "self",
      "vllm_config"
    ],
    "processor_cache_from_config": [
      "self",
      "vllm_config"
    ],
    "processor_only_cache_from_config": [
      "self",
      "vllm_config"
    ],
    "engine_receiver_cache_from_config": [
      "self",
      "vllm_config"
    ],
    "worker_receiver_cache_from_config": [
      "self",
      "vllm_config",
      "shared_worker_lock"
    ]
  },
  "ProcessorInputs": {},
  "BaseDummyInputsBuilder": {
    "__init__": [
      "self",
      "info"
    ],
    "get_dummy_text": [
      "self",
      "mm_counts"
    ],
    "get_dummy_mm_data": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ],
    "get_dummy_processor_inputs": [
      "self",
      "seq_len",
      "mm_counts",
      "mm_options"
    ],
    "_get_dummy_audios": [
      "self"
    ],
    "_get_dummy_images": [
      "self"
    ],
    "_get_dummy_videos": [
      "self"
    ]
  },
  "_S": [],
  "_cached_encode": [
    "tokenizer",
    "text"
  ],
  "_cached_decode": [
    "tokenizer",
    "token_ids"
  ],
  "_seq2text": [
    "tokenizer",
    "seq"
  ],
  "_seq2tokens": [
    "tokenizer",
    "seq"
  ],
  "_GetMatchIndex": {
    "__call__": [
      "self",
      "tokenizer",
      "prompt",
      "start_idx"
    ]
  },
  "PromptIndex": {},
  "PromptIndexTargets": {
    "start": [],
    "prefix": [
      "seq"
    ],
    "end": []
  },
  "PromptUpdateDetails": {
    "from_seq": [
      "seq"
    ],
    "select_text": [
      "seq",
      "embed_text"
    ],
    "select_token_id": [
      "seq",
      "embed_token_id"
    ],
    "select_token_ids": [
      "seq",
      "embed_token_ids"
    ]
  },
  "UpdateMode": {
    "INSERT": [],
    "REPLACE": []
  },
  "PromptUpdate": {
    "content": [
      "self"
    ],
    "mode": [
      "self"
    ],
    "_resolve_target": [
      "self",
      "item_idx"
    ],
    "_resolve_content": [
      "self",
      "item_idx"
    ],
    "resolve": [
      "self",
      "item_idx"
    ]
  },
  "PromptInsertion": {
    "content": [
      "self"
    ],
    "mode": [
      "self"
    ]
  },
  "PromptReplacement": {
    "content": [
      "self"
    ],
    "mode": [
      "self"
    ]
  },
  "_HasModalityAttr": {},
  "_HasModalityProp": {
    "modality": [
      "self"
    ]
  },
  "full_groupby_modality": [
    "values"
  ],
  "PromptTargetMatch": {},
  "ResolvedPromptUpdate": {
    "iter_token_matches": [
      "self",
      "prompt",
      "tokenizer"
    ],
    "iter_text_matches": [
      "self",
      "prompt",
      "tokenizer"
    ],
    "iter_matches": [
      "self",
      "prompt",
      "tokenizer"
    ],
    "with_target": [
      "self",
      "target"
    ],
    "with_content": [
      "self",
      "content"
    ]
  },
  "_TokenMatch": {},
  "iter_token_matches": [
    "token_ids",
    "match_ids"
  ],
  "replace_token_matches": [
    "token_ids",
    "match_ids",
    "new_ids"
  ],
  "PlaceholderFeaturesInfo": {
    "length": [
      "self"
    ],
    "to_range": [
      "self"
    ]
  },
  "_MatchToApply": [],
  "_find_matches": [
    "prompt",
    "mm_prompt_updates",
    "tokenizer"
  ],
  "_all_items_found": [
    "mm_item_counts",
    "mm_found_counts"
  ],
  "_apply_matches": [
    "prompt",
    "mm_prompt_updates",
    "tokenizer"
  ],
  "apply_token_matches": [
    "prompt",
    "mm_prompt_updates",
    "tokenizer"
  ],
  "apply_text_matches": [
    "prompt",
    "mm_prompt_updates",
    "tokenizer"
  ],
  "_iter_placeholders": [
    "prompt",
    "mm_prompt_updates",
    "tokenizer"
  ],
  "find_mm_placeholders": [
    "prompt",
    "mm_prompt_updates",
    "tokenizer"
  ],
  "MultiModalIsCached": [],
  "MultiModalPromptUpdates": [],
  "MultiModalPromptUpdatesApplyResult": [],
  "BaseMultiModalProcessor": {
    "__init__": [
      "self",
      "info",
      "dummy_inputs"
    ],
    "supported_mm_limits": [
      "self"
    ],
    "allowed_mm_limits": [
      "self"
    ],
    "__call__": [
      "self",
      "prompt",
      "mm_data",
      "hf_processor_mm_kwargs"
    ],
    "_get_data_parser": [
      "self"
    ],
    "validate_num_items": [
      "self",
      "modality",
      "num_items"
    ],
    "_to_mm_items": [
      "self",
      "mm_data"
    ],
    "_get_mm_fields_config": [
      "self",
      "hf_inputs",
      "hf_processor_mm_kwargs"
    ],
    "_get_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_bind_and_group_updates": [
      "self",
      "prompt_updates",
      "mm_item_counts"
    ],
    "_get_mm_prompt_updates": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "out_mm_kwargs"
    ],
    "_find_mm_placeholders": [
      "self",
      "new_token_ids",
      "mm_prompt_updates"
    ],
    "_get_hf_mm_data": [
      "self",
      "mm_items"
    ],
    "_call_hf_processor": [
      "self",
      "prompt",
      "mm_data",
      "mm_kwargs",
      "tok_kwargs"
    ],
    "_hf_processor_applies_updates": [
      "self",
      "prompt_text",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_apply_hf_processor_text_mm": [
      "self",
      "prompt_text",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_apply_hf_processor_text_only": [
      "self",
      "prompt_text",
      "tokenization_kwargs"
    ],
    "_apply_hf_processor_tokens_only": [
      "self",
      "prompt_tokens"
    ],
    "_apply_hf_processor_mm_only": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_apply_hf_processor_main": [
      "self",
      "prompt",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_hash_mm_items": [
      "self",
      "mm_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_get_cache_missing_items": [
      "self",
      "cache",
      "mm_data_items",
      "mm_hashes"
    ],
    "_recompute_cached_prompt_update": [
      "self",
      "cached_update",
      "new_item_idx"
    ],
    "_merge_mm_kwargs": [
      "self",
      "cache",
      "mm_hashes",
      "mm_is_cached",
      "mm_missing_kwargs",
      "mm_missing_prompt_updates"
    ],
    "_apply_hf_processor": [
      "self",
      "prompt",
      "mm_data_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_cached_apply_hf_processor": [
      "self",
      "prompt",
      "mm_data_items",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ],
    "_apply_token_matches": [
      "self",
      "prompt",
      "mm_prompt_updates"
    ],
    "_apply_text_matches": [
      "self",
      "prompt",
      "mm_prompt_updates"
    ],
    "_apply_prompt_updates": [
      "self",
      "token_ids",
      "mm_prompt_updates"
    ],
    "_validate_mm_kwargs": [
      "self",
      "mm_kwargs",
      "mm_item_counts"
    ],
    "_validate_mm_updates": [
      "self",
      "mm_updates",
      "mm_item_counts"
    ],
    "_validate_mm_placeholders": [
      "self",
      "mm_placeholders",
      "mm_item_counts"
    ],
    "_maybe_apply_prompt_updates": [
      "self",
      "mm_items",
      "prompt_ids",
      "mm_kwargs",
      "mm_prompt_updates",
      "is_update_applied"
    ],
    "apply": [
      "self",
      "prompt",
      "mm_data",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ]
  },
  "EncDecMultiModalProcessor": {
    "create_encoder_prompt": [
      "self",
      "prompt",
      "mm_data"
    ],
    "create_decoder_prompt": [
      "self",
      "prompt",
      "mm_data"
    ],
    "_get_enc_dec_inputs": [
      "self",
      "prompt",
      "mm_data",
      "encoder_inputs"
    ],
    "apply": [
      "self",
      "prompt",
      "mm_data",
      "hf_processor_mm_kwargs",
      "tokenization_kwargs"
    ]
  },
  "get_current_request_id": [],
  "set_request_id": [
    "request_id"
  ],
  "MultiModalProcessorTimingStats": {
    "to_dict": [
      "self"
    ]
  },
  "get_timing_stats_from_engine_client": [
    "engine_client"
  ],
  "timed_preprocessor_operation": [
    "ctx",
    "stage_name"
  ],
  "_P": [],
  "InputProcessingContext": {
    "get_tokenizer": [
      "self"
    ],
    "get_hf_config": [],
    "get_hf_image_processor_config": [
      "self"
    ],
    "get_mm_config": [
      "self"
    ],
    "get_hf_processor": [],
    "init_processor": [],
    "_postprocess_output": [
      "self",
      "output"
    ],
    "call_hf_processor": [
      "self",
      "hf_processor",
      "data",
      "kwargs"
    ],
    "get_timing_stats": [
      "self",
      "request_id"
    ],
    "create_timing_stats": [
      "self",
      "request_id"
    ],
    "clear_timing_stats_registry": [
      "self"
    ],
    "get_all_timing_stats": [
      "self"
    ]
  },
  "BaseProcessingInfo": {
    "__init__": [
      "self",
      "ctx"
    ],
    "model_id": [
      "self"
    ],
    "get_tokenizer": [
      "self"
    ],
    "get_hf_config": [
      "self"
    ],
    "get_hf_processor": [
      "self"
    ],
    "skip_prompt_length_check": [
      "self"
    ],
    "get_supported_mm_limits": [
      "self"
    ],
    "get_allowed_mm_limits": [
      "self"
    ],
    "get_mm_max_tokens_per_item": [
      "self",
      "seq_len",
      "mm_counts"
    ]
  },
  "AudioMediaIO": {
    "__init__": [
      "self"
    ],
    "load_bytes": [
      "self",
      "data"
    ],
    "load_base64": [
      "self",
      "media_type",
      "data"
    ],
    "load_file": [
      "self",
      "filepath"
    ],
    "encode_base64": [
      "self",
      "media"
    ]
  },
  "AudioEmbeddingMediaIO": {
    "__init__": [
      "self"
    ],
    "load_bytes": [
      "self",
      "data"
    ],
    "load_base64": [
      "self",
      "media_type",
      "data"
    ],
    "load_file": [
      "self",
      "filepath"
    ],
    "encode_base64": [
      "self",
      "media"
    ]
  },
  "VideoMediaIO": {
    "__init__": [
      "self",
      "image_io",
      "num_frames"
    ],
    "load_bytes": [
      "self",
      "data"
    ],
    "load_base64": [
      "self",
      "media_type",
      "data"
    ],
    "load_file": [
      "self",
      "filepath"
    ],
    "encode_base64": [
      "self",
      "media"
    ]
  },
  "MediaWithBytes": {
    "__array__": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "MediaIO": {
    "load_bytes": [
      "self",
      "data"
    ],
    "load_base64": [
      "self",
      "media_type",
      "data"
    ],
    "load_file": [
      "self",
      "filepath"
    ]
  },
  "ImageMediaIO": {
    "__init__": [
      "self",
      "image_mode"
    ],
    "_convert_image_mode": [
      "self",
      "image"
    ],
    "load_bytes": [
      "self",
      "data"
    ],
    "load_base64": [
      "self",
      "media_type",
      "data"
    ],
    "load_file": [
      "self",
      "filepath"
    ],
    "encode_base64": [
      "self",
      "media"
    ]
  },
  "ImageEmbeddingMediaIO": {
    "__init__": [
      "self"
    ],
    "load_bytes": [
      "self",
      "data"
    ],
    "load_base64": [
      "self",
      "media_type",
      "data"
    ],
    "load_file": [
      "self",
      "filepath"
    ],
    "encode_base64": [
      "self",
      "media"
    ]
  },
  "DEFAULT_FA_VERSION": [],
  "_is_fa2_supported": [
    "device"
  ],
  "_is_fa3_supported": [
    "device"
  ],
  "_is_fa4_supported": [
    "device"
  ],
  "is_fa_version_supported": [
    "fa_version",
    "device"
  ],
  "fa_version_unsupported_reason": [
    "fa_version",
    "device"
  ],
  "maybe_contiguous": [
    "x"
  ],
  "get_scheduler_metadata": [
    "batch_size",
    "max_seqlen_q",
    "max_seqlen_k",
    "num_heads_q",
    "num_heads_kv",
    "headdim",
    "cache_seqlens",
    "qkv_dtype",
    "headdim_v",
    "cu_seqlens_q",
    "cu_seqlens_k_new",
    "cache_leftpad",
    "page_size",
    "max_seqlen_k_new",
    "causal",
    "window_size",
    "has_softcap",
    "num_splits",
    "pack_gqa",
    "sm_margin"
  ],
  "sparse_attn_func": [
    "q",
    "k",
    "v",
    "block_count",
    "block_offset",
    "column_count",
    "column_index",
    "dropout_p",
    "softmax_scale",
    "causal",
    "softcap",
    "alibi_slopes",
    "deterministic",
    "return_attn_probs"
  ],
  "sparse_attn_varlen_func": [
    "q",
    "k",
    "v",
    "block_count",
    "block_offset",
    "column_count",
    "column_index",
    "cu_seqlens_q",
    "cu_seqlens_k",
    "max_seqlen_q",
    "max_seqlen_k",
    "dropout_p",
    "softmax_scale",
    "causal",
    "softcap",
    "alibi_slopes",
    "deterministic",
    "return_attn_probs"
  ],
  "rotary_kernel": [
    "OUT",
    "X",
    "COS",
    "SIN",
    "CU_SEQLENS",
    "SEQLEN_OFFSETS",
    "seqlen",
    "rotary_dim",
    "seqlen_ro",
    "stride_out_batch",
    "stride_out_seqlen",
    "stride_out_nheads",
    "stride_out_headdim",
    "stride_x_batch",
    "stride_x_seqlen",
    "stride_x_nheads",
    "stride_x_headdim",
    "BLOCK_K",
    "IS_SEQLEN_OFFSETS_TENSOR",
    "IS_VARLEN",
    "INTERLEAVED",
    "CONJUGATE",
    "BLOCK_M"
  ],
  "apply_rotary": [
    "x",
    "cos",
    "sin",
    "seqlen_offsets",
    "cu_seqlens",
    "max_seqlen",
    "interleaved",
    "inplace",
    "conjugate"
  ],
  "apply_rotary_emb_torch": [
    "x",
    "cos",
    "sin",
    "interleaved"
  ],
  "apply_rotary_emb_func": [],
  "ApplyRotaryEmbQKV_": {
    "forward": [
      "ctx",
      "qkv",
      "cos",
      "sin",
      "cos_k",
      "sin_k",
      "interleaved",
      "seqlen_offsets",
      "num_heads_q"
    ],
    "backward": [
      "ctx",
      "dqkv"
    ]
  },
  "apply_rotary_emb_qkv_": [
    "qkv",
    "cos",
    "sin",
    "cos_k",
    "sin_k",
    "interleaved",
    "seqlen_offsets",
    "num_heads_q"
  ],
  "ApplyRotaryEmbKV_": {
    "forward": [
      "ctx",
      "kv",
      "cos",
      "sin",
      "interleaved",
      "seqlen_offsets"
    ],
    "backward": [
      "ctx",
      "dkv"
    ]
  },
  "apply_rotary_emb_kv_": [
    "kv",
    "cos",
    "sin",
    "interleaved",
    "seqlen_offsets"
  ],
  "parse_raw_prompts": [
    "prompt"
  ],
  "ParsedStrPrompt": {},
  "ParsedTextPrompt": {},
  "ParsedTokensPrompt": {},
  "ParsedEmbedsPrompt": {},
  "parse_singleton_prompt": [
    "prompt"
  ],
  "is_explicit_encoder_decoder_prompt": [
    "prompt"
  ],
  "split_enc_dec_inputs": [
    "inputs"
  ],
  "PromptComponents": {},
  "get_prompt_components": [
    "prompt"
  ],
  "InputPreprocessor": {
    "__init__": [
      "self",
      "model_config",
      "observability_config",
      "mm_registry",
      "mm_processor_cache"
    ],
    "tokenizer": [
      "self"
    ],
    "get_tokenizer": [
      "self"
    ],
    "get_bos_token_id": [
      "self"
    ],
    "get_eos_token_id": [
      "self"
    ],
    "get_decoder_start_token_id": [
      "self"
    ],
    "_get_default_enc_dec_decoder_prompt": [
      "self"
    ],
    "_prepare_decoder_input_ids_for_generation": [
      "self",
      "decoder_input_ids"
    ],
    "_get_tokenization_kw": [
      "self",
      "overrides"
    ],
    "_tokenize_prompt": [
      "self",
      "prompt",
      "tokenization_kwargs"
    ],
    "_get_mm_processor": [
      "self"
    ],
    "_process_multimodal": [
      "self",
      "prompt",
      "mm_data",
      "mm_processor_kwargs",
      "tokenization_kwargs"
    ],
    "_process_embeds": [
      "self",
      "parsed_content"
    ],
    "_truncate_inputs": [
      "self",
      "inputs",
      "tokenization_kwargs"
    ],
    "_process_tokens": [
      "self",
      "parsed_content",
      "tokenization_kwargs"
    ],
    "_process_text": [
      "self",
      "parsed_content",
      "tokenization_kwargs"
    ],
    "_prompt_to_llm_inputs": [
      "self",
      "prompt",
      "tokenization_kwargs"
    ],
    "_build_enc_dec_llm_inputs": [
      "self",
      "encoder_inputs",
      "decoder_inputs"
    ],
    "_split_enc_dec_mm_inputs": [
      "self",
      "inputs",
      "decoder_inputs_to_override"
    ],
    "_process_encoder_decoder_prompt": [
      "self",
      "prompt",
      "tokenization_kwargs"
    ],
    "_build_decoder_only_llm_inputs": [
      "self",
      "prompt_inputs"
    ],
    "_process_decoder_only_prompt": [
      "self",
      "prompt",
      "tokenization_kwargs"
    ],
    "_preprocess": [
      "self",
      "prompt",
      "tokenization_kwargs"
    ],
    "preprocess": [
      "self",
      "prompt",
      "tokenization_kwargs"
    ],
    "stat_mm_cache": [
      "self"
    ],
    "clear_mm_cache": [
      "self"
    ]
  },
  "TextPrompt": {},
  "TokensPrompt": {},
  "EmbedsPrompt": {},
  "DataPrompt": {},
  "is_tokens_prompt": [
    "prompt"
  ],
  "is_embeds_prompt": [
    "prompt"
  ],
  "_T1_co": [],
  "_T2_co": [],
  "ExplicitEncoderDecoderPrompt": {},
  "TokenInputs": {},
  "token_inputs": [
    "prompt_token_ids",
    "cache_salt"
  ],
  "EmbedsInputs": {},
  "embeds_inputs": [
    "prompt_embeds",
    "cache_salt"
  ],
  "EncoderDecoderInputs": {},
  "_T1": [],
  "_T2": [],
  "build_explicit_enc_dec_prompt": [
    "encoder_prompt",
    "decoder_prompt",
    "mm_processor_kwargs"
  ],
  "zip_enc_dec_prompts": [
    "enc_prompts",
    "dec_prompts",
    "mm_processor_kwargs"
  ],
  "to_enc_dec_tuple_list": [
    "enc_dec_prompts"
  ],
  "compile_protos": [],
  "_sym_db": [],
  "DESCRIPTOR": [],
  "_globals": [],
  "GRPC_GENERATED_VERSION": [],
  "GRPC_VERSION": [],
  "_version_not_supported": [],
  "VllmEngineStub": {
    "__init__": [
      "self",
      "channel"
    ]
  },
  "add_VllmEngineServicer_to_server": [
    "servicer",
    "server"
  ],
  "VllmEngine": {
    "Generate": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "Embed": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "HealthCheck": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "Abort": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "GetModelInfo": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "GetServerInfo": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ]
  },
  "_ModuleTreeNode": {
    "is_leaf": [
      "self"
    ],
    "is_torch_op": [
      "self"
    ],
    "is_cuda": [
      "self"
    ]
  },
  "SummaryStatsEntry": {},
  "ModelStatsEntry": {},
  "_StatsTreeNode": {},
  "LayerwiseProfileResults": {
    "__post_init__": [
      "self"
    ],
    "print_model_table": [
      "self",
      "column_widths"
    ],
    "print_summary_table": [
      "self",
      "column_widths"
    ],
    "export_model_stats_table_csv": [
      "self",
      "filename"
    ],
    "export_summary_stats_table_csv": [
      "self",
      "filename"
    ],
    "convert_stats_to_dict": [
      "self"
    ],
    "_indent_row_names_based_on_depth": [
      "depths_rows",
      "indent_style"
    ],
    "_build_correlation_map": [
      "self"
    ],
    "_build_module_tree": [
      "self"
    ],
    "_get_kineto_gpu_event": [
      "self",
      "node"
    ],
    "_cumulative_cuda_time": [
      "self",
      "node"
    ],
    "_total_cuda_time": [
      "self"
    ],
    "_build_stats_trees": [
      "self"
    ],
    "_flatten_stats_tree": [
      "self",
      "tree"
    ],
    "_convert_stats_tree_to_dict": [
      "self",
      "tree"
    ]
  },
  "layerwise_profile": {
    "__init__": [
      "self",
      "num_running_seqs"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "trim_string_front": [
    "string",
    "width"
  ],
  "trim_string_back": [
    "string",
    "width"
  ],
  "TablePrinter": {
    "__init__": [
      "self",
      "row_cls",
      "column_widths"
    ],
    "print_table": [
      "self",
      "rows"
    ],
    "_print_header": [
      "self"
    ],
    "_print_row": [
      "self",
      "row"
    ],
    "_print_line": [
      "self"
    ]
  },
  "indent_string": [
    "string",
    "indent",
    "indent_style"
  ],
  "event_has_module": [
    "event"
  ],
  "event_is_torch_op": [
    "event"
  ],
  "event_arg_repr": [
    "arg"
  ],
  "event_torch_op_repr": [
    "event"
  ],
  "event_module_repr": [
    "event"
  ],
  "event_torch_op_stack_trace": [
    "curr_event",
    "until"
  ],
  "WorkerProfiler": {
    "__init__": [
      "self",
      "profiler_config"
    ],
    "_start": [
      "self"
    ],
    "_stop": [
      "self"
    ],
    "_call_start": [
      "self"
    ],
    "_call_stop": [
      "self"
    ],
    "start": [
      "self"
    ],
    "step": [
      "self"
    ],
    "stop": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "annotate_context_manager": [
      "self",
      "name"
    ]
  },
  "TorchProfilerActivity": [],
  "TorchProfilerActivityMap": [],
  "TorchProfilerWrapper": {
    "__init__": [
      "self",
      "profiler_config",
      "worker_name",
      "local_rank",
      "activities",
      "on_trace_ready"
    ],
    "_start": [
      "self"
    ],
    "_stop": [
      "self"
    ],
    "annotate_context_manager": [
      "self",
      "name"
    ]
  },
  "CudaProfilerWrapper": {
    "__init__": [
      "self",
      "profiler_config"
    ],
    "_start": [
      "self"
    ],
    "_stop": [
      "self"
    ],
    "annotate_context_manager": [
      "self",
      "name"
    ]
  },
  "logtime": [
    "logger",
    "msg"
  ],
  "NewLineFormatter": {
    "__init__": [
      "self",
      "fmt",
      "datefmt",
      "style"
    ],
    "format": [
      "self",
      "record"
    ]
  },
  "ColoredFormatter": {
    "COLORS": [],
    "GREY": [],
    "RESET": [],
    "__init__": [
      "self",
      "fmt",
      "datefmt",
      "style"
    ],
    "format": [
      "self",
      "record"
    ]
  },
  "lazy": {
    "__slots__": [],
    "__init__": [
      "self",
      "factory"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "prepare_object_to_dump": [
    "obj"
  ],
  "dump_engine_exception": [
    "config",
    "scheduler_output",
    "scheduler_stats"
  ],
  "_dump_engine_exception": [
    "config",
    "scheduler_output",
    "scheduler_stats"
  ],
  "DEFAULT_PLUGINS_GROUP": [],
  "IO_PROCESSOR_PLUGINS_GROUP": [],
  "PLATFORM_PLUGINS_GROUP": [],
  "STAT_LOGGER_PLUGINS_GROUP": [],
  "plugins_loaded": [],
  "load_plugins_by_group": [
    "group"
  ],
  "load_general_plugins": [],
  "FilesystemResolver": {
    "__init__": [
      "self",
      "lora_cache_dir"
    ],
    "resolve_lora": [
      "self",
      "base_model_name",
      "lora_name"
    ]
  },
  "register_filesystem_resolver": [],
  "IOProcessorInput": [],
  "IOProcessorOutput": [],
  "IOProcessor": {
    "__init__": [
      "self",
      "vllm_config"
    ],
    "pre_process": [
      "self",
      "prompt",
      "request_id"
    ],
    "pre_process_async": [
      "self",
      "prompt",
      "request_id"
    ],
    "post_process": [
      "self",
      "model_output",
      "request_id"
    ],
    "post_process_async": [
      "self",
      "model_output",
      "request_id"
    ],
    "parse_request": [
      "self",
      "request"
    ],
    "validate_or_generate_params": [
      "self",
      "params"
    ],
    "output_to_response": [
      "self",
      "plugin_output"
    ]
  },
  "get_io_processor": [
    "vllm_config",
    "plugin_from_init"
  ],
  "in_wsl": [],
  "PlatformEnum": {
    "CUDA": [],
    "ROCM": [],
    "TPU": [],
    "XPU": [],
    "CPU": [],
    "OOT": [],
    "UNSPECIFIED": []
  },
  "CpuArchEnum": {
    "X86": [],
    "ARM": [],
    "POWERPC": [],
    "S390X": [],
    "RISCV": [],
    "OTHER": [],
    "UNKNOWN": []
  },
  "DeviceCapability": {
    "__lt__": [
      "self",
      "other"
    ],
    "__le__": [
      "self",
      "other"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__ge__": [
      "self",
      "other"
    ],
    "__gt__": [
      "self",
      "other"
    ],
    "as_version_str": [
      "self"
    ],
    "to_int": [
      "self"
    ]
  },
  "Platform": {
    "pass_key": [
      "self"
    ],
    "supported_dtypes": [
      "self"
    ],
    "is_cuda": [
      "self"
    ],
    "is_rocm": [
      "self"
    ],
    "is_tpu": [
      "self"
    ],
    "is_xpu": [
      "self"
    ],
    "is_cpu": [
      "self"
    ],
    "is_out_of_tree": [
      "self"
    ],
    "is_unspecified": [
      "self"
    ],
    "get_max_output_tokens": [
      "self",
      "prompt_len"
    ],
    "is_cuda_alike": [
      "self"
    ],
    "is_sleep_mode_available": [
      "self"
    ],
    "get_pass_manager_cls": [
      "cls"
    ],
    "get_compile_backend": [
      "cls"
    ],
    "device_id_to_physical_device_id": [
      "cls",
      "device_id"
    ],
    "import_kernels": [
      "cls"
    ],
    "get_attn_backend_cls": [
      "cls",
      "selected_backend",
      "attn_selector_config"
    ],
    "get_supported_vit_attn_backends": [
      "cls"
    ],
    "get_vit_attn_backend": [
      "cls",
      "head_size",
      "dtype",
      "backend"
    ],
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "has_device_capability": [
      "cls",
      "capability",
      "device_id"
    ],
    "is_device_capability": [
      "cls",
      "capability",
      "device_id"
    ],
    "is_device_capability_family": [
      "cls",
      "capability",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_uuid": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "inference_mode": [
      "cls"
    ],
    "seed_everything": [
      "cls",
      "seed"
    ],
    "set_device": [
      "cls",
      "device"
    ],
    "pre_register_and_update": [
      "cls",
      "parser"
    ],
    "check_and_update_config": [
      "cls",
      "vllm_config"
    ],
    "verify_model_arch": [
      "cls",
      "model_arch"
    ],
    "verify_quantization": [
      "cls",
      "quant"
    ],
    "get_cpu_architecture": [
      "cls"
    ],
    "is_pin_memory_available": [
      "cls"
    ],
    "get_current_memory_usage": [
      "cls",
      "device"
    ],
    "get_punica_wrapper": [
      "cls"
    ],
    "get_infinity_values": [
      "cls",
      "dtype"
    ],
    "can_update_inplace": [
      "cls"
    ],
    "get_lora_vocab_padding_size": [
      "cls"
    ],
    "get_device_communicator_cls": [
      "cls"
    ],
    "supports_mx": [
      "cls"
    ],
    "supports_fp8": [
      "cls"
    ],
    "is_fp8_fnuz": [
      "cls"
    ],
    "fp8_dtype": [
      "cls"
    ],
    "use_all_gather": [
      "cls"
    ],
    "use_custom_allreduce": [
      "cls"
    ],
    "opaque_attention_op": [
      "cls"
    ],
    "validate_request": [
      "cls",
      "prompt",
      "params",
      "processed_inputs"
    ],
    "__getattr__": [
      "self",
      "key"
    ],
    "get_global_graph_pool": [
      "self"
    ],
    "get_static_graph_wrapper_cls": [
      "cls"
    ],
    "stateless_init_device_torch_dist_pg": [
      "cls",
      "backend",
      "prefix_store",
      "group_rank",
      "group_size",
      "timeout"
    ],
    "check_if_supports_dtype": [
      "cls",
      "dtype"
    ],
    "support_hybrid_kv_cache": [
      "cls"
    ],
    "support_static_graph_mode": [
      "cls"
    ],
    "use_sync_weight_loader": [
      "cls"
    ],
    "make_synced_weight_loader": [
      "cls",
      "original_weight_loader"
    ],
    "get_nixl_supported_devices": [
      "cls"
    ],
    "get_nixl_memory_type": [
      "cls"
    ],
    "check_max_model_len": [
      "cls",
      "max_model_len"
    ],
    "set_additional_forward_context": [
      "cls"
    ]
  },
  "UnspecifiedPlatform": {
    "_enum": [],
    "device_type": []
  },
  "with_amdsmi_context": [
    "fn"
  ],
  "on_gfx1x": [],
  "on_mi3xx": [],
  "on_gfx9": [],
  "on_gfx942": [],
  "on_gfx950": [],
  "use_rocm_custom_paged_attention": [
    "qtype",
    "head_size",
    "block_size",
    "gqa_ratio",
    "max_seq_len",
    "sliding_window",
    "kv_cache_dtype",
    "alibi_slopes",
    "sinks"
  ],
  "flash_attn_triton_available": [],
  "RocmPlatform": {
    "_enum": [],
    "import_kernels": [
      "cls"
    ],
    "get_attn_backend_cls": [
      "cls",
      "selected_backend",
      "attn_selector_config"
    ],
    "get_supported_vit_attn_backends": [
      "cls"
    ],
    "get_vit_attn_backend": [
      "cls",
      "head_size",
      "dtype",
      "backend"
    ],
    "set_device": [
      "cls",
      "device"
    ],
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "is_fully_connected": [
      "cls",
      "physical_device_ids"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "check_and_update_config": [
      "cls",
      "vllm_config"
    ],
    "verify_model_arch": [
      "cls",
      "model_arch"
    ],
    "verify_quantization": [
      "cls",
      "quant"
    ],
    "get_punica_wrapper": [
      "cls"
    ],
    "get_current_memory_usage": [
      "cls",
      "device"
    ],
    "get_device_communicator_cls": [
      "cls"
    ],
    "supports_mx": [
      "cls"
    ],
    "supports_fp8": [
      "cls"
    ],
    "is_fp8_fnuz": [
      "cls"
    ],
    "fp8_dtype": [
      "cls"
    ],
    "use_custom_allreduce": [
      "cls"
    ],
    "opaque_attention_op": [
      "cls"
    ],
    "is_navi": [
      "cls"
    ],
    "get_static_graph_wrapper_cls": [
      "cls"
    ],
    "device_count": [
      "cls"
    ],
    "check_if_supports_dtype": [
      "cls",
      "dtype"
    ],
    "support_hybrid_kv_cache": [
      "cls"
    ],
    "support_static_graph_mode": [
      "cls"
    ]
  },
  "vllm_version_matches_substr": [
    "substr"
  ],
  "tpu_platform_plugin": [],
  "cuda_platform_plugin": [],
  "rocm_platform_plugin": [],
  "xpu_platform_plugin": [],
  "cpu_platform_plugin": [],
  "builtin_platform_plugins": [],
  "resolve_current_platform_cls_qualname": [],
  "_current_platform": [],
  "__setattr__": [
    "name",
    "value"
  ],
  "get_max_threads": [
    "pid"
  ],
  "LogicalCPUInfo": {
    "_int": [
      "cls",
      "value"
    ],
    "json_decoder": [
      "obj_dict"
    ]
  },
  "CpuPlatform": {
    "_enum": [],
    "device_control_env_var": [],
    "supported_dtypes": [
      "self"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_attn_backend_cls": [
      "cls",
      "selected_backend",
      "attn_selector_config"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "set_device": [
      "cls",
      "device"
    ],
    "inference_mode": [
      "cls"
    ],
    "check_and_update_config": [
      "cls",
      "vllm_config"
    ],
    "get_allowed_cpu_core_node_list": [
      "cls"
    ],
    "is_pin_memory_available": [
      "cls"
    ],
    "get_punica_wrapper": [
      "cls"
    ],
    "get_device_communicator_cls": [
      "cls"
    ],
    "supports_structured_output": [
      "cls"
    ],
    "opaque_attention_op": [
      "cls"
    ],
    "support_hybrid_kv_cache": [
      "cls"
    ]
  },
  "pynvml": [],
  "_get_backend_priorities": [
    "use_mla",
    "device_capability"
  ],
  "with_nvml_context": [
    "fn"
  ],
  "CudaPlatformBase": {
    "_enum": [],
    "supported_dtypes": [
      "self"
    ],
    "set_device": [
      "cls",
      "device"
    ],
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "is_fully_connected": [
      "cls",
      "device_ids"
    ],
    "log_warnings": [
      "cls"
    ],
    "check_and_update_config": [
      "cls",
      "vllm_config"
    ],
    "get_current_memory_usage": [
      "cls",
      "device"
    ],
    "get_valid_backends": [
      "cls",
      "device_capability",
      "attn_selector_config"
    ],
    "get_attn_backend_cls": [
      "cls",
      "selected_backend",
      "attn_selector_config"
    ],
    "get_supported_vit_attn_backends": [
      "cls"
    ],
    "get_vit_attn_backend": [
      "cls",
      "head_size",
      "dtype",
      "backend"
    ],
    "get_punica_wrapper": [
      "cls"
    ],
    "get_device_communicator_cls": [
      "cls"
    ],
    "supports_fp8": [
      "cls"
    ],
    "use_custom_allreduce": [
      "cls"
    ],
    "opaque_attention_op": [
      "cls"
    ],
    "get_static_graph_wrapper_cls": [
      "cls"
    ],
    "device_count": [
      "cls"
    ],
    "check_if_supports_dtype": [
      "cls",
      "dtype"
    ],
    "insert_blocks_to_device": [
      "cls",
      "src_cache",
      "dst_cache",
      "src_block_indices",
      "dst_block_indices"
    ],
    "swap_out_blocks_to_host": [
      "cls",
      "src_cache",
      "dst_cache",
      "src_block_indices",
      "dst_block_indices"
    ],
    "support_hybrid_kv_cache": [
      "cls"
    ],
    "support_static_graph_mode": [
      "cls"
    ]
  },
  "NvmlCudaPlatform": {
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "has_device_capability": [
      "cls",
      "capability",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_uuid": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "is_fully_connected": [
      "cls",
      "physical_device_ids"
    ],
    "_get_physical_device_name": [
      "cls",
      "device_id"
    ],
    "log_warnings": [
      "cls"
    ]
  },
  "NonNvmlCudaPlatform": {
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "is_fully_connected": [
      "cls",
      "physical_device_ids"
    ]
  },
  "nvml_available": [],
  "CudaPlatform": [],
  "XPUPlatform": {
    "_enum": [],
    "import_kernels": [
      "cls"
    ],
    "get_attn_backend_cls": [
      "cls",
      "selected_backend",
      "attn_selector_config"
    ],
    "get_supported_vit_attn_backends": [
      "cls"
    ],
    "get_vit_attn_backend": [
      "cls",
      "head_size",
      "dtype",
      "backend"
    ],
    "set_device": [
      "cls",
      "device"
    ],
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_punica_wrapper": [
      "cls"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "inference_mode": [
      "cls"
    ],
    "check_and_update_config": [
      "cls",
      "vllm_config"
    ],
    "support_hybrid_kv_cache": [
      "cls"
    ],
    "support_static_graph_mode": [
      "cls"
    ],
    "is_pin_memory_available": [
      "cls"
    ],
    "get_current_memory_usage": [
      "cls",
      "device"
    ],
    "fp8_dtype": [
      "cls"
    ],
    "is_data_center_gpu": [
      "cls"
    ],
    "get_device_communicator_cls": [
      "cls"
    ],
    "device_count": [
      "cls"
    ],
    "check_if_supports_dtype": [
      "cls",
      "dtype"
    ],
    "opaque_attention_op": [
      "cls"
    ],
    "insert_blocks_to_device": [
      "cls",
      "src_cache",
      "dst_cache",
      "src_block_indices",
      "dst_block_indices"
    ],
    "swap_out_blocks_to_host": [
      "cls",
      "src_cache",
      "dst_cache",
      "src_block_indices",
      "dst_block_indices"
    ]
  },
  "should_load_quant_weights": [
    "quant_method"
  ],
  "set_default_quant_scales": [
    "layer",
    "register_buffer"
  ],
  "_init_kv_cache_quant": [
    "layer",
    "quant_config",
    "prefix"
  ],
  "MLAAttention": {
    "__init__": [
      "self",
      "num_heads",
      "scale",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "v_head_dim",
      "q_lora_rank",
      "kv_lora_rank",
      "kv_b_proj",
      "cache_config",
      "quant_config",
      "prefix",
      "use_sparse",
      "indexer"
    ],
    "forward": [
      "self",
      "q",
      "kv_c_normed",
      "k_pe",
      "output_shape"
    ],
    "process_weights_after_loading": [
      "self",
      "act_dtype"
    ],
    "calc_kv_scales": [
      "self",
      "q",
      "kv_c_normed",
      "k_pe"
    ],
    "get_attn_backend": [
      "self"
    ],
    "get_kv_cache_spec": [
      "self",
      "vllm_config"
    ]
  },
  "maybe_calc_kv_scales": [
    "query",
    "key",
    "value",
    "layer_name"
  ],
  "maybe_calc_kv_scales_fake": [
    "query",
    "key",
    "value",
    "layer_name"
  ],
  "get_attention_context": [
    "layer_name"
  ],
  "unified_attention": [
    "query",
    "key",
    "value",
    "layer_name"
  ],
  "unified_attention_fake": [
    "query",
    "key",
    "value",
    "layer_name"
  ],
  "unified_kv_cache_update": [
    "key",
    "value",
    "layer_name"
  ],
  "unified_kv_cache_update_fake": [
    "key",
    "value",
    "layer_name"
  ],
  "unified_attention_with_output": [
    "query",
    "key",
    "value",
    "output",
    "layer_name",
    "output_scale",
    "output_block_scale",
    "kv_cache_dummy_dep"
  ],
  "unified_attention_with_output_fake": [
    "query",
    "key",
    "value",
    "output",
    "layer_name",
    "output_scale",
    "output_block_scale",
    "kv_cache_dummy_dep"
  ],
  "unified_mla_attention": [
    "q",
    "kv_c_normed",
    "k_pe",
    "layer_name"
  ],
  "unified_mla_attention_fake": [
    "q",
    "kv_c_normed",
    "k_pe",
    "layer_name"
  ],
  "unified_mla_attention_with_output": [
    "q",
    "kv_c_normed",
    "k_pe",
    "output",
    "layer_name",
    "output_scale",
    "output_block_scale"
  ],
  "unified_mla_attention_with_output_fake": [
    "q",
    "kv_c_normed",
    "k_pe",
    "output",
    "layer_name",
    "output_scale",
    "output_block_scale"
  ],
  "maybe_transfer_kv_layer": [
    "func"
  ],
  "validate_kv_sharing_target": [
    "current_layer_name",
    "target_layer_name",
    "static_forward_context"
  ],
  "try_get_class_from_dynamic_module": [
    "class_reference",
    "pretrained_model_name_or_path",
    "trust_remote_code",
    "cache_dir",
    "force_download",
    "resume_download",
    "proxies",
    "token",
    "revision",
    "local_files_only",
    "repo_type",
    "code_revision",
    "warn_on_fail"
  ],
  "ConfigParserBase": {
    "parse": [
      "self",
      "model",
      "trust_remote_code",
      "revision",
      "code_revision"
    ]
  },
  "check_gguf_file": [
    "model"
  ],
  "is_remote_gguf": [
    "model"
  ],
  "is_valid_gguf_quant_type": [
    "gguf_quant_type"
  ],
  "split_remote_gguf": [
    "model"
  ],
  "is_gguf": [
    "model"
  ],
  "detect_gguf_multimodal": [
    "model"
  ],
  "extract_vision_config_from_gguf": [
    "mmproj_path"
  ],
  "maybe_patch_hf_config_from_gguf": [
    "model",
    "hf_config"
  ],
  "get_gguf_file_path_from_hf": [
    "repo_id",
    "quant_type",
    "revision"
  ],
  "is_s3": [
    "model_or_path"
  ],
  "is_gcs": [
    "model_or_path"
  ],
  "is_cloud_storage": [
    "model_or_path"
  ],
  "modelscope_list_repo_files": [
    "repo_id",
    "revision",
    "token"
  ],
  "_maybe_json_dict": [
    "path"
  ],
  "_maybe_space_split_dict": [
    "path"
  ],
  "maybe_model_redirect": [
    "model"
  ],
  "parse_safetensors_file_metadata": [
    "path"
  ],
  "convert_model_repo_to_path": [
    "model_repo"
  ],
  "with_retry": [
    "func",
    "log_msg",
    "max_retries",
    "retry_delay"
  ],
  "list_repo_files": [
    "repo_id"
  ],
  "list_filtered_repo_files": [
    "model_name_or_path",
    "allow_patterns",
    "revision",
    "repo_type",
    "token"
  ],
  "file_exists": [
    "repo_id",
    "file_name"
  ],
  "file_or_path_exists": [
    "model",
    "config_name",
    "revision"
  ],
  "get_model_path": [
    "model",
    "revision"
  ],
  "get_hf_file_bytes": [
    "file_name",
    "model",
    "revision"
  ],
  "try_get_local_file": [
    "model",
    "file_name",
    "revision"
  ],
  "get_hf_file_to_dict": [
    "file_name",
    "model",
    "revision"
  ],
  "SUPPORTED_SCHEMES": [],
  "list_safetensors": [
    "path"
  ],
  "is_runai_obj_uri": [
    "model_or_path"
  ],
  "ObjectStorageModel": {
    "__init__": [
      "self",
      "url"
    ],
    "_close": [
      "self"
    ],
    "_close_by_signal": [
      "self",
      "existing_handler"
    ],
    "pull_files": [
      "self",
      "model_path",
      "allow_pattern",
      "ignore_pattern"
    ]
  },
  "HashableDict": {
    "__hash__": [
      "self"
    ]
  },
  "HashableList": {
    "__hash__": [
      "self"
    ]
  },
  "_get_processor_factory_fn": [
    "processor_cls"
  ],
  "_collect_dynamic_keys_from_processing_kwargs": [
    "kwargs_cls"
  ],
  "_merge_mm_kwargs": [],
  "get_processor": [
    "processor_name"
  ],
  "cached_get_processor": [],
  "get_processor_kwargs_from_processor": [
    "processor"
  ],
  "cached_get_processor_without_dynamic_kwargs": [
    "processor_name"
  ],
  "cached_processor_from_config": [
    "model_config",
    "processor_cls"
  ],
  "get_feature_extractor": [
    "processor_name"
  ],
  "cached_get_feature_extractor": [],
  "cached_feature_extractor_from_config": [
    "model_config"
  ],
  "get_image_processor": [
    "processor_name"
  ],
  "cached_get_image_processor": [],
  "cached_image_processor_from_config": [
    "model_config"
  ],
  "get_video_processor": [
    "processor_name"
  ],
  "cached_get_video_processor": [],
  "cached_video_processor_from_config": [
    "model_config",
    "processor_cls"
  ],
  "_filter_allow": [
    "paths",
    "patterns"
  ],
  "_filter_ignore": [
    "paths",
    "patterns"
  ],
  "glob": [
    "s3",
    "path",
    "allow_pattern"
  ],
  "list_files": [
    "s3",
    "path",
    "allow_pattern",
    "ignore_pattern"
  ],
  "MISTRAL_CONFIG_NAME": [],
  "LazyConfigDict": {
    "__getitem__": [
      "self",
      "key"
    ]
  },
  "is_rope_parameters_nested": [
    "rope_parameters"
  ],
  "HFConfigParser": {
    "parse": [
      "self",
      "model",
      "trust_remote_code",
      "revision",
      "code_revision"
    ]
  },
  "MistralConfigParser": {
    "parse": [
      "self",
      "model",
      "trust_remote_code",
      "revision",
      "code_revision"
    ]
  },
  "ConfigFormat": [],
  "get_config_parser": [
    "config_format"
  ],
  "register_config_parser": [
    "config_format"
  ],
  "set_default_rope_theta": [
    "config",
    "default_theta"
  ],
  "patch_rope_parameters": [
    "config"
  ],
  "patch_rope_parameters_dict": [
    "rope_parameters"
  ],
  "_uses_mrope": [
    "config"
  ],
  "uses_mrope": [
    "config"
  ],
  "thinker_uses_mrope": [
    "config"
  ],
  "uses_xdrope_dim": [
    "config"
  ],
  "is_encoder_decoder": [
    "config"
  ],
  "is_interleaved": [
    "config"
  ],
  "_maybe_update_auto_config_kwargs": [
    "kwargs",
    "model_type"
  ],
  "_maybe_remap_hf_config_attrs": [
    "config"
  ],
  "maybe_override_with_speculators": [
    "model",
    "tokenizer",
    "trust_remote_code",
    "revision",
    "vllm_speculative_config"
  ],
  "get_pooling_config": [
    "model",
    "revision"
  ],
  "parse_pooling_type": [
    "pooling_name"
  ],
  "get_sentence_transformer_tokenizer_config": [
    "model",
    "revision"
  ],
  "maybe_register_config_serialize_by_value": [],
  "get_hf_image_processor_config": [
    "model",
    "hf_token",
    "revision"
  ],
  "get_hf_text_config": [
    "config"
  ],
  "try_get_generation_config": [
    "model",
    "trust_remote_code",
    "revision",
    "config_format"
  ],
  "try_get_safetensors_metadata": [
    "model"
  ],
  "try_get_tokenizer_config": [
    "pretrained_model_name_or_path",
    "trust_remote_code",
    "revision"
  ],
  "try_get_dense_modules": [
    "model",
    "revision"
  ],
  "get_safetensors_params_metadata": [
    "model"
  ],
  "_download_mistral_config_file": [
    "model",
    "revision"
  ],
  "_maybe_retrieve_max_pos_from_hf": [
    "model",
    "revision"
  ],
  "ModelArchConfigConvertorBase": {
    "__init__": [
      "self",
      "hf_config",
      "hf_text_config"
    ],
    "get_architectures": [
      "self"
    ],
    "get_num_hidden_layers": [
      "self"
    ],
    "get_total_num_attention_heads": [
      "self"
    ],
    "get_vocab_size": [
      "self"
    ],
    "get_hidden_size": [
      "self"
    ],
    "get_head_size": [
      "self"
    ],
    "get_total_num_kv_heads": [
      "self"
    ],
    "get_num_experts": [
      "self"
    ],
    "get_torch_dtype": [
      "cls",
      "hf_config",
      "model_id",
      "revision"
    ],
    "_normalize_quantization_config": [
      "self",
      "config"
    ],
    "get_quantization_config": [
      "self"
    ],
    "is_deepseek_mla": [
      "self"
    ],
    "derive_max_model_len_and_key": [
      "self"
    ],
    "convert": [
      "self"
    ]
  },
  "MambaModelArchConfigConvertor": {
    "get_head_size": [
      "self"
    ],
    "get_total_num_kv_heads": [
      "self"
    ]
  },
  "TerratorchModelArchConfigConvertor": {
    "get_head_size": [
      "self"
    ],
    "get_total_num_kv_heads": [
      "self"
    ]
  },
  "MedusaModelArchConfigConvertor": {
    "get_head_size": [
      "self"
    ],
    "get_total_num_kv_heads": [
      "self"
    ]
  },
  "Zamba2ModelArchConfigConvertor": {
    "get_head_size": [
      "self"
    ]
  },
  "FalconModelArchConfigConvertor": {
    "get_total_num_kv_heads": [
      "self"
    ]
  },
  "MPTModelArchConfigConvertor": {
    "get_total_num_kv_heads": [
      "self"
    ]
  },
  "DbrxModelArchConfigConvertor": {
    "get_total_num_kv_heads": [
      "self"
    ]
  },
  "NemotronNasModelArchConfigConvertor": {
    "get_total_num_kv_heads": [
      "self"
    ]
  },
  "DeepSeekMTPModelArchConfigConvertor": {
    "get_num_hidden_layers": [
      "self"
    ]
  },
  "MimoMTPModelArchConfigConvertor": {
    "get_num_hidden_layers": [
      "self"
    ]
  },
  "GLM4MoeMTPModelArchConfigConvertor": {
    "get_num_hidden_layers": [
      "self"
    ]
  },
  "ErnieMTPModelArchConfigConvertor": {
    "get_num_hidden_layers": [
      "self"
    ]
  },
  "Qwen3NextMTPModelArchConfigConvertor": {
    "get_num_hidden_layers": [
      "self"
    ]
  },
  "PanguUltraMoeMTPModelArchConfigConvertor": {
    "get_num_hidden_layers": [
      "self"
    ]
  },
  "LongCatFlashMTPModelArchConfigConvertor": {
    "get_num_hidden_layers": [
      "self"
    ]
  },
  "MODEL_ARCH_CONFIG_CONVERTORS": [],
  "CHAT_TEMPLATES_DIR": [],
  "_get_qwen_chat_template_fallback": [
    "tokenizer_name_or_path"
  ],
  "_get_minicpmv_chat_template_fallback": [
    "tokenizer_name_or_path"
  ],
  "register_chat_template_fallback_path": [
    "model_type",
    "chat_template"
  ],
  "get_chat_template_fallback_path": [
    "model_type",
    "tokenizer_name_or_path"
  ],
  "Qwen3NextConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "base_model_tp_plan": [],
    "base_model_pp_plan": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_parameters",
      "attention_bias",
      "attention_dropout",
      "head_dim",
      "linear_conv_kernel_dim",
      "linear_key_head_dim",
      "linear_value_head_dim",
      "linear_num_key_heads",
      "linear_num_value_heads",
      "decoder_sparse_step",
      "moe_intermediate_size",
      "shared_expert_intermediate_size",
      "num_experts_per_tok",
      "num_experts",
      "norm_topk_prob",
      "output_router_logits",
      "router_aux_loss_coef",
      "mlp_only_layers",
      "layer_types"
    ]
  },
  "adapt_config_dict": [
    "config_dict",
    "defaults"
  ],
  "_remap_mistral_vision_args": [
    "config"
  ],
  "_remap_mistral_yarn_args": [
    "config"
  ],
  "_remap_general_mistral_args": [
    "config"
  ],
  "_remap_mistral_quantization_args": [
    "config"
  ],
  "_remap_mistral_audio_args": [
    "config"
  ],
  "_remap_moe_args": [
    "config"
  ],
  "NemotronConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "head_dim",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings",
      "rope_parameters",
      "attention_bias",
      "attention_dropout",
      "mlp_bias"
    ],
    "_rope_parameters_validation": [
      "self"
    ]
  },
  "HunYuanVLVisionConfig": {
    "model_type": [],
    "base_config_key": [],
    "__init__": [
      "self",
      "hidden_act",
      "hidden_size",
      "intermediate_size",
      "interpolate_mode",
      "rms_norm_eps",
      "learnable_mlp_pooling_size",
      "num_attention_heads",
      "num_key_value_heads",
      "num_channels",
      "num_hidden_layers",
      "out_hidden_size",
      "patch_size",
      "remove_prenorm",
      "spatial_merge_size",
      "temporal_patch_size",
      "resize_resolution",
      "img_max_token_num",
      "max_image_size",
      "video_max_image_size",
      "video_min_image_size",
      "min_image_size",
      "anyres_vit_max_image_size",
      "max_vit_seq_len",
      "text_hidden_size"
    ]
  },
  "HunYuanVLTextConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "eod_token_id",
      "pretraining_tp",
      "tie_word_embeddings",
      "rope_theta",
      "rope_scaling",
      "attention_bias",
      "attention_dropout",
      "head_dim"
    ],
    "_rope_scaling_validation": [
      "self"
    ]
  },
  "HunYuanVLConfig": {
    "model_type": [],
    "sub_configs": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "text_config",
      "vision_config",
      "im_start_id",
      "im_end_id",
      "image_token_id",
      "im_newline_id",
      "video_start_id",
      "video_end_id"
    ],
    "__setattr__": [
      "self",
      "key",
      "value"
    ],
    "__getattribute__": [
      "self",
      "key"
    ]
  },
  "FlexOlmoConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings",
      "rope_parameters",
      "attention_bias",
      "attention_dropout",
      "num_experts_per_tok",
      "num_experts",
      "output_router_logits",
      "router_aux_loss_coef",
      "norm_topk_prob"
    ]
  },
  "KimiLinearConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "model_type",
      "vocab_size",
      "hidden_size",
      "head_dim",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "rope_parameters",
      "tie_word_embeddings",
      "moe_intermediate_size",
      "moe_renormalize",
      "moe_router_activation_func",
      "num_experts",
      "num_experts_per_token",
      "num_shared_experts",
      "routed_scaling_factor",
      "first_k_dense_replace",
      "moe_layer_freq",
      "use_grouped_topk",
      "num_expert_group",
      "topk_group",
      "q_lora_rank",
      "kv_lora_rank",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "v_head_dim",
      "mla_use_nope",
      "num_nextn_predict_layers",
      "linear_attn_config"
    ],
    "is_mla": [
      "self"
    ],
    "is_moe": [
      "self"
    ],
    "is_linear_attn": [
      "self"
    ],
    "is_kda_layer": [
      "self",
      "layer_idx"
    ]
  },
  "MoonViTConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "patch_size",
      "init_pos_emb_height",
      "init_pos_emb_width",
      "num_attention_heads",
      "num_hidden_layers",
      "hidden_size",
      "intermediate_size",
      "merge_kernel_size"
    ]
  },
  "Olmo3Config": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings",
      "rope_parameters",
      "attention_bias",
      "attention_dropout",
      "rms_norm_eps",
      "sliding_window",
      "layer_types"
    ]
  },
  "NemotronHConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "tie_word_embeddings",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "hybrid_override_pattern",
      "num_attention_heads",
      "head_dim",
      "num_key_value_heads",
      "mlp_hidden_act",
      "attention_bias",
      "mlp_bias",
      "use_bias",
      "initializer_range",
      "layer_norm_epsilon",
      "residual_in_fp32",
      "use_cache",
      "num_logits_to_keep",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "sliding_window",
      "max_position_embeddings",
      "attention_dropout",
      "hidden_dropout",
      "use_mamba_kernels",
      "ssm_state_size",
      "mamba_num_heads",
      "mamba_n_groups",
      "mamba_head_dim",
      "mamba_d_conv",
      "mamba_expand",
      "mamba_hidden_act",
      "mamba_dt_min",
      "mamba_dt_max",
      "mamba_dt_limit",
      "mamba_dt_init_floor",
      "mamba_conv_bias",
      "mamba_proj_bias",
      "mamba_chunk_size",
      "rescale_prenorm_residual",
      "n_routed_experts",
      "n_shared_experts",
      "moe_intermediate_size",
      "moe_shared_expert_intermediate_size",
      "moe_latent_size",
      "num_experts_per_tok",
      "routed_scaling_factor",
      "n_group",
      "topk_group",
      "norm_topk_prob"
    ],
    "layers_block_type": [
      "self"
    ]
  },
  "DashengConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "embed_dim",
      "outputdim",
      "patch_size",
      "patch_stride",
      "input_channels",
      "target_length",
      "depth",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "init_values",
      "drop_rate",
      "attn_drop_rate",
      "f_min",
      "f_max",
      "center",
      "win_length",
      "hop_length",
      "sample_rate",
      "n_fft",
      "n_mels"
    ]
  },
  "MiDashengLMConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "audio_encoder_config",
      "subsample_factor",
      "text_config",
      "audio_token_id"
    ]
  },
  "Lfm2MoeConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "moe_intermediate_size",
      "num_hidden_layers",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings",
      "rope_parameters",
      "max_position_embeddings",
      "use_cache",
      "norm_eps",
      "num_attention_heads",
      "num_key_value_heads",
      "conv_bias",
      "conv_L_cache",
      "num_dense_layers",
      "num_experts_per_tok",
      "num_experts",
      "use_expert_bias",
      "routed_scaling_factor",
      "norm_topk_prob",
      "layer_types"
    ]
  },
  "Tarsier2Config": {
    "model_type": []
  },
  "MedusaConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "vocab_size",
      "num_heads",
      "num_hidden_layers",
      "max_paths",
      "topk",
      "truncated_vocab_size"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "num_attention_heads": [
      "self"
    ],
    "num_lookahead_tokens": [
      "self",
      "num_lookahead_tokens"
    ]
  },
  "VisionEncoderConfig": {
    "__init__": [
      "self",
      "model_name",
      "image_size",
      "patch_size",
      "width",
      "layers",
      "heads",
      "mlp_ratio",
      "global_pool",
      "ignore_head",
      "class_token",
      "num_classes",
      "use_checkpoint"
    ]
  },
  "MlpProjectorConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "projector_type",
      "input_dim",
      "n_embed",
      "depth",
      "mlp_ratio",
      "downsample_ratio"
    ]
  },
  "DeepseekVLV2Config": {
    "model_type": [],
    "__init__": [
      "self",
      "tile_tag",
      "global_view_pos",
      "candidate_resolutions"
    ]
  },
  "BagelConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "visual_gen",
      "visual_und",
      "llm_config",
      "vit_config",
      "vae_config",
      "latent_patch_size",
      "max_latent_size",
      "vit_max_num_patch_per_side",
      "connector_act",
      "interpolate_pos",
      "timestep_shift"
    ],
    "hidden_size": [
      "self"
    ]
  },
  "JAISConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "n_positions",
      "n_embd",
      "n_layer",
      "n_head",
      "n_inner",
      "activation_function",
      "resid_pdrop",
      "embd_pdrop",
      "attn_pdrop",
      "layer_norm_epsilon",
      "initializer_range",
      "scale_attn_weights",
      "use_cache",
      "bos_token_id",
      "eos_token_id",
      "scale_attn_by_inverse_layer_idx",
      "reorder_and_upcast_attn",
      "position_embedding_type",
      "mup_width_scale",
      "mup_embeddings_scale",
      "mup_output_alpha",
      "mup_scale_qk_dot_by_d",
      "alibi_scaling",
      "architectures"
    ],
    "_alibi_scaling_validation": [
      "self"
    ]
  },
  "KimiK25VisionConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "patch_size",
      "init_pos_emb_height",
      "init_pos_emb_width",
      "init_pos_emb_time",
      "pos_emb_type",
      "num_attention_heads",
      "num_hidden_layers",
      "hidden_size",
      "intermediate_size",
      "merge_kernel_size",
      "video_attn_type",
      "merge_type",
      "mm_projector_type",
      "mm_hidden_size",
      "projector_hidden_act",
      "projector_ln_eps"
    ]
  },
  "KimiK25Config": {
    "model_type": [],
    "__init__": [
      "self",
      "vision_config",
      "text_config",
      "ignore_index",
      "media_placeholder_token_id",
      "pad_token_id",
      "use_unified_vision_chunk",
      "video_placeholder"
    ],
    "hidden_size": [
      "self"
    ],
    "vocab_size": [
      "self"
    ]
  },
  "EAGLEConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "model",
      "truncated_vocab_size",
      "method"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "to_json_string": [
      "self",
      "use_diff"
    ]
  },
  "MLPSpeculatorConfig": {
    "model_type": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "emb_dim",
      "inner_dim",
      "n_predict",
      "top_k_tokens_per_head",
      "n_candidates",
      "tie_weights",
      "scale_input"
    ]
  },
  "RWConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "n_layer",
      "n_head",
      "layer_norm_epsilon",
      "initializer_range",
      "use_cache",
      "bos_token_id",
      "eos_token_id",
      "hidden_dropout",
      "attention_dropout",
      "multi_query",
      "n_head_kv",
      "alibi",
      "bias",
      "parallel_attn",
      "new_decoder_architecture"
    ],
    "head_dim": [
      "self"
    ],
    "rotary": [
      "self"
    ]
  },
  "UltravoxConfig": {
    "model_type": [],
    "audio_token": [],
    "is_composition": [],
    "__init__": [
      "self",
      "audio_config",
      "text_config",
      "audio_model_id",
      "text_model_id",
      "ignore_index",
      "audio_token_index",
      "hidden_size",
      "stack_factor",
      "norm_init",
      "projector_act",
      "projector_ln_mid",
      "num_projector_layers"
    ],
    "__setattr__": [
      "self",
      "key",
      "value"
    ],
    "text_config": [
      "self"
    ]
  },
  "PixelShuffleSiglip2VisionConfig": {
    "model_type": [],
    "base_config_key": [],
    "__init__": [
      "self",
      "pixel_shuffle_scale_factor",
      "num_patches"
    ]
  },
  "IsaacConfig": {
    "model_type": [],
    "sub_configs": [],
    "__init__": [
      "self",
      "text_config",
      "vision_config",
      "vision_patch_size",
      "vision_max_num_patches",
      "vision_min_num_patches",
      "pixel_shuffle_scale",
      "max_sequence_length",
      "vision_token",
      "vision_attn_implementation"
    ]
  },
  "AIMv2Config": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "rms_norm_eps",
      "attention_dropout",
      "projection_dropout",
      "qkv_bias",
      "use_bias"
    ]
  },
  "BaseVisualTokenizerConfig": {
    "__init__": [
      "self",
      "vocab_size",
      "tokenize_function",
      "tau",
      "depths",
      "drop_cls_token",
      "backbone_config",
      "hidden_stride"
    ]
  },
  "Aimv2VisualTokenizerConfig": {
    "model_type": [],
    "__init__": [
      "self"
    ]
  },
  "SiglipVisualTokenizerConfig": {
    "model_type": [],
    "__init__": [
      "self"
    ]
  },
  "OvisConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "llm_config",
      "visual_tokenizer_config",
      "multimodal_max_length",
      "hidden_size",
      "conversation_formatter_class",
      "llm_attn_implementation",
      "disable_tie_weight"
    ]
  },
  "OPENAI_CLIP_MEAN": [],
  "OPENAI_CLIP_STD": [],
  "RadioConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "model_name",
      "image_size",
      "patch_size",
      "qkv_bias",
      "qk_normalization",
      "norm_type",
      "layer_norm_eps",
      "initializer_factor",
      "hidden_act",
      "cpe_max_size",
      "norm_mean",
      "norm_std",
      "register_multiple",
      "teachers",
      "cls_token_per_teacher"
    ]
  },
  "Step3p5Config": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "num_attention_heads",
      "num_attention_groups",
      "num_hidden_layers",
      "max_seq_len",
      "vocab_size",
      "rms_norm_eps",
      "moe_every_n_layer",
      "use_moe",
      "moe_intermediate_size",
      "moe_num_experts",
      "moe_top_k",
      "moe_layer_offset",
      "rope_theta",
      "rope_scaling",
      "head_dim",
      "share_expert_dim",
      "norm_expert_weight",
      "bos_token_id",
      "eos_token_id",
      "moe_router_activation",
      "moe_router_scaling_factor",
      "att_impl_type",
      "use_head_wise_attn_gate",
      "use_moe_router_bias",
      "need_fp32_gate",
      "layer_types",
      "use_rope_layers",
      "yarn_only_types",
      "attention_other_setting",
      "num_nextn_predict_layers",
      "swiglu_limits",
      "swiglu_limits_shared",
      "max_position_embeddings"
    ]
  },
  "ARCTIC_PRETRAINED_CONFIG_ARCHIVE_MAP": [],
  "ArcticLoRAConfig": {},
  "ArcticQuantizationConfig": {},
  "ArcticConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings",
      "rope_parameters",
      "sliding_window",
      "attention_dropout",
      "num_experts_per_tok",
      "num_local_experts",
      "router_aux_loss_coef",
      "moe_layer_frequency",
      "parallel_attn_mlp_res",
      "moe_train_capacity_factor",
      "moe_eval_capacity_factor",
      "enable_expert_tensor_parallelism",
      "moe_min_capacity",
      "moe_token_dropping",
      "quantization"
    ],
    "from_dict": [
      "cls",
      "config_dict"
    ],
    "to_dict": [
      "self"
    ]
  },
  "KimiVLConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vision_config",
      "text_config",
      "ignore_index",
      "media_placeholder_token_id",
      "pad_token_id"
    ]
  },
  "AfmoeConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "moe_intermediate_size",
      "num_hidden_layers",
      "num_dense_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "head_dim",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_parameters",
      "rope_scaling",
      "num_experts",
      "num_experts_per_tok",
      "num_shared_experts",
      "num_expert_groups",
      "num_limited_groups",
      "score_func",
      "route_norm",
      "route_scale",
      "global_attn_every_n_layers",
      "sliding_window",
      "layer_types",
      "attention_dropout",
      "mup_enabled",
      "n_group",
      "topk_group"
    ]
  },
  "Step3VisionEncoderConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "output_hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "hidden_act",
      "layer_norm_eps"
    ]
  },
  "Step3TextConfig": {
    "model_type": [],
    "architectures": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "num_attention_heads",
      "num_attention_groups",
      "num_hidden_layers",
      "max_seq_len",
      "vocab_size",
      "rms_norm_eps",
      "moe_intermediate_size",
      "moe_num_experts",
      "moe_top_k",
      "rope_parameters",
      "max_position_embedding",
      "share_expert_dim",
      "share_q_dim",
      "head_dim",
      "norm_expert_weight",
      "moe_layers_enum"
    ]
  },
  "Step3VLConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vision_config",
      "text_config",
      "understand_projector_stride",
      "projector_bias",
      "image_token_id"
    ]
  },
  "ChatGLMConfig": {
    "model_type": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "num_layers",
      "padded_vocab_size",
      "hidden_size",
      "ffn_hidden_size",
      "kv_channels",
      "num_attention_heads",
      "seq_length",
      "hidden_dropout",
      "attention_dropout",
      "layernorm_epsilon",
      "rmsnorm",
      "apply_residual_connection_post_layernorm",
      "post_layer_norm",
      "add_bias_linear",
      "add_qkv_bias",
      "interleaved_qkv",
      "bias_dropout_fusion",
      "multi_query_attention",
      "multi_query_group_num",
      "apply_query_key_layer_scaling",
      "attention_softmax_in_fp32",
      "fp32_residual_connection",
      "quantization_bit",
      "pre_seq_len",
      "prefix_projection"
    ]
  },
  "DotsVisionConfig": {
    "__init__": [
      "self",
      "embed_dim",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "patch_size",
      "spatial_merge_size",
      "temporal_patch_size",
      "rms_norm_eps",
      "use_bias",
      "attn_implementation",
      "initializer_range",
      "init_merger_std",
      "is_causal",
      "post_norm",
      "gradient_checkpointing"
    ]
  },
  "DotsOCRConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "image_token_id",
      "video_token_id",
      "vision_config"
    ],
    "save_pretrained": [
      "self",
      "save_directory"
    ]
  },
  "SpeculatorsConfig": {
    "model_type": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ],
    "extract_vllm_speculative_config": [
      "cls",
      "config_dict"
    ],
    "validate_speculators_config": [
      "cls",
      "config_dict"
    ],
    "build_vllm_speculative_config": [
      "cls",
      "config_dict"
    ]
  },
  "SUPPORTED_SPECULATORS_TYPES": [],
  "register_speculator": [
    "name"
  ],
  "update_eagle3": [
    "config_dict",
    "vllm_config"
  ],
  "HunYuanVLProcessor": {
    "attributes": [],
    "valid_kwargs": [],
    "image_processor_class": [],
    "tokenizer_class": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer",
      "video_processor",
      "chat_template"
    ],
    "__call__": [
      "self",
      "images",
      "text",
      "videos"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "post_process_image_text_to_text": [
      "self",
      "generated_outputs",
      "skip_special_tokens",
      "clean_up_tokenization_spaces"
    ],
    "apply_chat_template": [
      "self"
    ],
    "get_imgs_pos": [
      "self",
      "doc_ids"
    ],
    "model_input_names": [
      "self"
    ]
  },
  "split_image_into_patch_blocks": [
    "pixel_values",
    "patch_size",
    "adaptor_patch_div"
  ],
  "BASE_SIZE": [],
  "IMAGE_SIZE": [],
  "CROP_MODE": [],
  "MIN_CROPS": [],
  "MAX_CROPS": [],
  "calculate_aspect_ratios": [
    "min_num",
    "max_num"
  ],
  "count_tiles": [
    "orig_width",
    "orig_height",
    "min_num",
    "max_num",
    "image_size",
    "use_thumbnail"
  ],
  "ImageTransform": {
    "__init__": [
      "self",
      "mean",
      "std",
      "normalize"
    ],
    "__call__": [
      "self",
      "pil_img"
    ]
  },
  "DeepseekOCRProcessor": {
    "tokenizer_class": [],
    "attributes": [],
    "__init__": [
      "self",
      "tokenizer",
      "patch_size",
      "downsample_ratio",
      "image_mean",
      "image_std",
      "normalize",
      "image_token",
      "pad_token",
      "add_special_token",
      "sft_format",
      "mask_prompt",
      "ignore_id"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "pad_id": [
      "self"
    ],
    "encode": [
      "self",
      "text",
      "bos",
      "eos"
    ],
    "decode": [
      "self",
      "t"
    ],
    "process_one": [
      "self",
      "prompt",
      "images",
      "crop_mode"
    ],
    "__call__": [
      "self"
    ],
    "tokenize_with_images": [
      "self",
      "conversation",
      "images",
      "bos",
      "eos",
      "cropping"
    ]
  },
  "HunYuanVLImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "do_convert_rgb",
      "min_pixels",
      "max_pixels",
      "patch_size",
      "temporal_patch_size",
      "merge_size"
    ],
    "_preprocess": [
      "self",
      "images",
      "do_resize",
      "size",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "patch_size",
      "temporal_patch_size",
      "merge_size",
      "do_convert_rgb",
      "data_format",
      "input_data_format"
    ],
    "preprocess": [
      "self",
      "images",
      "videos",
      "do_resize",
      "size",
      "min_pixels",
      "max_pixels",
      "resample",
      "do_rescale",
      "rescale_factor",
      "do_normalize",
      "image_mean",
      "image_std",
      "patch_size",
      "temporal_patch_size",
      "merge_size",
      "do_convert_rgb",
      "return_tensors",
      "data_format",
      "input_data_format"
    ],
    "get_number_of_image_patches": [
      "self",
      "height",
      "width",
      "images_kwargs"
    ]
  },
  "MIN_PIXELS": [],
  "Ovis2_5ProcessorKwargs": {
    "_defaults": []
  },
  "Ovis2_5Processor": {
    "attributes": [],
    "valid_kwargs": [],
    "image_processor_class": [],
    "tokenizer_class": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer",
      "chat_template",
      "image_pad_token",
      "patch_size",
      "hidden_stride",
      "temporal_patch_size"
    ],
    "extra_special_tokens": [
      "self"
    ],
    "__call__": [
      "self",
      "images",
      "videos",
      "text"
    ],
    "_tokenize_with_visual_symbol": [
      "self",
      "text_list"
    ],
    "smart_resize": [
      "self",
      "height",
      "width",
      "factor",
      "min_pixels",
      "max_pixels"
    ],
    "get_token_value": [
      "self",
      "tok"
    ],
    "construct_visual_indicators": [
      "self",
      "grid",
      "is_video"
    ],
    "construct_visual_placeholders": [
      "self",
      "grid",
      "is_video"
    ],
    "preprocess_multidata": [
      "self",
      "images",
      "video",
      "convert_to_rgb",
      "min_pixels",
      "max_pixels",
      "return_tensors"
    ]
  },
  "DeepseekVLV2Processor": {
    "tokenizer_class": [],
    "attributes": [],
    "__init__": [
      "self",
      "tokenizer",
      "candidate_resolutions",
      "patch_size",
      "downsample_ratio",
      "image_mean",
      "image_std",
      "normalize",
      "image_token",
      "pad_token",
      "add_special_token",
      "sft_format",
      "mask_prompt",
      "ignore_id"
    ],
    "select_best_resolution": [
      "self",
      "image_size"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "pad_id": [
      "self"
    ],
    "encode": [
      "self",
      "text",
      "bos",
      "eos"
    ],
    "decode": [
      "self",
      "t"
    ],
    "process_one": [
      "self",
      "prompt",
      "images",
      "inference_mode"
    ],
    "__call__": [
      "self"
    ],
    "tokenize_with_images": [
      "self",
      "conversation",
      "images",
      "bos",
      "eos",
      "cropping"
    ]
  },
  "BagelProcessor": {
    "attributes": [],
    "image_processor_class": [],
    "tokenizer_class": [],
    "__call__": [
      "self",
      "text",
      "images"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "model_input_names": [
      "self"
    ]
  },
  "IGNORE_ID": [],
  "OvisProcessorKwargs": {
    "_defaults": []
  },
  "OvisProcessor": {
    "attributes": [],
    "valid_kwargs": [],
    "image_processor_class": [],
    "tokenizer_class": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer",
      "chat_template",
      "image_pad_token",
      "image_segment_len"
    ],
    "extra_special_tokens": [
      "self"
    ],
    "__call__": [
      "self",
      "images",
      "text"
    ],
    "_tokenize_with_image_symbol": [
      "self",
      "text_list"
    ],
    "get_image_size": [
      "self"
    ],
    "get_token_value": [
      "self",
      "tok"
    ],
    "construct_image_indicators": [
      "self",
      "grid"
    ],
    "construct_image_placeholders": [
      "self",
      "grid"
    ],
    "preprocess_image": [
      "self",
      "image",
      "max_partition",
      "covering_threshold",
      "convert_to_rgb",
      "return_tensors"
    ],
    "batch_decode": [
      "self"
    ],
    "decode": [
      "self"
    ],
    "post_process_image_text_to_text": [
      "self",
      "generated_outputs"
    ],
    "model_input_names": [
      "self"
    ]
  },
  "LogprobsLists": {
    "slice_request": [
      "self",
      "req_idx",
      "num_positions"
    ]
  },
  "LogprobsTensors": {
    "tolists": [
      "self",
      "cu_num_generated_tokens"
    ],
    "to_cpu_nonblocking": [
      "self"
    ],
    "filter": [
      "self",
      "mask"
    ],
    "empty_cpu": [
      "num_positions",
      "num_tokens_per_position"
    ]
  },
  "SamplerOutput": {},
  "KVConnectorOutput": {
    "is_empty": [
      "self"
    ]
  },
  "ECConnectorOutput": {},
  "ModelRunnerOutput": {},
  "AsyncModelRunnerOutput": {
    "get_output": [
      "self"
    ]
  },
  "DraftTokenIds": {},
  "make_empty_encoder_model_runner_output": [
    "scheduler_output"
  ],
  "EMPTY_MODEL_RUNNER_OUTPUT": [],
  "StreamingUpdate": {
    "from_request": [
      "cls",
      "request"
    ]
  },
  "Request": {
    "__init__": [
      "self",
      "request_id",
      "prompt_token_ids",
      "sampling_params",
      "pooling_params",
      "eos_token_id",
      "client_index",
      "arrival_time",
      "prompt_embeds",
      "mm_features",
      "lora_request",
      "cache_salt",
      "priority",
      "trace_headers",
      "block_hasher",
      "resumable"
    ],
    "from_engine_core_request": [
      "cls",
      "request",
      "block_hasher"
    ],
    "append_output_token_ids": [
      "self",
      "token_ids"
    ],
    "use_structured_output": [
      "self"
    ],
    "num_tokens": [
      "self"
    ],
    "num_tokens_with_spec": [
      "self"
    ],
    "num_output_tokens": [
      "self"
    ],
    "num_encoder_inputs": [
      "self"
    ],
    "has_encoder_inputs": [
      "self"
    ],
    "get_skip_reading_prefix_cache": [
      "self"
    ],
    "is_finished": [
      "self"
    ],
    "get_finished_reason": [
      "self"
    ],
    "get_num_encoder_embeds": [
      "self",
      "input_id"
    ],
    "record_event": [
      "self",
      "event_type",
      "timestamp"
    ],
    "take_events": [
      "self"
    ],
    "__lt__": [
      "self",
      "other"
    ]
  },
  "RequestStatus": {
    "WAITING": [],
    "WAITING_FOR_FSM": [],
    "WAITING_FOR_REMOTE_KVS": [],
    "WAITING_FOR_STREAMING_REQ": [],
    "RUNNING": [],
    "PREEMPTED": [],
    "FINISHED_STOPPED": [],
    "FINISHED_LENGTH_CAPPED": [],
    "FINISHED_ABORTED": [],
    "FINISHED_IGNORED": [],
    "FINISHED_ERROR": [],
    "__str__": [
      "self"
    ],
    "is_finished": [
      "status"
    ],
    "get_finished_reason": [
      "status"
    ]
  },
  "_FINISHED_REASON_MAP": [],
  "ConstantList": {
    "__init__": [
      "self",
      "x"
    ],
    "append": [
      "self",
      "item"
    ],
    "extend": [
      "self",
      "item"
    ],
    "insert": [
      "self",
      "item"
    ],
    "pop": [
      "self",
      "item"
    ],
    "remove": [
      "self",
      "item"
    ],
    "clear": [
      "self"
    ],
    "index": [
      "self",
      "item",
      "start",
      "stop"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "__setitem__": [
      "self",
      "item",
      "value"
    ],
    "__delitem__": [
      "self",
      "item"
    ],
    "__iter__": [
      "self"
    ],
    "__contains__": [
      "self",
      "item"
    ],
    "__len__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "copy": [
      "self"
    ]
  },
  "CpuGpuBuffer": {
    "__init__": [
      "self"
    ],
    "copy_to_gpu": [
      "self",
      "n"
    ],
    "copy_to_cpu": [
      "self",
      "n"
    ]
  },
  "get_engine_client_zmq_addr": [
    "local_only",
    "host",
    "port"
  ],
  "APIServerProcessManager": {
    "__init__": [
      "self",
      "target_server_fn",
      "listen_address",
      "sock",
      "args",
      "num_servers",
      "input_addresses",
      "output_addresses",
      "stats_update_address"
    ],
    "close": [
      "self"
    ]
  },
  "wait_for_completion_or_failure": [
    "api_server_manager",
    "engine_manager",
    "coordinator"
  ],
  "shutdown": [
    "procs"
  ],
  "copy_slice": [
    "from_tensor",
    "to_tensor",
    "length"
  ],
  "report_usage_stats": [
    "vllm_config",
    "usage_context"
  ],
  "_PROFILER_FUNC": [],
  "record_function_or_nullcontext": [
    "name"
  ],
  "tensor_data": [
    "tensor"
  ],
  "IterationDetails": {
    "__repr__": [
      "self"
    ]
  },
  "compute_iteration_details": [
    "scheduler_output"
  ],
  "CUSTOM_TYPE_PICKLE": [],
  "CUSTOM_TYPE_CLOUDPICKLE": [],
  "CUSTOM_TYPE_RAW_VIEW": [],
  "_log_insecure_serialization_warning": [],
  "_typestr": [
    "val"
  ],
  "_encode_type_info_recursive": [
    "obj"
  ],
  "_decode_type_info_recursive": [
    "type_info",
    "data",
    "convert_fn"
  ],
  "UtilityResult": {
    "__init__": [
      "self",
      "r"
    ]
  },
  "MsgpackEncoder": {
    "__init__": [
      "self",
      "size_threshold"
    ],
    "encode": [
      "self",
      "obj"
    ],
    "encode_into": [
      "self",
      "obj",
      "buf"
    ],
    "enc_hook": [
      "self",
      "obj"
    ],
    "_encode_ndarray": [
      "self",
      "obj"
    ],
    "_encode_tensor": [
      "self",
      "obj"
    ],
    "_encode_mm_items": [
      "self",
      "items"
    ],
    "_encode_mm_item": [
      "self",
      "item"
    ],
    "_encode_mm_field_elem": [
      "self",
      "elem"
    ],
    "_encode_nested_tensors": [
      "self",
      "nt"
    ],
    "_encode_mm_field": [
      "self",
      "field"
    ]
  },
  "MsgpackDecoder": {
    "__init__": [
      "self",
      "t",
      "share_mem"
    ],
    "decode": [
      "self",
      "bufs"
    ],
    "dec_hook": [
      "self",
      "t",
      "obj"
    ],
    "_decode_utility_result": [
      "self",
      "obj"
    ],
    "_convert_result": [
      "self",
      "result_type",
      "result"
    ],
    "_decode_ndarray": [
      "self",
      "arr"
    ],
    "_decode_tensor": [
      "self",
      "arr"
    ],
    "_decode_mm_items": [
      "self",
      "obj"
    ],
    "_decode_mm_item": [
      "self",
      "obj"
    ],
    "_decode_mm_field_elem": [
      "self",
      "obj"
    ],
    "_decode_nested_tensors": [
      "self",
      "obj"
    ],
    "_decode_nested_slices": [
      "self",
      "obj"
    ],
    "ext_hook": [
      "self",
      "code",
      "data"
    ]
  },
  "run_method": [
    "obj",
    "method",
    "args",
    "kwargs"
  ],
  "PydanticMsgspecMixin": {
    "__get_pydantic_core_schema__": [
      "cls",
      "source_type",
      "handler"
    ],
    "_validate_msgspec": [
      "cls",
      "value"
    ]
  },
  "CudagraphDispatcher": {
    "__init__": [
      "self",
      "vllm_config"
    ],
    "_compute_bs_to_padded_graph_size": [
      "self"
    ],
    "_create_padded_batch_descriptor": [
      "self",
      "num_tokens",
      "uniform_decode",
      "has_lora"
    ],
    "add_cudagraph_key": [
      "self",
      "runtime_mode",
      "batch_descriptor"
    ],
    "initialize_cudagraph_keys": [
      "self",
      "cudagraph_mode",
      "uniform_decode_query_len"
    ],
    "dispatch": [
      "self",
      "num_tokens",
      "uniform_decode",
      "has_lora",
      "disable_full"
    ],
    "get_capture_descs": [
      "self"
    ]
  },
  "KVCacheSpec": {
    "page_size_bytes": [
      "self"
    ],
    "max_memory_usage_bytes": [
      "self",
      "vllm_config"
    ],
    "copy_with_new_block_size": [
      "self",
      "block_size"
    ],
    "merge": [
      "cls",
      "specs"
    ]
  },
  "AttentionSpec": {
    "page_size_bytes": [
      "self"
    ],
    "real_page_size_bytes": [
      "self"
    ]
  },
  "FullAttentionSpec": {
    "__post_init__": [
      "self"
    ],
    "max_memory_usage_bytes": [
      "self",
      "vllm_config"
    ],
    "merge_window_sizes": [
      "cls",
      "window_sizes"
    ],
    "merge": [
      "cls",
      "specs"
    ],
    "real_page_size_bytes": [
      "self"
    ]
  },
  "MLAAttentionSpec": {
    "real_page_size_bytes": [
      "self"
    ],
    "merge": [
      "cls",
      "specs"
    ]
  },
  "ChunkedLocalAttentionSpec": {
    "max_memory_usage_bytes": [
      "self",
      "vllm_config"
    ]
  },
  "SlidingWindowSpec": {
    "max_memory_usage_bytes": [
      "self",
      "vllm_config"
    ]
  },
  "MambaSpec": {
    "page_size_bytes": [
      "self"
    ],
    "max_memory_usage_bytes": [
      "self",
      "vllm_config"
    ]
  },
  "EncoderOnlyAttentionSpec": {
    "max_memory_usage_bytes": [
      "self",
      "vllm_config"
    ]
  },
  "CrossAttentionSpec": {
    "max_memory_usage_bytes": [
      "self",
      "vllm_config"
    ]
  },
  "SinkFullAttentionSpec": {
    "merge": [
      "cls",
      "specs"
    ]
  },
  "UniformTypeKVCacheSpecs": {
    "page_size_bytes": [
      "self"
    ],
    "max_memory_usage_bytes": [
      "self",
      "vllm_config"
    ],
    "is_uniform_type": [
      "cls",
      "kv_cache_specs"
    ],
    "from_specs": [
      "cls",
      "kv_cache_specs"
    ]
  },
  "KVCacheTensor": {},
  "KVCacheGroupSpec": {},
  "KVCacheConfig": {},
  "RayWorkerMetaData": {},
  "RayDistributedExecutor": {
    "WORKER_SPECIFIC_ENV_VARS": [],
    "ADDITIONAL_ENV_VARS": [],
    "_init_executor": [
      "self"
    ],
    "max_concurrent_batches": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "_configure_ray_workers_use_nsight": [
      "self",
      "ray_remote_kwargs"
    ],
    "_get_env_vars_to_be_updated": [
      "self"
    ],
    "_init_workers_ray": [
      "self",
      "placement_group"
    ],
    "reinitialize_distributed": [
      "self",
      "reconfig_request"
    ],
    "execute_model": [
      "self",
      "scheduler_output",
      "non_block"
    ],
    "sample_tokens": [
      "self",
      "grammar_output",
      "non_block"
    ],
    "_execute_dag": [
      "self",
      "scheduler_output",
      "grammar_output",
      "non_block"
    ],
    "collective_rpc": [
      "self",
      "method",
      "timeout",
      "args",
      "kwargs",
      "non_block"
    ],
    "_check_ray_cgraph_installation": [
      "self"
    ],
    "_compiled_ray_dag": [
      "self",
      "enable_asyncio"
    ],
    "__del__": [
      "self"
    ],
    "check_health": [
      "self"
    ]
  },
  "FutureWrapper": {
    "__init__": [
      "self",
      "futures_queue",
      "aggregate"
    ],
    "result": [
      "self",
      "timeout"
    ],
    "wait_for_response": [
      "self",
      "get_response"
    ]
  },
  "MultiprocExecutor": {
    "__init__": [
      "self",
      "vllm_config",
      "monitor_workers"
    ],
    "_init_executor": [
      "self"
    ],
    "_get_parallel_sizes": [
      "self"
    ],
    "_post_init_executor": [
      "self"
    ],
    "_is_driver_worker": [
      "self",
      "rank"
    ],
    "start_worker_monitor": [
      "self",
      "inline"
    ],
    "register_failure_callback": [
      "self",
      "callback"
    ],
    "execute_model": [
      "self",
      "scheduler_output",
      "non_block"
    ],
    "sample_tokens": [
      "self",
      "grammar_output",
      "non_block"
    ],
    "execute_dummy_batch": [
      "self"
    ],
    "take_draft_token_ids": [
      "self"
    ],
    "collective_rpc": [
      "self",
      "method",
      "timeout",
      "args",
      "kwargs",
      "non_block",
      "unique_reply_rank",
      "kv_output_aggregator"
    ],
    "_ensure_worker_termination": [
      "worker_procs"
    ],
    "shutdown": [
      "self"
    ],
    "check_health": [
      "self"
    ],
    "max_concurrent_batches": [
      "self"
    ],
    "_get_output_rank": [
      "self"
    ]
  },
  "UnreadyWorkerProcHandle": {},
  "WorkerProcHandle": {
    "from_unready_handle": [
      "cls",
      "unready_handle",
      "worker_response_mq",
      "peer_worker_response_mqs"
    ]
  },
  "WorkerProc": {
    "READY_STR": [],
    "_init_message_queues": [
      "self",
      "input_shm_handle",
      "vllm_config"
    ],
    "__init__": [
      "self",
      "vllm_config",
      "local_rank",
      "rank",
      "distributed_init_method",
      "input_shm_handle",
      "shared_worker_lock",
      "is_driver_worker"
    ],
    "make_worker_process": [
      "vllm_config",
      "local_rank",
      "rank",
      "distributed_init_method",
      "input_shm_handle",
      "shared_worker_lock",
      "is_driver_worker"
    ],
    "wait_for_response_handle_ready": [
      "handles",
      "proc_handle"
    ],
    "wait_for_ready": [
      "unready_proc_handles"
    ],
    "shutdown": [
      "self"
    ],
    "worker_main": [],
    "enqueue_output": [
      "self",
      "output"
    ],
    "handle_output": [
      "self",
      "output"
    ],
    "async_output_busy_loop": [
      "self"
    ],
    "worker_busy_loop": [
      "self",
      "cancel"
    ],
    "setup_proc_title_and_log_prefix": [
      "enable_ep"
    ]
  },
  "set_multiprocessing_worker_envs": [],
  "PG_WAIT_TIMEOUT": [],
  "ray_is_available": [],
  "assert_ray_available": [],
  "_verify_bundles": [
    "placement_group",
    "parallel_config",
    "device_str"
  ],
  "_wait_until_pg_ready": [
    "current_placement_group"
  ],
  "_wait_until_pg_removed": [
    "current_placement_group"
  ],
  "initialize_ray_cluster": [
    "parallel_config",
    "ray_address"
  ],
  "get_num_tpu_nodes": [],
  "get_num_nodes_in_placement_group": [],
  "UniProcExecutor": {
    "_init_executor": [
      "self"
    ],
    "_distributed_args": [
      "self"
    ],
    "max_concurrent_batches": [
      "self"
    ],
    "collective_rpc": [
      "self",
      "method",
      "timeout",
      "args",
      "kwargs",
      "non_block",
      "single_value"
    ],
    "execute_model": [
      "self",
      "scheduler_output",
      "non_block"
    ],
    "sample_tokens": [
      "self",
      "grammar_output",
      "non_block"
    ],
    "take_draft_token_ids": [
      "self"
    ],
    "check_health": [
      "self"
    ],
    "reinitialize_distributed": [
      "self",
      "reconfig_request"
    ],
    "shutdown": [
      "self"
    ]
  },
  "ExecutorWithExternalLauncher": {
    "_init_executor": [
      "self"
    ],
    "_distributed_args": [
      "self"
    ],
    "determine_available_memory": [
      "self"
    ]
  },
  "FailureCallback": [],
  "Executor": {
    "get_class": [
      "vllm_config"
    ],
    "__init__": [
      "self",
      "vllm_config"
    ],
    "_init_executor": [
      "self"
    ],
    "initialize_from_config": [
      "self",
      "kv_cache_configs"
    ],
    "register_failure_callback": [
      "self",
      "callback"
    ],
    "determine_available_memory": [
      "self"
    ],
    "get_kv_cache_specs": [
      "self"
    ],
    "collective_rpc": [
      "self",
      "method",
      "timeout",
      "args",
      "kwargs",
      "non_block"
    ],
    "get_kv_connector_handshake_metadata": [
      "self"
    ],
    "execute_model": [
      "self",
      "scheduler_output",
      "non_block"
    ],
    "sample_tokens": [
      "self",
      "grammar_output",
      "non_block"
    ],
    "execute_dummy_batch": [
      "self"
    ],
    "take_draft_token_ids": [
      "self"
    ],
    "max_concurrent_batches": [
      "self"
    ],
    "profile": [
      "self",
      "is_start"
    ],
    "save_sharded_state": [
      "self",
      "path",
      "pattern",
      "max_size"
    ],
    "check_health": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "init_kv_output_aggregator": [
      "self",
      "connector"
    ],
    "supported_tasks": [
      "self"
    ],
    "add_lora": [
      "self",
      "lora_request"
    ],
    "remove_lora": [
      "self",
      "lora_id"
    ],
    "pin_lora": [
      "self",
      "lora_id"
    ],
    "list_loras": [
      "self"
    ],
    "reset_mm_cache": [
      "self"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wake_up": [
      "self",
      "tags"
    ],
    "reinitialize_distributed": [
      "self",
      "reconfig_request"
    ]
  },
  "BaseCacheStats": {},
  "CachingMetrics": {
    "__init__": [
      "self",
      "max_recent_requests"
    ],
    "observe": [
      "self",
      "stats"
    ],
    "reset": [
      "self"
    ],
    "empty": [
      "self"
    ],
    "hit_rate": [
      "self"
    ]
  },
  "PrefixCacheStats": {
    "record": [
      "self",
      "num_tokens",
      "num_hits",
      "preempted"
    ]
  },
  "MultiModalCacheStats": {},
  "KVCacheEvictionEvent": {},
  "SchedulerStats": {},
  "RequestStateStats": {},
  "FinishedRequestStats": {},
  "IterationStats": {
    "__init__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_time_since": [
      "self",
      "start"
    ],
    "update_from_output": [
      "self",
      "output",
      "engine_core_timestamp",
      "is_prefilling",
      "prompt_len",
      "req_stats",
      "lora_states",
      "lora_name"
    ],
    "update_from_events": [
      "self",
      "req_id",
      "events",
      "is_prefilling",
      "req_stats",
      "lora_states",
      "lora_name"
    ],
    "update_from_finished_request": [
      "self",
      "finish_reason",
      "num_prompt_tokens",
      "max_tokens_param",
      "req_stats",
      "num_cached_tokens"
    ]
  },
  "LoRAStats": {
    "__init__": [
      "self"
    ],
    "update": [
      "self",
      "req_id",
      "waiting",
      "running"
    ],
    "empty": [
      "self"
    ]
  },
  "LoRARequestStates": {
    "__init__": [
      "self",
      "log_stats"
    ],
    "_request_update": [
      "self",
      "req_id",
      "lora_name",
      "waiting",
      "running"
    ],
    "request_waiting": [
      "self",
      "req_id",
      "lora_name"
    ],
    "request_running": [
      "self",
      "req_id",
      "lora_name"
    ],
    "request_finished": [
      "self",
      "req_id",
      "lora_name"
    ],
    "update_scheduler_stats": [
      "self",
      "scheduler_stats"
    ]
  },
  "Metric": {},
  "Vector": {},
  "Gauge": {},
  "Histogram": {},
  "get_metrics_snapshot": [],
  "_get_samples": [
    "metric",
    "suffix"
  ],
  "_strip_label": [
    "labels",
    "key_to_remove"
  ],
  "_digest_histogram": [
    "bucket_samples",
    "count_samples",
    "sum_samples"
  ],
  "_digest_num_accepted_by_pos_samples": [
    "samples"
  ],
  "PerEngineStatLoggerFactory": [],
  "AggregateStatLoggerFactory": [],
  "StatLoggerFactory": [],
  "StatLoggerBase": {
    "__init__": [
      "self",
      "vllm_config",
      "engine_index"
    ],
    "record": [
      "self",
      "scheduler_stats",
      "iteration_stats",
      "mm_cache_stats",
      "engine_idx"
    ],
    "log_engine_initialized": [
      "self"
    ],
    "log": [
      "self"
    ],
    "record_sleep_state": [
      "self",
      "is_awake",
      "level"
    ]
  },
  "load_stat_logger_plugin_factories": [],
  "AggregateStatLoggerBase": {
    "__init__": [
      "self",
      "vllm_config",
      "engine_indexes"
    ]
  },
  "LoggingStatLogger": {
    "__init__": [
      "self",
      "vllm_config",
      "engine_index"
    ],
    "_reset": [
      "self",
      "now"
    ],
    "_enable_perf_stats": [
      "self"
    ],
    "_track_iteration_stats": [
      "self",
      "iteration_stats"
    ],
    "_get_throughput": [
      "self",
      "tracked_stats",
      "now"
    ],
    "log_prefix": [
      "self"
    ],
    "record": [
      "self",
      "scheduler_stats",
      "iteration_stats",
      "mm_cache_stats",
      "engine_idx"
    ],
    "_update_stats": [
      "self"
    ],
    "aggregate_scheduler_stats": [
      "self"
    ],
    "log": [
      "self"
    ],
    "log_engine_initialized": [
      "self"
    ]
  },
  "AggregatedLoggingStatLogger": {
    "__init__": [
      "self",
      "vllm_config",
      "engine_indexes"
    ],
    "log_prefix": [
      "self"
    ],
    "_enable_perf_stats": [
      "self"
    ],
    "record": [
      "self",
      "scheduler_stats",
      "iteration_stats",
      "mm_cache_stats",
      "engine_idx"
    ],
    "aggregate_scheduler_stats": [
      "self"
    ],
    "log": [
      "self"
    ],
    "log_engine_initialized": [
      "self"
    ]
  },
  "PerEngineStatLoggerAdapter": {
    "__init__": [
      "self",
      "vllm_config",
      "engine_indexes",
      "per_engine_stat_logger_factory"
    ],
    "record": [
      "self",
      "scheduler_stats",
      "iteration_stats",
      "mm_cache_stats",
      "engine_idx"
    ],
    "log": [
      "self"
    ],
    "log_engine_initialized": [
      "self"
    ]
  },
  "PrometheusStatLogger": {
    "_gauge_cls": [],
    "_counter_cls": [],
    "_histogram_cls": [],
    "_spec_decoding_cls": [],
    "_kv_connector_cls": [],
    "__init__": [
      "self",
      "vllm_config",
      "engine_indexes"
    ],
    "log_metrics_info": [
      "self",
      "type",
      "config_obj"
    ],
    "record": [
      "self",
      "scheduler_stats",
      "iteration_stats",
      "mm_cache_stats",
      "engine_idx"
    ],
    "record_sleep_state": [
      "self",
      "sleep",
      "level"
    ],
    "log_engine_initialized": [
      "self"
    ]
  },
  "make_per_engine": [
    "metric",
    "engine_idxs",
    "model_name"
  ],
  "build_buckets": [
    "mantissa_lst",
    "max_value"
  ],
  "build_1_2_5_buckets": [
    "max_value"
  ],
  "StatLoggerManager": {
    "__init__": [
      "self",
      "vllm_config",
      "engine_idxs",
      "custom_stat_loggers",
      "enable_default_loggers",
      "aggregate_engine_logging",
      "client_count"
    ],
    "record": [
      "self",
      "scheduler_stats",
      "iteration_stats",
      "mm_cache_stats",
      "engine_idx"
    ],
    "record_sleep_state": [
      "self",
      "sleep",
      "level"
    ],
    "log": [
      "self"
    ],
    "log_engine_initialized": [
      "self"
    ]
  },
  "InvalidComponent": {},
  "DebugPerfStats": {},
  "PerfStats": {},
  "ExecutionContext": {
    "add": [
      "self",
      "num_tokens",
      "context_len",
      "is_prefill"
    ],
    "total_num_tokens": [
      "self"
    ],
    "total_token_context_product": [
      "self"
    ],
    "from_single_request": [
      "cls",
      "num_tokens",
      "context_len",
      "is_prefill"
    ]
  },
  "ParsedArgs": {
    "__getattr__": [
      "self",
      "name"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "model_dump": [
      "self"
    ]
  },
  "Parser": {
    "parse": [
      "self",
      "args",
      "vllm_config"
    ]
  },
  "ParserChain": {
    "__init__": [
      "self"
    ],
    "add_parser": [
      "self",
      "parser"
    ],
    "parse": [
      "self",
      "vllm_config"
    ]
  },
  "ComponentMetrics": {
    "component_type": [
      "cls"
    ],
    "get_parser": [
      "cls"
    ],
    "__init_subclass__": [
      "cls"
    ],
    "from_vllm_config": [
      "cls",
      "vllm_config"
    ],
    "registered_metrics": [
      "cls"
    ],
    "get_num_flops_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_read_bytes_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_write_bytes_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_num_flops": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_read_bytes": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_write_bytes": [
      "self",
      "ctx",
      "per_gpu"
    ]
  },
  "BaseConfigParser": {
    "parse": [
      "self",
      "args",
      "vllm_config"
    ]
  },
  "BaseAttentionConfigParser": {
    "parse": [
      "self",
      "args",
      "vllm_config"
    ]
  },
  "AttentionQuantizationConfigParser": {
    "parse": [
      "self",
      "args",
      "vllm_config"
    ]
  },
  "AttentionMetrics": {
    "component_type": [
      "cls"
    ],
    "get_parser": [
      "cls"
    ],
    "get_num_flops_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_read_bytes_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_write_bytes_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ]
  },
  "BaseFfnConfigParser": {
    "parse": [
      "self",
      "args",
      "vllm_config"
    ]
  },
  "FfnParallelParser": {
    "parse": [
      "self",
      "args",
      "vllm_config"
    ]
  },
  "InterleaveMoeLayerStepParser": {
    "parse": [
      "self",
      "args",
      "vllm_config"
    ]
  },
  "MoeLayerFreqParser": {
    "parse": [
      "self",
      "args",
      "vllm_config"
    ]
  },
  "FfnQuantizationConfigParser": {
    "parse": [
      "self",
      "args",
      "vllm_config"
    ]
  },
  "FfnMetrics": {
    "validate_moe_fields": [
      "self"
    ],
    "component_type": [
      "cls"
    ],
    "get_parser": [
      "cls"
    ],
    "get_num_flops_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_read_bytes_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_write_bytes_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ]
  },
  "UnembedMetrics": {
    "component_type": [
      "cls"
    ],
    "get_parser": [
      "cls"
    ],
    "get_num_flops_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_read_bytes_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_write_bytes_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ]
  },
  "ModelMetrics": {
    "__init__": [
      "self",
      "vllm_config"
    ],
    "is_enabled": [
      "self"
    ],
    "get_num_flops": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_read_bytes": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_write_bytes": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_num_flops_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_read_bytes_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_write_bytes_breakdown": [
      "self",
      "ctx",
      "per_gpu"
    ],
    "get_step_perf_stats_per_gpu": [
      "self",
      "scheduler_output"
    ]
  },
  "PerfMetricsDebugLogging": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "observe": [
      "self",
      "debug_stats"
    ],
    "log": [
      "self",
      "log_fn",
      "log_prefix",
      "delta_time"
    ]
  },
  "PerfMetricsLogging": {
    "__init__": [
      "self",
      "vllm_config"
    ],
    "reset": [
      "self"
    ],
    "observe": [
      "self",
      "perf_stats"
    ],
    "log": [
      "self",
      "log_fn",
      "log_prefix"
    ]
  },
  "get_required": [
    "obj",
    "attr"
  ],
  "getattr_from_list": [
    "obj",
    "attrs",
    "default"
  ],
  "_get_replica_id": [],
  "RayPrometheusMetric": {
    "__init__": [
      "self"
    ],
    "_get_tag_keys": [
      "labelnames"
    ],
    "labels": [
      "self"
    ],
    "_get_sanitized_opentelemetry_name": [
      "name"
    ]
  },
  "RayGaugeWrapper": {
    "__init__": [
      "self",
      "name",
      "documentation",
      "labelnames",
      "multiprocess_mode"
    ],
    "set": [
      "self",
      "value"
    ],
    "set_to_current_time": [
      "self"
    ]
  },
  "RayCounterWrapper": {
    "__init__": [
      "self",
      "name",
      "documentation",
      "labelnames"
    ],
    "inc": [
      "self",
      "value"
    ]
  },
  "RayHistogramWrapper": {
    "__init__": [
      "self",
      "name",
      "documentation",
      "labelnames",
      "buckets"
    ],
    "observe": [
      "self",
      "value"
    ]
  },
  "RaySpecDecodingProm": {
    "_counter_cls": []
  },
  "RayKVConnectorPrometheus": {
    "_gauge_cls": [],
    "_counter_cls": [],
    "_histogram_cls": []
  },
  "RayPrometheusStatLogger": {
    "_gauge_cls": [],
    "_counter_cls": [],
    "_histogram_cls": [],
    "_spec_decoding_cls": [],
    "_kv_connector_cls": [],
    "_unregister_vllm_metrics": []
  },
  "setup_multiprocess_prometheus": [],
  "get_prometheus_registry": [],
  "unregister_vllm_metrics": [],
  "shutdown_prometheus": [],
  "StructuredOutputRequest": {
    "from_sampling_params": [
      "sampling_params"
    ],
    "_check_grammar_completion": [
      "self"
    ],
    "is_grammar_ready": [
      "self"
    ],
    "grammar": [
      "self",
      "grammar"
    ],
    "structured_output_key": [
      "self"
    ]
  },
  "get_structured_output_key": [
    "params"
  ],
  "StructuredOutputOptions": {
    "JSON": [],
    "JSON_OBJECT": [],
    "REGEX": [],
    "GRAMMAR": [],
    "CHOICE": [],
    "STRUCTURAL_TAG": []
  },
  "StructuredOutputKey": [],
  "StructuredOutputGrammar": {
    "accept_tokens": [
      "self",
      "request_id",
      "tokens"
    ],
    "validate_tokens": [
      "self",
      "tokens"
    ],
    "rollback": [
      "self",
      "num_tokens"
    ],
    "fill_bitmask": [
      "self",
      "bitmask",
      "batch_index"
    ],
    "is_terminated": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "StructuredOutputBackend": {
    "compile_grammar": [
      "self",
      "request_type",
      "grammar_spec"
    ],
    "allocate_token_bitmask": [
      "self",
      "max_num_seqs"
    ],
    "destroy": [
      "self"
    ]
  },
  "CACHE": [],
  "apply_grammar_bitmask": [
    "scheduler_output",
    "grammar_output",
    "input_batch",
    "logits"
  ],
  "OutlinesVocabulary": {
    "__init__": [
      "self",
      "vocabulary"
    ]
  },
  "get_outlines_cache_path": [],
  "get_outlines_cache": [],
  "re_llama_byte_token": [],
  "re_replacement_seq": [],
  "_reduced_vocabulary": [
    "tokenizer",
    "eos_token_id"
  ],
  "get_outlines_vocabulary": [
    "tokenizer"
  ],
  "grammar_is_likely_lark": [
    "grammar_str"
  ],
  "convert_lark_to_ebnf": [
    "grammar_str"
  ],
  "choice_as_grammar": [
    "choice"
  ],
  "StructuredOutputManager": {
    "__init__": [
      "self",
      "vllm_config"
    ],
    "grammar_init": [
      "self",
      "request"
    ],
    "_create_grammar": [
      "self",
      "request"
    ],
    "_fill_bitmasks": [
      "self",
      "batch"
    ],
    "_async_submit_fill_bitmask": [
      "self",
      "batch"
    ],
    "grammar_bitmask": [
      "self",
      "requests",
      "structured_output_request_ids",
      "scheduled_spec_decode_tokens"
    ],
    "should_fill_bitmask": [
      "self",
      "request"
    ],
    "should_advance": [
      "self",
      "request"
    ],
    "clear_backend": [
      "self"
    ]
  },
  "XgrammarBackend": {
    "__post_init__": [
      "self"
    ],
    "compile_grammar": [
      "self",
      "request_type",
      "grammar_spec"
    ],
    "allocate_token_bitmask": [
      "self",
      "max_num_seqs"
    ],
    "destroy": [
      "self"
    ]
  },
  "XgrammarGrammar": {
    "accept_tokens": [
      "self",
      "request_id",
      "tokens"
    ],
    "validate_tokens": [
      "self",
      "tokens"
    ],
    "rollback": [
      "self",
      "num_tokens"
    ],
    "fill_bitmask": [
      "self",
      "bitmask",
      "idx"
    ],
    "is_terminated": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "STRING_SUPPORTED_FORMATS": [],
  "has_xgrammar_unsupported_json_features": [
    "schema"
  ],
  "validate_xgrammar_grammar": [
    "sampling_params"
  ],
  "_cached_build_vllm_token_enforcer_tokenizer_data": [
    "tokenizer",
    "vocab_size"
  ],
  "LMFormatEnforcerGrammar": {
    "accept_tokens": [
      "self",
      "request_id",
      "tokens"
    ],
    "validate_tokens": [
      "self",
      "tokens"
    ],
    "rollback": [
      "self",
      "num_tokens"
    ],
    "fill_bitmask": [
      "self",
      "bitmask",
      "batch_index"
    ],
    "is_terminated": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "LMFormatEnforcerBackend": {
    "__post_init__": [
      "self"
    ],
    "compile_grammar": [
      "self",
      "request_type",
      "grammar_spec"
    ],
    "allocate_token_bitmask": [
      "self",
      "max_num_seqs"
    ],
    "destroy": [
      "self"
    ]
  },
  "validate_structured_output_request_lm_format_enforcer": [
    "params"
  ],
  "OutlinesBackend": {
    "__post_init__": [
      "self"
    ],
    "_compile_index": [
      "self",
      "regex_string",
      "vocabulary"
    ],
    "compile_grammar": [
      "self",
      "request_type",
      "grammar_spec"
    ],
    "allocate_token_bitmask": [
      "self",
      "max_num_seqs"
    ],
    "destroy": [
      "self"
    ]
  },
  "OutlinesGrammar": {
    "accept_tokens": [
      "self",
      "request_id",
      "tokens"
    ],
    "rollback": [
      "self",
      "num_tokens"
    ],
    "validate_tokens": [
      "self",
      "tokens"
    ],
    "fill_bitmask": [
      "self",
      "bitmask",
      "idx"
    ],
    "is_terminated": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "validate_structured_output_request_outlines": [
    "params"
  ],
  "_prefix_needs_context": [
    "parsed"
  ],
  "_check_unsupported": [
    "parsed"
  ],
  "validate_regex_is_buildable": [
    "pattern"
  ],
  "_walk_json_for_additional_properties": [
    "data"
  ],
  "has_guidance_unsupported_json_features": [
    "schema"
  ],
  "process_for_additional_properties": [
    "guide_json"
  ],
  "GuidanceBackend": {
    "__post_init__": [
      "self"
    ],
    "compile_grammar": [
      "self",
      "request_type",
      "grammar_spec"
    ],
    "allocate_token_bitmask": [
      "self",
      "max_num_seqs"
    ],
    "destroy": [
      "self"
    ]
  },
  "GuidanceGrammar": {
    "check_error": [
      "self"
    ],
    "accept_tokens": [
      "self",
      "request_id",
      "tokens"
    ],
    "validate_tokens": [
      "self",
      "tokens"
    ],
    "rollback": [
      "self",
      "num_tokens"
    ],
    "fill_bitmask": [
      "self",
      "bitmask",
      "idx"
    ],
    "is_terminated": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "serialize_guidance_grammar": [
    "request_type",
    "grammar_spec",
    "disable_any_whitespace",
    "disable_additional_properties"
  ],
  "validate_guidance_grammar": [
    "sampling_params",
    "tokenizer"
  ],
  "MAX_SPEC_LEN": [],
  "RejectionSampler": {
    "__init__": [
      "self",
      "sampler"
    ],
    "forward": [
      "self",
      "metadata",
      "draft_probs",
      "logits",
      "sampling_metadata"
    ],
    "_get_logprobs_tensors": [
      "self",
      "max_num_logprobs",
      "metadata",
      "logits",
      "target_logits",
      "bonus_logits",
      "sampled_token_ids"
    ],
    "parse_output": [
      "output_token_ids",
      "vocab_size",
      "discard_req_indices",
      "logprobs_tensors"
    ],
    "apply_logits_processors": [
      "self",
      "logits",
      "sampling_metadata",
      "metadata"
    ],
    "apply_penalties": [
      "logits",
      "sampling_metadata",
      "metadata",
      "repeat_indices",
      "output_token_ids"
    ],
    "_combine_outputs_with_spec_tokens": [
      "output_token_ids",
      "spec_token_ids"
    ]
  },
  "rejection_sample": [
    "draft_token_ids",
    "num_draft_tokens",
    "max_spec_len",
    "cu_num_draft_tokens",
    "draft_probs",
    "target_probs",
    "bonus_token_ids",
    "sampling_metadata"
  ],
  "apply_sampling_constraints": [
    "logits",
    "cu_num_draft_tokens",
    "sampling_metadata"
  ],
  "expand_batch_to_tokens": [
    "x",
    "cu_num_tokens",
    "num_tokens",
    "replace_from",
    "replace_to"
  ],
  "generate_uniform_probs": [
    "num_tokens",
    "num_draft_tokens",
    "generators",
    "device"
  ],
  "sample_recovered_tokens": [
    "max_spec_len",
    "num_draft_tokens",
    "cu_num_draft_tokens",
    "draft_token_ids",
    "draft_probs",
    "target_probs",
    "sampling_metadata",
    "device"
  ],
  "rejection_greedy_sample_kernel": [
    "output_token_ids_ptr",
    "cu_num_draft_tokens_ptr",
    "draft_token_ids_ptr",
    "target_argmax_ptr",
    "bonus_token_ids_ptr",
    "is_greedy_ptr",
    "max_spec_len"
  ],
  "rejection_random_sample_kernel": [
    "output_token_ids_ptr",
    "cu_num_draft_tokens_ptr",
    "draft_token_ids_ptr",
    "draft_probs_ptr",
    "target_probs_ptr",
    "bonus_token_ids_ptr",
    "recovered_token_ids_ptr",
    "uniform_probs_ptr",
    "is_greedy_ptr",
    "max_spec_len",
    "vocab_size",
    "NO_DRAFT_PROBS"
  ],
  "expand_kernel": [
    "output_ptr",
    "input_ptr",
    "cu_num_tokens_ptr",
    "replace_from",
    "replace_to",
    "MAX_NUM_TOKENS"
  ],
  "sample_recovered_tokens_kernel": [
    "output_token_ids_ptr",
    "cu_num_draft_tokens_ptr",
    "draft_token_ids_ptr",
    "draft_probs_ptr",
    "target_probs_ptr",
    "q_ptr",
    "vocab_size",
    "PADDED_VOCAB_SIZE",
    "NO_DRAFT_PROBS"
  ],
  "SamplingMetadata": {},
  "Sampler": {
    "__init__": [
      "self",
      "logprobs_mode"
    ],
    "forward": [
      "self",
      "logits",
      "sampling_metadata",
      "predict_bonus_token",
      "logprobs_mode_override"
    ],
    "apply_temperature": [
      "logits",
      "temp",
      "all_random"
    ],
    "greedy_sample": [
      "logits"
    ],
    "sample": [
      "self",
      "logits",
      "sampling_metadata",
      "logprobs_mode_override"
    ],
    "compute_logprobs": [
      "logits"
    ],
    "gather_logprobs": [
      "logprobs",
      "num_logprobs",
      "token_ids"
    ],
    "_combine_outputs_with_spec_tokens": [
      "output_token_ids",
      "spec_token_ids"
    ],
    "apply_logits_processors": [
      "self",
      "logits",
      "sampling_metadata",
      "predict_bonus_token"
    ],
    "apply_penalties": [
      "logits",
      "sampling_metadata",
      "output_token_ids"
    ]
  },
  "_SMALLEST_LOGIT": [],
  "_apply_bad_words_single_batch": [
    "logits",
    "bad_words_token_ids",
    "past_tokens_ids"
  ],
  "apply_bad_words": [
    "logits",
    "bad_words_token_ids",
    "past_tokens_ids"
  ],
  "apply_bad_words_with_drafts": [
    "logits",
    "bad_words_token_ids",
    "past_tokens_ids",
    "num_draft_tokens"
  ],
  "batched_count_greater_than": [
    "x",
    "values"
  ],
  "TopKTopPSampler": {
    "__init__": [
      "self",
      "logprobs_mode"
    ],
    "forward_native": [
      "self",
      "logits",
      "generators",
      "k",
      "p"
    ],
    "forward_cuda": [
      "self",
      "logits",
      "generators",
      "k",
      "p"
    ],
    "forward_cpu": [
      "self",
      "logits",
      "generators",
      "k",
      "p"
    ],
    "forward_hip": [
      "self",
      "logits",
      "generators",
      "k",
      "p"
    ],
    "aiter_sample": [
      "self",
      "logits",
      "k",
      "p",
      "generators"
    ]
  },
  "compiled_random_sample": [
    "logits"
  ],
  "apply_top_k_top_p": [
    "logits",
    "k",
    "p"
  ],
  "apply_top_k_only": [
    "logits",
    "k"
  ],
  "random_sample": [
    "probs",
    "generators"
  ],
  "flashinfer_sample": [
    "logits",
    "k",
    "p",
    "generators"
  ],
  "_to_tensor_scalar_tuple": [
    "x"
  ],
  "apply_all_penalties": [
    "logits",
    "prompt_token_ids",
    "presence_penalties",
    "frequency_penalties",
    "repetition_penalties",
    "output_token_ids"
  ],
  "_convert_to_tensors": [
    "output_token_ids",
    "vocab_size",
    "device"
  ],
  "MoveDirectionality": {
    "UNIDIRECTIONAL": [],
    "SWAP": []
  },
  "RemovedRequest": [],
  "AddedRequest": [],
  "MovedRequest": [],
  "BatchUpdate": {},
  "BatchUpdateBuilder": {
    "__init__": [
      "self",
      "removed",
      "added",
      "moved"
    ],
    "_ensure_removed_sorted": [
      "self"
    ],
    "removed": [
      "self"
    ],
    "removed_append": [
      "self",
      "index"
    ],
    "has_removed": [
      "self"
    ],
    "peek_removed": [
      "self"
    ],
    "pop_removed": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "get_and_reset": [
      "self",
      "batch_size"
    ]
  },
  "STR_POOLING_REJECTS_LOGITSPROCS": [],
  "STR_SPEC_DEC_REJECTS_LOGITSPROCS": [],
  "LOGITSPROCS_GROUP": [],
  "_load_logitsprocs_plugins": [],
  "_load_logitsprocs_by_fqcns": [
    "logits_processors"
  ],
  "_load_custom_logitsprocs": [
    "logits_processors"
  ],
  "build_logitsprocs": [
    "vllm_config",
    "device",
    "is_pin_memory",
    "is_pooling_model",
    "custom_logitsprocs"
  ],
  "cached_load_custom_logitsprocs": [],
  "validate_logits_processors_parameters": [
    "logits_processors",
    "sampling_params"
  ],
  "AdapterLogitsProcessor": {
    "__init__": [
      "self",
      "vllm_config",
      "device",
      "is_pin_memory"
    ],
    "new_req_logits_processor": [
      "self",
      "params"
    ],
    "_new_state": [
      "self",
      "params",
      "prompt_ids",
      "output_ids"
    ],
    "update_state": [
      "self",
      "batch_update"
    ],
    "apply": [
      "self",
      "logits"
    ]
  },
  "MinPLogitsProcessor": {
    "__init__": [
      "self",
      "vllm_config",
      "device",
      "is_pin_memory"
    ],
    "is_argmax_invariant": [
      "self"
    ],
    "get_min_p_by_index": [
      "self",
      "index"
    ],
    "update_state": [
      "self",
      "batch_update"
    ],
    "apply": [
      "self",
      "logits"
    ]
  },
  "LogitBiasLogitsProcessor": {
    "__init__": [
      "self",
      "_",
      "device",
      "is_pin_memory"
    ],
    "is_argmax_invariant": [
      "self"
    ],
    "update_state": [
      "self",
      "batch_update"
    ],
    "_device_tensor": [
      "self",
      "data",
      "dtype"
    ],
    "apply": [
      "self",
      "logits"
    ]
  },
  "MinTokensLogitsProcessor": {
    "__init__": [
      "self",
      "vllm_config",
      "device",
      "is_pin_memory"
    ],
    "is_argmax_invariant": [
      "self"
    ],
    "add_request": [
      "params",
      "_",
      "output_tok_ids"
    ],
    "update_state": [
      "self",
      "batch_update"
    ],
    "_device_tensor": [
      "self",
      "data",
      "dtype"
    ],
    "apply": [
      "self",
      "logits"
    ]
  },
  "process_dict_updates": [
    "req_entries",
    "batch_update",
    "new_state"
  ],
  "pin_memory": [],
  "PoolingCursor": {
    "__getitem__": [
      "self",
      "indices"
    ],
    "is_partial_prefill": [
      "self"
    ],
    "is_finished": [
      "self"
    ]
  },
  "PoolingStates": {
    "__init__": [
      "self"
    ],
    "clean": [
      "self"
    ]
  },
  "PoolingMetadata": {
    "__post_init__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "indices"
    ],
    "get_prompt_token_ids": [
      "self"
    ],
    "get_pooling_cursor": [
      "self"
    ],
    "build_pooling_cursor": [
      "self",
      "num_scheduled_tokens_np",
      "seq_lens_cpu",
      "device"
    ]
  },
  "ParentRequest": {
    "__init__": [
      "self",
      "request"
    ],
    "_get_child_sampling_params": [
      "self",
      "index"
    ],
    "get_child_info": [
      "self",
      "index"
    ],
    "n": [
      "self"
    ],
    "get_outputs": [
      "self",
      "child_request_id",
      "completion_output"
    ],
    "observe_num_generation_tokens": [
      "self",
      "num_generation_tokens"
    ],
    "observe_finished_request": [
      "parent_req",
      "iteration_stats",
      "num_generation_tokens"
    ]
  },
  "POLLING_TIMEOUT_S": [],
  "HANDSHAKE_TIMEOUT_MINS": [],
  "EngineCore": {
    "__init__": [
      "self",
      "vllm_config",
      "executor_class",
      "log_stats",
      "executor_fail_callback",
      "include_finished_set"
    ],
    "_initialize_kv_caches": [
      "self",
      "vllm_config"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "add_request": [
      "self",
      "request",
      "request_wave"
    ],
    "abort_requests": [
      "self",
      "request_ids"
    ],
    "log_error_detail": [
      "self",
      "scheduler_output"
    ],
    "log_iteration_details": [
      "self",
      "scheduler_output"
    ],
    "step": [
      "self"
    ],
    "post_step": [
      "self",
      "model_executed"
    ],
    "step_with_batch_queue": [
      "self"
    ],
    "_process_aborts_queue": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "profile": [
      "self",
      "is_start"
    ],
    "reset_mm_cache": [
      "self"
    ],
    "reset_prefix_cache": [
      "self",
      "reset_running_requests",
      "reset_connector"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wake_up": [
      "self",
      "tags"
    ],
    "is_sleeping": [
      "self"
    ],
    "execute_dummy_batch": [
      "self"
    ],
    "add_lora": [
      "self",
      "lora_request"
    ],
    "remove_lora": [
      "self",
      "lora_id"
    ],
    "list_loras": [
      "self"
    ],
    "pin_lora": [
      "self",
      "lora_id"
    ],
    "save_sharded_state": [
      "self",
      "path",
      "pattern",
      "max_size"
    ],
    "collective_rpc": [
      "self",
      "method",
      "timeout",
      "args",
      "kwargs"
    ],
    "preprocess_add_request": [
      "self",
      "request"
    ]
  },
  "EngineCoreProc": {
    "ENGINE_CORE_DEAD": [],
    "__init__": [
      "self",
      "vllm_config",
      "local_client",
      "handshake_address",
      "executor_class",
      "log_stats",
      "client_handshake_address"
    ],
    "_perform_handshakes": [
      "self",
      "handshake_address",
      "identity",
      "local_client",
      "vllm_config",
      "client_handshake_address"
    ],
    "_perform_handshake": [
      "self",
      "ctx",
      "handshake_address",
      "identity",
      "local_client",
      "headless",
      "vllm_config",
      "parallel_config_to_update"
    ],
    "startup_handshake": [
      "handshake_socket",
      "local_client",
      "headless",
      "parallel_config"
    ],
    "run_engine_core": [],
    "_init_data_parallel": [
      "self",
      "vllm_config"
    ],
    "run_busy_loop": [
      "self"
    ],
    "_process_input_queue": [
      "self"
    ],
    "_process_engine_step": [
      "self"
    ],
    "_handle_client_request": [
      "self",
      "request_type",
      "request"
    ],
    "_convert_msgspec_args": [
      "method",
      "args"
    ],
    "_send_engine_dead": [
      "self"
    ],
    "process_input_sockets": [
      "self",
      "input_addresses",
      "coord_input_address",
      "identity",
      "ready_event"
    ],
    "process_output_sockets": [
      "self",
      "output_paths",
      "coord_output_path",
      "engine_index"
    ],
    "_handle_request_preproc_error": [
      "self",
      "request"
    ]
  },
  "DPEngineCoreProc": {
    "__init__": [
      "self",
      "vllm_config",
      "local_client",
      "handshake_address",
      "executor_class",
      "log_stats",
      "client_handshake_address"
    ],
    "_init_data_parallel": [
      "self",
      "vllm_config"
    ],
    "shutdown": [
      "self"
    ],
    "add_request": [
      "self",
      "request",
      "request_wave"
    ],
    "_handle_client_request": [
      "self",
      "request_type",
      "request"
    ],
    "_maybe_publish_request_counts": [
      "self"
    ],
    "run_busy_loop": [
      "self"
    ],
    "_has_global_unfinished_reqs": [
      "self",
      "local_unfinished"
    ],
    "reinitialize_distributed": [
      "self",
      "reconfig_request"
    ]
  },
  "EngineCoreActorMixin": {
    "__init__": [
      "self",
      "vllm_config",
      "addresses",
      "dp_rank",
      "local_dp_rank"
    ],
    "_set_visible_devices": [
      "self",
      "vllm_config",
      "local_dp_rank"
    ],
    "_set_cuda_visible_devices": [
      "self",
      "vllm_config",
      "local_dp_rank",
      "device_control_env_var"
    ],
    "_perform_handshakes": [
      "self",
      "handshake_address",
      "identity",
      "local_client",
      "vllm_config",
      "client_handshake_address"
    ],
    "wait_for_init": [
      "self"
    ],
    "run": [
      "self"
    ]
  },
  "DPMoEEngineCoreActor": {
    "__init__": [
      "self",
      "vllm_config",
      "local_client",
      "addresses",
      "executor_class",
      "log_stats",
      "dp_rank",
      "local_dp_rank"
    ]
  },
  "EngineCoreActor": {
    "__init__": [
      "self",
      "vllm_config",
      "local_client",
      "addresses",
      "executor_class",
      "log_stats",
      "dp_rank",
      "local_dp_rank"
    ]
  },
  "EMPTY_CPU_TENSOR": [],
  "RequestOutputCollector": {
    "__init__": [
      "self",
      "output_kind",
      "request_id"
    ],
    "put": [
      "self",
      "output"
    ],
    "get": [
      "self"
    ],
    "get_nowait": [
      "self"
    ],
    "close": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "OutputProcessorOutput": {},
  "RequestState": {
    "__init__": [
      "self",
      "request_id",
      "external_req_id",
      "parent_req",
      "request_index",
      "lora_request",
      "output_kind",
      "prompt",
      "prompt_token_ids",
      "prompt_embeds",
      "logprobs_processor",
      "detokenizer",
      "max_tokens_param",
      "arrival_time",
      "queue",
      "log_stats",
      "stream_interval",
      "top_p",
      "n",
      "temperature",
      "stream_input"
    ],
    "apply_streaming_update": [
      "self",
      "update"
    ],
    "from_new_request": [
      "cls",
      "tokenizer",
      "request",
      "prompt",
      "parent_req",
      "request_index",
      "queue",
      "log_stats",
      "stream_interval"
    ],
    "make_request_output": [
      "self",
      "new_token_ids",
      "pooling_output",
      "finish_reason",
      "stop_reason",
      "kv_transfer_params",
      "routed_experts"
    ],
    "_new_request_output": [
      "self",
      "external_req_id",
      "outputs",
      "finished",
      "kv_transfer_params"
    ],
    "_new_completion_output": [
      "self",
      "token_ids",
      "finish_reason",
      "stop_reason",
      "routed_experts"
    ],
    "_new_pooling_output": [
      "self",
      "pooling_output"
    ]
  },
  "OutputProcessor": {
    "__init__": [
      "self",
      "tokenizer",
      "log_stats",
      "stream_interval"
    ],
    "get_num_unfinished_requests": [
      "self"
    ],
    "has_unfinished_requests": [
      "self"
    ],
    "wait_for_requests_to_drain": [
      "self"
    ],
    "propagate_error": [
      "self",
      "e"
    ],
    "abort_requests": [
      "self",
      "request_ids",
      "internal"
    ],
    "add_request": [
      "self",
      "request",
      "prompt",
      "parent_req",
      "request_index",
      "queue"
    ],
    "_update_streaming_request_state": [
      "self",
      "req_state",
      "request",
      "prompt"
    ],
    "process_outputs": [
      "self",
      "engine_core_outputs",
      "engine_core_timestamp",
      "iteration_stats"
    ],
    "_finish_request": [
      "self",
      "req_state"
    ],
    "update_scheduler_stats": [
      "self",
      "scheduler_stats"
    ],
    "do_tracing": [
      "self",
      "engine_core_output",
      "req_state",
      "iteration_stats"
    ],
    "_update_stats_from_output": [
      "self",
      "req_state",
      "engine_core_output",
      "engine_core_timestamp",
      "iteration_stats"
    ],
    "_update_stats_from_finished": [
      "self",
      "req_state",
      "finish_reason",
      "iteration_stats"
    ]
  },
  "EngineIdentity": [],
  "EngineCoreClient": {
    "make_client": [
      "multiprocess_mode",
      "asyncio_mode",
      "vllm_config",
      "executor_class",
      "log_stats"
    ],
    "make_async_mp_client": [
      "vllm_config",
      "executor_class",
      "log_stats",
      "client_addresses",
      "client_count",
      "client_index"
    ],
    "shutdown": [
      "self"
    ],
    "get_output": [
      "self"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "add_request": [
      "self",
      "request"
    ],
    "profile": [
      "self",
      "is_start"
    ],
    "reset_mm_cache": [
      "self"
    ],
    "reset_prefix_cache": [
      "self",
      "reset_running_requests",
      "reset_connector"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wake_up": [
      "self",
      "tags"
    ],
    "is_sleeping": [
      "self"
    ],
    "execute_dummy_batch": [
      "self"
    ],
    "execute_dummy_batch_async": [
      "self"
    ],
    "abort_requests": [
      "self",
      "request_ids"
    ],
    "add_lora": [
      "self",
      "lora_request"
    ],
    "remove_lora": [
      "self",
      "lora_id"
    ],
    "list_loras": [
      "self"
    ],
    "pin_lora": [
      "self",
      "lora_id"
    ],
    "save_sharded_state": [
      "self",
      "path",
      "pattern",
      "max_size"
    ],
    "collective_rpc": [
      "self",
      "method",
      "timeout",
      "args",
      "kwargs"
    ],
    "dp_engines_running": [
      "self"
    ],
    "scale_elastic_ep": [
      "self",
      "new_data_parallel_size"
    ],
    "get_output_async": [
      "self"
    ],
    "get_supported_tasks_async": [
      "self"
    ],
    "add_request_async": [
      "self",
      "request"
    ],
    "profile_async": [
      "self",
      "is_start"
    ],
    "reset_mm_cache_async": [
      "self"
    ],
    "reset_prefix_cache_async": [
      "self",
      "reset_running_requests",
      "reset_connector"
    ],
    "sleep_async": [
      "self",
      "level"
    ],
    "wake_up_async": [
      "self",
      "tags"
    ],
    "is_sleeping_async": [
      "self"
    ],
    "abort_requests_async": [
      "self",
      "request_ids"
    ],
    "add_lora_async": [
      "self",
      "lora_request"
    ],
    "remove_lora_async": [
      "self",
      "lora_id"
    ],
    "list_loras_async": [
      "self"
    ],
    "pin_lora_async": [
      "self",
      "lora_id"
    ],
    "save_sharded_state_async": [
      "self",
      "path",
      "pattern",
      "max_size"
    ],
    "collective_rpc_async": [
      "self",
      "method",
      "timeout",
      "args",
      "kwargs"
    ]
  },
  "InprocClient": {
    "__init__": [
      "self"
    ],
    "get_output": [
      "self"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "add_request": [
      "self",
      "request"
    ],
    "abort_requests": [
      "self",
      "request_ids"
    ],
    "shutdown": [
      "self"
    ],
    "profile": [
      "self",
      "is_start"
    ],
    "reset_mm_cache": [
      "self"
    ],
    "reset_prefix_cache": [
      "self",
      "reset_running_requests",
      "reset_connector"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wake_up": [
      "self",
      "tags"
    ],
    "is_sleeping": [
      "self"
    ],
    "execute_dummy_batch": [
      "self"
    ],
    "add_lora": [
      "self",
      "lora_request"
    ],
    "remove_lora": [
      "self",
      "lora_id"
    ],
    "list_loras": [
      "self"
    ],
    "pin_lora": [
      "self",
      "lora_id"
    ],
    "save_sharded_state": [
      "self",
      "path",
      "pattern",
      "max_size"
    ],
    "collective_rpc": [
      "self",
      "method",
      "timeout",
      "args",
      "kwargs"
    ],
    "dp_engines_running": [
      "self"
    ]
  },
  "BackgroundResources": {
    "__call__": [
      "self"
    ],
    "validate_alive": [
      "self",
      "frames"
    ]
  },
  "MPClient": {
    "__init__": [
      "self",
      "asyncio_mode",
      "vllm_config",
      "executor_class",
      "log_stats",
      "client_addresses"
    ],
    "shutdown": [
      "self"
    ],
    "_format_exception": [
      "self",
      "e"
    ],
    "ensure_alive": [
      "self"
    ],
    "add_pending_message": [
      "self",
      "tracker",
      "msg"
    ],
    "free_pending_messages": [
      "self"
    ],
    "dp_engines_running": [
      "self"
    ],
    "start_engine_core_monitor": [
      "self"
    ]
  },
  "_process_utility_output": [
    "output",
    "utility_results"
  ],
  "SyncMPClient": {
    "__init__": [
      "self",
      "vllm_config",
      "executor_class",
      "log_stats"
    ],
    "get_output": [
      "self"
    ],
    "_send_input": [
      "self",
      "request_type",
      "request"
    ],
    "call_utility": [
      "self",
      "method"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "add_request": [
      "self",
      "request"
    ],
    "abort_requests": [
      "self",
      "request_ids"
    ],
    "profile": [
      "self",
      "is_start"
    ],
    "reset_mm_cache": [
      "self"
    ],
    "reset_prefix_cache": [
      "self",
      "reset_running_requests",
      "reset_connector"
    ],
    "add_lora": [
      "self",
      "lora_request"
    ],
    "remove_lora": [
      "self",
      "lora_id"
    ],
    "list_loras": [
      "self"
    ],
    "pin_lora": [
      "self",
      "lora_id"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wake_up": [
      "self",
      "tags"
    ],
    "is_sleeping": [
      "self"
    ],
    "execute_dummy_batch": [
      "self"
    ],
    "collective_rpc": [
      "self",
      "method",
      "timeout",
      "args",
      "kwargs"
    ],
    "save_sharded_state": [
      "self",
      "path",
      "pattern",
      "max_size"
    ]
  },
  "AsyncMPClient": {
    "__init__": [
      "self",
      "vllm_config",
      "executor_class",
      "log_stats",
      "client_addresses",
      "client_count",
      "client_index"
    ],
    "_ensure_output_queue_task": [
      "self"
    ],
    "get_output_async": [
      "self"
    ],
    "_send_input": [
      "self",
      "request_type",
      "request",
      "engine"
    ],
    "_send_input_message": [
      "self",
      "message",
      "engine",
      "objects"
    ],
    "call_utility_async": [
      "self",
      "method"
    ],
    "_call_utility_async": [
      "self",
      "method"
    ],
    "get_supported_tasks_async": [
      "self"
    ],
    "add_request_async": [
      "self",
      "request"
    ],
    "abort_requests_async": [
      "self",
      "request_ids"
    ],
    "profile_async": [
      "self",
      "is_start"
    ],
    "reset_mm_cache_async": [
      "self"
    ],
    "reset_prefix_cache_async": [
      "self",
      "reset_running_requests",
      "reset_connector"
    ],
    "sleep_async": [
      "self",
      "level"
    ],
    "wake_up_async": [
      "self",
      "tags"
    ],
    "is_sleeping_async": [
      "self"
    ],
    "execute_dummy_batch_async": [
      "self"
    ],
    "add_lora_async": [
      "self",
      "lora_request"
    ],
    "remove_lora_async": [
      "self",
      "lora_id"
    ],
    "list_loras_async": [
      "self"
    ],
    "pin_lora_async": [
      "self",
      "lora_id"
    ],
    "save_sharded_state_async": [
      "self",
      "path",
      "pattern",
      "max_size"
    ],
    "collective_rpc_async": [
      "self",
      "method",
      "timeout",
      "args",
      "kwargs"
    ]
  },
  "DPAsyncMPClient": {
    "__init__": [
      "self",
      "vllm_config",
      "executor_class",
      "log_stats",
      "client_addresses",
      "client_count",
      "client_index"
    ],
    "_ensure_stats_update_task": [
      "self"
    ],
    "add_request_async": [
      "self",
      "request"
    ],
    "get_core_engine_for_request": [
      "self",
      "request"
    ]
  },
  "DPLBAsyncMPClient": {
    "__init__": [
      "self",
      "vllm_config",
      "executor_class",
      "log_stats",
      "client_addresses",
      "client_count",
      "client_index"
    ],
    "get_core_engine_for_request": [
      "self",
      "request"
    ],
    "call_utility_async": [
      "self",
      "method"
    ],
    "process_engine_outputs": [
      "self",
      "outputs"
    ],
    "abort_requests_async": [
      "self",
      "request_ids"
    ],
    "_abort_requests": [
      "self",
      "request_ids",
      "engine"
    ],
    "scale_elastic_ep": [
      "self",
      "new_data_parallel_size"
    ],
    "_scale_up_elastic_ep": [
      "self",
      "cur_data_parallel_size",
      "new_data_parallel_size"
    ],
    "_scale_down_elastic_ep": [
      "self",
      "cur_data_parallel_size",
      "new_data_parallel_size"
    ]
  },
  "NONES": [],
  "LogprobsProcessor": {
    "from_new_request": [
      "cls",
      "tokenizer",
      "request"
    ],
    "_update_sample_logprobs": [
      "self",
      "logprobs_lists"
    ],
    "_update_prompt_logprobs": [
      "self",
      "prompt_logprobs_tensors"
    ],
    "pop_prompt_logprobs": [
      "self"
    ],
    "_correct_decoded_token": [
      "self",
      "idx",
      "tokens"
    ],
    "_verify_tokens": [
      "self",
      "decoded_tokens_list",
      "tokens"
    ],
    "update_from_output": [
      "self",
      "output"
    ]
  },
  "InputProcessor": {
    "__init__": [
      "self",
      "vllm_config",
      "mm_registry"
    ],
    "tokenizer": [
      "self"
    ],
    "get_tokenizer": [
      "self"
    ],
    "renderer": [
      "self"
    ],
    "_validate_logprobs": [
      "self",
      "params"
    ],
    "_validate_sampling_params": [
      "self",
      "params"
    ],
    "_validate_logit_bias": [
      "self",
      "params"
    ],
    "_validate_supported_sampling_params": [
      "self",
      "params"
    ],
    "_validate_params": [
      "self",
      "params"
    ],
    "_parse_mm_items": [
      "self",
      "mm_data"
    ],
    "_validate_singleton_mm_uuids": [
      "self",
      "prompt"
    ],
    "_validate_mm_uuids": [
      "self",
      "prompt"
    ],
    "_validate_lora": [
      "self",
      "lora_request"
    ],
    "_validate_structured_output": [
      "self",
      "params"
    ],
    "_extract_singleton_mm_data": [
      "self",
      "prompt"
    ],
    "_extract_mm_data": [
      "self",
      "prompt"
    ],
    "_maybe_build_mm_uuids": [
      "self",
      "request_id",
      "prompt"
    ],
    "_get_mm_identifier": [
      "self",
      "mm_hash",
      "lora_request"
    ],
    "assign_request_id": [
      "request"
    ],
    "process_inputs": [
      "self",
      "request_id",
      "prompt",
      "params",
      "arrival_time",
      "lora_request",
      "tokenization_kwargs",
      "trace_headers",
      "priority",
      "data_parallel_rank",
      "resumable"
    ],
    "_validate_model_inputs": [
      "self",
      "encoder_inputs",
      "decoder_inputs"
    ],
    "_validate_model_input": [
      "self",
      "prompt_inputs"
    ],
    "stat_mm_cache": [
      "self"
    ],
    "clear_mm_cache": [
      "self"
    ],
    "close": [
      "self"
    ]
  },
  "STARTUP_POLL_PERIOD_MS": [],
  "CoreEngineState": {
    "NEW": [],
    "CONNECTED": [],
    "READY": []
  },
  "CoreEngine": {
    "__init__": [
      "self",
      "index",
      "local"
    ]
  },
  "EngineZmqAddresses": {},
  "EngineHandshakeMetadata": {},
  "CoreEngineProcManager": {
    "__init__": [
      "self",
      "target_fn",
      "local_engine_count",
      "start_index",
      "local_start_index",
      "vllm_config",
      "local_client",
      "handshake_address",
      "executor_class",
      "log_stats",
      "client_handshake_address"
    ],
    "close": [
      "self"
    ],
    "join_first": [
      "self"
    ],
    "sentinels": [
      "self"
    ],
    "finished_procs": [
      "self"
    ]
  },
  "set_device_control_env_var": [
    "vllm_config",
    "local_dp_rank"
  ],
  "get_device_indices": [
    "device_control_env_var",
    "local_dp_rank",
    "world_size",
    "local_world_size"
  ],
  "get_prompt_text": [
    "prompt"
  ],
  "CoreEngineActorManager": {
    "__init__": [
      "self",
      "vllm_config",
      "addresses",
      "executor_class",
      "log_stats",
      "placement_groups",
      "local_dp_ranks"
    ],
    "create_dp_placement_groups": [
      "vllm_config"
    ],
    "add_dp_placement_groups": [
      "old_vllm_config",
      "new_data_parallel_size"
    ],
    "scale_up_elastic_ep": [
      "self",
      "cur_vllm_config",
      "new_data_parallel_size"
    ],
    "scale_down_elastic_ep": [
      "self",
      "cur_data_parallel_size",
      "new_data_parallel_size"
    ],
    "get_run_refs": [
      "self"
    ],
    "close": [
      "self"
    ]
  },
  "launch_core_engines": [
    "vllm_config",
    "executor_class",
    "log_stats",
    "num_api_servers"
  ],
  "wait_for_engine_startup": [
    "handshake_socket",
    "addresses",
    "core_engines",
    "parallel_config",
    "coordinated_dp",
    "cache_config",
    "proc_manager",
    "coord_process"
  ],
  "DPCoordinator": {
    "__init__": [
      "self",
      "parallel_config",
      "enable_wave_coordination"
    ],
    "get_stats_publish_address": [
      "self"
    ],
    "get_engine_socket_addresses": [
      "self"
    ],
    "close": [
      "self"
    ]
  },
  "EngineState": {
    "__init__": [
      "self"
    ]
  },
  "DPCoordinatorProc": {
    "__init__": [
      "self",
      "engine_count",
      "min_stats_update_interval_ms",
      "enable_wave_coordination"
    ],
    "run_coordinator": [
      "engine_count",
      "front_publish_address",
      "back_output_address",
      "back_publish_address",
      "min_stats_update_interval_ms",
      "enable_wave_coordination"
    ],
    "process_input_socket": [
      "self",
      "front_publish_address",
      "back_output_address",
      "back_publish_address"
    ],
    "_send_start_wave": [
      "socket",
      "wave",
      "exclude_engine_index"
    ],
    "_get_engine_counts": [
      "self",
      "do_copy"
    ]
  },
  "FINISH_REASON_STRINGS": [],
  "FinishReason": {
    "STOP": [],
    "LENGTH": [],
    "ABORT": [],
    "ERROR": [],
    "__str__": [
      "self"
    ]
  },
  "EngineCoreRequest": {
    "params": [
      "self"
    ]
  },
  "EngineCoreEventType": {
    "QUEUED": [],
    "SCHEDULED": [],
    "PREEMPTED": []
  },
  "EngineCoreEvent": {
    "new_event": [
      "cls",
      "event_type",
      "timestamp"
    ]
  },
  "EngineCoreOutput": {
    "finished": [
      "self"
    ]
  },
  "UtilityOutput": {},
  "EngineCoreOutputs": {
    "__post_init__": [
      "self"
    ]
  },
  "EngineCoreRequestType": {
    "ADD": [],
    "ABORT": [],
    "START_DP_WAVE": [],
    "UTILITY": [],
    "EXECUTOR_FAILED": []
  },
  "ReconfigureDistributedRequest": {},
  "ReconfigureRankType": {
    "KEEP_CURRENT_RANK": [],
    "SHUTDOWN_CURRENT_RANK": []
  },
  "StreamingInput": {},
  "InputStreamError": {
    "__init__": [
      "self",
      "cause"
    ]
  },
  "AsyncLLM": {
    "__init__": [
      "self",
      "vllm_config",
      "executor_class",
      "log_stats",
      "usage_context",
      "mm_registry",
      "use_cached_outputs",
      "log_requests",
      "start_engine_loop",
      "stat_loggers",
      "aggregate_engine_logging",
      "client_addresses",
      "client_count",
      "client_index"
    ],
    "from_vllm_config": [
      "cls",
      "vllm_config",
      "start_engine_loop",
      "usage_context",
      "stat_loggers",
      "enable_log_requests",
      "aggregate_engine_logging",
      "disable_log_stats",
      "client_addresses",
      "client_count",
      "client_index"
    ],
    "from_engine_args": [
      "cls",
      "engine_args",
      "start_engine_loop",
      "usage_context",
      "stat_loggers"
    ],
    "__del__": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "add_request": [
      "self",
      "request_id",
      "prompt",
      "params",
      "arrival_time",
      "lora_request",
      "tokenization_kwargs",
      "trace_headers",
      "priority",
      "data_parallel_rank",
      "prompt_text"
    ],
    "_add_request": [
      "self",
      "request",
      "prompt",
      "parent_req",
      "index",
      "queue"
    ],
    "_add_streaming_input_request": [
      "self",
      "request_id",
      "input_stream",
      "sampling_params",
      "arrival_time",
      "lora_request",
      "tokenization_kwargs",
      "trace_headers",
      "priority",
      "data_parallel_rank"
    ],
    "_validate_streaming_input_sampling_params": [
      "params"
    ],
    "generate": [
      "self",
      "prompt",
      "sampling_params",
      "request_id"
    ],
    "_run_output_handler": [
      "self"
    ],
    "abort": [
      "self",
      "request_id",
      "internal"
    ],
    "pause_generation": [
      "self"
    ],
    "resume_generation": [
      "self"
    ],
    "is_paused": [
      "self"
    ],
    "encode": [
      "self",
      "prompt",
      "pooling_params",
      "request_id",
      "lora_request",
      "trace_headers",
      "priority",
      "truncate_prompt_tokens",
      "tokenization_kwargs"
    ],
    "tokenizer": [
      "self"
    ],
    "get_tokenizer": [
      "self"
    ],
    "renderer": [
      "self"
    ],
    "is_tracing_enabled": [
      "self"
    ],
    "do_log_stats": [
      "self"
    ],
    "check_health": [
      "self"
    ],
    "start_profile": [
      "self"
    ],
    "stop_profile": [
      "self"
    ],
    "reset_mm_cache": [
      "self"
    ],
    "reset_prefix_cache": [
      "self",
      "reset_running_requests",
      "reset_connector"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wake_up": [
      "self",
      "tags"
    ],
    "is_sleeping": [
      "self"
    ],
    "add_lora": [
      "self",
      "lora_request"
    ],
    "remove_lora": [
      "self",
      "lora_id"
    ],
    "list_loras": [
      "self"
    ],
    "pin_lora": [
      "self",
      "lora_id"
    ],
    "collective_rpc": [
      "self",
      "method",
      "timeout",
      "args",
      "kwargs"
    ],
    "wait_for_requests_to_drain": [
      "self",
      "drain_timeout"
    ],
    "scale_elastic_ep": [
      "self",
      "new_data_parallel_size",
      "drain_timeout"
    ],
    "is_running": [
      "self"
    ],
    "is_stopped": [
      "self"
    ],
    "errored": [
      "self"
    ],
    "dead_error": [
      "self"
    ]
  },
  "EngineGenerateError": {},
  "EngineDeadError": {
    "__init__": [
      "self"
    ]
  },
  "USE_FAST_DETOKENIZER": [],
  "INVALID_PREFIX_ERR_MSG": [],
  "IncrementalDetokenizer": {
    "__init__": [
      "self"
    ],
    "output_token_ids": [
      "self"
    ],
    "update": [
      "self",
      "new_token_ids",
      "stop_terminated"
    ],
    "get_next_output_text": [
      "self",
      "finished",
      "delta"
    ],
    "from_new_request": [
      "cls",
      "tokenizer",
      "request"
    ]
  },
  "BaseIncrementalDetokenizer": {
    "__init__": [
      "self",
      "request"
    ],
    "update": [
      "self",
      "new_token_ids",
      "stop_terminated"
    ],
    "decode_next": [
      "self",
      "next_token_id"
    ],
    "get_next_output_text": [
      "self",
      "finished",
      "delta"
    ]
  },
  "FastIncrementalDetokenizer": {
    "__init__": [
      "self",
      "tokenizer",
      "request"
    ],
    "decode_next": [
      "self",
      "next_token_id"
    ],
    "_protected_step": [
      "self",
      "next_token_id"
    ]
  },
  "SlowIncrementalDetokenizer": {
    "__init__": [
      "self",
      "tokenizer",
      "request"
    ],
    "output_token_ids": [
      "self"
    ],
    "decode_next": [
      "self",
      "next_token_id"
    ]
  },
  "check_stop_strings": [
    "output_text",
    "new_char_count",
    "stop",
    "include_in_output"
  ],
  "BlockStatus": {
    "_fields_": [],
    "__init__": [
      "self"
    ],
    "is_ready": [
      "self"
    ]
  },
  "OffloadingSpecFactory": {
    "register_spec": [
      "cls",
      "name",
      "module_path",
      "class_name"
    ],
    "create_spec": [
      "cls",
      "config",
      "kv_cache_config"
    ]
  },
  "BlockIDsLoadStoreSpec": {
    "__init__": [
      "self",
      "block_ids"
    ],
    "__repr__": [
      "self"
    ]
  },
  "GPULoadStoreSpec": {
    "medium": []
  },
  "CPULoadStoreSpec": {
    "medium": []
  },
  "ARCOffloadingManager": {
    "__init__": [
      "self",
      "backend",
      "enable_events"
    ],
    "lookup": [
      "self",
      "block_hashes"
    ],
    "prepare_load": [
      "self",
      "block_hashes"
    ],
    "touch": [
      "self",
      "block_hashes"
    ],
    "complete_load": [
      "self",
      "block_hashes"
    ],
    "prepare_store": [
      "self",
      "block_hashes"
    ],
    "complete_store": [
      "self",
      "block_hashes",
      "success"
    ],
    "take_events": [
      "self"
    ]
  },
  "LoadStoreSpec": {
    "medium": []
  },
  "PrepareStoreOutput": {},
  "OffloadingEvent": {},
  "OffloadingManager": {
    "lookup": [
      "self",
      "block_hashes"
    ],
    "prepare_load": [
      "self",
      "block_hashes"
    ],
    "touch": [
      "self",
      "block_hashes"
    ],
    "complete_load": [
      "self",
      "block_hashes"
    ],
    "prepare_store": [
      "self",
      "block_hashes"
    ],
    "complete_store": [
      "self",
      "block_hashes",
      "success"
    ],
    "take_events": [
      "self"
    ]
  },
  "CPUOffloadingSpec": {
    "__init__": [
      "self",
      "vllm_config",
      "kv_cache_config"
    ],
    "get_manager": [
      "self"
    ],
    "get_handlers": [
      "self",
      "kv_caches",
      "attn_backends"
    ]
  },
  "LRUOffloadingManager": {
    "__init__": [
      "self",
      "backend",
      "enable_events"
    ],
    "lookup": [
      "self",
      "block_hashes"
    ],
    "prepare_load": [
      "self",
      "block_hashes"
    ],
    "touch": [
      "self",
      "block_hashes"
    ],
    "complete_load": [
      "self",
      "block_hashes"
    ],
    "prepare_store": [
      "self",
      "block_hashes"
    ],
    "complete_store": [
      "self",
      "block_hashes",
      "success"
    ],
    "take_events": [
      "self"
    ]
  },
  "OffloadingSpec": {
    "__init__": [
      "self",
      "vllm_config",
      "kv_cache_config"
    ],
    "get_manager": [
      "self"
    ],
    "get_handlers": [
      "self",
      "kv_caches",
      "attn_backends"
    ]
  },
  "TransferSpec": [],
  "TransferType": [],
  "TransferResult": [],
  "OffloadingHandler": {
    "transfer_async": [
      "self",
      "job_id",
      "spec"
    ],
    "get_finished": [
      "self"
    ],
    "wait": [
      "self",
      "job_ids"
    ]
  },
  "OffloadingWorker": {
    "__init__": [
      "self"
    ],
    "register_handler": [
      "self",
      "src_cls",
      "dst_cls",
      "handler"
    ],
    "transfer_async": [
      "self",
      "job_id",
      "spec"
    ],
    "get_finished": [
      "self"
    ],
    "wait": [
      "self",
      "job_ids"
    ]
  },
  "expand_block_ids": [
    "block_ids",
    "block_size_factor",
    "output",
    "skip_count"
  ],
  "SingleDirectionOffloadingHandler": {
    "__init__": [
      "self",
      "src_tensors",
      "dst_tensors",
      "src_block_size_factor",
      "dst_block_size_factor"
    ],
    "transfer_async": [
      "self",
      "job_id",
      "transfer_spec"
    ],
    "get_finished": [
      "self"
    ],
    "wait": [
      "self",
      "job_ids"
    ]
  },
  "CpuGpuOffloadingHandlers": {
    "__init__": [
      "self",
      "gpu_block_size",
      "cpu_block_size",
      "num_cpu_blocks",
      "gpu_caches",
      "attn_backends"
    ]
  },
  "CPUBlockStatus": {
    "_fields_": [],
    "__init__": [
      "self",
      "block_id"
    ]
  },
  "CPUBackend": {
    "__init__": [
      "self",
      "block_size",
      "num_blocks"
    ],
    "get_num_free_blocks": [
      "self"
    ],
    "allocate_blocks": [
      "self",
      "block_hashes"
    ],
    "free": [
      "self",
      "block"
    ],
    "get_load_store_spec": [
      "self",
      "block_hashes",
      "blocks"
    ]
  },
  "WorkerBase": {
    "__init__": [
      "self",
      "vllm_config",
      "local_rank",
      "rank",
      "distributed_init_method",
      "is_driver_worker"
    ],
    "get_kv_cache_spec": [
      "self"
    ],
    "compile_or_warm_up_model": [
      "self"
    ],
    "check_health": [
      "self"
    ],
    "init_device": [
      "self"
    ],
    "initialize_cache": [
      "self",
      "num_gpu_blocks",
      "num_cpu_blocks"
    ],
    "reset_mm_cache": [
      "self"
    ],
    "get_model": [
      "self"
    ],
    "apply_model": [
      "self",
      "fn"
    ],
    "get_model_inspection": [
      "self"
    ],
    "load_model": [
      "self"
    ],
    "execute_model": [
      "self",
      "scheduler_output"
    ],
    "sample_tokens": [
      "self",
      "grammar_output"
    ],
    "get_cache_block_size_bytes": [
      "self"
    ],
    "add_lora": [
      "self",
      "lora_request"
    ],
    "remove_lora": [
      "self",
      "lora_id"
    ],
    "pin_lora": [
      "self",
      "lora_id"
    ],
    "list_loras": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "shutdown": [
      "self"
    ]
  },
  "WorkerWrapperBase": {
    "__init__": [
      "self",
      "rpc_rank",
      "global_rank"
    ],
    "shutdown": [
      "self"
    ],
    "adjust_rank": [
      "self",
      "rank_mapping"
    ],
    "update_environment_variables": [
      "self",
      "envs_list"
    ],
    "init_worker": [
      "self",
      "all_kwargs"
    ],
    "initialize_from_config": [
      "self",
      "kv_cache_configs"
    ],
    "init_device": [
      "self"
    ],
    "execute_method": [
      "self",
      "method"
    ],
    "__getattr__": [
      "self",
      "attr"
    ],
    "_apply_mm_cache": [
      "self",
      "scheduler_output"
    ],
    "execute_model": [
      "self",
      "scheduler_output"
    ],
    "reset_mm_cache": [
      "self"
    ]
  },
  "CPUWorker": {
    "__init__": [
      "self",
      "vllm_config",
      "local_rank",
      "rank",
      "distributed_init_method",
      "is_driver_worker"
    ],
    "init_device": [
      "self"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wake_up": [
      "self",
      "tags"
    ],
    "determine_available_memory": [
      "self"
    ],
    "compile_or_warm_up_model": [
      "self"
    ],
    "_get_autobind_cpu_ids": [
      "self",
      "cpu_selector"
    ],
    "profile": [
      "self",
      "is_start"
    ]
  },
  "check_attention_cp_compatibility": [
    "vllm_config"
  ],
  "get_total_cp_world_size": [],
  "ECConnectorModelRunnerMixin": {
    "maybe_save_ec_to_connector": [
      "encoder_cache",
      "mm_hash"
    ],
    "get_finished_ec_transfers": [
      "scheduler_output"
    ],
    "maybe_get_ec_connector_output": [
      "scheduler_output",
      "encoder_cache"
    ],
    "_get_ec_connector_output": [
      "scheduler_output",
      "encoder_cache"
    ]
  },
  "KVConnectorModelRunnerMixin": {
    "ensure_kv_transfer_shutdown": [],
    "kv_connector_no_forward": [
      "scheduler_output",
      "vllm_config"
    ],
    "maybe_get_kv_connector_output": [
      "scheduler_output"
    ],
    "_get_kv_connector_output": [
      "scheduler_output",
      "wait_for_save"
    ],
    "use_uniform_kv_cache": [
      "attn_groups",
      "cache_dtype"
    ],
    "allocate_uniform_kv_caches": [
      "kv_cache_config",
      "attn_groups",
      "cache_dtype",
      "device",
      "kernel_block_sizes"
    ]
  },
  "UBatchContext": {
    "__init__": [
      "self",
      "id",
      "comm_stream",
      "compute_stream",
      "forward_context",
      "ready_barrier",
      "cpu_wait_event",
      "cpu_signal_event",
      "gpu_comm_done_event",
      "gpu_compute_done_event",
      "schedule"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "_restore_context": [
      "self"
    ],
    "update_stream": [
      "self",
      "stream"
    ],
    "_signal_comm_done": [
      "self"
    ],
    "_signal_compute_done": [
      "self"
    ],
    "_wait_compute_done": [
      "self"
    ],
    "_wait_comm_done": [
      "self"
    ],
    "_cpu_yield": [
      "self"
    ],
    "switch_to_comm": [
      "self"
    ],
    "switch_to_compute": [
      "self"
    ],
    "switch_to_comm_sync": [
      "self"
    ],
    "switch_to_compute_sync": [
      "self"
    ],
    "maybe_run_recv_hook": [
      "self"
    ],
    "yield_": [
      "self"
    ],
    "yield_and_switch_from_compute_to_comm": [
      "self"
    ],
    "yield_and_switch_from_comm_to_compute": [
      "self"
    ]
  },
  "dbo_enabled": [],
  "dbo_current_ubatch_id": [],
  "_register_ubatch_function": [
    "func"
  ],
  "dbo_maybe_run_recv_hook": [],
  "dbo_yield": [],
  "dbo_yield_and_switch_from_compute_to_comm": [],
  "dbo_yield_and_switch_from_comm_to_compute": [],
  "dbo_switch_to_comm": [],
  "dbo_switch_to_compute": [],
  "dbo_switch_to_comm_sync": [],
  "dbo_switch_to_compute_sync": [],
  "dbo_register_recv_hook": [
    "recv_hook"
  ],
  "dbo_get_previous_event": [
    "func"
  ],
  "make_ubatch_contexts": [
    "num_micro_batches",
    "compute_stream",
    "comm_stream",
    "forward_contexts",
    "ready_barrier",
    "schedule"
  ],
  "MultiModalBudget": {
    "__init__": [
      "self",
      "vllm_config",
      "mm_registry"
    ],
    "get_modality_with_max_tokens": [
      "self"
    ],
    "get_encoder_budget": [
      "self"
    ],
    "get_max_items": [
      "self",
      "modality",
      "max_tokens_per_item"
    ],
    "reset_cache": [
      "self"
    ]
  },
  "AttentionGroup": {
    "create_metadata_builders": [
      "self",
      "vllm_config",
      "device",
      "kernel_block_size",
      "num_metadata_builders"
    ],
    "get_metadata_builder": [
      "self",
      "ubatch_id"
    ]
  },
  "sanity_check_mm_encoder_outputs": [
    "mm_embeddings",
    "expected_num_items"
  ],
  "scatter_mm_placeholders": [
    "embeds",
    "is_embed"
  ],
  "gather_mm_placeholders": [
    "placeholders",
    "is_embed"
  ],
  "request_memory": [
    "init_snapshot",
    "cache_config"
  ],
  "add_kv_sharing_layers_to_kv_cache_groups": [
    "shared_kv_cache_layers",
    "kv_cache_groups",
    "runner_only_attn_layers"
  ],
  "bind_kv_cache": [
    "kv_caches",
    "forward_context",
    "runner_kv_caches",
    "num_attn_module"
  ],
  "is_residual_scattered_for_sp": [
    "vllm_config",
    "num_input_tokens"
  ],
  "XPUWorker": {
    "__init__": [
      "self",
      "vllm_config",
      "local_rank",
      "rank",
      "distributed_init_method",
      "is_driver_worker"
    ],
    "xpu_get_mem_info": [
      "self"
    ],
    "determine_available_memory": [
      "self"
    ],
    "init_device": [
      "self"
    ]
  },
  "CachedRequestState": {
    "__post_init__": [
      "self"
    ],
    "num_tokens": [
      "self"
    ],
    "get_token_id": [
      "self",
      "idx"
    ]
  },
  "InputBatch": {
    "__init__": [
      "self",
      "max_num_reqs",
      "max_model_len",
      "max_num_batched_tokens",
      "device",
      "pin_memory",
      "vocab_size",
      "block_sizes",
      "kernel_block_sizes",
      "max_num_blocks_per_req",
      "logitsprocs",
      "logitsprocs_need_output_token_ids",
      "is_spec_decode",
      "is_pooling_model",
      "cp_kv_cache_interleave_size"
    ],
    "req_ids": [
      "self"
    ],
    "_register_add_request": [
      "self",
      "request"
    ],
    "add_request": [
      "self",
      "request"
    ],
    "update_req_spec_token_ids": [
      "self",
      "request",
      "scheduled_spec_tokens"
    ],
    "remove_request": [
      "self",
      "req_id"
    ],
    "swap_states": [
      "self",
      "i1",
      "i2"
    ],
    "condense": [
      "self"
    ],
    "refresh_metadata": [
      "self"
    ],
    "_make_sampling_metadata": [
      "self"
    ],
    "get_pooling_params": [
      "self"
    ],
    "get_pooling_states": [
      "self"
    ],
    "get_pooling_metadata": [
      "self"
    ],
    "_make_prompt_token_ids_tensor": [
      "self"
    ],
    "make_lora_inputs": [
      "self",
      "num_scheduled_tokens",
      "num_sampled_tokens"
    ],
    "set_async_sampled_token_ids": [
      "self",
      "sampled_token_ids_cpu",
      "async_copy_ready_event"
    ],
    "update_async_output_token_ids": [
      "self"
    ],
    "update_async_spec_token_ids": [
      "self",
      "draft_token_ids"
    ],
    "num_reqs": [
      "self"
    ],
    "all_greedy": [
      "self"
    ],
    "all_random": [
      "self"
    ],
    "no_top_p": [
      "self"
    ],
    "no_top_k": [
      "self"
    ],
    "no_penalties": [
      "self"
    ],
    "max_num_logprobs": [
      "self"
    ],
    "no_allowed_token_ids": [
      "self"
    ]
  },
  "BlockTable": {
    "__init__": [
      "self",
      "block_size",
      "max_num_reqs",
      "max_num_blocks_per_req",
      "max_num_batched_tokens",
      "pin_memory",
      "device",
      "kernel_block_size",
      "cp_kv_cache_interleave_size"
    ],
    "append_row": [
      "self",
      "block_ids",
      "row_idx"
    ],
    "add_row": [
      "self",
      "block_ids",
      "row_idx"
    ],
    "move_row": [
      "self",
      "src",
      "tgt"
    ],
    "swap_row": [
      "self",
      "src",
      "tgt"
    ],
    "compute_slot_mapping": [
      "self",
      "req_indices",
      "positions"
    ],
    "commit_block_table": [
      "self",
      "num_reqs"
    ],
    "commit_slot_mapping": [
      "self",
      "num_tokens"
    ],
    "clear": [
      "self"
    ],
    "map_to_kernel_blocks": [
      "kv_manager_block_ids",
      "blocks_per_kv_block",
      "kernel_block_arange"
    ],
    "get_device_tensor": [
      "self",
      "num_reqs"
    ],
    "get_cpu_tensor": [
      "self"
    ],
    "get_numpy_array": [
      "self"
    ],
    "_make_buffer": [
      "self"
    ]
  },
  "MultiGroupBlockTable": {
    "__init__": [
      "self",
      "max_num_reqs",
      "max_model_len",
      "max_num_batched_tokens",
      "pin_memory",
      "device",
      "block_sizes",
      "kernel_block_sizes",
      "max_num_blocks",
      "cp_kv_cache_interleave_size"
    ],
    "append_row": [
      "self",
      "block_ids",
      "row_idx"
    ],
    "add_row": [
      "self",
      "block_ids",
      "row_idx"
    ],
    "move_row": [
      "self",
      "src",
      "tgt"
    ],
    "swap_row": [
      "self",
      "src",
      "tgt"
    ],
    "compute_slot_mapping": [
      "self",
      "req_indices",
      "positions"
    ],
    "commit_block_table": [
      "self",
      "num_reqs"
    ],
    "commit_slot_mapping": [
      "self",
      "num_tokens"
    ],
    "clear": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ]
  },
  "UbatchMetadata": {},
  "CUDAGraphMetaData": {},
  "SMControlContextManager": {
    "__init__": [
      "self",
      "comm_sms",
      "set_comm_sms",
      "set_compute_sms"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "UBatchWrapper": {
    "__init__": [
      "self",
      "runnable",
      "vllm_config",
      "runtime_mode",
      "device"
    ],
    "_create_sm_control_context": [
      "vllm_config"
    ],
    "__getattr__": [
      "self",
      "key"
    ],
    "unwrap": [
      "self"
    ],
    "_capture_ubatches": [
      "self",
      "ubatch_metadata",
      "model"
    ],
    "_run_ubatches": [
      "self",
      "ubatch_metadata",
      "model"
    ],
    "_make_ubatch_metadata": [
      "self",
      "ubatch_slices",
      "attn_metadata",
      "slot_mapping",
      "input_ids",
      "positions",
      "inputs_embeds",
      "intermediate_tensors",
      "compute_stream",
      "dp_metadata",
      "batch_descriptor",
      "cudagraph_runtime_mode"
    ],
    "_slice_model_inputs": [
      "self",
      "tokens_slice",
      "input_ids",
      "positions",
      "inputs_embeds",
      "intermediate_tensors"
    ],
    "__call__": [
      "self"
    ]
  },
  "Worker": {
    "__init__": [
      "self",
      "vllm_config",
      "local_rank",
      "rank",
      "distributed_init_method",
      "is_driver_worker"
    ],
    "sleep": [
      "self",
      "level"
    ],
    "wake_up": [
      "self",
      "tags"
    ],
    "_maybe_get_memory_pool_context": [
      "self",
      "tag"
    ],
    "initialize_cache": [
      "self",
      "num_gpu_blocks",
      "num_cpu_blocks"
    ],
    "init_device": [
      "self"
    ],
    "load_model": [
      "self"
    ],
    "update_config": [
      "self",
      "overrides"
    ],
    "reload_weights": [
      "self"
    ],
    "determine_available_memory": [
      "self"
    ],
    "get_kv_connector_handshake_metadata": [
      "self"
    ],
    "get_kv_cache_spec": [
      "self"
    ],
    "update_max_model_len": [
      "self",
      "max_model_len"
    ],
    "initialize_from_config": [
      "self",
      "kv_cache_config"
    ],
    "compile_or_warm_up_model": [
      "self"
    ],
    "reset_mm_cache": [
      "self"
    ],
    "get_model": [
      "self"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "get_encoder_timing_stats": [
      "self"
    ],
    "annotate_profile": [
      "self",
      "scheduler_output"
    ],
    "sample_tokens": [
      "self",
      "grammar_output"
    ],
    "execute_model": [
      "self",
      "scheduler_output"
    ],
    "take_draft_token_ids": [
      "self"
    ],
    "profile": [
      "self",
      "is_start"
    ],
    "execute_dummy_batch": [
      "self"
    ],
    "add_lora": [
      "self",
      "lora_request"
    ],
    "remove_lora": [
      "self",
      "lora_id"
    ],
    "list_loras": [
      "self"
    ],
    "pin_lora": [
      "self",
      "lora_id"
    ],
    "check_health": [
      "self"
    ],
    "_eplb_before_scale_down": [
      "self",
      "old_ep_size",
      "new_ep_size"
    ],
    "_eplb_after_scale_up": [
      "self",
      "old_ep_size",
      "new_ep_size",
      "global_expert_loads"
    ],
    "_reconfigure_parallel_config": [
      "self",
      "reconfig_request"
    ],
    "_reconfigure_moe": [
      "self",
      "old_ep_size",
      "new_ep_size"
    ],
    "reinitialize_distributed": [
      "self",
      "reconfig_request"
    ],
    "save_sharded_state": [
      "self",
      "path",
      "pattern",
      "max_size"
    ],
    "save_tensorized_model": [
      "self",
      "tensorizer_config"
    ],
    "shutdown": [
      "self"
    ]
  },
  "init_worker_distributed_environment": [
    "vllm_config",
    "rank",
    "distributed_init_method",
    "local_rank",
    "backend"
  ],
  "AsyncGPUModelRunnerOutput": {
    "__init__": [
      "self",
      "model_runner_output",
      "sampled_token_ids",
      "logprobs_tensors",
      "invalid_req_indices",
      "async_output_copy_stream",
      "vocab_size"
    ],
    "get_output": [
      "self"
    ]
  },
  "AsyncGPUPoolingModelRunnerOutput": {
    "__init__": [
      "self",
      "model_runner_output",
      "raw_pooler_output",
      "finished_mask",
      "async_output_copy_stream"
    ],
    "get_output": [
      "self"
    ]
  },
  "ExecuteModelState": {},
  "GPUModelRunner": {
    "__init__": [
      "self",
      "vllm_config",
      "device"
    ],
    "update_max_model_len": [
      "self",
      "max_model_len"
    ],
    "reset_mm_cache": [
      "self"
    ],
    "init_fp8_kv_scales": [
      "self"
    ],
    "_get_positions": [
      "self",
      "num_tokens"
    ],
    "_make_buffer": [
      "self"
    ],
    "_init_model_kwargs": [
      "self"
    ],
    "_may_reorder_batch": [
      "self",
      "scheduler_output"
    ],
    "_init_device_properties": [
      "self"
    ],
    "_sync_device": [
      "self"
    ],
    "_update_states": [
      "self",
      "scheduler_output"
    ],
    "_update_states_after_model_execute": [
      "self",
      "output_token_ids",
      "scheduler_output"
    ],
    "_update_streaming_request": [
      "self",
      "req_id",
      "new_req_data"
    ],
    "_init_mrope_positions": [
      "self",
      "req_state"
    ],
    "_init_xdrope_positions": [
      "self",
      "req_state"
    ],
    "_extract_mm_kwargs": [
      "self",
      "scheduler_output"
    ],
    "_dummy_mm_kwargs": [
      "self",
      "num_seqs"
    ],
    "_get_cumsum_and_arange": [
      "self",
      "num_tokens",
      "cumsum_dtype"
    ],
    "_prepare_input_ids": [
      "self",
      "scheduler_output",
      "total_num_scheduled_tokens",
      "cu_num_tokens"
    ],
    "_get_encoder_seq_lens": [
      "self",
      "num_scheduled_tokens",
      "kv_cache_spec",
      "num_reqs",
      "for_cudagraph_capture"
    ],
    "_prepare_inputs": [
      "self",
      "scheduler_output",
      "num_scheduled_tokens"
    ],
    "_build_attention_metadata": [
      "self",
      "num_tokens",
      "num_reqs",
      "max_query_len",
      "num_tokens_padded",
      "num_reqs_padded",
      "ubatch_slices",
      "logits_indices",
      "use_spec_decode",
      "for_cudagraph_capture",
      "num_scheduled_tokens",
      "cascade_attn_prefix_lens",
      "slot_mappings"
    ],
    "_compute_cascade_attn_prefix_lens": [
      "self",
      "num_scheduled_tokens",
      "num_computed_tokens",
      "num_common_prefix_blocks"
    ],
    "_compute_cascade_attn_prefix_len": [
      "self",
      "num_scheduled_tokens",
      "num_computed_tokens",
      "num_common_prefix_blocks",
      "kv_cache_spec",
      "attn_metadata_builder"
    ],
    "_calc_mrope_positions": [
      "self",
      "scheduler_output"
    ],
    "_calc_xdrope_positions": [
      "self",
      "scheduler_output"
    ],
    "_calc_spec_decode_metadata": [
      "self",
      "num_draft_tokens",
      "cu_num_scheduled_tokens"
    ],
    "_prepare_kv_sharing_fast_prefill": [
      "self",
      "logits_indices"
    ],
    "_batch_mm_inputs_from_scheduler": [
      "self",
      "scheduler_output"
    ],
    "_execute_mm_encoder": [
      "self",
      "scheduler_output"
    ],
    "_gather_mm_embeddings": [
      "self",
      "scheduler_output",
      "shift_computed_tokens"
    ],
    "get_model": [
      "self"
    ],
    "get_supported_generation_tasks": [
      "self"
    ],
    "get_supported_pooling_tasks": [
      "self"
    ],
    "get_supported_tasks": [
      "self"
    ],
    "sync_and_slice_intermediate_tensors": [
      "self",
      "num_tokens",
      "intermediate_tensors",
      "sync_self"
    ],
    "eplb_step": [
      "self",
      "is_dummy",
      "is_profile"
    ],
    "_pool": [
      "self",
      "hidden_states",
      "num_scheduled_tokens",
      "num_scheduled_tokens_np",
      "kv_connector_output"
    ],
    "_pad_for_sequence_parallelism": [
      "self",
      "num_scheduled_tokens"
    ],
    "_prepare_mm_inputs": [
      "self",
      "num_tokens"
    ],
    "_preprocess": [
      "self",
      "scheduler_output",
      "num_input_tokens",
      "intermediate_tensors"
    ],
    "_sample": [
      "self",
      "logits",
      "spec_decode_metadata"
    ],
    "_bookkeeping_sync": [
      "self",
      "scheduler_output",
      "sampler_output",
      "logits",
      "hidden_states",
      "num_scheduled_tokens",
      "spec_decode_metadata"
    ],
    "synchronize_input_prep": [
      "self"
    ],
    "_model_forward": [
      "self",
      "input_ids",
      "positions",
      "intermediate_tensors",
      "inputs_embeds"
    ],
    "_is_uniform_decode": [
      "max_num_scheduled_tokens",
      "uniform_decode_query_len",
      "num_tokens",
      "num_reqs",
      "force_uniform_decode"
    ],
    "_determine_batch_execution_and_padding": [
      "self",
      "num_tokens",
      "num_reqs",
      "num_scheduled_tokens_np",
      "max_num_scheduled_tokens",
      "use_cascade_attn",
      "allow_microbatching",
      "force_eager",
      "force_uniform_decode",
      "force_has_lora",
      "num_encoder_reqs"
    ],
    "_register_layerwise_nvtx_hooks": [
      "self"
    ],
    "_get_slot_mappings": [
      "self",
      "num_tokens_padded",
      "num_reqs_padded",
      "num_tokens_unpadded",
      "ubatch_slices"
    ],
    "execute_model": [
      "self",
      "scheduler_output",
      "intermediate_tensors"
    ],
    "sample_tokens": [
      "self",
      "grammar_output"
    ],
    "take_draft_token_ids": [
      "self"
    ],
    "_copy_draft_token_ids_to_cpu": [
      "self",
      "scheduler_output",
      "zeros_only"
    ],
    "_get_draft_token_ids_cpu": [
      "self"
    ],
    "_copy_valid_sampled_token_count": [
      "self",
      "next_token_ids",
      "valid_sampled_tokens_count"
    ],
    "_get_valid_sampled_token_count": [
      "self"
    ],
    "propose_draft_token_ids": [
      "self",
      "scheduler_output",
      "sampled_token_ids",
      "sampling_metadata",
      "hidden_states",
      "sample_hidden_states",
      "aux_hidden_states",
      "spec_decode_metadata",
      "common_attn_metadata",
      "slot_mappings"
    ],
    "update_config": [
      "self",
      "overrides"
    ],
    "load_model": [
      "self",
      "eep_scale_up"
    ],
    "_get_eagle3_aux_layers_from_config": [
      "self"
    ],
    "reload_weights": [
      "self"
    ],
    "save_tensorized_model": [
      "self",
      "tensorizer_config"
    ],
    "_get_prompt_logprobs_dict": [
      "self",
      "hidden_states",
      "num_scheduled_tokens"
    ],
    "_get_nans_in_logits": [
      "self",
      "logits"
    ],
    "maybe_randomize_inputs": [
      "self",
      "input_ids",
      "inputs_embeds"
    ],
    "_get_mm_dummy_batch": [
      "self",
      "modality",
      "max_items_per_batch"
    ],
    "_dummy_run": [
      "self",
      "num_tokens",
      "cudagraph_runtime_mode",
      "force_attention",
      "uniform_decode",
      "allow_microbatching",
      "skip_eplb",
      "is_profile",
      "create_mixed_batch",
      "remove_lora",
      "activate_lora",
      "is_graph_capturing"
    ],
    "_dummy_sampler_run": [
      "self",
      "hidden_states"
    ],
    "_dummy_pooler_run_task": [
      "self",
      "hidden_states",
      "task"
    ],
    "_dummy_pooler_run": [
      "self",
      "hidden_states"
    ],
    "profile_run": [
      "self"
    ],
    "capture_model": [
      "self"
    ],
    "_capture_cudagraphs": [
      "self",
      "batch_descriptors",
      "cudagraph_runtime_mode"
    ],
    "initialize_attn_backend": [
      "self",
      "kv_cache_config"
    ],
    "initialize_metadata_builders": [
      "self",
      "kv_cache_config",
      "kernel_block_sizes"
    ],
    "_check_and_update_cudagraph_mode": [
      "self",
      "attention_backends",
      "kv_cache_groups"
    ],
    "calculate_reorder_batch_threshold": [
      "self"
    ],
    "select_common_block_size": [
      "kv_manager_block_size",
      "attn_groups"
    ],
    "may_reinitialize_input_batch": [
      "self",
      "kv_cache_config",
      "kernel_block_sizes"
    ],
    "_allocate_kv_cache_tensors": [
      "self",
      "kv_cache_config"
    ],
    "_attn_group_iterator": [
      "self"
    ],
    "_kv_cache_spec_attn_group_iterator": [
      "self"
    ],
    "_prepare_kernel_block_sizes": [
      "self",
      "kv_cache_config"
    ],
    "_reshape_kv_cache_tensors": [
      "self",
      "kv_cache_config",
      "kv_cache_raw_tensors",
      "kernel_block_sizes"
    ],
    "_update_hybrid_attention_mamba_layout": [
      "self",
      "kv_caches"
    ],
    "initialize_kv_cache_tensors": [
      "self",
      "kv_cache_config",
      "kernel_block_sizes"
    ],
    "maybe_add_kv_sharing_layers_to_kv_cache_groups": [
      "self",
      "kv_cache_config"
    ],
    "initialize_kv_cache": [
      "self",
      "kv_cache_config"
    ],
    "init_routed_experts_capturer": [
      "self"
    ],
    "may_add_encoder_only_layers_to_kv_cache_config": [
      "self"
    ],
    "get_kv_cache_spec": [
      "self"
    ],
    "_to_list": [
      "self",
      "sampled_token_ids"
    ],
    "get_encoder_timing_stats": [
      "self"
    ],
    "timed_encoder_operation": [
      "self",
      "should_time",
      "group_lora_refs",
      "current_item_idx",
      "num_items"
    ]
  },
  "EncoderTimingStats": {
    "to_dict": [
      "self"
    ]
  },
  "XPUModelRunner": {
    "__init__": [
      "self",
      "vllm_config",
      "device"
    ],
    "_init_device_properties": [
      "self"
    ],
    "_sync_device": [
      "self"
    ]
  },
  "_torch_cuda_wrapper": [],
  "_get_device_and_group": [
    "parallel_config"
  ],
  "_run_ar": [
    "should_ubatch",
    "should_dp_pad",
    "orig_num_tokens_per_ubatch",
    "padded_num_tokens_per_ubatch",
    "cudagraph_mode",
    "parallel_config"
  ],
  "_post_process_ubatch": [
    "tensor",
    "num_ubatches"
  ],
  "_post_process_dp_padding": [
    "tensor",
    "should_dp_pad"
  ],
  "_post_process_cudagraph_mode": [
    "tensor"
  ],
  "_synchronize_dp_ranks": [
    "num_tokens_unpadded",
    "num_tokens_padded",
    "should_attempt_ubatching",
    "should_attempt_dp_padding",
    "cudagraph_mode",
    "parallel_config"
  ],
  "coordinate_batch_across_dp": [
    "num_tokens_unpadded",
    "allow_microbatching",
    "allow_dp_padding",
    "parallel_config",
    "num_tokens_padded",
    "uniform_decode",
    "num_scheduled_tokens_per_request",
    "cudagraph_mode"
  ],
  "UBatchSlice": {
    "is_empty": [
      "self"
    ],
    "num_tokens": [
      "self"
    ]
  },
  "is_last_ubatch_empty": [
    "orig_num_tokens",
    "padded_num_tokens",
    "num_ubatches"
  ],
  "check_ubatch_thresholds": [
    "config",
    "num_tokens",
    "uniform_decode"
  ],
  "_pad_out_ubatch_slices": [
    "ubatch_slices",
    "num_total_tokens",
    "num_reqs_padded"
  ],
  "maybe_create_ubatch_slices": [
    "should_ubatch",
    "num_scheduled_tokens",
    "num_tokens_padded",
    "num_reqs_padded",
    "num_ubatches",
    "split_point"
  ],
  "slice_query_start_locs": [
    "query_start_loc",
    "request_slice"
  ],
  "_make_metadata_with_slice": [
    "ubatch_slice",
    "attn_metadata"
  ],
  "split_attn_metadata": [
    "ubatch_slices",
    "common_attn_metadata"
  ],
  "CPUModelRunner": {
    "__init__": [
      "self",
      "vllm_config",
      "device"
    ],
    "_postprocess_tensors": [
      "self"
    ],
    "load_model": [
      "self",
      "eep_scale_up"
    ],
    "get_model": [
      "self"
    ],
    "warming_up_model": [
      "self"
    ],
    "_init_device_properties": [
      "self"
    ],
    "_sync_device": [
      "self"
    ],
    "get_dp_padding": [
      "self",
      "num_tokens"
    ]
  },
  "_set_global_compilation_settings": [
    "config"
  ],
  "batch_memcpy_kernel": [
    "src_ptrs",
    "dst_ptrs",
    "sizes",
    "BLOCK_SIZE"
  ],
  "batch_memcpy": [
    "src_ptrs",
    "dst_ptrs",
    "sizes"
  ],
  "get_mamba_groups": [
    "kv_cache_config"
  ],
  "collect_mamba_copy_meta": [
    "src_state_list",
    "dest_state_list",
    "num_elements_list",
    "kv_cache_config",
    "mamba_state_copy_funcs",
    "mamba_group_ids",
    "src_block_idx",
    "dest_block_idx",
    "accept_token_bias",
    "req_state",
    "forward_context"
  ],
  "do_mamba_copy_block": [
    "src_state_list",
    "dest_state_list",
    "num_elements_list"
  ],
  "preprocess_mamba": [
    "scheduler_output",
    "kv_cache_config",
    "cache_config",
    "mamba_state_idx",
    "input_batch",
    "requests",
    "forward_context",
    "mamba_state_copy_funcs"
  ],
  "postprocess_mamba": [
    "scheduler_output",
    "kv_cache_config",
    "input_batch",
    "requests",
    "mamba_state_idx",
    "forward_context",
    "mamba_state_copy_funcs"
  ],
  "LoRAModelRunnerMixin": {
    "load_lora_model": [
      "self",
      "model",
      "vllm_config",
      "device"
    ],
    "_set_active_loras": [
      "self",
      "prompt_lora_mapping",
      "token_lora_mapping",
      "lora_requests",
      "mapping_type"
    ],
    "_ensure_lora_enabled": [
      "self"
    ],
    "set_active_loras": [
      "self",
      "input_batch",
      "num_scheduled_tokens",
      "num_sampled_tokens",
      "mapping_type"
    ],
    "maybe_setup_dummy_loras": [
      "self",
      "lora_config",
      "remove_lora"
    ],
    "maybe_select_dummy_loras": [
      "self",
      "lora_config",
      "num_scheduled_tokens",
      "mapping_type",
      "num_sampled_tokens",
      "activate_lora"
    ],
    "maybe_dummy_run_with_lora": [
      "self",
      "lora_config",
      "num_scheduled_tokens",
      "num_sampled_tokens",
      "activate_lora",
      "remove_lora",
      "mapping_type"
    ],
    "maybe_remove_all_loras": [
      "self",
      "lora_config"
    ],
    "add_lora": [
      "self",
      "lora_request"
    ],
    "remove_lora": [
      "self",
      "lora_id"
    ],
    "pin_lora": [
      "self",
      "lora_id"
    ],
    "list_loras": [
      "self"
    ]
  },
  "_compute_bytes": [
    "shape",
    "dtype"
  ],
  "_MB": [],
  "_GiB": [],
  "WorkspaceManager": {
    "__init__": [
      "self",
      "device",
      "num_ubatches"
    ],
    "_workspace_size_bytes": [
      "workspace"
    ],
    "lock": [
      "self"
    ],
    "is_locked": [
      "self"
    ],
    "get_simultaneous": [
      "self"
    ],
    "_ensure_workspace_size": [
      "self",
      "required_bytes"
    ]
  },
  "is_workspace_manager_initialized": [],
  "current_workspace_manager": [],
  "init_workspace_manager": [
    "device",
    "num_ubatches"
  ],
  "lock_workspace": [],
  "reset_workspace_manager": [],
  "StructuredOutputsWorker": {
    "__init__": [
      "self",
      "max_num_logits",
      "vocab_size"
    ],
    "apply_grammar_bitmask": [
      "self",
      "logits",
      "input_batch",
      "grammar_req_ids",
      "grammar_bitmask"
    ]
  },
  "_apply_grammar_bitmask_kernel": [
    "logits_ptr",
    "logits_stride",
    "logits_indices_ptr",
    "bitmask_ptr",
    "bitmask_stride",
    "vocab_size",
    "BLOCK_SIZE"
  ],
  "KVConnector": {
    "pre_forward": [
      "self",
      "scheduler_output"
    ],
    "post_forward": [
      "self",
      "scheduler_output",
      "wait_for_save"
    ],
    "no_forward": [
      "self",
      "scheduler_output"
    ],
    "set_disabled": [
      "self",
      "disabled"
    ]
  },
  "ActiveKVConnector": {
    "__init__": [
      "self",
      "vllm_config",
      "kv_caches_dict"
    ],
    "pre_forward": [
      "self",
      "scheduler_output"
    ],
    "post_forward": [
      "self",
      "scheduler_output",
      "wait_for_save"
    ],
    "no_forward": [
      "self",
      "scheduler_output"
    ],
    "set_disabled": [
      "self",
      "disabled"
    ]
  },
  "NO_OP_KV_CONNECTOR": [],
  "get_kv_connector": [
    "vllm_config",
    "kv_caches_dict"
  ],
  "CudaGraphManager": {
    "__init__": [
      "self",
      "vllm_config",
      "uses_mrope",
      "device"
    ],
    "needs_capture": [
      "self"
    ],
    "get_cudagraph_size": [
      "self",
      "num_tokens_after_padding",
      "num_tokens_per_request"
    ],
    "capture_graph": [
      "self",
      "num_tokens",
      "model",
      "input_buffers",
      "mrope_positions",
      "inputs_embeds",
      "block_tables",
      "attn_metadata_builders",
      "kv_cache_config"
    ],
    "capture": [
      "self",
      "model",
      "input_buffers",
      "mrope_positions",
      "inputs_embeds",
      "block_tables",
      "attn_metadata_builders",
      "kv_cache_config"
    ],
    "run": [
      "self",
      "num_tokens"
    ]
  },
  "get_cudagraph_sizes": [
    "capture_sizes",
    "max_num_reqs",
    "max_num_tokens",
    "cudagraph_mode"
  ],
  "get_cudagraph_size": [
    "num_tokens_after_dp_padding",
    "num_tokens_per_request",
    "cudagraph_sizes",
    "cudagraph_mode"
  ],
  "capture_graphs": [
    "cudagraph_sizes",
    "device",
    "capture_fn"
  ],
  "prepare_inputs_to_capture": [
    "num_reqs",
    "num_tokens",
    "input_buffers",
    "block_tables",
    "attn_metadata_builders",
    "max_model_len",
    "kv_cache_config"
  ],
  "get_kv_cache_spec": [
    "vllm_config"
  ],
  "init_attn_backend": [
    "kv_cache_config",
    "vllm_config",
    "device"
  ],
  "_allocate_kv_cache": [
    "kv_cache_config",
    "device"
  ],
  "_reshape_kv_cache": [
    "kv_cache_config",
    "kv_cache_raw_tensors",
    "attn_backends"
  ],
  "init_kv_cache": [
    "runner_kv_caches",
    "forward_context",
    "kv_cache_config",
    "attn_backends",
    "device"
  ],
  "build_slot_mappings_by_layer": [
    "slot_mappings",
    "kv_cache_config"
  ],
  "build_attn_metadata": [
    "attn_metadata_builders",
    "num_reqs",
    "num_tokens",
    "query_start_loc_gpu",
    "query_start_loc_cpu",
    "seq_lens",
    "max_seq_len",
    "block_tables",
    "slot_mappings",
    "kv_cache_config"
  ],
  "AsyncOutput": {
    "__init__": [
      "self",
      "model_runner_output",
      "sampler_output",
      "num_sampled_tokens",
      "copy_stream",
      "copy_event"
    ],
    "get_output": [
      "self"
    ]
  },
  "async_barrier": [
    "event"
  ],
  "async_copy_to_np": [
    "x"
  ],
  "InputBuffers": {
    "__init__": [
      "self",
      "max_num_reqs",
      "max_num_tokens",
      "device"
    ]
  },
  "_prepare_prefill_inputs_kernel": [
    "input_ids_ptr",
    "next_prefill_tokens_ptr",
    "idx_mapping_ptr",
    "query_start_loc_ptr",
    "prefill_token_ids_ptr",
    "prefill_token_ids_stride",
    "prefill_lens_ptr",
    "num_computed_tokens_ptr",
    "BLOCK_SIZE"
  ],
  "prepare_prefill_inputs": [
    "input_ids",
    "next_prefill_tokens",
    "idx_mapping",
    "query_start_loc",
    "prefill_token_ids",
    "prefill_len",
    "num_computed_tokens"
  ],
  "_prepare_pos_seq_lens_kernel": [
    "pos_ptr",
    "seq_lens_ptr",
    "idx_mapping_ptr",
    "query_start_loc_ptr",
    "num_computed_tokens_ptr",
    "max_num_reqs",
    "BLOCK_SIZE"
  ],
  "prepare_pos_seq_lens": [
    "idx_mapping",
    "query_start_loc",
    "num_computed_tokens",
    "pos",
    "seq_lens"
  ],
  "_combine_sampled_and_draft_tokens_kernel": [
    "input_ids_ptr",
    "idx_mapping_ptr",
    "last_sampled_tokens_ptr",
    "query_start_loc_ptr",
    "seq_lens_ptr",
    "prefill_len_ptr",
    "draft_tokens_ptr",
    "draft_tokens_stride",
    "cu_num_logits_ptr",
    "logits_indices_ptr",
    "BLOCK_SIZE"
  ],
  "combine_sampled_and_draft_tokens": [
    "input_ids",
    "idx_mapping",
    "last_sampled_tokens",
    "query_start_loc",
    "seq_lens",
    "prefill_len",
    "draft_tokens",
    "cu_num_logits",
    "num_logits"
  ],
  "_get_num_sampled_and_rejected_kernel": [
    "num_sampled_ptr",
    "num_rejected_ptr",
    "seq_lens_ptr",
    "cu_num_logits_ptr",
    "idx_mapping_ptr",
    "prefill_len_ptr"
  ],
  "get_num_sampled_and_rejected": [
    "num_sampled",
    "seq_lens",
    "cu_num_logits",
    "idx_mapping",
    "prefill_len"
  ],
  "_post_update_kernel": [
    "idx_mapping_ptr",
    "num_computed_tokens_ptr",
    "last_sampled_tokens_ptr",
    "output_bin_counts_ptr",
    "output_bin_counts_stride",
    "sampled_tokens_ptr",
    "sampled_tokens_stride",
    "num_sampled_ptr",
    "num_rejected_ptr",
    "query_start_loc_ptr"
  ],
  "post_update": [
    "idx_mapping",
    "num_computed_tokens",
    "last_sampled_tokens",
    "output_bin_counts",
    "sampled_tokens",
    "num_sampled",
    "num_rejected",
    "query_start_loc"
  ],
  "_expand_idx_mapping_kernel": [
    "idx_mapping_ptr",
    "expanded_idx_mapping_ptr",
    "cu_num_logits_ptr",
    "BLOCK_SIZE"
  ],
  "expand_idx_mapping": [
    "idx_mapping",
    "total_num_logits",
    "cu_num_logits",
    "max_expand_len"
  ],
  "UvaBuffer": {
    "__init__": [
      "self",
      "size",
      "dtype"
    ]
  },
  "UvaBufferPool": {
    "__init__": [
      "self",
      "size",
      "dtype",
      "max_concurrency"
    ],
    "copy_to_uva": [
      "self",
      "x"
    ],
    "copy_to_gpu": [
      "self",
      "x",
      "out"
    ]
  },
  "UvaBackedTensor": {
    "__init__": [
      "self",
      "size",
      "dtype",
      "max_concurrency"
    ],
    "copy_to_uva": [
      "self",
      "n"
    ]
  },
  "StagedWriteTensor": {
    "__init__": [
      "self",
      "size",
      "dtype",
      "device",
      "max_concurrency",
      "uva_instead_of_gpu"
    ],
    "stage_write": [
      "self",
      "index",
      "start",
      "x"
    ],
    "stage_write_elem": [
      "self",
      "index",
      "x"
    ],
    "apply_write": [
      "self"
    ],
    "clear_staged_writes": [
      "self"
    ]
  },
  "_apply_write_kernel": [
    "output_ptr",
    "output_stride",
    "write_indices_ptr",
    "write_starts_ptr",
    "write_contents_ptr",
    "write_cu_lens_ptr",
    "BLOCK_SIZE"
  ],
  "NO_LORA_ID": [],
  "LoraState": {
    "__init__": [
      "self",
      "max_num_reqs"
    ],
    "add_request": [
      "self",
      "req_id",
      "req_index",
      "lora_request"
    ],
    "remove_request": [
      "self",
      "req_id"
    ],
    "make_lora_inputs": [
      "self",
      "req_ids",
      "idx_mapping",
      "num_scheduled_tokens"
    ]
  },
  "BlockTables": {
    "__init__": [
      "self",
      "block_sizes",
      "max_num_reqs",
      "max_num_batched_tokens",
      "max_model_len",
      "device"
    ],
    "_make_ptr_tensor": [
      "self",
      "x"
    ],
    "append_block_ids": [
      "self",
      "req_index",
      "new_block_ids",
      "overwrite"
    ],
    "apply_staged_writes": [
      "self"
    ],
    "gather_block_tables": [
      "self",
      "idx_mapping"
    ],
    "get_dummy_block_tables": [
      "self",
      "num_reqs"
    ],
    "compute_slot_mappings": [
      "self",
      "idx_mapping",
      "query_start_loc",
      "positions"
    ],
    "get_dummy_slot_mappings": [
      "self",
      "num_tokens"
    ]
  },
  "_gather_block_tables_kernel": [
    "batch_idx_to_req_idx",
    "src_block_table_ptrs",
    "dst_block_table_ptrs",
    "block_table_strides",
    "num_blocks_ptr",
    "num_blocks_stride",
    "BLOCK_SIZE"
  ],
  "_compute_slot_mappings_kernel": [
    "num_tokens",
    "max_num_tokens",
    "idx_mapping",
    "query_start_loc",
    "pos",
    "block_table_ptrs",
    "block_table_strides",
    "block_sizes",
    "slot_mappings_ptr",
    "slot_mappings_stride",
    "PAD_ID",
    "TRITON_BLOCK_SIZE"
  ],
  "_load_ptr": [
    "ptr_to_ptr",
    "elem_dtype"
  ],
  "make_num_tokens_across_dp": [
    "dp_size",
    "num_tokens"
  ],
  "get_batch_metadata_across_dp": [
    "num_tokens",
    "cudagraph_size",
    "dp_size",
    "dp_rank"
  ],
  "get_cudagraph_and_dp_padding": [
    "num_tokens",
    "cudagraph_size",
    "dp_size",
    "dp_rank"
  ],
  "_num_nans_kernel": [
    "logits_ptr",
    "logits_stride",
    "num_nans_ptr",
    "vocab_size",
    "BLOCK_SIZE"
  ],
  "get_num_nans": [
    "logits"
  ],
  "_topk_log_softmax_kernel": [
    "output_ptr",
    "logits_ptr",
    "logits_stride",
    "topk_ids_ptr",
    "topk",
    "vocab_size",
    "BLOCK_SIZE",
    "PADDED_TOPK"
  ],
  "_ranks_kernel": [
    "output_ptr",
    "logits_ptr",
    "logits_stride",
    "token_ids_ptr",
    "vocab_size",
    "BLOCK_SIZE"
  ],
  "compute_token_logprobs": [
    "logits",
    "token_ids"
  ],
  "compute_topk_logprobs": [
    "logits",
    "num_logprobs",
    "sampled_token_ids"
  ],
  "NO_LOGPROBS": [],
  "_NP_INT64_MIN": [],
  "_NP_INT64_MAX": [],
  "SamplingStates": {
    "__init__": [
      "self",
      "max_num_reqs",
      "vocab_size"
    ],
    "add_request": [
      "self",
      "req_idx",
      "sampling_params"
    ],
    "apply_staged_writes": [
      "self"
    ],
    "do_min_p": [
      "self",
      "idx_mapping_np"
    ],
    "do_top_k": [
      "self",
      "idx_mapping_np"
    ],
    "do_top_p": [
      "self",
      "idx_mapping_np"
    ],
    "max_num_logprobs": [
      "self",
      "idx_mapping_np"
    ]
  },
  "_min_p_kernel": [
    "logits_ptr",
    "logits_stride",
    "idx_mapping_ptr",
    "min_p_ptr",
    "vocab_size",
    "BLOCK_SIZE"
  ],
  "apply_min_p": [
    "logits",
    "idx_mapping",
    "min_p"
  ],
  "PromptLogprobsWorker": {
    "__init__": [
      "self",
      "max_num_reqs"
    ],
    "add_request": [
      "self",
      "req_id",
      "req_idx",
      "sampling_params"
    ],
    "remove_request": [
      "self",
      "req_id"
    ],
    "compute_prompt_logprobs": [
      "self",
      "logits_fn",
      "hidden_states",
      "input_batch",
      "prefill_token_ids",
      "num_computed_tokens",
      "prompt_lens",
      "prefill_lens",
      "num_computed_prefill_tokens"
    ]
  },
  "_prompt_logprobs_token_ids_kernel": [
    "prompt_logprobs_token_ids_ptr",
    "query_start_loc_ptr",
    "idx_mapping_ptr",
    "num_computed_tokens_ptr",
    "prefill_token_ids_ptr",
    "prefill_token_ids_stride",
    "BLOCK_SIZE"
  ],
  "get_prompt_logprobs_token_ids": [
    "num_tokens",
    "query_start_loc",
    "idx_mapping",
    "num_computed_tokens",
    "prefill_token_ids"
  ],
  "compute_prompt_logprobs_with_chunking": [
    "prompt_token_ids",
    "prompt_hidden_states",
    "logits_fn"
  ],
  "MAX_NUM_ALLOWED_TOKEN_IDS": [],
  "MAX_NUM_LOGIT_BIAS_TOKENS": [],
  "MAX_NUM_STOP_TOKEN_IDS": [],
  "LogitBiasState": {
    "__init__": [
      "self",
      "max_num_reqs",
      "device"
    ],
    "add_request": [
      "self",
      "req_idx",
      "prompt_len",
      "sampling_params"
    ],
    "apply_staged_writes": [
      "self"
    ],
    "apply_logit_bias": [
      "self",
      "logits",
      "idx_mapping",
      "idx_mapping_np",
      "pos"
    ]
  },
  "_bias_kernel": [
    "logits_ptr",
    "logits_stride",
    "vocab_size",
    "idx_mapping_ptr",
    "num_allowed_token_ids_ptr",
    "allowed_token_ids_ptr",
    "allowed_token_ids_stride",
    "num_logit_bias_ptr",
    "bias_token_ids_ptr",
    "bias_token_ids_stride",
    "bias_ptr",
    "bias_stride",
    "pos_ptr",
    "min_lens_ptr",
    "num_stop_token_ids_ptr",
    "stop_token_ids_ptr",
    "stop_token_ids_stride",
    "BLOCK_SIZE",
    "LOGITS_BLOCK_SIZE"
  ],
  "apply_logit_bias": [
    "logits",
    "idx_mapping",
    "pos",
    "num_allowed_token_ids",
    "allowed_token_ids",
    "num_logit_bias",
    "logit_bias_token_ids",
    "logit_bias",
    "min_lens",
    "num_stop_token_ids",
    "stop_token_ids"
  ],
  "_temperature_kernel": [
    "logits_ptr",
    "logits_stride",
    "idx_mapping_ptr",
    "temperature_ptr",
    "vocab_size",
    "BLOCK_SIZE"
  ],
  "apply_temperature": [
    "logits",
    "idx_mapping",
    "temperature"
  ],
  "_gumbel_sample_kernel": [
    "local_argmax_ptr",
    "local_argmax_stride",
    "local_max_ptr",
    "local_max_stride",
    "logits_ptr",
    "logits_stride",
    "idx_mapping_ptr",
    "seeds_ptr",
    "pos_ptr",
    "temp_ptr",
    "vocab_size",
    "BLOCK_SIZE",
    "APPLY_TEMPERATURE"
  ],
  "gumbel_sample": [
    "logits",
    "idx_mapping",
    "temperature",
    "seed",
    "pos",
    "apply_temperature"
  ],
  "PenaltiesState": {
    "__init__": [
      "self",
      "max_num_reqs",
      "vocab_size",
      "device"
    ],
    "add_request": [
      "self",
      "req_idx",
      "sampling_params"
    ],
    "apply_staged_writes": [
      "self",
      "prefill_token_ids",
      "prefill_lens",
      "prompt_lens"
    ],
    "apply_penalties": [
      "self",
      "logits",
      "idx_mapping",
      "idx_mapping_np"
    ]
  },
  "_penalties_kernel": [
    "logits_ptr",
    "logits_stride",
    "idx_mapping_ptr",
    "repetition_penalty_ptr",
    "frequency_penalty_ptr",
    "presence_penalty_ptr",
    "prompt_bin_mask_ptr",
    "prompt_bin_mask_stride",
    "output_bin_counts_ptr",
    "output_bin_counts_stride",
    "vocab_size",
    "BLOCK_SIZE"
  ],
  "_bincount_kernel": [
    "prefill_token_ids_ptr",
    "prefill_len",
    "prompt_len",
    "prompt_bin_mask_ptr",
    "output_bin_counts_ptr",
    "BLOCK_SIZE"
  ],
  "bincount": [
    "prefill_token_ids",
    "prefill_len",
    "prompt_len",
    "prompt_bin_mask",
    "output_bin_counts"
  ],
  "use_penalty": [
    "sampling_params"
  ],
  "init_speculator": [
    "vllm_config",
    "device"
  ],
  "EagleSpeculator": {
    "__init__": [
      "self",
      "vllm_config",
      "device"
    ],
    "load_model": [
      "self",
      "target_model"
    ],
    "set_attn": [
      "self",
      "kv_cache_config",
      "attn_metadata_builders",
      "block_tables"
    ],
    "run_model": [
      "self",
      "num_tokens",
      "attn_metadata",
      "slot_mappings",
      "num_tokens_across_dp"
    ],
    "generate_draft": [
      "self",
      "num_reqs",
      "attn_metadata",
      "slot_mappings",
      "num_tokens_across_dp"
    ],
    "capture_model": [
      "self"
    ],
    "propose": [
      "self",
      "input_batch",
      "last_hidden_states",
      "aux_hidden_states",
      "num_sampled",
      "num_rejected",
      "last_sampled",
      "next_prefill_tokens",
      "temperature",
      "seeds"
    ]
  },
  "_prepare_eagle_inputs_kernel": [
    "last_token_indices_ptr",
    "eagle_input_ids_ptr",
    "eagle_positions_ptr",
    "target_input_ids_ptr",
    "target_positions_ptr",
    "idx_mapping_ptr",
    "last_sampled_ptr",
    "next_prefill_tokens_ptr",
    "num_sampled_ptr",
    "num_rejected_ptr",
    "query_start_loc_ptr",
    "BLOCK_SIZE"
  ],
  "prepare_eagle_inputs": [
    "input_buffers",
    "input_batch",
    "num_sampled",
    "num_rejected",
    "last_sampled",
    "next_prefill_tokens"
  ],
  "_prepare_eagle_docode_kernel": [
    "draft_tokens_ptr",
    "output_hidden_states_ptr",
    "output_hidden_states_stride",
    "last_token_indices_ptr",
    "target_seq_lens_ptr",
    "num_rejected_ptr",
    "input_ids_ptr",
    "positions_ptr",
    "input_hidden_states_ptr",
    "input_hidden_states_stride",
    "query_start_loc_ptr",
    "seq_lens_ptr",
    "hidden_size",
    "max_model_len",
    "max_num_reqs",
    "BLOCK_SIZE"
  ],
  "prepare_eagle_decode": [
    "draft_tokens",
    "output_hidden_states",
    "last_token_indices",
    "target_seq_lens",
    "num_rejected",
    "input_buffers",
    "input_hidden_states",
    "max_model_len",
    "max_num_reqs"
  ],
  "_update_eagle_inputs_kernel": [
    "input_ids_ptr",
    "positions_ptr",
    "input_hidden_states_ptr",
    "input_hidden_states_stride",
    "seq_lens_ptr",
    "max_model_len",
    "draft_tokens_ptr",
    "output_hidden_states_ptr",
    "output_hidden_states_stride",
    "hidden_size",
    "BLOCK_SIZE"
  ],
  "update_eagle_inputs": [
    "draft_tokens",
    "output_hidden_states",
    "input_buffers",
    "hidden_states",
    "max_model_len"
  ],
  "EagleCudaGraphManager": {
    "__init__": [
      "self",
      "vllm_config",
      "device"
    ],
    "get_cudagraph_size": [
      "self",
      "num_tokens"
    ],
    "capture_graph": [
      "self",
      "num_tokens",
      "generate_fn",
      "input_buffers",
      "block_tables",
      "attn_metadata_builders",
      "kv_cache_config"
    ],
    "capture": [
      "self",
      "generate_fn",
      "input_buffers",
      "block_tables",
      "attn_metadata_builders",
      "kv_cache_config"
    ],
    "run": [
      "self",
      "num_tokens"
    ]
  },
  "_rejection_sample_kernel": [
    "sampled_ptr",
    "sampled_stride",
    "num_sampled_ptr",
    "target_sampled_ptr",
    "input_ids_ptr",
    "cu_num_logits_ptr"
  ],
  "EncoderRunner": {
    "__init__": [
      "self",
      "max_num_tokens",
      "hidden_size",
      "dtype",
      "device"
    ],
    "add_request": [
      "self",
      "req_id",
      "mm_features"
    ],
    "free_encoder_cache": [
      "self",
      "mm_hash"
    ],
    "remove_request": [
      "self",
      "req_id"
    ],
    "prepare_mm_inputs": [
      "self",
      "scheduled_encoder_inputs"
    ],
    "execute_mm_encoder": [
      "self",
      "model",
      "mm_hashes",
      "mm_kwargs"
    ],
    "gather_mm_embeddings": [
      "self",
      "req_ids",
      "total_num_scheduled_tokens",
      "num_scheduled_tokens",
      "query_start_loc",
      "prefill_lens",
      "computed_prefill_lens"
    ],
    "get_inputs_embeds": [
      "self",
      "model",
      "input_ids",
      "mm_embeds",
      "is_mm_embed"
    ]
  },
  "MRopeState": {
    "__init__": [
      "self",
      "max_num_reqs",
      "max_num_tokens",
      "max_model_len",
      "device"
    ],
    "init_prefill_mrope_positions": [
      "self",
      "req_idx",
      "mrope_model",
      "prefill_token_ids",
      "mm_features"
    ],
    "apply_staged_writes": [
      "self"
    ],
    "prepare_mrope_positions": [
      "self",
      "idx_mapping",
      "query_start_loc",
      "prefill_lens",
      "num_computed_tokens"
    ]
  },
  "_prepare_mrope_positions_kernel": [
    "mrope_positions_ptr",
    "mrope_positions_stride",
    "prefill_mrope_positions_ptr",
    "prefill_mrope_positions_stride0",
    "prefill_mrope_positions_stride1",
    "prefill_mrope_delta_ptr",
    "idx_mapping_ptr",
    "query_start_loc_ptr",
    "prefill_lens_ptr",
    "num_computed_tokens_ptr",
    "BLOCK_SIZE"
  ],
  "SpecDecodingStats": {
    "new": [
      "cls",
      "num_spec_tokens"
    ],
    "observe_draft": [
      "self",
      "num_draft_tokens",
      "num_accepted_tokens"
    ]
  },
  "SpecDecodingLogging": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "observe": [
      "self",
      "spec_decoding_stats"
    ],
    "log": [
      "self",
      "log_fn"
    ]
  },
  "SpecDecodingProm": {
    "_counter_cls": [],
    "__init__": [
      "self",
      "speculative_config",
      "labelnames",
      "per_engine_labelvalues"
    ],
    "observe": [
      "self",
      "spec_decoding_stats",
      "engine_idx"
    ]
  },
  "SpecDecodeMetadata": {
    "__post_init__": [
      "self"
    ],
    "make_dummy": [
      "cls",
      "draft_token_ids",
      "device"
    ]
  },
  "eagle_prepare_inputs_padded_kernel": [
    "cu_num_draft_tokens_ptr",
    "valid_sampled_tokens_count_ptr",
    "query_start_loc_gpu_ptr",
    "token_indices_to_sample_ptr",
    "num_rejected_tokens_gpu_ptr",
    "num_reqs"
  ],
  "eagle_prepare_next_token_padded_kernel": [
    "sampled_token_ids_ptr",
    "discard_request_mask_ptr",
    "backup_next_token_ids_ptr",
    "next_token_ids_ptr",
    "valid_sampled_tokens_count_ptr",
    "vocab_size",
    "num_sampled_tokens_per_req",
    "num_reqs",
    "stride_sampled_token_ids",
    "BLOCK_SIZE_TOKENS"
  ],
  "DraftModelProposer": {
    "__init__": [
      "self",
      "vllm_config",
      "device",
      "runner"
    ],
    "_block_size": [
      "self"
    ],
    "_raise_if_multimodal": [
      "self"
    ],
    "_raise_if_mrope": [
      "self"
    ],
    "_raise_if_padded_drafter_batch_disabled": [
      "self"
    ],
    "_raise_if_vocab_size_mismatch": [
      "self"
    ],
    "_raise_if_draft_tp_mismatch": [
      "self"
    ],
    "set_inputs_first_pass": [
      "self",
      "target_token_ids",
      "next_token_ids",
      "target_positions",
      "last_token_indices",
      "cad",
      "num_rejected_tokens_gpu"
    ],
    "load_model": [
      "self",
      "target_model"
    ]
  },
  "create_vllm_config_for_draft_model": [
    "target_model_vllm_config"
  ],
  "compute_new_slot_mapping": [
    "cad",
    "new_positions",
    "is_rejected_token_mask",
    "block_size",
    "max_model_len"
  ],
  "merge_toks_kernel": [
    "target_toks_ptr",
    "next_toks_ptr",
    "query_start_locs_ptr",
    "query_end_locs_ptr",
    "out_ptr_merged_toks",
    "out_ptr_is_rejected_tok",
    "target_toks_size",
    "rejected_tok_fill"
  ],
  "MedusaProposer": {
    "__init__": [
      "self",
      "vllm_config",
      "device"
    ],
    "propose": [
      "self",
      "target_hidden_states",
      "sampling_metadata",
      "slot_mappings"
    ],
    "load_model": [
      "self",
      "target_model"
    ],
    "dummy_run": [
      "self",
      "num_tokens"
    ]
  },
  "NgramProposer": {
    "__init__": [
      "self",
      "vllm_config"
    ],
    "batch_propose": [
      "self",
      "num_requests",
      "valid_ngram_requests",
      "num_tokens_no_spec",
      "token_ids_cpu"
    ],
    "propose": [
      "self",
      "sampled_token_ids",
      "num_tokens_no_spec",
      "token_ids_cpu",
      "slot_mappings"
    ],
    "load_model": [
      "self"
    ]
  },
  "batch_propose_numba": [
    "valid_ngram_requests",
    "num_tokens_no_spec",
    "token_ids_cpu",
    "min_n",
    "max_n",
    "max_model_len",
    "k",
    "valid_ngram_draft",
    "valid_ngram_num_drafts"
  ],
  "_find_longest_matched_ngram_and_propose_tokens": [
    "origin_tokens",
    "min_ngram",
    "max_ngram",
    "max_model_len",
    "k"
  ],
  "SuffixDecodingProposer": {
    "__init__": [
      "self",
      "vllm_config"
    ],
    "propose": [
      "self",
      "input_batch",
      "sampled_token_ids",
      "slot_mappings"
    ],
    "load_model": [
      "self"
    ]
  },
  "PADDING_SLOT_ID": [],
  "SpecDecodeBaseProposer": {
    "__init__": [
      "self",
      "vllm_config",
      "device",
      "pass_hidden_states_to_model",
      "runner"
    ],
    "_get_positions": [
      "self",
      "num_tokens"
    ],
    "_set_positions": [
      "self",
      "num_tokens",
      "positions"
    ],
    "_get_slot_mapping": [
      "self",
      "num_tokens",
      "slot_mapping"
    ],
    "initialize_cudagraph_keys": [
      "self",
      "cudagraph_mode"
    ],
    "propose": [
      "self",
      "target_token_ids",
      "target_positions",
      "target_hidden_states",
      "next_token_ids",
      "last_token_indices",
      "common_attn_metadata",
      "sampling_metadata",
      "mm_embed_inputs",
      "num_rejected_tokens_gpu",
      "slot_mappings"
    ],
    "set_inputs_first_pass": [
      "self",
      "target_token_ids",
      "next_token_ids",
      "target_positions",
      "last_token_indices",
      "cad",
      "num_rejected_tokens_gpu"
    ],
    "model_returns_tuple": [
      "self"
    ],
    "prepare_next_token_ids_cpu": [
      "self",
      "sampled_token_ids",
      "requests",
      "gpu_input_batch",
      "num_scheduled_tokens"
    ],
    "prepare_next_token_ids_padded": [
      "self",
      "common_attn_metadata",
      "sampled_token_ids",
      "requests",
      "gpu_input_batch",
      "discard_request_mask"
    ],
    "prepare_inputs_padded": [
      "self",
      "common_attn_metadata",
      "spec_decode_metadata",
      "valid_sampled_tokens_count"
    ],
    "propose_tree": [
      "self",
      "batch_size",
      "logits",
      "positions",
      "hidden_states",
      "common_attn_metadata",
      "slot_mappings"
    ],
    "prepare_inputs": [
      "self",
      "common_attn_metadata",
      "sampled_token_ids",
      "num_draft_tokens"
    ],
    "get_model_name": [
      "self",
      "model"
    ],
    "load_model": [
      "self",
      "target_model"
    ],
    "dummy_run": [
      "self",
      "num_tokens",
      "use_cudagraphs",
      "is_graph_capturing",
      "slot_mappings"
    ],
    "_get_attention_metadata_builder": [
      "self"
    ],
    "_get_eagle3_use_aux_hidden_state_from_config": [
      "self"
    ],
    "validate_same_kv_cache_group": [
      "self",
      "kv_cache_config"
    ],
    "_pad_batch_across_dp": [
      "self",
      "num_tokens_unpadded",
      "num_tokens_padded"
    ]
  },
  "EagleProposer": {
    "__init__": [
      "self",
      "vllm_config",
      "device",
      "runner"
    ]
  },
  "compute_probs_and_sample_next_token": [
    "logits",
    "sampling_metadata"
  ],
  "AttentionSelectorConfig": {
    "__repr__": [
      "self"
    ]
  },
  "get_attn_backend": [
    "head_size",
    "dtype",
    "kv_cache_dtype",
    "block_size",
    "use_mla",
    "has_sink",
    "use_sparse",
    "use_mm_prefix",
    "attn_type"
  ],
  "_cached_get_attn_backend": [
    "backend",
    "attn_selector_config"
  ],
  "get_mamba_attn_backend": [
    "mamba_type"
  ],
  "_cached_get_mamba_attn_backend": [
    "mamba_type"
  ],
  "AttentionType": {
    "DECODER": [],
    "ENCODER": [],
    "ENCODER_ONLY": [],
    "ENCODER_DECODER": []
  },
  "MultipleOf": {
    "__init__": [
      "self",
      "base"
    ]
  },
  "AttentionBackend": {
    "get_supported_kernel_block_sizes": [],
    "get_name": [],
    "get_impl_cls": [],
    "get_builder_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ],
    "get_kv_cache_stride_order": [
      "include_num_layers_dimension"
    ],
    "full_cls_name": [
      "cls"
    ],
    "get_supported_head_sizes": [
      "cls"
    ],
    "supports_head_size": [
      "cls",
      "head_size"
    ],
    "supports_dtype": [
      "cls",
      "dtype"
    ],
    "supports_kv_cache_dtype": [
      "cls",
      "kv_cache_dtype"
    ],
    "supports_block_size": [
      "cls",
      "block_size"
    ],
    "is_mla": [
      "cls"
    ],
    "supports_sink": [
      "cls"
    ],
    "supports_alibi_sqrt": [
      "cls"
    ],
    "supports_mm_prefix": [
      "cls"
    ],
    "is_sparse": [
      "cls"
    ],
    "supports_attn_type": [
      "cls",
      "attn_type"
    ],
    "supports_compute_capability": [
      "cls",
      "capability"
    ],
    "supports_combination": [
      "cls",
      "head_size",
      "dtype",
      "kv_cache_dtype",
      "block_size",
      "use_mla",
      "has_sink",
      "use_sparse",
      "device_capability"
    ],
    "validate_configuration": [
      "cls",
      "head_size",
      "dtype",
      "kv_cache_dtype",
      "block_size",
      "use_mla",
      "has_sink",
      "use_sparse",
      "use_mm_prefix",
      "device_capability",
      "attn_type"
    ],
    "get_required_kv_cache_layout": [
      "cls"
    ]
  },
  "AttentionMetadata": {},
  "CommonAttentionMetadata": {
    "batch_size": [
      "self"
    ],
    "naive_query_lens": [
      "self"
    ],
    "replace": [
      "self"
    ],
    "seq_lens_cpu": [
      "self"
    ],
    "num_computed_tokens_cpu": [
      "self"
    ],
    "compute_num_computed_tokens": [
      "self"
    ],
    "unpadded": [
      "self",
      "num_actual_tokens",
      "num_actual_reqs"
    ]
  },
  "AttentionCGSupport": {
    "ALWAYS": [],
    "UNIFORM_BATCH": [],
    "UNIFORM_SINGLE_TOKEN_DECODE": [],
    "NEVER": []
  },
  "AttentionMetadataBuilder": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "get_cudagraph_support": [
      "cls",
      "vllm_config",
      "kv_cache_spec"
    ],
    "_init_reorder_batch_threshold": [
      "self",
      "reorder_batch_threshold",
      "supports_spec_as_decode",
      "supports_dcp_with_varlen"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ],
    "update_block_table": [
      "self",
      "metadata",
      "blk_table",
      "slot_mapping"
    ],
    "build_for_cudagraph_capture": [
      "self",
      "common_attn_metadata"
    ],
    "build_for_drafting": [
      "self",
      "common_attn_metadata",
      "draft_index"
    ],
    "use_cascade_attention": [
      "self",
      "common_prefix_len",
      "query_lens",
      "num_query_heads",
      "num_kv_heads",
      "use_alibi",
      "use_sliding_window",
      "use_local_attention",
      "num_sms",
      "dcp_world_size"
    ]
  },
  "AttentionLayer": {
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "kv_cache",
      "attn_metadata"
    ]
  },
  "AttentionImpl": {
    "__new__": [
      "cls"
    ],
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name"
    ],
    "forward": [
      "self",
      "layer",
      "query",
      "key",
      "value",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ],
    "fused_output_quant_supported": [
      "self",
      "quant_key"
    ],
    "process_weights_after_loading": [
      "self",
      "act_dtype"
    ]
  },
  "MLAAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name",
      "q_lora_rank",
      "kv_lora_rank",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "qk_head_dim",
      "v_head_dim",
      "kv_b_proj",
      "indexer"
    ],
    "forward": [
      "self",
      "layer",
      "hidden_states_or_cq",
      "kv_c_normed",
      "k_pe",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ]
  },
  "is_quantized_kv_cache": [
    "kv_cache_dtype"
  ],
  "subclass_attention_backend": [
    "name_prefix",
    "attention_backend_cls",
    "builder_cls"
  ],
  "subclass_attention_backend_with_overrides": [
    "name_prefix",
    "attention_backend_cls",
    "overrides"
  ],
  "_correct_attn_cp_out_kernel": [
    "outputs_ptr",
    "new_output_ptr",
    "lses_ptr",
    "vlse_ptr",
    "outputs_stride_B",
    "outputs_stride_H",
    "outputs_stride_D",
    "lses_stride_N",
    "lses_stride_B",
    "lses_stride_H",
    "lse_idx",
    "HEAD_DIM",
    "N_ROUNDED",
    "IS_BASE_E"
  ],
  "CPTritonContext": {
    "__init__": [
      "self"
    ],
    "call_kernel": [
      "self",
      "kernel",
      "grid"
    ]
  },
  "correct_attn_out": [
    "out",
    "lses",
    "cp_rank",
    "ctx",
    "is_lse_base_on_e"
  ],
  "_cp_lse_common": [
    "cp_attn_out",
    "cp_attn_lse",
    "cp_group",
    "ctx",
    "is_lse_base_on_e"
  ],
  "cp_lse_ag_out_rs": [
    "cp_attn_out",
    "cp_attn_lse",
    "cp_group",
    "ctx",
    "return_lse",
    "is_lse_base_on_e"
  ],
  "cp_lse_ag_out_ar": [
    "cp_attn_out",
    "cp_attn_lse",
    "cp_group",
    "ctx",
    "return_lse",
    "is_lse_base_on_e"
  ],
  "_pack_seq_kernel": [
    "x_ptr",
    "out_ptr",
    "lengths_ptr",
    "N",
    "D",
    "Lmax",
    "PAD_VALUE",
    "BLOCK_T",
    "BLOCK_D"
  ],
  "pack_seq_triton": [
    "x",
    "lengths",
    "pad_value",
    "block_t",
    "block_d"
  ],
  "_unpack_seq_triton_kernel": [
    "packed_ptr",
    "out_ptr",
    "lengths_ptr",
    "B",
    "Lmax",
    "D",
    "BLOCK_T",
    "BLOCK_D"
  ],
  "unpack_seq_triton": [
    "packed_tensor",
    "lengths",
    "block_t",
    "block_d"
  ],
  "is_hip_": [],
  "tanh": [
    "x"
  ],
  "_fwd_kernel_stage1": [
    "Q",
    "K_Buffer",
    "V_Buffer",
    "sm_scale",
    "Req_to_tokens",
    "B_Seqlen",
    "Att_Out",
    "stride_req_to_tokens_b",
    "stride_qbs",
    "stride_qh",
    "stride_buf_kbs",
    "stride_buf_kh",
    "stride_buf_vbs",
    "stride_buf_vh",
    "stride_mid_ob",
    "stride_mid_oh",
    "stride_mid_os",
    "kv_group_num",
    "BLOCK_DMODEL",
    "BLOCK_DV",
    "BLOCK_N",
    "NUM_KV_SPLITS",
    "PAGE_SIZE",
    "logit_cap",
    "Lk",
    "Lv"
  ],
  "_decode_att_m_fwd": [
    "q",
    "k_buffer",
    "v_buffer",
    "att_out",
    "Req_to_tokens",
    "B_Seqlen",
    "num_kv_splits",
    "sm_scale",
    "page_size",
    "logit_cap"
  ],
  "_fwd_grouped_kernel_stage1": [
    "Q",
    "K_Buffer",
    "V_Buffer",
    "sm_scale",
    "Req_to_tokens",
    "B_Seqlen",
    "Att_Out",
    "stride_req_to_tokens_b",
    "stride_qbs",
    "stride_qh",
    "stride_buf_kbs",
    "stride_buf_kh",
    "stride_buf_vbs",
    "stride_buf_vh",
    "stride_mid_ob",
    "stride_mid_oh",
    "stride_mid_os",
    "kv_group_num",
    "q_head_num",
    "BLOCK_DMODEL",
    "BLOCK_DPE",
    "BLOCK_DV",
    "BLOCK_N",
    "BLOCK_H",
    "NUM_KV_SPLITS",
    "PAGE_SIZE",
    "logit_cap",
    "Lk",
    "Lv"
  ],
  "_decode_grouped_att_m_fwd": [
    "q",
    "k_buffer",
    "v_buffer",
    "att_out",
    "Req_to_tokens",
    "B_Seqlen",
    "num_kv_splits",
    "sm_scale",
    "page_size",
    "logit_cap"
  ],
  "_fwd_kernel_stage2": [
    "Mid_O",
    "o",
    "lse",
    "B_Seqlen",
    "stride_mid_ob",
    "stride_mid_oh",
    "stride_mid_os",
    "stride_obs",
    "stride_oh",
    "stride_lse_bs",
    "NUM_KV_SPLITS",
    "BLOCK_DV",
    "Lv"
  ],
  "_decode_softmax_reducev_fwd": [
    "logits",
    "q",
    "o",
    "lse",
    "v_buffer",
    "b_seq_len",
    "num_kv_splits"
  ],
  "decode_attention_fwd_normal": [
    "q",
    "k_buffer",
    "v_buffer",
    "o",
    "lse",
    "req_to_token",
    "b_seq_len",
    "attn_logits",
    "num_kv_splits",
    "sm_scale",
    "page_size",
    "logit_cap"
  ],
  "decode_attention_fwd_grouped": [
    "q",
    "k_buffer",
    "v_buffer",
    "o",
    "lse",
    "req_to_token",
    "b_seq_len",
    "attn_logits",
    "num_kv_splits",
    "sm_scale",
    "page_size",
    "logit_cap"
  ],
  "decode_attention_fwd": [
    "q",
    "k_buffer",
    "v_buffer",
    "o",
    "lse",
    "req_to_token",
    "b_seq_len",
    "attn_logits",
    "num_kv_splits",
    "sm_scale",
    "page_size",
    "logit_cap"
  ],
  "PagedAttention": {
    "split_kv_cache": [
      "kv_cache",
      "num_kv_heads",
      "head_size"
    ],
    "write_to_paged_cache": [
      "key",
      "value",
      "key_cache",
      "value_cache",
      "slot_mapping",
      "kv_cache_dtype",
      "k_scale",
      "v_scale"
    ]
  },
  "_indexer_k_quant_and_cache_kernel": [
    "k_ptr",
    "kv_cache_ptr",
    "kv_cache_scale_ptr",
    "slot_mapping_ptr",
    "kv_cache_scale_stride",
    "kv_cache_value_stride",
    "block_size",
    "num_tokens",
    "head_dim",
    "LAYOUT",
    "BLOCK_TILE_SIZE",
    "HEAD_TILE_SIZE",
    "IS_FNUZ",
    "USE_UE8M0"
  ],
  "indexer_k_quant_and_cache_triton": [
    "k",
    "kv_cache",
    "slot_mapping",
    "quant_block_size",
    "scale_fmt",
    "block_tile_size",
    "head_tile_size"
  ],
  "_cp_gather_indexer_quant_cache_kernel": [
    "kv_cache_ptr",
    "kv_cache_scale_ptr",
    "k_fp8_ptr",
    "k_scale_ptr",
    "block_table_ptr",
    "cu_seqlen_ptr",
    "token_to_seq_ptr",
    "block_size",
    "block_table_stride",
    "kv_cache_stride",
    "kv_cache_scale_stride",
    "LAYOUT",
    "HEAD_DIM",
    "BLOCK_TILE_SIZE",
    "HEAD_TILE_SIZE"
  ],
  "cp_gather_indexer_k_quant_cache_triton": [
    "k_cache",
    "k_fp8",
    "k_fp8_scale",
    "block_table",
    "cu_seqlen",
    "token_to_seq",
    "block_tile_size",
    "head_tile_size"
  ],
  "fp8_paged_mqa_logits_torch": [
    "q",
    "kv_cache",
    "weights",
    "context_lens",
    "block_tables",
    "max_model_len"
  ],
  "rocm_fp8_paged_mqa_logits": [
    "q_fp8",
    "kv_cache_fp8",
    "weights",
    "context_lens",
    "block_tables",
    "schedule_metadata",
    "max_model_len"
  ],
  "fp8_mqa_logits_torch": [
    "q",
    "kv",
    "weights",
    "cu_seqlen_ks",
    "cu_seqlen_ke"
  ],
  "rocm_fp8_mqa_logits": [
    "q",
    "kv",
    "weights",
    "cu_seqlen_ks",
    "cu_seqlen_ke"
  ],
  "rocm_aiter_sparse_attn_indexer_fake": [
    "hidden_states",
    "k_cache_prefix",
    "kv_cache",
    "q_fp8",
    "k",
    "weights",
    "quant_block_size",
    "scale_fmt",
    "topk_tokens",
    "head_dim",
    "max_model_len",
    "total_seq_lens",
    "topk_indices_buffer"
  ],
  "rocm_aiter_sparse_attn_indexer": [
    "hidden_states",
    "k_cache_prefix",
    "kv_cache",
    "q_fp8",
    "k",
    "weights",
    "quant_block_size",
    "scale_fmt",
    "topk_tokens",
    "head_dim",
    "max_model_len",
    "total_seq_lens",
    "topk_indices_buffer"
  ],
  "float8_info": [],
  "cdiv_fn": [
    "x",
    "y"
  ],
  "apply_softcap": [
    "S",
    "x"
  ],
  "find_seq_idx": [
    "query_start_len_ptr",
    "target_idx",
    "num_seqs",
    "BLOCK_Q",
    "use_q_block_mode"
  ],
  "kernel_unified_attention_2d": [
    "output_ptr",
    "query_ptr",
    "key_cache_ptr",
    "value_cache_ptr",
    "sink_ptr",
    "block_tables_ptr",
    "seq_lens_ptr",
    "alibi_slopes_ptr",
    "qq_bias_ptr",
    "scale",
    "k_scale",
    "v_scale",
    "out_scale",
    "softcap",
    "num_query_heads",
    "num_queries_per_kv",
    "block_table_stride",
    "query_stride_0",
    "query_stride_1",
    "output_stride_0",
    "output_stride_1",
    "qq_bias_stride_0",
    "BLOCK_SIZE",
    "TILE_SIZE",
    "HEAD_SIZE",
    "HEAD_SIZE_PADDED",
    "USE_ALIBI_SLOPES",
    "USE_ALIBI_SQRT",
    "USE_QQ_BIAS",
    "USE_SOFTCAP",
    "USE_SINKS",
    "SLIDING_WINDOW",
    "USE_MM_PREFIX",
    "MAX_MM_RANGES",
    "mm_prefix_range_ptr",
    "stride_k_cache_0",
    "stride_k_cache_1",
    "stride_k_cache_2",
    "stride_k_cache_3",
    "stride_v_cache_0",
    "stride_v_cache_1",
    "stride_v_cache_2",
    "stride_v_cache_3",
    "query_start_len_ptr",
    "BLOCK_Q",
    "num_seqs",
    "BLOCK_M",
    "USE_FP8",
    "FP8_MIN",
    "FP8_MAX"
  ],
  "kernel_unified_attention_3d": [
    "segm_output_ptr",
    "segm_max_ptr",
    "segm_expsum_ptr",
    "query_ptr",
    "key_cache_ptr",
    "value_cache_ptr",
    "sink_ptr",
    "block_tables_ptr",
    "seq_lens_ptr",
    "alibi_slopes_ptr",
    "qq_bias_ptr",
    "scale",
    "k_scale",
    "v_scale",
    "softcap",
    "num_query_heads",
    "num_queries_per_kv",
    "block_table_stride",
    "query_stride_0",
    "query_stride_1",
    "qq_bias_stride_0",
    "BLOCK_SIZE",
    "TILE_SIZE",
    "HEAD_SIZE",
    "HEAD_SIZE_PADDED",
    "USE_ALIBI_SLOPES",
    "USE_ALIBI_SQRT",
    "USE_QQ_BIAS",
    "USE_SOFTCAP",
    "USE_SINKS",
    "SLIDING_WINDOW",
    "stride_k_cache_0",
    "stride_k_cache_1",
    "stride_k_cache_2",
    "stride_k_cache_3",
    "stride_v_cache_0",
    "stride_v_cache_1",
    "stride_v_cache_2",
    "stride_v_cache_3",
    "query_start_len_ptr",
    "BLOCK_Q",
    "num_seqs",
    "BLOCK_M",
    "NUM_SEGMENTS_PER_SEQ",
    "USE_MM_PREFIX",
    "MAX_MM_RANGES",
    "mm_prefix_range_ptr"
  ],
  "reduce_segments": [
    "output_ptr",
    "segm_output_ptr",
    "segm_max_ptr",
    "segm_expsum_ptr",
    "seq_lens_ptr",
    "num_seqs",
    "num_query_heads",
    "out_scale_inv",
    "output_stride_0",
    "output_stride_1",
    "block_table_stride",
    "TILE_SIZE",
    "HEAD_SIZE",
    "HEAD_SIZE_PADDED",
    "query_start_len_ptr",
    "BLOCK_Q",
    "NUM_SEGMENTS_PER_SEQ",
    "USE_FP8",
    "FP8_MIN",
    "FP8_MAX"
  ],
  "_is_gemma3_attention": [
    "head_size",
    "sliding_window"
  ],
  "_get_tile_size": [
    "head_size",
    "sliding_window",
    "element_size",
    "is_prefill"
  ],
  "reshape_and_cache_kernel_flash": [
    "key_ptr",
    "value_ptr",
    "key_cache_ptr",
    "value_cache_ptr",
    "slot_mapping_ptr",
    "k_scale",
    "v_scale",
    "key_stride",
    "value_stride",
    "block_stride",
    "head_stride",
    "dim_stride_k",
    "dim_stride_v",
    "page_stride",
    "num_heads",
    "head_size",
    "block_size",
    "x",
    "USE_HEAD_MAJOR_LAYOUT",
    "FP8_KV_CACHE",
    "TILE_SIZE"
  ],
  "triton_reshape_and_cache_flash": [
    "key",
    "value",
    "key_cache",
    "value_cache",
    "slot_mapping",
    "kv_cache_dtype",
    "k_scale",
    "v_scale"
  ],
  "reshape_and_cache_kernel_flash_diffkv": [
    "key_ptr",
    "value_ptr",
    "kv_cache_ptr",
    "slot_mapping_ptr",
    "k_scale",
    "v_scale",
    "key_stride",
    "value_stride",
    "block_stride",
    "page_stride",
    "num_heads",
    "head_size_k",
    "head_size_v",
    "block_size",
    "FP8_KV_CACHE",
    "TILE_SIZE"
  ],
  "triton_reshape_and_cache_flash_diffkv": [
    "key",
    "value",
    "kv_cache",
    "slot_mapping",
    "kv_cache_dtype",
    "k_scale",
    "v_scale"
  ],
  "merge_attn_states_kernel": [
    "output",
    "output_lse",
    "prefix_output",
    "prefix_lse",
    "suffix_output",
    "suffix_lse",
    "prefix_head_stride",
    "output_head_stride",
    "HEAD_SIZE",
    "PADDED_HEAD_SIZE",
    "OUTPUT_LSE"
  ],
  "flash_attn_maxseqlen_wrapper": [
    "q",
    "k",
    "v",
    "batch_size",
    "is_rocm_aiter",
    "fa_version",
    "scale",
    "cu_seqlens",
    "max_seqlen"
  ],
  "flash_attn_maxseqlen_wrapper_fake": [
    "q",
    "k",
    "v",
    "batch_size",
    "is_rocm_aiter",
    "fa_version",
    "scale",
    "cu_seqlens",
    "max_seqlen"
  ],
  "vit_flash_attn_wrapper": [
    "q",
    "k",
    "v",
    "batch_size",
    "is_rocm_aiter",
    "fa_version",
    "scale",
    "cu_seqlens",
    "max_seqlen"
  ],
  "apply_sdpa": [
    "q",
    "k",
    "v",
    "scale"
  ],
  "torch_sdpa_wrapper": [
    "q",
    "k",
    "v",
    "scale",
    "cu_seqlens"
  ],
  "torch_sdpa_wrapper_fake": [
    "q",
    "k",
    "v",
    "scale",
    "cu_seqlens"
  ],
  "vit_torch_sdpa_wrapper": [
    "q",
    "k",
    "v",
    "scale",
    "cu_seqlens"
  ],
  "_is_flashmla_available": [],
  "is_flashmla_dense_supported": [],
  "is_flashmla_sparse_supported": [],
  "_raise_flashmla_unavailable": [],
  "get_mla_metadata_dense_fp8": [
    "cache_seqlens",
    "num_q_tokens_per_head_k",
    "num_heads_k"
  ],
  "flash_mla_with_kvcache_fp8": [
    "q",
    "k_cache",
    "block_table",
    "cache_seqlens",
    "head_dim_v",
    "tile_scheduler_metadata",
    "num_splits",
    "softmax_scale",
    "causal",
    "descale_q",
    "descale_k"
  ],
  "kernel_paged_attention_2d": [
    "output_ptr",
    "query_ptr",
    "key_cache_ptr",
    "value_cache_ptr",
    "sink_ptr",
    "block_tables_ptr",
    "seq_lens_ptr",
    "alibi_slopes_ptr",
    "scale",
    "k_scale",
    "v_scale",
    "out_scale_inv",
    "num_query_heads",
    "num_queries_per_kv",
    "num_queries_per_kv_padded",
    "block_table_stride",
    "query_stride_0",
    "query_stride_1",
    "output_stride_0",
    "output_stride_1",
    "BLOCK_SIZE",
    "PHYSICAL_BLOCK_SIZE",
    "HEAD_SIZE",
    "HEAD_SIZE_PADDED",
    "USE_ALIBI_SLOPES",
    "SLIDING_WINDOW",
    "x",
    "stride_k_cache_0",
    "stride_k_cache_1",
    "stride_k_cache_2",
    "stride_k_cache_3",
    "stride_k_cache_4",
    "stride_v_cache_0",
    "stride_v_cache_1",
    "stride_v_cache_2",
    "stride_v_cache_3",
    "filter_by_query_len",
    "query_start_len_ptr",
    "USE_SINKS",
    "USE_FP8",
    "FP8_MIN",
    "FP8_MAX"
  ],
  "chunked_prefill_paged_decode": [
    "query",
    "key",
    "value",
    "output",
    "kv_cache_dtype",
    "key_cache",
    "value_cache",
    "block_table",
    "query_start_loc",
    "seq_lens",
    "max_seq_len",
    "max_query_len",
    "k_scale",
    "v_scale",
    "alibi_slopes",
    "sliding_window",
    "sm_scale",
    "output_scale",
    "sinks",
    "is_block_table_ptr"
  ],
  "_fwd_kernel": [
    "Q",
    "K",
    "V",
    "sm_scale",
    "B_Start_Loc",
    "B_Seqlen",
    "Out",
    "stride_qbs",
    "stride_qh",
    "stride_kbs",
    "stride_kh",
    "stride_vbs",
    "stride_vh",
    "stride_obs",
    "stride_oh",
    "kv_group_num",
    "BLOCK_M",
    "BLOCK_DMODEL",
    "BLOCK_N",
    "IS_CAUSAL",
    "SLIDING_WINDOW_Q",
    "SLIDING_WINDOW_K",
    "Lk"
  ],
  "get_block_size": [
    "dtype"
  ],
  "context_attention_fwd": [
    "q",
    "k",
    "v",
    "o",
    "b_start_loc",
    "b_seq_len",
    "max_input_len",
    "is_causal",
    "softmax_scale",
    "sliding_window_q",
    "sliding_window_k"
  ],
  "BASE_BLOCK": [],
  "IS_TURING": [],
  "_fwd_kernel_alibi": [
    "Q",
    "K",
    "V",
    "K_cache",
    "V_cache",
    "B_Loc",
    "sm_scale",
    "k_scale",
    "v_scale",
    "B_Start_Loc",
    "B_Seqlen",
    "Alibi_slopes",
    "block_size",
    "x",
    "Out",
    "stride_b_loc_b",
    "stride_b_loc_s",
    "stride_qbs",
    "stride_qh",
    "stride_qd",
    "stride_kbs",
    "stride_kh",
    "stride_kd",
    "stride_vbs",
    "stride_vh",
    "stride_vd",
    "stride_obs",
    "stride_oh",
    "stride_od",
    "stride_k_cache_bs",
    "stride_k_cache_h",
    "stride_k_cache_d",
    "stride_k_cache_bl",
    "stride_k_cache_x",
    "stride_v_cache_bs",
    "stride_v_cache_h",
    "stride_v_cache_d",
    "stride_v_cache_bl",
    "num_queries_per_kv",
    "IN_PRECISION",
    "BLOCK_M",
    "BLOCK_DMODEL",
    "BLOCK_DMODEL_PADDED",
    "BLOCK_N",
    "SKIP_DECODE"
  ],
  "BaseMambaAttentionMetadata": {},
  "BaseMambaAttentionMetadataBuilder": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "build_for_cudagraph_capture": [
      "self",
      "common_attn_metadata"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ],
    "_compute_prefix_caching_block_indices": [
      "self",
      "common_attn_metadata",
      "mamba_block_size"
    ],
    "_compute_common_metadata": [
      "self",
      "common_attn_metadata"
    ],
    "update_block_table": [
      "self",
      "metadata",
      "blk_table",
      "slot_mapping"
    ]
  },
  "LinearAttentionBackend": {
    "get_name": [],
    "get_builder_cls": []
  },
  "LinearAttentionMetadata": {},
  "LinearAttentionMetadataBuilder": {
    "_cudagraph_support": [],
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ]
  },
  "TreeAttentionBackend": {
    "get_supported_kernel_block_sizes": [],
    "get_supported_head_sizes": [
      "cls"
    ],
    "get_name": [],
    "get_impl_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ],
    "get_builder_cls": [],
    "use_cascade_attention": []
  },
  "TreeAttentionMetadata": {
    "prefill_metadata": [
      "self"
    ],
    "decode_metadata": [
      "self"
    ]
  },
  "TreeAttentionMetadataBuilder": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ],
    "build_for_drafting": [
      "self",
      "common_attn_metadata",
      "draft_index"
    ]
  },
  "_get_depth_counts": [
    "sorted_tree_choices"
  ],
  "_prepare_tree_attn_bias": [
    "sorted_tree_choices",
    "depth_counts",
    "dtype",
    "device"
  ],
  "TreeAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name"
    ],
    "forward": [
      "self",
      "layer",
      "query",
      "key",
      "value",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ]
  },
  "_PARTITION_SIZE_ROCM": [],
  "_CP_TOKENS_PER_ITER_ROCM": [],
  "AiterFlashAttentionDecodeMetadata": {},
  "AiterFlashAttentionPrefillMetadata": {},
  "AiterChunkSlidingWindowMetadata": {},
  "AiterChunkContextMetadata": {},
  "AiterFlashAttentionChunkPrefillMetadata": {},
  "AiterFlashAttentionMetadata": {},
  "AiterFlashAttentionMetadataBuilder": {
    "_cudagraph_support": [],
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "build_for_cudagraph_capture": [
      "self",
      "common_attn_metadata"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ],
    "use_cascade_attention": [
      "self"
    ]
  },
  "AiterFlashAttentionBackend": {
    "get_supported_kernel_block_sizes": [],
    "get_supported_head_sizes": [
      "cls"
    ],
    "get_name": [],
    "get_impl_cls": [],
    "get_builder_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ]
  },
  "AiterFlashAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name"
    ],
    "extend_for_sliding_window": [
      "self",
      "attn_metadata",
      "query",
      "key_cache",
      "value_cache",
      "output",
      "cu_seqlens_q",
      "max_seqlen_q",
      "block_table",
      "k_scale",
      "v_scale"
    ],
    "extend_forward": [
      "self",
      "attn_metadata",
      "query",
      "key",
      "value",
      "key_cache",
      "value_cache",
      "output",
      "cu_seqlens_q",
      "max_seqlen_q",
      "max_seqlen_k",
      "min_seqlen_q",
      "block_table",
      "slot_mapping",
      "k_scale",
      "v_scale"
    ],
    "forward": [
      "self",
      "layer",
      "query",
      "key",
      "value",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ]
  },
  "_CPU_ARCH_PREFER_MIXED_BATCH": [],
  "CPUAttentionBackend": {
    "get_supported_dtypes": [
      "cls"
    ],
    "get_supported_head_sizes": [
      "cls"
    ],
    "get_name": [],
    "supports_attn_type": [
      "cls",
      "attn_type"
    ],
    "get_impl_cls": [],
    "get_builder_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ],
    "use_cascade_attention": []
  },
  "CPUAttentionMetadata": {},
  "CPUAttentionMetadataBuilder": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ]
  },
  "CPUAttentionBackendImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name",
      "sinks"
    ],
    "forward": [
      "self",
      "layer",
      "query",
      "key",
      "value",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ],
    "_run_sdpa_forward": [
      "self",
      "query",
      "key",
      "value",
      "output",
      "attn_metadata",
      "attn_type"
    ]
  },
  "_make_alibi_bias": [
    "alibi_slopes",
    "dtype",
    "sdpa_start_loc"
  ],
  "_make_sliding_window_bias": [
    "sdpa_start_loc",
    "left_window_size",
    "right_window_size",
    "dtype"
  ],
  "_get_attn_isa": [
    "dtype",
    "block_size",
    "head_size"
  ],
  "compute_varlen_chunk_metadata": [
    "query_start_loc",
    "chunk_size"
  ],
  "Mamba2AttentionBackend": {
    "get_name": [],
    "get_builder_cls": []
  },
  "Mamba2AttentionMetadata": {},
  "Mamba2AttentionMetadataBuilder": {
    "metadata_cls": [],
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "_compute_chunk_metadata": [
      "self",
      "num_prefills",
      "num_computed_tokens_p_cpu",
      "query_start_loc_p_cpu"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ]
  },
  "Mamba1AttentionBackend": {
    "get_name": [],
    "get_builder_cls": []
  },
  "Mamba1AttentionMetadata": {},
  "Mamba1AttentionMetadataBuilder": {
    "metadata_cls": []
  },
  "FlashAttentionBackend": {
    "get_supported_kernel_block_sizes": [],
    "get_name": [],
    "supports_attn_type": [
      "cls",
      "attn_type"
    ],
    "get_impl_cls": [],
    "get_builder_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ],
    "get_kv_cache_stride_order": [
      "include_num_layers_dimension"
    ],
    "get_fp8_dtype_for_flashattn": [
      "kv_cache_dtype"
    ],
    "supports_head_size": [
      "cls",
      "head_size"
    ],
    "supports_kv_cache_dtype": [
      "cls",
      "kv_cache_dtype"
    ],
    "supports_sink": [
      "cls"
    ],
    "supports_compute_capability": [
      "cls",
      "capability"
    ],
    "supports_combination": [
      "cls",
      "head_size",
      "dtype",
      "kv_cache_dtype",
      "block_size",
      "use_mla",
      "has_sink",
      "use_sparse",
      "device_capability"
    ]
  },
  "FlashAttentionMetadata": {},
  "_get_sliding_window_configs": [
    "vllm_config"
  ],
  "FlashAttentionMetadataBuilder": {
    "_cudagraph_support": [],
    "get_cudagraph_support": [
      "cls",
      "vllm_config",
      "kv_cache_spec"
    ],
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ],
    "update_block_table": [
      "self",
      "metadata",
      "blk_table",
      "slot_mapping"
    ],
    "use_cascade_attention": [
      "self"
    ]
  },
  "FlashAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name",
      "sinks"
    ],
    "forward": [
      "self",
      "layer",
      "query",
      "key",
      "value",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ],
    "do_kv_cache_update": [
      "self",
      "layer",
      "key",
      "value",
      "kv_cache",
      "slot_mapping"
    ],
    "_forward_with_dcp": [
      "self",
      "query",
      "key",
      "value",
      "key_cache",
      "value_cache",
      "output",
      "attn_metadata",
      "q_descale",
      "k_descale",
      "v_descale"
    ],
    "_forward_encoder_attention": [
      "self",
      "query",
      "key",
      "value",
      "output",
      "attn_metadata",
      "layer"
    ]
  },
  "use_cascade_attention": [
    "common_prefix_len",
    "query_lens",
    "num_query_heads",
    "num_kv_heads",
    "use_alibi",
    "use_sliding_window",
    "use_local_attention",
    "num_sms",
    "dcp_world_size"
  ],
  "cascade_attention": [
    "output",
    "query",
    "key_cache",
    "value_cache",
    "cu_query_lens",
    "max_query_len",
    "cu_prefix_query_lens",
    "prefix_kv_lens",
    "suffix_kv_lens",
    "max_kv_len",
    "softmax_scale",
    "alibi_slopes",
    "sliding_window",
    "logits_soft_cap",
    "block_table",
    "common_prefix_len",
    "max_num_splits",
    "fa_version",
    "prefix_scheduler_metadata",
    "suffix_scheduler_metadata",
    "q_descale",
    "k_descale",
    "v_descale",
    "s_aux"
  ],
  "ShortConvAttentionBackend": {
    "get_name": [],
    "get_builder_cls": []
  },
  "ShortConvAttentionMetadata": {},
  "ShortConvAttentionMetadataBuilder": {
    "metadata_cls": []
  },
  "KVCacheLayoutType": [],
  "PAD_SLOT_ID": [],
  "is_valid_kv_cache_layout": [
    "value"
  ],
  "get_kv_cache_layout": [],
  "set_kv_cache_layout": [
    "cache_layout"
  ],
  "PerLayerParameters": {},
  "get_per_layer_parameters": [
    "vllm_config",
    "layer_names",
    "cls_"
  ],
  "infer_global_hyperparameters": [
    "per_layer_params"
  ],
  "make_local_attention_virtual_batches": [
    "attn_chunk_size",
    "common_attn_metadata",
    "block_size"
  ],
  "make_kv_sharing_fast_prefill_common_attn_metadata": [
    "common_attn_metadata"
  ],
  "split_decodes_prefills_and_extends": [
    "common_attn_metadata",
    "decode_threshold"
  ],
  "split_decodes_and_prefills": [
    "common_attn_metadata",
    "decode_threshold",
    "require_uniform"
  ],
  "split_prefill_chunks": [
    "seq_lens_cpu",
    "workspace_size",
    "request_offset"
  ],
  "reorder_batch_to_split_decodes_and_prefills": [
    "input_batch",
    "scheduler_output",
    "decode_threshold"
  ],
  "reshape_query_for_spec_decode": [
    "query",
    "batch_size"
  ],
  "reshape_attn_output_for_spec_decode": [
    "attn_output"
  ],
  "subclass_attention_metadata": [
    "name_prefix",
    "metadata_cls",
    "fields"
  ],
  "KVSharingFastPrefillMetadata": {},
  "create_fast_prefill_custom_backend": [
    "prefix",
    "underlying_attn_backend"
  ],
  "compute_causal_conv1d_metadata": [
    "query_start_loc_p_cpu"
  ],
  "get_dcp_local_seq_lens": [
    "seq_lens",
    "dcp_size",
    "dcp_rank",
    "cp_kv_cache_interleave_size"
  ],
  "extend_all_queries_by_1": [
    "common_attn_metadata",
    "arange",
    "new_slot_mapping"
  ],
  "mamba_get_block_table_tensor": [
    "block_table",
    "seq_lens",
    "kv_cache_spec",
    "mamba_cache_mode"
  ],
  "MIN_LAUNCH_GRID_SIZE_2D": [],
  "NUM_PAR_SOFTMAX_SEGMENTS": [],
  "TritonAttentionMetadata": {
    "mm_prefix_range_tensor": [
      "self"
    ]
  },
  "TritonAttentionMetadataBuilder": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "build_for_cudagraph_capture": [
      "self",
      "common_attn_metadata"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ]
  },
  "TritonAttentionBackend": {
    "get_supported_kernel_block_sizes": [],
    "get_name": [],
    "get_impl_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ],
    "get_kv_cache_stride_order": [
      "include_num_layers_dimension"
    ],
    "use_cascade_attention": [],
    "get_builder_cls": [],
    "supports_head_size": [
      "cls",
      "head_size"
    ],
    "supports_mm_prefix": [
      "cls"
    ],
    "supports_sink": [
      "cls"
    ],
    "supports_attn_type": [
      "cls",
      "attn_type"
    ],
    "supports_alibi_sqrt": [
      "cls"
    ],
    "supports_compute_capability": [
      "cls",
      "capability"
    ]
  },
  "TritonAttentionImpl": {
    "fused_output_quant_supported": [
      "self",
      "quant_key"
    ],
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name",
      "sinks",
      "use_alibi_sqrt"
    ],
    "forward": [
      "self",
      "layer",
      "query",
      "key",
      "value",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ],
    "_forward_encoder_attention": [
      "self",
      "query",
      "key",
      "value",
      "output",
      "attn_metadata",
      "layer"
    ]
  },
  "FLASHINFER_WORKSPACE_BUFFER_SIZE_BATCH_INVARIANT": [],
  "trtllm_gen_workspace_buffer": [],
  "_get_trtllm_gen_workspace_buffer": [],
  "_trtllm_prefill_attn_kvfp8_dequant": [
    "kv_cache_ptr",
    "block_tables_prefill_ptr",
    "block_table_stride",
    "mock_kv_cache_ptr",
    "k_scale_ptr",
    "v_scale_ptr",
    "K_CACHE_STRIDE",
    "KV_CACHE_STRIDE"
  ],
  "trtllm_prefill_attn_kvfp8_dequant": [
    "kv_cache",
    "block_tables_prefill",
    "k_scale",
    "v_scale",
    "dequant_dtype"
  ],
  "BatchDCPPrefillWrapper": {
    "__init__": [
      "self",
      "workspace_buffer"
    ],
    "plan": [
      "self",
      "qo_indptr_cpu",
      "paged_kv_indptr_cpu",
      "paged_kv_indices",
      "paged_kv_last_page_len_cpu",
      "page_size",
      "num_qo_heads",
      "dcp_world_size",
      "num_kv_heads",
      "head_dim",
      "sm_scale",
      "window_left",
      "logits_soft_cap",
      "q_data_type",
      "kv_cache_dtype",
      "prefill_fixed_split_size",
      "disable_split_kv"
    ],
    "run": [
      "self",
      "layer",
      "prefill_query",
      "kv_cache_permute",
      "key",
      "value",
      "out"
    ]
  },
  "FlashInferBackend": {
    "get_supported_kernel_block_sizes": [],
    "get_name": [],
    "get_impl_cls": [],
    "get_builder_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ],
    "get_kv_cache_stride_order": [
      "include_num_layers_dimension"
    ],
    "get_fp8_dtype_for_flashinfer": [
      "kv_cache_dtype"
    ],
    "get_supported_head_sizes": [
      "cls"
    ],
    "supports_compute_capability": [
      "cls",
      "capability"
    ],
    "supports_sink": [
      "cls"
    ],
    "get_required_kv_cache_layout": [
      "cls"
    ]
  },
  "FIPrefill": {},
  "FIDecode": {},
  "TRTLLMPrefill": {},
  "TRTLLMDecode": {},
  "FlashInferMetadata": {},
  "FlashInferMetadataBuilder": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "_make_buffer": [
      "self"
    ],
    "get_cudagraph_support": [
      "cls",
      "vllm_config",
      "kv_cache_spec"
    ],
    "_get_workspace_buffer": [
      "self"
    ],
    "set_workspace_buffer": [
      "self",
      "workspace_buffer"
    ],
    "_get_prefill_wrapper": [
      "self"
    ],
    "_get_decode_wrapper": [
      "self",
      "batch_size",
      "use_cudagraph"
    ],
    "_get_cascade_wrapper": [
      "self"
    ],
    "_compute_flashinfer_kv_metadata": [
      "self",
      "num_blocks_np",
      "seq_lens_np",
      "block_table_tensor",
      "num_reqs",
      "page_size"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ],
    "use_cascade_attention": [
      "self"
    ]
  },
  "FlashInferImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name",
      "sinks"
    ],
    "fused_output_quant_supported": [
      "self",
      "quant_key"
    ],
    "process_weights_after_loading": [
      "self",
      "act_dtype"
    ],
    "forward": [
      "self",
      "layer",
      "query",
      "key",
      "value",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ]
  },
  "fast_plan_decode": [
    "self",
    "indptr_cpu",
    "indices",
    "last_page_len_cpu",
    "seq_lens_cpu",
    "num_qo_heads",
    "num_kv_heads",
    "head_dim",
    "page_size",
    "pos_encoding_mode",
    "window_left",
    "logits_soft_cap",
    "q_data_type",
    "kv_data_type",
    "o_data_type",
    "data_type",
    "sm_scale",
    "rope_scale",
    "rope_theta",
    "non_blocking",
    "fixed_split_size",
    "disable_split_kv"
  ],
  "_copy_page_indices_kernel": [
    "page_indices",
    "block_table",
    "block_table_stride",
    "cu_num_blocks",
    "BLOCK_SIZE"
  ],
  "FlashAttentionDiffKVBackend": {
    "set_head_size_v": [
      "cls",
      "head_size_v"
    ],
    "get_name": [],
    "get_impl_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ],
    "get_kv_cache_stride_order": [
      "include_num_layers_dimension"
    ]
  },
  "FlashAttentionDiffKVImpl": {
    "forward": [
      "self",
      "layer",
      "query",
      "key",
      "value",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ]
  },
  "create_block_mask_compiled": [],
  "flex_attention_compiled": [],
  "_offsets_to_doc_ids_tensor": [
    "offsets"
  ],
  "pad_to_multiple": [
    "x",
    "multiple",
    "dim"
  ],
  "FlexAttentionBackend": {
    "get_name": [],
    "supports_attn_type": [
      "cls",
      "attn_type"
    ],
    "supports_mm_prefix": [
      "cls"
    ],
    "get_impl_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ],
    "get_builder_cls": [],
    "use_cascade_attention": [],
    "get_supported_head_sizes": [
      "cls"
    ]
  },
  "physical_to_logical_mapping": [
    "block_table",
    "seq_lens",
    "block_size",
    "total_blocks"
  ],
  "unique_static_unsorted": [
    "x"
  ],
  "causal_mask_mod": [
    "b",
    "h",
    "q_idx",
    "kv_idx"
  ],
  "FlexAttentionMetadata": {
    "num_blocks": [],
    "logical_block_ids": [
      "self"
    ],
    "_convert_physical_to_logical": [
      "self",
      "request_lookup",
      "q_idx",
      "physical_kv_idx"
    ],
    "get_causal_mask_mod": [
      "self"
    ],
    "get_bidirectional_mask_mod": [
      "self"
    ],
    "get_sliding_window_mask_mod": [
      "self"
    ],
    "get_prefix_lm_mask_mod": [
      "self"
    ],
    "get_mask_mod": [
      "self"
    ],
    "get_transformed_score_mod": [
      "self"
    ],
    "_build_block_mask_direct": [
      "self"
    ],
    "build_block_mask": [
      "self"
    ],
    "__post_init__": [
      "self"
    ]
  },
  "FlexAttentionMetadataBuilder": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ],
    "use_cascade_attention": [
      "self"
    ]
  },
  "FlexAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name"
    ],
    "view_as_4d": [
      "tensor"
    ],
    "forward": [
      "self",
      "layer",
      "query",
      "key",
      "value",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ]
  },
  "get_kernel_options": [
    "query",
    "block_m",
    "block_n",
    "use_direct_build"
  ],
  "RocmAttentionMetadata": {},
  "RocmAttentionMetadataBuilder": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "build_for_cudagraph_capture": [
      "self",
      "common_attn_metadata"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ]
  },
  "RocmAttentionBackend": {
    "get_supported_kernel_block_sizes": [],
    "get_supported_head_sizes": [
      "cls"
    ],
    "validate_head_size": [
      "cls",
      "head_size"
    ],
    "get_name": [],
    "get_impl_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ],
    "use_cascade_attention": [],
    "get_builder_cls": []
  },
  "RocmAttentionImpl": {
    "fused_output_quant_supported": [
      "self",
      "quant_key"
    ],
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name",
      "sinks"
    ],
    "forward": [
      "self",
      "layer",
      "query",
      "key",
      "value",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ]
  },
  "_AttentionBackendEnumMeta": {
    "__getitem__": [
      "cls",
      "name"
    ]
  },
  "AttentionBackendEnum": {
    "FLASH_ATTN": [],
    "FLASH_ATTN_DIFFKV": [],
    "TRITON_ATTN": [],
    "ROCM_ATTN": [],
    "ROCM_AITER_MLA": [],
    "ROCM_AITER_TRITON_MLA": [],
    "ROCM_AITER_FA": [],
    "ROCM_AITER_MLA_SPARSE": [],
    "TORCH_SDPA": [],
    "FLASHINFER": [],
    "FLASHINFER_MLA": [],
    "TRITON_MLA": [],
    "CUTLASS_MLA": [],
    "FLASHMLA": [],
    "FLASHMLA_SPARSE": [],
    "FLASH_ATTN_MLA": [],
    "IPEX": [],
    "NO_ATTENTION": [],
    "FLEX_ATTENTION": [],
    "TREE_ATTN": [],
    "ROCM_AITER_UNIFIED_ATTN": [],
    "CPU_ATTN": [],
    "CUSTOM": [],
    "get_path": [
      "self",
      "include_classname"
    ],
    "get_class": [
      "self"
    ],
    "is_overridden": [
      "self"
    ],
    "clear_override": [
      "self"
    ]
  },
  "MambaAttentionBackendEnum": {
    "MAMBA1": [],
    "MAMBA2": [],
    "SHORT_CONV": [],
    "LINEAR": [],
    "GDN_ATTN": [],
    "CUSTOM": [],
    "get_path": [
      "self",
      "include_classname"
    ],
    "get_class": [
      "self"
    ],
    "is_overridden": [
      "self"
    ],
    "clear_override": [
      "self"
    ]
  },
  "MAMBA_TYPE_TO_BACKEND_MAP": [],
  "register_backend": [
    "backend",
    "class_path",
    "is_mamba"
  ],
  "RocmAiterUnifiedAttentionBackend": {
    "get_name": [],
    "get_impl_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ],
    "use_cascade_attention": [],
    "get_builder_cls": []
  },
  "RocmAiterUnifiedAttentionImpl": {
    "fused_output_quant_supported": [
      "self",
      "quant_key"
    ],
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name",
      "sinks"
    ],
    "forward": [
      "self",
      "layer",
      "query",
      "key",
      "value",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ]
  },
  "get_flash_attn_version": [
    "requires_alibi"
  ],
  "flash_attn_supports_fp8": [],
  "flash_attn_supports_sinks": [],
  "flash_attn_supports_mla": [],
  "is_flash_attn_varlen_func_available": [],
  "GDNAttentionBackend": {
    "get_name": [],
    "get_builder_cls": []
  },
  "GDNAttentionMetadata": {},
  "GDNAttentionMetadataBuilder": {
    "_cudagraph_support": [],
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "num_accepted_tokens",
      "num_decode_draft_tokens_cpu",
      "fast_build"
    ],
    "build_for_cudagraph_capture": [
      "self",
      "common_attn_metadata"
    ]
  },
  "AiterMLABackend": {
    "get_supported_kernel_block_sizes": [],
    "get_name": [],
    "get_impl_cls": [],
    "get_builder_cls": []
  },
  "AiterMLADecodeMetadata": {},
  "AiterMLAMetadata": {},
  "AiterMLAMetadataBuilder": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "_build_decode": [
      "self",
      "block_table_tensor",
      "seq_lens_device",
      "max_seq_len",
      "query_start_loc_cpu",
      "query_start_loc_device",
      "num_decode_tokens",
      "dcp_tot_seq_lens_device"
    ]
  },
  "AiterMLAImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name"
    ],
    "_flash_attn_varlen_diff_headdims": [
      "self",
      "q",
      "k",
      "v",
      "return_softmax_lse",
      "softmax_scale"
    ],
    "_forward_decode": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "attn_metadata",
      "layer"
    ]
  },
  "fetch_id_to_ragged_kernel": [
    "in_tensor_ptr",
    "cumsum_ptr",
    "out_tensor_ptr",
    "in_tensor_ptr_stride",
    "TOPK",
    "TOKEN_NUM",
    "BLOCK_SIZE"
  ],
  "fetch_id_to_ragged_triton": [
    "in_tensor",
    "cumsum",
    "out_tensor",
    "topk"
  ],
  "ROCMAiterMLASparseBackend": {
    "get_name": [],
    "get_metadata_cls": [],
    "get_builder_cls": [],
    "get_impl_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ],
    "get_supported_dtypes": [
      "cls"
    ],
    "get_supported_head_sizes": [
      "cls"
    ]
  },
  "ROCMAiterMLASparseMetadata": {},
  "ROCMAiterMLASparseMetadataBuilder": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ]
  },
  "reference_mla_sparse_prefill": [
    "q",
    "kv",
    "indices",
    "sm_scale",
    "d_v"
  ],
  "ROCMAiterMLASparseImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name",
      "topk_indice_buffer",
      "indexer"
    ],
    "_forward_bf16_kv": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "topk_indices",
      "attn_metadata"
    ],
    "forward": [
      "self",
      "layer",
      "q",
      "k_c_normed",
      "k_pe",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ]
  },
  "MIN_HEADS_FOR_BF16_PREFILL": [],
  "FlashMLASparseBackend": {
    "get_supported_kernel_block_sizes": [],
    "get_name": [],
    "get_builder_cls": [],
    "get_impl_cls": [],
    "get_supported_head_sizes": [
      "cls"
    ],
    "is_mla": [
      "cls"
    ],
    "is_sparse": [
      "cls"
    ],
    "supports_compute_capability": [
      "cls",
      "capability"
    ],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ]
  },
  "FlashMLASparseMetadata": {},
  "_convert_req_index_to_global_index_kernel": [
    "req_id_ptr",
    "block_table_ptr",
    "token_indices_ptr",
    "out_ptr",
    "prefill_request_id_ptr",
    "workspace_starts_ptr",
    "max_num_blocks_per_req",
    "BLOCK_SIZE",
    "BLOCK_N",
    "HAS_PREFILL",
    "bt_stride0",
    "bt_stride1",
    "ti_stride0",
    "ti_stride1",
    "out_stride0",
    "out_stride1"
  ],
  "triton_convert_req_index_to_global_index": [
    "req_id",
    "block_table",
    "token_indices",
    "BLOCK_SIZE",
    "NUM_TOPK_TOKENS",
    "BLOCK_N",
    "HAS_PREFILL_WORKSPACE",
    "prefill_workspace_request_ids",
    "prefill_workspace_starts"
  ],
  "get_prefill_workspace_size": [
    "max_model_len"
  ],
  "FlashMLASparseMetadataBuilder": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "_build_fp8_mixed_decode_prefill": [
      "self",
      "common_attn_metadata"
    ],
    "_build_fp8_separate_prefill_decode": [
      "self",
      "common_attn_metadata"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ]
  },
  "FlashMLASparseImpl": {
    "_compute_fp8_decode_padded_heads": [
      "num_heads"
    ],
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name",
      "topk_indice_buffer",
      "indexer"
    ],
    "_forward_bf16_kv": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "topk_indices",
      "attn_metadata"
    ],
    "_forward_fp8_kv_separate_prefill_decode": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "topk_indices",
      "attn_metadata"
    ],
    "_forward_fp8_kv_mixed_batch": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "topk_indices",
      "attn_metadata"
    ],
    "_fp8_flash_mla_kernel": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "topk_indices",
      "kernel_metadata"
    ],
    "_bf16_flash_mla_kernel": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "topk_indices"
    ],
    "forward": [
      "self",
      "layer",
      "q",
      "k_c_normed",
      "k_pe",
      "kv_cache",
      "attn_metadata",
      "output",
      "output_scale",
      "output_block_scale"
    ]
  },
  "DeepseekV32IndexerBackend": {
    "get_name": [],
    "get_supported_kernel_block_sizes": [],
    "get_supported_head_sizes": [
      "cls"
    ],
    "get_builder_cls": [],
    "get_kv_cache_shape": [
      "num_blocks",
      "block_size",
      "num_kv_heads",
      "head_size",
      "cache_dtype_str"
    ],
    "get_kv_cache_stride_order": [
      "include_num_layers_dimension"
    ]
  },
  "DeepseekV32IndexerPrefillChunkMetadata": {},
  "DeepseekV32IndexerPrefillMetadata": {},
  "DeepSeekV32IndexerDecodeMetadata": {},
  "DeepseekV32IndexerMetadata": {},
  "kv_spans_from_batches": [
    "start_seq_loc",
    "seq_len_per_batch",
    "device"
  ],
  "get_max_prefill_buffer_size": [
    "vllm_config"
  ],
  "DeepseekV32IndexerMetadataBuilder": {
    "__init__": [
      "self"
    ],
    "build_one_prefill_chunk": [
      "self",
      "reqs_start",
      "reqs_end",
      "query_start_loc_cpu",
      "seq_lens_cpu",
      "block_table"
    ],
    "build": [
      "self",
      "common_prefix_len",
      "common_attn_metadata",
      "fast_build"
    ]
  },
  "CutlassMLAMetadataBuilder": {},
  "CutlassMLABackend": {
    "get_supported_kernel_block_sizes": [],
    "get_name": [],
    "get_impl_cls": [],
    "get_builder_cls": [],
    "supports_compute_capability": [
      "cls",
      "capability"
    ]
  },
  "SM100Workspace": {
    "__init__": [
      "self",
      "initial_workspace_size"
    ],
    "get_buf": [
      "self"
    ],
    "ensure_size": [
      "self",
      "attn_metadata",
      "num_kv_splits"
    ]
  },
  "g_sm100_workspace": [],
  "MAX_HEADS": [],
  "CutlassMLAImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name"
    ],
    "_sm100_cutlass_mla_decode": [
      "self",
      "q_nope",
      "q_pe",
      "kv_c_and_k_pe_cache",
      "seq_lens",
      "page_table",
      "workspace",
      "sm_scale",
      "num_kv_splits"
    ],
    "_forward_decode": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "attn_metadata",
      "layer"
    ]
  },
  "FlashMLABackend": {
    "get_supported_kernel_block_sizes": [],
    "get_name": [],
    "get_builder_cls": [],
    "get_impl_cls": [],
    "supports_compute_capability": [
      "cls",
      "capability"
    ],
    "supports_combination": [
      "cls",
      "head_size",
      "dtype",
      "kv_cache_dtype",
      "block_size",
      "use_mla",
      "has_sink",
      "use_sparse",
      "device_capability"
    ]
  },
  "FlashMLADecodeMetadata": {},
  "FlashMLAMetadata": {},
  "FlashMLAMetadataBuilder": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "_build_decode": [
      "self",
      "block_table_tensor",
      "seq_lens_device",
      "max_seq_len",
      "query_start_loc_cpu",
      "query_start_loc_device",
      "num_decode_tokens",
      "dcp_tot_seq_lens_device"
    ]
  },
  "FlashMLAImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name"
    ],
    "_forward_decode": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "attn_metadata",
      "layer"
    ]
  },
  "AiterTritonMLABackend": {
    "get_name": [],
    "get_impl_cls": []
  },
  "AiterTritonMLAImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name"
    ],
    "_flash_attn_varlen_diff_headdims": [
      "self",
      "q",
      "k",
      "v",
      "return_softmax_lse",
      "softmax_scale"
    ]
  },
  "FLASHINFER_MLA_WORKSPACE_BUFFER_SIZE": [],
  "FlashInferMLAMetadataBuilder": {},
  "FlashInferMLABackend": {
    "get_supported_kernel_block_sizes": [],
    "get_name": [],
    "get_impl_cls": [],
    "get_builder_cls": [],
    "supports_compute_capability": [
      "cls",
      "capability"
    ],
    "supports_combination": [
      "cls",
      "head_size",
      "dtype",
      "kv_cache_dtype",
      "block_size",
      "use_mla",
      "has_sink",
      "use_sparse",
      "device_capability"
    ],
    "get_required_kv_cache_layout": [
      "cls"
    ]
  },
  "g_fi_workspace": [],
  "FlashInferMLAImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name"
    ],
    "_forward_decode": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "attn_metadata",
      "layer"
    ]
  },
  "FlashAttnMLABackend": {
    "get_supported_kernel_block_sizes": [],
    "get_name": [],
    "get_builder_cls": [],
    "get_impl_cls": [],
    "supports_compute_capability": [
      "cls",
      "capability"
    ],
    "supports_combination": [
      "cls",
      "head_size",
      "dtype",
      "kv_cache_dtype",
      "block_size",
      "use_mla",
      "has_sink",
      "use_sparse",
      "device_capability"
    ]
  },
  "FlashAttnMLADecodeMetadata": {},
  "FlashAttnMLAMetadata": {},
  "FlashAttnMLAMetadataBuilder": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "layer_names",
      "vllm_config",
      "device"
    ],
    "_schedule_decode": [
      "self",
      "num_reqs",
      "cu_query_lens",
      "max_query_len",
      "seqlens",
      "max_seq_len",
      "causal",
      "max_num_splits"
    ],
    "_build_decode": [
      "self",
      "block_table_tensor",
      "seq_lens_device",
      "max_seq_len",
      "query_start_loc_cpu",
      "query_start_loc_device",
      "num_decode_tokens",
      "dcp_tot_seq_lens_device"
    ]
  },
  "FlashAttnMLAImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name"
    ],
    "_forward_decode": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "attn_metadata",
      "layer"
    ]
  },
  "TritonMLABackend": {
    "get_name": [],
    "get_impl_cls": [],
    "supports_compute_capability": [
      "cls",
      "capability"
    ]
  },
  "TritonMLAImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "scale",
      "num_kv_heads",
      "alibi_slopes",
      "sliding_window",
      "kv_cache_dtype",
      "logits_soft_cap",
      "attn_type",
      "kv_sharing_target_layer_name"
    ],
    "_flash_attn_varlen_diff_headdims": [
      "self",
      "q",
      "k",
      "v",
      "return_softmax_lse",
      "softmax_scale"
    ],
    "_forward_decode": [
      "self",
      "q",
      "kv_c_and_k_pe_cache",
      "attn_metadata",
      "layer"
    ]
  },
  "KVCacheBlocks": {
    "__add__": [
      "self",
      "other"
    ],
    "get_block_ids": [
      "self",
      "allow_none"
    ],
    "get_unhashed_block_ids": [
      "self"
    ],
    "new_empty": [
      "self"
    ]
  },
  "KVCacheManager": {
    "__init__": [
      "self",
      "kv_cache_config",
      "max_model_len",
      "hash_block_size",
      "enable_caching",
      "use_eagle",
      "log_stats",
      "enable_kv_cache_events",
      "dcp_world_size",
      "pcp_world_size",
      "metrics_collector"
    ],
    "usage": [
      "self"
    ],
    "make_prefix_cache_stats": [
      "self"
    ],
    "get_computed_blocks": [
      "self",
      "request"
    ],
    "allocate_slots": [
      "self",
      "request",
      "num_new_tokens",
      "num_new_computed_tokens",
      "new_computed_blocks",
      "num_lookahead_tokens",
      "num_external_computed_tokens",
      "delay_cache_blocks",
      "num_encoder_tokens"
    ],
    "free": [
      "self",
      "request"
    ],
    "remove_skipped_blocks": [
      "self",
      "request_id",
      "total_computed_tokens"
    ],
    "evict_blocks": [
      "self",
      "block_ids"
    ],
    "reset_prefix_cache": [
      "self"
    ],
    "get_num_common_prefix_blocks": [
      "self",
      "running_request_id"
    ],
    "take_events": [
      "self"
    ],
    "get_blocks": [
      "self",
      "request_id"
    ],
    "get_block_ids": [
      "self",
      "request_id"
    ],
    "cache_blocks": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "create_kv_cache_blocks": [
      "self",
      "blocks"
    ]
  },
  "BlockHashToBlockMap": {
    "__init__": [
      "self"
    ],
    "get_one_block": [
      "self",
      "key"
    ],
    "insert": [
      "self",
      "key",
      "block"
    ],
    "pop": [
      "self",
      "key",
      "block_id"
    ],
    "__len__": [
      "self"
    ],
    "_unexpected_blocks_type": [
      "self",
      "blocks"
    ]
  },
  "BlockPool": {
    "__init__": [
      "self",
      "num_gpu_blocks",
      "enable_caching",
      "hash_block_size",
      "enable_kv_cache_events",
      "metrics_collector"
    ],
    "get_cached_block": [
      "self",
      "block_hash",
      "kv_cache_group_ids"
    ],
    "cache_full_blocks": [
      "self",
      "request",
      "blocks",
      "num_cached_blocks",
      "num_full_blocks",
      "block_size",
      "kv_cache_group_id"
    ],
    "get_new_blocks": [
      "self",
      "num_blocks"
    ],
    "_maybe_evict_cached_block": [
      "self",
      "block"
    ],
    "touch": [
      "self",
      "blocks"
    ],
    "free_blocks": [
      "self",
      "ordered_blocks"
    ],
    "evict_blocks": [
      "self",
      "block_ids"
    ],
    "reset_prefix_cache": [
      "self"
    ],
    "get_num_free_blocks": [
      "self"
    ],
    "get_usage": [
      "self"
    ],
    "take_events": [
      "self"
    ]
  },
  "BlockMetricsState": {
    "__init__": [
      "self"
    ],
    "record_access": [
      "self"
    ],
    "get_lifetime_seconds": [
      "self"
    ],
    "get_idle_time_seconds": [
      "self"
    ],
    "get_reuse_gaps_seconds": [
      "self"
    ]
  },
  "KVCacheMetricsCollector": {
    "__init__": [
      "self",
      "sample_rate"
    ],
    "should_sample_block": [
      "self"
    ],
    "on_block_allocated": [
      "self",
      "block"
    ],
    "on_block_accessed": [
      "self",
      "block"
    ],
    "on_block_evicted": [
      "self",
      "block"
    ],
    "reset": [
      "self"
    ],
    "drain_events": [
      "self"
    ]
  },
  "EncoderCacheManager": {
    "__init__": [
      "self",
      "cache_size"
    ],
    "check_and_update_cache": [
      "self",
      "request",
      "input_id"
    ],
    "can_allocate": [
      "self",
      "request",
      "input_id",
      "encoder_compute_budget",
      "num_embeds_to_schedule"
    ],
    "allocate": [
      "self",
      "request",
      "input_id"
    ],
    "get_cached_input_ids": [
      "self",
      "request"
    ],
    "free_encoder_input": [
      "self",
      "request",
      "input_id"
    ],
    "free": [
      "self",
      "request"
    ],
    "get_freed_mm_hashes": [
      "self"
    ]
  },
  "compute_encoder_budget": [
    "model_config",
    "scheduler_config",
    "mm_registry"
  ],
  "compute_text_encoder_budget": [
    "scheduler_config"
  ],
  "compute_mm_encoder_budget": [
    "scheduler_config",
    "max_tokens_by_modality"
  ],
  "EncoderDecoderCacheManager": {
    "__init__": [
      "self",
      "cache_size"
    ],
    "check_and_update_cache": [
      "self",
      "request",
      "input_id"
    ],
    "can_allocate": [
      "self",
      "request",
      "input_id",
      "encoder_compute_budget",
      "num_embeds_to_schedule"
    ],
    "allocate": [
      "self",
      "request",
      "input_id"
    ],
    "free": [
      "self",
      "request"
    ],
    "get_cached_input_ids": [
      "self",
      "request"
    ],
    "get_freed_mm_hashes": [
      "self"
    ],
    "free_encoder_input": [
      "self",
      "request",
      "input_id"
    ]
  },
  "SingleTypeKVCacheManager": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "block_pool",
      "enable_caching",
      "kv_cache_group_id",
      "dcp_world_size",
      "pcp_world_size"
    ],
    "_get_num_evictable_blocks": [
      "cls",
      "blocks"
    ],
    "get_num_blocks_to_allocate": [
      "self",
      "request_id",
      "num_tokens",
      "new_computed_blocks",
      "total_computed_tokens",
      "num_tokens_main_model"
    ],
    "allocate_new_computed_blocks": [
      "self",
      "request_id",
      "new_computed_blocks",
      "num_local_computed_tokens",
      "num_external_computed_tokens"
    ],
    "allocate_new_blocks": [
      "self",
      "request_id",
      "num_tokens",
      "num_tokens_main_model"
    ],
    "cache_blocks": [
      "self",
      "request",
      "num_tokens"
    ],
    "free": [
      "self",
      "request_id"
    ],
    "get_num_common_prefix_blocks": [
      "self",
      "running_request_id"
    ],
    "find_longest_cache_hit": [
      "cls",
      "block_hashes",
      "max_length",
      "kv_cache_group_ids",
      "block_pool",
      "kv_cache_spec",
      "use_eagle",
      "alignment_tokens",
      "dcp_world_size",
      "pcp_world_size"
    ],
    "remove_skipped_blocks": [
      "self",
      "request_id",
      "total_computed_tokens"
    ],
    "get_num_skipped_tokens": [
      "self",
      "num_computed_tokens"
    ]
  },
  "FullAttentionManager": {
    "find_longest_cache_hit": [
      "cls",
      "block_hashes",
      "max_length",
      "kv_cache_group_ids",
      "block_pool",
      "kv_cache_spec",
      "use_eagle",
      "alignment_tokens",
      "dcp_world_size",
      "pcp_world_size"
    ],
    "get_num_common_prefix_blocks": [
      "self",
      "running_request_id"
    ]
  },
  "SlidingWindowManager": {
    "__init__": [
      "self",
      "kv_cache_spec"
    ],
    "find_longest_cache_hit": [
      "cls",
      "block_hashes",
      "max_length",
      "kv_cache_group_ids",
      "block_pool",
      "kv_cache_spec",
      "use_eagle",
      "alignment_tokens",
      "dcp_world_size",
      "pcp_world_size"
    ],
    "get_num_skipped_tokens": [
      "self",
      "num_computed_tokens"
    ],
    "get_num_common_prefix_blocks": [
      "self",
      "running_request_id"
    ]
  },
  "ChunkedLocalAttentionManager": {
    "__init__": [
      "self",
      "kv_cache_spec"
    ],
    "find_longest_cache_hit": [
      "cls",
      "block_hashes",
      "max_length",
      "kv_cache_group_ids",
      "block_pool",
      "kv_cache_spec",
      "use_eagle",
      "alignment_tokens",
      "dcp_world_size",
      "pcp_world_size"
    ],
    "get_num_skipped_tokens": [
      "self",
      "num_computed_tokens"
    ],
    "get_num_common_prefix_blocks": [
      "self",
      "running_request_id"
    ]
  },
  "MambaManager": {
    "__init__": [
      "self",
      "kv_cache_spec"
    ],
    "find_longest_cache_hit": [
      "cls",
      "block_hashes",
      "max_length",
      "kv_cache_group_ids",
      "block_pool",
      "kv_cache_spec",
      "use_eagle",
      "alignment_tokens",
      "dcp_world_size",
      "pcp_world_size"
    ],
    "remove_skipped_blocks": [
      "self",
      "request_id",
      "num_computed_tokens"
    ],
    "get_num_common_prefix_blocks": [
      "self",
      "running_request_id"
    ],
    "get_num_blocks_to_allocate": [
      "self",
      "request_id",
      "num_tokens",
      "new_computed_blocks",
      "total_computed_tokens",
      "num_tokens_main_model"
    ],
    "allocate_new_blocks": [
      "self",
      "request_id",
      "num_tokens",
      "num_tokens_main_model"
    ],
    "free": [
      "self",
      "request_id"
    ],
    "get_num_skipped_tokens": [
      "self",
      "num_computed_tokens"
    ]
  },
  "CrossAttentionManager": {
    "allocate_new_computed_blocks": [
      "self",
      "request_id",
      "new_computed_blocks",
      "num_local_computed_tokens",
      "num_external_computed_tokens"
    ],
    "cache_blocks": [
      "self",
      "request",
      "num_tokens"
    ],
    "get_num_common_prefix_blocks": [
      "self",
      "running_request_id"
    ],
    "find_longest_cache_hit": [
      "cls",
      "block_hashes",
      "max_length",
      "kv_cache_group_ids",
      "block_pool",
      "kv_cache_spec",
      "use_eagle",
      "alignment_tokens",
      "dcp_world_size",
      "pcp_world_size"
    ]
  },
  "SinkFullAttentionManager": {
    "__init__": [
      "self",
      "kv_cache_spec",
      "block_pool",
      "enable_caching",
      "kv_cache_group_id",
      "dcp_world_size",
      "pcp_world_size"
    ]
  },
  "get_manager_for_kv_cache_spec": [
    "kv_cache_spec"
  ],
  "KVCacheCoordinator": {
    "__init__": [
      "self",
      "kv_cache_config",
      "max_model_len",
      "use_eagle",
      "enable_caching",
      "enable_kv_cache_events",
      "dcp_world_size",
      "pcp_world_size",
      "hash_block_size",
      "metrics_collector"
    ],
    "get_num_blocks_to_allocate": [
      "self",
      "request_id",
      "num_tokens",
      "new_computed_blocks",
      "num_encoder_tokens",
      "total_computed_tokens",
      "num_tokens_main_model"
    ],
    "allocate_new_computed_blocks": [
      "self",
      "request_id",
      "new_computed_blocks",
      "num_local_computed_tokens",
      "num_external_computed_tokens"
    ],
    "allocate_new_blocks": [
      "self",
      "request_id",
      "num_tokens",
      "num_tokens_main_model",
      "num_encoder_tokens"
    ],
    "cache_blocks": [
      "self",
      "request",
      "num_computed_tokens"
    ],
    "free": [
      "self",
      "request_id"
    ],
    "get_num_common_prefix_blocks": [
      "self",
      "running_request_id"
    ],
    "remove_skipped_blocks": [
      "self",
      "request_id",
      "total_computed_tokens"
    ],
    "get_blocks": [
      "self",
      "request_id"
    ],
    "find_longest_cache_hit": [
      "self",
      "block_hashes",
      "max_cache_hit_length"
    ]
  },
  "KVCacheCoordinatorNoPrefixCache": {
    "__init__": [
      "self",
      "kv_cache_config",
      "max_model_len",
      "use_eagle",
      "enable_kv_cache_events",
      "dcp_world_size",
      "pcp_world_size",
      "hash_block_size",
      "metrics_collector"
    ],
    "get_num_common_prefix_blocks": [
      "self",
      "running_request_id"
    ],
    "find_longest_cache_hit": [
      "self",
      "block_hashes",
      "max_cache_hit_length"
    ]
  },
  "UnitaryKVCacheCoordinator": {
    "__init__": [
      "self",
      "kv_cache_config",
      "max_model_len",
      "use_eagle",
      "enable_caching",
      "enable_kv_cache_events",
      "dcp_world_size",
      "pcp_world_size",
      "hash_block_size",
      "metrics_collector"
    ],
    "find_longest_cache_hit": [
      "self",
      "block_hashes",
      "max_cache_hit_length"
    ]
  },
  "HybridKVCacheCoordinator": {
    "__init__": [
      "self",
      "kv_cache_config",
      "max_model_len",
      "use_eagle",
      "enable_caching",
      "enable_kv_cache_events",
      "dcp_world_size",
      "pcp_world_size",
      "hash_block_size",
      "metrics_collector"
    ],
    "verify_and_split_kv_cache_groups": [
      "self"
    ],
    "find_longest_cache_hit": [
      "self",
      "block_hashes",
      "max_cache_hit_length"
    ]
  },
  "get_kv_cache_coordinator": [
    "kv_cache_config",
    "max_model_len",
    "use_eagle",
    "enable_caching",
    "enable_kv_cache_events",
    "dcp_world_size",
    "pcp_world_size",
    "hash_block_size",
    "metrics_collector"
  ],
  "BlockHash": [],
  "BlockHashWithGroupId": [],
  "make_block_hash_with_group_id": [
    "block_hash",
    "group_id"
  ],
  "get_block_hash": [
    "key"
  ],
  "get_group_id": [
    "key"
  ],
  "maybe_convert_block_hash": [
    "hash_bytes"
  ],
  "_CBOR_HASH_FUNCTIONS": [],
  "init_none_hash": [
    "hash_fn"
  ],
  "KVCacheBlock": {
    "block_hash": [
      "self",
      "block_hash"
    ],
    "reset_hash": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "FreeKVCacheBlockQueue": {
    "__init__": [
      "self",
      "blocks"
    ],
    "popleft": [
      "self"
    ],
    "popleft_n": [
      "self",
      "n"
    ],
    "remove": [
      "self",
      "block"
    ],
    "append": [
      "self",
      "block"
    ],
    "append_n": [
      "self",
      "blocks"
    ],
    "get_all_free_blocks": [
      "self"
    ]
  },
  "need_extra_keys": [
    "request"
  ],
  "_gen_mm_extra_hash_keys": [
    "request",
    "start_token_idx",
    "end_token_idx",
    "start_mm_idx"
  ],
  "_gen_lora_extra_hash_keys": [
    "request"
  ],
  "_gen_prompt_embeds_extra_hash_keys": [
    "request",
    "start_token_idx",
    "end_token_idx"
  ],
  "generate_block_hash_extra_keys": [
    "request",
    "start_token_idx",
    "end_token_idx",
    "start_mm_idx"
  ],
  "hash_block_tokens": [
    "hash_function",
    "parent_block_hash",
    "curr_block_token_ids",
    "extra_keys"
  ],
  "get_request_block_hasher": [
    "block_size",
    "caching_hash_fn"
  ],
  "_check_enough_kv_cache_memory": [
    "available_memory",
    "get_needed_memory",
    "max_model_len",
    "estimate_max_model_len"
  ],
  "max_memory_usage_bytes": [
    "vllm_config",
    "kv_cache_specs"
  ],
  "estimate_max_model_len": [
    "vllm_config",
    "kv_cache_spec",
    "available_memory"
  ],
  "check_enough_kv_cache_memory": [
    "vllm_config",
    "kv_cache_spec",
    "available_memory"
  ],
  "create_kv_cache_group_specs": [
    "kv_cache_spec",
    "grouped_layer_names"
  ],
  "is_kv_cache_spec_uniform": [
    "kv_cache_spec"
  ],
  "get_max_concurrency_for_kv_cache_config": [
    "vllm_config",
    "kv_cache_config"
  ],
  "may_override_num_blocks": [
    "vllm_config",
    "num_blocks"
  ],
  "get_num_blocks": [
    "vllm_config",
    "num_layers",
    "available_memory",
    "page_size"
  ],
  "get_uniform_page_size": [
    "kv_cache_specs"
  ],
  "_get_kv_cache_groups_uniform_spec": [
    "kv_cache_specs"
  ],
  "_get_kv_cache_groups_uniform_type": [
    "spec"
  ],
  "is_kv_cache_page_size_uniform": [
    "kv_cache_spec"
  ],
  "unify_kv_cache_spec_page_size": [
    "kv_cache_spec"
  ],
  "is_kv_cache_type_attention_free": [
    "kv_cache_spec"
  ],
  "_get_kv_cache_groups_uniform_page_size": [
    "kv_cache_spec"
  ],
  "get_kv_cache_config_from_groups": [
    "vllm_config",
    "kv_cache_groups",
    "available_memory"
  ],
  "unify_hybrid_kv_cache_specs": [
    "kv_cache_spec"
  ],
  "get_kv_cache_groups": [
    "vllm_config",
    "kv_cache_spec"
  ],
  "generate_scheduler_kv_cache_config": [
    "kv_cache_configs"
  ],
  "_report_kv_cache_config": [
    "vllm_config",
    "kv_cache_config"
  ],
  "_max_memory_usage_bytes_from_groups": [
    "vllm_config",
    "kv_cache_groups"
  ],
  "_estimate_max_model_len_from_groups": [
    "vllm_config",
    "kv_cache_groups",
    "available_memory"
  ],
  "_auto_fit_max_model_len": [
    "vllm_config",
    "kv_cache_groups",
    "available_memory"
  ],
  "get_kv_cache_configs": [
    "vllm_config",
    "kv_cache_specs",
    "available_memory"
  ],
  "BlockHashListWithBlockSize": {
    "__init__": [
      "self",
      "block_hashes",
      "hash_block_size",
      "target_block_size"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__iter__": [
      "self"
    ],
    "_get_value_at": [
      "self",
      "idx"
    ]
  },
  "BlockHashList": [],
  "SchedulerInterface": {
    "__init__": [
      "self",
      "vllm_config",
      "kv_cache_config",
      "structured_output_manager",
      "block_size",
      "mm_registry",
      "include_finished_set",
      "log_stats"
    ],
    "schedule": [
      "self"
    ],
    "get_grammar_bitmask": [
      "self",
      "scheduler_output"
    ],
    "update_from_output": [
      "self",
      "scheduler_output",
      "model_runner_output"
    ],
    "update_draft_token_ids": [
      "self",
      "draft_token_ids"
    ],
    "update_draft_token_ids_in_output": [
      "self",
      "draft_token_ids",
      "scheduler_output"
    ],
    "add_request": [
      "self",
      "request"
    ],
    "finish_requests": [
      "self",
      "request_ids",
      "finished_status"
    ],
    "get_num_unfinished_requests": [
      "self"
    ],
    "has_unfinished_requests": [
      "self"
    ],
    "has_finished_requests": [
      "self"
    ],
    "has_requests": [
      "self"
    ],
    "reset_prefix_cache": [
      "self",
      "reset_running_requests",
      "reset_connector"
    ],
    "get_request_counts": [
      "self"
    ],
    "make_stats": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "get_kv_connector": [
      "self"
    ]
  },
  "Scheduler": {
    "__init__": [
      "self",
      "vllm_config",
      "kv_cache_config",
      "structured_output_manager",
      "block_size",
      "mm_registry",
      "include_finished_set",
      "log_stats"
    ],
    "_mamba_block_aligned_split": [
      "self",
      "request",
      "num_new_tokens",
      "num_new_local_computed_tokens",
      "num_external_computed_tokens"
    ],
    "schedule": [
      "self"
    ],
    "_preempt_request": [
      "self",
      "request",
      "timestamp"
    ],
    "_update_after_schedule": [
      "self",
      "scheduler_output"
    ],
    "_update_request_as_session": [
      "self",
      "session",
      "update"
    ],
    "_make_cached_request_data": [
      "self",
      "running_reqs",
      "resumed_reqs",
      "num_scheduled_tokens",
      "spec_decode_tokens",
      "req_to_new_blocks"
    ],
    "_try_schedule_encoder_inputs": [
      "self",
      "request",
      "num_computed_tokens",
      "num_new_tokens",
      "encoder_compute_budget",
      "shift_computed_tokens"
    ],
    "get_grammar_bitmask": [
      "self",
      "scheduler_output"
    ],
    "update_from_output": [
      "self",
      "scheduler_output",
      "model_runner_output"
    ],
    "_handle_stopped_request": [
      "self",
      "request"
    ],
    "_get_routed_experts": [
      "self",
      "request"
    ],
    "_update_request_with_output": [
      "self",
      "request",
      "new_token_ids"
    ],
    "_free_encoder_inputs": [
      "self",
      "request"
    ],
    "update_draft_token_ids": [
      "self",
      "draft_token_ids"
    ],
    "update_draft_token_ids_in_output": [
      "self",
      "draft_token_ids",
      "scheduler_output"
    ],
    "get_request_counts": [
      "self"
    ],
    "add_request": [
      "self",
      "request"
    ],
    "finish_requests": [
      "self",
      "request_ids",
      "finished_status"
    ],
    "_free_request": [
      "self",
      "request"
    ],
    "_free_blocks": [
      "self",
      "request"
    ],
    "get_num_unfinished_requests": [
      "self"
    ],
    "has_finished_requests": [
      "self"
    ],
    "reset_prefix_cache": [
      "self",
      "reset_running_requests",
      "reset_connector"
    ],
    "reset_connector_cache": [
      "self"
    ],
    "make_stats": [
      "self",
      "spec_decoding_stats",
      "kv_connector_stats",
      "cudagraph_stats",
      "perf_stats"
    ],
    "make_spec_decoding_stats": [
      "self",
      "spec_decoding_stats",
      "num_draft_tokens",
      "num_accepted_tokens",
      "num_invalid_spec_tokens",
      "request_id"
    ],
    "shutdown": [
      "self"
    ],
    "_update_connector_prefix_cache_stats": [
      "self",
      "request"
    ],
    "_make_connector_prefix_cache_stats": [
      "self"
    ],
    "get_kv_connector": [
      "self"
    ],
    "_connector_finished": [
      "self",
      "request"
    ],
    "_update_waiting_for_remote_kv": [
      "self",
      "request"
    ],
    "_update_from_kv_xfer_finished": [
      "self",
      "kv_connector_output"
    ],
    "_update_requests_with_invalid_blocks": [
      "self",
      "requests",
      "invalid_block_ids",
      "evict_blocks"
    ],
    "_handle_invalid_blocks": [
      "self",
      "invalid_block_ids"
    ]
  },
  "SchedulingPolicy": {
    "FCFS": [],
    "PRIORITY": []
  },
  "RequestQueue": {
    "add_request": [
      "self",
      "request"
    ],
    "pop_request": [
      "self"
    ],
    "peek_request": [
      "self"
    ],
    "prepend_request": [
      "self",
      "request"
    ],
    "prepend_requests": [
      "self",
      "requests"
    ],
    "remove_request": [
      "self",
      "request"
    ],
    "remove_requests": [
      "self",
      "requests"
    ],
    "__bool__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "FCFSRequestQueue": {
    "add_request": [
      "self",
      "request"
    ],
    "pop_request": [
      "self"
    ],
    "peek_request": [
      "self"
    ],
    "prepend_request": [
      "self",
      "request"
    ],
    "prepend_requests": [
      "self",
      "requests"
    ],
    "remove_request": [
      "self",
      "request"
    ],
    "remove_requests": [
      "self",
      "requests"
    ],
    "__bool__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "PriorityRequestQueue": {
    "__init__": [
      "self"
    ],
    "add_request": [
      "self",
      "request"
    ],
    "pop_request": [
      "self"
    ],
    "peek_request": [
      "self"
    ],
    "prepend_request": [
      "self",
      "request"
    ],
    "prepend_requests": [
      "self",
      "requests"
    ],
    "remove_request": [
      "self",
      "request"
    ],
    "remove_requests": [
      "self",
      "requests"
    ],
    "__bool__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "create_request_queue": [
    "policy"
  ],
  "remove_all": [
    "lst",
    "items_to_remove"
  ],
  "check_stop": [
    "request",
    "max_model_len"
  ],
  "AsyncScheduler": {
    "_update_after_schedule": [
      "self",
      "scheduler_output"
    ],
    "_update_request_with_output": [
      "self",
      "request",
      "new_token_ids"
    ]
  },
  "NewRequestData": {
    "from_request": [
      "cls",
      "request",
      "block_ids",
      "prefill_token_ids"
    ],
    "__repr__": [
      "self"
    ],
    "anon_repr": [
      "self"
    ]
  },
  "CachedRequestData": {
    "anon_repr": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "num_reqs": [
      "self"
    ],
    "_req_id_to_num_output_tokens": [
      "self"
    ],
    "is_context_phase": [
      "self",
      "req_id"
    ],
    "make_empty": [
      "cls"
    ]
  },
  "SchedulerOutput": {
    "make_empty": [
      "cls"
    ]
  },
  "GrammarOutput": {}
}