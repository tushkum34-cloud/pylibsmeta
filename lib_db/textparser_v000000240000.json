{
  "__author__": [],
  "__version__": [],
  "_Mismatch": {},
  "MISMATCH": [],
  "_String": {
    "__init__": [
      "self",
      "kind"
    ],
    "match": [
      "self",
      "tokens"
    ]
  },
  "_Tokens": {
    "__init__": [
      "self",
      "tokens"
    ],
    "get_value": [
      "self"
    ],
    "peek": [
      "self"
    ],
    "peek_max": [
      "self"
    ],
    "save": [
      "self"
    ],
    "restore": [
      "self"
    ],
    "update": [
      "self"
    ],
    "mark_max_restore": [
      "self"
    ],
    "mark_max_load": [
      "self"
    ],
    "drop": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_StringTokens": {
    "get_value": [
      "self"
    ]
  },
  "_wrap_string": [
    "item"
  ],
  "_wrap_strings": [
    "items"
  ],
  "_format_invalid_syntax": [
    "text",
    "offset"
  ],
  "Error": {},
  "TokenizeError": {
    "__init__": [
      "self",
      "text",
      "offset"
    ],
    "text": [
      "self"
    ],
    "offset": [
      "self"
    ]
  },
  "GrammarError": {
    "__init__": [
      "self",
      "offset"
    ],
    "offset": [
      "self"
    ]
  },
  "ParseError": {
    "__init__": [
      "self",
      "text",
      "offset"
    ],
    "text": [
      "self"
    ],
    "offset": [
      "self"
    ],
    "line": [
      "self"
    ],
    "column": [
      "self"
    ]
  },
  "Token": [],
  "Pattern": {
    "match": [
      "self",
      "tokens"
    ]
  },
  "Sequence": {
    "__init__": [
      "self"
    ],
    "match": [
      "self",
      "tokens"
    ]
  },
  "Choice": {
    "__init__": [
      "self"
    ],
    "match": [
      "self",
      "tokens"
    ]
  },
  "ChoiceDict": {
    "__init__": [
      "self"
    ],
    "patterns_map": [
      "self"
    ],
    "_check_pattern": [
      "self",
      "inner",
      "outer"
    ],
    "_add_pattern": [
      "self",
      "kind",
      "pattern"
    ],
    "match": [
      "self",
      "tokens"
    ]
  },
  "Repeated": {
    "__init__": [
      "self",
      "pattern",
      "minimum"
    ],
    "match": [
      "self",
      "tokens"
    ]
  },
  "RepeatedDict": {
    "__init__": [
      "self",
      "pattern",
      "minimum",
      "key"
    ],
    "match": [
      "self",
      "tokens"
    ]
  },
  "ZeroOrMore": {
    "__init__": [
      "self",
      "pattern"
    ]
  },
  "ZeroOrMoreDict": {
    "__init__": [
      "self",
      "pattern",
      "key"
    ]
  },
  "OneOrMore": {
    "__init__": [
      "self",
      "pattern"
    ]
  },
  "OneOrMoreDict": {
    "__init__": [
      "self",
      "pattern",
      "key"
    ]
  },
  "DelimitedList": {
    "__init__": [
      "self",
      "pattern",
      "delim"
    ],
    "match": [
      "self",
      "tokens"
    ]
  },
  "Optional": {
    "__init__": [
      "self",
      "pattern"
    ],
    "match": [
      "self",
      "tokens"
    ]
  },
  "Any": {
    "match": [
      "self",
      "tokens"
    ]
  },
  "AnyUntil": {
    "__init__": [
      "self",
      "pattern"
    ],
    "match": [
      "self",
      "tokens"
    ]
  },
  "And": {
    "__init__": [
      "self",
      "pattern"
    ],
    "match": [
      "self",
      "tokens"
    ]
  },
  "Not": {
    "__init__": [
      "self",
      "pattern"
    ],
    "match": [
      "self",
      "tokens"
    ]
  },
  "NoMatch": {
    "match": [
      "self",
      "tokens"
    ]
  },
  "Tag": {
    "__init__": [
      "self",
      "name",
      "pattern"
    ],
    "pattern": [
      "self"
    ],
    "match": [
      "self",
      "tokens"
    ]
  },
  "Forward": {
    "__init__": [
      "self"
    ],
    "pattern": [
      "self"
    ],
    "__ilshift__": [
      "self",
      "other"
    ],
    "match": [
      "self",
      "tokens"
    ]
  },
  "Grammar": {
    "__init__": [
      "self",
      "grammar"
    ],
    "parse": [
      "self",
      "tokens",
      "token_tree"
    ]
  },
  "choice": [],
  "markup_line": [
    "text",
    "offset",
    "marker"
  ],
  "line": [
    "text",
    "offset"
  ],
  "column": [
    "text",
    "offset"
  ],
  "tokenize_init": [
    "spec"
  ],
  "Parser": {
    "_unpack_token_specs": [
      "self"
    ],
    "keywords": [
      "self"
    ],
    "token_specs": [
      "self"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "grammar": [
      "self"
    ],
    "parse": [
      "self",
      "text",
      "token_tree",
      "match_sof"
    ]
  },
  "replace_blocks": [
    "string",
    "start",
    "end"
  ]
}