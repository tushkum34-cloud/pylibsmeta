{
  "test_mistral_instruct": [],
  "mistral_7b_tokenizer_config": [],
  "test_hf_tokenizer_config_str_to_chat_formatter": [],
  "test_find_candidate_pred_tokens": [],
  "MODEL": [],
  "test_llama_cpp_version": [],
  "test_llama_cpp_tokenization": [],
  "llama_cpp_model_path": [],
  "test_real_model": [
    "llama_cpp_model_path"
  ],
  "test_real_llama": [
    "llama_cpp_model_path"
  ],
  "test_real_llama_embeddings": [
    "llama_cpp_model_path"
  ],
  "tree": [],
  "test_grammar_from_string": [],
  "test_composed_pydantic_grammar": [],
  "test_grammar_anyof": [],
  "make_request": [
    "url",
    "params"
  ],
  "check_magic_and_version": [
    "filename"
  ],
  "download_file": [
    "url",
    "destination"
  ],
  "get_user_choice": [
    "model_list"
  ],
  "main": [],
  "_libllava_base_name": [],
  "_libllava_override_path": [],
  "_libllava_base_path": [],
  "_libllava": [],
  "ctypes_function": [],
  "clip_ctx_p": [],
  "clip_ctx_p_ctypes": [],
  "llava_image_embed": {
    "_fields_": []
  },
  "llava_validate_embed_size": [],
  "llava_image_embed_make_with_bytes": [],
  "llava_image_embed_make_with_filename": [],
  "llava_image_embed_free": [],
  "llava_eval_image_embed": [],
  "clip_model_load": [],
  "clip_free": [],
  "outnull_file": [],
  "errnull_file": [],
  "STDOUT_FILENO": [],
  "STDERR_FILENO": [],
  "suppress_stdout_stderr": {
    "sys": [],
    "os": [],
    "__init__": [
      "self",
      "disable"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "MetaSingleton": {
    "__call__": [
      "cls"
    ]
  },
  "Singleton": {
    "__init__": [
      "self"
    ]
  },
  "LlamaModel": {
    "__init__": [
      "self"
    ],
    "close": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "vocab_type": [
      "self"
    ],
    "n_vocab": [
      "self"
    ],
    "n_ctx_train": [
      "self"
    ],
    "n_embd": [
      "self"
    ],
    "rope_freq_scale_train": [
      "self"
    ],
    "desc": [
      "self"
    ],
    "size": [
      "self"
    ],
    "n_params": [
      "self"
    ],
    "get_tensor": [
      "self",
      "name"
    ],
    "token_get_text": [
      "self",
      "token"
    ],
    "token_get_score": [
      "self",
      "token"
    ],
    "token_get_attr": [
      "self",
      "token"
    ],
    "token_bos": [
      "self"
    ],
    "token_eos": [
      "self"
    ],
    "token_cls": [
      "self"
    ],
    "token_sep": [
      "self"
    ],
    "token_nl": [
      "self"
    ],
    "token_prefix": [
      "self"
    ],
    "token_middle": [
      "self"
    ],
    "token_suffix": [
      "self"
    ],
    "token_eot": [
      "self"
    ],
    "add_bos_token": [
      "self"
    ],
    "add_eos_token": [
      "self"
    ],
    "tokenize": [
      "self",
      "text",
      "add_bos",
      "special"
    ],
    "token_to_piece": [
      "self",
      "token",
      "special"
    ],
    "detokenize": [
      "self",
      "tokens",
      "special"
    ],
    "metadata": [
      "self"
    ],
    "default_params": []
  },
  "LlamaContext": {
    "__init__": [
      "self"
    ],
    "close": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "n_ctx": [
      "self"
    ],
    "pooling_type": [
      "self"
    ],
    "kv_cache_clear": [
      "self"
    ],
    "kv_cache_seq_rm": [
      "self",
      "seq_id",
      "p0",
      "p1"
    ],
    "kv_cache_seq_cp": [
      "self",
      "seq_id_src",
      "seq_id_dst",
      "p0",
      "p1"
    ],
    "kv_cache_seq_keep": [
      "self",
      "seq_id"
    ],
    "kv_cache_seq_shift": [
      "self",
      "seq_id",
      "p0",
      "p1",
      "shift"
    ],
    "get_state_size": [
      "self"
    ],
    "decode": [
      "self",
      "batch"
    ],
    "encode": [
      "self",
      "batch"
    ],
    "set_n_threads": [
      "self",
      "n_threads",
      "n_threads_batch"
    ],
    "get_logits": [
      "self"
    ],
    "get_logits_ith": [
      "self",
      "i"
    ],
    "get_embeddings": [
      "self"
    ],
    "get_embeddings_ith": [
      "self",
      "i"
    ],
    "get_embeddings_seq": [
      "self",
      "seq_id"
    ],
    "set_rng_seed": [
      "self",
      "seed"
    ],
    "sample_repetition_penalties": [
      "self",
      "candidates",
      "last_tokens_data",
      "penalty_last_n",
      "penalty_repeat",
      "penalty_freq",
      "penalty_present"
    ],
    "sample_softmax": [
      "self",
      "candidates"
    ],
    "sample_top_k": [
      "self",
      "candidates",
      "k",
      "min_keep"
    ],
    "sample_top_p": [
      "self",
      "candidates",
      "p",
      "min_keep"
    ],
    "sample_min_p": [
      "self",
      "candidates",
      "p",
      "min_keep"
    ],
    "sample_typical": [
      "self",
      "candidates",
      "p",
      "min_keep"
    ],
    "sample_temp": [
      "self",
      "candidates",
      "temp"
    ],
    "sample_grammar": [
      "self",
      "candidates",
      "grammar"
    ],
    "sample_token_mirostat": [
      "self",
      "candidates",
      "tau",
      "eta",
      "m",
      "mu"
    ],
    "sample_token_mirostat_v2": [
      "self",
      "candidates",
      "tau",
      "eta",
      "mu"
    ],
    "sample_token_greedy": [
      "self",
      "candidates"
    ],
    "sample_token": [
      "self",
      "candidates"
    ],
    "grammar_accept_token": [
      "self",
      "grammar",
      "token"
    ],
    "reset_timings": [
      "self"
    ],
    "print_timings": [
      "self"
    ],
    "default_params": []
  },
  "LlamaBatch": {
    "__init__": [
      "self"
    ],
    "close": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "n_tokens": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "set_batch": [
      "self",
      "batch",
      "n_past",
      "logits_all"
    ],
    "add_sequence": [
      "self",
      "batch",
      "seq_id",
      "logits_all"
    ]
  },
  "LlamaTokenDataArray": {
    "__init__": [
      "self"
    ],
    "copy_logits": [
      "self",
      "logits"
    ]
  },
  "normalize_embedding": [
    "embedding"
  ],
  "LlamaSamplingParams": {},
  "LlamaSamplingContext": {
    "reset": [
      "self"
    ],
    "cp": [
      "self"
    ],
    "last": [
      "self"
    ],
    "prev_str": [
      "self",
      "ctx_main",
      "n"
    ],
    "sample": [
      "self",
      "ctx_main",
      "idx",
      "logits_array"
    ],
    "accept": [
      "self",
      "ctx_main",
      "id",
      "apply_grammar"
    ]
  },
  "CustomSampler": {
    "__init__": [
      "self",
      "apply_func"
    ],
    "get_sampler": [
      "self"
    ]
  },
  "LlamaSampler": {
    "__init__": [
      "self"
    ],
    "close": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "add_greedy": [
      "self"
    ],
    "add_dist": [
      "self",
      "seed"
    ],
    "add_softmax": [
      "self"
    ],
    "add_top_k": [
      "self",
      "k"
    ],
    "add_top_p": [
      "self",
      "p",
      "min_keep"
    ],
    "add_min_p": [
      "self",
      "p",
      "min_keep"
    ],
    "add_typical": [
      "self",
      "p",
      "min_keep"
    ],
    "add_temp": [
      "self",
      "temp"
    ],
    "add_temp_ext": [
      "self",
      "t",
      "delta",
      "exponent"
    ],
    "add_xtc": [
      "self",
      "p",
      "t",
      "min_keep",
      "seed"
    ],
    "add_top_n_sigma": [
      "self",
      "n"
    ],
    "add_mirostat": [
      "self",
      "n_vocab",
      "seed",
      "tau",
      "eta",
      "m"
    ],
    "add_mirostat_v2": [
      "self",
      "seed",
      "tau",
      "eta"
    ],
    "add_grammar": [
      "self",
      "model",
      "grammar"
    ],
    "add_grammar_lazy_patterns": [
      "self",
      "model",
      "grammar",
      "trigger_patterns",
      "trigger_tokens"
    ],
    "add_penalties": [
      "self",
      "penalty_last_n",
      "penalty_repeat",
      "penalty_freq",
      "penalty_present"
    ],
    "add_dry": [
      "self",
      "model",
      "n_ctx_train",
      "dry_multiplier",
      "dry_base",
      "dry_allowed_length",
      "dry_penalty_last_n",
      "seq_breakers"
    ],
    "add_logit_bias": [
      "self",
      "n_vocab",
      "logit_bias"
    ],
    "add_infill": [
      "self",
      "model"
    ],
    "add_custom": [
      "self",
      "apply_func"
    ],
    "get_seed": [
      "self"
    ],
    "sample": [
      "self",
      "ctx",
      "idx"
    ],
    "accept": [
      "self",
      "token"
    ],
    "reset": [
      "self"
    ],
    "clone": [
      "self"
    ]
  },
  "_lib_base_name": [],
  "_override_base_path": [],
  "_base_path": [],
  "_lib": [],
  "GGML_TYPE_F32": [],
  "GGML_TYPE_F16": [],
  "GGML_TYPE_Q4_0": [],
  "GGML_TYPE_Q4_1": [],
  "GGML_TYPE_Q5_0": [],
  "GGML_TYPE_Q5_1": [],
  "GGML_TYPE_Q8_0": [],
  "GGML_TYPE_Q8_1": [],
  "GGML_TYPE_Q2_K": [],
  "GGML_TYPE_Q3_K": [],
  "GGML_TYPE_Q4_K": [],
  "GGML_TYPE_Q5_K": [],
  "GGML_TYPE_Q6_K": [],
  "GGML_TYPE_Q8_K": [],
  "GGML_TYPE_IQ2_XXS": [],
  "GGML_TYPE_IQ2_XS": [],
  "GGML_TYPE_IQ3_XXS": [],
  "GGML_TYPE_IQ1_S": [],
  "GGML_TYPE_IQ4_NL": [],
  "GGML_TYPE_IQ3_S": [],
  "GGML_TYPE_IQ2_S": [],
  "GGML_TYPE_IQ4_XS": [],
  "GGML_TYPE_I8": [],
  "GGML_TYPE_I16": [],
  "GGML_TYPE_I32": [],
  "GGML_TYPE_I64": [],
  "GGML_TYPE_F64": [],
  "GGML_TYPE_IQ1_M": [],
  "GGML_TYPE_COUNT": [],
  "ggml_backend_sched_eval_callback": [],
  "ggml_abort_callback": [],
  "LLAMA_MAX_DEVICES": [],
  "LLAMA_DEFAULT_SEED": [],
  "LLAMA_TOKEN_NULL": [],
  "LLAMA_FILE_MAGIC_GGLA": [],
  "LLAMA_FILE_MAGIC_GGSN": [],
  "LLAMA_FILE_MAGIC_GGSQ": [],
  "LLAMA_SESSION_MAGIC": [],
  "LLAMA_SESSION_VERSION": [],
  "LLAMA_STATE_SEQ_MAGIC": [],
  "LLAMA_STATE_SEQ_VERSION": [],
  "llama_vocab_p": [],
  "llama_vocab_p_ctypes": [],
  "llama_model_p": [],
  "llama_model_p_ctypes": [],
  "llama_context_p": [],
  "llama_context_p_ctypes": [],
  "llama_memory_t": [],
  "llama_memory_t_ctypes": [],
  "llama_kv_cache_p": [],
  "llama_kv_cache_p_ctypes": [],
  "llama_pos": [],
  "llama_token": [],
  "llama_token_p": [],
  "llama_seq_id": [],
  "LLAMA_VOCAB_TYPE_NONE": [],
  "LLAMA_VOCAB_TYPE_SPM": [],
  "LLAMA_VOCAB_TYPE_BPE": [],
  "LLAMA_VOCAB_TYPE_WPM": [],
  "LLAMA_VOCAB_TYPE_UGM": [],
  "LLAMA_VOCAB_TYPE_RWKV": [],
  "LLAMA_VOCAB_TYPE_PLAMO2": [],
  "LLAMA_VOCAB_PRE_TYPE_DEFAULT": [],
  "LLAMA_VOCAB_PRE_TYPE_LLAMA3": [],
  "LLAMA_VOCAB_PRE_TYPE_DEEPSEEK_LLM": [],
  "LLAMA_VOCAB_PRE_TYPE_DEEPSEEK_CODER": [],
  "LLAMA_VOCAB_PRE_TYPE_FALCON": [],
  "LLAMA_VOCAB_PRE_TYPE_MPT": [],
  "LLAMA_VOCAB_PRE_TYPE_STARCODER": [],
  "LLAMA_VOCAB_PRE_TYPE_GPT2": [],
  "LLAMA_VOCAB_PRE_TYPE_REFACT": [],
  "LLAMA_VOCAB_PRE_TYPE_COMMAND_R": [],
  "LLAMA_VOCAB_PRE_TYPE_STABLELM2": [],
  "LLAMA_VOCAB_PRE_TYPE_QWEN2": [],
  "LLAMA_VOCAB_PRE_TYPE_OLMO": [],
  "LLAMA_VOCAB_PRE_TYPE_DBRX": [],
  "LLAMA_VOCAB_PRE_TYPE_SMAUG": [],
  "LLAMA_VOCAB_PRE_TYPE_PORO": [],
  "LLAMA_VOCAB_PRE_TYPE_CHATGLM3": [],
  "LLAMA_VOCAB_PRE_TYPE_CHATGLM4": [],
  "LLAMA_VOCAB_PRE_TYPE_VIKING": [],
  "LLAMA_VOCAB_PRE_TYPE_JAIS": [],
  "LLAMA_VOCAB_PRE_TYPE_TEKKEN": [],
  "LLAMA_VOCAB_PRE_TYPE_SMOLLM": [],
  "LLAMA_VOCAB_PRE_TYPE_CODESHELL": [],
  "LLAMA_VOCAB_PRE_TYPE_BLOOM": [],
  "LLAMA_VOCAB_PRE_TYPE_GPT3_FINNISH": [],
  "LLAMA_VOCAB_PRE_TYPE_EXAONE": [],
  "LLAMA_VOCAB_PRE_TYPE_CHAMELEON": [],
  "LLAMA_VOCAB_PRE_TYPE_MINERVA": [],
  "LLAMA_VOCAB_PRE_TYPE_DEEPSEEK3_LLM": [],
  "LLAMA_VOCAB_PRE_TYPE_GPT4O": [],
  "LLAMA_VOCAB_PRE_TYPE_SUPERBPE": [],
  "LLAMA_VOCAB_PRE_TYPE_TRILLION": [],
  "LLAMA_VOCAB_PRE_TYPE_BAILINGMOE": [],
  "LLAMA_VOCAB_PRE_TYPE_LLAMA4": [],
  "LLAMA_VOCAB_PRE_TYPE_PIXTRAL": [],
  "LLAMA_VOCAB_PRE_TYPE_SEED_CODER": [],
  "LLAMA_ROPE_TYPE_NONE": [],
  "LLAMA_ROPE_TYPE_NORM": [],
  "LLAMA_ROPE_TYPE_NEOX": [],
  "GGML_ROPE_TYPE_NEOX": [],
  "LLAMA_ROPE_TYPE_MROPE": [],
  "GGML_ROPE_TYPE_MROPE": [],
  "LLAMA_ROPE_TYPE_VISION": [],
  "GGML_ROPE_TYPE_VISION": [],
  "LLAMA_TOKEN_TYPE_UNDEFINED": [],
  "LLAMA_TOKEN_TYPE_NORMAL": [],
  "LLAMA_TOKEN_TYPE_UNKNOWN": [],
  "LLAMA_TOKEN_TYPE_CONTROL": [],
  "LLAMA_TOKEN_TYPE_USER_DEFINED": [],
  "LLAMA_TOKEN_TYPE_UNUSED": [],
  "LLAMA_TOKEN_TYPE_BYTE": [],
  "LLAMA_TOKEN_ATTR_UNDEFINED": [],
  "LLAMA_TOKEN_ATTR_UNKNOWN": [],
  "LLAMA_TOKEN_ATTR_UNUSED": [],
  "LLAMA_TOKEN_ATTR_NORMAL": [],
  "LLAMA_TOKEN_ATTR_CONTROL": [],
  "LLAMA_TOKEN_ATTR_USER_DEFINED": [],
  "LLAMA_TOKEN_ATTR_BYTE": [],
  "LLAMA_TOKEN_ATTR_NORMALIZED": [],
  "LLAMA_TOKEN_ATTR_LSTRIP": [],
  "LLAMA_TOKEN_ATTR_RSTRIP": [],
  "LLAMA_TOKEN_ATTR_SINGLE_WORD": [],
  "LLAMA_FTYPE_ALL_F32": [],
  "LLAMA_FTYPE_MOSTLY_F16": [],
  "LLAMA_FTYPE_MOSTLY_Q4_0": [],
  "LLAMA_FTYPE_MOSTLY_Q4_1": [],
  "LLAMA_FTYPE_MOSTLY_Q8_0": [],
  "LLAMA_FTYPE_MOSTLY_Q5_0": [],
  "LLAMA_FTYPE_MOSTLY_Q5_1": [],
  "LLAMA_FTYPE_MOSTLY_Q2_K": [],
  "LLAMA_FTYPE_MOSTLY_Q3_K_S": [],
  "LLAMA_FTYPE_MOSTLY_Q3_K_M": [],
  "LLAMA_FTYPE_MOSTLY_Q3_K_L": [],
  "LLAMA_FTYPE_MOSTLY_Q4_K_S": [],
  "LLAMA_FTYPE_MOSTLY_Q4_K_M": [],
  "LLAMA_FTYPE_MOSTLY_Q5_K_S": [],
  "LLAMA_FTYPE_MOSTLY_Q5_K_M": [],
  "LLAMA_FTYPE_MOSTLY_Q6_K": [],
  "LLAMA_FTYPE_MOSTLY_IQ2_XXS": [],
  "LLAMA_FTYPE_MOSTLY_IQ2_XS": [],
  "LLAMA_FTYPE_MOSTLY_Q2_K_S": [],
  "LLAMA_FTYPE_MOSTLY_IQ3_XS": [],
  "LLAMA_FTYPE_MOSTLY_IQ3_XXS": [],
  "LLAMA_FTYPE_MOSTLY_IQ1_S": [],
  "LLAMA_FTYPE_MOSTLY_IQ4_NL": [],
  "LLAMA_FTYPE_MOSTLY_IQ3_S": [],
  "LLAMA_FTYPE_MOSTLY_IQ3_M": [],
  "LLAMA_FTYPE_MOSTLY_IQ2_S": [],
  "LLAMA_FTYPE_MOSTLY_IQ2_M": [],
  "LLAMA_FTYPE_MOSTLY_IQ4_XS": [],
  "LLAMA_FTYPE_MOSTLY_IQ1_M": [],
  "LLAMA_FTYPE_MOSTLY_BF16": [],
  "LLAMA_FTYPE_MOSTLY_TQ1_0": [],
  "LLAMA_FTYPE_MOSTLY_TQ2_0": [],
  "LLAMA_FTYPE_MOSTLY_MXFP4_MOE": [],
  "LLAMA_FTYPE_GUESSED": [],
  "LLAMA_ROPE_SCALING_TYPE_UNSPECIFIED": [],
  "LLAMA_ROPE_SCALING_TYPE_NONE": [],
  "LLAMA_ROPE_SCALING_TYPE_LINEAR": [],
  "LLAMA_ROPE_SCALING_TYPE_YARN": [],
  "LLAMA_ROPE_SCALING_TYPE_LONGROPE": [],
  "LLAMA_ROPE_SCALING_TYPE_MAX_VALUE": [],
  "LLAMA_POOLING_TYPE_UNSPECIFIED": [],
  "LLAMA_POOLING_TYPE_NONE": [],
  "LLAMA_POOLING_TYPE_MEAN": [],
  "LLAMA_POOLING_TYPE_CLS": [],
  "LLAMA_POOLING_TYPE_LAST": [],
  "LLAMA_POOLING_TYPE_RANK": [],
  "LLAMA_ATTENTION_TYPE_UNSPECIFIED": [],
  "LLAMA_ATTENTION_TYPE_CAUSAL": [],
  "LLAMA_ATTENTION_TYPE_NON_CAUSAL": [],
  "LLAMA_SPLIT_MODE_NONE": [],
  "LLAMA_SPLIT_MODE_LAYER": [],
  "LLAMA_SPLIT_MODE_ROW": [],
  "llama_token_data": {
    "_fields_": []
  },
  "llama_token_data_p": [],
  "llama_token_data_array": {
    "_fields_": []
  },
  "llama_token_data_array_p": [],
  "llama_progress_callback": [],
  "llama_batch": {
    "_fields_": []
  },
  "LLAMA_KV_OVERRIDE_TYPE_INT": [],
  "LLAMA_KV_OVERRIDE_TYPE_FLOAT": [],
  "LLAMA_KV_OVERRIDE_TYPE_BOOL": [],
  "LLAMA_KV_OVERRIDE_TYPE_STR": [],
  "llama_model_kv_override_value": {
    "_fields_": []
  },
  "llama_model_kv_override": {
    "_fields_": []
  },
  "llama_model_params": {
    "_fields_": []
  },
  "llama_context_params": {
    "_fields_": []
  },
  "llama_log_callback": [],
  "llama_model_quantize_params": {
    "_fields_": []
  },
  "llama_logit_bias": {
    "_fields_": []
  },
  "llama_logit_bias_p": [],
  "llama_sampler_chain_params": {
    "_fields_": []
  },
  "llama_chat_message": {
    "_fields_": []
  },
  "llama_adapter_lora_p": [],
  "llama_adapter_lora_p_ctypes": [],
  "llama_model_default_params": [],
  "llama_context_default_params": [],
  "llama_sampler_chain_default_params": [],
  "llama_model_quantize_default_params": [],
  "llama_backend_init": [],
  "GGML_NUMA_STRATEGY_DISABLED": [],
  "GGML_NUMA_STRATEGY_DISTRIBUTE": [],
  "GGML_NUMA_STRATEGY_ISOLATE": [],
  "GGML_NUMA_STRATEGY_NUMACTL": [],
  "GGML_NUMA_STRATEGY_MIRROR": [],
  "GGML_NUMA_STRATEGY_COUNT": [],
  "llama_backend_free": [],
  "llama_numa_init": [],
  "llama_load_model_from_file": [],
  "llama_model_load_from_file": [],
  "llama_model_load_from_splits": [],
  "llama_model_save_to_file": [],
  "llama_free_model": [],
  "llama_model_free": [],
  "llama_init_from_model": [],
  "llama_new_context_with_model": [],
  "llama_free": [],
  "llama_time_us": [],
  "llama_max_devices": [],
  "llama_max_parallel_sequences": [],
  "llama_supports_mmap": [],
  "llama_supports_mlock": [],
  "llama_supports_gpu_offload": [],
  "llama_supports_rpc": [],
  "llama_n_ctx": [],
  "llama_n_batch": [],
  "llama_n_ubatch": [],
  "llama_n_seq_max": [],
  "llama_n_ctx_train": [],
  "llama_n_embd": [],
  "llama_n_layer": [],
  "llama_n_head": [],
  "llama_n_vocab": [],
  "llama_get_model": [],
  "llama_get_memory": [],
  "llama_pooling_type": [],
  "llama_get_kv_self": [],
  "llama_model_get_vocab": [],
  "llama_model_rope_type": [],
  "llama_model_n_ctx_train": [],
  "llama_model_n_embd": [],
  "llama_model_n_layer": [],
  "llama_model_n_head": [],
  "llama_model_n_head_kv": [],
  "llama_model_n_swa": [],
  "llama_model_rope_freq_scale_train": [],
  "llama_model_n_cls_out": [],
  "llama_model_cls_label": [],
  "llama_vocab_type": [],
  "llama_vocab_n_tokens": [],
  "llama_model_meta_val_str": [],
  "llama_model_meta_count": [],
  "llama_model_meta_key_by_index": [],
  "llama_model_meta_val_str_by_index": [],
  "llama_model_desc": [],
  "llama_model_size": [],
  "llama_model_chat_template": [],
  "llama_model_n_params": [],
  "llama_model_has_encoder": [],
  "llama_model_has_decoder": [],
  "llama_model_decoder_start_token": [],
  "llama_model_is_recurrent": [],
  "llama_model_is_diffusion": [],
  "llama_model_quantize": [],
  "llama_adapter_lora_init": [],
  "llama_adapter_lora_free": [],
  "llama_set_adapter_lora": [],
  "llama_rm_adapter_lora": [],
  "llama_clear_adapter_lora": [],
  "llama_apply_adapter_cvec": [],
  "llama_memory_clear": [],
  "llama_memory_seq_rm": [],
  "llama_memory_seq_cp": [],
  "llama_memory_seq_keep": [],
  "llama_memory_seq_add": [],
  "llama_memory_seq_div": [],
  "llama_memory_seq_pos_min": [],
  "llama_memory_seq_pos_max": [],
  "llama_memory_can_shift": [],
  "llama_kv_self_n_tokens": [],
  "llama_kv_self_used_cells": [],
  "llama_kv_self_clear": [],
  "llama_kv_self_seq_rm": [],
  "llama_kv_self_seq_cp": [],
  "llama_kv_self_seq_keep": [],
  "llama_kv_self_seq_add": [],
  "llama_kv_self_seq_div": [],
  "llama_kv_self_seq_pos_min": [],
  "llama_kv_self_seq_pos_max": [],
  "llama_kv_self_defrag": [],
  "llama_kv_self_can_shift": [],
  "llama_kv_self_update": [],
  "llama_state_get_size": [],
  "llama_get_state_size": [],
  "llama_state_get_data": [],
  "llama_copy_state_data": [],
  "llama_state_set_data": [],
  "llama_set_state_data": [],
  "llama_state_load_file": [],
  "llama_load_session_file": [],
  "llama_state_save_file": [],
  "llama_save_session_file": [],
  "llama_state_seq_get_size": [],
  "llama_state_seq_get_data": [],
  "llama_state_seq_set_data": [],
  "llama_state_seq_save_file": [],
  "llama_state_seq_load_file": [],
  "llama_batch_get_one": [],
  "llama_batch_init": [],
  "llama_batch_free": [],
  "llama_encode": [],
  "llama_decode": [],
  "llama_set_n_threads": [],
  "llama_n_threads": [],
  "llama_n_threads_batch": [],
  "llama_set_embeddings": [],
  "llama_set_causal_attn": [],
  "llama_set_warmup": [],
  "llama_set_abort_callback": [],
  "llama_synchronize": [],
  "llama_get_logits": [],
  "llama_get_logits_ith": [],
  "llama_get_embeddings": [],
  "llama_get_embeddings_ith": [],
  "llama_get_embeddings_seq": [],
  "llama_vocab_get_text": [],
  "llama_vocab_get_score": [],
  "llama_vocab_get_attr": [],
  "llama_vocab_is_eog": [],
  "llama_vocab_is_control": [],
  "llama_vocab_bos": [],
  "llama_vocab_eos": [],
  "llama_vocab_eot": [],
  "llama_vocab_sep": [],
  "llama_vocab_nl": [],
  "llama_vocab_pad": [],
  "llama_vocab_mask": [],
  "llama_vocab_get_add_bos": [],
  "llama_vocab_get_add_eos": [],
  "llama_vocab_get_add_sep": [],
  "llama_vocab_fim_pre": [],
  "llama_vocab_fim_suf": [],
  "llama_vocab_fim_mid": [],
  "llama_vocab_fim_pad": [],
  "llama_vocab_fim_rep": [],
  "llama_vocab_fim_sep": [],
  "llama_token_get_text": [],
  "llama_token_get_score": [],
  "llama_token_get_attr": [],
  "llama_token_is_eog": [],
  "llama_token_is_control": [],
  "llama_token_bos": [],
  "llama_token_eos": [],
  "llama_token_eot": [],
  "llama_token_cls": [],
  "llama_token_sep": [],
  "llama_token_nl": [],
  "llama_token_pad": [],
  "llama_add_bos_token": [],
  "llama_add_eos_token": [],
  "llama_token_fim_pre": [],
  "llama_token_fim_suf": [],
  "llama_token_fim_mid": [],
  "llama_token_fim_pad": [],
  "llama_token_fim_rep": [],
  "llama_token_fim_sep": [],
  "llama_vocab_cls": [],
  "llama_tokenize": [],
  "llama_token_to_piece": [],
  "llama_detokenize": [],
  "llama_chat_apply_template": [],
  "llama_chat_builtin_templates": [],
  "llama_sampler_context_t": [],
  "llama_sampler_i": {},
  "llama_sampler": {
    "_fields_": []
  },
  "llama_sampler_p_ctypes": [],
  "llama_sampler_i_name": [],
  "llama_sampler_i_accept": [],
  "llama_sampler_i_apply": [],
  "llama_sampler_i_reset": [],
  "llama_sampler_i_clone": [],
  "llama_sampler_i_free": [],
  "llama_sampler_init": [],
  "llama_sampler_name": [],
  "llama_sampler_accept": [],
  "llama_sampler_apply": [],
  "llama_sampler_reset": [],
  "llama_sampler_clone": [],
  "llama_sampler_free": [],
  "llama_sampler_chain_init": [],
  "llama_sampler_chain_add": [],
  "llama_sampler_chain_get": [],
  "llama_sampler_chain_n": [],
  "llama_sampler_chain_remove": [],
  "llama_sampler_init_greedy": [],
  "llama_sampler_init_dist": [
    "seed"
  ],
  "llama_sampler_init_softmax": [],
  "llama_sampler_init_top_k": [
    "k"
  ],
  "llama_sampler_init_top_p": [
    "p",
    "min_keep"
  ],
  "llama_sampler_init_min_p": [
    "p",
    "min_keep"
  ],
  "llama_sampler_init_typical": [
    "p",
    "min_keep"
  ],
  "llama_sampler_init_temp": [
    "t"
  ],
  "llama_sampler_init_temp_ext": [
    "t",
    "delta",
    "exponent"
  ],
  "llama_sampler_init_xtc": [],
  "llama_sampler_init_top_n_sigma": [],
  "llama_sampler_init_mirostat": [],
  "llama_sampler_init_mirostat_v2": [],
  "llama_sampler_init_grammar": [],
  "llama_sampler_init_grammar_lazy": [],
  "llama_sampler_init_grammar_lazy_patterns": [],
  "llama_sampler_init_penalties": [],
  "llama_sampler_init_dry": [],
  "llama_sampler_init_logit_bias": [],
  "llama_sampler_init_infill": [],
  "llama_sampler_get_seed": [],
  "llama_sampler_sample": [],
  "llama_split_path": [],
  "llama_split_prefix": [],
  "llama_print_system_info": [],
  "llama_log_set": [],
  "llama_perf_context_data": {
    "_fields_": []
  },
  "llama_perf_sampler_data": {
    "_fields_": []
  },
  "llama_perf_context": [],
  "llama_perf_context_print": [],
  "llama_perf_context_reset": [],
  "llama_perf_sampler": [],
  "llama_perf_sampler_print": [],
  "llama_perf_sampler_reset": [],
  "llama_opt_param_filter": [],
  "llama_opt_param_filter_all": [],
  "llama_opt_params": {
    "_fields_": []
  },
  "llama_opt_init": [],
  "llama_opt_epoch": [],
  "__version__": [],
  "libggml_base_path": [],
  "libggml": [],
  "_libmtmd_base_name": [],
  "_libmtmd_override_path": [],
  "_libmtmd_base_path": [],
  "_libmtmd": [],
  "mtmd_context_p": [],
  "mtmd_context_p_ctypes": [],
  "mtmd_bitmap_p": [],
  "mtmd_bitmap_p_ctypes": [],
  "mtmd_image_tokens_p": [],
  "mtmd_image_tokens_p_ctypes": [],
  "mtmd_input_chunk_p": [],
  "mtmd_input_chunk_p_ctypes": [],
  "mtmd_input_chunks_p": [],
  "mtmd_input_chunks_p_ctypes": [],
  "MTMD_INPUT_CHUNK_TYPE_TEXT": [],
  "MTMD_INPUT_CHUNK_TYPE_IMAGE": [],
  "MTMD_INPUT_CHUNK_TYPE_AUDIO": [],
  "mtmd_context_params": {
    "_fields_": []
  },
  "mtmd_input_text": {
    "_fields_": []
  },
  "mtmd_default_marker": [],
  "mtmd_context_params_default": [],
  "mtmd_init_from_file": [],
  "mtmd_free": [],
  "mtmd_support_vision": [],
  "mtmd_bitmap_init": [],
  "mtmd_bitmap_free": [],
  "mtmd_input_chunks_init": [],
  "mtmd_input_chunks_free": [],
  "mtmd_input_chunks_size": [],
  "mtmd_input_chunks_get": [],
  "mtmd_tokenize": [],
  "mtmd_input_chunk_get_n_tokens": [],
  "mtmd_input_chunk_get_type": [],
  "mtmd_input_chunk_get_tokens_text": [],
  "mtmd_helper_bitmap_init_from_buf": [],
  "mtmd_helper_get_n_tokens": [],
  "mtmd_helper_eval_chunk_single": [],
  "JsonType": [],
  "EmbeddingUsage": {},
  "Embedding": {},
  "CreateEmbeddingResponse": {},
  "CompletionLogprobs": {},
  "CompletionChoice": {},
  "CompletionUsage": {},
  "CreateCompletionResponse": {},
  "ChatCompletionResponseFunctionCall": {},
  "ChatCompletionResponseMessage": {},
  "ChatCompletionFunction": {},
  "ChatCompletionTopLogprobToken": {},
  "ChatCompletionLogprobToken": {},
  "ChatCompletionLogprobs": {},
  "ChatCompletionResponseChoice": {},
  "CreateChatCompletionResponse": {},
  "ChatCompletionMessageToolCallChunkFunction": {},
  "ChatCompletionMessageToolCallChunk": {},
  "ChatCompletionStreamResponseDeltaEmpty": {},
  "ChatCompletionStreamResponseDeltaFunctionCall": {},
  "ChatCompletionStreamResponseDelta": {},
  "ChatCompletionStreamResponseChoice": {},
  "CreateChatCompletionStreamResponse": {},
  "ChatCompletionFunctions": {},
  "ChatCompletionFunctionCallOption": {},
  "ChatCompletionRequestResponseFormat": {},
  "ChatCompletionRequestMessageContentPartText": {},
  "ChatCompletionRequestMessageContentPartImageImageUrl": {},
  "ChatCompletionRequestMessageContentPartImage": {},
  "ChatCompletionRequestMessageContentPart": [],
  "ChatCompletionRequestSystemMessage": {},
  "ChatCompletionRequestUserMessage": {},
  "ChatCompletionMessageToolCallFunction": {},
  "ChatCompletionMessageToolCall": {},
  "ChatCompletionMessageToolCalls": [],
  "ChatCompletionRequestAssistantMessageFunctionCall": {},
  "ChatCompletionRequestAssistantMessage": {},
  "ChatCompletionRequestToolMessage": {},
  "ChatCompletionRequestFunctionMessage": {},
  "ChatCompletionRequestMessage": [],
  "ChatCompletionRequestFunctionCallOption": {},
  "ChatCompletionRequestFunctionCall": [],
  "ChatCompletionFunctionParameters": [],
  "ChatCompletionToolFunction": {},
  "ChatCompletionTool": {},
  "ChatCompletionNamedToolChoiceFunction": {},
  "ChatCompletionNamedToolChoice": {},
  "ChatCompletionToolChoiceOption": [],
  "EmbeddingData": [],
  "CompletionChunk": [],
  "Completion": [],
  "CreateCompletionStreamResponse": [],
  "ChatCompletionMessage": [],
  "ChatCompletionChoice": [],
  "ChatCompletion": [],
  "ChatCompletionChunkDeltaEmpty": [],
  "ChatCompletionChunkChoice": [],
  "ChatCompletionChunkDelta": [],
  "ChatCompletionChunk": [],
  "ChatCompletionStreamResponse": [],
  "ChatCompletionResponseFunction": [],
  "ChatCompletionFunctionCall": [],
  "LlamaDraftModel": {
    "__call__": []
  },
  "LlamaPromptLookupDecoding": {
    "__init__": [
      "self",
      "max_ngram_size",
      "num_pred_tokens"
    ],
    "find_candidate_pred_tokens": [
      "input_ids",
      "max_ngram_size",
      "num_pred_tokens"
    ],
    "__call__": []
  },
  "GGML_LOG_LEVEL_TO_LOGGING_LEVEL": [],
  "logger": [],
  "_last_log_level": [],
  "set_verbose": [
    "verbose"
  ],
  "CHATML_CHAT_TEMPLATE": [],
  "CHATML_BOS_TOKEN": [],
  "CHATML_EOS_TOKEN": [],
  "MISTRAL_INSTRUCT_CHAT_TEMPLATE": [],
  "MISTRAL_INSTRUCT_BOS_TOKEN": [],
  "MISTRAL_INSTRUCT_EOS_TOKEN": [],
  "MIXTRAL_INSTRUCT_CHAT_TEMPLATE": [],
  "LLAMA3_INSTRUCT_CHAT_TEMPLATE": [],
  "LlamaChatCompletionHandler": {
    "__call__": [
      "self"
    ]
  },
  "LlamaChatCompletionHandlerNotFoundException": {},
  "LlamaChatCompletionHandlerRegistry": {
    "register_chat_completion_handler": [
      "self",
      "name",
      "chat_handler",
      "overwrite"
    ],
    "unregister_chat_handler": [
      "self",
      "name"
    ],
    "get_chat_completion_handler_by_name": [
      "self",
      "name"
    ]
  },
  "get_chat_completion_handler": [
    "name"
  ],
  "register_chat_completion_handler": [
    "name"
  ],
  "ChatFormatterResponse": {},
  "ChatFormatter": {
    "__call__": [
      "self"
    ]
  },
  "Jinja2ChatFormatter": {
    "__init__": [
      "self",
      "template",
      "eos_token",
      "bos_token",
      "add_generation_prompt",
      "stop_token_ids"
    ],
    "strftime_now": [
      "f"
    ],
    "__call__": [
      "self"
    ],
    "to_chat_handler": [
      "self"
    ]
  },
  "_convert_text_completion_logprobs_to_chat": [
    "logprobs"
  ],
  "_convert_text_completion_to_chat": [
    "completion"
  ],
  "_convert_text_completion_chunks_to_chat": [
    "chunks"
  ],
  "_convert_completion_to_chat": [
    "completion_or_chunks",
    "stream"
  ],
  "_convert_completion_to_chat_function": [
    "tool_name",
    "completion_or_chunks",
    "stream"
  ],
  "chat_formatter_to_chat_completion_handler": [
    "chat_formatter"
  ],
  "hf_autotokenizer_to_chat_formatter": [
    "pretrained_model_name_or_path"
  ],
  "hf_autotokenizer_to_chat_completion_handler": [
    "pretrained_model_name_or_path"
  ],
  "hf_tokenizer_config_to_chat_formatter": [
    "tokenizer_config",
    "add_generation_prompt"
  ],
  "hf_tokenizer_config_to_chat_completion_handler": [
    "tokenizer_config",
    "add_generation_prompt"
  ],
  "guess_chat_format_from_gguf_metadata": [
    "metadata"
  ],
  "_get_system_message": [
    "messages"
  ],
  "_map_roles": [
    "messages",
    "role_map"
  ],
  "_format_llama2": [
    "system_message",
    "messages",
    "sep",
    "sep2"
  ],
  "_format_add_colon_single": [
    "system_message",
    "messages",
    "sep"
  ],
  "_format_add_colon_two": [
    "system_message",
    "messages",
    "sep",
    "sep2"
  ],
  "_format_no_colon_single": [
    "system_message",
    "messages",
    "sep"
  ],
  "_format_add_colon_space_single": [
    "system_message",
    "messages",
    "sep"
  ],
  "_format_chatml": [
    "system_message",
    "messages",
    "sep"
  ],
  "_format_chatglm3": [
    "system_message",
    "messages",
    "sep"
  ],
  "_grammar_for_json": [
    "verbose"
  ],
  "_grammar_for_json_schema": [
    "schema",
    "verbose",
    "fallback_to_json"
  ],
  "_grammar_for_response_format": [
    "response_format",
    "verbose"
  ],
  "register_chat_format": [
    "name"
  ],
  "format_llama2": [
    "messages"
  ],
  "format_llama3": [
    "messages"
  ],
  "format_alpaca": [
    "messages"
  ],
  "format_qwen": [
    "messages"
  ],
  "format": [
    "messages"
  ],
  "format_oasst_llama": [
    "messages"
  ],
  "format_baichuan2": [
    "messages"
  ],
  "format_baichuan": [
    "messages"
  ],
  "format_openbuddy": [
    "messages"
  ],
  "format_redpajama_incite": [
    "messages"
  ],
  "format_snoozy": [
    "messages"
  ],
  "format_phind": [
    "messages"
  ],
  "format_intel": [
    "messages"
  ],
  "format_open_orca": [
    "messages"
  ],
  "format_mistrallite": [
    "messages"
  ],
  "format_zephyr": [
    "messages"
  ],
  "format_pygmalion": [
    "messages"
  ],
  "format_chatml": [
    "messages"
  ],
  "format_mistral_instruct": [
    "messages"
  ],
  "format_chatglm3": [
    "messages"
  ],
  "format_openchat": [
    "messages"
  ],
  "format_saiga": [
    "messages"
  ],
  "format_gemma": [
    "messages"
  ],
  "functionary_chat_handler": [
    "llama",
    "messages",
    "functions",
    "function_call",
    "tools",
    "tool_choice",
    "temperature",
    "top_p",
    "top_k",
    "min_p",
    "typical_p",
    "stream",
    "stop",
    "response_format",
    "max_tokens",
    "presence_penalty",
    "frequency_penalty",
    "repeat_penalty",
    "tfs_z",
    "mirostat_mode",
    "mirostat_tau",
    "mirostat_eta",
    "model",
    "logits_processor",
    "grammar"
  ],
  "functionary_v1_v2_chat_handler": [
    "llama",
    "messages",
    "functions",
    "function_call",
    "tools",
    "tool_choice",
    "temperature",
    "top_p",
    "top_k",
    "min_p",
    "typical_p",
    "stream",
    "stop",
    "response_format",
    "max_tokens",
    "presence_penalty",
    "frequency_penalty",
    "repeat_penalty",
    "tfs_z",
    "mirostat_mode",
    "mirostat_tau",
    "mirostat_eta",
    "model",
    "logits_processor",
    "grammar"
  ],
  "Llava15ChatHandler": {
    "CHAT_FORMAT": [],
    "__init__": [
      "self",
      "clip_model_path",
      "verbose"
    ],
    "_init_mtmd_context": [
      "self",
      "llama_model"
    ],
    "load_image": [
      "self",
      "image_url"
    ],
    "_create_bitmap_from_bytes": [
      "self",
      "image_bytes"
    ],
    "__call__": [
      "self"
    ],
    "_load_image": [
      "image_url"
    ],
    "get_image_urls": [
      "messages"
    ],
    "split_text_on_image_urls": [
      "text",
      "image_urls"
    ],
    "from_pretrained": [
      "cls",
      "repo_id",
      "filename",
      "local_dir",
      "local_dir_use_symlinks",
      "cache_dir"
    ]
  },
  "ObsidianChatHandler": {
    "CHAT_FORMAT": []
  },
  "MoondreamChatHandler": {
    "CHAT_FORMAT": []
  },
  "Llava16ChatHandler": {
    "DEFAULT_SYSTEM_MESSAGE": [],
    "CHAT_FORMAT": []
  },
  "NanoLlavaChatHandler": {
    "DEFAULT_SYSTEM_MESSAGE": [],
    "CHAT_FORMAT": []
  },
  "Llama3VisionAlphaChatHandler": {
    "DEFAULT_SYSTEM_MESSAGE": [],
    "CHAT_FORMAT": []
  },
  "Llama3VisionAlpha": [],
  "MiniCPMv26ChatHandler": {
    "DEFAULT_SYSTEM_MESSAGE": [],
    "CHAT_FORMAT": []
  },
  "Qwen25VLChatHandler": {
    "DEFAULT_SYSTEM_MESSAGE": [],
    "CHAT_FORMAT": [],
    "__call__": [
      "self"
    ]
  },
  "chatml_function_calling": [
    "llama",
    "messages",
    "functions",
    "function_call",
    "tools",
    "tool_choice",
    "temperature",
    "top_p",
    "top_k",
    "min_p",
    "typical_p",
    "stream",
    "stop",
    "response_format",
    "max_tokens",
    "presence_penalty",
    "frequency_penalty",
    "repeat_penalty",
    "tfs_z",
    "mirostat_mode",
    "mirostat_tau",
    "mirostat_eta",
    "model",
    "logits_processor",
    "grammar",
    "logprobs",
    "top_logprobs"
  ],
  "Llama": {
    "__backend_initialized": [],
    "__init__": [
      "self",
      "model_path"
    ],
    "ctx": [
      "self"
    ],
    "model": [
      "self"
    ],
    "_input_ids": [
      "self"
    ],
    "_scores": [
      "self"
    ],
    "eval_tokens": [
      "self"
    ],
    "eval_logits": [
      "self"
    ],
    "tokenize": [
      "self",
      "text",
      "add_bos",
      "special"
    ],
    "detokenize": [
      "self",
      "tokens",
      "prev_tokens",
      "special"
    ],
    "set_cache": [
      "self",
      "cache"
    ],
    "set_seed": [
      "self",
      "seed"
    ],
    "reset": [
      "self"
    ],
    "eval": [
      "self",
      "tokens"
    ],
    "_init_sampler": [
      "self",
      "top_k",
      "top_p",
      "min_p",
      "typical_p",
      "temp",
      "repeat_penalty",
      "frequency_penalty",
      "presence_penalty",
      "tfs_z",
      "mirostat_mode",
      "mirostat_eta",
      "mirostat_tau",
      "penalize_nl",
      "logits_processor",
      "grammar"
    ],
    "sample": [
      "self",
      "top_k",
      "top_p",
      "min_p",
      "typical_p",
      "temp",
      "repeat_penalty",
      "frequency_penalty",
      "presence_penalty",
      "tfs_z",
      "mirostat_mode",
      "mirostat_eta",
      "mirostat_tau",
      "penalize_nl",
      "logits_processor",
      "grammar",
      "idx"
    ],
    "generate": [
      "self",
      "tokens",
      "top_k",
      "top_p",
      "min_p",
      "typical_p",
      "temp",
      "repeat_penalty",
      "reset",
      "frequency_penalty",
      "presence_penalty",
      "tfs_z",
      "mirostat_mode",
      "mirostat_tau",
      "mirostat_eta",
      "penalize_nl",
      "logits_processor",
      "stopping_criteria",
      "grammar"
    ],
    "create_embedding": [
      "self",
      "input",
      "model"
    ],
    "embed": [
      "self",
      "input",
      "normalize",
      "truncate",
      "return_count"
    ],
    "_create_completion": [
      "self",
      "prompt",
      "suffix",
      "max_tokens",
      "temperature",
      "top_p",
      "min_p",
      "typical_p",
      "logprobs",
      "echo",
      "stop",
      "frequency_penalty",
      "presence_penalty",
      "repeat_penalty",
      "top_k",
      "stream",
      "seed",
      "tfs_z",
      "mirostat_mode",
      "mirostat_tau",
      "mirostat_eta",
      "model",
      "stopping_criteria",
      "logits_processor",
      "grammar",
      "logit_bias"
    ],
    "create_completion": [
      "self",
      "prompt",
      "suffix",
      "max_tokens",
      "temperature",
      "top_p",
      "min_p",
      "typical_p",
      "logprobs",
      "echo",
      "stop",
      "frequency_penalty",
      "presence_penalty",
      "repeat_penalty",
      "top_k",
      "stream",
      "seed",
      "tfs_z",
      "mirostat_mode",
      "mirostat_tau",
      "mirostat_eta",
      "model",
      "stopping_criteria",
      "logits_processor",
      "grammar",
      "logit_bias"
    ],
    "__call__": [
      "self",
      "prompt",
      "suffix",
      "max_tokens",
      "temperature",
      "top_p",
      "min_p",
      "typical_p",
      "logprobs",
      "echo",
      "stop",
      "frequency_penalty",
      "presence_penalty",
      "repeat_penalty",
      "top_k",
      "stream",
      "seed",
      "tfs_z",
      "mirostat_mode",
      "mirostat_tau",
      "mirostat_eta",
      "model",
      "stopping_criteria",
      "logits_processor",
      "grammar",
      "logit_bias"
    ],
    "create_chat_completion": [
      "self",
      "messages",
      "functions",
      "function_call",
      "tools",
      "tool_choice",
      "temperature",
      "top_p",
      "top_k",
      "min_p",
      "typical_p",
      "stream",
      "stop",
      "seed",
      "response_format",
      "max_tokens",
      "presence_penalty",
      "frequency_penalty",
      "repeat_penalty",
      "tfs_z",
      "mirostat_mode",
      "mirostat_tau",
      "mirostat_eta",
      "model",
      "logits_processor",
      "grammar",
      "logit_bias",
      "logprobs",
      "top_logprobs"
    ],
    "create_chat_completion_openai_v1": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "save_state": [
      "self"
    ],
    "load_state": [
      "self",
      "state"
    ],
    "n_ctx": [
      "self"
    ],
    "n_embd": [
      "self"
    ],
    "n_vocab": [
      "self"
    ],
    "tokenizer": [
      "self"
    ],
    "token_eos": [
      "self"
    ],
    "token_bos": [
      "self"
    ],
    "token_nl": [
      "self"
    ],
    "pooling_type": [
      "self"
    ],
    "close": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "logits_to_logprobs": [
      "logits",
      "axis"
    ],
    "longest_token_prefix": [
      "a",
      "b"
    ],
    "from_pretrained": [
      "cls",
      "repo_id",
      "filename",
      "additional_files",
      "local_dir",
      "local_dir_use_symlinks",
      "cache_dir"
    ]
  },
  "LlamaState": {
    "__init__": [
      "self",
      "input_ids",
      "scores",
      "n_tokens",
      "llama_state",
      "llama_state_size",
      "seed"
    ]
  },
  "LogitsProcessor": [],
  "LogitsProcessorList": {
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "StoppingCriteria": [],
  "StoppingCriteriaList": {
    "__call__": [
      "self",
      "input_ids",
      "logits"
    ]
  },
  "MinTokensLogitsProcessor": {
    "__init__": [
      "self",
      "min_tokens",
      "token_eos"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "BaseLlamaTokenizer": {
    "tokenize": [
      "self",
      "text",
      "add_bos",
      "special"
    ],
    "detokenize": [
      "self",
      "tokens",
      "prev_tokens",
      "special"
    ]
  },
  "LlamaTokenizer": {
    "__init__": [
      "self",
      "llama"
    ],
    "tokenize": [
      "self",
      "text",
      "add_bos",
      "special"
    ],
    "detokenize": [
      "self",
      "tokens",
      "prev_tokens",
      "special"
    ],
    "encode": [
      "self",
      "text",
      "add_bos",
      "special"
    ],
    "decode": [
      "self",
      "tokens"
    ],
    "from_ggml_file": [
      "cls",
      "path"
    ]
  },
  "LlamaHFTokenizer": {
    "__init__": [
      "self",
      "hf_tokenizer"
    ],
    "tokenize": [
      "self",
      "text",
      "add_bos",
      "special"
    ],
    "detokenize": [
      "self",
      "tokens",
      "prev_tokens",
      "special"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "LLAMA_GRAMMAR_DEFAULT_ROOT": [],
  "LlamaGrammar": {
    "__init__": [
      "self"
    ],
    "from_string": [
      "cls",
      "grammar",
      "verbose"
    ],
    "from_file": [
      "cls",
      "file",
      "verbose"
    ],
    "from_json_schema": [
      "cls",
      "json_schema",
      "verbose"
    ]
  },
  "ARITHMETIC_GBNF": [],
  "C_GBNF": [],
  "CHESS_GBNF": [],
  "JAPANESE_GBNF": [],
  "JSON_ARR_GBNF": [],
  "JSON_GBNF": [],
  "LIST_GBNF": [],
  "SPACE_RULE": [],
  "INVALID_RULE_CHARS_RE": [],
  "GRAMMAR_LITERAL_ESCAPE_RE": [],
  "GRAMMAR_LITERAL_ESCAPES": [],
  "_build_repetition": [
    "item_rule",
    "min_items",
    "max_items",
    "separator_rule",
    "item_rule_is_literal"
  ],
  "BuiltinRule": {
    "__init__": [
      "self",
      "content",
      "deps"
    ]
  },
  "_up_to_15_digits": [],
  "PRIMITIVE_RULES": [],
  "STRING_FORMAT_RULES": [],
  "DOTALL": [],
  "DOT": [],
  "RESERVED_NAMES": [],
  "NON_LITERAL_SET": [],
  "ESCAPED_IN_REGEXPS_BUT_NOT_IN_LITERALS": [],
  "SchemaConverter": {
    "__init__": [
      "self"
    ],
    "_format_literal": [
      "self",
      "literal"
    ],
    "not_literal": [
      "self",
      "literal",
      "dotall",
      "maybe_escaped_underscores"
    ],
    "_add_rule": [
      "self",
      "name",
      "rule"
    ],
    "resolve_refs": [
      "self",
      "schema",
      "url"
    ],
    "_generate_union_rule": [
      "self",
      "name",
      "alt_schemas"
    ],
    "_visit_pattern": [
      "self",
      "pattern",
      "name"
    ],
    "_resolve_ref": [
      "self",
      "ref"
    ],
    "_generate_constant_rule": [
      "self",
      "value"
    ],
    "visit": [
      "self",
      "schema",
      "name"
    ],
    "_add_primitive": [
      "self",
      "name",
      "rule"
    ],
    "_build_object_rule": [
      "self",
      "properties",
      "required",
      "name",
      "additional_properties"
    ],
    "format_grammar": [
      "self"
    ]
  },
  "json_schema_to_gbnf": [
    "schema",
    "prop_order"
  ],
  "BaseLlamaCache": {
    "__init__": [
      "self",
      "capacity_bytes"
    ],
    "cache_size": [
      "self"
    ],
    "_find_longest_prefix_key": [
      "self",
      "key"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "LlamaRAMCache": {
    "__init__": [
      "self",
      "capacity_bytes"
    ],
    "cache_size": [
      "self"
    ],
    "_find_longest_prefix_key": [
      "self",
      "key"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "LlamaCache": [],
  "LlamaDiskCache": {
    "__init__": [
      "self",
      "cache_dir",
      "capacity_bytes"
    ],
    "cache_size": [
      "self"
    ],
    "_find_longest_prefix_key": [
      "self",
      "key"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "load_shared_library": [
    "lib_base_name",
    "base_path"
  ],
  "F": [],
  "ctypes_function_for_shared_library": [
    "lib"
  ],
  "_byref": [
    "obj",
    "offset"
  ],
  "byref": [],
  "ErrorResponse": {},
  "ErrorResponseFormatters": {
    "context_length_exceeded": [
      "request",
      "match"
    ],
    "model_not_found": [
      "request",
      "match"
    ]
  },
  "RouteErrorHandler": {
    "error_message_wrapper": [
      "self",
      "error",
      "body"
    ],
    "get_route_handler": [
      "self"
    ]
  },
  "ModelSettings": {
    "set_dynamic_defaults": [
      "self"
    ]
  },
  "ServerSettings": {},
  "Settings": {},
  "ConfigFileSettings": {},
  "_get_base_type": [
    "annotation"
  ],
  "_contains_list_type": [
    "annotation"
  ],
  "_parse_bool_arg": [
    "arg"
  ],
  "add_args_from_model": [
    "parser",
    "model"
  ],
  "T": [],
  "parse_model_from_args": [
    "model",
    "args"
  ],
  "LlamaProxy": {
    "__init__": [
      "self",
      "models"
    ],
    "__call__": [
      "self",
      "model"
    ],
    "__getitem__": [
      "self",
      "model"
    ],
    "__setitem__": [
      "self",
      "model",
      "settings"
    ],
    "__iter__": [
      "self"
    ],
    "free": [
      "self"
    ],
    "load_llama_from_model_settings": [
      "settings"
    ]
  },
  "router": [],
  "set_server_settings": [
    "server_settings"
  ],
  "get_server_settings": [],
  "llama_outer_lock": [],
  "llama_inner_lock": [],
  "set_llama_proxy": [
    "model_settings"
  ],
  "get_llama_proxy": [],
  "set_ping_message_factory": [
    "factory"
  ],
  "create_app": [
    "settings",
    "server_settings",
    "model_settings"
  ],
  "prepare_request_resources": [
    "body",
    "llama_proxy",
    "body_model",
    "kwargs"
  ],
  "get_event_publisher": [
    "request",
    "inner_send_chan",
    "body",
    "body_model",
    "llama_call",
    "kwargs"
  ],
  "_logit_bias_tokens_to_input_ids": [
    "llama",
    "logit_bias"
  ],
  "bearer_scheme": [],
  "authenticate": [
    "settings",
    "authorization"
  ],
  "openai_v1_tag": [],
  "create_completion": [
    "request",
    "body"
  ],
  "create_embedding": [
    "request",
    "llama_proxy"
  ],
  "create_chat_completion": [
    "request",
    "body"
  ],
  "get_models": [
    "llama_proxy"
  ],
  "extras_tag": [],
  "tokenize": [
    "body",
    "llama_proxy"
  ],
  "count_query_tokens": [
    "body",
    "llama_proxy"
  ],
  "detokenize": [
    "body",
    "llama_proxy"
  ],
  "model_field": [],
  "max_tokens_field": [],
  "min_tokens_field": [],
  "temperature_field": [],
  "top_p_field": [],
  "min_p_field": [],
  "stop_field": [],
  "stream_field": [],
  "top_k_field": [],
  "repeat_penalty_field": [],
  "presence_penalty_field": [],
  "frequency_penalty_field": [],
  "mirostat_mode_field": [],
  "mirostat_tau_field": [],
  "mirostat_eta_field": [],
  "grammar": [],
  "CreateCompletionRequest": {
    "model_config": []
  },
  "CreateEmbeddingRequest": {
    "model_config": []
  },
  "CreateChatCompletionRequest": {
    "model_config": []
  },
  "ModelData": {},
  "ModelList": {},
  "TokenizeInputRequest": {
    "model_config": []
  },
  "TokenizeInputResponse": {
    "model_config": []
  },
  "TokenizeInputCountResponse": {
    "model_config": []
  },
  "DetokenizeInputRequest": {
    "model_config": []
  },
  "DetokenizeInputResponse": {
    "model_config": []
  },
  "PartialLoraTensor": {},
  "LoraTorchTensor": {
    "__init__": [
      "self",
      "A",
      "B"
    ],
    "get_lora_A_B": [
      "self"
    ],
    "__getitem__": [
      "self",
      "indices"
    ],
    "dtype": [
      "self"
    ],
    "shape": [
      "self"
    ],
    "size": [
      "self",
      "dim"
    ],
    "reshape": [
      "self"
    ],
    "reshape_as": [
      "self",
      "other"
    ],
    "view": [
      "self"
    ],
    "permute": [
      "self"
    ],
    "transpose": [
      "self",
      "dim0",
      "dim1"
    ],
    "swapaxes": [
      "self",
      "axis0",
      "axis1"
    ],
    "to": [
      "self"
    ],
    "__torch_function__": [
      "cls",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "get_base_tensor_name": [
    "lora_tensor_name"
  ],
  "parse_args": [],
  "load_hparams_from_hf": [
    "hf_model_id"
  ],
  "sess": [],
  "convert_py_pth": [],
  "convert_py": [],
  "hf_token_pth": [],
  "hf_token": [],
  "TOKENIZER_TYPE": {
    "SPM": [],
    "BPE": [],
    "WPM": [],
    "UGM": []
  },
  "DOC_STRING": [],
  "parser": [],
  "args": [],
  "CHK_TXT": [],
  "models": [],
  "pre_computed_hashes": [],
  "download_file_with_auth": [
    "url",
    "token",
    "save_path"
  ],
  "download_model": [
    "model"
  ],
  "get_existing_models": [
    "convert_py"
  ],
  "existing_models": [],
  "all_models": [],
  "src_ifs": [],
  "src_func": [],
  "tests": [],
  "GGMLFormat": {
    "GGML": [],
    "GGMF": [],
    "GGJT": []
  },
  "GGMLFType": {
    "ALL_F32": [],
    "MOSTLY_F16": [],
    "MOSTLY_Q4_0": [],
    "MOSTLY_Q4_1": [],
    "MOSTLY_Q4_1_SOME_F16": [],
    "MOSTLY_Q8_0": [],
    "MOSTLY_Q5_0": [],
    "MOSTLY_Q5_1": [],
    "MOSTLY_Q2_K": [],
    "MOSTLY_Q3_K_S": [],
    "MOSTLY_Q3_K_M": [],
    "MOSTLY_Q3_K_L": [],
    "MOSTLY_Q4_K_S": [],
    "MOSTLY_Q4_K_M": [],
    "MOSTLY_Q5_K_S": [],
    "MOSTLY_Q5_K_M": [],
    "MOSTLY_Q6_K": []
  },
  "Hyperparameters": {
    "__init__": [
      "self"
    ],
    "set_n_ff": [
      "self",
      "model"
    ],
    "load": [
      "self",
      "data",
      "offset"
    ],
    "__str__": [
      "self"
    ]
  },
  "Vocab": {
    "__init__": [
      "self",
      "load_scores"
    ],
    "load": [
      "self",
      "data",
      "offset",
      "n_vocab"
    ]
  },
  "Tensor": {
    "__init__": [
      "self",
      "use_padding"
    ],
    "load": [
      "self",
      "data",
      "offset"
    ]
  },
  "GGMLModel": {
    "__init__": [
      "self"
    ],
    "validate_header": [
      "self",
      "data",
      "offset"
    ],
    "validate_conversion": [
      "self",
      "ftype"
    ],
    "load": [
      "self",
      "data",
      "offset"
    ]
  },
  "GGMLToGGUF": {
    "__init__": [
      "self",
      "ggml_model",
      "data",
      "cfg",
      "params_override",
      "vocab_override",
      "special_vocab"
    ],
    "save": [
      "self"
    ],
    "add_params": [
      "self",
      "gguf_writer"
    ],
    "add_vocab": [
      "self",
      "gguf_writer"
    ],
    "add_tensors": [
      "self",
      "gguf_writer"
    ]
  },
  "handle_metadata": [
    "cfg",
    "hp"
  ],
  "handle_args": [],
  "SentencePieceTokenTypes": {
    "NORMAL": [],
    "UNKNOWN": [],
    "CONTROL": [],
    "USER_DEFINED": [],
    "UNUSED": [],
    "BYTE": []
  },
  "ModelType": {
    "TEXT": [],
    "MMPROJ": []
  },
  "AnyModel": [],
  "ModelBase": {
    "__init__": [
      "self",
      "dir_model",
      "ftype",
      "fname_out"
    ],
    "add_prefix_to_filename": [
      "cls",
      "path",
      "prefix"
    ],
    "find_hparam": [
      "self",
      "keys",
      "optional"
    ],
    "get_tensors": [
      "self"
    ],
    "format_tensor_name": [
      "self",
      "key",
      "bid",
      "suffix"
    ],
    "match_model_tensor_name": [
      "self",
      "name",
      "key",
      "bid",
      "suffix"
    ],
    "map_tensor_name": [
      "self",
      "name",
      "try_suffixes"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "tensor_force_quant": [
      "self",
      "name",
      "new_name",
      "bid",
      "n_dims"
    ],
    "generate_extra_tensors": [
      "self"
    ],
    "prepare_tensors": [
      "self"
    ],
    "set_type": [
      "self"
    ],
    "prepare_metadata": [
      "self",
      "vocab_only"
    ],
    "write_vocab": [
      "self"
    ],
    "write": [
      "self"
    ],
    "get_model_part_names": [
      "dir_model",
      "prefix",
      "suffix"
    ],
    "load_hparams": [
      "dir_model",
      "is_mistral_format"
    ],
    "register": [
      "cls"
    ],
    "print_registered_models": [
      "cls"
    ],
    "from_model_architecture": [
      "cls",
      "arch",
      "model_type"
    ]
  },
  "TextModel": {
    "model_type": [],
    "__init__": [
      "self"
    ],
    "__init_subclass__": [
      "cls"
    ],
    "set_vocab": [
      "self"
    ],
    "prepare_metadata": [
      "self",
      "vocab_only"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "write_vocab": [
      "self"
    ],
    "does_token_look_special": [
      "self",
      "token"
    ],
    "get_vocab_base": [
      "self"
    ],
    "get_vocab_base_pre": [
      "self",
      "tokenizer"
    ],
    "_set_vocab_none": [
      "self"
    ],
    "_set_vocab_gpt2": [
      "self"
    ],
    "_set_vocab_qwen": [
      "self"
    ],
    "_set_vocab_sentencepiece": [
      "self",
      "add_to_gguf"
    ],
    "_create_vocab_sentencepiece": [
      "self"
    ],
    "_set_vocab_llama_hf": [
      "self"
    ],
    "_set_vocab_rwkv_world": [
      "self"
    ],
    "_set_vocab_builtin": [
      "self",
      "model_name",
      "vocab_size"
    ],
    "_try_set_pooling_type": [
      "self"
    ]
  },
  "MmprojModel": {
    "model_type": [],
    "model_arch": [],
    "n_block_keys": [],
    "__init__": [
      "self"
    ],
    "get_vision_config": [
      "self"
    ],
    "get_audio_config": [
      "self"
    ],
    "set_type": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "write_vocab": [
      "self"
    ],
    "find_vparam": [
      "self",
      "keys",
      "optional"
    ],
    "find_aparam": [
      "self",
      "keys",
      "optional"
    ],
    "_find_param": [
      "self",
      "obj",
      "keys",
      "optional"
    ]
  },
  "GPTNeoXModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "BloomModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "MPTModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "OrionModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "BaichuanModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "_reverse_hf_permute": [
      "self",
      "weights",
      "n_head",
      "n_kv_head"
    ],
    "_reverse_hf_permute_part": [
      "self",
      "weights",
      "n_part",
      "n_head",
      "n_head_kv"
    ],
    "_reverse_hf_part": [
      "self",
      "weights",
      "n_part"
    ]
  },
  "XverseModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "_reverse_hf_permute": [
      "self",
      "weights",
      "n_head",
      "n_kv_head"
    ]
  },
  "FalconModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "StarCoderModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "RefactModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "StableLMModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "_stack_qk_norm": [
      "self",
      "bid",
      "n_head",
      "norms",
      "layer_name"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "ArceeModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "LlavaVisionModel": {
    "img_break_tok_id": [],
    "__init__": [
      "self"
    ],
    "get_token_id": [
      "self",
      "token"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "SmolVLMModel": {
    "__init__": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "tensor_force_quant": [
      "self",
      "name",
      "new_name",
      "bid",
      "n_dims"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Llama4Model": {
    "model_arch": [],
    "undo_permute": [],
    "__init__": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Llama4VisionModel": {
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Mistral3Model": {
    "model_arch": [],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "DeciModel": {
    "model_arch": [],
    "_ffn_mult_to_intermediate_size": [
      "ffn_mult",
      "n_embd"
    ],
    "_find_multiple": [
      "n",
      "k"
    ],
    "__init__": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "permute": [
      "weights",
      "n_head",
      "n_head_kv"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "generate_extra_tensors": [
      "self"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "BitnetModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "weight_quant": [
      "self",
      "weight"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "GrokModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "DbrxModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "tensor_force_quant": [
      "self",
      "name",
      "new_name",
      "bid",
      "n_dims"
    ]
  },
  "MiniCPMModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "generate_extra_tensors": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "MiniCPM3Model": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "generate_extra_tensors": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "_reverse_hf_permute": [
      "self",
      "weights",
      "n_head",
      "n_kv_head"
    ]
  },
  "QwenModel": {
    "model_arch": [],
    "token_bytes_to_string": [
      "b"
    ],
    "bpe": [
      "mergeable_ranks",
      "token",
      "max_rank"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "Qwen2Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "DreamModel": {
    "model_arch": [],
    "get_vocab_base": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "LLaDAModel": {
    "model_arch": [],
    "undo_permute": [],
    "get_vocab_base": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "permute": [
      "weights",
      "n_head",
      "n_head_kv"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Ernie4_5Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Ernie4_5MoeModel": {
    "model_arch": [],
    "__init__": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "Qwen2VLModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Qwen2VLVisionModel": {
    "__init__": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "tensor_force_quant": [
      "self",
      "name",
      "new_name",
      "bid",
      "n_dims"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Qwen25OmniModel": {
    "has_vision_encoder": [],
    "has_audio_encoder": [],
    "__init__": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "get_vision_config": [
      "self"
    ],
    "get_audio_config": [
      "self"
    ],
    "generate_extra_tensors": [
      "self"
    ],
    "tensor_force_quant": [
      "self",
      "name",
      "new_name",
      "bid",
      "n_dims"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "InternVisionModel": {
    "set_gguf_parameters": [
      "self"
    ],
    "tensor_force_quant": [
      "self",
      "name",
      "new_name",
      "bid",
      "n_dims"
    ],
    "_mapping_interns1_name": [
      "self",
      "name"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "WavTokenizerDecModel": {
    "model_arch": [],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "Qwen2MoeModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "Qwen3Model": {
    "model_arch": []
  },
  "Qwen3MoeModel": {
    "model_arch": [],
    "__init__": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "_set_vocab_interns1": [
      "self"
    ]
  },
  "GPT2Model": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Phi2Model": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "Phi3MiniModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "generate_extra_tensors": [
      "self"
    ]
  },
  "PhiMoeModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "PlamoModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "shuffle_attn_q_weight": [
      "self",
      "data_torch"
    ],
    "shuffle_attn_output_weight": [
      "self",
      "data_torch"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Plamo2Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "CodeShellModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "_has_tok_embd": [],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "InternLM2Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "InternLM3Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "BertModel": {
    "model_arch": [],
    "__init__": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "_xlmroberta_tokenizer_init": [
      "self"
    ],
    "_xlmroberta_set_vocab": [
      "self"
    ]
  },
  "DistilBertModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "RobertaModel": {
    "model_arch": [],
    "__init__": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "NomicBertModel": {
    "model_arch": [],
    "__init__": [
      "self",
      "dir_model",
      "ftype",
      "fname_out"
    ],
    "set_vocab": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "_is_tokenizer_xlmroberta": [
      "self"
    ]
  },
  "NeoBert": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "XLMRobertaModel": {
    "model_arch": [],
    "__init__": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "GemmaModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Gemma2Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Gemma3Model": {
    "model_arch": [],
    "norm_shift": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Gemma3VisionModel": {
    "set_gguf_parameters": [
      "self"
    ],
    "tensor_force_quant": [
      "self",
      "name",
      "new_name",
      "bid",
      "n_dims"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Gemma3NModel": {
    "model_arch": [],
    "norm_shift": [],
    "__init__": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "_stack_matrices": [
      "self",
      "matrices"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "StarCoder2Model": {
    "model_arch": []
  },
  "Rwkv6Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "RWKV6Qwen2Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Rwkv7Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "calc_lora_rank": [
      "self",
      "hidden_size",
      "exponent",
      "multiplier"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "ARwkv7Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "MambaModel": {
    "model_arch": [],
    "__init__": [
      "self",
      "dir_model"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "_tok_embd": [],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Mamba2Model": {
    "model_arch": [],
    "__init__": [
      "self",
      "dir_model"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "JambaModel": {
    "model_arch": [],
    "get_vocab_base_pre": [
      "self",
      "tokenizer"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "CommandR2Model": {
    "model_arch": [],
    "__init__": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "Cohere2Model": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "OlmoModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Olmo2Model": {
    "model_arch": []
  },
  "OlmoeModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "JinaBertV2Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ]
  },
  "OpenELMModel": {
    "model_arch": [],
    "_make_divisible": [
      "v",
      "divisor"
    ],
    "__init__": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "find_hparam": [
      "self",
      "keys",
      "optional"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "ArcticModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "DeepseekModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "permute": [
      "weights",
      "n_head",
      "n_head_kv"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "DeepseekV2Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "Dots1Model": {
    "model_arch": [],
    "__init__": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "PLMModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "T5Model": {
    "model_arch": [],
    "__init__": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "T5EncoderModel": {
    "model_arch": [],
    "__init__": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "JaisModel": {
    "model_arch": [],
    "__init__": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "Glm4Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "Glm4MoeModel": {
    "model_arch": [],
    "__init__": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "ChatGLMModel": {
    "model_arch": [],
    "set_vocab_chatglm3": [
      "self"
    ],
    "token_bytes_to_string": [
      "b"
    ],
    "bpe": [
      "mergeable_ranks",
      "token",
      "max_rank"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "NemotronModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "ExaoneModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "generate_extra_tensors": [
      "self"
    ]
  },
  "Exaone4Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "generate_extra_tensors": [
      "self"
    ]
  },
  "GraniteModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "GraniteMoeModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "GraniteHybridModel": {
    "model_arch": [],
    "undo_permute": [],
    "__init__": [
      "self"
    ],
    "get_attn_layers": [
      "self"
    ],
    "find_hparam": [
      "self",
      "keys"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "set_vocab": [
      "self"
    ]
  },
  "BailingMoeModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "permute": [
      "weights",
      "n_head",
      "n_head_kv"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "ChameleonModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "set_vocab": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "_reverse_hf_permute": [
      "data_torch",
      "n_heads",
      "hidden_dim"
    ]
  },
  "UltravoxModel": {
    "model_arch": [],
    "__init__": [
      "self"
    ]
  },
  "WhisperEncoderModel": {
    "has_vision_encoder": [],
    "has_audio_encoder": [],
    "__init__": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "tensor_force_quant": [
      "self",
      "name",
      "new_name",
      "bid",
      "n_dims"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "UltravoxWhisperEncoderModel": {
    "has_vision_encoder": [],
    "has_audio_encoder": [],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "VoxtralWhisperEncoderModel": {
    "has_vision_encoder": [],
    "has_audio_encoder": [],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "FalconH1Model": {
    "model_arch": [],
    "__init__": [
      "self"
    ],
    "find_hparam": [
      "self",
      "keys"
    ],
    "set_vocab": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "HunYuanMoEModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "HunYuanModel": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "SmolLM3Model": {
    "model_arch": [],
    "set_vocab": [
      "self"
    ]
  },
  "GptOssModel": {
    "model_arch": [],
    "transform_nibble_layout": [
      "self",
      "tensor"
    ],
    "repack_mxfp4": [
      "self",
      "new_name",
      "blocks",
      "scales"
    ],
    "generate_extra_tensors": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "set_vocab": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ]
  },
  "LFM2Model": {
    "model_arch": [],
    "_add_feed_forward_length": [
      "self"
    ],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ]
  },
  "SmallThinkerModel": {
    "model_arch": [],
    "set_gguf_parameters": [
      "self"
    ],
    "modify_tensors": [
      "self",
      "data_torch",
      "name",
      "bid"
    ],
    "prepare_tensors": [
      "self"
    ]
  },
  "MistralModel": {
    "model_arch": [],
    "model_name": [],
    "hf_arch": [],
    "is_mistral_format": [],
    "undo_permute": [],
    "get_community_chat_template": [
      "vocab",
      "templates_dir"
    ]
  },
  "PixtralModel": {
    "model_name": [],
    "hf_arch": [],
    "is_mistral_format": [],
    "set_gguf_parameters": [
      "self"
    ],
    "map_tensor_name": [
      "self",
      "name",
      "try_suffixes"
    ]
  },
  "LazyTorchTensor": {
    "_tensor_type": [],
    "numpy": [
      "self"
    ],
    "meta_with_dtype_and_shape": [
      "cls",
      "dtype",
      "shape"
    ],
    "from_safetensors_slice": [
      "cls",
      "st_slice"
    ],
    "from_remote_tensor": [
      "cls",
      "remote_tensor"
    ],
    "__torch_function__": [
      "cls",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "split_str_to_n_bytes": [
    "split_str"
  ],
  "get_model_architecture": [
    "hparams",
    "model_type"
  ],
  "LibLlama": {
    "DEFAULT_PATH_LLAMA_H": [],
    "DEFAULT_PATH_INCLUDES": [],
    "DEFAULT_PATH_LIBLLAMA": [],
    "__init__": [
      "self",
      "path_llama_h",
      "path_includes",
      "path_libllama"
    ],
    "_load_libllama_cffi": [
      "self",
      "path_llama_h",
      "path_includes",
      "path_libllama"
    ],
    "model_default_params": [
      "self"
    ],
    "context_default_params": [
      "self"
    ]
  },
  "LibLlamaModel": {
    "__init__": [
      "self",
      "libllama",
      "path_model",
      "mparams",
      "cparams"
    ],
    "free": [
      "self"
    ],
    "tokenize": [
      "self",
      "text",
      "add_special",
      "parse_special"
    ],
    "detokenize": [
      "self",
      "ids",
      "remove_special",
      "unparse_special"
    ]
  },
  "Tokenizer": {
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "ids"
    ]
  },
  "TokenizerGroundtruth": {
    "__init__": [
      "self",
      "dir_tokenizer"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "ids"
    ]
  },
  "TokenizerLlamaCpp": {
    "__init__": [
      "self",
      "vocab_file"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "ids"
    ]
  },
  "generator_custom_text": [],
  "generator_custom_text_edge_cases": [],
  "generator_vocab_words": [
    "tokenizer"
  ],
  "generator_ascii_lr_strip": [],
  "generator_apostrophe": [],
  "generator_added_lr_strip": [
    "tokenizer"
  ],
  "generator_random_added_tokens": [
    "tokenizer",
    "iterations"
  ],
  "generator_random_chars": [
    "iterations"
  ],
  "generator_unicodes": [],
  "generator_random_unicodes": [
    "iterations"
  ],
  "generator_random_vocab_chars": [
    "tokenizer",
    "iterations"
  ],
  "generator_random_vocab_words": [
    "tokenizer",
    "iterations"
  ],
  "compare_tokenizers": [
    "tokenizer1",
    "tokenizer2",
    "generator"
  ],
  "dir_tokenizer": [],
  "fname_tok": [],
  "tokenizer": [],
  "fname_out": [],
  "SHARD_NAME_FORMAT": [],
  "TensorInfo": {},
  "GGUFValue": {},
  "WriterState": {
    "NO_FILE": [],
    "EMPTY": [],
    "HEADER": [],
    "KV_DATA": [],
    "TI_DATA": [],
    "WEIGHTS": []
  },
  "GGUFWriter": {
    "_simple_value_packing": [],
    "__init__": [
      "self",
      "path",
      "arch",
      "use_temp_file",
      "endianess",
      "split_max_tensors",
      "split_max_size",
      "dry_run",
      "small_first_shard"
    ],
    "get_total_parameter_count": [
      "self"
    ],
    "format_shard_names": [
      "self",
      "path"
    ],
    "open_output_file": [
      "self",
      "path"
    ],
    "print_plan": [
      "self"
    ],
    "add_shard_kv_data": [
      "self"
    ],
    "write_header_to_file": [
      "self",
      "path"
    ],
    "write_kv_data_to_file": [
      "self"
    ],
    "write_ti_data_to_file": [
      "self"
    ],
    "add_key_value": [
      "self",
      "key",
      "val",
      "vtype",
      "sub_type"
    ],
    "add_uint8": [
      "self",
      "key",
      "val"
    ],
    "add_int8": [
      "self",
      "key",
      "val"
    ],
    "add_uint16": [
      "self",
      "key",
      "val"
    ],
    "add_int16": [
      "self",
      "key",
      "val"
    ],
    "add_uint32": [
      "self",
      "key",
      "val"
    ],
    "add_int32": [
      "self",
      "key",
      "val"
    ],
    "add_float32": [
      "self",
      "key",
      "val"
    ],
    "add_uint64": [
      "self",
      "key",
      "val"
    ],
    "add_int64": [
      "self",
      "key",
      "val"
    ],
    "add_float64": [
      "self",
      "key",
      "val"
    ],
    "add_bool": [
      "self",
      "key",
      "val"
    ],
    "add_string": [
      "self",
      "key",
      "val"
    ],
    "add_array": [
      "self",
      "key",
      "val"
    ],
    "ggml_pad": [
      "x",
      "n"
    ],
    "add_tensor_info": [
      "self",
      "name",
      "tensor_shape",
      "tensor_dtype",
      "tensor_nbytes",
      "raw_dtype"
    ],
    "add_tensor": [
      "self",
      "name",
      "tensor",
      "raw_shape",
      "raw_dtype"
    ],
    "write_padding": [
      "self",
      "fp",
      "n",
      "align"
    ],
    "write_tensor_data": [
      "self",
      "tensor"
    ],
    "write_tensors_to_file": [
      "self"
    ],
    "flush": [
      "self"
    ],
    "close": [
      "self"
    ],
    "add_type": [
      "self",
      "type_name"
    ],
    "add_architecture": [
      "self"
    ],
    "add_quantization_version": [
      "self",
      "quantization_version"
    ],
    "add_custom_alignment": [
      "self",
      "alignment"
    ],
    "add_file_type": [
      "self",
      "ftype"
    ],
    "add_name": [
      "self",
      "name"
    ],
    "add_author": [
      "self",
      "author"
    ],
    "add_version": [
      "self",
      "version"
    ],
    "add_organization": [
      "self",
      "organization"
    ],
    "add_finetune": [
      "self",
      "finetune"
    ],
    "add_basename": [
      "self",
      "basename"
    ],
    "add_description": [
      "self",
      "description"
    ],
    "add_quantized_by": [
      "self",
      "quantized"
    ],
    "add_size_label": [
      "self",
      "size_label"
    ],
    "add_license": [
      "self",
      "license"
    ],
    "add_license_name": [
      "self",
      "license"
    ],
    "add_license_link": [
      "self",
      "license"
    ],
    "add_url": [
      "self",
      "url"
    ],
    "add_doi": [
      "self",
      "doi"
    ],
    "add_uuid": [
      "self",
      "uuid"
    ],
    "add_repo_url": [
      "self",
      "repo_url"
    ],
    "add_source_url": [
      "self",
      "url"
    ],
    "add_source_doi": [
      "self",
      "doi"
    ],
    "add_source_uuid": [
      "self",
      "uuid"
    ],
    "add_source_repo_url": [
      "self",
      "repo_url"
    ],
    "add_base_model_count": [
      "self",
      "source_count"
    ],
    "add_base_model_name": [
      "self",
      "source_id",
      "name"
    ],
    "add_base_model_author": [
      "self",
      "source_id",
      "author"
    ],
    "add_base_model_version": [
      "self",
      "source_id",
      "version"
    ],
    "add_base_model_organization": [
      "self",
      "source_id",
      "organization"
    ],
    "add_base_model_description": [
      "self",
      "source_id",
      "description"
    ],
    "add_base_model_url": [
      "self",
      "source_id",
      "url"
    ],
    "add_base_model_doi": [
      "self",
      "source_id",
      "doi"
    ],
    "add_base_model_uuid": [
      "self",
      "source_id",
      "uuid"
    ],
    "add_base_model_repo_url": [
      "self",
      "source_id",
      "repo_url"
    ],
    "add_dataset_count": [
      "self",
      "source_count"
    ],
    "add_dataset_name": [
      "self",
      "source_id",
      "name"
    ],
    "add_dataset_author": [
      "self",
      "source_id",
      "author"
    ],
    "add_dataset_version": [
      "self",
      "source_id",
      "version"
    ],
    "add_dataset_organization": [
      "self",
      "source_id",
      "organization"
    ],
    "add_dataset_description": [
      "self",
      "source_id",
      "description"
    ],
    "add_dataset_url": [
      "self",
      "source_id",
      "url"
    ],
    "add_dataset_doi": [
      "self",
      "source_id",
      "doi"
    ],
    "add_dataset_uuid": [
      "self",
      "source_id",
      "uuid"
    ],
    "add_dataset_repo_url": [
      "self",
      "source_id",
      "repo_url"
    ],
    "add_tags": [
      "self",
      "tags"
    ],
    "add_languages": [
      "self",
      "languages"
    ],
    "add_tensor_data_layout": [
      "self",
      "layout"
    ],
    "add_vocab_size": [
      "self",
      "size"
    ],
    "add_context_length": [
      "self",
      "length"
    ],
    "add_embedding_length": [
      "self",
      "length"
    ],
    "add_features_length": [
      "self",
      "length"
    ],
    "add_posnet_embedding_length": [
      "self",
      "length"
    ],
    "add_posnet_block_count": [
      "self",
      "length"
    ],
    "add_convnext_embedding_length": [
      "self",
      "length"
    ],
    "add_convnext_block_count": [
      "self",
      "length"
    ],
    "add_shortconv_l_cache": [
      "self",
      "length"
    ],
    "add_block_count": [
      "self",
      "length"
    ],
    "add_leading_dense_block_count": [
      "self",
      "length"
    ],
    "add_feed_forward_length": [
      "self",
      "length"
    ],
    "add_expert_feed_forward_length": [
      "self",
      "length"
    ],
    "add_expert_shared_feed_forward_length": [
      "self",
      "length"
    ],
    "add_parallel_residual": [
      "self",
      "use"
    ],
    "add_decoder_start_token_id": [
      "self",
      "id"
    ],
    "add_embedding_length_per_layer_input": [
      "self",
      "value"
    ],
    "add_altup_active_idx": [
      "self",
      "val"
    ],
    "add_altup_num_inputs": [
      "self",
      "val"
    ],
    "add_activation_sparsity_scale": [
      "self",
      "values"
    ],
    "add_head_count": [
      "self",
      "count"
    ],
    "add_head_count_kv": [
      "self",
      "count"
    ],
    "add_key_length": [
      "self",
      "length"
    ],
    "add_value_length": [
      "self",
      "length"
    ],
    "add_key_length_mla": [
      "self",
      "length"
    ],
    "add_value_length_mla": [
      "self",
      "length"
    ],
    "add_max_alibi_bias": [
      "self",
      "bias"
    ],
    "add_clamp_kqv": [
      "self",
      "value"
    ],
    "add_shared_kv_layers": [
      "self",
      "value"
    ],
    "add_sliding_window_pattern": [
      "self",
      "value"
    ],
    "add_logit_scale": [
      "self",
      "value"
    ],
    "add_attn_logit_softcapping": [
      "self",
      "value"
    ],
    "add_final_logit_softcapping": [
      "self",
      "value"
    ],
    "add_expert_count": [
      "self",
      "count"
    ],
    "add_expert_used_count": [
      "self",
      "count"
    ],
    "add_expert_shared_count": [
      "self",
      "count"
    ],
    "add_expert_weights_scale": [
      "self",
      "value"
    ],
    "add_expert_weights_norm": [
      "self",
      "value"
    ],
    "add_expert_gating_func": [
      "self",
      "value"
    ],
    "add_moe_every_n_layers": [
      "self",
      "value"
    ],
    "add_nextn_predict_layers": [
      "self",
      "count"
    ],
    "add_swin_norm": [
      "self",
      "value"
    ],
    "add_rescale_every_n_layers": [
      "self",
      "count"
    ],
    "add_time_mix_extra_dim": [
      "self",
      "dim"
    ],
    "add_time_decay_extra_dim": [
      "self",
      "dim"
    ],
    "add_residual_scale": [
      "self",
      "value"
    ],
    "add_embedding_scale": [
      "self",
      "value"
    ],
    "add_wkv_head_size": [
      "self",
      "size"
    ],
    "add_token_shift_count": [
      "self",
      "count"
    ],
    "add_interleave_moe_layer_step": [
      "self",
      "value"
    ],
    "add_layer_norm_eps": [
      "self",
      "value"
    ],
    "add_layer_norm_rms_eps": [
      "self",
      "value"
    ],
    "add_group_norm_eps": [
      "self",
      "value"
    ],
    "add_group_norm_groups": [
      "self",
      "value"
    ],
    "add_causal_attention": [
      "self",
      "value"
    ],
    "add_q_lora_rank": [
      "self",
      "length"
    ],
    "add_kv_lora_rank": [
      "self",
      "length"
    ],
    "add_decay_lora_rank": [
      "self",
      "length"
    ],
    "add_iclr_lora_rank": [
      "self",
      "length"
    ],
    "add_value_residual_mix_lora_rank": [
      "self",
      "length"
    ],
    "add_gate_lora_rank": [
      "self",
      "length"
    ],
    "add_relative_attn_buckets_count": [
      "self",
      "value"
    ],
    "add_sliding_window": [
      "self",
      "value"
    ],
    "add_attention_scale": [
      "self",
      "value"
    ],
    "add_pooling_type": [
      "self",
      "value"
    ],
    "add_rope_dimension_count": [
      "self",
      "count"
    ],
    "add_rope_dimension_sections": [
      "self",
      "dims"
    ],
    "add_rope_freq_base": [
      "self",
      "value"
    ],
    "add_rope_scaling_type": [
      "self",
      "value"
    ],
    "add_rope_scaling_factor": [
      "self",
      "value"
    ],
    "add_rope_scaling_attn_factors": [
      "self",
      "value"
    ],
    "add_rope_scaling_orig_ctx_len": [
      "self",
      "value"
    ],
    "add_rope_scaling_finetuned": [
      "self",
      "value"
    ],
    "add_rope_scaling_yarn_log_mul": [
      "self",
      "value"
    ],
    "add_ssm_conv_kernel": [
      "self",
      "value"
    ],
    "add_ssm_inner_size": [
      "self",
      "value"
    ],
    "add_ssm_state_size": [
      "self",
      "value"
    ],
    "add_ssm_time_step_rank": [
      "self",
      "value"
    ],
    "add_ssm_group_count": [
      "self",
      "value"
    ],
    "add_ssm_dt_b_c_rms": [
      "self",
      "value"
    ],
    "add_tokenizer_model": [
      "self",
      "model"
    ],
    "add_tokenizer_pre": [
      "self",
      "pre"
    ],
    "add_token_list": [
      "self",
      "tokens"
    ],
    "add_token_merges": [
      "self",
      "merges"
    ],
    "add_token_types": [
      "self",
      "types"
    ],
    "add_token_type_count": [
      "self",
      "value"
    ],
    "add_token_scores": [
      "self",
      "scores"
    ],
    "add_bos_token_id": [
      "self",
      "id"
    ],
    "add_eos_token_id": [
      "self",
      "id"
    ],
    "add_unk_token_id": [
      "self",
      "id"
    ],
    "add_sep_token_id": [
      "self",
      "id"
    ],
    "add_pad_token_id": [
      "self",
      "id"
    ],
    "add_mask_token_id": [
      "self",
      "id"
    ],
    "add_add_bos_token": [
      "self",
      "value"
    ],
    "add_add_eos_token": [
      "self",
      "value"
    ],
    "add_add_sep_token": [
      "self",
      "value"
    ],
    "add_add_space_prefix": [
      "self",
      "value"
    ],
    "add_remove_extra_whitespaces": [
      "self",
      "value"
    ],
    "add_precompiled_charsmap": [
      "self",
      "charsmap"
    ],
    "add_chat_template": [
      "self",
      "value"
    ],
    "add_eot_token_id": [
      "self",
      "id"
    ],
    "add_eom_token_id": [
      "self",
      "id"
    ],
    "add_classifier_output_labels": [
      "self",
      "labels"
    ],
    "add_clip_has_vision_encoder": [
      "self",
      "value"
    ],
    "add_clip_has_audio_encoder": [
      "self",
      "value"
    ],
    "add_clip_projector_type": [
      "self",
      "value"
    ],
    "add_vision_projection_dim": [
      "self",
      "value"
    ],
    "add_vision_patch_size": [
      "self",
      "value"
    ],
    "add_vision_embedding_length": [
      "self",
      "value"
    ],
    "add_vision_feed_forward_length": [
      "self",
      "value"
    ],
    "add_vision_block_count": [
      "self",
      "value"
    ],
    "add_vision_head_count": [
      "self",
      "value"
    ],
    "add_vision_attention_layernorm_eps": [
      "self",
      "value"
    ],
    "add_vision_image_size": [
      "self",
      "value"
    ],
    "add_vision_image_mean": [
      "self",
      "values"
    ],
    "add_vision_image_std": [
      "self",
      "values"
    ],
    "add_vision_spatial_merge_size": [
      "self",
      "value"
    ],
    "add_vision_use_gelu": [
      "self",
      "value"
    ],
    "add_vision_use_silu": [
      "self",
      "value"
    ],
    "add_vision_projector_scale_factor": [
      "self",
      "value"
    ],
    "add_vision_n_wa_pattern": [
      "self",
      "value"
    ],
    "add_audio_projection_dim": [
      "self",
      "value"
    ],
    "add_audio_embedding_length": [
      "self",
      "value"
    ],
    "add_audio_feed_forward_length": [
      "self",
      "value"
    ],
    "add_audio_block_count": [
      "self",
      "value"
    ],
    "add_audio_head_count": [
      "self",
      "value"
    ],
    "add_audio_attention_layernorm_eps": [
      "self",
      "value"
    ],
    "add_audio_num_mel_bins": [
      "self",
      "value"
    ],
    "add_audio_stack_factor": [
      "self",
      "value"
    ],
    "add_diffusion_shift_logits": [
      "self",
      "value"
    ],
    "_pack": [
      "self",
      "fmt",
      "value",
      "skip_pack_prefix"
    ],
    "_pack_val": [
      "self",
      "val",
      "vtype",
      "add_vtype",
      "sub_type"
    ],
    "format_n_bytes_to_str": [
      "num"
    ]
  },
  "Metadata": {
    "load": [
      "metadata_override_path",
      "model_path",
      "model_name",
      "total_params"
    ],
    "load_metadata_override": [
      "metadata_override_path"
    ],
    "load_model_card": [
      "model_path"
    ],
    "load_hf_parameters": [
      "model_path"
    ],
    "id_to_title": [
      "string"
    ],
    "get_model_id_components": [
      "model_id",
      "total_params"
    ],
    "apply_metadata_heuristic": [
      "metadata",
      "model_card",
      "hf_params",
      "model_path",
      "total_params"
    ],
    "set_gguf_meta_model": [
      "self",
      "gguf_writer"
    ]
  },
  "READER_SUPPORTED_VERSIONS": [],
  "ReaderField": {
    "contents": [
      "self",
      "index_or_slice"
    ]
  },
  "ReaderTensor": {},
  "GGUFReader": {
    "__init__": [
      "self",
      "path",
      "mode"
    ],
    "_DT": [],
    "get_field": [
      "self",
      "key"
    ],
    "get_tensor": [
      "self",
      "idx"
    ],
    "_get": [
      "self",
      "offset",
      "dtype",
      "count",
      "override_order"
    ],
    "_push_field": [
      "self",
      "field",
      "skip_sum"
    ],
    "_get_str": [
      "self",
      "offset"
    ],
    "_get_field_parts": [
      "self",
      "orig_offs",
      "raw_type"
    ],
    "_get_tensor_info_field": [
      "self",
      "orig_offs"
    ],
    "_build_fields": [
      "self",
      "offs",
      "count"
    ],
    "_build_tensor_info": [
      "self",
      "offs",
      "count"
    ],
    "_build_tensors": [
      "self",
      "start_offs",
      "fields"
    ]
  },
  "fill_templated_filename": [
    "filename",
    "output_type"
  ],
  "model_weight_count_rounded_notation": [
    "model_params_count",
    "min_digits"
  ],
  "size_label": [
    "total_params",
    "shared_params",
    "expert_params",
    "expert_count"
  ],
  "naming_convention": [
    "model_name",
    "base_name",
    "finetune_string",
    "version_string",
    "size_label",
    "output_type",
    "model_type"
  ],
  "RemoteTensor": {
    "data": [
      "self"
    ]
  },
  "SafetensorRemote": {
    "BASE_DOMAIN": [],
    "ALIGNMENT": [],
    "get_list_tensors_hf_model": [
      "cls",
      "model_id"
    ],
    "get_list_tensors": [
      "cls",
      "url"
    ],
    "get_metadata": [
      "cls",
      "url"
    ],
    "get_data_by_range": [
      "cls",
      "url",
      "start",
      "size"
    ],
    "check_file_exist": [
      "cls",
      "url"
    ],
    "_get_request_headers": [
      "cls"
    ]
  },
  "quant_shape_to_byte_shape": [
    "shape",
    "quant_type"
  ],
  "quant_shape_from_byte_shape": [
    "shape",
    "quant_type"
  ],
  "_apply_over_grouped_rows": [
    "func",
    "arr",
    "otype",
    "oshape"
  ],
  "np_roundf": [
    "n"
  ],
  "QuantError": {},
  "quantize": [
    "data",
    "qtype"
  ],
  "dequantize": [
    "data",
    "qtype"
  ],
  "__Quant": {
    "__init__": [
      "self"
    ],
    "__init_subclass__": [
      "cls",
      "qtype"
    ],
    "init_grid": [
      "cls"
    ],
    "quantize_blocks": [
      "cls",
      "blocks"
    ],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ],
    "quantize_rows": [
      "cls",
      "rows"
    ],
    "dequantize_rows": [
      "cls",
      "rows"
    ],
    "__shape_to_bytes": [
      "cls",
      "shape"
    ],
    "__shape_from_bytes": [
      "cls",
      "shape"
    ],
    "__quantize_array": [
      "cls",
      "array"
    ],
    "__dequantize_array": [
      "cls",
      "array"
    ],
    "__quantize_lazy": [],
    "__dequantize_lazy": [],
    "can_quantize": [
      "cls",
      "tensor"
    ],
    "quantize": [
      "cls",
      "tensor"
    ],
    "dequantize": [
      "cls",
      "tensor"
    ]
  },
  "BF16": {
    "quantize_blocks": [
      "cls",
      "blocks"
    ],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "Q4_0": {
    "quantize_blocks": [
      "cls",
      "blocks"
    ],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "Q4_1": {
    "quantize_blocks": [
      "cls",
      "blocks"
    ],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "Q5_0": {
    "quantize_blocks": [
      "cls",
      "blocks"
    ],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "Q5_1": {
    "quantize_blocks": [
      "cls",
      "blocks"
    ],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "Q8_0": {
    "quantize_blocks": [
      "cls",
      "blocks"
    ],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "Q2_K": {
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "Q3_K": {
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "Q4_K": {
    "K_SCALE_SIZE": [],
    "get_scale_min": [
      "scales"
    ],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "Q5_K": {
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "Q6_K": {
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "TQ1_0": {
    "quantize_blocks": [
      "cls",
      "blocks"
    ],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "TQ2_0": {
    "quantize_blocks": [
      "cls",
      "blocks"
    ],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "MXFP4": {
    "kvalues": [],
    "e8m0_to_fp32_half": [
      "x"
    ],
    "quantize_blocks": [
      "cls",
      "blocks"
    ],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "IQ2_XXS": {
    "grid_shape": [],
    "grid_map": [],
    "grid_hex": [],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "IQ2_XS": {
    "grid_shape": [],
    "grid_map": [],
    "grid_hex": [],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "IQ2_S": {
    "grid_shape": [],
    "grid_map": [],
    "grid_hex": [],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "IQ3_XXS": {
    "grid_shape": [],
    "grid_map": [],
    "grid_hex": [],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "IQ3_S": {
    "grid_shape": [],
    "grid_map": [],
    "grid_hex": [],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "IQ1_S": {
    "grid_shape": [],
    "grid_map": [],
    "grid_hex": [],
    "delta": [],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "IQ1_M": {
    "grid_shape": [],
    "grid_map": [],
    "grid_hex": [],
    "delta": [],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "IQ4_NL": {
    "kvalues": [],
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "IQ4_XS": {
    "dequantize_blocks": [
      "cls",
      "blocks"
    ]
  },
  "SpecialVocab": {
    "__init__": [
      "self",
      "path",
      "load_merges",
      "special_token_types",
      "n_vocab"
    ],
    "__repr__": [
      "self"
    ],
    "add_to_gguf": [
      "self",
      "gw",
      "quiet"
    ],
    "_load": [
      "self",
      "path"
    ],
    "_try_load_merges_txt": [
      "self",
      "path"
    ],
    "_set_special_token": [
      "self",
      "typ",
      "tid"
    ],
    "_try_load_from_tokenizer_json": [
      "self",
      "path"
    ],
    "_try_load_from_config_json": [
      "self",
      "path"
    ]
  },
  "BaseVocab": {},
  "NoVocab": {
    "tokenizer_model": [],
    "name": [],
    "__repr__": [
      "self"
    ]
  },
  "BpeVocab": {
    "tokenizer_model": [],
    "name": [],
    "__init__": [
      "self",
      "base_path"
    ],
    "bpe_tokens": [
      "self"
    ],
    "added_tokens": [
      "self"
    ],
    "all_tokens": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SentencePieceVocab": {
    "tokenizer_model": [],
    "name": [],
    "__init__": [
      "self",
      "base_path"
    ],
    "sentencepiece_tokens": [
      "self"
    ],
    "added_tokens": [
      "self"
    ],
    "all_tokens": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "LlamaHfVocab": {
    "tokenizer_model": [],
    "name": [],
    "__init__": [
      "self",
      "base_path"
    ],
    "hf_tokens": [
      "self"
    ],
    "get_token_type": [
      "self",
      "token_id",
      "token_text",
      "special_ids"
    ],
    "get_token_score": [
      "self",
      "token_id"
    ],
    "added_tokens": [
      "self"
    ],
    "has_newline_token": [
      "self"
    ],
    "all_tokens": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "MistralTokenizerType": {
    "spm": [],
    "tekken": []
  },
  "bytes_to_unicode": [],
  "MistralVocab": {
    "tokenizer_model": [],
    "name": [],
    "__init__": [
      "self",
      "base_path"
    ],
    "tokenizer_name": [
      "self"
    ],
    "gguf_tokenizer_model": [
      "self"
    ],
    "_sentencepiece_tokens": [
      "self"
    ],
    "_tekken_tokens": [
      "self"
    ],
    "get_token_id": [
      "self",
      "token"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "pad_id": [
      "self"
    ],
    "unk_id": [
      "self"
    ],
    "bos_token": [
      "self"
    ],
    "eos_token": [
      "self"
    ],
    "pad_token": [
      "self"
    ],
    "unk_token": [
      "self"
    ],
    "all_tokens": [
      "self"
    ],
    "token_bytes_to_string": [
      "b",
      "byte_encoder"
    ],
    "extract_vocab_merges_from_model": [
      "self"
    ]
  },
  "TensorNameMap": {
    "__init__": [
      "self",
      "arch",
      "n_blocks"
    ],
    "get_type_and_name": [
      "self",
      "key",
      "try_suffixes"
    ],
    "get_name": [
      "self",
      "key",
      "try_suffixes"
    ],
    "get_type": [
      "self",
      "key",
      "try_suffixes"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "__repr__": [
      "self"
    ]
  },
  "get_tensor_name_map": [
    "arch",
    "n_blocks"
  ],
  "GGUF_MAGIC": [],
  "GGUF_VERSION": [],
  "GGUF_DEFAULT_ALIGNMENT": [],
  "GGML_QUANT_VERSION": [],
  "Keys": {},
  "GGUFType": {
    "MODEL": [],
    "ADAPTER": [],
    "IMATRIX": [],
    "MMPROJ": []
  },
  "MODEL_ARCH": {
    "MMPROJ": [],
    "LLAMA": [],
    "LLAMA4": [],
    "DECI": [],
    "FALCON": [],
    "FALCON_H1": [],
    "BAICHUAN": [],
    "GROK": [],
    "GPT2": [],
    "GPTJ": [],
    "GPTNEOX": [],
    "MPT": [],
    "STARCODER": [],
    "REFACT": [],
    "BERT": [],
    "NOMIC_BERT": [],
    "NOMIC_BERT_MOE": [],
    "NEO_BERT": [],
    "JINA_BERT_V2": [],
    "BLOOM": [],
    "STABLELM": [],
    "QWEN": [],
    "QWEN2": [],
    "QWEN2MOE": [],
    "QWEN2VL": [],
    "QWEN3": [],
    "QWEN3MOE": [],
    "PHI2": [],
    "PHI3": [],
    "PHIMOE": [],
    "PLAMO": [],
    "PLAMO2": [],
    "CODESHELL": [],
    "ORION": [],
    "INTERNLM2": [],
    "MINICPM": [],
    "MINICPM3": [],
    "GEMMA": [],
    "GEMMA2": [],
    "GEMMA3": [],
    "GEMMA3N": [],
    "STARCODER2": [],
    "RWKV6": [],
    "RWKV6QWEN2": [],
    "RWKV7": [],
    "ARWKV7": [],
    "MAMBA": [],
    "MAMBA2": [],
    "JAMBA": [],
    "XVERSE": [],
    "COMMAND_R": [],
    "COHERE2": [],
    "DBRX": [],
    "OLMO": [],
    "OLMO2": [],
    "OLMOE": [],
    "OPENELM": [],
    "ARCTIC": [],
    "DEEPSEEK": [],
    "DEEPSEEK2": [],
    "CHATGLM": [],
    "GLM4": [],
    "GLM4_MOE": [],
    "BITNET": [],
    "T5": [],
    "T5ENCODER": [],
    "JAIS": [],
    "NEMOTRON": [],
    "EXAONE": [],
    "EXAONE4": [],
    "GRANITE": [],
    "GRANITE_MOE": [],
    "GRANITE_HYBRID": [],
    "CHAMELEON": [],
    "WAVTOKENIZER_DEC": [],
    "PLM": [],
    "BAILINGMOE": [],
    "DOTS1": [],
    "ARCEE": [],
    "ERNIE4_5": [],
    "ERNIE4_5_MOE": [],
    "HUNYUAN_MOE": [],
    "HUNYUAN_DENSE": [],
    "SMOLLM3": [],
    "GPT_OSS": [],
    "LFM2": [],
    "DREAM": [],
    "SMALLTHINKER": [],
    "LLADA": []
  },
  "VISION_PROJECTOR_TYPE": {
    "MLP": [],
    "LDP": [],
    "LDPV2": [],
    "RESAMPLER": [],
    "GLM_EDGE": [],
    "MERGER": [],
    "GEMMA3": []
  },
  "MODEL_TENSOR": {
    "TOKEN_EMBD": [],
    "TOKEN_EMBD_NORM": [],
    "TOKEN_TYPES": [],
    "POS_EMBD": [],
    "OUTPUT": [],
    "OUTPUT_NORM": [],
    "ROPE_FREQS": [],
    "ROPE_FACTORS_LONG": [],
    "ROPE_FACTORS_SHORT": [],
    "ATTN_Q": [],
    "ATTN_K": [],
    "ATTN_V": [],
    "ATTN_QKV": [],
    "ATTN_OUT": [],
    "ATTN_NORM": [],
    "ATTN_NORM_2": [],
    "ATTN_OUT_NORM": [],
    "ATTN_POST_NORM": [],
    "ATTN_ROT_EMBD": [],
    "ATTN_SINKS": [],
    "FFN_GATE_INP": [],
    "FFN_GATE_INP_SHEXP": [],
    "FFN_NORM": [],
    "FFN_PRE_NORM": [],
    "FFN_POST_NORM": [],
    "FFN_GATE": [],
    "FFN_DOWN": [],
    "FFN_UP": [],
    "FFN_ACT": [],
    "FFN_NORM_EXP": [],
    "FFN_GATE_EXP": [],
    "FFN_DOWN_EXP": [],
    "FFN_UP_EXP": [],
    "FFN_GATE_SHEXP": [],
    "FFN_DOWN_SHEXP": [],
    "FFN_UP_SHEXP": [],
    "FFN_EXP_PROBS_B": [],
    "ATTN_Q_NORM": [],
    "ATTN_K_NORM": [],
    "LAYER_OUT_NORM": [],
    "PER_LAYER_TOKEN_EMBD": [],
    "PER_LAYER_MODEL_PROJ": [],
    "PER_LAYER_INP_GATE": [],
    "PER_LAYER_PROJ": [],
    "PER_LAYER_PROJ_NORM": [],
    "PER_LAYER_POST_NORM": [],
    "ALTUP_PROJ": [],
    "ALTUP_UNEMBD_PROJ": [],
    "ALTUP_CORRECT_COEF": [],
    "ALTUP_CORRECT_SCALE": [],
    "ALTUP_PREDICT_COEF": [],
    "ALTUP_ROUTER": [],
    "ALTUP_ROUTER_NORM": [],
    "LAUREL_L": [],
    "LAUREL_R": [],
    "LAUREL_POST_NORM": [],
    "SSM_IN": [],
    "SSM_CONV1D": [],
    "SSM_X": [],
    "SSM_DT": [],
    "SSM_DT_NORM": [],
    "SSM_A": [],
    "SSM_B_NORM": [],
    "SSM_C_NORM": [],
    "SSM_D": [],
    "SSM_NORM": [],
    "SSM_OUT": [],
    "TIME_MIX_W0": [],
    "TIME_MIX_W1": [],
    "TIME_MIX_W2": [],
    "TIME_MIX_A0": [],
    "TIME_MIX_A1": [],
    "TIME_MIX_A2": [],
    "TIME_MIX_V0": [],
    "TIME_MIX_V1": [],
    "TIME_MIX_V2": [],
    "TIME_MIX_G1": [],
    "TIME_MIX_G2": [],
    "TIME_MIX_K_K": [],
    "TIME_MIX_K_A": [],
    "TIME_MIX_R_K": [],
    "TIME_MIX_LERP_X": [],
    "TIME_MIX_LERP_K": [],
    "TIME_MIX_LERP_V": [],
    "TIME_MIX_LERP_R": [],
    "TIME_MIX_LERP_G": [],
    "TIME_MIX_LERP_FUSED": [],
    "TIME_MIX_LERP_W": [],
    "TIME_MIX_FIRST": [],
    "TIME_MIX_DECAY": [],
    "TIME_MIX_DECAY_W1": [],
    "TIME_MIX_DECAY_W2": [],
    "TIME_MIX_KEY": [],
    "TIME_MIX_VALUE": [],
    "TIME_MIX_RECEPTANCE": [],
    "TIME_MIX_GATE": [],
    "TIME_MIX_LN": [],
    "TIME_MIX_OUTPUT": [],
    "CHANNEL_MIX_LERP_K": [],
    "CHANNEL_MIX_LERP_R": [],
    "CHANNEL_MIX_KEY": [],
    "CHANNEL_MIX_RECEPTANCE": [],
    "CHANNEL_MIX_VALUE": [],
    "ATTN_Q_A": [],
    "ATTN_Q_B": [],
    "ATTN_KV_A_MQA": [],
    "ATTN_KV_B": [],
    "ATTN_K_B": [],
    "ATTN_V_B": [],
    "ATTN_Q_A_NORM": [],
    "ATTN_KV_A_NORM": [],
    "FFN_SUB_NORM": [],
    "ATTN_SUB_NORM": [],
    "DEC_ATTN_NORM": [],
    "DEC_ATTN_Q": [],
    "DEC_ATTN_K": [],
    "DEC_ATTN_V": [],
    "DEC_ATTN_OUT": [],
    "DEC_ATTN_REL_B": [],
    "DEC_CROSS_ATTN_NORM": [],
    "DEC_CROSS_ATTN_Q": [],
    "DEC_CROSS_ATTN_K": [],
    "DEC_CROSS_ATTN_V": [],
    "DEC_CROSS_ATTN_OUT": [],
    "DEC_CROSS_ATTN_REL_B": [],
    "DEC_FFN_NORM": [],
    "DEC_FFN_GATE": [],
    "DEC_FFN_DOWN": [],
    "DEC_FFN_UP": [],
    "DEC_OUTPUT_NORM": [],
    "ENC_ATTN_NORM": [],
    "ENC_ATTN_Q": [],
    "ENC_ATTN_K": [],
    "ENC_ATTN_V": [],
    "ENC_ATTN_OUT": [],
    "ENC_ATTN_REL_B": [],
    "ENC_FFN_NORM": [],
    "ENC_FFN_GATE": [],
    "ENC_FFN_DOWN": [],
    "ENC_FFN_UP": [],
    "ENC_OUTPUT_NORM": [],
    "CLS": [],
    "CLS_OUT": [],
    "CONV1D": [],
    "CONVNEXT_DW": [],
    "CONVNEXT_NORM": [],
    "CONVNEXT_PW1": [],
    "CONVNEXT_PW2": [],
    "CONVNEXT_GAMMA": [],
    "POSNET_CONV1": [],
    "POSNET_CONV2": [],
    "POSNET_NORM": [],
    "POSNET_NORM1": [],
    "POSNET_NORM2": [],
    "POSNET_ATTN_NORM": [],
    "POSNET_ATTN_Q": [],
    "POSNET_ATTN_K": [],
    "POSNET_ATTN_V": [],
    "POSNET_ATTN_OUT": [],
    "SHORTCONV_CONV": [],
    "SHORTCONV_INPROJ": [],
    "SHORTCONV_OUTPROJ": [],
    "V_MMPROJ": [],
    "V_MMPROJ_FC": [],
    "V_MMPROJ_MLP": [],
    "V_MMPROJ_PEG": [],
    "V_ENC_EMBD_CLS": [],
    "V_ENC_EMBD_PATCH": [],
    "V_ENC_EMBD_POS": [],
    "V_ENC_INPUT_NORM": [],
    "V_ENC_ATTN_Q": [],
    "V_ENC_ATTN_Q_NORM": [],
    "V_ENC_ATTN_K": [],
    "V_ENC_ATTN_K_NORM": [],
    "V_ENC_ATTN_V": [],
    "V_ENC_ATTN_O": [],
    "V_ENC_ATTN_O_NORM": [],
    "V_ENC_POST_ATTN_NORM": [],
    "V_ENC_FFN_UP": [],
    "V_ENC_FFN_GATE": [],
    "V_ENC_FFN_DOWN": [],
    "V_LAYER_SCALE_1": [],
    "V_LAYER_SCALE_2": [],
    "V_PRE_NORM": [],
    "V_POST_NORM": [],
    "V_MM_INP_NORM": [],
    "V_MM_INP_PROJ": [],
    "V_MM_SOFT_EMB_NORM": [],
    "V_RESMPL_POS_EMBD_K": [],
    "V_RESMPL_ATTN_Q": [],
    "V_RESMPL_ATTN_K": [],
    "V_RESMPL_ATTN_V": [],
    "V_RESMPL_ATTN_OUT": [],
    "V_RESMPL_KV": [],
    "V_RESMPL_KV_NORM": [],
    "V_RESMPL_POST_NORM": [],
    "V_RESMPL_Q_NORM": [],
    "V_RESMPL_PROJ": [],
    "V_RESMPL_QUERY": [],
    "V_TOK_EMBD_IMG_BREAK": [],
    "V_MM_PATCH_MERGER": [],
    "A_ENC_EMBD_POS": [],
    "A_ENC_CONV1D": [],
    "A_PRE_NORM": [],
    "A_POST_NORM": [],
    "A_ENC_ATTN_Q": [],
    "A_ENC_ATTN_K": [],
    "A_ENC_ATTN_V": [],
    "A_ENC_INPUT_NORM": [],
    "A_ENC_OUTPUT": [],
    "A_ENC_OUTPUT_NORM": [],
    "A_ENC_FFN_UP": [],
    "A_ENC_FFN_GATE": [],
    "A_ENC_FFN_DOWN": [],
    "A_MMPROJ": [],
    "A_MMPROJ_FC": [],
    "A_MM_NORM_PRE": [],
    "A_MM_NORM_MID": [],
    "NEXTN_EH_PROJ": [],
    "NEXTN_EMBED_TOKENS": [],
    "NEXTN_ENORM": [],
    "NEXTN_HNORM": [],
    "NEXTN_SHARED_HEAD_HEAD": [],
    "NEXTN_SHARED_HEAD_NORM": []
  },
  "TokenType": {
    "NORMAL": [],
    "UNKNOWN": [],
    "CONTROL": [],
    "USER_DEFINED": [],
    "UNUSED": [],
    "BYTE": []
  },
  "RopeScalingType": {
    "NONE": [],
    "LINEAR": [],
    "YARN": [],
    "LONGROPE": []
  },
  "PoolingType": {
    "NONE": [],
    "MEAN": [],
    "CLS": [],
    "LAST": [],
    "RANK": []
  },
  "GGMLQuantizationType": {
    "F32": [],
    "F16": [],
    "Q4_0": [],
    "Q4_1": [],
    "Q5_0": [],
    "Q5_1": [],
    "Q8_0": [],
    "Q8_1": [],
    "Q2_K": [],
    "Q3_K": [],
    "Q4_K": [],
    "Q5_K": [],
    "Q6_K": [],
    "Q8_K": [],
    "IQ2_XXS": [],
    "IQ2_XS": [],
    "IQ3_XXS": [],
    "IQ1_S": [],
    "IQ4_NL": [],
    "IQ3_S": [],
    "IQ2_S": [],
    "IQ4_XS": [],
    "I8": [],
    "I16": [],
    "I32": [],
    "I64": [],
    "F64": [],
    "IQ1_M": [],
    "BF16": [],
    "TQ1_0": [],
    "TQ2_0": [],
    "MXFP4": []
  },
  "ExpertGatingFuncType": {
    "SOFTMAX": [],
    "SIGMOID": []
  },
  "LlamaFileType": {
    "ALL_F32": [],
    "MOSTLY_F16": [],
    "MOSTLY_Q4_0": [],
    "MOSTLY_Q4_1": [],
    "MOSTLY_Q8_0": [],
    "MOSTLY_Q5_0": [],
    "MOSTLY_Q5_1": [],
    "MOSTLY_Q2_K": [],
    "MOSTLY_Q3_K_S": [],
    "MOSTLY_Q3_K_M": [],
    "MOSTLY_Q3_K_L": [],
    "MOSTLY_Q4_K_S": [],
    "MOSTLY_Q4_K_M": [],
    "MOSTLY_Q5_K_S": [],
    "MOSTLY_Q5_K_M": [],
    "MOSTLY_Q6_K": [],
    "MOSTLY_IQ2_XXS": [],
    "MOSTLY_IQ2_XS": [],
    "MOSTLY_Q2_K_S": [],
    "MOSTLY_IQ3_XS": [],
    "MOSTLY_IQ3_XXS": [],
    "MOSTLY_IQ1_S": [],
    "MOSTLY_IQ4_NL": [],
    "MOSTLY_IQ3_S": [],
    "MOSTLY_IQ3_M": [],
    "MOSTLY_IQ2_S": [],
    "MOSTLY_IQ2_M": [],
    "MOSTLY_IQ4_XS": [],
    "MOSTLY_IQ1_M": [],
    "MOSTLY_BF16": [],
    "MOSTLY_TQ1_0": [],
    "MOSTLY_TQ2_0": [],
    "GUESSED": []
  },
  "GGUFEndian": {
    "LITTLE": [],
    "BIG": []
  },
  "GGUFValueType": {
    "UINT8": [],
    "INT8": [],
    "UINT16": [],
    "INT16": [],
    "UINT32": [],
    "INT32": [],
    "FLOAT32": [],
    "BOOL": [],
    "STRING": [],
    "ARRAY": [],
    "UINT64": [],
    "INT64": [],
    "FLOAT64": [],
    "get_type": [
      "val"
    ]
  },
  "VisionProjectorType": {
    "GEMMA3": [],
    "IDEFICS3": [],
    "PIXTRAL": [],
    "LLAMA4": [],
    "QWEN2VL": [],
    "QWEN25VL": [],
    "ULTRAVOX": [],
    "INTERNVL": [],
    "QWEN2A": [],
    "QWEN25O": [],
    "VOXTRAL": []
  },
  "QK_K": [],
  "KEY_GENERAL_ARCHITECTURE": [],
  "KEY_GENERAL_QUANTIZATION_VERSION": [],
  "KEY_GENERAL_ALIGNMENT": [],
  "KEY_GENERAL_NAME": [],
  "KEY_GENERAL_AUTHOR": [],
  "KEY_GENERAL_URL": [],
  "KEY_GENERAL_DESCRIPTION": [],
  "KEY_GENERAL_LICENSE": [],
  "KEY_GENERAL_SOURCE_URL": [],
  "KEY_GENERAL_FILE_TYPE": [],
  "KEY_VOCAB_SIZE": [],
  "KEY_CONTEXT_LENGTH": [],
  "KEY_EMBEDDING_LENGTH": [],
  "KEY_BLOCK_COUNT": [],
  "KEY_FEED_FORWARD_LENGTH": [],
  "KEY_USE_PARALLEL_RESIDUAL": [],
  "KEY_TENSOR_DATA_LAYOUT": [],
  "KEY_ATTENTION_HEAD_COUNT": [],
  "KEY_ATTENTION_HEAD_COUNT_KV": [],
  "KEY_ATTENTION_MAX_ALIBI_BIAS": [],
  "KEY_ATTENTION_CLAMP_KQV": [],
  "KEY_ATTENTION_LAYERNORM_EPS": [],
  "KEY_ATTENTION_LAYERNORM_RMS_EPS": [],
  "KEY_ROPE_DIMENSION_COUNT": [],
  "KEY_ROPE_FREQ_BASE": [],
  "KEY_ROPE_SCALING_TYPE": [],
  "KEY_ROPE_SCALING_FACTOR": [],
  "KEY_ROPE_SCALING_ORIG_CTX_LEN": [],
  "KEY_ROPE_SCALING_FINETUNED": [],
  "KEY_SSM_CONV_KERNEL": [],
  "KEY_SSM_INNER_SIZE": [],
  "KEY_SSM_STATE_SIZE": [],
  "KEY_SSM_TIME_STEP_RANK": [],
  "KEY_SSM_GROUP_COUNT": [],
  "KEY_SSM_DT_B_C_RMS": [],
  "KEY_TOKENIZER_MODEL": [],
  "KEY_TOKENIZER_PRE": [],
  "KEY_TOKENIZER_LIST": [],
  "KEY_TOKENIZER_TOKEN_TYPE": [],
  "KEY_TOKENIZER_SCORES": [],
  "KEY_TOKENIZER_MERGES": [],
  "KEY_TOKENIZER_BOS_ID": [],
  "KEY_TOKENIZER_EOS_ID": [],
  "KEY_TOKENIZER_EOT_ID": [],
  "KEY_TOKENIZER_EOM_ID": [],
  "KEY_TOKENIZER_UNK_ID": [],
  "KEY_TOKENIZER_SEP_ID": [],
  "KEY_TOKENIZER_PAD_ID": [],
  "KEY_TOKENIZER_MASK_ID": [],
  "KEY_TOKENIZER_HF_JSON": [],
  "KEY_TOKENIZER_RWKV": [],
  "KEY_TOKENIZER_FIM_PRE_ID": [],
  "KEY_TOKENIZER_FIM_SUF_ID": [],
  "KEY_TOKENIZER_FIM_MID_ID": [],
  "KEY_TOKENIZER_FIM_PAD_ID": [],
  "KEY_TOKENIZER_FIM_REP_ID": [],
  "KEY_TOKENIZER_FIM_SEP_ID": [],
  "KEY_TOKENIZER_PREFIX_ID": [],
  "KEY_TOKENIZER_SUFFIX_ID": [],
  "KEY_TOKENIZER_MIDDLE_ID": [],
  "LazyMeta": {
    "__new__": [
      "cls",
      "name",
      "bases",
      "namespace"
    ]
  },
  "LazyBase": {
    "__init__": [
      "self"
    ],
    "__init_subclass__": [
      "cls"
    ],
    "_recurse_apply": [
      "o",
      "fn"
    ],
    "_wrap_fn": [
      "cls",
      "fn"
    ],
    "to_eager": [
      "cls",
      "t"
    ],
    "eager_to_meta": [
      "cls",
      "t"
    ],
    "meta_with_dtype_and_shape": [
      "cls",
      "dtype",
      "shape"
    ],
    "from_eager": [
      "cls",
      "t"
    ]
  },
  "LazyNumpyTensor": {
    "_tensor_type": [],
    "meta_with_dtype_and_shape": [
      "cls",
      "dtype",
      "shape"
    ],
    "astype": [
      "self",
      "dtype"
    ],
    "tofile": [
      "self"
    ]
  },
  "UUID_NAMESPACE_LLAMA_CPP": [],
  "gguf_hash": [
    "reader",
    "filename",
    "disable_progress_bar",
    "no_layer"
  ],
  "KEY_TO_ENUM_TYPE": [],
  "TOKENIZER_LINKED_KEYS": [],
  "TokenizerEditorDialog": {
    "__init__": [
      "self",
      "tokens",
      "token_types",
      "scores",
      "parent"
    ],
    "apply_filter": [
      "self"
    ],
    "previous_page": [
      "self"
    ],
    "next_page": [
      "self"
    ],
    "load_page": [
      "self"
    ],
    "handle_cell_double_click": [
      "self",
      "row",
      "column"
    ],
    "edit_token_type": [
      "self",
      "row",
      "orig_idx"
    ],
    "add_token": [
      "self"
    ],
    "remove_selected": [
      "self"
    ],
    "get_data": [
      "self"
    ]
  },
  "ArrayEditorDialog": {
    "__init__": [
      "self",
      "array_values",
      "element_type",
      "key",
      "parent"
    ],
    "apply_filter": [
      "self"
    ],
    "previous_page": [
      "self"
    ],
    "next_page": [
      "self"
    ],
    "load_page": [
      "self"
    ],
    "edit_array_enum_value": [
      "self"
    ],
    "bulk_edit_selected": [
      "self"
    ],
    "add_item": [
      "self"
    ],
    "remove_selected": [
      "self"
    ],
    "edit_enum_value": [
      "self",
      "row",
      "enum_type"
    ],
    "get_array_values": [
      "self"
    ]
  },
  "AddMetadataDialog": {
    "__init__": [
      "self",
      "parent"
    ],
    "get_data": [
      "self"
    ]
  },
  "GGUFEditorWindow": {
    "__init__": [
      "self"
    ],
    "setup_ui": [
      "self"
    ],
    "load_file": [
      "self",
      "file_path"
    ],
    "open_file": [
      "self"
    ],
    "load_metadata": [
      "self"
    ],
    "extract_array_values": [
      "self",
      "field"
    ],
    "get_enum_for_key": [
      "self",
      "key"
    ],
    "format_enum_value": [
      "self",
      "value",
      "enum_type"
    ],
    "format_field_value": [
      "self",
      "field"
    ],
    "load_tensors": [
      "self"
    ],
    "on_metadata_changed": [
      "self",
      "item"
    ],
    "remove_metadata": [
      "self"
    ],
    "edit_metadata_enum": [
      "self"
    ],
    "edit_array_metadata": [
      "self"
    ],
    "edit_tokenizer_metadata": [
      "self",
      "trigger_key"
    ],
    "update_tokenizer_display": [
      "self",
      "key",
      "values"
    ],
    "add_metadata": [
      "self"
    ],
    "save_file": [
      "self"
    ]
  },
  "convert_byteorder": [
    "reader",
    "args"
  ],
  "MetadataDetails": {},
  "get_field_data": [
    "reader",
    "key"
  ],
  "find_token": [
    "token_list",
    "token"
  ],
  "copy_with_new_metadata": [
    "reader",
    "writer",
    "new_metadata",
    "remove_metadata"
  ],
  "minimal_example": [
    "filename"
  ],
  "set_metadata": [
    "reader",
    "args"
  ],
  "get_file_host_endian": [
    "reader"
  ],
  "dump_metadata": [
    "reader",
    "args"
  ],
  "dump_metadata_json": [
    "reader",
    "args"
  ],
  "markdown_table_with_alignment_support": [
    "header_map",
    "data"
  ],
  "element_count_rounded_notation": [
    "count"
  ],
  "translate_tensor_name": [
    "name"
  ],
  "dump_markdown_metadata": [
    "reader",
    "args"
  ],
  "TestMetadataMethod": {
    "test_id_to_title": [
      "self"
    ],
    "test_get_model_id_components": [
      "self"
    ],
    "test_apply_metadata_heuristic_from_model_card": [
      "self"
    ],
    "test_apply_metadata_heuristic_from_hf_parameters": [
      "self"
    ],
    "test_apply_metadata_heuristic_from_model_dir": [
      "self"
    ]
  },
  "c_float_p": [],
  "ggml_init_params": {
    "_fields_": []
  },
  "GGMLQuants": {
    "__init__": [
      "self",
      "libggml"
    ],
    "dequantize": [
      "self",
      "tensor",
      "qtype"
    ],
    "quantize": [
      "self",
      "data",
      "qtype"
    ]
  },
  "compare_tensors": [
    "t1",
    "t2",
    "qtype"
  ],
  "do_test": [
    "libggml_path",
    "quick",
    "user_type"
  ],
  "writer_example": [],
  "read_gguf_file": [
    "gguf_file_path"
  ],
  "escape_triple_quotes": [
    "wgsl"
  ],
  "to_cpp_string_literal": [
    "varname",
    "content"
  ],
  "TYPES_KV": [],
  "SOURCE_FATTN_VEC": [],
  "SOURCE_FATTN_MMA_START": [],
  "SOURCE_FATTN_MMA_CASE": [],
  "TYPES_MMQ": [],
  "SOURCE_MMQ": [],
  "get_short_name": [
    "long_quant_name"
  ],
  "get_head_sizes": [
    "type_k",
    "type_v"
  ],
  "sha256sum": [
    "file"
  ],
  "llama_path": [],
  "hash_list_file": [],
  "results": [],
  "get_chat_template": [
    "model_id",
    "variant"
  ],
  "vendor": [],
  "LLAMA_BENCH_DB_FIELDS": [],
  "LLAMA_BENCH_DB_TYPES": [],
  "TEST_BACKEND_OPS_DB_FIELDS": [],
  "TEST_BACKEND_OPS_DB_TYPES": [],
  "LLAMA_BENCH_KEY_PROPERTIES": [],
  "TEST_BACKEND_OPS_KEY_PROPERTIES": [],
  "LLAMA_BENCH_BOOL_PROPERTIES": [],
  "TEST_BACKEND_OPS_BOOL_PROPERTIES": [],
  "LLAMA_BENCH_PRETTY_NAMES": [],
  "TEST_BACKEND_OPS_PRETTY_NAMES": [],
  "DEFAULT_SHOW_LLAMA_BENCH": [],
  "DEFAULT_HIDE_LLAMA_BENCH": [],
  "DEFAULT_SHOW_TEST_BACKEND_OPS": [],
  "DEFAULT_HIDE_TEST_BACKEND_OPS": [],
  "GPU_NAME_STRIP": [],
  "MODEL_SUFFIX_REPLACE": [],
  "DESCRIPTION": [],
  "help_b": [],
  "help_c": [],
  "help_t": [],
  "help_i": [],
  "help_o": [],
  "help_s": [],
  "input_file": [],
  "tool": [],
  "LlamaBenchData": {
    "__init__": [
      "self",
      "tool"
    ],
    "_builds_init": [
      "self"
    ],
    "_check_keys": [
      "self",
      "keys"
    ],
    "find_parent_in_data": [
      "self",
      "commit"
    ],
    "get_all_parent_hexsha8s": [
      "self",
      "commit"
    ],
    "get_commit_name": [
      "self",
      "hexsha8"
    ],
    "get_commit_hexsha8": [
      "self",
      "name"
    ],
    "builds_timestamp": [
      "self",
      "reverse"
    ],
    "get_rows": [
      "self",
      "properties",
      "hexsha8_baseline",
      "hexsha8_compare"
    ]
  },
  "LlamaBenchDataSQLite3": {
    "__init__": [
      "self",
      "tool"
    ],
    "_builds_init": [
      "self"
    ],
    "builds_timestamp": [
      "self",
      "reverse"
    ],
    "get_rows": [
      "self",
      "properties",
      "hexsha8_baseline",
      "hexsha8_compare"
    ],
    "_get_rows_llama_bench": [
      "self",
      "properties",
      "hexsha8_baseline",
      "hexsha8_compare"
    ],
    "_get_rows_test_backend_ops": [
      "self",
      "properties",
      "hexsha8_baseline",
      "hexsha8_compare"
    ]
  },
  "LlamaBenchDataSQLite3File": {
    "__init__": [
      "self",
      "data_file",
      "tool"
    ],
    "valid_format": [
      "data_file"
    ]
  },
  "LlamaBenchDataJSONL": {
    "__init__": [
      "self",
      "data_file",
      "tool"
    ],
    "valid_format": [
      "data_file"
    ]
  },
  "LlamaBenchDataJSON": {
    "__init__": [
      "self",
      "data_files",
      "tool"
    ],
    "valid_format": [
      "data_files"
    ]
  },
  "LlamaBenchDataCSV": {
    "__init__": [
      "self",
      "data_files",
      "tool"
    ],
    "valid_format": [
      "data_files"
    ]
  },
  "format_flops": [
    "flops_value"
  ],
  "format_flops_for_table": [
    "flops_value",
    "target_unit"
  ],
  "get_flops_unit_name": [
    "flops_values"
  ],
  "bench_data": [],
  "hexsha8_baseline": [],
  "name_baseline": [],
  "hexsha8_compare": [],
  "name_compare": [],
  "table": [],
  "primary_metric": [],
  "headers": [],
  "HuggingFaceModel": {},
  "collect_hf_model_test_parameters": [
    "test_file"
  ],
  "MAX_CODEPOINTS": [],
  "UNICODE_DATA_URL": [],
  "unicode_data_iter": [],
  "CODEPOINT_FLAG_UNDEFINED": [],
  "CODEPOINT_FLAG_NUMBER": [],
  "CODEPOINT_FLAG_LETTER": [],
  "CODEPOINT_FLAG_SEPARATOR": [],
  "CODEPOINT_FLAG_MARK": [],
  "CODEPOINT_FLAG_PUNCTUATION": [],
  "CODEPOINT_FLAG_SYMBOL": [],
  "CODEPOINT_FLAG_CONTROL": [],
  "UNICODE_CATEGORY_TO_FLAG": [],
  "codepoint_flags": [],
  "table_whitespace": [],
  "table_lowercase": [],
  "table_uppercase": [],
  "table_nfd": [],
  "out": [
    "line"
  ],
  "get_prompts_text": [
    "dataset_name",
    "n_prompts"
  ],
  "get_prompt_lengths_rng": [
    "n_prompts",
    "prompt_length_min",
    "prompt_length_max",
    "seed_offset"
  ],
  "get_prompts_rng": [
    "prompt_lengths"
  ],
  "get_server": [
    "path_server",
    "path_log"
  ],
  "get_prompt_length": [
    "data"
  ],
  "send_prompt": [
    "data"
  ],
  "benchmark": [
    "path_server",
    "path_log",
    "path_db",
    "name",
    "prompt_source",
    "n_prompts",
    "n_predict",
    "n_predict_min",
    "seed_offset"
  ],
  "scoped_server": [
    "sp"
  ],
  "app": [],
  "plot": [
    "files",
    "output",
    "test_regex",
    "server_regex"
  ],
  "run": [
    "output",
    "model",
    "hf",
    "chat_template",
    "chat_template_file",
    "ollama",
    "llama_baseline",
    "n",
    "temp",
    "top_p",
    "top_k",
    "ctk",
    "ctv",
    "fa",
    "seed",
    "port",
    "force",
    "append",
    "test_hello_world",
    "test_weather",
    "test_calc_result"
  ],
  "DocsGenerator": {
    "__init__": [
      "self",
      "ggml_root",
      "output_filename"
    ],
    "parse_support_files": [
      "self"
    ],
    "_parse_support_file": [
      "self",
      "file_path"
    ],
    "get_backend_support_status": [
      "self",
      "backend",
      "operation"
    ],
    "get_support_status": [
      "self",
      "operation"
    ],
    "get_support_symbol": [
      "self",
      "status"
    ],
    "generate_markdown": [
      "self"
    ],
    "run": [
      "self"
    ]
  },
  "n": [],
  "result": [],
  "requests_post_async": [],
  "PydanticDataType": {
    "STRING": [],
    "TRIPLE_QUOTED_STRING": [],
    "MARKDOWN_CODE_BLOCK": [],
    "BOOLEAN": [],
    "INTEGER": [],
    "FLOAT": [],
    "OBJECT": [],
    "ARRAY": [],
    "ENUM": [],
    "ANY": [],
    "NULL": [],
    "CUSTOM_CLASS": [],
    "CUSTOM_DICT": [],
    "SET": []
  },
  "map_pydantic_type_to_gbnf": [
    "pydantic_type"
  ],
  "format_model_and_field_name": [
    "model_name"
  ],
  "generate_list_rule": [
    "element_type"
  ],
  "get_members_structure": [
    "cls",
    "rule_name"
  ],
  "regex_to_gbnf": [
    "regex_pattern"
  ],
  "generate_gbnf_integer_rules": [
    "max_digit",
    "min_digit"
  ],
  "generate_gbnf_float_rules": [
    "max_digit",
    "min_digit",
    "max_precision",
    "min_precision"
  ],
  "generate_gbnf_rule_for_type": [
    "model_name",
    "field_name",
    "field_type",
    "is_optional",
    "processed_models",
    "created_rules",
    "field_info"
  ],
  "generate_gbnf_grammar": [
    "model",
    "processed_models",
    "created_rules"
  ],
  "generate_gbnf_grammar_from_pydantic_models": [
    "models",
    "outer_object_name",
    "outer_object_content",
    "list_of_outputs"
  ],
  "get_primitive_grammar": [
    "grammar"
  ],
  "generate_markdown_documentation": [
    "pydantic_models",
    "model_prefix",
    "fields_prefix",
    "documentation_with_field_description"
  ],
  "generate_field_markdown": [
    "field_name",
    "field_type",
    "model",
    "depth",
    "documentation_with_field_description"
  ],
  "format_json_example": [
    "example",
    "depth"
  ],
  "generate_text_documentation": [
    "pydantic_models",
    "model_prefix",
    "fields_prefix",
    "documentation_with_field_description"
  ],
  "generate_field_text": [
    "field_name",
    "field_type",
    "model",
    "depth",
    "documentation_with_field_description"
  ],
  "format_multiline_description": [
    "description",
    "indent_level"
  ],
  "save_gbnf_grammar_and_documentation": [
    "grammar",
    "documentation",
    "grammar_file_path",
    "documentation_file_path"
  ],
  "remove_empty_lines": [
    "string"
  ],
  "generate_and_save_gbnf_grammar_and_documentation": [
    "pydantic_model_list",
    "grammar_file_path",
    "documentation_file_path",
    "outer_object_name",
    "outer_object_content",
    "model_prefix",
    "fields_prefix",
    "list_of_outputs",
    "documentation_with_field_description"
  ],
  "generate_gbnf_grammar_and_documentation": [
    "pydantic_model_list",
    "outer_object_name",
    "outer_object_content",
    "model_prefix",
    "fields_prefix",
    "list_of_outputs",
    "documentation_with_field_description"
  ],
  "generate_gbnf_grammar_and_documentation_from_dictionaries": [
    "dictionaries",
    "outer_object_name",
    "outer_object_content",
    "model_prefix",
    "fields_prefix",
    "list_of_outputs",
    "documentation_with_field_description"
  ],
  "create_dynamic_model_from_function": [
    "func"
  ],
  "add_run_method_to_dynamic_model": [
    "model",
    "func"
  ],
  "create_dynamic_models_from_dictionaries": [
    "dictionaries"
  ],
  "map_grammar_names_to_pydantic_model_class": [
    "pydantic_model_list"
  ],
  "json_schema_to_python_types": [
    "schema"
  ],
  "list_to_enum": [
    "enum_name",
    "values"
  ],
  "convert_dictionary_to_pydantic_model": [
    "dictionary",
    "model_name"
  ],
  "SendMessageToUser": {
    "run": [
      "self"
    ]
  },
  "example_rce": [
    "host"
  ],
  "MathOperation": {
    "ADD": [],
    "SUBTRACT": [],
    "MULTIPLY": [],
    "DIVIDE": []
  },
  "Calculator": {
    "run": [
      "self"
    ]
  },
  "example_calculator": [
    "host"
  ],
  "Category": {
    "Fiction": [],
    "NonFiction": []
  },
  "Book": {},
  "example_struct": [
    "host"
  ],
  "get_current_datetime": [
    "output_format"
  ],
  "get_current_weather": [
    "location",
    "unit"
  ],
  "example_concurrent": [
    "host"
  ],
  "_generate_min_max_int": [
    "min_value",
    "max_value",
    "out",
    "decimals_left",
    "top_level"
  ],
  "GRAMMAR_RANGE_LITERAL_ESCAPE_RE": [],
  "ARCH": [],
  "DEFAULT_CONCURRENCY": [],
  "ADDED_TOKENS_FILE": [],
  "FAST_TOKENIZER_FILE": [],
  "DataType": {
    "elements_to_bytes": [
      "self",
      "n_elements"
    ]
  },
  "UnquantizedDataType": {},
  "DT_F16": [],
  "DT_F32": [],
  "DT_I32": [],
  "DT_BF16": [],
  "QuantizedDataType": {
    "quantize": [
      "self",
      "arr"
    ],
    "elements_to_bytes": [
      "self",
      "n_elements"
    ]
  },
  "Q8_0QuantizedDataType": {
    "quantize": [
      "self",
      "arr"
    ]
  },
  "DT_Q8_0": [],
  "GGMLFileType": {
    "AllF32": [],
    "MostlyF16": [],
    "MostlyQ8_0": [],
    "type_for_tensor": [
      "self",
      "name",
      "tensor"
    ]
  },
  "Params": {
    "guessed": [
      "model"
    ],
    "loadHFTransformerJson": [
      "model",
      "config_path"
    ],
    "loadOriginalParamsJson": [
      "model",
      "config_path"
    ],
    "load": [
      "model_plus"
    ]
  },
  "permute": [
    "weights",
    "n_head",
    "n_head_kv"
  ],
  "bf16_to_fp32": [
    "bf16_arr"
  ],
  "UnquantizedTensor": {
    "__init__": [
      "self",
      "ndarray"
    ],
    "astype": [
      "self",
      "data_type"
    ],
    "to_ggml": [
      "self"
    ],
    "permute_part": [
      "self",
      "n_part",
      "n_head",
      "n_head_kv"
    ],
    "part": [
      "self",
      "n_part"
    ],
    "permute": [
      "self",
      "n_head",
      "n_head_kv"
    ]
  },
  "load_unquantized": [
    "lazy_tensor",
    "expected_dtype",
    "convert"
  ],
  "GGMLCompatibleTensor": [],
  "LazyTensor": {
    "load": [
      "self"
    ],
    "astype": [
      "self",
      "data_type"
    ],
    "validate_conversion_to": [
      "self",
      "data_type"
    ]
  },
  "ModelPlus": {},
  "merge_sharded": [
    "models"
  ],
  "merge_multifile_models": [
    "models_plus"
  ],
  "permute_lazy": [
    "lazy_tensor",
    "n_head",
    "n_head_kv"
  ],
  "permute_part_lazy": [
    "lazy_tensor",
    "n_part",
    "n_head",
    "n_head_kv"
  ],
  "part_lazy": [
    "lazy_tensor",
    "n_part"
  ],
  "pack_experts_lazy": [
    "lazy_tensors"
  ],
  "LazyStorageKind": {},
  "LazyStorage": {},
  "LazyUnpickler": {
    "__init__": [
      "self",
      "fp",
      "data_base_path",
      "zip_file"
    ],
    "persistent_load": [
      "self",
      "pid"
    ],
    "lazy_rebuild_tensor_v2": [
      "storage",
      "storage_offset",
      "size",
      "stride",
      "requires_grad",
      "backward_hooks",
      "metadata"
    ],
    "rebuild_from_type_v2": [
      "func",
      "new_type",
      "args",
      "state"
    ],
    "find_class": [
      "self",
      "module",
      "name"
    ]
  },
  "lazy_load_torch_file": [
    "outer_fp",
    "path"
  ],
  "lazy_load_safetensors_file": [
    "fp",
    "path"
  ],
  "must_read": [
    "fp",
    "length"
  ],
  "lazy_load_file": [
    "path"
  ],
  "In": [],
  "Out": [],
  "bounded_parallel_map": [
    "func",
    "iterable",
    "concurrency",
    "max_workers",
    "use_processpool_executor"
  ],
  "check_vocab_size": [
    "params",
    "vocab",
    "pad_vocab"
  ],
  "OutputFile": {
    "__init__": [
      "self",
      "fname_out",
      "endianess"
    ],
    "add_meta_model": [
      "self",
      "params",
      "metadata"
    ],
    "add_meta_arch": [
      "self",
      "params"
    ],
    "extract_vocabulary_from_model": [
      "self",
      "vocab"
    ],
    "add_meta_vocab": [
      "self",
      "vocab"
    ],
    "add_meta_special_vocab": [
      "self",
      "svocab"
    ],
    "add_tensor_info": [
      "self",
      "name",
      "tensor"
    ],
    "write_meta": [
      "self"
    ],
    "write_tensor_info": [
      "self"
    ],
    "write_tensor_data": [
      "self",
      "ftype",
      "model",
      "concurrency"
    ],
    "close": [
      "self"
    ],
    "write_vocab_only": [
      "fname_out",
      "params",
      "vocab",
      "svocab",
      "endianess",
      "pad_vocab",
      "metadata"
    ],
    "do_item": [
      "item"
    ],
    "maybe_do_quantize": [
      "item"
    ],
    "write_all": [
      "fname_out",
      "ftype",
      "params",
      "model",
      "vocab",
      "svocab",
      "concurrency",
      "endianess",
      "pad_vocab",
      "metadata"
    ]
  },
  "pick_output_type": [
    "model",
    "output_type_str"
  ],
  "per_model_weight_count_estimation": [
    "tensors"
  ],
  "convert_to_output_type": [
    "model",
    "output_type"
  ],
  "convert_model_names": [
    "model",
    "params",
    "skip_unknown"
  ],
  "nth_multifile_path": [
    "path",
    "n"
  ],
  "find_multifile_paths": [
    "path"
  ],
  "load_some_model": [
    "path"
  ],
  "VocabFactory": {
    "__init__": [
      "self",
      "path"
    ],
    "_create_special_vocab": [
      "self",
      "vocab",
      "model_parent_path"
    ],
    "_create_vocab_by_path": [
      "self",
      "vocab_types"
    ],
    "load_vocab": [
      "self",
      "vocab_types",
      "model_parent_path"
    ]
  },
  "default_convention_outfile": [
    "file_type",
    "expert_count",
    "model_params_count",
    "metadata"
  ],
  "default_outfile": [
    "model_paths",
    "file_type",
    "expert_count",
    "model_params_count",
    "metadata"
  ],
  "do_dump_model": [
    "model_plus"
  ],
  "labels": [],
  "numbers": [],
  "numEntries": [],
  "rows": [],
  "bar_chart": [
    "numbers",
    "labels",
    "pos"
  ],
  "calculatecorrect": [],
  "fill_hann_window": [
    "size",
    "periodic"
  ],
  "irfft": [
    "n_fft",
    "complex_input"
  ],
  "fold": [
    "buffer",
    "n_out",
    "n_win",
    "n_hop",
    "n_pad"
  ],
  "process_frame": [
    "args"
  ],
  "embd_to_audio": [
    "embd",
    "n_codes",
    "n_embd",
    "n_thread"
  ],
  "save_wav": [
    "filename",
    "audio_data",
    "sample_rate"
  ],
  "process_text": [
    "text"
  ],
  "host_llm": [],
  "host_dec": [],
  "text": [],
  "prefix": [],
  "words": [],
  "suffix": [],
  "response": [],
  "response_json": [],
  "codes": [],
  "embd": [],
  "n_codes": [],
  "n_embd": [],
  "audio": [],
  "filename": [],
  "sample_rate": [],
  "model_path": [],
  "path_dst": [],
  "model": [],
  "flatten_state_dict": [
    "state_dict",
    "parent_key",
    "sep"
  ],
  "flattened_state_dict": [],
  "output_path": [],
  "total_size": [],
  "weight_map": [],
  "metadata": [],
  "index_path": [],
  "config": [],
  "stop_server_after_each_test": [],
  "DEFAULT_HTTP_TIMEOUT": [],
  "ServerResponse": {},
  "ServerProcess": {
    "__init__": [
      "self"
    ],
    "start": [
      "self",
      "timeout_seconds"
    ],
    "stop": [
      "self"
    ],
    "make_request": [
      "self",
      "method",
      "path",
      "data",
      "headers",
      "timeout"
    ],
    "make_stream_request": [
      "self",
      "method",
      "path",
      "data",
      "headers"
    ],
    "make_any_request": [
      "self",
      "method",
      "path",
      "data",
      "headers",
      "timeout"
    ]
  },
  "ServerPreset": {
    "tinyllama2": [],
    "bert_bge_small": [],
    "bert_bge_small_with_fa": [],
    "tinyllama_infill": [],
    "stories15m_moe": [],
    "jina_reranker_tiny": [],
    "tinygemma3": []
  },
  "parallel_function_calls": [
    "function_list"
  ],
  "match_regex": [
    "regex",
    "text"
  ],
  "is_slow_test_allowed": [],
  "server": [],
  "create_server": [],
  "test_completion": [
    "prompt",
    "n_predict",
    "re_content",
    "n_prompt",
    "n_predicted",
    "truncated",
    "return_tokens"
  ],
  "test_completion_stream": [
    "prompt",
    "n_predict",
    "re_content",
    "n_prompt",
    "n_predicted",
    "truncated"
  ],
  "test_completion_stream_vs_non_stream": [],
  "test_completion_with_openai_library": [],
  "test_completion_stream_with_openai_library": [],
  "test_completion_stream_with_openai_library_stops": [],
  "test_consistent_result_same_seed": [
    "n_slots"
  ],
  "test_different_result_different_seed": [
    "n_slots"
  ],
  "test_consistent_result_different_batch_size": [
    "n_batch",
    "temperature"
  ],
  "test_cache_vs_nocache_prompt": [],
  "test_nocache_long_input_prompt": [],
  "test_completion_with_tokens_input": [],
  "test_completion_parallel_slots": [
    "n_slots",
    "n_requests"
  ],
  "test_completion_response_fields": [
    "prompt",
    "n_predict",
    "response_fields"
  ],
  "test_n_probs": [],
  "test_n_probs_stream": [],
  "test_n_probs_post_sampling": [],
  "test_logit_bias": [
    "tokenize",
    "openai_style"
  ],
  "test_cancel_request": [],
  "test_chat_completion": [
    "model",
    "system_prompt",
    "user_prompt",
    "max_tokens",
    "re_content",
    "n_prompt",
    "n_predicted",
    "finish_reason",
    "jinja",
    "chat_template"
  ],
  "test_chat_completion_stream": [
    "system_prompt",
    "user_prompt",
    "max_tokens",
    "re_content",
    "n_prompt",
    "n_predicted",
    "finish_reason"
  ],
  "test_chat_completion_with_openai_library": [],
  "test_chat_template": [],
  "test_chat_template_assistant_prefill": [
    "prefill",
    "re_prefill"
  ],
  "test_apply_chat_template": [],
  "test_completion_with_response_format": [
    "response_format",
    "n_predicted",
    "re_content"
  ],
  "test_completion_with_json_schema": [
    "jinja",
    "json_schema",
    "n_predicted",
    "re_content"
  ],
  "test_completion_with_grammar": [
    "jinja",
    "grammar",
    "n_predicted",
    "re_content"
  ],
  "test_invalid_chat_completion_req": [
    "messages"
  ],
  "test_chat_completion_with_timings_per_token": [],
  "test_logprobs": [],
  "test_logprobs_stream": [],
  "path": [],
  "TIMEOUT_SERVER_START": [],
  "TIMEOUT_HTTP_REQUEST": [],
  "CompletionMode": {
    "NORMAL": [],
    "STREAMED": []
  },
  "TEST_TOOL": [],
  "PYTHON_TOOL": [],
  "WEATHER_TOOL": [],
  "do_test_completion_with_required_tool_tiny": [
    "server",
    "tool",
    "argument_key",
    "n_predict"
  ],
  "test_completion_with_required_tool_tiny_fast": [
    "template_name",
    "tool",
    "argument_key",
    "stream"
  ],
  "test_completion_with_required_tool_tiny_slow": [
    "template_name",
    "tool",
    "argument_key",
    "stream"
  ],
  "test_completion_with_required_tool_real_model": [
    "tool",
    "argument_key",
    "hf_repo",
    "template_override",
    "stream"
  ],
  "do_test_completion_without_tool_call": [
    "server",
    "n_predict",
    "tools",
    "tool_choice"
  ],
  "test_completion_without_tool_call_fast": [
    "template_name",
    "n_predict",
    "tools",
    "tool_choice",
    "stream"
  ],
  "test_completion_without_tool_call_slow": [
    "template_name",
    "n_predict",
    "tools",
    "tool_choice",
    "stream"
  ],
  "test_weather": [
    "hf_repo",
    "template_override",
    "stream"
  ],
  "do_test_weather": [
    "server"
  ],
  "test_calc_result": [
    "result_override",
    "n_predict",
    "hf_repo",
    "template_override",
    "stream"
  ],
  "do_test_calc_result": [
    "server",
    "result_override",
    "n_predict"
  ],
  "test_thoughts": [
    "n_predict",
    "reasoning_format",
    "expect_content",
    "expect_reasoning_content",
    "hf_repo",
    "template_override",
    "stream"
  ],
  "test_hello_world": [
    "hf_repo",
    "template_override",
    "stream"
  ],
  "do_test_hello_world": [
    "server"
  ],
  "test_infill_without_input_extra": [],
  "test_infill_with_input_extra": [],
  "test_invalid_input_extra_req": [
    "input_extra"
  ],
  "test_with_qwen_model": [],
  "LONG_TEXT": [],
  "test_ctx_shift_enabled": [],
  "test_ctx_shift_disabled_short_prompt": [
    "n_predict",
    "n_token_output",
    "truncated"
  ],
  "test_ctx_shift_disabled_long_prompt": [],
  "test_ctx_shift_disabled_stream": [],
  "test_server_start_simple": [],
  "test_server_props": [],
  "test_server_models": [],
  "test_server_slots": [],
  "test_load_split_model": [],
  "test_no_webui": [],
  "TEST_API_KEY": [],
  "test_access_public_endpoint": [
    "endpoint"
  ],
  "test_incorrect_api_key": [
    "api_key"
  ],
  "test_correct_api_key": [],
  "test_openai_library_correct_api_key": [],
  "test_cors_options": [
    "origin",
    "cors_header",
    "cors_header_value"
  ],
  "EPSILON": [],
  "test_embedding_single": [],
  "test_embedding_multiple": [],
  "test_embedding_multiple_with_fa": [],
  "test_embedding_mixed_input": [
    "input",
    "is_multi_prompt"
  ],
  "test_embedding_pooling_none": [],
  "test_embedding_pooling_none_oai": [],
  "test_embedding_openai_library_single": [],
  "test_embedding_openai_library_multiple": [],
  "test_embedding_error_prompt_too_long": [],
  "test_same_prompt_give_same_result": [],
  "test_embedding_usage_single": [
    "content",
    "n_tokens"
  ],
  "test_embedding_usage_multiple": [],
  "test_embedding_openai_library_base64": [],
  "MODEL_DRAFT_FILE_URL": [],
  "fixture_create_server": [],
  "test_with_and_without_draft": [],
  "test_different_draft_min_draft_max": [],
  "test_slot_ctx_not_exceeded": [],
  "test_with_ctx_shift": [],
  "test_multi_requests_parallel": [
    "n_slots",
    "n_requests"
  ],
  "test_reasoning_budget": [
    "template_name",
    "reasoning_budget",
    "expected_end",
    "tools"
  ],
  "test_date_inside_prompt": [
    "template_name",
    "format",
    "tools"
  ],
  "test_add_generation_prompt": [
    "template_name",
    "expected_generation_prompt",
    "add_generation_prompt"
  ],
  "TEST_DOCUMENTS": [],
  "test_rerank": [],
  "test_rerank_tei_format": [],
  "test_invalid_rerank_req": [
    "documents"
  ],
  "test_rerank_usage": [
    "query",
    "doc1",
    "doc2",
    "n_tokens"
  ],
  "test_tokenize_detokenize": [],
  "test_tokenize_with_bos": [],
  "test_tokenize_with_pieces": [],
  "test_slot_save_restore": [],
  "test_slot_erase": [],
  "IMG_URL_0": [],
  "IMG_URL_1": [],
  "IMG_BASE64_0": [],
  "test_vision_chat_completion": [
    "prompt",
    "image_url",
    "success",
    "re_content"
  ],
  "LORA_FILE_URL": [],
  "test_lora": [
    "scale",
    "re_content"
  ],
  "test_lora_per_request": [],
  "test_with_big_model": [],
  "start_benchmark": [
    "args"
  ],
  "start_server": [
    "args"
  ],
  "start_server_background": [
    "args"
  ],
  "is_server_listening": [
    "server_fqdn",
    "server_port"
  ],
  "is_server_ready": [
    "server_fqdn",
    "server_port"
  ],
  "escape_metric_name": [
    "metric_name"
  ],
  "ap": [],
  "checkpoint": [],
  "mm_tensors": [],
  "projector": [],
  "clip_tensors": [],
  "tok": [],
  "is_safetensor_file": [
    "file_path"
  ],
  "load_model": [
    "file_path"
  ],
  "save_model": [
    "model",
    "file_path",
    "file_type"
  ],
  "is_vision_tower": [
    "weight_name"
  ],
  "is_newline": [
    "weight_name"
  ],
  "is_mm_projector": [
    "weight_name"
  ],
  "newline_criteria": [
    "checkpoint"
  ],
  "proj_criteria": [
    "checkpoint"
  ],
  "clean_vision_tower_from_checkpoint": [
    "checkpoint_path"
  ],
  "find_relevant_checkpoints": [
    "checkpoint_paths",
    "newline_criteria",
    "projector"
  ],
  "model_files": [],
  "checkpoint_paths": [],
  "first_mm_tensors": [],
  "first_checkpoint": [],
  "last_checkpoint": [],
  "TEXT": [],
  "VISION": [],
  "k": [
    "raw_key",
    "arch"
  ],
  "should_skip_tensor": [
    "name",
    "has_text",
    "has_vision",
    "has_llava"
  ],
  "get_tensor_name": [
    "name"
  ],
  "default_image_mean": [],
  "default_image_std": [],
  "dir_model": [],
  "ftype_str": [],
  "ftype": [],
  "vision_config": [],
  "fname_middle": [],
  "has_text_encoder": [],
  "has_vision_encoder": [],
  "has_glm_projector": [],
  "output_dir": [],
  "output_prefix": [],
  "fout": [],
  "model_name": [],
  "state_dict": [],
  "SiglipVisionConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "hidden_act",
      "layer_norm_eps",
      "attention_dropout"
    ]
  },
  "_CHECKPOINT_FOR_DOC": [],
  "SIGLIP_PRETRAINED_MODEL_ARCHIVE_LIST": [],
  "_get_unpad_data": [
    "attention_mask"
  ],
  "_trunc_normal_": [
    "tensor",
    "mean",
    "std",
    "a",
    "b"
  ],
  "trunc_normal_tf_": [
    "tensor",
    "mean",
    "std",
    "a",
    "b"
  ],
  "variance_scaling_": [
    "tensor",
    "scale",
    "mode",
    "distribution"
  ],
  "lecun_normal_": [
    "tensor"
  ],
  "default_flax_embed_init": [
    "tensor"
  ],
  "SiglipVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ]
  },
  "SiglipAttention": {
    "__init__": [
      "self",
      "config"
    ]
  },
  "SiglipMLP": {
    "__init__": [
      "self",
      "config"
    ]
  },
  "SiglipEncoderLayer": {
    "__init__": [
      "self",
      "config"
    ]
  },
  "SiglipPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "supports_gradient_checkpointing": [],
    "_init_weights": [
      "self",
      "module"
    ]
  },
  "SIGLIP_START_DOCSTRING": [],
  "SIGLIP_VISION_INPUTS_DOCSTRING": [],
  "SiglipEncoder": {
    "__init__": [
      "self",
      "config"
    ]
  },
  "SiglipVisionTransformer": {
    "config_class": [],
    "main_input_name": [],
    "_supports_flash_attn_2": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "add_key_str": [
    "raw_key",
    "arch"
  ],
  "config_path": [],
  "model_config": [],
  "minicpmv_version": [],
  "processor": [],
  "has_minicpmv_projector": [],
  "use_gelu": [],
  "get_1d_sincos_pos_embed_from_grid": [
    "embed_dim",
    "pos"
  ],
  "get_2d_sincos_pos_embed_from_grid": [
    "embed_dim",
    "grid"
  ],
  "get_2d_sincos_pos_embed": [
    "embed_dim",
    "grid_size",
    "cls_token"
  ],
  "_replace_name_resampler": [
    "s",
    "v"
  ],
  "_replace_name": [
    "s",
    "v"
  ],
  "new_state_dict": [],
  "encoder_group": [],
  "has_llava_projector": [],
  "get_non_negative_vision_feature_layers": [
    "v_hparams"
  ],
  "feature_layers": [],
  "GptParams": {},
  "gpt_params_parse": [
    "argv"
  ],
  "gpt_random_prompt": [
    "rng"
  ],
  "ANSI_COLOR_RESET": [],
  "ANSI_COLOR_YELLOW": [],
  "ANSI_BOLD": [],
  "ANSI_COLOR_GREEN": [],
  "CONSOLE_COLOR_DEFAULT": [],
  "CONSOLE_COLOR_PROMPT": [],
  "CONSOLE_COLOR_USER_INPUT": [],
  "IterSearch": {
    "__init__": [
      "self",
      "pattern"
    ],
    "__call__": [
      "self",
      "char"
    ]
  },
  "Circle": {
    "__init__": [
      "self",
      "size",
      "default"
    ],
    "append": [
      "self",
      "elem"
    ],
    "__getitem__": [
      "self",
      "val"
    ]
  },
  "env_or_def": [
    "env",
    "default"
  ],
  "prompt": [],
  "params": [],
  "N_THREADS": [],
  "MODEL_PATH": [],
  "lparams": [],
  "cparams": [],
  "ctx": [],
  "tmp": [],
  "n_past": [],
  "embd_inp": [],
  "n_of_tok": [],
  "n_ctx": [],
  "n_predict": [],
  "input_consumed": [],
  "input_noecho": [],
  "remaining_tokens": [],
  "last_n_size": [],
  "last_n_tokens_data": [],
  "n_batch": [],
  "last_n_repeat": [],
  "repeat_penalty": [],
  "frequency_penalty": [],
  "presence_penalty": [],
  "AI_NAME": [],
  "USER_NAME": [],
  "N_PREDICTS": [],
  "N_THREAD": [],
  "today": [],
  "DATE_YEAR": [],
  "DATE_TIME": [],
  "LLaMAInteract": {
    "__init__": [
      "self",
      "params"
    ],
    "_tokenize": [
      "self",
      "prompt",
      "bos"
    ],
    "set_color": [
      "self",
      "c"
    ],
    "use_antiprompt": [
      "self"
    ],
    "generate": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "type",
      "value",
      "tb"
    ],
    "exit": [
      "self"
    ],
    "token_to_str": [
      "self",
      "token_id"
    ],
    "past": [
      "self"
    ],
    "input": [
      "self",
      "prompt"
    ],
    "output": [
      "self"
    ],
    "read_input": [
      "self"
    ],
    "interact": [
      "self"
    ]
  },
  "llm": [],
  "output": [],
  "response_stripped": [],
  "unwanted_response_suffix": [],
  "unwanted_response_length": [],
  "filtered": [],
  "stream": [],
  "LlamaLLM": {
    "_llm_type": [
      "self"
    ],
    "__init__": [
      "self",
      "model_path"
    ],
    "_call": [
      "self",
      "prompt",
      "stop"
    ],
    "_identifying_params": [
      "self"
    ]
  },
  "answer": [],
  "chain": [],
  "create_chat_completions": [],
  "llama": [],
  "predict": [
    "message",
    "history"
  ],
  "js": [],
  "css": [],
  "client": [],
  "LlamaDeployment": {
    "__init__": [
      "self",
      "model_path"
    ],
    "__call__": [
      "self",
      "http_request"
    ]
  },
  "llm_builder": [
    "args"
  ]
}