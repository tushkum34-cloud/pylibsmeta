{
  "int16_max": [],
  "preprocess_wav": [
    "fpath_or_wav",
    "source_sr"
  ],
  "wav_to_mel_spectrogram": [
    "wav"
  ],
  "trim_long_silences": [
    "wav"
  ],
  "normalize_volume": [
    "wav",
    "target_dBFS",
    "increase_only",
    "decrease_only"
  ],
  "mel_window_length": [],
  "mel_window_step": [],
  "mel_n_channels": [],
  "sampling_rate": [],
  "partials_n_frames": [],
  "vad_window_length": [],
  "vad_moving_average_width": [],
  "vad_max_silence_length": [],
  "audio_norm_target_dBFS": [],
  "model_hidden_size": [],
  "model_embedding_size": [],
  "model_num_layers": [],
  "name": [],
  "VoiceEncoder": {
    "__init__": [
      "self",
      "device",
      "verbose",
      "weights_fpath"
    ],
    "forward": [
      "self",
      "mels"
    ],
    "compute_partial_slices": [
      "n_samples",
      "rate",
      "min_coverage"
    ],
    "embed_utterance": [
      "self",
      "wav",
      "return_partials",
      "rate",
      "min_coverage"
    ],
    "embed_speaker": [
      "self",
      "wavs"
    ]
  }
}