{
  "_IS_TORCH_GTE_24": [],
  "_": [
    "optimizer_name",
    "g",
    "p",
    "state1",
    "state2",
    "beta1",
    "beta2",
    "beta3",
    "alpha",
    "eps",
    "step",
    "lr",
    "qmap1",
    "qmap2",
    "absmax1",
    "absmax2",
    "weight_decay",
    "gnorm_scale",
    "skip_zeros"
  ],
  "DYNAMIC_LIBRARY_SUFFIX": [],
  "PACKAGE_DIR": [],
  "PACKAGE_GITHUB_URL": [],
  "NONPYTORCH_DOC_URL": [],
  "outlier_hook": [
    "module",
    "input"
  ],
  "OutlierTracer": {
    "_instance": [],
    "__init__": [
      "self"
    ],
    "initialize": [
      "self",
      "model"
    ],
    "is_initialized": [
      "self"
    ],
    "get_hvalue": [
      "self",
      "weight"
    ],
    "get_outliers": [
      "self",
      "weight"
    ],
    "get_instance": [
      "cls"
    ]
  },
  "find_outlier_dims": [
    "weight",
    "reduction_dim",
    "zscore",
    "topk",
    "rdm"
  ],
  "execute_and_return": [
    "command_string"
  ],
  "replace_linear": [
    "model",
    "linear_replacement",
    "skip_modules",
    "copy_weights",
    "post_processing_function"
  ],
  "pack_dict_to_tensor": [
    "source_dict"
  ],
  "unpack_tensor_to_dict": [
    "tensor_data"
  ],
  "LINEAR_8BIT_WEIGHTS_FORMAT_MAPPING": [],
  "INVERSE_LINEAR_8BIT_WEIGHTS_FORMAT_MAPPING": [],
  "sync_gpu": [
    "t"
  ],
  "CUDASpecs": {
    "has_imma": [
      "self"
    ]
  },
  "get_compute_capabilities": [],
  "get_cuda_version_tuple": [],
  "get_cuda_version_string": [],
  "get_cuda_specs": [],
  "get_rocm_gpu_arch": [],
  "get_rocm_warpsize": [],
  "features": [],
  "supported_torch_devices": [],
  "_import_backends": [],
  "__pdoc__": [],
  "__version__": [],
  "logger": [],
  "get_cuda_bnb_library_path": [
    "cuda_specs"
  ],
  "BNBNativeLibrary": {
    "compiled_with_cuda": [],
    "__init__": [
      "self",
      "lib"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "__getitem__": [
      "self",
      "item"
    ]
  },
  "CudaBNBNativeLibrary": {
    "compiled_with_cuda": [],
    "__init__": [
      "self",
      "lib"
    ]
  },
  "get_available_cuda_binary_versions": [],
  "parse_cuda_version": [
    "version_str"
  ],
  "ErrorHandlerMockBNBNativeLibrary": {
    "__init__": [
      "self",
      "error_msg"
    ],
    "_format_lib_error_message": [
      "self",
      "available_versions",
      "user_cuda_version",
      "original_error",
      "requested_version"
    ],
    "_format_dependency_error": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "__getitem__": [
      "self",
      "name"
    ]
  },
  "get_native_library": [],
  "ROCM_GPU_ARCH": [],
  "ROCM_WARP_SIZE_64": [],
  "HIP_ENVIRONMENT": [],
  "BNB_BACKEND": [],
  "name2qmap": [],
  "str2optimizer8bit": [],
  "GlobalPageManager": {
    "_instance": [],
    "__init__": [
      "self"
    ],
    "initialize": [
      "self"
    ],
    "get_instance": [
      "cls"
    ],
    "prefetch_all": [
      "self",
      "to_cpu"
    ]
  },
  "CUBLAS_Context": {
    "_instance": [],
    "__init__": [
      "self"
    ],
    "initialize": [
      "self"
    ],
    "get_instance": [
      "cls"
    ],
    "get_context": [
      "self",
      "device"
    ]
  },
  "Cusparse_Context": {
    "_instance": [],
    "__init__": [
      "self"
    ],
    "initialize": [
      "self"
    ],
    "get_instance": [
      "cls"
    ]
  },
  "FIRST_CUDA_DEVICE": [],
  "get_paged": [],
  "prefetch_tensor": [
    "A",
    "to_cpu"
  ],
  "elementwise_func": [
    "func_name",
    "A",
    "B",
    "value",
    "prefetch"
  ],
  "fill": [
    "A",
    "value",
    "device",
    "prefetch"
  ],
  "_mul": [
    "A",
    "B",
    "device"
  ],
  "create_linear_map": [
    "signed",
    "total_bits",
    "add_zero"
  ],
  "create_normal_map": [
    "offset",
    "use_extra_value"
  ],
  "create_fp8_map": [
    "signed",
    "exponent_bits",
    "precision_bits",
    "total_bits"
  ],
  "create_dynamic_map": [
    "signed",
    "max_exponent_bits",
    "total_bits"
  ],
  "is_on_gpu": [
    "tensors"
  ],
  "_get_tensor_stream": [
    "tensor"
  ],
  "get_ptr": [
    "A"
  ],
  "QuantState": {
    "valid_quant_types": [],
    "valid_qs_type_keys": [],
    "valid_qs_keys": [],
    "__init__": [
      "self",
      "absmax",
      "shape",
      "code",
      "blocksize",
      "quant_type",
      "dtype",
      "offset",
      "state2"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "from_dict": [
      "cls",
      "qs_dict",
      "device"
    ],
    "as_dict": [
      "self",
      "packed"
    ],
    "to": [
      "self",
      "device"
    ],
    "__eq__": [
      "self",
      "other"
    ]
  },
  "quantize_blockwise": [
    "A",
    "code",
    "absmax",
    "out",
    "blocksize",
    "nested"
  ],
  "dequantize_blockwise": [
    "A",
    "quant_state",
    "absmax",
    "code",
    "out",
    "blocksize",
    "nested"
  ],
  "get_4bit_type": [
    "typename",
    "device",
    "blocksize"
  ],
  "quantize_fp4": [
    "A",
    "absmax",
    "out",
    "blocksize",
    "compress_statistics",
    "quant_storage"
  ],
  "quantize_nf4": [
    "A",
    "absmax",
    "out",
    "blocksize",
    "compress_statistics",
    "quant_storage"
  ],
  "quantize_4bit": [
    "A",
    "absmax",
    "out",
    "blocksize",
    "compress_statistics",
    "quant_type",
    "quant_storage"
  ],
  "dequantize_fp4": [
    "A",
    "quant_state",
    "absmax",
    "out",
    "blocksize"
  ],
  "dequantize_nf4": [
    "A",
    "quant_state",
    "absmax",
    "out",
    "blocksize"
  ],
  "dequantize_4bit": [
    "A",
    "quant_state",
    "absmax",
    "out",
    "blocksize",
    "quant_type"
  ],
  "quantize": [
    "A",
    "code",
    "out"
  ],
  "dequantize": [
    "A",
    "state",
    "absmax",
    "code",
    "out"
  ],
  "quantize_no_absmax": [
    "A",
    "code",
    "out"
  ],
  "dequantize_no_absmax": [
    "A",
    "code",
    "out"
  ],
  "optimizer_update_32bit": [
    "optimizer_name",
    "g",
    "p",
    "state1",
    "beta1",
    "eps",
    "step",
    "lr",
    "state2",
    "beta2",
    "beta3",
    "alpha",
    "weight_decay",
    "gnorm_scale",
    "unorm_vec",
    "max_unorm",
    "skip_zeros"
  ],
  "optimizer_update_8bit": [
    "optimizer_name",
    "g",
    "p",
    "state1",
    "state2",
    "beta1",
    "beta2",
    "eps",
    "step",
    "lr",
    "qmap1",
    "qmap2",
    "max1",
    "max2",
    "new_max1",
    "new_max2",
    "weight_decay",
    "gnorm_scale",
    "unorm_vec",
    "max_unorm"
  ],
  "optimizer_update_8bit_blockwise": [
    "optimizer_name",
    "g",
    "p",
    "state1",
    "state2",
    "beta1",
    "beta2",
    "beta3",
    "alpha",
    "eps",
    "step",
    "lr",
    "qmap1",
    "qmap2",
    "absmax1",
    "absmax2",
    "weight_decay",
    "gnorm_scale",
    "skip_zeros"
  ],
  "percentile_clipping": [
    "grad",
    "gnorm_vec",
    "step",
    "percentile"
  ],
  "check_matmul": [
    "A",
    "B",
    "out",
    "transposed_A",
    "transposed_B",
    "expected_type"
  ],
  "gemv_4bit": [
    "A",
    "B",
    "out",
    "transposed_A",
    "transposed_B",
    "state"
  ],
  "igemm": [
    "A",
    "B",
    "out",
    "transposed_A",
    "transposed_B"
  ],
  "batched_igemm": [
    "A",
    "B",
    "out",
    "transposed_A",
    "transposed_B"
  ],
  "int8_linear_matmul": [
    "A",
    "B",
    "out",
    "dtype"
  ],
  "int8_mm_dequant": [
    "A",
    "row_stats",
    "col_stats",
    "out",
    "bias"
  ],
  "COOSparseTensor": {
    "__init__": [
      "self",
      "rows",
      "cols",
      "nnz",
      "rowidx",
      "colidx",
      "values"
    ]
  },
  "CSRSparseTensor": {
    "__init__": [
      "self",
      "rows",
      "cols",
      "nnz",
      "rowptr",
      "colidx",
      "values"
    ]
  },
  "CSCSparseTensor": {
    "__init__": [
      "self",
      "rows",
      "cols",
      "nnz",
      "colptr",
      "rowidx",
      "values"
    ]
  },
  "coo2csr": [
    "cooA"
  ],
  "coo2csc": [
    "cooA"
  ],
  "coo_zeros": [
    "rows",
    "cols",
    "nnz",
    "device",
    "dtype"
  ],
  "int8_double_quant": [
    "A",
    "col_stats",
    "row_stats",
    "out_col",
    "out_row",
    "threshold"
  ],
  "int8_vectorwise_dequant": [
    "A",
    "stats"
  ],
  "int8_vectorwise_quant": [
    "A",
    "threshold"
  ],
  "spmm_coo": [
    "cooA",
    "B",
    "out"
  ],
  "spmm_coo_very_sparse": [
    "cooA",
    "B",
    "dequant_stats",
    "out"
  ],
  "_convert_weight_packed_for_cpu": [
    "qweight",
    "quant_state",
    "block_n"
  ],
  "_convert_weight_packed_for_cpu_inverse": [
    "packed_weight",
    "quant_state",
    "block_n"
  ],
  "has_avx512bf16": [],
  "C": [],
  "get_clock_rate_in_khz": [],
  "get_tensorcore_tflops": [
    "device",
    "num_ctas",
    "num_warps",
    "dtype"
  ],
  "get_simd_tflops": [
    "device",
    "num_ctas",
    "num_warps",
    "dtype"
  ],
  "get_tflops": [
    "device",
    "num_ctas",
    "num_warps",
    "dtype"
  ],
  "estimate_matmul_time": [
    "num_warps",
    "num_stages",
    "A",
    "B",
    "C",
    "M",
    "N",
    "K",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "SPLIT_K",
    "debug"
  ],
  "early_config_prune": [
    "configs",
    "named_args"
  ],
  "is_triton_available": [],
  "GlobalOutlierPooler": {
    "_instance": [],
    "__init__": [
      "self"
    ],
    "initialize": [
      "self"
    ],
    "get_instance": [
      "cls"
    ],
    "add_outliers": [
      "self",
      "outlier_idx",
      "feature_dim"
    ],
    "get_current_outlier_idx": [
      "self"
    ]
  },
  "_is_compiling": [],
  "MatmulLtState": {
    "has_accumulated_gradients": [],
    "threshold": [],
    "is_training": [],
    "has_fp16_weights": [],
    "use_pool": [],
    "formatB": [],
    "reset_grads": [
      "self"
    ],
    "tile_indices": [
      "self"
    ]
  },
  "MatMul8bitLt": {
    "forward": [
      "ctx",
      "A",
      "B",
      "out",
      "bias",
      "state"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "MatMul8bitFp": {
    "forward": [
      "ctx",
      "A",
      "B",
      "out",
      "bias",
      "state"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "MatMul4Bit": {
    "forward": [
      "ctx",
      "A",
      "B",
      "out",
      "bias",
      "quant_state"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "matmul": [
    "A",
    "B",
    "out",
    "state",
    "threshold",
    "bias"
  ],
  "matmul_4bit": [
    "A",
    "B",
    "quant_state",
    "out",
    "bias"
  ],
  "prod": [
    "iterable"
  ],
  "MatMulFP8Mixed": {
    "forward": [
      "ctx",
      "A",
      "B",
      "out",
      "fw_code",
      "bw_code",
      "bsz",
      "bsz2"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "MatMulFP8Global": {
    "forward": [
      "ctx",
      "A",
      "B",
      "out",
      "fw_code",
      "bw_code",
      "bsz",
      "bsz2"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "SwitchBackBnb": {
    "forward": [
      "ctx",
      "A",
      "B",
      "out",
      "bias",
      "state"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "get_block_sizes": [
    "input_matrix",
    "weight_matrix"
  ],
  "matmul_fp8_global": [
    "A",
    "B",
    "fw_code",
    "bw_code",
    "out",
    "bsz",
    "bsz2"
  ],
  "matmul_fp8_mixed": [
    "A",
    "B",
    "fw_code",
    "bw_code",
    "out",
    "bsz",
    "bsz2"
  ],
  "switchback_bnb": [
    "A",
    "B",
    "out",
    "state",
    "threshold",
    "bias"
  ],
  "T": [],
  "LinearFP8Mixed": {
    "__init__": [
      "self",
      "input_features",
      "output_features",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LinearFP8Global": {
    "__init__": [
      "self",
      "input_features",
      "output_features",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Bnb4bitParametrization": {
    "__init__": [
      "self",
      "quant_state"
    ],
    "forward": [
      "self",
      "quantized_param"
    ]
  },
  "replace_parameter_4bit_prequantized": [
    "module",
    "param_name",
    "qs_dict",
    "device"
  ],
  "replace_parameter_4bit": [
    "module",
    "param_name",
    "compress_statistics",
    "quant_type",
    "blocksize"
  ],
  "_disable_parametrization_cache": [
    "module",
    "inputs",
    "output"
  ],
  "_enable_parametrization_cache": [
    "module",
    "inputs"
  ],
  "_register_parametrization_hooks": [
    "module",
    "param_name"
  ],
  "_parametrized_state_dict_post_hook": [
    "module",
    "state_dict",
    "prefix",
    "local_metadata"
  ],
  "_switchback_global": {
    "forward": [
      "ctx",
      "X_3D",
      "W",
      "bias"
    ],
    "backward": [
      "ctx",
      "G_3D"
    ]
  },
  "_switchback_vectorrize": {
    "forward": [
      "ctx",
      "X_3D",
      "W",
      "bias"
    ],
    "backward": [
      "ctx",
      "G_3D"
    ]
  },
  "_switchback_global_mem_efficient": {
    "forward": [
      "ctx",
      "X_3D",
      "W",
      "bias"
    ],
    "backward": [
      "ctx",
      "G_3D"
    ]
  },
  "SwitchBackLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "device",
      "dtype",
      "vector_wise_quantization",
      "mem_efficient"
    ],
    "prepare_for_eval": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SwitchBackLinearGlobal": [],
  "SwitchBackLinearGlobalMemEfficient": [],
  "SwitchBackLinearVectorwise": [],
  "StandardLinearFunction": {
    "forward": [
      "ctx",
      "input",
      "weight",
      "bias"
    ],
    "backward": [
      "ctx",
      "grad_output_3D"
    ]
  },
  "StandardLinear": {
    "forward": [
      "self",
      "x"
    ]
  },
  "StableEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "padding_idx",
      "max_norm",
      "norm_type",
      "scale_grad_by_freq",
      "sparse",
      "_weight",
      "device",
      "dtype"
    ],
    "reset_parameters": [
      "self"
    ],
    "_fill_padding_idx_with_zero": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Embedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "padding_idx",
      "max_norm",
      "norm_type",
      "scale_grad_by_freq",
      "sparse",
      "_weight",
      "device"
    ],
    "reset_parameters": [
      "self"
    ],
    "_fill_padding_idx_with_zero": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Params4bit": {
    "__new__": [
      "cls",
      "data",
      "requires_grad",
      "quant_state",
      "blocksize",
      "compress_statistics",
      "quant_type",
      "quant_storage",
      "module",
      "bnb_quantized"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "__deepcopy__": [
      "self",
      "memo"
    ],
    "__copy__": [
      "self"
    ],
    "from_prequantized": [
      "cls",
      "data",
      "quantized_stats",
      "requires_grad",
      "device",
      "module"
    ],
    "_quantize": [
      "self",
      "device"
    ],
    "cpu": [
      "self"
    ],
    "cuda": [
      "self",
      "device",
      "non_blocking"
    ],
    "xpu": [
      "self",
      "device",
      "non_blocking"
    ],
    "to": [
      "self"
    ],
    "__torch_function__": [
      "cls",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "fix_4bit_weight_quant_state_from_module": [
    "module"
  ],
  "Linear4bit": {
    "__init__": [
      "self",
      "input_features",
      "output_features",
      "bias",
      "compute_dtype",
      "compress_statistics",
      "quant_type",
      "quant_storage",
      "device"
    ],
    "set_compute_type": [
      "self",
      "x"
    ],
    "_save_to_state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LinearFP4": {
    "__init__": [
      "self",
      "input_features",
      "output_features",
      "bias",
      "compute_dtype",
      "compress_statistics",
      "quant_storage",
      "device"
    ]
  },
  "LinearNF4": {
    "__init__": [
      "self",
      "input_features",
      "output_features",
      "bias",
      "compute_dtype",
      "compress_statistics",
      "quant_storage",
      "device"
    ]
  },
  "Int8Params": {
    "__new__": [
      "cls",
      "data",
      "requires_grad",
      "has_fp16_weights",
      "CB",
      "SCB"
    ],
    "_quantize": [
      "self",
      "device"
    ],
    "cpu": [
      "self"
    ],
    "cuda": [
      "self",
      "device",
      "non_blocking"
    ],
    "xpu": [
      "self",
      "device",
      "non_blocking"
    ],
    "__deepcopy__": [
      "self",
      "memo"
    ],
    "to": [
      "self"
    ]
  },
  "maybe_rearrange_weight": [
    "state_dict",
    "prefix",
    "local_metadata",
    "strict",
    "missing_keys",
    "unexpected_keys",
    "error_msgs"
  ],
  "Embedding8bit": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "device",
      "dtype"
    ],
    "_save_to_state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Embedding4bit": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "dtype",
      "quant_type",
      "quant_storage",
      "device"
    ],
    "_forward_with_partial_dequantize": [
      "self",
      "input"
    ],
    "_save_to_state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "EmbeddingFP4": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "dtype",
      "quant_storage",
      "device"
    ]
  },
  "EmbeddingNF4": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "dtype",
      "quant_storage",
      "device"
    ]
  },
  "Linear8bitLt": {
    "__init__": [
      "self",
      "input_features",
      "output_features",
      "bias",
      "has_fp16_weights",
      "threshold",
      "index",
      "device"
    ],
    "_save_to_state_dict": [
      "self",
      "destination",
      "prefix",
      "keep_vars"
    ],
    "_load_from_state_dict": [
      "self",
      "state_dict",
      "prefix",
      "local_metadata",
      "strict",
      "missing_keys",
      "unexpected_keys",
      "error_msgs"
    ],
    "init_8bit_state": [
      "self"
    ],
    "to": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OutlierAwareLinear": {
    "__init__": [
      "self",
      "input_features",
      "output_features",
      "bias",
      "device"
    ],
    "forward_with_outliers": [
      "self",
      "x",
      "outlier_idx"
    ],
    "quantize_weight": [
      "self",
      "w",
      "outlier_idx"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SwitchBackLinearBnb": {
    "__init__": [
      "self",
      "input_features",
      "output_features",
      "bias",
      "has_fp16_weights",
      "memory_efficient_backward",
      "threshold",
      "index",
      "device"
    ],
    "init_8bit_state": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_RELATED_PACKAGES": [],
  "sanity_check": [],
  "get_package_version": [
    "name"
  ],
  "show_environment": [],
  "main": [],
  "HEADER_WIDTH": [],
  "print_header": [
    "txt",
    "width",
    "filler"
  ],
  "print_dedented": [
    "text"
  ],
  "CUDART_PATH_PREFERRED_ENVVARS": [],
  "CUDART_PATH_IGNORED_ENVVARS": [],
  "CUDA_RUNTIME_LIB_PATTERNS": [],
  "find_cuda_libraries_in_path_list": [
    "paths_list_candidate"
  ],
  "is_relevant_candidate_env_var": [
    "env_var",
    "value"
  ],
  "get_potentially_lib_path_containing_env_vars": [],
  "find_cudart_libraries": [],
  "_print_cuda_diagnostics": [
    "cuda_specs"
  ],
  "_print_hip_diagnostics": [
    "cuda_specs"
  ],
  "print_diagnostics": [
    "cuda_specs"
  ],
  "_print_cuda_runtime_diagnostics": [],
  "_print_hip_runtime_diagnostics": [],
  "print_runtime_diagnostics": [],
  "LARS": {
    "__init__": [
      "self",
      "params",
      "lr",
      "momentum",
      "dampening",
      "weight_decay",
      "nesterov",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "max_unorm"
    ]
  },
  "LARS8bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "momentum",
      "dampening",
      "weight_decay",
      "nesterov",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "max_unorm"
    ]
  },
  "LARS32bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "momentum",
      "dampening",
      "weight_decay",
      "nesterov",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "max_unorm"
    ]
  },
  "PytorchLARS": {
    "__init__": [
      "self",
      "params",
      "lr",
      "momentum",
      "dampening",
      "weight_decay",
      "nesterov",
      "max_unorm"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "Adam": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "is_paged"
    ]
  },
  "Adam8bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "is_paged"
    ]
  },
  "Adam32bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "is_paged"
    ]
  },
  "PagedAdam": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "is_paged"
    ]
  },
  "PagedAdam8bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "is_paged"
    ]
  },
  "PagedAdam32bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "is_paged"
    ]
  },
  "SGD": {
    "__init__": [
      "self",
      "params",
      "lr",
      "momentum",
      "dampening",
      "weight_decay",
      "nesterov",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "SGD8bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "momentum",
      "dampening",
      "weight_decay",
      "nesterov",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "SGD32bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "momentum",
      "dampening",
      "weight_decay",
      "nesterov",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "LAMB": {
    "__init__": [
      "self",
      "params",
      "lr",
      "bias_correction",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "adam_w_mode",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "max_unorm"
    ]
  },
  "LAMB8bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "bias_correction",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "adam_w_mode",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "max_unorm"
    ]
  },
  "LAMB32bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "bias_correction",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "adam_w_mode",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "max_unorm"
    ]
  },
  "RMSprop": {
    "__init__": [
      "self",
      "params",
      "lr",
      "alpha",
      "eps",
      "weight_decay",
      "momentum",
      "centered",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "RMSprop8bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "alpha",
      "eps",
      "weight_decay",
      "momentum",
      "centered",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "RMSprop32bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "alpha",
      "eps",
      "weight_decay",
      "momentum",
      "centered",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "_ReferenceAdEMAMix": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "alpha",
      "eps",
      "weight_decay",
      "t_beta3",
      "t_alpha"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "AdEMAMix": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "alpha",
      "t_alpha",
      "t_beta3",
      "eps",
      "weight_decay",
      "optim_bits",
      "min_8bit_size",
      "is_paged"
    ],
    "init_state": [
      "self",
      "group",
      "p",
      "gindex",
      "pindex"
    ],
    "update_step": [
      "self",
      "group",
      "p",
      "gindex",
      "pindex"
    ],
    "_get_state_double_buffer": [
      "self",
      "p",
      "dtype"
    ]
  },
  "AdEMAMix8bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "alpha",
      "t_alpha",
      "t_beta3",
      "eps",
      "weight_decay",
      "min_8bit_size",
      "is_paged"
    ]
  },
  "PagedAdEMAMix8bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "alpha",
      "t_alpha",
      "t_beta3",
      "eps",
      "weight_decay",
      "min_8bit_size"
    ]
  },
  "PagedAdEMAMix": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "alpha",
      "t_alpha",
      "t_beta3",
      "eps",
      "weight_decay",
      "optim_bits",
      "min_8bit_size"
    ]
  },
  "AdEMAMix32bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "alpha",
      "t_alpha",
      "t_beta3",
      "eps",
      "weight_decay",
      "min_8bit_size",
      "is_paged"
    ]
  },
  "PagedAdEMAMix32bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "alpha",
      "t_alpha",
      "t_beta3",
      "eps",
      "weight_decay",
      "min_8bit_size"
    ]
  },
  "Adagrad": {
    "__init__": [
      "self",
      "params",
      "lr",
      "lr_decay",
      "weight_decay",
      "initial_accumulator_value",
      "eps",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "Adagrad8bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "lr_decay",
      "weight_decay",
      "initial_accumulator_value",
      "eps",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "Adagrad32bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "lr_decay",
      "weight_decay",
      "initial_accumulator_value",
      "eps",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "Lion": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "weight_decay",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "is_paged"
    ]
  },
  "Lion8bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "weight_decay",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "is_paged"
    ]
  },
  "Lion32bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "weight_decay",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "is_paged"
    ]
  },
  "PagedLion": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "weight_decay",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "PagedLion8bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "weight_decay",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "PagedLion32bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "weight_decay",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "AdamW": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "is_paged"
    ]
  },
  "AdamW8bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "is_paged"
    ]
  },
  "AdamW32bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "is_paged"
    ]
  },
  "PagedAdamW": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "PagedAdamW8bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "PagedAdamW32bit": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "amsgrad",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise"
    ]
  },
  "MockArgs": {
    "__init__": [
      "self",
      "initial_data"
    ]
  },
  "GlobalOptimManager": {
    "_instance": [],
    "__init__": [
      "self"
    ],
    "initialize": [
      "self"
    ],
    "get_instance": [
      "cls"
    ],
    "register_parameters": [
      "self",
      "params"
    ],
    "override_config": [
      "self",
      "parameters",
      "key",
      "value",
      "key_value_dict"
    ],
    "register_module_override": [
      "self",
      "module",
      "param_name",
      "config"
    ]
  },
  "Optimizer8bit": {
    "__init__": [
      "self",
      "params",
      "defaults",
      "optim_bits",
      "is_paged"
    ],
    "fill_qmap": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "move_to_device"
    ],
    "to_gpu": [
      "self"
    ],
    "check_overrides": [
      "self"
    ],
    "step": [
      "self",
      "closure"
    ],
    "get_config": [
      "self",
      "gindex",
      "pindex",
      "group"
    ],
    "init_state": [
      "self",
      "group",
      "p",
      "gindex",
      "pindex"
    ],
    "update_step": [
      "self",
      "group",
      "p",
      "gindex",
      "pindex"
    ],
    "get_state_buffer": [
      "self",
      "p",
      "dtype"
    ],
    "prefetch_state": [
      "self",
      "p"
    ]
  },
  "Optimizer2State": {
    "__init__": [
      "self",
      "optimizer_name",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "max_unorm",
      "skip_zeros",
      "is_paged",
      "alpha",
      "t_alpha",
      "t_beta3"
    ],
    "init_state": [
      "self",
      "group",
      "p",
      "gindex",
      "pindex"
    ],
    "update_step": [
      "self",
      "group",
      "p",
      "gindex",
      "pindex"
    ]
  },
  "Optimizer1State": {
    "__init__": [
      "self",
      "optimizer_name",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "optim_bits",
      "args",
      "min_8bit_size",
      "percentile_clipping",
      "block_wise",
      "max_unorm",
      "skip_zeros",
      "is_paged"
    ],
    "init_state": [
      "self",
      "group",
      "p",
      "gindex",
      "pindex"
    ],
    "update_step": [
      "self",
      "group",
      "p",
      "gindex",
      "pindex"
    ]
  },
  "_NF4_QUANT_TABLE": [],
  "_FP4_QUANT_TABLE": [],
  "CODE": [],
  "get_gaudi_sw_version": [],
  "GAUDI_SW_VER": [],
  "_try_torch_compile": [
    "func"
  ],
  "_int8_linear_matmul_impl": [
    "A",
    "B",
    "out"
  ],
  "_dequantize_4bit_impl": [
    "A",
    "absmax",
    "blocksize",
    "quant_type",
    "shape",
    "dtype"
  ],
  "MOMENTUM": [],
  "RMSPROP": [],
  "ADAGRAD": [],
  "ADAM": [],
  "LION": [],
  "ADEMAMIX": [],
  "name2optimizer_id": [],
  "_optimizer_precondition_32bit": [
    "g",
    "p",
    "state1",
    "state2",
    "unorm_vec",
    "beta1",
    "beta2",
    "eps",
    "weight_decay",
    "step",
    "lr",
    "gnorm_scale",
    "optimizer_id"
  ],
  "_optimizer_update_32bit": [
    "g",
    "p",
    "state1",
    "state2",
    "unorm_vec",
    "max_unorm",
    "param_norm",
    "beta1",
    "beta2",
    "beta3",
    "alpha",
    "eps",
    "weight_decay",
    "step",
    "lr",
    "gnorm_scale",
    "optimizer_id"
  ],
  "_optimizer_precondition_2state_32bit": [
    "g_ptr",
    "p_ptr",
    "state1_ptr",
    "state2_ptr",
    "unorm_ptr",
    "beta1",
    "beta2",
    "eps",
    "weight_decay",
    "step",
    "beta1_step",
    "beta2_step",
    "lr",
    "gnorm_scale",
    "n_elements",
    "OPTIMIZER_ID",
    "BLOCK_SIZE",
    "N_PER_TH"
  ],
  "_optimizer_precondition_1state_32bit": [
    "g_ptr",
    "p_ptr",
    "state1_ptr",
    "state2_ptr",
    "unorm_ptr",
    "beta1",
    "beta2",
    "eps",
    "weight_decay",
    "step",
    "beta1_step",
    "beta2_step",
    "lr",
    "gnorm_scale",
    "n_elements",
    "OPTIMIZER_ID",
    "BLOCK_SIZE",
    "N_PER_TH"
  ],
  "_optimizer_update_2state_32bit_triton_kernel": [
    "g_ptr",
    "p_ptr",
    "state1_ptr",
    "state2_ptr",
    "unorm_ptr",
    "max_unorm",
    "param_norm",
    "beta1",
    "beta2",
    "beta3",
    "alpha",
    "eps",
    "weight_decay",
    "step",
    "beta1_step",
    "beta2_step",
    "lr",
    "gnorm_scale",
    "skip_zeros",
    "n_elements",
    "OPTIMIZER_ID",
    "BLOCK_SIZE",
    "N_PER_TH"
  ],
  "_optimizer_update_1state_32bit_triton_kernel": [
    "g_ptr",
    "p_ptr",
    "state1_ptr",
    "state2_ptr",
    "unorm_ptr",
    "max_unorm",
    "param_norm",
    "beta1",
    "beta2",
    "beta3",
    "alpha",
    "eps",
    "weight_decay",
    "step",
    "beta1_step",
    "beta2_step",
    "lr",
    "gnorm_scale",
    "skip_zeros",
    "n_elements",
    "OPTIMIZER_ID",
    "BLOCK_SIZE",
    "N_PER_TH"
  ],
  "name2optimizer_32bit_fn": [],
  "optimizer_update_32bit_impl": [
    "optimizer_name",
    "g",
    "p",
    "state1",
    "state2",
    "unorm_vec",
    "max_unorm",
    "param_norm",
    "beta1",
    "beta2",
    "beta3",
    "alpha",
    "eps",
    "weight_decay",
    "step",
    "lr",
    "gnorm_scale",
    "skip_zeros"
  ],
  "_dequantize_blockwise_pytorch": [
    "A",
    "absmax",
    "code",
    "blocksize",
    "dtype"
  ],
  "_quantize_blockwise_pytorch": [
    "A",
    "code",
    "blocksize"
  ],
  "optimizer_update_8bit_blockwise_pytorch": [
    "p",
    "g",
    "state1",
    "state2",
    "beta1",
    "beta2",
    "beta3",
    "alpha",
    "eps",
    "step",
    "lr",
    "qmap1",
    "qmap2",
    "absmax1",
    "absmax2",
    "weight_decay",
    "gnorm_scale",
    "skip_zeros"
  ],
  "optimizer_update_8bit_blockwise_triton_quant": [
    "p",
    "g",
    "state1",
    "state2",
    "beta1",
    "beta2",
    "beta3",
    "alpha",
    "eps",
    "step",
    "lr",
    "qmap1",
    "qmap2",
    "absmax1",
    "absmax2",
    "weight_decay",
    "gnorm_scale",
    "skip_zeros"
  ],
  "_optimizer_update_1state_8bit_blockwise_triton_kernel": [
    "p_ptr",
    "g_ptr",
    "state1_ptr",
    "state2_ptr",
    "beta1",
    "beta2",
    "beta3",
    "alpha",
    "eps",
    "step",
    "beta1_step",
    "beta2_step",
    "lr",
    "qmap1_ptr",
    "qmap2_ptr",
    "absmax1_ptr",
    "absmax2_ptr",
    "weight_decay",
    "gnorm_scale",
    "n_elements",
    "BLOCK_SIZE_N",
    "N_PER_TH",
    "OPTIMIZER_ID"
  ],
  "_optimizer_update_2state_8bit_blockwise_triton_kernel": [
    "p_ptr",
    "g_ptr",
    "state1_ptr",
    "state2_ptr",
    "beta1",
    "beta2",
    "beta3",
    "alpha",
    "eps",
    "step",
    "beta1_step",
    "beta2_step",
    "lr",
    "qmap1_ptr",
    "qmap2_ptr",
    "absmax1_ptr",
    "absmax2_ptr",
    "weight_decay",
    "gnorm_scale",
    "n_elements",
    "BLOCK_SIZE_N",
    "N_PER_TH",
    "OPTIMIZER_ID"
  ],
  "name2optimizer_fn": [],
  "optimizer_update_8bit_blockwise_impl": [],
  "quantize_fp4_blockwise_kernel": [
    "A_ptr",
    "absmax_ptr",
    "out_ptr",
    "n_elements",
    "BLOCK_SIZE",
    "SPLIT_NUM_BLOCKS"
  ],
  "quantize_nf4_blockwise_kernel": [
    "A_ptr",
    "absmax_ptr",
    "out_ptr",
    "n_elements",
    "BLOCK_SIZE",
    "SPLIT_NUM_BLOCKS"
  ],
  "quantize_4bit_blockwise_triton": [
    "A",
    "blocksize",
    "quant_type",
    "blocks",
    "absmax",
    "num_elements",
    "quantized_out"
  ],
  "dequant_4bit_body_util": [
    "a",
    "offsets",
    "quant_ptr",
    "absmax_ptr",
    "n_elems",
    "QUANT_BLOCK"
  ],
  "dequantize_fp4_tree": [
    "val",
    "absmax"
  ],
  "dequant_fp4_body_util": [
    "a",
    "offsets",
    "absmax_ptr",
    "n_elems",
    "QUANT_BLOCK"
  ],
  "dequantize_nf4_tree": [
    "val"
  ],
  "dequant_nf4_body_util": [
    "a",
    "offsets",
    "absmax_ptr",
    "n_elems",
    "QUANT_BLOCK"
  ],
  "dequant_4bit_kernel": [
    "a_ptr",
    "c_ptr",
    "quant_ptr",
    "absmax_ptr",
    "num_paired_elements",
    "QUANT_BLOCK",
    "SPLIT_SIZE"
  ],
  "dequant_fp4_kernel": [
    "a_ptr",
    "c_ptr",
    "absmax_ptr",
    "num_paired_elements",
    "QUANT_BLOCK",
    "SPLIT_SIZE"
  ],
  "dequant_nf4_kernel": [
    "a_ptr",
    "c_ptr",
    "absmax_ptr",
    "num_paired_elements",
    "QUANT_BLOCK",
    "SPLIT_SIZE"
  ],
  "dequantize_4bit_impl": [
    "A",
    "absmax",
    "blocksize",
    "quant_type",
    "dtype",
    "out"
  ],
  "dequantize_4bit_impl_passing_code": [
    "A",
    "absmax",
    "blocksize",
    "code",
    "dtype",
    "out"
  ],
  "quantize_4bit_blockwise_kernel": [
    "A_ptr",
    "code_ptr",
    "absmax_ptr",
    "out_ptr",
    "n_elements",
    "BLOCK_SIZE",
    "CODE_SIZE",
    "SPLIT_NUM_BLOCKS"
  ],
  "device_type": [],
  "torch_accelerator_module": [],
  "dequantize_blockwise_inplace": [
    "A",
    "absmax",
    "code",
    "blocksize",
    "dtype",
    "out"
  ],
  "dequantize_4bit_inplace": [
    "A",
    "absmax",
    "blocksize",
    "quant_type",
    "shape",
    "dtype",
    "out"
  ],
  "dequant_8bit_kernel": [
    "a_ptr",
    "out_ptr",
    "code_ptr",
    "absmax_ptr",
    "n",
    "QUANT_BLOCK",
    "SPLIT_SIZE"
  ],
  "dequant_8bit_blockwise": [
    "a",
    "absmax",
    "quant_state_code",
    "quant_blocksize",
    "dtype",
    "out"
  ],
  "quantize_8bit_blockwise_kernel": [
    "A_ptr",
    "code_ptr",
    "absmax_ptr",
    "out_ptr",
    "n_elements",
    "BLOCK_SIZE",
    "CODE_SIZE",
    "SPLIT_NUM_BLOCKS"
  ],
  "quantize_blockwise_triton": [
    "A",
    "code",
    "blocksize",
    "absmax",
    "out"
  ],
  "quantize_8bit_blockwise_kernel_util": [
    "a",
    "code_ptr",
    "CODE_SIZE",
    "BLOCK_SIZE",
    "N_PER_TH"
  ],
  "dequant_8bit_blockwise_kernel_util": [
    "a_ptr",
    "offsets",
    "code_ptr",
    "absmax_ptr",
    "mask",
    "BLOCK_SIZE"
  ],
  "_reverse_4bit_compress_format": [
    "weight"
  ],
  "_dequantize_blockwise_impl": [
    "A",
    "absmax",
    "code",
    "blocksize",
    "dtype",
    "out"
  ],
  "_gemv_4bit_impl": [
    "A",
    "B",
    "shapeB",
    "absmax",
    "code",
    "blocksize",
    "out"
  ],
  "_get_col_absmax": [
    "A",
    "threshold"
  ],
  "str2optimizer32bit": [],
  "str2optimizer8bit_blockwise": [],
  "_optimizer_update_32bit_impl": [
    "optimizer_name",
    "g",
    "p",
    "state1",
    "state2",
    "unorm_vec",
    "max_unorm",
    "param_norm",
    "beta1",
    "beta2",
    "beta3",
    "alpha",
    "eps",
    "weight_decay",
    "step",
    "lr",
    "gnorm_scale",
    "skip_zeros"
  ],
  "_optimizer_update_8bit_blockwise_impl": [
    "optimizer_name",
    "g",
    "p",
    "state1",
    "state2",
    "beta1",
    "beta2",
    "beta3",
    "alpha",
    "eps",
    "step",
    "lr",
    "qmap1",
    "qmap2",
    "absmax1",
    "absmax2",
    "weight_decay",
    "gnorm_scale",
    "skip_zeros"
  ],
  "_has_avx512": []
}