{
  "_memoized_token_counters": [],
  "_NON_WHITESPACE_SEMANTIC_SPLITTERS": [],
  "_REGEX_ESCAPED_NON_WHITESPACE_SEMANTIC_SPLITTERS": [],
  "_split_text": [
    "text"
  ],
  "bisect_left": [
    "sorted",
    "target",
    "low",
    "high"
  ],
  "merge_splits": [
    "splits",
    "cum_lens",
    "chunk_size",
    "splitter",
    "token_counter",
    "start",
    "high"
  ],
  "chunk": [
    "text",
    "chunk_size",
    "token_counter",
    "memoize",
    "offsets",
    "overlap",
    "cache_maxsize",
    "_recursion_depth",
    "_start"
  ],
  "Chunker": {
    "__init__": [
      "self",
      "chunk_size",
      "token_counter"
    ],
    "_make_chunk_function": [
      "self",
      "offsets",
      "overlap"
    ],
    "__call__": [
      "self",
      "text_or_texts",
      "processes",
      "progress",
      "offsets",
      "overlap"
    ]
  },
  "chunkerify": [
    "tokenizer_or_token_counter",
    "chunk_size",
    "max_token_chars",
    "memoize",
    "cache_maxsize"
  ]
}